ADAPTIVE 2021
The Thirteenth International Conference on Adaptive and Self-Adaptive Systems
and Applications
ISBN: 978-1-61208-848-8
April 18 - 22, 2021
ADAPTIVE 2021 Editors
Andreas Rausch, TU Clausthal, Germany

ADAPTIVE 2021
Forward
The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications
(ADAPTIVE 2021), held on April 18 - 22, 2021, continued a series of events targeting advanced system
and application design paradigms driven by adaptiveness and self-adaptiveness. With the current
tendencies in developing and deploying complex systems, and under the continuous changes of system
and application requirements, adaptation is a key feature. Speed and scalability of changes require self-
adaptation for special cases. How to build systems to be easily adaptive and self-adaptive, what
constraints and what mechanisms must be used, and how to evaluate a stable state in such systems are
challenging duties. Context-aware and user-aware are major situations where environment and user
feedback is considered for further adaptation.
The conference had the following tracks:

Self-adaptation

Adaptive applications

Adaptivity in robot systems

Fundamentals and design of adaptive systems
Similar to the previous edition, this event attracted excellent contributions and active participation from
all over the world. We were very pleased to receive top quality contributions.
We take here the opportunity to warmly thank all the members of the ADAPTIVE 2021 technical
program committee, as well as the numerous reviewers. The creation of a high quality conference
program would not have been possible without their involvement. We also kindly thank all the authors
that dedicated much of their time and effort to contribute to ADAPTIVE 2021. We truly believe that,
thanks to all these efforts, the final conference program consisted of top quality contributions.
Also, this event could not have been a reality without the support of many individuals, organizations and
sponsors. We also gratefully thank the members of the ADAPTIVE 2021 organizing committee for their
help in handling the logistics and for their work that made this professional meeting a success.
We hope ADAPTIVE 2021 was a successful international forum for the exchange of ideas and results
between academia and industry and to promote further progress in the area of adaptive and self-
adaptive systems and applications.
ADAPTIVE 2021 General Chair
Jaime Lloret Mauri, Universitat Politecnica de Valencia, Spain
ADAPTIVE 2021 Steering Committee
Constantin Paleologu, University Politehnica of Bucharest, Romania

Claudia Raibulet, University of Milano-Bicocca, Italy
Sebastian Herold, Karlstad University, Department for Mathematics & Computer Science, Sweden
Andreas Rausch, TU Clausthal, Clausthal-Zellerfeld, Germany
Marc Kurz, University of Applied Sciences Upper Austria, Faculty for Informatics, Communications and
Media, Austria
Valerie Camps, Paul Sabatier University - IRIT, Toulouse, France
Yukio Hayashi, Japan Advanced Institute of Science and Technology, Japan
ADAPTIVE 2021 Publicity Chair
Jose Luis García, Universitat Politecnica de Valencia, Spain
Lorena Parra, Universitat Politecnica de Valencia, Spain
ADAPTIVE 2021 Industry/Research Advisory Committee
Habtamu Abie, Norwegian Computing Center/Norsk Regnesentral-Blindern, Norway
Marc-Philippe Huget, Polytech Annecy-Chambery-LISTIC | University of Savoie, France

ADAPTIVE 2021
Committee
ADAPTIVE 2021 General Chair
Jaime Lloret Mauri, Universitat Politecnica de Valencia, Spain
ADAPTIVE 2021 Steering Committee
Constantin Paleologu, University Politehnica of Bucharest, Romania
Claudia Raibulet, University of Milano-Bicocca, Italy
Sebastian Herold, Karlstad University, Department for Mathematics & Computer Science, Sweden
Andreas Rausch, TU Clausthal, Clausthal-Zellerfeld, Germany
Marc Kurz, University of Applied Sciences Upper Austria, Faculty for Informatics, Communications and
Media, Austria
Valerie Camps, Paul Sabatier University - IRIT, Toulouse, France
Yukio Hayashi, Japan Advanced Institute of Science and Technology, Japan
ADAPTIVE 2021 Industry/Research Advisory Committee
Habtamu Abie, Norwegian Computing Center/Norsk Regnesentral-Blindern, Norway
Marc-Philippe Huget, Polytech Annecy-Chambery-LISTIC | University of Savoie, France
ADAPTIVE 2021 Publicity Chairs
Jose Luis García, Universitat Politecnica de Valencia, Spain
Lorena Parra, Universitat Politecnica de Valencia, Spain
ADAPTIVE 2021 Technical Program Committee
Ibrahim Abdallah Abbas Atwa Elgendy, School of Computer Science and Technology | Harbin Institute of
Technology, China
Habtamu Abie, Norwegian Computing Center/Norsk Regnesentral-Blindern, Norway
Rasha Abu Qasem, Technische Universität Kaiserslautern, Germany
Harvey Alférez, Universidad de Montemorelos, Mexico
Raid Al-Nima, Northern Technical University, Iraq
Nik Bessis, Edge Hill University, UK
Antonio Brogi, University of Pisa, Italy
Barbara Buck, Boeing Global Services, USA
Valerie Camps, Paul Sabatier University - IRIT, Toulouse, France
Enrique Chirivella Perez, University West of Scotland, UK
Angel P. del Pobil, Jaume I University, Spain
Holger Eichelberger, University of Hildesheim, Germany

Fairouz Fakhfakh, University of Sfax, Tunisia
Yukio Hayashi, Japan Advanced Institute of Science and Technology, Japan
Hongsheng He, Wichita State University, USA
Sebastian Herold, Karlstad University, Department for Mathematics & Computer Science, Sweden
Koen Hindriks, Vrije University Amsterdam, Netherlands
Christopher-Eyk Hrabia, Technische Universität Berlin | DAI-Labor, Germany
Marc-Philippe Huget, Polytech Annecy-Chambery-LISTIC | University of Savoie, France
Francisco José García-Peñalvo, University of Salamanca, Spain
Imène Jraidi, McGill University - ATLAS Lab, Canada
Yasushi Kambayashi, Nippon Institute of Technology, Japan
Michael Katchabaw, Western University, London - Ontario, Canada
Stephan Kluth, FOM Hochschule für Oekonomie & Management gemeinnützige Gesellschaft mbH,
Germany
Abigail Koay, University of Waikato, New Zealand
Marc Kurz, University of Applied Sciences Upper Austria - Faculty for Informatics, Communications and
Media, Austria
Mikel Larrea, University of the Basque Country UPV/EHU, Spain
Mieke Massink, CNR-ISTI, Italy
James E. McCarthy, Instructional Systems - Sonalysts Inc., USA
René Meier, Lucerne University of Applied Sciences and Arts, Switzerland
Philippe Merle, UniversityofLille, France
Andreas Metzger, University of Duisburg-Essen, Germany
Amgad Mohammed Elsayed, University of Deusto, Spain
Vasco N. G. J. Soares, Instituto de Telecomunicações / Instituto Politécnico de Castelo Branco, Portugal
Filippo Neri, University of Napoli "Federico II", Italy
Karol Niewiadomski, University of Wuppertal, Germany
Ashley Oiknine, DCS Corporation / Army Research Laboratory / University of California, Santa Barbara,
USA
Krzysztof Okarma, West Pomeranian University of Technology in Szczecin, Poland
Joanna Isabelle Olszewska, University of West Scotland, UK
Constantin Paleologu, University Politehnica of Bucharest, Romania
Khoa Pham, The University of Manchester, UK
Marcin Pietron, University of Science and Technology in Cracow, Poland
Agostino Poggi, Università degli Studi di Parma, Italy
Claudia Raibulet, University of Milano-Bicocca, Italy
Andreas Rausch, TU Clausthal, Clausthal-Zellerfeld, Germany
Ruben Ricart Sanchez, University West of Scotland, UK
Oliver Roesler, Vrije Universiteit Brussel, Belgium
Joerg Roth, Nuremberg Institute of Technology, Germany
José Santos Reyes, University of A Coruña, Spain
Jagannathan (Jag) Sarangapani, Missouri University of Science and Technology, USA
Ichiro Satoh, National Institute of Informatics, Japan
Melanie Schranz, Lakeside Labs GmbH, Austria
Erik Sonnleitner, University of Applied Sciences Upper Austria - Faculty for Informatics, Communications
and Media, Austria, Germany
Mohammad Divband Soorati,University of Southampton, UK
Cristian-Lucian Stanciu, University Politehnica of Bucharest, Romania
Roy Sterritt, Ulster University, UK

Justyna Swidrak, August Pi & Sunyer Biomedical Research Institute (IDIBAPS), Barcelona, Spain / Institute
of Psychology - Polish Academy of Sciences, Warsaw, Poland
Christof Teuscher, Portland State University, USA
Jaap van den Herik, Leiden Centre of Data Science (LCDS) | Leiden University, Leiden, The Netherlands

Copyright Information
For your reference, this is the text governing the copyright release for material published by IARIA.
The copyright release is a transfer of publication rights, which allows IARIA and its partners to drive the
dissemination of the published material. This allows IARIA to give articles increased visibility via
distribution, inclusion in libraries, and arrangements for submission to indexes.
I, the undersigned, declare that the article is original, and that I represent the authors of this article in
the copyright release matters. If this work has been done as work-for-hire, I have obtained all necessary
clearances to execute a copyright release. I hereby irrevocably transfer exclusive copyright for this
material to IARIA. I give IARIA permission or reproduce the work in any media format such as, but not
limited to, print, digital, or electronic. I give IARIA permission to distribute the materials without
restriction to any institutions or individuals. I give IARIA permission to submit the work for inclusion in
article repositories as IARIA sees fit.
I, the undersigned, declare that to the best of my knowledge, the article is does not contain libelous or
otherwise unlawful contents or invading the right of privacy or infringing on a proprietary right.
Following the copyright release, any circulated version of the article must bear the copyright notice and
any header and footer information that IARIA applies to the published article.
IARIA grants royalty-free permission to the authors to disseminate the work, under the above
provisions, for any academic, commercial, or industrial use. IARIA grants royalty-free permission to any
individuals or institutions to make the article available electronically, online, or in print.
IARIA acknowledges that rights to any algorithm, process, procedure, apparatus, or articles of
manufacture remain with the authors and their employers.
I, the undersigned, understand that IARIA will not be liable, in contract, tort (including, without
limitation, negligence), pre-contract or other representations (other than fraudulent
misrepresentations) or otherwise in connection with the publication of my work.
Exception to the above is made for work-for-hire performed while employed by the government. In that
case, copyright to the material remains with the said government. The rightful owners (authors and
government entity) grant unlimited and unrestricted permission to IARIA, IARIA's contractors, and
IARIA's partners to further distribute the work.

Table of Contents
Smart Self-Adaptive Cyber-Physical Systems: How can Exploration and Learning Improve Performance in a
Partially Observable Multi-Agent Context?
Ana Petrovska, Malte Neuss, Sebastian Bergemann, Martin Buchner, and Muhammad Ansab Shohab
1
Variable-Regularized Low-Complexity RLS Adaptive Algorithms for Bilinear Forms
Ionut-Dorinel Ficiu, Camelia Elisei-Iliescu, Cristian-Lucian Stanciu, and Constantin Paleologu
9
With Cross-Industry Innovation to a Circular Economy
Andrea Lutsch
13
Powered by TCPDF (www.tcpdf.org)

Smart Self-Adaptive Cyber-Physical Systems: How can Exploration and Learning
Improve Performance in a Partially Observable Multi-Agent Context?
Ana Petrovska, Malte Neuss, Sebastian Bergemann, Martin B¨uchner, M. Ansab Shohab
Department of Informatics
Technical University of Munich
email: ana.petrovska, malte.neuss, sebastian.bergemann, martin.buechner, ansab.shohab@tum.de
Abstract—Cyber-physical
systems
(CPSs)
are
software-
intensive systems that are embedded in the physical world to
monitor, control and coordinate a variety of processes in both the
physical and the digital world. As a result, they often operate in
complex, dynamic, and unanticipated environments with various
potential sources of run-time changes and uncertainties, that
could potentially lead the CPSs to faults, and even to complete
system failures. To cope with these changes, the systems should
have the capabilities to self-adapt in order to continue meeting
their functional speciﬁcations. In this paper, we investigate how
creating self-adaptive CPSs which are able to collaborate and
learn in a dynamic, partially observable, multi-agent context,
can not only preserve but also improve the performance, despite
all the changes introduced to the system at run-time. We evaluate
the proposed methodology on an in-house developed, multi-agent
system from the robotics domain.
Keywords—self-adaptive systems, cyber-physical systems, collab-
oration, learning, partial observability
I. INTRODUCTION
In recent years, the widespread availability of cost-effective
embedded systems with increasing computation power and
the expansion of wireless networks have led to a solid
foundation for emergence and advancement of the pervasive
Cyber-Physical Systems (CPSs) in a multitude of different
domains, with progressively increasing technological and so-
cial inﬂuence. Modern CPSs, which lie in the intersection
of the control, computation and communication area [1], are
composed of many interacting and interconnected components,
while inheriting all the complexities of large-scale distributed
systems [2]. Also, they need to be able to operate efﬁciently
and reliably within a continually changing, uncertain, and
unanticipated environments or execution contexts [3] [4] [5].
Furthermore, they need to be able to collaborate and cooperate
with another CPSs towards realizing common goals, which a
single system or agent itself would not be able to achieve on
its own. To successfully cope with the change introduced at
run-time (and cannot be predicted during the design of the
system), these systems should be therefore engineered with
properties to learn, and to automatically and independently
modify themselves without any external human involvement
[6] [7] . The run-time changes can originate from 1) the CPSs
themselves and 2) from the context where these agents are
operating.
A. Motivation
The need for self-adaptive systems stems from the ideas
initially introduced in “The Vision of Autonomic Computing”
[8] by Kephart and Chess, where the authors envision the sys-
tems from the future to only manage themselves accordingly to
high-level business goals given by human administrators. In a
future world, where the present-days engineers and developers
become obsolete, systems organize and manage themselves in
a completely autonomous manner. These ideas, anticipating
fully autonomous self-engineering and self-managing systems,
still remain “ideas that are not science ﬁction, but elements
of the grand challenge [8]”. From a current time-point, it
is impossible to argue on how the systems from the future
will be engineered, but instead, continuous step-by-step inte-
gration of the contemporary concepts and ideas is necessary.
Consequently, self-adaptive systems can be considered as an
intermediate step toward complete autonomicity.
On a conceptual level a self-adaptive system, is comprised
of a managed element and adaptation logic, as shown in
Figure 1. The managed element is the entity that acquires
self-adaptation capabilities, given by the adaptation logic. A
common approach to realize the adaptation logic of a self-
adaptive system is through the MAPE-K (Monitor, Analyze,
Plan, Execute) [8] feedback loop, with shared Knowledge
among all the components of the loop. The self-adaptive
system interacts with the context, which is the relevant part
of the environment, or the external world, for that particular
system.
5
Developers/ Engineers 
Human administrators/
Users 
Self-adaptive system
Adaptation logic 
Managed element
Context
Knowledge
Context
model
Mang. el.
model
Adapt.
goals
M
A
P
E
𝐼
𝑂
Figure 1. Updated conceptual model of a self-adaptive system from [4].
The internal changes in the managed element(s)—in our
case CPS(s); and/or changes in the context during run-time,
are triggers for the system to self-adapt. Additionally, it is
1
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

essential for the system to know why it is adapting for, or what
the adaptation goals are. As a result, as shown in the ﬁgure,
the knowledge in the adaptation logic presents an abstraction
of relevant aspects of the managed element(s), the context and
the system’s adaptation goals.
B. Background
Russel and Norvig in [9] categorize environments, or
contexts (as we refer to in this work) accordingly to a
few informally deﬁned dimensions: fully observable vs. par-
tially observable, single-agent vs. multiagent, deterministic
vs. stochastic, episodic vs. sequential, discrete vs. continuous
and known vs. unknown. Unknown context does not refer
to the context itself, but it refers to the robots’ knowledge
about the laws of physics of the context [9]. These deﬁned
dimensions, to a large extent, determine the appropriate system
design and implementation. According to the authors, the
hardest case is designing and implementing solutions for
systems operating in partially observable, multiagent, stochas-
tic, sequential, dynamic, continuous and unknown [9], or
abbreviated, PMSSDCU context. This exactly how we would
classify the context in which our multi-agent systems are
operating. In this paper, we propose a methodology that
provides an engineering solution for self-adaptive multi-agent
CPSs operating in PMSSDCU context.
C. Gaps and Contributions
The majority of the previous works in the self-adaptive
systems community provide approaches where 1) the adap-
tation logic is predetermined and its structure does not change
over time, e.g., [10], or 2) the operational context in which
the self-adaptive CPSs operate is predetermined and static,
and does not change during run-time, e.g., [11]. Having an
adaptation logic that is predeﬁned at the design of the system
and does not improve over time, cannot provide adequate and
accurate adaptation, when the self-adaptive systems and the
context in which they operating are dynamic and changing
in an unpredictable manner during run-time. As a result, the
adaptation logic should have mechanisms to modify itself in
order to reﬂect the run-time changes in the context where the
agents are operating. In this paper, we tackle this issue by
proposing a methodology for building adaptation logic for self-
adaptive CPSs that operate in a dynamic, partially observable,
multi-agent context. Precisely, we focus on building a self-
adaptive system, for multi-agent CPSs, with shared adaptation
logic, in which the knowledge in the adaptation is continuously
updated at run-time. In our work, the adaptation logic does
not only adapts the behaviour of the systems (the managed
elements), but it changes its own knowledge during run-time.
The contributions of the paper are the following:
1) We propose an approach for modeling the context in
the knowledge of the adaptation logic, based on globally
aggregated observations of from all the agents. It is based
on learning two probabilistic maps by storing the past
contextual encounters, which enable the agents to over
time gain knowledge about the laws of physics of the
context.
2) For multi-agent tasks allocation, which provides close-
to-optimal solution, is computationally feasible, and is
dynamically adaptable during run-time, we apply Prim
Allocation algorithm using minimum spanning forests
(MSF), proposed in [12].
3) We propose local path planning that minimizes the dis-
tance to the assigned task and maximize the context
exploration.
4) Additionally, for evaluating the ideas, in this paper,
we have developed an in-house, ROS-based, multi-agent
simulated system from the robotics domain. The robotic
system is based on a reference problem proposed in the
following section, which explains and motivates the need
for self-adaptivity.
The paper is organized as follows: Section II explains the
reference problem and motivates the need for self-adaptation.
The reference problem is additionally used as a running
example throughout the paper. Section III elaborates in more
depth the challenges that we are addressing in this work. The
three-step methodology is proposed in Section IV. The details
of the implementation of the multi-agent system are presented
in Section V. Subsequently, the beneﬁts of collaboration,
exploration, and learning are evaluated in Section VI. In
Section VII we conclude the paper.
II. REFERENCE PROBLEM
Our reference problem comes from the robotics domain, and
aims to motivate and support the need for self-adaptivity. The
reference problem is used as a running example in the paper.
Additionally, based on the reference problem, we have built
the robotic system presented in Section V.
The setting of our reference problem consists of the follow-
ing: (1) the context: a room with static obstacles (for example,
walls and interior) where dirt appears perpetually in different
places at different points in time; and (2) agents—CPSs:
autonomous, ground robots. The robots need to explore and
detect dirt tasks in the room, and attain them in the most
efﬁcient way (in the shortest period of time) despite different
run-time uncertainties [13], including the limited sensor range
(see Figure 2). Namely, the sensors of the robots have a limited
sensing range and they observe the context or the room where
they are deployed only partially. Consequently, the agents can
detect dirt that is only within their range of observations. Once
the dirt locations are detected and identiﬁed, they become
goals for the robots. Additionally, each robot is equipped
with a map of the room, and they use Adaptive Monte Carlo
Localization (AMCL) for navigation and localization.
In our reference problem, the robots monitor or observe
the context, and discover new tasks in a distributed manner.
There is no global view of the room, meaning that the
robots only discover tasks which are within their range of
observation. In this case, the agents not knowing what is
happening in the local surroundings of the other agents, brings
inefﬁciency to the overall performance, for example, when one
2
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Figure 2. View of the room and the deployed agents.
part of the room is getting dirtier than the other. The effects
of having a partially observable context, is that as a result
only a local performance maximum is possible. To achieve
global performance maximum, a cooperative aggregation of
the contextual observations of all the robots deployed in the
room is necessary.
A self-adaptive system has business or mission goals, re-
lated to the functional requirements of the agents; and self-
adaptation goals related to the quality objectives or the non-
functional requirements [6]. The business goal of the system
in our reference problem is keeping the room clean by ﬁrst de-
tecting, and then removing the dirt. The self-adaptation goals
are the following: 1) increasing the performance by minimize
the time needed for the room to be cleaned and be kept clean,
and 2) increasing its fault-tolerance by avoiding failures (for
example, collision with other robots) and deadlocks. The self-
adaptation goals need to be satisﬁed despite the internal or the
external (contextual) changes and uncertainties that emerge
at run-time. In our speciﬁc reference problem the following
changes trigger the need for self-adaptation:
Internal changes: Imperfect sensors. As explained above,
the sensors have restricted range of observation; therefore,
the agents have only a partial view of the physical space
or the room in which they operate. Furthermore, they can
detect new dirt task only if it appears within their range
of observation. Additionally, there are sensor uncertainties
that originate from hardware and software limitations of the
sensors, for example, sensor imprecision, noise, ambiguity,
inconsistency and inaccuracy, and even sensor failures [13].
This means that even if a robot observes dirt (subsequently
referred to as task) within the range of its sensor, we cannot
be 100% certain in the accuracy and the precision of the
observation.
Context-changes: Multiple agents operating in the same
room. For CPSs, it is highly probable and more realistic
scenario to have multiple agents deployed in a relative prox-
imity, for instance, a platoon of autonomous cars or a ﬂeet
of robots. In our example, when the agents need to localize
themselves and navigate in a room, the other agents deployed
in their relative proximity indirectly inﬂuence their actions.
This can potentially lead to different AMCL localization and
navigation issues, which can later result as sources of failures.
For example, collisions or deadlocks that directly impact the
overall system performance.
Context-changes: Continuous appearance of new dirt. As
previously explained in Section I-B the agents do not have
knowledge about the laws of physics of the context. In our
case that would mean that when new tasks are continuously
spawned in the room, they will be spawned at random loca-
tions, with location patterns unknown to the robots in advance.
The run-time decisions on how the new tasks are assigned to
the agents, and what path the robots take to reach to those
tasks can signiﬁcantly inﬂuence the system performance.
To sum up, our reference problem introduces and identiﬁes
run-time changes and uncertainties that are characteristic of
a real multi-agent robotic systems. These changes and un-
certainties trigger the self-adaptation, and cannot be speciﬁed
beforehand during design time of the system. However, they
need to be dealt with during the run-time, without affecting
the system performance and system’s functional goals, as well
as the quality objectives.
III. CHALLENGES
In this work, we make our contributions by addressing
the following challenges and the corresponding emerging
questions:
Challenge 1: Distributed observation and reliable detection
of continuously appearing tasks in a partially observable
context, and learning the context by collaboratively building
aggregated context models in the knowledge of the adaptation
logic based on the previous observations.
All the agents deployed in the room observe the context in
a distributed manner. As explained in the previous section, the
CPSs have limited sensor range, and therefore, they make only
partial observations of the room. Consequently, when a new
task or dirt is being spawned, it can only be detected once it
is within the range of observation of at least one of the agents.
Additionally, there are other run-time sensor uncertainties, like
sensor imprecision, and sensor ambiguities, which imply that
we cannot be fully sure in the true position of a task, even
when a task is detected by the agents. Furthermore, if there is
no mechanism for the robots to share their observations with
each other, then achieving a global performance maximum
is not possible due to the likelihood of one part of the
room getting dirtier than the other. Hypothetically, developing
more complex adaptation logic—through collaboratively built
knowledge—based on globally aggregated context models
built jointly by all the agents, could enables us to achieve
a global maximum of the performance of the overall system
(in combination with close-to-optimal solutions from the other
challenges).
In our reference problem, learning the context (the room)
would mean storing the past context states, which potentially
lead towards learning the patterns in which the tasks appear
in the context. The built knowledge of the context in the
adaptation logic can be considered as an input to the local
path planning (further explained in Challenge 3), which, for
example, would enable the CPSs to choose paths with higher
3
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

probabilities of new tasks appearing, over paths with lower
probabilities.
Question 1: How to ensure reliable task detection?
Question 2: How to build global aggregated context
models from what the robots are independently observing
from the context?
Challenge 2: Global multi-agent task allocation that has a
close-to-optimal solution, which is computationally feasible,
and dynamically adapts during run-time.
Once the dirt tasks are detected, they become goals and
they need to be assigned to the CPSs in the most optimal
way. The requirements are the following: 1) the algorithm
should sufﬁce optimality criteria and 2) it should exhibit high
efﬁciency concerning distance and time travelled. Since we
need to ensure a true real-time capability of the goal allocation
(new task gets detected, or assigned goal is reached), the algo-
rithm should be dynamically adaptable during run-time. The
problem of computational feasibility needs to be considered,
since we cannot assume the complexity of the environment
and the number of dirt locations beforehand, and they can
increase during run-time. Also, the notion of completeness
is also essential since we need to consider all possible goal
locations detected, and ﬁnally, ﬁnd a suitable path to reach
the locations. Thus, the algorithm should terminate with a
solution when one exists. According to Lagoudakis et al. [12]
ﬁnding an allocation of goals to multiple agents, as in our
setting: identical robots, symmetric and uniform traversing
costs, operating on the Euclidean plane; where the total cost
(the sum of the travel costs of all robots over time) of all the
paths that the robots traverse to their goals is minimized, is
an NP-hard problem, because it is the multi-agent version of
the Euclidean Traveling Salesman Problem [14].
Question 3: How to allocate continuously appearing tasks,
as goals to many agents in a close-to-optimal, computationally
feasible and dynamically adaptable during run-time way?
Challenge 3: Local path planning to the assigned goal that
minimizes the traversed distance and maximizes the context
exploration.
Once the goals (the explored tasks) are assigned to the
CPSs, the agents should plan how to reach to the locations
of their goals in a way that maximizes the space exploration
while traversing paths that have the highest probability of new
tasks appearing. Maximizing the space exploration is essential,
due to the partial observability of the context, as explained in
Challenge 1. Having partially observable context might lead
to situations where the agents have enough tasks to complete
in the parts of the room that they have already observed and
explored; but maybe the other unobserved parts of the room
get dirtier with a higher rate. As a result, in this case, exploring
and accomplishing tasks the unexplored parts of the room
brings better the performance-time ratio. Consequently, the
robots should be incentivized to explore more space.
Additionally, as previously explained in Challenge 1, the
knowledge from the past context situations should be taken
into consideration during the local planning towards the cur-
rently assigned goal. Namely, even if the robots do not observe
any tasks on a particular path, but the knowledge tells that
there is a high probability of new dirt a appearing, then this
path should be preferred over the others.
Question 4: What local path planning can minimize the
distance to the assigned task and maximize the context explo-
ration?
IV. METHODOLOGY
Our methodology for engineering the adaptation logic in
self-adaptive CPSs that operate in PMSSDCU context is
shown on Figure 3. In our proposed solution, we address the
challenges described in the previous section, in three different
phases: two local (i.e., decentralized and distributed in every
CPSs), and a global phase shared among all the CPS, e.g..,
robots. Every phase in the proposed solution is performed
by the self-adaptive CPS autonomously. In the following
subsections, we address the three challenges, respectively.
Managed elements (CPSs)
Environment (Context)
Sensors
Actuators
Adaptation logic
Comparison
Possible dirt
pool
Optimal path
planning
 (weighted map)
Global map
update
Goal
allocation
(global)
(local)
(local)
Self-adaptive system
Context observations
(measured context map)
Next goals
Goal status
Learned map
Reliable dirt
task promoted
to Goal
Current global context map
Possible 
dirt task
Move to the optimal
assigned goal
C. Local path planning
B. Multi-robot goal
allocation
A. Task detection
A. Context models
Figure 3. General overview of our methodology.
A. Tasks detection, knowledge representation and context
models (Addressing Challenge 1.)
1) Reliable tasks detection:
Once new dirt or task is
sensed it is considered as a new potential goal object. In
our implementation, the new potential goal object is stored
in a list, with a unique identiﬁer, a pose (containing the x,
y coordinates of the detected task in the map), and an initial
conﬁdence value. We chose the initial conﬁdence value for
every new goal object stored in the list to be 10%. If the same
task is detected again (with a small position tolerance, due to
sensor uncertainties), by the same or the other agents in the
room, then the conﬁdence value is increased by 10% more.
The potential goal object is published as a reliable goal, once
the conﬁdence value exceeds 90%.
4
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

2) Context models and knowledge representation in the
adaptation logic: In Section I-A, we explained that the knowl-
edge in the adaptation logic presents an abstraction of several
relevant aspects, including the context where the system is
operating. We model the context as a global, centralized grid
map with a size equal to the size of the room. Each cell in
the grid is either free or occupied. The occupied cells are
occupied either by static obstacles, for example, the walls;
or by dynamic obstacles: the agents deployed in the space,
or the continuously appearing dirt or tasks. Additionally, in
our solution, each cell can hold multiple tasks. The motion
of the robots is discretized, and with each time-stamp the
robots can move up, down, left and right to the centre of their
neighbouring cells. As mentioned before, the operation of the
robots is limited to their sensor capabilities, meaning that the
agents only hold a partial observation of the context at a given
point in time. As the robots move in the room, they gather
their partial observations in the centralized grid map, where
the multiple observations from the robots are aggregated to
produce a new, common, global knowledge about the context
in the adaptation logic. The global aggregated knowledge
contains all the tasks detected by the partial observations of
all the agents that are operating in the room.
3) Updating context models based on probabilistic models:
In the following section, we explain how we build the knowl-
edge and update the context models during runtime, based on
two probabilistic maps. In order to minimize the time taken for
detection and completing the tasks, a probabilistic analysis of
the environment is necessary. Using this, a mechanism for pre-
dicting where the next dirt patch is most likely to appear will
be developed. Such predictions will help in minimizing the
time needed to clean the room, thus improving the efﬁciency
of the system. The approach for carrying out a probabilistic
analysis of the room consists of maintaining two probability
maps, which we call Probability Map and Cumulative Map.
Probability Map. The Probability Map associates with every
cell of the grid-map a value quantifying the probability Pi,j
of dirt appearing in that location in the next time step. It is
updated accordingly to Algorithm 1, where Ni,j is the number
of tasks in a respective cell ij, T is the number of time-steps
until a speciﬁc point in time, and ∆t is the frequency in which
new tasks appear. Ni,j
T
is the division of the number of dirt
tasks found since t = 0 with the number of time steps until that
point in time, resulting in the probability for a speciﬁc cell. In
case no dirt task has appeared in a speciﬁc cell, the expected
value for that cell is calculated, and we check whether its value
is less than 1 or not. The calculation performed under the else
statement is meant to reduce the probability but to never let it
reach zero.
Cumulative Map. The Cumulative Map is calculated by
making use of the Probability Map. It measures the probability
CPi,j(T) that there is at least one task in a speciﬁc cell, and
it is calculated by the following equation:
CPi,j(T) = 1 − (1 − Pi,j(T − 1))(1 − CPi,j(T − 1))
Algorithm 1 Update Probability Map
For every cell ij:
if Ni,j = 0 then
if PT
t=0 Pi,j(t) · ∆t < 1 then
No Change
else
Pi,j(T) = Pi,j(T −1)
2
end if
else
Pi,j(T) = Ni,j
T
end if
where (1 − Pi,j(T − 1))(1 − CPi,j(T − 1)) calculates the
probability that there is not a single of task in a cell.
B. Multi-robot goal allocation (Addressing Challenge 2.)
For the multi-robot goal allocation, we need to ﬁnd a goal-
allocation algorithm, which apart from the fact that it can be
centralized (and the means and the cost of communication are
neglected), we can undoubtedly say that it needs to provide a
solution to a problem of utmost complexity. Namely, in our
approach, to minimize the overall sum of travel costs of all
robots when visiting all detected targets (the identiﬁed goals)
where ﬁnding an optimal allocation is an NP-hard problem,
we employ a greedy principle termed Prim Allocation. This
auction-based approach, derived from operations research and
adapted to a multi-agent context, provides the following guar-
antee on the quality of its allocations [12]: in the worst-case,
the total cost of this principle is at most twice the cost of the
optimal solution, but in average-case it is close to the optimal
solution.
Figure 4. Minimum Spanning Forests
The pseudo-code is given in Algorithm 2, and in a nutshell,
it works as follows: an interconnected graph between all
the tasks (shown in red pentagons) is woven, and the robot
locations in close vicinity to this graph are determined. Then
the algorithm ﬁnds the shortest connecting link to a tree,
initially starting only contains the robot itself. The shortest
links are then pair-wise compared and the minimal cost-link is
returned and added to the particular tree. This step is repeated
until all tasks or dirt locations are assigned. According to this
principle, the minimum-spanning trees that grow together form
minimum-spanning forests, as shown in Figure 4. Finally, the
5
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

last step is to determine optimal trajectories to the previously
allocated goals by the Prim Allocation, per agent. In our case,
we use a depth-ﬁrst search algorithm for ﬁnding the paths
from the sub-trees (marked with green-dashed directed arrows
in Figure 4).
Algorithm 2 Prim Allocation from [12]
1) For each robot i, construct a tree Ti that contains
only the corresponding robot vertex from VR
2) While (VT ̸= ∅) do
a) For all i, ci = minv∈VT minw∈Ti {c(v,w)}
b) j = argmini ci
c) vj = minv∈VT minw∈Tj{c(v,w)}
d) Attach vj to Tj
e) VT = VT - {vj}
3) For all i, use the MSF heuristic on Ti to construct the
path for robot i.
C. Local path planning (Addressing Challenge 3.)
We model the explorational aspect of local planning as
a local optimization problem. The local path planning tries
to ﬁnd the optimal path between the current position of the
robot and its next assigned goal. The optimality depends
on two factors: 1) minimization of the distance traveled by
the robot to the allocated goal, and 2) maximization of the
context exploration. For the local path planning we use the
probabilistic models previously explained in Section IV-A.
Similarly as the grid-map, the vision of the robot is also
discretized as shown in Figure 5. The red circle represents the
range of the sensors of the robot and the area in which the
robot can detect new task, and the shaded grid is the discretized
region corresponding to this area. Using the discretization of
the motion of the robot, mentioned previously in the paper, one
can construct a search tree (shown in Figure 6) that iterates
through the robot’s possible actions: starting from the robot’s
current position until the robot reaches its next assigned goal,
looking for the optimal path. For the path search in this case
we use uniform cost search.
Figure 5.
Robot’s ob-
servation range
Figure 6.
One possible representation of the
search tree.
The costs for each transition C is calculated with the
following formula:
C = d(action) − α ∗ E(x, y, action, t)
where d(action) calculates the Euclidean distance of perform-
ing a certain action, for example, left right, up and down; and
E(x, y, action) is a function that calculates the exploration
gain based upon the current position (x, y) and the action
taken.
We further introduce a constant α which we can use to
empirically tune the relative magnitudes of the Euclidean
distance and exploration gain. This allows us to determine
the relative importance of the two factors and hereby the path
taken by the robot.
For quantifying the exploration gain we use the following
formula:
E(x, y, action, t) =
X
i,jϵS
CPij(t)
which sums all the cumulative probabilities of a set S, where
S is the set of currently unseen grid cells that will become
visible when a speciﬁc action is taken.
V. IMPLEMENTATION
In this section we discuss the implementation of the ROS-
based, multi-agent system based on the reference problem,
which was previously explained in Section II. We have created
simulated, yet realistic implementation of a multi-robot sys-
tem, which itself presents a challenge. In our implementation,
the entire communication is based on Robot Operating System
(ROS), and Gazebo [15] [16] is used for simulating the
robotics system. Gazebo relies on well-established physics
engines, which enables high physical, functional and visual
ﬁdelity. In this paper, we evaluate all the concepts considering
only two robots, in particular two Turtebots 3 Burger [17].
However, our implementation allows increasing the number of
robots deployed in the room. Additionally, we simulate 360
degrees 2D LIDAR sensor is mounted on top of the robots. The
laser scanners can detect obstacles up to a distance of 3.5 m.
[18] and [19] contain the source code of the implementation,
together with installation instructions, more detailed archi-
tecture of the implementation for each of the sub-tasks, the
complete ROS computation graph and illustrative concepts—
videos of the implementation and some of the results. The
robotic system can serve as a basis for various experiments
for other researchers, and can be modiﬁed accordingly to their
distinct scientiﬁc needs.
VI. EVALUATION
In this section we show some of the preliminary results.
For data collection and analysis, a series of rosbag-records
were performed. rosbag-records subscribe to topics and enable
recording of the content of all the messages published on
those topics. We have conducted one long-term experiment of
approximately 40 minutes, and seven shorter 10-minute exper-
iments. During all the experiments, the exploration parameter
α (explained in Section 4.3), the time-interval of dirt spawned
∆t, and the use of prior learned knowledge gained in time
T are varied. Speciﬁcally, the prior learned knowledge comes
in the form of probability task distribution that is learned for
1000 time-steps before the actual measurements are collected.
Furthermore, the start-time is used to denote the recordings.
The parameter speciﬁcs are given in the Table 7.
6
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

which the dirt appears ∆t and used a random seed for the
appearance of the tasks. Additionally, the multi-robot global
task allocation node runs at 1Hz, meaning that the newly de-
tected task are considered as goals and Minimum Spanning
Forests are re-calculated every second.
Sample
α
∆t
start-time
knowledge
LONG TERM
#1
0.0
10-10
15-49-49
FALSE
EXPLORATION
#1
0.75
10-10
17-15-00
FALSE
#2
0.75
25-25
17-27-12
FALSE
#3
0
25-25
17-39-28
FALSE
#4
0.75
25-25
17-58-57
TRUE
#5
0.75
25-25
19-12-42
FALSE
#6
0.75
15-15
19-31-39
FALSE
#7
0.75
10-10
14-09-16
TRUE
Table 1: Experiments parameters speciﬁcs.
In the following, we are showing results for three different
cases: 1) no exploration α = 0, and no prior knowledge
T = 0; 2) exploration α = 0.75, and no prior knowledge
T = 0; and 3) exploration α = 0.75, and prior knowledge
T = 1000.
Figure 7 shows whether the robots have a good coverage
in the partially observable context with regards to the de-
tection of tasks. In the graphs on the ﬁgure we compare the
spawned vs. detected tasks. In comparison with the ﬁrst two
Figure 8: Number of currently assigned goals.
The succeeded goals graph in Figure 9 accumulates the
number of succeeded goals over minutes. The results show
that the approach which combines the exploration and the
prior knowledge performs the best over time, in average
completing 5 goals/minute, following the approach with no
exploration and no prior knowledge with 3.75 goals/minute,
and at the end with only 2 goals/minute, the approach with
exploration but no prior knowledge. Interestingly, our ex-
periments revealed that exploration impulsion only bene-
ﬁts when combined with the previously learned knowledge
about the context.
Figure 7. Experiments parameters speciﬁcs.
It is important to point out that for testing purposes and
better replication of the scenarios in the experiments, we
have ﬁxed the frequency ∆t and used a random seed for the
appearance of the tasks. Additionally, the multi-robot global
task allocation node runs at 1Hz—detection and allocation of
new goals are re-calculated every second. In the following, we
are showing results for three different cases:
1) no exploration α = 0, and no prior knowledge T = 0;
2) exploration α = 0.75, and no prior knowledge T = 0;
3) exploration α = 0.75, and prior knowledge T = 1000.
Figure 8 and Figure 9 show whether the robots have good
coverage in the partially observable context with regards to
the detection of tasks, with α = 0, T = 0 and α = 0.75,
T = 1000, respectively. Concretely, in both of the graphs,
we compare the amount of spawned (in orange) vs. the
amount of detected tasks (in blue color). We can see that the
advanced approach combining exploration α = 0.75 and prior
knowledge T = 1000, shows a much better approximation of
the spawned tasks by the detected tasks over time.
Figure 8. Spawned vs. detected tasks (α = 0, T = 0).
The graph in Figure 10 shows how many goals are assigned
to both of the robots over time. From the graph, we can
see that with time, concretely in the second half of the
simulation time, the number of assigned goals increases when
we have exploration and prior knowledge (depicted in orange),
Figure 9. Spawned vs. detected tasks (α = 0.75, T = 1000).
in comparison, when there is no exploration and no prior
knowledge given (depicted in blue).
Figure 10. Number of currently assigned goals.
The succeeded goals graph in Figure 11 shows an accu-
mulated number of succeeded goals over time. The results
show that the approach which combines the exploration and
the prior knowledge (in green color) performs the best over
time, in average completing 5 goals/minute, following the
approach with no exploration and no prior knowledge (in
blue color) with 3.75 goals/minute, and at the end with only
2 goals/minute, the approach with exploration but no prior
knowledge. Interestingly, our experiments revealed that the
exploration beneﬁts are only noticeable when the exploration
is combined with the previously learned knowledge about
the context. Otherwise, when the system explores without
prior knowledge, it performs almost half worse than when the
system did not explore and did not learn. From the results, we
can conclude that a self-adaptive system beneﬁts by a more
extensive exploration of the partially observable context, only
if the exploration is guided by the previous learning of the
system.
7
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Figure 11. Succeeded goals (cumulative).
VII. CONCLUSION AND FUTURE WORK
The objective of this work was to investigate how self-
adaptive systems that establish their adaptation on incorpo-
rating human-like activities like collaboration and learning
can preserve or even improve their performance—despite the
continuous, run-time changes in the context that could not
be speciﬁed during the design time. The systems operate in
partially observable, multi-agent contexts. We proposed an
approach for building adaptation logic, which improves over
time and tackles different challenges of self-adaptive cyber-
physical systems. The collaboration was enabled through run-
time cooperative aggregations of the contextual observations
and run-time collaborative tasks assignment. The learning was
achieved by storing the past contextual encounters, which later
were reused in a predictive manner, to help the systems make
better, smarter decisions. To evaluate our approach, we built a
self-adaptive system testbed from the robotics domain. As part
of our future work, we intend to evaluate the applicability of
the methodology on another use case from a different domain.
Additional future enhancements should also comprise learning
and optimal hyper-parameters search for different parameters,
and changing the number of robots, for different contextual
setups.
REFERENCES
[1] E. A. Lee and S. A. Seshia, Introduction to embedded systems: A cyber-
physical systems approach. Mit Press, 2016.
[2] H. Muccini, M. Sharaf, and D. Weyns, “Self-adaptation for cyber-
physical systems: a systematic literature review,” in Proceedings of the
11th international symposium on software engineering for adaptive and
self-managing systems, pp. 75–81, 2016.
[3] P. Jamshidi, J. C´amara, B. Schmerl, C. K¨aestner, and D. Garlan,
“Machine learning meets quantitative planning: Enabling self-adaptation
in autonomous robots,” in 2019 IEEE/ACM 14th International Sympo-
sium on Software Engineering for Adaptive and Self-Managing Systems
(SEAMS), pp. 39–50, IEEE, 2019.
[4] D. Weyns, “Software engineering of self-adaptive systems: an organised
tour and future challenges,” Chapter in Handbook of Software Engineer-
ing, 2017.
[5] A. Petrovska, S. Quijano, I. Gerostathopoulos, and A. Pretschner,
“Knowledge aggregation with subjective logic in multi-agent self-
adaptive cyber-physical systems,” in SEAMS ’20: IEEE/ACM 15th
International Symposium on Software Engineering for Adaptive and Self-
Managing Systems, Seoul, Republic of Korea, 29 June - 3 July, 2020,
pp. 149–155, ACM, 2020.
[6] A. Petrovska and A. Pretschner, “Learning approach for smart self-
adaptive cyber-physical systems,” in 2019 IEEE 4th International Work-
shops on Foundations and Applications of Self* Systems (FAS* W),
pp. 234–236, IEEE, 2019.
[7] M. Broy, M. V. Cengarle, and E. Geisberger, “Cyber-physical systems:
imminent challenges,” in Monterey workshop, pp. 1–28, Springer, 2012.
[8] J. O. Kephart and D. M. Chess, “The vision of autonomic computing,”
Computer, vol. 36, no. 1, pp. 41–50, 2003.
[9] S. Russell and P. Norvig, “Artiﬁcial intelligence: a modern approach,”
2002.
[10] D. Garlan, S.-W. Cheng, A.-C. Huang, B. Schmerl, and P. Steenkiste,
“Rainbow: Architecture-based self-adaptation with reusable infrastruc-
ture,” Computer, vol. 37, no. 10, pp. 46–54, 2004.
[11] V. Matena, T. Bures, I. Gerostathopoulos, and P. Hnetynka, “Model
problem and testbed for experiments with adaptation in smart cyber-
physical systems,” in 2016 IEEE/ACM 11th International Symposium
on Software Engineering for Adaptive and Self-Managing Systems
(SEAMS), pp. 82–88, IEEE, 2016.
[12] M. G. Lagoudakis, M. Berhault, S. Koenig, P. Keskinocak, and A. J.
Kleywegt, “Simple auctions with performance guarantees for multi-
robot task allocation,” in 2004 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566),
vol. 1, pp. 698–705, IEEE, 2004.
[13] A. J. Ramirez, A. C. Jensen, and B. H. Cheng, “A taxonomy of
uncertainty for dynamically adaptive systems,” in Proceedings of the
7th International Symposium on Software Engineering for Adaptive and
Self-Managing Systems, pp. 99–108, IEEE Press, 2012.
[14] E. L. Lawler, “The traveling salesman problem: a guided tour of
combinatorial optimization,” Wiley-Interscience Series in Discrete Math-
ematics, 1985.
[15] N. Koenig and A. Howard, “Design and use paradigms for gazebo,
an open-source multi-robot simulator,” in 2004 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No.
04CH37566), vol. 3, pp. 2149–2154, IEEE, 2004.
[16] C. E. Ag¨uero et al., “Inside the virtual robotics challenge: Simulating
real-time robotic disaster response,” IEEE Transactions on Automation
Science and Engineering, vol. 12, no. 2, pp. 494–506, 2015.
[17] W. Garage and T. Foote, “TurtleBot 3 Burger.” https://www.turtlebot.
com/, 2016. [Online; accessed 19-July-2018].
[18] A. Petrovska, “Smart Self-Adaptive Cyber-Physical Systems Simula-
tion.” https://github.com/tum-i4/ssacps simulation, 2019. [Online; ac-
cessed 08-Sept-2019].
[19] A. Petrovska, “Smart Self-Adaptive Cyber-Physical Systems Packages.”
https://github.com/tum-i22/ssacps packages, 2019.
[Online; accessed
08-Sept-2019].
8
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Variable-Regularized Low-Complexity RLS
Adaptive Algorithms for Bilinear Forms
Ionut¸-Dorinel Fˆıciu, Camelia Elisei-Iliescu, Cristian-Lucian Stanciu, and Constantin Paleologu
University Politehnica of Bucharest, Romania
Email: {cristian, pale}@comm.pub.ro
Abstract—This work in progress targets the identiﬁcation of
bilinear forms using fast converging adaptive algorithms. In
this framework, the bilinear term is deﬁned with respect to
the impulse responses of a spatiotemporal model. Recently, the
recursive least-squares algorithm tailored for bilinear forms
(RLS-BF) was introduced in this context, together with its low-
complexity version based on dichotomous coordinate descent
(DCD) iterations, namely RLS-DCD-BF. Aiming to improve the
robustness of the RLS-DCD-BF algorithm in noisy conditions, a
variable-regularized version is presented in this paper. Simulation
results indicate the appealing performance of this solution and
motivate our future works on multilinear forms.
Index Terms—adaptive ﬁlter; bilinear forms; recursive least-
squares; variable regularization; dichotomous coordinate descent
I. INTRODUCTION
The recursive least-squares (RLS) is the algorithm of choice
in many system identiﬁcation scenarios [1]. The main reason
behind this popularity is its fast converging feature, while
the drawback consists of a high computational complexity.
However, there are several efﬁcient solutions to reduce the
computational amount of the RLS algorithm, like the dichoto-
mous coordinate descent (DCD) method [2].
Nevertheless, the system identiﬁcation problems become
challenging in case of a larger parameter space [3]. Such
approaches can be formulated in terms of the identiﬁcation
of multilinear forms, while the solutions are based on multi-
dimensional adaptive algorithms. Currently, we focus on the
identiﬁcation of bilinear forms, where the bilinear term is
deﬁned with respect to the impulse responses of a spatiotem-
poral model [4]. Recently, the RLS algorithm tailored for
the identiﬁcation of bilinear forms (RLS-BF) was developed,
together with its DCD-based version (RLS-DCD-BF) [5].
This work in progress is focused on two main directions.
First, in order to improve the robustness in noisy environments,
we present a variable-regularized (VR) version of the RLS-BF
algorithm (namely VR-RLS-BF), where the time-dependent
regularization parameters are adjusted so that the algorithm
can perform well in noisy environments. Second, we develop
low-complexity versions of the VR-RLS-BF algorithm based
on the DCD method. Simulation results show the good behav-
ior of the VR-based algorithms and open the path toward the
generalization of these solutions for multilinear forms.
The paper is organized as follows. Section II introduces
the system model and brieﬂy presents the RLS-DCD-BF al-
gorithm [5]. Section III is dedicated to the variable regularized
versions of this algorithm. Simulation results are provided in
Section IV, while Section V concludes the paper.
II. RLS-DCD-BF ALGORITHM
In the framework of a real-valued bilinear model [4], the
reference signal (at discrete-time index n) is deﬁned as
d(n) = hT X(n)g + w(n) = y(n) + w(n),
(1)
where
h
and
g
are
the
two
impulse
responses
of
the
system
(of
lengths
L
and
M,
respectively),
X(n)
=
[ x1(n)
x2(n)
· · ·
xM(n) ]
is the zero-
mean
multiple-input
signal
matrix
of
size
L × M,
xm(n) =
[ xm(n)
xm(n − 1)
· · ·
xm(n − L + 1) ]T
is a vector containing the L most recent time samples of the
mth (m = 1, 2, . . . , M) input signal, w(n) is the zero-mean
additive noise [which is uncorrelated with X(n)], and the
superscript T denotes the transpose operator. From (1), we
can deﬁne the signal-to-noise ratio (SNR) as SNR = σ2
y/σ2
w,
where σ2
y
=
E
[
y2(n)
]
and σ2
w
=
E
[
w2(n)
]
are the
variances of y(n) and w(n), respectively, with E[·] denoting
mathematical expectation. The goal is to identify the two
impulse responses of the bilinear system (i.e., h and g) with
two adaptive ﬁlters, denoted by bh(n) and bg(n).
Following this approach, the estimated signal results in
by(n) = bhT (n − 1)X(n)bg(n − 1), while the error signal is
e(n) = d(n) − by(n) = d(n) − bhT (n − 1)X(n)bg(n − 1)
= d(n) − bhT (n − 1)exbg(n) = d(n) − bgT (n − 1)exbh(n), (2)
with the notation exbg(n)
=
[bg(n − 1) ⊗ IL]T ex(n) and
exbh(n) =
[
IM ⊗ bh(n − 1)
]T
ex(n), where ⊗ is the Kro-
necker product, IL and IM are the identity matrices of
sizes L × L and M × M, respectively, and ex(n)
=
[
xT
1 (n)
xT
2 (n)
· · ·
xT
M(n)
]T .
Following
the
least-
squares (LS) error criterion, the normal equations are [4]
Rbg(n)bh(n) = pbg(n),
(3)
Rbh(n)bg(n) = pbh(n),
(4)
where the terms from (3)–(4) can be recursively updated as
Rbg(n) = λbhRbg(n − 1) + exbg(n)exT
bg (n),
(5)
pbg(n) = λbhpbg(n − 1) + exbg(n)d(n),
(6)
Rbh(n) = λbgRbh(n − 1) + exbh(n)exT
bh(n),
(7)
pbh(n) = λbgpbh(n − 1) + exbh(n)d(n),
(8)
9
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Table I. RLS-DCD-BF algorithm.
Initialization:
bh(0) =
[ 1
0
· · ·
0 ]T , bg(0) = 1
M
[ 1
1
· · ·
1 ]T
Rbg(0) = δIL, Rbh(0) = δIM, rbh(0) = 0L×1, rbg(0) = 0M×1
For n = 1, 2, . . .
Step 1:
Rbg(n) = λbhRbg(n − 1) + exbg(n)exT
bg (n)
Rbh(n) = λbgRbh(n − 1) + exbh(n)exT
bh (n)
Step 2:
e(n) = d(n) − exT
bg (n)bh(n − 1) = d(n) − exT
bh (n)bg(n − 1)
Step 3:
epbg(n) = λbhrbh(n − 1) + exbg(n)e(n)
epbh(n) = λbgrbg(n − 1) + exbh(n)e(n)
Step 4:
Rbg(n)△bh(n) = epbg(n)
DCD
==⇒ △bh(n), rbh(n)
Rbh(n)△bg(n) = epbh(n)
DCD
==⇒ △bg(n), rbg(n)
Step 5:
bh(n) = bh(n − 1) + △bh(n)
bg(n) = bg(n − 1) + △bg(n)
with λbh (0 ≪ λbh < 1) and λbg (0 ≪ λbg < 1) denoting the
forgetting factors. Using the matrix inversion lemma [1] to
update R−1
bg (n) and R−1
bh (n), the RLS algorithm for bilinear
forms (RLS-BF) was developed in [5]. This algorithm has a
computational complexity proportional to O(L2 + M 2).
In order to reduce the computational amount of the RLS-BF
algorithm, an efﬁcient approach is based on transforming the
sequences of the normal equations (3)–(4) into a sequence of
auxiliary normal equations. These auxiliary normal equations
can be solved by using an efﬁcient iterative technique, like
the DCD algorithm [2]. The resulting RLS-DCD algorithm
for bilinear forms (RLS-DCD-BF) is resumed in Table I.
The evaluation of the correlation matrices [i.e., Rbg(n) and
Rbh(n) in step 1] represents a computationally expensive step
of the RLS-DCD-BF algorithm. Exploiting the structure of
these matrices, two approximate versions of the RLS-DCD-BF
algorithm were proposed in [5]. The ﬁrst one, namely RLS-
DCD-BF-v1, takes into account that exbg(n) owns (to some
extent) the time-shift property, especially in the steady-state,
when bg(n) ≈ bg(n−1). Consequently, since the matrix Rbg(n)
is symmetric, only its ﬁrst column could be computed, i.e.,
R(1)
bg (n) = λbhR(1)
bg (n − 1) + exbg(n)ex(1)
bg (n),
(9)
where ex(1)
bg (n) denotes the ﬁrst element of the vector exbg(n).
Moreover, the lower-right (L−1)×(L−1) block of Rbg(n) can
be approximated by the (L − 1) × (L − 1) upper-left block of
the matrix Rbg(n − 1). Thus, the computational complexity of
the RLS-DCD-BF-v1 algorithm is proportional to O(L+M 2).
Similarly, under some strong assumptions [i.e., i) the co-
variance matrices of the inputs are close to a diagonal one
and ii) the input signals are independent and have the same
power], we can also assume that Rbh(n) tends to a diagonal
matrix, so that it could be efﬁciently updated similar to (9).
Hence, a second version of RLS-DCD-BF algorithm results
(namely RLS-DCD-BF-v2), with a computational complexity
proportional to O(L + M).
III. VARIABLE REGULARIZED RLS-BF ALGORITHMS
The regularization process is essential in practice, taking
into account the presence of additive noise [6]. Here, we
consider the regularized RLS-BF algorithm, with the updates:
bh(n) = bh(n − 1) +
[
Rbg(n) + δbhIL
]−1 exbg(n)e(n),
(10)
bg(n) = bg(n − 1) +
[
Rbh(n) + δbgIM
]−1 exbh(n)e(n),
(11)
where δbh and δbg are the regularization terms. Alternatively,
bh(n) = Pbg(n)bh(n − 1) + eh(n),
(12)
bg(n) = Pbh(n)bg(n − 1) + eg(n),
(13)
where Pbg(n)
=
IL −
[
Rbg(n) + δbhIL
]−1 exbg(n)exT
bg (n),
Pbh(n) = IM −
[
Rbh(n) + δbgIM
]−1 exbh(n)exT
bh(n), and
eh(n) =
[
Rbg(n) + δbhIL
]−1 exbg(n)d(n),
(14)
eg(n) =
[
Rbh(n) + δbgIM
]−1 exbh(n)d(n).
(15)
The vectors eh(n) and eg(n) are the correction components of
the algorithm, due to the dependency on d(n). Let us deﬁne
eebg(n) = d(n) − ehT (n)exbg(n),
(16)
eebh(n) = d(n) − egT (n)exbh(n),
(17)
the error signals between the desired signal and the estimated
signals obtained from the ﬁlters optimized in (14)–(15). In
the context of system identiﬁcation, the purpose is to recover
the noise signal from the error of the adaptive ﬁlter [6]. As a
consequence, we could ﬁnd δbh and δbg in such a way that
E
[
ee2
bg(n)
]
= E
[
ee2
bh(n)
]
= σ2
w.
(18)
At this point, let us assume that the covariance matrices of the
inputs are close to a diagonal one, i.e., E
[
xm(n)xT
m(n)
]
≈
σ2
xmIL, m = 1, 2, . . . , M; also, let us consider that the input
signals are independent and have the same power, i.e., σ2
xm ≈
σ2
x, m = 1, 2, . . . , M. In this context, we can show that
exT
bh(n)exbh(n) ≈ Mσ2
x
bh(n − 1)

2
, where ∥·∥ denotes the Eu-
clidean norm. Also, E
[
exbh(n)exT
bh(n)
]
≈ σ2
x
bh(n − 1)

2
IM.
Similarly, we obtain exT
bg (n)exbg(n) ≈ Lσ2
x ∥bg(n − 1)∥2 and
E
[
exbg(n)exT
bg (n)
]
≈ σ2
x ∥bg(n − 1)∥2 IL. Therefore, for λbh ≈
1 − 1/L and λbg ≈ 1 − 1/M, we obtain (for n large enough):
Rbg(n) + δbhIL ≈
[
Lσ2
x ∥bg(n − 1)∥2 + δbh
]
IL,
(19)
Rbh(n) + δbgIM ≈
[
Mσ2
x
bh(n − 1)

2
+ δbg
]
IM.
(20)
10
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Next, squaring and taking the expectations on both sides of
(16)–(17), then developing (18) based on (19)–(20), we obtain
two quadratic equations with the following solutions:
δbh =
LE
[
∥bg(n − 1)∥2] (
1 +
√
1 + SNR
)
SNR
σ2
x,
(21)
δbg =
ME
[bh(n − 1)

2] (
1 +
√
1 + SNR
)
SNR
σ2
x.
(22)
The most problematic term in (21)–(22) is the SNR, taking
into account that the additive noise could be nonstationary
in real-world applications. However, in (1), the output signal
y(n) can be considered uncorrelated with the noise w(n).
Therefore, (1) can be expressed in terms of power estimates
as σ2
d = σ2
y + σ2
w, where σ2
d = E
[
d2(n)
]
is the variance
of the reference signal. Consequently, σ2
w = σ2
d − σ2
y. At this
point, let us assume that the adaptive ﬁlters have converged to a
certain degree, so that we can use the approximation σ2
y ≈ σ2
by,
where σ2
by = E
[
by2(n)
]
is the variance of the estimated signal
by(n). Using this approximation, it results that σ2
w ≈ σ2
d − σ2
by.
The power estimates can be recursively estimated as bσ2
d(n) =
γbσ2
d(n − 1) + (1 − γ)d2(n) and bσ2
by(n) = γbσ2
by(n − 1) +
(1 − γ)by2(n), where 0 ≪ γ < 1. Therefore, an estimate of
the SNR results in [
SNR(n) = bσ2
by(n)/|bσ2
d(n) − bσ2
by(n)|. Next,
since bh(n − 1) and bg(n − 1) are available at time index n,
the expectation operator can be omitted in (21)–(22). Thus,
using the notation s(n) =
[
1 +
√
1 + [
SNR(n)
]
/[
SNR(n),
the regularization terms from (21)–(22) result in
δbh(n) = L ∥bg(n − 1)∥2 s(n)σ2
x,
(23)
δbg(n) = M
bh(n − 1)

2
s(n)σ2
x.
(24)
Consequently, we obtain a variable-regularized RLS-BF (VR-
RLS-BF) algorithm, with the updates similar to (10)–(11), but
using the variable regularization parameters from (23)–(24).
Furthermore, the problem can be interpreted in terms of
solving the normal equations [1]:
Rbg(n)bh(n) = pbg(n),
(25)
Rbh(n)bg(n) = pbh(n),
(26)
where Rbg(n) =
bRbg(n) + δbh(n)IL, Rbh(n) =
bRbh(n) +
δbg(n)IM, and pbg(n) and pbh(n) are given in (6) and (8),
respectively. The normal equations (25)–(26) can also be recur-
sively solved using the DCD method [2]. Therefore, following
a similar approach (as presented in Section II), it results a low-
complexity version of the VR-RLS-BF algorithm based on the
DCD iterations, namely VR-RLS-DCD-BF; this algorithm is
summarized in Table II. Also, the computational complexity
in step 1 of the VR-RLS-DCD-BF algorithm can be reduced
based on (9). Similarly, two versions of the VR-RLS-DCD-BF
algorithm can be obtained, which are also indexed as v1 and
v2. The ﬁrst one uses (7) and (9) in step 1 [i.e., an amount of
O(L+M 2) operations], while the second one further reduces
the computational amount up to O(L + M), similar to the
RLS-DCD-BF-v2 algorithm.
Table II. VR-RLS-DCD-BF algorithm.
Initialization:
bh(0) =
[ 1
0
· · ·
0 ]T , bg(0) = 1
M
[ 1
1
· · ·
1 ]T
Rbg(0) = 0L×L, Rbh(0) = 0M×M
rbh(0) = 0L×1, rbg(0) = 0M×1
For n = 1, 2, . . .
Step 1:
Rbg(n) = λbhRbg(n − 1) + exbg(n)exT
bg (n)
Rbh(n) = λbgRbh(n − 1) + exbh(n)exT
bh (n)
Step 2:
Compute δbh(n) and δbg(n) using (23)–(24)
Step 3:
Rbg(n) = Rbg(n) + δbh(n)IL
Rbh(n) = Rbh(n) + δbg(n)IM
Step 4:
e(n) = d(n) − exT
bg (n)bh(n − 1) = d(n) − exT
bh (n)bg(n − 1)
Step 5:
epbg(n) = λbhrbh(n − 1) + exbg(n)e(n)
epbh(n) = λbgrbg(n − 1) + exbh(n)e(n)
Step 6:
Rbg(n)△bh(n) = epbg(n)
DCD
==⇒ △bh(n), rbh(n)
Rbh(n)△bg(n) = epbh(n)
DCD
==⇒ △bg(n), rbg(n)
Step 7:
bh(n) = bh(n − 1) + △bh(n)
bg(n) = bg(n − 1) + △bg(n)
IV. SIMULATION RESULTS
Simulations are performed in the framework of the bilinear
model described in Section II, in the context of a system
identiﬁcation scenario. The two impulse responses of the
spatiotemporal system (h and g) are randomly generated, with
Gaussian distribution; the lengths are set to L = 64 and
M = 8. An abrupt change of the system is simulated in the
ﬁrst two experiments, by generating two new random impulse
responses in the middle of simulations, in order to evaluate the
tracking capabilities of the algorithms. In the experiments, we
compare the performance of the RLS-DCD-BF, VR-RLS-BF,
and VR-RLS-DCD-BF algorithms. The same values of the
forgetting factors are used for all the algorithms, by setting
λbh = λbg = 1 − 1/(2ML). As a performance measure,
the normalized projection misalignment (NPM) [7] is used to
evaluate the identiﬁcation of the individual impulse responses.
In the ﬁrst experiment (Figure 1), we compare the perfor-
mance of the VR-based algorithms in moderate SNR con-
ditions, using SNR = 10 dB. The input signals are AR(1)
processes, where each one of them is generated by ﬁltering
a white Gaussian noise through a ﬁrst-order system with
the transfer function 1/
(
1 − 0.8z−1)
. All the DCD-based
algorithms use only one “successful” DCD iteration [2], which
is a signiﬁcant gain in terms of computational complexity. As
we can notice in Figure 1(a), both VR-RLS-DCD versions (v1
and v2) perform very similar to the VR-RLS-BF algorithm.
However, it can be noticed a slower tracking reaction of the
VR-RLS-DCD-v2 [Figure 1(b)], due to the approximation
related to the matrix Rbh(n), which is related to the spatial
ﬁlter bg(n). On the other hand, since the temporal ﬁlter bh(n)
11
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Time (seconds)
0
1
2
3
4
5
6
7
8
9
10
NPM[g, bg(n)] (dB)
-50
-40
-30
-20
-10
0
(b)
VR-RLS-BF
VR-RLS-DCD-BF-v1
VR-RLS-DCD-BF-v2
Time (seconds)
0
1
2
3
4
5
6
7
8
9
10
NPM
h
h, bh(n)
i
(dB)
-30
-20
-10
0
(a)
VR-RLS-BF
VR-RLS-DCD-BF-v1
VR-RLS-DCD-BF-v2
Figure 1.
Comparison of the VR-based algorithms in terms of (a)
NPM
[
h, bh(n)
]
and (b) NPM [g, bg(n)]. The system changes after 5 sec-
onds. The input signals are AR(1) processes and SNR = 10 dB.
Time (seconds)
0
5
10
15
20
25
30
NPM[g, bg(n)] (dB)
-30
-20
-10
0
(b)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Time (seconds)
0
5
10
15
20
25
30
NPM
h
h, bh(n)
i
(dB)
-20
-15
-10
-5
0
(a)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Figure 2.
Comparison of the VR-based algorithms in terms of (a)
NPM
[
h, bh(n)
]
and (b) NPM [g, bg(n)]. The system changes after 15
seconds. The input signals are speech sequences and SNR = 0 dB.
is not directly inﬂuence by this approximation, it behaves well
in case of the VR-RLS-DCD-BF-v2 algorithm [Figure 1(a)].
In the following, we focus on the performance of the VR-
RLS-DCD-BF algorithm, which is compared to the RLS-
DCD-BF algorithm (i.e., the “non-regularized” version). The
input signals are speech sequences. Thus, we do not include
in comparisons the v2 versions, since the assumption related
to the matrix Rbh(n) is biased for nonstationary inputs.
In Figure 2, we consider low SNR conditions, by setting
SNR = 0 dB. It can be noticed that the VR-based algo-
rithms perform very similar. Nevertheless, the RLS-DCD-BF-
v1 algorithm achieves a slightly better tracking reaction, while
reaching a higher misalignment level.
Finally, in Figure 3, we assess the performance of the
algorithms in case of SNR variations. In the ﬁrst 12 seconds,
we set SNR = 0 dB; then, the SNR drops to −25 dB for
the next 6 seconds. Nevertheless, the VR-based algorithms
are very robust in this case. Also, the VR-RLS-BF and VR-
RLS-DCD-BF-v1 perform very similar. As expected, the RLS-
Time (seconds)
0
5
10
15
20
25
30
NPM[g, bg(n)] (dB)
-30
-20
-10
0
(b)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Time (seconds)
0
5
10
15
20
25
30
NPM
h
h, bh(n)
i
(dB)
-20
-15
-10
-5
0
(a)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Figure 3. Comparison of the VR-RLS-BF, VR-RLS-DCD-BF-v1, and RLS-
DCD-v1 algorithms in terms of (a) NPM
[
h, bh(n)
]
and (b) NPM [g, bg(n)].
The SNR decreases from 0 dB to −25 dB between times 12 and 18 seconds.
DCD-BF-v1 algorithm is affected by the noise variation.
V. CONCLUSIONS AND FUTURE WORKS
In this work in progress, we have focused on the regular-
ization terms of the RLS algorithm for bilinear forms. First,
a method for ﬁnding the optimal regularization parameters
(depending on the SNR) was presented. Second, using a proper
evaluation of the SNR, a variable-regularized algorithm was
developed, together with two low-complexity versions based
on the DCD method. Simulations have shown that the VR-
based algorithms outperform their non-regularized counterpart,
mainly in terms of robustness against SNR variations.
Future works will focus on the extension of these solutions
in case of multilinear forms, by exploiting tensor-based adap-
tive algorithms. In this context, the decomposition methods
can be combined with low-rank approximations, aiming the
identiﬁcation of more general forms of impulse responses.
ACKNOWLEDGEMENT
This work was supported by a grant of the Romanian Ministry of Education
and Research, CNCS – UEFISCDI, project number: PN-III-P1-1.1-TE-2019-
0529, within PNCDI III.
REFERENCES
[1] A. H. Sayed, Adaptive Filters. New York, NY: Wiley, 2008.
[2] Y. V. Zakharov, G. P. White, and J. Liu, “Low-complexity RLS algo-
rithms using dichotomous coordinate descent iterations,” IEEE Trans.
Signal Processing, vol. 56, pp. 3150–3161, July 2008.
[3] M. Rupp and S. Schwarz, “A tensor LMS algorithm,” in Proc. IEEE
International Conference on Acoustics, Speech, and Signal Processing
(ICASSP), 2015, pp. 3347–3351.
[4] C. Paleologu, J. Benesty, and S. Ciochin˘a, “Adaptive ﬁltering for the
identiﬁcation of bilinear forms,” Digital Signal Processing, vol. 75, pp.
153–167, Apr. 2018.
[5] C. Elisei-Iliescu et al., “Efﬁcient recursive least-squares algorithms for
the identiﬁcation of bilinear forms,” Digital Signal Processing, vol. 83,
pp. 280–296, Dec. 2018.
[6] J. Benesty, C. Paleologu, and S. Ciochin˘a, “Regularization of the RLS
algorithm,” IEICE Trans. Fundamentals, vol. E94-A, pp. 1628–1629,
Aug. 2011.
[7] D. R. Morgan, J. Benesty, and M. M. Sondhi, “On the evaluation of
estimated impulse responses,” IEEE Signal Processing Lett., vol. 5, pp.
174–176, July 1998.
12
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

With Cross-Industry Innovation to a Circular Economy 
Core competence transfer as the basis of sustainable business 
Andrea Lutsch 
Institute of Management and Economics 
Chair of General Management 
TU Clausthal 
E-Mail: andrea.lutsch@tu-clausthal.de 
 
 
Abstract— The cross-industry innovation approach can help 
companies diversify their existing core competencies into new 
sectors or industries with as little risk as possible. In five 
systematic phases, the management level is enabled to identify 
potentials for cross-industry innovations from existing 
innovative problem solutions or core competencies of the 
company. With this approach, existing core competencies of 
the company can be used sustainably and in the long term, 
thus contributing to a circular economy.  Instead of constantly 
building up new skills and resources, the already established 
resources are used sustainably and, if necessary, adapted to 
raise cross-industry innovation potential. The cross-industry 
innovation approach helps companies to transform their 
existing business model and form a sustainable business model. 
Keywords-Cross-Industry 
Innovation; 
Cross-Sector 
Innovation; Circular Economy; Open Innovation; Sustainable 
Business; Sustainable Innovation; Sustainability 
I. 
 INTRODUCTION 
The diversity of global and local industry and customer 
requirements is constantly increasing. Digitalization in 
particular has gained enormous momentum in recent years 
and is now demanding changes in all areas of society and the 
economy. This is also accompanied by increasing demands 
on companies at various levels. The megatrend of 
digitalization is stimulating the pressure for change in 
companies immensely [1]. Increasing complexity in product 
development, accompanied by a high demand for know-how 
and resources, shorter product life cycles and an ever-
decreasing time-to-market can be observed. This puts 
companies under increased time and innovation pressure [2]. 
Which makes it necessary to adapt old business models, but 
also offers the opportunity to develop new business models. 
In the long term, this gap between increased internal 
systemic and external requirements as well as shortened 
development times can only be countered with a change in 
the use of resources, increased efficiency in the innovation 
process or greater flexibility in the strategic orientation of the 
company [3]. This can be achieved by adapting the 
innovation process to a sustainable use of core competencies 
[4]. 
"Growth in stagnating industries can result from three 
starting points: Customer loyalty, propaganda or from 
innovation." [5] For this, a rethinking of companies is 
necessary in order to survive against competitors [6]. Digital 
technologies, such as big data, blockchain and cloud 
computing are the basis for overcoming the challenges of 
digital transformation and developing a digital business 
model and are already being used in a large number of 
industries [7].  
In the following, the cross-industry approach is first 
described as an enabler of the circular economy. Then the 
inside-out approach and the special role of core competences 
will be discussed in detail. Finally, a process model is 
presented based on cross-industry innovation, which 
combines the previous aspects and enables a circular 
economy. 
II. 
CROSS-INDUSTRY INNOVATION, AN ENABLER OF THE 
CIRCULAR ECONOMY 
The development of new ideas and the implementation of 
successful innovations on the market is not only time-
consuming, but the cost factor also plays a major role. 
Conventional development processes require a very high 
capital investment and at the same time the prospects of 
success are not guaranteed [8]. Cross-industry innovations 
help companies to sustainably commercialize existing know-
how and core competencies in other markets [9].  
The cross-industry innovation approach offers the 
possibility of opening up new sectors and business areas 
without the risk of losing competencies and having to 
develop completely new products. Rather, this approach 
enables companies to strengthen their existing competencies 
and capabilities and to identify and leverage cross-industry 
potential [2]. In this way, their own core competences are 
strengthened in the long term and transferred to other sectors.  
Cross-industry innovation thus contributes to cross-industry 
solution development and a circular economy by applying an 
open innovation strategy [10].  
In the cross-industry innovation approach, companies 
from different sectors enter into cooperation. In this way, 
successful mergers can be created without the cooperating 
companies being in direct competition [11]. By using 
heterogeneous sources to generate ideas and a high cognitive 
industry distance, cross-industry innovations have a higher 
potential for radical innovations [1].  
In contrast to intra-industry approaches, cross-industry 
innovation combines problems and existing solutions in a 
new way across existing industry boundaries. This is done by 
using the idea of analogical thinking and development [13]. 
There are hardly any limits to the creative scope; not only the 
know-how of companies from other sectors, but also 
13
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

technologies, patents, business processes or different 
approaches to solutions can produce innovations when 
adapted across sectors [14].  
These approaches can reduce development time, risk and 
effort. The cross-industry innovation approach thus 
contributes to a sustainable economy [15].  
III. 
CORE COMPETENCIES AND THE INSIDE-OUT 
APPROACH 
The concept of core competence, as a sub-area of a 
resource analysis, is to be assigned to the newer strategy 
theory [16]. The concept of core competence is to be 
understood as an outstanding capability that overlaps the 
functions of the value chain, even across different business 
areas, which holds specific corporate knowledge and thus 
simultaneously represents a differentiation from other 
companies [16]. A core competence can only be described as 
a strategically relevant resource if it represents an advantage 
over the competition [16]. Core competences are also 
permanent and transferable causes of a company's 
competitive advantage based on resources and capabilities 
[17].  
Within the framework of the cross-industry innovation 
approach, the potential for new business areas or new sectors 
is examined on the basis of the identified and abstracted core 
competences in order to achieve the creation of a strategic 
competitive advantage. The final assessment of whether the 
identified core competences represent actual strengths can 
only be meaningfully evaluated in relation to possible new 
sectors or current competitors [16]. 
Resources of any kind that are considered valuable are 
referred to as core competencies. These can also be present 
at all levels of the value chain and represent both supporting 
and primary activities [18]. Supporting activities include 
business 
infrastructure, 
human 
resources, 
technology 
development and procurement. Primary activities include 
inbound and outbound logistics, operations (all activities of 
production), marketing and sales, and customer service 
activities [19].  
In order to determine the intrinsic value of a corporate 
resource or core competence, and thus whether the resource 
represents a real competitive advantage, it must be valued 
accordingly. In order to achieve the best possible valuation, a 
competitor analysis would theoretically be possible, in the 
context of which an analogous resource analysis of the 
strongest competitors could be carried out. In practice, this is 
rarely possible in a comprehensive manner and hardly 
practicable. One common method is the VRIO scheme. The 
acronym VRIO stands for the properties to be checked: 
value, rarity, inimitability and organization [16]. The 
attribute "Value" describes the existence of an increase in 
value that is made possible or reinforced by the resource in 
question [16]. The attribute "rarity" in this context expresses 
a competitive advantage that arises from the fact that the 
resource or capability under consideration is so highly 
differentiated that only one or very few companies have it. 
The attribute "inimitability" applies if at least one of the 
following characteristics is fulfilled. The competence is 
based on empirical knowledge or achievements that remain 
causally incomprehensible. This is the case, for example, 
with artistic creation or advisory services, since these are 
based on individual knowledge or skill. In addition, such 
competence may also have arisen historically or from the 
interaction of different social structures [16]. The fourth 
characteristic of the VRIO scheme to strive for is 
"organization". In this context, this means the organizational 
anchoring of the resource to be tested in the company in such 
a way that the company can actually use the resource in a 
way that promotes the company [20]. 
Only if all four criteria of the VRIO scheme are fulfilled 
is a competence also a core competence and thus to be 
located as a long-term competitive advantage. If, on the other 
hand, the competence is not anchored in the organization, i.e. 
if the evaluation of the O-criterion is negative, the 
competence is an unused competitive advantage. If the 
competence can also be easily imitated (negative assessment 
of the I criterion), only a short-term competitive advantage 
can be assumed. If, in addition, the R criterion is also 
negative, the competence is not rare and one speaks of 
competitive equality. If the competence under consideration 
is additionally assessed as not valuable (V criterion), this can 
have an effect on the company as a competitive disadvantage 
[21]. 
The starting point for the inside-out process of the cross-
industry innovation approach are innovative solutions, core 
competencies, knowledge, products or innovations that 
already exist in the company [22]. In this process, new 
product-market combinations are developed [9]. With 
relatively low monetary and time expenditure, increases in 
turnover can be achieved, for example, through licensing. 
The inside-out approach can reduce development time, risk 
and effort. Inside-out approaches often result in radical or 
disruptive innovations [15]. 
IV. 
WITH CROSS-INDUSTRY INNOVATION TO A CIRCULAR 
ECONOMY 
The 
cross-industry 
innovation 
approach 
enables 
companies to transform their existing business model and 
form a sustainable business model. The transformation is 
carried out using the modified cross-industry innovation 
approach.  
In the cross-industry innovation approach presented 
below, five successive phases, which systematically 
interlock, are run through. The output of the upstream phase 
generates the input for the downstream phase. The entire 
five-phase process, which is based on the cross-industry 
innovation approach, can be seen in Fig. 1.   In the first 
phase, the analysis phase, the strategic group in which the 
company under consideration operates in the industry 
context is first analyzed. In addition, the core competencies 
of the company that are most interesting for further analysis 
are evaluated and selected. Subsequently, in the second 
phase, the abstraction phase, the previously selected core 
competence is broken down into its basic core competence 
elements in order to obtain a sector-unspecific description of 
the core competences. With these split core competence 
elements, analogous sectors are searched for in the analogy 
phase. These are industries that have a similar need for the 
14
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

core competence elements as is the case in the domestic 
industry of the company under consideration. The identified 
bundle of foreign industries is evaluated in the downstream 
assessment phase using the two main criteria of "industry 
attractiveness" and "strategic compatibility". The main 
criterion "industry attractiveness" is made up of the sub-
criteria "innovation activity", "industry entry barriers" and 
"position in the industry life cycle"[23]. The sole object of 
evaluation is the individual foreign industry, i.e., it is the 
independent criterion. The dependent main criterion 
"Strategic Compatibility", on the other hand, evaluates the 
gap in the characteristics of the sub-criteria between the 
dominant strategic group of the individual foreign industry 
and the strategic group of the home company. The sub-
criteria of the main criterion "strategic compatibility" are 
"industry distance", "competitive strategy" and the "degree 
of vertical integration". 
The classification of the individual foreign industries on 
the basis of the two main criteria mentioned is carried out in 
the developed "industry attractiveness portfolio" based on 
the portfolio method. The industry attractiveness portfolio is 
shown in Fig. 2. 
Based on this portfolio representation, the classified 
industries can be classified into the three portfolio standard 
strategies "monitoring", "selection" and "investment". Each 
of these three areas in the portfolio reflects specific strategic 
fields of action. In the final phase, the strategic adaptation, 
sector-specific strategies for action and cooperation are 
discussed and developed.  
The research model developed enables companies to 
identify their own core competencies and thus make visible 
those sectors which, from the company's point of view, have 
cross-industry innovation potential. Based on this, sector-
specific, 
strategic 
recommendations 
for 
action 
and 
cooperation strategies can be developed in order to be able to 
raise the cross-industry innovation potential. Due to the 
already existing core competences in the company under 
consideration, a diversification with minimal risk can be 
achieved through the raised innovation potential and 
sustainable economic activity can be achieved. 
V. 
CONCLUSION 
The 
five-phase 
cross-industry 
innovation 
approach 
presented can help companies to detect their core 
competencies, identify diversification potentials and thus 
create a sustainable business model in the long term, which 
builds on existing competencies and capabilities and 
successively expands them. This sustainable management of 
corporate competencies and resources can have an impact 
on the entire business model and, for example, lead to a 
higher return on investment through the improved 
utilization of corporate competencies. Instead of constantly 
building up new competencies and resources, the already 
established resources are used sustainably and, if necessary, 
adapted to leverage cross-industry innovation potentials. 
The cross-sectoral innovation approach can thus help 
companies to transform their existing business model into a 
circular business model. 
Future research could address the explicit theoretical and 
operational challenges and needs for adaptation to circular 
business models. 
 
REFERENCES 
 
[1] M. Zollenkop, „Changing business models and their impact 
on product development. In: Operations excellence: smart 
solutions for business success,“ Springer Science and 
Business Media, pp. 9-23, 2008. 
[2] O. Gassmann and K. Frankenberger, „Exploring the Field of 
Business Model Innovation. New Theoretical Perspectives, 
Springer International Publishing,“ 2018.  
Figure 1: The new five-phase cross-industry innovation process. 
Figure 2: The industry attractiveness portfolio is developed in the evaluation 
phase and shows the interesting industry options. 
15
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

[3] T. 
J. 
Gerpott, 
„Strategisches 
Technologie- 
und 
Innovationsmanagement,“ 
Stuttgart, 
Schäffer-Poeschel 
(Sammlung Poeschel, 162), 2005. 
[4] T. Müller-Prothmann and N. Dörr, „Innovationsmanagement. 
Strategien, Methoden und Werkzeuge für systematische 
Innovationsprozesse,“ Munich, Carl Hanser Verlag, 2014. 
[5] H. H. Hinterhuber and K. Matzler, „Kundenorientierte 
Unternehmensführung. 
Kundenorientierung 
- 
Kundenzufriedenheit – Kundenbindung,“ Wiesbaden, Gabler 
Verlag, 2004. 
[6] T. Sommerlatte, „Challenges of maintaining innovativeness in 
organizations under business model transformation and 
digitalization. In: Tiwari, Buse:  Managing innovation in a 
global and digital world,“ Wiesbaden, Springer Gabler, pp. 
41-48, 2020. 
[7] A. Ross, “The industries of the future,” First Simon & 
Schuster trade paperback edition, New York, London, 
Toronto, Sydney, New Delhi, Simon & Schuster paperbacks, 
2017. 
[8] P. Granig, „Innovationsmanagement. 12 Erfolgsstrategien für 
KMU,“ Munich, Hanser, 2013. 
[9] E. Enkel and C. Dürmüller, „Cross-Industry-Innovation. Der 
Blick 
über 
den 
Gartenzaun,“ 
In: 
Praxiswissen 
Innovationsmanagement : von der Idee zum Markterfolg, 
Munich, Hanser, pp. 215–235, 2011. 
[10] M. Palmié, J. Boehm, C. Lekkas, V. Parida, J. Wincent, and 
O. Gassmann, „Circular business model implementation: 
Design choices, orchestration strategies, and transition 
pathways for resource-sharing solutions,“ In: Journal of 
Cleaner Production 280: 124399, January 2021. 
[11] Z. Yaman and T. Abele, “Cross Industry Business,” In: 
Thomas Barsch, Thomas Heupel und Holger Trautmann 
(Hg.): Die Blue-Ocean-Strategie in Theorie und Praxis. 
Diskurs 
und 
16 
Beispiele 
erfolgreicher 
Anwendung. 
Wiesbaden: Springer Fachmedien Wiesbaden (FOM-Edition, 
FOM Hochschule für Oekonomie & Management), pp. 45–
58, 2019. 
[12] L. 
Koschate, 
„Implementierung 
von 
Cross-Industry-
Innovation. Konzeption und Best Practice“. 1. Auflage. 
München: Studylab, 2019. 
[13] E. Enkel and A. Horváth, „Exercising Opportunities for 
Cross-Industry Innovation: How to Support Absorptive 
Capacity in Distant Knowledge Processing,“ In: International 
Journal of Innovation Management, Vol. 19, No. 05, 
1550048, 2015. 
[14] A. Dingler and E. Enkel, „Cross-Industry Innovation,“ In: 
Thomas 
Abele 
(Hg.): 
Die 
frühe 
Phase 
des 
Innovationsprozesses. Neue, praxiserprobte Methoden und 
Ansätze, Bd.43. Wiesbaden: Springer Gabler (FOM-Edition), 
pp. 109–122, 2016. 
[15] E. Enkel and O. Gassmann, Oliver, “Creative imitation. 
Exploring the case of cross-industry innovation,” In: R & D 
management 40 (3), pp. 256–270, 2010. 
[16] H. Steinmann, G. Schreyögg, J. Koch, „Management. 
Grundlagen 
der 
Unternehmensführung: 
Konzepte 
- 
Funktionen – Fallstudien,“ Wiesbaden, Springer Gabler, 
2013. 
[17] W. Krüger and C. Homp, „Kernkompetenz-Management. 
Steigerung von Flexibilität und Schlagkraft im Wettbewerb,“ 
Wiesbaden, Gabler, 1997. 
[18] M. E. Porter, „Competitive advantage. Creating and 
sustaining superior performance,“ New York; London: Free 
Press, 2004. 
[19] M. K. Welge, A. Al-Laham and M. Eulerich, „Strategisches 
Management. Grundlagen - Prozess – Implementierung,“ 
Wiesbaden, Springer Gabler, 2017. 
[20] J. B. Barney and W. S. Hesterly, “Strategic management and 
competitive advantage. Concepts and cases,” 2005. 
[21] J. 
B. 
Barney, 
“Gaining 
and 
sustaining 
competitive 
advantage,” 2. ed. Upper Saddle River, NJ: Prentice Hall, 
2002. 
[22] R. Freund, “How to Overcome the Barriers Between 
Economy and Sociology With Open Innovation, Open 
Evaluation and Crowdfunding?” In: International Journal of 
Industrial Engineering and Management Januar (1 (3)), pp. 
105–109, 2010. 
[23] K. Shahidi, „Der Branchen-Lebenszyklus. Eine Untersuchung 
am Beispiel der deutschen Stahlindustrie,“ Hamburg, Univ. 
der Bundeswehr, 1997. 
 
 
16
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications
Powered by TCPDF (www.tcpdf.org)

