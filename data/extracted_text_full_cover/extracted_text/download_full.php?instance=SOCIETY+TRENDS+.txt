SOCIETY TRENDS 2023
International Conference on Technical Advances and Human Consequences
ISBN: 978-1-68558-087-2
November 13th – 17th, 2023
Valencia, Spain
SOCIETY TRENDS 2023 Editors
Laura Garcia, Universidad Politécnica de Cartagena, Spain

SOCIETY TRENDS 2023
Forward
The International Conference on Technical Advances and Human Consequences (SOCIETY
TRENDS 2023) inaugural series is a dedicated series of annual events to focus on the society existential
technical paradigm: “Where are We Going?”. The conference was held in Valencia, Spain, November 13
- 17, 2023.
Technical and handily solutions brought tremendous opportunities for humans. The pace the
society hastily created calls for preparedness and continuous adaptation for avoiding adverse effects.
Awareness, informal denials, and weak counteractions are becoming useless at the status of the
pace of innovative tendency, considering the technology complexity and weak humankind capabilities
for adapting to new services/technologies.
Apart useless intended features and unintended bugs, on purpose intruders (bugs, virus, worms,
etc.) are freely running on hardware & software. Unintended or ill-intended back doors are common
features of all systems and applications, putting cyber-security, critical services, and ultimately all
citizens at risk.
Apart security breaches and privacy invasion, addiction via the metaverse applications /
environments are the main new unknown in terms of consequences.
In the recent decades, society detrimentally sacrificed the safety privacy driven control, as well
as emotional and physical capacities in favor of prompt action and untested decisions, not necessarily
the best. Therefore, a careful education and awareness are suitable.
We take this opportunity to thank all the members of the SOCIETY TRENDS 2023 Technical
Program Committee as well as the numerous reviewers. The creation of such a broad and high-quality
conference program would not have been possible without their involvement. We also kindly thank all
the authors who dedicated much of their time and efforts to contribute to the SOCIETY TRENDS 2023.
We truly believe that, thanks to all these efforts, the final conference program consists of top quality
contributions.
This event could also not have been a reality without the support of many individuals,
organizations, and sponsors. We are grateful to the members of the SOCIETY TRENDS 2023 organizing
committee for their help in handling the logistics and for their work to make this professional meeting a
success.
We hope the SOCIETY TRENDS 2023 was a successful international forum for the exchange of
ideas and results between academia and industry and to promote further progress with respect to
technical trends in society. We also hope that Valencia provided a pleasant environment during the
conference and everyone saved some time for exploring this beautiful city.
SOCIETY TRENDS 2023 Chairs
SOCIETY TRENDS 2023 Steering Committee
Christine Perakslis, Arizona State University, USA
Samer Al-Khateeb, Creighton University, USA
Mihai Aurel Constantinescu, Orange Business Services, IMEAR Region, Romania

Rodica Neamtu, Worcester Polytechnic Institute, USA
SOCIETY TRENDS 2023 Publicity Chair
Lorena Parra Boronat, Universitat Politecnica de Valencia, Spain
Sandra Viciano Tudela, Universitat Politecnica de Valencia, Spain
Jose Miguel SOCIETY TRENDS

SOCIETY TRENDS 2023
Committee
SOCIETY TRENDS 2023 Steering Committee
Christine Perakslis, Arizona State University, USA
Samer Al-Khateeb, Creighton University, USA
Mihai Aurel Constantinescu, Orange Business Services, IMEAR Region, Romania
Rodica Neamtu, Worcester Polytechnic Institute, USA
SOCIETY TRENDS 2023 Publicity Chair
Lorena Parra Boronat, Universitat Politecnica de Valencia, Spain
Sandra Viciano Tudela, Universitat Politecnica de Valencia, Spain
Jose Miguel SOCIETY TRENDS
SOCIETY TRENDS 2023 Technical Program Committee
Md Shoaib Ahmed, Brain Station 23, Dhaka, Bangladesh
Ahmad Alnafessah, Imperial College London, UK
Sana Behnam Asl, North Carolina State University, Raleigh, USA
Elizabeth Aube-Van Patten, Western Governors University, USA
Tanjim Taharat Aurpa, Independent University Bangladesh (IUB), Bangladesh
Snježana Babić, Polytechnic of Rijeka / Juraj Dobrila University of Pula, Croatia
Tetiana Biloborodova, G.E. Pukhov Institute for Modelling in Energy Engineering, Kyiv, Ukraine
Marcos A. F. Borges, Unicamp - University of Campinas, Brazil
Ignacio Gabriel Bugueño Córdova, University of Chile, Chile
Sonia Casillas-Martín, University of Salamanca, Spain
Daniel Cermak-Sassenrath, Center for Computer Games Research - ITU, Copenhagen, Denmark
Sinan Chen, Kobe University, Japan
Stefano Cirillo, University of Salerno, Italy
Mihai Aurel Constantinescu, Orange Business Services, IMEAR Region, Romania
António Guilherme Correia, INESC TEC, Portugal
Ricardo Costa, School of Engineering - Polytechnic of Porto, Portugal
Luis Ferreira, IPCA, Portugal
Hamdan Gani, STMIK Handayani, Makassar, Indonesia
Jorge Gil Tejeda, Universidad Autónoma Metropolitana Unidad Xochimilco, Mexico
Luca Grilli, Università degli Studi di Foggia, Italy
Cédric Grueau, Instituto Politécnico de Setúbal, Portugal
Ekta Gujral, University of California - Riverside / Walmart Inc., USA
Delowar Hossain, University of Calgary, Canada
Tim Howes, Johnson & Wales University - Rhode Island, USA
Xin Huang, University of Maryland at Baltimore County, USA
Hamidah Ibrahim, Universiti Putra Malaysia, Malaysia

Svetlana Karkina, Kazan Federal University, Russia
Andreas Koch, Center for Ethics and Poverty Research | Paris Lodron Universität Salzburg, Austria
Hanna Kondratiuk, Fraunhofer Institute, Germany
Sondes Ksibi, University of Carthage | Higher School of Communications of Tunis, Tunisia
Hanna Kujawska, Siemens Energy, Norway
Laurie Lau, APATAS, Hong Kong
Yifan Lin, Georgia Institute of Technology, USA
Dongxin Liu, University of Illinois, Urbana-Champaign, USA
Christopher Mansour, Mercyhurst University, USA
José Martins, INESC TEC & Polytechnic of Leiria, Portugal
Fernando Moreira, Universidade Portucalense, Portugal
Rodica Neamtu, Worcester Polytechnic Institute, USA
Carlos E. Palau Salvador, Universitat Politècnica de València, Spain
Vitor Pinheiro de Almeida, Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio), Brazil
Paulo Pinto, Universidade Nova de Lisboa, Portugal
Vassilis Poulopoulos, University of the Peloponnese, Greece
Angelo Rega, Neapolisanit Research Center, Italy
Maryam Rezaei Ghaleh, Tabriz Art University, Iran
Marzieh Rezaei Ghaleh, Arizona State University, USA
Daniela Rotelli, University of Pisa, Italy
Debashish Roy, Ryerson University, Canada
Rupsa Saha, University of Agder, Norway
Donna M. Schaeffer, Marymount University, USA
Davide Senatori, Università degli Studi di Genova, Italy
Soroosh Shalileh, National Research University Higher School of Economics, Moscow, Russia
Deepanjal Shrestha, Pokhara University, Nepal
Micael Sousa, University of Coimbra, Portugal
Wendley Souza da Silva, Federal University of Ceará - UFC, Brazil
Christoph Stach, Institute for Parallel and Distributed Systems / University of Stuttgart, Germany
J. Carles Terés Casals, FGC, Spain
Laura Toma, Bowdoin College, USA
Patricia Torrijos Fincias, University of Salamanca, Spain
John Varlaro, Johnson & Wales University - Rhode Island, USA
Sonia Verdugo Castro, Universidad de Salamanca, Spain
Jason C.S. Yen, National Chin-Yi University of Technology, Taiwan
Wenbin Zhang, Carnegie Mellon University, USA

Copyright Information
For your reference, this is the text governing the copyright release for material published by IARIA.
The copyright release is a transfer of publication rights, which allows IARIA and its partners to drive the
dissemination of the published material. This allows IARIA to give articles increased visibility via
distribution, inclusion in libraries, and arrangements for submission to indexes.
I, the undersigned, declare that the article is original, and that I represent the authors of this article in
the copyright release matters. If this work has been done as work-for-hire, I have obtained all necessary
clearances to execute a copyright release. I hereby irrevocably transfer exclusive copyright for this
material to IARIA. I give IARIA permission or reproduce the work in any media format such as, but not
limited to, print, digital, or electronic. I give IARIA permission to distribute the materials without
restriction to any institutions or individuals. I give IARIA permission to submit the work for inclusion in
article repositories as IARIA sees fit.
I, the undersigned, declare that to the best of my knowledge, the article is does not contain libelous or
otherwise unlawful contents or invading the right of privacy or infringing on a proprietary right.
Following the copyright release, any circulated version of the article must bear the copyright notice and
any header and footer information that IARIA applies to the published article.
IARIA grants royalty-free permission to the authors to disseminate the work, under the above
provisions, for any academic, commercial, or industrial use. IARIA grants royalty-free permission to any
individuals or institutions to make the article available electronically, online, or in print.
IARIA acknowledges that rights to any algorithm, process, procedure, apparatus, or articles of
manufacture remain with the authors and their employers.
I, the undersigned, understand that IARIA will not be liable, in contract, tort (including, without
limitation, negligence), pre-contract or other representations (other than fraudulent
misrepresentations) or otherwise in connection with the publication of my work.
Exception to the above is made for work-for-hire performed while employed by the government. In that
case, copyright to the material remains with the said government. The rightful owners (authors and
government entity) grant unlimited and unrestricted permission to IARIA, IARIA's contractors, and
IARIA's partners to further distribute the work.

Table of Contents
Chord Extraction Method in Development of a Score Click Playback System
Kenta Morita, Naoki Morita, Chiharu Nakanishi, Chiaki Sawada, and Kazue Kawai
1
Universally Designed Augmented Reality (AR) for the School of the Future
Joschua Simon-Liedtke and Till Hallbach
4
Synchronized Recording System Using Multiple Smartphones
Naoki Morita, Md Saidi Muhammad Ashraf Naim, Kenta Morita, Chiharu Nakanishi, Chiaki Sawada, and Kazue
Kawai
12
Measuring AI Education Performance with Flipped Learning Based on Bloom's Taxonomy Objectives
Hyo-Jin Kim and Dongju Kim
15
Powered by TCPDF (www.tcpdf.org)

Chord Extraction Method in Development of
a Score Click Playback System
Kenta Morita
Faculty of Medical Engineeringdept.
Suzuka University of Medical Science
Mie, Japan
e-mail: morita@suzuka-u.ac.jp
Naoki Morita
School of Information Telecommunication Engineering
Tokai University
Tokyo, Japan
e-mail: morita@tokai.ac.jp
Chiharu Nakanishi
Kunitachi College of Music
Tokyo, Japan
e-mail: nakanishi.chiharu@kunitachi.ac.jp
Chiaki Sawada
Kunitachi College of Music
Tokyo, Japan
e-mail: sawada.chiaki@kunitachi.ac.jp
Kazue Kawai
Faculty of Literature
Seitoku University
Chiba, Japan
e-mail: kawai.kazue@wa.seitoku.ac.jp
Abstract—The purpose of this study is to recognize the
locations of the chords from sound data of recorded piano
performances. Previous methods have been unable to recognize
all the musical scales contained within a chord and to identify the
location of the chord. To identify the chord points, we adopted
two ideas. The first idea is that, in instances where multiple notes
of the same musical scale are present, if even one note reaches
the predetermined threshold, it is considered as representing
the respective scale. The second idea involves moderating the
determination of whether the threshold has been exceeded. To
validate the efficacy of the proposed method, piano performances
of scores containing chords were recorded, and the method’s
ability to identify chord locations from the recorded data was
assessed. The results demonstrated a notable improvement in
identifying chord points with the proposed method, achieving an
approximately 88% identification rate of musical notes, which is
significantly superior to the approximately 14% achieved by the
preceding method.
Keywords—Chord, Score Analysis, Video Analysis, Piano Les-
son.
I. Introduction
Piano practice is crucially centered around repetitive prac-
tice. Students, for instance, record their performances and,
through subsequent review, identify areas needing improve-
ment. They then engage in continual practice, making neces-
sary corrections based on these identified areas. Previous stud-
ies have proposed various methods to support piano lessons
[1]–[8].
In this study, we have been developing a system that enables
users to view a recorded piano performance from a specified
bar by selecting a bar within a piano score displayed on-screen.
In the system we are developing, it is necessary to syn-
chronize the visual onset of notes in the score with those
in the performance video. To synchronize the visual onset,
identification of the correspondence between notes in the
score and the auditory output in the recorded performance
is required. Wakiyama et al. have proposed a method for
identifying which measure in a musical score corresponds to
a played piano sound [9]. Piano performances encompass a
variety of techniques, including chords, which involve striking
two or more notes simultaneously using not only the fingers
but also the pedals. This method is capable of identifying the
musical scale of a note when only a single note is sounded
momentarily. However, it was unable to identify the musical
scale for sounds produced by striking two or more notes
simultaneously, such as chords. The objective of this study is
to recognize the scales of chords from recorded piano sounds.
In this paper, section II describes the previous method
and its associated challenges. The proposed method will be
explained in section III, and the validation of its efficacy and its
consideration will be described in section IV. Finally, section
V gives a summary of this study.
II. Previous Method
In this section, the preceding method for identifying mu-
sical scales is introduced, and the reasons for its inability to
recognize chords are elucidated.
A. The Previous Method for Identifying Musical Scales of
Piano Performances
The procedure utilized by the previous method to determine
which notes in the musical score correspond to the sounds of
the piano in the recorded performance is introduced herein.
This method consists of five steps.
1) Recognize musical notes from images of the scores using
OpenCV [10].
2) Retain the recognized notes as sequence data in chrono-
logical order.
3) Time-frequency analysis using Constant-Q Transform
(CQT) [11] for sound data of recorded piano perfor-
mance.
4) Extract notes one by one from the sequence data in step
2, and use the frequency corresponding to the musical
scale as a search key to search the results of step 3 in
chronological order.
1
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

Figure 1. A score sample.
TABLE I
The order data converted.
No.
Musical scale
1
F4
A3
F2
2
C3
3
F4
C4
A3
4
F4
A2
C5
5
F3
6
F4
C4
C5
...
...
5) If the value is searched in chronological order and
exceeds the threshold value, it is assumed that the
searched note is found, and the appearance timing of the
note in the performance data is recorded in a timestamp
list. Steps 4 and 5 are repeated until the last note in the
score is reached.
In step 1, the PDF or scanned music score is converted
to image data, and the notes and lines of the score are
recognized using recognition technology, specifically through
template matching. The musical scale of the recognized note
is identified by the position of the lines and the notes.
In step 2, the recognized musical scales are converted into
sequence data in order from the left. Figure 1 presents a piano
score sample, while Table I shows the sequence data converted
by recognizing the musical scale from the score in Figure 1.
In step 3, a CQT is performed on the sound of the recorded
piano performance. CQT is frequently utilized in the analysis
of musical signals. By using CQT, the strength of frequency
at each point of sound data can be obtained as a value. Figure
2 illustrates the result of applying the CQT of the music data
of a certain performance.
Each musical scale is determined by frequency, and the
horizontal axis of this table represents the music scale. The
vertical axis indicates time and progresses downward.
In step 4, based on the converted ordinal data, each item is
extracted in order and used as a search key. In the case of the
table in Table I, the search is performed in order starting with
No. 1. When No. 1 is selected, three scales, F4, A3, and F2,
are subjected to the search. The search examines the frequency
portion corresponding to the musical scale in chronological
order for the values of the angular frequency band obtained
by CQT.
Figure 2. An example of CQT result.
TABLE II
A example timestamp list.
No.
Musical scale
Time
1-1
F4
A3
F2
8.500
1-2
C3
8.830
1-3
F4
C4
A3
9.200
1-4
F4
A2
C5
9.960
1-5
F3
10.310
1-6
F4
C4
C5
10.690
2-1
A#2
D5
F4
11.490
...
...
...
In step 5, if the search identifies a point that exceeds the set
threshold, it is assumed that that musical scale was sounded at
that time. Then, the appearance timing of the note is recorded
in a timestamp list. Table II is an example of a timestamp
list. The number to the left of the No. is the bar number in
the musical score, and the number to the right indicates the
sequence in which the notes appear within that bar. The times
in the table represent the times when it is assumed that the
musical scale was pressed because the threshold was exceeded.
If the search process does not find the point that exceeds
the set threshold within a certain amount of time, the musical
scale of the next item is searched.
B. Some Problems of The Previous Method
Previous methods were unable to discern the timing of lower
octave key presses when scales of identical types were played
simultaneously. A chord is the sounding of multiple scales
by striking two or more notes. In Figure 1, the initial note
comprises three distinct notes: F4, A3, and F2. In this case,
the key press timing for F2 could not be ascertained using the
previous methods.
III. Proposed Method
In order to detect chords from the sound of recorded piano
performance, two ideas are introduced.
The first idea is that if multiple notes within a chord share
the same musical scale, and at least one of them surpasses a
predefined threshold, all notes of that particular musical scale
are deemed to have been pressed. For example, consider a
scenario where F4 and F3, which share the same musical scale,
2
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

TABLE III
Recognition rate of the proposed method and previous methods.
Proposed method
Previous method
Threshold
1.0
1.5
2.0
2.5
1.0
Chord only
29.55
63.64
88.64
0.00
11.36
ALL note
27.94
60.29
88.24
0.00
14.71
occur simultaneously in a score. If F4 exceeds the threshold,
F3 is also considered to have been pressed, regardless of its
actual value.
A second idea is to relax the determination of the threshold.
Initially, a search is conducted for three scales. If this search
is unfruitful, the number of scales is reduced to two, and
subsequently to one if the search still yields no results. If the
scale is not found in this way, the quantity of musical scales
subjected to the search is reduced by one by one.
IV. Confirmation Of Extraction
In this section, the efficacy of the proposed method is sub-
stantiated through a structured experimental approach, aimed
at ascertaining the capability of detecting chord points within
the musical data of chord scores played on the piano.
A. Experimental Setup
To validate the efficacy, a comparative analysis between
the note identification rates of the proposed method and the
preceding method is conducted. The musical score used in
this experiment contains not only singular notes but also
chords [12], with performers utilizing pedals to actuate the
keys during play The recognition of a note is determined by
comparing the manually pre-verified start time of each measure
with the adjudication time of each measure, as recognized by
the system Both the proposed method and the previous method
require a threshold setting as a parameter. The threshold of the
previous method is designated at 1.0, whereas the proposed
method is subjected to four threshold patterns: 1.0, 1.5, 2.0,
and 2.5. The search timeout time was set to 2.6, correlating
to the time span of one bar from the song.
B. Result
Table III shows the results of recognition rates for piano
performances of musical scores containing chords. The pro-
posed method achieved the highest note recognition rate at
a threshold of 2.0. In addition, the recognition rate of the
previous method was lower than that of the proposed method
even when utilizing the same threshold.
In piano performances that incorporate chords, it was deter-
mined to be effective to assume a chord is identified when one
or more of the notes sought are found. It was also observed
that contingent upon the threshold, the position of the musical
note might not be accurately recognized.
V. Conclusion
This study aimed to recognize chord points from the sound
data of recorded piano performances. Previous methods were
unable to recognize all scales within a chord, nor could they
identify the point of the chord. To identify the chord points,
we adopted two ideas. The first idea is that, when multiple
notes of the same musical scale are present, if at least one
reaches the threshold, it is considered as the same note. The
second idea involves moderating the determination of whether
the threshold has been exceeded. To validate the effectiveness,
a piano performance of a musical score containing chords was
recorded, and it was confirmed whether the proposed method
could identify chord locations from the recorded data. As a
result, the proposed method was able to identify chord points
more effectively than the previous method. Future work will
involve experimenting with other songs.
Acknowledgment
The present study was supported by the Japan Society for
the Promotion of Science (JSPS) through KAKENHI Grant
Number 21K18528.
References
[1] Y. Takegawa, T. Terada, and M. Tsukamoto, “Construction of a Piano
Learning Support System considering Rhythm”, IPSJ Interaction 2012,
March 2012.
[2] Y. Fukuya, K. Takegawa, and H. Yanagi, “Design and Implementation
of a Piano Learning Support System Considering Motivation”, IPSJ
Interaction 2015, March 2015.
[3] T. Ishigami and T. Hamamoto, “A Piano Practice Support System
Visualizing Correspondence Between Music Scores and Key Positions”,
ITE Technical Report Vol.41, No14, pp. 71–76, 2017.
[4] T. Nagai, K. T. Nakahira, and M. Kitajima, “Analysis of the relationships
between the proficiency levels of piano playing and the changes in visual
behaviors while reading score and performing piano”, IPSJ SIG Technical
Report, Vol.2017-CE 142 No.20, December 2017.
[5] T. Suzuki, K, Tanaka, R. Ogura, and Y. Tsuji, “Practice of Beginners’Piano
Skill Training Support Using “Visualization System for Piano performance
(VSPP)”, IPSJ SIG Technical Report, Vol. 2018-MUS-119 No.16, pp. 1–6,
Jun 2018.
[6] M. Hori, Christoph M. Wilk, and S. Sagayama, “Visualizing deviations
from exemplary performances for piano practice assistance (including
retry detection)”, The 81st National Convention of IPSJ 1T-02, pp.337–
338, March 2019.
[7] R. Matsui, K. Takegawa, and K. Hirata, “Design, Implementation and
Assessment of a remote piano lesson support system that automatically
generates optimal multi-view camera work.”. [Online]. Available
from:https://ipsj.ixsq.nii.ac.jp/ej/?action=repository uri&item id=1776
39&file id=1&file no=1 [retrieved: 10, 2023]
[8] R. Matsui, K. Takegawa, and K. Hirata, “Design, implementation and
Assessment of a Support System to Find Bad Fingering Habits for Piano
Teachers”, 2020 Information Processing Society of Japan Vol.61, No.4,
pp. 789–797, April 2020.
[9] M. Wakiyama, M. Wakao, N. Morita, K. Morita, C. Nakanishi, C.
Sawada, and K. Kawai,“Development of a Score Click Playback System”,
Proceedings of The Eighth International Conference on Advances in
Signal, Image and Video Processing, pp.21–23, 2023.
[10] Open CV
Library.
[Online].
Available
from:https://docs.opencv.org/4.7.0/index.html [retrieved: 10, 2023]
[11] Constant-Q
Transform
(CQT)
Description.
[Online].
Available
from:
https://www.wizard-notes.com/entry/music-analysis/constant-
q-transform [retrieved: 10, 2023]
[12] Score of “Twinkle Twinkle”. [Online]. Available from:https://atelier-
music.com/sheetmusic/twinkle-twinkle-little star [retrieved: 10, 2023]
3
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

Universally Designed Augmented Reality (AR) for the School of the Future 
Making eXtended Reality (XR) technology inclusive for students with and without disabilities 
Joschua Thomas Simon-Liedtke, Till Halbach 
Norwegian Computing Center 
Oslo, Norway 
e-mail: {joschua,halbach}@nr.no
Abstract—Augmented Reality (AR), together with other 
technologies collectively referred to as eXtended Reality (XR), 
can offer opportunities in education for experiential learning 
and the visualization of abstract concepts. However, there is a 
lack of universal design and significant challenges for students 
with disabilities. This paper presents a case study of AR 
technology used in Norwegian schools to identify inhibitors and 
facilitators for the inclusive use of AR in education. We let 
students with and without visual and cognitive disabilities try 
out an AR app for books. The AR app would superimpose 
virtual 3D models and videos on the books similar to a pop-up 
book. Interviews with educators and a focus group session with 
developers identified opportunities, benefits, user expectations, 
best 
practices, 
challenges, 
common 
pitfalls, 
and 
recommendations and concrete measures to address said 
challenges and pitfalls. Our study emphasizes the lack of 
support for assistive technologies, the over-emphasis on visual 
stimuli that can be hindering for students with visual 
disabilities, the significant demand of AR on cognitive 
capabilities, which might be challenging for students with 
cognitive disabilities, and the lack of awareness of and access to 
guidelines and best practices among developers. We suggest 
enabling compatibility with assistive technologies, increased 
multi-modality that engages hearing and touch, and increased 
usage of visual explanations and elements like symbols and 
icons. In addition, we suggest collecting, organizing, and 
promoting existing and new guidelines for the universal design 
of both XR and AR. We argue that many of our findings for AR 
are relevant to other technologies gathered under the umbrella 
of XR, including Mixed Reality (MR) and Virtual Reality (VR).  
Keywords - Universal design; accessibility; usability; 
inclusion; eXtended Reality; Augmented Reality; Virtual Reality; 
Mixed Reality; XR; AR; MR; VR; education; learning; disability; 
barriers; solutions. 
I. 
 INTRODUCTION 
eXtended Reality (XR) is an umbrella term to describe 
Virtual Reality (VR), Mixed Reality (MR), and Augmented 
Reality (AR) [1]. XR has been used in entertainment [2], 
industry [3], and education [4][5]. XR has benefits for 
education including new interaction methods, a high degree 
of sensory immersion, and high information density [4]. We 
previously examined the state of universal design of XR 
usage in Norwegian primary schools [5][6][7][8].  
We conducted a literature review about the different uses 
of XR, their opportunities and challenges, and we identified 
solutions to overcome these challenges and enhance the 
integration of XR in primary education [5][6]. This review 
shows that there are systemic and technical challenges that 
require improved pedagogical research and integration, skill-
set and acceptance improvement among educators and 
decision-makers, infrastructure development for XR in 
schools, and development of funding and procurement 
schemes for the technology [8]. Further, there is a need for 
increased co-creation of XR technology, the identification of 
barriers for students with disabilities, the development of 
solutions 
for 
said 
barriers, 
the 
advancement 
of 
standardization of guidelines and best practices, and the 
development of methods to assess the degree of accessibility 
and usability of an XR device or application [7].  
Moreover, we recruited informants among educators, 
decision-makers, 
representatives 
from 
civil 
society 
organizations, and developers of XR technology [7][8]. The 
participants emphasized the benefit of XR as an experience-
based technology that can facilitate the visualization of 
abstract concepts in an engaging and motivating way [7]. The 
informants also highlighted the need for making pedagogical 
benefits and limitations of XR better visible, including advice 
on utilizing opportunities XR technology offers, while 
mitigating challenges [8]. Especially the need for case study 
research and applicable solutions in schools has been 
emphasized. Likewise, there is a significant lack of research 
focusing on users and students with disabilities [7][9][10]. 
Last but not least, existing guidelines and best practices for 
digital user interfaces in general [11][12][13], and XR in 
particular [14][15][16][17], lack general recognition, 
acceptance, and compliance among developers [7]. The Web 
Content Accessibility Guidelines (WCAG) for accessibility 
and usability of digital interfaces, for instance, serve as 
standards in many national and international ICT regulations 
[11][12][13][18][19][20] but lack an adequate translation for 
XR technology. 
In this work, we attempt to decrease the knowledge gap 
by presenting results from a case study that investigates the 
accessibility and usability of a concrete AR application used 
in Norwegian primary schools. We conducted user testing, 
interviews, and a focus group to identify AR application 
opportunities and barriers and solutions to these barriers. The 
research involved students with and without disabilities, their 
educators, and AR developers.  
In this paper, we first present the protocol for user testing 
and interviews, and its implementation in Section II. Then, 
we present the results of the user evaluations and interviews 
conducted in the fall of 2022 in Section III and discuss our 
observations in Section IV. Finally, we conclude with 
suggestions for future research and improvements to the 
universal design of XR technology in Section V. 
4
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

II. 
METHODOLOGY & IMPLEMENTATION 
Our accessibility and usability assessment was inspired 
by inclusive-design approaches and strategies for the 
evaluation of design artifacts by focusing on user-centered 
evaluation, iterative processes, addressing the whole user 
experience, the integration of multidisciplinary skills and 
perspectives, and an iterative technical and formative 
evaluation [21][22]. We used user evaluations by students 
based on a thinking-aloud approach as a primary research 
method. Here, we identified the key features of the AR 
application and specified tasks that participants were asked to 
complete. A secondary method was focus group and semi-
structured interviews engaging educators and developers 
[23][24]. The protocols for the interviews consisted of 
guiding questions and conversation starters focusing on 
accessibility, usability, and universal design of AR in 
education. 
In the current study, we evaluated an AR application for 
mobile devices called Ludenso Explore, developed by 
Ludenso AS (cf. Figure 1). The app is an extension to the 
science book Solaris 9 used in Norwegian primary schools 
[25]. Ludenso Explore is similar to a traditional pop-up book 
in that students, after downloading the app, can gain access 
to several types of interactive content by scanning the pages 
of their book. Depending on the content, the app then shows 
a virtual interactive 3D model, a video that is superimposed 
on the paper page, or links to external digital learning 
resources on the publisher’s web pages (cf. Figure 1). 
The user evaluations involved four primary schools in 
Norway during the fall/winter of 2022: Jordal ungdomsskole, 
Midtstuen ungdomsskole, Holmen barneskole, and Greåker 
videregående skole. These schools represented a diverse 
range of students with and without disabilities. In this study, 
we focused specifically on cognitive and visual impairments. 
A total of 34 students between 9 and 16 years of both genders 
participated. 15 children had cognitive impairments. The 
cognitive impairments can be categorized as ASD and 
developmental disabilities. Several of the students had 
personal assistants and teachers who also were interviewed. 
Three students had visual impairments. One student had a 
significant amount of remaining vision, another had limited 
remaining vision, and one student was completely blind. We 
also interviewed a teacher with severe visual impairment. 
During the user evaluations, the students completed the tasks 
defined in the protocol, using the AR app on their phones or 
on the devices we provided. We asked them to comment 
aloud what they were doing and thinking as they completed 
the tasks, at the same time as we encouraged conversation 
with follow-up questions. The observations from these user 
evaluations were supplemented by conversations with 11 
educators and three AR developers, which were conducted 
during one-on-one interviews and focus groups.  
At least two researchers were present for each user 
evaluation. One researcher led the evaluation by presenting 
tasks, supporting students, and asking questions. The other 
researcher focused on observation and notetaking. We did not 
take any recordings during the evaluations to preserve the 
students’ privacy. After the evaluations, each researcher 
transcribed observations from the experiments conducted a 
thematic analysis of their notes, and summarized identifying 
themes to extract the most relevant and important points. 
Both researchers discussed their respective data sets. Finally, 
they summarized and compacted the findings across all 
evaluations combined. 
III. 
RESULTS 
Here, we present benefits and pedagogical opportunities, 
user expectations and best practices, systemic and practical 
challenges, and common technical and functional pitfalls. 
Further, we provide organizational recommendations and 
concrete measures to improve universal design of AR. We 
grouped observations into sections. Each category is 
summarized in bold font, followed by detailed explanations 
and examples. 
A. Pedagogical Opportunities and General Benefits 
AR can engage students with the curriculum in novel 
and more practical ways. AR can effectively illustrate 
abstract ideas and “obscured” objects, like atoms or planets, 
replacing the need for physical models. AR can enhance 
practical knowledge compared to text or 2D sketches. 
AR typically captures students' interest and attention 
better than traditional learning materials, leading to increased 
interest, motivation, and engagement. This increased 
engagement and motivation might be related to the use of 
innovative technology and the fact that many students are 
highly responsive and significantly drawn to tablets and 
mobile apps. Likewise, AR can provide various gamification 
elements that stimulate engagement. At the same time, 
research questions the long-term effect of XR technology in 
light of the so-called novelty effect [4][10]. 
Figure 1.  A student interacts with a virtual 3D model in the Ludenso 
Explore app on a smartphone. © Johanne Nyborg 
5
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

Consequently, AR might add variation to the learning 
process that can lead to positive learning effects, such as 
enhancing cognitive skills like comprehension and 
cooperation. For instance, AR allows for interactive 
exploration, enabling students to move around and zoom in 
on models, which can result in a better learning experience 
and increased understanding. AR may invite students to 
cooperate around the virtual content and to learn from each 
other when navigating the app. 
AR, on par with other digital learning aids, can 
provide benefits for the organization and distribution of 
curriculum materials. Organizing the curriculum digitally 
has the advantage of consolidating various resources in one 
easily accessible place for all students. Educators can more 
flexibly choose and use learning resources in the classroom. 
AR has the potential to increase inclusion if the 
accessibility of AR technology is properly addressed. 
Compared to the challenges of adapting analog learning aids 
in the past, AR can offer more flexible and easier adoption, 
as long as universal design is addressed from early in the 
design and development process. In general, digital learning 
aids including AR could more easily be adapted for screen 
readers than traditional paper books. Likewise, AR could 
provide interfaces for assistive technology like hearing aids 
and alternative input/output devices. However, this requires 
developers to be aware of users with disabilities and address 
their needs satisfactorily. 
AR serves as a suitable learning alternative for those who 
prefer visual and less text-based approaches, such as students 
with dyslexia, ADHD, or learning difficulties. 
B. User Expectations and Best Practices 
Users anticipate seamless and efficient user experience 
while utilizing an app, including installation, general 
usage, and scanning and tracking of virtual content. The 
students in the study appreciated the simple and convenient 
installation process of an AR app that can be downloaded 
from app stores like Apple's App Store or Google Play. They 
also appreciated robust and reliable tracking of AR content, 
particularly 3D models.  
Users respond positively to user-friendly interfaces 
with intuitive and familiar functions and elements. The 
students appreciated quick and easy access to digital content, 
such as videos and 3D models. The students appreciated an 
interface that is easy to understand and intuitive, with 
comprehensive buttons and tabs. Choosing the right default 
is also essential. Many students, for instance, preferred 
watching videos in full screen. Likewise, they appreciated 
features like auto-play combined with the initial muting of 
the video.  
An intuitive navigation within the AR app was positively 
received. This includes navigation of AR content based on 
functionality known from other apps like zooming in and out 
using pinch gestures, along with familiar icons for full screen, 
muting, and other functional elements. 
Users prefer a variety of interactivity options with 
virtual content. Many students preferred the option to access 
and freely interact with virtual content like 3D models by 
choosing it from a digital library instead of using image 
recognition or AR markers that restrict them to the literal 
confines of the paper book. Also, many students preferred 
using the standalone function for 3D models, i.e., the 
possibility to place 3D models in the physical room without 
connection to the physical paper book. 
C. Systemic and Practical Challenges 
AR 
might 
encounter 
technical 
and 
practical 
challenges in schools. There might be limited access to 
necessary hardware and reliable online access with sufficient 
capacity in schools. Also, limited physical environments can 
hinder AR use in practice, like overcrowded classrooms with 
restricting space to move around in. 
Lack of digital skills and experience with AR among 
educators and students might be a challenge. AR requires 
technical skills, posing a potentially steep learning curve for 
users, particularly older teachers who may struggle or are 
reluctant to adapt. Students with disabilities might lack the 
necessary skills to use AR devices. 
Insufficient universal design of digital learning tools, 
including AR, is likely to negatively impact accessibility 
for students with disabilities.  
There is a lack of awareness of and expertise in 
universal design of AR among developers and decision-
makers in schools and authorities. The awareness and 
knowledge about accessibility and usability among 
developers can be improved. The participating developers 
were partially familiar with general programming guidelines 
for accessibility and usability [26] [27] [28]. Even though 
national 
and 
international 
legal 
requirements 
exist 
[18][19][20][29], these are not widely known to developers.  
Some developers were aware of WCAG [11] [12] [13] but 
reported that their knowledge about them was very 
superficial and not embedded in any organizational or 
structural routines. When presented with surveys of barriers 
[9][15] and accessibility guidelines for gaming and XR 
[9][14][15][16][17], the participants were not aware of them. 
Universal design is by some considered costly and 
conflicting with aesthetics. The developers were concerned 
that limited resources and restrictive development budgets in 
AR companies may lead to situations where universal design 
is neglected. The developers in the study also reported a lack 
of demand for universal design of AR applications by 
decision-makers 
in 
schools, 
education 
boards, 
and 
authorities.  
Focus on visual presentation of the virtual content can be 
a challenge for some students. AR predominantly embraces 
visual aspects, limiting its suitability for individuals with 
visual impairments or cognitive challenges. It is our 
impression that sensory and auditory elements, such as sound 
effects and tactile feedback, are not adequately addressed in 
today’s digital learning tools, including AR. 
AR and other digital learning tools may distract 
students. Students may be distracted by other apps. Potential 
noise issues can occur when multiple students use the digital 
learning tools simultaneously, for instance by playing video 
simultaneously. 
6
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

D. Common Technical and Functional Pitfalls 
Some apps may have technical challenges related to 
their stability, performance, unexpected behavior, or 
erroneous tracking of virtual content that can disrupt the 
user experience, together with unreliable devices and the 
lack of cross-platform compatibility. An AR app might 
freeze and exhibit unexpected behavior, requiring restarts. 
Some students reported that their devices went into sleep 
mode while watching videos. Other students reported that 
some AR apps might be incompatible with newer versions of 
iOS or Android, limiting their usability. 
Many students reported that they experienced unreliable 
tracking behavior in many AR apps. Some students struggled 
to choose the best camera position and angle for proper 
scanning of the AR markers. Other students experienced 
challenges due to heterogeneous illumination conditions or 
physical distortions of the AR markers. 
Some apps lack tutorials, explanations for specific 
features and functions, intuitive presentation of functions, 
and sufficient feedback functionality. An AR app might 
lack suitable guides or tutorials, especially for users new to 
AR. The students in the study inquired about explanations of 
AR and its possibilities in general, and how to navigate an 
app's features in specific. 
Navigating the interface of an AR app and understanding 
its elements and functions might prove challenging for some 
users. Some functions might not be explained sufficiently. 
Some students might not understand features like muting, and 
full-screen mode when indicated by icons only. Features like 
choosing 3D models from a library instead of scanning might 
be particularly difficult for and feel non-intuitive to students 
with cognitive impairments. 
Apps might lack feedback after functions have been 
completed, either successfully or failed. An AR app might 
not provide proper feedback on functionality, like 
downloading content, leaving users uncertain about 
successful or failed downloads.  
Some apps lack localization for the country in which 
the app is deployed. An AR app targeted at Norwegian 
schools that is only available in English can pose difficulties 
for younger users or users with cognitive disabilities who 
may not fully understand the language. 
AR apps might not conform to universal design 
requirements and common accessibility guidelines. An 
AR app might not adhere to commonly used accessibility 
guidelines [13][16]. The most common missing measures 
include alternative ALT text for images, support for screen 
readers, proper semantic markup, adjustable text sizes, audio 
descriptions for videos, and keyboard navigation.  
The content of an AR app might be unsuitable for 
students with cognitive impairments. Videos may be too 
complex or delivered at a fast pace, posing difficulties for 
reading and comprehension. 
Motion-based navigation of 3D content can be 
challenging for students with and without disabilities. 
Visually impaired students might encounter challenges, as 
well as any students in small classrooms. Physical devices, 
such as tablets, may be challenging for young or physically 
impaired users due to their weight. 
E. Organizational Recommendations 
There should be an effort to increase awareness of and 
expertise in universal design of AR among developers, 
educators, and decision-makers. Educators and decision-
makers in municipalities need increased expertise in and 
awareness of accessibility, usability, and universal design of 
AR at all levels including development, testing, and 
procurement. Awareness can be raised by revisiting literature 
about barriers to XR technology and their solutions 
[5][8][9][15][16]. Likewise, training for developers and 
decision-makers should focus on universal design of ICT and 
digital inclusion in general, considering how universal design 
requirements can be integrated with modern and effective 
development and production.  
Schools should consciously demand universal design of 
digital learning materials and content, including AR, as a 
mandatory requirement by referencing existing legislation 
and living it in practice, too. 
Research on the cost-benefit of universal design in AR 
should be conducted and shared with stakeholders. 
Especially, the hypothesis that universally designed AR is 
more beneficial and cost-efficient than AR without UD 
should be investigated. 
Priority should be given to the development, 
organization, and distribution of guidelines, best 
practices, evaluation methods, and action plans. All digital 
learning materials and content should comply with national 
and international legal requirements and standards for 
universal design of ICT [18][19][20][29]. Existing guidelines 
for universally designed programming, XR, games, and user 
interfaces should be distributed and promoted among 
developers 
[12][13][14][16][17][26][27][28]. 
Relevant 
guidelines and best practices for AR and XR should be 
organized and highlighted for the production of XR 
applications (cf. Section III.F).  
More research on the needs of and challenges for XR 
users with disabilities and the solutions to said challenges is 
needed. More resources and literature targeting the universal 
design of XR in general and AR specifically should be 
developed for vendors of XR technology and content.  
Companies should create and implement concrete plans 
on how universal design is integrated into their development 
and production of products and services. Automated 
accessibility and usability tests, e.g., contrast checks, should 
be available for developers. Checklists, recommendations, 
and best practices tailored to XR and AR should be created. 
Development should include user testing throughout 
the entire planning, implementation, and testing stages of 
the production process, making the app as flexible, 
robust, and glitch-free as possible. Developers should 
deploy an agile development process with multiple iterations 
of planning, execution, review, and retrospective [30]. In this 
process, bugs and performance issues can be uncovered and 
then fixed. From the planning stage to pre-release, the app 
should be assessed by actual students with and without 
disabilities.  
7
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

F. Technical and Practical Measures to Increase Universal 
Design of AR 
Robust and stable scanning of the markers or image 
recognition should be a priority, as well as stable and 
robust tracking. This includes accommodating various 
exterior conditions related to lighting, surface texture, and 
structure, as well as a variety of possible user interactions. 
The AR app should be compatible with the latest versions of 
operating systems like iOS and Android. 
Efforts should be made to enhance the usability and 
user experience of an app by facilitating access to 
documentation and tutorials, including a feedback 
mechanism, 
and 
highlighting 
essential 
functions. 
Comprehensive installation instructions and documentation 
should be available to users. Tutorials and explanatory 
texts/illustrations for AR in general and specific app features 
should be provided. Instructions and information about 
pedagogical possibilities and the functionality of AR in 
education should be provided to teachers and decision-
makers. A feedback mechanism should be provided 
throughout the installation process and app usage that allows 
users to report bugs or send in suggestions. 
The most common functions should be easily 
understandable. Existing features like unmuting videos or 
standalone 3D models should be highlighted and provided 
with clear explanations.  
Internationalization and localization in the primary 
country language should be made available. The language 
used in texts should be kept as simple as possible for better 
comprehensiveness.  
AR content should be available in offline mode, 
including 3D models, video snippets, and audio files. 
Developers should revisit the presentation of text, 
speech, and non-textual elements by offering textual and 
non-textual alternatives to support students with visual 
and cognitive impairments. An AR app should incorporate 
both text and visual representation for its AR content, 
elements, and functions including explanatory descriptions 
and illustrations [15]. On the one hand, AR apps should 
increase the use of non-textual elements like symbols, icons, 
images, graphic elements, and images of 3D models to 
support students with cognitive impairments. On the other 
hand, all functional visual elements should have explanatory 
and descriptive text alternatives. If support for screen readers 
is yet unavailable, a text-to-speech feature can be considered. 
Efforts should be made to conform with existing 
standards, guidelines, and best practices. An AR app 
should be designed according to the latest WCAG [12][13], 
in particular the following success criteria :  
● 
Support for keyboard navigation and screen readers 
(cf. Guidelines 2.1 and 4.1). 
● 
Captions and audio description, or a text alternative 
for all videos (cf. 1.2.2 and 1.2.3). 
● 
Text alternatives for all visual elements (cf. 1.1). 
● 
Recommendations for distinguishable elements 
including the use of color, contrast, text size, 
dynamic adaptation, and text spacing (cf. 1.4). 
An AR app should be designed according to W3C's XR 
user requirements [16], including the following guidelines: 
● 
Adaptation to various assistive aids and output 
devices (cf. 4.1, 4.8, 4.13, and 4.14). 
● 
Alternative navigation options include using voice 
commands and providing alternatives to motion 
controls (cf. 4.2, 4.5, and 4.9). 
● 
The option to personalize content for students with 
cognitive challenges (cf. 4.3). 
● 
Establishing safe spaces and time limits to prevent 
overwhelm and exhaustion (cf. 4.11 and 4.12). 
● 
Allowing interaction speeds for, among others, text, 
video, and audio (cf. 4.15). 
● 
Captions for audio-visual media (cf. 4.19). 
Developers should follow best practices aiming at 
programming in general [26][27][28], and XR technology 
and games in specific [14][17]. 
AR and XR equipment and apps should accommodate 
special needs, both physically and programmatically. 
Support for assistive technology and alternative input 
and output devices should be implemented. AR and XR 
equipment should be lightweight and work on a variety of 
screens and devices [15]. Compatibility with common 
assistive technology should be enabled, including screen 
readers or text-to-speech tools for users with low vision, 
hearing aids for those with a hearing impairment, voice or 
gaze command, and wheelchairs with motor or mobility 
impairments [9][15]. Note that the most common aids are 
regular glasses that should be compatible with all AR and XR 
devices [31]. Alternative input devices are keyboards, 
computer mice, customized controllers, or buttons, whereas 
alternative output devices include additional external screens, 
customized headphones, or refreshable braille displays 
[9][15].  
Compatibility with these aids should work both 
programmatically and physically. Programmatically, by 
providing an interface or API for these technologies, e.g., 
screen readers, input or output devices. Physically, by not 
interfering with or hindering the usage of assistive 
technology, e.g., hearing aids, wheelchairs, or glasses. 
Moreover, all digital information needs to be available and 
accessible with and without assistive technology, e.g., 
through text alternatives for screen readers. 
Compatibility with screen readers like VoiceOver / 
TalkBack for students with visual impairments should be 
prioritized. Likewise, navigation within the interface and the 
virtual world through alternative input devices should also be 
prioritized. 
Developers should enhance the multi-modality of the 
virtual content. AR content should be presented through 
various 
modalities, 
i.e., 
engage 
multiple 
senses 
simultaneously, such as hearing and touch [15]. AR content 
should be expanded through modalities, such as sound, 
vibration, 3D-printed artifacts, and tactile display units. 
Different modalities should also be considered for user 
interaction, including auditory elements like sound effects, 
vibrations, and tactile feedback. We advise employing user 
preferences for modalities, combined with profiles for 
personalized experiences. 
8
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

Presentation of the virtual content without tracking 
should be available. There should be the possibility for a 
purely virtual representation of 3D models within the app 
through a so-called “stand-alone” mode. This would allow 
exploration without scanning book pages, tracking markers, 
or placing models in the classroom.  
Navigation within the virtual content should be 
possible without motion control through on-screen 
buttons. Navigation through various control methods, such 
as buttons, keyboard, motion control, gestures, and voice 
commands should be available. Navigation without motion 
control should be available through plus and minus buttons 
for zooming, buttons to rotate 3D models, or buttons to view 
the inside of models by zooming inside. Rotation should be 
possible along all axes, i.e., the x-, y-, and z-axes. 
The AR app should have a certain level of tolerance 
for input errors when it comes to navigating the 3D 
models. There should be designated areas on the screen 
where fingers and palms can be placed without triggering 
unintended gestures. 
AR apps should consider including more interactive 
features and educational content that is available both 
online and offline. AR apps should incorporate more 
interactive elements, such as opening/closing parts of models 
and 
displaying 
dynamic 
processes 
or 
animations. 
Gamification elements, such as progress indicators, levels, 
challenges, rewards, and competitions could be included. A 
collection of educational tasks that can be used outside the 
curriculum and without internet access could be provided. 
Measures 
to 
address 
distractions 
should 
be 
implemented. AR and digital learning materials should limit 
potential digital distractions. Features like locking the app or 
disabling the exit button for students can be considered. 
Notifications from other apps, particularly social media, 
should be disabled during app usage. 
Age and skill set, e.g., reading and abstract thinking, 
recommendations for using the learning tool should be 
provided in the description of an app and its content. 
IV. 
DISCUSSION 
The current study validates previous observations and 
introduces new findings regarding AR and other XR 
technologies in education. Although we have focused on AR, 
many of the findings can be applied to Mixed Reality (MR), 
Virtual Reality (VR), and other digital learning aids as well. 
AR shares many similarities with other digital learning aids 
that rely on tablets or mobile phones, as they utilize the same 
underlying technology. Thus, many of our findings are 
relevant to other tablet, mobile, or computer apps as well. 
Moreover, the differences between AR, MR, and VR 
technologies are blurred. For these technologies are often 
placed inside a “virtuality continuum”, also referred to as 
eXtended Reality, with a completely real environment on one 
end and a completely virtual environment at the other end 
[1][32]. Thus, most findings for AR are transferable to other 
XR technologies. The barriers associated with the necessary 
hardware, for instance, become more apparent in VR and MR 
than in AR, as both VR and MR require more extensive and 
immersive equipment. Thus, barriers related to virtual worlds 
and the demands placed on the user's abstraction and spatial 
sense become more apparent, as the level of immersion 
increases for MR and VR compared to AR. Likewise, the 
dominating focus on visual aspects is relevant for all XR 
technologies. In future research, we recommend investigating 
multiple types of XR technologies, while indicating which 
findings are most or least relevant to each respective type. 
Positive outcomes mentioned in the literature could be 
confirmed, such as increased motivation, collaboration, 
interest, and experiential learning [5][8]. Further, our study 
confirms practical challenges mentioned in the literature 
related to space and illumination limitations of the physical 
environments, availability of XR devices, and Internet 
availability in schools, along with the need for improved 
digital and XR skills among teachers, decision-makers and 
students [5][8]. In previous research, educators reported the 
lack of educational AR content suitable to national 
curriculums and daily routines in schools [5][8]. We 
addressed this challenge in the current study by evaluating an 
AR solution tailored to the Norwegian science curriculum. 
Nevertheless, participants in this study pointed out that there 
is still a need for more content in other subjects. 
The insufficient representation of students with 
disabilities during the development and testing of XR 
technology [5] is addressed in this study by including 
students with disabilities. Generally, this inclusion might lead 
to improved user experience for all students: Simplifying the 
user interface, integrating icons and graphical elements, and 
adding sound and vibration effects might benefit students 
with and without disabilities alike. This synergy is commonly 
referred to as the “curb-cut” effect [33][34]. Thus, future 
research could investigate how integrating students with 
disabilities in evaluations including other minority groups, 
such as those with hearing, motor, and mobility disabilities, 
as well as people with chronic conditions, could provide 
numerous benefits. 
The study further confirms the lack of accessibility and 
usability of current XR technology [5][7]. Barriers include 
the absence of support for assistive technology like screen 
readers, alternative input/output devices, glasses, hearing 
aids, or wheelchairs, and the complexity of virtual content for 
users 
with 
cognitive 
disabilities 
[5][7][9]. 
Without 
adjustments, AR and XR are little suited for people with 
cognitive disabilities and largely unusable for students with 
visual disabilities. We particularly suggest making sure that 
the app is compatible with and does not hinder the use of 
assistive technologies. Furthermore, we suggest exploring 
alternative modalities, such as sound effects, vibrations, 
(physical) 3D-printed artifacts, and tactile displays to 
enhance accessibility. Examples of such solutions are a white 
cane with auditory and tactile feedback in VR [35], or a 
toolbox with improvements for users with low vision [36]. 
Additionally, incorporating icons, images, and graphical 
elements may be helpful for students with cognitive 
challenges who lack linguistic capabilities and the ability to 
process abstraction. An example of this is using pictograms 
and icons for users with cognitive disabilities [37]. 
Our findings from the interviews with developers of XR 
technology echo previous findings [5]. Companies are often 
9
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

aware of universal design to some extent but lack the 
necessary resources and tools to enhance the accessibility and 
usability of their technology. Developers may also not be 
aware of barriers faced by users with disabilities or lack the 
expertise to adequately address these barriers. Existing 
guidelines 
and 
frameworks 
from other 
ICT 
areas 
[11][12][13][14][17], 
are 
often 
not 
adequately 
communicated. Additionally, developers express the need for 
easily accessible and usable best practices. The participating 
developers noted that many customers do not prioritize 
increased universal design, which may lead to a lack of 
emphasis on universal design at the management level. 
Developers of systems should be made aware that several 
directives and legal regulations already exist that require the 
universal design of digital learning aids [18][19][20][29]. 
Therefore, we suggest increasing the awareness of and 
expertise in universal design among developers, designers, 
and decision-makers responsible for procuring digital 
learning resources in both the private and public sectors. This 
can be achieved by promoting existing guidelines, visualizing 
concrete barriers, providing specific solutions to these 
barriers, and offering practical best practices. Additionally, 
guidelines from other areas like programming or video games 
[11][12][13][14][26][27][28] should be reviewed for their 
relevance to XR technology. Likewise, we argue that WCAG, 
originally developed for websites, is also relevant for XR 
through the integration of WCAG 2.0 and 2.1 in national and 
international legislations for ICT in general and digital 
learning aids in specific [12][13][20].  
At the same time, AR companies should incorporate 
dedicated procedures for universal design in their 
development and evaluation processes. This may include 
automated or manual checks for accessible and user-friendly 
user interfaces, testing for compatibility with ATs, and 
regular user trials involving students with and without 
disabilities. Similarly, decision-makers, educators, and 
buyers of digital learning solutions should demand and test 
for compliance with universal design requirements. The 
referenced guidelines and standards for user interfaces, video 
games, programming, and XR applications in this paper, 
provide some examples of what XR developers can use 
during the development process, and to which decision-
makers can refer for requirement specifications. 
Finally, our findings demonstrate the consequences of 
inaccessible learning resources used in schools, as well as the 
potential for improved integration if universal design is 
adequately addressed. Inaccessible digital learning resources 
can easily result in knowledge gaps, with students who lack 
essential knowledge struggling to keep up when more 
advanced topics are introduced. Students with disabilities, 
particularly those with visual impairments and cognitive 
challenges, are especially vulnerable to these difficulties. 
However, AR can serve as a suitable alternative for learners 
who rely less on text-based approaches, such as students with 
dyslexia, ADHD, and other learning disabilities. These 
findings align with findings from previous research we 
conducted [5]. 
V. 
CONCLUSION 
In this article, we presented a case study that explores the 
universal design of Augmented Reality (AR) technology in 
educational settings. We believe that the findings will also be 
relevant to other technologies under the umbrella of 
eXtended Reality (XR), such as Mixed Reality (MR) and 
Virtual Reality (VR). Central to the assessment is the 
evaluation of an AR-based pop-up-like book designed for 
primary schools in Norway. User evaluations and interviews 
were conducted with students, including those with 
disabilities, educators, and developers to assess the 
opportunities and benefits, user expectations and best 
practices, challenges, and common pitfalls of using AR in 
educational materials. The study especially identified barriers 
faced by students with visual and cognitive disabilities. 
Furthermore, we provided recommendations and concrete 
measures to improve the integration of AR into the primary 
school curriculum and enhance its accessibility and usability 
for students with and without disabilities. 
One significant challenge highlighted is the heavy 
reliance on visual stimuli in AR, which may pose difficulties 
for students with visual disabilities. Another challenge is the 
complexity and virtuality of AR putting a significant demand 
on the cognitive capabilities of the students, including spatial 
visualization ability and the concept of virtuality. This makes 
AR challenging for students with cognitive disabilities, 
especially in cases where the app lacks both visual and textual 
explanations. These challenges should be addressed by 
employing different approaches, such as incorporating 
alternative modalities like sound and tactile feedback, 
utilizing visual explanations, enhancing engaging symbols 
and icons to captivate students’ interest, and offering textual 
descriptions as alternatives for visual content. Consequently, 
these improvements could enhance the accessibility and 
usability of AR technology for students with and without 
disabilities alike. 
Moreover, many students with disabilities rely on 
assistive technology, like screen readers, hearing aids, 
glasses, or wheelchairs. Developers need to ensure that the 
AR application, including its operation, is compatible with 
these technologies, both physically and programmatically. 
Finally, we recommend raising awareness of and 
expertise in universal design among developers and decision-
makers in private companies and public institutions. This can 
be achieved by gathering best practices, consolidating 
existing guidelines for AR and XR technology, adapting 
relevant guidelines from other ICT areas, and making these 
guidelines easily accessible and widely distributed to 
developers and designers. 
ACKNOWLEDGMENT 
The research has been conducted in cooperation with 
Ludenso AS. The authors thank Ingrid Skrede for her 
contributions, and all participating informants as well. This 
work has been supported by the UnIKT program of the 
Norwegian Directorate for Children, Youth, and Family 
Affairs (Bufdir). 
 
10
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

REFERENCES 
[1] C. Andrews, M. K. Southworth, J. N. A. Silva, and J. R. Silva, 
“Extended Reality in Medical Practice,” Curr. Treat. Options 
Cardiovasc. Med., vol. 21, no. 4, p. 18, Mar. 2019, doi: 
10.1007/s11936-019-0722-7. 
[2] S. Z. A. Ansari, V. K. Shukla, K. Saxena, and B. Filomeno, 
“Implementing Virtual Reality in Entertainment Industry,” in Cyber 
Intelligence and Information Retrieval, Springer Singapore, 2022, pp. 
561–570. doi: 10.1007/978-981-16-4284-5_49. 
[3] E. Yildiz, C. Møller, and A. Bilberg, “Virtual Factory: Digital Twin 
Based Integrated Factory Simulations,” Procedia CIRP, vol. 93, pp. 
216–221, Jan. 2020, doi: 10.1016/j.procir.2020.04.043. 
[4] N. Pellas, I. Kazanidis, and G. Palaigeorgiou, “A systematic literature 
review of mixed reality environments in K-12 education,” Education 
and Information Technologies, vol. 25, no. 4, pp. 2481–2520, Jul. 2020, 
doi: 10.1007/s10639-019-10076-4. 
[5] J. T. Simon-Liedtke and R. C. Baraas, “The Need for Universal Design 
of eXtended Reality (XR) Technology in Primary and Secondary 
Education,” in Proc. of the HCII 2022, Springer International 
Publishing, 2022, pp. 121–141. doi: 10.1007/978-3-031-06015-1_9. 
[6] J. T. Simon-Liedtke and R. C. Baraas, “Investigating Universal Design 
of XR Technology in Primary Schools,” original: “Kartlegging av 
universell utforming av XR-teknologi i grunnskoler,” Norsk 
Regnesentral, 2022. 
[7] J. T. Simon-Liedtke and R. C. Baraas, “Towards eXtended Universal 
Design,” Stud. Health Technol. Inform., vol. 297, pp. 391–399, 2022, 
doi: 10.3233/SHTI220865. 
[8] J. T. Simon-Liedtke and R. C. Baraas, “The Future of eXtended Reality 
in Primary and Secondary Education,” Stud. Health Technol. Inform., 
vol. 297, pp. 549–556, Sep. 2022, doi: 10.3233/SHTI220886. 
[9] A. Wong, H. Gillis, and B. Peck, “VR accessibility: Survey for people 
with disabilities.” Disability Visibility Project, 2017. 
[10] J. Quintero, S. Baldiris, R. Rubira, J. Cerón, and G. Velez, “Augmented 
Reality in Educational Inclusion. A Systematic Review on the Last 
Decade,” Front. Psychol., vol. 10, p. 1835, Aug. 2019, doi: 
10.3389/fpsyg.2019.01835. 
[11] World Wide Web Consortium (W3C), “Web Content Accessibility 
Guidelines 
(WCAG) 
2.0,” 
Dec. 
2008. 
https://www.w3.org/TR/WCAG20/ (retr. Oct., 2023). 
[12] World Wide Web Consortium (W3C), “Web Content Accessibility 
Guidelines 
(WCAG) 
2.1,” 
Jun. 
2018. 
https://www.w3.org/TR/WCAG21/ (retr. Oct., 2023). 
[13] World Wide Web Consortium (W3C), “Web Content Accessibility 
Guidelines 
(WCAG) 
2.2,” 
May 
2023. 
https://www.w3.org/TR/WCAG22 (retr. Oct., 2023). 
[14] B. 
Ellis 
et 
al., 
“Game 
accessibility 
guidelines,” 
2013. 
http://gameaccessibilityguidelines.com/ (retr. Oct., 2023). 
[15] M. Mott et al., “Accessible by Design: An Opportunity for Virtual 
Reality,” in 2019 IEEE International Symposium on Mixed and 
Augmented Reality Adjunct (ISMAR-Adjunct), Oct. 2019, pp. 451–454. 
doi: 10.1109/ISMAR-Adjunct.2019.00122. 
[16] World Wide Web Consortium (W3C), “XR Accessibility User 
Requirements,” 2020. https://www.w3.org/TR/xaur/ (retr. Oct., 2023). 
[17] XR Association, “XRA’s Developers Guide, Chapter Three: 
Accessibility & inclusive design in immersive experiences,” Oct. 27, 
2020. https://xra.org/research/xra-developers-guide-accessibility-and-
inclusive-design/ (retr. Oct., 2023). 
[18] Kommunal- 
og 
moderniseringsdepartementet, 
“Regulation 
on 
Universal Design of Information and Communication Technology 
(ICT) Solutions (FOR-2013-06-21-732),” original: “Forskrift om 
universell utforming av informasjons- og kommunikasjonsteknologiske 
(IKT)-løsninger 
(FOR-2013-06-21-732),” 
Jun. 
2013. 
https://lovdata.no/dokument/SF/forskrift/2013-06-21-732 (retr. Oct., 
2023). 
[19] European Union (EU), “Web Accessibility Directive (WAD) - 
Directive 
(EU) 
2016/2102,” 
Oct. 
2016. 
https://eur-
lex.europa.eu/eli/dir/2016/2102/oj 
[20] European Telecommunications Standards Institute (ETSI), “EN 301 
549 v3.2.1 (2021-03): Accessibility requirements for ICT products and 
services.” 
Mar. 
2021. 
[Online]. 
Available: 
https://www.etsi.org/deliver/etsi_en/301500_301599/301549/03.02.01
_60/en_301549v030201p.pdf 
[21] K. S. Fuglerud and D. Sloan, “The Link between Inclusive Design and 
Innovation: Some Key Elements,” in Human-Computer Interaction. 
Human-Centred 
Design 
Approaches, 
Methods, 
Tools, 
and 
Environments, Springer Berlin Heidelberg, 2013, pp. 41–50. doi: 
10.1007/978-3-642-39232-0_5. 
[22] J. Venable, J. Pries-Heje, and R. Baskerville, “FEDS: A Framework for 
Evaluation in Design Science Research,” European Journal of 
Information Systems, vol. 25, no. 1, pp. 77–89, 2016, doi: 
10.1057/ejis.2014.36. 
[23] T. Boren and J. Ramey, “Thinking aloud: reconciling theory and 
practice,” IEEE Trans. Prof. Commun., vol. 43, no. 3, pp. 261–278, Sep. 
2000, doi: 10.1109/47.867942. 
[24] C. Power and H. Petrie, “Working With Participants,” in Web 
Accessibility, Y. Yesilada and S. Harper, Eds., in Human–Computer 
Interaction Series. London: Springer, 2019, pp. 153–168. doi: 
10.1007/978-1-4471-7440-0_9. 
[25] T. F. Gregers, E. Kalleson, S. H. Rosness, and S. Skarshaug, Solaris 9. 
in Solaris 1-10. Oslo, Norge: H. Aschehoug & Co. (W. Nygaard), 2021. 
[26] S. Zaraysky, “The designer’s guide to accessibility research,” Google 
Design, Mar. 15, 2018. https://design.google/library/designers-guide-
accessibility-research (retr. Oct., 2023). 
[27] Google, “Design for Android,” Android Developers, May 05, 2023. 
https://developer.android.com/design (retr. Oct., 2023). 
[28] Google, 
“Accessibility,” 
Material 
Design, 
May 
05, 
2023. 
https://m2.material.io/design/usability/accessibility.html (retr. Oct., 
2023). 
[29] Kulturdepartementet, 
“Act 
on 
Equality 
and 
Prohibition 
of 
Discrimination (Equality and Discrimination Act, ACT-2017-06-16-
51),” Jun. 2017. https://lovdata.no/dokument/NL/lov/2017-06-16-51 
(retr. Oct., 2023). 
[30] M. Drury, K. Conboy, and K. Power, “Obstacles to decision making in 
Agile software development teams,” J. Syst. Softw., vol. 85, no. 6, pp. 
1239–1254, Jun. 2012, doi: 10.1016/j.jss.2012.01.058. 
[31] T. Pladere, E. Svarverud, G. Krumina, S. J. Gilson, and R. C. Baraas, 
“Inclusivity in stereoscopic XR: Human vision first,” Frontiers in 
Virtual Reality, vol. 3, 2022, doi: 10.3389/frvir.2022.1006021. 
[32] P. Milgram and F. Kishino, “A taxonomy of mixed reality visual 
displays,” IEICE Trans. Inf. Syst., vol. 77, no. 12, pp. 1321–1329, 1994, 
[Online]. Available: https://search.ieice.org/bin/summary.php?id=e77-
d_12_1321 
[33] C. H. Heydarian, “The Curb-Cut Effect and its Interplay with Video 
Games,” Master of Science in Graphic Information Technology, 
Arizona State University, 2020. 
[34] A. G. Blackwell, “The Curb-Cut Effect,” Stanford Social Innovation 
Review, vol. 15, no. 1, pp. 28–33, 2017, doi: 10.48558/YVMS-CC96. 
[35] Y. Zhao et al., “Enabling People with Visual Impairments to Navigate 
Virtual Reality with a Haptic and Auditory Cane Simulation,” in Proc. 
of the 2018 CHI Conference, in CHI ’18. New York, NY, USA: 
Association for Computing Machinery, Apr. 2018, pp. 1–14. doi: 
10.1145/3173574.3173690. 
[36] Y. Zhao et al., “SeeingVR: A Set of Tools to Make Virtual Reality More 
Accessible to People with Low Vision,” in Proc. of the 2019 CHI 
Conference, New York, NY, USA: Association for Computing 
Machinery, May 2019, pp. 1–14. doi: 10.1145/3290605.3300341. 
[37] M. Mastrogiuseppe, L. Soares Guedes, M. Landoni, S. Span, and E. 
Bortolotti, “Technology Use and Familiarity as an Indicator of Its 
Adoption in Museum by People with Intellectual Disabilities,” Stud. 
Health Technol. Inform., vol. 297, pp. 400–407, 2022, doi: 
10.3233/SHTI220866. 
 
11
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

Synchronized Recording System Using Multiple Smartphones 
 
Naoki Morita, Md Saidi Muhammad Ashraf Naim 
School of Information Telecommunication Engineering 
Tokai University 
Tokyo, Japan 
e-mail: {wv062303@tsc, 0cjt2118@cc}.u-tokai.ac.jp 
Chiharu Nakanishi, Chiaki Sawada 
Kunitachi College of Music 
Tokyo, Japan 
e-mail: {nakanishi.chiharu, sawada.chiaki}@kunitachi.ac.jp 
Kenta Morita 
Faculty of Medical Engineering Dept. 
Suzuka University of Medical Science 
Mie, Japan 
e-mail: morita@suzuka-u.ac.jp 
Kazue Kawai 
Faculty of Literature 
Seitoku University 
Chiba, Japan 
e-mail: kawai.kazue@wa.seitoku.ac.jp 
 
 
 
Abstract—The author aims to pass down the tradition of 
classical music to the next generation by significantly 
reforming and evolving traditional piano teaching methods. 
Most of the studies on piano lessons aim to teach beginners 
how to accurately read scores and play the keys with accurate 
rhythms and without mistakes. This study aims to enable 
intermediate students to master musical expression. A system 
was developed to retrospectively analyze the movements of the 
upper body, hands, and feet from various angles using 
synchronized recording with multiple smartphones or tablets. 
This allows for multi-angle viewing without the need for 
complex wiring or data transfer from USB cameras or video 
cameras. By objectively evaluating actual performances, it is 
anticipated that disparities between the ideal and reality will 
be identified, and new challenges will be discovered. 
Keywords- Piano Lesson; support; Recording system; 
visualization. 
I. 
 INTRODUCTION 
This paper is part of research conducted at Japanese 
music universities to pass down the tradition of classical 
piano to the next generation. Most of the previous studies on 
piano lessons [1] - [15] have been aimed at helping beginners 
learn how to read scores accurately and play keys with 
accurate rhythms and without mistakes. The Idea, 
Connection, and Extension (ICE) model [16] is a framework 
describing phases of learning. In the piano ICE model, these 
preceding studies were in the Idea stage. 
This study focuses on the Connection stage in which 
musical expression is acquired. In order to acquire musical 
expression, it is necessary to understand the overall picture 
of the song and play it using the whole body, not just the 
fingertips Recording one’s own play-through on video and 
reviewing it is important. However, traditional video 
playback platforms did not allow for quickly cueing up 
specific phrases or scenes. 
This study aims to develop a “Piano Lesson Total 
Visualization System” that allows the user to instantly check 
the movements of the performer’s body (upper body, hands, 
feet) in conjunction with the score [17] - [19]. In this study, 
we report on the development of a system that can utilize 
smartphones and tablet devices to record performances from 
multiple angles and allow playback from annotated points 
through cueing up. 
The remainder of this paper is organized as follows. In 
Section II, this paper discusses the results of a survey on 
reviewing piano lesson videos, and Session III explains the 
concept of the proposed system that visualizes the entire 
piano lesson. Section IV discusses the multi-angle recording 
system developed in this study, and Section V provides 
conclusions and discusses future work. 
II. 
QUESTIONNAIRE SURVEY RESULT 
We conducted a survey regarding reviewing piano lesson 
videos [17]. The following responses were obtained: 
(1) Most of the students record their piano lessons. 
However, almost none of them reviewed all previously 
recorded lesson videos due to a lack of time and 
motivation to watch the videos from the beginning until 
the end. 
(2) Students feel dissatisfied when watching the videos, e.g., 
“I can’t see how I touch the keyboard,” “I can’t see my 
own face or hear my tone.” 
(3) Students were dissatisfied with video viewing, e.g., “It 
takes too much time to find my desired video from the 
video archive,” “It is difficult to pinpoint the part that I 
am interested in,” “It is difficult to go back in time to 
watch.” 
(4) Students and instructors have complaints about the 
device itself and application when handling the device, 
e.g., “Connecting is difficult,” “I don’t know how to use 
the app.” 
12
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

III. 
THE SYSTEM CONCEPT 
We have the following concepts for the visualization 
system of piano lessons: 
(1) A system that can synchronize recording using multiple 
smartphones or tablets. This function will be discussed 
in Section IV. 
(2) The system can instantly play a specific part of the video, 
playing the video from the measure clicked by the user. 
The association between the score and the video is made 
by comparing the scale recognized from the score and 
the pitch recognized from the video. These functions are 
currently successful with some melody scores and 
arpeggio staves [19]. 
(3) Videos recorded in the system are added to the calendar 
index by score name and recording time. Past and 
current performances can be instantly searched. 
IV. 
THE DEVELOPED SYSTEM 
The developed system realizes multi-angle recording and 
linkage of recorded performance videos and calendars. 
A. System Architecture 
This developed system consists of a server and a client. 
The server side is implemented using the Laravel framework, 
and the client side is implemented using Vue.js. The server 
coordinates with database and file management, as well as 
previously developed [19] score analysis and video analysis 
modules. The client provides a calendar, score upload, video 
recording, and video viewing to the user. 
B. Recording 
This section explains multi-angle recording using an 
example of three angles: the upper body, hands, and feet. 
Four smartphones are used. One is used as the controller 
machine for starting/stopping and for recording with the 
microphone. The remaining three smartphones are used as 
video cameras. 
After logging in on the controller smartphone, the system 
displays a QR code when selecting the score that the user 
uploaded in advance. The QR code contains the URL of the 
recording web address and user authentication information. 
When the user scans the QR code with another smartphone 
and clicks to allow camera access, the camera activates and 
will be in the recording standby state. Figure 1 shows the 
placement during the recording of a performance and each 
camera angle. 
Recording is synchronized with the start/stop signal from 
the controller device, and automatically uploaded to the 
server upon completion. This allows for multi-angle 
recording without the cumbersome wiring of USB cameras 
or data transfer from video cameras. This system has been 
tested for operation using Chrome browsers on PCs, iOS, 
and Android. The audio is saved in mp3 format on iOS, 
recording is possible in mp4 format for up to approximately 
12 minutes (110MB), and on Android, in WebM format for 
up to approximately 27 minutes (45MB). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Example of camera angle. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. Example of score and video viewing page. 
 
C. Review 
When the user clicks on an index (score name and 
practice time) on the calendar, the score and the video are 
displayed. Figure 2 is the viewing page. One angle of the 
video is displayed prominently, while the remaining angles 
are displayed as thumbnails. Selecting a thumbnail switches 
between the enlarged display and thumbnail display. If the 
previously developed Score Analysis Module [19] and Video 
Analysis Module [19] allow the linkage of scores and videos, 
playback can be started from the corresponding scene by 
clicking on a measure in the score. If a module cannot be 
parsed correctly, the user can watch the video once and add 
an annotation to the timestamp they want to review, making 
it easier to review from the second time onwards. In the 
example in Figure 2, annotations are added at the 2nd, 5th, 
and 11th measures during the initial listening session. 
D. Trial 
Before using this system in an actual class, we conducted 
a demonstration and interviewed an instructor. 
• 
USB cameras are difficult to set angles because the 
screen is not visible. On the other hand, smartphone 
cameras are easy. 
13
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

• 
It is convenient because no data transfer is required.  
• 
The sound quality is not very good. 
E. Discussion 
The purpose of this research is to develop a user interface 
that enables recording and playback from multiple angles 
using readily available PCs and smartphones, simplifying the 
review process through annotation functionality, all without 
the need for special equipment for the “Score Click Playback 
System.” The current system can only record up to 12 
minutes, so it cannot record an entire 60 minutes lecture. 
However, it is possible to record a single performance. In 
addition, being able to review immediately without data 
transfer is considered useful for reviewing performances 
External microphone support may be needed to improve 
sound quality issues. 
V. 
CONCLUSION 
This study aimed to record performances from multiple 
angles so that performers themselves can check how they use 
their bodies. Traditional single-camera shooting had 
problems, such as difficulty checking the use of hands and 
feet when shooting the whole. In this study, a multi-angle 
recording system was built that can shoot in cooperation with 
multiple smartphones. Future work will be to make the 
sound quality clearer. And then, examine the effectiveness of 
the system in actual lessons. 
ACKNOWLEDGMENT 
The present study was supported by the Japan Society for 
the Promotion of Science (JSPS) through KAKENHI Grant 
Number 21K18528. 
REFERENCES 
[1] C. Oshima, K. Nishimoto, and M. Suzuki, “A Piano Duo 
Performance Support System to Motivate Children’s Practice 
at Home,” IPSJ Journal, Vol. 46, No. 1, pp.157–171, 2005. 
[2] K. Nakahira, M. Akabane, and Y. Hukami, “Faculty 
Development for Playing and Singing Education with 
Blended 
Learning,” 
Japan 
Society 
for 
Educational 
Technology, Vol.34, pp.45–48, 2010. 
[3] Y. Yokoyama, and K. Nishimoto, “A piano practice support 
system for preventing performance cessation caused by 
performance errors,” IPSJ Interaction, pp.118–127, 2010. 
[4] E. Nakamura, H. Takeda, R. Yamamoto, S. Sako, and S. 
Sagayam, “Score Following Handling Performances with 
Arbitrary 
Repeats 
and 
Skips 
and 
Automatic 
Accompaniment,” IPSJ Journal, Vol. 54, No. 4, pp.1338–
1349, 2013. 
[5] Y. Takegawa, T. Terada, and M. Tsukamoto, “Design and 
Implementation of a Piano Learning Support System 
Considering Rhythm Learning,” IPSJ Journal, Vol. 54, No. 4, 
pp.1383–1392, 2013. 
[6] H. Kato, N. Emura, and M. Miura, “Support system for 
practicing piano-scale performances,” Acoustical Society of 
Japan, Vol.70, No.6, pp.273–276, 2014. 
[7] F. Yuto, T. Yoshinari, and Y. Hidekatsu, “Design and 
Implementation of a Piano Learning Support System 
Considering Motivation,” IPSJ Interaction, pp.118–127, 2015. 
[8] K. Yamada, K. Yamamoto, and T. Noma, “A Piano Learning 
System with Visual Correspondence Between Musical Scale 
and Keyboard,” IPSJ EC, pp.378–385, 2015. 
[9] K. Ueda, Y. Takegawa, and K. Hirata, “Design and 
Implementation of a Piano Learning Support System 
Focusing on Visualization of Keying Information and 
Annotation,” IPSJ Journal, Vol. 57, No. 12, pp.2617–2025, 
2016. 
[10] Y. Takegawa, K. Hirata, E. Tayanagi, and M. Tsubakimoto, 
“Evaluation Analysis of a Piano Learning Support System 
Focusing on the Learning Process,” IPSJ Journal, Vol. 58, No. 
5, pp.1093–1100, 2017. 
[11] T. Ishigami, and T. Hamamoto, “A Piano Practice Support 
System Visualizing Correspondence Between Music Scores 
and Key Positions,” ITE Technical Report, Vol.41, No.14, 
pp.71–76, 2017. 
[12] N. Takaya, S. Nakahira, and M. Kitajima, “Analysis of the 
relationships between the proficiency levels of piano playing 
and the changes in visual behaviors while reading score and 
performing piano,” IPSJ SIG Technical Report, pp.1–7, 2017. 
[13] T. Suzuki, K. Tanaka, R. Ogura, and Y. Tsuji, “Practice of 
Beginners’ Piano Skill Training Support Using ‘Visualization 
System for Piano Performance (VSPP)’,” IPSJ SIG Technical 
Report, Vol.2018-MUS-119 No.16, pp.1-6, 2018. 
[14] R. Matsui, Y. Takegawa, and K. Hirata, “Tel-Gerich: Remote 
Piano Lesson System Considering Joint Attention Camera 
Switching and Cam- era Switching,” Human interface: the 
transaction of Human Interface Society, Vol.20, No.3, 
pp.321–332, 2018. 
[15] R. Matsui, A. Hasegawa, Y. Takegawa, K. Hirata, and Y. 
Yanagawa, “Design, Implementation and Assessment of a 
Support System to Find Bad Fingering Habits for Piano 
Teachers,” IPSJ Journal, Vol. 61, No. 4, pp.789–797, 2020. 
[16] F. S. Young, and R. J. Wilson, “Assessment and learning: The 
ICE approach. Winnipeg,” MB: Portage and Main Press., 
2000. 
[17] C. Nakanishi, C. Sawada, K. Kawai, K. Morita, and N. Morita, 
“An Analysis of Needs for Developing a Tool for Piano 
Learning,” Proceedings of the 2022th National Convention of 
Society for Educational Technology, pp.35–36, 2022. 
[18] N. Morita, C. Nakanishi, C. Sawada, K. Morita, and K. Kawai, 
“Requirements 
for 
Piano 
Lesson 
Support 
System,” 
Proceedings of SIGNAL 2023, pp.18–20, 2023. 
[19] M. Wakiyama, et al., “Development of a Score Click 
Playback System,” Proceedings of SIGNAL 2023, pp.21–23, 
2023. 
 
 
14
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

Measuring AI Education Performance with Flipped Learning  
Based on Bloom's Taxonomy Objectives 
 
Hyo-Jin Kim 
Institute of Artificial Intelligence 
POSTECH 
Pohang, South Korea 
e-mail: hyojinkim@postech.ac.kr 
Dongju Kim 
Institute of Artificial Intelligence 
POSTECH 
Pohang, South Korea 
e-mail: kkb0320@postech.ac.kr
 
 
Abstract— As the importance of Artificial Intelligence (AI) 
capabilities increases across industries, the demand for AI 
education for young job seekers is also increasing. However, 
non-majors in related fields face difficulties in learning due to 
the lack of specialized learning content and prior learning 
opportunities. This study aimed to implement an AI education 
program through flipped learning for young job seekers and 
evaluate its effectiveness. The study included 80 students from 
a South Korean university AI training program, randomly 
assigned into control and experimental groups with 40 majors 
and 40 non-majors in each. In the end, the experimental group 
achieved higher academic results than the control group, 
particularly on higher-level items. 
Keywords- 
Artificial 
intelligence; 
Education; 
Flipped 
learning; Young job seekers. 
I. 
INTRODUCTION  
Currently, 
the 
demand 
for 
artificial 
intelligence 
manpower is exploding in various fields, but it is challenging 
to supply manpower through formal education within a short 
time. Although artificial intelligence can be classified as a 
computer science discipline, it has a wide range of fields and 
applications, so it is not just for science and engineering 
majors. Still, it is considered an essential literacy for modern 
people in the era of the Fourth Industrial Revolution. 
However, in order to learn AI, primary computer languages, 
basic mathematics, computer algorithms, and other essential 
learning contents are required in common. 
In the non-degree AI training program for young job 
seekers, a large number of trainees receive intensive training 
for a limited period of time. In addition, it is challenging to 
provide individual scaffolding for learners with varying 
levels of prior knowledge in the classroom, as AI education 
is conducted using the Project-Based Learning (PBL) 
method that combines theory and practice. In order to 
increase learner motivation and promote achievement, 
learner-centered education is necessary for individual 
learners in all majors [1]. Non-majors can repeatedly learn 
online video materials using the flipped learning method as 
scaffolding outside the classroom, based on individual 
capabilities and progress. It is possible to implement out-of-
classroom classes in which memory and understanding in 
Bloom's hierarchy of educational objectives [2] are learner-
driven. As a result, it is expected that efficient and effective 
learner-centered AI classes will be possible, as it will be 
possible to secure class time for complete learning and 
higher-level classes such as practical exercises and projects 
through summarizing and answering questions about core 
contents in the actual classroom.  
This study aimed to effectively implement AI education 
for both non-CS (Computer Science) majors and those who 
struggle to learn AI. To achieve this, an experimental study 
was conducted using a learner-centered approach by 
adopting the flipped learning method. The study measured 
academic achievement and the effectiveness of achieving 
learning goals in the higher dimensions of Bloom's 
Taxonomy. 
The remainder of this paper is organized as follows. The 
related works of flipped learning and Bloom's Taxonomy are 
presented in Section 2. The methodology of this study is 
explained in Section 3. Section 4 showcases the study's 
results. Finally, the paper concludes with Section 5.  
II. 
RELATED WORK 
In this section, we describe Flipped Learning and 
Bloom’s Taxonomy that are closely related to the topic of 
this paper. 
A. Flipped Learning 
Flipped learning is a learner-centered teaching method 
that allows instructors to utilize classroom time efficiently 
and effectively [3].  Baker used the term "The classroom 
flipped" [4], and Bergmann and Sams, teachers in Colorado, 
USA, created and provided online class videos for students 
who could not attend class and defined it as flipped learning 
[5]. Prior to that, there was a teaching method of learning the 
material in advance out of class and doing learner-centered 
activities in class. Still, with the development of technology 
and the advent of the information age, the role of the 
instructor has shifted from being a source of information to 
helping students learn how to handle information [6]. This 
phenomenon is expected to intensify with the rise of artificial 
intelligence and big data during the Fourth Industrial 
Revolution. As a result, the flipped learning teaching method 
is predicted to expand and advance. 
B. Bloom’s Taxonomy 
Bloom 
categorized 
the 
hierarchy 
of 
educational 
objectives 
as 
remembering, 
understanding, 
applying, 
15
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

analyzing, evaluating, and creating [2]. Bergmann and Sams 
reversed Bloom's hierarchy of objectives for flipped learning, 
suggesting that memory and comprehension occur outside 
the classroom, while higher-order thinking of application, 
analysis, evaluation, and creation are promoted in the 
classroom [5].  
In Figure 1, Bloom's inverted pyramid [7] shows the 
application of Bloom's Taxonomy to the flipped learning 
model. 
 
 
Figure 1.  Bloom’s reversed taxonomy [7] 
Pre-learning lecture videos provided out of class are a good 
content delivery tool to achieve the lower levels of Bloom's 
taxonomy, namely remembering and understanding and in-
class learning can be valuable to foster higher-level learning, 
namely applying, analyzing, evaluating, and creating. 
III. 
METHODOLOGY 
This study was conducted on 40 control and 40 
experimental group students enrolled in the artificial 
intelligence education program at a university in South 
Korea. Adopting a quasi-experimental research method with 
a non-identical control group before-and-after comparison, 
the control group received a traditional curriculum with only 
classroom lessons and no flipped learning. In contrast, the 
experimental group received flipped learning lessons using 
pre-learning video content created by the instructor and 
uploaded to the LMS (Learning Management System) as 
TABLE 1.  
TABLE I.  
FLIPPED LEARNING PLAN BASED ON BLOOM'S TAXONOMY 
Area 
Traditional Class  
(Control group) 
Flipped Class 
(Experimental group) 
Remember 
Face-to-face lecture 
Pre-learning lecture video 
(about 30 min.) 
Face-to-face lecture 
Understand 
Face-to-face lecture 
LMS, Padlet 
Face-to-face lecture 
Apply 
Hands-on programming 
training 
Hands-on programming 
training 
Analyze, 
Evaluate, 
Create 
Project work 
Project work 
For the experimental study, the control and experimental 
groups were given the same study time, content, test 
difficulty, assignment content, and number of assignments.  
IV. 
RESULT 
The academic achievement results of the lower and 
higher-level items of the test of the control group and the 
experimental group showed a statistical difference as 
indicated in TABLE 2.  
TABLE II.  
COMPARISON OF ACADEMIC ACHIEVEMENT 
Learni
ng 
level 
Group 
N 
Mean 
SD 
t 
p 
Lower-
level 
Control 
40 
27.00 
13.39 
2.108* 
.038 
Experime
ntal 
40 
32.27 
8.44 
Higher-
level 
Control 
40 
16.20 
11.66 
2.648* 
.010 
Experime
ntal 
40 
22.08 
7.81 
Total 
Control 
40 
43.20 
23.57 
2.581* 
.012 
Experime
ntal 
40 
54.35 
13.82 
* p<.05 
In particular, the scores of the experimental group were 
significantly higher in the higher-level items compared to the 
lower-level items, aligning with the goal of flipped learning, 
which is the achievement of higher-level learning objectives. 
As academic achievement significantly improved in the 
entire test and in all lower and higher-order items, it can be 
concluded that flipped learning-based AI education has a 
positive impact on enhancing academic achievement. 
V. 
DISCUSSION AND CONCLUSION 
This experimental study showed that the application of 
the flipped learning method in AI education for young job 
seekers improved academic achievement in both lower and 
higher-level items measured by the test. In a traditional 
classroom, lower-level learning, which corresponds to 
memory and comprehension in Bloom's Taxonomy, takes 
place face-to-face between the instructor and the learner, so 
the instructor can immediately identify the learner's level of 
understanding and adjust the difficulty and pace of the 
lecture to the learner. On the other hand, the memory and 
comprehension learning that occurs in flipped learning is 
replaced by pre-made videos, which makes it difficult for 
instructors to identify learners' needs in real time. Despite 
these disadvantages, flipped learning is a self-paced learning 
method that allows young adult learners with diverse 
backgrounds and prior knowledge to learn the basics of 
retention and comprehension at their own pace outside of the 
classroom. In addition, learners can engage in meta-learning, 
where they can learn at a higher level through online 
collaboration tools outside the classroom, group activities in 
the classroom, and questions and answers with the instructor, 
which is a strength of flipped learning that is difficult to 
achieve in traditional classrooms with limited class time.  
Since this study was conducted with a relatively small 
sample size, consisting of 40 individuals in each group 
(control and experimental) for both majors and non-majors, 
totaling 80 participants, it is essential to conduct multiple 
iterations of experimental research in the future. This will 
allow for the analysis of effectiveness based on results from 
a larger and more diverse population. 
 
16
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023

ACKNOWLEDGMENT 
This work was partly supported by IITP grant funded by 
MSIT (No.2019-0-01906 and No.2021-0-01096). This 
research was supported by Basic Science Research Program 
through the National Research Foundation (NRF) funded by 
the Ministry of Education (2022R1A6A1A03052954). 
 
REFERENCES 
[1] B. L McCombs and J. S. Whisler, “The Learner-Centered 
Classroom and School: Strategies for Increasing Student 
Motivation and Achievement. The Jossey-Bass Education 
Series,” Jossey-Bass Inc., Publishers, 350 Sansome St., San 
Francisco, CA 94104, 1997. 
[2] L. W. Anderson and D. R. Krathwohl, “A taxonomy for 
learning, teaching, and assessing: A revision of Bloom's 
taxonomy of educational objectives: complete edition,” 
Addison Wesley Longman, Inc, 2001. 
[3] A. Nederveld and Z. L. Berge, “Flipped learning in the 
workplace,” Journal of Workplace Learning, 27.2. pp. 162-
172, 2015 
[4] J. W. Baker, “The origins of “the classroom flip””, The First 
Annual Higher Education Flipped Learning Conference, 
Greeley, Colorado. 2016. 
[5] J. Bergmann and A. Sams, “Flip your classroom: Reach every 
student in every class every day,” International Society for 
Technology in Education, 2012. 
[6] J. F. Strayer, “Designing instruction for flipped classrooms,” 
in Instructional-Design Theories and Models, vol. IV. 
Routledge, pp. 321-350, 2016. 
[7] J. Bergmann and A. Sams, “Flipped learning: Gateway to 
student engagement,” International Society for Technology in 
Education, 2014. 
 
17
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-087-2
SOCIETY TRENDS 2023 : International Conference on Technical Advances and Human Consequences - 2023
Powered by TCPDF (www.tcpdf.org)

