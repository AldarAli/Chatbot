CORETA 2023
Advances on Core Technologies and Applications
ISBN: 978-1-68558-114-5
September 25 - 29, 2023
Porto, Portugal
CORETA 2023 Editors
Petre DINI, IARIA EU/USA

CORETA 2023
Forward
The Advances on Core Technologies and Applications - Building with and around AI, ML, IoT, 5G,
Mobility and Cognition 2023 (CORETA 2023), held between September 25th and September 29th, 2023,
continued a series of international events covering challenges to make use and correlate results in
different scientific and technological achievements.
A plethora of intertwined technologies and applications have been raised during the recent years
because of maturity of core approaches related to Artificial Intelligence (AI), Machine Learning (ML),
Deep Learning (DL), and Cognitive Computing (CC) domains. In parallel, new technologies like 5G, tactile
Internet, spatial and terrestrial communications augmented the speed and computing possibilities of
networking systems.
Citizen-centric services, as well as innovations in transportation, healthcare, industry, and economy,
in general become provocative challenges due to complexity, diversity and the increasing needs of our
society. In the virtual eco-systems, where robots are part of society as well, robot-driven industry, robot-
citizen care, behavior analytics, affective computing, and empathy set the search for practical
applications of deep-learning and knowledge discovery.
While progress is visible, sensitive aspects related to privacy, digital forgery, assisted-living, and
semantic processing of the enormous information collected for IoT and wearable devices are still
partially solved. Apart intrinsic citizen-focused issues, new self-driven systems and parts (drones,
vehicular systems), sustainable and green energy, protection of critical systems, and smart cities
challenges ask for innovative correlation and real-time solutions based on the core-technologies and
applications mentioned above.
We take here the opportunity to warmly thank all the members of the CORETA 2023 technical
program committee, as well as all the reviewers. The creation of such a high-quality conference program
would not have been possible without their involvement. We also kindly thank all the authors who
dedicated much of their time and effort to contribute to CORETA 2023. We truly believe that, thanks to
all these efforts, the final conference program consisted of top-quality contributions. We also thank the
members of the CORETA 2023 organizing committee for their help in handling the logistics of this event.
We hope that CORETA 2023 was a successful international forum for the exchange of ideas and
results between academia and industry and for the promotion of progress in the field of core
technologies and applications.
CORETA 2023 Chairs
CORETA 2023 Steering Committee
Eugen Borcoci, University Politehnica of Bucharest, Romania
Efstratios (Stratos) Kontopoulos, Catalink Ltd., Cyprus
Tsuyoshi Nakajima(中島毅), Shibaura Institute of Technology, Japan

CORETA 2023 Publicity Chairs
Laura Garcia, Universitat Politecnica de Valencia, Spain
Lorena Parra Boronat, Universitat Politecnica de Valencia, Spain
José Miguel Jiménez, Universitat Politecnica de Valencia, Spain

CORETA 2023
Committee
CORETA 2023 Steering Committee
Eugen Borcoci, University Politehnica of Bucharest, Romania
Efstratios (Stratos) Kontopoulos, Catalink Ltd., Cyprus
Tsuyoshi Nakajima(中島毅), Shibaura Institute of Technology, Japan
CORETA 2023 Publicity Chairs
Laura Garcia, Universitat Politecnica de Valencia, Spain
Lorena Parra Boronat, Universitat Politecnica de Valencia, Spain
José Miguel Jiménez, Universitat Politecnica de Valencia, Spain
CORETA 2023 Technical Program Committee
H. B. Acharya, Rochester Institute of Technology, USA
Francisco Airton Silva, Federal University of Piauí, Brazil
Abdullah Al-Mamun, University of Nevada, Reno, USA
Adel Aneiba, Birmingham City University, UK
Francisco J. Aparicio Navarro, De Montfort University, UK
Elias Benamira, Polytechnic School of Algiers, Algeria
Ayush Bhargava, Key Lime Interactive, USA
Mariuxi Alexandra Bruzza Moncayo, Pontificia Universidad Católica del Perú, Peru
José Manuel Cascalho, GRIA LIACC | Azores University, Portugal
Hubert Cecotti, California State University, Fresno, USA
Younghun Chae, Kent State University at Stark, USA
Lou Chitkushev, Boston University, USA
Gayo Diallo, University of Bordeaux, France
Ashutosh Dhar Dwivedi, Technical University of Denmark, Denmark
Dariusz Dymek, Krakow University of Economics, Poland
Martina Fröschl, University of Applied Arts Vienna, Austria
Yu Gao, Opus College of Business | University of St Thomas, USA
Zhiwei Gao, NorthumbriaUniversity, UK
Apostolos Gkamas, University Ecclesiastical Academy of Athens, Greece
Denis Gracanin, Virginia Tech, USA
P.K. Gupta, Jaypee University of Information Technology, India
Daniel Howe, City University of Hong Kong, Hong Kong
Muhammad Zahid Iqbal, University College Dublin, Ireland
Sheikh Rabiul Islam, University of Hartford, USA
Naeem Khalid Janjua, Edith Cowan University, Australia
Celine Jost, Paris 8 University, France
María-Carmen Juan-Lizandra, Universitat Politècnica de València, Spain
Yasushi Kambayashi, Sanyo-Onoda City University, Japan
Ilias Karasavvidis, University of Thessaly, Greece
Arashdeep Kaur, Lovely Professional University, India

Neo Tse Kian, Multimedia University, Malaysia
Jarosław Korpysa, University of Szczecin, Poland
Lida Kouhalvandi, Istanbul Technical University, Turkey
Galyna Kriukova, National University of Kyiv-Mohyla Academy, Ukraine
Dimosthenis Kyriazis, University of Piraeus, Greece
Rustam Latypov, Kazan Federal University, Russia
Gyu Myoung Lee, Liverpool John Moores University, UK
Sarah M. Lehman, Temple University, USA
Yiu-Wing Leung, Hong Kong Baptist University, Kowloon Tong, Hong Kong
Tahir Mahmood, School of Natural Sciences (SNS) | National University of Sciences and Technology
(NUST), Islamabad, Pakistan
Sadouanouan Malo, University Nazi Boni, Bobo-Dioulasso, Burkina Faso
Alina-Elena Marcu, "Politehnica" University of Bucharest, Romania
Pramit Mazumdar, University of Roma Tre, Italy
Khalil Mebarkia, Budapest University of Technology, Hungary
Paolo Mercorelli, Institute of Product and Process Innovation - PPI | Leuphana University of Lueneburg,
Germany
Mohammad F. Obeid, Shenandoah University, USA
Cláudia Ortet, University of Aveiro, Portugal
Grażyna Paliwoda-Pękosz, Krakow University of Economics, Poland
Stamatis Papadakis, University of Crete, Greece
Isidoros Perikos, University of Patras, Greece
Krzysztof Pietroszek, Institute for IDEAS / American University, Washington, USA
Alessandro Sebastian Podda, University of Cagliari, Italy
Ladislav Polak, Brno University of Technology, Poland
Chinthaka Premachandra, Shibaura Institute of Technology, Japan
M. Mustafa Rafique, Rochester Institute of Technology, USA
Fernando Reinaldo Ribeiro, Polytechnic Institute of Castelo Branco, Portugal
Anatoliy Sachenko, West Ukrainian National University, Ukraine
Lobna A. Said, Nile University, Egypt
Amitrajit Sarkar, Ara Institute of Canterbury | University of Canterbury, New Zealand
Oleg Sergiyenko, Baja California Autonomous University, Mexico
Shouqian Shi, Google, USA
Liyang Sun, New York University, USA
Eirini Eleni Tsiropoulou, University of New Mexico, USA
Mabel Vazquez Briseno, Autonomous University of Baja California (UABC), Mexico
Naga Vemprala, University of Portland, USA
Hazem Wannous, IMT Lille Douai, France
Hong Yang, Nokia Bell Labs, Murray Hill, USA
Rui Yang, Xi'an Jiaotong-Liverpool University, China
Serhii Yevseiev, National Technical University - Kharkiv Polytechnic Institute, Ukraine
Nurul Azma Zakaria, Universiti Teknikal Malaysia Melaka, Malaysia
Kashif Zia, Bahria University, Pakistan

Copyright Information
For your reference, this is the text governing the copyright release for material published by IARIA.
The copyright release is a transfer of publication rights, which allows IARIA and its partners to drive the
dissemination of the published material. This allows IARIA to give articles increased visibility via
distribution, inclusion in libraries, and arrangements for submission to indexes.
I, the undersigned, declare that the article is original, and that I represent the authors of this article in
the copyright release matters. If this work has been done as work-for-hire, I have obtained all necessary
clearances to execute a copyright release. I hereby irrevocably transfer exclusive copyright for this
material to IARIA. I give IARIA permission or reproduce the work in any media format such as, but not
limited to, print, digital, or electronic. I give IARIA permission to distribute the materials without
restriction to any institutions or individuals. I give IARIA permission to submit the work for inclusion in
article repositories as IARIA sees fit.
I, the undersigned, declare that to the best of my knowledge, the article is does not contain libelous or
otherwise unlawful contents or invading the right of privacy or infringing on a proprietary right.
Following the copyright release, any circulated version of the article must bear the copyright notice and
any header and footer information that IARIA applies to the published article.
IARIA grants royalty-free permission to the authors to disseminate the work, under the above
provisions, for any academic, commercial, or industrial use. IARIA grants royalty-free permission to any
individuals or institutions to make the article available electronically, online, or in print.
IARIA acknowledges that rights to any algorithm, process, procedure, apparatus, or articles of
manufacture remain with the authors and their employers.
I, the undersigned, understand that IARIA will not be liable, in contract, tort (including, without
limitation, negligence), pre-contract or other representations (other than fraudulent
misrepresentations) or otherwise in connection with the publication of my work.
Exception to the above is made for work-for-hire performed while employed by the government. In that
case, copyright to the material remains with the said government. The rightful owners (authors and
government entity) grant unlimited and unrestricted permission to IARIA, IARIA's contractors, and
IARIA's partners to further distribute the work.

Table of Contents
Educational Location-Based Augmented Reality Applications for Indoor Spaces: Creating the Application
“Exploring the Aquarium of Kastoria”
Alexandros Kleftodimos and Athanasios Evagelou
1
Powered by TCPDF (www.tcpdf.org)

 
 
Educational Location-Based Augmented Reality Applications for Indoor Spaces: 
Creating the Application “Exploring the Aquarium of Kastoria” 
 
Alexandros Kleftodimos  
Department of Communication and Digital Media,  
University of Western Macedonia,                                    
Kastoria, Greece 
email: akleftodimos@uowm.gr 
Athanasios Evagelou 
 Center for Education for the Environment                               
and Sustainability  
Kastoria, Greece 
email: evagel@sch.gr 
Abstract—Location-based Augmented Reality (AR) is a type 
of markerless AR technology where content is activated when a 
user reaches a specific location. This type of AR is currently used 
in many fields, such as tourism, recreational games, marketing, 
education, and initiatives that combine these purposes. 
Location-based AR applications typically rely on the mobile 
device’s Global Positioning System (GPS) sensor to report the 
user’s location. In indoor spaces, however, the GPS signals are 
either absent or weak, and tracking the users’ position requires 
alternative methods. This paper aims to present an educational 
location-based application for an indoor aquarium. The 
application was created to inform school students and visitors 
about the fish and other freshwater organisms exhibited in this 
aquarium. The paper also aims to present an affordable process 
for developing location-based AR educational applications for 
indoor spaces (e.g., museums, schools, etc.). This process does 
not require programming expertise or special equipment; 
therefore, it can be followed by all educators. 
Keywords—Augmented Reality; Location-Based Augmented 
Reality; Museum Education. 
I. 
INTRODUCTION 
Augmented Reality (AR) is a technology that has existed 
for many years. According to the literature, the first AR 
technology, an AR head-mounted display, was developed in 
1968 at Harvard by a scientist called Ivan Sutherland. Since 
then, many initiatives contributed to the growth of AR [1]. 
AR, however, gained significant popularity when AR mobile 
applications appeared, and AR could be experienced using 
devices such as smartphones and tablets. Mobile augmented 
reality has experienced explosive growth over the last decade 
[2].  
Augmented reality is currently used in many academic and 
commercial fields, such as tourism, marketing, entertainment, 
and education. It can also be used to fulfill more than one 
purpose. For example, an augmented reality application can 
be used to promote destinations and monuments by educating 
and entertaining visitors at the same time.  
On the other hand, education is a sector where many AR 
innovations have been introduced. By exploring the literature, 
one can find a wide variety of AR applications designed for 
all levels of education. More specifically, there are numerous 
AR applications designed for primary (e.g., [3]–[5]), 
secondary education  (e.g., [6], [7]), as well as higher 
education [8]. AR has also been used for a wide range of 
subjects, as it can be seen in a recent literature review [9].  
Quite a few categorizations have been presented 
throughout the evolution of AR. One broadly known 
taxonomy concerns the way in which the AR experience is 
triggered. Marker-based AR, also referred to as image-based 
AR, relies on visual markers, such as Quick Response (QR) 
codes, printed images, and real-world objects to trigger the 
experience. Markerless AR, on the other hand, does not rely 
on physical markers. Instead, mobile device cameras and other 
sensors are used to detect and track the user’s environment and 
determine the place where the virtual content will appear. Two 
common types of markerless AR are projection-based AR and 
location-based AR. Projection-based AR uses projectors to 
display multimedia content (e.g., 3D images) onto flat two-
dimensional surfaces, such as building walls. In location-
based AR, the content is fixed to a specific physical location. 
Mobile devices with GPS sensors are the most common way 
to identify specific locations and superimpose the real 
environment with multimedia content through the mobile 
device camera. The multimedia content can be in the form of 
text, images (3D and 2D), sound, videos, and animations. 
Location-based Augmented Reality (LBAR) applications 
(or location-aware AR) have existed for quite some time, but 
their use for various communication purposes has become 
widespread after the advent of two popular augmented reality 
location-based games, namely Pokemon Go and Ingress, 
created by Niantic in 2014 and 2016, respectively. 
However, location-based AR is limited in education 
regardless of its potential for creating application-assisted 
tours in areas of educational interest (e.g., open museums, 
cultural heritage sites, and places of environmental interest). 
A quick analysis of the scientific literature reveals that most 
AR projects are based on a marker-based approach. For 
example, a systematic mapping review of Science, 
Technology, 
Engineering, 
and 
Mathematics 
(STEM) 
augmented reality applications in higher education [8] 
revealed the scarcity of markerless AR and location-based 
applications in the specific field. Furthermore, creating AR 
applications for indoor spaces (e.g., museums) remains a 
challenge since GPS sensors lack precision in such places or 
fail entirely. This paper aims to present an indoor location-
based AR application and the methodology and tools used for 
developing the application. The application aims to inform the 
visitors of an aquarium about the fish exhibited in the 
aquarium’s tanks. Furthermore, the paper also aims to present 
the tools and process for creating location-based AR for 
indoor spaces using an open-source authoring tool, which 
many educators can use since it does not require advanced 
technical knowledge.  
In Section II, the available technologies for creating 
location-based AR applications will be presented. For this 
project, Taleblazer was chosen since it is an open-source and 
reliable solution. Taleblazer and its mechanism for creating 
such applications will also be explained briefly in this section. 
In Section III, a gamified location-based AR application for 
1
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-114-5
CORETA 2023 : Advances on Core Technologies and Applications - 2023

an indoor aquarium will be presented, and in Section IV, 
insights obtained from students who experienced the 
application during school visits to the aquarium will be 
discussed. The paper concludes in Section V. 
II. 
CREATING LOCATION-BASED AR APPLICATIONS FOR 
INDOOR SPACES 
A. Exploring the available position tracking technologies 
for indoor spaces. Using beacons for location-based AR.  
There are a few ways to create AR applications that keep 
track of the user’s position in an indoor environment and 
activate content when the user gets close to certain locations. 
One way to achieve this is by using an indoor positioning 
system. This system consists of electronic devices and special 
computer software for locating people or objects in settings 
where the GPS signal is weak or absent. Multiple indoor 
tracking systems technologies exist, including radio-based, 
optical, magnetic, and acoustic technologies. One hardware 
solution that is commonly supported by authoring software 
used for building location-based AR for indoor spaces is the 
iBeacon technology. An iBeacon is a Bluetooth low-energy 
device that only sends a signal in a specific format [10]. 
Beacons regularly broadcast packets in the iBeacon format. 
iBeacon packets contain the beacon’s identifying information 
and the power level at which the beacon is transmitting. The 
iOS and Android operating systems provide libraries for 
determining three proximity levels based on signal strength: 
immediate, near, and far. Multiple precision levels can 
indicate the user’s position and support different application 
(or game) mechanics.  
Some museums utilize beacons and AR to replace audio 
tours that rely on special equipment and provide visitors with 
a better experience by relying on their mobile devices. 
Beacons can transmit information about a user’s location in 
the museum. If the user’s location is known, then static or 
dynamic information about the exhibits (which can be in 
multimedia form) can be delivered. 
The National Slate Museum in England developed the 
Slate Museum| Amgueddfa Lechi app in 2014 and applied 
beacon technology to the museum so that visitors can use the 
guiding app [11]. The researchers of [12] used AR and 
beacons to develop a museum tour guide application. More 
specifically, the Chang Gung University Digital Media Lab 
combined AR and beacon technology to build the Formosa 
Plastic Group Museum's guiding system. The tour guide 
application provides an information-guiding service and 
various interactive education and entertainment functions. 
Furthermore, a recent study [13] explored Bluetooth beacon 
use cases in teaching and learning. Among the 33 reviewed 
studies, two combined AR with beacon technology in an 
educational setting. More specifically, Jurkovičová et al. [14] 
created an AR application that utilizes beacon technology to 
guide students around a learning space using complementary 
overlaid visual information displayed on their own devices, 
and Karlsson et al. used beacon–AR synergy to develop an 
educational quest game called ArQuest [15]. 
Although the use of beacons can solve the problem of the 
absence of a GPS signal in indoor spaces for AR applications 
by tracking the user's position, it must be said that beacons 
come with a cost. The average price for a single beacon is 
around $25, and in spaces such as museums with many 
exhibits, many beacons may be needed. In the next section, a 
way for developing location-based AR for indoor spaces 
without extra equipment will be presented.  
Another concern when building location-based AR 
applications for indoor spaces is the authoring tools. While 
there are many solutions for developing AR applications, most 
of them require advanced programming knowledge. Many 
applications have been built using development tools, such as 
ARCore, ARKit, WikiTude, and Vuforia, but these tools are 
intended for experienced programmers. On the other hand, 
there are tools such as Taleblazer [16], Metaverse Studio [17], 
and ARIS [18] that require little or no programming 
experience and are suitable for most educators who are 
interested in building AR experiences for their classes. In 
previous studies, we explored the capabilities of  Metaverse 
studio, Taleblazer, and ARIS to detect the pros and cons of 
these online authoring software packages for educators 
without particular expertise in software development [19][20]. 
The comparative analysis in [19] revealed that, while the 
application development with Taleblazer is not as simple as 
with Metaverse Studio, the advantages that Taleblazer 
provides in developing location-based AR apps are greater 
when compared to those provided by Metaverse Studio. 
Therefore, it is worth it for educators to make the extra effort 
to get acquainted with the Taleblazer programming 
environment.   
TaleBlazer was developed by the “Scheller Teacher 
Education Program (STEP)” of the Massachusetts Institute of 
Technology (MIT). Taleblazer has a visual block-based 
programming environment similar to Scratch [21], another 
famous product of MIT.  
      Regarding indoor location-based applications, both 
Metaverse Studio and Taleblazer support the use of iBeacons, 
and Taleblazer has detailed documentation on how to proceed 
with such a task. Furthermore, Taleblazer provides creators 
with an additional way to develop such applications, which is 
also cost-effective since it does not require special devices. 
This option will be discussed in the following subsection. 
B. Using Taleblazer and password-protected Agents for 
building location-based AR applications. 
The Taleblazer development environment relies on a 
visual block-based scripting language (Figure 1).  
 
Figure 1. Taleblazer visual block-based scripting language 
environment. 
To program a location-based learning application (e.g., 
game), the educator must be (or willing to get) acquainted with 
a visual block-based programming language that is very 
similar to Scratch, another known product of MIT as 
mentioned in the previous section. The visual block-based 
2
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-114-5
CORETA 2023 : Advances on Core Technologies and Applications - 2023

programming environment of Taleblazer is suitable for people 
with no prior knowledge of programming. Visual block-based 
programming environments are extensively used for 
introduction to programming and computational thinking and 
are also ideal for young kids. 
The basic elements of the Taleblazer environment are 
“Regions” and “Agents”. Regions are the physical areas on a 
map where the game takes place. The first thing that a designer 
must do is to determine the region of the game on a digital 
map using a selection tool. After the region is set, “Agents” 
can be introduced. Agents are digital content associated with 
a GPS location and activated when a learner “bumps” into this 
location. 
Taleblazer utilizes 
the 
Google 
Map 
Application 
Programming Interface (API) to guide user navigation. 
Furthermore, Taleblazer provides the ability to use custom 
maps besides the Google dynamic map. This means that 
creators can create their own maps using image editing and 
graphic design tools, and applications can be experienced on 
these custom maps as long as they are matched appropriately 
with the physical locations. This option allows designers to 
create applications that do not require an active internet 
connection during gameplay. Custom maps are also necessary 
when developing indoor applications since images of the 
interior spaces will have to be created (Figure 2).  
 
 
Figure 2. Snapshot from the Taleblazer development environment. 
Inserting location points (red dots) on a custom map and 
associating these points (Agents) with multimedia content. 
Taleblazer also has two settings called “Autobump” and 
“Tap to bump”. When the user comes close enough to the 
target GPS locations defined in the application scenario, a 
Taleblazer agent is activated. According to the Taleblazer 
terminology, the player is said to have ‘bumped’ into the 
Agent. In Taleblazer, an agent is activated either automatically 
(Autobump) or by tapping on the red dot of the Agent on the 
map (tap to bump). In the absence of position tracking, the 
“tap to bump” option can be used together with password-
protected agents. This feature is provided by Taleblazer and is 
well explained in its software documentation.  
By activating the “tap to bump – regardless of the player 
location” option in the ‘bump settings’ and using password-
protected agents, an indoor location-based application can be 
created without position-tracking devices. Agents are placed 
on the custom map, and passwords are associated with these 
agents. The passwords must be placed close to the physical 
location of the Agents in the indoor physical environment, and 
the application designer can think of various ways to achieve 
this (e.g., signs, stickers, etc.). The player will have to tap on 
the appropriate icon (Agent) on the application map and then 
insert the password found close to the target location to 
activate the digital content. This way, it is guaranteed that the 
player has reached the required location in the indoor region. 
III. 
THE APPLICATION “EXPLORING THE AQUARIUM OF 
KASTORIA”  
The application is a joint effort between the Center for 
Education for the Environment and Sustainability of Kastoria 
and the Digital Media and Strategic Communication Lab 
(DMSClab) of the Communication and Digital Media 
Department, University of Western Macedonia, Greece. 
These two entities are in close collaboration to implement 
research and education projects related to new technologies in 
education.  Every school year, a large number of K-12 
students visit the Center for Education for the Environment 
and Sustainability of Kastoria to attend one of its educational 
programs. The Center has also adopted augmented reality 
technologies in some programs to enhance the educational 
experience. 
Kastoria is a city in the province of Western Macedonia, 
Greece, a city near a lake named Orestiada. The larger part of 
the city is a peninsula that is literally surrounded by the lake. 
The aquarium of Kastoria hosts fish and other freshwater 
organisms of Greece that are either indigenous, endemic, or 
foreign. Most of the exhibited fish species in the aquarium 
have been living for centuries in the lakes and rivers of Greece, 
but there are also species that have been imported from other 
countries at some point. It is the largest freshwater aquarium 
in the Balkans, and in recent years has become one of the main 
attractions of the city of Kastoria. The aquarium is visited 
every year by a large number of tourists as well as students 
who visit the aquarium as part of organized school trips 
(Figure 3). 
 
 
Figure 3. A picture from the interior space of the Aquarium of 
Kastoria. 
 
 
The “Exploring the Aquarium of Kastoria” application is 
accessible to all aquarium visitors. The application is currently 
in the Greek language only, and there has been a translation of 
several screenshots for the purposes of this paper. In Figure 4, 
one can see the initial screen of the application.  
3
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-114-5
CORETA 2023 : Advances on Core Technologies and Applications - 2023

 
Figure 4. The initial screen of the application. 
Seeking to exploit the advantages offered by location-
aware AR technologies, the augmented reality digital 
application “Exploring the Aquarium of Kastoria” was 
designed with the following objectives in mind: 
• To provide an alternative method that will mobilize the 
students' interest and strengthen their active participation 
during an educational program. 
• To strengthen the experience of the educational activity 
through continuous observation and interaction with the 
real world (aquarium exhibits) and the digital elements of 
the AR mobile application. 
• To evoke positive feelings usually present when students 
participate in games that encourage cooperation and are 
supported using their favorite means of entertainment and 
communication devices (smartphones and tablets). 
• To utilize and further develop the students’ digital literacy. 
• To provide students with attractive means of obtaining 
information about the fish exhibited in the aquarium. The 
students can also visit the aquarium after a school trip, 
alone or with their family or friends, and experience the 
AR application at their own time and pace. 
The application aims to inform users about the following 
aspects:  
• 
What the fish eat  
• 
Their value in environmental sustainability  
• 
Their behaviour  
• 
The polymorphism of their species  
• 
Facts regarding the endemicity and migration of 
fish  
• 
The threats to their existence.  
The application has been developed using Taleblazer and 
password-protected agents. First, a custom map of the interior 
area of the aquarium was created using an image editing 
program. Adobe Photoshop was used in our case, but other 
open-source or free image editing programs can be used (e.g., 
Gimp, Photopea, etc). This custom map was then inserted in 
the Taleblazer development environment, and location points 
were inserted on this map (Agents). The location points were 
placed at several fish tanks (21 locations). The application 
users get oriented in the beginning by looking at the map and 
the first location to be reached (depicted as a red dot in Figure 
5). 
 
 
Figure 5. A custom map of the aquarium. The red dot is the first 
point that the application user must visit. 
 
After the users get acquainted with their position and the 
map, they are ready to embark on the tour. The tour is not 
sequential, meaning that the users are not prompted to visit the 
tanks one by one and in the order that they are exhibited in the 
aquarium. The visitors are led to move in a seemingly random 
order inside the aquarium with the task to observe, think, 
answer questions regarding the fish, and collect points when 
these questions are answered correctly. The next location is 
always depicted with a red dot. The users would have to move 
to the next location on the map and tap the red dot when they 
are in front of the right tank. A message then pops up on their 
screen asking them about the correct code (Figure 6).  Signs 
with number codes have been placed above each tank. The 
signs can be seen in Figure 7. 
 
 
4
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-114-5
CORETA 2023 : Advances on Core Technologies and Applications - 2023

 
Figure 6. The user is prompted to enter the correct code. 
 
 
Figure 7- Signs with codes are placed above each tank. 
Giving the correct code means that users are at the right 
location, observing the fish intended by the application. A 
message confirms whether the user is in the correct location. 
After this message, the users are asked to answer two 
questions regarding the fish exhibited in the tank before them 
(e.g., Figures 8 and 9).  
 
 
 
Figure 8. An application snapshot. 
 
 
Figure 9. Questions are posed to the users regarding the fish they 
see in the tank before them. 
The answers to the questions can be, in most cases, 
obtained by reading the information on the signs that exist 
underneath each tank. The signs contain the name of the fish 
and information about them. The application also gives 
additional information. Points are awarded every time the user 
answers correctly. At any stage of the game, the users can see 
the points they have collected by visiting the points tab (Figure 
10).  
 
Figure 10. Points are awarded for correct answers. 
The application also has sound. The information and the 
questions are also provided by a recorded human voice besides 
the application text. Visitors and students in the aquarium are 
advised to use headphones or keep the mobile device at low 
volume and next to their ears to listen to the application sound 
without disrupting other visitors.  
5
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-114-5
CORETA 2023 : Advances on Core Technologies and Applications - 2023

IV. INSIGHTS OBTAINED FROM APPLICATION USE 
Initially, the application was tested by all four educators 
who work at the Center for Education for the Environment and 
Sustainability of Kastoria. The educators did not experience 
any problems while using the application. 
Furthermore, the application was experienced by more 
than 100 students. Students were asked to experience the 
application in small groups after a small demonstration on 
how to use the application. Almost all students had not 
previously experienced a location-based AR application for 
indoor spaces. The students were left alone to navigate the 
aquarium while the Center’s educators observed their 
behaviour. While younger primary school students (ages 6 to 
9) needed some time to get oriented in the aquarium by using 
the application map, older students (ages 10 to 17) had no 
problems navigating in the aquarium using the application. 
Furthermore, it was obvious to the observers that the students 
were excited with this gamified method of exploring an 
aquarium and learning about its exhibits. Many students also 
expressed positive opinions about the novelty of the 
application to their peers and teachers.  
V. CONCLUSIONS  
This paper concerns location-based AR applications for 
indoor spaces and how such applications can be developed. 
While AR is widely used in education, location-based AR is 
limited and mainly concerns open spaces (e.g., city tours, 
cultural heritage sites, etc.). Location-based AR use cases for 
interior spaces where the GPS signal is either weak or totally 
absent are even fewer. 
Position-tracking devices, such as iBeacons, are 
encountered in literature as a way to implement location-based 
AR for interior spaces. However, these devices come with a 
cost. Moreover, most AR applications encountered in the 
literature rely on development tools that require advanced 
programming expertise. This paper presents an affordable way 
for creating educational location-based AR for interior spaces 
without the need for special devices, using an open-source 
software platform (Taleblazer), which is suitable for educators 
without previous programming experience. The paper also 
presents an educational application for an aquarium developed 
using this methodology to provide ideas and guidance for 
educators who wish to create similar applications (or games). 
Preliminary insights obtained from observing students who 
used the application are very encouraging. A limitation of this 
research effort is that a systematic evaluation using a large 
sample of students has not been carried out, and that is 
something that the research team intends to do in the future.  
ACKNOWLEDGMENT 
Special thanks to the University of Western Macedonia, 
Greece.  
REFERENCES 
[1] D. R. Berryman, ‘Augmented Reality: A Review’, Medical 
Reference Services Quarterly, vol. 31, no. 2, pp. 212–218, Apr. 
2012, doi: 10.1080/02763869.2012.670604. 
[2] A. B. Craig, Understanding Augmented Reality: Concepts and 
Applications. Newnes, 2013. 
[3] E. Demitriadou, K.-E. Stavroulia, and A. Lanitis, ‘Comparative 
evaluation of virtual and augmented reality for teaching 
mathematics in primary education’, Educ Inf Technol, vol. 25, 
no. 1, pp. 381–401, Jan. 2020, doi: 10.1007/s10639-019-
09973-5. 
[4] J.-M. Sáez-López, M. L. Sevillano-García-García, and M. de 
los Á. Pascual-Sevillano, ‘Application of the ubiquitous game 
with augmented reality in Primary Education’, Comunicar: 
Revista Científica de Comunicación y Educación, vol. 27, no. 
61, pp. 71–82, Oct. 2019, doi: 10.3916/C61-2019-06. 
[5] H. Hidayat, S. Sukmawarti, and S. Suwanto, ‘The application 
of augmented reality in elementary school education’, RSD, 
vol. 10, no. 3, p. e14910312823, Mar. 2021, doi: 10.33448/rsd-
v10i3.12823. 
[6] V. Marín-Díaz, B. Sampedro, and J. Figueroa, ‘Augmented 
Reality in the Secondary Education classroom: Teachers’ 
Visions’, CONT ED TECHNOLOGY, vol. 14, no. 2, p. ep348, 
Jan. 2022, doi: 10.30935/cedtech/11523. 
[7] C. Volioti et al., ‘Using Augmented Reality in K-12 Education: 
An Indicative Platform for Teaching Physics’, Information, 
vol. 13, no. 7, p. 336, Jul. 2022, doi: 10.3390/info13070336. 
[8] S. Mystakidis, A. Christopoulos, and N. Pellas, ‘A systematic 
mapping review of augmented reality applications to support 
STEM learning in higher education’, Educ Inf Technol, vol. 27, 
no. 2, pp. 1883–1927, Mar. 2022, doi: 10.1007/s10639-021-
10682-1. 
[9] G. Lampropoulos, E. Keramopoulos, K. Diamantaras, and G. 
Evangelidis, ‘Augmented Reality and Gamification in 
Education: A Systematic Literature Review of Research, 
Applications, and Empirical Studies’, Applied Sciences, vol. 
12, no. 13, p. 6809, Jul. 2022, doi: 10.3390/app12136809. 
[10] M. Kohne and J. Sieck, ‘Location-Based Services with iBeacon 
Technology’, in 2014 2nd International Conference on 
Artificial Intelligence, Modelling and Simulation, Madrid: 
IEEE, Nov. 2014, pp. 315–321. doi: 10.1109/AIMS.2014.58. 
[11] ‘National 
Slate 
Museum 
application’. 
https://appadvice.com/app/national-slate-museum-amgueddfa-
lechi-cymru/1122132874 (accessed Aug. 25, 2020). 
[12] T.-H. Tsai, C.-Y. Shen, Z.-S. Lin, H.-R. Liu, and W.-K. Chiou, 
‘Exploring Location-Based Augmented Reality Experience in 
Museums’, in Universal Access in Human–Computer 
Interaction. Designing Novel Interactions, M. Antona and C. 
Stephanidis, Eds., in Lecture Notes in Computer Science, vol. 
10278. Cham: Springer International Publishing, 2017, pp. 
199–209. doi: 10.1007/978-3-319-58703-5_15. 
[13] S. Griffiths et al., ‘Exploring Bluetooth Beacon Use Cases in 
Teaching and Learning: Increasing the Sustainability of 
Physical Learning Spaces’, Sustainability, vol. 11, no. 15, p. 
4005, Jul. 2019, doi: 10.3390/su11154005. 
[14] L. Jurkovičová, P. Červenka, T. Hrivikova, and I. Hlavatý, E-
Learning in augmented reality utilizing iBeacon technology,  
2015. 
[15] E. Karlsson, O. Nygren, and M. Gamboa, ‘ArQuest: 
Augmented reality in education’, in In Proceedings of 
SIDeR’16–student interaction design research conference.,  
[16] ‘Taleblazer’, http://taleblazer.org/ (accessed Aug. 25, 2023). 
[17] ‘Metaverse studio’, https://studio.gometa.io/landing (accessed 
Aug. 25, 2023). 
[18] ‘ARIS’, Fielddaylab.org (accessed Aug. 25, 2023). 
[19] A. Kleftodimos, G. Lappas, and M. Vrigkas, ‘Taleblazer vs. 
Metaverse: a comparative analysis of two platforms for 
building AR location-based educational games’, IJENTTM, 
vol. 
1, 
no. 
4, 
p. 
290, 
2022, 
doi: 
10.1504/IJENTTM.2022.129630. 
[20] A. Kleftodimos, M. Moustaka, and A. Evagelou, ‘Location-
Based Augmented Reality for Cultural Heritage Education: 
Creating 
Educational, 
Gamified 
Location-Based 
AR 
Applications for the Prehistoric Lake Settlement of Dispilio’, 
Digital, vol. 3, no. 1, pp. 18–45, Jan. 2023, doi: 
10.3390/digital3010002. 
[21] ‘Scratch’, https://scratch.mit.edu (accessed Aug. 25, 2023). 
 
6
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-114-5
CORETA 2023 : Advances on Core Technologies and Applications - 2023
Powered by TCPDF (www.tcpdf.org)

