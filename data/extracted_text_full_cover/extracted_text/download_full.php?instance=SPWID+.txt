SPWID 2018
The Fourth International Conference on Smart Portable, Wearable, Implantable
and Disability-oriented Devices and Systems
ISBN: 978-1-61208-657-6
July 22 - 26, 2018
Barcelona, Spain
SPWID 2018 Editors
Giovanni Albani, MD, Department of Neurology and Neurorehabilitation, Istituto
Auxologico Italiano, IRCCS Piancavallo, Verbania, Italy

SPWID 2018
Foreword
The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-
oriented Devices and Systems (SPWID 2018), held between July 22 - 26, 2018- Barcelona, Spain, is an
inaugural event bridging the concepts and the communities dealing with specialized implantable,
wearable, near-body or mobile devices, including artificial organs, body-driven technologies, and
assistive services
Mobile communications played by the proliferation of smartphones and practical aspects of
designing such systems and developing specific applications raise particular challenges for a successful
acceptance and deployment.
We take here the opportunity to warmly thank all the members of the SPWID 2018 Technical
Program Committee, as well as the numerous reviewers. The creation of such a broad and high quality
conference program would not have been possible without their involvement. We also kindly thank all
the authors who dedicated much of their time and efforts to contribute to SPWID 2018. We truly believe
that, thanks to all these efforts, the final conference program consisted of top quality contributions.
Also, this event could not have been a reality without the support of many individuals,
organizations, and sponsors. We are grateful to the members of the SPWID 2018 organizing committee
for their help in handling the logistics and for their work to make this professional meeting a success.
We hope that SPWID 2018 was a successful international forum for the exchange of ideas and
results between academia and industry and for the promotion of progress in the areas of smart portable
devices and systems.
We are convinced that the participants found the event useful and communications very open.
We hope that Barcelona provided a pleasant environment during the conference and everyone saved
some time to enjoy the charm of the city.
SPWID 2018 Chairs:
SPWID Steering Committee
Marius Silaghi, Florida Institute of Technology, USA
Jun-Dong Cho, SungKyunKwan University, Korea
Lenka Lhotska, Czech Institute of Informatics, Robotics and Cybernetics | Czech Technical University in
Prague, Czech Republic
SPWID Industry/Research Advisory Committee
Warner ten Kate, Philips Research, the Netherlands

SPWID 2018
COMMITTEE
SPWID Steering Committee
Marius Silaghi, Florida Institute of Technology, USA
Jun-Dong Cho, SungKyunKwan University, Korea
Lenka Lhotska, Czech Institute of Informatics, Robotics and Cybernetics | Czech Technical University in
Prague, Czech Republic
SPWID Industry/Research Advisory Committee
Warner ten Kate, Philips Research, the Netherlands
SPWID 2018 Technical Program Committee
Giovanni Albani, Istituto Auxologico Italiano - IRCCS, Verbania, Italy
Jesús B. Alonso Hernández, Institute for Technological Development and Innovation in Communications
(IDeTIC) | University of Las Palmas de Gran Canaria (ULPGC), Spain
Viacheslav Antsiperov, Kotel'nikov Institute of Radio-engineering and Electronics (IRE) of Russian
Academy of Sciences (RAS), Russia
Rohan Banerjee, Tata Consultancy Services, India
Roberto Beghi, University of Milan, Italy
Katharina Bredies, University of the Arts Berlin, Germany
Filip Bergquist, Sahlgrenska Academy | University of Gothenburg, Sweden
Juan V. Capella Hernández, Universitat Politècnica de València, Spain
Filippo Cavallo, The BioRobotics Institute | Scuola Superiore Sant'Anna, Pisa, Italy
Amitava Chatterjee, Jadavpur University, Kolkata, India
Claude Chaudet, Webster University Geneva, Switzerland
Jun-Dong Cho, SungKyunKwan University, Korea
Cesario Di Sarno, COSIRE Group, Aversa, Italy
Dermot Diamond, Dublin City University, Ireland
Mariella Dimiccoli, University of Barcelona, Spain
Jian Du, Carnegie Mellon University, Pittsburgh, USA
Ramin Fallahzadeh, Washington State University, USA
Biyi Fang, Michigan State University, USA
Gianluigi Ferrari, University of Parma, Italy
Alessia Garofalo, COSIRE Group, Aversa, Italy
Vivian Genaro Motti, George Mason University, USA
Arfan Ghani, Coventry University, UK
Athanasios Gkelias, Imperial College London, UK
Chris Gniady, University of Arizona, USA
Mario Goldenbaum, Princeton University, USA
Raffaele Gravina, University of Calabria, Italy
Jan Havlík, Czech Technical University in Prague, Czech Republic
Carmen Horrillo Güemes, Instituto de Tecnologías Físicas y de la Información (ITEFI) | Consejo Superior

de Investigaciones Científicas (CSIC), Spain
Gema Ibáñez Sánchez, ITACA - Universitat Politècnica de València, Spain
Ki-Il Kim, Chungnam National University, Republic of Korea
Andrew Kusiak, University of Iowa, USA
Lenka Lhotska, Czech Institute of Informatics, Robotics and Cybernetics | Czech Technical University in
Prague, Czech Republic
Tianliang Li, SMRT-NTU Smart Urban Rail Corporate Laboratory, Singapore
Feng Lin, University at Buffalo, USA
Jindong Liu, Imperial College London, UK
Jiang Lu, University of Houston - Clear Lake, USA
Jianwei Ma, Harbin Institute of Technology, China
Parbati Kumar Manna, Intel Corporation, USA
Farokh Marvasti, Sharif University of Technology, Iran
Abhinav Mehrotra, University College London, University of Birmingham, UK
Kunal Mitra, Florida Institute of Technology, USA
Hossein Mohamadipanah, University of Wisconsin, USA
Carlos A. Mugruza Vassallo, Universidad Nacional Tecnológica de Lima Sur / Universidad de Lima, Peru /
SINAPSE, UK
Sugata Munshi, Jadavpur University, India
Tadashi Nakano, Osaka University, Japan
Brendan O'Flynn, Tyndall National Institute, Ireland
Gregory O'Hare, University College Dublin (UCD), Ireland
Lorena Parra, Universitat Politècnica de València, Spain
Veljko Pejović, University of Ljubljana, Slovenia
Mohammad Pourhomayoun, Cornell University, USA
Alejandro Quintero, Polytechnique de Montreal, Canada
Daniel Roggen, University of Sussex, UK
Seyed-Ali Rokni, Washington State University, USA
Ramyar Saeedi, Washington State University, USA
Osamu Saisho, NTT, Japan
Jacob Scharcanski, UFRGS - Universidade Federal do Rio Grande do Sul, Brazil
Rasoul Shafipour, University of Rochester, USA
Pietro Siciliano, Institute for Microelectronics and Microsystems IMM-CNR, Lecce, Italy
Marius Silaghi, Florida Institute of Technology, USA
Mu-Chun Su, National Central University, Taiwan
Ryszard Tadeusiewicz, AGH University of Science and Technology, Krakow, Poland
Adrian Tarniceriu, PulseOn SA, Switzerland
Warner ten Kate, Philips Research, Netherlands
Vicente Traver, ITACA - Universitat Politècnica de València, Spain
Carlos M. Travieso-González, University of Las Palmas de Gran Canaria, Spain
Alessio Tugnolo, University of Milan, Italy
Wenwu Wang, University of Surrey, UK
Wang Wen, Institute of Acoustics - Chinese Academy of Sciences, China
Hui Wu, University of New South Wales, Australia
Xiao-Jun Wu, Jiangnan University, China
Kaikai Xu, University of Electronic Science and Technology of China, Chengdu, China
Xuesong Yang, Beckman Institute for Advanced Science and Technology | University of Illinois at
Urbana-Champaign, USA

José Yauri, FEEC-UNICAMP, Brazil
Haihang You, Institute of Computing Technology - Chinese Academy of Sciences, China
Qingxue Zhang, The University of Texas at Dallas, USA
Lihong Zheng, Charles Sturt University, Australia

Copyright Information
For your reference, this is the text governing the copyright release for material published by IARIA.
The copyright release is a transfer of publication rights, which allows IARIA and its partners to drive the
dissemination of the published material. This allows IARIA to give articles increased visibility via
distribution, inclusion in libraries, and arrangements for submission to indexes.
I, the undersigned, declare that the article is original, and that I represent the authors of this article in
the copyright release matters. If this work has been done as work-for-hire, I have obtained all necessary
clearances to execute a copyright release. I hereby irrevocably transfer exclusive copyright for this
material to IARIA. I give IARIA permission or reproduce the work in any media format such as, but not
limited to, print, digital, or electronic. I give IARIA permission to distribute the materials without
restriction to any institutions or individuals. I give IARIA permission to submit the work for inclusion in
article repositories as IARIA sees fit.
I, the undersigned, declare that to the best of my knowledge, the article is does not contain libelous or
otherwise unlawful contents or invading the right of privacy or infringing on a proprietary right.
Following the copyright release, any circulated version of the article must bear the copyright notice and
any header and footer information that IARIA applies to the published article.
IARIA grants royalty-free permission to the authors to disseminate the work, under the above
provisions, for any academic, commercial, or industrial use. IARIA grants royalty-free permission to any
individuals or institutions to make the article available electronically, online, or in print.
IARIA acknowledges that rights to any algorithm, process, procedure, apparatus, or articles of
manufacture remain with the authors and their employers.
I, the undersigned, understand that IARIA will not be liable, in contract, tort (including, without
limitation, negligence), pre-contract or other representations (other than fraudulent
misrepresentations) or otherwise in connection with the publication of my work.
Exception to the above is made for work-for-hire performed while employed by the government. In that
case, copyright to the material remains with the said government. The rightful owners (authors and
government entity) grant unlimited and unrestricted permission to IARIA, IARIA's contractors, and
IARIA's partners to further distribute the work.

Table of Contents
A Factor of Human-Robot Interaction on Wearable Robot: A Literature Review
Myung-Chul Jung, Kyung-Sun Lee, and Seung-Min Mo
1
A Single Wearable IMU-based Human Hand Activity Recognition via Deep Autoencoder and Recurrent Neural
Networks
Patricio Rivera Lopez, Edwin Valarezo Anazco, Sangmin Lee, Kyung Min Byun, Min Hyoung Cho, Soo Yeol Lee,
and Tae-Seong Kim
3
A Review of Wearable Tracking and Emotional Monitoring Solutions for Individuals with Autism and Intellectual
Disability
Mohammed Taj-Eldin, Brendan O’Flynn, Paul Galvin, and Christian Ryan
8
Steps Toward Automatic Assessment of Parkinson's Disease at Home
Roberto Nerino, Claudia Ferraris, Giuseppe Pettiti, Antonio Chimienti, Corrado Azzaro, Giovanni Albani,
Lorenzo Priano, and Alessandro Mauro
15
Proprioceptive Focal Stimulation (Equistasi®) May Improve Motor Symptoms in Moderate Parkinson’s Disease
Patients. Italian Multicentric Preliminary Open Study
Antonella Peppe, Paolo Paone, Stefano Paravati, Maria Giulia Baldassarre, Leila Bakdounes, Fabiola Spolaor,
Annamaria Guiotto, Davide Pavan, Zimi Sawacha, Daniela Clerici, Nicola Cau, Alessandro Mauro, Giovanni
Albani, Micol Avenali, Giorgio Sandrini, Cristina Tassorelli, and Daniele Volpe
21
TouchWear: Context-Dependent and Self-Learning Personal Speech Assistant for Wearable Systems with Deep
Neural Networks
Joshua Ho and Chien-Min Wang
25
Stress Detection of the Students Studying in University Using Smartphone Sensors
Ghulam Hussain, Muhammad Shahid Jabbar, Sangmin Bae, and Jun Dong Cho
30
Powered by TCPDF (www.tcpdf.org)

A Factor of Human-Robot Interaction on Wearable Robot: A Literature Review 
 
Myung-Chul Jung 
Department of Industrial Engineering 
Ajou University 
Suwon-si, Republic of Korea 
email: mcjung@ajou.ac.kr 
Kyung-Sun Lee 
Department of Industrial Safety 
Management 
Suncheon Jeil College 
Suncheon-si, Republic of Korea 
email: kslee@suncheon.ac.kr 
Seung-Min Mo 
Department of Industrial and 
Chemical Engineering 
Suncheon Jeil College 
Suncheon-si, Republic of Korea 
email: smmo@suncheon.ac.kr 
 
 
Abstract— The robot technology is developing to improve 
human life and that substitutes human function and capability. 
The key factor of wearable robot is a human-robot interaction. 
The purpose of this study is to analyze the ergonomic factors of 
a human-robot interaction based on literature reviews. To 
search for ergonomic factors on a human-robot interaction, we 
looked into four databases in Web of Science, Scopus, IEEE 
Explore, and Google Scholar. This study reviewed literature 
including papers, books, international standards published 
from January 1st, 2000 to May 1st, 2018. The title and abstract 
of literature was checked by authors. Selected literature was 
reviewed and the main factors were manually extracted. There 
were twelve literature that met the inclusion criteria. This 
study evaluated the ergonomic factors of human-robot 
interaction categorized as safety, human and robot factors 
which were warning sign, stability, fail-safe, range of motion, 
fatigue, contact pressure, motion intention, misalignment, 
power, closed-loop system, and etc. These ergonomic factors 
are suggested to the safety and usability evaluation systems by 
developing ergonomic design specifications of wearable robots. 
Keywords - Wearable Robot; Human-Robot Interaction; 
Ergonomic; Safety; Usability. 
I. 
 INTRODUCTION 
The robot technology is developing to improve industry 
productivity and convenience in human life. The application 
of wearable robotics is growing in various fields such as 
industry, rehabilitation, prosthetics, space application and 
defense. A wearable robot can be seen as a technology that 
extends, complements, substitutes human function and 
capability or replaces [1]. 
Previous studies still have focused on developing and 
improving the mechanical performance of a wearable robot. 
However, the key distinctive aspect in wearable robots is 
their Human-Robot Interaction(HRI).  An HRI is a hardware 
and software link that connects to both human and robot 
systems [2]. 
The purpose of this study is to analyze to the ergonomic 
factors of HRI on a wearable robot through a literature 
review. 
II. 
METHOD 
The purpose of this method is to search main factors in 
HRI, and to identify potential ergonomic factors. This review 
details the findings from four electronic databases via 
keyword searches in Web of Science, Scopus, IEEE Explore, 
and Google Scholar. For this study, we searched literature 
related with HRI of wearable robot including papers, public 
documents, books, international standards and report 
published from January 1st, 2000 to May 1st, 2018. 
Regarding the search keyword, the search criteria used 
were ‘human robot interaction’, ‘ergonomics’, ‘human 
factor’, ‘usability’, ‘safety’ and ‘comfortability’. To avoid 
literature not falling into the topic under study, the search 
was performed using the Boolean operator “AND”, with the 
search term ‘ergonomics’ [3]. 
The following additional inclusion criteria were used to 
search the literature: 
 
a. 
Published as a full text literature, or in press, in peer-
reviewed journals 
b. Published or in press between January 1st, 2000 and 
prior May 1st, 2018 
c. 
Literature in this study includes that paper, article, 
public document, book, international standard and 
issue report 
d. Literature that considered HRI on wearable robot 
e. 
Literature with an ergonomics studies or application 
purpose 
 
The process of literature review, titles and abstracts were 
checked separately by three of the authors. Prior to literature 
review, inclusion criteria were identified and corresponding 
relevant information required was analyzed. Then, the 
selected relevant literature was reviewed and the main 
factors manually extracted. 
III. 
RESULT 
A total of 51 literatures were searched, of which 12 
literatures that met the inclusion criteria [4]-[15]. Table 1 
shows the reviewed literature evaluated for the ergonomic 
factors. It categorized as safety, human and robot factors as 
follows: warning sign, emergency stop, stability, temperature, 
fail-safe, range of motion, fatigue, contact pressure, motion 
intention, misalignment, power, weight, operation type, 
closed-loop system, and etc. 
 
1
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

TABLE I.  
SUMMARY OF MAIN FACTOR REFERRING TO HUMAN, 
ROBOT AND SAFETY ON WEARABLE ROBOT. 
Author and 
year 
Main factor 
Safety 
Human 
Robot 
Chan 
and 
Courtney, 2001 
Warning sign 
Emergency stop 
 
 
Copaci et al., 
2017 
 
Joint angle 
Range of motion 
Actuator 
Degree of freedom 
Torque 
d’Elia 
et 
al., 
2017 
Stability 
Kinematic 
coupling 
Segment length 
Locomotion 
Mechanical power 
de Looze et al., 
2016 
 
Muscle load 
Musculoskeletal 
disorder 
Operation 
type(active/passive)  
De Santis et al., 
2008 
Control 
architecture 
Injury 
Damage 
Actuation 
Weight 
Sensor 
ISO 13482:2014 
Sharp edge 
Vibration 
Surface 
temperature 
Fail safe 
Musculoskeletal 
disorder 
Fatigue 
Battery 
Power down 
Lenzi 
et 
al., 
2011 
 
Contact pressure 
Comfort 
Interaction force 
and torque 
Motion intention 
Tactile sensor 
Lenzi 
et 
al., 
2012 
 
Movement 
intention 
Muscle activity 
Muscle torque 
Movement 
accuracy 
Nguyen 
and 
Sankai, 2013 
 
Strain of contact 
part 
Interaction force 
Contact part 
Nimawat 
and 
Jailiya 2015 
System 
architecture 
Hyper flex human 
joint 
User interface 
Misalignment 
Tissue load 
Tolerance of 
pressure 
Size 
weight 
Sensor 
Actuator 
Energy storage 
Long 
et 
al., 
2006 
 
Misalignment 
Discomfort 
Closed-loop system 
Proximal elastic 
module 
Schiele et al., 
2006 
 
Degree of 
freedom 
Misalignment 
Optimal design 
 
IV. 
DISCUSSION 
Based on these results, this study suggested three 
grouped ergonomic HRI factors including the safety for 
human-robot interaction, the usability for human, and the 
mechanical specification to ensure the human safety. A 
factor of HRI on wearable robot are suggested to the safety 
and usability evaluation system by developing ergonomic 
design specifications of wearable robots. This study is based 
on content literature review techniques that briefly reviews 
abstracts, key contents and passages. It means that the results 
of this study do not represent a detailed review of literature, 
or the impact of their findings. 
ACKNOWLEDGEMENT 
This study was supported by Basic Science Research 
Program through the National Research Foundation of 
Korea(NRF) funded by the Ministry of Education(NRF-
2017R1D1A3B03035407). 
REFERENCES 
[1] R. Alami et al., “Safe and dependable physical human-robot 
interaction in anthropic domains: State of the art and 
challenges”, in Proceedings of the Intelligent Robots and 
Systems, 2006 IEEE/RSJ International Conference, DOI: 
10.1109/IROS.2006.6936985, 2006. 
[2] J. L. Pons, Wearable robots: biomechatronic exoskeletons, 
UK: John Wiley & Sons, 2008. 
[3] C. Viviani et al., “Accuracy, precision and reliability in 
anthropometric survey for ergonomics purposes in adult 
working populations: A literature review”, Int J Ind Ergon, 
Vol. 65, pp. 1-16, 2018. 
[4] A. H. S. Chan and A. J. Courtney, “Safety and ergonomics 
evaluation of hybrid systems in Hong”, Accid Anal Prev, Vol. 
33, pp. 563-565, 2001. 
[5] D. Copaci, E. Cano, L. Moreno and D. Blanco, “New Design 
of a Soft Robotics Wearable Elbow Exoskeleton Based on 
Shape Memory Alloy Wire Actuators”, Appl Bionics 
Biomech, DOI: 10.1155/2017/1605101, 2017. 
[6] N. d’Elia et al., “Physical human-robot interaction of an 
active pelvis orthosis: Toward ergonomic assessment of 
wearable robots”, J Neuroeng Rehabil, Vol. 14:29, 2017. 
[7] M. P. de Looze, T. Bosch, F. Krause, K. S. Stadler and L. W. 
O’Sullivan, “Exoskeletons for industrial application and their 
potential effects on physical work load”, Ergonomics, Vol. 59, 
pp. 671–681, 2016. 
[8] A. De Santis, B. Siciliano, A. De Luca and A. Bicchi, “An 
atlas of physical human-robot interaction”, Mech Mach 
Theory, Vol. 43, pp. 259-270, 2008. 
[9] ISO 13482:2014, Robots and robotic devices – safety 
requirements for personal care robots, 2014. 
[10] T. Lenzi et al., “Measuring human–robot interaction on 
wearable robots: A distributed approach”, Mechatronics, Vol. 
21, pp. 1123–1131, 2011. 
[11] T. Lenzi, S. M. M. De Rossi, N. Vitiello and M. C. Carrozza, 
“Intention-based EMG control for powered exoskeletons”, 
IEEE Trans Biomed Eng, Vol. 59, pp. 2180-2190, 2012. 
[12] M. T. Nguyen and Y. Sankai, “Measurement method of 
interaction force between human and wearable assistive robot 
based on strain of contact part” Proceedings of the SICE 
Annual Conference, pp. 401-406, 2018. 
[13] D. Nimawat and P. R. S. Jailiya, “Requirement of wearable 
robots in Current scenario”, Euro J Adv Engg, Vol. 2, pp. 19–
23, 2015. 
[14] Y. Long, Z. Du, C. Chen, W. Wang and W. Dong, 
“Development of a lower extremity wearable exoskeleton 
with 
double 
compact 
elastic 
module: 
Preliminary 
experiments”, Mech Sci, Vol. 8, pp. 249-258, 2017. 
[15] T. Schiele and F. C. T. van der Helm, “Kinematic design to 
Improve ergonomics in human machine interaction”, IEEE 
Trans Neural Syst Rehabil Eng, Vol. 14, pp. 456-469, 2006.
 
 
2
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

A Single Wearable IMU-based Human Hand Activity Recognition  
via Deep Autoencoder and Recurrent Neural Networks 
 
P. Rivera Lopez1, E. Valarezo Añazco1,2, S. M. Lee1, K. M. Byun1, M. H. Cho1, S. Y. Lee1, and T.-S. Kim1*  
1Department of Biomedical Engineering 
Kyung Hee University  
Yongin, Republic of Korea  
2Faculty of Engineering in Electricity and Computation, FIEC 
Escuela Superior Politécnica del Litoral, ESPOL 
Guayaquil, Ecuador 
email: {patoalejor, edgivala, sangmlee, kmbyun, mhcho, sylee01}@khu.ac.kr 
*Corresponding author email: tskim@khu.ac.kr  
 
Abstract— Human Hand Activity Recognition (HAR) using 
wearable sensors can be utilized in various practical 
applications such as lifelogging, human-computer interaction, 
and gesture interfaces. Especially with the latest deep learning 
approaches, the feasibility of HAR in practice gets more 
promising. In this paper, we present a HAR system based on 
deep Autoencoder for denoising and deep Recurrent Neural 
Network (RNN) for classification. The proposed HAR system 
achieves a mean accuracy of 79.38% for seven complex hand 
activities, while only of 72.65% without the autoencoder. The 
presented combination of autoencoder and RNN could be 
useful for much improved human activity recognition. 
Keywords- Human Hand Activity Recognition; Autoencoder; 
Deep Learning; RNN; CNN. 
I. 
 INTRODUCTION 
Human Hand Activity Recognition (HAR) is an essential 
technology in many user-centric applications such as human-
computer interactions, assisted living, smart homes, and 
lifelogging [1]. In general, there are two ways for HAR: 
using imaging sensors or inertial sensors that capture human 
activities [2]. Wearable devices are generally equipped with 
inertial sensors such as accelerometer, gyroscope, and 
magnetometer, which have proven useful for HAR. There 
have been many studies recognizing Activities of Daily 
Living (ADL) with these wearable devices [1]-[10]. Besides, 
various classifiers have been employed such as Hidden 
Markov Models (HMM), Support Vector Machine (SVM), 
and Restricted Boltzmann Machines (RBMs) [3], [4], [5]. 
Recently, data-driven approaches using deep learning for 
HAR have led to a significant recognition improvement by  
self-learning without the need of handcrafting features [6], 
[7]. Approaches based on Convolutional Neural Networks 
(CNN) demonstrate the advantages of using convolutional 
filters to capture local dependencies and scale invariance 
features. Previous works, such as [8] and [9] applied CNN to 
extract features from multi-channel sensor data and 
recognized locomotion activities such as walking, sitting, 
walking upstairs, and walking downstairs.  
Recently, there is a growing interest in hand activity 
recognition [10], due to the widespread use and availability 
of wristbands and smartwatches. In the work [11], CNN was 
utilized to recognize multiple daily life hand activities from 
multiple sensors signals. Approaches in [12] and [13] used 
Recurrent Neural Networks (RNN) to recognize locomotion 
and hand gestures using multiple Inertial Measurement Units 
(IMU) on the wrist and body parts. The work in [14] 
presented improvements in a multi-sensor based HAR 
combining CNN and RNN. 
Although these previous studies accomplished some 
success recognizing hand activities, because of the delicate 
movements of hands and sensor noise, some additional 
preprocessing is needed to improve the recognition rate. One 
latest study in [15] examined different motion artifacts in 
constrained and free-mode motion sensor networks and 
demonstrated the effect of alleviating noise motion artifacts 
in HAR performance.   
In this work, we present a HAR system for daily hand 
activities consisting of a deep autoencoder for denoising and 
a deep RNN for classification. As reducing signal noise and 
improving signal representations can be dealt with a deep 
autoencoder 
[16], 
we 
have 
designed 
a supervised 
autoencoder for denoising and better signal representation. 
Then, a classifier based on RNN recognizes daily hand 
activities using only the signals from a single IMU on one 
dominant wrist. Our results show a significant improvement 
in recognizing complex hand activities. 
The rest of this paper is organized as follows. Section II 
describes the proposed methodology. In Section III, the 
experimental results of HAR are presented. Finally, the 
conclusion is given.  
II. 
METHODS 
Our proposed hand activity recognition system is shown in 
Figure 1. The input signal is composed of thirteen feature 
channels collected from a single IMU sensor at the right 
wrist of subjects. The Autoencoder (AE) module processes 
this input signal and transfers to the RNN classifier for hand 
activity recognition. 
A. Hand Activity Database 
In this study, we utilized the Opportunity public database 
[17], which contains continuous time-series data of various 
human hand activities. The database includes the recordings 
from four subjects: each subject performed an unscripted 
session of hand movements and ADL without constraints. 
3
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

 
Figure 1. Proposed HAR system for hand activity recognition. From the left, signals coming from a single IMU go through our autoencoder 
module. Autoencoder reconstructs the data and transfer to RNN classifier. Classifier predicts activity class probabilities.  
Each session was performed five times with different 
numbers of repetition for the activities. Additional hand 
activities were collected in an extra control (Drill) sessions, 
where each subject performed twenty scripted sequences of 
hand activities. We followed the Opportunity multi-modal 
gesture challenge guidelines in [17] to split the data into 
train and test datasets. We focus on data collected from a 
sensor placed on the right wrist of a custom jacket, which 
was worn by the subjects. This sensor included a 
commercial RS458-networked XSense IMU composed of a 
three-axis accelerometer, a three-axis gyroscope, a three–
axis magnetometer, and four-channel quaternion orientation 
information. 
From the total of hand gesture classes in the database, we 
selected thirteen activities of our interest. The activities that 
involve similar executions are grouped as the same class. 
Resultant seven classes of hand activities are Close Door 
(Close Door 1 and Close Door 2), Open Door (Open Door 1 
and Open Door 2), Close Fridge, Open Fridge, Open Drawer 
(Open Drawer 1, Open Drawer 2, and Open Drawer 3), 
Close Drawer (Close Drawer 1, Close Drawer 2, and Close 
Drawer 3), and Drink from Cup. 
Using a sliding window approach, the IMU signals were 
segmented with a window size of four seconds and an 
overlap of 50%. The data were normalized to a range of [-1, 
+1] with zero mean, which we denote them as epochs. Each 
epoch is tagged with a specific class label. We named these 
datasets of epochs as the IMU-train and IMU-test datasets 
respectively.  
To train our supervised autoencoder, we modeled the 
previous datasets using an Autoregressive Moving Average 
(ARMA) model and named them as the ARMA-train and 
ARMA-test datasets. Training the AE used these ARMA 
datasets as the ideal targets of the reconstructed and 
denoised signals. Finally, the AE reconstructed outputs are 
named as the AE-train and AE-test datasets. The classifier 
uses these datasets for performance analysis of recognition.  
B. Proposed Autoencoder 
In this section, the proposed AE and RNN classifier are 
presented.  
B1. Autoencoder Model 
The encoder 𝑓(𝑥) in our AE architecture is a combination of 
a CNN layer and a Bidirectional RNN (BRNN). A 
convolution layer extracts features from the input signal 
through a one-dimensional filter. These features capture 
local correlations hidden in the data and form an augmented 
representation in a set of multiple feature maps [14]. We use 
the hyperbolic tangent function as a non-linear activation 
function for the output of the convolution. The RNN layers 
process sequential data, taking advantage of parameter 
sharing, making possible each unit in the output be a 
function of the previous units. BRNN takes the output from 
CNN and uses it in two parallel layers: forward and 
backward loops used for exploding context from the past 
and future of a specific time step. The BRNN units are 
based on Long Short Term Memory (LSTM) cells, which 
use a concept of gates that define the behavior of the 
memory cell. The input 𝑥𝑡
  is fed into different gates such as 
the forget gate 𝑓𝑡 , input gate 𝑖𝑡, and output gate 𝑜𝑡  with the 
previous cell output ℎ𝑡−1 to compute the current output. In 
the following equations, we describe the LSTM unit where 
𝜎 represents a non-linear function and [𝑊, 𝑏] are the weight 
matrices and bias vector associated with each gate.  
 
 
𝑓𝑡 = 𝜎(𝑊𝑓 ∙ [ℎ𝑡−1,𝑥𝑡] + 𝑏𝑓) 
(1) 
𝑖𝑡 = 𝜎(𝑊𝑖 ∙ [ℎ𝑡−1,𝑥𝑡 ] + 𝑏𝑖) 
(2) 
𝐶𝑡̃ = tanh(𝑊𝑐 ∙ [ℎ𝑡−1,𝑥𝑡] + 𝑏𝑐) 
(3) 
𝐶𝑡 = 𝑓𝑡 ∗ 𝐶𝑡−1+ 𝑖𝑡 ∗ 𝐶𝑡̃  
(4) 
𝑜𝑡 = 𝜎(𝑊𝑜 ∙ [ℎ𝑡−1,𝑥𝑡 ]+ 𝑏𝑜) 
(5) 
ℎ𝑡 = 𝑜𝑡 ∗ tanh(𝐶𝑡) 
(6) 
 
 
From the encoder hidden representation ℎ, the decoder 
𝑔(ℎ) reconstructs the signals by two stacked convolutional 
layers. The last decoder convolution layer has its feature 
map size constrained to the same size of the input channels.  
B2. ARMA Modeling of IMU Activity Signals 
Before training the supervised AE, the ideal target dataset is 
obtained by modeling the original IMU datasets via ARMA. 
The Akaike information criterion was used to select an 
appropriate order for the autoregressive and moving average 
models. For each channel, an optimized model was carefully 
chosen from a pool of different combination of orders: in 
most cases, the autoregressive model order of 3 and moving 
4
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

average of 4 were selected. The ARMA-train and ARMA-
test 
datasets 
represent 
a 
denoised 
and 
improved 
representation of the signals in the IMU-train and IMU-test 
datasets. In Figure 2, one set of epoch instances from the 
IMU-test and ARMA-test datasets is shown. 
B3. Training and Testing Autoencoder 
The input to the AE was carried by mini-batches composed 
of epochs in the IMU-train dataset and target ARMA-train 
dataset. The AE used the Mean Square Error (MSE) as a 
loss function. The training algorithm iterated up to 100 
training steps with a learning rate of 1e-4. Gradient decedent 
recursively updated the network parameters using Adam 
optimizer algorithm. Weights initialization used a random 
Gaussian distribution with a mean of zero and standard 
deviation of 0.5. To validate the AE performance, we 
quantified the similarity between the AE-test and ARMA-
test datasets. This similarity is based on the overall Root 
Mean Square Error (RMSE) and Pearson Correlation 
Coefficient (R) for each corresponding channel from both 
datasets.  
C. RNN Classifier 
The classifier module is composed of three RNN layers 
based on Gate Recurrent Unit (GRU) memory cells. The 
GRU cell possesses a reset gate 𝑟 and an update gate 𝑧, 
unlike the LSTM variant it does not have an internal 
memory 𝑐𝑡 and an output gate 𝑜𝑡 . The GRU cell combines 
the input gate 𝑖𝑡 and forget gate 𝑓𝑡 in the update gate, and 
directly apply the reset gate to the previously hidden state. 
We describe the GRU gates in the following equations: 
 
 
𝑧𝑡 = 𝜎(𝑊𝑧 ∙ [ℎ𝑡−1,𝑥𝑡]) 
(7) 
𝑟𝑡 = 𝜎(𝑊𝑟 ∙ [ℎ𝑡−1,𝑥𝑡]) 
(8) 
ℎ̃𝑡 = 𝑡𝑎𝑛ℎ(𝑊[𝑟𝑡 ∗ ℎ𝑡−1,𝑥𝑡]) 
(9) 
ℎ𝑡 = (1 − 𝑧𝑡) ∗ ℎ𝑡−1 + 𝑧𝑡 ∗ ℎ̃𝑡 
(10) 
 
 
The output from last RNN layer is connected to a dense 
layer to obtain the class probabilities. Despite the 
compelling representation from RGRU, there is still a 
possibility of overfitting. We address this using a dropout 
technique for optimization with a value of 0.4 before the 
dense layer. The final layer produces the class probabilities 
from a Softmax function. Initialization of the weights uses a 
random Gaussian distribution with of mean zero and 
standard deviation of 0.5. The network is trained over 50 
training steps with a learning rate of 3e-4 with an 
optimization based on Adam algorithm. We compute the 
weighted F1-score and accuracy of classification for the 
given test datasets. 
III. 
EXPERIMENTAL RESULTS 
A. Validation of Autoencoder 
We computed the RMSE and R coefficient between the 
ARMA-test and AE-test datasets to evaluate the performance 
of AE. Table 1 shows a summary of these values. The 
signals in Figure 3 illustrate an exemplary epoch of “Open 
Door” activity from both datasets.  
 
 
Figure 3. Time series from the 3-axis gyroscope in the “Open Door” 
activity: ARMA (solid) and AE (dotted). 
TABLE 1. THE COMPUTED RMSE AND R-VALUES BETWEEN ARMA-
MODELED AND AE OUTPUT DATASETS. 
Channels 
Axis 
RMSE 
R 
Accelerometer 
X 
0.0441 
0.9387 
Y 
0.0383 
0.9805 
Z 
0.0359 
0.9953 
Gyroscope 
X 
0.0262 
0.9652 
Y 
0.0251 
0.9820 
Z 
0.0234 
0.9872 
Magnetometer 
X 
0.0130 
0.9799 
Y 
0.0111 
0.9892 
Z 
0.0122 
0.9927 
Quaternion 
Q1 
0.0328 
0.9873 
Q2 
0.0361 
0.9914 
Q3 
0.0340 
0.9870 
Q4 
0.0345 
0.9976 
 
 
Figure 2. Time series from the 3-axis accelerometer in the “Open 
Door” activity: IMU (solid) and ARMA (dotted).  
5
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

A1. Classification Performance 
The summary of the recall values achieved by the classifier 
on the IMU-test, ARMA-test, and AE-test datasets are 
shown in Table 2. Using the raw sensor signals in the IMU-
test dataset, the classifier achieved a mean F1-score of 
72.87% and accuracy of 72.65%. 
The recognition 
performance is not quite satisfactory for these complex hand 
activities. Using the ARMA-test dataset (i.e., modeled ideal 
dataset), recognition increased to a mean F1-score of 
82.40% and accuracy of 82.14%. For activities such as 
“Open Fridge” and “Open Drawer,” their recall values 
increased up to 78.33% and 81.55% respectively from 
around 60%. Finally, using the AE-test dataset (i.e., the 
output of AE), the classifier achieved a mean F1-score of 
79.64% and accuracy of 79.38%, reflecting a 6.75% 
improvement over the raw signals from the IMU-test dataset 
and similar to the performance of the ARMA-test dataset. 
 
A2. Comparison of Related Works  
In this work, we have implemented a HAR system of deep 
denoising AE and RNN classifier, through which the 
improved representation of activity signals are utilized to 
recognize seven daily hand activities using only a single 
IMU sensor. 
There are rare works of HAR systems utilizing denosing 
AE. The HAR work in [15] used an unsupervised 
Variational Autoencoder (VAE) in combination of CNN 
with LSTM. It shown that using 75 sensor channels that 
presented significative motion artifacts from Opportunity 
the denoised signals could improve the accuracy from 
72.96% to 90.81%. Also there have been HAR works 
utilzing multiple sensors (i.e., >70 sensor channels) to 
improve the performance. These studies reported F1-score 
of 75.4% [12], a recall value of 83.5% [13] , and F1-score of 
86.6% [14] without the use of AE. In contrast with those 
studies, our architecture receive an input data compose of 13 
feature channels extracted from only one IMU sensor, which 
is more practical for an end- user application. 
IV. 
CONCLUSION 
In this work, we have presented a HAR system for daily 
human hand activities combining a denoising autoencoder 
and RNN for classification. Our results prove that AE helps 
the deep classifier and eventually HAR by reducing noises 
and representing signals better. The promising results 
demonstrate the effectiveness of this approach, which could 
be used for other HAR systems. 
ACKNOWLEDGMENT 
This work was supported by the National Research 
Foundation of Korea (NRF) grant funded by the Korea 
government (MSIP; Ministry of Science, ICT & Future 
Planning) 
(No. 
NRF-2017M3A9E2062707), 
and 
by 
International Collaborative Research and Development 
Program funded by the Ministry of Trade, Industry and 
Energy (MOTIE, Korea) (N0002252).  
REFERENCES 
 
[1] 
A. Bulling, U. Blanke, and B. Schiele, “A Tutorial on 
Human Activity Recognition Using Body-worn Inertial 
Sensors,” ACM Comput. Surv., vol. 46, no. 3, p. 33:1--
33:33, Jan. 2014. 
[2] 
A. M. Khan, Y.-K. Lee, S. Y. Lee, and T.-S. Kim, “A 
Triaxial 
Accelerometer-based 
Physical-activity 
Recognition via Augmented-signal Features and a 
Hierarchical Recognizer,” Trans. Info. Tech. Biomed., vol. 
14, no. 5, pp. 1166–1172, Sep. 2010. 
[3] 
E. Garcia-Ceja, R. F. Brena, J. C. Carrasco-Jimenez, and 
L. Garrido, “Long-Term Activity Recognition from 
Wristwatch Accelerometer Data,” Sensors, vol. 14, no. 
12, pp. 22500–22524, 2014. 
[4] 
S. Bhattacharya and N. D. Lane, “From smart to deep: 
Robust activity recognition on smartwatches using deep 
learning,” in 2016 IEEE International Conference on 
Pervasive Computing and Communication Workshops 
(PerCom Workshops), 2016, pp. 1–6. 
[5] 
H. P. Gupta, H. S. Chudgar, S. Mukherjee, T. Dutta, and 
K. Sharma, “A Continuous Hand Gestures Recognition 
Technique 
for 
Human-Machine 
Interaction 
Using 
Accelerometer and Gyroscope Sensors,” IEEE Sens. J., 
vol. 16, no. 16, pp. 6425–6432, Aug. 2016. 
[6] 
M. Zeng et al., “Convolutional Neural Networks for 
human activity recognition using mobile sensors,” in 6th 
International 
Conference 
on 
Mobile 
Computing, 
Applications and Services, 2014, pp. 197–205. 
[7] 
J. Wang, Y. Chen, S. Hao, X. Peng, and L. Hu, “Deep 
learning for sensor-based activity recognition: A Survey,” 
Pattern Recognit. Lett., 2018. 
[8] 
Y. Zheng, Q. Liu, E. Chen, Y. Ge, and J. L. Zhao, 
“Exploiting multi-channels deep convolutional neural 
networks for multivariate time series classification,” 
Front. Comput. Sci., vol. 10, no. 1, pp. 96–112, Feb. 2016. 
[9] 
H. Gjoreski, J. Bizjak, M. Gjoreski, and M. Gams, 
“Comparing Deep and Classical Machine Learning 
Methods for Human Activity Recognition using Wrist 
Accelerometer,” 2016. 
[10] 
Choudhary, Santosh, and N. Choudhary, “Towards 
Developing an Effective Hand Gesture Recognition 
TABLE 2. SUMMARY OF CLASSIFICATION PERFORMANCE FOR THE 
IMU-TEST, ARMA-TEST, AND AE-TEST DATASETS WITH THE 
PROPOSED CLASSIFIER. 
Hand Activity 
Recognition 
Performance on Test Datasets (%) 
Activity 
Raw 
IMU 
ARMA 
AE 
Gestures 
OD 
83.89 
88.33 
91.67 
CD 
85.80 
88.27 
86.42 
OF 
61.00 
78.33 
73.00 
CF 
63.89 
70.83 
68.75 
DC 
84.08 
89.20 
87.44 
ODW 
60.71 
81.55 
69.64 
CDW 
57.58 
66.67 
68.18 
Mean 
F1-score 
72.87 
82.40 
79.64 
Accuracy 
72.65 
82.14 
79.38 
*OD: Open Door, CD: Close Door, OF: Open Fridge, CF: Close 
Fridge, DC: Drink from Cup, ODW: Open Drawer, CDW: Close 
Drawer  
 
6
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

System for Human Computer Interaction: A Literature 
Survey.,” Glob. J. Comput. Sci. Technol., 2016. 
[11] 
J. B. Yang, M. N. Nguyen, P. P. San, X. L. Li, and S. 
Krishnaswamy, “Deep Convolutional Neural Networks on 
Multichannel 
Time 
Series 
for 
Human 
Activity 
Recognition,” in Proceedings of the 24th International 
Conference on Artificial Intelligence, 2015, pp. 3995–
4001. 
[12] 
N. Y. Hammerla, S. Halloran, and T. Plötz, “Deep, 
Convolutional, and Recurrent Models for Human Activity 
Recognition Using Wearables,” in Proceedings of the 
Twenty-Fifth International Joint Conference on Artificial 
Intelligence, 2016, pp. 1533–1540. 
[13] 
A. Murad and J.-Y. Pyun, “Deep Recurrent Neural 
Networks for Human Activity Recognition,” Sensors, vol. 
17, no. 11, 2017. 
[14] 
F. J. Ordóñez and D. Roggen, “Deep Convolutional and 
LSTM Recurrent Neural Networks for Multimodal 
Wearable Activity Recognition,” Sensors, vol. 16, no. 1, 
p. 115, 2016. 
[15] 
S. Mohammed and I. Tashev, “Unsupervised deep 
representation learning to remove motion artifacts in free-
mode body sensor networks,” in 2017 IEEE 14th 
International Conference on Wearable and Implantable 
Body Sensor Networks (BSN), 2017, pp. 183–188. 
[16] 
S. Rifai, P. Vincent, X. Muller, X. Glorot, and Y. Bengio, 
“Contractive Auto-encoders: Explicit Invariance During 
Feature Extraction,” 
in Proceedings of 
the 28th 
International Conference on International Conference on 
Machine Learning, 2011, pp. 833–840. 
[17] 
R. Chavarriaga et al., “The Opportunity challenge: A 
benchmark database for on-body sensor-based activity 
recognition,” Pattern Recognit. Lett., vol. 34, no. 15, pp. 
2033–2042, 2013. 
 
7
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

A Review of Wearable Tracking and Emotional Monitoring Solutions for 
Individuals with Autism and Intellectual Disability
Mohammed Taj-Eldin, Brendan O’Flynn, Paul Galvin 
Tyndall National Institute 
University College Cork 
Cork, Ireland 
email: {mohammed.tajeldin, brendan.oflynn, 
paul.galvin}@tyndall.ie 
Christian Ryan 
School of Applied Psychology 
University College Cork 
Cork, Ireland 
e-mail: christian.ryan@ucc.ie
 
 
Abstract—Autism Spectrum Disorder (ASD) and Intellectual 
Disabilities (ID) affect an increasing proportion of today’s 
population. Individuals with ASD/ID exhibit frequent forms of 
challenging behaviours such aggression and wandering off 
without warning. Wandering or elopement is common among 
such population and poses a great risk to the individuals and 
causes significant stress to their caregivers. Concurrent with 
wandering is sometimes anxiety and stress which may lead to 
disruptive challenging behaviours emerging from their varying 
internal 
emotional 
states 
and 
hyper-sensory 
to 
their 
surroundings. Caregivers and/or family members do need to 
keep track of such vulnerable population especially the ones 
with more severe autism/intellectual disabilities. The use of 
location tracking and emotional monitoring solutions can assist 
caregivers and family members by complementing their 
behavioural monitoring and intervention approaches. This 
paper reviews existing location tracking and physiological 
monitoring wearable products suited for this population. This 
can help caregivers and family members select suitable device 
for the person of concern taking account his/her unique user 
needs.  
Keywords-autism; 
assistive 
technology, 
emotional 
monitoring, intellectual disabilities, patient localisation, wearable 
sensors. 
I. 
 INTRODUCTION 
Autism 
Spectrum 
Disorder 
(ASD) 
is 
a 
neurodevelopmental condition characterised by deficits in 
reciprocal social interactions and communication skills, 
accompanied by restrictive and repetitive behaviours. 
Intellectual disability (ID), on the other hand, can be 
characterised by deficits in intelligence and adaptive 
behaviour that is at least two standard deviations below the 
mean of the general population. Individuals with ASD/ID 
exhibit frequent forms of challenging behaviours that reduce 
their well-being and quality of life. Individuals with ASD are 
at higher risk of developing challenging behaviours 
compared to the general population [1].  
One common kind of challenging behaviours is wandering 
and elopement. A recent research study reported that about 
half of children with autism spectrum disorder are prone to 
wandering [2] which can be very stressful for parents, 
particularly so for parents caring for children with 
developmental disorders, where the child’s ability to 
communicate with strangers may be impaired.  Also, it has 
been found that more than a quarter of children with 
developmental 
disabilities 
wander 
away 
from 
safe 
environments [3]. Further, researchers found that nearly a 
third of reported ASD missing person cases related to 
wandering/elopement from 2011 to 2016 in the United States 
ended in death or required medical attention [4]. 
Therefore, a mechanism that allowed parents and carers to 
track the locations of those individuals could have significant 
benefits and reduce risk. Secondly, such a device could 
potentially be used to monitor physiological signals which 
may correlate with internal emotional states, such as high 
levels of stress. This data may predict episodes of 
wandering/elopement, and could be used to ensure the 
intervention to reduce stress, or to identify their location in 
case being lost.  
Since external challenging behaviour such as wandering is 
accompanied with anxiety issues and varying emotions, it 
will be very useful for caregivers to monitor the internal 
physiological and emotional states of the care-receiver to 
help them understand what such individuals are experiencing 
in a real-time fashion. Building on such physiological 
information, caregiver can take necessary actions to help the 
individual calm down, in case he/she is experiencing stress, 
for example. Also, having a wearable device may help some 
individuals with autism spectrum disorder to increase their 
self-awareness of their internal emotional state and anxiety 
levels so that they can follow certain behavioural techniques 
and coping strategies to help them self-regulate their 
emotions [5]. This could be particularly useful for clients 
with comorbid alexithymia. 
This paper reviews commercial devices that can track 
location and physiological signals, with the potential for 
application to individuals with ASD/ID. Specifically, it 
presents the existing commercial solutions, compares their 
features and associated sensors, and comments on their 
effectiveness and open challenges for this application.  
II. 
ASD/ID AND THEIR UNIQUE NEEDS 
      ASD and ID are a broad spectrum of disorders ranging 
from mild to profound intellectual disabilities. Individuals 
with these conditions experience a full range of emotional 
states, which can be triggered by a variety of environmental 
and sensory cues, and internal experiences. For example, 
escalated levels of anxiety can potentially lead to what is 
called Challenging Behaviour. Challenging behaviour is 
defined as a culturally abnormal behaviour(s) of such an 
8
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

intensity, frequency or duration that the physical safety of the 
person or others is likely to be placed in serious jeopardy [6]. 
Challenging 
behaviour 
include 
wandering/elopement, 
aggression, self-injury, property destruction, and tantrums. 
Prevalence rates as high as 94% have been reported for 
challenging behaviour in children with ASD [7]. Therefore, 
those individuals have unique needs. The widespread use of 
wearable technology offers an opportunity to help caregivers 
monitor and support such individuals. The use of wearable 
devices embedding sensing modalities such as location 
tracking and physiological sensing can offer a promising 
support for children and adults with ASD/ID who engage in 
challenging behaviour [5]. 
III. 
RELATED WORK 
      A number of reviews of relevant literature have been 
published. For example, S. Majumder et al [8] conducted a 
review study on sensors used for remote monitoring for 
general 
population. 
The 
authors 
compared 
various 
physiological and activity monitoring solutions aimed for the 
elderly population. Specifically, separate comparative studies 
for wearable monitoring devices of cardiovascular system, 
body temperature, oxygen level parameters, and activity 
trackers were presented.  Another work focused on the 
wearable technology from clinical perspective such as 
wellness, safety, and home rehabilitation for older adults and 
individuals with chronic conditions was conducted by S. 
Patel et al [9].  
      More recently, there has been a focus of reviews on the 
application of wearable technology to specific populations 
which bring unique design and function needs. This is 
because some populations have different design and 
wearability requirements [5].  Example of such users are the 
ASD/ID population. According to a survey conducted by S. 
H. Koo et al [5], parents of individuals with ASD were 
particularly interested in being able to monitor their son or 
daughter’s physiological signals to understand anxiety levels 
and other emotions (72%). J. Cabibihan et al [10] surveyed 
the research literatures on different sensing technologies that 
are suitable for screening and intervention for ASD. Those 
sensing technologies were categorised into eye trackers, 
movement trackers, physiological activity monitors, tactile 
sensors, vocal prosody and speech detectors, and sleep 
quality assessment devices. The benefits and effectiveness of 
those devices in supporting the treatment of some symptoms 
of autistic individuals as well as their limitations were 
assessed. 
      According to S. H. Koo et al [5], tracking the 
individual’s activity or location is the third most requested 
information by parents of individuals with ASD after the 
emotional state and aiding of multi-step tasks. Also, M. T. 
K. Tsun et al conducted a review study on tracking devices 
in ASD population [11]. The authors investigated potential 
future assistive tracking solutions for children with 
cognitive disabilities. Various localisation techniques have 
been considered such as radio frequency, inertial 
measurement units, and Global Positioning System which 
can be utilised for indoor and outdoor localisation. 
      As it can be seen, existing review papers either: study 
wearable devices for general or elderly population [8], [9] 
focuses on the research prototypes designed for individuals 
with ASD or ID [10], or target the devices offering one 
functionality such as the work by M. T. K. Tsun et al [11]. 
To the author’s best knowledge, no consideration has been 
given to commercial solutions that enable emotional 
monitoring as well as location tracking devices. This paper 
focuses on devices that offer those two functions.  
IV. 
TECHNOLOGIES AND SENSING SIGNALS USED  
Building on the urgent need found in previous section, this 
section discusses the technologies and sensors used in the 
following subsections. 
A. Location Tracking Technologies 
Location tracking solutions use different technologies 
based on the required distance and the environment. For 
example, indoor monitoring devices can use accelerometer 
sensors, infrared tags, Bluetooth or WiFi wireless network 
available inside the building, or use a combination of 
technologies for more accurate tracking. Solutions targeted 
for outdoor location monitoring mostly use Global 
Positioning System (GPS) or cellular network service (such 
as GSM or third generation mobile communications).  
B. Physiological Sensing Technologies for Emotional 
Monitoring  
Emotional assessment for individuals with autism 
spectrum disorder and intellectual disabilities can provide 
insights into the function of the challenging behaviour and 
supplement costly traditional observational approaches. 
Physiological monitoring is found useful to assess the 
varying emotional levels as it can be measured noninvasively 
[12]. Typical physiological signals used include: Heart Rate 
(HR), Heart Rate Variability (HRV), Cortisol Level, 
Respiration Rate (RR), Electrodermal Activity (EDA), Skin 
Temperature (ST), and Electromyography (EMG). Other 
potential technologies may be useful to apply, such as eye 
tracking, using ElectroEncephaloGram (EEG) or brain 
signals but, due to the intrusive nature of the devices 
required for the individual with ASD/ID, they will be 
excluded in this study. It should be noted that various 
emotional states can be inferred from the measured values 
such as: low mood, high stress levels, agitation, excitement, 
and aggression.  
V. 
REVIEW OF EXISTING TRACKING AND MONITORING 
PRODUCTS 
      While the market is abundant with various products that 
are targeted for tracking and health monitoring of general 
population, there is a set of products that are designed 
specifically for individuals with autism and/or intellectual 
disabilities or can be adopted for this population. In this 
section, we provide a review of existing solutions listed for 
each category. The criteria for selection were: (1) devices 
that are designed specifically for individuals with ASD or 
ID, then (2) devices designed for general population but can 
9
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

be adopted for ASD or ID population in terms of offering the 
functionality that delivers the service. Selected devices are 
consumer electronic device or medically approved ones. If a 
device is clinically validated, it is noted in the tables. 
This section gives an overview of the devices/solutions 
that can be used for monitoring the individuals with ASD/ID. 
Such solutions can be categorised into two groups: (a) 
solutions for tracking the location of the person of concern, 
and (b) solutions for monitoring the internal emotional state 
or physiological state identification. Those solutions will be 
reviewed in the following two subsections:        
A. Location Tracking Solutions 
      TABLE I. lists examples of related products. The 
following products are either commercially available in the 
market or still under development. For instance, Amber 
Alert GPS [13] is a tracking device that can be fitted in the 
backpack of the child or can be worn with a lanyard around
 
TABLE I.      LOCATION TRACKING PRODUCTS  
Product  
Device Type 
Wireless Technology and Range 
Amber Alert GPS [13] 
wristband 
GPS for outdoor tracking 
Angle Sense Location Tracker [14] 
Wristband  
Indoor tracking using Wi-Fi 
Pocket Finder [15] 
Attachable device 
GPS/AGPS, 3G Cell ID for outdoor location and 
Wi-Fi Touch for indoor locations 
Trax GPS Tracker [16] 
Attachable device with clips 
Location tracking using GPS, Beidou, and QZSS 
Securus eZoom [17] 
pocket-sized device 
GPS for outdoor tracking 
SPOT 3 Satellite GPS Messenger 
[18] 
pocket-sized device 
GPS for outdoor tracking 
Yepzon One [19] 
pocket-sized device 
GSM network, GPS for outdoor  and Bluetooth 
for near distances  
My Buddy Tag [20] 
Tag on wristband 
Bluetooth for near distances 
Trackimo GPS Track Watch [21] 
Watch 
GPS for outdoor, Wi-Fi for indoor tracking, and 
Bluetooth for short range tracking 
FiLIP Solution [22] 
wristband 
Location tracking using GPS, GSM & WiFi 
BeLuvv Guardian [23] 
Bracelet or necklace 
Bluetooth for near distances 
Polar Team Pro [24] 
T- Shirt 
GPS for outdoor 
D-Shirt [25] 
T- Shirt 
GPS for outdoor, altitude and route 
 
the neck and it uses 3G cellular network to track the 
individual. Also, Angle Sense Location Tracker [26] is a 
GPS device that can be inserted into a sleeve that can be put 
in the pocket or in the interior of the clothing. Another 
device called Trackimo [21], from Trackimo, uses five 
tracking modules: GPS, GPS-A, GSM, Wi-Fi and Bluetooth 
suitable for both indoor and outdoor tracking. Examples of 
other devices that can be attached to the person’s clothing 
are: Pocket Finder [27], Trax GPS Tracker [28], Securus 
eZoom and SPOT 3 Satellite GPS Messenger [18], Yepzon 
One [19], My Buddy Tag [20].  
      A recent acceptability study was conducted using 
questionnaires with individuals with autism spectrum 
disorder and their parents to see what types of devices they 
prefer to use. Accessories such as watches/wristband and 
bracelets have been found to be the most preferred wearable 
technology types [5]. Therefore, several companies have 
developed wristband/watch type devices such as FiLIP [29], 
for example, that can track the location of children both 
indoors and outdoors using GPS, GSM and WiFi with the 
ability to contact the caregiver in case of emergency. 
Another device is BeLuvv Guardian suited for short range 
tracking [23] that uses Bluetooth technology. Another 
product called, Trackimo GPS Track Watch, uses three 
ranges for tracking: GPS for outdoor, Wi-Fi for indoor 
tracking, and Bluetooth for short range tracking. 
      Smart clothing offers a seamless experience and thus 
can be used to track individuals with sensory sensitivities, 
who may not tolerate devices such as wristbands or watches. 
Furthermore, garments, such as t-shirts, have been found the 
second most preferred item for individuals with autism 
spectrum disorder [5]. Therefore, t-shirts and vests equipped 
with location trackers can be used to track those individuals 
by their parents or caregivers. Although most t-shirts with 
location tracking on the market are aimed for athletes, some 
may be adopted for individuals with autism spectrum 
disorder/intellectual disabilities. An example of those is 
Polar Team Pro that offers location and motion tracking 
sensors in addition to heart rate monitor [24]. Another one 
but still under development called D-Shirt by Cityzen 
Sciences which is also planned to measure heart rate, route, 
speed, and altitude [25].  
B. Emotional State Monitoring Solutions  
      The list of examples of physiological and/or emotional 
monitoring devices is presented in TABLE II. Wristbands 
and watches have also been the mainstream wearable device 
technology for physiological monitoring and emotional 
assessment. A brief description of the solutions/products is 
presented in the following paragraphs. 
      Simple consumer devices like Fitbit 2 can collect some 
physiological data such as heart rate. However, there are 
concerns pertaining to the reliability of such devices and 
their lack of capability to provide clinical data [30]. A more 
reliable solution which can provide more comprehensive 
physiological data is E4 Wristband from Empatica, Inc. 
which 
measures 
heart 
rate, 
heart 
rate 
variability, 
electrodermal activity, and skin temperature. However, this 
device can only collect raw physiological signals without 
10
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

providing insights or assessment of the internal emotional 
state. 
 
TABLE II.      PHYSIOLOGICAL AND EMOTIONAL MONITORING PRODUCTS  
Product/Forthcoming 
Device 
Purpose 
Device Form 
Factor 
Sensors/Parameters 
Usefulness/Clinical 
Validation 
Shortcomings 
E4 wristband, 
Empatica Inc. [31] 
Collecting 
physiological and 
movement data 
only 
Wristband 
HR, HRV, EDA, ST, 
Acceleration 
Medical Device 
class 2a (EU), FCC 
CFR 47 Part 15b 
IC (Industry 
Canada) 
- Obtrusive (may not be 
tolerable by individuals 
with severe to profound 
ID) 
TouchPoints wristband 
(Forthcoming), 
TouchPoints, Inc. [32]  
Stress and anxiety 
relief  
 
Wristband 
 Bi-lateral alternating 
stimulation –tactile 
(BLAST) 
Patent-pending 
neuroscientific 
technology to 
relieve stress 
Obtrusive (may not be 
tolerable by individuals 
with severe to profound 
ID) 
MyFeel  wristband,  
Sentio Solutions Inc. 
[33] 
 
Recognising 
emotions 
Wristband 
HR, EDA, Skin temperature 
(ST),  
Preliminary study 
showed usefulness 
on 150 subjects. 
However, no 
clinical validation 
Obtrusive (may not be 
tolerable by individuals 
with severe to profound 
ID) 
Reveal (Forthcoming), 
Awake Labs [34] 
 
Monitoring stress 
and anxiety 
Wristband 
HR, EDA, ST 
Clinical trials being 
conducted but not 
clinically validated 
yet. 
-Initial prototype, not 
validated, only for 
anxiety. 
- May not be suitable by 
individuals with severe to 
profound ID 
BioHarness 3.0, 
Zypher, Inc. [35]  
Physiological and 
activity data 
collection 
Chest strap 
HR, HRV, EDA, body 
temperature, RR, activity, 
posture, location 
Clinical 
HR 
measurements [36] 
but not to clinical 
HRV [37]. 
Obtrusive (may not be 
tolerable by individuals 
with severe to profound 
ID) 
Equivital Sensor Belt 
[38] 
Physiological and 
activity data 
collection 
Chest Belt 
ECG; HR, HRV, Respiratory 
rate (RR),  EDA, ST, 
accelerometer, Body 
position  
EQ02 
can 
accurately measure 
ECG and HRV, its 
accuracy 
and 
precision is highly 
dependent 
on 
artifact content [39]   
 
Obtrusive (may not be 
tolerable by individuals 
with severe to profound 
ID) 
Zephyr belt, 
Medtronic, Inc. [40] 
Sports health 
monitoring 
Belt 
HR, HRV, RR 
Suitable for 
consumer 
electronics but no 
clinical validation 
Obtrusive (may not be 
tolerable by individuals 
with severe to profound 
ID) 
Hexoskin Smart Shirt, 
Hexoskin Inc. [41] 
Physiological and 
activity data 
collection and 
monitoring quality 
of sleep 
Shirt 
HR, HRV, Heart rate 
recovery, Respiration rate 
(RR) and volume, 
Acceleration and power 
Clinical validated to 
obtain precise ECG 
cardiac monitoring 
for long-term 
monitoring [42] 
Does not support real-
time streaming or 
processing, but may be 
suited for monitoring of 
certain individuals with 
ASD/ID who cannot 
tolerate wristband  
Polar Team Pro Shirt, 
Polar Electro Oy [24] 
 
Sports health 
monitoring 
Shirt 
HR, location and motion 
tracking  
Not clinically 
validated 
Could be used for 
individuals with ASD/ID 
who can tolerate wearing 
the shirt 
AIO Sleeve, Komodo 
Technologies [43] 
 
Physiological, 
activity data 
collection and 
monitoring quality 
of sleep 
Sleeve 
ECG, HR, HRV, 
accelerometer 
Not clinically 
validated 
Does not support real-
time 
streaming/processing 
(may be suited for 
monitoring of certain 
individuals with ASD/ID 
who cannot tolerate 
wristband) 
    
      More advanced solutions have been developed that use 
emotional identification algorithms to make meaningful 
information out of such data. For example, MyFeel 
wristband, from Sentio Solutions Inc [33], uses proprietary 
algorithms to process the data where it collects heart rate, 
electrodermal activity and skin temperature. 
 
      Another device that is still under development and 
targeted for the population with autism spectrum disorder 
called Reveal, from Awake Labs [34]. This device collects 
heart rate, electrodermal activity and skin temperature data 
to assess anxiety level of the individual and can notify the 
11
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

caregiver when anxiety levels start to rise by applying data 
analytics techniques to make smart clinical decisions. 
Another more advanced solution called TouchPoints 
wristband and produced by TouchPoints Inc. [32]. This 
solution provides not only emotional monitoring but also 
claims to relieve stress using stimulating electrical pulses 
[44]. Other devices that can be worn include: BioHarness, 
Equivital Sensor Belt, Zepher belt and Hexoskin which is 
clinically validated to provide reliable ECG data. The last 
product listed is called AIO Sleeve, developed by Komodo 
Technologies but it is only a consumer device which does 
not provide clinical grade data.  
Recently, smart clothing is becoming the new trend for 
wearable devices especially for physiological monitoring 
and emotional assessment as it provides a seamless 
experience for the users compared to wristbands which can 
be obtrusive to some users. An example of such solutions is 
Hexoskin Smart Shirt, developed by Hexoskin Inc. [41], 
which incorporates fabric sensors that collect: ECG, heart 
rate, heart rate variability, respiration rate, and body 
movement data.  
The need to collect multiple data (e.g., physiological and 
positioning), based on the listed devices, may require the 
use of multiple devices which can cause inconvenience to 
the user. Thus, it is evident that having one device that can 
collect all relevant data (i.e., physiological, movement, and 
positioning) is more practical solution. EQ02 LifeMonitor, 
from Equivital Inc., offers this capability where it can also 
collect the previous parameters and has additional features 
including body movement and GPS location tracking 
system.  
VI. 
DISCUSSION 
The previous section has reviewed some existing or 
forthcoming products which are either designed for 
individuals with autism/intellectual disabilities or can be 
adopted for this population. 
It can be seen that most solutions provide either tracking 
or emotional monitoring which can be a drawback if they 
lack the other capability.  
As it was seen earlier, individuals with autism spectrum 
disorder /intellectual disabilities can exhibit different kinds 
of challenging behaviours such as wandering and anxiety at 
the same time.  From the reviewed products, it can be 
noticed that most commercial products can only offer one 
type of tracking. However, it would be more useful to 
inform the caregivers of the internal emotional state of the 
individual which may precede wandering so that they can 
take preventative measures to avoid harm for the individual 
or being exposed to unsafe environment. One listed device 
called, EQ02 LifeMonitor, is equipped with sensors that can 
provide the two functionalities. Using such a solution, 
clinicians and caregivers can objectively identify what the 
individuals with ASD/ID are experiencing physiologically, 
which could help in understanding the internal emotional 
state and the contexts and locations in which such behaviour 
is exhibited or escalated levels of anxiety are developed. 
From technical perspective, the target solution can use the 
unlicensed Bluetooth Low-Energy Protocol to transmit the 
physiological and positioning data to a remote recipient 
(e.g., smart phone) when the data can be processed locally 
in the wearable device and the useful information is only 
sent intermittently to the recipient to reduce the 
communication 
overhead 
and 
minimise 
the 
power 
consumption. It should be noted that other sensing 
modalities can include sound sensor and light sensor which 
can be useful to detect verbal aggression which is another 
kind of challenging behaviour.  
VII. 
   CONCLUSION 
In this work, we conducted a review on commercially off 
the-shelf wearable devices suitable for monitoring and 
tracking individuals with autism spectrum disorder and/or 
intellectual disability. Specifically, we briefly explained the 
unique issues that those individuals experience such as 
challenging behaviours. Then, we reviewed the related 
physiological, behavioural, and location related sensors that 
can be used to monitor the internal emotional state, their 
activities, and track their location. After that, we surveyed 
the existing and emerging products in the market with 
various form-factors, examined their usefulness in practice, 
and talked about lessons learnt and their shortcomings.   
ACKNOWLEDGMENT 
This research was supported by funding from the charity 
RESPECT and the People Programme (Marie Curie Actions) 
of the European Union's Seventh Framework Programme 
(FP7/2007-2013) 
under 
REA 
grant 
agreement 
no. 
PCOFUND-GA-2013-608728’. 
 
REFERENCES 
 
[1]  K. C Dominick, N. O. Davis, J. Lainhart, H. Tager-Flusberg, 
and S Folstein, “Atypical behaviours in children with autism 
and children with a history of language impairment. Research 
in Developmental Disabilities,,” Research in Developmental 
Disabilities, vol. 28, no. 2, pp. 145–162, 2007.  
[2]  C. E. Rice, et al., “Reported Wandering Behavior among 
Children with Autism Spectrum,” Journal Pediatrics, vol. 
174, pp. 232–239.e2, Jul 2016.  
[3]  B. Kiely, T. R. Migdal, S. Vettam, and A. Adesman, 
“Prevalence and Correlates of Elopement in a Nationally 
Representative Sample of Children with Developmental 
Disabilities in the United States,” PLoS ONE, vol. 11, no. 2 , 
pp. 1-11, Feb 2016.  
[4]  L. McIlwain and W. Fournier, “Mortality & Risk In ASD 
Wandering/Elopement 2011-2016,” [Online]. Available: 
http://nationalautismassociation.org/wp-
content/uploads/2017/04/NAAMortalityRiskASDElopement.
pdf. [retrieved: 06, 2018]. 
[5]  S. H. Koo1, K. Gaul, S. Rivera, T. Pan, D. Fong, “Wearable 
Technology Design for Autism Spectrum Disorders.,” 
12
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

Archives of Design Research, vol. 31, no. 1, pp. 37-55, 2018.  
[6]  E. 
Emerson, 
Challenging 
behaviour: 
Analysis 
and 
intervention in people with severe intellectual disabilities., 
New York: Cambridge University Press., 2001.  
[7]  J. L. Matson , J. Wilkins, and J. Macken, “The relationship of 
challenging behaviours to severity and symptoms of autism 
spectrum disorders.,” Journal of Mental Health Research in 
Intellectual Disabilities,, vol. 2, no. 1, pp. 29–44, 2009.  
[8]  S. Majumder, T. Mondal and M. J. Deen, “Wearable Sensors 
for Remote Health Monitoring,” Sensors, vol. 17, no. 130, 
pp. 130-175, 2017.  
[9]  S. Patel, H. Park, P. Bonato1, L. Chan and M. Rodgers, “A 
review of wearable sensors and systems with application in 
rehabilitation,” 
Journal 
of 
NeuroEngineering 
and 
Rehabilitation , vol. 9, no. 21, pp. 1-17, 2012.  
[10]  J. Cabibihan, H. Javed, M. Aldosari, T. W. Frazier and H. 
Elbashir, “Sensing Technologies for Autism Spectrum 
Disorder Screening and Intervention,” Sensors, vol. 17, no. 1, 
pp. 46-71, 2017.  
[11]  M. T. K. Tsun, L. B. Theng, H. Siswoyo and S. L. Lau. , 
“Potential of Human Tracking in Assistive Technologies for 
Children with Cognitive Disabilities,” in Supporting the 
Education of Children with Autism Spectrum Disorders, 
Philadelphia, Yefim Kats (Chestnut Hill College, USA), 
2017, pp. 22. 
[12]  St. Balters and M. Steinert, “Capturing emotion reactivity 
through physiology measurement as a foundation for 
affective engineering in engineering design science and 
engineering practices,” Journal of Intelligent Manufacturing, 
vol. 28, no. 7, pp. 1585–1607, October 2017.  
[13]  “Amber Alert GPS - How It Works,” Amber Alert GPS, 
[Online]. Available: https://amberalertgps.com/. [retrieved: 
05, 2018]. 
[14]  “Angle Sense Autism Tracker Solution,” AngleSense, Inc., 
[Online]. 
Available: 
https://www.angelsense.com/autism-
tracker/. [retrieved: 06, 2018]. 
[15]  [Online].  
[16]  “Trax GPS Tracker for Kids,” Trax , [Online]. Available: 
https://traxfamily.com/tracker-for-kids/. [retrieved: 05, 2018]. 
[17]  “Securus EZOOM1000 eZoom Personal GPS Locator,” 
Securus 
eZoom, 
[Online]. 
Available: 
https://www.amazon.com/Securus-EZOOM1000-Personal-
Locator-Requires/dp/B0079SR568. [retrieved: 06 2018]. 
[18]  “SPOT 3 Satellite GPS Messenger,” SPOT LLC, [Online]. 
Available: 
https://www.findmespot.com/en/index.php?cid=100. 
[retrieved: 06, 2018]. 
[19]  “Yepzon 
One,” 
Yepzon, 
[Online]. 
Available: 
http://yepzon.com/product/yepzon/. [retrieved: 06, 2018]. 
[20]  “Buddy Tag with Silicone Wristband,” Le Vise Products 
LLC, 
[Online]. 
Available: 
https://mybuddytag.com/collections/buddy-tag-with-silicone-
wristband. [retrieved: 06, 2018]. 
[21]  “Trackimo 3G GPS Watch Tracker,” Trackimo, [Online]. 
Available: 
https://store.trackimo.com/products/trackimo-
watch-3g. [retrieved: 05, 2018]. 
[22]  “FiLIP 
Solution,” 
FiLIP 
, 
[Online]. 
Available: 
http://www.myfilip.com/. [retrieved: 06, 2017]. 
[23]  “BeLuvv Guardian - Bluetooth 4.0 Proximity Guarding 
Device 
for 
kids,” 
BeLuvv, 
[Online]. 
Available: 
https://www.amazon.com/BeLuvv-Guardian-Bluetooth-
Proximity-Guarding/dp/B00JXDQJW8. [retrieved: 06, 2018]. 
[24]  “Polar Team Pro | GPS player tracking system,” Polar, 
[Online]. 
Available: 
https://www.polar.com/en/b2b_products/team_sports/team_p
ro. [retrieved: 06, 2018]. 
[25]  “Cityzen Sciences smart shirt tech to power banking ID, 
betting and virtual matches,” Cityzen Sciences, [Online]. 
Available: https://www.wareable.com/sport/cityzen-sciences-
smart-shirt-tech-to-power-banking-id-betting-and-virtual-
competitions-972. [retrieved: 06, 2018]. 
[26]  “Angle Sense Autism Tracker Solution,” AngleSense, Inc., 
[Online]. 
Available: 
https://www.angelsense.com/autism-
tracker/. [retrieved: 05, 2018]. 
[27]  “POCKETFINDER+® PERSONAL 3G GPS / Wi-Fi / Cell 
ID Tracker for Locating and Monitoring People,” Pocket 
Finder, 
[Online]. 
Available: 
https://pocketfinder.myshopify.com/. [retrieved: 06, 2018]. 
[28]  “Trax GPS Tracker for Kids,” Trax, [Online]. Available: 
https://traxfamily.com/tracker-for-kids/. [retrieved: 06, 2018]. 
[29]  “FiLIP 
Solution,” 
FiLIP, 
[Online]. 
Available: 
http://www.myfilip.com/. [retrieved: 05, 2017]. 
[30]  S. Benedetto, C. Caldato, E. Bazzan, D. C. Greenwood, V. 
Pensabene, and P. Actis, “Assessment of the Fitbit Charge 2 
for monitoring heart rate,” PLoS ONE 13(2): , vol. 13 , no. 2, 
pp. 1-10, 2018.  
[31]  “E4 Wristband Rev. 2,” Empatica, Inc., [Online]. Available: 
https://store.empatica.com/products/e4-
wristband?variant=39588207747. [retrieved: 06, 2018]. 
[32]  “TouchPoint™ original Kit,” TouchPoint, Inc, [Online]. 
Available: 
https://www.touchpointeurope.com/products/touchpoint-kit-
single-person. [retrieved: 06, 2018]. 
[33]  “MyFeel Wristband,” Sentio Solutions Inc., [Online]. 
Available: https://www.myfeel.co/reserve. [retrieved: 05, 
2018]. 
[34]  “Reveal,” 
Awake 
Labs, 
Inc, 
[Online]. 
Available: 
http://awakelabs.com/home/. [retrieved: 06, 2018]. 
[35]  “BioHarness 3 User Manual,” Zypher Technology, [Online]. 
Available: 
https://www.zephyranywhere.com/media/download/bioharne
ss3-user-manual.pdf. [retrieved: 05, 2018]. 
[36]  e. a. G. Nazari, “Psychometric properties of the Zephyr 
bioharness device: a systematic review,” BMC Sports 
Science, Medicine and Rehabilitation , vol. 10, no. 6, pp. 1-8, 
2018.  
[37]  D. Nepi, A. Sbrollini, A. Agostinelli, “Validation of the 
heart-rate signal provided by the Zephyr bioharness 3.0,” in 
Computing in Cardiology Conference (CinC) , Vancouver, 
BC, Canada, 2016, 43, pp. 361-364.  
[38]  “Equivital™ TnR Products,” Equivital, Inc., [Online]. 
Available: 
https://www.adinstruments.com/products/equivital-sensor-
belt. [retrieved: 05, 2018]. 
13
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

[39]  A. A. Akintola, V. v. de Pol, D. Bimmel, A. C. Maan, and D. 
v. Heemst, “Comparative Analysis of the Equivital EQ02 
Lifemonitor with Holter Ambulatory ECG Device for 
Continuous Measurement of ECG, Heart Rate, and Heart 
Rate Variability: A Validation Study for Precision and 
Accuracy,” Front Physiol. , vol. 7, no. 391, pp. 1-14, 2016.  
[40]  “Zephyr Performance Systems,” Medtronic, Inc., [Online]. 
Available: 
https://www.zephyranywhere.com/benefits/physiological-
biomechanical. [retrieved: 06, 2018]. 
[41]  “Hexoskin 
Smart 
Shirts,” 
Hexoskin, 
Inc., 
[Online]. 
Available: https://www.hexoskin.com/pages/health-research. 
[retrieved: 06, 2018]. 
 
 
 
 
 
 
[42]  “Health Research and Professional Solutions,” Hexoskin, 
[Online]. Available: https://www.hexoskin.com/pages/health-
research. [retrieved: 06, 2018]. 
[43]  “AIO Sleeve,” Komodo Technologies, [Online]. Available: 
http://komodotec.com/product/aio-sleeve/. 
[retrieved: 
06, 
2018]. 
[44]  A. Serin, N. S. Hageman, E. Kade, “The Therapeutic Effect 
of Bilateral Alternating Stimulation Tactile Form Technology 
on the Stress Response,” Journal of Biotechnology and 
Biomedical Science , vol. 1, no. 2, pp. 42-47, 2018.  
 
 
 
 
14
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

Steps toward Automatic Assessment of Parkinson’s Disease at Home  
 
Roberto Nerino, Claudia Ferraris, Giuseppe Pettiti, 
Antonio Chimienti 
Institute of Electronic, Computer and 
Telecommunication 
National Research Council 
Turin, Italy 
e-mail: roberto.nerino@ieiit.cnr.it, 
claudia.ferraris@ieiit.cnr.it, giuseppe.pettiti@ieiit.cnr.it, 
antonio.chimienti@ieiit.cnr.it  
Corrado Azzaro, Giovanni Albani, Lorenzo 
Priano, Alessandro Mauro 
Department of Neurology and Neurorehabilitation 
Istituto Auxologico Italiano, IRCSS 
Piancavallo, Verbania, Italy 
e-mail: c.azzaro@auxologico.it, 
g.albani@auxologico.it, lorenzo.priano@unito.it, 
mauro@auxologico.it  
 
 
Abstract—This work presents a non-invasive low-cost system 
suitable for the at home assessment of the neurological 
impairment of patients affected by Parkinson’s Disease. The 
assessment is automatic and it is based on the accurate 
tracking of hands and fingers movements of the patient during 
the execution of standard upper limb tasks specified by the 
Unified Parkinson’s Disease Rating Scale (UPDRS). The 
system is based on a human computer interface made by light 
gloves and an optical tracking RGB-Depth device. The 
accurate tracking and characterization of hands and fingers 
movements allows both the automatic and objective assessment 
of UPDRS tasks and the gesture-based management of the 
system, making it suitable for motor impaired users as are PD 
patients. The assessment of UPDRS tasks is performed by a 
machine 
learning 
approach which 
use 
the 
kinematic 
parameters that characterize the patient movements as input 
to trained classifiers to rate the UPDRS scores of the 
performance. The classifiers have been trained by an 
experimental campaign where cohorts of PD patients were 
assessed both by a neurologist and the system. Results on the 
assessment accuracy of the system, as compared to 
neurologist’s assessments, are given along with preliminary 
results on monitoring experiments at home.  
Keywords-Parkinson’s disease; UPDRS assessment; RGB-D 
camera; hand tracking; human computer interface; machine 
learning; tele-monitoring 
I. 
INTRODUCTION 
Parkinson’s Disease (PD) is a chronic neurodegenerative 
disease characterized by a progressive impairment in motor 
functions (e.g., bradykinesia) [1] , with important impacts on 
quality of life. Unified Parkinson's Disease Rating Scale 
(UPDRS) [2] is commonly used by neurologists to assess the 
severity of the disease, whose motor aspects are an important 
part. Specifically defined motor tasks are used by 
neurologists to assess impairments and to assign a subjective 
score for each task on a scale of five classes of increasing 
severity. 
The assessment process takes into account specific 
kinematic aspects of the movements (amplitude, speed, 
rhythm, hesitations) which are qualitatively and subjectively 
evaluated by neurologists. On the other hand, a quantitative 
and objective assessment of the tasks is important to increase 
the reliability of the clinical assessment [3]. A commonly 
adopted solution is to make use of the well-established 
correlation existing between kinematic parameters of the 
movements and the severity of the impairment [4][5]. This 
correlation is used in the automatic and objective assessment 
of  UPDRS motor tasks by several technological approaches, 
among which those based on optical devices and wearable 
inertial sensors [6][7]. 
Drug treatment of the PD symptoms is crucial to reduce 
the effects of the impairment in daily activities but, because 
of possible fluctuations in impairment, it would be desirable 
to adjust the therapy on a weekly basis, both for the best 
effectiveness and to reduce side and long term effects [8]. 
Unfortunately, the cost of a traditional weekly assessment, 
preferably at home to reduce patient’s discomfort, is 
unsustainable for the health care system. In this context, 
technology can support neurologists with an objective and 
quantitative assessment of UPDRS motor tasks. Focusing on 
the upper limb tasks of UPDRS, solutions based on wireless 
inertial 
measurement 
devices 
(accelerometers 
and 
gyroscopes) [8]-[10] and on resistive bend sensors [11] do 
not suffer of occlusion problems but they are more 
uncomfortable for motor impaired people respect to optical 
approaches and, more important, their invasiveness can 
affect motor performance. 
Optical approaches for hand tracking of motor impaired 
people and for the automatic assessment of upper limb tasks 
of UPDRS, namely Finger Tapping (FT), Opening-Closing 
(OC) and Pronation-Supination (PS), have been recently 
proposed based on RGB cameras [12], passive markers [13] 
and  bare hand tracking  by consumer depth sensing devices 
[14]-[17].  
Less attention is generally given to the assessment of the 
tracking accuracy obtainable by the proprietary hand-
tracking firmware of these consumer devices. Their accuracy 
can be unsatisfactory especially for fast movements, as has 
been shown by comparisons with standard optoelectronic 
systems [18]; nevertheless, this is an important requirement 
to be considered for the reliability of kinematic parameters 
and the motor performance assessment. Furthermore, the 
short product life span of these devices and of the related 
15
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

 
 
Figure 1. Hand/fingers tracking system 
Software Development Kit (SDK) warns against solutions 
too dependent on proprietary hardware and software. Along 
this line of research, we present a low-cost system for the 
automatic assessment of the upper limb UPDRS tasks (FT, 
OC, PS) at home. The system hardware is based on 
lightweight coloured gloves, a RGB-Depth sensor and a 
monitor, while the software implements 3D tracking of the 
hand trajectories, characterizes them by kinematic features 
and assesses the motor performance by trained Machine 
Learning algorithms. The software performs the real-time 
tracking by fusion of both colour and depth information from 
the RGB and depth streams. The system acts at the same 
time as a non-invasive Human Computer Interface (HCI) 
which allows motor impaired PD patients to self-manage the 
test execution. Respect to other approaches, based only on 
depth information and proprietary algorithms, the hand 
tracking is more robust and accurate for fast movements 
[18], making the final assessment more reliable. Another 
important characteristic of our solution is that it does not 
relay on any particular hardware or SDK; it assumes the 
availability of RGB and depth streams at reasonable frame 
rate.  The accuracies obtained by the classifiers demonstrate 
the feasibility of the system in remote assessment of upper 
limb UPDRS tasks. Some preliminary results on at-home 
monitoring of PD patients are given. 
The paper is organized as follows. The technological 
solution and the methodological approach for the accurate 
tracking of hand and fingers movement are described in 
Section II. Section III reports the results of the automatic 
classification of motor performance and some preliminary 
data about the assessment of patient’s performance at home. 
Conclusions and future work are discussed in Section IV.  
II. 
SYSTEMS AND METHODS 
A. System Hardware 
The hand/fingers tracking hardware consists of a low-
cost RGB-Depth device (Intel Realsense SR300 ©) that 
provides synchronized RGB color and Depth streams at 
resolutions of 1920x1080 (Full HD) at 30fps and 640x480 
(VGA) at 30 fps (max. 200) respectively. The RGB-Depth 
device is connected via a USB port to a personal computer 
(PC) running Microsoft Windows and equipped with a 
monitor positioned in front of the user (Figure 1). The 
monitor provides the visual feedback of the HCI for the hand 
and finger movements of the user. The user equipment 
consists of black lightweight gloves with imprinted colour 
markers: each colour marker corresponds to a particular part 
of hand to be tracked (e.g., fingertips and wrist) or to be used 
for colour calibration and system interaction (e.g., palm). 
The device drivers and our developed software are used 
to implement both the hand and fingers tracking and the user 
interface of the HCI. The software running on the PC 
implements the data stream acquisition and processing for 
the hand/fingers tracking, the kinematic parameter estimation 
and the task assessment. Furthermore, the data produced in 
every test session, including video sequence of each 
performance, kinematic parameters and system scores are 
automatically encrypted and archived for further analysis and 
for clinician independent supervision and assessment. 
B. Initial Setup 
Global image brightness adjustment, hand segmentation 
and colour calibration for marker segmentation are 
performed during the initial setup phase. The Intel 
LibRealSense library is used for RGB and depth stream 
acquisition and the OpenCV library  [19] is used to recover 
the 3D position of the hand centroid from the depth stream. 
A hand shaking movement of the user starts the recovering 
of the initial hand position. The hand centroid is used to 
segment the hand from the background and to define 2D and 
3D hand bounding boxes, both for colour and depth images. 
Then RGB streams are converted from RGB to the HSV 
colour space, more robust to brightness variations. The 
design of the colour markers and the implementation of a 
colour constancy algorithm compensate for different ambient 
lighting conditions found in domestic environments. For this 
purpose, during the initial setup the white circular marker on 
the palm is detected and tracked in the HSV stream.  The 
average levels of each HSV component of the circular 
marker are used to compensate for predominant colour 
components due to different types of lighting. Their values 
are used to scale each of the three HSV video sub-streams 
during the tracking phase.  
C. Hand and Finger Tracking 
During the tracking phase, the 3D position of the hand 
centroid is used to continuously update the 2D and 3D hand 
bounding boxes (Figure 2). The colour thresholds selected 
during the setup phase are used to detect and track all the 
color blobs of the markers. To improve performance and 
robustness, the CamShift algorithm [19] has been used in the 
tracking procedure.  The 2D pixels of every color marker 
area are re-projected to their corresponding 3D points by 
standard re-projection, and their 3D centroids are then 
evaluated. Each centroid is used as an estimate of the 3D 
position of the corresponding part of the hand that is used for 
movement analysis.  
16
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

 
 
Figure 2. Hand segmentation and marker detection: color blob 
centroids and bounding box 
 
 
Figure 3. Human computer interface with natural gestural 
interaction 
D. Human Computer Interface for System Management 
The real-time hand/fingers tracking software and the 
graphical user interface realize the human computer interface 
(Figure 3) where the patient can manage the test session 
(e.g., start and end the session, select the specific task, input 
information, etc.) by making simple gestures (opening and 
closing the hand, pointing with fingers) towards the 
graphical menu displayed on the monitor.  
E. Clinical Assessment and Data Acquisition 
The system performance was evaluated on two cohorts; 
one made up of forty patients (22 females, 18 males) with a 
diagnosis of Parkinson’s Disease (PD), and the other made 
up of fifteen Healthy Control (HC) subjects. Patients were 
recruited according the UK Parkinson’s Disease Society 
Brain Bank Clinical Diagnostic standards and met the 
following criteria:  Hoehn and Yahr score (average 2.2, min 
1, max 4); age 43–81 years; disease duration 2–29 years. 
Patients were excluded if they had previous neurosurgical 
procedures, tremor severity > 1 (UPDRS-III severity score), 
or cognitive impairment (Mini–Mental Score < 27/30). The 
HC subjects met these criteria: age, 35–78 years, not affected 
by neurological, motor and cognitive disorders. All subjects 
provided their informed consent prior to their participation. 
The PD cohort was assessed for the FT, OC and PS 
UPDRS tasks on both hands by one neurologist expert in 
movement disorders and the resulting UPDRS severity 
scores were found between 0 (normal) and 3 (moderate 
impaired). The performance of the PD patients were tracked 
at the same time by the system and the related kinematic 
parameters 
of 
the 
hand/fingers 
trajectories 
were 
automatically extracted. The HC subjects performed the tests 
in the same environmental conditions and with the same 
system setup of PD patients.  
F. Kinematic Parameter Selection 
The automatic assessment of UPDRS tasks makes use of 
the well establish correlation existing between the kinematic 
parameters of the movements, objectively evaluated by the 
system, and the severity of the impairment, subjectively rated 
by neurologists and expressed as UPDRS scores [4]. The 
kinematic parameters we choose are closely related to the 
typical characteristic of the patient movement that are used 
by neurologists to score the performance (amplitude, speed, 
rhythm, hesitations, and others). To compact the information 
associated to the parameters and to reduce their redundancy 
the most discriminative ones among them have been 
identified for every UPDRS tasks. First, a Principal 
Component Analysis (PCA) was applied to the initial set of 
parameters to filter out those which contribute less than 5% 
to represent the whole dataset. Then, the selected kinematic 
parameters were correlated to neurologist UPDRS scores 
(Spearman’s correlation coefficient ρ), keeping only those 
ones with the best correlation with neurologist UPDRS 
scores, at significance level p<0.01 (Table I). Note that the 
choice of the parameters is such that increasing values of the 
parameters indicate a worsening of the performance. 
In this context, the kinematic parameters of the HC 
subjects have been used to normalize the PD ones. Thanks to 
the better performance of HC subjects, their average score 
values pi HC are always better than the pi PD ones, and are 
used to obtain normalized PD parameters ( pi PD norm  = pi PD 
/pi 
HC). This selection process produces normalized 
parameters which are able to discriminate UPDRS classes 
for the FT, OC and PS, highlighting the increasing severity 
of motor performance by the corresponding increasing of 
their values. This is visually confirmed by the mean values 
of the selected kinematic parameters versus UPDRS severity 
class as shown in the radar graphs of Figure 4(a) for FT, 
Figure 4(b) for OC and Figure 4(c) for PS tasks respectively. 
UPDRS classes for the FT, OC and PS, highlighting the 
increasing 
severity 
of 
motor 
performances 
by 
the 
corresponding expansion of the related radar graph 
representation.  
G. Automatic UPDRS Assessment by Machine Learning  
To implement the automatic assessment of the FT, OC 
and PS UPDRS tasks, three data sets of “parameter vector – 
neurologist UPDRS score” pairs were used to train three 
different classifiers. We use the LIBSVM library package 
[20] to implement three Support Vector Machine (SVM) 
classifiers with polynomial kernel. Their accuracy in 
assigning correctly the UPDRS scores was tested by using 
the leave-one-out cross validation method. The confusion 
matrices were used to characterize the classification 
performance of the SVM classifiers. 
An interesting feature offered by the SVM classifier 
implementation is that, given the kinematic parameters 
vector as input, the classifier output is the vector P of 
17
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

 
(a) 
 
(b) 
 
(c) 
Figure 4. Radar graph from selected kinematic parameters for FT task 
(a), OC task (b) and PS task (c) 
probabilities pj that the input vector belongs class Cj. To test 
the classifiers and build the confusion matrices the class Ck 
corresponding to the highest probability pk among all the 
probabilities in P is chosen.  
TABLE I.  
SELECTED KINEMATIC PARAMETERS 
Name 
Finger Tapping UPDRS task 
Meaning 
Unit 
ρ-value 
X1 
Maximum opening (mean) 
mm 
-0.43 
X2 
Maximum opening (CV) 
- 
0.35 
X3 
Maximum amplitude (mean) 
mm 
-0.41 
X4 
Maximum amplitude (CV) 
- 
0.39 
X6 
Duration (CV) 
- 
0.42 
X9 
Maximum opening velocity (mean)  
mm/s 
-0.58 
X10 
Maximum opening velocity (CV) 
- 
0.39 
X11 
Maximum closing velocity (mean) 
mm/s 
-0.55 
X12 
Maximum closing velocity (CV) 
- 
0.43 
X13 
Main Frequency 
Hz 
-0.48 
Name 
Opening-Closing UPDRS task 
Meaning 
Unit 
ρ-value 
X1 
Maximum opening (mean) 
mm 
-0.54 
X2 
Maximum opening (CV) 
- 
0.34 
X3 
Maximum amplitude (mean) 
mm 
-0.55 
X4 
Maximum amplitude (CV) 
- 
0.31 
X5 
Duration (mean) 
s 
0.25* 
X6 
Duration (CV) 
- 
0.58 
X9 
Maximum opening velocity (mean)  
mm/s 
-0.63 
X10 
Maximum opening velocity (CV) 
- 
0.47 
X11 
Maximum closing velocity (mean) 
mm/s 
-0.54 
X12 
Maximum closing velocity (CV) 
- 
0.53 
Name 
Pronation-Supination UPDRS task 
Meaning 
Unit 
ρ-value 
X1 
Maximum supination (mean) 
deg 
-0.36 
X2 
Maximum supination (CV) 
- 
0.05 
X9 
Maximum supination velocity (mean)  
deg/s 
-0.42 
X10 
Maximum supination velocity (CV) 
- 
0.35 
X11 
Maximum pronation velocity (mean) 
deg/s 
-0.46 
X12 
Maximum pronation velocity (CV) 
- 
0.44 
X13 
Main Frequency 
Hz 
-0.47 
X19 
Pronation Phase Duration 
s 
0.33 
Legend 
Coefficient of Variation: ratio of standard deviation (σ) to mean μ of the parameter. CV = σ/μ 
Maximum Opening/Supination: peak of distance/angle in one movement 
Amplitude: difference between maximum and minimum distance/angles in one movement 
Duration: time elapsed between the start and the end of one movement 
Maximum Opening/Supination Velocity: peak in an opening/supination phase of one movement  
Maximum Closing/Pronation Velocity: peak in a closing/pronation phase of one movement  
Opening/Supination Phase Duration: Time for opening/supination phase of one movement 
Closing/Pronation Phase Duration: Time for closing/pronation phase of one movement 
Rate: Number of movements per second 
Main Frequency: Frequency with the peak in power spectrum (bandwidth 0.. 4 Hz) 
18
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

The probabilistic assignment P of the classifier output 
allows for an interesting extension to continuous values of 
the discrete UPDRS classification obtained using the most 
probable class. For this purpose, for each task, the 
probabilities pi to belong to specific UPDRS classes (i.e., the 
outputs of the related classifier) have been combined in a 
weighted mean. 
In this way, a continuous estimation (W) of the UPDRS 
score is obtained (1): 
 
                                     W = ∑ i ∙ pi                                                        (1) 
i = 0..4; pi = probability to belong to class Ci 
 
The advantage of this approach is the possibility to assess 
continuous variations of motor impairments that is not 
possible to obtain with a quantized (0-4) UPDRS score. A 
support to the correctness of the proposed extension is based 
on the choice of kinematic parameters, which are closely 
related to the clinical ones; the increase of a parameter value 
should correspond to an increasing of the neurologist’s score. 
In practice, the classifiers output probabilistic assignment 
vectors P with only two significant probabilities that are 
related to contiguous classes. An application of the 
continuous UPDRS score estimate W in monitoring small 
fluctuation of patient impairment is presented in the 
preliminary experiments paragraph.  
III. 
RESULTS 
A. Accuracy of the Automatic Assessment 
The confusion matrices shown in Table II, III and IV 
were used to characterize the classification performance of 
the SVM classifiers for the FT, OC and PS UPDRS tasks, 
both for the left and the right hand.  
From them, all standard parameters for classifier 
evaluation (accuracy, sensitivity and so on) can be easily 
derived. 
TABLE I.  
FT CONFUSION MATRIX (UPDRS CLASSES) 
 
SYSTEM SCORES 
 
C0 
C1 
C2 
C3 
CLINICAL 
SCORES 
C0 
15 
3 
0 
0 
C1 
2 
21 
2 
0 
C2 
0 
1 
18 
3 
C3 
0 
0 
2 
13 
TABLE II.  
OC CONFUSION MATRIX (UPDRS CLASSES) 
 
SYSTEM SCORES 
 
C0 
C1 
C2 
C3 
CLINICAL 
SCORES 
C0 
14 
2 
0 
0 
C1 
1 
17 
2 
0 
C2 
0 
1 
22 
3 
C3 
0 
0 
4 
14 
TABLE III.  
PS CONFUSION MATRIX (UPDRS CLASSES) 
 
SYSTEM SCORES 
 
C0 
C1 
C2 
C3 
CLINICAL 
SCORES 
C0 
8 
3 
0 
0 
C1 
1 
10 
2 
0 
C2 
0 
2 
30 
6 
C3 
0 
0 
3 
15 
 
It can be noted the nonzero off diagonal elements of the 
matrices are one position far from the diagonal ones, 
meaning the classification errors were limited to one UPDRS 
class. 
B. Preliminary Experiments on UPDRS Assessment 
A preliminary experiment to assess the feasibility of the 
proposed system in monitoring PD patient at home has been 
conducted. A small group of PD patients (4 subjects) used 
the system at home for a period of a week. The subjects were 
instructed to perform FT, OC and PS task at different times 
(30m, 1.5h, 2.5h, 3.5h) from drug intake, every day of the 
week. The intent was to assess the potential fluctuations in 
upper limb motor performance in the period after the drug 
intake. 
To give insight of the experiment results, a sample of the 
FT assessment is shown in Figure 5 for a PD patient, male, 
65 years old, diagnosis at 60, non-fluctuating, and with more 
motor impairment on the right side. The patient was 
performing the upper limb UPDRS tasks daily, at different 
times (30m, 1.5h, 2.5h, 3.5h) from drug intake as required. 
Thanks to the data storage and the remote retrieving 
capability of the system, the session data (video, scores, 
parameters) and in particular the videos acquired by the 
system during task executions were accessed from remote, 
analysed and scored by the neurologist for both hands, 
resulting in a FT score of UPDRS 0 or UPDRS 1. 
As shown in Figure 5, on the average, there is a good 
agreement 
between 
system 
and 
neurologist 
scores. 
Nevertheless, the system can assess tasks on a continuous 
scale (W score definition) respect to the standard discrete 
UPDRS score. This feature could open the possibility to 
investigate the interaction between drugs and motor effects 
with a more objective, sensible and hopefully accurate 
approach.  
IV. 
CONCLUSIONS AND FUTURE WORKS 
This work presents a non-invasive and low-cost system 
for the automatic assessment of PD patients performing 
standard upper limbs UPDRS tasks at home. The system is 
based on a new human computer interface that, by an 
accurate hand tracking allows both the system management 
and the automatic and objective UPDRS assessment. The 
hand gestural interface makes it suitable for motor impaired 
users, as are PD patients. The automatic assessment of 
UPDRS tasks is performed by a machine learning approach 
which uses some selected kinematic parameters that 
characterize 
the 
patient’s 
movements. 
UPDRS 
task 
19
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

 
 
Figure 5. Automatic assessment of a FT task (left and right hand) at 
different times from drug intake. The continuous UPDRS assessment 
values and neurologist scores are shown at four different time. To 
facilitate the interpretation, scores are connected by coloured lines 
classifiers were trained during an experimental campaign 
where PD patients were assessed by the neurologist and the 
system. The results about the obtained confusion matrices of 
the classifiers show the classification errors are limited to 
one UPDRS class and only in a few cases, making the 
system suitable for at home self-administrated assessment of 
upper limb UPDRS tasks. Based on the classifier outputs, a 
new continuous estimation of the UPDRS score is introduced 
and its potential benefit discussed. 
Preliminary results about the application of the 
continuous UPDRS score in the at home monitoring of PD 
patients are presented. Further experiments are still needed to 
validate both the system usability and accuracy in the home 
environment, and the usefulness of the continuous UPDRS 
score here introduced in monitoring fine motor impairment 
fluctuations. Next steps will address also the extension of 
this solution to the analysis of other UPDRS tasks, aiming to 
obtain a global and comprehensive assessment of the neuro 
motor status of PD patients. It would be very important in the 
perspective of an optimization of the drug therapy, so 
improving both the clinical management and the patient's 
quality of life. This would be even more relevant if the 
overall assessment could be carried out at the patient's home, 
whenever more frequent observations are needed to better 
evaluate worsening in motor symptoms. 
 
REFERENCES 
[1] G. Pal and C. G. Goetz, “Assessing bradykinesia in Parkinsonian 
disorders”,  Front. Neurol., vol. 4(54), Jun. 2013, pp. 1-5,  
eCollection, doi:10.3389/fneur.2013.00054 
[2] Movement Disorder Society Task Force on Rating Scales for 
Parkinson's Disease, “The Unified Parkinson's Disease Rating Scale 
(UPDRS): status and recommendations”, Mov. Disord., vol. 18(7), 
Jul. 2003,  pp. 738-50, doi:10.1002/mds.10473 
[3] M. Richards, K. Marder, L. Cote and R. Mayeux, "Interrater 
reliability of the Unified Parkinson's Disease Rating Scale motor 
examination", Mov. Disord., vol. 9(1), Jan. 1994,  pp. 89-91  
[4] D. A. Heldman, J. P. Giuffrida, R. Chen., M. Payne, F. Mazzella, A. 
P. Duker, A. Sahay, S. J. Kim, F. J. Revilla, and A. J. Espay, “The 
Modified Bradykinesia Rating Scale for Parkinson’s Disease: 
Reliability and Comparison with Kinematic Measures”, Mov. 
Disord., 
vol. 
26(10), 
Aug. 
2011, 
pp. 
1859-1863, 
doi:10.1002/mds.23740 
[5] A. L. Taylor Tavares, G. S. Jefferis, M. Koop, B. C. Hill, T. Hastie, 
G. Heit, and H. M. Bronte-Stewart, “Quantitative measurements of 
alternating finger tapping in Parkinson's disease correlate with 
UPDRS motor disability and reveal the improvement in fine motor 
control from medication and deep brain stimulation”, Mov. Disord., 
vol. 20(10), Oct. 2005, pp. 1286-1298, doi:10.1002/mds.20556 
[6] A. J. Espay, P. Bonato, F. B. Nahab, W. Maetzler, J. M. Dean, J. 
Kluken, B. M. Eskofier, and Movement Disorder Society Task Force 
on Technology, "Technology in Parkinson's disease: Challenges and 
opportunities", Mov. Disord., vol. 31(9), Sep. 2016, pp. 1272-1282, 
doi:10.1002/mds.26642 
[7] S. Patel, K. Lorincz, R. Hughes, N. Huggins, J. Growdon, D. 
Standaert, M. Akay, J. Dy, M. Welsh, and P. Bonato, “Monitoring 
motor fluctuations in patients with Parkinson's disease using wearable 
sensors”, IEEE Trans Inf Technol Biomed., vol. 13(6), Nov. 2009, pp. 
864-873, doi:10.1109/TITB.2009.2033471 
[8] A. J. Espay, J. P. Giuffrida, R. Chen, M. Payne, F. Mazzella, E. 
Dunn, J. E. Vaughan, A. P. Duker, A. Sahay, S. J. Kim, F. J. Revilla, 
and D. A. Heldman, “Differential Response of Speed, Amplitude and 
Rhythm to Dopaminergic Medications in Parkinson’s Disease”, Mov. 
Disord., 
vol. 
26(14), 
Dec. 
2011, 
pp. 
2504-2508, 
doi:10.1002/mds.23893 
[9] J. Stamatakis, J. Ambroise, J. Cremers, H. Sharei, V. Delvaux, B. 
Macq, and G. Garraux, “Finger Tapping Clinemetric Score Prediction 
in Parkinson’s Disease Using Low-Cost Accelerometers”,  Comput 
Intell Neurosci, vol. 2013, 2013, pp. 1-13, doi:10.1155/2013/717853 
[10] T. O. Mera, D.A. Heldman, A. J. Espay, M. Payne, and J. P. 
Giuffrida, "Feasibility of home-based automated Parkinson's disease 
motor assessment”, J Neurosci Methods, vol. 203(1), Jan. 2012, pp. 
152-156, doi:10.1016/j.jneumeth.2011.09.019 
[11] N. P. Oess, J. Wanek, and A. Curt, “Design and evaluation of a low-
cost instrumented glove for hand function assessment”, J Neuroeng 
Rehabil, vol. 9(2), Jan. 2012, doi:10.1186/1743-0003-9-2 
[12] T. Khana, D. Nyholmc, J. Westina, and M. Dougherty, “A computer 
vision framework for finger-tapping evaluation in Parkinson's 
disease”, Artif Intell Med, vol. 60(1), Jan. 2014, pp. 27-40, 
doi:10.1016/j.artmed.2013.11.004 
[13] A. Jobbagy, P. Harcos, R. Karoly, and G. Fazekas, “Analysis of 
finger-tapping movement”, J Neurosci Meth, vol. 141(1), Jan. 2005, 
pp. 29-39, doi:10.1016/j.jneumeth.2004.05.009 
[14] C. Ferraris, R. Nerino, A. Chimienti, G. Pettiti, D. Pianu, G. Albani, 
C. Azzaro, L. Contin, V. Cimolin, and A. Mauro, “Remote 
monitoring and rehabilitation for patients with neurological diseases”, 
Proc. 10th International Conference on Body Area Networks 
(BodyNets 
14), 
Oct. 
2014, 
pp. 
76-82, 
doi:10.4108/icst.bodynets.2014.257005  
[15] A. H. Butt, E. Rovini, C. Dolciotti, P. Bongioanni, G. De Petris, and 
F. Cavallo, “Leap motion evaluation for assessment of upper limb 
motor skills in Parkinson's disease”, IEEE International Conference 
on  Rehabilitation Robotics (ICORR 17), Jul. 2017, pp. 116-121,  doi: 
10.1109/ICORR.2017.8009232 
[16] P. J. M. Bank, J. Marinus, C. G. M. Meskers, J. H. de Groot, and J. J. 
van Hilten, "Optical Hand Tracking: A Novel Technique for the 
Assessment of Bradykinesia in Parkinson's Disease", Mov. Disord. 
Clinical 
Practice, 
vol. 4(6), 
Dec. 
2017, 
pp. 
875-883, 
doi:10.1002/mdc3.12536 
[17] B. Dror, E. Yanai, and A. Frid, "Automatic assessment of Parkinson's 
Disease from natural hands movements using 3D depth sensor", 
IEEE 28th Convention of Electrical & Electronics Engineers in Israel 
(IEEEI), Dec. 2014, doi: 10.1109/EEEI.2014.7005763 
[18] C. Ferraris, D. Pianu, A. Chimienti, G. Pettiti, V. Cimolin, N. Cau, 
and R. Nerino, "Evaluation of Finger Tapping Test Accuracy using 
the LeapMotion and the Intel RealSense Sensors", IEEE 37th Annual 
International Conference of Engineering in Medicine and Biology 
Society (EMBC 15),  Aug. 2015, one page abstract 
[19] G. Bradski and A. Kaehler, “Learning OpenCV: Computer Vision 
with the OpenCV Library”, O'Reilly Media, 1 ed., Oct. 2008, pp. 1-
580 
[20] C. C. Chang and C. J Lin, "LIBSVM: a library for support vector 
machines", ACM transactions on Intelligent Systems and Technology 
(TIST), 
vol. 2(3), 
Apr. 
2011, 
pp. 
27:1-27:27, 
doi: 
10.1145/1961189.1961199 
 
20
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

Proprioceptive Focal Stimulation (Equistasi®) May Improve Motor Symptoms in 
Moderate Parkinson’s Disease Patients  
Italian Multicentric Preliminary Open Study 
A. Peppe1, P. Paone1, S. Paravati1, M. G. Baldassarre2, L. Bakdounes2, F. Spolaor3, A. Guidotto3, D. Pavan3, Z. Sawacha3, D. 
Clerici4, N. Cau4,5, A. Mauro4,6, G. Albani4, M. Avenali7, G. Sandrini7, C. Tassorelli7, D. Volpe2. 
1 IRCCS Fondazione Santa Lucia, Roma  2 Parkinson Excellence Center of the Fresco Institute for Italy – Vicenza 3 Department of Information Engineering 
(DEI) University of Padova 4 Reparto di Neurologia Istituto Auxologico Italiano, IRCCS Piancavallo- Verbania- Italia 5 Politecnico di Milano 6 Università di 
Torino 7 Department of Brain and Behavioural Sciences, University of Pavia; Department of Neurology and Neurorehabilitation, Mondino Foundation, 
Pavia, Italy. 
a.peppe@hsantalucia.it; ppaone67mail.com; 
stefano.paravatimail.com; mgbaldassarremail.com; 
fs.crocetta@gmail.com; guiotto@dei.unipd.it; 
all.pavandavide@federugby.it; zimi.sawacha@dei.unipd.it; 
d.clerici@auxologico.it; nicola.cau@gmail.com; 
alessandro.mauro@unito.it; g.albani@auxologico.it; 
a_micol@hotmail.com giorgio.sandrini@unipv.it; 
cristina.tassorelli@mondino.it; dott.dvolpe@libero 
Abstract—Object of the study was to evaluate the efficacy of 
propriocettive Focal Stimulation on Gait in moderate 
Parkinson (PD) patients by a preliminary open multicentric 
study, using Equistasi®, nanotechnological device of the 
dimension of a plaster which generates High Frequency 
segmental vibration. The efficacy of Gait Analysis (GA) on 
evaluating gait modification on Parkinson’s Disease (PD) 
Patients is already well known. On the other hand, several 
studies have shown that Proprioceptive Focal Stimulation 
seems to be useful in symptoms amelioration in several 
neurological disease. Therefore, GA was recorded in a group of 
PD patients. Twenty-one PD patients (age 69,51 years, 
Duration disease 8.52 years, Duration Therapy 7,19 years; 
H&Y 2.46) at their best on therapy, were enrolled in the study. 
Two GA were performed always at the morning, before and 
after the treatment.  Three plaques devices were put on the 
skin: one at C7, one at the right and the left leg, on soleus 
muscle. Equistasi® is a nanotechnological device of the 
dimension of a plaster which generates High Frequency 
segmental vibration.  Clinical state was monitored by 
MDUPDRS part III. Parametric (One-way ANOVA and 
paired t-Student) and not – parametric statistic (Freidman 
ANOVA and Wilcoxon test) were used. The analysis of the 
Spatial –Temporal variables showed a significant improvement 
of Mean Velocity (MV) p=.002, Stride Lenght (SL) in right and 
left respectively p=.0013 and p=.017, Stance (STA) in right and 
left respectively p=.025 and p=.047 and Double Support Stance 
(DSS) in left and right stride respectively p=.034 and p=.033. 
MDUPDRS Part III was statistically reduced with p=0.017; 
furthermore the items 3.10, and 3.12 were statistically reduced 
respectively with p=.025 and p=.046. The results, in this group 
of patients, encourage to investigate the mechanical focal 
vibration as stimulation of proprioceptive system in PD. The 
effect of the device on patients may open a new possibility to 
the management of PD. The data indicates as the device 
ameliorates postural stability and gait performance and 
confirms the support that GA gives to underlight the 
modifications of gait in PD patients.
Keywords-Parkinson; 
Rehabilitation; 
focal 
vibrations; 
Equistasi; Gait Analysis. 
I.
INTRODUCTION 
Parkinson’s 
Disease 
one 
of 
more 
diffuse 
neurodegenerative disease, second after Alzheimer’s disease, 
present four cardinal motor symptoms: tremor, rigidity, 
bradykinesia, and postural instability. Last sign is the more 
influent on the activity of daily living, because it induces 
falls [10]. Pharmacological therapy as well as surgical 
therapy are not enough to well control this symptom, and 
many times the postural instability may induce fear to fall 
syndrome, and the PD patient are confined in wheelchair 
[11].  It is already know the Basal Ganglia have golden role 
in the pathological progression of PD patients, but it is not 
really true for balance and postural instability, where the 
Supplementary Motor Area, seems to be an important role 
specially, 
on 
production 
of 
Anticipatory 
Postural 
Adjustments (APAs). Humans in fact use anticipatory and 
compensatory postural strategies to maintain and restore 
balance 
when 
perturbed. 
Inefficient 
generation 
and 
utilization of anticipatory postural adjustments (APAs) is one 
of the reasons for postural instability [12]. SMA is a relay of 
many loops, not only cortical-subcortical loop (cortical-
BBGG- thalamic- Cortical loop), but also vestibular loop, 
and proprioceptive loop and is known that gait analysis is 
important for the clinical evaluation of PD patients [1]. 
Equistasi®, nanotechnological device of the dimension of a 
plaster which generates High Frequency segmental vibration. 
It is not really known how this devise works, there are some 
studies indicating that this focal stimulation modifies the H 
wave in the medulla [13] and in PD patients, the presence of 
Equistasi improves effects of rehabilitation [2]. Object of the 
study was to evaluate the efficacy of Propriocettive Focal 
Stimulation in moderate Parkinson disease patients by a 
preliminary open study. 
II.
METHOD 
A.
Design 
This is a multicentric, open study. 21 patients diagnosed 
with hydiopatic PD were enrolled in four rehabilitation 
21
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

centers in Italy: S. Lucia Foundation in Rome (principal 
center), the Auxologic Institute of Piancavallo Verbania, the 
Villa Margherita Clinic in Vicenza and the Mondino 
Neurological Institute of Pavia, each received approval from 
their ethics committee with protocol number respectively 
CE/PROG 478/15 del 19/11/2015, 58/16, 61/16, 60/16 After 
screening 
and 
enrollment, 
the 
patients 
receive 
a 
proprioceptive mechanical stimulation for 8 weeks with the 
Equistasi method [2], in the absence of any other 
rehabilitative trials. Informed consent was obtained from the 
participants. 
B.
Subjects 
Participants could be included if they had consented to 
participation, patients with rigid akinetik form of bilateral 
idiopatic Parkinsons Diseasei (Hoehn and Yahr 2-3) in 
according to current criteria [3] for at least four years with a 
good response to antiparkinsonian therapy and with stable 
drug therapy for at least 3 months. The exclusion criteria 
were: presence of co-morbidity that prevent safe mobility or 
exercise (including clinically evident neuropathy and 
important medical conditions such as malignant tumors), 
severe dysautonomia with marked hypotension, major 
depression of mood, dementia, pregnancy, caridac pacer 
maker, deep brain stimulation (DBS) or other conditions 
affecting postural stability (eg poor visual acuity or 
vestibular dysfunction). In addition, patients had to have a 
MMSE > 24 points [5]. 
C.
Instrumental assessment 
As primary measures of outcome for Gait Analisys 3D  
the main measures of the linear path (BTS Smart system 
with Davis Procol in all the Centers) were evaluated: the 
speed (Velocity), the length of the step (Stride Length), the 
percentage of support times (Stance) and the percentage of 
the times of double support (DST).  
D.
Clinical assessment 
Motor impairment was assessed with the parts III (motor 
examination) of the Unified PD Rating Scale [6] and Items 
3.10, 3.11, 3.12, 3.13 were separately evaluated for 
underlying data on gait, freezing of gait, postural and 
postural instability of PD patients. Other data collected at 
baseline included age, gender, body mass index (BMI), 
disease duration, Hoehn and Yahr scale, anti Parkinsonian 
treatment expressed as levodopa-equivalent daily dose [7] 
and cognitive status assessed with the MMSE. All adverse 
events such as injuries, were verified and recorded during the 
study.  
E.
Statistical Analysis 
This clinical trial used a sample of convenience, with the 
assumption that 21 participants would be ample to explore 
safety and feasibility. Given the small sample and the lack of 
normal distribution of most of the variables on Shapiro-Wilk 
test, nonparametric statistics were used. Treatment effect 
across time points were explored Wilcoxon signedrank test. 
we have also verified with Montecarlo method (MC) [12] 
[13], the adequacy of the p-value estimates. Categorical 
variables were compared by means of chisquare test. All 
values were expressed as mean and standard deviation were 
chosen to improve clarity of data presentation. IBM SPSS 
Statistics ver. 20.0 was used for all statistical analyses. All 
tests were two-sided with a level of significance set at 
P,0.05. 
III.
RESULT 
Twenty-one subjects were enrolled in this open study 
(Table 1) and we have observed the clinical and instrumental 
assessments before (T0) and after (T1) 8 weeks of treatment. 
No major adverse events or death were observed during the 
study period. 
TABLE I: BASELINE DEMOGRAPHIC AND 
CLINICAL VARIABLES. BMI: BODY MASS INDEX; 
H&Y: HOEHN & YAHR STAGE; LEDD: LEVODOPA 
EQUIVALENT DAILY DOSE; MMSE: MINI-MENTAL 
STATE EXAMINATION. 
Patients 
Mean 
stdv 
SEX (M/F) 
14/7 
SIDE (R/L) 
13/8 
AGE 
69,51 
10,1 
BMI 
25,89 
3,7 
DISEASE DURATION 
8,52 
3,2 
YEARS OF THERAPY WITH L-DOPA 
7,19 
3,1 
DISEASE ONSET AGE 
60,04 
10,4 
LEDDS 
697,3 
110,4 
H/Y 
2,46 
0,51 
MMSE 
26,4 
1,46 
A.
Kinematic parameters 
In the kinematic variables of the gait, we observed a 
significant improvement in Speed from 0.694 m/s to 0.756 m 
s p = .0002; a significant increase in the length of the Stride, 
both right and left respectively from 0.823 m to 0.902 m p = 
.0013 and from 0.835 m to 0.895 m p = .0173; Stance right 
and left significantly decreases, respectively from 64.65% to 
62.75% p = 0.0253 and from 64,22%; to 62,75% p = .0342; 
the right and left DST decreases significantly, respectively 
from 14.02% to 12.99% p = .0342 and from 14.71% to 
13.47% p = .0333 (Table 2). 
22
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

TABLE II: DIFFERENCES BETWEEN T0 AND T1 IN 
THE TEMPORAL SPACE PARAMETERS; WE USED 
ANOVA FOR REPEATED MEASURES 
Pre (dst) 
Post (dst) 
p value 
Velocity (m/s) 
0,694 (0,25)
0,756 (0,24) 
.0002 
Stride Lenght R (m) 
0,823 (0,25)
0,902 (0,22) 
.0013 
Stride Lenght L (m) 
0,835 (0,14)
0,895 (0,19) 
.0173 
Stance R (%) 
64,65 (3,5) 
63,46 (3,4) 
.0253 
Stance L (%) 
64,22 (2,3) 
62,75 (3,5) 
.0473 
DST R (%) 
14,02(3,2) 
12,99 (3,1) 
.0342 
DST L (%) 
14,71 (2,8) 
13,47 (3,1) 
.0333 
B.
Clinics parameters  
In the clinical variables we observed a significant 
decrease in Total Score UPDRS Part III from 37.57 to 32.25 
p = .0179; a significant decrease of ITEM 3.10 from 1.761 to 
1.333 p = .025 and a significant decrease of ITEM 3.12 from 
1.809 to 1.322 p = .0461. No other significant difference was 
observed at the end of active treatment (Table 3).  
TABLE III: DIFFERENCES BETWEEN T0 AND T1 
IN CLINICAL VARIABLES; WE USED WILKOXON 
SIGNED RANK TEST AND MC METHOD. 
IV.
CONCLUSION 
It is already demonstrated that the vibration of the axial 
muscles, produces systematic change in the erect posture 
[15] and the in the orientation of the body [16], and it 
induces in an improvement of balance. The imperceptible 
vibration released from the Equistasi device, have already 
given a positive response in the rehabilitation of some 
neurodegenerative pathologies [2] [17] [18] and have also 
highlighted their capacity in the modulation of the spinal 
circuit [13]. Nevertheless, the data indicate a trend of 
improvement on all spatial-temporal parameters, as if the 
vibrations were acting even on different circuits from the 
dopaminergic. It is noted in literature how the rehabilitation 
of Parkinson’s disease is centered on the stimulation of the 
vestibule spinal reflex (VSR), can modify those components 
of the ambulation more correlated with the rhythmicity and 
the equilibrium [19]. Furthermore precedent studies put in 
evidence how in PD there a compromise sense of timing [20] 
and of the discrimination of the proprioceptive input [21]. 
Therefore, the focal muscular vibration (FV) not only have 
an impact on the circuit on the spinal cord, but also provide a 
notable proprioceptive influx to different parts of the central 
nervous system, thus influencing the precision of the 
execution of the voluntary movements [14]. This open-label 
study has the limit of not being controlled and the number of 
patients must be calculated appropriately to have a power of 
at least 80%. Nevertheless, the results, in this group of 
patients, encourage to investigate the mechanical focal 
vibration as stimulation of proprioceptive system in 
Parkinson’s disease patients, and open a new possibility for 
management of moderate PD patients. Moreover, this study 
confirms the importance of GA in the clinical approach of 
Parkinson’s disease. 
REFERENCES
[1]
Peppe A, Chiavalon C, Pasqualetti P, Crovato D and 
Caltagirone 
C. 
“Does 
gait 
analysis 
quantify 
motor 
rehabilitation efficacy in Parkinson’s disease patients?” Gait 
Posture. 2007 Sep;26(3):452-62. 
[2]
Volpe D, Giantin MG and Fasano A “A wearable 
proprioceptive stabilizer (Equistasi®) for rehabilitation of 
postural instability in Parkinson’s disease: a phase II 
randomized 
double-blind, 
double-dummy, 
controlled 
study”.PLoS One. 2014 Nov 17;9(11). 
[3]
Berardelli A, Wenning GK, Antonini A, Berg D, Bloem BR,
Bonifati V, Brooks D, Burn DJ, Colosimo C, Fanciulli A, 
Ferreira J, Gasser T, Grandas F, Kanovsky P, Kostic V, 
Kulisevsky J, Oertel W, Poewe W, Reese JP, Relja M, 
Ruzicka E, Schrag A, Seppi K, Taba P and Vidailhet M. 
“EFNS/MDS-ES/ENS [corrected] Recommendations for the 
diagnosis of Parkinson’s disease.” Eur J Neurol 20: 16–3. 
[4]
Hoehn MM and Yahr MD (1967) “Parkinsonism: onset, 
progression and mortality. Neurology” 17: 427–442.
[5]
Folstein MF, Folstein SE and McHugh PR (1975) ‘‘Mini-
mental state. A practical method for grading the cognitive 
state of patients for the clinician.” J Psychiatr Res 12: 189–
198. 
[6]
Fahn S and Elton R Members of the UPDRS Development 
Committee (1987) “Recent developments in Parkinson’s 
disease.” Fahn S, Marsden C, Calne D, Goldstein M, editors. 
Folorham Park, NJ: Macmillan Health Care Information. 
153–163, 293–304. 
[7]
Tomlinson CL, Stowe R, Patel S, Rick C, Gray R, et al. 
(2010) “Systematic review of levodopa dose equivalency 
reporting in Parkinson’s disease.” Mov Disord 25: 2649–
2653. 
[8]
Fay MP, Kim HJ and Hachey M. “On Using Truncated 
Sequential Probability Ratio Test Boundaries for Monte Carlo 
Implementation of Hypothesis Tests”. J Comput Graph Stat. 
2007;16(4):946-967.  
[9]
Hozo I, Tsalatsanis A and Djulbegovic B. “Monte Carlo 
decision curve analysis using aggregate data.” Eur J Clin 
Invest. 2017 Feb;47(2):176-183. 
[10] Benatru I, Vaugoyeau M and Azulay JP. (2008) “Postural 
disorders in Parkinson’s disease.” Neurophysiol Clin 38: 459–
465 
[11] Smulders K, Dale ML, Carlson-Kuhta P, Nutt JG and Horak 
FB. “Pharmacological treatment in Parkinson's disease: 
Effects on gait.” Parkinsonism Relat Disord. 2016 Oct;31:3-
13 
Pre (dst) 
Post (dst) 
p value
UPDRS III 
37,57 (16,4)
32,25 (12,0) 
.0179 
ITEM 3.10 
1,761 (0.94)
1,333 (0,73) 
.0250 
ITEM 3.11 
0,525 (0,94)
0,656 (0,92) 
.1861 
ITEM 3.12 
1,809 (1,05)
1,322 (1,02) 
.0461 
ITEM 3.13 
1,901 (1,17)
1,550 (1,03) 
.0767 
23
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

[12] Schlenstedt C, Mancini M, Horak F and Peterson D. 
“Anticipatory Postural Adjustment During Self-Initiated, 
Cued, and Compensatory Stepping in Healthy Older Adults 
and Patients With Parkinson Disease.” Arch Phys Med 
Rehabil. 2017 Jul;98(7):1316-1324 
[13] Alfonsi E, Paone P, Tassorelli C, De Icco R, Moglia A, Alvisi 
E, Marchetta L, Fresia M, Montini A, Calabrese M, Versiglia 
V and Sandrini G. “Acute effects of high-frequency 
microfocal vibratory stimulation on the H reflex of the soleus 
muscle. A double-blind study in healthy subjects.” Funct 
Neurol. 2015 Oct-Dec;30(4):269-74. 
[14] Kording KP and Wolpert DM (2006) “Bayesian decision 
theory in sensorimotor control.” Trends Cogn Sci 10: 319–
326. 
[15] Courtine G, De Nunzio AM, Schmid M, Beretta MV and 
Schieppati M (2007) “Stance- and locomotion-dependent 
processing of vibration-induced proprioceptive inflow from 
multiple muscles in humans.” J Neurophysiol 97: 772–779. 
[16] Lackner JR and Levine MS (1979) “Changes in apparent 
body orientation and sensory localization induced by 
vibration of postural muscles: vibratory myesthetic illusions.” 
Aviat Space Environ Med 50: 346–354. 
[17] Spina E, Carotenuto A, Aceto MG, Cerillo I, Silvestre F, 
Arace F, Paone P, Orefice G and Iodice R. “The effects of 
mechanical focal vibration on walking impairment in multiple 
sclerosis patients: A randomized, double-blinded vs placebo 
study.”  Restor Neurol Neurosci. 2016 Sep 21;34(5):869-76. 
[18] Leonardi L, Aceto MG, Marcotulli C, Arcuria G, Serrao M, 
Pierelli F, Paone P, Filla A, Roca A and Casali C. “A 
wearable proprioceptive stabilizer for rehabilitation of limb 
and gait ataxia in hereditary cerebellar ataxias: a pilot open-
labeled study.” Neurol Sci. 2017 Mar;38(3):459-463. 
[19] Tramontano M, Bonnì S, Martino Cinnera A, Marchetti F, 
Caltagirone C, Koch G and Peppe A. “Blindfolded Balance 
Training in Patients with Parkinson's Disease: A Sensory-
Motor Strategy to Improve the Gait.” Parkinsons Dis. 
Hindawi Publishing Corporation Parkinson’s Disease Vol 
2016, Article ID 7536862, 6 pages. 
[20] Fiorio M, Stanzani C, Rothwell JC, Bhatia KP, Moretto G, et 
al. (2007) “Defective temporal discrimination of passive 
movements in Parkinson’s disease.” Neurosci Lett 417: 312–
315. 
[21] Jacobs JV and Horak FB (2006) “Abnormal proprioceptive-
motor 
integration 
contributes 
to 
hypometric 
postural 
responses of subjects with Parkinson’s disease.” Neuroscience 
141:999–1009.
24
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

TouchWear: Context-Dependent and Self-Learning Personal Speech Assistant for 
Wearable Systems with Deep Neural Networks 
Using Contextual LSTMs on Recurrent Neural Networks 
 
Joshua Ho 
Research Center for Information Technology Innovation 
Academia Sinica 
Taipei, Taiwan 
jho@iis.sinica.edu.tw 
Chien-Min Wang 
Institute of Information Science 
Academia Sinica 
Taipei, Taiwan 
cmwang@iis.sinica.edu.tw
 
 
Abstract— Context awareness in future adaptive systems for 
wearable computers comprise many features, such as ability to 
sense and perceive contexts, to be inferred by the generation of 
a user model, to perform the computation and present the 
communication interface, and to provision implemented 
services. In this work, we introduce a system application 
prototype implemented by distinguishing contexts from 
wearable 
systems. 
Thus, 
user 
behavior, activity, 
and 
application data are trained to generate a user model. Next, a 
voice interface administered by the artificial personal speech 
assistant not only enables conversation with the user but is also 
used to build a recurrent model of deep neural networks 
primarily based on the conversation logs. Ultimately, the 
service and recommendation framework are implemented and 
deployed so that the wearable system has the capacity to aid 
people in need by means of service-oriented and wearable 
adaptation. 
Keywords-wearable computing; personal speech assistant; 
context awareness; deep neural network. 
I. 
 INTRODUCTION 
Using wearable devices, like smart watch and smart 
glasses, is more than just convenient, because they collect 
important information about the context according to the 
user’s body behavior and head movement. In contrast to 
smartphone users who often receive limited information of 
little on-body context because of their ‘heads-down’ gesture 
from looking at their smartphones, users of wearable devices 
are able to focus more on social interactions and the 
surrounding views. Wearing smart watches and smart glasses 
permits fewer restrictions and more augmented conditions. 
In recent years, artificial speech assistants like Apple Siri, 
Amazon Alexa, Cortana, and Google Assistant [19] have 
become widely adopted as a conversing medium for mobile 
computation. By taking advantage of acoustic and 
concatenative models of Text-To-Speech (TTS), speech 
assistants can execute and control voice commands, system 
recommendations and services according to user requests. In 
our design, recommendations and services can more 
effectively conform to personal intentions, activities, 
favorites, 
records, 
surrounding 
environments, 
social 
networks and crowdsourced information. 
 
Figure 1.  Context dependent states with wearable systems are 
automatically learned and identified by the Personal Speech Assistant of 
DNN, which continously offers relevant and appropriate services. 
Therefore, the proposed system, TouchWear, aims to use 
wearable computers to present contextual, automated sensing 
as well as a service-oriented workflow for human 
computation (Figure 1). Furthermore, TouchWear is 
represented by the personal speech assistant (PSA) that 
models with continuous self-learning Deep Neural Networks 
(DNN), to transform and retrieve helpful, on-the-fly, 
historical, or even private information. Finally, the system 
provides mobile services that hinge on the infrastructure 
being successfully used in practical deployment. 
This paper introduces the implementation of our 
prototype application for wearable devices, which is built on 
context dependent and continuous information from the user 
perspective based on modern Artificial Intelligence of 
DNNs. TouchWear is designed according to the following 
four methods: (1) integration of previous research paradigms 
for recognizing user activity into the system, and the design 
of a system adapter for context awareness through the use of 
wearable devices; (2) evaluation of learning patterns from a 
user’s behavior and a conversation proposed by the PSA, and 
performance of continuously self-learning AI model based 
on DNNs, where the system adapter is flexible enough to 
manage either notifying the PSA of recognized contexts, or 
perceiving new contexts; (3) design of a message extractor 
and filter to better address the user’s contextual query, while 
at the same time, personalized results retrieved and generated 
by the PSA processed every now and then; (4) 
implementation of an infrastructure for mobile service-
oriented applications (SOAs), which model the business 
requirement and bring services via specially designed user 
interfaces.
25
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

               
 
Figure 2.  TouchWear system architecture – an overview of wearable application. 
The organization of this paper is presented as follows: 
Section II provides a review of the previously related works. 
Section III depicts the design of the system architecture and 
its challenges. Section IV evaluates the use cases and 
preliminary results, and finally, Section V concludes the 
paper with our current plan for the future work. 
II. 
RELATED WORK 
In recent years, research has discussed many areas that 
are related to our work, such as Human Activity Recognition 
(HAR) [1][5][6] on mobile devices, which helps us 
understand how to analyze user’s wearable sensory systems 
and the designed interfaces [2][3] for perceiving contexts. 
Context-awareness involves the concept of sensing oneself in 
a context, which means tracking ‘Head-Centered and 
Context-Aware Learning’ [12][15][16] on a wearable device, 
and also exploring the surrounding environments. Pervasive 
computing to address location-awareness [4] has also drawn 
considerable attentions in the development of wearable 
computers [7]. Other related work on wearable devices 
tackles privacy-preserving issues [11] on a crowd-powered 
system, which also inspires us for designing and enhancing 
our information retrieval, filtering, and extraction. 
Furthermore, conversational agents with Artificial 
Intelligence are becoming increasingly ubiquitous in 
business, technology and daily life. Relevant research on 
these agents describe PSA to recognize the disordered 
speech [18], Chatbots with a Support Vector Machine 
(SVM) classifier [9], end-to-end systems [21][22] to play the 
communication role to synchronize physical motoring [10], 
and DNN-based agents to build embedded questions and 
answers, based on bidirectional long short-term memory 
(LSTM) network to measure the cosine similarity [8][17]. 
In order to achieve ubiquitous data access on mobile and 
wearable computing in TouchWear, SOAs are practiced and 
designed due to the limited memory and connection 
bandwidth [13]. Based on the advocated services designed 
and implemented by SOAs [14], our proposed system is able 
to consider user’s adaptive contexts as predicted services via 
PSA more adequately and efficiently than the related works. 
III. 
SYSTEM ARCHITECTURE 
The system guides a user through the designed wearable 
application (Figure 2), while the PSA provides instructions 
and conversations on the voice-based application. The 
below steps present the processes, integrated frameworks, 
components and how they work together. 
A. Context Aware Sensing and Wearable Devices  
Contextual sensing is the most fundamental analysis of 
context-aware systems. TouchWear directly uses sensory 
data of Accelerometer, Gyroscope, and the signals of Global 
Positioning Systems (GPS) to detect a user’s activity and 
location, where Wi-Fi signals are also considered in the 
indoors [24]. With our wearable devices (Google Glass [25], 
Sony SmartEyeglass [26]) and producing data (frequency 
5Hz), the modeled SVM classifier is capable of recognizing 
targeted activity and location in around 3 seconds. 
B. Activity Recognition and System Adapter 
In Table 1, we depict six activities (both indoors and 
outdoors) in which TouchWear takes the detected context-
aware messages as prerequisite information to prepare for the 
conversations with the user. The system adapter, which is 
based on context awareness, will inform PSA per user’s 
request to initiate the conversation. As for the content of the 
conversation, the DNN will periodically notify the PSA via 
APIs if there is any update to the latest entropy. Furthermore, 
continuous self-learning occurs to conceive new contexts, 
such as new activities, or to improve accuracy of old ones. 
APIs can be triggered by the following: highly 
compressed formats, publishing and exchanging protocols, 
Web Services with SOAP, XML-based service invocation, 
JSON RESTful services implementing TouchWear, and 
interface compliance with Open Standard Gateway initiative 
(OSGi). The designed adapter needs not only to implement 
the regulations satisfying the requirement of each 
application, but also to use the exact pair of enterprise public 
and private key infrastructure (PKI), SSL, or the secure PGP 
encryption system [20] to cryptographically achieve needs. 
26
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

TABLE I.  
RECOGNIZED ACTIVITY AND LOCATIONS  
Smart Glasses Activity, Location, and Performance 
Activity  
Outdoor 
Indoor 
Performance 
driving 
city road, highway 
N/A 
87% 
jogging 
hiking route, 
mountain area 
gym, indoor 
stadium 
86% 
walking 
side walk, street 
building hallway, 
house 
88% 
sitting 
outdoor bench, 
park, open field 
office, study 
room, living room 
89% 
cooking 
BBQ, brewery area 
kitchen, dining 
room 
87% 
dining 
places for grilling, 
garden 
dining room, 
restaurant 
91% 
C. Database and Deep Neural Networks  
Early works on computer speech systems focused on 
rule-based or hand-crafted implementations to simulate 
human conversations [9]. However, it is very difficult to 
enumerate the real conditions and all possible states, 
especially in light of the great complexity of human 
language. For this reason, recent speech assistants and 
Chatbots in Recurrent Neural Networks (RNNs) of DNN 
have been shown to meliorate accuracy to improve 
performance. After the evaluations of two large datasets, the 
Cornell Corpus of movie dialogues and thousands of Twitter 
logs with Long Short-Term Memory networks (LSTMs), 
TouchWear takes sequence to sequence (seq2seq) learning 
process [23] to construct its memory dependent network by 
using the conversation logs at this stage. Information of 
personal (such as emails) and social (Emails, tweets) is 
stored in the database server, and also continuously migrated 
to model the recurrent contextual information in the 
proposed system. 
D. Personal Speech Assistant 
The PSA, or AI Bot in TouchWear, is implemented by 
using the open-source project of Google Hangouts [30] to 
leverage current applications on our wearable platform. The 
AI Bot uses contextual information of activity recognition 
according to the wearable application; then, the AI Bot 
initials the automated service with example greetings such as 
“Hi buddy, would you like some music while driving?” or 
“Good morning John, how may I help you?”, which are the 
first contextual messages. In contrast to these examples in 
which the AI Bot initiates the conversation, users for 
instance can just simply say “Please mute, Bot” to switch it 
back to the on-demand service type. So, “OK, AI Bot” or “Hi 
Bot” are launched by user to converse with the AI Bot.  
 
 
Figure 3.  (A) Loss, (B) Accuracy: Training after 1000 epochs, where 
three testing datasets were evaluated. 
There 
were 
three 
testing 
datasets 
that 
contain 
conversation logs trained by the LSTMs in our DNN. Since 
the seq2seq training processes use the same training data to 
validate the model in each epoch done by TensorFlow [27] 
and tflearn [28] frameworks, an iteration of 1000 epochs 
generates a loss of 0.00385 and an approaching accuracy of 
1.00000 near the 400th epoch visualized on the tensorboard 
[27] (Figure 3). 
E. Filter and Extractor 
The retrieved responses are provided by AI Bot 
according to the deep learning from ongoing conversations, 
user Email threads, and simulated social tweets. TouchWear 
currently uses four categories to filter and extract the results, 
as shown in Table II. The four categorized directories in the 
system are regular and critical for personal information, and 
regular and privacy preserving for social information. 
Accordingly, the authentication plays a vital role in the 
‘critical’ category for personal information, whereas filtered 
datasets, using metadata and programming, are particularly 
essential for the ‘privacy preserving’ category for social 
information. 
TABLE II.  
INFORMATION FILTER AND EXTRACTOR 
Information 
Type 
Category vs. Filter and Extractor 
Category 
Filter 
Extractor 
personal 
information 
regular 
none 
ranking 
critical 
authenticated 
by secure 
frameworks 
extracted ranking 
based on secure 
frameworks 
social 
informaion 
regular 
defined rules 
ranking 
privacy 
preserving 
filtered datasets 
extracted ranking 
based on filtered 
datasets 
F. Service-Oriented Mobile Application  
Mobile SOAs are examined and designed for 
TouchWear. The backend servers receive user commands 
through the PSA, and the commands are executed by 
contracting the system APIs of the targeted application. If the 
syntax is complying with the regulations and if the user’s 
authentications are authorized, the provisioning applications 
will be triggered and planned toward the completion to meet 
business requirements. At the present time, the system has 7 
mini services (or groups) to evaluate the system integrity in 
the experimental and validating phase. Table III below 
shows the list of SOA mini-services, where the services with 
asterisk have the permission to access the personal contacts. 
TABLE III.  
SOA MINI SERVICE LIST 
SOA Services 
1. Voice or video call * 
2. Search and play music (personal music albums) 
3. Facility automation 
4. Search ‘keyword’: conversation logs, Email * 
5. Social networks: recommendation for shopping and entertainment * 
6. GPS navigation setup  
7. Food / restaurant search and reference  
27
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

G. Other System Frameworks 
The system stands on the top of TensorFlow to build up 
DNNs with LSTM RNN, which is implemented by seq2seq 
learning process. In seq2seq, the encoder and decoder take 
the input and generate the output based on the semantic 
contexts. In our experiments, we observed that LSTM could 
learn to spell words and copy general syntactic structures to 
capture the essence of the input sentences. Thus, the system 
was prepared with initial trials of training data that consisted 
of 1025 Email threads, 480 lines of conversation log on 
Hangouts, and dozens of social tweets simulated by the 
open-source SocialEngine [29]. 
IV. 
USE CASES AND PRELIMITARY RESULTS 
We began our project with the aim of studying how to 
recognize activity and location by using sensors on wearable 
devices. The current system can recognize three activities, 
driving, jogging, walking with an accuracy up to 87% and its 
performance is getting better in our experiments. However, 
though sitting can be recognized with accuracy 89%, it is 
more difficult to distinguish dining and sitting since both are 
very similar, unless additional sensors like the camera and 
Wi-Fi signals are applied, same as for cooking as well. For 
information extraction and filtering, the current system ranks 
results with descending score and/or reverse chronicle order, 
and the top one will return to the query each time. 
Initial trials of use cases were conducted using 11 types 
(omitting indoor driving) according to 6 indoor and outdoor 
activities that were recognized by the system. From the 
user’s perspective, contextual services and conversing 
accuracy are the most important parts. Two use cases are 
demonstrated in Figure 4, where (a) a user is heading to work 
by driving and was successfully recommended an enjoyable 
song, and (b) a user is walking and located close to home or 
is on the way home, and the recipe recommendation of 
dinner is offered by AI Bot. 
 
     
      
 
                     (a)                                                 (b) 
Figure 4.  Demonstrated use cases (a) driving, (b) walking. 
TABLE IV.  
SURVEY AND POSITIVE RESPONSES 
Interview Questions 
Positive Responses 
Q1. Are context-aware PSAs more 
perceived and helpful? 
87.5% 
Q2. How is the performance by using 
contextual PSA with DNNs and SOA? 
83.3% 
Also, the filtered datasets are designed to authenticate 
users before accessing their personal information so as to 
protect their privacy, where defined rules are given to control 
sharing and prevent the leaking of private information. 
Shared topics include food, entertainment, shopping 
experiences in Emails and tweets, with the removal of 
critical data according to filtered datasets. The initial trials 
were conducted in a proof-of-concept system, and the results 
show that the performance is very high regarding context-
awareness, the conversation accuracy of LSTMs and the 
targeted SOAs in the laboratory, though more calibrations to 
our system are still further required, such as ‘machine-
learning search’, ‘social sharing’ and ‘location precision’. 
The survey from our user study with 16 participants 
shows that the proposed system was more preferred than 
systems without context-awareness (Table IV): (i) the 
wearable platform with context-aware PSAs were found to 
be more advantageous, as helpful aids and with more 
perceived accuracy; (ii) the performance of the contextual 
PSAs was seen as more resembling a real and constructive 
intelligent agent that assists people in their daily life. These 
PSAs were based on the security and the preservation of 
privacy of personal and social information on LSTMs, and 
the designed SOA mobile applications also offer contextual 
services per user’s requests. 
V. 
CONCLUSION AND FUTURE WORK 
TouchWear proposes a unique system design for the 
proposed wearable application that exploits the contextual 
information for future wearable systems, by integrating a 
wearable platform, context-aware computing, PSAs, and 
modeling and modification of DNNs with recurrent neural 
networks, with the aim to design more intelligent solutions 
for problems that emerge in daily living. Moreover, the 
system is tailored to user-centric requirements and services 
effectively extracted by the designated information retrieval. 
Likewise, service operations are explicitly performed by the 
SOA-based mini services of mobile applications. Compared 
to systems without contexts, the proposed contextual DNNs 
significantly outperform the accuracy of conversation 
exchanges, start automated workflows for predicting and 
comprehending user’s status, and take into account user 
favorites, demands and social associations by using the AI 
Bot more intimately. The continuous self-learning processes 
are clearly able to achieve more system genuineness, 
usability and user-friendliness. Our implementation was also 
more favored by the users according to the interviews. The 
insightful design of the application is promising and can be 
extended to the benefit of many people, their workplaces, 
and homes. If this forthcoming system is extensively 
adopted, we anticipate in the future that optimal context-
awareness and context-intelligent wearable computing will 
be achieved in addition to Artificial Intelligence. 
In our future work, we will focus other subsets of DNNs 
for any domain, investigate more use cases of search and 
social application, and identify and design more scenarios for 
disability-oriented systems in wearable computing. We hope 
our upcoming systems will assist more people in their daily 
living and activities. 
28
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

REFERENCES 
 
[1] Lara, Oscar D., and Miguel A. Labrador. “A Survey on 
Human Activity Recognition Using Wearable Sensors.” IEEE 
Communications Surveys and Tutorials, vol. 15, no. 3, 2013, 
pp. 1192–1209. 
[2] Patel, Shyamal, et al. “A Review of Wearable Sensors and 
Systems with Application in Rehabilitation.” Journal of 
Neuroengineering and Rehabilitation, vol. 9, no. 1, 2012, pp. 
21–21. 
[3] Mistry, Pranav, et al. “WUW - Wear Ur World: A Wearable 
Gestural Interface.” CHI ’09 Extended Abstracts on Human 
Factors in Computing Systems, 2009, pp. 4111–4116. 
[4] Ashbrook, Daniel, and Thad Starner. “Using GPS to Learn 
Significant Locations and Predict Movement across Multiple 
Users.” Ubiquitous Computing, vol. 7, no. 5, 2003, pp. 275–
286. 
[5] Lee, Seon-Woo, and Kenji Mase. “Activity and Location 
Recognition Using Wearable Sensors.” IEEE Pervasive 
Computing, vol. 1, no. 3, 2002, pp. 24–32. 
[6] Ho, Joshua, and Chien-Min Wang. “User-Centric and Real-
Time Activity Recognition Using Smart Glasses.” GPC, 2016, 
pp. 196–210. 
[7] Pascoe, Jason. “Adding Generic Contextual Capabilities to 
Wearable 
Computers.” Digest 
of 
Papers. 
Second 
International Symposium on Wearable Computers (Cat. 
No.98EX215), 1998, pp. 92–99. 
[8] Tan, Ming, et al. “LSTM-Based Deep Learning Models for 
Non-Factoid 
Answer 
Selection.” ArXiv 
Preprint 
ArXiv:1511.04108, 2015. 
[9] Joelianto, Endra, and Bowo Prakoso. “Support Vector 
Machine Classifier Based on Approximate Entropy Metric for 
Chatbot Text-Based Communication.” International Journal 
of Artificial Intelligence, vol. 15, no. 1, 2017, pp. 1–16. 
[10] Johnson, Alex, et al. "Implementing Physical Capabilities for 
an Existing Chatbot by Using a Repurposed Animatronic to 
Synchronize Motor Positioning with Speech." International 
Journal of Advanced Studies in Computers, Science and 
Engineering 6.1 (2017): 20. 
[11] Swaminathan, Saiganesh, et al. “WearMail: On-the-Go 
Access to Information in Your Email with a Privacy-
Preserving Human Computation Workflow.” Proceedings of 
the 30th Annual ACM Symposium on User Interface Software 
and Technology, 2017, pp. 807–815. 
[12] Krause, 
Andreas, 
et 
al. 
“Unsupervised, 
Dynamic 
Identification of Physiological and Activity Context in 
Wearable 
Computing.” Seventh 
IEEE 
International 
Symposium on Wearable Computers, 2003. Proceedings., 
2003, pp. 88–97. 
[13] Natchetoi, Yuri, et al. “Service-Oriented Architecture for 
Mobile Applications.” Proceedings of the 1st International 
Workshop on Software Architectures and Mobility, 2008, pp. 
27–32. 
[14] Taktak, Hajer, and Faouzi Moussa. “A Service-Oriented 
Application Creation Process in Ubiquitous Environments: 
Travel Assistant Mobile Application.” International Journal 
of Pervasive Computing and Communications, vol. 13, no. 3, 
2017, pp. 300–330. 
[15] Kuhn, Jochen, et al. “GPhysics—Using Smart Glasses for 
Head-Centered, 
Context-Aware 
Learning 
in 
Physics 
Experiments.” IEEE Transactions on Learning Technologies, 
vol. 9, no. 4, 2016, pp. 304–317. 
[16] Kim, Ki Joon, and Dong-Hee Shin. "An acceptance model for 
smart watches: Implications for the adoption of future 
wearable technology." Internet Research 25.4 (2015): 527-
541. 
[17] Kandasamy, Kirthevasan, et al. “Batch Policy Gradient 
Methods 
for 
Improving 
Neural 
Conversation 
Models.” International 
Conference 
on 
Learning 
Representations, 2017. 
[18] Cavalcante, Agnieszka Bętkowska, and Monika Grajzer. 
“Mobile and Personal Speech Assistant for the Recognition of 
Disordered Speech.” SPWID 2016, The Second International 
Conference on Smart Portable, Wearable, Implantable and 
Disability-Oriented Devices and Systems, 2016, pp. 6–10. 
[19] López, Gustavo, et al. “Alexa vs. Siri vs. Cortana vs. Google 
Assistant: A Comparison of Speech-Based Natural User 
Interfaces.” International Conference on Applied Human 
Factors and Ergonomics, 2017, pp. 241–250. 
[20] Hankerson D. Hernandez J.L. Kirkup M.Menezes A. Brown 
M., Cheung D. PGP in constrained wireless devices. In 9th 
USENIX Security Symposium., 2000. 
[21] Yang, X., Chen, Y.-N., Hakkani-Tur, D., Crook, P., Li, X., 
Gao, J., and Deng, L. (2016). End-to-End Joint Learning of 
Natural Language Understanding and Dialogue Manager. 
ArXiv e-prints.  
[22] Ali Orkan Bayer, Evgeny A. Stepanov, and Giuseppe 
Riccardi. Towards end-to-end spoken dialogue systems with 
turn embeddings. In Annual Conference of the International 
Speech 
Communication 
Association 
(INTERSPEECH), 
Stockholm, Sweden, August 2017. ISCA.  
[23] Sutskever, I. Vinyals, O. & Le. Q. V. Sequence to sequence 
learning with neural networks. In Proc. Advances in Neural 
Information Processing Systems 27 3104–3112 (2014). 
[24] FIND3, “FIND3,” https://github.com/schollz/find3, July 16, 
2018. 
[25] Glass 
Explorer 
Edition, 
“Glass 
Explorer 
Edition,” 
https://developers.google.com/glass/, July 16, 2018. 
[26] Sony Smarteyeglass SED-E1, “Sony Smarteyeglass SED-E1,” 
https://developer.sony.com/develop/smarteyeglass-sed-e1/, 
July 16, 2018. 
[27] TensorFlow, “TensorFlow,” https://www.tensorflow.org, July 
16, 2018. 
[28] tflearn, “tflearn,” https://www.github.com/tflearn/tflearn, July 
16, 2018. 
[29] SocialEngine, “SocialEngine,” https://www.socialengine.com, 
July 16, 2018. 
[30] Google Hangouts, “Hangouts,” https://hangouts.google.com, 
July 16, 2018. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
29
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

Stress Detection of the Students Studying in University using Smartphone Sensors
Ghulam Hussain1, Muhammad Shahid Jabbar1, Sangmin Bae1, Jun Dong Cho1,2
1School of Electrical and Computer Engineering, Sungkyunkwan University, South Korea
2School of Electrical and Computer Engineering, North University of China, Taiyuan, Shanxi, China,
Email: hussain@skku.edu,eeshahid@skku.edu,kyuwona@naver.com,jdcho@skku.edu
Abstract—Stress leaves a harmful impact on the health of people
and puts their health at serious risk. To assess stress, this study
presents an approach to measure the stress levels of graduate and
undergraduate students by analyzing the activity behavior of their
daily routine. Our approach monitors the activity behavior non-
invasively using the smartphone sensors. The activity behavior
is classiﬁed into three classes with an accuracy of 98.0% using
a support vector machine. We build linear relationship between
those recognized classes of activity (explanatory variables) and
stress level experienced by the students. This approach is based
on multiple linear regression that computes a stress score, and
categorizes stress in three levels: low, mild, and acute. Such results
illustrate that the graduate students experience high stress as
compared to the undergraduate students.
Keywords–Stress; activity and sleep behavior; smartphone sen-
sors.
I.
INTRODUCTION
A natural defense of the human body, also known as
stress, protects individual against any danger. Stress for a short
time can be helpful, but long-term stress can negatively affect
health. People suffer from stress when they are overloaded and
feeling an inability to cope with the demands. Stress is a state
in which individuals are expected to perform too much under
sheer pressure and in which they can only marginally meet
the demands. These demands can be related to psychology,
ﬁnance, work, and relationships that pose a real challenge or
threat to health, and well-being of individuals. If stress is
not timely cured and the person is going through constant
stress, it can affect human body with headache, depression
[1], heart attack [2]-[4], stomachache, high blood pressure,
insomnia, and weakened immune system. Clinically, subjective
methods such as questionnaires and interviews are conducted
to evaluate stress, whereas for objective assessment of stress,
many researchers presented their works to detect stress [5]-
[11]. However, they tried to measure stress using like inva-
sive sensors EEG [5][9][10], ECG [11], and Galvanic Skin
Response (GSR) [6]. EEG or ECG sensors provide state-
of-the-art accuracy for stress detection. However, the usage
of EEG or ECG to analyze stress is impractical in real-life
settings, because people do not feel comfortable to go outside
in public places wearing EEG or ECG in their daily-life.
People suffering from stress may not choose to openly wear
the device because stressed persons are already shy to express
themselves and therefore, such wearables may not be socially
acceptable to them. Moreover, the efﬁciency of these devices
degrades as users perform any motion-related task. To the best
of our knowledge, no one has designed a system for non-
invasive detection of stress yet. Therefore, we are motivated
to design non-invasive stress detection system.
Stress score
Microphone
Audio input
Accelerometer 
and gyroscope
Motion input
Smartphone sensors
Activity Recognition
Data analytics
Figure 1. An architecture of stress monitoring system.
Stationary
Moving
Sleepingy
Figure 2. Subject while performing different activities.
In this paper, we present a novel system to measure the
stress of the university students by analyzing their activity be-
havior in daily routine. We choose undergraduate and graduate
students to evaluate their stress level, because they are more
vulnerable to stress due to a variety of challenges such as poor
academic performance [12], ﬁnances [13], poor sleep [14], and
inability to cope with research demands of supervisor. Besides,
high rates of suicide in American and Asian countries are
associated with academic related stress [15]. It is imperative
to take preventive measures for protecting the students from
deleterious outcome associated with stress by monitoring their
daily activity behavior.
We have broadly categorized the daily-life routine of the
students into three clusters: stationary, moving, and sleeping.
We think that poor sleep and sedentary behavior (i.e., sta-
tionary) are two main indicators of stress, whereas movement
behavior of person signiﬁes less stressed or happy man. Our
system consists of motion and audio sensors that records
input data with the assistance of an application (App) running
on a smartphone. We exploit the motion sensors namely
accelerometer and gyroscope-sensors and a microphone sensor
of the smartphone as the primary sources of data input to
our system. The motion sensors record the activity behavior
and the audio sensor records voice signal of the participants
30
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

at the rate of 10 samples/second and 44100 samples/second,
respectively, as shown in Figure 1. The activity recognition
algorithm is applied to the acquired signals, and recognized
activity behavior is transmitted to the cloud server for data
analysis to detect stress.
This paper is organized as follows. In Section II, we
describe the experimental setup to collect raw data using the
smartphone sensors and the proposed approach. In section III,
we discuss and evaluate the system performance for stress
detection based on the daily activity behavior.
II.
MATERIALS AND METHODS
Our approach employs tri-axial accelerometer, tri-axial
gyroscope, and microphone of a smartphone. An accelerometer
and gyroscope are dedicated to measuring acceleration and
angular velocity of the subjects during stationary, moving, and
sleeping states, whereas the microphone records surrounding
noise level when subjects are in stationary and sleeping states.
Figure 2 depicts the three of the activities performed by the
subject while the smartphone is in the proximity to him.
Smartphone app developed by MATLAB is responsible for
collecting the experimental data and transmitting the data to
the cloud server for further analysis.
A. Experiment Design
We recruited 32 students (16 graduate and 16 under-
graduate) of Sungkyunkwan University, average age of 29.7
years with standard deviation of 10.6 years, to analyze our
envisioned system. Subjects signed consent form prior to the
experiment and whose rights have been protected following
declaration of Helsinki. Selected Subjects had no head injury
and were not using any medication. We employed same man-
ufacturer and same model smartphone, iPhone 6, for recording
the daily activity experimental data, because the majority of
participants in the trial had an iPhone 6, and since the idea
was to let the participants use the same type of smartphone
so as to avoid the normalization problem of the activity data.
Each participant recorded their 24 hour activity of daily routine
which constituted experimental data of 768 hours. If a person
is sleeping, the amplitude generated by a microphone is either
near to zero or very small due to snoring, whereas when subject
wakes up, he/she has to say “good morning” or “hello”, and
as to signal the microphone that the subject has woken up,
and similarly, subject has to utter “good night” to indicate
beginning of sleep. The words spoken at the time of before
and after the sleep helps in determining sleep duration of the
subject automatically. All participants also participated in a
stress-related survey. The data of 25 hours were discarded
because some participants could not carry mobile in some
unavoidable situations. The students were grouped into two
clusters based on educational degree they are currently pursu-
ing in the university: graduate and undergraduate. The daily
routine information of both groups forms experimental data
for activity recognition. Acquired signals of the sensors are
segmented into non-overlapping segments of 20 seconds. The
segment length of 20 seconds was selected based on the best
performance of activity recognition classiﬁer after exploring
a range of 3 to 30 seconds. The activity information was
annotated into three classes: stationary, moving, and sleeping.
B. Proposed Approach
Our system for stress detection has three stages. Subjective
assessment is performed about stress through a survey in
stage one. In stage two, subject’s activity of the whole day is
recognized, and stress level is detected based on the recognized
activity information in stage three. The activity information
is comprised of three broad classes: stationary, moving, and
sleeping. Our system tries to recognize these activities using
an activity recognition classiﬁer. We think that these three
classes of activities are essential to determine stress of the
university student. We have exploited participants’ interaction
with a smartphone to indirectly determine their stress level. If
participant is stressed, he/she suffers from insomnia and often
remains in stationary activity. Therefore, we exploited subjec-
tive assessment and daily activity information of participants
to calculate their stress levels. The proposed approach tries
to exploit relation of sleep, stationary, and moving activities
with stress using linear regression. We think that the pressure
of supervisor and fear of failure causes the student to sleep
less and study for long hours, whereas a person who sleeps
less and stays stationary longer than usual becomes victim of
stress. Therefore, it is very important to address the problem
of stress faced by the university students using a novel non-
invasive approach.
C. Activity Recognition
The distinct patterns as shown in (Figures 3(a) to 3(f)) were
generated by the motion sensors of smartphone according to
the activity subjects performed in their daily schedule. Three
segments of 40 seconds in Figure 3 demonstrate a difference
in acceleration and angular velocity of each activity. The
patterns of moving activity are clearly distinguishable from
the rest of the two activities. To some extent, patterns of
sleeping and stationary activity are obscure due to being same
in nature. For solving this problem, the microphone is used
to differentiate sleeping from stationary activity as shown in
Figure 4. We have modiﬁed the signal of audio input in order
to keep the privacy of subjects. Amplitude signal of audio input
during sleep stays approximate to zero, whereas the amplitude
during stationary (awake) state is higher as shown at extreme
ends of audio signal in Figure 4. Since, features play an
essential role in the recognition of activities, so features must
characterize the patterns effectively without carrying irrelevant
and redundant information so that activity recognition classiﬁer
perform efﬁciently. The amplitude based features are extracted
from segments of experimental data for training the activity
model. Those features are arithmetic mean, standard deviation,
interquartile range, kurtosis, geometric mean, median, maxi-
mum, range, skewness, energy of a signal, waveform length,
entropy, RMS and ratio of RMS to maximum.
Forward Features Selection (FFS) procedure is employed
on the computed features to reduce redundancy and avoid
overﬁtting. The top 6 features are selected using FFS and
those selected features are fed into Support Vector Machine
(SVM) to develop the activity recognition model. The activity
recognition model is trained and evaluated using a 32 fold
cross-validation technique with leave-one-out. This technique
allowed the training of the quadratic SVM on the features
from 31 out of 32 subjects and validated the model with
the remaining subject. The activity recognition algorithm has
classiﬁed the acquired signals of the sensors with an accuracy
31
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

0
10
20
30
40
-45
-32
-19
-6
7
Acceleration-X (m  s-2)
(a)
0
10
20
30
40
-5
-2
1
4
7
Angular Velocity-X(rad  s-1)
moving
stationary
sleeping
(b)
0
10
20
30
40
-15
-3
9
21
33
Acceleration-Y (m  s-2)
(c)
0
10
20
30
40
-4
-2
0
2
4
Angular Velocity-Y(rad  s-1)
moving
stationary
sleeping
(d)
0
10
20
30
40
-8
1
10
19
28
Acceleration-Z (m  s-2)
(e)
0
10
20
30
40
-5
-3
-1
1
3
Angular Velocity-Z(rad  s-1)
moving
stationary
sleeping
(f)
Figure 3. Motion sensors signals; (a), (c), and (e) represents Accelerometer
signals in x, y and z axes, whereas (b), (d), and (f) are Gyroscope signals in
x, y and z axes.
of 98.0% into three activity classes of stationary, moving, and
sleeping as shown in Figure 5. The moving class is comprised
of walking, running, and any other exercise involving the body
motion. SVM is a supervised machine learning algorithm. We
implemented SVM for activity recognition using classiﬁcation
learner tool in MATLAB 2016b. One-vs-all strategy and linear
kernel function k( ⃗Xt, ⃗Xi) = ⃗Xt, ⃗Xi is used whose penalty C
parameter is 1 by default.
D. Stress Detection
The activity information recognized by SVM is transmitted
to the cloud server for data analytics to detect stress (S) in
the students. We tried to search relationship between stress
and three activity classes: moving, stationary, sleeping. We
exploited different linear regression models to build a robust
model to estimate stress. Stationary and sleeping activities data
are included to develop the stress estimation model because
those two variables showed a signiﬁcant relationship with
stress, whereas moving activity data was discarded after it
showed no any signiﬁcant improvement in the model. We have
computed stress score using (1). We think that sleep duration
and stationary activity are essential explanatory variables to
0
1
2
3
4
5
6
7
Time(hours)
-0.6
-0.3
0
0.3
0.6
Audio signal
Sleeping
Stationary (awake)
Figure 4. Audio signals for sleeping activity.
stationary
moving
sleeping
Recall(%)
stationary
moving
sleeping
Precision(%)
SVM
64248
24
1238
98.1%
21
8982
5
99.7%
1358
19
58470
97.7%
97.9%
99.5%
97.9%
98.0%
Figure 5. Activity recognition performance of SVM.
determine the stress levels.
S = aX + bY + θ
(1)
where X and Y represents stationary and sleeping activity
classes, whereas a, b, and θ are parameters.
We employed curve-ﬁtting tool of MATLAB 2016b to
evaluate the proposed model, and determined the values of
a, b, and θ using least square method. As shown in Table I,
the parametric values of the proposed approach are calculated
as 0.176, -0.386, and 3.01 for a, b, and θ, respectively. The
pvalues of stationary and sleeping variables are lower than
0.05 which proved the statistical signiﬁcance of the earlier
mentioned variables in estimating the stress score. The adjusted
R-Squared value is 0.909 which means 90.9% variance in
stress is successfully explained by the proposed model based
32
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

on two explanatory variables (i.e., stationary and sleeping).
Stationary has the effect of a on the stress score, whereas
sleeping affects the stress score by factor of b. All the pa-
rameters have a partial effect on stress. The parametric values
of (1) shown in Table I suggest that sleeping has a higher
effect on stress score than stationary, because parameter b is
higher in weight than parameter a. If both the variables are
0 in values, then parameter θ affects estimated stress highly.
Stress reduces when sleep time increases and vice versa. On
the contrary, stationary activity is directly proportional to the
stress.
TABLE I. LINEAR REGRESSION ANALYSIS OF PROPOSED MODEL
Estimated
Standard
t Statistic
P value
parameters
error
Intercept
3.01
0.78263
3.8429
0.00061
Stationary
0.176
0.04124
4.2701
0.00019
Sleeping
-0.386
0.05506
-7.011
1.0393e-07
Number of observations
32
Root Mean Squared Error
0.287
R-squared
0.915
Adjusted R-Squared
0.909
Three levels of stress are calculated based on lower and
upper thresholds. Those three levels of stress are low, mild,
and acute. If S < δ1, the subject is less stressed or normal,
he has a mild stress if δ1 ≤ S ≤ δ2, and he has an acute
stress if S > δ2. The δ1 and δ2 represents lower and upper
thresholds. Stress level scores for all the students is computed.
The result of stress computation shown in Figures (5(a) to
5(b)) has demonstrated that 2 graduate student have acute or
high stress and 2 others out of 16 graduate students have mild
stress, whereas only 3 out of 16 undergraduate students have
mild stress. This statistics of stress experienced by students has
validated our claim that graduate students have higher average
stress as compared to the undergraduate students due to poor
sleep and higher sedentary or stationary behavior.
III.
DISCUSSION AND CONCLUSION
The focus of our research was to present an approach to
detect stress levels experienced by the students. Our approach
uses non-invasive strategy to monitor the three levels of stress
in the subjects using a commonly available electronic device
(smartphone). We employed the motion sensors and audio
sensor of the smartphone to record the overall activity of
the individuals. Prior studies have considered stress detec-
tion with EEG, ECG and Galvanic Skin Response (GSR)
[3][6][9][10][11] which provide a direct method to measure
stress and are preferred choice of users in indoor settings, but
these devices are socially unacceptable to people going out
in public places (i.e., school, ofﬁce, shopping market, etc.,)
while wearing these measurement devices. Our non-invasive
method based on the smartphone is user friendly and socially
acceptable to users, because the smartphone sensors do not
interfere with their daily work and they can use the smartphone
to measure their stress levels in public places without letting
anybody know.
We have analyzed our approach using two groups of the
students. The smartphone recorded the activity of students
when they performed routine tasks without interfering in their
daily-life tasks. An experiment was performed in order to
obtain activity data on the basis of which, stress scores or levels
4
5.5
7
8.5
10
1
2
3
4
5
(a)
7
8.75
10.5
12.25
14
15.75
1
2
3
4
5
(b)
0
1
2
4
3
4
5
15
6
10
8
10
5
(c)
Figure 6. Stress relation with daily life activity behavior (a) Effect of
Sleeping activity on Stress Score, (b) Effect of Stationary activity on Stress
Score, and (c) 3D curve ﬁtting of the proposed model.
can be detected. The activity recognition classiﬁer grouped
the daily-routine behavior of the subjects into three classes:
moving, stationary, and sleeping. We experimentally evaluated
three of the activity classes to build statistical models for
stress computation, but the model is built on only stationary
and sleeping classes. Moving activity did not contribute any
signiﬁcant information about stress in the model, therefore, it
is discarded. Stationary and sleeping are two broad classes
of activity which are essential to assess someone’s stress
level. The estimation of stress levels by proposed approach
is demonstrated in Figures (6(a) to 6(b)). The curve ﬁt of
the stress estimation model is shown in Figure 6(c) which
depicts the inverse relationship of sleeping with stress and
direct effect of stationary on the stress. The conclusion drawn
from proposed model also agrees with the previous studies
that stress causes poor sleep [16][17] and high stationary or
sedentary behavior [17] is related to stress.
We experimentally found that graduate students suffer
higher stress than the undergraduate students studying in the
university. Our proposed strategy determined the stress of the
students and 2 out of 16 graduate students is suffering from
acute or high stress, 2 out of 16 graduate students have mild
stress, whereas only 3 out of 16 undergraduate students have
mild stress. It is not possible that people carry the smartphone
all the time, so it is a limitation of our approach. We will
try to integrate motion and biological sensors in arm band
or embed to T-shirt for monitoring the activity of individuals
and notifying them about their stress levels in real-time as our
future work.
We have presented a novel approach based on smart-
phone sensors to measure the stress level of graduate and
undergraduate students studying in the university. Our system
has determined three stress levels by analyzing the activity
behavior and experimentally found that graduate students are
33
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

more stressed than undergraduate students.
ACKNOWLEDGMENT
This research was supported by Basic Research Program
through the National Research Foundation of Korea (NRF)
funded by Ministry of Science, ICT & Future Planning
(2017R1D1A1B03031323). We thank all participants who took
part in this study. We also thank anonymous reviewers who
assisted in improving the manuscript by providing valuable
suggestions.
REFERENCES
[1]
R. S. Duman, “Neurobiology of stress, depression, and rapid acting
antidepressants: remodeling synaptic connections,” Depression and anx-
iety, vol. 31, no. 4, 2014, pp. 291–296.
[2]
F. Lederbogen, et al., “City living and urban upbringing affect neural
social stress processing in humans,” Nature, vol. 474, no. 7352, 2011,
p. 498.
[3]
A. P. Allen, P. J. Kennedy, J. F. Cryan, T. G. Dinan, and G. Clarke,
“Biological and psychological markers of stress in humans: focus on the
trier social stress test,” Neuroscience & Biobehavioral Reviews, vol. 38,
2014, pp. 94–124.
[4]
H. Ursin and H. R. Eriksen, “The cognitive activation theory of stress,”
Psychoneuroendocrinology, vol. 29, no. 5, 2004, pp. 567–592.
[5]
A. R. Subhani, et al., “Machine learning framework for the detection
of mental stress at multiple levels,” IEEE Access, vol. 5, 2017, pp.
13 545–13 556.
[6]
A. de Santos Sierra, C. S. ´Avila, J. G. Casanova, and G. B. del Pozo, “A
stress-detection system based on physiological signals and fuzzy logic,”
IEEE Transactions on Industrial Electronics, vol. 58, no. 10, 2011, pp.
4857–4865.
[7]
S. Kontaxis, et al., “Mental stress detection using cardiorespiratory
wavelet cross-bispectrum,” in Computing in Cardiology Conference
(CinC), 2016.
IEEE, 2016, pp. 725–728.
[8]
S. Ollander, C. Godin, A. Campagne, and S. Charbonnier, “A compari-
son of wearable and stationary sensors for stress detection,” in Systems,
Man, and Cybernetics (SMC), 2016 IEEE International Conference on.
IEEE, 2016, pp. 004 362–004 366.
[9]
G. Jun and K. Smitha, “Eeg based stress level identiﬁcation,” in
Systems, Man, and Cybernetics (SMC), 2016 IEEE International Con-
ference on.
IEEE, 2016, pp. 003 270–003 274.
[10]
N. Adnan, Z. H. Murat, R. S. S. A. Kadir, and N. H. M. Yunos, “Uni-
versity students stress level and brainwave balancing index: Comparison
between early and end of study semester,” in Research and Development
(SCOReD), 2012 IEEE Student Conference on.
IEEE, 2012, pp. 42–
47.
[11]
A. Secerbegovic, S. Ibric, J. Nisic, N. Suljanovic, and A. Mujcic,
“Mental workload vs. stress differentiation using single-channel eeg,”
in CMBEBIH 2017.
Springer, 2017, pp. 511–515.
[12]
N. Sohail, “Stress and academic performance among medical students,”
J Coll Physicians Surg Pak, vol. 23, no. 1, 2013, pp. 67–71.
[13]
M. Ho, V. Wong, P. Chow, and W. Cheng, “A study on nursing stu-
dentsstress in hong kong,” HNE Handover: For Nurses and Midwives,
vol. 8, no. 2, 2015.
[14]
M. A. Sawah, et al., “Perceived stress and coffee and energy drink
consumption predict poor sleep quality in podiatric medical students:
a cross-sectional study,” Journal of the American Podiatric Medical
Association, vol. 105, no. 5, 2015, pp. 429–434.
[15]
F. T. Leong, M. M. Leach, C. Yeh, and E. Chou, “Suicide among asian
americans: What do we know? what do we need to know?” Death
Studies, vol. 31, no. 5, 2007, pp. 417–434.
[16]
C. Alc´antara, et al., “Stress and sleep: Results from the hispanic
community health study/study of latinos sociocultural ancillary study,”
SSM-population health, vol. 3, 2017, pp. 713–721.
[17]
J. E. Pelletier, L. A. Lytle, and M. N. Laska, “Stress, health risk
behaviors, and weight status among community college students,”
Health Education & Behavior, vol. 43, no. 2, 2016, pp. 139–144.
34
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-657-6
SPWID 2018 : The Fourth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems
Powered by TCPDF (www.tcpdf.org)

