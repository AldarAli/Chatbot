Exploring Test Composition: Towards Reusability in Combinatorial Test Design
Anna Zamansky
University of Haifa
Haifa, Israel
Email: annazam@is.haifa.ac.il
Eitan Farchi
IBM Research
Haifa, Israel
Email: farchi@il.ibm.com
Abstract—Combinatorial test design (CTD) is an effective test
planning technique that reveals faulty feature interaction in a
given system. CTD takes a systematic approach to formally model
the system to be tested, aiming to minimize the number of test
cases while ensuring coverage of given conditions or interactions
between parameters. Since the system model and its test space
in real-life cases are usually enormous, the process of creation of
new tests is very expensive. This naturally leads to the need for
exploring ways in which reuse methodologies can be incorporated
into CTD practices. In this paper, we extend the standard CTD
framework to a reuse-oriented setting by incorporating the notion
of test composition. This notion arises naturally in sequential
testing scenarios, where the output of one test is used as the
input of the next test. Based on the proposed framework, we
propose a reuse-oriented reformulation for the CTD problem,
with the composability of test plan being the main consideration.
Keywords–combinatorial test design; pairwise testing
I.
INTRODUCTION
As software systems become increasingly complex, ver-
ifying their correctness is even more challenging. Formal
veriﬁcation approaches are highly sensitive to the size of
complexity of software, and might require extremely expensive
resources. Functional testing, on the other hand, is prone to
omissions, as it always involves a selection of what to test
from a potentially enormous space of scenarios, conﬁgurations
or conditions that is typically exponential in nature.
The process of test planning refers to the design and selec-
tion of tests out of a test space aiming at reducing the risk of
bugs while minimizing redundancy of tests. Combinatorial Test
Design (CTD) ([1], [2]) is an effective test planning technique,
in which the space to be tested, called a combinatorial model,
is represented by a set of parameters, their respective values
and restrictions on the value combinations [3]. The approach of
CTD can be applied at different phases and scopes of testing,
including end-to-end and system-level testing and feature-,
service- and application program interface-level testing.
The standard general formulation of the CTD problem
consists of ﬁnding a small (and ideally minimal) set of test
cases (a subset of the space to be tested), which ensures
coverage of given conditions, or interactions between variables
(such as pairs, three-way, etc.) The most common special
case of the CTD problem is pairwise testing, in which the
interaction of every pair of parameters must be covered. This
is justiﬁed by experiments showing that a test set that covers all
possible pairs of parameter values can typically detect between
50 to 75 percent of the bugs in a program [4].
The process of building combinatorial models for CTD is a
laborious and error-prone task, which involves ﬁnding a set of
parameters and values that deﬁne the test space and correctly
identifying all valid value combinations. One potential pitfall
of this process is omissions, i.e., failing to include an important
parameter, value or combination of parameter values in the
test space. Another pitfall is failing to correctly deﬁne the
restrictions so that they capture the intended cobminations.
Providing support for the test space deﬁnition process is a
crucial factor in a successful application of CTD techniques to
a wide range of testing domains. IBM’s tool FoCuS [5] aims to
automatically assist the tester in the solution of CTD problems
by constructing the test space efﬁciently, while considerably
reducing the risk of omissions. In [3] recurring patterns in
CTD models were studied. These patterns capture cases that
often repeat in different CTD models of different types and
from different domains. Solutions for how to translate them
into parameters, values and restrictions already exist, and thus
can fascilitate model reuse.
In this paper, we address another type of reuse in CTD,
namely test reuse. Addressing this problem is important, as
the test space in real-life cases is usually enormous, creating
new tests is very expensive. In this work-in-progress we
explore the idea of reuse-oriented CTD based on the notion
of composition of test plans. We propose a formal framework
in which composition of test plans can be deﬁned. This leads
to a natural notion of the design space, which is the inductive
closure of test plans under composition. Based on the proposed
framework, we propose a reuse-oriented reformulation for the
CTD problem, with the composability of test plan being the
main consideration.
II.
THE CTD FRAMEWORK
CTD is a powerful technique for functional testing. The
most well-known versions of this approach aim at testing all
value combinations of a given size t of the system’s parameters.
This problem of ﬁnding a minimal set of tests that cover all
combinations of size t can be reduced to the mathematically
equivalent problem of ﬁnding a covering array of strength t
[6].
In this paper, we take a more general approach along
the lines of [7], where the CTD problem is considered as a
subset selection problem. Below we provide a generalization
of the basic deﬁnitions of the framework, in which we make
a separation between the input and output parameters of a test
plan. This will be instrumental in what follows for deﬁning
the notion of composition.
100
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-449-7
SOFTENG 2015 : The First International Conference on Advances and Trends in Software Engineering

We assume a ﬁnite set of system parameters Par =
{A1, . . . , An}. We treat a parameter as a ﬁnite set of its
possible values. For any value a ∈ Ai, we say that a has
type Ai, denoted by type(a) = Ai. Subsets of parameters are
called p-collections and are denoted by A, B, ...,.
We start by deﬁning the notion of an (unordered) test, which
is basically a collection of values the combination of which
needs to be tested:
Deﬁnition 1: Let A = {A1, . . . , Am} be a p-collection.
1)
A selection for A is an element S ∈ P(Sm
1 Ai) such
that for distinct a, b ∈ S, type(a) ̸= type(b). Write
SelectionsA for the set of all selections for A.
2)
Call a selection S for A an unordered test when
for every A ∈ A, there is some a ∈ S, such that
type(a) = A (so that |S| = |A|). Write TestsA for
the set of all unordered tests for A.
Example 1: A
=
{FileOps, PathName, OS} be a p-
collection (taken out of a larger superset of parameters), where
FileOps = {open, close, read, write}
PathName = {relative, absolute}
OS = {unix, windows}
Then
S1
=
{open, relative, unix}
and
S2
=
{close, windows} are selections for A, while the former is
also an unordered test.
Using sets of selections, we can easily capture various
interaction modes, such as pairwise testing (as well as others):
Example 2: For a p-collection A = {A1, . . . , Am}, de-
note by 2Pair(A) the set of all selections for A of size 2.
Thus we think of tests just as sets, specifying which values
interact with which. However, when actually running tests,
other types of information become important. One of them is
a separation between the input and output parameters, which
deﬁnes possible orders of execution of tests as sequences of
consecutive test runs. Another issue is the order of parameter
appearance. Thus, when deﬁning the notion of executable test
set, i.e., those tests that can actually be run in the system, we
incorporate the above types of information as well:
Deﬁnition 2: Let
A
=
{A1, . . . , Am}, B
=
{B1, . . . , Bk} be p-collections.
•
For e = (a1, . . . , ar) ∈ (A1 × . . . × Am) × (B1 ×
. . . × Bk) (where r = m + k), we deﬁne the collapse
of e by col(e) = {a1, . . . , ar}.
•
An element e ∈ (A1 ×. . .×Am)×(B1 ×. . .×Bk) is
called an ordered test if col(e) is an unordered test.
•
An executable test set from A to B, denoted by E :
A → B, is a set of ordered tests.
Deﬁnition 3: Let A, B, C be p-collections.
•
A pre-test plan from A to B, denoted by P : A → B
is a triple P = (E, R, T) where:
◦
E : A → B is an executable test set.
◦
R is a set of selections for A ∪ B called
coverage requirements,
◦
T is a set of selections for A ∪ B, such that
T ⊆ col(E),
A test plan from A to B is a pre-test plan P =
(E, R, T) which satisﬁes that for every R ∈ R, there
is some T ∈ T, such that R ⊆ T (in words: every
coverage requirement R in R is ‘covered’ by some
test T in T.)
Example 3: Let A be the p-collection from Example 1.
Let B = {PackageSize, AckRequired} be a p-collection, where
PackageSize = {1KB, 2KB, 3KB}
AckRequired = {yes, no}
Let C = {Mode, Protocol} be a p-collection, where
Mode = {on, off}
Protocol = {UDP, TCP}
We can deﬁne, e.g., the following test plans P1 : A → B
and P2 : B → C: P1 = (E1, R1, T1), where:
E1 = (FileOps×PathName×OS)×(PackageSize×AckRequired)
R1 = {{relative, unix, yes}}
T1 = {{open, relative, unix, 2KB, yes}}
P2 = (E2, R2, T2), where:
E2 = (PackageSize × AckRequired) × (Mode × Protocol)
R2 = {{yes, TCP}}
T2 = {{3KB, yes, on, TCP}}
We are now ready to state the standard formulation of the
CTD problem in terms of our framework: given the set of
executable tests E : A → B and coverage requirements R, ﬁnd
a set of tests T, such that P = (E, R, T) is a valid test plan.
In the case of pairwise testing, e.g., we set R = 2Pair(A∪B),
where the latter is taken from Example 2.
Many algorithms and tools exist for solving various in-
stances of the CTD problem ([8]). They can be classiﬁed into
three categories ([9]):
•
algebraic: providing a solution by a mathematical
construction. These approaches usually lead to optimal
results, but are however highly inefﬁcient in practice
(see, e.g., [10]).
•
greedy: applying some search heuristic to incremen-
tally build the solution. An efﬁcient algorithm of such
kind based on Binary Decision Diagrams [11] is given
in [7], other examples are [12], [13].
•
meta-heuristic: applying genetic or other bio-inspired
search techniques (see, e.g., [14], [15]).
101
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-449-7
SOFTENG 2015 : The First International Conference on Advances and Trends in Software Engineering

III.
INTRODUCING COMPOSITION
The intuition behind composition of test plans is very
simple. Suppose a user has designed tests plans for several
parts of the system. Now, he may want to test several parts
sequentially, running one after the other and using the output
of one as input for the other. Instead of constructing tests
from scratch, he can reuse existing tests for the system parts
via composition. To deﬁne in precise terms the notion of
composition of test plans, we start by deﬁning a composition
of each of their parts: executable test sets and selections (and
so also of tests).
Deﬁnition 4: Let
A
=
{A1, . . . , Am}
and
B
=
{B1, . . . , Bk}. Let SA, SB be selections for A and B respec-
tively. Let E1 : A → B and E2 : B → C be executable test
plans.
•
Deﬁne E2 ◦E1 = {(a, c) | ∃b ∈ B1 ×. . .×Bk.(a, b) ∈
E1 ∧ (b, c) ∈ E2}.
•
If for every a ∈ S
1≤i≤m Ai∪S
1≤i≤k Bi it holds that
type(a) ∈ A ∩ B implies a ∈ SA ∩ SB, we say that
SA ◦SB is well-deﬁned and equals to SA ∪SB \SA ∩
SB.
•
Deﬁne
SA ◦ SB
=
{SA ◦ SB
|
SA ◦
SB is well deﬁned, SA ∈ SA, SB ∈ SB}.
The above deﬁnition captures both compositions of cov-
erage requirements and of tests (as both of them are sets
of selections). Note also that composition of 2-pair coverage
requirements leads to 2-pair coverage requirements:
Proposition 1: Let A, B, C be p-collections. Then
2Pair(A ∪ B) ◦ 2Pair(B ∪ C) = 2Pair(A ∪ C)
We can now deﬁne the following natural notion of compo-
sition of test plans:
Deﬁnition 5: Let P1 = ⟨E1, T1, R1⟩ : A → B and P2 =
⟨E2, T2, R2⟩ : B → C be test plans. The composition of P1
and P2 is deﬁned by the pre-test plan
P2 ◦ P1 = ⟨E2 ◦ E1, T2 ◦ T1, R2 ◦ R1⟩
To capture the set of all possible runs of sequences of tests
for which the output of one test is used as the input of the
next test, we can now deﬁne the notion of the design space,
which contains pre-test plans:
Deﬁnition 6: Let P1 : A1 → B1, . . . , Pn : An → Bn
be test plans from Ai to Bi respectively. For i ≥ 0, deﬁne
the sets DSi(P1, . . . , Pn) of pre-test plans as the smallest sets
satisfying:
•
P1, . . . , Pn ∈ DS0(P1, . . . , Pn).
•
If Pi, Pj ∈ DSk(P1, . . . , Pn) and Bi = Aj, then Pi ◦
Pj ∈ DSk+1(P1, . . . , Pn).
We denote S
i≥0 DSi by DS.
IV.
REUSE-ORIENTED TEST DESIGN
Given existing test plans, e.g., for A → B, B → C, B → D,
one can compose them to obtain new test plans for A → C
and A → D. The challenge is, however, dealing with the fact
that composing valid test plans does not necessarily lead to
valid test plans. Indeed, the operation of composition does
not preserve validity of test plans, as demonstrated by the
following example:
Example 4: Consider again the test plans P1 and P2 from
Example 3. Their composition is the pre-test plan P2 ◦ P1 =
(E, T, R), where:
E = (FileOps × PathName × OS) × (Mode × Protocol)
T = ∅
R = {{relative, unix, TCP}}
This pre-test plan is obviously not a test plan, as there is
no test meeting the requirement in R.
We now come to the key idea of reuse-oriented CTD
problem based on composition: designing basic tests with
the aim of effectively composing them at later stages when
required.
Deﬁnition 7: Two test plans P1 = ⟨E1, T1, R1⟩ : A → B
and P2 = ⟨E2, T2, R2⟩ : B → C are composable if P2 ◦ P1 is
a valid test plan.
It is easy to see that for every pair of executable test
sets E1, E2 and coverage requirements for A
→
B and
B
→ C respectively, there always exist valid test plans
P1 = ⟨E1, T1, R1⟩ : A → B and P2 = ⟨E2, T2, R2⟩ : B → C,
which are composable.
The notion of composability can be naturally extended to
any number of test plans, as well as to the inductive closure
under composition DS of a given depth:
Deﬁnition 8: Let P1 : A1 → B1, . . . , Pn : An → Bn be
test plans from Ai to Bi respectively. The design space DS is
composable up to depth k if for every P ∈ DSi and P ′ ∈ DSj
for i, j ≤ k, such that Bi = Aj, Pi ◦ Pj is composable.
The notion of composability deﬁned above gives rise to
new interesting formulations of reuse-oriented versions of
the CTD problem, such as the following: given executable
test sets E1, E2 coverage requirements and R1 and R2 for
A → B and B → C respectively, ﬁnd T1, T2, such that
P1 = ⟨E1, T1, R1⟩ : A → B and P2 = ⟨E2, T2, R2⟩ : B → C
are composable test plans. This can also be extended to
composability of a design space of a ﬁxed depth in a natural
way.
Similarly to the standard CTD problem, the above problems
may be solved using appropriate algebraic, greedy or meta-
heuristic algorithms.
V.
SUMMARY AND FURTHER WORK
In this paper, we deﬁne a formal framework, in which
we formulate an algorithmic problem of reuse-oriented CTD
based on composition. Composition of tests naturally arises in
sequential testing scenarios, where the output of one test is
102
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-449-7
SOFTENG 2015 : The First International Conference on Advances and Trends in Software Engineering

used as the input of the next test. An evaluation of our frame-
work is the next natural step. It will be done by implementing
a greedy algorithm for solving the composition-based CTD
problem deﬁned in this paper, by extending the algorithm of
[7], based on Binary Decision Diagrams.
Natural operations on test plans other than composition can
be further considered for a systematic test reuse (e.g., the stan-
dard join operation from database theory). Another direction
for future research is investigating which data structures are
most suitable for providing efﬁcient solutions to the type of
algorithmic problems formulated in this paper.
REFERENCES
[1]
C. Nie and H. Leung, “A survey of combinatorial testing,” ACM
Computing Surveys (CSUR), vol. 43, no. 2, 2011, p. 11.
[2]
J. Zhang, Z. Zhang, and F. Ma, “Introduction to combinatorial testing,”
in Automatic Generation of Combinatorial Test Data.
Springer, 2014,
pp. 1–16.
[3]
I. Segall, R. Tzoref-Brill, and A. Zlotnick, “Common patterns in
combinatorial models,” in Proceedings of the IEEE Fifth International
Conference on Software Testing, Veriﬁcation and Validation (ICST).
IEEE, 2012, pp. 624–629.
[4]
S. R. Dalal, A. Jain, N. Karunanithi, J. Leaton, C. M. Lott, G. C. Patton,
and B. M. Horowitz, “Model-based testing in practice,” in Proceedings
of the 21st International Conference on Software engineering.
ACM,
1999, pp. 285–294.
[5]
http://researcher.watson.ibm.com/researcher/view group.php?id=1871.
[6]
A. Hartman and L. Raskin, “Problems and algorithms for covering
arrays,” Discrete Mathematics, vol. 284, no. 1, 2004, pp. 149–156.
[7]
I. Segall, R. Tzoref-Brill, and E. Farchi, “Using binary decision di-
agrams for combinatorial test design,” in Proceedings of the 2011
International Symposium on Software Testing and Analysis.
ACM,
2011, pp. 254–264.
[8]
M. Grindal, J. Offutt, and S. F. Andler, “Combination testing strategies:
a survey,” Software Testing, Veriﬁcation and Reliability, vol. 15, no. 3,
2005, pp. 167–199.
[9]
M. B. Cohen, M. B. Dwyer, and J. Shi, “Interaction testing of highly-
conﬁgurable systems in the presence of constraints,” in Proceedings of
the 2007 International Symposium on Software testing and analysis.
ACM, 2007, pp. 129–139.
[10]
N. Kobayashi, T. Tsuchiya, and T. Kikuno, “Non-speciﬁcation-based
approaches to logic testing for software,” Information and Software
Technology, vol. 44, no. 2, 2002, pp. 113–121.
[11]
S. B. Akers, “Binary decision diagrams,” IEEE Transactions on Com-
puters, vol. 100, no. 6, 1978, pp. 509–516.
[12]
D. M. Cohen, S. R. Dalal, M. L. Fredman, and G. C. Patton, “The
AETG system: An approach to testing based on combinatorial design,”
IEEE Transactions on Software Engineering, vol. 23, no. 7, 1997, pp.
437–444.
[13]
K. Tai and Y. Lie, “A test generation strategy for pairwise testing,”
IEEE Transactions on Software Engineering, vol. 28, no. 1, 2002, pp.
109–111.
[14]
M. B. Cohen, P. B. Gibbons, W. B. Mugridge, and C. J. Colbourn,
“Constructing test suites for interaction testing,” in Proceedings of the
IEEE 25th International Conference on Software Engineering, 2003, pp.
38–48.
[15]
K. J. Nurmela, “Upper bounds for covering arrays by tabu search,”
Discrete applied mathematics, vol. 138, no. 1, 2004, pp. 143–152.
103
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-449-7
SOFTENG 2015 : The First International Conference on Advances and Trends in Software Engineering

