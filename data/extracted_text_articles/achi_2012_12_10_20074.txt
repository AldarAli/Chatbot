Alleyoop: Interactive Information Retrieval System with Sketch Manipulations 
Hiroaki Tobita 
Sony Computer Science Laboratory Paris 
Paris, France 
tobby@csl.sony.fr 
 
Abstract—The Alleyoop system enables users to retrieve 
information through sketch manipulations. A number of 
information retrieval systems already enable users to casually 
search and browse through the Web. These systems are useful 
for conventional input forms where a user uses a keyboard to 
input a keyword to a dialog box. However, they are not 
suitable for pen-based input styles. Users of pen-based 
computers have to input a query to a fixed dialog box by 
drawing the query. In contrast, the Alleyoop system is designed 
for pen-based computing, so users can interactively retrieve 
information through sketch manipulations. When a user draws 
a closed curve and a keyword, information nodes related to the 
keyword are collected automatically inside the closed curve. 
The user can also create a Venn diagram by continuously 
drawing closed curves and keywords, and form more complex 
queries for information retrieval. Moreover, the system allows 
the user to create a layout by drawing strokes freely, so he/she 
can set the information nodes on the layout and see them in 
detail. In this paper, we describe our Alleyoop system and how 
it can be effectively applied. 
Keywords-Information Retrieval; Information Visualization; 
Sketch and Paint Manipulations; Interactive System. 
I. 
 INTRODUCTION 
As computer hardware and software are continuously 
improved, it becomes possible to more quickly express a 
wider variety of information (e.g., images, movies, 
documents, and Web pages). Also, many types of computers 
(e.g., 
augmented 
reality 
(AR) 
systems, 
ubiquitous 
computers, and personal digital assistants (PDAs)) have 
been developed to allow users to naturally interact with the 
information space. In the future, these diversifications will 
be advanced rapidly, so natural and simple visualization 
techniques for information retrieval are needed.  
Numerous systems have been designed for information 
retrieval. Web based search engines (e.g., Google and 
Yahoo) have become popular for casual use. Combining 
rough and detail search methods is one important element, 
since they have to treat huge amounts of information. These 
systems are based on conventional input methods, so a 
keyboard is used to input a keyword to a fixed dialog box. 
On the other hand, pen-based computers such as PDAs and 
tablet PCs have become popular recently. They are 
characterized by simple sketch manipulations similar to 
drawing a picture on paper in the real world. This sketch-
based interaction has been developed especially for creative 
activities [4, 5, 6]. Sketch interaction is not especially useful 
for communicating details, but is effective for approximate 
and casual use. In these systems, a user can use the entire 
system window as a workspace. Also, sketch based 
information retrieval systems have been developed. When a 
user draws a picture, the system finds similar images from 
the database automatically. However, they do not provide 
combination between rough and detail search methods. Some 
systems focus on the relationship between sketch and layout. 
Although, Maya paint effects allows users to set psudo-3D 
objects in the scene using 2D brush strokes, their target is not 
information retrieval. Thus, as the original applications have 
not supported information retrieval, users have to use 
conventional retrieval applications with pen-based input 
styles. 
Therefore, 
we 
have 
been 
developing 
a 
unique 
information retrieval system based on simple sketch 
manipulations for pen-based computers [1, 2]. A feature of 
our design is that all the manipulations required for 
information retrieval are based on sketch manipulations and 
that a user can use the entire window space as a search area. 
Thus, the user can freely use the whole application window 
as both an input and a search area. In order to retrieve 
information, the Alleyoop system mainly provides two 
interactions: rough and detail searches. The rough search is 
to collect related information nodes. A user of the Alleyoop 
system first draws a closed curve and then draws a keyword 
inside the curve. The system automatically recognizes both 
the curve area and the keyword after the user has drawn them. 
Information nodes related to the keyword are then collected 
within the curve area. In addition, by making a continuous 
series of simple drawings, the user can create a Venn 
diagram to form a more complex query. The detail search is 
to see the information nodes in detail. After collecting the 
nodes, the user creates an original layout by drawing strokes. 
The information nodes are set onto the layout, so the user can 
see the nodes in detail. As both search interactions are based 
on sketch manipulations, the user can interact with an 
information space freely and easily. 
In this paper, we describe a prototype of the Alleyoop 
system and how it enables users to handle information 
through interactive drawing. The next section describes the 
related work of the Alleyoop system. Section 3 describes the 
system design. The system overview is mentioned in detail 
in Section 4. In Section 5, we describe the implementation of 
the system. In Section 6, we discuss the system based on 
comments made by visitors. Section 7 concludes the paper. 
II. 
RELATED WORK 
Our system focuses on pen-based information retrieval 
and allows users to retrieve information through creative 
activities. Here, we describe work related to our concepts 
such as information visualization and sketch interfaces. 
297
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

While considerable research has been done to support the 
use 
of 
information 
visualization 
[3] 
for 
retrieving 
information, existing visualization systems are not designed 
to treat all data sets in a common way. Actually, by applying 
visualization techniques such as zooming and scaling, 
specialized systems can be designed to enable efficient 
visualization of huge amounts of data [8, 9, 11, 12], but such 
systems are not effective for simple visualization of 
moderate amounts of data. In particular, in the case of 3D 
layouts, the navigation methods become as important as the 
layouts as the amount of data increases. Although some 
systems include different layouts, these layouts are still 
designed on the basis of the system designers’ intention [13, 
14]. Thus, a casual visualization technique is needed for a 
wide variety of situations.  
Several pen-based computers have been developed. At the 
consumer product level, PDAs and tablet PCs have become 
common. These computers allow users to interact with the 
computer environment by means of simple sketch 
manipulations [4, 5, 6] and are effective for casual and rough 
inputs such as sketching in the real world. These sketch-
based systems allow users to perform 2D drawing 
manipulation of 3D computer graphics (CG) creations, so the 
difficulties of 3D CG are avoided. Characteristically, the 
manipulations required for these systems are simple and 
similar to drawing a stroke on a piece of paper with a pen. 
Sketch [4] users can draw 3D curves by performing 2D 
manipulations. This system calculates a 3D curve by 
combining a 2D stroke and a shadow stroke. Users of Harold 
[5] and Tolba [6] can create flat models in a 3D space using 
sketch-based manipulation, effectively creating a 2.5D scene 
in a 3D space.  
III. 
ALLEYOOP DESIGN 
One design focus is to enable interactive drawing for 
information retrieval. Such a system would let users operate 
the system more freely and easily when engaging in creative 
activities. Another design focus is to provide both rough and 
detail searches. This combination makes it possible to treat 
huge amounts of information. We consider the following 
features as important to achieving our design goal.  
A. Simple Creative Interaction 
Simple creative interaction was important to realize our 
concepts because this type of interaction provides flexibility. 
Integrating drawing with information retrieval enables a user 
to use the whole workspace interactively, much like drawing 
a picture on a piece of paper. In such an environment, the 
user can draw layouts to display information nodes and 
keywords related to the nodes anywhere within the 
workspace. While the system treats many types of 
information (e.g., images, movies, 3D models, documents, 
and Web pages) as visualized information nodes, we used 
mainly image data as the information node. An information 
node means a piece of information on the screen. Also, 
depending on how a line is drawn, the user can create either 
simple or complex queries for information retrieval. All the 
elements related to information retrieval such as layout 
design and keyword drawing should be realized flexibly.  
 
Figure 1.  System Overview: The system is divided into two areas, work 
and GUI areas. Some GUI buttons are included in the GUI area to control 
pen attributes. 
B. Rough and Detail Searches 
Combining rough and detail search methods is one 
important element, since we have to treat huge amounts of 
information. This combination has been supported by 
conventional Web search engines such as Google and Yahoo. 
Web users performing searches first collect related 
information roughly by setting queries and then see each 
information node in detail one by one. The Alleyoop system 
also treats huge amounts of information, so it should provide 
these rough and detail processes. Our system arranges these 
processes by sketch manipulations (setting an area and 
creating a layout). In such an environment, the user first 
creates an outline to collect information nodes roughly and 
then creates an original layout to see each information node 
in detail. 
C. Node Animation 
Node animation plays an important role in our 
information retrieval. For example, through the animation, 
users can know the relationship between node and keyword 
dynamically and retrieve extra information. Our system 
integrates node animation with the user’s drawing. 
IV. 
SYSTEM OVERVIEW 
Figure 1 shows the user interface for our system. The 
system is divided into two areas: work and graphic user 
interface (GUI) areas. The GUI buttons at the bottom of the 
figure allow the user to choose pen attributes and draw four 
types of strokes (area, text, layout, and relation strokes). The 
first button is for the area pen, which is used to draw a 
closed curve. The second button is for the text pen, which is 
used to draw a keyword. The third button activates the layout 
pen. The user can create a 2D layout by drawing a layout 
stroke. The fourth button is for the relation pen, which 
allows the user to add relationships between different pieces 
of a visualized information node.  
The interaction is divided into two phases: rough and 
detail searches. The area and text strokes are used for the 
former and the layout and relation strokes are used for the 
latter. The color of the stroke depends on the color of the 
button, so the user can use stroke colors like paint colors. 
298
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

The buttons to set and clear GUIs are located in the area. The 
“Set GUI” button is used to set visualized information 
alongside the user’s strokes and the “Clear GUI” button is 
used to clear the work area. 
 
 
Figure 2.  Rough search: A user first draws a closed curve with the area 
pen and a keyword inside the curve with the text pen. As the system 
recognizes the area and keyword, related information nodes appear inside 
the area. 
 
 
Figure 3.  Drawing a Venn diagram: By continuously drawing crossed 
curves and keywords, a user creates a Venn diagram and can then retrieve 
information by forming a complex query (1, 2, 3, 4). It is possible to create 
a Venn diagram between a drawing and an image that contains character 
information (5, 6). 
A. Rough Search 
A user can collect information nodes roughly by using 
the area and text pens. In spite of the simple interactions, it is 
possible to form complex queries through a series of 
continuous drawings. The system can also be used in 
combination with other types of datasets, such as an image 
dataset. 
1) Drawing a closed curve and a keyword 
A user starts interacting with the information space by 
drawing a closed curve with the area pen (displayed as a 
yellow stroke) and a keyword with the text pen (displayed as 
a blue stroke). The closed curve provides an area where 
information nodes related to the keyword will be collected 
and the keyword provides a query to search for related 
information nodes from a database. Figure 2 shows an 
example of simple information retrieval through drawing. 
First, the user draws a closed curve, and then draws a 
keyword CG inside the curve (1, 2). The system recognizes 
the area and keyword, so information nodes related to the 
keyword move to the closed curve (3, 4). The related 
information nodes are moved with a force depending on the 
distance between the node position and the center of the 
curve. As a result, the information nodes related to the 
keyword are collected inside the area. 
2) Venn Diagrams 
By continuing to use simple drawings, a user can form 
more complex queries. Figure 3 shows an example of 
creating a Venn diagram by continuing to draw closed curves 
and keywords. For example, when a user retrieves 
information that has two keywords CG and 3D, the user first 
draws a closed curve and CG (1), and then draws another 
closed curve and 3D (2). Information nodes related to both 
keywords appear in the shared area of the Venn diagram (3, 
4). From the information distribution results on the Venn 
diagram, the user can retrieve information roughly and 
recognize relationships between nodes. Moreover, the user 
can use an image to create a Venn diagram by combining 
drawings with image data. In this case, a file name or 
contained character information becomes a query for the 
Venn diagram. The figure shows an example of creating a 
Venn diagram between an image and a drawing (5, 6). In this 
example, related nodes with both VR and the file name 
appear. 
 
 
 
 
Figure 4.  Detail search: The user can create a layout by drawing a layout 
stroke to see information nodes in detail. It is possible to control the 
information output by selecting the appropriate pen width (top) and 
adjusting the painting area (bottom). 
B. Detail Search 
After collecting related information nodes roughly, a user 
can see them in detail by using an original layout the user 
created. The user can create a layout with the layout stroke 
and add relationships between nodes with the relation stroke. 
1) Layout Design 
Figure 4 shows how the user can create a 2D layout by 
selecting the layout pen and drawing a stroke with it 
(displayed as a green stroke). Since a set of images is 
automatically displayed alongside the user’s strokes, he/she 
can create a layout that freely displays the images in the 
work area. Thus, the user can place information nodes onto 
drawn words and pictures. In addition, as the pen width is 
directly related to the image size, larger images appear 
alongside the stroke if the user draws a bold stroke, while 
smaller images appear if he/she draws a thin stroke in the 
work area (Fig. 4 (top)). A painted area is recognized as one 
big point, so the system positions a large image alongside the 
painted area (bottom). Thus, the user can select a large image 
when painting to see it in more detail (Fig. 4 (bottom)).  
299
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
Figure 5.  Relation stroke: The user can create a layered layout by drawing 
relation strokes (top). Multiple information can be connected to single 
information nodes at the same time (bottom). 
 
Figure 6.  Layout creation with our system. Each layout was created by 
drawing simple strokes.  
Conventional information visualization systems enable 
users to visually search and browse through a layout to locate 
grouped information. While these layouts are pre-defined 
and useful in applications considered by designers, users 
cannot freely change or redesign them. In contrast, our 
system integrates information visualization with sketch 
manipulations and allows users to create a layout freely and 
easily. 
2) Relationships between Nodes 
Figure 5 shows how the user can add relationships to 
connect focused images by drawing a relation stroke 
(displayed as a white stroke) from one image to another. As 
the pen width directly corresponds to the relationship value, 
the user can establish and control relationships between 
images. The clicked image in the figure becomes the parent 
for the connected image, and the system establishes the 
relation through the pen width. This manipulation is 
especially useful in grouping new information, such as 
digital photographs and user creations such as painted 
images or 3D models. Users can now easily take pictures 
using digital cameras and, as a result, have a huge amount of 
original image data in their computers. This stroke is useful 
for such an environment. Moreover, users can create simple 
information visualization layouts through continuous, 
straightforward manipulations with our relation techniques 
(Fig. 6). 
V. 
IMPLEMENTATION 
Next, we consider the implementation of the Alleyoop 
system. Users’ drawing manipulations are reflected in the 
bitmap data that make up the workspace. The workspace has 
four bitmap layers and each layer is used for each pen 
attribute. The system is basically realized through simple sets 
of image processing. 
 
  
(a) The system labels the user’s drawing area (left) and then recognizes 
keywords by using an OCR library (right). 
 
 
(b) Labeling of a Venn diagram. The system uses mouse trace data to 
determine the shared area and its keyword. 
Figure 7.  Implementation of rough searching. The implementation is 
divided into two parts: labeling of the user’s drawing area and recognition 
of a keyword.  
A. Rough Search 
When the user draws an area with the area pen and a 
keyword with the text pen, the system stores four types of 
data (stroke-ID, mouse-trace, area-bitmap, and keyword-
bitmap data). 
When the user pushes the “Set GUI” button after drawing 
a closed curve and a keyword, the system starts the 
calculations for the user’s drawing. For the closed curve area, 
the system labels the inside of the area (Fig. 7 (a-left)). This 
labeling process depends on the mouse trace data, which the 
system uses to determine the inside or outside area. For the 
keyword bitmap data, the system sends the data to an optical 
character recognition (OCR) library and recognizes the 
keyword meaning (Fig. 7 (a-right)). When the user creates a 
Venn diagram through continuous drawing of a closed curve 
and a keyword, the system uses the mouse trace data to 
determine the shared area and its keyword (Fig. 7 (b)). In the 
event the combination includes an image, the system labels 
the inside of the image area with the same label as the drawn 
curve. The image is thus treated as the drawn curve. After 
the calculations, the system contains three types of data (area 
ID, area position, and keyword) for each labeled area. 
Next, calculations for the node animations start. Each 
node is subject to a force that depends on the node’s 
relationship with the keyword. This calculation is done by a 
spring model [9]. The node then moves until it is in the 
appropriate area for the relationship. The system has an 
original database containing three types of data: node names, 
keywords, and relation levels. The database is loaded when 
the system starts. 
300
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
(a) System contains mouse-trace, pen-width, and bitmap data for user 
drawings. 
 
	 
(b) Painted area is recognized as one point through labeling and pattern 
matching of screen image. 
 
 
(c). System recalculates mouse trace data depending on information size 
and then sets information. 
Figure 8.  Detail search implementation and drawing area calculation. 
B. Detail Search 
As Fig. 8 shows, for a detail search the system stores 
three types of data (i.e., mouse-trace, pen-width, and bitmap 
data from the screen) for a set of layout strokes (a). The 
bitmap data is labeled and then matched to simple template 
data (b). The system recognizes what shape was drawn (e.g., 
line or circle) through template matching with the labeling 
data. If the results for labeling are different from the template 
pattern, the system recognizes strokes as lines and sets 
visualized information. Next, the trace data is recalculated to 
maintain the same distance according to pen width, enabling 
a painted circle to be recognized as one big point (c). The 
amount of visualized information shown on the screen 
depends on the stroke length. Less information is visualized 
if the total length of the line on which visualized information 
is laid out is longer than the stroke. As a result, visualized 
information is automatically set along with the user’s strokes. 
These calculations to set information are done when the user 
draws strokes and pushes the “Set GUI” button. 
In connecting with a relation stroke, the system recognizes 
visualized information under the starting point as a parent 
and visualized information connected with the relation stroke 
as a child of the scene graph. The system defines the size and 
position parameters of the child by taking the stroke width 
into account. The child image that is included in the layout 
becomes half the size of the parent, because they are 
connected with a double-sized pen. These results are saved 
by the system database. 
VI. 
DISCUSSION 
Here, we discuss user interactions with Alleyoop based 
on comments made by visitors to our demonstrations. 
A. Rough Search 
In our demonstrations, visitors quickly understood the 
system concepts and interaction methods. It was not difficult 
for them to recognize the relationships between information 
nodes and keywords directly through Venn diagrams, or to 
use the whole workspace for free drawing. Most visitors 
were able to create simple Venn diagrams and set related 
nodes onto them after a simple demonstration. While 
conventional information retrieval systems require users to 
input a keyword to a dialog box field, our system allows 
them to use the entire workspace and retrieve information 
through creative activities. Since the system facilitates 
creative activities, we expect its users will be able to create 
more original and effective drawings for information 
retrieval. We also received good reactions from visitors 
regarding the combination of drawings and images to create 
a Venn diagram. Our system can use various types of 
information included in images, such as characters and 
words. Through sketch manipulations, a user can retrieve 
information without drawing a keyword. Moreover, the user 
can use other types of data, such as real-world information, 
to create Venn diagrams. If the information contains text and 
characters, these information elements are used as queries for 
information retrieval. Figure 9 shows an example of using 
real-world information as a Venn diagram element. The user 
first captures real-world information through a digital camera 
attached to his/her computer (1, 2) and then draws a closed 
curve around a keyword on the captured data and another 
closed curve to collect information nodes (3, 4). As the 
system recognizes the keyword inside the first closed curve, 
related information nodes appear inside the second curve. 
B. Detail Search 
Most visitors designed original layouts through simple 
manipulations. Although none of them created a complex 
layout, they were able to easily create simple layouts and 
created words and pictures to visualize grouped information. 
This indicated that they quickly understood our system 
concepts and interaction methods. Our system was designed 
to enable users to design simple layouts and freely redesign 
layouts. The visitors were able to casually create simple or 
unusual layouts not requiring special design skills and 
encountered no difficulties in this casual use. Allowing users 
to design and create layouts freely in and of itself, however, 
does not ensure an easy design process. Accordingly, our 
system provides sketch and paint techniques instead of 
complex parameter settings. This enables even a simple 
stroke to become a kind of layout and thus allows design 
difficulties to be avoided. We also showed through simple 
demonstrations that both sketch and paint interactions could 
be used to directly control parameters (e.g., scale and 
relation). The visitors reacted particularly favorably to the 
relation stroke because it made it possible to handle the 
user’s original data set while controlling the relation rate by 
adjusting the pen width. They generally held their original 
data set in a folder named “Related Data”, and all were able 
to establish relationships between data and create simple 
databases using only the relation strokes. 
301
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
Figure 9.  Combination with real-world information: Capturing real-world 
information as a picture (1, 2) and drawing two closed curves (3, 4). One 
curve (shown in yellow) means an area and the other (shown in blue) 
means a keyword.  
 
Figure 10.  Combination with wall-type display. A user sets data by 
drawing a stroke on a wall-type display.  
Some visitors had questions related to the system’s lack 
of effectiveness with detailed manipulations. A few of them 
also said they would have preferred more complex layouts 
and relationships. However, our goal was to enable simple 
and convenient interactions that would allow casual users to 
freely utilize the system. As complex manipulations and 
GUIs would have increased the complexity of the layout and 
relations, we did not include these in our system. 
C. Communication 
It is also possible to combine our system with AR 
systems based on tablet computers [7] and with ubiquitous 
computing environments. As the user generally interacts 
with the computer to display and change visualized 
information in these environments, information layout 
techniques are as important as interaction techniques. To 
enable more natural interactions, the visualized information 
size and position need to change depending on the situation 
and type of computer to allow more natural interaction with 
the information space through both visualization techniques 
and AR systems. Also, as the interactions should be simpler 
than for normal computing in these systems, a combination 
of our system and AR systems promises to be quite useful. 
For example, in case of using wall-type AR systems, the user 
can use the wide information space freely (Fig. 10 (top)). 
Our system also provides good support for displaying 
information for presentation in meetings (Fig. 10 (bottom)). 
Here, the user can draw the most effective layout according 
to the situation and type of information.  
D. Future Work 
Our system is so far only at the prototype stage, so we are 
planning to further improve it by combining with other 
types of database. Then, we will conduct practical user tests.  
As a subject for future work we plan to combine our 
system with AR system to enable it to support more natural 
interactions [10]. Combining it with a gesture recognition 
system would be a particularly effective way to achieve this.  
VII. CONCLUSIONS  
The Alleyoop system enables users to retrieve 
information through sketch manipulations. The system is 
divided into two phases: rough and detail searches. We have 
described our design concepts and a prototype of the 
Alleyoop system. Although the interactions based on sketch 
manipulations are very simple, users can use them to set 
complex queries and create original layouts freely. 
REFERENCES 
[1] 
H. Tobita. Catenaccio: interactive information retrieval system 
through drawing. In Proceedings of AVI'2006. pp.79-82 . 
[2] 
H. Tobita. VelvetPath: Layout Design System with Sketch and Paint 
Manipulations, In Proceedings of EUROGRAPHICS2003 Short 
Presentations, pp. 137-144, 2003. 
[3] 
S. K. Card, J. D. Mackinlay, and B. Shneiderman. Readings in 
Information Visualization : Using Vision to Think, 1999. 
[4] 
R.C. Zeleznik, K.P. Herndon, and J.F. Hughes. An Interface for 
Sketching 3D Curves. SIGGRAPH ’96 Proceedings, pp. 163-170, 
1996. 
[5] 
J.M. Cohen, J.F. Hughes, and R.C. Zeleznik. Harold: A World Made 
of 
Drawings. 
NPAR2000 (Symposium on Non-Photorealistic 
Animation and Rendering), pp. 83-90, 2000. 
[6] 
O. Tolba, J. Doresey, and L. McMillan. Sketching with Projective 2D 
Strokes. Proceedings of UIST ’99, pp. 149-157, 1999. 
[7] 
J. Rekimoto. Pick-and-Drop: A Direct Manipulation Technique for 
Multiple Computer Environments. Proceedings of UIST’97, pp. 31-39, 
1997. 
[8] 
G. G. Robertson, J. D. Mackinlay and S. K. Card. Cone Trees: 
Animated 3D Visualization of hierarchical information. Proceedings 
of the ACM Conference on Human Factors in Computing Systems 
(CHI ’91), pp. 189-194, 1991. 
[9] 
R. Davidson and D. Harel. Drawing Graphics Nicely Using Simulated 
Annealing. ACM Transactions on Graphics, Vol. 15, No. 4, pp. 301-
331, 1996. 
[10] Rekimoto, J. and Ayatsuka, Y. Cybercode: Designing Augmented 
Reality Environments with Visual Tags. In Proccedings of DARE 
2000, pp. 1-10, April 2000. 
[11] G. W. Furnas. Generalized fisheye views. Proceedings of the ACM 
Tran. on Computer-Human Interaction, Vol. 1, No. 2, pp. 126-160, 
1994. 
[12] B. B. Bederson, J. D. Hollan, K. Perlin, J. Meyer, D. Bacon, and G. 
Furnas. Pad++: A Zoomable Graphical Sketchpad for Exploring 
Alternate Interface Physics. Journal of Visual Languages and 
Computing, Vol. 7, No. 1, pp. 3-31, 1996. 
[13] L. Zhicheng, J. Stasko, T. Sullivan. SellTrend: Inter-Attribute Visual 
Analysis of Temporal Transaction Data. IEEE Transactions on 
Visualization and Computer Graphics, pp. 1025-1032, 2009. 
[14] B. 
B. 
Bederson, 
B. 
Shneiderman, 
and 
M. 
Wattenberg. 
Orderedandquan- tum treemaps: Making effective use of 2D space to 
display hierarchies. ACM Transactions on Graphics, 21(4), pp. 833–
854, 2002.  
 
302
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

