Sample Trace: Deriving Fast Approximation for Repetitive Queries
Feng Yu
Department of Computer Science
and Information System
Youngstown State University
Email: fyu@ysu.edu
Wen-Chi Hou
Department of Computer Science
Southern Illinois University Carbondale
Email: hou@cs.siu.edu
Cheng Luo
Department of Mathematics and
Computer Science
Coppin State University
Email: cluo@coppin.edu
Abstract—Repetitive queries refer to those queries that are likely
to be executed repeatedly in the future. Queries such as those
used to generate periodic reports, perform routine summarization
and data analysis belong to this category. Repetitive queries can
constitute a large portion of the daily activities of a database
system, and thus deserve extra optimization efforts. In this paper,
we propose to record information about how tuples are joined
in a repetitive query, called the query trace. We prove that the
query trace is sufﬁcient to compute the exact selectivities of
joins for all plans of a given query. To reduce the space and
time overheads in generating the query trace, we propose to
construct only a sample of the query trace, called a sample
trace, which can be much smaller than a (complete) query trace.
A special operation, called a sample outer join, is designed to
accomplish this feat. Accurate estimations of join selectivities,
with associated conﬁdence intervals, can be derived easily using
the sample trace. Extensive experiments show that the sample
trace can be constructed efﬁciently and be a controllable trade-off
between accuracy and efﬁciency in estimations of join selectivities
for repetitive queries.
Keywords-query optimization, query re-optimization, trace, sam-
pling method, sample trace
I.
INTRODUCTION
Query re-optimization aims to reﬁne execution plans of
queries. There has been some progress made on this subject
recently. In the literature, some [1–3], have focused on reﬁning
execution plans on-the-ﬂy for currently running queries, while
others [4–8], etc., on reﬁning cost estimation for future queries.
In this paper, we are interested in identifying useful statistics
for reﬁning cost estimation for future queries, similar to the
latter.
To reﬁne cost estimation for future queries, a common
approach is to collect actual selectivities [7], [8], and some
other statistics of the operators [5] and use them to adjust
cost estimation for future queries. Unfortunately, selectivities
of joins obtained from one plan of a query may not be sufﬁcient
for estimating selectivities of joins of another plan of the
same query because as the join order changes, the selectivities
of joins change, not to mention the selectivities of joins of
other queries. The problem is exacerbated by adding selection
predicates to the queries (to specify the tuples of interest). It is
probably difﬁcult to gather all information that may be needed
for estimating selectivities of joins for all plans of all possible
queries. Therefore, in this research, we set a more realistic
goal by restricting ourselves to considering only a subset, but
a large and frequently used subset, of queries, called repetitive
queries.
Repetitive queries refer to those that are likely to be
posted repeatedly in the future. Many useful queries, such as
those used for generating periodical reports, performing routine
maintenances, summarizing and grouping data for analysis,
are repetitive queries. They are often stored in databases for
convenient reuses for the long term. Any sub-optimality in
the execution plans of such queries may mean repetitive and
continued waste of system resources and time. Moreover, as
new queries are continuously being developed, more queries
become repetitive queries. Usually, the longer a database is
in production, the greater the number of repetitive queries is
in the database; their executions can constitute a large part
of daily activities of a database system. The optimality of
execution plans of repetitive queries has a tremendous effect
on the performance of the system and thus deserves more
optimization efforts.
Unlike much of the existing re-optimization work that
focuses on reﬁning physical execution plans of queries, our
research focuses on reﬁning logical execution plans (or the
join order) of queries. Selectivities obtained from previous
executions can be very useful for selecting an efﬁcient access
method (e.g., table scan and index access) and join method
(e.g., nested-loop, sort-merge, etc.), that is, physical plans,
but they may not be sufﬁcient to estimate the selectivities of
joins of the query in other join orders accurately without using
simplifying assumptions, such as attribute independence and/or
distribution uniformity. Our approach here focuses on how to
gather sufﬁcient information for computing the selectivities of
joins for all plans of a query accurately.
In this paper, we continue to study the query or join
trace [9], [10] that records information about how tuples are
joined in the query. We have designed operators to gather such
information so that the exact join selectivities in all join orders
for a query can be computed. To reduce the overheads incurred
in collecting a query trace, we design an innovative sample
scheme that generates only a sample of the query trace. The
sampling scheme is very effective in reducing overheads and
the experimental results have shown that the sample trace is
very accurate. With accurate selectivity estimations, running
repetitive queries in the most efﬁcient ways becomes possible.
The rest of the paper is organized as follows. Section II
discusses previous work in relation to re-optimization. Section
III introduces the query trace. The relationships between the
traces and selectivities of queries with acyclic join graphs are
59
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

discussed in Sections IV. In Section V, we discuss deriving
a sample of the trace and using the sample trace to estimate
the selectivity of an arbitrary subquery. The sample trace is
empirically evaluated in Section VI. Section VII presents the
conclusions and future work.
II.
LITERATURE SURVEY
The work in query re-optimization can be classiﬁed into
two categories: (1) re-optimizations of current (or ongoing)
queries and (2) re-optimization of future queries. Our work
falls into the second category as we try to optimize the future
executions of repetitive queries.
There has been much work that falls into the ﬁrst category.
ReOpt [3] discussed re-optimization of join queries. Statistics
are collected at run-time and ad hoc heuristics are used to
determine whether or not to re-optimize by either changing
the execution plan or improving the resource allocations for
the remainder of the execution. POP [11] improved upon
ReOpt [3] by computing a more rigorous validity range for
an input to a join within which the plan is valid. When
the actual cardinality falls outside the validity range, a re-
optimization is triggered. Rio [1] further improved on POP
by computing interval estimates, instead of point estimates, of
the cardinalities. Within the intervals, they selected robust and
switchable plans to avoid repeated re-optimization and loss of
earlier pipelined work.
The second category includes [4], [11–15] Chen et al.
[14] ﬁrst used query feedback to reﬁne the data distribution,
represented by a linear combination of “model function”. Only
1-dimensional distributions were considered. Aboulnaga et al.
[4] used the actual range selectivities obtained from queries
to adjust histograms. By splitting high frequency buckets and
merging similar consecutive buckets, histograms are tuned.
Lim et al. [6] used actual selectivities to tune bucket frequen-
cies and query workloads to determine what set of histograms
to build. All these approaches are mainly concerned with
selection queries.
The pay-as-you-go approach [16] improves the idea of
LEO [7], [8] with proactive monitoring and plan modiﬁcations.
Nevertheless, it does not collect enough information needed for
estimating arbitrary logical execution plans, and it must rely
on repetitive executions of the query to collect complementary
cardinality information.
Microsoft Index Wizard [17] recommends the database
administator (DBA) on indexes. It is similar to DB2 Advisor
[18] and Oracle SQL Access Advisor [19] that are limited to
access path recommendations rather than selections of logical
execution plans.
Xplus [20] enumerates plans and their neighborhoods to
search for alternative plans with lower cost. However, it may
only ﬁnd plans with local minimum values that may not
necessarily be the optimal plan.
Oracle’s Automatic Tuning Optimizer (ATO) [21] performs
SQL Proﬁling and what-if analysis on selected high load SQL
statements. SQL Proﬁles are used with other statistics to build
a well-tuned plan. However, it may not have sufﬁcient statistics
that are needed for cost estimation of all plans of the query,
and must generate auxiliary information for estimations, which
can be time-consuming and inaccurate.
In this research, we are interested in gathering sufﬁcient in-
formation about a query during execution so that an optimizer
can use the information to ﬁnd the best join order, or the best
logical execution plan, for the query. Existing re-optimiation
works, such as POP, Rio, and LEO can be very effective
in reﬁning physical execution plans of queries, e.g., access
methods (e.g., table scan, and index access and join methods
(e.g., nested loop, sort-merge, and hash join using the actual
selectivities obtained from the feedback. However, they may
fall short of optimizing logical execution plans of the queries
because as the join orders change, the selectivities of joins in
alternative plans change too. It requires more information than
just the selectivities of operators of the current plan to estimate
the selectivities of joins of alternative plans accurately.
III.
QUERY TRACE
When a query is being processed, information about how
tuples are joined is gathered. We intend to use this information,
called the query or join trace, to estimate selectivities of joins
in all execution orders.
We use tuple IDs to identify matching tuples in the joins
of a query in the trace. To create the trace of a query, an
ID attribute, Ri-ID, is added to (the schema of) each relation
Ri. The added ID attributes are to be included in the output
(schema) of all operations to identify tuples that contribute to
the output. For example, in the join of two relations R1 and R2,
a result tuple, besides its normal set of attributes, will have two
additional attributes: R1-ID and R2-ID, whose values identify
the pairs of tuples that match in the join of R1 and R2. It is
noted that we do not need to add an ID attribute physically
to (the schema of) a relation on disk, but just append an ID
value when a tuple ﬂows into the join operation.
In the following, we use an example to show how query
traces look like in their simplest form and how they are
generated. More complicated examples will be discussed in
subsequent sections, including using other operators, such as
outer joins, or designing new operators, such as extended outer
joins, to gather sufﬁcient information in the trace for different
types of queries.
Example 1. (Trace) Consider a left-deep tree execution plan
P = ((R1 ⋊⋉ R2) ⋊⋉ R3) ⋊⋉ R4. To generate the trace, an
ID attribute is added to every relation and the attribute is to
be preserved in the outputs of all operators. Thus, the result
of R1 ⋊⋉ R2, as shown in Fig. 1(b), besides its normal set
of attributes, denoted by Result-Attrs, has additional attributes
R1-ID and R2-ID, called the trace of R1 ⋊⋉ R2, denoted by
T(R1 ⋊⋉ R2).
Once a query is completely processed, we can extract the
ﬁnal trace, e.g., T(((R1 ⋊⋉ R2) ⋊⋉ R3) ⋊⋉ R4) in Example
1. Keeping the ﬁnal trace is enough to derive the selectivities
of joins in all execution orders Consequently, we shall retain
only the ﬁnal trace for selectivity re-estimation. Hereafter, the
trace of a query refers to the ﬁnal trace of the query, unless
otherwise stated.
IV.
SELECTIVITY ESTIMATION FOR ACYCLIC JOIN
GRAPHS USING TRACE
Let Q be a query with an acyclic join graph G(V, E) and
P an execution plan of the query. Let T(P) be the ﬁnal trace
of P. Let G′(V ′, E′) be a vertex-induced connected subgraph
of G(V, E), where V ′ = {Ri1, ..., Rim} ⊆ V and E′ ⊆ E,
representing a subquery Q′ of Q. We propose to compute the
exact selectivity of Q′ as
60
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

R1
R2
R3
R4
1
2
3
a
b
A
B
I
II
(a) Matching of Tuples
Result-Attrs
R1-ID
R2-ID
...
1
a
...
2
b
...
3
b
(b) Result and Trace of R1 ⊲⊳ R2
R1-ID
R2-ID
R3-ID
1
a
A
2
b
B
3
b
B
(c) Trace of (R1 ⊲⊳ R2) ⊲⊳ R3
R1-ID
R2-ID
R3-ID
R4-ID
1
a
A
I
2
b
B
II
3
b
B
II
(d) Trace of ((R1 ⊲⊳ R2) ⊲⊳ R3) ⊲⊳ R4
Figure 1.
Query Traces with Tuple IDs
f
sel(Q′) = |πRi1-ID,...,Rim-IDT(P)|
|Ri1| × ... × |Rim|
(1)
where πRi1-ID,...,Rim-IDT(P) is the projection of trace
T(P) on attributes Ri1-ID, ..., Rim-ID, with duplicates re-
moved.
As we shall discuss later that trace tuples, generated
by other operators (e.g., (extended) outer joins), could have
null values in some of the projected ID components Ri1-ID,
... ,Rim-ID, and such tuples shall not be accounted for in
|πRi1-ID,...,Rim-IDT(P)|
The cardinalities of the input relations |Ri1|, ..., |Rim| can
be obtained easily. If Rij, 1 ≤ j ≤ m, is a base relation,
|Rij| is certainly known. If Rij represents a relation that is
immediately preceded by some selections and projection, |Rij|
can be obtained by counting the number of tuples ﬂowing into
the join operation. Another possible way to compute |Rij| is
just to count the numbers of unique IDs in the respective ID
columns in the ﬁnal trace. Thus, without regard to the access
methods used to retrieve tuples from relations, such as table
scan, index access, etc., exact |Rij| can always be obtained.
A. No Dangling Tuples in the Joins
Here, we assume no dangling tuple exists in any of the
joins in the query. The join relationships in Fig. 1(a) satisfy
this condition. Now, let us see how accurate (1) derives the
selectivities.
Example 2. (No Dangling Tuple). Consider the query and
plan in Example 1. Given the (ﬁnal) query trace in Fig. 1(c),
the selectivities of R1 ⋊⋉ R2, R2 ⋊⋉ R3, and R3 ⋊⋉ R4, are
derived, by (1), as 1
2, 1
2, and 1
2, respectively, which are the exact
selectivities of the respective joins. The derived selectivities
of (R1 ⋊⋉ R2) ⋊⋉ R3(= (R2 ⋊⋉ R3) ⋊⋉ R1 = (R3 ⋊⋉ R2) ⋊⋉
R1), (R3 ⋊⋉ R4) ⋊⋉ R2(= (R3 ⋊⋉ R2) ⋊⋉ R4 = (R4 ⋊⋉ R3) ⋊⋉
R2), are all 1/4; again they are all exact.
It is not a coincidence that the estimated selectivities are
exact. In fact, we can prove that if there is no dangling tuple
in any join of the query, (1) derives the exact selectivities of
all possible subqueries.
Theorem 1 (Exact Estimation without Dangling Tuples).
Let P be an execution plan of a query Q with a connected
acyclic join graph G(V, E). Let Q′ be a subquery of Q that has
a vertex-induced connected join subgraph G′(V ′, E′), V ′ =
{Ri1, ..., Rim} ⊆ V . If there is no dangling tuple in any join
of P, (1) gives the exact selectivity of Q′ from T(P).
Proof: Please see Appendix A.
B. Dangling Tuples in Joins
Now, let us consider joins with dangling tuples. Dangling
tuples are lost in the joins. To retain matching information
about dangling tuples, we replace the joins in the original query
by the full outer joins (
◦⋊⋉). Fig.2(c) to 2(e) show the traces
generated at different stages of query execution, where the
joins are replaced by the full outer joins. The trace in Fig.
2(c) is the same as if it were generated by a join because
there is no dangling tuple in the join. The trace in Fig. 2(d)
retains information about dangling tuples b in R2 and B in R3
by the outer join.
The estimated selectivities for R1 ⋊⋉ R2, R2 ⋊⋉ R3,
and R3
⋊⋉ R4 are now, by (1),
1
2(=
2
2×2), 1
4(=
1
2×2),
and
1
2(=
2
2×2), respectively, which are exact. Note that, as
mentioned earlier, a trace tuple having a null for any of
the projected attributes is not accounted for in the respective
|πRi1-ID,...,Ri1-IDT(P)| because a null in a Rij-ID column of
a trace tuple indicates that there is no match found in Rij
for the respective combination of tuples to generate an output
in the (sub)query. One can easily verify that the estimated
selectivities for all other subqueries are all exact.
Theorem 2 (Exact Estimation with Dangling Tuples). Let
P be an execution plan of a query Q with a connected
acyclic join graph G(V, E). Let Q′ be a subquery of Q that
has a vertex-induced connected join subgraph G′(V ′, E′),
V ′ = {Ri1, . . . , Rim} ⊆ V . (1) gives the exact selectivity
of Q’ from the trace obtained by replacing the joins in the
query with the full outer joins, denoted by T(P).
Proof: Please see Appendix B.
For simplicity, hereafter an outer join refers to a full outer
join, unless otherwise stated. Note also that we have used
T(P) to denote the trace of a query, regardless of whether
the trace is generated by the joins, outer joins, or even other
operators (to be discussed shortly).
V.
SAMPLE TRACE AND SELECTIVITY ESTIMATION
Dangling tuples are retained in the outer and extended
outer joins. Thus, the result trace can contain more tuples than
the query result. This situation is exacerbated when relations
are preceded by selection predicates, which can eliminate
matching tuples from operand relations. In this section, we
discuss a sampling design that not only can signiﬁcantly
reduce the size of result trace, but it also can provide accurate
selectivity estimations.
61
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

R1
R2
R3
R4
1
2
a
b
A
B
I
II
(a) Matching of Join Attribute Values
R1-ID
R2-ID
R3-ID
R4-ID
1
a
A
I
(b) No Information about Dangling Tuples
R1-ID
R2-ID
1
a
2
b
(c) T(R1 ⋊
⋉ R2) Generated by Outer
Joins
R1-ID
R2-ID
R3-ID
1
a
A
2
b
B
(d) T((R1 ⋊
⋉ R2) ⋊
⋉ R3) Generated by Outer Joins
R1-ID
R2-ID
R3-ID
R4-ID
1
a
A
I
2
b
B
II
(e) T(((R1 ⋊
⋉ R2) ⋊
⋉ R3) ⋊
⋉ R4) Generated by Outer Joins
Figure 2.
Dangling Tuples in Relations
A. Sample Trace
A set of uniform random sample tuples is designated for
each relation. Instead of retaining all dangling tuples in the
trace, we keep only those dangling tuples that are related to
sample tuples. Certainly, query result tuples must be kept as
before. This partial trace is called a Sample Trace.
Example 3. (Sample Trace) Consider Fig. 3(a). Assume tuple
1, a, B, and I (in green and with asterisk) are picked as sample
tuples respectively from R1, R2, R3, and R4. We intend to
generate trace tuples only for query result tuples and dangling
tuples that are related to the sample tuples. In other words,
only those trace tuples containing any of 1, a, B, I, or result
tuples will be generated. That is, only the ﬁrst and third rows
of the original trace (red lines in Fig. 3(a)) will be generated
to be the Sample Trace, as shown in Fig. 3(b).
Deﬁnition 1. (Sample Trace) Given a join query Q with the
plan (((R1 ⋊⋉ R2)... ⋊⋉ Ri)... ⋊⋉ Rn), and {Si}n
i=1 are the
simple random samples of {Ri}n
i=1. The Sample Trace of Q,
T ∗, is the subset of the trace tuples of Q that are generated
by sample tuples from {Si}n
i=1.
To generate such a sample trace, the outer join operator
must be modiﬁed. The modiﬁed operator is called a Sample
Full Outer Join or just a Sample Outer Join. If the input
tuple is a sampled tuple or its joinable with a sample tuple,
then the sample outer join performs same as an outer join;
otherwise, it performs like the ordinary join operation. That
is, a dangling tuple in a join will become a result tuple of
the sample outer join only if it is a sample tuple from a base
relation or it is an intermediate result tuple derived from a
sample tuple. Certainly, a pair of match tuples generates an
output tuple in the sample outer join, like in an ordinary join.
R1
R2
R3
R4
1∗
2
a∗
b
A
B∗
I∗
II
(a) Sampled Tuple IDs with Asterisks and in Green
R1-ID
R2-ID
R3-ID
R4-ID
1
a
A
I
B
II
(b) Sample Trace with Tuple IDs
Figure 3.
An Example of Sample Trace
1: for each tuple tr ∈ Rr do
2:
for each match tl ∈ Rl do
3:
output a result tuple t
4:
tag[t]= tag[tl] OR tag[tr]
5:
if no match found in Rl and tag[tr]=1 then
6:
output a result tuples with nulls for all attributes
of Rr
7:
end if
8:
end for
9: end for
10: for each tuple tl ∈ Rl that found no match in Rr and
tag[tl]=1 do
11:
Output a result tuple with null for all attributes of Rl.
12: end for
Figure 4.
Algorithm of Sample Outer-join
Figure 4 describes the procedure of Sample Outer-join (Rl,
Rr). Let Rl and Rr be the left and right operand relations of
a sample outer join. A boolean tag tag[t] is associated with
each tuple t, with tag[t]=1 indicating that t is a sample tuple
or is derived from a sample tuple; tag[t]=0, otherwise.
B. Selectivity Estimation
Consider a query Q with the plan (((R1 ⋊⋉ R2)... ⋊⋉
Ri)... ⋊⋉ Rn). Let T ∗ be its sample trace generated by
replacing the joins with the sample outer joins. Given a
subquery q involving Ri1,..., Rij, ... , Rik, 1 ≤ j ≤ k,
we attempt to estimate the result size of q using T ∗. More
precisely, we will use only a subset of T ∗ that is related to the
sample tuples from Ri1, to estimate the query size.
Let Si1 be the set of IDs of sample tuples from Ri1. We
denote the subset of T ∗ that is related to the sample tuples
from Ri1 by T ∗
i1, that is, T ∗
i1 = σRi1 -ID∈Si1(T ∗). Let ni1 be
the number of result tuples of q generated by the sample tuples
from Ri1. It can be observed that
ni1 =

Y
Ri1−ID,...,Rik −ID
T ∗
i1

(2)
where Q is a projection operation. As mentioned, a tuple
with a null in any of the attributes Ri1-ID,..., Rik-ID will be
removed in the above projection. Our estimation formula for
the subquery q is stated in the following theorem.
Theorem 3 (Unbiased Estimation with Sample Trace). Con-
sider a query Q with the plan (((R1 ⋊⋉ R2)... ⋊⋉ Ri)... ⋊⋉ Rn),
and a subquery q involving Ri1,..., Rij, ... , Rik, 1 ≤ j ≤ k.
62
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

The query result size of q, Yq, is estimated as
bYq = ni1
|Ri1|
|Si1|
(3)
which is an unbiased estimator of the query result size of
subquery q. Here, |Ri1| and |Si1| are the sizes of Ri1 and
Si1, respectively. And ni1 is described in (2).
Proof: Please see Appendix C.
By Theorem 2.2 in [22], we get the variance of the query
estimation using sample trace in the following theorem.
Theorem 4 (Variance of Estimator). Let
S2 =
P|Ri1|
j=1 (Yj − Y q)2
|Ri1| − 1
in which Yj is the total number of result tuples generated
by the jth tuple in relation Ri1 in subquery q, and Y q =
1
|Ri1|
P|Ri1|
j=1 Yj. The variance of the query size estimation for
subquery q using sample trace is
V ar( ˆYq) = |Ri1|2
|Si1| S2

1 − |Si1|
|Ri1|

We can also get an unbiased estimation of V ar( ˆYq) from
the values in the sample relations. By Theorem 2.4 in [22], we
have the following theorem.
Theorem 5 (Approximation of Variance). Let
s2 =
P|Si1|
j=1 (yj − y)2
|Si1| − 1
in which yj is the total result tuples generated by the jth
tuple in the sample relation Si1, and y =
ni1
|Si1| An unbiased
estimation of V ar( ˆYj) is
v( ˆYq) = |Ri1|2
|Si1| s2

1 − |Si1|
|Ri1|

It is usually assumed that the estimated value bYq is nor-
mally distributed about the corresponding true query result size
Yq. When this assumption holds, by Central Limit Theory [22],
we derive the conﬁdence interval of Yq as follows.
Theorem 6 (Conﬁdence Interval of Yq). The associated
conﬁdence interval of Yq can be computed as

ˆYq − tp
q
v( ˆYq), ˆYq + tp
q
v( ˆYq)

where v( ˆYq) is in Theorem 5 and tp is the normal deviate
corresponding to the desired probability p.
VI.
EXPERIMENTAL RESULTS
The experiments will focus on the feasibility of using
sample traces by examining their estimation accuracy and
construction overheads, including space and time. We replace
the joins in a query by sample outerjoins to construct the
sample trace and use it to estimate the selectivities of joins in
all possible orders for the query. All programs are implemented
in Java on a X86 Linux Desktop, equipped with a 3.4 GHz
CPU, a 4GB RAM, and a 500GB hard drive (7200rpm, buffer
size 16MB). All data, including datasets, test queries, and
intermediate query results, is materialized on a local hard drive.
To facilitate the evaluation of sample outerjoins, we use index
ﬁles.
A. Datasets and Sampling Ratios
We conducted experiments on both synthetic data — the
TPC-H skewed datasets [23] , and real-life data — the DBLP
dataset [24]. We generated 1GB TPC-H datasets with different
skew factors of z =0.5, 1, and 1.5. Each TPC-H dataset has
8 relations. The DBLP database listed more than 1.3 million
articles in computer science. The DBLP dataset sources from
a relational enhancement of the original DBLP data, named
DBLP++ [25]. The many-many relationship between “author”
and “paper” has been replaced by introducing an “author of”
relation and two many-one relationships: from “author of” to
“author”, and “author of” to “paper”, as it is often did in
relational databases.
Sampling ratio indicates the fraction of tuples that are sam-
pled to construct the sample trace. We performed experiments
with sampling ratios from 0.1%, 0.2%, ..., to 1% to test the
average performance, as shown in Fig. 5.
B. Test Queries
A set of test queries is constructed for each dataset. For
the TPC-H datasets, we chose a subset of the original TPC-
H benchmark queries that contain joins of 3 to 8 selections.
The total number of queries is 15 from which we construct
50 subqueries, with different join orders, to examine the
accuracy and overheads. For the DBLP dataset, we generated
5 queries that involved joins of all relations in the database.
20 subqueries are tested. Note that, selection predicates are
deployed on relations. The ranges of selection predicates are
randomly generated to examine the average performance of
the sample traces under complex selection conditions.
C. Space Performance
Besides the query result tuples, the sample outer join
retains dangling tuples that are related to the sample tuples
in evaluation, which contributes to the space overhead.
The space overhead, denoted SO, of the sample trace is
calculated as
SO =
#{intermediate dangling tuples}
#{intermediate query result sizes} × 100%
in which “#{}” denotes the cardinality of a set, and “interme-
diate” means that we account for all sample traces generated
during the intermediate phases of a query.
The
space
overheads
for
datasets
TPCH1G05
and
TPCH1G1 are very close. It is because their skew factors
are relatively low (z = 0.5 and 1). When the skew factor z
increased to 1.5 (i.e., very skewed) in TPCH1G15, the space
overhead in Fig. 5(a) grew noticeably higher than the other
two low skewed TPC-H datasets (z = 0.5 and 1). Under the
same selection ranges in the test queries, greater skew factor
produced more dangling tuples, as explained earlier.
Results on the DBLP dataset are similar. The space over-
head increased with the increase of the sampling ratio. The
space overhead was affected by the skewness of the dataset
and the selection criteria of the queries.
D. Accuracy Performance
The results of the accuracy tests are shown in Fig. 5(b). We
use the absolute relative error, or relative error, E, to evaluate
63
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

0.2
0.4
0.6
0.8
1
0
5
10
15
20
25
Sampling Ratio (%)
Space Overhead (%)
TPCH1G05
TPCH1G1
TPCH1G15
DBLP
(a) Space Overhead Tests
0.2
0.4
0.6
0.8
1
5
10
15
Sampling Ratio (%)
Relative Error (%)
TPCH1G05
TPCH1G1
TPCH1G15
DBLP
(b) Estimation Relative Error
0
20
40
60
80
100
0
2
4
6
8
10
12
Number of Estimates
Relative Error (%)
TPCH1G05
TPCH1G15
(c) Bias Tests Sample Ratio = 0.1%
0
20
40
60
80
100
0
2
4
6
8
10
12
Number of Estimates
Relative Error (%)
TPCH1G05
TPCH1G15
(d) Bias Tests Sample Ratio = 1%
Figure 5.
Sample Trace Tests on Multiple Datasets
TABLE I.
AVERAGE PERFORMANCE
TPCH1G05
TPCH1G1
TPCH1G15
DBLP
Space Overhead (%)
6.26
6.32
13.68
10.40
Construction Time (s)
0.06
0.06
0.05
0.30
Time Overhead (%)
1.10
1.12
1.06
5.90
Relative Error (%)
2.62
5.41
10.76
5.56
the accuracy of using a sample traces, which is deﬁned as
follows.
E =

bY Est − Y Act
Y Act
 × 100%
where Y Act denotes the actual query result size and bY Est is
the estimated result size.
To evaluate the average performance, for each test query,
we generated 10 sets of sample traces, and use them to estimate
the sizes of the subqueries of these test queries.
As shown in Fig. 5(b), the relative errors of all datasets de-
creased gradually as the sampling ratio increased. The relative
errors for datasets TPCH1G05 (z = 0.5), TPCH1G1 (z = 1.0),
and DBLP decreased more smoothly than the relative errors for
TPCH1G15 (z = 1.5), which has a higher skew factor than
others. In general, it is more difﬁcult to represent a skewed
distribution than a smooth distribution. Therefore, the more
skewed the data, the higher the sampling ratio is needed to
achieve the same accuracy.
E. Average Performance
The average performances of sample trace on all datasets
are listed in Table I. Note that the minimum sampling ratio
is 0.1% and the maximum is 1%. The space overheads are
less than 13.68%, and construction times are no more than 0.3
seconds. In addition, under a low sampling ratio, the maximum
relative error is 10.76%, which occurred on TPCH1G15 dataset
when the sampling ratio is 0.1%.
In summary, with a small amount of samples (e.g., ≤
1%), accurate estimation of subquery result sizes (e.g., ≤
10%) can be obtained, even for highly skewed data. And
the time and space overheads are mostly small, around 1%
and 10%, respectively. The experimental results conﬁrm that
sample trace can be a viable approach for re-estimation of
selectivities for repetitive queries. It is effective and accurate.
F. Bias Test of the Sample Trace Estimator
In Section V, we proposed using bYq to estimate a subquery
with sample trace, which is proved to be unbiased in Theorem
3. Here we empirically validate the unbiasedness of bYq. For
demonstrative purpose, we choose one query and one of
its subqueries from previous test queries. We performed the
unbiased tests on two datasets TPCH1G05 and TPCH1G15,
where the sample ratios are equal to 0.1% and 1%, respectively.
A subquery is estimated using a different sample trace of the
same sample ratio. We generated 100 sample traces for this
purpose. To demonstrate the variation tendency of bias when
the number of estimations increases, we average the ﬁrst i
estimation values by absolute average relative error deﬁned as
Ei =

Pi
j=1 bY Est
qj
i
− Y Act
q
Y Act
q

× 100%
where i ≥ 1, Y Act
q
is the actual subquery size, bY Est
qj
is the
estimated value derived from the jth sample trace. For an
unbiased estimator, the absolute average relative error should
approach 0 as i (the number of tries) increases [22].
As observed in Fig 5(c) and Fig 5(d), the errors on both
TPCH1G05 and TPCH1G15 approached 0 as the number of
estimations increased. The experiments validate the earlier
proof of the unbiasedness of the sample trace estimator. Note
that when the skew factor is relatively higher, in TPCH1G15,
the relative errors are generally higher. Also, the error curves
in Fig 5(d) converged smoother than those in Fig 5(c), where
the sample ratios are equal to 1% and 0.1%, respectively.
VII.
CONCLUSIONS AND FUTURE WORK
In this paper, we proposed utilizing information about how
tuples are matching in the joins in a query, called the query
trace, and estimate selectivities of all subqueries of a repetitive
query. To gather sufﬁcient information in the traces, we used
the full outerjoins for queries with acyclic join graphs. We
have shown that the exact selectivities of joins in all execution
orders of the query can be computed from its trace.
To reduce the overheads incurred in collecting traces,
we enhanced the outerjoins with sampling capability so that
a random sample of the trace can be obtained efﬁciently.
Experimental results have shown that with a small amount of
sample tuples, accurate selectivity estimations can be obtained.
Sample traces can be a very efﬁcient and effective tool for the
re-optimization of repetitive queries.
For future work, we would like to give an estimated sample
size to get a satisfying estimation conﬁdence interval with
64
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

efﬁcient space budget. We are also interested in, for highly
skewed data, how to use adaptive sampling on the relations to
construct the adaptive sample trace.
REFERENCES
[1]
S. Babu, P. Bizarro, and D. DeWitt, “Proactive re-optimization,” SIG-
MOD ’05, (New York, NY, USA), ACM, 2005, pp. 107–118.
[2]
N. Kabra and D. J. DeWitt, “Efﬁcient mid-query re-optimization of sub-
optimal query execution plans,” SIGMOD ’98, (New York, NY, USA),
ACM, 1998, pp. 106–117.
[3]
V. Markl, V. Raman, D. Simmen, G. Lohman, H. Pirahesh, and M. Cil-
imdzic, “Robust query processing through progressive optimization,”
SIGMOD ’04, 2004, pp. 659–670.
[4]
A. Aboulnaga and S. Chaudhuri, “Self-tuning histograms: building
histograms without looking at data,” SIGMOD Rec., vol. 28, June 1999,
pp. 181–192.
[5]
S. Chaudhuri, V. Narasayya, and R. Ramamurthy, “Diagnosing estima-
tion errors in page counts using execution feedback,” (Washington, DC,
USA), IEEE Computer Society, 2008, pp. 1013–1022.
[6]
L. Lim, M. Wang, and J. S. Vitter, “Sash: a self-adaptive histogram set
for dynamically changing workloads,” VLDB ’2003, VLDB Endow-
ment, 2003, pp. 369–380.
[7]
V. Markl, G. M. Lohman, and V. Raman, “LEO: An autonomic query
optimizer for DB2,” IBM Syst. J., vol. 42, Jan. 2003, pp. 98–106.
[8]
M. Stillger, G. M. Lohman, V. Markl, and M. Kandil, “LEO - DB2’s
learning optimizer,” VLDB ’01, (San Francisco, CA, USA), 2001,
pp. 19–28.
[9]
F. Yu, W.-C. Hou, C. Luo, Q. Zhu, and D. Che, “Join selectivity re-
estimation for repetitive queries in databases,” in Database and Expert
Systems Applications, vol. 6861 of Lecture Notes in Computer Science,
pp. 420–427, 2011.
[10]
F. Yu, Constructing Accurate Synopses for Database Query Optimiza-
tion and Re-optimization. PhD thesis, Carbondale, IL, USA, 2013.
[11]
K. Ono and G. M. Lohman, “Measuring the complexity of join
enumeration in query optimization,” VLDB ’97, (San Francisco, CA,
USA), 1990, pp. 314–325.
[12]
N. Bruno, S. Chaudhuri, and L. Gravano, “Stholes: a multidimensional
workload-aware histogram,” SIGMOD ’01, (New York, NY, USA),
ACM, 2001, pp. 211–222.
[13]
S. Christodoulakis, “Implications of certain assumptions in database
performance evauation,” ACM Trans. Database Syst., vol. 9, June 1984,
pp. 163–186.
[14]
C. M. Chen and N. Roussopoulos, “Adaptive selectivity estimation using
query feedback,” SIGMOD ’94, (New York, NY, USA), ACM, 1994,
pp. 161–172.
[15]
V. Poosala and Y. E. Ioannidis, “Selectivity estimation without the
attribute value independence assumption,” VLDB ’97, 1997, pp. 486–
495.
[16]
S. Chaudhuri, V. Narasayya, and R. Ramamurthy, “A pay-as-you-go
framework for query execution feedback,” Proc. VLDB Endow., vol. 1,
Aug. 2008, pp. 1141–1152.
[17]
S. Chaudhuri and V. R. Narasayya, “An efﬁcient cost-driven index
selection tool for microsoft sql server,” VLDB ’97, (San Francisco,
CA, USA), 1997, pp. 146–155.
[18]
G. Valentin, M. Zuliani, D. C. Zilio, G. Lohman, and A. Skelley, “DB2
advisor: An optimizer smart enough to recommend its own indexes,”
ICDE ’00, (Washington, DC, USA), IEEE Computer Society, 2000,
pp. 101–.
[19]
O. W. Paper, “Oracle coporation: Performance tuning using the sql
access advisor.” http://otn.oracle.com, 2003.
[20]
H. Herodotou and S. Babu, “Xplus: a sql-tuning-aware query optimizer,”
Proc. VLDB Endow., vol. 3, Sept. 2010, pp. 1149–1160.
[21]
B. Dageville, D. Das, K. Dias, K. Yagoub, M. Zait, and M. Ziauddin,
“Automatic sql tuning in oracle 10g,” VLDB ’04, VLDB Endowment,
2004, pp. 1098–1109.
[22]
W. G. Cochran, Sampling Techniques, 3rd Edition. John Wiley, 1977.
[23]
S. Chaudhuri and V. Narasayya, “Program for tpc-d data generation
with skew..” ftp://ftp.research.microsoft.com/users/viveknar/tpcdskew.
[24]
M. Ley, “The DBLP computer science bibliography.” http://www.
informatik.uni-trier.de/∼ley/db/.
[25]
J. Diederich, “FacetedDBLP.” http://dblp.l3s.de/dblp++.php. [Retrieved
Dec, 2013].
APPENDIX
A. Proof of Theorem 1
Proof: We show that there is a one-to-one correspondence
between a result tuple of πRi1-ID,...,Rim-IDT(P) and a result
tuple of Q′.
“⇒” By the construction of the trace, for each edge
(Ri, Rj) in E, the Ri-ID and Rj-ID record the matches in
T(P). Let S be a set of tuples {ti1, . . . , tim}, tij ∈ Rij ∈ V ′,
whose IDs appear in a result tuple of πRi1-ID,...,Rim-IDT(P).
For each edge (Rij, Rik) ∈ E′, 1 ≤ j, k ≤ m, tij and tik must
match in their join attribute values because their IDs appear
in the same trace tuple. That is, the set of tuples S satisﬁes
all the join predicates placed between relations in V ′ and thus
can generate a result tuple in Q′ by joins. Moreover, the joins
of {ti1, . . . , tim} cannot generate more than one tuple.
“⇐” Let S′ = {t′
i1, . . . , t′
im}, t′
ij ∈ Rij ∈ V ′ be a set
of tuples that generates a result tuple in Q′. With joinable
tuples from V − V ′ (they always exist because there is
no dangling tuples in any join), S′, following plan P, can
generate at least one result tuple in Q. Since S′ has no null
tuple, their corresponding IDs must appear as a result tuple
of πRi1-ID,...,Rim-IDT(P). The projection πRi1-ID,...,Rim-ID will
retain only one set of IDs corresponding to {t′
i1, ..., t′
im} in
πRi1-ID,...,Rim-IDT(P).
B. Proof of Theorem 2
Proof: We show that there is a one-to-one correspondence
between a result tuple of πRi1-ID,...,Rim-IDT(P) and a result
tuple of Q′.
“⇒” Same arguments as in ⇒ of Theorem 1.
“⇐” Let S′ = {t′
i1, ..., t′
im}, t′
ij ∈ Rij ∈ V ′ be a set
of tuples that generates a result tuple in Q’. With joinable
tuples or null tuples (if there are no joinable tuples) from the
relations V − V ′, S′, following plan P, can generate at least
one result tuple in the query derived from Q in which all joins
are replaced by full outer joins; and all these result tuples
must have valid IDs for all Ri-ID attributes, Ri ∈ V ′, since
there is no null tuple in S′. Since duplicates are eliminated in
πRi1-ID,...,Rim-ID(T(P)), S′ can only produce one result tuple
in πRi1-ID,...,Rim-ID(T(P)).
C. Proof of Theorem 3
Proof: First of all, we denote the query result size of q
by Yq. The total result tuples in the subquery q generated by
the jth tuple of Ri1 is denoted by nj. i.e. In relation Ri1,
its jth tuple generated nj result tuples in the ﬁnal result of
subquery q. The query result size of q equals the sum of
result tuples generated by each tuple on relation Ri1. Thus
Yq = P|Ri1|
j=1 nj. Also note that Si1 is a simple random sample
without replacement of Ri1. And ni1 is the sum of result tuples
generated by Si1. By Theorem 2.1 of [22], we have bYq is an
unbiased estimator of Yq.
65
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-334-6
DBKDA 2014 : The Sixth International Conference on Advances in Databases, Knowledge, and Data Applications

