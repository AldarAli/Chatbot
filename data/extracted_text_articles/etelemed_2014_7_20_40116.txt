Patient's rationale: Patient Knowledge retrieval from health forums 
 
S. Melzi, A. Abdaoui, J. Azé, S. Bringay, P. Poncelet 
LIRMM UM2 CNRS, UMR 5506  
161 rue Ada, 34095 Montpellier, France 
dermo_samo@hotmail.fr, abdaoui@lirmm.fr, 
Jerome.aze@lirmm.fr, bringay@lirmm.fr, 
pascal.poncelet@lirmm.fr 
F. Galtier 
CIC, CHU Saint Eloi, 80 avenue Augustin Fliche 34295 
Montpellier Cedex 5, France 
f-galtier@chu-montpellier.fr 
 
Abstract— Online health forums are areas of exchange where 
patients, on condition of anonymity, can speak freely on their 
personal experiences. These resources are a gold mine for 
health professionals—giving them access to patient to patient, 
patient to health professional and even health professional to 
health professional exchanges. In this study, we used text 
mining techniques to analyse health forums in order to extract 
emotions (e.g., joy, anger, surprise, etc.) expressed by patients. 
After a study of real messages, we demonstrate the difficulty of 
manual annotation due to the low level of agreement between 
humans. We propose a method to identify the polarity of a 
message and extract one or several emotions. This method was 
validated on a substantial real dataset. 
Keywords— Health forum analysis, emotion analysis 
I. 
 INTRODUCTION 
Online health forums are areas of exchange where 
patients, on condition of anonymity, can speak freely about 
their personal experiences. Some examples are the very 
active forums, including healthforum.com[1], ehealthforum 
[2], 
which 
allow 
internet 
users 
(often 
non-health 
professionals) to exchange opinions on their health situation. 
Hancock [3] demonstrated that the ability to communicate 
anonymously via computers facilitates the expression of 
affective states such as emotions, opinions, doubts, risk fears, 
etc. These affective states are generally repressed in more 
traditional communication contexts, such as face to face 
interviews or when responding to surveys. These resources 
are a gold mine for health professionals—giving them access 
to patient to patient, patient to health professional and even 
health professional to health professional exchanges. For 
example, recently, the effects of new generation pills have 
been widely debated in French forums. This prompted some 
women to stop taking contraceptive pills, with a concomitant 
increase in abortions. Even if all patients do not use health 
forums, they represent a large and varied database of 
knowledge and patients’ perceptions on their illnesses and 
any healthcare they have received. In this highly subjective 
setting, the characterization and understanding of these 
perceptions is difficult but nevertheless particularly relevant 
for complementing and improving public health programs. 
As part of the French project called “Parlons de nous” 
(“Let’s talk about us”), we tried to combine different 
markers (emotions, risk fears, uncertainty, etc.) with respect 
to medical items (drugs, treatments, etc.) in order to identify 
common collocations (e.g., between mediator and fear). In 
this article, we focus on the identification of emotions as a 
specific sentiment analysis task. While many approaches 
have been proposed for the analysis of text polarity (positive 
and negative), few approaches focus on the analysis of 
feelings (joy, anger, sadness, etc.). From a corpus of 
messages collected on the English-language Spine Health 
website, we used the vocabulary of emotions of Mohammad 
and Turney [4] to automatically annotate messages. A part of 
the corpus was manually annotated by 60 annotators. Based 
on a study of the agreement between annotators, we were 
able to show that it was difficult, even for humans, to 
associate a particular emotion to a message. We decided to 
give two information items to health professionals: the 
polarity of the text (positive or negative) and associated 
emotions (e.g., joy). We looked for the best descriptors for 
these two items. Experiments on real datasets revealed the 
effectiveness of this approach and discussions with health 
professionals have shown the medical importance of 
identifying such information. 
The rest of this paper is organized as follows: in Section 
2, we identify the medical issues. In Section 3, we propose a 
first sentiment analysis categorization and recent methods. In 
Section 4, we describe the corpus used in our approach. The 
method we used is described in Section 5. In Section 6, we 
describe the main results. Finally, in Section 7, we conclude 
and give the main prospects. 
II. 
MOTIVATIONS 
As pointed out by Siegrist [5], one of the great challenges 
for health professionals is to capture patients’ satisfaction to 
answer the question "How can we improve our practice?". 
With this objective, Siegrist studied patients’ feedbacks after 
their stay in large American hospitals and turned them into 
raw data that could be tapped by the medical authorities for 
decision making. Using the forums as an object of study, we 
are getting closer to the patient private sphere. Indeed, 
patients express things in posts, they does not express in 
comments 
(even 
anonymous). 
However, 
precisely 
identifying the emotional state of patients through these 
messages is a difficult objective task and not always 
verifiable, as discussed by Quirk [6]. However, we could 
consider using these large amounts of emotionally-charged 
texts to construct indicators that are relevant for health 
professionals. An example of such an application is "We feel 
fine" [7]. This tool queries the web with the aim of assessing 
users’ moods. Every 10 minutes, the application considers 
140
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

sentences with emotional words and performs statistical 
calculations based on the type of feelings, age, gender, etc. 
An example of application is dedicated to pharmaceutical 
companies. They monitor the social web in general to 
identify texts in which patients talk about their medications 
and measure the associated emotional states. This feedback 
can 
help 
them 
improve 
their 
products 
or 
their 
communication about these products. Another example 
concerns the physicians who want to know the patients fears 
about the prescribed treatments. This feedback can help them 
to improve their communications to patients. 
The (semi-)automatic analysis of forums is difficult from 
a technological standpoint. Most (semi)-automatic methods 
used in the health domain are applied to publications and 
hospital reports. Adapting these methods to messages from 
social media like forums is not simple at all. Such messages 
are written by patients in rather a loose style. They vary in 
size (between a hundred and a thousand characters). They 
contain 
non-standard 
grammatical 
structures, 
many 
misspellings, abbreviations, emotion-rich expressions as well 
as emotion-rich words (I love, I hate), unconventional lay-
out, e.g., repeated use of capital letters (TIRED), 
unconventional spelling (enoooooough), and punctuation 
repetition (!!!!!!!!), slang words that are (or not) specific to 
the forum or the topic (LOL vs. IVF) and emoticons (:-)). 
Message volumes are generally very high (in the French 
forum dedicated to breast cancer on the Doctissimo site, 
there are more than 3,300 threads, some of which contain 
more than 2,000 replies). Finally, the processing of health 
forum data based on semi-automatic information extraction 
methods is a significant technological challenge. 
III. 
STATE OF THE ART 
Sentiment analysis has been widely studied since the 
early 2000s. Many communities are interested in this area 
and their definitions and interpretations are highly varied 
(e.g., psychology, social sciences, computational linguistics, 
natural language processing, data mining, etc.). Sentiment 
analysis involves the extraction of emotional states expressed 
or implied in texts [8]. It includes the following tasks: 
1. Subjectivity analysis [9] focuses on the detection of 
feelings based on subjective expressions or words; 
2. Polarity analysis [10] focuses on the detection of 
positive and negative polarity of texts; 
3. Emotional analysis [11] focuses on the emotional 
category of texts (e.g., anger, disgust, fear, etc.) 
4. Intensity analysis [12] focuses on different levels of 
polarity or emotion intensity (e.g., very positive, very sad, 
etc.). These approaches offer a more precise granularity of 
expressed opinions and emotions. 
We focus on the third task. Like most semi-automatic 
methods in the literature, we use the typology of emotions 
defined by Ekman [13], which describes six emotions, but 
many other typologies also exist ([14]; [15]; [16]). 
The methods used to analyse feelings are numerous and 
generally specific to the text type, e.g., tweets [17], press 
titles [18], etc., and application areas, e.g., social media 
analysis 
[19], 
gender 
impact 
in 
negotiations 
[20], 
identification of suicidal emails [21]. 
For all studied sentiment analysis tasks (polarity and 
emotions), most previous studies focus either on the creation 
of resources to describe feelings or on the use of these 
resources to classify texts according to sentiments. In the 
first category, most methods associate texts with emotional 
word resources. Most of these resources have been compiled 
for English texts and polarity analysis, e.g., General Inquirer 
[22], Linguistic Inquiry and Word count [23], MicroWNOp 
[24], sentiwordnet [25]. More specific resources, such as the 
DAL dictionary [26], Wordnet affect [27] or the lexicon of 
Mohammad and Turney [4] were created for emotional 
words. There are also approaches for extending these 
vocabularies for specific application domains by building 
manual rules [28], or identifying co-occurring words with 
words already identified as denoting emotions through large 
corpora [29] or the web [30]. For classification, most 
approaches use machine learning techniques based on 
specific attributes, including emotion words ([31]; [18]) to 
build a statistical model from a corpus of texts and use it to 
detect feelings in other texts. 
While many of these methods are effective on large text 
corpora, they are limited in the case of short texts such as 
tweets or specific texts as in health forums. In our study, 
these limitations were mainly due to the subjectivity of the 
annotation task, as we describe in Section 4.2. 
IV. 
CORPUS 
A. Data collection and  annotation 
We built a corpus from 17,000 messages collected in the 
English-language Spine-health forum. We automatically 
annotated the corpus with the vocabulary of emotions of 
Mohammad and Turney [4]. This lexicon consists of more 
than 14,000 entries characterized by their polarity and 
associated with 8 emotions. In this work, we consider only 6 
emotions (Ekman, 1992): anger, disgust, fear, joy, sadness 
and surprise. 
Each word in the lexicon could be associated with several 
emotions (e.g., the word abandoned was associated with the 
emotions fear, anger and sadness). This automatic annotation 
enabled us to filter 22% of the messages (not containing 
emotion words). In order to focus only on emotions 
associated with medical items, we used MeSH to identify 
medical units in the text, which allowed us to filter messages 
without any medical references (6% of messages). In a 
message, many emotions were usually expressed because the 
messages were relatively long. We therefore chose to 
segment the messages in sentences. We finally kept 3,000 
sentences to constitute an Automatically Annotated Corpus 
(AAC) and labelled sentences with several emotions by the 
most frequent one (re-annotation step). 
A subset of this corpus (600 sentences) was manually 
annotated by 60 non-health professionals, i.e. basically 
Master’s students and computer science researchers from our 
lab. We called this the Manually Annotated Corpus (MAC). 
We thus set up a web-based platform. Unlike Strapparava 
and Mihalcea [18] who used an interface to annotate and 
capture many emotions through an emotion-intensity cursor, 
we decided to simplify the task and asked the annotators to 
141
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

identify only the presence of emotions expressed in the texts. 
Each sentence was pre-labelled automatically via the 
lexicon, the corresponding emotion was shown by default 
but could be unchecked if the annotator believed that it was 
not expressed in the sentence. If the sentence did not express 
any emotion, all emotions were to be unchecked. Finally, if 
the annotator could not decide, "I do not know" was selected. 
Table 1 shows the distribution of sentences in both 
corpora according to six emotional categories. The AAC 
corpus was clearly unbalanced and both fear and sadness 
emotions were best represented. In the MAC corpus, 45% of 
the sentences were annotated as neutral (no emotion) and 9% 
were undecidable. We also noted after the re-annotation that 
the MAC corpus was better balanced than the AAC corpus. 
However, surprise was very poorly represented. 
TABLE I.  
PERCENTAGE OF SENTENCES IN BOTH AAC AND MAC 
CORPORA ACCORDING TO 8 CATEGORIES (J – JOY, SU - SURPRISE, F - FEAR, 
A - ANGER SA - SADNESS, D - DISGUST, N - NEUTRAL, DK - DO NOT 
KNOW) BEFORE AND AFTER RE-ANNOTATION. 
AAC 
J 
Su 
F 
A 
Sa 
D 
N 
DK 
Before 
22 
14 
39 
22 
39 
18 
/ 
/ 
After 
13 
4 
33 
9 
35 
6 
/ 
/ 
MAC 
J 
Su 
F 
A 
Sa 
D 
N 
DK 
Before 
10 
4 
17 
13 
19 
14 
45 
9 
After 
14 
6 
23 
14 
25 
18 
0 
0 
 
B. Between-annotator agreement 
We used the Kappa measure to assess the between-
annotator agreement. For this, 150 sentences from the MAC 
were annotated by two non-professional annotators. We got a 
Kappa of 0.26, which clearly shows that the agreement 
between annotators was very low. In addition, we measured 
the agreement between health professional annotators and 
non-professionals for the same 150 sentences and obtained a 
moderate agreement of 0.46. This preliminary experiment 
highlighted the difficulty of the manual annotation task. 
Moreover, the disagreement between annotators was mainly 
due to the variability between people and not their sensitivity 
to health (professional vs. non-professional). 
A first bias, already identified by [32], was in considering 
the perspective of the annotator/reader likely differed 
markedly from that of the author of the message. Indeed, 
health forum posts treat topics such as disease, treatment, etc. 
This information is negative by nature and most of the 
annotators, by empathy, associated an emotion such as 
sadness to factual information such as the description of a 
diagnosis. For example, the sentence "I am also HLA-B27 
negative, so was diagnosed with a spondyloarthropathy" was 
annotated as sad in our corpus, although it contained a 
factual diagnosis. A second bias concerned the fact that the 
corpus was in English, while the annotators were native 
French-speakers. Furthermore, by studying sentences with 
gaps in the annotations, we noticed that it was easier to 
identify the polarity than the emotion. It was also easier to 
predict positive emotions than negative emotions because 
negative emotions share very similar vocabulary. We also 
noted that surprise was the hardest emotion to identify, as 
also noted by Strapparava and Mihalcea [18] who argue that 
surprise is not often taken into account in studies of emotions 
as it is neutral in nature. For example, the sentence "I 
discovered its effect on me the hard way, hugging the toilet 
after a painful back procedure, ugh!" None of our annotators 
considered the emotion surprise, despite the presence of the 
word "discover".  
The quality of our annotated corpus was actually quite 
questionable. Indeed, the annotators were not sufficiently 
coached with specific instructions to avoid the biases 
mentioned above. Tests of internal consistency (inter-
individual reproducibility) would have to be done to assess if 
the annotators were consistent over time. Another possibility 
would be to get several annotators to annotate sentences and 
choose labels by majority vote. Finally, even with its 
drawbacks, this study gave a relatively clear picture of the 
difficulties involved in obtaining a qualitative corpus and the 
methodology to improve its quality. Based on these findings, 
we then decided to compare the results obtained with the 
AAC and MAC corpus, knowing that most of the methods of 
the state of the art only use AAC corpus. We evaluate 
different methods to characterize forum texts based on: 1) a 
two-category classification to identify the polarity of 
emotions; 2) a multi-category classification for six emotions: 
a sentence could only be associated with a single emotion 
class. Surprise was eliminated because of its neutrality. This 
typology is similar to that described by Roberts [17]; 3) a 
multi-label classification allowed us to associate a sentence 
to several emotion classes. 
V. 
EXPERIMENTAL PROCEDURE 
Our approach relies on a classification method based on 
attributes such as unigrams, bigrams and specific attributes, 
defined to capture traces of emotions in messages. It consists 
of two steps: 1) pre-processing of sentences from messages, 
and 2) classification of these sentences. Evaluation of the 
results depends on the classification performed. 
Pre-treatments: forum posts are specific in the sense 
that the words used are not necessarily found in conventional 
dictionaries 
(slang, 
special 
formatting, 
abbreviations, 
emoticons, etc.). It is therefore necessary to standardize them 
by generalizing their content. To do this, we applied the pre-
processing procedure outlined in Table 2 and corresponding 
to the chain set up by (Balahur, 2013) for tweets. 
TABLE II.  
APPLIED PRE-PROCESSING 
Pre-processing 
Example 
Resource 
Repeated punctuation 
!!!! 
/ 
Specific layout 
TIRED 
/ 
Emoticon 
:-) 
/ 
Slang 
2mr > Tomorrow 
Chatslang.com 
Emotional words 
Fear 
Mohammad’s lexicon [4] 
Classification: We used the following attributes in order 
to find the best emotion descriptors: 
– Attributes based on N-Grams (U, U+B): Unigrams, 
Unigrams and Bigrams; 
– Emotion words (EW): if a sentence contains two words 
corresponding to the emotion joy, it takes the value 2 for the 
corresponding attribute; 
142
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

– Smileys (SMI): all emoticons (:-):-(...) were classified 
according to the six emotions. If a sentence contains a smiley 
related to joy, it takes the value 1 for the corresponding 
attribute; 
- Amplifiers (AM): These attributes correspond to 
punctuation (!,?...), repeated letters (looool) and capitalized 
words (HATE). If a sentence contains such elements, it takes 
the value 1 for the corresponding attribute; 
- The emotion context (CONT): we used two attributes 
that we call neighbour emotion and overall emotion. The 
first attribute is true if the sentence that precedes or follows 
the sentence expresses the same emotion and the overall 
feeling is the true value if there is another sentence in the 
message that expresses the same emotion. 
Like Bechet [33], we enriched the attributes with patterns 
obtained using a sequential pattern algorithm (PAT). For 
this, we used the MeSH medical thesaurus to identify 
medical words (labelled MW), the lexicon of emotion words 
(labelled EW) to identify traces of emotions and a 
lemmatizer for grammatical category words (labelled JJ, NN, 
VV, MD, etc.). Each sentence was then considered as a 
sequence of itemsets corresponding to a combination of 
these three labels. We then used the GSP algorithm [34] to 
obtain frequent patterns, i.e. frequent sequences. We used 
only those containing at least one label for a medical entity 
and another label for an emotion word. These patterns were 
then used as attributes. A sentence was labelled true for a 
pattern if its syntactic form fit the pattern. Figure 1 
summarizes the protocol for obtaining patterns. 
 
Initial sentence: 
Chronic pain may cause secondary depression 
 
Emotional and Medical word tagging: 
Chronic/MW 
pain/EW/MW 
may 
cause 
secondary 
depression/EW/MW 
 
Grammatical tagging: 
Chronic/MW/JJ 
pain/EW/MW/NN 
may/MD 
cause/VV 
secondary/JJ depression/EW/MW/NN 
 
Sequence: 
MW/JJ EW/MW/NN MD VV JJ EW/MW/NN 
Figure 1.   Sequence definition 
Evaluation: The quality of the two-class classification 
was evaluated using the standard precision measurements P 
(percentage of correct predictions), recall R (percentage of 
correct labels found by the system) and F-measure F 
(harmonic mean of precision and recall). For multi-class 
classification, we calculate both the average Fmi at a micro 
level (R and P were calculated by constructing the overall 
contingency table) and Fma at a macro level (R and P were 
calculated for each class and averaged). For multi-label 
classification, other metrics were needed. Indeed, if we took, 
for example, a sentence belonging to both classes sadness 
and anger, the system could predict: sadness and anger (the 
prediction was correct), sadness (the prediction was partially 
correct) and disgust (the prediction was wrong). So there 
were degrees of possible misclassification. Other measures 
[35] were then used such as the Hamming loss HL (accuracy 
for each class averaged per class), accuracy A (averaged for 
all examples) and macro F-measure Fma. 
VI. 
RESULTS AND DISCUSSION 
We used implementations of Weka for bi-class and 
multi-class 
classification 
and 
Meka 
for 
multi-label 
classification. We used the SMO implementation of the 
SVM classifier of Weka with default settings. We used the 
CC chain classification implemented in Meka for multi-label 
classification. We used two datasets: MAC and AAC 
corpora (considering that the majority emotion label set after 
automatic annotation was the class to predict). We carried 
out a cross-validation (10-fold) and used the attributes 
described in Section 5. Table 3 presents the AAC corpus 
results. We do not present the MAC corpus results which 
were similar that seems to suggest that even with the 
previsous limitations mentioned in Section IV.B, the MAC 
corpus has at least the same quality as the corpus used in the 
literature and obtained automatically from emotional word 
ressources. 
TABLE III.  
COMPARISON OF RESULTS OBTAINED ACCORDING TO A SET 
OF ATTRIBUTES USING THE AAC CORPUS 
 
Bi-class 
M-class 
M-labels 
Attributes 
R 
P 
F 
Fmi 
Fma 
HL 
A  
Fma 
U 
U+B 
U+B+EW 
U+B+EW+SM+AM 
U+B+EW+CONT 
U+B+EW+PAT 
62.7 
65.9 
66.3 
53.4 
53.6 
66.2 
57.8 
61.5 
64.1 
52.4 
45.5 
65.2 
60.1 
63.6 
65.1 
52.9 
49.2 
65.7 
24.4 
24.8 
27.3 
23.4 
25.2 
26.1 
23.2 
22.3 
25.1 
20.7 
22.5 
25.8 
0.24 
0.14 
0.12 
0.25 
0.22 
0.15 
51.5 
58.3 
61.4 
55.5 
55.4 
58.2 
58.2 
59.3 
61.8 
55.8 
57.6 
62.4 
 
The bi-class classification gave the best results, which 
seemed fairly consistent because the two classes were better 
represented. This task was also easier for human annotators. 
Multi-label classification gave better results than the multi-
class classification because one example could be associated 
with multiple classes. Moreover, we detected only little 
differences between the micro and macro F-measures for 
multi-class classifications, which suggests that all classes 
were hard to identify. These results should be compared with 
the inter-annotator agreement (see section 4.2). In both cases, 
the task was difficult, but the semi-automatic method seemed 
to detect patterns more systematically, except in specific 
cases such as irony. 
We could also conclude that the best descriptors were a 
combination of unigram and bigram with emotion words (U 
+ B + EW). Taking smileys and amplifiers into account did 
not improve the classification. Indeed, smileys were often 
used for irony, which was not captured by considering their 
presence in the sentence. For example, the sentence "I 
stopped working in 1/09 and kind a thought that at some 
point I would get better, in hindsight, also rather dumb:-) 
instead of picking up the pace of getting worse significantly" 
was automatically associated with the label joy because of 
the smiley:-),  even though it was used by the patient to 
indicate his bitterness. A simple improvement consists in 
changing the polarity of the smiley if in the near context 
there is a contradictory polarity. 
143
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

Similarly, the context was not an attractive attribute. 
Indeed, messages were often long (7 sentences on average in 
our corpus) and contained many feelings (more than 6 
emotions in 41% of the messages). Two consecutive 
sentences often contained different uncorrelated emotions. 
Finally, patterns were also ineffective because they were too 
general. They could easily be used to improve the accuracy if 
we define them by class of emotion. 
Note that when the classifiers were wrong, they often 
placed the sample in a "close" class, with the same polarity. 
These incorrect predictions were due to the fact that the 
classes shared many words (such as anger, disgust and 
sadness). Dictionaries and lemmatizers are used as resources, 
so the method could easily be applied for other languages 
using similar resources. 
VII. CONCLUSIONS AND PERSPECTIVES 
Here we describe a method for analysing emotions in 
health forums. The main challenge was the acquisition of 
annotated data, and this step will be further improved. For 
the extraction of emotions, we compared different attributes 
for different classification tasks (two-class, multi-class and 
multilabel) and showed that the most effective were a 
combination of unigrams and bigrams and emotion words for 
classification bi-classes. However, suggesting a precise label, 
despite the precision obtained, could be relevant for the 
health care professionals involved in such studies. 
[36]Prospects associated with this work are numerous. 
From the emotion analysis standpoint, we will apply our 
method on larger datasets not specific to health, such as the 
SemEval challenge [37] and compare our method with other 
published methods such as SWAT [38], uPAR [31] and UA 
[30]. We will also take shifters into account. Indeed, Smith 
and Lee [36] showed that the polarity of a term is often 
modified by the context surrounding it, including markers of 
negation. In the sentence "This treatment does not make her 
happy", the negation changes the polarity of the sentence 
from positive to negative. In the case of emotions, it is harder 
to understand the impact of these shifters because there are 
close links between emotions, such as between the failure to 
be happy and to be sad. For this, more complex emotion 
models should be used, such as SentiSens [39] which takes 
the relationship between emotions into account (e.g., hate vs. 
love). In addition, we will build a lexicon of emotion words 
specific to our area, as proposed by Carrillo de Albornoz 
[39]. For this, several options are considered. Smith and Lee 
[36] used Wordnet [40] to associate new words with words 
already associated with an emotion based on the relationship 
"similar to" for adjectives and hyponymy for nouns and 
verbs. Inspired by the Turney and Littman approach [41], it 
is also possible to search for frequently co-occurring 
adjectives (or other grammatical forms) using the web or 
large corpora [30]. We will also validate the genericity of our 
approach on a French corpus. Indeed, our method relies 
solely on lexicons and a stemming tool. Finally, the 
attributes used in our study are focused on the expression of 
emotions through the lexicon and not through the syntax or 
through other discourse markers. An improvement would be 
to integrate these aspects, although complex rhetorical 
constructions are not frequent in the studied forums. 
We also identified issues related to the field of 
application. The spine-health forum is specialised in the 
topic of "pain" and discusses a pathology which is a disease 
of the elderly. The nature of the text message is closely 
related to these two factors (little smileys or slang, little 
expressions of joy, etc.). To explore other feelings, we need 
to diversify the themes of the studied forums. Once the 
emotions are identified, many applications can be envisaged. 
The discovery of novelties such as medical associations 
between medical entities and emotional markers can be used 
for informational searches by laboratories (e.g., what 
patients think of this medicine?), physicians (e.g., what 
patients think of this operation?), patients, etc. More 
generally, emotion searches could be used to model 
variations in emotions over time. For example, over time we 
frequently observed changes in the emotions of patients, e.g., 
"fear and surprise", "surprised and angry", etc. Furthermore, 
we could study the influence of the media on the patients’ 
emotion changes, e.g., the case of the third generation pill. 
Another 
application 
might 
be 
to 
identify 
patients 
communities based on the expressed emotions. For 
example, in the debate about the effects of new generation 
pills, it was noticed that many of the comments were related 
to religious beliefs. This information is essential for 
moderators. This applications list is not exhaustive. 
Identification of emotions is a step toward these 
applications. 
ACKNOWLEDGMENT 
This paper is based on studies supported by the Maison 
des Sciences de l’Homme de Montpellier (MSH-M) within 
the framework of the French project Let’s talk about us 
(Parlons de nous) [42]. 
REFERENCES 
[1] 
“healthforum.” 
[Online]. 
Available: 
http://www.healthforum.com/. [Accessed: 05-Jan-2014]. 
[2] 
“ehealthforum.” 
[Online]. 
Available: 
http://ehealthforum.com/. [Accessed: 05-Jan-2014]. 
[3] 
 J. T. Hancock, C. Toma, and N. Ellison, “The truth 
about lying in online dating profiles,” in Proceedings of the 
SIGCHI conference on Human factors in computing systems, 2007, 
pp. 449–452. 
[4] 
 S. M. Mohammad and P. D. Turney, “Emotions Evoked 
by Common Words and Phrases : Using Mechanical Turk to 
Create an Emotion Lexicon,” in Workshop on Computational 
Approaches to Analysis and Generation of Emotion in Text, 
Stroudsburg, PA, USA, 2010, pp. 26–34. 
[5] 
 J. Siegrist, Emotions and Health in Occupational Life: 
New Scientific Findings and Policy Implications : Inauguration 
Speech Belle Van Zuylen Professorship. Universiteit Utrecht, 
1994. 
[6] 
 R. Quirk, A Comprehensive grammar of the english 
language. London [etc.]: Longman, 1985. 
[7] 
 S. D. Kamvar and J. Harris, “We feel fine and searching 
the emotional web,” in ACM International conference on Web 
search and data mining, New York, NY, USA, 2011, pp. 117–126. 
[8] 
 B. Liu, Sentiment Analysis and Opinion Mining, vol. 5. 
144
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

Morgan & Claypool Publishers, 2012. 
[9] 
 J. Wiebe, T. Wilson, and C. Cardie, “Annotating 
expressions of opinions and emotions in language,” Language 
Resources and Evaluation, vol. 39, no. issue 2–3, pp. 165–210, 
2005. 
[10] 
 E. Boiy, P. Hens, K. Deschacht, and M.-F. Moens, 
“Automatic sentiment analysis in on-line text,” in 11th 
International Conference on Electronic Publishing, Vienna, 
Austria, 2007, pp. 349–360. 
[11] 
 C. Lu, J. Hong, and S. Cruz-lara, “Emotion Detection in 
Textual Information by Semantic Role Labeling and Web Mining 
Techniques,” 
in 
Third 
Taiwanese-French 
Conference 
on 
Information Technology - TFIT 2006, Nancy, France, 2006. 
[12] 
 M. Mulder, A. Nijholt, M. D. Uyl, and P. Terpstra, “A 
lexical grammatical implementation of affect,” in 7th International 
Conference on Text, Speech & Dialogue, Heidelberg, 2004, pp. 
171–177. 
[13] 
 P. Ekman, “An argument for basic emotions,” Cognition 
and emotion, vol. 6, no. 3–4, pp. 169–200, 1992. 
[14] 
 R. Plutchik, “A general psychoevolutionary theory of 
emotion,” in Emotion: Theory, research, and experience: Vol. 1. 
Theories of emotion, R. Plutchik and H. Kellerman, Eds. New 
York: Academic press, 1980, pp. 3–33. 
[15] 
 L. Pearl and M. Steyvers, “Identifying emotions, 
intentions, and attitudes in text using a game with a purpose,” in 
Workshop on Computational Approaches to Analysis and 
Generation of Emotion in Text, USA, 2010, pp. 71–79. 
[16] 
 V. Francisco and P. Gervás, “Automated mark up of 
affective information in english texts,” in 9th international 
conference on Text, Speech and Dialogue, Berlin, Heidelberg, 
2006, pp. 375–382. 
[17] 
 K. Roberts, M. A. Roach, J. Johnson, J. Guthrie, and S. 
M. Harabagiu, “EmpaTweet: Annotating and Detecting Emotions 
on Twitter,” in Eight International Conference on Language 
Resources and Evaluation, Istanbul, Turkey, 23-25. 
[18] 
 C. Strapparava and R. Mihalcea, “Learning to identify 
emotions in text,” in Symposium on Applied Computing, New 
York, NY, USA, 2008, pp. 1556–1560. 
[19] 
 A. Balahur, “Sentiment Analysis in Social Media 
Texts,” in 4th Workshop on Computational Approaches to 
Subjectivity, Sentiment and Social Media Analysis, Atlanta, 
Georgia, 2013, pp. 120–128. 
[20] 
 B. Boneva, R. Kraut, and D. Frohlich, “Using E-mail for 
Personal Relationships The Difference Gender Makes,” American 
Behavioral Scientist, vol. 45, no. 3, pp. 530–549, Jan. 2001. 
[21] 
 J. P. Pestian, P. Matykiewicz, M. Linn-Gust, B. South, 
O. Uzuner, J. Wiebe, K. B. Cohen, J. Hurdle, C. Brew, and others, 
“Sentiment analysis of suicide notes: A shared task,” Biomedical 
Informatics Insights, vol. 5, no. Suppl. 1, p. 3, 2012. 
[22] 
 P. J. Stone, D. C. Dunphy, M. S. Smith, and D. M. 
Ogilvie, The General Inquirer: A Computer Approach to Content 
Analysis. MIT Press, 1966. 
[23] 
 Y. R. Tausczik and J. W. Pennebaker, “The 
Psychological Meaning of Words: LIWC and Computerized Text 
Analysis Methods,” Journal of Language and Social Psychology - 
J LANG SOC PSYCHOL, vol. 29, no. 1, pp. 24–54, 2010. 
[24] 
 S. 
Cerini, 
V. 
Compagnoni, 
A. 
Demontis, 
M. 
Formentelli, and G. Gandini, “Language resources and linguistic 
theory: 
Typology, 
second 
language 
acquisition, 
English 
linguistics.,” A. Sansò, Ed. Milano, IT, 2007. 
[25] 
 S. 
Baccianella, 
A. 
Esuli, 
and 
F. 
Sebastiani, 
“SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment 
Analysis and Opinion Mining.,” in LREC, 2010, vol. 10, pp. 2200–
2204. 
[26] 
 C. Whissell, The dictionary of affect in language. 
Academic Press, 1989. 
[27] 
 C. Strapparava and A. Valitutti, “WordNet-Affect: an 
affective extension of WordNet,” in Proc. of 4th International 
Conference on Language Resources and Evaluation, Lisbon, 2004, 
pp. 1083–1086. 
[28] 
 A. Neviarouskaya, H. Prendinger, and M. Ishizuka, 
“Affect analysis model: Novel rule-based approach to affect 
sensing from text,” Natural Language Engineering, vol. 17, no. 1, 
pp. 95–135, Jan. 2011. 
[29] 
 A. Harb, M. Plantié, G. Dray, M. Roche, F. Trousset, 
and P. Poncelet, “Web Opinion Mining : How to extract opinions 
from blogs ? Categories and Subject Descriptors,” in International 
conference on Soft Computing as Transdisciplinary Science and 
Technology, 2008. 
[30] 
 Z. Kozareva, B. Navarro, S. Vazquez, and A. Montoyo, 
“UA-ZBSA: a headline emotion classification through web 
information,” in 4th International Workshop on Semantic 
Evaluations, Stroudsburg, PA, USA, 2007, pp. 334–337. 
[31] 
 F. Chaumartin, “UPAR7 : A knowledge-based system 
for headline sentiment tagging,” in 4th International Workshop on 
Semantic Evaluations, Prague, Czech Republic, 2007, pp. 422–
425. 
[32] 
 M. Sokolova and V. Bobicev, “Sentiments and Opinions 
in Health-related Web messages,” in RANLP, 2011, pp. 132–139. 
[33] 
 N. Béchet, P. Cellier, T. Charnois, B. Crémilleux, and S. 
Quiniou, “SDMC : un outil en ligne d’extraction de motifs 
séquentiels pour la fouille de textes,” in Conférence Francophone 
sur l’Extraction et la Gestion des Connaissances, Toulouse, 
France, 2013. 
[34] 
 M. Zhang, B. Kao, C.-L. Yip, and D. Cheung, “A GSP-
based efficient algorithm for mining frequent sequences,” in Proc. 
of IC-AI, 2001, pp. 497–503. 
[35] 
 J. Read, B. Pfahringer, G. Holmes, and E. Frank, 
“Classifier Chains for Multi-label Classification,” in European 
Conference on Machine Learning and Knowledge Discovery in 
Databases: Part II, Berlin, Heidelberg, 2009, pp. 254–269. 
[36] 
 P. Smith and M. Lee, “A CCG-Based Approach to Fine-
Grained Sentiment Analysis in Microtext,” in AAAI Spring 
Symposium: Analyzing Microtext, 2013. 
[37] 
 C. Strapparava and R. Mihalcea, “SemEval-2007 Task 
14: Affective Text,” in Proceedings of the 4th International 
Workshop on Semantic Evaluations, USA, 2007, pp. 70–74. 
[38] 
 P. Katz, M. Singleton, and R. Wicentowski, “SWAT-
MP: the SemEval-2007 systems for task 5 and task 14,” in 4th 
International Workshop on Semantic Evaluations, Stroudsburg, 
PA, USA, 2007, pp. 308–313. 
[39] 
 J. Carrillo de Albornoz, L. Plaza, and P. Gervás, 
“SentiSense: An easily scalable concept-based affective lexicon for 
sentiment analysis,” in 8th International Conference on Language 
Resources and Evaluation, Istanbul, Turkey, 23-25. 
[40] 
 G. A. Miller, “WordNet: A Lexical Database for 
English,” Commun. ACM, vol. 38, no. 11, pp. 39–41, Nov. 1995. 
[41] 
 P. D. Turney and M. L. Littman, “Measuring praise and 
criticism: Inference of semantic orientation from association,” 
ACM Transactions on Information Systems (TOIS), vol. 21, no. 4, 
pp. 315–346, 2003. 
[42] 
“Maison des Sciences de l’Homme de Montpellier. 
Parlons de nous,” 07-Jan-2013. Available: http://www.msh-
m.fr/programmes/programmes-2013/parlons-de-nous/ 
145
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

