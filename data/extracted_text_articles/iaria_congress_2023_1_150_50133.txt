 
 
Autonomic Computing in the Cloud: An Overview of Past, Present and Future Trends 
 
Alistair McLean, Roy Sterritt 
School of Computing, Ulster University 
Belfast, Northern Ireland 
Email: Mclean-a13@ulster.ac.uk | r.sterritt@ulster.ac.uk  
 
 
Abstract - The use of cloud computing has grown at an 
exceptional rate, with offerings from major cloud providers 
removing the requirement for organisations to acquire and 
maintain their own infrastructure. However, the complexity of 
computer-based systems deployed to the cloud means that 
efficient and effective management of resources is difficult for 
humans to achieve. The application of autonomic computing to 
this environment has solved the problem of complexity and 
management by creating systems that can self-manage through 
self- and environmental awareness. This work aims to 
investigate how the application of autonomic computing has 
advanced the field of cloud computing with an overview of 
historical developments, current state-of-the-art solutions, and 
expected future trends. Investigation shows that optimisation of 
cloud services with respect to operational costs, energy 
consumption, Service Level Agreements (SLAs), and Quality of 
Service (QoS) has, and remains to be, an active area of research. 
With the protection of data and services in the cloud being a 
priority for users, we discuss advancements in the application of 
security-aware components for autonomic cloud computing. 
Ethical implications of cloud computing are discussed, 
principally the energy consumption of data centres, highlighting 
the growing research in the field of energy efficient computation 
and resource management.  The contribution of this paper is 
Systematization of Knowledge (SoK).  
 
Keywords – Cloud Computing; Autonomic Computing; 
Autonomous Systems; Service Oriented Architecture. 
I. INTRODUCTION 
Cloud computing has dramatically changed the way 
businesses approach creating, deploying, maintaining, 
scaling, and financing their information technology services. 
Small to Medium-sized Enterprises (SMEs) can benefit from 
accessing 
vast 
computational 
resource 
without 
the 
unaffordable upfront costs of provisioning and maintaining 
their own hardware or data centres [1][2]. Additionally, the 
diverse offerings from cloud computing providers today 
appeals to a range of consumers, from SMEs to large 
multinational corporations. The adoption rate of cloud 
technologies over the last few decades has been high and it is 
expected that organisations will continue to embrace cloud 
computing, with adoption of public cloud services 
accelerating [3][4].  
Simultaneously, organisations have been working on 
improving the dependability of their systems. In an 
increasingly technological world, the reliance on computing 
systems is more important than ever. The criticality of 
computing systems is such that unplanned application 
downtime and critical IT failures can have massive business 
impact – potentially costing large organisations hundreds of 
thousands of dollars per hour [5]. Autonomic computing is an 
area that emerged to help address the challenge of creating 
reliable, fault tolerant, self-managing systems. The principles 
of autonomic computing are now commonplace, having 
already been incorporated into many computing systems. 
Work in the area has proposed that all computer-based 
systems should indeed be autonomic [6]. 
The aim of this paper is to detail how the principles of 
Autonomic Computing have been applied throughout the 
emergence of Cloud Computing. This section continues with 
“what is Cloud Computing?” and “what is Autonomic 
Computing?”, followed by a history of the areas in Section 2.  
Section 3 then looks at the current state of the art, and Section 
4 describe potential future trends before the paper concludes.  
 
A. What is Cloud Computing? 
Cloud computing is a method of utilising remote 
computing resource and capacity provided by means of an 
Internet service [7]. It has become customary in the field of 
cloud computing to describe cloud service models with the 
“as a Service” (aaS) phrase – prepended by the technology on 
offer [8]. Although there have been many takes on this “as a 
Service” approach – the major cloud service providers have 
generally 
adopted a 
three-tier approach, each tier 
representing a distinct level of resource abstraction and 
control. They include: 
1. Software as a Service (SaaS) 
2. Platform as a Service (PaaS) 
3. Infrastructure as a Service (IaaS) 
 
 
Figure 1. Representation of resource abstraction and level of control for 
the three main service models [9]. 
 
Figure 1 shows an example of how the level of control 
between the cloud provider and the customer varies between 
service models. 
 
B. What is Autonomic Computing? 
Inspired by the autonomic nervous system where bodily 
functions are unconsciously regulated, autonomic computing 
is a design model that aims to create computer-based systems 
that, through self- and environmental awareness, act to self-
Configure, self-Heal, self-Optimise, and self-Protect (self-
CHOP) [6][10].  
77
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-089-6
IARIA Congress 2023 : The 2023 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications

 
 
An established method for achieving self- and 
environmental awareness in computing systems is by use of 
autonomic managers [11]. An autonomic manager cycles 
through a four-step control loop entailing Monitoring, 
Analysing, Planning, and Executing (MAPE) managed 
elements in a system, while consulting Knowledge (MAPE-
K). Sensors collect information from the autonomic element 
and from its environment, with effectors able to complete 
executable tasks to accomplish system adaptation [12]. 
Figure 2 shows the high-level design of an autonomic 
manager. 
 
Figure 2. Autonomic manager utilising a MAPE-K control loop [11]. 
 
The monitoring stage collects information from the 
managed resource and prepares this data for analysis. 
Information collected may include data, such as performance 
metrics, capacity utilisation, response times, and health status 
of 
other 
managed 
elements 
in 
the 
environment. 
Communication between autonomic managers, including 
reporting of their health status, can facilitate self-healing and 
self-protecting mechanisms [13][14].  
The analysis stage is responsible for determining if self-
adjustment is necessary based on the data presented by the 
monitoring process. Comparison between the current state of 
the system and the ideal state of the system, dictated by 
policy, supports decision making at this stage of the control 
loop. Predictive forecasting techniques can also be utilised to 
determine the likelihood of self-adjustment in the future, 
allowing for pre-emptive change in the system to facilitate 
self-CHOP behaviour. 
The planning stage naturally follows the analysis stage. 
If analysis determines that change is necessary, the plan acts 
on the change request to structure the workflow.  
Execution puts the change workflow into action to 
update the state of the system through effector interfaces with 
managed resources.  
Knowledge extends the standard MAPE control loop, 
allowing data to be shared between each of the four stages 
and between multiple autonomic managers in a system. 
Knowledge in an autonomic system may include information, 
such as decision-making governance policies, symptom 
diagnostics, and solutions.  
II. HISTORY OF THE AREA 
The emergence of cloud computing has provided many 
benefits to users including increased flexibility and 
scalability of resources, reduced time to market for 
applications, and financial savings on infrastructure cost and 
maintenance. However, the growth of this field has increased 
the complexity of computer-based systems making it harder 
for humans to manage, further emphasising the importance of 
autonomic computing to create self-managing systems 
[15][16]. 
 
A. Runtime Management 
Large-scale distributed applications deployed to the 
cloud are adaptive and evolve throughout the lifetime of their 
execution. Early research identified the benefit of non-static 
techniques, which continually assess the demands and 
priorities of systems at runtime. One such proposed 
architecture was the Autonomic Runtime Manager (ARM), 
which used MAPE techniques to self-optimise the system. 
Experiments using wildfire simulation showed that the use of 
dynamic ARM optimisation improved performance by up to 
45% compared with static techniques [17]. 
 
B. Service Level Agreements 
Autonomic computing as a concept showed great 
promise for the management of infrastructure, however some 
outstanding issues meant that application within a cloud 
environment was not a simple task. Notably, existing 
frameworks did not account for virtualisation layers, and 
conflicts could arise between SLA and other targets, such as 
energy efficiency. This led to research proposals, such as 
extending the traditional MAPE-K loop to include an 
Adaption phase to balance virtualisation in the cloud. The 
adaptation phase of the suggested A-MAPE-K loop could 
establish SLA contracts, tailor monitoring processes, or 
handle attribute inconsistencies prior to application 
deployment [18]. The result being that cloud providers and 
consumers could create SLAs on demand, with self-
management of infrastructure considering multiple goals 
simultaneously. Other work included flexible and reliable 
management of SLAs, with improved monitoring to prevent 
SLA violations [19]. 
 
C. Scaling Optimisation 
The ability for cloud consumers to scale up their 
resources when required, and decommission or scale down 
when demand is reduced, has been one the greatest benefits 
of cloud computing. This elastic quality reduces the need for 
vast resource redundancy in preparation for peak demand – 
the infrastructure can simply scale up its capacity during peak 
times. This has the benefit of reducing the running costs for 
cloud providers, with cloud consumers only paying for the 
resources that are needed to maintain QoS. However, the 
processes involved with scaling resources up and down take 
time and have associated costs and therefore research has 
aimed to optimise this autonomic process. One such paper 
utilises machine learning techniques to classify Virtual 
Machines (VM) in a system during the analysis stage of the 
MAPE-K loop [20]. The VMs are labelled with a status of 
“Normal”, “Underutilized”, or “Overutilized” at each layer of 
the system based on their workload.  
78
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-089-6
IARIA Congress 2023 : The 2023 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications

 
 
 
 
      Figure 3 shows how labelling the VMs can inform the 
autoscaling decision process at each layer. Experimental 
results of simulations using this method discovered benefits 
including improved VM utilisation, shorter response times 
for customer requests, and lower operating costs for the cloud 
consumer. 
III. CURRENT STATE OF THE ART 
Work in the field of autonomic cloud solutions is well 
established [43]. Indeed, Cloud Computing was Autonomic 
Computing’s major impact success during its 2nd decade 
[43].  
      Figure 4 shows a proposed taxonomy of the field, based 
on literature review, showing existing solutions categorised 
as either feature or parameter based [21]. The taxonomy is 
further divided into autonomic management, performance 
management, security-aware, and QoS-aware solutions.  
 
A. Autonomic Management 
Service, workload, and resource management are all 
types of autonomic management methodologies actively 
studied in research.   
Service management concerns the ability to effectively 
manage the autonomic processes to abide by SLA and QoS 
agreements between cloud consumers and cloud providers.  
The efficiency of this process has been actively studied, with  
 
 
research revealing innovative solutions to improve on the 
existing methods. One such solution used a game theory 
approach to manage capacity of IaaS services [22]. Using 
simulations and real deployments to Amazon EC2, they 
report efficiency improvements of up to 70% when compared 
with other state of the art solutions. Other research has shown 
how an unsupervised machine learning approach can 
improve the performance of autonomic cloud managers, 
reporting reduction of SLA violations by up to 62% [23].  
Workload management is important for adapting to the 
heterogenous demand throughout the system lifecycle. The 
trade-off between the benefit of auto-scaling and the cost of 
addition resources on the cloud has been an area of interest in 
industry and an active research topic. In the context of cloud 
web applications, one paper proposed an autonomic approach 
to optimise profits through consideration of revenue and costs 
models alongside performance objectives [24]. Although the 
scalability of the cloud is one of its greatest selling points, 
this research highlights the need to assess the business 
requirements to ascertain if the revenue generated by the 
additional resources will justify the costs of those additional 
resources. Their autonomic solution, implemented in a hybrid 
cloud setting, showed considerable profit improvement 
compared with other baseline methodologies. 
      Resource management is concerned with the availability 
and optimisation of resources at system runtime. It is 
Fig. 3. 
Resource scaling based on K-nearest neighbour VM classification in multi-layered systems [20]. 
 
79
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-089-6
IARIA Congress 2023 : The 2023 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications

 
 
important that resources are highly available to meet QoS 
demands, and that they are adequately utilised for greater cost 
benefit to the cloud consumer. An autonomic approach to 
resource provisioning has been presented, which uses 
Bayesian learning techniques and time series prediction 
models for scaling decisions in fog computing environments 
[25].  
 
 
Simulation results of this novel approach shows benefits, 
such as decreased operating costs, decreased delays, and 
higher resource utilisation. Another approach that uses 
Reinforced Learning (RL) combined with autonomic 
computing benefitted from cost reductions of up to 50% 
whilst increasing resource utilisation by up to 12% [26].  
 
B. Security-Awareness 
The increased interest in cloud computing has 
necessitated consideration of how to protect systems 
deployed on such infrastructure. In the spirit of autonomic 
computing, self-protection is a key requirement of any 
system. Predominantly, self-protection of cloud resources 
and cloud data have been of significance in research.  
It is important that sensitive data used in the cloud is 
protected in storage and during transmission to and from the 
cloud. There have been encouraging proposals to improve 
existing systems in this area [27]. Furthermore, existing 
security techniques have been evolving to better protect 
resources on the cloud. One of the latest proposals in this 
area, a system called SECURE [28], has shown promising 
improvements over other techniques, emphasising better QoS 
during security attacks. 
C. QoS-Awareness 
It is obvious that computing systems that can achieve 
higher QoS ratings will deliver greater benefit to 
organisations. The ability for autonomic systems to have 
QoS-awareness [29] is therefore another area of interest in 
research. An example of this research is a proposed 
“Agriculture as a Service” [30] using a QoS-aware autonomic  
 
 
information system. The system gathers information from 
Internet of Things (IoT) devices and, through analysis of QoS 
objectives with the use of fuzzy logic, makes appropriate 
decisions that are autonomically implemented. Simulations 
have shown resource management benefits of the system 
including lower execution costs, lower latency, and shorter 
execution times when compared with existing systems in the 
area. 
 
D. Performance Management 
The amount of computing power necessary to facilitate 
the scale of cloud computing today creates an ethical 
conundrum. The greater demand for processing capacity is 
causing energy consumption of cloud technologies to 
continuously grow. As mentioned, the adoption of cloud 
computing is likely to continue accelerating therefore it has 
become important to investigate other methods of addressing 
energy consumption in the cloud. This is where performance 
management plays a role, aiming to improve performance 
efficiency of cloud systems (getting better performance for 
the same energy usage). A proposed system called DREAM 
[31] tackles the issue of high energy consumption in mobile 
cloud systems. Their system specifically addresses high 
energy consumption related to cloud CPU and network usage 
by smartphones. Through optimisation techniques they were 
Figure 4. Overview showing the taxonomy of existing autonomic cloud solutions based on review of literature [21]. 
 
80
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-089-6
IARIA Congress 2023 : The 2023 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications

 
 
able to show energy reductions of up to 35% compared with 
other methods with similar performance. 
IV. POTENTIAL FUTURE TRENDS 
We have already seen many examples of successful 
implementation 
of 
autonomic 
cloud 
solutions 
and 
improvements. However, some areas will benefit from 
continued research and innovation. 
  
A. Cloud Privacy and Security 
Relinquishing control of system and user data to the 
cloud provider will be a concern for many cloud consumers, 
therefore, work in the field of security-aware solutions will 
continue [32]. It has been speculated that the emergent field 
of “confidential computing” is the future of the cloud [33]. 
Confidential computing gives cloud consumers full control 
over their sensitive workloads. It explicitly details the 
computing components that they must trust, whilst providing 
strong protection from other components, and preventing 
attacks from other cloud users. Although still in its initial 
stages, it is expected that the field will grow rapidly to 
become as popular as some of the most prevalent privacy 
mechanisms of today. 
 
B. IoT Ecosystems 
Although seemingly two independent fields, the IoT and 
cloud computing are closely linked. IoT “generally refers to 
scenarios where network connectivity and computing 
capability extends to objects, sensors and everyday items not 
normally considered computers, allowing these devices to 
generate, exchange and consume data with minimal human 
intervention” [34]. Quite often, it is cloud computing services 
that are facilitating IoT devices, but as the number of 
connected devices increases, cloud technologies are 
struggling to sustain real-time demand [35]. It is expected 
that research will continue to investigate autonomic 
processes to handle the complexity and demands of IoT 
systems [36]-[39]. 
C. Energy Consumption and Sustainability 
As mentioned, the enormous demand for computational 
processing and data storage on the cloud means that energy 
efficiency is a high priority topic. Data centres consume huge 
amounts of energy with high utilisation of resources, large 
operating costs, and substantial carbon footprints. In addition 
to using cleaner energy sources to power data centres, it is 
paramount that progress continues in the field of 
computational energy efficiency. We have already described 
some of the successes in this endeavour, but it is expected 
that research and development into energy-efficient 
computation will continue to improve as energy consumption 
of the cloud grows [40]-[42]. 
V. CONCLUSIONS 
Autonomic computing has been a key facilitator in the 
advancement of cloud computing. With the scale and 
complexity of cloud computing systems growing, autonomic 
computing has helped deal with the difficulty of managing 
these systems. Autonomic computing has shown great 
advantages, including improved dependability of systems, 
through the ability to self-configure, self-heal, self-optimise, 
and self-protect.  
Historically, we have seen the challenges and successes 
of applying autonomic principles to a cloud infrastructure. 
The ability to manage autonomic elements at runtime in a 
heterogenous environment was achieved with innovations on 
the topic of ARM. SLA violations drove advancements in 
autonomic techniques to create a tailored approach for cloud 
applications, for example the proposal of an A-MAPE-K 
control loop within autonomic managers. Furthermore, 
identifying that the process of resource scaling could be 
optimised with respect to time and cost saw the introduction 
of other technologies, such as those used in machine learning, 
to support decision making. 
Evaluation of the current state of the art highlighted new 
innovative solutions alongside considerable improvements to 
existing autonomic techniques in the cloud. Autonomic 
management solutions have been able to drastically reduce 
SLA violation occurrence rates, increase resource utilisation, 
and reduce operational costs of resources resulting in 
increased profit. Development of self-protecting security-
aware solutions has expanded on existing security techniques 
whilst improving the QoS of systems under attack. QoS-
aware systems have shown resource management benefits 
including lower costs, improved latency, and shorter 
execution times. Performance management research is 
extremely important for both cloud providers and cloud 
users, with the aim being to improve energy efficiency of 
computation. Innovation in this field has shown promise with 
proposed solutions achieving considerable energy reductions 
whilst maintaining performance. 
The current state of the art in autonomic cloud 
computing is promising. Further work in the area will likely 
see optimisations with respect to self-CHOP and MAPE 
mechanisms in cloud-based computing systems. As the 
digital age continues, with more and more data generated 
every day, the importance for cloud providers to handle data 
in an efficient and secure manner will increase. It is expected 
that optimisation of cloud security will continue to be an 
active research topic in the future. Additionally, in the interest 
of sustainable ethical practices and Corporate Social 
Responsibility (CSR), cloud providers are becoming 
increasingly pressured to address the scale of their 
operational energy consumption. With the vast energy 
demands of data centres used to provide cloud computing 
services continually growing, it is expected that research into 
energy efficient computation will long continue. 
ACKNOWLEDGEMENT 
This paper was produced as part of COM760 Autonomic 
Computing & Robotics for Ulster University’s MSc. in 
Artificial Intelligence. 
                                             REFERENCES 
[1] P. Modisane and O. Jokonya, “Evaluating the benefits of Cloud 
Computing in Small, Medium and Micro-sized Enterprises 
(SMMEs)”, Procedia Computer Science, vol. 181, pp. 784-792, 2021. 
[2] A. Khayer, M. Talukder, Y. Bao, and M. Hossain, “Cloud computing 
adoption and its impact on SMEs’ performance for cloud supported 
operations: A dual-stage analytical approach”, Technology in Society, 
60, p.101225, 2020. 
[3] A. Adamuthe and G. Thampi, “Technology forecasting: A case study 
of computational technologies”, Technological Forecasting and Social 
Change, 143, pp. 181-189, 2019. 
[4] Flexera, “2023 State of the Cloud Report” [online] Available at: 
https://info.flexera.com/CM-REPORT-State-of-the-
81
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-089-6
IARIA Congress 2023 : The 2023 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications

 
 
Cloud?lead_source=Website%20Visitor&id=Blog, 2023, [Accessed 
Oct. 2023]. 
[5] S. Elliot, “DevOps and the cost of downtime: Fortune 1000 best 
practice metrics quantified”, International Data Corporation (IDC), 
2014. 
[6] R. Sterritt and M. Hinchey, “Why Computer-Based Systems Should Be 
Autonomic”, 12th IEEE International Conference and Workshops on 
the Engineering of Computer-Based Systems (ECBS'05), pp. 406-412, 
2005. doi: 10.1109/ECBS.2005.75. 
[7] V. Arutyunov, “Cloud computing: Its history of development, modern 
state, and future considerations”, Scientific and Technical Information 
Processing, vol. 39 issue 3, pp. 173-178, 2012. 
[8] Y. Duan, G. Fu, N. Zhou, X. Sun, N. Narendra, and B. Hu, “Everything 
as a Service (XaaS) on the Cloud: Origins, Current and Future 
Trends”,  IEEE 8th International Conference on Cloud Computing, pp.  
621-628, 2015. 
[9] J. Surbiryala and C. Rong, “Cloud Computing: History and Overview”, 
IEEE Cloud Summit, pp. 1-7, 2019. 
[10] R. Sterritt, “Towards Autonomic Computing: Effective Event 
Management”, Proceedings of 27th Annual IEEE/NASA Software 
Engineering Workshop (SEW), IEEE Computer Society, pp. 40-47, 
2002. 
[11] IBM, “An Architectural Blueprint for Autonomic computing”, IBM 
White Paper 3rd Ed., 2005. 
[12] R. Kazhamiakin, S. Benbernou, L. Baresi, P. Plebani, M. Uhlig, and O. 
Barais, “Adaptation of Service-Based Systems”, Service Research 
Challenges and Solutions for the Future Internet, pp.117-156, 2010. 
[13] R. Sterritt and D. Bantz, “PAC-MEN: Personal Autonomic Computing 
Monitoring Environment”, Proceedings 15th International Workshop 
on Database and Expert Systems Applications, 2004. 
[14] R. Sterritt and S. Chung, “Personal Autonomic Computing Self-
Healing Tool”, Proceedings of the 11th IEEE International Conference 
and Workshop on the Engineering of Computer-Based Systems, 2004. 
[15] J. Kephart, “Research challenges of autonomic computing”, 
Proceedings of the 27th International Conference on Software 
Engineering, 2005. ICSE 2005. 
[16] R. Sterritt and M. Hinchey, “Autonomicity An Antidote for 
Complexity?”, 
IEEE 
Computational 
Systems 
Bioinformatics 
Conference - Workshops (CSBW'05), 2005. 
[17] J. Yang, H. Chen, S. Hariri, and M. Parashar, “Autonomic runtime 
manager for adaptive distributed applications”, Proceedings 14th IEEE 
International 
Symposium 
on 
High 
Performance 
Distributed 
Computing (HPDC-14), 2005., 69-78, 2005. 
[18] M. Maurer, I. Breskovic, V. Emeakaroha, and I. Brandic, “Revealing 
the MAPE loop for the autonomic management of Cloud 
infrastructures”, IEEE Symposium on Computers and Communications 
(ISCC), 2011. 
[19] V. C. Emeakaroha, R. N. Calheiros, M. A. Netto, I. Brandić, and C. A. 
Rose, “DeSVi: An Architecture for Detecting SLA Violations in Cloud 
Computing 
Infrastructures”, 
Available 
at: 
https://www.semanticscholar.org/paper/DeSVi-%3A-An-
Architecture-for-Detecting-SLA-in-Cloud-Emeakaroha-
Calheiros/d4c8a4c9d6fa921e20e479714e1a14d92b948ad9, 
2010, 
[Accessed Oct. 2023].  
[20] A. Mazidi, M. Golsorkhtabaramiri, and M. Tabari, “Autonomic 
resource provisioning for multilayer cloud applications with K‐nearest 
neighbor resource scaling and priority‐based resource allocation”, 
Software: Practice and Experience, 50(8), pp. 1600-1625, 2020. 
[21] N. Agrawal, “Autonomic cloud computing-based management and 
security solutions: State‐of‐the‐art, challenges, and opportunities”, 
Transactions on Emerging Telecommunications Technologies, 32(12), 
2021. 
[22] D. Ardagna, B. Panicucci, and M. Passacantando, “Generalized Nash 
Equilibria for the Service Provisioning Problem in Cloud Systems”, 
IEEE Transactions on Services Computing, 6(4), pp. 429-442, 2013. 
[23] R. Uriarte, F. Tiezzi, and S. Tsaftaris, “Supporting Autonomic 
Management of Clouds: Service Clustering with Random Forest”, 
IEEE Transactions on Network and Service Management, 13(3), 
pp.595-607, 2016. 
[24] N. Beigi-Mohammadi, M. Shtern, and M. Litoiu, “Adaptive Load 
Management 
of 
Web 
Applications 
on 
Software 
Defined 
Infrastructure”, IEEE Transactions on Network and Service 
Management, 17(1), pp. 488-502, 2020. 
[25] M. Etemadi, M. Ghobaei-Arani, and A. Shahidinejad, “Resource 
provisioning for IoT services in the fog computing environment: An 
autonomic approach”, Computer Communications, 161, pp. 109-131, 
2020. 
[26] M. Ghobaei-Arani, S. Jabbehdari, and M. Pourmina, “An autonomic 
resource provisioning approach for service-based cloud applications: 
A hybrid approach”, Future Generation Computer Systems, 78, pp. 
191-210, 2018. 
[27] A. Sarhan and S. Carr, “A Highly-Secure Self-Protection Data Scheme 
in Clouds Using Active Data Bundles and Agent-Based Secure Multi-
party Computation”, IEEE 4th International Conference on Cyber 
Security and Cloud Computing (CSCloud), pp. 228-236, 2017. 
[28] S. Gill and R. Buyya, “SECURE: Self-Protection Approach in Cloud 
Resource Management”, IEEE Cloud Computing, 5(1), pp. 60-72, 
2018. 
[29] S. Singh, I. Chana, and M. Singh, “The Journey of QoS-Aware 
Autonomic Cloud Computing”, IT Professional, 19(2), pp. 42-49, 
2017. 
[30] S. Singh, I Chana, and R. Buyya, “Agri-Info: Cloud Based Autonomic 
System for Delivering Agriculture as a Service”, Internet of Things, 9, 
100131, 2020. 
[31] J. Kwak, Y. Kim, J. Lee, and S. Chong, “DREAM: Dynamic Resource 
and Task Allocation for Energy Minimization in Mobile Cloud 
Systems”, IEEE Journal on Selected Areas in Communications, 
33(12), pp. 2510-2523, 2015. 
[32] S. Gill and A. Shaghaghi, “Security-Aware Autonomic Allocation of 
Cloud Resources”, Journal of Organizational and End User 
Computing, 32(3), pp. 15-22, 2020. 
[33] M. Russinovich et al., “Toward confidential cloud computing”, 
Communications of the ACM, 64(6), pp. 54-61, 2021. 
[34] K. Rose, S. Eldridge, and L. Chapin, “The internet of things: An 
overview”, The Internet Society (ISOC), pp. 1–50. 
[35] S. Gill, S. Tuli, M. Xu, I. Singh, K. Singh, D. Lindsay, S. Tuli, D. 
Smirnova, M. Singh, U. Jain, H. Pervaiz, B. Sehgal, S. Kaila, S. Misra, 
M. Aslanpour, H. Mehta, V. Stankovski, and P. Garraghan, 
“Transformative effects of IoT, Blockchain and Artificial Intelligence 
on cloud computing: Evolution, vision, trends and open challenges”, 
Internet of Things, 8, 100118, 2019. 
[36] A. Zyane, M. Bahiri, and A. Ghammaz, “IoTScal-H: Hybrid 
monitoring solution based on cloud computing for autonomic 
middleware-level scalability management within IoT systems and 
different SLA traffic requirements”, International Journal of 
Communication Systems, 33(14), 2020. 
[37] A. Lam, O. Haugen, and J. Delsing, “Dynamical Orchestration and 
Configuration Services in Industrial IoT Systems: An Autonomic 
Approach”, IEEE Open Journal of the Industrial Electronics Society, 
3, pp. 128-145, 2022. 
[38] S. Rahman and G. Jackson, “Autonomic Methods for Mitigating 
Threats to the Internet of Things (IoT)”, International Conference on 
Computational Science and Computational Intelligence (CSCI), pp. 
1302-1307, doi: 10.1109/CSCI.2017.227, 2017. 
[39] E. Mezghani, S. Berlemont, and M. Douet, “Autonomic Coordination 
of IoT Device Management Platforms”, IEEE 29th International 
Conference 
on 
Enabling 
Technologies: 
Infrastructure 
for 
Collaborative Enterprises (WETICE), 2020. 
[40] T. Tekreeti, T. Cao, X. Peng, T. Bhattacharya, J. Mao, X. Qin, and W. 
Ku, “Towards Energy-Efficient and Real-Time Cloud Computing”, 
IEEE International Conference on Networking, Architecture and 
Storage (NAS), 2021. 
[41] S. Simaiya, V. Gautam, U. Lilhore, A. Garg, P. Ghosh, N. Trivedi, and 
A. Anand, “EEPSA: Energy Efficiency Priority Scheduling Algorithm 
for Cloud Computing”, 2nd International Conference on Smart 
Electronics and Communication (ICOSEC), 2021. 
[42] M. Xu, A. Toosi, and R. Buyya, “A Self-Adaptive Approach for 
Managing Applications and Harnessing Renewable Energy for 
Sustainable Cloud Computing”, IEEE Transactions on Sustainable 
Computing, 6(4), pp. 544-558, 2021. 
[43] T. Lorimer and R. Sterritt, "Autonomic Management of Cloud 
Neighborhoods through Pulse Monitoring," 2012 IEEE Fifth 
International Conference on Utility and Cloud Computing, Chicago, 
IL, USA, 2012, pp. 295-302, doi: 10.1109/UCC.2012.60 
[44] R. Sterritt, "Keynote: 20 Years of Autonomic Computing," in 
International Conference on Autonomic and Autonomous Systems 
(ICAS), Online (Covid-19), 2021.
 
82
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-089-6
IARIA Congress 2023 : The 2023 IARIA Annual Congress on Frontiers in Science, Technology, Services, and Applications

