 
 
Online Sliding Window Based Self-Organising Fuzzy Neural Network for Cognitive 
Reasoning 
 
Gang Leng, Anjan Kumar Ray, T. M. McGinnity, Sonya Coleman, Liam Maguire 
Intelligent Systems Research Centre (ISRC), Faculty of Computing and Engineering 
 University of Ulster, Magee Campus, Londonderry, U.K. 
e-mail: {g.leng, ak.ray, tm.mcginnity, sa.coleman, lp.maguire}@ulster.ac.uk 
 
 
Abstract —We propose an online sliding window based self-
organising fuzzy neural network (SOFNN) as the core 
component of a cognitive reasoning system for a smart home 
environment. The network has the ability to configure its 
neuronal structure through adding and pruning of neurons 
while exploring the relationships between the inputs and the 
desired reasoning outputs, thus enabling continuous learning 
and reasoning to provide meaningful cognitive understanding 
of the environment. Initially, the network is trained with 
environmentally realistic synthesised data thus demonstrating 
its adaptation capabilities. The network is then validated using 
unseen data. In the simulation, we have studied the network 
structures and responses for three different scenarios with and 
without online sliding window based approaches and the 
results obtained show the effectiveness of the proposed method. 
Keywords- self-organise; fuzzy logic; neural network; 
reasoning module  
I. 
 INTRODUCTION 
Smart home environments are emerging rapidly as sensor 
rich systems. These systems require substantial computation 
to extract high level knowledge and understanding from low 
level sensory information, so as to enable appropriate 
decisions to be made regarding the state of the environment,  
i.e., the ecology. The main objectives of introducing 
intelligence into a smart home environment are to identify 
events with various degrees of importance and automatically 
activate suitable responses [1]. The intelligence comes from 
the adaptive behaviour of the overall ecology as per the 
requirements of the user.  Different aspects of smart home 
environments have been reported in the literature [2][11]. 
These include an intelligent just-in-time Activity of Daily 
Living (ADL) assistance provision within an integrated 
system architecture [3], a home monitoring system for 
elderly-care application [2],   and a context aware system for 
smart home applications [9][11][19]. Researchers have used 
different 
methods 
for 
contextual 
representations.  
Mastrogiovanni et al., [5] have integrated ontology and logic 
based approaches to map numerical data to symbolic 
representations. Roy et al. [6] have used possibility theory 
and description logic (DL) as the semantic model of the 
agent’s behaviour for activity recognition.  
Detection of anomalous events within a smart home is an 
important aspect of situation awareness. Jakkula [4] has used 
One Class Support Vector Machines (OCSVM) techniques 
to address this issue. In [15], we have shown that the 
SOFNN based cognitive reasoning module can be utilised to 
extract knowledge from everyday events occurring within a 
smart home environment. The SOFNN has a self-organising 
capability to configure its structure and identify parameters 
of the fuzzy neural network from data. We explored the 
potential of the SOFNN as a core component of a cognitive 
system unfolding the relations of its inputs and the desired 
reasoning outputs and showed its ability to adapt its neuronal 
structure through adding and pruning of neurons. In this 
work, we show that the proposed sliding window based 
online SOFNN can achieve similar knowledge via a simpler 
structure with a reduced number of neurons.  
The remainder of this paper is organised as follows: 
Section II presents an overview of the SOFNN. A sliding 
window based online SOFNN is described in Section III. 
Section IV presents the implementation results of the 
proposed work in a smart home environment.  We consider 
three cases: case 1 represents purely offline training and 
testing; case 2 represents offline initial training and then 
online training and testing simultaneously during the 
verification stage with sliding window control; case 3 
represents fully online situation utilising the proposed 
method. Section V presents the overall conclusion of this 
work.  
II. 
AN OVERVIEW OF THE SOFNN  
The self-organising fuzzy neural network (SOFNN) [14], 
implementing Takagi-Sugeno (TS) fuzzy models [16] 
online, is a five-layer fuzzy neural network with the ability  
 
Figure 1. Structure of self-organising fuzzy neural networks 
114
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

 
 
to self-organise its own structure during the learning 
process. The structure of SOFNN is shown in Fig. 1. 
Consider the t-th observation (
Xt dt )
. We define 
[
rt ]
t
t
t
x
x x
X
L
2
1
=
 as the input vector, r is the number of 
inputs, 
td  is the desired output (target) at time t and 
ty  is 
the actual output of the current network at time t. Then, the 
output in layer 5 is obtained as 
 
2
2
2
1
1
2
2
1
1
(
)
exp
2
( )
.
(
)
exp
2
u
r
i
ij
j
j
i
ij
u
r
i
ik
k
i
ik
x
c
w
y
x
c
σ
σ
=
=
=
=


−
−

∑
∑




=


−
−
∑
 ∑





x
                              (1) 
 
Here, u  is the number of neurons, 
ijc is the centre of the i-th 
membership function in the j-th neuron, 
ij
σ  is the width of 
the i-th membership function in the j-th neuron; j and k are 
variables of the number of neurons and i is the variable of 
the number of membership functions in each neuron. The 
row vector 
0
1
2
[
]
j
j
j
jr
a
a
a
a
Aj =
LL
 represents the set of 
parameters corresponding to the neuron j and 
w2 j
 is the 
weighted bias, which is defined for the TS model as 
 
2
1
2
0
1 1
[1
]
1,2,
, .
T
j
r
j
j
jr r
w
x x
x
a
a x
a x
j
u
=
×
=
+
+
+
=
Aj
LL
L
L
     (2) 
     
For learning purposes, the output of the network can be 
described in matrix form as 
 
Ψ
=
W2
Y
 
(3) 
[
ny ]
y y
Y
2 L
1
=
 
(4) 



= 
aur
au
au
a r
a
a
W
L
L
L
1
0
1
11
10
2
 
 
(5) 
 






























=
Ψ
un xrn
xr
u
un x n
x
u
un
u
n xrn
xr
n x n
x
n
ψ
ψ
ψ
ψ
ψ
ψ
ψ
ψ
ψ
ψ
ψ
ψ
L
M
M
M
L
L
M
M
M
L
M
M
M
L
L
1
1
1
11
1
1
1
1
11
1
1
11
11
1
11
                                   (6) 
 
where W2 is the parameter matrix, 
ψ jt
 is the output of the j-
th neuron in the normalised layer when the t-th training 
pattern enters the network. 
The learning process of the SOFNN can be divided into 
structure learning and parameter learning. The structure 
learning combines adding new EBF (ellipsoidal basis 
function) neurons and pruning unimportant EBF neurons 
[14]-[15]. The parameter learning is based on the linear least 
squares method and the recursive least squares algorithm 
[17]. The recursive parameter matrix learning algorithm 
developed in [14] is as follows 
 
[
]
( ) 1
)1
( ) (
( )1
)1
(
( ) ( )
( )
−
−
+
−
=
=
p t
t Q t
p
p t
Q t
Q t p t
L t
T
 
(7) 
 
[
]
)1
(
( )
( )
( )
−
−
=
t Q t
L t p
I
Q t
T
α
 
 
(8) 
1)]
(
( )
( )[
)1
(
( )
−
∧
Θ
−
+
−
∧
Θ
=
∧
Θ
t
pT t
L t dt
t
t
α
 
(9) 



<
≥
=
( )
( )
,
0
( )
( )
,1
t
t
e
t
t
e
ε
ε
α
 
(10) 
 
where 
1
PT (t)P(t)
Q(t)
−



= 
 is an MxM Hermitian matrix 
(Q-matrix),
T
pT(t)
pT (1) pT (2)
ΨT
P(t)



= 
=
L
, 
× ( + )1
=
r
u
M
,
[
]T
θM
θ1 θ2
T
Θ(t) W 2
L
=
=
,  
)1
(
( )
( )
−
∧
Θ
−
=
t
pT t
dt
e t
 is the estimation error and 
( )
( )
( )
t
t
p
d
y
d
t
T
t
t
t
∧
Θ
−
=
−
=
ε
 is the approximation error. 
More details can be found in [14]. 
III. 
THE PROPOSED ONLINE APPROACH OF SOFNN  
The dynamic structure of a SOFNN enables the 
cognitive system to learn different situations online via self-
adaptation. To facilitate online training a sliding-window 
(SW) [12][13], as a data pool, has been employed. In this 
case the Q-matrix has to be updated based on limited 
historical data and current data.  
The proposed online approach implements a first-in-
first-out sliding window (FIFO-SW) (Fig. 2) with the 
SOFNN. When new data are obtained the oldest data will be 
discarded and the new data will be added to this window. 
The data in the sliding window include the current input-
target learning pair as in (11) and limited historical input-
target learning pairs as shown in (12) where W is the width 
of the sliding window. 
 
[
t ]T
t
t
d
Data
= Χ
                                    (11) 
1
2
[
...
].
SW
t W
t W
t
Data
Data
Data
Data
−
+
−
+
=
                   (12) 
 
Fig. 3 is the block diagram of the proposed online SOFNN. 
The structure of the SOFNN is self-organised during the 
115
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

 
 
W=width of SW 
t-W+1 
t 
Time 
Moving direction 
 
Figure 2. First-in-first-out sliding window 
 
Figure 3. Block diagram of the online SOFNN 
 
 
 
Figure 4. Outline of cognitive reasoning system 
 
learning process.  A new SOFNN structure is generated if 
EBF neurons have been added or pruned in the existing 
SOFNN structure.  In the proposed recursive parameter 
matrix learning algorithm, the size of the Hermitian matrix 
(Q-matrix) depends on the number of neurons as 
1
PT (t)P(t)
Q(t)
−



= 
 and
P(t) = ΨT
. If the number of 
neurons in the SOFNN structure is changed, the data 
organized in the sliding window will be used to update the 
parameter 
( )t
∧
Θ
 and Q-matrix 
Q(t)
 through equations (13) 
and (14) as follows 
 
[
]
( )D(t)
( ) ( )
( )
1
t
P
t P t
P
t
T
T
−
∧
=
Θ
                                    (13) 
   
1
PT (1)P(1)
Q(1)
−



= 
                                          (14) 
 
where
[
t ]T
t W
t W
d
d
d
D t
2 L
1
( )
+
−
− +
=
. 
The 
proposed 
recursive parameter matrix learning algorithm is then 
applied to update the parameters during subsequent 
learning. It is clear that if the width of the sliding window is 
the same as the number of entire training data, then this can 
be considered as offline training. 
IV. 
RESULTS  
In order to evaluate the proposed approach we consider a 
smart home environment with different sensors and 
actuators as in the EU FP7 RUBICON project (contract no. 
269914) [7]. There are four technical layers named learning, 
control, communication and cognitive layers, which explore 
and support the smart home environment. The learning layer 
addresses sensory information for event classification, the 
control layer employs robots for different goals within the 
ecology whereas the communication layer is responsible for 
data transmission among the layers. The cognitive layer 
seeks to acquire knowledge and understanding of the state 
of the ecology as per the event information, while accurately 
reflecting its dynamics. The proposed online algorithm is 
employed in the reasoning module of the cognitive layer as 
shown in Fig. 4. To demonstrate the cognitive capability, it 
is necessary to handle multiple events that may occur in the 
ecology, and in particular extract higher-level intelligence. 
We have anticipated 19 events as inputs from a home 
environment reflecting activities of a user and the states of 
the environment and a set of 10 reasoning goals as outputs 
are chosen to reflect the network’s capabilities of reasoning 
across user activities and current state of the ecology. Table 
I and II show the chosen inputs and outputs [15]. Values of 
inputs and outputs represent confidence levels between 0 
and 1. We synthesize 4500 data samples including data for 
19 inputs and 10 reasoning outputs. To validate the 
performance of the proposed online algorithm, three cases 
have been designed. 
A. Case 1: Offline Training and Learning 
The first 3900 data are chosen as the training data and 
the last 600 data are used as the testing data. We use the 
training data to obtain the SOFNN structure. We then test 
the performance using the testing data based on the obtained 
SOFNN structure during which the structure is not refined. 
This is an offline training process without sliding window 
control. 
B. Case 2: Pseudo Online Training and Learning  
In case 2, the first 3900 data are used as the first group 
of training data. The remaining 600 data are used as the 
testing data, as well as the second group of training data. 
The first phase is offline training without sliding window 
control. In the testing process using the second group of 
data, the obtained structure is also updated based on the 
FIFO sliding window with the size of 300 samples. In this 
phase, the refining process is based on the proposed online 
training algorithm as equations (7) to (14). The testing data 
are used to validate the performance of the obtained SOFNN 
structure. This case is a combination of offline and online 
training process (pseudo online). This process also shows 
that the approach can continue its training and learning from 
a previously offline trained network.  
 
 
116
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

 
 
TABLE I. THE EVENT INPUTS FOR REASONING MODULE 
Synthesized Input 
Events 
1 
User in room 1 
2 
User in room 2 
3 
User in room 3 
4 
Visitor detection 
5 
Phone event 
6 
Doorbell event 
7 
Dripping event 
8 
Music event 
9 
Fire alarm 
10 
Microwave usage 
11 
Dishwasher usage 
12 
TV usage 
13 
Cleaning operation 
14 
Cooking 
15 
Use of oven 
16 
Smoke detection 
17 
Room temperature  
18 
Burglary alarm 
19 
Front door usage 
 
TABLE II. TARGETED OUTPUT OF SOFNN REASONING 
ID 
Potential reasoning outputs 
1 
User exercise 
2 
User relaxing 
3 
User in kitchen 
4 
Bring phone 
5 
Open door  
6 
Cooking activity 
7 
Fire alert situation 
8 
Burglary alert situation 
9 
Dripping alert situation 
10 
Cleaning situation 
 
C. Case 3: Fully Online 
In case 3, all 4500 data are used as the training data. The 
rear 600 data are the testing data used to validate the 
performance of the obtained SOFNN structure. For this 
case, we use the training data to train the SOFNN structure, 
based on the FIFO sliding window with the size of 300 
samples from the beginning of the training. No offline 
training occurs in this case. To compare with case 1 and 
case 2, the testing data are used to validate the performance 
of the obtained SOFNN structure. In this testing process, the 
obtained structure is also continuing its refinement. So, the 
structure and parameters are also changing based on the 
proposed online algorithm. 
During the training process in all cases, event inputs and 
reasoning outputs form the training data as presented in 
(11). However, during the testing phase, only event data are 
presented to the network and the reasoning outputs are 
obtained from the trained network. The results achieved for 
each of the three cases are presented in Tables III, IV and V. 
It is observed in Table III that case 1 through to case 3 have 
42, 42 and 28 neurons respectively to reason across the 
reasoning outputs for the smart home environment.  The 
root mean square errors (RMSE) of the training are 
presented in Table IV for the first set of 3900 data. As case 
2 incorporates offline training with the first set of data, the 
RMSEs are same as case 1. RMSEs of testing of case 2 are 
better than those of case 1 (Table V) as the obtained 
structure for case 2 has been refined during the testing 
process. For a number of the reasoning outputs, the RMSEs 
of the training and testing of cases 1 and 2 are smaller than 
the corresponding values in case 3. This is because of the 
sliding window with limited data has been applied in case 3 
from the beginning of the training process as opposed to 
offline training without sliding window in other cases. 
However, the reduced number of neurons in case 3 than 
those in case 1 and case 2 highlights the potential for the 
proposed online sliding window based approach. Fig. 5 
shows the change in neuronal structure for each of these 
cases. It is observed that case 3 has 28 neurons compared to 
42 neurons for cases 1 and 2 respectively. Hence in 
comparison with the offline approach in case 1 and the 
pseudo online approach in case 2, the fully online approach 
in case 3 with FIFO sliding window has the capability to 
generate 
a 
simple 
structure 
and 
achieve 
similar 
performances. 
Fig. 6 presents an example of the online case 3 with the 
output “User Exercise”. Fig. 6-(a) shows the training 
process where the network has identified the transitions 
when the user starts and ends exercising. In this case, the 
plot shows only data samples from 3301 to 3900 for clarity. 
It shows the desired state and the training output of the user 
exercise situation. It is observed that the network is able to 
learn this situation. For this output, there are two neurons 
generated during the training process, which are shown in 
Fig. 7. It also shows that the number of neurons in the 
network is changed dynamically during the training process 
illustrating the self-organising capability of the proposed 
network. The final 600 data, from 3901 to 4500, have been 
used in the testing process. The testing results are given in 
Fig. 6-(b). It is observed that the network is capable of 
identifying the user exercise situation as desired. 
Fig. 8 presents an example of the online case 3 for the 
open door situation. Fig. 8-(a) shows the desired and actual 
outputs during the training process where the network has 
identified the requirements to open the door of the home. In  
TABLE III. NUMBERS OF NEURONS FOR 3 CASES 
Outputs 
Case 1 
Case 2 
Case 3 
User Exercise 
3 
3 
2 
User Relaxing 
9 
9 
4 
User in Kitchen 
2 
2 
2 
Bring Phone 
2 
2 
2 
Open Door 
2 
2 
2 
Cooking Activity 
2 
2 
2 
Fire Alert Situation 
2 
2 
2 
Burglary Alert Situation 
3 
3 
3 
Dripping Alert Situation 
14 
14 
6 
Cleaning Situation 
3 
3 
3 
Total Number 
42 
42 
28 
 
117
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

 
 
TABLE IV. RMSES OF THE TRAINING FOR 3 CASES 
Outputs 
Case 1 
Case 2 
Case 3 
User Exercise 
0.0566    0.0566    0.0566 
User Relaxing 
0.0463    0.0463    0.0478 
User in Kitchen 
0.0562    0.0562    0.0551 
Bring Phone 
0.0641    0.0641    0.0596 
Open Door 
0.0540    0.0540    0.0507 
Cooking Activity 
0.0629    0.0629    0.0617 
Fire Alert Situation 
0.0393    0.0393    0.0311 
Burglary Alert Situation 
0.0395    0.0395    0.0463 
Dripping Alert Situation 
0.0359    0.0359    0.0378 
Cleaning Situation 
0.0385 
0.0385 
0.0481 
 
TABLE V. RMSES OF THE TESTING FOR 3 CASES 
Outputs 
Case 1 
Case 2 
Case 3 
User Exercise 
0.0580    0.0577    0.0631    
User Relaxing 
0.0492    0.0490    0.0558    
User in Kitchen 
0.0558    0.0557    0.0555    
Bring Phone 
0.0652    0.0650    0.0683    
Open Door 
0.0498    0.0496    0.0533    
Cooking Activity 
0.0658    0.0650    0.0705    
Fire Alert Situation 
0.0401    0.0397    0.0432    
Burglary Alert Situation 
0.0189    0.0184    0.0187    
Dripping Alert Situation 
0.0484    0.0481    0.0832    
Cleaning Situation 
0.0443 
0.0526 
0.0532 
 
    
0
500
1000
1500
2000
2500
3000
3500
4000
4500
10
15
20
25
30
35
40
45
Time Step t
Number of neurons
 
 
Case 1
Case 2
Case 3
 
Figure 5. Change of neuronal structure for case 1 through to 3 
 
this case, the plot shows only data samples from 3301 to 
3900 for clarity. For this output, there are two neurons 
generated during the training process, which are shown in 
Fig. 9. It also shows that the number of neurons in the 
network is changing dynamically during the training 
process. The final 600 data, from 3901 to 4500, have been 
used in the testing process. The testing results are given in 
Fig. 8-(b). It is observed that the network is capable of 
identifying the situation as desired. 
    The Mackey-Glass time-series with a 6-step-ahead 
prediction model [18] is simulated to show the advantage of 
the proposed online algorithm in machine learning. This is a 
benchmark example of a chaotic system. We have chosen 
the parameters as in [18] for consistency with earlier work.  
 
 
Figure 6. Results of case 3 for user exercise situation 
500
1000
1500
2000
2500
3000
3500
4000
4500
0
1
2
3
4
Time Step t
Number of neurons
 
Figure 7. Growth of neurons for user exercise in case 3 
 
 
Figure 8. Results of case 3 for open door situation 
 
 
Figure 9. Growth of neurons for open door situation in case 3 
     
118
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

 
 
TABLE VI. RESULTS OF MACKEY-GLASS TIME-SERIES 
PREDICTION 
Approach 
Number 
of 
neurons 
RMSE 
of 
training 
RMSE 
of 
testing 
WNN [18] 
4 
- 
0.0153 
Case 1 (no SW) 
4 
0.0114 
0.0116 
Case 2 (SW 100 during testing) 
4 
0.0113 
0.0151 
Case 2 (SW 200 during  testing) 
4 
0.0114 
0.0148 
Case 2 (SW 300 during testing ) 
4 
0.0113 
0.0123 
Case 3 (SW 100) 
4 
0.0141 
0.0151 
Case 3 (SW 200) 
4 
0.0142 
0.0148 
Case 3 (SW 300) 
4 
0.0142 
0.0123 
 
The results of this simulation are shown in Table VI. We 
compare our results with the wavelet based neural network 
(WNN) in [18] which also tabulated further comparative 
results with other existing methods. It is observed from the 
RMSE values that our approach produces better results for 
all three cases presented when compared with the WNN. 
V. 
CONCLUSIONS  
This paper presents an online self-organising fuzzy neural 
network based on the sliding window. The proposed online 
algorithm has been applied to a smart home situation. The 
method is also compared with two other designed cases 
(cases 1 and 2) to show its advantage. A more compact 
structure and similar performance are obtained using this 
proposed online algorithm (case 3). Furthermore, we also 
show through case 2 that the proposed algorithm can be 
combined with a previously learnt system for continuous 
learning with new available data. From these results, we can 
conclude that the proposed method is suitable for online 
cognitive reasoning. We also consider a benchmark chaotic 
system prediction using our proposed method and present 
comparative results with an existing wavelet neural network 
based approach. The results show that the proposed sliding 
window based online approach is suitable for machine 
learning.  
ACKNOWLEDGMENT 
The authors would like to acknowledge support of the 
European Commission. This work is partially supported by 
the EU FP7 RUBICON project (contract no. 269914) – 
www.fp7rubicon.eu.  
 
REFERENCES 
[1] D. Bregman, “Smart home intelligence - the ehome that 
learns,” International Journal of Smart Home, vol. 4, no. 4, 
Oct. 2010, pp. 35-46.  
[2] A. Gaddam, S. C. Mukhopadhyay, and G. S. Gupta,  “Elder 
care based on cognitive sensor network,” IEEE Sensors 
Journal, vol. 11, no. 3, Mar. 2011, pp. 574-581. 
[3] L. Chen and C. Nugent, “Situation aware cognitive assistance 
in smart homes,” Journal of Mobile Multimedia, vol. 6, no. 3, 
2010, pp. 263-280. 
[4] V. Jakkula and D. J. Cook, “Detecting anomalous sensor 
events in smart home data for enhancing the living 
experience,” AAAI Workshop, 2011, pp. 33-37. 
[5] F. Mastrogiovanni, A. Sgorbissa, and R. A. Zaccaria, 
“Cognitive model for recognizing human behaviours in smart 
homes,” Ann. Telecommunication, vol. 65, Apr. 2010, pp. 
523-538. 
[6] P. C. Roy et al., “Possibilistic behavior recognition in smart 
homes for cognitive assistance,” Twenty-fourth AAAI 
Workshop, Jul., 2010, pp. 53-60. 
[7] RUBICON project. EU FP7 project. FP7 challenge 2, 
cognitive 
systems 
and 
robotics. 
2011, 
Available: 
http://www.fp7rubicon.eu [retrieved: Mar. 2013]. 
[8] J. Y. Son, J. H. Park, K. D. Moon, and Y. H. Lee, “Resource-
aware smart home management system by constructing 
resource relation graph,” IEEE Transactions on Consumer 
Electronics, vol. 57,  no. 3, Aug. 2011, pp. 1112-1119. 
[9] W. Y. Wang, C. C. Chuang, Y. S. Lai, and Y. H. A. Wang, 
“Context-aware system for smart home applications,” EUC 
Workshops, LNCS 3823,  2005, pp. 298 – 305.  
[10] Aware Home. Aware Home, Georgia Institute of Technology, 
http://awarehome.imtc.gatech.edu/, [retrieved: Mar. 2013]. 
[11] H. Storf, T. Kleinberger, M. Becker, M. Schmitt, F. 
Bomarius, and S. Prueckner, “An event-driven approach to 
activity recognition in ambient assisted living,”  Ambient 
Intelligence, LNCS vol. 5859, 2009, pp. 123-132.  
[12] P. M. Ferreira and A. E. Ruano, “Online sliding-window 
methods for process model adaptation,” IEEE Transactions on 
Instrumentation and Measurement, vol. 58, no. 9, Sept. 2009, 
pp. 3012-3020. 
[13] H. Izzeldin, V. S. Asirvadam, and N. Saad, “Online sliding-
window based for training MLP networks using advanced 
conjugate gradient,” IEEE 7th International Colloquium on 
Signal Processing and Its Applications, Mar. 2011, pp. 112-
116. 
[14] G. Leng, T. M. McGinnity, and G. Prasad, “An approach for 
on-line extraction of fuzzy rules using a self-organising fuzzy 
neural network,” Fuzzy Sets and Systems, vol. 150, no. 2, 
Mar. 2005, pp. 211-243. 
[15] A. K. Ray, G. Leng, T. M. McGinnity, S. A. Coleman, and L. 
P. Maguire, “Development of cognitive capabilities for smart 
home using a self-organizing fuzzy neural network,” 10th 
IFAC Symposium on Robot Control, Dubrovnik, Croatia, 
Sept. 2012, pp. 447-454. 
[16] T. Takagi and M. Sugeno, “Fuzzy identification of systems 
and its applications to modeling and control,” IEEE 
Transactions on Systems, Man, and Cybernetics, vol. 15, no. 
1, 1985, pp. 116-132.  
[17] K. J. Astrom and B. Wittenmark, Adaptive control, 2nd ed., 
Addison-Wesley, 1995. 
[18] M. Awad, “Chaotic time series prediction using wavelet 
neural network,” Journal of Artificial Intelligence: Theory and 
Application, vol.1, no. 3, 2010, pp. 73-80. 
[19]  H. Zheng, H. Wang, and N. Black, “Human activity detection 
in smart home environment with self-adaptive neural 
networks,” IEEE ICNSC, Apr. 2008, pp. 1505–1510. 
 
 
119
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

