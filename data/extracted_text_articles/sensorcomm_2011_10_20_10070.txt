Rate Adaptation for Slepian-Wolf Coding in Presence of Uncertain Side Information
Reza Parseh and Farshad Lahouti
Wireless Multimedia Communications Laboratory
School of Electrical and Computer Engineering
College of Engineering, University of Tehran
{rparseh,lahouti}@ut.ac.ir, URL: http://wmc.ut.ac.ir
Abstract—In this paper, a rate adaptation framework is
proposed to address the problem of Slepian-Wolf coding with
uncertain side information at the encoder. The uncertainty
arises due to the time-varying nature of the correlation be-
tween source and side information in settings such as wireless
sensor networks and distributed video coding. The proposed
framework is set up based on a multi-mode Slepian-Wolf coding
scheme which is designed to minimize the average rate. The
presented solution utilizes the feedback channel judiciously
to select the best encoder mode and substantially reduces
the delay and decoding complexity compared to the previous
methods which rely on frequent retransmissions for successful
decoding. The designs based on both practical and ideal
Slepian-Wolf codes are considered, where the latter serves as
the corresponding theoretical performance bound. Simulation
results based on LDPC codes show that by using sufﬁcient
number of modes, a desirably small average rate gap from the
theoretical bound with no uncertainty can be achieved.
Keywords-Slepian-Wolf coding; rate adaptation; uncertain side
information; rate-limited feedback channel.
I. INTRODUCTION
Distributed Source Coding (DSC) and especially Slepian-
Wolf (SW) coding has been the subject of substantial
research interest recently. This is mainly due to its appli-
cations in data compression for wireless sensor networks
and distributed video coding.
The SW coding theorem as introduced in [1], states that
the ultimate lossless compression rate for a source with a
given correlated Side Information (SI) only available to the
decoder, is the same as that when SI is also available to the
encoder. Practical coding schemes appeared later and may
be categorized as parity-based and syndrome-based coding
approaches [2][3]. These schemes are constructed based on
capacity approaching codes such as LDPC and Turbo codes
[4][5]. As indicated in [1], the joint Probability Distribution
Function (PDF) of source and SI must be available to the
encoder for compression based on SW coding.
In many practical scenarios, the joint PDF of source
and SI may not be available perfectly to the encoder. For
instance, in distributed video coding [6] for wireless video
sensor networks, correlation model cannot be estimated
at the encoder due to its associated computational cost
for the encoder, usually being a mobile device. Also, in
wireless sensor networks for environmental monitoring, the
correlation varies in time as a result of natural phenomena.
Simple feedback schemes are suggested to overcome this
uncertainty problem in the joint PDF of source and SI. For
instance, for distributed video coding based on Turbo or
LDPC codes, decoding failure is ﬁrst detected. Next, with
requested additional syndrome or parity bits via a feedback
channel, subsequent decodings are performed until a proba-
bility of error constraint is satisﬁed [6]. The aforementioned
procedure has two major drawbacks; (1) the delay due to
the number retransmissions and (2) the computational cost
of multiple decodings each time more syndrome or parity
bits are fed to the decoder. Different approaches have been
proposed to tackle the inefﬁcient use of feedback usually re-
sulting in increasing encoder complexity. Recently in [7], the
relay nodes in a wireless video sensor network are utilized
to reduce the said retransmission delay by incorporating
network coding. However, the delay is still non-negligible.
For ﬂexible rate SW compression, [8] and [9] provide
methods to construct multi-rate LDPC and serial and parallel
concatenated convolutional codes from a parent code to
efﬁciently handle possibly varying correlation of source and
SI. However, these works are focused on code design and
either do not present a code selection mechanism or rely on
simple ACK/NACK feedback schemes discussed before.
The rate-distortion performance bounds for Gaussian
Wyner-Ziv (WZ) coding (lossy DSC) with uncertain SI at
the encoder is studied in [10]. In [11], for the case when the
SI quality has two different states, unknown to both encoder
and decoder, a two-layer WZ coding scheme using transform
coding and ideal SW coding is presented.
In this work, we propose a framework to address the
problem of SW coding with uncertain SI at the encoder.
The framework consists of a multi-mode encoder working
with a carefully designed feedback from the decoder. The
proposed scheme utilizes the feedback channel effectively
and consequently performs a one-time-only decoding for
each data frame to substantially reduce decoding delay and
computational cost of multiple decodings. It is assumed that
the joint PDF of source and SI is ﬁxed over each source
frame but varies from frame to frame. In line with [10], we
assume that this PDF is controlled by a single parameter σ,
which is known to the decoder. We partition the range of σ
and assign each interval to a unique mode of the encoder. For
each frame, the decoder sends the mode index to the encoder
249
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

Xn
SWenc
SWdec
ˆXn
Y n
Rf
Figure 1.
Rate-adaptive SW coding with a rate-limited feedback channel
using the feedback channel. To derive the corresponding per-
formance bounds, we consider ideal (lossless) SW codes and
obtain the optimized partitioning and code rates such that the
average rate is minimized. Next considering practical SW
codes with ﬁnite block length and discrete rates, we present
an algorithm for the design of the optimized partitioning to
minimize the average rate while a given probability of error
constraint is satisﬁed. Simulation results based on LDPC
SW codes using syndromes are provided which quantify the
performance for different number of modes and demonstrate
the effectiveness of the proposed algorithms and designs.
The rest of this paper is organized as follows. Section
II discusses the preliminaries on SW coding and introduces
the system model. In Section III, performance bounds for
SW coding with uncertain SI are derived and in Section IV,
effective solutions based on practical codes are presented.
Section V is dedicated to simulations and numerical results
and ﬁnally Section VI concludes the paper.
II. PRELIMINARIES
In this section, we ﬁrst brieﬂy discuss the original SW
coding theorem. We then present the proposed system model
and introduce the parameters used in the rest of the paper.
A. Slepian-Wolf Coding and Related Limitations
Consider the i.i.d sequence (Xn, Y n) = {xi, yi}∞
i=0 with
joint probability distribution Pxy(x, y) = Px(x)Py|x(y|x).
It may be assumed that Xn and Y n are correlated via a
virtual innovation channel model Py|x(y|x). It was shown
in [1] that the two sources Xn and Y n may be separately
encoded and jointly and losslessly decoded at a minimum
sum rate of H(X, Y ), where H(.) is the Shannon entropy
function. This is referred to as distributed source coding in
symmetric setting. Interestingly, the said rate coincides with
that when both sources are collocated.
If Y n is available to the decoder as SI, Xn can be encoded
at the rate of H(X|Y ). This scenario is known as distributed
source coding in asymmetric setting. The situation in which
Xn is a discrete random variable but Y n has a continuous
alphabet, usually arises in compression of data in sensor
networks [12] or compression of quantized indexes in WZ
coding of correlated data [13]. A good model for these
scenarios is that Xn is a sequence of binary uniform random
variables, i.e., X = {−1, 1} and Py|x(y|x) represents an
AWGN channel. If the variance of the AWGN channel is
equal to σ2, then the necessary rate for compression of Xn
as given in [1] equals RSW = H(X|Y ). This rate can be
calculated as
RSW = H(X|Y ) = H(X) + 1
2 log 2πeσ2 − h(σ) ,
(1)
where
h(σ) = − 1
2
∫ ∞
−∞
(
1
σ
√
2π (e
−(y−1)2
2σ2
+ e
−(y+1)2
2σ2
))
log (
1
σ
√
2π (e
−(y−1)2
2σ2
+ e
−(y+1)2
2σ2
))dy .
(2)
Clearly, the compression rate is a function of σ2 and if
the correct compression rate is not known at the encoder,
lossless decoding is not possible at the decoder.
Practical SW coding is based on ﬁnite rate and ﬁnite
length codes as follows. According to [3], if the parity
check matrix for this code is Hp of size (n − k) × n, ﬁrst
the syndrome Sl for a block Xl of source is created by
calculating Sl = HpXl and then Sl is sent to the decoder.
This indicates a compression rate of (n − k)/n. At the
decoder, exploiting SI, an estimate ˆXl is found such that
Sl = Hp ˆXl and the Hamming distance between Xl and ˆXl
is minimized. This is ideally done by Maximum-Likelihood
decoding, but iterative decoding algorithms based on Turbo
or LDPC codes are usually used in practice. In this paper, the
method of [5] has been used for practical implementations
in Section V.
B. System Model
Figure 1 shows the general system model in this pa-
per. Xn = {xi}∞
i=0 is the source to be encoded where
xi are binary random variables with uniform distribution.
Y n = {yi}∞
i=0 is the correlated SI available to the decoder.
To model the correlation, we have yi = xi + zi, where
zi is Gaussian distributed with variance σ2. The source is
encoded in frames of length nf and it is assumed that σ is
constant for each separate frame, but varies from one frame
to another. The random variable σ follows the PDF gσ(σ)
and cumulative distribution function G(σ) =
∫ σ
0 gσ(x)dx,
where the range of σ is denoted by Σ, usually including all
non-negative real numbers.
Encoding is performed using a multi-mode encoder with
a set R of pre-designed SW codes for compression, where
|R| = M. The decoder is assumed to estimate σ perfectly in
each frame [10], and based on which select an encoder mode
or equivalently the SW code to be used. The decoder then
sends the index i, i ∈ {1, 2, . . . , M} of the selected mode
to the encoder via a rate-limited feedback channel with the
rate Rf = ⌈log2(M)⌉ without delay or error. Therefore, Σ is
partitioned into M disjoint intervals (modes) in an optimized
250
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

manner and each interval is associated with one code. The
partitions are in the form [Ti−1, Ti), i = 1, 2, . . . , M. The
probability of each mode being used is then equal to pi =
∫ Ti
Ti−1 gσ(x)dx.
Given a set of SW codes R with rates Ri, i ∈ {1, . . . , M},
the multi-mode SW design problem is to determine the
partitioning of Σ such that the source coder average rate
Ravg = ∑M
i=1 piRi, is minimized (maximum compression).
Without loss of generality, we assume that Ri > Ri−1, 2 ≤
i
≤
M. To the best of the authors’ knowledge, this
paper is the ﬁrst in the context of Slepian-Wolf coding to
formulate the rate control mechanism as the solution to an
optimization problem. In Section III, performance bounds to
this problem are obtained when ideal (lossless) SW codes
are considered and their corresponding rates may also be
designed. In Section IV, the design problem with practical
SW codes and hence a practical lossless decoding constraint
is addressed. This is accomplished by modeling the decoding
error performance of each SW code by a function fi(.).
Speciﬁcally, fi(α) denotes the probability of bit error at the
SW decoder, when σ2 = α and α is known to both encoder
and decoder.
III. RATE ADAPTATION FOR IDEAL SLEPIAN-WOLF
CODING
Assuming ideal SW codes with inﬁnite block length and
zero error probability, one can obtain a lower bound for the
average rate and use it as a benchmark for the performance
of practical SW codes. In this direction, no constraint on the
rate of the codes are assumed, i.e., Ri ∈ [0, 1], and indeed,
the code rates are design parameters. This is in contrast to
practical SW codes with predetermined rates.
Formally
stating
the
problem,
the
objective
is
to
minimize the average rate (maximize the compression
ratio) for lossless decoding. In this case, the probability of
decoding error goes to zero as the block length goes to
inﬁnity.
Problem 1:
min
Ti∈Σ,Ri,i=1,2,...,M Ravg =
M
∑
i=1
piRi
s.t.{ ¯Pe → 0|nf → ∞}
(3)
where ¯Pe denotes the average probability of error and Ri ∈
[0, 1]. To solve this problem, we set
Ri = H(Ti) = 1 + 1
2 log(2πeT 2
i ) − h(Ti) .
(4)
This is due to the fact that each Ti in fact corresponds to a
value of σ and by deﬁnition of conditional entropy and as
given in equation (1), H(Ti) is the minimum achievable rate
for σ = Ti. It can be simply veriﬁed that if Ri < H(Ti) the
probability of error cannot go to zero when nf → ∞. After
setting Ri for given Ti, ﬁnding the optimal partitioning of
Σ, or equivalently the values of Ti, completes the solution
to problem 1. Algorithm 1 is proposed for this purpose.
Algorithm 1:
• Initialize Ti,0 for i = 1, 2, . . . , M − 1 as the interval
thresholds at iteration 0 arbitrarily, but satisfying Ti,0 <
Tj,0 for any i < j. Set T0,0 = min(Σ) and TM,0 =
max(Σ).
• Choose the values of η and kmax as predeﬁned constants
to control the number of iterations.
Now, for each iteration k = 1, 2, . . . , kmax, do the following,
1) For each i = 1, 2, . . . , M − 1, ﬁnd Ti,k such that
∂Ravg,k(Ti,k)
∂Ti,k
= 0,
Ti−1,k < Ti,k < Ti+1,k . (5)
where
∂Ravg,k(x)
∂x
= gσ(x)
[
H(x) − H(Ti+1,k)
]
+
[
G(x) − G(Ti−1,k)
]∂H(x)
∂x
.
(6)
If there are multiple solutions for Ti,k, select the one
which results in the smallest average rate Ravg,k. Note
that in calculating Ti,k using (5), all other Tj,k, j ̸= i
are kept ﬁxed.
2) Calculate
the
average
rate,
Ravg,k,
using
the
ﬁnal
partitioning
at
iteration
k.
If
(Ravg,k−1 − Ravg,k)
/
(Ravg,k−1) < η or k > kmax,
stop.
More details on Algorithm 1 are presented below.
Proposition 1: The average rate computed using Algo-
rithm 1 is reduced in each run of its step 1.
Proof: From (3) and (4), we have
Ravg =
M
∑
i=1
∫ Ti
Ti−1
gσ(x)H(Ti)dx
(7)
= β +
∫ Ti
Ti−1
gσ(x)H(Ti)dx +
∫ Ti+1
Ti
gσ(x)H(Ti+1)dx ,
where β is a constant independent of Ti. As evident in (6) for
x = Ti, noting that H
′(Ti) = ∂H(Ti)/∂Ti is differentiable
for Ti > 0, ∂Ravg/∂Ti exists for all values of Ti and
continuous gσ(x).
In the following, we show that Algorithm 1 is able to
ﬁnd at least one minimum for Ravg in each step. It can be
veriﬁed that
Ravg|Ti→Ti−1 = Ravg|Ti→Ti+1 =
(8)
= β + H(Ti+1)(G(Ti+1) − G(Ti−1)).
Also from (6), we have
lim
Ti→T +
i−1
∂Ravg
∂Ti
= gσ(Ti−1)(H(Ti−1)−H(Ti+1)) < 0 , (9)
251
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

lim
Ti→T −
i+1
∂Ravg
∂Ti
= H
′(Ti−1)(G(Ti+1)−G(Ti−1)) > 0, (10)
which follow as both H(.) and G(.) are increasing functions
of their arguments or consequently H(Ti−1) < H(Ti+1),
H
′(Ti−1) > 0, and G(Ti+1) − G(Ti−1) > 0. Equations (8),
(9) and (10) are sufﬁcient conditions that Ravg(Ti) has at
least one minimum in the interval [Ti−1, Ti+1), which is
found using (6). This indicates that Ravg is in fact reduced
in each run of the step 1 of Algorithm 1.
Remark 1. Rf → ∞ is associated with inﬁnite number
of encoder modes or having an ideal feedback channel with
no rate limit. This eliminates any uncertainty at the encoder
and the SW bound is then achieved for an equivalent encoder
which is fully aware of SI statistics. This results in the
minimum possible rate. In such case we have,
Rmin =
∫ ∞
0
H(x)gσ(x)dx
(11)
which can be calculated numerically. This is referred to as
SI-Aware SW Coding bound (SIA-SWC) and is used for
comparison in Section V.
IV. RATE ADAPTATION FOR PRACTICAL SLEPIAN-WOLF
CODING
The performance bounds of multi-mode rate-adaptation
scheme for SW coding with rate-limited feedback was
studied in Section III using ideal (lossless) SW codes. For
practical SW coding and in presence of uncertain SI, the
encoder may only use a certain number of pre-designed
codes with predetermined rates. These codes are not ideal
and may involve possible decoding error.
A. Rate-Adaptation Based on Practical Codes
The
following
design
problem
formulates
the
minimization
of
the
average
rate
when
ﬁnite
length
and discrete rate SW codes are used and their probability
of error performance are taken into account.
Problem 2:
min
Ti∈Σ,i=1,2,...,M Ravg =
M
∑
i=1
Ri
∫ Ti
Ti−1
gσ(x)dx
(12)
s.t.
{ ¯pi =
∫ Ti
Ti−1
gσ(x)fi(x)dx < p0
|
Ri ∈ R}
where ¯pi denotes the average probability of error in mode
i. Note that in this design, practical lossless compression
has been interpreted as the average probability of error per
mode being limited to a small p0. Satisfying the stricter per-
mode average probability of error constraint also satisﬁes the
overall average probability of error.
In the following, we present an algorithm to solve
problem 2. The proposed solution is general in the sense
that it is independent of the selected set of codes, their
rates, and their error probability performance.
Algorithm 2:
Set Ti = 0 and select ϵ a small number. For i = 1, 2, . . . , M
do the following,
1) Set Ti = Ti−1.
2) Increase Ti with a step size ϵ.
3) Calculate ¯pi, if ¯pi < p0, go to (2). Else reduce Ti by
ϵ.
Intuitively, with Ri > Ri−1, in order to reduce Ravg,
the lower rates are to cover as much of the range of σ
as possible. Thus, the thresholds are updated from T1 to
TM. Each one is increased until the probability of error
constraint for the corresponding mode is met with equality.
To show that Ravg is decreased at each step of Algorithm
2, we present Proposition 2.
Proposition 2: Suppose that Σ is partitioned with the
intervals [Tj−1, Tj), j = 1, 2, . . . , M. If all thresholds except
Ti are ﬁxed, in order for Ravg to be reduced, Ti must be
increased.
Proof:
Suppose that all thresholds {Tj}M
j=1, j ̸= i
are ﬁxed and only Ti is to be updated. Also suppose that
T
′
i refers to the modiﬁed Ti value, and deﬁne R
′
avg as the
updated value for Ravg when Ti is modiﬁed. Now, we have
R
′
avg − Ravg =
+
(
γ +
∫ T
′
i
Ti−1
Rigσ(x)dx +
∫ Ti+1
T ′
i
Ri+1gσ(x)dx
)
−
(
γ +
∫ Ti
Ti−1
Rigσ(x)dx +
∫ Ti+1
Ti
Ri+1gσ(x)dx
)
(13a)
=
(∫ Ti+1
Ti−1
Rigσ(x)dx +
∫ Ti+1
T ′
i
(Ri+1 − Ri)gσ(x)dx
)
−
(∫ Ti+1
Ti−1
Rigσ(x)dx +
∫ Ti+1
Ti
(Ri+1 − Ri)gσ(x)dx
)
=
∫ Ti
T ′
i
(Ri+1 − Ri)gσ(x)dx
(13b)
where γ = ∑M
j=1
∫ Tj
Tj−1 Rjgσ(x)dx , j ̸= i, i + 1. The term
(Ri+1 − Ri)gσ(x) is always positive as the code rates are
assumed ordered and gσ(x) is positive as a PDF. Therefore,
it is a necessary and sufﬁcient condition for Ravg to decrease
that T
′
i > Ti.
B. Mode Selection
In practice, due to limitations for the feedback channel
rate Rf and for reduced encoder/decoder complexity, only
a limited number of modes equal to N = 2Rf < M may
be allowed. For that reason in the following, we propose
the Algorithm 3 to select a suitable subset of modes
with the desired size N and their associated rates and
252
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

intervals from the original result obtained using Algorithm 2.
Algorithm 3:
• Initialization: Given the set R, use Algorithm 2 to
design a rate-adaptive multi-mode SW code. Consider
the resulting thresholds in the sequel.
• Perform the followings for m = 1, 2, . . . , |R| − N.
• For i = 1, 2, . . . , |R|,
1) Merge
each
two
partitions
in
the
form
of
[Ti−1, Ti) and [Ti, Ti+1), into one single partition
[Ti−1, Ti+1).
2) Remove the code in R with the rate Ri, associated
with [Ti−1, Ti), temporarily from R and assign
Ri+1 to the partition [Ti−1, Ti+1).
3) Calculate Ravg and store its value as Ri
avg.
• Select the merging of intervals corresponding to
arg mini Ri
avg.
Note that by selecting Ri+1 for the merged partitions,
the probability of error constraint is still satisﬁed because
Ri+1 > Ri and SW code (i + 1) can be used for com-
pression instead of code i without incurring more error.
The presented algorithm provides a low complexity but
suboptimal solution to select a subset of N codes out of M
available codes for the multi-mode SW encoder. Using an
exhaustive search to this end, involves running Algorithm
2 for each code subset, which equals M!/(N!(M − N)!)
subsets in total. However, Algorithm 3 has only M−N steps
(a small number). Also, the computational cost for each step,
which only consists of merging partitions, is much smaller
than cost of running Algorithm 2. Algorithm 3 is used for
mode selection in simulations of Section V.
V. SIMULATIONS AND RESULTS
In this section, we present a simulation setting and corre-
sponding results to validate and compare the designs of Sec-
tions III and IV. We used a set of high-performance LDPC
codes from the DVB-S2 standard for SW compression. The
selected set consists of 11 SW codes with discrete rates as
in Table 1. The bit error rate performance of this set was
obtained via extensive simulations. The probability of error
function fi(σ2) for the code with rate Ri is modeled by
fi(σ2) =
1
(1 + eci(1/σ2−bi))di ,
(14)
for small (less than 10−2) bit error rates, where bi, ci, di
are constants that are obtained using ﬁtting techniques as
presented in Table 1. It is noteworthy that a similar error
performance model as in (14) has been used to model
channel decoding error in [14].
For the simulations, it is assumed that the parameter σ2,
as introduced in Section II, is Rayleigh distributed with
parameter θ2, i.e, if u = σ2, then fu(u) = u
θ2 e− u2
2θ2 , u > 0.
A greater θ2 implies more uncertain SI. We also set p0 =
1 × 10−4.
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
θ2
Ravg
SIA − SWC Bound
M = 11
N = 8, Practical
N = 8, Ideal
N = 4, Practical
N = 4, Ideal
N = 2, Practical
N = 2, Ideal
Figure 2.
Ravg for different levels of SI uncertainty controlled by θ2
Figure 2 depicts the performance of the proposed multi-
mode SW coding quantiﬁed by Ravg, as a function of
θ2 for different number of modes. Using ideal SW codes
and Algorithm 1, a lower bound for Ravg is presented. As
expected, adding to the number of modes or equivalently
the feedback rate, reduces the average rate. Using ideal
SW codes with feedback rates Rf = 1, 2, 3 bps and for
values of θ2 > 0.2 the gap from SIA-SWC bound (ideal
feedback) approximately equals 0.188, 0.104, and 0.060 bps,
respectively. For practical SW codes and using 2, 4, 8, and
11 modes, this gap is approximately 0.278, 0.145, 0.093,
and 0.084 bits per symbol (bps), respectively.
The gap between ideal and practical SW code perfor-
mance for θ2 > 0.2 equals 0.090, 0.047, 0.033 bps, re-
spectively for Rf = 1, 2, 3 bps. For small values of θ2, this
Ravg gap is larger, e.g., for θ2 = 0.1 and Rf = 1 bps, it
amounts to 0.141 bps. This small gap between practical and
ideal code performance is more due to using ﬁnite length and
discrete rate codes, and not to sub-optimality of Algorithm 3.
This is supported by performance comparison of Algorithm
3 for mode selection and an exhaustive search solution as
depicted in Figure 3. As evident, the incurred gap due to
sub-optimality of the proposed Algorithm 3 is negligible
over a wide range of values of Rf and θ. This is certainly
outweighed by its much smaller complexity in comparison
to an exhaustive search.
It is noteworthy that the gap between ideal and practical
code performance decreases as Rf increases. This is due
to the fact that as Rf and hence the number of modes
(codes) increase, the set R approximately resembles a set
of continuous rate codes. It is very interesting that the
induced rate loss using 11 modes for compression is only
0.084 bps. This is comparable with the suggested SI aware
253
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
θ2
Ravg
N = 2, Practical − Exhaustive
N = 2, Practical − Proposed
N = 2, Ideal
N = 4, Practical − Exhaustive
N = 4, Practical − Proposed
N = 4, Ideal
Figure 3.
Performance comparison of the exhaustive search and the
proposed method for mode selection (Algorithm 3)
Table I
FITTING PARAMETERS FOR MODELING THE PERFORMANCE OF
LDPC-BASED SW CODES
Ri
bi
ci
di
Ri
bi
ci
di
1/10
4.249
4.18
11.9
2/5
1.898
9.22
90.4
1/9
3.803
4.04
6.8
1/2
1.183
40.78
9.5
1/6
3.124
14.24
7.0
3/5
0.923
28.35
50.1
1/5
2.820
11.73
11.5
2/3
0.680
50.11
12.2
1/4
2.474
12.45
15.5
3/4
0.505
60.18
16.0
1/3
2.042
14.59
31.4
-
-
-
-
schemes of [8] and [9] with LDPC and Turbo-based SW
codes. In comparison to [6], the superiority of the proposed
method is of course due to its judicious use of feedback and
hence reduced decoding complexity and delay as discussed
in section I.
VI. CONCLUSION AND FUTURE WORK
In this paper, a rate adaptation framework for the problem
of Slepian-Wolf coding in presence of uncertain side infor-
mation at the encoder is presented which uses a multi-mode
encoder accompanied by a well-designed feedback scheme.
SW compression rate and other mode parameters based on
practical SW codes are designed such that the average rate is
minimized. A lower bound is also derived considering ideal
lossless codes. Simulation results based on LDPC codes
show that by using sufﬁcient number of modes, a desirably
small average rate gap from the theoretical bound with no
uncertainty can be achieved.
For the future work, the generalization of the proposed
scheme for the context of Wyner-Ziv coding may be consid-
ered. This generalization requires introduction of distortion
to the average rate minimization problem and the use of
quantizers. The generalized scheme can then be adapted to
be used in contexts such as distributed video coding and
wireless sensor networks.
ACKNOWLEDGMENT
This project was funded in part by Iran Telecommunica-
tions Research Center (ITRC).
REFERENCES
[1] D. Slepian and J. Wolf, “Noiseless coding of correlated
information sources,” IEEE Trans. Inf. Theory, vol. 19, no. 4,
pp. 471–480, July 1973.
[2] F. Cabarcas and J. Garcia-Frias, “Approaching the Slepian-
Wolf boundary using practical channel codes,” Signal Pro-
cessing, vol. 86, no. 11, pp. 3096–3101, 2006.
[3] S. Pradhan and K. Ramchandran, “Distributed source coding
using syndromes (DISCUS):Design and construction,” IEEE
Trans. Inf. Theory, vol. 49, no. 3, pp. 626–643, Mar. 2003.
[4] J. Bajcsy and P. Mitran, “Coding for the Slepian-Wolf prob-
lem with turbo codes,” in Proceedings GlobeCom, 2001, pp.
1400–1404.
[5] A. D. Liveris, Z. Xiong, and C. N. Georghiades, “Compres-
sion of binary sources with side information at the decoder
using LDPC codes,” IEEE Communications Letters, vol. 6,
no. 10, pp. 440–442, Oct. 2002.
[6] B. Girod, A. Aaron, S. Rane, and D. Rebollo-Monedero,
“Distributed video coding,” Proceedings of the IEEE, vol. 93,
no. 1, pp. 71–83, Jan. 2005.
[7] H. Zhang and H. Ma, “Delay-efﬁcient rate control for Wyner-
Ziv video coding in wireless video sensor networks using
network coding,” in ICME, 2010, pp. 243–248.
[8] D. Varodayan, A. Aaron, and B. Girod, “Rate-adaptive dis-
tributed source coding using low-density parity-check codes,”
in Asilomar Conf. on Signals, Systems and Computers, 2005,
pp. 1203–1207.
[9] M. Zamani and F. Lahouti, “A ﬂexible rate Slepian-Wolf code
construction,” IEEE Trans. Commun., vol. 57, no. 8, pp. 2301
–2308, Aug. 2009.
[10] C. Ng, C. Tian, A. Goldsmith, and S. Shamai, “Minimum
expected distortion in Gaussian source coding with uncertain
side information,” in ITW, 2007, pp. 454–459.
[11] F. Bassi, M. Kieffer, and C. Weidmann, “Wyner-Ziv coding
with uncertain side information quality,” in Europeen Signal
Process. Conf., 2010, pp. 2141 – 2145.
[12] Z. Xiong, A. Liveris, and S. Cheng, “Distributed source
coding for sensor networks,” IEEE Signal Process. Mag.,
vol. 21, no. 5, pp. 80–94, 2004.
[13] Z. Liu, S. Cheng, A. Liveris, and Z. Xiong, “Slepian-Wolf
coded nested lattice quantization for Wyner-Ziv coding: High-
rate performance analysis and code design,” IEEE Trans. Inf.
Theory, vol. 52, no. 10, pp. 4358–4379, 2006.
[14] D. J. C. MacKay and C. P. Hesketh, “Performance of low
density parity check codes as a function of actual and assumed
noise levels,” Electronic Notes in Theoretical Computer Sci-
ence, vol. 74, pp. 91–98, 2003.
254
SENSORCOMM 2011 : The Fifth International Conference on Sensor Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-144-1

