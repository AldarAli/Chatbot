Defect Detection and Classiﬁcation of Electronic Circuit Boards Using Keypoint
Extraction and CNN Features
Yohei Takada Tokiko Shiina Hiroyasu Usami Yuji Iwahori
Department of Computer Science
Chubu University
Kasugai, 487-8501 Japan
email:{ytakada|shiina|usami}@cvl.cs.chubu.ac.jp
email:iwahori@cs.chubu.ac.jp
M. K. Bhuyan
Dept. of Electronics
and Electrical Engineering
Indian Institute of Technology Guwahati
Guwahati, 781039 India
email:mkb@iitg.ernet.in
Abstract—This paper proposes a method for defect detection and
classiﬁcation of electronic circuit board by extracting keypoints
without reference images. The ﬁnal purpose is to distinguish a
problematic defect, such as disconnection from a non-defect, dust
in the manufacturing process et al. Keypoints are extracted from
the electronic circuit board image, then a patch image is cropped
using obtained keypoint information, such as the position. The
cropped images are used as input to CNN (Convolutional Neural
Network) and 4096-dimensional features are obtained in the ﬁnal
layer of the full connected layers. SVM (Support Vector Machine)
is introduced for learning and classiﬁcation using CNN features.
The effectiveness of the proposed method is conﬁrmed through a
detection experiment using actual electronic circuit board images
containing defects and by comparing the results with the previous
method.
Keywords–Defect Detection; Defect Classiﬁcation; CNN; SVM;
SURF.
I.
INTRODUCTION
Electronic circuit boards are used as components of various
precision instruments, such as computers and liquid crystal
displays. Each layer is inspected after drawing and baking the
mask pattern in the manufacturing process of the electronic
circuit boards. There is Automated Optical Inspection (AOI)
as a computer assisted automated visual inspection for circuit
boards. The defect is judged from the loss rate of the lead
wire portion in AOI, but the ﬁnal goal is to determine if
that defect is a true or a pseudo defect of the product. The
inspections need to be done with high accuracy. The current
AOI needs a subsequent ﬁnal veriﬁcation by the human eye to
judge the existence of a defect. The human cost and variability
of the inspection accuracy originating from individual checking
ability are problems in the veriﬁcation process. It is hoped to
reduce this cost and to keep the accuracy for inspection with
computer-aided defect inspection.
Defect types during the inspection consist of true defect
and pseudo defect. True defects include chipping, breaking,
protrusions, shorts, etc. True defects cannot be shipped as the
products when these defects are found. On the other hand,
pseudo defects have foreign matter adherence and stains and
these can be removed after inspection. So, pseudo defets can be
shipped as the product. If a true defect is erroneously classiﬁed
into a pseudo defect, it becomes a problem. If a pseudo defect
is erroneously classiﬁed as a true defect, the product will be
discarded. Normal products are disposed of when a pseudo
defect is erroneously classiﬁed as a true defect, and it causes
reduction of production yield rate.
Papers [1] and [2] have been proposed to solve these
problems using image processing. Paper [1] proposes a global
defect inspection of defects by learning using Mahalanobis
distance. Paper [2] supplies a current to the electronic circuit
boards, and the defect is detected from the radiation position
from the radiation infrared image by taking advantage of the
characteristic that the short portion generates heat due to the
leak current.
The works [3] - [4] have proposed the defect classiﬁcation.
Paper [3] classiﬁes defect type using its shape informatio-
nunder the assumption that the reference image is used for
the classiﬁcation. Paper [5] detects a candidate region of
defect by taking the difference between the reference image
and the test image. Feature quantities are obtained from the
candidate region and two classes classiﬁcation of true defect
and pseudo defect is proposed using SVM. Mutiple subsets are
constructed by random sampling of the dataset,thenn multiple
classiﬁers are constructed based on each subsets feature. The
data classiﬁcation is performed by taking a majorityvote, and
the stable accuracy is obtained if the number of learningdata
is sufﬁcient. However, it is necessary to prepare the reference
images under inspection. The creation of the reference image
requires positioning in units of pixels, and it costs much to
create a reference image for each inspection image. Paper [4]
proposes a defect classiﬁcation method using Bag-of-Features
as a method without using a reference image, while this
paper deals with AVI (Automatic Visual Inspection) which is
available to the simpler patterns of electronic circuit boards.
The method cannot be directly applied to AOI.
This paper tries to improve the accuracy of detection and
classiﬁcation using features obtained by Convolutional Neural
Network (CNN). The candidate defect region is extracted
without reference image by keypoint extraction in defect clas-
siﬁcation, and features are extracted by inputting the cropped
region into the CNN.
II.
TYPES OF DEFECT
True defect and pseudo defect are classiﬁed into several
types depending on the color and shape of the defect portion.
113
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

A defect of the same type often has some variation based on
the image, and this makes it difﬁcult to classify it as a true or
pseudo defect.
(a) Disconnection
(b) Crack
(c) Crack
(d) Connection
(e) Connection
(f) Projection
Figure 1. Type of True Defects
(a) Dust
(b) Stain
(c) Stain
Figure 2. Type of Pseudo Defects
It is conﬁrmed that there is a difference in the intensity
value of the edge portion in the crack defect as shown in Figure
1(b) and Figure 1(c). The connected part is thinner than the
normal lead wire as shown in Figure 1(d), while a thicker part
than the normal lead is observed in connection defect as shown
in Figure 1(e). The appearance also differs even in the pseudo
defect. It is conﬁrmed that there is a difference in the radiance
value of the defect part in the Figure 2(b) and Figure 2(c)
which are stain defect. It is also conﬁrmed that noise appears
in the entire image.
III.
INSPECTION METHOD USING REFERENCE IMAGE
In [5], a non-defect reference image is prepared for an
image to be inspected. A difference is taken for each RGB
channel and a binary conversion is performed on the difference
image using a threshold value obtained from a discriminant
analysis method. The defect region is detected by taking the
logical sum of three binarized images (Figure (3)). Since the
reference image should be aligned on a pixel-by-pixel basis
at the time of creation and there may be multiple similar
portions in the same electronic board, it takes cost to obtain
the difference from the correct portion. The example result
of defect detection using both inspection image and reference
image is shown in Figure 3(c).
Feature quantities, such as maximum value, median value,
mode value, and so on are extracted as a feature quantity from
the detected defect region in each channel of RGB and HSV
(a) Inspection Image
(b) Reference Image (c) Result of Detection
Figure 3. Detection of Defect
(Hue, Saturation, Value) and so on. Subsets are created from
the entire dataset using random sampling and multiple SVMs
are constructed. The ﬁnal result is decided by the majority vote
using multiple SVMs.
IV.
PROPOSED METHOD
The proposed method uses SURF, which is a keypoint
extraction method, and extracts a defect candidate region
without reference images. Features are obtained by inputting
the extracted region to CNN, which is a feature extraction
processing of Deep Learning. Both SVMs for defect detection
and defect classiﬁcation are constructed using the obtained
features, and these SVMs perform defect detection and defect
classiﬁcation, respectively.
The procedure of the proposed method is as follows.
1)
Convert the learning image to the HSV color rep-
resentation system and detect the feature for the S
channel using SURF.
2)
Create a rectangle using the coordinates and scale of
the obtained keypoint, and crop the image.
3)
Label the image cropped from the defect portion or
non-defect portion using the reference image.
4)
Obtain features from the ﬁnal layer of the full con-
nected layer of CNN by inputting the cropped image
to CNN.
5)
Construct SVM for defect detection by using the
features obtained from the defect portion and the
features obtained from the non-defect portion.
6)
Construct SVM for defect classiﬁcation by separating
the features obtained from defect region into true
defect and pseudo defect.
A. Determination of Pseudo Defect Region Using Keypoint
Extraction
SURF is a method to extract features which are invariant
to the illumination change, the scale change or the rotation.
Keypoints are detected by creating multiple DoG (Difference
of Gaussian) images and detecting the local maximum value
of intensity in SURF. The value of scale σ is also used to
obtain the orientation of the keypoint. SURF is a rotationally
invariant feature by normalizing direction in orientation. The
gradient direction is determined within the circle region whose
radius is obtained by multiplying the scale σ of the keypoint
by six times.
SURF obtains the S channel after converting the input
image to HSV color system. As a result, the S channel was
adopted from the experience that the keypoint detected from
the defect region gained the common point where the gradient
strength becomes strong when obtaining SURF.
114
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

(a) SURF for R
Channel
(b) SURF for G
Channel
(c) SURF for B
Channel
(d) SURF for H
Channel
(e) SURF for S
Channel
(f) SURF for V
Channel
Figure 4. SURF Features
At ﬁrst sight, observation shows that the keypoint is
concentrated on the defect in the three channels of RGB
(Figure 4(a)，4(b) and 4(c), but the keypoint was detected
at the position deviating from the defect when the result is
exactly conﬁrmed with the mask image. It is conﬁrmed that
the keypoint concentrates on the defect at the result of the
S channel (Figure 4(e)), and all ﬁve keypoints were detected
on the defect region when the result is exactly conﬁrmed with
mask image. This characteristic was conﬁrmed with more than
90% of dataset images.
B. Cropping Defect Candidate Image
Defect candidate images are cropped by SURF, as ex-
plained in Section IV-A. An image is cropped using a rectangle
that encloses a circle with a radius of 6 × σ used when
orientation is determined by SURF. The number of keypoints
used for a rectangle cropping in a test image is determined by
the following procedure.
1)
The keypoints detected from the learning image In is
sorted in descending order of the gradient strength.
2)
The keypoints are plotted in order of sorting for the
mask image created from the learning image In and
the reference image.
3)
Record the number of the keypoint which is ﬁrst
plotted in the defect region of the mask image.
4)
1) to 3) are applied to all learning images, and the
average value of the keypoint numbers recorded is
used for cropping the rectangle in a test image.
True defect patches and pseudo defect patches are used for
the learning with labelling.
Rectangle images cropped for the keypoint obtained using
SURF are shown in Figure 5.
C. Feature Extraction Using CNN
Feature extraction is performed by inputting the image
cropped using SURF in IV-B to CNN. AlexNet [6] is used
as a pre-training model of CNN which structural concept is
shown in Figure 6. Here, 4096-dimensional features which
are obtained from the ﬁnal layer of the fully connected layer
(a) Result of SURF
(b) Cropped by rectangle
Figure 5. Cut by rectangle
(Layer FC7) are used for SVM learning as a transfer learning
method.
Figure 6. AlexNet
D. Construction of Classiﬁer
SVM for defect detection is constructed using the defect
patch and non-defect patch in the learning data. A linear kernel
is used for defect detection SVM. The linear kernel is denoted
by Equation (1).
k(xn, xm) = xT
nxm
(1)
The RBF kernel is used for constructing defect classiﬁcation
SVM. The RBF kernel is denoted by Equation (2). γ in
Equation (2) is a parameter that controls the identiﬁcation
boundary. Here, as the value of γ increases, the boundary
becomes more complicated.
k(xn, xm) = exp(−γ∥xn − xm∥2)
(2)
The performance of the ﬁnal classiﬁcation of the test image
is shown in Table I according to the classiﬁcation result using
the classiﬁcation SVM. It is important to reduce the rate of
erroneously classifying a true defect as a pseudo defect.
TABLE I. FINAL JUDGMENT
Defect Patch in Image
Final Classiﬁcation
Only True Defect Patch
True Defect
Only Pseudo Defect Patch
Pseudo Defect
True Defect Patch and Pseudo Defect Patch
Classify by Majority Voting
Non-Defect Patch
True Defect
V.
EXPERIMENT
An experiment was performed to validate the effectiveness
of the proposed method. Defect detection and defect classiﬁ-
cation are performed in two stages with the proposed method,
that is, the experiment consists of detection and classiﬁcation.
The dataset used for the experiment consists of 65 true
defect images and 72 pseudo defect images.
115
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

A. Detection Experiment
The keypoints was detected by SURF on the defect image
of the dataset, and SURF was obtained according to the
number deﬁned in the learning data in detection experiments.
The results of obtained patches are shown in Table II.
TABLE II. NUMBER OF PATCH
Defect Patch
Non-Defect Patch
274
164
Detection and evaluation experiments were performed us-
ing the patch shown in Table II. The classiﬁer is SVM, the
kernel of SVM is a linear kernel, the parameter C of SVM is
1000 by GridSearch, and the evaluation method used is Leave-
One-Out. Patches cropped from the same image were removed
from the learning data for the test patch when Leave-One-Out
is applied.
Precision，Recall，F-measure and Accuracy are calculated
using the following equations.
Precision
=
TP
TP + FP
Recall
=
TP
TP + FN
F − measure
=
2 ∗ Recall ∗ Precision
Recall + Precision
Accuracy
=
TP + TN
TP + FP + FN + TN
TABLE III. EVALUATION OF DETECTION ACCURACY[%]
Precision
Recall 　
F-measure
Accuracy
89.05
84.14
86.52
82.64
It is conﬁrmed that more than 80 percent of accuracy is
obtained even without the reference image in inspection shown
as Table 7.
(a) True
Defect
(b) Pseudo
Defect
(c) Detect of
True Defect
(d) Detect of
Pseudo Defect
Figure 7. Result of Detect
The detected images are shown in Figure 7. Figure 7(a) and
Figure 7(b) show original images, and Figure 7(c) and Figure
7(d) show results of defect detection. The green circle in Figure
7 represents the keypoint that became a defect candidate. The
red rectangle indicates the patch judged as a defect. It is shown
from Figure 7 that the defect region can be cropped correctly.
B. Classiﬁcation Experiment
The classiﬁcation experiment was performed under the
assumption that all detections made in V-A on the defect image
of the dataset were successful. It is judged whether the patch
is a true defect patch or a pseudo defect patch using only the
defect patch from the cropped patch. The classiﬁer is SVM, the
kernel of SVM is RBF kernel, the parameter C of SVM is 1
by GridSearch, and the parameter γ of RBF kernel is 131. The
evaluation method used is Leave-One-Out. The classiﬁcation
result of method [5] is shown when mask image is used at the
test time for comparison. The number of learning images in
the subset in method [5] is set to 50 as the number of datasets.
The result of classiﬁcation are shown in Table IV.
TABLE IV. EVALUATION OF CLASSIFICATION ACCURACY[%]
Method
Precision
Recall 　
F-measure
Accuracy
Paper [5]
53.21
80.56
62.38
52.55
Proposed
86.11
67.39
75.61
70.80
It is conﬁrmed that defect classiﬁcation can be performed
more accurately than method [5] despite using the defect
detection method without reference images, which is shown
from Table IV.
VI.
CONCLUSION
This paper proposed a new highly accurate defect clas-
siﬁcation method without using reference images by intro-
ducing keypoint extraction and CNN feature extraction. The
effectiveness of the proposed method was validated by an
experiment for detecting the defect using actual images of
electronic circuit boards. Defect detection without reference
images was implemented by performing patch cropped using
the keypoint extraction in the proposed method. As future
work, there is higher accuracy of detection and classiﬁcation.
ACKNOWLEDGMENT
Iwahori’s research is supported by Japan Society for the
Promotion of Science (JSPS) Grant-in-Aid for Scientiﬁc Re-
search (C) (23500228) and Chubu University Grant.
REFERENCES
[1]
S. Maeda, M. Ono, H. Kubota, and M. Nakatani, “Precise detection
of short-circuit defects on tft substrate by infrared image matching,”
Systems and Computers in Japan, vol. 30, no. 12, 1999, pp. 72–84.
[2]
M. Numada and H. Koshimizu, “A method for detecting globally
distributed defects by using learning with mahalanobis distance,” Journal
of the Japan Society for Precision Engineering, vol. 75, no. 2, 2009, pp.
262–266.
[3]
H. Rau and C.-H. Wu, “Automatic optical inspection for detecting defects
on printed circuit board inner layers,” The International Journal of
Advanced Manufacturing Technology, vol. 25, no. 9-10, 2005, pp. 940–
946.
[4]
H. Inoue, Y. Iwahori, B. Kijsirikul, and M. Bhuyan, “Svm based defect
classiﬁcation of electronic board using bag of keypoints,” in ITC-CSCC:
International Technical Conference on Circuits Systems, Computers and
Communications, 2015, pp. 31–34.
[5]
H. Hagi, Y. Iwahori, S. Fukui, Y. Adachi, and M. K. Bhuyan, “Defect
classiﬁcation of electronic circuit board using svm based on random
sampling,” Procedia Computer Science, vol. 35, 2014, pp. 1210–1218.
[6]
A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Advances in neural infor-
mation processing systems, 2012, pp. 1097–1105.
116
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

