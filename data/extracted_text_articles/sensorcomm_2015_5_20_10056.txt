Evidential Network for Multi-Sensor Fusion in an Uncertain Environment 
 
Abstract—Interpreting and quantifying the confidence granted 
to signals transmitted and received in a sensor network is likely 
to be called into question by various factors. On an architectural 
plan, first of all, the nature of the networks or the distance 
between sensors can induce risk of false alarm or non-detection 
by misinterpretation of the analyzed signals. External factors 
related to stresses induced by the environment are also potential 
sources of measurement errors. Finally, despite the maturity of 
techniques, internal influence factors related to the accuracy or 
reliability sensors may also, at a more basic level, impact the 
confidence placed in the test or the performed diagnosis. A 
system-embedded intelligence is then necessary to compare the 
information received for the purpose of decision aiding based on 
margin of errors converted in confidence intervals. In this 
paper, we present three complementary approaches to quantify 
the interpretation of signals exchanged in a network of sensors 
in the presence of uncertainty. 
Keywords: 
Sensor 
networks; 
Uncertainty; 
Bayesian 
techniques; Belief functions; Evidential networks. 
I. 
 INTRODUCTION 
Within the field of science and engineering, data 
imperfection requires the use of tools to define mechanisms 
for reasoning with partial knowledge and uncertain 
information. In [1], several types of imperfections are 
discerned: 
 Incompleteness and vagueness are used to qualify the 
status of a data. It is said to be incomplete if it is 
impossible for the source to provide information 
regarding 
all or part of 
the aspects of a 
problem. Vagueness is a form of incompleteness for 
when the source provides an imprecise data, the 
resulting information is necessarily incomplete. 
 Uncertainty applies when the source is unable to 
distinguish the veracity of a piece of information (that 
is to say whether the information is true or false). It 
therefore characterizes the extent of information 
compliance compared to reality. It is possible to 
distinguish 
two 
kinds 
of 
uncertainty. Random 
uncertainty is induced by the variability of an entity in 
a population and is the outcome of random 
experiments. This type of uncertainty cannot be 
reduced since it is the result of chance. Epistemic 
uncertainty is due to the lack of knowledge and 
therefore relates to the concept of incompleteness.  
 Ambiguity represents the fact that a same information 
can have several interpretations. It is therefore linked 
to the formalism of information representation which 
is not always clear and shared by all the 
stakeholders. This type of imperfection is very 
common and is often a source of misinterpretation. It 
can be avoided when formalizing the representation. 
 Granularity 
of 
information 
characterizes 
the 
difficulties that appear when two very close values 
have to be distinguished. 
A decision requires integrating this imperfection to justify 
the actions that will be undertaken. In the field of sensor 
networks, decisions must be taken at every moment with 
respect to signals individually emitted by each sensor or 
regarding the signals received and compiled by a centralized 
basis. Taking into account imperfect data allows the decision 
maker to legitimate its choices since he will have at its 
disposal additional knowledge associating the data with an 
interval of confidence and a margin of error. 
In the following are presented two distinct approaches 
based on Bayesian Networks (Section II) and Belief Functions 
(Section III) for integrating and propagating imperfect data in 
a network of sensors. In Section IV, it is shown how both 
techniques can be combined and reinforced each other within 
the same tool, namely evidential networks. Finally, in Section 
V, a comparative view of the different techniques is presented 
to show their respective conditions of use. 
II. 
BAYESIAN NETWORK APPROACH 
 
Bayesian Networks are graphic models designed to formalize 
knowledge with the purpose of reasoning about a problem. 
A. Principles 
Bayes theorem is central in the mechanism of inference in 
Bayesian Networks. It makes the link between a series of 
hypotheses, characterized by probabilities of occurrence, and 
a series of observations representing the actual state of the 
system. From the Bayes theorem, it is possible to implement 
two types of reasoning: 
 Diagnosis, or reasoning by backward inference, which 
allows, in the set of assumptions made, the 
identification of the probable cause of a given result,  
 Prognosis, or reasoning by forward inference, which 
enables the estimation of the occurrence probability of 
an evidence with respect to the formulated assumptions. 
Eric Villeneuve, François Pérès, Cédrik Béler 
Laboratoire Génie de Production 
Université de Toulouse – INPT - ENIT 
Tarbes, France 
e-mail: eric.villeneuve@enit.fr  
francois.perez@enit.fr 
cedrik.beler @enit.fr 
Vincente Gonzalez-Prida 
Department of Industrial Management 
School of Engineering, University of Seville 
Seville, Spain 
e-mail: vicente.gonzalezprida@gdels.com 
97
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

From a mathematical point of view, the space of 
hypothesis ߆={ߠଵ, … ,ߠ௜,… } and 
observations 
Ω =
{߱ଵ, … ,߱௞, … } are defined. To represent the link between 
observations and assumptions, the probability theory allows 
the use of a conditional probability distribution based on each 
verified hypothesis. This distribution can be noted ܲஐ(. |ߠ௜). 
Whether there is a knowledge regarding the values of the 
hypothesis ߠ௜∈߆ , it is then represented in the form of a 
conditional probability distribution across the observation Ω, 
noted ܲஐ(߱௞|ߠ௜), which characterizes the likelihood of 
observation ߱௞ knowing hypothesis ߠ௜. Bayes theorem can 
then be used to provide a reasoning forward inference to 
determine the most probable cause associated with this 
evidence by calculating the a posteriori probability 
distribution ܲ஀(.|߱௞). 

ܲ(ߠ௜|߱௞)=
௉(ఏ೔)×௉(ఠೖ|ఏ೔)
∑
ഇ೔∈೭ ௉(ఏ೔)×௉(ఠೖ|ఏ೔)


When the probability distribution ܲ(. |ߠ௜) is known (i.e., 
the probability of occurrence of an observation given each 
hypothesis) and a hypothesis ܲ(ߠ௜) is assumed, Bayes 
theorem allows the implementation of reasoning backward 
inference to estimate the effect of a hypothesis on an evidence 
ܲ(߱௞) . By calculating the probability distribution on the 
evidence it is then possible to predict the most likely one: 

ܲ(߱௞) = ∑
ఏ೔∈௵ ܲ(ߠ௜)×
ܲ(߱௞|ߠ௜)

Bayesian Networks are used to formalize knowledge in the 
form of a causal graph associated with a probability space. 
They are acyclic directed graphs where knowledge is 
represented by variables. Each node of the graph corresponds 
to a variable and arcs represent the probabilistic dependencies 
between these variables. Formally, a Bayesian network is 
defined by [2]: 
 a graph-oriented without circuit, noted ࣡ = (ࣰ, ℰ), 
with ࣰ, the set of nodes of ࣡, and ℰ, the set of arcs of 
࣡, 
 a finite probability space (Ω, ࣛ, ࣪), where Ω is the 
universe, i.e., the set of all the elements considered in 
the problem, ࣛ is a σ-algebra on Ω and ࣪ is a measure 
on Ω such that ࣪(Ω) = 1, 
 a set of random variables defined on (Ω,ࣛ, ࣪) , 
corresponding to each node of the graph, such that the 
set of probabilities associated with these variables 
defines the distribution of probabilities attached to the 
network:  
 ࣪(ࣰଵ, ࣰଶ,… , ࣰ௡) = ∏
࣪൫ࣰ௜|݌ܽ(ࣰ௜)൯
௡
௜ୀଵ


with ݌ܽ(ࣰ௜),  the parent set (also called predecessors or 
causes) of ࣰ௜ in graph ࣡. There are two types of probability 
tables in Bayesian Networks [2]. Tables of prior probabilities 
(table II.2) characterizes the chances that the variable ࣰ௔ 
without any parent is in state ܽ௜ . Tables of conditional 
probabilities (table II.2) establish the chances that a variable 
ࣰ௕ is in state ܾ௝ based on the state of his parents. 
Inference in a Bayesian network consists in propagating 
information in the network. Indeed, a model using this 
formalism is generally not intended to be a static 
representation of knowledge. Beyond the a priori reasoning, 
evidences may be introduced to update the observed situation 
and to insert into the model the changes enabling the 
refinement of the results [3]. This new knowledge, takes the 
form of a so-called elementary information, denoted ℐ , 
relative to a particular node. There are two types of basic 
information. 
The 
deterministic 
information 
allows 
instantiating a variable, which is affecting it a precise value, 
(i.e., ࣪(ࣰ௔ = ܽଵ|ℐ) = 1 ). The imprecise information 
modifies the distribution of probability of the variable, either 
by excluding a value of the universe of the variable 
(࣪(ࣰ௔ = ܽଵ|ℐ) = 0) or, more usually, by changing the law 
(࣪(ࣰ௔ = ܽଵ|ℐ) ≠ ࣪(ࣰ௔ = ܽଵ)). 
B. Case Study 
The growing need of wiring in avionics, automotive, 
telecommunications, nuclear plants, buildings, etc., has 
caused the increase of cable length moving from 200m up to 
4km in a modern car. The type of a cable (coaxial, twisted 
pair, optic fiber, etc.) depends on the nature of the 
propagating signal (data and energy) into network, the 
corresponding voltage level and the environment (noise, 
temperature, vibration, etc.) in which the cable is 
implemented. One day or another, a cable will show signs of 
damage involving the appearance of faults (short and open 
circuit, aging, etc.). These faults can be a consequence of 
environmental stress (heat, moisture, chafes, etc.) and a cause 
of dramatic mishaps such as TWA ﬂight 800 in 1996. 
Therefore, a wiring diagnosis system is needed to detect and 
locate faults as early as possible. Reﬂectometry is a suitable 
diagnosis technique as it requires a single access point to 
inject a test signal into the cable network. During its 
propagation, a part of its energy is reﬂected back to the access 
point at each impedance discontinuity (fault, junction, etc.). 
Then, the analysis of the reﬂected signals, commonly called 
“Reﬂectogram”, permits to characterize this discontinuity. In 
the literature, several reﬂectometry methods are proposed 
depending on the studied domain and the type of the used test 
signal [4]. Although standard reﬂectometry has proven its 
eﬃciency in wire fault detection, it suﬀers from ambiguity 
problems related to fault location in branched networks. As a 
solution, a distributed diagnosis strategy is proposed [5]. 
It consists in using multiple diagnosis systems, called 
“reﬂectometer”, to make reﬂectometry measurements at 
many extremities of the cable network. Here, the major 
problematic involves the diagnosis system reliability, number 
and location, signal processing, resource allocation, 
communication protocol, etc. Based on the uncertainty 
regarding diagnosis system failure, measurement precision 
and fault location, the use of Bayesian networks is motivated 
by the combination of deterministic and stochastic behaviors 
of such systems of diagnosis [4]. 
Figure 2 shows the computed reflectogram for the 
branched network of Figure 1 with an open circuit fault at a 
distance of 25m from the injection point. Only one 
reflectometer is placed at the extremity of L1 to diagnose the 
whole network. The reflectometer and the network are  
98
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

 
considered unmatched, explaining the first positive peak on 
the reflectogram. The end of lines are also unmatched. Here, 
the detected fault on L3 cannot be distinguished from the 
same fault on L2. It is then possible to add another 
reﬂectometer at the end of line L. Although, the ambiguity 
problem is resolved for the fault on branch L, it remains 
inevitable if another fault appears on the branch L. So, 
another reﬂectometer should be added to overcome this 
ambiguity, which increases the diagnosis cost (number of 
reﬂectometers) [6]. As a solution, we proposed to introduce 
the cable life proﬁle aiming to cancel the fault location 
ambiguity problem with a low cost. Considering the 
uncertainty regarding faults location, measurement precision 
and reﬂectometer reliability, the use of Bayesian Networks 
appeared to be appropriate to combine these deterministic 
and stochastic behaviors [7]. 
The proposed strategy includes two steps: (1) local 
diagnosis based on BNs, (2) global diagnosis for the whole 
network to locate the detected fault(s) [8]. In local diagnosis, 
each reﬂectometer introduces the cable life proﬁle to 
calculate the conditional probability of the presence of the 
fault on each branch. Then, the obtained results for each 
reﬂectometer are integrated into a global BN to locate the 
fault in the whole network. Simulation results prove the 
eﬃciency of the proposed strategy to cancel or mitigate the 
ambiguity for fault location in a branched network with 
respect to the reﬂectometer reliability. 
Since this is not the main purpose of the paper, please refer 
to [6] for more details on the procedures. 
III. 
TRANSFERABLE BELIEF MODEL APPROACH 
 
Based on the work of Dempster [9] generalizing the theory 
of probabilities by using probability intervals, the belief 
function theory was developed by Shafer [10] to provide a 
general framework for the representation of uncertainties. 
A. Principles 
This combined approach is commonly referred to as the 
Dempster-Shafer Theory (DST). It is used to represent 
information based on the belief or the state of knowledge of 
an entity (person, sensor, etc.) and provides a very rich 
mathematical framework for: 
 the characterization of partial knowledge (including 
total ignorance) 
 the fusion of information from various homogeneous 
or heterogeneous sources 
  the modelling of uncertainty (random and epistemic) 
related to the state of a system 
 the assessment of the degree of confidence associated 
with a result 
The theory of belief is particularly well suited to the 
representation of different forms of uncertainty. It allows the 
modelling of problems where the lack of information 
prevents the reasonable use of probability theory. Belief 
techniques are used in many fields (decision, data analysis, 
classification, diagnosis, multi-sensor perception, image 
processing, etc.) for the very varied tasks such as pattern 
recognition, likelihood analysis or information merging. 
This formalism evolved and saw the emergence of a 
second approach, developed by Smets in [11]. This approach, 
called Transferable Belief Model (TBM) is a subjectivist 
interpretation of the theory of belief functions and allows the 
analyst to overcome the notion of probability. The TBM 
approach introduces a decision-making level (also called 
pignistic level) that irreversibly transforms beliefs (non-
probabilistic expression) in a probability-based consistent 
form to facilitate decision making. 
The TBM approach enables the representation of 
imperfect knowledge from multiple sources [11]. It is based 
on the assumption that reasoning in uncertainty (credal level) 
and decision-making (pignistic level) are two cognitive tasks 
of different kinds: 
 The credal level corresponds to the representation and 
manipulation of the belief statements (without using 
for example equiprobable distribution. 
 The pignistic level makes possible the decision-
making by transforming the subjective measures of 
non-probabilistic beliefs into a measure of probability. 
This transformation which allows the consideration of 
risk or bet notions, intervenes only at the time of the 
decision-making and does not alter the credal level. 
Modelling a problem using belief functions, requires to 
determine the value of the variable ω, which represents the 
system states. The frame of discernment (FoD) represents all 
possible n values (or hypothesis) for the variable ω and is 
denoted by Ω. 
Figure 1: Fault location ambiguity in a branched network 
Figure 2 : Obtained Reﬂectogram using TDR method 
99
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

Ω = {߱ଵ, ߱ଶ, … , ߱௜, … , ߱௡} = ⋃
௜ୀ௡{߱௜}
௜ୀଵ


The definition of the belief mass function, denoted ݉ஐ , 
allows the translation of an observation provided by an agent 
on the power set of Ω (denoted 2ஐ ). The power set 
corresponds to all the subsets that can be formed from the 
assumptions and the unions of assumptions of Ω. 
Consequently, the belief mass function is defined as:  
 
݉ஐ ∶  2ஐ
→
[0,1]
ܣ↦݉ஐ(ܣ)

ݓ݅ݐℎ 2ஐ = ൛∅, {߱ଵ}, {߱ଶ},{߱ଵ, ߱ଶ},{߱ଷ},{߱ଵ, ߱ଷ},{߱ଶ, ߱ଷ},… ,{߱ଵ,… , ߱௡}ൟ 
Notation ݉ௌ
ஐ(ܣ) stands for the identification of a 
source S which provides information on proposal A. The 
basic belief assignment (bba) is the set of belief masses on 
the proposition A ⊆ Ω that satisfies: 

∑
ஐ(ܣ)=1஺⊆ஐ ݉ௌ


A bba can be transformed to highlight information and to 
improve the dynamic aspects of TBM, including the fusion 
rules. The credibility measure or belief (denoted ܾ݈݁ஐ(ܣ)) 
symbolizes the minimal belief in a hypothesis A. It is the part 
of belief speciﬁcally attributed to A (without the part 
corresponding to the empty set). The plausibility measure 
(denoted ݈ܲஐ(ܣ)) represents the maximal belief in a 
hypothesis A. It is the sum of all the masses for A. Both 
measures are defined as: 
ܾ݈݁ஐ(ܣ)=∑݉ஐ(ܤ),∀ܣ⊆ Ω
∅ஷ஻⊆஺


݈ܲஐ(ܣ)=∑݉ஐ(ܤ),∀ܣ⊆ Ω
஻⋂஺ஷ∅


The transformation from credal level to pignistic level is 
called pignistic transformation [11]. This non-reversible 
transformation aims to reduce the bba in a probability 
distribution so as to be compatible with decision theory. 
Hence, the mass of proposal A is distributed using 
equiprobability on the singletons of the FoD, Ω, i.e., on the 
hypotheses related to A. Therefore, this probability 
distribution, denoted BetP, can be obtained as: 
ܤ݁ݐܲ{݉ஐ} ∶
Ω ⟶
[0,1]
߱௜  ⟼ܤ݁ݐܲ{݉ஐ}(߱௜ )

With regard to decision-making itself, it is to select the 
singleton ߱௜  of the FoD Ω having the highest pignistic 
probability to maximize the chances that the hypothesis 
symbolized by ߱௜ represents the actual state of the system (or 
the smallest, if for instance, the goal is to minimize the 
probability of occurrence of an event). It is therefore to 
maximize the expected utility in order to rationalize the 
decision. From a mathematical standpoint, this decision can 
be expressed by: 
߱ = ฬܽݎ݃݉݅݊
ܽݎ݃݉ܽݔฬܤ݁ݐܲ{݉ஐ}(߱௜ )

B. Case Study 
An example of an illustration of the concept of belief 
functions applied to sensor networks can be found in [12]. 
The author of the work deals with the area of Wireless Sensor 
Networks (WSN) based especially on infrared or ultrasonic 
techniques. These networks are made up of smaller 
equipment whose number varies from hundreds to hundreds 
of thousands. They can be deployed on one or more locations 
to observe a particular phenomenon and their mutual 
collaboration enables the triggering of alerts or the gathering 
of information on a supervised phenomenon.  
The number and the position of the sensors deployed in an 
area of interest, determine the topology of the network and 
characterizes its intrinsic properties in terms of coverage, 
connectivity, cost and life. Therefore, the performance of the 
WSN depends mainly on the method used in the deployment 
of sensors. The network architecture is intimately linked to 
the reliability of the information transmitted by the sensors 
which determines the quality of network coverage. The belief 
functions are used in this work to analyze the problem of 
management of imperfections related to the uncertainty in the 
data gathering process.  
The construction of evidence is based on two states 
required to specify whether a space point ݌ ∈ ܴ݋ܫ is 
covered (ߠଵ) or uncovered (ߠ଴). Thus, the FoD is the set ߆=
{ߠ଴,ߠଵ}. Let ݏ be a sensor, ܴ௦ be its sensing range and ܴ௨ be 
a distance (0 ≤ ܴ௨  ≤ ܴ௦) (Figure 3). 
 
Each sensor ݏ provides information on the coverage of a 
space point ݌ ∈ ܴ݋ܫ (Region of Interest) with a belief ܾ௦/௣. 
The complementary information 1 − ܾ௦/௣ is assigned to the 
whole FoD because it encodes the sensor ignorance. The 
output from the sensor ݏ about a space point ݌ ∈ ܴ݋ܫ can 
thus be represented as a bba ݉௦/௣ with two focal sets: the 
singleton {ߠଵ} and the FoD ߆. 
݉௦/௣({ߠଵ}) = ܾ௦/௣,ܾ௦/௣ ∈ [0, 1]
݉௦/௣(߆)=1−ܾ௦/௣
݉௦/௣(∅) = 0


 
Relatively to a space point ݌, a sensor ݏ provides ݉௦/௣ as 
a belief function. To decide whether ݌ is covered by ݏ, the 
pignistic transformation of ݉௦/௣  (denoted by ܤ݁ݐܲ௦/௣  )is 
constructed. The decision is based on selecting the hypothesis 
ߠ෠ with the largest pignistic probability ߠ෠= argmax
௜ୀ଴,ଵ
ܤ݁ݐܲ௦/௣({ߠ௜}).  
A space point ݌ is covered by a sensor ݏ if: 
ߠ෠ =ߠଵ
ܤ݁ݐܲݏ/݌({ߠ݅})=ܶℎ௣


 
Figure 3: Sensor sensing range representation 
100
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

The threshold (ܶℎ௣) value is an application-speciﬁc user-
speciﬁed parameter. 
One current application of WSNs is target/event detection; 
the sensors collaborate to arrive at a consensus decision as to 
whether a target is present in the RoI. A TBM-based approach 
is considered for reaching this consensus: one of the sensors 
(called a fusion center: it can be a sink, a cluster-head or any 
sensor), gathers the evidence from the other sensors, 
combines the evidence and decides whether an event is 
present or not. 
IV. 
EVIDENTIAL NETWORKS 
 
In order to take advantage of the two approaches 
mentioned so far, it is possible to combine TBM and 
Bayesian Networks. 
A. Principles 
Basic approaches enable this integration but are limited to 
binary variables [13]. Evidential networks, introduced in [14] 
and developed in [15], use conditional belief functions for 
belief propagation in acyclic oriented graphs. Each node of 
the evidential network represents a random variable that is 
associated with a finite number of values. Directed 
evidentials networks were introduced in [16]. 
In the same way as evidential networks, they use 
conditional belief functions to propagate the belief in graphs 
without circuit. This formalism is very close to Bayesian 
networks but uses conditional beliefs instead of conditional 
probability functions [17]. Each arc of the graph represents a 
conditional relationship between two variables, represented 
by nodes. Each variable is set to a FoD representing the set 
of values it can take. Parent nodes are characterized by a 
priori belief functions whereas child nodes are represented by 
belief functions conditioned by their parent values.  
The Generalized Bayes Theorem (GBT) and the 
Disjunctive Combination Rule (DCR) are used to infer and 
propagate the knowledge in the network. Figure 4 represents 
a very simple directed evidential network with only two 
nodes, ߆  and Ω  and one arc representing the causal 
relationship between the nodes. From the perspective of the 
variables, which are represented by nodes, the edge indicates 
that node Ω , which represents the observation space 
characterized by a priori belief mass distribution, noted ݉଴
Ω, 
is conditioned by node ߆, standing for the hypothesis space 
characterized by a conditional belief mass distribution ݉Ω[ߠ].  
There are several ways to propagate knowledge in a 
directed evidential network depending on the node receiving 
the current knowledge expressed in the form of a new belief 
mass distribution [14]. 
 
The knowledge is spread in the direction of the arc if the 
߆ node receives a new distribution of masses ݉௵, the Ω node 
is then updated taking into account this new information. This 
type of spread, called forward propagation enables the 
calculation of the distribution of plausibility ݈ܲΩ using the 
equation of the GBT based on an a priori knowledge. This 
equation uses the DCR rule to determine the plausibility 
݈ܲΩ[ߠ௜]] for each subset ߠ௜∈߆ and evaluate ݈ܲΩ  by 
combining the conditional plausibilities ݈ܲΩ[ߠ௜] using the 
Conjunctive Combination Rule (CCR). 
The knowledge can also be propagated in the opposite 
direction of the arc if the Ω node receives a new distribution 
of masses ݉Ω. The information contained in the Θ node is 
therefore updated to take account of this new information. 
This type of spread, called backward propagation enables the 
calculation of the plausibility distribution ݈ܲ௵ by using the 
following equation:  
݈ܲ௵(ߠ)=∑݉Ω(߱) × ൫1 − ∏
ఠ೔⊆ఠ൫1 − ݈ܲ௵[߱௜](ߠ)൯
൯, ∀ߠ⊆
ఠ⊆Ω
 ߆  
B. Case Study 
A case study using evidential network applied to sensor 
networks is being processed (Figure 5). It is related to 
Advanced Sensor Technologies for Nondestructive Testing 
(NDT) in the field of aeronautics Structural Health 
Monitoring (SHM). Sensors based on ultrasonic or Eddy 
Current techniques are arranged on an aircraft structure to 
measure the level of damage. Functional recycling of 
products or just testing the integrity of an aeronautical 
structure (fuselage or wing of an airplane for example) 
requires a diagnosis of their current state.  
 
The main goal is to detect, locate and identify defects, and, 
subsequently, follow their evolution. The use of NDT 
techniques allows the decision-maker to call on the 
compliance of the parts analyzed by quantification of the 
level of damage. The discussed example aims to develop an 
informational interface based on an evidential networks 
superimposed on the NDT sensor network for the 
interpretation of the signals received and the decision support. 
The position and the number of sensors lead to a level of 
uncertainty characterized by belief functions introduced and 
propagated in the evidential network. 
As a possible illustration of the interest of using evidential 
networks and with respect to the sensor architecture, as well 
as the emitted and received signals, one can use here this 
technique both to: 
Figure 5: Instrumented aircraft monitored by sensor networks 
Figure 4: Basic directed evidential network 
101
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

 predict the presence of a defect in a forward 
propagation of the marginal belief functions knowing 
the signal values 
 predict the detection of a defect in a backward 
propagation of the conditional belief function knowing 
the existence of a proven deterioration or failure. 
We may observe also that upon receiving the information 
where a particular defect has been detected by any one of 
several distinct sensors, one can identify the source as 
belonging to this set. Therefore, one can assign the belief that 
the signal is present to the set of possibilities. The use of a 
Bayesian network would have forced to distribute this belief 
over all the individual nodes (sensors). Evidential reasoning 
avoids so the need for assumptions on missing data. When 
beliefs on a sensor is later required they are under constrained 
resulting from the disjunction and an interval representation is 
needed to capture the real constraint which enable the explicit 
representation of uncertain and certain knowledge. 
V. 
COMPARISON OF FORMALISMS 
 
As we mentioned above, each presented formalism aims 
at modeling and reasoning under uncertainty. However, their 
conditions of application are different and some are better than 
others in given circumstances. Table 1 positions the three 
formalisms (Bayesian Networks, belief functions, evidential 
Networks) according to four criteria: the kind of uncertainty 
addressed, the minimum amount of data required, the capacity 
to model causality and the computational complexity (in 
relation with the computation time).  
VI. 
CONCLUSION 
The purpose of this paper was to present several techniques 
to introduce the notion of uncertainty in the use of sensor 
networks. The underlying idea is to be able to assess the 
measurement error and the corresponding risk to reduce the 
oversizing of the monitoring architectures and better define 
the level of confidence placed in the information received 
from the network. After presenting approaches respectively 
based on Bayesian Networks and Belief Functions, Evidential 
Networks have been introduced. The interest of their use lies 
in their ability to spread non-probabilistic knowledge 
according to forward or backward modes of propagation to 
facilitate dynamic decision making. 
REFERENCES  
[1] 
D. Dubois, and H. Prade, Formal representation of uncertainty, 
chapter 3, UK Wiley, 2009. 
[2] 
F. Jensen, and T. Nielsen, Bayesian networks and decision graphs. 
Springer, 2007. 
[3] 
M. Godichaud, A. P. Tchangani, F. Pérès, and B. Iung, “Sustainable 
management of end-of-life systems,” Production Planning & Control 
vol. 23 (2-3), 2012, pp. 216-236. 
[4] 
W. Ben Hassen, F. Auzanneau, F. Pérès, and A. P. Tchangani, 
“Diagnosis sensor fusion for wire fault location in CAN bus systems,” 
In Sensors, 2013 IEEE, 2013, pp. 1–4. 
[5] 
W. Ben Hassen, F. Auzanneau, L. Incarbone, F. Pérès, and A. P. 
Tchangani, “OMTDR using BER estimation for ambiguities 
cancellation in ramified networks diagnosis,” In IEEE Eighth 
International Conference on Intelligent Sensors, Sensor Networks and 
Information Processing, Melbourne, 2013, pp. 414–419. 
[6] 
W. Ben Hassen, F. Auzanneau, L. Incarbone, F. Pérès, and A. P. 
Tchangani, “Distributed Sensor Fusion for Wire Fault Location Using 
Sensor Clustering Strategy”, International Journal of Distributed 
Sensor Networks, vol. 2015, 2015, doi: 10.1155/ijdsn.2015.538643. 
[7] 
W. Ben Hassen, F. Auzanneau, L. Incarbone, F. Pérès, and A. P. 
Tchangani, “Distributed Reflectometry Method for Wire Fault 
Location using BER in CAN Bus,” Transactions on systems, Signals 
and Devices, 2014. 
[8] 
W. Ben Hassen, F. Auzanneau, F. Pérès, and A. P. Tchangani,  
“Ambiguity Cancellation for Wire Fault Location based on Cable Life 
Profile”,  IFAC World Congress, Cape Town, 2014, pp. 9593-9598. 
[9] 
A. Dempster, “Upper and lower probabilities induced by a 
multivalued mapping,” Annals of Math. Statistics, vol. 38, 1967, pp. 
325–329. 
[10] G. Shafer, “A Mathematical Theory of Evidence, ” Princeton 
University Press 1976. 
[11] P. Smets, and R. Kennes, “The transferable belief model,” Artificial 
Intelligence, vol. 66, 1994, pp. 191–234. 
[12] M. R. Senouci, A. Mellouk, L. Oukhellou, and A. Aissani, “Using the 
belief functions theory to deploy static wireless sensor networks,” 
Belief Functions: Theory and Applications, Springer Berlin 
Heidelberg, 2012, pp. 425-432. 
[13] C. Simon, P. Weber, and E. Levrat, “Bayesian networks and evidence 
theory to model complex systems reliability,” Journal of Computers, 
vol. 2-1, 2007, pp. 33–43. 
[14] P. Smets, “Belief functions: The disjunctive rule of combination and 
the generalized bayesian theorem,” International Journal of 
Approximate Reasoning, vol. 9, 1993, pp. 1–35. 
[15] H. Xu, and P. Smets, “Evidential reasoning with conditional belief 
functions,” Proceedings of the 10th Conference on Uncertainty in 
Artificial Intelligence, 1994, pp. 598–605. 
[16] B. Yaghlane, P. Smets, and K. Mellouli, “Directed Evidential 
Networks with Conditional Belief Functions,” LNCS, vol. 2711, 2004, 
pp. 291–305. 
[17] E. Villeneuve, C. Beler, F. Pérès, and L. Geneste, “Hybridization of 
Bayesian Networks and belief functions to assess risk. Application to 
aircraft disassembly,” IESM International Conference on Industrial 
Engineering and Systems Management, Metz, 2011, pp. 1070-1079. 
[18] F Pérès, C Martin Design methods applied to the selection of a rapid 
prototyping resource ETFA 1999 
[19] AP Tchangani, F Pérès BOCR framework for decision analysis Large 
Scale Complex Systems Theory and Applications 9 (1), 507-513 2010 
[20] AP Tchangani, Y Bouzarour-Amokrane, F Pérès Evaluation model in 
decision analysis: bipolar approach Informatica 23, 461
TABLE I.  
COMPARISON OF FORMALISMS 
 
Uncertainty kind 
Amount of data 
Causality 
modeling 
Computational complexity 
Bayesian networks 
Random uncertainty 
High (frequentist approach) 
Low (Subjectivist approach) 
Yes 
Low to Mean (depending on the 
complexity of the network) 
Belief functions 
Random and epistemic 
uncertainties 
Low 
No 
Low to mean (depending on the number of 
singletons of the variables) 
Directed evidential networks 
Random and epistemic 
uncertainties 
Low 
Yes 
Very High 
 
102
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-425-1
SENSORCOMM 2015 : The Ninth International Conference on Sensor Technologies and Applications

