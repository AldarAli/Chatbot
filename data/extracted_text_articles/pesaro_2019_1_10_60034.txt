Link Prediction in Network by a Modified Mutual Information Model
Yuling Yang
College of Information Systems and Management
National University of Defense Technology
Changsha, China
yulingyoung@yeah.net
Kuihua Huang
College of Information Systems and Management
National University of Defense Technology
Changsha, China
yang_ma_cn@163.com
Guangquan Cheng
College of Information Systems and Management
National University of Defense Technology
Changsha, China
yyl9505@126.com
Zhong Liu
College of Information Systems and Management
National University of Defense Technology
Changsha, China
phillipliu@263.net
Abstract— Link prediction in a network refers to predicting
the possibility of connection between two nodes. A traditional
method, Local Baysian Method, based on nodes’ common
neighbors, achieves high prediction accuracy as well as has low
computing complexity. However, the method ignores the
Mutual Information between the common neighbors. So, we
take mutual information model into consideration, while the
algorithm has high computing complexity. In this paper, we
will modify the model and make it more efficient.
Keywords- link prediction; Mutual Information; baysian
network.
I.
INTRODUCTION
Real-world
systems
can
be
modeled
by
complex
networks in most cases. A typical network is composed of
nodes and links, where nodes represent different individuals
in the system, and links represent relationships between
individuals. If there is a connection between two nodes,
edges are joined, and vice versa. Two nodes connected by an
edge are considered neighbors in the network. The nervous
system of nematode worms, for example, can be thought of
as a network of neurons connected by synapses. The
American aviation network can be seen as a network formed
by airports connected with each other through existing direct
flight routes. Similarly, there are computer networks, social
networks, logistics networks and so on.
Link prediction in the network refers to predicting the
possibility of connection between two nodes that have not
yet generated edges or whose connection has not yet been
discovered [1] through known network structure and other
information, which is actually a process of data mining. For
example, A is a friend of B’s, B is a friend of C’s, then there
may be a connection between A and C. The traditional link
prediction method is to use Markov chain or machine
learning to predict nodes using nodes’ attributes. The
prediction
accuracy
of
this
method
is
high,
but
its
computational complexity and non-universal parameters
limit its uses. Another method is mainly based on similarity
and likelihood analysis, which uses the network structure
characteristics. Among various similarity-based indices,
Common Neighbors (CN) is undoubtedly the precursor with
low computing complexity. This paper mainly adopts this
method.
II.
PROBLEM DESCRIPTION
Considering an undirected network G(V, E), where V is
the set of nodes and E is the set of links. Multiple links and
self-connections are not allowed. Denote by U the universal
set containing all |V| · (|V| − 1)/2 possible links, where |V|
denotes the number of elements in set V, and |E| denotes the
number of edges in set E. Then, the set of nonexistent links is
U − E. We assume there are some missing links (or the links
that will appear in the future) in the set U −  E, and the task
of link prediction is to find out these links. Generally, we do
not know where the missing or future links are, otherwise we
do not need to do prediction. Therefore, to test the
algorithm’s accuracy, the observed links, E, is randomly
divided into two parts: the training set, E୘, which is treated
as known information, while the probe set (i.e., validation
subset), E୔ , is used for testing and no information in this set
is allowed to be used for prediction. Clearly, E୘ ∪ E୔ = E
and E୘ ∩ E୔  =  ∅. Considering a simple undirected network
denoted as G(V, E), the given network can be represented by
an N × N (N represents the number of the nodes) adjacency
matrix A, where the element A୧୨ = 1, if nodes i and j are
connected and A୧୨ = 0 otherwise.
III.
MODIFIED MUTUAL INFORMATION (MI) APPROACH
In probability theory and information theory, the Mutual
Information (MI) of two random variables is a measure of
the mutual dependence between the two variables. More
specifically, it quantifies the "amount of information" (in
units such as shannons, commonly called bits) obtained
about one random variable through observing the other
1
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-698-9
PESARO 2019 : The Ninth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

random variable. The concept of mutual information is
intricately linked to that of entropy of a random variable, a
fundamental notion in information theory that quantifies the
expected "amount of information" held in a random variable.
A. Mutual Information (MI) Approach
Considering a random variable X related to the outcome
ݔ௞ and probability ݌(ݔ௞), its self-informationܫ(ݔ௞) can be
denoted as
ܫ(ݔ௞)=݈݋݃
ଵ
௣(௫ೖ) = − ݈݋݃ ݌(ݔ௞)

where the base of the logarithm is specified as (1), thus
the unit of self-information is bit. This is applicable for the
following if not otherwise specified. The self-information
indicates the uncertainty of the outcomeݔ௞. Obviously, the
higher the self-information is, the less likely the outcomeݔ௞
occurs.
Consider two random variables X and Y with a joint
probability mass function p(x, y) and marginal probability
mass functions p(x) and p(y). The mutual information I(X; Y)
can be denoted as follows:
ܫ(ܺ;ܻ)=෍෍݌(ݔ,ݕ)
௬∈௒
݈݋݃ ݌(ݔ,ݕ)
݌(ݔ)݌(ݕ)
௫∈௑
= ∑
௫,௬ ݌(ݔ,ݕ)
݈݋݃
௣(௫|௬)
௣(௫) 
Thus, in the network, the mutual information betweenݔ௜
andݔ௝ can be represented as:
ܫ൫ݔ௜,ݕ௝൯ = ݈݋݃ ݌൫ݔ௜|ݕ௝൯
݌(ݔ௜)
                                    =−݈݋݃݌(ݔ௜)− ൫− ݈݋݃ ݌൫߯௜|ݕ௝൯൯

Mutual information is a measure of the dependency
between two variables.ܫ൫ݔ௜,ݕ௝൯ = 0 represents thatݔ௜ and
ݕ௝ are independent to each other. Considering link prediction
method, we want to use local structure information to
improve the prediction. For this purpose, we use Γ(x) to
represent the set of adjacent nodes of node x. For node pairs
(x,y), the set of their common neighborhoods is denoted as
O஧୷ = Γ(x) ∩ Γ(y)Given an unconnected node pair (x,y), if
the set of its common neighbor O஧୷ is available, the
likelihood score of node pair (x,y) is defined as
ܫ൫ܮ௫௬
ଵ หܱ௫௬൯ =ܫ൫ܮ௫௬
ଵ ൯ −ܫ൫ܮ௫௬
ଵ ; ܱ௫௬൯

ܫ൫ܮ௫௬
ଵ ൯ is the self-information of that node pair (x,y) is
connected.ܫ൫ܮ௫௬
ଵ ; ܱ௫௬൯indicates the reduction in uncertainty
of the connection between nodes x and y due to the
information given by their common neighbors.
If the elements of Oxy are assumed to be independent of
each other, then
ܫ൫ܮ௫௬
ଵ ; ܱ௫௬൯ = ෌ܫ൫ܮ௫௬
ଵ ;ݖ൯
௭∈ைೣ೤

ܫ൫ܮ௫௬
ଵ ;ݖ൯ =
ଵ
|௰(௭)|(|௰(௭)|ିଵ) ෌ܫ(ܮ௠௡
ଵ
;ݖ)௠,௡∈௰(௭)

ܫ(ܮ௠௡
ଵ
;ݖ)=ܫ(ܮ௠௡
ଵ
) −ܫ(ܮ௠௡
ଵ
|ݖ)

Hereܫ൫ܮ௫௬
ଵ ;ݖ൯ is
defined
as
the
average
mutual
information over all node pairs connected to node z.
ܫ(ܮ௠௡
ଵ
|ݖ) is the conditional self-information of that node pair
(m,n) is connected when node z is one of their common
neighbors, andܫ(ܮ௠௡
ଵ
) denotes the self-information of that
node pair (m,n) has one link.
B. A Modified Model
Since the computation of the Mutual Information of pair
nodes costs much time, we want to simplify it. In formula
(2),
it
is
easy
to
relate
the
sum
of
possibility
݌(ݔ,ݕ)݈݋݃
௣(௫|௬)
௣(௫) to the expectation of
݈݋݃
௣(௫|௬)
௣(௫) , so we
change the formula (2) into (8)
ܫ(ܺ;ܻ)=∑∑݌(ݔ,ݕ)
௬∈௒
݈݋݃
௣(௫,௬)
௣(௫)௣(௬)
௫∈௑
= ∑
௫,௬ ݌(ݔ,ݕ)
݈݋݃
௣(௫|௬)
௣(௫)
=ܧ௫,௬←௣(௫,௬) ቂ݈݋݃
௣(௫|௬)
௣(௫) ቃ
We can sample the network nodes, and calculate the
݈݋݃
௣(௫|௬)
௣(௫) of them. When the sample is big enough,The
expectation in formula (8) is close to the realܫ(ܺ;ܻ).
IV.
CONCLUSION
By modifying the model, we repair the big bug in the
traditional Baysian method in network link prediction. The
method is simple and fast. It approximates the real value
with simulation results, and saves a lot of computing time.
REFERENCES
[1]
F. Tan, Y. Xia, and B. Zhu, “Link Prediction in Complex
Networks: A Mutual Information Perspective” Plos One,
2014, 9(9):e107056.
[2]
Z. Boyao, X. Yongxiang, and S. N. Irene , “Link Prediction in
Weighted Networks: A Weighted Mutual Information Model”
PLOS ONE, 2016, 11(2):e0148265-.
[3]
H. Shakibian and N.M. Charkari. “Mutual information model
for link prediction in heterogeneous complex networks”
Scientific Reports, 2017, 7:44981.
[4]
A.V.D. Oord, Y. Li, and O. Vinyals, “Representation
Learning with Contrastive Predictive Coding”, 2018.
[5]
L. Lü et al. “Toward link predictability of complex networks”,
Proceedings of the National Academy of Sciences, 2015,
112(8):2325-2330
2
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-698-9
PESARO 2019 : The Ninth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

