Machine Learning-Based Object Detection System Using PIR Sensor
Dong Hyun Kim, Jung Bin Park, and Jong Deok Kim* 
Department of Computer Science and Engineering 
Pusan National University 
Pusan, South Korea 
e-mail: {dhkim1106, jbpark, kimjd}@pusan.ac.kr 
 
 
Summary—An intrusion prevention system using a 
digital Pyroelectric Infra-Red (PIR) sensor produces an 
error with an object, not a human. To solve this error, this 
research suggests an analog PIR sensor and an object 
detection system using machine learning. The analog PIR 
sensor provides an output based on various voltage scales 
within a certain area rather than producing binary outputs 
using a threshold value. From samples of an analog signal 
attained by using an analog PIR sensor, a Fast Fourier 
Transform (FFT) processed frequency is produced and 
used as a feature vector of the Artificial Convolutional 
Neural Network (CNN). The artificial CNN then studies 
the signal patterns of human motion and animal motion 
and detects whether it is a human or animal that intruded.  
 
Keywords—machine learning; object detection system; 
PIR sensor 
I. INTRODUCTION 
A Pyroelectric Infra-Red (PIR) sensor uses the 
pyroelectric effect of electromotive forces that occur when 
it absorbs infrared rays and polarization changes result in 
electronic charges abandoned. The PIR sensor then 
detects an object that has a temperature differential with 
surrounding environments and produces signals. Using 
these signals, the sensor can detect human or animal 
motion [1].  
In security systems, there are a number of ray detection 
machines developed that prevent intrusion and give an 
alarm using a PIR based motion sensor [1][2]. However, 
the PIR based motion detection sensor that works with a 
temperature differential between objects and surrounding 
environments is highly sensitive when the object moves 
closer to the sensor; hence, it is radically less sensitive 
when the object is close enough to warm up the 
surrounding environment, which presents a problem [3]. 
Therefore, during the summer, when the ambient 
temperature is closer to the temperature of the human 
body, the sensor will experience more problems than 
would occur in the winter. In addition, even if a human 
body is moving slowly or has a cover to block the heat, 
the sensor has a propensity to decrease in sensitivity. For 
example, if a person is holding an umbrella or wearing a 
raincoat, his or her umbrella or raincoat blocks the heat 
generated by their body, and the PIR sensor has difficulty 
detecting motion. Sunlight has various rays that the PIR 
sensor can detect and which have motion; therefore, the 
sensor will have problems if the sunlight touches it. 
The existing intrusion prevention system detects 
motions based on the threshold values of the PIR sensors. 
If the digital logic values go above the fixed threshold 
value, they produce a HIGH, which is considered an 
intrusion; otherwise they produce a LOW, which is not 
considered an intrusion. The threshold values vary by 
objects and situations; therefore, they can only identify 
whether there is an object [3]. 
This research suggests a new form of PIR sensor and 
machine learning based object detection algorithm to 
identify a human and an object. First, the paper describes 
the extraction of a range of signals attained from PIR 
sensors and the technique by which PIR data are 
processed into signals and frequency components of the 
signals are extracted into feature vectors. This research is 
still underway; therefore, this paper only covers the 
learning method through an Artificial Convolutional 
Neural Network (CNN) that is a machine learning 
algorithm and the design of a classification method after 
the learning.  
II. GATHERING SENSOR AND CNN LAYERS 
In this section, we describe the signal acquisition 
process using PIR and the operation process of CNN. 
A. Gathering sensor data  
To collect infrared lights in pyroelectric devices, a 
Fresnel lens was used. The advantage of using a Fresnel 
lens is that owing to its extremely thin construction it 
behaves exactly like a convex lens.  
 
Figure 1. Concept of recognizing an object using PIR sensor and Fresnel 
lens[5] 
11
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-658-3
ACCSE 2018 : The Third International Conference on Advances in Computation, Communications and Services

The infrared lights detection area is separated into two 
parts, as seen in Figure 1, which are the detection area and 
non-detection area. The detection area describes a 
distance wherein a human can be detected, while the non-
detection area describes a distance wherein a human 
cannot be detected; however, the movement of an object 
smaller than a human, which has a heat source higher in 
temperature than that of a human’s body temperature, can 
be detected. Generally, the detection distance of an 
infrared detection sensor means the distance to the 
detection area [4]. However, when the infrared detection 
system is being installed, the non-detection area should be 
considered. 
B. Convolutional Neural Network (CNN)  
A Convolutional Neural Network (CNN) that was 
firstly proposed by Yann Lecun in 1998 is an artificial 
neural network modeling the training process for 
recognizing cursive writing [6]. CNN has contributed to 
simplifying the complex calculation structure of existing 
Multi-Layer Perceptron (MLP) by adding a convolutional 
layer.  Henceforth, the CNN has been studied in many 
researches by proving its high performance for studying 
image [7]. 
1) Convolutional Layer 
The big difference between MLP and CNN is the 
convolutional layer. For the existing MLP, every neuron is 
connected to those of next layer when every layer is 
transferred to the next one. For example, assume that we 
perform training having an image as inputs.  When the size 
of input image is 32x32x3 (32 wide, 32 high, 3 color 
channels), the number of neuron of first input layer 
becomes 3,072 by 32x32x3 = 3,072.  The number of 
neuron of second hidden layer is 120,000 by 200x200x3 = 
120,000. If every neuron of input and hidden layer is 
connected then the total becomes 368,640,000 by 
3,072x120,000 = 368,640,000. Accordingly, every layer 
has a quite complex structure, which requires huge amount 
of calculation. In other words, investigating every pixel 
when recognizing image is not possible and even a waste 
of time. Recognizing an image requires a method of 
extracting features of various pixels. The convolutional 
layer is used in this method. The calculation of 
convolutional layer is shown in Figure 2.  
2) Pooling Layer 
A pooling layer takes the role of reducing width, height 
and size, which in turn reduces the amount of calculation 
of neural network and the number of parameter and 
controls the overfitting. 
The left side of Figure 3 shows the result volume of 
pooling layer. It shows that 224*224*64 size volume 
decreased to 112*112*64 volume. The right side of Figure 
shows the example of Max Pooling process that results in 
the maximum value in every area. If the result value has 
the average value of filters, then it is called an average 
pooling.  
3) Fully Connected Layer 
A fully connected layer has the same structure of MLP 
that was previously explained. Every neurons of each layer 
is connected and the results go through the activation 
function; therefore it has the same structure with the one of 
MLP. 
 
Figure 2. Calculation process of convolutional layer 
 
Figure 3. Example of Pooling Layer 
4) ReLU Function 
and 
have been 
widely used after passing through the neural network. 
However, looking at the function from the calculation of 
training process using gradient descent, the training 
process is quite slow because of nonlinear aspect. 
Therefore, 
to 
improve 
the 
calculating 
speed, 
is used. Rectified Linear Units (ReLU) 
has much faster calculating speed than hyper tangent or 
sigmoid function which were referred when training Deep 
Convolutional Neural Networks (DCNN).  
III. SUGGESTED PIR SENSOR-BASED HUMAN AND OBJECT 
DETECTION SYSTEM 
In this section, we propose a PIR sensor based human 
and object detection system. 
Sensor Part
Fresnel
Lens
PIR
Sensor
Circuit Part
Negative Feedback
Signal Conditioning Circuit
ADC
Circuit Part
Frequency Domain 
Preprocessing
Micro Computing
Board
Neural 
Network
Figure 4. Construction of PIR sensor-based human and object detection 
system 
Figure 4 is used to represent the entire data processing 
part. The overall data processing structure is divided into 
a sensor part, circuit part, and processor part. The sensor 
part has a role in extracting signals from an external 
stimulus. The circuit part amplifies and transforms the 
signals that came from the sensor part up to the dynamic 
12
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-658-3
ACCSE 2018 : The Third International Conference on Advances in Computation, Communications and Services

range. Additionally, it transforms the analog signals into 
digital signals so that they can be processed in the 
processor part. The processing part transforms the signals 
of the digital time area that came from the circuit part into 
signals of the frequency area so that they can be easily 
classified into machine learning class. The signals 
transformed into the frequency area go through the 
artificial CNN and are classified by models that study 
newly given inputs.  
x 3
Input
Conv
BN
Max Pool
Dense
Dense
SoftMax
 
Figure 5. CNN based human and object detection algorithm 
 
This research uses a five-layered structure that consists 
of input and output layers and three CONV LAYERs, 
while each input layer uses its own feature information. 
The output layers consist of two nodes that are the criteria 
for distinguishing between a human and a pet. Figure 5 
describes the structure of the artificial CNN that was used.  
IV. IMPLEMENTATION 
 
 
Figure 6. Object detection part of the realized PIR sensor-based human 
and object detection system  
 
The circuit part of the suggested system amplifies the 
signal by 69 dB through a non-inverting two-stage 
amplifier. This filtered the low and high frequency noise 
that could have led to incorrect detection. Thus, the direct 
current components were removed. After confirming that 
the input signals in the analog-to-digital converter (ADC) 
were ranging from 0 to 3020, the reference voltage was 
set to 0.37 times the maximum voltage.  
An LHI-878 was used as a PIR sensor in the sensor part 
and a PD23-6020 was used for the Fresnel lens. A 
Raspberry Pi 3 Model B was used in the processor part. 
To check object detection, a Raspberry Pi NoIR Camera 
V3 module was connected to the process. Figure 6 shows 
the actual equipment of proposed system.  
The software development tool of machine learning 
used keras library-based deep learning studio, CPU used 
Intel®Core(i)i5-6600 and GPU used Geforce GTX 1050 
Ti. 
V. EXPERIMENTS AND EVALUATION  
We had conducted experiments based on several 
factors that affect the amount of ambient infrared that PIR 
sensor detects.  
In Figure 7, the t represents the number of samples and 
the sample rate is equal to 14.5 ksps; f(t) describes values 
ranging from 0 to 5 v in quantization rate of 3020. Data 
from the PIR sensor were collected when a human was at 
a distance of 1 m, 2 m, and 5 m and in different positions. 
Additionally, data were collected when a dog at a distance 
of 2 m was in motion. These data were Fast Fourier 
Transform (FFT) processed to detect whether the object 
was human or animal using an artificial CNN. 
 
Figure 7. Distribution of PIR sensor values depending on distance of 
human and animal  
13
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-658-3
ACCSE 2018 : The Third International Conference on Advances in Computation, Communications and Services

TABLE I.  
TRAINING, VALIDATION, TEST DATA 
CONDITION 
 
Group 
Human 
Nothing 
Training 
A group 
9,000 
9,000 
Validation 
3,000 
3,000 
Test 
B group 
3,000 
3,000 
Total 
- 
15,000 
15,000 
 
By using the developed Object Detection System, data 
were collected by distinguishing between when there 
being a person and when there being none. The 
acquisition cycle was 1 second and was labeled with 1000 
data per second. Table 1 shows the dataset configuration. 
 
 
Figure 8. Accuracy and loss rate distribution toward each step 
 
The accuracy and the loss rate were identified by 
distinguishing between when there being a person and 
when there being none toward the training, validation and 
test. 
Training accuracy was 97.62%, validation accuracy 
was 80.5% and test accuracy was 72.8%. Figure 8 shows 
the accuracy and loss rate distribution toward the training, 
validation and test. 
VI. CONCLUSION 
This study designed a PIR signal process and CNN 
based learning algorithm using analog signals to improve 
a PIR sensor-based intrusion detection system. The signal 
processing 
algorithm 
was 
realized 
and 
used 
in 
experiments to distinguish between a human and an object 
in various situations.  
In the future, this research will transform signals of a 
certain time range into a frequency range to express a 
certain frequency component of a human or an object as 
data. Thereafter, using this data as a parameter of the 
machine learning algorithm, the accuracy of an object 
detection system using a PIR sensor will be improved.  
ACKNOWLEDGMENT 
"This work was supported by the National Research 
Foundation of Korea (NRF) grant funded by the Korea 
government (MSIP) (No. 2016R1A2B4013150 )."  
* : Corresponding Author 
 
REFERENCES 
[1] P. Shpter, “Passive infrared motion detector and method”, US 
Patent 6, 215,399, November 1997 
[2] S. Soliman and M. Srinath, “Continuous and Discrete Signals and 
System”, Prentice Hall, 1998. 
[3] P. Shpter, “Infrared motion detection signal sampler”, US Patent 6, 
111,256, April 1997 
[4] J. H. Park, H. G. Yeom, B. G. Jung, I. H. Jang and K. B. Sim, 
“Soundsource Localization and Tracking System of Intruder for 
Intelligent Surveillance System”, Journal of Korean Institute of 
Intelligent Systems, Vol.17, No.6, pp.786-791, December 2007. 
[5] F. Nelli, “PIR motion detector - a sensor for Arduino and 
Raspberry 
Pi”, 
http://www.meccanismocomplesso.org/en/pir-
motion-detector/, February 2016. 
[6] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, “Gradient-based 
learning applied to document recognition”, Proceedings of the 
IEEE, Vol. 86, No. 11, pp. 2278-2324, November 1998. 
[7] V. Nair and G. E. Hinton. Rectified linear units improve restricted 
boltzmann machines. In Proc. 27th International Conference on 
Machine Learning, 2010. 
 
14
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-658-3
ACCSE 2018 : The Third International Conference on Advances in Computation, Communications and Services

