Real-Time Packet Loss Probability Estimates from
IP Trafﬁc Parameters
Ahmad Vakili
Institut national de la recherche scientiﬁque
(INRS-EMT)
Montreal, Canada
vakili@emt.inrs.ca
Jean-Charles Gr´egoire
Institut national de la recherche scientiﬁque
(INRS-EMT)
Montreal, Canada
gregoire@emt.inrs.ca
Abstract—For network service providers, assessing and moni-
toring network parameters according to a Service Level Agree-
ment and optimal usage of resources is important. Packet loss
is one of the main factors to be monitored, especially when
IP networks carry multimedia applications. Measuring network
parameters is more valuable when it is accurate and online. In
this paper, we propose an accurate approximation for packet loss
probability at an intermediate high speed node with ﬁnite buffer,
where a large number of sources are expected to be aggregated.
In this method, based on Large Deviation Theory, estimation of
packet loss probability at the intermediate nodes is based on the
input stochastic trafﬁc process. In accordance with Central Limit
Theorem arguments, the input process is modelled as a general
Gaussian process. Different trafﬁc situations and node buffer
sizes are simulated (with NS-2 software) and the effectiveness of
the method is examined via a detailed numerical investigation.
The simulation results show that our proposed method signiﬁ-
cantly improves the quality of packet loss probability estimate
compared to other recently introduced estimators.
Keywords—Packet loss probability, estimation, stochastic trafﬁc
process.
I. INTRODUCTION
In telecommunications, performance is assessed in terms of
quality of service (QoS). QoS, in turn, is measured either in
terms of technology (e.g., for ATM, cell loss, variation, etc.)
or at some protocol level (e.g., packet loss, delay, jitter, etc.)
[1]–[3].
Today, increased access to Internet networks as well as
broadband networks have made possible and affordable the
deployment of multimedia applications such as Internet tele-
phony, video conferencing, and IP television (IPTV) by
academia, industry, and residential communities. Therefore the
quality assessment of media communication systems and the
parameters, which affect this quality have been an important
ﬁeld of study for both academia and industry for decades. Due
to the interactive or online nature of media communications
and the existence of applicable solutions to deduce the effect
of delay and jitter (e.g., deployment of a jitter buffer at the
end user node [4][5]), data loss is a key issue, which must be
considered. If there is a possibility for online accurate mea-
surement of packet loss, then the network service providers can
take the appropriate action to satisfy the contractual Service
Level Agreement (SLA) or to improve and troubleshoot their
service without receiving end user feedback.
Packet loss often happens because of congestion. In other
words, buffer overﬂow at the outgoing interface in intermediate
network nodes causes packet loss. Since measuring packet loss
ratio at the intermediate nodes in high speed networks does not
seem applicable in real time, some recent research has focused
on estimation of packet loss probability (plp) [1][6]–[9].
According to central limit theory, the aggregated input trafﬁc
at intermediate nodes in the network core can be described
with a Gaussian model [10][11]. Based on the Large Deviation
Theory (LDT) and the large buffer asymptote approach, the
plp can be estimated by a stochastic process considering
the probability of buffer overﬂow in a ﬁnite buffer system
where b is the buffer size (or tail probability P{Q > b} in a
inﬁnite buffer system). Since the input trafﬁc is described by
a Gaussian process, the latter can be identiﬁed by an online
measure of the mean and variance of the input trafﬁc.
In this paper, we propose a tighter approximation of plp
based on the input trafﬁc process and the information, which
was measured in the past. In other words, we use some online
measures and historical data for accurate estimation and thus
improve on earlier proposed estimates. Our plp estimation
method can also compose with systems whose buffer size is
not large enough to meet the assumptions of the large buffer
asymptote approach.
Furthermore, this estimate can integrate well with a quality
control architecture. Using the online estimated plp as feed-
back information, a control system could properly throttle the
ingress trafﬁc rate and keep the plp below some target upper
bound value of packet loss in an SLA. An overall architecture
of measurement, estimation, and control loop to keep the
quality of service/experience within the SLA bounds is shown
in Fig. 1. In this ﬁgure, the estimated plp is used as an online
transducer in a control loop of packet loss.
The paper continues in Section II by reviewing prior bodies
of work on measuring or estimating the packet loss proba-
bility. Section III provides some useful deﬁnitions, which are
employed in this paper. In Section IV, we develop a new plp
estimator. Section V presents the testbed and the simulations
used to assess the quality of our estimator. Numerical results
and comparison that demonstrate the effectiveness of our
proposed estimator are presented in Section VI. Section VII
concludes the paper and points to our future work.
34
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Fig. 1.
Measurement, estimation, and control loop schematic.
II. PREVIOUS WORK
In our observations, earlier research on measuring and
modelling the packet loss would generally either increase the
burden of probe packets’ bit rate to the available bandwidth
[6][12][13] or not provide real time information [14]–[16].
For example, [14] and [15] have characterized loss traces by
identifying mathematical models. Yin Zhang et al. in [17] and
[18] have analyzed the stationarity of the loss process on the
Internet paths and studied its predictability. Although these
studies are undoubtedly useful to understand the general loss
characteristics, they cannot be used in real time performance
estimation and consequently online control systems.
To obtain real time network performance information such
as available bandwidth, delay, and loss, various probing tech-
niques have been recently used by researchers. For instance,
[15], [19], and [20] have employed packet pair and packet train
techniques, respectively, to measure bottleneck bandwidth. He
et al. in [21] have used probing method to explore end-to-
end trafﬁc by exploiting the long range dependence nature of
Internet trafﬁc. The authors of [12] and [13] have measured the
loss rate on individual links by end-to-end multicast/unicast
probes and different inference techniques. Further, Tao and
Gu´erin in [6] have used a probing method to construct a
Hidden Markov Model (HMM) [22] to capture the main
characteristics of loss process such as loss length distribution,
loss distance, etc. The disadvantage of these methods is to
increase the burden of probe packets’ bit rate to the available
bandwidth when better accuracy is required.
To cope with the shortcomings of the aforementioned meth-
ods, many researchers have tried to link the input process to the
loss probability at intermediate nodes. Behavior of the FIFO
scheduler fed by many on-off sources was investigated by An-
ick et al. in [23]. Elvalid et al. and Stern et al. in [24] and [25],
respectively, extended Anick’s work by presenting a simple
approximation of the loss for a very large buffer size system
whose input can be modelled with Markov Modulated Rate
Processes (MMRP). Their mathematical models are derived
from large deviation theory (LDT).
Studies, which estimate loss probability based on input
trafﬁc process generally fall into one of the following method-
ological categories given their underlying assumptions:
• Large buffer asymptote: In this approach, the intermediate
node’s buffer size is assumed to be large. The value of
overﬂow and consequently loss attained in the case of
small buffer size is extrapolated using the large buffer
asymptote. Chang in [26] and the references therein
review this topic comprehensively. Zhang and Ionescu in
[8][9][27][28] have extended this research to estimate the
loss probability.
• Large number of sources asymptotic: This method is
based on the homogeneity of n identical sources that
feed the intermediate node’s input buffer. Likhanov and
Mazumdar in [29] used this methodology to estimate the
loss probability.
• Aggregate trafﬁc approximation: This approach is used
to reduce the computational complexity of input trafﬁc
model estimation. It is employed when an intermediate
high-speed node’s input trafﬁc consists of a large number
of individual user trafﬁc ﬂows with unique characteristics,
in which case the large number of sources asymptotic
method is not applicable [30]. The main justiﬁcation for
a packet loss probability estimation based on aggregate
trafﬁc approximation is the Bahadur-Rao Theorem, which
computes the asymptotic tail distribution of the sum of
n identically non-lattice random variables when n → ∞
[31].
In this paper, we use large buffer asymptote approach for
online packet loss estimation. Our work revisits Zhang and
Ionescu’s research [8][9][27][28] (i.e., recent work on this
topic); we will review their method and explain how we
overcome its shortcomings at the end of Section IV.
III. DEFINITIONS
The input trafﬁc model and packet loss probability are
explained in this section. All the deﬁnitions are related to a
high speed intermediate node in which the received packets
are served with First In First Out (FIFO) scheduling.
A. Input trafﬁc model
According to the Central Limit Theorem (CLT), the aggre-
gated trafﬁc at an intermediate link in a high-speed network
can be well approximated by a Gaussian process [32][33][34].
Moreover, characterizing the input process of a large num-
ber of sources with the traditional Markovian models seems
infeasible. Therefore, in our study the input process λn is
characterized by a Gaussian process and presented by
λ(t) = µt + σZ(t),
(1)
where µ and σ2 are the mean and variance of arrival rate (i.e.,
λ(t)), respectively. Z(t) is a centered Gaussian process when
V ar{Z(t)} = 1 [35].
35
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

B. Packet loss probability
The packet loss probability, Ploss, is deﬁned as the long
term ratio of the number of lost packets to the number of
input packets. It is expressed by the following formula:
Ploss = lim
N→∞
PN
k=1(qk−1 + λk − c − b)+
PN
k=1 λk
= E[lk]
E[λk],
(2)
where (x)+ denotes max{x, 0}, b is buffer size, c is output
link capacity, and qk and l denote the number of packets that
occupy the buffer in the time interval [k, k+1) and the number
of lost packets, respectively. E[x] is the expected value of
variable x.
The packet loss ratio, plr(k), is deﬁned as the short term
ratio of the amount of packets lost to the amount of input
packet. It is expressed by the following formula:
plr(k) = l(k)
λ(k),
(3)
where l(k) is the number of lost packets during the time slot
[k, k+1) and λ(k) is the number of packets that arrive during
the time slot [k, k + 1).
Kim and Shroff in [32] showed that the plp in a buffer
of size x can be well approximately mapped from the tail
probability in the inﬁnite buffer system. Tail probability also
called the overﬂow probability P{Q > x} is expressed as
P{Q > x} = lim
N→∞
1
N
N
X
k=1
I(Qk > x),
(4)
where I(A) is an identiﬁcation function, which is equal to 1
if A is true and equal to 0 otherwise, and Q is the dynamic
queue size. Although P{Q > x} is averaged by time and plp
is averaged by the input, [32] shows the following relationship
between P{Q > x} and plp:
Ploss(x) = αP{Q > x},
(5)
where α is constant and equal to Ploss(0)/P{Q > 0} and
Ploss(0) denotes the packet loss probability in a bufferless
system.
C. Effective bandwidth
The effective bandwidth of arrival trafﬁc process A(t) is
deﬁned as
ω(θ, t) = 1
θtlnE[eθA(t)]
0 < θ, t < ∞,
(6)
where θ and t are system parameters determined by the
channel capacity and buffer size, the QoS requirement, and
the characteristics of the multiplexed sources [36]. Based on
G¨artner-Ellis theorem [37][38], ω(θ, ∞) exists when the input
trafﬁc is Gaussian. So,
ω(θ∗, ∞) = lim
t→∞
1
θ∗tlnE[eθ∗A(t)] = c,
(7)
where c is link capacity. Glynn and Whitt in [39][40] have
proved that overﬂow probability can be related to θ∗, which
is calculated from (7) as following
lim
x→∞
1
xlnP{Q > x} = −θ∗.
(8)
IV. PACKET LOSS PROBABILITY ESTIMATOR
There are several approaches to estimate packet loss proba-
bility. Sending probe packets periodically through the path and
processing the returned signals for predicting the performance
of path (e.g., packet loss ratio, delay, etc.) is one of the recent
methods for estimating the plp [6][41]. The disadvantage of
this method is to increase the burden of probe packets’ bit rate
to the available bandwidth when greater accuracy is requested.
Estimation of plp based on stochastic input trafﬁc process is
another approach in this ﬁeld [8][9][42]. In this method some
important assumptions are made as follows: 1) Measurement
and estimation take place at intermediate nodes in high-speed
network core links, therefore the input trafﬁc is a mix of a large
number of individual trafﬁcs and thus the Gaussian process
model is considered to represent the stochastic input trafﬁc
process [10][11]; and 2) the size of the buffer should be large,
otherwise the queue process is not exponential and the be-
haviour of the trafﬁc in small buffers cannot be approximated
by a logarithmically linear behavior [43][44][26], so the input
trafﬁc process cannot estimate plp.
Following the Gaussian model assumption for the input
trafﬁc, the effective bandwidth in this model [36] is given by:
ω(θ, t) = µ + θ
2σ2t(2H−1)V arZ(t),
(9)
where θ is the space parameter, t is the time parameter,
which corresponds to the most probable duration of the buffer
congestion period prior to overﬂow, µ is deﬁned as the trafﬁc
mean, Var represents the second moment of Z(t), which is
equal to 1 (see (1)), σ2 is the variance of the input trafﬁc
random variable, and H is the Hurst parameter.
The Hurst parameter H shows the degree of self-similarity
in the trafﬁc. H = 0.5 corresponds to a well behaved Gaussian
trafﬁc while any value larger than 0.5 indicates a self-similar
trafﬁc source. Based on the classical assumption for input
trafﬁc [42][45], the H parameter is set to 0.5. So the effective
bandwidth is ﬁnite, independent of time, and can be simpliﬁed
into:
ω(θ, t) = µ + θ
2σ2.
(10)
Further, if µ and σ exist, effective bandwidth, in case of
t → ∞, is equal to link capacity (see (7)). Therefore,
ω(θ∗, ∞) = µ + θ∗
2 σ2 = c.
(11)
Based on our second assumption of large buffer asymptotic
approach for packet loss estimation, the overﬂow probability
for the large buffer size can be approximated by a logarithmi-
cally behavior as follow [39][40]:
∃κ ∈ R+, P{Q > x} = κe−θ∗x,
(12)
36
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

where θ∗ is the solution of (11). Note that such an approxi-
mation in (12) is more precise when the buffer size x is large
[26]. Therefore, P{Q = x} can be deﬁned by
P{Q = x} = κ(eθ∗ − 1)e−θ∗x.
(13)
To estimate the packet loss probability, E[lk] of (2) is
deﬁned as follows (recall that b is buffer size):
E[lk] =
Z ∞
b
(x − b)P{Q = x} dx.
(14)
From (13) and (14), we have
E[lk] = κ(eθ∗ − 1)e−θ∗b
θ∗2 ,
(15)
where θ∗ calculated from (11) is
θ∗ = 2c − µ
σ2 .
(16)
Solving (11) in θ∗ and replacing in (15) deﬁne Ploss by the
following equation:
Ploss = E[lk]
E[λk] = κ(e2 (c−µ)
σ2
− 1)e−2b (c−µ)
σ2
4µ (c−µ)2
σ4
.
(17)
Applying the natural logarithm (ln) to (17), we derive the
following estimator:
ln(Ploss) = ln(e2 (c−µ)
σ2
− 1) − 2b(c − µ)
σ2
−ln

4µ(c − µ)2
σ4

+ ln(κ).
(18)
In line with other similar studies [8][9], we change the base
of the logarithm function from e to 10. Thus, (18) can be
replaced by:
log(Ploss) = log(e2 (c−µ)
σ2
− 1) − 2bc − µ
σ2 log(e)
−log

4µ(c − µ)2
σ4

+ log(κ).
(19)
Replacing µ and σ with their measurement value ¯µ(k) and
¯σ(k) changes (19) into the following equation:
log(Ploss) = log(e
2 (c−¯
µ(k))
¯σ2(k)
− 1) − 2bc − ¯µ(k)
¯σ2(k) log(e)
−log

4¯µ(k)(c − ¯µ(k))2
¯σ4(k)

+ κ′,
(20)
where κ′ = log(κ) and ¯µ(k) and ¯σ(k) are deﬁned as:
¯µ(k) = 1
N
N−1
X
i=0
¯λ(k − i),
(21)
and
¯σ2(k) =
1
N − 1
N−1
X
i=0
¯λ(k − i) − ¯µ(k)
2 ,
(22)
where ¯λ(k) is the measured input packet rate in the kth time
interval and N is the number of time intervals for calculating
the average of the mean and variance of the packet rate.
In the rest of the paper let epl(k) denote the log(Ploss),
which is estimated by
epl(k) = log(e
2 (c−¯
µ(k))
¯σ2(k)
− 1) − 2bc − ¯µ(k)
¯σ2(k) log(e)
−log

4¯µ(k)(c − ¯µ(k))2
¯σ4(k)

,
(23)
and let plp(k) denote the logarithm of real packet loss proba-
bility during the time slot [k, k + 1), which can be expressed
by:
plp(k) = log
 l(k)
λ(k)

,
(24)
where l(k) is the number of packets lost during the time slot
[k, k+1) and λ(k) is the number of packets that arrive during
the time slot [k, k + 1).
Some estimation errors are expected due to the assumption
made for the stochastic trafﬁc process and the simpliﬁcations
and approximations employed in (23) (e.g., κ′ is eliminated
from (20)). Numerical results in the next section show that
estimating the plp with (23) completely follows the variation
of plp, although there is an almost constant offset between the
real plp value and epl, which is best explained from ignoring
the constant κ′ in (20).
To eliminate this difference it is proposed to use the ofﬂine
measured plp and compare it with the estimated one to obtain
the offset. We therefore present an improved estimator, iep,
deﬁned as:
iep(k) = epl(k)
+ 1
n
n
X
l=1
[plp(k − l − m) − epl(k − l − m)] ,
(25)
where m is the number of interval periods after which the data
of plp is available and epl(k) and plp(k) are calculated via
(23) and (24), respectively.
With this improved estimator, the required time for mea-
suring and calculating the plp is represented by m in (25),
where the mean of errors between epl and plp during a
moving window (i.e., n time intervals) in the past (i.e., m
time intervals ago) is added to epl to estimate the new plp.
Note that the duration of the time interval is independent from
the measurement and calculation speed of plp. In other words,
the estimator depends on m, in (25), only for the duration of
the measuring time interval.
As we have mentioned in Section II, Zhang and Ionescu
[8][27][28] also have proposed a packet loss probability es-
timator based on LDT and buffer asymptote approach. Their
estimator describes packet loss probability by:
epl′ =log(Ploss)=−2bc − µ
σ2 log(e)−log

2µ(c − µ)
σ2

. (26)
To cope with their estimator’s error, they have introduced a
Reactive Estimator (re) [9], which is deﬁned as:
re(k) = epl′(k) + 1
n
n
X
l=1
[plp(k − l) − re(k − l)] ,
(27)
37
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

where epl′ is packet loss probability estimated by (26).
A careful examination of (27) reveals that the error re
attempts to correct will decrease to the amount of difference
between re and plp, whereas the error really is the difference
between epl′ and plp.
We thus claim that our proposed estimator, iep, does a
better job at tracking plp. To investigate the accuracy and
applicability of the aforementioned estimators and to compare
their performance with that of our estimator, we propose
to conduct simulations. In these simulations, the effects of
different conﬁgurations of network trafﬁc and packet loss ratio
on estimators’ performance are examined, and then will be
discussed in detail in Sections V and VI.
V. SIMULATION TESTBED
The NS-2 software [46] is used to simulate the network.
The network topology, which is simulated is shown in Fig. 2.
An MPEG2 trafﬁc ﬂow is generated by node 1 and the Real-
time Transport Protocol (RTP) is deployed for transferring
video data to node 4. Node 2 generates the voice trafﬁc
ﬂow, which is coded by G.729 [47]. This data is transferred
to node 5. Node 3 and node 6 are designed to generate
the common Internet trafﬁc ﬂow for background trafﬁc and
make the aggregated trafﬁc situation closer to the Gaussian
distributed trafﬁc for stochastic input trafﬁc process. The Tmix
module in NS-2 is utilized in node 3 and 6 in order to
generate realistic Internet network trafﬁc [48]. The protocol
deployed for communications between nodes 3 and 6 is TCP.
Since the background trafﬁc is TCP-based, congestion (i.e.,
buffer overﬂow and loss) affects trafﬁc ﬂows, which leads to
a situation similar to that of a real Internet network trafﬁc.
Nodes 7 and 8 generate the on-off trafﬁc to randomly increase
the probability of packet loss. Measurement of the input and
output trafﬁcs is performed at node 9. Since the focus is on
node 9, the bandwidth of all links except link A is set to
100 Mbps and the buffer size of all nodes except node 9 is
set to 500 packets. We vary the size of the node 9 buffer
from 5 packets to 100 packets to examine different router
conﬁgurations. To generate different amounts of packet loss,
the bandwidth of link A varies between 7.4 Mbps and 7.8
Mbps. With these settings loss takes place only in node 9.
When the bandwidth of link A is set to 7.8 Mbps and nodes 7
and 8 do not generate any trafﬁc, the packet loss probability is
about 0.1 percent and when the bandwidth is decreased to 7.4
Mbps, the packet loss probability in node 9 increases to about
1 percent, which is closer to the amount where effect of loss on
media communication quality becomes annoyingly noticeable.
By turning on the trafﬁc of nodes 7 and 8 at some short
periods of time, the packet loss probability reaches 7 percent,
which is an unacceptable amount of packet loss for media
communications. In the next section the numerical values of
the different estimators in these situations will be examined.
VI. NUMERICAL RESULTS ANALYSIS
This section presents the experimental results of the eval-
uation of the performance of the proposed estimator for the
different types of trafﬁc generated in the simulation testbed.
The accuracy of the loss probability predicted by our proposed
estimator is compared to that of a couple of other recent
estimators.
A. Input trafﬁc
The crucial assumption in estimating loss probability based
on input trafﬁc process is the Gaussian behavior of the aggre-
gated input trafﬁc. Therefore, the veriﬁcation of this statement
(i.e., the aggregated input trafﬁc process is a Gaussian process)
is the ﬁrst test, which should be performed. So, the received
times of all packets for aggregated trafﬁc are measured,
while node 1 generates MPEG2 trafﬁc ﬂow, a voice trafﬁc
is generated by node 2, and node 3 sends an approximate
common Internet trafﬁc mix through the core of testbed.
In this paper the graphical technique is used for normality
testing, although, the Chi-Square test [49] could also be used to
verify the assumption of Gaussian behavior of input trafﬁc in
our simulations. Fig. 3, which shows the instantaneous input
trafﬁc bit rate and the distribution of input trafﬁc visually,
veriﬁes that in our simulations the aggregated trafﬁc in core
link can be approximated by Gaussian trafﬁc and consequently,
the main assumption of proposed estimator is met.
B. Individual ﬂow loss
To satisfy the SLA and to take the appropriate action on
each ﬂow’s source, a control system needs to be aware of
the packet loss probability of each ﬂow. However, only the
aggregated trafﬁc loss probability can be estimated by the
proposed estimator.
The simulation results show that the loss ratio of each ﬂow
(e.g., MPEG2 ﬂow) is very close to loss ratio of the aggregated
trafﬁc. Therefore, it can be concluded that the estimated loss
probability of aggregated trafﬁc can be used as the individual
probability of packet loss. Fig. 4 veriﬁes this statement by
showing that the measured MPEG2 ﬂow’s packet loss ratio is
very close to the packet loss ratio of aggregated trafﬁc in node
9.
Fig. 4.
Comparison of the MPEG2 loss ratio with the aggregated trafﬁc loss
ratio.
C. Estimator performance
First, to evaluate that if the epl from (23) follows the plp
variation with an almost constant offset, a situation has been
38
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Fig. 2.
Testbed topology.
(a) Instantaneous input trafﬁc bit rate.
(b) Histogram of input trafﬁc distribution.
Fig. 3.
Aggregated input trafﬁc characteristics in network core.
investigated in which the bandwidth of link A was 7.4 Mbps
and there was no trafﬁc coming from nodes 7 and 8. As shown
in Fig. 5, although there is an offset between plp and epl, epl
follows the variation of plp thoroughly and this can be seen
as a clear sign of soundness of the use of epl as the main part
of proposed estimator.
Fig. 5.
Comparison of plp (measured loss) and epl (estimated loss with
offset).
Next, all the mentioned estimators (i.e., epl′, re, and our
proposed estimator, iep) are evaluated and their performance
compared in different situations.
Fig. 6 shows the performance of the different estimators in
a situation where the bandwidth of link A is 7.8 Mbps and
there is no trafﬁc coming from nodes 7 and 8. The accuracy
of proposed estimator (iep) to estimate the plp compared to
the other estimators is demonstrated in this ﬁgure.
In all experiences the time interval is 100 ms. In Fig. 6 iep
is calculated according to (25) where m is 5. This means that
iep uses plp data measured up to 500 ms earlier.
Since the amount of loss in the former example might be
negligible for media communications, we change the network
conditions to increase the loss ratio and then re–evaluate the
accuracy of estimators. To achieve this situation, the buffer
size of node 9 is decreased to 10 packets. Fig. 7 shows the
results of this experience: during the time periods of [10, 15],
nodes 7 and 8 add network trafﬁc and bring the loss ratio
close to 7 percent (log(plp) = −1.5). As Fig. 7 shows, the
effect of simpliﬁcation and approximation in (26) and (27) on
the operation of epl′ and re methods is more apparent at this
larger loss ratio.
Tables I and II summarize the statistics for the different
estimators with varying loss ratio. In all comparisons the error
is deﬁned as the difference between estimated and measured
plp.
As mentioned before, the buffer size affects the plp and the
accuracy of estimators [43][44]. The larger the buffer size, the
lesser plp and the better the accuracy of the estimation. The
39
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Fig. 6.
Measurement and estimation of packet loss probability when plp is
about -2.5.
Fig. 7.
Measurement and estimation of packet loss probability when plp is
about -1.5.
effect of buffer size on estimation methods re and epl′ has
been examined in [8] and [27], respectively. The value of m,
in (25), also affects the accuracy of iep estimation.
To examine the accuracy of the proposed estimator in
different conﬁgurations (i.e., buffer size and m), we introduce
a new variable, error. Given that the errors of logarithmic
variables (plp’s) are not easily comparable, error is deﬁned
as follows to make it more sensible to small variations:
error = 10estimation − 10plp.
(28)
Fig. 8 shows the probability density function of error when
buffer size is 10, 30, and 100 packets, and m is 5, 10, and
20 (m = 10 means using a plp measured 1 s before), and
the effect of buffer size on estimation. Fig. 8-(a),(b), and (c)
show that our proposed estimator has better performance in the
case of a larger buffer. Note that a larger buffer size causes
more latency, which is not suitable particularly for multimedia
transmission; hence, it should be set carefully. However, in
our simulations, the buffer size of 100 packets causes only a
15 ms delay, which could be even lower in real high speed
intermediate networks.
It can be also shown by Fig. 8 that the ofﬂine measuring
speed affects the accuracy of our proposed estimator: the faster
the measurement, the more accurate the estimation.
Further considering the effect of buffer size on estimations
derived from (23), it appears that the accuracy of estimation
TABLE I
STATISTICS SYNOPSIS ON LOSS PROBABILITY ESTIMATION FOR
DIFFERENT ESTIMATORS WHEN plp IS ABOUT -2.5.
Estimator
Error∗ Mean
Error Variance
Error Min
Error Max
iep
0.16
0.77
0.016
2.24
epl′
2.47
0.60
0.88
4.22
re
1.27
0.70
0.25
2.98
Error∗ is equal to difference between estimations (iep, epl′, and re) and plp.
TABLE II
STATISTICS SYNOPSIS ON LOSS PROBABILITY ESTIMATION FOR
DIFFERENT ESTIMATORS WHEN plp IS ABOUT -1.5.
Estimator
Error Mean
Error Variance
Error Min
Error Max
iep
0.19
0.45
0.016
2.8
epl′
2.86
0.50
1.59
3.8
re
1.49
0.24
0.20
2.93
(iep) will improve if the role of the measured plp is increased.
Therefore, (25) is changed to:
iep(k) = p × epl(k)
+ 1
n
n
X
l=1
[plp(k − l − m) − p × epl(k − l − m)], (29)
where p is the proportional coefﬁcient and is less than 1.
To increase the importance of the second term in (29), n is
increased from 3, which is recommended in [9], to 10 and to
decrease the effect of ﬁrst part, p is set to 2
3. For a smaller
p, when a considerable variation happens to plp, the estimator
(iep) cannot follow the plp properly and the value of error
will be signiﬁcant.
Fig. 9 shows the value of error when buffer size is 10 and
(29) is used for estimation. Comparing Fig. 9 and Fig. 8(a),
the effectiveness of the changes in estimation is clear.
To conclude, the advantages of our proposed estimator are:
1) an increase in the accuracy of estimation by using the
measured parameters properly, 2) ﬂexibility on the duration of
measuring time interval, and 3) an estimate of plp reasonably
accurate in the case of a small buffer.
Fig. 9.
PDF of error for estimator, which uses (29) when buffer size is 10.
40
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

(a) PDF of error for different buffer size when m is 5.
(b) PDF of error for different buffer size when m is 10.
(c) PDF of error for different buffer size when m is 20.
(d) PDF of error for different estimators when buffer size is
100, m=5, and there is no random trafﬁc.
Fig. 8.
The comparison of PDF of error for different conditions.
VII. CONCLUSION
One of the most important issues in multimedia quality
of experience is packet loss, which has an especially critical
role in interactive communications. Accurate online network-
based measurements of loss are necessary to give service
providers the means to estimate the quality received by a
user and to give them an opportunity to take remedial actions
to satisfy the contractual SLA. Increased use of multimedia
communications in the Internet has led to a renewed interest
in the measure and estimation of loss, in the form of the
plp, in modern communication networks. More speciﬁcally,
recent studies have focused on estimation of the plp by
measurement of input trafﬁc based on LDT and the large buffer
asymptote. In this paper, we have reviewed the theory behind
the ﬁnite buffer overﬂow probability (tail probability in inﬁnite
buffer) estimation. Based on central limit theory, by modelling
the input trafﬁc of an intermediate high speed node as a
Gaussian process, we have introduced a new approximation
for plp. Combining this online approximation with the ofﬂine
output trafﬁc measurement, we have proposed an accurate
plp estimator, which signiﬁcantly improves the quality of
the estimate compared to the recent proposed plp estimators
[27][28], which have used similar theoretical basis.
To study the accuracy of the estimates, we have used the
NS-2 simulator with the input trafﬁc, which is very similar
to the Internet trafﬁc at the measurement node. Overall, the
simulation results demonstrate the effect of different conﬁgura-
tions, such as buffer size, on the estimates. The analysis of the
results shows the improvement of accuracy in plp estimation
achieved by our new calculation method.
For future research, we plan to investigate how it is possible
to estimate the end user’s perception, aka the Quality of
Perception (QoP), based on the effect of loss. Along this line of
research, we plan to study the methods of estimation of other
network parameters (e.g., delay and jitter) to utilize them as
the input of QoP measurement.
REFERENCES
[1] A. Vakili and J. C. Gr´egoire, “Estimation of packet loss probability
from trafﬁc parameters for multimedia over IP,” Proc. of the Seventh
International Conference on Networking and Services, ICNS 2011, pp.
44–48, May 2011.
[2] D. McDysan, QoS & trafﬁc management in IP & ATM networks,
McGraw-Hill, 2000.
[3] W. C. Hardy,
VoIP service quality: measuring and evaluation packet-
switched voice, McGraw-Hill, 2003.
[4] B. Oklander and M. Sidi, “Jitter buffer analysis,” Proc. of 17th IEEE
International Conference on Computer Communications and Networks,
pp. 1–6, August 2008.
[5] H. Hata, “Playout buffering algorithm using of random walk in VoIP,”
Proc. of IEEE International Symposium on Communications and Infor-
mation Technology, pp. 457–460, October 2004.
41
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[6] S. Tao and R. Guerin, “On-line estimation of internet path performance:
an application perspective,” Proc. of 23rd IEEE Conference on Computer
Communications, Vol. 3, pp. 1774–1785, March 2004.
[7] R. Serral-Gracia, A. Cabellos-Aparicio, and J. Domingo-Pascual, “Packet
loss estimation using distributed adaptive sampling,” Proc. of IEEE
Workshop on End-to-End Monitoring Techniques and Services, pp. 124–
131, April 2008.
[8] D. Zhang and D. Ionescu, “A new method for measuring packet loss
probability using a Kalman ﬁlter,” IEEE Transaction on Instrumentation
and Measurement, Vol. 58, No. 2, pp. 488–499, February 2009.
[9] D. Zhang and D. Ionescu, “Reactive estimation of packet loss probability
for IP-based video services,” IEEE Transaction on Broadcasting, Vol. 55,
No. 2, pp. 375–385, June 2009.
[10] R. van de Meent and M. Mandjes, “Evaluation of user-oriented and
black-box trafﬁc models for link provisioning,” Proc. of the 1st EuroNGI
Conference on Next Generation Internet Networks Trafﬁc, pp. 380–387,
April 2005.
[11] J. Kilpi and I. Norros, “Testing the Gaussian approximation of aggre-
gate trafﬁc,” Proc. of the 2nd ACM SIGCOMM Workshop on Internet
Measurement, pp. 49–61, November 2002.
[12] R. Caceres, N. G. Dufﬁeld, J. Horowitz, D. Towsley, and T. Bu,
“Multicast-based inference of network-internal characteristics: Accuracy
of packet loss estimation,” Proc. IEEE INFOCOM, New York, March
1999.
[13] N.G. Dufﬁeld, F. Lo Presti, V. Paxson, and D. Towsley, “Inferring
link loss using striped unicast probes,” Proc. of Twentieth Annual Joint
Conference of the IEEE Computer and Communications Societies, Vol.2,
pp. 915–923, 2001.
[14] M. Yajnikk. S. Moon. J. Kurose, and D. Towsley, “Measurement and
modeling of the temporal dependence in packet loss,” Proc. of IEEE
INFOCOM. New York, March 1999.
[15] V Paxon. “End-to-end Internet packet dynamics,” IEEE/ACM Transac-
tion on Networking. Vol. 7. No. 3, pp. 277–292. June 1999.
[16] J. Bolot, “End-to-end packet delay and loss behavior in the Internet,”
Proc. ACM SIGCOMM, San Francisco, CA, September 1993.
[17] Y. Zhang, V. Paxson, and S. Shenker, “The stationarity of Internet path
properties: routing, loss, and throughput,” ACIRI Technical Report, 2000
[18] Y. Zhang, N. Dufﬁeld, V. Paxan, and S. Shenker. “On the constancy of
Internet path properties,” Proc. of ACM SIGCOMM Internet Measure-
ment Workshop, San Francisco. CA. November 2001.
[19] V. Jacobson, “Pathchar: a tool to infer characteristics of Internet paths,”
Mathematical Sciences Research Institute MSRI Workshop, April 1997.
[20] M. Jain and C. Dovrolis, “End-to-end available bandwidth: measurement
methodology, dynamics, and relation with TCP throughput,” Proc. of
ACM SIGCOMM, pp. 295–308, 2002.
[21] G. He and J. C. Hou, “On exploiting long range dependence of network
trafﬁc in measuring cross trafﬁc on an end-to-end basis,” Proc. of IEEE
lNFOCOM, March, 2003.
[22] K. Salamatian and S. Vaton, “Hidden Markov modeling for network
communication channels,” ACM SIGMETRICS Cambridge, 2001.
[23] D. Anick, D. Mitra, and M.M. Sodhi, “Stochastic theory of a data
handling system with multiple sources,” Bell Sys. Tech Journal, Vol. 61,
No. 8, 1982.
[24] A. Elwalid and D. Mitra, “Effective bandwidth of general Markovian
trafﬁc sources and admission control of high speed networks,” IEEE
Transactions on Networking, Vol. 3, pp. 329–343, 1993.
[25] T.E. Stern and A.I. Elwdid, “Analysis of a separable Markov modulated
rate models for information handling systems,” Advances in Applied
Probability, Vol. 23, pp. 105–139, 1992.
[26] C. Chang, Performance guarantees in communication networks, New
York: Springer-Verlag, 2000.
[27] D. Zhang and D. Ionescu, “Online packet loss measurement and esti-
mation for VPN-based services,” IEEE Transactions on Instrumentation
and Measurement, Vol. 59, No. 8, pp. 2154–2166, Aug. 2010.
[28] D. Zhang and D. Ionescu, “On packet loss estimation for virtual
private networks services,” Proc. of 13th IEEE Conference on Computer
Communications and Networks, pp. 175–180, October 2004.
[29] N. Likhanov and R.R. Mazumdar, “Cell loss asymptotics in buffers
fed with a large number of independent stationary sources,” Proc. of
INFOCOM, Seventeenth Annual Joint Conference of the IEEE Computer
and Communications Societies, vol. 1, pp. 339–346, 1998.
[30] C. Lambiri, “On the estimation and control of packet loss for VPN
services,” Ph.D. dissertation, University of Ottawa, Ottawa, 2003.
[31] R. R. Bahadur and R. Ranga Rao, “On deviations of the sample mean,”
Ann. Mathematical Statistics, Vol. 31, No. 23, pp. 1015–1027, 1960.
[32] H. S. Kim and N. Shroff, “Loss probability calculations and asymp-
totic analysis for ﬁnite buffer multiplexers,” IEEE/ACM Transaction on
Networking, Vol. 9, No. 6, pp. 755–767, Dec. 2001.
[33] J. Choe and N. Shroff, “A central-limit-theorem-based approach for an-
alyzing queue behavior in high-speed networks,” IEEE/ACM Transaction
on Networking, Vol. 6, No. 5, pp. 659–671, Oct. 1998.
[34] K. Debicki and M. Mandjes, “Exact overﬂow asymptotics for queues
with many Gaussian inputs,” Journal of Applied Probability, Vol. 40, pp.
704–720, 2003.
[35] A. Leon-Garcia, Probability, Statistics, and Random Processes for
Electrical Engineering, Prentice Hall, 1994.
[36] F. Kelly, “Notes on effective bandwidths,” in Stochastic Networks:
Theory and Applications, Oxford University Press, pp. 141–168, 1996.
[37] J. G¨artner, “On large deviations from invariant measure,” Theory of
Probability and Its Applications, Vol. 22, pp. 24–39, 1977.
[38] R.S. Ellis, “Large deviations for a general class of random vectors,”
Ann. Probability, Vol. 12, pp. 1–12, 1984.
[39] W. Whitt, “Tail probabilities with statistical multiplexing and effective
bandwidths in multi-class queues,” journal of Telecommunication Sys-
tems, Vol. 2, pp. 71–107, 1993.
[40] P.W. Glynn and W. Whitt, “Logarithmic asymptotics for steady-state tail
probabilities in a single-server queue,” Journal of Applied Probability, Vol.
31, 1994.
[41] S. Tao, K. Xu, A. Estepa, T.F.L. Gao, R. Guerin, J. Kurose, D. Towsley,
and Z.L. Zhang, “Improving VoIP quality through path switching,” Proc.
of 24th IEEE Conference on Computer Communications, Vol. 4, pp.
2268–2278, March 2005.
[42] C. Lambiri, D. Ionescu, and V. Groza, “A new method for the estimation
and measurement of trafﬁc packet loss for virtual private networks
services,” Proc. of the 21st IEEE Conference on Instrumentation and
Measurement Technology, Vol. 1, pp. 401–406, May 2004.
[43] D. P. Heyman and T. V. Lakshman, “What are the implications of
long-range dependence for VBR-video trafﬁc engineering?,” IEEE/ACM
Transactions on Networking, Vol. 4, No. 3, pp. 301–317, June 1996.
[44] B. K. Ryu and A. Elwalid, “The importance of long-range dependence
of VBR video trafﬁc in ATM trafﬁc engineering: myths and realities,”
Proc. of ACM SIGCOMM Conference on Applications, Technologies,
Architectures, and Protocols for Computer Communications, pp. 3–14,
August 1996.
[45] X. Yu, I. L. Thng, and Y. Jiang, “Measurement-based effective band-
width estimation for long range dependent trafﬁc,” Proc. of IEEE Region
10 International Conference on Electrical and Electronic Technology
TENCON, Vol. 1, pp. 359–365, 2001.
[46] UC Berkeley, LBL, USC/ISI, and Xerox PARC, Network simulator NS-
2, http://www.isi.edu/nsnam/ns, [Accessed: 14 June 2012].
[47] ITU-T Recommendation G.729, “Coding of speech at 8 kbit/s us-
ing conjugate-structure algebraic-code-excited linear prediction (CS-
ACELP),” 2007.
[48] M.C. Weigle, P. Adurthi, F. Hernandez-Campos, K. Jeffay, and F.D.
Smith, “Tmix: A tool for generating realistic application workloads in
NS-2,” ACM SIGCOMM Computer Communication Review, Vol 36, No
3, pp. 67–76, July 2006.
[49] P.E. Greenwood and M.S. Nikulin, A guide to chi-squared testing, Wiley-
Interscience, 1996.
42
International Journal on Advances in Networks and Services, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/networks_and_services/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

