Context-Aware Data Analytics for Activity Recognition 
 
Mohammad Pourhomayoun                        
Ebrahim Nemati, Majid Sarrafzadeh 
Computer Science Department 
University of California, Los Angeles (UCLA) 
Los Angeles, USA 
e-mails:{mpourhoma, ebrahim, majid}@cs.ucla.edu 
Bobak Mortazavi 
School of Medicine  
Yale University 
Connecticut, USA 
e-mail: bobak.mortazavi@yale.edu
 
 
Abstract— Remote Health Monitoring Systems are gaining 
an important role in healthcare by collecting and transmitting 
patient information and providing data analytics techniques to 
analyze the collected data and extract knowledge. Physical 
activity recognition and indoor localization are two of the most 
important concepts in assistive healthcare, where tracking the 
positions, motions and reactions of a patient or elderly is 
required for medical observation or accident prevention. In 
this paper, we propose a novel context-aware data analytics 
framework to classify and recognize the physical activity based 
on the signals received from a worn SmartWatch, the location 
information of the human subject, and advanced machine 
learning algorithms. In this approach, we take into account the 
physical location of the human subject as contextual 
information to improve the accuracy of the activity 
classification. The hypothesis is that the location information 
can get involved in classifier decision making as a prior 
probability distribution to help improve the accuracy of 
activity recognition. The results demonstrate improvements in 
accuracy and performance of the activity classification when 
applying the proposed method compared to conventional 
classifications. 
Keywords-Activity Recognition; Indoor Localization. 
I. 
INTRODUCTION AND BACKGROUND 
As the number of elderly people grows rather quickly 
over the past few decades and continues to do so ‎[1], it is 
essential to seek alternative and innovative ways to provide 
affordable healthcare to the aging population ‎[2]. A 
compelling solution is to enable pervasive healthcare for the 
elderly or patients with chronic disease at their own homes, 
while reducing the use and dependency of healthcare 
facilities. New technologies, such as Body Sensor Networks 
(BSN) and Remote Health Monitoring Systems (RHMS) 
allow for collecting continuous data and monitoring the 
patients in their home environment. There have been a 
number of studies on end-to-end remote health monitoring 
and medical data analytics using wearable or environmental 
sensors known as Smart Environment or Smart Home ‎[3]-
‎[7]. RHMS has shown substantial potential in reducing 
healthcare costs and improving quality of care ‎[3]-‎[10]. 
Rapid advances in many technological domains including 
electronics, wireless communications, Internet, and sensor 
design has led to the development of effective RHMS that 
can collect varying physiological information, vital signs, 
and physical activity from patients ‎[3]-‎[7].   
Although RHMS have shown promise in reducing 
healthcare costs and improving quality of care, effective 
analysis of the data collected by these systems and the 
potential benefits of utilizing such analysis is by large an 
open problem. One of the key demands in such an assistive 
environment is to promptly and accurately determine the 
state and activities of an inhabitant subject. The physical 
activity recognition and indoor localization provide 
effective means in tracking the positions, motions, and 
reactions of a patient, the elderly or any person with special 
needs 
for 
medical 
observation 
or 
accident 
prevention ‎[11]‎[12]. 
Physical activity recognition using wearable sensors or 
smartphones has been a long-standing problem. There have 
been a number of studies on utilizing machine learning 
algorithms to monitor the activities of daily living ‎[24]‎[25]. 
However, in this paper, we propose a novel context-aware 
data analytics framework to classify the physical activity 
based on the signals received from a wearable sensor (e.g., 
SmartWatch ‎[28]), the position information of the human 
subject, and advanced machine learning algorithms. The 
location of a patient can provide important prior information 
that can be used to better classify the physical activity. We 
hypothesize that the location information of the human 
subject can get involved in classifier decision making as a 
prior probability distribution to improve the accuracy of 
activity recognition. In other word, we take into account the 
location of the subject as contextual information to improve 
the accuracy of the activity classification. The results 
demonstrate improvements in accuracy and performance of 
the classifier when applying the proposed method compared 
to typical classifications.  
The rest of the paper is organized as follows: Section II 
describes the systems architecture and main modules for the 
proposed context-aware data analytics framework, Section 
III provides a brief overview of the indoor localization 
technique that we use to come up with the contextual 
information. This localization technique is a novel approach 
developed by the authors. However, since the focus of this 
paper is on data analytics, we just briefly review this 
technique, and use the results as contextual information in 
63
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-423-7
DATA ANALYTICS 2015 : The Fourth International Conference on Data Analytics

our analytics framework. Section IV describes the details of 
the proposed context-aware analytics framework for activity 
recognition, including feature extraction, feature selection 
algorithms, classification, training/testing stages, and the 
context-awareness characteristics of the system. Finally, 
Section V describes the results and conclusion.  
II. 
RELATED WORK 
Physical activity monitoring and indoor localization are 
important problems in the areas of wireless health and 
assistive healthcare that have raised increasing attention 
recently ‎[12]-‎[37]‎[28]‎[36]. Monitoring the activities of daily 
living with smartphones and devices with these phones have 
been well-studied ‎[4]‎[24]-‎[37]. In particular, Alshurafa, et 
al. ‎[4] presents a comprehensive activity recognition process 
and particularly, looks at activity tracking for a clinical 
environment, and how to guarantee that patients are 
performing the desired activity. Gupta, et al. ‎[37] presents 
an activity recognition system using a single waist-mounted 
accelerometer to classify gait events into six daily living 
activities. SmartWatches have also been used to provide 
activity tracking applications to date ‎[28]‎[35]. Mortazavi, et 
al. ‎[28] provides visual feedback and interface for activity 
repetition counting using SmartWatch. Park, et al. ‎[35] 
develops a watch sensor to track fall, walking, handrelated 
shocks, and general activity. Using a feature extraction and 
selection technique, results are presented in a 10-fold cross 
validation to determine the ability to track elderly patients. 
Park, et al. ‎[35] uses a forward selection technique for 
feature selection and a support vector machine, to obtain 
accuracy results and recall results. In this study, we propose 
a new context-aware activity recognition system that utilizes 
the SmartWatch accelerometer and gyroscope signals, and 
takes into account the location of the subject as contextual 
information to improve the accuracy of the activity 
classification. The results demonstrate improvements in 
accuracy and performance of the classifier when applying 
the proposed method compared to typical classifications. 
III. 
SYSTEM ARCHITECTURE 
The proposed framework includes two main modules:      
a) Indoor Localization/Tracking Module and b) Context-
Aware Activity Recognition Module. Indoor Localization 
and Tracking Module is responsible for estimating and 
tracking the position of a patient. We use a novel approach 
for localization based on spatial sparsity of target in x-y-z 
space and the Received-Signal-Strength (RSS) between a 
SmartWatch and RF beacons mounted in the building.  
Context-Aware 
Activity 
Recognition 
Module 
is 
responsible for classifying and recognizing patients' 
physical activities using data analytics techniques based on 
the wearable embedded accelerometer and gyroscope 
signals. This module includes feature extraction, feature 
selection and dimensionality reduction, and context-aware 
classification submodules. In the proposed approach, we 
exploit the location information of the subject (received 
form patient tracking module) to achieve more accurate 
results for activity recognition. Details of these modules are 
described in next sections. 
IV. 
INDOOR LOCALIZATION AND TRACKING 
As mentioned before, the main focus of this paper is not 
on indoor localization; instead it is on context-aware data 
analytics for activity recognition knowing the indoor 
location of the individual. In other word, we take into 
account the position of the human subject as contextual 
information to improve the accuracy of the analytics engine 
for activity recognition. Thus, in this paper, we only provide 
a brief overview of the novel indoor localization techniques 
that we have developed in our other studies, and then apply 
these techniques to estimate individual's location that will be 
later used in our analytics framework. For more details 
about our developed localization techniques please refer 
to ‎[11]-‎[17]. 
Indoor localization has been a long-standing and 
important problem in the areas of signal processing and 
sensor networks that has raised increasing attention 
recently ‎[11]-‎[23]. One of the key demands in assistive 
environment is to promptly and accurately determine the 
state and activities of an inhabitant subject. Indoor 
localization provides an effective means in tracking the 
positions, motions, and reactions of a patient, the elderly or 
any person with special needs for medical observation or 
accident prevention.   
The classic approach for localization is to first estimate 
one or more location-dependent signal parameters, such as 
Time-Of-Arrival (TOA), Angle-Of-Arrival (AOA) or RSS. 
Then in a second step, the collection of estimated 
parameters is used to determine‎an‎estimate‎of‎the‎subject’s‎
location. The TOA-based methods are usually more 
accurate than RSS or AOA techniques. However, the 
accuracy of the classic TOA based methods often suffer 
from massive multipath conditions for indoor localization, 
which is caused by the reflection and diffraction of the RF 
signals from objects (e.g., interior walls, doors or furniture) 
in the environment ‎[23]. Moreover, it usually necessitates 
using synchronized emitters/sensors to be able to estimate 
accurate time-of arrival or time-difference-of-arrival.  
In ‎[11]-‎[15], we introduced a novel accurate localization 
method based on the spatial sparsity in the x-y-z space. In 
this approach, we directly estimate the location of the 
emitter without going through the intermediate stage of 
TOA or RSS estimation. To this end, we utilize the spatial 
sparsity of the target (SmartWatch worn by a human 
subject) in the X-Y-Z space, and use the convex 
optimization theory to estimate the location of the subject. 
Assume that we divide the X-Y-Z space into fine enough 
grids. By assigning a positive number to each grid that 
contains the target and zeros to all the rest of grid cells, we 
will have a very sparse 3-dimensional grid matrix that can 
be reformed as a sparse vector. Since each element of this 
64
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-423-7
DATA ANALYTICS 2015 : The Fourth International Conference on Data Analytics

grid vector corresponds to one grid point in the X-Y-Z 
space, we can estimate the location of emitters by extracting 
the position of non-zero element (or non-zero elements 
when we have more than one subject to be determined) in 
the sparse vector. To this end, we have to estimate the 
sparsest vector that minimizes the cost between the 
predicted received signal and the actual observed signal 
with respect to the signal model and distance between the 
transmitted signals and the received signals (for details and 
problem formulation please refer to ‎[11]-‎[15]).  
The results demonstrate that the proposed method has 
very good performance even with small number of sensors. 
The results also indicate that, in contrary to the classic 
methods, the proposed approach is a very effective and 
robust tool to overcome multipath issues, which is a very 
serious problem in indoor localization. Furthermore, the 
system works well in noisy environments with low SNRs. It 
implies that, even with low transmitted power (to keep the 
devices small with long battery life), we can still achieve a 
high localization accuracy.  
Figure 1 shows some of the results for patient localization 
and tracking in a sample building using only 4 RF sensors 
mounted at the corners of a building. Figure 1-(a) shows the 
actual trajectory (blue line) of the patient walking around in 
the room, and the estimated path (red line) by the proposed 
system. Figure 1-(b) shows the error defined as the root-
mean-square (RMS) errors for positioning in the X, Y and Z 
dimensions.  
      
       (a) 
  
 
                                                     (b) 
Figure 1. (a) True position of the patient (in blue) and the estimated 
position (in red), (b) Error in positioning for each location in part (a). 
V. 
CONTEXT-AWARE ANALYTICS FRAMEWORK FOR 
ACTIVITY RECOGNITION  
Context-Aware 
Activity 
Recognition 
Module 
is 
responsible for recognizing the physical activities based on 
the accelerometer and gyroscope signals. This work will 
investigate the ability of the SmartWatch to recognize and 
track the necessary activities of human subjects in order to 
better assess their health status. In particular, by identifying 
the transitions between sitting, standing, and lying, this 
work approaches the classification of patient status. 
Monitoring the Activities of Daily Living (ADL) through 
wearable body sensors has attracted extensive attention 
recently ‎[24]-‎[28]. In this study, we propose a context-aware 
activity recognition system based on the signals received 
from embedded accelerometer and gyroscope of a 
SmartWatch, a real-time machine learning based analytics 
engine, and the position information received from the 
indoor localization module.  
Our preliminary results ‎[28] show that the watch can 
provide accurate activity tracking results similar to custom 
sensing environment. However, in this work, we propose a 
context-aware technique by taking into account the indoor 
position of the individual as prior contextual information 
that can modify the classifier model, and consequently 
provide more accurate results for activity recognition. The 
activity recognition module includes feature extraction, 
feature 
selection, 
and 
context-aware 
classification 
submodules as described in the following. 
A. 
Feature Extraction and Feature Selection 
The first step is to gathering the patient's activity signals 
from the SmartWatch embedded accelerometer and 
gyroscope. After receiving the signals, the next step is to 
data preprocessing and feature extraction. We use a moving 
average window as a low-complexity low-pass filter for the 
purpose of denoising. Then, a total number of 150 features 
are extracted from accelerometer and gyroscope signals. 
Statistical and morphological features are the most common 
features used for data analytics. Theses feature are extracted 
for each one of the three axes of the accelerometer and 
gyroscope. Some of the extracted features include Mean, 
Standard Deviation, Kurtosis, Skewness, Energy, Variance, 
Median, RMS, Minimum, Maximum, Sum, Average 
Difference, Eigenvalues of Dominant Directions, CAGH, 
Average Mean Intensity, Dominant Freq., Peak Diff., Peak 
RMS, Root Sum of Squares, First Peak, Second Peak. In 
this study, the Samsung Galaxy Gear SmartWatch is used 
for experimentation. It employs a ±2g triaxial accelerometer 
and ±300 degree per second gyroscope sensors.  
Once the features are extracted, a dimensionality 
reduction algorithm is applied to select the most prominent 
features and reduce the redundancy. The conventional 
feature selection algorithms usually focus on specific 
metrics to quantify the relevance and redundancy of each 
feature with the goal of finding the smallest subset of 
65
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-423-7
DATA ANALYTICS 2015 : The Fourth International Conference on Data Analytics

features that provides the maximum amount of useful 
information for prediction. Thus, the main goal of feature 
selection algorithms is to eliminate redundant or irrelevant 
features in a given feature set. Applying an effective feature 
selection algorithm not only decreases the computational 
complexity of the system by reducing the dimensionality 
and eliminating the redundancy, but also increases the 
performance of the classifier by removing irrelevant 
features. In this paper, we tried both wrapper and filter 
methods; the two well-known feature selection categories. 
Wrapper methods usually utilize a classifier to evaluate 
feature subsets in an iterative manner according to their 
predictive power. A new feature subset is used to train a 
predictive model that will later be evaluated on a testing 
dataset to assess the relative usefulness of subsets of 
features ‎[39]. Figure 2-(a) provides an illustration of the 
wrapper feature selection method. 
Filter methods use a specific metric to score each 
individual feature (or a subset of features together). The 
most popular metrics used in filter methods include 
correlation coefficient, mutual information, Fisher score, 
chi-square parameters, entropy and consistency. Filter 
methods are very popular (especially for large datasets) 
since they are usually very fast and much less 
computationally intensive than wrapper methods. Figure 2-
(b) illustrates the steps involved in the filter feature selection 
method. 
 
       
Predictive Model 
Training & Testing
Original Feature Set
Selecting a Feature Subset
Predictive Model 
Performance Assessment
Final Feature Set
     
Original Feature Set
Feature Ranking Based on  
Relevancy & Redundancy
Selecting the Proper 
Number of Features
Final Feature Set
 
                                 (a)                                                       (b) 
Figure 2. Feature Selection: (a) Wrapper method, (b) Filter method. 
  
In this study, after trying several filter and wrapper 
methods, we finally chose only 5 features to keep the 
computational complexity low on the device. The selected 
features includes: minimum of acceleration axis x (min ax), 
average acceleration axis z (avg az), eigenvalue acceleration 
axis z (eigen az), correlation between acceleration axis x 
and y (cor axy), sum gyro axis z (sum gz). 
B. 
Classification: Training and Testing  
Once the subset of features is selected, a machine learning 
based classifier is applied to classify the motions. In this 
research, we tried various classification algorithms such as 
SVM, Random Forest, BayesNet, and Artificial Neural Net 
(ANN) as the predictor. According to our results, a Random 
Forest classifier with 100 trees provided fast and accurate 
prediction results for our dataset. Random Forest is an 
ensemble learning classification method comprising of a 
collection of decision tree predictors operating based on i.i.d 
random vectors. In this process, each tree casts a unit vote 
for the most popular class ‎[40]. The classifier was supplied 
with training data labeled with 6 labels being the six 
transition movements (sit_to_lie, sit_to_stand, stand_to_sit, 
stand_to_lie, lie_to_sit, lie_to_stand). The recognition 
algorithm must then be validated to ensure the proper 
development of a system to accurately track the state of 
subjects. Figure 3 indicates the Training and Testing stages. 
The next section describes the context-awareness approach 
and how we take into account the location information to 
improve the classifier accuracy. 
C. Context Awareness 
The indoor position of a patient (received from indoor 
localization and tracking module) can provide significant 
prior information about the possible physical activity. For 
example, when we know that the patient is in the kitchen, 
the probability of standing is much higher than lying, 
consequently, the labels are not uniformly distributed 
anymore. Thus, by knowing the approximate position of the 
patient, we will have better understanding about the possible 
activities that the patient can have.  
We hypothesize that the location information can get 
involved in classifier decision making as a prior probability 
distribution to help improve the accuracy of activity 
Gyro X,Y,Z 
Signal
Feature 
Extraction
Feature
Selection
Classifier: 
Model 
Generation
Classifier:
Prediction
Sitting
Standing
Lying
Accelerometer  
X,Y,Z Signal
Signal 
Preprocessing 
Signal 
Preprocessing 
Gyro X,Y,Z 
Signal
Feature 
Extraction
Accelerometer  
X,Y,Z Signal
Signal 
Preprocessing 
Signal 
Preprocessing 
Training 
Stage
Testing
Stage
Figure 3: Regular Physical Activity Classification 
Figure 3. The regular Physical Activity Classification. 
66
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-423-7
DATA ANALYTICS 2015 : The Fourth International Conference on Data Analytics

recognition module. 
Assume that 
1,
,
N
F
F  are the classifier input features 
and C  represents the classifier labels. Then, the classifier 
probability model can be expressed as a conditional 
probability 
1
(
,
,
N )
p C F
F
 (known 
as 
Posterior 
Probability) that can be formulated using the Bayes' 
Theorem as following ‎[41]: 
1
1
1
( ,
,
,
)
(
,
,
)
(
,
,
)
N
N
N
p C F
F
p C F
F
p F
F

                     (1) 
The joint probability in the numerator can be reformulated 
as: 
1
1
1
2
1
1
2
1
1
1
( ,
,
,
)
( )
(
,
,
|
)
( )
(
|
)
(
,
,
|
,
)
( )
(
|
)
(
|
,
)
(
|
,
,
,
)
N
N
N
N
N
p C F
F
p C p F
F
C
p C p F C p F
F
C F
p C p F C p F
C F
p F
C F
F 



 (2) 
A "Maximum A Posteriori" (MAP) decision making rule 
can be applied as following to pick the most probable class 
label: 
1
1
(
,
,
)
argmax
(
)
(
,
,
|
)
N
N
c
calssify f
f
p C
c p f
f
C
c



     (3) 
The term 
( 1
,
,
|
)
N
p F
F
C (called likelihood) is usually 
determined in the training stage. For the case of simplicity 
(e.g., in Naive Bayes classifier ‎[41]), the features can be 
assumed to be conditionally independent. In this case, the 
equation (3) can be simplified to: 
1
1
(
,
,
)
argmax
(
)
(
|
)
N
N
i
i
c
i
calssify f
f
p C
c
p F
f
C
c






       (4) 
In traditional classification, a uniform distribution is used 
for Prior Probability
( )
p C . However, in our approach, we 
hypothesize that the patient's position can provide some 
information 
about 
the 
distribution 
of 
the 
prior 
probability
( )
p C . Thus, we can write 
( )
p C as: 
 
(
)
(
,
)
(
)
(
|
)
i
i
i
i
i
p C
c
p C
c L
l
p L
l p C
c L
l










                 (5) 
where 
( , )
p C L
 is the joint probability distribution of 
location and activity label. Thus, when the location is 
known, the uniformly distributed Prior Probability 
( )
p C  
will be replaced by the conditional probability 
(
|
i )
p C L
 l
 
and consequently, the equation (4) provides more accurate 
model for activity recognition. 
VI. 
RESULTS AND CONCLUSION 
A pilot trial has been conducted to collect the data. The 
dataset contains 1200 data samples collected from 20 
subjects. Table I shows the F-Score results for the activity 
recognition using only 5 features in two different cases:       
a) Using conventional classification without considering the 
location information, b) Context-aware activity recognition 
knowing and taking into account the location information. 
As we see, for example in the kitchen, we achieve 7% 
improvement (using 5 features) since knowing the location 
of the subject provides significant information about the 
activity. However, in the living room, we achieve 3% 
improvement, and it totally makes sense, because the 
likelihoods of sitting, lying, and standing in the living room 
are almost similar, and consequently the prior probability 
distribution is closer to the uniform distribution which is the 
pre-assumption for conventional activity recognition too. 
 
TABLE I.  F-SCORE FOR REGULAR AND CONTEXT-AWARE ANALYTICS 
USING ONLY 5 FEATURES  
Location 
F-Score for conventional 
classification 
F-Score for context-
aware classification 
Kitchen 
0.81 
0.88 
Living room 
0.82 
0.85  
Bedroom 
0.80 
0.84  
 
 
Figure 4. F-Score versus the number of selected features for conventional 
and context-aware activity recognition in kitchen. 
 
 
Figure 5. F-Score versus the number of selected features for conventional 
and context-aware activity recognition in the living room. 
 
Figures 4 and 5 show the F-Score ‎[41] versus the number of 
selected features for conventional and context-aware 
analytics in the kitchen and living room. F-Score is a well-
known measure for classification accuracy, and it can be 
interpreted as the harmonic mean of precision (the fraction 
of retrieved instances that are relevant) and recall (the 
fraction of relevant instances that are retrieved). Thus, F-
67
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-423-7
DATA ANALYTICS 2015 : The Fourth International Conference on Data Analytics

score is an indication of how well the system can identify 
the activity and how strong it is at not mis-predicting.  
For example, for kitchen, we achieved 43% improvement 
using 1 feature and 9% improvement using 5 features in 
activity recognition accuracy, which is a significant 
improvement. Our work in ‎[42] investigates the impact of 
improvement in classification accuracy on cost. 
Again, as we expected, the improvement by using 
context-aware approach is higher in the kitchen compared to 
living room because the probability distribution of various 
activities in the living room is closer to uniform distribution.  
REFERENCES 
[1] W. He, M. Sengupta, V. Velkoff, and K. DeBarros, 65+ in the United 
States, Current Population Reports, U.S. Census Bureau, 2005. 
[2] United‎ Nations,‎ “World‎ Population‎ Prospects:‎ The‎ 2008‎ Revision,‎
Highlights,”‎Department‎of‎Economic‎and‎Social‎Affairs,‎Population‎
Division, Working Paper No. ESA/P/WP.210, 2009. 
[3] M. Lan, et al., "WANDA: An End-to-End Remote Health Monitoring 
and Analytics System for Heart Failure Patients," Wireless Health 
Conf., 2012, pp. 68–74. 
[4] N. Alshurafa, et al. "Anti-Cheating: Detecting Self-Inflicted and 
Impersonator Cheaters for Remote Health Monitoring Systems with 
Wearable Sensors," BSN 2014, 2014, pp. 92-97.  
[5] N. Alshurafa, et al. "Battery optimization in smartphones for remote 
health monitoring systems to enhance user adherence," Int. Conf. on 
PErvasive Technologies Related to Assistive Environments, 2014.  
[6] N. Alshurafa, et al. "Improving Compliance in a Remote Health 
Monitoring System through Smartphone Battery Optimization," IEEE 
J Biomed Health Inform, 2014, pp. 57-63. 
[7] M. Pourhomayoun, et. al., "Multiple Model Analytics for Adverse 
Event Prediction in Remote Health Monitoring Systems," IEEE 
EMBS Conference on Healthcare Innovation & Point-of-Care 
Technologies, 2014, pp. 106-110. 
[8] R. Cebul, T. Love, A. Jain, and C. Herbert, "Electronic Health 
Records and Quality of Diabetes Care," J. Med., 2011, pp. 825-833.  
[9] R. Hillestad, et al., "Can Electronic Medical Record Systems 
Transform Health Care? Potential Health Benefits, Savings, and 
Costs," Health Affairs, vol. 24, no. 5, 2005, pp. 1103-1117. 
[10] R.‎ W.‎ Jang,‎ et‎ al.,‎ “Simple‎ prognostic‎ model‎ for‎ patients‎ with‎
advanced‎cancer‎based‎on‎performance‎status,”‎JOP, 2014,pp. 10-15. 
[11] M. Pourhomayoun, Z. Jin, and‎ M.L.‎ Fowler,‎ “Indoor‎ Localization,‎
Tracking and Fall Detection for Assistive Healthcare Based on 
Spatial‎ Sparsity‎ and‎ Wireless‎ Sensor‎ Network,”‎ Journal‎ of‎
Monitoring and Surveillance Tech. Research, 2013, pp. 72-83. 
[12] M. Pourhomayoun,‎Z.‎Jin‎and‎M.L.‎Fowler,‎“Spatial‎Sparsity‎Based‎
Indoor Localization in Wireless Sensor Network for Assistive 
Healthcare‎Systems,”‎34th‎IEEE‎Int.‎Conference‎of‎the‎Engineering‎
in Medicine and Biology (EMBC2012), 2012, pp. 3696-3699. 
[13] M. Pourhomayoun‎and‎M.‎L.‎Fowler,‎“Spatial‎Sparsity‎Based‎Emitter‎
Localization,”‎Conf.‎on‎Information‎Sciences‎and‎Sys.,‎2012, pp. 1-4. 
[14] M.‎Pourhomayoun,‎Z.‎Jin‎and‎M.L.‎Fowler,‎“Accurate‎Localization‎
of In-Body‎ Medical‎ Implants‎ Based‎ on‎ Spatial‎ Sparsity,”‎ IEEE‎
Transactions on Biomedical Engineering, 2013, pp. 590-597. 
[15] M. Pourhomayoun, M. Fowler, and Z.‎ Jin,‎ “A‎ Novel‎ Method‎ for‎
Medical Implant In-Body‎Localization,”‎Conf.‎of‎IEEE‎Engineering‎
in Medicine & Biology Society (EMBC), 2012, pp. 5757-5760. 
[16] M. Pourhomayoun and M. Fowler, "Sensor network distributed 
computation for Direct Position Determination,"  IEEE In Sensor 
Array and Multichannel Signal Processing, 2012, pp. 125-128. 
[17] M. Pourhomayoun and M. Fowler, "An SVD approach for data 
compression in emitter location systems," IEEE Signals, Systems and 
Computers (ASILOMAR) Conf., 2011, pp. 257-261. 
[18] K.‎ Pahlavan,‎ P.‎ Krishnamurthy,‎ and‎ J.‎ Beneat,‎ “Wideband‎ radio‎
propagation‎ modeling‎ for‎ indoor‎ geolocation‎ applications,”‎ IEEE‎
Commun. Mag., vol. 36, 1998, pp. 60–65.  
[19] K. Pahlavan,‎ X.‎ Li,‎ J.‎ Makela,‎ “Indoor‎ geolocation‎ science‎ and‎
technology,”‎IEEE‎Commun.‎Mag.,‎vol.‎40,‎pp.‎112–118, Feb. 2002. 
[20] X.‎ Li,‎ and‎ K.‎ Pahlavan,‎ “Super-Resolution TOA Estimation With 
Diversity‎ for‎ Indoor‎ Geolocation”,‎ IEEE‎ Transactions‎ on‎ Wireless‎
Communications, vol 3, January 2004, pp. 224-234.  
[21] Y. Chen‎ and‎ H.‎ Kobayashi,‎ “Signal‎ Strength‎ Based‎ Indoor‎
Geolocation,”‎Int. Conf. on Communications, 2002, pp. 436-439. 
[22] G. Zàruba, M. Huber, F. Kamangar, and I. Chlamtac,‎“Indoor‎location‎
tracking using RSSI readings from a single Wi-Fi‎ access‎ point,”‎
Wireless Networks, 2007, pp. 221-235. 
[23] A. Hatami, B. Alavi, K. Pahlavan, and M. Kanaan, "A comparative 
performance evaluation of indoor geolocation technologies," 
Interdisciplinary Information Sciences, 2006, 133-146. 
[24] N. Ravi,‎ N.‎ Dandekar,‎ P.‎ Mysore,‎ and‎ M.‎ L.‎ Littman,‎ “Activity‎
recognition‎from‎accelerometer‎data,”‎AAAI,‎2005, pp. 1541-1546.  
[25] N.‎ Alshurafa,‎ et.‎ al.,‎ “Robust‎ human‎ intensity-varying activity 
recognition‎ using‎ stochastic‎ approximation‎ in‎ wearable‎ sensors,”‎‎
BSN, 2013, pp. 1–6. 
[26] Z. Yan, D. Chakraborty, A. Misra, H. Jeung, and K. Aberer, 
“Sammple:‎Detecting‎semantic‎indoor‎activities‎in‎practical‎settings‎
using‎locomotive‎signatures,”‎in‎Wearable‎Computers‎(ISWC),‎16th‎
International Symposium on. Ieee, 2012, pp. 37–40. 
[27] J.‎ Fontecha,‎ F.‎ Navarro,‎ R.‎ Herv´as,‎ and‎ J.‎ Bravo,‎ “Elderly‎ frailty‎
detection by using accelerometer-enabled smartphones and clinical 
information‎records,”‎Personal‎and‎ubiquitous‎computing, 2013, pp. 
1073-1083. 
[28] B. Mortazavi, et al.,‎ “Determining‎ the single best axis for exercise 
repetition‎recognition‎and‎counting‎with‎SmartWatches,”‎11th IEEE 
Body Sensor Networks Conference (BSN), 2014, pp. 33-38.  
[29] B. Mortazavi, M. Pourhomayoun, S. Nyamathi, B. Wu, S. Lee, M. 
Sarrafzadeh, "Multiple Model Recognition for Near-Realistic 
Exergaming," 
IEEE 
International 
Conference 
on 
Pervasive 
Computing and Communications (PerCom), 2015. 
[30] L.‎ Bao‎ and‎ S.‎ S.‎ Intille,‎ “Activity‎ recognition‎ from‎ user-annotated 
acceleration‎data,”‎in‎Pervasive‎computing.‎Springer,‎2004,‎pp.‎1-17. 
[31] B. J. Jefferis, et al.,‎ “Trajectories‎ of‎ objectively‎ measured‎ physical‎
activity in free-living‎older‎men.”‎Med. & Sci. in sports, 2014. 
[32] H.‎ L.‎ Brooke,‎ K.‎ Corder,‎ A.‎ J.‎ Atkin,‎ and‎ E.‎ M.‎ van‎ Sluijs,‎ “A‎
systematic literature review with meta-analyses of within-and 
betweenday differences in objectively measured physical activity in 
school-aged‎children,”‎Sports‎Medicine,‎2014, pp. 1–12. 
[33] B.‎ Najafi,‎ D.‎ G.‎ Armstrong,‎ and‎ J.‎ Mohler,‎ “Novel‎ wearable‎
technology for assessing spontaneous daily physical activity and risk 
of‎falling‎in‎older‎adults‎with‎diabetes,”‎Journal‎of‎diabetes‎science‎
and technology, vol. 7, no. 5, 2013, pp. 1147–1160. 
[34] G.‎ Bieber,‎ M.‎ Haescher,‎ and‎ M.‎ Vahl,‎ “Sensor‎ requirements‎ for‎
activity‎ recognition‎ on‎ smart‎ watches,”‎ in‎ Proceedings‎ of‎ the‎ 6th‎
International Conference on PErvasive Technologies Related to 
Assistive Environments. ACM, 2013, p. 67. 
[35] C. Park, J. Kim, and H.-J.‎ Choi,‎ “A‎ watch-type human activity 
detector‎for‎the‎aged‎care,”‎in‎Advanced‎Communication‎Technology‎
(ICACT), International Conference on. IEEE, 2012, pp. 648–652. 
[36] M.‎Zhang‎and‎A.‎A.‎Sawchuk,‎“A‎feature‎selection-based framework 
for‎human‎activity‎recognition‎using‎wearable‎multimodal‎sensors,”‎
6th Int. Conference on Body Area Networks, 2011, pp. 92–98. 
[37] P. Gupta, P. and T. Dallas, "Feature Selection and Activity 
Recognition System Using a Single Triaxial Accelerometer," 
Biomedical Eng., IEEE Trans., vol. 61, 2014, pp. 1780 - 1786.  
[38] L.‎Palmerini,‎S.‎Mellone,‎L.‎Rocchi,‎and‎L.‎Chiari,‎“Dimensionality‎
reduction for the quantitative evaluation of a smartphone-based timed 
up‎and‎go‎test,”‎EMBC‎2011,‎2011,‎pp.‎7179 - 7182. 
[39] I. Guyon and A. Elisseeff, "An Introduction to Variable and Feature 
Selection", J. of Machine Learning Research, 2003, pp. 1157-1182. 
[40] L. Breiman, "Random Forests". Machine Learning, 2001. 
[41] M. N. Murty and V. Susheela Devi, "Pattern Recognition: An 
Algorithmic Approach," Springer Science & Business Media, 2011. 
[42] S. I. Lee, et al., "Remote Patient Monitoring Systems: What Impact 
Can Data Analytics Have on Cost?," Wireless Health Conf., 2013. 
 
 
68
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-423-7
DATA ANALYTICS 2015 : The Fourth International Conference on Data Analytics

