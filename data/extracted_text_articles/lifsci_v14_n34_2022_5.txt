An Assessment of Human Depth Understanding  
in Handheld Light-Field Displays 
 
Raymond Swannack, Oky Dicky Ardiansyah Prima 
Graduate School of Software and Information Science 
Iwate Prefectural University 
152-52 Takizawa, Iwate, Japan 
e-mail: g231s501@s.iwate-pu.ac.jp, prima@iwate-pu.ac.jp
 
 
Abstract‚ÄîLight-field displays (LFDs) allow users to view 
stereoscopic images without the need for a headset, providing a 
novel 3-Dimensional (3D) experience. This study aims to expand 
upon the preliminary experiment, in which we evaluated the 
benefits of stereoscopic cues in human visual understanding 
through users performing 3D interactions on a multi-view, LFD 
display. Our task scenario involves user tests for 3D alignment 
accuracy and a questionnaire about the experience during the 
test. For each task, using the LFD ‚ÄúLume Pad‚Äù developed by 
Leia Inc., 3D contents are presented with stereoscopic cues and 
without. Results from subjects showed that task alignment could 
be achieved with greater accuracy when stereo cues were 
available than when there were not. The questionnaire showed 
that depth perception appeared to be easier to comprehend with 
stereoscopic cues. 
Keywords-component 
Light-Field 
Display; 3D human 
perception; motion-parallax; stereoscopic vision; head tracking. 
I.  INTRODUCTION 
Two-Dimensional (2D) screens have almost limitless 
possibilities. These displays can show locations that the user 
has never seen, visualize data of almost any form, and allows 
professionals to interact with information in ways that are 
difficult within a physical medium. Even with all these 
possibilities, the 2D screen is not perfect. This style screen 
cannot show true depth, as it is a flat object and does not have 
any depth to it. This paper is an extension of our previous 
work, evaluating the benefits of depth comprehension of an 
LFD over a standard flat screen [1].  
The human eye does not interact with a screen in the same 
way as it does with the real 3D world [2], especially in terms 
of seeing depth. To aid in recreating depth, there are many 
tools that can be used to simulate depth cues. There are nine 
widely agreed-upon sources of information that the human 
brain uses for the purpose of perceiving depth. They are as 
follows, binocular disparity, convergence, occlusion, relative 
size, height in the visual field, relative density, aerial 
perspective, accommodation, and motion parallax [3]. To a 
greater or lesser extent, these are the primary tools used in 
conveying the illusion of depth within a 2D screen, and it is 
the manipulation of these sources that forms the basis of 3D 
displays. By putting more focus on one source than others, 
many different types of 3D displays can be created, each being 
tailored to suit different tasks. 
For most of the populace, VR represents a VR headset, or 
Head Mounted Display (HMD) as these have had the most 
exposure in popular culture. The popularity of products such 
as the HTC VIVE and the Oculus sold by Meta are best known 
for their entertainment uses but are becoming more well 
known for their benefits to training, such as cancer patient care 
[4], as well as in scientific research. The basis of VR HMDs 
is to use two small, high-resolution displays, placed close to 
the wearer‚Äôs eyes. Each display is positioned so that only one 
eye can see each screen, thus using binocular disparity to 
create a stereoscopic experience. Each screen displays a 
slightly different view of the same scene, allowing the user‚Äôs 
brain to put them together to create a 3D image. This is to 
simulate how the human eyes naturally work in the real world 
where human eyes are slightly split apart, giving us two 
slightly different views. 
Hand-held displays are not usually considered to be a type 
of 3D display, but they are also capable of displaying 
believable 3D images. These displays are largely composed of 
devices not specifically designed for this purpose such as 
smartphones and tablets, though there are some that are 
specifically designed to be used for 3D content such as the 
RED Hydrogen One smartphone and the Nintendo 3DS. 
Many hand-held displays use apps and programs, such as 
Pok√©mon Go or IKEA Place, that use the device‚Äôs inbuilt 
camera to give the appearance of projecting objects into the 
real world via the device‚Äôs screen. This style of software 
displays what the camera sees and adds digital objects to the 
scene to show the user a believable 3D scene. In so doing, this 
type of 3D display relies largely on height in the visual field, 
comparing the height of the digital objects to the size of 
known physical objects in the scene, for the user to believe 
that what they are looking at is real.  
Another device that is designed to create stereoscopic 
images in a different way is known as an LFD. LFDs use 
curved lenses, such as lenticular lenses, to redirect the light 
coming out of the screen of the display [5]. By doing this, the 
LFD can split the display so that it gives a different view to 
each eye. In this way, an LFD works similarly to an HMD, 
though the LFD performs this job without the need for a 
headset. This also allows for more than one user to be able to 
see the 3D effect from the same display. 
The purpose of this study is to improve on our preliminary 
findings and to show that adding stereoscopy to a tablet 
display increases a user‚Äôs understanding of what it is that they 
are seeing. To this end, the new experiment has more easily 
100
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

understood user controls, so the experiment emphasizes visual 
understanding and not mastery of the controls. The 
experiment also has less visual stimulation, to help the 
subjects focus on the important details of the experiment. 
The remainder of the paper is structured as follows. In 
Section II, we present our experiment‚Äôs methodology for 
evaluating the subject‚Äôs accuracy with and without 
stereoscopy. Section III covers the details of the hardware and 
software used in the experiment. Our preliminary experiment 
is discussed in Section IV, both our findings and what we felt 
needed to be improved for a follow-up experiment. Section V 
details the experiment as well as the results and questionnaire. 
In Section VI we discuss our findings and the implications. 
Finally, we finish our work in Section VII, with our 
conclusion and discuss future work. 
II. METHODS 
The focus of this study was to measure a subject‚Äôs 
understanding of a 3D scene displayed on a 2D screen, given 
different visual cues. To measure accuracy, subjects were 
asked to aim an arrow at a target, using the visual cues 
available to them to attempt to hit as close to the center of the 
target as they could. This test was repeated four times with 
some changes to assess the subject‚Äôs understanding of the 
scene.  
A. Visual Cues 
The primary visual cues that are observed in this test are 
occlusion, motion parallax, and stereoscopy. Occlusion 
happens when an object blocks the line of sight to another 
object. This technique has been used for centuries as a method 
of showing depth in many different forms of illustrations.  
Humans see objects closer to them as moving faster than 
objects that are further away. This is more prevalent in a 
vehicle moving at speed and is known as motion parallax. 
Both visual cues are prevalent throughout the entire 
experiment. 
B. Accuracy Test 
To assess the subject‚Äôs understanding of the simulated 
depth within the screen, a 3D scene was created to interact 
with. This scene includes an arrow, target, obstacles, and 
minute details to enhance the visual cues within the scene.  
The target, as seen in Figure 1, is at a set y position, 7 
meters, and is offset by a distance in the x and z directions. 
This distance changes for each test, as seen in Figure 2, 
altering the ideal arrow angle and camera position for each 
test. 
To obscure the subject‚Äôs view and encourage them to 
interact with the scene, obstacles are added to the scene. A 
rock is placed directly behind the arrow, stopping subjects 
from simply positioning the camera behind the arrow and 
lining up their aim this way. By doing this, the subject would 
not require the visual cues we are evaluating. There are also 
four trees that are placed to further complicate the scene and 
encourage more interaction. These trees change their location 
after each test much like the target. 
 
Figure 1. Target. 
 
 
Figure 2. Top-down view of Accuracy Test. 
 
C. Accuracy Measurement 
To measure the subject‚Äôs understanding of the scene, the 
distance from the arrow to the center of the target is measured. 
Euclidean distance is used for this measurement. A lower 
distance is desirable as it shows the subject was able to aim 
the arrow close to the center of the target. 
ùê∑ùëñùë†ùë°ùëéùëõùëêùëí = ‚àö(ùë•1 ‚àí ùë•2)2 + (ùëß1 ‚àí ùëß2)2                       (1) 
In this equation, x1 and z1 correspond to the position of the 
target while x2 and z2 to the final location of the arrow. The 
unit of measure for the experiment is Unity units, which are 
equivalent to meters (m). A score of less than 1 was 
considered a good score, as it hit within the center ring of the 
target, while a score between 1 and 2.5 was considered an 
acceptable score, as it hit the outer ring. A score of above 2.5 
missed the target and was considered a poor score. 
101
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

D. Head Tracking 
Another key to this research was the decision to perform 
head tracking. With an LFD, head movements change the 
view that the user is seeing, therefore moving around gives 
different viewing angles into the same scene. We believe that 
subjects will benefit from seeing these different views. Head 
movement is not required for the test though. A user can 
perform the entire test without moving their head enough to 
shift which view they are seeing. 
Two VIVE trackers were used to monitor the position of 
the subject‚Äôs head in relation to the position of the tablet. One 
tracker was placed on a stand so that it is positioned just below 
the tablet. The tracker sits 8 cm above the table, with the 
bottom of the tablet being 13 cm above the table and the top 
of the tablet being 30 cm above the table. The second tracker 
was attached to the user‚Äôs head via a head strap. This allowed 
for the user‚Äôs head position and rotation to be monitored both 
on their own, as well as in relation to the tablet, as seen in 
Figure 3. 
E. Experimental Procedure 
The procedure for the experiment was as follows. Firstly, 
the subject was sat at the table, put on the head tracker, and 
told what was expected of them as well as given a description 
and short demonstration of how the controller worked. Then 
they were given a practice scene and told to spend as much 
time as they needed to feel comfortable with how to control 
the arrow and move the camera but were instructed to not 
press the X button. Once they felt comfortable, they were 
instructed to press the X button and the test began. The subject 
performed the first four tests, then the experiment was reset, 
and the Light-field effect was either turned on or off, 
depending on which group the subject was in. After this, they 
were asked to do another four tests. Finally, they filled out a 
short questionnaire.  
Subjects sat 45-55 centimeters from the Lume Pad as seen 
in Figures 3 and 4. This is the distance that Leia Inc states is 
the best viewing distance for observing the stereoscopic visual 
cues that the Lume Pad produces. The tablet itself was 
positioned on a stand that was adjusted for each user to give 
them the best viewing angle. The subject‚Äôs horizontal position 
was not considered as the subjects were free to move to 
observe the different views displayed by the LFD. 
Subjects were separated into two groups. Group one 
performed the practice as well as the first four tests without 
the Light-field effect turned on, then the Light-field effect was 
turned on and they performed another four tests. Group two 
performed the practice and first four tests with the Light-field 
effect turned on, then it was turned off for the second four 
tests. 
III. HARDWARE AND SOFTWARE USED IN EXPERIMENT 
A. Lume Pad 
The following research was performed using a Lume Pad, 
an LFD tablet produced by Leia Inc. As discussed above, this 
allows users to see the illusion of depth inside a 2D screen by 
creating stereopsis. The tablet boasts a 10.1-inch screen with 
a resolution of 2560x1600 pixels.  
 
Figure 3. Experiment Setup. 
 
 
Figure 4. Subject Participating in Experiment. 
 
To create the light field effect, the tablet displays four 
views at the same time and uses lenticular lenses to allow the 
user to see two of these images at a time. If the user moves to 
the sides they will see two different images, thus creating a 
different view. In this way, the Lume Pad creates three views 
that can be viewed by changing the user‚Äôs viewing angle. 
To generate the different views, the Lume Pad stores four 
images internally as a single image file broken into a 2x2 grid. 
Due to needing to put four images into one screen, each image 
can only make use of one-quarter of the total resolution, so 
each view has a resolution of 640x400 pixels [6].  
One way to measure how much detail a screen can show 
is through pixel density.  This is calculated as follows, 
ùëÉùëÉùêº = 
ùê∑ùëñùëéùëîùëúùëõùëéùëô ùëñùëõ ùëÉùëñùë•ùëíùëôùë†
ùê∑ùëñùëéùëîùëúùëõùëéùëô ùëñùëõ ùêºùëõùëê‚Ñéùëíùë† 
 
 
   (2) 
ùê∑ùëñùëéùëîùëúùëõùëéùëô ùëñùëõ ùëÉùëñùë•ùëíùëôùë† = ‚àöùëäùëñùëëùë°‚Ñé2 + ùêªùëíùëñùëî‚Ñéùë°2           (3) 
The width and height pertain to the dimensions of the 
tablet. In this case, the Lume Pad has a width of 2560 pixels 
and a height of 1600 pixels. Given this, the pixel density of 
each image within an LFD image on the Lume Pad, is 75 
102
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

pixels per inch (ppi) which is small compared to the potential 
of the tablet without the Light-field turned on, which has a 
pixel density of 290 ppi. This is not a favorable comparison as 
the LFD uses only 25.9% of the pixels per image for each of 
its images, though this is to be expected and is a misnomer. 
For a more realistic comparison, the LFD can be compared to 
a standard computer monitor. A popular computer screen size 
is 24 inches with a resolution of 1920x1080 pixels, giving this 
screen a pixel density of 92 ppi. This is a much more favorable 
comparison for the Lume Pad with the LFD turned on, as it 
has 81.5% of the pixel density of a standard computer screen. 
The Lume Pad uses a few techniques to make the display 
appear to have a clear picture even with its slightly low 
resolution. These include having a smaller screen size 
compared to a desktop or laptop computer as well as the 
orientation of the lenticular lenses. These lenses are not 
aligned vertically but are instead slanted slightly. This allows 
for smoother transitions between views as well as allowing for 
vertical changes of view and not just horizontal changes of 
view. It has also been shown as an effective way to blend 
views together, making the user believe they are able to see 
more views than are being displayed [7].  
B. Sony Dual Sense Controller 
A Sony Dual Sense controller was chosen as the input tool 
for this experiment for a few reasons. Firstly, it is Bluetooth 
compatible, so it can easily connect to the Lume Pad. 
Secondly, it is a familiar controller in both shape and layout 
to many people as it follows a similar layout to popular home 
gaming systems. 
The directional pad (d-pad) on the left side of the 
controller, is used to control the arrow, allowing the user to 
aim it to the facing that the subject believes will hit the center 
of the target to the best of their ability. On the right side of the 
controller, the southern button, the X, on the controller, 
launches the arrow. The western button, the Square button, 
resets the test and the northern button, the Triangle button, 
turns the LFD effect on and off.  
The left stick controls the scene rotation, but it only rotates 
the scene camera around the center point on the horizontal 
axis. There is no way to move the camera on the vertical axis. 
This decision was made because the Lume Pad works best 
with multiple horizontal views and not multiple vertical 
views. The right shoulder button zooms the camera in while 
the left zooms the camera out. The full controller layout can 
be seen in Figure 5. 
C. Unity 
Our experiment was designed using the Leia Unity 
Software Development Kit (SDK) [8]. This SDK allows for 
the utilization of the Lume Pad‚Äôs features, such as the special 
Leia camera, as well as having the ability to turn the LFD on 
and off within the test. The Leia camera is four cameras, 
aligned in parallel with each other. Aligning the cameras in 
parallel is important to avoid the keystone distortion and depth 
plane curvature, as seen in Figure 6, that can occur with a toed-
in camera [9]. This distortion is not as visible at close range 
but at a longer range the image warps in a way that does not 
align with how human eyes naturally see the world.  
 
 
Figure 5. Sony Dual Sense Controller - Layout. 
 
 
 
 
            (a)  Keystone Distortion              (b) No Distortion 
Figure 6. Keystone Distortion. 
IV. PRELIMINARY  EXPERIMENT  
In the preliminary experiment, 12 subjects (3 females and 
9 males) were asked to fire an arrow at a target. Subjects were 
split into two groups, with group one testing with the Light-
field turned off first and then turned on, while group two did 
the same but in reverse. In that experiment, the subjects 
performed three tests, with the target being placed further 
away from the arrow with each test. Then the LFD was 
switched off or on, depending on the subject‚Äôs group, and 
three more attempts were performed. The data collected was 
103
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

the distance from the center of the target as well as the time it 
took for each attempt. 
A. Results 
The results can be viewed in Table 1. The scores are the 
median value of all attempts that each subject performed. The 
overall mean of the tests with the Light-field turned on, 1.881, 
was lower than when it was turned off, 2.264. This shows that 
overall, the subjects were on average more accurate with the 
Light-field turned on. Furthermore, we can see from this data 
that group two was more accurate than group one on average. 
Within the groups, another interesting point can be observed. 
Group one was more accurate on average with the Light-field 
effect turned on than with it off, with scores of 2.119 and 
2.666, respectively. Group two follows the same pattern, with 
scores of 1.644 with the Light-field turned on and 1.863 with 
it turned off.  
While it is tempting to state that this proves our hypothesis 
that stereoscopy increases the user‚Äôs understanding and thus 
their accuracy, this data does not allow us to state this. A two-
way ANOVA to analyze the effect of test order and the Light-
field effect on subject accuracy was performed. Simple main 
effects analysis showed that test order did not have a 
statistically significant effect on subject accuracy (p = 
0.1118). Similarly, the analysis showed that the Light-field 
effect did not have a statistically significant effect on subject 
accuracy either (p = 0.3305). 
The two-way ANOVA revealed that there was not a 
statistically significant interaction between the effects of test 
order and the Light-field effect (F(1, 20) = 0.1829, p = 
0.6735). 
These results show that the preliminary experiment 
strengthens the hypothesis that the stereo effect of the LFD 
was beneficial to the subjects, but the results were not 
conclusive. We observed that the first group did get more 
accurate when stereoscopy was added and that the second 
group was more accurate while using stereoscopy than 
without. The results of the ANOVA were a large problem 
though, as it is not clear that it is mainly the Light-field effect 
that is affecting subject accuracy. 
B. Improvements for the Main Experiment 
The most critical issue that needed addressing in further 
experiments was the precision of the controls. Some of the 
subjects stated that the controls were too imprecise to feel 
confident in their accuracy with these tests. Trying to make 
minute changes to the aim of the arrow proved difficult to 
achieve using the dual sense controller‚Äôs control stick. For 
some subjects, this was partially due to unfamiliarity with the 
controller. A control stick is intuitive to those that often play 
video games, but confusing to those who do not.  
Another reason is due to how hard it is to control an object 
when it has free movement in three dimensions. While some 
users were able to control the arrow without much effort, 
feeling that they understood where the arrow was pointing at 
all times, others constantly overcorrected their aim and had to 
try to bring it back to where they wanted the arrow pointing. 
This tested some subjects‚Äô patience, and a few seemed to 
decide they were close enough instead of trying to be as 
precise as possible. By making the controls more precise and 
easier to operate, we believe that users would be more 
confident in their accuracy with the test, and as such it would 
be clearer how much of a significant role the Light-field 
played in subject accuracy. 
Based on feedback and further research, changes were 
proposed to the scene itself. Moving the target closer to the 
arrow is one such change. In the preliminary experiment, the 
later tests placed the target at a distance that made it difficult 
to understand where it was on the small screen. 
Some scenery was removed as well, being one of the trees 
and a portion of the grass. The tree was deemed to be 
unnecessary as there were already enough obstacles blocking 
sight lines. The grass was there to give the user more visual 
cues to perceive motion parallax, but the amount of detail that 
the display needed to render was affecting its performance and 
we also worried that there were perhaps too many cues for the 
user [10]. 
In our previous paper, we discussed performing eye 
tracking as a possible addition to future research, but it was 
decided that head tracking would give more significant data 
than eye tracking. The reasoning behind this was that eye 
tracking would show eye vergence [11], giving a better 
understanding of how subjects‚Äô brains perceive the scene 
displayed on the LFD, while head tracking indicates the user‚Äôs 
interaction with the device. Head tracking was chosen over 
eye tracking because an LFD is a flat screen, so eye vergence 
will not be the same as if the scene was in real 3D and would 
likely behave as they were interacting with a standard 2D 
screen. Thus, head tracking was deemed to be more 
noteworthy. 
TABLE 1. PRELIMINARY EXPERIMENT RESULTS 
  
1
2.234
2.175
3
2.054
1.673
5
2.408
1.993
7
2.490
1.907
9
5.422
4.058
11
1.387
0.905
2
1.363
1.859
4
1.580
0.861
6
1.927
1.946
8
2.842
2.083
10
1.731
1.433
12
1.733
1.681
2.264
1.881
1.0935
0.8069
Mean
St.Dev
I
II
G
r
o
u
p
2.392
0.4729
1.753
1.2167
Subject
Without 
LFD
With
LFD
St.
Dev
Mean
Display
104
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

V. EXPERIMENT AND RESULTS 
 
For the experiment, there were 8 subjects (one 
female and seven males). They ranged in age from 22 to 27 
with an average age of 25. All had either normal or corrected-
to-normal vision. The experiment was carried out over two 
days, with subjects asked not to discuss the test with other 
subjects. Each subject was assigned a number, with odd-
numbered subjects placed in group one while even-numbered 
subjects were placed in group two. 
TABLE 2. MAIN EXPERIMENT RESULTS 
 
Figure 7. Interquartile Range 
A. Scores 
Table 2 displays the accuracy results of the experiment. 
From this table, it can be observed that on average, subjects 
were more accurate when they had access to stereoscopy, with 
the LFD effect turned on. On average with the LFD turned on, 
the average score was 1.189, which would miss the inner 
circle of the target by 0.189 meters. The low variance, the 
square of the standard deviation, of 0.381 means that this is a 
rather reliable estimation. With the LFD turned off, the 
subjects on average had a score of 1.189, which would hit the 
outer circle of the target, though with a high variance of 1.264 
this number is not as reliable as the results with the LFD on.  
Due to the small data set, another way to evaluate this data 
is by looking at the interquartile range. This is a look at the 
range of the inner two-quarters of the data. It is useful in small 
data sets by removing outliers and observing the distance 
between the data around the mean. When the LFD is turned 
off the interquartile range is 1.826, while with the LFD turned 
on the interquartile range is 0.760. Figure 7 visualizes this 
information. 
As with the preliminary experiment, a two-way ANOVA 
was performed to analyze the effect of test order and the 
Light-field effect on subject accuracy. Simple main effects 
analysis showed that test order did not have a statistically 
significant effect on subject accuracy (p = 0.6944). Similarly, 
the analysis showed that the Light-field effect did not have a 
statistically significant effect on subject accuracy either (p = 
0.4676).  
The two-way ANOVA revealed that there was not a 
statistically significant interaction between the effects of test 
order and the Light-field effect (F(1, 12) = 0.0091, p = 
0.9256). 
Figure 8 allows for a more visually direct comparison of 
the individual results of the two groups and the two tests. 
Within Group 1, shown in Figure 8 (a), subjects 3 and 5 both 
were more accurate when the Light-field was turned on for the 
second half of the experiment. Subjects 1 and 7 were less 
accurate, but both were still very accurate and did not miss the 
target.  
Group 2 is similar, as shown in Figure 8 (b), where 
subjects 2 and 8 are less accurate when the Light-field is 
turned off, subject 8‚Äôs third test is so far off the target it does 
not appear on the graph. Subject 4 is more accurate when the 
Light-field it turned off, and subject 6 appears to be the 
roughly the same over both tests. 
Furthermore, it can be seen that the target was missed 
twice with the Light-field effect turned on but was missed 
seven times with it turned off. The center ring was hit 14 times 
in both tests. 
 
1
0.318
0.519
3
1.321
0.722
5
3.454
1.640
7
0.641
1.218
2
1.467
0.742
4
0.462
0.912
6
1.998
1.343
8
2.748
2.412
1.551
1.189
1.1244
0.6174
Mean
St.Dev
Subject
Mean
St.
Dev
I
II
Display
1.0047
1.229
0.8159
1.511
Without
LFD
With
LFD
G
r
o
u
p
105
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
(a) Group 1 Accuracies. Light-Field Off, then On 
 
(b) Group 2 Accuracies. Light-Field On, then Off 
Figure 8. Accuracy Plot 
 
B. Head Tracking 
The head tracking data can be observed in Figures 9 (a) 
and (b). As only the horizontal distance changes the view that 
the subject sees within the LFD, the X value is the only 
variable that we have recorded in these graphs. Within the 
graphs, the distance, measured in centimeters, to the left or 
right of the centerline of the tablet is displayed. The distance 
traveled to the right is recorded as a positive value while the 
distance traveled to the left is recorded as a negative value. 
A comparison of subjects 1 and 7 shows the difference in 
how each interacted with the tablet. Subject 1 scored the best 
median accuracy over the Light-field tests, with a score of 
0.519. They actively moved their head while the Light-field 
effect was turned on, as seen in Figure 9 (a), moving close to 
thirty centimeters to either side of the centerline of the tablet 
at times. In comparison, subject 7, whose data can be seen in 
Figure 9 (b), tried a small head movement at the beginning 
and then moved very little until the end of the experiment. 
They had a median score of 1.218. While head movement may 
not have been the leading factor for this disparity in the two 
subject‚Äôs scores, it could possibly have affected them.  
C. Time Comparison 
Table 3 shows the median time spent by each subject for 
each test. Some subjects were quicker while others took more 
time. A further comparison of subjects 1 and 7, specifically 
looking at the times in which they were performing the Light-
 
 
(a) Active Subject During Light-Field Test (Subject 1)
 
(b) Inactive Subject During Light-field Test (Subject 7) 
Figure 9. Comparison of Active and Inactive Subjects 
 
field tests illustrates how much time some subjects felt 
they needed for each portion of the experiment. Overall, 
Subject 2 spent around 200 seconds performing this portion of 
106
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
(a) Subject 1, Shot 1 
 
(b) Subject 7, Shot 1
 
(c) Subject 1, Shot 4 
 
(d) Subject 7, Shot 4 
Figure 10. Head Movement Comparisons.
 
TABLE 3. TIME COMPARISON 
 
  
  
Subject 
Display 
Mean 
St.Dev 
  
  
Without 
LFD 
With 
LFD 
  
  
Group 
I 
1 
22.91 
24.90 
41.29 
23.870 
3 
73.57 
56.07 
5 
19.51 
12.26 
7 
54.89 
66.18 
II 
2 
12.26 
24.90 
30.52 
19.858 
4 
23.60 
29.10 
6 
66.18 
56.07 
8 
16.94 
15.13 
  
  
Mean 
36.23 
35.58 
  
  
  
  
St.Dev 
24.503 
20.729 
  
  
 
the experiment while Subject 7 spent around 350 seconds, 
over two minutes longer. For their first shot, Figure 10 (a), 
with the Light-field turned on, subject 1 spends a few seconds 
observing and interacting with the test before moving their 
head to look at the different views. At this point, they move 
10 centimeters to the left, then about 13 to the right. 
Afterward, they make much less drastic movements as they 
finish aiming the arrow. The process takes about 12 seconds. 
By contrast, in the exact same scenario, Figure 10 (b) shows  
that subject 7 spends the entirety of their first shot focusing 
on the scene and not utilizing the other views available if they 
moved their head.  Subject 7 took more than double the time 
that subject 1 took, at 27 seconds. A similar comparison can 
be made over their last shot. Subject 1 only makes one 
movement of around 15cm at about halfway through this 
shot. They take roughly 9 seconds to perform their final test. 
Subject 7 by contrast makes a similar movement four seconds 
into their final attempt which lasts 11 seconds. In both cases, 
subject 1 spends less time, and moves more. One 
interpretation of this is that subject 7 spent that time making 
up for not seeing the other views that Subject 1 utilized.  
D. Questionaire 
Subjects were also given a questionnaire to ascertain how 
well they believed they had understood the experiment. The 
questions were as follows: 
1) How confident were you that you would hit the center 
of the target with the LFD turned off? 
107
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 11. Confidence in Accuracy. 
 
2) How confident were you that you would hit the center 
of the target with the LFD turned on? 
3) Were you more confident with the LFD turned on, off, 
or neither? 
4) When the LFD was turned on, did you feel that moving 
your head to see the other viewing angles helped to 
improve your accuracy? 
5) Did you feel dizzy or sick at any time during the test? 
 
Figure 11 shows the results of the first two questions of the 
questionnaire. Subjects were asked to rank their confidence on 
a scale of 1 to 5, where 1 was not confident at all, 3 was 
somewhat confident, and 5 was extremely confident. Most 
subjects stated that they felt more confident with the Light-
field turned on. Although subjects 2, 5, and 8 ranked their 
confidence the same over both tests, they stated that they felt 
they were marginally more confident with the Light-field 
turned on than with the Light-field effect turned off.  
All subjects agreed that they did not feel that moving their 
head to see other viewing angles helped them. Finally, two 
subjects felt dizzy when the Light-field effect was turned off, 
though not so bad that they felt they needed to stop the 
experiment. 
VI. DISCUSSION 
Although subjects were encouraged to move their head to 
see the other views that the LFD generates, every one of them 
stated that they did not believe that doing this helped with their 
accuracy. While objects in the foreground and background 
would move as the view was shifted, the objects near the 
arrow and the target rarely did. The foreground movement 
was sometimes slightly helpful, but not enough to make a 
difference in user confidence. 
After further testing, it was concluded that the convergence 
distance was too short for the different views to have 
noticeable changes. The convergence distance is the distance 
from the camera where all camera points converge. One way 
to think about this is that whatever objects are set at the 
convergence distance are the focal point. In this test, that was 
set to be the arrow so that it was always in focus. In the 
preliminary experiment, the convergence distance was set at 
10 meters from the camera, and this led to 2 subjects saying 
that they felt they could not pull the camera very far from the 
arrow because then they were unsure of the direction that the 
arrow was facing. Because of this, both of them took what 
they believed to be too much time aiming the arrow for each 
test. 
A compromise would be to set the convergence point some 
distance behind the arrow. This would create more differences 
in the views. This causes the arrow to be less in focus, making 
it more difficult to be confident in knowing where the arrow 
is pointing exactly. With more testing, a good compromise can 
be achieved.  
Another option would be to increase the distance between 
each camera within the Leia camera. This causes a larger 
difference between each view from the Lume Pad, and also 
increases the feeling of stereopsis in the user, as the view 
given to each eye is spaced further apart. This is also 
dangerous though as if this is spread too far, it appears 
unnatural and can cause motion sickness. 
VII. CONCLUSION AND FUTURE WORK 
In this study, we examined the accuracy of a user‚Äôs 
understanding, given some constraints, with a 3D scene on an 
LFD in an attempt to show that the human brain understands 
a scene displayed on an LFD better than a standard 2D screen. 
While the subjects were more accurate with the Light-field 
turned on, it is not conclusive that the human brain 
understands simulated distance in the light field display more 
so than that simulated with a 2D screen. With the two-way 
ANOVA once again being inconclusive we are not able to 
say definitively that the reason that the subjects were, on 
average, more accurate with the Light-field on than with it 
turned off.  
To further this experiment, enhancing the change in views 
when the subject moves their head is the priority. Creating a 
stereoscopic viewing experience without the use of a headset 
is the most well-known feature of an LFD, but the fact that it 
can be viewed from multiple angles to see different views is 
a feature that should be further explored. Both changing the 
convergence distance as well as experimenting with 
increasing the distance between cameras should be fully 
explored in further work.  
Another feature that goes along with the LFD being able 
to show multiple views at one time is that it can be used by 
multiple people at the same time. This concept has been 
explored on large-scale LFDs, such as the 120-degree 
viewing angle LFD designed by Liu et al. [12]. This LFD is 
far more complicated than the Lume Pad, requiring vast 
amounts of space and hardware to set up. The Lume Pad has 
a much smaller optimal viewing angle but more than one user 
can still fit within this space. Finding a way to test how well 
two subjects can interact with and understand what is being 
shown to them with one Lume Pad would give us useful 
information for future work. 
An idea that would utilize this concept would be a cube-
style display. The pCubee, by Stavness et al. [13] is a 
multiscreen display comprised of 5 screens arranged in a cube 
formation, each connected to a control board. By using a head 
tracker and an accelerometer, the control boards change the 
108
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

view on each screen to create a believable 3d image without 
using stereopsis. Since the cube reacts to the user‚Äôs 
interactions, it feels like the user is looking into the cube and 
seeing real depth. By using Lume Pads, or a similar device, a 
similar experience could be created, without the need for the 
head tracker. Similar to the pCubee, an accelerometer would 
detect movements and inform the screens to change their 
views accordingly, while the lenticular lenses would display 
the extra views required for any head movements that the 
subject performs. It could also be designed to give multiple 
viewers the same experience at one time. Instead of directing 
all of the screens to one viewpoint, multiple viewpoints can 
be defined and the LFDs can create them at the same time. 
REFERENCES 
[1] R. Swannack and O. D. A. Prima, ‚ÄúAssessment of Differences 
in Human Depth Understanding Between Stereo and Motion 
Parallax Cues in Light-Field Displays,‚Äù The Fifteenth 
International Conference on Advances in Computer-Human 
Interactions, ACHI 2022, IARIA, pp. 18-21, 2022. 
[2] K. Kato and O. D. A. Prima, ‚Äú3D Gaze Characteristics in 
Mixed-Reality Environment,‚Äù eTELEMED 2021 : The 
Thirteenth 
International 
Conference 
on 
EHealth, 
Telemedicine, and Social Medicine, IARIA, pp.11-15, 2022. 
[3] J. E. Cutting and P. M. Vishton, ‚ÄúPerceiving Layout and 
Knowing Distances: The Integration, Relative Potency, and 
Contextual use of Different Information about Depth,‚Äù 
In Perception of Space and Motion, W. Epstein, S. Rogers, Eds. 
Academic Press, pp. 69-117, 1995. 
[4] A. Chirico, et al. ‚ÄúVirtual Reality in Health System: Beyond 
Entertainment. A Mini‚ÄêReview on the Efficacy of VR During 
Cancer Treatment,‚Äù Journal of Cellular Physiology, 231(2), pp. 
275-287, doi:10.1002/jcp.25117, 2015. 
[5] P. Benzie, et al. ‚ÄúA survey of 3DTV displays: techniques and 
technologies,‚Äù IEEE Transactions on Circuits and Systems for 
Video 
Technology, 17(11), 
pp. 
1647-1658, 
2007. 
doi:10.1109/TCSVT.2007.905377. 
[6] 3D Lightfield Experience Platform, https://www.leiainc.com/ 
[Retrieved at May 2022]. 
[7] C. Van Berkel, and J. A. Clarke, ‚ÄúCharacterization and 
Optimization of 3D-LCD Module Design,‚Äù Stereoscopic 
Displays and Virtual Reality Systems IV, 3012, pp. 179-186. 
SPIE, 1997. doi:10.1117/12.274456. 
[8] SDK and Developer Resources, www.leiainc.com/sdk. 
[Retrieved on 10 June 2022]. 
[9] A. J. Woods, T. Docherty, and R. Koch, ‚ÄúImage Distortions in 
Stereoscopic Video Systems,‚Äù Stereoscopic Displays and 
Applications 
IV, 
1915, 
pp. 
36-48, 
SPIE, 
1993. 
doi:10.1117/12.157041. 
[10] T. S. Murdison, G. Leclercq, P. Lef√®vre, and G. Blohm, 
‚ÄúMisperception of Motion in Depth Originates from an 
Incomplete Transformation of Retinal Signals,‚Äù Journal of 
Vision, 19(12), pp. 21-21, 2019. doi:10.1167/19.12.21. 
[11] C. Elmadjian, P. Shukla, A. D. Tula, and C. H. Morimoto, ‚Äú3D 
gaze estimation in the scene volume with a head-mounted eye 
tracker,‚Äù Proc. Workshop on Communication by Gaze 
Interaction, pp. 1-9, 2018. doi:10.1145/3206343.3206351. 
[12] B. Liu, et al. ‚ÄúTime-multiplexed light field display with 120-
degree wide viewing angle,‚Äù Optics Express, 27(24), pp. 
35728-35739, 2019. doi:10.1364/OE.27.035728. 
[13] I. Stavness, B. Lam, and S. Fels, ‚ÄúpCubee: A Perspective-
Corrected 
Handheld 
Cubic 
Display,‚Äù 
Proc. 
SIGCHI 
Conference on Human Factors in Computing Systems pp. 
1381-1390, 2010. doi:10.1145/1753326.1753535.
 
109
International Journal on Advances in Life Sciences, vol 14 no 3 & 4, year 2022, http://www.iariajournals.org/life_sciences/
2022, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

