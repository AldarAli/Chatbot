MIRAGE: An E-repository of Medical Images for Learning Biomedical Informatics 
 
Xiaohong Gao 
School of Engineering and Information Sciences, 
Middlesex University 
London, NW4 4BT, UK 
x.gao@mdx.ac.uk 
Yu Qian 
School of Engineering and Information Sciences, 
Middlesex University 
London, NW4 4BT, UK 
y.qian@mdx.ac.uk 
 
 
Abstract— Although around 5 billion medical image studies 
were carried out in 2010, there is still a shortage of medical 
image databases that are available for students due to well-
know reasons. To this end, an online image repository, 
MIRAGE, has been developed for teaching and learning 
biomedical informatics, which accommodates collections of 
published medical images of both 2D and 3D. The facilities of 
domain-based, atlas-based, and content-based retrieval (CBIR) 
are implemented to proffer the search in the repository. The 
novelty of the system is that not only a collection of 3D brain 
images is warehoused, but also CBIR for 3D is developed 
coupled with 3D visualization, leading to a versatile 
educational material, leading to future tele-education. The 
initial evaluation of the repository by users of both research 
students and lecturers has proven its positive impact. 
 
Keywords - medical image data base; image retrieval; CBIB; 
image labeling. 
I. 
INTRODUCTION 
With the advances of Internet technology, e-learning and 
e-teaching have flourished and borne fruits in a number of 
applications. In recent years, many online learning systems 
are available to students and have played an important part 
in assisting them learning. These systems usually tend to be 
in general purpose in order to meet majority students’ need, 
e.g., institutional e-print repositories providing published 
materials of papers, reports, etc.. However, sometimes, 
subject-based databases are in demand by a number of 
groups, leading to the development of discipline-based 
systems. For example, an online system, ENDOCAS [1], 
has implemented imaging assisted surgery (IAS) systems to 
provide information help, action help and training help by 
offering assistance on planning surgical intervention, 
integrating mechanic components of the robots, and 
simulating complex environment for surgical training 
respectively. Whereas in [2], a medical image repository has 
been integrated with a web-based learning system, 
providing web-based tools to assign and assemble the 
contents of medical images. 
E-learning has not only offered a new way of learning, 
but also brings all the advantages that an internet can offer 
to the learning and teaching process, such as flexibility, 
accessibility and straightforwardness. On the other hand, 
however, although medical imaging has revolutionized 
health care delivery in the last 30 years, and around 5 billion 
medical imaging studies were conducted worldwide [3] in 
2010 alone, there are very limited numbers of online 
databases available, due to the well known reasons of 
patients’ privacy and security, prompting the development 
of purpose-built repository for the benefit of both students 
and lecturers.  
At Middlesex University in the UK, a new MSc 
programme was introduced in 2007 on BioMedical 
Modelling and Informatics (BMI) that has been attracting an 
increasing number of students. During the course of 
studying and conducting final projects, a large number of 
medical images had been employed in addition to many 
other forms of data. Following a successful bid to JISC [4] 
at the UK in 2009, an attempt to establish a subject-based 
repository started. The main aim of the online repository, 
MIRAGE, is to develop a subject-based repository of 
medical images, in the immediate term, benefiting MSc 
students who are on the programme of Biomedical 
Modelling and Informatics (BMI) at Middlesex University 
at the UK. It is anticipated the repository will be adopted by 
and serve the community in the middle term. As a result, 
MIRAGE, acronym of Middlesex Image Repository with a 
CBIR Archiving Environment, has been up and running and 
is available at [5].  
The structure of the paper is organized as follows. 
Methodology is detailed in Section II, which is followed by 
Evaluation of Section III. Proceeding Conclusions and 
Discussion, the Section of Results is given in Section IV. 
II. 
METHODLOGY 
Figure 1 demonstrates the interface of the system. 
209
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-179-3
eTELEMED 2012 : The Fourth International Conference on eHealth, Telemedicine, and Social Medicine

 
 
 
 
Figure 
1. 
The 
interface 
of 
MIRAGE 
system 
at 
http://image.mdx.ac.uk/vin/demo.php . Top: menu interface; bottom: 
retrieval results for a query. 
 
The repository began with the ingestion of a large 
collection of medical images into the existing server that 
then had only archived a few hundreds of images of limited 
domains. Since many image data are without any textual 
labeling, archiving image data is different from that to 
textual files that can be indexed using a few key words 
embedded in the files. This deposition stage hence included 
the establishment of both feature and image databases.  A 
number of approaches in extracting features had been 
applied in pre-processing images. By building on from an 
open source software GNU GIFT (GNU Image-Finding 
Tool [6], the online system currently not only facilitates a 
means to search images by their contents, notably content-
based image retrieval (CBIR), but also interfaces with 
OASIS+, the online teaching system at Middlesex 
University to ensure it can be accessed easily.  
The system at present accommodates over 100,000 
images. All the collected images in the server comply with 
the informed consent requirement and consist of 2D medical 
images, 3D brain images (CT, MR and PET) and 4D 
cardiovascular ultrasound images. MIRAGE adapts an open 
framework of GIFT for the retrieving of 2D medical images. 
By introducing the automatic image annotation, MIRAGE 
offers the possibility of combining visual content with 
keywords to achieve the higher level of semantic search. In 
addition, MIRAGE has developed its own method for 3D 
brain images retrieval to complement to the existing 2D 
medical image repositoryCBIR for 3D Brain Images. 
 
A. The System 
 
Figure 2 illustrates the infrastructure of MIRAGE. To 
address the problems that current text-based image retrieval 
systems suffer, MIRAGE integrated the methods of both 
content-based image retrieval (CBIR) for 2D and 3D 
collections and automatic image annotation to label the 
images with its keywords, leading to a higher level of 
semantic search. It therefore consists of three modules as 
shown in Figure 2, with components of image annotation, 
2D image retrieval and 3D image retrieval.  
 
 
Figure 2. The Framework for MIRAGE. 
 
Built on the open source GNU Image Finding Tool 
(GIFT), the online database is based on the Query-by-
Example (QBE) paradigm coupled with user-relevance 
feedback facility whereby retrievd images most closely 
resemble a query image in appearance (i.e., the content that 
an image is carrying). Two algorithms have been 
implemented for indexing image collections, which are IDF 
(Inverse Document Frequency) and Separate Normalisation. 
IDF is a classical method and is based on counting the 
number of documents in the collection being searched, 
which contain (or are indexed by) the terms in question [3]. 
The inverted-file database system has been applied in text 
retrieval systems, giving rise to the efficiency when 
210
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-179-3
eTELEMED 2012 : The Fourth International Conference on eHealth, Telemedicine, and Social Medicine

employed in an image system. The weighting features are 
calculated as in Eq. (1) [7]. 
 
                    
 
 ∑
       
 
   
      
 
     
              ∑                        
 
          (1) 
 
where tfij is the term frequency of a feature in either a query 
or a resultant image, cfi the collection frequency of a feature,  
whereas q is a query containing N images (i = 1,2…N) with 
relevance Ri = 1(relevant) or -1(irrelevant). In addition, k is 
a retrieved image, j the index of a feature, and R the user-
relevance of a query image with value between [-1,1]. 
On the other hand, feature normalisation is required to 
compensate the scale disparity between the feature 
components that are defined in different domains. On the 
client side, a web page based interface is given. Whist the 
client-server communication is achieved using the XML-
based Multimedia Retrieval Markup Language (MRML). 
All client-server communication, including queries from the 
client or results returned by the server, is realised using 
message passing. Consequently, the client can be 
implemented in any programming language. The current 
MIRAGE client is implemented using PHP (Personal Home 
Programming) language to generate dynamic web pages for 
the client web browser.  
 
B. Image Annotation based on Domains 
One feature that the MIRAGE has is its ability of image 
annotation fully automatic, in order to achieve a higher level 
of semantic search, and to organize and categorize images 
of interests. Automatic image annotation is the process by 
which a computer system automatically assigns metadata in 
the form of captioning or keywords to a digital image. At 
present, the Bag-of-visual-Words (BoW) [8] paradigm 
becomes very popular and has been successfully applied for 
image categorization. By transforming images into a set of 
‘visual vocabulary’, images are represented using the 
statistics of the appearance of each word as feature vectors, 
upon which the learning of an image classification rule 
could be achieved as a classifier. This idea has been adopted 
in the MIRAGE system coupled with SIFT sparse coding 
approach [9], which is achieved in the following four steps 
that is also illustrated in Figure 3. 
 
Step 1 -- the visual features are extracted from 
local patches of each image in the training dataset 
, leading to the construction of  a visual dictionary 
of codebook; 
 
Step 2 -- to quantize the visual features of the 
image dataset into discrete ‘visual words’.; 
 
Step 3 -- an image is represented as a unique 
distribution (e.g. a histogram) over the generated 
dictionary of words; and 
 
Step 4 -- image representations of the training 
dataset obtained in Step 3 are applied to train the 
classifiers using supervised machine learning 
methods. 
Finally, 
the 
trained 
classifier 
automatically 
allocates 
new 
images 
into 
corresponding categories and hence labels them. 
 
 
Figure 3. Dictionary construction and image representations. 
 
Unlike traditional BoW paradigm, sparse coding is 
employed in the MIRAGE instead of vector quantization 
(VQ) to extract the SIFT descriptors of local image patches. 
Furthermore, instead of using histograms, multiple scales of 
max pooling are employed as an image representation by the 
use of simple linear support vector machines (SVMs).  In 
comparison with the SVMs using nonlinear kernels, e.g. 
histogram 
intersection 
kernels, 
linear 
SVMs 
can 
dramatically 
reduce 
the 
training 
complexity 
while 
maintaining a good performance.  
 
C. CBIR for 3D Brain Images 
For 3D brain images, four texture based methods are 
implemented as shown in Figure 4, including , 3D Local 
Binary Pattern (LBP), 3D Grey Level Co-occurrence 
Matrices (GLCM), 3D Wavelet Transforms (WT) and 3D 
Gabor Transforms (GT) as detailed in [10, 11]. Figure 5 
depicts the flowchart of CBIR for 3D images.  
 
211
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-179-3
eTELEMED 2012 : The Fourth International Conference on eHealth, Telemedicine, and Social Medicine

 
 
Figure 4. The interface of 3D images retrieval with four texture-based 
methods (arrowed) and visualization. 
 
 
 
Figure 5. Framework for Content-based 3D Brain Image Retrieval 
 
As shown in Figure 5, the collection of 3D brain images 
firstly underwent a pre-processing stage to normalize them 
into the same resolution before the indexing stage.  After 
spatial normalization of volumetric brain data into a 
standard template, the data are then divided into 64 non-
overlapping equally sized blocks, from which, 3D texture 
features are extracted to create a feature database. On the 
query side, a pre-processing stage is introduced to detect the 
potential VOI of lesions after spatial normalization from a 
query image. Subsequently, the extraction of 3D texture 
features from a query only takes place from these potential 
sub-blocks that, in the retrieval stage, are in turn compared 
with the corresponding features in the feature database to 
obtain retrieval results. Figure 6 demonstrates an example 
retrieved using different texture approaches [12]. 
 
 
 
Figure 6. Retrieved results in top 5 ranking from  
3D GLCM (row 1), 3D WT(row 2), 3D GT (row 3), and 3D LBP (row 4). 
 
The judgement of each approach is subject to the 
applications of the retrieval task as to which of the measures 
of size, location or shape plays more important role than the 
others. 
 
III. 
EVALUATION 
The system evaluation is carried out from both objective 
and subjective prospects. As an objective evaluation, a 
number of statistic measures are applied to evaluate the 
research methods, such as Average Accuracy Rate (AAR) 
for image classification and Mean Average Precision (MAP) 
for image retrieval. On the other hand, the subjective 
evaluation is accomplished by using a survey questionnaire 
conducted by the students and researchers/lecturers at MU 
who have employed the medical image repository MIRAGE 
in their teaching and research. 
To assess the effectiveness of image classification, a 
confusion matrix is firstly created as explained at [13]. Then 
with regard to the performance of image retrieval, 
traditional measures of Precision (P) and Recall (R) are 
worked out. By representing P-R graph using one value, 
MAP value is applied to measure overall performance for all 
queries and is calculated as Eq. (2). 



M
i
i
AP
M
1
1
Mean Average Precision (MAP)
        (2)                      
where M  is the total number of the queries, 
i
AP  is the AP 
value for the ith query, which is formulated as Eq. (3). 



r
N
j
j
r
P
N
1
1
 Precision (AP)
Average
     
   (3)                      
Upon which 
r
N  is the total number of relevant images in a 
dataset for a query, and
jp  is the precision when retrieving 
212
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-179-3
eTELEMED 2012 : The Fourth International Conference on eHealth, Telemedicine, and Social Medicine

the jth relevant image. A P-R graph together with a MAP 
value is therefore applied to evaluate the performance of 
CBIR for 2D and 3D images in this project. 
In addition, an on-line questionnaire as given on the 
interface (e.g., the bottom line at Figure 1) is designed in the 
hope to subjectively evaluate and further improve the 
system.  The questionnaire consisted of 15 questions 
organized in three categories on i) the general information 
on the use of MIRAGE; ii) the evaluation of system 
usability; and iii) the comments/recommendations in 
regarding to the features of MIRAGE.   
 
IV. 
RESULTS 
A. Results on Image Annotation 
 
In order to train a codebook for image annotation, a 
training dataset is firstly selected containing 1000 images 
that are randomly chosen from our medical image 
repository. Then 200,000 random patches are collected from 
these images. Subsequently, from each patch, SIFT 
descriptors are extracted, yielding a feature database that has 
the size of 200,000*128 elements, which are finally applied 
to train the codebook with the size of 1024*128 in terms of 
feature vectors.  
With respect to ground truth for image annotation, six 
domain names are defined at the highest level, including 
brain, lung (x-ray), microscopy, abdomen, ultrasound and 
graph respectively. Each category is allocated 100 images as 
ground truth with each half as being training and testing sets 
respectively. The classification results for the six categories 
are visualized in a confusion matrix in Table 1. 
 
TABLE 1: CONFUSION MATRIX FOR THE SIX MEDICAL IMAGE 
CATEGORIES, WHERE B, L, M, A, U, G REPRESENT CATEGORIES 
OF BRAIN, LUNG, MICORSCOPY, ABDOMEN, ULTRASOUND, 
AND GRAPH 
 
 
 
Classification Results 
AR 
(%) 
 
 
B 
L 
M 
A 
U 
G 
Brain 
48 
0 
2 
0 
0 
0 
96 
Lung 
(x-ray) 
0 
50 
0 
0 
0 
0 
100 
Microscopy 
0 
0 
49 
0 
1 
0 
98 
Abdomen 
0 
0 
0 
50 
0 
0 
100 
Ultrasound 
0 
0 
0 
0 
50 
0 
100 
Graph 
0 
0 
0 
0 
0 
50 
100 
ER(%) 
0 
0 
3.92 
0 
1.96 
0 
 
 
The values in the last column of Table 2 are the 
Accuracy Rate(AR) values for each class, whereas the 
values in the last row are the Error Rate(ER) for each class. 
The Average Accuracy Rate (AAR) for all classes is 99% 
(297/300), and Average Error Rate (AER) is 1% (3/300), 
demonstrating the approach of annotation being very 
efficient.  
 
B.  Results for 3D image retrieval with CBIR 
 
Figure 7 plots the average Precision Recall Graph for ten 
queries across the whole datasets (around 100 of 3D MR 
brain images). The MAP and average query time by using 
the approaches of 3D GLCM, 3D WT, 3D GT and 3D LBP 
are given in Table 3.  The query time amounts to the time 
spending on both feature extraction and retrieval, the results 
based on the programs that are written in MATLAB R2009a 
running on a computer with specifications of Intel P8600 
CPU of 1.58GHz with 3.45GB RAM.   
 
 
 
  Figure 8. Average precision recall graph for ten queries.  
 
TABLE 2. MAP AND QUERY TIME FOR 4 TEXTURE 
REPRESENTATION METHODS. 
 
Methods 
Mean Average 
Precision 
(MAP) 
Query time 
3D GLCM 
0.690 
10.96s 
3D WT 
0.749 
1.22s 
3D GT 
0.691 
10.77m 
3D LBP 
0.786 
0.21s 
 
The above results show the approach of LBP not only 
can achieve precision rate by up to 78% but also can 
perform retrieval in real time with sub-second speed. All 
these four methods are implemented in the system giving 
users the choices. 
 
C.  Results on Subjective Evaluation  
 
An on-line questionnaire is applied to subjectively 
evaluate and thereafter further improve the system. This 
questionnaire comprises three parts covering the general 
impression of the repository, system evaluation and 
comments on the system respectively. This survey has been 
carried out by MSc students and researchers at MU, by 
which a total of 15 people participated.  
213
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-179-3
eTELEMED 2012 : The Fourth International Conference on eHealth, Telemedicine, and Social Medicine

In terms of expectations, all respondents 'agreed' (80%) 
or 'strongly agreed' (20%) with the retrieved results, 
suggesting that the system meets users’ expectations. They 
all 'agreed’ (30%) or 'strongly agreed' (70%) that the system 
was fast and easy to use, and was useful to teaching and 
learning. On the other hand, users of 60% and 40% strongly 
agree or agree that the system is useful for teaching and 
learning.  
 
V. 
CONCLUSION AND DISCUSSION 
This project integrates the existing technologies to 
implement a versatile, useful and easy to operate system for 
teaching and learning, The techniques include GIFT 
framework for CBIR and image annotation using SIFT 
sparse codes while developing its own re-useable module 
retrieval and visualization of 3D brain images.  
Works on 4D ultrasound images with CBIR facility 
currently is underway with future working including 
visualization of 3D video images (=4D) while performing 
the retrieval. 
With respect to the issue of security, the system is 
controlled via password. Because it is not connected to any 
clinical systems and the images are without any 
identifications, the risk to patients’ privacy is very limited. 
Furthermore, all collections are from published work on the 
search of implying information in images, i.e., data mining. 
With this in mind, the developed system MIRAGE is wide 
open to the communities of research, learning and teaching, 
especially when remote teaching and leaning prevail. 
On the other hand, the source code for 3D image retrieval 
and visualization are to be realised to the public to benefit 
the community that are carrying out similar work. 
 
ACKNOWLEDGEMENT 
This work is financially funded by the research council JISC at 
the UK, their support is gratefully acknowledged. The authors 
would also like to thanks all those MSc students and staff at 
Middlesex University who took part in the evaluation survey. 
 
REFERENCES 
[1] www.endocas.org. 01.12.2011. 
 
[2] C.H. Hsiao, T.C. Hsu, J.N. Chang, S.J.H. Yang,  S.T. Young 
and W.C. Chu, Developing a medical image content 
repository for E-Learning, Journal of Digital Imaging, Vol. 
19 (3), pp. 207-215, 2006. 
 
[3] www.jisc.ac.uk. 01.12.2011. 
 
[4] C.A. Roobottom., G. Mitchell and G. Morgan-Hughes, 
Radiation-reduction 
strategies 
in 
cardiac 
computed 
tomographic angiography. Clin Radiol 65 (11), pp. 859–67, 
2010. 
 
[5]  http://image.mdx.ac.uk. 01.12.2011 
 
[6] http://www.gnu.org/software/gift/gift.html. 01.12.2011. 
 
[7] S. Robertson, Understanding Inverse Document Frequency: 
On theoretical arguments for IDF, Journal of Documentation, 
60 (5), pp. 503–520, 2004. 
 
[8]  H. Müller, W. Müller, D.M. Squire, Z. Pecenovic, S. 
Marchand-Maillet and T. Pun, An open framework for 
distributed multimedia retrieval. Technical Report 00.03, 
Computer Vision Group, Computing Group, University of 
Geneva, 
rue 
Gnral 
Dufour, 
24, 
CH-1211 
Geneva, 
Switzerland, 502, 503, 2000. 
 
[9] V. Viitaniemi and J. Laaksonen,  Spatial Extensions to Bag 
of Visual Words, VIVR’09, 2009, Santorini, Greece. 
 
[10] J. Yang, K. Yu, Y. Gong and T. Huang, Linear Spatial 
Pyramid Matching Using Sparse Coding for Image 
Classification, 2009 IEEE Conference on Computer Vision 
and Pattern Recognition, 2009, Miami, USA. 
 
[11] X.W. Gao, Y. Qian, M. Loomes, R. Comley, B. Barn, A. 
Chapman, and J. Rix, Texture-based 3D image retrieval for 
medical applications, IADIS e-Health2010, 2010. 
 
[12] Y. Qian, X.W. Gao , M. Loomes, R. Comley, B. Barn, R. 
Hui, and Z. Tian, The Third International Conference on 
eHealth, Telemedicine, and Social Medicine, eTELEMED 
2011, 2011.  
 
[13] R. Kohavi and F. Provost, , Editorial for the Special Issue on 
application of machine learning and the knowledge of 
discovery process, Machine Learning 30, pp. 271, 1998. 
 
 
 
 
 
 
214
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-179-3
eTELEMED 2012 : The Fourth International Conference on eHealth, Telemedicine, and Social Medicine

