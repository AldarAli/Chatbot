Towards Semantic Analysis of Training-Learning Relationships                                  
within Human-Machine Interactions    
 Farshad Badie
   Center for Linguistics, Aalborg University,
Aalborg, Denmark. Email: badie@id.aau.dk  
Abstract— In this article First-Order Predicate Logic (FOL) is 
employed for analysing some relationships between human 
beings and machines. Based on FOL, we will be conceptually 
and logically concerned with semantic analysis of training-
learning relationships in human-machine interaction. The 
central focus is on formal semantics and its role in the 
‘relationship’ between human beings and machines. The 
analysed relationships between a human being and a machine 
will support our thoughts on and contemplations over the 
HowNess of establishing formal semantics within human-
machine interaction. 
Keywords: Semantics; Training-Learning Relation; 
Human-Machine Interaction; Predicate Logic.  
 I. INTRODUCTION AND MOTIVATION   
Machine Learning is a subfield of Artificial Intelligence 
and Computer Science. A machine learning approach 
attempts to develop appropriate procedures and techniques 
that allow machines to improve the productivity of their 
performances concerning a given goal, see [8]. In [2], we 
have focused on conceptual analysis of human-machine 
interactions and we have provided a conceptual and 
epistemological junction between human beings’ minds and 
machines’ knowledge bases. According to [6], and relying 
on our epistemological approach, the multilevel interactions 
between a human being (as a trainer) and a machine (as a 
metaphorical learner) could be seen as a radical 
constructivist account of human cognition, realisation and 
comprehension. Let me bring up some fundamentals in 
order to clarify our conception and way of thinking about 
the metaphorical use of ‘learning’. In the expression 
‘machine learning’, the word ‘learning’ has been utilised as 
a binary predicate with the word machine. Learning as a 
binary predicate has been asserted to be a role that is being 
performed by a machine. Thus, the act of ‘learning’ for a 
machine could be interpreted as a reflection of the [human] 
learning phenomenon in machines. In fact, machine learning 
is a metaphor that attempts to simulate the learning 
phenomenon with regard to the ingredients, components and 
concepts that are concerned with effective and successful 
learning processes in the real world. Let me bring the notion 
‘concept’ into our explanation and be more specific on this 
research’s objectives. ‘Machine concept learning’ 
approaches try to provide appropriate realisable logical 
descriptions for a human being’s constructed concepts and 
their interrelationships after being transformed (from a 
human’s mind into a machine’s knowledge base) with 
regard to their structures and to their interrelationships to the 
world. Note that ‘concept’ is a complicated term. We see a 
concept as a linkage between a human’s mental images of 
parts of reality (as things/phenomena), on the one hand, and 
a human's linguistic expressions and statements concerning 
those things/phenomena on the other hand, see [4]. In [2], 
we have explained that concepts are transformed in order to 
be represented and expressed within a machine’s knowledge 
base. For instance, concepts can be reflected in order to be 
represented in the form of the entities as classes of 
individuals and objects. In other words, a concept is 
understood and is seen as an idea that can be transformed 
into a hypothesis in order to correspond to a distinct entity 
[and, respectively, to a group of entities] or to its [and their] 
essential attributes, features, characteristics and properties. 
The hypotheses can describe multiple theories based on 
terminologies and world descriptions. Accordingly, they 
support inferential and reasoning processes and satisfy 
multiple conditions for definitions of truth with regard to 
interpretation functions. 
 In this article, we will employ First-Order [Predicate] 
Logic in order to focus on relationships between human 
beings and machines. FOL allows us to make arbitrarily 
complex relationships between different objects of a system. 
Based on FOL we will be conceptually and logically 
concerned with semantic analysis of training-learning 
relationships in human-machine interactions. We shall stress 
that our main focus is on the semantics of the ‘relationships’ 
between human beings and machines. The analysed 
relationships between a human being and a machine will 
support our thoughts about the HowNess of establishing a 
[formal] semantics concerning human-machine interactions. 
According to [3], semantics is the study of the meanings, 
and the relation of signs to the objects to which the signs are 
applicable. 
In the following sections you will be offered the 
following: (III) The Logical Specification of the Notion of 
Hypothesis, (IV) Preliminaries: Predicate Logic and 
Semantics in FOL, (V) Formal Representation and Semantic 
Analysis of ‘Training-Learning’ and (VI) Conclusions and 
Future Work.   
II. THE LOGICAL SPECIFICATION OF THE NOTION OF 
HYPOTHESIS   
Based on Predicate Logic and focusing on Description 
Logics [1], an unary predicate is supposed to be logically 
equivalent to a concept. For instance, we can consider the 
unary predicate Set as a concept in order to employ it in 
323
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

concept learning (concept expression) processes. 
Additionally, a concept can be logically described by a 
hypothesis, see [5][8]. For instance, the concept Set can be 
described as a collection of the distinct things in order to 
provide a foundation for a hypnosis. And, for instance, {a , 
5, Science, ∞, ∑} and {Book, ●} could be the positive 
(constructive) examples of the proposed hypothesis, and ‘{3 
, T’ and ‘Y’ could be the negative examples of the proposed 
hypothesis. In our opinion, (i) analysing the supportive 
inferential processes on a hypothesis, and (ii) focusing on 
world descriptions using generated hypotheses relying on 
defined terminologies, could collectively determine the 
applications of predicates, and, subsequently, the 
applications of terms and statements. Conceptually and 
logically the hypotheses focus on describing the predicates. 
Then they are expected to describe the same attributes, 
characteristics and properties. According to [8], a hypothesis 
as a logical description of a concept, arises during a machine 
learning process. Actually, it is a tentative explanation of 
why the objects are members (or non members) of the 
concept. A characteristic feature of most concept learning 
approaches is the use of background knowledge. In concept 
learning with background knowledge, a machine, with 
regard to the given set of training examples and background 
knowledge, will focus on hypothesis generation. 
III. PRELIMINARIES: PREDICATE LOGIC  
The Propositional Logic and its formulae (i.e., the 
formal and mathematical relationships or rules expressed in 
Propositional Logic's symbols) are constructed based on 
atomic objects. Note that the atomic objects, and, 
accordingly, the propositional formulae, could only be either 
true or false. First-order Predicate Logic (FOL) is 
constructed over propositional logic by seeing objects as the 
elements of sets and by applying universal and existential 
quantifications (restrictions). That’s why some logicians and 
mathematicians see FOL as Quantification Theory, see [7]
[9]. FOL allows us for making arbitrarily complex 
(specified) relationships between various objects. There are 
two kinds of symbols in FOL; (i) logical symbols and (ii) 
non logical symbols. The set of logical symbols in FOL is 
{Conjunction (∧), Disjunction (⋁), Negation (¬), 
Implication (→), Bi-conditional (⟷), Equality (=), 
Existential Restriction (∃), Universal Restriction (∀), 
Tautology (⊤), Contradiction (⊥), Parentheses and 
brackets}. We shall stress that logical symbols always have 
the same meaning. It means that we are not allowed to 
interpret them and assign multiple values and definitions to 
them. The non logical symbols are represented in the 
following forms: 
(i) Constant Symbols. For instance, john, 0 and blue are 
constant symbols. 
(ii) Unary Predicates. In P(x) and Q(y), P and Q denote 
unary predicates. Also, x and y are variables (multiple 
constant symbols). These variables are the instances of P 
and Q. For instance, Person(john) denotes that ‘John is a 
person’. 
(iii) Binary Predicates (Relations). R(m,n) is a binary 
predicate and makes a relation between two variables m 
and n. For example, Equals(m,n) can represent the 
‘equality between m and n’ (i.e., m equals n).  
(iv) Function Symbols. f(x) is a function that operates the 
variable x. For example, mother(john) can represent the 
‘mother of john’. 
At this point we shall draw your attention to the fact that 
the meanings of the non logical symbols are dependent on 
human being’ interpretations. So, we need to interpret the 
non logical symbols to produce meanings and to clarify 
what we mean by them. 
A.
Semantics in FOL 
In formal languages  semantics is the study and analysis 
of the meanings of symbols and signifiers. Semantics focuses 
on the relationships between the signifiers of any language. 
In fact, the formal semantics employs the products of the 
human beings’ interpretations in order to produce meanings. 
In fact, we need to consider the interpretation I that consists 
of (i) the domain of interpretation (that is a non empty set 
like D) and (ii) an interpretation function (like ▪
I) that 
interprets the domain D in order to analyse the formal 
semantics of a term in FOL. For example, D = {Bob, Mary, 
Julian} could be interpreted (D
I) to represent the list of three 
PhD researchers in Metaphysics. Obviously, a meaning has 
been produced. Formally, the interpretation function assigns 
to every atomic unary predicate P (e.g., Apple, Red), a set 
like P
I ⊆ D
I. For instance, the interpretation of Apple (Apple
I) 
could express that “Apple is a Fruit and could be eaten”. 
Also, the interpretation function assigns to every atomic 
binary predicate R (e.g., Equals) a binary predicate R
I ⊆ D
I × 
D
I. For instance, the interpretation of Equals (Equals
I) could 
express that “Equals describes a kind of alignment between 
its right-hand side and its left-hand side”.  
Here we feel the need to describe the logical conception 
of equivalence relationship between two predicates. Two 
unary predicates (either atomic or non atomic) P and Q are 
equivalent (P ≡ Q), when for all interpretations I we have P
I 
=
 Q
I. On the other hand, they are not equivalent when there 
exists an (at least one) interpretation like J such that P
J ≠
 Q
J . 
IV. TRAINING-LEARNING: FORMAL REPRESENTATION   
In this section, the central focus is on conceptual and 
logical analysis of formal semantics within a training-
learning relationship in the context of human-machine 
interactions. This research aims at investigating where the 
formal semantics come from and when it appears within a 
relationships between a human being and a machine. 
Considering the human being as the trainer and the machine 
as the metaphorical learner, accept the following axioms. 
These axioms focus on the non logical symbols of our 
324
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

formalism. They are the main building blocks of this 
research.  
• The symbols h and m denote human being an machine 
respectively. They both represent constant symbols. 
• The most significant unary predicates in our formalism 
are Learner and Trainer. Also, Learner(m) and Trainer(h) 
represent two unary predicate assertions (world 
descriptions over unary predicates). They demonstrate that 
the constant symbol m is an instance of the unary 
predicate Learner and the constant symbol h is an instance 
of the unary predicate Trainer. In other words, m is a 
Learner and h is a Trainer. 
• Considering the unary predicates Learner and Trainer, 
the binary predicates TrainerOf and LearnerOf are 
defined. Consequently, TrainerOf(h,m) and 
LearnerOf(m,h) are two binary predicate assertions (or 
relation assertions, or world descriptions over binary 
predicates). The first relation describes that the human 
being h is the trainer of the machine m and the second one 
describes that the machine m is the learner of the human 
being h. 
• Two functions trainer(m) and learner(h) are defined in 
order to represent the ‘trainer of m’ and the ‘learner of h’. 
A.
Semantic Analysis  
According to the proposed axioms and to the non logical 
symbols, we shall claim that the binary predicate 
TrainerOf(h,m) logically produces (implies) the equality 
trainer(m) = h. In fact,  
TrainerOf(h,m)      (i) 
⇒  trainer(m) = h .     (ii) 
The equation (ii) expresses the fact that the trainer of the 
machine m has been realised to be the person h. Note that 
this equality is produced with regard to our interpretation. In 
fact, it has been achieved based on the interpreted non 
logical symbols. Therefore, the equation (i) as a binary 
predicate, describes the interpreted relation between 
trainer(m) and h. We may claim that this equality is the root 
of the formal semantics within a training-learning 
relationship. The binary predicate equality describes that the 
meanings of its right-hand side and its left-hand side are the 
same. Consequently, the meaning of trainer(m) and h are the 
same. So, we shall emphasise that the achieved equality [as a 
binary predicate in FOL] aligns the meaning of trainer(m) 
and the meaning of h. Then we have:   
Equals (trainer(m) , h).      (iii) 
We shall maintain that the binary predicate (iii) has 
provided a supportive background for introducing the formal 
semantics. Considering this binary predicate, the function 
trainer(m) (as a non logical symbol) and the individual h (as 
a constant symbol) have been supposed to have the same 
meanings. Additionally, regarding the commutative laws, 
‘the trainer of m is h’ and ‘h is the trainer of m’ are logically 
equivalent [and, thus, meaningfully, they are equal]. 
Consequently, ‘the trainer of m implies h’ and ‘h implies the 
trainer of m’. Therefore: 
trainer(m) = h  ⇒ 
( trainer(m) → h )  ∧  ( h → trainer(m) ).      (iv)  
The logical term (iv) is inherently equal to: 
(function → constant) ∧ (constant → function).      (v)  
We have already deduced that the term ‘a function 
symbol implies a constant symbol and a constant symbol 
implies a function symbol’ supports the analysis of our 
objective. Note that the term (iv) has been deduced based on 
the binary predicate TrainerOf(h,m) (or (i)). Then, there is a 
bi-conditional relation between (i) and (iv). Therefore: 
TrainerOf(h,m)   ⟷  
[ ( trainer(m) → h ) ∧ ( h → trainer(m) ) ].      (vi) 
Equivalently: 
TrainerOf(h,m)  →   
[ (trainer(m) → h ) ∧ ( h → trainer(m) ) ]  
AND 
[ ( trainer(m) → h ) ∧ ( h → trainer(m) ) ]  →   
TrainerOf (h,m).      (vii) 
The logical term (vii) is structurally equal to:  
Relation  →  
[ ( function → constant )  ∧  ( constant → function ) ]   
AND 
[ ( function → constant )  ∧  ( constant → function ) ] → 
Relation.      (viii) 
In Figure 1, this logical conclusion has been figured out. 
Conceptually, taking the afore-mentioned conclusions 
into consideration, we need to focus on four fundamental 
relationships: (I) The training relationship between human 
Fig.1.  The General Structure of Semantics within 
Relationships Between Human Being & Machine
325
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

and machine (from human into machine), (II) The learning 
relationship between machine and human (from machine 
into human), (III) The iterative loops between human and 
machine (from human into machine and from machine into 
human), and (IV) The iterative loops between machine and 
human (from machine into human and from human into 
machine). Therefore, the formal semantics of training-
learning relationship in the context of human-machine 
interactions is definable over four constructive implications: 
I. Implying the ‘iterative loops between human and 
machine’ from the ‘training relation between human and 
machine’. Then: 
TrainerOf(h,m)  →  
[ ( trainer(m) → h ) ∧ ( h → trainer(m) ) ].      (ix)  
II.Implying the ‘iterative loops between machine and 
human’ from the ‘learning relation between machine and 
human’. Then: 
LearnerOf (m,h) → 
[ ( learner(h) → m ) ∧ ( m → learner(h) ) ].      (x) 
III. Implying the ‘training relationship between human 
and machine’ from the ‘iterative loops between human 
and machine’. This item is the inverse of the item (1). 
Then: 
[ ( trainer(m) → h ) ∧ ( h → trainer(m) ) ] →              
TrainerOf(h,m).      (xi) 
IV. Implying the ‘learning relationship between machine 
and human’ from the ‘iterative loop between machine and 
human’. This item is the inverse of the item (2). Then: 
[ ( learner(h) → m ) ∧ ( m → learner(h) ) ] → 
LearnerOf(m,h).      (xii)  
Therefore:  
• Fundamental I expresses: [ ( Training Relation ) → 
( Training Function ⟷  Learner Constant ) ] . 
• Fundamental III expresses: [ ( Training Function ⟷ 
Learner Constant ) → ( Training Relation ) ] . 
• Fundamental II expresses: [ ( Learning Relation ) → 
( Learning Function ⟷ Trainer Constant ) ] . 
• Fundamental IV expresses: [ ( Learning Function ⟷ 
Trainer Constant ) → ( Learning Relation ) ]. 
According to the deduced results, we shall conclude that 
(I) the training relations (from human into machine) support 
the interrelationship between ‘the act of training’ and ‘the 
machine’, (II) the learning relations (from machine into 
human) support the interrelationships between ‘machine 
learning’ and ‘human’, (III) the interrelationship between 
‘the act of training’ and ‘the machine’ support the training 
relation (from human into machine), and finally, (IV) the 
interrelationship between ‘machine learning’ and ‘human’ 
support the learning relation (from machine into human).    
V. CONCLUSION AND FUTURE WORK  
In this article, we have focused on First-Order 
formalisms in order to think of relationships between human 
beings and machines. The context of this research has been 
‘the training-learning relation between human and machine’. 
We have focused on logical description and logical analysis 
of the training-learning relations within human-machine 
interactions. The analysed relationships between human 
beings and machines have supported our thoughts about the 
HowNess of producing the formal semantics. This research 
has formed a building block of our PhD researches, which 
are dealing with Semantic Analysis of Constructivist 
Concept Leaning within Mentor-Learner-Machine 
Interactions. We have concluded four fundamentals that 
conceptualise meanings and express the structure of the 
formal semantics within relationships. Subsequently, we 
have concluded that the implications between ‘relations’ and 
‘the interrelationship of functions and constant symbols’ 
support the formal semantics of the training-learning 
relationships. The conclusion of this research has prepared a 
strong backbone for our future research. In future research, 
we will focus on semantic analysis of human concept 
learning with regard to the semantics of her/his relationships 
with machines. We will also focus on the formal semantics 
of concept transformations from humans’ minds into 
machine’s knowledge bases with regard to our research in 
[10]. We will also work on semantic analysis of hypothesis 
generation. Human being generates a hypothesis in order to 
make it corresponded to a distinct entity or to its essential 
attributes, characteristics and properties. Semantically we 
will focus on an important form of HowNess: ‘How do 
hypotheses determine the applications of the predicates?’ 
REFERENCES   
1.
F. Baader, D. Calvanese, D. McGuinness, D. Nardi, and P. 
Patel-Schneider, “The Description Logic Handbook: Theory, 
Implementation and Applications”, Cambridge University 
Press, 2010. 
2.
F. Badie, “Concept Representation Analysis in The Context of 
Human-Machine Interactions”, The 14th International 
Conference on e-Society Proceedings, 2016, in press.  
3.
S. Blackburn, “The Oxford Dictionary of Philosophy”, Oxford 
University Press, UK, 2008. 
4.
H. Götzsche, “Deviational Syntactic Structures”, Bloomsbury 
Academic: London / New Delhi / New York / Sydney, 2013. 
5.
J. Lehmann, “Learning OWL Class Expressions”, Leipziger 
Beiträge zur Informatik, 2010. 
6.
G. McIntyre Boyd, “Conversation Theory”. Handbook of 
Research on Educational Communications and Technology, 
2004.. 
7.
E. Mendelson, “Introduction to Mathematical Logic (3.ed.)”, 
Chapman and Hall. 1987. 
8.
T. Mitchell, “Machine learning”, in Machine Learning, Kluwer 
Academic Publishers, 1997. 
9.
H. J. Ohlbach, “Predicate Logic Hacker Tricks”,  J. Autom. 
Reasoning 1 (4), 1985, 435-440.  
10. F. Badie, “Logical Characterisation of Concept Transformations From 
Human into Machine Relying on Predicate Logic”, The Ninth 
International Conference on Advances in Computer-Human 
Interactions, Venice, Italy, 2016, in press. 
326
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

