 
Image Processing to Evaluate Post-harvest Damages on Grapes and Their Impact on 
Fruit Aspect 
 
Francisco Javier Diaz1, Ali Ahmad1, Lorena Parra1, Sandra Sendra1, Jaime Lloret1* 
1Instituto de Investigación para la Gestión Integrada de Zonas Costeras, Universitat Politècnica de València, 46730 Grau de Gandia, Spain 
 
Email: fjdiabla@doctor.upv.es, aahmad1@upv.es, loparbo@doctor.upv.es, sansenco@upv.es, jlloret@dcom.upv.es 
 
Abstract— The interaction between grapes and fungi is a 
topic that recently has increased its interest since it can benefit 
or reduce fruit quality. Multiple factors determine the quality of 
grapes, which is directly affected by their ripeness, flavour, 
colour and overall health. In the post-harvest process, decay due 
to water loss and fungal decay are major challenges in grape 
quality and preservation. In this paper, we aim to develop an 
image tool capable of spotting anomalies in the skin of grapes 
using image processing and machine learning. A series of 
cameras connected to nodes identify irregularities on grape skin. 
Pictures are processed, and the results are sent to a database 
where the feature extraction happens. Data is sent to the cloud, 
where machine learning classifies the state of the fruit. In order 
to perform our tests, 2 bunches of grapes were studied for 14 
days. One bunch had their skin punctured, while the other was 
left untouched. The metrics selected to evaluate quality 
detection were accuracy and recall. According to the results, the 
modules that represent the most accuracy and recall are K-
Nearest-Neighbor (KNN), followed by Artificial Neural 
Network (ANN). In the case of KNN, when 4 parameters are 
included, the accuracy reaches 100 %. Following this same 
pattern, the ANN module rose an accuracy of 95 % when 4 
parameters were added. In addition, in the recall metric, KNN 
spiked at 95 % with the incorporation of 3 parameters, while 
ANN escalated to 90 % by adding 4 parameters.  
Keywords— Fungal disease; quality; image analysis 
techniques; Machine Learning; disease detection.  
I. 
INTRODUCTION 
Grapes are known to be the primary source of many of the 
world's most popular wines, so understanding how to grow 
and cultivate high-quality grapes is essential for the wine 
industry and daily consumption [1]. Since it is such an 
important crop, the number of studies on this topic has 
increased in the last decades. Therefore, a vast number of 
studies have been focused on vineyard yields, specifically on 
the surrounding environment, climate, soil, and human 
interaction [2]. The quality is a property of the grapes, which 
might be strongly affected by time and is closely related to 
the presence of fungi. There are several aspects that can 
determine the quality of grapes, including their ripeness, 
flavour, colour, and overall health. During post-harvest, 
grapes are prone to rapid deterioration following harvest due 
to significant water loss from the drying of the rachis and 
pedicel. This dehydration leads to berry softening, weight 
loss, and browning [3]. In addition, significant losses are 
incurred due to fungal decay, primarily caused by 
necrotrophic pathogens. It has been studied that fungi have a 
rapid growth rate and can easily spread through berries, 
making their preservation challenging [4]. 
On the one hand, many reviews have described 
technological factors used to enhance the quality of grapes 
during the post-harvest stage [5]. Nevertheless, despite the 
need to improve methods for preserving the quality of table 
grapes during post-harvest, consumers are reluctant to use 
existing chemical treatments. Therefore, exploring and 
enhancing the physical processes during the post-harvest is 
important. The objective is to keep the grapes in 
environmental conditions that prevent the proliferation of 
fungi and water loss to keep the quality of the grapes [6].  
On the other hand, monitoring systems based on sensors 
and image processing are being used in agriculture to identify 
fungal diseases and fruit quality. Nowadays, hyper- and 
multispectral imaging can be used to detect foliar symptoms 
of grapevine trunk diseases [7]. Additionally, image 
processing and Machine Learning (ML) techniques can be 
used to develop an automatic system for detecting grapevine 
diseases [8]. By doing this, it was detected that reflectance 
data could potentially serve as a means for evaluating crop 
damage [9]. Though, most research has been carried out on 
leaves rather than on the fruit itself. Nevertheless, as far as 
we are concerned, no papers focusing on the use of images 
for detecting loss of grape quality during the post-harvest due 
to the proliferation of fungi have been found. 
The aim of the paper is to develop a tool capable of 
detecting anomalies in grapes by using image analysis 
techniques. To achieve this goal, 2 bunches of grapes were 
used. The first one was punctured, and the second one was 
left untreated. The process took 14 days before fungi 
appeared. During the study, 3 sets of photos were taken each 
day to observe grape and fungi development. The main 
novelty of this study was to cast aside molecular and chemical 
techniques to use a more visual and technological approach 
and apply it to the fruit instead of leaves. The process would 
be based on a camera connected to a node. This camera will 
take pictures to every grape bunch. Then, these images will 
be processed and detect the presence or absence of anomalies 
and an evaluation of their quality, informing the operator. 
Furthermore, this study will provide easier identification and 
presence of fungi in grapes. 
The rest of the paper is structured as follows: Section 2 
outlines the related work. The proposed system is fully 
described in Section 3. Following Section 4 details the test 
bench. The results are discussed in Section 5. Finally, Section 
6 summarises the conclusion and future work. 
II. RELATED WORK 
In this section, we will summarise the current image 
analysis, the processing techniques used on leaves and the 
traditional methods for fungi detection and techniques to 
determine the quality of grapes. 
A. Use of image analysis on leaves. 
In [10], Meena et al. proposed the use of a Convolutional 
Neural Net (CNN) to classify picture pre-processing, image 
segmentation, and feature extraction in 5 different types of 
plants. By doing this, they analysed the colour, shape, and 
17
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-088-9
MODERN SYSTEMS 2023 : International Conference of Modern Systems Engineering Solutions - 2023

texture of the leaf and allowed them to locate the disease in 
the leaves. Similar to this study, Jaisakthi et al. [8] proposed 
an automatic system capable of identifying diseases in grape 
vines by analysing the leaves with image processing and 
machine learning. By doing this, they observed a difference 
between the possible diseases affecting the leaves. 
The aforementioned examples show the use of image 
processing to analyse the presence of diseases in leaves and 
cannot be applied directly in post-harvest monitoring of 
grapes. These techniques can be applied in our case, but 
specific indexes or feature extraction settings must be adapted 
or developed.  
B. Traditional methods for fungi and quality detection. 
Among the methods to detect the fungi's presence, most 
of them are based on chemical and molecular techniques. In 
[11], Diguta et al. used a restriction digestion analysis of the 
Internal Transcriber Spacer (ITS) products. This is a 
relatively easy method that involves using biological 
procedures to digest the ITS products of the fungal isolation 
from grapes. Then, the resulting fragments can be analysed to 
determine and identify the type of fungi. This method is 
known to be rapid and reliable. However, it can only be used 
to study only filamentous fungi. On another note, additional 
widely used techniques are the DNA-based molecular 
methods. This involves studying the DNA of the fungi to 
identify them. For example, in [12], Zhang et al. isolated 
colonies from grapes by HPLC-FLD tests. They detected the 
production of certain toxins. Meanwhile, amplification 
products were analysed and compared with other sequences 
with PCR. In another study, Han et al. [13] tested microRNAs 
by extracting and sequencing RNA with a subsequent PCR to 
find resistance to a certain type of fungal disease. A similar 
study was developed by Zhu et al. in [14], where they studied 
fungal communities in the maturation process by using DNA 
extraction and amplification with PCR, purification, and 
analysis. 
Regarding the methods for determining fruit quality, there 
are many sample-based laboratory analyses, such as PCR or 
DNA-based molecular methods. However, in 2017, 
Doerflinger et al. [15] proposed a digital image analysis that 
involves 
assessing 
berry 
quality 
using 
MATLAB 
programming language, providing an accurate description of 
berry quality. Kasimati et al. [16] used a machine learning-
based data analysis technique. The use of ML algorithms to 
predict yield and quality has become increasingly popular in 
recent years. 
Although these biological procedures are easy to repeat 
and conduct in the laboratory, it is essential to remark that 
technological tools are much faster and more efficient 
options. For example, direct observation and identification 
with sensors and cameras [17], [18] can provide a faster 
response than the aforementioned biological methods. 
Moreover, the biological procedures require specific 
equipment, reagents, trained personnel, damage the samples, 
and are time-consuming.  
III. 
PROPOSAL 
In this section, we detail the proposed system to analyse 
the grape skin in order to find the presence of anomalies. 
First, we present the system description, with details of all the 
different included devices. Subsequently, the used sensor and 
nodes are identified. Following, the architecture of the 
proposed system is depicted. Finally, all the image processing 
techniques are explained. 
A. System description 
The system consists of a series of cameras connected to 
nodes along the warehouse. The system aims to identify the 
quality of fruit and possible damages along the different parts 
of the treatment and packaging chain.  
Sensor nodes will be programmed to capture pictures at 
specific time periods. Subsequently, these photos will be first 
processed in the edge, applying a vegetation index, and then 
sent to the database (DB). Then, in the DB, fog computing is 
performed to classify and segment the images. Moreover, in 
the DB, the feature extraction process is conducted. The 
obtained data is sent to the cloud, where ML is applied to 
classify the state of the fruit.  
Regarding image processing, our system will be based on 
a mathematical combination of different bands. By doing so, 
we are able to identify between a healthy grape and an 
infected grape. Therefore, we will explore the differences in 
the values of healthy and infected grapes, emphasising on the 
fungi, and find mathematical functions that enhance these 
distinctions in the resulting bitmap image. This will be carried 
out by the node. Then, with the index, we are going to apply 
a reclassification. This will allow us to convert the original 
pixel value to a new value which represents a class. 
Following, image segmentation and feature extraction will be 
conducted. These steps will be done in the DB. 
Tagged images are used for the classification of data with 
ML. The tagged data is based on the fruit colour and the 
existence of visible damage in the grapes.  
B. Camera description 
A camera that accomplishes the following requirements 
is needed for the proposed system. First of all, the minimum 
size for this application is 9024 x 12032 pixels with a vertical 
and horizontal resolution of 72 ppi. The RGB camera should 
offer a bit resolution of 24 bits.  
The cameras should be placed at a maximum distance of 
30 cm from the fruit. Flash will be used to ensure a 
homogeneous illumination in all the pictures.  
C. Node selection 
A Raspberry Pi 4 model B node is selected for this 
application. This node is used because of its high 
computational capacity compared with other nodes, such as 
Arduino Mega or EPS32. The selected node can perform 
some simple image-processing steps. Thus, edge computing 
can be included, reducing the required bandwidth to forward 
the data.   
D. Architecture 
The architecture of the proposed system can be seen in 
Figure 1. The network system is based on a series of cameras 
connected to the nodes, an Access Point (AP), a DB, and a 
cloud server. Cameras are connected to Raspberry Pi 4 model 
B microcontrollers that are able to identify and take photos of 
the grapes and apply the initial index. Then, the nodes 
forward the result of the index to the DB using a WiFi AP. 
The DB stores the data and performs some additional image-
processing steps. The extracted features are sent to the cloud 
server, where the ML tools are applied to classify the grapes.  
18
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-088-9
MODERN SYSTEMS 2023 : International Conference of Modern Systems Engineering Solutions - 2023

E. Image processing and ML classification 
This subsection explains the different conducted 
processes for feature extraction of the captured images. The 
different steps include index calculation, reclassification, 
segmentation and feature extraction.  
Concerning the index calculation, also known as band 
combination, we have used an existing index. The index was 
initially designed to estimate the chlorophyll content in 
leaves; nonetheless, it can be applied in this case to evaluate 
the greenness versus ripeness of the grapes. The index is 
named Green Leaf Index (GLI) [19] and is described in (1) 
 
𝐺𝐿𝐼 = (2𝐺 − 𝑅 − 𝐵)
(2𝐺 + 𝑅 + 𝐵) 
(1) 
 
For image reclassification, a series of thresholds have 
been defined. The thresholds, based on the quartiles of the 
first processed image, can be seen in Table 1. After the 
reclassification, the new values range from 1 to 5 - the lower 
the values, the better the quality. The pixels from class 5 
include areas of the grape with damages.  
TABLE I.  
SUMMARY OF CAMERA FEATURES 
Class 
Original GLI 
Minimum value 
Maximum Value 
1 
-100 
-1 
2 
-1 
0 
3 
0 
6 
4 
6 
13 
5 
13 
100 
 
With regard to the segmentations, the centre of each grape 
is identified and a radial buffer of 125 pixels is generated. The 
included pixels in the circle are the analysed area of the grape, 
which are the included segments of the reclassified image. 
Feature extraction consists of obtaining histograms of the 
different segments. The histograms will contain the number 
of pixels for each one of the pixel values, which can be 1 to 
5. Thus, the generated histograms will include 5 classes.  
The obtained data from the histograms are used for the 
classification with the ML module. For the classification, the 
segments must be tagged. An expert has classified the 
portions according to their colour and the presence of 
damages by providing two scores. The scores range from 1 to 
5, the latter of which represents the lower quality. Then, an 
overall score is calculated by averaging both scores, which is 
an integer number. If the result of the mathematical operation 
is not an integer number, the next integer number is 
considered the result.  
Finally, for the ML module, 5 alternatives are considered: 
Support Vector Machine (SMV), Discriminant Analysis 
(DA), ANN, Bayesian Network (BN) and K-Nearest-
Neighbor (KNN). The selection of the most appropriate 
number of parameters for the classification is studied. The 
parameters are the values of the histograms obtained from the 
segments of the reclassified index, which are the 5 classes. A 
larger number of parameters will increase the accuracy of the 
system. Nevertheless, a greater energy consumption will be 
linked to the obtention of these parameters. Selecting the 
number of parameters, we balance the accuracy and energy 
consumption. Concerning the dataset, 6 pictures are used, and 
features were extracted from 12 and 13 areas of each picture. 
Thus, 75 areas are used in our proposal. 
All the steps for the grape's classification are summarised 
in Figure 2.  
 
 
Figure 2. Summary of image processing and ML tools for the multimedia 
monitoring system for grape quality detection. 
 
 
Figure 1. Architecture of proposed multimedia monitoring system. 
19
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-088-9
MODERN SYSTEMS 2023 : International Conference of Modern Systems Engineering Solutions - 2023

IV. 
TEST BENCH 
In this section, the complete test bench is detailed. First of 
all, the equipment and the image-capturing process is 
described. Then, the sample preparation is presented. Finally, 
the metrics employed to assess the results are shown. 
A. Equipment and image-capturing process 
In order to capture the images, a regular camera has been 
used. The camera lens corresponds to a sensor model with 
108 Mpx, 1/1,33 inches in size and 1,66 µm pixels. Pictures 
were taken from a distance of 20 cm, and the flash was active 
in each case. Photos were taken 3 times a day, at 8 am, 4 pm 
and 12 pm, for 14 days. They were placed in two transparent 
plastic containers to prevent the grapes from being lost and to 
obtain a better study of their quality. A white filter paper was 
placed at the bottom of the compartment to simplify the 
process in the following image analysis. The dimensions of 
each receptacle were about 22x15x5 cm. These containers 
were selected with the objective of representing a similar 
situation as in real post-harvest. The grapes are carefully 
placed to avoid overlapping effects in this preliminary step. 
B. Sample preparation 
In order to perform our tests, 2 bunches of grapes were 
studied. All grapes were white seedless grapes, the variety 
Autumn Crisp. Each group had about 12-13 grapes, and all of 
them were attached to the stem. Both bunches of grapes were 
displayed in two compartments exposed to the air. The 
diameter of the studied grapes was around 2 and 3 cm.  
To test the environmental influence and post-harvest 
quality, one bunch of grapes was left untouched, while the 
other had small punctures since day 1.  
C. Selected Metrics 
Two metrics are used to evaluate the performance of the 
different available ML modules. The selected metrics are 
accuracy (1) and recall (2), which can be seen below: 
𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 = 
𝑇𝑃
𝑇𝑃 + 𝐹𝑃 
(1) 
𝑅𝑒𝑐𝑎𝑙𝑙 = 
𝑇𝑃
𝑇𝑃 + 𝐹𝑁 
(2) 
where TP is the number of True Positive classified cases, 
FP is the number of False Positive classified cases, and FN is 
the number of False Negative classified cases.  
Considering this is a multiclass problem, each class's 
metrics are calculated individually. Then, macro-averaged 
accuracy and recall are calculated as the average of all classes 
for each ML module. Since we have tested the inclusion of 
different numbers of parameters, macro-averaged metrics are 
calculated for each number of parameters.  
V. 
RESULTS 
In this section, the results of image processing and data 
classification are conducted. First, the results obtained after 
applying the GLI and the reclassification are described. Then, 
each grape's estimated quality is described. Finally, the 
classification results based on ML algorithms are discussed. 
A. Image processing 
The application of GLI allows, on the one hand, to reduce 
the image size by having a single band instead of three bands. 
On the other hand, the new band maximises the differences 
between the greener areas, the healthy grapes, and areas with 
other colours, such as bumps, damages or fungic infections. 
The RGB and the index have been calculated for the RGB 
images captured during the experiments. Results can be seen 
in Figure 3. Next, the reclassified image according to the 
established thresholds in Table I is displayed with the circles 
indicating the segments to be analysed.  
RGB picture                         GLI                     Reclassified image 
 
a) 
Day: 1 Treatment: Normal
 
b) 
Day: 7 Treatment: Normal
 
c) 
Day: 14 Treatment: Normal 
 
d) 
Day: 1 Treatment: Punctured 
 
e) 
Day: 7 Treatment: Punctured 
 
f) 
Day: 14 Treatment: Punctured 
Figure 3. Process followed for image classification. 
20
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-088-9
MODERN SYSTEMS 2023 : International Conference of Modern Systems Engineering Solutions - 2023

In Figure 3 a) and d), we can see the image of the first day 
with the standard treatment and punctured grapes. Figure 3 b) 
and e) correspond to the pictures after 7 days for the normal 
and the punctured treatment. Finally, Figure 3 c) and e) 
correspond to the images after 14 collections with the 
different treatments. It is possible to see that there are 
differences among the treatments and over time in the RGB 
image. Nonetheless, the differences are much more evident 
when the GLI is applied and when the image is reclassified.  
Concerning the feature extraction results, an example of 
data of obtained histograms from a random grape of normal 
treatment and a random grape of standard treatment can be 
seen in Table 2. In the Table, it is possible to see the number 
of pixels contained in the studied segments for each one of 
the 4 classes.  
TABLE II.  
EXAMPLE OF OBTAINED HISTOGRAMS 
 
B. Classification results 
This subsection presents the results of different ML 
modules for solving the multiclass problem based on data 
obtained in the previous subsection. In Figure 4, the macro-
accuracy results can be seen. Regardless of the number of 
included parameters, the KNN is the algorithm that offers a 
better performance in terms of accuracy, followed by ANN. 
When the KNN algorithm is used with 4 or more parameters, 
100 % of accuracy is reached. No other algorithms achieve 
similar results. In the case of results with the ANN, the 
maximum accuracy is 95.2 % with both 4 and 5 parameters. 
The worst accuracies are obtained with BN with maximum 
accuracy of 78 %, SVM, and DA, the last two of which have 
similar performances. 
Concerning the macro-averaged recall, the results can be 
seen in Figure 5. Again, the KNN algorithm's performance is 
the best among the tested ML methods. As for accuracy, 100 
% of recall is achieved when 4 and 5 parameters are used. In 
the case of the ANN, the recall reaches 92 % when 4 or more 
parameters are used.  
 
 
Figure 4. Macro-averaged accuracy results for the different tested algorithms 
and with different numbers of included parameters. 
Contrary to what happened in the case of accuracy, the 
worst results are linked with SVM, with recall values below 
40 % in all the cases. The performance of DA is slightly better 
than that of SVM, with a maximum recall of 46 %. Finally, 
BN is in the third position among the tested algorithms. It is 
the only one that has an increase in its performance when the 
last parameters are included, rising from 55 % with 4 
parameters to 67 % with 5 parameters. 
 
 
Figure 5. Macro-recall accuracy results for the different tested algorithms 
and with different numbers of included parameters. 
After analysing the results, it is possible to affirm that in 
order to maximise the performance of the system, it is 
required to use the KNN algorithms as an ML tool to classify 
the data. It is recommended to use 4 parameters since the 
results when an additional parameter is included do not 
increase, and a lower number of parameters will have less 
space in the DB and less information to be exchanged with 
the cloud server, thus decreasing the network requirements 
and energy use.  
We can affirm that the proposed methodology for fruit 
quality determination using image processing and ML tools 
offered promising results. Accuracy and recall equal to 100 
% have been achieved. For the application of this system in 
real conditions, it will be recommended to include additional 
cameras to gather more images from the same bunch to avoid 
the overlapping effect. 
C. Limitations 
There is a series of constraints to be considered in this 
study before its implementation in real conditions. As 
mentioned in Section IV A, to avoid overlapping two or more 
grapes, they were carefully distributed to make it easier for 
the program to detect the area of the grapes. It remains to be 
determined in which sense this overlap affects the image 
generated. The program may detect one grape instead of two. 
Further studies should be carried out to study how to avoid 
this overlapping and how to solve it. 
In this study, the camera used to obtain the images of the 
bunch of grapes was a conventional camera. For future 
studies, it would be advisable to use a higher resolution 
camera to better delimit the area of each grape. 
 
VI. 
CONCLUSIONS AND FUTURE WORK 
Rapid fruit quality evaluation is extremely important in 
warehouses along the value chain. While there are several 
proposals to control and reduce fruit quality decay, few 
70
75
80
85
90
95
100
2
3
4
5
Accuracy (%)
Nº of included parameters (nº)
SVM
DA
ANN
KNN
BN
30
40
50
60
70
80
90
100
2
3
4
5
Recall (%)
Nº of included parameters (nº)
SVM
DA
ANN
KNN
BN
Class 
Example of Grape of 
Normal Treatment 
Example of Grape of 
Punctured Treatment 
Day 1 
Day 7 
Day 14 
Day 1 
Day 7 
Day 14 
1 
0 
0 
1092 
0 
6 
889 
2 
0 
0 
203 
0 
136 
314 
3 
355 
27 
1339 
1020 
6312 
6441 
4 
27292 
33739 
43166 
42276 
42520 
41382 
5 
21394 
15280 
3243 
5727 
63 
13 
21
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-088-9
MODERN SYSTEMS 2023 : International Conference of Modern Systems Engineering Solutions - 2023

methods are found to evaluate the fruit quality remotely 
during the storing and processing periods. 
In this paper, we have proposed, analysed and verified a 
methodology to determine the fruit's quality and the fungi's 
presence based on image processing. The proposed method is 
based on applying GLI, image segmentation and using ML to 
classify extracted features. With KNN, accuracy and recall of 
100 % are achieved even if not all the extracted features are 
included in the classification.  
The future work will include adding additional sensors, 
such as gas sensors [20] with the aim of predicting the fruit's 
quality decay. In addition, the study of other grape varieties 
and other berries is foreseen to evaluate the suitability of this 
method with fruits characterised by other colours.  
 
 
ACKNOWLEDGMENT 
This work is partially funded by the "Programa Estatal de 
I + D + i Orientada a los Retos de la Sociedad, en el marco del 
Plan Estatal de Investigación Científica y Técnica y de 
Innovación 
2017-2020 
project 
PID2020-114467RR-
C33/AEI/10.13039/501100011033 and by "Proyectos Estraté-
gicos Orientados a la Transición Ecológica y a la Transición 
Digital" project TED2021-131040B-C31. This study also 
forms part of the ThinkInAzul programme and was supported 
by MCIN with funding from the European Union 
NextGenerationEU (PRTR-C17.I1) and by Generalitat 
Valenciana (THINKINAZUL/2021/002). 
REFERENCES 
 
[1] OIV. 2019 Statistical Report on World Vitiviniculture; International 
Organisation of Vine and Wine: Paris, France, 2019. 
[2] J.A. Santos, et al., "A Review of the Potential Climate Change Impacts 
and Adaptation Options for European Viticulture," Appl. Sci., 10, pp. 
3092, 2020. 
[3] B. M. Chang, Y. Zhang, and M. Keller, "Softening at the onset of grape 
ripening alters fruit rheological properties and decreases splitting 
resistance," Planta 250, pp. 1293–1305, 2019. 
[4] L. Sevillano, M. T. Sanchez-Ballesta, F. Romojaro, and F. B. Flores, 
"Physiological, hormonal and molecular mechanisms regulating 
chilling injury in horticultural species. Postharvest technologies 
applied to reduce its impact," J. Sci. Food Agric., 89, pp. 555-573, 
2009.  
[5] N. Sonker, A. K. Pandey and P Singh, "Strategies to control post-
harvest diseases of table grape: a review," Journal of Wine Research, 
27:2, pp. 105-122, 2016. 
[6] M. Vázquez-Hernández et al., "High CO2 alleviates cell ultrastructure 
damage in Autumn Royal table grapes by modulating fatty acid 
composition and membrane and cell oxidative status during long-term 
cold storage," Postharvest Biology and Technology 160: pp. 111037, 
2020. 
[7] N. Bendel, et al., "Evaluating the suitability of hyper- and multispectral 
imaging to detect foliar symptoms of the grapevine trunk disease Esca 
in vineyards," Plant Methods 16, pp. 142, 2020.  
[8] S. M. Jaisakthi, P. Mirunalini, D. Thenmozhi and Vatsala, "Grape Leaf 
Disease Identification using Machine Learning Techniques," 
International Conference on Computational Intelligence in Data 
Science (ICCIDS), Chennai, India, pp. 1-6, 2019. 
[9] H. Al-Saddik, A. Laybros, B. Billiot and F. Cointault, "Using Image 
Texture and Spectral Reflectance Analysis to Detect Yellowness and 
Esca in Grapevines at Leaf-Level," Remote Sens., 10, 618, 2018.  
[10] M. Meena, S. Varshini K and M. G, "Plant Diseases Detection Using 
Deep Learning," 2022 1st International Conference on Computational 
Science and Technology (ICCST)," CHENNAI, India, pp. 549-553, 
2022. 
[11] C. F. Diguta et al., "PCR ITS-RFLP: A useful method for identifying 
filamentous fungi isolates on grapes," Food microbiology, 28(6), pp. 
1145–1154, 2011. 
[12] X. Zhang et al., "Screening and Identification of Novel Ochratoxin A-
Producing Fungi from Grapes," Toxins, 8, pp. 333 2016. 
[13] A. Reinekeand and D. Thiéry, "Grapevine insect pests and their natural 
enemies in the age of global warming," J Pest Sci 89, pp. 313–328, 
2016. 
[14] E. Neethling, G. Barbeau, C. Coulon-Leroy and H. Quénol, "Spatial 
complexity and temporal dynamics in viticulture: A review of climate-
driven scales," Agricultural and Forest Meteorology. pp. 276-277, 
2019. 
[15] F. Doerflinger, Franziska and V. Pagay, "Objective assessment of dried 
sultana grape quality using digital image analysis," Australian Journal 
of Grape and Wine Research. 24, 2017. 
[16] A. Kasimati, B. Espejo-García, N. Darra and S. Fountas, "Predicting 
Grape Sugar Content under Quality Attributes Using Normalised 
Difference Vegetation Index Data and Automated Machine Learning," 
Sensors (Basel), 22(9): pp. 3249, 2022 Apr 23. 
[17] A. Ahmad, F. J. Diaz, L. Parra, S. Sendra and J. Lloret. “Turning 
Smartphone Camera into a Fungal Infection Detector for Chickpea 
Seed Germination.”, The International Conference on Multimedia 
Computing, Networking and Applications (MCNA2023), Valencia, 
Spain, 19 to 22 of June 2023, pp XX. 
[18] N. Gorretta, M. Nouri, A. Herrero, A. Gowen, and J. M. Roger, J. Early 
detection of the fungal disease" apple scab" using SWIR hyperspectral 
imaging. In 2019 10th workshop on hyperspectral imaging and signal 
processing: Evolution in remote sensing (WHISPERS), Amsterdam, 
Netherlands, 24-26 september 201, pp. 1-4. 
[19] F. Z. Bassine, A. Errami, and M. Khaldoun, Vegetation recognition 
based on UAV image color index. In 2019 IEEE international 
conference on environment and electrical engineering and 2019 IEEE 
industrial and commercial power systems Europe (EEEIC/I&CPS 
Europe), Genova, Italy, 11-14 June 2019, pp. 1-4. 
[20] S. Viciano-Tudela, S. Sendra, L. Parra, J. M. Jimenez, and J. Lloret, 
Proposal of a Gas Sensor-Based Device for Detecting Adulteration in 
Essential Oil of Cistus ladanifer. Sustainability, 15(4), 2023, pp. 3357. 
 
22
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-088-9
MODERN SYSTEMS 2023 : International Conference of Modern Systems Engineering Solutions - 2023

