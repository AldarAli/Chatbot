Uncertainty Quantiﬁcation of Density Reconstruction in High-Energy X-ray
Radiography
Haibo Xu
Institute of Applied Physics and
Computational Mathematics
Beijing, P.R. China
Email: xu_haibo@iapcm.ac.cn
Xinge Li
Institute of Applied Physics and
Computational Mathematics
Beijing, P.R. China
Email: lixinge@lsec.cc.ac.cn
Abstract—High-energy X-ray radiography is a measuring tech-
nique for quantitative diagnosis of the object and its internal
structure. Tomographic reconstruction determines the geometric
and physical properties of the object according to the energy
distribution on the imaging plane. Considering the noise and
blur in the process of radiographing, we construct a general
reconstruction model for the axisymmetric single image pho-
tographic system. This inverse problem is then cast within a
statistical framework in order to compute volumetric object
densities from X-ray radiographs and to quantify uncertainties in
the reconstruction. A hierarchical Bayesian model is developed
with a likelihood based on a Gaussian noise model and with
priors placed on the unknown nonnegative density proﬁle, the
precision matrix, and two scale parameters. This results in a
joint posterior distribution, which can be readily sampled using
the Markov chain Monte Carlo (MCMC) method. To study the
role of hyperparameters and their sensitivity analysis, a wide
variety of tests were conducted which led to a number of deﬁnitive
conclusions. Results of the density reconstructions and pointwise
uncertainty estimates are presented for simulated signals with
various physical factors in the imaging process included.
Keywords–inverse problem; density reconstruction; uncertainty
quantiﬁcation; Bayesian inference; MCMC method.
I.
INTRODUCTION
High-energy X-ray radiography measures the spatial densi-
ty distribution of the object, which is of great signiﬁcance for
studying the compression behavior of the object subjected to
powerful shocks under the effect of explosives. In this paper,
we focus on the problem of uncertainty quantiﬁcation of densi-
ty reconstruction for high-energy X-ray radiography. Bayesian
formulations for inverse problems have gained considerable
attention in the inverse problems community for their utility
in uncertainty quantiﬁcation [1]–[7]. In the application here,
we seek an unknown that contains discontinuities but we do
not precisely know the discontinuity locations, so we develop
a hierarchical Bayesian model for localizing the discontinuities
and computing object densities simultaneously. The Bayesian
approach combines the prior knowledge of the unknown pa-
rameters and the forward model to yield a posterior probability
distribution of the model parameters. In this way, the unknown
parameters can be characterized by their posterior distributions.
The posterior distributions are typically not of analytical form
or from a standard parametric family, and characterizing them
exactly requires optimization algorithms [8]–[11] or sampling
approaches such as MCMC [12].
(a)
(b)
Figure 1. Illustration to single radiographic imaging system for radially
symmetric object in 3D view (a) and 2D view (b).
In our experimental setting, a radially symmetric object
with radius R and height H is situated so that its center-
layer lies in the xy-plane and its axis of symmetry coincides
with the z-axis (see Figure 1(a)). Only a single radiograph is
taken with a radiographic axis perpendicular to the symmetric
axis of the object. The transmitted radiation is measured by a
detector lying on a plane x = x0. The X-ray source is placed
sufﬁciently far from the object compared to its size, so that the
X-rays can be assumed to be parallel on different layers. In
each layer, we consider that the X-rays form a fan-beam shape,
see Figure 1(b). Each cross section of the object is projected
onto a line of the detector plane. We formulate the density
reconstruction model as
b = KAρ + ε,
(1)
where b ∈ Rm is the areal density values, ρ ∈ Rn is the
object radial density values, ε ∈ Rm is unknown noise, K
presents the blurring that may be produced in the process of
radiographing, and A ∈ Rm×n denotes the forward projection
matrix.
The rest of the paper is organized as follows. Section II
discusses how to estimate the object density and its corre-
sponding uncertainty quantitatively. Uncertainty quantiﬁcation
of the French Test Object (FTO) reconstruction are presented
in Section III, as well as the parameter selection method and
sensitivity study. Finally, the conclusion and outlook are given
in Section IV.
II.
BAYESIAN FORMULATION OF RECONSTRUCTION
PROBLEM
In this section, we introduce a hierarchical Bayesian model
to compute object densities and quantify their corresponding
25
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-737-5
ADVCOMP 2019 : The Thirteenth International Conference on Advanced Engineering Computing and Applications in Sciences

uncertainties at the same time. By selecting conjugate prior
distributions, the ﬁnal posterior formulation can be easily
and efﬁciently sampled using a Gibbs sampler, a specialized
MCMC method.
A. Hierarchical Bayesian model
Since the noise distribution in areal density space is difﬁcult
to estimate, we begin with the standard additive Gaussian noise
model [13], [14], i.e., ε ∼ Normal(0, (λI)−1) with precision
λ. Then the conditional probability density of b given the
information of ρ and λ, would be
p(b|ρ, λ) ∝ λm/2 exp

−λ
2 ∥KAρ − b∥2

.
(2)
Assume that the prior model for ρ is also a Gaussian,
ρ ∼ Normal(0, (δL)−1),
where L ∈ Rn×n is referred to as the precision matrix, and
δ > 0 and L are poorly known. Hence, we write a conditional
prior for ρ, assuming that δ and L were known, as
p(ρ|δ, L) ∝ δn/2|L|1/2 exp

−δ
2ρTLρ

,
that is, the prior density is conditioned on the knowledge of δ
and L. In consideration of the nonnegativity of density value ρ,
we impose nonnegativity constraint on the computed samples.
Suppose I = I(ρ)
def
= {i|ρi = 0} is the zero set and p(I)
a probability model for I. Then the prior will depend upon
the zero set. If we deﬁne C to be the diagonal matrix with
diagonal entries cii = 1 for i /∈ I, and cii = 0 otherwise, the
prior in the unconstrained case is modiﬁed as follows:
p(ρ|δ, L, I) ∝ δnp/2|L|1/2 exp

−δ
2ρTCLCρ

,
(3)
where np = n − |I|, i.e., the number of positive elements in
ρ.
Assume further that we have a hyperprior density p(L) for
the precision matrix L. We suppose here that this density is a
Wishart distribution, which is often used for inverse covariance
matrices [15]. Thus L ∼ Wishart(Σ, ν), with probability
density function
p(L) =
1
2νn/2|Σ|ν/2Γn(ν/2)|L|
ν−n−1
2
exp

−1
2tr(Σ−1L)

, (4)
where Σ is a positive deﬁnite scale matrix, and ν is the degrees
of freedom parameter.
Last, a Gamma hyperprior distribution is chosen for both
scale parameters λ and δ so that
p(λ) ∝ λαλ−1 exp(−βλλ),
(5)
p(δ) ∝ δαδ−1 exp(−βδδ),
(6)
that is, λ ∼ Gamma(αλ, βλ), δ ∼ Gamma(αδ, βδ), where
αλ and αδ are Gamma shape parameters and βλ and βδ are
Gamma rate parameters.
Considering now all ρ, λ, δ, L and I as unknowns, we
write Bayes’ formula conditioned on b as
p(ρ, λ, δ, L, I|b) ∝ p(b|ρ, λ, I)p(ρ|δ, L, I)p(L)p(δ)p(I)p(λ),
which allows us to estimate ρ, λ, δ and L simultaneously:
ρ|λ, δ, L, I, b ∼ Normal(B†
IλATKTb, B†
I),
(7)
λ|ρ, δ, L, I, b ∼ Gamma (m/2 + αλ, 1
2∥KACρ − b∥2 + βλ), (8)
δ|ρ, λ, L, I, b ∼ Gamma (np/2 + αδ, 1
2ρTLIρ + βδ),
(9)
L|ρ, λ, δ, I, b ∼ Wishart((Σ−1 + δ(ρρT)I)−1, ν + 1),
(10)
where B = λATKTKA + δL, DI
def
= CDC and † denotes
psuedo-inverse. Since Cρ = ρ (recall that ρi = 0 for i ∈ I),
equivalent distributions result if C is removed in (8), LI is
replaced by L in (9), and (ρρT)I is substituted as ρρT in
(10). We do this in what follows.
It remains to deﬁne p(I) and the conditional density
p(I|ρ, λ, δ, L, b). This can be accomplished by computing [1]
ˆρ = arg min
ρ≥0
1
2ρTBρ − ρT(λATKTb + w)

,
(11)
where w
∼
Normal(0, B). That is, solving (11) yields
simultaneous samples of both ρ and, implicitly, I from
p(I|ρ, λ, δ, L, b). And, more remarkable, this optimization
problem can be easily solved exploiting the Constrained Con-
jugate Gradient (CCG) method [16]. We still have not deﬁned
p(I), but this is not necessary to deﬁne our MCMC method.
B. MCMC sampling of the posterior distribution
The power in (7)–(10) lies in the fact that samples from
these four distributions can be easily computed using standard
statistical software, though nonlinear optimization techniques
will be needed for (7). A Gibbs sampler that results from
sequential use of the conditional densities p(I|ρ, λ, δ, L, b) and
(7)–(10) can be written without an explicit sampling step for
I. The sampler begins with ρ, and is initialized with λ0, δ0,
and L0. A basic outline is listed in Algorithm 1.
Algorithm 1 (MCMC sampler)
1.
Select λ0, δ0 and L0. Select a maximum number of
samples, N, and set k = 0.
2.
Compute
ρk = arg min
ρ≥0
1
2ρTBkρ − ρT(λkATKTb + w)

,
where Bk
=
λkATKTKA + δkLk
and w
∼
Normal(0, Bk), using the CCG method.
3.
Compute λk+1 ∼ Gamma(m/2 + αλ, 1
2∥KAρk −
b∥2 + βλ).
4.
Compute δk+1 ∼ Gamma (nk
p/2+αδ, 1
2(ρk)TLkρk+
βδ), where nk
p is the number of positive entries in ρk.
5.
Compute
Lk+1 ∼ Wishart

III.
NUMERICAL EXPERIMENTS
In this section, we test on a simulated radiograph of
the FTO, which is generated by the Monte Carlo N-Particle
(MCNP) transport code [17], to demonstrate the ability of
MCMC method to reconstruct an axially symmetric object.
In this numerical simulation, the source is assumed as a
monoenergetic photon beam of 4 MeV, and the source blur
is treated as Gaussian, whose full width at half maximum
is 0.3 cm. The FTO consists of a set of concentric spheres
with a void region at the center. The void has a radius of
1.0 cm. The second layer is tungsten with radius of 4.5 cm
and density of 18.9 g/cm3. The third layer is copper with
radius of 6.5 cm and density of 8.9 g/cm3. The FTO is placed
200 cm from the source, and the detector is 250 cm behind the
object. Figure 2(a) shows the synthetic radiograph of the total
exposure, and Figure 2(b) shows the proﬁles at the equator of
the direct and scattered exposure respectively.
(a)
(b)
Figure 2. MCNP simulation results of the FTO. (a) Radiograph
capturing both direct and scattered radiation; (b) the central cross
sections of the direct and scattered exposure.
Obviously, the introduction of the hyperprior distributions
in (4)–(6) requires the choice of hyperparameters αλ, βλ, αδ,
βδ, ν, and Σ. Setting the MCMC sampler with these hyper-
parameters and initializations λ0, δ0 and L0, we computed
100,000 samples and made the last 95,000 available, which
demonstrated stationarity and had little correlation between
samples [15]. From these samples, we plot the sample mean as
our reconstruction, which is known as conditional mean (CM)
estimate of the unknown density, and 95% credibility intervals
given by the 0.025 and 0.975 quantiles of the samples at each
location, which were computed using empirical quantiles.
A. Parameter selection
We have to study ﬁrst the role of hyperparameters. For the
hyperparameters (αλ, βλ), it is easy to see that λ characterises
the noise level σ2 of areal density. The smaller the value,
the higher the noise. Since the mean and variance of the
corresponding Gamma distribution are αλ/βλ and αλ/β2
λ
respectively, we choose appropriate αλ and βλ such that
αλ/βλ is close to σ−2 and αλ/β2
λ is smaller. In our numerical
experiments, we just set αλ = σ−2 and βλ = 1.
We now study the effect of the hyperparameters (αδ, βδ).
To this end, we employ the variable-controlling approach by
setting λ and L as known. We then ﬁx αδ = 1, and the cor-
responding Gamma distribution degenerates to an exponential
distribution. The maximum a posteriori estimate for the pair
(ρ, δ) are calculated for various values of βδ. We then pick
a proper ˆβδ with good performance of ˆρ. Similar to λ, we
select suitable αδ and βδ such that αδ/βδ is equal to 1/ˆβδ
and αδ/β2
δ is smaller. In our numerical experiments, we just
set αδ = ˆβ−1
δ
and βδ = 1.
Last but not least, setting the Wishart degrees of freedom
parameter ν = n + 1 ensures that the distribution is well
deﬁned [18] [19]. Since the Wishart has mean νΣ, the quality
of the ﬁnal reconstruction is supposed to be greatly improved
by choosing a Σ that incorporates edge information. We then
set Σ =
1
ν LTV(ρTV) to center the hyperprior for L around
the initial edge estimate provided by total variation (TV)
solution ρTV, where LTV(ρTV) = DTψ(ρTV)D, ψ(ρTV) :=
diag

1/
p
(DρTV)2 + η

, η is a small positive constant, and
D is the forward differencing matrix [15].
B. Parameter sensitivity
We now reconstruct the density distribution of the FTO
with the resulting areal density from the direct radiation shown
in Figure 2(b), and provide a parameter sensitivity analysis for
Σ and βδ. For the MCMC sampler, the degrees of freedom
parameter ν is set to be n + 1, the Wishart scale matrix Σ
is computed to be
1
ν LTV(ρTV), and LTV(ρTV) is also used
for L0. The initial λ and δ parameters are drawn from a
Uniform(0, 1) distribution. All the remaining parameters for
the Gibbs sampler are selected as noted above and are given
in Table I.
The sensitivity of the TV solution, which is used to inform
the hyperparameter Σ, is tested by providing the sampler with
a TV solution that contained no edge information and a TV
solution that indicated incorrect edge locations and densities.
For ease of comparison, we also calculate the CM estimate,
initializing the sampler with a proper TV solution. The mean
square error is computed using the mean reconstruction com-
pared to the true density proﬁle of the FTO. As shown in
Table I, the mean square error of the original reconstruction is
0.0637392 and each of these two reconstructions differs from
that by no more than 0.000002. Both of these reconstructions
demonstrate the Bayesian method’s ability to overcome a
poorly informed Σ parameter, relying on the data to determine
edges and density scales.
To understand the sensitivity of the solution to the param-
eter βδ, we carry out reconstruction experiments on the areal
density, which is corrupted with Gaussian noise at level 1.5%
of maximum of the noiseless projection data. Samples of the
MCMC chain are drawn from the conditional distributions,
holding all but βδ constant and changing βδ from 100 to
101. Combined with the mean square error in Table I, we can
observe that the MCMC sampler with different βδ makes very
little difference.
TABLE I. PARAMETERS STATISTICS AND COMPARISON OF
MEAN SQUARE ERRORS.
αλ
βλ
αδ
βδ
Σ
∥ρMCMC − ρtrue∥/√n
106
100
102
100
correct
0.0637392
106
100
102
100
non
0.0637399
106
100
102
100
wrong
0.0637404
7.3 × 105
100
102
100
correct
0.0636181
7.3 × 105
100
102
101
correct
0.0632581
We can summarize from the data in Table I that (αδ, βδ)
can be applicable to the projection data of the same object in
different situations, while the selection of (αλ, βλ) is related
27
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-737-5
ADVCOMP 2019 : The Thirteenth International Conference on Advanced Engineering Computing and Applications in Sciences

to the noise level of the projected data, and different values
are obtained for different data.
C. Uncertainty caused by physical factors
Although empirical knowledge constraints have been added
into density reconstruction, it does not eliminate the uncer-
tainty of reconstruction results (11), but only reduces the
uncertainty of reconstruction modeling (1), so it is neces-
sary to analyze the factors causing uncertainty in density
reconstruction. Generally, there are uncertainties caused by the
conversion from optical density to areal density, the noise in
areal density, the measurement error of areal density as well
as the reconstruction method itself. In our simulation, errors
in the reconstruction from the direct radiation data are mainly
caused by the noise and measurement error in areal density
and our approach to the density reconstruction problem (1).
Images captured by X-ray imaging systems are direct
measures of the optical density. The measured optical density,
G, can be converted to areal density, b, using a measured
transmission curve, which is given by
G = G0 + k(XD + XS) = G0 + k
X0
d2 e−b + XS

, (12)
where G and G0 is the optical density and background density
at that point; k is the slope of the transmission curve; X0 is
the radiation exposure; d is the distance between source and
the imaging plane; XS is the scattered radiation; XD is the
direct radiation. The uncertainty of areal density measurement
caused by the indeterminacy of scattering irradiation, incident
exposure and transmission curve measurements can be sum-
marized as
∆b =
s
SDR2
∆XS
XS
2
+
∆X0
X0
2
+ (1 + SDR)2
∆k
k
2
,
(13)
where SDR =
XS
XD denotes the ratio of scattering to direct
radiation. According to the accuracy of experimental measure-
ment, the error range of physical quantities in (13) can be
approximated by
∆XS
XS
≤ 10%,
∆X0
X0
≤ 5%,
∆k
k
≤ 10%,
then we can obtain the measurement error of areal density:
∆b = 0.1
q
SDR2 + 0.25 + (1 + SDR)2.
(14)
To analyse the uncertainty introduced by noise in the
imaging process, we carry out reconstruction experiment on
the noisy areal density, which is corrupted with Gaussian noise
at level 1.5% of maximum of the noiseless projection data.
Compared with the posterior estimation from noiseless data,
as shown in Figure 3 (a), credibility interval at every location
in (b) becomes obvious when noise added, and all of them
are within 10% of the density value there. When comparing
the CM estimate with TV estimate, in the terminology of the
classical regularization theory one is tempted to say that the
former is underregularized compared to the latter. However,
from the statistical point of view, the CM estimate is consistent
with the prior.
In consideration of the uncertainty in areal density mea-
surement, we impose the correct value ∆b on the areal density.
Then we run MCMC for the corrected areal densities b − ∆b
(a)
(b)
(c)
(d)
Figure 3. Density reconstructions. (a) Reconstruction results from the
noiseless areal density; (b) reconstruction results from the noisy areal
density; (c) reconstruction results from the noiseless areal density with
correction; (d) reconstruction results from the noisy areal density with
correction.
and b + ∆b separately. To imitate the density uncertainty
caused by measurement uncertainty, these two estimates are
merged into single one, as shown in Figure 3 (c), whose
density values are average of two estimates, and the pointwise
credibility intervals are unions of two original intervals. The
mean square error between the density distributions in (c) and
(a) is 0.0133972, which veriﬁes the validity of our estimation
method. The credible band is tight across the image except for
the jump locations.
Considering the uncertainties caused by noise and areal
density measurement together, we get the noisy areal density
to minus and plus the correction (14) separately, and obtain
the corresponding noisy projection data with correction. Based
on the previously explained MCMC run, the CM estimates
together with credible intervals are shown in Figure 3 (d).
It is easy to see that the density distribution in (d) is very
close to those in (b), and the mean square error between them
is 0.0130941. However, the 95% credibility intervals become
wider with the introduction of correction, particularly around
the boundary of inner layers, and this is consistant with the
case in (c). In each example illustrated above, the uncertainty
is seen to be lower near regions of constant density in the
reconstruction and higher near edge locations.
IV.
CONCLUSION
In this paper, a generalized density reconstruction model
is presented based on the assumption that noise and blur
will occur during the imaging process. Then, a hierarchical
Bayesian model is proposed for computing object densities and
estimating their uncertainties simultaneously. Density samples
drawn from the conditional posterior distribution are insensi-
tive to the choice in hyperparameter values selected based on
the model. Numerical experiments indicate that our MCMC
method achieves quite effective reconstruction results and is
comparable to TV regularization. Moreover, the uncertainty
28
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-737-5
ADVCOMP 2019 : The Thirteenth International Conference on Advanced Engineering Computing and Applications in Sciences

of density reconstruction is mainly introduced by noise and
measurement error of physical quantities in the process of
radiography.
In this paper, the X-rays are assumed to be parallel on
different layers, and they form a fan-beam shape in each layer.
In the future, we plan to estimate the uncertainty of cone
beam reconstruction using the MCMC method. Furthermore,
we will consider other explicit noise models according to the
characteristics of experimental data, such as poisson noise,
impulse noise and a composition of them. We will also
construct the prior density in more ways based on the nature
of the prior information, for example, ℓ1 prior, Cauchy density,
entropy density, lognormal density, discontinuities prior and so
on.
ACKNOWLEDGMENT
H. Xu was supported by NSFC Funds (grant No.
11675021). X. Li was supported by National Postdoctoral
Program for Innovative Talents (grant No. BX201700038).
REFERENCES
[1]
J. M. Bardsley and C. Fox, “An MCMC method for uncertainty
quantiﬁcation in nonnegativity constrained inverse problems,” Inverse
Problems in Science & Engineering, vol. 20, no. 4, pp. 477–498, 2012.
[2]
J. P. Kaipio and E. Somersalo, “Statistical and computational inverse
problems,” Technometrics, vol. 48, no. 1, pp. 146–146, 2005.
[3]
A. M. Stuart, “Inverse problems: A Bayesian perspective,” Acta Numer-
ica, vol. 19, no. 19, pp. 451–559, 2010.
[4]
L. Tenorio, Statistical Regularization of Inverse Problems.
Society for
Industrial and Applied Mathematics, 2001.
[5]
J. Li and Y. M. Marzouk, “Adaptive construction of surrogates for
the bayesian solution of inverse problems,” SIAM Journal on Scientiﬁc
Computing, vol. 36, no. 3, pp. A1163–A1186, 2014.
[6]
L. Yan and T. Zhou, “Adaptive multi-ﬁdelity polynomial chaos approach
to bayesian inference in inverse problems,” Journal of Computational
Physics, vol. 381, pp. 110–128, 2019.
[7]
L. M. M. V. D. Bos, B. Sanderse, W. A. A. M. Bierbooms, and
G. J. W. V. Bussel, “Bayesian model calibration with interpolating
polynomials based on adaptively weighted leja nodes,” Communications
in Computational Physics, 2019.
[8]
A. Soares, R. Rabelo, and A. Delbem, “Optimization based on phylo-
gram analysis,” Expert Systems with Applications, vol. 78, pp. 32–50,
2017.
[9]
M. Shams, E. Rashedi, S. M. Dashti, A. Hakimi, M. Shams, E. Rashedi,
S. M. Dashti, and A. Hakimi, “Ideal gas optimization algorithm,”
International Journal of Artiﬁcial Intelligence, vol. 15, no. 2, pp. 116–
130, 2017.
[10]
R.-E. Precup, Nature-Inspired Optimization Algorithms for Fuzzy Con-
trolled Servo Systems.
Oxford: Butterworth-Heinemann, 2019.
[11]
B. H. Abed-alguni, “Island-based cuckoo search with highly disruptive
polynomial mutation,” International Journal of Artiﬁcial Intelligence,
vol. 17, no. 1, pp. 1–29, 2019.
[12]
S. Brooks, A. Gelman, G. L. Jones, and X.-L. Meng, Handbook of
Markov Chain Monte Carlo.
Boca Raton: Chapman & Hall/CRC,
2011.
[13]
D. Calvetti and E. Somersalo, Introduction to Bayesian scientiﬁc
computing.
New York: Springer, 2007.
[14]
O. Scherzer, M. Grasmair, H. Grossauer, M. Haltmeier, and F. Lenzen,
Variational Methods in Imaging.
New York: Springer, 2009.
[15]
M. Howard, M. Fowler, A. Luttman, S. E. Mitchell, and M. C. Hock,
“Bayesian Abel inversion in quantitative X-ray radiography,” SIAM
Journal on Scientiﬁc Computing, vol. 38, no. 3, pp. B396–B413, 2016.
[16]
E. A. H. Vollebregt, “The bound-constrained conjugate gradient method
for non-negative matrices,” Journal of Optimization Theory and Appli-
cations, vol. 162, no. 3, pp. 931–953, 2014.
[17]
X. M. C. Team, “MCNP – A general Monte Carlo N-particle transport
code, version 5,” Los Alamos Nuclear Laboratory, Tech. Rep. LA-UR-
03-1987, 2003.
[18]
C. Bishop, Pattern Recognition and Machine Learning.
New York:
Springer, 2006.
[19]
A. Gelman et al., Bayesian Data Analysis.
Boca Raton: CRC Press,
2013.
29
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-737-5
ADVCOMP 2019 : The Thirteenth International Conference on Advanced Engineering Computing and Applications in Sciences

