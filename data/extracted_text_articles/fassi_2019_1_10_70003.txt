Design Model of a Training Simulator in Virtual Reality
Igor Petukhov
Department of Radio Technical
Volga State University of Technology
Yoshkar-Ola, Russia
email: Petuhoviv@volgatech.net
Liudmila Steshina
Department of Radio Technical
Volga State University of Technology
Yoshkar-Ola, Russia
email: Steshinala@volgatech.net
Andrey Glazyrin
Department of Radio Technical
Volga State University of Technology
Yoshkar-Ola, Russia
email: railot116@gmail.com
Dimiter Velev
Department of Information Technologies and
Communications
University of National and World Economy
Sofia, Bulgaria
email: dgvelev@unwe.bg
Abstract— This paper discusses problems that arise in the
process of designing training simulators based on virtual
reality. Virtual reality increases the performance of training
due to immersion and realistic spatial objects. Unfortunately,
there
are
problems
associated
with
designing
training
simulators based on virtual reality. These problems are related
to the performance of the environment in the context of
effective user training. The paper presents a new approach to
design a framework for a training simulator in virtual reality.
Its key idea is to introduce basic principles for building of a
two-level architecture using a user-centered design (on low-
level) and object-closed design (on high-level). The low-level
includes a modeling of the subject’s orientation and the
response of the environment to external influences. The high-
level focuses on the specific of training scripts such as
specificity
of
the
operation
or
a
detailed
3D
model
(visualization of target’s operation through user interaction
with the virtual environment). The data obtained can provide
benefits to modeling training systems in virtual reality and for
improving learning performance. The material presented can
open new prospects for further research studies. It seems
interesting to those who work in the field of usability
engineering, training and human-computer interaction.
Keywords- virtual reality; virtual environment; human-
computer interaction; training simulator; virtual subjectivities;
user-centered design; design framework component.
I.
INTRODUCTION
The applications of Virtual Reality (VR) are becoming
very popular in different fields of human activity. On one
hand, there is a continued optimism in the growth of the
immersive industry sector [1]. On the other hand, there are
many opportunities in the contexts of communication and
integration of human feelings and emotions in the Virtual
Environments (VE) [2].
The greatest interest is simulation based training on VR
(the system hardware and software are essential components
of the virtual reality system), which affects the sense organs
like in a realistic scenario of professional activity.
Despite the active progress of immersive and interactive
technologies, some difficulties are still associated with
certain restrictions. These problems include 3D interaction
design in VR [3], creation of realistic 3D content such as
physics
and
visual
effects
[4],
unified
techniques
of
interaction in the VE [5], the difficulties of geo-positioning
and spatial relocation [6].
This paper covers actual issues linked with the analyses
and description model of VR for training simulation, which
takes into account the subject area and subjective user
experience.
One of the most common applications of VR is
simulation training in the different spheres such as medicine
[7], astronautic science [8], education [9], industry [10],
sports [11], military [12], games [13], building architecture
[14], etc. Therefore, VR should reproduce a user's practical
activity in the context of any task. At the same time, VR is
safe
for
humans
in
comparison
with
the
physical
environment [15].
It was noted that the training of tasks that are performed
in a three-dimensional space are better performed in VE [16],
for example, memory training [17] or improving spatial
thinking [18]. Moreover, perceptions of learning programs
are becoming more effective in VE by increasing user
motivations [19], modeling collaborative learning or other
communication practices [20]. The greatest interest is
training of movements and memorizing motor skills [21],
such as simulations of accurate manipulations at atypical
conditions for humans [8] [22].
It was shown that VE has an influence on psycho-
emotional states and stress resistance [23]; thus, this one
could activate the corresponding behavior like in the real
world [24]. The analysis mentioned above shows the
potential of VR in the context of increasing the effectiveness
of learning and simulation training.
1
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

The rest of the paper is structured as follows. Section 2
describes the main problems of human-computer interaction
within VR. Section 3 covers some related works in this area,
summarizing the differences between characteristics and
features of training simulation in VR. Section 4 mentions the
mapping model, which is followed for the training simulator.
Section 5 concludes this paper.
II.
PROBLEMS
At
the
moment,
the
design
of
human-computer
interaction within VR is centered on classical usability
methods [25] that have been used in the Windows Icon
Mouse Pointer (WIMP) - paradigm applications for a long
time.
At
the
same
time,
VR
crucially
differs
from
conventional desktop applications first of all by its deep
psychophysiological action, a wider set of interaction
techniques, and 3D contents [26].
Another key problem is related to the design of the
immersion functionality. On one hand, there is an empirical
correlation of immersion with hardware and software
parameters of VR such as a frame rate, tracking a head
rotation, audio, and interaction methods applied in the VE.
On the other hand, a deep level of interaction can be
explained by activation of similar structures in the brain, i.e.
sensory stimuli as in the real world. Therefore, we face a
problem of continuity between the subjective experience of
the
presence
in
the
environment
and
the
functional
performance of the VR hardware [27].
It was noted that human performance is the basic element
in
VR
because
performance-based
simulator-design
guidelines
include
balancing
perceived
realism
with
simulator limitations, such as latency resulting from graphic
and haptic renderings [28]. The problems of presence that
affected humans in VR, such as user movement control,
should be streamlined to enhance performance and reduce
sickness [29].
The main principles of the complex processing of input
information in VR were discussed [30]. This approach
considers the user through the perception of the psycho-
emotional model of the environment. On one hand, it is
important to find a balance between rational reasoning and
emotional reasoning because these factors integrate the
human psychological state with VE [31]. On the other hand,
there is the virtual subjectiveness [32], which affects
consistency (mapping) between the cognitive-psychological
level of the user’s perception and the VR system [33].
Due to the problems mentioned, various research works
and studies are focusing on finding out the components of
visual immersion, including field of view, field of regard,
and display size. Each element of visual immersion affects
measurable user performance, understanding, and preference
in a wide variety of VEs [34]. In this way, it is important to
define what components affect the performance of which
tasks [35].
However, there is a wide set of training simulator-based
VRs that gives a good account of itself. These are VR
simulators in medicine [36], education [37], communication
[38], military [39], etc. So, let us consider how these
problems are overcome. Based on these results, it is possible
to describe the attributes and architectures (approaches) for
designing the training systems in VE. It should be noted that
the selection of parameters for the model of training
simulators will be controlled by the specifics of the user-
environment relations.
III.
RELATED WORK
The Structural-Functional Design (SFD) overcomes the
difficulties linked with the complex structure of the VR
system and defines separated components, such as visual,
behavioral and interaction characteristics. Each characteristic
refers to the object’s state inside the VR system and includes
a set of parameters. For example, the visual level includes
the rendering of the 3D content after the process of a user’s
interaction
with
the
environment.
The
behavioral
characteristic defines the actions of objects in VE and the
interaction between 3D objects.
In the context of training, the design model finds out the
components that may have a strong impact on the modeling
of
a
realistic
training
simulation.
The
methodology
formalizes the process of VR interface into two phases,
which describe levels of abstraction, and breaks down the
phases into components [40]. The high-level phase defines
the conceptual feature of the environment (the target of
training, methods simulations); at the same time, the low-
level phase guides details of human interaction, rendering of
3D objects, behavior of the environment, etc.
Consequently, SFD helps to unify around the structure of
the VR system, defines the components of the systems, and
finds out the target and features of components. In practice,
this methodology uses the Virtual Reality Interface Design
(VRID) model [40], TRES-D [41] and other examples [42-
44].
Unfortunately, the mentioned model focuses to a greater
extent on technical details and ignores the specifics of
participants. This conceptual framework may help to plan a
design process or represents the operational behavior of the
system. Therefore, it is important to consider other examples
of the model of VR, which takes an active part in the
interaction and communication with the user.
The Communication-Information Design (CID) suggests
considering a training environment like an active subject of
communication with the user [45]. For that reason, the
mentioned environment contains a decision support system
based on Artificial Intelligence (AI) that concentrates around
avatars (virtual human being) and virtual surroundings.
The typical illustration of CID is the so-called Virtual
Human Project (VHP) [46]. The goal of VHP is to create
realistic virtual humans to increase the effectiveness of the
communication
information
procedure
of
interaction
between users and avatars. In this case, the user is a
concurrent part of the training environment and active object
in VE.
Conceptually, the virtual humans or avatars should
include three nested layers that make up the mind the agent
thinks with (cognitive layer), the body the agent acts with
(virtual layer), and the world of the agent (simulation layer)
[46]. Each layer is the set of components that extend features
2
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

of avatars and includes verbal speech, body gesture, and
actions the character performs, for example, walking.
For training simulation, the approach mentioned may
help to design the environment for cognition and emotion
modeling of the user’s condition. In practice, it is training in
VR such as tactical questions in military or cultural
immersive training [47], commutative capacity [48], and
crowd
simulation
[49].
The
specific
feature
of
the
communication–information approach is modeling virtual
humans for interaction with the user through speech and
gesture.
The Object-Closed Design (OCD) focuses on detailed
implementation
(visualization
of
granule
operation’s
component, pressure feedback, quality of movement) of the
complex manipulation in a variety of fields such as medical
[50], handling operations [51], engineering [52][53], system
of
telepresence
[54][55],
etc.
This
approach
includes
monitoring the system in real time. In this case, the
environment should be reacting on each event that appears
after the user’s manipulation, 3D object’s interaction, the end
of a fixed period, etc.
Therefore, VR should reproduce a user’s practical
activity in the context of any task. Indeed, the user is key to
the system’s component; at the same time, the reaction of the
environment is more important. The user is defined as a
secondary member and a concurrent element to perform any
task. The communication between the training environment
and
the
participant
is
executed
through
object-closed
manipulation. For example, in the medical field, there is
pressure on the special mannequin, imitation of elasticity and
feedback of rendering a 3D view of anatomical structures
[50].
The object-closed approach may help with detailed
modeling of task execution. Unfortunately, this model
disregards the significance of user’s attribute such as
motility, psychophysiological specificity, subjectivity, and
experiences.
The User-Centered Design (UCD) models a training
environment that consists of users (humans) as the most
important items in interaction with virtual content through
equipment. For that reason, the user is no longer “a black
box” because this one may be considered like an object with
previous experience or psychophysiological specificity. It
was noted that human performance is related to the quality of
the VE (level of immersion, self-explanatory navigation,
ease of interaction with 3D object, etc.). At the same time, it
has shown the positive and negative impact of VR on the
health of humans [56]. Therefore, it is important to extract a
human feature, which affects the performance of the
environment. For example, in the Conceptual VR Model
(CVRM), the user handles effectors (shell, fixture, appliance)
from VR, which reduce feedback in the form of sensory
stimuli. Consequently, for correct modeling, UCD finds out
the mapping of the virtual effectors and the perceptual
system of the participant. So, the visual perceptual system is
linked with visual display such as orientation in time and
space [57].
Conceptually, there are three independent main parts of
the system, such as the environment, a user and a mediator.
The mediator integrates the user with VE through Virtual
Subjectivities (VS) [53]. The VS includes reminiscence
about the surrounding medium and subjective experiences in
the context of the psychophysiological-cognitive patterns
that become active in the same situations as in physical
reality. The mediator appears in the form of scale perception,
orientation, action, etc. The UCD does user an active actor in
the scheme of training systems because the virtual model
combines human perception and dynamic spatial content.
Unfortunately, the border between the user and the VE
remains diffuse in this model. The mediator is a key
component needed in defining the factors that support the
performance of the training simulation in VR.
Table
1
summarizes
the
differences
between
the
characteristics and features of different model designs. As
the
table
indicates,
each
approach
brings
significant
challenges in modeling the training environment. For
example, CID fits collaborative training or face-to-face
communication, but it is unlikely to be used in an illustration
of
surgical
operation.
UCD,
for
example,
does
not
completely reflect the specific quality of the operation, but it
probably allows to include the virtual subjunctives in the
process of simulation.
TABLE I.
PREVIOUS RESEARCH AND DEFINITIONS OF THE DESIGN
MODEL OF TRAINING SIMULATION IN VR
Name
Framework
and design
model
Type of
training
Central
elements
Key features
SFD
Tanriverdi
V., Jacob
R. J. K.
VRID 2001
[40],
Molina J. P.
et al.
TRES-D
2006 [41],
Cochrane
T. et al.
DBR 2017
[43].
none
The visual,
behavioral
and
interaction
characteristics
Defines
components
of the
systems;
finds out
target and
features of
components
CID
Kenny P. et
al. VHP
2007 [46],
Prange A.
et al. MDS
2017 [48],
Ulicny B.,
Thalmann
D. Crowd
simulation
2001 [49]
Collaborati
ve training,
communica
tion, crowd
training,
cultural
interchange
.
The cognitive
level and AI,
model of
avatar (verbal
speech, body
gesture, and
actions the
character
performs)
Creates a
realistically
virtual
human to
increase the
effectivenes
s of
communicat
ion–
information
procedure of
interaction
between
users and
avatars
OCD
Çakmak H.
K.,
Kühnapfel
U. KisMo
2000 [50],
Pürzel F. et
al. 2013
[51], Stoll
Modeling
of granule
operation’s
component,
pressure
feedback,
quality of
movement
The reaction
of VR on
actions of
user
(pressure,
feedback,
imitation of
elasticity and
The special
mannequin
or a detailed
3D model.
Visualizatio
n of target’s
operation
through user
3
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

Name
Framework
and design
model
Type of
training
Central
elements
Key features
E., Wilde
M., Pong
C. 2009
[54]
and etc.
etc.)
interaction
with VR.
UCD
Stanney K.
M.,
Mourant R.
R.,
Kennedy R.
S. 1998
[56], Latta
J. N.,
Oberg D. J.
et al.
CVRM
1994 [57],
Parés N.,
Parés R.
2006 [32]
Modeling
of training
simulator
includes
user
experiences
,
characterist
ics, and
psychophys
iological-
cognitive
patterns.
The user
handles
effectors
(shell, fixture,
appliance)
from VR and
reproduces
feedback in
the form of
sensory
stimuli
Model of
mapping
virtual
element’s
and correct
user’s
perception.
It is necessary to emphasize that current models are
linked with targets of training simulation and use different
architectural components. The most interest brings UCD and
OCD approaches’ focus on the subjective perception of the
environment and VE’s reflection on input user’s action. In
the next section, the extended model of training systems
based on UCD and OCD will be discussed.
Immersion or presence is a critical attribute of VR [58].
Immersion is the state of mind of an individual where he or
she excludes the outside world and is totally focused on
experiencing another world [59]. It was shown that the
immersion appears in the form of cognitive and perception
components of user’s subjectivities [60]. On the one hand,
immersion influences the performance and quality of an
executed
task
[61][62]
through
correct
selection
and
specification of spatial elements. In this context, the 3D
content and property elements of VR are important attributes
of the presence. Especially, the important role of physical
laws [63], velocity [59][64], collision and occlusion [65]
were shown.
There is a set of properties of VR devices that affect
presence, for example head rotation [66], tracking system
[67], screen resolution [68], and rendering [69]. Moreover,
the empirical result found in [70] confirms the requirement
for the presence of the following parameters: frame rate,
tracking head rotation, sound, and technique of interaction.
The relation between the correct properties of spatial
objects and any parameters of devices remains an open
discussion. This problem has been considered through
different
schemes,
for
example,
human
reaction
and
subjectivities mapping.
Subjectivities mapping attracts the most interest because
this approach defines two additional and important cues for
the understanding of the psychological impact of VR. These
two cues are the physical interface (any manipulation of
devices based on the movement of the user) and the logical
interface (any rendering or view’s feedback after the
movement of the user). Then, the virtual subjectivities
impact on the environment itself seem to be a mapping or
correct association between the user movement and the view
rendering. Unfortunately, the approach mentioned is needed
in the definition of mapping elements. At the same time, the
elements are key to understanding the principles of modeling
the training environment in VR. In the next section, we will
discuss
the
mapping
elements
based
on
the
training
requirements and the framework for designing a training
environment in VR.
IV.
THE MAPPING ELEMENTS OF TRAINING SIMULATION
The sequence of human actions in a VE was shown [71].
Firstly, the person orients himself/herself in the VE and, after
that, he/she interacts with the VE. We believe mapping
elements might include a set of grouped human actions based
on the priority for human perception inside the VE.
For this reason, the Queuing Network-Model Human
Processor (QN-MHP) may help to describe the process of
human perception through the functioning of the sensory-
motor system based on three layers (sensory, cognitive and
motor) [72]. Therefore, human actions are associated with
ordered
sensory-motor
reactions.
Indeed,
the
person
perceives visual information through the sensory layer
(sensory analysis). The visual information activates previous
experiences from the human knowledge (the database of
knowledge). Finally, the motor program is reproduced in the
form of actions and manipulation (motor program).
These
assumptions
about
the
process
of
human
perception and mapping elements may have a strong impact
on modeling training systems. On one hand, the mapping in
the VR system in context of human knowledge (the database
of
knowledge)
from
QN-MHP
may
include
human
perception of VE in form (distance = scaled, rotation =
viewing angle, lighting = visual effects, sound = audio
effects) and the simulation of behavior for the environment
based on previous user experiences from real situations such
as (physics laws = correct rendering 3D-content, tracing =
moving reaction, fitting = distance reacting).
On the other hand, for modeling of the specific process in
form of focused actions should be included components from
human perception of VE and the simulation of behavior for
VE. We believe this combination is a high-level model for
object-closed design. It is focused on specific training
simulation. The relation between mapping and design levels
for the training simulation is shown table 2.
The sensory-motor activation in training simulation with
mapping model may help to understand the relation between
VE and the functioning of the human perception. For this
reason, each perception layer may be linked to virtual
subjectivities, which include logical interfaces, physical
interfaces and mapping.
The logical interface is responsible for visual effects in
context
of
virtual
subjectivities.
In
this
way,
human
perception in the form of sensory analysis is related to the
logical
interface
through
visual
feedback.
The
visual
feedback
perceives
from
the
database
of
knowledge
«Conceptual
model»
inside
the
cognitive
layer.
The
extracted situational model may be corrected according to
the current situation. Accordingly, the synchronization of
previous user experiences is triggered.
4
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

TABLE II.
THE CONCEPTUAL SCHEME OF MAPPING ELEMENTS OF
TRAINING SIMULATION
High-
level
(OCD)
Object-closed modeling
Execution a task: The logic of application with modeling of
different scripts and important of components (the imitation
of workflow, operation’s quality, precedence, and time
delay).
Output:
Logic interface (correct rendering of VE as feedback from
physics interface)
Low-
level
(UCD)
User-centered modeling
Orientation
Imitation
The mapping elements
Distance
Scaled
Moving
Time
correlation
Rotation
Viewing
angle
Tracking
Moving
reaction
Lighting
Visual
effect
Fitting
Changed
distance
Sound
Audio
effect
Physics laws
Correct
rendering
Input:
Physics interface (manipulation with virtual devices: Head-
mounted display, virtual glove, tracking, joysticks and etc.)
At the same time, the corrected model influences to
choose motor action in the form of “motor reaction”. Finally,
this motor reaction converts to muscle efforts through the
physical interface. The mentioned steps are summarized in
Figure 1.
Figure 1.
The user’s role in training simulator based on mapping model
The mentioned model is focused on human reactions,
which
are
related
to
virtual
subjectivities
through
synchronization of previous user experiences. Therefore, the
abstract database of knowledge «Conceptual model» needs
great numbers of training situations for effective training. It
reminds us of training a set of examples for Artificial Neural
Networks (ANN).
We do not know the deep principles of brain learning. At
the same time, there are different primitive models of the
human brain such as ANN. This models show better results
than human beings in some tasks such as classification or
image recognitions. For that reason, we should make an
analogy about ANN and «Conceptual model» from the
mapping model. The ANN gets many various pieces of data
for training, and then a training simulator based on
«Conceptual model» may be considered as the generator of
nonrecurring learning situations. Those situations may help
to overcome the problems that are linked with the satiation of
the database of knowledge «Conceptual model».
V.
RESULTS AND CONCLUSION
In this paper, we identified the contemporary approaches
to the design model for the training simulator in VR. It was
noted that there is a relationship between the type of training
and the design model of training simulator in VR. The
greatest interest is in a design model based on OCD and
UCD. Both approaches are perspective in different fields of
training process. These approaches offer to focus on a
detailed process of task execution is the same as integrating
the user into the workflow. We believe in a central role of
human reactions in the training process based on the
mapping model.
The mentioned approach for training simulator based on
VE allows us to define a design framework, including two
design levels. The low-level UCD paradigm focuses on the
human reaction, simple actions and perception. This level
includes mapping logical and physical interfaces.
On one hand, the main target is a correct adjustment of
mapping using scaled setting, viewing angle, visual and
audio for correct orientation inside the VE. For example,
scaled and viewing angle may be selected by empirical value
based on experimental results (regression model and least
square method - LSM). The other attributes (lighting and
sound)
are
selected
with
expert’s
requirements
and
normative standards.
On the other hand, the environment should reproduce the
imitation of basic tasks through reacting to the user’s actions
(movement, changed distance, time and physics laws). In this
case, simple tasks (tracking and fitting) may be reduced in
simple special tests (reaction on moving an object or
changed object’s distance).
The other things such as the physics laws or the
movement may be corrected by developing tools (example
Unity3D: colliders or rigid body). The main purpose is to
create the immersion of a recipient in VE.
Then, after the process of immersion, there is a need to
fill the environment with dynamic content. The high-level
consists of building correct low-level and application logic
based on the OCD. Therefore, the main target of this layer is
to collect an unbound data in the complex training context
based on a specific training simulator. There are many
templates of OCD such as a complex 3D object or a
mannequin.
Further research work should be focused on the low level
of the design model. Especially, we will focus on scale and
viewing angle based on experiments. A person will evaluate
the distance between two points in the VE and real-world
such as viewing angle. The results will be shown in the form
of recommendation for the design of the training system, for
example, simulator of harvesting machine.
5
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

ACKNOWLEDGMENTS
The results of this study were obtained with the support
of Grant No. 25.1095.2017/4.6.
REFERENCES
[1]
R. R. Burke, “Virtual Reality for Marketing Research,”
Innovative Research Methodologies in Management, Palgrave
Macmillan, Cham, 2018, pp. 63-82.
[2]
J. L.Rubio-Tamayo, B. M. Gertrudix and G. F. García,
“Immersive Environments and Virtual Reality: Systematic
Review and Advances in Communication, Interaction and
Simulation,” Multimodal Technologies and Interaction, 2017,
vol. 1, № 4, 21. 
[3]
C. Boletsis, “The New Era of Virtual Reality Locomotion: A
Systematic Literature Review of Techniques and a Proposed
Typology,” Multimodal Technologies and Interaction, 2017,
vol. 1, № 4, 24. 
[4]
M. Cha et al., “A virtual reality based fire training simulator
integrated with fire dynamics data,” Fire Safety Journal, 2012,
vol. 50, pp. 12-24.
[5]
D. A. Bowman, J. L. Gabbard and D. Hix, “A survey of
usability evaluation in virtual environments: classification and
comparison of methods,” Presence: Teleoperators & Virtual
Environments, 2002, vol. 11, № 4, pp. 404-424. 
[6]
C. Boletsis, J. E. Cedergren and S. Kongsvik, “HCI research
in
Virtual
Reality:
A
discussion
of
problem-solving,”
International Conference on Interfaces and Human Computer
Interaction, IHCI 2017, Portugal, 21–23 July 2017, pp. 263-
267.
[7]
T. Gunn et al., “The use of virtual reality simulation to
improve technical skill in the undergraduate medical imaging
student,” Interactive Learning Environments, 2017, pp. 1-8.
[8]
T. Everson et al., “Astronaut training using virtual reality in a
neutrally buoyant environment,” DesTech 2017: Proceedings
of
the
2017
International
Conference
on
Design
and
Technology, Knowledge E, 2017, pp. 319-327.
[9]
S. Greenwald et al., “Technology and applications for
collaborative learning in virtual reality,” 2017.
[10] L. P. Berg and J. M. Vance, “Industry use of virtual reality in
product design and manufacturing: a survey,” Virtual reality,
2017, vol. 21, № 1, pp. 1-17. 
[11] D. L. Neumann et al., “A systematic review of the application
of interactive virtual reality to sport,” Virtual Reality, 2017,
pp. 1-16.
[12] E. Prasolova-Førland et al., Preparing for International
Operations
and
Developing
Scenarios
for
Inter-cultural
Communication
in
a Cyberworld: A Norwegian
Army
Example,” Transactions on Computational Science XXIII,
Springer, Berlin, Heidelberg, 2014, pp. 118-138.
[13] M. Zyda, “From visual simulation to virtual reality to games,”
Computer, 2005, vol. 38, № 9, pp. 25-32. 
[14] C. H. Lin and P. H. Hsu, “Integrating Procedural Modelling
Process and Immersive VR Environment for Architectural
Design Education,” MATEC Web of Conferences, EDP
Sciences, 2017, vol. 104, 03007.
[15] T. Everson and C. McDermott, “Astronaut training using
Virtual Reality in a Neutrally Buoyant Environment,” School
of Engineering, Australia DesTech Conference Proceedings
The International Conference on Design and Technology,
2017, pp. 319-326.
[16] M. Gonzalez-Franco and P. Rodrigo, “Immersive Mixed
reality for Manufacturing Training: Frontiers in Robotics and
AI,” Frontiers in Robotics and AI, 2017, vol. 4, № 3. 
[17] J. McComas, “CyberPsychology & Behavior,” Children’s
Transfer of Spatial Learning from Virtual Reality to Real
Environments, 1998, vol. 1, pp. 121-127.
[18] J. Broekens et al.,
“Virtual reality negotiation training
increases negotiation knowledge and skill,” International
Conference on Intelligent Virtual Agents, Springer, Berlin,
Heidelberg, 2012, pp. 218-230.
[19] J. Pirker, I. Lesjak and C. G. Maroon, “VR: A Room-Scale
Physics
Laboratory
Experience,”
Advanced
Learning
Technologies
(ICALT),
2017
IEEE
17th
International
Conference on IEEE, 2017, pp. 482-484.
[20] J. Rickel and W. L. Johnson, “Virtual humans for team
training
in
virtual
reality,”
Proceedings
of
the
ninth
international conference on artificial intelligence in education,
1999, vol. 578, p. 585.
[21] L. Schmid, A. Glässel and C. Schuster-Amft, “Therapists’
Perspective on Virtual Reality Training in Patients after
Stroke: A Qualitative Study Reporting Focus Group Results
from Three Hospitals,” Stroke research and treatment, 2016,
vol. 2016, 12 p.
[22] I. Petukhov, L. Steshina and A. Glazyrin, “Application of
virtual reality technologies in training of man-machine system
operators,” 2017 International Conference on Information
Science and Communications Technologies, ICISCT 2017,
2017-December, pp. 1-7.
[23] G. Riva et al., “Affective interactions using virtual reality: the
link between presence and emotions,” CyberPsychology &
Behavior, 2007, vol. 10, № 1, pp. 45-56. 
[24] M. Slater et al., “Immersion, presence, and performance in
virtual environments: An experiment with tri-dimensional
chess,” ACM virtual reality software and technology (VRST),
New York, NY: ACM Press, 1996, vol. 163, 72 p.
[25] D. Bachmann, F. Weichert and G. Rinkenauer, “Review of
three-dimensional human-computer interaction with focus on
the leap motion controller,” Sensors, 2018, vol. 18, № 7,. 
2194.
[26] C. Repetto, P. Cipresso and G. Riva, “Virtual action and real
action have different impacts on comprehension of concrete
verbs,” Frontiers in psychology, 2015, vol. 6, 176.
[27] H. G. Kim et al., “Measurement of exceptional motion in VR
video contents for VR sickness assessment using deep
convolutional autoencoder,” Proceedings of the 23rd ACM
Symposium on Virtual Reality Software and Technology,
ACM, 2017, p. 36.
[28] D. B. Kaber et al., “Investigating human performance in a
virtual reality haptic simulator as influenced by fidelity and
system latency,” IEEE Transactions on Systems, Man, and
Cybernetics-Part A: Systems and Humans, 2012, vol. 42,
№ 6, pp. 1562-1566. 
[29] K. M. Stanney et al., “Human performance in immersive
virtual environments: Effects of exposure duration, user
control, and scene complexity,” Human performance, 2002,
vol. 15, № 4, pp. 339-366.
[30] J. Diemer et al., “The impact of perception and presence on
emotional reactions: a review of research in virtual reality,”
Frontiers in psychology, 2015, vol. 6, p. 26.
[31] B. Herbelin, F. Vexo and D. Thalmann, “Sense of presence in
virtual reality exposures therapy,” Proceedings of the 1st
International Workshop on Virtual Reality Rehabilitation,
Lausanne, Switzerland, Citeseer, 2002.
[32] N. Parés and R. Parés, “Towards a model for a virtual reality
experience:
the
virtual
subjectiveness,”
Presence:
Teleoperators and Virtual Environments, 2006, vol. 15, № 5, 
pp. 524-538.
[33] J. N. Latta and D. J. Oberg, “A conceptual virtual reality
model,” IEEE Computer Graphics and Applications, 1994,
vol. 14, № 1, pp. 23-29. 
6
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

[34] D. A. Bowman and R. P. McMahan, “Virtual reality: how
much immersion is enough? ,” Computer, 2007, vol. 40, № 7. 
[35] R. Pausch,
D. Proffitt
and G.
Williams,
“Quantifying
immersion in virtual reality,” Proceedings of the 24th annual
conference on Computer graphics and interactive techniques,
ACM Press/Addison-Wesley Publishing Co., 1997, pp. 13-18.
[36] R. M. Satava and S. B. Jones, “Current and future applications
of virtual reality for medicine,” Proceedings of the IEEE,
1998, vol. 86, № 3, pp. 484-489. 
[37] J. B. Cooper and V. R. Taqueti, “A brief history of the
development of mannequin simulators for clinical education
and training,” Postgraduate medical journal, 2008, vol. 84,
№ 997, pp. 563-570. 
[38] F. Biocca and M. R. Levy, “Communication in the age of
virtual reality,” Routledge, 2013.
[39] A. Lele, “Virtual reality and its military utility //Journal of
Ambient Intelligence and Humanized Computing,” 2013, vol.
4, № 1, pp. 17-26. 
[40] V. Tanriverdi and R. J. K. Jacob, “VRID: a design model and
methodology
for
developing
virtual
reality
interfaces,”
Proceedings of the ACM symposium on Virtual reality
software and technology, ACM, 2001, pp. 175-182.
[41] J. P. Molina et al., “An interaction model for the TRES-D
framework,” Electrotechnical Conference, 2006, MELECON
2006, IEEE Mediterranean, IEEE, 2006, pp. 457-461.
[42] C. H. Lin and P. H. Hsu, “Integrating Procedural Modelling
Process and Immersive VR Environment for Architectural
Design Education,” MATEC Web of Conferences, EDP
Sciences, 2017, vol. 104, 03007.
[43] T. Cochrane et al., “A DBR framework for designing mobile
virtual reality learning environments,” Australasian Journal of
Educational Technology, 2017, vol. 33, № accepted for 
Special Issue on Mobile Augmented and Virtual Reality.
[44] W. Li, A. Y. C. Nee and S. K. Ong, “A State-of-the-Art
Review of Augmented Reality in Engineering Analysis and
Simulation,” Multimodal Technologies and Interaction, 2017,
vol. 1,  № 3, 17. 
[45] A.
M.
Al-Ahmari
et
al.,
“Development
of
a
virtual
manufacturing assembly simulation system,” Advances in
Mechanical 
Engineering, 
2016, 
vol. 
8, 
№ 
3,  
1687814016639824.
[46] P. Kenny et al., “Building interactive virtual humans for
training environments,” Proceedings of i/itsec, 2007, vol. 174,
pp. 911-916.
[47] E. Prasolova-Førland et al., “Preparing for International
Operations
and
Developing
Scenarios
for
Inter-cultural
Communication
in
a Cyberworld: A Norwegian
Army
Example,” Transactions on Computational Science XXIII,
Springer, Berlin, Heidelberg, 2014, pp. 118-138.
[48] A. Prange et al., “A Multimodal Dialogue System for Medical
Decision Support inside Virtual Reality,” Proceedings of the
18th Annual SIGdial Meeting on Discourse and Dialogue,
2017, pp. 23-26.
[49] B.
Ulicny
and
D.
Thalmann,
“Crowd
simulation
for
interactive virtual environments and VR training systems,”
Computer Animation and Simulation 2001, Springer, Vienna,
2001, pp. 163-170.
[50] H. K. Çakmak and U. Kühnapfel, “Animation and simulation
techniques for vr-training systems in endoscopic surgery,”
Computer Animation and Simulation, Springer, Vienna, 2000,
pp. 173-185.
[51] F. Pürzel et al., “Real NC Control Unit and Virtual Machine
to Improve Operator Training,” Procedia Computer Science,
2013, vol. 25, pp. 98-107.
[52] A. Nakai, Y. Kaihata and K. Suzuki, “The experience-based
safety training system using VR technology for chemical
plant,” Editorial Preface, 2014, vol. 5, № 11. 
[53] T. Im et al., “A Virtual Reality based Engine Training
System-A Prototype Development & Evaluation,” CSEDU,
2017, vol. 1, pp. 262-267.
[54] E. Stoll, M. Wilde and C. Pong, “Using virtual reality for
human-assisted in-space robotic assembly,” Proc. World
Congress on Engineering and Computer Science, 2009.
[55] X. Wang, P. S. Dunston and M. Skiniewski, “Mixed Reality
technology applications in construction equipment operator
training,” Proceedings of the 21st International Symposium
on Automation and Robotics in Construction (ISARC 2004),
2004, pp. 21-25.
[56] K. M. Stanney, R. R. Mourant and R. S. Kennedy, Human
factors issues in virtual environments: A review of the
literature Presence, 1998, vol. 7, № 4, pp. 327-351. 
[57] J. N. Latta and D. J. Oberg, “A conceptual virtual reality
model,” IEEE Computer Graphics and Applications, 1994,
vol. 14, № 1, pp. 23-29. 
[58] M. J. Schuemie et al.,
“Research on presence in virtual
reality: A survey,” CyberPsychology & Behavior, 2001, vol.
4, № 2, pp. 183-201. 
[59] P. Gander, “Two myths about immersion in new storytelling
media,” Lund University, 1999, Immersion and Emotion:
Their Impact on the Sense of Presence.
[60] R. M. Baños et al., “Immersion and emotion: their impact on
the sense of presence,” CyberPsychology & Behavior, 2004,
vol. 7, № 6, pp. 734-741. 
[61] I. Petukhov, L. Steshina and A. Glazyrin, “Application of
virtual environments in training of ergatic system operators,”
Journal of Applied Engineering Science, 2018, 16(3), pp. 398-
403.
[62] S. Gupta et al., “Training in Virtual Environments: A Safe,
Cost Effective, and Engaging Approach to Training,” 2008.
[63] M. J. Schuemie et al., “Research on presence in virtual reality:
A survey,” CyberPsychology & Behavior, 2001, vol. 4, № 2, 
pp. 183-201.
[64] L. Piron et al., “Virtual Reality as an assessment tool,”
Medicine Meets Virtual Reality 2001: Outer Space, Inner
Space, Virtual Space, 2001, vol. 81, 386.
[65] C.Hendrix
and
W.
Barfield,
“Presence
within
virtual
environments as
a function of visual display parameters,”
//Presence: Teleoperators & Virtual Environments, 1996, vol.
5, № 3, pp. 274-289. 
[66] S. Sharples et al., “Virtual reality induced symptoms and
effects (VRISE): Comparison of head mounted display
(HMD), desktop and projection display systems,” Displays,
2008, vol. 29, № 2, pp. 58-69. 
[67] H. Sveistrup, “Motor rehabilitation using virtual reality,”
Journal of neuroengineering and rehabilitation, 2004, vol. 1,
№ 1, 10. 
[68] F. P. Brooks, “What's real about virtual reality?,” IEEE
Computer graphics and applications, 1999, vol. 19, № 6, pp. 
16-27.
[69] G.
Robertson,
M.
Czerwinski
and
M.Van
Dantzich,
“Immersion in desktop virtual reality,” Proceedings of the
10th annual ACM symposium on User interface software and
technology, ACM, 1997, pp. 11-19.
[70] M. V. Sanchez-Vives and M. Slater, “From presence to
consciousness
through
virtual
reality,”
Nature
Reviews
Neuroscience, 2005, vol. 6, № 4, 332. 
[71] J. Jerald, “The VR book: Human-centered design for virtual
reality,” Morgan & Claypool, 2015.
[72] Y. Liu, R. Feyen, and O. Tsimhoni, “Queuing Network-
Model
Human Processor
(QN-MHP):
A Computational
Architecture for Multitask Performance in Human-Machine
Systems,”
ACM
Transactionson
Computer-Human
Interaction, March 2006, vol. 13, № 1, pp. 37–70. 
7
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-750-4
FASSI 2019 : The Fifth International Conference on Fundamentals and Advances in Software Systems Integration

