Vision-based Cattle Detection and Localization System in an RGB Color Space 
Detection and localization system for cattle shed management 
 
Jieun Kim 
Department of IT Convergence  
Daegu Gyeongbuk Institute of Science and Technology 
Daegu, Republic of Korea  
intocosmos@dgist.ac.kr 
Woo Young Jung 
Department of IT Convergence  
Daegu Gyeongbuk Institute of Science and Technology 
Daegu, Republic of Korea  
wyjung@dgist.ac.kr
 
 
Abstract— In this paper, we present an approach to automatic 
cattle detection and localization system from natural scenes. 
Cattle shed scene has complex background and various 
illumination. In this reason, the proposed approach includes 
object detection method in complex background using active 
tags and RGB color filtering. In addition, we proposed 
localization method using image data and RFID data. First, we 
narrow down the localization range using RFID data. Then, we 
estimate more accurately the object location using vision-based 
methods. 
Keywords-animal localization; cattle shed surveillance 
system   
I. 
 INTRODUCTION 
Robust object localization and object detection method 
have applications including gaming, security, defense and 
even medical service.  
Recently, domestic stock farmers suffered from highly  
contagious livestock diseases, such as the Foot-and 
-mouth disease (FMD). These kind of contagious livestock 
diseases have often initial symptom of high temperature. For 
this reason, it is necessary to sense a temperature change of 
cattle in stock farms. Additionally, we are able to early 
detect and isolate a cow which has high temperature change 
through each object localization. This is important because 
isolation of an ill cattle prevents spread of the disease. 
Furthermore, we should isolate not only the sick cattle but 
also a group containing the sick cattle. Previous researches 
[1] of finding a group containing target object are less 
accurate in cattle shed.  For this reason, we propose a 
vision-based cattle localization and detection system in 
stock farm. Our system performs vision-based ill cattle 
detection and localization, as shown in Fig. 1. Target stock 
farm is divided into multiple room. We called each room 
“cattle shed cell” and each cell has unique number as Fig. 1. 
Each cattle shed cell has one or two cows. Our system has 
one camera per each axis. Each camera can move 
horizontally on axis. We utilize the active tag [3] and Radio 
Frequency Identification (RFID) [4] information and camera 
images for assistance of object detection. Each active tag 
works along with temperature sensor. We put active tag and 
RFID on each cow’s body. In other words, each cow has an 
active tag and a RFID chip. When it senses an increase in 
temperature that is above a given threshold, the tag light 
associated with the sensor lights up. We detect the active tag 
and estimate the object’s localization. Then, mobile cameras 
collect cattle’s image data using object position information.  
Object localization and detection systems have two 
problems. Generally, vision-based object detection system 
has less accuracy on brightness change. As mentioned 
earlier, we propose active tag as technical assistance. It has 
merits and demerits. It helps the systems to achieve high 
accuracy by detection in dark environment, but it requires 
checking the batteries periodically. Second, it is difficult to 
estimate the object’s location in a natural scene by using 
vision-based methods.  
Our localization method has two steps. We localize object 
cattle using RFID primarily. We narrow down the 
localization range using RFID location information. Then, 
we estimate the object’s location using vision-based method. 
A common approach is a region-based method, which uses 
multiple feature or high complexity feature and Adaboost or 
neural network. [5],[6],[7]. This method needs a diverse 
training dataset and multi-features require large processing 
time. Also, the recently proposed camera-based real time 
mapping for Simultaneous Localization And Mapping 
(SLAM) [8],[9],[10] is not suitable for stock farm 
environment.   
                  Figure 1.  Vision-based ill cattle localization system 
 
173
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

Start
Some cattle＇s body 
temperature are rising
Temperature sensor runs
RFID provides the cattle 
shed cell number
High temperature cattle＇s 
active tag turn on
Allocate camera in the 
cattle shed cell
Camera is allocated in a spot where camera can see the 
high temperature cow using RFID information
Take images using four cameras
Detect active tag using color information
Localize object using LUT
Take cow＇s detail images using cow＇s position 
information
Send images to system 
manager.
 
Figure 2. System Flow Chart 
II. 
CATTLE DETECTION AND LOCALIZATION SYSTEM 
In this section, we describe our system. We proposed ill 
cows detection and localization system in stock farms.  Fig. 2 
shows a system overview. This vision-based system works 
when the cattle’s body temperature rises. If some cattle’s 
temperature 
rises, 
the 
cattle’s 
RFID 
provides 
the 
corresponding shed number. At the same time, the cattle’s 
active tag turns on and four cameras convey the location of 
the targeted cow using the light Images are captured by these 
four cameras. An active tag has brighter and clearer color 
than general object. Accordingly, we detect active tags using 
color filtering. We make a localization map using color 
markers as Figs. 4(c), (d) and (e). Also, we estimate the 
active tag’s position using matching LUT (Look-up table). 
LUTs are trained beforehand. We record the image of the 
affected cow using the estimated position. Finally, we send 
images to system administrator. These images are used for 
cattle shed management service.     
 
Figure 3. Active tag sample 
A. 
Cattle detection in RGB color space 
Real datasets in cattle shed have more problems than 
indoor images. These images are more sensitive to lighting 
variation. In order to solve the problem, we propose active 
tags that provide illumination invariant color information. 
Our active tag is made of LEDs, as shown in Fig. 3.  Each 
cow has one active tag, and each active tag turns on when the 
cow has high temperature.  
Our active tag gives out a red light. Using this simple fact, 
we perform normalized color filtering to detect active tag. R-
band pass filter has high weight. 
B. 
Processing region define method and object 
localization using color marker and RFID information 
A common approach is vision-based probabilistic model 
[11]. Natural scene includes various color and illumination. 
For this reason, it is difficult to perform object localization in 
wide natural scene. In order to solve the problem, we defined 
processing region using RFID information and color marker 
as shown in Figs.4 (b).  Fig. 4.(d) and (e) show color marker 
examples. The marker is placed at one meter interval. We 
make color marker-based localization map as shown in Fig.4 
(c). We have absolute position of four cameras. Thus, we 
estimate active tag position using LUT. 
LUTs are trained beforehand using k-means clustering 
and Euclidean distance. We perform the training using 640 
images. In order to overcome various illumination in cattle 
shed images, these images have two types brightness, such as 
0.15klux, 0.3klux.  
III. 
EXPERIMENT RESULT 
We have tested our system on real datasets and test 
datasets. Real datasets are captured at the target cattle shed 
as shown in Fig. 4 (a), and test datasets take our indoor test-
bed as shown in Fig. 5. These images are captured in jpeg 
RGB colored form in the size of 1600*1200 pixels. The 
indoor test-bed size is 4 meters * 6meters. We used Intel 
Xeon 3.2GHz, 16G RAM, Win7, Visual Studio C++ 2008 in 
all of our computations. Fig. 6 shows the system’s GUI. 
The test-bed has 1 meter x 1 meter grid, as shown in Fig. 
5. Each grid component has unique number. We evaluate the 
localization system using the grid. 
In our research, the performance of object detection is 
79.16%. Localization performance is 71.52%. The main 
reasons of errors are comprised of two categories, as follows. 
l 
Images have various illuminations. Because part of test 
images is a natural scene, the images have shadows 
spots and sunny spots. A sunny spot is so much brighter 
than an active tag. It is difficult to detect an active tag in 
sunny spots.  
174
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

l 
Camera’s position and PTZ (Pen, Tilt, Zoom) have 
errors because four cameras are mobile cameras. To 
solve this matter, we need to perform camera calibration. 
Camera calibration reduces error rate, but camera 
calibration method requires a considerable processing 
time.   
 
 
Figure 4. Experiment result in real cattle shed dataset 
 
 
Figure 5. Indoor Testbed 
 
Figure 6. System GUI 
IV. 
DISCUSSION AND FUTURE WORK 
In this paper, we proposed object detection and 
localization in cattle shed. Cattle shed images has complex 
background and a variety of illumination changes. In 
illumination changes, the color active tag-based method is 
used for detection. In addition, our localization method is 
attractive. The proposed localization method has two steps. 
First, we estimate rough location using RFID. Then, we 
localize object using vision-based method. We have tested 
our approach on a number of real datasets, demonstrated its 
good capabilities of cattle shed area.  
Object detection is difficult in cattle shed because cattle 
shed images have a lot of image noise. Our future work 
involves color filtering method and image segmentation 
method to solve illumination and complex background 
problem. Also, we need to solve the camera calibration 
problem. We will continue developing our detection and 
localization algorithm.  
ACKNOWLEDGEMENT 
This research was financially supported by the Ministry 
of Knowledge Economy (MKE), Korea Institute for 
Advancement of Technology (KIAT) through the Inter-ER 
Cooperation Projects. No. R0000577 
REFERENCES 
[1] M. D. Fresno, “Application of Color Image Segmentation to Estrus 
Detection”. Journal of Visualization, vol.9, no. 2, 2006, pp. 171-178 
[2] D. T. Booth, “Image-based monitoring to measure ecological change 
in rangeland”. Front. Ecol. Environ. vol.6, 2008, pp. 185-190 
[3] M. Sakata, “ALTAIR: automatic location tracking system using 
active IR-tag”. IEEE Conf. Multisensor Fusion and Integration for 
Intelligent systems, 2003, pp. 299-304 
[4] J. Landt, “The history of RFID”. Potentials, IEEE, vol. 24, no. 4, 
2005, pp. 8–11 
[5] H. Takahashi. “Region graph based text extraction from outdoor 
images”. In Proc. Third Int.l Conf. Information Technology and 
Applications (ICITA'05), 2005, pp. 680-685. 
[6] H. Takatsuka, M. Tanaka, and M. Okutomi. “Distribution-based face 
detection using calibrated boosted cascade classifier”. In Proc. 14th 
Int.l Conf. Image Analysis and Processing (ICIAP'07), 2007, pp. 351-
356. 
[7] S. M. Hanif and L. Prevost. “Text Detection and Localization in 
Complex Scene Images using Constrained AdaBoost Algorithm”. 
ICDAR, 2009, pp.1-5. 
[8] M. Agrawal and K. Konolige  "Real-time localization in outdoor 
environments using stereo vision and inexpensive GPS".  Proc. Intl. 
Conf. Pattern Recog. (ICPR), 2006,  pp.1063-1068. 
[9] M. Dissanayake , P. Newman , S. Clark , H. Durrant-Whyte, and M. 
Csorba  "A solution to the simultaneous localization and map 
building (SLAM) problem".  IEEE Trans. Robot. Autom.,  vol. 17,  
no. 3, 2001, pp. 229 -241. 
[10] A. Davison  "Real-time simultaneous localisation and mapping with a 
single camera".  Proc. Int. Conf. Comput. Vis. (ICCV), 2003,  pp. 
1403 -1410. 
[11] B.Krose, R. Bunschoten, “Probabilistic localization by appearance 
models and active vision”. Proc. In. conf. Robot. 1999, pp. 2255-2260 
175
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

