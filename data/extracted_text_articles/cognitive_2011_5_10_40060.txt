A new Ranking Technique for Integration among Higher-Level and Lower-Level 
Domain Ontologies and its Application to the Electromagnetic Domain 
 
Alessandra Esposito, Marco Zappatore and Luciano Tarricone 
Dept. of Engineering for Innovation 
University of Salento 
73100 Lecce, ITALY 
{alessandra.esposito; marcozappatore; luciano.tarricone}@unisalento.it 
 
 
Abstract – Nowadays ontologies represent a largely adopted 
information codification technique in many knowledge 
domains. 
Complex 
ontological 
frameworks 
have 
been 
developed in diverse areas, presenting the association of 
different levels of logic and semantic abstraction. These 
structures gather general contents (Domain Ontologies) and 
integrate them with more specific concepts (Subdomain and 
Application Ontologies). However, integration procedures may 
bring about complex issues such as semantic overlaps and 
knowledge base modifications. In order to minimize the 
occurrence of such events, an accurate selection and evaluation 
phase is advisable. In this paper we propose a methodology to 
evaluate higher-level domain ontologies in order to determine 
which candidate ontology would perform better if integrated 
with lower-level ones. The methodology is based on the 
computation of a set of multi-purpose ad-hoc metrics that are 
used as evaluation criteria in a multi-decisional ranking 
process. The methodology is applied to a real-life integration 
case study in the Electromagnetic knowledge domain. Two 
well-known scientific ontology frameworks are selected and 
evaluated in order to determine their suitability to provide a 
mid-level to proprietary Electromagnetic ontologies.  
Keywords – ontology, metric, ranking technique, integration . 
I. 
 INTRODUCTION  
Recent years have seen a constant increase in ontology 
usage among heterogeneous scientific domains. Such 
rigorous formalizations [1] provide a globally accepted way 
of codifying knowledge and promoting information sharing 
and reuse across different research organizations. From 
Astronomy [2] to Healthcare [3], ontologies find a great 
variety of applications. On the contrary, the Electromagnetic 
(EM) scientific area did not benefit from robust ontological 
codifications so far.  
The authors paved this way by proposing OntoCEM 
(Ontological Codification of ElectroMagnetism) [4]. The 
semantic description and integration of different branches of 
Electromagnetism is at the basis of OntoCEM. However, 
such ambitious goal hides many of the issues related to 
ontology merging procedures. Indeed, joining diverse 
ontologies may collide with potentially severe semantic 
heterogeneity of data, causing content overlaps or requiring 
knowledge base adjustments. At the same time, the need of 
an ontological superstructure made up of general scientific 
concepts (i.e., scientific domain ontologies) from which EM 
concepts (i.e., EM application ontologies) can inherit 
properties is perceived as well. This leads to the adoption of 
a hierarchical architecture [5], based on different layers of 
semantic abstraction and on the reuse of available ontologies. 
As a consequence, a deep integration activity is required. 
In order to reduce typical issues that weigh down 
integration procedures, specific techniques for examining the 
ontologies that should be merged together are needed. 
Semantic completeness, domain adequacy and reusable 
contents availability are just a small example of the 
requirements that should be satisfied. 
Evaluation metrics represent a common method to 
numerically establish the “goodness” of an ontology, as they 
take into account many of its aspects. A great amount of 
these metrics is nowadays available in literature, which 
consider ontology structure [6] and contents [7]. 
In this paper, rather than focusing on single metrics we 
propose a thorough methodology based on the computation 
of heterogeneous metrics and on their synthetical evaluation 
through a multi-decisional scoring process. The methodology 
is adopted to determine the best candidate for the integration 
with the EM ontologies defined in OntoCEM. 
OntoCEM is briefly described in Section II. Section III 
introduces the proposed analysis technique. Sections IV to 
VI detail such technique, providing a tangible evaluation use 
case in the EM domain. 
II. 
RELATED WORK 
Ontological evaluation techniques based on the analysis 
of the design choices [8] have been proposed since late ‘90s. 
These methods evaluate ontologies without considering how 
ontology contents affect integration procedures. Kalfoglu et 
al. [7], instead, focus on this aspect by proposing distance 
measurements among different entities belonging to the 
same ontology or among entities codifying the same concept 
in different ontologies. Hu et al. [9] present a lattice-based 
similarity metric. Yunjiao et al. [10] extend classical tree 
similarity measurements towards content examination by 
considering domain expert contribution in evaluating the 
similarity between concept meanings. Other works measure 
semantic similarity by adopting lexical databases (i.e., 
WordNet) and by analyzing synonyms and hierarchical 
relationships. Among them, we recall GLUE [11], 
COMA++ [12] and SeCoOn [13].  
110
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

Our proposal differs from previous works as we suggest 
an integrated approach based on the computation of 
heterogeneous metrics, which examine different ontological 
issues and on their aggregation by means of a consolidated 
ranking procedure. Finally, the entire evaluation process 
adopts a real-life scenario as benchmark case: i.e., the 
choice of the best-suited ontology for providing a scientific 
mid-level to an ontological framework describing the 
electromagnetism knowledge domain. 
III. 
ONTOCEM ARCHITECTURE 
As depicted in Fig. 1, OntoCEM [14] is organized into 
three semantic layers codified in OWL2-DL [15] language. 
The top level comprises publicly reusable scientific domain 
ontologies, collecting general concepts that belong to Math 
and Physics knowledge domains. The mid level gathers EM 
domain ontologies: these proprietary modules describe 
several EM branches and topics such as antennas, EM fields, 
EM propagation mechanisms, EM measurement units, etc. 
At the bottom there are ontologies describing specific EM 
applications, such as: shielding techniques, specific 
microwave devices, CAD processes, etc. Moving upward 
along the stack, contents become more and more abstract. 
 
 
Figure 1.  OntoCEM architecture. 
IV. 
ONTOLOGY EVALUATION TECHNIQUE 
Choosing the scientific domain ontology that would 
perform better if integrated with EM proprietary ontologies 
requires the application of a rigorous methodology. We 
propose a three-step technique, as described in Fig.  2. 
Firstly, candidate scientific domain ontologies are 
selected by considering the following requirements: OWL-
DL codification language, public availability and modularity.  
Secondly, multi-purpose metrics are computed in order to 
analyze candidates in terms of size, structure, content, 
integration effort and reusability. 
Thirdly, the candidates are ranked by using those metrics 
as performance criteria in a well-known multi-decisional 
process. 
This 
results 
in 
a 
rigorous, 
unambiguous 
classification. 
 
 
Figure 2.  Proposed evaluation methodology. 
V. 
SELECTING THE CANDIDATE ONTOLOGIES 
We selected candidate ontologies by identifying 
scientific semantic frameworks that mainly deal with Math 
and Physics domains. We searched for openly available, 
highly modular and wide ontology sets codified in OWL-DL 
in order to fulfill reusability and selective import 
requirements.  
From such bases, two corpora of ontologies were chosen: 
the ontologies published by the Astronomical Department of 
the University of Maryland (UMD) [16] and the Semantic 
Web for Earth and Environmental Terminology (SWEET) 
Ontologies [17].  
VI. 
COMPUTING THE METRICS 
Three sets of metrics have been defined, each taking into 
account a different ontological aspect: 1) size and structure; 
2) contents; 3) suitability to integration.  In the following, the 
metrics are first described and then computed against the 
selected candidate ontologies. 
A. Overall considerations 
Although the proposed metrics refer to heterogeneous 
features of an ontology, they are designed to share common 
characteristics in order to make their behavior as uniform as 
possible.  
• 
Metrics are closed-ended, i.e., defined in a closed 
numerical range. More in detail, the range is [0;1]. 
• 
Metrics producing out-of-bounds values require a 
linear scaling transformation (1) in order to be 
normalized to the definition range given above. 
 
𝑥𝑥𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛 =
𝑥𝑥𝑎𝑎− min
𝑖𝑖 {𝑥𝑥𝑖𝑖}
max
𝑖𝑖
{𝑥𝑥𝑖𝑖} − min
𝑖𝑖 {𝑥𝑥𝑖𝑖} 
  (1) 
 
Where xa is the actual value of the metric, xnorm its 
normalization and xi all its possible values. 
• 
Metrics must produce a maximization problem. 
Metrics behaving differently are suitably converted 
by complementing them. 
B. Size and Structure-related Metrics 
The first set of metrics monitors typical design aspects 
related to OWL language and do not consider any domain-
related issue. Although they are relatively simple, structural 
metrics reveal themselves as an important source of 
information, especially for wide ontologies. 
 
Class to Entity ratio (CtEr) measures the ratio between 
the total number of classes (nCl) and the total number of 
entities (nEnt).  
𝐶𝐶𝐶𝐶𝐶𝐶𝑛𝑛 = 𝑛𝑛𝐶𝐶𝑛𝑛
𝑛𝑛𝐶𝐶𝑛𝑛𝐶𝐶 
  
(2) 
 
Property to Entity ratio (PtEr) and Instance to Entity 
ratio (ItEr) quantify property and instance presence, as it  is 
recognized to enrich the ontology [18]. Indeed, the less 
properties and instances there are, the more the ontology 
111
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

resembles a mere taxonomy made up only of “is-A” 
relationships.   
 
𝑃𝑃𝐶𝐶𝐶𝐶𝑛𝑛 = 𝑛𝑛𝑛𝑛𝑃𝑃 + 𝑛𝑛𝑛𝑛𝑃𝑃
𝑛𝑛𝐶𝐶𝑛𝑛𝐶𝐶
 
 (3) 
 
𝐼𝐼𝐶𝐶𝐶𝐶𝑛𝑛 = 𝑛𝑛𝐼𝐼𝑛𝑛𝑛𝑛𝐶𝐶
𝑛𝑛𝐶𝐶𝑛𝑛𝐶𝐶 
(4) 
 
where nOP, nDP and nInst represent the number of 
Object Properties, Datatype Properties and Instances 
respectively.  
 
Entities per Module ratio (EpMr) is the ratio between 
the number of entities (nEnt) and the number of available 
modules (nM) in the ontology. 
 
𝐶𝐶𝐸𝐸𝐸𝐸𝑛𝑛 = 𝑛𝑛𝐶𝐶𝑛𝑛𝐶𝐶
𝑛𝑛𝐸𝐸  
(5) 
 
This is a non-normalized, bounded quantity. Its lower 
bound is the case of one entity per module, EpMrmin=1 and 
its upper bound is represented by all the entities defined in 
only one module, that gives: EpMrMAX=nEnt. Therefore, 
recalling (1), the normalized ratio (EpMrnorm) is: 
 
𝐶𝐶𝐸𝐸𝐸𝐸𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛 =
ቀ𝑛𝑛𝐶𝐶𝑛𝑛𝐶𝐶
𝑛𝑛𝐸𝐸 ቁ − 1
𝑛𝑛𝐶𝐶𝑛𝑛𝐶𝐶 − 1  
(6) 
 
In order to avoid modules huge in size and problems in 
finding contents, the value of this metrics should be as low as 
possible. Therefore, the complemented metrics (7) is 
considered: 
 
𝐶𝐶𝐸𝐸𝐸𝐸𝑛𝑛 = 1 − 𝐶𝐶𝐸𝐸𝐸𝐸𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛𝑛  
(7) 
 
Table I presents size metric computation results with 
respect to the candidates. UMD ontologies showed a better 
performance in terms of CtEr whilst SWEET are preferable 
in terms of the other metrics. Better values for each metric 
have been highlighted. 
TABLE I.  
SIZE METRIC COMPUTATION RESULTS 
Metric 
UMD  
SWEET  
CtEr 
0.88 
0.63 
PtEr 
0.06 
0.08 
ItEr 
0.05 
0.28 
EpMr 
0.923 
0.995 
 
C. Content-related Metrics 
These metrics examine domain-related information. 
Entities defined in candidate ontologies are partitioned into 
three subsets and must be identified by a domain expert. 
• 
Scientific (S) entities: scientific concepts capable of 
acting as valid superclasses or useful reusable 
properties for EM concepts defined in OntoCEM 
ontologies. Their number is indicated as nS. 
• 
Electromagnetic (E) entities: concepts concerning 
EM. As EM concepts are located in OntoCEM 
modules as well, E entities may generate semantic 
conflicts during the integration procedure. Therefore 
it is preferable to have only a small quantity (nE) of 
them in candidate ontologies.  
• 
Unusable (U) entities are entities that belong neither 
to S nor to E set. The number nU of U entities should 
be as low as possible, in order to reduce ontology 
loading times.  
Additionally, we indicated as ES modules the modules 
comprising at least one S or E entity.  
Table II enlists some S and E entities. 
 
TABLE II.  
EXAMPLES OF S AND E ENTITES 
Scientific (S) Entities 
Electromagnetic (E) Entities 
Classes 
Physical Property; Energy; 
Function; Scientific Model; 
Vector; Integral; Transmitter; 
Orientation;; Algorithm... 
Remote Sensing; Electric 
Dipole;  Diffraction; EM 
Spectrum; Antenna; 
Wavelength; Microwave… 
Object Properties 
has Effect; has Component; has 
Unit; has Force… 
Radiate; has Frequency; has 
Spectral Band… 
Datatype Properties 
has Probability; has Scale; has 
Numeric Value…  
has Scattering Coefficient; has 
Resonant Frequency...  
Instances 
Sn; X Axis; Meter; per Second; 
dB; Joule; FFT... 
SNR; Ohm; Refractive Index; 
MHz; Siemens; Volt per meter…  
 
Domain Scientific Richness (DSR) weights the presence 
of S concepts. 
 
𝑛𝑛𝐷𝐷𝐷𝐷 =
𝑛𝑛𝐷𝐷
𝑛𝑛𝐷𝐷 + 𝑛𝑛𝐶𝐶 + 𝑛𝑛𝑛𝑛 
(8) 
 
Domain EM Richness (DER) quantifies the presence of 
E concepts. 
 
𝑛𝑛𝐶𝐶𝐷𝐷 = 1 −
𝑛𝑛𝐶𝐶
𝑛𝑛𝐷𝐷 + 𝑛𝑛𝐶𝐶 + 𝑛𝑛𝑛𝑛 
(9) 
 
Loading Overhead (LO) assess the presence of U 
concepts. 
 
𝐿𝐿𝑛𝑛 = 1 −
𝑛𝑛𝑛𝑛
𝑛𝑛𝐷𝐷 + 𝑛𝑛𝐶𝐶 + 𝑛𝑛𝑛𝑛 
(10) 
 
Table III shows computation results for the candidates. 
Better values for each metric have been highlighted. As 
UMD and SWEET content metrics have discordant values, a 
unifying methodology is needed. This technique will be 
described in Section VI. 
 
 
112
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

TABLE III.  
CONTENT METRIC COMPUTATION RESULTS 
Metric 
UMD  
SWEET  
DSR 
0.44 
0.59 
DER 
0.94 
0.93 
LO 
0.5 
0.66 
 
D. Integration-related Metrics 
In order to evaluate how suitable a candidate ontology is 
to be integrated with available lower-level ontologies, we 
propose an approach based on the simulation of integration 
tasks. 
First of all, a set of concepts (named benchmark entities, 
BE) codified in the lower-level ontology has to be identified 
on the basis of “structural” and/or “semantic” considerations. 
Indeed, we selected classes that subsume a great number of 
concepts and/or that are relevant from a domain expert point 
of view. Table IV enlists the chosen entities and provides a 
brief description for each of them. They are taken from each 
of the ten EM domain modules defined in OntoCEM mid-
level (see  Fig. 1). 
TABLE IV.  
LIST OF BENCHMARK ENTITIES (BE) 
EM Concept 
Role in OntoCEM 
OntoCEM module 
Antenna 
Root concept subsuming all antenna 
typologies 
Antenna 
Radio  
Propagation Model 
Root concept describing scientific models 
that estimate signal attenuation due to Path 
Loss in wireless communication systems 
EM Propagation 
Uniform Plane Wave 
Particular solution of Maxwell’s equations 
with electric field assuming the same 
magnitude and phase in all planes 
perpendicular to the direction of propagation 
EM Waves 
MilliVolt per meter 
A common unit of measurement for electric 
field strength values 
EM Units 
Dielectric Medium 
Root concept extended by all other insulator 
media 
EM Medium 
Method of Moments 
It is a general numerical technique for 
solving EM problems stated in terms of an 
inhomogeneous equation 
EM Analysis 
RF Measurement 
Root concept subsuming all kinds of 
measurements performed at RF frequencies 
EM Measurements 
Plane Wave Shielding 
It is the process that determines a total or 
partial block of EM radiation (propagating 
as a plane wave) in a far field region 
EM Compatibility 
Spectrum Analyzer 
Fundamental EM instrument for measuring 
the frequencies present in a complex signal 
or resulting from modulation on a carrier 
EM Instruments 
Passive Microwave 
Device 
Root concept subsuming all passive 
components operating at microwave 
frequencies 
Microwave Devices 
 
We designed three metrics adapting metrics proposed 
from Zhang in [6]. Such metrics must be computed with 
respect to each BE, then they are mediated over the total 
number of BE (nBE). 
 
Ancestor Domain Pertinence (ADP). This metric was 
constructed starting from the so-called Depth of Inheritance 
metric (DoI) [6]. DoI quantifies the distance of the class 
identified as the best ancestor for the current BE from the 
root class of the candidate ontology. This distance represents 
the overall set of superclasses for the BE. However, DoI does 
not provide any information about the validity of those 
classes from a domain expert point of view. This additional 
feature is provided by ADP metric. It computes the ratio 
between the total number of “appropriate ancestors” (nSA) 
and DoI, according to the following formula:  
 
𝐴𝐴𝑛𝑛𝑃𝑃 =
∑
𝐴𝐴𝑛𝑛𝑃𝑃𝑖𝑖
𝑛𝑛𝑛𝑛𝐶𝐶
𝑖𝑖=1
𝑛𝑛𝑛𝑛𝐶𝐶
,
𝐴𝐴𝑛𝑛𝑃𝑃𝑖𝑖 = 𝑛𝑛𝐷𝐷𝐴𝐴𝑖𝑖
𝑛𝑛𝑛𝑛𝐼𝐼𝑖𝑖
 
(11) 
 
ADPi refers to the i-th BE and ADP is the arithmetic 
mean over the nBE. The closer to zero ADP is, the more 
unfitting the superclasses are. 
 
DoI Deviation (DoID). This metric is derived from DoI 
as well. It takes into account the maintenance issues, which 
could occur when the distance from the root class is too long 
(i.e., DoI is high). In this case, a modification in higher-level 
scientific 
domain 
concepts 
can 
involve 
relevant 
modifications in lower-level EM ontologies [6]. Therefore 
we set a reference value (DoIREF) and measure the deviation 
of DoIi from it. DoIDi is normalized to the range [0;1] and 
converted to a maximization metric. DoID is its arithmetic 
mean.  
 
𝑛𝑛𝑛𝑛𝐼𝐼𝑛𝑛 =
∑
𝑛𝑛𝑛𝑛𝐼𝐼𝑛𝑛𝑖𝑖
𝑛𝑛𝑛𝑛𝐶𝐶
𝑖𝑖=1
𝑛𝑛𝑛𝑛𝐶𝐶
   , 
 
𝑛𝑛𝑛𝑛𝐼𝐼𝑛𝑛𝑖𝑖 = 1 −
|𝑛𝑛𝑛𝑛𝐼𝐼𝐷𝐷𝐶𝐶𝑅𝑅 − 𝑛𝑛𝑛𝑛𝐼𝐼𝑖𝑖|
𝑛𝑛𝑎𝑎𝑥𝑥{𝑛𝑛𝑛𝑛𝐼𝐼𝑖𝑖, 𝑛𝑛𝑛𝑛𝐼𝐼𝐷𝐷𝐶𝐶𝑅𝑅} 
(12) 
 
The closer to one DoID is, the closer to the reference the 
actual DoI value is. We selected DoIREF=3 as a proper 
reference. 
 
Domain Property Reusability (DPR). It analyzes how 
the descriptive statements for the benchmark entity can be 
rendered. DPR is the ratio between the reusable OWL 
properties belonging to higher-level ontologies (nRPi) and 
the number of natural language restrictions (nNLRi ≥ nRPi) 
needed to codify the descriptive statement for the i-th 
benchmark entity: 
 
𝑛𝑛𝑃𝑃𝐷𝐷 =
∑
𝑛𝑛𝑃𝑃𝐷𝐷𝑖𝑖
𝑛𝑛𝑛𝑛𝐶𝐶
𝑖𝑖=1
𝑛𝑛𝑛𝑛𝐶𝐶
,
𝑛𝑛𝑃𝑃𝐷𝐷𝑖𝑖 = 𝑛𝑛𝐷𝐷𝑃𝑃𝑖𝑖
𝑛𝑛𝑛𝑛𝐿𝐿𝐷𝐷𝑖𝑖
 
(12) 
 
The closer to one the DPR is, the more preferable the 
ontology is. Indeed, by counting the number of reusable 
properties, we measure how the higher-level ontology 
facilitates the integration enhancement. On the contrary, a 
DPR close to zero denotes a small reusability.  
113
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

Considering all the BE detailed in Table IV, the 
candidate ontologies feature the following mean values in 
terms of ADP, DoID and DPR metrics (Table V). SWEET 
ontologies performed better with respect to all the integration 
metrics. Better values for each metric have been highlighted. 
TABLE V.  
INTEGRATION METRIC COMPUTATION RESULTS 
Metric 
UMD  
SWEET  
ADP 
0.667 
0.91 
DoID 
0.398 
0.659 
DPR 
0.386 
0.711 
 
VII. RANKING THE CANDIDATE ONTOLOGIES 
In previous sections, metric computation produced 
discordant results. In order to assess which candidate is the 
best suited for the integration procedure in a rigorous and 
unambiguous way, we adopted a multi-decisional scoring 
technique. We selected the ELECTRE-I method [19]. It is 
the simpler version of the ELECTRE methods (ELimination 
Et choix Traduisant la REalité, that stands for Elimination 
and Choice Expressing the Reality). Such methodologies are 
widely used for their ability to cope with criteria giving 
contrasting evaluations.  
A. Overall Considerations 
Our metrics, called evaluation criteria (C={Ci}, i=1,...,m) 
according to ELECTRE terminology, are weighted by using 
subjective quantities (W={wi}, i=1,...,m). A decision table 
(Table VI) is populated by the scores aij, expressing the 
performance of the Ai alternative against the Cj criterion. The 
alternatives 
are 
compared, 
in 
pair, 
by 
calculating 
concordance (cjk) or discordance (djk) indices [19] according 
to (13) formulas.  
 
𝑐𝑐𝑗𝑗𝑗𝑗 =
∑
𝑤𝑤𝑖𝑖
𝑖𝑖∈ቀ𝑪𝑪𝑗𝑗𝑗𝑗
+ ∪𝑪𝑪𝑗𝑗𝑗𝑗
= ቁ
∑
𝑤𝑤𝑖𝑖
𝑖𝑖∈𝑪𝑪𝑗𝑗𝑗𝑗
= ∑
𝑤𝑤𝑖𝑖
𝑖𝑖∈ቀ𝑪𝑪𝑗𝑗𝑗𝑗
+ ∪𝑪𝑪𝑗𝑗𝑗𝑗
= ቁ
   , 
 
𝑑𝑑𝑗𝑗𝑗𝑗 =
max 𝑖𝑖∈𝑪𝑪𝑗𝑗𝑗𝑗
− ൛𝑤𝑤𝑖𝑖ห𝑎𝑎𝑖𝑖𝑗𝑗 −𝑎𝑎𝑖𝑖𝑗𝑗 หൟ
max 𝑖𝑖∈𝑪𝑪൛𝑤𝑤𝑖𝑖ห𝑎𝑎𝑖𝑖𝑗𝑗 −𝑎𝑎𝑖𝑖𝑗𝑗 หൟ    , 
 
𝑪𝑪𝑗𝑗𝑗𝑗 = 𝑪𝑪𝑗𝑗𝑗𝑗
+ ∪ 𝑪𝑪𝑗𝑗𝑗𝑗
= ∪ 𝑪𝑪𝑗𝑗𝑗𝑗
−  
 
  
(13) 
where C+
jk, C=
jk and C–
jk represent respectively the subset 
of criteria against which alternative Aj is better, equivalent 
and worst than Ak.  
TABLE VI.  
ELECTRE-I TYPICAL DECISION TABLE 
Criteria 
Weights 
Alternatives 
 
 
 
A1 
. 
. 
An 
 
C1 
W1 
a11 
. 
. 
a1n 
A1 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
. 
Cm 
wm 
am1 
. 
. 
amn 
An 
 
In order to assert that the alternative Aj outranks Ak, the 
concordance index should be at the same time above a 
concordance threshold cth and the discordance index should 
be below a discordance threshold dth (14), where cth and dth 
are the mean values of the indices calculated over the n 
alternatives [19]. 
 
⎩
⎪⎪
⎨
⎪⎪
⎧𝑐𝑐𝑗𝑗𝑗𝑗 ≥ 𝑐𝑐𝐶𝐶ℎ =
1
𝑛𝑛(𝑛𝑛 − 1) ෍ ෍ 𝑐𝑐𝑗𝑗𝑗𝑗
𝑛𝑛
𝑗𝑗=1,
𝑗𝑗≠𝑗𝑗
𝑛𝑛
𝑗𝑗 =1
𝑑𝑑𝑗𝑗𝑗𝑗 ≤ 𝑑𝑑𝐶𝐶ℎ =
1
𝑛𝑛(𝑛𝑛 − 1) ෍ ෍ 𝑐𝑐𝑗𝑗𝑗𝑗
𝑛𝑛
𝑗𝑗=1,
𝑗𝑗≠𝑗𝑗
𝑛𝑛
𝑗𝑗 =1
 
  
(14) 
 
B. Candidates ranking 
First of all, criterion weights were defined. We assumed 
[19] that the sum of the weights of all criteria equals to 1. 
Then, we distributed the weights amongst the three sets of 
metrics. We assigned heavier weights to sets better 
complying with our major objective, i.e., integration between 
our EM ontologies. Therefore, content and integration sets 
were both given a weight of 0.4. The set containing size 
metrics, which are general-purpose, was instead given a 
weight equal to 0.2. The same criterium was adopted to 
distribute weights among the single metrics belonging to 
each set.  
Therefore, size metrics (i.e., CtEr, PtEr, ItEr and EpMr) 
share the same weight. 
Among content-related metrics (i.e., DSR, DER and LO), 
the first one is the most relevant in our opinion. Indeed, the 
more S entities there are, the more suitable to integration the 
scientific candidate ontology could be. In addition, E entities 
introduce semantic overlaps, which may render the 
integration task onerous, therefore the DER metric has the 
second heaviest weight. 
As to integration metrics, we assigned the heaviest 
weight to ADP, as it expresses the scientific suitability of 
higher-level concepts.  
Table VII resumes the final decision table. The highest 
scores for each criteria have been highlighted.  
TABLE VII.  
CANDIDATE ONTOLOGIES DECISION TABLE 
Ci 
wi 
A1  
(UMD) 
A2 
(SWEET) 
CtEr 
0.05 
0.88 
0.63 
PtEr 
0.05 
0.06 
0.08 
ItEr 
0.05 
0.05 
0.28 
EpMr 
0.05 
0.923 
0.995 
DSR 
0.2 
0.44 
0.59 
DER 
0.15 
0.94 
0.93 
LO 
0.05 
0.5 
0.66 
ADP 
0.2 
0.667 
0.91 
DoID 
0.1 
0.398 
0.659 
DPR 
0.15 
0.386 
0.711 
 
The following matrices report the concordance and 
discordance indices of the alternatives. 
 
114
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

𝐶𝐶 = ቂ ∙
𝑐𝑐12
𝑐𝑐21
∙ ቃ = ቂ ∙
0.2
0.8
∙ ቃ 
(15) 
 
𝑛𝑛 = ൤ ∙
𝑑𝑑12
𝑑𝑑21
∙ ൨ = ቂ
∙
1
0.256
∙ ቃ 
(16) 
 
According to (14), we have the following concordance 
and discordance conditions against respective thresholds:  
 
൜ (𝑐𝑐12 = 0.2) < (𝑐𝑐𝐶𝐶ℎ = 0.5)
(𝑑𝑑12 = 1) > (𝑑𝑑𝐶𝐶ℎ = 0.628)
 
(17) 
 
൜
(𝑐𝑐21 = 0.8) > (𝑐𝑐𝐶𝐶ℎ = 0.5)
(𝑑𝑑21 = 0.256) < (𝑑𝑑𝐶𝐶ℎ = 0.628)
 
(18) 
 
Since (18) satisfies both the conditions, the alternative A2 
(i.e., SWEET ontologies) shows a better integration behavior 
rather than A1 (i.e., the UMD ontologies).  
These results confirmed the assessments given by 
independent electromagnetic knowledge domain experts 
who, based on a preliminary overview of their content and 
on the evaluation of their “electromagnetic soundness”, 
accounted SWEET ontologies as the most profitable choice 
among candidates. 
VIII. CONCLUSIONS 
In this paper, a proposal for a ranking methodology 
dealing with scientific domain ontologies has been proposed. 
The aim of this evaluation technique is to assess, in a 
possibly rigorous way, how suitable to be integrated with 
EM ontologies a scientific domain ontology could be. In 
order to do that, a set of multi-purpose ontological metrics 
has been defined. They consider different aspects such as 
size and structure, contents and integration worthiness for a 
given candidate ontology. Moreover, these metrics take into 
account both ontology designer and domain expert point of 
view. The metrics have been used as evaluation criteria in a 
widely adopted multi-decisional scoring process belonging 
to the ELECTRE method family. Two well known scientific 
ontological framework have been compared and ranked, 
showing the validity of the proposed methodology. 
 
REFERENCES 
[1] G.T. Gruber, “Towards Principles for the Design of 
Ontologies Used for Knowledge Sharing,” Int. Journal of 
Human-Computer Studies, vol. 43, issue 5-6, pp. 907-928, 
1995. 
[2] S. Lesteven et al., “Ontologies For Astronomy,” Library and 
Information Services in Astronomy V: Common Challenges, 
Uncommon Solutions. (Astronomical Society of the Pacific) 
ASP Conference Series, vol. 377, p. 193-196, 2006. 
[3] OpenClinical 
Ontologies 
homepage. 
Available 
at: 
http://www.openclinical.org/ontologies.html, (last accessed: 
May 2011) 
[4] A. Esposito, L. Tarricone, L. Vallone and M. Zappatore, “A 
Proposal for an Electromagnetic Ontology Framework,” Int. 
Journal of Web and Grid Services, Vol. 4, No. 3, pp. 284-302,  
2008. 
[5] N. Guarino, “Formal ontology and information systems,” 
Proc. of the 1st Int. Conf. on Formal Ontologies in 
Information Systems, FOIS98, IOS Press, pp. 3-15, 1998. 
[6] H. Zhang, Y.-F. Li and H. B .K. Tan, “Measuring Design 
Complexity of Semantic Web Ontologies,” The Journal of 
Systems and Software, Science Direct, vol. 83, pp. 803-814, 
2010. 
[7] Y. Kalfoglou et al.,  "Semantic Metrics,"  Proc. of 5th Int. 
Conf. 
on 
Knowledge 
Engineering 
and 
Knowledge 
Management (EKAW06), pp. 166-181, 2006. 
[8] T. Lethbridge, “Metrics for Concept-Oriented Knowledge 
Bases”, in: International Journal of Software Engineering and 
Knowledge Engineering, vol. 8(2), pp. 161-188, 1998. 
[9] H. Hu and X.-Y. Du, “A Lattice Metric for Evaluating 
Ontology Hierarchies,” Proc. of International Conference on 
Machine Learning and Cibernetics, 2007, vol. 7, pp. 3880-
3883, 2007. 
[10] X. Yunjiao, W. Chun, H. H. Ghenniwa and S. Weiming, “A 
New Tree Similarity measuring method and its application to 
ontology comparison,” Proc. of  CSCWD’08, pp. 258-263, 
2008. 
[11] A. Doan,  J. Madhavan, P. Domingos and A. Halevy, 
“Learning to Map Between Ontologies on the Semantic 
Web,” Proc. of the WWW Conference, Hawaii, USA, pp. 
662-673, ACM Press, 2002. 
[12] D. Aumuller, H. H. Do, S. Massmann and E. Rahm, “Schema 
and ontology matching with COMA++,” Proc. of SIGMOD, 
Software Demonstration, pp. 906-908, ACM Press, 2005. 
[13] E. Sosa, A. Lozano-Tello and A. E. Prieto, “Semantic 
Comparison of Ontologies Based on WordNet,” Proc. of 
Complex Intelligent and Software Intensive Systems 
(CISIS08), pp. 899-904, 2008. 
[14] W3C OWL Working Group, “OWL2 Web Ontology 
Language Document Overview”, W3C Recomm., 27th 
October 2009. Available at: http://www.w3.org/TR/owl2-
overview/ (last accessed: May 2011). 
[15] Ontological 
Codification 
of 
ElectroMagnetism 
v.2.1 
(OntoCEM), University of Salento, Electromagnetic Lab 
Lecce (EML2). http://www.electromagnetics.unisalento.it/ 
/ontologies/OntoCEM/2.1/ (progressively available). 
[16] "Astronomy/Science Ontology", Department of Astronomy, 
University 
of 
Maryland, 
USA. 
Available 
at: 
http://www.astro.umd.edu/~eshaya (last accessed: May 2011). 
[17] Semantic Web for Earth and Environmental Terminology 
(SWEET) Ontologies, NASA JPL, CA, USA Available at:  
http://sweet.jpl.nasa.gov/  (last accessed: May 2011). 
[18] S. Tartir, I. B. Arpinar, M. Moore, A. P. Sheth and B. 
Aleman-Meza, "OntoQA: Metric-Based Ontology Quality 
Analysis," Proc. of IEEE Workshop on Knowledge 
Acquisition from Distributed, Autonomous, Semantically 
Heterogeneous Data and Knowledge Sources (KADASH), 
Houston, Texas, USA, pp. 45-53, 2005. 
[19] J. Figueira, S. Greco and M. Ehrgott (Eds.), Multiple Criteria 
Decision Analysis: The State of the Art Surveys, Springer 
Science and Business Media, Inc., New York, 2005. 
 
 
115
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

