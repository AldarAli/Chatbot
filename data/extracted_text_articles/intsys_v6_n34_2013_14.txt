329
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Automobile Driving Interface Using Gesture Operations for Disabled People 
 
 
Yoshitoshi Murata and Kazuhiro Yoshida 
Faculty of Software and Information Science 
Iwate Prefectural University 
Takizawa, Japan 
y-murata@iwate-pu.ac.jp, kyoshida@ipu-office.iwate-pu.ac.jp 
 
 
Abstract— A steering operation interface has been designed for 
disabled people that uses right and left gesture operations. A 
questionnaire survey on gestures made with appendages had 
shown that gestures other than right and left ones were not 
suitable for driving a car. The interface incorporates both non-
linear and semi-automatic steering control. Experiments using 
gyro sensors and a driving simulator demonstrated that 
driving operation using the foot, forefinger, wrist, or lower 
arm after training was close to conventional steering wheel 
operation. Sufficient practice in using the proposed interface 
should therefore enable users to achieve steering control close 
to that achieved with a steering wheel. 
Keywords-automobile driving interface; disabled people; gyro 
sensor; gesture operation; appendage operation; driving 
simulator 
I. 
 INTRODUCTION 
 Disabled people generally want to stand on their own 
two feet, and achieving mobility is an important step in 
doing this. One way for them to enhance mobility is by 
driving automobiles to which driving-assistance devices 
have been attached. However, there has been a lack of 
development of new automobile driving interfaces that 
would enable disabled people, especially people with arm 
and wrist disabilities, to drive cars. Hence, we are designing 
a new steering operation interface for disabled people that is 
operated by gestures. We developed a prototype control 
device that used a gyro sensor, evaluated it by using a 
driving simulator and a skillful participant, and presented it 
at the Association for Community Health Improvement 
(ACHI 2013) [1]. 
The first auxiliary device for people with arm and wrist 
disabilities, the original of Honda’s Franz system [2], was 
developed in the 1960s. A car is operated with only the feet 
in this system. Since the steering wheel is turned by pumping 
the pedals, its operation is not intuitive. 
The autonomous car and the brain controlled car are ideal 
solutions for disabled people. Autonomous cars have been 
developed by many automobile manufacturers in addition to 
those by Google [3][4]. They need a very detailed 3D-map 
and many sensors to detect pedestrians, other cars, and 
obstacles around them. Therefore, their manufacturing costs 
must be expensive. Brain controlled cars have also been 
developed by researchers including those by automobile 
manufacturers [4][5]. A skillful driver for the brain control 
interface can indicate several kinds of commands. The 
control is not accurate for letting the brain controlled cars 
operate within open traffic. Autonomous car technologies are 
needed for brain controlled cars to drive on usual roads. That 
is to say, brain controlled cars also need detailed 3D-maps 
and many sensors, and they are expensive. A current realistic 
solution for disabled people is to control steering with bodily 
appendages they can move. 
The steering wheel in the system developed by Wada and 
Kameda was controlled with a joystick, and the brake and 
accelerator were controlled with another joystick [6][7]. This 
system has aided many disabled people, but strength is 
needed to operate the joysticks. Moreover, the levers onto 
which the joysticks were fixed had to be customized for the 
hand positions of individual users.  
In any case, mechanical devices such as these lack 
flexibility and have to be customized for users. Hence, they 
are inherently expensive.  
The on-going shift from hydraulic to electronic driving 
interface systems (e.g., steering and braking) means that 
systems combining computer chips with sensors can now be 
used to easily control these driving interfaces. Candidate 
sensors include Kinect sensors and gyro sensors. 
In this paper, we verified the results we presented in 
ACHI 2013 by checking them in experiments, and 
investigated what movements by appendages drivers found 
to be natural by administering questionnaires. 
 
(1) Steering pedal
(2) Steering box
(3) Brake lock button
(4) Selection bar for feet
(5) Side brake for knee
(6) Sub-brake for exercise
Wiper lever for left knee
Winker lever for  right knee
Combination switch es
 
Figure 1. Honda’s Franz system 
 

330
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
After related work is discussed in Section II, we will 
describe the driving simulator we developed to evaluate our 
proposed driving interface in Section III. Gestures, i.e., 
movements by appendages assigned to various functions are 
explained in Section IV and the driving interface equipment 
we developed is presented in Section V. The experimental 
evaluation we conducted is described in Section VI. The key 
points are summarized and future work is mentioned in 
Section VII. 
II. 
RELATED WORK 
Since the purpose of this study is to design a steering 
operation interface for disabled people that is operated by 
gestures, we introduce an advanced driving interface for 
people who have difficulty moving their arms and/or hands. 
We also introduce sensors that support driving a car by 
gesturing. 
A. Driving Interface for Disabled people 
The Franz system used by Honda is aimed at people who 
have difficulty moving their arms and hands. The user 
operates a car with only his or her feet [2]. It was originally 
implemented in a Honda Civic in 1982, which was the first 
vehicle to introduce the Franz system in Japan. It has now 
been implemented in a Honda Fit. 
The steering wheel is turned right or left by pumping a 
steering pedal (see Fig. 1). The transmission is shifted into 
drive by lifting the selection bar, into reverse by pushing it 
down, and into park by pushing it further down. The turn 
signals and windshield wipers are operated by turning levers 
with the right and left knees. Power windows and lights are 
controlled by flipping switches up or down with the right 
foot or knee. 
Wada and Kameda developed a car driving interface for 
people who do not have enough strength to control a steering 
wheel, accelerator pedal, or brake pedal. They used joysticks 
instead of a steering wheel and pedals. Steering, braking, and 
acceleration in the initial version [5] were controlled with 
one joystick. Two joysticks are used in the latest version 
shown in Fig. 2 [6]. The joystick on the right controls the 
steering and that on the left controls acceleration and braking. 
The relationship between the angle of the steering wheel and 
the angle of the joystick is a polyline, as seen in Fig. 3. This 
means that a driver can sensitively control the steering wheel 
around a neutral position and can turn the wheel quickly 
when making a wide turn. People who can freely move their 
hands can drive automobiles with this device. 
However, such mechanical devices must be customized 
to fit individual users’ disabilities and physical form. 
B. Sensors for gesturing 
Several driving interfaces using Kinect sensors have been 
developed. A user can drive a virtual car in a simulated 
world with the “Air Driving” interface developed by Forum8 
by moving his or her hands and feet in front of a sensor [8]. 
Since there must be at least 50 cm between the sensor and 
the appendage that is gesturing, it cannot be used in actual 
cars. Rahman et al. developed an interface for car audio 
operation that used a Kinect sensor [9]. Although this 
interface has been demonstrated in an actual car, its use as a 
driving interface (e.g., steering and braking) has not been 
investigated.  
Döring et al. developed a multi-touch steering wheel that 
could not only control steering but also the car audio [10]. 
However, users with arm disabilities had trouble operating it. 
Other examples of using acceleration sensors and/or gyro 
sensors as gesture operation interfaces include those in video 
games and home appliance remote controls [11]. 
Unfortunately, there were not existing sensors for 
gesturing to control a steering wheel, accelerator pedal, and a 
brake pedal in an actual car. 
 
 
 
Figure 2. Wada and Kameda’s joystick driving interface 
 
 
50
100
- 50
-100
50
100
-50
-100
Angle of joystick (%)
Angle of steering
wheel (%)
 
 
Figure 3. Relationship between angle of joystick and angle of steering 
wheel 
 
III. 
DRIVING SIMULATOR 
Before evaluating the proposed driving interface in an 
actual car, we evaluated it in a driving simulator to avoid 
traffic accidents. We introduce our developed driving 
simulator in this section. 

331
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
A. Driving course 
As one of our ultimate aims is to help disabled people 
obtaining a driver’s license, we design a driving simulator to 
not only measure driving operability, but also exercise when 
driving. The three main issues with the driving simulator are: 
(1) The feel of driving has to be similar to that of a real car. 
(2) It has to be possible to measure the position of the car 
within driving lanes. 
(3) It has to be easy to choose various driving courses from 
real roads. 
 
We extract road data from maps such as Google Maps. 
The creation tools prepare 3D roads from extracted data, as 
shown in Fig. 4 [12]. We use OpenGL [13] as the 3D 
program interface and develop a program using the “glut”, 
“sdl” [14], “glew” [15], and “OpenAL” tools [16].  
First, the simulation program has to find a direction 
perpendicular to the parametric curve that expresses the 
center line of the road to create the width of an 
approximated road, and it then calculates the coordinates of 
a point shifted to the right or left of the center line, as shown 
in Fig. 5. 
A tangential angle of an arbitrary point on the curve can 
be calculated as 
dx
Tan 1 dy

 
. 
(1) 
 
The point of the road edge is a position that shifts to the 
road width from an arbitrary point on the curve. The point 
of the road edge can be calculated as 
( )
2)
cos(
( )
x t
W
t
x
r
r





・
 
( )
2)
sin(
( )
y t
W
t
y
r
r





・
 
( )
2)
cos(
( )
x t
W
t
x
l
l





・
 
( )
2)
sin(
( )
y t
W
t
y
l
l





・
. 
(2) 
 
 
 
 
Figure 4. Outline for creating driving simulator road 
 
 
Figure 5. Method of creating 3D roads 
 
3D road polygons are created by changing three-
dimensional spline curve parameter “t” from zero to one, 
calculating many points on the road edge, and storing these 
points in a vertex array. Road center lines and lane lines are 
created by changing value W in Eq. (2). 
When the width or the number of lanes at a curve’s 
parameter, t = 0, differs from the width or number of lanes 
at t = 1, the simulation program finds that the road has a 
right- or left-turn-only lane. When a road has a right- or left-
turn-only lane, the road width has to be gradually increased. 
The simulation program in our system calculates a smooth 
curve that expresses increments in the width of the lane. We 
used the sigmoid function to increase the width. The 
sigmoid function is a monotonic increase function and has 
one inflection point. Therefore, it is suitable for expressing a 
right- or left-turn-only lane.  
The polygon for a crossing consists of all curve 
functions that connect the crossing. The calculated curve 
function’s parameter “t” changes from zero to one in the 
same way as for a road, and a crossing polygon is created. 
Fig. 6 has examples of a 3D road environment created 
by the simulation program according to this method.  
 
 
 
(a) Example of straight road 
 
 
(b) Example of crossing 
 
Figure 6.  Examples of created 3D roads 
 
 

332
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
B. Motions of car 
Two motions are simulated: gyration and acceleration 
[17][18]. 
 
1) Gyration 
Steady gyrating motion is applied to the car under three 
main assumptions. 
- The movement of the car is broadside motion of a 
rigid body. That is, the car is rigid and free of 
distortion. 
- The speed is constant throughout each curve. 
- The characteristics of the tires on the right are the 
same as those on the left. 
The radius, R, of gyrating movement is given by the 
following equation, in which V is the running speed and  is 
the steering angle. 

) 1
1(
CV 2
R


. 
(3) 
The C is given by the following equation, in which the mass 
of the car is m, the cornering force on the front tires is Kf, 
that on the rear tires is Kr, the wheel base is l, and the 
distances between the car’s center of gravity and the front 
and rear axles are lf and lr. 
r
f
r
r
f
f
K
K
l K
K
l
l
m
C

 
2
2
. 
(4) 
 
Each parameter is set to produce driving characteristics 
similar to those of an actual car. The cornering force is 
controlled by adjusting the radius of the gyrating movement, 
i.e., the larger the radius, the stronger the cornering force. 
 
2) 
Acceleration 
The acceleration, Ac, of an actual car depends on the 
engine torque, the transmission gear ratio, the tire radius, the 
vehicle weight, and the engine speed. The engine speed 
depends on the degree to which the accelerator pedal is 
pressed. 
Air resistance Ra and rolling resistance Rr are considered 
to be the total running resistance. 
2
2
1
SV
C
R
d
a


, 
(5) 
 
where Cd is the aerodynamic coefficient, is the fluid 
density of air, and S is the total surface area of the car.  
 
C mg
R
r  rr
, 
(6) 
 
where m is the mass of the car, Crr is the rolling coefficient, 
and g is the gravitational acceleration. The resulting 
acceleration, A, is given by 
 
)
(
r
a
c
R
R
A
A



. 
(7) 
 
C. Simulation display 
There is an example view seen through the windshield in 
Fig. 7. The upper right shows the position of the car on the 
course. The operation monitoring tool we developed to 
facilitate operation is shown in Fig. 8. It helps the driver 
recognize the angle of the sensor from the angle of the 
steering wheel and the angle of the toes in case of rolling the 
ankle. It also displays the degree to which the accelerator or 
brake pedal has been pushed.   
 
 
D. Measured data 
Nine data items are measured. 
1) Steering angle 
2) Running speed 
3) Distance driven and driving time 
4) Position of car on course 
5) Distance between left of car and left lane marker line 
6) Distance between right of car and right lane marker 
line 
7) Degree to which accelerator pedal was pushed 
8) Depth to which brake pedal was pushed 
9) Angle of car relative to driving direction  
 
IV. 
GESTURES (MOVEMENTS BY APPENDAGES) FOR 
OPERATION 
Here we describe the requirements for steering operation 
and control schemes that satisfy them. We then describe 
gestures for each body part on which a sensor is attached. 
(Operation monitor)
(Steering wheel)
(Sensor output)
(Brake/Acceration)
 
 
Figure 8. Operation monitoring tool 
 
 
Figure 7. Example view through front window 

333
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
A. Operating functions 
It is necessary to have door open/close, window 
open/close, wiper on/off, and turn signal on/off functions to 
drive an automobile in addition to the basic operations of 
steering, braking, and accelerating. Moreover, since 
automobiles typically have an audio system, a navigation 
system, and a climate control system, a driver should be able 
to operate these systems as well. Other than for the basic 
operating functions, a fine degree of control is not needed for 
the operating functions—they can generally be controlled by 
flipping a switch, as in Honda’s Franz system. Moreover, 
voice-command control systems like that used by Samsung’s 
Smart TV [19] could also be used. Of the basic operations 
requiring a fine degree of real-time control (steering, braking, 
and accelerating), we focus on steering, which requires the 
finest degree of control. The results from our research should 
easily be able to be transferred to braking and accelerating. 
B. Steering operation requirements 
Steering an automobile by moving bodily appendages 
should produce the same results as manually turning the 
wheel. Given this basic requirement, we derived four specific 
requirements. 
1) The automobile should be able to be steered within ± 
about 500 degrees from the neutral position. 
- There should be a fine degree of steering control 
around the neutral position. 
- Steering should be quick when making a wide turn. 
2) The driver should be able to keep the vehicle within 
the lane on both straightaways and curves of various 
radii at a normal driving speed. 
3) The driver should be able to drive stably, and not 
zigzag, on straightaways.  
4) The driver should be able to traverse a curve while 
keeping the steering wheel at a position fixed 
immediately before entering the curve and then exit 
the curve into a straightaway by gradually returning 
the steering wheel to the neutral position. 
C. Steering control 
The steering wheel in an actual automobile can be turned 
about three complete revolutions from wheel lock to wheel 
lock (~1080°). In contrast, the movable angle of a joint angle 
is about 20–90°, which is much less than that of a steering 
wheel. Hence, it is impossible to control steering with a joint 
angle because it is not the same as that of a steering wheel. 
We thus introduce the non-linear steering control and 
the semi-automatic steering control. The direct operation 
angle and automatic steering angle are determined, as 
outlined in Fig. 9, which illustrates steering control with a 
foot and an ankle. The driver operates using the non-linear 
steering control within the direct operation angle. Although 
Wada and Kameda used a polyline function for their steering 
control with a joystick, we used a non-linear function (y = 
xn). We set n = 3 on the basis of our experimental results, 
which are described in Section VI. The steering angle 
increases automatically when it is beyond the direct 
operation angle. The rate of increase depends on the speed of 
the car; the faster the car moves, the lower the rate. The 
driver can stop further increases in the steering angle by 
lifting his or her toes (about 20° for the case in Fig. 9). The 
driver can return the steering angle to the neutral position by 
lowering his or her toes. Drift error is canceled by carrying 
out this operation while the car is running straight.  
 
D. Sensor attachment and actions 
We measure the car control characteristics for several 
actions: rolling the ankle, moving the forefinger, moving the 
wrist, rolling the lower arm, moving the lower arm backward 
and forward, and moving the upper arm backward and 
forward. The motions of appendages to turn a car to the right 
or left may differ for individuals. For example, someone may 
move his or her finger down to turn a car to the right, while 
another may move his or her finger up to turn to the right. 
Hence, we obtained information about different motions by 
individuals 
by 
administering 
questionnaires 
before 
measuring the car control characteristics. There were 29 
participants. The results we obtained from the questionnaires 
are summarized in Table I. Most people chose the same 
action for motions that led to the right or left, such as rolling 
the lower arm. However, the number of people who chose 
alternative motions was roughly the same for motions that 
did not lead to the right or left such as moving his or her 
fingers up or down. For example, 86% of people chose 
rolling their right lower arm to the right to turn a car to the 
right. However, 52% of participants chose “up” and 48% of 
them chose “down” for moving their left finger up or down. 
We predicted that there would be opposite relations 
before the questionnaires were administered between moving 
the right lower arm forward or backward and moving the left 
lower arm backward or forward, and moving the right upper 
arm forward or backward and moving the left upper arm 
backward or forward. Nevertheless, there were not extensive 
opposite relations, but slightly opposite relation in the results 
obtained from the questionnaires. 
The positions of the sensors and the motions of 
appendages are as follows. 
 
[Rolling ankle] 
We considered using knee turning and knee movements 
to move gyro sensors. However, as these movements 
produce a narrow angle of movement, we roll the ankles. 
The sensor is placed on top of the foot, as shown in Fig. 9. 
The sensor moves when a foot are pivoted right or left on the 
heel. 
 
Direct operation
angle
Automatic
steering range
Automatic
steering angle
Sensor
20°
 
Figure 9. Example of controlling steering by foot 

334
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
TABLE I.  
RESULTS FROM QUESTIONNAIRES FOR MOTION OF TURNING 
CAR TO RIGHT 
Left hand 
Turn to right 
Right hand 
Turn to right 
Finger 
Up 
15 
Finger 
Up 
18 
Down 
14 
Down 
11 
Finger 
Right 
26 
Finger 
Forward 
(Right) 
27 
Forward 
(Left) 
3 
Left 
2 
Wrist 
Up 
16 
Wrist 
Up 
16 
Down 
13 
Down 
13 
Wrist 
Right 
24 
Wrist 
Right 
27 
Left 
5 
Left 
2 
Lower 
arm 
Forward 
11 
Lower 
arm 
Forward 
21 
Backward 
18 
Backward 
8 
Lower 
arm 
Right 
25 
Lower 
arm 
Right 
28 
Left 
4 
Left 
1 
Upper 
arm 
Forward 
17 
Upper 
arm 
Forward 
14 
Backward 
12 
Backward 
15 
 
 
[Moving forefinger] 
There are two movements for a forefinger. The first is 
when the back of the hand is raised upward, the forefinger 
can be moved up and down, the second is when the back of 
the right hand is toward the right; the right forefinger can 
move right or left. About half the participants for the former 
motion chose the up direction to turn a car to the right, and 
the rest chose the down direction, as summarized in Table I. 
This means that about half of all people may make 
operational mistakes in the first. However, about 90% of 
people chose the same operation to turn a car to the right in 
the second. This means that most people will not make 
operational mistakes. Therefore, we choose the latter motion 
to drive a car with the forefinger. A sensor is placed on the 
second joint of the forefinger and is moved as shown in Fig. 
10. 
 
 
Figure 10. Moving forefinger (top view) 
 
[Moving wrist] 
There are two motions for the wrist, which are the same 
as those for the forefinger. We choose a motion when the 
back of the hand moves forward to the right and the hand 
moves right or left for the same reason as that for the 
forefinger. 
The sensor is placed on the back of the hand and is 
moved as shown in Fig. 11. 
 
 
Figure 11. Moving wrist (top view) 
 
 
[Moving lower arm] 
We considered two motions for the lower arm. The first 
was moving the lower arm forward or backward, and the 
second was rolling the lower arm right or left. Most people 
will not make operational mistakes in rolling the lower arm 
right or left (the latter case) from the results in the 
questionnaires. In contrast, ~30% of people may make 
operational errors in the former case. However, since the 
ratio is less than that for the forefinger and wrist cases, we 
measure both their control characteristics. 
The sensor is placed on the lower arm and is rolled as 
shown in Fig. 12. 
 
Sensor
Moving forth 
and back
Rolling right and left
 
 
Figure 12. Rolling and moving lower arm (top view) 
 
 
 
 
 

335
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[Moving upper arm backward and forward] 
There is not big difference between the number of 
participants who chose to move their right lower arm 
forward to turn a car to the right and the number who chose 
to move it backward. Therefore, this gesture is not basically 
suitable for the driving interface. Nevertheless, we measure it 
this time. 
The sensor is placed above the elbow and is swung as shown 
in Fig. 13. 
 
 
Figure 13. Moving upper arm (side view) 
V. 
DRIVING INTERFACE EQUIPMENT 
In this section, we describe various types of sensors, the 
type we used and its preprocessing, and the system 
configuration for the driving interface and its connection to 
a driving simulator. 
A. Candidate sensors or devices 
We considered five types of sensors or devices to control 
steering. 
- 
Kinect sensors 
- 
Video cameras 
- 
Rotary encoders 
- 
Gyro sensors 
- 
Strain gauges 
It is problematic to use Kinect sensors or video cameras 
because the units have to be attached to cars, and the 
locations for possible attachment are limited. Moreover, 
there must be at least 50 cm between a Kinect sensor and the 
gesturing appendage, which greatly limits the possible 
locations for attachment, as was previously mentioned. 
Rotary encoders require the use of a mechanical adapter 
to measure the joint angle of fingers, elbows, or ankles. 
Since gyro sensors are not only affected by the joint 
angle but also vehicle motion, they must be attached to 
vehicles to eliminate this effect. Moreover, gyro sensors have 
drift error that increases cumulatively and it is very difficult 
to completely remove this cumulative error. However, gyro 
sensors can very flexibly be attached to bodily appendages. 
Strain gauges do not have drift error and are not affected 
by vehicle motion. Therefore, they are better suited to 
measuring joint angles than gyro sensors, when it is possible 
to attach them to joints. We plan to investigate their 
usefulness in future work. 
B. Used sensor and its preprosessing 
We used gyro sensors to evaluate gesture operations as 
the initial stage of our research regardless of various 
problems such as the influence of movements of a car to 
apply them to a real car. The main reasons for this were that 
gyro sensors are very flexible and can be attached to bodily 
appendages and moving joints, and the simulated car did not 
physically move. We used a practical 3-axis accelerometer 
system (ATR Promotions, WAA-010 [20]) as the sensor 
terminal. Not only a gyro sensor but also an accelerometer 
sensor, a terrestrial magnetic sensor, and a Bluetooth unit 
are mounted on it. 
The drift phenomenon in gyro sensors is a problem for 
driving simulators. Angular velocity under static conditions 
is not zero but some other value. Example data of angular 
velocity and its integrated data (angle) on the WAA-006 are 
presented in Fig. 14. The value for angular velocity is small 
and varies around zero. However, since its characteristics of 
distribution are not normal, the value for the angle remains 
plus or minus for a long period. A moving average filter and 
1st function adaptation are applied to reduce the drift 
phenomenon. The slope and the intercept of the 1st adapting 
function are derived from various moving averaged angular 
velocity data, e.g., 200 samples, under static conditions. 
They are automatically renewed to the latest data. Decisions 
under static conditions are determined from moving 
averaged angular velocity data that are within some 
threshold level. We could choose the average of the 10 
largest angular velocity data under static conditions in this 
paper. The final output data of angular velocity are offset by 
the adapted 1st function. There is an example of 
compensated data under static conditions in Fig. 15. They 
remained zero under static conditions. When a gyro sensor 
begins to move, angular velocity data are offset by the latest 
adapted 1st function. Angular velocity data and their 
integrated data that are angle data are provided in Fig. 16 
when a gyro sensor is being moved by foot.  
 
Angle
Angle velocity
 
 
Figure 14. Uncompensated data for WAA-010 under static conditions 

336
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Angle
Angle velocity
 
 
Figure 15. Compensated data of WAA-010 in static condition 
 
 
Angle
Angle velocity
 
 
Figure 16. Angle velocity and angle data while moving WAA-010 
 
C. Sytem configuration 
We designed the driving interface we propose that will 
not only be used for operating a simulated car but also a real 
car. Therefore, the driving interface unit must be connected 
to a driving simulator and a real car. We designed our 
driving interface unit to comprise a wireless gyro sensor 
terminal and a PC. We developed an angle data convertor 
and a driving simulator and mounted them on a PC. Since 
the driving interface unit should be tested with an immersive 
driving simulator before it is applied to a real car, we also 
designed it to be connected to an immersive driving 
simulator. Therefore, the data convertor was comprised of a 
serial communication library, a sensor control library, an 
angle conversion library, and an immersive driving 
simulator communication library. The relationship between 
libraries had the layered structure shown in Fig. 17. The 
serial communication library provided communication 
functions for the Bluetooth unit. The sensor control library 
sent commands to control the sensor terminal WAA-010 
such as the sampling rate. The angle conversion library 
transformed data received from the sensor terminal to a data 
format to enable steering control. This library contained 
integration that converted the angular velocity to an angle 
and the drift compensation function described in the 
previous paragraph. Since the immersive driving simulator 
at our university did not have a movable pedestal, this unit 
did not have a gyro sensor that cancelled the movements of 
the car. There is an example dialog box for setting the 
parameters in Fig. 18. It is possible to monitor output data 
and to set up connection parameters and compensation 
parameters for drift errors. The practical parameters are as 
follows; 
Connection: 
- Serial port number (COM10) 
- Sampling period (5 ms) 
- Average number of sampled data (5) 
Drift error compensation: 
- Number of data obtained for initial data (200). 
- Windows size for moving average (5). 
- Number of array lists for storing larger values (10). 
 
Serial communication library
Sensor control library
Sensor data/steering angle conversion library
Driving simulator in PC
Comm. library for IDS
Immersive driving simulator
(IDS)
Gyro
sensor
 
 
Figure 17. Configuration of the driving interface equipment 
 
 
 
Figure 18. Dialog box for setting parameters 

337
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The values within parentheses are examples of each 
parameter. The offset values X and Z and the maximum 
angular velocities X and Z under static conditions were 
calculated from the above data. These data are presented on 
the right of the dialog box.  
VI. 
EVALUATION 
We evaluated the ability of a driver to keep within the 
lane and to drive stably without zigzagging on straightaways 
while using the proposed driving interface. Since potential 
users likely have difficulty moving their arms and hands, we 
first measured fundamental data for the foot. We then 
measured data for other parts of the body. 
A. Evaluation issues 
We calculated the ratio of lane departure (RLD) and the 
standard deviation of the driving gap (SDDG) to analyze 
performance against the 2nd and 3rd steering operation 
requirements described in Section IV-B; 
- 
As can be seen from Fig. 19(a), lane departure means 
that one or more of the tires run on or across a lane 
marker line. RLD is the ratio between the distance 
driven and the distance during, which the car left the 
lane. 
- 
As we can see from Fig. 19(b), the driving gap is the 
distance between the lane center and the car’s center 
line. A value of zero means that the car is centered in 
the lane. SDDG is calculated using the values 
obtained for the car running on a straight portion of 
the course. 
 
Figure 19. Lane departure and driving gap 
 
B. Test course 
As one of our ultimate aims is to help disabled people 
obtaining a driver’s license, we use a driving route based on 
a typical course at a driving school (Fig. 20) to measures 
RLD and SDDG. It is comprised of a rectangular outer 
course, two crank-shaped courses, two S-shaped courses, and 
two parallel parking courses. The outer course is 300 × 120 
m and had a corner radius of 20 m. A 3.3-m-wide driving 
lane runs in each of the courses. 
 
Figure 20. Driving course for evaluations 
 
C. Results for operation by foot 
Since the first objective of this research is to develop a 
driving interface for people with disabled arms and fingers, 
we focus on foot-controlled steering, as illustrated in Fig. 9. 
A non-linear function (y = xn) is used to control steering 
within the direct operation angle. We measured the position 
of a car on the course and calculated the RLD and SDDG for 
n=1 – 4 in y = xn. We also measured and calculated the same 
data using a steering-wheel-type game controller for 
comparison. The measured and calculated data used for the 
non-linear function are listed in Table II for one of the four 
participants, who was person Y who had a great deal of 
experience driving a car using his foot with the proposed 
driving interface. These data were measured and calculated 
in September 2012. Since the details of the experiment by 
Wada and Kameda have not been published, we could not 
compare the precision of our control function with theirs. 
 
TABLE II.  
MEASURED AND CALCULATED DATA FOR NON-LINEAR 
CONTROL FUNCTION FOR SKILLFUL PARTICIPANT 
 
y=x 
y=x2 
y=x3 
y=x4 
y=x 
Game str. 
wheel 
Operating 
body part 
Left feet 
DOA* 
±20° 
±15° 
 
SWA** 
±180° 
±30° 
 
Distance 
driven (km) 
 
7.91 
 
7.91 
 
7.91 
 
7.91 
2.39 
2.37 
Ave.  speed 
(km/h) 
26.6 
26.3 
25.5 
27.3 
14.3 
30.4 
RLD (%) 
0.15 
0.38 
0.24 
0.91 
9.8 
0 
SDDG (m) 
0.21 
0.24 
0.27 
0.29 
0.15 
0.11 
 
*DOA: Direct operation angle 
**SWA: Corresponding steering wheel angle 
(Measured and calculated in Sep. 2012) 
 
We initially thought that a driver could easily operate the 
car by using the semi-automatic steering control. However, 
the RLD and SDDG were much worse than those with the 
game controller when the direct operation angle (DOA) was 
±15° and the corresponding steering wheel angle (SWA) was 
±30°. We observed that it was very difficult to drive the car 
using the semi-automatic steering control during typical 
driving maneuvers. Hence, we changed DOA to ±20° and the 
Departure
No departure
Lane line
Lane line
Car is on the lane line
or over the lane line
+
－
0
Center of lane
Driving gap
 
(a) Lane departure                                   (b) Driving gap 

338
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
corresponding SWA was ±180°. It is possible to drive a car 
through most of the corners in normal driving within these 
parameters. Although neither of the two participants in this 
experiment negotiated the corners of the rectangular outer 
course smoothly at DOA= ±15° and SWA= ±30°, as seen in 
Fig. 21, both of them could negotiate the same corners at 
DOA= ±20° and SWA= ±180°. We concluded that 
controlling the car with the semi-automatic steering control 
was not suitable for normal driving except for parking and 
traversing the crank- and S-shaped courses. Detailed data 
traversing the crank- and S-shaped course will be given later. 
 
 
y = x1
(DOA=±15°, SWA±30°)
y = x3
(DOA=±20°, SWA±180°)
Participant
A
Participant
B
 
Figure 21. Cornering for participants A and B 
(Measured in Sep. 2012) 
 
 
(a) RLD 
 
 
(b) SDDG 
 
Figure 22. Car control characteristics against the number of laps 
 (Measured in Oct. 2012), * Average speed: 26.4 km 
 
(a) y=x 
 
 
(b) y=x3 
 
Figure 23.  RLD against the number of laps (Measured in Jul. 2013) 
* Average speed for each participant: written within parentheses 
 
 
We considered which non-linear function was best to 
control the car. RLD and SDDG are the smallest for n = 1, as 
listed in Table II. However, the difference in values between 
n = 1 and n = 3 is negligible. Since the driving interface 
needs to enable a car to be driven for a long time, we 
measured 10 laps of the outer course for each function. The 
data are plotted in Fig. 22. There is not a big difference for 
the number of laps and the non-linear function in SDDG, but 
RLD is the smallest for n=3 during the last three laps. Since 
these data were measured and calculated for participant Y in 
Oct. 2012, we measured and calculated RLD and SDDG for 
four other participants in addition to participant Y at y = x 
(DOA=±20°, SWA±180°) and y = x3 (DOA=±20°, 
SWA±180°) in July 2013. The measured and calculated data 
for RLD and SDDG in each lap are plotted in Figs. 23 and 
24. The data including those on participant Y measured and 
calculated in July 2013 are rather worse than those measured 
in Oct. 2012. Participants B and T, especially, could not 
drive the car well. RLD and SDDG become better in later 
laps at y=x3, and become worse in later laps at y=x. B and 
T’s data clearly reveal this tendency, and their values come 
close to the values of the other three participants. Although 
data for the other three participants have the same tendency, 
the changes in them are small. This tendency is the same as 
the data for participant Y measured and calculated in Oct. 
2012. Participant Y’s data in Oct. 2012 are outstanding. RLD 
during the last three laps is zero percent. Yet his data in Jul. 

339
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
2013 are worse than his data measured and calculated 10 
months earlier. Their values are roughly the same as those 
for participants M and D.  
Although the quantity of data is insufficient, these issues 
suggest that most drivers can drive cars well with their feet, 
but they have to continue to train (i.e., drive) to retain high 
levels of skill. The non-linear function of y=x3 may be better 
than y=x. 
We calculated the RLD for the crank- and S-shaped 
course for four participants as well in Oct. 2012. The 
measured and calculated data are listed in Table III. The 
values are their averages. Traversing the crank- and S-shaped 
course is more difficult than traversing the rectangular course. 
The driver had to use both the non-linear and the semi-
automatic steering control. Driving precision for these two 
courses differed greatly. As shown in Figs. 25 and 26, the 
precision of participant S is very close to that with the game 
steering wheel while that of participant C substantially 
diverged from it. This indicates that performance with the 
steering operation interface we propose should approach that 
with a steering wheel as the amount of practice and 
experience increases. 
 
 
(a) y=x 
 
 
 
(b) y=x3 
 
 
Figure 24. SDDG  against the number of laps (Measured in Jul. 2013) 
* Average speed for each participant: written within parentheses 
 
TABLE III.  
MEASURED AND CALCULATED DATA FOR CRANK- AND S-
SHAPED COURSES 
 
Crank-shaped course 
S-shaped course 
Operation device 
Game 
wheel 
Sensor 
Game 
wheel 
Sensor 
DOA 
±20° 
SWA 
±180° 
Cont. function 
y = x3 and semi-automatic steering control 
Distance driven (m) 
239.7 
234.6 
370.8 
377.4 
Ave. speed 
(km/h) 
9.7 
8.3 
15.0 
12.9 
RLD-Ave. (%) 
17.2 
22.9 
8.9 
16.8 
RLD-Max. (%) 
26.6 
42.8 
21.2 
40.8 
RLD-Min. (%) 
6.6 
8.5 
0 
1.2 
(Measured in Oct. 2012) 
 
-55
-45
-35
-25
-55
-45
-35
-25
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
-55
-45
-35
-25
-55
-45
-35
-25
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
Participant C
Participant S
 
 
Figure 25. Crank-shaped course performance for participants C and D  
(Measured in Oct. 2012) 
 
-40
-30
-20
-10
25
35
45
55
65
75
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
Participant C
Participant S
-40
-30
-20
-10
25
35
45
55
65
75
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
 
Figure 26. Precision on S-shaped course for participants C and D 
(Measured in Oct. 2012) 
D. Results from other appendages 
We measured and calculated the RLD and SDDG for 
steering control using the forefinger, wrist, lower arm, and 
upper arm in addition to the foot to examine to what extent 
the proposed driving interface could be applied to various 
types of disabilities. The data are presented in Fig. 27. There 
are two kinds of bars in each graph. One was measured for 
participant Y in Oct. 2012, and the other was measured for 
four participants that did not include Y in Aug. 2013. Each 
data was an average of driving three laps of the outer course. 
The movements are illustrated in Figs. 15–18. They drove 
three laps of the outer curse. 

340
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Y’s data for each appendage in Oct. 2012 are better than 
the data in Aug. 2013, especially Y’s RLD for the foot in 
Oct. 2012 is very small. The reason why Y’s feet data are 
very good is that Y trained for long periods and had a great 
deal of skill in controlling the car with his feet. His lengthy 
training and exceptional skills must have affected driving 
with his other appendages because their data were rather 
good. 
There are large differences between appendages in Aug. 
2013. Since this was the first time for participants who took 
part in the experiment to drive a simulated car with their 
appendages, ease of driving with each appendage for each 
participant clearly became apparent.  
 
 
(a) RLD for several body parts 
 
 
(b) SDDG for several appendages 
 
Figure 27. Car control characteristics for several appendages 
  * Moving lower arm backward and forward 
  ** Rolling lower arm right or left 
  *** Average speed: 24.8 – 33km 
 
The data for the upper arm is the worst because in both 
experiences it must have been difficult to precisely move the 
upper arm (and shoulder). 
In any case, measured and calculated data except for the 
data for Y’s feet in Oct. 2012 given in Fig. 27 are not 
sufficient to drive a car. At least, driving characteristics 
RLD and SDDG with each appendage must be closer to that 
with the game wheel. The data for participant Y measured in 
Oct. 2012 shows that more practice should enable users to 
achieve steering control closer to that with a steering wheel. 
Therefore, we measured driving characteristics RLD and 
SDDG against the training period. Moving forward or 
backward with the upper arm and the lower arm are not 
suitable for driving a car from Table I. RLD and SDDG for 
both of them are not good enough in Fig. 27. We chose 
turning right or left with the forefinger and wrist, and rolling 
right or left with the lower arm. There was one participant 
for each gesture. The data are provided in Fig. 28. We 
measured the data after 30 minutes practice each day. Each 
data was an average of driving three laps of the outer course. 
The car control characteristics data improved in initial three 
day (90 minutes). Especially, the participant for rolling the 
lower arm improved in driving a car dramatically. RLD and 
SDDG became less than 3% and 0.3m after 5 days practice. 
But, SDDGs of the participant for the forefinger and the 
wrist on 2 September became worse than those on 31 
August. The reason is that 31 August and 1 September were 
weekends, and the patients could not practice for two days. 
Most people should be able to drive a car well by a few 
hours of practice regardless of irrespective of their body 
characteristics. But, they have to continue to train to retain 
high level of skills. 
 
 
(a) RLD 
 
 
(b) SDDG 
Figure 28. Car control characteristics against the number of days for 
practice (Measured in Aug. and Sep. 2013)  
* Average speed for each participant: written within parentheses 
 
VII. CONCLUSION 
The steering operation interface we proposed for disabled 
people uses gesture operation. Questionnaires on gestures 
made with appendages indicated that gestures not leading to 
the right or left were not suitable for driving a car. The 
interface incorporated both non-linear and semi-automatic 
steering control. Simulated experiments using foot control 
and gyro sensors indicated that semi-automatic steering 
control was only suitable for parking and traversing crank- or 
s-shaped courses, and that non-linear  steering control (y=x3) 

341
International Journal on Advances in Intelligent Systems, vol 6 no 3 & 4, year 2013, http://www.iariajournals.org/intelligent_systems/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
was better than linear steering control (y=x) for typical 
driving maneuvers. Data on worse drivers (participants in the 
experiment) revealed that they could not remain stable in 
later laps at y=x, but they improved in later laps at y=x3. 
Driving operations by training the forefinger, wrist, and 
lower arm (rolling) were close to that achieved with a 
steering wheel. More practice in using the new interface 
should enable user to achieve steering control that is closer to 
that with a steering wheel. 
We plan to develop a prototype of a control device using 
strain gauges instead of gyro sensors to avoid influencing car 
movements and to evaluate driving operations with it. We 
also plan to evaluate our proposed interface in an actual car. 
ACKNOWLEDGMENT 
This research has been conducted as part of the Iwate 
Strategic Research Foundation. We would like to express our 
appreciation to students in Murata-Lab, Iwate Prefectural 
University for taking data with our experiment. 
 
REFERENCES 
[1] Yoshitoshi Murata, Kazuhiro Yoshida, Kazuhiro Suzuki, and Daisuke 
Takahashi, “Proposal of an Automobile Driving Interface Using 
Gesture Operation for Disabled People,” IARIA ACHI 2013, March 
2013. 
[2] Development of Honda's Franz System Car; 
http://world.honda.com/history/challenge/1982franzsystemcar/index.ht
ml, December 2013. 
[3] Erico Guizzo, “How Google's Self-Driving Car Works,” IEEE 
Spectrum, February 26, 2013. 
[4]  Autonomos Labs, http://www.autonomos.inf.fu-berlin.de/,   
December 2013. 
[5]  Daniel Göhring, David Latotzky, Miao Wang, and Raul Rojas, “Semi-
Autonomous Car Control,” Intelligent Autonomous System 12, 
Springer, pp. 393-408, 2013. 
[6] Joystick Driving System: allows wheelchair users to drive a car; 
http://www.youtube.com/watch?v=EvMii_a7qi4, December 2013. 
[7] Masayoshi Wada and Fujio Kameda, “A joystick car drive system with 
seating in a wheelchair,” IEEE IECON ’09, pp. 2163-2168, November 
2009. 
[8] FORUM8 Air Driving and RoboCar 
http://www.youtube.com/watch?v=LMr2dyfAzl0, December 2013. 
[9] A.S.M. Mahfujur Rahman, Jamal Saboune, and Abdulmotaleb El 
Saddik, “Motion-path based in car gesture control of the multimedia 
devices,” ACM DIVANet ’11, Proceedings of the first ACM 
international symposium on Design and analysis of intelligent 
vehicular networks and applications, pp. 69-75, November 2011. 
[10] Tanja Döring, Dagmar Kern, Paul Marshall, Max Pfeiffer, Johannes 
Schöning, Volker Gruhn, and Albrecht Schmidt, “Gestural interaction 
on the steering wheel: reducing the visual demand,” ACM CHI ’11, 
Proceedings of the 2011 annual conference on Human factors in 
computing systems, pp. 483-492, May 2011. 
[11] Yoshitoshi Murata, Nobuyoshi Sato, Tsuyoshi Takayama, and 
Shinetsu Onodera, “A Gesture-based Remote Control for Finger 
Disabled People,” IEEE, GCCE 2012, pp. 411-415, October  2012. 
[12] Shinya Saito, Yoshitoshi Murata, Tsuyoshi Takayama, and Nobuyoshi 
Sato, “An International Driving Simulator: Recognizing the Sense of a 
Car Body by the Simulator,” Workshops in AINA 2012, W-FINA-
S12.1, pp. 254-260, March 2012. 
[13] OpenGL – The Industry Standard for High Performance Graphics,  
http://www.opengl.org/, December 2013. 
[14] Simple DirectMedia Layer, http://www.libsdl.org/, December 2013. 
[15] The OpenGL Extension Wrangler Library, 
http://glew.sourceforge.net/, December 2013. 
[16] OpenAL Soft, http://kcat.strangesoft.net/openal.html, December 2013. 
[17] Masato Abe, “Automotive Vehicle Dynamics - Theory and 
Applications,” Tokyo Denki University Press, 2008. 
[18]  Giancalro Genta, “We apply the steady gyrating movement to a car 
under following assumptions,” World Scientific Publishing, 1997. 
[19] Samsung SMART-TV,  
http://www.samsung.com/us/2012-smart-tv/, December 2013. 
[20] ATR Promotion WAA-010, http://www.atr-p.com/sensor10.html, 
December 2013. 
 
 

