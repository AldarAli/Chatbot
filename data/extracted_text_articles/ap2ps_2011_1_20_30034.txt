Virtual Landmarking for Locality Aware Peer IDs
Alexander Allan, James Bradbury and Giuseppe Di Fatta
School of Systems Engineering
The University of Reading
Whiteknights, Reading, Berkshire, RG6 6AY, UK
A.J.M.Allan@student.reading.ac.uk, siu06jb@reading.ac.uk and G.DiFatta@reading.ac.uk
Abstract—In Peer-to-Peer (P2P) networks, it is often desir-
able to assign node IDs which preserve locality relationships
in the underlying topology. Node locality can be embedded
into node IDs by utilizing a one dimensional mapping by a
Hilbert space ﬁlling curve on a vector of network distances
from each node to a subset of reference landmark nodes within
the network. However this approach is fundamentally limited
because while robustness and accuracy might be expected to
improve with the number of landmarks, the effectiveness of
1 dimensional Hilbert Curve mapping falls for the curse of
dimensionality. This work proposes an approach to solve this
issue using Landmark Multidimensional Scaling (LMDS) to
reduce a large set of landmarks to a smaller set of virtual
landmarks. This smaller set of landmarks has been postu-
lated to represent the intrinsic dimensionality of the network
space and therefore a space ﬁlling curve applied to these
virtual landmarks is expected to produce a better mapping
of the node ID space. The proposed approach, the Virtual
Landmarks Hilbert Curve (VLHC), is particularly suitable for
decentralised systems like P2P networks. In the experimental
simulations the effectiveness of the methods is measured by
means of the locality preservation derived from node IDs in
terms of latency to nearest neighbours. A variety of realistic
network topologies are simulated and this work provides strong
evidence to suggest that VLHC performs better than either
Hilbert Curves or LMDS use independently of each other.
Keywords-Peer-to-Peer Networks; Hilbert Curve; Landmark
Multidimensional Scaling; Virtual Landmarks; Network Coor-
dinates
I. INTRODUCTION
In Peer to Peer (P2P) networks it is useful in many
circumstances for a node to be aware of its relative locality,
the neighbourhood in which it resides. Latency optimizations
that neighbourhood knowledge provides bring clear beneﬁts
to search and routing algorithms [1] [2] [3] [4]. In addition,
locality information itself is key to many self organizing,
cooperative and gossip based networks which represent an
emerging paradigm in P2P technology [5] [6].
A node’s calculation of its network locality is problematic
as it is impractical for each node to apply a distance measure
such as Round Trip Time (RTT) to all other nodes in the
network.
A solution to this problem comes in the form of landmark
clustering [3] used to create a scalar node ID space [7].
The assumption behind this technique is that RTT dis-
tances from any node to a predetermined set of landmark
nodes (a subset of nodes which act as reference points) will
be similar for other nodes in the immediate neighbourhood.
The vector of distances to landmarks can be used in itself if
the network protocols support a multidimensional index [8].
This work will be mainly focusing on the 1D scalar index
that can be generated from this vector, noting that such an
index can be more easily integrated into many existing peer-
to-peer distributed hash table (DHT) systems. A scalar index
provides an intuitive notion of locality for node naming
schemes in all areas of P2P networks.
In order to create this scalar node ID from a distance
vector, a dimensionality reduction algorithm is required.
Previous work [9] has shown that in the context of landmark
vector reduction, Hilbert Curves (HC), which are a type of
space ﬁlling curve with good locality preserving properties
[10] [11], outperform Principal Component Analysis (PCA)
and Sammon Mapping [12] in terms of neighbourhood
preservation. The Hilbert Curve can also be deployed in a
distributed manner, requiring only a set of landmark vectors
and a predeﬁned HC granularity at each node to produce a
homogeneous indexing for all nodes.
A problem identiﬁed with this method and with landmark
indexing in general stems from the vulnerability and network
trafﬁc implication inherent in having a small number of
landmark nodes upon which all other nodes depend to
produce their node ID. Furthermore the less landmarks
used, the greater the importance of landmark placement to
the accuracy of the overall algorithm [13]. It is desirable
therefore to increase the number of landmarks used as much
as possible so as to negate the need for a heuristic landmark
selection process and to decrease the vulnerability to single
node failures.
However, Hilbert Curves are affected considerably by the
curse of dimensionality [9], which causes accuracy to fall
and computational load to increase with each additional
dimension.
This work proposes a method to avoid the critical trade
off in the number of landmark nodes. The notion of virtual
landmarks is exploited to decouple the two issues. A large
number L of actual landmark nodes are projected into an
opportune small number K (K < L) of virtual landmarks
which deﬁne a network coordinates space for a given topol-
ogy. The HC is applied to the network coordinates space
7
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-173-1
AP2PS 2011 : The Third International Conference on Advances in P2P Systems

which has lower dimensionality than the space deﬁned by the
actual landmarks. In particular, a decentralised version of the
Landmark Multidimensional Scaling (LMDS) [14] algorithm
is adopted to map the landmark vectors into virtual landmark
vectors of lower dimensionality.
The proposed method, Virtual Landmarks Hilbert Curve
(VLHC), is expected to be more accurate in preserving
locality in the peer ID space than using either LMDS or
Hilbert Curve alone.
In the experimental analysis realistic network topologies
are used to compute and compare the accuracy of the
methods in preserving nearest neighbour relations.
The remainder of the paper is organized in the follow-
ing manner: Section II shows an overview of the various
algorithms and techniques used, Section III describes the
proposed method, Section IV describes the experimental
methodology used for the comparison and benchmarking,
Section V displays the experimental results and presents
their analysis and, ﬁnally, Section VI provides some con-
clusive remarks and suggests future extensions to this work.
II. OVERVIEW OF TECHNIQUES
A. Hilbert’s Curve
The Hilbert Curve (HC) is a method of sequentially
indexing points in space via a non intersecting line. The
idea of space ﬁlling curves was ﬁrst proposed theoretically
by Giuseppe Peano in 1890 then geometrically by David
Hilbert a year later. These curves allow points in an N
dimensional space to be ordered on a 1D line in a manner
which preserves locality relationships. Although a number
of other space ﬁlling curves exist, such as Lebesque Curves,
it has been shown that Hilbert Curves are among the best
at preserving locality in terms of compact regions of space
[15] [16].
B. Virtual Landmarking
Virtual landmarks in the context of network coordinates
were proposed by Tang et al in 2003 [17]. The concept arose
from analysis of the process in which locality information
was embedded as sets of vectors to landmarks. This analysis
showed that the intrinsic dimensionality of these embeddings
in Internet-like networks was typically around 8 [17].
The concept of intrinsic dimensionality can be illustrated
by imagining a mechanical arm with 5 joints. A data set
might have the angle of each joint sampled at a certain
time interval with the tip of the arm represented by a 5
dimensional coordinates. Since the mechanical arm exists
in a 3D lab however, this position could be described by
a 3 dimensional coordinate system with no reduction in
accuracy. The embedding dimension of this data set would
then be 5, with an intrinsic dimensionality of 3.
This work is based on the assumption that the intrinsic
dimensionality of computer networks is relatively small. The
approximate ﬁgure of 8 given by Tang et al. suggests that
projecting a high dimensional coordinate space to a few
dimensions will retain most of the locality information.
C. LMDS
Multidimensional Scaling (MDS) [18][19] is a family
of dimensionality reduction methods. In classical MDS an
N×N distance matrix is required, where N is the number of
objects (nodes). The algorithm performs the eigendecompos-
tion of the distance matrix and has a complexity of O(N 3).
In order to generate the landmark vectors each node would
need to determine the communication latency to every other
node in the topology. This approach clearly has practical
limitations in a large-scale P2P network.
Landmark Multidimensional Scaling (LMDS) [20], [21]
is a scalable MDS variant which does not require computa-
tionally expensive matrix calculations, nor the entire distance
matrix. Landmark MDS instead performs a classical MDS
on the subset of landmark nodes only, and computes embed-
ding coordinates for the other nodes by using distance-based
triangulation by means of the decomposed landmark matrix.
Landmark MDS was developed primarily as a technique
to speed up the ISOMap procedure [20], and has been
shown to be equivalent to the Nystr¨om approximation of
the eigenvectors and eigenvalues of a matrix [22], The
method works by utilising properties of kernel matrices to
calculate embedding coordinates based upon estimations of
eigenvalues and eigenvectors.
Two distance matrices are calculated, landmark node
to landmark node matrix A, and landmark node to non-
landmark node matrix B. To distinguish Landmark MDS
from the Nystr¨om approximation, A and B must undergo
double-centering, akin to the classical MDS procedure [22].
The Nystr¨om approximation then calculates estimated em-
bedding coordinates using values from the eigendecomposed
A matrix and values from the B matrix only, therefore
negating the need for the costly calculation of the N × N
distance matrix as well as its eigendecomposition. LMDS
has a complexity of O(NLk + L3), where L (L ≪ N) is
the number of landmarks and k (k ≤ L) is the number of
the largest positive eigenvalues used in the approximation.
D. Landmark Selection
The landmark selection problem has itself been the subject
of much work as for small numbers of landmarks it can
have a large impact on any triangulation based methods
[23][13][24]. Various heuristics have been proposed which
attempt to select landmarks spread throughout the network
with a uniform distribution.
However, Tang et al (2004) [13] ﬁnd that as the number of
landmarks in a network surpass 20, most landmark selection
techniques (with the exception of a computationally infea-
sible greedy approach) are no better than random selection
because a uniform distribution inevitably emerges from any
random selection method given sufﬁcient points.
8
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-173-1
AP2PS 2011 : The Third International Conference on Advances in P2P Systems

This work adopts a random selection of a large number of
landmarks, thus avoiding the complexity of implementing a
distributed non random selection heuristic.
III. VIRTUAL LANDMARKS HILBERT CURVE (VLHC)
This work proposes a novel approach for 1 dimensional
index generation by combining the notion of virtual network
landmarks with the two techniques HC and LMDS. In a two-
stage process at each node, LMDS is applied to the local
RTT vector vL obtained from a large set of L landmarks.
LMDS is used to project the high-dimensional RTT vector
to a lower K-dimensional space, where K
< L. The
corresponding low-dimensional vector v K is referred to as
the virtual landmark vector.
In the second stage the local virtual landmark vector is
converted into a scalar index by means of a Hilbert Curve.
A traditional approach would apply HC to the landmark
vectors in L dimensions. In the proposed approach HC is
applied to the virtual landmark vectors in K dimensions. The
LMDS dimensionality reduction is adopted to overcome the
restriction of the Hilbert Curve that performs badly in high
dimensional spaces. This combination is also likely to be
more effective than using the LMDS to project directly into
the 1D index space, as Hilbert Curves have more favourable
locality preserving properties.
A. Decentralised Algorithm
A distributed approach for conducting the LMDS at each
node would be as follows.
In the initialisation step the landmark nodes ping each
other in order to create a matrix of latencies (RTT) between
them. The landmark nodes perform an all-to-all broadcast
operation to propagate their local latency vector and to
generate the L×L matrix. Each landmark node then uses this
matrix to perform classic MDS locally and independently.
All landmark nodes will compute the eigenvalue decomposi-
tion of the matrix. The landmark nodes generate an identical
reference set of K 1 eigenvalues and vectors.
When a node joins the network, it pings the landmarks to
create a local landmark vector. The node also requests and
receives the reference set of eigenvalues and eigenvectors
from any one of the landmarks. From the reference set and
its local RTT vector, the node can calculate its own ap-
proximate position in the lower dimensional MDS projection
using the Nystr¨om approximation [22]. The coordinates of
this approximate position is then taken as the node’s virtual
landmark vector to which the Hilbert Curve is applied to
produce the 1D node index (peer ID).
The approach is scalable as nodes have to communicate
with landmark nodes only. The number and choice of actual
landmarks is not critical as already discussed.
1The actual number of virtual landmarks corresponds to the maximum
between the parameter K and the number of positive eigenvalues.
The VLHC technique can be applied in P2P networks
without the need for global communication and synchroni-
sation. This can be done in a fully decentralised approach
as outlined in the following steps.
Using a Gossip-based protocol nodes can randomly select
the landmarks by exchanging sorted lists of IP addresses and
choosing the top L after a suitable convergence period.
The elected landmark nodes collect RTTs to each other
and create the matrix needed for LMDS. The landmark
nodes distribute the matrix throughout the network at a
certain rate to prevent a trafﬁc bottleneck at the landmarks.
When each node receives the matrix, it can then calculate
its virtual landmarks vector and from this its node ID.
IV. COMPARATIVE ANALYSIS
The comparative analysis of the different methods is based
on the average latency to the 30 Nearest Neighbour (NN)
nodes. Two methods provided the baseline and the optimal
value of the performance index. The ideal performance was
computed by searching the 30 actual NNs in the topology
for each node. The random selection of 30 nodes provided
a baseline value of the worst performance. The performance
indices from several random selections of landmark sets
were averaged.
In the experimental evaluation four methods were tested
to carry out a comparative analysis:
• 1-dimensional Landmark Multidimensional Scaling
(1D LMDS),
• Hilbert Curve applied to the landmark vectors (Hilbert),
• the proposed Virtual Landmarks Hilbert Curve (VLHC)
and
• 8-dimensional LMDS Network Coordinates (8D Net-
work Coordinates).
The 8D LMDS generates a network coordinates scheme
which is suitable to assess the information loss associ-
ated with the virtual landmarks. Ideally a loss-less latency
vector projection from the L-dimensional space to the K-
dimensional space would produce a performance index com-
parable to the ideal NN method. It should be noticed that
this method does not produce a scalar index which can be
used as peer ID and it serves as reference only.
In each test L landmark nodes were chosen randomly and
RTTs between them were used to create the matrix for the
LMDS calculations with the Nystr¨om approximation. RTTs
from each node i to the landmark nodes were determined,
vL
i , and were input into the LMDS algorithm to create a
vector of distances to K virtual landmarks v K
i .
The Douge Moore’s C implementation [25] of a recursion
free algorithm of the Hilbert’s space ﬁlling curve [26] was
adopted. It was applied to vK
i
to produce the 1D index
H(vK
i ). The same algorithm was also applied to the vector
vL
i to produce the 1D index H(vL
i ) for the classical Hilbert
Curve method.
9
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-173-1
AP2PS 2011 : The Third International Conference on Advances in P2P Systems

 0
 20
 40
 60
 80
 100
 120
 140
 0
 5
 10
 15
 20
 25
 30
Average Latency to Nearest Neighbours
Number of Virtual Landmarks (K)
random
Network Coordinates (L=20)
Network Coordinates (L=30)
Network Coordinates (L=40)
Network Coordinates (L=50)
ideal
Figure 1.
Average latency to nearest neighbours vs. the number of virtual
landmarks: reference methods only
LMDS with K = 1 was applied to vectors vL
i to produce
a 1D index L(vL
i ). Each of the three methods generates a
different set of peer IDs, respectively, {H(v K
i )}, {H(vL
i )}
and {L(vL
i )}.
Each generated index set was used to search the set of
30 nearest neighbours nodes for each node. Multiple sets
of random nodes were generated and the exact NNs in the
topology were computed using the Floyd Warshals algorithm
[27]. The set of NNs in the 8D network coordinates scheme
was determined by means of the Euclidean distance.
A set of NNs was used to compute an accuracy index.
The distances between every node and its NNs was used to
produce an average NN latency for each method.
The accuracy index is a normalized average NN latency
(∈ [0, 1]) which is designed to be relevant across hetero-
geneous topologies. An accuracy index of 1 is assigned to
the ideal average NN latency; 0 is assigned to the worst
average NN latency average associated with the random
method. The average NN latency of each method and on
each topology was normalized between these two indices.
Using this accuracy measure results close to 1 indicate the
method was almost as good as was possible and results
which were closer to 0 imply that the method was almost
as bad as a purely random selection of neighbours.
V. SIMULATIONS AND RESULTS
We have tested the algorithms in two different types of
network topologies:
• 10 Internet-like topologies with 1000 nodes generated
by the topology generator BRITE [28] with a Waxman
model [29] to simulate a ﬂat level Autonomous System;
• 10 2D mesh topologies with dimensions 40 × 25 (1000
nodes).
In the ﬁrst test the average NN latency of the three
reference methods (ideal, random and Network Coordinates)
was compared to verify the intrinsic dimensionality of the
Internet-like topologies. In Figure 1 the average NN latency
for these three methods is shown for a varying number of
virtual landmarks K. The number of actual landmarks L is
ﬁxed to 20, 30, 40 and 50. For the Network Coordinates
method and for a given value L, the test was executed
till the eigendecomposition would return enough positive
eigenvalues to generate the desired number K of virtual
landmarks. For K < 10 the average NN latency of the Net-
work Coordinates scheme clearly improves as K increases.
For K > 10 it does not improve further or it worsens. The
test was run on a single Internet-like topology; similar results
were obtained for the other topologies. This experiment
shows that a choice of 8 virtual landmarks is a good trade
off, conﬁrming the intrinsic dimensionality of the Internet-
like topologies as determined in [17]. In all other simulations
we have ﬁxed the number K of virtual landmarks to 8.
All methods were tested on each network topology mul-
tiple times. For each topology, the resulting performance
indices were averaged over 20 tests with different random
selections of landmarks. For each topology, the number of
landmarks was increased from L = 3 to L = 49 and for
every L value the normalised accuracy index was computed
as the average over 20 tests with different random selections
of landmarks.
Figures 2(a) and 2(b) show the accuracy of the methods
when varying the number of the actual landmark nodes.
The curve for the Hilbert method is truncated at L = 20.
Within Douge Moore’s C implementation of the Hilbert
Curve, the number of input bits (which deﬁnes the gran-
ularity of the curve) multiplied by the number of input
dimensions cannot exceed the value of 8 times an unsigned
‘long long’ data type (which is 64 bytes in the used CPU
architecture). A curve with 3-byte granularity was used to
give sufﬁcient precision, so when the input dimensionality
increased beyond 21, the curve would no longer compute as
22 × 3 > 64.
A. Discussion
The VLHC technique performs better than either the 1D
LMDS or stand alone Hilbert curve on both mesh and
Internet like topologies. Its accuracy plateaus at around 0.87
on the mesh topology, and around 0.41 on the Internet like
topology. It achieves this after 18 or more landmarks are
used, only improving marginally after this point as more
landmarks are added.
On the mesh topologies, where the intrinsic dimensional-
ity is 2, the standard Hilbert Curve computed over all land-
marks was comparable to VLHC. However, implementation
issues did effect its actual scalability in terms of the number
of landmarks.
On the Internet like topologies, the standard Hilbert Curve
achieved a maximum accuracy of around 0.24 after 6 land-
marks but could only maintain this until the implementation
failed at 22 landmarks. On this type of topologies, where the
10
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-173-1
AP2PS 2011 : The Third International Conference on Advances in P2P Systems

 0
 0.2
 0.4
 0.6
 0.8
 1
 1.2
 0
 10
 20
 30
 40
 50
Accuracy
Number of Landmarks (L)
8D Network Coordinates
VLHC
1D LMDS
Hilbert
(a) Mesh topologies
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0
 10
 20
 30
 40
 50
Accuracy
Number of Landmarks (L)
8D Network Coordinates
VLHC
1D LMDS
Hilbert
(b) Internet-like topologies
Figure 2.
Accuracy for mesh (a) and Internet-like topologies (b)
intrinsic dimensionality is about 8, it performed constantly
worse than the VLHC.
On the mesh topologies the 1D index produced by the
LMDS was the worst performer with a peak of 0.23 accuracy
at 5 landmarks. As more landmarks were added the accuracy
fell slowly. For the Internet like topology the 1D LMDS
index was again the worst performer for any numbers of
landmarks we have tested, getting a peak accuracy score
of 0.1 which again fell slowly as the number of landmarks
increased.
The 8D network coordinates produced by LMDS showed
almost optimal performance in the mesh topologies, with
accuracy rising up to 0.97 after 17 landmarks. In the Internet
like topologies, however, it performed signiﬁcantly worse,
achieving a maximum of 0.58 at 49 landmarks. The curve
shows a steep improvement up to around 8 landmarks, at
which point the rate of improvement slows considerably.
This is also another indirect conﬁrmation of the intrinsic
dimensionality of this type of topologies.
The non optimal performance of the 8D network coordi-
nates system in the Internet-like topologies may be due to
using a triangulation based technique (which is essentially
how LMDS works) in a network space which violates the
triangular inequality (the communication latency from A
to B might be more than from A to C to B). The mesh
topology however is much closer to Euclidean space and so
the inequality would hold true in most cases.
The effectiveness of the VLHC 1D node indexing scheme
is considerably greater in the mesh topology than in the
Autonomous Systems topology. Indeed it scores only 12%
less than a brute force approach in the mesh topology which
makes it suitable for most applications. The utility in an
Internet like topology will be considerably more dependant
on the problem domain, as the peak accuracy of 41% may
not be sufﬁcient for some applications where a high degree
of geographical accuracy is needed, but rather for ones
where a notion of locality in a scalar index outweighs the
overheads of adopting a more accurate but more complex
multidimensional network coordinate scheme.
VI. CONCLUSION
This work has presented the application of the concept of
virtual landmarks to the problem of generating locality aware
peer identiﬁers by means of space ﬁlling curves. Quantitative
evidence has suggested that applying LMDS in conjunction
with a Hilbert Curve produces a superior mapping to a
1D index in terms of locality preserving properties, when
compared to either technique applied independently. This
agrees with the postulation that a small number of virtual
landmarks are sufﬁcient to capture the intrinsic dimension-
ality of Internet-like networks. More experimental work is
required to investigate the sensitivity of the proposed method
with respect to this parameter in real network topologies.
In contrast to previous applications of the Hilbert Curve, a
larger numbers of landmarks can be employed by exploiting
a decentralised LMDS algorithm. This not only increases
accuracy but also allows for more robustness.
The experimental analysis has shown that, as expected,
1D indices are less accurate than multidimensional network
coordinates. In general, applications should consider what
accuracy level of nearest neighbour preservation is needed
before adopting either a 1D scheme or a multidimensional
scheme, as the cost of simplicity is still substantial.
Further work will include using graphs extracted from
real network topologies to support the results obtained via
simulation, the implementation and testing of the outlined
Gossip-based approach and the adaptation of the algorithm
to handle a dynamic environment with churn rate for nodes
and landmarks and with time-varying latencies.
REFERENCES
[1] H. Shen and C. Xu, “Hash-based proximity clustering for load
balancing in heterogeneous dht networks,” Journal of Parallel
and Distributed Computing, vol. 65, no. 5, pp. 686–702, May
2005.
11
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-173-1
AP2PS 2011 : The Third International Conference on Advances in P2P Systems

[2] M. Castro, P. Druschel, Y. C. Hu, and A. Rowstron, “Ex-
ploiting network proximity in peer-to-peer overlay networks,”
Microsoft Research, Cambridge, England, Tech. Rep. MSR-
TR-2002-82, May 2002.
[3] S. Ratnasamy, M. Handley, R. Karp, and S. Shenker,
“Topologically-aware overlay construction and server selec-
tion,” in Twenty-First Annual Joint Conference of the IEEE
Computer and Communications Societies Proceedings, New
York, USA, Jun. 2002, pp. 1190–1199.
[4] Y. Zhu and Y. Hu, “Towards efﬁcient load balancing in
structured P2P systems,” in 18th International Parallel and
Distributed Processing Symposium (IPDPS’04), Santa Fe,
USA, april 2004, p. 20.
[5] M. Cai and M. Frank, “RDFPeers: a scalable distributed RDF
repository based on a structured peer-to-peer network,” in
Proceedings of the 13th international conference on World
Wide Web.
ACM, 2004, pp. 650–657.
[6] S. Savarimuthu, M. Purvis, M. Purvis, and B. Savarimuthu,
“Mechanisms for the self-organization of peer groups in
agent societies,” Multi-Agent-Based Simulation XI, pp. 93–
107, 2011.
[7] Z. Li, G. Xie, and Z. Li, “Locality-aware consistency mainte-
nance for heterogeneous P2P systems,” in IEEE International
Parallel and Distributed Processing Symposium (IPDPS),
2007, pp. 1–10.
[8] M. Gharib, Z. Barzegar, and J. Habibi, “A novel method for
supporting locality in peer-to-peer overlays using hypercube
topology,” in International Conference on Intelligent Systems,
Modelling and Simulation (ISMS), 2010, pp. 391–395.
[9] A. Allan and G. Di Fatta, “Effectiveness of landmark analysis
for establishing locality in P2P networks,” in The Second In-
ternational Conference on Advances in P2P Systems (AP2PS
2010), October 2010.
[10] C. Gotsman and M. Lindenbaum, “On the metric properties
of discrete space-ﬁlling curves,” IEEE Transactions on Image
Processing, vol. 5, no. 1, pp. 794–797, Jan. 1996.
[11] B. Moon, H. Jagadish, C. Faloutsos, and J. Saltz, “Analysis
of the clustering properties of the Hilbert space-ﬁlling curve,”
IEEE Transactions on Knowledge and Data Engineering,
vol. 13, no. 1, pp. 124–141, Jan. 2001.
[12] J. Sammon, “A nonlinear mapping for data structure analysis,”
IEEE Transactions on Computers, vol. C-18, no. 5, pp. 401–
409, May 1969.
[13] L. Tang and M. Crovella, “Geometric exploration of the
landmark selection problem,” Passive and Active Network
Measurement, pp. 63–72, 2004.
[14] V. De Silva and J. Tenenbaum, “Sparse multidimensional scal-
ing using landmark points,” Dept. Math., Stanford University,
Stanford, CA, Tech. Rep, 2004.
[15] C. Faloutsos and Y. Rong, “Spatial access methods using
fractals: Algorithms and performance evaluation,” University
of Maryland, Maryland, USA, Tech. Rep. UMIACS-TR-89-
31, Mar. 1989.
[16] H. Jagadish, “Linear clustering of objects with multiple
attributes,” ACM SIGMOD Record, vol. 19, no. 2, pp. 332–
342, Jun. 1990.
[17] L. Tang and M. Crovella, “Virtual landmarks for the internet,”
in Proceedings of the 3rd ACM SIGCOMM conference on
Internet measurement.
ACM, 2003, pp. 143–152.
[18] W. Torgeson, “Multidimensional scaling of similarity,” Psy-
chometrika, vol. 30, pp. 379–393, 1965.
[19] R. Shepard, “Analysis of proximities: Multidimensional scal-
ing with an unknown distance function I & II,” Psychome-
trika, vol. 27, pp. 125–140, 219–246, 1962.
[20] J. B. Tenenbaum and V. de Silva, “A global geometric
framework for nonlinear dimensionality reduction,” Science,
vol. 290, no. 5500, pp. 2319–2323, 2000.
[21] V. de Silva and J. B. Tenenbaum, “Sparse multidimensional
scaling using landmark points,” University of Stanford, Stand-
ford, USA, Tech. Rep. CSE-TR-456-02, jun 2004.
[22] J. C. Platt, “Fastmap, metricmap, and landmark mds are all
nystrom algorithms,” in In Proceedings of 10th International
Workshop on Artiﬁcial Intelligence and Statistics.
IEEE,
2005, pp. 261–268.
[23] S. Baskakov, “Landmarks selection algorithm for wireless
sensor networks,” in Self-Adaptive and Self-Organizing Sys-
tems, 2008. SASO’08. Second IEEE International Conference
on.
IEEE, 2008, pp. 361–369.
[24] Q. Cao and T. Abdelzaher, “Scalable logical coordinates
framework for routing in wireless sensor networks,” ACM
Transactions on Sensor Networks (TOSN), vol. 2, no. 4, pp.
557–593, 2006.
[25] D.
Moore.
(2011)
Fast
hilbert
curve
gen-
eration,
sorting,
and
range
queries.
Rice
University.
Texas,
USA.
[Online].
Available:
http://www.tiac.net/∼sw/2008/10/Hilbert/moore/hilbert.c
[26] A. Butz, “Alternative algorithm for Hilbert’s space-ﬁlling
curve,” IEEE Transactions on Computers, vol. C-20, no. 4,
pp. 424–426, april 1971.
[27] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein,
Introduction to Algorithms (3rd Ed.).
MIT Press, 2009.
[28] A. Medina, A. Lakhina, I. Matta, and J. Byers, “BRITE:
An approach to universal topology generation,” in Proc.
of the International Workshop on Modeling, Analysis and
Simulation of Computer and Telecommunications Systems
(MASCOTS’01), 2001, pp. 346–353.
[29] B. Waxman, “Routing of multipoint connections,” Selected
Areas in Communications, IEEE Journal on, vol. 6, no. 9,
pp. 1617–1622, 1988.
12
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-173-1
AP2PS 2011 : The Third International Conference on Advances in P2P Systems

