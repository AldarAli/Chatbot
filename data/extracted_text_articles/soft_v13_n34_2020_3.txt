Build Comparator: Integrated Semantic Comparison for Continuous Testing of
Android-based Devices using Sandiff
Carlos E. S. Aguiar, Jose B. V. Filho, Agnaldo O. P. Junior,
Rodrigo J. B. Fernandes, C´ıcero A. L. Pahins, Paulo C. R. Fonseca
Sidia R&D Institute
Manaus, Brazil
Emails: {carlos.aguiar, jose.vilarouca, agnaldo.junior,
rodrigo.fernandes, cicero.pahins, paulo.fonseca}@sidia.com
Abstract—With ever-larger software development systems con-
suming more time to perform testing routines, it is necessary
to think about approaches that accelerate continuous testing of
those systems. This work aims to allow the correlation of semantic
modiﬁcations with speciﬁc test cases of complex suites, and based
on that correlation, skip time-consuming routines or mount lists of
priority routines (fail-fast) to improve the productivity of mobile
developers and time-sensitive project deliveries and validation. In
order to facilitate continuous testing of large projects, we propose
Sandiff, a solution to efﬁciently analyze semantic modiﬁcations
on ﬁles that impact domain-speciﬁc testing routines of the ofﬁcial
Android Test Suite. We also propose the Build Comparator, an
integrated tool that leverages the semantic comparison on real-
world use cases. We demonstrate our approach by evaluating
both semantic coverage and scalability on a set of commercially-
available Android images of a large mobile-related company that
comprises both major and minor versions of the system.
Keywords–Testing; Validation; Content Comparison; Continu-
ous Delivery; Tool.
I.
INTRODUCTION
As software projects grow up, continuous testing becomes
critical, but at the same time, complicated and time-consuming.
Consider a project with a million ﬁles and intermediate arti-
facts. A test suite that offers continuous testing functionalities
must perform without creating bottlenecks or impacting project
deliveries. However, effectively using continuous integration
can be a problem: tests are time-consuming to execute. Con-
sequently, it is impractical to run complete modules of testing
on each build. In these scenarios, it is common that teams lack
time-sensitive feedback about their code and compromise user
experience.
The testing of large software projects is typically bounded
to robust test suites. Moreover, the quality of testing and
evaluation of ubiquitous software can directly impact people’s
life, a company’s perceived image, and the relation with its
clients. Companies inserted in the Global Software Develop-
ment (GSD) environment, i.e., with a vast amount of develop-
ers cooperating across different regions of the world, tend to
design a tedious testing and evaluation process that becomes
highly time-consuming and impacts the productivity of devel-
opers. Moreover, continuous testing is a de facto standard in
the software industry. During the planning of large projects, it
is common to allocate some portion of the development period
to design testing routines. Test-Driven Development (TDD)
is a well-known process that promotes testing before feature
development. Typically, systematic software testing approaches
lead to computing and time-intensive tasks.
Sandiff [1] is a tool that helps to reduce the time spent on
testing of large Android projects by enabling to skip domain-
speciﬁc routines based on the comparison of meaningful data
without affecting the functionality of the target software.
For instance, when comparing two Android Open Source
Project (AOSP) builds generated in different moments, but
with the same source code, create the environment and build
instructions, the ﬁnal result is different in byte level (byte-
to-byte). Still, it can be semantically equivalent based on its
context (meaning). In this case, it is expected that these two
builds perform the same. However, how to guarantee this? Our
solution relies on how to compare and demonstrate that two
AOSP builds are semantically equivalent. Another motivation
is the relevance of Sandiff to the continuous testing area,
where it can be used to reduce the time to execute the ofﬁcial
Android Vendor Test Suite (VTS). As our solution provides a
list of semantically equivalent ﬁles, it is possible to skip tests
that show the behavior provided by these ﬁles. The Figure 1
shows the execution ofﬁcial Android Test Suite is execute in a
commercially-available build based on AOSP. The execution
of all modules exceeded 4 hours, compromising developer
performance and deliveries on a planned schedule.
By comparison of meaningful data, we mean comparison
of sensitive regions of critical ﬁles within large software: dif-
ferent from a byte-to-byte comparison, a semantic comparison
can identify domain-related changes, i.e., it compares sensitive
code paths, or key-value attributes that can be related to the
output of large software. By large, we mean software designed
by a vast number of developers inserted in a distributed
software development environment; after that, automatic test
suits are necessary.
Another motivation of Sandiff is to enable developers to
ﬁnd bugs faster on complex software. Take as an example a
camera bug in which the component or module is part of a
complex Android subsystem stack covering various architec-
tural levels: application framework, vendor framework, native
code, ﬁrmware, and others. With the help of the Sandiff, a de-
veloper can analyze the semantic comparison between different
software releases and narrow the source of the problem.
In summary, we present the key research contributions of
our proposal:
139
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Suite/Plan
VTS/VTS
Suite/Build
9.0 R9 / 5512091
Host Info
seltest-66 (Linux - 4.15.0-51-generic)
Start Time
Tue Jun 25 16:17:23 AMT 2019
End Time
Tue Jun 25 20:39:46 AMT 2019
Tests Passed
9486
Tests Failed
633
Modules Done
214
Modules Total
214
Security Patch
2019-06-01
Release (SDK)
9 (28)
ABIs
arm64-v8a,armeabi-v7a,armeabi
Figure 1. Summary of the ofﬁcial Android Test Suite – Vendor Test
Suite (VTS) – of a commercially-available AOSP build.
1. An approach to perform semantic comparison and facili-
tate continuous testing of large software projects.
2. An integrated Build Comparator tool that leverages se-
mantic comparison to support Android-based software
releases and DevOps teams.
3. An evaluation of the impact of using Sandiff in real-world
and commercially-available AOSP builds.
Our paper is organized as follows. In Section II, we
provide an overview of binary comparators and their impact on
continuous testing of large projects. In Section III, we describe
Sandiff and its main functionalities: (i) input detection, (ii) con-
tent recognition, and (iii) specialized semantic comparison. In
Section IV, we present the Build Comparator tool and its ar-
chitecture, which enables the integration of Sandiff on systems
of the Android development environment. In Section V, we
present the evaluation of Sandiff in commercially-available
builds based on AOSP and discuss the impact of continuous
testing of those builds. We conclude the paper with avenues
for future work in Section VI.
II.
RELATED WORK
To the best of our knowledge, few literature approaches
propose comparison of ﬁles with different formats and types.
Most comparison tools focus on the comparison based on diff
(text or, at most, byte position). Araxis [2] is a well-known
commercial tool that performs three types of ﬁle comparison:
text ﬁles, image ﬁles, and binary ﬁles. For image ﬁles, the
comparison shows the pixels that have been modiﬁed. For
binary ﬁles, the comparison is performed by identifying the
differences in a byte level. Diff-based tools, such as Gnu
Diff Tools [3] diff and cmp, also perform ﬁle comparison
based on byte-to-byte analysis. The main difference between
diff and cmp is the output: while diff reports whether ﬁles
are different, cmp shows the offsets, line numbers and all
characters where compared ﬁles differs. VBinDiff [4] is another
diff-inspired tool that displays the ﬁles in hexadecimal and
ASCII, highlighting the difference between them.
Other approaches to the problem of ﬁle comparison, in
a semantic context, typically use the notion of change or edit
distance [5] [6]. Wang et al. [5] proposed X-Diff, an algorithm
that analyses the structure of an XML ﬁle by applying standard
tree-to-tree correction techniques that focus on performance.
Pawlik et al. [6] also propose a performance-focused algorithm
based on the edit distance between ordered labeled nodes of an
XML tree. Both approaches can be used by Sandiff to improve
its XML-based semantic comparator. Similarly, with study
applied on music notations, in [7] implemented a solution to
compare ﬁles, like XML, based on a tree representation of
music notation combining with sequence and tree distance.
Besides, the authors show a tool to visualize the differences
side-by-side.
In
[8], is showed a tool named Difﬁ, which is a diff
improved build to observe the correlation between ﬁle formats.
So, Difﬁ veriﬁes the heaps of the ﬁles’ reﬂection levels and
discovers which ﬁle levels can recognize the delta between two
ﬁles correctly.
In [9], the authors explore the use of wavelets for the
division of documents into fragments of various entropy levels,
which made a separation between grouping sections to decide
the similarity of the ﬁles, and ﬁnally, detect malicious software.
Additionally, with a similar objective in [10] is investigated the
applicability of machine learning techniques for recognizing
criminal evidence in activities into ﬁle systems, verifying
possible manipulations caused by different applications.
Different from previous works, the Sandiff also supports
byte-level and semantic comparison simultaneously. However,
the semantic comparison is the main focus of the tool to
facilitate extensive software projects testing since it allows to
discard irrelevant differences in the comparison.
III.
SANDIFF
Sandiff aims to compare meaningful data of two artifacts
(e.g., directories or ﬁles) and report a compatible semantic
list that indicates modiﬁcations that can impact the output of
domain-related on continuous testing setups of large projects.
In the context of software testing, syntactically different (byte-
to-byte) ﬁles can be semantically equivalent. Once the charac-
teristics of a context are deﬁned, previously related patterns to
this context can deﬁne the compatibility between artifacts from
different builds. By deﬁnition, two artifacts are compatible
when the artifact A can replace the artifact B without losing its
functionality or changing their behavior. As each ﬁle type has
its own set of attributes and characteristics, Sandiff employs
specialized semantic comparators that are designed to support
nontrivial circumstances of domain-speciﬁc tests. Consider
the comparison of AOSP build output directory and its ﬁles.
Note that the building process of AOSP in different periods
of time can generate similar outputs (but not byte-to-byte
equivalent). Different byte-to-byte artifacts are called syntac-
tically dissimilar and typically require validation and testing
routines. However, in the context where these ﬁles are used, the
position of key-value pairs do not impact testing either software
functionality. We deﬁne these ﬁles as semantically compatible,
once Sandiff is able to identify them and suggest a list of tests
to skip. Take Figure 3 as example. It shows a difference in
the position of the last two lines. When comparing them byte-
to-byte, this results in syntactically different ﬁles. However,
in the execution context where these ﬁles are used, this is
irrelevant, and the alternate position of lines does not change
how the functionality works. Thus, the ﬁles are semantically
compatible.
Sandiff consists of three main functionalities: (i) input
detection, (ii) content recognition, and (iii) specialized se-
mantic comparison, as shown in Figure 2. During analysis of
140
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 2. Sandiff veriﬁes the semantic compatibility of two ﬁles or directories (list of ﬁles) and report their differences.
Conﬁguration 1
ro.build.version.preview sdk=0
ro.build.version.codename=REL
ro.build.version.all codenames=REL
ro.build.version.release=8.0.0
ro.build.version.security patch=17-08-05
Conﬁguration 2
ro.build.version.preview sdk=0
ro.build.version.codename=REL
ro.build.version.all codenames=REL
ro.build.version.security patch=17-08-05
ro.build.version.release=8.0.0
Figure 3. Example of AOSP conﬁguration ﬁles.
TABLE I. SUMMARY OF CONTENT RECOGNITION ANALYSIS FOR
EACH FILE.
Attribute
Meaning
Tag
Represents a ﬁle type
Action
Action to be taken with the ﬁle. (COMPARE or IGNORE)
Reason
In case of action IGNORE, the reason of ignore
Context
Information about context that is used to deﬁne the ACTION
directories and ﬁles, we can scan image ﬁles or archives that
require particular read operations. The ﬁrst step of Sandiff
is to identify these ﬁles to abstract ﬁle systems operations
used to access the data. This task is performed by the Input
Recognizer. Then, the Content Recognizers and Comparators
are instantiated. In order to use the correct Comparator, Sandiff
implements recognizers that are responsible to detect supported
ﬁle types and indicate if a ﬁle should be ignored or not based
on a test context. Once Sandiff detects a valid ﬁle, it proceeds
to the semantic comparison. The Comparators are specialized
methods that take into consideration features and characteris-
tics that are able to change the semantic meaning of execution
or testing, ignoring irrelevant syntactical differences. Note
that the correct analysis of semantic differences is both ﬁle
type and context-sensitive. Sandiff implements two operation
modes: (i) ﬁle and (ii) directory-oriented (walkables). In ﬁle-
oriented mode, the input is two valid comparable ﬁles, whereas
directory-oriented is the recursive execution of ﬁle-oriented
mode in parallel, using a mechanism called Orchestrator.
In the following sections, we describe the functionalities of
Sandiff in detail.
A. Content Recognition
The Sandiff performs the analysis of ﬁle contents by
leveraging internal structures, and known patterns to allow
the correct selection of semantic comparators, i.e., artifact
extension, headers, type signatures, and internal rules of AOSP
to then summarize the results into (i) tag, (ii) action, (iii)
reason, and (iv) context attributes, as shown in Table I. Each
attribute helps the semantic comparators to achieve maximum
semantic coverage over ﬁle types inside images embedded
on commercially-available devices. The Android-based devices
include several partitions that serve for speciﬁc purposes on
boot process and general operation, as deﬁned below:
• system.img: contains the Android operating system
framework.
• vendor.img: contains any manufacturer-speciﬁc binary
ﬁle that is not available to the AOSP.
• userdata.img: contains user-installed data and appli-
cations, including customization data.
To measure the semantic coverage, we gathered the per-
centage (amount of ﬁles) of ﬁle types inside vendor.img.
We created a priority list to develop semantic comparators,
as shown in the Table II. For instance, both ELF (32 and 64
bits) ﬁles represent about roughly 60% of total ﬁles inside
.img ﬁles, whereas symbolic link ﬁles about 14% and XML
ﬁles about 6%. This process enables us to achieve about 90%
of semantic coverage. As the comparison is performed in a
semantic form, it is necessary to know the context in which
the artifact was used to enable the correlation between ﬁles
and test cases. Note that a ﬁle can impact one or more tests in
a different manner, e.g., performance, security and fuzz tests.
The remaining 10% of ﬁles are compared using the byte-to-
byte comparator.
Each recognizer returns a unique tag from a set of available
tags or a tag with no content to indicate that the ﬁle could
not be recognized. Recognizers can also decide whether a
ﬁle should be ignored based on context by using the action
attribute and indicating a justiﬁcation in the reason attribute.
Recognizers are evaluated sequentially. The ﬁrst recognizer
runs and tries to tag the ﬁle: if the ﬁle cannot be tagged,
the next recognizer in the list is called, repeating this process
until a valid recognizer is found or, in the latter case, the ﬁle
is tagged to the default comparator (byte-to-byte). Table III
summarizes the list of AOSP-based recognizers supported by
Sandiff.
B. Semantic Comparators
Sandiff was designed to maximize semantic coverage of
the AOSP by supporting the most relevant intermediate ﬁles
used for packing artifacts into .img image ﬁles, i.e., the
bootable binaries used to perform a factory reset and restore the
original operating system of AOSP-based devices. To ensure
141
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE II. SUMMARY OF SANDIFF SEMANTIC COVERAGE.
File Type
# Files
Percentage (%)
ELF-64
320
31.34
ELF-32
298
29.19
Symbolic link
152
14.89
XML document text
63
6.17
RC
34
3.33
.bin
34
3.33
.tlbin
28
2.74
.prop
21
2.06
.conf
10
0.98
ASCII text
8
0.79
Exported SGML
6
0.59
.dat
6
0.59
.hcd
4
0.39
JAR
3
0.29
.txt
3
0.29
.xml
2
0.20
Gzip compressed data
1
0.10
SE Linux
1
0.10
PEM certiﬁcate
1
0.10
* Green = Semantic comparison is performed. Red = Semantic comparison not
applicable. Default comparator (checksum) is performed. Orange = Semantic
comparison not supported by Sandiff. Default comparator (checksum) is performed.
TABLE III. LIST OF AOSP-BASED RECOGNIZERS SUPPORTED BY
SANDIFF.
Recognizer
Tags
Action
IgnoredByContextRecognizer
ignored by context
Ingore
ContextFileRecognizer
zip manifest
Compare
MagicRecognizer
elf, zip, xml, ttf, sepolicy
Compare
AudioEffectsRecognizer
audio effects format
Compare
SeappContextsRecognizerc
seapp contexts
Compare
PKCS7Recognizer
pkcs7
Compare
PropRecognizer
prop
Compare
RegexLineRecognizer
regex line
Compare
SEContextRecognizer
secontext
Compare
ExtensionRecognizer
Based on ﬁle name.
e.g.: ﬁle.jpg ? ”jpg”
Compare
the approach assertiveness, we performed an exploratory data
analysis over each ﬁle type and use case to deﬁne patterns
of the context’s characteristics for each semantic comparator.
The exploratory data analysis over each ﬁle type relies on three
steps:
1. ﬁle type study;
2. where these ﬁles are used;
3. how these ﬁles are used (knowledge of its behavior).
The result of this analysis was used to implement each
semantic comparator. The following subsections describe the
main semantic comparators of Sandiff.
1) Default (Fallback) Comparator: Performs byte-to-byte
(checksum) comparison and is the default comparator for
binary ﬁles (e.g., .bin, .tlbin, and .dat). Acts as a fallback
TABLE IV. EXAMPLE OF COMPARING TWO SEQUENCES OF BYTES.
Position
0
1
2
3
4
5
6
7
8
Sequence #1
1D
E1
2A
DD
5F
AE
F8
5F
19
Sequence #2
1D
ED
31
9E
5F
08
F8
5F
2E
alternative, performing comparison for cases where (i) ﬁle type
is not recognized or is unsupported and (ii) due to any errors
during the comparison (e.g., corrupted or malformed ﬁles).
Sandiff employs the industry standard [11] MD5 checksum
algorithm, as it balances performance and simplicity to verify
data integrity. For security-critical scenarios, Sandiff offers a
set of SHA algorithms with improved robustness and reliability
for collision attacks, i.e., veriﬁcation of intentional corruption,
despite lower run-time performance. The supported alternatives
are: SHA1 [12], SHA224 [13], SHA256 [14], SHA384 [15],
and SHA512 [16]. To choose the most suitable algorithm,
it is necessary to consider the infrastructure, the application
requirements and the knowledge of the developers. A complete
overview and discussion about SHA algorithms is provided in
[17], [18] reviews.
When comparing two or more sequences of bytes, each
position is represented on hexadecimal format, i.e., positional
format that represents numbers using a base of 16 and uses
symbols 0-9 and A-F, representing each byte by two hex-
adecimal digits. Table IV illustrates how Sandiff performs the
byte-to-byte comparison. Note that in this case, the comparison
veriﬁed that positions 1-3, 5 and 8 are different, summarizing
the result as illustrated in Listing 1.
Difference(s):
Differs on range between position 1 and 3
Differs on byte at position 5
Differs on byte at position 8
Listing 1. Example of checksum comparator output.
2) Audio Effects: AOSP represents audio effects and con-
ﬁgurations in .conf ﬁles that are similar to .xml:
(i) <name>{[sub-elements]}
(ii) <name> <value>
Audio ﬁles are analysed by an ordered model detection
algorithm that represents each element (and its sub-elements)
as nodes in a tree alphabetically sorted.
3) Executable and Linking Format (ELF): ELF ﬁles are
common containers for binary ﬁles in Unix-base systems that
packs object code, shared libraries, and core dumps. This
comparator uses the deﬁnition of the ELF format (<elf.h>
library) to analyse (i) the ﬁles architecture (32 or 64-bit),
(ii) the object ﬁle type, (iii) the number of section entries in
header, (iv) the number of symbols on .symtab and .dynsym
sections, and (v) the mapping of segments to sections by
comparing program headers content.
To correlate sections to test cases, Sandiff detects semantic
differences for AOSP test-sensitive sections (e.g., .bss, .rodata,
.symtab, .dynsym, .text), listing and performing byte-to-byte
comparison on all relevant ELF sections found on target
ﬁles. Table VI summarizes irrelevant sections to ignore when
implementing the semantic comparison for ELF ﬁles. When
ELF ﬁles are Linux loadable kernel modules (.ko extension,
142
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE V. LIST OF LISTCOMPARATOR OPERATIONS MODES AND
FLAGS SUPPORTED BY SANDIFF.
Flag
Description
File Order
Indicates if there are difference among the item position
in list and the line number of ﬁle
Line Type
Indicates if ﬁle lines has only one key ONLY KEY) or are
(composed by more elements (MORE THAN KEY), with
a value associated to the key
Displacement
Indicates if the result refers to differences semantically
relevant (true), or differences semantically irrelevant (false)
TABLE VI. LIST OF IRRELEVANT SECTIONS FOR SEMANTIC
COMPARISON OF ELF FILES.
Section
Reason
.debug *
holds information for symbolic debugging
.comment
version control information
.gnu debugdata
allows adding a subset of full debugging info to a special
section of the resulting ﬁle so the stack traces can be more
easily ”symbolicated”
.gnu debuglink
contains a ﬁle name and a CRC checksum of a separated
debug ﬁle
.gnu hash
allow fast lookup up of symbols to speed up linking
.ident
where GCC puts its stamp on the object ﬁle, identifying the
GCC version which compiled the code
.shstrtab
section names
.got.*
provides direct access to the absolute address of a symbol
without compromising position-independence and sharebility
.note.gnu.build-id
unique identiﬁcation 160-bit SHA-1 string
kernel object), the comparator checks if the module signature is
present to compare its size and values. Signature differences
are not considered relevant to semantic comparison. In case
of any ELF ﬁle is corrupted or malformed, the fallback
comparison is performed.
4) ListComparator: Base comparator for ﬁles structured
as item lists, reporting (i) items that exist only in one of the
compared ﬁles, (ii) line displacements (i.e., lines in different
positions), (iii) comments and empty lines, and (iv) duplicated
lines. To facilitate the correlation between ﬁles and test cases,
Sandiff implements speciﬁc list-based semantic comparators
for Prop, Regex Line and SELinux ﬁles, as they contain
properties and settings that are speciﬁc to a particular AOSP-
based device or vendor. To support such variety of ﬁles, the
list-based comparators offers a list of operation modes to
tackle speciﬁc scenarios, e.g., when the ﬁle has empty lines or
comments semantically irrelevant, as summarized in Table V.
The following paragraphs describe the list-based comparators
of Sandiff.
a) Prop: Supports ﬁles with .prop extensions and
formatted as <key> = <value> patterns. Prior to analysis,
each line of a .prop ﬁle is categorized in import, include or
property, as deﬁned below:
1. import: lines with format import <key>, i.e., lines
containing the word ”import”, followed by one key.
2. include: lines with format include <key>, i.e., lines
containing the word ”include”, followed by one key.
3. property: lines with format <key> = [<value>], i.e.,
lines containing a pair composed by a key and an asso-
ciated value (optional) - separated by ”=” symbol.
After categorization, each line is parsed and added to its
respective list, i.e., import, include, and property lists. Each
of the three lists is individually compared with the others,
generating disjoint results that are later jointed for reporting.
TABLE VII. LIST OF SEMANTIC IRRELEVANT PROPERTIES OF
ANDROID BUILDS.
Property
Description
BD
Found in system/sepolicy version
ro.bootimage.build.*
Build property set by android/build/make/core/Makeﬁle
ro.build.*
Build property set by android/build/make/tools/buildinfo.sh
at each new build
ro.expect.recovery id
Build property set by android/build/make/core/Makeﬁle
ro.factory.build id
Build property set by android/build/make/core/main.mk
ro.ss.bid
Build property set by android/build/make/core/main.mk
ro.vendor.build.*
Build property set by android/build/make/core/Makeﬁle
The PropComparator also provides a list of properties to be
discarded (considered irrelevant) on the semantic comparison,
as summarized in Table VII. A line can be ignored if is empty
or commented.
b) RegexLine:
Performs the comparison of ﬁles in
which all lines match a user-deﬁned regex pattern, e.g.,
’/system/.’ or ’.so’, offering the ﬂexibility to perform
semantic comparison of unusual ﬁles.
c) SELinux: Security-Enhanced Linux, or SELinux, is a
mechanism that implements Mandatory Access Control (MAC)
in Linux kernel to control the permissions a subject context
has over a target object, representing an important security
feature for modern Linux-based systems. Sandiff supports
semantic comparison of SELinux speciﬁcation ﬁles that are
relevant to security test cases of the VTS suite, i.e., Seapp
contexts, SELinux context, and SELinux Policy, summarizing
(i) components, (ii) type enforcement rules, (iii) RBAC rules,
(iv) MLS rules, (v) constraints, and (vi) labeling statements.
5) RC: The Android Init System is responsible for the
AOSP bootup sequence, init and init resources, components
that are typically customized for speciﬁc AOSP-based devices
and vendors. The initialization of modern systems consists of
several phases that can impact a myriad number of test cases
(e.g., kernel, performance, fuzz, security). Sandiff supports the
semantic comparison of .rc ﬁles that contain instructions used
by the init system:
• imports: analyses the importing calls of the invoking
mechanism.
• actions: compares the sequence of commands to test if
logical conditions are met, since commands in different
order may lead to different results.
• services: tackles operation modes by analysing options
(e.g., oneshot, onrestart, etc.) and characteristics (e.g.,
critical, priority, etc.) of the init-related services.
6) Symbolic Link: The semantic comparison of symbolic
links is an important feature of Sandiff that allows correlation
between test cases and absolute or relative paths that can
be differently stored across speciﬁc AOSP-based devices or
vendors, but result in the same output or execution. The
algorithm is deﬁned as follows: ﬁrst it checks if the ﬁle status
is a symbolic link, and if so, reads where it points to. With
this content it veriﬁes if two compared symbolic links points
to same path. The library used to check the ﬁle status depends
on the input type and is abstracted by Input Recognizers. The
libraries are:
File System → <sys/stat.h>
Image File → <ext2/ext2fs.h>
ZIP → <zip.h>
143
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

7) True Type Font: Sandiff uses the Freetype library [19]
to extract data from TrueType fonts, which are modeled in
terms of faces and tables properties. For each property ﬁeld, the
comparator tags the semantically irrelevant sections to ignore
during semantic comparison. This is a crucial feature of Sandiff
since is common that vendors design different customization
on top of the default AOSP user interface and experience.
8) XML: XML is the de facto standard format for web
publishing and data transportation, being used across all
modules of AOSP. To support the semantic comparison of
XML ﬁles, Sandiff uses the well-known Xerces library [20]
by parsing the Document Object Model (DOM), ensuring
robustness to complex hierarchies. The algorithm compares
nodes and checks if they have (i) different attributes length,
(ii) different values, (iii) attributes are only in one of the inputs,
and (iv) different child nodes (added or removed).
9) Zip and Zip Manifest:
During the building pro-
cess of AOSP images, zip-based ﬁles may contain Java
Archives (.jar), Android Packages (.apk) or ZIP ﬁles
itself (.zip). As these ﬁles follow the ZIP structure, they
are analysed by the same semantic comparator. Note that, due
to the archive nature of ZIP format, Sandiff covers different
cases:
1. In-place: there is no need to extract ﬁles.
2. Ignore Metadata: ignore metadata that is related to the
ZIP speciﬁcation, e.g., archive creation time and archive
modiﬁcation time.
3. Recursive: ﬁles inside ZIP are individually processed by
Sandiff, so they can be handled by the proper semantic
comparator. The results are summarized to represent the
analysis of the zip archive.
Another important class of ﬁles of the AOSP building
process are the ZIP manifests. Manifest ﬁles can contain
properties that are time-dependent, impacting naive byte-to-
byte comparators. Sandiff supports the semantic comparison
of manifests by ignoring header keys entries (e.g., String:
”Created-By”, Regex: ”(.+)-Digest”) and ﬁles keys
entries (e.g., SEC-INF/buildinfo.xml).
Each APK – the package ﬁle format used by Android – has
a set of manifest information and other metadata that are part
of the signature process. The most relevant for semantic com-
parison are META-INF/CERT.SF and MANIFEST.MF ﬁles,
since it contains integrity checks for ﬁles which are included
in the distribution, as shown in Listings 2 and 3. As both ﬁles
share the same structure, it is possible to analyse them with
the same semantic comparator. The ZipManifestComparator
parses both ﬁles and compares headers and digests by ignoring
irrelevant header and ﬁles entries.
Manifest-Version: 1.0
Created-By: singlejar
Name: AndroidManifest.xml
SHA-256-Digest: cEnjm4r95tb8NSMCP6B2Nn+P1G8sIpeXpPtsmuvSnfM=
Name: META-INF/services/
com.google.protobuf.GeneratedExtensionRegistryLoader
SHA-256-Digest: AT7RUk9qflHB8mVVceY0Zi7UuRK2bIPMewdxqL2zIBY=
Name: android-support-multidex.version.txt
SHA-256-Digest: OuJR1NnX1srJFP8Td2Bv9F5nMX3O5iAgxf15egCfa+Q=
Listing 2. The MANIFEST.MF ﬁle contains metadata used by the java
run-time when executing the APK.
Build Comparator
Comparator Service
WEB Interface1
2
Sandiff
Orchestrator
Manage Parallel Jobs
Recognizers
Recognize File Types
Semantic Comparators
Semantic Comparison
Input Adapters
Recognize and Read Input Files
Output
Semantic Compatible List 
Android
Build System
4
5
6
7
3
Figure 4. Build Comparator architecture and its relation with Sandiff’s
semantic comparison features.
Signature-Version: 1.0
Created-By: 1.0 (Android SignApk)
SHA-256-Digest-Manifest: rk0ZXezaawnGF65RmyYEmpqL+
gFdHzRTNb3kr/NeNNQ=
X-Android-APK-Signed: 2, 3
Name: AndroidManifest.xml
SHA-256-Digest: ZgWkXiulhWzT7qwbAVYgepd5tyGt6D+RQNAeT+AJw1Y=
Name: META-INF/services/
com.google.protobuf.GeneratedExtensionRegistryLoader
SHA-256-Digest: ASo5NB1Aa4gclvZke+olzjfErZMzxn/hthDK7Ann56w=
Name: android-support-multidex.version.txt
SHA-256-Digest: 6/lnFOH7mFVER94rAWcUmubglFFrHR7nf8+7zqQOgQs=
Listing 3. The CERT.SF ﬁle contains the whole-ﬁle digest of the
MANIFEST.MF and its sections.
10)
PKCS7:
Public Key Cryptography Standards, or
PKCS, are a group of public-key cryptography standards that
is used by AOSP to sign and encrypt messages under a Public
Key Infrastructure (PKI) structured as ASN.1 protocols. To
maximize semantic coverage, Sandiff ignores signatures and
compares only valid ASN.1 elements.
C. Orchestrator
The Orchestrator mechanism is responsible to share the
resources of Sandiff among a variable number of competing
comparison jobs to accelerate the analysis of large software
projects. Consider the building process of AOSP. We noticed
that, for regular builds, around 384K intermediate ﬁles are
generated during compilation. In this scenario, running all
routines of the ofﬁcial Android Test Suite, known as Vendor
Test Suite (VTS), can represent a time consuming process that
impacts productivity of mobile developers. To mitigate that,
the Orchestrator uses the well-known concept of workers and
jobs that are managed by a priority queue. A worker is a thread
that executes both recognition and comparison tasks over a
pair of ﬁles, consuming the top-ranked ﬁles in the queue. To
accelerate the analysis of large projects, Sandiff adopts the
notion of a fail greedy sorting metric, i.e., routines with higher
probability of failing are prioritized. The deﬁnition of failing
priority is context-sensitive, but usually tends to emphasize
critical and time-consuming routines. After the processing of
all ﬁles, the results are aggregated into a structured report
with the following semantic sections: (i) addition, (ii) removal,
(iii) syntactically equality, and (iv) semantic equality.
IV.
INTEGRATED BUILD COMPARATOR TOOL
To provide semantic comparison beneﬁts on supporting
software releases and DevOps operations, we propose Build
Comparator, an integrated tool that abstracts conﬁguration,
image management, test execution, and report visualization to
144
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 5. (A) Main Build Comparator interface. (B) List of jobs with unique
identiﬁer (ID), status, user, and job begin time. (C) Creation of comparison
jobs based on (i) build systems, (ii) remote or (iii) local images.
facilitate Android-based development pipelines and processes.
The Build Comparator can be integrated with systems that
are commonly used for compilation jobs and managing the
conﬁguration and execution of Android’s platform scripts, as
shown in Figure 4. The proposed integration covers all main
steps from user input to report visualization, as follows:
1. The user interacts with the tool through the Web Inter-
face, which is responsible for providing communication
between the user and service.
2. The Comparator Service provides a REST-based service
that is responsible for managing the whole life-cycle of
scheduled jobs (i.e., creation, management and running)
using Sandiff as back-end. The service is also integrated
with the systems responsible for compilation jobs, per-
forming the user credential and image downloads.
3. On Sandiff side, the Input Adapters provide the ability
to R/W different input ﬁles, abstracting the methods used
to access the data.
4. The Orchestrator is responsible for managing the paral-
lel jobs when Sandiff is ﬁlled with directories analysis,
tracking ﬁle additions, removals, and type changes.
5. The Recognizers are responsible for determining the
correct Semantic Comparator by analysing the (i) ﬁle
type, (ii) header, and (iii) general structure.
6. In the last step, Sandiff generates the semantic compatible
list, making it available to the Comparator Service and
Web Interface.
In Figures 5 and 6, we summarize the main Build Com-
parator interfaces. We use a client-server architecture for the
current implementation. The browser-based client is written
in JavaScript, HTML5, and Angular. The server is a C++11
template-based implementation that exposes its API for queries
via HTTP, enabling the comparison of Android builds accord-
ing with the source of the artifacts. The architecture supports
the most common integration methods with continuous testing
tools or development pipelines:
• Build Systems: the artifacts are located in continuous
integration and deployment servers, e.g., QuickBuild [21].
• Remote: the artifacts are located in an HTTP server or
the cloud.
• Local: the artifacts are located in the user’s personal
computer.
Figure 6. Interface that summarizes the semantic comparison results.
(A) General statistics of the analysed pair of Android images. (B) List of
semantic relevant artifacts that are supported by Sandiff. (C) Type of each
semantic modiﬁcation (add, remove, edit, type edit).
V.
EXPERIMENTS
A. Semantic Coverage
To verify the comparison performance of Sandiff, we
did experiments between different branches of commercially-
available images of AOSP. The AOSP contains numerous
types of ﬁles (text, audio, video, symbolic links, binary ﬁles,
among others) that can be compared semantically. The exper-
iments consist of comparing the following image pairs:
- Experiment #1: Analysing two major AOSP with minor
revisions: 8.1.0 r64 x 8.1.0 r65.
- Experiment #2: Analysing the last revision of AOSP Oreo
and initial release of AOSP Pie: 8.1.0 r65 x 9.0.0 r1.
- Experiment #3: Analysing the last revision of AOSP Pie
and its initial release: 9.0.0 r1 x 9.0.0 r45.
- Experiment #4: Analysing two major releases of AOSP
Oreo and AOSP 10: 8.1.0 r77 x 10.0.0 r39.
- Experiment #5: Analysing two major releases of AOSP Pie
and AOSP 10: 9.0.0 r57 x 10.0.0 r39.
These pairs were compared using both semantic (Sandiff)
and byte-to-byte (checksum) comparison methods. To demon-
strate the robustness of each method, we analysed the ﬁles con-
tained in system.img, userdata.img and vendor.img
images, which are mounted in the EXT2 ﬁle system under a
UNIX system. Note that, differently from Sandiff, the byte-
to-byte comparison cannot read empty ﬁles and symbolic link
targets. These ﬁles are listed as errors, as shown in Table VIII.
Based on the experiments of Table VIII, we can note that
Sandiff was able to analyze large software projects like the
AOSP. First, the semantic comparison was able to determine
145
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE VIII. OVERALL SUMMARY OF THE IMPACT OF USING SANDIFF IN REAL-WORLD COMMERCIALLY-AVAILABLE AOSP BUILDS.
Comparison
Add
Remove
Edit
Type Edit
Equal
Error
Ignored
Semantic
Binary
Semantic
Binary
Semantic
Binary
Semantic
Binary
Semantic
Binary
Semantic
Binary
Semantic
Binary
Experiment #1
0
0
0
0
11
12
0
0
2185
2165
0
19
0
0
Experiment #2
13
13
27
27
0
0
3
3
0
0
0
0
0
0
Experiment #3
23
23
18
18
527
606
0
0
1929
1805
0
45
0
0
Experiment #4
179
179
41
41
98
97
5
5
153
154
0
0
0
0
Experiment #5
439
439
240
240
839
844
11
11
785
780
0
0
0
0
* Add = ﬁle is present on the second input. Remove = ﬁle is present in the ﬁrst input. Edit = ﬁle is present in both inputs, but the comparison returned differences. Type Edit = ﬁle
is present in both inputs, but there were changes in its metadata (e.g., permissions). Equal = ﬁle is present in both inputs, and the comparison returns an equal status. Error = ﬁle is
present in both inputs, but the comparison returns an error status. Ignored = ﬁle is present in both inputs, but is not semantically relevant, so it was ignored.
the ﬁle type and compare the ﬁle contents and its metadata. In
contrast, a byte-to-byte comparison was unable to compare the
symbolic link’s targets and broken links. Second, the semantic
comparison was able to discard irrelevant differences (e.g.,
the build time in build.prop) which are no differences in
functionality.
Note that, during experiment #2, Sandiff is unable to
perform a full analysis between these trees because there were
structural changes. For instance, in AOSP Oreo, the /bin is a
directory containing many ﬁles. In contrast, in AOSP Pie, the
/bin is now a symbolic link to another directory path (that
can be another image). As a result, Sandiff detects this case
as a Type Edit and does not traverse /bin since it is only a
directory in AOSP Oreo.
The experiment #3 is similar to experiment #1, except that
the number of edited ﬁles is signiﬁcantly more extensive since
the code has changed due to the different revisions. We notice
that errors occur in symbolic links, as expected for byte-to-
byte comparison. Some ﬁles only changed in terms of data,
but not in semantic meaning, making this the optimal scenario
for Sandiff over the traditional checksum.
Both experiments #4 and #5 evaluate at which point the
semantic comparison becomes irrelevant, i.e., they exploit
Sandiff performance when analyzing signiﬁcantly different
AOSP releases. As expected for these scenarios, the results
of both semantic and byte-to-byte comparisons are similar.
In summary, the semantic comparison is inaccurate when
analyzing ﬁles that are not recognized by the rules in the
current implementation of Sandiff, making the byte-to-byte
more appropriate in these cases. Nevertheless, Sandiff is able
to support both semantic and non-semantic tasks, despite run-
time performance disadvantages when compared with naive
solutions.
B. Scalability
To study the behavior of Sandiff when dealing with multi-
threaded AOSP build systems, we performed a scalability
evaluation that measures the run-time performance on different
(i) execution modes, (ii) number of concurrent comparison
jobs, and (iii) AOSP builds. In this experiment, we used a
workstation-based setup with an Intel Core i7-2600 at 3.40GHz
with 16GB of memory, hereafter called Machine #1, and a data
center server with an Intel Xeon E5-2697 at 2.30GHz with
125GB of memory, hereafter called Machine #2.
The execution modes are responsible for deﬁning the
parallel and recursive operations of Sandiff’s Orchestrator, as
deﬁned in Section III. In summary, it manages the strategies
for resource sharing and how comparison results are collected.
Below we list the evaluated modes:
• Walk First: leverages multi-threading by sequentially
analyzing the directories, distributing its ﬁles across the
comparison jobs. It is the default mode of the Sandiff.
• Parallel Walk: performs concurrent directory analysis up
to the number of comparison jobs. It is the recommended
mode for analyzing directories with a large number of
ﬁles.
• Mixed: iterates in both ﬁles and directories.
• Slice: lists all ﬁles before processing, then distributes
them in similar batches across the maximum number of
comparison jobs.
To minimize the variance between runs, we repeated each
experiment four times, as shown in Figures 7 and 8. Note that,
despite different scenarios, Sandiff achieved its best run-time
performance when running with four parallel comparison jobs.
Due to AOSP nature, Sandiff cannot successfully parallelize
the jobs since the tasks are interdependent. In general, Walk
First, Parallel Walk, and Mixed modes tend to attain similar
scalability.
To cope with the variance, we repeated each experiment
four times, as shown in Figures 7 and 8. Note that, despite
different scenarios, run-time performance increases quickly as
the number of jobs grows. Due to the small amount of data in
pure AOSP images - not more than 1900 ﬁles and 800MB - the
orchestration process among multiple jobs creates an overhead
that is not compensated by the parallelization after four parallel
jobs. This limitation is overcome when larger images are used.
To illustrate the scenario where more data is compared, we
run a comparison between two commercially-available builds
based on AOSP having 4847 ﬁles and a total size of 4GB. As
can be seen in Figure 9, parallel comparison stands up when a
higher amount of data is compared. Execution time decreases
as the number of jobs gets closer to the number of physical
cores available on the machine.
In general, Walk First, Parallel Walk, and Mixed modes
tend to attain similar scalability, but Slice mode provided
better performance, relatively and absolutely, when the number
of jobs coincides with the number of available cores of
the machine. This occurs due to the decreased number of
context changes provided by the Slice mode combined with
the maximum usage of available cores.
VI.
CONCLUSION
In this paper, we presented Build Comparator, an integrated
tool for supporting software releases and DevOps operations
146
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Build 8.1.0r64 vs. Build 8.1.0r65
Build 9.0.0r1 vs. Build 9.0.0r45
2
4
6
8
2
4
6
8
9
12
15
Number of Parallel Comparison Jobs
Execution Time (in sec)
Execution Modes
Mixed
Parallel Walk
Slice
Walk First
Workstation Setup
Figure 7. Scalability performance when analysing AOSP builds on
workstation-based setups.
Build 8.1.0r64 vs. Build 8.1.0r65
Build 9.0.0r1 vs. Build 9.0.0r45
0
20
40
60
80
0
20
40
60
80
7.5
10.0
12.5
15.0
Number of Parallel Comparison Jobs
Execution Time (in sec)
Execution Modes
Mixed
Parallel Walk
Slice
Walk First
Data Center Server
Figure 8. Scalability performance when analysing AOSP builds on data
center servers, i.e., dedicated environments for experimenting.
on Android development pipelines by leveraging Sandiff, a
semantic comparator designed to facilitate continuous test-
ing of large software projects, speciﬁcally those related to
AOSP. To the best of our knowledge, Sandiff is the ﬁrst to
allow correlation of test routines of the ofﬁcial Android Test
Suite (VTS) with semantic modiﬁcations in intermediate ﬁles
of AOSP building process. When used to skip time-consuming
test cases or to mount a list of priority tests (fail-fast), Sandiff
can lead to higher productivity of mobile developers. We
showed that semantic comparison is more robust to analyze
large projects than binary comparison since the latter cannot
discard irrelevant modiﬁcations to the target software’s output
or execution. As we reﬁne the semantic comparators of Sandiff,
more AOSP speciﬁc rules will apply, and consequently, more
items can be classiﬁed as ”Equal” in Sandiff’s comparison
reports.
With Build Comparator, we presented and analyzed an
architecture that enables the integration of semantic compari-
son with systems that are commonly used in the development
of AOSP software, exploiting real-world use cases. In the
context of making Sandiff domain agnostic, another avenue
for future work is to explore machine learning techniques
100
150
200
0
20
40
60
80
Number of Parallel Comparison Jobs
Execution Time (in sec)
Execution Modes
Mixed
Parallel Walk
Slice
Walk First
Commercial AOSP
Figure 9. Scalability performance when analysing a large commercial AOSP
build on a data center server.
to detect how tests are related to different ﬁles and formats.
We also plan to extend Build Comparator’s reporting features
by proposing visualizations that highlight relevant semantic
differences between pairs of ﬁles and integrate Sandiff to the
ofﬁcial Android Test Suite (VTS) to validate our intermediate
results.
ACKNOWLEDGMENTS
We thank both Rafael Melo da Silva and Nick Diego
Yamane Pinto for their valuable help during the development
of the project. This work was partially supported by Samsung
Eletrˆonica da Amazˆonia Ltda., under the auspice of the infor-
matics law no 8.387/91.
REFERENCES
[1]
C. E. D. S. Aguiar, J. I. B. V. Filho, A. O. P. Junior, R. J. B.
Fernandes, and C. A. D. L. Pahins, “Sandiff: Semantic ﬁle comparator
for continuous testing of android builds,” VALID 2019 : The Eleventh
International Conference on Advances in System Testing and Validation
Lifecycle, Nov. 2019, pp. 51–55.
[2]
Araxis Ltd. Araxis: Software. [Online]. Available: https://www.araxis.
com/ [retrieved: November, 2020]
[3]
Free Software Foundation, Inc. Diffutils. [Online]. Available: https:
//www.gnu.org/software/diffutils/ [retrieved: October, 2020]
[4]
C. J. Madsen. Vbindiff - visual binary diff. [Online]. Available:
https://www.cjmweb.net/ [retrieved: October, 2020]
[5]
Y. Wang, D. J. DeWitt, and J. Cai, “X-diff: an effective change detec-
tion algorithm for xml documents,” in Proceedings 19th International
Conference on Data Engineering, March 2003, pp. 519–530.
[6]
M. Pawlik and N. Augsten, “Efﬁcient computation of the tree edit
distance,” ACM Transactions on Database Systems, vol. 40, 2015, pp.
3:1–3:40.
[7]
F. Foscarin, F. Jacquemard, and R. Fournier-S’niehotta, “A diff
procedure for music score ﬁles,” in 6th International Conference
on Digital Libraries for Musicology, ser. DLfM ’19.
New York,
NY, USA: Association for Computing Machinery, 2019, pp. 58–64.
[Online]. Available: https://doi.org/10.1145/3358664.3358671
147
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[8]
G. Barabucci, “Difﬁ: Diff improved; a preview,” in Proceedings of the
ACM Symposium on Document Engineering 2018, ser. DocEng ’18.
New York, NY, USA: Association for Computing Machinery, 2018.
[Online]. Available: https://doi.org/10.1145/3209280.3229084
[9]
I.
Sorokin,
“Comparing
ﬁles
using
structural
entropy,”
Journal
in Computer Virology, vol. 7, 2011. [Online]. Available: https:
//doi.org/10.1007/s11416-011-0153-9
[10]
R. M. A. Mohammad and M. Alqahtani, “A comparison of machine
learning techniques for ﬁle system forensics analysis,” Journal of
Information Security and Applications, vol. 46, 2019, pp. 53 –
61. [Online]. Available: http://www.sciencedirect.com/science/article/
pii/S2214212618307579
[11]
D. Rachmawati, J. T. Tarigan, and A. B. C. Ginting, “A comparative
study of message digest 5(MD5) and SHA256 algorithm,” Journal of
Physics: Conference Series, vol. 978, 2018, pp. 1–6.
[12]
G. Leurent and T. Peyrin, “From collisions to chosen-preﬁx collisions
application to full sha-1,” in Annual International Conference on the
Theory and Applications of Cryptographic Techniques. Springer, 2019,
pp. 527–555.
[13]
R. Martino and A. Cilardo, “Sha-2 acceleration meeting the needs of
emerging applications: A comparative survey,” IEEE Access, vol. 8,
2020, pp. 28 415–28 436.
[14]
D. M. A. Cortez, A. M. Sison, and R. P. Medina, “Cryptographic
randomness test of the modiﬁed hashing function of sha256 to address
length extension attack,” in Proceedings of the 2020 8th International
Conference on Communications and Broadband Networking, 2020, pp.
24–28.
[15]
P. M. Simanullang, S. Sinurat, and I. Saputra, “Analisa metode sha384
untuk mendeteksi orisinalitas citra digital,” KOMIK (Konferensi Na-
sional Teknologi Informasi dan Komputer), vol. 3, no. 1, 2019.
[16]
A. Jose and K. Subramaniam, “Dna based sha512-ecc cryptography
and cm-csa based steganography for data security,” Materials Today:
Proceedings, 2020.
[17]
S. Long, “A comparative analysis of the application of hashing encryp-
tion algorithms for MD5, SHA-1, and SHA-512,” Journal of Physics:
Conference Series, vol. 1314, Oct. 2019, p. 012210.
[18]
G. Shaheen, “A robust review of sha: Featuring coherent characteris-
tics,” International Journal of Computer Science and Mobile Computing,
vol. 9, 2020, p. 111–116.
[19]
FreeType Project. Freetype. [Online]. Available: https://www.freetype.
org/freetype2/ [retrieved: November, 2020]
[20]
Apache Software Foundation. C xml parser. [Online]. Available:
https://xerces.apache.org/xerces-c/ [retrieved: October, 2020]
[21]
PMEase. Quickbuild. [Online]. Available: https://www.pmease.com/
[retrieved: October, 2020]
148
International Journal on Advances in Software, vol 13 no 3 & 4, year 2020, http://www.iariajournals.org/software/
2020, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

