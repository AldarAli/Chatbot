Supervised Approach for Indication of Contrast Enhancement
in Application of Image Segmentation
Gabriel F. C. Campos∗ , Rodrigo A. Igawa∗ , Jos´e L. Seixas Jr.∗ , Alex M. G. de Almeida∗ ,
Rodrigo Capobianco Guido† and Sylvio Barbon Jr.∗
∗ Department of Computer Science, State University of Londrina, Brazil
† Department of Computer Science and Statistics, S˜ao Paulo State University, Brazil
Email: camposg@uel.br, igawa.rodrigo@gmail.com, jlseixasjr@gmail.com,
alex.marino@fatecourinhos.edu.br, guido@ieee.org, barbon@uel.br
Abstract—Segmentation methods need a satisfactory input image
with a good contrast between Region of Interest and background
to provide a high accuracy result. Thus, the application of
contrast enhancement before the segmentation is a usual practice.
This paper presents a supervised approach to determine if an
input image is satisfactory for a speciﬁc segmentation approach
by using Feature Extraction, Feature Selection and Machine
Learning. Experimental results showed the proposed approach
ability to indicate the need of contrast enhancement in different
segmentation problems with 94 percent accuracy.
Keywords–Contrast; Image Segmentation; Machine Learning.
I.
INTRODUCTION
Image segmentation is one of the most difﬁcult tasks
in image processing [1] [2] [3]. In order to provide high
accuracy results, segmentation methods need a satisfactory
input image with good contrast between Region of Interest
(ROI) and background. Due to this fact, application of contrast
enhancement before segmentation is an usual practice as shown
in [4] [5] [6] [7] [8].
Some contrast enhancement algorithms, such as CLAHE
[9], rely on input parameters to be performed. This aspect of
contrast enhancement implies that an individual conﬁguration
for each image is necessary. A standard conﬁguration for the
whole image dataset is impractical in a real application.
Undesirable results, such as noise formation, are obtained
in cases where contrast enhancement is used with wrong
parameters or in an originally good contrast image, especially
when using a simple and general contrast enhancement algo-
rithm like Histogram Equalization (HE). Furthermore, execu-
tion time may decrease considerably by removing a useless
contrast enhancement step.
The features of an image provide useful information for
automatic classiﬁcation. In this paper, we explore several
features, like histogram-based [10], gray-level co-occurrence
matrix [11] [12] and Fast Fourier Transform (FFT) [13] [14],
which can retrieve contrast and texture information from an
image. Our proposal is a supervised approach with image
features as input to classify between insufﬁcient and sufﬁcient
images contrast, making it possible to decide if a contrast
enhancement is necessary before the segmentation step, re-
gardless the problem. The appropriate contrast enhancement
step for images with insufﬁcient contrast was not addressed in
this paper.
Works related to our proposal are presented in Section
II, while a detailed description of our proposed approach is
presented in Section III. In Section IV, materials, methods
and experiments used to validate our proposed approach are
described and in Section V, we show results and discussion of
this work. Conclusions are presented in Section VI.
II.
RELATED WORK
A good contrast between ROI and background in an input
image is essential to provide high accuracy segmentation
results. Due to this fact, application of contrast enhancement
before segmentation is a usual practice.
In [15], an enhancement approach is presented to address
the limitations of medical thermal images such as low contrast,
low signal-to-noise ratio, and absence of clear edges. Despite
these limitations which usually make the segmentation process
difﬁcult, the proposed approach using image enhancement
were able to segment the images with an average accuracy
of 98%. Similarly, [16] shows that pre-processing can have
positive impacts on mammographic segmentation since it im-
proves the contrast of tissue structures in uncompressed breast
peripheral areas. Those recent works, and others like [6] and
[8], indicate that contrast enhancement before segmentation
can be useful to improve segmentation accuracy in gray-scale
images.
The CLAHE contrast enhancement algorithm, which relies
on input parameters to be performed, is used to improve
segmentation as well. In [4], CLAHE was used to successfully
improve the accuracy of a fruit segmentation approach. Even
if color images were acquired, CLAHE was applied to the
Intensity channel (gray-scale) and the enhanced image was
segmented by the Hough algorithm. Fixed parameters were
used for CLAHE in this approach.
CLAHE was used again in [5], with the goal of improving
the segmentation in an intelligent iris recognition system for
eye images. Regarding the two main CLAHE parameters, the
clip limit parameter was dynamically chosen by the technique
proposed in [17], while the sub-region size was ﬁxed to 8x8.
The use of ﬁxed parameters to improve a set of images
is not the better solution, since some images may need
more enhancement than others. It is possible as well that
some images do not require any enhancement (which can
be a problem even to contrast enhancement algorithms that
do not need parameters). In a real world dataset, in which
12
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

thousands of images will be segmented, enhancing images that
do not require any enhancement may represent a huge waste
of time depending on the algorithm used. An unnecessary
enhancement can also create noise and decrease segmentation
accuracy. Thus, it is important to know which images must be
enhanced before segmentation.
Some applications use the information contained in mul-
tiple channels of an image to perform segmentation. This
information is usually related to color. Segmentation and
enhancement of color images are not handled in the actual
stage of our work, but the idea of enhancing images to improve
its segmentation can be applied to color images as well. It can
be seen in [7] and [18].
Since features can provide useful information of an image,
they may be used for automatic classiﬁcation. Our proposed
approach uses a supervised classiﬁer based on Machine Learn-
ing to classify images considering its features.
Machine Learning for Image Classiﬁcation is widely used
in Medical applications [19] [20] [21] [22] [23]. In [24], a
survey about Medical image analysis with artiﬁcial neural
networks is presented. It shows that, besides segmentation,
Machine Learning can be useful to classify images and ROI’s,
providing computer-aided detection and diagnosis.
Machine Learning is also used for aerial and satellite
image classiﬁcation [25] [26] [27], image classiﬁcation in
agriculture applications [28], in astronomical applications [29],
image classiﬁcation in palynology [30] and many other image
applications.
Still, contrast enhancement before segmentation can im-
prove accuracy. It may be useful to know which images
must be enhanced before segmentation. By extracting the
right features, it is possible to classify images using machine
learning, which motivates our proposal: a supervised approach
to indicate the need of contrast enhancement in applications
of image segmentation.
III.
PROPOSED APPROACH
Inadequate usage of contrast enhancement leads to wrong
segmentation and misunderstandings concerning ﬁnal results,
since some features like objects intensity, objects size, area of
image occupied by objects and number of different objects are
relevant while applying an automatic segmentation approach.
We propose, as shown in Figure 1, an approach to build a
model capable of identifying images with insufﬁcient contrast
for a speciﬁc segmentation task. The built model is created
based on feature vectors extracted from a small set of image
examples, Image Subset, and it is improved using feature
subset selection, considering a supervised labeling process.
A specialist labels each image of the Image Subset as
insufﬁcient or sufﬁcient, and this, combined with the extracted
features, provide a training set. After performing a feature
subset selection, the training set can be used as input to
the Classiﬁer Training step, as shown in Figure 1. Labels
are applied by visual evaluation from original image and
segmentation result. The Training Set is composed of a subset
of features that optimally represent the focused segmentation
related to the contrast enhancement applied.
In the last step, Supervised Classiﬁer Training, the model
for image classiﬁcation between insufﬁcient or sufﬁcient con-
trast is created.
Figure 1. Proposed Approach
A. Image Features
A histogram is a statistical tool that can be used in contrast
quality assurance and can represent the mean luminosity of
an image. Considering this, we use different metrics from the
histogram associated with Texture (Gray-tone spatial depen-
dencies and Spectral Analysis) with the purpose of covering
distinct image applications.
Texture is an important characteristic used to identify
objects or regions of interest in images. Texture features based
on gray-tone spatial dependencies are easily computable and
have a general applicability for a wide variety of image-
classiﬁcation applications [11]. Gray-level co-occurrence ma-
trices indicate how often a pixel with gray-tone value i occurs
horizontally adjacent to a pixel with value j [12]. On the other
hand, texture features based on Spectral Analysis can detect
global periodicity on images by ﬁnding narrow peaks of high
energy in frequency (spectrum) domain and Fourier transform
is a common spectral method [13] [14].
We selected several features based on Histogram, Gray-
tone spatial dependencies and Image Fourier Domain (shown
in Table I). In Figure 2, it is possible to see features P12, P13,
P14, P15, P16 and P17 in comparison to a standard histogram,
where the x-axis represents gray tones going from 0 to 255 and
the y-axis represents the frequency of each tone in an image.
B. Correlation-based Feature Subset Selection
A central problem in machine learning is identifying a
representative set of features that best represents a model,
increasing precision and reducing dimension. In this paper, we
addressed this problem through a correlation based approach,
where the main hypothesis is that good feature sets contain
features that are highly correlated with the insufﬁcient or
sufﬁcient label, yet uncorrelated with each other [31].
Concretely, a correlation-based approach is an algorithm
which evaluates a great number of features subsets in order to
13
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

TABLE I. IMAGE FEATURES: HISTOGRAM, TEXTURE AND
SPECTRAL
ID
Description
P1
Entropy of original grayscale image
P2
Entropy of gray-level co-occurrence matrix
P3
Inertia of gray-level co-occurrence matrix
P4
Energy of gray-level co-occurrence matrix
P5
Correlation of gray-level co-occurrence matrix
P6
Homogeneity of gray-level co-occurrence matrix
P7
Entropy of FFT
P8
Energy of FFT
P9
Inertia of FFT
P10
Homogeneity of FFT
P11
Image resolution
P12
Amount of non-zeros index
P13
Amount of non-zeros groups
P14
Largest length group
P15
Smallest length group
P16
Peak of Largest length group
P17
Peak of Smallest length group
P18
Amplitude of mean
P19
Amplitude of median
P20
Histogram Variance
P21
Histogram Standard Deviation
0
50
100
150
200
250
Histogram
0
50
100
150
200
250
P12
3
7
16
0
50
100
150
200
250
P13
1
2
3
0
50
100
150
200
250
P14
9
0
50
100
150
200
250
P15
3
0
50
100
150
200
250
P16
0
50
100
150
200
250
P17
Figure 2. Histogram Based Features
obtain a better set of features than the current one. In order
to do so, a correlation-based algorithm is initialized with an
empty set of features. Then, with each round, a new feature
is added to the set and measures like entropy, relief or merit
are used to evaluate how suitable that subset of features has
become. The most usual way to add features to the subset is
by using a best ﬁrst search in a feature space [31].
C. Classiﬁcation
In order to have a suitable approach, which can be used
for different segmentation problems and contrast enhancers, a
supervised classiﬁer based on Machine Learning is required.
This way, it is possible to inform classiﬁers about what feature
can improve ROI segmentation and when the contrast between
the ROI and the background is good enough to a speciﬁc
segmentation process.
Another important characteristic of several Machine Learn-
ing approaches, as Artiﬁcial Neural Networks (ANN), is online
learning [32]. The online learning capacity means that non-
stationary processes, which this might well be, can be modelled
dynamically based on new image samples. Furthermore, the
generalization and scaling feature leads to a model based
on fewer samples [33]. In this paper, ANN were chosen as
Machine Learning classiﬁers, since they are widely used in
classiﬁcation problems [24] [34] [35] [36] [37].
IV.
EXPERIMENTAL SETTINGS
Two datasets were used in experiments. The ﬁrst one
(Dataset I) was composed of medical images, where the ROI
was regarding a wound region. The second dataset (Dataset II)
was composed of pork image samples where the ROI was the
intramuscular fat (marbling).
Note that the datasets represent different real world prob-
lems, speciﬁcally regarding ROI, where size, color and contrast
with the background is really different between both datasets.
Three experiments were conducted in order to validate our
proposed approach.The ﬁrst experiment was performed using
the medical dataset, the second was performed using the pork
dataset and the third experiment was performed by combining
both datasets in order to verify the robustness of the model to
handle two different image scenarios.
The medical images dataset was composed of 100 color
images. All ﬁles were in Portable Network Graphics format
(PNG) and an example image can be seen in Figure 3a.
The complete information about the image acquisition for the
medical images dataset can be found in [38].
The pork images dataset was composed of 300 gray-
scale images containing meat samples (the background was
already removed). All ﬁles were PNG, as well and an example
image can be seen in Figure 4a. The pork images dataset
was acquired using a digital single-lens reﬂex camera and a
tripod that supported the device at 37cm above the sample.
The camera was conﬁgured with automatic settings and had
a 16.2 megapixels image sensor and high quality lens, which
was optimally engineered to gather more light.
All images were segmented by thresholding, where thresh-
old value was found by max entropy algorithm [39]. The
medical images dataset was segmented in the same way as
the pork images dataset, but, in order to obtain a better
visualization in the labeling process, the original image colors
were applied instead of saturation values used in segmentation.
Figure 3 shows the segmentation of images from the
medical dataset. Figures 3a and 3b represent samples labeled as
’sufﬁcient contrast’ while Figures 3c and 3d represent samples
labeled as ’insufﬁcient contrast’.
14
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

(a) Original - Sufﬁcient
(b) Segmented - Sufﬁcient
(c) Original - Insufﬁcient
(d) Segmented - Insufﬁcient
Figure 3. Medical dataset - Segmentation and labeling
Figure 4 shows the segmentation of images from the
pork dataset. Figures 4a and 4b represent samples labeled as
’sufﬁcient contrast’ while Figures 4c and 4d represent samples
labeled as ’insufﬁcient contrast’.
(a) Original - Sufﬁcient
(b) Segmented - Sufﬁcient
(c) Original - Insufﬁcient
(d) Segmented - Insufﬁcient
Figure 4. Pork dataset - Segmentation and labeling
As it can be seen in Figure 3 and Figure 4, the labeling
is simple and easy for such images, so only one specialist
performed the labeling process. Every image that generated
any kind of doubt in the evaluation by the specialist was
removed from the dataset.
Before the labeling process, random samples were removed
to balance both datasets. Thus, we obtained Dataset I Balanced
(Dataset I BA) and Dataset I Imbalanced (Dataset I IM),
as well, Dataset II Balanced (Dataset II BA) and Dataset II
Imbalanced (Dataset II IM). An extra dataset was created by
combining both balanced datasets (Dataset I BA and II BA).
In our experiment, the max entropy algorithm was used to
ﬁnd a threshold value for image segmentation. It is a simple
and fast method, being one of the best solutions to segment
meat marbling [39] [40], which is one of our datasets.
In order to evaluate the generalization power of ANN, we
experimented with two different networks: Multilayer Percep-
tron (MLP) and Radial Basis Function (RBF) [19] [41] [42]
[43] [44]. We evaluated approximately 22 different MLP and
RBF architectures.
Regarding computational complexity, the MLP is O(n2) to
train and O(n) to execute while the RBF is O(n) to both train
and execute [19] [45]. Fortunately, the specialist only needs to
label a small subset of images in order to build the training
set, which makes the model viable to be used in real-world
computer vision problems with huge datasets.
Towards MLPs, the following settings values were used:
learning rate 0.3, momentum 0.2, number of epochs 2500. For
MLP, we experimented with different numbers of perceptrons
on the hidden layers, ranging from 1 to 22. Settings values
towards RBF, on the other hand, were: number of basis
functions ranging from 1 to 22, number of iterations on logistic
regression until convergence and seeds on k-means as defaults.
The results are mostly discussed in terms of accuracy.
However, in special cases, detailed results can be shown in
confusion matrices. As it is known in many cases where super-
vised learning is performed, a confusion matrix is represented
by a simple two dimensional matrix. Rows represent the actual
classes of each instance, in our case contrast sample labeled.
Columns represent the predicted classes, for us: contrast sufﬁ-
cient or insufﬁcient based on the supervised model. This way,
ideal results correspond to large numbers on the main diagonal
and smaller numbers, hopefully zero, for entries off the main
diagonal.
V.
RESULTS AND DISCUSSION
An overview of the results is shown in Table II. The results
of the most accurate architectures are shown for each classiﬁer
in each dataset. The results regarding feature selection are also
presented.
We ﬁrst discuss feature selection relevance. As it is pos-
sible to note, feature selection matters not only to increase
performance by dimensional reduction, but also to help with
accuracy. This importance is shown in Table II, where column
AF Acc (All Features Accuracy) always presented lower
results than column SF Acc (Selected Features Accuracy).
In general, as shown in the lower part of Table II, feature
selection added an average 6.04% accuracy. There is only one
case where using feature selection did not improve classiﬁer
accuracy, which is RBF in Dataset II IM. Details considering
this special case are properly discussed in Section V-B.
Considering classiﬁers, it is also possible to realize that the
best results from MLP were always higher than the best results
from RBF. Details concerning accuracies are shown in Figure
5 and discussed in Section V-B.
A. Feature Selection
Towards selected features, Table III shows results consid-
ering all datasets. As it can be seen in the second column
15
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

TABLE II. ACCURACIES OF CLASSIFIERS WITH ALL AND SUBSET
FEATURES
Dataset
ANN
AF Acc
SF Acc
Diff.
I IM
MLP
87.21%
88.72%
1.51%
RBF
81.11%
82.20%
1.09%
I BA
MLP
86.13%
91.08%
4.95%
RBF
67.32%
80.19%
12.87%
I & II BA
MLP
87.06%
89.55%
2.49%
RBF
72.13%
82.58%
10.45%
II IM
MLP
83.66%
84.66%
1.00%
RBF
83.33%
83.33%
0.00%
II BA
MLP
88.00%
94.00%
6.00%
RBF
70.00%
90.00%
20.00%
Mean Diff.
6.04%
(quantity of features selected), dimensionality reduction was
signiﬁcant. In the particular case of Dataset II IM, it was
possible to reduce the number of features from 22 to just
4. In another case, as seen for Dataset I BA, dimensionality
reduction was less expressive, but still, reduced from 22 to just
9 features.
In summary, the features selected for each dataset varied.
No feature was present in all cases after feature selection. The
most used feature was P12 but this feature was not present in
Dataset II BA feature selection.
TABLE III. SUB-SELECTED FEATURES IN EACH EXPERIMENT
DataSet
Quantity
Features Subset
I IM
7
P12, P14, P17, P3, P4, P8 and P7
I BA
9
P1, P12, P14, P17, P2, P3, P4, P6 and P8
I & II BA
5
P1, P12, P13, P2 and P3
II IM
4
P12, P13, P17 and P2
II BA
6
P11, P16, P17, P18, P21 and P9
B. Classiﬁers
Regarding classiﬁers, Figure 5 shows box-plots for both
MLP and RBF on each dataset when using feature selection.
MLP, plotted as blue box-plots, shows much greater accuracy
than RBF in all ﬁve datasets. Although MLP presented lower
outliers in some cases, they were still better than the RBF
results. This fact is notable on Dataset I IM and Dataset I & II
BA where the lowest results from MLP are still higher than the
median results from RBF. Another outstanding result achieved
by MLP on experiments is the difference from third quartile
and the ﬁrst quartile in all datasets. In practice, this is shown
on the smaller box size from MLP plots which results in a
very stable classiﬁer on experiments.
Considering balanced and imbalanced instances, it is also
possible to realize that MLP achieved higher results when the
dataset is balanced, as seen from Dataset I BA to Dataset
I IM and from Dataset II BA to Dataset II IM. However,
this is not the case for RBF. Actually, on Dataset I IM, RBF
achieved better results than in Dataset I BA, where instances
are balanced.
A third situation is shown by results on Dataset I & II BA,
a situation where both scenarios are tested at once. This time,
MLP also performed better than RBF regarding stability and
higher accuracy results. Considering stability, MLP presented
only one outlier, while RBF presented several. Considering
higher accuracy results, the entire box from MLP is plotted
above the best results from RBF.
Datasets and ANN
Dataset I IM
Dataset I BA
Dataset I & II BA
Dataset II BA
Dataset II IM
Accuracy (%)
45
50
55
60
65
70
75
80
85
90
95
MLP
RBF
Figure 5. Boxplot of MLP and RBF accuracies
TABLE IV. CONFUSION MATRIX OF DATASET II IM PERFORMED
BY RBF
Predicted
Sufﬁcient
Insufﬁcient
Total
Actual
Sufﬁcient
250
0
250
Insufﬁcient
50
0
50
Total
300
0
300
TABLE V. CONFUSION MATRIX OF DATASET II BA PERFORMED BY
MLP
Predicted
Sufﬁcient
Insufﬁcient
Total
Actual
Sufﬁcient
46
4
50
Insufﬁcient
2
48
50
Total
48
52
100
A special case is shown in the case of Dataset II IM,
where RBF seemed stable by presenting a very small box.
However, it is not a true sign of success. As shown in Table IV,
the results imply that, actually, the classiﬁer presented a very
high rate of error. Therefore, in different datasets and different
ways of evaluation, MLP presented more desirable results
than RBF. In order to show that results in other cases were
satisfactory in terms of generalization, we show the prediction
results to another classiﬁer on Dataset II BA. Table V shows
predictions with settings which achieved 94% accuracy to
classify instances.
VI.
CONCLUSION
In this paper, we proposed a supervised approach able to in-
dicate the need of contrast enhancement in images, speciﬁcally
before segmentation process. Experimental results showed
high accuracy when dealing with two different datasets, es-
pecially when using feature selection and MLP classiﬁer. As
well, it exposed some features that best represent contrast in
digital images.
The proposed approach can be used in computer vision sys-
tems that can afford a segmentation step, avoiding undesirable
noise and wasted time by an incorrect or useless application
of a contrast enhancement method.
Addressing feature discussions, dimensional reduction was
an important issue on our approach in terms of performance.
As discussed in Section V-A, in a particular case, feature
selection enabled reduction from 22 to only 4 features.
ANN accuracy was also discussed and experiments showed
that, mostly, MLP performed better than RBF in terms of maxi-
16
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

mum accuracy, outliers values and stability. Details concerning
such issue were presented in Section V-B. Still, RBF presented
a very peculiar case in which no generalization was performed
correctly, as seen in Table IV.
In summary, supervised learning approach for indication of
contrast enhancement in image segmentation was successfully
achieved. Different datasets were tested and 94% accuracy was
achieved in a case where different datasets were tested at the
same time. The proposed approach performed well not only
when the dataset consisted of a single scenario, but also when
the dataset consisted of different image scenarios.
As future work, we will employ contrast enhancement
approach in order to observe the behavior of the classiﬁer
and analyze if the model will be able to handle the adjusted
contrast. We also intend to use color information as features
besides segmenting the images with more complex algorithms,
e. g. watershed and decision trees.
ACKNOWLEDGMENT
The authors would like to thank CAPES (Brazilian Agency)
for ﬁnancial support.
REFERENCES
[1]
R. C. Gonzalez and R. E. Woods, Processamento Digital De Imagens.
Addison Wesley Bra, 2010.
[2]
T. Sag and M. C¸ unka, “Color image segmentation based on multi-
objective artiﬁcial bee colony optimization,” Applied Soft Computing,
vol. 34, no. 0, 2015, pp. 389 – 401.
[3]
W. Shi, R. Zou, F. Wang, and L. Su, “A new image segmentation method
based on multifractal detrended moving average analysis,” Physica A:
Statistical Mechanics and its Applications, vol. 432, no. 0, 2015, pp.
197 – 205.
[4]
E. A. Murillo-Bracamontes et al., “Implementation of hough transform
for fruit image segmentation,” Procedia Engineering, vol. 35, no. 0,
2012, pp. 230 – 239, international Meeting of Electrical Engineering
Research 2012.
[5]
A. F. M. Raffei, H. Asmuni, R. Hassan, and R. M. Othman, “A
low lighting or contrast ratio visible iris recognition using iso-contrast
limited adaptive histogram equalization,” Knowledge-Based Systems,
vol. 74, no. 0, 2015, pp. 40 – 48.
[6]
L.-C. Chen, C.-H. Chien, and X.-L. Nguyen, “An effective image
segmentation method for noisy low-contrast unbalanced background in
mura defects using balanced discrete-cosine-transfer (bdct),” Precision
Engineering, vol. 37, no. 2, 2013, pp. 336 – 344.
[7]
G. Schaefer, M. I. Rajab, M. E. Celebi, and H. Iyatomi, “Colour
and contrast enhancement for improved skin lesion segmentation,”
Computerized Medical Imaging and Graphics, vol. 35, no. 2, 2011,
pp. 99 – 104, advances in Skin Cancer Image Analysis.
[8]
N. Al-Najdawi, M. Biltawi, and S. Tedmori, “Mammogram image
visual enhancement, mass segmentation and classiﬁcation,” Applied
Soft Computing, vol. 35, no. 0, 2015, pp. 175 – 185.
[9]
K. Zuiderveld, “Graphics gems iv,” P. S. Heckbert, Ed. San Diego, CA,
USA: Academic Press Professional, Inc., 1994, ch. Contrast Limited
Adaptive Histogram Equalization, pp. 474–485.
[10]
G. Balaji, T. Subashini, and N. Chidambaram, “Automatic classiﬁcation
of cardiac views in echocardiogram using histogram and statistical
features,” Procedia Computer Science, vol. 46, no. 0, 2015, pp. 1569 –
1576, proceedings of the International Conference on Information and
Communication Technologies, {ICICT} 2014, 3-5 December 2014 at
Bolgatty Palace amp; Island Resort, Kochi, India.
[11]
R. Haralick, K. Shanmugam, and I. Dinstein, “Textural features for im-
age classiﬁcation,” Systems, Man and Cybernetics, IEEE Transactions
on, vol. SMC-3, no. 6, Nov 1973, pp. 610–621.
[12]
S. Chowdhury, B. Verma, and D. Stockwell, “A novel texture feature
based multiple classiﬁer technique for roadside vegetation classiﬁca-
tion,” Expert Systems with Applications, vol. 42, no. 12, 2015, pp.
5047 – 5055.
[13]
H.-K. Shen, P.-H. Chen, and L.-M. Chang, “Automated steel bridge
coating rust defect recognition method based on color and texture
feature,” Automation in Construction, vol. 31, no. 0, 2013, pp. 338
– 356.
[14]
M. Nixon and A. Aguado, Feature Extraction and Image Processing,
ser. Electronics & Electrical.
Newnes, 2002.
[15]
S. Suganthi and S. Ramakrishnan, “Anisotropic diffusion ﬁlter based
edge enhancement for segmentation of breast thermogram using level
sets,” Biomedical Signal Processing and Control, vol. 10, 2014, pp. 128
– 136.
[16]
W. He, P. Hogg, A. Juette, E. R. Denton, and R. Zwiggelaar, “Breast im-
age pre-processing for mammographic tissue segmentation,” Computers
in Biology and Medicine, vol. 67, 2015, pp. 61 – 73.
[17]
B. S. Min, D. K. Lim, S. J. Kim, and J. H. Lee, “A novel method of
determining parameters of clahe based on image entropy,” International
Journal of Software Engineering and Its Applications, vol. 7, no. 5,
2013, pp. 113–120.
[18]
A.
Aimi
Salihah,
M.
Mashor,
N.
Harun,
A.
Abdullah,
and
H. Rosline, “Improving colour image segmentation on acute myel-
ogenous leukaemia images using contrast enhancement techniques,” in
Biomedical Engineering and Sciences (IECBES), 2010 IEEE EMBS
Conference on, Nov 2010, pp. 246–251.
[19]
J. Seixas, S. Barbon, and R. Gomes Mantovani, “Pattern recognition
of lower member skin ulcers in medical images with machine learning
algorithms,” in Computer-Based Medical Systems (CBMS), 2015 IEEE
28th International Symposium on, June 2015, pp. 50–53.
[20]
B. Ashinsky et al., “Machine learning classiﬁcation of oarsi-scored
human articular cartilage using magnetic resonance imaging,” Os-
teoarthritis and Cartilage, vol. 23, no. 10, 2015, pp. 1704 – 1712.
[21]
A. Gertych et al., “Machine learning approaches to analyze histological
images of tissues from radical prostatectomies,” Computerized Medical
Imaging and Graphics, vol. 46, Part 2, 2015, pp. 197 – 208, information
Technologies in Biomedicine.
[22]
S. Yu, K. K. Tan, B. L. Sng, S. Li, and A. T. H. Sia, “Lumbar
ultrasound image feature extraction and classiﬁcation with support
vector machine,” Ultrasound in Medicine
Biology, vol. 41, no. 10,
2015, pp. 2677 – 2689.
[23]
H. Joutsijoki, M. Haponen, I. Baldin, J. Rasku, Y. Gizatdinova, M. Paci,
J. Hyttinen, K. Aalto-Setala, and M. Juhola, “Histogram-based clas-
siﬁcation of ipsc colony images using machine learning methods,”
in Systems, Man and Cybernetics (SMC), 2014 IEEE International
Conference on, Oct 2014, pp. 2611–2617.
[24]
J. Jiang, P. Trundle, and J. Ren, “Medical image analysis with artiﬁcial
neural networks,” Computerized Medical Imaging and Graphics, vol. 34,
no. 8, 2010, pp. 617 – 631.
[25]
S. Manthira Moorthi, I. Misra, R. Kaur, N. Darji, and R. Ramakrishnan,
“Kernel based learning approach for satellite image classiﬁcation using
support vector machine,” in Recent Advances in Intelligent Computa-
tional Systems (RAICS), 2011 IEEE, Sept 2011, pp. 107–110.
[26]
G. Yan and S. Fenzhen, “Study on machine learning classiﬁcations
based on oli images,” in Mechatronic Sciences, Electric Engineering
and Computer (MEC), Proceedings 2013 International Conference on,
Dec 2013, pp. 1472–1476.
[27]
P. Jordhana and K. Soundararajan, “Kernel methods and machine
learning techniques for man-made object classiﬁcation in sar images,”
in Information Communication and Embedded Systems (ICICES), 2014
International Conference on, Feb 2014, pp. 1–6.
[28]
S. Mulyono, T. Pianto, M. Fanany, and T. Basaruddin, “An ensemble
incremental approach of extreme learning machine (elm) for paddy
growth stages classiﬁcation using modis remote sensing images,” in
Advanced Computer Science and Information Systems (ICACSIS),
2013 International Conference on, Sept 2013, pp. 309–314.
[29]
M. Abd Elfattah, N. Elbendary, H. Elminir, M. Abu El-Soud, and
A. Hassanien, “Galaxies image classiﬁcation using empirical mode
decomposition and machine learning techniques,” in Engineering and
Technology (ICET), 2014 International Conference on, April 2014, pp.
1–5.
[30]
M. Popescu and L. Sasu, “Feature extraction, feature selection and ma-
chine learning for image classiﬁcation: A case study,” in Optimization
17
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

of Electrical and Electronic Equipment (OPTIM), 2014 International
Conference on, May 2014, pp. 968–973.
[31]
M. A. Hall, “Correlation-based feature selection for machine learning,”
Tech. Rep., 1999.
[32]
U. Seiffert, “Annieartiﬁcial neural network-based image encoder,” Neu-
rocomputing, vol. 125, 2014, pp. 229–235.
[33]
I. Basheer and M. Hajmeer, “Artiﬁcial neural networks: fundamentals,
computing, design, and application,” Journal of microbiological meth-
ods, vol. 43, no. 1, 2000, pp. 3–31.
[34]
O.-R. Manuel, M.-B. del Rosario, G. Eduardo, and V.-C. Rene, “Arti-
ﬁcial neural networks modeling evolved genetically, a new approach
applied in neutron spectrometry and dosimetry research areas,” in
Electronics, Robotics and Automotive Mechanics Conference, 2008.
CERMA ’08, Sept 2008, pp. 387–392.
[35]
X. Li and X. Yu, “Inﬂuence of sample size on prediction of animal
phenotype value using back-propagation artiﬁcial neural network with
variable hidden neurons,” in Computational Intelligence and Software
Engineering, 2009. CiSE 2009. International Conference on, Dec 2009,
pp. 1–4.
[36]
V. Shahpazov, V. Velev, and L. Doukovska, “Design and application of
artiﬁcial neural networks for predicting the values of indexes on the
bulgarian stock market,” in Signal Processing Symposium (SPS), 2013,
June 2013, pp. 1–6.
[37]
R. Venkatesan and B. Balamurugan, “A real-time hardware fault de-
tector using an artiﬁcial neural network for distance protection,” Power
Delivery, IEEE Transactions on, vol. 16, no. 1, Jan 2001, pp. 75–82.
[38]
J. Seixas et al., “Color energy as a seed descriptor for image segmenta-
tion with region growing algorithms on skin wound images,” in e-Health
Networking, Applications and Services (Healthcom), 2014 IEEE 16th
International Conference on, Oct 2014, pp. 387–392.
[39]
J. Kapur, P. Sahoo, and A. Wong, “A new method for gray-level picture
thresholding using the entropy of the histogram,” Computer Vision,
Graphics, and Image Processing, vol. 29, no. 3, 1985, pp. 273 – 285.
[40]
K. Chen and C. Qin, “Segmentation of beef marbling based on vision
threshold,” Computers and Electronics in Agriculture, vol. 62, no. 2,
2008, pp. 223–230.
[41]
M. Bagheri, S. Mirbagheri, M. Ehteshami, and Z. Bagheri, “Modeling of
a sequencing batch reactor treating municipal wastewater using multi-
layer perceptron and radial basis function artiﬁcial neural networks,”
Process Safety and Environmental Protection, vol. 93, 2015, pp. 111 –
123.
[42]
L. Cakir and N. Yilmaz, “Polynomials, radial basis functions and mul-
tilayer perceptron neural network methods in local geoid determination
with gps/levelling,” Measurement, vol. 57, 2014, pp. 148 – 153.
[43]
R. Velo, P. Lpez, and F. Maseda, “Wind speed estimation using
multilayer perceptron,” Energy Conversion and Management, vol. 81,
2014, pp. 1 – 9.
[44]
Z. Ramedani, M. Omid, A. Keyhani, S. Shamshirband, and B. Khosh-
nevisan, “Potential of radial basis function based support vector regres-
sion for global solar radiation prediction,” Renewable and Sustainable
Energy Reviews, vol. 39, 2014, pp. 1005 – 1011.
[45]
S. Haykin, Neural Networks: A Comprehensive Foundation.
Prentice
Hall, 1999.
18
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-452-7
MMEDIA 2016 : The Eighth International Conferences on Advances in Multimedia

