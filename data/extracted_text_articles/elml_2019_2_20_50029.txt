 
Software System for Automatic Creation of Operation Manuals for Real-Time Use 
by Students During Lectures 
Naoki Morita 
Graduate School of Information and  
Telecommunication Engineering 
Tokai University 
Tokyo, Japan 
e-mail: morita@tokai.ac.jp 
Kenta Morita 
Graduate School of Engineering 
Mie University 
Mie, Japan 
e-mail: k-morita@ip.elec.mie-u.ac.jp 
 
 
Abstract – Recently, classes in which students use their 
own Personal Computers (PCs) to follow lecture 
instructions are becoming increasingly commonplace. 
However, in situations where students are unable to fully 
understand a portion of an ongoing lecture or have 
missed portions of the instructor’s explanation due to 
late arrival, it is unlikely that they will be able to catch 
up with and track ongoing explanations and/or perform 
operations in tandem with the instructor. However, it is 
also burdensome for the instructors that have prepared 
such classroom materials to alter their lessons to 
accommodate students who are late or having difficulties. 
Accordingly, we developed a system that automatically 
creates operation manuals for real-time use by students 
during lectures and confirmed that students who were 
late for classes in which it was used could recover from 
such delays on their own. 
Keywords 
- 
Operation 
manual; 
Automatic 
creation; 
Computer-assisted instructions; Global hook 
I. 
 MOTIVATION 
Recently, classes in which students use their own 
Personal Computers (PCs) to learn how to use applications, 
such as Microsoft Word or Excel, or to practice 
programming 
techniques, 
have 
become 
increasingly 
commonplace. In such classes, the instructor projects their 
desktop display onto a screen that is used to demonstrate 
how the software is used and to show students how to 
perform operations. 
Normally, the screen changes that result from the 
instructor’s actions are explained just before a new window 
appears, and the instructor typically clarifies what s/he 
intends to do by highlighting the operation target with the 
mouse cursor. However, not all students are always able to 
hear and understand the instructor's explanations and 
students who lose track of an operation in progress will be 
unable to perform that operation independently.  
In an earlier study, Bandoh et al. developed a system that 
uses two screens, one displaying the state before an operation 
and the other displaying the expected result [1]. This system 
allows students to recognize the before and after conditions 
for an operation at a glance. However, the problem with this 
system is that explanations regarding the corresponding 
operation are limited, and the system only displays the most 
current operations. Hence, students whose understanding of 
the operations is incomplete will be unable to follow the 
entire demonstration. Additionally, students will be unable to 
review the operation after the lecture. 
In another study, Itamiya et al. developed a lecture 
recording system that can superimpose blackboard-writing 
and images from the lecturer’s PC screen on the student’s 
device in real time using a video camera [2]. However, since 
the required operations are performed during the lesson 
while explanations are provided, long intervals tend to occur 
between operations and the efforts required to confirm 
student comprehension levels may be inappropriate during 
lectures. 
Furthermore, students who are late to attending the 
instructor's demonstration need the ability to rapidly 
configure their devices to the same state as the lecturer's PC, 
which means that they have to compensate for the lack 
instructions regarding the operations they missed. To address 
such issues, the creation of an instruction manual would be 
very desirable. The use of manual creation software [3][4], 
makes it possible for instructors to reduce the labor involved 
when creating lecture materials to a certain extent, but it 
remains very time consuming to create such detailed 
manuals. 
In this paper, we discuss the process of creating lecture 
materials without requiring additional labor in Section II. 
Section III explains our newly developed system, and 
Section IV summarizes our work. 
II. 
CONCEPT 
The ultimate goal of our research is to enable all students 
to operate their PCs in tandem with their instructor's 
operations and provide a way for students who do not fully 
understand previous operations, or who have arrived at the 
lecture late, to compensate for their incomplete knowledge. 
However, as noted above, it is usually very time consuming 
for instructors to create such detailed manuals. 
The purpose of this research is to provide a system that 
creates an operation manual of an ongoing lecture for student 
use without requiring any special work on the part of the 
lecturer. To accomplish this, it is necessary to provide a 
method by which they can quickly grasp the operation target 
and perform any required operations they have missed or do 
not understand. However, since this must be done while the 
36
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-689-7
eLmL 2019 : The Eleventh International Conference on Mobile, Hybrid, and On-line Learning

 
lecture is in progress, students must first complete those 
missed operations and advance their screens to match the 
instructor's PC in the shortest period of time possible.  
Our newly developed system creates a screenshot of the 
instructor's PC at each operation change, that students can 
watch as a slideshow. More specifically, first the system 
creates a screenshot of the instructor's PC window just before 
an operation. Second, based on the operation of the active 
window, it extracts the operation target. Third, the system 
highlights the targeted operation on the captured image and 
inserts a text explanation of how the operation is performed 
(such as via a left mouse click). Finally, the edited image 
capture is sent to a Web server. 
Since each of these tasks is performed in real-time every 
time the instructor performs an operation, students who are 
late or unable to attend the lecture, or who need help 
understanding the processes involved, can review the entire 
process on the Web server. 
III. 
DEVELOPED SYSTEM 
The system developed in this study consists of an 
operation log storage module on the instructor’s PC and an 
operation log publish module on the Web server. In the 
subsections below, we will explain these modules, the results 
used in the class, and then discuss the system. 
A. Storage Module 
This module runs on the Windows 10 Operating System 
(OS). 
During operation, 
the instructor’s application 
constantly exchanges messages with the OS regarding 
keyboard and mouse input operations. Our system monitors 
these messages using Global Hook technology and extracts 
all WM_LBUTTONDOWN messages (left mouse button 
clicks), WM_RBUTTONDOWN messages (right mouse 
button clicks), WM_KEYDOWN messages (press any key 
operations), and WM_MENUSELECT messages for the 
active window. As a result, all of the required information is 
extracted without the need for any special operations other 
than the instructor's demonstration.  
Figures 1(a) to 1(f) show the captured screen images 
created by this module when using Windows Notepad while 
our system is active. Figures 1(a) and 1(f) were created by 
analyzing the form of the WM_LBUTTONDOWN message, 
Figures 1(b) and 1(e) were created by analyzing the form of 
the WM_KEYDOWN messages, and Figures 1(c) and 1(d) 
were 
created 
by 
analyzing 
the 
form 
of 
the 
WM_MENUSELECT messages. 
In these images, the target window or object is 
highlighted, and the click position is displayed by the cursor 
image if the operation is a mouse action. 
B. Publish Module 
This module runs on a Web server. On the top page, all 
the images sent from the storage module are displayed as 
thumbnails. To switch to the slideshow mode, the user 
simply clicks on one of the thumbnails. In the slideshow 
mode, there are backward and forward link buttons that 
permit users to navigate between images. In the highlighted 
part of the operation target, users can immediately identify 
the changed parts. The cursor image and the operation 
annotations allow the user to identify the targeted operations.  
C. Result 
We conducted an experiment at a lecture to develop an 
Android application using the Eclipse development 
environment. In this lesson, the operations performed by a 
student to create a project (primarily mouse clicks), the 
operations used to create an Android Window (primarily 
click and drag) and the programming instructions (primarily 
keyboard input) were extracted for use. 
Using our system, six students who were late for the 
lecture reviewed the missed portions of the lesson and 
attempted to catch up with the instructor’s ongoing 
explanation. All of these students completed these missed 
operations, and were able to operate their PCs in tandem 
with their instructor's operations. 
D. Discussion 
When the pace of the instructor's explanation increases, 
the number of students who will be unable to follow the 
operations also increases. In this class, the instructor paced 
the lecture while periodically checking to ensure that all the 
students completed the operations in tandem with the 
presentation. To confirm the operations of students, we 
recorded the operation process. Checking the operations 
performed by students after the lecture, we found that a few 
students could not smoothly perform the drag operations. 
More specifically, even though the students observed the 
screen captures and identified the target object, they could 
not identify the drag destination from the screen capture, and 
had to click the forward link displayed by the Web browser 
to obtain that information.  
However, once they became familiar with the system, the 
students realized they could quickly click forward to the next 
image to determine the drag destination, and then click back 
to the image displaying the mouse drag operation itself. 
Next, we will discuss the times taken for the operation. In 
the lecture, since explanations are given as the operations are 
performed, the process takes longer than simply performing 
the actual operations. However, since there is no waiting 
time for students who perform operations while observing 
the operation manual created by the system, there were 
situations where some students finished the required 
operations more quickly than the students that simply 
listened to the lecture. 
IV. 
CONCLUSION 
In this paper, we report on a newly developed system that 
automatically creates an operation manual based on 
instructor PC operations that students can watch in real time 
during lectures, and which can be quickly reviewed by late 
arriving students. Using our system, the students who were 
late for the lecture reviewed the missed portions of the lesson 
and attempted to catch up with the instructor’s ongoing 
explanation. All students successfully completed these 
missed operations, and were able to operate their PCs in 
tandem with their instructor's operations. 
37
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-689-7
eLmL 2019 : The Eleventh International Conference on Mobile, Hybrid, and On-line Learning

 
However, since the experiment described in this paper 
involved only a limited number of subjects and student 
participants, it will be necessary to apply the system to 
additional classes with larger numbers of participating 
students in future studies in order to more fully confirm its 
effectiveness. 
ACKNOWLEDGMENT 
This work was supported by the Japan Society for the 
Promotion of Science (JSPS) KAKENHI Grant Number 
16K16324. 
 
 
 
 
REFERENCES 
[1] H. Bandoh, Y. Otsuki, and S. Sawada, "Prototyping of an 
educational supporting tool to ease instruction of software 
operation; automatic display of operation process and result," 
IPSJ SIG Technical Report, pp.1-8, 2003. 
[2] T. Itamiya, K Tagawa, and H. Chiyokura, "Development of 
the Lecture recording system for Superimposing a Blackboard 
Writing and Lecturer's image on the Lecturer's PC Screen," 
Japan Society for Educational Technology, pp.119–128, 2011. 
[3] "Click! 
Recorder," 
2014, 
[Online] 
Available 
from: 
http://www.gluesoft.co.jp/en/ClickRec2 [accessed December 
2018] 
[4] "iTutor," 2018, [Online] Available from: https://itutor.jp/ 
[accessed December 2018] 
 
 
38
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-689-7
eLmL 2019 : The Eleventh International Conference on Mobile, Hybrid, and On-line Learning

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(a)                                                                                                                (b) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(c)                                                                                                                (d) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 (e)                                                                                                                (f) 
Figure 1.  Sample images created by our system based on instructor operation. 
39
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-689-7
eLmL 2019 : The Eleventh International Conference on Mobile, Hybrid, and On-line Learning

