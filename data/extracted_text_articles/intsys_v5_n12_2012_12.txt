Concept, Design and Evaluation of 
Cognitive Task-based UAV Guidance 
Johann Uhrmann & Axel Schulte 
Institute of Flight Systems 
Universität der Bundeswehr München 
Munich, GERMANY 
{johann.uhrmann|axel.schulte}@unibw.de 
 
Abstract—This 
paper 
discusses 
various 
aspects 
of 
automation for the integration of multiple, detached, 
unmanned sensor platforms into a military helicopter 
scenario. The considered scenario incorporates operating 
over unknown, potentially unsafe terrain including ad-hoc 
mission orders issued to the crew even during flight. 
Unmanned sensor platforms provide mission-relevant real-
time reconnaissance and surveillance information to the 
crew and therefore lead to an increase in mission 
performance. To achieve this, the UAVs (Uninhabited Aerial 
Vehicles) shall be automated beyond the level of commonly 
used systems, i.e., autopilots and waypoint guidance. Instead 
the human operator shall be enabled to transfer authority to 
the unmanned platforms in a well-defined manner just like 
in tasking human subordinates. Automatic task execution is 
achieved by installing knowledge-based and goal-driven 
agents based on artificial cognition on the unmanned 
platforms for planning and decision-making. These agents 
allow the human operator to assign tasks to the UAVs on an 
abstraction level which is comparable to the supervision of 
human subordinates within a mission. This paper presents 
the concept and design of such artificial cognitive agents. A 
novel views on levels of automation will be discussed. The 
required knowledge driving the cognitive automation will be 
explained and the results of the evaluation of the system with 
subject matter experts will be discussed. The results, which 
include measures of the overall mission performance, 
operators’ interaction, behaviour, workload, situation 
awareness and acceptance ratings, indicate that task-based 
UAV guidance is feasible, accepted and beneficial in military 
helicopter operations. 
Keywords - task-based guidance; goal-driven behaviour; 
artificial cognititive units; artificial cognition; level of 
automation 
I. 
 INTRODUCTION 
The utilization of UAVs (Uninhabited Aerial Vehicles) 
as detached sensor platforms of a manned helicopter in a 
military scenario promises to enhance mission safety and 
effectiveness by allowing the crew to deploy sensors in 
dynamic and uncertain environments without exposing 
personnel to potential threats more than needed. Using 
unmanned vehicles for this purpose requires a change in 
the UAV guidance paradigm that enables a single human 
operator to control one or even multiple UAVs while being 
the commander of a manned aircraft. If those detached 
platforms were controlled by humans, a commander would 
just assign tasks referring to the mission context and the 
current situation and leave the details of task execution as 
well as the application of domain knowledge generating 
local tactical behaviours to the human subordinate. A way 
to incorporate this leadership concept in the guidance of 
uninhabited vehicles using such knowledge in a machine 
agent and the evaluation of a corresponding experimental 
system are first time described in [1]. A final evaluation 
experiment as described in [1] took place in May 2011. 
This paper extends the findings provided by [1] and 
describes the overall concept of task-based guidance, the 
system architecture, the knowledge base and the evaluation 
in more detail. 
 
 
Figure 1.  Helicopter simulator of the Institute of Flight Systems  
Some current research approaches concerning UAV 
guidance allow the definition of scripts or plays [2] to 
define action sequences for one or multiple UAVs. 
Moreover, some of these systems also react to changes in 
the situation like a new threat along a flight route [3]. 
However, the resulting behaviours of these systems are 
solely defined at design-time. The underlying goals of the 
UAVs are not explicitly expressed in the system but are 
implicitly encoded in the implementation of the 
behaviours. With implicit goals, the system “simply makes 
guesses – statistically plausible guesses based on the 
designer’s observations and hunches.” [4]. This paper 
describes the system architecture that avoids most of the 
“guessing” by the application of knowledge and goals 
driving task-based, cooperative and cognitive UAV 
automation. Furthermore, various metrics that can be 
applied to automation of UAVs are presented. The 
resulting type of supervisory control shall avoid at least 
some of the issues of conventional automation by taking a 
step towards human-centred automation [5]. The resulting 
laboratory prototype has been integrated in the helicopter 
research flight simulator of the Institute of Flight Systems 
at the Universität der Bundeswehr München, which is 
shown in Figure 1, and evaluated in experiments with 
experienced German Army aviators. In these experiments, 
the pilots had to perform several, dynamic troop transport 
missions including an unscheduled combat recovery task 
Virtual Pilot View
Commander /
UAV Operator
Pilot flying
UAV displays / 
controls
H/C displays / controls
145
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

with the support of the manned helicopter and three 
tactical UAVs. 
The following sections present related work in the field 
of UAV guidance and the concepts behind the task-based 
guidance approach in general as well as its application to 
UAVs. Section IV illustrates different measures of 
automation in the domain of unmanned vehicles. Section V 
presents the system architecture of a simulation prototype 
including a short introduction into the concept of artificial 
cognitive units (ACUs) and a description of the knowledge 
base of a UAV. Finally, Section VI contains the 
description, measures and results of an experimental 
evaluation of the concept of task-based guidance. 
II. 
RELATED WORK 
Most current research projects in the area of UAV 
guidance and mission management focus on solving 
problems in the field of trajectory generation [6] and 
management and the achievement of what is mostly 
referred to as “full autonomy” by the application of control 
algorithms [7]. 
This research concentrates on optimizing mission 
effectiveness, e.g., time or fuel consumption, within a 
given constraint set. However, such constraint sets and 
parameters are either static or the definition is left to the 
human operator or the experimenter. If the handling and 
monitoring of the control algorithms of multiple UAV is 
allocated to the commander of a manned helicopter, then 
the result is error-prone behaviour and high workload for 
the operator [8, 9]. Therefore, we present a system that 
integrates flight management, payload control and data 
links into one entity of automation. This entity uses its 
knowledge about the situation, the mission, the vehicle and 
its capabilities to provide an interface to the human 
operator that allows UAV guidance on a situation adaptive 
task level rather than sub-system handling. Instead of 
optimising isolated algorithms or use-cases, this approach 
aims for the integration of multiple unmanned vehicles 
into a highly dynamic military mission while allowing the 
commander of a manned helicopter to use the UAV 
capabilities at an abstraction level similar to commanding 
human subordinates, i.e., additional manned helicopters. 
Previous publications focus on the requirements 
engineering [9] and global system design and test 
environment including the integration of assistant systems 
[10–12]. Moreover, [13] provides a detailed description of 
the software framework used in this work. This framework 
is currently undergoing a major redesign to reflect the 
feedback from various applications [14]. The main 
contribution of this paper consists of a discussion of the 
foundations of task-based guidance, its implementation for 
UAV guidance, the resulting levels of automation on 
various scales, a detailed description of the knowledge 
base as well as the experimental evaluation of the system. 
III. 
TASK-BASED GUIDANCE 
The concept of task-based guidance by sharing 
authority and common goals was first described by the 
military strategist Sun Tzu [15] around 500 BC. He noted 
the importance of sharing and pursuing common goals 
among all ranks to be successful. Consequently, the 
guidance of subordinates should not just consist of 
instructions but also include the reason and the objectives. 
A. Concept of tasks 
In this paper we define task as the combination of (1) a 
goal to achieve and (2) a transfer of authority to a 
subordinate in order to achieve that goal. Therefore, 
issuing tasks to a subordinate (who may be human or 
artificial agents) has several implications and requirements 
to the subordinate as well as to the supervisor. 
Miller [16] lists six requirements for delegation 
relationships: 
1. “The supervisor retains overall responsibility for 
the outcome of the work…” as well as the overall 
authority. 
2. “if the supervisor wishes to provide detailed 
instructions, s/he can; when s/he wishes to provide 
only loose guidelines … s/he can do as well…” 
3. “… the subordinate must have substantial 
knowledge about and capabilities within the 
domain.” 
4. A supervisor has to know the limitations of the 
subordinate. 
5. A common representation of tasks and goals has to 
be shared between supervisor and subordinate to 
communicate about tasks, goals and constraints. 
6. “The act of delegation will itself define a window 
of control authority within which the subordinate 
may act.” 
Based 
on 
those 
requirements 
the 
following 
consequences for designing an artificial subordinate can be 
derived: 
 
Following the first requirement, a subordinate 
must not be “fully autonomous”, i.e., a subordinate 
must not alter the goal to achieve. According to 
[16], a truly autonomous system would neither be 
ethical nor be useful, because it takes away 
responsibility and control from the human 
supervisor. Therefore, an artificial subordinate 
must not violate its “window of control authority” 
(requirement 6). 
 
Requirement 
3 
demands 
that 
an 
artificial 
subordinate shall be designed and implemented as 
knowledge based system. In combination with 
requirement 5, this leads to a symbolic knowledge 
representation which allows to use explicit 
knowledge for processing and communication. 
 
Requirement 5 as well as our definition of the term 
“task” leads to a goal-driven system, i.e., the 
overall behaviour of the system shall be defined by 
the goals pursued. 
 
To address requirement 2, the supervisor may 
choose to provide only tasks considered relevant to 
him or her. Consequently, it is the responsibility of 
the system, to maintain a consistent task agenda. 
This is accomplished by inserting missing tasks as 
required the mission to be accomplished, general 
domain knowledge and causality, e.g., knowing 
that a start procedure is required to be airborne. 
It is obvious that a technical system capable of 
fulfilling those requirements and the above-mentioned 
conclusions is a very complex technical system by design. 
Billings [18] listed several negative characteristics of 
systems where humans have to supervise complex 
automation in general. Complexity in this context means 
that the system cannot fully be understood by the human 
146
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

operator in every state of the system or in every workload 
situation that may arise. The characteristics described by 
Billings are: 
 
Brittleness – The design of the automation limits 
its use cases to those defined by the designer. 
Outside of these limits, the behaviour of the 
automation is not defined. Further information 
about the relation between designer and operator 
of complex systems can be found in [19]. 
 
Opacity – The operator of complex automation 
may have a wrong or incomplete model of the 
automation. The automation does not provide 
sufficient information to support a correct and 
complete model in every situation. 
 
Literalism – The automation does not have any 
knowledge about goals and intents of the operator, 
but executes its functions defined at design time. It 
does not and cannot check if those functions 
support the achievement of the operator’s goals. 
While automation complexity is inherent to the 
introduction of a new automation layer, the approach of 
task-based guidance attempts to reduce those negative 
effects. This is achieved by the following techniques in the 
design of task-based guidance systems: 
 
To address brittleness, domain specific practices 
and regulations, e.g., air space regulations in the 
aviation domain, shall be known to the automation 
and shall be pursued as goals rather than executed 
as hard wired functions. Due to the inherent 
knowledge-processing characteristics of cognitive 
automation, the system will strive to follow the 
regulations even in situations not foreseen by its 
designer. 
 
Opacity can be reduced by providing feedback on 
the abstraction level of task description. Using this 
abstraction level during task assignment, task 
processing, task execution and in the feedback 
about current and future tasks allows the human 
operator to build a mental model about the current 
and future state of the automation. 
 
In contrast to conventional, procedure-based 
automation, task-based guidance follows explicit 
and 
abstract 
objectives. 
This 
counteracts 
literalism, 
because 
the 
automation 
chooses 
functions (action alternatives) that pursue the task 
objectives with respect to the currently observed 
situation. 
The following section describes the application of this 
concept to the guidance of UAVs. 
B. Application to UAV guidance 
Task-based UAV guidance aims at integrating multiple 
unmanned vehicles into a manned helicopter mission in a 
similar 
manner 
as 
integrating 
additional 
manned 
helicopters into the scenario. Therefore, the guidance of 
unmanned vehicles should be on an abstraction level that 
allows the allocation of a series of tasks to each UAV. 
These tasks are issued by the human operator and request 
the 
achievement 
of 
goals, 
e.g., 
the 
request 
of 
reconnaissance information about a landing site. The 
interpretation of the tasks and the use of on-board systems 
to fulfil these tasks are left to the UAV. The series of tasks 
is on a similar abstraction level as tasks assigned to a pilot 
during mission briefing in a conventional, manned 
helicopter mission.  
Moreover, just like a human pilot, UAVs should also 
use opportunities of supporting the mission, e.g., by 
getting sensor information of nearby objects, without a 
direct command from the operator. 
This implies UAV guidance and mission management 
on a level where one or more UAVs are controlled by tasks 
that use mission terms instead of waypoints and the request 
of results rather than in-detail configuration of flight 
control functions and sensor payload. The latter should be 
generated aboard the UAV by its on-board automation. 
The tasks currently implemented in the experimental 
setup are: 
 
a departure task that respects basic air traffic 
regulations of the airfield and makes the UAV take 
off and depart via a given, named departure 
location. 
 
a transit task that causes a flight to a specific, 
named location. While being in transit, the UAV 
configures the on-board camera into forward 
looking 
mode. 
Known 
threats 
will 
be 
automatically avoided, if possible. 
 
a recce route (short for “route reconnaissance”) 
task that causes the UAV to fly a route to a named 
destination. The sensor payload will be configured 
to provide reconnaissance information about the 
flight path, i.e., information about locations of 
sensor readings that indicate armed vehicles and 
hostile air defence. If the UAV possesses 
knowledge about another UAV also tasked with a 
recce of the same route, it will modify its flight 
path to maximize sensor coverage. 
 
a recce area task that causes the UAV to gather 
recce information about a named area. The camera 
will be used to provide ortho-photos of the area. 
 
an object surveillance task. While working on this 
task, the UAV will use the payload control to 
deliver a continuous video stream of a named 
location. 
 
a cross corridor task makes the UAV fly through a 
transition corridor between friendly and hostile 
territory. It consists in avoiding friendly fire and 
ease cooperation with the own ground based air 
defence; this crossing is modelled as separate task. 
Moreover, it is the only task allowed to cross the 
border between friendly and hostile territory. 
 
a landing task causes the UAV to take an 
approach route to an airfield and to land at that 
airfield. 
The capability to understand these tasks at mission 
level consists in knowledge of several domains, i.e., 
artificial situation awareness, planning capabilities and 
using the air vehicle and its payload. This requires an 
automation that incorporates certain sub-functions as 
found in cognitive behaviour of a human [10, 14], i.e., 
creating cognitive behaviour of the automation. The 
following sections discuss issues concerning the levels of 
automation and describe the architecture and information 
processing of a so-called Artificial Cognitive Unit (ACU). 
147
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

IV. 
LEVELS OF AUTOMATION 
Currently, UAV systems operate on a wide range of 
different guidance modes. That modes cover the whole 
range from direct manual control [20], flight control based 
[9], scripted behaviours [2] up to above-mentioned task-
based guidance [10]. These guidance modes form a stack 
of abstraction layers as depicted in Figure 2. In this figure, 
“R/C pilot” refers to remotely controlled piloted systems 
like model airplanes. FMS stands for Flight Management 
Systems capable of following pre-programmed waypoint 
lists. 
 
Figure 2.  Levels of abstraction in UAV guidance [1] 
Sheridan and Verplank [21] describe a different view 
of levels of automation. These levels are mostly 
independent from the chosen abstraction layer but set the 
focus on task allocation and authority sharing between the 
human and the automation. They range from manual 
control (level 1) to automation that does neither allow 
intervention from the human operator nor provide 
information about the action taken (level 10). In the design 
of current UAV guidance systems, various levels of 
automation can be found, e.g., in waypoint based guidance 
systems, the definition of waypoints may be the sole 
responsibility of the human operator. No automation, in 
this case, is provided to support that task. However, 
automatic flight termination systems, e.g., may not allow 
the human to veto on the decision of the automation but 
merely report the flight termination after its execution, i.e., 
level 7 according to Sheridan and Verplank: “computer 
does the whole job and necessarily tells the human what it 
did” [21]. 
Another view to automation focuses on capabilities and 
the interoperability with the control station provided by 
the system. A prominent example for this kind of 
automation scale is defined in [22] as Levels of 
Interoperability (LoI): 
 
Level 1: Indirect receipt of UAV data 
 
Level 2: Direct receipt of UAV data 
 
Level 3: Level 2 plus control and monitoring of 
the payload 
 
Level 4: Control and monitoring of the UAV, less 
launch and recovery 
 
Level 5: Level 4 plus launch and recovery 
The task-based guidance approach described in this 
paper introduces an additional dimension in the levels of 
automation. The operator can choose to provide different 
tasks to the UAV. The UAV will check the tasks for 
consistency and may insert additional tasks to warrant a 
consistent task agenda. The consistency check and 
completion of the task agenda is based on a planning 
scheme, which behaves deterministic with respect to the 
current tactical situation and the task elements known so 
far. Therefore, the operator may choose to specify only 
task elements relevant to him or her and leave the 
specification of other tasks to the UAV. This particular 
type of adaptable automation allows the specification of 
strict or tight task agendas, i.e., the human operator defines 
every task of the UAV. However, also loose task agendas 
may be defined, i.e., the human operator only defines the 
most important tasks and leaves the details to the UAV. 
Therefore, this level of automation defines a varying 
tightness of UAV control. 
Moreover, this kind of automation also can reduce the 
chance of human errors, because unintentionally omitted 
tasks are also completed by the automation.  
Table I shows an overview of the aforementioned 
dimensions of automation in UAV guidance. In the design 
of a UAV guidance system, each automation level may be 
fixed, e.g., a system may provide task-based guidance 
(abstraction) with management where the system offers a 
complete set of action alternatives, i.e., authority sharing 
on level 2 [21] including launch and recovery 
(interoperability LoI 5) where every single task has to be 
specified by the human operator (strict tightness). 
Despite of having a fixed level of automation on the 
four scales, a system can allow the human operator to 
adapt the abstraction level, the sharing of authority and the 
tightness level. Moreover, the automation can change the 
sharing of authority, i.e., it can be designed as adaptive 
system. 
TABLE I.  
DIMENSIONS OF AUTOMATION 
Dimension 
fixed 
adaptable 
adaptive 
Abstraction 
• 
• 
 
Authority sharing 
• 
• 
• 
Interoperability 
• 
 
 
Tightness 
• 
• 
 
 
As the focus of this work is on the task-based guidance 
and the tightness of the UAV guidance, our prototype and 
evaluation environment uses a fixed abstraction level 
(task-based guidance), a fixed sharing of authority 
(depending on the automated function) and operates on 
LoI 5. The tightness can be implicitly adapted by the 
human operator. For every task the operator assigns to the 
UAV the authority of task refinement is passed from the 
operator to the UAV. The amount of the required 
refinement defines the degree of tightness in the UAV 
guidance. 
V. 
SYSTEM ARCHITECTURE 
With respect to implementing the desired machine 
behaviours, this section will provide an overview of the 
design principles and information processing architecture 
enabling task-based guidance capabilities. 
A. Design of knowledge-based Artificial Cognitive Units 
Based on models of cognitive capabilities of human 
pilots, Artificial Cognitive Units (ACUs) were designed. 
As depicted in Figure 3, these units become the sole 
mediator between the human operator and the vehicle [23] 
in the work system [17]. This additional automation allows 
Task based guidance (single & cooperating UAV)
Scripted Behaviours
FMS
Ground 
mapping
Object 
surveillance
Autopilot
R/C pilot
manual
Payload control
Flight control
mission management
automation
148
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the desired shift in the guidance paradigm from the 
subsystem level, i.e., separate flight guidance and payload 
management, to commanding intelligent participants in the 
mission context (also refer to [24]). 
 
Figure 3.  Work system “UAV guidance” 
To understand and execute tasks with respect to the 
current situation, the ACU requires relevant parts of the 
knowledge and cognitive capabilities of human pilots. That 
knowledge can be grouped into system management, 
understanding and evaluating mission objectives in the 
context of the current scenario as well as knowledge to 
interact with the human operator [25]. This knowledge is 
derived by formalization of domain specific procedures 
defined in documents like the NATO doctrine for 
helicopter use in land operations [26]. Furthermore, 
interviews with experienced helicopter pilots revealed 
relevant knowledge. The interviews and the additional 
evaluation of recordings of training missions used the 
Cognitive Process Method [13]. For every phase, the 
human’s objective is evaluated. Moreover, all possible and 
hypothetic action alternatives to pursue the objective are 
determined. Furthermore, all environmental knowledge is 
gathered, which is used to select a particular action 
alternative or which influences the execution of a chosen 
action. In our laboratory prototype, this knowledge is used 
to select a particular action alternative over another, 
thereby avoiding state space explosions and reducing 
planning time. At last, the procedural knowledge to 
execute the actions is evaluated and transformed into 
machine readable instruction models. 
B. Human-machine interface 
To support the guidance of multiple UAVs from a 
manned helicopter, the human-machine interface (HMI) 
has to be integrated into the manned helicopter. 
Considering an audio interface, i.e., speech recognition to 
guide the UAVs, was rejected by a majority of the 
interviewed pilots due to the already high radio traffic that 
has to be handled by the helicopter crew. 
Therefore, a graphical interface was chosen to interact 
with the UAV. This interface is integrated into two 
identical multifunctional displays available to the 
commander of the manned helicopter. Figure 4 depicts the 
implemented multifunctional display format. 
On the lower left of the multifunctional keyboard, the 
operator can switch between UAV control and the displays 
of the manned helicopter (A/C / UAV). Above, the current 
UAV can be selected. On the top left, the operator can 
select three different modes: CAM, TASKS, and ID. The 
right multifunctional soft keyboard shows the context 
sensitive options for the current mode chosen on the left. 
 
 
Figure 4.  UAV tasking interface 
CAM provides a live video stream from the camera of 
the currently selected UAV. 
TASKS can be used to monitor the current tactical 
situation and to manipulate the displayed task elements of 
the currently selected UAV. The currently active task is 
highlighted in yellow. A task can be inserted into the task 
agenda of the UAV by choosing the task type as shown on 
the right in Figure 4, optionally choosing the predecessor 
of the task on the map and selecting the target position of 
the task. A task can be selected for immediate execution. 
This functionality can be used to start the execution of the 
first task as well as for skipping tasks, i.e., the human 
operator chooses to cancel one or more task to give 
priority to a more important task. Additionally, tasks can 
be deleted and moved, i.e., the target area description of 
the task is altered. If tasks are added, deleted or modified, 
the UAV will maintain a consistent task agenda by 
inserting missing tasks depending on the current tactical 
situation. As long as this planning is in progress, it is 
indicated on the bottom of the display as shown for UAV 
number 2 in Figure 4. To prevent immediate re-insertion of 
deleted task elements, the consistency checks are delayed 
after the operator deletes a task element. This allows 
further modifications of the task agenda by the human 
operator without being interrupted by the UAV. 
The ID display mode is used to review photos taken by 
the UAV and to classify the objects on the images into pre-
defined types (car, military vehicle, ground based air 
defence) and hostility, i.e., neutral, friend or foe. Those 
classifications are also reflected in the tactical situation 
shown in the task mode as well as the electronic map 
displays available to the pilot flying. Furthermore, those 
classifications will be transmitted to the UAVs in order to 
support reaction to the changed tactical environment, e.g., 
to plan flight routes around hostile air defence. 
The combination of those display functionalities shall 
allow the human operator to guide the UAVs to support a 
military air assault mission that involves operation over 
hostile areas and support of infantry troops. Moreover, by 
tasking the UAVs using mission terms, e.g., by selection of 
“area reconnaissance of the primary landing site”, the 
control of three UAVs shall be feasible and enhance 
mission safety by providing valuable information about 
mission relevant areas and routes without risking exposure 
Human 
Operator
Task 
Based
Guidance
(ACU)
Payload 
Management 
System
Flight 
Management 
System
Payload
Avionics
Operating Force
Operation Supporting Means
environment
work
objective
work
result
149
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

of own troops to threats like ground based air defence and 
other opposing forces. 
C. Information processing 
The implementation of artificial cognitive units is 
based on the Cognitive System Architecture (COSA) 
framework [13]. This framework is based upon Soar [28] 
and adds support for object-oriented programming as well 
as stereotypes for structuring the knowledge into 
environment models, desires, action alternatives and 
instruction models. 
This (a-priori) knowledge constitutes the application 
specific part of the Cognitive Process, which is described 
in detail by Putzer and Onken [13] as well as Onken and 
Schulte [17]. Information and knowledge processing as 
well as interfacing with the environment is depicted in 
Figure 5. The inner ellipse represents the static, a-priori 
knowledge of the system. This knowledge is defined at 
design-time. Input data and instances of the a-priori 
knowledge constitute the situation knowledge, which is 
depicted in light grey in Figure 5. The arrows indicate the 
information flow in the cognitive process. Every 
processing step modifies one specific area of situation 
knowledge, but may read from all areas of knowledge. 
The following describes the information processing 
steps using examples of the knowledge of the UAVs’ on-
board ACUs. 
 
Figure 5.  Knowledge processing in the Cognitive Process [17] 
Input data are retrieved from the environment by input 
interfaces. There are three types of input interfaces: (1) 
reading sensor information from the sensors of the UAV, 
(2) reading information from the communication link of 
the UAV and (3) providing results from on-board 
automation, e.g., information about flight routes generated 
by an external route planner. 
The environment models of the a-priori knowledge of 
the ACU drive the interpretation of input data into 
instances of semantic concepts. Those concepts form an 
understanding of the current tactical environment 
including knowledge about existence and positions of 
threats, areas, bases, landing sites, routes, waypoints etc. 
Due to the nature of the cognitive system architecture, 
environment models continuously monitor all the input 
data and other knowledge of the cognitive process and 
react with instantiation, modification or removal of 
corresponding beliefs. All instances of environment 
models, i.e., beliefs, form the representation of the current 
situation of the UAV. Desires describe world states the 
UAV should maintain. Every desire contains declarative 
knowledge about the detection of violation of the state, i.e., 
it contains rules that continuously monitor the situation for 
facts that indicate a violation of the desire. If a violation is 
detected, an instance of the desire is created, i.e., the desire 
creates an active goal. Desires may contain knowledge that 
derives priorities from the current situation, e.g., the desire 
of executing task modifications issued by the human 
operator takes precedence over the desire of having a 
consistent task agenda. The motivation is to avoid fixing 
agendas that are currently modified by the operator. 
Action alternatives provide ways to support active 
goals. They instantiate if a corresponding goal is active, 
but only if the current situational knowledge allows the 
selection of the action alternative. If more than one action 
alternative can be proposed, then the action alternatives 
model selection knowledge to prefer one alternative over 
the other. For example, the action alternatives “transit 
flight” and “route reconnaissance” may both support the 
goal of reaching a specific location. If both action 
alternatives are feasible, the fitness and selection of the 
alternative depends on the type of area that has to be 
crossed. 
After the action alternative has been chosen, the 
instruction models become active and support the action 
alternatives by generating instructions on the output 
interface of the ACU. Those instructions are read by the 
output interface and cause the transmission of radio 
messages, configuration changes at the flight control 
system or the payload system or activate on-board 
automation, e.g., a route planner. 
In combination, all those processing steps depicted in 
Figure 5 generate purely goal-driven behaviour that allows 
reasoning over the tactical situation and the task elements 
entered by the human operator to provide situation-
dependent actions, which are consistent with tactical 
concepts 
of 
operations. 
Unlike 
procedure-based 
architectures, the Cognitive Process is not bound to pre-
defined algorithms, which are affected by unforeseen 
changes in the environment or may be unable to deal with 
concurrent events.. Instead, the situation is continuously 
analysed with respect to explicitly encoded domain 
knowledge. Furthermore, the open world assumption of 
COSA allows dealing with “… incomplete information, 
which is essential taking sensor data into account.” [27]. 
D. Knowledge Base 
While the information processing of COSA is domain 
independent, the knowledge base defines the domain 
knowledge models. The knowledge of the ACU is grouped 
into packages which may refer to each other. Each package 
defines knowledge of one subdomain: 
 
environment 
 
supervisory control 
 
mission 
 
cooperation 
 
task synthesis for loose vs. tight control 
 
task scheduling 
 
role management 
 
Every package consists of knowledge models, which 
are 
represented 
in 
CPL 
(Cognitive 
Programming 
Language) [25], which is based on Soar [28]. For every 
Environ-
ment
Planning
Plan
Scheduling
Instructions
Environment
Models
Instruction Models
Desires
Goals
Action
Alternatives
Input
Interface
Output
Interface
Input Data
situational
knowledge
a-priori-
knowledge
Goal
Determi-
nation
Belief
observable behaviour of CP
= ACU behaviour
Interpretation
150
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

type of knowledge described in this section, there is a 
separate knowledge model encoded in CPL. 
The knowledge models of the prototype focus on 
mission management, cooperation of UAVs and task-
based guidance in general and are mostly vehicle 
independent. However, [24] presents an architecture that 
allows the integration of high-level UAV mission tasking 
and vehicle specific knowledge. 
1) Environment knowledge 
The environment package contains all knowledge 
models that allow the ACU to build an internal, symbolic 
representation of the current environment including the 
state of the UAV. This knowledge may be considered 
machine situation awareness comparable to human 
situation awareness on level 2 (understanding of the 
current situation) according to Endsley [29]. 
This knowledge covers models about the existence of 
the UAV and other UAVs in the team. Moreover, 
knowledge about ground forces, air spaces, positions in 
general and relation between positions is represented. 
Information about the sensor system is covered by a model 
of the on-board sensors. Information about sensor photos 
that may be reviewed by the human operator for 
classification is represented by a corresponding knowledge 
model.  
 
 
Figure 6.   Example of an environment model 
Fig. 6 shows a short example of an environment model 
of the UAV. This particular environment model represents 
sensor readings of the automated target recognition system 
(ATR), which indicate possible threats at a defined 
position. The stereotype “belief” makes the knowledge 
model an environment model. The behavior “create*from-
sensor-input” consists of a condition part and an action 
part. The conditions are matched against the current 
knowledge and check for the existence of a “thermal-
detector” node in the sensor input data. If the condition is 
met, an instance of the knowledge model is created 
(“elaborate”) and the coordinates of the sensor input are 
copied from the input data into the newly created instance. 
The keyword “o-support” makes the instance permanent, 
i.e., the general truth maintenance property of COSA is not 
applied and the instance will not disappear if the input data 
disappears. The syntax used here is an object oriented 
extension [13] of Soar [28].  
2) Supervisory control knowledge 
Knowledge 
about 
supervisory 
control 
covers 
knowledge necessary for the task assignment to the UAV. 
It contains a model of the instruction sent from the human 
operator to the UAV. For every task type available, there is 
an instruction model derived from that base instruction 
model. Furthermore, there are models for the messages 
that request the execution of a specific task as well as one 
model for the request to stop or delete a task. 
Another knowledge model in this package represents 
the current guidance mode of the UAV. This model is 
responsible for the representation of the task-based 
guidance as such. It detects overrides to the task-based 
guidance, e.g., the aforementioned request to stop a task, 
and is responsible for granting or revoking access to the 
flight management system to the ACU as such. The ACU 
always initializes with those privileges being revoked, i.e., 
it is the sole authority of the human operator to transfer the 
authority over the flight management system to the ACU. 
3) Mission knowledge 
The mission knowledge represents the models used to 
execute the tasks assigned to the ACU. Most of the 
behavior of the ACU is defined by its desire to comply 
with the assigned tasks. This knowledge model makes the 
ACU strive to fulfill the current task at hand.  
Furthermore, the mission knowledge contains the 
desire to use opportunities for retrieving additional recce 
information which may be unrelated to the current task. 
Therefore, the ACU combines its knowledge about the 
type of sensor information, i.e., “unidentified sensor-
hotspot”, the availability of its sensors, the availability of 
sensor information from its own sensors and from other 
UAVs, and its relative position to the unidentified force. 
This combination of knowledge enables the UAV to safely 
detect and use the chance of getting more information 
about the location. Moreover, the UAVs also behave 
cooperative as the decision to generate additional sensor 
information is suppressed if another UAV has generated 
that sensor information from a similar angle to the 
unidentified force. 
The action alternatives of this knowledge package 
model ways to achieve active goals. Moreover, additional 
desires model prerequisites for action alternatives, e.g., to 
make the action alternative of crossing an airspace corridor 
feasible, the aircraft shall be near the entry point of the 
airspace corridor.  
Instruction models contain the knowledge about how to 
execute the chosen action alternative, i.e., how to interact 
with the on-board automation and the environment. 
4) Cooperation knowledge 
The cooperation package contains all models which 
 
represent knowledge about current and future tasks 
of the own UAV as well as tasks of other UAVs. 
 
represent knowledge about the task at hand and the 
sequence of future tasks. This knowledge also 
includes strategies for determining the current task 
at hand. 
 
determine the information needs of all teammates, 
i.e., other UAVs, and generates the information 
feedback to the human operator. Furthermore, 
action alternatives exist to fulfill those information 
needs. 
There is a common base model for all task elements 
that defines the common knowledge and common behavior 
of all tasks. Derived from that model, there is a model for 
every task type available, i.e.: 
class <belief> hotspot
{
attributes:
string name := |hotspot|;
// location of the hotspot (WGS84)
double lat;
double lon;
double alt;
behaviour:
sp { create*from-sensor-input
: o-support
(state <s> ^io.input-link.sensor.thermal-detector <sensinput>)
(<sensinput> ^lat <lat> ^lon <lon> ^alt <alt> )
-->
(elaborate <i>)
(<i> ^lat <lat> ^lon <lon> ^alt <alt> )
}
};
151
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
recce-route is the task to get reconnaissance 
information about a flight route to a specified 
destination. 
 
recce-area is the task to get information about a 
specified area and its surroundings. 
 
surveillance delivers a continuous video stream of 
a specified location or a designated force. 
 
transit is the task to fly a safe transit to a specified 
target location. 
 
departure is the task to execute a departure 
procedure with compliance to the departure rules 
of the current location. 
 
landing is the task to execute an approach and 
landing procedure with compliance to the 
approach rules of the specified landing location. 
 
cross-flot is the task to cross airspace boundaries, 
i.e., the so-called forward line of own troops 
(FLOT), at a specified airspace corridor. 
An agenda models the sequence of the tasks of a UAV. 
In order to know the current task at hand, the cooperation 
package defines three action alternatives. First, if there is 
an instruction from the human operator requesting a task 
for immediate execution, then this task becomes the 
current task. If this alternative is available, then it is 
preferred over other strategies. Second, the ACU may 
select the successor of the last completed task as the new 
current task. This is the default strategy. If neither strategy 
is applicable, the ACU may choose the first non-completed 
task from the agenda. 
To model the information needs of the team mates, a 
knowledge monitor tracks instantiation, change and 
destruction of relevant knowledge models. The relevance 
for team mates is implemented as additional model 
attribute that can be evaluated at runtime. The model of the 
desire to keep the team informed is activated, if an instance 
of “knowledge monitor” detects a change in the monitored 
instances. As a consequence, action alternatives are 
activated and propose to communicate the change in the 
knowledge to the team. There are multiple action 
alternatives to model different serializations of knowledge, 
i.e., to address different communication channels. 
5) Knowledge about task synthesis 
To model the variable tightness described in 
Section IV, the ACU possesses a desire to have a 
consistent task agenda. This desire activates into an active 
goal, if one of the following rules for consistent agendas is 
violated: 
1. Every task except departure requires the UAV to 
be airborne. 
2. If there is an approach route for a landing site, then 
it shall be used by the landing task. 
3. The tasks “recce-area” and “surveillance” require 
the UAV to be near the area or the named location 
respectively. 
4. The task “cross-flot” should start at an airspace 
corridor. 
5. If there are designated entry/exit points for an 
operation area, then these shall be used by the 
UAV. 
6. If 
there are airspace 
corridors 
connecting 
airspaces, then those corridors shall be used. 
To detect those violations, there is a knowledge model 
representing the state of the UAV after completion of a 
task. An additional instance of that knowledge model 
refers to the current state of the UAV. Furthermore, there 
is a knowledge model whose instances represent the 
preconditions of future tasks. Violations of the rules can be 
detected by comparing the prerequisites of one task with 
the predicted state after completion of its predecessor. 
An example of a violation is depicted in Figure 4. The 
route reconnaissance on the lower half of the image, which 
is shown by a stippled, orange line with a camera symbol, 
crosses the boundaries of the operation area (white stippled 
rectangle). However, that area shall be entered only via its 
designated entry points (white dots). Therefore, this leads 
to an activation of “have a consistent task agenda”. As this 
activation is considered relevant knowledge to the team, it 
is transmitted to the operator and shown as “UAV 
planning” in Figure 4.  
If there are multiple, concurrent violations of rules, the 
violations are scheduled according to a “divide-and-
conquer” scheme, e.g., if rule 6 is violated, this violation is 
addressed first to divide the agenda into parts operating 
only in a single airspace. 
The action alternatives supporting the goal of having a 
consistent agenda are the creation and insertion of 
additional tasks into the task agenda. Furthermore, existing 
tasks may be altered, e.g., to ensure that a cross-flot task 
starts on the right side of the airspace corridor. Action 
alternatives are selected based on the current or projected 
tactical situation, e.g., the resolution of a violation of rule 4 
depends on the type of the terrain, i.e. a “transit” task is 
inserted when operating over safe terrain and a “recce 
route” task is inserted to reach the corridor while operating 
over unsafe terrain. 
As mentioned in Section IV, the human operator can 
make use of this behaviour of the ACU by skipping tasks 
on purpose and thereby shifting the completion and 
specification of missing tasks to the ACU. 
6) Task scheduling 
The human machine interface allows the operator to 
insert new tasks at a certain position of the agenda after 
having specified the predecessor of the new task. 
However, the operator may also define tasks without 
specifying where to insert the task into the existing agenda. 
Therefore, the ACU follows a desire to know the task 
insertion point. For new tasks without specified insertion 
point that the behavior of that desire creates an active goal. 
The action alternatives for determining the insertion 
point are to insert the task at the end of the task agenda or 
to insert the task in a way that minimizes the detour based 
on the existing task agenda. The latter alternative is not 
available for departures and landings. 
7) Role management 
Knowledge about role management supports the 
cooperation of multiple actors (UAVs) working on a 
common task. The term role is used as defined in social 
sciences [30]. Biddle states that roles in the symbolic 
interactionist role theory are “…thought to reflect norms, 
attitudes, contextual demands, negotiation, and the 
evolving definition of the situation as understood by the 
actors.” [30] 
To bring the concept of roles to the UAV, the ACU has 
a knowledge model describing its roles and the roles of the 
teammates. Furthermore, another knowledge model 
defines the desire of having a unique role per task. This 
152
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

desire is activated into an active goal if there is no role 
assigned to a task or if there is knowledge available, that 
the assigned role is also assigned to a teammate for the 
same task. 
There are models about role configurations that define 
which roles are available depending on the task type and 
the number of UAVs working on the common task. 
Depending on those configurations, all possible roles are 
proposed for a task. 
To support the goal of having a unique role per task, 
there are two action alternatives available. Firstly, the 
ACU may assign an available role to the common task. 
The selection can be random or based on the application of 
selection knowledge like preferring to stick to a role in 
subsequent tasks of the same type. Secondly, the ACU 
may drop an assigned role as result of a role conflict.  
Therefore, 
the 
general 
outline 
of 
role-based 
cooperation is: 
1. UAVs communicate assigned tasks to each other. 
2. Each UAV detects that it participates in a task also 
assigned to another UAV, i.e., a common task 
requiring cooperation. 
3. Every UAV proposes a role describing how to 
participate in the task. 
4. Conflicting and missing role assignments are 
detected and resolved. 
5. Roles affect the way a task is executed by the 
UAV. 
Because of the knowledge-based nature of the ACU, 
the arbitration of roles is immune to race conditions like 
simultaneously changing roles and environment. Any 
invalid role assignment triggers the activation of the goal 
of having a valid assignment and consequently causes the 
correction of the role configuration. The following 
example illustrates how a team of UAVs benefits from this 
property in a dynamic situation. 
 
Figure 7.  Multiple UAVs working on common task 
If there are three UAVs with a common recce-route 
task, the corresponding role configuration and roles will 
become active and propose the roles to “fly to the left of 
the track”, “fly to the right of the track” and “fly on track” 
in order to maximize the sensor coverage. When the ACU 
plans its route for the route reconnaissance, the assigned 
role affects the instruction model responsible for the route 
planning. Therefore, the route planner is instructed to add 
an offset to the track while planning. This leads to a 
formation-like flight of the three UAVs. The left half of 
Figure 7 depicts the resulting flight paths of three UAVs 
flying a common recce-route task. The grey patches 
illustrate the coverage of the sensor images taken by the 
UAVs. 
Once a UAV is withdrawn from the common task, the 
roles available may change. This leads to a reassignment 
of the roles and to a change in the task execution as 
depicted in the right half of Figure 7, i.e., one UAV is 
being withdrawn from the common task causing the other 
UAVs to change their roles and flight paths. 
VI. 
EXPERIMENTAL SETUP AND RESULTS 
Experiments were conducted with experienced German 
Army helicopter pilots in order to evaluate the task-based 
guidance approach. The simulator cockpit shown in 
Figure 1 has been used to perform military transport 
helicopter missions. The simulation of the UAVs consists 
of a simple kinematic model of a generic helicopter. The 
elementary flight performance envelope of this model is 
comparable to the model of the manned helicopter, i.e., the 
maximum speed is about 120 knots. However, the concept 
of task-based UAV guidance is independent from specific 
UAV platform types or dynamics, and is also applicable to 
fixed-wing aircraft. The kinematic flight model was fitted 
with an autopilot, waypoint tracking capabilities, and 
interfaces to the ACU. Together with an electro-optical 
sensor simulation, this simulates the flight control and 
payload control as depicted in Figure 2. In the simulation 
setup, the LoI is fixed at level 5, i.e., the operator has full 
control of UAV including payload, launch and recovery 
(cf. Section IV) and only the task-based layer is available 
to the human operator, i.e., the abstraction layer is fixed in 
the experiment. 
The objective of the missions was to pick up troops 
from a known location and to carry them to a possibly 
threatened destination. According to the briefing, three 
UAVs should be used to provide reconnaissance 
information about the flight routes and landing sites in 
order to minimize exposure of the manned helicopter to 
threats. In addition to the tasks to perform in previous 
baseline experiments without task-based guidance [9], in 
this experiment an unscheduled combat recovery task was 
commanded to the crew as soon as the main mission 
objective had been accomplished. 
Prior to the measurements, every test person had been 
given one and a half day of education and training on the 
system. The test persons acted as pilot flying and 
commander. This configuration was chosen to evaluate the 
effects of the UAV guidance to crew cooperation and crew 
resource management. 
The following data were recorded during the 
experiment:  
 
Interaction of the operator with the system 
 
Commands sent to the UAV via data link 
 
Resulting task agendas of the UAVs 
 
Helicopter and UAV flight paths 
 
Sensor coverage 
This data was used to retrieve measures in the 
categories performance, behaviour and subjective ratings. 
Performance covers the mission success as such, including 
different aspects of reconnaissance and UAV flight 
guidance. Behavioural measures include the attention 
demand of UAV guidance, the distribution of interaction 
with the UAV guidance system over the mission phases 
and the tightness of the UAV guidance (see Section IV). 
Subjective ratings cover the perceived workload and the 
system ratings from the test persons.  
object to monitor
UAV withdrawn from
common task
153
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

In the following, the measures and results of the 
commander of the manned helicopter, who is also the 
UAV operator at the same time, are presented. Results for 
the complete flight crew may be found in [31]. 
A. Performance 
One key aspect when measuring performance in 
military missions is the overall mission success. The test 
persons managed to accomplish the mission including the 
additional combat recovery in every simulation run. 
Another figure is the gain in mission safety and 
security achieved by the deployment of detached sensor 
platforms. This can be estimated by the sensor coverage of 
the flight path of the manned helicopter. In the experiment, 
the manned helicopter operated within the terrain mapped 
by ortho-photos 94.5% of the time in hostile areas. 
It is the responsibility of the commander to use the 
UAVs in a way that maximizes tactical advantages. 
According to the test persons, this consisted in having 
sufficient information about the flight path of the 
helicopter to support mission-critical decisions. Moreover, 
the army aviators emphasized the importance of having 
forces near the helicopter to react to unforeseen events. 
To evaluate the tactical advantages, a scoring was 
developed to measure the quality of the reconnaissance 
achieved with the UAVs. 
TABLE II.  
SCORES FOR RECONNAISSANCE PERFORMANCE 
 
yes 
no 
Reconnaissance data of helicopter route  
available in time? 
2 
0 
Reconnaissance data of primary landing site 
available in time? 
2 
0 
Classification of UAV sensor data in time?  
(only 1 point, if pilot flying had to request classification) 
2 
0 
 
Table II lists the applied criteria for the reconnaissance 
performance and the corresponding scoring. The video 
recordings of the simulations were analysed to apply the 
conditions listed. To get the full score of 2 points, the 
listed requirement has always to be fulfilled during the 
mission. Otherwise, the criterion was assessed 0 points. 
The availability of reconnaissance data was considered not 
“in time”, if the manned helicopter had to slow down in 
order to wait for UAV data or classification or if the 
helicopter operated near unknown or not-located forces. In 
the experiment, an average score of 88.3% (n=16) of the 
maximum of 6 points was reached. 
Furthermore, most of the commanders used the 
capabilities of the UAVs to get reconnaissance information 
that could have been useful in alternate outcomes of the 
missions, i.e., information about alternate flight routes and 
information about alternate landing sites. In some cases 
this led to delays in the mission progress as UAVs were 
busy getting information of alternate routes and landing 
sites. 
TABLE III.  
SCORES FOR ADDITIONAL TACTICAL BENEFITS 
 
yes 
partial 
no 
Reconnaissance data of alternate flight 
routes available? 
2 
1 
0 
Reconnaissance data of alternate landing 
sites available? 
2 
1 
0 
Delays in the mission progress because of 
missing reconnaissance data? 
0 
n/a 
2 
 
Table III provides a scoring for these additional 
benefits, the commanders got from the deployment of the 
UAVs. On average (n=16), 60.5% of the maximum score 
was reached in this scale. 
The results in this section indicate, that task-based 
guidance is a way of UAV guidance which supports the 
overall mission success as well as mission safety. 
Moreover, the test persons used the UAVs as force 
multiplier to get additional sensor data of alternate sites 
and routes. 
B. Fan-Out 
Supervision of the UAVs places extra work demands 
on the human operator. To get a measure of the demands 
of multiple UAV guidance using task-based guidance, the 
maximum number of UAVs the operator can handle shall 
be estimated. This estimation is based on the operator’s 
attention required by one UAV. Goodrich and Olsen [32] 
introduce the concept of Robot Attention Demand (RAD) 
which can be calculated as 

RA  
IT
IT  T

where IT denotes the Interaction Time, i.e., the time the 
operator actually interacts with a multi-robot system. NT is 
the Neglect Time, i.e., the amount of time a robot can be 
neglected before its performance drops below a certain 
threshold [32]. 
For multi-robot systems like multi-UAV guidance, it 
can be assumed, that the human operator uses NT to 
interact with additional robots. Therefore, the inverse of 
RAD gives an upper bound for the number of robots that 
the human operator can handle. This measure is called 
Fan-Out (FO) [32]. 
To further improve the estimate of the Fan-Out, 
Cummings et al. [33, 34] introduce the concept of Wait 
Time (WT). Wait times occur, if the human operator 
should interact with a robot, but fails to do so because he is 
busy with another robot (wait time caused by interaction – 
WTI), because of task switching delays (wait time in 
decision making queue – WTQ) or he lacks the situation 
awareness to recognize the need for interaction (WTSA). 
With wait times, the Fan-Out can be calculated as 
 
F   
 T
IT WT    
(2) 
To apply the measurement of IT, NT and WT to the 
experiment, which models a complex military scenario, the 
following criteria are used to distinguish interaction time, 
neglect time and wait time: 
Wait Time (WT) occurs in the following cases: 
 
At least one UAV is idle, i.e., it has completed all 
of its tasks. 
154
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
There is at least one mission relevant object in the 
sensor 
images 
of 
the 
UAV 
waiting 
for 
classification by the human operator, e.g., a UAV 
has taken an image of hostile ground forces but the 
operator has not yet evaluated that image. 
 
A UAV enters the range of hostile air defence. 
Interaction Time (IT) occurs, if none of the conditions 
for wait times are fulfilled and at least one of the following 
conditions is true: 
 
The 
operator 
prepares 
the 
human-machine 
interface for interacting with a UAV. 
 
The operator defines, modifies or removes a task 
of a UAV. 
 
The operator evaluates UAV sensor data or 
prepares the human-machine interface to do so. 
 
The operator interacts with the human-machine 
interface to monitor the current position and task 
of a UAV. This is equivalent to “robot monitoring 
and selection” as defined by Olsen [35]. 
All other time spans are considered Neglect Time 
(NT). 
The 
times 
were 
measured by 
evaluating 
the 
interactions of the operator with the overall system instead 
of measuring per UAV. Therefore, the resulting Fan-Out is 
relative to the initial number of UAVs, which is three. 
The average neglect time measured is 57% (n=16) of 
the overall mission time. The mean of the wait times is 
6.5% (n=16).  
 
Figure 8.  Distribution of the Fan-Out (FO) in the experiment 
Hence, the average Fan-Out is computed to 2.49 
(n=16).  
The average share of NT used for interactions with the 
systems of the manned helicopter as well as interacting 
with the pilot flying is only 19%. 
This result and the high neglect time indicate that task-
based guidance of three UAVs is feasible and the human 
operator still has sufficient resources to remain in his role 
of being the mission commander and pilot in command of 
the manned helicopter. 
C. Task Instructions per Mission Phase 
To evaluate if the concept of task-based guidance is 
also applicable in situations unforeseen by the human 
operator, all missions of the experiment were divided into 
four phases: 
 
Phase A begins with the start of the experiment 
and ends with the take-off of the manned 
helicopter. This phase is not time-critical, i.e., it is 
assumed that the crew can start the preparation of 
the mission as early as required, although in the 
real 
application 
there 
might 
be 
some 
organisational and military constraints to that. 
 
Phase B begins with the take-off of the manned 
helicopter and ends with the successful completion 
of the main mission objective, e.g., if the main 
mission objective is to transport troops, phase B 
ends when the troops leave the helicopter at the 
remote landing site. 
 
Phase C starts after phase B with the assignment of 
an additional mission objective which was 
unknown to the crew prior to the experiment, e.g., 
to rescue the crew of a crashed aircraft. Phase C 
ends with the successful completion of the 
additional mission assignment. 
 
Phase D starts after phase C and covers the egress 
to the home base. 
 
Figure 9.  Number of task modifications per mission phase 
Figure 9 depicts the number of task instructions, i.e., 
instructions to insert, alter or remove tasks from the 
agenda, issued by the operator per mission phase. The 
mission phase with the most instructions to the UAVs was 
the time-wise uncritical preparation phase A. If there are 
only minor changes to the situation, i.e., changes that can 
be foreseen by experienced mission commanders, only a 
small number of changes to the UAV task agenda are 
necessary (phases B and D in Figure 9). 
However, if there is a fundamental change to the 
mission objective including locations and goals which 
were unknown to the helicopter crew, this can also be 
handled with a relative small number of changes to the 
UAV agenda. This is expressed by a small increase of 
tasking instructions in phase C compared with phases B 
and D. 
Therefore, task-based guidance as evaluated in this 
experiment shows two qualities: 
1. It allows the human operator to shift interactions 
from mission critical phases to the mission 
preparation. 
2. Even unforeseen situations can be handled with an 
adequate amount of interactions that is not 
significantly larger than the number of interactions 
in known situations. 
Just like in conventional, pre-planned missions with 
only little flexible mission management approaches, most 
of the interactions are performed in the planning and 
preparation phase. Nevertheless, the flexibility of the task-
based guidance approach is demonstrated, because the 
unknown secondary task and, hence, the required re-
planning activities could be handled with minimum effort.  
1
1,5
2
2,5
3
3,5
4
Fan-Out
0
10
20
30
40
50
60
A
B
C
D
mission phase
number of instructions
155
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

D. Tightness Level 
The tightness level in the task-based UAV guidance 
can be expressed as the ratio of the number of task 
elements assigned by the human operator versus the 
number of synthesized tasks. 
 
Figure 10.  Average thightness in UAV guidance per mission phase 
In the experiment, 51% (n=8) of the elements in the 
task agendas of the UAVs were inserted by the human 
operator. The remaining 49% of the task elements were 
automatically inserted by the UAVs to establish a 
consistent task agenda. Figure 10 depicts the share of task 
elements assigned by the human operator. In the 
experiment, this observed tightness level is mostly 
independent from the mission phase. However, it may vary 
depending on the individual human operator, as depicted in 
Figure 11 which shows the figures for two different 
operators. 
 
Figure 11.  Individual tightness in UAV guidance 
Operator A preferred to allow the UAV a higher degree 
of authority and defined only 38% of all task elements 
entries during the mission. While being faced with an 
unknown situation (phase C), the operator took back some 
of the authority by specifying the new tasks in more detail. 
Operator B specified 78% of all tasks elements and did 
not change that tight guidance level during the course of 
the mission. 
E. Subjective Measures 
In every simulation run, the simulation had been halted 
twice, i.e., in the ingress and during a demanding situation 
while the helicopter is near the hostile target area, to get 
measures of the operator’s workload using  ASA TLX 
[36]. During the simulation halt, all displays and the virtual 
pilot view were blanked and the intercom between pilot 
flying and pilot non-flying was disabled. To get an 
indication of the test persons’ situation awareness, the test 
persons were simultaneously questioned about the current 
tactical 
situations, 
system 
settings, 
e.g., 
radio 
configuration, and the upcoming tasks of the UAV and the 
manned helicopter. Furthermore, commander and pilot had 
to mark the positions of the manned helicopter, the UAVs 
and known ground forces in an electronic map. The 
specified positions were compared with the actual 
positions of the objects. This measure is an adaption of the 
SAGAT technique [29]. The test persons achieved a score 
of 100% for deviations less than 0.75 nm, 50% for 
deviations up to 1.5 nm and 0% for larger distances or if 
the object was missing. Only hostile ground forces objects 
were counted, because neutral ground forces are 
considered irrelevant to the mission progress [31].  
 
Figure 12.  Overall SAGAT measures 
Figure 12 depicts the distribution of this score. The 
commanders got an average score of 80% in this test.  
After every mission, a debriefing follows which 
includes questions about the system acceptance, system 
handling, interface handling as well as feedback about the 
degree of realism of the simulation environment. 
 
Figure 13.  Subjective Pilot Ratings for HMI / Consistency Management 
Figure 13 shows the subjective ratings of the test 
persons concerning the human machine interface and the 
automatic maintenance of a consistent task agenda, i.e., the 
automatic insertion of tasks. The representation of tasks as 
graphic elements on an interactive map was considered 
suitable for task monitoring and task manipulation. As 
depicted in Figure 13, one operator missed interfaces for 
time critical modification of tasks, especially a way to 
quickly assign low-level commands, e.g., heading and 
speed, to the UAV. The chosen type of human-machine 
interface and the automatic insertion of task elements to 
maintain a consistent agenda are generally accepted by all 
test persons. 
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
A
B
C
D
task elements from human operator
mission phase
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
A
B
C
D
task elements from human operator
mission phase
Operator A
Operator B
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
SA rating
hindering
surprising
wearing
Automatic Task Insertion
supportive
comprehensible
relieving
useless
necessary
time-consuming
time-saving
unpleasant
pleasant
unusable
highly usable
general interaction
target ident.
area recce
time crit. retasking
Human Machine Interface
156
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

The test persons stated that handling the UAVs 
consumed an average of 62% of the time while 34% 
remained for acting as commander of the manned 
helicopter. This indicates that the test persons felt the UAV 
guidance twice as demanding as supporting the pilot 
flying. However, the test persons also experienced the 
UAVs as highly supportive element for mission 
accomplishment, which outweighs the additional demands 
of guiding the unmanned aircraft. 
TLX measures of the commander range from 23% of 
subjective workload during the ingress over friendly 
territory up to a value of 60% during time-critical re-
planning of multiple UAV in the target area. 
VII. CONCLUSION 
This paper shows a way how operational knowledge 
can be encoded into an artificial cognitive system to allow 
the guidance of multiple UAV from the commander of 
manned helicopter. Task-based guidance, being the 
guidance concept advertised in this paper, shows high 
potential for embedding unmanned assets not just as 
additional 
complex 
automation 
but 
as 
artificial 
subordinates.  
The experiment provided evidence, that task-based 
guided 
UAVs 
can 
increase 
the 
overall 
mission 
performance and provide tactical advantages. The 
behavioural measures show that task-based guidance 
consumes only a moderate share of the operator’s mental 
resources, which allows him to remain in his role of the 
commander of the manned helicopter. Furthermore, the 
introduced adaptable tightness of UAV control is found to 
be intuitively used by the operators to balance the authority 
between the human and the UAV. 
Subjective 
measures 
and 
ratings 
indicated 
a 
manageable workload, a sufficient level of situation 
awareness as well as a good acceptance of task-based 
guidance. 
Fields that shall be addressed in future work are the 
handover and shared use of UAV capabilities. Thereby, 
UAVs could remain airborne over the operation area and 
human crews can request UAV services on demand. 
Furthermore, as reaction to emergencies, the human 
operator should use varying levels of automation, e.g., 
bypassing task-based guidance to directly set heading and 
altitude of a UAV. For that case, a methodology shall be 
developed that defines when and how the authority over 
the UAV can be reassigned to the artificial cognitive unit. 
The introduction of varying levels of automation may also 
incorporate the guidance of teams of UAVs [37], i.e., a 
single task can be assigned to multiple unmanned systems 
and those will define and distribute subtasks within the 
team. 
 
 
157
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

REFERENCES 
[1] J. Uhrmann and A. Schulte, “Task-based guidance of multiple 
UAV using cognitive automation,” in C G ITIVE 20   - The 
Third 
International 
Conference 
on 
Advanced 
Cognitive 
Technologies and Applications, T. Bossomaier and P. Lorenz, Eds, 
Rome, Italy, 2011, pp. 47–52. 
[2] C. Miller, H. Funk, P. Wu, R. Goldman, J. Meisner, and 
M. Chapman, “The Playbook™ approach to adaptive automation,” 
Ft. Belvoir: Defense Technical Information Center, 2005. 
[3] M. Valenti, T. Schouwenaars, Y. Kuwata, E. Feron, J. How, and 
J. Paunicka, “Implementation of a manned vehicle-UAV mission 
system”, 2004. 
[4]  .  orman, “The design of future things,” Basic Books, 2007. 
[5] D. D. Woods and N. B. Sarter, “Learning from automation 
surprises and ‘going sour’ accidents: Progress on human-centered 
automation,” Ohio State University, Institute for Ergonomics, 
Cognitive Systems Engineering Laboratory; National Aeronautics 
and Space Administration; National Technical Information Service, 
distributor, 1998. 
[6] I. Kaminer,  . Yakimenko, A. Pascoal, and R. Ghabcheloo, “Path 
generation, path following and coordinated control for timecritical 
missions of multiple UAVs,” in American Control Conference, 
2006, pp. 4906–4913. 
[7] S. Wegener, S.S. Schoenung, J. Totah, D. Sullivan, J. Frank, 
F. Enomoto, C. Frost, and C. Theodore, “UAV autonomous 
operations for airborne science missions”, in Proceedings of the 
American Institute for Aeronautics and Astronautics 3rd 
“Unmanned...Unlimited” Technical Conference, Workshop, and 
Exhibit, 2004. 
[8] A. Schulte and  .  onath, “Measuring self-adaptive UAV 
operators’ load-shedding strategies under high workload,” in 
EPCE'11 Proceedings of the 9th international conference on 
Engineering psychology and cognitive ergonomics, 2011, pp. 342–
351. 
[9] J. Uhrmann, R. Strenzke, A. Rauschert, and A. Schulte, “Manned-
unmanned teaming: Artificial cognition applied to multiple UAV 
guidance,” in  AT  SCI-202 Symposium on Intelligent 
Uninhabited Vehicle Guidance Systems, 2009. 
[10] J. Uhrmann, R. Strenzke, and A. Schulte, “Task-based guidance of 
multiple detached unmanned sensor platforms in military 
helicopter opertations,” in C GIS 20 0, 20 0. 
[11] R. Strenzke and A. Schulte, “The MMP: A mixed-initiative 
mission planning system for the multi-aircraft domain,” in 
Scheduling and Planning Applications woRKshop (SPARK) at 
ICAPS 2011, 2011. 
[12]  .  onath, A. Rauschert, and A. Schulte, “Cognitive assistant 
system concept for multi-UAV guidance using human operator 
behaviour models,” in Conference on Humans  perating 
Unmanned Systems (HUMOUS'10), 2010. 
[13] H. Putzer and R.  nken, “C SA - A generic cognitive system 
architecture based on a cognitive model of human behavior,” 
Cognition, Technology & Work, vol. 5, no. 2, pp. 140–151, 2003. 
[14] S. Brüggenwirth, W. Pecher, and A. Schulte, “ esign 
considerations for C SA2,” in Intelligent Agent (IA), 20   IEEE 
Symposium on Intelligent Agents, 2011, pp. 1–8. 
[15] R. D. Sawyer,.“The seven military classics of ancient china 
(history and warfare),“ Basic Books, 2007. 
[16] C. Miller, “ elegation architectures: Playbooks and policy for 
keeping operators in charge,” Workshop on Mixed-Initiative 
Planning and Scheduling, 2005. 
[17] R. Onken and A. Schulte, “System-ergonomic design of cognitive 
automation: Dual-mode cognitive design of vehicle guidance and 
control work systems,” Heidelberg: Springer-Verlag; 2010. 
[18] C. E. Billings, “Aviation automation: The search for a human-
centered approach,” Mahwah, N.J: Lawrence Erlbaum Associates 
Publishers, 1997. 
 
 
 
 
 
[19] H. Wandke and J.  achtwei, “The different human factor in 
automation: the developer behind versus the operator in action,” in 
Human factors for assistance and automation, D. de Waard, 
F. Flemisch, B. Lorenz, H. Oberheid, and K. Brookhuis, Eds, 
Maastricht, the Netherlands: Shaker Publishing, 2008, pp. 493–
502. 
[20] H. Eisenbeiss, “A mini unmanned aerial vehicle (UAV): system 
overview and image acquisition,” International Archives of 
Photogrammetry Remote Sensing and Spatial Information 
Sciences, vol. 36, no. 5/W1, 2004. 
[21] T. B. Sheridan and W. L. Verplank, “Human and Computer 
Control of Undersea Teleoperators,” Ft. Belvoir: Defense 
Technical Information Center, 1978. 
[22] Standard interfaces of UAV control system (UCS) for NATO UAV 
interoperability, STANAG 4586, NATO, 2007. 
[23] J. Uhrmann, R. Strenzke, and A. Schulte, “Human supervisory 
control of multiple UAVs by use of task based guidance,” in 
Conference 
on 
Humans 
Operating 
Unmanned 
Systems 
(HUMOUS'10), 2010. 
[24] M. Kriegel, S. Brüggenwirth, and A. Schulte, “Knowledge 
Configured Vehicle - A layered artificial cognition based approach 
to decoupling high-level UAV mission tasking from vehicle 
implementations,” in AIAA Guidance,  avigation, and Control 
Conference 2011, 2011. 
[25] G. Jarasch, S. Meier, P. Kingsbury, M. Minas, and A. Schulte, 
“ esign methodology for an Artificial Cognitive System applied to 
human-centred semi-autonomous UAV guidance,” in Conference 
on Humans Operating Unmanned Systems (HUMOUS'10), 2010. 
[26] Use of helicopters in land operations, NATO doctrine 49(E). 
[27] S. Puls, J. Graf, and H. Wörn, “Design and Evaluation of 
Description Logics based Recognition and Understanding of 
Situations and Activities for Safe Human-Robot Cooperation,” in 
International Journal On Advances in Intelligent Systems, vol. 4, 
no. 3 & 4, 2011. 
[28] J. Laird, A. Newell, and P. S. Rosenbloom, “Soar: An architecture 
for general intelligence,” Stanford, CA: Dept. of Computer 
Science, Stanford University, 1986. 
[29] M. R. Endsley, “Situation awareness global assessment technique 
(SAGAT),” in Aerospace and Electronics Conference, 1988, pp. 
789–795. 
[30] B. J. Biddle, “Recent  evelopments in Role Theory,” Annual 
Review of Sociology, vol. 12, no. 1, pp. 67–92, 1986. 
[31] R. Strenzke, J. Uhrmann, A. Benzler, F. Maiwald, A. Rauschert, 
and A. Schulte, “Managing cockpit crew excess task load in 
military manned-unmanned teaming missions by Dual-Mode 
Cognitive Automation approaches,” in AIAA Guidance  avigation 
and Control GNC Conference, 2011. 
[32] M. Goodrich and  .  lsen, “Seven principles of efficient human 
robot interaction,” in SMC'03 Conference Proceedings. 2003 IEEE 
International Conference on Systems, Man and Cybernetics. 
Conference Theme - System Security and Assurance (Cat. 
No.03CH37483): IEEE, 2003, pp. 3942–3948. 
[33] M. L. Cummings, C. E. Nehme, J. Crandall, and P. Mitchell, 
“Predicting operator capacity for supervisory control of multiple 
UAVs,” in Studies in Computational Intelligence, Innovations in 
Intelligent Machines - 1, J. Chahl, L. Jain, A. Mizutani, and M. 
Sato-Ilic, Eds.: Springer Berlin / Heidelberg, 2007, pp. 11–37. 
[34] M. L. Cummings and P. Mitchell, “Predicting controller capacity in 
supervisory control of multiple UAVs,” Systems, Man and 
Cybernetics, Part A: Systems and Humans, IEEE Transactions on, 
vol. 38, no. 2, pp. 451‐460, 2008. 
[35] D. R. Olsen Jr. and S. B. Wood, “Fan-out: measuring human 
control of multiple robots,” in Proceedings of the SIGCHI 
conference on Human factors in computing systems, 2004, pp. 
231‐238. 
[36] S. G. Hart and L. E. Staveland, “ evelopment of  ASA-TLX 
(Task Load Index): Results of empirical and theoretical research,” 
Human mental workload, vol. 1, pp. 139‐183, 1988. 
[37] A. Schulte, C. Meitinger, and R.  nken, “Human factors in the 
guidance of uninhabited vehicles: oxymoron or tautology?,” Cogn 
Tech Work, vol. 11, no. 1, pp. 71–86, 2009. 
158
International Journal on Advances in Intelligent Systems, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

