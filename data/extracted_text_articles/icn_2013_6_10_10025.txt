Consensus Problem in Stochastic Network Systems
with Switched Topology, Noise and Delay
Natalia Amelina
Faculty of Mathematics and Mechanics
St.Petersburg State University
St.Petersburg, Russia
Department of Telematics
Norwegian University of Science and Technology
Trondheim, Norway
Email: natalia amelina@mail.ru
Alexander Fradkov
Faculty of Mathematics and Mechanics
St.Petersburg State University
St.Petersburg, Russia
Institute of Problems in Mechanical Engineering
St.Petersburg, Russia
Email: fradkov@mail.ru
Abstract—This paper deals with the problem of achieving
consensus in decentralized stochastic network with switched
topology and noise and delays in measurements. To solve the
consensus problem of the group of interacting agents it was
supposed to use the stochastic approximation type algorithm with
the step-size non-decreasing to zero. Simulation results show the
quality of the algorithm.
Index Terms—consensus problem; stochastic networks; dis-
crete systems; network systems.
I. INTRODUCTION
The problems of control and distributed interaction in dy-
namical networks attracted more and more attention during
last decade. A number of survey papers [1], [2], monographs
[3], [4], [5], special issues of journals [6], [7], [8] and edited
volumes [9], [10] are published. An interest is driven by
applications to multiprocessor networks, transportation net-
works, production networks, coordinated control of motion
of ﬂying vehicles, submarines and mobile robots, distributed
systems of control of power networks, complex crystal lattices,
and nanostructured objects. In the presence of stochastic
disturbances and noise, the stochastic gradient-like (stochastic
approximation) methods have been used [11], [12], [13], [14],
[15], [16].
Despite of large number of publications, satisfactory so-
lutions are obtained only for a restricted class of problems
by now. Such factors as nonlinearity of agent dynamics
switching topology, noisy and delayed measurements may
signiﬁcantly complicate the solution. Additional important
factors are limited transmission rate in the channels and
quantizing (discretization) phenomenon. In presence of various
disturbing factors, asymptotically exact consensus may be
hard to achieve, especially in time-varying environment [17].
It those cases, approximate consensus problems should be
examined. In [18], the approximate consensus problem in
multi-agent stochastic systems with noisy information about
the current state of the nodes and randomly switched topology
for agents with nonlinear dynamics is considered.
This work is an extension of [18] to the case of multi-
agent systems with delays in measurements. Following [18],
we adopt an approach to analysis of stochastic multi-agent
systems based on using the averaged models of system dynam-
ics: the so-called method of averaged (discrete or continuous)
models [19], [20], [21], [22], [23], [24].
The paper is organized as follows. In Section II, the basic
concepts are introduced and an approximate mean-square con-
sensus problem is posed. In Section III, the basic assumptions
are described. The main results are presented in Section IV.
In Section V, an example of computer network is given and
the simulation results are provided. Section VI presents the
conclusion.
II. PRELIMINARIES: CONSENSUS PROBLEM ON
GRAPHS
Consider a dynamic network of a set of agents (nodes) N =
{1,2,...,n}.
Graph (N,E) is deﬁned by N and set edges E. Deﬁne the
set of neighbors of node i as Ni = { j : (j,i) ∈ E}, i.e. the set
of nodes with edges incoming to i. Associate with each edge
( j,i) ∈ E a weight ai, j > 0 and denote adjacency matrix (or
connectivity matrix) A = [ai, j] of graph, denoted hereinafter as
GA (hereinafter the index of variables shows the corresponding
number of nodes). Deﬁne the weighted in-degree of node i as
the i-th row sum of A: di(A) = ∑n
j=1 ai, j.
Endow each node i ∈ N at time t = 0,1,2...,T with a time-
varying state xi
t ∈ R with dynamics
xi
t+1 = xi
t + f i(xi
t,ui
t),
(1)
where f i(·,·) : R×R → R are some functions that depend on
the states in the previous time xi
t and on control actions ui
t ∈ R.
We consider the network (multi-agent) system consisting of
dynamic agents with inputs ui
t, outputs yi,i
t
and states xi
t.
Nodes i and j agree in a network at time t if and only if
xi
t = x j
t .
The consensus problem is the agreement of all nodes in
network, i.e., we have to ﬁnd a control protocol that drives all
states to the same constant steady-state values: xi
t = x j
t
∀i, j ∈
N,i ̸= j.
118
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

We assume that the structure of links of the dynamic
network is modeled by a sequence of directed graphs
{(N,Et)}t≥0, where Et ⊂ E change in time. If ( j,i) ∈ Et, then
we say that node i at time t obtains information from the node
j for the purposes of feedback control. Denote At as adjacency
matrix corresponding to Et; Emax = {( j,i) : supt≥0 ai, j
t
> 0} is
the maximum set communication links.
To form its control strategy each node uses its own state
(possibly noisy)
yi,i
t = xi
t +wi,i
t ,
(2)
and if Ni
t ̸= /0, noisy measurements of its neighbors states
yi, j
t
= x j
t−di,j
t +wi, j
t , j ∈ Ni
t ,
(3)
where wi,i
t ,wi, j
t
is the noise, 0 ≤ di, j
t
≤ ¯d is integer-valued delay,
¯d is a maximal delay.
Since the system starts working at t = 0 so implicit require-
ment to set of neighbors would be: j ∈ Ni
t ⇒ t −di, j
t
≥ 0. We
put wi, j
t
= 0 for all other pairs of i, j and denote ¯wt ∈ Rn2 as
a vector (matrix n × n which is written in rows as a vector)
consisting of elements wi, j
t , i, j ∈ N.
The control algorithm (protocol), called the local voting
protocol, is given by
ui
t = αt ∑
j∈ ¯Nit
bi,j
t (yi, j
t −yi,i
t ),
(4)
where αt > 0 are step-sizes of control protocol, bi, j
t
> 0 ∀j ∈
¯Ni
t . We set bi, j
t
= 0 for other pairs i, j and denote Bt = [bi, j
t ] as
the matrix of control protocol.
For the vector or matrix M denote the Frobenius norm:
||M|| = [Tr(MTM)]1/2, where Tr(·) is a trace (sum of the
diagonal elements) of matrix. In some cases for matrix A the
vector norm (square root of the sum of the squares of all its
elements) will be used, which we denote as ||A||2.
The n nodes to achieve asymptotic mean square consensus
if E||xi
t||2 < ∞,t = 0,1,..., i ∈ N and there exists a random
variable x⋆ such that limt→∞ E||xi
t −x⋆||2 = 0 for i ∈ N.
The n nodes to achieve ε-consensus if E||xi
t||2 < ∞, i ∈ N,
and there exists a random variable x⋆ such that E||xi
t −x⋆||2 ≤ ε
for all i ∈ N.
III. MAIN ASSUMPTIONS
Let (Ω,F,P) be the underlying probability space. Let E
be symbol of mathematical expectation and Ex be conditional
expectation under the condition x.
In the formulation of further results, we assume that the
following conditions are satisﬁed.
A1. ∀i ∈ N functions f i(x,u) are Lipschitz in x and u:
|f i(x,u)− f i(x′,u′)| ≤ L1(Lx|x−x′|+|u−u′|), the growth rate
is bounded: |f i(x,u)|2 ≤ L2(Lc + Lx|x|2 + |u|2), and for any
ﬁxed x the function f i(x,·) is such that Ex f i(x,u) = f i(x,Ex u);
Remark. A typical case when this condition holds is the
case when f i(x,u) is linear in control.
A2. a) ∀i ∈ N, j ∈ Ni the noises wi, j
t
are centered, indepen-
dent and have bounded variance: E(wi,j
t )2 ≤ σ2
w.
b) ∀i ∈ N, j ∈ Ni the appearances of variable edges (j,i) in
the graph GAt are independent random events with probability
pi, j
a
(i.e., matrices At are independent, identically distributed
random matrices).
c) ∀i ∈ N, j ∈ Ni weights bi, j
t
in the control protocol are
bounded random variables: b ≤ bi,j
t
≤ ¯b with probability 1,
and there exist limits bi, j = limt→∞ Ebi, j
t .
d) ∀i ∈ N, j ∈ Ni there exists a ﬁnite quantity
¯d ∈ N:
di, j
t
≤ ¯d with probability 1 and integer-valued delay di, j
t
—
independent, identically distributed random variables taking
values k = 0,..., ¯d with probability pi, j
k .
Moreover, all of these random variables and matrices are
independent of each other and their components have a limited
variance.
If ¯d > 0 we add new nodes to the current network topology
n ¯d. We add new “ﬁctitious” agents with states at time t equal
to the corresponding states of the “real” agents at the previous
¯d time: t −1,t −2,...,t − ¯d.
Denote ¯n = n( ¯d +1). Matrix Amax of size ¯n× ¯n is denoted
as:
ai,j
max = pi, jmod ¯d
j÷ ¯d
pi, jmod ¯d
a
bi, jmod ¯d, i ∈ N, j = 1,2,..., ¯n,
ai, j
max = 0, i = n+1,n+2,..., ¯n, j = 1,2,..., ¯n.
Here, the operation
mod is a remainder of the division, and
÷ is division without a remainder.
Note that if ¯d = 0 so this deﬁnition of network topology (of
matrix Amax of size n×n) is as follows
ai, j
max = pi, j
a bi, j, i ∈ N, j ∈ N.
If we consider the sequence of random matrices ¯At with
elements that deﬁne the connections at time t, then all of them
are identically distributed and the matrix Amax is in fact its
expectation (averaging).
We assume that the following condition is satisﬁed for the
network topology matrix:
A3. Graph (N,Emax) has a spanning tree, and for any edge
( j,i) ∈ Emax among the elements ai, j
max,ai, j+n
max ,...,ai, j+ ¯dn
max
of the
matrix Amax there exists at least one non-zero.
For t = 1,2,... we deﬁne an increasing sequence of σ-
algebras of probability of events
˜
Ft, generated by random el-
ements A1,...,At−1; di, j
1 , ...,di, j
t−1, bi, j
1 , ...,bi,j
t−1,wi, j
1 , ...,wi, j
t ,
i, j ∈ N, and Ft = σ{F A
t ,At;bi, j
t ,di, j
t ,i, j ∈ N}.
For a random variable Q and σ-algebra of probability event
F we use the notation EF Q for the conditional expectation
Q with respect to σ-algebra F.
Note that the random variables ¯xt are measurable with
respect σ-algebra Ft−1, i.e. EFt−1 ¯xt = ¯xt.
IV. ANALYSIS OF THE CLOSED LOOP SYSTEM
DYNAMICS
Denote ¯xt = [x1
t ;...;xn
t ]. Let ¯xt ≡ 0 for − ¯d ≤ t < 0, and de-
note ¯Xt ∈ Rn ¯d as extended state vector ¯Xt = [¯xt, ˜xt−1,..., ˜xt− ¯d],
where ˜xt−k is vector consisting of such xi
t−k that ∃ j ∈ Ni ∃k′ ≥
k : pi, j
k′ > 0, i.e. this value with positive probability involved in
119
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

the formation of at least one of the controls. To simplicity,
we assume that so introduced an extended state vector is
¯Xt = [¯xt, ¯xt−1,..., ¯xt− ¯d], i.e. it includes all the components with
all kinds of delays not exceeding ¯d.
Rewrite the dynamics of the nodes in vector-matrix form:
¯Xt+1 = U ¯Xt +F(αt, ¯Xt, ¯wt),
(5)
where U is the following matrix of size ¯n× ¯n:
U =







I
0
0
...
0
I
0
0
...
0
0
I
0
...
0
...
...
...
...
...
0
0
...
I
0







,
(6)
where I is the identity matrix of size n×n, and F(αt, ¯Xt, ¯wt) :
R×R¯n ×Rn2 → R¯n — vector function of the arguments:
F(αt, ¯Xt, ¯wt) =
=





···
f i(xi
t,αt ∑
j∈ ¯Nit
bi,j
t ((x j
t−di, j
t −xi
t)+(wi, j
t −wi,i
t )))
···
0n ¯d




,
(7)
containing a non-zero components only on the ﬁrst n places.
Consider the corresponding (5) averaged discrete model
¯Zt+1 = U ¯Zt +G(αt, ¯Zt), ¯Z0 = ¯X0,
(8)
where
G(α, ¯Z) = G


α,
z1
...
zn( ¯d+1)


 =




···
f i(zi,αsi( ¯Z))
···
0n ¯d



,
(9)
si( ¯Z) = ∑
j∈Ni
pi, j
a bi, j((
¯d
∑
k=0
pi, j
k zj+kn)−zi) =
= −di(Amax)zi +
¯n
∑
j=1
ai, j
maxzj, i ∈ N.
It turns out that the trajectory of solutions of the initial
system { ¯Xt} from (5) at time t are close in mean square sense
to the average trajectory of the discrete system (8).
Theorem 1: If conditions A1, A2 are satisﬁed, then there
exists ˜α such that for 0 < αt ≤ ¯α < ˜α the following inequality
holds:
E max
0≤t≤T || ¯Xt − ¯Zt||2 ≤ c1τTec2τ2
T ¯α,
(10)
where τT = 2 ¯d(α0 + α1 + ... + αT−1), c1,c2 > 0 are some
constants:
c1 = 8n

˜c+ ˆc(nL2Lc + ¯α2 ˜c
c3
+|| ¯X0||2)eT ln(c3+1)

,
˜c = n2L2
1¯b2σ2
w, c2 = 21− ¯dL2
1(Lx
α +2 ¯α2||L (Amax)||2
2),
c3 = ˜d +Lx(21+ ˜d/2L1 +L2)+ ¯αc′, ˆc = 2L2
1n(n−1)¯b2,
c′ = 21+ ˜d/2L1||L (Amax)||2 + ¯α(L2||L (Amax)||2
2 + ˆc),
α = min
1≤t≤T αt, ˜d = 0 if ¯d = 0, or ˜d = 1 if ¯d > 0.
Note that in case without delays in the measurement ( ˜d = 0)
and if Lx = 0 then constant c3 which is deﬁned in Theorem 1
is estimated by the value proportional to ¯α and therefore
constant c1 is estimated by the value proportional to τT, which
corresponds to the previously obtained results for this case
from [21], [19].
Proof:
Denote
vt = F(αt, ¯Xt, ¯wt)−G(αt, ¯Xt).
(11)
By condition A2 averaging with respect to σ-algebras F d
t and
Ft yields EFtvt = 0.
To proof Theorem 1, the following facts will be useful.
Proposition 1:
||U ¯X||2 ≤ 2 ˜d|| ¯X||2, ..., ||U ¯d ¯X||2 ≤ 2 ¯d|| ¯X||2, ..., ||Uk ¯X||2 ≤
≤ 2 ¯d|| ¯X||2,
Proof: By the deﬁnition of matrix U it is easy to obtain
the ﬁrst inequality, and the rest we get by induction on k and
by the following equality
∀k > ¯d Uk = U ¯d =





I
0
0
...
0
I
0
0
...
0
...
...
...
...
...
I
0
0
...
0




.
(12)
Proposition 2: By assumptions A2 the following inequality
holds
E max
1≤t≤T ||
t
∑
i=1
vt||2 ≤ 4n
T
∑
t=1
E||vt||2.
Proof:
Under the conditions A2 random elements vt are martingale
differences, i.e., they are centered with respect to the condi-
tional averaging of the background: EFt−1vt = 0. So, Lemma 1
from section 3 of [25] is applicable. The dimension of vectors
vt is n ¯d, but since only the ﬁrst n components of vectors vt are
nonzero, then it is possible to use in the estimation the value
of n instead of n ¯d.
Proposition 3: Let the sequence of numbers µt ≥ 0, t =
0,1,...,T satisﬁes the inequalities
µt+1 ≤ ¯αc1τt +c22 ¯dτt
t
∑
k=1
γkµk, c1,c2 ≥ 0,
then
µt ≤ c1τtec2τ2t ¯α.
Proof: Statement of Proposition follows directly from the
corresponding result in [26]
Proposition 4: [18] For ¯z ∈ Rn and matrix Amax the fol-
lowing inequality holds ∑n
i=1(∑ j∈Ni ai, j
maxzj)2 ≤ ||Amax||2
2||¯z||2.
120
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

Proposition 5: [18] ||¯s(¯z)||2 ≤ 2||L (Amax)||2
2||¯z||2.
Proposition 6: [18]
If
A2
is
satisﬁed
then
si(¯x) =
1
αt EFt−1ui
t and the following inequality holds
1
α2t EFt−1ui
t
2 ≤
(n−1)¯b2||¯xt −xi
t1||2 +n¯b2σ2
w, i ∈ N.
Proposition 7: By assumptions A1, A2 yields
E|| ¯Xt||2 ≤ (2nL2 + ¯α2 ˜c
c3
+|| ¯X0||2)et ln(c3+1).
Proof: We write equation (5) as
¯Xt+1 = U ¯Xt +G(αt, ¯Xt)+vt.
(13)
For the squared norm of ¯Xt+1 we have
|| ¯Xt+1||2 = ||U ¯Xt +G(αt, ¯Xt)||2+2(U ¯Xt +G(αt, ¯Xt))Tvt +||vt||2.
(14)
Taking the conditional expectation of both parts of (14) on
σ-algebra Ft−1 (i.e. for ﬁxed ¯Xt) by the centrality of vt we
obtain
EFt−1|| ¯Xt+1||2 = ||U ¯Xt +G(αt, ¯Xt)||2 +EFt−1||vt||2 ≤
≤ 2||U ¯Xt||2 +2||G(αt, ¯Xt)||2 +EFt−1||vt||2.
(15)
By the form of vt and Lipschitz in u of functions f i(u) (by
A1) for ||vt||2 we have
||vt||2 = ∑
i∈N
|f i(xi
t,αt ∑
j∈ ¯Nit
bi, j
t (x j
t−di,j
t −xi
t +wi, j
t −wi,i
t ))−
−f i(xi
t,αtsi
t( ¯Xt))|2 ≤ L2
1|| ¯ut −α2
t ¯st||2.
Under the conditions A2, random variables EFt−1ui
t, i ∈ N
satisfy the conditions of Proposition 6
EFt−1||vt||2 = α2
t L2
1(2n(n−1)¯b2|| ¯Xt||2 +n2¯b2σ2
w).
(16)
Consistently evaluating all three summands on the right
hand side of (15) and taking into account the results of
Propositions 1, 5 and 6, we deduce
EFt|| ¯Xt+1||2 ≤ 2 ˜d|| ¯Xt||2 +21+ ˜d/2|| ¯Xt||L1(Lx|| ¯Xt||+αt||¯s||)+
+L2(nLc +Lx|| ¯Xt||2 +α2
t ||¯s||2)+α2
t L2
1(2n(n−1)¯b2|| ¯Xt||2+
+n2¯b2σ2
w) ≤ (2 ˜d +21+ ˜d/2L1Lx+L2Lx+αt21+ ˜d/2L1||L (Amax)||2+
+α2
t (L2||L (Amax)||2
2 +2n(n−1)L2
1¯b2))|| ¯Xt||2 +nL2Lc+
+α2
t n2L2
1¯b2σ2
w ≤ ¯c+ ¯c3|| ¯Xt||2,
where ¯c = nL2Lc +α2
t ˜c, ¯c3 = c3 +1.
By taking unconditional expectation of both parts of this
inequality and consistently iterating on t, we obtain Proposi-
tion 7
E|| ¯Xt||2 ≤ ¯c+ ¯c3E|| ¯Xt−1||2 ≤ ¯c+ ¯c¯c3 + ¯c2
3E|| ¯Xt−2||2 ≤
≤ ¯c(1+ ¯c3 + ¯c2
3 +...+ ¯ct−1
3
)+ ¯ct
3|| ¯X0||2 ≤ ¯c ¯ct
3 −1
c3
+ ¯ct
3|| ¯X0||2 ≤
≤
 ¯c
c3
+|| ¯X0||2

¯ct
3 ≤ (¯c4 +|| ¯X0||2)et ln ¯c3,
¯c4 = ¯c/c3.
Let us turn to the proof of Theorem 1. By iterating equa-
tion (5) for t,t −1,...t −d +1 we obtain
¯Xt+1 = U ¯Xt +G(αt, ¯Xt)+vt =
= U2 ¯Xt−1 +UG(αt−1, ¯Xt−1)+G(αt, ¯Xt)+Uvt−1 +vt = (17)
= ··· = Ut+1 ¯X0 +
t
∑
k=0
Ut−kG(αk, ¯Xk)+
t
∑
k=0
Ut−kvk.
Similarly we obtain
¯Zt+1 = Ut+1 ¯X0 +
t
∑
k=0
Ut−kG(αk, ¯Zk).
(18)
Let us estimate || ¯Xt − ¯Zt||2, t = 1,...,T. By subtracting (18)
from (17) and squaring the result we obtain
|| ¯Xt − ¯Zt||2 = ||
t
∑
k=1
Ut−kvk+
t
∑
k=1
Ut−k(G(αk, ¯Xk)−G(αk, ¯Zk))||2 ≤
≤ 2||
t
∑
k=1
Ut−kvk||2 +2||
t
∑
k=1
Ut−k(G(αk, ¯Xk)−G(αk, ¯Zk))||2 ≤
≤ 2||
t
∑
k=1
Ut−kvk||2+2 τt
2 ¯d
t
∑
k=1
1
αt
||Ut−k(G(αk, ¯Xk)−G(αk, ¯Zk))||2.
(19)
For the summands in the second sum of (19) using Propo-
sitions 5, 1 and Lipschitz condition f i(·,·) (assumption A1)
we obtain
||Ut−k(G(αk, ¯Xk)−G(αk, ¯Zk))||2 ≤ 2 ¯dL2
1
n
∑
i=1
(Lx|xi
k −zi
k|+
+αk|s(xi
k)−s(zi
k)|)2 ≤ 21+ ¯dL2
1
n
∑
i=1
Lx|xi
k −zi
k|2+α2
k s(xi
k −zi
k)2 ≤
≤ 21+ ¯dL2
1(Lx +2α2
k ||L (Amax)||2
2)|| ¯Xk − ¯Zk||2
We take expectation of both parts of (19) and denote
µT = max
0≤t≤T E|| ¯Xt − ¯Zt||2. By applying Proposition 2 to the ﬁrst
summand and obtained above estimate of the second summand
we obtain
µT ≤ 23+ ¯dn
T
∑
k=1
E||vk||2 +2τTL2
1
t
∑
k=1
(Lx
α +2αk||L (Amax)||2
2)µk.
(20)
To estimate E||vk||2 by using previously obtained relation (16)
and the result of Proposition 7 we deduce
E||vk||2 ≤ α2
k (˜c+ ˆc(¯c4 +|| ¯X0||2)ekln(c3+1))
and hence
23+ ¯dn
T
∑
k=1
E||vk||2 ≤ ¯α8nτT(˜c+ ˆc(¯c4 +|| ¯X0||2)eT ln(c3+1)).
(21)
By the following relation 2 ¯d ∑t
k=1 α2
k ≤ ¯α2 ¯d ∑t
k=1 αk = ¯ατt,
considering estimates (21) from (20), we have
EµT ≤ ¯αc1τT +c2τT2 ¯d
T
∑
k=1
αkEµk.
(22)
121
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

From last inequality (22) by applying Proposition 3 we get
the conclusion of Theorem 1.
Theorem 2: Let the conditions A1, A2 be satisﬁed; 0 <
αt ≤ ¯α; in averaged discrete system (8)
ε
4-consensus is
achieved for time T and for constants c1, c2 from Theorem 1
the following estimate holds
c1τTec2τ2
T ¯α ≤ ε
4,
then ε-consensus is achieved in stochastic discrete system (5)
at time t.
Proof: Denote x⋆ as consensus value of discrete sys-
tem (8). From the ﬁrst group of conditions of Theorem 2
the conditions of Theorem 1 hold. From other conditions of
Theorem 2 and the result of Theorem 1 we obtain
E|| ¯Xt −x⋆1||2 ≤ 2E|| ¯Xt − ¯Zt||2 +2|| ¯Zt −x⋆1||2 ≤ ε
2 + ε
2 ≤ ε.
Consider an important particular case ∀i ∈ N f i(x,u) = u and
αt = α = const, in which the discrete averaged system (8) has
the form:
¯Zt+1 = (I −((I −U)−L (αAmax)))Zt.
(23)
Theorem 3: If conditions A2, A3 are satisﬁed; αt = α > 0;
f i(x,u) = u for any i ∈ N and condition α <
1
dmax for matrix
Amax is satisﬁed, then asymptotic mean square consensus for
n nodes in averaged discrete system (23).
Moreover if ε
4-consensus is achieved for the time T( ε
4) in
averaged discrete system (23) and there exist T > T( ε
4) for
which the parameter α provides the condition
¯C1e ¯C2α ≤ ε
4,
¯C1 = 8n

˜c+ ˆc(α2 ˜c
c3
+|| ¯X0||2)eT ln(c3+1)

τt,
¯C2 = 22− ¯dα2||L (Amax)||2
2, ˜c = n2¯b2σ2
w, ˆc = 2n(n−1)¯b2τ2
t ,
c3 = 21+ ˜d +2α2(||L (Amax)||2
2 + ˆc),
where ˜d = 0 if ¯d = 0, or ˜d = 1 if ¯d > 0.
then ε-consensus at time t : T( ε
4) ≤ t ≤ T is achieved in
stochastic discrete system (5).
Proof:
The result of Theorem 3 is derived from Theorem 2.
All amounts in rows of elements of the matrix
¯
L =
(I −U)−L (αAmax) are equal to zero and, moreover, all the
diagonal elements are positive and equal to the absolute value
of the sum of all the other elements in the row, which are
negative. Hence the matrix
¯
L is the Laplacian of a graph and
a vector of 1’s 1 is the right eigenvector corresponding to zero
eigenvalue.
By condition A3, the graph corresponding to the Laplacian
¯
L has a spanning tree. By condition A3 graph of the ﬁrst n
nodes has a spanning tree. And units on (n + 1)-th diagonal
consistently connect ¯n-th node with (¯n− ¯d)-th node, (¯n−1)-
th node with (¯n − ¯d − 1)-th and so on. Hence asymptotic
consensus is achieved in such a discrete system since the
condition α <
1
dmax holds by the assumptions of Theorem 3.
To satisfy the conditions of Theorem 2 it remains to show
that the constants ¯C1 and ¯C2 are the same as the corresponding
constants from Theorem 1. It follows from the fact that in this
case L1 = L2 = 1, Lx = Lc = 0.
Note that in [11], under certain assumptions similar to
the conditions of Theorem 3, the necessary and sufﬁcient
condition for achieving mean square consensus in case when
step-sizes αt tending to zero was proved. More general case of
the form of functions f i(xi
t,ui
t) and step-sizes αt not tending
to zero were considered above.
V. EXAMPLE
To illustrate the theoretical results we give an example the
computer network.
We consider the system of separation the same type of jobs
between different agents for parallel computing with feedback.
Denote N = {1,...,n} as a set of intelligent agents, each of
which serves the incoming requests a ﬁrst-in-ﬁrst-out queue.
Jobs are received at different times and on different nodes.
At any time t state of agent i, i = 1,...,n is described by
two characteristics:
• qi
t is queue length of the atomic elementary jobs of the
node i at time t;
• pi
t is a productivity of the node i at time t.
The dynamics of each agent are described by
qi
t+1 = qi
t − pi
t +zi
t +ui
t; i ∈ N, t = 0,1,...,T,
(24)
where zi
t is the new job received by node i at time t, ui
t is
the result of information redistribution between agents, which
is obtained by using the selected protocol of information
redistribution. In the dynamics we assume that ∑i ui
t = 0, t =
0,1,2,....
We assume that to form the control strategy each agent i ∈ N
at time t can receive from its neighbors j ∈ Ni
t the following
information:
• the noisy observations about its queue length
yi,i
t = qi
t +wi,i
t ,
(25)
• the noisy and delayed observations about its neighbors
queue length, if Ni
t ̸= /0
yi,j
t
= qj
t−di,j
t +wi, j
t , j ∈ Ni
t ,
(26)
where wi, j
t
are noises, 0 ≤ di, j
t
≤ ¯d is integer-valued delay,
¯d is a maximal delay,
• the information about its productivity pi
t and about its
neighbors productivity pj
t , j ∈ Ni
t .
In the stationary case from all possible options for all job
redistribution, which are not distributed by the time t, then
minimum operation time of the system corresponds to
qi
t/pi
t = qj
t /p j
t , ∀i, j ∈ N
(27)
122
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

So if we take xi
t = qi
t/pi
t as a state of agent i in dynamic
network, then the control gain — to achieve consensus in
network — will correspond to the optimal job redistribution
between agents in the stationary case [27]. Let the fraction
qit
pit denote the load of agent i at time t. Thus, it is enough
to consider the problem of how to keep the equal load of all
agents in the network.
Assume that pi
t ̸= 0∀ i. Consider the control protocol (4),
where ∀ i ∈ N, ∀ t denote ¯Ni
t = Ni
t and bi,j
t
= pj
t /pi
t, , j ∈ Ni
t .
As an example of such system consider the simulation for
the computer network consisting of six computing agents.
We set the initial queue lengths, the productivities of agents
and some initial network topology. Let pt
j be constant ∀t.
For the considered case the dynamics of closed loop sys-
tem (24) with local voting protocol (4) is as follows:
xi
t+1 = xi
t −1+zi
t/pi
t +αt ∑
j∈Nit
bi, j
t (yi, j
t /pj
t −yi,i
t /pi
t).
(28)
where αt are step-sizes of control protocol, yi, j
t
noisy and
delayed observation about j-th agents queue length, zi
t is the
new job received by agent i at time t.
In Fig. 1, we can see the system operation in nonstationary
case with local voting protocol (4). It means that new jobs can
come to different nodes during the system work. We can see
that the income of new jobs do not affect to the quality of the
system work. It is a big advantage of the algorithm.
Fig. 1.
The dynamics of the agents xi
t for nonstationary case.
VI. CONCLUSION
In this paper, an approximate consensus problem for net-
works of nonlinear agents with switching topology, noisy and
delayed measurements was studied. In contrast to the existing
stochastic approximation-based control algorithms (protocols)
local voting protocols with nonvanishing step size are pro-
posed. Nonvanishing (e.g., constant) step size ensures better
transients in the time-invariant case and provides bounded
error in the case of time-varying loads and agent states.
The price to pay is replacement of the almost sure or mean
square convergence with an approximate one. To analyze
dynamics of the closed loop system the so-called method of
the averaged models is used. It allows to reduce complexity
of the closed loop system analysis. In the paper new upper
bounds for mean square distance between initial system and
its approximate average model are proposed. The proposed
upper bounds are used to obtain conditions for approximate
consensus achievement.
This work was carried out during the tenure of an ERCIM
“Alain Bensoussan” Fellowship Programme. The research
leading to these results has received funding from the Eu-
ropean Union Seventh Framework Programme (FP7/2007-
2013) under grant agreement No. 246016. Also the work was
supported by Russian Federal Program “Cadres” (agreements
8846, 8855), by RFBR (project 11-08-01218) and also by the
SPRINT laboratory of SPbSU and Intel Corp.
REFERENCES
[1] R. Olfati-Saber, J. Fax, and R. Murray, “Consensus and cooperation in
networked multi-agent systems,” Proceedings of the IEEE, vol. 95, no. 1,
pp. 215–233, 2007.
[2] W. Ren, R. Beard, and E. Atkins, “Information consensus in multivehicle
cooperative control,” Control Systems, IEEE, vol. 27, no. 2, pp. 71–82,
2007.
[3] C. Wu, Synchronization in complex networks of nonlinear dynamical
systems.
World Scientiﬁc Publishing Company Incorporated, 2007.
[4] W. Ren and R. Beard, Distributed consensus in multi-vehicle cooperative
control: theory and applications.
Springer, 2007.
[5] F. Bullo, J. Cort´es, and S. Martinez, Distributed control of robotic
networks: a mathematical approach to motion coordination algorithms.
Princeton University Press, 2009.
[6] P. Antsaklis and J. Baillieul, “Guest editorial special issue on networked
control systems,” Automatic Control, IEEE Transactions on, vol. 49,
no. 9, pp. 1421–1423, 2004.
[7] C. Abdallah and H. Tanner, “Complex networked control systems:
introduction to the special section,” Control Systems, IEEE, vol. 27,
no. 4, pp. 30–32, 2007.
[8] P. Antsaklis and J. Baillieul, “Special issue on technology of networked
control systems,” Proceedings of the IEEE, vol. 95, no. 1, pp. 5–8, 2007.
[9] D. Armbruster, Networks of Interacting Machines: Production Orga-
nization in Complex Industrial Systems and Biological Cells.
World
Scientiﬁc Publishing Company Incorporated, 2005, vol. 3.
[10] I. Kalaev and E. Melnik, Decentralized computer control systems.
Rostov on Don: UNC RAN, 2011.
[11] M. Huang, “Stochastic approximation for consensus: a new approach via
ergodic backward products,” IEEE Transactions on Automatic Control,
vol. 57, no. 12, pp. 2994–3008, 2012.
[12] R. Olfati-Saber and R. Murray, “Consensus problems in networks of
agents with switching topology and time-delays,” Automatic Control,
IEEE Transactions on, vol. 49, no. 9, pp. 1520–1533, 2004.
[13] W. Ren and R. Beard, “Consensus seeking in multiagent systems under
dynamically changing interaction topologies,” Automatic Control, IEEE
Transactions on, vol. 50, no. 5, pp. 655–661, 2005.
[14] J. Tsitsiklis, D. Bertsekas, and M. Athans, “Distributed asynchronous de-
terministic and stochastic gradient optimization algorithms,” Automatic
Control, IEEE Transactions on, vol. 31, no. 9, pp. 803–812, 1986.
[15] M. Huang and J. Manton, “Coordination and consensus of networked
agents with noisy measurements: stochastic algorithms and asymptotic
behavior,” SIAM Journal on Control and Optimization, vol. 48, no. 1,
pp. 134–161, 2009.
[16] T. Li and J. Zhang, “Mean square average-consensus under measure-
ment noises and ﬁxed topologies: Necessary and sufﬁcient conditions,”
Automatica, vol. 45, no. 8, pp. 1929–1936, 2009.
[17] N. Amelina, A. Lada, I. Mayiorov, P. Skobelev, and A. Tsarev, “Cargo
transportation models analysis using multi-agent adaptive real-time truck
scheduling system,” Problemy Upravleniya, vol. 6, pp. 31–37, 2011.
[18] N. Amelina, A. Fradkov, and K. Amelin, “Approximate consensus in
multi-agent stochastic systems with switched topology and noise,” in
Proc. IEEE 2012 Multiconference on Systems and Control (MSC2012),
Dubrovnik, Croatia, 2012, pp. 445–450.
123
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

[19] D. Derevitskii and A. Fradkov, Applied theory of discrete adaptive
control systems.
Moscow: Nauka, 1981.
[20] H. Kushner, “Convergence of recursive adaptive and identiﬁcation
procedures via weak convergence theory,” Automatic Control, IEEE
Transactions on, vol. 22, no. 6, pp. 921–930, 1977.
[21] D. Derevitskii and A. Fradkov, “Two models for analysis the dynamics
of adaptation algorithms,” Automation and Remote Control, no. 1, pp.
59–67, 1974.
[22] L. Ljung, “Analysis of recursive stochastic algorithms,” Automatic
Control, IEEE Transactions on, vol. 22, no. 4, pp. 551–575, 1977.
[23] S. Meerkov, “On simpliﬁcation of slow markovian walks description,”
Automation and Remote Control, no. 3, pp. 6–75, 1972.
[24] A. Fradkov, “Continuous-time averaged models of discrete-time stochas-
tic systems: Survey and open problems,” in Proc. 2011 50th IEEE
Conference on Decision and Control and European Control Conference
(CDC-ECC).
Orlando, Florida, USA: IEEE, 2011, pp. 2076–2081.
[25] I. Gihman and A. Skorohkod, Stochastic Differential Equations.
Kiev:
Nauk. dumka, 1968.
[26] S. Bernstein, “Stochastic difference equations and stochastic differential
equations,” Sobr. soch. in 4-th Vol., vol. 4, pp. 484–542, 1964.
[27] N. Amelina and A. Fradkov, “Approximate consensus in the dynamic
stochastic network with incomplete information and measurement de-
lays,” Automation and Remote Control, vol. 73, no. 11, pp. 1765–1783,
2012.
124
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

