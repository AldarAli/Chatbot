Active Surgeon Support during Orthopedic Surgery using the BOrEScOPE-
Exoskeleton: System Design and First Results 
Peter P. Pott, Markus Hessinger, Roland 
Werthschützky,  
Helmut F. Schlaak 
Institute of Electromechancial Design 
Technische Universität Darmstadt 
Darmstadt, Germany 
p.pott@emk.tu-darmstadt.de 
m.hessinger@emk.tu-darmstadt.de 
werthschuetzky@emk.tu-darmstadt.de 
schlaak@emk.tu-darmstadt.de 
Eugen Nordheimer, Essameddin Badreddin,  
Achim Wagner 
Institute of Computer Engineering, Automation Lab 
Heidelberg University  
Heidelberg, Germany 
eugen.nordheimer@ziti.uni-heidelberg.de 
badreddin@ziti.uni-heidelberg.de  
achim.wagner@ziti.uni-heidelberg.de 
 
 
Abstract— A great number of medical robotics projects is 
driven by researchers all around the globe. Aim is to enhance 
surgery output, accelerate the procedure or to shorten post-
operative convalescence. In most cases, the surgeon interacts 
with a machine directly by some kind of remote control in 
general soft tissue surgery or robotic systems recapitulate pre-
programmed trajectories, e.g., during milling of cavities. One 
option to achieve a better acceptance in human robot 
interaction systems in operating theatre is to use exoskeletons 
for tight integration. This is widely accomplished in body 
rehabilitation to provide patients with continuous passive or 
active motion. However the way to commercial application is 
long for many systems. In this paper for an anthropomorphic 
upper extremity exoskeleton worn by the surgeon during 
orthopedic interventions (e.g., pedicle drilling) first results 
concerning control strategy and user guidance are presented. 
The system is intended to enhance overall task-precision as the 
surgeon is guided by optic, acoustic, and haptic perception. 
The parallel flux of forces and the inherently wearable robot 
base attached to his back allow the surgeon to directly 
maintain responsibility for surgery. The mechanical design as 
well as the control strategy are described briefly. The device 
provides seven concentric axes and uses conventional DC 
motors and wire gears to deliver torque. An optical tracking 
system is employed to provide low-latency absolute position 
data of the system and the patient. A User Guidance Opto-
Acoustic Display is utilized to provide the surgeon with 
information on position and orientation of the tool in six 
degrees of freedom with respect to the desired trajectory. The 
control strategy is decomposed into several levels. First 
experiments have demonstrated the correlation between 
provided workspace and space requirements during pedicle 
screw placement and an intuitive handling of the user guidance 
system to follow a desired trajectory. 
Keywords- exoskeleton, orthopedic surgery, human-machine 
interaction, behavior-based system decomposition 
I. 
 INTRODUCTION 
Parts of this work have been previously published at the 
7th International Conference on Advances in Computer-
Human Interactions (ACHI 2014), March 23-27 2014, 
Barcelona, Spain [1]. 
Medical robotic systems for the use in the OR have been 
under development for more than 20 years [2]. Early systems 
for neurosurgery [3] [4] and orthopedics [5] proved 
usefulness and even made it for commercialization. 
However, their impact was not as high as expected [6]. In the 
last ten years, many new robotic systems have been 
developed and even introduced to the market. The most 
successful is the daVinci Surgical System by Intuitive 
Surgical, Inc., Sunnyvale, CA, USA. Nevertheless, there are 
hundreds of different systems [2] and many specific reviews 
e.g., by Nguyen [7], Taylor and Stoianovici [8], Cleary and 
Stoianovici [9], Korb [10], Cepolina [11], Kuo [12], Vitiello 
[13], Dhumane [14] to learn more about the various fields of 
robotics. 
The aim of our work is to develop and to design a robotic 
interaction system for orthopaedic surgery. Here, the surgeon 
has to fulfil delicate tasks like drilling the spine while 
maintaining high precision in the sub-millimetre range. 
Placing a cooperating robotic arm next to the OR table [15], 
the ceiling [16] or even on the patient [17] does not seem to 
be appropriate. The primary reason is that such systems 
either require rather large space next to the table, have to be 
rigidly installed in the OR reducing flexibility of use, or tend 
to hinder the approach to the situs due to their mounting in 
the third case. Earlier work of our group showed the high 
potential of placing the robot in the user’s hand [18] [19] to 
compensate tremor and involuntary movements both from 
surgeon and patient [20]. This robotic system provides 
precise movement and ease-of-use. However, its size and 
weight are not appropriate for longer deployment. Instead of 
using a passive balancing system for the handheld device or 
even a separate cooperating robot placed next to the OR 
table, as both approached would be bulky and space 
consuming, we decided to develop a new system worn at the 
surgeon’s arm near to his or her centre of gravity to improve 
ergonomic handling. This is intended to lead to a better 
acceptance of and control over the system by the surgeon. 
In the following sections, we will present and describe 
the system’s concept, basic components, the control strategy 
(all in Section II), first results (Section III), and a conclusion 
(Section IV).  
272
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

II. 
SYSTEM DESIGN 
In this paper, we provide an overview of the 
BOrEScOPE system. It comprises an external optical high-
speed tracking system for six Degrees Of Freedom (DOF), 
position and orientation measurement fused with data from 
an Inertial Measurement Unit (IMU), the robotic system 
including actuation and sensor systems together with the 
mechanical part, the control hard- and software, and finally 
an opto-acoustic display unit for interactive user guidance. In 
the following sections, we will address these sub-systems 
and describe the control strategy.  
A. Robotic System 
The robotic system of the BOrEScOPE basically consists 
of an exoskeleton for the (right) arm of the surgeon including 
shoulder and wrist (Fig. 1). All together,  seven active DOF 
are realized to provide good compliance with the human 
anatomy and the same dexterity. The range of motion of the 
shoulder (170° abd./add.; 150° flex./ex.; 180° inw./outw. 
rotation), elbow (100° flex.), and wrist (150° pron./sup.; 20° 
ulnar flex./ex.; 120° flex./ex.) joints has been derived 
experimentally. Shoulder elevation is not considered as the 
abduction angle is reduced to 80°. The arm is attached to a 
backpack that is carried by shoulder and hip harness.  
To achieve a lightweight mechanism in the final version, 
the actuators are placed in the backpack and force is 
transmitted via Bowden cables. The actuators will be based 
on the twisted string-concept [21], using a bunch of at least 
two strings that are twisted axially by a DC motor. This 
causes the string-arrangement to shorten and produces a  
 
 
Figure 1. Overview of the robotic sub-system of the BOrEScOPE 
consisting of the actual exoskeleton, a 3D measurement camera, control 
computer, and patient (shown as spinal column only). 
rather high force. Using a lightweight  17 mm DC motor 
(1741 024 CXR by Faulhaber, Schönaich, Germany) with 
8 mNm nominal torque and three strings, a force of 130 N 
can be produced. Also, no traditional gear reduction is 
needed leading to very quiet operation.  
As only pulling forces can be produced, an antagonistic 
arrangement is used. Sensors are deployed at the string 
actuator to measure contraction and at the actuated joint to 
provide precise angle information. By doing so, the elasticity 
of the Bowden cable is used to derive a series-elastic actuator 
(SEA) [22]. Prior work of our group showed good results 
using SEA in human machine interaction [23]. The inherent 
compliance allows zero-torque control and robust reaction to 
dynamic external forces. This reduced stiffness “feels better” 
than a conventional robotic arm. 
The final system will be designed to carry a 2.5 kg 
payload of a surgical device [24] and compensate the gravity 
force of the human arm up to a body weight of 80 kg. 
Shoulder and elbow joints can provide speeds up to 6 rad/s. 
The static force to guide the user can be up to 10 N at the 
handle. 
B. Opto-Acoustic Display 
One of the challenges in developing a user-friendly 
Graphical User Interface (GUI) for the Human Machine 
Interaction (HMI) is to facilitate an intuitive operation and 
control of the technical system. The basic requirements are to 
reduce the possible error occurring during user interaction 
with the machine and to navigate the user. Since the tool 
position is influenced by the human tremor (frequency range 
of several Hertz), and since latencies in the feedback-loop 
must be avoided, a dynamical tool tracking is proposed, 
consisting of a combination of optical and inertial motion 
measurements. Based on these data the User Guidance Opto-
Acoustic Display (UGOAD) is realized, which navigates the 
user to the goal pose (position and orientation), displays the 
processing trajectory, and gives a feedback of pose errors. 
Display and measurement latency has to be kept low to 
reduce phase shift in the feedback loop and to provide stable 
overall system behavior. The goal 6D poses as well as the 
processing trajectories are provided from planning data, 
which are defined by the surgeon using 3D patient imaging 
(CT). According to the requirements, a first UGOAD 
functional prototype was realized (see Fig. 2).  
 
 
Figure 2. Experimental environment for the first handheld prototype of the 
opto-acoustic display (UGOAD) deployed in the BOrEScOPE system. 
Camera coordinate system
Base coordinate system
Image coordinate system
Patient coordinate system
Tool coordinate system
Shoulder
joint
Elbow
joint
Wrist
joint
Robot-mounted
optical display
Experimental handheld
drill°
Marker for optical
tracking
Counter weight
Inertial measurement
unit (IMU)
Krypton optical tracking
system
273
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

The experimental handheld drilling tool (Fig. 2), on the 
left) was equipped with three active optical LED markers 
and an IMU device (Crista IMU, Cloud Cap Technology, 
Inc.). The miniature monitor (Fig. 2, on the right) mounted at 
the distal end of the system can provide both optical and 
acoustic information. In the final implementation, a 
lightweight miniaturized screen will be attached directly to 
the tool. The optical tracking system (Krypton K600, Nikon 
Metrology, Inc.) (Fig. 2, in the background) is used in 
addition to the Crista IMU to collect the motion data of the 
handheld device. Data fusion is accomplished using Kalman-
filter based methods [25]. The resulting filtered variables for 
position, orientation, velocities, angular rates, and linear 
acceleration are utilized for navigation purposes and 
provided to the lower levels. In later development stages the 
display can be mounted and aligned to the exoskeleton. The 
6 DOF user navigation is realized by 2D representations of 
the tool pose on the UGOAD which is described below in 
detail. 
C. Control Structure 
The control system is developed according to Nested 
Recursive Behavior-based Control (RNBC) structure [26]. 
Accordingly, the hardware is realized as a number of 
components (Fig. 3) interacting on diverse behavioral levels. 
In contrast to a one-to-one mapping of the behavior levels, 
one single behavior level can be distributed on multiple 
hardware components. Several behavior levels may be 
aggregated in one single hardware device. In the latter case, 
behaviors are realized as software processes. For the 
BOrEScOPE realization, the upper levels, i.e., mission, 
navigation and trajectory control, are realized as software 
processes integrated into a QNX-based (QNX Software 
Systems Ltd.) real-time PC. The behavior levels for position 
control, collision avoidance, velocity control and force 
control are realized using an embedded PC based on xPC  
Target™ (The Mathworks, Inc.). The xPCTM Target PC is 
interconnected with the QNX PC via a serial link and to the 
motor controllers (type EL7342 by Beckhoff Automation, 
Verl, Germany) via EtherCAT. The motor controllers 
directly control the currents of the actuators. Position 
constraints for link actuation are calculated using the robot 
kinematics in order to avoid internal collisions. Additionally, 
external ultrasonic (US) sensors can help to avoid collisions 
of the robot with its environment. A milling tool can be 
aligned with the patient coordinate frame and a target bone 
can be processed with the preplanned trajectory. 
To achieve compliance with the behavior of the operator, 
three interaction modalities are realized: The opto-acoustic 
display provides optical (1) and acoustical output (2) while 
the robot provides haptic feedback (3). The control 
algorithm’s input is a virtual static force field generated 
around the main axis of the bore and depending on the actual 
distance, speed and direction of movement of the 
BOrEScOPE’s end effector [27, 28]. When the patient is 
moving, this force field also moves in space. To achieve 
smooth and comfortable movement, the real force acting 
between BOrEScOPE and the wrist are measured. The user 
tries to minimize the forces following the BOrEScOPE 
system. 
Using this algorithm, the 7 DOF redundant robotic system 
can be controlled easily and intuitively while maintaining 
Human 
operator
Touchscreen
Speaker
Haptics
Robot
QNX real-time 
control PC
xPC target
Embedded PC
EtherCAT 
motor
controllers
Pre-op
planning data
Inertial
measurement
unit
Optical 
tracking
system
Ultrasonic
sensors
Patient
seeing
touching
haptic
perception
forces
hearing
pose
user
controls
alarms
cone
tool force
OP data
distance
pose
pose
torque
angle
motor signals
status
trajectory
constraints
forces
physical interaction
Physical
interaction
Figure 3. System architecture of the BOrEScOPE system. The human operator interacts with the robotic system, which interacts with the patient. This latter 
interaction is measured by a number of sensors while the first is based on audio, visual, and haptic effects. 
274
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 4. First Prototype of the BOrEScOPE system as a CAD drawing. 
 
the human’s dexterity. As both, the linear displacement at the 
actuators and the angular displacement in the actual joints 
are measured and controlled, serial-elastic actuation is 
achieved. 
III. 
RESULTS 
The BOrEScOPE system is still under development. The 
two main sub-systems opto-acoustic display and robotic 
system show first and promising results that are described in 
the following. 
A. Robotic System 
The mechanical sub-system of the BOrEScOPE is shown 
in Fig. 4. The device features the same seven axes as a 
human arm and can be adjusted to persons between roughly 
165 and 200 cm body height and a BMI under 30. It is worn 
around the arm and thus provides congruent axes. To allow 
this for the axial rotation of upper and lower arm, special 
wire ball bearings (LEL 1.5/5 by Franke GmbH, Aalen, 
Germany) have been chosen for a lightweight, strong, and 
backlash-free solution for these two DOF. For first 
experiments, conventional DC gear-motors (shoulder joint: 
3890 048 CR+38/2 S, elbow joint: 3272 048 CR+32/3 S, 
wrist joint: 2657 048 CR+26/1 S) and wire-gearing have 
been chosen to reduce development effort while still 
accounting for backlash-free smooth motion with constant 
friction. The range of motion of the shoulder (100° abd./add.; 
90° flex./ex.; 180° inw./outw. rotation), the elbow (105° 
flex.) and wrist (150° pron./sup.; 35° ulnar flex./ex.; 90° 
flex./ex.) fits in the requirements of the operational task. Its 
force is capable to maneuver payload up to 1 kg safely 
within the complete range of motion. The device can be 
worn by the surgeon using a backplate and a rucksack-like 
arrangement of straps and belts. 
A first realization of the 3-DOF wrist of the robot is 
shown in Fig. 5. Here, especially the wire-geared actuation 
principle and the structural integration of the torque sensors 
is visible. The structural integration allows high-stiffness 
measurement with no additional masses or elasticity. It is 
achieved by integrating full-bridge strain gauges to the wire-
gearing mechanism in a way that the pulling force of the 
wire is measured. 
B. Opto-Acoustic Display 
The measured peak response time of hand movement as a 
result of optical stimuli amounts to around 250 ms. The 
requirement of visually provided information should be 
adapted on this process time. The reaction time of the 
UGOAD as well as the robot must be kept within a limit of 
10-20 ms (10 to 20-fold faster). Thus, the calculation of 
graphical contents and of the control algorithm should 
terminate within this time. Based on this knowledge, the 
sensor data acquisition, the global-control loop, and UGOAD 
were implemented as real-time processes in the QNX 
Neutrino operating system.  
The first display prototype was realized by a 2D 
representation of the 6 DOF pose data. Accordingly, the 
actual and the reference pose of the tool are shown in the x-
y-plane of the display. The z-axis is perpendicular to the 
display plane. In order to intuitively capture the 6 DOF 
contents in the 2D image a two body projection metaphor is 
 
 
Figure 5. First realisation of the wrist. The three axes intersect in one point 
in the centre of the human wrist (not shown). 
Pronation supination axis, ±150°
Ulnar Flexion/Extension axis ±35°
Flexion Extension axis ±90°
Hand grip w/ tool interface
Structural integration of
torque sensors
Wire gearing
Wire ball bearing
275
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

realized. In this imagination one small colored octagon is 
mounted virtually at the tool tip and one large colored  
octagon at the rear of the tooling machine. Looking from 
above in direction of the drilling tool (z-axis) corresponds to 
looking through the large octagon and through the small 
octagon on the tool tip, which is in the center of both. The 
small black octagon with crosshairs and large black octagon 
are virtually mounted at the target (reference) pose. If the 
tool is aligned (Fig. 6a), the small octagons are aligned and 
the large colored octagon has its original size in the central 
position. If the tool is misaligned in the x-axis (Fig. 6b) the 
large colored octagon is shifted correspondingly in the x-
direction. The same holds for the y-axis. A misalignment in 
the z-axis is represented by the size of the large colored 
octagon. A deviation in the positive z-direction means that 
the tool is too far away from the user, which is shown by the 
reduced size relatively to the large black octagon. Negative 
deviation displays an increased size of the octagon to report 
that the tool is too narrow. A deviation in the orientation is 
displayed as shift of the small colored octagon. For 
example, if the tool is turned around the y-axis (Fig. 6), the 
tool tip is moved in x-direction, displayed as x-axis-shift of 
the small colored octagon. The corresponding principle 
holds for the orientation error around the x-axis. Here, a y-
shift of the small octagon can be observed. The orientation 
error around the z-axis is directly displayed as a rotation of 
the colored octagons around their centers. 
As additional element, a rectangular border is shown in 
green color, which indicates that the pose is in the desired 
workspace. If the tool approximates the limit positions for at 
least one axis, the color changes firstly from green to orange, 
showing that a user intervention is required. In critical 
vicinity to the constraints the color changes to red (Fig. 6d) 
asking for urgent motion actions. The color change is 
supported by changing the waveform of the acoustic channel. 
C. User Experiments 
Several experiments with subjetcs (users) have been 
performed resulting in a first performance test of the 
UGOAD. The goal was to keep the handheld drill (Fig. 2) 
still in position and orientation in six DOF while looking at 
the UGOAD only and at the tool-tip exclusively in guided 
(assisted) and unguided (unassisted) case, respectively. The 
user himself chose the holding comfortable pose. Substantial 
results of these trials are presented for two users exemplary. 
User1: 
The first human operator (user 1) was requested twice to 
hold the tool calmly during 60 seconds. Firstly, without 
UGAOD assistance and secondly after short instruction and 
training with the UGOAD. The results point out that it was 
possible to keep the tool in the defined workspace (5 mm in 
position-axes and 5° in orientation-axes) in assisted attempt 
(blue trajectory, Fig. 7). Unassisted the workspace was left 
after short time and the trajectory was drifted in all axes (red 
trajectory, Fig. 7). To evaluate the position errors the histo-  
Figure 6. Display content of the UGOAD (refer to Fig. 2): a) Correct 
position and orientation, b) Translational displacement in x-axis, c) 
Rotational displacement around x- and y-axis, d) Displacement in all view 
axes. 
grams for both cases with and without UGOAD are 
represented in one plot (Fig. 8). 
Without assistance, the position is distributed over a wide 
range according to the non-stationary process. With 
UGOAD feedback the human-in-the-loop position control 
reaches as stationary condition, while the remaining position 
error has a distribution with an approximately Gaussian  
 
Figure 7. Position deviation in xy-direction with and without guide with the 
human operator (user1) in the loop (without the robotic sub-system). z-axis 
deviation is not shown for reasons of brevity. 
 
a)
b)
c)
d)
276
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 8. Position y-deviation histogram for guided and unguided trial of 
user1 (instructed). 
 
shape. The histograms show the posed distribution together 
with a fit using the normal distribution in one dimension 
while the standard deviation and the mean of the distribution 
are σ =1.3529 and μ = -0.2039 for the case with UGOAD 
and σ = 6.606 and μ = -12.0661 for the case without 
UGOAD, respectively. 
User2: 
Another human operator (user 2) was also requested 
twice to hold the tool also calmly during 60 seconds. In both 
cases, the UGOAD was used. In contrast to the former 
experiment, user2 was not instructed about the operating 
principle of the UGOAD so that the user had to find it out by 
himself during trial 1. Nevertheless, it was possible to keep 
the tool inside the workspace (blue trajectory, Fig. 9). The 
second trial shows the learning effect in operation (red 
trajectory, Fig. 9). 
The histograms show also Gaussian shapes for both trials 
with UGOAD while the standard deviation and the mean of 
the distribution are σ = 1.8460 and μ = -3.9976 for trial 
1 and σ =0.8879 and μ = -0.4686 for trial 2, respectively 
(Fig. 10). 
It is obvious that using the opto-acoustic display a strong 
improvement of the pose deviation was achieved (here 
presented for two different axes and operators). 
IV. 
DISCUSSION AND CONCLUSION 
To set up a robotic system with close human-machine 
interaction in a medical environment is a delicate task. 
However, the project is still in progress and work starting 
from the presented concept to the final realization is still 
ongoing. We managed to define interfaces between the 
robotic system and the human operator not only 
mechanically, but also visually and using the audio channel. 
Smooth and comfortable working with the system is strongly 
dependent on low latency, high update rates, and actually 
predictable behavior. Here, our system will have to deal with 
some drawbacks as the force field generation is depending 
on data quality of the optical tracking system which tends to 
Figure 9. Position deviation in xy-direction for two trials with guide with 
the human operator (user2) in the loop (without the robotic sub-system). 
jitter and noisy signals. This will be addressed in future by 
using redundant LED markers and by combining data of an 
inertial tracking system. Furthermore, the quality of real-time 
data transfer will be improved. 
Mechanically, the robot will have to cope with force-
depended friction wire gearing and residual backlash in the 
gearing. This issue will be addressed by a model-based 
controller with individual parameters for each axis. The first 
prototype shown in Fig. 4 differs slightly from the initial 
concept due to time restriction during development. 
However, the schedule of the first tests of the complete 
system is set and first promising objectives have been 
reached.  
First experiments with users demonstrate that the 6 DOF-
guidance can be captured by the majority of subjects 
 
Figure 10. Position x-deviation histogram for guided trials of user2 
(uninstructed). 
277
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

without further explanation (Fig. 6). Thus, the usage of the 
UGOAD as a feedback in the human interaction with the 
machine implicates a massive improvement of human 
performance to achieve the common tasks and there is every 
indication that the developed UGOAD insure an intuitive 
operation and an intuitive control. 
ACKNOWLEDGMENT 
The work is funded by the German Federal Ministry of 
Education and Research under grants 16SV5773 and 
16SV5774. 
REFERENCES 
[1] 
P. P. Pott, M. Hessinger, R. Werthschützky, H. F. Schlaak, 
E. Nordheimer, E. Badreddin, and A. Wagner, "BOrEScOPE 
– Exoskeleton for Active 
Surgeon Support during 
Orthopedic Surgery," Proc. 7. International Conference on 
Advances in Computer-Human Interactions (ACHI 2014), 
Barcelona, pp. 377-380,  2014. 
[2] 
P. P. Pott, H.-P. Scharf, and M. L. R. Schwarz, "Today's 
State of the Art of Surgical Robotics," Journal of Computer 
Aided Surgery, vol. 10, pp. 101-132, 2005. 
[3] 
Y. Kwoh, I. Reed, J. Chen, H. Shao, T. Truong, and E. 
Jonckheere, "A new computerized tomography-aided robotic 
stereotaxis system," Robotics Age, pp. 17-22, 1985. 
[4] 
J. Doll, W. Schlegel, O. Pastyr, V. Sturm, and W. Maier-
Borst, "The use of an industrial robot as a stereotactic 
guidance system," Proc. International Symposium and 
Exhibition on Computer Assisted Radiology (CAR 87), 
Berlin, D,  1987. 
[5] 
R. H. Taylor, et al., "An Image-Based Roboitc System for 
Hip Replacement Surgery," Journal of the Robotics Society 
of Japan, pp. 111-116, 1990. 
[6] 
C. Caetano da Rosa, Operationsroboter in Aktion. Bielefeld, 
Germany: transcript Verlag, 2013. 
[7] 
K. Cleary and C. Nguyen, "State of the art in surgical 
robotics: Clinical Applications and Technology Challenges," 
Computer aided Surgery, vol. 6, pp. 312-328, 2001. 
[8] 
R. Taylor and D. Stoianovici, "Medical Robotics in 
Computer-Integrated Surgery," IEEE Transactions on 
Robotics and Automation, vol. 19, pp. 765-781, 2003. 
[9] 
K. Cleary, D. Stoianovici, V. Watson, R. Cody, B. Hum, and 
D. Lindisch, "Robotics for Percutaneous Spinal Procedures: 
Initial Report," Proc. Computer Aided Radiology and 
Surgery, San Francisco, USA,  2002. 
[10] W. Korb, R. Marmulla, J. Raczkowsky, J. Mühling, and S. 
Hassfeld, "Robots in the operating theatre—chances and 
challenges," Int. J. Oral Maxillofac. Surg., vol. 33, pp. 721-
732, 2004. 
[11] F. Cepolina, B. Challacombe, and R. C. Michelini, "Trends 
in robotic surgery," J Endourol, vol. 19, pp. 940-51, Oct 
2005. 
[12] C.-H. Kuo and J. S. Dai, "Robotics for Minimally Invasive 
Surgery: A Historical Review from the Perspective of 
Kinematics," in International Symposium on History of 
Machines and Mechanisms, H.-S. Yan and M. Ceccarelli, 
Eds., ed: Springer Science+Business Media B.V., 2009, pp. 
337-354. 
[13] V. Vitiello, S.-L. Lee, T. Cundy, and G.-Z. Yang, "Emerging 
Robotic Platforms for Minimally Invasive Surgery," IEEE 
reviews in Biomedical Engineering, vol. 6, pp. 111-126, 
2013. 
[14] P. W. Dhumane, M. Diana, J. Leroy, and J. Marescaux, 
"Minimally invasive single-site surgery for the digestive 
system: A technological review," J Minim Access Surg, vol. 
7, pp. 40-51, 2011. 
[15] M. Jakopec, S. J. Harris, F. R. Baena, P. Gomes, J. Cobb, 
and B. L. Davies, "The First Clinical Application of a 
"Hands-on" Robotic Knee Surgery System," Computer 
Aided Surgery, vol. 6, pp. 329-339, 2001. 
[16] H. Mayer, I. Nagy, A. Knoll, E. U. Schirmbeck, and R. 
Bauernschmitt, "A robotic system providing force feedback 
and automation for minimally invasive heart surgery," Proc. 
20th International Congress and Exhibition on Computer 
Assisted Radiology and Surgery CARS 2006, Osaka, Japan, 
pp. 265-267,  2006. 
[17] M. Shoham, M. Burman, E. Zehavi, and Y. Kunicher, 
"MARS: 
miniature 
bone-mounted 
robot," 
Proc. 
ISRACAS'2003, Tel Aviv, Israel,  2003. 
[18] P. P. Pott, et al., "ITD - A handheld manipulator for medical 
applications - Concept and design," Proc. 3rd annual meeting 
of CAOS, Marbella / Spain, pp. 290-291,  2003. 
[19] P. P. Pott, A. Wagner, E. Badreddin, H.-P. Weiser, and M. L. 
R. Schwarz, "Inverse Dynamic Model and a Control 
Application of a Novel 6-DOF Hybrid Kinematics 
Manipulator," Journal of Intelligent and Robotic Systems, 
vol. 63, pp. 3-23, 2010. 
[20] A. El-Shenawy, A. Wagner, P. P. Pott, and E. Badreddin, 
"Disturbance Attenuation of a Handheld Parallel Robot," 
Proc. IEEE ICRA, Karlsruhe,  2013. 
[21] T. Würtz, C. May, B. Holz, C. Natale, G. Palli, and M. C, 
"The Twisted String Actuation System: Modeling and 
Control," Proc. IEEE/ASME International Conference on 
Advanced Intelligent Mechatronics, Montréal, Canada, pp. 
1215-1220,  2010. 
[22] K. Kong, J. Bae, and M. Tomizuka, "Control of Rotary 
Series Elastic Actuator for Ideal Force-Mode Actuation in 
Human-Robot 
Interaction 
Applications," 
IEEE/ASME 
Transactions on Mechatronics, vol. 14, pp. 105-118, 2009. 
[23] M. Grün, R. Müller, and U. Konigorski, "Model Based 
Control of Series Elastic Actuators," Proc. IEEE Biomedical 
Robotics and Biomechatronics (BioRob), Rome, Italy, pp. 
538-543,  2012. 
[24] M. Hessinger, J. Hielscher, P. P. Pott, and R. Werthschützky, 
"Handheld surgical drill with integrated thrust force 
recognition," Proc. E-Health and Bioengineering Conference 
(EHB), Iasi, RO,  2013. 
[25] N. Sadaghzadeh, L. Zouaghi, A. Wagner, J. Poshtan, and E. 
Badreddin, "Cascaded Error Estimation and Compensation 
of an Inertial Measurement Unit using the Fusion of Optical 
and Inertial Sensors," Proc. COMADEM, Helsinki,  2013. 
[26] E. Badreddin, "Recursive Control Structure for Mobile 
Robots," 
Proc. 
International 
Conf. 
on 
Intelligent 
Autonomous Systems 2 (IAS.2), Amsterdam, pp. 11-14,  
1989. 
[27] A. Wagner, E. Nordheimer, and E. Badreddin, "Hierarchical 
constraint-based singularity avoidance," Proc. System 
Theory, Control and Computing (ICSTCC), Sinaia,  2012. 
[28] O. Khatib, "Real-time obstacle avoidance for manipulators 
and mobile robots," The International Journal of Robotics 
Research, vol. 5, pp. 90-98, 1986. 
 
278
International Journal on Advances in Life Sciences, vol 6 no 3 & 4, year 2014, http://www.iariajournals.org/life_sciences/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

