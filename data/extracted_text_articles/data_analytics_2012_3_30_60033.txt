Analysis of Streaming Service Quality Using Data Analytics of Network Parameters 
Jie Zhang 
Dept. Computer Engineering  
Kangwon National University 
ChunCheon, Korea 
zarg_1982@hotmail.com 
Hwa-Jong Kim 
Dept. Computer Engineering  
Kangwon National University 
ChunCheon, Korea 
hjkim3@gmail.com 
Doo-Heon Ahn 
Dept. Computer Engineering  
Kangwon National University 
ChunCheon, Korea 
arcarpe@daum.net
 
 
Abstract—Quality of multimedia streaming service depends on 
network parameters such as bandwidth, delay, jitter and pack-
et loss rate. In order to effectively improve the Quality of Ser-
vice (QoS), it is needed to know which parameter is dominant 
in deterioration of the service quality at the moment. In the 
paper, we investigate the interdependency among network 
parameters in terms of finding out which parameter is domi-
nant in the quality deterioration. We also studied the sensitivi-
ty of parameters on the change of quality in an emulated com-
munication network. For these purposes, we performed exper-
imental tests on streaming video with 16 testers, and we used 
transformed 5-level values for each network parameter to imi-
tate a Likert style evaluation for each variable. It is found that 
bandwidth and delay affect more on service quality than jitter 
or loss rate.  
Keywords-Data analytics; Network parameter; Quality of 
Service; Streaming service 
I. 
 INTRODUCTION 
During the last decades, quality management of real-time 
communications has been widely studied in order to provide 
improved multimedia services [1] [2]. With rapid develop-
ment in audio-visual technology and products, various types 
of TV-based multimedia services have been introduced in-
cluding high definition TV (HDTV). Recently, along with 
the wide spread of high speed cellular networks and wireless 
LANs, mobile multimedia services also became common for 
the tablet PC or Smartphone users. The increased wireless 
multimedia service is known as the key source of network 
traffic and service dissatisfaction [3] [4] [5].  
The purpose QoS control in network service is to satisfy 
users. To satisfy the users, we should consider many factors 
simultaneously such as contents searching time, download 
speed, screen size, and contents itself, beside the network 
parameters such as bandwidth, delay, error rate or jitter. 
However we cannot satisfy all the resources simultaneously, 
so it is needed to prioritize factors to support. For example, 
we may choose large screen for some movies, high band-
width for high quality image, and low jitter for conversations. 
For a given quality level, we need to choose optimal combi-
nation of network resources.  
In the paper, we analyze simulation test data in order to 
find which network parameter dominantly affected service 
quality at the moment. In other words, we want to under-
stand the relationship between quality factors in streaming 
service. However, it is difficult to take into account various 
network parameters and human factors together in the analy-
sis because it is difficult to extract correct relationship be-
tween user satisfaction and the factor such as screen size, 
search time, download speed exactly. Therefore, in the paper, 
we considered only four typical network parameters (band-
width, delay, jitter, and loss rate). As a further study, we can 
extend the number of factors in the dependency analysis fol-
lowing the rationale proposed in the paper.  
The paper is organized as follows. Chapter 2 introduces 
related works for QoS studies. Chapter 3 describes an exper-
iment for QoS related user experiment and result analysis 
follows on chapter 4. Chapter 5 is for conclusion and further 
works. 
II. 
RELATED WORKS 
QoS measurement for multimedia services has been 
widely studied to find an optimized network environment [6]. 
Kostas E. Psannis, Yutaka Ishibashi and Marios G. 
Hadjinicolaou presented an approach for multimedia stream-
ing services, which used priority including dedicated band-
width, controlled jitter for video interactive services that re-
quire additional resources to provide differently encoded 
video [7]. The research showed how the encoded bit rate and 
its bandwidth give influence to the video quality. Liuming 
Lu, Xiaoyuan Lu, Jin Li monitored stream video quality by 
observing packet losses, and showed how the packet loss 
ratio affects the quality of video streaming services [8].  
Most typical network parameters used in the QoS analy-
sis are bandwidth, delay, loss rate and jitter [6]. Bandwidth is 
the most significant parameter in multimedia streaming ser-
vice, delay can cause unsynchronized video/audio frames, 
packet loss would be the reason of video error, and jitter may 
cause frame bursting. However, it is rarely studied to consid-
er the parameters together in order to find their dependencies. 
In the paper, we focused on finding the relative importance 
of the four parameters in streaming service. 
III. 
SIMULATION MODEL 
In the paper, we measured the quality levels for video 
streaming service via simulation. The simulation model is 
composed of three parts: the streaming server, network simu-
lator and client PC. Figure 1 shows the simulation model 
used in the paper. 
A. The streaming server 
The streaming server provides video contents. A standard 
HD (1280x720 resolutions with 30 frames per second) video 
is sent to the clients through a simulated network. 
76
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-242-4
DATA ANALYTICS 2012 : The First International Conference on Data Analytics

B. The Network simulator 
The Network simulator is used to emulate a real network. 
We used simulation package Shunra Cloud [9]. The package 
can change the bandwidth, delay, loss rate and jitter via 
software settings. We can choose any value of network pa-
rameters. For example, we can modify the channel capacity 
to have any bit rate, e.g., 10Mbps or 7Mbps. If the server is 
transmitting a 9Mbps video stream, the 10Mbps channel 
would be enough. However, if the bandwidth is set to be 
7Mbps, then it will suffer a shortage of bandwidth. In simu-
lation, we used various channel speed (bandwidth) ranging 
from, for example, 5Mbps to 10Mbps, and monitored the 
video quality with different bandwidth settings.  
We also can choose any value for delay, loss rate and jit-
ter for network emulation. With this scheme, we can have 
infinite number of sets for combinations (b, d, j, l) where b, d, 
j and l represent specific value of bandwidth, delay, jitter and 
loss rate respectively. In order to investigate the effect of 
each parameter to the video quality with a finite number of 
simulations, we need to minimize the number of parameter 
set. For this purpose, we chose discrete values for each b, d, j, 
and l.   
 
 
 
Figure 1.  Simulation model. 
In order to choose a reasonable finite number of parame-
ter sets, we divided the range of each parameter into 5 quali-
ty levels (mimicking the Likert levels). For example, for the 
bandwidth parameter, first we set other parameter to have 
best conditions, that is, no delay, no error, and no jitter. Then 
we decrease the channel capacity (bandwidth) from 10Mbps 
down smoothly to find the Mean Opinion Score (MOS) 
evaluation to be 4 from 16 testers. Table 1 shows the 5 MOS 
threshold values for bandwidth, delay, loss rate and jitter. In 
the first column, when bandwidth is over 8.06Mbps, many 
people evaluated MOS 5, and with bandwidth of 
7.85~8.06Mbps, many people evaluated the MOS to be 4, 
and so on. Below 7.47Mbps, many people evaluate MOS to 
be 1. In the evaluation we used the MOS such as, 5: Best, 4: 
Good, 3: Moderate, 2: Bad, 1: Worst. 
 
 
 
TABLE I.  
LEVELS OF NETWORK PARAMETERS FOR EXPERIMENT 
Likert
Bandwidth(Mbps)
Delay(ms) 
Loss(%) 
Jitter(ms) 
5 
8.06~ 
~257 
~0.11 
~28 
4 
7.85~8.06 
257~359 
0.11~0.15 
28~55 
3 
7.75~7.85 
359~423 
0.15~0.17 
55~140 
2 
7.47~7.75 
423~455 
0.17~0.21 
140~188 
1 
~7.47 
455~ 
0.21~ 
188~ 
 
Along the same way, we chose 5 discrete regions of de-
lay, jitter and loss rate (see Table 1). Among the 5 classes of 
parameter levels, we used only 4 levels in simulation because 
any level-1 value of each parameter always generated intol-
erable video quality.  
We then have in total 4(parameter) ^ 4(level) = 256 com-
bination sets (b, d, j, l) to measure the effects of each param-
eter sets to the quality of service at the moment.  
C. Client PC  
At the client PC, testers evaluated the streaming video 
quality. In the simulation, we used a simple binary quality 
measurement that only evaluates the quality as “Good” or 
“Bad” [10] in order to find out the percentile of dissatisfac-
tion of users, or “unacceptability rate”. For example, if one 
tester out of the 16 testers notified “Bad”, the unacceptability 
rate is 1/16= 6.25% at the moment. If two people showed 
“Bad”, then the unacceptability rate becomes 2/16=12.5% 
IV. 
SIMULATION RESULTS 
Figures 2-5 show the simulation result, where X axis rep-
resents the unacceptability rate evaluated by the 16 testers. Y 
axis denotes the probability of occurrence of network param-
eters (b, d, j, l) for different quality levels; i.e., b5 is a typical 
value of bandwidth for Best (e.g., over 8.06Mbps), b4 for 
Good (e.g. 7.85~8.06Mbps), b3 for Moderate, and b2 for 
Bad.  
For example, in Figure 2, at unacceptability rate 6.25% 
(at the most left-hand side), b5 occurred 3 times out of four 
tests (3/4=0.75), and b4 occurred once (1/4=0.25). Y axis 
denotes the probability of occurrence of bandwidth levels, 
and X axis denotes the unacceptability rate, where TL (Trend 
Line) is approximation plot of the dots. Here unacceptability 
rate 6.25% means a good quality because only one tester out 
of 16 felt Bad quality, and 15 felt Good. When the video is in 
good quality (i.e., when low unacceptability rate in X axis), 
there is no low level of bandwidth (b2) cases (in Figure 2, 
the “x” marks the presence of b2). As long as the video qual-
ity is decreasing (i.e., unacceptability rate increase in the X 
axis), we can find more occurrence of b2 (see the trend line 
“TL-b2” in Figure 2 is increasing along with the X axis). 
When the unacceptability rate increases, we can find low 
occurrence of b5 (see the trend line ‘TL-b5” is decreasing in 
Figure 2). This represents that video quality is strongly de-
pendent on the bandwidth levels in the various combination 
set of (b, d, j, l).  
Figure 3 shows the dependency of delay levels (d5~d2) 
on the video quality. Y axis denotes the probability of delay 
and X axis denotes the unacceptability rate. In Figure 3, we 
can find strong dependency of delay on the video quality 
because as the unacceptability rate increase, the TL-d5 de-
77
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-242-4
DATA ANALYTICS 2012 : The First International Conference on Data Analytics

creases down and the TL-d2 increase up sharply. We can 
find Figure 3 shows similar pattern to Figure 2, which means 
that delay affects the video quality in a similar manner like 
bandwidth.  It is noted that the levels (b5~b2) or (d5~d2) 
were determined from a level normalization process as 
summarized in table 1.  
Dependency of jitter and loss on the video quality are 
shown in Figures 4 and 5, respectively. From Figures 4 and 5, 
it is shown that jitter and loss did not affect much on the vid-
eo quality. It can be said that jitter is less sensitive to the 
quality of video comparing to the bandwidth or delay.  
 
 
Figure 2.  Dependency of bandwidth levels (b5~b2) on the video quality. 
Y axis denotes the probability of bandwidth levels, and X axis denotes the 
unacceptability rate, where TL (Trend Line) is approximation plot of the 
dots. 
 
Figure 3.  Dependency of delay levels (d5~d2) on the video quality. Y axis 
denotes the probability of delay levels, and X axis denotes the 
unacceptability rate, where TL (Trend Line) is approximation plot of the 
dots.  
 
Figure 4.  Dependency of jitter levels (j5~j2) on the video quality. Y axis 
denotes the probability of jitter levels, and X axis denotes the 
unacceptability rate, where TL (Trend Line) is approximation plot of the 
dots.  
 
Figure 5.  Dependency of loss levels (l5~l2) on the video quality. Y axis 
denotes the probability of loss levels, and X axis denotes the 
unacceptability rate, where TL (Trend Line) is approximation plot of the 
dots.  
 
Figure 6.  Comparison of the sensitivity of (b, d, j, l) to the 
quality variation (unacceptability rates). 
 
78
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-242-4
DATA ANALYTICS 2012 : The First International Conference on Data Analytics

Figure 6 compares the sensitivity of (b, d, j, l) to the qual-
ity variation (unacceptability rates). In Figure 6, the X axis 
shows the number of experiment cases under the assumption 
of that the distribution of each level of parameter is even. In 
other words, under the same distribution of parameter values, 
we can see that as the video quality is decreasing (going right 
in the X axis) the bandwidth gives more influence (i.e., sen-
sitive) to the quality comparing to other parameters. The next 
sensitive parameter is delay and the next one is jitter.  
V. 
CONCLUSION AND FURTHER WORKS 
In the paper, we compared the influence of network pa-
rameters to the quality of streaming video. In order to per-
form the simulation within a finite number of tests, and com-
pare them with evenly distributed patterns, we used a dis-
crete set of levels for each parameter: bandwidth, delay, jitter 
and loss. Level 5 is Best quality, and level 4 is Good, level 3 
is Moderate, and Level 2 is Bad. We found that bandwidth 
and delay affected directly the quality of video rather than 
the jitter or loss rate. We compared the dependency and sen-
sitivity of the parameters on the service quality. 
Even though the simulation was performed by 16 testers, 
and only 256 combination of parameter set are used in this 
paper, a larger dataset from real communication network 
service will provide a more accurate analysis.  
ACKNOWLEDGMENT 
This research was supported by the MKE (The Ministry 
of Knowledge Economy), Korea, under the ITRC (Infor-
mation Technology Research Center) support program su-
pervised by the NIPA (National IT Industry Promotion 
Agency) (NIPA-2012-H0301-12-1004) 
REFERENCES 
[1] P. Wang, Y. Yemini, D. Florissi, P. Florissi, and J. Zinky, 
“Experimental 
QoS 
Performances 
of 
Multimedia 
Applications”, INFOCOM 2000, March, 2000 
[2] Tao Yu; Baoyao Zhou; Qinghu Li; Rui Liu; Weihong Wang; 
Cheng Chang, “The service architecture of real-time video 
analytic 
system”, 
Service-Oriented 
Computing 
and 
Applications (SOCA), 2009, pp. 1-8. 
[3] Sewook Oh, Seong Rae Park, “Providing qos for streaming 
traffic in mobile network with mobile router”, 3rd ACM 
workshop on QoS and security for wireless and mobile 
networks (Q2SWinet '07), 2007. 
[4] Kostas E. Psannis, Yutaka Ishibashi, Marios G. Hadjinicolaou, 
“Qos for wireless interactive multimedia streaming”, 3rd 
ACM workshop on QoS and security for wireless and mobile 
networks (Q2SWinet '07), 2007. 
[5] ITU-T 
Recommendation 
J.247, 
“Objective 
perceptual 
multimedia video quality measurement in the presence of a 
full reference”, 2008. 
[6] Cisco, Internetworking Technology Handbook, “chap 49: 
Quality of Service Networking”. 
[7] K. Piamrat, C. Viho, J-M. Bonnin, A. Ksentini, “Quality of 
Experience Measurements for Video Streaming over Wireless 
Networks”, Information Technology: New Generations, Sixth 
International Conference (ITNG ’09), 2009, pp. 1184 – 1189. 
[8] Liuming Lu, Xiaoyuan Lu, Jin Li, “Quality Monitoring of 
Streaming Video Based on Packet-loss Artifacts”, Wireless 
and Optical Communications Conference (WOCC), 2010. 
[9] http://www.ticomsoft.com/products/shunra/ 
[10] HwaJong Kim, KyoungHyoun Lee, Jie Zhang, “In-service 
Feedback 
QoE 
Framework”, 
Communication 
Theory, 
Reliability, and Quality of Service (CTRQ), 2010, pp. 135-
138. 
 
79
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-242-4
DATA ANALYTICS 2012 : The First International Conference on Data Analytics

