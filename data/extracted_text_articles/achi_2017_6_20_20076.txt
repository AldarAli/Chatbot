Two-button Mobile Interface: 
Touchscreen Based Text-Entry for Visually-Impaired Users 
Hanseul Cho and Jae-joon Kim 
Department of Creative IT Engineering  
POSTECH 
Pohang, Korea, Republic of 
e-mail: {johanseul, jaejoon}@postech.ac.kr 
 
 
Abstract—As the usage of mobile devices grows explosively, 
texting on a touchscreen becomes everyday routines for 
communication. For visually-impaired people, however, text-
entry on the touchscreen is largely cumbersome and time-
consuming due to the difficulty of locating keyboard buttons 
without any physical signifiers. We present new text-entry 
methods based on the Braille system to address this issue. The 
proposed Left Touch and Double Touch schemes are based on 
the two-button interface for Braille input, so that visually-
impaired users can type textual characters without moving 
their fingers to find target buttons. We conducted experiments 
to evaluate the usability of the proposed methods and 
compared them with the One Finger Method and VoiceOver. 
The results show that the speed of the Double Touch is 3.94 
second per letter (SPL) while that of the Left Touch is 2.60 
SPL. The Left Touch was twice as slow as the VoiceOver but 
39% faster than the One Finger Method. Although the typing 
speeds of the proposed schemes were slower than the 
VoiceOver, we found that the subjects felt the proposed 
schemes more comfortable to use than the VoiceOver. The 
convenience of using only two buttons in the mobile interface 
also enabled visually-impaired users to be less dependent on 
auditory feedback while typing texts. 
Keywords-visullay-impaired; touchscreen; text-entry; input; 
Braiile. 
I. 
 INTRODUCTION 
Despite the technological advances, there are still groups 
of people that cannot benefit from the recent innovation 
because such advances usually aim to address the demand of 
the general public. One example is the touchscreen 
technology that fails to serve visually-impaired people. They 
acquire information mainly through auditory and tactile 
senses, whereas touchscreens require high dependency on 
vision. Touchscreens lack physical components to support 
auditory and tactile senses of visually-impaired people. 
Because visually-impaired cannot find a target to touch on 
the screen [3][8][16], regardless of the inventors’ intention, 
visually-impaired people are naturally excluded from using 
touchscreens. As mobile devices and interfaces for 
smartphones become an essential element of modern life and 
communication, visually-impaired people have been facing 
unprecedented frustration. 
Among a number of issues associated with touchscreens, 
we focused on text-entry methods on touchscreens for 
visually-impaired people. Although there are numerous 
assistive typing devices for visually-impaired people, such as 
the Braille Hansone [6], these devices are typically not light 
and portable, thus less desirable for smartphones. There are 
also existing text-entry tools for visually-impaired users. For 
example, iPhone, the most popular smartphone among 
visually-impaired users, has its own eye-free interface called 
VoiceOver [1]. It supports text-entry based on the standard 
QWERTY keyboard, using a split-tapping method [7] to find 
and touch each character. Although VoiceOver is a dominant 
text-entry interface among visually-impaired users, it still has 
a problem. The number of target buttons is too large, while 
the size of each target is too small for visually-impaired users 
to locate and touch easily. In addition, because VoiceOver 
requires high dependency on auditory sense, it is difficult to 
use in noisy places. Most of other existing text-entry 
methods have similar audio-related problems. Therefore, 
there is a pressing need to develop an appropriate text-entry 
method for touchscreens that is specifically targeted to 
visually-impaired people 
In this research, we first review the previous approaches 
of alternative text-entry methods for visually-impaired users, 
and evaluate the advantages and disadvantages of each 
approach. Based on the review and evaluation, we developed 
new Braille based text-entry methods, called Left Touch and 
Double Touch. These two text-entry methods use only two 
buttons in the mobile interface, so visually-impaired users 
can input letters without changing finger positions. That is, 
visually-impaired users do not need to scan and search the 
touchscreen to find a target. At the same time, the level of 
dependency on auditory sense is relatively low in the 
proposed method.  
We begin this paper with the analysis of background 
(Section 2), followed by the detailed presentation of our text-
entry methods, Left Touch and Double Touch (Section 3). 
Then we report the methodology and results of our 
experiment (Section 4, 5). As a conclusion, we discuss the 
analysis of the experiment result and its implications for 
future research directions (Section 6). 
II. 
BACKGROUND 
In this section, we discuss basic Braille system and 
researches related to text-entry for visually-impaired users to 
provide background knowledge of our research. 
134
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

A. Text-entry Methods Based on Braille 
Since developed in 1825, the Braille system has been used 
for reading and writing characters by visually-impaired 
people. One Braille character consists of six dots with three 
rows and two columns as shown in Figure 1, so 64 different 
letters can be represented in principle. 
 
 
Figure 1. Examples of Braille characters (the black circle means a raised 
dot, and the white means a flat): Lower-case 'a' (left); Lower-case 'n' (right). 
Each dot could be raised or remain flat so that people 
can figure out characters with tactile sense. Since most of 
visually-impaired people learn Braille, the advantage of 
text-entry based on the Braille system is the relatively low 
barrier for learning compared to non-Braille based entry 
methods. 
 
 
Figure 2. The numerical order of each dot. 
There is a numerical order for the dots in a Braille 
character. As shown in Fig. 2, the three dots in the left 
column have an order of 1 to 3, whereas three dots in the 
other column have an order of 4 to 6. Since this order is 
widely known to visually-impaired people, recognizing 
Braille in different orders would be challenging for them 
[11]. Therefore, it is important to keep the same order when 
designing new text-entry methods. 
Naturally, many previous Braille based text-entry 
methods place six buttons on a touchscreen to map the 
Braille cell directly. An example is BrailleType presented by 
Olivia et al [12]. In BrailleType, the user inputs one dot at a 
time by touching a corresponding button on the touchscreen. 
The speed was 1.45 wpm, which was relatively slower than 
the speed observed in other similar studies [10][14]. Paisios 
et al. presented four text-entry methods based on the Braille 
system [11]. The most preferred one was the One Finger 
Method, which is similar to BrailleType. In BrailleTouch 
presented by Southern et al., users input six dots in the 
Braille cell simultaneously using six fingers [14]. To use 
BrailleTouch, users hold a device with two hands and the 
screen faces away from them.  This method, however, may 
cause difficulties since the general holding posture is 
opposite from the typing posture. Usually, users hold 
smartphones to face them for general use. In BrailleTouch, 
the average speed of experts group was 23.2wpm, while that 
of non-experts group was 9.4 wpm. 
Mascetti et al. presented TypeInBraille, where users 
input one row at a time [10]. The speed was 6.3 wpm. 
Although there are no quantitative data available to be 
compared with other Braille-based input methods, it is 
possible that visually-impaired users may experience some 
confusion by the different order of the dots from the 
conventional Braille character and the need for additional 
training and practices [11].  
Based on the review of the previous methods, we view 
that there are three advantages in the Braille-based text-
entry method. First, visually-impaired users are already 
familiar with the Braille layout and the function of buttons. 
Second, users do not have to newly learn how to input in the 
Braille-based system different from VoiceOver since the 
input methods use Braille characters. Third, the number of 
target button decreases. For example, the maximum number 
of target in text-entry methods based on Braille is six. That 
is a relatively small number of target button compared to 
other text-entry methods, such as QWERTY. To leverage 
these advantages, we propose a simple text-entry layout 
with a smaller number of targets, for easy input way and 
small cognitive load. In this research, we use the One 
Finger Method as a baseline for our experiment, because it 
is the simplest way of input based on the standard six 
buttons format of Braille characters. 
B. Other Text-entry Methods 
Kane et al. presented Slide Rule, an eye-free interface for 
touchscreens with audio-based multi-touch techniques [7].  
Later, Slide Rule was incorporated into the Apple’s 
VoiceOver, which supports QWERTY-based eye-free text-
entry. In VoiceOver, since there are too many tiny targets, 
visually impaired users have to explore the keyboard with 
the finger to find targets [10]. Due to the small size and the 
lack of tactile feedback [13], even skilled users can rarely 
find a key without initial scanning. Due to the difficulty of 
recognizing the visual layout, QWERTY may not be a 
viable solution of text-entry design for visually-impaired 
users. Bonner et al. presented No-Look Notes, which uses 
the multi-touch interface and audio feedback [2]. In No-
Look Notes, 26 letters of the English alphabet are arranged 
around the screen in an 8-segment pie menu reminiscent. In 
one segment, there are three to four letters. When a user 
touches a target segment, the letters in the targeted segment 
appear in the alphabetical order from top to bottom on the 
screen. The speed was 1.32 wpm. Niazi et al. applied similar 
mobile 3*4 keyboard concept to touch screen text-entry, and 
compared the results with QWERTY keyboard [18].  
Oliveira et al. also presented NavTouch, which is a 
gesture-based interface [5]. The average speed was around 
1.7 wpm. Heni et al. also proposed gesture based text-entry 
135
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

and the speed was about 12 WPM [19]. On the whole, it 
appears that text-entry methods not based on Braille have 
fundamental problems that visually-impaired users need 
additional training and prolonged experience to skillfully 
use such methods. 
III. 
THE PROPOSED TEXT-ENTRY METHODS 
Based on the review of the existing text-entry methods, in 
the initial stage of our research, we set the following three 
design principles to propose a new mobile text-entry 
interface for visually-impaired users: 
 
Principle 1: Design a text-entry method based on the 
Braille system for the simplicity of the interface layout, 
and the fewer burdens for additional training and 
practices.  
 
Principle 2: Design a text-entry method with a minimal 
number of targets, thereby users do not have to move 
their position of fingers extensively.  
 
Principle 3: Design a text-entry method less dependent 
on auditory sense, so that visually-impaired people can 
use it in noisy places without solely depending on 
auditory feedback. 
A. Two-Button Interface 
Based on the first and second design principles, we 
designed text-entry methods that have only two vertical 
buttons for Braille character input as shown in Fig. 3. In the 
rest of the paper, we use the term LEFT button for 
the button on the left side and RIGHT button for the other 
one.  
 
 
Figure 3. The layout of two-button interface. 
Using this two-button interface, we propose two types of 
text-entry methods, called Left Touch and Double Touch. 
For each method, users can input a letter using the LEFT 
and RIGHT button. Fig. 4 shows three different holding 
postures for using the two-button interface. Users can hold a 
smartphone with one hand and typing with another hand 
(Fig. 4, left), hold and typing with the same hand (Fig. 4, 
middle) or using both thumbs for input (Fig. 4, right). 
 
Figure 4. Holding postures for using the two-button interface: Holding with 
one hand, and typing with the other (left); holding and typing with the same 
hand (middle); typing with both thumbs (right). 
One of the most important features of the two-button 
interface is that it minimizes the movement of fingers on the 
touchscreen. Users only need to lift fingers up and down at 
the same position. By applying the two-button interface, it is 
expected that Braille input on touchscreens can be 
convenient and easy for visually-impaired users. In the 
following section, we provide more detailed descriptions 
about each text-entry method in the two-button mobile 
interface.  
B. Left Touch 
Visually-impaired people recognize the numerical order 
of dots when understanding Braille characters. To leverage 
on this learned behavior, in the Left Touch method, users 
input dots in a regular order. The operating mechanism is 
simple. If a user wants to mark a dot, touch the LEFT 
button; otherwise, touch the RIGHT button. Users always 
touch buttons six times to complete one letter since one 
Braille character is composed of six dots. After typing one 
letter, the system presents audio feedback that informs users 
of the typed letter for confirmation.  
For example, the sequence of touching the alphabet ‘n’ 
is ‘LEFTRIGHTLEFTLEFTLEFTRIGHT’ as 
shown in Fig. 5 (top).  
Users can delete letters by swiping upward on the LEFT 
button, and input a ‘space’ by swiping downward on the 
RIGHT button. When users want to restart inputting a letter, 
they can cancel an inputted pattern and restart input by 
swiping down on the LEFT button. 
Visually-impaired people that are familiar with Braille 
can easily adopt the Left Touch method because the 
touching sequence is same as the natural order for the 
original Braille system. The layout is highly simple to 
reduce the need for memorizing locations and functions of 
buttons. Finally, the dependency on auditory sense is 
relatively low because users can easily recognize the 
completion of a letter input through the fixed number (6) of 
touches for each letter.  
C. Double Touch 
In the Double Touch method, a user touches a button 
twice to mark a dot and touches a button once to mark an 
empty dot. Different from the Left Touch method, users 
input dots in the order of row, not in numerical order of 
136
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

 
Figure 5. Way of inputting 'n' using different methods (each cell stands for each step for input, shaded buttons and dots mean a current step): Left Touch 
(top); Double Touch (bottom).
Braille. For example, users input dots for the first row, then 
for the second row, and finally for the third row. In the same 
row, left dots are inputted first. Therefore, the order should 
be 'left dot (1st row) - right dot (1st row) - left dot (2nd row) - 
right dot (2nd row) - left dot (3rd row) - right dot (3rd row)’. 
In this scheme, we use the LEFT button for entering Braille 
characters in the left column and the RIGHT button for 
entering Braille characters in the right column. If users want 
to input left dots in a row as marked, they need to touch the 
LEFT button twice.  Otherwise, if users want to input right 
dots in a row as empty, they need to touch the RIGHT 
button once. Following this rule, the sequence of entering 
the 
alphabet 
‘n’ 
is 
‘(LEFT-LEFT) 
(RIGHT-
RIGHT)LEFT(RIGHT-RIGHT)(LEFT-
LEFT)RIGHT’ as shown in Fig. 5 (bottom).  
The same audio feedback as in the Left Touch method is 
presented to inform users of the completion of letter input. 
Deleting, spacing and restarting mechanisms are also same 
as the ones for Left Touch. Since the order of entering each 
dot (1-4-2-5-3-6 in Fig. 2) is different from the conventional 
one (1-2-3-4-5-6), users may feel some confusion in the 
beginning. 
However, 
in 
Double 
Touch, 
dots 
and 
corresponding buttons mapped spatially to reduce cognitive 
load to remember the layout. Also, the way the buttons are 
pressed is rhythmical because a user touches the LEFT and 
RIGHT button alternately. The downside of this method, 
however, is that the number of touching may vary 
depending on the letters. In the worst case, the buttons have 
to be pressed 12 times (all dots are marked).  
IV. 
EXPERIMENTS 
We conducted an experiment with four visually-impaired 
participants. In the experiment, we compared the efficacy of 
our proposed methods, Left Touch and Double Touch with 
the existing methods including the One Finger Method, and 
VoiceOver. 
A. Participants 
We recruited four visually-impaired users for the 
experiment. All participants are university students from the 
same university located in a mid-sized city in Korea. As 
shown in Table 1, the average age was 24 (standard 
deviation=1.63, range: 22-26). Three participants were 
visually-impaired from birth. All of them were iPhone users, 
and used VoiceOver for more than two years. Also, all of 
them used Braille Hansone at least once. We asked the 
participants about their experiences with using the English 
Braille, since the tasks in the experiment were to type 
English letters. The average period of the English Braille 
experience was 10.75 years (standard deviation=4.03, range:  
5-14). 
 
*C/A(age)[Congenital 
or 
Acquired(age)];P/E[Period 
of 
Using 
English 
Braille];P/V[Period of Using VoieOver]. 
 
Age 
Gender 
C/A (age) 
P/E(year) 
P/V(year) 
1 
26 
male 
acquired(18) 
5  
3 
2 
22 
female 
congenital 
11  
2 
3 
24 
female 
congenital 
13  
3 
4 
24 
female 
congenital 
14  
3 
TABLE I. PARTICIPANTS’ CHARACTERIAZATION  
137
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

B. Apparatus 
We used Galaxy S3 from Samsung for the One Finger 
Method, Double Touch, and Left Touch, and used iPhone4 
for VoiceOver.  
C. Tasks 
1) Dictation 
We used dictation as the main task. First, participants 
listened to specific sentences, and then entered the sentences 
with the given input method. We delivered sentence 
uniformly by using the Google translator [4] for Text-to-
Speech method as suggested in [14]. Because all 
participants were not native English speakers, they were 
allowed to ask questions before starting text input when 
having troubles in identifying spellings. 
2) Phrase Set 
We used the 'standard set of 500 English phrases 
commonly used in text entry studies' developed by 
MacKenzie and Soukoreff [9]. Participants inputted 
alphabets in lower-case only. There were no numbers and 
punctuation marks. We recorded inputted logs and times to 
calculate second per letter (SPL) and to evaluate the 
accuracy of each entry method. 
3) Procedure 
Participants had four sessions of twenty-minute typing 
tasks. Before starting main tasks, they had a training session 
to learn and practice each text-entry method. Since all 
participants were familiar with VoiceOver, they did not 
have the training time for VoiceOver.  
Each method was tested for one day, not to overburden 
participants and to reduce confusion and learning effects 
across the different methods compared. We did not conduct 
experiments for Left Touch and Double Touch continuously 
to avoid the ordering effect because two methods commonly 
use the two-button interface style. Half of the participants 
were given the Left Touch test first, whereas the others tried 
the Double Touch method first. 
For data collection, we recorded both audio and video 
data. After finishing all experiments, the participants were 
asked to complete a survey concerning usability issues such 
as ease of use, willingness to use, and satisfaction. All 
survey questions were given in a five-point Likert scale 
(1=strongly disagree, 5=strongly agree), and open questions 
about the personal opinion on the method. The experiments 
were followed by semi-structured interviews for further 
details about participants’ qualitative opinions. 
4) Experimental Design and Data Analysis 
For quantitative data, the dependent variables are speed 
and accuracy, with a 4 x 4 within-subjects analysis of 
variance: the four text-entry methods (Left Touch, Double 
Touch, One Finger Method, & VoiceOver) X four sessions 
(from the 1st to the 4th). To test the significance of the main 
effect, a Student Newman-Keuls (SNK) test was conducted 
as a post-hoc analysis. For the analysis, we assumed that for 
text-entry methods, the input speed would increase as 
sessions progress. Furthermore, we assumed that there 
would be significant differences among the four different 
input methods in terms of input speed. 
V. 
RESULTS 
In this section, we report results of the experiments; 
speed, accuracy and survey results. 
A. Speed 
Fig. 6 shows means of the speed measured in the four 
sessions for each text-entry method. The unit for speed is 
SPL, which indicates the time taken to input one letter. 
Hence, the higher SPL value means that it takes longer time 
to input. 
 
Figure 6. Speed results for the four text-entry methods across sessions 
(error bars standard error). 
Fig. 6 shows that VoiceOver (Mean SPL=1.38, 
SD=0.11) is the fastest among the four different text-entry 
methods compared (F3,9=14.69, p<0.001). It was then 
followed by Left Touch (Mean SPL=2.86, SD=0.55), One 
Finger Method (Mean SPL=4.10, SD=0.91), and Double 
Touch (Mean SPL=4.98, SD=2.06). There was no 
significant difference between Double Touch and One 
Finger Method. The speeds among Left Touch, Double 
Touch and VoiceOver were significantly different from each 
other. 
In terms of sessions, there was a significant effect 
(F3,9=23.98, p<0.001). The first session was much slower 
than the others, with means of 4.20 SPL, 3.35 SPL (2nd), 
2.99 SPL (3rd), and 2.78 SPL (4th), respectively. The SNK 
analysis indicates that the 1st session was significantly 
different from the 3rd, the 4th sessions. There was no 
significant difference in terms of speed for sessions of the 
2nd, the 3rd and the 4th sessions. 
There was a significant text-entry  session interaction 
(F9,27=3.84, p<0.01).  
To find the learnability effect of each text-entry, an 
ANOVA test was performed with the speed of sessions for 
each text-entry method as the dependent variables.  
1) Left Touch 
138
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

For Left Touch, the ANOVA test results show that there 
is a significant effect of session (F3,9=28.82, p<0.0001). 
Although there was no significant difference between the 
2nd and 3rd sessions, the 1st, 2nd, and 4th sessions were 
significantly different from each other. Since the speed 
became faster in the later sessions, the analysis result 
confirms that there is the learnability effect in Left Touch. 
2) Double Touch  
There were significant effects of session for Double 
Touch (F3,9=7.08, p<0.01). Similar to the Left Touch, the 
speed became faster as sessions are repeated. However, the 
learnability effect was less than the effect observed in Left 
Touch. There was no significant difference in the 2nd, 3rd, 
and 4th sessions. Only the 1st session was significantly 
different from other sessions.  
3) One Finger Method 
Similar to the Double Touch method, significant effects in 
session were found for One Finger Method (F3,9=9.22, 
p<0.01). While the speed became faster as sessions were 
repeated, there was no significant difference in the 2nd, 3rd, 
and 4th sessions. Only the 1st session was significantly 
different from other sessions. From that, it was found that 
the learnability effect of the One Finger Method was less 
than that of the Left Touch method.  
4) VoiceOver 
As expected, VoiceOver had little effect on learnability 
because the participants were already familiar with this 
method. Although the test results show that there was a 
significant effect of session (F3,9=5.85), it was mainly due to 
the fastest speed of the 2nd session, which is significantly 
different from others. There was no significant difference in 
the 1st, 3rd, and 4th sessions. Note that Voiceover did not 
have any significant improvement in speed, whereas other 
text-entry methods showed about 20% improvements in 
speed from the first session and onward. 
B. Accuracy 
Regarding accuracy, there was no significant difference 
among the four text-entry methods, as measured in the 
number of errors in text input, because all participants 
corrected errors whenever they found them. Therefore, we 
analyzed the number of deleting action during the 
experiments instead. We set the number of deleting per 
letter, NPL, as a unit of analysis. 
There were no significant main effects in both text-entry 
method (F3,9=2.26, p>0.05) and session (F3,9=2.99, p>0.05).   
The mean number of deleting for Left Touch, Double 
Touch, One Finger Method, and VoiceOver were 0.0201 
NPL, 0.0398 NPL, 0.0882 NPL, and 0.0507 NPL 
respectively. In other words, when the user types 100 letters, 
he/she only deleted letters 2 to 8 times only.  
C. Survey Results 
After completing all the experiments, we asked for 
participants' opinion through the survey and semi-structured 
interview. As shown in Table 2, in terms of ease of use, Left 
Touch and One Finger Method received the highest scores. 
VoiceOver received the highest score in willingness to use. 
In the satisfaction factor, the participants rated both Left 
Touch and Double Touch methods highly satisfactory. 
 
TABLE II. SURVEY RESULTS ON A LIKERT SCALE (1= strongly 
disagree, 5= strongly agree). 
 
Left 
Touch 
Double 
Touch 
One 
Finger 
Method 
Voice 
Over 
Ease of use 
4.25 
3.00 
4.25 
3.75 
Willingness 
to use 
4.00 
4.00 
3.50 
5.00 
Satisfaction 
4.00 
4.00 
3.25 
3.75 
VI. 
DISCUSSION 
In this section, we discuss results of experiments 
A. Speed 
Among the four text-entry methods compared, it was 
observed that VoiceOver was the fastest one. For the 
accurate analysis, we used the speed from only the 3rd and 
4th session, since three text-entry methods except VoiceOver 
showed the learnability effect. VoiceOver was still the 
fastest among the four different text-entry methods with 
1.29 SPL. It was then followed by Left Touch (2.60 SPL), 
One Finger Method (3.68 SPL), and Double Touch (3.94 
SPL). Left Touch was twice slower than the VoiceOver but 
39% faster than the One Finger Method. 
To compare this with results from previous research that 
used word per minute (WPM), we converted the speed unit 
from SPL to WPM [2][12]. The converted speed for our 
participants was 9.30 WPM that was faster than the speed of 
the methods proposed in [2], 0.66 WPM and [12], which 
was 2.11 WPM [12]. We speculate that the reason for large 
differences between our participants and the others is likely 
due to the following reasons; 1) all participants were experts 
of VoiceOver who had used the system for more than two 
years. 2) All participants were university students who were 
relatively heavy users of smart phones. This is also one of 
the reasons that magnify the speed difference between 
VoiceOver and others.  
In contrast to the extensive experience of using 
VoiceOver, participants used other three text-entry methods 
for 100 minutes only. This difference was also a significant 
factor that affected the speed of other text-entry methods. 
In case of other three text-entry methods, the speed 
increased with the number of sessions (Fig. 6). It indicates 
that there were the effects on learnability for three text-entry 
methods. Hence, it is possible to improve speed if users 
have more time to use. Two participants described that they 
felt experienced in using Left Touch, and that the speed 
would increase as time went by. Both of them mentioned 
that they liked to use the Braille system. 
139
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

Quote 1 (P2). I think this (Left Touch) will be 
convenient, because I am familiar with the Braille 
system. It will be faster if I get used to it, since it only 
needs six times of touching. 
Quote 2 (P3). The Braille system was made for the 
visually-impaired, so it is very convenient for us. I think 
it (using Left Touch) may become faster.  
Quote 3 (P3). At first, I tried to think what to touch. For 
example, to touch ‘t’, I have to touch that button. 
However, as I used Left Touch over time, my finger 
naturally moved. It felt like my finger moved 
automatically without even thinking.  
Quote 4 (P4). In case of Left Touch, I felt my finger 
moved faster than my thinking, because I could 
remember the pattern of Braille. 
The participants have conceived the shape and pattern of 
Braille through years, so the process of recalling Braille 
character is highly natural and easy to them. Using the 
Braille-based system, we can support natural text-entry for 
visually-impaired users. Hence, we assumed that it is 
worthwhile to make comparison among the Braille-based 
method to identify which factors are important in terms of 
improving the Braille typing speed. We report them in the 
following section. 
1) Double Touch vs. Left Touch 
Left Touch was faster than Double Touch. Both Double 
Touch and Left Touch are based on the two-button interface. 
However, the number of buttons for touching an alphabet is 
different. In Double Touch, a user touches at least 6 times, 
and 12 times in worst case, whereas in Left Touch, a user 
touches 6 times in every case.  In addition, the mapping rule 
in Left Touch is more natural as the order of pushing 
buttons is same as the conventional order of entering Braille 
characters explained earlier. Hence, we believe that Left 
Touch is the better method to apply the two-button interface 
than Double Touch.   
2) Left Touch vs. One Finger Method 
There are two main differences between Left Touch and 
One Finger Method; 1) One Finger Method is based on the 
six-button interface, so users have to change the position of 
fingers. 2) Different from Left Touch, the number of 
touching is not fixed in the One Finger Method.  In Left 
Touch, although the average number of touching is more 
than other text-entry methods such as VoiceOver and One 
Finger Method, a user does not have to change position of 
fingers. From this comparison, we believe that limiting the 
range of finger movements and having the fixed number of 
touching are more important than reducing the average 
number of touching. This finding is also supported by the 
users’ quotes during the interview: 
Quote 5 (P1). If I can figure out the exact position of 
each button, the One Finger Method will be better. 
However, it is very difficult for visually-impaired 
people. 
Quote 6 (P3). I do not like the One Finger Method 
because the finger movement is too much. 
B. Accuracy 
We measured the error rates of text-entry methods using 
the NPL numbers. The measured data ranged from 2% to 
8%, which is much smaller than the results in the previous 
research in which the error rate of expert group was 14.5%, 
and that of the average group was 33.1% [14]. Our 
participants might have been more careful not to make 
typing errors compared to those in the previous research. 
C. Satisfaction 
Satisfaction is a subjective factor. After completing all 
the experiments, we conducted the survey and semi-
structured interviews to collect participants' opinion. 
Both of the proposed two-button interfaces, Left Touch 
and Double Touch were well-received by the participants 
because their dependency on auditory sense was lessened. 
Fig. 7 (left) and (right) show the pictures of the participants 
using VoiceOver and Left Touch taken in a noisy place 
during the survey. 
When visually-impaired people use VoiceOver, they 
cannot input without hearing auditory feedback. Therefore, 
the participant in the Fig. 7 placed the mobile phone close to 
her ear (Fig. 7 (left)). In case of Left Touch, they can 
recognize the patterns of each letter, thereby using auditory 
sense as an assistive means not as the essential one.  Note 
that the participant in Fig. 7 (right) placed the mobile phone 
on the table far from her ears. The participants mentioned 
about this advantage of being less dependent on auditory 
feedback during the interview, as follows:   
Quote 7 (P1). When I use VoiceOver, I cannot hear any 
other sound. I have to concentrate on VoiceOver’s audio 
feedback.  
Quote 8 (P2). I cannot use VoiceOver in such a noisy 
place. When I used a folder phone, I could input without 
hearing any sound. However, now I cannot do that (with 
VoiceOver). 
From this, we believe that Left Touch is more effective 
in a noisy place than VoiceOver, because its dependency on 
auditory sense is relatively less. 
Figure 7. Different postures for VoiceOver (left) and Left Touch (right). 
140
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

D. Ease of Use 
Left Touch and One Finger Method were well received 
in terms of the ease of use. Both of them are based on the 
Braille system and use relatively simple input patterns.  
In contrast, Double Touch received lower scores. The 
reason might be that Double Touch has a variable number of 
touching for a letter and that the order of button is different 
from the original Braille system as explained earlier. From 
this observation, we believe that distinguishing marked and 
unmarked dots in a Braille character by spatial differences is 
likely to be more user-friendly than distinguishing them 
using the difference in the number of touching.  Note that 
VoiceOver also received a lower score than Left Touch. 
Some participants complained that the input method of 
VoiceOver had been too complex although they were used 
to VoiceOver. 
E. Willingness to Use 
All Participants gave five points for VoiceOver in terms 
of the willingness to use. The fast speed and familiarity 
were the main reasons behind this result, as indicated in the 
following quotes:  
Quote 9 (P1). Until now, there is no replacement for 
VoiceOver. 
Quote 10 (P2). I gave 5 points for VoiceOver in the 
‘Willingness to Use’ factor because it is the most 
convenient for now, anyway. 
Participants gave a higher score for the Left Touch than 
the One Finger Method because of its usability and 
simplicity. 
F. Additional Feedback on the Two-Button Interface 
In this research, we proposed two text-entry methods 
that are based on the two-button interface. Between Left 
Touch and Double Touch, we found that Left Touch is 
better than Double Touch in terms of speed and ease of use.  
Participants suggested some interesting ideas for the 
potential application where two-button interface can be used. 
For instance, they wanted to use it in large screen interfaces.  
From this feedback, we think that large screen interfaces 
in public places could be another exciting application for 
Left Touch because users do not have to fully concentrate 
on audio feedback, and do not have to scan the screen for 
input. This kind of approach matches with the ability-based 
design introduced by Wobbrock et al. [15] that suggested a 
design interface to utilize the full range of human potential 
not to focus on disabilities.  
Quote 11 (P3). Left Touch can be used for other 
applications. For example, ATM has the touchscreen 
interface but I cannot use it appropriately. Of course, 
there is audio feedback, but it takes long time to use. If 
there were Left Touch in ATM, it would be convenient.  
Quote 12 (P4). It (two-button interface) would be good 
if we use it in large touchscreens such as reservation 
machines in a train station. If we use VoiceOver in large 
screen, it would be difficult to scan, but we can apply the 
Two-button interface easily in large screens. 
VII. FUTURE WORK 
There were a few limitations in this research. The 
followings are plans to do further work. 
A. Automatic Correction System 
iPhone has an automatic correction system. For 
convenience, Left Touch and Double Touch should have 
such an automatic correction system like iPhone, which 
could greatly reduce the number of actions for deleting and 
restarting, thereby increasing speed of text-entry methods. 
B. Abbreviation 
Many visually-impaired people are familiar to use 
abbreviations for frequently used English words like ‘with’ 
and ‘out’. However, Left Touch and Double Touch 
currently 
do 
not 
support 
such 
abbreviations. 
The 
participants were confused when they inputted some words 
that have well-known abbreviations. If the system supports 
abbreviations, it could significantly reduce the number of 
touching and eventually improve the speed for text-entry.  
C. Finding Suitable Applications 
Some participants suggested that the two-button interface 
would be applicable for large screen applications. As future 
research work, we plan to evaluate the strength of two-
button interface by conducting experiments based on large 
screens, such as tablet PC or large touchscreen machines in 
public spaces. Furthermore, by conducting experiments in 
noisy places, we plan to evaluate the strength of low 
dependency on auditory feedback in our proposed methods. 
D. Needs for Longitudinal Study 
This study lacks the number of participants and period of 
using proposed methods. To get valid and statistically 
significant results, future work with more participants is 
needed. In addition, participants’ experience of VoiceOver 
and proposed method is disparate. Therefore, for fair 
comparison, we plan to conduct longitudinal study for 
proposed methods.  
VIII. CONCLUSION 
In this study, we proposed two types of touchscreen text-
entry methods for visually-impaired users, called Left 
Touch and Double Touch. The key components of the 
proposed mechanisms are to use the two-button interface 
and the Braille system. The proposed two-button interface 
limits the range of finger movements on a touchscreen; 
hence, visually-impaired users can input English letters 
more comfortably. Although the experiment results showed 
that the proposed methods were slower than the VoiceOver, 
we believe that familiarity played a major role for the results 
as indicated by the learnability effect and survey feedback. 
The survey results also indicated that the Left Touch method, 
in particular, had various strengths such as ease of use and 
satisfaction. All participants agreed that Left Touch was 
141
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

easier and simpler to use than VoiceOver. Compared to the 
VoiceOver that requires visually-impaired users to rely on 
audio feedback, the proposed schemes do not have such 
limitations. Based on the overall feedback from the 
participants, we expect that our proposed scheme can be 
easily used for large screen applications or in noisy settings 
including movie theaters, bus terminals or restaurants. 
REFERENCES 
[1] “Apple. 
Accessibility” 
[Online]. 
Available 
from: 
https://www.apple.com/accessibility/ios/voiceover/ 
[accessed:2017-01-17] 
[2] M. N. Bonner, J. T. Brudvik, G. D. Abowd, and W. K. 
Edwards, “No-look notes: accessible eye-free multi-touch text 
entry”, In Pervasive Computing, Springer Berlin Heidberg, 
2010, pp. 409-426. 
[3] G. Evreinov and R. Raisamo, “ Tactile pointer for touchscreen 
manipulations”, In Proc. HANDICAP, 2002, pp. 137-142. 
[4] “Google. Google Translate,” [Online]. Available from: 
https://translate.google.com. [accessed: 2017-01-17] 
[5] T. Guerreiro, P. Lagoá, H. Nicolau, D. Gonçalves, and J. A. 
Jorge, “From tapping to touching: Making touch screens 
accessible to blind users”, IEEE MultiMedia, 2008. 
[6] “HIMS 
International,” 
[Online]. 
Available 
from: 
http://www.himsintl.co.kr/?r=ko&m=shop&cat=6&uid=27&f
rameTab=1 [accessed: 2017-01-17] 
[7] S. K. Kane, J. P. Bigham, and J. O. Wobbrock, “Slide rule: 
making mobile touch screens accessible to blind people using 
multi-touch interaction techniques”, In Proc. of the 10th 
international ACM SIGACCESS conference on Computers 
and accessibility, 2008, pp. 73-80.  
[8] S. K. Kane, J. O. Wobbrock, and R. E. Ladner, “Usable 
gestures for blind people: understanding preference and 
performance”, In Proc. Of the SIG SIGCHI Conference on 
Human Factors in Computing Systems, 2011, pp. 413-422. 
[9] I. S. MacKenzie and R. W. Soukoreff, “ Phrase sets for 
evaluating on Human factors in computing systems”, In 
CHI'03 extended abstracts on Human factors in computing 
systems, 2003, pp. 754-755. 
[10] S. Mascetti, C. Bernareggi, and M. Belotti, “TypeInBraille: a 
braille-based typing application for touchscreen devices”, In 
The proceedings of the 13th international ACM SIGACCESS 
conference on Computers and accessibility, 2011, pp.295-296.  
[11] N. Paisios, A. Rubinsteyn, and L. Subramanian, “Mobile 
brailler: Making touch-screen typing accessible to visually 
impaired users”, In Workshop on Frontiers in Accessibility 
for Pervasive Computing, 2012. 
[12] J. Oliveira, T. Guerreiro, H. Nicolau, J. Jorge, and D. 
Gonçalves, “BrailleType: unleashing braille over touch screen 
mobile phone”, In Human-Computer Interaction–INTERACT,  
Springer Berlin Heidelberg, 2011, pp. 100-107. 
[13] J. Oliveira, T. Guerreiro, H. Nicolau, J. Jorge, and D. 
Gonçalves, “Blind people and mobile touch-based text-entry: 
acknowledging the need for different flavors”, In The 
proceedings of the 13th international ACM SIGACCESS 
conference on Computers and accessibility, 2011, pp. 179-186. 
[14] C. Souther, J. Clawson, B. Frey, G. Abowd, and M. Romero, 
“An evaluation of BrailleTouch: mobile touchscreen text 
entry for the visually impaired”, In Proceedings of the 14th 
international conference on Human-computer interaction with 
mobile devices and services, 2012, pp. 317-326. 
[15] J. O. Wobbrock, S. K. Kane, K. Z. Gajos, S. Harada, and J. 
Froehlich, “Ability-based design: Concept, principles and 
examples”, ACM Transactions on Accessible Computing 
(TACCESS), 2011, 3(3), 9. 
[16] G. Yfantidis and G. Evreinov, “Adaptive blind interaction 
technique for touchscreens”, Universal Access in the 
Information Society, 2006, 4(4), pp. 328-337. 
[17] K. Ushida, Y. Sekine, and S. Hasegawa, “IPPITSU: A one-
stroke text entry method for touch panels using Braille 
system”, In 2014 IEEE 3rd Global Conference on Consumer 
Electronics, 2014, pp. 374-375. 
[18] B. Niazi, S. Khusro, A. Khan, and I. Alam, “A Touch 
Sensitive Keypad Layout for Improved Usability of 
Smartphones for the Blind and Visually Impaired Persons”,  
In Artificial Intelligence Perspectives in Intelligent Systems, 
2016, pp. 427-436.  
[19] S. Heni, W. Abdallah, D. Archambault, G. Uzan, and M. S. 
Bouhlel, “An Empirical Evaluation of MoonTouch: A Soft 
Keyboard for Visually Impaired People”, In International 
Conference on Computers Helping People with Special Needs, 
2016, pp. 472-478.  
 
 
142
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

