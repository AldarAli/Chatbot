A Systematic Literature Review on Misconceptions in Software Engineering
Carolin Gold-Veerkamp
University of Applied Sciences
Aschaffenburg
Aschaffenburg, Germany
Email: carolin.gold-veerkamp@th-ab.de
Nermin Saray
University of Applied Sciences
Coburg
Coburg, Germany
Email: nermin.saray@stud.hs-coburg.de
Abstract—From a constructivist perspective, learning is an 
active, cognitive process in which individuals construct their own 
knowledge by connecting new concepts with previous knowledge, 
skills, and experience that serve as points of departure. The 
purpose of this study is to identify and analyse known evidence-
based misconceptions in Software Engineering to use these 
insights for higher education. We used a systematic literature 
review as a secondary data accumulation, searching 10 databases 
automatically using predeﬁned s earch q ueries a nd selection 
criteria. Out of 2,158 publications found, 18 could be identiﬁed 
as appropriate for the selection criteria. These contain over 100 
statements which the authors of these publications refer to as 
misconceptions/beliefs/myths. Yet, only a fraction of these are 
based on evidence; namely 20 items from 3 papers. Currently, 
evidence-based research on misconceptions in Software Engineer-
ing is limited. We, therefore, deduce that evidence-based primary 
data acquisition and analysis should be the research desideratum.
Keywords–Software Engineering, Higher Education, 
Misconceptions, Systematic Literature Review.
I. INTRODUCTION
From a constructivist point of view, learning is to be under-
stood as an active, individual, situated, social, and cognitive 
psychological process. Each individual has to build up their 
own knowledge by combining new concepts based on previous 
knowledge, existing competencies, previous experience, as 
well as conceptions and putting it into a network-like rela-
tionship. This means, learners form conceptions and models 
to explain phenomena, processes, and artifacts before they are 
confronted with them in institutional learning. These possibly 
alternative – from scientiﬁc or expert perspective – conceptions 
have a twofold signiﬁcant impact on the learning process. On 
one hand, they can serve as the basis for learning, on the 
other, they can also contradict the educational content and thus 
hinder the learning process.
In order to be able to achieve sustainable learning (in 
higher education), a purely technical structuring of the learn-
ing content is therefore insufﬁcient. F urthermore, didactics 
should do justice to the learners’ “points of departure” [1, 
p. 6]. The Model of Educational Reconstruction, which is
epistemologically based on the constructivist position, calls
for precisely this consideration [1][2]. The model comprises
the triad of content clariﬁcation, l earners’ c onceptions, and
didactic design; it considers the scientiﬁc c oncepts a nd the
student conceptions as equivalents.
To be able to use this model in Software Engineering (SE)
education, we have to take a step back and clarify which
misconceptions undergraduates bring to university. Thus, a
Systematic Literature Review (SLR) as a secondary data anal-
ysis provides information about known SE misconceptions.
Therefore, the paper is structured as follows: It starts with
terminological aspects, as a plurality of terms evolved, and
related work in other disciplines. The SLR process is explained
in Section II, complemented by the results (Section III). Before
the paper closes, a short discussion is given (Section IV).
A. Terminological Aspects
Due to many different ways of looking at the research
object ‘(mis-)conceptions’ as well as the critical examination
of the terminology, an abundance of terms has developed.
The different understandings have led to a plurality of terms
with multiple connotations. The abundance of technical terms
has risen so much in the course of research (especially in
natural sciences didactics) that it is now almost impossible to
survey. The fact that the terms cannot be clearly distinguished
from each other often leads to a more or less synonymous
use and thus to an undifferentiated mix. As a result of
the dissatisfaction with this situation, researchers have again
constructed and deﬁned additional terms, which expands the
existing term dilemma.
In addition to [3] [4], also others include entire collections
of terms. This list (merely referenced by single publications
due to restricted page space) gives an impression of the broad
spectrum:
• Preconceptions [3]–[6]
• (Students’) conceptions [3][4]
• Alternative conceptions [3]
• Na¨ıve conceptions [4]
• Na¨ıve theories [3][4]
• Na¨ıve beliefs [3]
• Beliefs [7]
• Alternative beliefs [3]
• Alternative frameworks [3][4][6]
• Intuitive theories/science [6]
• Prior knowledge [6]
• Misconceptions, the “standard term” as [3, p. 119] state
– despite the negative connotation [4] [6].
1
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

In spite of the heterogeneity of terms, opposed opinions
and discussions on the different types of expression, it can
be stated consensually that individuals each develop different
conceptions of certain concepts, which should and must be
used as a starting point in teaching. These conceptions can,
but do not have to be in line with modern scientiﬁc theories [4]
and therefore may act as learning obstacles [8], often referred
to as misconceptions.
B. Related Work on Misconceptions in Didactics
The research and publications about misconceptions in
natural sciences in the context of school are immense, as a bib-
liography by Duit [9] proves. When looking at the catalogue,
encompassing over 8,300 publications and summarizing them
per decade (Figure 1), it is obvious that since the mid-1970s
international researchers have been investigating the ﬁeld.
Fig. 1. Diagram of Accumulated Number of Publications per Decade, Sorted
by Discipline Listed in [9]; esp. Focused on ‘Programming’
Out of these, merely ﬁve publications [10]–[14] can be
assigned to ‘programming’ as nearest to SE, but also to science
and/or maths; i.e. they are equivocal.
Moreover, in the last few years, several papers on miscon-
ception research in computer sciences appeared concerning:
• ... programming [15]–[18] and object-oriented program-
ming in particular [19][20].
• ... artifacts, e.g., computers, smartphones, and so on [21,
and others].
• ... the Internet [22].
All publications listed have in common that they do not
particularly deal with SE and are contextualised within school
education. This results in research needs for SE in university.
II. METHOD: SLR ON MISCONCEPTIONS IN SE
In order to be able to present the state of research on (under-
graduate) conceptions in SE, there is a need for a SLR, which
summarizes all available information about this phenomenon
thoroughly and impartially [23, p. 7]. Conducting a SLR is
a quantitative methodology of secondary data collection for
the synthesis of research results from primary studies. The
guidelines – used here – that Kitchenham and Charters have
drawn up for SE are derived from several approaches in
medicine and the social sciences [23, p. vi].
The following explanations, which describe the three-phase 
process of the SLR – carried out as a computer-based, auto-
mated search – are divided into the initial planning in Section 
II-A, the actual practical implementation (Section II-B) and
the subsequent presentation and use of the results (Section
III), see also [23][24].
A. Phase 1: Initial Planning
The planning of the SLR contains some parameters that
require previous deﬁnition in order to minimize bias. The SLR
is determined as follows:
1) Research Question(s): To what extent does research on
misconceptions in SE already exist? Which misconceptions in
SE are known/documented?
2) Search Strategy:
a) Language Selection: At this point, the language ra-
dius, which is one of the inclusion criteria, should be antic-
ipated. The reason for this is the following deﬁnition o f the 
Search Query (SQ). Since research on conceptions is interna-
tional, publications in German and English are considered.
b) Queries and Synonyms: Regardless of the various
connotations (Section I-A), the search should encompass the 
previous research on misconceptions in SE as broadly as 
possible. Therefore, the search query is based on the numerous 
synonymously used English terms shown in Table I. (Indicat-
ing wildcards, i.e. placeholders, by an asterisk (*).)
TABLE I. DEVELOPMENT OF THE ENGLISH SEARCH QUERY USING 
SYNONYMS
Synonyms
Substrings
Noun
Adjective
preconceptions
preconception*
–
students’ conceptions
conception*
–
alternative conceptions
alternative
na¨ıve conceptions
na¨ıve
na¨ıve theories
–
na¨ıve beliefs
belief*
beliefs
–
alternative beliefs
alternative
alternative frameworks
–
intuitive theories
–
intuitive
intuitive science
–
prior knowledge
–
prior
misconceptions
misconception*
–
In contrast to preconception, conception, belief and miscon-
ception, the terms theory, framework and science (plus plurals)
are only included in combination with the respective adjectives
(Table I), since they are often used as technical terms in
SE and unspeciﬁc for answering the research question. Same
applies to the terms student, knowledge and science, because
of the usage of pedagogical databases. These are combined
with the disciplinary focus on SE, resulting in Search Query 1;
including wildcards (*) and search for exact phrases (quotation
marks). (The equivalent German SQ is not attached here.)
c) Database: Electronic literature databases are selected
based on Kitchenham et al. [25] in combination with [26].
Kitchenham et al. have already dealt intensively with SLRs in
the area of SE and set up a list of important English-language
journals and conferences, which they themselves use for their
literature research (see Table II).
2
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

(“software engineer*” OR “software development*” OR “software
process*”)
AND
(“preconception*” OR “conception*” OR “belief*” OR “misconception*”
OR
“na¨ıve theor*” OR “alternative framework*” OR
“intuitive theor*” OR “intuitive science” OR “prior knowledge”)
Query 1. English Search Query
TABLE II. SELECTION OF ELECTRONIC DATABASES FOR SLR BASED ON 
[25] [26]
Source
IEEE
ACM
SD
SC
SL
ERIC
WoS
GS
arXiv
dblp
Information and Software Technology
X
X
X
Journal of Systems and Software
X
X
X
IEEE Transactions on SE
X
X
IEEE Software
X
X
Communications of the ACM
X
ACM Computer Surveys
X
ACM Transactions on SE
Methodologies
X
Software Practice and Experience
X
Empirical SE Journal
X
IEEE Proc. Software (now: IET
Software)
X
X
Proc. Int. Conference on SE
X
X
X
Proc. Int. Symp. of Software Metrics
X
X
X
Proc. Int. Symp. on Empirical SE
X
X
X
These are used as a basis to identify databases that include
these compilations, namely: IEEE-Xplore [28], ACM-Digital
Library [29], SpringerLink (SL) [30], Scopus (SC) [31], and
Science Direct (SD) [32]. This selection is supplemented by
further search engines from the educational context (ERIC
[33], Web of Science (WoS) [34]) and the metadata database
GoogleScholar (GS) [35]. In addition to the proposed ones,
arXiv [36], an open access repository for electronic preprints
from numerous areas – including computer science –, and
the dblp [37], which is co-founded by the German federal
government, are used.
3) Selection Strategy: The selection is controlled on the
basis of the following predeﬁned Inclusion (IC) and Exclusion
Criteria (EC).
IC.1 The publication is written in English or German lan-
guage.
IC.2 It is explicitly about the discipline SE.
IC.3 Misconceptions in SE are explicitly mentioned.
EC.1 The contribution is an abstract, workshop, poster, or
similar, as these do not provide in-depth information.
4) Quality Assessment: The gathered publications have to
be qualiﬁed against predeﬁned Quality Criteria (QC):
QC.1 Traceability: How do the authors know this misconcep-
tion? It is scientiﬁcally important to be able to track
where the information comes from.
QC.2 Validation: Has it been conﬁrmed that it is a miscon-
ception? How did the authors validate the conception to
be “at odds with modern scientiﬁc theories” [4, p. 2]?
If not done, there is no indication that it is really a
misconception.
QC.3 Occurence in the population: Does this misconcep-
tion exist in the population? Did the authors test the
misconception in a speciﬁc target group? Otherwise,
the existence of the misconception is not empirically
proven at all or limited to individual subjects (e.g.
through interviews).
B. Phase 2: Conducting the SLR
The process of conducting the SLR is shown in Figure 2 as
Phase 2 of the overall process.
Fig. 2. Flowchart of the SLR process (based on [23][24][27])
1) Stage 1: Conducting the Automated Search: For the
search – if possible – use of extended/advanced search 
functions, wildcards (e.g., “misconception*”), and Boolean 
operators is made in order to be able to exploit the predeﬁned 
syntax of the query (see String 1). Nevertheless, the string 
must be adapted to the options of the search engine. Care is 
taken to ensure no semantic changes take place.
The SQ is limited to document title and abstract, as rec-
ommended by [27, p. 2050] as well as others. (Deviations 
from this deﬁnition, due to the search options of the individual 
databases, are documented accordingly in the evaluation in 
Section III). The reason for this is that both metadata are 
already indicators of the relevance of a publication.
3
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

TABLE III. SUMMARY OF SLR RESULTS AFTER APPLYING IN-/EXCLUSION CRITERIA ON TITLE & ABSTRACT
Search Engines
Sum
IEEE
ACM
SD
SC
SL
ERIC
WoS
GS
arXiv
dblp
Results of English SQ
250
410
93
847
0
29
4
87
257
41
2,018
Results of German SQ
16
54
7
46
0
3
0
7
2
5
140
Sum of Search Results
266
464
100
893
0
32
4
94
259
46
2,158
No Papers (e.g. Proc.)
2
2
0
53
0
2
0
34
6
0
99
Duplicates
15
85
18
383
0
10
4
16
18
29
578
Balance without Duplicates
249
377
82
457
0
20
0
44
235
17
1,481
IC.1a:
English
249
352
81
442
0
20
0
40
231
10
1,425
IC.1b:
German
0
0
0
5
0
0
0
1
0
0
6
IC.2:
SE Discipline-Speciﬁc
223
253
65
381
0
18
0
34
162
7
1,143
IC.3:
Misconceptions
30
60
4
43
0
8
0
6
5
2
158
EC.1:
Contribution Type
0
1
0
0
0
1
0
0
0
0
2
EC:
No Information
0
0
0
1
0
0
0
2
0
0
3
Paper Candidates
29
40
4
37
0
6
0
5
5
2
128
Note: At this point, IC.3 is not completely applicable,
since misconceptions are not speciﬁcally mentioned in title &
abstract, but it is checked, whether the contribution is explicitly
about misconceptions.
2) Stage 2: Applying the In-/Exclusion Criteria: The rel-
evance of a publication is determined in a two-stage process
(see Figure 2, Stage 2). First of all, the title and abstract are
examined and evaluated on the basis of the predeﬁned criteria.
These provide enough information to decide whether a pub-
lication encompasses insights of interest; in doubt they were
included. The papers included are then rechecked regarding
the in-/exclusion criteria; this time considering the full text.
3) Stage 3: Backward Snowballing: Once Stage 2 is com-
pleted, “the references of the selected papers [are] reviewed
and any missing candidate papers [are] assessed against the
inclusion/exclusion criteria” [27, p. 2052] as well; this is
referred to as ‘backward snowballing’.
4) Stage 4: Data Analysis: To assess the quality of the
methods and results in the gathered publications, quality
criteria have to be predeﬁned against which to assess the data
extracted and synthesized.
III. PHASE 3: RESULTS
The results of the coarse search based on the selection
criteria (Section II-A3) applied to titles and abstracts (Section
III-A) and the detailed search using full texts (Section III-B)
are presented. Additionally, the results of the analysis of the
misconceptions found in the selected publications is shown in
Section III-C, which is based on the QCs (Section II-A4).
A. Results: Coarse Search
The automated search has been completed between April,
30th and May, 1st 2020. Since the search was not limited
to a date range, the review process timewise included every
research found, covering papers as of 1970. Table III illus-
trates the number of matches (n = 2, 158) initially received
through the SQs. Excluding data sets that contained entire
proceedings/compilations instead of contributions as well as
duplicates, results in n = 1, 481. Finally, after applying the
inclusion and exclusion criteria to title and abstract, n = 128
papers/articles can be identiﬁed as potentially relevant to our
interest. Therefore, only these are considered in the next step, 
in which the full text of these publications is considered.
Duplicates could be localized both internally – within the 
results of the same SQ, within the same database, or overlaps 
between English and German SQs – and externally – between 
the results of different search engines. The number of dupli-
cates can be seen in Table IV including multiple mentioning, 
as papers might be found in multiple databases. (Therefore, 
the sums are not equivalent with the numbers of duplicates 
in Table III.)
TABLE IV. NUMBER OF DUPLICATES
IEEE
ACM
SD
SC
SL
ERIC
WoS
GS
arXiv
dblp
IEEE
15
32
222
1
2
15
5
12
ACM
54
111
9
4
7
SD
18
60
4
2
SC
53
7
4
31
10
21
SL
0
ERIC
3
3
WoS
0
3
4
GS
17
19
arXiv
8
2
dblp
4
B. Results: Full Text Search
Proceeding further, the predeﬁned inclusion and exclusion
criteria are then applied to the paper candidates based on the
full text of the contributions. This results in n = 15 papers
that match the criteria (see Table V, on the next page). Papers
are excluded that cover the topic ‘misconception’, but did not
explicitly mention at least one statement the respective authors
refer to as misconception concerning the topic SE (cf. IC.3).
The subsequent backward snowball search – based on the
adequate papers found – reveals some additional publications
that have been checked against the inclusion/exclusion criteria
listed as well. Summing up, a total of n = 18 papers are found
(see Table V) that are of interest to the research question of
this SLR.
Through the selection process in Stage 2 and Backward
Snowballing in Stage 3 as a whole, we double-checked the
contributions by assessing each paper. As Kitchenham et
al. suggest, publications are included if we cannot make a
consensual decision [27, p. 2052].
4
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

TABLE V. SUMMARY OF SLR RESULTS AFTER APPLYING IN-/EXCLUSION CRITERIA ON FULL TEXTS
Search Engines
Sum
IEEE
ACM
SD
SC
SL
ERIC
WoS
GS
arXiv
dblp
Paper Candidates (see Table III)
29
40
4
37
0
6
0
5
5
2
128
IC.1a: English
29
40
4
37
0
6
0
5
5
2
128
IC.1b: German
0
0
0
0
0
0
0
0
0
0
0
IC.2: SE Discipline
29
40
4
37
0
6
0
4
5
2
127
IC.3: Mention Misconceptions
5
3
1
2
0
0
0
1
3
0
15
Papers Found
5
3
1
2
0
0
0
1
3
0
15
Backward Snowballing
27
5
0
2
0
0
0
1
4
0
39
Already Included in SLR
2
1
0
1
0
0
0
0
2
0
6
After Applying Selection Criteria
0
0
0
1
0
0
0
0
2
0
3
Result
5
3
1
3
0
0
0
1
5
0
18
The matching papers found (n = 18, shown as the result in
Table V) are listed below:
• IEEE: [38]–[42]
• ACM: [43]–[45]
• Science Direct: [46]
• SCOPUS: [47] (cites and covers the myths of the primary 
source [48] and 7 new statements) [48][49]
• Google Scholar: [50]
• arXiv: [51][52] (is included in [53] and thus not con-
sidered further) [53][54] (is the basis for [53]); and thus 
considered together, covering 21 misconceptions in total)
[55]
C. Results: Misconceptions Found
Within the publications named, a total of 167 individ-
ual statements (see Table VI; without cross-references) are
declared as misconceptions by the respective authors. The
misconceptions gathered should be evaluated by assessing the
quality of the publications in order to determine the capacity
of the ﬁndings, using the quality criteria from Section II-A4.
The coding of the subcategories of the quality criteria was
not determined in advance, but developed during the analysis
based on and close to the available data; i.e. the publications
themselves. The following subcategories are considered as
high-quality (see grey marking in Table VI):
QC.1 Traceability: A primary study as well as the reference to
quotable publication(s), in which the misconception(s)
TABLE VI. SUMMARY OF MISCONCEPTIONS FOUND IN THE FULL TEXTS USING THE QUALITY CRITERIA
Papers Found
Sum
[38]
[39]
[40]
[41]
[42]
[43]
[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[53]
[54]
[55]
17
Misconceptions explicitly named
16
12
12
7
6
4
5
12
4
7
7
10
36
4
10
21
4
167
QC.1:
- Study
4
36
21 (in [54])
51
Traceability
- Reference(s)
15
6
6
37
- No Indication
1
6
12
7
5
12
4
7
7
10
4
4
79
QC.2:
- Empirically Conﬁrmed
12
8 (in [53])
20
Validation
- Empirically Rejected
2 (in [53])
2
- Reference(s)
6
6
5
17
- Only based on Explanation
4
4
7
7
10
4
36
- No Indication
10
6
12
2
6
5
36
11
4
92
QC.3:
- Practitioners
16
6
4
21 (in [54])
37
Occurrence
- Undergraduates
12
12
12
36
- No Indication
7
5
4
7
7
10
36
4
10/21 (in [53])
4
94
Intersection (of rows marked)
12
8
20
were found is deﬁned as satisfying scientiﬁc claims.
In contrast, no indication is insufﬁcient.
QC.2 Validation: The conception has to be empirically con-
ﬁrmed as “at odds with modern scientiﬁc theories” [4,
p. 2] to be a misconception. Whereas, a rejection, an
explanation by the author(s) or reference(s) that the
statement given is supposed to be a misconception is no
sufﬁcient evidence for validation. This is also due to the
fact that misconceptions exist in all ages, from primary
level to university and even experts and professors can
hold them themselves [56, p. 9, 11].
QC.3 Occurrence in the population: Practitioners misconcep-
tions are included, as it is very likely that students have
them as well, if they can be encountered in profession-
ally experienced. However, no indication of occurrence
in the population can initially only be interpreted as a
presumption.
The intersection of the QCs results in n = 20 misconcep-
tions (Table VI). Yet, the papers [53] and [54] only deal with
the topic ’defect prediction’, the authors of [45] look at SE
covering the software life cycle more holistically; see thematic
structuring in Table VII (on the next page).
Note: [45] would actually not be included in the intersection,
as it is not explained where the misconceptions come from
(QC.1). But the authors validated them (QC.2) and tested their
occurrence concerning students (QC.3). Thus, the misconcep-
tions listed are hypotheses, that have been empirically con-
ﬁrmed; thus, nevertheless, they are included in the intersection.
5
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

TABLE VII. LIST OF MISCONCEPTIONS MATCHING THE QUALITY CRITERIA
Topic(s)
Project
Process Models
Team Skills
Reuqirements
Implementation
Defects
Documentation
Misconception
Reference(s)
X
A deﬁned software process is only important when you are working with people who are less skilled.
[45, (1)]
X
A good software developer will often choose to work alone on a project in order to get it done faster.
[45, (2)]
X X
When you have a team of good programmers who work well together, a software process will usually get in the way.
[45, (3)]
X
My code should take advantage of the implementation details in other code.
[45, (4)]
X
It is expected that clients will describe their requirements accurately before a team begins programming.
[45, (5)]
X
As a software developer, most of my time will be spent designing and implementing new algorithms and data structures.
[45, (6)]
X
Most of the time when I start a new programming task in industry, I will be working on a new project.
[45, (7)]
X
Developers do not need to know the high-level context of the system; this allows them to concentrate on their task.
[45, (8)]
X
A software project is successful only if it ships with very few known defects.
[45, (9)]
X
Software engineering is about producing lots of documentation on the requirements and implementation of the project.
[45, (10)]
X X X
Process, requirements, and team-management are important to business majors, not software developers.
[45, (11)]
X
The majority of the cost of a successful software project will be the initial implementation effort.
[45, (12)]
X
A ﬁle with a complex code change process tends to be buggy.
[53, (B1)], [54, (S2)]
X
A ﬁle that is changed by more developers is more bug-prone.
[53, (B2)], [54, (S14)]
X
A ﬁle with more added lines is more bug-prone.
[53, (B3)], [54, (S4)]
X
Recently changed ﬁles tend to be buggy.
[53, (B4)], [54, (S7)]
X
Recently bug-ﬁxed ﬁles tend to be buggy.
[53, (B6)], [54, (S10)]
X
A ﬁle with more ﬁxed bugs tends to be more bug-prone.
[53, (B7)], [54, (S11)]
X
A ﬁle with more commits is more bug-prone.
[53, (B8)], [54, (S12)]
X
A ﬁle with more removed lines is more bug-prone.
[53, (B9)], [54, (S13)]
IV. DISCUSSION
A. Methodology: Threats to Validity
Several aspects regarding the SLR should be remarked upon.
First, one signiﬁcant limitation is the broad number of syn-
onyms for ’misconception’; it is almost impossible – despite
all efforts – to ensure that all relevant papers are found.
Second, we used the four-eyes principle to proceed and
discussed to achieve consensus, but enclosed papers causing
persistent disagreement. However, this is not an ideal process,
affecting reliability of assessment and evidence of results.
Third, a limitation is that own publications could turn out
to be matches in the SLR, which must be handled objectively.
This can result in a systematic error. It is therefore noted that
authors of this paper also authored the publication [50].
B. Discussion of Results
Regarding the results of the SLR, it is noted that the cut
of 2,158 publications to merely 3 [45] [53] [54] of interest
identiﬁed is immense. As a result, it could be assumed that the
search (engines/query) or the selection (in-/exclusion/quality
criteria) are inadequate. However, this contradicts that ...
• ... SE didactics are still developing.
• ... the consideration of another database (Section I-B, [9])
also indicates that little research is available to date.
• ... other authors report the same for the adjacent ﬁeld of
computer sciences: “At present, hardly any empirical data
concerning the issue of expectations and prior knowledge
[...] in informatics [...] are available” [57, p. 143].
V. CONCLUSION
The paper’s purpose, to identify and analyse known
misconceptions
in
SE
to
use
these
insights
in
higher
education, has been pursued using a systematic literature
review. Predeﬁned search queries have been applied to search
10 databases before the publications have been ﬁltered using
the selection strategy described. Out of 2,158 publications, 18
could be identiﬁed as appropriate for the selection criteria.
These contain 167 statements, which the authors of these
papers refer to as misconceptions. 20 of them met the quality
criteria speciﬁed; i.e. only 3 publications cover valuable data.
To conclude, the results show that currently evidence-based
research on misconceptions in SE is limited; this secondary
study demonstrates, there is not enough research on evidence-
based misconceptions in SE to use these insights for higher
education. So, in addition a primary study to identify miscon-
ception in SE is indispensable before addressing them.
ACKNOWLEDGEMENT
The present work as part of the EVELIN project was funded
by the German Federal Ministry of Education and Research
(BMBF) under grant numbers 01PL17022B and 01PL17022A.
The authors are responsible for the content of this publication.
REFERENCES
[1] R. Duit, “Science education research internationally: Conceptions, re-
search methods, domains of research,” EURASIA Journal of Mathemat-
ics, Science & Technology Education, vol. 3, no. 1, pp. 3–15, 2007.
[2] R. Duit, H. Gropengießer, U. Kattmann, M. Komorek, and I. Parch-
mann, “The model of educational reconstruction,” in Science Education
Research and Practice, D. Jorde and J. Dillon, Eds.
Springer, 2012,
pp. 13–37.
[3] J. P. Smith, A. A. diSessa, and J. Roschelle, “Misconceptions recon-
ceived: A constructivist analysis of knowledge in transition,” Journal of
the Learning Sciences, vol. 3, no. 2, pp. 115–163, 1994.
[4] J. R. Read, “Children’s misconceptions and conceptual change in
science education,” 2004, [retrieved: 09, 2020]. [Online]. Available:
http://acell.chem.usyd.edu.au/Conceptual-Change.cfm
[5] I. Diethelm and S. Zumbr¨agel, “An investigation of secondary school
students’ conceptions on how the internet works,” in Koli Calling Inter-
national Conference on Computing Education Research, M.-J. Laakso
and R. McCartney, Eds.
ACM Press, 2012, pp. 67–73.
[6] S. Todtenhaupt, To develop an understanding of chemistry in schoolchil-
dren: An investigation into the redox topic at a high school. (Original
title: ”Zur Entwicklung des Chemieverst¨andnisses bei Sch¨ulern: Eine
Untersuchung zur Redox-Thematik an einem Gymnasium” [German]).
Frankfurt a.M.: Lang, 1995.
6
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

[7] A. Taylor Kujawski, and P. Kowalski, “Na¨ıve psychological science: the
prevalence, strength, and source of misconceptions,” The Psychological
Record, vol. 54, pp. 15–25, 2004.
[8] R. Reuter, F. Hauser, C. Gold-Veerkamp, J. Mottok, and J. Abke,
“Towards a deﬁnition and identiﬁcation of learning obstacles in higher
software engineering education,” in Annual International Conference on
Education and New Learning Technologies (EDULEARN), IATED, Ed.,
2017, pp. 10 259–10 267.
[9] R. Duit, “STCSE: Students’ and teachers’ conceptions and science
education,”
Bibiography,
2009,
[retrieved:
09,
2020].
[Online].
Available: http://archiv.ipn.uni-kiel.de/stcse/download stcse.html
[10] D. N. Perkins and R. Simmons, “Patterns of misunderstanding: An
integrative model of misconceptions in science, math and programming,”
in 2. Int. Seminar Misconceptions and Educational Strategies in Science
and Mathematics: Vol. I, J. D. Novak, Ed., 1987, pp. 381–395.
[11] ——, “Patterns of misunderstanding: An integrative model for science,
math, and programming,” Review of Educational Research, vol. 58,
no. 3, pp. 303–326, 1988.
[12] L. Louca and Z. C. Zacharia, “The use of computer-based programming
environments as computer modelling tools in early science education:
The cases of textual and graphical program languages,” International
Journal of Science Education, vol. 30, no. 3, pp. 287–324, 2008.
[13] J. Confrey, “Misconceptions across subject matter: science, mathematics,
programming,” in 2. Int. Seminar Misconceptions and Educational
Strategies in Science and Mathematics: Vol. I, J. D. Novak, Ed., 1987,
pp. 81–106.
[14] N. Taylor and G. Corrigan, “New South Wales primary school teachers’
perceptions of the role of ICT in the primary science curriculum - A
rural and regional perspective,” International Journal of Science and
Mathematics Education, vol. 5, no. 1, pp. 85–109, 2007.
[15] R. D. Pea, “Language-independent conceptual ”bugs” in novice pro-
gramming,” Journal educational computing research, vol. 2, no. 1, pp.
25–36, 1986.
[16] J. Sorva, “Visual program simulation in introductory programming
education.” Dissertation, Espoo, Aalto Univ., Finland, 2012.
[17] A. Swidan, F. Hermans, and M. Smit, “Programming misconceptions for
school students,” in Conference on International Computing Education
Research (ICER).
ACM, 2018, pp. 151–159.
[18] ˇZ. ˇZanko, M. Mladenovi´c, and I. Boljat, “Misconceptions about variables
at the K-12 level,” Education and Information Technologies, vol. 24,
no. 2, pp. 1251–1268, 2019.
[19] R. Kelter, M. Kramer, and T. Brinda, “Statistical frequency-analysis
of misconceptions in object-oriented-programming: Regularized pcr
models for frequency analysis across oop concepts and related factors,”
in Koli Calling International Conference on Computing Education
Research, M. Joy and P. Ihantola, Eds.
ACM, 2018, pp. 6:1–6:10.
[20] S. Holland, R. Grifﬁths, and M. Woodman, “Avoiding object misconcep-
tions,” in SIGCSE technical symposium on Computer science education,
C. M. White, C. Erickson, B. Klein, and J. E. Miller, Eds. ACM, 1997,
pp. 131–134.
[21] M. T. R¨ucker and N. Pinkwart, “”How else should it work?” A grounded
theory of pre-college students’ understanding of computing devices,”
ACM Transactions on Computing Education, vol. 19, no. 1, pp. 2:1–
2:23, 2018.
[22] I. Diethelm, P. Hubwieser, and R. Klaus, “Students, teachers and
phenomena: Educational reconstruction for computer science education,”
in Koli Calling International Conference on Computing Education
Research, M.-J. Laakso and R. McCartney, Eds.
ACM, 2012, pp. 164–
173.
[23] B. A. Kitchenham and S. Charters, “Guidelines for performing sys-
tematic literature reviews in software engineering: Version 2.3,” EBSE
Technical Report (EBSE-2007-01), Keele University & University of
Durham, 2007.
[24] P. O. Brereton, B. A. Kitchenham, D. Budgen, M. Turner, and M. Khalil,
“Lessons from applying the systematic literature review process within
the software engineering domain,” Journal of Systems and Software,
vol. 80, no. 4, pp. 571–583, 2007.
[25] B. A. Kitchenham, et al., “Systematic literature reviews in software
engineering – a systematic literature review,” Information and Software
Technology, vol. 51, no. 1, pp. 7–15, 2009.
[26] A. Bartel, “Conception and development of a DSM-based gamiﬁca-
tion authoring system to support university teaching. (Original title:
”Konzeption und Entwicklung eines DSM-basierten Gamiﬁcation Au-
thoring Systems zur Unterst¨utzung hochschulischer Lehre” [German]),”
Dissertation, Universit¨at Regensburg, 2018.
[27] B. A. Kitchenham and P. O. Brereton, “A systematic review of systematic
review process research in software engineering,” Information and
Software Technology, vol. 55, no. 12, pp. 2049–2075, 2013.
[28] IEEE, “IEEE Xplore Digital Library,” 2020. [Online]. Available:
https://ieeexplore.ieee.org/Xplore/home.jsp
[29] ACM,
“ACM
Digital
Library,”
2020.
[Online].
Available:
http:
//dl.acm.org/
[30] Springer Nature Switzerland AG, “SpringerLink,” 2020. [Online].
Available: https://link.springer.com/
[31] Elsevier B.V., “Scopus,” 2020. [Online]. Available: http://www.scopus.
com/
[32] ——,
“ScienceDirect,”
2020.
[Online].
Available:
https://www.
sciencedirect.com/
[33] Institute of Education Sciences of the US Department of Education,
“Eric – education resources information center,” 2020. [Online].
Available: https://eric.ed.gov/
[34] Clarivate Analytics, “Web of Science,” 2020. [Online]. Available:
http://www.webofknowledge.com
[35] Google LLC, “Google Scholar,” 2020. [Online]. Available: http:
//scholar.google.de/
[36] Cornell
University,
“arXiv.org:
e-Print
archive,”
2020.
[Online].
Available: https://arxiv.org/
[37] Schloss Dagstuhl and Universit¨at Trier, “dblp: computer science
bibliography,” 2020. [Online]. Available: https://dblp.uni-trier.de/
[38] P. Devanbu, T. Zimmermann, and C. Bird, “Belief evidence in empirical
software engineering,” in International Conference on Software Engi-
neering (ICSE), 2016, pp. 108–119.
[39] M. M. Inuwa and A. Varol, “Intensity of misconception in software
engineering,” in International Informatics and Software Engineering
Conference (UBMYK), 2019, pp. 1–6.
[40] J. Ivins, B. R. von Konsky, D. Cooper, and M. Robey, “Software
engineers and engineering: A survey of undergraduate preconceptions,”
in Frontiers in Education (FIE), 2006, pp. MIF–6–11.
[41] B.
¨Ozkan and O. Demirors, “On the seven misconceptions about
functional size measurement,” in Joint Conference of the International
Workshop on Software Measurement and the International Conference
on Software Process and Product Measurement (IWSM-MENSURA),
2016, pp. 45–52.
[42] J. S. van der Ven and J. Bosch, “Busting software architecture beliefs: A
survey on success factors in architecture decision making,” in Euromi-
cro Conference on Software Engineering and Advanced Applications
(SEAA), 2016, pp. 42–49.
[43] A. Begel and B. Simon, “Struggles of new college graduates in their ﬁrst
software development job,” SIGCSE Bull, vol. 40, no. 1, pp. 226–230,
2008.
[44] D. DeMarco Brown, “Five agile ux myths,” Journal of Usability Studies,
vol. 8, no. 3, pp. 55–60, 2013.
[45] L. A. Sudol and C. Jaspan, “Analyzing the strength of undergraduate
misconceptions about software engineering,” in International Computing
Education Research (ICER).
ACM, 2010, pp. 31–39.
[46] R. H. Wilcox, “Behavioral misconceptions facing the software engineer,”
in Computer and Information Sciences, ser. SEN Report Series Software
Engineering, J. T. Tou, Ed.
Elsevier, 1971, vol. 2, pp. 285–287.
[47] J. P. Bowen and M. G. Hinchey, “Seven more myths of formal meth-
ods: Dispelling industrial prejudices,” in FME’94: Industrial Beneﬁt of
Formal Methods, ser. LNCS 873.
Springer, 1994, pp. 105–117.
[48] A. Hall, “Seven myths of formal methods,” IEEE Software, vol. 7, no. 5,
pp. 11–19, 1990.
[49] D. Carlson, “Debunking agile myths,” CrossTalk, vol. 30, no. 3, pp.
32–36, 2017.
[50] S. Jahn, C. Gold-Veerkamp, R. Reuter, J. Mottok, and J. Abke, “Secure
software engineering in academic education: Students’ preconceptions
of it security,” in International Conference of Education, Research and
Innovation (ICERI), IATED, Ed., 2019, pp. 6825–6834.
[51] P. Ralph and B. J. Oates, “The dangerous dogmas of software
engineering,” 2018, [retrieved: 09, 2020]. [Online]. Available: arXiv:
1802.06321v1
[52] Shrikanth N. C. and T. Menzies, “Assessing developer beliefs: A reply
to ”perceptions, expectations, and challenges in defect prediction”,”
2019, [retrieved: 09, 2020]. [Online]. Available: arXiv:1904.05794v1
7
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

[53] ——, “Assessing practitioner beliefs about software defect prediction,”
2020, accepted at ICSE’20, [retrieved: 09, 2020]. [Online]. Available:
arXiv:1912.10093v3
[54] Z. Wan et al., “Perceptions, expectations, and challenges in defect
prediction,” IEEE Transactions on Software Engineering, pp. 1–26,
2018.
[55] D. Rombach and F. Seelisch, “Formalism in software engineerings:
Myths versus empirical facts,” in Balancing Agility and Formalism in
Software Engineering, D. Hutchison, et al., Ed.
Springer, 2008, pp.
13–25.
[56] R. Duit, “Sch¨ulervorstellungen – von Lerndeﬁziten zu neuen Unterricht-
sans¨atzen [German],” in Sch¨ulervorstellungen in der Physik, R. M¨uller,
R. Wodzinski, and M. Hopf, Eds.
K¨oln: Aulis, 2011, pp. 8–14.
[57] C. Schulte and J. Magenheim, “Novices’ expectations and prior knowl-
edge of software development,” in First international Workshop on Com-
puting education research, R. Anderson, S. A. Fincher, and M. Guzdial,
Eds.
ACM Press, 2005, pp. 143–153.
8
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-827-3
ICSEA 2020 : The Fifteenth International Conference on Software Engineering Advances

