324
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Designing for Experienced Simplicity 
Why Analytic and Imagined Simplicity Fail in Design of Assistive Technology
Suhas Govind Joshi 
Department of Informatics 
Faculty of Mathematics and Natural Sciences, University of Oslo 
Oslo, Norway 
joshi@ifi.uio.no 
 
 
Abstract— This paper uses the design of assistive technology 
for elderly people as a case for exploring why analytic or 
imagined simplicity often end up as complicated and 
incomprehensible in use. Our claim is that building on mastery 
and context is more important than objective guidelines on 
simplicity. Rather than relying solely on context-detached 
principles that cannot guarantee simplicity in use, we 
introduce the term experienced simplicity as a way of shifting 
focus from how designers shape the design, to how users 
experience the design. Finally, we present and discuss five 
design implications for experienced simplicity. 
Keywords — simplicity; elderly; assistive technology. 
I. 
 INTRODUCTION 
As assistive technology is being rolled out in large scale in 
Norway, designers are aiming at delivering simple 
interactions specially adapted and tailored for the needs of 
elderly people. Most designers follow principles of 
simplicity (e.g., minimalism) in order to create a design 
simple enough for elderly people with reduced experience 
and capacities to interact with the technology. However, 
designing for simplicity does not guarantee simplicity in use, 
and our prior research has demonstrated how designs 
claiming to be simple can end up making life difficult [1].  
One of the technological devices found in the apartment 
of an 84-year-old lady residing in a local care home in Oslo 
is an automated light sensor in her living room. Because of 
the small size of her apartment she sleeps with the door open, 
and when she turns in bed at night the sensor in the living 
room registers her movement and the light is activated 
throughout the apartment. Her solution to this was to cover 
the sensor with tinfoil (as illustrated in Figure 1).  
 
 
 
Figure 1. Covering a sensor with tinfoil (Photo: S. Finken [2]) 
 
This observation exemplified how simple technology may 
end up making life difficult, and served as a trigger for us to 
explore the matter of simplicity. In this paper, we (1) 
investigate why existing assistive technology claiming to be 
simple end up as difficult in use by looking at simplicity 
from the perspective of the elderly users rather than the 
designer, and we (2) introduce experienced simplicity as a 
term that focus on the use rather than the isolated design. We 
discuss why it is challenging to design technology simple for 
others, in this particular case making assistive technology 
simple for the elderly users. The discussion is grounded in 
data gathered with three different evaluation methods 
spanning over 13 months. We have engaged 45 participants, 
including 30 elderly people with an average age of 86 years. 
The paper is structured as follows. In Section II, we give 
an analysis of simplicity in the literature, as well as our 
perspective on the matter. In Sections III and IV, we outline 
the research context and research methods of our study 
before presenting the results in Section V. We end the paper 
with a discussion in Section VI on why simplicity is 
challenging through five implications for design pursuing 
experienced simplicity. 
II. 
SIMPLICITY 
A. Defining simplicity 
In the complex world we live in, taming the complexity is 
one of our major goals with human-centered design [3].  
Simplicity in its most elementary definition describes 
something with an uncomplicated quality or condition. 
Researchers have applied the concept of simplicity to 
various research studies within various disciplines of 
computer science. Over time, this vague definition of 
simplicity has made it applicable to different areas of 
computer science, and in several disciplines the term has 
evolved into an established term with a more refined and 
tailored use mainly applicable to that specific discipline or 
context. As a philosophical principle, simplicity can be 
differentiated into ontological simplicity, following the 
principle 
of 
parsimony, 
and syntactical 
(structural) 
simplicity, perceived as elegance [4]. Hence, the theoretical 
perspective of the researchers in the debate of philosophy of 
science can heavily influence how they perceive and apply 
such a term. Lee et al. [5] describes simplicity within the 

325
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
area of Human-Computer Interaction (HCI) as “not only 
simple page layout but also interface organization, 
functionality, structure, and workflow and framework”. 
Following this definition, simplicity in HCI encompasses 
various elements and researchers tend to find their own 
perspectives and definitions to simplicity. One of the most 
cited authors on simplicity, Maeda [6], defines his ten laws 
of simplicity (reduce, organize, time, learn, differences, 
context, emotion, trust, failure and the one). On the other 
hand, Colborne [7] concentrates on only four strategies 
(remove, organize, hide and displace) in his discussion on 
simplifying devices and experiences. Simplicity has also 
been analyzed through the notion of minimalism by 
Obendorf [8] who defines four types of minimalism 
(functional, structural, compositional and architectural) and 
utilize this perspective on minimalism to discuss simplicity 
in HCI. However, as Picking et al. [9] points out, design 
principles are in general often formulated as brief guidelines 
that aim to cover wide areas of application and apply to 
multiple domains simultaneously; it is difficult to use these 
guidelines consistently as they rarely specify which specific 
design choices to make. Since laws, strategies and principles 
for simplicity can serve as everything from minor 
inspirations to governing factors, Obendorf [8] have called 
for more differentiated and concretized definitions of how 
simplicity is understood, and exactly how it influences the 
design outcome. 
Several researchers have pointed out the importance of 
simplicity as a design principle in systems designed for the 
older population [10]-[12], however, prior studies [4] [1] 
suggest that perceived simplicity is context-dependent and 
relies heavily on the users’ previous exposure. As a result, 
we want to expand on the definitions of simplicity currently 
found in the literature (summarized in Table I). 
 
TABLE I. OVERVIEW OF DEFINITIONS OF SIMPLICITY 
Related work Definition 
Lee et al. [5] 
“not only simple page layout but also interface 
organization, functionality, structure, and workflow 
and framework” 
Maeda [6] 
Ten principles of simplicity: reduce, organize, time, 
learn, differences, context, emotion, trust, failure and 
the one. 
Colborne [7] 
Strategies for simplicity: remove, organize, hide and 
displace. 
Obendorf [8] 
Minimalism: functional, structural, compositional and 
architectural. 
 
B. Experienced simplicity 
Our understanding of simplicity is anchored in two main 
elements, namely mastery and context. Both of these 
elements revolve around the users' experience and 
perception of the system in use rather than the isolated and 
context-detached design itself; simplicity is a characteristic 
of a system that manifests itself once the intended users take 
use of the system in its appropriate context. When using 
simplicity as a design guideline, one should always envision 
the act of simplification resulting in positive effects on the 
mastery of the user in the desired context. Blindly following 
simplicity as a design principle, e.g., reducing or hiding 
elements because general rulebook on simplicity says so, 
ignores the true intention behind the design choice, namely 
disentangling the perceived complexity. We have labeled 
this perspective on simplicity as experienced simplicity as it 
shifts focus on simplicity from something the designer use 
as a guideline to something we can only confirm through 
user experience. A design is not simple unless the user 
perceives the interaction to be simple in use. 
However, analyzing the simplicity laws and principles of 
Maeda, Colborne and Obendorf one quickly register that 
these laws mainly consider simplicity as context-
independent. All of Colborne’s four principles encourage 
modification to the design detached from the eventual 
context. Similarly, Obendorf relies on minimalism which 
itself does not automatically ensure systems free of 
complexity; it only encourages basic design with deliberate 
lack of decoration without discussing the perceived 
simplicity. From Maeda's ten laws we can extract five laws 
concerning the relational use of the system rather than the 
system itself, namely time, learn, context, emotions and 
trust. Only these laws reflect how we understand simplicity, 
i.e., rather than being a term of size, quantity or volume, it 
should first and foremost reflect the contextual experience. 
Thus, simplicity in a system is not something one adds to 
the design; it is something achieved once mastery is 
uncomplicated in its appropriate context.  
Our view on simplicity aligns with the research of Eytam 
and Tractinsky [13] who suggest that the ability to design 
own complexities can be a desire among users. They define 
this contrast between advocated guidelines for simplicity and 
the observed behavior as the paradox of simplicity, and argue 
that simplicity is not defined in objective guidelines, but 
rather a quality to be understood through how the users 
perceive simplicity. The explicit focus on the users’ side of 
the interaction in HCI influences how we discuss the concept 
of simplicity how it is a matter of more than just reducing 
complexity; simplification is an intricate and dynamic design 
principle embracing factors such as mastery and context of 
use as examples of decisive factors of simplicity. This is also 
in line with [4] who suggest that simplicity as a design 
principle should be a complex and flexible design paradigm 
rather than a simple dichotomous variable, incorporating 
elements such as user interface design, as well as contextual 
factors (for example integration to other IS). Keay-Bright 
and Howarth [14] focus on designing intuitive interfaces and 
describe simplicity not as a compromise in richness or 
diversity of human experience, but rather a minimal interface 
that empowers the users to design their own complexities 
that ensures mastery. 
Another early supporter of our perspective is Norman who 
claimed that designing solely for simplicity would force a 
compromise on functionality [3]. He pointed out two 
common implicit assumptions that designers rely on: (1) that 

326
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
features equals capability, and (2) that simplicity equals ease 
of use. He argued that this one-way logic does not have any 
guaranteed backwards mechanism. Thus, if we want to 
achieve capable and usable systems, designing for simplicity 
alone will not automatically deliver our desired solution: 
"Features do not equal capability. Simplicity is not the same 
as usability. Simplicity is not the answer." [3]. 
III. 
RESEARCH CONTEXT 
A. Empirical context 
This study is part of a larger long-term research project 
focusing on newly acquired assistive technology in local 
care homes in Oslo Municipality. The particular local care 
home involved in this study consists of 91 individual 
apartments for the elderly residents (with an average age of 
84 years) organized with common reception, cantina and 
recreation room (depicted in Figure 2). There are no medical 
services provided, and those in need organize their own 
arrangements with the district home care services. However, 
the residents have access to basic services such as 
hairdressing, foot therapist, gym and cinema. The goal of 
the local care home is to be a smart house, for instance 
actively utilizing technology in order to prolong the time 
elderly people can remain independent in their own homes 
before being admitted to a nursing home.  
 
 
 
Figure 2. The reception and common area of the local care home 
 
Each individual apartment comes pre-installed with a set 
of new technologies, including automated lighting, heating 
and ventilation control, stove guard, electrical sockets with 
timers, motion sensors in all rooms, video calling, door 
locks with radio-frequency identification (RFID), and a 
customized tablet. Ever since the building opened in 2012, 
our research group has been present at this facility, and this 
local care home is an excellent arena to study existing 
technology. It also serves a venue where we experiment 
with new and alternative assistive technology. 
 
B. Technology under evaluation 
For the purpose of evaluation in this study, we included 
the tablet and some of the room control devices found in the 
apartments of the local care home. The initial main objective 
was to concentrate solely on the tablet; however, we feared 
that only studying this touch-based device would restrict the 
discussion of simplicity to an analysis of touch-screen 
interfaces rather than being an open discussion of how users 
experience simplicity in the assistive technological devices 
that surround them. As a result, we included a set of devices 
in the room, i.e., light, temperature and ventilation systems, 
as well as the RFID door locking system. 
 
1) Tablet 
The tablet illustrated in Figure 3 comes pre-installed in all 
apartments and introduces a new way of arranging, planning 
and keeping an overview of everyday activities, as well as 
allowing residents to order meals from the downstairs 
cafeteria straight from the device. The tablet also provides 
basic opportunities for communication, namely telephoning 
and text messaging, as well as entertainment services, e.g., 
radio and an Internet browser. However, the tablet only 
comes with one mode and offers few options for 
customization, hence, flexibility and robustness is of great 
importance as it needs to support the daily activities of all 
residents and employees. 
 
 
 
Figure 3. The tablet 
 
2) Room controls devices 
Some of the pre-installed assistive technologies and 
devices in each apartment is lightning, heating and 
ventilation control in every room of the apartment. This 
includes 
automated 
motion-activated 
light 
sensors, 
automated 
thermostat 
and 
automated 
adjustment 
of 
ventilation. The photos in Figure 4 depicts a close-up of the 
heating interface as well as the RFID door locking system 
used to access each apartment. The door locks automatically, 
but opens with a RFID-card, and represents an interface few 
had experienced before.  Since all these devices come pre-
installed there is no option for the residents to utilize other 
interfaces or interaction methods, e.g., traditional door locks 
with keys or two-button light switches, and these pre-
installments can all be considered a part of the "welfare 
package" in each apartment. As a result, they were tested 

327
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
together during the evaluations, and we will refer to these 
devices as "room control devices" in this paper. 
 
 
 
Figure 4. Heating control (left) and RFID door (middle) 
 
IV. 
RESEARCH METHOD  
The data for this study was gathered over a period of 13 
months divided into three phases. We were motivated by 
prior experiences with elderly people and assistive 
technology [13] [14], where findings suggested that giving 
enough time could help avoiding or eliminating bias. Three 
different methods of evaluation were used during these three 
phases, and Figure 5 illustrates the outline of the research 
phases.  
 
 
 
Figure 5. Outline of the research phases 
 
We applied different methods of evaluation. This was 
partly motivated by methodical triangulation, although the 
main reason was giving the participant more than just one 
opportunity to express their perspectives on simplicity. 
Also, in order to detect any cases of reverse-halo effect, we 
preferred to have at least one method that was an objective 
and metric evaluation of performance rather than subjective 
assessment. The applied methods are listed in Table II.  
The task-based group evaluation allowed the participants 
to freely address simplicity issues during the task 
walkthrough independent of schemas, heuristics or 
guidelines. Through the simplicity evaluation participants 
had a chance to evaluate the simplicity by grading pre-
selected factors of simplicity, and during the usability 
assessment we did not ask them, but rather observed and 
measured them in order to discuss simplicity through their 
performance. The first phase included a task-based group 
evaluation, a simplicity evaluation and a usability 
assessment. The initial plan was to conduct these three 
activities during the first phase and then follow up with an 
equivalent usability assessment after six months with the 
same participants and the same usability criteria. However, 
due to the feedback and results discovered during the second 
usability assessment, we chose to repeat the simplicity 
evaluation as well. The results from the second phase 
suggested that six months was not enough time to capture 
whether perspectives on simplicity had evolved over time. 
As a result, the third phase was conducted almost 13 months 
after the first phase, giving us enough time to reduce the 
selection bias such as length time bias. It also gave the 
participants the opportunities to experience the technology 
through additional stages of its lifecycle, e.g., maintenance, 
software updates, component replacement, and thereby 
attributing their assessment of simplicity to actual use over 
time rather than just first-impression or initial use. 
 
TABLE II. OVERVIEW OF METHODS 
# 
Method 
Participants  
Phase 1 
Participants 
Phase 2 
Participants 
Phase 3 
A 
Task-based group 
evaluation 
22 
- 
- 
B 
Usability 
assessment 
11 
11 
11 
C 
Simplicity 
evaluation 
12 
12 
12 
D 
Follow-up interview
- 
- 
6 
A. Task-based group evaluation 
The task-based group evaluation was a part of a broad 
study where altogether 22 participants were engaged, 
namely 11 elderly users, 7 employees and 4 experts. This 
dataset includes several factors out of which some are not 
relevant for this study, although data from this evaluation 
has previously 
contributed 
to 
another 
study [15]. 
Nevertheless, the evaluation included a total of 6 sessions, 3 
sessions with groups of elderly, 2 sessions with groups of 
employees, and 1 session with a group of HCI-experts. The 
employees were recruited from the local care home, and the 
participants represented both daytime and nighttime 
employees. The sessions were structured as group 
walkthroughs of pre-selected representative tasks where the 
participants were asked to grade the severity of identified 
issues and then engage in a plenary discussion. Examples of 
representative tasks were ordering a meal and signing up for 
activities on the tablet and controlling lighting and 
ventilation in the room. During this session all participants 
labeled issues with predefined categories. The data included 
in this study are those issues labeled by the participants as 
“simplicity” 
issues. 
All 
participants 
were 
free 
to 

328
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
individually define what issues they considered to be 
simplicity issues.  
B. Usability assessment 
The usability assessment involved 11 participants; 7 
elderly residents and 4 experts. The participants were given 
a set of 10 representative tasks to perform while completion 
time and error rates were measured and the sessions 
photographed. The tasks are listed in Table III. The given 
tasks were distributed evenly between the tablet and the 
room control devices. Errors were counted and also divided 
into deliberate errors and accidental errors; the former 
represents errors where the user performed an action 
intentionally although performed the wrong action, while 
the latter represents unintentional actions. An example of a 
deliberate error is intentionally pressing the channel button 
on the television remote control when you want to adjust the 
volume because you in your best judgment consider the 
channel button to be the correct action for the desired 
outcome (i.e., adjust the volume), and you intentionally 
press that button. On the other hand, if you want to change 
the channel and while reaching for the correct button you 
unintentionally bump into the power button instead, then it 
would be a case of an accidental error. 
 
TABLE III. OVERVIEW OF PERFORMED TASKS 
Task # 
Task description 
Task 1 
Locking and unlocking the RFID door 
Task 2 
Playing a game on the tablet 
Task 3 
Browsing on the tablet 
Task 4 
Sending and receiving text messages on the tablet 
Task 5 
Listening to radio on the tablet 
Task 6 
Ordering food from the cafeteria on the tablet 
Task 7 
Activating room control devices with movement 
Task 8 
Setting and adjusting the ventilation 
Task 9 
Turning on and off wall and ceiling lighting 
Task 10 
Adjusting the heating level 
 
In the first two phases, these evaluations were carried 
out in the homes of 5 of the 7 participants, while 2 
participants preferred to have the test conducted in an 
adjacent meeting room along with the experts. In the third 
phase, we conducted all evaluations in the meeting room. 
The usability assessment was repeated during the second 
and third phase in order to study changes in behavior, 
performance and satisfaction after six and thirteen months. 
The conditions and environmental factors were similar 
between the three assessments with the exception of the 
participants agreeing to have the evaluation along with the 
experts in the meeting room in the final evaluation.  
C. Simplicity evaluation 
The goal of the simplicity evaluation was to provide the 
residents with an opportunity to evaluate the simplicity 
without being restricted to certain tasks (as in method A) or 
tied to their performance (as in method B). Hence, the 
participants were asked only to grade the simplicity of the 
tablet and the room control systems. The evaluation 
included 12 elderly users in each of the three phases. All 
participants were given an individual oral and written 
explanation of each factor and was then asked to grade the 
simplicity factor from 1-5.  
 The evaluation comprised 7 factors redefined from 5 
laws of Maeda coinciding with our perspective of 
experienced simplicity, namely the symbiotic relationship 
between mastery and context. The 7 elements were 
intuitivity, organization, memorability, error rate, time, 
learnability and trust. Intiutivity reflects the perceived 
easiness when first approaching the system in the given 
context, while learnability and memorability describes the 
system’s ability to foster mastery and maintain it over time. 
With organization we did not look at organization of the 
interface, e.g., icon clutter, but studied how the system fitted 
within its context. We also included time, i.e., their 
experience on their own performance and error rate, i.e., 
how many errors they encountered, in order to study their 
own perspective on mastery.  
D. Follow-up interview 
The usability assessment and simplicity evaluation 
during the third phase was accompanied with a few 
interviews in order to gather perspectives from both experts 
and elderly participants on their opinions and performance. 
We chose to include these interviews in the final phase as 
we could not interpret the rationale behind the fluctuating 
opinions between phase 1 and phase 2, and wanted to get 
some insight into this matter. The interviews included three 
elderly participants and three daytime employees and were 
conducted immediately after the evaluations.  
E. Participants 
The three methods involved 45 participants altogether 
and the participants were divided into four user groups 
described in Table IV. The elderly people (n = 30) 
participated in all methods during all three phases, while the 
usability experts (n = 8) participated during all phases of the 
simplicity evaluation and the usability assessment. Finally, 
the employees (n = 7) only participated in the task-based 
group evaluation. A few daytime employees were invited to 
the follow-up interviews after the evaluation in phase 3 in 
order to capture some of their experience since last time. 
 
 
 
Figure 6. Elderly residents participating in the task-based group evaluation  

329
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The elderly participants were recruited among the 
residents at the local care home and their age ranged from 
79-94 (μ = 86). Participants from one session are depicted 
in Figure 6. As a general rule, upon moving into this local 
care home, all residents are cognitively cleared by medical 
experts, i.e., possessing at least an acceptable level of 
cognitive and reasoning abilities. However, they all share in 
common that they struggle with various medical conditions, 
e.g., reduced motor abilities or reduced vision, and they 
represent a broad range of social difficulties. In addition, the 
cognitive abilities of the residents are not monitored 
regularly, and several residents, including some of our 
participants, developed symptoms of beginning cognitive 
disorder throughout the 13-month period of our study. 
 
TABLE IV. OVERVIEW OF PARTICIPANTS 
User 
group 
User role 
Use 
frequency 
Expertise 
Participated 
in method # 
N 
The 
elderly 
End-users 
Every day 
(none) 
A, B, C, D 
30
Daytime 
employees 
End-users 
and 
trainers 
Every day 
Health and 
domain 
A, D 
4 
Shift work 
employees 
End-users 
and 
trainers 
Once a week 
Limited 
domain-
expertise 
A 
3 
Usability 
experts 
None 
One-time 
only 
HCI and 
usability 
A, B 
8 
V. 
RESULTS 
A. Task-based group evaluation 
Out of a total of 39 identified issues, 17 were considered 
simplicity issues by at least one of the user groups. Each 
group that had identified the issue was then asked to grade 
the severity of the issue as minor (M), serious (S) or critical 
(C). All identified issues are listed in Table V. The 
aggregated degree of seriousness reflects the final level of 
seriousness assigned to the issue based on the grading of the 
groups. If there were disagreements between only two 
groups, the most serious grading took precedence; otherwise 
the number of occurrences decided this aggregated degree 
of seriousness. Out of these 17 identified issues 5 were 
labeled as critical issues, 7 were categorized as serious 
issues, and 5 were considered minor issues. The group of 
elderly reported a total of 14 issues, out of which 36 % were 
graded as minor. The similar percentage was lower for the 
two other groups, respectively 25 % for the employees and 
27 % for the experts. Since both the employees and experts 
reported fewer issues overall that the other two groups, this 
implies that the employees and experts regarded identified 
issues as more severe that the elderly, with a percentage of 
75 % (employees) and 73 % (experts) graded as either 
serious or critical against only 64 % for the elderly 
participants. 
We also wanted to study the balance of simplicity, i.e., 
identify the level of simplicity where the system was neither 
too simple nor too complex. As a result, we also asked the 
participants to differentiate between issues they considered a 
result of the vendor making the interface or interaction too 
simple, i.e., a matter of oversimplification, and issues they 
considered too complex and wished were further simplified. 
13 issues were considered a result of oversimplification and 
participants expressed usability issues due to interface, 
language, symbols, etc., being too simple for their liking. 4 
of the 5 critical and 6 of the 7 serious issues were labeled 
oversimplified. It should be noted that similar to the 
aggregated 
degree 
of 
seriousness, 
the 
expressed 
simplification desire is the aggregated evaluation of the 
group(s) who brought forward the issues, however, all 
groups answered unanimously for all issues. As a result, 
their individual answers are not presented similar to the 
degree of seriousness where we encountered variations 
between groups. 
Most of the issues had a clear consensus on the grade of 
severity. Only those 3 cases where two groups addressed an 
TABLE V. IDENTIFIED SIMPLICITY ISSUES 
Issue # Issue description 
Aggregated 
degree of 
seriousness
Group 1 
Elderly 
Group 2 
Employees 
Group 3  
Experts 
Imbalance issue 
1 
The device screen always stays on (even in standby mode) 
S 
M 
S 
S 
Too simple 
5 
The phone icon color is misleading 
S 
S 
M 
S 
Too complex 
7 
There is no indicator of remaining battery 
C 
C 
C 
C 
Too simple 
8 
There is no indication of the device being charged or already fully charged 
S 
- 
S 
- 
Too simple 
10 
The system signals two new messages when just one message arrive 
S 
M 
S 
- 
Too simple 
11 
The system uses separate indicators to indicate the same message 
M 
M 
- 
- 
Too complex 
15 
There is one phone number for texting (12-digit) and another for calling 
C 
C 
S 
C 
Too complex 
20 
The default values in text boxes are misleading and unpractical 
S 
S 
C 
S 
Too simple 
21 
It is impossible to grad the on-screen keyboard in certain views 
C 
S 
- 
C 
Too simple 
24 
The language is inconsistent 
S 
S 
S 
- 
Too simple 
25 
It is too easy to delete everything 
M 
- 
M 
M 
Too simple 
28 
The events in the calendar are not chronologically ordered 
M 
M 
S 
M 
Too complex 
29 
The duration of phone calls is missing 
S 
M 
- 
S 
Too simple 
34 
There is no comment feature on activities and events 
M 
- 
- 
M 
Too simple 
35 
The language is confusing 
M 
S 
M 
- 
Too simple 
36 
The icons are confusing 
C 
S 
- 
C 
Too simple 
38 
The notifications are misleading 
C 
C 
S 
- 
Too simple 

330
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
issue and simultaneously gave it different grades did we 
encounter any disagreements. Rather than considering the 
grade of one group as more important than other, we chose 
instead to always use the highest grade. This was considered 
an acceptable solution by the participants; for example, the 
elderly participants labeled the highest number of issues as 
minor issue, but for 3 of the 5 issues that the elderly labeled 
as minor issues (#1, #10, #29) the aggregated grading was 
upgraded to serious since either the employees or the 
experts regarded the issue as serious. For the two remaining 
issues one was only reported by the elderly residents (#11) 
and one group disagreed with the group of elderly on the 
severity grade of the last issue (#28). Additionally, only in 3 
cases were the issue only addressed by one group (out of 
which two were minor issues), and the overall consistency 
of the grading of the issues was therefore considered to be 
good.  
B. Usability assessment 
The usability assessment included 10 tasks (Table III) 
tested by 7 elderly people and 4 experts in each of the three 
phases, and Figures 7-9 present the completion time and 
error rate for each of the tasks in all three phases. The 
completion time listed for each task is the average time 
spent by all 11 participants to complete the task, while the 
error rate is the average error rate for deliberate and 
accidental errors.  
On average, the experts performed their tasks during the 
first phase within almost half the time of the elderly 
participants (μexperts = 173.11 against μelderly = 330.57), and 
did so with half as many deliberate (μexperts = 1.82 against 
μelderly = 3.90) and accidental (μexperts = 1.18 against μelderly = 
3.18) errors. Their standard deviation also confirms a more 
consistent performance throughout the 10 tasks both time 
wise (σexperts = 11.90 against σelderly = 36.66) and error wise 
(σexperts = 0.52 against σelderly = 1.06 and σexperts = 0.32 
against σelderly = 0.59). There is no clear consistency in how 
the user performs on average in each task. Between the two 
first phases, the completion time of four tasks decreased 
with an average of 9.46 seconds, while the completion time 
of the remaining six tasks increased with an average of 
15.98 seconds. The deliberate error rate dropped for six 
tasks (Δμ1-2 = -0.36) and increased for the other four tasks 
(Δμ1-2 = 0.46). On the other hand, the accidental error rate 
increased for four tasks (Δμ1-2 = 0.29), dropped for four 
tasks (Δμ1-2 = -0.32) and remained unchanged for the 
remaining two tasks (#7 and #9). However, there is no 
correlation between which tasks that went up in deliberate 
or accidental error rate. Only for one of the tasks (#4) did 
the sum of deliberate and accidental errors decrease when 
the completion time decreased. For the other three tasks, 
where the completion time dropped (#1, #2 and #10), one 
increased the sum of errors by 0.14 (#1) while the two other 
had no change in error rate even though the completion time 
decreased.  
Between the second and third phases, the completion 
time of seven tasks increased with an average of 16.45 
seconds, while the 3 additional tasks demonstrated a 4.38 
second drop in completion time. Interestingly, three of the 
four tasks that decreased in average completion time 
between the first and second cycle (#1, #2 and #4) flipped 
between the second and third evaluation and demonstrated 
an increase between the two final evaluations. Hence, any 
consistencies were even harder to identify after the third 
phase. This lack of pattern in performance was further 
strengthened by the changes in error rates. The deliberate 
error rate increased for 6 tasks (Δμ2-3 = 0.29) and dropped 
for the other four (Δμ2-3 = -0.36). Four of the six tasks that 
had increased in deliberate error rate since last time had 
previously demonstrated a negative change between the first 
two phases, indicating an increased performance (#1, #2, #7, 
#8). The accidental error rate remained unchanged for two 
tasks between the second and third phase (#2 and #6), 
increased for five tasks (Δμ2-3 = 0.34), and decreased for 
three tasks (Δμ2-3 = 0.33). Again, the changes were inverted 
for four of the five tasks comparted to last time. Only for 
one task (#5) did we register a similar trend between the 
three cycles.  
The average completion time for all ten tasks increased 
slightly between the first and second phase (Δμ1-2 = 8.29, 
Δσ1-2 = 7.36) for the elderly participants. The difference 
between the second and third phase almost completely 
inverted the change between the first two phases by 
dropping back on both completion time and standard 
deviation (Δμ1-2 = -14.63, Δσ1-2 = -4.92). The standard 
deviation on average completion time in the second (σexperts 
= 8.32 against σelderly = 29.3) and third (σexperts = 9.25 against 
σelderly = 25.0) phase still suggested that the performance of 
the experts was time wise more consistent throughout all ten 
tasks. However, the standard deviation kept dropping and 
between the first and third phase for the elderly participants, 
the change in standard deviation considering average 
completion time dropped from 36.6 to 25.0 seconds. This 
happened despite the average completion time increasing 
between the first two phases, and then decreasing between 
the two last. 
The standard deviation for deliberate errors hovered 
around the value from the first phase for both experts and 
elderly users. For the experts the standard deviation from 
the first phase (σ1 = 0.52) changed both positively and 
negatively in the two following phases (Δσ1-2 = -0.14 and 
Δσ2-3 = 0.08). In the case of the standard deviation for the 
elderly participants, the changes from the first phase (σ1 = 
1.06) were again both positive and negative in the 
successive phases (Δσ1-2 = -0.16 and Δσ2-3 = 0.08). The 
standard deviation for accidental errors also remained very 
close to its initial value after a year. For the experts, the 
initial value (σ1 = 0.32) decreased before the second phase 
(Δσ1-2 = -0.02) and increased back before the third phase 
(Δσ2-3 = 0.05). As this value is marginally higher after the 
third phase, we see an example of how the accidental error 

331
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
count does not necessarily improve over time even for 
younger users. For the elderly people, changes followed a 
similarly fluctuating pattern as the experts. The standard 
deviation from the first phase (σ1 = 0.59) both decreased 
before the second phase (σ1-2 = -0.08) and then increased 
before the third phase (Δσ2-3 = 0.12). This also demonstrates 
a very low overall deviation from this initial value even 
after a year. 
 
 
Figure 7. Overview of average completion time (s) 
 
 
Figure 8. Overview of average number of accidental errors 
 
 
Figure 9. Overview of average number of deliberate errors 
 
Already during the first phase, we registered that the two 
last tasks had the lowest completion time in both cases for 
all participants, as well as the lowest error rate (both 
deliberate and accidental) for both groups. A similar 
performance pattern was also registered among the experts, 
a group with less performance fluctuation than the elderly 
participants, and these were the two tasks with highest mean 
deviation in all three phases for both groups. These two 
tasks were also the only tasks where the group of elderly 
participants matched the performance of the experts. The 
average difference in completion time between elderly 
residents and experts in phase 1 was 110.2 seconds (σ1 = 
30.9), 117.6 seconds (σ2 = 26.4) in phase 2, and 105.4 
seconds (σ3 = 18.8), while the differences for task #9 and 
#10 were only 61.7 seconds in phase 1, 67.15 in phase 2, 
and 67.8 in phase 3. Similarly, the difference in deliberate 
error rate had an average of 1.46 (σ1 = 0.69) in phase 1, 1.68 
(σ2 = 0.73) in phase 2, and 1.52 (σ3 = 0.86) in phase 3, 
while the differences for task #9 and #10 were only 0.48 in 
phase 1, 0.41 in phase 2, and 0.45 in phase 3. The accidental 
error rate had an average difference of 1.4 (σ1 = 0.45) for 
phase 1, 1.57 (σ2 = 0.48) for phase 2, and 1.47 (σ3 = 0.53) 
for phase 3, compared to 1.2 difference in phase 1, 0.55 in 
phase 2, and 0.87 for task #9 and task #10. The task order 
was completely randomized and the participants never saw 
any task numbers – only tasks. Consequently, this anomaly 
is not a result of learning effect but rather a sign of tasks that 
were significantly easier than the rest. This anomaly, 
alongside the fluctuating opinions on simplicity between 
phase 1 and 2, was the reason for introducing the follow-up 
interviews conducted in phase 3. The follow-up interviews 
helped us confirm the distinction between the eight first and 
the two final tasks; the participants, regardless of whether 

332
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
they belonged to the elderly group or the employee group, 
unanimously reported the two final tasks as categorically 
different from the rest. The participants also unanimously 
rejected any learning effect as the reason behind the sudden 
drop in task #9 and task #10. In any case, a pattern of 
learning effect would have manifested itself through a more 
constant descending curve from tasks #1 through task #10 
rather than the abrupt drop after task #8.  
 
C. Simplicty evaluation 
Figures 10 and 11 present the results from all three 
phases of the simplicity evaluation. During the first phase, 
there were clear differences in opinion between the 
participants. While the average score of the 12 participants 
ended up on the upper half of the scale, the deviation within 
the data was large (μ1 = 3.4 and σ1 = 0.79), and participant 
#10 gave 4.4 out of 5 on average for the seven factors of 
simplicity, whereas participant #11 only gave 1.7 out of 5. 
The average score given to each of the seven factors were 
much more evenly distributed with only half the deviation 
(σ1 = 0.4) despite some of the factors having a much higher 
internal deviation (e.g., memorability with μ1 = 3.0 and σ1 = 
1.2).  
The second phase yielded results very similar to the first 
phase. There were few changes in how the users perceived 
and rated the seven factors with the highest factor difference 
between the two first phases being as low as 0.3 (intuitivity 
and trust), while the rest averaged at 0.15. However, almost 
all participants had changed their perception of simplicity 
since the first phase. Participant #10 and #12 both end up 
with an average score 0.1 below their previous average, and 
for some participants, e.g., participant #6 with a 0.9 
difference, the change in opinion was much more evident. 
Five of the participants ended up giving a higher average 
score during the second phase (Δμ1-2 = 0.53), while the 
remaining 7 reduced their average score (Δμ1-2 = -0.37). 
Hence, even though the number of participants increasing 
their score between the two first evaluations is lower than 
those reducing it, the difference in their average score brings 
the total average up (Δμ1-2 = 0.1). While the overall 
perception of simplicity does not necessarily change much, 
the reduced deviation between participants carefully suggest 
that their opinions had harmonized during the six months 
between the two evaluations (σ2 = 0.51 against σ1 = 0.79). 
During the third phase, we saw very few changes in the 
simplicity evaluation compared to the previous phase. Two 
factors represented the biggest changes in opinion 
(intuitivity and error rate) with a difference of 0.4 in both 
cases, while the rest had an average difference of <0.01. Yet 
again, we registered changes both individually and as a 
group, even though the average remained almost constant. 
The overall standard deviation between phases 2 and 3 
suggested that their opinions continued its convergence (σ2 
= 0.47), yet the extremities were more apparent. Participant 
#9 set a new record with a 1.2 positive difference between 
July and February, increasing the average score from 2.7 out 
of 5 to 3.9 out of 5. Participant #12 also demonstrated 
distinct changes in opinion by dropping the average score 
from 4.0 to 3.1, thereby reducing the score by 0.9. The 
follow-up interview revealed that the participants had not 
changed their definition of the seven factors, only their 
opinion on the matter.  
 
 
 
Figure 10. Average score given by each participant 
 
 
 
Figure 11. Average score given for each simplicity factor 
 
VI. 
UNDERSTANDING WILL BRING SIMPLICITY 
A. Designing for understanding rather than simplicitiy 
Our main results from [1] relied on quantitative data to 
demonstrate how technologies intended to be simple in use 
were experienced as difficult. We studied the performance 

333
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
and error rate in order to determine the experienced 
simplicity, and we demonstrated that their aggregated 
performance over time did not improve. However, we 
quickly found these usability metrics unable to capture the 
real essence of the problem, i.e., why the system was not 
perceived as simple. In general, usability metrics such as 
aggregated or average speed or error rate does not reflect 
individual experience, only performance. And there is no 
guaranteed correlation between an objectively good 
performance and a satisfactory experience. To expand on 
our work, we carried out a third research phase with a new 
cycle of usability assessment and simplicity evaluation 
where we followed up both activities with a short interview 
of the participants. Through our interviews, we attempted to 
capture insight on experienced simplicity of a system where 
we simultaneously had knowledge about their performance. 
This allowed us to compare their performance in relation to 
their perception of the simplicity, and it also provided an 
opportunity to ask for the reasoning behind the given grades 
and assessments.  
One prominent example within our own empirical 
context was employees who would consistently outperform 
the elderly people, despite spending less time on the tablet. 
They would perform tasks faster and with fewer errors. 
However, they did not perceive it as simple. As the results 
in Table V shows, several participants found the system to 
be oversimplified and preventing them from performing 
tasks in the preferred manner, and instead drove them into a 
predefined pattern of use. One participant claimed that she 
had “[…] learned to perform this task in a certain way 
because that is how it wants me to do it". This user in 
particular did not perceive the system as simple. She had 
written down a step-by-step guide, which she had then 
memorized over time. It was not a matter of simplicity that 
led to the fast performance, but rather her learning precise 
instructions by heart. When asked to perform a similar, 
albeit slightly different task, she was no longer performing 
as well. Just by switching to a task with different sequential 
steps she was unable to use her instructions, and she was 
unable to transfer the knowledge from the familiar tasks to 
this new task. This example illustrates how the constructed 
simplicity imagined by the designers does not manifest itself 
as a simple experience as long as the user is unable to 
understand the system, even though they somehow manage 
to get through the task. As long as the understanding of the 
system remains at the same level, the experienced simplicity 
will also remain the same.   
From the elderly participants, we learned that we should 
be realistic on how much effort we can and should expect 
from elderly end-users. If even basic operations of the 
system require a lot of new understanding and practice, 
most elderly would not invest the necessary time. While the 
employees were able to learn the system during their work 
hours as a part of their profession, the elderly people would 
rather choose to abstain from use if the entry level threshold 
was set too high. This exact phenomenon has also been 
captured in prior research in the same empirical context; 
more precisely, lack of familiarity with the features of the 
system led to fewer people using it [17]. Designers should 
not spend time on trying to make the design itself simple, 
but instead focus on designing for understanding and 
mastery which will give users an opportunity to experience 
simplicity as their understanding and mastery grows. 
Designing solely for simplicity will force a compromise on 
functionality. Norman also argues that by recognizing 
understandability as the real issue, we are halfway to the 
solution [3]. In fact, his three suggested principles, i.e. 
modularization, mapping and conceptual models, all suggest 
supporting user in their use indirectly by helping them better 
understand the system. 
However, the cognitive capacities of elderly people 
should not be discarded. Nor should it be the default excuse 
for interfaces and interactions that fail to deliver simplicity. 
Several participants demonstrated fully functional cognitive 
capabilities, and for these participants it was not their 
mental or physical conditions that prevented them from 
learning. It was simply the way the tablet had been 
introduced. During our follow-up interviews, on participant 
said she still used the tablet regularly after 13 months, and 
knew exactly what to expect from it. However, she did not 
understand it. She explained that repetitions help a lot, and 
she knew exactly what to expect from the tablet. There were 
issues she could not explain, and she “[…] knew the errors 
will show up, because they do every time, but knowing about 
them was not the same as knowing how to remove them”. 
She explained that she would attend a new training course 
or course for intermediate users, however, no such courses 
existed, so she had just learned to live with the errors. 
 
B. Lowering the threshold for understanding 
Designing for experienced simplicity also require 
attention to the way the technology is introduced and taught 
to the users. Our initial research was supported by 
ethnographic studies, and one of the lessons learned from 
home visits was that only 23.9 % (22/92) of the residents at 
the care facility were actively using the tablet one year after 
the introduction. After two years, the number of active users 
had dropped to 18.5 % (17/92). The number of participants 
at the introductory training given by the vendor was 
significantly higher (56.5 %). Through follow-up interviews 
we could conclude that the reason behind the high dropout 
rate was that the entry-level threshold was too high for most 
people. Several elderly people had attempted to learn the 
basic operations of the system, yet the provided training was 
not enough to get them familiar and confident enough to 
continue the learning on their own. The instructions that 
came along the tablet were also not adapted to individual 
needs, something that made it difficult to catch up for those 
who felt comfortable starting after they saw how the early 
adopters were mastering the system.  

334
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The lack of ideal users within the context of assistive 
technology strongly suggests diversity in both the design of 
the system and in the way the user is taught to operate the 
system. It has also been pointed out that heterogeneous 
qualities can blur out if elderly people are clustered into one 
or only a few larger groups, and thereby end up ignoring 
individual needs and understanding [18]. Prior research  
[19] [20] have pointed out how this homogenous clustering 
can force user groups over on impractical or difficult 
alternatives, or even exclude them all together [20]. The 
generation of elderly people that has grown up without 
technology also entails diversity in both exposure and prior 
knowledge [21]. This also suggests a more individually 
tailored approach in order to help users accommodate and 
struggle less in order to feel a sense of mastery.  
 
 
 
Figure 12. Group training on the left and individual training on the right 
 
Other researchers within our empirical context have 
addressed this issue by developing an alternative instruction 
manual of the tablet aiming at a design for all approach. The 
goal was to design an instruction manual understandable for 
everyone regardless of skills and possible disabilities [17]. 
Their instruction manual was built around a task-divided 
design where tasks where grouped into difficulty levels, and 
thereby only introduced more advanced operations once the 
users had gained some basic skills. This made the 
instruction manual more dynamic as it would adapt to the 
learning curve of the user rather overwhelming the user by 
introducing all tasks at once. We carried out sessions of 
individual workshops and training in our prior research [22], 
and used a similar approach with smaller groups of people. 
When elderly people with limited abilities to participate in 
communal activities were unable to join our sessions, we 
brought in family members or daytime employees who 
could speak authoritatively on behalf of those who could not 
voice their own needs. Thereby their challenges and mastery 
progress were represented through proxy-users who could 
follow them up individually later. Moving from training in 
larger groups to smaller groups or even individual training 
(Figure 12) demonstrated a significant increase in the 
number of users. One of the quotes reported by our colleges 
in [17] illustrates the need to adapt the training in order to 
support mastery: “I think I could have used this on my own, 
if someone first just once had showed me how it works”.  
VII. DISCUSSION 
A. Ensuring familiarity and transferability 
Mastery requires understanding and learning. It also 
relies heavily on the users’ previous exposure, and design 
following simplicity should evoke a connection to prior 
experiences. Thus, the elderly users rely heavily on 
transferring prior skills and knowledge in order to adapt a 
level of understanding and learning that nurtures mastery. 
One of the key challenges with both systems evaluated in 
our study was the lack of consistent metaphors. Several 
elderly residents with prior experience with devices similar 
to those used in our evaluation were unable to utilize prior 
knowledge due to metaphors not being consistent; 
simplicity also encompasses other design principles, e.g., 
consistency and affordance. Actions, icons, symbols and 
other metaphors should mediate experiences rather than 
direct [13]. And the diverse backgrounds of the elderly 
participants made us very aware of the difficulty of reducing 
complex information into simplified metaphors where 
everyone understands both the metaphors and the symbolic 
meaning or feeling they encompass. This challenge has been 
addressed by previous studies [23] who relied on a 
simplified design to trigger a nostalgic effect in order to 
help familiarizing metaphors.  
In our studies, several elderly users struggled with the 
tablet responding to their actions with unexpected outcomes. 
One example included residents trying to use prior 
knowledge like familiarized gestures on the tablet, e.g., 
pinching and dragging to zoom or sliding actions to scroll, 
when visiting websites during task #3 (Table III). The 
system being of a different operating system than what they 
had previously used responded differently than expected; 
the slider scrolled the website in the opposite direction and 
the pinch and drag gesture were not recognized by the 
system at all. During the follow-up interviews we confirmed 
that participants still struggled after 13 months of use as 
they still had not forgotten the habits of their prior 
interaction. For many participants, the cognitive and 
physical load of learning how to independently operate a 
piece of technology was so straining that the participants 
were unable to completely unlearned their prior habits, also 
after 13 months. 
Another prominent example was the RFID doors 
automatically locking if they were closed, i.e., a contrast 
from the traditional method of locking doors, by turning a 
key. The doors were heavy and closed automatically, and 
once closed they would also lock automatically like a spring 
lock, only without any sound or click. It was especially 
confusing during the first evaluation as the elderly people 
still had not memorized that the redundant key hole 
affording use of traditional keys (Figure 4) served no 
purpose, and repeatedly expected the door to be locked 
manually with a key after closing the door, when instead the 
door would automatically close and lock behind them. In 
fact, the accidental error rate for the task involving the doors 

335
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
(task #1 in Table III) was one of the tasks with highest 
combined average error rate and was one out of only four 
cases where the deliberate error rate increased between the 
first and second phase. This was a matter of confusion and 
reported as one of the main issues responsible for the degree 
of learnability dropping in the simplicity evaluations 
throughout the three phases (see Figure 11).  
A third example included problems during text 
messaging (task #4 in Table III). When asked to send and 
receive text messages, several old and familiar metaphors 
were suddenly replaced by new unfamiliar metaphors, 
where the residents struggled with applying old knowledge 
to the new system. For instance, the phone number was not 
their usual phone number, nor did it resemble a traditional 
phone number (issue #15), and the icons used to symbolize 
contacts and messages were not recognized (issue #36). The 
task of text messaging yielded the highest number of 
deliberate errors during all three evaluations, and this was 
clearly a result of their attempt to perform actions associated 
with prior experience or applying old metaphors to the new 
system that were no longer compatible or purposeful. The 
number had too many digits to learn by heart, and it did not 
make sense for the participants to break with the standard 
eight-digit phone number system in Norway as their number 
would not be recognized as a phone number most places. 
Through the follow-up interview we also learned how this 
way of using phone numbers eliminated their close identity 
to their phone number. There was no way of registering the 
new number on their own name in any of the major phone 
directories, and no way of people to finding their number by 
entering their name. 
Through these three examples we discovered that the 
most confusing and frustrating situations arose when the 
elderly users performed an action where the outcome was 
unclear or unfamiliar. Familiarity and transferability became 
strong indicators of the ability to master new systems; when 
actions became disconnected from their meaning, the 
purposefulness in the actions disappeared and mastery 
suddenly became a challenge. 
B. Maintaining purposeful actions 
In order to further discuss purposeful actions, we gave 
the participants 6 months and then later another 7 months to 
familiarize themselves with the systems before asking them 
to evaluate the simplicity a second and third time. 4 
participants (#1, #4, #6 and #11 in Figure 10) reported a 
higher average score during the second simplicity 
evaluation, suggesting a more positive attitude towards the 7 
elements of simplicity we evaluated. As a result, we used 
the second and third phase to investigate whether this was a 
result of increased learning and understanding, or just a 
matter of increased use frequency. When discussing the 
mastery of the system, we need to distinguish between 
increased ease due to more frequent use and increased ease 
due to actions, metaphors and language suddenly making 
more sense. It was unanimously agreed upon that the 
participants reported a higher score as a result of increased 
frequency rather than actions, metaphors and language 
making sense. Confusing metaphors were still confusing 
and over the course of 13 months participants had begun to 
learn certain use patterns by heart. To them, adopting 
strategies to avoid problems would result in less 
complicated interaction and improve the efficiency once 
memorized.  
However, over time, we registered that the average score 
for some of these participants had normalized. Only 
participant #2 and #11 in Figure 10 increased their average 
score between the second and third phase. It was evident 
that time did not contribute to increased understanding of 
metaphors, but rather resulted in incorporated strategies and 
workarounds. Confusing actions, metaphors and language 
remained confusing even after 13 months of use, also for 
those reporting a higher average score, and the increased 
perception bloomed out of the development of personal 
strategies for memorizing or working around troublesome 
tasks. This is an important finding as patience is often 
considered a virtue when elderly people adapt to new 
technology, including in our own previous work [15] [16]. 
However, in this study, we observed that actions, metaphors 
and language confusing the ended up remaining confusing 
after 6 and 13 months as well; providing more time might 
heal all wounds, but it does not guarantee disentanglement 
of perplexities and disorientations. 
Another argument for ensuring purposeful actions is to 
maintain good mapping. Natural mapping is understood as 
designing the interface in such a manner that the user can 
readily determine the relationship between the action and 
the outcome into the world [24]; i.e., a design where the 
user is able to associate cause with effect, thereby 
understanding expected output for provided input. For 
instance, the autonomy and intangibility of the automated 
light sensor evaluated during the usability assessment (task 
#9 in Table III) imposed several challenges to mapping. The 
physical zone in the room where movements were 
recognized was not clear, and there were no indications in 
the interface towards the intensity of the light or the 
duration of the light. One participant claimed that the best 
mapping for her was a traditional light switch where up 
meant on and down meant off in the middle in the room 
where the left switch controlled the lamp to the left and the 
right switch controlled the lamp to the right. Similarly, 
replacing traditional door keys with RFID cards to unlock 
doors had similar effects on the natural mapping; the users 
were unable to properly answer how long the door remained 
unlocked once the RFID card was scanned or determine the 
minimum required distance between the RFID card and the 
scanner on the door. 
C. Adapting to evolving perceptions of simplicity 
Trier and Richter [4] argues that the application of 
simplicity as a design guideline requires flexibility. Between 
the two first phases we observed two participants undergo 

336
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
changes in their overall health level. There were significant 
differences in their cognitive and reasoning abilities. Before 
the third phase, we consulted with the daytime employees 
and caretakers in order to confirm the appropriateness of 
their participation. For example, one of these participants 
could no longer explain the numbers on the display used to 
adjust heating levels (Figure 4). She had a custom color 
marker that indicate up and down for temperature as the up- 
and down-facing arrows no longer served as metaphors for 
increasing and decreasing the room temperature. While the 
arrows and display offered sufficient explanation during the 
first evaluation, she could no longer explain the details of 
the system during the second evaluation, e.g., the meaning 
of “1.4oC” on the display (as illustrated in Figure 4). 
Instead, she found that blue and red colors helped her 
remembering that if she pressed those buttons long enough 
it would eventually get colder or warmer. This exemplifies 
how typical aging symptoms, e.g., reduced cognitive 
capacities, clearly influenced both their performance and 
their assessment of simplicity.  
Related work [10] discusses how only paying attention 
to physical and perceptual characteristics of elderly users 
end up struggling with coping with the cognitive behavioral 
characteristics and traits of becoming elderly. Consequently, 
we consider achieving simplicity among elderly people 
especially difficult as they undergo rapid cognitive, physical 
and social changes in their lives that alter their attitude and 
opportunities towards technology. As metaphors lose their 
abilities to aide us with understanding and interacting with 
the system, our perception of the simplicity of the system 
deteriorate over time. Simplicity is not a constant factor that 
remains the same throughout of life, but rather one of the 
dynamic and flexible factors that evolves along as we 
evolve; acquiring new knowledge, entering new contexts 
and adapting new technologies contribute to reshaping our 
view on simplicity and what we perceive as simple. 
Similarly, changes in our lives can contribute to 
complicating systems we once considered simple; it often 
becomes a matter not only of preference, but also a matter 
of limited opportunities. Over a period of 13 months the 
perspectives of all the elderly participants changed in both 
the simplicity evaluation and the usability assessment. A 
design offering simplicity should therefore adapt according 
to the changing behavior and abilities of the elderly. 
Cooper et al. [25] also discuss the phenomenon where 
visual simplicity leads to cognitive complexity due to an 
unbalanced reduction. Several participants struggled with 
adapting to new technology due to cognitive load and 
preferred to rely on old knowledge and metaphors instead; 
they 
preferred 
familiar 
technologies, 
even 
those 
comparatively inefficient and impractical, because they 
could rely on habits. Examples of such desires included 
installing old landline telephones rather than telephoning 
from the tablet even though the latter was free, and using 
old televisions with large physical buttons instead of new 
flat screen television even though it involved getting out of 
the couch every time to change channel. A frequent counter-
argument is that this behavior is a result of their attitude 
towards technology in general rather than a matter of 
cognitive overload, however their attitude during the rest of 
discussions clearly suggested that they were positive 
towards technology but struggled with adapting to certain 
aspects of the system, in this particular case it was the 
misleading colors (#5), the two separate phone number 
(#15) and the confusing language (#35) that caused the 
perceived complexity (Table V). If those aspects of the 
systems are metaphors intended to bridge the gap between 
the system and prior experiences, achieving mastery can 
become difficult, sometimes even impossible. As a result, 
we argue that design striving for simplicity should be open 
to seemingly inefficient and impractical features if they 
evoke positive stimuli for the users, e.g., allowing them to 
take advantage of old habits rather than adapting new ones.  
D. Avoiding forcing ways of reasoning 
By oversimplifying technology, we limit the users' 
freedom and make decisions on their behalf by forcing them 
into predefined patterns of behavior that do not necessarily 
comply with their needs. The participants in our study 
disliked the predefined settings and missed working with a 
system that could adapt or be customized to fit their 
cognitive and bodily capabilities. Similar to studies of 
Eytam and Tractinsky [13], several participants desired the 
ability to design their own complexities. Our principal 
example was the tablet which did not offer any 
customization options or the option to install custom 
application with services that the system did not currently 
offer. Once one participant discovered a way to override the 
system and install own application, in this case a video chat 
application, several others asked for instruction on how to 
do so as well. This case exemplified how the intention of 
simplifying the system by removing seemingly undesired 
features became a restriction of the users’ desires. By 
directing, limiting or forcing decisions on the elderly, the 
outcome might end up being stigmatizing rather than 
inspiring [26]. For the elderly people who feel they are 
losing control and influence over their own life, this stigma 
through oversimplification may further assume a role as a 
reinforcing factor counteracting dignity and integrity by 
depriving them of their opportunity and right to autonomy 
[15]. This may again influence the ability to learn how to 
operate such systems as more general suggestions on 
simplicity in learning advocates the use of environments 
where users feel good and able.  
From their own results, Keay-Bright and Howarth [14] 
conclude that environmental factors that stimulate and 
encourage without prejudgment is a vital requirement for 
learning. Besides decelerating or even preventing the 
process of mastering, inhibiting learning has also proven to 
result in negative experiences for elderly people. The feeling 
of helplessness that comes with aging makes the elderly 
people more aware of their own dependability, and previous 

337
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
findings from our studies indicated that several participants 
felt deprived of their independence due to oversimplified 
and restrictive systems limited their opportunity to function 
at their best level [15].  
E. Balancing the simplicity 
The phenomenon of systems involving simplification 
measurements that end up having the opposite effect is often 
referred to as fake simplicity. Colborne [7] describes fake 
simplicity as the idea unable to ever meet its initial promise, 
instead just making everything unnecessarily complex and 
less effective. One example was the microwave of one of 
the participants that instead of using time or watt as input, 
used pictures of a pizza slice and a cup of tea to signal the 
duration and strength. Another example mentioned by a 
participant was his washing machine with only predefined 
programs where neither duration nor temperature was 
specified. Oversimplification can prevent mastery by 
concealing important components of the interaction thereby 
preventing the user from learning the relationship between 
action and effect. It also demonstrates how mastery requires 
balance. On one hand, the system needs to foster mastery 
through a design that is perceived as free of complexities; 
on the other hand, the system should encourage mastery by 
challenging and exciting the user and simultaneously 
avoiding oversimplified and condescending interfaces. 
Finding this balance where users are both presented with 
challenging tasks and at the same time provided with 
enough help to solve them helps us preventing that the 
system tips over in either direction. 
During the task-based group evaluation, the participants 
were asked to identify simplicity issues as either too simple 
or too complex systems. As a result, they were asked to 
clarify whether it was a case of lack of simplicity or 
abundance of simplicity, i.e., a complex issue that could 
benefit from simplification or an issue that was simplified to 
such an extent that it had become oversimplified and 
demeaning. Surprisingly, 13 out of 17 issues were classified 
by the participants as matters of oversimplification, i.e., that 
the simplification of the interface or interaction resulted in 
either poor usability or led undesired user experiences. The 
most important finding from these results was that 
simplicity is not a principle where “one size fits all”.  
One argument presented by an elderly lady for not liking 
the phone function of the tablet was that with tablets and 
mobile phones, the action of answering a call required an 
additional step. With a traditional land line phone, picking 
up the phone initiated the call, while on newer device she 
would first have to press an answer button and then pick up 
the phone, thereby complicating it for her by introducing 
additional step. Secondly, the internal disagreement between 
the groups further suggests that the elderly residents might 
have a different outlook on simplicity relatively compared 
to the two other groups, thereby demonstrating a variation 
not only between individuals but also between groups of 
individuals. What remains a matter of simplicity for the 
elderly users seems to deviate from what the employees and 
experts consider simplicity issues further suggesting that 
simplicity in use is different from analytic simplicity or 
imagined 
simplicity. 
Achieving 
simplicity 
without 
simultaneously weakening the functionality is one of the 
great struggles of designers, and it is vital to find this point 
of intersection where constructive simplification suddenly 
begins to defeat its own end. Simplicity is not only a matter 
of aesthetics; it is also a matter of balanced functionality.  
VIII. CONCLUSION 
In this paper, we have discussed the difference between 
analytic and experienced simplicity in the context of 
assistive technology. We have examined and evaluated 
existing assistive technology over the course of 13 months 
in order to study how perspectives on simplicity evolve over 
time. We have focused on how the users experience the 
technology by looking at experienced simplicity as 
something defined through mastery and context. As a result, 
central to our studies have been to understand how the sense 
of mastery changes over time, and whether technology 
aiming at being simple in use is actually experienced as 
simple. We have reported from three phases of evaluation 
involving altogether 45 participants, including 30 elderly 
people with an average age of 86 years. Our main discussion 
revolve around the difference between analytic and 
imagined simplicity, and how analytic simplicity usually do 
not manifest itself as experienced simplicity within the 
context of assistive technology. We also discuss how 
designs 
aiming 
at 
simplicity 
should 
focus 
on 
understandability and adaptation revolving around mastery 
and context through five key implications suggesting that 
simplicity should (1) build on familiarity and the ability to 
utilize old knowledge to help mastering the system; (2) 
ensure purposeful actions where the user can understand and 
learn to master the system; (3) adapt along with the evolving 
contextual factors; (4) avoid limiting the users to predefined 
patterns of behavior and allow them to use and master the 
system as they find appropriate; and (5) find the balance 
where the design is simple enough to be understood and 
learned, yet challenging enough to allow users to progress 
towards mastery. Only by doing so, we can achieve mastery 
in the intended context of use, which is what we believe 
simplicity to be. 
REFERENCES 
[1] 
S. G. Joshi, “When Simple Technologies Make Life 
Difficult,” in ACHI 2015, The Eighth International 
Conference 
on 
Advances 
in 
Computer-Human 
Interactions. Lisbon, pp. 168-177, 2015. 
[2] 
S. Finken and C. Mörtberg, “Performing Elderliness – 
Intra-actions with Digital Domestic Care Technologies,” 
in ICT and Society, Springer Berlin Heidelberg, pp. 307-
319, 2014. 
[3] 
D. Norman, “Simplicity is not the answer,” Interactions, 
septiembre-octubre, 15(5), pp. 45-46, 2008. 

338
International Journal on Advances in Intelligent Systems, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/intelligent_systems/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[4] 
M. Trier and A. Richter, "" I Can Simply…"-Theorizing 
Simplicity As A Design Principle And Usage Factor," in 
ECIS 2013, pp. 2-3, 2013. 
[5] 
J. Lee, D. Lee, J. Moon, and M.-C. Park, “Factors 
affecting the perceived usability of the mobile web portal 
services: comparing simplicity with consistency,” 
Information Technology and Management, 14(1), pp. 43-
57, 2013. 
[6] 
J. Maeda, “The laws of simplicity,” MIT Press, 2006. 
[7] 
G. Colborne, “Simple and usable web, mobile, and 
interaction design,” New Riders, 2010. 
[8] 
H. Obendorf, “Minimalism: Designing Simplicity,” 
Springer, 2009. 
[9] 
R. Picking, V. Grout, J. Mcginn, J. Crisp, and H. Grout, 
“Simplicity, consistency, universality, flexibility and 
familiarity: the SCUFF principles for developing user 
interfaces for ambient computer systems,” International 
Journal of Ambient Computing and Intelligence (IJACI), 
2(3), pp. 40-49, 2010. 
[10] 
H. Akatsu, H. Miki, and N. Hosono, “Design principles 
based on cognitive aging,” in Human-Computer 
Interaction, Interaction Design and Usability, Springer, 
pp. 3-10, 2007. 
[11] 
F. H. A. Razak, N. A. Razak, W. A. Wan Adnan, and N. 
A. Ahmad, “How simple is simple: our experience with 
older adult users,” in Proceedings of the 11th Asia 
Pacific Conference on Computer Human Interaction, 
ACM, pp. 379-387, 2013. 
[12] 
S. Sulaiman and I. S. Sohaimi, “An investigation to 
obtain a simple mobile phone interface for older adults,” 
in Intelligent and Advanced Systems (ICIAS), IEEE, pp. 
1-4, 2010. 
[13] 
E. Eytam and N. Tractinsky. “The Paradox Of 
Simplicity: Effects Of User Interface Design On 
Perceptions And Prefence Of Interactive Systems,” in 
MCIS 2010. pp. 30, 2010. 
[14] 
W. Keay-Bright and I. Howarth, “Is simplicity the key to 
engagement for children on the autism spectrum?,” 
Personal and Ubiquitous Computing, 16(2), pp. 129-141, 
2012. 
[15] 
S. G. Joshi, "Emerging ethical considerations from the 
perspectives of the elderly," in Ninth International 
Conference on Cultural Attitudes in computer-Human 
Interactions,  pp. 1-15, 2014. 
[16] 
S. G. Joshi and A. Woll, “A Collaborative Change 
Experiment: Telecare as a Means for Delivery of Home 
Care Services,” in Design, User Experience, and 
Usability. User Experience Design for Everyday Life 
Applications and Services, Springer, pp. 141-151, 2014. 
[17] 
C. Haug and F. H. Kvam, “Tablets and elderly users: 
Designing a guidebook,” Master thesis, Department of 
informatics, UiO, 2014. 
[18] 
S. Finken and C. Mörtberg, “Performing Elderliness–
Intra-actions with Digital Domestic Care Technologies,” 
in ICT and Society, Springer, p. 307-319, 2014. 
[19] 
A. L. Culén, S. Finken, and T. Bratteteig, “Design and 
interaction in a smart gym: Cognitive and bodily 
mastering,” in Human Factors in Computing and 
Informatics, Springer, pp. 609-616, 2013. 
[20] 
E. Brandt, T. Binder, L. Malmborg, and T. Sokoler, 
“Communities of everyday practice and situated 
elderliness as an approach to co-design for senior 
interaction,” in Proceedings of the 22nd Conference of 
the Computer-Human Interaction Special Interest Group 
of Australia on Computer-Human Interaction, ACM, pp. 
400-403, 2010. 
[21] 
N. Wagner, K. Hassanein, and M. Head, “Computer use 
by older adults: A multi-disciplinary review,” Computers 
in human behavior, 26(5), pp. 870-882,2010. 
[22] 
S. G. Joshi and T. Bratteteig, “Assembling Fragments 
into Continuous Design: On Participatory Design with 
Old People,” in Nordic Contributions in IS Research, 
Springer, pp. 13-29, 2015. 
[23] 
M. Nilsson, S. Johansson, and M. Håkansson. 
“Nostalgia: an evocative tangible interface for elderly 
users,” in CHI'03 Extended Abstracts on Human Factors 
in Computing Systems, ACM, pp. 964-965, 2003. 
[24] 
D. A. Norman, “The design of everyday things,” Basic 
books, 2002. 
[25] 
A. Cooper, R. Reimann, and D. Cronin, “About face 3: 
the essentials of interaction design,” John Wiley & Sons, 
2007. 
[26] 
L. Rosenberg, A. Kottorp, and L. Nygård, “Readiness for 
Technology Use With People With Dementia The 
Perspectives of Significant Others,” Journal of Applied 
Gerontology, 31(4), pp. 510-530, 2012. 
 

