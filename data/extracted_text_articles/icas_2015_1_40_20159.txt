Estimation of Time to Contact from Blurred Images 
Yukitada Takanashi, Kazuyuki Ito 
Dept. of Electrical and Electronics Engineering 
HOSEI University 
Tokyo, Japan 
e-mail:10x2061@stu.hosei.ac.jp, ito@hosei.ac.jp 
 
Abstract— Recently, intelligent safety systems, such as 
autonomous 
collision 
avoidance 
for 
automobiles 
have 
attracted considerable attention. In this paper, we propose an 
algorithm that can estimate time to contact by using blurred 
images that are captured by a monocular camera rather than 
distance information. We conducted experiments in order to 
confirm the validity of the algorithm.  
Keywords-ecological 
psychology; 
τ-margin; 
monocular 
camera; crush avoidance; blurred image; time to contact 
I. 
 INTRODUCTION  
Recently, intelligent safety systems, such as autonomous 
collision 
avoidance 
for 
automobiles 
have 
attracted 
considerable attention. Automobiles are typically equipped 
with distance sensors or stereo cameras to detect obstacles in 
their path [1][2].  
In conventional works, there are three major methods for 
measuring distance between the automobile and the obstacle 
[3]. Table I shows the features of the three major methods. 
 
TABLE I. FEATURES OF THE MAIN METHODS TO MEASURE 
AUTOMOBILE-OBSTACLE DISTANCE 
 
Bad weather environment 
Dark conditions 
Cost 
Stereo camera 
Not-applicable 
Not-applicable 
Middle 
Laser radar 
Not-applicable 
Applicable 
Low 
Millimeter-wave radar 
Applicable 
Applicable 
High 
 
In general, in order to measure distances in dark 
conditions, the cost to realize the system becomes high 
because a combination of the multiple methods is required in 
this case.  
On the other hand, in the context of ecological 
psychology [4][5], it has been demonstrated that time to 
contact can also be estimated by simply using monocular 
visual information rather than distance information. In 
ecological psychology, time to contact is called tau-margin, 
and it can be calculated based on the apparent size of an 
approaching object and its temporal change [6]. 
 In our previous studies, we proposed methods to 
estimate tau-margin using the images of a monocular camera 
[7]. However, in dark conditions, such as those at night, it 
was very difficult to estimate tau-margin because of blurred 
images.  
To address this issue, in this paper, we propose an 
algorithm that can estimate the tau-margin at night despite 
blurred images acquired from monocular camera.   
We conducted experiments in order to confirm the 
validity of the algorithm. 
 
 
The rest of the paper is organized as follows. Section II 
introduces the tau-margin. Section III describes our 
proposed algorithm tau-margin using blurred images. 
Section IV verifies the proposed algorithm. Section V 
concludes this paper. 
II. 
TAU-MARGIN 
Figure 1 shows an object approaching a camera. 
 
Figure 1. Appearance of the object. 
        The apparent size W can be expressed by (1). The 
temporal change  𝑊̇ is given by (2), where 𝐷̇   is the 
approaching speed. 
Equation (3) is obtained from (1) and (2). Equation (3) 
implies that the time to contact – 𝐷 𝐷̇
⁄
 is obtained from 
𝑊 𝑊̇
⁄
. In ecological psychology, 𝑊 𝑊̇
⁄
 is called tau-
margin (τ). 
𝑊 = 𝑑
𝐷 𝑆  
 
 
(1) 

𝑊̇ = − 𝑑𝑆
𝐷2 𝐷̇  
 
 
(2) 
 
− 𝐷
𝐷̇ = 𝑊
𝑊̇ (= 𝜏)    
  
(3) 
 
In our previous study [7], we estimated tau-margin based 
on the movement of each pixel. Figure 2 shows the 
movement of pixels and Figure 3 shows the coordinate 
system. 
   
 
Figure 2. Movement of pixels. 
20
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-405-3
ICAS 2015 : The Eleventh International Conference on Autonomic and Autonomous Systems

  
 
Figure 3. Coordinate system. 
The center of the expanding image is called the 
vanishing point. In Figure 3, the origin of the polar 
coordinate system is the vanishing point. In the polar 
coordinate system, the expansion of an image is expressed 
by (4) and (7). The position of the vanishing point moves 
when the car turns. The movement of the vanishing point is 
expressed in the X-Y coordinate system in Figure 3. Thus, 
the movement of each pixel is given by (5) and (6), and (8) 
and (9), where ∆𝑡 is the time interval. 
  𝑃(𝑡 + ∆𝑡) = 𝑃(𝑡) {1 + ∆𝑡
𝜏(𝑡)}                                          (4) 
 
𝑥(𝑡 + ∆𝑡) = {𝑥(𝑡) − 𝑎} {1 + ∆𝑡
𝜏(𝑡)} + 𝑎 
 
(5) 
 
𝑦(𝑡 + ∆𝑡) = {𝑦(𝑡) − 𝑏} {1 + ∆𝑡
𝜏(𝑡)} + 𝑏    
 
(6) 
 
𝑃(𝑡 − ∆𝑡) = 𝑃(𝑡) {1 +
∆𝑡
𝜏(𝑡−∆𝑡)}
−1
  
          
          (7) 
 
𝑥(𝑡 − ∆𝑡) = {𝑥(𝑡) − 𝑎} {1 +
∆𝑡
𝜏(𝑡−∆𝑡)}
−1
+ 𝑎         
(8) 
 
 𝑦(𝑡 − ∆𝑡) = {𝑦(𝑡) − 𝑏} {1 +
∆𝑡
𝜏(𝑡−∆𝑡)}
−1
+ 𝑏                   (9) 
III. 
PROPOSED ALGORITHM 
Figure 4 shows the setting of camera, and Figures 5-7 
show the algorithm. 
 
 
   
 
Figure 4. Setting of camera and its blurred image. 
 
Figure 5. Estimated vanishing point. 
 
Figure 6. Reduce a locus of light. 
 
Figure 7. Acquisition of tau-margin. 
In this study, we propose an algorithm that can estimate 
tau-margin using blurred images. Figure 4 shows an 
example of a blurred image captured in dark conditions. We 
assume that static point light sources are on the same plane 
perpendicular to the direction of camera’s movement, and 
the trajectory of the point light source on the captured 
image is a straight line, as shown in Figure 4. We process 
the entire image without having to distinguish a point light 
sources. These trajectories include information on the 
movement of the moving camera. The inside edge of the 
trajectory is the initial position of the light and the other 
side is its final position. 
We estimate the vanishing point (𝑎, 𝑏) using (8) and (9). 
First, we shrink the trajectory by substituting 𝑎̂, 𝑏̂, and 𝜏̂ in 
(8) and (9), where 𝑎̂, 𝑏̂, and 𝜏̂ are estimated values. Through 
trajectory shrinking, the trajectory moves to the estimated 
vanishing point (𝑎̂, 𝑏̂), as shown in Figures 5-7. As shown 
in Figure 5, when there is an erroneous position between the 
actual vanishing point and the estimated vanishing point, 
the shrunk trajectory does not lie on the original trajectory. 
On the other hand, as shown in Figure 6, the estimated 
vanishing point and the actual vanishing point are the same. 
The shrunk trajectory moves to the original trajectory 
towards the actual vanishing point. By conforming the 
shrunk trajectory to the original trajectory, we can obtain 
the estimated values of 𝑎̂ , 𝑏̂, and 𝜏̂.  
To estimate 𝑎̂ , 𝑏̂, and 𝜏̂, we employ the method of least 
squares. Figure 8 shows changes in the trajectory due to the 
position of the vanishing point.  
21
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-405-3
ICAS 2015 : The Eleventh International Conference on Autonomic and Autonomous Systems

 
  (a) Vanishing point has error                  (b) Vanishing point has no error 
Figure 8. Changes in the trajectory due to the position of the vanishing 
point  
 
 
  (a) Tau is too small                    (b) Tau is too large 
Figure 9. Changes in the trajectory due to the value of tau  
 
When there is an erroneous position between the actual 
vanishing point and the estimated vanishing point, the 
trajectory shrinks, as shown in Figure 8 (a). On the other 
hand, when there is no error, the trajectory shrinks, as 
shown in Figure 8 (b). 
By minimizing the area of the rectangle composed of 
the original trajectory and the shrunk trajectory, we obtain 
estimated position of the vanishing point (𝑎̂ , 𝑏̂). 
In the same way, as shown Figure 9, by minimizing 
the area of the overlaps and the intermittent between the 
original trajectory and the shrunk trajectory, we obtain the 
estimated time to contact  𝜏̂. Figure 10 the flowchart of the 
theory and Table II defines the parameters used in the 
flowchart. In Figure 10, we employ the coordinate system 
in Figure 11.  
 
TABLE II. PARAMETERS  
B(𝑖, 𝑗) 
Binary image 
S(𝑖, 𝑗) 
Shrink image 
𝑆𝑎(𝑖,𝑗) 
Accumulation of shrink image 
(𝑖𝑏,𝑗𝑎) 
Position of vanishing point 
M 
Height of image 
N 
Width of image 
R 
Shrink rate 
𝑅𝑚𝑎𝑥 
Upper limit of shrink rate 
∆𝑅 
Step size of 𝑅𝑚𝑎𝑥 
∆𝑡 
Shutter speed 
𝑒𝑠𝑡 _𝑅 
estimate value of R 
𝑒𝑠𝑡 _𝑖𝑏 
estimate value of 𝑖𝑏 
𝑒𝑠𝑡 _𝑗𝑎 
estimate value of 𝑗𝑎 
𝑒𝑠𝑡 _𝜏 
estimate value of time to contact τ 
𝑚𝑖𝑛 _𝑆𝑎 
minimum value of sum of pixels of 𝑆𝑎(𝑖, 𝑗) 
𝑚𝑖𝑛 _𝑑𝑖𝑠 
minimum value of sum of pixels of the overlaps 
and the intermittent between  B(𝑖, 𝑗) and S(𝑖, 𝑗) 
 
 
Figure 10. Flowchart of the theory 
 
22
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-405-3
ICAS 2015 : The Eleventh International Conference on Autonomic and Autonomous Systems

 
Figure 11. Coordinate system for captured image 
 
IV. 
EXPERIMENT 
We conducted an experiment to verify the basic 
capability of the proposed method. Table III shows the 
setting of the experiment. Processing was conducted offline. 
Processing time per image was approximately 90 seconds. 
TABLE III.     SPECS OF THE PC AND EXPERIMENT SETTING 
OS 
Windows 7 Enterprise 
CPU 
Intel(R) Core(TM) i3 1.33GHz 
Memory 
4GB 
Application for 
calculation 
MATLAB R2013a 
Image size  
150×300 [pixel] 
Shutter speed of the 
camera 
0.5 [sec] 
 
The camera moved to the point light source by a 
constant speed, as shown in Figure 4. Figure 12 depicts the 
captured images. Figure 13 shows the estimated time to 
contact (𝜏̂). From Figure 13, we can confirm that the time to 
contact is successfully estimated. 
   
 
(a) Still image                                 (b) Blurred image 
Figure 12. Five point light sources. 
 
Figure 13. Experiment result. 
 
 
V. 
CONCLUSION AND FUTURE WORK 
      In this paper, we focused on the framework of ecological 
psychology and we proposed a simple algorithm to estimate 
the time to contact using blurred images. In this algorithm, 
expansion of obstacles on captured images is estimated from 
the trajectories of point light sources on the blurred images, 
and the time to contact to the obstacles is obtained. Thus, the 
proposed algorithm is applicable to dark conditions.   
     To demonstrate the effectiveness of the proposed 
algorithm, an experiment in a simple dark condition was 
conducted and we confirmed that time to contact could be 
estimated.  
In the future, we plan to apply the proposed approach to 
various types of real environment and verify its usability in 
that environment.  
 
ACKNOWLEDGMENT 
This research was partially supported by the Japan 
Society for the Promotion of Science through a Grant-in-Aid 
for Scientific Research (C), No. 24500181. 
 
REFERENCES 
[1] I. Joung and I. Ahn, “Two-dimensional depth data 
measurement using an active omni-directional range sensor,” 
IEICE Trans. Fund. Electron., Commun. Comp. Sci., vol. 
E84-A, no. 5, 2001, pp. 1288–1292. 
[2] B. D. Lucas and T. Kanade, “An Iterative Image Registration 
Technique with an Application to Stereo Vision”, Proc 7th 
Intl Joint Conf on Artificial Intelligence, 1981, pp. 674-679. 
[3] Nikkei Electronics:NE Handbook series Sensor Networks:  
Nikkei Business Publications, Inc., June, 2014, pp. 16-19. 
[4] J. J. Gibson, “Reasons for Realism: Essays in Feminist 
Theory,” Lawrence Erlbaum Associates, 1982. 
[5] J. J. Gibson, “The Ecological Approach to Visual 
Perception,”Lawrence Erlbaum Associates, 1986. 
[6] D. N. Lee, “The optic flow field: The foundation of vision,” 
Phil. Trans. Royal Soc. London B, vol. 290, no. 1038, 1980, 
pp. 169–179. 
[7] Y. Kawai and K. Ito, “Estimation Method for Time to 
Contact from Visual Information - A Simple Approach That 
Requires No Recognition of Objects 
–“International 
Conference, IEEE 2014, Bali, Indonesia, 5-10th December, 
Robotics and Biomimetics, 2014, pp. 469-474. 
 
 
23
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-405-3
ICAS 2015 : The Eleventh International Conference on Autonomic and Autonomous Systems

