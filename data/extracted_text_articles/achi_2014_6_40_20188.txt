Concepts of Multi-artifact Systems in Artifact Ecologies  
Henrik Sørensen and Jesper Kjeldskov 
Research Centre for Socio-Interactive Design 
Department of Computer Science 
Aalborg University, Denmark 
{hesor, jesper}@cs.aau.dk 
 
 
Abstract— The artifact ecologies emerging from the increasing 
number 
of 
interactive 
digital 
artifacts, 
capable 
of 
communicating with each other, have created a situation where 
software applications no longer need to be limited by the 
physical boundaries of a single artifact. In order to take 
advantage of the full potential of this situation, we first need to 
establish a common understanding of the interaction that 
crosses physical artifact boundaries. Eventually, this will help 
us understand and design multi-artifact systems that are more 
than the sum of its individual parts. In this paper, we analyze 
two multi-artifact systems from our prior work within the 
domain of music consumption and identify four concepts of 
multi-artifact 
interaction: 
Plasticity, 
migration, 
complementarity, and multi-user. We discuss the concepts in 
order to relate them to an artifact ecology thinking and 
identify implications for future work. 
Keywords- artifact ecology; multi-artifact; music system 
I. 
 INTRODUCTION 
The establishment of a wireless network infrastructure 
surrounding us has introduced easier connectivity between 
different digital devices. In addition, to enable data sharing 
and synchronization it provides great potential for 
interactions transcending the physical boundaries of 
individual devices. Jung et al. [8] describe this network of 
devices as a personal ecology of interactive artifacts and 
defines it as “a set of all physical artifacts with some level 
of interactivity enabled by digital technology that a person 
owns, has access to, and uses”. Taking advantage of the 
potential offered by such artifact ecologies is however 
challenging. Our focus lies in the concepts of the interaction 
between humans and artifacts. It is however clear that 
interaction designs spanning multiple artifacts is highly 
dependent on a comprehensive and flexible technical 
infrastructure for artifact discovery, connection, and 
communication. We therefore work under the assumption 
that this is or will be available to some extent.    
Interaction designers have become quite good at 
designing desktop applications and are in a post-desktop era 
progressively getting better at designing mobile artifacts as 
well. It is however, our belief that good interaction design 
for artifact ecologies consists of more than the aggregation 
of good designs for each individual artifact. Previous work 
has already moved towards an understanding of the 
composition [8] and dynamics [4] of the ecologies as a 
whole. What we find is however that there is a gap between 
the work on understanding interactions with single artifacts 
and 
understanding 
our 
personal 
artifact 
ecologies. 
Understanding multi-artifact systems that combine specific 
artifacts from our personal artifact ecologies creates an 
additional layer of complexity that requires us to think of 
the system in a holistic way on an abstraction layer above 
the single artifact but below the entire artifact ecology. 
The overall goal is to move towards multi-artifact 
interaction designs that deliberately exploit the synergetic 
effects of artifact combinations. Our contribution in this 
paper is a step towards an understanding that eventually can 
lead to this goal. The specific contribution is to identify and 
discuss concepts of multi-artifact systems that we find to be 
of particular significance to an artifact ecology context. We 
base our analysis around multi-artifact systems from our 
previous work in the music domain. 
First, we present related work on artifact ecologies and 
music consumption in Human-Computer Interaction (HCI). 
We then clarify our understanding and delimitation of the 
multi-artifact system concept followed by a description of 
the two music systems from our prior work. Finally, we 
analyze the systems in order to identify and discuss 
characteristic concepts of multi-artifact systems before we 
conclude with implications for future work. 
II. 
RELATED WORK 
This section relates our work to previous research in 
artifact ecologies and music consumption. 
A. Artifact Ecologies 
In a study of the social role of products, Forlizzi [6] 
introduced a product ecology framework used to describe 
the dynamic aspects of use. The framework puts the product 
in the middle, meaning that each individual product has its 
own ecology in which components are interconnected. For 
example, a product often has certain relations to other 
products that together act as a system. The components 
included in the framework, besides other products, are 
people, activities, place, and the routines and cultural 
context. Forlizzi’s product ecology framework provides 
means to reason about the single product and its social 
impact across users. 
Artifact ecologies represent a different approach of 
putting an ecological thinking into play in relation to the 
141
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

products surrounding us. In the framework of Jung et al. [8], 
they put the user in the center and define a personal ecology 
of interactive artifacts that a person owns, has access to, and 
uses. This means that an ecology is defined from the 
perspective of a person instead of a product/artifact. In their 
work, they conducted two types of exploratory studies with 
the common goal of understanding the relationships within 
artifact ecologies. Their study works under the assumption 
that the experience with an artifact can only be fully 
understood when it is considered in relation to an artifact 
ecology. We find the personal perspective very useful in 
understanding interactions that involve several artifacts. 
However, the limitations of the framework are that it does 
not take into account what happens when different personal 
ecologies intersect in multi-user interactions. 
Jung et al. [8] argues that artifact ecologies are 
dynamically evolving. Bødker and Klokmose [4] follow up 
on that idea and emphasize the importance of not only 
understanding a current composition of artifacts in our 
surroundings but also how relationships among them change 
over time. Using Activity Theory as their theoretical 
framing and the Human-Artifact Model [3] as an analytical 
tool, they identify three states of an artifact ecology: The 
unsatisfactory, the excited, and the stable state. The artifact 
ecology of a person will change state over time and at some 
point reach the unsatisfactory state once again. Changes to 
the ecology can then put it into an excited state and the 
cycle repeats itself. One challenge they encountered in their 
analysis was to describe what the artifacts of artifact 
ecologies is. While Jung et al. [8] describes artifacts as 
physical objects, Bødker and Klokmose [4] found from their 
study that this did not tell the whole story and that 
something more may be needed to systematically address 
the software as well. 
B. Music Consumption 
Music has always been an interesting topic due to its 
universal appeal. Holmquist talks about the field of 
ubiquitous music and how it has been formed by a 
digitization of music, portable music players and heightened 
bandwidth [7]. Although the article is from 2005, the notion 
of ubiquitous music has only become more relevant due to 
the emergence of Internet streaming services and affordable 
multi-room music systems. Liikkanen [10] however points 
out that music consumption, as a defined research area in 
HCI is extinct. He argues that research on music 
consumption through interactive devices continues but is 
marginal. There are however still interesting projects 
emerging in the HCI community. An example that operates 
in the area of multi-artifact interactions is Mo by Lenz et al. 
[9]. Mo is a music player with an integrated speaker that 
focuses on a shared music experience. Mo can be brought 
into a social setting and by placing it next to other Mo 
players, it creates a connected music system.   
III. 
MULTI-ARTIFACT SYSTEMS 
Before we start conceptualizing multi-artifact systems in 
artifact ecologies, it is important for us to clarify what we 
mean by the term in the first place and how we delimit it to 
reflect our scope. By multi-artifact systems, we refer to 
interactive systems, which are part of an artifact ecology, 
and involves more than a single physical artifact. Different 
terms have previously been used to describe similar 
concepts. Rekimoto has for instance described it as 
multiple-computer user interfaces with a focus on graphical 
user interfaces [11]. Terrenghi et al. [12] have furthermore 
created a taxonomy for what they refer to as multi-person-
display ecosystems. As much as we appreciate the desirable 
features of the visual aspect, we also want to acknowledge 
other modalities of input and output, especially since our 
point of departure is in the music domain. Multi-device 
interface is another term often used. It however 
ambiguously describe also interfaces accessible across 
different platforms, which is not part of our scope. Because 
we want to continue the ongoing work on artifact ecologies, 
it makes sense to refer to the sub-sets of artifacts as multi-
artifact systems. According to the systems’ view, the 
essential properties of an organism, or a system, is the 
properties of the whole that none of the parts has alone [5]. 
This view fits perfectly well with our intention of 
addressing systems with interaction designs that provide 
more than cross-platform interfaces. 
A. Delimitation 
We acknowledge Bødker and Klokmose’s [4] notion of 
the artifact term encompassing more than the physical 
interactive artifact. Our interest lies in the interaction 
designs, which transcends the boundaries of a physical 
artifact, thus we use multi-artifact systems as a term to 
describe sub-systems of artifact ecologies consisting of a 
specific composition of hardware and software artifacts 
used throughout a particular activity. This could technically 
involve the interaction with a desktop-PC communicating 
with a web server through a browser, but our focus is more 
specifically on systems where either the user provides direct 
input to the artifacts or the artifacts provide direct output to 
the user. The server part of the example fulfils neither role. 
Another example is video conferencing that involves several 
artifacts, however only one from each user’s personal 
ecology, hence it is not a multi-device system either. A 
system that merges two persons’ smartphones into a 
common interface when put together is however an example 
of a multi-artifact system from our perspective, as it would 
become a multi-artifact system in each user’s ecology. The 
last example shows the inclusion of systems that exist in the 
intersection between different personal artifact ecologies, 
where multiple persons interact with some or all of the same 
artifacts.  
142
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

B. Time and Space 
Although the browser and video conferencing examples 
provide some limitation to our scope it is not to be 
understood as if the artifacts in the multi-device systems are 
required to be co-located or even that the interaction with 
each artifact has to happen simultaneously. We still consider 
systems that distribute interaction across time and space. It 
will however have to be as a part of the same activity from 
the personal point-of-view. An important point is also still 
that the system should provide more than an interface 
accessible from different artifacts. An example is the 
Google Chrome browser. Having a version for Windows, 
Android and iOS is still a single-device interaction, but 
when it starts remembering open tabs, bookmarks, search 
preferences etc. across artifacts it becomes a multi-artifact 
system.  
The following two sections provide descriptions of the 
two multi-artifact music systems from prior work, on which 
we base our conceptualization. 
IV. 
AIRPLAYER 
AirPlayer is a multi-room music system that adapts to 
the location of the user with the purpose of allowing for an 
implicit interaction. It builds on top of Apple’s AirPlay, 
hence the name, making it capable of streaming music from 
a central digital music collection to speakers placed in 
different locations around the home. Each speaker connects 
wirelessly to a central music player application through an 
Airport Express that also works as a Wi-Fi access point. The 
use of a Wi-Fi network furthermore makes it possible for 
the user to control the music independently in specific 
locations from a smartphone application. AirPlayer handles 
separate locations through the notion of zones. A zone is per 
default a representation of the room in which a particular 
Airport Express is placed. The user can however combine 
zones to play and control the music in several locations 
simultaneously. The zone name is visible in the bottom of 
the main screen (see Fig. 1). By sliding horizontally, the 
user can cycle through the different zones to see the current 
song playing, change the volume etc. 
Similar features are already present in Apple’s existing 
product family, through iTunes, as well as in other multi-
room music systems. What is significant to AirPlayer is the 
addition of the proxemic interaction features that allows the 
system to adapt to spatial relations between the user and 
particular speakers placed in different rooms. The proxemic 
interaction manifests itself in AirPlayer as two features 
called location and movement, which the user enables 
through 
the 
smartphone 
application. 
A 
simple 
implementation of an indoor positioning system. The 
smartphone application continuously measures Received 
Signal Strength Indicator (RSSI) values from the Airport 
Express Wi-Fi access points and uses them to estimate in 
which zone the user is located.  
A. Location 
When the location feature is enabled, the smartphone 
application continuously adapts to represent the music 
currently playing in the zone where the user is located. As 
illustrated in Fig. 1, this means that the user interface 
presents information about the song playing and furthermore 
automatically controls the music in this particular location. 
The change happens in a seamless and subtle way, when the 
user changes location, without the need for further explicit 
user interaction. Whenever the system detects a change in 
location, it simply adapts the smartphone application to 
represent the current zone. The interaction from the user 
point-of-view is similar to having a universal remote control 
for independent music players in each room. 
B. Movement 
When the movement feature is enabled, the music 
follows the user around the home as illustrated in Fig. 2. By 
tracking the smartphone, the system is able to anticipate 
which zone the user is entering, continue the music in the 
new zone, and stop the music in the old one. What actually 
happens is that AirPlayer streams the music to all zones 
simultaneously and simply adjusts the volume in accordance 
to the location of the user. The movement and location 
feature can be enabled/disabled independently but are not 
 
Figure 1. The location feature adapts the user interface and control to 
the location of the user. 
 
 
Figure 2. Music follows the user across locations.  
143
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

strictly independent. Whenever the movement feature is 
enabled, so is the location feature as the same music is 
always playing where the user is located. The location 
feature enables a state where the smartphone user interface 
adapts to the location of the user and the music content 
stays. Inversely the movement feature enables a state where 
the user interface stays the same and the music content 
adapts to the location of the user. 
V. 
MEET 
The 
second 
system, 
called 
Music 
Experienced 
Everywhere Together (MEET), is a multi-device, multi-user 
music system used, to explore the interaction space of 
distributed interactions with co-located artifacts. The 
concept of MEET is to allow co-located users to share their 
music at social events, in order to nominate and vote for 
songs using their smartphones, thereby influencing the 
music in a collaborative manner. The interaction design 
consists of the following entities. 
A. Smartphone Application 
This smartphone application is the primary input artifact 
for the music player. Besides the music sharing control, it 
features a nominate functionality, where users can browse 
the collection of music shared by users and nominate songs 
they would like to hear. Another part of the interface present 
the list of nominations, giving the option to give a positive 
or negative vote for each nomination. Each vote will simply 
add or subtract one point from the total score. An important 
aspect is to utilize the users’ own smartphones, thereby 
making it a personal token representing the specific owner’s 
choices at any time. 
B. Tablet Application 
The tablet application is a simplified version of the 
smartphone application that only works for nominating and 
voting. It first serves the purpose of a public input artifact 
used by people without a compatible smartphone and 
secondly to create a physical interaction point for the music 
system in general. Because the tablet is an artifact shared 
among several users, we modified the vote feature to 
include a 10-second countdown after a vote, where the 
application locks itself. We added this mechanism to 
prevent a person from voting repeatedly for the same song. 
C. Situated Display 
The situated display shows the primary visual output of 
the music player to the users. The interface is suitable for a 
large flat screen TV or projector and should be placed with 
visibility in mind. The situated display represents 
nominations as album covers. The current score is 
represented by size, meaning that the largest nominations 
are more likely to be played next. This score does not map 
to the smartphone application, thus the situated display is 
the only place where the status is visible. Fig. 3 shows the 
voting interface of the different artifacts. 
The music system is running in one place and distributes 
interaction to other artifacts. Specific artifacts consist of a 
device with a part of the distributed interface each with their 
own output screen and each serving a specific purpose. 
VI. 
CONCEPTS 
In this section, we use the two presented systems to 
identify concepts that we find meaningful in the context of 
multi-artifact systems. The concepts are not necessarily 
novel in themselves, but the contribution lies in the use of 
them as concepts that describe interaction across artifacts. 
A. Plasticity 
In AirPlayer, the location feature enables the smartphone 
application to adapt to the location of the user, providing 
control of the music in this particular location as well as 
information about the music playing. Balme et al. refers to 
this kind of adaptability as plasticity [1]. More precisely, 
they define plasticity applied to HCI as “…the capacity of 
an interactive system to adapt to changes of the interactive 
space while preserving usability”. 
 Plasticity is not only meaningful in multi-artifact 
systems but for single artifacts as well. A smartphone 
application could for instance adapt to the location of the 
user independently of other artifacts, or a public display 
could adapt to the time of day or number of people in front 
of it. In AirPlayer, it is the spatial relations between the 
smartphone and speakers placed around the home that 
determines what is presented to the user, which is why we 
argue that plasticity also has its place as a concept of multi-
artifact systems.  
MEET does not have any plasticity integrated in the 
interaction design. Each artifact has a certain form that plays 
a specific role in the system. An idea of introducing it into 
the smartphone application could however be to provide 
 
Figure 3. The different artifacts of MEET and their respective GUIs 
for the voting functionality. 
 
144
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

more feedback on the status of the voting, if the user is not 
able to see the situated display.  
Another interesting challenge of artifact ecologies is the 
increase in general-purpose artifacts capable of executing 
different sort of applications Our phone is no longer just for 
making phone calls, our TV is no longer just for watching 
TV, and the newest addition to our ecologies is seemingly 
smart watches that does much more than showing the time. 
As our collection of general-purpose artifacts expand 
arguably so does the number of multi-artifact systems and 
the complexity of them. In AirPlayer, the smartphone 
application adapts to contextual information within the 
user’s current activity. Artifacts able to adapt to fit a certain 
activity and composition of artifacts could be an interesting 
aspect of plasticity.  
B. Migration 
The movement feature of AirPlayer makes music follow 
the user around the home by moving the music output from 
one artifact to another. This behavior is very much in line 
with the work on migratory user interfaces, which Berti et 
al. describes as “…interfaces that can transfer among 
different devices, and thus allow the users to continue their 
tasks…” [2]. The essential issue here is the continuity in the 
interaction. The interesting thing about the movement 
feature of AirPlayer is not that it plays the same music from 
a central source. The interesting thing is the ability to do so 
continuously across locations as the user moves around. In 
the AirPlayer example, it is only the content (the music) that 
migrates and always between exactly two artifacts. Berti et 
al. however also defines different levels of migration: 
 
Total migration: The entire interface migrates from 
one artifact to another. 
 
Partial migration: Only a part migrates to the target 
artifact. 
 
Distributing migration: The interface migrates to 
multiple target artifacts. 
 
Aggregating migration: The interface migrates from 
multiple artifacts into one. 
Migration and plasticity are somehow related concepts 
that both encourage more flexible and adaptable relations in 
our artifact ecologies. There is no implementation of 
interface migration in MEET but is in a similar way as 
plasticity a concept that could be integrated. 
C. Complementarity 
In MEET, the system distributes interaction across 
different artifacts. The different artifacts can be described as 
being complementary to each other, as each of them 
provides features that improve the overall system. The 
music player is useless if no one has connected a 
smartphone, shared some music and nominated at least one 
song. The smartphone application similarly does nothing on 
its own. Distributing functionality is of course a conscious 
design choice that is not strictly necessary to play music at a 
party. Doing so however takes advantage of available 
interaction resources to create a different kind of experience. 
What field studies of MEET have shown is also that such 
systems can provide an opportunity for a different social 
interaction and utilization of the environment, than a 
traditional music system. The benefits however come with 
the cost of an additional level of complexity, both 
technically and in the interaction design that we needs to 
address.  
The complementarity between the smartphone/tablet and 
situated display in MEET is similar to the notion of coupled 
displays [12] and a lot can be learned from the work on that 
topic. It is however important also to consider other 
modalities of input and output of multi-artifact systems as 
artifacts may be able to utilize these to complement each 
other in different ways in different contexts.  
AirPlayer similarly has an element of complementarity 
in its interaction design although more subtle than in MEET. 
The smartphone application provides the input and output to 
a music system distributed throughout the home that 
provides the music output. Although the smartphone 
application is able to control various music outputs 
independently, the complementarity in AirPlayer is basically 
a remote control metaphor. In a way this is also the case in 
MEET 
although 
both 
examples 
illustrate 
that 
complementary artifacts can be more powerful than a direct 
mapping of a traditional remote control.  
It seems reasonable to talk about dependency of the 
relationships between complementary artifacts. In MEET 
there is a very strong dependency between the smartphone 
application, the music player, and the situated display as 
none of them can work independent of the other. The tablet 
can 
however 
be 
removed 
without 
losing 
crucial 
functionality but does nothing on its own. In AirPlayer there 
is also a strong dependency between artifacts as no control 
of the music is implemented outside the smartphone 
application. The point is that it can be useful to consider the 
dependencies of complementary artifacts. Not only in the 
scope of the multi-artifact system but also in relation to the 
artifact ecologies involved. In AirPlayer all the artifacts 
belongs to the ecology of a single person as only one 
smartphone application is allowed at any time. MEET on 
the other hand is by design dependent on artifacts from 
several personal artifact ecologies. 
D. Multi-user 
The last concept is different from the others, as it 
addresses the users instead of the artifacts. Whether a 
system is designed for single or multi-user interaction is not 
surprisingly an important factor. What it means to include 
multiple users in terms of artifact ecologies is that the multi-
artifact system spans more than one personal artifact 
ecology and that all involved users’ ecologies intersect. 
MEET is for instance designed specifically for a social 
context with several simultaneous users. Each user has an 
artifact ecology, which their smartphone is a part of. When 
they arrive and connect their smartphone to the player the 
145
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

situated display and music player becomes part of each 
user’s artifact ecology as well. Even though each 
smartphone at this point is part of the same multi-artifact 
system, they are not part of any other user’s artifact ecology.  
The 
new 
possibilities 
for 
designing 
multi-user 
interactions is one strength of multi-artifact systems. MEET 
for example, has no inherent upper limit on the number of 
simultaneous users by design. The possibilities do however 
come with a price. Just as multi-artifact systems adds an 
extra layer of complexity to single-artifact interaction, so 
does multi-user interaction. The idea of the movement 
feature in AirPlayer is an example where whenever there is 
only one person present there is no problem. Difficulties 
however arise if more people want to use the feature 
simultaneously. What happens if two persons, with different 
music following them, enter the same room? Rules could of 
course be made to cope with this problem, and as it may 
seem trivial to always take the number of intended users 
into account, it is important to do more to understand the 
multi-user dynamics in artifact ecologies. 
E. Summary 
We have analyzed the two multi-artifact music systems, 
MEET and AirPlayer and have identified four concepts of 
multi-artifact 
interaction: 
Plasticity, 
migration, 
complementarity, and multi-user. Fig. 4 shows an overview 
of where the concepts were identified in the two systems.  
 
Figure 4. Utilization of discussed concepts in the two systems. 
 
We do want to stress that the concepts should not be 
seen as individual solutions. There lies great opportunity in 
combining the concepts as was also evident in our analysis. 
Partial, distributing, and aggregating 
migration can 
furthermore be used to switch between complementary 
artifact compositions. 
VII. CONCLUSION AND FUTURE WORK 
The work in understanding artifact ecologies becomes 
important as they evolve and the relationships among 
artifacts become more complex. Previous work has focused 
on the composition and dynamics of artifact ecologies on a 
very high abstraction level. What we have done is to start an 
articulation of the sub-systems of artifact ecologies on a 
level in between the interaction with single artifacts and the 
understanding of the ecologies in their entirety. The four 
identified concepts of multi-artifact systems, i.e., plasticity, 
migration, complementarity, and multi-user can help obtain 
a more fine-grained understanding of artifact ecologies. One 
future step that we are already looking into is to create a 
clearer picture of the three layers of artifact ecologies 
possibly through a reference framework. An obvious next 
step would furthermore be to get a deeper understanding of 
the identified concepts with the ultimate goal of creating 
design guidelines for multi-artifact systems that do not only 
work well in isolation, but fits into an artifact ecology. 
REFERENCES 
[1] L. Balme, A. Demeure, N. Barralon, J. Coutaz, and G. 
Calvary, 
“CAMELEON-RT: 
a 
Software 
Architecture 
Reference Model for Distributed, Migratable, and Plastic User 
Interfaces,” 
Proc. 
Second 
European 
Symp. 
Ambient 
Intelligence (EUSAI 2004), Springer, 2004, pp. 291-302, 
doi:10.1007/978-3-540-30473-9_28. 
[2] S. Berti, F. Paternò, and C. Santoro, ”A Taxonomy for 
Migratory User Interfaces,” Proc. 12th Int. Workshop on 
Interactive Systems. Design, Specification, and Verification 
(DSVIS 
2005), 
Springer, 
2005, 
pp. 
149-160, 
doi: 
10.1007/11752707_13. 
[3] S. Bødker and C. Klokmose, “The Human-Artifact Model: An 
Activity Theoretical Approach to Artifact Ecologies,” 
Human-Computer Interaction, vol. 26, no. 4, 2011, pp. 315-
371, doi: 10.1080/07370024.2011.626709.  
[4] S. Bødker and C. Klokmose, “Dynamics in artifact 
ecologies,” Proc. Nordic Conference on Human-Computer 
Interaction: Making Sense Through Design (NordiCHI ‘12), 
ACM 
Press, 
2012, 
pp. 
448-457, 
doi:10.1145/2399016.2399085. 
[5] F. Capra, “The Web of Life,” Anchor Books, New York, 
1996. 
[6] J. Forlizzi, “How Robotic Products Become Social Products: 
An Ethnographic Study of Cleaning in the Home,” Proc. 
ACM/IEEE 
International 
Conference 
on 
Human-robot 
Interaction (HRI ‘07), ACM Press, 2007, pp. 129-136, 
doi:10.1145/1228716.1228734. 
[7] L.E. Holmquist, “Ubiquitous Music,” Interactions – Ambient 
intelligence: exploring our living environment, vol. 12, no. 4, 
July 
+ 
August 
2005, 
pp. 
71-ff, 
doi: 
10.1145/1070960.1071002. 
[8] H. Jung, E. Stolterman, W. Ryan, T. Thompson, and M. 
Siegel, “Toward a Framework for Ecologies of Artifacts : 
How Are Digital Artifacts Interconnected within a Personal 
Life ?,” Proc. Nordic Conference on Human-Computer 
Interaction: Building Bridges (NordiCHI ‘08), ACM Press, 
2008, pp. 201-210, doi: 10.1145/1463160.1463182. 
[9] E. Lenz, S. Diefenbach, M. Hassenzahl, and S. Lienhard, 
“Mo. Shared music, shared moment,” Proc. Nordic 
Conference on Human-Computer Interaction: Making Sense 
Through Design (NordiCHI ‘12), ACM Press, 2012, pp. 736-
741, doi: 10.1145/2399016.2399129. 
[10] L. Liikkanen, C. Amos, S.J. Cunningham, J.S. Downie, and 
D. McDonald, “Music interaction research in HCI: let’s get 
the band back together,” CHI ’12 Extended Abstracts on 
Human Factors in Computing Systems (CHI EA ‘12), ACM 
Press, 2012, pp. 1119-1122, doi: 10.1145/2212776.2212401. 
[11] J. Rekimoto, “Multiple-computer user interfaces: "beyond the 
desktop" direct manipulation environments,” Proc. CHI ‘00 
Extended Abstracts on Human Factors in Computing Systems 
(CHI 
EA 
‘00), 
ACM 
Press, 
2000, pp. 
6-7, doi: 
10.1145/633292.633297. 
[12] L. Terrenghi, A. Quigley, and A. Dix, “A taxonomy for and 
analysis of multi-person-display ecosystems,” Personal and 
Ubiquitous Computing, vol. 13, no. 8, November 2009, pp. 
583-598, doi: 10.1007/s00779-009-0244-5. 
 
146
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

