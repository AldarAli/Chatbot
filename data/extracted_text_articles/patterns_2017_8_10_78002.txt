A Data Adjustment Method of Low-priced Data-glove
based on Hand Motion Pattern
Kenji Funahashi
Department of Computer Science
Nagoya Institute of Technology
Nagoya 466–8555 Japan
Email: kenji@nitech.ac.jp
Yutaro Mori1
Hiromasa Takahashi2
Nagoya Institute of Technology
(1present: NEC Solution Innovators, Ltd.)
(2present: Chubu Electric Power Co.,Inc.)
1Email: moriyu@center.nitech.ac.jp
2Email: hiromasa@center.nitech.ac.jp
Yuji Iwahori
Department of Computer Science
Chubu University
Kasugai, Aichi 487-8501 Japan
Email: iwahori@cs.chubu.ac.jp
Abstract—A data glove is one of the major interfaces used in the
ﬁeld of virtual reality. In order to get detailed data about the
ﬁnger joint angles, we must use a data glove with many sensors.
However, a data glove with many sensors is expensive and a
low-priced data glove does not have enough sensors to capture
all the hand data correctly. In our previous work, we propose a
method to obtain all ﬁnger joint angles by estimating the pattern
of hand motion from the low-priced data glove sensor values. In
our experiment system, we assumed some representative hand
motion patterns as grasping behavior. We also assumed that
other hand motions can be represented by synthetic motion of
the representative patterns. In our previous work, we used the
data glove with sensors covering two joints of each ﬁnger. In this
paper, we estimate the ﬁnger joint angles when using the data
glove whose sensors cover only the middle angle of each ﬁnger.
Keywords–Data-glove; Hand motion estimation; Finger joint
angles estimation.
I.
INTRODUCTION
Virtual Reality (VR) is a rapidly growing research ﬁeld
in recent years. VR technologies give us various advantages.
There are simulators to practice an operation and to ﬂy a plane
as examples of VR technologies. These simulators enable us to
avoid the risk and to save on cost. VR researches that targets
to households also have been attracted. A data glove is one
of the major interfaces which are used in the ﬁeld of VR. It
measures curvatures of ﬁngers using bend sensors. In order to
obtain accurate hand motions, it is necessary to use a data glove
which has many sensors, but it is expensive. It is preferable
that an interface is small scale and low cost. Various types of
researches about data glove have been conducted [1][2][3]. On
the other hand, there is a low cost data glove which measures
an angle for each ﬁnger through one sensor. But it cannot get
detailed data directly. For example, the 5DT Data Glove 5
Ultra and DG5 VHand have a single sensor on each ﬁnger,
so they have ﬁve sensors in the whole hand (see Figures 1
and 2). However, there are three ﬁnger joints for each ﬁnger, a
single sensor can not measure all of these three angles directly.
In our laboratory, we have proposed a method to get plausible
user hand motion pattern from the low-cost glove. This method
estimates the kind of hand motion patterns using each relation
among angles of ﬁngers during operation. Then, it estimates
all ﬁnger joint angles by estimating the types of hand motion
patterns from the correlation between each ﬁnger angle in the
Figure 1. 5DT Data Glove 5 Ultra
Figure 2. DG5 VHand
hand motion pattern [4]. We assume some representative hand
motion patterns, and consider that other hand motions can be
represented as a synthetic motion of the representative hand
motion patterns. In addition, we calculate the ratio of each
representative motion pattern. Moreover, estimating each ﬁnger
angle using the result, we express any hand motion patterns
other than the representative hand motions. In our previous
work, we have used 5DT Data Glove (see Figure 1) whose
sensors cover two joints of each ﬁnger. Here, we estimate
ﬁnger joint angles when using the data glove DG5 VHand
(see Figure 2) whose sensors cover only the middle angle of
each ﬁnger.
The rest of the paper is structured as follows. In Section II,
we describe how to estimate ﬁnger joint angels. In Section III,
we apply this method to the data-glove that sensor positons
are limited. In Section IV, the experimental results are shown.
Finally, we conclude in Section V.
97
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

!"#$%"#&"#$"#'#()%*+#&,%(-&./*/(&$%0#"('&
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&!"#$%"%*/(&
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&1'#2*/(&33456&&
7#28-#&$%"%.#)#"'&)/&2%92:9%)#&;(<#"&=/8()&%(<9#'&&
&&&>/"&#%2,&"#$"#'#()%*+#&,%(-&./*/(&$%0#"(!
&
&
3($:)&7%)%&?9/+#&@#('/"&+%9:#'!
&
&
A'*.%)#&),#&,%(-&./*/(B&
&&&"%*/&>/"&"#$"#'#()%*+#&,%(-&./*/(&$%0#"('&
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&!"/2#''&8(&"#%9&*.#&
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&1'#2*/(&334C6&
D%92:9%)#&&&%99&%(<9#'&&
&&&:'8(<&),#&$%"%.#)#"'&/>&$%0#"('&%(-&),#&"%*/&
!
Figure 3. Overview of method
II.
ESTIMATION OF FINGER JOINT ANGLES
In section II, we describe an estimation method of ﬁnger
joint angles using 5DT data glove which has been developed
in our laboratory (see Figure 3).
A. Representative Hand Motion Patterns
To estimate ﬁnger joint angles, this method limits user’s
hand motion to grasping motion. First of all, we chose four
representative hand motion patterns (see Figure 5)[4] from
human’s grasping motion (Figure 6)[5].
Furthermore, we assume that a human’s grasping motion
can be represented as a synthetic motion of representative
hand motion patterns. To derive three ﬁnger joint angles from
a single sensor value, we use the following method (see
Figure 4). We sample many sets of the sensor values with the
low-priced data glove when some subjects open their hand ﬁrst
and then close it to each representative hand motion patterns.
Also, we sample the sets of the true angles of ﬁnger joints
for the same representative patterns, provided that we use true
angles obtained from a data glove which has a lot of sensors.
We use Immersion CyberGlove as data glove with a lot of
sensors. Then, the sensor values and the true angles of ﬁnger
joints at the same time are associated. We show an example
of correspondence in Figure 7.
We derive the following numerical formulas using this
correspondence.
θpi1
=
2
3θpi2
(1)
θpi2
=
Epi2S3
i + Fpi2S2
i + Gpi2Si + Hpi2
(2)
θpi3
=
Epi3S3
i + Fpi3S2
i + Gpi3Si + Hpi3
(3)
where pattern p is one of representative hand motion patterns.
Angles θpi1, θpi2 and θpi3 express the DIP, PIP, and MP joint
angle of the ﬁnger i for the pattern p. The DIP, PIP, and
MP joint mean the ﬁrst, second and third joint of a ﬁnger
respectively. The Si is sensor value of ﬁnger i. And Epij, Fpij,
!"#$%&'())*+,!
!"""!"""!"""###"""!"""###$
$
!"""!"""!"""""""""!""""$
$
!"""!"""!"""""""""!""""$
$
%"""""""""""""""""%$
$
!"""!"""!"""""""""!""$
$
!"""!"""!"""###"""!"""###$
$
-.#/-0#(&1(2/3#(-'04#!
-(/#5/#"#'2-%.#(5-6#/'(p 
"#'"&/(.-43#(((78(
(S(!S1, S2, ... S5) 
µpn, Σpn(((((977 
97(-'04#"((
(((((((&1((:&;'2"(θpij(
Epij, Fpij, 
 Gpij, Hpij 
$3//#'2("#'"&/(
(((((.-43#(S 
$3//#'2(-'04#"<(
(((=(
(((>(
$4&"# 
(((>(
(((>(
(((>(
&5#'(
(((>(
(((.(
?-'@(A&%&'(!/-%&,(
#-$?("#2(&1("-A54#!
Figure 4. Detail of method
Gpij and Hpij are constant parameters for the pattern p, ﬁnger
i and joint j. These parameters, Epij to Hpij, are calculated
by pre-experiment. Besides, DIP joint angle is obtained by
proportional connection with PIP joint angle (eq. 1)[6]. Joint
angles of ﬁnger i of pattern p are obtained by these numerical
formulas.
B. Hand Motion Estimation and Angles Estimation
To represent user’s hand motion as synthetic motion of
representative hand motion patterns, we need to know how
similar the user’s hand motion is and to which representative
hand motion patterns. Then, we set the following formula
based on the probability density function of the multivariate
normal distribution for n points in the ﬁve dimensional feature
amount space.
Lpn = exp{−1
2(S − µpn)T Σ−1
pn (S − µpn)}
(4)
where S is the sensor value vector. And µpn and Σpn
represent mean vector of sensor sample values, and variance-
covariance matrix of sample point n (an integer satisfying
1≤n≤a number of samples) in representative hand motion pat-
tern p. Besides, µpn and Σpn are obtained by pre-experiment
for an average user. If the sensor values are obtained actually
from the glove, we select the maximum value according to the
following formula.
Lp = max
n {Lpn(S : µpn, Σpn)}
(5)
Thus, we get the likelihood on representative hand motion
pattern p in current sensor values. After that, we decide the
ratio rp of hand motion pattern p according to the following
formula.
rp =
Lp
ΣP
p=1Lp
(6)
98
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

Figure 5. Representative hand motion patterns
!"#$%#&%
'&()*%
+#&#,,-,./0"
1(&23,#&.4,-0
'().1*$"#2"
5**67,(6-
8$%-0./0"
+9#&#$:-#, /0"
;#"-&#,.1*$"#2"
+#&#,,-,.4,-0
Figure 6. Candidates of representative motions
Figure 7. Example of correspondence
where P is the total number of representative hand motions,
which takes the value of four. As stated above, we can obtain
θpij and rp. At last, each angle θij of current hand posture is
derived by the following formula.
θij =
P
∑
p=1
rp·θpij
(7)
III.
DATA-GLOVE THAT SENSOR POSITIONS ARE LIMITED
In section III, we describe an estimation method of ﬁnger
joint angles using DG5 data glove whose sensor positions are
limited only to PIP joints.
A. MP Angle for Representative Hand Motion Pattern
Although we mentioned above representative hand motion
patterns are selected, the pattern Parallel Ext. is almost the
motion related only to MP joints. When doing the Parallel
Ext. pattern, the sensor values hardly change. We tentatively
use three other patterns as representative hand motion patterns
for now.
For the 5DT data glove whose sensors cover PIP and MP
joints, the DIP angle is related to PIP directly, as mentioned in
the previous section. It means the sensor values contain all of
their information. However, using DG5 whose sensors are only
on PIP, the motion of MP does not change the sensor value.
Of course, we assume that the hand motion is a grasping one,
so the MP angle of a ﬁnger is related to the PIP angle of the
same ﬁnger. Then we can assume that the MP of a ﬁnger is
related to the PIPs of all ﬁngers.
We consider a new estimation model to obtain angles for
representative hand motion patterns using multiple regression
analysis. First, we make a estimation equation with explanatory
variable is a set of sensor values, and response variable is each
MP joint angle, as follows.
θpi3 =
5
∑
f=1
Cpif3Sf + Ipi3
(8)
where θpi3 is MP joint angle of ﬁnger i of representative
pattern p, Sf is sensor value of ﬁnger f, and Cpif3 and Ipi3
are constant.
99
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

Now, a subject opens his hand ﬁrst and then closes it
to each representative pattern with DG5 data glove, the set
of sensor value Sf(time) of ﬁnger f at time is sampled.
Then, the subject moves his hand as each same pattern with
CyberGlove which has many sensors, the set of angle value
θpi3(time) is sampled as true one.
Here, we should get the constant Cpif3 and Ipi3. The
residual sum of squares Q is represented as in (9).
Q =
∑
time


θpi3(time) −


5
∑
f=1
Cpif3Sf(time) + Ipi3





2
(9)
Focusing on coefﬁcient Cpi13 where f = 1;
Q =
∑
time



(
S1(time)Cpi13
)2
+ 2S1(time)Cpi13


5
∑
f=2
Cpif3Sf(time) + Ipi3


− 2θpi3(time)S1(time)Cpi13
+


5
∑
f=2
Cpif3Sf(time) + Ipi3


2
− 2θpi3(time)


5
∑
f=2
Cpif3Sf(time) + Ipi3


+
(
θpi3(time)
)2



(10)
Using the partial differentiations with Cpi13;
∂Q
∂Cpi13
= 2
∑
time
S1(time)



5
∑
f=1
Cpif3Sf(time)
+Ipi3 − θpi3(time)



(11)
Using the partial differentiations also with Cpif3 and Ipi3;
∂Q
∂Cpif3
= 2
∑
time
Sf(time)



5
∑
f ′=1
Cpif ′3Sf ′(time)
+Ipi3 − θpi3(time)



(12)
∂Q
∂Ipi3
= 2
∑
time


Ipi3 +
5
∑
f=1
Cpif3Sf(time)
−θpi3(time)



(13)
The constant Cpif3 and Ipi3 to be obtained make Q represented
as the minimum of the equation from (9). And the Cpif3 and
Ipi3 that make Q minimum satisfy following equation.
∂Q
∂Cpif3
= ∂Q
∂Ipi3
= 0
(14)
Solving this, coefﬁcient Cpif3 and constant Ipi3 are obtained
to estimate MP joint angle for representative pattern with (8).
The angles of PIP are obtained directly from the sensor value
with (2), and the angles of DIP are also obtained only from
PIP with (1).
B. Hand Motion Estimation with Pseudo-Inverse Matrix
When the variance of sensor values is zero at the sample
point n of representative hand motion pattern, the variance-
covariance matrix will be abnormal at the sample point n.
It means the inverse matrix of variance-covariance matrix of
sensor values Σ−1
pn can not be obtained, and the likelihood for
the sample data of representative pattern p can not be obtained
with (4).
So we use Moore-Penrose pseudo-inverse matrix to solve
it. The variance-covariance 5×5 matrix of sensor values Σ−1
pn
which is abnormal at the sample point n is represented as next
equation with 5 × r matrix Apn and r × 5 matrix Bpn where
rank (Σpn) = r;
Σpn = ApnBpn
(15)
Here the Moore-Penrose pseudo-inverse matrix Σ+
pn for Σpn
is described as:
Σ+
pn = BT
pn
(
AT
pnΣpnBT
pn
)−1
AT
pn
= BT
pn
(
BpnBT
pn
)−1 (
AT
pnApn
)−1
AT
pn
(16)
Using this Moore-Penrose pseudo-inverse matrix Σ+
pn for (4)
instead of the inverse matrix of variance-covariance matrix of
sensor values Σ−1
pn at the sample point n where inverse matrix
can not be deﬁned, the likelihood is obtained and the ratio
of each hand motion pattern is determined with (5) and (6),
respectively. Now, we can use a low-priced data glove whose
sensors cover only the middle angle of each ﬁnger to estimate
all ﬁnger joint angles of current hand posture with (7).
IV.
EXPERIMENT AND RESULT
We performed an experiment to conﬁrm the effectiveness
of the method described above. The experiment system was
constructed using the DG5 Data Glove whose sensor positions
are limited only on middle joints. Other hand motions that
were different from representative patterns were tested. The
minimum of Activities of Daily Living (ADL) needs the
following hand motions (see Figure 8) [7].
1)
Power grasps (used in 35% ADLs)
2)
Precision grasps (30% ADLs)
3)
Lateral grasps (20% ADLs)
4)
Extension grasps (10% ADLs),
5)
Tripod grasps,
6)
Index pointing, and
7)
Basic gestures.
We tested ﬁve motions; 1)–5).
100
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

(1) Power grasp
(2) Precision grasp
(3) Lateral grasp
(4) Extension grasp
(5) Tripod grasp
(6) Index pointing
(7) Basic gestures
Figure 8. Hand motions needed for ADL
TABLE I. ERROR OF FINGER JOINT ANGLES [DEGREE]
thumb
index
middle
ring
little
average
Power G.
7.3
12.0
10.5
12.5
10.0
10.5
Precision G.
8.1
9.2
7.2
7.0
6.8
7.7
Lateral G.
9.4
6.0
8.8
7.5
10.5
8.4
Extension G.
9.8
8.1
11.0
11.3
9.0
9.9
Tripod G.
8.5
8.5
7.2
11.6
10.9
9.3
average
8.6
8.7
8.9
10.0
9.4
9.2
Figure 9. Result CG for Power grasp
Figure 10. Result CG for Precision grasp
The subjects opened their hands and then closed them to
each test pattern 1)–5) with DG5 data glove. The average of
estimated joint angles were compared with the true angles
obtained from CyberGlove which had many bend sensors.
Table I shows the average error of ﬁnger joint angles. Each
error is around 10 degrees. The result using the 5DT data glove
whose sensors cover two joints of each ﬁnger also had about
10 degrees error [4]. This means that the lower-priced data
glove can obtain joint angles accurately enough.
Actual hand posture images and the CG images generated
from estimated joint angles are shown in Figures 9 and 10.
The MP joints that were not covered with bend sensors are
estimated from the sensors on PIP joints.
V.
CONCLUSION
In this paper, we described a useful method using a low-
priced data-glove based on hand motion patterns. It estimates
all ﬁnger joint angles using the data glove whose sensors
cover only the middle angle of each ﬁnger. The method has
been expanded from our previous method using a data-glove
whose sensors cover two joints of each ﬁnger. A data glove
is one of the major interfaces which are used in the ﬁeld
of VR. It measures curvatures of ﬁngers using bend sensor.
However, in order to obtain accurate hand motions, it is
necessary to use an expensive data glove which has many
sensors. On the other hand, there is a low cost data glove
which measures an angle for each ﬁnger through one sensor.
101
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

It cannot get detailed data directly. Our method estimates
plausible user hand motion patterns using each relation among
angles of ﬁngers during the operation of the low-cost glove
ﬁrst. Then, it estimates all ﬁnger joint angles by estimating the
types of hand motion patterns from the correlation between
each ﬁnger angle in the hand motion pattern. We assumed
some representative hand motion patterns, and considered that
other hand motions could be represented as synthetic motion
of these. The ratio of each representative motion pattern is
calculated using Moore-Penrose pseudo-inverse matrix, and all
ﬁnger angles are estimated using multiple regression analysis.
With the low priced data-glove being useful, it is expected that
VR systems that target households will become more popular.
In the future, we should reconsider the representative hand
motion patterns because we removed Parallel Ext. from our
previous research based on medical knowledge. We should
also expand the target hand motion patterns to various ones
that are not only grasping patterns.
ACKNOWLEDGMENT
The authors would like to thank our colleagues in our
laboratory for useful discussions.
REFERENCES
[1]
P. Temoche, E. Ramirez, and O. Rodrigues., “A Low-cost Data Glove
for Virtual Reality,” in Proceedings of the XI International Congress of
Numerical Methods in Engineering and Applied Sciences (CIMENICS),
2012, pp. TCG31–36.
[2]
F. Camastra and D. Felice, “LVQ-based Hand Gesture Recognition using
a Data Glove,” in Proceedings of the Neural Nets and Surroundings Smart
Innovation, Systems and Technologies, vol. 19, 2013, pp. 159–168.
[3]
N. Tongrod, T. Kerdcharoen, N. Watthanawisuth, and A. Tuantranont,
“A Low-Cost Data-Glove for Human Computer Interaction Based on
Ink-Jet Printed Sensors and ZigBee Networks,” in Proceedings of the
International Symposium on Wearable Computers (ISWC), 2010, pp. 1–
2.
[4]
H. Takahashi and K. Funahashi, “A Data Adjustment Method of Low-
priced Data-glove based on Representative Hand Motion Using Medical
Knowledge,” in Proceedings of the ICAT2013, 2013, (USB Flash Drive,
no page number).
[5]
N. Kamakura, H. Matsuo, M. Ishii, and Y. Mitsuboshi, F. Miura, “Patterns
of Static Prehension in Normal Hands,” Am J Occup Ther 34, pp. 437–
445, 1980.
[6]
G. Elkoura, “Handrix: Animating the Human hand,” in Proceedings of
the ACM SIGGRAPH/Eurographics Symposium on Computer Animation,
2003, pp. 110–119.
[7]
C. Capriani, “Objectives, criteria and methods for the design of the
SmartHand transradial prosthesis,” in Proceedings of the Robotica 2010,
vol. 28, 2010, pp. 919–927.
102
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

