Automated Drug-Related Information Extraction
from French Clinical Documents: ReLyfe Approach
Azzam Alwan
R&D Department
ReLyfe - Medical Intelligence
Paris, France
email: azzam.alwan@relyfe.com
Maayane Attias
Computer Science
Ecole Polytechnique
Palaiseau, France
email: maayane-lea.attias@polytechnique.edu
Larry Rubin
R&D Department
BeCareLink
New York, United States
email: larry.rubin@becarelink.com
Adnan El Bakri
R&D Department
ReLyfe - Medical Intelligence
Paris, France
email: ceo@relyfe.com
Abstract—Structuring medical data in France remains a chal-
lenge mainly because of the lack of medical data due to privacy
concerns and the lack of methods and approaches on processing
the French language. One of these challenges is structuring
drug-related information in French clinical documents. To our
knowledge, over the last decade, there are less than ﬁve relevant
papers that study French prescriptions. This paper proposes
a new approach for extracting drug-related information from
French clinical scanned documents while preserving patients’
privacy. In addition, we deployed our method in a health
data management platform where it is used to structure drug
medical data and help patients organize their drug schedules.
It can be implemented on any web or mobile platform. This
work closes the gap between theoretical and practical work by
creating an application adapted to real production problems. It
is a combination of a rule-based phase and a Deep Learning
approach. Finally, numerical results show the outperformance
and relevance of the proposed methodology.
Index Terms—Drug related information, French clinical docu-
ment, Natural Language Processing, Rule-Based system, Recur-
rent Neural Network.
I. INTRODUCTION
Today, the main source of mistakes in medicine is due to
the lack of information that doctors have on their patients,
especially when multiple doctors treat the same patient. The
information ﬂow has to be as efﬁcient and smooth as possible,
especially when patient is transferred from one doctor to
another. When making a medical decision, it is necessary
to avoid wrong actions that are incoherent with the patient’s
status, such as incompatibility between medication and their
medical condition. Consequently, doctors need to have access
to all of the patient’s information and background. However,
this is not always the case since healthcare systems do not
have patient’s information gathered all in one place: medical
information only exists in silos. For example, the main source
of medication errors is related to wrong drug prescriptions
having severe consequences on a patient’s health [1].
Based on the arguments mentioned so far, we see that there
is a crucial need to gather patients’ information in one unique
system/platform to be easily retrieved, understood, and shared.
Electronic Health Records (EHRs) provide healthcare workers
with a better understanding of the patient thanks to the stored
information. However, the information not only needs to be
stored, it also needs to be structured to be used efﬁciently.
Indeed, when clinical data is extracted from a document
and structured, it is easier to be examined and interpreted.
Today, 80% of relevant clinical information exists only in
an unstructured form [2], which results in a massive loss of
helpful information. We decided to focus in this paper on the
structuration of medical prescriptions. They contain valuable
information about a patient’s drug history and, when struc-
tured, can be used for pharmaco-vigilance and epidemiology.
Manual extraction would be too difﬁcult and time-consuming,
which explains why clinical Natural Language Processing
(NLP) and entity extraction are of genuine interest in the ﬁeld
of research. Considering the lack of solutions available in the
French health care system, we propose our algorithm and put
it at the service of any other solution that enhances the health
care system.
The rest of the paper is organized as follows. The prob-
lem formulation is presented in Section II. In Section III,
the proposed methodology is described. Experimental results
evaluating the efﬁciency of the proposed method are presented
in Section IV. Finally, conclusions are drawn in Section V.
II. RELATED WORK
The majority of NLP research work on medical data has
been carried out on texts/documents in English, whether it
is to structure or analyze them [3]–[9]. In fact, the need to
structure medical documents in any language is as strong as
in English. In French speciﬁcally, many policies advocate for a
better healthcare system while there is still a lack of structured
data and research. One of the principal methodologies in NLP
24
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-892-1
GLOBAL HEALTH 2021 : The Tenth International Conference on Global Health Challenges

applied to medical data is the Named Entity Recognition
(NER), whose purpose is to extract relevant medical informa-
tion from unstructured medical text. To our knowledge, since
2010, there have been less than ﬁve pertinent papers talking
about the extraction of drug-related information from French
clinical prescriptions [2], [10], [11]. In addition, none of them
is open-source, or a paid service or can be used as a real
application. One of the most known method applied in practice
is the Amazon Web services (AWS) medical service (Amazon
Comprehend Medical); however, its initial release can only
detect medical entities in English texts [12]. Therefore, the
idea is to use our expertise to achieve something similar for
French medical documents. The major approaches in NER for
medication are based on lexicon/rules and machine learning
and can be combined into a hybrid model.
First, lexicon-based approaches use predeﬁned lexicons or
regular expressions to match parts of the text to recognize
predeﬁned entities. They aim to model expert knowledge with
dictionaries. Examples of such approaches for English clinical
texts are MedEx [13] and MedXN [14]. These models are built
to recognize seven categories: drug name, route, frequency,
dosage, strength, form, duration. They have shown a good
performance compared to other methods. Indeed, MedXN
gives a F1-score of 0.975 for medication name and over
0.90 for attributes for a dataset of 397 medication mentions.
Regarding the rule-based approaches for French clinical texts,
the extraction also relies on a system with specialized lexicons
and extraction rules in a similar approach to English. Some
research has shown that the same methods in English can be
applied to French [10], however, they does not perform as well
as in English.
Regardless of the considered language, in a rule-based
approach, the rules have to be extremely ﬁne-tuned to ﬁt
the entities that will be extracted. Most researchers agree
that this can be challenging when working with a very large
dataset [15]. Additionally, it gives poor results when applied
to texts deviating from the ones referenced in the dictionary.
However, in case the whole entity is well predeﬁned, this
method provides precise results. That is why, in our approach,
we have applied this method to get the drug name: we are
connected to a database with all drug names in the French
market [16]. In addition, based on the solid expertise of our
physicians, we have been able to design and build rules and
patterns covering drug-related information with a variety of
abbreviations, grammatical errors and physicians’ common
mistakes.
There exists a second approach that uses machine learning
in order to extract entities (dosage, frequency, duration, route,
drug name) from clinical texts in [17]. The system proposed
in [17] is a NER model relying on a bidirectional long-short
term memory with conditional random ﬁelds (BiLSTM-CRF)
architecture composed of 3 different layers: embedding layer,
bidirectional long-short term memory layer, and conditional
random ﬁelds layer. Different deep learning-based approaches
were explored. All of them rely on a bidirectional long-short
term memory with conditional random ﬁelds but with various
embeddings such as word embedding, character embedding,
and semantic-feature embedding. This system achieved en-
couraging results and demonstrated the feasibility of using
deep learning methods to extract medication information from
raw clinical texts. Several other research papers have proposed
BiLSTM with conditional random ﬁelds for their NER model
[18], [19]. However, this type of approach requires working
with words and phrases that have meaning in their sequence.
However, in French prescriptions, the information is presented
as a distinct set of words, where each set is generally made
up of three or four words that are always in the same order.
In order to leverage the advantages of these methods and the
rule-based approaches, researchers combined both methods,
which shows a better performance. An example of such a
combination can be found in [7], where the authors use a
conditional random ﬁeld for the NER model along with a
support vector machine extracting related entities combined
with a rule-based context engine. These approaches were
designed for text written in English. To the best of our
knowledge, there are only a few research works done for
French clinical texts. In [2], a hybrid system combining a
rule-based approach with contextual word embedding trained
on clinical data with a deep recurrent neural network was
developed, and it outperforms other approaches based on a
token-level evaluation.
In this work, we combine deep learning techniques and
rule-based approaches to create our NER model from a
different perspective. A deep learning approach is used to
classify sentences into three categories (drug, posology, or
useless sentence), and then a rule-based approach is crafted
accordingly to the identiﬁed category. Indeed, applying the
sentence classiﬁcation model beforehand improves the output
of our global model since it applies the rule-based extractor on
the appropriate sentence containing the required information,
i.e., prevents applying rules-based patterns on a confusing
sentence that may or may not contain the desired entity. In
addition, we then link the sentences that are classiﬁed as drugs
to a unique ID in the Vidal database [20]. That way, the
drug is recognized in an international database, and additional
information is fetched. By matching the extracted drug with
the Vidal database, we can also deal with the potential errors
occurring when running the Optical Character Recognition
(OCR) on the scanned document. Indeed, even if the drug
name is not complete, our algorithm can still recover the
ofﬁcial drug name. Finally, we designed a geometric approach
to build a relation extractor system that matches a drug and
its associated posology. In the following section, we present a
detailed explanation of each part of our method.
III. MATERIALS AND METHODS
This section presents in detail the explicit steps and tools
used and applied to achieve our desired goal. First, we describe
the employed data. Then, we deﬁne the tools and libraries used
to annotate the data and establish its utility. Also, we determine
the referenced databases used in the project. Lastly, we explain
the steps developed in our algorithms to extract a drug and its
25
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-892-1
GLOBAL HEALTH 2021 : The Tenth International Conference on Global Health Challenges

related information (dose, frequency, duration, and comment)
and how we connect them.
A. Data
Almost all medical prescriptions in French have identical
structures. Based on our database and the knowledge of our
physicians, we visualized and concluded that 90% of the
prescription could be categorized into three types of formats.
The rest have either a unique structure or are handwritten.
Hence, this insight helps us choose the right way to achieve the
desired goal, which we will develop in the following sections.
Figure 1 shows the variety of prescriptions that are the subject
of focus.
We had more than 2000 medical documents classiﬁed
between blood work, medical reports, and prescriptions in
our internal databases. 500 of them are medical prescriptions.
Upon examination, we found out that only 70 users accepted
that their documents could be used in our research work,
although they have already gone through our anonymization
algorithms.
Therefore, we launched a campaign to collect data from our
work colleagues and our families (47 persons), and we got over
100 prescriptions from 10 different cities and different clinics.
Brieﬂy, for the training dataset, we obtain 170 prescriptions
where each of them has at least ﬁve drug names followed by
1-3 sentences describing how it should be taken (posology).
Practically all of them have a well-deﬁned structure with some
changes in the header and layout of the document frame.
Again, we can ﬁnd prescriptions that have a unique format.
B. Annotation tools
For the project development, it was decided to apply a
textual classiﬁcation model to the prescription before extract-
ing the drug-related information. To proceed with this plan,
the ﬁrst step consists of using annotation tools to create
the labeling data. This step was carried out by the Prodigy
web application developed by the same Spacy team. It is a
paid tool. It offers a streaming display of all the document
sentences one by one. The data scientist’s role is to choose
one of the predeﬁned categories for each sentence as a label.
Ultimately, this results in a database of all of the sentence-level
annotated texts. Prodigy proposes several training functions
and a continuous active learning system, but we did not use
this system in our project.
C. Drug names database
In this work, we are not just looking to extract the name
of the drug from the prescription. One of the main objectives
is to link the detected drug to an ofﬁcial reference database
where a drug can have a unique ID and a description of
its medical information. In addition, we are looking for an
international solution as we are working on an international
project. Thus, we relied upon two drug databases. The ﬁrst
one is the Vidal Drug Information Systems database [20]. This
database contains drug information in several languages, and
it can be used for many other functionalities that will be useful
for the project in future work. The second database we used
is the French Government drug database [16].
D. Methods
Our objective is to develop a drug-related information
extraction system and deploy it in an actual web/mobile
application. In this section, we will describe the adopted
solution for each task in this project. Figure 2 shows the
sequence of operations that have been applied to obtain the
ﬁnal output.
Since this solution is intended to be used in a real-time
application, it is crucial to develop a design with a precise
and trusted outcome. This is one of our main contribution. To
our knowledge, no one has yet developed such an application.
The existing state-of-art is academic, and it is implemented
on data from hospitals or clinics, unlike ours, which is
composed of scanned documents by the patient using different
smartphone cameras. That represents a higher challenge due
to the document quality and the versatility that does not exist
in other work.
As shown in Figure 2, ﬁrstly, we implement the OCR
technique to extract text from documents in pdf or image
format, which includes the skew correction. Then we apply
the deep learning method from the Spacy library to classify
sentences between drug, posology, or useless sentences. De-
pending on the predicted class, if it is a drug sentence, we
apply a particular matcher to ﬁnd out the drug’s name and
attach it to a unique ID in the Vidal databases. Otherwise, a
Spacy rule-based matcher is applied to extract the drug-related
information (dosage, frequency, duration, comments) if it is
a posology sentence. These matchers are highly customized
to ﬁt only French prescriptions that have speciﬁcs formats.
We follow this step with a geometric relationship approach
to assign each posology to its corresponding drug. At the
end, we display the result in a structured user interface for
a mobile/web application. In the following sections, a detailed
description will be presented for each of the proposed tasks.
E. Optical character recognition
In the existing research work, most projects operate either
on pure medical text or PDF documents. Nobody needed to
examine the quality of the documents or process the noise in
data to extract the texts. That implies they had no limitation
regarding the document’s quality or the method used to extract
the text. Despite the limited number of documents in our
database, there is a diversity in the quality of photos and how
the posology is drafted for each drug. Therefore, the extraction
of texts is the fundamental step to have a clean data to process
in the coming phases. For this purpose, we use the service of
AWS to carry out this task. We compared it with other open-
source methods, but the AWS results were persuasive enough
regarding their performance on the text extraction quality with
all its details. This functionality takes as input a document’s
photo and returns a JSON ﬁle containing the text and its
geometric-related information in sentence level and word level.
26
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-892-1
GLOBAL HEALTH 2021 : The Tenth International Conference on Global Health Challenges

Fig. 1. Example of scanned documents. These prescriptions were scanned with a smartphone camera. They vary in terms of quality, orientation,
and color. Some documents contain the drug and its equivalent in case it is not available. Our algorithm should be clever enough to detect
this case and choose only one of them.
F. Text pre-processing
Due to the low quality of the scanned document, OCR may
return unclean texts. For this reason, a data cleaning step is
crucial to make the texts more useful. We have applied the
following treatment to the extracted text:
• Remove the accents.
• Transfer words to lowercase format.
• Unify the format of the number. Remove space and
unnecessary punctuation between them if they exist.
• Remove the stop words.
• Remove sentences with one word of less than two char-
acters (we got many of them).
G. Sentence classiﬁcation
Before we started extracting the desired entities from the
text, it was more efﬁcient to categorize the text sentences and
exclusively use those containing the drug and its information.
This step will increase the efﬁciency of our NER model since
it will only focus on sentences that contain the desired entities.
Moreover, with limited databases, learning a model to classify
the sentence is more realistic and doable than learning a NER
model.
To accomplish this task, we downloaded 15000 drug names
from the government public drug database. We also generated
Fig. 2. Flowchart of our appraoch.
15000 synthetic sentences that describe how a drug should
be taken (these sentences are called posologies). Moreover,
we have produced over 15000 sentences carrying medical
information, patient information, names, and all kinds of
information that may be present in a prescription other than
the drug and the posology.
We trained our classiﬁer using these 45000 sentences with
a bidirectional LSTM architecture. It is used to classify
sentences into three categories; drug, posology, and useless
sentences. This classiﬁer achieved an accuracy of 95.23%.
The remaining 5% will be automatically ignored by the drug
extraction model due to the rules-based approach.
H. Drug detection
In a French prescription, the text is structured in a particular
way. A drug is located on a separate line or on the same line
with the posology. So, after getting the classiﬁed sentence from
the previous model, we will know in advance that there are
two choices for the sentence classiﬁed as ”drug sentence”;
either this sentence contains only the name of the drug, or it
contains both the name of the drug and its related information
(posology). In addition, generally, between two drug sentences,
there is only one or more posology. We have never seen any
information unrelated to posology.
Moreover, one of the main points that generally holds true
in French prescriptions is that the names of the drugs are
consistently among the top three words in the sentence. That
information led us to minimize the search within a window
in the sentence. Hence, we have created a drug-matcher that
relied on a rule-based approach using the French Government
drug databases [16]. Once we have detected the ﬁrst word
of the drug name, it is used to send a query to the Vidal
Drug Databases and extract a list of all similar names and
features. Then, we apply similarity measurements to determine
the closest and longest contiguous matching sub-sequence to
the name in the prescription. Indeed, this task is not evident
since the name of each drug is composed of up to ﬁve words
including numbers and units. We can see that clearly in Figure
1. We often obtain the closest match despite the difference in
word succession or the spaces between numbers and units.
27
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-892-1
GLOBAL HEALTH 2021 : The Tenth International Conference on Global Health Challenges

Fig. 3. Patterns that have developed using the rule-based matching Spacy library.
I. Posology detection
Similar to the previous section, after the sentence is clas-
siﬁed as a posology sentence, a rule-based matcher will be
applied over the sentence to extract the related drug infor-
mation. We used the 170 prescriptions introduced in Section
III-A to produce the related information pattern. We employed
the rule-based model from the NLP Spacy library to create
the entity matcher. We designed four matchers for the four
different features we search for (dosage, frequency, duration,
comment). Figure 3 shows the rules created for the ”dose
matcher”. Our physicians designed more than 100 patterns for
each feature. They include abbreviations, miss-writing, and
common mistakes.
J. Drug-posology relation extraction
The AWS ”textract” API output format includes geometric
coordinates of the polygons enclosing the words and the
sentences. Based on this information, we created an algorithm
to assign each entity to its corresponding drugs using the
geometric features. We relied on human linguistic intuition
in this approach. Each posology is assigned to the closest
top drug while respecting a given distance threshold between
their polygons. A drug can have a posology composed of
several lines. So, for a given text, if the successive sentences
respect the given distance threshold, they are considered in
the same section and associated to the same drug. Otherwise,
when the posology is aligned horizontally with a drug, it will
automatically be assigned to it.
IV. EVALUATION AND RESULTS
In order to evaluate our method, we used the standard
metrics for this task. We measure the recall, the precision,
and the F1-score on our test dataset for each feature by itself.
An entity is considered a true-positive when it was annotated
with the correct label, a false-positive when a token is falsely
annotated with respect to each feature. A false-negative is
considered when it was not annotated at all, or it was annotated
with the incorrect label [2].
Regarding the testing data, we gathered documents from
20 colleagues at work. These 20 colleagues are located in
TABLE I: MEDICATION INFORMATION PREDICTIONS METRICS RE-
SULTS.
Label
F-measure
Precision
Recall
Drug name
94.33
100
89.33
Dose
93.91
100
88.52
Duration
94.91
98.24
91.80
Frequency
96.60
100
93.44
Comment
91.10
100
83.60
different cities in France and work remotely with the Re-
Lyfe group. The majority are in Paris and Reims. The data
constituted of 33 prescriptions. This data is composed of
1096 sentences with 4572 words. It contains in total 75 drug
names and 61 posology sentences. Some of the drugs do not
have an associated posology, where others have multiple ones.
Despite the limited number of documents for testing, these
documents are characterized by their diversity. Each one has a
different drug and a different way of representing how to take
it (posology). Table I summarises the results of each different
entity matcher. We can see that the model results are higher
than 90%, which is not unexpected due to the high number of
patterns that we have created to cover the maximum number of
cases and sentences. In addition, as mentioned in the previous
section, more than 80% of the prescription documents have
the same structure and format, which helped us get these
good results. We can notice that the precision for all models
is approximately 100%. That may be due to the accuracy of
the sentence classiﬁer model that is applied beforehand. This
model eliminates the confusion presented when we apply our
NER models to sentences that do not ﬁt into the posology
category.
Figure 4 shows the results of getting the drugs and their
medical-related information from a prescription. This docu-
ment has seven drug names and four posologies. After getting
all the desired entities, they will be the input of another
algorithm to differentiate between numbers and units, as
shown in the photo. Moreover, sometimes physicians provide
equivalent to each drug if it does not exist, so our algorithm
works to choose one of them to make it the reference. Figure 5
displays the extracted entities in our web/mobile application
where the user can upload a French prescription and get the
structured data.
Fig. 4. The extracted entities from our approach. Despite the low
quality of this photo, we were able to extract the text and apply the
relation entity extraction models.
28
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-892-1
GLOBAL HEALTH 2021 : The Tenth International Conference on Global Health Challenges

Fig. 5. The display of our results in our mobile application after
getting the drug and its related information.
V. CONCLUSION
This paper presents a functionality created to be applied
in a real application to extract drug-related information. This
work is one of the few that contributes to the French medical
documents. Our approach is a series of methods concatenated
together to achieve a high-performance system capable of cop-
ing with the constraints of real applications. We have applied a
deep learning technique to classify the prescription sentences
into three categories: drug, posology, and useless sentences.
Then, we applied the corresponding rule-based approach to
extract the targeted features for each of these categories. A
unique international ID is associated with the detected drug
name via the Vidal databases. Lastly, an algorithm based on
human intuition and the sentence’s geometric position was
designed to build a relation extractor system to associate
the detected entities to their corresponding drug. Theoretical
and practical tests have proved the outperformance of our
approach.
REFERENCES
[1] R. A. Tariq, R. Vashisht, A. Sinha, and Y. Scherbak, “Medication
dispensing errors and prevention,” StatPearls: Treasure Island, FL, USA,
2020.
[2] J. Jouffroy, S. F. Feldman, I. Lerner, B. Rance, A. Burgun, and
A. Neuraz, “Hybrid deep learning for medication-related information
extraction from clinical texts in french: Medext algorithm development
study,” JMIR medical informatics, vol. 9, no. 3, p. e17934, 2021.
[3] S. Gold, N. Elhadad, X. Zhu, J. J. Cimino, and G. Hripcsak, “Extracting
structured medication event information from discharge summaries,” in
AMIA Annual Symposium Proceedings, vol. 2008.
American Medical
Informatics Association, 2008, p. 237.
[4] Z. Shen, “Natural language processing (nlp) applications in patient care:
A systematic analysis,” QRBD, p. 223, 2020.
[5] A. B. Abacha and P. Zweigenbaum, “Automatic extraction of semantic
relations between medical entities: a rule based approach,” Journal of
biomedical semantics, vol. 2, no. 5, pp. 1–11, 2011.
[6] O. S. Lupse and L. Stoicu-Tivadar, “Extracting and structuring drug
information to improve e-prescription and streamline medical treatment,”
Applied Medical Informatics., vol. 40, no. 1-2, pp. 7–14, 2018.
[7] J. Patrick and M. Li, “High accuracy information extraction of medi-
cation information from clinical notes: 2009 i2b2 medication extraction
challenge,” Journal of the American Medical Informatics Association,
vol. 17, no. 5, pp. 524–527, 2010.
[8] A. N´ev´eol, H. Dalianis, S. Velupillai, G. Savova, and P. Zweigenbaum,
“Clinical natural language processing in languages other than english:
opportunities and challenges,” Journal of biomedical semantics, vol. 9,
no. 1, pp. 1–13, 2018.
[9] S. Sheikhalishahi, R. Miotto, J. T. Dudley, A. Lavelli, F. Rinaldi, and
V. Osmani, “Natural language processing of clinical notes on chronic
diseases: systematic review,” JMIR medical informatics, vol. 7, no. 2, p.
e12239, 2019.
[10] L. Del´eger, C. Grouin, and P. Zweigenbaum, “Extracting medication
information from french clinical texts,” in MEDINFO 2010. IOS Press,
2010, pp. 949–953.
[11] I. Lerner, N. Paris, and X. Tannier, “Terminologies augmented recurrent
neural network model for clinical named entity recognition,” Journal of
biomedical informatics, vol. 102, p. 103356, 2020.
[12] L. Bai, M. D. Mulvenna, Z. Wang, and R. Bond, “Clinical entity
extraction: Comparison between metamap, ctakes, clamp and amazon
comprehend medical,” in 2021 32nd Irish Signals and Systems Confer-
ence (ISSC).
IEEE, 2021, pp. 1–6.
[13] H. Xu, S. P. Stenner, S. Doan, K. B. Johnson, L. R. Waitman, and J. C.
Denny, “Medex: a medication information extraction system for clinical
narratives,” Journal of the American Medical Informatics Association,
vol. 17, no. 1, pp. 19–24, 2010.
[14] S. Sohn, C. Clark, S. R. Halgrim, S. P. Murphy, C. G. Chute, and
H. Liu, “Medxn: an open source medication extraction and normalization
tool for clinical text,” Journal of the American Medical Informatics
Association, vol. 21, no. 5, pp. 858–865, 2014.
[15] K. Kreimeyer, M. Foster, A. Pandey, N. Arya, G. Halford, S. F.
Jones, R. Forshee, M. Walderhaug, and T. Botsis, “Natural language
processing systems for capturing and standardizing unstructured clinical
information: a systematic review,” Journal of biomedical informatics,
vol. 73, pp. 14–29, 2017.
[16] “The
public
drug
database
.https://base-donnees-
publique.medicaments.gouv.fr/,” August 2021.
[17] G. Alfattni, M. Belousov, N. Peek, and G. Nenadic, “Extracting drug
names and associated attributes from discharge summaries: Text mining
study,” JMIR medical informatics, vol. 9, no. 5, p. e24678, 2021.
[18] G. Lample, M. Ballesteros, S. Subramanian, K. Kawakami, and C. Dyer,
“Neural architectures for named entity recognition,” arXiv preprint
arXiv:1603.01360, 2016.
[19] M. Sadikin, M. I. Fanany, and T. Basaruddin, “A new data representation
based on training data characteristics to extract drug name entity in
medical text,” Computational intelligence and neuroscience, vol. 2016,
2016.
[20] “Api
of
the
vidal
drug
information
systems
databases.
url:
https://www.vidal.fr/,” August 2021.
29
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-892-1
GLOBAL HEALTH 2021 : The Tenth International Conference on Global Health Challenges

