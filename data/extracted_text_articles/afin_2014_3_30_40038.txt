Multiple Tree-Based Online Trafﬁc Engineering for Energy Efﬁcient Content-Centric
Networking
Ling Xu, Tomohiko Yagyu
Cloud System Research Lab
NEC Corporation, Japan
Email: lingxu@gisp.nec.co.jp, yagyu@cp.jp.nec.com
Abstract—Content-Centric Networking (CCN) is a new network
architecture aiming to solve many fundamental problems of
existing IP networks. CCN is unique in that it widely deploys
caches on routers to reduce redundant data transmission. In-
troducing caches into routers, however, causes the networks
to consume extra energy. Although great research effort has
been put for improving energy efﬁciency in IP networks, little
work has been done for CCN networks yet. We designed an
online trafﬁc engineering algorithm called Multiple Tree-based
Trafﬁc Engineering (MTTE) to ﬁll this void. Our approach
is to make trafﬁc ﬂow on a small portion of edges in the
network and shut down underutilized edges. Data are delivered
on multiple tree-topology networks that are dynamically created
based on the physical network topology and the current network
trafﬁc pattern. The trees are carefully constructed so that they
contain minimal edges and mitigate congestion. Simulations using
network topologies of real-world autonomous systems show that
by using MTTE, up to 45% of the edges can be shut down. To the
best of our knowledge, MTTE is the ﬁrst online green mechanism
for CCN.
Keywords–Content-centric networking; energy efﬁciency; mul-
tiple trees; trafﬁc engineering.
I.
INTRODUCTION
Recently, Content-Centric Networking (CCN) has been
drawing considerable attention from the industry and academic
community [1]. In conventional IP networks, a great part
of data transmission is redundant. CCN reduces redundant
data transmission by deploying caches on all routers in the
networks. A CCN network consists of hosts and routers.
Each host holds contents, and each content has a unique
name. Each name consists of a preﬁx and a ﬁle name. For
example, the name “/Asia/Tokyo/music1.mp3” contains preﬁx
“/Asia/Tokyo/” and ﬁle name “music1.mp3”. For host p and
its content d, p registers d’s name on each router. This process
is called content publishing, and p is known as the producer
of d. Suppose that another host, say c, needs d. c sends an
Interest i to its adjacent router. The Interest is then forwarded
toward p according to certain forwarding policies. We refer to
c as a consumer of d. Having received i, producer p packs d
into content object packets, denoted as co(d), and sends co(d)
back to c. Each router r along co(d)’s forwarding path tries to
store d in its caches. The next time r receives an Interest for d,
if d is still in its cache, r sends co(d) to the consumer directly.
In this paper, for ease of exposition, we do not differentiate
hosts from routers. For host h and its adjacent router r, when
h issues an Interest for content d, we simply regard r as the
consumer of d; when h is a producer of d, we regard r as d’s
producer.
We are concerned about CCN’s energy consumption. Net-
works consume a huge amount of energy, and improving their
energy efﬁciency has been a hot research topic in recent
years. CCN networks generally consume more energy than
conventional IP networks since in-router caches cost extra
energy.
Recent studies have evaluated CCN’s energy efﬁciency
[2][3]. However, no effective mechanism has been proposed
for reducing CCN’s energy consumption.
Although many energy-saving techniques have been pro-
posed in IP networks, they cannot be readily transplanted into
CCN networks. One of the general ideas for reducing network
energy is to shut down underutilized edges [4]. Routers are
the main hardware components and main energy consumers
in networks. A router consists of a Central Processing Unit
(CPU) and a set of network interfaces. Each interface connects
an adjacent router via a piece of cable. Henceforth, we use
edges to denote interfaces. The general idea for conserving
energy is to shut down CPUs and edges, and the critical
challenge is to shut down edges without remarkably reducing
the system performance. In IP networks, one of the most
commonly used techniques for this challenge is to (1) estimate
the trafﬁc matrix (i.e., the amount of trafﬁc that will ﬂow
between each pair of edge routers) periodically, and (2) based
on the estimated trafﬁc matrix, ﬁnd the edges whose shutdown
minimizes performance degradation using linear programming
[5]. In CCN networks, however, all routers can cache and
provide all kinds of content. The trafﬁc patterns are more
complicated than in IP networks. Hence, estimating the trafﬁc
matrix is difﬁcult.
Our objective is to design a mechanism that reduces CCN’s
energy consumption without remarkably reducing the network
performance. To this end, we proposed Multiple Tree-based
Trafﬁc Engineering (MTTE). Previous research has found that
edges in modern networks are generally underutilized [4]. Our
idea is to shut down as many underutilized edges as possible.
We split trafﬁc on multiple tree-topology networks generated
based on the physical network. The trees are generated in
such a way that the number of edges included in the trees
is minimized. Since trees generally contain fewer edges than
the original physical network, energy can be conserved.
We face two challenges in our design. First, as fewer edges
are used for forwarding trafﬁc, the network is more vulnerable
to trafﬁc congestion. We assume that when a network system
is heavily congested, most likely the congestion is caused
79
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

by a few bottleneck edges. To reduce congestion, we need
to reduce the load on the congested edges. In MTTE, the
network contains a centralized server called the controller. The
controller dynamically monitors the congestion status of the
system. When the system congestion is severe, the controller
generates more trees so that the congestion on the bottleneck
edges can be relieved. When the maximal utilization among
all edges is low, the controller merges trafﬁc on fewer trees
and shuts down more edges.
The second challenge is that creating new trees potentially
increases transmission latency. In a native CCN network,
contents are delivered on the full physical network; in MTTE,
contents are delivered on sub-networks. The (shortest path)
distance between each pair of consumer and producer in MTTE
is essentially greater than in native CCN network. Hence, the
mean length of physical forwarding paths between consumers
and produces in MTTE, denoted by the Mean Forwarding
Length (MFL), is greater. Moreover, under the original CCN
protocol, when a content is forwarded, all routers along the
forwarding path will try to cache this content. As the MFL
increases, the same content is likely to be cached on more
routers. Previous studies have shown that repeatedly caching
the same content reduces caching efﬁciency [6]. Hence, adding
more trees naively is likely to further increase the system
latency. We address this challenge by reducing the diameters
of the trees.
We compare the performance of MTTE and native CCN
under two metrics, Live Edge Rate (LER) and the system
latency, via simulations running on real-world autonomous
system topologies. Here, live edges are the edges contained
in trees, and other edges are called free edges. LER is the
ratio between the average number of live edges used during
the simulation and the total number of edges in the physical
network. The system latency is the average time between
issuing Interests and getting content objects. Simulation results
reveal that MTTE can shut down up to 45% of the edges while
maintaining a latency comparable to CCN. Furthermore, under
heavy congestion, MTTE can shut down 40% of the edges and
achieve a latency 90% lower than CCN.
In short, we propose an online energy-saving mechanism
for CCN which, to the best of our knowledge, is the ﬁrst of
its kind.
We detail the design of MTTE in Section III and evaluate
MTTE’s performance via simulation in Section IV. We high-
light the relevant prior literature in this ﬁeld in Section II and
present our conclusion in Section V.
II.
RELATED WORK
In conventional IP networks, Trafﬁc Engineering (TE) is
a kind of well-researched mechanism that adjusts routing
paths of trafﬁc for relieving congestion, balancing trafﬁc and
reducing energy consumption [4]. MTTE is one of the few
TE schemes designed for CCN networks. TE mechanisms
can be implemented either ofﬂine [7] or online [8]. Ofﬂine
TE mechanisms need to estimate the trafﬁc matrix. Based
on the trafﬁc matrix, the TE protocols ﬁnd the routing paths
that minimize the energy consumption of the whole network
using linear programming. In CCN, however, due to the wide
existence of caches, the trafﬁc between each pair of edge
routers are more dynamic, and the trafﬁc matrix would be
hard to predict. In contrast, online TE mechanisms monitor
the real-time trafﬁc of the network and dynamically change
routing paths according to the trafﬁc ﬂuctuation. MTTE is,
to the best of our knowledge, the ﬁrst online TE mechanism
for CCN networks that both reduces energy consumption and
relieves congestion.
Online energy-aware TE protocols for IP and MPLS net-
works have been proposed recently [9][10]. Vasi´c et al. assume
that network edges work on multiple ﬁxed energy consumption
levels, and edges can switch to lower energy consumption
levels when their utilization is low [9]. Each pair of routers
maintain multiple routing paths. Each router periodically ad-
justs the trafﬁc partition among its routing paths so that more
edges can shift to lower energy consumption levels. Coiro et
al. propose EATE, a distributed energy-aware architecture [10].
EATE is created above the MPLS protocol stack. Routers in
the network run a modiﬁed OPSF-TE algorithm to periodically
compute the shortest paths to each other based on the hop
counts and the numbers of sleeping edges along the paths.
When congestion occurs, nodes create new routing paths to
bypass the congested area. However, these TE schemes are
designed for connection-oriented architectures. Whether they
can be readily used for CCN networks is unknown.
Chanda et al. implemented an online TE scheme for
Information-Centric Networking (ICN) for balancing trafﬁc
[2] (CCN is a speciﬁc architecture implementation of the
information-centric networking philosophy). The research ob-
jective of [2] is to demonstrate that TE mechanisms can be
implemented more efﬁciently on CCN networks than on IP
networks. Xie et al. [3] implemented a TE protocol in CCN
with the goal of improving the caching efﬁciency, but how [3]
would affect CCN’s energy efﬁciency is unclear.
Research effort has been made in assessing CCN’s energy
efﬁciency using simulation [11][12]. Many of these researches
compare the energy efﬁciency of CCN with existing IP-
based content delivery techniques such as content delivery
networking and peer-to-peer networking. Song et al. [13]
noticed that in modern carrier networks, a great amount of
trafﬁc is generated from the edge. [13] uses GreenTE - an
existing energy-aware TE mechanism designed for IP networks
[4] - for reducing energy consumption of the core network,
and uses CCN for eliminating redundant trafﬁc generated by
the edge network. However, Song. et al.’s approach does not
reduce the energy consumption of CCN itself.
III.
MULTIPLE TREE-BASED TRAFFIC ENGINEERING
To reduce energy consumption, our idea is to shut down
as many underutilized edges as possible. From an energy-
saving viewpoint, delivering all contents on a single spanning
tree would be the most favorable option. This extreme case,
however, is impractical since a single tree is vulnerable to
congestion and results in the high latency. Hence, we try
to deliver the trafﬁc on multiple trees to minimize edges
contained in the trees and relieve congestion at the same time.
We use G to denote the whole network. In MTTE, G
contains a central server called the controller. We use ST s
to denote the set of trees created in MTTE. Initially, the
controller creates one spanning tree based on the physical
network topology and adds this tree to ST s.
A. Congestion Detection
The controller periodically measures system congestion
status and based on this, decides whether to create new trees or
not. Let us brieﬂy explain why congestion and latency occurs.
80
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

In a standard network, for each router and each edge of this
router, the edge maintains a packet queue of a ﬁxed length
and has a ﬁxed capacity. The edge’s utilization is the ratio
between the speed at which packets come to this edge to the
edge’s capacity. When utilization > 1.0, new incoming packets
are added to the queue’s tail and await forwarding. We call the
edges with utilization higher than φCE the congested edges,
where we empirically set φCE to be 0.9. When packets traverse
the congested edges, the system latency is likely to grow. Each
router periodically reports the utilization of its adjacent edges
to the controller. The controller calculates the Congestion Rate
(CR) as the maximal utilization of edges in the networks.
When CR > φtcc, where φtcc is a system parameter which
we empirically set to be 0.9, the controller creates one more
tree and asks routers to deliver the trafﬁc on each tree evenly.
We call this mechanism the Tree-based Congestion Control
(TCC).
B. Creating a New Tree
When the controller creates a new tree, we keep three
objectives in our minds: (1) the new tree should introduce free
edges into E(ST s) so that less trafﬁc traverses the congested
edges; (2) the new tree should not dramatically increase
the live edge rate; (3) the new tree should not remarkably
increase latency. Here, E(ST s) represents the set of live edges.
Basically, the new tree is created using Kruskal’s minimal
spanning tree algorithm [14], while the three goals are realized
by deciding which edges should be added into the new tree.
To realize goals (1) and (2), the controller assigns weights
to edges so that the uncongested edges are chosen ﬁrst, free
edges are chosen later, and congested edges are chosen last.
Here, uncongested edges are the live edges that have utilization
lower than φCE.
We realize goal (3) by reducing the diameters of the trees.
By doing so, we can reduce MFL and consequently, the system
latency. We need to create a spanning tree st with a small diam-
eter from the underlay physical network. Although theoretical
research has been performed on creating minimal diameter
trees [15], we use our own heuristic algorithm for simplicity.
For each edge e, we compute its “edge betweenness” (e.be)
- a widely used metric in graph theory [16]. Informally, e.be
represents the number of shortest paths in the entire network
that traverse e. Imagine that routers c and p are a pair of
consumer and producer, and sp is the shortest path between c
and p on G. Intuitively, if more edges with high betweennesses
are added to st, the probability that the data transmitted on
st between c and p are delivered along the shortest path is
higher. Accordingly, the diameter of st will be small. Based
on this observation, in MTTE, the controller selects edges
with higher betweennesses ﬁrst. When the controller creates
the initial tree, for each edge e, it calculates e.eb, and sets
e.weight = 1/e.eb. When subsequent trees are created, the
controller makes the weights of uncongested edges directly
proportional to the edges’ utilization, and makes the weights of
free edges inversely proportional to the edges’ betweennesses.
If the new tree is different from all the existing trees, the
controller adds the new tree into ST s; otherwise, the network
has no more capacity for mitigating congestion, the tree
creation fails and the system stays unchanged. Namely, the
system will not add trees permanently.
The complete tree-creation algorithm is shown in Figure 1.
1: EUE = Edges in E(ST s) with utilization <= φCE.
2: ECE = Edges in E(ST s) with utilization > φCE.
3: Efree: Edges not in E(ST s)
4: Umax = maximum of edge utilization of EUE
5:
6: The controller calculates the betweenness e.eb of each
edge e.
7:
8: if |ST s| = 0 then
9:
// The controller is creating the initial tree
10:
for all e in the network do
11:
e.weight = 1/e.eb
12:
end for
13: else
14:
// The controller creates a new tree for mitigating
congestion
15:
for all e ∈ EUE do
16:
e.weight = e.utilization
17:
end for
18:
for all e ∈ Efree do
19:
e.weight = Umax + 1/e.eb
20:
end for
21:
for all e ∈ ECE do
22:
e.weight = Umax + 2
23:
end for
24: end if
25:
26: The controller generates a minimal spanning tree st using
Kruskal ’s algorithm on the whole network.
27: if st is different from all the existing trees then
28:
return st
29: else
30:
return FAILED
31: end if
Figure 1. Based on current edge utilization, the controller generates a new spanning tree.
C. Hash-based Trafﬁc Splitting
We brieﬂy discuss CCN’s packet (Interests and content ob-
jects) forwarding mechanisms. In CCN, each router r contains
a Forwarding Information Base (FIB). Each FIB contains a set
of entries and each entry is a mapping from one preﬁx to a set
of network interfaces. To explain CCN’s forwarding process,
suppose that r’s FIB contains two entries fe0=‘‘/Asia/’’:{face
2} and fe2=‘‘/Asia/Tokyo/’’:{face2,face5}, and suppose that
an incoming packet has a name n=“/Asia/Tokyo/music.mp3”.
r searches in FIB for the entry fe whose preﬁx matches n’s
preﬁx in the longest length. In this example, fe = fe2. r
has multiple forwarding strategies. According to forwarding
strategies, the incoming packets will be forwarded to one or
multiple faces in fe.faces. How routers create their FIB entries
and set their forwarding strategies is not standardized yet. In
this paper, we suppose that routers create FIBs in such a way
that packets are forwarded along one of the shortest paths
between each pair of routers.
Each time ST s is changed, routers update their respective
FIBs so that packets can be delivered on the new ST s. We
split the hash name space of CCN names into |ST s| sub-name
spaces, denoted by NS[1], ...NS[|ST s|]. Packets with names
whose hash values belong to NS[i] will be forwarded on the
i-th tree. Speciﬁcally, the controller sends both the topologies
of trees and G to routers. For each producer p and each content
81
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

d stored on p, p publishes d. We suppose that H is a collision-
proof hash function preloaded on each router. We use N(d) to
denote the CCN name of d. Producer p broadcasts N(d) along
the (H(N(d)) mod |ST s|)-th tree. Suppose that two routers
r1 and r2 are adjacent, during the broadcast, N(d) traverses
r1 ﬁrst and then r2, and f is r1’s face that connects r2. Upon
receiving N(d), router r1 adds an entry N(d).prefix : f in
its FIB.
D. Tree Removal
When trafﬁc in the network decreases, the controller
shrinks ST s and makes routers forward packets on fewer trees.
That is, when CR < φlowUtil, the controller removes off the
last tree in ST s and asks routers to update their FIBs. φlowUtil
is a preloaded system parameter that we empirically set to
be 0.6. Routers shut down their adjacent edges that are not
included in E(ST s).
IV.
EVALUATION
This section evaluates MTTE’s performance by compar-
ing the system latency and LER between MTTE and native
CCN. Our simulation is performed on ndnSIM – a simulation
platform developed by UCLA for CCN-related research [17].
A. Performance Metrics
The system latency is calculated in the following manner.
Each consumer r issues Interest Issuing Frequency (IIF)
Interests for random contents per second. CCN’s forwarding
mechanism ensures that if r issues multiple Interests for the
same content d before receiving the corresponding content
object, ﬁnally r will receive no more than one content object
of d. Upon receiving the content object, r calculates a local
latency as the time interval since r issues the ﬁrst Interest for
d, until the time r receives the ﬁrst content object of d. At any
time point, we calculate the mean value of the local latencies
of all consumers since the simulation starts by now as the
system latency.
LER is deﬁned as γ/|E|, where γ is the average number
of live edges used in STs during the simulation, and E is
the total number of edges in the physical network. We use
latency(MTTE) and latency(CCN) to denote the latencies of
MTTE and CCN, respectively.
B. Simulator Setting
Our simulations run on the network topology of au-
tonomous system 3257 (AS3257). This topology is provided
in Rocketfuel network dataset [18], a dataset that has been
used in network research [19][20]. Each node in AS3257
represents a router. We extract the largest connected component
of AS3257 and use all the remaining nodes for creating trees.
AS3257 contains three types of routers: cores, gateways and
leaves. According to the deﬁnition of Rocketfuel datasets,
leaves are the routers with degrees equal to or less than two,
gateways are the routers directly connected to the leaves, and
the remaining routers are cores. The numbers of edges and
routers in AS3256 are listed in Table I. We have also run
simulations on other Rocketfuel autonomous system topologies
and obtained consistent performance results.
We assume that in real world CCN networks, consumers
are adjacent to leaves, and producers are adjacent to both
gateways and leaves. In our simulation, we assign one producer
to each leaf and each gateway, and assign one consumer to
each leaf. Namely, totally 132 producers and 80 consumers
are generated.
TABLE I. NETWORK PARAMETERS
Parameter
Value
Total number of edges
420
Total number of routers
240
Number of gateway routers
52
Number of leaf routers
80
Each producer generates ten random preﬁxes, and each
preﬁx covers ten unique ﬁle names. Therefore, a total number
of (producer count) × 10 × 10 names are generated.
In each second, each consumer issues IIF Interests with
randomly selected names. The requested names are selected
according to a Zipf distribution [21][22][6]: the k-th name is
generated with a probability proportional to 1/kα, where α
is 0.7 in our simulations. Each simulation lasts 300 seconds.
We evaluate the performance when the trafﬁc is light (IIF=5)
and heavy (IIF=15). The payload of each content object is
1024 bytes, the capacity of each edge is 106 bps, φCE =
φtcc = 0.9, and φlowUtil = 0.6. For each parameter setting, we
repeat the simulation ten times and measure the average results.
Parameters φtcc, φC and φlowUtil reﬂect the trade-off between
transmission quality and energy efﬁciency. Generally, under
the same trafﬁc, more trees will be created and maintained
when φtcc and φlowUtil are low. TCC will more aggressively
choose free edges when φCE is low. In a real world CCN
network, the network administrators can adjust the parameters
themselves accordingly to the real needs of the system (high
transmission quality or high energy efﬁciency).
C. Performance under High Trafﬁc
Figure 2 compares the latency between MTTE and CCN
when trafﬁc is high (IIF=15). It shows that as times passes
by, latency(MTTE) decreases and latency(CCN) increases. At
the time point of second 300, MTTE shuts down 40% edges
(Figure 3), and latency(MTTE) is 1/9 of latency(CCN).
Figure 2. The comparison of the latency
between MTTE and CCN when IIF=15.
The horizontal and vertical axes represent
the time the simulation has elapsed (in sec-
onds) and the average latency (in seconds).
Figure 3. The comparison of LER between
MTTE and CCN. The horizontal and verti-
cal axes represent the simulation time and
LER, respectively.
As argued in Section III, the system latency is mainly
caused by the congestion on a few bottleneck edges (i.e.,
the congested edges). To validate this, we measure the mean
and maximum of edge utilization over all edges (Figure 5
and Figure 6). The utilization of each edge is calculated
as the ratio between the Exponentially Weighted Moving
82
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

300
200
100
0
400
300
200
100
0
-100
228 (bb-421)
227 (bb-425)
226 (bb-422)
225 (bb-420)
222 (leaf-458)
220 (gw-417)
218 (leaf-453)
215 (leaf-446)
214 (gw-415)
210 (leaf-442)
208 (gw-407)
207 (leaf-441)
201 (leaf-553)
193 (leaf-551)
191 (gw-372)
239 (leaf-543)
190 (bb-542)
189 (gw-541)
204 (leaf-394)
195 (bb-392)
178 (gw-393)
200 (leaf-382)
199 (leaf-381)
198 (leaf-380)
197 (leaf-379)
184 (leaf-516)
183 (leaf-540)
182 (leaf-508)
181 (leaf-507)
180 (leaf-506)
179 (leaf-371)
160 (leaf-525)
158 (leaf-528)
157 (leaf-527)
163 (leaf-338)
196 (leaf-547)
177 (bb-347)
148 (leaf-509)
142 (leaf-548)
141 (leaf-513)
140 (gw-312)
194 (gw-383)
192 (bb-373)
153 (gw-339)
152 (bb-330)
143 (leaf-315)
135 (bb-304)
186 (bb-368)
185 (leaf-361)
139 (bb-313)
134 (bb-301)
132 (bb-316)
131 (bb-305)
130 (bb-302)
128 (leaf-567)
126 (leaf-262)
124 (leaf-248)
235 (leaf-456)
233 (leaf-445)
224 (leaf-460)
217 (leaf-452)
117 (leaf-450)
115 (leaf-447)
114 (gw-438)
113 (leaf-437)
109 (bb-430)
107 (gw-419)
236 (bb-457)
234 (bb-455)
237 (leaf-454)
221 (bb-424)
219 (bb-416)
209 (bb-414)
216 (bb-411)
213 (gw-410)
206 (gw-406)
116 (bb-449)
232 (leaf-448)
231 (leaf-451)
108 (bb-423)
106 (gw-413)
230 (leaf-426)
223 (leaf-459)
112 (bb-436)
111 (bb-435)
110 (bb-434)
212 (leaf-444)
211 (leaf-443)
205 (leaf-440)
102 (gw-439)
101 (bb-433)
100 (gw-432)
99 (gw-431)
98 (gw-429)
97 (gw-418)
96 (bb-412)
95 (gw-409)
94 (gw-408)
93 (gw-405)
229 (bb-427)
176 (bb-537)
238 (leaf-534)
175 (bb-533)
123 (gw-247)
73 (leaf-204)
122 (bb-261)
125 (gw-260)
105 (gw-229)
121 (bb-246)
70 (bb-259)
127 (gw-268)
104 (bb-230)
55 (bb-270)
103 (bb-233)
92 (bb-226)
91 (leaf-225)
56 (bb-193)
43 (bb-185)
79 (bb-254)
42 (bb-183)
48 (bb-250)
47 (bb-249)
39 (bb-186)
38 (bb-184)
37 (bb-180)
53 (bb-221)
45 (bb-218)
74 (bb-205)
68 (bb-231)
61 (bb-245)
59 (bb-195)
51 (bb-191)
26 (leaf-219)
25 (bb-188)
27 (bb-179)
22 (leaf-176)
120 (leaf-244)
35 (bb-243)
34 (bb-242)
33 (bb-241)
119 (leaf-267)
118 (leaf-265)
32 (bb-238)
90 (bb-589)
57 (bb-269)
78 (bb-253)
89 (leaf-251)
88 (bb-234)
87 (bb-232)
67 (bb-228)
49 (bb-227)
46 (gw-224)
86 (leaf-223)
65 (bb-220)
29 (bb-197)
28 (bb-196)
52 (bb-189)
24 (gw-177)
63 (bb-266)
69 (bb-257)
77 (leaf-256)
75 (bb-222)
30 (bb-199)
64 (bb-198)
58 (leaf-194)
54 (bb-192)
41 (bb-181)
20 (leaf-239)
19 (gw-237)
18 (bb-236)
17 (gw-235)
14 (gw-159)
203 (leaf-388)
202 (leaf-387)
162 (leaf-337)
161 (leaf-336)
159 (gw-335)
156 (gw-334)
155 (leaf-333)
154 (leaf-332)
188 (leaf-367)
187 (leaf-364)
133 (gw-362)
174 (bb-342)
172 (bb-389)
171 (gw-378)
170 (leaf-358)
169 (leaf-357)
168 (gw-356)
167 (gw-354)
166 (leaf-353)
165 (leaf-352)
164 (leaf-351)
151 (leaf-523)
150 (leaf-522)
149 (gw-377)
146 (bb-345)
145 (leaf-322)
144 (gw-321)
138 (bb-374)
136 (gw-327)
137 (bb-306)
129 (bb-300)
21 (bb-590)
16 (gw-217)
72 (gw-213)
66 (bb-212)
71 (bb-211)
31 (bb-210)
60 (bb-201)
62 (bb-200)
36 (bb-190)
50 (bb-187)
23 (gw-178)
13 (bb-391)
12 (gw-390)
11 (gw-363)
9 (gw-340)
8 (gw-326)
7 (bb-320)
6 (gw-319)
5 (bb-303)
4 (bb-203)
173 (leaf-348)
147 (bb-346)
10 (bb-343)
3 (bb-153)
85 (bb-536)
84 (leaf-535)
83 (bb-532)
82 (gw-531)
81 (leaf-530)
80 (leaf-355)
40 (bb-209)
44 (bb-208)
15 (gw-207)
76 (bb-252)
2 (gw-341)
1 (gw-214)
0 (bb-16)
Figure 4. AS3257, the network topology used in user simulation.
Average (EWMA) of the trafﬁc load on this edge to this
edge’s capacity. Theoretically, edge utilization ranges between
0.0 and 1.0. However, since the utilization is calculated in a
EWMA manner, it may slightly exceed 1.0 when the network
experiences congestion. In MTTE, the mean utilization is about
0.19, but CR is up to 1.0. We illustrate the topology of AS3257
in Figure 4. This ﬁgure also shows that several clusters exist
in the network, where clusters are connected by a few edges.
These edges correspond to the congested edges.
The reason that latency(CCN) increases with time is that
the congested edges are overloaded, packet drop occurs, and
consumers cannot receive the required contents. According
to CCN’s forwarding rules, the consumers will re-send their
Interests, which makes the system even more congested and
increases the system latency. The reason why latency(MTTE)
decreases is that MTTE splits trafﬁc onto multiple trees. As
CR exceeds φtcc (Figure 6), new trees are generated (Figure
3). This reduces both the trafﬁc on the congested edges and the
Interest retransmission rate, which reduces the system latency
accordingly.
In a CCN network, the mean edge utilization can be
affected by the maximal routing capacity - the total capacity
of the minimal cut of the routing paths [23], and the Cache
Hit Rate (CHR). Generally, more trafﬁc can be delivered and
higher mean utilization can be achieved when the maximal
routing capacity is high. Meanwhile, as routers deliver more
trafﬁc, the CHR increases (discussed in more detail in Section
IV-D) and the mean edge utilization decreases. In MTTE,
as more trees are created, the maximal routing capacity and
hence the mean edge utilization increase. This trend can be
observed at the early stage of the simulation (before second
30, Figure 5). As the maximal routing capacity of the overlay
trees approaches the maximal capacity of the physical network,
the increase in the mean utilization stops. On the other hand,
routing paths in CCN and hence the maximal routing capacity
do not change since the beginning of the simulation. The mean
edge utilization of CCN generally decreases at the early stage
of the simulation (before second 30, Figure 5), which is mainly
attributed to the improve of the CHR.
In Figure 2, latency (MTTE) increases before second 10
and henceforth decreases. This is because before second 10,
no sufﬁcient trees are created. Packets accumulate on the
bottleneck edges, which increases the delay. After that, as more
trees are created, the congestion is mitigated and the delay
Figure 5. The comparison of the mean
edge utilization (vertical axis; ranging be-
tween 0.0 and 1.0) between MTTE and
CCN when IIF is 15.
Figure 6. The comparison of the maximum
of edge utilization among all edges (verti-
cal axis) between MTTE and CCN when
IIF is 15.
decreases.
D. Performance under Low Trafﬁc
Figure 7 compares the system latency between MTTE and
CCN when trafﬁc is low (IIF=5). Speciﬁcally, latency(MTTE)
is roughly 18% higher than latency(CCN), and MTTE shuts
down up to 45% edges (Figure 8).
Figure 7. The comparison of the system la-
tency (vertical axis; measured in seconds)
between MTTE and CCN when the trafﬁc
is low (IIF is 5).
Figure 8. The comparison of LER (vertical
axis) between MTTE and CCN when IIF
is 5.
As the clock ticks, the system latencies of both MTTE and
CCN decrease. To ﬁnd out why, we measure the CHR. Suppose
a router receives an Interest. If the content requested by this
Interest is (not) in the router’s cache, we say that the cache
makes a (miss) hit. Each router records the number of hits
(misses) its cache makes during the simulation as the cache
hit count (cache miss count). Then, we calculate the CHR
according to (1):
CHR =
mean cache hit count
mean cache hit count + mean cache miss count .
(1)
As routers process more Interests, more popular contents
are stored in the caches and the CHR increases (Figure 10).
Accordingly, that the system latency decreases over time. Note
that the CHR is calculated based on the trafﬁc from the past
ﬁve seconds. The delay is calculated based on the trafﬁc since
the simulation starts until the current time point. Hence, the
converging speed of the delay is lower than the CHR, where
the delay keeps slightly decreasing even when the CHR has
largely turned stable at second 55.
The reason that latency(MTTE) > latency(CCN) is that
as stated in Section III, MFL(MTTE) is generally larger than
MFL(CCN). To see this, we measure the mean hop counts
83
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

Figure 9. The comparison of the MHC
(vertical axis) between MTTE and CCN
when IIF is 5.
Figure 10. The comparison of the CHR
(vertical axis; ranging between 0.0 and
1.0) between MTTE and CCN when IIF
is 5.
(MHCs) of MTTE and CCN as indicators of the MFLs. The
MHC is calculated as the average number of hops for content
objects to return to consumers. The MHC is not equal to
the MFL as the MHC is also affected by the CHR, but it
should positively correlate to the MFL. Figure 9 shows that
MHC(MTTE) can be 30% greater than MHC(CCN). As the
MFL increases, the same content is cached on more routers,
making CHR(MTTE) decrease as well. Figure 10 shows that
CHR(MTTE) can be 20% lower than CHR(CCN). As the com-
bined result of the high MFL and low CHR, latency(MTTE)
is greater than latency(CCN).
E. Performance under Fluctuating Trafﬁc
In order to evaluate the performance when the network
experiences ﬂuctuating trafﬁc, we vary the IIF so that the IIF
rides a sine wave. The wave shape of the IIF is shown in
Figure 11. We expect to see that (1) TCC works correctly, i.e.,
MTTE adds trees when congestion is heavy and removes trees
when network utilization is low, and (2) MTTE keeps both the
latency and the LER low.
Figure 11. We make the IIF form a sine
wave. The horizontal and vertical axes
represent the simulation time and the IIF,
respectively.
Figure 12 shows that generally, latency(MTTE) is much
lower than latency(CCN). As the IIF increases, so does the
congestion on bottleneck links. On one hand, MTTE dy-
namically creates and removes trees (Figure 14), and la-
tency(MTTE) largely remains stable, which proves the effec-
tiveness of TCC. On the other hand, in CCN, packet drop
occurs and latency(CCN) increases as the IIF increases. As
packet drop occurs, consumers re-send Interests, which makes
the congestion deteriorate further. Latency(CCN) remains high
even when the IIF peak is over. The peak of the IIF emerges
Figure 12. The comparison of the system
latency (vertical axis) between MTTE and
CCN when the IIF ﬂuctuates.
Figure 13. LER changes in MTTE and
CCN as the IIF ﬂuctuates.
Figure 14. The change in tree count in
MTTE. As the IIF ﬂuctuates, so does the
tree count.
Figure 15. Comparison of latency(MTTE)
(in seconds) when TCC is disabled and
enabled under ﬂuctuating trafﬁc.
at the 100th second (Figure 11) while latency(CCN) does not
start decreasing until the 190th second (Figure 12), meaning
that it takes a long time for the network to completely transmit
the Interests accumulated when the network was congested.
All thought the simulations, MTTE shuts down up to 40%
of edges (Figure 13). Since trees created in MTTE are heavily
overlapped, the increase in LER(MTTE) is slight even thought
the trafﬁc remarkably surges. Figure 15 compares the latency
when the TCC mechanism is disabled (by setting φtcc = 100
so that no tree is created) and enabled (φtcc = 0.9). We can
clearly see that TCC effectively reduces the latency.
V.
CONCLUSION AND FUTURE WORK
CCN is a promising network architecture that provides
many new possibilities. In this work, we concentrated on
CCN’s energy efﬁciency, which is a barely-explored but much-
needed research topic. With the core idea of shutting down ex-
pendable edges, we have proposed a novel multiple tree-based
architecture called MTTE, the ﬁrst online green mechanism for
CCN. Through simulation, we have shown that MTTE can shut
down up to 45% of redundant edges, and achieve comparable,
and in many cases superior, trafﬁc transmission performance,
compared to native CCN. As for future work, we plan to
improve MTTE’s performance using more sophisticated tree
generation algorithms, and evaluate the performance in larger-
scale physical networks. Meanwhile, we will design energy-
saving mechanisms for CCN based on more accurate energy
models. MTTE uses a centralized controller, which may incur
scalability problems. Implementing it in a distributed manner
is another future research topic.
84
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

ACKNOWLEDGMENT
The work described in this paper was, in part, performed
in the context of the FP7/NICT EU-JAPAN GreenICN project.
REFERENCES
[1]
L. Zhang et al., “Named data networking (NDN) project,” Relat´orio
T´ecnico NDN-0001, Xerox Palo Alto Research Center-PARC, 2010.
[2]
A. Chanda, C. Westphal, and D. Raychaudhuri, “Content based trafﬁc
engineering in software deﬁned information centric networks,” Proc.
IEEE NOMEN Workshop, 2013, 2013.
[3]
H. Xie, G. Shi, and P. Wang, “TECC: Towards collaborative in-network
caching guided by trafﬁc engineering,” in INFOCOM, 2012 Proceedings
IEEE.
IEEE, 2012, pp. 2546–2550.
[4]
M. Zhang, C. Yi, B. Liu, and B. Zhang, “GreenTE: Power-aware
trafﬁc engineering,” in Network Protocols (ICNP), 2010 18th IEEE
International Conference on.
IEEE, 2010, pp. 21–30.
[5]
L. Chiaraviglio, M. Mellia, and F. Neri, “Reducing power consumption
in backbone networks,” in IEEE International Conference on Commu-
nications, 2009.
IEEE, 2009, pp. 1–6.
[6]
W. K. Chai, D. He, I. Psaras, and G. Pavlou, “Cache less for more
in information-centric networks,” in NETWORKING 2012.
Springer,
2012, pp. 27–40.
[7]
J. C. C. Restrepo, C. G. Gruber, and C. M. Machuca, “Energy proﬁle
aware routing,” in IEEE International Conference on Communications
Workshops, 2009. ICC Workshops 2009.
IEEE, 2009, pp. 1–5.
[8]
S. Kandula, D. Katabi, B. Davie, and A. Charny, “Walking the tightrope:
Responsive yet stable trafﬁc engineering,” in ACM SIGCOMM Com-
puter Communication Review, vol. 35, no. 4. ACM, 2005, pp. 253–264.
[9]
N. Vasi´c and D. Kosti´c, “Energy-aware trafﬁc engineering,” in Proceed-
ings of the 1st International Conference on Energy-Efﬁcient Computing
and Networking.
ACM, 2010, pp. 169–178.
[10]
A. Coiro, M. Listanti, A. Valenti, and F. Matera, “Energy-aware
trafﬁc engineering: A routing-based distributed solution for connection-
oriented ip networks.” Computer Networks, vol. 57, no. 9, 2013, pp.
2004–2020.
[11]
N. Choi, K. Guan, D. C. Kilper, and G. Atkinson, “In-network caching
effect on optimal energy consumption in content-centric networking,” in
2012 IEEE International Conference on Communications (ICC). IEEE,
2012, pp. 2889–2894.
[12]
U. Lee, I. Rimac, D. Kilper, and V. Hilt, “Toward energy-efﬁcient
content dissemination,” Network, IEEE, vol. 25, no. 2, 2011, pp. 14–19.
[13]
Y. Song, M. Liu, and Y. Wang, “Power-aware trafﬁc engineering with
named data networking,” in Seventh International Conference on Mobile
Ad-hoc and Sensor Networks (MSN), 2011. IEEE, 2011, pp. 289–296.
[14]
J. B. Kruskal, “On the shortest spanning subtree of a graph and the trav-
eling salesman problem,” Proceedings of the American Mathematical
society, vol. 7, no. 1, 1956, pp. 48–50.
[15]
R. Hassin and A. Tamir, “On the minimum diameter spanning tree
problem,” Information processing letters, vol. 53, no. 2, 1995, pp. 109–
111.
[16]
M. Girvan and M. E. Newman, “Community structure in social and
biological networks,” Proceedings of the National Academy of Sciences,
vol. 99, no. 12, 2002, pp. 7821–7826.
[17]
A. Afanasyev, I. Moiseenko, and L. Zhang, “ndnsim: Ndn simulator for
ns-3,” Named Data Networking (NDN) Project, Tech. Rep. NDN-0005,
Rev, vol. 2, 2012.
[18]
“Rocketfuel
dataset,”
https://github.com/cawka/
ndnSIM-ddos-interest-ﬂooding/tree/master/topologies/rocketfuel
maps cch, (retrieved: September, 2014).
[19]
N. Spring, R. Mahajan, and D. Wetherall, “Measuring ISP topologies
with rocketfuel,” ACM SIGCOMM Computer Communication Review,
vol. 32, no. 4, 2002, pp. 133–145.
[20]
C. Yi et al., “A case for stateful forwarding plane,” Computer Commu-
nications, 2013, pp. 779–791.
[21]
A. Ghodsi et al., “Information-centric networking: Seeing the forest for
the trees,” in Proceedings of the 10th ACM Workshop on Hot Topics
in Networks.
ACM, 2011, p. 1.
[22]
S. K. Fayazbakhsh et al., “Less pain, most of the gain: incrementally
deployable ICN,” in Proceedings of the ACM SIGCOMM 2013 con-
ference on SIGCOMM, ser. SIGCOMM ’13.
New York, NY, USA:
ACM, 2013, pp. 147–158.
[23]
G. Dantzig and D. R. Fulkerson, “On the max ﬂow min cut theorem of
networks,” Linear inequalities and related systems, vol. 38, 2003, pp.
225–231.
85
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-377-3
AFIN 2014 : The Sixth International Conference on Advances in Future Internet

