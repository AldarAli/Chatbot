 
An Extension of RankBoost for semi-supervised Learning of Ranking Functions 
 
Faïza Dammak                         
Laboratoire MIRACL – ISIMS 
SFAX 
Sfax, Tunisia 
faiza.dammak@gmail.com 
Hager Kammoun  
Laboratoire MIRACL – ISIMS 
SFAX 
Sfax, Tunisia 
hager.kammoun@isd.rnu.tn 
 
Abdelmajid Ben Hamadou 
Laboratoire MIRACL – ISIMS 
SFAX 
Sfax, Tunisia 
abdelmajid.benhamadou@isimsf.rnu.tn 
 
 
Abstract—The purpose of this paper was a semi-supervised 
learning method of alternatives ranking functions. This 
method extends the supervised RankBoost algorithm to 
combines labeled and unlabeled data. RankBoost is a 
supervised boosting algorithm adapted to the ranking of 
instances. Previous work on ranking algorithms has focused on 
supervised learning (i.e. only labeled data is available for 
training) or semi-supervised learning of instances. We 
are interested in semi-supervised learning, which has as 
objective to learn in the presence of a small quantity of labeled 
data, simultaneously a great quantity of unlabeled data, to 
generate a ranking method of alternatives. The goal is to 
understand how combining labeled and unlabeled data may 
change the ranking behavior, and how RankBoost can with its 
character inductive improve ranking performance.  
Keywords-learning to rank; ranking functions; semi-supervised 
learning; RankBoost algorithm. 
I. 
 INTRODUCTION 
Learning to rank is a relatively new research area which 
has emerged rapidly in the past decade. It plays a critical 
role in information retrieval. Learning to rank is to learn a 
ranking function by assigning a weight to each document 
feature, then using this obtained ranking function to estimate 
relevance scores for each document, and finally ranking 
these documents based on the estimated relevance scores 
[1][2]. This process has recently gained much attention in 
learning, due to its large applications in real problems such 
as information retrieval (IR). In learning to rank, the 
performance of a ranking model is strongly affected by the 
number of labeled examples in the training set, therefore, 
labeling large examples may require expensive human 
resources and time-consuming, especially for ranking 
problems. This presents a great need for the semi-supervised 
learning approaches [3] in which the model is constructed 
with a small number of labeled instances and a large number 
of unlabeled instances. Semi-supervised learning is a well-
known strategy to label unlabeled data using certain 
techniques and thus increase the amount of labeled training 
data [5]. 
Ranking is the central problem for many information 
retrieval (IR) applications. It aims to induce an ordering or 
preference relations over a predefined set of labeled 
instances. This is for example the case of Document 
Retrieval (DR), where the goal is to rank documents from a 
collection based on their relevancy to a user’s query. This 
type of problem is known under the name of ranking for 
alternatives [1]. The ranking of instances is another type of 
ranking which comes from the IR such as routing 
information [6].  
Since obtaining labeled examples for training data is very 
expensive and time-consuming, it is preferable to integrate 
unlabeled data in training base.  
Most semi-supervised ranking algorithms are graph-
based transductive techniques [4]. These techniques can not 
easily extend to new test points outside the labeled and 
unlabeled training data. Induction has recently received 
increasing attention. 
 For an effective use of the semi-supervised learning on 
large collections data, [6] presents a boosting based 
algorithm for learning a bipartite ranking function (BRF) for 
instances. This an extended version of the RankBoost 
algorithm [7] that optimizes an exponential upper bound of a 
learning criterion which combines the misordering loss for 
both parts of the training set. We propose an adaptation of 
the supervised RankBoost algorithm on partially labeled data 
of alternatives which can be applied to some applications 
such as web search. Our algorithm based on pairwise 
approach [8] which takes query-document pairs as instances 
in learning. 
Our contribution is to develop a semi-supervised ranking 
algorithm for alternatives. The proposed algorithm has an 
inductive character since it is able to infer an ordering on 
new examples that were not used for its training [5]. The 
unlabeled data will be initially labeled by a transductive 
method such as the K nearest neighbours KNN. 
The rest of the paper is organized as follows : Section 2 
provides a brief literature review to the related work, we 
introduce the principle learning to rank and its interest into 
the IR. We also detail the problem of ranking of alternatives, 
the RankBoost algorithm and the principle of semi-
supervised learning. In sections 3, we present our proposal 
49
Copyright (c) The Government of Tunisia, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

for semi-supervised method. The collections used and 
experimental results are detailed in Section 4. Finally, 
Section 5 concludes the paper and gives directions for future 
work. 
II. 
LEARNING TO RANK 
Ranking a set of retrieval documents according to their 
relevance for a given query is a popular problem at the 
intersection of web search, machine learning, 
and 
information retrieval. Over the past decade, a large number 
of learning to rank algorithms has been proposed [9]. In 
learning to rank, a number of queries are provided, each 
query is associated with a perfect ranking list of documents, 
a ranking function assigns a score to each document, and 
ranks the documents in descending order of the scores [7]. 
The ranking order represents relative relevance of documents 
with respect to the query. In a problem related to learning to 
rank, an instance is a set of objects and a label is a sorting 
applied over the instance. Learning to rank aims to construct 
a ranking model from training data. 
Many applications of learning to rank involve a large 
number of unlabeled examples and a few labeled examples, 
as expensive human effort is usually required in labeling 
examples [7].  
The issue of effectively exploiting the information in the 
unlabeled instances to facilitate supervised learning has been 
extensively studied known as the name semi-supervised 
learning [2]. We are interested to apply the supervised 
RankBoost algorithm with this type of learning. Indeed, 
RankBoost has an inductive character; it is thus able to order 
a list of examples not seen during the phase of training by 
inferring an order on this list. In the following, we present 
the principle of the ranking for alternatives, the RankBoost 
algorithm as well as the principle of semi-supervised ranking 
algorithm.  
A.  Ranking of Alternatives 
Learning to rank is a newly popular topic in machine 
learning. When it is applied to DR, it can be described as the 
following problem : assume that there is a collection of  
alternatives which called documents in DR. In retrieval, 
giving a query, the ranking function assigns a score to each 
pair query-document, and ranks the documents in descending 
order of these scores. The ranking order represents the 
relevance of documents according to the query. The 
relevance scores can be calculated by a ranking function 
constructed with machine learning. This type of ranking is 
known as of ranking of alternatives [1].  
B.  RankBoost Algorithm 
RankBoost is a supervised learning algorithm of 
instances designed for ranking problems.  It builds a 
document ranking function by combining a set of ranking 
features of a set of document pairs [3].  
More precisely, RankBoost learns a ranking feature 
tf  
on each iteration, and maintains a distribution
t
D over the 
ranked pairs. The final ranking function F is a linear 
combination of these ranking features that, in our context , 
defined by: 
 
, )
(
1
x k
f
F
i
t
T
t
t
= ∑ =
α
. 
(1) 
where xi is the query and k its vector of alternatives 
associated.  
Each ranking feature 
tf  is uniquely defined by an input 
feature jt∈{1...d} and a threshold 
tθ : 
 
( )
(
)



>
=
non
si
x k
if
x
f
t
i
jt
t
,0
,
,1
θ
ϕ
. 
(2) 
where 
(
k)
jt xi
,
ϕ
 is the j th  feature characteristic of xi. 
Assume that for all example pairs, one knows which 
example should be ranked above the other one. The learning 
criterion to be minimized in RankBoost is the number of 
example pairs whose relative ranking as computed by the 
final combination is incorrect. 
C. Semi-supervised Ranking 
Semi-supervised ranking has a great interest in machine 
learning because it can readily use available unlabeled data 
to improve supervised learning tasks when the labeled data 
are scarce or expensive. Semi-supervised ranking also shows 
potential as a quantitative tool to understand human category 
learning, where most of the input is self-evidently unlabeled. 
The majority of the semi-supervised ranking algorithms 
are transductive techniques based on valuated and non-
oriented graph [10]. The latter is formed by connecting 
gradually the nearest points until the graph becomes 
connected.  The nodes are consisted of the examples labeled 
and unlabeled of training base and the weights reflect the 
similarity between the neighboring examples. This graph is 
built with a method, such as k nearest neighbors, which 
allows finding the labels of the unlabeled examples by 
exploiting the graph directly by propagating for example the 
labels of the data labeled with their unlabeled neighbors. It 
thus affects a score for each instance, 1 for the positive 
instances and 0 for the others.  The scores are then 
propagated through the graph until the convergence.  At the 
end, the scores obtained make it possible to induce an order 
on the whole of the unlabeled instances [5].  We chose this 
method in our context to label the unlabeled data in the 
training 
set.  
These data will be used with the labeled as inputs in our 
proposal that have the advantage of both the inductive and 
transductive approaches. We thus propose a semi-supervised 
algorithm which it is able to infer an ordering on new pairs 
query-alternative that were not used for its training. We 
detail this proposal in the following section.   
50
Copyright (c) The Government of Tunisia, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

III. 
PROPOSAL FOR SEMI-SUPERVISED METHOD 
In training, a set of queries X = {
1x ,
2
x , ..,
xm
} and a set 
of alternatives Y is given. Each query 
ix ∈ X is associated 
with a list of retrieved alternatives of variable size mi, 
iy = 
(
1
iy ,...,
iymi
), with 
iyk
∈ IR . 
k
iy represents the degree of 
relevance of the alternative k  from 
ix . A feature vector ϕ j 
(
ix , k) is created from each query-document pair 
, )
(
xi k
[6]. 
The ranking function 
tf allows associating a score for 
this vector. We propose thus a labeled learning base S 
= (
)
{
}
m
i
xi yi
1
,
=  and an unlabeled learning base formed with 
all parts of queries unlabeled SU= ( )
{
}
n
m
i m
ix
+
+
=
1
'
.  
In this paper, we demonstrate a semi-supervised learning 
method could worth exploring in ranking functions of 
alternatives. The principal motivation to this led to find an 
effective ranking function. And it is necessary to have a base 
of learning which often requires on the one hand the manual 
labeling alternatives and on the other hand the unlabeled 
alternatives. The goal is to find the best entered to label to 
reduce to the maximum the number of labeled data. For an 
effective use of the semi-supervised learning on large 
collections, we adapted a modification of the supervised 
ranking RankBoost algorithm, and we presented the model 
suggested and described its functionalities as well as the 
choices of implementation.  
In the following part, we detail the operation of the 
RankBoost algorithm applied to our context. 
A. Adapation 
of 
RankBoost 
algorithm 
to 
semi-
supervised ranking of alternatives 
The adaptation of RankBoost is given in the algorithm 1: we 
dispose a labeled training set S = {(
1x ,
1y ), .., (
xm
,
m
y )}, 
where each example
ix  is associated with a vector of 
relevance judgment 
iy = (
1
iy ,..., 
iymi
) where 
k
iy ∈ IR  . 
i
m  
denotes the number of alternatives for 
ix .  
S’ = (
)
{
}
{
n }
m
m
i
y
x
i
i
+
+
∈
1,..,
;
,
'
'
is the second labeled 
subset obtained from unlabeled set SU by using the nearest 
neighbours (NN) algorithm. 
At each iteration, the algorithm maintains a distribution  
tλ (resp.
'
tλ ) on the examples of the learning base S (rep. 
S’), a distribution 
νti
 (resp.
ν t 'i
) on the alternatives 
associated with the example
ix
(resp.
'ix
) and a 
distribution
ti
D  (resp.
t 'i
D ) over the pairs (query, alternative), 
represented by a distribution on couples (k, l) (resp. (k’, l’)) 
such as
iyk
∈
Y+
(resp. 
iyk '
∈
Y+ '
) and 
iyl
∈
Y−
(resp. 
iy 'l
∈
Y− '
) for each example 
ix (resp.
'ix ).  
∀ i ∈ {1,..,m}, ∀ (k, l) ∈ {1,..,
i
m }2 such as 
iyk
∈
+Y , 
l
iy ∈
−
Y , 
 
ti
D (κ,λ)=
tλi
νti (k)
νti (l)
. 
(3) 
∀ i∈{m+1,.., m+n}, ∀ (k’, l’) ∈ {1,.., 
i
m ’}2 such as 
iyk '
 
∈
Y+ '
 , 
iy 'l
∈ 
Y− '
:  
 
t 'i
D ( k’,l’)) =
tλi '
νti (' k )'
νti (' l )'
. 
(4) 
These distributions are updated due to the scoring 
function 
tf , selected from the semi-supervised learning of 
ranking features algorithm (algorithm 2) which will return 
the resulting value of the threshold 
θres
associated with each 
characteristic and the possible values which can be 
associated with
tf , such as:   
 
(
)
(
)
(
)



≤
>
=
res
i
j
res
i
j
i
t
x k
si
x k
si
x k
f
θ
ϕ
θ
ϕ
,
0
,
1
,
. 
(5) 
where 
ix  is the query of index i and k is the index of the  
alternative associated with
ix .  
For each example, the weight 
t
α  is defined by [3]: 
 






−
+
=
t
t
t
r
r
1
2 ln 1
1
α
. 
(6) 
where 
 
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
' )
,'
'
,'
'
,'
'
,
,
,
'
,'
,
l
x
f
k
x
f
l
k
D
x l
f
k
x
f
k l
D
r
i
t
i
t
k l
i
t
i
t
i
t
k l
i
t
t
−
+
−
=
∑
∑
β
. 
(7) 
 
β is a discount factor. When this factor is zero, we will find 
the situation of supervised learning. 
Algorithm 1. RankBoost algorithm adapted to ranking of 
alternatives 
Entry : A labeled learning set S= (
)
{
}
{
m }
i
y
x
i
i
1,..,
;
,
∈
 
A labeled learning set S’= (
)
{
}
{
n }
m
m
i
y
x
i
i
+
+
∈
1,..,
;
,
'
'
 
obnained by KNN method. 
Initialisation :    
51
Copyright (c) The Government of Tunisia, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

           ∀ i∈{1, ..., m},
m
i
λ1 = 1
, 
( )






∈
∈
=
−
+
Y
si y
n
Y
si y
p
k
k
i
i
k
i
i
i
1
1
ν1
 
     ∀ i∈{m+1, .., m+n}, 
n
i
1
'
λ1 =
 ,
( )






∈
∈
=
+
'
_
'
'
'
1
'
1
'
1
'
Y
si y
n
Y
si y
p
k
k
i
i
k
i
i
ν i
 
       For t : = 1,…, T  do 
- Select the ranking feature 
tf  from
t
D and 
t '
D  
- Calculate 
t
α  using formula (6) 
      - ∀ i ∈ {1, .., m}, ∀ (k,l) ∈ {1, ..., mi}2 such as 
 
k
iy ∈
+
Y , 
l
iy ∈
−
Y , update 
Dti
1
+ ( k, l)  :  
 
Dti
1
+ (k, l) = 
tλ +1
i
t 1
ν +
(k) 
i
t 1
ν +
(l)  
 
      - ∀ i∈{m+1, .., m+n}, ∀ (k’, l’) ∈ {1, ..., 
'i
m }2 such 
 
as 
iyk '
∈
+'
Y , 
iy 'l
∈
−'
Y , update 
1'
ti
D + ( k’, l’) : 
 
 
1'
ti
D +  (k’, l’) =
'
tλ +1
1'
i
νt+
(k’) 
1'
i
νt+
 (l’)   
 
- ∀ i∈{1, .., m}, 
t
i
t
i
t
i
t
Z
Z 1
1
λ
λ
+ =
,  
( )
( )
(
)
(
)
( )
(
)
(
)







∈
∈
−
=
−
−
+
+
Y
si y
Z
k
x
f
k
Y
si y
Z
k
x
f
k
k
k
i
i
t
i
t
t
i
t
k
i
i
t
i
t
t
i
t
i
t
1
1
1
,
exp
,
exp
α
ν
α
ν
ν
 
 
where
i
tZ 1 , 
Zt i
1
− and 
tZ  are defined by :  
( )
, ))
(
exp(
:
1
x k
f
k
Z
i
t
t
Y
y
k
i
t
i
t
ik
α
ν
−
= ∑
∈ +
, 
( )
, ))
(
exp(
:
1
x l
f
l
Z
i
t
t
Y
y
l
i
t
i
t
il
α
ν
∑
−
∈
−
=
, 
i
t
i
t
m
i
i
t
t
Z
Z
Z
1
1
1
−
=∑
=
λ
   
- ∀ i∈{m+1, .., m+n}, 
'
'
'
'
'
1
1
1
t
i
t
i
t
i
t
i
t
Z
Z
Z −
λ + = λ
 , 
( )
( )
(
)
(
)
( )
(
)
(
)







∈
∈
−
=
−
−
+
+
'
'
'
'
,'
' exp
'
'
'
'
,'
' exp
'
'
'
1
1
1
Y
si y
Z
k
x
f
k
Y
si y
Z
k
x
f
k
k
k
i
i
t
i
t
t
i
t
k
i
i
t
i
t
t
i
t
ti
α
ν
α
ν
ν
 
 
where 
1i '
Zt
,
t 1i '
Z −
 and 
Z 't
 are defined by : 
( )
'))
,'
(
' exp(
'
'
'
'
:'
1
k
x
f
k
Z
i
t
t
Y
y
k
i
t
i
t
ik
α
ν
−
= ∑
∈ +
 
( )
,' '))
(
' ' exp(
'
'
'
:'
1
l
x
f
l
Z
i
t
t
Y
y
l
i
t
i
t
il
α
ν
∑
−
∈
−
=
 
'
'
'
'
1
1
1
i
t
i
t
n
m
m
i
i
t
t
Z
Z
Z
−
+
+
=∑
=
λ
 
        end 
Output : The final ranking function 
t
T
t
t f
F ∑ =
=
1α
 
In each iteration t, 
t
α  is selected in order to minimize 
the normalization factors
tZ and
tZ '
.  
Our goal in this algorithm is finding a function F, which 
minimizes the average numbers of irrelevant alternatives 
scored better than relevant ones in S and S’ separately. We 
call this quantity the average ranking loss for alternatives, 
(
)'
,
S
Rloss F S
∪
 defined as: 
 
(
)
(
)
(
)
[
]
[
]
(
)
(
)
[
]
[
]
∑
∑
∑
∑ ∑
∑
+
−
+
−
∈
∈
=
∈
∈
=
≤
−
+
≤
−
=
∪
'
:'
'
'
:'
1
:
:
1
'
0
,' '
'
,'
'
'
1
0
,
,
1
1
'
,
Y
k y
Y
l y
i
i
m
i
i
i
Y
k y
Y
l y
i
i
m
i
i
i
k
i
k
i
k
i
k
i
l
f x
k
f x
p
n
n
f x l
f x k
n p
m
S
F S
Rloss
β
 (8) 
 
where pi (resp. ni) is the number of relevant alternatives 
(resp. not relevant) for example xi in S and p’i (resp. n’i) is 
the number of relevant alternatives (resp. not relevant) for 
example x’i  in S’. And the expression [[P]] is defined to be 
1 if predicate P is true and 0 otherwise.    
B. Adaptation of the Algorithm of selection of ranking 
features  
The algorithm of selection of ranking features or 
functions (Algorithm 2) makes it possible to find, with a 
linear complexity in a number of alternatives, a function 
tf  
which minimizes 
tr  in a particular case where the 
function
tf is in {0, 1} and is created by thresholded 
characteristics associated to the examples.   
Let us suppose that each query 
ix  (resp.
'ix ) has a set of 
characteristics provided by functionsϕ j, j = 1... d. For each j, 
ϕ j (
ix , k) (resp.ϕ j(
'ix , k’))  is a real value.  Thus, it is a 
question of using a thresholding of the characteristicϕ j to 
create binary values.  All the basic functions are created by 
defining a priori a set of thresholds { }Q
q q
=1
θ
 with 
.
...
1
θq
θ
>
>
 
Generally, these thresholds depend on the characteristic 
considered. 
 
 
 
 
52
Copyright (c) The Government of Tunisia, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

Algorithm 2.  Algorithm of selection de ranking features 
Entry :  
 ∀ i ∈ {1,…, m}, (k, l) ∈ {1,…,
i
m } such as 
iyk
∈
+
Y and 
l
iy ∈
−
Y  : 
A distribution 
ti
D (k, l) =
tλi
νti (k)
νti (l)
on the training set S. 
 ∀ i ∈ {m+1, .., m+n}, ∀ (k’, l’) ∈  {1, ..., 
m 'i
}2 such as 
iyk '
∈
+'
Y , 
iy 'l
∈
−'
Y  :  
     A distribution 
1'
ti
D +
 (k’, l’) =
'
tλ +1
1'
i
νt+
(k’) 
1'
i
νt+
 (l’) on the 
training subset S’. 
 Set of characteristics
(
)
{
}d
j
i
j
k
x
1
,
=
ϕ
 
 For each
j
ϕ , a set of thresholds { }Q
q q
=1
θ
such as 
θq
θ
1 > ... >
 
Initialisation : 
 ∀ i ∈{1,…, m}, (k, l) ∈ {1,…, mi }, 
     π (
ix , k)=
( )
( )l
k
y
k
i
il
y
l y
i
i
i
ik
∑
≠
:
1
1 1
ν
λ ν
 
 ∀ i∈{m+1,..,m+n}, (k’, l’)∈{1,…,
'i
m },  
      
'
π (
'ix , k’)=
( )
( )'
'
'
'
'
'
:'
1
1
1
'
l
k
y
k
i
il
y
y
l
i
i
i
ik
∑
≠
ν
λ ν
 
  r*←0 
For j :=1,…, d do 
- L← 0 
 For q :=1,…, Q do 
   L← L + 
(
)
(
)
∑
∑
=
m
i
k
x
k
i
i
j
k
x
1
,
:
,
ϕ
π
   
   +    
(
)
(
)
∑
∑
+
+
=
n
m
i m
x k
k
i
j i
k
x
1
'
,'
:'
'
,'
'
ϕ
π
 
 if  |L|>|r*| then 
        r*← L 
 
j*←j 
       
θ *
← 
q
θ  
       k*←k 
  end 
     end 
 end 
Output : (
ϕ j *
,
θ *
, k*) 
IV. 
EXPERIMENTS 
We used the MQ2008-semi (Million Query track) dataset 
in LETOR4.0 (LEarning TO Rank) [1] in our experiments, 
because it contains both labeled and unlabeled data. There 
are about 2000 queries in this dataset. On average, each 
query is associated with about 40 labeled documents and 
about 1000 unlabeled documents. 
MQ2008-semi is conducted on the .GOV2 corpus using 
the TREC 2008, which is crawled from Web sites in the .gov 
domain. There are 25 million documents contained in the 
.GOV2 corpus, including HTML documents, plus the 
extracted text of PDF, Word and postscript files [1]. 
Each subset of the collection MQ2008-semi is 
partitioned into five parts, denoted as S1, S2, S3, S4, and 
S5, in order to conduct five-fold cross validation. The 
results reported in this section are the average results over 
multiple folds. For each fold, three parts are used : one part 
for training, one part for validation, and the remaining one 
for testing. The training set is used to learn the ranking 
model, the validation set is used to tune the parameters of 
the ranking model, such as the number of iterations in 
RankBoost. And the test set is used to report the ranking 
performance of the model. 
In order to compare the performance of the algorithm we 
evaluate our experimental results using a set of standard 
ranking measures such as Mean Average Precision MAP, 
Precision at N, and normalised Discounted Cumulative Gain 
(NDCG). 
 
relevants docs for this query
total
rel n
n
P
MAP
N
n
#
( ))
*
@
∑ =1 (
=
 
(14) 
 
n
#
@
relevantdocsin top n results
n
P
=
 
(15) 
 
∑ =
+
−
=
n
j
j
r
n
j
Z
N n
1
)
(
)
log(1
1
2
( )
 
(16) 
The value of the discount factor, which provided the best 
ranking performance for these training sizes, is β = 1. We 
therefore use this value in our experiments. 
Tables 1 and 2 show the results on testing set generated 
by an assessment tool associated with the benchmark Letor 
[1]. 
TABLE I.  
P@N AND MAP MEASURES ON THE MQ2008-SEMI 
COLLECTION 
Algorithmes 
P@1 
P@3 
P@5 
P@7 
P@10 
MAP 
RankBoost 
0. 457 
0.391 
0.340 
0.302 
0.248 
0.477 
RankSVM 
0.427 
0.390 
0.347 
0.302 
0.249 
0.469 
Algorithme 1 
0.450 
0.393 
0.341 
0.302 
0.252 
0.479 
TABLE II.  
NDCG@N MEASURES ON THE MQ2008-SEMI 
COLLECTION 
Algorithmes 
NDCG@1 
NDCG@3 
NDCG@5 
NDCG@7 
NDCG@10 
RankBoost 
0.463 
0.455 
0.449 
0.412 
0.430 
RankSVM 
0.495 
0.420 
0.416 
0.413 
0.414 
Algorithme 1 
0. 465 
0.453 
0.438 
0.414 
0.434 
 
These results illustrate how the unlabeled data affect the 
performance of ranking in the proposed algorithm. We 
notice a slight improvement in using the criterion P @ n 
(resp. NDCG) for n = 3 and n =10 (resp. for n = 1, n=7 and 
53
Copyright (c) The Government of Tunisia, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

n = 10). The results also show that our proposed algorithm 
has an average precision (MAP) better than that found by 
RankBoost and RankSVM. These results prove the interest 
of integrating unlabeled data in ranking functions with semi-
supervised learning. 
V. 
CONCLUSION 
In this paper, we proposed a semi-supervised learning 
algorithm for learning ranking functions for alternatives. 
This algorithm has the advantages of both transductive and 
inductive approaches, and can be applied in semi-supervised 
and supervised ranking setups. In fact, this algorithm is able 
to infer an ordering on new pairs query-alternative that were 
not used for its training. The advantage of this proposition is 
that it is able to advantageously exploit the unlabeled 
alternatives. We propose in the following to supplement the 
experimental part and to integrate other methods such as 
active learning which select most informative examples for 
ranking learning.   
REFERENCES 
[1] T.-Y. Liu, J. Xu, T. Qin, W.-Y. Xiong, and H. Li, LETOR: 
Benchmark dataset for research on learning to rank for information 
retrieval. SIGIR, 2007. 
[2] J. Xu, and H. Li, AdaRank : a boosting algorithm for information 
retrieval. In Kraaij, W., de Vries, A. P. Clarke, C. L. A. Fuhr, N. 
Kando, N. editors, SIGIR, pp. 391-398. ACM, 2007. 
[3] X. Zhu, Semi-supervised learning literature survey. Technical Report 
1530, Computer Sciences, University of Wisconsin-Madison, 2005. 
[4] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and B. Schölkopf, 
Ranking on data manifolds. NIPS. MIT Press, 2003. 
[5] K. Duh, and K. Kirchhoff, Learning to rank with partially-labeled 
data. In Myaeng, S.-H. Oard, D. W. Sebastiani, F. Chua, T.-S., and 
Leong, M.-K., editors, SIGIR, pp. 251-258. ACM. 2008. 
[6] M.-R Amini, V. Truong, and C. Goutte: A boosting algorithm for 
learning bipartite ranking functions with partially labeled data. SIGIR 
2008: pp. 99-106. 2008. 
[7] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer, “An efficient 
boosting algorithm for combining preferences”. Journal of Machine 
Learning Research, pp. 933-969, 2003. 
[8] F. Xia, T. Liu,  J. Wang, W. Zhang and H. Li, Listwise 
approach to learning to rank: theory and algorithm. In 
ICML ’08, pp. 1192-1199, New York, NY, USA, ACM 2008. 
[9] T. Y. Liu, Learning to Rank for Information Retrieval. Now 
Publishers, 2009. 
[10] S. Agarwal, Transductive Ranking on Graphs, Computer Science and 
Artificial Intelligence Laboratory Technical Report, CSAIL-TR-
2008-051, 2008. 
 
54
Copyright (c) The Government of Tunisia, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

