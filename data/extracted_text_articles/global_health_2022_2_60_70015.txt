3D Flickers for Visually Evoked Potentials-based
Brain Computer Interface Paradigm in Virtual
Reality
Thibault Porssut
Altran Lab
Capgemini Engineering
Paris, France
0000-0002-6691-1427
email: thibault.porssut@capgemini.com
Alix Gouret
Altran Lab
Capgemini Engineering
Paris, France
email: alix.gouret@capgemini.com
Sol`ene LeBars
Altran Lab
Capgemini Engineering
Paris, France
email: solene.lebars@capgemini.com
Abstract—One of the most commonly used non-invasive Brain-
Computer Interface (BCI) paradigms for virtual reality control
relies on particular brain signals: Visually Evoked Potentials
(VEP). However, the optimization of virtual 3D targets is required
in order to conciliate satisfying VEP induction - leading to high
classification accuracy - and visual discomfort minimization. This
constitutes a real challenge that could unlock new possibilities
for rehabilitation, gaming or other applications. In the current
experiment, we designed 30 original 3D-stimuli by combining
particular visual patterns with various 8Hz-movements. The
objectives were (1) to test new associations of stimuli for better
BCI-VR(Brain Computer Interface- Virtual Reality) ergonomics
and (2) to test a new paradigm of VEP-based BCI that dis-
criminates stimuli according to their visual features (e.g., motion
type) without exploiting any variation in flickers’ frequency
(constant frequency = 8Hz). Offline classification abilities were
assessed using an EEGNet deep learning model. The results
suggested the possible role of the stimulation patterns on the
visual fatigue induced. The EEGNet model successfully classified
all the 30 stimuli with a high level of accuracy (97.58%). This
development broadens VEP-BCI stimulation possibilities and
could allow overcoming the problem of epileptogenic frequencies
by exploiting visual properties of targets instead of frequency
variations to discriminate VEP-BCI stimuli.
Index Terms—VEP, SSVEP, BCI, VR, EEGNet, Deep Learning.
I. INTRODUCTION
There is great potential in combining Virtual Reality (VR)
with non-invasive Brain-Computer Interface (BCI) within
gaming and clinical fields. Visual Evoked Potential based BCI
(VEP-based BCI) constitutes one of the most efficient BCI
paradigms for this kind of interaction. VEPs correspond to
brain activations in visual areas, which are often induced by
flickering stimuli / beating effect, and which can be measured
via electroencephalography (EEG). In VEP-based BCIs, sub-
jects must shift their gaze and attention to flickering stimuli.
A strong correlation between the flicker frequency and the
electroencephalogram pattern can then be observed [2]. Two
main types of stimuli are usually used to elicit VEP: frequency
modulated VEP (f-VEP) and pseudorandom code modulated
VEP (c-VEP). In the f-VEP-based BCI paradigm, stimuli flash
at different frequencies and elicit periodic sequences - Steady-
State Visual Evoked Potential (SSVEP) - of evoked responses
with the same spectral characteristics (fundamentals and har-
monics) as those of the stimulus [3]. The main advantages
of this method are the stable characteristics of the signal, the
high information level and accuracy [2], [26], and a good user
experience (control and intuitive) [19], [24].
In the c-VEP-based-BCI, a pseudorandom sequence is re-
peated periodically, modulating the stimulus appearance and
eliciting specific patterns in the electroencephalogram. This
method requires a higher information rate and enables high-
speed BCI [3]. Although VEP-based BCI can be very efficient,
the flickering aspect might cause visual fatigue, and the VEP
features depend on stimulus characteristics, which are limited
by the refreshing rate of the system [2]. Thus, stimuli choice
represents a major limitation of VR-BCI. Visual fatigue here
refers to the state of reduced alertness and the feeling of
tiredness which both impair the willingness and ability to
perform a task [4], [8], resulting from visual stimulations.
In f-VEP-based BCI, different paradigms have been pro-
posed to minimize performance decrease due to repeated
visual stimulation. Those paradigms regard both the stimu-
lation graphics (visual aspect such as shape, color, pattern)
and the periodic motion (frequency, waveform, motion evoked
potentials) [6], [7], [10], [12], [23]. For example, steady-state
motion VEP paradigm has been proposed as an alternative
to that of SSVEP to reduce visual fatigue while ensuring
a comparable level of accuracy [5], [12], [14]. However,
very few studies have compared stimulation modalities and
paradigms in a VR environment yet [7]. Moreover, most did
not take advantage of VR characteristics by displaying 2D
targets on plain walls for instance.
Given the lack of literature on the combination of VR
and BCI, and especially on using 3D objects to elicit visu-
ally evoked potentials, the combinations of VEP stimulation
paradigms were investigated (with both c-VEP stimuli and f-
VEP ones – SSVEP and Steady-State Motion Visual Evoked
Potential (SSMVEP)). These new paradigms might overcome
22
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-995-9
GLOBAL HEALTH 2022 : The Eleventh International Conference on Global Health Challenges

the visual fatigue induced by the beating effect of standard
flickering stimuli while offering high classification perfor-
mance. Thus, first, new 3D ergonomic flickers were proposed.
Then, the 3D flickers were evaluated within a VR environment
through ergonomics ratings and EEG signal quality. Finally,
the last objective was to discriminate flickers based on their
specific visual features and not their frequency, which remains
constant (8Hz).
The rest of the paper is structured as follows. In Section
II, we detail the experiment design and the methods. In the
section III, we present our results. Finally, we conclude the
work in Section IV.
II. MATERIALS AND METHODS
A. Participants
Twenty-four participants consented to take part in the study.
They had normal or corrected vision and were either na¨ıve or
had already experienced standard VEP stimulations (flickering
objects) or VR. Data from twelve participants could not be
included in the study due to technical problems or interruption
of the experiment.
B. Equipment, Software and EEG Pre-processing
Participants were equipped with a Pico Neo 2 Eye, a Head-
Mounted Display (HMD) with 3840x2160 pixels per eye at
75 Hz refresh rate. It has a Field of View (FOV) of 101°
(diagonal) (see Figure 1). The EEG signal was recorded using
an OpenBCI® EEG Electrode Cap kit (21 electrodes). The
EEG data were collected at 250 Hz sampling frequency. Once
acquired, EEG data were low-pass filtered at 40 Hz, high-pass
filtered at 5 Hz and a 50 Hz Notch filter was also applied.
Since the stimuli had to elicit VEP, electrodes located in
the occipital and parietal regions [9], [14], [15] were chosen.
Electrodes ‘Ground’, ’ O1’, ‘O2’, ‘P3’, ‘P4’, ‘CPz’, ‘Cz’, ‘F3’
and ‘F4’ whose locations correspond to the international 10-20
system (Fig. 1) were selected. EEG data were epoched into
3s windows according to the triggers of the onset of visual
stimuli during the experimental task.
Fig. 1. A. Time sequence of the experiment/ B. Time sequence of a trial with
the virtual environment (left to right) and the subject wearing the EEG cap,
the HMD and carrying the controller while executing the task (right).
C. 3D Stimuli Inducing VEP
The visual 3D stimuli were generated using Unity‘s built-in
Shader Graph tool [1]. The design of efficient VEP stimuli was
inspired from the existing literature, and features to decrease
visual fatigue were considered.
The targets consisted of a cuboid that behaved differently
according to the stimulus types. The targets’ positions were
randomly changed so the participants would not lose motiva-
tion. For the duration of the task, targets were equiprobably
located: up-right, bottom-right, bottom-left, and up-left on the
scene. The frequency that modulated the stimuli aspect was
set to 8 Hz to avoid epileptogenic frequencies – which is one
major limitation of VEP-based BCI and limits visual comfort
[6], [10], [15]. The color of the cuboid was set to red as this
color was shown to be less uncomfortable for VEP stimuli
in the low-frequency range [10]. The color amplitude was
reduced to 60% as studies showed that lower contrasts or
stimulation amplitude depth improved flickers ergonomics by
reducing visual fatigue [16]. The virtual environment consisted
of a dark cubic room with a grey grid pattern. The questions
displayed on the wall in front of the participant and the targets
(the cuboids with modulated behavior) appeared in the in-
between space. Before each stimulation, a red cross cued the
localization of the upcoming target (see Figure 1).
The 30 types of stimulations were split into two pattern
categories: full (the whole cuboid was visible – i.e., the entire
cuboid flickered) or fragmented (only 30 circular areas per
face of the cuboid were visible – i.e., only parts of the
cuboid flickered). The standard efficient VEP stimuli types
and the c-VEP stimuli considered were the following: standard
flash flicker (luminance variation of the object from black
to full luminosity according to a sinusoidal modulation) [3],
Newton’s ring inspired flicker (concentric square ring with ex-
panding movement) [25], grow-shrink stimulus [7] (an object
whose size periodically changes from 60% up to 120% of its
original size according to a sinusoidal function), a spinning
motion around the vertical axis (according to a sine function)
[12], [21] and a c-VEP flash flicker whose variation was
controlled by a pseudo-random sequence square signal (further
referred to as m-sequence) [3], [11], [20]. Combinations of
these five basic stimuli defined the other stimulation types:
all possible combinations of two sinusoidal variation-based
stimulation types and the combination of the c-VEP flash with
one sinusoidal-f-VEP stimulus. A video showing all the stimuli
is presented here [22].
D. Experimental Design
Participants were instructed to stare at a target stimulus for 3
s per trial, with an inter-trial interval of 1s. Before each trial, a
cross cue appeared at the location of the next target to indicate
to the participant where to direct their gaze (see Figure 1 B).
Once ready, they had to press the trigger of the right controller
for 1 s. Each stimulus type randomly appeared 15 times; to
assess the usability of each stimulation paradigm, participants
had to answer a question at the end of the stimulation for
20% of the trials for each stimulus – three assessments per
23
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-995-9
GLOBAL HEALTH 2022 : The Eleventh International Conference on Global Health Challenges

type in total randomly distributed across the experiment (see
Figure 1 A). The order of question occurrence was balanced
according to the Latin square so that with 30 participants, we
could reduce the order-effect when rating the fatigue level of
one stimulation. Participants rated the visual fatigue level of
each stimulus using the right controller: the joystick to select
the score and then the trigger for 2 s to confirm their choice.
Participants were instructed not to move or blink during the
visual stimulation. The task had a minimum duration of 38
minutes – with no imposed breaks, and participants could
control the resting time between each trial (trials started only
if the trigger was pressed for 1 s).
E. EEG Data Analysis
Canonical Correlation Analysis (CCA) is often used when
studying VEP-based BCI [18] to perform the automatic clas-
sification of VEP. However, this method is quite sensitive to
inter-subject variability and the quality of the EEG recordings.
Thus, EEGnet proposed by Lawhern et al. [17] to classify EEG
signals has been adapted to classify VEP. Thirty classes corre-
sponding to the thirty stimulation types were considered. Data
were epoched and augmented so that 438 temporal windows
could be given to each class. The EEGNet was trained for
each subject (within-subject). Participants were asked to rate
the fatigue level of each stimulation type three times during
the task to evaluate flickers’ ergonomics. The questionnaire
was inspired by the visual analog scale [13], which is often
used in clinical research to evaluate pain intensity; it is also
used to rate the discomfort or fatigue of tasks. The question
was written in French and could be translated as: ”considering
the visual discomfort and amount of tiredness induced by the
last stimulation, rate its visual fatigue level.” Participants could
rate the stimulation from 1 to 7 (1: not tiring at all, 7: highest
fatigue level) [5], [7].
III. RESULTS
A. Offline Classification
The average offline recognition accuracy of the 30 classes
corresponding to the different stimulation types was close to
ceiling (M=97.58%, SD=.0.0066) across subjects, indicating
that the EEGNet classifier was very effective at classifying
stimuli of the same frequency that only difered via their visual
characteristics (see Figure 2). Hence, the sole modification
of the visual transformation of one target might be sufficient
to modulate the induced EEG response and enable proper
identification of the stimulation type. In addition, the accuracy
results showed a weak inter-subject variability.
B. Stimuli Ergonomics
The analysis is conducted using Python. Since the data
were not normally distributed using the Shapiro-Wilk test,
a two-way repeated-measures Friedman ANOVA was per-
formed to investigate the stimulation type’s main effect on
fatigue level score. The significant level was set to 0.05.
A significant difference in the main effect was observed
(F = 95.31, DL = 10, p < 0.0001). Thus, the type of
Fig. 2.
Classification accuracies of EEGNet model over 30 classes corre-
sponding to the 30 stimulation types for 11 participants. Accuracies ranged
above 97%. Dotted orange line indicates the mean accuracy (M=97.58%,
SD=.0.0066).
stimulation could affect the scoring of its fatigue level, that
is, its ergonomics. Wilcoxon signed-rank test was applied for
each pair of the conditions to investigate the interaction effects
of ergonomics and stimulation type. The False Discovery Rate
(FDR) was corrected for the within-group comparison using
the Benjamini-Hochberg procedure. The difference in the er-
gonomics rating for different stimuli could not be highlighted,
so we could not conclude about the influence of the type
of stimulation on the fatigue score. However, most of the
participants rated the fatigue level of the different stimulus
types in the range of 2.5 – 5 (See Figure 3 A). The combination
of the c-VEP flash with a sine-modulated spinning motion
in a fragmented pattern ( highlighted in red in Figure 3A)
was the only stimulation to have a mean fatigue level higher
than 5. 12 stimuli had a mean average fatigue level per
participant less than 4, i.e., were rated in the comfortable /
no particular fatigue induced range ( highlighted in green in
Figure 3A). The sinusoidal modulation combining Newton’s
square range type and grow-shrink motion ( 28 on Figure 3A)
had the lowest standard deviation, suggesting a good overall
appreciation from participants. Interestingly, the hybrid c-VEP
and f-VEP flash with both full and fragmented patterns were
part of stimuli with an acceptable fatigue level. These results
are consistent with the pattern’s effect when considering the
standard deviation values.
Wilcoxon signed-rank test was used to explore the pos-
sible role of the completeness effect (full vs. fragmented
pattern). The average answers per subject for all stimulation
types of patterns ‘full’ to those of pattern ‘fragmented’ were
significantly different (Z = 1777, p < 0.0001). Thus, the
type of completeness could affect the scoring of the fatigue
level of the stimulation, with full pattern stimuli possibly
being less disturbing or less uncomfortable than fragmented
stimulations (see Figure 3). Indeed, the average fatigue score
in the fragmented condition was higher than that in the full
condition (M=4.58, SD=1.39 vs.M= 3.65, SD=0.98).
IV. CONCLUSION AND FUTURE WORK
In order to find ergonomic visual stimulations to be im-
plemented in a future VEP-based BCI-VR, efficient 2D VEP
stimuli were converted into 3D VEP stimuli within a virtual
environment. The EEGNet model managed to classify the
different stimuli with a high level of accuracy based on their
24
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-995-9
GLOBAL HEALTH 2022 : The Eleventh International Conference on Global Health Challenges

Fig. 3.
A. Average fatigue score per stimulation type, n=11 participants, (
flicker inducing most fatigue highlighted in red and flickers inducing the least
fatigue highlighted in green in A Figure 3) B. Average fatigue score depending
on the pattern, n=11 participants
visual differences, which suggested that the different types of
stimulation did induce VEP with their very own specific EEG
signatures. This pilot study paves the way for immersive BCI-
VR research and applications using 3D targets.
However due to the small number of participants, the EEG-
net classification and ergonomic analyses should be nuanced
but they give a good idea of the trends. More participants
should be included in the study to improve the statistical
power. Moreover, the EEG recording system consisted of a
consumer kit with a sampling frequency of only 250hz. This
could be a limitation for the accuracy of the EEG signals but
as the study was intended to be applied directly to an industrial
project, using the OpenBCI EEG cap kit for such a study was
part of the contributions – as for the VR headset used.
In order to lighten the experimental task, we used a subjec-
tive method for assessing visual fatigue, based on a simple
question [5], [7]. However, more comprehensive question-
naires could improve the accuracy of the ergonomics score in
future works and the analysis of brain rythms could provide
an objective evaluation method of induced fatigue (depending
on the stimuli presentation and their occurence in the task)
while taking advantage of the EEG recording [4].
Finally, the next step will be integrating these ergonomics
flickers into a VR-based BCI application to help future pa-
tients’ rehabilitation. As for existing studies in the literature,
eye movements were not monitored. Using a VR headset
allowing eye tracking could control this parameter and avoid
artifacts in the EEG signal.
REFERENCES
[1] Unity real-time development platform | 3d, 2d VR & AR engine.
[2] R. Abiri, S. Borhani, E. W. Sellers, Y. Jiang, and X. Zhao.
A
comprehensive review of eeg-based brain–computer interface paradigms.
Journal of neural engineering, 16(1):011001, 2019.
[3] G. Bin, X. Gao, Y. Wang, B. Hong, and S. Gao.
Vep-based brain-
computer interfaces: time, frequency, and code modulations [research
frontier]. IEEE Computational Intelligence Magazine, 4(4):22–26, 11
2009.
[4] T. Cao, F. Wan, C. M. Wong, J. N. da Cruz, and Y. Hu.
Objective
evaluation of fatigue by eeg spectral analysis in steady-state visual
evoked potential-based brain-computer interfaces. Biomedical Engineer-
ing Online, 13(1):28, 3 2014. PMID: 24621009 PMCID: PMC3995691.
[5] X. Chai, Z. Zhang, K. Guan, T. Zhang, J. Xu, and H. Niu.
Effects
of fatigue on steady state motion visual evoked potentials: Optimised
stimulus parameters for a zoom motion-based brain-computer interface.
Computer Methods and Programs in Biomedicine, 196:105650, 11 2020.
[6] X. Chen, Y. Wang, S. Zhang, S. Xu, and X. Gao. Effects of stimulation
frequency and stimulation waveform on steady-state visual evoked
potentials using a computer monitor. Journal of Neural Engineering,
16(6):066007, 10 2019. PMID: 31220820.
[7] K.-M. Choi, S. Park, and C.-H. Im. Comparison of visual stimuli for
steady-state visual evoked potential-based brain-computer interfaces in
virtual reality environment in terms of classification accuracy and visual
comfort. Computational Intelligence and Neuroscience, 2019:9680697,
2019. PMID: 31354804 PMCID: PMC6636533.
[8] A. Craig, Y. Tran, N. Wijesuriya, and P. Boord.
A controlled in-
vestigation into the psychological determinants of fatigue. Biological
psychology, 72(1):78–87, 2006.
[9] A. M. Dreyer and C. S. Herrmann. Frequency-modulated steady-state
visual evoked potentials: A new stimulation method for brain–computer
interfaces. Journal of Neuroscience Methods, 241:1–9, 2 2015.
[10] X. Duart, E. Quiles, F. Suay, N. Chio, E. Garc´ıa, and F. Morant.
Evaluating the effect of stimuli color and frequency on ssvep. Sensors
(Basel, Switzerland), 21(1):117, 12 2020. PMID: 33375441 PMCID:
PMC7796402.
[11] S. et al. Introducing chaotic codes for the modulation of code modulated
visual evoked potentials (c-vep) in normal adults for visual fatigue
reduction.
PLoS ONE, 14(3):e0213197, 3 2019.
PMID: 30840671
PMCID: PMC6402685.
[12] W. et al. Steady-state motion visual evoked potential (ssmvep) based on
equal luminance colored enhancement. PLoS ONE, 12(1):e0169642, 1
2017. PMID: 28060906 PMCID: PMC5218567.
[13] M. Hayes. Experimental developement of the graphics rating method.
Physiol Bull, 18:98–99, 1921.
[14] S. P. Heinrich. A primer on motion visual evoked potentials. Documenta
Ophthalmologica. Advances in Ophthalmology, 114(2):83–105, 3 2007.
PMID: 17431818.
[15] C. S. Herrmann. Human eeg responses to 1-100 hz flicker: resonance
phenomena in visual cortex and their potential correlation to cognitive
phenomena. Experimental Brain Research, 137(3-4):346–353, 4 2001.
PMID: 11355381.
[16] S. Ladouce, L. Darmet, J. Torre Tresols, G. Ferraro, and F. Dehais.
Improving user experience of ssvep-bci through reduction of stimuli
amplitude depth. pages 2936–2941, 2022.
[17] V. J. Lawhern, A. J. Solon, N. R. Waytowich, S. M. Gordon, C. P.
Hung, and B. J. Lance. Eegnet: A compact convolutional network for
eeg-based brain-computer interfaces.
Journal of Neural Engineering,
15(5):056013, 10 2018. arXiv:1611.08024 [cs, q-bio, stat].
[18] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo, A. Rako-
tomamonjy, and F. Yger. A review of classification algorithms for eeg-
based brain–computer interfaces: a 10 year update. Journal of Neural
Engineering, 15(3):031005, 4 2018. publisher: IOP Publishing.
[19] P. Martinez, H. Bakardjian, and A. Cichocki. Fully online multicom-
mand brain-computer interface with visual neurofeedback using ssvep
paradigm. Computational intelligence and neuroscience, 2007, 2007.
[20] V. Mart´ınez-Cagigal, J. Thielen, E. Santamar´ıa-V´azquez, S. P´erez-
Velasco, P. Desain, and R. Hornero. Brain–computer interfaces based
on code-modulated visual evoked potentials (c-VEP): a literature review.
Journal of Neural Engineering, 18(6):061002, nov 2021.
[21] M. Rekrut, T. Jungbluth, J. Alexandersson, and A. Kr¨uger. Spinning
icons: Introducing a novel ssvep-bci paradigm based on rotation.
In
26th International Conference on Intelligent User Interfaces, IUI ’21,
page 234–243, New York, NY, USA, 2021. Association for Computing
Machinery.
25
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-995-9
GLOBAL HEALTH 2022 : The Eleventh International Conference on Global Health Challenges

[22] Thibault Porssut. Ergonomic 3d flickers for VEP-based BCI paradigm
to interact in virtual reality using deep learning.
[23] N. R. Waytowich, Y. Yamani, and D. J. Krusienski. Optimization of
checkerboard spatial frequencies for steady-state visual evoked potential
brain-computer interfaces.
IEEE transactions on neural systems and
rehabilitation engineering: a publication of the IEEE Engineering
in Medicine and Biology Society, 25(6):557–565, 6 2017.
PMID:
27542113.
[24] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T. M.
Vaughan.
Brain–computer interfaces for communication and control.
Clinical Neurophysiology, 113(6):767–791, 2002.
[25] J. Xie, G. Xu, J. Wang, F. Zhang, and Y. Zhang.
Steady-state
motion visual evoked potentials produced by oscillating newton’s rings:
implications for brain-computer interfaces. Plos one, 7(6):e39707, 2012.
[26] D. Zhu, J. Bieger, G. Garcia Molina, and R. M. Aarts.
A survey
of stimulation methods used in ssvep-based bcis.
Computational
intelligence and neuroscience, 2010.
26
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-995-9
GLOBAL HEALTH 2022 : The Eleventh International Conference on Global Health Challenges

