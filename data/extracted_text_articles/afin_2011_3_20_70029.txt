Tag Relevancy for Similar Artists
Brandeis Marshall
Computer and Information Technology
Purdue University
401 North Grant Street
West Lafayette, IN 47907
brandeis@purdue.edu
Abstract—In music information retrieval, the rank position in
similar artist lists have gained a lot of attention due to the surge in
online music listening and semi-automated song recommendation
approaches. Artist tags with respect to genre, style and mood
are critical components in assisting these online communities.
In this paper, we examine the relationship between an artist
and associated similar artists by considering an artist’s top tags.
We are seeking to uncover patterns and correlations between
pairwise rank positioning e.g., rank 1-2, rank 2-3, and so forth.
The experiments show positive correlation between rank position
pairs; however, the strength of the correlation is not as high as
expected.
Keywords-music information retrieval, knowledge dissemina-
tion, algorithms, experimentation
I. INTRODUCTION
The music information retrieval ﬁeld has grown signiﬁcantly
in recent years due to online music communities such as
AllMusic, The Echo Nest, Idiomag, Last.fm and Pandora. In
fact, the landscape for ﬁnding new music has been vastly
transformed thanks to the Internet [3] as it has helped new
artists such as Taylor Swift (country) and Sean Kingston
(reggae) ﬁnd new listeners as well. Several online music
communities have user interface limitations and advantages.
For instance, song ‘replay’ and/or previous song option is not
allowed while permitting the use of ‘skip’ and ‘pause’ option
with the advances of data streaming and network bandwidth
capabilities.
Each online music listening website allows music listeners
to create a user account in hopes of tracking music genre
and artist preferences. In most cases, the user chooses a radio
station with a programmed playlist. In contrast, Pandora also
provides an option to construct a customized playlist with
the input of a single music artist to begin the personalized
user station. To assist their user in building a playlist, song
recommendations are made through leveraging similar artists’
ranking. Any form of music recommendation makes use of the
artist proﬁle, including primary genre, style and mood, and the
user proﬁle, including song ratings and song listening history.
Semi-automated song recommendation services are powered
by the quality of similar artist rankings with the expectation
that the most similar artists are ranked highly with respect
to artist characteristics including audio features, genre, style,
mood and music tags. As shown in Figure 1 [9], artist similar-
ity is subjective. Daughtry (Rock), Bob Marley (Reggae) and
Usher (R & B) are music artists from very distinctive genres;
however, the number of similar artists vary and the proximity
of their similar artists to the initial artist (center) differ widely.
In this paper, we consider only music tag relevancy as related
to a set of similar artists. Music tags can represent audio tones,
genre, style and mood attributes unique to each artist. Hence,
we expect that the music tag performance of similar artists
would decrease as the rank positions increase.
Through experimentation, we record three types of per-
formance e.g., precision, reciprocal rank and covariance, to
show the relationship between an artist’s music tags and
corresponding similar artists’ music tags. The precision per-
formance measure records the number of tags overlapping
between an artist and each of its similar artist. Reciprocal
rank performance, on the other hand, computes the strength
of the matching tags as higher rank positions receive greater
weight. We then calculate the covariance between pairwise
rank position e.g., rank 1-2, rank 2-3, and so forth, in order
to investigate the quality of similar artist rankings.
The speciﬁc contributions of this paper are:
• study music tag relevancy in the context of similar artist
rankings,
• perform a quantitative study showing the inﬂuence of
music tags on similar artist rankings using Last.fm music
data including 10 genres and nearly 500 artists
• conduct a performance analysis of tag relevancy consid-
ering precision, reciprocal rank and Spearman’s ρ rank
correlation coefﬁcient.
The rest of the paper is organized as follows. Section
II reviews the relevant literature in music recommendation
research. In Section III, we discuss the popular online music
communities and describe our approach to music tag relevancy
for similar artists. Section iV contains our experimental eval-
uation. We summarize our ﬁndings and discuss future work in
Section V.
II. RELATED WORK
Music recommendation research has three main branches:
(1) content-based through audio processing, (2) pre-deﬁned or
user-generated tagging of artists, albums and/or songs and (3)
mixed music content-based and tagging methods.
a) Content-based approaches: A large section of music
research focuses on content-based methods by processing the
audio ﬁle in order to correctly determine a song’s genre. How-
ever, content-based methods are computationally expensive,
54
AFIN 2011 : The Third International Conference on Advances in Future Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-148-9

2
(a) Daughtry
(b) Bob Marley
(c) Usher
Fig. 1.
Sample Artist Similarity Maps from Music-Map
but has led to improvements in the music genre labeling,
artist style classiﬁcation and identifying song moods. These
improvements have been applied to construct music recom-
mendation systems [2], [11], [18] by using collaborative ﬁlter-
ing methods to provide user-speciﬁc results using information
from many users. Other prior work [2], [18] concentrates on
the users’ playlist through song properties including pitch,
duration and loudness. While users’ playlist are customized,
artist similarity can assist in generating a playlist but has
a wider appeal with greater song and artist diversity. The
primary disadvantages of content-based approaches are the
higher computational cost of pre- and post-processing of sound
recordings and the identiﬁcation of relevant audio features to
assist in distinguishing songs and vocalists.
b) Tagging approaches: In recommending music using
text, tags associated with artists and/or songs are typically
classiﬁed into either pre-deﬁned expert opinion or community-
based labeling categories. Assessing the quality of artist tag-
ging and similarity for determining appropriate ground truth
remains a challenging problem due to the current state of ill-
formed music tag semantics [4].
Regardless, tagging offers the average user and experts an
opportunity to catalog music in a detail unachievable with au-
dio features. Bischoff et al. [1] emphasize that music listeners
tend to label music and artist according to genre style and
enjoy providing personalized opinions of the music. In Shao et
al. [17], style and mood tags produced nearly identical results
using a content-based approach comparing 12 artists. Magno
and Sable [13] show the similarity of human recommendation
with automate music recommendation services provided by
Last.fm and Pandora. Nevertheless, the results also note the
limitations of human recommendation as some dependencies
are not captured for an individuals musical taste.
c) Mixed method approaches: Combining sound record-
ing and tag content has become a popular method through
the explosion of digital songs/albums e.g., Apple’s iTunes and
Google’s YouTube. One goal of 21st century music research is
building personal music information retrieval systems. Mixed
method approaches tend to focus on either establishing cus-
tomized artist similarity ( [12], [19]) or song recommendation
( [15], [16]). Through clustering, Li et al. [12] propose
bimodal learning technique to semi-automate the process of
grouping similar artists based on songs, albums and artists
using the AllMusic repository as ground truth. Based on
the MapReduce framework, Zhao et al. [19] consider tag
semantic similarity in hopes of minimizing semantic loss and
tag noise, while ensuring attribute diversity. The research
reveals the scarcity of style and mood tags, but the need
to give this content more importance when available. Both
MusicWiz [15] and MusicBox [16] proposes specialized music
management systems. MusicWiz is individual user-focused
as to personalize song playlists according to an individual’s
feelings and memories while MusicBox is community-focused
with the goal of exploiting correlation between users, tags and
music content.
III. MUSIC TAGGING
Mainstream music listening is no longer primarily on the
radio and playing CDs, but has become to mainly digital
activity. On the Web, online music communities have been
designed as a digital repository of artists, albums, songs,
artist similarity and music inﬂuences & followers. In III-A,
we discuss beneﬁts and limitations of ﬁve popular music
communities. Then in III-B, we describe speciﬁc challenges
of music and artist tagging. We also discuss an approach to
evaluate relevancy of tags for Last.fm.
A. Online Music Communities
1) AllMusic. [6] Originally All Music Guide or AMG,
AllGuide offers consumers access to artist/group infor-
mation containing biography, discography, songs, credits
and charts & awards. The AllMusic database also in-
cludes descriptive content (genres, styles, tones, moods,
themes and nationalities) and relational content (similar
artists, inﬂuences and followers). The genres, styles and
moods content are assigned to each artist from a pre-
deﬁned expert- approved list.
2) The Echo Nest. [5] Due to intellectual property rights,
Echo Nest has not unveiled their process of relating
artists. Nevertheless, the company has revealed that artist
information is generated in a number of ways such as
the analyzation of the raw music, blogs, song lyrics
55
AFIN 2011 : The Third International Conference on Advances in Future Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-148-9

3
and message board postings. While the exact method
in rating artist similarity is unknown, test queries have
shown that their artist database is multi-faceted with
many musicians and genres.
3) Idiomag. [7] Idiomag uniquely labels, or tags, a given
artist by weighted genre names from a preset list of 144
acceptable genre names maintained by the company’s
staff. Then a manual weight is applied to each of the
tags by Idiomag’s expert musicians/music lovers. Lastly,
the artists are ordered according to their labels’ values.
4) Last.fm. [8] Last.fm is highly user-centric by allowing
any user to create self-deﬁned tags. In contrast to
Idiomag, Last.fm supports user-tagging which has led
to a number of issues, including duplicate tags due to
grammatical errors and maliciously false tags applied
to artists. Last.fm combats this challenge by counting
multiple occurrences of a single tag for a single artist as
a vote for that artists tag. A tag’s votes are reﬂected
in how each tag is weighted. To determine musical
similarity for an artist, Last.fm compares the tags of all
artists in their database to the target artist.
5) Pandora Radio. [10] Originally the Music Genome
Project (2000-2008), Pandora Radio is an automated
customizable music recommendation service available
only in the United States. The music recommendations
are made based on nearly 400 attributes to describe
songs using a U.S.-patented mathematical algorithm.
At the core, the 5 music genomes are Pop/Rock, Hip-
Hop/Electronica, Jazz, World Music and Classical. Artist
and song labels are embedded within Pandora Radio and
only partially accessible through the “Why this song?”
choice in the Menu tab.
The Echo Nest, Idiomag and Last.fm offer well-developed
Web APIs which allows anyone to develop specialized pro-
grams using their music data. Marshall [14] aggregates the
artist tags from these three Web APIs in order to extract
better and more consistent similar artists. However, Echo Nest,
Idiomag and Last.fm return relatively diverse similar artists
lists with a majority of agreement occurring within the top-3
similar artist list. Hence, artist similarity aggregation broadens
the identiﬁcation of similar artists; however, these online music
communities do not have a consensus on artist similarity given
a particular artist. We now examine the quality of these artist
similarity rankings.
B. Tag Relevancy of Similar Artists
Much of the previous work [1], [4], [13], [16], [17], [19]
used Last.fm music data since Last.fm remains an open-source
environment since its creation. As a result, we use Last.fm
music data as our experimental research platform.
Based on the artists presented in Figure 1, we display the
top-10 tags and score values in Table I. We notice that all
tags in rank position 1 have a score value of 100 indicating
a universally recognizable tag associated with the artist. In
addition, the tags at rank position 1 represent the primary
artist genre. From rank position 2 downward, the score values
decrease signiﬁcantly with ties allowed where the tags are
mainly genre subcategories and includes the artist’s name.
Daughtry
Bob Marley
Usher
rock (100)
reggae (100)
rnb (100)
alternative rock (80)
roots reggae (25)
Hip-Hop (52)
alternative (47)
Bob Marley (18)
soul (38)
hard rock(34)
ska (15)
pop (38)
American Idol (22)
rock (9)
rap (26)
post-grunge (13)
jamaican (4)
Usher (20)
daughtry (9)
classic rock (3)
hip hop (11)
male vocalists (7)
chill (3)
male vocalists (8)
pop rock (7)
singer-songwriter (3)
r & b (7)
american(5)
roots(2)
r and b (6)
TABLE I
LAST.FM TOP TAGS WITH FREQUENCY COUNTS
With Last.fm music data, we observe some inherent tag
semantic overlap, such as rock, alternative rock, alternative,
that makes assessing the quality of the similar artists’ tags
more difﬁcult. For instance, depending on the matched tags
between two artist, a distinctive similarity relationship may
exist. In the TRAS function below, we follow a template in
evaluating the quality of tags with respect to the similar artist
list returned from the Last.fm GETTOPTAGS method. A string
IA denotes the initial artist, a string array similars holds n
similar artists of IA and retrieving the top-k tags serve as input
and returns an array of performance analysis calculations for
each (IA, SAi) pair.
1: function TRAS(initial:IA,similars:{SA1, . . . , SAn},
count:k)
2: resultArray=empty //holds the result of performance
measure
3: IAtags = LASTFM.GETTOPTAGS(initial,k)
4: for i = SA1 to SAn do
5:
SAtags = LASTFM.GETTOPTAGS(i, k)
6:
//MEASURE(·, ·) is a place holder for a performance
measure e.g., precision, reciprocal rank, covariance
7:
result = MEASURE(IAtags, SAtags)
8:
resultArray.append(result)
9: return resultArray
IV. EXPERIMENTAL STUDY
To test the degree of similarity amongst music artists, we
ran nearly 500 artist queries over 10 popular music genres.
We manually selected the query artists as to guarantee the
return of at least 10 similar artists from Last.FM. We present
a sample of the artists queried in Table II.
For each artist query, we ﬁrst gather the top 10 similar
artists. Then, we extract the top 10 popular tags associated with
each artist query, we denote as initial artist (IA) and its similar
artists, we denote as SA. We chose the ﬁrst 10 tags because
the score values associated with these rank positions are
consistently above 0. We examine the tag match performance
between IA and each of its SA using two measures. The ﬁrst
error measure, precision P, is calculated by taking the two
tag lists mIA, mSA and ﬁnding the number of common tags
in relation to the number of returned elements k. We chose
k = 10. Formally, precision is deﬁned as follows
Pk(mIA, mSA) = mIA ∩ mSA
k
56
AFIN 2011 : The Third International Conference on Advances in Future Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-148-9

4
Alternative
50
Disturbed, Korn, Muse, Nickelback, Papa Roach, The Fray
Blues/Jazz
48
B.B. King, Nina Simone, Otis Redding, Ray Charles, Stevie Wonder,
Doris Day
Country
50
Garth Brooks, Faith Hill, Toby Keith, Vince Gill, Willie Nelson
Electronic
48
Air, Daft Punk, Depeche Mode, Massive Attack, Zero 7
Funk
49
Culture Club, Funkadelic, Musiq, Parliament, Sade
Hip-Hop
48
Janet Jackson, John Legend, TLC, Monica, Black Eyed Peas
Pop
50
Blackstreet Boys, Britney Spears, Coldplay, Justin Timberlake, Lady
Gaga
Rap
50
Dr. Dre, Eminem, Lil’ Wayne, Run DMC, Snoop Dogg, Young Jeezy
Reggae
45
Bob Marley, Black Uhuru, Matisyahu, Shaggy, Toots & The Maytals
Rock
49
Creed, Finger Eleven, Hinder, Rob Thomas, Train
TABLE II
SAMPLE ARTISTS
Precision is a commonly used measure to distinguish between
relevance and non-relevance. However, precision does not
indicate the degree of relevance, e.g., the rank position of
relevant data. To assess relevancy based on rank position, we
use the reciprocal rank measure. Formally, reciprocal rank is
deﬁned as follows
RRk(mIA, mSA) =
X
l=1,...,k
1
l
if mIA(l) = mSA(q)
where l, q (l = q or l ̸= q) refer to a position in a ranking. In
the case when precision is 100% and thus, the reciprocal rank
value is 2.93 ( = Pk=10
l=1
1/l).
Genre
P10(min, max)
RR10(min, max)
Alternative
(33.20%, 73.8%)
(1.35, 2.51)
Blues/Jazz
(23.92%, 75.29%)
(1.06, 2.54)
Country
(8.00%, 54.00%)
(0.41, 1.93)
Electronic
(25.91%, 75.51%)
(1.08, 2.45)
Funk
(17.21%, 67.60%)
(0.73, 2.37)
Hip-Hop
(2.29%, 66.04%)
(0.08, 2.35)
Pop
(33.40%, 72.00%)
(1.39, 2.48)
Rap
(25.40%, 70.80%)
(1.15, 2.43)
Reggae
(20.21%, 62.82%)
(0.93, 2.26)
Rock
(38.20%, 79.20%)
(1.51, 2.67)
TABLE III
PRECISION AND RECIPROCAL RANK AVERAGE INTERVALS
In our ﬁrst set of experiments, we observe the interval range
of both precision and reciprocal rank for each music genre as
shown in Table III. We record the minimum and maximum
value observed for each IA and its 10 SA e.g., for alternative
music, we record 50 minimum and 50 maximum precision val-
ues (as well as 50 minimum and 50 maximum reciprocal rank
values). The observed precision values ranges from the lowest
maximum of 54% for Country music to the highest maximum
of 79% for Rock music. The reciprocal rank values mirrored
those observed in the precision calculations. The reciprocal
rank, however, assist in determining the rank positions of the
matching tags. Hence, for Country music, the minimum 8%
precision is seen on average 1 out of the 10 rank positions at
position 2 (RR(·, ·) = 1
2) or position 3 (RR(·, ·) = 1
3) in order
to compute a minimum reciprocal rank of 0.41. To achieve the
maximum precision and reciprocal rank in Country music, 5 or
6 rank position has matching tags giving the average maximum
precision of 54% and the matching rank position are either {1,
3, 4, 5, 6} (RR(·, ·) = 1
1 + 1
3 + 1
4 + 1
5 + 1
6 = 1.95) or {1, 4,
5, 6, 7, 8} (RR(·, ·) = 1
1 + 1
4 + 1
5 + 1
6 + 1
7 + 1
8 = 1.88).
We
further
investigate
the
relationship
between
rank
positions with respect to the precision and reciprocal rank
values in our second and third experiments. We consider
the change in performance values between consecutive rank
positions e.g., Rank 1 to Rank 2, Rank 2 to Rank 3, and so
forth. We expect that the performance between consecutive
rank positions would be increasingly negative. In other words,
when compared to the initial artist IA, the tag similarity of
a similar artist SA at rank 1 (SA1) is greater than the tag
similarity of a similar artist at rank 2 (SA2). In addition,
we assume that as SAw in which w → 10, the difference
between rank w and w + 1 increases. Last.fm returns a
“count” value for each tag indicating the popularity of the tag
with the corresponding artist. These counts are consistently
and quickly decreasing in value.
Rank
Position
Sum
Difference. For each consecutive
pair of rank positions, we compute the average precision
sum difference for each genre. The results are displayed in
Table IV. We anticipate that the precision at rank position 1
would be higher than precision at rank position 2, precision
at rank position 2 would be higher than precision at rank
position 3 and so forth. However, our observations did not
lead to this conclusion. Instead, we notice a low and mainly
positive precision difference between consecutive pairs of
rank positions. The highest precision value difference is -0.34
(or increase of 34% in the Hip-Hop genre from Rank 1 to
Rank 2). The majority of the precision value difference is ≤
+/- 0.050 (or increase/drop of precision by less than 5%).
In fact, no genre tested is consistently negative or positive
in terms of their consecutive rank positions. This oscillating
precision performance implies that the similarity ordering of
artists is not primarily based on tag label.
Through precision performance, we can only assess how
many tags consistently matched. We have no information
about which rank position the artists appeared in the ranking.
The reciprocal rank performance provides this evaluation. In
Table V, we compute the average sum difference for each
genre and rank position pair. Each cell value records the
magnitude change between rank positions. A majority of the
change is in a [-0.100,0.100] interval or within one position
57
AFIN 2011 : The Third International Conference on Advances in Future Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-148-9

5
Genre
Rank 1-2
Rank 2-3
Rank 3-4
Rank 4-5
Rank 5-6
Rank 6-7
Rank 7-8
Rank 8-9
Rank 9-10
Alternative
-0.006
0.044
-0.010
0.050
-0.056
-0.002
0.034
-0.064
0.054
Blues/Jazz
0.082
0.002
0.037
-0.012
0.006
-0.012
0.047
-0.027
0.031
Country
-0.034
0.028
-0.036
0.028
-0.064
0.076
0.012
-0.050
0.012
Electronic
0.016
0.027
-0.012
0.041
-0.006
0.031
-0.018
-0.039
0.076
Funk
0.078
-0.066
0.048
-0.030
0.028
0.016
-0.018
-0.014
0.018
Hip-Hop
-0.340
-0.112
-0.021
0.060
-0.019
-0.010
0.033
-0.029
-0.025
Pop
0.044
-0.036
0.032
-0.034
0.030
0.010
0.016
0.058
-0.042
Rap
-0.082
0.044
0.016
0.018
0.012
-0.036
0.006
0.032
-0.028
Reggae
0.004
0.054
-0.002
0.009
0.004
0.020
0.043
-0.061
0.011
Rock
0.020
0.004
0.002
0.022
-0.004
0.034
0.006
-0.004
-0.016
TABLE IV
PRECISION SUM DIFFERENCE: RAW VALUES (MULTIPLY BY 100 FOR PERCENTILE)
Genre
Rank 1-2
Rank 2-3
Rank 3-4
Rank 4-5
Rank 5-6
Rank 6-7
Rank 7-8
Rank 8-9
Rank 9-10
Alternative
-0.076
0.154
-0.078
0.151
-0.142
0.009
0.146
-0.210
0.116
Blues/Jazz
0.186
-0.016
0.060
0.034
-0.042
0.029
0.101
-0.100
0.103
Country
-0.130
0.053
-0.102
0.111
-0.230
0.208
0.024
-0.108
0.166
Electronic
-0.017
0.130
-0.078
0.090
-0.052
0.112
-0.004
-0.155
0.265
Funk
0.224
-0.189
0.150
-0.085
0.097
0.032
-0.107
0.099
-0.030
Hip-Hop
-1.419
-0.371
-0.037
0.165
-0.115
-0.043
0.097
-0.088
-0.077
Pop
0.053
-0.148
0.139
-0.088
0.074
0.001
0.011
0.189
-0.059
Rap
-0.317
0.101
0.048
0.100
-0.038
-0.121
-0.005
0.085
-0.007
Reggae
0.052
0.169
-0.033
0.042
-0.103
0.117
0.209
-0.265
0.036
Rock
0.071
0.023
0.003
0.041
0.028
0.074
0.030
-0.015
-0.114
TABLE V
RECIPROCAL RANK SUM DIFFERENCE: RAW VALUES (DIVIDE BY 2.93 FOR NORMALIZATION)
Genre
Rank 1-2
Rank 2-3
Rank 3-4
Rank 4-5
Rank 5-6
Rank 6-7
Rank 7-8
Rank 8-9
Rank 9-10
Alternative
0.544
0.651
0.668
0.640
0.627
0.617
0.588
0.578
0.574
Blues/Jazz
0.333
0.376
0.404
0.448
0.452
0.475
0.459
0.465
0.438
Country
0.083
0.165
0.276
0.310
0.309
0.330
0.329
0.325
0.352
Electronic
0.699
0.627
0.633
0.638
0.608
0.598
0.569
0.559
0.539
Funk
0.358
0.397
0.380
0.347
0.358
0.377
0.382
0.387
0.377
Hip-Hop
-0.010
0.017
0.127
0.216
0.181
0.211
0.235
0.236
0.257
Pop
0.551
0.470
0.515
0.530
0.555
0.553
0.554
0.557
0.578
Rap
0.260
0.426
0.461
0.518
0.521
0.512
0.530
0.537
0.542
Reggae
0.565
0.648
0.581
0.530
0.528
0.543
0.545
0.544
0.547
Rock
0.512
0.495
0.375
0.361
0.359
0.364
0.383
0.401
0.411
TABLE VI
SPEARMAN’S ρ EVALUATION OF PRECISION VALUES
Genre
Rank 1-2
Rank 2-3
Rank 3-4
Rank 4-5
Rank 5-6
Rank 6-7
Rank 7-8
Rank 8-9
Rank 9-10
Alternative
0.592
0.669
0.688
0.638
0.611
0.602
0.594
0.579
0.577
Blues/Jazz
0.470
0.490
0.483
0.530
0.520
0.524
0.495
0.499
0.483
Country
0.254
0.371
0.436
0.470
0.486
0.493
0.500
0.488
0.484
Electronic
0.831
0.714
0.686
0.666
0.636
0.623
0.594
0.593
0.570
Funk
0.326
0.381
0.390
0.354
0.375
0.386
0.402
0.397
0.393
Hip-Hop
0.016
0.041
0.145
0.218
0.210
0.240
0.259
0.270
0.290
Pop
0.544
0.506
0.553
0.544
0.564
0.576
0.569
0.587
0.607
Rap
0.345
0.509
0.545
0.603
0.595
0.593
0.620
0.629
0.625
Reggae
0.571
0.663
0.621
0.551
0.546
0.568
0.564
0.553
0.555
Rock
0.468
0.364
0.246
0.228
0.259
0.291
0.313
0.330
0.344
TABLE VII
SPEARMAN’S ρ EVALUATION OF RECIPROCAL RANK VALUES
58
AFIN 2011 : The Third International Conference on Advances in Future Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-148-9

6
at rank 10. Hence, we conclude that, on average, the matched
tags differ by one or two rank positions in the higher ranks
e.g., rank 8, rank 9 or rank 10. The anomaly is the Hip-Hop
genre at rank 1-2 with a value of -1.419, which implies rank
1 has low matching tags to a much higher matching tags at
rank 2.
Spearman’s ρ Evaluation. However, precision nor reciprocal
rank measure the covariance of two variables or two rank
positions in our case e.g., rank 1-2, rank 2-3, etc. To
assess the covariance between rank positions, we use the
Spearman’s
rank
correlation
coefﬁcient
(Spearman’s
ρ).
Formally, Spearman’s ρ is deﬁned as follows
rhok(rpX, rpY )
=
cov(X, Y )
σXσY
(1)
=
P (X − ¯X)(Y − ¯Y )
pP (X − ¯X)2pP (Y − ¯Y )2
Spearman’s ρ values have a [-1,1] interval in which -
1 denotes that the two variables are negatively correlated,
1 denotes that the two variables are positively correlated
and 0 denotes no correlation between these two variables.
We calculate the covariance between rank positions for both
the precision and reciprocal rank performance, which are
displayed in Tables VI and VII. The Electronic genre is the
most positively correlated while Hip-Hop genre is the least
correlated. The Spearman’s ρ evaluation of the reciprocal rank
values are only slightly different from the equivalent precision
values in Table VI. We conclude that there is moderate correla-
tion between consecutive rank positions for both performance
measures. The oscillating nature between rank positions for
each genre observed in Tables IV and V is observed once
again as the positive correlation slightly ﬂuctuates.
V. CONCLUSION
Music listening has become a mainly digital activity with
online music communities such as Pandora and Last.fm.
Music listening has become a science with relevant song
recommendation methods at its core. Song recommendations
are guided by appropriate artist similarity rankings. Using
the frequently-used Last.fm music data across 10 genres, we
investigate the relevancy of music tags with respect to the
similar artists’ ranking by looking at pairwise rank positions.
We expected to discover a strong relationship between an
artist and its corresponding similar artists. With precision,
we explore how many tags consistently matched while with
reciprocal rank, we evaluate the rank position of matching tags.
In both performance analysis measures, we did not observe any
logarithmic, polynomial, power or exponential trendlines. We
also perform a Spearman’s ρ evaluation across genre and rank
positions. We found a moderately positive correlation between
pairwise rank positions.
In the future, we plan to examine how to better randomize
music song recommendation by mixing highly and moder-
ately similar artists. To this end, we will consider a two-
prong approach: 1) artist tag classiﬁcations and 2) artist song
collaborations. We will investigate the inﬂuence of artist song
collaborations on artist similarity. These song collaborations
can increase the interestingness of the song by highlighting
the unique sound of each artist. The tends in popular song
collaborations based on determining genre, style and mood
correlation of each artist.
REFERENCES
[1] K. Bischoff, C. Firan, W. Nejdl, and T. Paiu. Can all tags be used for
search. In Proceedings of ACM CIKM, pages 203–212, 2008.
[2] H.-C. Chen and A. L. P. Chen. A music recommendation system based
on music data grouping and user interests.
In Proceedings of ACM
CIKM, pages 231–238, 2001.
[3] S. Cunningham, D. Bainbridge, and D. McKay. Finding new music: a
diary study of everyday encounters with novel songs. In International
Conference on Music Information Retrieval (ISMIR), pages 83–88, 2007.
[4] G. Geleijnse, M. Schedl, and P. Knees. The quest for ground truth in
musical artist tagging in the social web era. In International Conference
on Music Information Retrieval (ISMIR), pages 525–530, 2007.
[5] http://developer.echonest.com/. Echo nest : The musical brain, 2005.
[6] http://www.allmusic.com/. All music guide, 1991.
[7] http://www.idiomag.com/api/. Idiomag, 2006.
[8] http://www.lastfm.com/api/. Last.fm, 2002.
[9] http://www.music map.com/. Musician map, 2002.
[10] http://www.pandora.com/. Pandora radio, 2007.
[11] I. Im and A. Hars. Does a one-size recommendation system ﬁt all? the
effectiveness of collaborative ﬁltering based recommendation systems
across different domains and search modes.
ACM Transactions on
Information Systems, 26(1), 2007.
[12] T. Li, M. Ogihara, W. Peng, B. Shao, and S. Zhu. Music clustering
with features from different information sources. IEEE Transactions on
Multimedia, 11(3):477–485, 2009.
[13] T. Magno and C. Sable. A comparison of signal-based music recom-
mendation to genre labels, collaborative ﬁltering, musicological analysis,
human recommendation, and random baseline. In International Confer-
ence on Music Information Retrieval (ISMIR), pages 161–166, 2008.
[14] B. Marshall.
Recent Trends in Information Reuse and Integration,
chapter Music Artist Similarity Aggregation. Springer-Verlag, 2011.
[15] K. Meintanis and F. M. Shipman.
Visual expression for organizing
and accessing music collections in musicwiz.
In Proceedings of the
European Conference on Research and Advanced Technology for Digital
Libraries, pages 80–91, 2010.
[16] A. Nanopoulos, D. Rafailidis, P. Symeonidis, and Y. Manolopoulos.
Musicbox: Personalized music recommendation based on cubic analysis
of social tags.
IEEE Transactions on Audio, Speech and Language
Processing, 18(2):407–412, 2010.
[17] B. Shao, T. Li, and M. Ogihara. Quantity music artist similarity based
on style and mood. In Proceedings of the ACM International Workshop
on Web Information and Data Management, pages 119–124, 2008.
[18] M. Slaney and W. White. Measuring playlist diversity for recommen-
dation systems. In Proceedings of the ACM Workshop on Audio and
Music Computing Multimedia, pages 77–82, 2006.
[19] Z. Zhao, X. Wang, Q. Xiang, A. M. Sarroff, Z. Li, and Y. Wang. Large-
scale music tag recommendation with explicit multiple attributes.
In
Proceedings of the International Conference on Multimedia, pages 401–
410, 2010.
59
AFIN 2011 : The Third International Conference on Advances in Future Internet
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-148-9

