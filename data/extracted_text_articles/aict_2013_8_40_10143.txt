Modelling Mobility-Aware Applications for Internet-based Systems
Bruno Yuji Lino Kimura
Instituto de Matem´atica e Computac¸˜ao - IMC
Universidade Federal de Itajub´a - UNIFEI
Itajub´a - MG, Brasil
Email: kimura@unifei.edu.br
Edson dos Santos Moreira
Instituto de Ciˆencias Matem´aticas e de Computac¸˜ao - ICMC
Universidade S˜ao Paulo - USP
S˜ao Carlos - SP, Brasil
Email: edson@icmc.usp.br
Abstract—Future network architectures, such as Next Gener-
ation Network (NGN) and Vehicular Communication Network
(VCN), will provide large scale mobile Internet access sup-
ported with multiple and small cells of wireless communication.
Therefore, the access to the Internet services are prone to
very frequent disconnections when the mobile node migrates
across the cells. This paper deals with this concern and
discusses issues involved on the modelling of mobility-aware
applications. An abstract model is described by means of
two Finite State Machines (FSM) designed for both mobile
nodes, client and server. The FSMs are meant to networked
applications to preserve their integrity in the event of frequent
connection disruptions in Single Jumps (client side mobility)
and Double Jumps (both client and server sides mobility). The
FSMs for mobility-aware applications were evaluated using a
handover delay mathematical model. With handover latencies
from 230 ms in single jumps and from 450 ms in double
jumps, simulation results show that the proposed strategies are
capable of providing automatic Transmission Control Protocol
(TCP) connection re-establishment with smooth impact when
increasing the frame error rate and the data lost in handovers.
Keywords-Mobility-Awareness; Application Layer Mobility;
Internet-based systems; IP Mobility Management.
I. INTRODUCTION
The paradigm of Mobile Computing is already part of
our modern lifestyle. However, new challenges are arising
with future wireless networks. While NGNs consider nu-
merous heterogeneous wireless networks with small cells
to increase scalability, mobile nodes are becoming devices
of higher mobility. Recently, Internet-based applications for
safety and infotainment have been designed to be deployed
in vehicles. These applications suffer frequent connection
disruptions while the node migrates quickly among the
road-side wireless
Internet Protocol (IP) networks. These
scenarios demand research efforts to enable efﬁcient support
for IP mobility in the TCP/IP protocol stack.
Given the common absence of network support for mo-
bility, several solutions have been proposed to work at the
various layers of the TCP/IP protocol stack. Mobile IP
[1][2] is the general IP mobility solution in the literature.
It is designed to work at the Network Layer to provide the
special handling required in the addressing and forwarding
conﬁgurations when a node is moved. Applications running
on the mobile node do not need to deal with mobility. Such
transparency is an important requirement for IP Mobility
Management.
Considering upper layers (Transport and Application) and
lower layers (Link and Network) to classify mobility pro-
tocols, the choice of the layer where the mobility handling
should be implemented implies on where to put the inherent
overhead:
i. For the sake of transparency, mobility can be handled
by the lower layers to reduce the impact on the upper
layers. This is achieved with additional infrastructures
for managing location of mobile nodes and agents to
forward incoming packets to the current location of the
nodes [1][2]. However, speciﬁc infrastructure increases
the cost of deployment and maintenance of the mobility
solution. In addition, agents imply modiﬁcations in the
core of IP networks.
ii. Handling mobility at upper layers, then the mobile
node takes control of its own mobility. At the appli-
cation level, host mobility implies the complete re-
establishment of broken connections, peer authentica-
tion, and recovering data at the Socket buffers lost with
disruptions [3][4]. The cost of deployment is reduced,
since the handling is conducted end-to-end, therefore,
there is no need for agents. On the other hand, it
increases the overhead at the upper layer with the burden
of the mobility.
In this sense, including mobility support in the TCP/IP
stack is a dilemma. However, upper layer based solutions
are less costly [5]: the support is provided without requiring
a node to be attached to a Home Network, then there is no
need for additional infrastructure; solutions are implemented
as software components, so that their deployment and main-
tenance are easier; route optimization is inherent, since there
is no entity to intermediate communicating along the end-to-
end path; the mean-time-to-recovery ( i.e., handover latency)
takes no longer than a second [3], therefore, performance is
also an advantage. Due to these reasons, several mobility
protocols [3][4][6]–[10] are in favour of handling mobility
at the upper layers.
There is a promising trend of designing communication
184
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

solutions to work at the Application Layer. With recent Web
technologies, e.g., HTML5, in support for new paradigms,
such as Cloud Computing and Internet of Things, the
Web browsers became a generalized interface to access
distributed resources on the Internet. In the meantime, efforts
on Software-Deﬁned Networking (SDN) have been made
toward IP programmable networks by separating and imple-
menting the trafﬁc control as software service.
We advocate this trend
and, in this paper, we discuss
an abstract model for handling mobility at the Application
Layer. Two Finite State Machines (FSM) are exploited to
deﬁne distributed systems aware of communication events
caused by the host mobility on the Internet. We aim to
provide a general purpose mobility solution that can be
implemented as a software service according to the computer
architecture and language of choice of developers. We evalu-
ated the performance of mobility-aware applications accord-
ing to the handover delay model discussed in [11] and [12].
Simulation results show good performance when degrading
parameters of quality of handovers, such as frame error rate
and retransmission of data lost in mobility. Handover delays
take no longer than 793 ms for the worst case.
This paper is organized as follows: in the next section ,
we describe the mobility-aware application model; Section
III describes the handover delay mathematical model used to
evaluate performance of the proposed mobility-aware appli-
cations; Section IV discuss results obtained from simulations
using the handover delay model; and the last section brings
our conclusions.
II. MOBILITY-AWARE APPLICATION MODEL
We assume that the host mobility causes a failure F that
breaks the TCP connections of a networked application.
Failure F lasts a disconnection time, which is the handover
latency Thandover, until the mobile node acquires
Layer
2 and Layer 3 access at the visited network and the mo-
bility protocol resumes ongoing communications. To pro-
vide seamless mobility the disconnection latency Thandover
should be as short as possible, which is a big challenge on
Mobile Computing under research efforts in the last decade.
F is denoted by one of the following events:
F = {F:TO, F:RST, F:DU, F:BC},
(1)
where they represent connection timeout, connection reset,
destination unreachable, and broken connection, respec-
tively. These events lead the system to unexpected states and,
without the proper handling, they make the system crash.
We propose a repair plan at the application runtime to
handle F events by means of two Finite State Machines,
shown in Figure 1, regarding mobile clients connected to
mobile servers. They identify unexpected states as erroneous
states (grey circles). When reaching erroneous states, the
system is able to lead to a safe state again (white circles)
with transition operations based on the semantic of the
Socket API, so that the communication is resumed consis-
tently without losses. This system property provides mobility
awareness to networked applications.
Next, we discuss fundamental aspects for handling mo-
bility with the proposed model.
A. Session establishment
We assume that the mobile nodes are uniquely identiﬁed
by an identiﬁer decoupled from the IP address, as in [10]. IP
addresses become locators that indicate the current logical
location of the mobile nodes. When the (re)connection is es-
tablished, we suggest a handshake for the nodes exchanging
their local control information (c.info and s.info), as
shown in the transitions c3, c4, c5 and s4, s5, s6. The control
information represent a set of communication parameters
that includes: host identiﬁer, transmission checkpoints, and
control ﬂags that indicate the role (mobile or stationary node
and client or server application) each communicating side
plays in a session.
To generate a host identiﬁer, we suggest the use of the
SHA-1 algorithm to digest unique RSA Public Keys. The
hash SHA-1 allows a low probability of bit collision as
well as a huge name space of 2160 bits in length. This
key material can be used for authenticating peers during
handshake. This prevents spooﬁng and replay attacks during
the (re)connections. The key material can be combined
with a mutual challenge-question authentication [13], as we
implemented in [3].
Thus, the server is aware of who the client is, and vice-
versa, and also of where such (re)connection is coming from.
Then, the server is able to abort (re)connections that come
from untrusted clients, as shown in the transition from s5 to
s11. In the meantime, the client denies communicating with
fake servers by aborting connections in the transition from
c5 to c11.
B. Saving the transmission status
After handover, the data enqueued in the send buffer may
be lost. The lost data are those unconﬁrmed by the remote
peer and those ready for sending. To provide reliability at
the Application Layer, it needs to preserve a copy of the
message to be sent, and checkpoints to successfully count
the sent and received bytes.
When the peers are connected and ready for sending
and receiving messages, the client is in state c5 and
the server is in state s6. The client sends the message
(send(new.data)) and reaches state c6. Then, it saves
the transmission context by keeping a local copy of the sent
message (from c6 to c7) in an ancillary buffer, and it counts
the amount of sent bytes (from c7 to c8).
After sending, a client can remain waiting for a server’s
response. When the socket receive buffer is ready for read-
ing, the client consumes the enqueued data and reaches the
state c9 (from c5 or from c8). Then, it saves the transmission
185
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

c0
c1
 update(c.reg)
c11
c2
 lookup(s.id)
 F,
mobile server
c3
 connect(s.ip)
 F:DU
 F:TO | F:RST
c4
 send(c.info)
 F:BC
c5
 recv(s.info)
 close() 
 Abort
 F:TO
c6
 send(new.data) | 
send(lost.data)
c9
 recv(new.data)
 close()
 F:BC
c7
 store(new.data)
c8
 save(c.tx)
send(new.data)
 recv(new.data)
 close()
 F:TO
c10
 save(c.tx)   
 send(new.data)
 recv(new.data)
(a)
s0
s1
 update(s.reg)
s11
s2
 bind()
s3
 listen()
s4
accept()
s5
recv(c.info)
s10
F:TO
close()
s6
send(s.info)
F:TO
close()
s9
recv(new.data)    
F:BC
s7
send(new.data) |
 send(lost.data)     
 save(s.tx)
F:TO
mobile node, 
 update(s.reg)
stationary node, 
 accept()
F:BC
s8
store(new.data)
save(s.tx)  
(b)
Figure 1.
Finite state machines for mobility-aware applications: (a) client, and (b) server.
status by counting the received bytes (c9 to c10). The client
can receive more messages (c10 to c9), send new messages
(from c10 or from c8), or ﬁnish the transmission (from c9
or from c6).
At the server side a similar approach is used. Once
connected, the server receives a new message (s6 to s9) from
the client and saves its transmission context by counting the
received bytes (s9 to s6). The server can also send new
messages to the client (s6 to s7) and save its transmission
context by copying the sent message in its ancillary buffer
and counting the sent bytes (s7, s8, s6). The server is also
able to ﬁnish the transmission by closing the connection and
reaching the ﬁnal state s11.
C. Disruption Detection
Modiﬁcations in the routing table ( e.g.,, adding new IPs
or routes) and connection timeout break established TCP
sessions. On the attempt of sending a new message on a
broken TCP socket, an error is returned after calling the
send function. In the client, the handling is conducted in
the transition from state c5 to c6, in which the error F:BC
(broken connection) leads the system to state c2 again. In
the server, the same failure leads to the erroneous state s10.
In the receiver, unread bytes can remain in the socket
receive buffer. Thus, the receiver will not crash immediately
after the disruption. Instead, the connection becomes half-
open, so that the receiver stays in deadlock waiting for
messages from a dead sender. To quickly detect a broken
connection in the receiver’s side, parameters of the TCP
Keepalive is reduced as much as possible [14]. Thus, the
receiver detects disruption with connection timeouts F:TO
according to the transitions c5, c9, c2 and s6, s9.
D. Resuming communication from broken connections
After a failure, when the transition leads to state c2, a
re-connection has to be established to resume the commu-
nication in the client. In order to do so, the server must be
resynchronized and prepared to accept a new re-connection
from the client again. Then, the server must be waiting in
state s3. By executing the session handshake, client and
server are aware about the current transmission context of
each other, as shown in the transitions from c2, c3, c4,
c5 and from s3, s4, s5, s6. This resumes the end-to-end
communication into a new TCP connection. The session is
preserved by authenticating the peer using the key material
and the host identiﬁer. Thus, the server relates the incoming
re-connection to an existent session.
E. Restoring Transmission Status
After the TCP connection re-establishment and the hand-
shake between the peers, the sender restores the transmission
context by resending the lost data recovered from the ancil-
lary buffer. To determine the amount of lost data, both client
and server must know the amount of bytes that was sent and
186
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

received by each other until to the disruption. To do so, the
peers can mark transmission checkpoints by counting the
bytes that are sent and received successfully.
We suggest the use of in-band signalling between the
peers. Session control information, including transmission
checkpoints, are exchanged over the data connection, as
we propose with handshake between client and server with
transitions from c3, c4, c5 and from s4, s5, s6, respectively.
The sender’s amount of data lost in handover is given by:
Nld = Nls − Nrr,
(2)
where Nls is the local amount of bytes sent by the node,
and Nrr is the amount of bytes received by the remote peer.
The node is able to recover the lost data from the ancillary
buffer and, then, resend them to the opposite node with the
function resend(lost.data) in the transition from c5
to c6 and from s6 to s7.
While resending, however, a disruption might eventually
cause a connection failure again. Since the lost data are al-
ready saved, only new messages are copied into the ancillary
buffer. The model provides the same support for handling
this disruption as described previously. In that case, the
remote peer can receive part of the lost data that the sender
tried to resend. Although this sending is incomplete, with the
next handshake the peers recalculate the new amount of lost
data, which denotes the remaining of lost data that has to be
sent. This strategy provides integrity of the data transmission
in the whole session duration and brings reliability to the
Application Layer of the mobile nodes.
F. Mobility scenarios and Location Management
In a Single Jump scenario, the server usually runs on a
stationary host to which the client re-connects. The mobility
becomes a more complex problem when the server node also
changes its location. In this scenario, called Double Jump,
location management is required. Some entity must provide
the current location of mobile server nodes. Besides, there is
the possibility of moving both nodes simultaneously, which
increases the chance of race conditions.
Race conditions are experienced when the client tries to
re-connect to the server when it is not prepared to accept
connections. This occurs when: i) the server visits a new
network and the client does not know about the new server’s
location; ii) the client detects the disruption before the server,
so that the client starts the re-connection in advance.
Mobility protocols can leverage Dynamic DNS for mobile
node location [7]. Rendezvous Servers [8][10] have also been
applied to location management. However, we suggest the
use of distributed mechanisms to store node locations. A
Distributed Hash Table (DHT) of general purpose, such as
OpenDHT [15], is able to provide the necessary scalability
to manage mobile node location. A DHT provides storage
based on key-value semantic, as well as a simple put-get
interface. Thus, to query the peer’s location, a node uses the
peer’s host identiﬁer as a key for searching in the DHT. To
update location, a node puts its location register under its
host identiﬁer in the DHT.
A node is aware of the role it plays in a session. Thus,
when the server is migrated, if it runs on a mobile node,
it puts its location register in the DHT (s10, s3). Other-
wise, it just waits for re-connections from the client (s10,
s4), without performing a location update. In the client, a
connection failure arises when the server is migrated. The
client is aware of the role the server plays due to the control
ﬂags exchanged in the handshake. Then it can query the
current server’s location in the DHT with the server’s host
identiﬁer. If the client attempts to re-connect to the outdated
server’s location, the connection fails, since the destination
is unreachable (F:DU). Then, the client stays in the loop
from c2, c3, c1 until the race condition is overcome.
III. HANDOVER DELAY MODEL
To evaluate mobility-aware applications we applied the
mathematical model proposed by Mohanty and Akyildiz [11]
and extended by Shah et al. [12].
As discussed in [12], the end-to-end handover delay is the
sum of the following delays:
Thandover = TL2 + TIP + Tsig + Td,
(3)
where they represent, respectively, the delay of: Link
Layer connectivity, IP address acquisition, handover control
messages signalling, and one-way data packet transmission
in new network.
The critical delay is Tsig. It varies according to the
approach used by the mobility protocol. Next, we discuss
the model used in [11] and [12], which is based on the
number of control messages exchanged between
mobile
node (MN) and correspondent node (CN) to complete end-
to-end handover.
A. Handover signalling delay as function of packet loss
probability
The handover operation model of TCP-Migrate [7] dis-
cussed by [11] can be applied to the majority of end-to-
end mobility management protocols [12]. As in [16], the
model is based on the delay of TCP connection establish-
ment as function of end-to-end packet loss probability and
of retransmission timeout. In mobility scenarios, then, the
model represents the delay of connection set-up or migration
between MN and CN in new visited network. It is calculated
as function of end-to-end packet loss probability, number of
handover signalling messages exchanged between the peers
and their number of retries, and the retransmission timeout.
The delays of handover signalling completion for end-
to-end mobility protocols of two [12] and three control
messages [11], respectively, are
Lsig(i, j) = RTT + (2i + 2j − 2)RTO,
(4)
187
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

and,
Lsig(i, j, k) = 1.5RTT + (2i + 2j + 2k − 3)RTO,
(5)
where i, j, and k are the number of unsuccessful tries for
handover control messages, RTT is the round trip time of
the message, and RTO is the initial retransmission timeout
for the TCP connection.
Using Equation (4) and (5), we express the overall delay
of handover signalling completion for a end-to-end mobility
protocol of Nm handover control messages as
Lsig(A) = Nm
2
RTT +
" Nm
X
i=1
2ai
!
− Nm
#
RTO,
(6)
where A = (a1 a2 a3 . . . aNm) is the number of
unsuccessful tries for each handover control message.
The end-to-end packet loss probability between MN and
CN discussed by [11] is
p = 1 − (1 − FER)f(1 − pwr),
(7)
where FER is the link layer frame error rate; f = Lp
Lf is
the number of link layer frames per packet, where Lp is the
length of the packet, and Lf is the length of the Link Layer
frame; and pwr is the packet loss probability in wired link
part.
From the TCP latency model in [16], the authors in [12]
and [11] discuss the probabilities of handover signalling
completion for protocols of two and three control messages,
respectively, by expressing
Psig(i, j)
=
pi
1(1 − p1) pj
2(1 − p2),
(8)
Psig(i, j, k)
=
pi
1(1 − p1) pj
2(1 − p2) pk
3(1 − p3), (9)
where p1, p2, and p3 are the packet loss probabilities
calculated using Equation (7) for each individual handover
control message with its respective i, j, and k number of
unsuccessful tries. These equations represent the probabili-
ties of end-to-end mobility protocols to complete handover
after the exchange of i unsuccessful tries for the ﬁrst control
message, followed by the ﬁrst succeeded message, followed
by j unsuccessful tries for the second control message,
followed by the second succeeded message, and so on.
Assuming the number of unsuccessful retries in A, for a
mobility protocol of Nm control messages, we express the
overall probability of handover signalling completion as
Psig(A)
=
Nm
Y
i=1
pai
i (1 − pi),
(10)
where pi is the end-to-end packet loss probability cal-
culated using Equation (7) of ith control message with its
respective ai number of unsuccessful tries.
The average of the handover signalling messages delay
for a protocol of Nm = 3 control messages, such as TCP-
Migrate, is [11]:
E[Tsig] =
Nr−1
X
i=0
Nr−1
X
j=0
Nr−1
X
k=0
Psig(i, j, k) Lsig(i, j, k),
(11)
where Nr is the number of retransmissions before giving
up and abort the connection establishment of TCP-Migrate.
As discussed in [12], Nr is used as the maximum allowed
number of retries for handover control messages.
Using the overall delay and probability of Equation (6)
and (10), we generalize the average of the handover sig-
nalling messages delay for any Nm-message protocol as
E[Tsig] =
NA
X
A=1
Psig(Ai) Lsig(Ai),
(12)
where NA is the number of all the combination of A
taking into account Nm and Nr − 1.
B. Handover signalling delay for mobility-aware applica-
tions
According to the state machines for mobility-aware ap-
plication, the handover signalling delay at the active opener
(mobile client) in single jump scenario is
TsigSJ = TT CP + Ths + Tld,
(13)
where TT CP is the new TCP connection establishment
delay between MN and CN (from c2 to c3), Ths is the
protocol handshake delay which is used for end-to-end
synchronization and/or authentication (from c3 to c5), and
Tld is the lost data retransmission delay (from c5 to c6).
These delays are calculated using Equation (12), each one
according to the number of control messages Nm exchanged
between MN and CN.
The handover signalling delay at the active opener in
double jump scenario is
TsigDJ = Tlookup + TT CP + Ths + Tld,
(14)
where Tlookup is the client’s delay to lookup server’s
location. TT CP , Ths, and Tld are deﬁned in Equation (13).
To lookup location register, the requester sends a request
to the DHT and waits response from it. The DHT is accessed
using either Sun RPC over TCP or XML RPC over HTTP
[15]. Assuming that the delay to get a register is the sum of
the time to establish a TCP connection with the DHT and
the message round trip time (lookup request and its reply),
the registration location lookup delay can be expressed as
Tlookup = TT CP + Treq + Trep.
188
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

However, as discussed in [11], the round trip time for a
lookup request can be expressed as twice the one-way end-
to-end delay transportation. Thus,
Tlookup
=
TT CP + 2(D + tw),
(15)
where D is the Link Layer access delay, and tw is the
one-way delay in the wired network between the new Base-
Station/Access-Point and the remote node (DHT).
IV. SIMULATION RESULTS
We evaluated the cost of handovers for the mobile active
opener by using the described handover delay model in both
single and double jumps; i.e., the handover latencies for the
client to leave the state c1 (in double jump) or c2 (in single
jump) and, then, reach the state c5 (if there are no lost data
to resend) or reach the state c9 (after resending the lost data).
Both communicating sides accomplish equivalent operations
to handle F, therefore, the cost of handover is considered
the same for both client and server.
We implemented the
handover delay model using the GNU software environment
for statistical computing provided by R[17].
A. Simulation Parameters
In most application protocols the connection is considered
to be established when SYN/ACK packet arrives at the active
opener [16]. This is because immediately after sending ACK
in the third packet of the three-way handshake, the active
opener sends a data segment to the passive opener that
contains the redundant ACK [16]. Then, we assume that
TCP connection is considered to be established by the client
with 2 control messages. Thus, we set Nm = 2 in Equation
(12) to calculate TT CP .
The number of control messages exchanged during the
handover signalling depends on the synchronization and/or
authentication used by the mobility protocol. The mobile
node can conﬁrm its new location by simply sending a
single control message to the correspondent node. SIP [8]
requires at least exchanging two control messages using
re-INVITE and 200 OK conﬁrmation. The FSM suggests
exchanging two control messages to provide end-to-end
synchronization and unilateral authentication. TCP-Migrate
[7] requires exchanging three control packets with the three-
way handshake needed to migrate TCP connections. When
secure connection re-establishment is a requirement, a four-
way handshake can provide mutual challenge-response au-
thentication and end-to-end synchronization [18] [3]. We
evaluated these different handover signalling strategies for
mobility-aware application by varying the values of Nm
from 1 to 4 in the calculation of Ths from Equation (12).
To compare these different handover signalling strategies,
we assume the values of the handover delay model param-
eters as in [12]: TL2 = 10 ms, TIP = 20 ms, Td = 50 ms,
RTT = 100 ms, RTO = 200 ms, pwr = 1e − 6. Since
G
G
G
G
G
G
G
G
G
G
G
FER
Handover delay (ms)
0.00
0.10
0.20
0.30
0.40
0.50
0
100
200
300
400
500
G
Nm=1, Nld=0
Nm=2, Nld=0
Nm=3, Nld=0
Nm=4, Nld=0
(a)
G
G
G
G
G
G
G
G
G
Block size of lost data (KBytes)
1
16
32
48
64
80
96
128
0
100
200
300
400
500
G
Nm=1
Nm=2
Nm=3
Nm=4
(b)
Figure 2.
Handover delay in single jump scenarios: (a) as function of the
frame error rate; (b) as function of the lost data (Nld) in handover.
most TCP implementations abort connection establishment
attempts after 4-6 failures [16], we assume Nr = 4 retries.
We set Lf = 576 bytes (length of Link Layer frame),
regarding the packet size every host must be able to handle
on the Internet [19]. The length of the packet Lp = 40
bytes for the TCP connection establishment, regarding the
size of IP header and TCP header, both with no options.
We assume Lp = 60 bytes for the length of the handover
control message, which is able to accommodate the control
information (host identiﬁer, checkpoints, and protocol ﬂags)
we described in Section II-A. As in [11], we set the link
layer access delay D = 10 ms in WLANs, and the one-way
delay in the wired network tw = 50 ms.
As argued in [12], although these values are not constant
and may vary depending on the network conditions, when
the values are changed they affect in the same manner the
behaviour of all the mobility strategies evaluated.
B. Handover Latencies
Figures 2 and 3 show handover delay results for Nm =
1, 2, 3, 4 strategies in single and double jumps, respectively.
Figures 2(a) and 3(a) show delays as function of FER when
there are no lost data in handovers,
i.e., Nld = 0, hence,
Tld = 0.0. In both scenarios, handover delays increase as
the FER increases, which is natural. When FER gets high, it
increases the probability of dropping packets and, therefore,
handover control messages need to be retransmitted Nr
times to successful complete the handover. The overall cost
of using a handover control message was 62.18 ms in
average for both mobility scenarios.
Figures 2(b) and 3(b) show delays as function of the lost
data in handovers. We set FER = 1e − 3 and evaluated the
lost data by varying Nld in Lp with multiple blocks of 16
KB up to 128 KB, which is the maximum amount of lost
data by a sender. We assume such limit due to the maximum
size of 131071 bytes for socket send buffers in GNU/Linux
systems with Kernel version above 2.4. We observed that
the cost of retransmitting a block of 16 KB of lost data
with a single operation send(lost.data) increases the
handover latency in 7.65 ms.
189
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

G
G
G
G
G
G
G
G
G
G
G
FER
Handover delay (ms)
0.00
0.10
0.20
0.30
0.40
0.50
0
150
350
550
750
G
Nm=1, Nld=0
Nm=2, Nld=0
Nm=3, Nld=0
Nm=4, Nld=0
(a)
G
G
G
G
G
G
G
G
G
Block size of lost data (KBytes)
1
16
32
48
64
80
96
128
0
150
350
550
750
G
Nm=1
Nm=2
Nm=3
Nm=4
(b)
Figure 3.
Handover delay in double jump scenarios: (a) as function of the
frame error rate; (b) as function of the lost data (Nld) in handover.
In single jumps, which is the common mobility scenario,
the mobile client can be moved with no need for location
updates. Therefore,
the entity for managing location is
avoided. This allows reduced handover latencies than the
ones in double jumps, as shows Figure 3. Due to the
registration location lookup delay (Tlookup), in which the
client gets the current server’s location registration from the
DHT in order to re-connect, the handover latencies in double
jumps are 42% in average bigger than the ones in single
jump; i.e., a mean overhead of 244.37 ms.
We observed that mobility-aware applications provide
little and smooth impact when both FER and lost data
increase. This behaviour can be an interesting advantage in
dynamic scenarios, such VCNs, where devices are of high
mobility and packet loss rates are prone to be higher than
the ones in mobility scenarios focused on the mobile user.
Comparing results in [12], Nm = 2 strategy (as primarily
suggest our FSMs) provides handover latencies very close
to the kernel space based mobility solutions, such as TCP-
R, TCP-Migrate and HIP. In relation to these solutions, an
overhead lower than 100 ms is the weight of the burden
on handling mobility at the user address space of mobile
nodes. However, this performance degradation is derisive
when taking into account the beneﬁts of providing easy
deployment and maintenance of full support for mobility,
which can be implemented as a single software service.
V. CONCLUSION
In this paper, we described the general purpose mobility-
aware applications by means of Finite State Machines ca-
pable of providing transitions between erroneous and safe
states. These transitions are abstract operations based on the
Socket semantic, which are necessary to resume consistently
and lossless the end-to-end communications broken with
mobility. The presented abstraction is useful in support for
developing mobility solutions as software services at the
end nodes involved in TCP sessions, with no relying on
home networks or agents to intermediate the communication.
Applying the analytical model for handover delay discussed
in [11] and [12], simulation results show good performance
and smooth impact in situations of high packet loss rates
and of lost data.
VI. ACKNOWLEDGEMENTS
We thank INCT-SEC for funding this work by means of
the agencies CNPq and FAPESP.
REFERENCES
[1] C. E. Perkins, “IP Mobility Support for IPv4, Revised,” in IETF RFC
5944, November 2010, pp. 1–100.
[2] D. Johnson, C. Perkins, and J. Arkko, “Mobility Support in IPv6,” in
IETF RFC 6275, July 2011, pp. 1–169.
[3] B. Y. L. Kimura, H. C. Guardia, and E. S. Moreira, “Disruption-
Tolerant Session for Seamless Mobility,” in WCNC 2012: Proceeding
of the 2012 IEEE Wireless Communications and Networking Confer-
ence, 2012, pp. 2412 –2417.
[4] B. Y. L. Kimura and H. C. Guardia, “TIPS: Wrapping the Sockets
API for Seamless IP Mobility,” in SAC’08: Proceedings of the 23rd
Annual ACM symposium on Applied computing, vol. 3, March 2008,
pp. 1940–1945.
[5] W. M. Eddy, “At what layer does mobility belong?” IEEE Commu-
nications Magazine, vol. 42, no. 10, pp. 155–159, October 2004.
[6] D. Funato, K. Yasuda, and H. Tokuda, “TCP-R: TCP mobility support
for continuous operation,” in ICNP’97: Proceedings of the IEEE
International Conference on Network Protocols, October 1997, pp.
229 – 236.
[7] A. C. Snoeren and H. Balakrishnan, “An end-to-end approach to host
mobility,” in MobiCom’00: Proceedings of the 6th ACM Annual In-
ternational Conference on Mobile computing and Networking, August
2000, pp. 155–166.
[8] J. Rosenberg, et al., “SIP: Session Initiation Protocol,” in IETF RFC
3261, June 2002, pp. 1 – 269.
[9] V. C. Zandy and B. P. Miller, “Reliable Network Connections,” in
MobiCom’02: Proceedings of the 8th ACM Annual International
Conference on Mobile computing and Networking, September 2002,
pp. 95–106.
[10] R. Moskowitz, P. Nicander, and P. Jokela, “Host Identity Protocol,”
in IETF RFC 5201, April 2008, pp. 1 – 104.
[11] S. Mohanty and I. F. Akyildiz, “Performance analysis of handoff tech-
niques based on mobile ip, tcp-migrate, and sip,” IEEE Transactions
on Mobile Computing, vol. 6, no. 7, pp. 731–747, July 2007.
[12] P. A. Shah, M. Yousaf, A. Qayyum, and H. B. Hasbullah, “Perfor-
mance comparison of end-to-end mobility management protocols for
tcp,” Journal of Network and Computer Applications, vol. 35, no. 6,
pp. 1657 – 1673, 2012.
[13] D. M’Raihi, J. Rydell, S. Bajaj, S. Machani, and D. Naccache,
“OCRA: OATH Challenge-Response Algorithm,” in IETF RFC 6287,
June 2011, pp. 1 – 38.
[14] B. Y. L. Kimura, R. S. Yokoyama, R. R. F. Lopes, H. C. Guardia,
and E. S. Moreira, “Prototyping applications to handle connection
disruptions in end-to-end host mobility,” in WONS 2010: the Seventh
IEEE International Conference on Wireless On-demand Network
Systems and Services, 2010, pp. 1–8.
[15] S. Rhea, B. Godfrey, B. Karp, J. Kubiatowicz, S. Ratnasamy,
S. Shenker, I. Stoica, and H. Yu, “OpenDHT: a public DHT service
and its uses,” SIGCOMM Comput. Commun. Rev., vol. 35, no. 4, pp.
73–84, August 2005.
[16] N. Cardwell, S. Savage, and T. Anderson, “Modeling TCP latency,” in
INFOCOM 2000: Proceedings of the Nineteenth IEEE Annual Joint
Conference of the IEEE Computer and Communications Societies,
March 2000, pp. 1742 – 1751.
[17] R Development Core Team, R: A Language and Environment
for Statistical Computing, R Foundation for Statistical Computing,
Vienna, Austria, 2008. [Online]. Available: http://www.R-project.org
[18] B. Y. Kimura, R. S. Yokoyama, H. C. Guardia, and E. S. Moreira,
“Secure connection re-establishment for session-based ip mobility,” in
CBSEC 2012: Proceeding of the 2nd Brazilian Conference on Critical
Embedded Systems, 2012, pp. 58–63.
[19] J. Postel, “Internet Protocol,” in IETF RFC 791, September 1981, pp.
1 – 45.
190
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-279-0
AICT 2013 : The Ninth Advanced International Conference on Telecommunications

