Regional Comparisons of Critical Telecommunication Infrastructure 
Resiliency Based on Outage Data 
Andrew P. Snow, John C. Hoag 
School of Information and Telecommunication Systems 
Ohio University 
Athens, Ohio USA 
Email: snowa@ohio.edu; hoagj@ohio.edu 
 
Gary R. Weckman, Naga T. Gollamudi 
Department of Industrial and Systems Engineering 
Ohio University 
Athens, Ohio USA 
Email: weckmang@ohio.edu, ng746812@ohio.edu 
William A. Young 
Department of Management and Strategic Leadership 
Ohio University 
Athens, Ohio USA 
Email: youngw1@ohio.edu 
 
 
 
 
 
 
 
 
Abstract— The resiliency of telecommunication infrastructure 
by US Federal Emergency Management Agency (FEMA) 
region, is presented, based on almost 9,000 telecommunication 
outages over a 14 year period. Executive policy organizations in 
the US have described a resilient infrastructure as one that can 
minimize the magnitude and/or duration of service disruptions. 
To that end an empirical assessment of resiliency is made by 
region using telecommunication outages, each of which has 
duration and magnitude (the number of users affected by the 
outage). 
Wireline 
central 
offices 
are 
essential 
to 
telecommunication 
infrastructure, 
as 
they 
house 
local 
switching, transmission, and user access infrastructure for both 
voice and data services, including the Public Switched 
Telephone 
System 
(PSTN), 
the 
Internet, 
mobile 
communications, and emergency communication. Central office 
resiliency is studied by proxy, examining local telephone switch 
outages in those offices over 14 years. Regional comparisons are 
first 
made 
using 
classic 
time-series-of-event 
reliability 
techniques, allowing reliability trend comparisons. Next, outage 
cause comparisons are made. Then, a resiliency metric is 
presented that allows a fair comparison between regions 
differing in population. Marked differences in resiliency trends 
are apparent in some FEMA regions.  
Keywords- Resiliency; FEMA; telecommunication outage; critical 
infrastructure. 
I. 
 INTRODUCTION 
The resilience of telecommunication services and 
capabilities are important to any nation. In the US, the 
Department of Homeland Security (DHS) states, in reference 
to critical infrastructure of all types, that resilience is 
“….the ability to adapt to changing conditions and 
withstand and rapidly recover from disruption due to 
emergencies.  Whether it is resilience towards acts of 
terrorism, cyber attacks, pandemics, and catastrophic 
natural disasters, our national preparedness is the shared 
responsibility of all levels of government, the private and 
nonprofit sectors, and individual citizens.” [1] 
Additionally, The National Infrastructure Advisory Council 
(NIAC) was created as a Federal Advisory Committee to 
advise the President and the Secretary of Homeland Security 
on all areas of critical infrastructure. NAIC further refines the 
definition of effective infrastructure resilience to include 
measurable attributes: 
“Infrastructure resilience is the ability to reduce the 
magnitude and/or duration of disruptive events. The 
effectiveness of a resilient infrastructure or enterprise 
depends upon its ability to anticipate, absorb, adapt to, 
and/or rapidly recover from a … disruptive event.” [2] 
This research presents a resilience metric that include not 
only the magnitude and duration (called “impact”) of 
telecommunication outages, but also frequency of these 
outages, on a regional basis.  The regional paradigm chosen 
for this research is defined by FEMA, who  
“…coordinates the federal government's role in 
preparing for, preventing, mitigating …. responding to, 
and recovering from all domestic disasters, whether 
natural or man-made, including acts of terror.” [3] 
In performance of this mission, FEMA has divided the US 
and its territories into ten regions, shown in Figure 1, which 
present a useful and practical way to study critical 
telecommunication infrastructure resiliency across the US. 
 
Figure 1. FEMA regions [4] 
13
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

This paper addresses telecommunication infrastructure 
resiliency based on a 14 year record of U.S. PSTN local 
telecommunication switch outage data. In Section II 
Background, the role of local switches as service access 
points in the PSTN is covered. The importance of Central 
Offices where local switches, mobile switching, and internet 
access equipment is housed is discussed. Also, a description 
of the outage data is presented. In Section III, Methods and 
Results, regional differences in outage causality, reliability 
and resiliency methods and results are presented. Lastly, in 
Section IV Summary, major findings, research limitations, 
implications, and future research are discussed. 
II. 
BACKGROUND 
A. Central Office Buildings Serve More Than the PSTN 
Central Offices house not only local voice telephone 
switches, but also other important network elements such as 
mobile communication backhaul and Internet access/transport 
equipment. For instance, it is not uncommon for a Mobile 
Switching Center (MSC) circuit switch to be located in a 
Central Office building. Alternately, the local exchange 
carrier often provide a wireless carrier Layer 1/2 connectivity 
between its Base Station Controllers (BSC) and its MSCs, 
which might be tens to hundreds of miles away. In these cases, 
the Central Office building is very important to wireless voice 
and data services.  
Additionally, there are often optical SONET add/drop 
multiplexers in Central Offices that not only provide trunking 
between PSTN switches, but also digital internet trunks. At 
Layer 2/3, central offices involved in backhaul could be 
forwarding or aggregating Metro Ethernet virtual circuits per 
VLAN, interconnecting virtual circuits to Multiprotocol Label 
Switching (MPLS). Also, Central offices house important 
Internet assets such as routers and DSL internet access 
equipment. So, a range of services from Metropolitan 
Ethernet, MPLS, multiplexers and DSL can be adversely 
affected by the same factor that causes a local 
telecommunication switch in a Central Office to fail [5].  
For these reasons, PSTN local switch outages that are 
caused by external circumstances, potentially affecting all 
electronics in a Central Office building, can be an indicator of 
PSTN, Mobile, and Internet telecommunication infrastructure 
resilience. Such local switch outage causes include those 
induced by external power outages, building damage, massive 
line cuts, and acts of god. 
B. Local Telecommunication Switches 
The PSTN is a complex system composed of a switching 
subsystem, a signaling subsystem, and a transmission 
subsystem. The switching subsystem routes voice calls 
throughout the PSTN network. The signaling subsystem 
coordinates call initiation, maintenance, and termination. The 
transmission subsystem provides physical links between 
switches so end-to-end voice circuit connections can be made. 
The signaling and transmission subsystems are not part of the 
research in this paper. The switching subsystem consists of 
local exchange switches (local switches), tandem switches, 
and international gateway access switches (see Figure 2). 
Only the local exchange switching subsystem is investigated 
in this study. There are three types of local switches: 
standalone, host, and remote. Less common are some tandem 
switches that also have access lines, but they are very small 
percentage of all switches in this study with outages. 
Importantly, best practices requires E911 call centers to 
connect to two tandems – however, as many centers are far 
away from tandems, some local switches are configured to act 
as tandems for E911 calls [6]. The importance of local 
switches using circuit switched technologies should not be 
underestimated.  Even though the PSTN is migrating to voice 
over internet protocol (VoIP), the migration will take many 
years, and local switches will be in service for many years [7]. 
In 2011, although there were 32 million VoIP subscribers, 
there were 117 million subscribers connected over local loops 
to circuit switched local switches [8]. Also consider the work 
of Lyons, et al, where the economic impact of 
telecommunication outages were empirically assessed for 
local exchange outages. The economic loss estimates are 
based on actual business and residential demographics, 
including residential service and manufacturing. Economic 
loss estimates ranged from €370,000 to €1.1 million per day, 
for seven local exchange outages in Ireland [9]. 
 
 
 
Figure 2. The PSTN switching subsystem. 
 
C. Local Telecommunication Switch Outage Data 
This study investigates 8,975 local telecommunication 
switch outages in the U.S. of at least 2 minutes in duration for 
a 14-year period (1996-2009) and considers only totally 
failed switches rather than partially failed switches (partially 
failed switches were not reported).  Scheduled outages are not 
included because of their small duration – only the 8,875 
outages caused by failures are studied here. Scheduled 
outages are not considered. This outage data was reported to 
the Federal Communications Commission (FCC) and 
obtained from [10]. Unfortunately, after 2009, the FCC 
stopped requiring carriers to report this data.  Carriers 
classified each local switch outage incident using one of 
fifteen FCC defined cause codes. In this research, by combing 
14
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

similar cause codes reported to the FCC into categories, we 
reduced the fifteen causes reported to the FCC down to five 
causality categories, similar to what was previously done in 
[11]: 
• Human Procedural Errors:  Procedural errors made in 
installation, maintenance or other activities by Telco 
employees, contractors, or vendors.  
• HW and SW Design errors:  Software or hardware 
design errors made by the switch vendor prior to 
installation. 
• Hardware Errors: A random hardware failures, which 
causes the switch to fail.   
• External Circumstances: An event not directly 
associated with the switch, which causes it to fail or be 
isolated from the PSTN. 
• Other/unknown: A failure for which the cause was not 
ascertained by the carrier. 
As each reported switch outage includes date, time, duration, 
magnitude, and location, important reliability and resiliency 
analysis can be performed. 
 
III. 
OUTAGE  ANALYSIS METHODS AND RESULTS 
A. Regional Local Switch Causality Differences 
To see to what extent switch outage cause categories might 
differ across regions, histograms were created for major cause 
categories. Each histogram shows the percentage of outages 
due to a particular causal category across the ten regions, two 
of which are shown in Figure 3. These categories, their 
composition, and the distribution of failures to each category 
are shown in Table I.  
 
 
 
Figure 3. Regional causal percentage histogram examples. 
 
 
 
TABLE I.  LOCAL SWITCH OUTAGE FREQUENCY BY CAUSE  
OUTAGE CATEGORY 
Frequency 
Percent 
Human Procedural Error 
1,394 
16% 
HW or SW Design Error 
1,214 
14% 
Random HW Failure 
2,951 
33% 
External Circumstances 
2,900 
32% 
Other/Unknown 
516 
6% 
Total 
8,975 
100% 
For each cause category, the question of interest is whether 
there is a statistical difference in causal category percentages 
across the regions. The following hypotheses were used to 
test this notion for each histogram: 
H0: Cause category percentages is uniformly 
distributed across the 10 regions 
Ha: Cause category percentage is not uniformly 
distributed across the 10 regions 
The method used to test the hypotheses is the Chi-squared 
test, where the expected values are the average percentage 
across the 10 regions for each cause category, and the 
observed values are the actual percentages across the regions 
in a histogram. The results are shown in Table II, where we 
accept differences across the regions in the “External 
Circumstances” and the “Other/Unknown” cause categories. 
 
TABLE II.  REGIONAL OUTAGE CAUSALITY DIFFERENCES 
CAUSE 
CATEGORY 
ACCEPT 
P-VALUE 
CONCLUSION 
External 
Circumstances 
Ha 
0.0005 
Different across 
regions 
Random HW 
Failures 
H0 
0.4599 
No difference 
across regions  
Human 
Procedure 
Errors 
H0 
0.5655 
No difference 
across regions 
HW or SW 
Design Errors 
H0 
0.2599 
No difference 
across regions 
Other/Unknown 
Ha 
0.0340 
Different across 
regions 
 
These results are useful, because they indicate that “External 
Circumstance” outages are not uniform across the regions. 
The makeup of external circumstances are the type of events 
that potentially affect all central office telecommunications 
equipment/services, rather than just the PSTN local 
telecommunication switch. For instance, the vast majority of 
external circumstance local switch outages are due to 
environmental reasons such as FCC cause codes described by 
“acts of god”, “external power failure”, “environmental” and 
“massive transmission facility loss”. These type of outages 
are very likely to also affect all other communications 
services in the central office building such as mobile 
switches, transmission and internet equipment. Note that 
Regions 4 and 6 have the highest percentages of outages due 
to external circumstances 
15
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

B. Regional Local Switch Reliability Differences 
Reliability is a study of times-to-failure (ttf), or said 
another way, the study of failure arrival process. If a failure 
rate is constant, the failure process is a stationary failure 
process, and Mean-Time-to-Failure (MTTF) can be 
calculated. If the times-to-failure are independent and 
exponentially 
distributed, 
the 
process 
is 
called 
a 
Homogeneous Poison Process (HPP). If the ttf’s are not 
exponentially distributed, but still independent, the failure 
process is a renewal process (RP), and the distributions can be 
fitted to other distributions such as Weibull, Gamma, or other 
distributions.  
Cumulative failure count versus time plots are often used 
to assess whether the arrival rate is constant, in that a straight 
line is apparent. However, if the plot is concave (bending 
down), reliability growth is indicated as the failures are 
decreasing over time. Conversely, if the plot is convex 
(bending up), reliability deterioration is indicated as the time 
between failures is decreasing.  In these cases, the failure 
process is non-stationary and distributions cannot be used and 
MTTF cannot be calculated, as it is a function of time. 
However, if the bending is smooth and steady (monotonically 
increasing or decreasing), these processes can be modeled as 
Non-homogeneous Poison Processes (NHPP), also known as 
“doubly-stochastic processes” as the arrivals are random and 
the rate of arrivals is changing over time. If the changes are 
not smooth, these processes can often be analyzed in a 
piecewise fashion over time. The reliability from cumulative 
plots can easily be assessed visually, and if the changes appear 
subtle, analytical methods can be used to arrive at the degree 
of statistical significance of trends (using such tests as the 
Laplace trend, Lewis-Robinson, Mann, or the MIL-Handbook 
tests [12]. 
In this research, to compare the reliability of local switch 
outages by region, cumulative plots were made for each 
region and visually assessed for reliability growth, constancy, 
or deterioration. In no instances were the visual presentations 
subtle, so no formal statistical trend tests are necessary. An 
example of cumulative outage plots vs. years are shown in 
Figure 4. Note that the number of outages differs, however 
this is not important at this stage of the comparison, as we are 
looking for differences in trends for each region. A normalized 
resiliency comparison will be made later in the paper.  
 
Figure 4. Regional switch cumulative failures vs. years 
 
Region 5 exhibits classic reliability growth, which could 
by modeled by an NHPP. However, Region 6 exhibits two 
distinct piecewise regions – steady reliability growth over 
about 11 years, followed by reliability deterioration over the 
last 3 years. Region 9 also exhibits two distinct piecewise 
regions – fairly constant reliability for about 4 years followed 
by 10 years of fairly constant reliability at a much lower 
failure rate. Region 10 indicates reliability growth, but is not 
as smooth as smooth an improvement as Region 5. A 
summary of the visual assessments for each region is shown 
in Table III. 
 
TABLE III.  LOCAL SWITCH RELIABILITY TRENDS BY REGION 
Reg. 
Rel. Trend (Imp. - Improvement; Det. – Deterioration) 
1 
Monotonic Imp. 
2 
Monotonic Imp. 
3 
Monotonic Imp. 
4 
Monotonic Imp. for 13 years, steep Det. for last year 
5 
Monotonic Imp 
6 
Imp. for 11 years, steep Det. for last 3 years 
7 
Monotonic Imp. 
8 
Det. years 0-4, marked Imp. years 4-14 
9 
Constant years 0 to 4, marked Imp. years  4-14 
10 
Monotonic Imp. 
 
At this point, it is useful to present the cumulative failure 
plot for all 8,975 switch failures in the U.S., as seen in Figure 
5. Note that the overall trend is decreasing, as indicated by the 
Laplace Trend Test statistic U, where U is like a Z-score 
where at a value greater than +1.96, we accept the hypothesis 
of reliability growth at a critical value of 0.05. However, the 
trend is seen to be monotonically improving up to year 11, 
after which it starts to monotonically deteriorate. It appears 
that the reason for this deterioration is due to Regions 4 and 6. 
This observation is corroborated by the external circumstance 
frequencies for Regions 4 and 6, which is in Figure 3. 
 
 
Figure 5. Local switch cumulative failure plot vs. years for the U.S. 
C. Regional Local Switch Resiliency Differences 
Earlier, we pointed out NAIC’s interest to be minimizing 
the magnitude and/or the duration of impacts to critical 
infrastructure. So any resiliency measure must account for 
these factors.  There has been past work using these two 
variables in assessing impact of telecommunication outages. 
 
16
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

McDonald introduced the User Lost Erlang (ULE) as an 
impact metric for large-scale outages, given by:  
ULE = log10 (Magnitude)                        (1) 
where magnitude is the subscribers impacted. So the impact 
of an outage affecting 100,000 lines would be 5 ULE. 
McDonald figured such a metric would be easy to use and be 
understandable by the public, similar to the logarithmic 
Richter scale for the intensity of earthquakes [13]. The 
disadvantage of the ULE is that only outage magnitude is 
taken into account -- duration is not.  As outages have both 
size and duration, the ULE was not adopted or used, but did 
establish the need for an outage metric.  
The FCC introduced use of the Lost Line Hour (LLH) 
metric, which is the product of the number of subscribers lost 
times the duration in hours, and also the lost line minute. For 
instance, a 100,000 line switch out for ½ hour represents 
50,000 LLH. Although a straightforward metric incorporating 
both size and duration, the LLH does not include blocked 
calls. Also, the LLH is not logarithmic, a feature that nicely 
accommodates very long or large outages.  
In the U.S., Committee T1, published an American 
National Standards Institute (ANSI) sponsored metric called 
the Outage Index (OI). This metric mapped duration and 
magnitude to weightings, which are logarithmic-like. The 
carrier industry adopted the OI metric. Analysis of the OI 
indicated a network administrator bias, as the index was 
sensitive to large size outages, but insensitive to long duration 
outages [14]. As an example, in [15] it was demonstrated that 
if a local switch with 10,000 lines experiences an outage of 24 
hours duration the OI is 0.529, while an 8-day outage for the 
same switch is 0.532. The other disadvantage of OI is that the 
values are not intuitive, for example, what does an outage with 
an OI of 1.24 mean with respect to impact? Lastly, in [16], 
resiliency was more recently defined as the fraction of 
subscribers deriving successful service. Although an 
interesting metric, the number of users impacted is not 
apparent from say 0.99 resiliency factor.  
Snow and Weckman recently introduced a novel 
resiliency metric for local switch outages in [17]. The metric 
is referred to as OIdbK, includes both duration and magnitude 
(represented by LLH), is logarithmic, and intuitive as it is 
referenced to a baseline outage of 1000 LLH: 
𝑂𝑂𝑂𝑂𝑑𝑑𝑑𝑑𝑑𝑑 = 10𝑙𝑙𝑙𝑙𝑙𝑙10 ቂ
𝐿𝐿𝐿𝐿𝐿𝐿
1000ቃ 
 
(2) 
Like the well-known dbm, a power referenced to 1 milliwatt 
in communications engineering, a doubling is about 3db while 
a halving is about -3db. Additionally, a tenfold increase is 
10db and decrease by a tenth is -10db. Below are a few 
examples of OIdbK: 
• OIdbK = 0 corresponds to 1,000 LLH, as log of 1 is 0 
• OIdbK = -3 represents a halving, or 500 LLH 
• OIdbK = 20 corresponds to two orders of magnitude above              
1,000 LHH, or 100,000 LLH 
• OIdbK = 23 is s a doubling above 20, or 200,000 LLH. 
This new metric tames wide swings of LLH, and give an 
intuitive reference when doing time series plots and regression 
of outage resilience over time. Of course, if desirable, we can 
also have OIdbM, which references the severity to one million 
LLH. Additionally, with outliers controlled, linear regression 
can be used to assess trends in resilience. An example of the 
utility of OIdbK is seen by referring to Figure 6 and Figure 7, 
where LLH and OIdbK for impact due to external 
circumstances are plotted The LLH plot appears unremarkable 
while the OIdbK plot indicates relative values of impact and a 
clear upward trend. In fact, statistically significant linear 
regression results for local switch external circumstance 
OIdbK indicate a 10.6 db increase per 10 years, which 
represents just over a 10 fold increase in LLH. [17]. 
 
 
Figure 6. Quarterly LLH vs. years for ext. circumstance outages 
 
 
 
Figure 7. Quarterly OIdbk vs. years for external circumstance outages 
 
FEMA regions are different in a number of geographical 
factors, such as climate, area, and population. Where there are 
more people, there are more switches, so we expect more 
failures and more impact on resilience due to switch outages. 
There is a large range in population over the regions, as seen 
in Table IV. 
 
TABLE IV:  REGIONAL POPULATION AND OUTAGES  
Region 
Population 
 (Millions) 
Outages 
1 
19.0 
139 
2 
31.6 
301 
3 
28.3 
519 
4 
55.3 
2,300 
5 
50.7 
1,299 
6 
34.4 
2,139 
7 
13.1 
1,065 
8 
9.7 
246 
9 
44.0 
488 
10 
11.6 
479 
17
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

For a fair comparison of regional resilience, in this 
research we modify the OIdbK by weighting LLH by 
population in millions, and reference the value to 1000 LLH 
per 1 Million people: 
𝑂𝑂𝑂𝑂𝑑𝑑𝑑𝑑𝑑𝑑/𝑀𝑀 = 10𝑙𝑙𝑙𝑙𝑙𝑙10 ቂ
𝐿𝐿𝐿𝐿𝐿𝐿
𝑃𝑃𝑃𝑃𝑃𝑃_𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀
1000𝐿𝐿𝐿𝐿𝐿𝐿
ൗ 1 𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀
ቃ 
        (3) 
where Pop_Mill is average regional population (in Millions, 
e.g., 19.0 for Region 1) over the study period. The average 
population was used because there was little percentage 
change in regional population over the study period. This new 
metric has all the advantages of OIdbK in addition to being 
scaled to the number of people in the region. 
Comparative regional resilience examples are shown 
in Figure 8 and Figure 9, due to all outages. In Figure 8, 
upward impact over time indicates resiliency deterioration in 
both Regions 4 and 6. The deterioration in these regions are 
very similar, however note the large outliers in years 6 and 10 
for Region 6. Examples of resiliency growth and constancy 
are shown in Figure 9. In Region 1, relatively constant 
resiliency is indicated, while in Region 1 strong resiliency 
growth is seen by the dramatic downward trend in outage 
impact.  
 
 
 
Figure 8. Yearly outage impact for regions 4 and 6 
 
 
 
 
Figure 9. Yearly outage impact for regions 1 and 7 
 
 
Although there is not room in this paper to show all ten 
regional impact plots, a qualitative description of FEMA 
regional resilience is given in Table V. In this table, regional 
resiliency is described as either improving, constant or 
deteriorating. Trend descriptions are based on regression lines 
for each regions outage impact plot. 
 
Table V.  REGIONAL RESILIENCY TRENDS 
Reg. 
Resiliency 
Description based on Regression 
1 
Improving 
Starting at 16db, and dropping to 0db 
over 14-years (from 40K to 1K LLH per 
mill pop.) 
2 
Improving 
Starting at 16db, and dropping to 6db 
over 14 years (from 40K to 4K LLH per 
mill pop.) 
3 
Deteriorating 
Starting at 10db, and increasing to 16db 
over 14-years (from 10K to 40K LLH per 
mill pop)  
4 
Deteriorating 
Constant first 8-years at 13db, up to 19db 
over 6-years (from 20K to 80K LLH per 
mill pop.) 
5 
Constant 
Constant at about 10db, or about 10K 
LLH per mill in pop.; some large 
variances 
6 
Deteriorating 
Starting at 13db, and increasing to 18db 
over 14-years (from 20K to 80K LLH per 
mill pop.)  
7 
Constant 
Constant at about 15db, or about 40K 
LLH per mill in pop. 
8 
Improving 
Starting at 10db, and dropping 10db over 
14 years, a drop of 10,000 LLH per mill 
pop. 
9 
Constant 
Constant at about 10db, or about 10K 
LLH per mill in pop.; some large 
variances 
10 
Constant 
Constant at about 10db, or about 10K 
LLH per mill in pop.; some large 
variances 
 
IV. 
SUMMARY 
A. Major Findings 
The major findings of this research on FEMA regional 
local telecommunication switch outages from 1996 to 2009 
are: 
• 
From a causality perspective, there are statistically 
significant differences in external circumstance outages 
across the regions. Additionally, histograms indicate the 
largest differences are due to Regions 4 and 5. External 
circumstance local switch outages are also likely to affect 
other telecommunication sector capabilities such as mobile 
and internet. 
• 
Over a 14-year period, the arrival process of outages 
in each region are non-stationary processes for which time-
to-failure distributions and MTTF metrics are not feasible. 
However, there are clear instances for some regions where 
there are different processes over the entire period, which can 
be segmented and analyzed separately. In some instances 
they are piecewise linear (constant reliability) where MTTF 
can be calculated. 
• 
Most regions experienced dramatic reliability 
growth in local switch reliability over the 14-year period, 
although two regions (Regions 4 and 5) experienced initial 
reliability growth for most of the time period but severe 
reliability deterioration towards the latter part of the 14 years.  
18
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

• 
From a resiliency perspective a recently introduced 
resiliency metric was successfully modified to weight impact 
by regional population, offering a fairer way to compare 
geographically different regions. The metric also conforms to 
NAIC desires, as it accounts for both magnitude and duration. 
• 
These results indicate that empirical methods and 
metrics are very useful in understanding the impact of 
outages to critical infrastructure, and that resilience is best 
understood when coupled with reliability, or the arrival rate 
of outages, which are in fact resiliency deficits. 
 
B. Research Limitations 
As the quantitative research presented here is based on 
data reported by carriers, it is not known how consistent the 
reporting was over a 14-year period by each carrier, and how 
similar the capabilities of carriers to capture outages, and 
accurately report the size, duration, and cause of outages. 
Additionally, only complete switch failures are reported and 
partial switch outages were excluded from reporting 
requirements. Also, this research was limited to using lost 
line hours in its resiliency metrics, as no reporting of blocked 
calls was required of carriers.  Lastly, actual impact of local 
switch 
external 
circumstances 
outages 
on 
mobile 
communication and Internet services/infrastructure in the 
same Central Office buildings cannot be quantified by these 
results.  
C. Future Work and Policy Implications 
More research is required to develop better resilience 
measures across all sectors of the telecommunication 
industry, in addition to metrics that can be linked or include 
economic impact. Additionally, the results in this paper 
indicate that local switch outages might serve as a “canary in 
the mine shaft” with respect to telecommunication 
infrastructure resiliency, due to the plethora of other 
telecommunication service sector equipment residing in 
PSTN Central Office buildings. In retrospect, these results 
indicate that the FCC’s discontinuance of local switch outage 
reporting after 2009 might be unfortunate, as an insightful 
reliability and resiliency bellwether seems to have been lost.  
V. ACKNOWLEDGEMENT 
This work is based on an unpublished paper presented at 
the 13th Annual Conference on Telecommunications and 
Information Technology, ITERA 2015 [18]. The original 
work has been corrected, refined and augmented here. 
 
REFERENCES 
[1] 
Quote retrieved December 2016 from 
http://www.dhs.gov/national-infrastructure-advisory-
council 
[2] 
NAIC Charter November 2013 [Online] available from 
http://www.dhs.gov/publication/niac-charter 
[3] 
Quote retrieved December 2016 from 
https://www.fema.gov/about-agency 
[4] 
Figure retrieved December 2016 from 
https://www.fema.gov/risk-mapping-assessment-
planning/regional-contact-information 
[5] 
Author discussions with engineers from several Local 
Exchange Carriers, March 1-8, 2015. 
[6] 
A. P. Snow, A. Shyirambere, J. Arauz, G. R. Weckman. "A 
Reliability and Survivability Analysis of US Local 
Telecommunication Switches." International Journal On 
Advances in Telecommunications 6, no. 3 and 4 (2013): 81-
97. 
[7] 
J. Gillan, and D. Malfara, The transition to an all-IP network: 
a primer on the architectural components of IP 
interconnection, National Regulatory Research Institute, 
May 2012. 
[8] 
FCC, Local Telephone Competition: Status as of December 
31, 2010, Industry Analysis and Technology Division, 
Wireline Competition Bureau, October 2011. 
[9] 
S. Lyons, E. Morgenroth, R. Tol, “Estimating the value of 
lost telecoms connectivity”, Electronic Commerce Research 
and Applications 12, 2013, pp. 40–51. 
[10] 
FCC Report 43-05, ARMIS Service Quality Report Table 
IVa, retrived December 2016 from 
http://transition.fcc.gov/wcb/armis/ September 2012. 
[11] 
A. P. Snow, J. Arauz, G. R. Weckman, and A. Shyirambere. 
"A Reliability and Survivability Analysis of Local 
Telecommunication Switches Suffering Frequent Outages." 
In ICN 2013, The Twelfth International Conference on 
Networks, pp. 209-216. 2013. 
[12] 
D.M Louit, R. Pascual, A. K. S. Jardine, “A Practical 
Procedure for the Selection of Time-to-failure Models Based 
on the Assessment of Trends in Maintenance Data”, 
Reliability Engineering and System Safety 94 (2009) 1618-
1628. 
[13] 
J. C. McDonald, “Public network integrity-avoiding a crisis 
in trust” Journal on Selected Areas in Communications, 
IEEE Journal, Volume: 12 , Issue: 1, 1994. 
[14] 
A. 
P. 
Snow, 
“A 
Survivability 
Metric 
for 
Telecommunications: Insights and Shortcomings”, IEEE 
Computer Society, Proceedings, Information Survivability 
Workshop – ISW’98, 1998, pp. 135-138. 
[15] 
A. P. Snow and Y. Carver, “Carrier-industry, fcc and user 
perspectives of a long duration outage: challenges in 
characterizing impact”, T1A1.2/99- 026, Contribution to 
Committee T1 – Telecommunications, Boulder Colorado, 
1999. 
[16] 
M. Omer, R. Nilchiani, and A. Mostashari, "Measuring the 
resilience of the global internet infrastructure system", 3rd 
Annual IEEE Systems Conference, March 2009, pp. 152-
162. 
[17] 
A. P. Snow and G. R. Weckman, "Trends in Local 
Telecommunication Switch Resiliency." In ICN 2014, The 
Thirteenth International Conference on Networks, pp. 178-
184. 2014. 
[18] 
A. P. Snow, G. R. Weckman, N. Gollamudi, J. C. Hoag, W. 
A. Young, "A Resiliency Assessment of Critical 
Telecommunication Infrastructure by FEMA Region: 
Empirical Metrics and Trends.", 13th Annual Conference on 
Telecommunications and Information Technology, ITERA 
2015. Unpublished.
 
19
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-550-0
CTRQ 2017 : The Tenth International Conference on Communication Theory, Reliability, and Quality of Service

