Discriminative Learning of Relevant Percepts for a
Bayesian Autonomous Driver Model
Mark Eilers
Human Centered Design
OFFIS Institute for Information Technology
Oldenburg, Germany
e-mail: mark.eilers@ofﬁs.de
Claus Möbus
Learning and Cognitive Systems
Carl-von-Ossietzky University
Oldenburg, Germany
e-mail: claus.moebus@uni-oldenburg.de
Abstract—Models of the human driving behavior are essential
for the rapid prototyping of assistance systems. Based on
psychological studies, various percepts and measures have been
proposed for the lateral and longitudinal control in driver
models without demonstrating the generalizability of results
to natural settings. In this paper, we present the learning of a
probabilistic driver model. It represents and mimics the lateral
and longitudinal human driving behavior on virtual highways
by performing situation-adequate lane-following, car-following,
and lane changing behavior. Because there is considerable
uncertainty about the relevant percepts in natural driving
behavior, we select hypothetically relevant percepts from the
variety of possibilities based on their statistical relevance.
This is a new approach to generate hypothesis about the
relevant percepts and situation-awareness of drivers in dynamic
trafﬁc scenes. The percepts are revealed in a structure-learning
procedure using a discriminative scoring criterion based on
the Bayesian Information Criterion. Discriminative learning
maximizes the conditional likelihood of probabilistic models,
whereas the traditional generative learning maximizes the
unconditional likelihood. This way, it attempts to ﬁnd the
structure with the best performance for the intended use, which
in our application is the best prediction of driving actions given
the available percepts.
Keywords–Probabilistic Driver Models; Bayesian Autonomous
Driver Models; Machine-Learning; Structure-Learning; Discrim-
inative Learning.
I.
INTRODUCTION
The Human Centered Design of intelligent transport
systems requires computational models of human behavior
and cognition. Particularly models of the human driving
behavior (i.e., driver models) are essential for the rapid
prototyping of error-compensating assistance systems [1].
Various authors proposed control-theoretic models (e.g.,
[2]), closely related perception-action models (e.g., [3][4]),
and production-system models implemented in cognitive
architectures (e.g., [5]). Due to the variability of human
cognition and behavior, the irreducible lack of knowledge
about underlying cognitive mechanisms, and the irreducible
incompleteness of knowledge about the environment [6],
we conceptualize, estimate, and implement models of hu-
man drivers as probabilistic models: Bayesian Autonomous
Driver (BAD) models.
In earlier research [7], we developed a BAD model
with Dynamic Bayesian Networks (DBNs), based on the
assumption that a single DBN representing a single skill is
sufﬁcient for lateral and longitudinal control. Later, we re-
alized that for modeling the complex competence of human
drivers, a skill hierarchy (e.g., Figure 1) is necessary. We
developed a hierarchical modular probabilistic architecture
that allows to construct driver models by decomposing
complex behaviors into pure behaviors and vice versa:
Bayesian Autonomous Driver Mixture-of-Behaviors (BAD
MoB) models [8][9][10].
Based
on
psychological
studies
(e.g.,
[11][12][13]
[14][15]), various percepts and measures have been recom-
mended for the lateral and longitudinal control in driver
models. These proposals are partly contradictory and often
depend on special experimental settings, like straight roads,
winding roads, low speed, and/or the absence of other trafﬁc
participants. Other and more natural scenarios may provide
and require different perceptual cues that are not yet fully
understood or formalized. A general computational vision
theory of driving behavior is still pending.
Because there remains considerable uncertainty about the
relevant percepts in natural driving behavior, we propose the
use of structure-learning procedures to select hypothetically
relevant percepts from the variety of possibilities based on
their statistical relevance. We used the proposed procedure
to learn the relevant percepts for a BAD MoB model that
represents and mimics the lateral and longitudinal human
driving behavior on virtual two-lane highways according
to the skill hierachy shown in Figure 1. We assume that
the overall complex driving behavior can be decomposed
into the simpler behaviors lane-following, car-following,
performing lane changes to the left and lane changes to the
right.
Highway
Lane-Following
Car-Following
Lane
Change Left
Lane Change
Right
Figure 1.
Skill hierarchy representing the human driving behavior on
virtual two-lane highways.
19
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

The paper is organized as follows. In the following
section we give a brief overview of percepts and measures
that have been recommended in the literature for modeling
the lateral and longitudinal human control behavior. Section
III introduces the fundamentals of BAD MoB models. In
Section IV, we describe a structure-learning procedure for
selecting the pertinent percepts from a universe of hypotheti-
cally available percepts, using a discriminative version of the
Bayesian Information Criterion. In Section V, we present a
resulting BAD MoB model that mimics the human driving
behavior on virtual highways and discuss the meaningfulness
of the learned percepts with respect to the literature. Finally,
we conclude with Section VI.
II.
A UNIVERSE OF PERCEPTS
For the most part, the literature considers three types
of percepts as important for lateral control: bearing angles
[13][14][3][16], splay angles [13][14][17], and the optic ﬂow
[13][14][17] (Figure 2).
Bearing angles are deﬁned as the angles between the
driver’s heading (the driver’s body axis, assuming that he is
belted in) and the direction to speciﬁc reference points in the
driver’s ﬁeld of view (Figure 2a) [14]. If available, obvious
choices for such reference points are the lane edges. When
aligned with the course of the road, a conceivable strategy
for lane-keeping on a straight path is to keep the bearing
angle to a reference point on the left lane edge and the
bearing angle to a reference point on the right lane edge
constant [14].
Bearing angles to single reference points that drivers tend
to visually target are also known as visual direction angles
[13]. Notable proposed examples for such targeted reference
points are points on the future path of the driver, the
centerline, lead-cars, and for curved roadways, the tangent
point [3][18][19].
Splay angles are deﬁned as the optical projections of
lane edges or the centerline around a reference point on the
driver’s retina relative to a vertical line in the driver’s ﬁeld of
view, e.g., the heading [14] (Figure 2b). Similar to bearing
angles, when aligned with the course of the road, a valid
strategy for lane-keeping would be to keep the splay angle
to the left lane edge and the splay angle to the right lane
edge constant.
The optic ﬂow denotes the global image motion of the
environment projected on the retina when one moves in the
world [14][16]. Similar to bearing and splay angles, we can
deﬁne ﬂow angles as the angles between the driver’s heading
and the direction of the optic ﬂow of reference points in the
driver’s ﬁeld of view (Figure 2c). A simple strategy for lane-
keeping using the optic ﬂow would be to align the focus of
expansion (speciﬁed by the intersection of two ﬂow angles)
with the intended target direction.
For longitudinal control, the literature mainly discusses
the time-to-contact/collision (TTC) [13][20][21] and the
time-headway (THW) [21][22]. The TTC of a vehicle A
with a speed vA, following a vehicle B with a speed vB,
in a distance d, is deﬁned as TTC = d/(vA − vB) and
denotes the remaining time until A reaches B. As a special
case of the TTC, the THW denotes the remaining time until
A will reach the current position of B and is deﬁned as
THW = d/vA.
III.
BAYESIAN AUTONOMOUS DRIVER
MIXTURE-OF-BEHAVIOR MODELS
Throughout this paper, we will be concerned with prob-
ability distributions over sets of discrete random variables.
Variables and set of variables will be denoted by capital let-
ters, while speciﬁc values taken by those (sets of) variables
will be denoted by lowercase letters. For time series, we
assume that the timeline is discretized into time-slices with
a constant granularity of 50ms. We will index these time-
slices by non-negative integers and will use Xt
i to represent
the instantiation of a variable Xi at time t. A sequence
Xj
i , Xj+1
i
, . . . , Xk
i will be denoted by Xj:k
i
and we will
use the notation xj:k
i
for an assignment of values to such
sequences.
A Bayesian Network (BN) is an annotated directed
acyclic graph (DAG) that encodes a joint probability over
a set of variables X = {X1, . . . , Xn} [23]. Formally, a
Bayesian Network B is deﬁned as a pair B = {G, θ}.
The component G is a DAG, whose vertices correspond to
the random variables X1, . . . , Xn, and whose arcs deﬁne
the (in)dependencies between these variables, in that each
variable Xi is independent of its non-descendants given
its (possibly empty) set of parents Pa (Xi) in G. The
component θ represents a set of parameters that quantiﬁes
the probabilities of the network. We assume that θ contains a
parameter θx|pa(X) = P (x|pa (X)) for each possible value
x ∈ X and pa (X) ∈ Pa (X). Given G and θ, a Bayesian
network B deﬁnes a unique joint probability distribution
(JPD) over X as:
PB (X) =
n
Y
i=1
P (Xi|Pa (Xi)) .
(1)
DBNs extend BNs to model the stochastic evolution
of a set of variables X = {X1, . . . , Xn} over time [24].
A DBN D is deﬁned as a pair D =

Heading
A
B
(a)
Heading
A
B
(b)
Heading
A
B
(c)
Figure 2.
Illustration of bearing angles (a), splay angles (b) and ﬂow angles (c).
Let A denote a set of discrete random variables rep-
resenting the lateral and longitudinal control actions of a
driver. In this paper, we assume the use of steering wheel
angles for lateral control and the position of a combined
acceleration and braking pedal for longitudinal control. P =
{P1, . . . , Pm} denotes a set of discrete random variables
representing hypothetical percepts that could be available to
the driver due to foveal and ambient vision [25]. Given a skill
hierarchy, decomposing a complex behavior in a number of
n simple behaviors, B denotes a discrete random variable
with n values for the n simple behaviors.
We assume, that the sensor-motor schema of each of the
n simple behaviors in the skill hierarchy can be modeled
by a distinct DBN πi that deﬁnes a JPD Pπi

IV.
LEARNING BAD MOB MODELS
We derive the structures of component-models by a
machine-learning method, based on the score and search
paradigm, where a search in the space of possible graph
structures is guided by a scoring function that evaluates the
degree of ﬁtness between the model and a set of experi-
mental data. From a Bayesian perspective such a scoring
criterion can be deﬁned as P (Gπ|δ), the probability of a
graph structure Gπ of a model π given a dataset δ [23].
Using the Bayes’ rule, P (Gπ|δ) is given by:
P (Gπ|δ) = P (δ|Gπ) P (Gπ) /P (δ) ,
(6)
where P (δ|Gπ) is the likelihood of the data given the
graph structure, P (Gπ) is a prior over possible graph
structures, and P (δ) is a constant that does not depend on
the actual graph structure and can therefore be neglected
[23]. The likelihood of the data given a graph structure can
be computed by integrating over all possible parameters θπ
of π [23][24]:
P (δ|Gπ) =
Z
P (δ|Gπ, θπ) P (θπ|Gπ) dθπ,
(7)
where P (δ|Gπ, θπ) is the likelihood of the data given π and
P (θπ|Gπ) is a prior distribution over the possible parameter
values for a graph structure Gπ. A common approach for
evaluating the integral, is to use an approximation derived
from the asymptotic behavior of (7) for inﬁnite datasets,
which results in a scoring criterion known as the Bayesian
Information Criterion (BIC) [23][24][27][28].
Although their structure is ﬁxed, we derive our structure-
learning approach for component-models from the hypo-
thetically learning of BAD MoB models. Let δ denote a
complete database consisting of n samples δi = (ai, bi, pi),
ˆθπ denote the maximum likelihood estimator, and Dim [π]
denote the number of independent parameters, the BIC score
for a BAD MoB model π is deﬁned as:
BIC (Gπ : δ) = log P

δ|Gπ, ˆθπ

− Dim [π]
2
log n.
(8)
For
a
BAD
MoB
model
π,
the
log-likelihood
log P(δ|Gπ, ˆθπ) is given by log Pπ(a1:n, b1:n, p1:n : ˆθπ) (in
X1
Xt−1
Xt
P 1
1
P t
1
...
...
P 1
i
P t
i
P 1
i+1
P t
i+1
...
...
P 1
m
P t
m
PR
PI
Figure 3.
Schematic structure of action- and behavior-classiﬁcation-
models, deﬁned by a BN and a 2TBN.
the following we will drop ˆθπ for clarity). Using (3) this can
be rewritten as a sum of terms:
log Pπ

the graph from Xt to P t
j (therefore replacing P

TABLE I.
PERTINENT PERCEPTS FOR ACTION-MODELS REPRESENTING THE BEHAVIORS FOR LANE-FOLLOWING,
CAR-FOLLOWING, LANE CHANGES TO THE LEFT, AND LANE CHANGES TO THE RIGHT.
Behavior
Relevant Percepts for Lateral Control
Relevant Percepts for Longitudinal Control
Lane-following
1. Bearing angle between the heading and a reference point on the
middle of the driver’s lane in a distance of vego · 5s
1. Speed potential
Car-following
1. Flow angle between heading and the optic ﬂow direction of a
reference point on the centerline in a distance of vego · 3s
1. TTC to the lead-car (bumper-to-bumper distance, allowing
positive and negative values)
Lane changes to the left
1. Bearing angle between the heading and a reference point on the
middle of the right lane in a distance of 100m
1. TTC to the lead-car on the fast lane (bumper-to-bumper distance,
only positive values)
2. Bearing angle between the heading and a reference point on the
left lane edge in a distance of vego · 2s
Lane changes to the right
1. Flow angle between the heading and the optic ﬂow direction of
a reference point on the middle of the right lane in a distance of
75m
1. TTC to the lead-car on the fast lane (bumper-to-bumper, only
positive values)
2. Bearing angle between the heading and a reference point on the
right lane edge in a distance of vego · 3s
3. TTC to the lead-car on the fast lane (bumper-to-bumper distance,
allowing positive and negative values)
4. TTC from the car behind on the slow lane (Euclidean distance,
only positive values)
between the driver’s heading and a reference point on the
middle of the driver’s lane in a distance of vego · 5s. Under
the assumption that the middle of the lane can be seen as an
approximation of the future path of the driver, this percept is
consistent with the proposals of [13] for roads with gentle
curvatures, and ﬁndings of [19] and [32], who report that
drivers often ﬁxate the center of the road resp. the future
path. In contrast, the far point, as proposed by [3] for lane-
following, was only the 114th highest-rated percept.
The single relevant percept selected for the longitudinal
control represents the speed potential. This seems reason-
able, as it should be sufﬁcient for a driver to keep an intended
target speed as implied by the current speed limit. However,
as German trafﬁc rules prohibits to overtake on the right,
we expected a second percept, associated with the lead-car
on the lane left to the driver. Indeed, the percept that would
have been selected as the second relevant percept (but was
rejected due to the increasing penalty) represents the distance
to the lead-car on the fast lane.
2) Car-Following: The single percept learned for the
lateral control in car-following represents the angle between
the driver’s heading and the optic ﬂow direction of a
reference point on the centerline in a distance of vego · 3s.
This is in contrast to [33], who found that drivers tend to
primarily ﬁxate the lead-car during car-following. Based on
these ﬁndings, [3] concluded that in the presence of a lead-
car, the lead-car would act as the primary reference point
and consequently proposed the angle between the heading
and the lead-car as the most relevant percept for lateral
control during car-following. Maybe surprisingly, this angle
was only the 353th best-rated percept.
However, the single relevant percept for longitudinal
control in car-following represents the TTC to the lead-car.
This is consistent with the proposals of [20] and [21] and
would imply that the driver indeed primarily focuses the
lead-car. Our model would therefore imply that during car-
following, the driver primarily depends on ambient vision for
lateral control, while using the foveal vision for longitudinal
control.
3) Lane Changes: For the lateral control during lane
changes to the left, two percept were selected. They rep-
resent the bearing angle to the middle of the right lane in
a distance of 100m and the bearing angle to the left lane
edge in a distance of vego · 2s. These percepts are consistent
with ﬁndings of [34], who report that during lane changes to
the left lane, drivers direct their gazes primarily and almost
equally to the left and the right lane.
In contrast, during lane changes to the right, drivers
direct the majority of their gazes to the right lane, while
dividing the rest of their gazes equally between the left
lane and the mirror [34]. As shown in Table I, the selected
percepts are indeed consistent with these ﬁndings. The
two most relevant percepts represent the angle between the
heading and the optic ﬂow direction of a reference point on
the middle of the right lane and the bearing angle between
the heading and a reference point on the right lane edge.
The third percept represents the TTC to the lead-car on the
fast lane, which implies a certain attention to the left lane.
The last percept represents the TTC to the car behind on the
slow lane, which implies a certain attention to the mirror.
Concerning the longitudinal control, for both lane
changes to the left and to the right, the single selected
percept represents the TTC to the lead-car on the fast
lane. This may be explained by a rare and unpredictable
tendency of non-controlled trafﬁc participants to surprisingly
and recklessly change lanes, which enforced the participant
to perform all-out brakings during lane changes. However,
this also gives us a hint to explore the use of separated skill
hierarchies for lateral and longitudinal control in our future
research.
VI.
CONCLUSION
We presented the learning of a hierarchical and modular
probabilistic driver model that represent and mimics the lat-
eral and longitudinal human driving behavior on virtual high-
ways. Its relevant percepts were selected in a discriminative
structure-learning procedure from a set of hypothetical per-
cepts proposed in literature. The performance of the learned
BAD MoB model is very promising (videos available at
24
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

http://www.lks.uni-oldenburg.de/46350.html). The selected
percepts are sufﬁcient for the modeling and simulation of the
lateral and longitudinal human driving behavior on virtual
highways, including situation-adequate lane-following, car-
following, and lane changing behavior. The selected percepts
seem reasonable and for the most part consistent with ﬁnd-
ings reported in psychological studies. This indicates that the
proposed method can be used to generate hypothesis about
the relevant percepts and situation-awareness of drivers in
dynamic trafﬁc scenes to be validated by experiments with
human drivers.
In our future work, we will expand our selection of
hypothetical percepts and will explore the use of different
and separated skill hierarchies for lateral and longitudinal
control.
ACKNOWLEDGMENT
This work has been supported by the projects IMoST2
(Integrated Modeling for Safe Transportation II), sponsored
by the Government of Lower Saxony, Germany under con-
tracts ZN2245, ZN2253, ZN2366, and the project HoliDes
(Holistic Human Factors and System Design of Adap-
tive Cooperative Human-Machine Systems), funded by the
ARTEMIS Joint Undertaking Grant agreement no.: 332933.
REFERENCES
[1]
C. Cacciabue, Ed., Modelling Driver Behaviour in Automotive En-
vironments: Critical Issues in Driver Interactions with Intelligent
Transport Systems.
Springer, 2007.
[2]
T. Jürgensohn, Modelling Driver Behaviour in Automotive Environ-
ments.
Springer, 2007, ch. Control Theroy Models of the Driver,
pp. 277–292.
[3]
D. Salvucci and R. Gray, “A two-point visual control model of
steering,” Perception, vol. 33, 2004, pp. 1233–1248.
[4]
R. Wilkie and J. Wann, “Controlling steering and judging heading:
Retinal ﬂow, visual direction and extra-retinal information,” Journal
of Experimental Psychology: Human Perception and Performance,
vol. 29, 2003, pp. 363–378.
[5]
D. Salvucci, Integrated Models of Cognitive Systems.
New York:
Oxford University Press, 2007, ch. Integrated Models of Driving
Behavior, pp. 356–367.
[6]
P. Bessière, C. Laugier, and R. Siegwart, Eds., Probabilistic Rea-
soning and Decision Making in Sensory-Motor Systems.
Berlin:
Springer, 2008.
[7]
C. Möbus and M. Eilers, “Further steps towards driver modelling
according to the Bayesian programming approach,” in Digital Human
Modeling, ser. LNCS (LNAI).
San Diego: Springer, 2009, pp. 413–
422.
[8]
C. Möbus and M. Eilers, “Mixture of behaviors and levels-of-
expertise in a Bayesian autonomous driver model,” in Advances in
Applied Digital Human Modeling, V. Duffy, Ed.
Boca Raton: CRC
Press, Taylor & Francis Group, 2010, pp. 425–435.
[9]
M. Eilers and C. Möbus, “Learning of a Bayesian autonomous driver
mixture-of-behaviors (bad-mob) model,” in Advances in Applied
Digital Human Modeling, V. Duffy, Ed.
Boca Raton: CRC Press,
Taylor & Francis Group, 2010, pp. 436–445.
[10]
M. Eilers and C. Möbus, “Learning the relevant percepts o modular
hierarchical Bayesian driver models using a Bayesian information
criterion,” in Digital Human Modelling, ser. LCNS 6777, V. Duffy,
Ed.
Heidelberg: Springer, 2011, pp. 463–472.
[11]
M. Chattington, M. Wilson, D. Ashford, and D. Marple-Horvat,
“Eye-steerig coordination in natural driving,” Experimental Brain
Research, vol. 180, 2007, pp. 1–14.
[12]
M. Land, Vision and Action.
Cambridge: Cambridge University
Press, 1998, ch. The Visual Control of Steering, pp. 163–180.
[13]
M. Land and B. Tatler, Looking and Acting: Vision and eye move-
ments in natural behavior.
Oxford: Oxford University Press, 2009.
[14]
L. Li and J. Chen, “Relative contribution of optic ﬂow, bearing, and
splay angle information to lane keeping,” Journal of Vision, vol. 10,
2010, pp. 1–14.
[15]
R. Wilkie, D. Poulter, and J. Wann, “Where you look when you learn
to steer,” Journal of Vision, vol. 4, no. 8, 2004, doi:10.1167/4.8.1.
[16]
J. Wann and R. Wilkie, Optical ﬂow and beyond.
Norwell, MA,
USA: Kluwer Academic Publishers, 2004, ch. How do we control
high speed steering?, pp. 401–419.
[17]
A. Chatziastros, G. Wallis, and H. Bülthoff, “The use of optical ﬂow
and splay angle in steering a central path,” Max Planck Institute for
Biological Cybernetics, Tübingen, Germany, Tech. Rep. 71, October
1999.
[18]
M. Land and D. Lee, “Where we look when we steer,” Nature, vol.
369, 1994, pp. 742–744.
[19]
O. Lappi, E. Lehtonen, J. Pekkanen, and T. Itkonen, “Beyond the
tangent point: Gaze targets in naturalistic driving,” Journal of Vision,
vol. 13, 2013, pp. 1–18.
[20]
D. Lee, “A theory of visual control of braking based on information
about time to collision,” Perception, vol. 5, 1976, pp. 437–459.
[21]
W. van Winsum, “The human element in car following models,”
Tranportation Research Part F, vol. 2, 1999, pp. 207–211.
[22]
M. Gouy, C. Diels, N. Reed, A. Stevens, and G. Burnett, “Preferred
or adopted time headway? A driving simulator study,” in Proceedings
of the International Conference on Ergonomnics & Human Factors,
M. Anderson, Ed., 2013, pp. 153–159.
[23]
D. Koller and N. Friedman, Probabilistic Graphical Models: Princi-
ples and Techniques.
MIT Press, 2009.
[24]
N. Friedman, K. Murphy, and S. Russell, “Learning the structure
of dynamic probabilistic networks,” in Proceedings of the 14th
conference on Uncertainty in artiﬁcial intelligence, 1998, pp. 139–
147.
[25]
W. Horrey, C. Wickens, and K. Consalus, “Modeling driver’s visual
attention allocation while interacting with in-vehicle technologies,”
Journal of Experimental Psychology, vol. 12, no. 2, 2006, pp. 67–78.
[26]
P. Bessière et al., “Survey: Probabilistic methodolgy and techniques
for artefact conception and development,” INRIA - Institut National
de Recherce en Informatique et en Automatique, Tech. Rep., 2003.
[27]
G. Schwarz, “Estimating the dimension of a model,” Ann. Stat.,
vol. 6, 1978, pp. 461–464.
[28]
K. Murphy, Machine Learning: A Probabilistic Perspective.
The
MIT Press, 2012.
[29]
Y. Guo and R. Greiner, “Discriminative model selection for belief
net structures,” in Proceedings of the 20th National Conference on
Artiﬁcial Intelligence, 2005, pp. 770–776.
[30]
S. Natarajan, W.-K. Wong, and P. Tadepalli, “Structure reﬁnement
in ﬁrst order conditional inﬂuence language,” in Proceedings of
the Workshop on Open Problems in Statistical Relational Learning
(SRL), 2006, 8 pages.
[31]
G. Santafe, J. Lozano, and P. Larranaga, “Discriminative vs. gener-
ative learning of Bayesian network classiﬁers,” in ECSQARU 2007,
ser. LNAI 4724, K. Mellouli, Ed.
Berlin, Heidelberg: Springer,
2007, pp. 453–464.
[32]
R. Wilkie and J. Wann, “Eye-movements aid the control of locomo-
tion,” Journal of Vision, vol. 3, no. 11, 2003, pp. 677–684.
[33]
D. Salvucci, E. Boer, and A. Liu, “Toward an integrated model of
driver behavior in a cognitive architecture,” Transportation Research
Record, vol. 1779, 2001, pp. 9–16.
[34]
D. Salvucci and A. Liu, “The time course of a lane change: Driver
control and eye-movement behavior,” Tranportation Research Part F,
vol. 5, 2002, pp. 123–132.
25
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

