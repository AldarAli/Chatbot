 
1 
A Three-Dimensional Interactive Simulated-Globe System Application in Education 
 
Wei-Kai Liou 
Science Education Center and Graduate Institute of Science 
Education, National Taiwan Normal University,  
 Taipei, Taiwan(R.O.C) 
 Email: liouweik@ntnu.edu.tw 
 
 
  
Chun-Yen Chang  
Science Education Center and Graduate Institute of Science 
Education and Department of Earth Sciences,  
National Taiwan Normal University,  
 Taipei, Taiwan(R.O.C) 
 Email: changcy@ntnu.edu.tw 
 
 
Abstract 
This study proposes an innovative three-dimensional (3D) 
Interactive 
Simulated-Globe 
System 
application. 
The 
instrument includes: a data processing unit, a wireless control 
unit, an image capturing unit, a laser emission unit as well as 
3D hemispheric body imaging. The 3D hemispheric body 
imaging is designed to display the output image from a data 
processing unit. The Laser emission unit is for emitting a laser 
spot on the output image. Based on the spherical coordinates of 
the laser spot, detected by a data processing unit through an 
image capture unit, the spherical coordinates, with a plane 
coordinates converter operation, can provide spherical 
coordinates to convert into plane coordinates for the data 
processing unit. Utilizing the coordinates location, of the laser 
spot through image acquisition, calibration and internal 
coordinates with external coordinate converter operation can 
be guided the cursor, output by the data processing unit on 3D 
hemispheric body to launch synchronous movement with laser 
spot. To combine wireless control technology can perform 
synchronous driven, control and interactive with the software 
image on 3D hemispheric body. This work allows general 
planet software such as Google Earth (Mar, Moon), used in a 
variety of panel displays or projection turn into the 3D 
hemispheric body, and then through the laser spot emitted by 
the laser emission unit and wireless control unit, allows the 
laser spot in synchronization to control the cursor and 
software on the 3D hemispheric body imaging for a variety of 
interactive, and then perform the effect of 3D interactive globe 
system in any classroom or astronomical Museum for formal  
and Social education. 
Keywords-three-dimensional; interactive; spherical coordinates; 
internal coordinates; external coordinate  
I. 
 INTRODUCTION  
The various sizes of earth or planet instrument models have 
been widely used in traditional classroom and astronomical 
museums; they have become an integral part of teaching 
aids for formal or informal education teaching field. [1-3] In 
recent years, related inventions have attempted to use 
projection to project earth or other planets software images 
as digital teaching auxiliary aids. [4-6] However, the way to 
project earth or other planets software image on the screen 
is not much difference to use traditional earth or planet 
instrument for the teacher in the teaching and can not to 
fully demonstrate the advantages of digitization teaching 
aids in this way. Therefore, we propose a kind of earth or 
planet instrument, which can take advantage of simple 
technology and classroom existing equipment. This 
instrument is employed to project the earth or other planets 
images as three-dimensional sphere surfaces. By forming 
3D earth or plants images, and utilizing the interactive 
technology of this work, the operator can use a simply 
handheld wireless control device to interact and synchronize 
control the cursor and function then perform the effect of an 
3D interactive globe system. 
 
II. 
RELATED WORK 
 
Existing applications of laser guidance technology, U.S. 
Patent No. 6,275,214 [7], use a variety of different light 
sources for projection to projection curtain via the camera 
receives images. Through image processing and computer 
software program calculated the light projected onto the 
screen spot position of the projection screen to convert the 
signal to control a computer mouse cursor moves. The 
existing the whiteboard also uses the image capture element 
to achieve method (internal coordinates based on the 
coordinates of the image input is converted to the 
coordinates of the external programs and methods), in U.S. 
Patent No. 4,507,557 [8]. At present, the 3D image 
projection method synchronizes the projector in a different 
direction and position on the respective image in a 3D 
sphere. The corresponding image project on a spherical 
surface according to each specific projector to multiple 
projectors, each represents a specific image region of the 
sphere to generate a complete surface projection mapping 
imaging such as U.S. Patent No.0,256,302 [9]. Other 
method as 3D internal back projection methods, this method 
is to use the projector image, projected to an inner surface of 
the 3D projection surface. The formation of the 3D 
projection surface outside observer can see the imaging. 
Application examples are celestial bodies such as the earth, 
the planets and the anatomical organs in detail, such as the 
U.S. Patent No. 8,066,378 [10]. A 3D convex surface of the 
194
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
2 
display system is the system's display surface having a 3D 
convex shape. Projector system sucked image output to the 
internal display surface of the display surface, the image due 
to the convex shape of the display so that the viewer can see 
the 3D stereo images. For details is on U.S. Patent No. 
7,352,340 [11]. The 3D internal projection system is to use 
optical scanning or projection, projected on a large 3D 
objects on the inner surface, so that when viewed by an 
external stereoscopic imaging effect, such as the U.S. Patent 
No. 0,027,622 [12]. 
 
III. 
PROPOSED THEOREM 
 
This research main technology is divided into two parts. The 
first part is laser guide technology to control cursor. For 
controlling the cursor directional control function, it needs 
to install a laser emitter source and utilizes an optical 
camera with special light filter lens receiver to detect the 
laser source on the screen. After some image process and  
the spherical coordinates with plane coordinates converter 
operation, the movement of image can be transformed by a 
cursor command to guide the cursor directional control 
function. The second part is to install a wireless control 
electron circuit in our system. By linking the wireless 
control technology, it can direct execute each kind of 
interactive control function completely.  
A. Image acquisition 
 
The 3D hemispheric body imaging is to display the output 
image from data processing unit as shown in Figure 1. Laser 
emission unit is for emitting laser spot imaging on 
hemispheric body and the spherical coordinates of laser spot 
was detected by a data processing unit through the image 
capture unit. The key point of image acquisition technology 
in this study is the red visible light filter when an optics 
camera is used. This kind of special light filter lens may 
filter the Blue and Green visible light on the 3D hemispheric 
body imaging effectively, and causes optics photography 
function effective to trace the laser emitter spot on the three-
dimensional imaging hemispheric body. The wherefores is 
red visible light filter lens make whole image and 
background turn  into full red view. And it is because the 
wavelength of red laser spot is higher than any visible red 
color. When using this spot tracking can provide spherical 
coordinates of laser spot precisely. 
 
B. The spherical coordinates with plane coordinates 
converter operation 
 
Laser emission unit is for emitting laser spot imaging on 
hemispheric body. Based on the spherical coordinates of 
laser spot, detected by a data processing unit through the 
image capture unit and the spherical coordinates with plane 
coordinates converter operation can make spherical 
coordinates convert into plane coordinates for the data 
processing unit. By the coordinates location of the laser spot 
through 
image 
acquisition, 
calibration 
and 
internal 
coordinates with external coordinate converter operation can 
be guided the cursor, output by the data processing unit on 
3D hemispheric body imaging to launch synchronous 
movement with laser spot as shown in Figure 2. The 
formula of spherical coordinates convert into plane 
coordinates as follow: 
 
 
 
 
 
On the contrary, formula of plane coordinates convert into 
spherical coordinates as follow: 
 
 
 
 
 
C. Wireless control technology 
 
By wireless control technology, this work can perform 
control and interactive with the software image on 3D 
hemispheric body imaging. We have succeeded to develop a 
useful technique for the classroom and museum, and have 
obtained the solution of the man-machine interface for its 
interactive operations. A three-dimensional interactive globe 
system was proposed in this study. This invention makes 
general planet software, used in a variety of panel displays 
or projection turn into the 3D hemispheric body imaging. 
Through the laser spot emitted by the laser emission unit 
and wireless control unit, allows the laser spot to 
synchronize control the cursor and software on the 3D 
hemispheric body imaging for a variety of interactive. Then 
perform the effect of 3D interactive globe system in 
education. 
 
IV. 
IMPLEMENTATION 
 
A. System installation 
Figure 3 shows the schematic diagram of 3D interactive 
simulated-globe system. In this figure, the system contains 
information processing unit, image capture Unit, a three-
dimensional imaging hemispheric body, laser emitting unit 
and wireless control unit. The 3D hemispheric body 
imaging is to display the output image from data processing 
unit. The operator held a laser emission unit for emitting 
195
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
3 
laser spot on imaging hemispheric body in front of 
hemispheric. The laser spot position was detected by a data 
processing unit through the image capture unit. By program 
operation can drive the control cursor on 3D hemispheric 
body imaging to execute simultaneous movement with laser 
spot. Wireless control unit is a device, installed a wireless 
control electron circuit inside. Each button has unique 
command 
function 
for 
remote 
control 
information processing unit then can perform control 
command function. By simple technology and classroom 
existing equipment, this system shows an effect solution for 
interactive of three-dimensional interactive globe system.  
 
B. Calibration 
 
The data processing unit by the image capture unit to detect 
five laser spots on the 3D hemispheric body imaging in 
sequence at initial. Based on the five laser spot localization 
method by internal plant coordinates with external spherical 
coordinates conversion program operator can calibrate the 
coordinate of control cursor on the imaging hemispheric 
body at the outset. Every point for calibration takes 
approximately a few seconds for each. That is followed by a 
defined sequence for completing five points calibration. 
When each point is captured by the camera the tracking 
process can be started, the cursor tracking is set up 
completely. By this five laser spot localization method, the 
control cursor on the imaging sphere can launch 
synchronous movement with laser spot precisely.  
 
C. Interactive control 
To combine laser guide technology and wireless control 
technology, this work can fully demonstrate the advantages 
of digitization 3D interactive simulated-globe teaching aids 
in this study. For example: the operator can rotate the earth 
or the planet, drag, draw, click, move, zoom in and zoom 
out any icon or function to directly interactive with 3D 
simulated-globe as show in Figure 4. Whenever to control 
the laser spot, stopped at the desired tap objects imaging on 
3D simulated-globe then continuously pressing left mouse 
button function key on handheld device and we can perform 
a drag function in this system as we want.  If we want to 
rotate this 3D simulated-globe, we only have to control the 
laser spot in any position on the globe and to press left 
mouse button function key on handheld device and quick 
move to left or right then release the button at the same time. 
The 3D simulated-globe will continuous rotate following by 
our movement speed and direction until the laser spot on 
globe and to press left mouse button function key again to 
stop it. 
As we want to select any objects or icons on the 3D 
simulated-globe, the laser spot pointed objects or icons and 
click left mouse button function key on handheld device and 
the objects or icons will be selected. The zoom function in 
our system is to point the laser spot on the desired imaging 
objects and click left mouse button function key on 
handheld device to select an objects. Then subsequently 
press the zoom in or zoom out function button on handheld 
device issued the command to control zoom the desired 
imaging objects on 3D simulated-globe. Based on zoom 
function in this study, the pointed object by the laser spot on 
globe will be enlarged or reduced as we want. Such as when 
forward mouse wheel or key in PgUp is making a selected 
object to enlarge. On the contrary, backward mouse wheel 
or key in PgDn is making the selected objects to shrink. 
With drag and click function as mention above, we also can 
use drawing software to draw any sign, mark, emblem, label 
and symbol on the 3D simulated-globe. 
 The operation of the present study described as follow: 
First step, the data processing unit output the image on 
hemispheric body by a projector as shown in Figure 4. 
Subsequently, an operator held a device, integrated by the 
laser emitting unit and the wireless control unit. After, the 
operator points to the laser spot on an imaging hemispheric 
body. Then, the coordinate position of laser spot on the 
imaging hemispheric body was detected through the image 
capture unit. At the same time, data processing unit 
executed the internal coordinates with external coordinate 
converter operation and calibration. By laser-guided control 
program and the five points calibration program, enables the 
control cursor on the imaging hemispheric body can be 
synchronized movement with laser spot. With conjunction 
laser emission and wireless control units, the laser spot can 
synchronous drive the 3D simulated-globe by control cursor 
movement and issued a variety of computer command 
function. Finally, this work complete and achieve an 
efficient and economical interactive simulated- globe 
system. 
   
V. 
CONCLUSIONS 
This work can take advantage of simple technology and 
classroom existing equipment to employ project the earth or 
other planets software the images in three-dimensional 
sphere surface, thereby forming a three-dimensional earth or 
plants images. By use the interactive technology of this 
work could make general planet software, used in a variety 
of panel displays on the projection turn into the three-
dimensional imaging sphere. Through the laser spot emitted 
by the laser emission unit and wireless control unit, allows 
the laser spot synchronization to control the cursor and 
software on the three-dimensional imaging sphere for a 
variety of interactive, and then perform the effect of three-
dimensional interactive globe system in any classroom or 
astronomical museum for formal and social education. We 
have succeeded to develop a useful technique for the 
classroom and museum, and have obtained the solution of 
the man-machine interface for its interactive operations. 
196
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
4 
ACKNOWLEDGMENT 
The authors wish to thank the Aim for the Top University 
(ATU) project of the National Taiwan Normal University 
(NTNU) for financing this study. 
REFERENCES 
 
[1] Albanese, A., Neves, M. C. D., & Vicentini, M. （1997）. Models in 
science and in education: Acritical review of research on students' 
ideas about the earth and its place in the universe. Science and 
Education, 6, 573-590. 
[2] Crews, W. E. （1990）. Development of a paper-and-pencil 
instrument to elicit student conceptsconcerning the earth as a planet. 
Paper presented at the Annual Meeting of the NationalAssociation for 
Research in Science Teaching. （ERIC Document Reproduction 
Service No. ED324 191） 
[3] Vosniadou, S., & Brewer, W. F. （1994b）. Mental models of the 
earth: A study of conceptual change in childhood. Cognitive 
Psychology, 24, 535-585. 
[4] Bednarz, S. W. (2004). Geographic Information Systems: A Tool to 
Support Geography and Environmental Education?, GeoJournal, 60, 
191-199. 
[5] Butler, D. (2006). Virtual globes The web-wide world, Nature 
Publishing Group, 439,776-778. 
[6] Demirci, A. (2009). How do Teachers Approach New Technologies 
Geography Teachers’ Attitudes towards Geographic Information 
Systems (GIS), European Journal of Educational Studies, 1(1), 43-53. 
[7] Computer presentation system and method with optical tracking of 
wireless pointer, U.S. Patent No. 6,275,214.  
[8] Non-contact X, Y digitizer using two dynamic ram imagers,U.S. 
Patent No. 4,507,557. 
[9] Three-Dimensional(3D) image projection, U.S. Patent No. 0,256,302. 
[10] Three-Dimensional internal back-projection system and method for 
using the same, U.S. Patent No. 8,066,378. 
[11] Display system having a three-dimensional convex display 
surface ,U.S. Patent No. 7,352,340. 
[12] Three-dimensional internal projection system, U.S. Patent No.: 
0,027,622. 
 
 
  
 
Figure 1.  The 3D hemispheric body imaging is to display the output image from data processing unit 
 
 
Figure2.  Internal coordinates with external coordinate converter operation   
197
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
5 
 
Figure 3.  The schematic diagram of 3D interactive simulated-globe system 
 
 
 
Figure 4. The operator can rotate the earth or the planet, drag, draw , click, move, zoom in and zoom out any icon or function to directly 
interactive with 3D simulated-globe 
198
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

