Performance Bounds for Regular LDPC Codes
for Asymmetric Channels
P˚al Ellingsen
Department of Computing, Mathematics and Physics
Bergen University College
Bergen, Norway
Email: pal.ellingsen@hib.no
Abstract—It is well known that it is not possible to achieve capac-
ity on an asymmetric channel using an even input distribution. In
recent literature, complex code constructions has been proposed
that gives rise to uneven input distributions to the channel such
that capacity in theory can be achieved. However, it is of interest
to know how well we can do on these channels with ordinary,
linear codes due to the other desirable properties of such codes.
In this paper, density evolution for symbol dependent channels
is used in combination with a classical theorem by Gallager to
bound the performance of regular Low Density Parity Check
(LDPC) codes by showing that the check node degree of the
graph describing a regular LDPC code, must go to inﬁnity if
the code is to achieve capacity on the Z-channel. Based on
this, performance bounds for different check node degrees are
calculated, and it is also shown that this is only a problem for
small error probabilities.
Keywords–Asymmetric channel; Regular LDPC codes; Gal-
lager’s theorem
I.
INTRODUCTION
A binary asymmetric channel is a class of channels in
which the probability of symbol error depends on the input
symbol. In this paper, we will study a particular instance of
this class, namely the binary asymmetric channel where the
error probabilities of the two input values 0 and 1 are set to 0
and q as shown in Figure 1(a). This channel is also called the
the Z-channel.
0 •
1
/ • 0
1 •
1−q
/
♥♥♥♥♥q
♥
♥♥♥♥ 7♥
♥
• 1
(a) The Z-channel
0 •
1−q
/
PPPPPq
P
PPPP 'P
P
• 0
1 •
1−q
/
♥♥♥♥♥q
♥
♥♥♥♥ 7♥
♥
• 1
(b) The binary symmetric chan-
nel
Figure 1.
Channel models
Since the transition probabilities of the Z-channel are non-
equal, the capacity not only depends on the probability of bit
errors on the channel, but also on the input bit probability
to the channel. Binary asymmetric channels have received
considerable attention in classical coding theory, and many
important works on this topic were compiled by Kløve in
[1]. Since the introduction of iterative decoding, the coding
community has succeeded in making codes that approach the
Shannon bound on symmetric channels; meanwhile the relative
performance of the best known codes for asymmetric channels
has fallen behind. The cause for this has probably been the
fact that due to their symbol dependent nature, asymmetric
channels can not be analyzed using the techniques available
for symmetric channels like density evolution in its original
form. Further, the optimum input distribution actually depends
on the error probability of the channel so it is impossible
to achieve capacity on an asymmetric channel using a code
with an even input probability. Since all linear codes have
an even input distribution to the channel, capacity can not
be achieved using a linear code, further complicating the
task of approaching capacity on asymmetric channels. In this
paper, new performance bounds for such codes are found by
using a theorem by Gallager regarding the check node degree
distribution of LDPC codes on the binary symmetric channel,
and showing a similar result for the Z-channel. A necessary
property of regular LDPC codes that are to approach the
Shannon bound for all values of the error probability q is also
proved.
In the rest of this paper, some background material on
LDPC codes is ﬁrst presented in Section II, then the devel-
opment of the performance bound is given in Section III.
Results are analyzed in Section IV, and ﬁnally, conclusions
and possible future work are given in Section V and Section
VI.
II.
BACKGROUND
LDPC codes is a class of codes that uses belief propagation
to attain near-capacity decoding. The codes are sparse linear
block codes that may be pseudorandom or result of an explicit
construction. The code may be represented as a bipartite graph
construction called a Tanner graph (see Figure 2) where the
parity checks of are represented by ⊞ and the variable nodes
are represented by ⃝. The decoding can be viewed as message
passing on the same graph. Initially each variable nodes send
messages to its parity check nodes indicating the probability
of it being a +1 versus a −1. The check nodes returns the
probabilities from all its neighbors, except from the node itself.
The subsequent iterations proceeds analogously, except for that
the information passed form the variable nodes is based on
both the channel values and the information received in the
previous iteration.
Recently there has been some interest in the use of LDPC
codes for asymmetric channels. In [2] the use of LDPC codes
on the some types of binary input fading multiple access
channels (MAC) without channel state information (CSI) is in-
vestigated, while in [3], new code constructions are developed
7
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-455-8
CTRQ 2016 : The Ninth International Conference on Communication Theory, Reliability, and Quality of Service

⊞
⊞
⊞
· · ·
⃝
⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤
⃝
♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠
⃝
rrrrrrrrrrrrrrrrrrrrrrrrr
⃝
❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦❦
⃝
♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠
♠
❇❇❇❇❇❇❇❇❇❇❇❇❇❇❇❇❇❇
✌✌✌✌✌✌✌✌✌✌✌✌✌✌
⃝
▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲
⃝
✶✶✶✶✶✶✶✶✶✶✶✶✶✶
⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤⑤
⃝
✌✌✌✌✌✌✌✌✌✌✌✌✌✌
⃝
⃝
❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲❲
⃝
❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙❙
Figure 2.
Tanner graph
based on transforming LDPC codes designed for the Binary
Symmetric Channel (BSC) to bias the input distribution to
the channel. Lately Mondelli, Marco and Urbanke [4] studies
three different techniques designing concatenated codes with
optimum input distribution for binary asymmetric channels.
However, the bounds on performance of ordinary, regular
LDPC codes are also of great interest as these codes are well
known and widely used.
III.
PERFORMANCE BOUNDS
In his seminal paper “Low-Density Parity-Check Codes”,
Gallager [5] proved the following theorem which shows that
decoding error probability for the binary symmetric channel
is bounded away from 0 for all codes of rates above a
threshold that depends on the check node degree d of the graph
describing the code. We prove that there exists a similar bound
for the Z-channel when considering regular, linear codes, and
state as a corollary that as a consequence, the check node
degree must go to inﬁnity to achieve linear capacity for all
values of q.
Theorem 1 (Gallager). Let a regular parity check code of
length n and rate r with check node degree d be used on a
BSC with crossover probability q and let the codewords be
used with equal probability. Let
qd = 1 + (1 − 2q)d
2
.
(1)
Then
r > h(qd) − h(q)
h(qd)
,
(2)
where h(·) is the binary entropy function, implies that for
a ﬁxed d the probability of decoding error is bounded away
from 0 by an amount independent of n.
Proof: See [5].
With certain adaptations, Gallager’s theorem is also true
for the Z-channel.
Theorem 2. Let a linear, regular LDPC code of rate r and
length n with check node degree d be used on a Z-channel with
error probability q and assume the codewords are equiprobable.
If
qd = 1 + (1 − 2q)d/2
2
(3)
and
r > 2h(qd) − h(q)
2h(qd)
,
(4)
where h(·) is the binary entropy function, then the probability
of decoding error is bounded away from 0 by an amount
independent of n.
Proof: We will follow Gallager’s proof of Theorem 1
closely in the following. Let u be a transmitted codeword,
and let v be the received sequence. If we consider u and v
as instances of the variables U and V , the mutual information
between two variables U and V is given by
I(U; V ) = h(U) − h(U|V ) =
−
X
u
p(u) log(p(u)) +
X
u,v
p(u, v) log(p(u|v))
(5)
For simplicity, we will write P
u p(u) log(p(u)) = log(p(u))
and P
u,v p(u, v) log(p(u|v)) = log(p(u|v)). Then, the aver-
age mutual information per bit in a codeword can be written
1
nI(u, v)
=
− 1
nlog(p(u)) + 1
nlog(p(u|v))
(6)
or, by the symmetry of the mutual information function
1
nI(u, v)
=
− 1
nlog(p(v)) + 1
nlog(p(v|u))
(7)
The probability of decoding error is bounded away from 0
if there exists an ǫ independent of n for which the conditional
probability p(u|v) satisﬁes
1
nlog(p(u|v)) ≥ ǫ > 0
(8)
We will proceed to prove the existence of such an ǫ by
expanding the terms of equation (6).
The code has nr message bits, and thus there are 2nr mes-
sages in the code, so assuming the codewords are equiprobable
− 1
nlog(p(u))
=
− 1
n
X
u
p(u) log(p(u))
(9)
=
− 1
n
X
u
2−nr log(2−nr)
(10)
=
− 1
n2nr · 2−nr · (−nr)
(11)
=
r
For a linear code, the average weight of a codeword is n/2,
and since each 1-digit in the sequence u has probability q of
being different from the corresponding digit in v, the average
conditional probability p(v|u) is qqn/2(1 − q)(1−q)n/2. Then,
we can write
1
nlog(p(v|u))
=
1
n log(qqn/2(1 − q)(1−q)n/2)
(12)
=
1
n · n
2 (q log(q) + (1 − q) log(1 − q))
=
−h(q)
2
(13)
If we average over all parity checks, the weight of the
nodes involved in each parity check should be d/2. Now, the
probability that a parity check is satisﬁed is the probability that
an even number of errors have occurred in the d/2 1-nodes that
belongs to the parity check. If we sum over all even-number
error events we get the probability qd that a parity sums to 0.
qd
=
X
i even
d/2
i

qi(1 − q)d/2−i
(14)
=
1 + (1 − 2q)d/2
2
(15)
8
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-455-8
CTRQ 2016 : The Ninth International Conference on Communication Theory, Reliability, and Quality of Service

To verify (14), rewrite the right hand side as
(1 − q + q)d/2 + (1 − q − q)d/2
2
(16)
and expand it as a binomial series.
A received word v can be described by the parities of the
n(1−r) parity checks together with the received values in some
set of nr linearly independent variable nodes. The entropy of
a received word is h(v) = −log(p(v)) and the entropy of a
parity check is h(qd). Then, since the entropy of a variable
node is at most 1 bit and dependencies only can reduce the
overall entropy, we have
− 1
nlog(p(v)) ≤ (1 − r)h(qd) + r
(17)
If we substitute (9), (12) and (17) into (6) we get
1
nlog(p(u|v)) ≥ h(q)
2
− (1 − r)h(qd)
(18)
By hypothesis, there is an ǫ > 0 that satisﬁes
r = 2h(qd) − h(q) + ǫ
2h(qd)
(19)
Substituting for (19) in (18) we get
1
nlog(p(u|v))
≥
ǫ
(20)
Based on this theorem, we can formulate the following
corollary.
Corollary 1. Let C 1
2 (q) be the maximum achievable rate for
error free decoding of a linear code on a Z-channel with
error probability q. Given the prerequisites of Theorem 2, a
necessary condition for an LDPC code to achieve C 1
2 (q) for
all values of q is that d must go to ∞.
Proof: The capacity of the Z-channel is
max
p (h(p(1 − q)) − ph(q))
(21)
where p is the input distribution and q is the error probability.
Since we restrict ourselves to using linear codes, the highest
achievable rate of the channel is
C 1
2 (q)
=
h(1
2(1 − q)) − 1
2h(q)
(22)
=
1 − 1
2((1 + q) log(1 + q) − q log q)
(23)
For computational convenience we will use the form
1 −
h(q)
2h(qd)
(24)
instead of the original form of the bound in (4).
Assume d is ﬁnite.
Let q∗ be the value of q for which
C 1
2 (q) = 1 −
h(q)
2h(qd).
(25)
By the monotonicity of the log function there is a unique
q∗. When q = 1
2, qd = 1
2 for all values of d so 1−
h(q)
2h(qd) = 1
2,
and also C 1
2 ( 1
2) = h( 1
4) − 1
2. Consequently, when q = 1
2
C 1
2 (q) < 1 −
h(q)
2h(qd)
(26)
for all values of d.
Further, h(qd) = 0 for q = 0 since qd(0) = 1 so 1−
h(q)
2h(qd)
is not deﬁned for q = 0. We can, however, ﬁnd an expression
for 1 −
h(q)
2h(qd) as q → 0 by taking the limit
lim
q→0 1 −
h(q)
2h(qd),
(27)
Initially, we can simplify (27) to
lim
q→0 1 −
h(q)
2h(qd)
=
1 − 1
2 lim
q→0
h(q)
h(qd)
(28)
Let d′ = d
2. Then
lim
q→0
h(q)
h(qd)
=
lim
q→0
q log q
1−(1−2q)d′
2
log 1−(1−2q)d′
2
(29)
Since both numerator and denominator in (29) go to 0 when
q goes to 0, we can apply L’Hopital’s rule so that
lim
q→0
q log q
1−(1−2q)d′
2
log 1−(1−2q)d′
2
= lim
q→0
1 + log e
log q
d′(1−2q)d′−1
2

2 log 1−(1−2q)d′
2
+ log e

1
log q
(30)
We calculate the limit of the denominator in (30) separately
by applying L’Hopital’s rule repeatedly:
lim
q→0
 
2 log 1 − (1 − 2q)d′
2
+ log e
!
1
log q
(31)
= lim
q→0
2 log 1−(1−2q)d′
2
log q
+ log e
log q
(32)
= lim
q→0
2 log 1−(1−2q)d′
2
log q
= lim
q→0
2 · 2d′(1 − 2q)d′
log e
1−(1−2q)d′
log e
q
(33)
= lim
q→0
4qd′(1 − 2q)d′
1 − (1 − 2q)d′
(34)
Applying L’Hopital’s rule to (34) yields
lim
q→0
4qd′(1 − 2q)d′
1 − (1 − 2q)d′
(35)
= lim
q→0
4d′(1 − 2q)d′ − 8q(d′2 − d′)(1 − 2q)d′−2
2d′(1 − 2q)d′−1
(36)
= lim
q→0
2d′(1 − 2q)d′
d′(1 − 2q)d′−1
(37)
= 2
(38)
9
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-455-8
CTRQ 2016 : The Ninth International Conference on Communication Theory, Reliability, and Quality of Service

Substituting (38) into (30) gives us
lim
q→0
1 + log e
log q
d′(1−2q)d′−1
2

2 log 1−(1−2q)d′
2
+ log e

1
log q
= lim
q→0
1
d′(1 − 2q)d′−1
= 1
d′
(39)
Finally, substituting (39) into (28) and setting d′ = d
2 again
we get
lim
q→0 1 −
h(q)
2h(qd)
=
1 − 1
d
(40)
Now, since we assume d is ﬁnite, (26) and (27) imply that
0 < q∗ < 1
2 so there exists some interval ⟨0, q∗⟩ for which
1 −
h(q)
2h(qd) < C 1
2 (q) making it impossible to achieve C 1
2 (q)
for those values of q.
Assume d → ∞.
Since (1 − 2q) ∈ ⟨−1, 1⟩ for q ∈ ⟨0, 1⟩ we see that
lim
d→∞ qd
=
lim
d→∞
1 + (1 − 2q)d/2
2
(41)
=
1
2
(42)
for all q ∈ ⟨0, 1⟩, and so
∀q ∈ ⟨0, 1⟩ lim
d→∞ h(qd) = 1
(43)
Thus, under these conditions, the limit of (24) when d goes to
inﬁnity becomes
lim
d→∞ 1 −
h(q)
2h(qd) = 1 − h(q)
2
(44)
We want to know when
C 1
2 (q) < 1 −
h(q)
2h(qd).
(45)
Using (21) this expands to
h(1
2(1 − q)) − 1
2h(q) < 1 −
h(q)
2h(qd)
(46)
When d → ∞, we can substitute (44) into (46), and the
inequality becomes
h(1
2(1 − q)) − h(q)
2
< 1 − h(q)
2
(47)
This reduces to
h(1
2(1 − q)) < 1
(48)
From the properties of the entropy function of a binary
variable we can deduce that this is true for all values of q ∈
⟨0, 1⟩. Further, from (40) we get
lim
d→∞ lim
q→0 1 −
h(q)
2h(qd) = 1
(49)
Thus 1 −
h(q)
2h(qd) goes to 1 when q goes to 0. Further, since
the entropy function h(q) is symmetric about the line q = 1
2,
the function 1 −
h(q)
2h(qd) is also symmetric about q = 1
2 and
therefore 1 −
h(q)
2h(qd) also goes to 1 when q goes to 1.
We can conclude that C 1
2 ≤ 1 −
h(q)
2h(qd) for all q ∈ [0, 1]
when d → ∞. Ergo, for a code to achieve capacity for all q,
d must go to ∞.
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
Rate
q
 C1/2(q)
 d=2
 d=4
 d=8
 d=16
Figure 3.
Comparison between C 1
2 (q) and the upper bound from (4) for
different values of d.
 0.0001
 0.001
 0.01
 0.1
 1
 1
 10
 100
 1000
 10000
d
q*
Figure 4.
The intersection point q∗ as a function of d
10
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-455-8
CTRQ 2016 : The Ninth International Conference on Communication Theory, Reliability, and Quality of Service

IV.
RESULTS AND DISCUSSION
As stated in Corollary 1: for ﬁnite d there will be some
values of q for which 1 − h(q)/2h(qd) > C so capacity
cannot be achieved for all q. In a practical implementation,
d will necessarily have to be ﬁnite, so the interesting question
is how fast the intersection point q∗ between C 1
2 (q) and
1−h(q)2h(qd), illustrated in Figure 3 for different values of d,
approaches 0 as d grows. It appears to be a hard problem to ﬁnd
an exact solution of the equation C 1
2 (q) = 1 − h(q)/2h(qd),
but numerical evaluation can give an indication of the rate at
which q∗ approaches 0. Results for d from 1 up to 10000 are
given in Figure 4, and it is apparent that q∗ decreases relatively
slowly with increasing d.
V.
CONCLUSION
Hence, building on Gallager’s theorem, we have proved
that the check node degree of the Tanner graph of an LDPC
code imposes a lower bound on error free decoding also for
the Z-channel. We have shown that this implies that capacity
can not be achieved for all values of q for ﬁnite d, and that
as d goes to inﬁnity, the interval of q where error probability
is bounded away from zero goes to 0. However, we see that
this interval decreases only slowly, so a very high check node
degree is a necessary condition to achieve C 1
2 for small values
of q. Thus, these results tell us that the performance of regular
LDPC codes on the Z-channel is bounded away from zero for
small values of q, and that optimum performance is hard to
achieve as q goes to 0. However, the theorem provides a bound
on the performance of a regluar LDPC code for a given d.
VI.
FUTURE WORK
The results in this paper have been proved for regular
LDPC codes. However, the class of irregular LDPC codes
has so far proved to have the best performance, at least for
symmetric channels. A natural step would therefore be to
extend the above results to irregular codes as well.
REFERENCES
[1]
T. Kløve, Error Correcting Codes for the Asymmetric Channel. HiB, N-
5020 Bergen, Norway: Department of Informatics, University of Bergen,
1995.
[2]
N. Marina, “Ldpc codes for binary asymmetric channels,” in Telecom-
munications, 2008. ICT 2008. International Conference on. IEEE, 2008,
pp. 1–7.
[3]
R. Gabrys and L. Dolecek, “Coding for the binary asymmetric channel,”
in Computing, Networking and Communications (ICNC), 2012 Interna-
tional Conference on.
IEEE, 2012, pp. 461–465.
[4]
M. Mondelli, R. Urbanke, and S. H. Hassani, “How to achieve the capac-
ity of asymmetric channels,” in Communication, Control, and Computing
(Allerton), 2014 52nd Annual Allerton Conference on.
IEEE, 2014, pp.
789–796.
[5]
R. G. Gallager, “Low density parity check codes,” IRE Trans. Information
Theory, vol. 8, pp. 21–28, 1962.
[6]
P. Ellingsen, “Iterative coding for the asymmetric channel,” University
of Bergen, Tech. Rep. 295, April 2005.
[7]
C.-C. Wang, S. R. Kulkarni, and H. V. Poor, “Density evolution for
asymmetric memoryless channels,” in Proc. 3rd International Symposium
on Turbo Codes, 2003.
11
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-455-8
CTRQ 2016 : The Ninth International Conference on Communication Theory, Reliability, and Quality of Service

