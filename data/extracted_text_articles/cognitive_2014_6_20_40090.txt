How to Make Robots Feel and Social as Humans 
Building attributes of artificial emotional intelligence with robots of human-like behavior 
 
Aleksandar D. Rodić and Miloš D. Jovanović 
Institute Mihailo Pupin 
University of Belgrade 
Belgrade, Serbia 
e-mail: {aleksandar.rodic, milos.jovanovic}@pupin.rs 
 
 
Abstract—Paper contributes to building attributes of artificial 
Emotional Intelligence (EI) aimed to be implemented in robots 
of human behavior as advanced intelligent robot interface. The 
main research objective of the paper regards to searching is it 
possible and how to make robots emotive and sociable as 
humans. For this purpose, the Meyers-Briggs theory on human 
personality, known from personality psychology, is employed 
for mapping human psychological traits and development of 
robot EI-controller. A customized multi-input and multi-
output fuzzy inference model is designed to fit human affective 
and social attributes. The assumed fuzzy structure makes core 
of the robot EI-controller. Developed intelligent robot interface 
was implemented with small Aldebaran’s Nao humanoid robot 
used to validate control performances and EI model developed. 
In the paper, was presented how the developed intelligent 
robot interface can be used for mapping different human 
personality traits and temperaments to the machine. Accuracy 
of the model used for building robot interface was verified by 
tests with human examinees by using corresponding on-line 
psychological tests – questionnaires. 
Keywords-emotional intelligence; emotion-driven behavior; 
social robots; embodied mind; affective computing; 
I. 
 INTRODUCTION 
To function in a complex and unpredictable physical and 
social environment humans are faced with applying their 
physical and intellectual resources to realize multiple goals 
in an intelligent and flexible manner. Two distinct and 
complementary information processing systems – cognition 
and emotion enable humans achieving of these goals by 
operating simultaneously [1]. The cognitive system is 
responsible for interpreting and making sense of the world, 
whereas the emotion system is responsible for evaluating and 
judging events to assess their overall value with respect to 
the human (e.g., positive or negative, desirable or 
undesirable, hospitable or harmful, etc.) [2]. When operating 
in the proper balance, the emotion system modulates the 
operating parameters of the cognitive system and the body to 
improve the overall mental and physical performance of the 
human. The scientific literature documents the beneficial 
effect of emotion on creative problem solving, attention, 
perception, memory retrieval, decision-making, learning, etc.  
The fact that emotions are considered to be essential to 
human reasoning suggests that they might play an important 
role 
in 
autonomous 
robots 
as 
well 
[3][4].Today's 
autonomous robots can certainly improve their ability to 
function 
in 
complex 
environments 
and 
to 
behave 
appropriately in partnership with people. Using the 
properties of natural intelligence as a guide, a robot's 
cognitive system would enable it figure out what to do, 
whereas the emotion system would help it to do so more 
flexibly in complex and uncertain environments, as well as 
help the robot behave in a socially acceptable and effective 
manner with people [4].  
In order to interact with social partners (whether it is a 
device, robot or another person), it is essential to have a good 
conceptual model of how the social partners operates [5]. 
With such a model, it is possible to explain and predict what 
the interlocutor is about to do, its reasons to doing it, and 
how to elicit a desired behavior from it. The work in this 
paper focuses on developing emotionally-driven and sociable 
robots for envisioned applications where the robot interacts 
with a person or another robot as a partner. The field of 
social robots and safe Human-Robot Interaction (HRI) opens 
new areas of applications like: healthcare, caretaking, 
assistance, edutainment and entertainment. 
The paper is organized in seven sections. In Section 1, a 
brief introduction into the topics considered in the paper is 
given. Progress beyond the state-of-the-art is pointed out in 
Section 2. Necessary theoretic background as a platform for 
building of the EI model is given in Section 3. Section 4  
addresses to modeling of human affective and social 
behavior dealing with concept and solutions. Model 
validation and implementation of EI interface with the small 
Nao humanoid robot are given in Sections 5 and 6. The 
paper is concluded in Section 7.    
II. 
PROGRESS BEYOND STATE-OF-THE-ART 
Modeling of natural intelligence, artificial EI, embodied 
mind and embodied cognition are emerging research fields. 
They were thoroughly explored by many scientists in natural, 
human and technical sciences in the last decade.   
Inspired by models of natural intelligence in biological 
systems, Breazeal [2] [6] designed an architecture that 
features both - cognitive system and Emotion System (ES). 
Both systems operated in parallel and are deeply intertwined 
to foster optimal functioning of the robot in its environment. 
The overall architecture was comprised of a distributed 
network of interacting agent-like processes that excite and 
inhibit one another by spreading activation. For modeling of 
133
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

the ES, a learning structure for dynamically deciding the 
appropriate number of kernels, were applied [6]. This work 
resulted in development the sociable machine Kismet [7], an 
expressive robotic creature with perceptual and motor 
modalities, tailored to natural human communication 
channels.  
Beginning with an outline of the theoretical and 
methodological commitments of standard cognitive science, 
Shapiro then examined philosophical and empirical 
arguments surrounding the traditional perspective [8]. 
Varela et al. have highlighted several themes clearly [9]: 
our dualistic tendencies to distinguish between subject and 
object, and the reification of representation in our framing of 
experience - both projected outward (idealism) onto objects 
in the world that can then contain and give shape to our inner 
representations, or assimilated symbols of an independent 
world 'out there' (realism). 
 Brooks theorized on the importance of emotional 
intelligence in predicting individual and group success [10]. 
Drawing off of a variety of disciplines including psychology, 
economics and cognitive research, Brooks made a case for 
the power of the unconscious mind in influencing our 
interactions, beliefs and decisions. We are products of our 
emotions, he said. “Emotions enable us to value things. We 
can’t make decisions if we can’t value things.” Brooks 
stressed out that “the mere act of affection rewires 
connections in our brains”. 
Authors of this paper contribute beyond the recent 
research results in this field by searching for the answer how 
to make robots feel and sociable as humans. They go even 
further trying to give the answer how to make robot psyche 
to be of predefined (requested) human-like personality traits. 
The solution proposed in this paper concerns with design of 
an appropriate model of human affective and social behavior 
based on personality psychology that also takes into account 
real interior and exterior constraints. 
III. 
THEORETIC BACKGROUND 
The platform for development mathematical model of 
human emotionally driven and social behavior is the Meyers-
Briggs theory on personality [11] widely used in personality 
psychology.  According to this theory, the personality type 
and temperament dominantly influence human psychological 
behavior.  
A. Personality Type 
Personality psychology is a branch of psychology that 
studies personality and its individual differences [12]. 
According to the theory, "personality" is a dynamic and 
organized set of characteristics possessed by a person that 
uniquely 
influences 
individual 
cognitions, 
emotions, 
motivations, and behaviors in various situations. Personality 
also refers to the pattern of thoughts, feelings, social 
adjustments, and behaviors consistently exhibited over time 
that strongly influences one's expectations, self-perceptions, 
values, and attitudes. It also predicts human reactions to 
other people, problems, and stress [13] [14]. This scientific 
discipline uses the Myers-Briggs Type Indicator (MBTI) 
assessment as a psychometric questionnaire designed to 
measure psychological preferences in how people perceive 
the world and make decisions [15]. The MBTI sorts 
psychological 
differences 
into 
four 
opposite 
pairs, 
i.e., dichotomies 
(Extravert-Introvert, 
Sensing-iNtuitive, 
Feeling-Thinking and Perceiving-Judging). That results in 16 
possible psychological, i.e., personality types. None of these 
types are better or worse. However, Briggs and Myers 
theorized 
that 
individuals 
naturally prefer one 
overall 
combination of type differences [12].  
B. Human Temperament 
Under the notion “temperament” it is assumed in 
psychology, unlike to the term “personality”, the individual 
kinds of the psyche traits that determine dynamics of human 
psychological activity [16]. The temperament traits are 
expressed in an even manner in any activity nevertheless to 
its’ content, goals and motives, remaining invariant in the 
later years and which, in their interconnections, characterize 
the type of temperament [16]. The temperaments are (Fig. 1): 
sanguine 
(pleasure-seeking 
and 
sociable), 
choleric 
(ambitious and leader-like), melancholic (introverted and 
thoughtful), and phlegmatic (relaxed and quiet), Fig. 1. 
A temperament type can be determined by filling 
corresponding questionnaires (tests) available at the Internet 
as well as corresponding personality tests [17] [18]. 
IV. 
MODELING EMOTIONS 
While the artificial intelligence copes with tasks such as 
pattern recognition, context understanding, reasoning, 
decision making, etc., the emotional intelligence is 
responsible 
with 
humans 
for 
self-awareness, 
self-
management, 
awareness 
of 
others 
and 
relationship 
management [19]-[21]. According to the theory of 
personality, human emotional reactions primarily depend on 
three factors [13]: (i) personality type, (ii) personality 
character, and (ii) temperament. These factors are mainly 
determined by genetic code and acquired by a birth. Also, 
behavior of individuals is strongly influenced by additional 
exterior and interior factors (Fig. 2). Under the term “exterior 
world” our physical and social environment (such as events, 
situations, acts or relationships with other persons) are 
assumed. The “interior stimuli” mainly concerns with our 
physical and psychological conditions (regarding to body 
and psyche) such us senses of fatigue, pain, disease, etc. 
Under the same term, the feelings like love, depression, 
anger, hatred, fear, satisfaction, etc., are assumed, too. The 
“social factors” regard to the conditions that influence some 
features of individual behavior. 
 
 
 
 
 
 
 
 
Figure 1.  Emotion representation of four temperament types. 
134
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

The “social factors” includes the following: family and 
school education, influence of companions, religion and 
affiliation to the social groups such as political parties, civil 
communities, clubs, etc.  
To derive generic model of a human psychological 
behavior the following assumptions can be assumed. The 
considered biological system, such as human psyche, can be 
approximated by a deterministic, dynamic, non-linear, multi-
input and multi-output (MIMO) system of arbitrary 
complexity. The input and output variables of the emotion-
driven behavior (EDB) model are hardly measurable. They 
can 
be 
quantified 
(rated) 
by 
using 
corresponding 
psychological questionnaires [17], [18]. 
The variables of interest required for modeling EDB 
include qualitative information regarding personality profile, 
physical and social environment, emotional and health 
conditions, social factors, etc. They are quite heterogeneous, 
defined in the form that is more symbolic and descriptive 
than measurable and numerical. Generally, humans use to 
behave (in psychological sense) in a fuzzy manner by using 
corresponding linguistic variables. That means people use 
their different natural skills of sensing, symbolic and 
phonetic communication (e.g., body and facile gestures, 
phonetic meanings, etc.) to express their emotional state – 
feelings, mood, etc. Due to a fuzzy nature of human 
behavior, the modeling approach to be assumed in this paper 
as appropriate solution consequently belongs to the 
knowledge-based type. It assumes utilizing of a fuzzy logic 
system structure. Accordingly, the appropriate model 
structure of emotionally-driven and social behavior can be 
represented by a three-stage block structure presented in Fig. 
2. It consists of three fuzzy logic blocks FIS-1 to FIS-3 
where everyone contributes particularly to shaping of 
outcome event-driven emotional reaction(s).  
Human affective behavior is generated and profiled by 
influence of three input variables (information carriers) that 
are: (i) “trigger-event” that arouses different psychological 
reactions, (ii) “behavior profiler” that shapes event-driven 
behavior in a way to fit particular personal profile of 
individual whose behavior need to be modeled, and (iii) 
“behavior booster/inhibitor” that intensifies or weakens the 
expressiveness of the affective manifestations of individual. 
The trigger-event (e.g., situation, interpersonal relationship, 
interaction or just an act) provokes (excites) corresponding 
affective reactions (mood) with individuals. It is well known 
that some persons react more intensively in emotional sense 
(depending on their personality type and temperament) to the 
same trigger-event than others. 
 
 
 
 
 
 
 
Figure 2.  Block-structure of  the emotionally-driven behavior model 
consists of behavior generator, modulator and interpreter. 
These personality differences can be modeled by introducing 
corresponding “behavior profiler”. The “behavior profiler” 
modulates usual (generally expected) emotional reactions 
characteristic for this trigger-event. It is done in a way to 
imitate reactions characteristic for the particular personality 
profile and temperament of the individual whose behavior 
need to be modeled. The “behavior booster/inhibitor” in the 
model presented in Fig. 2 serves to intensify or weaken the 
intensity of emotional reactions depending on dominant 
personality traits and temperament type. 
Fuzzy model blocks FIS-1, FIS-2 and FIS-3 (Fig. 2) are 
assumed to be of Mamdani type. The input and output 
variable vectors at the particular fuzzy blocks are of the 
arbitrary number depending on how comprehensive model 
wish to be developed. In the model presented in Fig. 2, the 
corresponding input/output membership functions of the 
FIS-1 to FIS-3 blocks are either the Gauss curves or Sigmoid 
functions. The number of fuzzy rules synthesized in the 
model varies depending on how comprehensive and accurate 
model is required. The proposed model architecture (Fig. 2), 
with three fuzzy blocks aligned in a cascade, enables easy 
monitoring of the model state variables.  
Trigger-events to be considered in the model, presented 
in Fig. 2, can be rather numerous. The list of the trigger-
event attributes used for modeling of human emotional 
behavior in this paper is given in [22]. At this stage of 
research, this number of event attributes is limited to 
approximately n1=50. This amount of attributes satisfies 
modeling requirements of majority usual scenarios to appear 
in everyday practice. The actual number of event attributes 
can be in principle very high - the larger number of trigger-
event attributes in the model, the more comprehensive, 
accurate and complex model is. The number of emotions 
(moods) n2, modeled in the paper, is higher than the number 
of trigger-event attributes n1 (middle column, Fig.3). The 
right column, presented in Fig. 3, contains emotional 
reactions, i.e., attributes of reactions, caused by trigger-
events. They are modulated by use of the fuzzy rules that 
take into account personality traits and temperament of the 
individual whose affective and social behavior is modeled. 
To clarify the methodology applied, the event “birthday 
anniversary”, taken as an example, represents combination of 
several particular event attributes such as: cheerful, funny, 
surprising, sociable, etc. To build a model, every particular 
event attribute as well as emotion state of the individual has 
to be quantified (rated) in an appropriate way. It can be done 
in a way presented in Fig. 4. Such an approach leads to 
correct definition of linguistic fuzzy variables as appropriate 
inputs to the corresponding fuzzy model blocks. For 
example, if take the attribute “cheerful” as a variable, its’ 
rating can be accomplished in the following way: (i) not at 
all (0%), (ii) somewhat (<25%), (ii) very (25-75%) and (iii) 
entirely (>75%). Concerning fuzzy rules of the model, they 
are determined based on the semantic-graph whose reduced 
(not complete) form is presented in Fig. 3. According to this 
graph, the following fuzzy rule, as an example, can be 
derived: 
 
 
135
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3.  Example of functional interconnections between the trigger 
events, produced emotions and corresponding affective reactions. 
if (event.is.cheerful) than (mood.is.pleasant) and (mood.is. 
happy) and (mood.is.excited). 
 
By designing of the model rules, it is also necessary to 
take into account the influence of the personality profile of 
individual as well exterior and interior constraints.  
The model designed in this paper includes 75 fuzzy rules, 
n1=20 trigger-event attributes, n2=35 emotion attributes and 
n3=20 different affective reactions.  The number of rules can 
be much higher in the case of a more accurate and 
comprehensive model. Being we have implemented this 
model to a small humanoid robot with limited capabilities 
the number assumed was enough numerous to verify the 
performances of the designed robot EI-controller. More 
details regarding model building are given in [22].  
Additionally, attributes of social behavior regard to 
interpersonal ability of communication and self-adaptation to 
group or team. The properties such as sociability (easiness of 
communication with others), cooperativeness, compatibility 
with 
others, 
interpersonal 
synergy, 
reliability 
and 
responsibility for the community interest, mutual tolerance, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 4.  Example of rating (quantification) trigger-event attributes 
according to degree of experiance. 
feel of belonging community, etc., are properties based on 
highly developed degree of EI. Brooks [10] pointed out that 
emotions are the motor-power of human individual and 
collective behavior. Attributes of social behavior of 
individuals strongly depend on personality profile and 
temperament but also on social constraints such as family 
education, companions, club memberships, religion, etc. 
V. 
MODEL VALIDATION 
Model validation is accomplished experimentally by 
involving human examines in this procedure to provide 
reference values. Ten persons of different gender and age 
were requested to fill out the personality type and 
temperament test. Both questionnaires are available on 
Internet [17] [18]. The same examinees were asked also to 
fill out the questionnaires to assess their affective reactions 
(response) to the imagined (hypothetical) set of trigger-
events taken from the life practice. The results were 
systematized and presented in [22]. In the paper, a 
characteristic trigger event, arousing emotional behavior, is 
chosen for model verification.  
Trigger event example: At the dinner table, someone told 
a funny joke. While laughing, you have suddenly burped 
loudly.  
The chosen event is experienced in a different way by 
interviewed persons. Model validation was done by 
comparison of the results obtained by testing human 
examinees 
(of 
known 
personality 
profiles) 
with 
corresponding results obtained by simulation of the generic 
model proposed in the paper. In such a way, the objectivity 
of model assessment is achieved. 
Also, the model sensitivity test upon variation of exterior 
and interior factors (personality traits, social factors and 
interior stimuli) was done. The emotion trigger-event 
assumed in this simulation experiment has the attributes 
presented in Fig. 4. These attributes are independently rated 
by anonymous human examinees. The model of EI presented 
in Section IV is simulated taking into account the parameters 
that correspond to the following test-cases: 
C-1: Personality type INTJ (Introvert=60%, iNtu-
itive=57%, Feeling=78%, Judging=69%); Temperament: 
Sanguine=80%; Interior stimuli: none; Social factor: none; 
C-2: Personality type ESTP (Extrovert=60%, Sen- 
sing=57%, Thinking=78%, Perceiving=69%; Temperament: 
Sanguine=80%; Interior stimuli: none; Social factor: none; 
C-3: Personality type ESTP; Temperament: Chole- 
ric=80%; Interior stimuli: none; Social factor: none; 
C-4: Personality type ESTP; Temperament: Phleg- 
matic=80%; Interior stimuli: none; Social factor: none; 
C-5: Personality type ESTP; Temperament: Phleg- 
matic=80%; Interior stimuli: completely moody; Social 
factor: none; 
C-6: Personality type ESTP; Temperament: Phleg- 
matic=80%; Interior stimuli: none; Social factor: strict family 
education; 
Simulation results presented in Table 1 represent the 
rated feelings (affective reactions) obtained by model 
simulation. Feeling attributes (Table 1) were aroused by the  
 
136
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

TABLE I.  
SIMULATION RESULTS: TABLE OF FEELING RATES    
 
C-1 
C-2 
C-3 
C-4 
C-5 
C-6 
Feeling rate 
% 
% 
% 
% 
% 
% 
Unpleasant 
50.49 
51.72 
51.84 
45.89    45.94   
46.55   
Guilty 
84.82 
87.98 
85.78 
67.88 
70.36 
72.69 
Shame 
97.41 
97.41 
95.45 
79.82 
79.82 
82.70 
Frightened 
49.86 
51.48 
51.63 
45.62 
45.71 
46.29 
Excited 
45.80 
48.80 
49.37 
42.60 
43.13 
43.35 
Disgusted 
43.49 
46.32 
46.98 
40.33 
40.98 
41.07 
Warried 
48.37 
50.88 
51.13 
44.83 
45.00 
45.52 
 
imposed 
trigger-event 
example 
and 
modulated 
by 
corresponding interior and exterior factors such as: 
personality traits, temperaments, emotional states and social 
factors. The presented results validate model sensitivity upon 
variation of the previously mentioned factors. By comparing 
the feeling indicators presented in the columns C-1 and C-2 
of Table 1, it is evident that an ESTP person demonstrates 
emotions in a more intensive way than one IFTJ person.  
Also, an ESTP choleric person (C-3) is more sensitive than 
corresponding sanguine (C-2) and phlegmatic (C-4) persons. 
A moody person (C-5) and a person that is subjected to the 
strict social constraints (e.g., family education) are slightly 
more sensitive than others with the same temperament and 
personality. Affective reactions that are generated by the 
model proposed in Section IV commonly can be displayed 
by the feeling charts, as presented in Fig. 5. 
The obtained simulation results and verification of model 
properties make us believe that the EI model designed in this 
paper can be effectively implemented with robots to enable 
them to feel and be social as humans. In the next section it 
will be demonstrated.   
VI. 
 IMPLEMENTATION OF ROBOT EI-INTERFACE  
Robot interface (software algorithms), based on the 
model of human affective and social behavior developed in 
this paper, is implemented in the controller of the 
Aldebaran’s Nao humanoid robot [23]. Block-diagram of the 
high-level control structure is presented in Fig. 6. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5.  Example of feeling charts. Mood rating scale with respect to the 
sadness and happiness 
A. Software Implementation 
As a widely used open robotic platform, the Nao robot 
provides a relatively fine possibility of simple implementing 
advanced control algorithms through the Naoqi robotic 
application [23]. The Naoqi application is an open and fully 
accessible software module which provides easily access 
through all major ports of the Nao robot. The Naoqi 
application is embedded Nao software that includes fast, 
secure and reliable development platform. It allows easy 
implementation of new features that can improve functions 
of the Nao robot. The Naoqi allows an implementation of 
algorithms that share its Application Programming Interface 
(API) to the other systems and supports the development of 
modules that run on the Nao platform or on a remote PC 
system. Software development can be accomplished in 
Windows, Mac OS, or Linux environment. A software 
package that collects signals from the visual system of the 
robot is written in Open CV. Through the Naoqi, the 
application gathers information from one of the video 
cameras implemented in the head of the Nao robot. It is not 
possible at once to combine signals from both cameras due 
to the configuration of the controller built into the Nao robot. 
So, images from selected high-definition camera are 
transmitted to remote PC, via Naoqi implemented software 
applications by wireless communication. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6.  High-level system description. The control block-diagram of the NAO humanoid with EI-controller. 
 
137
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

Remote PC provides signal processing and recognition of 
individuals based on face recognition applications. When the 
Nao robot observes and locates the person for possible 
cognitive interaction, an ultrasound sensor is activated to 
determine the distances to the interlocutors. Based on the 
vision algorithms and signals from ultrasonic rangefinder, 
the distance between Nao and interlocutor is obtained and 
estimated and modules of cognitive analysis are activated. 
Cognitive analysis module of persons, together with  face 
recognition module, analyze the condition of the interlocutor, 
based on the movement of arms and legs of the interlocutors, 
coordinate all the parameters of cognitive analysis and 
decide about the emotional state of the interlocutor. In 
accordance with all analyzed cognitive parameters of the 
interlocutor, a conclusion is made and desired movement of 
the Nao robot are generated achieving its’ hands, and at the 
same time it is  generated desired audio message that Nao 
robot directs to the interlocutor. So, the audio system is 
included into the algorithm. Namely, entire action is initiated 
by the voice. The block diagram of the overall cognitive task 
is shown in Fig. 6. 
B. Embodiment of Social Behavior Attributes in Robot 
Attributes of social behavior were implemented in Nao 
robot controller as an advanced EI-interface. The task of EI-
controller is to enable robot some basic functions of social 
behavior attributes characteristic for behavior in groups. 
Bearing in mind the real technical constraints of the 
hardware, some of the particular attributes of social behavior, 
shown in the semantic graph in Fig. 7, were implemented 
with the Nao robot. Principle of implementation of fuzzy 
model in realization of some features of social behavior is 
similar to the principle of implementation the functions of 
affective behavior presented in Fig. 3. In this case, instead of 
a trigger-event, physical and social environment arouse 
corresponding 
emotional 
reactions 
and 
interpersonal 
relationship (communication, collaboration, etc.) between 
robot and others. In the paper, Nao robot is requested to 
express some elements of social behavior based on 
relativelly modest perceptive capabilities. They are based on 
embedded robotic vision, external Kinetic sensor (for gesture 
recognition) and speach recognition system. Fuzzy model, 
that is core of the control interface implemented in Nao 
robot, 
includes 
variables 
that 
carry 
on 
neccessary 
information 
regarding 
stimuli 
received 
from 
social 
environemnt such as audio and physical incentives: 
invitation voice, salutation, body and arms gestures,  dialog 
sequences, etc.  
 
 
 
 
 
 
 
 
 
 
Figure 7.  High-level semantic diagram of Nao robot social behavior.   
Robot also checks for possible risks of interacting with 
others by recognizing exsitance of some irregular physical 
gestures originating from the interacting persons.  Also, type 
of 
communication, 
assuming 
unilateral, 
bilateral 
or 
multilateral modus, determines character of robot interaction.     
Nao robot interacts with social environment by using its’ 
audio interface (microphones and speakerphones) and 
physical gestures through movements of body and arms. The 
rating scale of phonetic and physical reactions implemented 
in the Nao robot is presented in Fig. 8. 
 
 
 
 
 
 
 
 
 
Figure 8.  Rating scale of phonetic and physical reactions  implemented 
with Nao robot.   
C. Experiments with Nao Robot 
 The task „teamwork“ is a typical scenario that includes 
attributes of social behavior. In this case, temperamental and 
strongly motivated individuals accomplish this task easier 
and in a more efficient way than ones with weak 
temperament and low motivation. In this example, group of 
junior researchers from laboratory invites (stimulates by 
voice) Nao robot to join them and salute (Fig. 9). Nao robot, 
having an advanced EI interface, recognizes calls, locates 
persons in the surrounding, recognizes their gestures and 
responses them by stretching arm forward and speaking the 
kind words. In such a way, robot expresses its’ social 
behavior as presented in Fig. 9. In this experiment, 
personality traits of a joyful, sociable and temperamental 
individual are imposed to the NAO robot. The experiment 
was repeated by changing robot parameters (features) 
making robot to be a “person” of properties that regards to a 
reserved (introverted) and melancholic person.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 9.  NAO robot demonstrates EI capabilities by communicating with 
young reserchers from the IMP Robotics Laboratory.   
 
138
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

By comparison of robot affective reactions obtained in 
the previously mentioned experimental sessions, the 
expected validation of the proposed modeling concept is 
achieved. 
VII. CONCLUSION AND FUTURE WORK 
The paper concerns with development of robot EI 
interface designed to ensure advance robot capabilities – 
emotional and social behavior as humans.  Developed 
interface is based on generic model of natural emotional 
intelligence that includes human emotion-driven and social 
behavior. EI model is synthesized by implementing multi-
input and multi-output fuzzy inference system. The purpose 
of artificial EI in robots is to increase the autonomy through 
building advance cognitive features such as: emotion 
understanding, self-management, managing relationship with 
others, etc. The novelties given in the paper regards to 
modeling approach of human affective and social behavior 
attributes 
based 
on 
theory 
taken 
from 
personality 
psychology. Model takes into account personality traits, type 
of temperament as well as interior and exterior constraints – 
emotional conditions, social factors, etc. Model validation 
was done by comparison of experimentally acquired 
indicators from human examinees and indicators obtained by 
model simulation. Convergence of experimentally obtained 
and simulation results indicates that developed EI-model can 
be used with robots for embodiment of mind and cognitive 
capabilities. The EI-interface was implemented with NAO 
humanoid robot. It was demonstrated how Nao robot 
demonstrate some attributes of social behavior based on its’ 
EI-controller. Additional model extension and validation are 
planned in the future by using extensive experimental results 
with human examinees. The model structure will be 
upgraded by including new attributes of emotion and social 
behavior. In such a way, the EI-model will become more 
comprehensive and accurate. 
ACKNOWLEDGMENT 
The research in the paper is funded by the Serbian 
Ministry of Science under the grants TR-35003 and III-
44008. It is partially supported by the SNSF IP project 
IZ74Z0_137361/1 
as 
well 
by 
the 
Serbia-Portugal 
“COLBAR” research project under the grant 451-03-
02338/2012-14/12. The authors express thanks to the 
scientists from the Department of Experimental Psychology, 
Faculty of Human Sciences, University of Belgrade, for the 
valuable suggestions and expertize. 
REFERENCES 
 
[1] R. Picard, Affective computation. MIT Press, Cambridge, 
MA. 1997. 
[2] C. Breazeal, “Function Meets Style: Insights from Emotion 
Theory Applied to HRI”, IEEE Transactions in Systems, 
Man, and Cybernetics, Part C, 34(2), 2003, pp. 187-194.  
[3] J. H. Busher, Human Intelligence its Nature and Assessment, 
Harfer Torbchbooks, NewYork, 1973. 
[4] J. Weng et al., “Autonomous mental development by robots 
and animals”, Science, vol. 291, 2001, pp. 599–600.  
[5] D. Norman, “How might humans interact with robots”, 
Keynote address to the DARPA/NSF Workshop on Human-
Robot Interaction, San Luis Obispo, CA., 2001, pp. 72-78. 
[6] C. Breazeal, Designing sociable robots. MIT Press. 
Cambridge. 2002. 
[7] Sociable machines – the Kismet robot. http://www.ai.mit.edu/ 
/projects/sociable/baby-bits.html [retrieved: April, 2014]. 
[8] L.Shapiro, 
Embodied 
Cognition 
(New 
Problems 
of 
Philosophy), Routledge Taylor & Francis Group, London and 
NewYork, 
ISBN-10: 
0415773423 
| 
ISBN-13: 
978-
0415773423, 2010.  
[9] F. J. Varela, E. Rosch, and E. Thompson, The Embodied 
Mind: Cognitive Science and Human Experience, MIT Press, 
1992.  
[10] D. Brooks, The Social Animal: The Hidden Sources of Love, 
Character, and Achievement, Books Inc. - The West's Oldest 
Independent Bookseller, Published by Random House, ISBN-
10: 140006760X, ISBN-13: 9781400067602, 2011. 
[11] I. Myers-Briggs and P. Myers, Gifts Differing: Understanding 
Personality Type. Mountain View, CA: Davies-Black 
Publishing. 1995.  
[12] Personality psychology. http://en.wikipedia.org/wiki/Persona- 
lity_psychology [retrived: April, 2014]. 
[13] G. D. Myers, Psychology (9th ed.). New York: Worth 
Publishers. 2010.  
[14] F. J. Winnie and W. J. Gittinger, “An introduction to the 
personality 
assessment 
system”, 
Journal 
of 
Clinical 
Psychology, Monograph Supplement, 38, 1973, pp. 1-68.  
[15] MBTI. http://en.wikipedia.org/wiki/Myers-Briggs-Type-Indi-
cator  [retrived: April, 2014]. 
[16] Temperament types. http://en.wikipedia.org/wiki/Four-tempe-
raments  [retrived: April, 2014]. 
[17] On-line personality test. http://www.16personalities.com/free-
personality-test  [retrived: April, 2014].  
[18] On-line temperament test. http://neoxenos.org/wp-content/ 
blogs.dir/1/files/temperaments/temperament_test.htm 
[retrived: April, 2014]. 
[19] H. D. Kluemper, “Trait emotional intelligence: The impact of 
core-self evaluations and social desirability” Personality and 
Individual Differences, 44(6), 2008, pp. 1402-1412.  
[20] D. J. Mayer and P. Salovey, What is emotional intelligence? 
In: P. Salovey & D. Sluyter (Eds.), Emotional development 
and emotional intelligence: Implications for educators, pp. 3-
31, New York: Basic Books,  1997.  
[21] V. K. Petrides, R. Pita, and F. Kokkinaki, “The location of 
trait emotional intelligence in personality factor space”, 
British Journal of Psychology, 98, 2007, pp. 273-289.  
[22] A. D. Rodić and K. M. Addi, „Mathematical Modeling of 
Human Affective Behavior Aimed to Design Robot EI-
Controller“,A. Rodic´ et al. (eds.), New Trends in Medical 
and Service Robots, Series: Mechanisms and Machine 
Science 20, DOI: 10.1007/978-3-319-05431-5_10, Springer 
International Publishing Switzerland, 2014, pp. 141-162.  
[23] NAO robot. www.aldebaran-robotics.com/en/Discover-NAO/ 
Key-Features/open-source.html  [retrived: April, 2014]. 
 
 
         
 
 
 
 
 
 
139
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

