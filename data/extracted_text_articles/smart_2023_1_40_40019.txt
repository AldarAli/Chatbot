Augmented-Reality Optical Narrowcasting (ARON) 
 
Narkis Shatz 
SureFire, LLC 
Fountain Valley, USA 
email: nshatz@surefire.com 
 
 
Mark Squire  
SureFire, LLC  
Fountain Valley, USA  
email: msquire@surefire.com
 
 
Abstract—We introduce a new communications technology for 
consumers in Smart Cities, which we refer to as Augmented-
Reality Optical Narrowcasting (ARON). This technology has 
the potential to significantly enhance mobile consumer 
communications by enabling information exchange between 
multiple transmitters and multiple receivers using free-space 
optical data transmission in the near infrared. A practical 
communication range of 400 meters in broad daylight is 
achievable with miniaturized optics transmitting HD video, for 
example, to smartphones and 1,000 meters to vehicles.  An 
augmented-reality-style 
user 
interface, 
wherein 
visual 
representations of available information sources are overlaid on 
a live display of local video imagery allows users to conveniently 
manage transmissions from multiple parties. The new 
technology is envisioned to be installed in smartphones and 
other mobile devices and in vehicles, opening new vistas for 
commerce and social interaction. We have demonstrated key 
features of the technology using custom optical communications 
hardware and software developed especially for this purpose. 
 
Keywords- optical communication; augmented reality; 
smartphones; automobiles; nonimaging optics. 
I. 
 INTRODUCTION  
In 1880, Alexander Graham Bell patented and 
demonstrated 
the 
world’s 
first 
free 
space 
optical 
communication system, which he dubbed the Photophone. 
Bell achieved the first ever over-the-air voice transmission 
over a distance of 213 meters using meter-sized transmitter 
and receiver parabolic mirror dishes harnessing modulated 
sunlight.  This achievement preceded by 19 years the first 
demonstration of radio by Marconi [1].  In his latter years, 
Bell stated that he believed this invention was “…greater than 
the telephone” [1].  
     In modern times, there have been several attempts, largely 
unsuccessful, to commercialize this technology. The Maxima 
Corporation published its operating theory in Science [2], and 
received $9 million in funding before permanently shutting 
down. No known spin-off or purchase followed this effort.  In 
2004, a Visible Light Communication Consortium was 
formed in Japan [3]. This was based on work from 
researchers that used a white Light Emitting Diode (LED)-
based space lighting system for indoor Local Area Network 
(LAN) communications.  Projected data rates and future data 
rate claims vary - a low-cost white LED (GaN-phosphor) 
which could be used for space lighting can typically be 
modulated up to 20 MHz [4]. Research published in 2009 
used a system for traffic control of automated vehicles with 
LED traffic lights [5]. Increased security when working with 
narrow beams has also been demonstrated [6].  
Our approach is conceptually and technically different 
from all previous commercialization attempts.  We introduce 
a new type of communications channel, intended for the 
consumer in a Smart Cities environment.  We refer to this 
technology as Augmented-Reality Optical Narrowcasting 
(ARON). ARON is a pioneering communications technology 
that transmits information locally using LED-generated 
beams of near-infrared light with tailored directionality. 
ARON offers a robust many-transmitters to many-receivers 
free-space optical communications channel for personal use 
with mobile devices (such as smartphones and automobiles).  
We envision the use of this localized optical communications 
channel as a means to enhance information flow, free-up 
overtaxed Radio Frequency (RF) bands, create a new class of 
mobile social networks, and provide a novel user experience.  
In Section II, we discuss how the physics of optical 
communication differ from radio communication and how 
we can exploit these differences. In Section III, we discuss 
the underlying principles of our ARON architecture and how 
they significantly differ from prior work.  In Section IV, we 
discuss the architecture of a new type of optical information 
processing chip, the Adaptive Communications Focal Plane 
Array (ACFPA), and how that design folds into our concept.  
In Section V, we present the assumptions and physics model 
for our signal to noise tradeoffs.  In Section VI, we discuss 
our Technology Demonstration Unit (TDU) and real-life test 
results.  In Section VII, we present conclusions and offer 
comments about how ARON can impact Smart Cities.    
II. 
THE PHYSICS OF ELECTROMAGNETIC WAVE 
TRANSMISSION AND RECEPTION 
RF waves are electromagnetic (EM) waves of frequency 
between 3 hertz (Hz) and 300 gigahertz (GHz). These waves 
readily reflect, refract and diffract.  Due to their long 
wavelengths, radio waves can navigate around obstacles and 
also penetrate some types of materials.  This is much less true 
of light waves which, due to their short wavelengths, require 
a line of sight to achieve a viable communications path and 
cannot penetrate most materials. These seeming limitations 
of light waves have until now stalled the development of free-
space optical communications for use by the consumer - 
possibly because it was always considered an impractical 
proposition.  Consequently, the only free-space optical 
14
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

device that has ever really achieved commercial success is 
the celebrated TV remote control.  
EM waves propagating through the atmosphere obey the 
non-interference principle (i.e., EM waves originating from 
multiple transmitters do not exert force on each other).  So, 
waves from multiple sources pass through each other 
unaffected.  This occurs because Maxwell’s equations are 
linear in the electric and magnetic fields, and in their sources, 
so the superposition of two solutions is also a solution. This 
is true of EM waves in both the RF band and the optical 
frequency band, but there is a major difference between the 
two types of waves which has to do with the physics of the 
intended receiver.  Oscillating EM waves used in radio 
transmissions are designed to be detected via their interaction 
with a conducting antenna, in which an Alternating Current 
(AC) is induced with a frequency equal to that of the carrier 
EM wave.   Consequently, if two EM waves utilizing the 
same carrier frequency and comparable strengths are 
transmitted in proximity to each other, the induced AC 
currents on the conducting antenna will superimpose and 
jamming will occur.  This issue, associated with the detection 
of radio waves, has far reaching consequences requiring the 
strict allocation of broadcast transmission frequencies to 
different parties.  
The authority for controlling the use of RF frequencies in 
the United States resides with the Federal Communications 
Commission (FCC).  The FCC also regulates content and 
requires broadcasters (government, corporate and amateur) to 
be licensed.  The RF spectrum, the total range of radio 
frequencies that can be used for communication in a given 
area, is a limited resource. Each radio transmission occupies 
a portion of the total bandwidth available.  RF bandwidth is 
regarded as an economic commodity, which has a high 
monetary cost and is in increasing demand. Because it is a 
fixed resource which is in demand by an increasing number 
of users, the RF spectrum has become increasingly congested 
in recent decades, and the need to use it more effectively is 
driving many additional radio innovations, such as trunked 
radio 
systems, 
spread 
spectrum 
(ultra-wideband) 
transmission, 
frequency 
reuse, 
dynamic 
spectrum 
management, frequency pooling, and cognitive radio.   The 
FCC, however, has no jurisdiction over the use of light waves 
for communication. 
Light waves are also a form of EM waves but they differ 
from RF in one important aspect:  because light photons are 
on the order of a million times more energetic than their RF 
counterparts, then instead of a conducting antenna, a different 
mechanism is employed for their reception.  A carrier wave 
for optical transmission is not necessary (to induce an AC 
current on an antenna) and the receiver comprises a focal 
plane array of miniature photodiodes.  High energy photons 
impacting the receiver focal plane detector array cause 
electrons to be emitted.  This is a highly localized 
phenomenon 
(with 
low 
spatial 
crossover 
noise).  
Consequently, a focal plane array may receive (and process) 
multiple signals simultaneously without experiencing 
jamming or interference, as long as there is some spatial 
separation between the respective receiving array detectors.  
This mechanism offers us an opportunity to implement a 
novel receiver strategy of angular multiplexing which we can 
exploit to remediate the problem of potential obstructions to 
the optical transmission line of sight.   In essence, our method 
will be to employ a redundant transmission of identical 
optical signals, narrowcast at the same frequency, containing 
the same identical data stream, but transmitted from spatially 
distinct origins.   
Optical data transmission has no spectrum regulations 
attached to it. Additional loads to the RF spectrum introduced 
by Smart Cities, the Internet of Things, and now, the 
ubiquitous use of RF communications for the most mundane 
of tasks are already taxing the availability of clear channels 
in that spectrum.  Unregulated optical alternatives are a 
simple way to relieve some of this stress and reduce the data 
collisions that will become more and more common in the 
future.  
Some of the benefits of employing a free-space optical 
communication system vs RF are: 
 
 
Alternative optical many-to-many localized 
communications channel 
 
Independent of cell phone data plans or the Internet 
 
Unregulated, uncensored and free to use 
 
Capable of forming localized social networks 
between individuals/vehicles within visual range 
without login 
 
Receive educational and entertainment information 
in theme parks, museums and conferences 
 
Receive information from virtually generated 
electronic billboards both indoors (e.g., airports) or 
outdoors 
 
Universal international use without limitation or 
data plan 
 
Stress reduction for the already overtaxed RF 
spectrum 
 
Energy-efficient, low power 
 
Does not require geolocation 
 
Highly secure (if so desired) because optical data 
beams do not have leaking sidelobes 
 
III. 
THE PRINCIPLES OF AUGMENTED-REALITY OPTICAL 
NARROWCASTING (ARON) 
The augmented reality aspect of ARON (US Patent 
9,747,503 [7]) provides the user with data overlaid over the 
field of view of the human eye, supplementing the experience 
of natural vision with information.  Narrowcasting is 
distinguished from broadcasting in that the transmitted 
radiation field containing the optical signal is limited in range 
and in its projected solid angle.  
 
15
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

ARON provides a user experience like no other.  The 
receiver (e.g., an ARON-equipped smartphone) is held 
vertically and the user views their surroundings through the 
wide angle camera function of a smartphone.  ARON 
transmitters are similar to small inexpensive flashlights, can 
be installed outdoors and their data content is programmable.  
Since ARON does not require a cell plan, WiFi, Bluetooth or 
any kind of network login the usage is very simple and 
natural, and is intended to enhance the normal human vision 
experience.   
ARON provides a many (transmitters) to many (receivers) 
network topology. ARON eliminates the need for the precise 
alignment of optical transmitters and receivers, due to its 
configurable narrowcast and wide receive angles, making 
optical communications at ranges of hundreds of meters 
practical and convenient for handheld use with mobile 
devices. Data received optically is automatically integrated 
with imagery from mobile-device cameras, thereby providing 
a user-friendly AR experience without the need for complex 
AR software and inputs from additional sensors.  
To prevent obstruction of the line-of-sight optical signals 
and ensure robustness of use we implement a 3-step 
mitigation process: 
1) We employ a robust forward error correction algorithm 
(i.e. data and retrieval buffering) of the signal which 
compensates for short term obstructions (Fig. 1).    
 
 
 
Figure 1. Forward error correction algorithm compensates for temporary 
obstructions. 
 
2) We expand the emission beam from a pencil-like beam to 
a uniform, configurable, broad beam using nonimaging 
optics [8] so that the receiver does not need to be accurately 
aligned with the beam (Fig. 2) and multiple users can receive 
the data from any transmitter.    
3) We employ multiple emitters, which through spatial 
separation, and angular multiplexing at the receiver’s focal 
plane array, coupled with an AI-style adaptive processing 
algorithm achieve a photonic cross-fire mode, ensuring with 
very high probability that at least one of the transmissions of 
interest will always reach the receiver (Fig. 3).    
 
 
 
Figure 2. Expanding the transmitter beam into a uniform swath. 
 
 
 
 
Figure 3. Combining transmitter swaths to achieve photonic cross-fire and a 
many-to-many network topology. 
 
    ARON provides a secure optical communication channel 
with capabilities that complement, rather than replace, Wi-Fi 
and other RF technologies. Our patented Adaptive 
Communications Focal-Plane Array can also function as an 
ultra-high-data-rate replacement for conventional RF-based 
Wi-Fi systems and can also be used for Li-Fi 
communications. 
    As an optical, rather than RF, communication channel, 
ARON is not subject to regulation by the FCC. Its directional, 
localized characteristics provide a unique capability to 
securely send and receive information in a manner that is 
difficult to achieve using RF channels, such as interacting 
with mobile emitters.  ARON provides a natural, user-
friendly method of exploring a local environment (e.g., a 
shopping district) using an intuitive, visually-oriented AR 
interface (Fig. 4). For social media applications, ARON 
provides a convenient means of automatically attaching 
relevant additional information in an AR format to shared 
photos and videos.  The ARON user can remain anonymous 
if desired. 
    ARON can fuse information transmitted via infrared light 
with video data from cameras in smartphones and other 
mobile devices to create dynamic AR imagery in real time, 
without reliance on cellular networks, Wi-Fi, the Internet, or 
other radio-frequency (RF) communication technologies. 
16
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

 
 
 
Figure 4. ARON-equipped smartphone receiving outdoor optical signals. 
 
    ARON is also intended to augment sensor fusion in the 
digital vehicle platform (Fig. 5). It can operate in locations 
where no cellular signals or other RF-based communications 
are available. Optically beamed information can be detected 
by vehicles at ranges on the order of 1 km. ARON’s 
directional, localized characteristics provide a unique 
capability to tailor the delivery of information, allowing 
ARON to easily communicate with moving vehicles. 
Multiple small ARON receivers providing 3600 coverage 
could be mounted on vehicles, with no beam steering 
necessary due to the wide-angle field of view afforded by the 
optics.  Received data can be selectively displayed on the 
vehicle console and/or stored in the vehicle central computer 
and filtered and forwarded as desired.   
 
 
 
Figure 5. Vehicle equipped with ARON transmitters and receivers. 
 
    The solid angle tailoring of the data beam, i.e. directing the 
projection of the radiant energy only to where it is expected 
to be required, into a predefined area, allows us to reduce 
energy consumption by a factor of as much as 300, as 
compared to Wi-Fi, for an equal data rate of transmission. By 
tiling multiple transmitters and pointing them with angular 
separation, we can form a combined transmission beam that 
covers a zone of interest (for example, we can form a beam 
exclusively illuminating a zone along a street where reception 
coverage might be desired). 
    Multiple data streams are detected and processed by the 
focal plane array but if one of the redundant streams is 
interrupted then an adaptive (AI-style) algorithm which 
continuously analyzes the receiver data identifies which of 
the streams is being interrupted and switches the data 
processing to an alternate stream.  Using this data processing 
algorithm it is straightforward to accommodate the 
simultaneous processing of 100 or more such streams on the 
focal plane array with a modest number of detectors (e.g., 
100-1,000).   
IV. 
THE ADAPTIVE COMMUNICATIONS FOCAL PLANE 
ARRAY (ACFPA)  
    Our Optical Narrowcasting System (ONS) utilizes Optical 
Receiver Modules (ORMs) to detect and receive optical data 
transmitted by Optical Transmitter Modules (OTMs).  An 
ORM must include at least one Optical Beacon Receiver 
(OBR) and one Optical Signal Receiver (OSR). OBRs are 
designed to detect the presence of, determine the angular 
position of, and receive information from beacons, which are 
modulated optical beams transmitted by OTMs. Beacons 
contain information identifying entities (e.g., businesses, 
organizations, or private individuals) associated with OTMs. 
Once an OBR has detected, located, and received identifying 
information from a beacon, an OSR may be used to receive 
data from a signal beam transmitted by the same OTM that 
transmitted the beacon. A signal beam is a modulated optical 
beam that transmits data other than identifying information 
and typically utilizes a much higher average data rate than 
beacons. 
    In most cases it is desirable for an OBR to have a relatively 
wide field of view (FOV), because its purpose is to search for 
OTMs in situations in which little, if any, information will be 
available regarding their horizontal and vertical angular 
locations. A video camera is a suitable choice for use as a 
sensor for an OBR. Such a camera consists of an imaging lens 
with a focal-plane array (FPA) in its focal plane. The FPA is 
a 2D array of optical detectors designed to sequentially 
capture multiple frames of imagery at a frame rate usually on 
the order of a few tens of Hz. A narrowband optical filter will 
generally also be included in the optical train to improve the 
signal-to-noise ratio (SNR) by suppressing incident 
background radiation outside the beacon waveband. With the 
appropriate choice of imaging lens and FPA, such a video-
camera-based OBR can have a sufficiently large FOV to 
provide a convenient means of searching for, detecting, and 
receiving data from beacons. The bit rate at which identifying 
information can be received from beacons by such a camera 
is limited by the Nyquist-Shannon sampling theorem to no 
more than half its frame rate. Since the information content 
of the identifying information is typically quite small (e.g., 
several bytes), this is not a serious limitation.  
 
17
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

    Although a conventional video camera is a suitable choice 
of sensor for use in an OBR, it turns out not to be suitable for 
use in an OSR. In most cases, an OSR must be capable of 
receiving data from signal beams at much higher average data 
rates than OBRs will typically receive data from beacons. 
Typically, data rates on the order of 1 Mb/s or higher may be 
required. A video camera used as a sensor in an OSR 
operating at a data rate of 1 Mbit/sec would have to have a 
frame rate of at least 2 MHz. The highest frame rates 
provided by conventional video cameras are on the order of 
240 Hz, which is much too low. The ARON focal plane array 
(ACFPA, Fig. 6) differs from a video-style FPA in that it 
exploits the sparseness of the positioning of the 
communication signals on the FPA.  So for example, in 
contrast to a typical 10 megapixel video FPA with a full 
frame sampling rate of  240 Hz, such as may employed by 
imaging cameras, ARON will employ a 100 element FPA 
array of detectors which is sampled at 2 megahertz.  The total 
throughput of the receiver chip in pixels per second is 
comparable in both cases. 
 
 
Figure 6. Multiple transmitter signals captured by the ACFPA. 
 
    Our Adaptive Communications FPA (ACFPA) provides 
the capability of receiving signal beams from OTMs at the 
required data rates. An Optical Communications Camera 
(OCC) consisting of an imaging lens with such a ACFPA in 
its focal plane will be capable of serving as both an OBR and 
an OSR, as long as the beacons and signal beams received 
from a given OTM do not overlap in time. As discussed 
above with regard to OBRs, a narrowband optical filter would 
most likely be included in the optical train of an OCC to 
suppress out-of-band background radiation. The ACFPA is 
designed to take advantage of the fact that the number of 
OTMs found within the FOV of the OCC will, in practice, be 
very small relative to the number of its detectors. The rate at 
which data is required to be output by the CFPA can therefore 
be substantially reduced by only outputting data from 
detectors that are actually receiving signal beams from 
OTMs, or from a subset of such detectors. 
    Detailed information describing the ACFPA chip design 
and the method of data processing is provided in US Patent 
9,853,740 [9]. 
V. 
PERFORMANCE MODEL AND VALIDATION 
    To support our device design studies and provide a 
working physics tradeoff model for free-space optical 
communication, we composed a comprehensive signal to 
noise 
model 
to 
approximate 
the 
communications 
characteristics of an ARON-like device.  The Technology 
Demonstration Unit (TDU) was then designed and fabricated 
using these modeled parameters to validate this model under 
real life test conditions.   The methodology for the model and 
the detailed physics formulas are described in detail in the 
RCA Electro-Optics Handbook [10].     
    The model inputs are driven by the TDU system required 
capabilities.  The outputs of the model flow into the hardware 
design parameters.  In Section VI, we discuss the actual tested 
performance results of the TDU in comparison with the 
model.   
    The top-level requirements that drove our demo unit 
design are: 
 
 
A small IR transmitter with low power (under 5W 
total dissipation), using an LED source. 
 
Receiver to be integrated into smartphone Rx’s 
case area near that of existing cell camera. 
 
Robust, no signal loss in communications to / 
between handheld phones with inherent physical 
jitter and occasional gross signal loss. 
 
Communication range up to 400 meters under ideal 
conditions passing HD video signals at rates higher 
than that required to watch in real time (i.e., able to 
quickly buffer excess error-free data). 
The model assumptions are: 
 
 
Number of transmitter optics used, with 8° 
horizontal tilt difference between adjacent optics: 5. 
 
Output horizontal beam width produced by 
combined transmitter optics: 
,
40
trans horiz

 . 
 
Output vertical beam width produced by combined 
transmitter optics: 
,
8
trans vert

 . 
 
Peak optical output power (during transmission of a 
1-bit) of infrared emitting diode used in each 
transmitter optic: 
,
1.4 W
Psrc max

. 
 
Center wavelength, for both transmitter and 
receiver: 
c  850nm
. 
 
Optical bandwidth, for both transmitter and 
receiver: 
75nm


. 
 
Bit rate: 
BR  1MHz
. 
18
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

 
Maximum 
allowable 
bit-error 
probability: 
9
10
error
P


. 
 
Modulation scheme: return-to-zero (RZ) on-off 
keying (OOK). 
 
Duty cycle of signal pulse, defined as the duration 
of a transmitted signal pulse representing a binary 1-
bit in units of integration times: 
0.85
mod

. 
 
Optical efficiency of transmitter optics, due to 
reflection and transmission losses: 
0.80
trans

. 
 
In-band 
atmospheric 
extinction 
coefficient: 
1
0.1km
atmos



. (This value is based on Figure 7-3 
of the RCA Electro-Optics Handbook, which shows 
horizontal clear-air attenuation coefficient as a 
function of wavelength. Atmospheric transmittance 
as a function of range r from transmitter to receiver 
is 
( )
exp(
)
atmos
atmos
T
r
r



 .) 
 
In-band spectral background radiance for use in 
computing photon noise produced by background 
radiation: 
2
W
500
m
sr μm
Lback



  (assumption of 
sun-illuminated 
background 
during 
daytime 
operation) or 
2
W
5
m
sr μm
Lback



 (assumption for 
nighttime operation). 
 
Optical efficiency of receiver optics: 
0.8939
rec

 
(assuming uncoated polycarbonate lens). 
 
Full width of square field of view of receiver optics: 
3.6
FOVrec

 . 
 
Refractive index of medium in which each detector 
in the receiver is immersed: 
1.00
ndet

. 
 
External quantum efficiency of each detector in the 
receiver: 
0.7402
QEdet

. 
 
Specific detectivity of each detector in the receiver: 
12 cm
Hz
4.06
10
W
Dstar



. 
The output intensity in the center of the beam produced by 
the five transmitters (with 8° horizontal tilt difference 
between adjacent optics) is 43.9 W/sr, assuming the optical 
output of each infrared emitting die is 1.4 W and neglecting 
reflection and transmission losses. When optical losses are 
included, this becomes 35.12 W/sr, where we have assumed 
each transmitter has an optical efficiency of 0.80. The 
maximum range for daytime operation is 415 m. The 
irradiance at this maximum range is: 
 
8
8
,
2
2
2
W
35.12
W
W
sr
(415m)
2.039
10
0.959
1.956
10
(415m)
cm
cm
max range
atmos
E
T









. 
The primary model output data included:  
 
 
Minimum transmitter exit pupil diameter, based on 
étendue conservation (~260 mm2 ). 
 
Minimum signal Irradiance at entrance pupil – the 
minimum required optical power at input aperture 
of the receiver (2e-8 W/cm2). 
 
Day and Night maximum operational range based 
upon bit rate (see Fig. 7 and Fig. 8) 
 
Day maximum operational range based upon Rx 
aperture (see Fig. 9). 
 
 
Figure 7. Maximum range vs bit rate (day). 
 
 
Figure 8. Maximum range vs bit rate (night). 
 
 
Figure 9. Maximum range vs aperture (day). 
VI. 
TECHNOLOGY DEMONSTRATOR UNIT 
    To demonstrate the feasibility and functionality of the 
ARON concept, we have developed and fabricated a 
Technology Demonstration Unit (TDU) [11] that provides a 
19
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

communication channel in the 810-890 nm near-infrared 
(NIR) wavelength band, with a data rate greater than 1 Mbit 
per second and an operational range tested to work in excess 
of 200 meters in broad daylight. The unit consists of an optical 
transmitter (OT) and an optical receiver (OR), depicted in 
Figs. 10 and 12, respectively.   This unit can transmit and 
receive HD video (and other digital files). 
    An ARON receiver’s OBR measures the horizontal and 
vertical angular positions of ARON transmitters detected 
within its field of view (FOV) and then creates visual 
representations of the locations of the transmitters, including 
the identities of entities operating the transmitters. These 
representations comprise icons and text overlaid at the 
positions of these transmitters within live imagery produced 
by a video camera collocated with each ARON receiver. For 
example, the availability of information transmitted from a 
pizza restaurant may appear in the form of an iconic 
representation of a pizza accompanied by the name of the 
pizza restaurant, where the icon and text are overlaid at the 
location of the actual restaurant within the live video imagery. 
Controls are provided for allowing users to opt to receive 
high-bandwidth information of interest to them from the pizza 
restaurant’s ARON transmitter or from additional ARON 
transmitters that may also be viewable in the FOV. 
  
 
 
Figure 10. Cross-sectional perspective view of optical transmitter assembly 
for technology demonstration unit employing a nonimaging wineglass 
collimator. 
 
    The TDU’s OT design comprises OT electronics, an 
incoherent solid-state NIR emitter, and a nonimaging 
beamforming optic. Our transmitter requires a mere 4 W of 
electrical power and has an exit-pupil diameter of 18 mm. The 
ARON system requires each OT to simultaneously transmit 
two types of modulated optical beams. The first type, referred 
to as a beacon, provides the means for an OR to: (1) detect the 
presence of OTs, (2) identify entities operating OTs, and (3) 
determine the positions of OTs within the FOV of the OR’s 
visible-light camera. The second type of modulated beam, 
referred to as the signal, provides the actual information the 
operator of the OT wishes to send. Typically the average data 
rate transmitted by an OT in the form of signals will be much 
higher than that transmitted in the form of beacons. 
Temporary obstructions of the beam path that may occur due 
to moving obstacles are handled effectively using forward 
error correction algorithms. 
 
 
Figure 11. ARON transmitter forming a uniform 8o–square data beam. 
 
 
 
 
Figure 12. Optical receiver assembly of technology demonstration unit, 
mounted in a smartphone case. 
 
 
    To simultaneously transmit beacons and signals, the TDU 
uses a double-modulation scheme, in which a beacon having 
a data rate of 10 bits per second modulates a signal having a 
data rate greater than 1 Mbit per second. (ARON systems 
having far higher bit rates are feasible.) The double-
modulation scheme has the advantage of allowing it to utilize 
a single NIR source and beamforming optic to simultaneously 
transmit both beacons and signals. 
    Fig. 10 depicts a cross sectional view of the NIR source and 
beamforming optic for the TDU’s OT. The efficient, highly 
compact nonimaging optical design of the beamforming optic 
utilizes an advanced reflective collimator followed by a 
Köhler homogenizer to transform the output of the source into 
a NIR beam that is highly uniform within an 8°-square angular 
region (Fig. 11). The uniform square output beam allows 
copies of this optic, each with its own emitter, to be combined 
as modules to produce a customized tiled beam swath 
consisting of multiples of the 8°-square, arranged horizontally 
and/or vertically. A wide beam swath enables widely 
separated receivers to be able to simultaneously tune in to the 
transmission. The beamforming optical design used in the 
TDU is representative of a design that could be used for an OT 
mounted at a fixed installation (e.g., outside or inside a 
building) or on a vehicle.  The wineglass collimator optic 
achieves a volume reduction factor of 2.5 compared to a 
conventional parabolic reflector. 
20
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

    The TDU OT electronics (not shown) consists of a 
smartphone interfaced via USB on-the-go (OTG) to a 
Universal Asynchronous Transmitter/Receiver (UART) 
which converts the byte-wise transmit data into a proprietary 
return-to-zero serial data format with a high level of 
embedded forward error correction. A current driver is used 
to modulate the solid-state NIR LED emitter with this data. 
    The OR design for the TDU comprises OR electronics, a 
beacon receiver, and a signal receiver, all mounted within a 
smartphone case and interfaced with a smartphone by means 
of a USB connection. An ARON app installed in the receiver 
smartphone provides the capability of combining beacon 
information received from OTs with live imagery produced 
by the phone’s camera to create and display AR presentations. 
    The TDU’s beacon receiver is a monochrome NIR video 
camera, which serves the purpose of detecting beacon data 
transmitted by the OT and using this data to determine the 
angular position of the OT within the FOV of the visible-light 
camera. The beacon receiver also receives and decodes 
identifying information encoded in transmitted beacons, 
allowing the OR to identify the entity operating the OT.  Once 
a beacon has been detected, the processor determines its 
horizontal and vertical position within the visible-light 
camera’s FOV and generates and overlays an augmented 
reality icon with identifying text at the correct location on the 
live video imagery, where the icon and text represent the 
identity of the detected OT obtained from its beacon. Multiple 
beacons can be handled.  These functions could easily be 
integrated with a cell phone’s existing camera if the OR is also 
integrated into the phone, as opposed to being in a cell phone 
case for the TDU. 
    The TDU’s signal receiver uses a 6x6 array of square-
aperture lenslets to concentrate flux onto a 6x6 array of silicon 
photodetectors. The outputs of all 36 detectors are summed, 
amplified, filtered and digitized to produce the signal output. 
The signal receiver has a 3.6°-square FOV within which it can 
receive signals. Since this FOV is much smaller than the FOV 
of the beacon receiver and the phone’s visible-light camera, in 
order to receive a signal from a detected OT, the TDU user 
needs to manually tilt the phone until the OT is within the 
signal receiver’s FOV.   
    Fig. 13 depicts the display screen of the receiver 
smartphone after the ARON app has been activated, showing 
the live video feed, overlaid with a central box representing 
the FOV of the signal receiver and an icon and text 
representing a detected OT. To receive a signal from the 
detected OT, the phone is tilted manually until the icon is 
located inside the box, at which time signal data will begin to 
be received. Receipt of signal data will continue as long as the 
icon is kept within the box.  Once received, the app allows the 
user to view the signal data in various ways.  
    This section has described the elements of our technology 
demonstrator unit.  In its planned production configuration, 
as an integrated internal component within a smartphone, an 
ARON receiver and optical assembly will ultimately occupy 
a footprint no larger than a conventional video camera.  In 
this consumer configuration, employing an ACFPA chip, the 
phone will not require tilting to receive signals.   
 
 
 
Figure 13. Display produced by augmented-reality optical narrowcasting app 
in technology demonstration unit’s receiver smartphone. 
 
 
    The TDU’s transmitter uses a single LED emitting into a 
wineglass collimator through a pair of micro-lens 
homogenizers, with dimensions and parameters very similar 
to those of the model.  The TDU receive aperture was chosen 
to be ~19mm and bit rate at 1.1Mbit/s (good HD video 
transmission speed) was selected, both to support the 400m 
modeled maximum range goal.  The TDU’s receiver uses 36 
fixed micro photodiodes in a 6x6 array, illuminated by 36 
micro-lenslets also in a 6x6 array.  These provide a large 
aperture while maintaining a very short system depth and are 
very close to those used in the theoretical model. The micro-
lens array, an optical bandpass array and the detectors are 
mounted on a small circuit board along with the necessary 
support electronics.  All are mounted in a case containing a 
smartphone used for the processing and display of the 
received information. 
    Results of outdoor tests with the Technology Demonstrator 
Unit hardware showed that actual daylight performance 
matched closely with that predicted by the theoretical model.  
Demonstrated maximum range was in excess of 200 m versus 
the desired 400 m.  
    Two known issues explain a large part of this range 
difference.  The modeled receiver optics loss did not include 
additional attenuation in the band-pass filter, which has a 
pass-through limited to about 85% at our wavelength.  
Amplifier choice in the front-end electronics limited trans-
impedance gain to about 75% of that desired for optimum 
signal to noise.  In all, signal at the receiver was down at least 
64%.  Both of these losses can be mitigated easily in the 
future. 
    Finally, a commercial smartphone implementation would 
use a much smaller detector size than our TDU, and with an 
AFCPA chip architecture we estimate that the resulting 
detector noise could be lower by a factor of 4, which would 
lead to a realistic achieved signal reception range of 400 m 
for transmitted HD video. 
21
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

VII. 
CONCLUSION AND FUTURE WORK 
    The availability of clear RF channels is fading.  The yearly 
growth in demand for data bandwidth is fueled by the needs 
of IOT and Smart Cities.  An open, unrestricted optical 
communications channel can provide space for at least some 
of this growth and enable a novel path for information 
expansion.   
    ARON’s use of its tailored, configurable transmit areas for 
narrowcasting to desired locations, its ACFPA chip for 
angular multiplexing and detection of signals over a wide area, 
and its error correction and photonic cross-fire to solve the 
problem of obstruction, make it a new and novel platform to 
support this alternate data channel.  ARON is intended to 
complement, rather 
than replace, 
the 
use 
of 
RF 
communications and to help ease future bottlenecks in a useful 
and elegant fashion. 
     Our main 
conclusion 
is that 
free-space 
optical 
communication using incoherent light sources is a much more 
practical proposition than has been believed to date. 
     Future work will entail the design and fabrication of the 
ACFPA chip and the integration of ARON into smartphone 
platforms and automobiles. 
    ARON is the subject of 21 US Patents. 
 
 
 
 
REFERENCES 
[1] Alexander Graham Bell, Wikipedia,  
https://en.wikipedia.org/wiki/Alexander_Graham_Bell.  
Retrieved 6-18-23. 
[2] Service RF. Laser technology. “Hot new beam may zap 
bandwidth bottleneck”. Science. 2001 Dec 21;294(5551):2454. 
[3] Y. Tanaka, S. Haruyama, and M. Nakagawa. "Wireless optical 
transmissions with white colored LED for wireless home 
links". Personal, Indoor and Mobile Radio Communications. 
Vol 2, pp. 1325–1329, 2000.  
[4] J. Grubor, S. Randel, K.-D. Langer and J. W. Walewski. 
"Broadband Information Broadcasting Using LED-Based 
Interior Lighting". Journal of Lightwave Technology. Vol 26 
(24), pp. 3883–3892, 2008. 
[5]  I. E Lee, M. L. Sim and F. W. L. Kung, "Performance 
enhancement of outdoor visible-light communication system 
using selective combining receiver". IET Optoelectronics. Vol 
3 (1), pp. 30–39, 2009. 
[6] M. A. Khalighi and M. Uysal. "Survey on Free Space Optical 
Communication: A Communication Theory Perspective". 
IEEE Communications Surveys & Tutorials. Vol 16 (4), pp 
2231–2258, 2014. 
[7] N. E. Shatz, J. C. Bortz, Optical narrowcasting augmented 
reality, US Patent 9,747,503, 2017. 
[8] R. Winston, J. C. Miñano, and P. Benítez, with contributions 
by N. Shatz and J. Bortz, Nonimaging Optics, Elsevier 
Academic Press, New York, 2005. 
[9] J. C. Bortz and N. E. Shatz, Adaptive communications focal 
plane array, US Patent 9,853,740, 2018. 
[10] RCA Electro-Optics Handbook, RCA Corp, 1974. 
[11] N. Shatz, J. Bortz and M. Squire, "Demonstration of 
augmented-reality optical narrowcasting," 2018 15th IEEE 
Annual Consumer Communications & Networking Conference 
(CCNC), Las Vegas, NV, USA, pp. 1-2, 2018. 
 
 
 
 
 
 
 
22
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-071-1
SMART 2023 : The Twelfth International Conference on Smart Cities, Systems, Devices and Technologies

