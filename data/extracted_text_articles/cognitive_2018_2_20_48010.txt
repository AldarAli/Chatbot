Image Transformations in a Cognitive System  
Tunnel transition and combining ensembles  
Ekaterina D. Kazimirova 
Kaspersky Lab  
Moscow, Russia 
e-mail: Ekaterina.Kazimirova@kaspersky.com  
Abstract —
The nature of creativity and its hidden 
mechanisms are areas that researchers have only recently 
begun to approach. In this paper, within the symbol-image 
cognitive architecture paradigm, we consider some operations 
on graphs that can be compared to the process of image 
synthesis and transformation in a cognitive system. We address 
such phenomena as the combination of neural ensembles and 
tunnel (sub-barrier) transition in a cognitive system. We also 
consider degree of fusibility of a cognitive system that 
characterizes its creative ability.  
Keywords- graph; symbol; attribute; cognitive architecture; 
creativity. 
I.
INTRODUCTION 
In the era of the rapidly developing ecosystem of living 
things (the Internet of Things) and human-friendly 
anthropomorphic robots [1][2][3], the issues related to 
developing artificial intelligence systems that are not only 
rational, but also creative, take on a special significance. 
The ability of cognitive systems to generate new thoughts 
and new images will turn machine into man's equal partner 
in addressing important issues of the 21st century, in solving 
its challenges, such as overcoming disease and resolving 
complicated economic problems. 
 In this paper, we discuss some of the mechanisms that 
could be employed in artificial cognitive systems to 
generate new information. Such ability is treated as a 
synonym for creativity. 
The paper is organized as follows. A description of the 
model is provided in Section II. An example of the model’s 
application is provided in Section III. The summary and 
conclusions are in Section IV. 
II.
DESCRIPTION OF THE MODEL
We consider the following organization of a cognitive 
system. Each image encoded in the system is represented by 
its attributes and the corresponding symbol. The attributes 
are linked together by the image’s symbol [4][5]. The main 
role of symbolization is compressing information, but we 
believe it is equally important that it prevents images with 
the same attributes from being mixed together. This idea 
was briefly described in [6]. 
For the sake of brevity, we consider a two-layer system 
(graph), where the first layer encodes image attributes and 
the second layer encodes image symbols. 
A.
Basic Relationships 
In our model, the following relationships are formed 
between a symbol and its attributes. When two or more 
attributes are activated, the symbol is also activated. 
Conversely, when a symbol is activated, the attributes of its 
image are also activated. 
Figure 1. The basic model represented by a two-layer graph. The markers 
“А” and “В” correspond to symbols, 1, 2, 3, 4, 5 correspond to their 
attributes. 
In Figure 1, the basic two-layer model is presented. The 
symbol "A" is activated when there are signals from 
particular attributes (nodes 1, 2, or 3) in different 
combinations, (provided that more than one node is 
involved). The symbol "B" is activated when there are 
signals from nodes 3, 4, or 5 in different combinations (also 
provided that more than one attribute is involved). When the 
symbol "A" is activated, this leads to the activation of an 
image consisting of a set of attributes (1, 2, 3). Activation of 
the symbol "B" leads to the activation of an image consisting 
of a different set of attributes (3, 4, 5). 
Let us consider the following example. The relations 
between attributes and symbols in our model of a cognitive 
system work similarly to children’s riddles. Something that 
is round, striped, and sweet (nodes: attributes) is a 
watermelon (node: symbol); something that is striped and 
orange, with sharp claws and teeth, is a tiger. 
30
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

Concerning the problem of the possibility of images 
being mixed together, note that a cat and a dog have many 
attributes in common. According to our model, it is symbols 
that enable the cognitive system to tell them apart. 
Let us illustrate the “more than one attribute” rule. 
Given the attributes “striped” and “round”, we can guess 
“watermelon” and given the attributes “striped” and “with 
sharp teeth”, we can guess “tiger”. However, given only one 
attribute (e.g., “striped”), we cannot guess what the object 
is. And conversely, specifying a symbol (e.g., watermelon), 
brings its attributes to mind (“striped”, “round”, “sweet”, 
“with seeds”, etc.). 
In a real-world system, the number of layers is obviously 
much greater. For example, there is the integrative symbol 
“carnivores” (Lat. Carnivora) above the symbols “cat” and 
“dog”, etc.
B.
Attribute and Attention 
We assume that a cognitive process starts when one of 
the cognitive system’s elements appears in the field of 
attention. The development of a thought involves revealing 
connections between that element and its neighbors, as well 
as forming its new relationships and connections with other 
elements of the cognitive system. 
Figure 2. Activation of two symbols by one attribute. 
According to our concept, prolonged activation of one 
attribute (for a time interval t > tatt) increases its influence. 
As a result, that attribute, even if it is alone, can activate the 
associated symbols. In Figure 2, the attribute “3” is 
activated by attention and, in turn, activates the symbols 
“A” and “B”. 
For example, thinking about speed, we can recall a car, a 
cheetah, and an airplane. 
Below we look at the ways in which a system based on 
these rules can generate new information by transforming 
images – that is, creating new images out of existing ones. 
C.
Combining ensembles 
The symbols associated with a certain attribute can be 
activated by activating the attribute for a time interval t > tatt. 
These symbols, in turn, activate the rest of their attributes. 
As a result, a new ensemble combining the elements of two 
images (symbols and attributes) is formed.  
Figure 3. The activation of symbols A and B leads to the activation of all 
their attributes. This gives rise to an ensemble ("A + B"). 
In Figure 3, the attribute “3” is enhanced by attention or 
emotion, i.e., it receives additional activation from “neurons” 
(represented by nodes in our model) that are external relative 
to the ensembles A and B. Due to enduring activation, it 
activates both neuron-symbols “A” and “B” simultaneously. 
These two images, i.e., symbols "A" and "B" plus all their 
attributes, are temporarily united into an ensemble. Starting 
from that moment, the attributes of image “B” also belong to 
the symbol “A”, and vice versa (for a certain time interval). 
This mechanism could serve as the basis for metaphorical 
thinking (feature transfer). We briefly described this problem 
in [7]. Issues related to the integration of information in the 
cognitive system are also discussed in [8]. 
Let us consider the following example of metaphorical 
thinking. In [9], the general metaphor “argument is war” is 
presented. G. Lakoff and M. Johnsen write, “We see the 
person we are arguing with as an opponent. We attack his 
positions and we defend our own. We gain and lose ground. 
We plan and use strategies. If we find a position 
indefensible, we can abandon it and take a new line of 
attack.” What they describe in this passage is attribute 
transfer between the concepts “war” and “argument”.  
It is important to realize that the transfer process starts 
after the common attribute of two concepts is found. In the 
case of the metaphor “argument is war”, the term 
“confrontation” represents the common attribute, while the 
transfer process follows the mechanism described above.  
G. Lakoff and M. Johnsen write, “The most important 
claim we have made so far is that metaphor is not just a 
matter of language, that is, of mere words. We shall argue 
that, on the contrary, human thought processes are largely 
metaphorical.”  
D.
Tunnel transition 
Under certain conditions, the activation of attributes can 
lead to transitions on the same (attribute) level (activation of 
attributes through attributes) rather than the activation of 
symbols. Suppose that there is a neurotransmitter acting at 
the network’s attribute level, dynamically strengthening the 
connections and thus facilitating the transition from one 
attribute to another. Under such conditions, attributes 
(neuron attributes) can activate each other without the 
activation of symbols (see Figure 4). We called this effect 
31
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

“tunnel (sub-barrier) transition”. In this case, the activation 
wave can “dive” under an adjacent symbol and activate one 
of the more remote symbols rather than the nearest one. 
This process could be controlled by presence or absence 
of a neurotransmitter. Favorable conditions for such a 
process could also be created by the "constitutional" 
characteristics of the cognitive system, e.g., relatively weak 
connections between the attribute and symbolic levels 
(attribute-symbol), or, on the contrary, by the relatively 
strong connections at the attribute level (attribute-attribute). 
Figure 4. Flow within the cognitive system.
We would like to emphasize that Hebb's rule [10] describes 
the strengthening of connections between closely spaced 
(directly contacting) neurons. In contrast, the tunnel 
transition corresponds to the formation of connections 
between non-neighboring neurons that are not directly 
connected. 
E.
Fusibility of thinking 
Within our model, the presence of a “neurotransmitter” in 
a subnet containing attributes and/or the cognitive system’s 
constitutional features make this system more "fusible", i.e., 
more fluid (akin to molten metal). It would be interesting to 
study the "coefficient of fusibility” (Kfus) of a cognitive 
system defined as the ratio of the connection strength at the 
attribute 
level 
to 
the 
strength 
of 
attribute-symbol 
connections: 
symb
atr
fus
W
W
K
/

(1) 
Note that mental disorders can be associated with 
different types of associative thinking impairment. For 
example, the so-called acceleration of thinking (racing 
thoughts) is characterized by an excessive emergence of 
associations. As a result, thinking becomes superficial, with 
attention being switched too easily. 
Let us examine how the character of thinking depends 
on Kfus. The creative process involves working with 
associations as the mechanism of new image production. 
We believe that the "coefficient of fusibility" may control 
the ease with which associations emerge in the cognitive 
system. At low values of Kfus, the "flow" (activation of 
connections) between images on the same attribute level and 
the subsequent merging of different images into new ones is 
hampered, and the system becomes rigid. Such a system can 
only work with the images (symbols together with their 
attributes) it already contains. The system can analyze them, 
i.e., it knows the properties of each symbol and can attribute 
it. However, such a cognitive system is virtually incapable 
of synthesizing new images. As Kfus increases, it becomes 
possible for new images to appear within the cognitive 
system. With Kfus > Kcritical, flow across the attribute level 
becomes too easy, numerous associations arise, but they are 
not fixed in new images. This process represents a thinking 
disorder. 
In psychology, our concept corresponds (to some extent) 
to Raymond Cattell’s concept [11] of fluid and crystallized 
intelligence, where crystallized intelligence is the ability to 
operate with already acquired knowledge, skills and 
experience, while fluid intelligence (or fluid reasoning) 
corresponds to the ability to reason and solve novel 
problems in new ways.  
III.
EXAMPLE 
As an example, let us consider the poem “The Soft 
Moscow Rain” by Osip Mandelstam, translated by Richard 
McKane [12]: 
It shares so stingily 
its sparrow cold – 
a little for us, a little for the clumps of trees, 
a little for the cherries for the hawker’s stall. 
     And a bubbling grows in the darkness, 
the light fussing of tea-leaves, 
as though an ant-hill in the air 
were feasting in the dark green grass; 
  fresh drops stirred 
like grapes in the grass, 
as though the hot-bed of the cold 
was revealed in web-footed Moscow. 
Let us consider the main symbols and their important 
attributes that are mentioned in this poem.  
Figure 5. Semantic connections in Mandelstam’s poem The Soft Moscow 
rain. "Tunnel transitions" result in unexpected combinations of symbols. 
32
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

In Figure 5, we can see that symbols that are 
semantically close to the term “rain” (such as “cloud” and 
“water”) do not appear in the poem. At the same time, 
connections are established via attribute-attribute transitions 
between semantically distant symbols, such as “rain”, “ant-
hill”, “tea leaves”, and “grapes”. The artistic value of the 
poem and the fact that it is a masterpiece seems to be due to 
the “tunnel effect” which reveals distant connections, thus 
helping to communicate an impression of the rain. 
IV.
CONCLUSION
Problems associated with understanding the mechanisms 
of creativity and reproducing them form a barrier to creating 
general Artificial Intelligence (AI), which has not been 
overcome so far. It seems that entirely anthropomorphic AI 
could only be developed if artificial intelligence systems 
were able to think independently and perform creative tasks. 
To achieve this, we will have to solve the problem of 
generating new information in the cognitive system, which 
was discussed within the framework of Dynamic Theory of 
Information [13]. In this paper, we made an attempt to show 
the possible basic mechanisms of information synthesis in 
the cognitive system, illustrating them with some operations 
on graphs. The main concepts discussed in this paper are: 

formation of ensembles that combine different 
images; 

the "tunnel effect", i.e., the attribute-attribute 
transition that leads to unexpected combinations of 
symbols; 

the "degree of fusibility" of a cognitive system. 
The formation of ensembles and the “tunnel effect” are 
associated with the mechanism that can transform images in 
the cognitive system. In the former case (the formation of 
ensembles), image transformation is caused by the transfer of 
attributes from one image to another. In the latter case (the 
“tunnel effect”), the attributes of semantically distant 
symbols are combined together. This can result not only in 
the enrichment of an existing image, but also in the 
generation of a new image (e.g., as in Mandelstam’s poem, 
where rain is associated with an ant-hill and grapes). Both 
mechanisms are characteristic of cognitive processes, not the 
simple image classification provided by existing artificial 
neural networks. It should be emphasized that in both of the 
above cases, new information is generated. These 
mechanisms could be closely connected with the intuitive 
and creative thinking process. 
The concept of the degree of fusibility, as well as the 
coefficient of fusibility introduced in this paper, when 
applied to an artificial cognitive system, could provide a way 
of controlling the rigidity of artificial cognitive systems, 
making them more adept at reflecting the reality or, on the 
contrary, more intuitive and creative.  
Implementing these mechanisms could help to achieve an 
AI that can think creatively and has intuition. The next step 
would be to develop these ideas further as a mathematical 
model. 
ACKNOWLEDGMENTS
The author is grateful to Olga Chernavskaya, Evgeny 
Volovich and Artem Vorontsov for the fruitful discussions.  
REFERENCES 
[1]
What 
is 
Amazon 
Alexa? 
Available 
from: 
https://developer.amazon.com/alexa  Retrieved 2018.01.09 
[2]
Meet 
your 
Google 
Assistant. 
Available 
from: 
https://assistant.google.com. Retrieved 2018.01.09 
[3]
Azuma 
Hikari. 
Official 
Site. 
Available 
from: 
http://gatebox.ai/hikari/en/  Retrieved 2018.01.09 
[4]
O. D. Chernavskaya, D. S. Chernavskii, V. P. Karp, A. P. 
Nikitin, and D. S. Shchepetov, “An architecture of thinking 
system within the Dynamical Theory of Information,” BICA, 
vol. 6, pp. 147158, 2013. 
[5]
O. D. Chernavskaya, D. S. Chernavskii, V. P. Karp, Ya. A. 
Rozhylo “An architecture of the cognitive  system with 
account for emotional component,” Biologically Inspired 
Cognitive Architectures, vol.12, pp. 144–154, 2015. 
[6]
E. D. Kazimirova, “Two-Component Scheme of Cognitive 
System Organization: the Hippocampus Inspired Model,” The 
Ninth International Conference on Advanced Cognitive 
Technologies and Applications (COGNITIVE 2017) IARIA, 
Feb. 2017, pp. 2123, ISBN: 978-1-61208-531-9 
[7]
 E. D. Kazimirova, “Elements of the symbol-image 
architecture of cognition and their parallelism to certain 
linguistic phenomena”, Neurocomputers, vol. 4, pp. 3537, 
2015. Available from: http://www.radiotec.ru/article/16364 
Retrieved 2017.12.12 
[8]
M. Oizumi, L. Albantakis, and G. Tononi, “From the 
Phenomenology to the Mechanisms of Consciousness” 
Integrated Information Theory”. Available from:  
http://journals.plos.org/ploscompbiol/article?id=10.1371/jour
nal.pcbi.1003588 Retrieved 2018.01.09. 
[9]
G. Lakoff and M. Johnsen, “Metaphors we live by”, London: 
The university of Chicago Press, pp. 8–10, 2003. 
Available from: http://shu.bg/tadmin/upload/storage/161.pdf 
Retrieved 2018.01.24 
[10] D. O. Hebb. The organization of behavior: a neuro-
psychological theory. New York, 2002. 
[11] R. B. Cattell, "Theory of fluid and crystallized intelligence: A 
critical experiment", Journal of Educational Psychology, 
vol. 54, pp. 1–22, 1963.DOI:10.1037/h0046743 
[12] Available 
from: 
 
http://arlindo-correia.com/200801.html 
Retrieved 29.01.2018 
[13] D. S. Chernavsky, Synergetics and information: Dynamic 
Theory of Information. Moscow: URSS, 2004. (in Russian). 
(Sinergetica 
i 
Informaciya: 
Dinamicheskaya 
Theoriya 
Informacii) 
33
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-609-5
COGNITIVE 2018 : The Tenth International Conference on Advanced Cognitive Technologies and Applications

