The Privacy Funnel from the Viewpoint of Local Differential Privacy
Milan Lopuha¨a-Zwakenberg
Department of Mathematics and Computer Science
Eindhoven University of Technology
Eindhoven, the Netherlands
email: m.a.lopuhaa@tue.nl
Abstract—In the Open Data approach, governments want to
share their datasets with the public, for accountability and to
support participation. Data must be opened in such a way that
individual privacy is safeguarded. The Privacy Funnel is a math-
ematical approach that produces a sanitised database that does
not leak private data beyond a chosen threshold. The downsides
to this approach are that it does not give worst-case privacy
guarantees, and that ﬁnding optimal sanitisation protocols can be
computationally prohibitive. We tackle these problems by using
differential privacy metrics, and by considering local protocols
which operate on one entry at a time. We show that under both
the Local Differential Privacy and Local Information Privacy
leakage metrics, one can efﬁciently obtain optimal protocols;
however, Local Information Privacy is both more closely aligned
to the privacy requirements of the Privacy Funnel scenario,
and more efﬁciently computable. We also consider the scenario
where each user has multiple attributes, for which we deﬁne
Side-channel Resistant Local Information Privacy, and we give
efﬁcient methods to ﬁnd protocols satisfying this criterion while
still offering good utility. Exploratory experiments conﬁrm the
validity of these methods.
Keywords—Privacy funnel; local differential privacy; in-
formation privacy; database sanitisation; complexity.
I. INTRODUCTION
Under the Open Data paradigm, governments and other
public organisations want to share their collected data with the
general public. This increases a governments transparency, and
it also gives citizens and businesses the means to participate
in decision-making, as well as using the data for their own
purposes. However, while the released data should be as
faithful to the raw data as possible, individual citizen’s private
data should not be compromised by such data publication.
To state this problem mathematically, let X be a ﬁnite set.
Consider a database ⃗X = (X1, · · · , Xn) ∈ X n owned by a
data aggregator, containing a data item Xi ∈ X for each user
i (For typical database settings, each user’s data is a vector
of attributes Xi = (X1
i , · · · , Xm
i ); we will consider this in
more detail in Section V). This data may not be considered
sensitive by itself, however, it might be correlated to a secret
Si. The aggregator wants to release the database to the general
public while preventing adversaries from retrieving the secret
values Si. For instance, Xi might contain the age, sex, weight,
skin colour, and average blood pressure of person i, while
Si is the presence of some medical condition. To publicise
the data without leaking the Si, the aggregator releases a
privatised database ⃗Y = (Y1, · · · , Yn), obtained from applying
a sanitisation mechanism R to ⃗X. One way to formulate this
is by considering the Privacy Funnel:
S1
S2
...
Sn
Database
X1
X2
...
Xn
Sanitised
Database
Y1
Y2
...
Yn
Q
Q
Q
Hidden from public
Figure 1. Model of the Privacy Funnel with local protocols.
Problem 1. (Privacy Funnel, [4]) Suppose the joint probability
distribution of ⃗S and ⃗X is known to the aggregator, and let
M ∈ R≥0. Then, ﬁnd the privatization mechanism R such
that I( ⃗X; ⃗Y ) is maximised while I(⃗S; ⃗Y ) ≤ M.
There are two difﬁculties with this approach:
1) Finding and implementing good privatization mecha-
nisms that operate on all of ⃗X can be computationally
prohibitive for large n, as the complexity is exponential
in n [6] [14].
2) Taking mutual information as a leakage measure has as
a disadvantage that it gives guarantees about the leakage
in the average case. If n is large, this still leaves room
for the sanitisation protocol to leak undesirably much
information about a few unlucky users.
To deal with these two difﬁculties, we make two changes to
the general approach. First, we look at local data sanitisation,
i.e., we consider optimization protocols Q: X → Y, for some
ﬁnite set Y, and we apply Q to each Xi individually; this
situation is depicted in Figure 1. These can be efﬁciently
implemented. Second, to ensure strong privacy guarantees
even in worst-case scenarios, we take stricter notions of
privacy, based on Local Differential Privacy (LDP) [11].
The structure of this paper is as follows. In Section II, we
deﬁne the mathematical setting of our problem. We discuss
two privacy notions, LDP and Local Information Privacy
(LIP), and discuss their relation to the Privacy Funnel. In
Sections III and IV, we show that for a given level of
LDP or LIP, respectively, one can efﬁciently ﬁnd the optimal
sanitisation protocol. In Section V, we consider the setting
where every Xi is a vector of attributes, and we show how
1
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-760-3
ICDS 2020 : The Fourteenth International Conference on Digital Society

to make protocols that protect against side-channel attacks. In
Section VI, we numerically assess the methods presented in
this paper.
II. MATHEMATICAL SETTING
The database ⃗X = (X1, · · · , Xn) consists out of a data
item Xi for each user i, each an element of a given ﬁnite set
X. Furthermore, each user has sensitive data Si ∈ S, which
is correlated with Xi; again we assume S to be ﬁnite (see
Figure 1). We assume each (Si, Xi) is drawn independently
from the same distribution pS,X on S × X which is known
to the aggregator through observing (⃗S, ⃗X) (if one allows for
non-independent Xi, then differential privacy is no longer an
adequate privacy metric [5] [16]). The aggregator, who has
access to ⃗X, sanitises the database by applying a sanitisation
protocol (i.e., a random function) Q: X → Y to each Xi,
outputting ⃗Y = (Y1, · · · , Yn) = (Q(X1), · · · , Q(Xn)). The
aggregator’s goal is to ﬁnd a Q that maximises the information
about Xi preserved in Yi (measured as I(Xi; Yi)) while leaking
only minimal information about Si.
Without loss of generality we write X = {1, · · · , a} and
Y = {1, · · · , b} for integers a, b. We omit the subscript i
from Xi, Yi, Si as no probabilities depend on it, and we write
such probabilities as px, ps, px|s, etc., which form vectors
pX, pS|x, etc., and matrices pX|S, etc.
As noted before, instead of looking at the mutual informa-
tion I(S; Y ), we consider two different, related measures of
sensitive information leakage known from the literature. The
ﬁrst one is an adaptation of LDP, the de facto standard in
information privacy [11]:
Deﬁnition 1. (ε-LDP) Let ε ∈ R≥0. We say that Q satisﬁes
ε-LDP w.r.t. S if for all y ∈ Y and all s, s′ ∈ S one has
P(Y = y|S = s)
P(Y = y|S = s′) ≤ eε.
(1)
This is less strict than the ‘standard’ notion of ε-LDP, which
measures the information about X leaked in Y . This reﬂects
the fact that we are only interested in hiding sensitive data,
rather than all data; it is a speciﬁc case of what has been named
‘pufferﬁsh privacy’ [12]. The advantage of LDP compared to
mutual information is that it gives privacy guarantees for the
worst case, not just the average case. This is desirable in the
database setting, as a worst-case metric guarantees the security
of the private data of all users, while average-case metrics are
only concerned with the average user. Another useful privacy
metric is Local Information Privacy (LIP) [9] [16], also called
Removal Local Differential Privacy [8]:
Deﬁnition 2. (ε-LIP) Let ε ∈ R≥0. We say that Q satisﬁes
ε-LIP w.r.t. S if for all s ∈ S and y ∈ Y we have
e−ε ≤ P(Y = y|S = s)
P(Y = y)
≤ eε.
(2)
Compared to LDP, the disadvantage of LIP is that it depends
on the distribution of S; this is less relevant in our scenario, as
the aggregator, who chooses Q, has access to the distribution
ε-LDP
2ε-LDP
ε-LIP
I(S; Y ) ≤ ε
ε-SRLIP
Multiple attributes
Figure 2. Relations between privacy notions. The multiple attributes setting
is discussed in Section V.
of S. The advantage of LIP is that is more closely related
to an attacker’s capabilities: since P(Y =y|S=s)
P(Y =y)
= P(S=s|Y =y)
P(S=s)
,
satisfying ε-LIP means that an attacker’s posterior distribution
of S given Y = y does not deviate from their prior distribution
by more than a factor eε. The following Lemma outlines
the relations between LDP, LIP and mutual information (see
Figure 2).
Lemma 1. (See [16]) Let Q be a sanitisation protocol, and
let ε ∈ R≥0.
1) If Q satisﬁes ε-LDP, then it satisﬁes ε-LIP.
2) If Q satisﬁes ε-LIP, then it satisﬁes 2ε-LDP, and
I(S; Y ) ≤ ε.
Remark 1. One can choose to employ more stringent privacy
metrics for LDP and LIP by demanding that Q satisfy ε-LIP
(ε-LDP) for a set of pS,X, instead of only one [12]. Letting
pS,X range over all possible distributions on S × X yields
standard LIP (LDP) (i.e., w.r.t. X).
In this notation, instead of Problem 1 we consider the
following problem:
Problem 2. Suppose pS,X is known to the aggregator, and
let ε ∈ R≥0. Then, ﬁnd the sanitisation protocol Q such
that I(X; Y ) is maximised while Q satisﬁes ε-LDP (ε-LIP,
respectively) with respect to S.
Note that this problem does not depend on the number of
users n, and as such this approach will ﬁnd solutions that are
scalable w.r.t. n.
III. OPTIMIZING Q FOR ε-LDP
Our goal is now to ﬁnd the optimal Q, i.e., the protocol
that maximises I(X; Y ) while satisfying ε-LDP, for a given
ε. We can represent any sanitisation protocol as a matrix Q ∈
Rb×a, where Qy|x = P(Y = y|X = x). Then, Q deﬁnes a
sanitisation protocol Q satisfying ε-LDP if and only if
∀x:
X
y
Qy|x = 1,
(3)
∀x, y: 0 ≤ Qy|x,
(4)
∀s, s′, y: (Q pX|s)y ≤ eε(Q pX|s′)y.
(5)
As such, for a given Y, the set of ε-LDP-satisfying sanitisation
protocols can be considered a closed, bounded, convex poly-
2
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-760-3
ICDS 2020 : The Fourteenth International Conference on Digital Society

tope Γ in Rb×a. This fact allows us to efﬁciently ﬁnd optimal
protocols.
Theorem 1. Let ε ∈ R≥0. Let Q: X → Y be the ε-LDP
protocol that maximises I(X; Y ), i.e., the protocol that solves
Problem 2 w.r.t. LDP.
1) One has b ≤ a.
2) Let Γ be the polytope described above. Then one can ﬁnd
Q by maximising a convex function on Γ.
This result is obtained by generalising the results of [10]:
there this is proven for regular ε-LDP (i.e., w.r.t. X), but
the arguments given in that proof hold just as well in our
situation; the only difference is that their polytope is deﬁned
by the ε-LDP conditions w.r.t. X, but this has no impact on
the proof. Together, these results reduce our problem to a ﬁnite
optimisation problem: By point 1, we only need to consider
Y = X, and, by point 2, we only need to ﬁnd the set of
vertices of Γ, a a(a − 1)-dimensional convex polytope.
One might argue that, since the optimal Q depends on
pS,X, the publication of Q might provide an aggregator with
information about the distribution of S. However, information
on the distribution (as opposed to information of individual
users’ data) is not considered sensitive [13]. In fact, the reason
why the aggregator sanitises the data is because an attacker
is assumed to have knowledge about this correlation, and
revealing too much information about X would cause the
aggregator to use this information to infer information about
S.
IV. OPTIMIZING Q FOR ε-LIP
If one uses ε-LIP as a privacy metric, one can ﬁnd the
optimal sanitisation protocol in a similar fashion. To do this,
we again describe Q as a matrix, but this time a different one.
Let q ∈ Rb be the probability mass function of Y , and let
R ∈ Ra×b be given by Rx|y = P(X = x|Y = y); we denote
its y-th row by RX|y ∈ Ra. Then, a pair (R, q) deﬁnes a
sanitisation protocol Q satisfying ε-LIP if and only if
∀y: 0 ≤ qy,
(6)
Rq = pX,
(7)
∀y:
X
x
Rx|y = 1,
(8)
∀x, y: 0 ≤ Rx|y,
(9)
∀y, s: e−ε ps ≤ ps|X RX|y ≤ eε ps .
(10)
Note that (10) deﬁnes the ε-LIP condition, since for a
given s, y we have
ps|X RX|y
pS
= P(S=s|Y =y)
P(S=s)
= P(Y =y|S=s)
P(Y =y)
.
(In)equalities (8–10) can be expressed as saying that for every
y ∈ Y one has that RX|y ∈ ∆, where ∆ is the convex closed
bounded polytope in RX given by
∆ =


v ∈ RX :
P
x vx = 1,
∀x : 0 ≤ vx,
∀s : e−ε ps ≤ ps|X v ≤ eε ps


 .
(11)
As in Theorem 1, we can use this polytope to ﬁnd optimal
protocols:
Theorem 2. Let ε ∈ R≥0. Let Q: X → Y be the ε-LIP
protocol that maximises I(X; Y ), i.e., the protocol that solves
Problem 2 w.r.t. LIP.
1) One has b ≤ a.
2) Let ∆ be the polytope described above, and let V be its
set of vertices. Then one can ﬁnd Q by solving a #V-
dimensional linear optimization problem.
This is proven for ε
=
0 (i.e., when S and Y
are
independent) in [15], but the proof works similarly for ε > 0;
the main difference is that the equality constraints of their
(10) will be replaced by the inequality constraints of our
(10), but this has no impact on the proof presented there.
Since linear optimization problems can be solved fast, again
the optimization problem reduces to ﬁnding the vertices of
a polytope. The advantage of this approach, however, is that
∆ is a (a − 1)-dimensional polytope, while Γ is a(a − 1)-
dimensional. The time complexity of vertex enumeration is
linear in the number of vertices [1], while the number of
vertices can grow exponentially in the dimension of the
polyhedron [2]. Together, this means that the dimension plays
a huge role in the time complexity, hence we expect ﬁnding
the optimum under LIP to be signiﬁcantly faster than under
LDP.
V. MULTIPLE ATTRIBUTES
An often-occuring scenario is that a user’s data consists
out of multiple attributes, i.e., Xi = (X1
i , · · · , Xm
i ) ∈ X =
Qm
j=1 X j. This can be problematic for our approach for two
reasons:
1) Such a large X can be problematic, since the computing
time for optimisation both under LDP and LIP will
depend heavily on a.
2) In practice, an attacker might sometimes utilise side
channels to access to some subsets of attributes Xj
i for
some users. For these users, a sanitisation protocol can
leak more information (w.r.t. to the attacker’s updated
prior information) than its LDP/LIP parameter would
suggest.
To see how the second problem might arise in practice,
suppose that X1
i is the height of individual i, X2
i is their
weight, and Si is whether i is obese or not. Since height is
only lightly correlated with obesity, taking Yi = X1
i would
satisfy ε-LIP for some reasonably small ε. However, suppose
that an attacker has access to X2
i via a side channel. While
knowing i’s weight gives the attacker some, but not perfect
knowledge about i’s obesity, the combination of the weight
from the side channel, and the height from the Yi, allows the
attacker to calculate i’s BMI, giving much more information
about i’s obesity. Therefore, the given protocol gives much
less privacy in the presence of this side channel.
To solve the second problem, we introduce a more stringent
privacy notion called Side-channel Resistant LIP (SRLIP),
which ensures that no matter which attributes an attacker has
access to, the protocol still satisﬁes ε-LIP with respect to the
attacker’s new prior distribution. One could similarly introduce
3
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-760-3
ICDS 2020 : The Fourteenth International Conference on Digital Society

SRLDP, and many results will still hold for this privacy mea-
sure; nevertheless, since we concluded that LIP is preferable
over LDP, we focus on SRLIP. For J ⊂ {1, · · · , m}, we write
X J = Q
j∈J X j and its elements as xJ.
Deﬁnition 3. (ε-SRLIP). Let ε > 0, and let X = Qm
j=1 X j.
We say that Q satisﬁes ε-SRLIP if for every y ∈ Y, for every
s ∈ S, for every J ⊂ {1, · · · , m}, and for every xJ ∈ X J
one has
e−ε ≤ P(Y = y|S = s, XJ = xJ)
P(Y = y|XJ = xJ)
≤ eε.
(12)
In terms of Remark 1, Q satisﬁes ε-SRLIP if and only if it
satisﬁes ε-LIP w.r.t. pS,X|xJ for all J and xJ. Taking J = ∅
gives us the regular deﬁnition of ε-LIP, proving the following
Lemma:
Lemma 2. Let ε > 0. If Q satisﬁes ε-SRLIP, then Q satisﬁes
ε-LIP.
While SRLIP is stricter than LIP itself, it has the advantage
that even when an attacker has access to some data of a
user, the sanitisation protocol still does not leak an unwanted
amount of information beyond the knowledge the attacker
has gained via the side channel. Another advantage is that,
contrary to LIP itself, SRLIP satisﬁes an analogon of the
concept of privacy budget [7]:
Theorem 3. Let X
=
Qm
j=1 X j, and for every j, let
Qj : X j → Yj be a sanitisation protocol. Let εj ∈ R≥0
for every j. Suppose that for every j
≤ m, for every
J ⊂ {1, · · · , j − 1, j + 1, · · · , m}, and every xJ ∈ X J,
Qj satisﬁes εj-LIP w.r.t. pS,X|xJ. Then Q
j Qj : X → Q
j Yj
satisﬁes P
j εj-SRLIP.
The proof is presented in Appendix A. This theorem tells
us that to ﬁnd a ε-SRLIP protocol for X, it sufﬁces to ﬁnd a
sanitisation protocol for each X j that is ε
m-LIP w.r.t. a number
of prior distributions. Unfortunately, the method of ﬁnding an
optimal ε-LIP protocol w.r.t. one prior pS,X of Theorem 2 does
not transfer to the multiple prior setting. This is because this
method only ﬁnds one (R, q), while by (7) we need a different
(R, q) for each prior distribution. Therefore, we are forced to
adopt an approach similar to the one in Theorem 1. The matrix
Qj (given by Qj
yj|xj = P(Qj(xj) = yj)) corresponding to
Qj : X j → Yj satisﬁes the criteria of Theorem 3 if and only
if the following criteria are satisﬁed:
∀xj :
X
yj
Qj
yj|xj = 1,
(13)
∀xj, yj : 0 ≤ Qj
yj|xj,
(14)
∀J, xJ, s, yj : e−ε/m(Qj pXj|xJ)yj ≤ (Qj pXj|s,xJ)yj, (15)
∀J, xJ, s, yj : (Qj pXj|s,xJ)yj ≤ eε/m(Qj pXj|xJ)yj.
(16)
Similar to Theorem 1, we can ﬁnd the optimal Qj satis-
fying these conditions by ﬁnding the vertices of the polytope
deﬁned by these equations. In terms of time complexity, the
comparison to ﬁnding the optimal ε-LIP protocol via Theorem
2 versus ﬁnding a ε-SRLIP protocol via Theorem 3 is not
straightforward. The complexity of enumerating the vertices of
a polytope is O(ndv), where n is the number of inequalities,
d is the dimension, and v is the number of vertices [1]. For ∆
of Theorem 2 we have d = a−1 and n = a+2c. By contrast,
for the polytope deﬁned by (13–16) satisﬁes d = aj(aj − 1)
and n = (aj)2 + 2c Q
j′̸=j(aj′ + 1). Finding v for both these
polytopes is difﬁcult, but in general v ≤

-4
-3.5
-3
-2.5
-2
-1.5
-1
-0.5
log(LIP time / LDP time)
0.8
0.82
0.84
0.86
0.88
0.9
0.92
0.94
0.96
0.98
1
LDP info / LIP info
eps = 0.5
eps = 1
eps = 1.5
eps = 2
Figure 3. Comparision of computation time and I(X; Y ) for ε-LDP
protocols found via Theorem 1 and ε-LIP protocols found via Theorem 2,
for random pS,X with c = 2, a = 5, and ε ∈ {0.5, 1, 1.5, 2}.
-4
-3.5
-3
-2.5
-2
-1.5
-1
-0.5
log(LIP time / LDP time)
0.8
0.82
0.84
0.86
0.88
0.9
0.92
0.94
0.96
0.98
1
LIP info / LDP info
eps = 0.5
eps = 1
eps = 1.5
eps = 2
Figure 4. Comparision of computation time and I(X; Y ) for ε-LDP
protocols found via Theorem 1 and ε
2 -LIP protocols found via Theorem 2,
for random pS,X with c = 2, a = 5, and ε ∈ {0.5, 1, 1.5, 2}.
advantage of using differential privacy-like privacy metrics
is that they provide worst-case guarantees, ensuring that the
privacy of every user is sufﬁciently protected. For both ε-LDP
and ε-LIP we have found methods to ﬁnd optimal sanitisation
protocols. Within this setting, we have found that ε-LIP has
two main advantages over ε-LDP. First, it ﬁts better within
the privacy funnel setting, where the distribution pS,X is (at
least approximately) known to the estimator. Second, ﬁnding
the optimal protocol is signiﬁcantly faster than under LDP,
especially for small ε. If one nevertheless prefers ε-LDP as
a privacy metric, then it is still worthwile to ﬁnd the optimal
ε
2-LIP protocol, as this can be found signiﬁcantly faster, at a
low utility cost.
In the multiple attributes setting, we have shown that ε-
SRLIP is a more sensible privacy metric than ε-LIP, since
-4
-3.5
-3
-2.5
-2
-1.5
-1
-0.5
log(LIP time / SRLIP time)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
SRLIP info / LIP info
eps = 0.5
eps = 1
eps = 1.5
eps = 2
Figure 5. Comparison of computation time and I(X; Y ) for
ε-(SR)LIP-protocols found via Theorems 2 and 3, for random pS,X with
c = 2, a1 = a2 = 3, a3 = 4, and ε ∈ {0.5, 1, 1.5, 2}.
without this requirement a protocol can lose all its privacy
protection in the presence of side channels. Unfortunately,
however, experiments show that we pay for this both in
computation time and in utility. Nevertheless, because of the
robustness of ε-SRLIP, it remains the preferred privacy notion
in this setting.
For further research, two important avenues remain to be
explored. First, the aggregator’s knowledge about pS,X may
not be perfect, because they may learn about pS,X through ob-
serving (⃗S, ⃗X). Incorporating this uncertainty leads to robust
optimisation [3] , which would give stronger privacy guar-
antees. Second, it might be possible to improve the method
of obtaining ε-SRLIP protocols via Theorem 3. Examining
its proof shows that lower values of εj may sufﬁce to still
ensure ε-SRLIP. Furthermore, the optimal choice of (εj)j≤m
such that P
j εj = ε might not be εj =
ε
m. However, it is
computationally prohibitive to perform the vertex enumera-
tion for many different choices of (εj)j≤m, and as such a
new theoretical approach is needed to determine the optimal
(εj)j≤m from ε and pS,X.
ACKNOWLEDGEMENTS
This work was supported by NWO grant 628.001.026
(Dutch Research Council, the Hague, the Netherlands). The
author thanks Jasper Goseling and Boris ˇSkori´c for helpful
discussions.
REFERENCES
[1] D. Avis and K. Fukuda, “A pivoting algorithm for convex hulls and
vertex enumeration of arrangements and polyhedra,” Discrete and Com-
putational Geometry, vol. 8, no. 1, pp. 174–190, 1992.
[2] I. B´ar´any and A. P´or, “On 0-1 Polytopes with Many Facets,” Advances
in Mathematics, vol. 161, no. 2, pp. 209–228, 2001.
[3] D. Bertsimas, V. Gupta, and N. Kallus, “Data-driven robust optimiza-
tion,” Mathematical Programming, vol. 167, no. 2, pp. 235–292, 2017.
[4] F.P. Calmon et al., “Principal Inertia Components and Applications,”
IEEE Transactions on Information Theory, vol. 63 no. 8, pp. 5011–
5038, 2017.
5
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-760-3
ICDS 2020 : The Fourteenth International Conference on Digital Society

[5] P. Cuff and L. Yu, “Differential Privacy as a Mutual Information Con-
straint,” ACM SIGSAC Conference on Computer and Communications
Security 2016, pp. 43–54, 2016.
[6] N. Ding and P. Sadeghi, “A Submodularity-based Agglomerative
Clustering Algorithm for the Privacy Funnel,” Unpublished preprint,
arXiv:1901.06629, 2019 (retrieved: February, 2020).
[7] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise to
sensitivity in private data analysis,” Theory of Cryptography Conference,
pp. 265–284, 2006.
[8]
´U. Erlingsson et al., “Encode, Shufﬂe, Analyze Privacy Revis-
ited: Formalizations and Empirical Evaluation,” Unpublished preprint,
arXiv:2001.03618, 2020 (retrieved: February, 2020).
[9] B. Jiang, M. Li, and R. Tandon, “Local Information Privacy with
Bounded Prior,” IEEE International Conference on Communications,
pp. 1–7, 2019.
[10] P. Kairouz, S. Oh, and P. Viswanath, “Extremal Mechanisms for Lo-
cal Differential Privacy,” Advances in Neural Information Processing
Systems, vol. 27, pp. 2879–2887, 2014.
[11] S. P. Kasiviswanathan, H. K. Lee, K. Nissim, S. Raskhodnikova, and
A. Smith, “What can we learn privately?,” SIAM Journal of Computing,
vol. 40, no. 3, pp. 793–826,2011.
[12] D. Kifer and A. Machanavajjhala, “Pufferﬁsh: A Framework for Math-
ematical Privacy Deﬁnitions,” ACM Transactions on Database Systems,
vol. 39, no 1., pp. 1–36, 2014.
[13] M. Lopuha¨a-Zwakenberg, B. ˇSkori´c, and N. Li, “Information-theoretic
metrics for Local Differential Privacy protocols,” Unpublished preprint,
arXiv:1910.07826, 2019 (retrieved: February, 2020).
[14] F. Prasser, F. Kohlmayer, R. Lautenschl¨ager, and K. A. Kuhn, “ARX - A
Comprehensive Tool for Anonymizing Biomedical Data,” AMIA Annual
Symposium Proceedings, pp. 984–993, 2014.
[15] B. Rassouli and D. G¨und¨uz, “On Perfect Privacy and Maximal Correla-
tion,” Unpublished preprint, arXiv:1712.08500, 2017 (retrieved: Febru-
ary, 2020).
[16] S. Salamatian, F.P. Calmon, N. Fawaz, A. Makhdoumi, and M. M´edard,
“Privacy-Utility Tradeoff and Privacy Funnel,” Unpublished preprint,
http://www.mit.edu/∼salmansa/ﬁles/privacy TIFS.pdf, 2020 (retrieved:
February, 2020).
APPENDIX A
PROOF OF THEOREM 3
For J ⊂ {1, · · · , m} and j ∈ {1, · · · , m}, we write J[j] :=
J ∪ {1, · · · , j − 1}. Furthermore, we write X \J = Q
j /∈J X j,
and its elements as x\J. We write ε := P
j εj. We then have
py|s,xJ =
X
x\J
py|x px\J|s,xJ
(17)
= pyJ|xJ
X
x\j

Y
j /∈J
pyj|xj

 px\J|s,xJ
(18)
= pyJ|xJ
X
x\j
Y
j /∈J
pyj|xj pxj|s,xJ[j]
(19)
= pyJ|xJ
Y
j /∈J
X
xj
pyj|xj pxj|s,xJ[j]
(20)
= pyJ|xJ
Y
j /∈J
pyj|s,xJ[j]
(21)
≤ pyJ|xJ
Y
j /∈J
eεj pyj|xJ[j]
(22)
≤ eε pyJ|xJ
Y
j /∈J
pyj|xJ[j]
(23)
= eε py|xJ .
(24)
The fact that e−ε py|xJ ≤ py|s,xJ is proven analogously.
6
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-760-3
ICDS 2020 : The Fourteenth International Conference on Digital Society

