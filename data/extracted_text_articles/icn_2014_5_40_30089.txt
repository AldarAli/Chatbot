Modeling of Content Dissemination Networks on Multiplexed Caching Hierarchies
Satoshi Imai
Fujitsu Laboratories Ltd.
4–1–1 Kamikodanaka, Kawasaki,
Kanagawa, Japan
Email: imai.satoshi@jp.fujitsu.com
Kenji Leibnitz
CiNet, NICT and Osaka University
1–4 Yamadaoka, Suita,
Osaka, Japan
Email: leibnitz@nict.go.jp
Masayuki Murata
Osaka University
1–5 Yamadaoka, Suita,
Osaka, Japan
Email: murata@ist.osaka-u.ac.jp
Abstract—In-network caching technologies like Content-Centric
Networking (CCN) are expected to reduce the network trafﬁc
and improve the service quality, such as communication latency,
by storing content data on routers near to users. Meanwhile,
the adaptive cache management using Time-To-Live (TTL) of
content can realize efﬁcient memory management per content.
However, for a distributed cache system such as CCN, it is
difﬁcult to evaluate cache performance and network resources
required in the cache mechanism using the TTL value. Therefore,
we propose a theoretical model, which can analyze the impact of
TTL-based caching on network resources and cache performance,
and evaluate some scenarios using the proposed model. We ﬁnally
introduce a cache mechanism using energy efﬁcient TTLs and
show its effectiveness by the model-based analysis.
Keywords-In-network caching; distributed cache system; Con-
tent Centric Networking; Time-To-Live
I.
INTRODUCTION
The currently increasing network trafﬁc is caused by the
growing number of content dissemination services in the net-
work and Content Delivery Networks (CDN) are well known as
efﬁcient content delivery mechanisms. Since the CDN service
can provide content delivery at the edge of the networks
by allocating content replicas in cache servers, which are in
geographical proximity to users, it is expected to reduce the
network trafﬁc. Moreover, the caching services can improve
communication quality, such as latency and throughput, in the
delivery of content. Recently, a new communication paradigm,
namely Content Centric Networking (CCN) [1], has been
proposed. The CCN-enabled routers have autonomous caching
functionality for content data. In the content dissemination
mechanism of CCN, content publishers advertise newly re-
leased content from the origin site of the content along
predeﬁned routes. A content request (Interest) is forwarded on
each content router (CR) based on the Forwarding Information
Base (FIB) until the requested content is found. An Interest
forwarded on a CR is added to the Pending Interest Table
(PIT) in order to remember the interface on which to send
back the replies (Data). When the requested content is found
on a CR, Data of the content are transmitted based on the PIT.
Furthermore, Data are cached on all CRs along the transmis-
sion route based on the speciﬁc replacement policy such as
Least Recently Used (LRU) or Least Frequently Used (LFU).
Therefore, CCN can automate the placement and delivery of
Data by CRs on networks and it is highly expected to reduce
network trafﬁc and improve the communication quality.
However, the network trafﬁc and communication quality
are inﬂuenced by the cache locations because content is
generated by many publishers at various locations in CCN.
Moreover, the caching performance depends on the memory
size in each CR on multiplexed delivery trees rooted at each
origin site of content. Therefore, it is a major issue to analyze
the impact of the distributed cache mechanism on network
resources, such as memory or network devices, and cache
performance, such as cache hit ratio and hop length, while
delivering content.
Meanwhile, the persistent storage of content in each CR
is inefﬁcient because the content, such as video streaming,
generally has a limited lifetime. Therefore, dynamic caching
mechanisms often use a limited period of time, called Time-
To-Live (TTL) for content. Moreover, TTL-based caching can
improve the scalability of cache management compared with
LRU or LFU replacement with cache coordination which sorts
content by popularity and selects which content should be
discarded. In this paper, we ﬁrst propose an analytical model
to evaluate the impact of TTL on cache performance and
network resources of content in a distributed cache mechanism
like CCN. Furthermore, we demonstrate evaluation results for
some network scenarios using the proposed model. In addition,
we introduce a cache mechanism using energy efﬁcient TTLs
as one possible application of TTL-based caching and show
the effectiveness of the proposed cache mechanism using our
model.
The remainder of this paper is organized as follows. Section
II discusses the TTL-based cache mechanism followed by
Section III which summarizes related work. We propose our
analytical model in Section IV and demonstrate evaluation
results using the proposed model in Section V. Furthermore,
in Section VI we introduce a cache mechanism to improve
energy efﬁciency using TTL and we evaluate the effectiveness
of the proposed mechanism. Finally, we conclude the paper in
Section VII.
II.
TTL-BASED CACHE MECHANISM AND ISSUES
In this paper, we assume that each CR executes data
caching using TTL of content which can, for instance, be
signaled in the data header of the content or set at each CR in
advance.
In TTL-based caching, each CR resets the time counter to
111
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

TTL Update
me
me
(hit)
(hit) (hit)
(miss)
Request arrival of content
Data Retention Period
me
Data Reten!on Period
TTL
Figure 1: Traditional TTL-based caching
Less Popular 
    Content
More Popular 
    Content
Origin
Origin
Server
User
User
Caching hierarchy
for content having Origin 4
Caching hierarchy
for content having Origin 8
4
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
Request Site
8
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
0
1
2
3
4
5
6
7
8
Request Site
0
1
2
4
3
6
7
8
Router Topology
5
Figure 2: An example of caching hierarchies for origin sites 4 and 8
the TTL of content every time a new request for this content
arrives and decreases the counter by 1 every time unit (cf.
Figure 1). In this mechanism, each CR caches data of content
delivered by another CR or an origin server when the content
counter is above 0 and discards the data of content when the
counter becomes 0.
Meanwhile in CCN, each CR autonomously constructs
some caching hierarchies rooted at each origin site of content
(cf. Figure 2). The caching hierarchy is constructed by routes
between the origin site, caching routers, and users, such that
less popular content is cached on CRs near to the origin site
and more popular content is cached on CRs near to users.
Therefore, it is difﬁcult to evaluate the impact of TTL-based
caching on network resources and performance because the
characteristics in the distributed cache mechanism depend on
the caching hierarchies connected by distributed cache nodes.
In this paper, we ﬁrst propose an analytical model using
matrix equations to evaluate the cache characteristics on multi-
plexed caching hierarchies of content and evaluate the validity
of the proposed model and the impact of the TTL value.
III.
RELATED WORK
The modeling of efﬁcient memory management is a major
issue in content caching systems. Traditionally, there are
content placement algorithms [2], [3] as a solution for File
Allocation Problems [4], which minimize the cost imposed for
content storage and queries, or maximize performance such as
1e−04
1e−02
1e+00
1e+02
0.0
0.2
0.4
0.6
0.8
1.0
Request rates of content (log)
Cache Hit Ratio
model
simulation
(a) TTL = 1
1e−04
1e−02
1e+00
1e+02
0.0
0.2
0.4
0.6
0.8
1.0
Request rates of content (log)
Cache Hit Ratio
model
simulation
(b) TTL = 10
Figure 3: Cache hit ratio when the requests per content with the rate λ input
to a CR at an independent and identically distributed exponential interval and
“total request rates of a content item [requests/sec]” and “TTL [sec]” to various
values
distance to content. Baev et al. [2] propose a linear program-
ming model which minimizes content placement cost and an
approximation solution using a linear relaxation. Furthermore,
Qui et al. [3] develop a method and compare it with some
replica placement algorithms to solve a K-median problem for
CDNs.
In contrast to the above-mentioned content placement prob-
lems, Borst et al. [5] formulate a liner programming model
based on a hierarchical structure for content locations to mini-
mize bandwidth costs through a distributed solution. In view of
energy efﬁciency for content delivery networks, Guan et al. [6]
build energy models of trafﬁc transmission power and caching
power for content delivery architectures such as “Conventional
and decentralized server-based CDN”, “Centralized server-
based CDN using dynamic optical bypass”, and CCN.
Furthermore, Caroﬁglio et al. [7] explore the impact of
storage management on the cache performance per application
in CCN and evaluate the effectiveness of static storage parti-
tioning and dynamic management by priority-based weighted
fair schemes combined with TTL-based caching. Moreover,
they study the possibility of improving cache scalability in
TTL-based caching without cache coordination.
However, these proposals don’t discuss the cache character-
istics using TTL of content and the impact of TTL on network
resources and cache performance on the multiplexed caching
hierarchies. Therefore in this paper, we construct a model to
analyze the cache characteristics using TTL and evaluate the
cache performance for the TTL value.
IV.
ANALYTICAL MODEL
We ﬁrst propose the evaluation model to analyze the cache
performance using TTL of a content in the distributed cache
system having multiplexed caching hierarchies.
In TTL-based caching, the cache probability of content
c having request rates λc to a CR can be expressed by the
following function [8].
f(λc, TTLc) = 1 − e−λcT T Lc
As shown in Figure 3, we demonstrate that this statistical
function can provide a good approximation of the cache hit
112
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

3
5
2
4
1
Figure 4: An example of matrices Λc, Rc, and Dc for the request propagation on the delivery tree having origin 1
ratio of content at a CR under the assumption that content
requests arrive as a Homogeneous Poisson Process. We next
show the matrix model of request propagation of content
in TTL-based caching on caching hierarchy of content. The
propagation of each request (Interest) of content c on its
caching hierarchy is expressed by the following model.
Λc[s + 1] = Dc[s] · Λc[s] + Rc, ∀c
(1)
Under the condition that M, N, and s are the number of CRs,
the number of sites having requesting users, and the number of
steps that each request propagates to the next CR, respectively,
we deﬁne Λc as the M × N matrix consisting of the request
rates λc
(i,j) of content c from the requesting user in site j to
CRi and Rc as the M × N matrix of which elements are the
request rates rc
i of content c from users in site i.
Λc[s] := [λc
(i,j)]M×N
[Rc]i,j :=
{ rc
i , when CRi is located on j-th
site having requesting users
0
otherwise
Dc is the M × M matrix of request propagation for content c
as follows.
[Dc]m,n :=



1 − f(∑N
k λc
(n,k)[s], TTLc),
m = parent node(n)
0
otherwise
(2)
Here we deﬁned the condition that CRm is a parent node of
CRn as “m = parent node(n)”. In Figure 4, we show an
example of these matrices for the delivery tree having origin
1.
In the iterative matrix equation, we can consider the request
propagation process and data caching at each CR for content
requested from each site. Moreover, the steady state of network
resources and cache performance per content can be derived
by iteratively calculating the equation smax-times, which is the
maximum number of hops from each site having requesting
users to its origin site.
Using the proposed solution, we can model the system state
and the cache performance for content c such as
•
memory usage per content in each CR,
•
the total amount of transmission data in the network,
•
power consumption which is the sum of “cache allo-
cation power” and “trafﬁc transmission power”,
•
cache hit ratio per content which is the probability that
the content is cached in the network, and
•
average hop length per content.
A. Memory Usage
The memory usage of content c at CRi is derived using the
data size θc of content c as follows.
Uc
i := θcf(
N
∑
k
λc
(i,k), TTLc).
(3)
B. Transmission Data
The total amount of data delivery of content c through all
CRs is derived as
Dtc := θc
N
∑
j
Trc
j
(4)
using the following vector consisting of the cumulative number
of trafﬁc ﬂows Trc
j through each CR on the delivery route for
content c having origin site o requested by users in site j.
Trc := [Trc
1 · · · Trc
j · · · Trc
N]T
= (H ∗ Λc)T


f(∑N
k λc
(1,k), TTLc)
...
f(∑N
k λc
(M,k), TTLc)


+ (H[o, ] ∗ Λc[o, ])T(1 − f(
N
∑
k
λc
(o,k), TTLc))
(5)
Here, we deﬁne “∗” as the element-wise product of a matrix
or vector and H = [h(i,j)]M×N as the matrix consisting of
shortest hop length h(i,j) from CRi to CRj.
Moreover, the second term in (5) presents the amount of
transmission data which aren’t cached on the network.
113
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

CR
WDM
Pr [J/bit]
Pwdm [J/bit]
Cache Data
Pca [J/(bit s)]
Origin
Server
User
Figure 5: Network model
TABLE I: VARIABLES IN THE PROPOSED MODEL
Variable
Deﬁnition
M
The number of CRs
N
The number of sites having requesting users
θc
Data size of content c
λc
(i,j)
Request rates to CRi for content c requested by users in site j
rc
i
Request rate of content c requested by users in site i
T T Lc
TTL of content c at CRi
Uc
i
Memory usage of content c at CRi
Dtc
Total amount of data delivery of content c through all CRs
Trc
j
Cumulative number of trafﬁc ﬂows through each CR on the delivery
route for content c requested by users in site j
CHRc
Cache hit ratio of content c in the network
AHLc
Average hop length of content c
Hpo
Hop length from origin server to the content router in origin site o
CPc
Total power consumption [J] for data storage of content c in 1 sec
TPc
Total power consumption [J] delivering content c on the delivery
routes
Pca
Power density for storage [J/(bit·s)]
Pr
Power density of a router [J/bit]
Pwdm
Power density of a WDM node [J/bit]
C. Power Consumption
We consider total power consumption based on Energy
Proportional Networks [9], [10] in which power consumption
of each device is proportional to its usage for a network com-
posed of CRs and Wavelength Division Multiplexing (WDM)
nodes in Figure 5. In this paper, we assume 1 sec as time unit.
Cache allocation power: CPc [J] for storing data of content
c in 1 sec, i.e., the total power consumed by storing content c
on each CR in the network, is deﬁned as
CPc := θcPca
M
∑
i
f(
N
∑
k
λc
(i,k), TTLc),
(6)
where Pca is the memory power density [J/(bit· s)].
Trafﬁc transmission power: TPc [J] i.e., the total power
consumed by network devices when data of content c are
delivered on the shortest routes, is derived as
TPc := (Pr + Pwdm)Dtc,
(7)
where Pr and Pwdm are the power densities [J/bit] of a router
and of a WDM node along the delivery routes, respectively.
D. Cache Hit Ratio
The cache hit ratio of content c having origin o in the
network is derived as
CHRc := 1 −
∑N
j λc
(o,j)
(
1 − f(∑N
k λc
(o,k), TTLc)
)
∑N
j rc
j
.
(8)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
(a) Test topology A
6
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
(b) Test topology B
Zipf(α=1.2)
Zipf(α=0.8)
Request distrribution (log)
1e−04
1e−02
1e+00
1e+02
0
2000
4000
6000
8000
10000
Content id
(c) Request distribution rc
i
Figure 6: Evaluation conditions
E. Average Hop Length
The average hop length of content c having origin o is
derived as
AHLc :=
∑N
j
(
Trc
j + Hpoλc
(o,j)(1 − f(∑N
k λc
(o,k), TTLc)
)
∑N
j rc
j
.
(9)
The second term of the numerator is a penalty for the hop
length of content c, which isn’t cached on any CRs in the
network and for which a request reaches its origin server and
Hpo is the hop-length from the origin server to the content
router in origin site o and is used as penalty if the content is
not found in the network. All variables in the proposed model
are summarized in Table I.
V.
EVALUATION USING THE PROPOSED MODEL
We evaluate the cache characteristics in TTL-based caching
when changing the TTL value of content. The evaluation
conditions are set to the following.
•
Test networks: NSF topology with 14 CRs (Topology
A), cf. Figure 6(a) / US-backbone topology with 24
CRs (Topology B), cf. Figure 6(b). The maximum
number of hops (smax) is 5 in Topology A and 7 in
Topology B. Furthermore, we assume that the memory
size of each CR is inﬁnite and each site has requesting
users for all content items, which means M is equal to
N. For the evaluation, we set Hpo to 5 as the penalty
of hop length.
114
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

0
0.4
0.6
1.0
Cache hit ratio for each content
0.8
0.2
Content id
1
6000
1000 2000 3000 4000 5000
simulation(TTL=1)
simulation(TTL=20)
simulation(TTL=40)
simulation(TTL=60)
model (TTL=1)
model (TTL=20)
model (TTL=40)
model (TTL=60)
(a) Cache hit ratio
4
6
10
Average hop length for each content
8
2
0
simulation(TTL=1)
simulation(TTL=20)
simulation(TTL=40)
simulation(TTL=60)
model (TTL=1)
model (TTL=20)
model (TTL=40)
model (TTL=60)
Content id
1
6000
1000 2000 3000 4000 5000
(b) Average hop length
Figure 7: Cache performance estimated by the proposed model and calculated
by simulations for different content ids
•
Content information: Zipf-distributed requests from
each site i for K = 10000 content items are deﬁned as
rc
i = γk−α/c, c = ∑K
k=1 k−α, cf. Figure 6(c). We set
α to 0.8 for User Generated Content (UGC) and 1.2
for VoD [12] and γ to 100 [requests/sec]. Furthermore,
the origin site t of content ID k is set randomly
based on a uniform distribution. The content size is
geometrically distributed with mean 10 MB [13].
A. Veriﬁcation of the Proposed Model
To verify the proposed model, we compare the cache per-
formance using the model with that measured by simulations
for 7 content items with α = 0.8 in Topology A. In the
evaluations, we set the TTL value as {1, 20, 40, 60} [sec].
Figure 7 shows that the cache hit ratio and average hop
length for each content provide suitable approximations of
the simulation results. As a result, we see that the proposed
0
20
40
60
80
Memory usage of each CR  [GB]
TTL [sec]
1
100
150
200
300
250
50
Content with α=0.8
Content with α=1.2
(a) Topology A
0
20
40
60
80
Memory usage of each CR  [GB]
TTL [sec]
1
100
150
200
300
250
50
Content with α=0.8
Content with α=1.2
(b) Topology B
Figure 8: Box plot of memory usage at each CR when the TTL value is
changed
model can express the statistical characteristics for TTL-based
caching.
B. Impact of TTL
For the next evaluation, we deﬁne TTL as the same value
for each content which is changed from 1 [sec] to 300 [sec]
on the assumption that the TTL value is signaled in the data
header of content.
Figure 8 shows the memory usage at each CR when the
TTL value is changed. In these results, the memory usage of
each CR becomes larger as the TTL value becomes larger.
Moreover, the memory usage for content with α = 0.8 is
larger than that for content with α = 1.2 because less popular
content with α = 0.8 has higher request rates and is easier to
be cached than that with α = 1.2.
Furthermore, Figure 9 shows the power consumption of
the target network according to the change of the TTL value
using the power densities of network devices shown in Table
II. In addition, Figure 10 presents cache hit ratio for all content
items calculated by (8) and average hop length for all content
items calculated by (9).
115
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

TABLE II: POWER DENSITY PARAMETERS
Device
Power /
Power Density
(Product)
Spec
DRAM
10 W /
Pca = 3.125 × 10−10 J/(bit · s)
4 GB
Content Router
4185 W /
Pr = 1.3 × 10−8 J/bit
(CRS-1)
320 Gbps
WDM
800 W /
Pwdm = 1.67 × 10−9 J/bit
(FLASHWAVE9500)
480 Gbps
0
2000
4000
6000
Average  power consumption  [J/s]
TTL [sec]
0
100
150
200
300
250
50
8000
Total Power 
Traffic Transmission Power
Cache Allocation Power
(a) Content with α = 0.8 in
Topology A
0
2000
4000
6000
Average  power consumption  [J/s]
TTL [sec]
0
100
150
200
300
250
50
8000
Total Power 
Traffic Transmission Power
Cache Allocation Power
(b) Content with α = 1.2 in
Topology A
0
2000
4000
6000
Average  power consumption  [J/s]
TTL [sec]
0
100
150
200
300
250
50
8000
Total Power 
Traffic Transmission Power
Cache Allocation Power
(c) Content with α = 0.8 in
Topology B
0
2000
4000
6000
Average  power consumption  [J/s]
TTL [sec]
0
100
150
200
300
250
50
8000
Total Power 
Traffic Transmission Power
Cache Allocation Power
(d) Content with α = 1.2 in
Topology B
Figure 9: Power consumption of the network when the TTL value is changed
Figure 9 demonstrates the tradeoff between cache allo-
cation power and trafﬁc transmission power for the change
of the TTL value. Figures. 9(a) and (c) show that there is
a point reversing the relation of cache allocation power and
trafﬁc transmission power for the TTL value. Therefore, the
energy impact of TTL is also different depending on the
network conditions and the proposed model can search for the
energy efﬁcient TTL in consideration of the tradeoff of power
consumption.
Meanwhile in Figure 10(a), the cache hit ratio is also
low in the region of the TTL values leading to lower power
consumption. Therefore, we should consider the relation be-
tween cache hit ratio and power consumption to search for the
energy efﬁcient TTL. Furthermore, Figure 10(b) shows that the
average hop length of all content items becomes smaller as the
TTL becomes larger. In these results, approaching the average
hop length of 1 hop means that all content items are cached
0
0.4
0.6
1.0
Cache hit ratio for all contents
TTL [sec]
0
100
150
200
300
250
50
0.8
0.2
Content with Zipf(α=0.8) for Top. A
Content with Zipf(α=1.2) for Top. A
Content with Zipf(α=0.8) for Top. B
Content with Zipf(α=1.2) for Top. B
(a) Cache hit ratio for all content items
0
4
6
10
Average hop length for all contents
TTL [sec]
0
100
150
200
300
250
50
8
2
Content with Zipf(α=0.8) for Top. A
Content with Zipf(α=1.2) for Top. A
Content with Zipf(α=0.8) for Top. B
Content with Zipf(α=1.2) for Top. B
(b) Average hop length for all content
items
Figure 10: Cache performance when the TTL value is changed
in all CRs. The cache hit ratio approaches to around 100 % as
the average hop length is approaching to 1 and the memory
usage becomes larger. Therefore, using the proposed model, we
can analyze the cache characteristics in the distributed cache
system and provide a design guideline for TTL of content in
view of energy efﬁciency or efﬁcient memory usage in each
CR. Next, we introduce an energy efﬁcient cache mechanism
using TTL as application and demonstrate the effectiveness of
the energy efﬁcient TTL.
VI.
APPLICATION TO A CACHE MECHANISM USING
ENERGY EFFICIENT TTLS
In consideration of energy efﬁciency in content dissem-
ination networks, we previously proposed an ILP model to
design the most energy efﬁcient cache locations taking the
multiplexed caching hierarchies into account [14].
In [15], we proposed the threshold-based cache mechanism
to locally search for locations which are near to the most
energy efﬁcient locations. In threshold-based caching, every
CR automatically pre-designs a threshold of request rates of
content using local information on each caching hierarchy
before cache operation and the content data are cached when
the request rate of the content is above a pre-designed threshold
or isn’t cached when the request rate is below that threshold.
116
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

1e−03
1e−01
1e+01
1e+03
0.0
0.2
0.4
0.6
0.8
1.0
Request rates of content (log)
Cache hit ratio
TTL
Threshold
(a) TTL = 1, Th = 1
1e−03
1e−01
1e+01
1e+03
0.0
0.2
0.4
0.6
0.8
1.0
Request rates of content (log)
Cache hit ratio
TTL
Threshold
(b) TTL = 10, Th = 0.1
Figure 11: Comparison of cache hit ratio at a CR with threshold-based caching
and TTL-based caching
0
100 200 300 400 ∞
2
4
6
8
10
12
14
TTL [sec] set to each CR
Content router
TTLo
o
(a) Topology A
0
100 200 300 400
TTL [sec] set to each CR
5
10
15
20
Content router
∞
TTLo
o
(b) Topology B
Figure 12: Energy efﬁcient TTL for each topology
In threshold-based caching, CRi has the threshold Tho
i [re-
quests/sec] of request rates for origin site o of content, which
is uniquely determined for each delivery tree in the target
network. Furthermore, we can express the request propagation
matrix Dc
th of threshold-based caching in the proposed model
as
[Dc∈Co
th
]m,n :=



1
∀m = parent node(n)
∧ ∑N
k λc
(n,k)[s] < Tho
n
0
otherwise
.
(10)
Co is the set of content items having origin o.
In this paper, we propose an approximation method using
TTL of threshold-based caching because TTL-based caching
can realize a more simple cache management by just updating
the TTL counter of content without having to measure the
request rates of content like in threshold-based caching.
We derive the approximation method using TTL of
threshold-based caching as follows.
TTLo
i =
1
Tho
i
, ∀i, o
(11)
Here, TTLo
i is set to CRi and deﬁned as a different value for
each origin site o of content. In Figure 11, we evaluate the
cache hit ratio of content at a CR for threshold-based caching
and the energy efﬁcient TTL-based caching. As a result, we see
0
2000
4000
6000
Average  power consumption  [J/s]
8000
Cache Power 
Traffic Power 
TTL
Threshold
TTL
Threshold
TTL
Threshold
TTL
Threshold
α＝0.8 α＝1.2
α＝0.8 α＝1.2
Topology A
Topology B
Figure 13: Power consumption for energy efﬁcient TTL-based caching and
threshold-based caching
0
4
6
10
Average hop length for all contents
8
2
0
0.4
0.6
1.0
Cache hit ratio for all contents
0.8
0.2
TTL
Threshold
TTL
Threshold
Topology
      A
Topology
      B
Topology
      A
Topology
      B
TTL
Threshold
TTL
Threshold
TTL
Threshold
TTL
Threshold
α＝0.8
α＝1.2
α＝0.8
α＝1.2
TTL
Threshold
TTL
Threshold
α＝0.8
α＝1.2
α＝0.8
α＝1.2
Figure 14: Cache performance for energy efﬁcient TTL-based caching and
threshold-based caching
that the cache hit ratio in the energy efﬁcient TTL can provide
similar characteristics to that in threshold-based caching.
Using (1), we can derive the request propagation matrix
Dc∈Co
ttl
using the energy efﬁcient TTL as
[Dc∈Co
ttl
]m,n :=



1 − f(∑N
k λc
(n,k)[s],
1
T ho
n ),
∀m = parent node(n)
0
otherwise
. (12)
In these cache mechanisms, the threshold Tho
o and the TTL
1
T hoo for content having origin o at CRo are deﬁned as 0 and ∞,
respectively. Therefore, all content items are always cached in
the network unless memory overﬂow occurs in each CR.
Here, we demonstrate the effectiveness of the energy
efﬁcient TTL based on the same conditions as in Section V.
Figure 12 shows the TTL values derived by (11). In these
117
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

TTL
Threshold
TTL
Threshold
TTL
Threshold
TTL
Threshold
α＝0.8
α＝1.2
α＝0.8
α＝1.2
Topology A
Topology B
0
20
40
60
80
Memory usage of each CR  [GB]
Outlier 
Figure 15: Box plot of memory usage for TTL-based caching and threshold-
based caching
results, TTLo
o at CRo in origin site o is inﬁnite and the other
TTLs are derived as different values for each target network.
In Figure 13 and Figure 14, we compare the total power
consumption and the cache performance for two mechanisms
using the energy efﬁcient TTLs and thresholds of request rates,
respectively. In these results, the total power consumption
in the energy efﬁcient TTL-based caching is near to that
in threshold-based caching. Moreover, the cache hit ratio is
always 100% because TTLo
o and Tho
o (∀o) are inﬁnite and
0. The average hop length in TTL-based caching is slightly
smaller than that in threshold-based caching because the mem-
ory usage in TTL-based caching is larger than that in threshold-
based caching as shown in Figure 15.
VII.
CONCLUSION
We proposed an analytical model to evaluate the cache
characteristics of a distributed cache system like CCN. The
proposed model is expressed by iterative matrix equations and
can evaluate the impact of TTL-based caching on network
resources and cache performance on multiplexed caching hi-
erarchies. In the evaluations, we veriﬁed the validity of cache
characteristics estimated by the proposed model under the as-
sumption that content requests are generated at an independent
and identically distributed exponential interval and analyzed
the impact on memory usage, power consumption, cache hit
ratio, and average hop length when changing the TTL value of
content. Furthermore, we introduced the energy efﬁcient TTL
to reduce the power consumption of the network and evaluated
its effectiveness. Based on the proposed model, we showed that
the energy efﬁcient TTL-based caching can achieve a similar
power consumption like threshold-based caching that searches
for the most energy efﬁcient cache locations and can realize
shorter hop length than threshold-based caching.
As future work, we plan on enhancing the model in
consideration of the limit of memory size and a different
arrival process of content requests. Furthermore, we will study
memory control mechanisms based on the theoretical model
of TTL-based caching.
REFERENCES
[1]
V. Jacobson, D. K. Smetters, J. D. Thornton, M. F. Plass, N. H. Briggs,
and R. L. Braynard, “Networking Named Content”, in Proc. of
CoNEXT’09, Rome, Italy, December, 2009, pp. 1–12.
[2]
I. Baev, R. Rajaraman, and C. Swamy,“Approximation Algorithms for
Data Placement in Arbitrary Networks”, in Proc. of the 12th ACM-
SIAM Symposium on Discrete Algorithms (SODA), Washington, DC,
USA, January, 2001, pp. 661–670.
[3]
L. Qiu, V. N. Padmanabhan, and G. M. Voelker, “On the Placement of
Web Server Replicas”, in Proc. of INFOCOM, Anchorage, AK, USA,
April, 2001, pp. 1587–1596.
[4]
Z. Drezner, “Facility Location: A Survey of Applications and Methods”,
Springer, Berlin, 1995.
[5]
S. Borst, V. Gupta, and A. Walid, “Distributed Caching Algorithms for
Content Distribution Networks”, in Proc. of INFOCOM’10, San Diego,
CA, USA, March, 2010, pp. 1–9.
[6]
K. Guan, G. Atkinson, and D. C. Kilper, “On the Energy Efﬁciency of
Content Delivery Architectures”, in Proc. of the 4th IEEE International
Conference on Communications (ICC) Workshop on Green Communi-
cations, Kyoto, Japan, June, 2011, pp. 1–6.
[7]
G. Caroﬁglio, V. Gehlen, and D. Perino, “Experimental Evaluation
of Memory Management in Content-Centric Networking”, in Proc. of
IEEE International Conference on Communications (ICC 2011), Kyoto,
Japan, June, 2011, pp.1–6.
[8]
H. Che, Y. Tung, and Z. Wang, “Hierarchical web caching systems:
modeling, design and experimental results”, IEEE JSAC, 20(7), 2002,
pp. 1305–1314.
[9]
P. Mahadevan, P. Sharma, S. Banerjee, and P. Ranganathan, “A Power
Benchmarking Framework For Network Devices”, in Proc. of NET-
WORKING’09, vol. 5550, Aachen, Germany, May, 2009, pp. 795–808.
[10]
T. Harder, V. Hudlet, Y. Ou, and D. Schall, “Energy Efﬁciency is not
Enough, Energy Proportionality is Needed!”, in Proc. of DASFAA’11,
Hong Kong, China, April, 2011, pp. 226-239.
[11]
U. Lee, I. Rimac, D. C. Kilper, and V. Hilt, “Toward energy-efﬁcient
content dissemination”, IEEE Network, vol. 25, no. 2, 2011, pp. 14–19.
[12]
C. Fricker, P. Robert, J. Roberts, and N. Sbihi, “Impact of trafﬁc
mix on caching performance in a content-centric network”, in IEEE
NOMEN’12, Workshop on Emerging Design Choices in Name-Oriented
Networking, Orlando, Florida, USA, March, 2012, pp. 310–315.
[13]
D. Rossi and G. Rossini, “Caching performance of content centric
networks under multi-path routing”, Technical Report, Telecom Paris
Tech,. 2011.
[14]
S. Imai, K. Leibnitz, and M. Murata, “Energy Efﬁcient Content Lo-
cations for In-Network Cachingin Proc. of APCC’12, Jeju, Korea,
October, 2012, pp. 554 – 559.
[15]
S. Imai, K. Leibnitz, and M. Murata, “Energy-Aware Cache Manage-
ment for Content-Centric Networking”, in Proc. of First International
Workshop on Energy-Aware Systems, Communications and Security,
Barcelona, Spain, March, 2013, pp. 1623 – 1629.
118
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

