Eager to Take Part in the Global AI Race? 
 Better, Look for Traps Waiting There for You  
Emanuel  Diamant 
VIDIA-mant  
Kiriat Ono, Israel 5510801 
e-mail: emanl.245@gmail.com 
  
 
 
Abstract—The concept of Artificial Intelligence (AI) was 
introduced about 60 years ago. At the same time, Artificial 
Neural Networks (ANNs) were devised as a means for AI 
implementation. They were conceived as a collection of small 
interconnected computational units (called artificial neurons), 
which are supposed to imitate the biological neurons of the 
human brain. Essentially, ANNs were devised as data 
processing units – 60 years ago, all things in the world were 
considered computational. But today, the brain is thought as 
an information processing system. Therefore, biological 
neurons (and their artificial analogs) should be considered as 
information-processing units. This shift in the underlying 
assumptions is overlooked by almost all AI designers. I hope 
that a clarification of this issue will help AI designers to avoid 
dead ended trails and harmful pitfalls on their way to a 
successful and trustworthy AI realization. 
Keywords- Artificial Intelligence; Artificial Neural Network; 
information; information processing  
I. 
 INTRODUCTION  
It is generally agreed and accepted that the human race 
is on the eve of a great and unknown time – the time of the 
AI era advent and victory. What once was considered a 
futuristic technology today begins to penetrate almost every 
aspect of our life.   
The unprecedently rapid pace of AI infiltration is usually 
attributed to the latest Deep Learning Neural Nets (DLNN) 
explosion. Although Neural Nets have their roots a lot of 
years ago, DLNNs have rapidly became the best known 
technique in AI, yielding numerous state of the art results in 
a wide variety of domains such as speech recognition, image 
processing , language translation and as such tough and 
difficult tasks.  
Wikipedia defines Deep learning as a set of machine 
learning algorithms that attempt to model high-level 
abstractions in data by using model architectures composed 
of multiple non-linear transformations. Deep learning 
software works by filtering data through a hierarchical, 
multilayered network of simulated neurons that are 
individually simple but can exhibit complex behavior when 
linked together, [1]. The might of Deep learning is now 
servicing AI research and development (R&D) supremacy. 
Although in its long history AI’s R&D has seen several 
ups and downs, the current surge of interest in AI is 
unmatched in its extent and enormity. The reason for this is 
the advent of the Big data era: Advances in sensor 
technologies, explosive growth of computing power, 
proliferation of broadband internet equipment, have led to 
an unprecedented flood of data inundating our surrounding. 
In such circumstances traditional practice of human-
centered management of data volumes does not hold 
anymore and has to be delegated to a machine (a computer 
as we usually call it today). It is self-evident that such a 
computer has to possess many human-like cognitive 
abilities, which underpin understanding, analysis, and 
interpretation of the incoming data streams. In short, has to 
possess AI abilities.  
The urgent need for AI solutions apt to meet the growing 
flood of Big data has led to an unprecedented rise in AI 
R&D efforts undertaken today around the world. 
II. 
THE AI RACE 
As the opportunities of AI technology become more 
recognized and appreciated, more and more nation states 
begin to consider their own AI strategies. Tim Dutton, in 
[2], has summarized a package of such national programs 
announced in the past two years. 
In 2018, 25 European countries have joined up to make 
sure that the AI revolution doesn’t leave them aside. The EU 
Commission has adopted a document that includes a 
commitment to increase the EU’s investment in AI from 
€500 million in 2017 to €1.5 billion by the end of 2020, and 
the creation of the European AI Alliance, [2]. President 
Emmanuel Macron unveiled France’s €1.5 billion plan to 
turn his country into a world leader for AI research and 
innovation. The U.K. Parliament has urged its government 
to draw up a policy to help the country become one of the 
world’s AI leaders. Germany, too, has its grand ambitions in 
AI, [3], [4]. 
All these announcements are inspired by the idea that 
Europe must catch up with the United States and China in 
an AI arms race. Although the leadership of the United 
States and China is worldwide acknowledged and 
appreciated, the real state of affairs in AI R&D in US and 
China remains blurred and ambiguous.    
The accepted (in the USA) free-market-oriented 
approach results in an entangled combination of classified 
research, public contracts from development organizations 
(like DARPA), and partnerships with the private sector, [4]. 
The extent of government funding in each of the sectors is 
blurred and unclear: In its unclassified 2017 budget, 
Pentagon reported on spending approximately $7.4 billion on 
16
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

AI and the supporting fields, [3]. Billions more are invested 
in classified R&D, but how large are the figures is unknown. 
DARPA alone pledged to invest $2 billion in AI over the 
next five years through its AI Next initiative [5]. 
Similarly blurred and fuzzy are China’s intentions in the 
AI. Only the budget figures are much more higher: The 
Chinese government pledges to build a US$150 billion AI 
industry by 2030, [4]. 
It is worth to be mentioned that human brain research, 
which is closely related and associated with AI’s R&D, 
exhibits remarkably lower levels of government support and 
funding: The USA BRAIN Initiative is provided with $1 
billion budget for ten years of project duration. European 
Human Brain Project is funded with 1.3 billion euro for the 
same 10 years long research span.  
III. 
UNEXPECTED HURDLES 
Despite the hype and the fascination that naturally 
surrounds AI undertakings, the real state of affairs is far 
from being satisfactory – despite of a long history of use and 
exploration, the operational principles of the DLNNs remain 
unclear and ambiguous. There is still little insight into their 
internal operations, and a lack of knowledge on why and 
how they achieve their impressive performances. From a 
scientific point of view, this is entirely unsatisfactory. 
Without a clear understanding of how and why the NNs 
work, the development of better models inevitably reduces 
to trial-and-error experimentation [6]. 
For 
that 
reason, 
the 
issue 
of 
explainability, 
interpretability, and transparency of ANNs applications has 
become a subject of hot public discourse and is repeatedly 
raised at many AI design related conferences, forums and 
gatherings, [7], [8], [9], [10]. 
An interesting turn in this discussion has been inspired 
by the recent announcement of Ali Rahimi (and his friends) 
that Machine Learning (ML) and AI “have slipped out of 
the bounds of science and engineering into alchemy”, [11]. 
At the 2017 NIPS conference, Ali Rahimi declared that AI 
researchers do not know why some algorithms work and 
others don't. Relying on a trial and error strategy, AI 
algorithms have become a form of "alchemy." [12].  
IV. 
OVERLOOKED  REASONS 
There is a common agreement among the participants of 
the public discussions about the measures that should to be 
taken in order to reach more “user friendly” and explainable 
ML/ANN constructions [13]. However, what is surprising in 
these recommendations is that, (agreeing with the statement 
that better theoretical understanding of the ANNs functional 
principles is compulsory for further successful development 
of ML/AI applications), no single attempt is undertaken to 
elaborate such theoretical principles. Therefore, I consider 
as my duty to try and to develop these overlooked 
theoretical grounds. 
As to me, contemporary ANN designers are ignorant and 
unaware about the difference and the inconsistency between 
artificial and natural biologic neurons. While artificial 
neurons are intentionally designed to be data processing 
computational units, the natural biologic neurons are 
evolutionary developed to deal with and carry out 
information processing.  
60 years ago, the world was at the dawn of a computing 
era, and the human brain was regarded as a computing 
device. Intelligence was considered as a human trait and as a 
product of human brain activity. Therefore, Intelligence was 
considered to be a computable function, and Computational 
Intelligence has evolved as a respected field of human-
related computer science. 
To facilitate human brain functioning studies, Artificial 
Neural Networks (ANNs) were conceived as a set of tightly 
interconnected simple computational units resembling the 
network of biological neurons in human brain. As it was just 
mentioned, ANNs units’ functionality indisputably implies 
data processing ability. That is, ANNs were designed and 
used as data processing (computational) devices. 
However, in recent decades, a significant paradigm shift 
in brain functionality understanding has occurred. Now, 
human brain is considered as an information processing 
apparatus. Intelligence, thus, should be seen as an 
information processing outcome. Subsequently, brain 
neurons should be seen as information processing units (not 
data processing instruments, as it was before). At the same 
time, Intelligence is no more an exceptionally human trait – 
it is a feature common to all living beings, with and without 
brains or nervous systems. (Another argument in favor of an 
information processing principle).  
Contemporary AI designers are not aware about these 
revolutionary transforms. The difference between data and 
information is not seen and not understood properly by the 
contemporary research community and therefore the subject 
is overlooked and neglected. Often, the notions of data and 
information are used interchangeably, most often being 
mixed and blended. That is the legacy of Shannon’s 
Information Theory or, let us be more accurate, the way of 
how people understand and use Shannon’s Theory. I do not 
think it would be wise to deepen our understanding of these 
inconsistencies. Rather, I think, it will be more appropriate 
to understand what actually information is. 
V. 
LET ME EXPLAIN  
There is a widespread conviction that a consensus 
definition of Information does not exist. I do not agree with 
this. On several occasions, I have already published my 
opinion on the subject [14], [15], [16]. This time, with all 
fitting excuses, I would like to repeat some parts of these 
earlier publications in order to preserve consistency of this 
discussion. 
Contrary 
to 
the 
widespread 
use 
of 
Shannon’s 
Information Theory, my research relies on Kolmogorov’s 
ideas on information, [17]. According to Kolmogorov, a not 
random binary string (called a separate finite object) can be 
represented by a compressed description of it (produced by 
a computer program in an algorithmic fashion) “in such a 
way that from the description, the original message can be 
completely reconstructed” [18]. The compressed description 
of a binary object has been dubbed as “algorithmic 
information” and its quantitative measure (the length of the 
17
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

descriptive program) has been dubbed as the description 
“Complexity”.  
Taking Kolmogorov’s insights as a starting point, I have 
developed my own definition of information that can be 
articulated in the following way: “Information is a 
linguistic description of structures observable in a given 
data set”.  
To make the scrutiny into this definition more palpable I 
propose to consider a digital image as a given data set. A 
digital image is a two-dimensional set of data elements 
called picture elements or pixels. In an image, pixels are 
distributed not randomly, but, due to the similarity in their 
physical properties, they are naturally grouped into some 
clusters or clumps. I propose to call these clusters primary 
or physical data structures.  
In the eyes of an external observer, the primary data 
structures are further arranged into more larger and complex 
agglomerations, which I propose to call secondary data 
structures. These secondary structures reflect human 
observer’s view on the grouping of primary data structures, 
and therefore they could be called meaningful or semantic 
data structures. While formation of primary (physical) data 
structures is guided by objective (natural, physical) 
properties of the data, the subsequent formation of 
secondary (semantic) data structures is a subjective process 
guided by human conventions and habits. 
As it was said, Description of structures observable in 
a data set should be called “Information”. In this regard, 
two types of information must be distinguished – Physical 
Information and Semantic Information. They are both 
language-based descriptions; however, physical information 
can be described with a variety of languages (recall that 
mathematics is also a language), while semantic information 
can be described only by means of natural human language. 
(More details on the subject could be find in [19]).  
Those, who will go and look in [19], would discover that 
every information description is a top-down-evolving 
coarse-to-fine hierarchy of descriptions representing various 
levels of description complexity (various levels of 
description details). Physical information hierarchy is 
located at the lowest level of the semantic hierarchy. The 
process of sensor data interpretation is reified as a process 
of physical information extraction from the input data, 
followed by an attempt to associate this physical 
information (about the input data) with physical information 
already retained at the lowest level of the semantic 
hierarchy. 
If such an association is attained, the input physical 
information becomes related (via the physical information 
retained in the system) with a relevant linguistic term, with a 
word that places the physical information in the context of a 
phrase that provides the semantic interpretation of it (see 
also the block diagram in [14]). In such a way, the input 
physical data object becomes named with an appropriate 
linguistic label and framed into a suitable linguistic phrase 
(and further – in a story, a tale, a narrative), which provides 
the desired meaning for the input physical information. 
(Again, more details can be found on the website [19]). 
VI. 
WHAT FOLLOWS FROM ALL THIS  
Equipped with the “In this paper introduced” (ITPI) 
definition of Information we can now try to analyze what is 
going on in a typical ANN-based AI installation (it goes 
without further saying that DLNN, CNN, RNN, and all 
other NN versions are simply revisions of the same basic 
NN layout). Usually, as it is always proudly declared, after 
an act of training the NN transforms autonomously the data 
at its input into a semantic label or a semantic statement at 
its output. Terms “physical information” and “semantic 
information” are not known to the ANN design community. 
As a result, any information processing goal has not been 
foreseen and is not fulfilled in the course of ANN data 
processing activity.  
It is unnecessary to remind the readers that according to 
ITPI theory, direct transition from primary (physical) 
information description to secondary (semantic) information 
description is not possible (does not exist). It is 
unreasonable, from a theoretical point of view. The 
grouping of primary data structures into secondary data 
structures is entirely an observer’s privilege and prerogative. 
The rules of secondary structures organization are 
subjective, that is, they are solely observer’s habits and 
concerns. Intelligence displaying systems (natural or 
artificial) acquire them as a grant, as a gift, a shared 
common 
agreement 
(a 
common 
knowledge 
base). 
Afterwards they all are preserved (conserved) in the 
system’s memory. ANN training phase can be seen as a hint 
of this processing tread. But in ANN practice, which is 
devoid of any information processing intents, such things 
are even do not appear.  
The term “information” is frequently seen in ANN R&D 
texts. But it is used in the sense of Shannon’s Information 
Theory. That is, the term information is used as a 
substitution swap for data. Shannon’s theory does not define 
what information is. It introduces and exploits a notion of 
“information measure”. Which is equivalent to the 
“entropy” of a data set. Shannon himself has warned not to 
mix up the terms (information and information measure). 
But who cares? 
An important outcome of the ITPI theory is the 
referential mode of information processing, which is 
unknown (to AI systems designers) and therefore is not 
addressed in any ANN-based AI designs. The long list of 
missed AI related properties that must be satisfied in an 
information processing AI system is not even mentioned 
here because of the limited article space.  
VII. CONCLUSIONS  
The purpose of this paper is not to reject or deny AI’s 
virtues or to turn down its achievements. The purpose of 
this paper is to convince interested people that any further 
success in AI R&D requires immediate rejection of the 
ANN approach, which today is the main workhorse of AI 
modeling.   
The notions of AI and ANN were introduced about 60 
years ago. It was at the down of the computer era, when, 
according to the spirit of that time, every fact and every 
18
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

action were considered as a computational expression. All 
scientific fields were considered “computational”. The brain 
and its functions were considered computational (recall 
“Computational Intelligence”, which is alive and prosperous 
even in these days). Brain neurons, accordingly, were 
regarded as computational units. It is worth to mention that 
“computational” 
always 
implies 
“busy 
with 
data 
processing”. 
The beginning of this century was denoted by a rapid 
paradigm shift in scientific thinking – from data processing 
predisposition to information processing preference. Almost 
immediately, Computational Biology has become converted 
to Cognitive Biology, Computational Neuroscience to 
Cognitive Neuroscience, Computer Vision to Cognitive 
Vision. Almost every conventional Computational science 
was converted to an associated Cognitive science. (Here 
“Cognitive” implies “Information processing” aptness and 
ability). Unfortunately, ANN-based approach to AI 
modeling has not been affected by this general paradigm 
shifting. 
At the same time, the information processing paradigm 
adopted by the whole spectrum of biological sciences has 
led to significant advancement in understanding the nature 
and special virtues of Intelligence. Intelligence is not 
anymore a uniquely human attribute. It is an evolutionary 
developed feature present in every living being, from 
bacteria to humans. Intelligence – as an ability to process 
information – is present now (evident, observable, 
discernable) at all levels of living beings spectrum. It does 
not require Neural Nets complexity, it is ruled by the same 
principles of information processing at all levels of living 
beings presence, [20]. Therefore, such things as Narrow 
Intelligence or General Intelligence for this constellation do 
not exist. You can guess that Artificial Intelligence and 
Natural Intelligence (in such a case and with all their 
diversities) differ only by the level of information 
complexity that is supposed to be processed or is actually 
processed in the system.   
I hope that clarification of these issues will help AI 
designers to avoid dead ended trails and harmful pitfalls on 
their way to a successful and trustworthy AI realization. 
 
References 
 [1]   “Deep learning”, From Wikipedia, the free encyclopedia, 
http://en.wikipedia.org/wiki/Deep_learning  
[2]    T. Dutton, “An Overview of National AI Strategies”,  
         https://medium.com/politics-ai/an-overview-of-national-ai-strategies-
2a70ec6edfd  
[3]    T. Rabesandratana, “With €1.5 billion for artificial intelligence 
research, Europe pins hopes on ethics”, Apr. 25, 2018, 
http://www.sciencemag.org/news/2018/04/15-billion-artificial-
intelligence-research-europe-pins-hopes-ethics  
[4]    J. K. Delaney, “France, China, and the EU All Have an AI 
Strategy. Shouldn’t the US?”, May 20, 2018. 
https://www.wired.com/story/the-us-needs-an-ai-
strategy/?mbid=social_twitter  
[5]    VentureBeat Events, “DARPA is betting $2 billion on your next AI 
innovation”, October 8, 2018. 
https://venturebeat.com/2018/10/08/darpas-betting-2b-on-your-next-
ai-innovation/ 
[6] M. Zeiler and R. Fergus, “Visualizing and Understanding 
Convolutional Networks”, http://arxiv.org/abs/1311.2901  
[7]    R. Shwartz-Ziv and N. Tishby, “Opening the Black Box of Deep 
Neural Networks via Information”, https://arxiv.org/abs/1703.00810  
[8]    B. Mittelstadt, et al, “Explaining Explanations in AI”, 
https://arxiv.org/abs/1811.01439  
[9] T. Xu, et al, “Deeper Interpretability of Deep Networks”, 
https://arxiv.org/abs/1811.07807  
[10]  Z. C. Lipton, “The Mythos of Model Interpretability”, 
https://arxiv.org/abs/1606.03490  
[11] R. Letzter, “Google AI Expert: Machine Learning Is No Better Than 
Alchemy”, May 7, 2018, https://www.livescience.com/62495-rahimi-
machine-learning-ai-alchemy.html  
[12] A. Rahimi and B. Recht, “An Addendum to Alchemy”, Dec 11, 2017 
http://www.argmin.net/2017/12/11/alchemy-addendum/  
[13] Z. Lipton and J. Steinhardt, “Troubling Trends in Machine Learning 
Scholarship”, https://arxiv.org/abs/1807.03341  
[14]  E. Diamant, “Unveiling the mystery of visual information processing 
in human brain”, Brain Research, vol. 1225, pp. 171-178, 15 Aug. 
2008, https://arxiv.org/abs/0807.0337 
[15] E. Diamant, “Shannon's definition of information is obsolete and 
inadequate. It is time to embrace Kolmogorov’s insights on the 
matter”, 
Conference 
Paper, 
November 
2016. 
https://www.researchgate.net/publication/311223095  
[16] E. Diamant,  “Advances in Artificial Intelligence: Are you sure, we are 
on the right track?” 
https://www.researchgate.net/publication/272478913  
[17] A. N. Kolmogorov, “Three approaches to the quantitative definition of 
information”, Problems of Information and Transmission, Vol. 1, No. 
1, pp. 1-7, 1965. 
http://alexander.shen.free.fr/library/Kolmogorov65_Three-
Approaches-to-Information.pdf   
[18] P. Grunwald and P. Vitanyi, “Algorithmic Information Theory”, 2008.  
http://arxiv.org/pdf/0809.2754.pdf   
[19] E. Diamant, “Brain, Vision, Robotics and Artificial Intelligence”. 
http://www.vidia-mant.info  
[20]  E. Diamant, “Designing Artificial Cognitive Architectures: Brain 
Inspired or Biologically Inspired?” 
https://www.researchgate.net/publication/329582475   
 
 
 
 
19
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

