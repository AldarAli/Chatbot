A Trust-based Model for Quality of Web Service
Bo Ye, Anjum Pervez, Mohammad Ghavami
the Faculty of Engineering, Science and Built Environment
London South Bank University
London, UK
{yeb,perveza,ghavamim}@lsbu.ac.uk
Maziar Nekovee
BT Research,
Polaris 134 Adastral Park,
Martlesham, Suffolk, UK
maziar.nekovee@bt.com
Abstract—In order to choose the best services among various
services across the world, how much a service can be trusted
is increasingly important for service consumers. In addition, if
services are invoked by machines, it is increasingly crucial that
the trust in services can be calculated automatically. However,
most existing approaches are based on the assumption that the
trust value can be provided by consumers, but ‘how’ is not
solved. In this paper, criteria of Quality of Service (QoS) are
classiﬁed into different groups, and an automatic trust calculation
is introduced. After that, an approach based on the Kalman
Filter is presented to ﬁlter out malicious values and to estimate
real values. Through aggregating the values provided by other
consumers, the value of the trust in different QoS criteria can
be obtained. Finally, experiments are carried out to access the
validation and robustness of our model.
Keywords-Web service; Quality of Service; Trust; Kalman
Filter
I. INTRODUCTION
While more and more systems are developed based on
Service and Cloud Computing, more and more different kinds
of services are going to emerge on the Internet. Because of var-
ious users’ requirements and many service attributes, selection
of a proper service is not easy for a user in Service Oriented
Architecture (SOA) systems. Currently, most approaches are
based on Quality of Service (QoS) to select services.
Among these QoS criteria, reputation is a really important
one because service consumers can access a large number
of services providing identical or similar functions. Most
providers publish values of their services’ QoS. However, how
much these values can be trusted is really crucial. Electronic
commerce has a similar issue, and various electronic markets
and online electronic commerce companies have built repu-
tation systems, e.g., Amazon, eBay, Yahoo!, Slashdot. Many
researchers have considered trust-based system, an effective
way to identify malicious consumers to minimize their threat
and protect the system from possible misuses and abuses.
Therefore, it is crucial to measure web service trust and
many researchers have proposed various approaches using dif-
ferent techniques. Although many efﬁcient and robust measure
solutions [1]–[6] has been proposed in previous research, these
approaches still mostly have following weaknesses.
First of all, most approaches measure service reputation
based on the feedback provided by human, and therefore it is
difﬁcult to ensure the accuracy. This kind of systems cannot be
built without humans participating. Due to different abilities
and knowledge of human, it is impossible for them to provide
the same feedback, even if they use the identical service.
Hence, it is necessary to build an automatic trust measure
system.
Secondly, existing trust measure solutions mostly collect
feedbacks only between service consumers and providers, but
rarely use information among service consumers. Most of such
systems are centralized, and not all systems have a center
server. Hence, how a new service consumer can obtain the trust
level of a service in distributed systems needs to be considered.
In addition, due to existing malicious service consumers,
how those malicious ones can be ﬁltered out becomes increas-
ingly crucial. Malicious consumers might provide malicious
values to falsely improve the trust, or to degrade the trust in
certain service providers for commercial beneﬁts.
To address the weaknesses above, an approach to measure
the trust both in service providers and consumers has been
proposed. This approach ﬁrst groups QoS criteria, and then
measures the trust in each QoS criterion of a service based
on the characteristics of QoS criteria. The measure of trust in
services has also been divided into two main stages, including
Time Domain and Aggregation Domain, because a service
consumer can measure the trust in service providers at different
domains. First, it may invoke a service many times, so that it
can measure the trust based on its own observation at Time
Domain. All data obtained itself at Time Domain, and there-
fore it is unnecessary to ﬁlter out any information. Second, it
may also obtain the trust by using the data from others, called
as Aggregation Domain. At this stage, the consumer not only
needs to aggregate all information, but also has to ﬁlter out
malicious data.
Compared to the existing approaches, our main contribu-
tions have been summarised as follows:
1) Quality of Web Service Criteria have been grouped
into several classes based on their characteristics, and
the stages of trust measure have been classiﬁed into
two main domains. A trust measure approach has been
proposed to overcome the weaknesses mentioned above.
2) Both negative and positive malicious values can be
detected by our approach, and the trust in both service
providers and consumers has been measured, which
makes the measure more reliable. Trust in consumers
reﬂects its trust level from another one’s perspective.
3) At Aggregation Domain, when a service consumer ag-
39
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

gregates the information from numerous other service
consumers, it uses the trust in other consumer X to
weight the trust in a service provider from X.
The rest of this paper is organized as follows. The major
related research has been introduced in Section I. Section III
presents how quality criteria are grouped and how the values
of trust in quality criteria and reference trust are calculated
automatically. Section IV describes how malicious values are
detected and how different values from a variety of consumers
are aggregated to calculate the value of trust. The model is
evaluated by carrying out different experiments in Section V.
Finally, the conclusion is given in the Section VI.
II. RELATED WORK
The characterization of reputation systems and threats fac-
ing them from a computer science perspective can be found
in [4]. Wang and Lin [5] reviewed the reputation-based trust
evaluation mechanisms in literature and outline some trust
issues in e-commerce environments. An overview of existing
and proposed systems that can be used to derive measures of
trust and reputation for Internet transactions was given in [6].
Ardagna and Pernici [7] proposed a modelling approach to
service selection problem, but trust is just one of those con-
sidered quality criteria. Although this approach is effective to
select a service for a consumer, it did not focus on the detection
of malicious consumers. Then if malicious consumers exist, it
may not select appropriate services for consumers.
In [8], the reputation was modelled as a three-dimension
belief (b, d, u), which represent the positive, negative and
uncertain probabilities. In [9]–[11], a Bayesian reputation ap-
proach was proposed to calculate the reputation value based on
the beta probability density functions (PDF). In [10], intuitive
parameters needs to be tuned manually without guarantee of
any quantitative conﬁdence. Wang, Liu and Su [12] proposed
a general trust model for a more robust reputation evaluation.
The trust in [8]–[10] was modelled as predicted probability
values, but prediction variance was ignored by them, which
was considered in [12]. However, all these models only use
feedbacks between service providers and consumers, but did
not use feedbacks among service consumers.
Based on reputation Corner et al. [13] proposed a trust
management framework that supports the synthesis of trust-
related feedback from multiple services while also allowing
each entity to apply various scoring functions over the same
feedback data for personalized trust evaluations. However, this
approach is based on the assumption that consumers do not
mask their malicious behaviour, meaning that it is hard to
detect those malicious service consumers that behave well until
they gain good trust values and then behave maliciously. Xiong
et al. and Srivatsa et al. [14], [15] measured the trust by the
use of personalized similarity between itself and other peer X
to weight feedback from X.
However, all these models were built based on the assump-
tion that a consumer can provide a trust value in the service.
This is the ﬁrst weakness summarized in Section I. How a
trust value can be automatically calculated is ignored in these
models.
III. QUALITY CRITERION
In this section, Quality Criterion and relevant concepts are
introduced ﬁrst, and then, how trust values can be calculated
automatically is presented.
Deﬁnition 1. Quality Criterion: This encompasses a number
of Quality of Service (QoS) properties used to evaluate a web
service. The following is a brief explanation of criteria:
1) Price (P): The price of a web service is a sum of the
invoked operations’ prices of the web service.
2) Response Time (RT): The estimated time between
when a request is sent and when a result is received.
3) Availability (A): The probability that a web service is
available.
4) Success Rate (SR): The rate of a web service’s ability
to response to requests successfully.
Based on the way how it affects the overall QoS of a service,
Quality Criterion can be classiﬁed as either Positive Criterion,
whose increase beneﬁts the overall QoS, or Negative Crite-
rion whose decrease beneﬁts the overall QoS. Based on the
nature of a criterion, criteria fall into two major classes:
1) Ratio Criterion: The value of a criterion can be ex-
pressed as a ratio, and their values can also be directly
used as the trust in the criterion, e.g., availability,
success rate, etc. Please note that Ratio Criteria are not
the criteria whose values obtained from providers are
rate. For example, compensation rate’s values are rate.
However, it is not a ratio criterion.
2) Non-ratio Criterion: The value of a criterion can not
be expressed by a ratio, e.g., price, response time, etc.
Because there are different ways to obtain the value of a
criterion, there are two major classes of criterion value:
1) Published Value of a Criterion:
The value of a
criterion is published by service provider. This can be
updated by providers at any time.
2) Actual Value of a Criterion: The value of a criterion is
obtained by service consumers after invoking a service,
which may be different from Published Value. For
instance, a provider may publish 40ms as a service’s
response time, but the actual response time may be 43ms
when the service is invoked.
Deﬁnition 2. Trust:
To simplify description, in this paper,
‘Trust’ is used as a property of a service, denoted by T.
For example, a consumer A has a trust in another consumer
B, meaning that A knows how much he can trust B. Trust
can be classiﬁed as either criterion or reference trust, on the
basis of trust purpose.
1) Criterion Trust: A consumer A’s trust in a criterion C
of a service S provided by a service provider P, denoted
by T(A → P.S.C). It identiﬁes how much a Published
Value of P.S.C can be trusted.
40
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

2) Reference Trust: Consumer A’s trust in consumer B’s
capacity of referring to other consumers’ ability to do
something, deﬁned by T(A → B). Please note that a
service provider can also have a reference trust, because
the service provider can also be a service consumer,
recommending another service provider.
Based on the ways how it affects the overall trust, a trust
can be divided into Positive Part, which increases the trust,
and Negative Part, which decreases the trust.
Similarly, the actual value of a criterion can also be classi-
ﬁed as either Positive Actual Value, which increases the trust
of the criterion, or Negative Actual Value, which decreases
the criterion’s trust.
A. Criterion Trust Calculation
T(A → S.C)j represents A’s trust in service S’s criterion
C after jth time user A invokes web service S. c represents the
published value of S.C, while cj is the actual value obtained
by the user after jth time invoking service S.
Suppose Criterion C is a negative one, meaning that the
decrease of this criterion beneﬁts the trust, then T(A → S.C)j
is calculated by the following equations.
The number of positive C values, numpo
j , is calculated by:
numpo
j
=

numpo
j−1 + 1
cj ≤ c
numpo
j−1
cj > c
(1)
The number of negative C values, numne
j , is computed by:
numne
j
=

numne
j−1
cj ≤ c
numne
j−1 + 1
cj > c
(2)
The following equation is used to calculate the value of
positive part of C’s trust,
T po
j
=



r
numpo
j−1(T po
j−1)2+(1−
cj
c )2
numpo
j
cj ≤ c
T po
j−1
cj > c
(3)
Value of negative part of C’s trust,
T ne
j
=



T ne
j−1
cj ≤ c
r
numne
j−1(T ne
j−1)2+(1−
cj
c )2
numne
j
cj > c
(4)
At last, T(A → S.C)j is calculated by
T(A → S.C)j = 1 + T po
j−1 −
numne
j
numne
j
+ numpo
j
· T ne
j
(5)
Please note that the equal values to the Published Value are
always classiﬁed as positive values.
B. Reference Trust Calculation
A service consumer A’s reference trust in another consumer
B is used to identify how much B can be trusted by A. Using
the value of trust in B, A can know how much he can trust
the services or other consumers referred by B.
Because a service provider can provide various services and
an identical service can be provided by a number of service
providers, P.S.C is used to denote a service S’s criterion C
provided by a service provider P. T(A → P.S.C) represents
the value of A’s trust value in P.S.C, while similarly T(B →
P.S.C) represents the value of B’s trust value.
The set of trust’s values obtained by service users can be
viewed as a multidimensional space and each user can be a
point in the space. Hence, A’s trust T(A → B) in service
consumer B can be calculated by the geometric distance
between the points as follows
T = 1−
v
u
u
u
t
X
P
X
S
X
C
(T(A → P.S.C) − T(B → P.S.C))2
|T(A → P.S.C)|
(6)
Their values are more similar, meaning that their experience
is more similar, and then, A can trust B more.
C. Trust Transitivity
If a service consumer A needs to know how much he can
trust in criterion C of service provider S, but he has no
information about it. However, B has trust in criterion C of
service provider S, and A knows how much he can trust B.
Then A’s trust in S.C can be deﬁned by:
A → S.C = (A → B) ∩ (B → S.C)
(7)
In this equation, the symbol ∩ does not mean that A → B
and B → S.C intersect. It means that based on the trust’s
transitive property, A’s trust in S.C can be derived by A’s
reference trust in B and B’s criterion trust in S.C.
It is common to collect reference trusts from several differ-
ent service users to make better decisions. This can be called
consensus trust. Assume a service consumer A needs to obtain
the value of the trust in a criterion C of a service S, but he
has no information about the trust of S.C. However, he has
information about trust in other consumer X and Y , and both
of they have a trust in S.C. Then the trust relationship between
A and S.C can be deﬁned by :
A → S.C = ((A → X) ∩ (X → S.C)) ∪ ((A → Y ) ∩ (Y → S.C))
(8)
In this equation, the symbol ∪ means that A’s trust in S.C can
be derived by combining X and Y ’s criterion trust in S.C.
Deﬁnition 3. Transitive Trust: Suppose there are two service
consumers A and B, where A has a reference trust in B.
Additionally, B has a function trust in criterion C of service S.
A’s trust in P.S.C can be derived by using both B’s function
trust in S.C and A’s trust in B:
T(A → P.S.C) = T(A → B) · T(B → P.S.C)
(9)
Deﬁnition 4. Consensus Trust: The consensus trust of two
consumers’ trust in P.S.C is a trust that reﬂects both trust in
a fair and equal way. Then derived consensus trust in P.S.C,
T(A → P.S.C), is calculated by:
|T(A → X) · T(X → P.S.C)|+|T(A → Y ) · T(Y → P.S.C)|
|T(A → X)|+|T(A → Y )|
(10)
41
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

IV. CRITERION VALUE ESTIMATION AND MALICIOUS
VALUE DETECTION
Malicious service consumer can be classiﬁed as either adu-
lating service consumer, which tries to falsely improve the trust
in certain service providers, or defaming service consumer,
trying to degrade the trust in certain service providers.
A. Criterion Value Estimation
It is reasonable to model the distribution of the value of
P.S.C as Normal distribution with (µ, σ), because the values
of P.S.C obtained by a consumer A are independent. For each
criterion, its value follows normal distribution with {µr, σr},
where µr is the real value of P.S.C’s µ, and σr is the actual
P.S.C’s variance.
At one time, each service consumer i has an estimated value
of P.S.C’s {µr, σr}, denoted as {µe
i, σe
i }, µe
i and σe
i represent
the estimated real value of P.S.C and estimated variance,
respectively. A service consumer A is going to use estimated
values of all other service consumers to predict P.S.C’s
{µr, σr}. After using service consumer i’s estimated value,
A’s estimated values are denoted as {µe
A,i, σe
A,i}. Because
of incomplete knowledge of the criterion of the service, i’s
estimated value usually has a deviation from A’s estimated
value {µe
A,i, σe
A,i}. Because the estimated value from many
independent service consumers, the relation between i’s esti-
mate and A’s estimate is modeled as
µe
i =
µe
A,i + λµ and p(λµ) ∼ Normal(0, Λµ)
σe
i =
σe
A,i + λσ and p(λσ) ∼ Normal(0, Λσ)
(11)
Note that λµ is different from σe
i . λµ is an estimate noise
covariance when service consumer A estimating real value
µr, while σe
i is estimated covariance from service consumer
i, which may be malicious. Similarly, λσ is an estimate noise
covariance when A estimating real value σr.
Based on Kalman Filter [16], the estimates of {µr, σr}
are governed by the following linear stochastic difference
equations:
µe
A,i = Fµµe
A,i−1 + Bui−1 + wµ,i−1; p(wµ) ∼ Normal(0, Wµ)
σe
A,i = Fσσe
A,i−1 + Bui−1 + wσ,i−1; p(wσ) ∼ Normal(0, Wσ)
(12)
where, F is the factor for relationship between the previous
estimate based on the estimate from consumer i − 1 and the
current estimate based on i’s estimate, and u is the optional
control input to the estimate {µe
A, σe
A}. Because in our model
there is no control input, u is 0. Hence, our estimate is
governed by the following linear difference equation:
µe
A,i = Fµµe
A,i−1 + wµ,i−1; p(wµ) ∼ Normal(0, Wµ)
σe
A,i = Fσσe
A,i−1 + wσ,i−1; p(wσ) ∼ Normal(0, Wσ)
(13)
In Kalman Filter, there are two steps: Predict step and
Update step. Pµ and Pσ represents predict error covariance
of µe
A,i and σe
A,i respectively. By using {µe
A,i−1, σe
A,i−1}, the
Predict step is responsible for obtaining the priori estimate,
denoted by{¯µe
A,i, ¯σe
A,i}, for Update step. Similarly, priori
predict error covariances are denoted by ¯Pµ and ¯Pσ. The
Update step is responsible for incorporating a new service
consumer’s estimate {µe
i, σe
i } to obtain an improved posteriori
estimate {µe
A,i, σe
A,i}.
Predict step:
¯µe
A,i = Fµ,iµe
A,i−1,
¯σe
A,i = Fσ,iσe
A,i−1
(14)
¯Pµ,i = F 2
µ,iPµ,i−1 + Wµ,i,
¯Pσ,i = F 2
σ,iPσ,i−1 + Wσ,i
(15)
Update step:
Kµ,i = ¯Pµ,i/( ¯Pµ,i + Λµ,i),
Kσ,i = ¯Pσ,i/( ¯Pσ,i + Λσ,i)
(16)
µe
A,i =
¯Pµ,i + Kµ,i(µe
i − ¯µe
A,i),
σe
A,i =
¯Pσ,i + Kσ,i(σe
i − ¯σe
A,i)
(17)
Pµ,i = (1 − Kµ,i) ¯Pµ,i,
Pσ,i = (1 − Kσ,i) ¯Pσ,i
(18)
In order to compute the parameters Fµ,i, Λµ,i, Wµ,i, Fσ,i,
Λσ,i, Wσ,i, the following equations are used:
Fµ,i =
i−1
X
j=1
µe
A,jµe
A,j−1
i−1
X
j=1
(µe
A,j)2
,
Fσ,i =
i−1
X
j=1
σe
A,jσe
A,j−1
i−1
X
j=1
(σe
A,j)2
(19)
Λµ,i = 1
i
i−1
X
j=1
(µe
j − µe
A,j)2,
Λσ,i = 1
i
i−1
X
j=1
(σe
j − σe
A,j)2
(20)
Wµ,i = 1
i
i−1
X
j=1
(µe
A,j − Fiµe
A,j−1)2,
Wσ,i = 1
i
i−1
X
j=1
(σe
A,j − Fiσe
A,j−1)2
(21)
B. Malicious Value Detection
Given signiﬁcance probability levels δµ and δσ, the problem
of determine if the service consumer i is not malicious is to
ﬁnd the threshold values ∆µ,i and ∆σ,i so that:
P(|µe
i − µe
A,i|≤ ∆µ,i) = δµ, P(|σe
i − σe
A,i|≤ ∆σ,i) = δσ (22)
In addition, µe
i − µe
A,i and σe
i − σe
A,i follow zero mean
normal distribution with variance Pµ,i + Λµ,i and Pσ,i + Λσ,i
respectively. Hence, there are also equations:
P(|µe
i − µe
A,i|≤ ∆µ,i) = 1 − 2Φ(
−∆µ,i
p
Pµ,i + Λµ,i
),
P(|σe
i − σe
A,i|≤ ∆σ,i) = 1 − 2Φ(
−∆σ,i
p
Pσ,i + Λσ,i
)
(23)
where Φ(x) is the cumulative distribution function of the
standard normal distribution. Hence, after solving Equations.
(22) and (23), ∆µ,i and ∆σ,i can be obtained:
∆µ,i = −Φ−1((1 − δµ)/2)
p
Pµ,i + Λµ,i,
∆σ,i = −Φ−1((1 − δσ)/2)
p
Pσ,i + Λσ,i
(24)
42
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

0
50
100
150
200
250
300
350
400
450
500
80
85
90
95
100
105
110
115
120
 
 
Real value
Obtained value
Estimate value
Fig. 1.
The real, estimate and obtained values
C. Calculation Algorithm
Deﬁnition 5. Time Domain: Each time a service consumer
invokes a service, it can obtain values of all criteria. Then
it can use the values to estimate real criterion value and the
values are called values of quality criterion at Time Domain.
Because at time domain all values are collected by a service
consumer A itself, it is unnecessary to detect malicious values.
For ratio criteria, it is easy to calculate the values and it is
accurate. For instance, the success rate csr of a service S can
be calculated by the following equations:
If the ith invocation of service S is successful:
numsuccess,i = numsuccess,i−1 + 1
(25)
If the ith invocation of service S fails:
numsuccess,i = numsuccess,i−1
(26)
Finally:
numtotal,i = numtotal,i−1 + 1
(27)
csr = numsuccess,i
numtotal,i
(28)
Each time a service S invoked by a service consumer i, then
i can get values of non-ratio criteria. If exact values of non-
ratio criteria C can be obtained, such as price, then the value
{µe
i, σe
i } can also be calculated by the equations as follows:
µe
i = E[Ci]
(29)
σe
i = E[(Ci − µe
i)2]
(30)
However, exact values of certain non-ratio criteria cannot be
obtained, such as response time. Not only because computer
is a complex dynamic system, but also because of network
delay, it is impossible to get exact response time of a service.
Hence, at this point, the method of criterion value estimation
in Section IV is used to obtain the estimate value {µe
i, σe
i }.
Deﬁnition 6. Aggregation Domain: Each service consumer
can collect criterion values of various services from numerous
service consumers. Further these values can be aggregated
by this service consumer to estimate real criterion value too,
although some of these values may be malicious. These values
are called values of quality criterion at Aggregation Domain.
At aggregation domain, values of all criteria including
ratio criteria and non-ratio criteria are estimated by using
the method of criterion value estimation in Section IV, not
only because malicious values need to be ﬁltered out, but also
because all these values may not be accurate due to incomplete
knowledge on service providers.
Assume a consumer A is going to aggregate all values
from others to calculate the trust in a quality criterion C of a
service S provided by service provider P. Then each step after
estimating the value of C by the use of the value provided by
other service consumer X, the trust in C is calculated using
the method presented in Section III-A. When A use this value
to estimate the trust in P.S.C, the trust in other consumer
X calculated by the use of the method introduced in Section
III-B is used to weight the trust in a service provider from
that consumer X . Furthermore, second hand values are also
aggregated using the approach presented in Section III-C.
V. PERFORMANCE EVALUATION
In this section, this trust model is evaluated in a simulated
environment. The model is validated ﬁrst, and then another
experiment is carried out to evaluate the robustness of this
model, compared to some other approaches.
The ﬁrst experiment is carried out in a clean environment
without malicious values in order to validate the model. The
value of a QoS criterion C is estimated and the accuracy of the
value estimation is evaluated each step. One result calculated
by our model is shown in Fig.1. The dashed line represents C’s
real values, while the obtained value with noise is denoted by
the stars. The real line represents the values estimated by our
model. It is seen that in this experiment the obtained values
43
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

10
15
20
25
30
35
40
0.4
0.5
0.6
0.7
0.8
0.9
1
Malicious Service Party Rate (%)
True Malicious Service Party Rate
 
 
KM
Bayesian
EWMA
Fig. 2.
Average true malicious rate
are not accurate, but C’s values are still being estimated well,
which is closer to the real values than the obtained values.
In order to evaluate the robustness of this model, another
experiment is carried out in an environment with malicious
values. Our approach is compared with the methods in [9],
[13], respectively represented by EWMA and Bayesian, to
evaluate the robustness of malicious value detection. Because
it is almost impossible that more than a half of all service
consumers within an environment behaviour maliciously and
it is impossible to perform well in an environment with more
than 50% malicious service consumers, the probability of
malicious service consumers is set up to 40%.
Deﬁnition 7. True Malicious Rate: The percentage of cor-
rectly detected malicious service consumers.
The number of malicious values and correctly detected
malicious ones are denoted by numm and numc respectively,
and true malicious rate is calculated by numc
numm
.
Deﬁnition 8. False Malicious Rate: The percentage of
wrongly detected non-malicious service consumers.
The number of all non-malicious and wrongly detected ma-
licious values are denoted by numnon and numw respectively,
and then false malicious rate is calculated by
numw
numnon
.
As shown in Figs. 2 and 3, as the increase of the malicious
service consumer probability, our model performs better than
those two approaches. Hence, the accuracy of those approaches
is lower than ours.
VI. CONCLUSION
Trust in Quality of Service of service providers is really
important for service consumers to select services. In this
paper, a model using Kalman Filter to ﬁlter out malicious
values was introduced. First, QoS criteria were classiﬁed into
several groups on the basis of their characteristics. Then a
model to estimate the trust in quality criterion was presented,
not only based on the trust in service providers but also on
the basis of the trust in service consumers, which signiﬁcantly
10
15
20
25
30
35
40
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Malicious Service Party Rate (%)
False Malicious Service Party Rate
 
 
KM
Bayesian
EWMA
Fig. 3.
Average false malicious rate
helped reduce the inﬂuence of dishonest service consumers.
The trust calculation processes were classiﬁed into two groups,
including Time and Aggregation Domain. At time domain,
a service consumer uses the values obtained by itself while
at aggregation domain, a service consumer to calculate the
value of trust in a service provider by the use of values from
other service consumers, which may be malicious. Hence, at
aggregation domain, a method based on Kalman Filter was
presented to ﬁlter out malicious values and the trust in other
consumer X was used to weight the data from X. Finally, our
model was evaluated by two experiments and the results shown
that a more accurate value estimation can be made, with better
detection accuracy, compared with two other approaches.
Although our model works well, a large amount of historic
estimation needs to be stored and it needs lots of calculation.
Hence, further research will be carried out to reduce the need
of storing historic estimation and calculation.
ACKNOWLEDGMENT
This work is partly supported by British Telecommunica-
tions Research. The authors would like to thank Keith Briggs,
Michael Fitch, Santosh Kawade, etc.
REFERENCES
[1] S. R. Yan, X. L. Zheng, D. R. Chen, and W. Y. Zhang, “User-centric
trust and reputation model for personal and trusted service selection,”
International Journal of Intelligent Systems, vol. 26, no. 8, 2011, pp.
687–717.
[2] S. D. Kamvar, M. T. Schlosser, and H. Garcia-Molina, “The eigentrust
algorithm for reputation management in p2p networks,” in Proceedings
of the 12th International Conference on World Wide Web, 2003, pp.
640–651.
[3] Z. Yan and H. Silke, “Trust modeling and management: From social
trust to digital trust,” in Computer Security, Privacy and Politics: Current
Issues, Challenges and Solutions, 2008, pp. 290–323.
[4] K. Hoffman, D. Zage, and C. Nita-Rotaru, “A survey of attack and
defense techniques for reputation systems,” ACM Compute Survey,
vol. 42, no. 1, 2009, pp. 1:1–1:31.
[5] Y. Wang and K.-J. Lin, “Reputation-oriented trustworthy computing in
e-commerce environments,” Internet Computing, IEEE, vol. 12, no. 4,
2008, pp. 55–59.
[6] A. Jøsang, R. Ismail, and C. Boyd, “A survey of trust and reputation
systems for online service provision,” Decision Support System, vol. 43,
no. 2, 2007, pp. 618–644.
44
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

[7] D. Ardagna and B. Pernici, “Adaptive service composition in ﬂexible
processes,” Software Engineering, IEEE Transactions on, vol. 33, no. 6,
2007, pp. 369–384.
[8] Y. H. Wang and M. P. Singh, “Trust Representation and Aggregation in
a Distributed Agent System,” in Proceeding of National Conference on
Artiﬁcial Intelligence, 2006, pp. 1425–1430.
[9] Y. C. Zhang and Y. G. Fang, “A ﬁne-grained reputation system for reli-
able service selection in peer-to-peer networks,” Parallel and Distributed
Systems, IEEE Transactions on, vol. 18, no. 8, 2007, pp. 1134–1145.
[10] A. Whitby, A. Josang, and J. Indulska, “Filtering out unfair ratings in
bayesian reputation systems,” in Proceeding of the International Joint
Conference on Autonomous Agenst Systems, 2004, pp. 106–117.
[11] S. Buchegger and J.-Y. Le Boudec, “A robust reputation system for
peer-to-peer and mobile ad-hoc networks,” in Proceedings of the Second
Workshop Economics of P2P Systems, 2004, pp. 1–6.
[12] X. F. Wang, L. Liu, and J. S. Su, “Rlm: A general model for trust
representation and aggregation,” Services Computing, IEEE Transactions
on, vol. 5, no. 1, 2012, pp. 131–143.
[13] W. Conner, I. Rouvellou, A. Iyengar, K. Nahrstedt, and T. Mikalsen,
“A trust management framework for service-oriented environments,” in
International World Wide Web Conference, 2009, pp. 891–900.
[14] L. Xiong and L. Liu, “Peertrust: supporting reputation-based trust for
peer-to-peer electronic communities,” Knowledge and Data Engineering,
IEEE Transactions on, vol. 16, no. 7, 2004, pp. 843 – 857.
[15] M. Srivatsa, L. Xiong, and L. Liu, “Trustguard: countering vulnerabil-
ities in reputation management for decentralized overlay networks,” in
Proceedings of the 14th international conference on World Wide Web,
2005, pp. 422–431.
[16] R. E. Kalman “A New Approach to Linear Filtering and Prediction
Problems,” Transaction of the ASME-Journal of Basic Engineering,
vol. 82, 1960, pp. 35-45.
45
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-270-7
SERVICE COMPUTATION 2013 : The Fifth International Conferences on Advanced Service Computing

