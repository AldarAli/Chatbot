Indoor Source Localization Using 2D Multi-Sensor Based
Spatial Spectrum Fusion Algorithm
Taha Bouras1, Di He1, Wenxian Yu1, Yi Zhang2
1Shanghai Key Laboratory of Navigation and Location-based Services,
Shanghai Jiao Tong University
Shanghai, P.R. China
E-mail: {tahatox, dihe, wxyu }@sjtu.edu.cn
2.Huawei Technologies Co. Ltd.
Shanghai, P.R. China
E-mail: aaabear@huawei.com
Abstract— In a starving indoor environment where non-line of
sight (NLOS) signals are strongly dominant, localization using
traditional spatial spectrum estimation techniques easily fails due
to low signal to noise ratio (SNR). Accordingly, in this paper, a
novel
2-D
multi-sensor Spatial
Spectrum Fusion (2D-SSF)
localization algorithm based on the multiple signal classification
(MUSIC) method is proposed. The output data of each uniform
rectangular array (URA) at each access point (AP) are first
processed to get the noise subspace data. Then, after estimating
the corresponding azimuth and elevation angles of each array
using the MUSIC approach and finding the position of each point
relative to each sensor in the search grid with the help of grid
refinement algorithm, the parameters of interest of the target are
estimated from a single spectrum that results from fusing all
maximum noise subspaces where the position corresponding to
the minimum error between the set of angles and every estimated
point in the searching area is situated. Different simulation
results of the proposed method in terms of RMSE as a function of
SNR for various APs LOS/NLOS scenarios, the change in the
number of antennas at each AP and the comparison with the
MUSIC approach and the 1D localization based spatial spectrum
fusion algorithm are carried out. The obtained results prove the
significant performance of the proposed 2D-SSF localization
algorithm with the strong presence of NLOS signals.
Keywords—2-D Localization; Multi-Sensor; Spatial Spectrum
Estimation Techniques; Data Fusion.
I.
INTRODUCTION
In recent decades, the use of multi-sensor data fusion [1]
for the purpose of localization has become a fundamental
problem in modern signal processing and it has found wide
applications in radar, sonar, wireless communications and
acoustics [2][3].
In general, the localization of sources using multiple
stations based spatial spectrum information at known locations
is achieved by first exploiting the spatial information at each
base station in order to estimate the direction of arrival (DOA)
of the sources by employing an efficient direction finding (DF)
estimator algorithm, such as the well-known Multiple signal
classification (MUSIC) algorithm [4] .Then, the set of data
(DOAs) will be sent to the fusion center where the positions of
the sources are determined based on the appropriate approach
in the fusion decision center like triangulation (e.g., as used in
[5] and [6]) or other techniques that have been proposed in the
literature [7].
However, in rush indoor environment, the propagation of
the source signal is strongly attenuated by reflection when it
hits the surface of an obstacle, which results in the high
existence of NLOS signals arriving at the receiver through
different paths. This multipath effect is even more severe
where a ceiling, equipment, floor, and walls are present. Thus,
the performance of the localization methods mentioned before
is degraded under such starving environment with low SNR.
To overcome this problem, different methods have been
proposed in the literature. In [8], the author proposed the use of
the nonlinear PSO optimization algorithm to find the position
of the target after the fusion process for a single moving array.
A hybrid localization approaches with data fusion, like the
employment of TOA/TDOA in [9]. There has also been
comprehensive research work centering on fusion frameworks
that rely on heterogeneous information, such as the proposed
“MapSentinel” tracking system, which performs non-intrusive
location sensing based on WiFi access points and ultrasonic
sensors [10]. A system that exploits the acoustic properties of
the room named as “SoundLoc” in [11] and indoor CO2
concentration based on the sensing by proxy methodology
[12].
But, according to many previous types of research that rely
on WiFi wireless network based indoor localization, to
simplify the research conditions, such as time consumption and
computation complexity, the arrays at the receiver sides were
considered to be uniform linear array (ULA) geometry, which
reduces the accuracy of the localization problem certainly in
very low SNR.
In this paper, 2-D multi-sensor Spatial Spectrum Fusion
(2D-SSF) localization algorithm based on WIFI signals is used
for indoor localization. In the proposed work, the subspace-
based MUSIC algorithm is used to estimate the azimuth and
elevation angles at each URA array at the receiver side. Then,
79
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

depending on known search grid dimension, 2D spectrum
fusion process at the fusion center is used to estimate the
DOAs or the coordinates of the target position.
The remainder of this paper is organized as follows: In
Section II, we present the data model and we formulate the
main problem. The proposed 2D spatial spectrum fusion
algorithm is demonstrated in Section III. Thereafter, in Section
IV, different simulation results of the RMSE of the proposed
method as a function of SNR are carried out for various APs
LOS/NLOS scenarios, the change in the number of antennas at
each AP and the comparison with the MUSIC approach and
the 1D localization based spatial spectrum fusion algorithm
used in [13]. The paper is concluded in Section V.
II.
DATA MODEL AND PROBLEM FORMULATION
Consider an indoor environment composed of P Access
point (AP) each has URA geometry with M= ܰ௫ × ܰ௬ number
of antennas impinged by Q multi-path source signal in the far
field of the antenna array, see Figure 1. Suppose that the
direction of the waves is F and Ɵ. Then, the received signal at
the p-th AP, with p = 1,…,P is given by:
X୮(t) =
A୮(F, Ɵ)S(t) + N୮(t)
(1)
Also is equal to
X୮(t) = a୮൫F୮, Ɵ୮൯ ∗ S୮(t) +
෍ g୩(t) a୮(F୩, Ɵ୩)
୕
୩ୀଵ
S୮(t − t୩) + N୮(t)
(2)
Where;
S(t)
is
the
source
signal, g୩(t) = a୩ eି୨ଶ஠୤ౙtౡ.
a୩ , fୡ, t୩ , F୩, Ɵ୩ , F୮, Ɵ୮
are the correlation coefficient,
carrier frequency, delay of travel time, azimuth and elevation
angles of the k-th multipath signal with k = 1, 2,…,
Q,
azimuth
and
elevation
angles
of the
direct
signal
respectively. N(t) is white Gaussian additive noise with mean
0 and variance sଶ . a୮(F, Ɵ) ∈  ₵୑×୔ is the steering vector of
the URA at each receiver point. We can observe from (2) that
the received signal at each array consists of direct path signals
and multipath signals. So, the transfer vector corresponding to
the LOS signal at the p-th array is equal to:
a୮൫F୮, Ɵ୮൯ = ቂ1 e୨మಘ
l ∆(౦,మ) e୨మಘ
l ∆(౦,య) … … … e୨మಘ
l ∆(ౌ,౉షభ) ቃ
୘
(3)
Here, (. )୘ denotes the transpose operator, where the inter-
element delay ∆(୮,୫) is given by:
                     ∆(୮,୫)= e୨ మಘ
l (୫ିଵ) ୢ౮ ୱ୧୬(Ɵ౦) ୡ୭ୱ(F౦) +
e୨ మಘ
l (୫ିଵ) ୢ౯ ୱ୧୬(Ɵ౦) ୱ୧୬(F౦)
(4)
In general, the steering matrix corresponding to the direct
path signals can be expressed as:
Figure 1.
2D-Multi-sensor spatial spectrum fusion target localization in an
indoor environment.
Aୱ(F, Ɵ) = [aଵ(Fଵ, Ɵଵ) aଶ(Fଶ, Ɵଶ)…… … a୮൫F୮, Ɵ୮൯]
(5)
However, for simplicity, we can obtain the steering matrix
corresponding to the NLOS signals from [14].
Our task is to estimate the position of the target p using the
spatial
spectrum
fusion
(SSF)
approach
starting
from
estimating the azimuth and elevation of each URA, i.e., two-
dimensional search, based on the observations obtained from
(2) under an environment mixed with LOS and NLOS signals.
It can be briefly demonstrated in Figure 1.
III.
LOCALIZATION ALGORITHM
A. Spatial spectrum estimation for every array
A.1 Construct the covariance matrix
The first step is to construct the covariance matrix of the
received spatial data at each array and then decompose it into
signal and noise subspaces. At a certain array p, the
covariance matrix of the observed data X୮(t) can be expressed
as:
Rଡ଼౦ = 1
L X୮(t)X୮
ୌ(t)  ∈  ₵୑×୑
(6)
= U୮å୮U୮
ୌ = [U୮
(ୱ)U୮
(୬)] å୮[U୮
(ୱ)U୮
(୬)]ୌ
(7)
Here, (. )ୌsymbolizes to the Hermitian Transpose.
U୮
(ୱ) ∈  ₵୑×ଵ denotes the eigenvector spanning the signal
subspace.
U୮
(୬) ∈  ₵୑×୑ିଵdenotes the eigenvector spanning the noise
subspace.
80
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

å୮ ∈  ₵୑×୑ is a diagonal matrix containing the decreasing
order of the associated eigenvalues.
A.2 MUSIC algorithm
After
obtaining
the
covariance
matrix,
DOA
based
subspace estimation method is used to estimate the spatial
spectrum of each array. Here, we use the MUSIC algorithm
due to its reliable performance compared to the traditional
spatial spectrum estimation algorithms certainly in low SNR
[15]. The power spectrum of the MUSIC algorithm is given
by:
P୮(F, Ɵ) =
1
norm [Aୌ(F, Ɵ) U୮
(୬)]
(8)
The used MUSIC algorithm explores the searching area
(-π < F <ߨ) and (0< Ɵ < π)
to look around the spectrum
peak of (8) where the azimuth and elevation of each URA is
located.
B. Spatial spectrum fusion
B.1 Calculate the set of angles of each position p in the
search grid
Before starting the data fusion procedure, the fusion center
needs to know the position of each point relative to each
sensor in the search grid. The search grid is set to vary
between (x୥బ, y୥బ, z୥బ) and (x୥౜, y୥౜, z୥౜). Assuming that the
reference AP is placed in the position G଴(x଴, y଴, z଴) where the
p-th sensor array coordinates is G୮(x୮, y୮, z୮) proportional to
the reference sensor in the search grid. The set of each angle
in the whole scanning grid corresponding to each array can be
calculated as follows:
for i=x୥బ: x୥౜
for j=y୥బ: y୥౜
for l=z୥బ: z୥౜
ݏ݁ݐ_F୮ = arctan
y୨ − y୮
x୧ − x୮
(9)
ݏ݁ݐ_Ɵ୮ =
arccos z୪ − z୮
Drp
(10)
Drp = ට(x୧ − x୮)2+(y୨ − y୮)2 + (z୪ − z୮)2
(11)
end
end
end
Where Drp is the distance between the p-th sensor and the i-th
position of the grid.
B.2 Spectrum Fusion
From (9) and (10), we can observe that the set of angles
ݏ݁ݐ_F୮ andݏ݁ݐ_Ɵ୮ represents matrices that contain the
azimuth and elevation angles for all possible points in the
search grid corresponding to the position of each AP.
Now, the target position estimating problem comes down to
find the maximum of the spectrum, which is a combination of
spatial spectrums of (8) (Pଵ(݌), Pଶ(݌), … , P୔(݌)), where the
position coinciding to the minimum error between each
estimated point in the search grid and every angle in the
searching area (-π <ߩ<ߨ) is situated.
The
target
position
estimation
can
be
expressed
by
the following formula:
݌௧௔௥௚௘௧೐ೞ೟
= arg max
௣
ቐarg min
௣ ቌ෍ P୮ ቀ ܲ௘௥௥F౦, ܲ௘௥௥Ɵ౦ቁ
୔
୮ୀଵ
ቍቑ
(12)
ܲ௘௥௥F౦ = abs ቀݏ݁ݐF୮ − Fఘቁ ≤ ε                         (13)
ܲ௘௥௥Ɵ౦ = abs ቀݏ݁ݐƟ୮ − Ɵఘቁ ≤ ε                          (14)
Where ܲ௘௥௥F౦ and ܲ௘௥௥Ɵ౦ are the errors between each set
position and every azimuth and elevation angles respectively
in the searching area. ε is the threshold. The 2D-SSF can be
generalized along the lines shown in Figure 2.
Figure 2.
The 2D-SSF procedures needed for target positioning.
IV.
SIMULATION RESULTS AND DISCUSSION
We consider an indoor environment with dimensions
length=20m, width=20m and height=20m contain four APs
such that each consists of 4 antenna arrays with half
wavelength distance and uniform rectangular geometry is
placed
inside.
The
reference
sensor
is
positioned
at
Aଵ(0,0,0) whereas
the
remaining
three
sensors
placed
at Aଶ(20,0,0), Aଷ(0,20,0) and Aସ(20,20,20).The position of
1.
Compute the covariance matrix of the observed spatial
output data at each sensor using (6).
2.
Decompose (1) into signal and noise subspaces using
(7).
3.
Use MUSIC algorithm in (8) to get the azimuth and
elevation angles of each array.
4.
Calculate the set of each position p in the search grid.
for i=࢞ࢍ૙:࢞ࢍࢌ
for j=࢟ࢍ૙:࢟ࢍࢌ
for l=ࢠࢍ૙:ࢠࢍࢌ
࢙ࢋ࢚_F࢖ =ࢁ࢙ࢋ(ૢ)
࢙ࢋ࢚_Ɵ࢖ =ࢁ࢙ࢋ(૚૙)
࢝࢏࢚ࢎ D࢘࢖ ࢏࢔ (૚૚)
end
end
end
5.
Transfer the obtained data to the fusion center and
compute the minimum errors between each set position
and every azimuth and elevation angles respectively in the
searching area using (13) and (14).
6.
Get the position of the target using (12).
81
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

the target is P (11, 20, 5) and the number of multipath signals
Q= 6. Some obstacles are taken to be placed in the middle of
the AP and the target such that no LOS signal exists whereas
the others are placed away from the middle. SNR = 5 dB and
the sample number is set to be 200 samples. All simulation
results obtained using MATLAB R2015a.
Firstly, we consider the case where all APs are able to see
the target directly, i.e., the LOS signal between the source
signal and each array exists. From Figure 3, the resulting
angles (F, Ɵ)  of each array are (76.6̊, 60.8̊), (-3.2̊, 23̊.4),         
(-51.8̊, 66.4̊) and (-0.4̊, 120.8̊). Compared with the actual
angles in Figure 3, the highest error difference between the
azimuth ones is in array 2 (about 3 degrees difference)
whereas almost 1 degrees error difference in elevation
corresponding to array1 and this can improve the additional
support of the
elevation angle for more target position
estimation accuracy during the application of the fusion
process.
Figure 4 presents spectrums resulted from the fusion of the
spatial spectra of Figure 3. The maximum values of the
obtained spectra represent the estimated position of the source
signal. From the left side of Figure 4, we can observe that the
obtained horizontal coordinates are 10.4 m and 19.4 m while
the vertical position (height) of the target is 5.2 m
Figure 3.
Music spectrums for the four arrays, SNR=5 dB, N=4 antennas.
Figure 4.
The estimated (x,y,z) coordinates of the target position using the
2D-SSF method. SNR=5 dB, N=4 antennas.
according to the right part of Figure 4. Compared to the actual
location of the source (11, 20, and 5) m, the location
estimation error is reliable thus can prove the important
localization accuracy achievement of the 2D-SSF algorithm
certainly in Low SNR.
Now we examine the performance of the 2D-SSF in terms
of root mean square error (RMSE) in different LOS and
NLOS scenarios (Figure 5). 50 Monte Carlo simulations were
carried out. We observe that the RMSE decreases with the
increasing number of the LOS APs. For low SNR (-10 dB) the
RMSE of the 5 cases varies between 2 and 2.5 meters whereas
in high SNR (20 dB) the localization performance improved
until 0.1373 m error when the LOS signals can be seen by the
whole APS whilst the difference gap between the first and the
last case is still reliable (almost 1 meter). When a group of
arrays is disorganized with the NLOS signals, the aid of the
Aps, which consider the LOS signal is used, we can remark
that for the cases of 1AP LOS, 2AP LOS and 3AP LOS with
RMSE below than 1 meter and this gives an important point in
real applications when a couple of WiFi systems are blocked
with massive obstacles, so the placement of the APS should be
reliable such that the chance of the LOS signal between the
WiFi systems and the user would be dominant.
In order to compare the performance of the 2D-SSF with
the traditional approaches, we test the estimation of angles
relative to each antenna arrays by using the classical MUSIC
algorithm and the 2D-SSF algorithm in terms of RMSE. We
consider the case where the target is able to be seen by 2 APs.
According to Figure 6, it is obvious that the advocated method
outperforms the MUSIC algorithm. From SNR= -10dB to
SNR= 20 dB, the RMSE for 2D-SSF decreases slightly and
tend to 0 dB in very high SNR while although the SNR is high
the MUSIC method cannot give reliable angles estimation for
both azimuth and elevation (about 3° error) and this is due to
the NLOS environment. Moreover, the error estimation for
angles of the 2D-SSF in low SNR (2.5̊, 2.1̊) is even better than 
.
Figure 5.
RMSE (distance) for different APs LOS/NLOS scenarios using
the 2D-SSF method.
82
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

Figure 6. Angles (azimuth and elevation) estimation comparison between
MUSIC and the 2D-SSF method.
the estimation of the MUSIC in High SNR (3.4̊, 3.1̊).  
The
outperformance
of
the
advocated
method
is
represented in the usage of multi-sensor in addition of that the
estimation of the elevation angles of each array that enhance
the accuracy of the location of the sensor, hence, the target
position.
Here, the performance of the 2D-SSF approach is tested
according to the change in the number of antennas at the
sensors. The same situation for the target and the sensors is
taken as before. It is evident from Figure 7 that the increase in
the number of antennas at each AP gives a significant
enhancement for the target localization. At SNR=-10 dB there
is a considerable decrease in the estimated distance error from
2.3 meters using 4 antennas to 0.7 meters using 16 antennas
While the RMSE for using 16 antennas tends to 0 meters at
high SNR.
Figure 7.
RMSE (distance) for a different number of antennas at each sensor
using the 2D-SSF method.
Figure 8.
Comparison between ULA based fusion method [13] and the 2D-
SSF localization method.
In the final part, the 2D-SSF is compared with the 1-D
localization algorithm based fusion method used in [10]. We
use the same parameters for the two algorithms during the
source location estimation process. According to Figure 8, the
change in the geometry of antennas to the 2-D array at each
AP results in considerable enhancement of the error difference
between the RMSE of the two used algorithms such that in
SNR=-10 dB the difference error between the two curves is
about 56 centimeters. However, the performance of the two
methods attends to be the same as the SNR is higher,
obviously, when SNR=10 dB the difference in error reaches
20 centimeters.
V.
CONCLUSION
In this paper, 2D multiple sensors based on spatial
spectrum fusion estimation algorithm was investigated. Under
an indoor environment, the use of multiple sensors with the
proposed fusion method in addition of that the change in the
geometry of the antennas to URA at each sensor gave a
significant improvement in source localization. Simulation
results showed that the performance of the 2D-SSF method
can be changed according to the used number of antennas at
each sensor, the placement of the APs in the monitoring area,
and
the
selected
SNR.
Moreover,
the
considerable
outperformance of the 2D-SSF compared with traditional and
1-D based source localization methods has been proved.
As future work, the proposed algorithm will be implied to
the real environments along with real data and extra massive
obstacles, which can lead to the elimination of most LOS
signals. Also, the modification of the 2D-SSF might be done
by considering the Time of Arrive (TOA) based localization
approach for more positioning accuracy.
83
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

ACKNOWLEDGMENT
This research work is supported by the Important National
Science and Technology Specific Project of China under
Grant No. 2016ZX03001022-006, the Shanghai Science and
Technology Committee under Grant No. 16DZ1100402, and
the National Natural Science Foundation of China under Grant
No. 91438113.
REFERENCES
[1]
D. L. Hall and J. Llinas, “An introduction to multisensor data
fusion,” Proceedings of the IEEE, vol. 85, no. 1, pp. 6–23, 1997.
[2]
J. Prieto and A. Bahillo, “Adaptive Data Fusion for Wireless
Localization in Harsh Environments,” IEEE Transactions on
Signal Processing. vol. 16, no.04, pp. 1585 - 1596., April 2012.
[3]
G. Mirzaei, M. M. Jamali, and J. Ross, “Data Fusion of
Acoustics, Infrared, and Marine Radar for Avian Study,” IEEE
Sensors Journal. vol. 15, no.11, pp. 6625 - 6632., Nov. 2015.
[4]
R. O. Schmidt, “Multiple emitter location and signal parameter
estimation,” IEEE Trans. on Antenna Propagation, vol. 34, no.
3,March 1986, pp. 276-280.
[5]
J. Caffery and G. Stuber, “Overview of Radiolocation in CDMA
cellular systems,” IEEE Commun. Mag., vol. 36, pp. 38–45,
Apr.1998.
[6]
J. I. Xiu, Y. He, and G. H. Wang, “Constellation of Multi-
sensors in Bearing-only Location System,” Radar, Sonar and
Navigation, lEE Proceedings, Vol. 152, No.3, pp.215-218, 2005.
[7]
F. Gustafsson and F. Gunnarsson, “Mobile positioning using
wireless networks: Possibilities and fundamental limitations
based on available wireless network measurements,” IEEE
Signal Process. Mag., vol.22, pp 41–53, July 2005.
[8]
Z. Huang and J. Wu, “Multi-Array Data Fusion Based Direct
Position Determination Algorithm,” 2014 Seventh International
Symposium on Computational Intelligence and Design.pp.121-
124. China. 2014.
[9]
R. Reza, “Data fusion for improved TOA/TDOA position
determination in wireless systems,” Ph.D. dissertation, Virginia
Tech., Blacksburg, VA, 2000.
[10] R. Jia, et al., “MapSentinel: Can the Knowledge of Space Use
Improve Indoor Tracking Further?, ”, Sensors 2016, 16, 472.
[11] R Jia, M. Jin, Z. Chen and C.J. Spanos, “SoundLoc: Accurate
Room-level Indoor Localization using Acoustic Signatures,”
2015 IEEE International Conference on Automation Science
and Engineering (CASE). Gothenburg, Sweden, pp. 186 – 193.
[12] M. Jin, N. Bekiaris-Liberis, K. Weekly, C. Spanos and A.
Bayen, “Sensing by Proxy: Occupancy Detection Based on
Indoor CO2 Concentration,” The 9th International Conference
on Mobile Ubiquitous Computing, Systems, Services and
Technologies (UBICOMM'15), July 2015, pp. 1-10, ISSN:
2308-4278, ISBN: 978-1-61208-418-3
[13] M. K. Choudhary et al., “DOA Estimation And Localization
Using Multi-Base Station Spatial Spectrum Fusion,” ION
GNSS+, 2017. Manuscript in press.
[14] Mohammad Sajjadieh and Amir Asif,
“Uniform Rectangular
Time
Reversal
Arrays:
Joint
Azimuth
And
Elevation
Estimation,”
IEEE,
2012,
Statistical
Signal
Processing
Workshop (SSP). Ann Arbor, MI, USA, pp. 89-92, 2012.
[15] X. Wang and H. Wang, '' Study on Data Fusion Technology in
the Field of Spatial Signal Processing,” International Conference
on Electronics, Communications, and Control (ICECC), Ningbo,
China, pp. 4531 – 4533, 2011.
84
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

