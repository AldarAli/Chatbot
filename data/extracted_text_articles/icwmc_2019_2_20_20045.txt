Partial-Diffusion Least Mean-Square Estimation Over Networks Under Noisy 
Information Exchange 
 
Wael M. Bazzi 
Electrical Engineering Department 
American University in Dubai 
Dubai, UAE 
Email: wbazzi@aud.edu 
Vahid Vadidpour, Amir Rastegarnia, Azam Khalili 
Department of Electrical Engineering 
Malayer University 
Malayer, Iran, 65719-95863 
 
 
Abstractâ€” Partial diffusion scheme is an effective method for 
reducing computational load and power consumption in 
adaptive 
network 
implementation. 
The Information 
is 
exchanged among the nodes, usually over noisy links. In this 
paper, we consider a general version of Partial-Diffusion 
Least-Mean-Square (PDLMS) algorithm in the presence of 
various sources of imperfect information exchanges. Like the 
established PDLMS, we consider two different schemes to 
select the entries, sequential and stochastic, for transmission at 
each iteration. Our objective is to analyze the aggregate effect 
of these perturbations on general PDLMS strategies. 
Simulation results demonstrate that considering noisy link 
assumption adds a new complexity to the related optimization 
problem and the trade-off between communication cost and 
estimation performance in comparison to ideal case becomes 
unbalanced. Our simulation results substantiate the effect of 
noisy links on PDLMS algorithm and verify the theoretical 
analysis. 
Keywords- adaptive networks; diffusion adaptation; noisy 
informatin exchange; partial diffusion; sequential, stochastic. 
I. 
 INTRODUCTION 
Due to limited electrical power and bandwidth resources 
for inter-node communication over a practical Wireless 
Sensor Networks (WSN) or ad hoc networks, data 
transmission through radio communication links can become 
prohibitively expensive for realizing a collaborative task. 
Generally speaking, although benefits of diffusion strategies 
achieved by increasing inter-node communications, they are 
compromised by the communication cost. As a result, since 
various nodes can have various numbers of neighbors, they 
may require disparate hardware or consume power 
dissimilarity [1]â€“[4]. Therefore, reducing the communication 
cost while maintaining the benefits of cooperation is of 
practical importance. 
There have been several attempts to reduce the 
communication cost without considerable degradation of the 
estimation and compromising the cooperation benefits in 
diffusion algorithms. Among them diffusion least mean-
square (LMS), such as reducing the dimension of the 
estimates [5]â€“[7], selecting a subset of the entries of the 
estimates [1] [2] [8] [9], set-membership filtering [10][11], 
or partial updating [12] have been reported in [13]â€“[15]. 
Among these methods, we focus on [1] which LMS 
algorithm for adaptive distribute estimation has been 
formulated and analyzed by utilizing partial-diffusion. In [1], 
an adapt-then-combine (ATC) Partial-Diffusion Least-Mean-
Square (PDLMS) algorithm is proposed for distributed 
estimation over adaptive networks in which, at each iteration, 
each node transmits a subsets of the entries of intermediate 
estimate vector to its neighbors. 
In the PDLMS strategy proposed in [1], the weight 
estimates that are exchanged among the nodes can be subject 
to perturbations over communication links. The effect of link 
noise during the exchange of weight estimates, already 
appear for the diffusion algorithm in the works [16]â€“[20]. It 
should be noted that since our objective is to minimize the 
inter-node communications, the nodes only exchange their 
intermediate estimates with their neighbors. Therefore, we 
allow for noisy exchange just during the two combination 
steps.  We subsequently study the performance of this 
general case utilizing the energy conservation argument. We 
established its stability and convergence in the mean and 
mean-square senses. We also derive a theoretical expression 
for the steady-state Mean-Square-Deviation (MSD) and 
verify its accuracy via numerical simulations.  
The main contributions in this paper include: 
â€¢ Focusing on [1] which involves transmission of a 
subset of entries of the inter-node estimate vectors 
named partial diffusion, we provide a more general 
algorithmic structure of which [1] is just a special 
case. To achieve this, we consider the fact that the 
weight estimates exchanged among the nodes can be 
subject to quantization errors and additive noise over 
communication links. We also consider two different 
schemes for selecting the weight vector entries for 
transmission at each iteration. We allow for noisy 
exchange during the two combination steps only. It 
should be noted that since our objective is to 
minimize the inter-node communication, the nodes 
only exchange their intermediate estimates with their 
neighbors; 
â€¢ 
Using the energy conservation argument [21] we 
analyze the stability of algorithms in mean and 
mean square senses under certain statistical 
conditions.  
â€¢ 
We 
illustrate 
the 
comparable 
convergence 
performance of PDLMS algorithm with noisy links 
using different numerical examples. 
This paper is organized as follows. In Section II, we 
formulate the PDLMS under noisy information exchange. 
The performance analyses are examined in Section III. We 
Email: {vahidpour, rastegarnia, khalili}@malayeru.ac.ir 
19
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

provide simulation results in Section IV and draw 
conclusions in Section V. 
A. Notation 
We adopt the lowercase letters to denote vectors, 
uppercase letter for matrices, normal font for nonrandom 
(deterministic) quantities, and the boldface letters for random 
quantities. 
The 
notation 
(. )âˆ—
 refers 
to 
conjugate 
transposition, ğ‘‡ğ‘Ÿ(. ) refer to the trace of its matrix argument, 
â¨‚ for the Kronecker product, and ğ‘£ğ‘’ğ‘(. ) for a vector formed 
by stacking the columns of its matrix argument. We shall 
also use ğ‘ğ‘œğ‘™(â€¦ )  to denote a column vector formed by 
stacking its arguments on top of each other and ğ‘‘ğ‘–ğ‘ğ‘”(. . . ) to 
denote a (block) diagonal matrix formed from its argument. 
All vectors in our treatment are column vectors, with the 
exception of regression vectors, ğ’–à¯,à¯œ. 
II. 
PARTIAL DIFFUSION ALGORITHMS WITH IMPERFECT 
INFORMATION EXCHANGE 
Consider a connected network consisting of ğ‘ nodes. At 
time instant ğ‘– â‰¥  0 , each node ğ‘˜  has access to scalar 
measurements ğ’…à¯(ğ‘–) and 1 Ã— ğ‘€ regression data vectors ğ’–à¯,à¯œ. 
The data across all nodes are assumed to be related to an 
unknown ğ‘€ Ã— 1 vector ğ‘¤à¯¢ via linear regression model of the 
form [17]: 
 
ğ’…à¯(ğ‘–) = ğ’–à¯(ğ‘–)ğ‘¤à¯¢ + ğ’—à¯(ğ‘–) 
(1) 
where ğ’—à¯(ğ‘–) denotes the measurement noise with zero mean 
and variance ğœà¯©,à¯
à¬¶  and the vector ğ‘¤à¯¢ refers to the parameter 
of interest. 
We are now interested in solving optimization problems 
of the type: 
 
min
à¯ª âˆ‘
ğ”¼à¸«ğ’…à¯(ğ‘–) âˆ’ ğ’–à¯,à¯œğ’˜à¸«
à¬¶
à¯‡
à¯à­€à¬µ
 
(2) 
The nodes in the network would like to estimate ğ‘¤à¯¢ by 
solving the equation above in adaptive and collaborative 
manners. We review the diffusion adaptation strategies with 
imperfect information exchange below. 
A. Diffusion Adaptation with Imperfect Information 
Exchange 
Consider the following general adaptive diffusion 
strategies with ğ¶ = ğ¼à¯‡ corresponding to the case in which the 
nodes only share the weight estimates for ğ‘– â‰¥ 0 [21]: 
 
ğ“à¯,à¯œ = âˆ‘
à¯Ÿà°¢ğ’©à³– ğ‘à¬µ,à¯Ÿà¯ğ’˜à¯Ÿ,à¯œà¬¿à¬µ
 
(3) 
 
ğà¯,à¯œ = ğ“à¯,à¯œà¬¿à¬µ + ğœ‡à¯ğ’–à¯,à¯œ
âˆ— àµ£ğ’…à¯(ğ‘–) âˆ’ ğ’–à¯,à¯œğ“à¯,à¯œà¬¿à¬µàµ§ 
(4) 
 
ğ’˜à¯,à¯œ = âˆ‘
à¯Ÿà°¢ğ’©à³– ğ‘à¬¶,à¯Ÿà¯ğà¯Ÿ,à¯œ
 
(5) 
The 
scalars 
àµ›ğ‘à¬µ,à¯Ÿà¯, ğ‘à¬¶,à¯Ÿà¯ àµŸ
 are 
non-negative 
real 
coefficients corresponding to the (ğ‘™, ğ‘˜)  entries of ğ‘ Ã— ğ‘ 
combination matrices {ğ´à¬µ, ğ´à¬¶} , respectively. The role of 
these combination matrices is in convergence behavior of the 
diffusion strategy (3)-(5). These coefficients are zero 
whenever node ğ‘™ âˆ‰ ğ’©à¯, where ğ’©à¯ denotes the neighborhood 
of node ğ‘˜ . These matrices are assumed to satisfy the 
conditions: 
 
ğ´à¬µ
à¯ğ•ğ‘µ = ğ•ğ‘µ,           ğ´à¬¶
à¯ğ•ğ‘µ = ğ•ğ‘µ 
(6) 
where the notation ğ• denotes an ğ‘ Ã— 1 column vector with all 
its entries equal to one. 
We model the noisy data received by node ğ‘˜ from its 
neighbor ğ‘™ as follows (see Figure 1): 
 
ğ’˜à¯Ÿà¯,à¯œà¬¿à¬µ = ğ’˜à¯Ÿ,à¯œà¬¿à¬µ + ğ’—à¯Ÿà¯,à¯œà¬¿à¬µ
(ğ’˜)
 
(7) 
 
ğà¯Ÿà¯,à¯œ = ğà¯Ÿ,à¯œ + ğ’—à¯Ÿà¯,à¯œ
(ğ) 
(8) 
where ğ’—à¯Ÿà¯,à¯œà¬¿à¬µ
(à¯ª)
 (ğ‘€ Ã— 1)  and ğ’—à¯Ÿà¯,à¯œ
(à°Ÿ) (ğ‘€ Ã— 1)  are vector noise 
signal. They are temporally white and spatially independent 
random process with zero mean and covariance given by 
á‰„ğ‘…à¯©,à¯Ÿà¯
(à¯ª), ğ‘…à¯©,à¯Ÿà¯
(à°Ÿ)á‰…. The quantities á‰„ğ‘…à¯©,à¯Ÿà¯
(à¯ª), ğ‘…à¯©,à¯Ÿà¯
(à°Ÿ)á‰… are all zero if ğ‘™ âˆ‰
ğ’©à¯ or when ğ‘™ = ğ‘˜. It should be noted that the subscript ğ‘™ğ‘˜ 
indicates that ğ‘™ is the source and ğ‘˜ the sink, the flow of 
information is from ğ‘™ to ğ‘˜. 
Using the perturbed data (7) and (8), the adaptive 
strategy (3)-(5) becomes 
 
ğ“à¯,à¯œ = âˆ‘
à¯Ÿà°¢ğ’©à³– ğ‘à¬µ,à¯Ÿà¯ğ’˜à¯Ÿà¯,à¯œà¬¿à¬µ
 
(9) 
 
ğà¯,à¯œ = ğ“à¯,à¯œà¬¿à¬µ + ğœ‡à¯ğ’–à¯,à¯œ
âˆ— àµ£ğ’…à¯(ğ‘–) âˆ’ ğ’–à¯,à¯œğ“à¯,à¯œà¬¿à¬µàµ§ 
(10) 
 
ğ’˜à¯,à¯œ = âˆ‘
à¯Ÿà°¢ğ’©à³– ğ‘à¬¶,à¯Ÿà¯ğà¯Ÿà¯,à¯œ
 
(11) 
B. Partial-Diffusion with Impeferct Information Exchange  
In order to lower the level of inter-node communication 
required among the nodes, we utilize partial-diffusion 
strategy proposed in [1], to transmit ğ¿ out of ğ‘€ entries of the 
intermediate estimates at each time instant where the integer 
ğ¿  is fixed and pre-specified. Again, we develop a more 
general class of PDLMS of which [1] is a special case. The 
selection of to-be-transmitted entries at node ğ‘˜  and time 
instant ğ‘–  can be portrayed by an ğ‘€ Ã— ğ‘€  diagonal entry-
selection matrix, denoted by ğš²à¯,à¯œ, that has ğ¿ ones and ğ‘€ âˆ’ ğ¿ 
zeros on its diagonal. The position of ones states the selected 
entries. Multiplication of an intermediate estimate vector by 
this matrix replaces its non-selected entries with zero. 
According to (9) and (11) that can also be expressed as: 
 
 
 
(12) 
 
ğà¯,à¯œ = ğ“à¯,à¯œà¬¿à¬µ + ğœ‡à¯ğ’–à¯,à¯œ
âˆ— àµ£ğ’…à¯(ğ‘–) âˆ’ ğ’–à¯,à¯œğ“à¯,à¯œà¬¿à¬µàµ§ 
(13) 
 
 
 
ğ“à¯,à¯œ = ğ‘à¬µ,à¯à¯ğ’˜à¯,à¯œà¬¿à¬µ + âˆ‘
ğ‘à¬µ,à¯Ÿà¯àµ£ğš²à¯Ÿ,à¯œà¬¿à¬µğ’˜à¯Ÿà¯,à¯œà¬¿à¬µ +
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œà¬¿à¬µàµ¯ğ’˜à¯Ÿà¯,à¯œà¬¿à¬µàµ§  
ğ’˜à¯,à¯œ = ğ‘à¬¶,à¯à¯ğà¯,à¯œ + âˆ‘
à¯Ÿà°¢ğ’©à³–âˆ–{à¯} ğ‘à¬¶,à¯Ÿà¯àµ£ğš²à¯Ÿ,à¯œğà¯Ÿà¯,à¯œ +
àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œàµ¯ğà¯Ÿà¯,à¯œàµ§  
20
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

 
l 
k
Source 
ğ’—ğ‘™ğ‘˜,ğ‘–âˆ’1
(ğ’˜)  
ğğ‘™ğ‘˜,ğ‘– 
ğ’˜ğ‘™,ğ‘–âˆ’1 
ğğ‘™,ğ‘– 
ğ’—ğ‘™ğ‘˜,ğ‘–
(ğ) 
ğ’˜ğ‘™ğ‘˜,ğ‘–âˆ’1
Sink
ğ’—ğ‘™(ğ‘–) 
ğ’—ğ‘˜(ğ‘–)
 
 
(14) 
Figure 1.  Several additive nise sources perturb the exchange of 
information from node ğ‘™ to node ğ‘˜. 
Each node needs the information of all entries of its 
neighborsâ€™ intermediate estimate vectors for the consultation 
phase. However, when the intermediate estimates are 
broadcast partially (0 <  ğ¿ <  ğ‘€), nodes have no access to 
the non-communicated entries. To resolve this indistinctness, 
we allow the nodes utilize their own intermediate estimates 
entries instead of ones from the neighbors that have not been 
communicated, i.e., at node ğ‘˜, substitute 
 
àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œà¬¿à¬µàµ¯ğ’˜à¯,à¯œà¬¿à¬µ          âˆ€ğ‘™ âˆˆ ğ’©à¯ âˆ– {ğ‘˜} 
(15) 
for 
 
àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œà¬¿à¬µàµ¯ğ’˜à¯Ÿà¯,à¯œà¬¿à¬µ          âˆ€ğ‘™ âˆˆ ğ’©à¯ âˆ– {ğ‘˜} 
(16) 
and 
 
àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œàµ¯ğà¯,à¯œ          âˆ€ğ‘™ âˆˆ ğ’©à¯ âˆ– {ğ‘˜} 
(17) 
for 
 
àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œàµ¯ğà¯Ÿà¯,à¯œ         âˆ€ğ‘™ âˆˆ ğ’©à¯ âˆ– {ğ‘˜} 
(18) 
Based on this approach together with using perturbed 
data as introduced in (7) and (8), we formulate general 
PDLMS under noisy exchange as follows: 
 
 
 
 
 
(19) 
 
ğà¯,à¯œ = ğ“à¯,à¯œà¬¿à¬µ + ğœ‡à¯ğ’–à¯,à¯œ
âˆ— àµ£ğ’…à¯(ğ‘–) âˆ’ ğ’–à¯,à¯œğ“à¯,à¯œà¬¿à¬µàµ§ 
(20) 
 
 
 
 
 
(21) 
Remark: The probability of transmission for all the entries at 
each node is equal and state as [1], [9] 
 
ğ“… = ğ¿ ğ‘€
àµ—  
(22) 
Moreover, the entry selection matrices, ğš²à¯,à¯œ, do not rely on 
any data/parameter with the exception of ğ¿ and ğ‘€. 
Introduce the following aggregate ğ‘€ Ã— 1  zero mean 
noise signals: 
 
ğ’—à¯,à¯œà¬¿à¬µ
(ğ’˜)
â‰œ âˆ‘
ğ‘à¬µ,à¯Ÿà¯ğš²à¯Ÿ,à¯œà¬¿à¬µğ’—à¯Ÿà¯,à¯œà¬¿à¬µ
(ğ’˜)
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
 
(23) 
 
ğ’—à¯,à¯œ
(ğ) â‰œ âˆ‘
ğ‘à¬¶,à¯Ÿà¯ğš²à¯Ÿ,à¯œğ’—à¯Ÿà¯,à¯œà¬¿à¬µ
(ğ)
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
 
(24) 
These noises correspond to the cumulative effect on node ğ‘˜ 
of all selected exchange noises from the neighbors of node ğ‘˜ 
while exchanging the estimates àµ›ğ’˜à¯Ÿ,à¯œà¬¿à¬µ, ğà¯Ÿ,à¯œàµŸ in the course of 
the two consultation steps. The ğ‘€ Ã— ğ‘€ covariance matrices 
of these noises are given by: 
 
ğ‘…à¯©,à¯
(à¯ª) â‰œ âˆ‘
ğ‘à¬µ,à¯Ÿà¯
à¬¶
ğš²à¯Ÿ,à¯œà¬¿à¬µğ‘…à¯©,à¯Ÿà¯
(à¯ª)
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
 
(25) 
 
ğ‘…à¯©,à¯
(à°Ÿ) â‰œ âˆ‘
ğ‘à¬¶,à¯Ÿà¯
à¬¶
ğš²à¯Ÿ,à¯œğ‘…à¯©,à¯Ÿà¯
(à°Ÿ)
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
 
(26) 
Thus, the PDLMS algorithm, Adapt Then Combine 
(ATC) approach, under noisy information exchange takes the 
following form: 
TABLE I.  
PDLMS ALGORITHM UNDER NOISY INFORMATION 
EXCHANGE 
Initialization: 
Start with ğ’˜à¯,à¬¿à¬µ = 0 and given non-negative real coefficient {ğ‘à¯Ÿà¯}, ğ´à¬µ = ğ¼à¯‡ 
and ğ´à¬¶ = ğ´, satifying (6),  
for ğ‘– â‰¥ 0, every node k computes 
Step 1: Incremental Phase 
ğà¯,à¯œ = ğ’˜à¯,à¯œà¬¿à¬µ + ğœ‡à¯ğ’–à¯,à¯œ
âˆ— àµ£ğ’…à¯(ğ‘–) âˆ’ ğ’–à¯,à¯œğ“à¯,à¯œà¬¿à¬µàµ§ 
Step 2: Diffusion Phase 
ğ’˜à¯,à¯œ = ğ‘à¯à¯ğà¯,à¯œ +
à·
ğ‘à¯Ÿà¯àµ£ğš²à¯Ÿ,à¯œğà¯Ÿà¯,à¯œ + àµ«ğ¼à¯† âˆ’ ğš²à¯Ÿ,à¯œàµ¯ğà¯Ÿà¯,à¯œàµ§
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
 
C. Entry Selection Method 
In order to select ğ¿ out of ğ‘€ entries of the intermediate 
estimates of each node at each iteration, the methods we 
utilized are comparable to the selection processes in 
stochastic and sequential partial-update schemes [12], [22], 
[23]. Here, we just review these methods namely sequential 
and stochastic partial-diffusion. 
In sequential partial-diffusion the entry selection 
matrices, ğš²à¯,à¯œ, is a diagonal matrix: 
ğš²à¯,à¯œ = á‰
ğ“‡à¬µ,à¯œ
â‹¯
0
â‹®
â‹±
â‹®
0
â‹¯
ğ“‡à¯†,à¯œ
á‰ ,      ğ“‡â„“,à¯œ = àµœ1     ğ‘–ğ‘“ â„“ âˆˆ â„(à¯œ à¯ à¯¢à¯— à®»à´¤)à¬¾à¬µ
0    ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’               (27) 
with ğµà´¤ = âŒˆğ‘€ ğ¿
â„ âŒ‰. The number of selection entries at each 
iteration is limited by ğ¿. The coefficient subsets â„à¯œ are not 
unique as long as they meet the following requirements [12]: 
1. Cardinality of â„à¯œ is between 1 and ğ¿; 
2. â‹ƒ
â„ğ“‡ = ğ’® 
à®»à´¤
ğ“‡à­€à¬µ
where ğ’® = {1,2, â€¦ , ğ‘€}; 
3. â„ğ“‡ âˆ© â„ğ“… = âˆ…, âˆ€ğ“‡, ğ“… âˆˆ {1, â€¦ , ğµà´¤} and ğ“‡ â‰  ğ“…. 
ğ“à¯,à¯œ = ğ‘à¬µ,à¯à¯ğ’˜à¯,à¯œà¬¿à¬µ 
 + âˆ‘
à¯Ÿà°¢ğ’©à³–âˆ–{à¯} ğ‘à¬µ,à¯Ÿà¯àµ£ğš²à¯Ÿ,à¯œà¬¿à¬µğ’˜à¯Ÿ,à¯œà¬¿à¬µ + àµ«ğ¼à¯† âˆ’
                ğš²à¯Ÿ,à¯œà¬¿à¬µàµ¯ğ’˜à¯,à¯œà¬¿à¬µàµ§ + âˆ‘
ğ‘à¬µ,à¯Ÿà¯ğš²à¯Ÿ,à¯œà¬¿à¬µğ’—à¯Ÿà¯,à¯œà¬¿à¬µ
(ğ’˜)
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
 
ğ’˜à¯,à¯œ = ğ‘à¬¶,à¯à¯ğà¯,à¯œ 
         + âˆ‘
à¯Ÿà°¢ğ’©à³–âˆ–{à¯} ğ‘à¬¶,à¯Ÿà¯àµ£ğš²à¯Ÿ,à¯œğà¯Ÿ,à¯œ + àµ«ğ¼à¯† âˆ’
             ğš²à¯Ÿ,à¯œàµ¯ğà¯,à¯œàµ§ + âˆ‘
ğ‘à¬¶,à¯Ÿà¯ğš²à¯Ÿ,à¯œğ’—à¯Ÿà¯,à¯œ
(ğ)
à¯Ÿà°¢ğ’©à³–âˆ–{à¯}
  
21
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

The description of the entry selection matrices, ğš²à¯,à¯œ, in 
stochastic partial-diffusion is similar to that of sequential 
one. The only difference is as follows. At a given iteration, ğ’Š, 
sequential case one of the set â„ğ“‡, ğ‘Ÿ = 1, â€¦ , ğµà´¤ is chosen in a 
predetermined fashion, whereas for stochastic case, one of 
the sets â„ğ“‡ is sampled at random from {â„à¬µ, â„à¬¶, â€¦ , â„à®»à´¤}. One 
might ask why these methods are considered to organize 
these selection matrices. To answer this question, it is worth 
mentioning that the nodes need to recognize which entries of 
their neighborsâ€™ intermediate estimates have been propagated 
at each iteration. These schemes bypass the need for 
addressing (position in the vector) [1], [9]. 
III. 
STEADY-STATE PERFORMANCE ANALYSIS 
We now move on to examine the behavior of the general 
PDLMS implementations (19)-(21), and the influence of the 
mentioned perturbations on its convergence and steady-state 
performance. For this reason, we shall study the 
convergence of the weight estimates both in the mean and 
mean-square senses. In order to make the analysis tractable, 
we introduce the following assumptions on statistical 
properties of the measurement data and noise signals. 
Assumptions: 
1. The regression data  ğ’–à¯,à¯œ are temporally white and 
spatially independent random variables with zero 
mean and covariance matrix ğ‘…à¯¨,à¯ â‰œ Î•ğ’–à¯,à¯œ
âˆ— ğ’–à¯,à¯œ  â‰¥ 0. 
2. The noise signal ğ’—à¯(ğ‘–)  , ğ’—à¯,à¯œà¬¿à¬µ
(à¯ª)  and ğ’—à¯,à¯œ
(à°Ÿ)  are 
temporally white and spatially independent random 
variable with zero mean and covariance ğœà¯©,à¯
à¬¶ , ğ‘…à¯©,à¯
(à¯ª) 
and ğ‘…à¯©,à¯
(à°Ÿ) , respectively. In addition, the quantities 
á‰„ğ‘…à¯©,à¯Ÿà¯
(à¯ª), ğ‘…à¯©,à¯Ÿà¯
(à°Ÿ)á‰… are all zero if ğ‘™ âˆ‰ ğ‘à¯ or when ğ‘™ = ğ‘˜. 
3. The regression data àµ›ğ’–à¯ ,à¯œà°­àµŸ, the model noise signals 
ğ’—à¯¡(ğ‘–à¬¶), and the link noise signals ğ’—à¯Ÿà°­à¯à°­,à¯à°­
(à¯ª)
 and ğ’—à¯Ÿà°®à¯à°®,à¯à°®
(à°Ÿ)
 
are mutually independent random variables for all 
indexes {ğ‘–à¬µ, ğ‘–à¬¶, ğ‘—à¬µ, ğ‘—à¬¶, ğ‘˜à¬µ, ğ‘˜à¬¶, ğ‘™à¬µ, ğ‘™à¬¶, ğ‘š, ğ‘›}. 
4. The step-sizes, ğœ‡à¯  âˆ€ğ‘˜, are small enough such that 
their squared values are negligible. 
We are interested in examining the evolution of the 
weight-error vectors. To do so, we let: 
 
ğ’˜à·¥ à¯,à¯œ â‰œ ğ‘¤à¯¢ âˆ’ ğ’˜à¯,à¯œ 
(28) 
We import the information from across the network into 
block vectors and matrices as follows: 
 
ğ“¡à¯¨,à¯œ â‰œ ğ‘‘ğ‘–ğ‘ğ‘”àµ›ğ’–à¬µ,à¯œ
âˆ— ğ’–à¬µ,à¯œ, ğ’–à¬¶,à¯œ
âˆ— ğ’–à¬¶,à¯œ, â€¦ , ğ’–à¯‡,à¯œ
âˆ— ğ’–à¯‡,à¯œàµŸ 
(29) 
 
ğ’”à¯œ â‰œ ğ‘‘ğ‘–ğ‘ğ‘”àµ›ğ’–à¬µ,à¯œ
âˆ— ğ’—à¬µ(ğ‘–), ğ’–à¬¶,à¯œ
âˆ— ğ’—à¬¶(ğ‘–), â€¦ , ğ’–à¯‡,à¯œ
âˆ— ğ’—à¯‡(ğ‘–)àµŸ 
(30) 
 
ğ’—à¯œ
(à¯ª) â‰œ ğ‘ğ‘œğ‘™á‰„ğ’—à¬µ,à¯œ
(à¯ª), ğ’—à¬¶,à¯œ
(à¯ª), â€¦ , ğ’—à¯‡,à¯œ
(à¯ª)á‰… 
(31) 
 
ğ’—à¯œ
(à°Ÿ) â‰œ ğ‘ğ‘œğ‘™á‰„ğ’—à¬µ,à¯œ
(à°Ÿ), ğ’—à¬¶,à¯œ
(à°Ÿ), â€¦ , ğ’—à¯‡,à¯œ
(à°Ÿ)á‰… 
(32) 
 
â„³ â‰œ ğ‘‘ğ‘–ğ‘ğ‘”{ğœ‡à¬µğ¼à¯†, â€¦ , ğœ‡à¯‡ğ¼à¯†} 
(33) 
 
ğ’˜à·¥ à¯œ â‰œ ğ‘ğ‘œğ‘™àµ›ğ’˜à·¥à¬µ,à¯œ, â€¦ , ğ’˜à·¥ à¯‡,à¯œàµŸ 
(34) 
Subsequently, some algebra demonstrates that 
 
 
 
 
 
(35) 
where 
 
ğ“à¯¥,à¯œ = á‰
Î‘à¬µ,à¬µ,à¯œ
â‹¯
Î‘à¬µ,à¯‡,à¯œ
â‹®
â‹±
â‹®
Î‘à¯‡,à¬µ,à¯œ
â€¦
Î‘à¯‡,à¯‡,à¯œ
á‰ , âˆ€ğ‘Ÿ âˆˆ {1,2} 
(36) 
 
ğš¨à¯£,à¯¤,à¯œ = á‰
ğ¼à¯† âˆ’ âˆ‘
à¯Ÿà°¢à¯‡à³›âˆ–{à¯£} ğ‘à¯¥,à¯Ÿà¯£ğš²à¯Ÿ,à¯œ  ğ‘–ğ‘“ ğ‘ = ğ‘
ğ‘à¯¥,à¯¤à¯£ğš²à¯¤,à¯œ               ğ‘–ğ‘“ ğ‘ğœ–ğ‘à¯£ âˆ– {ğ‘}
ğ‘‚à¯†                        ğ‘œğ‘¡â„ğ‘’ğ‘Ÿ ğ‘¤ğ‘–ğ‘ ğ‘’        
 
(37) 
A. Mean Performance 
Taking expectation of both sides of (35) under Remark  
and Assumptions, we find that the mean error vector evolves 
according to the following recursion: 
 
ğ”¼ğ’˜à·¥ à¯œ = ğ’¬à¬¶Î•(ğ¼à¯‡à¯† âˆ’ â„³â„›à¯¨)ğ’¬à¬µğ”¼ğ’˜à·¥ à¯œà¬¿à¬µ 
(38) 
where 
 
ğ’¬à¬µ = ğ”¼àµ£ğ“à¬µ,à¯œàµ§,      ğ’¬à¬¶ = ğ”¼àµ£ğ“à¬¶,à¯œà¬¿à¬µàµ§ 
(39) 
From (38), we observe that in order for the recursion to 
be stable in the mean sense, the matrix ğ’¬à¬¶Î•(ğ¼à¯‡à¯† âˆ’ â„³â„›à¯¨)ğ’¬à¬µ 
should be stable [24]. Picking ğ’¬à¬µ  and ğ’¬à¬¶  which all their 
entries are real non-negative and all their rows add up to 
unity [1]. Therefore, in the light of lemma 1 of [25], mean 
stability and asymptotic unbiasedness of the algorithm is 
guaranteed if the matrix  ğ¼à¯‡à¯† âˆ’ â„³â„›à¯¨  is stable or 
equivalently if 
 
|ğœ†à¯ à¯”à¯«{ğ¼à¯‡à¯† âˆ’ â„³â„›à¯¨}| < 1 
(40) 
where ğœ†à¯ à¯”à¯«{. } refers to the largest eigenvalue of a matrix. 
The set of the eigenvalue of ğ¼à¯‡à¯† âˆ’ â„³â„›à¯¨ is the union of the 
set of the eigenvalue of  ğ¼à¯† âˆ’ ğœ‡à¯ğ‘…à¯¨,à¯ âˆ€ğ‘˜ [25]. Thus, (40) is 
satisfied 
when à¸«ğœ†à¯ à¯”à¯«àµ›ğ¼à¯† âˆ’ ğœ‡à¯ğ‘…à¯¨,à¯àµŸà¸« < 1, âˆ€ğ‘˜
 or à¸«1 âˆ’
ğœ‡à¯ğœ†à¯ à¯”à¯«àµ›ğ‘…à¯¨,à¯àµŸà¸« < 1, âˆ€ğ‘˜ . These inequalities determine the 
stability bounds for step-sizes as 
 
0 < ğœ‡à¯ <
à¬¶
à°’à³˜à³Œà³£àµ›à¯‹à³ ,à³–àµŸ    âˆ€ğ‘˜ 
(41) 
ğ’˜à·¥ à¯œ = ğ“à¬¶,à¯œàµ«ğ¼à¯‡à¯† âˆ’ â„³ğ“¡à¯¨,à¯œàµ¯ğ“à¬µ,à¯œà¬¿à¬µğ’˜à·¥ à¯œà¬¿à¬µ    
 
âˆ’ğ“à¬¶,à¯œàµ«ğ¼à¯‡à¯† âˆ’ â„³ğ“¡à¯¨,à¯œàµ¯ğ’—à¯œà¬¿à¬µ
(à¯ª) âˆ’ ğ“à¬¶,à¯œâ„³ğ’”à¯œ âˆ’ ğ’—à¯œ
(à°Ÿ)  
22
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

B. Mean-Square Performance 
The weighted variance relation for the error vector ğ’˜à·¥ à¯œ 
can be obtained from the error recursion (35) as: 
 
 
 
(42) 
where  Î£  is an arbitrary positive semi-definite Hermitian 
matrix of size ğ‘ğ‘€ Ã— ğ‘ğ‘€ and 
 
ğ“—à¯œ â‰œ ğ“à¬¶,à¯œàµ«ğ¼à¯‡à¯† âˆ’ â„³ğ“¡à¯¨,à¯œàµ¯ 
(43) 
Furthermore, the matrix  Î£Â´ can be expressed as 
 
Î£Â´ â‰œ ğ”¼ğ“‘à¯œ
âˆ—Î£ğ“‘à¯œ 
(44) 
with 
 
ğ“‘à¯œ â‰œ ğ“à¬¶,à¯œàµ«ğ¼à¯‡à¯† âˆ’ â„³ğ“¡à¯¨,à¯œàµ¯ğ“à¬µ,à¯œà¬¿à¬µ 
(45) 
The variance relation becomes 
 
 
 
 
 
 
(46) 
where 
 
ğ’Ÿà¬µ = ğ”¼àµ«ğ“à¬µ,à¯œà¬¿à¬µ
à¯
â¨‚ğ“à¬µ,à¯œà¬¿à¬µ
à¯
àµ¯ 
(47) 
 
ğ’Ÿà¬¶ = ğ”¼àµ«ğ“à¬¶,à¯œ
à¯ â¨‚ğ“à¬¶,à¯œ
à¯ àµ¯ 
(48) 
 
ğ’¢ = â„³ğ”¼áˆ¾ğ’”à¯œğ’”à¯œ
âˆ—áˆ¿â„³ = ğ‘‘ğ‘–ğ‘ğ‘”àµ›ğœ‡à¬µğœà¯©,à¬µ
à¬¶ ğ‘…à¯¨,à¬µ, â€¦ , ğœ‡à¯‡ğœà¯©,à¯‡
à¬¶ ğ‘…à¯¨,à¯‡àµŸ (49) 
 
â„‹ â‰œ ğ”¼àµ£ğ¼à¯‡à¯† âˆ’ â„³ğ“¡à¯¨,à¯œàµ§ = ğ¼à¯‡à¯† âˆ’ â„³â„›à¯¨ 
(50) 
 
ğ‘…à¯©
(à¯ª) â‰œ ğ”¼ğ’—à¯œà¬¿à¬µ
(à¯ª)ğ’—à¯œà¬¿à¬µ
âˆ—(à¯ª) = ğ‘‘ğ‘–ğ‘ğ‘”á‰„ğ‘…à¯©,à¬µ
(à¯ª), â€¦ , ğ‘…à¯©,à¯‡
(à¯ª)á‰… 
(51) 
 
ğ‘…à¯©
(à°Ÿ) â‰œ ğ”¼ğ’—à¯œ
(à°Ÿ)ğ’—à¯œ
âˆ—(à°Ÿ) = ğ‘‘ğ‘–ğ‘ğ‘”á‰„ğ‘…à¯©,à¬µ
(à°Ÿ), â€¦ , ğ‘…à¯©,à¯‡
(à°Ÿ)á‰… 
(52) 
Therefore, the steady-state weighted variance relation 
(46) becomes 
lim
à¯œâ†’à®¶ ğ”¼â€–ğ’˜à·¥ à¯œâ€–à¯¨à¯¡à¯©à¯˜à¯–á‰‚á‰€à­à±Šà°®à±‰à°®à¬¿ğ’Ÿà°­àµ£ğ”¼àµ«à¯‚à²¿à²¾à¬¿ğ“¡à³ ,à³”â„³àµ¯â¨‚àµ«à¯‚à²¿à²¾à¬¿ğ“¡à³ ,à³”â„³àµ¯àµ§ğ’Ÿà°® á‰à¯©à¯˜à¯–(à®Š)á‰ƒ
à¬¶
 
= àµ¬ğ‘£ğ‘’ğ‘à¯{ğ’¢}ğ’Ÿà¬¶ + ğ‘£ğ‘’ğ‘à¯ á‰€â„‹ğ‘…à¯©
(à¯ª)â„‹âˆ—á‰ ğ’Ÿà¬¶ + ğ‘£ğ‘’ğ‘à¯ á‰€ğ‘…à¯©
(à°Ÿ)á‰àµ° ğ‘£ğ‘’ğ‘(Î£) (53) 
It is known that a recursion of type (53) is stable and 
convergent if the matrix ğ’Ÿà¬µàµ£ğ”¼àµ«ğ¼à¯‡à¯† âˆ’ ğ“¡à¯¨,à¯œâ„³àµ¯â¨‚àµ«ğ¼à¯‡à¯† âˆ’
ğ“¡à¯¨,à¯œâ„³àµ¯àµ§ğ’Ÿà¬¶  is stable [24], [26]. All the entries of ğ’Ÿà¬µ and 
ğ’Ÿà¬¶ are real non-negative and all its columns sum up to one. 
Moreover, the eigenvalue of ğ’¯â¨‚ğ’¯  are square of the 
eigenvalue of ğ’¯. Therefore, stability of this matrix has the 
same conditions as the stability of ğ¼à¯‡à¯† âˆ’ â„›à¯¨â„³. This means 
that choosing the step-sizes is accordance with (41) makes 
the algorithm stable likewise in the mean-square sense hence 
convergent to steady state. 
The network MSD is defined as: 
 
MSDà­¬à­£à­²à­µà­­à­°à­© â‰œ lim
à¯œâ†’à®¶
à¬µ
à¯‡ âˆ‘
ğ”¼à¸®ğ’˜à·¥ à¯,à¯œà¸®
à¬¶
à¯‡
à¯à­€à¬µ
 
(54) 
Since we are free to choose Î£, we select it as Ià¯‡à°®à¯†à°® âˆ’
ğ’Ÿà¬µàµ£ğ”¼àµ«ğ¼à¯‡à¯† âˆ’ ğ“¡à¯¨,à¯œâ„³àµ¯â¨‚àµ«ğ¼à¯‡à¯† âˆ’ ğ“¡à¯¨,à¯œâ„³àµ¯àµ§ğ’Ÿà¬¶ = ğ‘£ğ‘’ğ‘(ğ¼à¯‡à¯†/ğ‘)  
then the expression (53) gives 
 
 
 
(55) 
 
IV. 
NUMERICAL STUDIES 
In order to illustrate the PLDMS strategies performance 
under noisy information exchange, we present some 
simulation results in this section. 
A. Simulation 
We consider an adaptive network with a random topology 
and ğ‘ = 10 where each node is, in average, connected to 
two other nodes. The unknown parameter ğ‘¤à¯¢ of length ğ‘€ =
8 is randomly generated. We adopt a uniform step-size, 
ğœ‡à¯ = 0.01,  The measurements were generated according to 
model (1), and regressors, ğ’–à¯,à¯œ, were chosen Gaussian i.i.d 
with randomly generated different diagonal covariance 
matrices, ğ‘…à¯¨,à¯. The additive noises at nodes are zero mean 
Gaussian with variances ğœà¯©,à¯
à¬¶
 and independent of the 
regression data. The traces of the covariance matrix 
regressors and the noise variances at all nodes, ğ‘‡ğ‘Ÿàµ«ğ‘…à¯¨,à¯àµ¯ 
and ğœà¯©,à¯
à¬¶ , are shown in Figure 2. 
We also use white Gaussian link noise signals such that 
ğ‘…à¯©,à¯Ÿà¯
(à¯ª) = ğœà¯ª,à¯Ÿà¯
à¬¶
ğ¼à¯† and ğ‘…à¯©,à¯Ÿà¯
(à°Ÿ) = ğœà°Ÿ,à¯Ÿà¯
à¬¶
ğ¼à¯†. All link noise variances 
àµ›ğœà¯ª,à¯Ÿà¯
à¬¶
, ğœà°Ÿ,à¯Ÿà¯
à¬¶
àµŸ are randomly generated. The average power 
of each type of link noise across the network is 35 dB less 
than that of the model noise. In Figure 3, we plot the 
experimental network MSD curves for ATC case (ğ´à¬µ = ğ¼à¯‡) 
of PDLMS algorithm using both sequential and stochastic 
partial diffusion schemes under noisy information exchange 
for different numbers of entries at each iteration, ğ‘€. We use 
uniform weights for àµ›ğ‘à¬µ,à¯Ÿà¯, ğ‘à¬¶,à¯Ÿà¯àµŸ at combination phase at 
this stage. In Figure 4, we compare network MSD learning 
curve of PDLMS for both ATC and CTA, Combine Then 
Adapt, cases (ğ´à¬¶ = ğ¼à¯‡) under ideal and noisy links. 
 
ğ”¼â€–ğ’˜à·¥ à¯œâ€–à®Š
à¬¶ = ğ”¼â€–ğ’˜à·¥ à¯œà¬¿à¬µâ€–à®ŠÂ´
à¬¶ + ğ”¼àµ«ğ’”à¯œ
âˆ—â„³ğ“à¬¶,à¯œ
à¯ Î£ğ“à¬¶,à¯œâ„³ğ’”à¯œàµ¯ 
  +ğ”¼àµ«ğ’—à¯œà¬¿à¬µ
âˆ—(à¯ª)ğ“—à¯œ
âˆ—Î£ğ“—à¯œğ’—à¯œà¬¿à¬µ
(à¯ª)àµ¯ + ğ”¼ á‰€ğ’—à¯œ
âˆ—(à°Ÿ)Î£ğ’—à¯œ
(à°Ÿ)á‰ 
ğ”¼â€–ğ’˜à·¥ à¯œâ€–à®Š
à¬¶ = ğ”¼â€–ğ’˜à·¥ à¯œà¬¿à¬µâ€–à®Šá‡²
à¬¶  
                + àµ¬ğ‘£ğ‘’ğ‘à¯{ğ’¢}ğ’Ÿà¬¶ + ğ‘£ğ‘’ğ‘à¯àµ«â„‹ğ‘…à¯©
(à¯ª)â„‹âˆ—àµ¯ğ’Ÿà¬¶
+ ğ‘£ğ‘’ğ‘à¯ á‰€ğ‘…à¯©
(à°Ÿ)á‰àµ° ğ‘£ğ‘’ğ‘(Î£) 
MSDà­§à­«à­®à­£à­°à­¤à­£à­¡à­²
à­¬à­£à­²à­µà­­à­°à­© =
à¬µ
à¯‡ àµ£ğ‘£ğ‘’ğ‘(ğ’¢)ğ’Ÿà¬¶ + ğ‘£ğ‘’ğ‘(â„‹ğ‘…à¯©
à¯ªâ„‹âˆ—)ğ’Ÿà¬¶ +
ğ‘£ğ‘’ğ‘àµ«ğ‘…à¯©
(à°Ÿ)àµ¯àµ§
à¯(ğ¼à¯‡à°®à¯†à°® âˆ’ â„±)à¬¿à¬µvec(ğ¼à¯‡à¯†)  
23
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

 
 
Figure 2.  Covariance matrix trace of the input signal and the variance of 
the noise at each node. 
 
Figure 3.  Network MSD learning curve of PDLMS for ATC under noisy 
links (top) sequential and (bottom) stochastic. 
B. Discussion 
From the simulation results, we make the following 
observations: 
In  [1], authors emphasized that the PDLMS algorithm 
delivers a trade-off between communications cost and 
estimation performance. However, noisy links add a new 
complexity to the network optimization problem. In 
addition, in the presence of noisy links, the trade-off 
between communication cost and estimation performance 
becomes unbalanced. This is because as more entries are 
broadcast at each iteration, more perturbed weight estimates 
are interred in consultant phase.   
The sequential partial-diffusion schemes outperform the 
stochastic partial-diffusion. Finally, the adaptive ATC 
strategy outperforms the adaptive CTA strategy for both 
perfect and imperfect cases. 
 
 
Figure 4.  Comparison of network MSDs of sequential PDLMS algorithm 
for (top) ATC and (bottom) CTA under noisy information exchange  
V. 
CONCLUSION 
In this work, we presented a general form of PDLMS 
algorithms, formulated the ATC and CTA versions of 
PDLMS 
under 
noisy 
Links, 
and 
investigated 
the 
performance of partial-diffusion algorithms under several 
sources of noise during information exchange for both 
sequential and stochastic schemes. We also illustrated that 
the PDLMS strategy could still stabilize the mean and mean-
square convergence of the network with noisy information 
exchange. We derived analytical expressions for network 
learning curve MSD. The important result is that the noisy 
links are the main factor in performance degradation of a 
diffusion LMS strategy running in a network with imperfect 
communication. Furthermore, there is no direct relation 
between the MSD performance and number of selected 
entries 
under 
imperfect 
information 
exchange. 
The 
performance degradation incurred by noisy links depends not 
only on the link noise variances, ğœà¯ª,à¯Ÿà¯
à¬¶
 and ğœà°Ÿ,à¯Ÿà¯
à¬¶
, but also on 
the other parameters of the network, i.e., the measurement 
and state noise variances, the network topology, and 
combination weights. These topics will be addressed in 
future work. 
REFERENCE 
[1] 
R. Arablouei, S. Werner, Y.-F. Huang, and K. Dogancay, 
â€œDistributed least mean-square estimation with partial diffusion,â€ 
Signal Process. IEEE Trans., vol. 62, no. 2, pp. 472â€“484, 2014. 
[2] 
V. Vahidpour, A. Rastegarnia, A. Khalili, and S. Sanei, â€œAnalysis of 
partial diffusion recursive least squares adaptation over noisy links,â€ 
IET Signal Process., 2017. 
[3] 
V. Vahidpour, A. Rastegarnia, A. Khalili, and S. Sanei, â€œPartial 
24
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

Diffusion Kalman Filtering for Distributed State Estimation in 
Multiagent Networks,â€ Neural Networks Learn. Syst. IEEE Trans., 
2019. 
[4] 
E. E. Tsiropoulou, S. T. Paruchuri, and J. S. Baras, â€œInterest, energy 
and physical-aware coalition formation and resource allocation in 
smart IoT applications,â€ in 2017 51st Annual Conference on 
Information Sciences and Systems (CISS), 2017, pp. 1â€“6. 
[5] 
M. O. Sayin and S. S. Kozat, â€œCompressive diffusion strategies over 
distributed networks for reduced communication load,â€ Signal 
Process. IEEE Trans., vol. 62, no. 20, pp. 5308â€“5323, 2014. 
[6] 
M. O. Sayin and S. S. Kozat, â€œSingle bit and reduced dimension 
diffusion strategies over distributed networks,â€ Signal Process. Lett. 
IEEE, vol. 20, no. 10, pp. 976â€“979, 2013. 
[7] 
S. Chouvardas, K. Slavakis, and S. Theodoridis, â€œTrading off 
complexity with communication costs in distributed adaptive 
learning via Krylov subspaces for dimensionality reduction,â€ Sel. 
Top. Signal Process. IEEE J., vol. 7, no. 2, pp. 257â€“273, 2013. 
[8] 
R. Arablouei, K. Dogancay, S. Werner, and Y.-F. Huang, â€œAdaptive 
distributed estimation based on recursive least-squares and partial 
diffusion,â€ Signal Process. IEEE Trans., vol. 62, no. 14, pp. 3510â€“
3522, 2014. 
[9] 
V. Vahidpour, A. Rastegarnia, A. Khalili, W. M. Bazzi, and S. 
Sanei, â€œAnalysis of Partial Diffusion LMS for Adaptive Estimation 
Over Networks with Noisy Links,â€ IEEE Trans. Netw. Sci. Eng., 
2017. 
[10] J. R. Deller Jr and Y. F. Huang, â€œSet-membership identification and 
filtering for signal processing applications,â€ Circuits, Syst. Signal 
Process., vol. 21, no. 1, pp. 69â€“82, 2002. 
[11] S. Gollamudi, S. Nagaraj, S. Kapoor, and Y.-F. Huang, â€œSet-
membership filtering and a set-membership normalized LMS 
algorithm with an adaptive step size,â€ Signal Process. Lett. IEEE, 
vol. 5, no. 5, pp. 111â€“114, 1998. 
[12] K. Dogancay, Partial-update adaptive signal processing: Design 
Analysis and Implementation. Academic Press, 2008. 
[13] S. Werner, T. Riihonen, and Y.-F. Huang, â€œEnergy-efficient 
distributed parameter estimation with partial updates,â€ in Green 
Circuits and Systems (ICGCS), 2010 International Conference on, 
2010, pp. 36â€“40. 
[14] S. Werner and Y.-F. Huang, â€œTime-and coefficient-selective 
diffusion strategies for distributed parameter estimation,â€ in Signals, 
Systems and Computers (ASILOMAR), 2010 Conference Record of 
the Forty Fourth Asilomar Conference on, 2010, pp. 696â€“697. 
[15] A. Malipatil, Y.-F. Huang, and S. Werner, â€œAn SMF approach to 
distributed average consensus in clustered sensor networks,â€ in 
Signal Processing Advances in Wireless Communications, 2009. 
SPAWCâ€™09. IEEE 10th Workshop on, 2009, pp. 81â€“85. 
[16] R. Abdolee and B. Champagne, â€œDiffusion LMS algorithms for 
sensor networks over non-ideal inter-sensor wireless channels,â€ in 
Distributed Computing in Sensor Systems and Workshops (DCOSS), 
2011 International Conference on, 2011, pp. 1â€“6. 
[17] A. Khalili, M. A. Tinati, and A. Rastegarnia, â€œPerformance analysis 
of distributed incremental LMS algorithm with noisy links,â€ Int. J. 
Distrib. Sens. Networks, vol. 2011, 2011. 
[18] A. Khalili, M. A. Tinati, A. Rastegarnia, and J. Chambers, â€œSteady-
state analysis of diffusion LMS adaptive networks with noisy links,â€ 
Signal Process. IEEE Trans., vol. 60, no. 2, pp. 974â€“979, 2012. 
[19] A. Khalili, M. A. Tinati, A. Rastegarnia, and J. A. Chambers, 
â€œTransient analysis of diffusion least-mean squares adaptive 
networks with noisy channels,â€ Int. J. Adapt. Control Signal 
Process., vol. 26, no. 2, pp. 171â€“180, 2012. 
[20] X. Zhao, S.-Y. Tu, and A. H. Sayed, â€œDiffusion adaptation over 
networks under imperfect information exchange and non-stationary 
data,â€ Signal Process. IEEE Trans., vol. 60, no. 7, pp. 3460â€“3475, 
2012. 
[21] A. H. Sayed, â€œAdaptive Filters. Hoboken.â€ NJ: John Wiley & Sons, 
2008. 
[22] A. H. Sayed, â€œDiffusion adaptation over networks,â€ Acad. Press 
Libr. Signal Process., vol. 3, pp. 323â€“454, 2013. 
[23] M. Godavarti and A. O. Hero III, â€œPartial update LMS algorithms,â€ 
Signal Process. IEEE Trans., vol. 53, no. 7, pp. 2382â€“2399, 2005. 
[24] C. D. Meyer, Matrix analysis and applied linear algebra, vol. 2. 
Siam, 2000. 
[25] F. S. Cattivelli and A. H. Sayed, â€œDiffusion LMS strategies for 
distributed estimation,â€ Signal Process. IEEE Trans., vol. 58, no. 3, 
pp. 1035â€“1048, 2010. 
[26] K. M. Abadir and J. R. Magnus, Matrix algebra, vol. 1. Cambridge 
University Press, 2005. 
 
 
25
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

