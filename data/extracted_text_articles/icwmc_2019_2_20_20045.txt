Partial-Diffusion Least Mean-Square Estimation Over Networks Under Noisy 
Information Exchange 
 
Wael M. Bazzi 
Electrical Engineering Department 
American University in Dubai 
Dubai, UAE 
Email: wbazzi@aud.edu 
Vahid Vadidpour, Amir Rastegarnia, Azam Khalili 
Department of Electrical Engineering 
Malayer University 
Malayer, Iran, 65719-95863 
 
 
Abstract— Partial diffusion scheme is an effective method for 
reducing computational load and power consumption in 
adaptive 
network 
implementation. 
The Information 
is 
exchanged among the nodes, usually over noisy links. In this 
paper, we consider a general version of Partial-Diffusion 
Least-Mean-Square (PDLMS) algorithm in the presence of 
various sources of imperfect information exchanges. Like the 
established PDLMS, we consider two different schemes to 
select the entries, sequential and stochastic, for transmission at 
each iteration. Our objective is to analyze the aggregate effect 
of these perturbations on general PDLMS strategies. 
Simulation results demonstrate that considering noisy link 
assumption adds a new complexity to the related optimization 
problem and the trade-off between communication cost and 
estimation performance in comparison to ideal case becomes 
unbalanced. Our simulation results substantiate the effect of 
noisy links on PDLMS algorithm and verify the theoretical 
analysis. 
Keywords- adaptive networks; diffusion adaptation; noisy 
informatin exchange; partial diffusion; sequential, stochastic. 
I. 
 INTRODUCTION 
Due to limited electrical power and bandwidth resources 
for inter-node communication over a practical Wireless 
Sensor Networks (WSN) or ad hoc networks, data 
transmission through radio communication links can become 
prohibitively expensive for realizing a collaborative task. 
Generally speaking, although benefits of diffusion strategies 
achieved by increasing inter-node communications, they are 
compromised by the communication cost. As a result, since 
various nodes can have various numbers of neighbors, they 
may require disparate hardware or consume power 
dissimilarity [1]–[4]. Therefore, reducing the communication 
cost while maintaining the benefits of cooperation is of 
practical importance. 
There have been several attempts to reduce the 
communication cost without considerable degradation of the 
estimation and compromising the cooperation benefits in 
diffusion algorithms. Among them diffusion least mean-
square (LMS), such as reducing the dimension of the 
estimates [5]–[7], selecting a subset of the entries of the 
estimates [1] [2] [8] [9], set-membership filtering [10][11], 
or partial updating [12] have been reported in [13]–[15]. 
Among these methods, we focus on [1] which LMS 
algorithm for adaptive distribute estimation has been 
formulated and analyzed by utilizing partial-diffusion. In [1], 
an adapt-then-combine (ATC) Partial-Diffusion Least-Mean-
Square (PDLMS) algorithm is proposed for distributed 
estimation over adaptive networks in which, at each iteration, 
each node transmits a subsets of the entries of intermediate 
estimate vector to its neighbors. 
In the PDLMS strategy proposed in [1], the weight 
estimates that are exchanged among the nodes can be subject 
to perturbations over communication links. The effect of link 
noise during the exchange of weight estimates, already 
appear for the diffusion algorithm in the works [16]–[20]. It 
should be noted that since our objective is to minimize the 
inter-node communications, the nodes only exchange their 
intermediate estimates with their neighbors. Therefore, we 
allow for noisy exchange just during the two combination 
steps.  We subsequently study the performance of this 
general case utilizing the energy conservation argument. We 
established its stability and convergence in the mean and 
mean-square senses. We also derive a theoretical expression 
for the steady-state Mean-Square-Deviation (MSD) and 
verify its accuracy via numerical simulations.  
The main contributions in this paper include: 
• Focusing on [1] which involves transmission of a 
subset of entries of the inter-node estimate vectors 
named partial diffusion, we provide a more general 
algorithmic structure of which [1] is just a special 
case. To achieve this, we consider the fact that the 
weight estimates exchanged among the nodes can be 
subject to quantization errors and additive noise over 
communication links. We also consider two different 
schemes for selecting the weight vector entries for 
transmission at each iteration. We allow for noisy 
exchange during the two combination steps only. It 
should be noted that since our objective is to 
minimize the inter-node communication, the nodes 
only exchange their intermediate estimates with their 
neighbors; 
• 
Using the energy conservation argument [21] we 
analyze the stability of algorithms in mean and 
mean square senses under certain statistical 
conditions.  
• 
We 
illustrate 
the 
comparable 
convergence 
performance of PDLMS algorithm with noisy links 
using different numerical examples. 
This paper is organized as follows. In Section II, we 
formulate the PDLMS under noisy information exchange. 
The performance analyses are examined in Section III. We 
Email: {vahidpour, rastegarnia, khalili}@malayeru.ac.ir 
19
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

provide simulation results in Section IV and draw 
conclusions in Section V. 
A. Notation 
We adopt the lowercase letters to denote vectors, 
uppercase letter for matrices, normal font for nonrandom 
(deterministic) quantities, and the boldface letters for random 
quantities. 
The 
notation 
(. )∗
 refers 
to 
conjugate 
transposition, 𝑇𝑟(. ) refer to the trace of its matrix argument, 
⨂ for the Kronecker product, and 𝑣𝑒𝑐(. ) for a vector formed 
by stacking the columns of its matrix argument. We shall 
also use 𝑐𝑜𝑙(… )  to denote a column vector formed by 
stacking its arguments on top of each other and 𝑑𝑖𝑎𝑔(. . . ) to 
denote a (block) diagonal matrix formed from its argument. 
All vectors in our treatment are column vectors, with the 
exception of regression vectors, 𝒖௞,௜. 
II. 
PARTIAL DIFFUSION ALGORITHMS WITH IMPERFECT 
INFORMATION EXCHANGE 
Consider a connected network consisting of 𝑁 nodes. At 
time instant 𝑖 ≥  0 , each node 𝑘  has access to scalar 
measurements 𝒅௞(𝑖) and 1 × 𝑀 regression data vectors 𝒖௞,௜. 
The data across all nodes are assumed to be related to an 
unknown 𝑀 × 1 vector 𝑤௢ via linear regression model of the 
form [17]: 
 
𝒅௞(𝑖) = 𝒖௞(𝑖)𝑤௢ + 𝒗௞(𝑖) 
(1) 
where 𝒗௞(𝑖) denotes the measurement noise with zero mean 
and variance 𝜎௩,௞
ଶ  and the vector 𝑤௢ refers to the parameter 
of interest. 
We are now interested in solving optimization problems 
of the type: 
 
min
௪ ∑
𝔼ห𝒅௞(𝑖) − 𝒖௞,௜𝒘ห
ଶ
ே
௞ୀଵ
 
(2) 
The nodes in the network would like to estimate 𝑤௢ by 
solving the equation above in adaptive and collaborative 
manners. We review the diffusion adaptation strategies with 
imperfect information exchange below. 
A. Diffusion Adaptation with Imperfect Information 
Exchange 
Consider the following general adaptive diffusion 
strategies with 𝐶 = 𝐼ே corresponding to the case in which the 
nodes only share the weight estimates for 𝑖 ≥ 0 [21]: 
 
𝝓௞,௜ = ∑
௟ఢ𝒩ೖ 𝑎ଵ,௟௞𝒘௟,௜ିଵ
 
(3) 
 
𝝍௞,௜ = 𝝓௞,௜ିଵ + 𝜇௞𝒖௞,௜
∗ ൣ𝒅௞(𝑖) − 𝒖௞,௜𝝓௞,௜ିଵ൧ 
(4) 
 
𝒘௞,௜ = ∑
௟ఢ𝒩ೖ 𝑎ଶ,௟௞𝝍௟,௜
 
(5) 
The 
scalars 
൛𝑎ଵ,௟௞, 𝑎ଶ,௟௞ ൟ
 are 
non-negative 
real 
coefficients corresponding to the (𝑙, 𝑘)  entries of 𝑁 × 𝑁 
combination matrices {𝐴ଵ, 𝐴ଶ} , respectively. The role of 
these combination matrices is in convergence behavior of the 
diffusion strategy (3)-(5). These coefficients are zero 
whenever node 𝑙 ∉ 𝒩௞, where 𝒩௞ denotes the neighborhood 
of node 𝑘 . These matrices are assumed to satisfy the 
conditions: 
 
𝐴ଵ
்𝕝𝑵 = 𝕝𝑵,           𝐴ଶ
்𝕝𝑵 = 𝕝𝑵 
(6) 
where the notation 𝕝 denotes an 𝑁 × 1 column vector with all 
its entries equal to one. 
We model the noisy data received by node 𝑘 from its 
neighbor 𝑙 as follows (see Figure 1): 
 
𝒘௟௞,௜ିଵ = 𝒘௟,௜ିଵ + 𝒗௟௞,௜ିଵ
(𝒘)
 
(7) 
 
𝝍௟௞,௜ = 𝝍௟,௜ + 𝒗௟௞,௜
(𝝍) 
(8) 
where 𝒗௟௞,௜ିଵ
(௪)
 (𝑀 × 1)  and 𝒗௟௞,௜
(ట) (𝑀 × 1)  are vector noise 
signal. They are temporally white and spatially independent 
random process with zero mean and covariance given by 
ቄ𝑅௩,௟௞
(௪), 𝑅௩,௟௞
(ట)ቅ. The quantities ቄ𝑅௩,௟௞
(௪), 𝑅௩,௟௞
(ట)ቅ are all zero if 𝑙 ∉
𝒩௞ or when 𝑙 = 𝑘. It should be noted that the subscript 𝑙𝑘 
indicates that 𝑙 is the source and 𝑘 the sink, the flow of 
information is from 𝑙 to 𝑘. 
Using the perturbed data (7) and (8), the adaptive 
strategy (3)-(5) becomes 
 
𝝓௞,௜ = ∑
௟ఢ𝒩ೖ 𝑎ଵ,௟௞𝒘௟௞,௜ିଵ
 
(9) 
 
𝝍௞,௜ = 𝝓௞,௜ିଵ + 𝜇௞𝒖௞,௜
∗ ൣ𝒅௞(𝑖) − 𝒖௞,௜𝝓௞,௜ିଵ൧ 
(10) 
 
𝒘௞,௜ = ∑
௟ఢ𝒩ೖ 𝑎ଶ,௟௞𝝍௟௞,௜
 
(11) 
B. Partial-Diffusion with Impeferct Information Exchange  
In order to lower the level of inter-node communication 
required among the nodes, we utilize partial-diffusion 
strategy proposed in [1], to transmit 𝐿 out of 𝑀 entries of the 
intermediate estimates at each time instant where the integer 
𝐿  is fixed and pre-specified. Again, we develop a more 
general class of PDLMS of which [1] is a special case. The 
selection of to-be-transmitted entries at node 𝑘  and time 
instant 𝑖  can be portrayed by an 𝑀 × 𝑀  diagonal entry-
selection matrix, denoted by 𝚲௞,௜, that has 𝐿 ones and 𝑀 − 𝐿 
zeros on its diagonal. The position of ones states the selected 
entries. Multiplication of an intermediate estimate vector by 
this matrix replaces its non-selected entries with zero. 
According to (9) and (11) that can also be expressed as: 
 
 
 
(12) 
 
𝝍௞,௜ = 𝝓௞,௜ିଵ + 𝜇௞𝒖௞,௜
∗ ൣ𝒅௞(𝑖) − 𝒖௞,௜𝝓௞,௜ିଵ൧ 
(13) 
 
 
 
𝝓௞,௜ = 𝑎ଵ,௞௞𝒘௞,௜ିଵ + ∑
𝑎ଵ,௟௞ൣ𝚲௟,௜ିଵ𝒘௟௞,௜ିଵ +
௟ఢ𝒩ೖ∖{௞}
൫𝐼ெ − 𝚲௟,௜ିଵ൯𝒘௟௞,௜ିଵ൧  
𝒘௞,௜ = 𝑎ଶ,௞௞𝝍௞,௜ + ∑
௟ఢ𝒩ೖ∖{௞} 𝑎ଶ,௟௞ൣ𝚲௟,௜𝝍௟௞,௜ +
൫𝐼ெ − 𝚲௟,௜൯𝝍௟௞,௜൧  
20
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

 
l 
k
Source 
𝒗𝑙𝑘,𝑖−1
(𝒘)  
𝝍𝑙𝑘,𝑖 
𝒘𝑙,𝑖−1 
𝝍𝑙,𝑖 
𝒗𝑙𝑘,𝑖
(𝝍) 
𝒘𝑙𝑘,𝑖−1
Sink
𝒗𝑙(𝑖) 
𝒗𝑘(𝑖)
 
 
(14) 
Figure 1.  Several additive nise sources perturb the exchange of 
information from node 𝑙 to node 𝑘. 
Each node needs the information of all entries of its 
neighbors’ intermediate estimate vectors for the consultation 
phase. However, when the intermediate estimates are 
broadcast partially (0 <  𝐿 <  𝑀), nodes have no access to 
the non-communicated entries. To resolve this indistinctness, 
we allow the nodes utilize their own intermediate estimates 
entries instead of ones from the neighbors that have not been 
communicated, i.e., at node 𝑘, substitute 
 
൫𝐼ெ − 𝚲௟,௜ିଵ൯𝒘௞,௜ିଵ          ∀𝑙 ∈ 𝒩௞ ∖ {𝑘} 
(15) 
for 
 
൫𝐼ெ − 𝚲௟,௜ିଵ൯𝒘௟௞,௜ିଵ          ∀𝑙 ∈ 𝒩௞ ∖ {𝑘} 
(16) 
and 
 
൫𝐼ெ − 𝚲௟,௜൯𝝍௞,௜          ∀𝑙 ∈ 𝒩௞ ∖ {𝑘} 
(17) 
for 
 
൫𝐼ெ − 𝚲௟,௜൯𝝍௟௞,௜         ∀𝑙 ∈ 𝒩௞ ∖ {𝑘} 
(18) 
Based on this approach together with using perturbed 
data as introduced in (7) and (8), we formulate general 
PDLMS under noisy exchange as follows: 
 
 
 
 
 
(19) 
 
𝝍௞,௜ = 𝝓௞,௜ିଵ + 𝜇௞𝒖௞,௜
∗ ൣ𝒅௞(𝑖) − 𝒖௞,௜𝝓௞,௜ିଵ൧ 
(20) 
 
 
 
 
 
(21) 
Remark: The probability of transmission for all the entries at 
each node is equal and state as [1], [9] 
 
𝓅 = 𝐿 𝑀
ൗ  
(22) 
Moreover, the entry selection matrices, 𝚲௞,௜, do not rely on 
any data/parameter with the exception of 𝐿 and 𝑀. 
Introduce the following aggregate 𝑀 × 1  zero mean 
noise signals: 
 
𝒗௞,௜ିଵ
(𝒘)
≜ ∑
𝑎ଵ,௟௞𝚲௟,௜ିଵ𝒗௟௞,௜ିଵ
(𝒘)
௟ఢ𝒩ೖ∖{௞}
 
(23) 
 
𝒗௞,௜
(𝝍) ≜ ∑
𝑎ଶ,௟௞𝚲௟,௜𝒗௟௞,௜ିଵ
(𝝍)
௟ఢ𝒩ೖ∖{௞}
 
(24) 
These noises correspond to the cumulative effect on node 𝑘 
of all selected exchange noises from the neighbors of node 𝑘 
while exchanging the estimates ൛𝒘௟,௜ିଵ, 𝝍௟,௜ൟ in the course of 
the two consultation steps. The 𝑀 × 𝑀 covariance matrices 
of these noises are given by: 
 
𝑅௩,௞
(௪) ≜ ∑
𝑎ଵ,௟௞
ଶ
𝚲௟,௜ିଵ𝑅௩,௟௞
(௪)
௟ఢ𝒩ೖ∖{௞}
 
(25) 
 
𝑅௩,௞
(ట) ≜ ∑
𝑎ଶ,௟௞
ଶ
𝚲௟,௜𝑅௩,௟௞
(ట)
௟ఢ𝒩ೖ∖{௞}
 
(26) 
Thus, the PDLMS algorithm, Adapt Then Combine 
(ATC) approach, under noisy information exchange takes the 
following form: 
TABLE I.  
PDLMS ALGORITHM UNDER NOISY INFORMATION 
EXCHANGE 
Initialization: 
Start with 𝒘௞,ିଵ = 0 and given non-negative real coefficient {𝑎௟௞}, 𝐴ଵ = 𝐼ே 
and 𝐴ଶ = 𝐴, satifying (6),  
for 𝑖 ≥ 0, every node k computes 
Step 1: Incremental Phase 
𝝍௞,௜ = 𝒘௞,௜ିଵ + 𝜇௞𝒖௞,௜
∗ ൣ𝒅௞(𝑖) − 𝒖௞,௜𝝓௞,௜ିଵ൧ 
Step 2: Diffusion Phase 
𝒘௞,௜ = 𝑎௞௞𝝍௞,௜ +
෍
𝑎௟௞ൣ𝚲௟,௜𝝍௟௞,௜ + ൫𝐼ெ − 𝚲௟,௜൯𝝍௟௞,௜൧
௟ఢ𝒩ೖ∖{௞}
 
C. Entry Selection Method 
In order to select 𝐿 out of 𝑀 entries of the intermediate 
estimates of each node at each iteration, the methods we 
utilized are comparable to the selection processes in 
stochastic and sequential partial-update schemes [12], [22], 
[23]. Here, we just review these methods namely sequential 
and stochastic partial-diffusion. 
In sequential partial-diffusion the entry selection 
matrices, 𝚲௞,௜, is a diagonal matrix: 
𝚲௞,௜ = ቎
𝓇ଵ,௜
⋯
0
⋮
⋱
⋮
0
⋯
𝓇ெ,௜
቏ ,      𝓇ℓ,௜ = ൜1     𝑖𝑓 ℓ ∈ ℐ(௜ ௠௢ௗ ஻ത)ାଵ
0    𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒               (27) 
with 𝐵ത = ⌈𝑀 𝐿
⁄ ⌉. The number of selection entries at each 
iteration is limited by 𝐿. The coefficient subsets ℐ௜ are not 
unique as long as they meet the following requirements [12]: 
1. Cardinality of ℐ௜ is between 1 and 𝐿; 
2. ⋃
ℐ𝓇 = 𝒮 
஻ത
𝓇ୀଵ
where 𝒮 = {1,2, … , 𝑀}; 
3. ℐ𝓇 ∩ ℐ𝓅 = ∅, ∀𝓇, 𝓅 ∈ {1, … , 𝐵ത} and 𝓇 ≠ 𝓅. 
𝝓௞,௜ = 𝑎ଵ,௞௞𝒘௞,௜ିଵ 
 + ∑
௟ఢ𝒩ೖ∖{௞} 𝑎ଵ,௟௞ൣ𝚲௟,௜ିଵ𝒘௟,௜ିଵ + ൫𝐼ெ −
                𝚲௟,௜ିଵ൯𝒘௞,௜ିଵ൧ + ∑
𝑎ଵ,௟௞𝚲௟,௜ିଵ𝒗௟௞,௜ିଵ
(𝒘)
௟ఢ𝒩ೖ∖{௞}
 
𝒘௞,௜ = 𝑎ଶ,௞௞𝝍௞,௜ 
         + ∑
௟ఢ𝒩ೖ∖{௞} 𝑎ଶ,௟௞ൣ𝚲௟,௜𝝍௟,௜ + ൫𝐼ெ −
             𝚲௟,௜൯𝝍௞,௜൧ + ∑
𝑎ଶ,௟௞𝚲௟,௜𝒗௟௞,௜
(𝝍)
௟ఢ𝒩ೖ∖{௞}
  
21
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

The description of the entry selection matrices, 𝚲௞,௜, in 
stochastic partial-diffusion is similar to that of sequential 
one. The only difference is as follows. At a given iteration, 𝒊, 
sequential case one of the set ℐ𝓇, 𝑟 = 1, … , 𝐵ത is chosen in a 
predetermined fashion, whereas for stochastic case, one of 
the sets ℐ𝓇 is sampled at random from {ℐଵ, ℐଶ, … , ℐ஻ത}. One 
might ask why these methods are considered to organize 
these selection matrices. To answer this question, it is worth 
mentioning that the nodes need to recognize which entries of 
their neighbors’ intermediate estimates have been propagated 
at each iteration. These schemes bypass the need for 
addressing (position in the vector) [1], [9]. 
III. 
STEADY-STATE PERFORMANCE ANALYSIS 
We now move on to examine the behavior of the general 
PDLMS implementations (19)-(21), and the influence of the 
mentioned perturbations on its convergence and steady-state 
performance. For this reason, we shall study the 
convergence of the weight estimates both in the mean and 
mean-square senses. In order to make the analysis tractable, 
we introduce the following assumptions on statistical 
properties of the measurement data and noise signals. 
Assumptions: 
1. The regression data  𝒖௞,௜ are temporally white and 
spatially independent random variables with zero 
mean and covariance matrix 𝑅௨,௞ ≜ Ε𝒖௞,௜
∗ 𝒖௞,௜  ≥ 0. 
2. The noise signal 𝒗௞(𝑖)  , 𝒗௞,௜ିଵ
(௪)  and 𝒗௞,௜
(ట)  are 
temporally white and spatially independent random 
variable with zero mean and covariance 𝜎௩,௞
ଶ , 𝑅௩,௞
(௪) 
and 𝑅௩,௞
(ట) , respectively. In addition, the quantities 
ቄ𝑅௩,௟௞
(௪), 𝑅௩,௟௞
(ట)ቅ are all zero if 𝑙 ∉ 𝑁௞ or when 𝑙 = 𝑘. 
3. The regression data ൛𝒖௠,௜భൟ, the model noise signals 
𝒗௡(𝑖ଶ), and the link noise signals 𝒗௟భ௞భ,௝భ
(௪)
 and 𝒗௟మ௞మ,௝మ
(ట)
 
are mutually independent random variables for all 
indexes {𝑖ଵ, 𝑖ଶ, 𝑗ଵ, 𝑗ଶ, 𝑘ଵ, 𝑘ଶ, 𝑙ଵ, 𝑙ଶ, 𝑚, 𝑛}. 
4. The step-sizes, 𝜇௞  ∀𝑘, are small enough such that 
their squared values are negligible. 
We are interested in examining the evolution of the 
weight-error vectors. To do so, we let: 
 
𝒘෥ ௞,௜ ≜ 𝑤௢ − 𝒘௞,௜ 
(28) 
We import the information from across the network into 
block vectors and matrices as follows: 
 
𝓡௨,௜ ≜ 𝑑𝑖𝑎𝑔൛𝒖ଵ,௜
∗ 𝒖ଵ,௜, 𝒖ଶ,௜
∗ 𝒖ଶ,௜, … , 𝒖ே,௜
∗ 𝒖ே,௜ൟ 
(29) 
 
𝒔௜ ≜ 𝑑𝑖𝑎𝑔൛𝒖ଵ,௜
∗ 𝒗ଵ(𝑖), 𝒖ଶ,௜
∗ 𝒗ଶ(𝑖), … , 𝒖ே,௜
∗ 𝒗ே(𝑖)ൟ 
(30) 
 
𝒗௜
(௪) ≜ 𝑐𝑜𝑙ቄ𝒗ଵ,௜
(௪), 𝒗ଶ,௜
(௪), … , 𝒗ே,௜
(௪)ቅ 
(31) 
 
𝒗௜
(ట) ≜ 𝑐𝑜𝑙ቄ𝒗ଵ,௜
(ట), 𝒗ଶ,௜
(ట), … , 𝒗ே,௜
(ట)ቅ 
(32) 
 
ℳ ≜ 𝑑𝑖𝑎𝑔{𝜇ଵ𝐼ெ, … , 𝜇ே𝐼ெ} 
(33) 
 
𝒘෥ ௜ ≜ 𝑐𝑜𝑙൛𝒘෥ଵ,௜, … , 𝒘෥ ே,௜ൟ 
(34) 
Subsequently, some algebra demonstrates that 
 
 
 
 
 
(35) 
where 
 
𝓐௥,௜ = ቎
Αଵ,ଵ,௜
⋯
Αଵ,ே,௜
⋮
⋱
⋮
Αே,ଵ,௜
…
Αே,ே,௜
቏ , ∀𝑟 ∈ {1,2} 
(36) 
 
𝚨௣,௤,௜ = ቐ
𝐼ெ − ∑
௟ఢே೛∖{௣} 𝑎௥,௟௣𝚲௟,௜  𝑖𝑓 𝑞 = 𝑝
𝑎௥,௤௣𝚲௤,௜               𝑖𝑓 𝑞𝜖𝑁௣ ∖ {𝑝}
𝑂ெ                        𝑜𝑡ℎ𝑒𝑟 𝑤𝑖𝑠𝑒        
 
(37) 
A. Mean Performance 
Taking expectation of both sides of (35) under Remark  
and Assumptions, we find that the mean error vector evolves 
according to the following recursion: 
 
𝔼𝒘෥ ௜ = 𝒬ଶΕ(𝐼ேெ − ℳℛ௨)𝒬ଵ𝔼𝒘෥ ௜ିଵ 
(38) 
where 
 
𝒬ଵ = 𝔼ൣ𝓐ଵ,௜൧,      𝒬ଶ = 𝔼ൣ𝓐ଶ,௜ିଵ൧ 
(39) 
From (38), we observe that in order for the recursion to 
be stable in the mean sense, the matrix 𝒬ଶΕ(𝐼ேெ − ℳℛ௨)𝒬ଵ 
should be stable [24]. Picking 𝒬ଵ  and 𝒬ଶ  which all their 
entries are real non-negative and all their rows add up to 
unity [1]. Therefore, in the light of lemma 1 of [25], mean 
stability and asymptotic unbiasedness of the algorithm is 
guaranteed if the matrix  𝐼ேெ − ℳℛ௨  is stable or 
equivalently if 
 
|𝜆௠௔௫{𝐼ேெ − ℳℛ௨}| < 1 
(40) 
where 𝜆௠௔௫{. } refers to the largest eigenvalue of a matrix. 
The set of the eigenvalue of 𝐼ேெ − ℳℛ௨ is the union of the 
set of the eigenvalue of  𝐼ெ − 𝜇௞𝑅௨,௞ ∀𝑘 [25]. Thus, (40) is 
satisfied 
when ห𝜆௠௔௫൛𝐼ெ − 𝜇௞𝑅௨,௞ൟห < 1, ∀𝑘
 or ห1 −
𝜇௞𝜆௠௔௫൛𝑅௨,௞ൟห < 1, ∀𝑘 . These inequalities determine the 
stability bounds for step-sizes as 
 
0 < 𝜇௞ <
ଶ
ఒ೘ೌೣ൛ோೠ,ೖൟ    ∀𝑘 
(41) 
𝒘෥ ௜ = 𝓐ଶ,௜൫𝐼ேெ − ℳ𝓡௨,௜൯𝓐ଵ,௜ିଵ𝒘෥ ௜ିଵ    
 
−𝓐ଶ,௜൫𝐼ேெ − ℳ𝓡௨,௜൯𝒗௜ିଵ
(௪) − 𝓐ଶ,௜ℳ𝒔௜ − 𝒗௜
(ట)  
22
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

B. Mean-Square Performance 
The weighted variance relation for the error vector 𝒘෥ ௜ 
can be obtained from the error recursion (35) as: 
 
 
 
(42) 
where  Σ  is an arbitrary positive semi-definite Hermitian 
matrix of size 𝑁𝑀 × 𝑁𝑀 and 
 
𝓗௜ ≜ 𝓐ଶ,௜൫𝐼ேெ − ℳ𝓡௨,௜൯ 
(43) 
Furthermore, the matrix  Σ´ can be expressed as 
 
Σ´ ≜ 𝔼𝓑௜
∗Σ𝓑௜ 
(44) 
with 
 
𝓑௜ ≜ 𝓐ଶ,௜൫𝐼ேெ − ℳ𝓡௨,௜൯𝓐ଵ,௜ିଵ 
(45) 
The variance relation becomes 
 
 
 
 
 
 
(46) 
where 
 
𝒟ଵ = 𝔼൫𝓐ଵ,௜ିଵ
்
⨂𝓐ଵ,௜ିଵ
்
൯ 
(47) 
 
𝒟ଶ = 𝔼൫𝓐ଶ,௜
் ⨂𝓐ଶ,௜
் ൯ 
(48) 
 
𝒢 = ℳ𝔼ሾ𝒔௜𝒔௜
∗ሿℳ = 𝑑𝑖𝑎𝑔൛𝜇ଵ𝜎௩,ଵ
ଶ 𝑅௨,ଵ, … , 𝜇ே𝜎௩,ே
ଶ 𝑅௨,ேൟ (49) 
 
ℋ ≜ 𝔼ൣ𝐼ேெ − ℳ𝓡௨,௜൧ = 𝐼ேெ − ℳℛ௨ 
(50) 
 
𝑅௩
(௪) ≜ 𝔼𝒗௜ିଵ
(௪)𝒗௜ିଵ
∗(௪) = 𝑑𝑖𝑎𝑔ቄ𝑅௩,ଵ
(௪), … , 𝑅௩,ே
(௪)ቅ 
(51) 
 
𝑅௩
(ట) ≜ 𝔼𝒗௜
(ట)𝒗௜
∗(ట) = 𝑑𝑖𝑎𝑔ቄ𝑅௩,ଵ
(ట), … , 𝑅௩,ே
(ట)ቅ 
(52) 
Therefore, the steady-state weighted variance relation 
(46) becomes 
lim
௜→ஶ 𝔼‖𝒘෥ ௜‖௨௡௩௘௖ቂቀ୍ొమ౉మି𝒟భൣ𝔼൫ூಿಾି𝓡ೠ,೔ℳ൯⨂൫ூಿಾି𝓡ೠ,೔ℳ൯൧𝒟మ ቁ௩௘௖(ஊ)ቃ
ଶ
 
= ൬𝑣𝑒𝑐்{𝒢}𝒟ଶ + 𝑣𝑒𝑐் ቀℋ𝑅௩
(௪)ℋ∗ቁ 𝒟ଶ + 𝑣𝑒𝑐் ቀ𝑅௩
(ట)ቁ൰ 𝑣𝑒𝑐(Σ) (53) 
It is known that a recursion of type (53) is stable and 
convergent if the matrix 𝒟ଵൣ𝔼൫𝐼ேெ − 𝓡௨,௜ℳ൯⨂൫𝐼ேெ −
𝓡௨,௜ℳ൯൧𝒟ଶ  is stable [24], [26]. All the entries of 𝒟ଵ and 
𝒟ଶ are real non-negative and all its columns sum up to one. 
Moreover, the eigenvalue of 𝒯⨂𝒯  are square of the 
eigenvalue of 𝒯. Therefore, stability of this matrix has the 
same conditions as the stability of 𝐼ேெ − ℛ௨ℳ. This means 
that choosing the step-sizes is accordance with (41) makes 
the algorithm stable likewise in the mean-square sense hence 
convergent to steady state. 
The network MSD is defined as: 
 
MSD୬ୣ୲୵୭୰୩ ≜ lim
௜→ஶ
ଵ
ே ∑
𝔼ฮ𝒘෥ ௞,௜ฮ
ଶ
ே
௞ୀଵ
 
(54) 
Since we are free to choose Σ, we select it as Iேమெమ −
𝒟ଵൣ𝔼൫𝐼ேெ − 𝓡௨,௜ℳ൯⨂൫𝐼ேெ − 𝓡௨,௜ℳ൯൧𝒟ଶ = 𝑣𝑒𝑐(𝐼ேெ/𝑁)  
then the expression (53) gives 
 
 
 
(55) 
 
IV. 
NUMERICAL STUDIES 
In order to illustrate the PLDMS strategies performance 
under noisy information exchange, we present some 
simulation results in this section. 
A. Simulation 
We consider an adaptive network with a random topology 
and 𝑁 = 10 where each node is, in average, connected to 
two other nodes. The unknown parameter 𝑤௢ of length 𝑀 =
8 is randomly generated. We adopt a uniform step-size, 
𝜇௞ = 0.01,  The measurements were generated according to 
model (1), and regressors, 𝒖௞,௜, were chosen Gaussian i.i.d 
with randomly generated different diagonal covariance 
matrices, 𝑅௨,௞. The additive noises at nodes are zero mean 
Gaussian with variances 𝜎௩,௞
ଶ
 and independent of the 
regression data. The traces of the covariance matrix 
regressors and the noise variances at all nodes, 𝑇𝑟൫𝑅௨,௞൯ 
and 𝜎௩,௞
ଶ , are shown in Figure 2. 
We also use white Gaussian link noise signals such that 
𝑅௩,௟௞
(௪) = 𝜎௪,௟௞
ଶ
𝐼ெ and 𝑅௩,௟௞
(ట) = 𝜎ట,௟௞
ଶ
𝐼ெ. All link noise variances 
൛𝜎௪,௟௞
ଶ
, 𝜎ట,௟௞
ଶ
ൟ are randomly generated. The average power 
of each type of link noise across the network is 35 dB less 
than that of the model noise. In Figure 3, we plot the 
experimental network MSD curves for ATC case (𝐴ଵ = 𝐼ே) 
of PDLMS algorithm using both sequential and stochastic 
partial diffusion schemes under noisy information exchange 
for different numbers of entries at each iteration, 𝑀. We use 
uniform weights for ൛𝑎ଵ,௟௞, 𝑎ଶ,௟௞ൟ at combination phase at 
this stage. In Figure 4, we compare network MSD learning 
curve of PDLMS for both ATC and CTA, Combine Then 
Adapt, cases (𝐴ଶ = 𝐼ே) under ideal and noisy links. 
 
𝔼‖𝒘෥ ௜‖ஊ
ଶ = 𝔼‖𝒘෥ ௜ିଵ‖ஊ´
ଶ + 𝔼൫𝒔௜
∗ℳ𝓐ଶ,௜
் Σ𝓐ଶ,௜ℳ𝒔௜൯ 
  +𝔼൫𝒗௜ିଵ
∗(௪)𝓗௜
∗Σ𝓗௜𝒗௜ିଵ
(௪)൯ + 𝔼 ቀ𝒗௜
∗(ట)Σ𝒗௜
(ట)ቁ 
𝔼‖𝒘෥ ௜‖ஊ
ଶ = 𝔼‖𝒘෥ ௜ିଵ‖ஊᇲ
ଶ  
                + ൬𝑣𝑒𝑐்{𝒢}𝒟ଶ + 𝑣𝑒𝑐்൫ℋ𝑅௩
(௪)ℋ∗൯𝒟ଶ
+ 𝑣𝑒𝑐் ቀ𝑅௩
(ట)ቁ൰ 𝑣𝑒𝑐(Σ) 
MSD୧୫୮ୣ୰୤ୣୡ୲
୬ୣ୲୵୭୰୩ =
ଵ
ே ൣ𝑣𝑒𝑐(𝒢)𝒟ଶ + 𝑣𝑒𝑐(ℋ𝑅௩
௪ℋ∗)𝒟ଶ +
𝑣𝑒𝑐൫𝑅௩
(ట)൯൧
்(𝐼ேమெమ − ℱ)ିଵvec(𝐼ேெ)  
23
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

 
 
Figure 2.  Covariance matrix trace of the input signal and the variance of 
the noise at each node. 
 
Figure 3.  Network MSD learning curve of PDLMS for ATC under noisy 
links (top) sequential and (bottom) stochastic. 
B. Discussion 
From the simulation results, we make the following 
observations: 
In  [1], authors emphasized that the PDLMS algorithm 
delivers a trade-off between communications cost and 
estimation performance. However, noisy links add a new 
complexity to the network optimization problem. In 
addition, in the presence of noisy links, the trade-off 
between communication cost and estimation performance 
becomes unbalanced. This is because as more entries are 
broadcast at each iteration, more perturbed weight estimates 
are interred in consultant phase.   
The sequential partial-diffusion schemes outperform the 
stochastic partial-diffusion. Finally, the adaptive ATC 
strategy outperforms the adaptive CTA strategy for both 
perfect and imperfect cases. 
 
 
Figure 4.  Comparison of network MSDs of sequential PDLMS algorithm 
for (top) ATC and (bottom) CTA under noisy information exchange  
V. 
CONCLUSION 
In this work, we presented a general form of PDLMS 
algorithms, formulated the ATC and CTA versions of 
PDLMS 
under 
noisy 
Links, 
and 
investigated 
the 
performance of partial-diffusion algorithms under several 
sources of noise during information exchange for both 
sequential and stochastic schemes. We also illustrated that 
the PDLMS strategy could still stabilize the mean and mean-
square convergence of the network with noisy information 
exchange. We derived analytical expressions for network 
learning curve MSD. The important result is that the noisy 
links are the main factor in performance degradation of a 
diffusion LMS strategy running in a network with imperfect 
communication. Furthermore, there is no direct relation 
between the MSD performance and number of selected 
entries 
under 
imperfect 
information 
exchange. 
The 
performance degradation incurred by noisy links depends not 
only on the link noise variances, 𝜎௪,௟௞
ଶ
 and 𝜎ట,௟௞
ଶ
, but also on 
the other parameters of the network, i.e., the measurement 
and state noise variances, the network topology, and 
combination weights. These topics will be addressed in 
future work. 
REFERENCE 
[1] 
R. Arablouei, S. Werner, Y.-F. Huang, and K. Dogancay, 
“Distributed least mean-square estimation with partial diffusion,” 
Signal Process. IEEE Trans., vol. 62, no. 2, pp. 472–484, 2014. 
[2] 
V. Vahidpour, A. Rastegarnia, A. Khalili, and S. Sanei, “Analysis of 
partial diffusion recursive least squares adaptation over noisy links,” 
IET Signal Process., 2017. 
[3] 
V. Vahidpour, A. Rastegarnia, A. Khalili, and S. Sanei, “Partial 
24
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

Diffusion Kalman Filtering for Distributed State Estimation in 
Multiagent Networks,” Neural Networks Learn. Syst. IEEE Trans., 
2019. 
[4] 
E. E. Tsiropoulou, S. T. Paruchuri, and J. S. Baras, “Interest, energy 
and physical-aware coalition formation and resource allocation in 
smart IoT applications,” in 2017 51st Annual Conference on 
Information Sciences and Systems (CISS), 2017, pp. 1–6. 
[5] 
M. O. Sayin and S. S. Kozat, “Compressive diffusion strategies over 
distributed networks for reduced communication load,” Signal 
Process. IEEE Trans., vol. 62, no. 20, pp. 5308–5323, 2014. 
[6] 
M. O. Sayin and S. S. Kozat, “Single bit and reduced dimension 
diffusion strategies over distributed networks,” Signal Process. Lett. 
IEEE, vol. 20, no. 10, pp. 976–979, 2013. 
[7] 
S. Chouvardas, K. Slavakis, and S. Theodoridis, “Trading off 
complexity with communication costs in distributed adaptive 
learning via Krylov subspaces for dimensionality reduction,” Sel. 
Top. Signal Process. IEEE J., vol. 7, no. 2, pp. 257–273, 2013. 
[8] 
R. Arablouei, K. Dogancay, S. Werner, and Y.-F. Huang, “Adaptive 
distributed estimation based on recursive least-squares and partial 
diffusion,” Signal Process. IEEE Trans., vol. 62, no. 14, pp. 3510–
3522, 2014. 
[9] 
V. Vahidpour, A. Rastegarnia, A. Khalili, W. M. Bazzi, and S. 
Sanei, “Analysis of Partial Diffusion LMS for Adaptive Estimation 
Over Networks with Noisy Links,” IEEE Trans. Netw. Sci. Eng., 
2017. 
[10] J. R. Deller Jr and Y. F. Huang, “Set-membership identification and 
filtering for signal processing applications,” Circuits, Syst. Signal 
Process., vol. 21, no. 1, pp. 69–82, 2002. 
[11] S. Gollamudi, S. Nagaraj, S. Kapoor, and Y.-F. Huang, “Set-
membership filtering and a set-membership normalized LMS 
algorithm with an adaptive step size,” Signal Process. Lett. IEEE, 
vol. 5, no. 5, pp. 111–114, 1998. 
[12] K. Dogancay, Partial-update adaptive signal processing: Design 
Analysis and Implementation. Academic Press, 2008. 
[13] S. Werner, T. Riihonen, and Y.-F. Huang, “Energy-efficient 
distributed parameter estimation with partial updates,” in Green 
Circuits and Systems (ICGCS), 2010 International Conference on, 
2010, pp. 36–40. 
[14] S. Werner and Y.-F. Huang, “Time-and coefficient-selective 
diffusion strategies for distributed parameter estimation,” in Signals, 
Systems and Computers (ASILOMAR), 2010 Conference Record of 
the Forty Fourth Asilomar Conference on, 2010, pp. 696–697. 
[15] A. Malipatil, Y.-F. Huang, and S. Werner, “An SMF approach to 
distributed average consensus in clustered sensor networks,” in 
Signal Processing Advances in Wireless Communications, 2009. 
SPAWC’09. IEEE 10th Workshop on, 2009, pp. 81–85. 
[16] R. Abdolee and B. Champagne, “Diffusion LMS algorithms for 
sensor networks over non-ideal inter-sensor wireless channels,” in 
Distributed Computing in Sensor Systems and Workshops (DCOSS), 
2011 International Conference on, 2011, pp. 1–6. 
[17] A. Khalili, M. A. Tinati, and A. Rastegarnia, “Performance analysis 
of distributed incremental LMS algorithm with noisy links,” Int. J. 
Distrib. Sens. Networks, vol. 2011, 2011. 
[18] A. Khalili, M. A. Tinati, A. Rastegarnia, and J. Chambers, “Steady-
state analysis of diffusion LMS adaptive networks with noisy links,” 
Signal Process. IEEE Trans., vol. 60, no. 2, pp. 974–979, 2012. 
[19] A. Khalili, M. A. Tinati, A. Rastegarnia, and J. A. Chambers, 
“Transient analysis of diffusion least-mean squares adaptive 
networks with noisy channels,” Int. J. Adapt. Control Signal 
Process., vol. 26, no. 2, pp. 171–180, 2012. 
[20] X. Zhao, S.-Y. Tu, and A. H. Sayed, “Diffusion adaptation over 
networks under imperfect information exchange and non-stationary 
data,” Signal Process. IEEE Trans., vol. 60, no. 7, pp. 3460–3475, 
2012. 
[21] A. H. Sayed, “Adaptive Filters. Hoboken.” NJ: John Wiley & Sons, 
2008. 
[22] A. H. Sayed, “Diffusion adaptation over networks,” Acad. Press 
Libr. Signal Process., vol. 3, pp. 323–454, 2013. 
[23] M. Godavarti and A. O. Hero III, “Partial update LMS algorithms,” 
Signal Process. IEEE Trans., vol. 53, no. 7, pp. 2382–2399, 2005. 
[24] C. D. Meyer, Matrix analysis and applied linear algebra, vol. 2. 
Siam, 2000. 
[25] F. S. Cattivelli and A. H. Sayed, “Diffusion LMS strategies for 
distributed estimation,” Signal Process. IEEE Trans., vol. 58, no. 3, 
pp. 1035–1048, 2010. 
[26] K. M. Abadir and J. R. Magnus, Matrix algebra, vol. 1. Cambridge 
University Press, 2005. 
 
 
25
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-719-1
ICWMC 2019 : The Fifteenth International Conference on Wireless and Mobile Communications

