A Review of Universal Design in
Ambient Intelligence Environments
Aleksander Bai, Heidi Camilla Mork, Till Halbach,
Kristin S. Fuglerud, Wolfgang Leister, Trenton Schulz
Norwegian Computing Center, Oslo, Norway
Email: {aleksander.bai, heidi.mork, kristin.skeide.fuglerud
till.halbach, wolfgang.leister, trenton.schulz}@nr.no
Abstract—This work summarizes the state of research in uni-
versal design in ambient intelligence environments. We provide a
detailed background, specify relevant research areas, and review
research in these areas. We discuss the ﬁndings and put them
into perspective with regard to universal design and accessibility
in smart environments, and point out research shortcomings
concerning ambient intelligence and hybrid interactions. Our
ﬁndings show that the majority of related work needs stronger
emphasis on aspects related to universal design in general; univer-
sal design in ambient intelligence; universal design in multimodal
interactions; and universal design in security, privacy, and other
ethical aspects of smart environments.
Keywords—Universal design; ambient intelligence; multimodal
interaction
I. INTRODUCTION
The United Nations Convention on the Rights of Persons
with Disabilities (CRPD) [1] aims to ensure that people
with disabilities can enjoy the full range of human rights:
civil, political, economic, social, and cultural. Besides the
requirements for accessible ICT (Article 2), the Convention
refers to universal design (UD) as a means to achieve this goal
(Article 4). UD is the design of products and environments to
be usable by all people, to the greatest extent possible, without
the need for adaptation or specialized design [2].
Universally designed smart environments have the potential
to improve the mental and social well-being of individuals
as well as their economy. People with disabilities will have
increased independence with a reduced need for aid, other
support services, and personal assistants. Smart environments
in the workplace mean that a person with disabilities can get
work experience early on. This has a direct positive effect
for the person and increases the probability of being in the
workforce and contributing to society in the future [3].
Stevenson and McQuivey [4] ﬁnd that 57% of working-
age people with mild to severe difﬁculties or impairments are
likely or very likely to beneﬁt from accessible technologies
when they use computers. The increased social, cultural, and
economic participation of this group is likely to improve their
health, which in turn inﬂuences their human and economic
development positively [5]. Looking at the economic side,
the participation of a larger part of the population in the
workforce – including people with disabilities – is the key
to fostering economic growth: a larger workforce should lead
to increased tax incomes and reduced welfare and health
expenses. Creating structures and systems to accommodate
people with disabilities facilitates the retention and return to
work of other workers as well [5].
Yet the focus for smart environments or ambient intelligence
(AmI) has mainly been on technology and its capabilities.
User-centric design and accessibility are often neither part of
the design nor the evaluation process [6]. A vital part of AmI
environments implements interactions between users and the
environment. To make these interactions accessible and usable
for diverse people (all people, including people with different
types of disabilities) the interfaces must be ﬂexible and offer
interaction through different types of modalities [7].
Although multimodal interactions constitute an important
concept in universally designed AmI, many AmI solutions lack
the aspect of multimodality. It seems we are long way from
the disappearing computer scenario proposed by Weiser [8].
In this scenario, devices are concealed into everyday objects
and everyday interaction modalities, and people spontaneously
interact with digital objects as they do with physical ones.
We refer to a combined physical and digital environment
as a hybrid environment. A universally designed hybrid envi-
ronment enhances the surroundings with ambient intelligence
and digital interfaces so humans can interact according to their
abilities and preferences. In this context, a hybrid interaction
may comprise of both input and output in various modalities
and interaction types.
The remainder of the paper is organized as follows: After
a summary of the current knowledge state within ambient
intelligence and multimodal interactions (Sections II and III)
we discuss the challenges of universal design in ambient
intelligence and multimodal interactions (Section IV). Finally,
we highlight research directions (Section V).
II. AMBIENT INTELLIGENCE
Ducatel et al. [9] deﬁne Ambient Intelligence (AmI) as a
smart environment that supports its inhabitants. The vision
for AmI is an environment that is unobtrusive, interconnected,
adaptive, dynamic, embedded, and intelligent. Instead of com-
municating through a keyboard, mouse, and screen, people
use implicit interaction with the objects in the environment
[10], such as light sources, furniture, or household devices.
The devices themselves can communicate with each other
through the Internet of Things (IoT) to facilitate collaborative
assistance of the environment. Other visions for AmI include
6
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-525-8
SMART ACCESSIBILITY 2016 : The First International Conference on Universal Accessibility in the Internet of Things and Smart Environments

that AmI environments can anticipate and predict the people’s
needs and behavior and provide services or interactions in
people’s preferred way [11].
AmI has become a complex, multidisciplinary research
ﬁeld and consists of several domains. There are multiple
deﬁnitions of how AmI can support its inhabitants, but intelli-
gent reasoning, multimodal interfaces, sensors and ubiquitous
computing are elements that are usually required for an AmI.
The development of AmI’s requires specialists from ﬁelds like
information and communication technology (ICT), psychol-
ogy, social sciences, engineering, design, security, privacy, and
humanities.
Kodratoff and Michalski [12] presents intelligent reasoning
as a broad ﬁeld built on well established theories and methods
with machine learning at its core. Mikolov et al. [13] point out
that building an intelligent reasoning system must incorporate
many parts like models of human behavior, predictions about
human actions, user preferences, large amounts of sensor data,
and machine learning.
To personalize the environment for a speciﬁc person or
group of people, a proﬁle is usually built, based on the person’s
abilities and needs, preferences, context, and history. Large
variations in what to store in a proﬁle and how to apply the
proﬁle in a given context have been shown by van Otterlo
[14]. Koller and Friedman [15] suggest using probabilistic
models like Bayesian or Markov networks. These models can
predict how likely someone wants to turn on the light, or how
likely someone wants to use voice modality instead of textual
modality.
Instead of modelling the probabilistic distribution of the
data, a common approach is to look at the similarities between
the examples using kernel methods. Bishop [16] deﬁnes a
kernel as a collections of algorithms that look at the differences
(more formally: distances) between examples in complex data
structures. Possible methods suggested by Bishop include
support vector machine (SVM) and principal components
analysis (PCA).
In the ﬁeld of human behavior and prediction, much work
has been done on modelling human behavior with statistical
models within machine learning algorithms [17]. However,
due to the curse of dimensionality [18] that occurs when
analysing high-dimensional spaces, the statistical models of
people and their behavior are often too simplistic. Instead
of only using statistical models, studies by Rosenfeld et al.
[19] and An [20] have combined psychological models with
machine learning and achieved good results in more complex
domains. Another method used by Panagiotou et al. [21]
is to apply machine learning algorithms to sensory data in
combination with personal data. A more recent approach for
personalization is to build a model for each user from a
large dataset. Ghahramani [22] call this the personalization of
models. Suitable methods for solving these problems include
hierarchical Dirichlet processes [23] and Bayesian multitask
learning [24].
For an intelligent system to learn and adjust to users, it
needs information from sensors, actuators, and monitoring
tools. Liu et al. [25] have connected sensor output to high-
level intelligence, and Sun et al. [26] have worked on pre-
dicting human routines from sensor data. Deep learning and
convolutional recurrent neural networks have lately gained
much attention in voice and image recognition, but have also
given results in activity recognition as shown by Ord´o˜nez and
Roggen [27]. Wiering and van Otterlo [28] have used rein-
forcement learning and feedback loops in a learning system.
A vital part of reinforcement learning is the reward function
that motivates model adjustment. Barto [29] has incorporated
human motivation into these models.
There are several AmI frameworks. Karakostas et al. [30]
created a sensor-based framework for supporting clinicians in
dementia assessment with several wearable sensors used on
the patients. Blackman et al. [31] identiﬁed 59 technologies
that have been developed for ambient assisted living for the
elderly. They also indicate that more research should be done
on middleware and integration.
Home environment is probably the most dominant area of
application for AmI. Often described as smart or intelligent
homes, the integration and utilization of multiple sensors are
the center of attention. The goal is to improve quality of
life by performing everyday tasks automatically and improve
safety by preventing and detecting accidents. For instance, an
oven can be equipped with a database of recipes with oven
temperature, timing, and method of heating, as demonstrated
in the GENIO Project [32].
Ambient assisted living for elderly is another application
area in AmI. The goal is to increase the quality of life by
providing health care in domestic homes. Kientz et al. [33]
show how AmI can monitoring medication use and alert
caretakers in case of a person’s fall. Other AmI application
areas include shops, museums and driving [11]. Lately, also the
working environment has seen some progress, with the goal to
get more people back to work and to accommodate people at
work. The SMARTDISABLE Project aims at including people
with disabilities in the workplace by means of ICT equipment
with voice control [34]. Another example is a fatigue-sensitive
chair aimed at workplaces to alert the user to rest or take a
break [35].
Despite many promising applications, only a few evalua-
tions show how AmI solutions works in practice. G¨overcin
et al. [36] conducted a study with 35 households as part
of the SmartSenior@home project, but there are few other
evaluations at this scale. There are also few studies that involve
real users in the evaluation phase. Often, as shown by Wilson
et al. [37], the results show a mismatch between expectations
from the users and the developers and designers.
III. MULTIMODAL INTERACTIONS
Humans interact with the world in a multimodal way by
using multiple perceptual modalities, both in parallel and
sequentially. Turk [38] introduces the concept of multimodal
human-computer interaction (HCI) as the attempt to provide
similar capabilities to computers, and multimodal interfaces
are intended to deliver more natural and efﬁcient interaction.
7
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-525-8
SMART ACCESSIBILITY 2016 : The First International Conference on Universal Accessibility in the Internet of Things and Smart Environments

Jaimes and Sebe [39] deﬁne a multimodal HCI system as
one that responds to input in more than one modality, where
modality is understood as communication according to human
senses. We would extend the deﬁnition of multimodal inter-
faces to include input and output in more than one modality.
There is extensive research on interactions with modalities
like visual, auditory, cognitive, touch, gesture, reach, and
tactile. Covering all of them is beyond the scope of this
paper, but some concepts that have shown good results across
different modalities are mentioned here: Ullmer and Ishii
[40] deﬁne a tangible user interface as an interface that
couples physical representations with digital representations in
a way that leads to interactive systems mediated by computers,
and not identiﬁable as computers. The various meanings of
tangible interactions in different science ﬁelds are summarized
by Hornecker and Buur [41], and common characteristics
are tangibility and materiality, physical embodiment of data,
embodied interaction, and integration in real space. Recent
research on tangible user interfaces includes work on haptics to
improve the use of touch screens by Zimmermann et al. [42],
and work by Bianchi and Oakley [43] on the use of magnetic
appcessories, i.e., robust physical interfaces with magnets in
interaction with a mobile phone and its built-in magnetometer.
Ferati et al. [44] studied the design of audemes (short
non-speech sound symbols composed of music and sound-
effects) with the goal of highest possible meaning recognition.
Audemes can be used as a complement to visual output and to
leverage more of the auditory capacities of people with vision
impairments. The use of auditory modalities is useful in many
case, for instance in eyes-free activities like driving or running.
Rohani Ghahari et al. [45] study how one can browse the web
on mobile devices with aural ﬂows.
Takeuchi [46] has done work on digitizing architectural
spaces, but there are no studies that try to bring the different
architectural concepts together to facilitate multimodal inter-
actions. In addition, Takeuchi [46] has proposed habitable user
interfaces (HUIs) intended to fulﬁll the disappearing computer
vision by digitalizing the environment. Here, the environment
can be as easily transformed as changing the desktop wallpaper
background on a modern computer. However, more studies
that try to integrate all the different concepts into a complete
environment are needed.
In a universally designed AmI environment, multimodal
interactions are critical for adaptation purposes. Oviatt [47]
and Obrenovic et al. [48] found that interfaces must handle
multimodal input and output depending on a person’s personal
abilities, preferences, and the environmental conditions. The
use of multimodal interfaces is one step towards universally
designed interaction, but the interaction still must be usable
and accessible. For example, a person must understand that
a modality (e.g., auditory interaction) is available and know
how to use it; the availability of a modality is not enough.
Fuglerud [7] found that introducing several modalities into
an interface may make it more complex and, thus, less usable.
Much work has been done on multimodal interaction and
human-computer interaction, but Turk [38] found that only a
minority of these studies focus on UD. Moustakas et al. [49]
found that the translation from one modality to the other, an
essential part of universally designed multimodal interfaces, is
often limited to vision and voice modalities. Alce et al. [50]
noted that more studies including diverse people and a larger
number of participants is needed.
Homola et al. [51] found that when several humans are in
one AmI environment, several types of conﬂicts can occur,
from modality conﬂicts to goal and action conﬂicts. Resendes
et al. [52] list the extensive research on resolving such con-
ﬂicts, but Carreira et al. [53] point out that little work has
been done with multimodal output conﬂicts. Also, usability
and UD have not been focused on. For effectively working
AmI environments, these challenges need to be solved.
IV. DISCUSSION
The idea of UD in AmI is to increase the degree of inclusion
and life quality for users. As illustrated in Figure 1, the core
entities are diverse people & UD (in the middle), hybrid
interactions, ambient intelligence, and things & environment.
These entities interact with each other, and UD is the key
component that is infused in all the components.
Hybrid interactions, i.e., interactions between a user and
digital and physical things in the environment must be adjusted
for each user, based on preferences and abilities (proﬁles). The
AmI will try to predict the best combination of interaction
types and modalities for a given user or group of users. For
instance, an older person with impaired hearing might prefer
to speak actions out loud, but receive information visually in
large type. This combination of interactions, however, might
not be suitable for someone with vision impairment who may
prefer to receive information as audio or tactile feedback
depending on the context.
Figure 1. The core elements of universal design in ambient intelligence,
and how they are interconnected.
The AmI must learn from previous interactions and associ-
ated contexts to improve and validate further predictions. Some
things, like a smart rug, might not be able to use audio for
interaction, while a talking door could support both visual and
8
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-525-8
SMART ACCESSIBILITY 2016 : The First International Conference on Universal Accessibility in the Internet of Things and Smart Environments

auditory interaction, but may not support tactile interaction. To
our knowledge, research in AmI has not yet considered UD
combined with human behavior and interaction prediction.
As illustrated in Figure 1, UD must be included in all parts
of an AmI environment if the vision of AmI is to be fulﬁlled.
As Wilson et al. [37] points out, most of the current AmI
research does not have a clear understanding of who the users
are and what their needs are, and this must get a stronger focus
in the research fulﬁll the AmI vision.
O Shea et al. [54] note that the common approach for
measuring UD is the use of checklists and expert evaluations
as well as lab experiments, which are less feasible for practi-
tioners. There are signiﬁcant challenges in studying the impact
of UD in the ﬁeld, e.g., in buildings. Some of the difﬁculties
include controlling for factors that may introduce confound-
ing inﬂuences, e.g., the age of a building, occupancy type,
activities occurring in the building, and its size. Sometimes,
these issues have been resolved by conducting controlled
experiments, or by comparing speciﬁc features in buildings,
rather than evaluating the overall effect in the building.
The participants activity index documented by Danford
et al. [55] is an example of a quantitative evaluation method.
By means of crowdsourcing, Holone [56] found that users can
play a central role in providing the accessibility information by
using mobile apps. Moreover, Varela et al. [57] are considering
autonomous evaluation, but current research appears to prefer
conventional user interfaces rather than interactions. There is
a need for research on methods and effective data gathering
techniques for evaluating UD in AmI.
A. UD in ambient intelligence
Concerning the design of smart environments, Queir´os et al.
[6] posits that the limits of technology have been studied rather
than the actual people’s needs. Tavares et al. [58] is working on
ontologies for accessibility, and Catenazzi et al. [59] proposed
guidelines for inclusive intelligent environments. More studies
that focus on human-centered design and on meeting user
needs are called for in the AmI literature [37], [6], [60]. There
is also a lack of evaluations including people with disabilities
and evaluations in real-life environments.
Corno et al. [61] has proposed a set of design guidelines
for user conﬁdence in AmI environments. But there is little
work on the cognitive and social aspects in the design of AmI
environments nor how cognitive and social aspects can be
combined with technology requirements.
Olaru et al. [62] list many AmI system architectures, but
not many consider accessibility or UD as part of the system
architecture. One platform that has a large community is
the Global Public Inclusive Infrastructure (GPII) for making
digital technologies more accessible by providing adaptive
user interfaces in a cloud based infrastructure [63]. Other
frameworks involving UD in AmI environments should be
proposed and evaluated.
Currently, there is a lack of research regarding multiple
cultures. Kaiying et al. [64] notes that most studies have been
conducted in Western countries with a differing view on AmI
as compared to non-Western countries. Hence, all cultures
should be represented throughout the design, development, and
evaluation phase of universally designed solutions.
B. UD in multimodal interactions
The UD aspect of multimodal interactions is deﬁcient in the
research, and Turunen et al. [60] requests studies that are more
human oriented. This includes ﬁnding the best combination
of multimodal interaction types and modalities for universally
designed AmI environments [65]. Both the accessibility and
the feasibility of possible interactions must be evaluated with
broadly diversiﬁed users and cultures to evaluate what works
best in practice.
While there are studies for multimodal output conﬂict
resolution, the focus has not been on usability or UD [53]. If
multiple interactions in different modalities are to be realized
in an AmI environment, then more user studies must be done
to evaluate conﬂict resolutions.
C. UD in security, privacy, and ethical aspects of AmI
Venkatesh et al. [66] details security-related work in AmI
environments, and He and Zeadally [67] document how to
provide secure system authentication. To preserve privacy
within AmI, Gope and Hwang [68] propose architectures for
ensuring that sensory output is untraceable. Sicari et al. [69]
list projects that address general privacy and security aspects
in the IoT.
Even though Nurse et al. [70] stress that usability is impor-
tant for security, Realpe et al. [71] point out that UD has not
been a focus area. Fritsch et al. [72] show that UD introduces
additional challenges in relation to personalization, privacy,
and the design of the security mechanisms themselves. Privacy
is paramount when users interact with ambient environments.
There is a need for anonymity and pseudo-anonymity, exem-
pliﬁed by systems which give people the choice to opt-in for
the disclosure of their proﬁle and data to the services. We did
not ﬁnd research that considers universally designed security
and privacy solutions in the context of AmI and interactions.
Further, a review by Novitzky et al. [73] ﬁnds that ethical
questions have not been a research focus of AmI and ambient
assisted living; more research is clearly needed. Bibri [74]
has suggested to implement safeguards for protecting privacy,
but there is a lack of research not on how to incorporate
ethical concerns during the development process in general and
on ethics in combination with AmI and hybrid interactions.
There is a need for research on how AmI solutions may
affect autonomy, integrity, dignity, human contact, and human
relations.
V. CONCLUSION AND FUTURE WORK
We have given an overview and highlighted some important
issues and new areas for research in the ﬁeld of universal
design in AmI environments. Clearly, much research work
remains. This view is also supported by several studies that
point out the failure of meeting user needs. Even though
there are guidelines for designing inclusive AmI solutions,
9
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-525-8
SMART ACCESSIBILITY 2016 : The First International Conference on Universal Accessibility in the Internet of Things and Smart Environments

there are very few user studies of AmI in general. There are
even fewer studies that evaluate the AmI solutions for users
with disabilities. Therefore, future work should develop AmI
solutions that consider the full spectrum of user abilities and
involves a number of diverse user groups throughout the entire
development process, including users from different cultures.
It would be interesting to see more automated evaluation
methods for measuring the effect of UD and usability in AmI
environments. Methods like crowdsourcing and autonomous
data gathering are possible ways to measure UD, and we
believe that a higher degree of automation could in turn
stimulate more user studies.
From our literature search, no AmI research has considered
UD combined with human behavior and interaction prediction.
Further, there seems to be a need for research on ethical and
social aspects of AmI solutions.
Finally, security and privacy issues abound in AmI environ-
ments. Particularly, security and privacy mechanisms must be
reliable and usable for diverse people. Future research should
contribute to the development of novel, universally designed
security mechanisms that offer comparable protection for all
users as current regular systems.
ACKNOWLEDGMENT
This work has been supported by the UDiAide project
funded by Research Council of Norway in the IKTPLUSS
programme, grant number 255146.
REFERENCES
[1] CRPD, United Nations, and UN, “Convention on the rights of persons
with disabilities,” 2006.
[2] R. Mace, “What is universal design,” The Center for Universal Design at
North Carolina State University. Retrieved Retrieved November, vol. 19,
1997, p. 2004.
[3] R. C. Schreiner, S. Markussen, and K. Røed, “Sysselsetting blant
funksjonshemmede,” Ragnar Frisch Centre for Economic Research,
University of Oslo, Tech. Rep., 2014, in Norwegian.
[4] B. Stevenson and J. L. McQuivey, “The wide range of abilities and its
impact on computer technology,” commissioned by Microsoft Corpora-
tion and conducted by Forrester Research, research study, 2003.
[5] L. M. Banks and S. Polack, “The economic costs of exclusion and
gains of inclusion of people with disabilities,” CBM, International Centre
for Evidence in Disability and London School of Hygiene & Tropical
Medicine, 2014.
[6] A. Queir´os, A. Silva, J. Alvarelh˜ao, N. P. Rocha, and A. Teixeira, “Us-
ability, accessibility and ambient-assisted living: a systematic literature
review,” Universal Access in the Information Society, vol. 14, no. 1,
2015, pp. 57–66.
[7] K. S. Fuglerud, “The challenge of diversity in universal design of ICT,”
Ph.D, University of Oslo, 2014.
[8] M. Weiser, “The computer for the 21st century,” Scientiﬁc American,
vol. 265, no. 3, 1991, pp. 94–104.
[9] K. Ducatel, M. Bogdanowicz, F. Scapolo, J. Leijten, and J.-C. Burgel-
man, “Ambient intelligence: From vision to reality,” IST Advisory Group
Draft Report, European Commission, 2003.
[10] A. Schmidt, “Implicit human computer interaction through context,”
Personal technologies, vol. 4, no. 2-3, 2000, pp. 191–199.
[11] F. Sadri, “Ambient intelligence: A survey,” ACM Computing Surveys
(CSUR), vol. 43, no. 4, 2011, p. 36.
[12] Y. Kodratoff and R. S. Michalski, “Machine learning: an artiﬁcial
intelligence approach”.
Morgan Kaufmann, 2014, vol. 3.
[13] T. Mikolov, A. Joulin, and M. Baroni, “A roadmap towards machine
intelligence,” arXiv preprint arXiv:1511.08130, 2015.
[14] M. van Otterlo, “A machine learning view on proﬁling”.
Routledge,
2013, pp. 41–64.
[15] D. Koller and N. Friedman, “Probabilistic graphical models: principles
and techniques”.
MIT press, 2009.
[16] C. M. Bishop, “Pattern recognition,” Machine Learning, 2006.
[17] A. Azaria, Y. Gal, S. Kraus, and C. V. Goldman, “Strategic advice
provision in repeated human-agent interactions,” Autonomous Agents
and Multi-Agent Systems, vol. 30, no. 1, 2016, pp. 4–29.
[18] R. Bellman, “Dynamic programming princeton university press,” Prince-
ton, NJ, 1957.
[19] A. Rosenfeld, I. Zuckerman, A. Azaria, and S. Kraus, “Combining
psychological models with machine learning to better predict people’s
decisions,” Synthese, vol. 189, no. 1, 2012, pp. 81–93.
[20] L. An, “Modeling human decisions in coupled human and natural
systems: review of agent-based models,” Ecological Modelling, vol. 229,
2012, pp. 25–36.
[21] C. Panagiotou, T. Panagiotakopoulos, and A. Kameas, “A multi: modal
decision making system for an ambient assisted living environment,”
in Proceedings of the 8th ACM International Conference on PErvasive
Technologies Related to Assistive Environments.
ACM, 2015, p. 44.
[22] Z. Ghahramani, “Probabilistic machine learning and artiﬁcial intelli-
gence,” Nature, vol. 521, no. 7553, 2015, pp. 452–459.
[23] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei, “Hierarchical
dirichlet processes,” Journal of the american statistical association, 2012.
[24] N. Houlsby, F. Huszar, Z. Ghahramani, and J. M. Hern´andez-lobato,
“Collaborative gaussian processes for preference learning,” in Advances
in Neural Information Processing Systems, 2012, pp. 2096–2104.
[25] Y. Liu, L. Nie, L. Liu, and D. S. Rosenblum, “From action to activity:
Sensor-based activity recognition,” Neurocomputing, 2015.
[26] F.-T. Sun, Y.-T. Yeh, H.-T. Cheng, C.-C. Kuo, and M. Griss, “Non-
parametric discovery of human routines from sensor data,” in Pervasive
Computing and Communications (PerCom), 2014 IEEE International
Conference on.
IEEE, 2014, pp. 11–19.
[27] F. J. Ord´o˜nez and D. Roggen, “Deep convolutional and lstm recurrent
neural networks for multimodal wearable activity recognition,” Sensors,
vol. 16, no. 1, 2016, p. 115.
[28] M. Wiering and M. van Otterlo, “Reinforcement learning,” Adaptation,
Learning, and Optimization, vol. 12, 2012.
[29] A. G. Barto, “Intrinsic motivation and reinforcement learning,” in Intrin-
sically motivated learning in natural and artiﬁcial systems.
Springer,
2013, pp. 17–47.
[30] A. Karakostas, G. Meditskos, T. G. Stavropoulos, I. Kompatsiaris, and
M. Tsolaki, “A sensor-based framework to support clinicians in dementia
assessment: The results of a pilot study,” in Ambient Intelligence-
Software and Applications.
Springer, 2015, pp. 213–221.
[31] S. Blackman, C. Matlo, C. Bobrovitskiy, A. Waldoch, M. L. Fang,
P. Jackson, A. Mihailidis, L. Nyg˚ard, A. Astell, and A. Sixsmith,
“Ambient assisted living technologies for aging well: a scoping review,”
Journal of Intelligent Systems, vol. 25, no. 1, 2016, pp. 55–69.
[32] A. G´arate, N. Herrasti, and A. L´opez, “Genio: an ambient intelligence
application in home automation and entertainment environment,” in
Proceedings of the 2005 joint conference on Smart objects and ambient
intelligence: innovative context-aware services: usages and technologies.
ACM, 2005, pp. 241–245.
[33] J. A. Kientz, S. N. Patel, B. Jones, E. Price, E. D. Mynatt, and G. D.
Abowd, “The georgia tech aware home,” in CHI’08 extended abstracts
on Human factors in computing systems.
ACM, 2008, pp. 3675–3680.
[34] G. Kbar and S. Aly, “Smart workplace for persons with disabilities
(smartdisable),” in Multimedia Computing and Systems (ICMCS), 2014
International Conference on.
IEEE, 2014, pp. 996–1001.
[35] A. Pimenta, D. Carneiro, P. Novais, and J. Neves, “A discomfort-
sensitive chair for pointing out mental fatigue,” in Ambient Intelligence-
Software and Applications.
Springer, 2015, pp. 57–64.
[36] M. G¨overcin, S. Meyer, M. Schellenbach, E. Steinhagen-Thiessen,
B. Weiss, and M. Haesner, “Smartsenior@ home: Acceptance of an
integrated ambient assisted living system. results of a clinical ﬁeld trial
in 35 households,” Informatics for Health and Social Care, 2016, pp.
1–18.
[37] C. Wilson, T. Hargreaves, and R. Hauxwell-Baldwin, “Smart homes
and their users: a systematic analysis and key challenges,” Personal and
Ubiquitous Computing, vol. 19, no. 2, 2015, pp. 463–476.
[38] M. Turk, “Multimodal interaction: A review,” Pattern Recognition Let-
ters, vol. 36, 2014, pp. 189–195.
[39] A. Jaimes and N. Sebe, “Multimodal human-computer interaction: A
survey,” Computer Vision and Image Understanding, vol. 108, no. 1-2,
2007, pp. 116–134.
10
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-525-8
SMART ACCESSIBILITY 2016 : The First International Conference on Universal Accessibility in the Internet of Things and Smart Environments

[40] B. Ullmer and H. Ishii, “Emerging frameworks for tangible user inter-
faces,” IBM Systems Journal, vol. 39, no. 3.4, 2001, pp. 915–931.
[41] E. Hornecker and J. Buur, “Getting a grip on tangible interaction: a
framework on physical space and social interaction,” Chi, 2006, pp.
437–446.
[42] S. Zimmermann, S. R¨umelin, and A. Butz, “I Feel it in my Fingers:
Haptic Guidance on Touch Surfaces,” Proc. TEI’14 2014, 2014, pp. 0–
3.
[43] A. Bianchi and I. Oakley, “Designing tangible magnetic appcessories,”
Proceedings of the 7th International Conference on Tangible, Embedded
and Embodied Interaction, 2013, pp. 255 – 258.
[44] M. Ferati, M. S. Pfaff, S. Mannheimer, and D. Bolchini, “Audemes at
work: Investigating features of non-speech sounds to maximize content
recognition,” International Journal of Human Computer Studies, vol. 70,
no. 12, 2012, pp. 936–966.
[45] R. Rohani Ghahari, J. George-Palilonis, and D. Bolchini, “Mobile
Web Browsing with Aural Flows: An Exploratory Study,” International
Journal of Human-Computer Interaction, vol. 29, no. 11, 2013, pp. 717–
742.
[46] Y. Takeuchi, “Towards habitable bits: Digitizing the built environment,”
in Proceedings of the Ninth ACM International Conference on Interac-
tive Tabletops and Surfaces.
ACM, 2014, pp. 209–218.
[47] S. Oviatt, “Flexible and robust multimodal interfaces for universal
access,” Universal Access in the Information Society, vol. 2, no. 2, 2003,
pp. 91–95.
[48] Z. Obrenovic, J. Abascal, and D. Starcevic, “Universal accessibility as
a multimodal design issue,” Commun. ACM, vol. 50, no. 5, 2007, pp.
83–88.
[49] K. Moustakas, D. Tzovaras, L. Dybkjaer, N. Bernsen, and O. Aran,
“Using Modality Replacement to Facilitate Communication between
Visually and Hearing-Impaired People,” IEEE Multimedia, vol. 18, no. 2,
feb 2011, pp. 26–37.
[50] G. Alce, L. Thern, K. Hermodsson, and M. Wallerg˚ard, “Feasibility
study of ubiquitous interaction concepts,” Procedia Computer Science,
vol. 39, 2014, pp. 35–42.
[51] M. Homola, T. Patkos, G. Flouris, J. ˇSefr´anek, A. ˇSimko, J. Frt´us,
D. Zograﬁstou, and M. Bal´aˇz, “Resolving conﬂicts in knowledge for
ambient intelligence,” The Knowledge Engineering Review, vol. 30,
no. 05, 2015, pp. 455–513.
[52] S. Resendes, P. Carreira, and A. C. Santos, “Conﬂict detection and
resolution in home and building automation systems: a literature review,”
Journal of Ambient Intelligence and Humanized Computing, 2013, pp.
1–17.
[53] P. Carreira, S. Resendes, and A. C. Santos, “Towards automatic conﬂict
detection in home and building automation systems,” Pervasive and
Mobile Computing, 2014, pp. 37–57.
[54] E. C. O Shea, S. Pavia, M. Dyer, G. Craddock, and N. Murphy,
“Measuring the design of empathetic buildings: a review of universal
design evaluation methods,” Disability and Rehabilitation: Assistive
Technology, vol. 11, no. 1, 2016, pp. 13–21.
[55] G. S. Danford, M. Grimble, and J. L. Maisel, “Benchmarking the
effectiveness of universal designs,” The State of the Science in Universal
Design: Emerging Research and Developments, 2010, p. 47.
[56] H. Holone, “Transient cooperation in mobile information systems:
Accessibility mapping by sharing traces of activity,” Ph.D. dissertation,
University of Oslo, Institute of informatics, 2011.
[57] G. Varela, A. Paz-Lopez, J. A. Becerra, and R. J. Duro, “Autonomous
evaluation of interaction resource adequateness for ambient intelligence
scenarios,” in Ubiquitous Computing and Ambient Intelligence. Sensing,
Processing, and Using Environmental Information.
Springer, 2015, pp.
174–186.
[58] J. Tavares, J. Barbosa, I. Cardoso, C. Costa, A. Yamin, and R. Real,
“Hefestos: an intelligent system applied to ubiquitous accessibility,”
Universal Access in the Information Society, 2015, pp. 1–19.
[59] N. Catenazzi, V. De Luca, L. Sommaruga, and M. Botta, “Guidelines to
design inclusive ambient intelligence solutions for human activity shar-
ing,” in Complex, Intelligent and Software Intensive Systems (CISIS),
2012 Sixth International Conference on.
IEEE, 2012, pp. 496–501.
[60] M. Turunen, D. Sonntag, K.-P. Engelbrecht, T. Olsson, D. Schnelle-
Walka, and A. Lucero, “Interaction and Humans in Internet of Things,”
in Human-Computer Interaction – INTERACT 2015, 2015, vol. 9299,
pp. 633–636.
[61] F. Corno, E. Guercio, L. De Russis, and E. Gargiulo, “Designing for user
conﬁdence in intelligent environments,” Journal of Reliable Intelligent
Environments, vol. 1, no. 1, 2015, pp. 11–21.
[62] A. Olaru, A. M. Florea, and A. E. F. Seghrouchni, “A context-aware
multi-agent system as a middleware for ambient intelligence,” Mobile
Networks and Applications, vol. 18, no. 3, 2013, pp. 429–443.
[63] “Raising the Floor,” http://gpii.net.
[64] C. L. Kaiying, D. A. Plewe, and C. R¨ocker, “The ambience of ambient
intelligence: An asian approach to ambient systems?” Procedia Manu-
facturing, vol. 3, 2015, pp. 2155–2161.
[65] A. Jaimes and N. Sebe, “Multimodal human–computer interaction: A
survey,” Computer vision and image understanding, vol. 108, no. 1,
2007, pp. 116–134.
[66] V. Venkatesh, V. Vaithyanathan, M. P. Kumar, and P. Raj, “A secure
ambient assisted living (aal) environment: An implementation view,” in
Computer Communication and Informatics (ICCCI), 2012 International
Conference on.
IEEE, 2012, pp. 1–7.
[67] D. He and S. Zeadally, “Authentication protocol for an ambient assisted
living system,” Communications Magazine, IEEE, vol. 53, no. 1, 2015,
pp. 71–77.
[68] P. Gope and T. Hwang, “Untraceable sensor movement in distributed iot
infrastructure,” Sensors Journal, IEEE, vol. 15, no. 9, 2015, pp. 5340–
5348.
[69] S. Sicari, A. Rizzardi, L. A. Grieco, and A. Coen-Porisini, “Security,
privacy and trust in internet of things: The road ahead,” Computer
Networks, vol. 76, 2015, pp. 146–164.
[70] J. R. Nurse, S. Creese, M. Goldsmith, and K. Lamberts, “Guidelines
for usable cybersecurity: Past and present,” in Cyberspace Safety and
Security (CSS), 2011 Third International Workshop on.
IEEE, 2011,
pp. 21–26.
[71] P. C. Realpe, C. A. Collazos, J. Hurtado, and A. Granollers, “Towards
an integration of usability and security for user authentication,” in
Proceedings of the XVI International Conference on Human Computer
Interaction.
ACM, 2015, p. 43.
[72] L. Fritsch, K. S. Fuglerud, and I. Solheim, “Towards inclusive identity
management,” Identity in the Information Society, vol. 3, no. 3, 2010,
pp. 515–538.
[73] P. Novitzky, A. F. Smeaton, C. Chen, K. Irving, T. Jacquemard,
F. O’Brolch´ain, D. O’Math´una, and B. Gordijn, “A review of contem-
porary work on the ethics of ambient assisted living technologies for
people with dementia,” Science and engineering ethics, vol. 21, no. 3,
2015, pp. 707–765.
[74] S. E. Bibri, “Ethical implications of ami and the iot: Risks to privacy,
security, and trust, and prospective technological safeguards,” in The
Shaping of Ambient Intelligence and the Internet of Things.
Springer,
2015, pp. 217–238.
11
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-525-8
SMART ACCESSIBILITY 2016 : The First International Conference on Universal Accessibility in the Internet of Things and Smart Environments

