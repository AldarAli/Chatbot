Assistive Mobile Software for Public Transportation 
João de Sousa e Silva, Catarina Silva, Luís Marcelino, Rui Ferreira, António Pereira 
Computer Science Communication and Research Centre 
School of Technology and Management, Polytechnic Institute of Leiria 
Morro do Lena - Alto do Vieiro -2411-901 Leiria - PORTUGAL 
joao.sousa.silva@gmail.com, {catarina,luis.marcelino,rui.ferreira,apereira}@ipleiria.pt 
 
 
 
Abstract— The need of mobility on public transport for 
persons with visual impairment is mandatory. While traveling 
on a public transport, the simple ability to know the current 
location is almost impossible for such persons. To overcome 
this hurdle, we developed an assistive application that can alert 
its user to the proximity of all public transportation stops, 
giving emphasis to the chosen final stop. The application is 
adjustable to any transportation system and is particularly 
relevant to use in public transports that do not have any audio 
system available. The developed prototype runs on an Android 
OS device equipped with Global Positioning System (GPS). To 
ensure the highest possible level of reliability and to make it 
predictable to users, the application’s architecture is free of as 
much dependencies as possible. Therefore, only GPS, or other 
localization mechanism, is required. The interface was 
designed to be suitable not only for talkback (Android’s inbuilt 
screen-reader) aimed at blind users, but also for people with 
low vision that can still use their sight to check the screen. 
Thus, it was meant to be graphically simple and unobtrusive. It 
was tested by visual impaired persons leading to the conclusion 
that it demonstrates an existing need, and opens a new 
perspective in public transportation’s accessibility. 
Keywords: Assistive software, mobility, accessibility, public 
transportation, Android. 
I. 
 INTRODUCTION 
In today’s complex and dynamic world, mobility is 
crucial to ensure the involvement of an individual in the 
society. In this context, it is easy to identify many situations 
where the personal presence is essential. From basic life 
necessities, such as having a job, shopping, attending 
medical consultations, and also leisure activities like 
cultural events, meeting with friends, practicing sport and 
many more. These are all situations where the bodily 
presence is mandatory. These notions, which are taken for 
granted 
for 
most 
population, 
are 
actions 
hardly 
accomplished for people with some kind of visual 
impairment. 
According with the censuses from 2001[8], in Portugal 
there were more than 150.000 visual impaired persons. This 
population typically relies on public transports for mobility. 
Hence, the user-friendliness of the transportation system 
should be particularly relevant. 
Some problems concerning public transportation’s 
accessibility were identified from the constraints of visually 
impaired persons. For instance, a blind person, or a person 
with low vision, may have trouble determining his/her 
location while traveling in a bus. This hurdle can also be an 
issue that negatively constraints decisions, degrading life 
quality. 
Although there are some public transportation vehicles 
with audio systems alerting to the current and the next stops, 
these are only marginal, and are almost only seen in big 
cities. 
Nowadays, a big part of visual impaired persons already 
has a smartphone equipped with speech output interface. In 
this work, we will present an assistive software running 
Android OS that mitigates the identified problems.  
The developed assistive software uses the GPS 
information to identify the user’s location, integrating a 
database with bus lines and their stops, and allowing the 
user to define entry and exit stops. Furthermore, the 
application keeps the user informed about its location, the 
next stop and alerts him/her when the exit stop is 
approaching and reached. 
 
The rest of the paper is organized as follows: in the next 
section, an overview of current assistive systems in public 
transportation is presented. In the Section III, the proposed 
approach is described and in Section IV implementation and 
tests are presented. The paper closes with the main 
conclusions and some insights on future work. 
 
II. 
CURRENT ASSISTIVE SYSTEMS IN PUBLIC 
TRANSPORTATION 
Nowadays there are already audio systems installed in the 
vehicles of some transportation operators with the aim of 
helping visually impaired people (VIP), which alert, via 
recorded sounds, the current and the next stops. With this 
information the VIP may decide independently whether or 
not to exit the transportation. There are systems [2] where 
such a system is deployed with the complement of some 
features such as, while at a bus stop, using a dedicated 
device, owned by the VIP, it is possible to check the 
estimated time for arrival of a certain bus. 
Another system [3], complements the audio system with 
two other devices, one at the vehicle and the other with the 
VIP. The user should select, in his device, the desired line 
309
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

and activate it at the bus stop. The VIP’s device’s radio 
emits a low frequency signal that activates the vehicle’s one, 
alerting its driver that a person with visually impairment 
wants to get on-board. On arrival, the device at the bus 
announces, using a recorded voice, the line’s number until 
the person gets in. 
Another example is described in [4] and is implemented 
in several cities. It can be used in two different ways, either 
a dedicated device or an inbuilt device in a white cane. With 
the simple hit of specific buttons, this system allows the 
user, not just to check, for example, the number of the bus 
line and of the vehicle that is arriving at the station, but also, 
if the vehicle is the desired one, and to alert the driver that a 
person with visual impairment (VI) wants to get on-board. 
This system may be complemented with some other 
technology to increase the independence of the VIP [4]. 
Even though these are enormously helpful systems, there 
are some identified flaws. Those systems are not easy to be 
adopted since they require specific equipment, which 
increases its complexity, maintenance and associated costs.  
For a person with VI it may be a problem to have an extra 
device to carry and handle. It can be particularly 
problematic for those that walk with a white cane. Finally, 
the audio system may be a problem when the noise of the 
surrounding ambient hinders it. 
 
III. 
PROPOSED APPROACH 
After carefully analyzing existing solutions, a solution 
was devised to overcome most of their handicaps. In this 
section, we present the proposed approach and architecture 
and further provide an insight on its deployment. 
 
A. Introduction 
 
Our primary goal is to announce the desired final stop to 
the VI user at a convenient time. The stop alert must be 
anticipated to allow the user to take the necessary actions, 
usually to signal the driver with the intention to exit and 
collect all personal belongings.  
Contemporary smartphones have a wide set of features 
that fulfill the essential conditions to ensure the feasibility of 
our goal, namely, mobility, GPS antenna and speech output. 
Moreover, smartphones are widely adopted by the target 
group, making them a natural choice to deploy the approach. 
To successfully achieve our goal, preliminary system 
requirements were gathered from surveys presented to 
visual impaired users and professionals in the area of visual 
impairment. Some of the identified requirements include: 
● 
The VI person should be able to select the desired 
line number and desired final stop 
● 
To achieve a level of accessibility that makes the 
application usable to VI people, the graphical 
interface has to be simple and unobtrusive 
● 
It would be suitable to allow the user to consult, at 
any time during the way, the next and remaining 
stops until his final desired one 
● 
The user should be alerted if the GPS signal is lost, 
since it will make it impossible to accomplish the 
predefined task 
 
This application may be the first step towards an 
integrated mobility system for VI people, or a  compliment 
to the research of UbiBus. Such system may have features 
such as alerting the proximity of the public transportation, 
giving the stop order from a bus stop or from a bus and 
consulting the estimated time to arrival of the transportation, 
among others. 
The application may be easily adjusted to any operator 
with marginal costs. For a user, in case s/he already owns a 
supported smartphone, the adoption consists simply on the 
installation of the application and a short training period. 
 
B. Application usage 
 
From the identified system requirements we defined what 
we expected to be the most frequent application usage. This 
proposed case study was the reference to the initial 
implementation and tests of the application. 
Once the user opens the application, a first screen with 
the available surface transportations operators’ names 
appears. There s/he has to select the desired operator. Then, 
a screen with a list of available routes is shown and again 
s/he has to select the desired route. After that, a list of stops 
appears, organized by their sequence in the chosen route. 
Then, the VIP has to select the entrance stop and then his 
desire final stop. Right after, the navigation screen appears. 
At this point the smartphone starts searching for GPS signal. 
Hence, the user should perform this task before arriving to 
the stop so that when the transportation arrives, the software 
is ready to track the way. The navigation screen keeps its 
backlight on, not only to allow the VIP to check it easily, 
but also to keep updating the location with a required 
frequency. 
While traveling, the list of stops is updated whenever the 
transportation passes by a stop, by removing it from the list. 
Thus, the first stop in the list stop is always the next one. 
This allows the user to check, at any time, the remaining 
route. 
In order to let the user comfortably get ready to exit the 
transportation, when the transportation reaches two stops 
before the exit stop, a distinct sound is played to alert him. 
Upon arrival at the chosen final stop, another distinct sound 
is played. 
There are also specific sounds to alert the user in case the 
smartphone loses the GPS signal as well as when it gets it 
back. 
After the application detects the arrival at the desired 
final stop, the navigation screen closes and the first screen 
(where the operator has to be chosen) reappears. 
310
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

 
C. Architecture 
The system, to be able to be used without network access 
requires a local database with all operators, lines and stops 
for a region of interest. The information associated with 
each stop includes its name and its geographic position (the 
information about which lines pass at a stop may be 
obtained from the line’s properties).  
To determine its current position, the system uses its GPS 
capability. The current position is then compared to the 
position of the stops to infer the location of the user in the 
route.  
 
Figure 1. Simplified system architecture. 
 
Figure 1 illustrates the capabilities explored by the 
proposed system and their basic architecture. The system 
must be able to function as a stand-alone device: GPS 
connection, database integration, and visual, tactile and 
audible feedback.  To implement these functionalities a 
location mapper layer uses the information from the location 
manager and queries the routes’ database for the stops on a 
given route. 
 
IV. 
IMPLEMENTATION 
This section presents some considerations about 
developing application for VIPs on the Android’s platform. 
The used technologies include: SQLite, Location Manager 
and Graphical user elements. Besides all the factors that 
must be considered when developing mobile applications 
[7], this section points some additional barriers to the 
development of applications to VIPs. 
 
A. Database 
 
SQLite database is cross-platform, which confers it 
significant flexibility that helps to its maintenance and 
provides the chance to create and load the database in a 
friendly environment, such as desk or laptop computer. 
Since the result is a single file that is often small and it does 
not need configuration, the portability to the target device is 
stress-free. At runtime, the system handles the database 
easily, since SQLite is an embedded SQL database engine. 
Furthermore, SQLite has a constant team that upkeeps its 
development. Therefore it is robust and fast, which is 
possible to confirm by its smoothness while retrieving 
information at runtime, even in devices with memory 
limitations such as smartphones. 
Given its simplicity, SQLite database has easy 
implementation. Moreover since its features are the most 
suitable for smartphones, it is the chosen databases engine 
for this application [6]. 
 
B. GPS Location 
 
The main classes of Android to manage GPS, were 
explored and tested in order to build an assistant manager 
class 
to 
deal 
with 
it. 
After 
researching, 
only 
LocationManager and LocationListener are being use, since 
those are adequate for setting triggers for proximity and fire 
sounds when the GPS state changes.  
In order to save battery, the location updates are required 
just when the navigation screen appears. Even there the 
updates are made just every 4 seconds. This value was 
chosen according with the following: the proximity alert has 
a distance of the major point of 40m, so the diameter is 
80m. If the transportation crosses the stop event at 60km/h, 
or 16,67m/s, so it means that theoretically the location 
update from 4 to 4 seconds will be enough as the covered 
distance will be 66,67m in 4 seconds.  
KML (Keyhole Markup Language) is an Extensible 
Markup Language (XML) schema, developed by Keyhole, 
Inc., used for expressing geographic annotation that is used 
with Google Earth [5]. These features made this format the 
right source for the required information. 
To extract the desired information from the file, such as 
stops’ names, their coordinates, the route they belong to, 
etc., manual parsing procedures were used. After the 
treatment a CSV file was generated, from where SQLite 
Administrator could load the database. 
Through the use of KML, there is the possibility to 
automate the addition of routes to the application in a future 
iteration. 
 
C. User Interface 
 
The graphical user interface is built over ListActivities, 
as shown in Figure 2. The best attention was taken while 
developing it in order to keep it as simple as possible. 
However, to navigate within these lists a trackball is 
required as the touch screen is barelly usable for a VIP and, 
among these, especially blind people. 
Also the size of the font is increased, letting people with 
low vision to manage the software using their sight. 
Furthermore the screen orientation is locked at portrayed 
position, with the aim of being more predictable for blind 
people. 
311
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

 
Figure 2: List Activity with Bus stops 
 
Using simple and standard OS graphical components, the 
software is intrinsically talkback compliant by default. 
Talkback is an application, which runs as a service and 
converts text-to-speech, natively available for Android OS 
since version 1.6 [10]. 
 
D. Accessibility 
 
The touch screen of smartphones may become a 
significant obstacle to the adoption of smartphones from 
VIPs. The unintentionally touch on the screen may trigger 
events that make the smartphone unusable. 
In order to minimize the possibility of mistakes while 
using the software, a double tap - where the second tap 
should be kept pressed – was initially defined as necessary 
to select an item. After this procedure a button to confirm 
the selection appears. This restriction was implemented with 
context menus, changing the normal selection behavior for 
this platform. 
With the exception of the font size that is increased, none 
of the graphical components of the software was changed 
with the aim of maintaining the software’s graphical user 
interface akin the operating system’s graphical standards. 
This favors usability and accessibility, by conserving an 
assured level of regularity, at expenses of fancy designs. To 
improve the predictability of the interface, the screen is set 
not to react to smartphone’s orientation changes. Therefore, 
it is locked at portrait position. 
 
V. 
TESTS 
To test to the developed prototype we invited 4 VIP to try 
to use the application on a real scenario. Therefore the tests 
were conducted on urban lines of a local bus company.  
We asked users to select itineraries that would take 
approximately 10 minutes because the greatest challenge for 
this application’s users is the selection of the desired route. 
All the 4 test subjects were blind and regular users of 
Nokia mobile phones. These devices are significantly 
different from the selected touch screen Android devices, as 
they have physical keyboard and no touch screen. Subjects 
were all male with ages between 30 and 50 years old and 
half of them are regular users of computers. 
The experiment script was defined to ask similar tasks to 
all the test users. While at a bus stop, they were asked to 
select the bus operator line and the entrance and exit stops. 
They would have to identify the stops in the itinerary and 
recognize the exit stop. The devices used for these tests 
were HTC Wildfire smartphones. This device has a 
capacitive touch screen with a small trackball and runs 
Android 2.2. The physical buttons, namely Home, Menu, 
Back and Search buttons, of this device are also capacitive 
with no distinctive feature that enables their identification 
(using touch is not possible to distinguish the screen from 
these buttons). 
The Android platform has a Home Shell for VI users 
denominated Eyes Free [9]. This speech enabled home 
application uses the concept of a matrix where the user can 
navigate through menus sliding the finger through one of 
the nine areas of the screen. The focused menu is vocalized 
with a built-in text to speech and the user may select it by 
lifting the finger. 
This matrix paradigm was completely new to all the test 
subjects and they required frequent assistance to be able to 
navigate and select our prototype application. 
During the first trial the menu navigation experiment was 
so challenging that we had to provide the device with the 
application already on screen. Even so, the back button was 
not recognizable and the user could not correct his mistakes 
while selecting the stops. For the remaining experiments we 
used a screen protector film with marks on the buttons. 
The built-in text to speech (TTS) capability supports 
English, French, Spanish and German. Unfortunately it does 
not support the Portuguese language (native language to all 
test users). An external TTS engine that supports Portuguese 
is available on the Android Market. However with this 
engine the application became very slow and irresponsive. 
For this reason the TTS engine read Portuguese text as it 
were English. Therefore, users had an additional effort to try 
to understand what was spoken, which they usually 
succeeded. 
A significant change carried out by user’s feedback was 
to alter the initially defined double tap to select an option 
followed by a second tap. Instead, users suggested the use of 
a single long pressing, which was implemented, since it was 
deemed extremely relevant. 
The software has shown its capabilities in real 
environment and testers successfully accomplish the preset 
task (choose a concrete entrance and exit stop from a 
concrete route and operator) in a time that often was less 
than one minute. 
312
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

As the accessibility is a priority for this software, it was 
taken into account at each step of testing, even in low level 
tests. A failure on this area could nullify the whole project. 
 
VI. 
CONCLUSIONS AND FUTURE WORK 
The major objective of this work was to provide a higher 
level of independency to people with visual impairment. To 
achieve this goal includes also trying to increase the privacy 
of this group of people.  
 
Often a big issue to be handled when referring to reduced 
mobility is also that when a person with disability wants to 
go somewhere, in order to be possible to provide help, 
someone will have to know where that person would like to 
go. 
 
This paper presents an assistive software for visually 
impaired people in surface public transportation, improving 
the mobility of people with visual impairment. The 
application receives the route and initial and final stops and 
proceeds by identifying the current stop and alerting the user 
of the proximity of his final desired stop. This information 
is available at any time of the route.  
 
The tests performed so far have shown that the 
application works in real contexts. The main constraints of 
the application are the devices where it can run on, as the 
usability of the devices that runs Android OS is often 
visually orientated. 
 
The usability test results provide support for further 
improvements, not only in the graphical interface, but also 
for new features that may be useful in large cities with a big 
number of lines and stops, such as auto selection of routes 
that may include connections between routes, set the order 
of stop in alphabetical order. System and acceptances tests 
should be performed to insure the reliability and usability of 
the software. 
 
 
ACKNOWLEDGMENT 
The authors would like to acknowledge the contribution 
of the Municipality of Leiria and the Portuguese Blind 
Association (ACAPO) to the success of this work. 
 
 
REFERENCES 
1. Silva, João de Sousa e.Mobile Technologies Supporting Inclusion and 
Accessibility (in portuguese). s.l. : Available at Library José 
Saramago at School of Technolagy and Management at Polytechnic 
Institute of Leiria, 2010. 
2. Rodoviária de Lisboa. Lisbon's Bus Operator - Real Time Information 
(in 
portuguese). 
[Online] 
http://www.rodoviariadelisboa.pt/tempo_real. 
3. Geraes Tecnologias Assistivas. DPS2000 - Electronic Signaling for 
Visually Impaired People and Transportation (in portuguese). 
[Online] http://www.geraestec.com.br/produto/dps2000.php. 
4. APEX Ltd. - Tyfloset. APEX Ltd. - Tyfloset. [Online] http://www.apex-
jesenice.cz/tyfloset.php?lang=en. 
5. Google. KML Documentation Introduction - KML - Google Code. 
[Online] http://code.google.com/intl/pt-PT/apis/kml/documentation/. 
6. 
SQLite 
Consortium. 
About 
SQLite. 
[Online] 
http://www.sqlite.org/about.html. 
7. 
Ricardo Gomes, Luís Marcelino, Catarina Silva, Survey on Mobile 
Application Development Case Study: WineDroid, 6ª Conferência 
Ibérica de Sistemas e Tecnologias de Informação, June 2011, 
Chaves, Portugal.  
8. 
Census 2001, http://www.pordata.pt, last accessed march 2011 
9. 
Eyes Free Project, http://code.google.com/p/eyes-free/, last accessed 
march 2011 
10. 
Eyes Free Project Repository, http://code.google.com/p/eyes-
free/source/, last accessed march 2011 
 
 
 
 
313
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-171-7
UBICOMM 2011 : The Fifth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

