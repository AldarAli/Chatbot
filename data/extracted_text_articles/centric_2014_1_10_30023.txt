Making the Most of Customer Product Reviews
Florian Volk∗, Janette Pitzschel, and Max M¨uhlh¨auser∗
∗Technische Universit¨at Darmstadt/CASED
Telecooperation Lab
ﬂorian.volk@cased.de, janette pitzschel@gmx.li, max@informatik.tu-darmstadt.de
Abstract—Online product reviews are a twofold user-centric
instrument: reviews are written by users and, furthermore, aid
other users with their purchase decisions. Moreover, detailed
product reviews that rate product parts help retailers in improv-
ing products by identifying reasons for defects. In this paper, we
report, analyse, and discuss the results and ﬁndings of two user
studies (160 and 229 participants respectively). We contribute
ﬁndings on customer reviewing behaviour and on improving
reviews to include ratings for product parts. Furthermore, we
analyse reviewing incentives and evaluate an alternative review
system that presents its users with a list of known problems that
they can select from.
Keywords–Online Product Reviews; Product Rating; Rating
Decomposition; Customer-centric; Review Systems.
I.
INTRODUCTION
Online product reviews are a remarkable user-centric com-
ponent of e-business. The duality of reviews involves cus-
tomers at two times during their online shopping experience: at
ﬁrst, potential customers of a product read reviews to evaluate
product suitability and therefore, base their purchase decision
on reviews. After a purchase, the second aspect of reviews
becomes relevant when customers may write their own product
reviews in an altruistic action to help others with their purchase
decisions. In general, product reviews report the experience
with the product alongside with an indication of the product’s
merits (called rating from now on).
Even though customer product reviews suffer from con-
ceptual problems, for example, authors lying about their ex-
perience with a product or reviews written by paid authors
who never bought the product, reviews are considered such
important for online business that they are implemented in
almost every online shopping platform. Besides aiding po-
tential customers, reviews also provide beneﬁts for online
retailers. Highly-rated products reach higher prices compared
with low-rated products [1][2]. Moreover, potential customers
will usually choose the highest-rated product from a set of
functionally identical ones.
The impact of product reviews on customers is in the focus
of research since some time. Our interest in customer reviews
differs. In order to improve the beneﬁt for both customers
and retailers, we are interested in splitting a review into
sub-ratings for individual parts of a product. Most products
sold today are composed of parts contributed by different,
potentially independent suppliers. However, customers receive
assembled products and thus, reviews address products as a
whole. While this is helpful for customers, having ratings for
product parts would enable retailers to improve the assembled
product by identifying weak parts and consequently replacing
their suppliers with other suppliers that deliver higher quality.
Eventually, this will have impact on the overall product quality
and thus, on customer satisfaction, as well as on the reviews
written for the product. Beyond the scope of this paper, such
knowledge on individual ratings would also have impact on
pricing strategies of retailers and similar.
Therefore, we are interested in ways to decompose product
reviews into detailed reviews for sub-components. It would
be a strong assumption to expect the general customer to
be able to write individual reviews for product parts or even
to identify such ones. In order explore reviewer capabilities,
as well as to understand how and why reviews are written,
we conducted a preliminary survey (160 participants) on the
attitudes of customers towards reviewing followed by a second
study (229 participants) that further investigates the results
of the preliminary study. By the term customer capabilities,
we summarize both the ability and the willingness to produce
detailed reviews. For the second study, the following assump-
tion was made: customers are generally unable to identify and
rate parts of products individually. Thus, we focused on the
capabilities to identify defects and the reasons for the defects.
Defect identiﬁcation is close to (negative) ratings for individual
parts, because it delivers the information needed to identify and
replace suppliers of weak product parts. This aids both retailers
in improving product quality and customers in buying better
products.
Seller
Customer
Retailer
Platform
product
review
Supplier n
Supplier 1
…
[review-1, …, review-n]
1
4
2
3
Figure 1.
The e-business reviews scenario: the retailer sells a product made
from components of different suppliers to customers. Each customer may write
a review about the product as whole. Nevertheless, our interest is to obtain
reviews for individual parts of the product.
Our studies assume the scenario depicted in Figure 1. A
seller assembles a product from parts contributed by several
suppliers. The ﬁnally assembled product is given to the re-
1
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-369-8
CENTRIC 2014 : The Seventh International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

tailer, which uses an e-business platform to offer the product
to potential customers. The seller and retailer may as well
be the same entity without inﬂuence on the results of our
studies. Products that are offered on the platform consist of a
description and a set of product reviews written by customers.
When a customer makes a purchase decision, the product
is given to the customer, who may write a product review,
which will be available on the platform to other potential
customers. Our intention is to determine the possibility of
obtaining decomposed reviews from customers.
A. Structure
This paper is organised as follows: we survey work related
to customer product reviews in Section II. Afterwards, in
Section III, we present the setup and demographics of the two
studies we conducted. In Section IV, we report our ﬁndings
on customer review behaviour, while Section V focuses on
the results on how customers can be incentivised to write
more useful reviews. Based on the results of the ﬁrst study,
we presented the participants of the second study with an
alternative review system. The reactions to the proposed review
system are analysed in Section VI. We conclude in Section VII.
II.
RELATED WORK
Online customer product reviews are of interest in several
ﬁelds of research, especially in psychology, economics, and
computer science. In the latter ﬁeld, most research targets
the extraction of features and ratings from textual reviews by
text mining. This section reviews a selection of the scientiﬁc
work most relevant to our approach of decomposing customer
product reviews.
A. General Aspects of Customer Product Reviews
In 2004, Resnick et al. conducted an experiment to research
the effects of positive and negative reputation in eBay [1].
Thereby, eBay users can rate a transaction, that means, a
purchase, as either positive, negative or neutral. Based on these
ratings, a reputation is built up for every eBay user. Resnick
et al. found that sellers with good ratings—and thus, good
reputation—were able to achieve signiﬁcantly higher prices for
the same products compared to sellers with less good ratings.
According to the authors, eBay’s reputation system is ﬂawed
but works anyway because buyers pay insufﬁcient attention to
bad reviews.
In [3], Li, Zhang, and Martin present an alternative review
system for e-marketplaces. To overcome the ﬂaws of current
systems (e.g., no information is available on new market
entities; delayed effects of negative reviews), they propose a
system in which reviews are kept private between the buyers
and the marketplace operator, which needs to be a trusted third
party. The operator then applies punishments to misbehaving
retailers. Related approaches to improve review systems have
been made, for example, by Miller, Resnick, and Zeckhauser in
[4]. Such improved systems usually apply ﬁnancial measures to
prevent misbehaviour; either by punishing misbehaving entities
[3] or by rewarding good behaviour [4].
Our research is targeted towards making better use of
reviews, not towards replacing the review systems themselves.
B. Effects and Motivations behind Customer Product Reviews
With the example of online movie reviews, Dellarocas and
Narayan investigated the motivations of customers to write
product reviews [5]. They found that exceptionally good or
bad movies, high marketing effort, public disagreement on
quality, and the number of already available reviews lead to an
increased number of reviews. Dellarocas and Narayan could
reject their hypothesis that customers write reviews out of
altruism. Their results ﬁt with ours from Section IV-B where
applicable.
Research on the impact of reviews on the number of sales
has been made by Chevalier and Mayzlin [2]. The authors
investigated the effects of customer reviews for books on two
large online shops. Besides a general tendency towards positive
reviews, they found that better reviews correlate with higher
sales numbers. Moreover, the impact of bad reviews is higher
than that of good ones. The most interesting ﬁnding for our
work, especially regarding consequences drawn from tests with
our alternative review system, is that customers prefer written
reviews over ratings only.
C. Text Mining Customer Product Reviews
There are many approaches in computer science that apply
text mining on written customer product reviews. All these
approaches use text mining to identify product features and
the sentiments of customers towards these features. Thereby,
features are detected in different ways and assigned with a
rating.
Aciar et al. apply text mining with a product-speciﬁc
ontology [6]. The authors deﬁne the ontology upfront and
match the results of their text mining afterwards. Moreover,
they calculate an overall product rating from all identiﬁed
features. We believe that the customers should have the option
to rate a product independently from their written review as it
is possible that relevant inﬂuence factors are missing from the
set of identiﬁed features.
Striving towards assisting manufacturers in increasing
product quality, Archak, Ghose, and Ipeirotis apply text mining
to customer product reviews [7]. In contrast to Aciar et al. [6],
their approach includes learning the features from the reviews
without the use of a predeﬁned ontology.
The text mining approach by Yu et al. distinguishes be-
tween reviews that contain so-called Pros&Cons lists and pure
textual reviews [8]. Besides this differentiation, the authors
also identify product features (which they call “aspects”) and
sentiments towards these features.
In terms of decomposed ratings, product features are simi-
lar to product parts. While our approach in this paper aims at
receiving reviews that are already decomposed from customers,
applying text mining to reviews seems promising to aid review
decomposition for situations in which the customers are unable
to write decomposed ratings by themselves.
III.
STUDY SETUP
To explore customer reviewing behaviour and their capa-
bilities to write detailed reviews, we conducted two studies.
2
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-369-8
CENTRIC 2014 : The Seventh International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

The results of the ﬁrst preliminary study helped in designing
the second full study.
Both studies were conducted by means of structured online
questionnaires. Invitations were sent to our extended network
of family and international friends with the plea to redistribute
to their friends and family. Both questionnaires were available
in English and German language. For each question, the
participants could choose from a list of predeﬁned answers that
ranged from speciﬁc answer like yes or no to an indication of
tendency, e.g., totally agree, agree, do not agree, do not agree
at all. When applicable, participants could concurrently select
multiple answers.
The preliminary study was designed to gather data on the
general attitude of customers towards online reviews. The full
study was focused on the participants’ capabilities in writing
detailed ratings that may reveal faulty parts of a product.
Additionally, the study was intended to reveal incentives that
increase the probability of customers to write reviews. At the
end, we presented the participants with a ﬁctitious alternative
review system designed on the results from the preliminary
study. Details on the alternative system are explained in
Section VI.
During both studies, all participants were asked for their
gender, their employment status, and if they consider their
job being in the ﬁeld of technology or not. The participants
were not asked for their age. Of course, all data was collected
anonymously.
Overall, 160 people participated in the preliminary study.
For the full study, we were able to recruit 229 people. Figure 2
shows the distribution of genders and of participants that see
their job in the technological ﬁeld. In both studies, almost 30%
of the participants are female. The amount of participants with
a technological job and those without increased from 60% to
about 66%.
0
25
50
75
100
125
150
175
200
225
250
preliminary9study
full9study
Number9of9participants
female
male
technological9job
non-techn.9job
70%
30%
71%
29%
40%
60%
34%
66%
Figure 2.
The distribution of genders and participants who consider their job
being in a technological ﬁeld for both studies.
The distribution among the different states of employment
was similar in both studies. As Figure 3 shows, the vast
majority of participants consisted of (university) students and
employees. Due to the high percentage of German-speaking
participants (around 80% of the participants chose to answer
the questionnaire in German), it is to assume that undergrad
students mostly chose “student”, while Ph.D. students chose
“employed” as a Ph.D. position usually is a full time position
at a German university.
0
20
40
60
80
100
Number of participants
preliminary study
full study
Figure 3. The distribution of participants among distinct types of employment
for both studies.
In the preliminary questionnaire, all 160 participants an-
swered the question if they ever bought products online with
yes. Therefore, this demographic question was removed from
the full study. However, we received an e-mail from one person
stating she didn’t complete our questionnaire because she never
used online shopping before.
IV.
CUSTOMER REVIEWING BEHAVIOUR
The preliminary study targeted general customer reviewing
behaviour. This sections discusses the main ﬁndings.
As expected, a high percentage of potential customers
base their purchase decisions on product reviews from other
customers. When asked if they are inﬂuenced by product
reviews, 50% of the participants answered with agree and
further 26.25% answered with totally agree. Therein, we see
a reason to believe that customer reviews have an important
effect on e-business in general. However, there appears to be
a contradiction as only 75% of the participants ever wrote a
review (in text form, on a point scale or in a mixed setting).
Moreover, 79.2% of those who write reviews, only write
reviews rarely.
A. Why Customers don’t write Reviews
In order to investigate why customers don’t write reviews,
those 25% participants who claimed not to write reviews were
asked for their reasons. Multiple answers were possible. The
two most chosen answers were missing motivation to do so
(75%) and unwillingness to perform a registration which is
required to write reviews (67.5%). The same answers were
given by the participants who write reviews only rarely. An
overview on all answers is given in Table I.
TABLE I.
REASONS NOT TO WRITE REVIEWS AS GIVEN BY THOSE
WHO WRITE REVIEWS ONLY RARELY. MULTIPLE ANSWERS ALLOWED.
Reason
Participants
Fraction
I lack motivation
71
74.74%
I don’t want to register
65
68.42%
I forget to write reviews
42
44.21%
I don’t mind writing reviews
36
37.89%
Other customers already write reviews
30
31.58%
I’m aware that it’s bad not to write reviews
21
22.11%
I consider reviews dispensable
12
12.63%
Reviews don’t represent the reality
11
11.58%
I regret to write reviews rarely
7
7.37%
I don’t know how to write a review
5
5.26%
other
8
8.42%
3
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-369-8
CENTRIC 2014 : The Seventh International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

B. Why Customers write Reviews
All participants that claimed to write reviews were asked
for their reasons to do so. For every potential reason, the
participants could state their consent on a ﬁve point Likert
scale ranging from totally agree, agree, neutral, do not agree,
do not agree at all. In Table II, the ﬁrst two options are
summarized under positive tendency, the last two ones under
negative tendency. A sixth option no opinion could be selected
in case none of the above applied. We asked for the eight
reasons to write reviews as given in Table II.
TABLE II.
REASONS TO WRITE PRODUCT REVIEWS. PARTICIPANTS
WHO CHOSE no opinion ARE NOT LISTED.
Positive
Neutral
Negative
I write reviews.. .
Tendency
Tendency
Tendency
to share my ﬁrm conviction
for the product
80.83%
9.17%
8.33%
to warn other potential customers
76.67%
10.83%
9.17%
to share my experience with others
73.34%
11.67%
11.66%
because I want others to follow suit
38.33%
28.83%
35.00%
to express my frustrations
36.66%
12.50%
47.50&
without deeper reason
30.84%
25.83%
32.50%
to receive discounts or other beneﬁts
22.50%
15.00%
58.33%
to receive assistance
20.00%
15.83%
55.83%
Participants could list additional reasons for writing re-
views in a text ﬁeld. Most notable reasons were boredom and
doing the retailer a favour.
Many customers implicitly assume that the majority of
reviews is written by unsatisﬁed customers. The assumption
herein is that customers invest more time when they are
dissatisﬁed with a product, for example, to “let off steam”. Our
ﬁndings do not back this assumption. In contrast, we found that
there is no general correlation between writing a review and
the tendency of the review.
In order to identify a general tendency towards positive or
negative reviews, the participants had to indicate their level of
agreement to the following two statements: if I write a review,
the review is always negative and if I write a review, the review
is always positive.
As can be seen in Figure 4, there is no tendency towards
writing only negative reviews. However, a slight trend towards
writing positive reviews is visible.
0
5
10
15
20
25
30
35
40
45
50
Fraction of participants [%] 
the review is negative
the review is positive
When I write a review,
Figure 4.
Tendencies towards generally writing positive or negative reviews
respectively.
In conclusion, the best way for retailers to gather product
reviews is to have convinced customers. Reviews are as often
written to warn about potential defects as to share product
experiences. This ﬁnding reconﬁrms that there is no tendency
towards writing negative reviews.
C. The Inﬂuence of Warranty
The reaction of customers to a defect depends mostly on
the state of warranty. If delivered with a defect, customers will
send the product back to the retailer, regardless of the price.
Moreover, searching the reason for the defect only plays a
minor role. Nevertheless, 51.53% of the participants stated that
they are usually capable of identifying the reason for a defect.
Additionally, only 13.97% of the participants write reviews a
long time after a purchase.
We conclude that it is especially difﬁcult to obtain decom-
posed product reviews during the warranty period as customers
are more prone to sending the product back than to ﬁnd the
defect. Getting information on product wearing is also difﬁcult.
V.
REVIEWING INCENTIVES
One part of the full study investigated how customers can
be motivated to write more product reviews. We explored three
potential incentives: receiving an explanation how a review
helps the retailer to improve the product, receiving feedback
to a review from the retailer, and rewards for writing a review.
Figure 5 lists the participants’ answers when asked for their
level of consent towards each of the potential incentives.
0
5
10
15
20
25
30
35
40
45
50
receive an
explanation
receive feedback
receive a reward
Fraction of participants [%]
totally agree
agree
do not agree
do not agree at all
Figure 5.
Potential incentives for customers to write more product reviews.
Interestingly, there is no signiﬁcant difference between the
participants that claim to have a technological job and those
who don’t (Fisher-Freeman-Halton test [9]).
In summary, only rewarding the customers would increase
the amount of reviews. However, rewards may distort the
balance between positive and negative reviews. On one hand,
customers might write more positive reviews as a form of
positive reciprocity towards the retailer. On the other hand,
those customers that are not satisﬁed with a product might not
be interested in the reward. Consider the following example:
when buying a video game, the retailer offers free access to
a bonus level as reward for customers that write a review.
Especially customers who dislike the video game proﬁt less
from a bonus level than satisﬁed customers. Therefore, a
tendency towards positive reviews is created by the reward.
That is, rewards need to be designed carefully not to inﬂuence
the reviews. In fact, most retailers would be interested in
manipulating customers towards writing positive reviews; but,
this is not the intention of our research.
4
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-369-8
CENTRIC 2014 : The Seventh International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

VI.
ALTERNATIVE REVIEW SYSTEM
The next part of the full study explored which features
customers like most in review systems. Additionally to classi-
fying the importance of speciﬁc features, the participants were
presented with an alternative review system. The given task
was to compare the proposed system with one that has the
features of common review systems: rating a product from ﬁve
stars (best) to one star (worst) and writing a textual review.
This section ﬁrst discusses the features of review systems,
then presents the alternative review system and closes with
the evaluation of the proposed system.
A. Features of Review Systems
For several features of review systems, the participants of
the full study could state their level of agreement. Table III
presents an overview of features that we could identify to be
relevant.
TABLE III.
RELEVANCE OF THE FEATURES OF A REVIEW SYSTEM.
Feature
Agreement
Overview over all products
94.32%
Detailed reviews from other customers
85.15%
Short reviews from other customers
80.79%
Ability to write reviews instead of ratings
61.57%
Interestingly, 68.5% of the participants who want access to
detailed reviews anyhow prefer short and compact reviews over
detailed ones. We believe that this type of potential customer
uses short reviews to get an overview over available products
and their features, but exploits detailed reviews for the ﬁnal
purchase decision.
Other features we tested are of minor relevance, for ex-
ample, the possibility to leave reviews fast or allowing only
reviews from authors who previously purchased the product.
4.5% of all participants are not interested in reading reviews
(or ratings) from other customers at all.
Based on the results of this part of the full study, we
deduce that a customer-centric review system should assist
potential customers with a good overview over the ratings
for all available products with the option to get detailed
information for speciﬁc products. Moreover, after a purchase,
a relevant set of customers expects a review system to accept
textual reviews instead of just a product rating.
B. The Alternative Review System
In common review systems, customers who bought a prod-
uct can leave a rating (e.g., one to ﬁve stars) for the product and
additionally, they can write an arbitrarily long textual review.
As motivated in the introductory section of this paper, reviews
left using such systems are focused on the product as a whole.
It would be an improvement for both customers and retailers
when product reviews included ratings for product parts. The
participants of the full study were presented with an alternative
review system that leads to such a type of product reviews.
As shown in Figure 6(a), a customer is asked to leave a star
rating (part 1) and to select all problems with the product the
customer had (part 2). Therefore, the customer is given a list
of all known problems with the product. The alternative review
system does not include the option to write textual reviews.
(a)
(b)
Leave afproduct review
1
How dofyou ratefthis item?
2
Please checkfthose problems
that apply to your product:
Shipment
long delivery time
packetfwasfdamaged
Battery
poor battery lifetime
battery gets hot while charging
battery can‘t be replaced
Display
too small
too large
poor response to touch input
poor viewing angles
unreadable infsunlight
Product reviews
Generalfcustomer satisfaction
308foutfof 5fstars
(5797
Shipment
long delivery time
packetfwasfdamaged
(4887
(1447
Battery
poor battery lifetime
battery gets hot while charging
battery can‘t be replaced
(5627
(1327
(5797
Display
too small
too large
poor response to touch input
poor viewing angles
unreadable infsunlight
(3027
(797
(757
(1027
(5117
Figure 6.
A mockup of the alternative review system with a smartphone as
example product: (a) interface for authors of product reviews, (b) interface for
potential customers. (The ﬁgure was edited for print.)
When a potential customer accesses reviews for a product,
a form similar to Figure 6(b) is shown. On top, the average
rating of all reviewers is shown. Below the average rating, all
known problems are listed with a numeric indicator how many
reviewers reported to have this problem.
C. Evaluation of the Proposed System
When asked if they perceived the alternative review system
to be more intuitive than the common ones, 68.12% of the
participants agreed (either totally agree or agree). 46.67% of
the participants would like to see the alternative system to
replace the common ones. However, the largest fraction of
participants prefers not to replace the common systems. When
asked if they want to see the alternative system as an addition
to common ones, 89.52% agreed. In total, 93.91% of the
participants said that they would like the alternative system to
be used (either as a replacement or as an addition to common
ones). Details can be found in Figure 7.
0
5
10
15
20
25
30
35
40
45
50
more intuitive
replacement for
current system
addition to current
system
Fraction of participants [%]
totally agree
agree
do not agree
do not agree at all
Figure 7.
Reactions to the proposed alternative review system.
Afterwards, the participants could agree or disagree with
reasons for using the proposed system. 59.72% of those who
would like the alternative system to be used (replacement or
addition) stated that the newer system would be faster and
easier to use. However, 69.86% of all participants assume that
a predeﬁned list of problems is not representative enough for
individual reviews. This is backed by the fact that 89.52%
5
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-369-8
CENTRIC 2014 : The Seventh International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

of all participants would want to leave additional textual
reviews when using the proposed system. Even in the group
of those who wanted to replace the common systems with
the alternative review system, 41.48% would want to leave
additional textual reviews.
We therefore conclude that our proposed system needs
further reﬁnement to be accepted by a majority of customers.
However, when customers are provided with an option to
additionally leave text reviews, the alternative review system
is able to assist customers in writing better product reviews.
Such better reviews help other customers to identify potential
problems with a product faster and more reliable because
the overview over problems is accompanied with a numeric
indicator how often the problem occured. For the same reasons,
the reviews help retailers to improve product quality, which,
eventually, also helps customers. Moreover, retailers can ex-
tract previously unknown problems with a product from the
written reviews and add those to the list of known problems
in the review form.
While we do not encourage forcing customers to write
reviews in any way, 89.08% of all participants stated that they
would ﬁll a mandatory questionnaire when returning products.
A questionnaire like this could be designed similar to our
proposed review system, but should include a free text ﬁeld.
VII.
CONCLUSIONS AND FUTURE WORK
Online product reviews assist users in two ways: ﬁrst,
customers can base their purchase decisions on reviews to
identify the best product to buy. Second, retailers can use
product reviews to identify problems with a product and thus,
improve the product quality.
In this paper, we report the results of two studies on
online customer product reviewing behaviour. Furthermore,
we analyse and discuss the results and ﬁndings. We identify
reasons for customers not to write product reviews (top reason:
lack of motivation), as well as reasons why customers write
product reviews (top reason: ﬁrm conviction for the product).
Subsequently, we explore potential incentives for customers to
write more or better reviews.
When using product reviews, retailers should be especially
aware of three aspects:
•
Only few customers write reviews a long time after
the purchase. Thus, reviews mention only problems
that occur early in the product lifetime or already
exist when delivered, but not those that are caused
by wearout.
•
Customers will return products during the warranty
period without trying to identify or ﬁx problems. Thus,
it is difﬁcult to obtain decomposed product reviews
during this period.
•
When incentivising customers with rewards to write
reviews, the design of the reward might distort the
representativeness of the reviews.
We also evaluate a mockup of an alternative review system
that strives towards producing detailed ratings for parts of
products instead of reviews that target a product as a whole.
Ratings for parts of a product enable directed improvements
to products from the retailers, e.g., by replacing the suppliers
of those product parts that cause defects. A major ﬁnding is
that a list of known problems from which customers can select
those problems that apply to them is insufﬁcient. Customers
prefer to have the option to leave textual reviews.
For future research, a prototypical implementation of the
alternative review system with textual reviews is needed for
in-depth evaluation of the system. Thus, a comparison of
reviews created with the new system and reviews created with
current review systems should reveal if the new system leads
to improved reviews.
A second future research direction is the use of mandatory
feedback forms when returning products. Our study reveals
a high customer acceptance for such feedback forms. Open
questions are how useful the information from such feedback
forms is and how to transform the results back into reviews
that can be used by other customers.
ACKNOWLEDGMENT
The work presented in this paper was performed in the
context of the Software Campus project Dekomposed and
funded by the German Federal Ministry of Education and
Research (BMBF) under grant no. “01IS12054”. The authors
assume responsibility for the content.
The authors would like to thank Sascha Hauke and Sheikh
Mahbub Habib for their help and suggestions while preparing
this manuscript.
REFERENCES
[1]
P. Resnick, R. Zeckhauser, J. Swanson, and K. Lockwood, “The value of
reputation on eBay: a controlled experiment,” Experimental Economics,
vol. 9, no. 2, pp. 79–101, 2006.
[2]
J. A. Chevalier and D. Mayzlin, “The effect of word of mouth on sales:
Online book reviews,” Journal of Marketing Research, vol. 43, no. 3, pp.
345–354, 2006.
[3]
Q. Li, J. Zhang, and K. M. Martin, “Feedback as ”shadow of the present”:
An alternative to reputation systems for e-marketplaces.” in TrustCom,
G. Min, Y. Wu, L. C. Liu, X. Jin, S. A. Jarvis, and A. Y. Al-Dubai, Eds.
IEEE Computer Society, 2012, pp. 334–341.
[4]
N. Miller, P. Resnick, and R. Zeckhauser, “Eliciting informative feed-
back: The peer-prediction method.” Management Science, vol. 51, no. 9,
pp. 1359–1373, 2005.
[5]
C. Dellarocas, R. Narayan, and C. Park, “What motivates people to
review a product online? A study of the product-speciﬁc antecedents of
online movie ratings,” Workshop on Information Systems and Economics
(WISE), 2006.
[6]
S. Aciar, D. Zhang, S. J. Simoff, and J. K. Debenham, “Informed
recommender: Basing recommendations on consumer product reviews,”
IEEE Intelligent Systems, vol. 22, no. 3, pp. 39–47, 2007.
[7]
N. Archak, A. Ghose, and P. Ipeirotis, “Show me the money! Deriving
the pricing power of product features by mining consumer reviews,” in
Proceedings of the ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD), 2007, pp. 56–65.
[8]
J. Yu, Z.-J. Zha, M. Wang, and T.-S. Chua, “Aspect ranking: Identifying
important product aspects from online consumer reviews,” in ACL,
D. Lin, Y. Matsumoto, and R. Mihalcea, Eds.
The Association for
Computer Linguistics, 2011, pp. 1496–1505.
[9]
G. H. Freeman and T. R. Halton, “Note on an exact treatment of contin-
gency, goodness of ﬁt and other problems of signiﬁcance,” Biometrika,
vol. 38, pp. 141–149, 1951.
6
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-369-8
CENTRIC 2014 : The Seventh International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

