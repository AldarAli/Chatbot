 
Live Geography: Interoperable Geo-Sensor Webs 
Facilitating the Vision of Digital Earth  
Bernd Resch 1,2 
Research Scientist 
bernd.resch@researchstudio.at 
Thomas Blaschke 1 
Head of Department 
thomas.blaschke@sbg.ac.at 
Manfred Mittlboeck 1 
Key Researcher 
manfred.mittlboeck@researchstudio.at 
 
 1 Research Studios Austria 
studio iSPACE 
Leopoldskronstrasse 30 
5020 Salzburg, Austria 
 
2 MIT 
SENSEable City Lab 
77 Massachusetts Avenue 
building 10, room 400 
Cambridge, MA 02139, USA 
 
 
 
 
Abstract – In the last decade, rapidly declining sensor costs and 
intense research in sensor technologies lead to the deployment 
of a number of sensor networks. However, most of these sensor 
networks are monolithic stovepipe-like systems causing limited 
interoperability and reusability of both data and workflow 
components. We present a Live Geography approach which 
integrates real-time measurement data in a fully standardised 
infrastructure and couples it with Complex Event Processing 
(CEP). We demonstrate the interoperability of this geo-sensor 
web approach and the resulting high degree of flexibility and 
portability beyond single monitoring applications generally 
and for five concrete real-world implementations in different 
application fields. We prove that the Live Geography approach 
allows for reacting to observed changes through sophisticated 
embedded processing based on OGC standards such as Sensor 
Observation Service (SOS) and Sensor Alert Service (SAS). 
Finally, we discuss how this approach contributes to the vision 
of Digital Earth as described by Al Gore in 1998 and how it 
contributes to monitor continuously the status of the 
environment, of urban infrastructure and the location and 
health conditions of persons to support an understanding of 
dynamic processes, to enhance prediction of developments, and 
to serve Spatial Decision Support Systems.   
Keywords – Live Geography; Standardised Geo-sensors; 
Embedded Sensor Webs; OGC Sensor Web Enablement; 
Interoperable Monitoring Systems; Digital Earth. 
I. 
 INTRODUCTION 
Monitoring 
single 
environmental 
parameters 
is 
established in many fields such as measuring water levels, 
precipitation, air quality, or traffic volume, and plenty more. 
Especially in urban areas the need for monitoring capabilities 
is increasing both from a technical side in regard to urban 
management, infrastructure planning and development 
capabilities, as well as from a more citizen-centered 
perspective aiming to support health applications, quality of 
life, or „geodemographics”. The latter term shall be a 
synonym for analysing the „Where“ of people, groups and 
populations based on tight coupling of absolute locations of 
individuals, relative movements and – if available – further 
parameters of the individuals.  
The ability to monitor the behaviour of people is still 
very limited for most city administrations. A mayor or a 
responsible security manager is usually not able to state how 
many people are at a certain place at a certain time. One 
department may know the number of vehicles travelled at an 
inbound route over the last hour, another information system 
may report on air quality. Existing demographics may reveal 
where people sleep or work but do not directly tell how 
many persons may be present at a certain central place in a 
city, e.g., at 10am on a Monday morning. Surveillance 
cameras may provide a first picture at critical locations, but 
are typically not meant to be quantitatively exploited or in 
regard to spatial movement patterns.   
In other words, integrated monitoring capabilities are 
critical in cities to ensure public safety including the state of 
the national infrastructure, to set up continuous information 
services, and to provide input for spatial decision support 
systems [1]. 
However, establishing an overarching monitoring system 
is not trivial. Up to now, different authorities with 
heterogeneous interests each implemented their own 
monolithic sensor systems to achieve specific goals. For 
instance, regional governments measure water levels for 
flood water prediction, while local governments monitor air 
quality to dynamically adapt traffic conditions, and energy 
providers assess water flow in order to estimate energy 
potentials. However, these data are mostly not combinable 
due to different data formats, proprietary protocols or closed-
off data access. 
This restricts automated workflows and machine-to-
machine communication, and prohibits the achievement of 
the long-term vision of a „digital skin for the Earth” [2], 
comprised 
of 
innumerable 
heterogeneous 
sensors, 
discoverable and accessible over the internet. 
323
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
In this regard, it is interesting to read how the future of 
the year 2010 was predicted in 1999: “Ten years from now, 
there will be trillions of such telemetric systems, each with a 
microprocessor brain and a radio. Consultant Ernst & Young 
predicts that by 2010, there will be 10,000 telemetric devices 
for every human being on the planet. They'll be in constant 
contact with one another” [2]. This optimistic view may have 
been inspired by the famous speech of the American Vice-
President Al Gore in 1998 [3]. 
 “Digital Earth” was and still is a vision of a multi-
resolution, three-dimensional representation of the planet 
that would make it possible to find, visualise, and make 
sense of vast amounts of geo-referenced information on the 
physical and social environment. Such a system would allow 
users to navigate through space and time, access to historical 
data as well as future predictions based for example on 
environmental models, and support access and use by 
scientists, policy-makers, and children alike [3]. 
At this time, this vision of Digital Earth seemed almost 
impossible to achieve given the requirements it implied 
about access to computer processing cycles, broadband 
internet, interoperability of systems, and above all data 
organisation, storage, and retrieval [4]. 
Generally speaking, the integration of inhomogeneous 
data poses great challenges, e.g., regarding multi source and 
heterogeneous, multi-disciplinary, multi-temporal, multi-
resolution, and multi-media, multi-lingual information. It is 
more and more believed that interoperability is key to a 
success of ubiquitous monitoring. This requires data pre-
processing following strict and rigid rules in monolithic 
sensor systems, in order to fit the specific non-recurring 
interfaces of the analysis system. Such analysis systems 
mostly analyse data in a closed black-box model, and usually 
provide data in a singular and application-tailored format 
preventing open use and re-use of processed data. When 
these systems are deployed in an isolated and uncoordinated 
way automatic assembly and analysis of these diverse data 
streams is impossible. However, making use of all available 
data sources is a prerequisite for holistic and successful 
monitoring for broad decision support using pervasive 
measurement systems. Thus, recent research increasingly 
addresses standardised interoperable sensor devices enabling 
the establishment of portable domain-independent sensing 
infrastructures [5], [6], [7]. 
This vision of fully integrated and interoperable sensing 
workflows fosters awareness for the benefits of open 
measurement systems. This is especially important for 
critical monitoring tasks such as emergency management, 
environmental monitoring or real-time traffic planning, 
which are not only relevant to the sensor network operators, 
but also for the city management and for the citizens. 
This paper presents the Live Geography approach, which 
proposes a fully standards-based distributed infrastructure 
combining current sensor data with Complex Event 
Processing (CEP) mechanisms, alerting and server-based 
analysis systems for a wide range of monitoring applications 
[8]. This approach’s main contribution is the creation of a 
generic standardised sensing and analysis infrastructure, 
which can be applied to a variety of end applications. This 
paper illustrates how the developed technical infrastructure 
can be applied in a broad range of application contexts. The 
architecture itself and its performance are described in more 
detail in [8] and in [9], respectively. 
This paper is structured as follows. After this 
introduction, Section II presents related work in the field of 
distributed sensing infrastructures; Sections III and V 
describe the Live Geography approach and its deployment in 
various heterogeneous application areas; Section IV 
illustrates the challenges and our specific implementation of 
geo-sensor webs, while Section VI contains a short 
conclusion. 
II. 
RELATED WORK 
The Oklahoma City Micronet [10] is a network of 40 
automated environmental monitoring stations across the 
Oklahoma City metropolitan area. The network consists of 4 
Oklahoma Mesonet stations and 36 sites mounted on traffic 
signals. At each traffic signal site, atmospheric conditions are 
measured and transmitted every minute to a central facility. 
One major shortcoming of the system is that it is a highly 
specialised implementation not using open standards or 
aiming at portability. The same applies to CORIE [11], 
which is a pilot environmental observation and forecasting 
system (EOFS) for the Columbia River. It integrates a real-
time sensor network, a data management system and 
advanced numerical models. 
Another sensing infrastructure named CitySense is 
described by Murty et al. [12]. The CitySense project uses an 
urban sensor network to measure environmental parameters 
and is thus the data source for further data analysis. The 
project focuses on the development of a city-wide sensing 
system using an optimised network infrastructure. 
King's College London designed an urban sensor 
network for air quality monitoring. The London Air Quality 
Network (LAQN) [13] currently consists of about 150 
monitoring sites being a very promising approach to real-
time monitoring as it also offers on-the-fly creation of 
statistic graphs, time series diagrams and wind plots. 
However, the network does not make use of open standards 
as a whole, meaning that it is built up in a closed system, 
although sensor data are accessible over the internet and 
despite the fact that this solution has a great local 
significance, but limiting trans-regional inter-linkage with 
other similar approaches. 
One more example is the Networked Soil CO2 Sensing 
Systems developed by UCLA with the objective to examine 
the spatial and temporal heterogeneity of a soil environment 
within a forest area in the James Reserve. The soil 
environmental measurements are collected with ten stations, 
each of which consists of an array of belowground sensors 
including soil CO2, soil temperature, soil water content, and 
aboveground air temperature, relative humidity, and 
photosynthetic active radiation. Models are used that relate 
the aboveground microclimate and the soil measurements to 
belowground measurements made by the project’s sensors to 
„map“ the microclimate in a fine-grained resolution, and 
investigate soil CO2 fluxes depending on the local 
characteristics of the forest cover story [14]. 
324
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Volcano activity observation of the volcano Reventador 
in Ecuador in 2005–2008 is technically interesting with 
regard to the remoteness and inaccessibility of the area [15]. 
Two US Universities have collaborated for several sensor 
network deployments in the remote, inaccessible area at the 
active volcano. The objective of the sensor network was to 
test the ability to detect and measure tremor events of the 
volcano. The geo-sensor was deployed over a linear 
centrifugal stretch of 3Km network consisting of seismo-
acoustic sensors. The sensor nodes used short-range, battery-
preserving 
wireless 
multi-hop 
communication 
to 
communicate with each other and relay data, and the sensor 
network 
was 
connected 
via 
a 
long-distance 
radio 
communication link to a Freewave radio modem powered a 
solar-panel powered car battery at a make-shift observatory. 
The goal of the sensor network deployments was to detect 
and measure tremor events saved batteries lifespan. The 
nodes were programmed to compare a short-term average 
with a long-term average based on locally stored samples. If 
the difference was bigger than a threshold, a node would 
send a message to the base station. If a sufficient number of 
nodes reported an event, the base station triggered a data 
collection request to all nodes in the sensor network. 
Among various examples for mobile geo-sensor 
networks consisting of individual sensor nodes that are 
mobile or attached to mobile objects one convincing 
example is the management of ocean buoys [16]. 
More 
recently, 
the 
Martha’s 
Vineyard 
Coastal 
Observatory (MVCO), owned and operated by the Woods 
Hole Oceanographic Institution (WHOI), provided the test 
bed for the first part of the Q2O project, returning the 
GetCapabilities, 
DescribeSensor 
and 
GetObservation 
responses for real time offerings of waves every twenty 
minutes.  Wave parameters are computed using an acoustic 
Doppler current meter, deployed at the 12m isobath 
continuously measuring pressure and horizontal velocity at 2 
Hz. SensorML instances and SOS offerings were developed, 
describing the sensor characteristics, system provenance and 
lineage, and the computation of the derived wave height 
parameters.  Quality control tests recommended by the 
Waves Team of QARTOD were implemented and reported 
through the SWE offerings [17]. 
Most of these examples – and many others - exhibit 
pioneering efforts and contributed significantly to the 
development of Geo-Sensor Webs. However, common 
shortcomings of the approaches described above and other 
related efforts are that the system architectures are at best 
partly based on open (geospatial) standards, and thus limit 
interoperability of data and services. Such systems are not 
able to tackle the challenges of numerous sensors which are 
built in masses today to observe the Earth surface, 
atmosphere, solid Earth, and the ocean in different 
dimensions. At a global level efforts to overcome these 
challenges are increasingly channelled by the Global Earth 
Observation (GEO) within the developing Global Earth 
Observation System of Systems (GEOSS) [5], [6].  
Sensor derived information is not only been produced at 
various locations, with various accuracies, different timely 
and spatial acquisition patterns but also archived at widely 
distributed locations. The Live Geography approach employs 
the „Digital Earth“ vision for concatenating sensor 
information and other geospatial information which is also 
widely collected and archived with the aim to providing 
information services and ultimately solving challenging 
environmental and societal issues beyond single application 
domains. The Live Geography approach seeks to fully utilise 
all available information resources and to apply them 
„intelligently“. In the following section we will lay out how 
we ensure the information is being gathered, processed and 
distributed in a fully interoperable way through open, 
community-consensus standards among current users and 
how to process information on demand in order to use non-
expert users. 
III. 
LIVE GEOGRAPHY APPROACH 
Utilisation of real-time data in GIS applications requires 
a rethinking of existing practices. The authors even believe 
that the next generation of GIS will be driven by process 
models in a sense that users’ requests trigger algorithms and 
heuristics to perform specific services. An „on demand“ 
connection to information networks and an „intelligent“ 
harvesting of existing information in combination with real-
time or near real-time data will be key in such a service-
centred architecture. This may also require further advances 
in space-time data models ultimately contextualising 
Hägerstrand’s vision of a time geography [18]. The time-
space path, devised by Hägerstrand, shows the movement of 
an individual in the spatial-temporal environment with the 
constraints placed on the individual by these two factors. 
Only for the last few years, we are able to utilise location 
information from GPS, mobile phones or indoor navigation 
systems to make such concepts operational. Even more 
recently, researchers study the behavior of groups or larger 
populations of cities or accessibility aspect based on the 
space-time model [19].  
At present, we 
may 
diagnose that Geographic 
Information Systems begin to evolve from „classic“ 
geospatial data analysis to more „on demand“ analysis. The 
GIS workflow established in the 1960ies and 1970ies may be 
deliberately characterised that analysis is performed in costly 
specialised software involving a high degree of manual 
intervention for data gathering, pre-processing and quality 
assurance. Furthermore, geospatial analysis has in a vast 
majority of cases been applied to „not up-to-date” data (at 
the very time of the analysis) with typically long cycles from 
data generation to analysis output and a real-world impact. 
While custodial GIS may predominantly still be associated 
with this style of information processing research in 
Geographic Information Science has paved the road towards 
„information harvesting“ on demand in spatial data 
infrastructures (see various publication in the recent issues of 
„International Journal of Digital Earth” or „International 
Journal of Spatial Data Infrastructures Research“).  
Generally speaking, sensor webs have only emerged very 
recently because of increasingly reliable communication 
technologies, affordable embedded devices and growing 
importance of sensor data for (near) real-time decision 
325
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
support (see discussion in Section V). They monitor 
phenomena in Geographic space [20]. 
The criteria for sensor webs are threefold. The first 
characteristic is interoperability, which means that different 
types of sensors should be able to communicate with each 
other and produce a common output. The requirement of 
scalability implies that new sensors can be easily added to an 
existing topology without necessitating aggravating changes 
in the present hardware and software infrastructure. Finally, 
intelligence means that the sensors are able to „think“ 
autonomously to a certain degree, which could for instance 
result in a data processing ability in order to only send 
required data. 
In a recent overview on Geo-Sensor Webs [21] three 
major trends are identified: the first trend is the currently 
more readily available technology of seemingly ubiquitous 
wireless communication networks, including access in 
remote 
and 
inaccessible 
areas 
without 
a 
wired 
communication infrastructure and often without even power 
lines. Furthermore, significant progress has been made in the 
development 
of 
low-power, 
short-range 
radio-based 
communication networks, which augment existing long-
distance wireless communication networks. Second, the 
miniaturisation of computing and storage platforms has led 
to low power consumption and has enabled novel 
computational platforms that can run on battery power for 
extended periods of time (e.g., several months with today’s 
technology). The third major trend is the development of 
novel sensors and sensor materials; this includes improved 
and size-reduced traditional sensors as well as the 
development of novel micro-scale sensors and sensor 
materials. For example, novel bio-chemical sensors may be 
used in the marine sciences or air pollution monitoring, or 
highly sensitive vibration and sound sensors have been 
applied for volcano monitoring. 
Operational real-world sensor network applications are 
still rare and the majority still serves a single purpose, which 
limits broader usage of measurement data. This section 
presents the Live Geography approach. It proposes a flexible 
and portable measurement infrastructure enabling a wide 
variety of real-time and near real-time monitoring 
applications. The system makes extensive use of open 
(geospatial) standards throughout the entire process chain – 
from sensor data integration to analysis, Complex Event 
Processing 
(CEP), 
alerting, 
and 
finally 
information 
visualisation. The basic architecture for such applications is 
illustrated in Fig. 1. 
 
Figure 1.  Basic Architecture Components and Standardised Interfaces of 
the Live Geography Infrastructure. 
Generally speaking, the infrastructure shown in Fig. 1 
can be sub-divided in five components, i.e., stand-alone 
parts, which have to be conflated. Component 1 is the geo-
sensor network itself including measurement devices Global 
Navigation Satellite System (GNSS) connectivity and basic 
processing 
capabilities. 
Component 
2 
covers 
the 
communication of the sensor network with a data centre via 
a variety of wireless and wired transmission technologies. 
Component 
3 
deals 
with 
sensor 
fusion, 
i.e., 
the 
harmonisation of measurements stemming from different 
heterogeneous sensor networks. Component 4 comprises the 
application-specific analysis of the sensor data on the server 
side. This operation does not only include pure sensor data 
processing, but also the integration of static and legacy 
geospatial data. Component 5 finally treats the presentation 
of analysed data depending on the particular requirements of 
end users or user groups. 
As the Live Geography approach accounts for the entire 
workflow, it builds the architectural bridge between domain-
independent sensor network development and use case 
specific requirements for end user sensitive information 
output.  
The implementation of the Live Geography approach 
only became feasible through the sharp decline of sensor 
costs over the last decade and intense research in sensor 
technologies (for an overview see [21]). This fact, together 
with miniaturisation efforts, increasing monitoring demands 
due to increasing pressure on resources, environmental 
regulations, security regulations and – at least partially - 
rising awareness of the benefits of automated real-time 
sensor applications, resulted in the deployment of a number 
of geo-sensor networks. 
This in turn will result in the emergence of vast amounts 
of sensor data during the next years. A main challenge will 
be to harmonise these data and integrate them in real-time 
into geospatial analysis systems. 
IV. 
LIVE GEOGRAPHY: IMPLEMENTATION OF AN 
INTEROPERABLE EMBEDDED GEO-SENSOR WEB 
A. Standardisation Enabling Open Measurement 
Infrastructures 
The increasing amount of data measured triggers a more 
extensive use of open standards and geospatial web services 
for structuring and managing heterogeneous data. The Open 
Geospatial Consortium (OGC) has achieved remarkable 
progress in setting up necessary standards (see Sub-section 
IV.C). One of the remaining challenges is the distributed 
processing of large amounts of sensor data in real-time, as 
the widespread availability of sensor data with high spatial 
and temporal resolution will increase dramatically with 
rapidly decreasing prices [8], [21], particularly if costs are 
driven down by mass utilisation. 
From a political and legal standpoint, national and 
international legislative bodies are called upon to foster the 
introduction of open standards in public institutions. Strong 
early efforts in this direction have been made by the 
European Commission through targeted, including the 
INSPIRE (INfrastructure for SPatial InfoRmation in 
326
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Europe), which aims at Europe-wide harmonisation of 
discovery and usage of geographical data for analysing and 
solving environmental problems [22]. 
These regulations both trigger and support the 
development of ubiquitous and generically applicable real-
time data integration mechanisms. Shifting development 
away from proprietary single-purpose implementations 
towards interoperable analysis systems will not only enable 
live assessment our environment, but can also lead to a new 
perception of our surroundings in general, e.g., expressed by 
the vision of a “digital skin” [1]. Consequently, this trend 
may in turn foster the creation of innovative applications that 
treat the city as an interactive sensing platform, as the 
WikiCity concept [23], involving the people themselves into 
re-shaping their own socio-technical context. This way, we 
may enable a manifestation of the vision of “citizens as 
sensors” [24]. 
B. Embedded Device Hardware 
The measurement device for the concrete implementation 
presented in this paper has been particularly designed for 
pervasive GIS applications using ubiquitous embedded 
sensing technologies. The system has been conceived in such 
a modular way that the base platform can be used within a 
variety of sensor web applications such as environmental 
monitoring, biometric parameter surveillance, critical 
infrastructure protection or energy network observation by 
simply changing the interfaced sensors. 
The sensor pod itself consists of a COTS embedded 
device, ISEE IGEPv2 platform including an ARM7-based 
Cortex A8 600MHz processor with 512MB RAM and 32MB 
flash memory. Generally speaking, ISEE offers a highly 
modular and easily expandable system. The computer-on-
module (the actual embedded device including CPU, 
memory and some interfaces) offers two I/O ports, which 
allows for extensibility of the basic system by specific 
modules such as GPS, Bluetooth, WiFi, LAN, interface 
breakouts or a console board for programming the device. 
In the configuration for the specific implementation 
presented within this paper, different sensors (GPS module, 
LM92 for ambient temperature, SHT15 for air temperature 
and humidity, NONIN 8000SM oxygen saturation and pulse, 
or SSM1 radiation sensors) have been attached via 
standardised interfaces like UART, I2C, USB, etc. The 
technical specifics of the sensor pod are described by Resch 
et al. [9]. 
The size of the complete sensor pod is approximately 
93x65x10mm, i.e., about the size of a chewing gum package. 
In full load, the device features an energy consumption of 
<2.2W including a running data query, the GPS module and 
data transmission via UMTS, which is known to be 
comparatively energy intensive way of broadcasting data. 
This configuration yields an operation time of 9.1 hours 
given a battery capacity of 4000mAh, which is held by a 
reasonably-sized rechargeable Lithium-ion Polymer (LiPo) 
battery (140x40x10mm) – whereby capacity and required 
sizes depend on the specific use case. 
C. Embedded Software Infrastructure 
The sensing device runs a customised version of the 
Ångström Linux distribution (kernel version 2.6.33) with an 
overall footprint of about 2MB. The software infrastructure 
comprises an embedded secure web server (Lighttpd), an 
SQLite database and several daemons, which convert sensor 
readings before they are served to the web. The database 
serves for short-term storage of historic measurements to 
allow for different error detection procedures and plausibility 
checks, as well as for non-sophisticated trend analysis. 
The hardware drivers for interfacing sensors and reading 
their measurements make up the low-level part of the 
embedded software infrastructure. As the geographical 
position is an essential must-parameter in geo-sensor 
networks, the sensor pod interfaces a location sensor (e.g., a 
GPS/Galileo module, a ZigBee/WiFi-based positioning 
component, etc.). 
These measurements are then read by a special sensor 
daemon that essentially builds the bridge between the sensors 
and the internal software components. These data are then 
stored into an embedded database (SQLite), which is held at 
a maximum data set volume, currently 12500 readings. 
The sensor data, which is stored in the database, is then 
accessed from two different web servers (HTTP/HTTPS and 
XMPP [Extensible Messaging and Presence Protocol]), 
which make the measurements accessible from the internet. 
HTTPS is considered a high enough security level for this 
implementation providing a secure channel between server 
and client using the Secure Socket Layer (SSL) protocol. 
Web Service Security (WSS) would be a viable alternative 
providing message-based security. However, as WSS is 
using the SOAP protocol, it is characterised by large 
overhead, which is not suitable for embedded sensor unit 
implementations. 
Communication of the sensing device with other 
components in the workflow is based on open standards of 
the Sensor Web Enablement (SWE) family [25]. This 
requires 
a 
SensorML-conformal 
description 
of 
the 
measurement platform, Observations and Measurements 
(O&M) compliant encapsulation of measurement values, as 
well as an SAS-compliant alerting module. In addition, an 
embedded database has to be implemented directly on the 
sensor device to provide for the possibility of short-term data 
storage, which enables trend analysis and quality assurance, 
and reduces communication overhead with the central 
archive database. Thus, the device also implements the 
following essential standards of the SWE family: 
• 
Observations & Measurements (O&M) – O&M 
allows for the formalised description of sensor 
measurements in a structured XML-based encoding 
schema. Thus, O&M can map sensor parameters and 
their relations. Measurements are organised by 
quantities, categories as well as their spatial and 
temporal characteristics. 
• 
Sensor Model Language (SensorML) – The Sensor 
Model Language (SensorML) is a general schema 
for describing functional models of the sensor. 
327
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Information 
provided 
by 
SensorML 
includes 
observation and geometry characteristics as well as a 
description and a documentation of the sensor, and a 
history of the component’s creation, modification, 
inspection or deployment. 
• 
Sensor Observation Service (SOS) – SOS allows for 
standardised access to sensor measurements (return 
type O&M) and their platform descriptions (return 
type SensorML) via a web service interface [26]. 
• 
Sensor Alert Service (SAS) – SAS is a service for the 
surveillance of pre-defined rules and trigger 
specified actions in a particular workflow in case of 
violation of these rules. 
D. In Detail: Embedded Sensor Observation Service (SOS) 
and Sensor Alert Service (SAS) 
The embedded SOS implements the three mandatory 
methods, 
DescribeSensor, 
GetCapabilites 
and 
GetObservation. 
Basically, 
the 
service, 
which 
is 
implemented in Common Gateway Interface (CGI), parses 
the request and creates the according response using 
appropriate XML templates. 
The SOS harmonises raw sensor measurements by 
encapsulating them into pre-defined XML-based OGC O&M 
format. This allows for the provision of sensor measurements 
(numerical values, raster images, binary states, complex or 
combined measurement data, etc.) in a structured and 
standardised format. 
For generating alerts, the OGC Sensor Alert Service 
(SAS) standard has been implemented for mobile sensor 
devices. SAS, which is part of the SWE initiative, specifies 
interfaces (not a service in the traditional sense) enabling 
sensors to advertise and publish alerts including according 
metadata. Alerts are defined as “data” sent from the SAS to 
the client, which may as well comprise alerts/notifications 
(e.g., 
OGC 
Web 
notification 
service 
[WNS]) 
as 
observational data (measurements matching pre-defined 
criteria) or a Complex Event Processing Engine (CEP). As 
SAS is based on the standardised XMPP protocol, alerts can 
be broadcasted very efficiently over the internet to 
subscribed consumers. 
The service implementation presented in this paper 
supports the mandatory operations as specified in the 
standard, 
namely 
DescribeSensor, 
DescribeAlert, 
GetCapabilities, 
Subscribe, 
RenewSubscription 
and 
CancelSubscription [27]. 
In this case, SAS is an asynchronous service connecting a 
sensor in a network to an observation client. In order to 
receive alerts, a client subscribes to the SAS. If the defined 
rules apply, a pre-defined alert is sent to the client via 
XMPP. It shall be stated that the whole communication 
between the embedded XMPP server (jabberd2) and the 
client is XML-based for simplifying M2M messaging. 
V. 
LIVE GEOGRAPHY PORTABILITY – IMPLEMENTED 
END APPLICATIONS 
This 
section 
describes 
five 
concrete 
real-world 
implementations in different application fields in order to 
demonstrate 
that 
the 
approach 
is 
highly 
portable, 
interoperable and flexible in terms of trans-domain usage and 
integration of heterogeneous data sources. This again builds 
the basis for the deployment of an overarching monitoring 
infrastructure for solving real-time analysis questions across 
a variety of research and service areas. 
A. Live Pollutant Monitoring for Public Health 
The Common Scents project focuses on real-time 
pollutant monitoring for public health. As Zardini [28] states, 
“we have renounced the utopian idea of a socially, 
politically, and economically perfect city, but not the 
promise of a perfectly clean and sanitised environment with 
pure air for breathing.” 
Thus, the goal of the project, which is a concerted effort 
of the MIT SENSEable City Lab, the Research Studio 
iSPACE, the Harvard University Sensor Networks Lab, the 
City of Cambridge’s Public Health Department, and BBN 
Technologies, is to provide fine-grained air quality 
information layers in near real-time. To achieve this vision, 
the CitySense sensor testbed [12] is utilised, measuring CO2 
concentrations along with environmental parameters like 
wind speed, air temperature, and relative humidity. 
The empirical project goal is to provide citizens with up-
to-date information to support short-term decisions in real-
time. Here, the term “real-time” is not defined by a pre-set 
numerical time constant, but more by qualitative expressions 
such as “immediately” or “ad-hoc”, i.e., information layers 
are created in a timely manner to serve application-specific 
purposes. Detailed results are presented by Resch et al. [29]. 
The actual implementation shown in Fig. 2 allows for 
correlating temporal measurement data fluctuation to traffic 
density, and other day-time related differences. The lower 
left part of Fig. 2 shows the temporal development of the 
sensor values, which have been integrated in the standardised 
O&M format. Running the time series dynamically changes 
symbologies in the map on the right side accordingly. 
 
Figure 2.  Time Series Visualisation of Pollutant Measurements in an 
ESRI ArcGIS software environment. 
328
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
B. Fine-grained Air Temperature Variations 
Another implementation of the Live Geography has been 
done in the course of the Real-time Geo-awareness project in 
a cooperative effort of the Research Studio iSPACE and 
SYNERGIS Informationssysteme GmbH. Apart from the 
establishment of the technical components (sensor devices, 
data integration and analysis), the project’s aim was to create 
a sensor network for fine-grained temperature variation 
assessment. 
The pervasive deployment of temperature sensors can 
lead to a detection of urban heat islands with a fine spatial 
resolution. Furthermore, the temperature measurements can 
be used for correlation with other environmental parameters 
such as air pollution, ozone or emissions caused by increased 
traffic emergence. Thus, an essential part of this particular 
implementation is the alerting functionality, which is 
achieved by the use of an OGC Sensor Alert Service (SAS), 
generating alerts according to pre-defined events, i.e., 
exceedance of pre-defined thresholds. These events are 
detected by a Complex Event Processing (CEP) engine that 
also serves for data quality control by identifying 
measurement outliers and performing other spatio-temporal 
plausibility controls. 
Fig. 3 shows the three-dimensional Inverse Distance 
Weighting (IDW) interpolation result of air temperature 
values provided by various OGC Sensor Observation 
Services (SOS). More implementation details are described 
by Resch et al. [8]. 
 
Figure 3.  Real-Time Interpolation of Ambient Temperature Values for 
Monitoring Optimal Environmental Parameters for the Local Fauna and 
Flora in the National Park Berchtesgaden, Germany. 
C. Ubiquitous Biometric Parameter Surveillance 
The geoHealth Monitor instance of the Live Geography 
approach responds to the needs of pervasive medical care. 
The system uses biometric sensors measuring a person’s 
pulse and oxygen saturation in the blood. The project itself 
has been carried out in cooperation between the Research 
Studio iSPACE and Salzburg University of Applied 
Sciences. 
The web interface shown in Fig. 4 comprises three 
sections. Firstly, a configuration panel to select a particular 
sensing device including different measurement parameters 
such as the update frequency or the number of measurements 
stored in the history. The middle section presents the 
temporal history of OGC Sensor Web Enablement conformal 
sensor data, which allows for intuitive visual assessment of 
the measured parameters. Finally, the map on the right side 
of the interface shows the last few positions of the 
measurement device to keep track of its spatial trace. 
It shall be stated the geoHealth Monitor application 
cannot only be used for patient surveillance, but may also be 
employed for equipment tracking, control of the food supply 
chain including the goods’ measured quality condition, or for 
keeping track of a stolen car. 
 
Figure 4.  Illustration of a “GeoHealth“ application: Biometric Parameter 
History with Geographical Location Illustration demonstrated in a MS 
Silverlight environment. 
D. Real-time Air Quality Assessment 
GENESIS (GENeric European Sustainable Information 
Space for environment), an FP7-funded collaborative 
research project, has two basic aims: 1.) to establish an open 
and standards-based infrastructure for managing, analysing 
and providing environmental information, and 2.) to 
demonstrate the efficiency of the solution through thematic 
pilots in different areas within environmental pilot 
deployments for air quality, water quality and associated 
health impacts. 
The Live Geography approach supports the GENESIS 
project as it builds the technological foundation for the 
thematic pilots by providing mechanisms for measurement 
data provision (Sensor Observation Service), sensor fusion 
(GeoServer data store), alerting (SAS and CEP) and server-
based data analysis (ArcGIS Server application). Fig. 5 
illustrates the web interface for live geo-data analysis of 
environmental information implemented in a kriging process. 
A special focus in GENESIS is on the coupling of SAS and 
CEP including the evaluation of the OGC Sensor Event 
Service (SES), which is widely seen as the successor of SAS. 
In the project, CEP serves for detecting complex patterns in 
sensor data related to spatial and temporal parameters as well 
as measurement values. Another emphasis is on integrating 
329
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
legacy GIS systems (ArcGIS Server, GRASS GIS, etc.) with 
the standardised OGC Web Processing Service (WPS) 
interface to achieve a wholly standardised workflow coupled 
by a Business Process Execution Language (BPEL) engine. 
The Live Geography solution is likely to be integrated 
into the overall GENESIS infrastructure, which finally aims 
at 
Europe-wide 
Spatial 
Data 
Infrastructure 
(SDI) 
harmonisation and provision of a complete infrastructure for 
standardised data access and analysis. For more information 
on the architecture and outcomes, see [30]. 
 
Figure 5.  Web-based Live Geo-processing for Fine-grained Real-time 
Assessment of Urban Air Quality. 
E. Real-time Decision Support for Radiation Safety 
Finally, the Live Geography workflow has been applied 
and evaluated in the course of the FP6 ERA Star G2real 
project exercise ‘Shining Garden’ in Seibersdorf, Austria. 
The field trial setup consisted of modules for live in-situ 
sensing of gamma radiation (using the SSM-1 radiation 
detection unit developed by Seibersdorf Laboratories), live 
geo-processing of radiation measurements, and rapid 
mapping of up-to-date multi-dimensional sensor information. 
The purple dots in Fig. 6 represent the trace of the 
radiation safety expert carrying the sensor device. Location 
data and radiation measurements were collected every 
second. These sensor data were spatially interpolated (in this 
case using the Inverse Distance Weighting – IDW 
algorithm). Partitions 1-6 in the figure below show the 
growing interpolation result in chronological order. 
 
Figure 6.  Growing Interpolation Result for Radiation Source 
Identification. 
Results of this experiment confirm that the Live 
Geography workflow significantly enhances both spatial and 
situational awareness of people in charge. This in turn 
enhances time-critical spatial decision support. Detailed 
results of the field test can be found in [31]. General design 
challenges are discussed in [9]. 
VI. 
DISCUSSION AND CONCLUSION 
With the prerequisites and challenges of real-time 
monitoring in mind, we developed the Live Geography 
approach. It provides an interoperable, modular and flexible 
distributed sensing and data analysis infrastructure – as 
opposed to previous monolithic sensor networks. Thus, it 
stands for the integration of real-time measurement data in a 
fully standardised infrastructure for real-time monitoring 
applications including web-based data processing. 
The main benefit of the Live Geography architecture 
presented in this paper is its composition in loosely-coupled 
and service-oriented building blocks. This allows for 
decoupling sensor fusion from CEP, data analysis and 
visualisation components, enabling flexible and dynamic 
service chaining. Consequently, the whole infrastructure can 
be ported easily to various application domains by changing 
the sensors (what shall be measured) and the process models 
(how shall the measurements be analysed). 
To demonstrate the Live Geography approach’s 
portability, five concrete real-world implementations in 
different application fields have been presented in this paper. 
This is to show that the approach is highly portable and 
flexible in terms of trans-domain usage and integration of 
heterogeneous data sources. This again builds the basis for 
the deployment of an overarching monitoring infrastructure 
for solving real-time analysis questions across a variety of 
research and service areas. In the future, platforms may 
generally get more lightweight and portable, which opens up 
a plethora of new application areas for which platforms have 
been too expensive or too difficult to deploy before. Another 
important aspect is real-time data delivery of information on 
demand. 
Consequently, it can be stated that a substantial benefit of 
the approach is that the developed infrastructure is applicable 
to a wide variety of cross-domain use cases due to its high 
degree of interoperability, modularity and flexibility. 
With the dramatic decrease of sensor costs as occurring 
recently, it can be assumed that even larger and even more 
heterogeneous amounts of measurement data will be 
available in the near future. A major future research task will 
be 
the 
standardisation 
and 
combination 
of 
these 
heterogeneous 
data 
sources 
using 
internationally 
standardised 
interfaces. 
Recently, 
several 
„testbed“, 
„experiment“, or „pilot“ activities are carried out worldwide 
such as the Web Services-OWS7 Testbed initiative the OGC 
which demonstrated the advantages of interoperable 
measurements infrastructures generally, the OGC Ocean 
Science Interoperability Experiment (Oceans IE) or the 
GEOSS Architecture Implementation Pilot. To summarise, 
although SWE  is  still  evolving and new  services  will  be  
developed  to  satisfy  emerging requirements of sensor web 
development OGC and ISO standards for „localised 
330
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
information“ discovery, retrieval and communication are 
increasingly providing a baseline needed for interoperability 
and portability. Furthermore, SensorML can be used outside 
the scope of SWE enabling long-term archive of sensor data 
to be reprocessed and refined in the future allowing software 
systems  to process, analyse and perform a visual fusion of 
multiple sensors [32]. 
Further research will elucidate the applicability of the 
Live Geography approach for situation awareness. Although 
preliminary work has demonstrated the potential of using 
combination of prevailing sensor data with real-time 
processing mechanisms to achieve situational awareness for 
an instantaneous assessment of environmental conditions 
[33] the advantage of the complete system described in this 
paper is that hitherto GIS approaches, which offered GIS 
functionality 
only 
in 
resource-consuming 
desktop 
applications, can be replaced by web-based analysis tools. 
GIS operations are performed on server-side whereas the 
results are sent to the client, which can for instance be an 
internet-connected personal computer in the mission control 
centre or also a tablet PC used by action forces on-site. This 
will allow for a real-time situational awareness making 
emergency and rescue actions much more efficient. 
Situational awareness is the perception of elements in the 
environment within a volume of time and space, the 
comprehension of their meaning, and the projection of their 
status in the near future [28]. In the context of sensor data 
about the real world, this may be translated to: (1) detecting 
and recognising objects and events, (2) determining how 
they are interrelated, and (3) predicting how things are going 
to change over a period of time going forward [34]. These 
developments may change the GIS community significantly 
and they do so already. Geo-processing featured prominently 
in the early origins of online GIS where server-based GIS 
delegated much of the work that a desktop-client would 
perform to the background, hidden from the user [35].  
The Live Geography approach has been made possible 
through the availability of both the body of standards 
described herein and the GIS-based investigation tools: we 
can build the means to facilitate analyses and appropriate 
characterisations of various processes involved many 
application areas proofed for five different applications. In 
turn, we might hope to achieve the further problem 
formalisation steps thanks to the result of our better 
understanding of complex systems. This is a prevalent topic 
in Geographic Information Science [36]. We are making 
progress beyond a reconstruction of the current state of the 
world from sensor data to reasoning from observed effects to 
possible causes. Predicting the future states or course of 
action is akin to deduction in logic, that is, reasoning from 
causes to effects [34]. In the future, situation awareness 
applications may benefit from symbolic representation of the 
state of the world by adding spatial reasoning capacities to 
our interoperable framework and by incorporating schemes 
from time geography into the Live Geography approach 
allowing structured queries to be performed on data’s 
temporal and spatial attributes simultaneously. 
The ability to obtain all kinds of sensor information at 
decreasing costs with higher measuring accuracies unlocks 
research potential and potentially end user applications to 
creating information at ever higher abstraction levels. This 
may cause now types of problems. The ability to determine 
and view locations and associated sensing information with 
high accuracy is increasingly in the hands of millions of 
people. Commonly available high-resolution digital terrain 
and aerial imagery, coupled with GPS-enabled handheld 
devices, powerful computers, and Web technology, is 
ultimately changing the quality, utility, and expectations of 
GIS to serve society. Analytic methods for non-expert users 
will need to be provided as millions of internet users learn to 
use data with greater detail and intensity, especially in terms 
of temporal resolution and the resulting amount of data and 
level of detail but they may not be aware of basic statistical 
and cartographic principles. GIS is more and more to be 
viewed as a media that helps data producers to communicate 
Geographic information in various forms to receivers, just as 
newspapers and television communicate more general forms 
of information [37]. 
Concluding, it shall be constituted that the main 
challenge in geo-sensor web research for monitoring 
applications in the coming years will be to harmonise 
existing networks with upcoming initiatives in order to 
guarantee 
optimal 
data 
availability 
for 
assessing 
environmental dynamics. As laid out, this requires a shift 
from 
monolithic 
single-purpose 
sensor 
systems 
to 
interoperable 
measurement 
infrastructures, 
which 
necessitates 
adequate 
public 
awareness 
and 
policy 
frameworks. This in turn allows for the straight-forward use 
of live sensor data in existing spatial decision support 
systems. 
ACKNOWLEDGMENT 
Our approach requires expertise in a wide variety of 
research areas such as sensor networks, data integration, GIS 
data and analysis, visualisation techniques, etc. We would 
like to thank all contributing groups at the Research Studio 
iSPACE, at MIT, at Salzburg University of Applied Sciences 
for their valuable inputs and contributions in different stages 
of the development process. 
Parts of the developments presented in this paper have 
been funded by the European Commission (FP7 project 
GENESIS, ref. no. 223996 and ERA STAR Regions project 
G2real, ref. no. 819747) and the Austrian Federal Ministry 
for Science and Research. 
REFERENCES 
[1] 
Resch, B. and Mittlboeck, M. (2010) Live Geography - Interoperable 
Geo-Sensor Webs Enabling Portability in Monitoring Applications. 
In: Proceedings of the 2nd IEEE International Conference on 
Advanced Geographic Information Systems, Applications, and 
Services - GEOProcessing 2010, St. Maarten, Netherlands Antilles, 
10-15 February 2010, pp. 74-79. 
[2] 
Gross, N. (1999) 14: The Earth Will Don an Electronic Skin. 
http://www.businessweek.com, BusinessWeek Online, 30 August 
1999. (2 January 2011) 
[3] 
Gore, A. (2010) The Digital Earth: Understanding our planet in the 
21st Century. Speech by Vice President Al Gore, Given at the 
California Science Center, Los Angeles, California, on January 31, 
1998. http://www.isde5.org/al_gore_speech.htm. (4 January 2011) 
331
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
[4] 
Craglia, M., Goodchild, M.F., Annoni, A., Camara, G., Gould, M., 
Kuhn, W., Mark, D., Masser, I., Maguire, D., Liang, S., and Parsons, 
E. (2008) Next-Generation Digital Earth: A Position Paper from the 
Vespucci Initiative for the Advancement of Geographic Information 
Science. International Journal of Spatial Data Infrastructures 
Research 1(3), pp. 146-167. 
[5] 
Yang, C., Li, W., Xie, J., and Zhou B. (2008) Distributed Geospatial 
Information Processing: Sharing Distributed Geospatial Resources to 
Support Digital Earth. International Journal of Digital Earth, 1(3), pp. 
259–278. 
[6] 
Nativi, S. (2010) The Implementation of International Geospatial 
Standards for Earth and Space Sciences. International Journal of 
Digital Earth, 3(S1), pp. 2–13. 
[7] 
Percivall, G. (2010) The Application of Open Standards to Enhance 
the Interoperability of Geoscience Information. International Journal 
of Digital Earth, 3(S1), pp. 14–30. 
[8] 
Resch, B., Mittlboeck, M., Girardin, F., Britter, R., and Ratti, C. 
(2009) Live Geography – Embedded Sensing for Standardised Urban 
Environmental Monitoring. International Journal on Advances in 
Systems and Measurements, 2(2&3), ISSN 1942-261x, pp. 156-167. 
[9] 
Resch, B., Lippautz, M., and Mittlboeck, M. (2010) Pervasive 
Monitoring - A Standardised Sensor Web Approach for Intelligent 
Sensing Infrastructures. Sensors - Special Issue "Intelligent Sensors 
2010", 10(12), 2010, pp. 11440-11467. 
[10] University of Oklahoma (2009) OKCnet. http://okc.mesonet.org, 
March 2009. (12 January 2011) 
[11] Center for Coastal and Land-Margin Research (2009) CORIE. 
http://www.ccalmr.ogi.edu/CORIE, June 2009 (14 July 2009) 
[12] Murty, R., Mainland, G., Rose, I., Chowdhury, A., Gosain, A., Bers, 
J., and Welsh, M. (2008) CitySense: A Vision for an Urban-Scale 
Wireless Networking Testbed. Proceedings of the 2008 IEEE 
International Conference on Technologies for Homeland Security, 
Waltham, MA, May 2008. 
[13] King's College London (2009) The London Air Quality Network. 
http://www.londonair.org.uk, August 2009. (3 February 2011) 
[14] Vargas, R., Allen, M., Swenson, W., and Hamilton, M. (2005) Soil 
Embedded Networked Systems for Studying Soil Carbon Dynamics: 
the A-MARSS Project. In Proceedings of Third USDA Symposium 
on Greenhouse Gases and Carbon Sequestration in Agriculture and 
Forestry, Baltimore, MA, USA, March 21–24, 2005. 
[15] Werner-Allen, G., Lorincz, K., Ruiz, M., Marcillo, O., Johnson, J., 
Lees, J., and Welsh, M. (2006) Deploying a Wireless Sensor Network 
on an Active Volcano. IEEE Internet Computing 2006, 10, pp. 18–25. 
[16] Nittel, S., Trigoni, N., Ferentinos, K., Neville, F., Nural, A., and 
Pettigrew, N. (2007) A Drift-tolerant Model for Data Management in 
Ocean Sensor Networks. Proceedings ACM MobiDE'07, Beijing. 
[17] Fredericks, J.J., Botts, M., Cook, T., and Bosch, J. (2009). Integrating 
Standards in Data QA/QC Into OpenGeospatial Consortium Sensor 
Observation Services. IEEE Xplore Oceans, 2009. 
[18] Hägerstrand, T. (1953) Innovationsförloppet ur korologisk synpunkt, 
C.W.K Gleerup, Lund, Sweden. Translated as Innovation Diffusion 
As a Spatial Process, Chicago, University of Chicago Press, 1967. 
[19] Pulselli, R.M., Romano, P., Ratti, C., and Tiezzi, E. (2008) 
Computing 
Urban 
Mobile 
Landscapes 
Through 
Monitoring 
Population Density Based on Cell-phone Chatting. International 
Journal of Design & Nature and Ecodynamics, 3(2), pp. 121-134.  
[20] Nittel, S., Labrinidis, A., and Stefanidis, A. (2006) Introduction in 
Geosensor Networks. In: Geosensor Networks Nittel, S., Labrinidis, 
A., Stefanidis, A. (eds.), Springer Lecture Notes in Computer Science 
4540, Heidelberg, pp. 1-6.  
[21] Nittel, S., (2009) A Survey of Geosensor Networks: Advances in 
Dynamic Environmental Monitoring. Sensors 9(7), pp. 5664-5678. 
[22] European 
Commission 
(2009) 
INSPIRE 
Directive. 
http://inspire.jrc.ec.europa.eu, August 2009. (7 February 2011) 
[23] Resch, B., Calabrese, F., Ratti, C., and Biderman, A. (2008) An 
Approach Towards a Real-time Data Exchange Platform System 
Architecture. In: Proceedings of the 6th Annual IEEE International 
Conference on Pervasive Computing and Communications, Hong 
Kong, 17-21 March 2008. 
[24] Goodchild M.F. (2007) Citizens as Sensors: Web 2.0 and the 
Volunteering of Geographic Information. Geofocus, 7, pp. 8-10. 
[25] Botts, M., Percivall, G., Reed, C., and Davidson, J. (Eds.) (2007) 
OGC® Sensor Web Enablement: Overview and High Level 
Architecture. http://www.opengeospatial.org, OpenGIS White Paper 
OGC 07-165, Version 3, 28 December 2007. (17 January 2011) 
[26] Na, A. and Priest, M. (Eds.) (2007) Sensor Observation Service. 
http://www.opengeospatial.org, OpenGIS Implementation Standard 
OGC 06-009r6, Version 1.0, 26 October 2007. (12 January 2011) 
[27] Simonis, 
I. 
(Ed.) 
(2007) 
Sensor 
Alert 
Service. 
http://www.opengeospatial.org, 
Candidate 
OpenGIS 
Interface 
Standard OGC 06-028r5, Version 0.9.0, 14 May 2007. (19 January 
2011) 
[28] Zardini, M. (Ed.) (2006) Sense of the City: An Alternate Approach to 
Urbanism. 352 pp., ISBN 3-03778-060-6, Lars Müller Publishers, 
Baden, Switzerland, 2006. 
[29] Resch, B., Britter, R., and Ratti, C. (2011) Live Urbanism - Towards 
the Senseable City and Beyond. In: Pardalos, P. and Rassia, S. (Eds.) 
(2010) Sustainable Architectural Design: Impacts on Health. 
[30] Resch, B., Mittlboeck, M., Lipson, S., Welsh, M., Bers, J., Britter, R., 
and Ratti, C. (2009) Urban Sensing Revisited – Common Scents: 
Towards Standardised Geo-sensor Networks for Public Health 
Monitoring in the City. In: Proceedings of the 11th International 
Conference on Computers in Urban Planning and Urban Management 
- CUPUM2009, Hong Kong, 16-18 June 2009. 
[31] Sagl, G., Lippautz, M., Resch, B., and Mittlboeck, M. (under review) 
Near Real-Time Geo-Analyses for Emergency Support: An Exercise 
for Radiation Safety. In: Proceedings of the 14th AGILE Conference 
on Geographic Information Science, Utrecht, The Netherlands, 18-21 
April 2011. 
[32] Chu, X. and Buyya, R. (2007) Service Oriented Sensor Web. In: 
Mahalik, 
N. 
(ed.) 
Sensor 
Networks 
and 
Configuration 
Fundamentals, Standards, Platforms, and Applications, Springer, 
Berling, Heidelberg, pp. 51-74. 
[33] Endsley, M. R. (1995) Toward a Theory of Situation Awareness in 
Dynamic Systems. Human Factors 37(1), pp. 32-64. 
[34] K. Thirunarayan, Henson, C., and Sheth, A. (2009) Situation 
Awareness via Abductive Reasoning from Semantic Sensor Data: A 
Preliminary Report. International Symposium on Collaborative 
Technologies and Systems (CTS2009), Workshop on Collaborative 
Trusted Sensing, Baltimore, Maryland, 2009. 
[35] Torrens, P. (2009) Process Models and next-Generation Geographic 
Information Technology. ArcNews 31(2), pp. 1-5. 
[36] Blaschke, T. and Strobl, J. (2010) Geographic Information Science 
Developments. GIS.Science. Zeitschrift für Geoinformatik 23(1), pp. 
9-15. 
[37] Sui, D. (1999) GIS as Media? Or How Media Theories Can Help Us 
Understand GIS and Society. In: Sheppard, E. and McMaster R. 
(eds.), GIS and Society: An International Perspective. 
 
 
332
International Journal on Advances in Networks and Services, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/networks_and_services/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

