Sensors-Based Virtual Reality Environment for
Volumetric CT Analyses of Agricultural Soils Samples
Leonardo C. Botega1,2,3, Paulo E. Cruvinel1,2
1Embrapa Instrumentation, São Carlos, SP, Brazil
2Post-Graduation Program in Computer Science - Federal University of São Carlos, SP, Brazil
3UNIVEM - University Centre Euripides of Marilia, Marilia, SP, Brazil
Email: botega@univem.edu.br, paulo.cruvinel@embrapa.br
Abstract—Virtual Reality (VR) is based on the use of sensors,
and the customization of its use for agricultural analysis is still
a challenge. This study presents a solution for the analysis of
agricultural soils based on sensor devices, signal conditioning,
X-ray tomographic images, and a VR interface. In such a
context,
tomographic
images
from
soil
samples
can
be
submitted though a user interface to a process of manipulation
and volumetric visualization based on graphic-computational
resources which add functionalities like immersion for the
user’s interaction with the samples. Validation was based on a
case study involving the analysis of the porosity of agricultural
soils samples in which preferential paths for water flow were
reconstructed and manipulated by VR interaction techniques.
In fact, by using 59.6 keV of energy and a time window of 10
seconds for sampling of each tomographic projection, it was
possible to reconstruct digital tomographic images from
agricultural soils to be analyzed using such a system. Results
indicated both a new and non-invasive way for the evaluation
of
the
spatial
organization
and
physical
properties
of
agricultural soils and its potential use for food production.
Keywords-X-ray Sensors; Virtual Reality Sensors; Digital Image
Processing; X-ray Tomography; Agricultural Soil Porosity;
Decision-making Process.
I.
INTRODUCTION
Evaluating the current evolution in the soil sciences, one
can
observe
an
increasing
interest
in
the
scientific
community in the development and application of non-
invasive techniques for the study of physical characteristics
of agricultural soils. Since the 1980s, one of the noninvasive
methods used for the evaluation of water movement into soil
due to morphology as well as aggregates distribution has
been the application of sensors and Computed Tomography
(CT) for agricultural soil imaging [1]–[8]. From that time, it
has been observed an expressive decreasing in the use of the
invasive gravimetric and neutron probes techniques for water
content
measurements
in
agricultural
soils
[9][10].
Additionally, combined with the development of CT, new
methods of three-dimensional (3-D) reconstruction have
been developed, mainly motivated by the lack of information
from two-dimensional models for a precise diagnosis in
studies that require volumetric information [11]. Other
challenges regarding such aspects were associated with the
image reconstruction process, as well as with reconstruction
algorithms, computational capacity, and handling large
amounts of data [12]. Therefore, since then, it has been
understood tomographic reconstruction must consider large
amounts of data and the need to have a large processing
capacity [13][14].
Moreover, owing to the advent of precision agriculture, it
has become imperative to have adequate models for
management based on data analyses not only related to
spatial variability, but also due to the temporal variability in
the
areas
used
for
agriculture.
In
this
sense,
the
standardization of data storage and the architecture of
distributed information systems that allow integration of
different types of data in a simple and transparent way have
become quite important for the development of new methods
for non-invasive analyses in agricultural industry [15]-[20].
For example, digital agricultural soil images are obtained by
tomography and take into account several projections.
Moreover, because one soil sample is scanned at different
angles, a large amount of data needs to be computationally
processed. Nowadays, the use of tomography not only allows
us to obtain information about soil density and moisture at
the pixel level, but also allows quantification of the pore
volume and its representation in three dimensions. The soil
pores vary in size and shape and can be interconnected.
In
1982,
Bouma
highlighted
the
importance
of
determining the continuity of the pore network for the flow
of water in soil [21]. Therefore, not only pore diameter, but
also
pore
continuity,
interferes
with
the
process
of
redistribution of soil water. In such a context, it is important
to assess the porosity of the soil, because, depending on the
soil management strategy adopted for planting, restriction of
soil water flow may occur, thus compromising plant growth.
To determine the soil porosity, volumetric measurements are
conventionally used [22][23]. For this, it is necessary to
collect undisturbed soil samples for quantitative evaluation
of its porosity based on the use of tomographic scanners.
Methods based on volumetric reconstruction have been
developed for such a purpose, mainly due to the inadequacy
of information provided by two-dimensional models for
accurate
diagnosis
in
studies
that
need
volumetric
information. Thus, such methods suggest the composition of
surfaces and volume of the samples under analyses and
contribute to the increase of precision in the process of
information extraction. However, it is still a challenge
gathering all the information from agricultural soils, i.e., the
continuity, size, and shapes of the pores in a soil sample,
among others.
CT is one methodology that allows observing the
structural
components
of
the
soil,
allowing
better
visualization of the behavior of the structure and soil porous
space. However, the interconnection for preferential flow
36
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

requires additional methods which can be beyond what CT
can provide. Sensors-based VR techniques can be combined
with CT to assist noninvasive research through immersive
and interactive processes.
VR was born in the eighties to help differentiate
traditional computational simulations of the synthetic worlds,
and researchers like Bolt [24] and Lanier [25] played a key
role in its development. VR transports a person into a fully
immersive and interactive experience with a degree of
realism. Academics, software developers, and researchers are
still trying to define a VR based on their own experiences.
However, it is possible to observe in specialized literature
that all of them technically consider the term related to a
immersive and interactive experience, i.e., based on images
generated by computers, rendering, or not in real time [26]-
[29]. In fact, the concept of sensors-based VR is related to
the use of sensors in external devices, i.e., digital gloves,
video-helmets, digital caves, digital tables, among others. In
1994, Machover stated that the quality of a VR system is a
significant consideration, because it stimulates the user to the
maximum in a creative and productive way, providing
feedback coherently regarding the user’s movements [30].
Presently, only some units of research have developed
projects using sensors-based VR applications in the area of
scientific visualization, such as tomographic reconstruction,
due to the high cost and technical difficulties involved in
such processes. However, some proposals have appeared to
minimize the difficulties of development and maintenance of
the systems and necessary programs.
Additionally, a better organization of human resources
has now been observed to integrate areas of the knowledge
leading to the application of such advanced methods based
on the connection and use of those technologies. Thereby,
the main objective of this work is to present the development
of a VR system to support the analysis of 3D reconstructed
soil samples using innovative immersive visualization and
interaction techniques by integrating sophisticated external
sensors-based devices.
Specifically, this paper presents the organization and
implementation of a synthetic environment that makes
possible the visualization, analysis, and manipulation of soil
samples
produced
by
an
algorithm
of
volumetric
reconstruction of X-ray tomographic images through graphic
computational tools and non-conventional sensors-based VR
devices, aiming immersion and user interaction at the scene
entities, making possible the non-destructive analysis of
agricultural soil samples, as shown by a case study in Soil
Science.
The materials and methods used in this work are
described in Section 2. In Section 3, the obtained results are
discussed, and the conclusions are presented in Section 4.
II.
MATERIALS AND METHODS
The conceptual and methodological structuring applied to
the development of the sensors-based VR system dedicated
to the inspection of digital tomographic images from
agricultural
soils uses data obtained
by
means
of a
volumetric reconstruction algorithm. Figure 1 shows a
general view of the sensors-based VR system dedicated to
the tomographic inspection of agricultural soil samples, as
well as the dataflow. From this tomographic image data, soil
samples can be reconstructed, imported, and treated by
several VR processes, focusing on the analysis related to the
soil science area.
Figure 1. General view of the sensors-based VR system customized for the
inspection of tomographic samples of agricultural soils, as well as a view of
the dataflow from the acquisition process to the visualization process.
The software system was organized based on the concept
of classes. In object-oriented programming, a class is an
extensible program code template used for creating objects,
providing initial values for states (member variables), and
implementations
of
behavior
(member
functions
or
methods). In this work, the following classes have been
considered:
Reconstruction,
Loader,
Transformations,
Polygonal
Attributes
Extraction,
Filter,
Transparency,
Illumination,
Coloring,
Conventional
Collision,
Non-
conventional Collision, Conventional Model Manipulation,
Non-conventional Model Manipulation, Conventional Scene
Manipulation,
Non-conventional
Scene
Manipulation,
Quaternion, Visualization, and VR Environment.
All
classes
were
implemented
using
the
Java
programming language and the Java3D API [31].
A CT scanner from Embrapa Instrumentation was used to
obtain the tomographic image data. All of the tomographic
projections
allowed
image
reconstruction,
i.e.,
turning
possible generation of mass attenuation coefficient maps
given in cm2/g with spatial resolution equal to or larger than
1 mm. All of the soil samples were submitted to the
acquisition process using an amount of energy of 59.6 keV
and a time window equal to 10 seconds for sampling of the
points for the tomographic projection.
For two-dimensional reconstruction, an algorithm of
Filtered Back-Projection (FBP) was used, with a filtering
based on the use of the Hamming´s window, implemented
under 1-D Fast Fourier Transform (FFT), using the C++
language [32]. After that, a suitable filtering technique was
37
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

also used with the 2-D reconstructed images. The filtering
technique was based on the use of the Wavelet Daubechies
Transform (WDT), which allowed filtering of only certain
image areas preserving borders and details, i.e., through
using a window with 76 coefficients [33].
An
interpolation-based
overlapping
algorithm
of
reconstructed
two-dimensional
slices
was
adopted
for
volumetric reconstruction. Such a technique consists of
setting up the plans generated by the function f(x, y, zi) for i
= 0... (n-1), where n is the number of reconstructed plans.
Consequently,
specific
two-dimensional
slices
were
interpolated to reconstitute the spaces left among these
overlapped plans.
Figure 2 shows the overlapping original plans and the
interpolated plans. This method was used to reduce the
computational costs and the radiation time, with the use of
interpolation in between the spaces of the reconstructed
slices based on the use of B-splines [34]. Thus, with only a
few slices, the algorithm was prepared to estimate and
complete the entire information.
The sensors-based VR system for the inspection of
agricultural soils samples was organized based on the CT
images and a set of non-conventional sensors to support the
VR environment. In addition, for the evaluation of the
preferential paths for the water movement in soil, sensors
were used to detect motion based on the use of gloves and
the space based on 3-D visualization (using a CCD head-
mounted
display)
as
well
as
microelectromechanical
actuators based on piezo-electrical devices [35][36]. Such
sensors were necessary to translate movement and to help the
users understand the relation of the workspace with the
agricultural soil samples.
Figure 2. Volumetric reconstruction based on a set of reconstructed slices
and the use of B-spline interpolator.
At the end of the process, the volumetric model is
converted into the Wavefront File Format (.obj) using the
vtkOBJExporter class from the vtkOBJExporter.h package of
the visualization toolkit. This format has been chosen for its
high performance and flexibility when importing such
models to a virtual environment, where all their attributes
can be customized for graphic APIs.
The Attributes Extraction class obtains the voxels data
from a volumetric image, using those above-mentioned input
non-conventional
devices,
i.e.,
supplying
the
users’
information
on
a
specific
point
of
the
volumetric
representation.
Initially,
the
objects
of
the
classes
PickCanvas and PickResult are instantiated, and these
objects are responsible for activating the data extraction of a
Canvas3D object and storing such data in vectors of event
results. Based on user interest, a region can be selected and
attributes extracted using a coordinate z, since it can be
stabilized on the selected region in the display, allowing
selection through a two-dimensional viewport in an intuitive
way.
Thus, the available data for picking operations under
instances of Shape3D and their respective methods are: the
borders, with getBounds; the scene graphs, with getLocale
and numBranchGraph; the geometries, with getGeometry;
ColoringAttributes, with get.ColoringAttributes; the material
under the Hue, Saturation, Lightness (HSL) and Red, Green,
Blue
(RGB)
formats,
with
getMaterial;
the
transparency,getTransparency; and the polygons, with the
getAppearance.getPolygonAttributes.getPolygonMod class.
In addition, an object is instantiated, belonging to the
PickIntersection class, also of the com.sun.j3d.utils.picking
package, responsible for sheltering the collision point
between an entity/node and the two-dimensional cursor.
Thus, this instance stores in its content the intersection
product among an entity of PickResult with the chosen
Canvas3D
point,
which
is
passed
to
the
getClosestIntersection
method
as
the
parameter.
The
PickIntersection class can offer through its events: the
distance between the point and the observer with the
getDistance method; the coordinates of the point with the
getCoordinates method; the coordinates of the closest vertex
with the getClosestVertexCoordinates method; the normal
straight line of the point with the getNormal method; and the
transformation head offices with the getMatrix method.
The classes PickIntersection and PickResult, as well as
the Attributes Extraction class, can allow the reading of each
mass
attenuation
coefficient
value,
present
in
the
tomographic volume. In this context, these values can be
obtained through the gray level tones, which are represented
by luminance, index “L” from the HSL pattern, obtained by
using the class getMaterial method.
The Non-conventional Scene Manipulation class is one of
the most important for user interactivity and immersion in
the VR environment, since it allows user browsing in all
directions through the synthetic scene, approximating and
going into the reconstructed structures using data gloves
P5Glove [37]. For the accomplishment of such events, the
manipulation classes and the model of the scene are both
based on another auxiliary class called FPSGlove, which is
available in the com.essentialreality package offered by the
device manufacturer. The FPSGlove classes is responsible
for including all the parameters regarding non-conventional
devices, and include the positioning, orientation, and finger
bending, i.e., making it possible to detect the proximity and
inclination, and thus launch a series of customized events.
On the other hand, in relation to the constructor method
of classes, additional parameters of the same importance can
be activated, such as: (1) P5_Init; (2) P5_setForward; (3)
P5_setMouseState;
(4)
P5_setFilterAmount;
and
(5)
P5_setRequiredAccuracy. These classes are responsible for
initializing, determining the positive direction, and turning
off the mouse, filtering the sign and determining the
precision movements, respectively. Soon afterwards, the
methods responsible for detecting the position of the glove in
Pixel
Voxel
Interpolated
Planes
Reconstructed
Planes
38
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

the real environment are declared. The methods are the
getXPosition, getYPosition and getZPosition, which map the
triggers mentioned before to launch an event type; it means,
they monitor the values received by the glove through
instances of the class P5State, a class responsible for
determining the current state of the glove. Thus, through the
filterPos method of P5State, the exact position of the device
is obtained and then assigned to the methods to check if the
limits were or were not outdated.
In a manner similar to the positioning detection methods
still in the FPSGlove class, the methods getYaw, getPitch,
and getRoll are described, as a solution for detecting the
inclination of the device in the Y, X, and Z axes, to
determine if the established limits for the flags were reached.
After having implemented the monitors and triggers of
events with the auxiliary class, the Non-conventional Scene
Manipulation class is also used with the ViewingPlatform
class. In such a way, two other specific parameters are
included, each of them related to the translation and rotation
steps respectively. Such an arrangement is responsible for
defining when the virtual models will be moved or leans in
each movement of the device in the real world and
recognized by the FPSGlove class.
Once such a process is concluded, the instance of the
Non-conventional
Scene
Manipulation
class
should
be
harnessed to the object of the ViewingPlatform class of the
current Canvas3D object, so that all of the movements can
be related on the scene and not the volumetric model, i.e.,
through
the
setViewingPlatform
method.
The
Non-
conventional Model Manipulation is a class responsible for
accomplishing
the
three-dimensional
representation
movement through real movements of the data glove
P5Glove, where the user can change the positioning and
orientation of models in real time in all directions and angles,
contributing to the VR environment interactivity in six
degrees of freedom. To operate such a process, it is
important
to
consider
the
Non-conventional
Scene
Manipulation class, in which the current implementation
uses the support FPSGlove class.
Thus, the Non-conventional Model Manipulation class is
an extension of the Behavior class, a class that describes
behaviors, customized for reactions to the movements of the
device.
Furthermore,
after
assigning
the
methods
getXPosition, getYPosition, and getZPosition to obtain the
positioning, and the methods getYaw, getPitch, and getRoll
to obtain the orientation under instances of the FPSGlove
class, the method rotateQuaternion is called. Such a method,
responsible for converting rotations is accomplished based
on the Euler angles in Quaternion coordinates and is useful
to establish rotations with complex numbers and imaginary
axis, in order to contribute to the movement’s precision.
The rotateQuaternion method assigns to its class the axis
and angles parameters in Euler coordinates and returns a
quaternion description; a set used in the same Quat4f
constructor, constructing a quaternion of float, and after a
setRotation
executes
a
rotation
with
instances
of
Transform3D.
At the end of the process, the product of Non-
conventional Model Manipulation class is encapsulated in a
BranchGroup object and assigned to the transformation
group,
TransformGroup,
which
conducts
the
three-
dimensional representation movements in a distinct way
from the previous class. In such a way, not only all of the
movements’ detection but also the effective positioning
change and the entities orientation produce effects under the
current models in the Canvas3D object.
The
Non-conventional
Collision
class
treats
the
implementation of a collision detection algorithm added to
the Non-conventional Scene Manipulation class and is
restricted to events that use non-conventional input data
devices, specifically those provided by the data glove
P5Glove. In that way, through the algorithm, the users are
also prevented from crossing the faces of a three-dimensional
representation during the browsing process in synthetic
scenes, allowing only the cameras transpositions inside the
empty spaces among such faces, simulating real physical
processes.
Thus, each spatial position of the glove is tested as the
current instance of itself; each direction of movement is
limited to a specific moment, where the possible alternatives
are:
left,
right,
up,
down,
forward,
and
back.
After
identifying the positioning of the glove in the moment of a
supposed collision, the Non-conventional Collision class can
block the device movement. Thus, the last movement of the
glove when a collision has been stopped is recorded,
although the glove can freely be moved in the real
environment. This is caused by a new instantiation of the
current position of the glove, assigning empty vectors to
them, in other words, initialized in the origin, i.e., causing
the immediate stop of the device movement.
Additionally, at the same time, when accomplishing any
other move that does not take them to a continuation of the
blocking, the class interprets them and allows continuing the
valid movements series through a new instantiation of the
mapped positions of the glove, using as parameters the
position where the collision began and the linear step was
adopted by the class. At the end of this process, a Shape3D is
added to PhysicalBody to detect the browsing of the scene
being used by a user, allowing interaction and selection of
each three-dimensional face. The algorithm of such a class
allows both preventing the browsing to continue (or not) in a
scene, as well as providing information of the direction of
the glove movement since it became active.
The Quaternion class implements a conversion algorithm
so that the system stops using just rotations on the x, y and z
axes,
and
starts
to
accomplish
orientations
on
some
intermediate axis, defined by a vector that goes through the
origin and reaches a point in space. Such a type of an axis
can be represented by a specific coordinate of the real
device, e.g., the Cartesian coordinates (x, y, z) of one of the
eight LEDs present in the controller tower which is used
with the glove [38].
To accomplish this operation, it uses imaginary bases and
complex numbers, providing an alternative parameter for the
setRotation, method of the Transform3D class, which allows
using a quaternion as an argument. Thus, calling an instance
of Quaternion to accomplish a rotation with the non-
conventional device P5Glove, the orientation of the glove is
39
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

interpreted by the FPSGlove class and translated by Non-
conventional Scene Manipulation or Model, is converted
from the Euler system to the Quaternion base, returned for
the system new orientation coordinates, to then be executed
by the Quat4f method of Transform3D, which encapsulates
the entire functioning of the quaternion as previously
described.
For the implementation of the Visualization class, the
system interface prepares a volumetric tomographic image to
be visualized. This way, the volumetric tomographic image
is prepared to be adjusted to the 3-D model, i.e., to occupy
the whole extension of the Canvas3D object, so that all of
the spaces are taken advantage of, contributing to the
visualization quality.
III.
RESULTS AND DISCUSSIONS
Based on the use of the tomographic projections and the
two-dimensional
reconstruction
FPB
algorithm,
it
was
possible to get volumetric images by means of use of the B-
spline algorithm.
Figure
3
presents
examples
of
the
volumetric
tomographic images obtained for stratified agricultural soil,
degraded soil, and a clay soil sample, respectively. Based on
the Attributes Extraction class, intrinsic characteristics of the
scene and of agricultural samples could be obtained through
the use of either the mouse or the P5Glove, with a data origin
in
the
three-dimensional
representations
in
the
VR
environment. The data set was divided into two categories:
one concerning the scene, and the other concerning the CT
measurements.
In relation to the first category, the synthetic scene data
are related to: borders, which have represented the geometry
limits or the geometry limits that involved it; the scene
graph, that has represented the node hierarchy in the tree; the
current geometry in the model and its composition, the
distance of a certain voxel in relation to the coordinates
chosen in the scene, the closest vertex to the chosen point in
the scene, the three-dimensional coordinates, and the normal
straight line in the closest face, which involved the chosen
coordinates.
Secondly, concerning the tomographic data, the obtained
data were: color attributes, which represented the individual
color of each voxel, independent of illumination intensity;
the mass attenuation coefficients values of the agricultural
soils, which are represented by the colors of each analyzed
voxel, and are related to the light intensity in each position;
transparency attributes; and polygons attributes, and finally
the saturation and matrix of the HSL coefficients.
An experiment for validation of the result was prepared
considering a digital and volumetric tomographic image
obtained from a latosol soil. For such a volumetric image, the
value of an arbitrary voxel was taken as presented in Figure
4.
Based on the developed method, the attributes can be
obtained from the latosol soil tomographic image at the
sensors-based
VR
environment,
i.e.,
under
the
two
mentioned
aspects,
through
the
choice
of
any
voxel
coordinates, assuring the reliable recovery of the sample
data.
Figure 3. Volumetric images reconstructed by FBP and the
B-Spline algorithm.
Figure 4. Resulting data obtained from a latosol soil sample
where an arbitrary point is chosen using a conventional device
(mouse) or a non-conventional one (glove). The coordinates of
the voxel are directly selected and the respective information
can be exhibited for the users.
40
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

As an example of such a result, attributes can be obtained
and presented as below:
In relation to the Non-conventional Scene Manipulation,
the feedback produced by the class implementation has
indicated absolute control of user browsing on the scene
using the P5Glove. In this context, according to device
positioning, the users can browse through the scene where
the displacement of their hand is faithfully translated in
scene
movements,
including
moving
the
environment
cameras in real time. Analogously, such movements are also
translated in the three-dimensional displacements.
Practically,
such
movement
with
a
glove
should
commence with closed hands, where the sensors are
activated by bending fingers, thus starting the action. The
Non-conventional Model Manipulation class simulates the
manual support of 3-D samples, as well as its total
movement inside the scene, with 6 degrees of freedom.
Also, the Quaternion class, when evaluated, presented an
adequate
conversion
from
Euler`s
coordinates
to
Quaternion`s
coordinates.
In
addition,
the
results
of
application of the Transform3D class produced smooth
orientation changes. Table I presents an example of results
for the 180º rotation, considering the initial position of the
LED = (-1.0, 1.0, 0.0), and the origin of the three axes that is
at coordinates (0.0, 0.0, 0.0).
Figure 5 presents the visual results of the applied
transform. Such a result has demonstrated that the three
rotations were composed by commutation of four other
rotations of smaller angles. Also, the transposition of an
orientation for another happened in a soft way, without leaps
or arbitrary paths, leading to an intuitive result.
The
three-dimensional
samples
were
examined
immersively by the Head Mounted Display through the
Visualization class. First, Canvas3D, responsible for the
rendering of three-dimensional images, was maximized to
omit the parts related to the main interface in the device to
focus only on the region where the sample was shown. Thus,
each display of HMD forms an image which is shown and
interpreted by the user’s brain with a larger depth effect.
Secondly, such an effect also has allowed performing the
analyses of the preferential paths of the water flow into the
agricultural soil samples, called fingering effects, as well as
the verification of the percentage of pores in the samples.
TABLE I - EXAMPLE OF RESULTS FOR THE ROTATION USING QUATERNIONS
Figure 5. Representation of the rotation described around the stippled axis
defined by the coordinate of LED = (1.0, 1.0, 0.0), and passing through the
origin of the axis.
As
described
in
the
Non-conventional
Scene
Manipulation class, as the cameras are moved with the
navigation processes, activated by keyboard interaction, or
data glove P5Glove, the traveled paths can be demarcated;
leaving
the
itinerary
registered
under
visual
and
mathematical form. Furthermore, for each device movement
identified, a new position for the camera is established, i.e.,
given by new coordinates (x, y, z).
Such positions are unique and occupied only one at a
time. Thus, activated by the demarcation process, forming
any point, the traveled path can be simulated for a certain
water flow, i.e, when working with an agricultural sample.
When accomplishing a certain movement, the current point
occupied by the camera receives a Shape3D under the form
of a blue sphere, which simulates the presence of a fluid drop
Colors:
Color=(0.03, 0.07, 0.04) | ShadeModel=SHADE_GOURAUD
Materials:
AmbientColor=(0.4, 0.4, 0.4)
EmissiveColor=(0.0, 0.0, 0.0)
DiffuseColor=(0.71, 0.70, 0.65)
SpecularColor=(0.3, 0.3, 0.3)
Shininess=128.0
LightingEnable=true
ColorTarget=2
Transparency Level: 0.3
Polygons: Planes
Gray Level: 156.82
Saturation: 22.86
Mass Attenuation Coefficient (cm²/g): 0.6521
Virtual borders:
Lower=-0.87 -1.0 -0.15
Upper=0.875 1.0 0.15
BranchGraphs: 3
Geometry: Triangles
Point Distance: 10.28
Closest Vertex: (0.92, -0.25, -10.24)
Point Coordinates: (0.75, -0.25, -10.26)
Point Normal Axis: (1.0, 0.0, 0.0)
41
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

occupying the previous position of the camera, leaving a
bluish trace through where the camera passed. Similar to the
simple scene manipulation, such demarcation obeys the laws
imposed by the Non-conventional Collision class, i.e., the
traveled path is prevented from passing over the non-porous
faces of the agricultural sample, leading the flow of fluids to
pass through the related pores, which are the preferential
paths.
The process can be repeated several times in ways similar
to real situations. It is also possible to make border
calculation where the limits of three-dimensional samples are
identified in space, as in the case of Attributes Extraction
class through the use of getBounds on Shape3D instances
combined
with
a
three-dimensional
borders
detection
algorithm called Polytope, available in the Bounds package
of Java3D API.
Besides, by using such an algorithm has become possible
drawing plans around of the surfaces of the soil samples
images, i.e., to delimit their borders exactly. Thus, it allows
the nonporous parts of the samples, including the internal
ones, to be identified, allowing the verification of its volume
in cm³.
Figure 6 presents the results of the case study based on a
tomographic image from degraded agricultural soil, where
the sample is in gray tones and the water flow is represented
with a blue color, demarcating the traveled paths.
Figure 6. Result of the case study using a degraded soil sample, i.e., with
representations of the non-porous soil portion (gray), emptiness (yellow),
and water flow (blue) in between the soil pores.
In fact, once the non-porous part has been identified, the
remaining portions were recognized based on the emptiness
of the sample, which present the color that corresponds to
those voxels in which there was an absence of the photons
attenuation. The porous voxel was filled out with a semi-
transparent yellow color, seeking a larger prominence close
to the sample. With such available data, it is possible to
calculate the total volume of the sample (sum of the non-
porous parts with its complement) in cm³. Thus, starting
from the total volume and the individual volume of the non-
porous part, it is possible to calculate exactly the volume
represented by the emptiness of the three-dimensional
sample.
IV.
CONCLUSIONS
This work presented the development of a new method
which considered the integration of a sensors-based VR
environment with a CT for the dedicated inspection of
agricultural soils. Results have shown both the possibility of
accessing CT digital images of the agricultural soils and the
opportunity of handling three-dimensional manipulation and
graphic
visualization
processes
through
computational
devices. Such a developed method allowed the addition of
immersion and the user`s interaction with soil samples.
These resources involved rendering control, illumination,
coloring, attributes extraction, and physical transformation,
as well as the integration of non-conventional data input and
output devices, such as a Head-Mounted Display (video-
helmet), and digital gloves.
In addition, it was also observed that the Java3D API
provided, in its group of classes, essential methods for HMD
programming.
Such
development
has
encapsulated
practically all of stereoscopy programming. Furthermore, the
case study demonstrated the applicability of the method in
visualization processes and agricultural soil sample analysis,
considering the progress and facilities when accomplishing
non-invasive inspections.
Finally, the integration of CT and sensors-based VR
made possible the measuring of volumes of emptiness of the
samples, i.e., the pores, and simulation of the water flow path
for the formation of preferential fingering. Future work will
consider embedded systems based on the use of the Field
Programmable Gate Array (FPGA), as well as use of the
augmented reality concepts.
ACKNOWLEDGMENT
This research was partially supported by the São Paulo
Research Foundation (FAPESP, Process No. 17/19350-2),
and the Brazilian Corporation for Agricultural Research
(Embrapa, Process No. 11.14.09.001.05.06). We thank the
institutional support received from the Computer Science
Department
of the Federal University of São
Carlos
(UFSCar), and the University Centre Euripides of Marilia
(UNIVEM).
REFERENCES
[1]
A. Petrovic, J. Siebert, and P. Rieke, “Soil bulk density
analysis in three dimensions by computed tomographic
scanning”, Soil Science Society of America Journal, vol. 46,
n. 3, pp. 445–450, 1982.
[2]
J.
M. Hainsworth
and L.A.G.
Aylmore,
“The use of
computer-assisted
tomography
to
determine
spatial
distribution of soil water content”, Australian Journal of Soil
Research, n. 21, pp. 435–440, 1983.
[3]
S. Crestana, S. Mascarenhas, and R. Pozzi-Mucelli, “Static
and dynamic threedimensional studies of water in soil using
computed tomographic scanning”, Soil Science, vol. 140, n. 5,
pp. 326–332, 1985.
[4]
P. E. Cruvinel, R. Cesareo, S. Crestana, and S. Mascarenhas,
“X-and gamma-rays computerized minitomograph scanner for
soil science”, IEEE Transactions on Instrumentation and
Measurement, vol. 39, n. 5, pp. 745–750, 1990.
[5]
Á. Macedo et al., “Wood density determination by X and
gamma
ray
tomography”,
International
Journal
of
the
42
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

Biology, Chemistry, Physics and Technology of Wood, vol.
56, pp. 535–540, 2002.
[6]
A. Pedrotti et al., “Computed tomography applied to studies
of a planosoil” (Original in Portuguese: Tomografia compu-
tadorizada aplicada a estudos de
um planossolo). Brazilian
Agricultural Research Journal, vol. 38, n. 7, pp. 819–826,
Brazil, 2003.
[7]
P.E. Cruvinel, M. L. F. Pereira, J. H. Saito, and L.F. Costa,
“Performance
optimization
of
tomographic
image
reconstruction based on DSP processors”, IEEE Transactions
on Instrumentation and Measurement , vol. 58, pp. 3295-
3304, 2009.
[8]
J. M. Beraldo, F. A. Scanavinno Junior, and P. E. Cruvinel,
“Application
of
X-ray
computed
tomography
in
the
evaluation of soil porosity in soil management systems”,
Engenharia Agrícola, vol. 34, n. 6, pp. 1162–1174, 2014.
[9]
E. S. B. Ferraz and R. S. Mansell, “Determining water content
and bulk density of soil by gamma-ray attenuation methods”,
Technical Bulletin, No. 807, IFAS, Florida, pp. 1-51, 1979.
[10] C. F. A. Teixeira, S. O. Moraes, and M. A. Simonete,
“Tensiometer, TDR and neutron probe performance in the
determination of soil moisture and hydraulic conductivity”,
(Original in Portuguese: Desempenho do tensiômetro, TDR e
sonda
de
nêutrons
na
determinação
da
umidade
e
condutividade hidráulica do solo), Brazilian Journal of Soil
Science, vol. 29, pp. 161–168, 2005.
[11] M. F. L. Pereira and P. E. Cruvinel, “A model for soil
computed tomography based on volumetric reconstruction,
Wiener filtering and parallel processing”, Computers and
Electronics In Agriculture, vol. 111, pp. 151-163, 2015.
[12] K. Slavakis, G. B. Giannakis, and G. Mateos, “Modeling and
Optimization
for
Big
Data
Analytics”,
IEEE
Signal
Processing Magazine, pp. 18–31, 2014.
[13] V. Bolón-Canedo, N. Sánchez-Maroño, A. Alonso-Betanzos,
“Recent
advances
and
emerging
challenges
of
feature
selection in the context of big data”, Knowledge-Based
Systems, Elsevier, vol. 86, n.9, pp. 33–45, 2015.
[14] A.
Ali,
G.
A.
Shah,
M.
O. Farooq,
and
U.
Ghani,
“Technologies and challenges in developing machine-to-
machine applications: A survey”, Journal of Network and
Computer Applications, vol. 83, pp. 124–139, 2017.
[15] S. S. Andrews, D. L. Karlen, and C. A. Cambardella, “The
Soil Management Assessment Framework: A Quantitative
Soil Quality Evaluation Method”, Soil Science Society of
America Journal, vol. 68, pp. 1945– 1962, 2004.
[16] A. Kaloxylos et al., “Farm management systems and the
future
internet
era”,
Computers
and
Electronics
in
Agriculture, vol. 89, pp. 130– 144, 2012.
[17] U. Zimmermann et al, “A non-invasive plant-based probe for
continuous monitoring of water stress in real time: a new tool
for irrigation scheduling and deeper insight into drought and
salinity stress physiology”, Theoretical and Experimental
Plant Physiology, vol. 25, n. 1, pp. 2-11, 2013.
[18] J. S. Selker, L. Graff, and T. Steenhuis, “Noninvasive time
domain reflectometry moisture measurement probe”, Soil
Science Society of America Journal, vol. 57, n. 4, pp. 934-
936, 1993.
[19] F. Palacios, M. P. Diago, and J. Tardaguila, “A non-invasive
method based on computer vision for grapevine cluster
compactness assessment using a mobile sensing platform
under field conditions”, Sensors, vol. 19, n. 17, pp. 3799-
3818, 2019.
[20] H. Liu, R. Jia, X. Zhou, and L. Fu, “Virtual assembly of man-
machine interactive mechanical seed-metering device based
on matter-element identification”, Transactions of the Chinese
Society of Agricultural Engineering, vol. 32, n. 1, pp. 38-45,
2016.
[21] J. Bouma, “Measuring the conductivity of soil horizons with
continuous macropores”, Soil Science Society of America
Journal, Madison, vol.46, pp. 438-441, 1982.
[22] Mualem, Y, “A new model for predicting the hydraulic
conductivity of unsaturated porous media”, Water Resources
Research, vol.12, pp. 2184-2193, 1976.
[23] M. Kutilek and D. R. Nielsen, Soil Hydrology, Cremlingen-
Destedt: Catena Verlag, 1994.
[24] R. A. Bolt, “Put¬that¬there: Voice and gesture at the graphics
interface”, in 7th International Conference on Computer
Graphics and Interactive Techniques, Washington, USA, pp.
262–270, 1980.
[25] J.
Lanier,
Visual
programming
languages,
Scientific
American, 1984.
[26] L. C. Botega and P. E. Cruvinel, “Development of a Virtual
Reality Environment for Agricultural Soil Analysis” (Original
in Portuguese: Desenvolvimento de Ambiente de Realidade
Virtual para Análise de Solos Agrícolas), in Proceedings of
the Workshop of Virtual and Augmented Reality, Itumbiara,
Brazil, 2007.
[27] K. Pimentel and K. Teixeira, Virtual reality through the new
looking glass, McGraw-Hill, New York, 2nd edition, 1995.
[28] O. Gonzalez et al, “Development and assessment of a tractor
driving simulator with immersive virtual reality for training to
avoid occupational hazards”, Computers and Electronics in
Agriculture, vol. 143, pp. 111-118, 2017.
[29] L. Jacobson, Garage Virtual Reality, SAMS Publication,
Indianapolis, 1994.
[30] C. Machover and S. Tice, “Virtual Reality”, IEEE Computer
Graphics and Application, vol. 14, n.1, pp. 15-16, 1994.
[31] Sun
Microsystems.
Java3D
Documentation.
[Online].
Available from: http://java.sun.com/javase/technologies/desk
top/java3d.
[32] C.
Kak
and
M
Slaney,
“Principles
of
computerized
tomographic imaging,” New york: The Institute of Electrical
and Electronics Engineers, Inc., IEEE Press, 1988.
[33] I. Daubechies, “Ten lectures on wavelets”, CBMS-NFS
Regional
Conference
Series
in
Applied
Mathematics,
Philadelphia,
PA:
Society
for
Insdustrial
and
Apllied
Mathematics (SIAM), vol. 61, 1992.
[34] T. N. E. Greville, “Spline functions, interpolation and
numerical quadrature”, Mathematical Methods for Digital
Computers, Vol.2, A. Ralston and H.S. Wilf, eds., Wiley,
New York, Ch. 8, pp. 156-168, 1967.
[35] S. Chen, L. Xu, and H. Li, “Research on 3D modeling in
scene simulation based on Creator and 3dsmax,” in IEEE
International
Conference,
vol.
4,
pp.
1736–1740,
Mechatronics and Automation, 2005.
[36] E. F. S. Montero and D. J. Zanchet, “Virtual reality and
medicine” (Original in Portuguese: Realidade virtual e a
medicina), Brazilian Surgical Act, vol. 18, n. 8, pp. 489-490,
2003.
[37] C. Kenner. Essential reality p5glove sumary: Dual mode
driver programming: [Online]. Available from: http://www.
geocities.com/carl_a_kenner/p5.html.
[38] S. C. Biasi and M. Gattass. Use of quaternions to represent 3-
D rotations. (Original in Portuguese: Utilização de quatérnios
para representação de rotações em 3-D), Catholic University
of Rio de Janeiro, February of 2002. [Online]. Available
from: http://www.tecgraf.puc-rio.br/~mgattass.
43
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-766-5
ALLSENSORS 2020 : The Fifth International Conference on Advances in Sensors, Actuators, Metering and Sensing

