JoGuide: A Mobile Augmented Reality Application for Locating and Describing
Surrounding Sites
Fadi Wedyan
Department of Software Engineering
Hashemite University
Zarqa, 13315 Jordan
Email: fadi.wedyan@hu.edu.jo
Reema Freihat
Department of Software Engineering
Hashemite University
Zarqa, 13315 Jordan
Email: reema.freihat@gmail.com
Ibrahim Aloqily
Department of Computer Science and Its Applications
Hashemite University
Zarqa, 13315 Jordan
Email: izaloqily@hu.edu.jo
Suzan Wedyan
Department of Computer Science
Amman Arab University
Amman, Jordan
Email: susanwedyan@gamil.com
Abstract—Augmented Reality is a variation of virtual reality
that allows users to view the real world augmented with virtual
objects. Therefore, it can be used to produce systems that
provide users with rich information about the scanned area. In
this paper, we present an application that locates and provides
the users with information about the local surrounding sites.
The application, which we call JoGuide, is designed to help
users in urban areas or tourism destinations to locate places
of interest near them by moving the camera of the device in
all possible directions to overlay information of places around
them. Places captured by the camera are located by adding
bins displaying the place name as deﬁned by Foursquare.com
database. JoGuide is developed with Android and is set to
run on smartphones and tablets with different screen sizes,
computational and memory capabilities.
Keywords-Augmented reality; Mobile Computing; Mobile de-
vices; Text in scene images; Android.
I. INTRODUCTION
Augmented Reality (AR) creates an environment in which
real world and virtual world objects are presented together
within a single display [1]. The core idea behind AR is
overlaying computer generated graphics on top of the real
world scenes to create a seamless spatially-registered envi-
ronment [2]. The main goal of AR is providing applications
and programs to the users that brings virtual information to
their immediate surroundings and also to any indirect view
of the real-world environment (e.g., live-video stream) [3].
Since the ﬁrst appearance of AR concepts in the 1950’s
in the cinema industry, AR has immensely grown. Cur-
rently, AR applications can be found in many domains
including medical visualization, entertainment, advertising,
maintenance and repair, annotation, robot path planning,
geographical information systems, and education [4] [3] [5].
The use of AR applications on mobile devices (e.g.,
tablets, smartphones, digital cameras) is gaining more at-
tention due to the increasing power and decreasing prices of
mobile devices. Moreover, mobile devices come with various
input means (sensors, cameras, location) that facilitate the
development of a wide range AR mobile applications. Mo-
bile Augmented Reality (MAR) expands the set of services
that AR offers to include a wide range of scenarios in the
rich diversity of the mobile environments [6] [7]. AR can be
used in many types of applications including entertainment
and gaming, tourism, and navigation. A key feature of a
MAR application is that it provides the user with context-
related information in real time. This information can sup-
port various context-dependent applications. For example,
information about surrounding places, products, events, or
moving objects (e.g., transportation means) [8].
In this paper, we present a MAR application, called JoGu-
ide (stands for Jordan Guide), for locating and providing
information about surrounding sites, building, ofﬁces, or
any buildings of interest. The application aims to facilitate
the process of searching for sites surrounding the user.
The application can be very useful especially for the user
who goes to places never visited before (e.g., tourists).
The application provides information about surrounding sites
including landmarks, or small objects (e.g., shops, ofﬁces,
restaurants, etc.) by moving the camera in the direction of
the desired site. The information is displayed on the screen
without blocking the view.
88
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

JoGuide is designed and implemented keeping in mind the
importance of achieving the following attributes: reliability,
usability, extensibility, and robustness. JoGuide is deployed
to run on Android platform version 4.1 or later and is
developed to work on devices with different screen sizes
and computational capabilities. JoGuide uses Global Posi-
tioning System (GPS) sensor, phone network and Internet
connection to determine current location. The application
uses a global maps website called Foursquare [9] to get
information about the sites of interest. The application uses
the phone camera to catch the scene, sends it to the site and
locates sites of interest. JoGuide allows users to learn more
information about venues and places surrounded them.
The rest of the paper is organized as follows. Section II
presents related work. Section III describes the design and
implementation of the presented application. Section IV
presents a demonstration of the application and discusses
usage issues. Finally, conclusions and future work are dis-
cussed in Section V.
II. RELATED WORK
In this section, we provide a summary of work in mobile
augmented reality that aims at developing tourism and navi-
gation applications. Please refer to [10], [11] for a complete
survey on mobile augmented reality.
Dahne et al. [12] presented a software that runs on Lap-
tops called Archeoguide to provide tourists with interactive
personalized information about historical sites. The applica-
tion was tested on the site of ancient Olympia in Greece.
Using Archeoguide, users can view a virtual reconstructions
of the ancient site. Images and videos are all loaded with the
application (i.e., no real time communication is required).
Fockler et al. [13] developed an enhanced museum guid-
ance application, called PhoneGuide, to introduce exhibi-
tions. PhoneGuide runs on mobile phones and displays
information on the phone when visitors targeted their mobile
phone cameras at exhibits. PhoneGuide runs a perception
neuronal network to recognize exhibits in images taken by
the phone camera.
Elmqvist et al. [14] presented a mixed Reality platform for
navigation assistance in indoor environments. The platform,
which is called 3DVN, provides a multi-modal user interface
for navigating in existing physical buildings. 3DVN supports
both path ﬁnding and highlighting of local features.
Another museum guide was presented by Bruns et al. [15].
The guide uses widespread camera-equipped mobile phones
for on-device object recognition in combination with per-
vasive tracking. It also provides location- and object-aware
multimedia content to museum visitors.
Tokusho and Feiner [16] developed an application called
AR street view which provided an intuitive way to obtain
surrounding geographic information for navigation. When
users walk on a street, street name, virtual paths and current
location were overlaid on real world to give users a quick
overview of environment around them.
Marimon et al. [17] developed an Android service plat-
form called MobiAR for tourist information based on AR.
MobiAR allows users to browse information and multimedia
content about a city through their mobile phones. The plat-
form handles location-based information, user preferences
and determines the tourist resource the user is interested in.
Bihler et al. [18] developed a prototypical context-aware
museum guide that uses ultrasonic signals, sent by a cheap,
stand-alone emitter. The smartphone is able to recognize
the exhibits by receiving a modulated ultrasonic signal, but
in any museum an adaptation of the used frequencies is
necessary.
Armanno et al. [19] developed an application called Sky-
LineDroid for virtual Heritage where Augmented Reality is
used on mobile phones to support visitors of outdoor cultural
heritage sites. Virtual and real world are overlaid on the
device screen, according to device position and orientation,
in order to immerse users in the 3D historical reconstruction
of ancient buildings.
Rubino et al. [20] presented a general framework for
the development of multimedia interactive guides for mo-
bile devices called MusA. The framework has a vision-
based indoor positioning system that allows the provision
of several LBS, from way-ﬁnding to the contextualized
communication of cultural contents, aimed at providing a
meaningful exploration of exhibits according to visitors’
personal interest and curiosity.
Chianese et al. [21] developed a location-based applica-
tion that aims at exploiting several location-based services
and technologies in order to realize a smart multimedia guide
system. The system is able to detect the closest artworks
to the user, make these artworks able to tweet and talk
during users visit and capable of automatically telling their
stories using multimedia facilities. The system was tested
at a sculptures art exhibition within the Maschio Angioino
castle, in Naples, Italy.
Murino et al. [22] presented an Android touristic appli-
cation called i-Street whose aim is to detect, identify and
read the street plates in a video ﬂow and then to estimate
relative pose in order to accurately augment them with
virtual overlays. The application was tested in the historical
centre of Grenoble, France, proving to be robust to outdoor
illumination conditions and to device pose variance. The
average identiﬁcation rate in realistic laboratory tests was
about 82%.
Jain et al. [23] adopted a top-down approach cutting
across smartphone sensing, computer vision, cloud ofﬂoad-
ing, and linear optimization in order to develop location-
free geometric representation of the environment and using
this geometry to prune down the visual search space. They
developed a system called OverLay, which is currently
deployed in the engineering building and open for use to
89
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

regular public.
III. APPLICATION DESIGN AND IMPLEMENTATION
We followed the Incremental Methodology in developing
our application. We choose this approach because it has
features that are suitable to our application. Mainly, it gener-
ates a working software early during the software life cycle,
easier to test and debug during a smaller iteration, and easier
to manage risks [24]. At a glance, incremental development
slices the system functionality into increments where in each
increment, a slice of functionality is delivered through cross-
discipline work, from the requirements to the deployment.
The uniﬁed process groups increments/iterations into the
phases of: inception, elaboration, construction,and transi-
tion [24].
We show the package diagram of the proposed application
in Figure 1. As the ﬁgure shows, the application consists of
three main components, these are:
1) Graphical User Interface (GUI). The component con-
tains the classes necessary for creating the GUIs. The
classes contained in the package are shown in Figure 2.
The component displays the following screens: (1)
Splash Layout, which includes the start and the wel-
come screens. (2)ArActivity Layout: the main applica-
tion screen, it combines two layouts, Camera Preview
layout, which is a simple wrapper around a camera
and a surface view that renders a centered preview
of the camera to the surface to resize preview aspect
ratio suitable for the screen of the device, and AR
Overlay layout, which shows pins and venues names
as text. (3) the output layout which show the view after
calculating angle between user location and nearby
venues.
Venue information is updated every 50 ms by a
request sent to Foursquare (using the communication
package).
2) Location. Contains classes for managing location in-
formation. The contents of the component are shown
in Figure 3.The location component is used by the
GUI to get and update the user location. Location is
detected every 30 seconds. That is, every 30 second
the application sends a request to the GPS or network
provider to get current user location.
3) Communication.
Provides
services
to
the
other
two
components
including:
communicating
with
Foursquare, communicating with the GPS or the net-
work provider to get location information, and check-
ing Internet availability. Classes participating in the
communication package are shown in Figure 4.
We choose to refresh the location every 30 seconds as
a default value experimentally. The users can decrease this
value when they are moving fast (e.g., driving on a highway)
or increase it when they use the application while walking.
Updating the scenes with information is performed every 50
Figure 1.
Package Diagram of JoGuide
Figure 2.
GUI Package
ms to give the users a real-time experience and avoid losing
important sites information.
The location information from the GPS is sent to
FourSquare to get information about the nearby venues.
This information is used by the application to compute the
angles between the user current location and the nearby
venues. In addition, the application computes the rotation
and orientation of the camera, using the smartphone sensor.
Using the internal measurement unit of the smartphone
and the angles between current location and venues, we map
the venues locations to their locations that appear on the
90
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

Figure 3.
Location Package
Figure 4.
Communication Package
screen by drawing an icon on each venue found.
The prototype version of the application is implemented
with Android. The following tools and software are used to
implement JoGuide:
• Eclipse Indigo [25] with android plug-in.
• Microsoft Visio 2013 [26], for preparing the design
documents. We used UML [27] to describe the system
architecture.
• Adobe Photoshop CS5 [28], for designing icons and
images.
IV. DEMONSTRATION
In this section, we demonstrate how JoGuide can be used
to obtain information about surrounding sites and places.
Figure 5 shows the ﬁrst screen displayed when a user starts
the application. When the application is loaded, it checks
if the GPS is activated, and if an Internet connection is
available. A message is displayed to the user to indicate
whether any of these resources are not available. Otherwise,
the start button becomes active and the user can start
spotting.
Figure 6 shows the screen displayed as the user presses the
start application button and JoGuide working by initializing
Figure 5.
Start Screen of JoGuide
camera and loading places. The application accordingly
sends a request to Foursquare and the GPS. This might take
some time depending on the Internet speed.
Figure 6.
loading JoGuide
We tested the application in different urban sites, includ-
ing the downtown of the city of Amman, Jordan, the city
of Zarqa, Jordan, and the historical site of Petra, Jordan. In
all our experiments, JoGuide shows to be an easy to use
application, reliable, and provided the needed information
about the sites and shops surrounding the user. In Figure 7,
we show a camera shot with site information. We choose to
display the sites pins in dark blue and the sites names in red
in order to: (1) eliminate potential overlapping with objects
that appear on the screen, and (2) allow the information
to appear when the application is used in the dark. This
is shown in Figure 8 which shows a screenshot of the
application while used in the night. The icons are visible
for the user and the red color can alert the user attention for
the required site while the blue color is bright and easy to
ﬁnd on a dark background.
It is though important to emphasize that the accuracy
of the displayed information depend on the information
provided by FourSquare maps (which in turn depend on the
information the municipality or the local government can
91
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

Figure 7.
Camera shot augmented with sites information (taken at Hashemite University Campus)
Figure 8.
A night screenshot of JoGuide (taken at the downtown of Amman, Jordan)
provide for public use).
In order to keep the application light, we only store the
information retrieved from FourSquare obtained the current
session (i.e., the currently spotted sites while the application
is turned on). Users have the option of saving the augmented
images in a special folder on the device or share them via
email or Google Drive.
V. CONCLUSIONS AND FUTURE WORK
In this paper, we presented an augmented reality based
mobile application named JoGuide. The prototype version of
the application is developed with Android, and requests data
92
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

about available sites from maps service site. The application
aims at easing the exploration of surrounding sites and
helping people like tourists to identify nearby places of
interest. In developing JoGuide, our target was to provide a
lightweight application with few memory and computational
requirements. We achieved our goal by minimizing the
amount of data stored in memory, and by retroﬁring the
information via web services, and therefore, performing
part of the computations on the server side. We tested
the application in two major cities in Jordan and in one
historical site. The application has shown to be easy to use,
lightweight, and robust.
The presented work can be further extended in many
directions including:
• Enabling the retrieval of more information about venues
in order to give detailed and more accurate results about
the venues and locations.
• Providing the option of saving the visited sites (i.e., trip
tracker). This option will require saving information in
a light local database.
• Providing a vocal guidance option for users with dis-
abilities.
• Developing versions of the application that work on
different platforms (e.g., iOS for iPhones, Windows
phones).
ACKNOWLEDGMENT
The authors would like to thank the students who helped
in implementing the presented work, namely: Shadi Ay-
man, Reham Bawaneh, and Nedaa Rahmeh. This work was
supported in part by the Hashemite University under grant
number 2013/19 to F. Wedyan.
REFERENCES
[1] P. Milgram, H. Takemura, A. Utsumi, and F. Kishino, “Aug-
mented reality: A class of displays on the reality-virtuality
continuum,” in Photonics for industrial applications.
Inter-
national Society for Optics and Photonics, 1995, pp. 282–292.
[2] O.
Bimber,
B.
Fr¨ohlich,
D.
Schmalstieg,
and
L.
M.
Encarnac¸˜ao, “The virtual showcase,” IEEE Computer Graph-
ics and Applications, no. 6, 2001, pp. 48–55.
[3] J. Carmigniani, B. Furht, M. Anisetti, P. Ceravolo, E. Dami-
ani, and M. Ivkovic, “Augmented reality technologies, sys-
tems and applications,” Multimedia Tools and Applications,
vol. 51, no. 1, 2011, pp. 341–377.
[4] R. T. Azuma, “A survey of augmented reality,” Presence,
Teleoperators and Virtual Environments, vol. 6, no. 4, August
1997, pp. 355–385.
[5] H.-K. Wu, S. W.-Y. Lee, H.-Y. Chang, and J.-C. Liang,
“Current status, opportunities and challenges of augmented
reality in education,” Computers & Education, vol. 62, 2013,
pp. 41–49.
[6] D. Wagner and D. Schmalstieg, “Making augmented reality
practical on mobile phones, part 1,” Computer Graphics and
Applications, IEEE, vol. 29, no. 3, 2009, pp. 12–15.
[7] ——, “Making augmented reality practical on mobile phones,
part 2,” Computer Graphics and Applications, IEEE, vol. 29,
no. 4, 2009, pp. 6–9.
[8] T. Olsson, T. K¨arkk¨ainen, E. Lagerstam, and L. Vent¨a-
Olkkonen, “User evaluation of mobile augmented reality
scenarios,” Journal of Ambient Intelligence and Smart En-
vironments, vol. 4, no. 1, 2012, pp. 29–47.
[9] “FourSquare,” URL: http://www.foursquare.com [retrieved:
February, 2016].
[10] Z. Huang, P. Hui, C. Peylo, and D. Chatzopoulos, “Mobile
augmented reality survey: A bottom-up approach,” HKUST,
Hong Kong University of Science and Technology, Tech.
Rep., 2013.
[11] C. Arth, R. Grasset, L. Gruber, T. Langlotz, A. Mulloni,
and D. Wagner, “The history of mobile augmented reality,”
Inst. for Computer Graphics and Vision, Graz University of
Technology, Austria, Tech. Rep., 2015.
[12] P. D¨ahne and J. N. Karigiannis, “Archeoguide: System ar-
chitecture of a mobile outdoor augmented reality system,” in
Proceedings of the ﬁrst IEEE/ACM International Symposium
on Mixed and Augmented Reality (ISMAR02), 2002, pp.
263–264.
[13] P. F¨ockler, T. Zeidler, B. Brombach, E. Bruns, and O. Bim-
ber, “Phoneguide: museum guidance supported by on-device
object recognition on mobile phones,” in Proceedings of
the 4th international conference on Mobile and ubiquitous
multimedia.
ACM, 2005, pp. 3–10.
[14] N. Elmqvist, M. Fjeld, D. Axblom, J. Claesson, J. Hagberg,
D. Segerdahl, Y. Tai So, A. Svensson, M. Thor´en, and
M. Wiklander, “3dvn: A mixed reality platform for mobile
navigation assistance,” in ACM CHI2007 Workshop on Mo-
bile Spatial Interaction, 2007, pp. 1–4.
[15] E. Bruns, B. Brombach, T. Zeidler, and O. Bimber, “Enabling
mobile phones to support large-scale museum guidance,”
IEEE multimedia, no. 2, 2007, pp. 16–25.
[16] Y. Tokusho and S. Feiner, “Prototyping an outdoor mobile
augmented reality street application,” in Proceedings of the
8th IEEE Symposium on Mixed and Augmented Reality,
October 2009, pp. 3–5.
[17] D. Marimon, C. Sarasua, P. Carrasco, R. ´Alvarez, J. Montesa,
T. Adamek, I. Romero, M. Ortega, and P. Gasc´o, “Mobiar:
tourist experiences through mobile augmented reality,” Tele-
fonica Research and Development, Barcelona, Spain, 2010.
[18] P. Bihler, P. Imhoff, and A. B. Cremers, “Smartguide–a
smartphone museum guide with ultrasound control,” Procedia
Computer Science, vol. 5, 2011, pp. 586–592.
[19] G. Armanno, A. Bottino, and A. Martina, “Skylinedroid:
An outdoor mobile augmented reality application for virtual
heritage,” in Proceedings of the International Conference
on Cultural Heritage and Tourism (CUHT12), Cambridge,
England, 2012, pp. 25–27.
93
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

[20] I. Rubino, J. Xhembulla, A. Martina, A. Bottino, and G. Mal-
nati, “Musa: Using indoor positioning and navigation to
enhance cultural experiences in a museum,” Sensors, vol. 13,
no. 12, 2013, pp. 17 445–17 471.
[21] A. Chianese, V. Moscato, F. Piccialli, and I. Valente, “A
location-based smart application applied to cultural heritage
environments,” in Proceedings of the 22nd Italian Symposium
on Advanced Database Systems,Sorrento Coast, Italy, June
2014, pp. 335–344.
[22] S. Messelodi, C. Modena, L. Porzi, and P. Chippendale, “i-
street: Detection, identiﬁcation, augmentation of street plates
in a touristic mobile application,” in Image Analysis and
Processing
ICIAP 2015, ser. Lecture Notes in Computer
Science, V. Murino and E. Puppo, Eds. Springer International
Publishing, 2015, vol. 9280, pp. 194–204.
[23] P. Jain, J. Manweiler, and R. Roy Choudhury, “Overlay:
Practical mobile augmented reality,” in Proceedings of the
13th Annual International Conference on Mobile Systems,
Applications, and Services, ser. MobiSys ’15, 2015, pp. 331–
344.
[24] C. Larman and V. R. Basili, “iterative and incremental devel-
opment: A brief history,” Computer, vol. 36, no. 6, 2003, pp.
47–56.
[25] Eclipse
Indigo,
https://eclipse.org/,
[retrieved:
February,
2016].
[26] Microsoft
Visio,
http://ofﬁce.microsoft.com/en-001/visio/,
[retrieved: February, 2016].
[27] Object Management Group, “Uniﬁed modeling language,”
http://www.uml.org/, [retrieved: February, 2016].
[28] Adobe
Photoshop
CS5,
http://www.adobe.com/products/
photoshop.html, [retrieved: February, 2016].
94
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

