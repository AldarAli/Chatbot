Trace Analysis Exploration Using Semantic Web Tools Use Case: You Tube Network
Trafﬁc
Oscar Alberto Santana-Alvarez
University of Guadalajara
Zapopan Jalisco M´exico
oscar santana@cucea.udg.mx
Liliana Ibeth Barbosa-Santill´an
University of Guadalajara
Zapopan Jalisco M´exico
ibarbosa@cucea.udg.mx
Gerardo Padilla-Z´arate
Intel Corporation. Guadalajara Design Center.
Tlaquepaque, Jalisco, M´exico
gerardo.padilla.zarate@intel.com
Abstract—Analysis and exploration of information gathered
through local networks are tasks that must constantly be done.
Such information is useful for the local network administrators
because it gives them a good input about the most effective
maintenance procedure for the local network. Maintenance
may include activities such as watching over preferences among
users, keeping track of the size of the ﬁles users are accessing,
most viewed videos, etc. It is especially important to watch over
Video On Demand (VoD) trafﬁc, such as YouTube-like services
providers because of the size of the ﬁles they handle and their
popularity among users, especially students. One approach to
address monitoring activities is network trafﬁc traces, which
are sequences of events that recorded speciﬁc aspects of a
web site. Such traces are usually stored as plain text ﬁles (i.e.,
logs). This paper presents the trace analysis exploration using
semantic Web tools, with focus on the You Tube Network Trafﬁc
approach, which is based on semantic methods in facilitating
network trace analysis by populating two Network Trafﬁc
Trace Turtle Files (NTTTF) with network traces obtained by
monitoring means. The queries used over the NTTTFs allow
us to identify key information presented in the network trafﬁc
trace associated with different aspects of our case study. The
results showed the feasibility of this approach, where NTTFs
improved the way valuable information is being found. Analysis
of network traces showed information such as the most viewed
videos, the slowest YouTube servers, etc. With this information,
more accurate maintenance procedures can be followed. The
analysis and exploration of approximately 1,100,000 (one million
one hundred thousand) YouTube network trafﬁc traces was
performed by means of semantic queries.
Keywords—Network Trafﬁc Traces; Semantic Analysis; Local
Area Networks.
I. INTRODUCTION
The analysis and exploration of network traces obtained
by means of network monitoring is a time consuming task
because of the enormous quantity of data and the structure
of the ﬁles gathered. Besides, human intervention is neces-
sary in order to interpret the information stored in traces.
Therefore, it is necessary to implement a framework that
support network administrators with the task of ﬁnding key
information about the use of the local network. This paper
presents the exploration and analysis of information stored in
network trafﬁc traces. Network trafﬁc traces are data in text
format that stores speciﬁc aspects of a network. It proposes
an approach that facilitates the way network administrators
analyze and extract valuable information from network traces
by means of semantic web tools. We have the hypothesis that
the use of semantic web tools in the analysis and exploration
of network traces will allow us to ﬁnd valuable information
in a more manageable and friendly way in order to support
network managers.
A. Contributions
The main contributions of the present paper are as follows:
• It presents the steps involved in our approach, which
allows the analysis of YouTube Trafﬁc Network traces.
The steps include the conceptualization of ﬂat ﬂow of
data into NTTTFs. It also includes the queries that were
performed in order in order to extract key information
about users’ behavior about YouTube trafﬁc at local
network. The contribution of this paper falls into the
category of querying for mining.
• It presents the schema of the NTTTFs, which allows us
to perform semantic queries with sparl. NTTTFs help us
identify key information and relate important information
inside network traces.
B. Structure of the paper
The structure of the paper is organized as follows: In
Section 2, we present the related work, while in Section 3,
our approach is fully explained. In Section 4, we explain
the experiments we performed with our approach. Section 5
explains the results we obtained and, ﬁnally, in Section 6, we
conclude and mention future work on the subject.
II. RELATED WORK
1) Characteristics of YouTube Network Trafﬁc at a Campus
Network - Measurements, Models, and Implications: Zink
et al. [1] present a full investigation on how they found
out that certain videos are far more popular than others by
performing a statistical analysis on the networking traces.
They took into account users local preferences instead of
international preferences. Therefore, they demonstrated by
means of simulations that by performing some actions in the
network infrastructure such as the implementation of proxy
catching, they could reduce network trafﬁc signiﬁcantly. We
took the same traces Zink et al. used, in order to perform a
semantic analysis.
89
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

2) Execution Trace Exploration and Analysis Using Ontolo-
gies: Al Haider et al. [2] obtained execution traces from a
software of a basic calculator and they performed a simple
semantic analysis by using ontologies. Although they utilized
a reasoner and sparql instructions, they did it with barely
100,000 traces. One of the contributions of the present paper is
the implementation of a semantic analysis on a large amount
of network traces.
3) Understanding Execution Traces Using Massive Se-
quence and Circular Bundle Views: Cornelissen et al. [3]
proposed a a visual approach to understand the system at
hand in order to maintain it. They do so by using dynamic
information, e.g., execution traces. They developed a tool that
shows the relationships between the method calls through
curves in a circular view. They propose a visual approach to
gather information from traces while we propose the execution
of sparql queries in order to achieve the same goal.
4) Execution Trace Visualization in a 3D Space: Just as
Cornelissen et al. [3] proposed a visual approach to understand
the system to be analyzed by means of execution traces,
Dugerdil et al. [4] proposed a visual approach to analyze
execution traces based on 3D space.
5) Exploiting text mining techniques in the analysis of
execution traces: Pirzadeh et al. [5] proposed an approach
to analyze execution traces by taking into account the traces
execution phases. They applied their approach to large traces
of two different systems. We did not take into account traces
execution phases because such analysis could not be applied
to the network traces we choose due to their schema and the
content as well.
6) Evaluating distributed real-time and embedded system
test correctness using system execution traces: Hill et al. [6]
proposed the evaluation of distributed real-time and embedded
system test correctness by means of execution traces. Although
the authors evaluated a distributed real-time and embedded
system by means of execution traces, they did not do it by
using semantic tools, which is an important difference from
our work.
7) A survey of trace exploration tools and techniques: A
survey of trace exploration tools and techniques was done by
A. Hamou-Lhadj et al [7]. A review of the different tools and
techniques for trace exploration has been made. None of them
makes use of TTL ﬁles to perform a semantic analysis.
8) Relational Database Approach for Execution Trace
Analysis: S. Alouneh et al. [8] proposed and approach to
implement relational databases with execution traces. They
visualize their proposed architecture and give advantages of
their approach even though they did not implement it.
9) A Distributed Architecture for Dynamic Analyses on
User-Proﬁle Data: Antoniol et al. [9] proposed a model to
represent dynamic information (traces). They collected and
comprised traces from a distributed system and and left the
door open to manipulate the resultant traces.
10) A
Systematic
Survey
of
Program
Comprehension
through Dynamic Analysis: Cornelissen et al. [10] made a
systematic review on program comprehension through dy-
namic analysis (analysis of execution traces). This study
was categorized into four facets: activity, target, method and
evaluation.
11) SEAT-A usable trace analysis tool: Hamou-Lhadj et
al. [11] proposed a software for a exploration analysis of
execution traces. The software supports several features such
as ﬁltering techniques or working on several traces while we
developed a tool that takes all the traces included in a folder
and puts them together in a turtle format.
III. OUR APPROACH
In the present section, an overview of our approach is
being given. Figure 1 clariﬁes our approach.
Fig. 1.
Steps followed to obtain the NTTTFs.
First, documentation was obtained from UMass [12] traces
repository. The downloaded documentation ﬁle has the schema
of the network traces. Such a schema served us to code the
algorithm of The Filler.
After that, both NTTTFs were populated by means of a
software developed in .NET platform. This software is called
The Filler. The Filler was developed in C# programming lan-
guage. It generates two turtle ﬁles with .ttl extensions (NTTTF
Client Requests and NTTTF Transport Session) and inserts
into them the network traces also downloaded from the UMass
[12] repository. Once we had the NTTTFs populated, semantic
queries were performed in order to ﬁnd key information.
Al Haider et al. [2] also proposed the use of semantic
tools for traces. However, they used an ontology on execution
traces they obtained from a software of a basic calculator.
This leads to several differences; for example, the use of a
reasoner to check consistency of the ontology. Also, they did
its semantic analysis with barely 100,000 traces. One of the
contributions of the present paper is the implementation of a
semantic analysis on a large amount of network traces
Alouneh et al. [8] proposed an approach to implement
relational databases with execution traces. They visualize their
proposed architecture and give advantages of their approach
even though the authors did not implement it. The main reason
why we did not utilize relational databases is because we
performed several tests before the experiments shown in the
present paper. We had the serious restriction of using only
400,000 traces on the Jena Framework [13], so, we adjusted
90
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

the resultant schema of the NTTF ﬁles and we were able
to perform sparql queries on 1,100,000 traces in Jena. That
is to say, we wanted to put to the test Jena Framework on
the quantity of traces it can handle. Doing it with relational
databases has the major drawback that every corporation that
has a software for relational databases has his own imple-
mentation. We wanted to make our research as portable as
possible by using turtle text ﬁles. It is not the scope of this
paper to compare the efﬁciency of tools that make use of text
ﬁles against tools that make use of relational databases. The
scope of the present paper is to demonstrate that with network
traces, keeping traces as text ﬁles and the use of semantic tools,
we can ﬁnd information for the decision taking. Even though
efﬁciency is an important variable to take into account, it is
the advantages of using ontologies the point we want to show.
A. Documentation
As a ﬁrst step, we obtain the documentation from the UMass
[12] repository. The document identiﬁes two types of network
traces:
• Trace ﬁles that contain information about client requests
for YouTube video clips.
• Trace ﬁles that contain information about the transport
session for video clips requested by clients from the
UMass campus network.
Table 1 shows in the left column the ﬁelds found in the
transport session trace ﬁles and an example in the right
column. This is for clariﬁcation purposes.
TABLE I
SCHEMA AND EXAMPLE OF A TRANSPORT SESSION NETWORK TRACE
Field
Example
id
# 5
source ip (anonymized)
64.15.112.107
sport
80
dest ip (anonymized)
148.85.44.11
dport
2365
pro
6
dir
1
start time
0.464492
ﬁnishtime
74.901594
duration (in seconds)
74.437101
datapkts
3182
size in bytes
4644692
rate
499.180
ﬂags
16
All parameters are self-explanatory except, for the ﬂags
parameter. This attribute is being used for control purposes,
in this special case, network administrators. One thing to note
about this attribute is that its value was always 16 in all the
traces. So, this attribute, nor by itself, neither in conjunction
with another attribute, gave us any information at all about
the trace. Table 2 shows the ﬁelds found in the documentation
for the client request trace ﬁles on the left column, while an
example network trace is being shown on the right column.
TABLE II
SCHEMA AND EXAMPLE OF A CLIENT REQUEST NETWORK TRACE
Field
Example
timestamp
1189828805.208862
YouTube Server IP (anonymized)
63.22.65.73
sport
80
Client IP (anonymized)
140.8.48.66
Request
GETVIDEO
Video Id
lML9dik8QNw
Content Server IP
158.102.125.12
B. Network Trafﬁc Traces
Network trafﬁc trace ﬁles contain the data collected by mon-
itoring the local network. There are 21 ﬁles that contain two
types of network trafﬁc traces, as was said before, YouTube
Client Requests and YouTube Transport Sessions. Figure 2
shows a fragment of the content of a network trafﬁc trace ﬁle.
Each ﬁle has .dat extension and the information stored in every
one of them is plain text.
Fig. 2.
Network Traces located in the .dat ﬁles.
As can be seen, each line represents a network trafﬁc trace
and the order of the ﬁelds is the same as shown in Section 3.
C. The Filler
The Filler automatically creates two empty ﬁles, Clien-
tRequests.ttl and TransportSession.ttl, the NTTTFs, and auto-
matically populates them with the information stored inside
the network trafﬁc traces ﬁles. It was because we were
dealing with a great number of elements in the trace ﬁles,
approximately 1,100,000 (one million one hundred thousand)
traces, and doing so manually would have been a very hard
and time consuming task. The Filler was created in order to
cope with this task. Figure 3 shows the main screen of the
software with all the controls visible and enabled in order for
the reader to look at all the controls that are present in the
Filler.
Figure 4 shows the software running with the ﬁrst step
already being taken. It is a software that consists of three
simple steps:
• Step 1 - Load Network Traces (Client Requests). By
pressing this button, a window will appear in which the
91
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

Fig. 3.
Main screen of Filler. All controls enabled for clariﬁcation.
Fig. 4.
The Filler running.
user can select the folder of the computer that contains
the network trafﬁc traces that correspond to the client
requests. It is important to note that all the ﬁles that
are inside the folder will be read in order to extract
the traces from them. The latter was done in order to
ensure minimum intervention from the user with the aim
of making the software more easy to use. The folder
needs to contain only the ﬁles that have traces within
them. In our approach, the NTTTF Client Request was
populated using two YouTube network trafﬁc traces ﬁles.
Their name start with the preﬁx ﬂows.xxxx and have the
.dat extension.
• Step 2 - Load Network Traces (Transport Sessions). By
pressing this button a window will appear in which the
user can select the folder of the computer that contains
the network trafﬁc traces that correspond to the transport
session. The ﬁles that are inside the folder will be read in
order to extract the traces from them. The folder needs to
contain only the ﬁles that have traces within them. In our
approach, the NTTTF Transport Session was populated
using 19 YouTube network trafﬁc traces ﬁles. Their name
start with the preﬁx youtube.parsed.xxxxxx and have .dat
extension.
• Step 3 - Populate Both NTTTFs. This button triggers the
method that takes the selected folders and reads all the
ﬁles included in them one by one. Each line of every ﬁle
that is being read, is being parsed to the corresponding
NTTTF with text marks that adjust the Turtle standard
in order to obtain a Resource Description Format (RDF)
[14] compliant ﬁle.
IV. EXPERIMENTATION AND RESULTS
Once both NTTTF ﬁles (client request and transport session)
were generated by The Filler, Jena Framework [13] was
installed on the computer in order to perform the experiments.
The Jena Framework has within the sparql [15] tool, which
was used for performing semantic queries over the NTTTFs.
Sparql is a RDF [14] query language that allows us to perform
semantic queries, updating, copying and creation of data, etc.
For our approach only the execution of semantic queries was
needed.
The aim of the tests was to ﬁnd valuable information that
support the decision making of the local network managers. In
order to perform the tests, the following steps were followed:
• Step 1 - Every sparql query was written down inside a
text ﬁle with a .rq extension.
• Step 2 - The sparql application was executed with every
query following the syntax:
sparql –query queryﬁle.rq –data NTTTFxx.ttl –time
where queryﬁle.rq was substituted by 1-Top100v1.rq, 2-
TopDuration.rq and 3-TopSlowServers.rq
where
NTTTFxx.ttl
was
substituted
by
NTTTFCR.ttl
(Client Request) and NTTTFTS.ttl (Transport Session).
where the -time clause measures the time the query needed
to execute. Finally, we interpret the results and demonstrate the
valuable information that can be found by means of semantic
tools.
A. First Test
The aim of the ﬁrst test was to locate the top 30 most viewed
videos. The purpose of this query is to provide local network
managers with a list of the videos that can be stored in the
cache local server in order to reduce the trafﬁc outside of the
local network, increasing the bandwidth left for other users.
The ﬁrst test made use of the NTTTF Client Request. Figure
5 shows the sparql query:
Fig. 5.
First test sparql query.
Here is the shell command that was necessary in order to
execute the query:
sparql –query 1-Top100v1.rq –data NTTTFCR.ttl –time
Figure 6 shows the result thrown by the sparql tool.
The left column in Figure 6 shows the number of times a
certain YouTube was visited. In the right column, there are the
video identiﬁers. The VideoId that is on top is the video that
has been accessed the most number of times (2398 times). This
means that, if we backup this video in a local cache server,
2398 accesses outside of the local network will be saved. Now,
by adding the top 100 hits of the same query, we get 28793
accesses. If we follow the same procedure, we would be saving
92
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

Fig. 6.
Results of the ﬁrst test.
28693 accesses outside of the local network. We think this
would represent a huge saving in bandwidth if measures for
saving would be applied. Another piece of information that can
be noted from Figure 6 is the time it took for the sparql tool to
perform the query, namely 415.926 seconds. This represents
a small amount of time taking into account the quantity of
traces analyzed.
B. Second Test
The second test we performed was to locate the id of the
longest transport sessions. We suggest that a local backup of
the longest transport sessions will increase overall bandwidth
available for the users. This test made use of the NTTTF
Transport Session. Figure 7 shows the sparql query:
Fig. 7.
Second test sparql query.
Here is the ms-dos command that was necessary in order
to execute the query:
sparql –query 2-TopDuration.rq –data NTTTFTS.ttl
Figure 8 shows the result thrown by the sparql tool.
Figure 8 shows on the left column the identiﬁers of the
transport sessions with the highest duration in seconds (right
column). As can be seen, we have very long sessions (6057.49
seconds the longest of them). Presumably, the longer the
transport sessions, the longer videos last. We are sure that
Fig. 8.
Results of the second test.
by storing not only most viewed videos but also the longest
videos in a local cache server will have a direct impact in
the overall available bandwidth for the rest of the users of
local network. Now, by summing the top 100 hits of the same
query we get 202,608.46 seconds in total. This means that by
backing up these videos, we will be unloading local network
from this amount of time. Another piece of information that
can be noted from Figure 8 is the time it took for the sparql
tool to perform the query, namely 2.141 seconds.
C. Third Test
The third test we performed was to locate the slowest
YouTube servers. We suggest that a local backup of the
slowest servers’ videos is necessary in order to increase overall
bandwidth available for the users. This test made use of the
NTTTF Transport Session. Here is the sparql query:
Fig. 9.
Third test sparql query.
Here is the ms-dos command that was necessary in order
to execute the query:
sparql –query 3-TopSlowServers.rq –data NTTTFTS.ttl
Figure 10 shows the result thrown by the sparql tool.
Figure 10 shows on the left column the IP addresses with
the lowest rates (right column). This means that these are the
slowest YouTube servers. The identiﬁcation of slow servers
93
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

Fig. 10.
Results of the second test.
allows for actions to be taken to improve the situation, such
as the search for alternate servers. These are actions taken by
some network devices, such as routers, in order to enhance
the overall performance of the network. Sometimes there is
no solution, no alternate servers for example, to this problem.
We are sure that by identifying slow servers and reducing
access to them will not only diminish the network usage but
also reduce the work load of network devices that perform
actions to bypass them. Another piece of information that can
be noted from Figure 10 is the time it took for the sparql tool
to perform the query, namely 2.156 seconds, which is very
little time for the information we gather.
D. Fourth Test
This test represents the last bastion we need to ensure we
can have a direct impact on the enhancement of the local
network by using semantic web tools. The fourth test we
performed was to search for atypical values on the duration on
the transpot sessions traces. An example of an atypical value
may be a session that lasted too long for a small ﬁle with a
good rate. This test made use of the NTTTF Transport Session.
Figure 11 shows the sparql query.
Fig. 11.
Fourth test sparql query.
Here is the ms-dos command that was necessary in order
to execute the query:
sparql –query 4-Anomalies.rq –data NTTTFTS.ttl
Figures 12 and 13 show the result given by the sparql tool.
Fig. 12.
Results of the fourth test with DESC clause.
Fig. 13.
Results of the fourth test with ASC clause.
Figures 12 and 13 show, from left to right, the Id of the
transport session, adjusted rate, expected duration, percentage
of accuracy. The main difference is that Figure 12 shows the
top most different transport sessions Ids and Figure 13 shows
the lowest different transport sessions. This query works as
follows: ﬁrst, we needed to adjust the rate to obtain 100%
accuracy. That is the reason why we multiply the rate by 125.
Later on, we divided the size and adjusted the rate. By doing
this we obtained the expected duration of a transport session.
Finally, we compared the duration of the transport session with
the expected duration. This comparison gave us a percentage
value of accuracy. Every value that has a bias of more than
1% would be considered as atypical. As it can be seen from
both ﬁgures, there is no atypical value. This means that all
values from this trace are perfectly explainable.
94
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

V. CONCLUSION AND FUTURE WORK
Semantic web tools, such as sparql from Jena Framework,
allow us to perform semantic queries in order to extract
valuable information from raw data. As shown in Section 4,
the information gathered by means of semantic queries could
help people (local network administrators in this case) to better
understand the system at hand in order to take precise decision
over its maintenance. It is important to note that the total
amount of time for the three queries to execute in a laptop with
standard speciﬁcations (Core i5, 8Gb RAM, 1TB HDD) was of
420.223 seconds (7 minutes). It is a very small amount of time
taking into account the network traces quantity, approximately
1100000 (1 million one hundred thousands). That is to say,
approximately 10 minutes are necessary in order to follow
our approach. It is our belief that more experimentation must
be done in order to take advantage of more semantic tools
that are at our disposal, for example, ontologies. Further
investigation will be done with network traces but next time,
we will take advantage of the characteristics of ontologies in
order to perform more sophisticated and complex processes.
Ontologies are formal representations of information and have
characteristics such as datatype properties, object properties,
inference of information, etc., that makes them attractive to be
applied to traces. One way of applying ontologies to traces is
by deﬁning a model of an ontology that matches the schema of
the trace at hand. After that, we need to look for the technology
that best suits the expecting results, a software for example.
Next steps are uncertain and will depend on what authors will
seek to solve with the ontology. This will allow us to gather
more accurate and concluding information for the decision
making.
VI. ACKNOWLEDGMENTS
Oscar Alberto Santana Alvarez will like to thank the Con-
sejo Nacional de Ciencia y Tecnolog´ıa (CONACyT) for their
support for his PhD program. Also, we will like to thank to
Michael Zink, Kyoungwon Suh and Jim Kurose for giving us
access to the network trafﬁc traces they gathered. These ﬁles
were the principal input for the present paper.
REFERENCES
[1] M.
Zink,
K.
Suh,
Y.
Gu,
and
J.
Kurose,
“Characteristics
of
youtube
network
trafﬁc
at
a
campus
network
-
measurements,
models, and implications,” Comput. Netw., vol. 53, no. 4, pp.
501–514, Mar. 2009, [retrieved: 05, 2014]. [Online]. Available:
http://dx.doi.org/10.1016/j.comnet.2008.09.022
[2] N. Al Haider, B. Gaudin, and J. Murphy, “Execution trace
exploration and analysis using ontologies,” in Proceedings of
the Second International Conference on Runtime Veriﬁcation,
ser. RV’11.
Berlin, Heidelberg: Springer-Verlag, 2012, pp.
412–426, [retrieved: 05, 2014]. [Online]. Available: http:
//dx.doi.org/10.1007/978-3-642-29860-8 33
[3] B. Cornelissen et al., “Understanding execution traces using
massive sequence and circular bundle views,” in Proceedings
of
the
15th
IEEE
International
Conference
on
Program
Comprehension, ser. ICPC ’07.
Washington, DC, USA: IEEE
Computer Society, 2007, pp. 49–58, [retrieved: 05, 2014].
[Online]. Available: http://dx.doi.org/10.1109/ICPC.2007.39
[4] P. Dugerdil and S. Alam, “Execution trace visualization in a
3d space,” in Information Technology: New Generations, 2008.
ITNG 2008. Fifth International Conference on, April 2008, pp.
38–43.
[5] H. Pirzadeh, A. Hamou-Lhadj, and M. Shah, “Exploiting text
mining techniques in the analysis of execution traces.” in ICSM.
IEEE, 2011, pp. 223–232, [retrieved: 05, 2014]. [Online].
Available: http://dblp.uni-trier.de/db/conf/icsm/icsm2011.html#
PirzadehHS11
[6] J. H. Hill, P. Varshneya, and D. C. Schmidt, “Evaluating
distributed real-time and embedded system test correctness
using system execution traces.” Central Europ. J. Computer
Science, vol. 1, no. 2, pp. 167–184, 2011, [retrieved: 05,
2014]. [Online]. Available: http://dblp.uni-trier.de/db/journals/
cejcs/cejcs1.html#HillVS11
[7] A. Hamou-Lhadj and T. C. Lethbridge, “A survey of trace
exploration tools and techniques,” in Proceedings of the
2004 Conference of the Centre for Advanced Studies on
Collaborative
Research,
ser.
CASCON
’04.
IBM
Press,
2004, pp. 42–55, [retrieved: 05, 2014]. [Online]. Available:
http://dl.acm.org/citation.cfm?id=1034914.1034918
[8] S. Alouneh, S. Abed, B. Mohd, and A. Al-Khasawneh, “Re-
lational database approach for execution trace analysis,” in
Computer, Information and Telecommunication Systems (CITS),
2012 International Conference on, May 2012, pp. 1–4.
[9] G. Antoniol and M. D. Penta, “A distributed architecture
for
dynamic
analyses
on
user-proﬁle
data.”
in
CSMR.
IEEE Computer Society, 2004, pp. 319–328, [retrieved: 05,
2014]. [Online]. Available: http://dblp.uni-trier.de/db/conf/csmr/
csmr2004.html#AntoniolP04
[10] B. Cornelissen, A. Zaidman, A. van Deursen, L. Moonen, and
R. Koschke, “A systematic survey of program comprehension
through
dynamic
analysis.”
IEEE
Trans.
Software
Eng.,
vol. 35, no. 5, pp. 684–702, 2009, [retrieved: 05, 2014].
[Online]. Available: http://dblp.uni-trier.de/db/journals/tse/tse35.
html#CornelissenZDMK09
[11] A. Hamou-Lhadj, T. Lethbridge, and L. Fu, “Seat: a usable trace
analysis tool,” in Program Comprehension, 2005. IWPC 2005.
Proceedings. 13th International Workshop on, May 2005, pp.
157–160.
[12] T. Weibel. Network - umass trace repository. [accessed: 05,
2014]. [Online]. Available: http://traces.cs.umass.edu/index.php/
Network/Network
[13] Apache.org. Jena framework. [accessed: 05, 2014]. [Online].
Available: http://www.apache.org/
[14] W3.org. Rdf - semantic web standards. [accessed: 05, 2014].
[Online]. Available: http://www.w3.org/RDF/
[15] W3.org. Sparql query language for rdf. [accessed: 05, 2014].
[Online]. Available: http://www.w3.org/RDF/
95
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-364-3
IMMM 2014 : The Fourth International Conference on Advances in Information Mining and Management

