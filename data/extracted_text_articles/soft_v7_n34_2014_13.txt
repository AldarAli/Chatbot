590
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Development and Evaluation of CSCL System for Large Classrooms Using 
Question-Posing Script 
 
Taketoshi Inaba and Kimihiko Ando        
Graduate School of Bionics, Computer and Media Sciences 
Tokyo University of Technology 
Tokyo, Japan
                                 e-mail: inaba@stf.teu.ac.jp, e-mail: ando@stf.teu.ac.jp 
 
 
Abstract—In the area of Computer Supported Collaborative 
Learning (CSCL) research, scripting collaborative learning is a 
relatively new but promising approach to promote learning. 
The term scripting is used to describe ways of prescribing 
relevant elements for collaborative interaction, such as group 
formation, roles, learning activities, sequence of learning 
activities. Many studies have shown that free collaboration 
without 
explicit 
scaffolding 
rarely 
produces 
effective 
interaction and that the script can be one of the most effective 
scaffoldings. Basing on SWISH model proposed by Dillenbourg, 
we have adopted the reciprocal teaching approach and 
designed a script which allows students to create questions and 
answer them mutually. To implement this question-posing 
script for large classrooms, we have developed a CSCL system 
which has two important functions: automated group 
formation function that can form groups on the fly, based on 
students’ personal traits, and chat function by which students 
can discuss each other within their group. For the evaluation, 
we have conducted an experiment with some 300 students in a 
large classroom to evaluate our system and analyze 
interactions in detail during each sequence of learning 
activities. The evaluation result indicates that the learners felt 
encouraged to understand better about learning task. At the 
same time, it becomes clear that the quality of discussion on 
chat affects reciprocal question posing. As well, it is indicated 
that group size and knowledge level of leader or other 
members affect the process of reciprocal actions and activities 
at some degree. 
 
Keywords-Collaborative learning; CSCL; large classroom; 
      collaborative script; question-posing 
                 
I. 
 INTRODUCTION  
This article is an extended version of a conference paper 
presented at eLmL 2014, the Sixth International Conference 
on Mobile, Hybrid and On-line Learning [1]. It introduces 
more information on the theoretical background of this 
study, a more specific and technical presentation of the 
system and some new data from the experiment. 
 
A. CSCL and its issues 
According to the social constructionism presented by 
Vygotsky [2] and the theory of legitimate peripheral 
participation presented by Lave and Wenger [3], the 
learning, which was understood as a cognitive process in an 
interior of an individual learner, will be recognized as a 
social process, or social cognition that progresses while 
cooperating with others [4]. Far from denying the learning as 
an individual cognitive activity, the social cognition can 
promote knowledge construction at an individual level and 
metacognition for learning strategies, through problem-
solving by discussing with others [5].  
The environment for such collaborative learning is built 
on the computer network, and such computer technologies 
are used as a supporting tool to promote collaborative 
learning, which is called, Computer Supported Collaborative 
Learning (CSCL). Advantages of CSCL over the face-to-
face learning are: learners who are geographically or timely 
distant from each other can learn, a large number of learners 
can learn and be managed, logs of the learning process in 
details can be saved for learners, managers and scholars to 
re-use them, learning software and contents can be used and 
many more.  
On the other hand, many case studies on the 
collaborative learning point out that it is highly unlikely for 
learners to carry out collaborative activities voluntarily while 
learning without an external scaffolding [6] [7]. For this 
reason, in order to resolve such issues in learning, various 
methods have been developed to appropriately regulate and 
structure the learning process within a group for effective 
and productive work and discussions among learners.  
In this study, one of such methods, “collaborative script” 
was implemented in the CSCL system and used in a large 
classroom in the university. First, the next section will 
provide the overview of the collaborative script.  
B.  Collaborative script and its issues 
The concept of script was originally suggested by Schank 
and Abelson in the field of cognitive science, and it has a 
meaning of internalized knowledge about socially sharing 
steps and rules people should follow in a certain situation 
(e.g., eating at a restaurant) [8]. 
Once the concept was introduced in the field of 
collaborative study, the script became a series of external 
scaffolding 
methods that 
are provided to 
promote 
collaborative learning. The first study on collaborative script 
was proposed by O’Donell and Dansereau [9] [10], which 
defines the script as a scenario for a small learning group, 

591
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
which prescribes in details, who is carrying out what kind 
of learning activities and when. Due to the complexity of the 
script before the learning activities themselves, learners 
needed to be trained to follow the script. 
After the script was adopted in CSCL, instead of training 
learners to execute the script prior to learning, the system 
interface was used to indirectly lead them to the scripted 
learning process [11].  
Many researches indicate that the script can be designed 
at 2 levels in the CSCL environment. First, there is a design 
approach at a macro level; it defines who will learn, what 
assignment subjects for a group and how to distribute tasks 
among learners. On the other hand, there is a micro level 
approach which consists in prescribing the details of each 
learning activity in order to revitalize social interactions 
among learners [12] [13]. 
There have been many studies that indicate the 
effectiveness of various CSCL systems with the script, but 
there are some issues at the same time. First, there is an issue 
on controlling a compelling power of the script. In other 
words, it means how to deal with the risk of over-scripting 
which takes too much self-motivation out from learners [14]. 
Next, despite a lot of empirical case studies, yet there are 
very few suggestion on a script design model that can be 
commonly used, with some exceptions [15] [16] [17]. About 
the first issue, we suggested previously a method to flexibly 
adjust compelling power of the script according to learners’ 
traits and learning situation [18]. So, this study focuses on 
the second issue, adopting a design method as the approach 
in order to design the script based on the design principle and 
implement and assess it. 
C. SWISH MODEL as Design Principle 
The purpose of the collaborative script is to support the 
problem solving and knowledge construction by social 
interactions among learners. To do so, a mechanism to 
trigger effective interactions is an important element. A 
Swiss scholar, Dillenbourg, suggests SWISH model as such 
mechanism. This model is the design principle for 
collaborative script that gives tasks that would generate 
conflicts among learners; it is supposed to promote intense 
interactions (statements, explanations, discussion, etc.) to 
overcome these conflicts [13].  
Exactly, SWISH is an abbreviation of “Split Where 
Interaction Should Happen”. And this model can be 
formulated in three points: 
1. Learning results from the interactions while students are 
constructing a shared understanding of the task despite the 
fact that the task is distributed. 
2. Task distribution determines the nature of interactions. 
Interactions are mechanisms for overcoming task splits. 
3. Task splits can be designed for triggering the interactions 
that designer wants to elicit. 
From this model, three script schemata are drawn as 
design guidelines: 1. jigsaw schema, 2. conflict schema, 3. 
reciprocal schema. In the jigsaw schema, the information 
necessary to solve the problem being distributed, no group 
member is able to solve the problem alone. This split elicits 
social interactions to seek mutually the solutions in bringing 
complementary knowledge each other. The conflict model 
forms groups with students having conflicting opinions; this 
conflicting relation elicits argumentation.  
 In this study, we adopt the third schema, reciprocal one. 
This schema defines the roles for each student and switches 
these roles. The horizontal split is realized between cognitive 
and metacognitive layers of the task and is counterbalanced 
by reciprocal regulation. The most well-known example of 
this schema is Palinsca and Brown’s reciprocal teaching 
method [19]. In their approach for enhancing reading skill, 
four roles (questioner, summarizer, clarifier, predictor) are 
assumed in rotation by students. Through the reciprocal 
teaching process, the activation of mutual monitoring activity 
is particularly expected; learning accuracy is monitored 
during asking questions or clarifying and summarizing the 
content, whereas learning consistency of predictions is 
assessed. 
According to Dillenbourg, by using collaborative script, 
the entire learning process is composed of multiple phases 
that are linear occurrence in succession [14]. Each phase has 
attributes, being regulated by: 1. Type of task, 2. Group 
structure, 3. Tasks assigned to group members, 4. 
Communication method and 5. Required time. As it will be 
shown in Section II, in conformity with the above, our script 
proposed in this study can be outlined as follows: 1. Tasks 
for the major phase is to prepare questions and discuss/refine 
the questions reciprocally, 2. The groups have 3 to 5 
members (depending on the system specifications, a number 
of group members can be flexible) 3. Tasks are assigned to 
question preparer, answerer and grader based on reciprocal 
tutoring method, 4. The major communication method is to 
chat, using the network and 5. Time required is a deadline 
for the final project to be submitted, which is the end of the 
class.  
Also, many existing systems have a control function in 
place such as an order in making comments and attributes of 
comments (suggestion, question, approval, disapproval, etc.) 
[20] [21]. This study, on the other hand, does not have such 
control in place at this time. We felt that such function to 
control 
attributes 
and 
occurrence 
of 
comments 
is 
unnecessary when the conditions are narrow and limited such 
as to prepare questions and allocating tasks to each leaner. 
D. Structure of this paper 
This paper is structured as follows. Section II presents 
the general outline and the purpose of this study, and 
Section III describes our CSCL system for large classrooms. 
The collaborative script design is discussed in Section IV. In 
the Section V, the details of page structure is described with 
their function. Then, we present our experiment and results 
from our evaluation in Sections VI and VII. Section VIII 
concludes the paper. 
II. 
PURPOSE OF THE STUDY 
In this study, the script based on the reciprocal schema, is 
designed and implemented in the system to assess its effects. 
The system is for an environment where several hundred 
students in higher educational institutions cannot interact 

592
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
with one another face-to-face. The collaborative learning is 
carried out by those students using the system online.  
As for the assessment, assignments and chat log data are 
used to assess the quality of interactions during the 
collaborative process and its learning effects. By analyzing 
the correlativity between the two, we aim to have some 
guidelines for improving the script and design principle.  
III. 
SYSTEM 
As Fig. 1 shows, our system was developed for an 
environment, such as a large classroom with several 
hundred people at higher educational institutions where 
face-to-face group learning is difficult. A teacher and 
students gain access to the CSCL server through PCs that 
are connected to the network. Learners can form a group 
regardless of where their locations are, and a teacher can 
remotely keep track of learning state of each group. 
Our system is a server-client web application. As Fig. 2 
shows, Linux server was constructed by using Java. We 
used Apache for Web server and Tomcat for Web container. 
The application was realized by JSP and servlet. Mysql was 
used for the data base in which information about the script 
and users properties is contained. 
On client-side, there is, practically, no limitation about 
the choice of OS and browsers, but the use of Windows is 
recommended  
A. System Overview 
As Fig. 3 shows, the system consists of different 
functions, such as “automated group formation” and 
“questionnaire preparation” by which a teacher designs a 
collaborative 
learning, 
“assignment 
submission”, 
“reciprocal reviews” and “chat within a group” that provide 
a collaborative environment to learners. “Learners’ 
properties” in Fig. 3 are drawn from questionnaires and pre-
tests that were administrated before. Based on the properties, 
the system automatically forms groups. 
 
B. Flow of Collaborative Learning 
The collaborative learning in this system is composed   
of 5 blocks, as Fig. 4 shows. The following is the learning   
flow. 
1. “Prior Setting” allows a teacher to conduct questionnaires,   
prepare pre-tests and register to the system.  
2. In “Pre-learning”, each learner submits the questionnaire 
and pre-test, which was registered in “Prior Setting” on the 
system.  
3. In “Group Formation”, the system automatically forms   
groups based on the parameters the teacher has set and 
results of statements/answers by the learners. Small 
adjustments to the group formation can be made manually 
by the teacher. 
4. In “Collaborative Learning”, reciprocal reviews within a 
group and among groups as well as chat system within a 
group can be done in the system. The learners carry out 
these collaborative works according to the collaborative 
script.  
5. In “Post Assessment”, the teacher reviews and grades 
submitted assignments. 
C. Automated Group Formation Function 
In this study, group formations are made possible in 
various ways that a teacher intends to do, by combining 
multiple elements of user characteristics that are obtained 
beforehand. 
 
 
Figure 3.  System structure 
 
 
Figure 4.  Flow of collaborative learning suggested 
by the system 
 
Management of
Collaborative
Learning
Design of
Collaborative 
Learning
Environment of
Collaborative
Learning
Automated 
Group 
Formation
Preparing
Questionnaires/
Pre-Tests
Assignment 
Management
Submitting
Questionnaires/
Assignment
Reciprocal
Review
Chat 
In a Group
Group
Management
Learners’ 
Properties
Pre-Setting
Pre-Learning
Returning
Questionnaires
Group 
Formation
Automated
Not 
Automated
Collaborative
Learning
Reciprocal
Review
Chat 
in Group
Individual 
Assignment
Post-
Evaluation
Review
Teacher
Student
Teacher
Student
Teacher
Preparing
Pre-Tests
Returning
Pre-Tests
Group 
Assignment
Evaluation
Preparing
Questionnaires
 
 
Figure 1.  System overview 
 
 
Figure 2.  Technical Details 
 
 
 
 
 
                                                                                                                       
 
 
 
Large Class Room
Home
Group2
Group1
Student A
Student B
Student C
Student D
Teacher
CSCL Server
Developed Application
Linux
Tomcat
Web Server
Apache
Java
JSP
DB
mysql
browser
servlet
Windows
server
client

593
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
For example, a teacher can freely decide how many 
people to be in a group. He can also form flexibly groups 
with members of which properties are similar, or different. 
Our system has two possibities for group formation; the 
first possibilty is to form groups with homogeneous students 
who have similar properties, the second is to form groups 
with heterogeneous students who have different properties. 
These properties are extracted from the test score or from 
the result of questionnaire, and then they are represented as 
numeric values . 
Fig. 5 shows the case of group formation with 3 students. 
At first, the numeric values are sorted. For forming 
homogeneous groupus, three students are picked up in 
number order, from the first to the last (Fig. 5). In contrast, 
for forming heterogenous groups, each student is distributed 
to each group from the first student to the last student (Fig. 
6). 
 
D. Collaborative Script Function 
In collaborative script, tasks are assigned according to 
roles, such as “Preparer”, “Answerer” and “Grader”. In the 
system, the group management function assigns tasks to 
each learner while the assignment management distributes 
allocated tasks. Also, roles that each learner is supposed to 
play and tasks are given automatically so that learners can 
work on their tasks at an appropriate speed without having 
to think about the collaborative script.                                                                                                                                                           
IV. 
COLLABORATIVE SCRIPT DESIGN 
Supposing the experimental environment shown in Table 
I, the details of the collaborative script to be executed in the 
proposed system were designed.  
A. Question-Posing Script 
A script was made for the learning process in the task 
model called “reciprocal question-posing”. The following is 
a flow of “reciprocal question-posing collaborative script”, 
which was designed in this experiment.  
 
Phase-1: Preparing individual questions 
A theme of question posing is given to learners. All the 
students prepare a question based on the given theme and 
submit it, including the answer and explanation about the 
question.  
 
Phase-2: Reviews within group 
Regarding the question prepared at Phase-1, 3 members 
within a group are assigned as a question preparer, answerer 
and grader and review reciprocally within the group through 
the following activities (Fig. 7).  
a. An answerer prepares answers to the questions prepared 
by a question preparer and submits the answer and 
evaluation of the question.  
b. A grader grades the answer submitted by the answerer in 
a. and submits the graded result and evaluation of the 
question. 
c. Based on the evaluation submitted in a. and b. a question 
preparer evaluates himself/herself,  
d. The above process from a to c is repeated until all the 
learners rotate to take a different role within the group and 
become a question preparer 
 
Phase-3: Question preparation within a group 
Through a discussion in a group chat, a question must be 
prepared for submission. The answer and explanation are 
prepared along with the question. 
 
Phase-4: Submission and publish of final questions 
Students submit a question/answer/explanation to their 
teacher. The teacher then publishes the questions as a 
assignment among groups. 
 
Phase-5: Solving questions reciprocally among groups 
Students solve group questions that are published. 
 
V. 
PAGE STRUCTRE 
In this section, the page structure of our system will be 
shown below with Webpage transition diagrams.      
 
TABLE I. PRECONDITION OF COLLABORATIVE SCRIPT 
Number of Students
Aboue 300 people
Member of Groups
3 people
Learning Time
90min × 2
Design Guideline
Reciprocal Teaching
 
 
 
Figure 7.  Group review 
Question Preparer
Answerer
Grader
Question
Grading
The Answer
Evaluating
Questions
Answer/
Explanation
Evaluating
Questions
 
 
Figure 5.  Formation of homogenous group 
 
 
Figure 6.  Formation of heterogeneous group 
 
66666666669
1
2
3
4
6
5
7
8
7
12
1
5
6
33
4
25
22
13
45
17
7
12
1
5
6
33
4
25
22
13
45
17
7
12
1
5
6
33
4
25
11
13
45
17
1
2
3
4
6
5
7
8
9
11
12
10
6666666666
6
33
4
25
4
3
2
1
18
19
17
7
12
1
5
6
33
4
25
22
13
45
17
7
12
1
5
6
33
4
25
22
13
45
17
7
12
1
5
33
4
25
22
13
45
17
1
17
2
18
3
19
35
20
36
4
33
34

594
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
As Fig. 8 shows, the system has three distinct 
subsystems: 
student 
subsystem, 
teacher 
subsystem, 
administrator subsystem. Each subsystem also has its own 
subsystems. In the following subsections, their functions 
with webpage transition are described. 
A. Student subsystem 
The student subsystem is composed of the main system 
and the CSCL system. Fig. 9 is a page transition diagram of 
the main system. In this system for students, functions like 
student registration and student login are set up. In My Page 
after the login page, students can do course registration and 
respond to questionnaires. From the data collected in these 
pages, user model of each student is constructed for 
automated group formation. After these pages, students 
enter into the Forum Login Page which leads to the CSCL 
system. 
 Fig. 10 recapitulates the main steps by which students 
move from the student registration to the Forum login. 
Fig. 11 shows the page transition of the CSCL 
subsystem after the Forum login which is opened to the 
students who have been assigned to a group after course 
registration. To execute the question-posing script explained 
in Section IV.A, this subsystem have main functions such as 
individual question submission, answer to question and 
evaluation, question grading and evaluation, question self-
evaluation, group chat BBS, group assignment submission 
and so on. 
Fig. 12 presents the flow of main student activities 
defined by the script. But if necessary, students can return to 
prior activities. 
B. Teacher subsystem 
The teacher system consists of the main system and the 
group formation system. 
Fig. 13 is a page transition diagram of the main system 
which has basic functions like teacher registration and 
teacher login. In My Page after the login, teachers can 
registrate their courses and make questionnaires. Since 
questionaire items are shared by all teachers, it is necessary 
to check the list of existing items before the new items 
registration.   
Fig. 14 shows the page transition of the group formation 
subsystem: teachers have roughly two possibilities in 
forming groups. The first possibility is to select 
questionnaire items and form groups on the basis of their 
result. The second possibility is to form groups from the 
result of test scores. 
C. Administrator subsystem 
The main system is the singular component of the 
administrator subsystem. Fig. 15 shows the page transition 
of this component. In the questionnaire classification 
registration, the administrator can determine what kind of 
subject (favorite subject, learning style, preferences, 
characters etc.) the questionnaire is addressing. In the 
questionnaire type registration, he can define the type of 
questionnaire (free writing, fill-in-the-blank, multiple-
 
 
Figure 10.  Steps of student activity 
 
 
Figure 11.  CSCL Subsystem 
 
 
 
Figure 12.  Steps of student activity in the CSCL Subsystem 
Student
Registration
System
Login
Course 
Registration
Questionn
aire
Forum
Login
Forum Login
Forum Top page
Individual Question Submission
Answer and Evaluation of Question
Question Grading and Evaluation
Own Question  Evaluation
Group chat BBS
Group Assignment Submission
Other Group Assignment List
Answer of Other Group Assignment
Explanation
Submit
Individual Questions
Answer
Other’s Question
Grade
Other’s Question
Evaluate
Own Question 
Make Group
Question
On –line 
Examination
 
Figure 8.  Webpage Transition Diagram 
 
 
Figure 9.  Student Subsystem 
System Top-page
Student Top Page
Teacher Top Page
Administrator Top 
Page
To Student Subsystem
To Teacher Subsystem
To Administrator Subsystem
Student Top page
Student Registration
Registration Confirmation
Completing Registration
Student Login
My Page
Course Registration
Questionnaire List
Answer 
Answer Confirmation 
Answer Completing 
Forum Login
To CSCL Subsystem

595
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
choice, etc.). He can also consult the student list, the actual 
learning status of each student, the teacher list and all the 
data of questionnaires. 
  
VI. 
EXPERIMENT OVERVIEW 
To assess this system, an experiment was carried out 
during a class at Tokyo University of Technology. The 
overview is as follows: 
・Targets: Students at Tokyo University of Technology 
Freshman to Senior 298 students, 112 groups 
・Dates for the experiment: January 10 (Tue) and January 
18 (Wed), 2011 
・Lecture: Basics of the logic 
・Learning assignment: students prepare a question; the 
question has statements in Japanese that represent an 
deductive inference that contain several premises and a 
conclusion. The answer must have a well–formed formula 
that represents correctly the inference, and a truth table that 
verifies the validity/invalidity of the inference. For this 
assignment, several exercises had been done during 
previous lectures. Also, similar question were distributed 
and completed as a pre-test one week before the experiment. 
The pre-test was graded by the teacher in charge. 
The experiment was carried out during 2 days in a 90 
minute class. On day 1, 60 minutes were spent for 
answering/evaluating reciprocally within each group. On 
day 2, another 60 minutes were spent for posing questions 
reciprocally within each group. The flows for learning are 
shown in Fig. 16. 
The 
group 
review 
phase 
for 
day 
1 
is 
for 
answering/evaluating 
questions, 
grading/evaluating 
questions and self-evaluation. Fig. 17 shows evaluations of 
a question by a grader’s point of view. 
The group review phase for Day 2 is for preparing group 
question. Using a group chat function, learners discuss how 
to pose the final question.  
In this experiment, a number of group members was set 
to 3. But there were some groups of less than 3 group 
members due to no attendance of some members. Specially, 
since groups could not be changed on Day 1 and Day 2, 
there were many groups of less than 3 group members due 
to no attendance of group members on Day 2. For this 
reason, the evaluation of this experiment was done on only 
93 groups with group members of 2 or 3 on Day 2. Table II 
shows changes in a number of group members.  
Also, on Day 1 carry out a group review, group 
members of less than 2 members could not carry out a group 
review. In this case, the groups of 2 members continued the 
learning using a different script that allows the 2 members 
 
Figure 13.  Teacher Subsystem 
 
                               
 
Figure 14.  Group Formation Sub System                                                                     Figure 15.  Administrator’s Subsystem      
 
 
Teacher Top Page
Teacher Registration
Registration Confirmation
Registration 
Completing
Teacher Login
My Page
Course Registration
Questionnaire Making
Item Selection
Registration Confirmation
Completing Registration
Item Ordering
Questionnaire 
Confirmation
Completing Making
Questionnaire Item Making
Item Registration Confirmation
Completing Making
Questionnaire Item List
Questionnaire List
Consulting Questionnaire
Group Formation
To Group Formation Subsystem
Group Formation
Group Formation Items Selection 
Number of people Setting
Parameters  for Group Formation Items and the 
Priority Setting  
Group Formation Confirmation
Completing  Group 
Formation 
Group Formation by 
Test Score
Administrator Top Page
Questionnaire Classification Registration
Registration Confirmation
Completing Registration
Questionnaire Type Registration
Type Confirmation
Completing Registration
Student List
Consulting Learning Status
Consulting Questionnaires List
Teacher List
Consulting Subjects List

596
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
solved questions and graded reciprocally. For a group of 1 
member, the 1 member had additional members who came 
in late. 
VII. 
EVALUATION 
The aim of this section is to present the results of the 
experiment and their evaluation in different ways. 
A. Automated Group Formation 
In this experiment, groups were formed in a way that the 
academic level for each group is similar. Each group 
consists of equal numbers of learners who ranked top, 
middle and low in the pre-tests about the content of the 
lecture. The results of the pre-tests were total points (perfect 
score is 400 points) of 4 pre-tests that had been 
implemented according to the progress of the lecture. All 
the grading was done by the same teacher. Fig. 18 shows the 
distribution of individual score and average score within 
group. Because the average scores gather in the median, the 
automated group formation functions normally. 
B. Question-Posing Script Evaluated by Learners 
At the end of the experiment, we distributed a 
questionnaire to the students. Fig. 19 shows the responses to 
the question “Did you have a deeper understanding through 
posing questions?” Since many responded, “Deepened” and 
few answered, “Not deepened” and “Not at all deepened”, 
the learners find the script effective. 
Fig. 20 shows the degree of difficulty in posing 
questions. “Very difficult” (18%) and “Difficult” (68%) 
form a large majority. This result indicates the high degree 
of difficulty for students while posing questions. And 
between the degree of understanding deepness and the 
degree of difficulty, there is a very strong correlation 
(r=0.98), which shows a trend that the higher is the 
difficulty, the deeper is the understanding. 
Fig. 21 shows the degree of interest in posing questions. 
Almost half of responses are positive ones (“Very 
interesting” and “Interesting”). Between the degree of 
interest and the degree of understanding deepness, there is a 
strong correlation (r=0.82), which shows a trend that the 
more interesting is the question-posing the deeper is the 
understanding. 
Fig. 22 shows the responses to the question, “what was 
 
 
Figure 16.  Flows of learning during experiment 
 
 
Figure 17.  Evaluations of a question by a grader’s 
point of view  
 
TABLE II. CHANGES IN A NUMBER OF GROUP MEMBERS 
1st Day
2nd Day
3
77
40
2
32
53
1
3
15
Number of
 Members
Number of Groups
 
 
Preparing Individual
Question
Answering Question
Evaluating Question
Grading Question
Evaluating Question
Self-Evaluating
1stDay
Preparing Group
Assignment
Submitting
Group Assignment
Inter-Group Evaluating
2ndDay
 
Figure 18.  Distribution of individual score and 
average score within groups 
 
 
Figure 19.  Responses to the question “Did you have a 
deeper understanding through posing questions?” 
 
 
Figure 20.  Responses to the question “Was it difficult to pose 
questions 
 
0%
5%
10%
15%
20%
25%
30%
35%
40%
50 100 150 200 250 300 350 400
Ratio of  People or Group 
Score of Pre-Tests 
Indivisual Score
Average With in
Groups
0
50
100
150
200
Very Deepened
Deepened
Neutral
Not Deepened
Not at All Deepened
Number of Person 
18%
62%
18%
2%
0%
Very difficult
Difficult
Neutral
Facile
Very facile

597
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the 
most 
useful 
reference 
while 
question-posing?”. 
Responses as “Chat within Group”, “Evaluation on 
questions by answerers” and “Evaluation on questions by a 
grader”, of which teamwork take a large part, were highly 
evaluated.  
C. Interaction within Groups 
Contents of the chat were divided up into the following 
5 categories: “Detailed discussion on important points”, 
“Discussion on important points”, “Discussion that often 
went off on a tangent”, “Discussion that were mostly chit-
chatting” and “Pointless discussion”. The categories are 
shown in Table III. We fixed these categories after the 
attentive reading of the contents of the chat. The evaluation 
was executed by 1 person according to the evaluation 
standard while the other checked the result. 
Tables IV to VI are extracted from the chat logs. Table 
IV shows a part of discussions that was evaluated as 
“Detailed discussion on important points”. It shows that 3 
people consulted with one another on how to carry on. 
Table V shows a part of discussions that was evaluated 
as “Discussion on important points”. It shows that only 
some casual conversations were the basis for making a 
decision to carry on. Even after the conversations, there 
were many communications to inform what had been 
decided and agreements on what had been decided. “Going 
off on a tangent” contained chit-chatting in the above 
conversations while “More chit-chatting” had more chit-
chatting than discussions. 
Table VI shows a part of discussions that was evaluated 
as “Pointless”. It shows that the conversations were going 
into a direction of avoiding deep discussions. 
Fig. 23 shows the quality of discussions by each group, 
of which chat logs were evaluated. In both groups of 2 or 3 
people, more than 70% of all the groups fell into either one 
of the 2 categories, “Detailed discussion on important points” 
and “Detailed discussion”, meaning that many groups had 
good interactions.  
Fig. 24 shows the number of statements made per person 
within each group. In the groups of 2 people, an average 
number of statements made per person is 26.2 while in the 
groups of 3 people, the average was 22.3. These results 
suggest that in both groups, relatively active discussions 
were held, and the interactions were sufficiently activated. 
Also, a number of statements was higher in the groups of 2 
people rather than in the groups of 3.  
Fig. 25 shows the comparison between the average 
scores of the pre-tests within each group and the qualities of 
the discussions. When the average scores were divided into 
 
TABLE III. QUALITY OF DISCUSSION 
Detailed Discussion
on Importnant Points
Participants discuss carefully and meticulously to
decide how to carry on.
Discussion
on Important Points
Decision are taken by short discussions.
Assignments are completed rapdely with
modifications.
Often Went Off on a
Tangent
Participants discuss on important points. But they
chitchat often.
Mostly Chit-Chatting
Participants chitchat more often.
Pointless Discussion
Participants always chitchat and don't try to
complete the assignments
 
TABLE IV. EXAMPLES OF “DETAILED DISCUSSION ON 
IMPORTANT POINTS” 
Talker
Contents
D
Where do you want to change?
E
That's right … I guess, first of all, we definitely need to change the
question, and then, what about the well-formed formula?
D
How is it that changes only the third line of the question?
D
Regarding the well-formed formula, it's the final part after ⊃.
E
That's good idea.
F
I agree. How do we want to change that?
 
TABLE V.  EXAPMPLE OF “DISCUSSSION ON IMPORTANT 
POINTS” 
Talker
Contents
G
Whose problem will we use? 
H
How about I's Question? I don't have any particular reason for
it though.
I
I think it's OK if it's corrected.
H
Then, let's make corrections on I's question and use itI. 
G
All right, let's work it out.
 
TABLE VI. EXAMPLE OF “POINTLESS” 
 
Talker
Contents
X
It's difficult to make a new question, isn't it?
Y
Why don't we pick the best question among three of us and
submit it?
X
I think that's great!
Y
OK, let's do so. 
 
         
 
Figure 21.  Responses to the question “Was it interesting to pose 
questions 
 
Figure 22.  Responses to the question “What was the 
most useful reference while question-posing?” 
 
6%
40%
38%
8%
8%
Very interesting
Interesting
Neutral
Little interesting
Uninteresting
0
50
100
150
Evaluation by Answer
Evaluation by Grader
Evaluation by oneself
Chat in a Group
Nothing
Others
Number of Person 

598
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the 3 different levels, “100 to 150”, “150 to 200” and “200-
250”, most of those groups that falls into the highest level, 
“200-250”, also falls into “Detailed discussion on important 
points”. 
D. Leader Function on Chat  
From the chat logs, learners who took a leader role in the 
chat were identified, and the relationship between the 
learners’ rank for the pre-tests within their group and the 
qualities of their discussions was evaluated.  
Fig. 26 shows a result of the groups of 2 people while 
Fig. 27 shows a result of the groups of 3 people. Based on 
the results, in the groups of 2 people, when those who 
played a leader role have less academic ability than those 
who did not, their discussion tends to be well. In the group 
of 3 people, on the other hand, when those who had the best 
grade within their group played a leader role, their 
discussion tends to be well.  
E. Evaluation of Group Assignments 
In this experiment, since the assignments that are 
submitted individually and by groups are the same, these 3 
patterns can be possible as re-submitted assignments: “Re-
submitted 
after 
improving 
individual 
assignment”, 
“Resubmitted the same individual assignments as is” and 
“Submitted completely new”. Those assignments that were 
made completely new include the ones that combined 
several different assignments. Fig. 28 shows a distribution 
of the ways each group made their assignment. In both 
groups of 2 and 3 people, the results indicate most groups 
“Re-submitted after improving individual assignment”.  
“Re-submitted the same individual assignment as is” does 
not serve the meaning of collaborative learning, and it also 
means the collaborative script did not work well. Fig. 29 
shows the quality of discussion being held by groups who 
Figure 23.   Quality of discussions and number of group 
 
Figure 24.  Number of statements made per person 
person within a group 
 
 
Figure 25.  Pre-tests and quality of discussions 
 
0
20
40
Pointless Discussion
Discussion That Were
Mostly Chit-Chatting
Discussion That Often
Went Off on a Tangent
Discussion
on Important Points
Detailed Discussion
on Importnant Points
Number of Group 
Quality of Discussion 
Group of 2
People
Group of 3
People
0
2
4
6
8
10
12
14
16
18
0-10
10-20
20-30
30-40
40-50
50-60
60-70
Number Of Group 
Number Of Statements  Made Per Person 
Group of 3 People
Group of 2 People
0%
20%
40%
60%
80%
100%
Ratio of Number of Group 
Average Score of Pre-Test With in Groups 
Detailed Discussion
on Importnant Points
Discussion
on Important Points
Discussion That Often
Went Off on a Tangent
Discussion That Were
Mostly Chit-Chatting
Pointless Discussion
 
Figure 26.  Leaders’ rank in the group of 2 people 
 
Figure 27.  Leaders’ rank in the groups of 3 people 
 
 
Figure 28.  How they submitted group project 
 
0
5
10
15
Pointless Discussion
Discussion That Were
Mostly Chit-Chatting
Discussion That Often
Went Off on a Tangent
Discussion
on Important Points
Detailed Discussion
on Importnant Points
Number of Group 
Quality of Discussion 
Rank 1st
Rank 2nd
0
2
4
6
8
Pointless Discussion
Discussion That Were
Mostly Chit-Chatting
Discussion That Often
Went Off on a Tangent
Discussion
on Important Points
Detailed Discussion
on Importnant Points
Number of Group 
Quality of Discussion 
Rank 1st
Rank 2nd + 3rd
0
10
20
30
40
50
No Change
Improving
Completely New
Number of Group 
Group of 3 People
Group of 2 People

599
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
“Re-submitted the same individual assignment as is”. Many 
of these groups had a discussion that was “Mostly chit-
chatting” and “Pointless”, so some type of scaffolding is 
necessary for them.  
Table VII shows a standard for the group assignment, 
“Good”, “Average” and “Bad”, which are used for grading. 
Table VIII shows a comparison between the evaluation 
result and the qualities of the discussions. The evaluation 
was done by 1 teaching staff who carried out the experiment. 
There were 2 different evaluators for this evaluator and the 
one who evaluated the qualities of the discussions. The 
result shows that the better the discussion quality is, the 
higher the assignment evaluation is.  
Also, Table IX shows a comparison between evaluation 
results and how discussions were carried on. “Made new” 
had a higher ratio of “Good” whereas “No changes” did not 
have any “Good”. As Fig. 18 suggests, “No changes” tends 
to result in “More chit-chatting” or “Pointless”. These points 
indicate that increasing a quality of discussion can lead to 
“Improvement” and “Make from scratch” with assignments 
highly scored.  
VIII. SUMMARY AND FUTURE ISSUES 
This section recapitulates the findings of this study and 
suggests briefly some future issues. 
A. Summary 
Supposing a situation where a face-to-face learning is 
impossible, we developed a CSCL system which can form 
many small groups for the online collaborative learning, and 
then the question-posing collaborative script based on the 
reciprocal teaching method was implemented in the system.  
Then, in the environment with 300 people, the 
automated group formation and the collaborative script were 
proved executable and effective.  
 
(1) The learners felt that the mutual work using the 
collaborative script was effective. In fact, discussions 
through the chat were activated while keeping their quality 
high.  
(2) Many groups improved their submitted individual 
assignment through discussions online. Those groups that 
held high quality discussions scored high on their group 
assignment.  
(3) It is suggested that the activation of discussions 
depends on an academic ability of the learners who play a 
leader role within their group. However, depending on a 
group structure, higher (academic ability) does not 
necessarily mean good.  
First, according to (1) and (2), the results showed that 
the design of the collaborative learning in this study was 
mostly appropriate.  
Also, according to (3), it is important to identify the 
most suitable learners to play a leader role and assign them 
in each group. However, the characteristics of learners who 
should play a leader role cannot be selected based on their 
academic ability, such as scores of pre-tests. To resolve such 
issue, in the future, it is important to develop a method to 
identify learners with an ability to take a leader role from a 
pre-survey and activity logs.  
On the other hand, when the collaborative script is 
executed in a class, it is important to plan for exceptional 
cases, such as students’ no attendance. Collaborative script 
does not allow a progress of tasks to be flexible, so the 
script often gets non-executable when the learning 
environment is off from an original plan. In this experiment, 
there are learners who attended on the 1st day and missed 
the 2nd day, or learners who missed the 1st day and 
attended on the 2nd day, so there were many groups that 
could not make progress their learning as planned. Also, 
there were some time limitations, such as a deadline for 
submitting assignments, so there were groups that had to 
 
TABLE VII.  EVALUATION STANDARD FOR PROJECT 
Good 
Complicated Question than the exercise shown in 
advance and an answer is right. 
Average 
Similar to the exercise shown in advance or 
equivalent in complexity, and a Answer is right 
Bad 
Similar to the exercise shown in advance or below 
equivalent in complexity, and an Answer is mistake 
 
TABLE VIII.  QUALITY OF DISCUSSION AND EVALUATION OF 
PROJECT BEING SUBMITTED 
Good
Avg
Bad
Detailed Discussion
on Importnant Points
13
18
9
Discussion
on Important Points
3
18
6
Often Went Off on a Tangent
2
5
7
Mostly Chit-Chatting
3
2
Pointless Discussion
2
4
Evaluation
 
 
TABLE IX.  HOW DISCUSSIONS WERE MOVED FORWARD AND 
PROJECT EVALUATION RESULTS 
Good Average
Bad
Completely New
2
3
1
Improving
16
38
22
No Change
5
5
Evaluation
 
 
 
Figure 29.  Quality of discussion held by groups 
without making changes 
 
0
5
10
Pointless Discussion
Discussion That Were
Mostly Chit-Chatting
Discussion That Often
Went Off on a Tangent
Discussion
on Important Points
Detailed Discussion
on Importnant Points
Number of Group 
Quality of Discussion 

600
International Journal on Advances in Software, vol 7 no 3 & 4, year 2014, http://www.iariajournals.org/software/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
submit without having sufficient discussions. Based on the 
above, executing a collaborative script needs some degree of 
flexibility depending on a learning environment and 
conditions of learners.  
 
B. Future issues 
In this study, the uniformed collaborative script was 
executed, but it is necessary to develop and practice 
collaborative script that is adaptable in groups in a way that 
the script changes flexibly depending on a group’s 
characteristics and progress. In addition, future experiments 
have to examine what kind of difference manifests in the 
collaborative activities, depending on different communities 
or different learning agenda 
Also, for the automated group formation, it is necessary 
to be capable of forming various groups based on learners’ 
detailed characteristics being specified and to clarify 
characteristics of groups depending on learners included in 
the groups. 
ACKNOWLEDGMENT 
 This work was supported by JSPS KAKENHI Grant 
Number 23501117. 
 
 
 
 
REFERENCES 
 
[1] T. Inaba and K. Ando, “Development and assessment of 
CSCL system for large classrooms using collaborative script,” 
in Proceedings of eLmL 2014, the Sixth International 
Conference on Mobile, Hybrid and On-line Learning, pp. 14-
21, Spain, 23-27 March 2014. 
[2] L. S. Vigotsky, Mind in society: The development of higher 
psychological processes, Cambridge: Havard University Press, 
1978. 
[3] J. Lave and E. Wenger, Situated learning: Legitimate 
peripheral participation, Cambridge: Cambridge University 
Press, 1991. 
[4] H. Miyake and H. Shirouzu, Learning sciences and 
technology, Tokyo: The Society for the Promotion of the 
Open University of Japan, 2003. 
[5] A. King, “Scipting collaborative learning processes: A 
collaborative perspective,” in Scripting computer-supported 
collaborative learning, F. Fisher, I. Kollar, H. Mandl, and J. M. 
Haake, Eds. Springer, pp. 13-37, 2007. 
[6] A. Weinberger, “Scripts for computer-supported collaborative 
learning: Effects of social and epistemic cooperation scripts 
on 
collaborative 
construction,” 
Doctoral 
Dissertation, 
Ludwig-Maximilians-University, 2003. 
[7] P. Bell, “Promoting students’ argument construciton and 
collaborative 
debate 
in 
the 
classroom,” 
in 
Internet 
environments for science education, M. C. Linn, E. A. Davis, 
and P.Bell, Eds. NJ: Erlbaum, pp. 114-144, 2004. 
[8] R. C. Schank and R. P. Abelson, Scripts, plans, goals and 
understandings, Hillsdale, NJ: Erlbaum, 1977. 
[9] D. F. Dansereau, “Cooperating learning strategies,” in 
Learning and study strategies, E. T. Goetz and P. A. 
Alexander, Eds. Academic Press INC., pp. 103-120, 1989. 
[10] A. O’Donell and D. F. Dansereau, “Scripted cooperation in 
student dyads: A method for analyzing and enhancing 
academic learning and performance,” In Interaction in 
Cooperative groups: The theoretical anatomy of group 
learning, R. Herts-Lazarowitz, and N. Miller, Eds. New York: 
Cambidge University Press, pp. 120-141, 1992.  
[11] I. Kollar, F. Fischer, and F. W. Hesse, “Collaboration scripts 
–A conceptual analysis,” Educational Psychology Review, vol. 
18, no. 2, pp. 159-185, 2006. 
[12] L. Kobbe, A. Weinberger, P. Dillenbourg, A. Harrer, R. 
Hämäläinen and F. Fischer, “Specifying computer-supported 
collaboration scripts,” International Journal of Computer-
Supported Collaborative Learning, vol. 2, no. 2-3, pp. 211-
224, 2007 
[13] P. Dillenbourg and P. Jerman, “Designing interactive scripts,” 
in Scripting computer-supported collaborative learning, F. 
Fisher, I. Kollar, H. Mandl, and J. M. Haake, Eds. Springer, 
pp. 275-301, 2007. 
[14] P. Dillenbourg, “Over-scripting CSCL: The risks of blending 
collaborative learning with instructional design,” In Three 
Worlds of CSCL, P. A. Kirschner, Eds. Heerlen: Open 
Univeristeit Nederland, pp. 61-91, 2002. 
[15] N. Rummel and H. Spada, “Learning to collaborate: An 
instructional approach to promoting problem-solving in 
computer-mediated settings,” Journal of the Learning 
Sciences vol. 14(2), 2005, pp. 201-241. 
[16] A. Weinberger, Cscl scripts: Effects of social and epistemic 
scripts 
on 
computer-supported 
collaborative 
learning, 
Saarbrücken: VDM, 2008. 
[17] F. Fischer, I. Kollar, K. Stegmann, and C. Wecker, “Toward a 
script theory of guidance in computer-supported collaborative 
learning,” Educational Psychologist, vol. 48, no. 1, pp. 56-66, 
2013. 
[18] S. Takahashi, K. Ando, S. Matsunaga and T. Inaba: “Utilizing 
collaborative script that is adoptive to learners’ characteristics 
to build and evaluate CSCL system,” Proceedings of the 74th 
National Convention of IPSJ 4, pp. 815-816, 2012. 
[19] A. S. Palinscar and A. L. Brown, “Reciprocal teaching of 
coprehension-fostering 
and 
comprehension-monitoring 
activities,” Congnition and instruction vol.1, no. 2, pp. 117-
175, 1984. 
[20] M. Baker and K. Lund, “Promoting reflective interactions in a 
CSCL environment,” Journal of Computer Assisted Learning, 
vol.13, pp. 175–193, 1997. 
[21] H. R. Pfister and M. Mühlpfordt, “Supporting discourse in a 
synchronous learning environment: The learning protocol 
approach,” in Proceedings of the conference on computer 
supported collaborative learning (CSCL) 2002 Conference, 
Laurence Erlbaum Associates, pp. 581–589, 2002. 
 
 
 

