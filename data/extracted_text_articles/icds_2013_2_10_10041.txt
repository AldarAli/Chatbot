Parametric Analysis of Speech Signals Based on Estimation of Joint Source-Filter
Model Using Evolutionary Computation
M´ario Uliani Neto, Jos´e Eduardo de C. Silva, Diego A. Silva,
Leandro de C. T. Gomes, Thiago de A. M. Campolina
CPqD Foundation
Campinas, SP, Brazil
Email: {uliani, jcsilva, diegoa, tgomes, thiagomc}@cpqd.com.br
Hani C. Yehia∗, Maur´ılio N. Vieira∗, Jo˜ao P. H. Sans˜ao†
∗DEE – UFMG
† DETEM – UFSJ
Email: {hani, maurilionunesv}@cpdee.ufmg.br
joao@ufsj.edu.br
Abstract—This paper presents an analysis-by-synthesis algo-
rithm based on joint estimation of speech parameters. The main
advantage of the proposed algorithm is that both vocal tract
and glottal source parameters are estimated simultaneously
in an automatic way. The use of evolutionary algorithms is
proposed to optimize these parameters. The results show that
this strategy seems to be feasible for some applications such
as compression of speech signals and voice conversion.
Keywords-Analysis-by-synthesis;
evolutionary
algorithm;
speech signal processing; source-ﬁlter model.
I. INTRODUCTION
One of the approaches used to model the process of
speech production is the so-called source-ﬁlter model [2].
In this model, the human vocal tract is separated into two
distinct components: a linear ﬁlter, whose transfer function
is related to the resonance frequencies of the supra-glottal
cavities in the human vocal tract (mouth, throat, nasal tract),
and a generating source that excites the ﬁlter with an input
signal.
The type of signal emitted by the source depends on
the characteristics of the speech signal to be analyzed. In
voiced speech segments, whose typical example is vowels,
the source signal is almost periodic, due to the vocal fold
vibration. In unvoiced segments, such as the fricative con-
sonants /s/ and /f/, the signal is treated as a white Gaussian
noise. For hybrid segments, the source signal is seen as a
sum of the two components described above.
On the basis of the source-ﬁlter model paradigm, speech
signals are analyzed through the estimation of parameters for
the excitation source and the vocal tract ﬁlter, by minimizing
an error measure between the original signal and the one
produced when the source signal is applied to the ﬁlter.
In this study, the representation of the voiced portions of
speech signals is performed by means of a simpliﬁed source-
ﬁlter model, proposing the use of evolutionary algorithms
to jointly estimate the parameters of the source and the
vocal tract ﬁlter [12]. The model is based on physical
characteristics of the speaker: the vocal tract model is able
to identify the formants of the speech signal, while the
excitation model makes use of the glottal waveform, as well
as of the aspiration and frication noises. To best ﬁt the
latter, the use of the Transient Modeling Synthesis (TMS)
algorithm is proposed.
The paper is structured as follows. Section II presents a
state of the art. Section III introduces the proposed analysis-
by-synthesis algorithm. In Section IV, experimental results
are presented to illustrate the proposed method. Finally,
Section V presents conclusions and perspectives for future
study.
II. STATE OF THE ART IN JOINT SOURCE-FILTER
ESTIMATION
Among the approaches used in joint source-ﬁlter estima-
tion, the most common is based on the use of models for
estimating the glottal waveform and the vocal tract, deﬁning
an error function and describing techniques for optimizing
it. Next, some works addressing these points are presented.
In [3], the vocal tract is modeled by a ﬁlter with poles
and zeros and the glottal waveform is obtained by the LF
model [2]. All the parameters are estimated minimizing the
least square error (LSE).
In
[5],
the
glottal
model
is
approximated
by
the
Rosenberg-Klatt model (RK) [1], and the vocal tract is mod-
eled by a Kalman ﬁlter. The Simulated Anealing algorithm
was used to ﬁnd the best set of parameters.
Lu and Smith [6] proposed a convex optimization method
for estimating the parameters of the source and the vocal
tract jointly. They used the RK model to estimate the
glottal signal, and an all pole ﬁlter to vocal tract. The error
criterion is the difference between estimated and original
waveforms. Del Pozo and Young [10] use a similar method,
but suggested certain improvements int the the glottal source
model.
The method proposed in this paper presents some advan-
tages, and the main ones are:
• The proposed vocal tract model automatically identify
the resonance frequencies of the vocal tract, unlike the
techniques presented. These frequencies carry informa-
tion of the physical structure of the speaker’s vocal
tract. This information is important in voice morphing
applications.
• In some studies (i. e., [6], [10]), the parameter that
indicates the time of the glottal closure, GCI (glottal
closure instant), is estimated a priori. The proposed
32
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-249-3
ICDS 2013 : The Seventh International Conference on Digital Society

joint estimation method, based on evolutionary algo-
rithms, enables the optimization of GCI together with
the source and vocal tract parameters.
• The estimation method proposed in this paper, based
on evolutionary algorithms, incorporates the spectral
tilt coefﬁcient in the joint optimization. Thus, this
parameter can change over the time. In other papers,
this parameter is usually a constant.
III. ANALYSIS BY SYNTHESIS BASED ON JOINT
SOURCE-FILTER ESTIMATION
The speech production model proposed in this article is
illustrated on Figure 1. The voiced and unvoiced portions
of the speech signal are modeled in different ways. For
the voiced segments, the derivative of the glottal waveform
is modeled by means of the Liljencrants-Fant (LF) model
[2]. The aspiration and frication noises are modeled using
TMS and a white Gaussian noise with modulated amplitude.
The vocal tract is modeled as a ﬁlter containing only poles,
composed of two structures: one based on formant frequency
and bandwidth, and an additional one representing the
information not covered by the formant ﬁlter. For unvoiced
frames, the turbulence noise is modeled as a white Gaussian
noise, while the vocal tract is modeled as a ﬁlter containing
only poles. The details of the proposed system are presented
in the following subsections.
A. Joint Source-Filter Deconvolution Based on Evolutionary
Algorithms
The method developed to estimate the parameters of the
glottal source and vocal tract are based on a paradigm known
as source-ﬁlter deconvolution. The proposed deconvolution
algorithm is based on evolutionary computation [9]. The
ﬁlter parameters of the vocal tract (modeled by a set of
formants in cascade), the parameters of the excitation source
(in this step, for simplicity, the Rosenberg-Klatt (RK) model
is used to model the source) and the GCI are jointly
estimated.
1) Glottal Source – RK Model: The RK model, parame-
terized in the time domain, models one phonatory period
of the derivative of the glottal waveform, accounting for
the glottal opening and closure instants. The RK model is
described by 4 parameters: a, T0 (the phonatory period), nc
Excitation Source
Glottal Excitation
LF Model
+
+
Vocal Tract Filter
Formant
   Filter
All-pole
   Filter
Voiced
 Signal
Derivative Glottal
Wave
Complementary Filter
Turbulence Noise
  White
Gaussian
   Noise
Vocal Tract Filter
All-Pole
   Filter
Unvoiced
   Signal
(a)
(b)
Figure 1.
Source-ﬁlter model. a) Model for hybrid and voiced signals. b)
Model for unvoiced signals.
Table I
SOURCE AND GCI PARAMETERS.
Parameter
Restriction
Enconding
nc
0.4 × T0 < nc ≤ 0.7 × T0
Integer
a
a ≤ 0
Real
µ
0 < µ < 0.99
Real
GCI
0 ≤ GCI ≤ T0
Integer
Table II
RESTRICTIONS ON FREQUENCY AND BANDWIDTH FOR THE CASCADE
FORMANT FILTER.
Formants
Freq (Hz)
BW (Hz)
Min
Max
Min
Max
1
150
900
40
500
2
500
2,500
40
500
3
1,300
3,500
40
500
4
2,500
4,500
100
500
5
3,500
5,500
150
700
(duration of the closed phase) and µ (control the spectral
tilt).
2) Vocal Tract Model – Formant Filter: The vocal tract
ﬁlter consists of a set of resonators in cascade [1]. Each
resonator is speciﬁed by two parameters: the resonance
(formant) frequency F and resonance bandwidth BW.
3) Optimization Based on Evolutionary Algorithms: The
method for the joint estimation of the glottal source and
vocal tract ﬁlter parameters is based on evolutionary com-
putation. To reduce the number of parameters to be opti-
mized and limit their search space, reducing computational
complexity, simpliﬁed models are used for the excitation
source (Section III-A1) and the vocal tract ﬁlter (Section
III-A2). A set of restrictions is also assumed, so that the
models represent a valid physical structure; this provides
an additional gain in computational cost and decreases the
amount of local minima in the ﬁtness surface. The RK model
is used in this step with the restrictions shown in Table I.
The vocal tract is modeled through a ﬁlter with the
restrictions listed in Table II [1].
An evolution strategy (µ + λ) was used to simultaneously
optimize model parameters. Both the source parameters
(nc, a, µ, GCI) and the ﬁlter (Fi, BWi) were part of the
chromosome, so that the models could be jointly evaluated.
The recombination pairs were selected based on a uniform
probability. Thus, the probability of choosing an individual
was the same for all the population. A discrete recombi-
nation operator, which generates the child genetic material
selecting the genes of parents with equal probability, was
used.
The chosen mutation operator acts on each gene of the
entire population. The mutation consists of applying a gaus-
sian mutation in all the parameters of the entire population
of chromosomes. Each gene is mutated according to its
variance, which is stored in the chromosome. After all the
chromosomes of the population mutates, it is checked if
they are still feasible. If one or more chromosomes become
unfeasible, they have the value of its mutated gene restored
33
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-249-3
ICDS 2013 : The Seventh International Conference on Digital Society

to the value used before the mutation.
The purpose of the evolutionary algorithm is to minimize
the error between the original and the estimated signal. The
equation for calculating the ﬁtness of a solution is presented
in equation 1. This function was constructed to obtain higher
ﬁtness values for solutions that present lower squared error
between their samples and the original samples.
fitness =
1
1 +
s
nP
i=1
(s(i) − ˆs(i))2
,
(1)
where s(i) represents the original speech frame and ˆs(i) the
estimated speech frame.
More details of this implementation were presented in
[11].
B. Adjustment of the Vocal Tract Using Adaptive Filters
To improve the vocal tract model, we propose the use
of an adaptive ﬁlter that can estimate the parameters of
an additional ﬁlter, which models the characteristics of the
vocal tract that are not present in the formant ﬁlter. The
adaptive ﬁlter is based on the Wiener ﬁlter, optimized with
the Recursive Least Squares (RLS) algorithm. Figure 2
details this ﬁltering model.
This method is based on the comparison between the
output go(n) of the Wiener ﬁlter and the estimate of the
glottal source derivative ˆgRK(n), obtained in the process
of joint estimation. When the Wiener ﬁlter coefﬁcients are
properly adjusted, the error signal e(n) is minimized, which
implies a ﬁlter output signal go(n) as close as possible to
the signal ˆgRK(n). The signal go(n) is the derivative of the
glottal waveform, obtained through the deconvolution of the
original speech frame with the vocal tract ﬁlter (composed
of the formant ﬁlter and the additional ﬁlter).
Due to inaccuracies caused by the simpliﬁcation of the
formant model used for the vocal tract, the joint estimation
process does not produce a good estimate of the interval
during which the glottis remains closed (parameter nc).
To adjust nc, we propose a linear search process during
ﬁlter adaptation. The adaptive ﬁltering algorithm is executed
for values of nc between 40% and 70% of the phonatory
period [4], with step of 10%. The optimal solution is the
one that leads to the lowest mean square error between
the original frame and the temporal waveform of the signal
synthesized from ˆgRK(n) and the vocal tract ﬁlter.
Wiener Filter
+
 Excitation source
obtained by inverse 
     filtering with
     formant filter
e(n)
Adjustment
 coefficient
g   (n)
^
Derivative of the glottal 
  waveform estimated 
       with RK model
g(n)
g (n)
o
Optimal excitation
          source
Adjust the complementary
        vocal tract filter
+
-
RK
Figure 2.
Adaptive ﬁlter used to adjust the additional ﬁlter in the vocal
tract model.
C. Adjustment of the Glottal Source - LF Model
The LF model [2] is able to describe the glottal waveform
derivative with greater precision than the RK model.
The waveform produced by the LF model can be deter-
mined from the four temporal parameters {Tp, Te, Ta, Tc}
and the magnitude of {Ee}.
The ﬁt of the LF model is performed in two stages.
Initially, the LF model parameters (Tp, Te, Ta, Tc, Ee) are
estimated through direct methods [8]. This technique mea-
sures the parameters directly from the waveform obtained
by means of the RK model.
The LF model parameters are then reﬁned through an
evolution strategy. The estimated Tc and Te are considered
reliable [8] and remain unchanged in the optimization pro-
cess. The parameter Ta is conﬁned between 0 and Tc − Te;
Tp can vary within ±20% of its initial estimate; and Ee can
vary within ±10% of its initial estimate. The ﬁtness function
is based on the quadratic error between the derivative of the
glottal waveform of the original frame and the waveform of
the model adjusted through the LF model.
D. Modeling of the Residual Noise
The modeling techniques for the glottal source described
in the previous sections do not account for the aspiration
and frication noises. Due to this limitation, the difference
between the source signal ˆgLF and the signal obtained
through the inverse ﬁltering of the original frame produces a
residual noise. One way to interpret this noise is to consider
it as a white Gaussian signal modulated in amplitude [10];
however, this approach does not always produce satisfactory
results. In order to handle the residual noise, the use of the
TMS algorithm [7] is proposed.
This technique exploits the time-frequency duality of
sinusoids and impulses, and, as shown in [7], can be used to
separate segments showing impulsive characteristics in the
time domain. This process is illustrated in Figure III-D.
E. Modeling the Final Residue
The ﬁnal residue model used in this article is based on
the technique proposed in [10]. The method consists in
treating the residue as a Gaussian noise synchronized with
the phonatory period and modulated in amplitude by the LF
model.
The ﬁnal residue is parameterized as follows: ﬁrst, a Gaus-
sian noise with zero mean and unit variance is modulated
by the glottal waveform obtained from the LF model. Then,
the energy of this modulated noise is set to be equal to the
energy of the ﬁnal residue.
DCT
Sinusoidal
Analysis
Sinusoidal
Synthesis
IDCT
Transients
parameters
Final
Residue
(Noise)
Residue
(Noise + Transient)
Figure 3.
Block diagram of the TMS operation.
34
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-249-3
ICDS 2013 : The Seventh International Conference on Digital Society

IV. RESULTS AND ANALYSIS
For the evaluation of the proposed model, we present
results for two signals: the ﬁrst is a synthesized signal
sampled at 8 kHz, generated by an LF source with a
frequency of 120 Hz and a tract with four formants located at
500 Hz, 1.500 Hz, 2.500 Hz, and 3.500 Hz, with a bandwidth
of 100 Hz; the second one is a frame of a stressed vowel
/a/, extracted from a studio-quality recording of an utterance
produced by a male speaker, encoded in linear PCM at a
sampling rate of 8 kHz with 16 bits per sample.
For optimization, we set an evolution strategy to iterate
through 100 generations, assuming a total of 200 individuals
(µ) per generation. In each generation, 400 children (λ) were
created, with a crossover rate of 1 and a mutation probability
of 1 (these values were empirically adjusted).
Figure 4 shows the results for the synthesized signal. As
can be seen in 4(a), the estimated tract is very close to the
original one. There are small differences that are especially
concentrated in high-order formants, which may be justiﬁed
by the fact that the ﬁtness of the evolutionary algorithm
(section III-C) is based only on the square error of the glottal
signal. Most of the glottal pulse energy is concentrated at
low frequencies (f < 2.000 Hz); thus, an error in high
order formants does not signiﬁcantly affect the glottal signal,
which in turn has no expressive effect on the ﬁtness. Figures
4(b) and 4(c) show that the estimate of the derivative of
the glottal waveform and the synthesized signal are close
to their references. The differences may be explained by
imprecisions in the optimization of the tract that reﬂect on
the glottal signal. Nevertheless, the synthesized signal is
close to the original one, as shown in Figure 4(c).
Figure 5 represents the optimization of a signal with
source and tract identical to the previous ones (ﬁgure 4),
except for the addition of aspiration noise to the glottal
source. The aspiration noise was generated as a Gaussian
noise of zero mean and unit variance, modulated by the
glottal signal. Figure 5(a) displays the original time signal
and the signal recovered by the algorithm (including the use
of the TMS algorithm). It can be observed that, though the
signals differ, they present similar contours.
Figure 5(b) shows the autocorrelation function of the
noise in the signal (calculated as the difference between
the LF model and the signal obtained by inverse ﬁltering
the original signal) with and without TMS. Unlike the
autocorrelation function of the noise produced without TMS,
the autocorrelation of the noise generated with TMS remains
within the range of 95% (deﬁned by the horizontal dotted
lines present in the ﬁgure) for all delays greater than two
samples, which means that the generated noise is whiter
when TMS is used. It is important to state that the evaluation
of the impact of TMS parameters on the presented results
is not the focus of this study.
Figure 6 presents a preliminary result of optimization for
a frame of a real signal of the vowel /a/. The waveform of
the synthesized signal presents, notably at the beginning and
end of the ﬁgure, large deviations from the original signal.
0
500
1000
1500
2000
2500
3000
3500
4000
−5
0
5
10
15
20
Frequency (Hz)
 
 
Original tract
Estimated tract
(a)
0
1
2
3
4
5
6
7
8
9
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time (ms)
 
 
Signal obtained by inverse filtering
Fant model
(b)
0
1
2
3
4
5
6
7
8
9
−1.5
−1
−0.5
0
0.5
1
Time (ms)
 
 
Original signal
Synthesized signal
(c)
Figure 4.
Optimization of a synthesized signal. a) Vocal tracts. b) Glottal
signals. c) Temporal waveforms.
This probably happened because of limitations in the models
used in this work. The precise identiﬁcation of the reasons
for this mismatch is a subject of future research.
V. CONCLUSIONS
This article presented a technique for the joint optimiza-
tion of the sound source and vocal tract ﬁlter parameters
for the production of voiced portions of speech signals. The
LF model was employed to represent the source, while a
strategy based on the TMS algorithm was used for modeling
noise components. The ﬁlter was obtained by cascading four
formants, deﬁned by their bandwidths and center frequen-
cies. The optimization was performed through an evolution
strategy.
Evolutionary computation has the advantage of allowing
the joint optimization of source and ﬁlter parameters, even
if the ﬁtness function implies a multimodal problem. In all
simulations, the algorithms found solutions that were feasi-
ble and satisfying. The main disadvantage of this approach
is related to computational cost for real time applications,
requiring a signiﬁcant amount of time for the convergence
of the algorithms.
35
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-249-3
ICDS 2013 : The Seventh International Conference on Digital Society

0
1
2
3
4
5
6
7
8
9
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
Time (ms)
 
 
Original signal
Synthesized signal 
(a)
0
10
20
30
40
50
60
70
−1
−0.5
0
0.5
1
Delay (samples)
 
 
Without TMS algorithm
With TMS algorithm
(b)
Figure 5. a) Original signal and recovered signal using the TMS algorithm.
b) Autocorrelation function of the noise signal.
0
1
2
3
4
5
6
7
8
9
10
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
Time (ms)
 
 
Original signal
Synthesized signal
Figure 6.
Temporal waveforms of the real and the synthesized signals
(one frame of the vowel /a/).
One advantage of the optimization method presented in
this article is its ability to efﬁciently determine the optimal
spectral decay coefﬁcient, as well as the instant of glottal
closure; in other studies, as presented in [10], it is common
to use speciﬁc algorithms for the obtainment of these param-
eters. Furthermore, the use of the TMS algorithm enables the
whitening of the residual noise obtained as the difference
between the derivative of the original glottal waveform and
the one produced by the LF model, leading to a better
adjustment of the noise.
The approach presented in this article for modeling the
source and the ﬁlter allows the physical interpretation of
the parameters obtained from the optimization, since the
LF model expresses the derivative of the glottal pulse and
the cascade formant ﬁlter represents the spectral envelope
of speech frames. This technique seems to be feasible for
applications such as compression of speech signals, voice
conversion (as the parameters obtained from the optimization
can be modiﬁed), and smoothing of frame boundaries prior
to concatenation (for concatenative speech synthesis).
In the next steps of this research, the feasibility of
applying the proposed technique in voice conversion systems
will be analyzed.
REFERENCES
[1] H. Klatt, Software for a cascade/parallel formant synthesizer.
Journal of the Acoustical Society of America, volume 67, issue
3, pp. 971-995, March 1980.
[2] G. Fant, J. Liljencrants, and Q. Lin, A four-parameter model of
glottal ﬂow. STL-QPSR, volume 26, issue 4, pp. 1-13, 1985.
[3] A. K. Krishnamurthy, Glottal source estimation using a sum-of-
exponentials model. IEEE Transactions on Signal Processing,
volume 40, issue 3, pp. 682-686, Mar 1992.
[4] M. N. Vieira, Automated measures of dysphonias and the
phonatory effects of asymmetries in the posterior larynx. Ph.D.
dissertation, University of Edinburgh, Scotland, 1997.
[5] W. Ding, N. Campbell, N. Higuchi, and H. Kasuya, Fast
and robust joint estimation of vocal tract and voice source
parameters. In IEEE International Conference on Acoustics,
Speech, and Signal Processing, ICASSP-97, pp. 1291-1294,
Munich , Germany, Apr 1997.
[6] H. L. Lu and J. O. Smith, Joint estimation of vocal tract ﬁlter
and glottal source waveform via convex optimization. In IEEE
Workshop on Applications of Signal Processing to Audio and
Acoustics, pp. 79-82, New Paltz, NY, 1999.
[7] T. S. Verma and T. H. Y. Meng, Extending spectral modeling
synthesis with transient modeling synthesis. Computer Music
Journal, volume 24, issue 2, MIT Press, pp. 47-59, 2000.
[8] J. Perez and A. Bonafonte, Automatic voice-source parameter-
ization of natural speech. In Proceedings of Interspeech, pp.
1065-1068, Lisbon, Portugal, Sep 2005.
[9] L. N. de Castro, Fundamentals of Natural Computing: Basic
Concepts, Algorithms and Applications. Florida, USA. Chap-
man & Hall/CRC, 2006.
[10] A. Del Pozo and S. J. Young, The linear transformation of
LF glottal waveforms for voice conversion. In Proceedings
Interspeech, pp. 1457-1460, Brisbane, Australia, Sep 2008.
[11] M. Uliani Neto, B. Costa, F. Sim˜oes, R. Violato, and M. Leal
Estimac¸˜ao conjunta do processo de produc¸˜ao de sinais de fala
utilizando computac¸˜ao evolutiva. In IV Congresso Tecnol´ogico
InfoBrasil, Fortaleza, Brazil, 2011.
[12] M. Uliani Neto, Jos´e E. de C. Silva, Leandro de C. T. Gomes,
Diego A. Silva, Thiago de A. M. Campolina, Jo˜ao P. H. Sans˜ao,
Hani C. Yehia and Maur´ılio N. Vieira, An´alise Param´etrica de
Sinais de Voz Baseada em Estimac¸˜ao Conjunta do Modelo
Fonte-Filtro. XXX Simp´osio Brasileiro de Telecomunicac¸˜oes -
SBrT, Bras´ılia, Brazil, 2012.
36
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-249-3
ICDS 2013 : The Seventh International Conference on Digital Society

