Investigating the Relevance of Sensor Selection:
Recognition of ADLs Based on Feet Movement and Posture Information
Rafael de Pinho André, Pedro Henrique Diniz, Hugo Fuks
Department of Informatics
Pontiﬁcal Catholic University of Rio de Janeiro
Rio de Janeiro, RJ, Brazil +55 21 3527-1510
Email: randre,pfonseca,hugo@inf.puc-rio.br
Abstract—In this work, we present an analysis of the relevance
of different sensor types for the recognition of activities of daily
living based on foot movement and position. By conducting a
comprehensive experiment with 12 diverse volunteers that re-
sulted in about 1 million data samples, and employing a machine
learning HAR (Human Activity Recognition) classiﬁer developed
for a 9-activity classes model, we were able to assess the impact
of sensor selection on the activity recognition accuracy. Aiming
at a replicable research, we provide full hardware information,
system source code and a public domain dataset.
Keywords–Clothes-based sensors; IoT (Internet of Things) de-
vices; Mobile sensing applications.
I.
INTRODUCTION
Human Activity Recognition (HAR) is an active and fast-
growing ﬁeld of research that has seen an intense growth
during the last ﬁve years, drawing attention of researchers from
ﬁelds, such as mobile healthcare, sports performance and mass
context inference. From the rehabilitation of stroke patients [1]
to energy expenditure estimation of Activities of Daily Living
(ADL) [2] [3], studies based on feet movement and posture
show promising results and interesting applications. Current
research works can be grouped into two main approaches for
collecting user’s feet movement and posture data: (i) image
processing and (ii) clothes-based sensors. In this work, we
address one of the current challenges of the clothes-based
sensors approach: understanding which types of sensors are
relevant for the recognition of ADLs. Since clothes-based
sensors HAR is a comprehensive ﬁled of research, we focus
on feet movement and posture information.
Firstly, we performed a literature review on HAR using
Internet of Things (IoT) devices and clothes-based sensors,
discussed in Section II, which unfolded the intense growth
on the number of publications related to the analysis of feet
posture and movement in recent years. Throughout the review,
we observed that (i) no previous work thoroughly addressed
the relevance of the sensors employed for the assessed activity
model, (ii) few works provided public datasets for bench-
marking, (iii) there is no sufﬁcient information on sensors
deployment, (iv) few works addressed their sample rates and
time window size choices and (vi) few works addressed the
positioning of the plantar pressure sensors. The lack of pub-
lished datasets, the insufﬁcient information for the replication
of these studies and the overall obliviousness of other work’s
results points to a lack of maturity of the area.
The main contributions of this work are (i) an analysis of
the relevance of different types of sensors for the building
of a HAR classiﬁer based on feet movement and posture
information, (ii) a comprehensive literature review focused on
HAR research using clothes-based sensors for collecting feet
movement and posture information and (iii) an IoT device
blueprint for HAR research, an insole equipped with all the
types of sensors used in the surveyed works along with novel
sensors. In Section III, the design of the IoT device, sensors
deployment and replication information are shown along with
the details of the experiment conducted to collect ADL data. In
Section IV, the development of the activity model, the classiﬁer
and the experimental results are presented and analyzed. In
Section V, we conclude with an assessment of sensor relevance
and additional ﬁndings.
II.
LITERATURE REVIEW
This section presents a comprehensive literature review and
meta-data analysis about HAR clothes-based sensors research
projects using feet movement and posture information for ADL
recognition. The literature review workﬂow was conducted in
the following way: (i) deﬁnition of a research question, (ii)
crafting of a search query string, (iii) deﬁnition of exclusion
criteria and (iv) performing quantitative and qualitative data
analysis. The research question posed in this review is: What
are the clothes-based sensors HAR research projects conducted
in recognition of ADL using feet movement and posture
information?
This research question was further divided into sub-
questions:
•
What are the types, quantities and locations of the
sensors used?
•
How was the sensor mix chosen?
•
What activities are present in the activity model?
Based on these questions, we formulated a search query
string and reﬁned it by the publication year range ﬁlter to
exclude works not published during the last 10 years. With over
three hundred search results combining the searched databases,
we applied a very strict exclusion criteria and obtained 24
articles for analysis. Whenever available, from each article,
we collected the (i) types and quantity of sensors used, (ii)
activity model and machine learning technique, (iii) number
of subjects and samples collected and (iv) test technique and
results.
The metadata associated with the IoT devices and clothes-
based sensor selection presented by these works is summarized
in Table I, where the articles are grouped into three distinct
research categories: (i) works using Ground Contact Force
(GCF) sensors, (ii) works using Inertial Motion Units (IMUs)
169
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

sensors and (iii) works employing sensor fusion and other non-
conventional sensors.
TABLE I. SUMMARY OF SENSOR SELECTION AND POSITIONING.
Name
Sensor
Positioning
Crea [4]
FSR
Insole
De Santis [5]
FSR
Insole
Drobny [6]
FSR
Insole
el Achkar [7]
FSR
Insole
Fukahori [8]
FSR
Sock
Holleczek [9]
FSR
Sock
Lin [10]
FSR
Insole
Zhu [11]
FSR
Shoe and Waist
Kong [12]
GCF
Insole
Ugulino [13]
Accelerometers
Waist, Thigh, Arm and Ankle
McCarthy [14]
Gyroscope
Shoe
Doppler [15]
IMU
Insole and Shoe
Ghobadi [16]
IMU
Shoe
Edgar [1]
FSR, IMU
Insole
Lin [17]
FSR, IMU
Insole and Shoe
Tang [18]
FSR, IMU
Insole
Zhang [19]
FSR, IMU
Insole and Shoe
Zhang [20]
FSR, IMU
Insole and External
Noshadi [21]
FSR, Gyroscope and
Accelerometers
Insole, Shoe and External
Sazonov [2]
FSR, Accelerometers
Insole and Shoe
Sazonov [22]
FSR, Accelerometers
Insole and Shoe
Jiang [23]
IR
Shoe
Matthies [24]
Capacitive Sensing
Insole
Haescher [25]
Capacitive Sensing
Chest, Leg and Insole
A. Recognition of Common Movement Activities
The recognition of common movement activities, such as
walking, standing, sitting, climbing stairs and running, is the
most common type of research found in this literature review.
Those works, such as [5] [7] [9] [15], rely mostly on plantar
Force Sensitive Resistor (FSR) pressure sensors to classify user
activity according to a previously elaborated activity model.
Other works, such as [6] [14] [16], rely on IMUs located on the
user’s feet for that purpose. Sensor fusion of FSRs and IMUs is
employed by works such as [2] [17] [18] [26], achieving good
overall results. Only four of the surveyed works used sensors
other than GCF sensors and IMUs: infrared sensors in [23],
capacitive sensing technology in [24] [25] and air bladders
in [12]. Some works positioned extra sensors in other places
beyond the user’s feet, such as [13], where extra sensors are
positioned onto user’s waist, thigh, arm and ankle and [25],
where extra sensors are positioned onto user’s chest and leg.
They all use very similar activity models composed of sitting,
standing, running, walking and slope-walking activities, the
main differences being the machine learning algorithms used
and the context of the experiments. Two of the activity models
proposed by the works of this section are more comprehensive
than the prevailing standing-walking-running activity models
[17] [20]. Both relied on sensor fusion techniques to classify
user’s activities and obtained promising results.
Many of the surveyed studies were conducted in the recog-
nition of activities related to healthcare and well-being, such
as (i) the research presented in [10], that aims at recognizing
caregiver’s Patient Handling Activities (PHA) and movement
activities to help prevent overexertion injuries, (ii) the works
presented in [19] [27], that measure activity in people with
stroke, (iii) the work presented in [1], that recognizes activities
and postures to provide behavioral feedback to patients recov-
ering from a stroke, and (iv) the research proposed by [21],
in which researchers present a pair of shoes that offer low-
cost balance monitoring outside of laboratory environments
using features identiﬁed by geriatric motion study experts. The
lightweight smart shoes are based on the MicroLEAP wireless
sensor platform [28], which uses an IMU and FSR pressure
sensors embedded inside each insole for data acquisition.
Some other shoe-based wireless sensor platforms, such as the
SmartStep [29], were used by many different healthcare-related
researches. In [30], the platform was used for developing an
Android application to capture data from the IoT device to
recognize activities and real time feedback provision. Works,
such as [3] [22], employ the SmartShoe platform for energy
expenditure estimation after the classiﬁcation of the activities
performed by the user, and in [31] it is used to predict body
weight and energy expenditure. The same platform is then used
by [27] [32] to identify activity levels and steps in people
with stroke. Although the majority of the works focused on
healthcare and well-being, some, such as [8], investigated the
use of foot-based gestures, known as Foot Plantar-Based (FPB)
gestures, to control computing devices.
B. Literature Review Discussion
The measuring of GCFs is the most prevalent approach
used by the surveyed works for the task of recognizing user
activity, being present in 16 of the 24 studies, while the second
most common approach, present in 12 of the 24 studies,
is the use of IMUs. Although the challenge of adequately
positioning the GCF sensors is recognized as a very important
factor by studies, such as [33] [34], it is not thoroughly
addressed by most of the surveyed works. Considering the
IoT devices presented in the literature, two characteristics
impair their reproducibility: (i) the lack of information about
the IMUs orientation and the (ii) absence of sensor model
information or speciﬁcation. Most of the works analyzed, 22
out of 24, provided detailed information regarding the models
of its activity classiﬁers, but only 12 studies detailed the test
techniques used in the activity classiﬁers – 7 of which used
k-fold cross validation and 5 used leave-one-out. Although
most studies stated that tests were performed, they provided no
detailed information about these tests. The success rate of ADL
recognition of the surveyed works fell into the 80% - 100%
range. No work addressed the sensor mix choice besides stating
that its selection is commonly found throughout the literature.
It was also observed that 21 out of 24 works provided
information on the number of participants, but only 6 of the
24 studies provided information on the dataset size. The main
issue detected in the literature review is the absence of publicly
available datasets, impairing that way the understanding of
the results. Knowledge of datasets is especially important to
assess works that use similar (i) sensor selection, (ii) sensor
placement and (iii) activity models. As discussed in [11],
dataset disclosure is crucial for benchmarking purposes, given
that classiﬁcation algorithms rely heavily on datasets. Beyond
dataset size, sample rates and time window durations also
affect the understanding of the results. Only 16 of the 24
surveyed works provided information on the sample rates,
and 8 of those 16 also provided information on the time
window size. The prevailing suggestions for future works and
contribution found in the literature are to (i) increase the data
set through longer data collection intervals and the diversi-
ﬁcation of participant’s proﬁles and (ii) adapt the activity
model to a speciﬁc challenge, such as helping patients to
avoid falls. To make the literature review presented in this
170
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

article replicable, all surveyed publications are available in RIS
(Research Information Systems) format in [35].
III.
METHODS
A. IoT Device Prototyping
In this section, we present the IoT device prototyped to
collect user data. Aiming at a highly replicable research, we
provide detailed software and hardware information – types,
quantities and models of every sensor, along with their exact
positioning and orientation, and source code of the embedded
software and the application server. Since battery lifetime is a
major concern for studies outside of a laboratory environment
and the participants came from diverse technological back-
grounds, the key design goals were to develop a (i) low power
consumption device capable of extended operation that (ii) was
easy to use during the experiment. The IoT device comprises
two components: an US men’s size 8 insole that houses the
plantar pressure sensors and an external protective case that
houses the microcontroller and the other sensors. The insole
component was developed with six GCF sensors, and their
placement followed literature’s recommendations found in [33]
[36]. We used the FSR 402 by Interlink Electronics, a Polymer
Thick Film (PTF) device that exhibits a decrease in resistance
as the force applied to its active surface increases. Given that
each sensor needs a static resistor to create a variable voltage
for the microcontroller’s Analog to Digital Converter (ADC)
inputs, we placed six 10KΩ 1/4W resistors inside the insole
next to them. We opted to use a single insole in the experiment
to reduce prototyping costs, since the literature suggested
that the loss of information when compared to experiments
collecting data from both feet is minimal [23]. The external
protective case is built around a Particle Electron, a 2G-enabled
microcontroller from Particle.io that collects and transmits
sensor data to the database. For the accelerometer, gyroscope
and magnetometer sensors responsible for monitoring the
feet posture, we used the LSM9DS1 by STMicroelectronics,
a system-in-package component that is part of the Photon
microcontroller board. The LSM9DS1 is a digital sensor,
automatically calibrated by its ﬁrmware when the device is
powered up [37]. The barometer selected for the experiment
is the MPL3115A2, by Freescale Semiconductor, a low power,
high-precision altitude, pressure and temperature sensor. The
MPL3115A2 sensor is factory calibrated for sensitivity, offset
for both temperature and pressure measurements, and has a
built-in altimeter calculator. Under normal operation, there is
no need for further calibration [38]. For the range-ﬁnder sensor,
we used the VL6180 by STMicroelectronics. Although other
sensors are capable of greater sampling rates, the selected
range-ﬁnder sensor is one of the few distance sensors adequate
for the 10 Hz sampling rate used in the experiment. The
VL6180 sensor is calibrated using the Very High Voltage
(VHV) calibration approach described in [39], and the method
for free-calibration usage described by the manufacturer in [40]
is also employed. The Electron microcontroller and its board,
along with the MPL3115A2 and VL6180 sensors mentioned
above, were positioned in the ABS 3D printed external protec-
tive case. The prototype is powered by a 2,200 mAh lithium ion
battery pack by Sparkfun Electronics, allowing for an easier,
faster replacement and improved usability. Its 7-segment LED
(Light-Emitting Diode) charge level display helped us plan
and execute the experiment session cycles. Since we needed
a comprehensive sensor selection to investigate the relevance
of sensor types for the recognition of ADLs based on feet
movement and posture information, we decided to use all
sensor types employed by the surveyed works and a novel
sensor, the barometer.
The software model used in this work comprises two com-
ponents: (i) the embedded software running on the microcon-
troller, responsible for acquiring, structuring and transmitting
raw sensor data over a 2G connection to an iMac application
server, and (ii) the application server itself, responsible for
processing and logging the streamed data to a NOSQL (Non
SQL) cloud database – tasks not suitable for the embedded
microcontroller due to its hardware limitations. The authors
made available the complete and commented source code of
the embedded software and the application server in [35].
B. Procedure
Twelve volunteers carefully selected for their diverse char-
acteristics participated in the experiment. One prevailing lim-
itation of the surveyed works was the employment of young
adults only as participants in their experiments. This study
tries to circumvent this problem with the participation of
people with disabilities, two Class II obesity individuals, two
overweight individuals, two knee-injured patients and one
ankle-injured patient, a balanced mix of male and female
participants and one third of senior adult volunteers. Since the
insole and shoes are US men’s size 8, we selected participants
in the 7.5 to 8.5 shoe size range. We collected 24 hours of
activity data, which is 2 hours of feet posture and movement
data from each volunteer. Compared to the other studies, the
number of subjects in our study is not that different from the
others, considering the average of 7 in the surveyed works.
However, the number of samples in our study – around 950,000
– is signiﬁcantly higher than the average number of samples –
around 50,000 – found in the surveyed works. We developed
a comprehensive activity model for the experiment, since we
were aiming at assessing the relevance of different sensor
types for the recognition of ADLs based on feet movement
and posture information. It comprises 9 activities: walking
straight (2km/h), walking slope up (2km/h), walking slope
down (2km/h), slow jogging (6km/h), slow jogging slope up
(6km/h), slow jogging slope down (6km/h), ascending stairs,
descending stairs and sitting. The experiment was conducted
in four distinct sessions, where participants performed a subset
of the planned activities. Due to their availability, some partic-
ipants performed more than one session per day. All sessions
were performed on a garden area inside the university campus.
The ﬁrst session lasted for 50 minutes, and each participant
performed 5 cycles of 10 minutes (8 minutes walking followed
by 2 minutes resting). The second session also lasted for 50
minutes and consisted of 5 cycles of 10 minutes (4 minutes
slope walking up, 4 minutes slope walking down and 2 minutes
resting). In the third session, each participant performed 5
cycles of stair climbing interleaved with sitting for a total
of 20 minutes (1 minute ascending stairs, 1 minute resting,
1 minute descending stairs, 1 minute resting). Finally, in the
last session, participants performed 3 cycles of slow jogging
and sitting – this section was performed two months after the
initial experiment, when we added 3 more activities to our
activity model, namely: (i) slow jogging (6km/h), (ii) slow
jogging slope up (6km/h) and (iii) slow jogging slope down
171
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

(6km/h). Subjects were free to perform the activities – the
IoT device did not restrict in any way their movement and
the instructions provided did not specify how the activities
were to be performed. This way we were able circumvent a
common limitation of most HAR works in which activities are
performed in a non-natural way. It is important to note that we
had removed running (8km/h) from the original model, because
that would be a deterrent to some of the participants. For the
sake of adding the last three activities to the activity model, we
had to remove one elder volunteer from the experiment, but
kept the injured participants after consulting with a certiﬁed
health professional. We accompanied all participants during
the sessions to log any unusual occurrence.
IV.
DATA ANALYSIS
In this section, we describe the stages followed to develop
the HAR classiﬁer, data acquisition, data processing, feature
extraction, feature selection, classiﬁcation and validation, and
our ﬁndings regarding sensor relevance. The full dataset is
available in [35].
A. Data Acquisition
During the data acquisition stage, a stream of raw, un-
processed signals was acquired from the insole’s sensors and
stored in the microcontroller in JSON format. This raw data
combined the accelerometer, gyroscope, magnetometer, six
FSR sensors, altitude, temperature and range-ﬁnder sensor sig-
nals, resulting in 17-feature set entries to the dataset. We used
the 10 Hz sampling rate recommended by [41]. As discussed in
[42], we understand that this sample rate may not be adequate
for recognizing similar activities or subtle variations within
the same activities. However, these concerns were not relevant
to our research. To reduce energy consumption and allow for
an extended operating time, the JSON formatted data was
periodically sent to the application server in small packages
of 100KB.
B. Data Processing and Feature Extraction
The data processing stage occurs in three steps. First, data
unrelated to the speciﬁc planned activities for the experiment
is discarded, given that the prototype starts collecting feet
movement and posture information immediately after it is
powered. Then, the dataset is labelled for supervised learning,
and activity class information is appended to each entry
according to the activity performed in the experiment. Finally,
all sensor data is normalized to make their scales equivalent,
partly address sensor drift and reduce the possibility of model
overﬁtting.
In the feature extraction stage, we used descriptive statis-
tics, standard deviation, variance, minimum, maximum and
average values, to generate derived features from each of the
17 original features:
•
Six FSR sensor readings;
•
Three gyroscope axis data;
•
Three magnetometer axis data;
•
Three accelerometer axis data;
•
Altimeter reading; and
•
Range-ﬁnder sensor reading.
Moreover, (i) the cumulative difference between samples
for each feature and (ii) the Euler angles of pitch, roll and
yaw were also used to generate additional derived features,
for a total of over 100 features for selection.
C. Classiﬁcation and Validation of the Baseline Model
To build and validate our baseline model, a model that
makes use of all sensor raw and derived features, we used
the Leave-one-out Cross Validation method, in an attempt
to decrease the chances of overﬁtting. Although there is no
evidence to support this assumption, this method at least
guarantees that both training and test splits do not share any
example data. Different strategies were then experimented to
build the classiﬁer for our 9-activities activity model, and
the Random Forest Algorithm was selected for classiﬁcation,
given that its average performance of 91.26% was superior
to the other ones. The individual validation results for each
of the 12 examples were: 89.17%, 90.86%, 92.42%, 94.82%,
97.41%, 90.18%, 79.78%, 94.14%, 95.01%, 88.31%, 91.98%
and 91.01%. In total, 12 features were utilized to build the
classiﬁer: 2 axis of the gyroscope, 2 axis of the magnetometer,
1 axis of the accelerometer, 4 FSRs, 2 Euler angles and the
cumulative difference between samples of the barometer. The
features selected for the baseline classiﬁer provided valuable
insights for the next step, the analysis of sensor type relevance.
As discussed in [43], after experimenting several time
window sizes during the classiﬁer construction, we decided
to use a 0.3s one based on our model validation results,
registering an accuracy improvement of about 19% when
contrasting the selected window (0.3s) and the largest time
window experimented (2.0s).
D. Analysis of Sensor Type Relevance
After building the baseline model, we were able to inves-
tigate the relevance, correlation of a feature with the average
classiﬁer accuracy, of each sensor type for the achieved results.
We used Hall’s algorithm [44] based on correlation with its de-
fault "Best Fit" conﬁguration, a backtracking greedy strategy.
This method was selected based on its superior performance
when compared to the other feature selection methods found
in the surveyed works. Ugulino et al. [13] also use this
same method to reduce feature redundancy and still achieve
better-than-average results. Based on the results commonly
found in the literature, we already expected to see gyroscope,
accelerometer and FSR features showing high correlation and
being used in the building of the classiﬁer. However, the results
achieved by Hall’s algorithm suggested which features were
relevant and to what extent. Considering the baseline model,
the distance sensor showed a very low correlation and was
not used in the building of the classiﬁer. Although distance
sensors were successfully employed by works such as [23],
when presented with a broader sensor selection the classiﬁer
did not make use of it. FSRs 5 and 6 showed a medium to
low correlation and were not employed, while the remaining
FSRs showed a high correlation. Considering that some of
the surveyed works also used between three to four FSRs with
similar positioning, further investigation could lead to evidence
as to where to position the sensors for better recognition
accuracy of the selected activities. Euler angles showed a high
correlation and were utilized by some of the surveyed works,
making a strong case that they should be evaluated during the
172
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

feature engineering phase for similar activity models. Finally,
the barometer provided the feature with the second highest
correlation score, suggesting that this type of sensor should
also be evaluated for similar activity models. The topic of
feature engineering and its methods are beyond the scope of
this work, so we used the features employed by the surveyed
works in our analysis.
After that initial assessment, we evaluated each sensor, raw
and derived features, separately, employing the same methods
used to build the baseline classiﬁer: (i) Leave-one-out Cross
Validation and (ii) Random Forest Algorithm. The average
accuracy results are shown in Table II, where all values are
rounded to the nearest whole number and ordered by average
accuracy.
TABLE II. SINGLE SENSOR CLASSIFIER ACCURACY.
Sensor
Model Accuracy
IMU
66%
FSRs
60%
Barometer
29%
Distance
17%
Following that analysis, we combined the two most suc-
cessful sensor types, FSRs and IMUs, with all available sensor
types. We built and validated a classiﬁer for each combination,
and the average accuracy results for the better performing
combinations are shown in Table III, where all values are
rounded to the nearest whole number and ordered by average
accuracy.
TABLE III. SENSOR MIX CLASSIFIER ACCURACY.
Sensor
Model Accuracy
IMU (9-axis) and FSRs
81%
FSRs and Barometer
71%
IMU (9-axis) and Barometer
70%
FSRs and Gyroscope
65%
FSRs and Accelerometer
60%
FSRs and Magnetometer
59%
IMU (9-axis) and Distance
57%
FSRs and Distance
55%
Distance
17%
Although the results shown in Table III take into account
the combined FSRs, FSR1 to FSR4, we also evaluated FSR5
and FSR6 for the same combinations, achieving less than 1%
increase in average accuracy. The experimental results show
that (i) 9-Axis IMUs, (ii) 4-FSR arrays and (iii) barometers
were the most relevant sensor types for the recognition of
ADLs based on feet movement and posture information, when
considering a typical activity model with the stand, walk,
run and climb stairs activities. Above that, we learned that
accuracy can be greatly improved (15%) by the IMU and FSR
sensor fusion, so that approach should be considered in future
research if it is needed to (i) differentiate between similar
activities or (ii) identify subtle variations of the same activity.
Lastly, the barometer sensor allowed for an increase of the
average accuracy by more than 10%, making a strong case for
its adoption whenever possible.
V.
CONCLUSION AND FUTURE WORK
In this work, we expanded the research conducted in [42]
by (i) enhancing the IoT device’s sensor array, (ii) improving
the machine learning HAR classiﬁer, (iii) increasing the num-
ber of participants and activity classes in the experiment and,
above all, (iv) focusing on assessing the relevance of different
sensor types for the task of recognizing ADL using foot
movement and posture information. The main contributions
of this work are:
•
An analysis of the relevance of different types of
sensors in the building of a HAR classiﬁer based on
foot movement and posture information, discussed in
Section IV;
•
A public domain dataset with about 1 million samples
and 9 activity classes, available in [35];
•
A comprehensive literature review about clothes-based
sensor HAR researches, presented in Section II; and,
•
A clothes-based sensor IoT device, presented in Sec-
tion III, for the data collection of feet movement and
posture information.
Despite not taking any measures to address FSRs’ drift
over time, the overall classiﬁer accuracy was satisfactory -
achieving top quartile performance when compared to the
surveyed works. After the experiment, we developed a new
version of the IoT device with the purpose of helping reduce
injury risk during functional exercise sessions. Our goal is
to employ sensor fusion and machine learning techniques
to provide users with real time feedback of the exercises,
helping them to improve and avoid injuries. Currently, we
are conducting an outdoor experiment with 18 volunteers -
including two sight impaired participants - to investigate the
extent to which we can detect correct execution of the exercise
routines. We were able to use the lessons learned from the
experiment presented in this work to improve the new version
of the IoT device developed for the new research, making
changes, such as: (i) removing the range-ﬁnder sensors, and
reducing the number of FSRs to 4, based on our ﬁndings, (ii)
using sewable connectors for the FSR sensors to withstand
the impact of jogging activities – all commercially available
connectors disconnected the sensors at some point during the
jogging sessions, forcing the session to pause to repair the
prototype – and (iii) using Sparkfun Electronics’ battery pack
to turn the IoT device into a convenient and easy-to-use device
that can be deployed outdoors without difﬁculty.
REFERENCES
[1]
S. R. Edgar, T. Swyka, G. Fulk, and E. S. Sazonov, “Wearable shoe-
based device for rehabilitation of stroke patients,” in Engineering in
Medicine and Biology Society (EMBC), 2010 Annual International
Conference of the IEEE.
IEEE, 2010, pp. 3772–3775.
[2]
E. S. Sazonov, G. Fulk, J. Hill, Y. Schutz, and R. Browning, “Monitoring
of posture allocations and activities by a shoe-based wearable sensor,”
IEEE Transactions on Biomedical Engineering, vol. 58, no. 4, 2011,
pp. 983–990.
[3]
N. Sazonova, R. C. Browning, and E. Sazonov, “Accurate prediction
of energy expenditure using a shoe-based activity monitor,” Med Sci
Sports Exerc, vol. 43, no. 7, 2011, pp. 1312–21.
[4]
S. Crea, S. De Rossi, M. Donati, P. Reberšek, D. Novak, N. Vitiello,
T. Lenzi, J. Podobnik, M. Munih, and M. Carrozza, “Development
of gait segmentation methods for wearable foot pressure sensors,” in
Engineering in Medicine and Biology Society (EMBC).
IEEE, 2012,
pp. 5018–5021.
[5]
A. De Santis, E. Gambi, L. Montanini, L. Raffaeli, S. Spinsante, and
G. Rascioni, “A simple object for elderly vitality monitoring: The
smart insole,” in Mechatronic and Embedded Systems and Applications
(MESA), ASME.
IEEE, 2014, pp. 1–6.
[6]
D. Drobny, M. Weiss, and J. Borchers, “Saltate!: a sensor-based system
to support dance beginners,” in CHI’09 Extended Abstracts on Human
Factors in Computing Systems.
ACM, 2009, pp. 3943–3948.
173
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

[7]
C. M. El Achkar, F. Massé, A. Arami, and K. Aminian, “Physical
activity recognition via minimal in-shoes force sensor conﬁguration,”
in Pervasive Computing Technologies for Healthcare.
ICST, 2013, pp.
256–259.
[8]
K. Fukahori, D. Sakamoto, and T. Igarashi, “Exploring subtle foot
plantar-based gestures with sock-placed pressure sensors,” in Proceed-
ings of the 33rd Annual ACM Conference on Human Factors in
Computing Systems.
ACM, 2015, pp. 3019–3028.
[9]
T. Holleczek, A. Ruegg, H. Harms, and G. Troster, “Textile pressure
sensors for sports applications 9th ieee sensors conf,” Kona, HI, 2010.
[10]
F. Lin, C. Song, X. Xu, L. Cavuoto, and W. Xu, “Sensing from
the bottom: Smart insole enabled patient handling activity recognition
through manifold learning,” in Connected Health: Applications, Systems
and Engineering Technologies (CHASE).
IEEE, 2016, pp. 254–263.
[11]
C. Zhu and W. Sheng, “Multi-sensor fusion for human daily activity
recognition in robot-assisted living,” in International conference on
Human robot interaction.
ACM, 2009, pp. 303–304.
[12]
K. Kong and M. Tomizuka, “A gait monitoring system based on air
pressure sensors embedded in a shoe,” IEEE/ASME Transactions on
mechatronics, vol. 14, no. 3, 2009, pp. 358–370.
[13]
W. Ugulino, D. Cardador, K. Vega, E. Velloso, R. Milidiú, and H. Fuks,
“Wearable computing: Accelerometers’ data classiﬁcation of body pos-
tures and movements,” in Advances in Artiﬁcial Intelligence, SBIA.
Springer, 2012, pp. 52–61.
[14]
M. McCarthy, D. James, J. Lee, and D. Rowlands, “Decision-tree-
based human activity classiﬁcation algorithm using single-channel foot-
mounted gyroscope,” Electronics Letters, vol. 51, no. 9, 2015, pp. 675–
676.
[15]
J. Doppler, G. Holl, A. Ferscha, M. Franz, C. Klein, M. dos San-
tos Rocha, and A. Zeidler, “Variability in foot-worn sensor placement
for activity recognition,” in Wearable Computers, 2009. ISWC’09.
International Symposium on.
IEEE, 2009, pp. 143–144.
[16]
M. Ghobadi and E. T. Esfahani, “Foot-mounted inertial measurement
unit for activity classiﬁcation,” in Engineering in Medicine and Biology
Society, EMBC.
IEEE, 2014, pp. 6294–6297.
[17]
F. Lin, A. Wang, Y. Zhuang, M. R. Tomita, and W. Xu, “Smart insole:
A wearable sensor device for unobtrusive gait monitoring in daily life,”
IEEE Transactions on Industrial Informatics, vol. 12, no. 6, 2016, pp.
2281–2291.
[18]
W. Tang and E. S. Sazonov, “Highly accurate recognition of human
postures and activities through classiﬁcation with rejection,” IEEE
Journal of Biomedical and Health Informatics, vol. 18, no. 1, 2014,
pp. 309–315.
[19]
T. Zhang, G. D. Fulk, W. Tang, and E. S. Sazonov, “Using decision
trees to measure activities in people with stroke,” in Engineering in
Medicine and Biology Society (EMBC), 2013 35th Annual International
Conference of the IEEE.
IEEE, 2013, pp. 6337–6340.
[20]
Z. Zhang and S. Poslad, “Improved use of foot force sensors and mobile
phone gps for mobility activity recognition,” IEEE Sensors Journal,
vol. 14, no. 12, 2014, pp. 4340–4347.
[21]
H. Noshadi, F. Dabiri, S. Ahmadian, N. Amini, and M. Sarrafzadeh,
“Hermes: mobile system for instability analysis and balance assess-
ment,” ACM Transactions on Embedded Computing Systems (TECS),
vol. 12, no. 1s, 2013, p. 57.
[22]
E. Sazonov, N. Hegde, R. C. Browning, E. L. Melanson, and N. A.
Sazonova, “Posture and activity recognition and energy expenditure
estimation in a wearable platform,” IEEE journal of biomedical and
health informatics, vol. 19, no. 4, 2015, pp. 1339–1346.
[23]
X. Jiang, Y. Chen, J. Liu, G. R. Hayes, L. Hu, and J. Shen, “Air:
recognizing activity through ir-based distance sensing on feet,” in
International Joint Conference on Pervasive and Ubiquitous Computing:
Adjunct.
ACM, 2016, pp. 97–100.
[24]
D. J. C. Matthies, T. Roumen, A. Kuijper, and B. Urban, “Capsoles:
Who
is
walking
on
what
kind
of
ﬂoor?”
in
Proceedings
of
the 19th International Conference on Human-Computer Interaction
with Mobile Devices and Services, ser. MobileHCI ’17.
New
York, NY, USA: ACM, 2017, pp. 9:1–9:14. [Online]. Available:
http://doi.acm.org/10.1145/3098279.3098545
[25]
M. Haescher, D. J. C. Matthies, G. Bieber, and B. Urban, “Capwalk: A
capacitive recognition of walking-based activities as a wearable assistive
technology,” in Proceedings of the 8th ACM International Conference
on PErvasive Technologies Related to Assistive Environments, ser.
PETRA ’15.
New York, NY, USA: ACM, 2015, pp. 35:1–35:8.
[Online]. Available: http://doi.acm.org/10.1145/2769493.2769500
[26]
N. Hegde, M. Bries, T. Swibas, E. Melanson, and E. Sazonov, “Auto-
matic recognition of activities of daily living utilizing insole based and
wrist worn wearable sensors,” IEEE journal of biomedical and health
informatics, 2017.
[27]
G. D. Fulk and E. Sazonov, “Using sensors to measure activity in people
with stroke,” Topics in stroke rehabilitation, vol. 18, no. 6, 2011, pp.
746–757.
[28]
L. K. Au, W. H. Wu, M. A. Batalin, D. H. McIntire, and W. J. Kaiser,
“Microleap: Energy-aware wireless sensor platform for biomedical
sensing applications,” in Biomedical Circuits and Systems Conference.
BIOCAS.
IEEE, 2007, pp. 158–162.
[29]
N. Hegde and E. Sazonov, “Smartstep: A fully integrated, low-power
insole monitor,” Electronics, vol. 3, no. 2, 2014, pp. 381–397.
[30]
N. Hegde, E. Melanson, and E. Sazonov, “Development of a real
time activity monitoring android application utilizing smartstep,” in
Engineering in Medicine and Biology Society (EMBC), 2016 IEEE
38th Annual International Conference of the.
IEEE, 2016, pp. 1886–
1889.
[31]
N. A. Sazonova, R. Browning, and E. S. Sazonov, “Prediction of
bodyweight and energy expenditure using point pressure and foot
acceleration measurements,” The open biomedical engineering journal,
vol. 5, 2011, p. 110.
[32]
G. D. Fulk, S. R. Edgar, R. Bierwirth, P. Hart, P. Lopez-Meyer,
and E. Sazonov, “Identifying activity levels and steps in people with
stroke using a novel shoe-based sensor,” Journal of Neurologic Physical
Therapy, vol. 36, no. 2, 2012, p. 100.
[33]
L. Shu, T. Hua, Y. Wang, Q. Li, D. D. Feng, and X. Tao, “In-shoe
plantar pressure measurement and analysis system based on fabric
pressure sensing array,” IEEE Transactions on Information Technology
in Biomedicine, vol. 14, no. 3, 2010, pp. 767–775.
[34]
U. Manupibul, W. Charoensuk, and P. Kaimuk, “Design and develop-
ment of smart insole system for plantar pressure measurement in im-
balance human body and heavy activities,” in Biomedical Engineering
International Conference (BMEiCON), 2014 7th. IEEE, 2014, pp. 1–5.
[35]
R. De Pinho André, P. H. F. S. Diniz, and H. Fuks, “Iwoar smart insole,”
https://goo.gl/6ozm26, 2017.
[36]
J. Perry and J. M. Burnﬁeld, “Gait analysis: normal and pathological
function,” Developmental Medicine and Child Neurology, vol. 35, 1993,
pp. 1122–1122.
[37]
ST, “Lsm9ds1 datasheet,” https://www.st.com/resource/en/datasheet/
lsm9ds1.pdf, 2018 (retrieved: june, 2018).
[38]
NXP, “Mpl3115a2 datasheet,” https://www.nxp.com/docs/en/data-sheet/
MPL3115A2.pdf, 2018 (retrieved: june, 2018).
[39]
ST, “Vl6180x datasheet,” https://cdn-learn.adafruit.com/assets/assets/
000/037/608/original/VL6180X_datasheet.pdf, 2017 (retrieved: june,
2018).
[40]
STMicroelectronics, “Vl6180x product site,” https://www.st.com/en/
imaging-and-photonics-solutions/vl6180x.html, 2017 (retrieved: june,
2018).
[41]
A. Harasimowicz, T. Dziubich, and A. Brzeski, “Accelerometer-based
human activity recognition and the impact of the sample size,” Advances
in Neural Networks, Fuzzy Systems and Artiﬁcial Intelligence, 2014,
pp. 130–135.
[42]
R. De Pinho André, P. H. F. S. Diniz, and H. Fuks, “Bottom-up
investigation: Human activity recognition based on feet movement and
posture information,” in Proceedings of the 4th International Workshop
on Sensor-based Activity Recognition and Interaction, ser. iWOAR
’17.
New York, NY, USA: ACM, 2017, pp. 10:1–10:6. [Online].
Available: http://doi.acm.org/10.1145/3134230.3134240
[43]
O. Banos, J.-M. Galvez, M. Damas, H. Pomares, and I. Rojas, “Window
size impact in human activity recognition,” Sensors, vol. 14, no. 4, 2014,
pp. 6474–6499.
[44]
M. Hall, “Correlation-based feature subset selection for machine learn-
ing,” Thesis submitted in partial fulﬁllment of the requirements of the
degree of Doctor of Philosophy at the University of Waikato, 1998.
174
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

