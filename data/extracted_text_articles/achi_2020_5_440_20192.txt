3D Virtual Try-On System Using Personalized Avatars:
Augmented Walking in the Real World
Yuhan Liu1, Yuzhao Liu1, Shihui Xu1, Jingyi Yuan1, Xitong Sun1, Kelvin Cheng2, Soh Masuko2 and Jiro Tanaka1
1 Waseda University, Kitakyushu, Japan
2 Rakuten Institute of Technology, Rakuten, Inc., Tokyo, Japan
E-mail: liuyuhan-op@akane.waseda.jp, liuyuzhao131@akane.waseda.jp, shxu@toki.waseda.jp,
jingyyuan@toki.waseda.jp, sunxitong@akane.waseda.jp, kelvin.cheng@rakuten.com,
so.masuko@rakuten.com, jiro@aoni.waseda.jp
Abstract— Despite the convenience offered by e-commerce
websites for consumers to purchase clothes online, consumers
still have difficulties imagining what they might look like. To
address this problem, we propose a holographic 3D virtual try-
on system that enables users a novel experience where they can
view garments fitted onto their own personalized virtual body.
The garment models are generated from the garment images
from online shopping websites. Users can animate their
dressed virtual body in a real-life scene in Augmented Reality.
We have conducted a user study to compare our proposed
system with an image-only shopping system and have validated
the effectiveness of our system.
Keywords-Virtual
try-on;
Virtual
garment
modeling;
Augmented reality.
I.
INTRODUCTION
With
the
continuous
development
of
e-commerce
technology, the number of consumers purchasing clothes
online is increasing [1]. Consumers usually have the desire to
try on garments in order to assess if they are suitable or not
before
purchasing.
However,
when
shopping
online,
consumers have the problem of not being able to try them
on. They might worry how well the clothes will fit on their
own body. Furthermore, it is difficult for customers to
imagine what they might look like with various postures (i.e.,
standing, walking, posing, etc.) or in different settings.
To address these problems, we propose a 3D virtual try-
on system using personalized models (Figure 1). (a) We
generate the virtual model of users based on their own body
and
face
information.
(b)
We
gather
some
garment
information and realize the 3D garment visualization using
Cloth-weaver [5]. (c) We customize the garment model for
each user and match the garment model to their personalized
virtual avatar. (d) We enable users to view their own
personalized body model fitted with virtual garment. (e)
These models can also be visualized in a real-life scene and
together with animated motions. To understand the user’s
acceptability, we conducted a user study to evaluate the
value and convenience of our system.
The main contributions of this paper can be summarized
as follows:
• Virtual garment models generation based on online
garment images;
• A method for users to view the virtual garment
interactively
and
immersively
in
360
degrees
and
enabling users to check the garment by augmenting the
motion of a personalized user body in the real-world.
Figure 1. Our system allows users to view virtual garment fitted onto personalized body models and animate them in real-life scene.
391
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

The rest of the paper is organized as follows. In Section
2, a brief review of previous research on 3D virtual try-on,
garment modeling and virtual avatar is presented. In Section
3, we describe the system design, including human model
personalization, garment model generation and 3D virtual
try-on system. In Section 4, we present our evaluation result.
In Section 5, we conclude our paper with a brief summary
and discusses future work.
II.
RELATED WORK
A. Virtual try-on
Earlier work on virtual try-on are mostly conducted in
computer graphics [11][12][14]. Previous work focused on
two types of virtual try-on: 2D overlay virtual try-on and 3D
virtual try-on.
•
2D overlay virtual try-on:
Hilsmann et al. [15] retextured garment overlay for
real-time visualization of garments in a virtual
mirror environment. Yamada et al. [2] proposed a
method of reshaping the garment image based on
human body shapes to make fitting more realistic.
However, like many other retexturing approaches,
they
operate
only
in
2D
without
using
3D
information in any way, which lacked the ability for
users to view their virtual self from arbitrary
viewpoints.
•
3D virtual try-on: 3D garment models perform
precise garment simulation rather than just a 2D
overlay.
Protopsaltou et al. [20] created a virtual
dressing room, where customers can view garments
fitted onto their virtual body. Li et al. [21] proposed
a
multi-part
3D
garment
model
reconstruction
method to generate virtual garments for virtual
fitting on virtual avatars.
Recently, virtual try-on combined with Augmented
Reality (AR) or Virtual Reality (VR) technologies can give
consumers a more realistic try-on experience. Consumers
can get a better sense of what they look like when wearing
the products. Several fashion firms utilized AR technology in
the form of a mobile application, including Uniqlo and Gap
[22]. Using VR technology, consumers can feel like they are
physically in a virtual fitting room. Several fashion retailers
have provided this kind of shopping experience, such as
Alibaba and Dior [22].
B. Garment modeling
Unlike 2D images, 3D garment model performs precise
garment simulation. Most garment modeling works focus on
modeling 3D garment for a virtual character. Some garment-
retargeting methods transform garment designs from one
character
to
another.
For
example,
Pons-Moll
et
al.
introduced a system using multi-part 3D model of clothed
bodies for clothing extraction and retargeting the clothing to
new body shapes [16]. Pattern-based methods simulate the
garment
creation
process
in
real
life,
while
garment
modeling tools, such as Marverlous Designer [25], offer
garment modeling and editing in pattern design. Pattern-
based methods require professional knowledge of garment
design and are difficult for non-experts. To address the
problem of digitizing garments, Zhou et al. created virtual
garments from a single image [10]. Chen et al. captured real
garment with a depth camera and built a coarse shape from
its raw RGBD sequence using the RGB color information
and depth information [17].
C. Virtual Avatar
Most
virtual
try-on
systems
provide
virtual
fitting
experiences on a default virtual avatar, rather than one
generated from user’s own body [13].
The default virtual
avatar can be modified by users based on the individual
preferences and could be personalized if the consumers
upload their facial image [23][24]. This type of virtual avatar
does not reflect consumers’ true body shape.
The absence of “true fit” may disappoint customers when
shopping online. For our system, we propose to create virtual
personalized models for each user, which can reflect their
body shape and facial appearance, making their try-on
experience more accurate, engaging, and increasing the
customer’s confidence when making purchasing decisions on
garments online.
III.
SYSTEM DESIGN
Our 3D virtual try-on system is composed of human
model personalization, garment model generation and 3D
virtual try-on.
1)
Human model personalization: we personalize users
virtual avatar using their face image and 360-degree
body shape video. 2D face image is used for generating
a face model of users, while 360-degree body shape
video is used for generating the body model of the user.
We then integrate the body model and face model into
their personalized virtual avatar.
2)
Garment model generation: in order to provide users a
better visualization of online clothes, we generate 3D
virtual garments based on 2D images of clothes. To
realize 3D garment visualization, we map the garment
texture to prepared garment model templates.
3)
3D virtual try-on: we combine VR (Virtual Reality) and
AR (Augmented Reality) technology to simulate try-on
experience for users.
•
VR fitting: users can view their personalized
avatar fitting different clothes in several virtual
scenes.
•
Augmented walking: users can view their
avatar doing daily life activity in their real
environment.
Figure 2 gives an overview of our proposed system
pipeline. Our system uses three elements as input:
a
single face image with a full-frontal face, a short video
of the user’s full body, and a 2D garment image from
online shopping websites.
392
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions


Garment model generation: (a) Mapping the
2D garment image into the 3D garment model
templates and generating the 3D garment
model based on online images.

Human model personalization: (b) Generating
the 3D human model based on the face image
and recorded video.

3D virtual try-on: (c) Matching the 3D garment
model to the human model. (d) VR fitting:
Users choose different clothes to try on. Users
can change the pose and animation of the
human
model
in
different
virtual
scenes.
Augmented
walking:
Users
can
animate
personalized virtual body walking or do some
natural activities in the real world.
Figure 2. System Overview
A. Human Model Personalization
Due to the lack of “physical fitting” in online shopping
experience, consumers may have a gap between actual and
perceived body size, which may make it difficult to examine
“true fit” on their own body and influence their purchase
selection while shopping online. Therefore, virtual human
body
should
have
an
appropriate
3D
representation
corresponding to the real user’s human body shape and face
features. This would give a better representation of the user
and allows for a more accurate clothes fitting, as well as for
virtual human body animation. We generate human body
models based on Alldieck’s work [4] and generate face
models based on Deng’s method [3]. Also, a hair model
library is prepared, and the most similar hair model is
matched to the face model we generated.
B. Garment Model Generation
In order to provide users with better garment product
visualization, we allow users to view garments from various
angles and directions when users are shopping online. Our
approach uses garment image information from existing
shopping websites (i.e., H&M [18], Zara [19]) to create a
virtual garment library. Textures are extracted from the
garment image and mapped onto the 3D garment model. The
final 3D garment is shown in Figure 3. We mainly focus on
these two parts: garment model templates used in our system
and 3D modeling and texturing approaches.
Figure 3. Generate 3D garment model based on the information
from shopping website.
1)
3D Garment Model Templates
Garments are created using the traditional 2D pattern
approach. We build several 3D templates of virtual garment
models for the personalized human model using Cloth
Weaver, which is a Blender template library. It allows us to
simulate the methods of traditional garment designs. The 2D
pattern is discretized into a triangular mesh. Next, we can
design and modify the 2D pattern, and then use the reference
line to automatically fit the flat pattern to the corresponding
part of the body (Figure 4).
Figure 4. 2D patterns creation and positioning around generic body.
These are used as the basis for creating a variety of
garment models (Figure 5). We simulated several types of
clothing for female bodies and male bodies. For females, we
prepare them with long sleeves, T-shirt, long pants, dress and
skirt for fitting. For males, we prepare them with t-shirts,
long sleeves and half pants for fitting.
Figure 5. Some 3D garment templates provided for users
2)
Texture Mapping
We
collected
garment
images
from
existing
shopping websites (H&M, ZARA, etc.) and mapped
these clothes images to generated 3D garment model
templates (Figure 6). We segmented different parts of the
garment from a single garment image. The segmented
clothes can be divided into three main parts: left sleeves,
right sleeves, and the front of clothes. The 3D mesh of a
generated garment template can be extended into a 2D
reference mesh in 3ds Max [26]. To map the Web
garment image into a 3D virtual garment template, we
393
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

map the different segmentation parts from the garments
image to its corresponding parts on the garment template.
In this way, we can generate 3D garment model with
texture.
Figure 6. Mapping Web garment image to generated 3D garment
templates
The garment can be customized in various ways to
match the desired design. The most obvious change is the
customization of appearance and color, which is achieved
by modifying the texture of the cloth. Therefore, we
collected garment images from online shopping websites as
textures and created a garment model library for users
(Figure 7).
Figure 7. Garment model library for female and male
C. 3D Virtual Try-on
We gather various garment information from online
websites and enhance the online shopping experience for
users. Our system was developed using Unity3D [27] on
Windows10 and we deployed our system on Android
smartphones. The 3D virtual try-on system consists of two
parts: virtual fitting and augmented walking.
1)
Virtual Fitting
Virtual reality relies on an entirely digital environment,
which can provide an immersive and interactive shopping
experience for users.
We prepared a variety of fitting scenes for users, such as
on the street, in the office and at the supermarket. Users can
view the virtual garment based on the different virtual scenes,
giving them an idea of what they would look like for various
occasions or purposes (Figure 8).
Figure 8. Fitting scenes.
2)
Augmented walking
In our daily life, when users shop at the physical
(offline) shops, they often check the attributes of clothes
through various motions, such as twisting the body or
raising the arm to help the user confirm the fit of the
clothes. However, when shopping online, users cannot
visualize the details of the garment. Compared to the
offline try-on experience, the traditional online shopping
purchasing environment lacks the capability for users to
try-on garment on their own body and check whether the
clothes fit on them in various postures. Therefore, we
propose a dynamically interactive method that allows
users to animate their dressed human body in 360 degrees
and enables users view their virtual body walking in the
real-life scene.
A. Overview of Augmented Walking
The implementation of the augmented walking
framework aimed to animate the personalized avatar of
users in the real world (see Figure 9 for its overview).
Figure
9
shows
the
workflow
of
animating
the
personalized virtual avatar in the real world.
•
Personalized virtual avatar: we integrate the
virtual human model and clothes model in 3ds
max and export the virtual avatar as .fbx file.
•
Skeleton Binding and Skinning: we upload the
personalized virtual avatar to Mixamo [7]
which is a Web-based services for creating 3D
human
models’
animation.
We
bind
the
skeleton to the virtual avatar and skin it using
Mixamo.
•
Animate virtual avatar: to attach the animation
to
personalized
avatar,
we
use
animator
controller in Unity [28] to control the virtual
avatar and perform various animation.
•
Augmented walking in real world: we realize
the
augmented
walking
using
Vuforia
Augmented Reality SDK [6].
Figure 9. Implementation of augmented walking
394
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

B. Daily Life Animation
We fitted our generated human model with garment
models and created walking and pose animations, as
Figure 10 shows. Using Mixamo, the motions we
generate are very lifelike actions, such as waving/shaking
hands, walking, sitting, turning around, etc.
Figure 10. Postures of personalized human model
C. Augmented walking
Augmented walking enables users to view the
dressed human model in a dynamic and interactive way
from
different
perspectives
(as
Figure
11
shows).
Therefore, users can have a better understanding of
whether the garment is suitable or not while moving.
Figure 11. Views personalized model in different perspectives
Most of the previous work focused on fitting with a
static body model [13][14]. So far, there is a lack of
research exploring virtual try-on with motion. Therefore,
we provide dynamic interaction with the virtual human
model. To realize the augmented walking of the virtual
human model in a real-life scene, we use Vuforia
Augmented Reality SDK to detect the ground plane and
place the user’s virtual body into the real-life scene, in
life size.
Our system enables users to view a life-size
personalized virtual body with garment models and
posing or walking augmented in the real-world so that
they can get a sense of the real fit and get a sense of what
they will look like wearing clothes with motion in a real-
life
scene.
Figure
12
demonstrates
different
users
animated with their virtual body with augmented walking
or posing in the real-life scene.
Figure 12. Augmented walking in the real world
IV.
EVALUATION
A. Evaluation Design
We have conducted an initial experiment to evaluate our
system. The objective of our experiment is to assess whether
our 3D virtual try-on system in augmented reality benefits
users’ experience when online shopping, thereby helping
users make better purchasing decisions. To investigate users’
attitude toward the traditional shopping experience and 3D
virtual try-on with augmented walking experience, we
conduct a user study with two conditions. The Experimental
Conditions are indicated below.

Virtual try-on condition: simulate the shopping
experience with our 3D virtual try-on system.

Image only condition: simulate typical online
shopping experience with only images of garments
online.
We hypothesized that the former condition would lead to
a higher rating than the latter.
B. Participants
A total of 10 college students participated in both
condition 1 (Virtual try-on condition) and condition 2
(Image only condition). College students aged 18-30 years
are usually targeted by AR/VR applications, as they are
more likely to try new technologies and they are proactive
in online shopping for fashion products. Hence, we invited
N=10 participants (7M, 3F) to complete our evaluation, with
an average age of 22.5 years.
C. Procedure
For each participant, we personalized their human model
based on their 2D face image and 360-degree body videos.
Each participant simulated the shopping experience with two
different conditions. The order of the conditions was
randomized. After each task, participants were asked to rate
their experience (from 1 “strongly disagree” to 7 “strongly
agree”) in our questionnaire, indicated on a 7-point Likert
395
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

scale. At the end of the experiment, we interviewed
participants to gather their preferences and open-ended
feedback.
D. Measures
We measured enjoyment, convenience, and user behavior
for
the
two
conditions.
We
also
measured
whether
augmented motion in the real-life scene enhances user’s
shopping experience. The questionnaire and measurement
items are shown in Table 1.
TABLE I.
QUSTIONNAIRE AND MEASRUEMENT ITEMS
Items
Statements
Enjoyment
a. Using the system, shopping experience
was enjoyable for me.
Convenience
b. I can get a sense of how the outfit might
look for the various occasions.
c. I can get a sense of how I look wearing
these clothes.
Augmented
Walking
d. Seeing a model of me walking in the
real-world
enhanced
my
shopping
experience.
e. Having a model walking in a real
environment helps me understand more
about the appearance of the clothes.
User
Behavior
f. I want to use this system when I buy
some clothes online in the future.
E. Results
We separate the result into two sections: analysis of the
rating from questionnaires and thematic analysis of the
participants’ comments.
We analyzed the result in terms of users’ enjoyment,
convenience, augmented walking and user behavior.
(1) Enjoyment:
As
Figure
13
shows,
we
found
a
significant
main
effect
on
participants
shopping
enjoyment. A repeated measures t-test revealed a
statistically significant difference between the various
conditions P<0.01. Participants’ rated the enjoyment
significantly higher in the virtual try-on condition.
Figure 13. Participants rated their Experiences more enjoyable in the
virtual try-on condition.
(2) Convenience: We analyzed
the user convenience
through the two questions below: A. I can get a sense of
how the outfit might look for the various occasions. We
found that participants rated the virtual try-on condition
(p< 0.01) significantly higher than the other condition
(Figure. 14). B. I can get a sense of how I look wearing
these clothes. We also found that participants rated the
virtual try-on condition (p< 0.01) significantly higher,
meaning that it gave users a better feeling for how these
clothes look like on their body (Figure 15).
Figure 14. Participants rated they feel easier to get a sense of how the
outfit might look for the various occasions in the virtual try-on
condition.
Figure 15. Participants rated that virtual try-on condition gave users a
better feel for how these clothes look like on their body.
(3) Augmented Walking: To understand if the 3D virtual
try-on system within the AR scene enhances the user’s
experience, we prepared two statements:
d.
Seeing a model of me walking in the real-world
enhanced
my
shopping
experience.
Figure
16
summarizes participants’ opinions in the virtual try-
on condition.
Figure 16. All participants agree that seeing own model in the
real-world enhanced their shopping experience. 9 out of 10
participants strongly agree with it.
e.
Having a model walking in a real environment helps
me understand more about the appearance of the
clothes.
Figure
17
summarizes
participants’
opinions in the virtual try-on condition.
396
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

Figure 17. Most participants agree that the model walking in the
real environment helps them understand more about the
appearance of the clothes.
In
conclusion,
all
the
participants
agreed
that
augmented walking may enhance their shopping experience.
9 out of 10 participants rated that the virtual model walking
in the real environment helps them understand more about
the appearance of the clothes. The main reasons given were,
for example, the real environment is very realistic which
helps them to view the appearance of the garment model.
Moreover, for the participants, the virtual models walking in
the real-life scene are very interesting and can improve their
enjoyment of online shopping process. At the same time,
augmented
walking
can
also
provide
a
better
3D
visualization for users. The dynamic fitting display can
show the shape of the clothes when they are in motion and
increases the number of clothes attributes that can be
observed.
(4) User Behavior: In summary, all participants preferred
the virtual try-on condition, for both enjoyment and
convenience. We also analyzed the user behavior about
whether they want to use the virtual try-on system in
the future or not. Results suggested that 9 out of 10
participants wanted to use this system in the future
(Figure 18).
Figure 18. Most participants want to use this system when they buy
some clothes online in future.
F. Qualitative Results
At the end of the experiment, open-ended feedback was
sought from participants, and a thematic analysis was
performed on participants’ responses and their feeling of
using our 3D virtual try-on system.
Most
participants
thought
that
the
virtual
avatar
augmented walking in real world offers them a sense of
wearing clothes on their own body, which can provide users
with a better understanding of the detail of the clothes.
Moreover, augmented walking allows users to visualize
their personalized model in real world, increasing their
shopping enjoyment. P6 mentioned that the augmented
walking makes them feel like they are looking into a mirror.
P7 said that augmented walking in the real world can help
them observe more details of clothes.
Most
participants
thought
that
our
system
was
interesting. Our system can enhance users’ experience and
narrow their selections when shopping online. For instance,
P1 mentioned: “shopping online is difficult because the
model’s body shape is pretty, while actual people in real life
don’t have such a perfect body. This system shows how the
clothes look like on my body in the real-world which makes
me
have
confidence
when
buying
clothes.”
Similar
comments were received from P3 and P4.
Furthermore, the 3D virtual try-on system gives users
outfit ideas and provides more clothing information to users.
P3 thinks that 3D virtual system provides various virtual
scenes to help users with selecting clothes, especially for
special occasions. P6 mentioned that the 3D garment model
allows him to see himself wearing clothes in 360 degrees
and obtain additional clothing information than just looking
in a mirror. P7 said the virtual model walking in the real
world may help them to check how they look like in the real
wearing conditions.
We also received comments about future improvement;
P3 suggested that the material of clothes could be improved
to look more like real fabric, and P9 thought that it would be
better to use motion capture to simulate real movement of
users’ moving in the real world. The free comments from
participants are summarized below in Table2.
TABLE II.
CONCLUSION OF FREE COMMENT
Keyword
Conclusion and Comments
Augmented
walking
Judging
of
fitting:
Wearing
clothes
doing some activities in the real world
provides users with better understanding
of the detail of clothes, which allows to
better judge of fitting.
Humanoid
motion:
Using
motion
capture
technology
to
capture
user’s
movement may offer users a better sense
of “real me”.
Garment
model
Information
visualization:
The
3D
virtual try-on system gives users outfit
ideas
and
provides
more
clothing
information to users (muti-direction and
muti-angle).
Realistic garment: Garment material can
be more like real fabric.
Shopping
experience
The 3D virtual try-on system can narrow
users’ selections of clothes and increase
their purchase confidence.
Increases
the
enjoyment
of
shopping
experience.
V.
CONCLUSION AND FUTURE WORK
In this paper, we have presented a 3D virtual try-on
system to facilitate consumers in getting a better sense of
397
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

how they would look when purchasing clothes online. To
allow users to assess how well the displayed products match
their actual body, we personalized users’ own virtual avatar
corresponding to real user’s human body shape and face
features. Based on online garment images, we generated 3D
virtual garment to personalize the human body. Users can fit
their 3D user models with a selection of virtual garments,
and view the animated body in the real-life scene, as well as
various virtual scenes, to get a better sense of the dynamic
effects of the clothes. An initial evaluation reveals that the
virtual try-on system was
more enjoyable and
more
convenient than the typical experience of using images only.
Augmented walking provides an interactive, dynamic virtual
try-on experience for users, which provide users with better
understanding of the detail of clothes. The virtual avatar
wearing clothes in the real world can provide a better sense
of “true fit”, which helps users better judge of fitting.
Furthermore, most of the participants would prefer using
this system for online shopping in the future. They think
that this system can increase their purchase confidence and
solve the fit problem when shopping online.
However, our system still has certain limitations that can
be improved. In the future, we plan to enhance our clothing
animations and cloth simulation methods to provide users
with a more realistic virtual try-on effect. Motion capture
can also be used to better simulate user’s walking motion, in
order to provide a more realistic and more interactive fitting
experience.
REFERENCES
[1]
C. Garcia Martin and E. Oruklu, "Human friendly interface
design for virtual fitting room applications on android based
mobile
devices,
"
Journal
of
Signal
and
Information
Processing3,
vol.
3,
pp.
481-490,
2012.
DOI:https://doi.org/10.4236/jsip.2012.34061
[2]
H. Yamada et al., "Image-based virtual fitting system with
garment image reshaping. In 2014 International Conference
on
Cyberworlds,
"
IEEE,
pp.
47-54,
2014.
DOI:https://doi.org/ 10.1109/CW.2014.15
[3]
Y. Deng et al., "Accurate 3D Face Reconstruction with
Weakly-Supervised Learning: From Single Image to Image
Set, " In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition Workshops, 11pages, 2019.
Retrieved from https://arxiv.org/abs/1903.08527
[4]
T. Alldieck et al., "Video based reconstruction of 3d people
models, " In 2018 IEEE/CVF Conference on Computer
Vision
and Pattern
Recognition,
pp.
8387-8397,
2018.
DOI:https://doi.org/10.1109/CVPR.2018.00875
[5]
Cloth-Weaver,
https://clothweaver.com/.
[retrieved:
Oct,
2020]
[6]
Vuforia Engine, https://developer.vuforia.com/. [retrieved:
Oct, 2020]
[7]
Maximo, https://www.mixamo.com/. [retrieved: Oct, 2020]
[8]
L. Chen et al., "Encoder-decoder with atrous separable
convolution for semantic image segmentation, " In computer
vision
(ECCV
2018),
pp.
833-851,
2018.
DOI:https://doi.org/10.1007/978-3-030-01234-2_49
[9]
H. Tanaka and H. Saito, "Texture Overlay onto Flexible
Object with PCA of Silhouettes and K-Means Method for
Search into Database, "MVA, pp. 5-8, 2009.
[10] Z. Bin et al., "Garment modeling from a single image, " In
Computer graphics forum, pp. 85-91, 2013.
DOI: https://doi.org/10.1111/cgf.12215
[11] X. Han et al., "Viton: An image-based virtual try-on network,
" In 2018 IEEE/CVF Conference on Computer Vision and
Pattern
Recognition,
pp.
7543-7552,
2018.
DOI:https://doi.org/10.1109/CVPR.2018.00787
[12] M. Sekine et al., "Virtual fitting by single-shot body shape
estimation,
"
In
Int.
Conf.
on
3D
Body
Scanning
Technologies. Citeseer, pp. 406-413, 2014.
[13] Warehouse,
https://www.warehouselondon.com/row/homepage.
[retrieved: Jan, 2020]
[14] P. Decaudin et al., "Virtual garments: A fully geometric
approach for clothing design," In Computer Graphics Forum,
pp. 625-634, 2006.
DOI:https://doi.org/10.1111/j.1467-8659.2006.00982.x
[15] A. Hilsmann and P. Eisert, "Tracking and Retexturing Cloth
for
Real-Time
Virtual
Clothing
Applications,
"
In
Proceedings of the 4th International Conference on Computer
Vision/Computer
Graphics
CollaborationTechniques
Springer-Verlag,
Berlin,
Heidelberg,
pp.
94–105,
2009.
DOI:https://doi.org/10.1007/978-3-642-01811-4_9
[16] G. Pons-Moll et al ., "ClothCap: seamless 4D clothing capture
and retargeting, " ACM Transactions on Graphics vol. 36,
15pages,
2017.
DOI:https://dl.acm.org/doi/10.1145/3072959.3073711
[17] X. Chen, B. Zhou, F. Lu, L. Wang, L. Bi and P. Tan,
"Garment modeling with a depth camera, " ACM Trans.
Graph. vol. 34 , 12 pages. 2015.
DOI:https://doi.org/10.1145/2816795.2818059
[18] H&M, https://www.hm.com/. [retrieved: Oct, 2020]
[19] ZARA, https://www.zara.com/. [retrieved: Aug, 2020]
[20] D. Protopsaltou et al., "A body and garment creation method
for an Internet based virtual fitting room, " In Advances in
modelling, animation and rendering, pp. 105-122, 2002.
DOI: https://doi.org/10.1007/978-1-4471-0103-1_7
[21] D. Li et al., "Automatic three-dimensional-scanned garment
fitting
based
on
virtual
tailoring
and
geometric
sewing." Journal of Engineered Fibers and Fabrics, vol. 14,
16
pages,
2019.
DOI:
https://doi.org/10.1177/1558925018825319
[22] H. Lee and K. Leonas,
"Consumer experiences, the key to
survive in an omni-channel environment: use of virtual
technology, " Journal of Textile and Apparel, Technology and
Management, Vol. 10, pp. 1-23, 2018.
[23] M. Yuan, I. R. Khan, F. Farbiz, S. Yao, A. Niswar and M. H.
Foo, "A mixed reality virtual clothes try-on system, " IEEE
Transactions on Multimedia, vol. 15, pp. 1958-1968, 2013
DOI: https://doi.org/10.1109/TMM.2013.2280560
[24] N. Magnenat-Thalmann, B. Kevelham, P. Volino, M. Kasap
and
E. Lyard,
"3d web-based virtual try on of physically
simulated
clothes,
"
Computer-Aided
Design
and
Applications, vol. 8, pp. 163-174, 2011.
DOI: https://doi.org/10.3722/cadaps.2011.163-174
[25] Marvelous Designer, https://www.marvelousdesigner.com/.
[retrieved: Oct, 2020]
[26] 3ds Max,
https://www.autodesk.co.jp/products/3ds-max/overview/.
[retrieved: Sep, 2020]
[27] Unity3D, https://unity.com/. [retrieved: Oct, 2020]
[28] Animator Controller, https://docs.unity3d.com/Manual/class-
AnimatorController.html , [retrieved: Oct, 2020]
398
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

