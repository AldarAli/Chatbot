Increased Cognitive Load in Resolution of Problems Caused by Human Error on New 
Aircrafts 
 
Edgard  Thomas Martins  
Depto de Design- CAA 
 Universidade Federal de Pernambuco 
Recife- Pernambuco - Brasil 
edgardpiloto@gmail.com 
 
 
Abstract- The flaws in the commitment of decision-making in 
emergency situations and the lack of perception related to all 
elements associated with a given situation in a short space of 
time indicate, often, lack of situational awareness. Automation 
always surprises the crews and often prevents them from 
understanding the extent of this technology that is very 
common in aircraft units with a high degree of automation. 
These facts are discussed in a subtle way by aircraft drivers 
who can not do it openly, as it might create an impression of 
professional self-worthlessness (self-deprecation). This leads to 
common questions like: What is happening now? What will be 
the next step of automated systems? This type of doubt would 
be inadmissible in older aircraft because the pilot of those 
machines works as an extension of the plane. This scenario 
contributes to emotional disorders and a growing hidden 
problem 
in 
the 
aeronautical 
field. 
These 
unexpected 
automation surprises reflect a complete misunderstanding or 
even the misinformation of the users. It also reveals their 
inability and limitations to overcome these new situations that 
were not foreseen by the aircraft designers. Our studies 
showed a different scenario when the accident is correlated 
with systemic variables. It has identified the problems or 
errors that contribute to the fact that drivers are unable to act 
properly. These vectors, when they come together, may 
generate eventually a temporary incompetence of the pilot due 
to limited capacity or lack of training in the appropriateness of 
automation in aircraft or even,  the worst alternative, due to a 
personal not visible and not detectable non-adaptation to 
automation. We must also consider in the analysis the 
inadequate training and many other reasons, so that we can 
put in right proportion the effective participation or culpability 
of the pilot in accidents. Our doctoral thesis presents statistical 
studies that allow us to assert that the emotional and cognitive 
overload are being increased with automation widely applied 
in the cockpits of modern aircraft, and also that these new 
projects do not go hand in hand with the desired cognitive and 
ergonomic principles.  
 
    Keywords-Cognitive overload; New technologies; Automation; 
Human error. 
I. 
INTRODUCTION 
   The emotional stability and physical health of workers on 
board aircraft are faced with the factors and conditions that 
enable professionals to carry out their activities and develop 
normally, despite the fact that these conditions may present 
themselves to professionals in adverse conditions [1]. The 
modern history of aviation with its great technological 
complexity has pilots as redundant components that 
integrate embedded controls in modern aircraft. This leads 
us to say that the value of the worker as a permanent social 
group in society does not receive, currently, the proper 
priority. In research on the health of the pilot, there are three 
major perspectives that have been investigated that 
influence his stability, as well as the mental and emotional 
development of the modern airline pilot [2]:  
 
• 
The previous life of the individual directly tied to 
experience, age, genetic and physiological vectors, 
• 
The social environment, cultural environment and 
formal education leading to the final result, 
manifested by the ability, personality, strength and 
character and 
• 
The verifiable standards of quality and quantity of 
life desired, ambition and achievements and its 
effects.                    
   The Digital technology advances, has changed the shape 
and size of instruments used for navigation and 
communication. This has changed the actions of pilots, 
especially in relation to emergency procedures. There are 
few studies that correlate the reduction of accidents with the 
cognitive and technological changes. The increased 
cognitive load relates to these changes and requires 
assessment. The benefits presented by new technologies do 
not erase the mental models built, with hard work, during 
times of initial training of the aircraft career pilots in flying 
schools. 
   The public must be heeded when an aircraft incident or 
accident becomes part of the news. In search of who or what 
to blame, the pilot is guilty and immediately appointed as 
the underlying factors that involve real evidence of the fact 
they are neglected. 
   The reading of the Black-Boxes notes that 70% to 80% of 
accidents happen due to human error, or to a string of 
failures that were related to the human factor [3]. We can 
mention stress and the failure to fully understand the new 
procedures related to technological innovations linked to 
automation. Complex automation interfaces always promote 
a wide difference in philosophy and procedures for 
implementation of these types of aircraft, including aircraft 
that are different even manufactured by the same 
278
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

manufacturer. In this case, we frequently can identify 
inadequate training that contributes to the difficulty in 
understanding 
procedures 
by 
the 
crews. 
Accident 
investigations concluded that the ideal would be to include, 
in the pilot training, a psychological stage, giving to him the 
opportunity 
of 
self-knowledge, 
identifying 
possible 
"psychological breakdowns" that his biological machine can 
present that endangers the safety of flight. Would be given, 
thus, more humane and scientific support to the crew and to 
everyone else involved with the aerial activity, minimizing 
factors that cause incidents and accidents. Accident 
investigators concluded that the ideal situation for pilot 
training should include a psychological phase [4], giving 
him or her, the opportunity of self-knowledge, identifying 
possible 
"psychological 
breakdowns" 
that 
biological 
features can present and can endanger the safety of flight. It 
should be given, thus, more humane and scientific support 
to the crew and everyone else involved with the aerial 
activity, reducing factors that can cause incidents and 
accidents.  Accidents do not just happen. They have 
complex causes that can take days, weeks or even years to 
develop [5]. However, when lack of attention and / or 
neglect take place resulting in a crash, we can be most 
certain there was a series of interactions between the user 
and the system that created the conditions for that to happen 
[6]. We understand that human variability and system 
failures are an integral part of the main sources of human 
error, causing incidents and accidents. The great human 
effort required managing and performing actions with the 
interface as the task of monitoring, the precision in the 
application of command and maintaining a permanent 
mental model consistent with the innovations in automation 
make it vulnerable to many human situations where errors 
can occur.                                  
   The human variability in aviation is a possible component 
of human error and we can see the consequences of these 
errors leading to serious damage to aircraft and people. It is 
not easy, in new aviation, to convey the ability to read the 
instruments displays. This can conduct to the deficiency and 
the misunderstanding in monitoring and performing control 
tasks: lack of motivation, the fact that it is stressful and 
tiring, and generate failures in control (scope, format and 
activation), poor training and instructions that are wrong or 
ambiguous. The mind of the pilot is influenced by cognition 
and communication components during flight, especially if 
we observe all information processed and are very critical 
considering that one is constantly getting this information 
through their instruments. There is information about 
altitude, speed and position of one’s aircraft and the 
operation of its hydraulic power systems. If any problem 
occurs, several lights will light up and warning sounds 
emerge increasing the volume and type of man-machine 
communication which can diminish the perception of detail 
in information that must be processed and administered by 
the pilot. All this information must be processed by one’s 
brain at the same time as it decides the necessary action in a 
context of very limited time. There is a limit of information 
that the brain can deal with which is part of natural human 
limitation. It can lead to the unusual situation in which, 
although the mind is operating normally, the volume of data 
makes it operate in overload, which may lead to failures and 
mistakes if we consider this man as a biological machine. 
Fig. 1 shows the human-machine interaction where 
difficulties with cognitive and operational perspectives 
needs and also physical and emotional aspects take place in 
a human being during the occurrence of system-level of 
flight.    
 
 
 
 
 
 
 
 
 
 
Figure 1 - Diagram of the interaction between man and machine 
 
   All situations in which a planned sequence of mental or 
physical activities fails to achieve its desired outputs are 
considered as errors [7].  Thus, it is necessary that steps be 
taken toward reducing the likelihood of occurrence of 
situations which could cause a problem.  The flight safety 
depends on a significant amount of interpretations made by 
the pilot in the specific conditions in every moment of the 
flight. Accidents do not only occur due to pilot error, but 
also as a result of a poor design of the transmission of 
information from the external environment, equipment, their 
instruments, their signs, sounds and different messages. In 
these considerations, the human agent will always be subject 
to fatality, which is a factor that can not be neglected. 
Because of human complexity, it is difficult to convince, in 
a generic way, people with merely causal explanations. 
Further analysis of the problem will always end with the 
identification of a human error, which was probably 
originated in the design phase, at the manufacturing stage, 
or given simply as a result of an "act of God". Aeronautical 
activities, designing human-machine systems becomes very 
necessary to characterize and classify human error. Human 
activities have always been confronted with the cognitive 
system. 
II.   CONTEXTUALIZATION 
   On the result of the causality of accidents, we must 
consider the human contribution to accidents, distinguishing 
between active failures and latent failures due to the 
immediate adverse effect of the system aspect. The main 
 
279
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

feature of this component is that it is present within the 
process of construction of an accident long before declaring 
the event like an accident, being introduced by higher 
hierarchical levels as designers, responsible for maintenance 
and personnel management. We can always guarantee, with 
respect to organizational accidents, that the layers of 
defenses, that are the protective barriers, were constructed to 
prevent the occurrence of natural or man-made disasters.  
This statement is derived from the design philosophy that 
treats the defense in depth. In Fig. 2, based on the model 
"Swiss Cheese" [8], a fail of defense of an accident may 
occur as a Swiss cheese with "holes", which mean "latent 
failures" that sometimes began the construction of an 
accident long before the event. In certain circumstances, 
such failures (holes) can align themselves and then, the 
accident happens. An accident is a succession of failures. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2- Latent failures, based on the "Swiss Cheese Model" of Reason. 
 
  When these barriers are destroyed or are flawed or become 
vulnerable, the accident occurs. In this fact, that is called 
latent failure. 
 
III. CURRENT ACTIVITIES PURSUED BY THE PILOT 
AND INCREASED COGNITIVE LOAD 
 
   The following factors are an integral part of cognitive 
activity in the pilot: fatigue, body rhythm and rest, sleep and 
its disorders, the circadian cycle and its changes, the G-force 
and acceleration of gravity, the physiological demands in 
high-altitude, night-time take-offs and the problem of false 
illusion of climbing. But, other physiological demands are 
placed by the aviators. It is suggested that specific studies 
must be made for each type of aircraft and workplace, with 
the aim of contributing to the reduction of incidents arising 
from causes so predictable, yet so little studied. We must 
also give priority to airmen scientists that have produced 
these studies in physiology and occupational medicine, 
since the literature is scarce about indicating the need for 
further work in this direction. Human cognition refers to 
mental processes involved in thinking and their use. It is a 
multidisciplinary area of interest includes cognitive 
psychology, psychobiology, philosophy, anthropology, 
linguistics and artificial intelligence as a means to better 
understand how people perceive, learn, remember  and how 
people think,  because will lead to a much broader 
understanding of human behavior. 
   Cognition is not presented as an isolated entity, being 
composed of a number of other components, such as mental 
imagery, attention, consciousness, perception, memory, 
language, problem solving, creativity, decision making, 
reasoning, 
cognitive 
changes 
during 
development 
throughout life, human intelligence, artificial intelligence 
and various other aspects of  human thought [9]. 
   The procedures of flying an aircraft involve observation 
and reaction to events that take place inside the cabin of 
flight and the environment outside the aircraft [10]. The 
pilot is required to use information that is perceived in order 
to take decisions and actions to ensure the safe path of the 
aircraft all the time. Thus, full use of the cognitive processes 
becomes dominant so that a pilot can achieve full success 
with the task of flying the "heavier than air."  
   With the advent of automated inclusion of artifacts in the 
cabin of flight that assist the pilot in charge of controlling 
the aircraft, provide a great load of information that must be 
processed in a very short space of time, when we consider 
the rapidity with which changes occur, an approach that 
cover the human being as an individual is strongly need. 
Rather, the approach should include their cognition in 
relation to all these artifacts and other workers who share 
that workspace [11]. 
 
IV.   CONDITIONS FOR THE DEPLOYMENT OF THE 
TASKS LEADING TO ACCIDENTS. 
   A strong component that creates stress and fatigue of 
pilots, referred to the design of protection, detection and 
effective handling of fire coming from electrical short 
circuit on board, is sometimes encountered as tragically 
happened on the Swissair Airlines flight 111, near Nova 
Scotia on September 2, 1998. The staff of the Federal 
Aviation Administration (FAA), responsible for human 
factors research and modern automated interfaces [12], 
reports a situation exacerbated by the widespread use an 
electrical product and a potentially dangerous wire on 
aircrafts, called "Kapton".   
   If a person has to deal with an outbreak of fire, coming 
from an electrical source at home, the first thing he would 
do is disconnect the electrical power switch for the fuses. 
But this option is not available on aircraft like the Boeing 
B777 and new Airbus. The aviation industry is not 
 
280
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

adequately addressing the problem of electrical fire in flight 
and is trying to deal recklessly [13]. The high rate of 
procedural error associated with cognitive errors, in the 
automation age, suggests that the projects in aviation have 
ergonomic flaws.  In addiction, is has been related that the 
current generation of jet transport aircraft, used on airlines, 
like the Airbus A320, A330, A340, Boeing B777, MD11 
and the new A380 (see Fig. 3), that are virtually "not 
flyable" without electricity. We can mention an older 
generation, such as the Douglas DC9 and the Boeing 737.   
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
    
 
 Figure 3- The automated Airbus A380 cockpit totally dependent on 
electricity (Photos from the Collection of the author) 
                                                                                                                                     
.  Another factor in pushing the pilots that causes emotional 
fatigue and stress is the reduction of the cockpit crew to just 
two. The next generation of large transport planes four 
engines (600 passengers) shows a relatively complex 
operation and has only two humans in the cockpit. The 
flight operation is performed by these two pilots, including 
emergency procedures, which should be monitored or re-
checked. This is only possible in a three-crew cockpit or 
cockpit of a very simple operation. According to the FAA, 
the only cockpit with two pilots that meets these criteria is 
the cabin of the old DC9-30 and the MD11 series (see Fig. 
4). The current generation of aircraft from Boeing and 
Airbus do not fit these criteria, particularly with respect to 
engine fire during the flight and in-flight electrical fire. 
 
 
 
 
 
 
 
 
 
Figure 4 - The cockpit of the old Douglas MD-11 (Photos from the 
Collection of the author) 
   
   The science of combining humans with machines requires 
close attention to the interfaces that will put these 
components (human-machine) working properly. The deep 
study of humans shows their ability to instinctively assess 
and treat a situation in a dynamic scenario. A good 
ergonomic design project recognizes that humans are 
fallible and not very suitable for monitoring tasks. A 
properly designed machine (such as a computer) can be 
excellent in monitoring tasks. This work of monitoring and 
the increasing the amount of information invariably creates 
a cognitive and emotional overload and can result in fatigue 
and stress. 
   According to a group of ergonomic studies from FAA [14] 
in the United States this scenario is hardly considered by the 
management of aviation companies and, more seriously the 
manufacturers, gradually, introduce further informations on 
the displays of Glass cockpits. These new projects always 
determine some physiological, emotional and cognitive 
impact on the pilots. 
   The accident records of official institutes such as the 
NTSB (National Transportation Safety Bureau, USA) and  
CENIPA (Central Research and Prevention of Accidents, 
Brazil) show that some difficulties in the operation, 
maintenance or training aircraft, which could affect flight 
safety are not being rapidly and systematically passed on to 
crews worldwide. These professionals of aviation may also 
not be unaware of the particular circumstances involved in 
relevant accidents and incidents, which makes the 
dissemination of experiences very precarious.  
   One of the myths about the impact of automation on 
human performance: “while investment in automation 
increases, less investment is needed in human skill” [15].   
In fact, many experiments showed that the progressive 
automation creates new demands for knowledge, and 
greater, skills in humans. Investigations of the FAA [16] 
announced 
that 
aviation 
companies 
have 
reported 
institutional problems existing in the nature and the 
complexity of automated flight platforms. This results in 
additional knowledge requirements for pilots on how to 
work subsystems and automated methods differently. 
Studies showed the industry of aviation introduced the 
 
281
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

complexities of automated platforms flight inducing pilots 
to develop mental models about overly simplified or 
erroneous system operation. This applies, particularly, on 
the logic of the transition from manual operation mode to 
operation in automatic mode [17]. The process of 
performing normal training teaches only how to control the 
automated systems in normal but do not teach entirely how 
to manage different situations that the pilots will eventually 
be able to find. This is a very serious situation that can 
proved through many aviation investigation reports that 
registered the pilots not knowing what to do, after some 
computers decisions taken, in emergences situations [18].  
VARIG (Brazilian Air lines), for example, until recently, 
had no Boeing 777 simulators where pilots could  simulate 
the emergence loss of automated systems what should be 
done, at list, twice a month, following the example of 
Singapore Airlines.   
   According to FAA [19], investigations showed incidents 
where pilots have had trouble to perform, successfully, a 
particular level of automation.  The pilots, in some of these 
situations, took long delays in trying to accomplish the task 
through automation, rather than trying to, alternatively, find 
other means to accomplish their flight management 
objectives. Under these circumstances, that the new system 
is more vulnerable to sustaining the performance and the 
confidence.  This is shaking the binomial Human-
Automation compounded with a progression of confusion 
and misunderstanding. The qualification program presumes 
it is important for crews to be prepared to deal with normal 
situations, to deal with success and with the probable. The 
history of aviation shows and teaches that a specific 
emergency situation, if it has not happen, will certainly 
happen. 
 
V.   NEW FOCUS FOR PROCEED AN SYSTEMIC 
EVALUATION IN THE PERFORMANCE OF THE 
PILOTS 
 
   Evaluating performance errors, and crew training 
qualifications, procedures, operations, and regulations, 
allows them to understand the components that contribute to 
errors.  At first sight, the errors of the pilots can easily be 
identified, and it can be postulated that many of these errors 
are predictable and are induced by one or more factors 
related to the project, training, procedures, policies, or the 
job. The most difficult task is centered on these errors and 
promoting a corrective action before the occurrence of a 
potentially dangerous situation.  
   The FAA team, which deals with human factors [20], 
believes it is necessary to improve the ability of aircraft 
manufacturers and aviation companies in detecting and 
eliminating the features of a project, that create predictable 
errors. The regulations and criteria for approval today do not 
include the detailed project evaluation from a flight deck in 
order to contribute in reducing pilot errors and performance 
problems that lead to human errors and accidents. Neither 
the appropriate criteria nor the methods or tools exist for 
designers or for those responsible for regulations to use 
them to conduct such assessments. Changes must be made 
in the criteria, standards, methods, processes and tools used 
in the design and certification. Accidents like the crash of 
the Airbus A320 of the AirInter (a France aviation 
company) near Strasbourg provide evidence of deficiencies 
in the project.   
   This accident highlights the weaknesses in several areas, 
particularly when the potential for seemingly minor features 
has a significant role in an accident. In this example, 
inadvertently setting an improper vertical speed may have 
been an important factor in the accident because of the 
similarities in the flight path angle and the vertical speed in 
the way as are registered in the FCU (Flight Control Unit).    
   This issue was raised during the approval process of 
certification and it was believed that the warnings of the 
flight mode and the PFD (Primary Flight Display-display 
basic flight information) would compensate for any 
confusion caused by exposure of the FCU, and that pilots 
would use appropriate procedures to monitor the path of the 
vertical plane, away from land, and energy state. This 
assessment was incorrect. Under current standards, 
assessments of cognitive load of pilots to develop potential 
errors and their consequences are not evaluated. Besides, the 
FAA seeks to analyze the errors of pilots, a means of 
identifying and removing preventively future design errors 
that lead to problems and their consequences. This posture 
is essential for future evaluations of jobs in aircraft crews. 
   Identify projects that could lead to pilot error, 
prematurely, in the stages of manufacture and certification 
process will allow corrective actions in stages that have 
viable cost to correct or modify with lower impact on the 
production schedule. Additionally, looking at the human 
side, this reduces unnecessary loss of life. 
 
  VI.   CONCLUSION AND FUTURE WORK 
  
   We developed a study focusing on the guilt of pilots in 
accidents when preparing our thesis. In fact, the official 
records of aircraft accidents blame the participation of the 
pilots like a large contributive factor in these events. 
   Modifying this scenario is very difficult in the short term, 
but we can see as the results of our study, which the root 
causes of human participation, the possibility of changing 
this situation. The cognitive factor has high participation in 
the origins of the problems (42% of all accidents found on 
our search). If we consider other factors, such as lack of 
usability applied to the ergonomics products, choise of 
inappropriate materials and poor design, for example, this 
percentage is even higher. 
   Time is a factor to consider. This generates a substantial 
change in the statistical findings of contributive factors and 
culpability on accidents. The last consideration on this 
process, as relevant and true, somewhat later, must be 
visible solutions. In aviation, these processes came very 
slowly, because everything is wildly tested and involves 
many people and institutions. The criteria adopted by the 
official organizations responsible for investigation in 
aviation accidents do not provide alternatives that allow a 
clearer view of the problems that are consequence of 
282
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

cognitive or other problems that have originate from 
ergonomic factors. We must also consider that some of 
these criteria cause the possibility of bringing impotence of 
the pilot to act on certain circumstances. The immediate 
result is a streamlining of the culpability in the accident that 
invariably falls on the human factor as a single cause or a 
contributing factor.  Many errors are classified as only "pilot 
incapacitation" or "navigational error". Our research shows 
that there is a misunderstanding and a need to distinguish 
disability and pilot incapacitation (because of inadequate 
training) or even navigational error.  
   Our thesis has produced a comprehensive list of accidents 
and a database that allows extracting the ergonomic, 
systemic and emotional factors that contribute to aircraft 
accidents. These records do not correlate nor fall into 
stereotypes or patterns. These patterns are structured by the 
system itself as the accident records are being deployed. We 
developed a computer system to build a way for managing a 
database called the Aviation Accident Database. The data 
collected for implementing the database were from the main 
international entities for registration and prevention of 
aircraft accidents as the NTSB (USA), CAA (Canada), ZAA 
(New Zealand) and CENIPA (Brazil). This system analyses 
each accident and determines the direction and the 
convergence of its group focused, instantly deployed 
according to their characteristics, assigning it as a default, if 
the conditions already exist prior to grouping. Otherwise, 
the system starts formatting a new profile of an accident 
[21]. 
   This feature allows the system to determine a second type 
of group, reporting details of the accident, which could help 
point to evidence of origin of the errors. Especially for those 
accidents that have relation with a cognitive vector. Our 
study showed different scenarios when the accidents are 
correlated with multiple variables. This possibility, of 
course, is due to the ability of Aviation DataBase system, 
which allows the referred type of analysis.   
   It is necessary to identify accurately the problems or errors 
that contribute to the pilots making it impossible to act 
properly. These problems could point, eventually, to an 
temporary incompetence of the pilot due to limited capacity 
or lack of training appropriateness of automation in aircraft. 
We must also consider many other reasons that can alleviate 
the effective participation or culpability of the pilot. 
Addressing these problems to a systemic view expands the 
frontiers of research and prevention of aircraft accidents. 
   This system has the purpose of correlating a large number 
of variables. In this case, the data collected converges to the 
casualties of accidents involving aircraft, and so, can greatly 
aid the realization of scientific cognitive studies or 
applications on training aviation schools or even in aviation 
companies [22]. This large database could be used in the 
prevention of aircraft accidents allowing reaching other 
conclusions that would result in equally important ways to 
improve air safety and save lives.  
 
 
 
                                VII.   REFERENCES 
 
[1] C. Eugenio, Automação no cockpit das aeronaves: um precioso 
auxílio à operação aérea ou um fator de aumento de 
complexidade no ambiente profissional dos pilotos, 1rd ed.,  
vol. 1. São Paulo: Brasil, 2011, pp. 34-35. 
 
[2] E. Henriqson, “Coordination as a Distributed Cognitive 
Phenomena Situated in Aircraft Cockpits- Aviation in Focus,” 
“A Coordenação Como Um Fenômeno Cognitivo Distribuído 
e Situado em Cockpits de Aeronaves,” UFRGS edit., Porto 
Alegre, vol. 12, pp. 58 –76, Dez. 2010. 
 
[3] Federal Aviation Administration, “DOT/FAA/AM-10/13,  
Office of Aerospace Medicine, Causes of General Aviation 
Accidents and Incidents: Analysis Using NASA Aviation,”  
Safety Reporting System Data, Washington DC, U.S. 
Department of Transportation  press, Sept. 2010. 
 
[4] S. Dekker, “Illusions of explanation- A critical essay on error 
classification,” The International Journal of Aviation 
Psychology, New Jersey, vol. 13, pp. 95-106, Sept. 2003.    
 
[5] J. Reason, Human Error, 2nd ed., Cambridge: U.K., University 
Press, 1990, pp.92-93. 
 
[6] J. Rasmussen, “A taxonomy for describing human malfunction 
in industrial installations,”  The Journal of Occupational 
Accidents, vol. 4, Jul. 1982, pp. 311-333. 
 
[7] J. Reason, The Smart Human, 5rd ed., Cambridge: U.K., 
University Press, 2008, p. 347. 
 
[8] J. Reason, The Smart Human, 5rd ed., Cambridge: U.K., 
University Press, 2008, p. 347 
 
[9] R. Sternberg,  Cognitive psychology,  Porto Alegre: Brasil, Ed 
Artmed, 2000. 
 
[10] R.G. Green  and M. Frenbard, Human Factors for Pilots. 
Avebury: England, Technical Aldershot, 1993. 
 
[11] Federal Aviation Administration- FAA, “The Interface 
Between Flightcrews and Modern Flight Deck Systems,” 
Federal Aviation, Administration Human Factors Team 
Report, May 2005. pp-34-35. 
 
[12] Federal Aviation Administration- FAA, “The Interface 
Between Flightcrews and Modern Flight Deck Systems,” 
Federal Aviation, Administration Human Factors Team 
Report, May 2005, pp-177-178. 
 
[13] Federal Aviation Administration- FAA, “The Interface 
Between Flightcrews and Modern Flight Deck Systems,” 
Federal Aviation, Administration Human Factors Team 
Report, May 2005, pp 113-116. 
 
[14] Federal Aviation Administration- FAA, “The Interface 
Between Flightcrews and Modern Flight Deck Systems,” 
Federal Aviation, Administration Human Factors Team 
Report, May 2005, pp 22-28. 
 
[15] Federal Aviation Administration, “Human Error Analysis of 
Asrts Reports: Altitude Deviations in Advanced Technology 
Aircraft,” Federal Aviation Administration, Human Factors 
Team Report, 1992, 1996, 2002. 
 
[16] National Transportation Safety Board,  “Airline Service 
Quality Performance- User Manual- ASQP,” Washington, 
DC, Bureau of Transportation Statistics, U.S. Department of 
Transportation press, Oct. 2011, pp. 75-77. 
283
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
[17] National Transportation Safety Board, “Airline Service 
Quality Performance- User Manual- ASQP,” Washington, 
DC, Bureau of Transportation Statistics, U.S. Department of 
Transportation press, Oct. 2011, pp. 123-128. 
 
 [18] National Transportation Safety Board, “C.F.R.- 234 Airline 
Service Quality Performance Reports,” Washington, DC, 
Bureau of Transportation Statistics, Research and Innovative 
Technology Administration (RITA), U.S. Department of 
Transportation press, Oct. 2011, pp. 45-61. 
 
[19] Federal Aviation Administration- FAA, “Human Error 
Analysis 
of 
Accidents 
Report,” 
Federal 
Aviation 
Administration- Human Factors Team Report, 2010, pp. 201-
206. 
 
[20] Federal Aviation Administration- FAA, “Human Error 
Analysis 
of 
Accidents 
Report,” 
Federal 
Aviation 
Administration- Human Factors Team Report, 2010, pp. 108-
115. 
 
[21] E. Martins, “Ergonomics in Aviation: A critical study of the 
causal responsibility of pilots in accidents,” “Ergonomia na 
Aviação: Um estudo crítico da responsabilidade dos pilotos na 
causalidade dos acidentes,” Msc. Monography, Universidade 
Federal de Pernambuco, Pernambuco: Brasil, Mar. 2007, pp. 
285-298. 
[22] E. Martins, “Study of the implications for health and work in 
the operationalization and the aeronaut embedded in modern 
aircraft in the man-machines interactive process complex,”    
“Estudo das implicações na saúde e na operacionalização e no 
trabalho do aeronauta embarcado em modernas aeronaves no 
processo interativo homem-máquinas complexas,” thesis, 
Centro de Pesquisas Aggeu Magalhães, Fundação Oswaldo 
Cruz,  Pernambuco:Brasil, Aug. 2010, pp. 567-612. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
284
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

