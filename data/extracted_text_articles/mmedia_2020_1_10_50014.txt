AR Smart Home: a Smart Appliance Controller Using Augmented Reality 
Technology and a Gesture Recognizer
Sora Inomata  
Department of Computer Science and Engineering,  
Waseda University, Japan 
 email: masolainota@dcl.cs.waseda.ac.jp  
 
Kosuke Komiya  
Department of Computer Science and Engineering,  
Waseda University, Japan  
email: kosukekomiya@dcl.cs.waseda.ac.jp   
 
Koya Iwase  
Department of Computer Science and Engineering,  
Waseda University, Japan 
 email: chocochan_i@dcl.cs.waseda.ac.jp     
 
Tatsuo Nakajima  
Department of Computer Science and Engineering,  
Waseda University, Japan  
email: tatsuo@dcl.cs.waseda.ac.jp  
 
Abstract— 
Recently, 
smart 
speakers 
have 
become 
commercially common operation methods for controlling home 
appliances, and they have solved some of the problems with 
remote control operations. However, smart speakers also have 
some problems. For example, it is difficult to use voice 
recognition in a noisy environment. In addition, it takes a long 
time to check the current status of home appliances because 
users have to ask their smart speakers questions or give 
commands and wait for answers. To investigate other remote 
operation methods, we propose AR Smart Home, which uses the 
augmented 
reality 
technology 
and 
gesture 
recognition 
technology. Through evaluating the prototype system, we found 
that operating home appliances with gestures and interacting 
with virtual 3D home appliances instead of the actual home 
appliances are acceptable in terms of usability. 
Keywords- Augmented Reality; Smart Home; Universal 
Control 
I. 
 INTRODUCTION  
Recently, new information technologies have been 
developed to make our daily lives more comfortable and 
reduce our levels of stress. In particular, technologies based 
on the Internet of Things enable us to access various devices 
over the Internet. For example, one of the major changes in 
our daily lives is how to operate home appliances. Until now, 
we have operated various home appliances using various 
remotes. However, in such an environment, multiple remotes 
are scattered in the room, and users may lose track of where a 
required remote control is. In addition, since each remote 
control may have different operation methods, users need to 
learn each operation method and use it properly. A common 
remote control operation method is pushing buttons, but there 
are new operation methods; for example, Siri Remote [1] can 
operate an Apple TV [2] to access some video content. Users 
can move a cursor on the display or select something by 
touching or sliding on the flat panel of Siri Remote. Recently, 
smart speakers, such as Google Home [3] and Amazon Echo 
[4] have solved the problem of having multiple remotes. By 
introducing these smart speakers in our home, we can operate 
various home appliances by voice command. However, due to 
the characteristics of smart speakers, it is difficult to operate 
them in noisy environments. In addition, when users check the 
current statuses of their home appliances, it takes a long time 
to activate their smart speakers by voice and wait for the 
answers. We propose a new home appliance operation method 
that can solve these problems. 
In this paper, we propose Augmented Reality Smart Home, 
which uses the Augmented Reality (AR) technology and 
gesture recognition technology. With AR Smart Home, it is 
possible to manipulate home appliances through gestures by 
interacting with 3D virtual objects corresponding to home 
appliances displayed in the room. In addition, users can 
recognize the current status of various home appliances by 
looking at how the 3D virtual objects are operating. In this 
paper, we evaluate the operation methods of various home 
appliances using augmented reality and gestures via the 
prototype application. 
We conducted a user study to evaluate AR Smart Home 
using the prototype application. We found that the augmented 
reality technology and a gesture recognition technology for 
home appliance operation are acceptable in terms of usability. 
We also found that visual information displayed in personal 
space is preferred to be the minimum and that switching the 
operation target by gaze is intuitive. In addition, we found that 
assigning the same gestures to similar operations makes it 
easier to remember the gestures. 
This paper is divided into the following sections. Section 
II shows the background and related work of our study. 
Section III explains the system architecture of AR Smart 
Home. Section IV describes the preliminary survey we 
conducted for investigating how to apply the augmented 
reality technology in AR Smart Home. Section V describes 
the design of AR Smart Home based on the results extracted 
from the preliminary survey in Section IV. Then, we explain 
our conducted user study for evaluating the prototype 
application in Section VI. Section VII shows the results and 
the analysis of user study. Finally, we conclude and describe 
the future work in Section VIII. 
II. 
BACKGROUND AND RELATED WORK 
Recently, the augmented reality technology has been 
developed, and head-mounted displays, such as Microsoft 
HoloLens [5] and Magic Leap [6] have appeared. This 
1
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-772-6
MMEDIA 2020 : The Twelfth International Conference on Advances in Multimedia

technology is becoming more familiar in our lives. With the 
technology, virtual information can be expressed in the real 
world [12]. The development of this technology may greatly 
change the perceptions and experiences in our daily lives. 
Kim et al. [13] proposed a universal remote controller that 
consists of a touch screen, buttons, a speaker, and a haptic dial 
that returns tactile feedback. The universal remote controller 
provides a simple and intuitive operation method for users 
using the menu screen displayed on the screen and tactile 
feedback on the dial. However, the shown scenario deals with 
only one home appliance, and it is difficult to switch the 
current operation target when users operate multiple home 
appliances. 
Wang et al. [14] proposed a user-centered control system 
for home appliances that consists of a versatile infrared 
controller, a task-based web application and a server that 
communicates between the application and the controller. 
They conclude that control methods of home appliance may 
become more user-friendly and enjoyable by combining 
sensor technologies and other services. 
There are other related studies using the augmented reality 
technology for home appliance control, such as [15] and [16]. 
However, few studies have evaluated applying the augmented 
reality technology to operation methods of home appliances 
in terms of usability. 
III. 
SYSTEM ARCHITECTURE OF AR SMART HOME   
This section describes the overall architecture of the AR 
Smart Home system. 
 
Figure 1.  AR Smart Home System architecture. 
Figure 1 shows the system architecture of AR Smart Home. 
The system uses Nature Remo [7] to operate home appliances 
by sending an HTTP request. The API of Nature Remo 
receives the HTTP request, and then Nature Remo sends 
preregistered infrared signals to home appliances. The system 
also includes Microsoft HoloLens to apply the augmented 
reality technology to display 3D virtual objects corresponding 
to each home appliance in the room. In addition, the system 
includes Myo [8] for gesture interaction with 3D virtual 
objects displayed in the room. By attaching Myo to the user's 
arm, various movements of the arm can be recognized. We 
implemented an application that organizes the processes of 
displaying 3D virtual objects through HoloLens, recognizing 
gestures through Myo and sending HTTP requests to Nature 
Remo. The application is implemented by Unity [9] and C#. 
The application uses the toolkit of Myo for the Myo gesture 
recognition and Mixed Reality Toolkit [10] for the HoloLens 
gesture 
recognition. 
The 
application 
also 
uses 
UnityWebSocket [11] for sending a HTTP Request. The 
sequence of the system is summarized as follows. 
(1) The user performs a gesture in front of a 3D virtual 
object displayed through HoloLens. 
(2) The application recognizes the gesture and sends a 
HTTP request to Nature Remo. 
(3) Nature Remo receives the HTTP request and sends a 
preregistered infrared signal. 
(4) The target home appliance receives the infrared signal 
and performs the defined operation. 
In the early prototype, 3D home appliance objects 
corresponding to four home appliances (display, air 
conditioner, audio speaker, and lighting) are displayed in front 
of the user. The “air tap” gesture, which is bending the index 
finger in the user’s sight, is implemented as an operation 
method activated by a gesture. Users “air tap” the 3D virtual 
object for it to display "Power On", "Volume Up", or other 
buttons above the object. Users “air tap” the button again to 
end the operation of the corresponding home appliance. 
Figure 2 shows the use of the early prototype.  
 
Figure 2.  Using the early prototype application. 
In Figure 2, the user is turning on the display by “air tapping” 
the button above the 3D virtual object displayed. 
IV. 
PRELIMINARY SURVEY  
We conducted a preliminary survey to investigate how to 
apply augmented reality technology for AR Smart Home. This 
section describes our survey. We conducted the survey 
according to the following steps. First, an overview of AR 
Smart Home is given to participants and then they learned 
about the concept by watching a video and using the early 
prototype application. After that, participants answered 
questionnaires. Figure 3 shows a subject using the early 
prototype. In the preliminary survey, questionnaires were 
conducted on 78 people. 
The contents of the questions are as follows. 
(1) What kind of 3D virtual objects would be useful to 
represent home appliances? 
(2) What functions would be useful on screens and operation 
methods? 
2
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-772-6
MMEDIA 2020 : The Twelfth International Conference on Advances in Multimedia

Table 1 shows the answers to Question 1, and Table 2 
shows the answers to Question 2. 
 
Figure 3.  Using the early prototype application in a preliminary survey. 
TABLE I.  
THE ANSWERS TO QUESTION 1. 
Answers 
Num 
3D virtual objects of home appliances  
12  
Animated characters with the same characteristics  
as home appliances  
11  
Other objects with characteristics similar to those of home 
appliances  
5  
3D virtual objects identified by color  
3  
Control panels of home appliances  
3  
Illustration of home appliance  
2  
Special tools and control panels based on fictional devices  
2  
Others  
11  
TABLE II.  
THE ANSWERS TO QUESTION 2. 
Answers 
Num 
Feedback effects indicating control and appliance status  
13  
Large and simple screens for users to easily recognize objects  
10  
Customization function that allows you to move an object  
to a desired position  
8  
Screens where all objects are visible  
2  
Application of AI assistants  
2  
Others  
10  
In Question 1, we investigated what kind of 3D virtual 
objects are suitable to represent actual home appliances. The 
most common answer was “3D virtual objects of home 
appliances corresponding to actual home appliances” because 
users can easily understand what they are operating.  
In Question 2, we investigated the required functions of 
the operation screen and operation method in AR Smart Home. 
The most common answers were “a function for displaying 
feedback on user's input and effects indicating the current 
status of home appliances” and “a function for placing 3D 
virtual objects in a desired position”. There were also many 
responses, such as “3D virtual objects should be simple, large 
and easy to look at”. 
V. 
DESIGN OF AR SMART HOME  
We improved the early prototype described in Section III 
in terms of the operation screen and the operation method 
based on the results of the preliminary survey described in 
Section IV. This section describes the improved design of AR 
Smart Home. It is assumed that home appliances operated 
with AR Smart Home can be operated with a remote control 
without touching the actual appliances, such as air 
conditioners, TVs, audio speakers, fans, lighting, and curtains. 
Figure 4 shows the use of the prototype application. 
 
Figure 4.  Using the prototype application. 
Figure 5 shows a screen of the prototype application. 
Based on the results of the preliminary survey, we applied 3D 
virtual objects that are the same shape as the actual home 
appliances. These 3D virtual objects are white in their initial 
state.  
 
Figure 5.  A screenshot of the prototype application. 
 
Figure 6.  Placing a 3D virtual object. 
3
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-772-6
MMEDIA 2020 : The Twelfth International Conference on Advances in Multimedia

The 3D virtual objects can be placed at the desired position 
by the user moving his or her hand and "air tapping" while 
putting the cursor on the target. In addition, the 3D virtual 
objects can be rotated by the user moving his or her hands and 
"air tapping" while putting the cursor on the target. Figure 6 
shows how a user places a 3D virtual object. 
Users can deliver commands to the target by performing 
gestures while placing the cursor displayed in the center of the 
sight on the target; then, the operation of the corresponding 
home appliance is completed. Table 3 shows the names of the 
gestures and their descriptions. Table 4 shows the 
correspondence of gestures to the operations of the home 
appliances. 
Users can view the results of the operations and the current 
status of home appliances by seeing feedback. First, we 
describe the feedback related to the results of the operations. 
When the cursor is placed on the object and the object is 
selected as the operation target, the object changes from the 
original color to yellow. When the cursor is removed, the 
object returns to the original color. As shown in Table 4, 
“wave right” has the effect of increasing the volume or 
temperature of a target, and “wave left” has the effect of 
decreasing them. Therefore, when “wave right” is performed, 
the effect of red particles rising from the bottom of the target 
is displayed. Additionally, when “wave left” is performed, the 
effect of blue particles descending from the top of the target is 
displayed. Figure 7 shows the effects displayed when each 
gesture is performed. In Figure 7, the top figure shows the 
effect of raising the temperature on the air conditioner, and the 
bottom figure shows the effect of lowering the temperature on 
the air conditioner. 
 Next, we describe the feedback related to the current 
status of home appliances. As shown in Table 4, each home 
appliance can be turned on by performing “make a fist”. So 
that users can immediately recognize whether the power is 
turned on by looking at the object, the object turned on by 
performing “make a fist” changes green. When the object is 
turned off by performing “make a fist”, the object returns to 
the original color. An air conditioner has a cooling mode and 
a heating mode, and users cannot recognize which mode an 
air conditioner is in unless they feel the temperature on their 
skin. To make it easier to recognize which mode an air 
conditioner is in, the object becomes red when heating is set, 
and the object becomes blue when cooling is set. 
 In addition, the volume, fan speed, set temperature, and 
other states are displayed in text on the panel that is displayed 
above the object when the cursor displayed in the center of the 
sight is placed on the object. 
TABLE III.  
GESTURES FOR OPERATING APPLIANCES. 
Gestures  
Descriptions  
Make a fist 
making a fist  
Wave right 
bending a wrist to the right  
 
Wave left 
bending a wrist to the left  
 
Double-Tap 
tapping an index finger and middle finger twice  
Spread  
fingers 
spreading fingers  
 
 
 
 
TABLE IV.  
CORRESPONDENCE OF GESTURES AND OPERATIONS. 
Appliances  
Operations  
Gestures  
Air Conditioner  
turning on the power  
Make a fist  
 
raising the temperature  
Wave right  
 
lowering the temperature  
Wave left  
 
switching mode  
(heating, cooling)  
Spread fingers  
  
 
switching fan speed  
(low, medium, high)  
Double-Tap  
  
Television  
turning on the power  
Make a fist  
 
increasing the volume  
Wave right  
 
decreasing the volume  
Wave left  
 
switching to  
the next channel  
Double-Tap  
  
Audio Speaker  
turning on the power  
Make a fist  
 
increasing the volume  
Wave right  
 
decreasing the volume  
Wave left  
Fan  
turning on the power  
Make a fist  
 
switching fan speed  
(low, medium, high)  
Double-Tap  
  
Lightning  
brightening / darkening  
Make a fist  
Curtains  
opening / closing  
Make a fist  
 
 
Figure 7.  Effects of 3D virtual objects. 
VI. 
USER STUDY  
This section describes the user study we conducted to 
evaluate the prototype application. To evaluate the operation 
method using the augmented reality technology and gesture 
recognition technology, we conducted the user study without 
actually sending requests to home appliances. It was assumed 
that the home appliances were working as expected in the user 
study. In the user study, 10 participants aged 21-27 years 
participated. We conducted the user study according to the 
following steps. First, participants were told about the concept 
of this study and how to use the prototype application. After 
wearing the HoloLens and the Myo device, they customized 
4
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-772-6
MMEDIA 2020 : The Twelfth International Conference on Advances in Multimedia

the location of 3D virtual objects representing home 
appliances and operated the prototype application according 
to the given scenario. Finally, they answered a questionnaire 
using a 5-level Likert scale and answered questions in a semi-
structured interview. To evaluate the usability of the system, 
we used the System Usability Scale (SUS) questionnaire [17]. 
The scenario given when participants operated the prototype 
application is as follows. 
(1) You open the door of your room. Since the room is 
dark, you turn on the light in front of the door.  
(2) Since you feel cold, you turn on the air conditioner 
and set the mode to the heating mode, the temperature 
to 20 degrees and the fan speed to medium.  
(3) You want to watch a news program, so you turn on 
the TV and set the volume to 20.  
(4) After finishing watching TV, you turn off everything 
and go to bed.  
VII. RESULSTS AND ANALYSIS  
This section describes the results of the user study 
described in Section VI and the analysis. We used the SUS 
questionnaire to evaluate the usability of the system. Table 5 
shows the SUS items of the questionnaire. Figure 8 shows the 
average score for each question. The average SUS score was 
70.0. According to [18], this average was within the 
acceptable range. We found that the usability of the prototype 
application was acceptable in terms of satisfaction. 
TABLE V.  
SUS QUESTIONNAIRE ITEMS. 
ID  
Questionnaires  
Q1  
I think that I would like to use this system frequently.  
Q2  
I found the system unnecessarily complex.  
Q3  
I thought the system was easy to use.  
Q4  
  
I think that I would need the support of a technical person to be 
able to use this system.  
Q5  
I found the various functions in this system were well integrated.  
Q6  
I thought there was too much inconsistency in this system.  
Q7  
  
I would imagine that most people would learn to use this system 
very quickly.  
Q8  
I found the system very cumbersome to use.  
Q9  
I felt very confident using the system.  
Q10  
  
I needed to learn a lot of things before I could get going with this 
system.  
TABLE VI.  
OUR QUESTIONNAIRE ITEMS. 
ID  
Questionnaires  
Q11  
Could you use the system without being stressed?  
Q12  
  
Is it suitable that the 3D home appliance object is displayed for 
interaction?  
Q13  
Is the feedback scale suitable?  
Q14  
Is it easy to switch home appliances by switching your gaze?  
Q15  
Did you use the gestures you learned as you intended?  
In addition, we used some questions that we developed. 
Table 6 shows these items of the questionnaire. Figure 9 
shows the average score for each question. 
We provide the responses to each question that was raised 
in the interview after the questionnaire. 
 
 
Figure 8.  Scores for the SUS questionnaire. 
 
Figure 9.  Scores for our questionnaire items. 
In Q11, we investigated whether participants experienced 
stress when using the prototype application. Many of the 
participants who gave a relatively low score said, “There was 
something wrong due to the low recognition accuracy of Myo, 
but there was no stress about the use of gestures as operations 
if the accuracy was good.” The system relies on the Myo 
function for gesture recognition, so it may be necessary to 
consider using another device to improve the accuracy of 
gesture recognition; however, we found that there is no stress 
in operating home appliances with gestures. 
In Q12, we investigated whether it is appropriate to use 
3D virtual objects representing home appliances instead of 
actual home appliances as the interaction target. The most 
common response was “It is intuitive and appropriate.” In 
addition, there were responses, such as “The light object did 
not look like a light.” and “It was difficult to adjust the line of 
sight to the light object compared to other objects because the 
light object was slender.” It is necessary to improve the system 
by selecting objects in consideration of operability, such as 
selecting objects with wide shapes. 
In Q13, we investigated whether the size scale of 3D 
virtual objects and the feedback displayed in the screen were 
appropriate. Most of the participants responded “I don't like 
displaying objects and feedback with ornate decorations in my 
room, so the simplicity of the system was just right.” There 
was also the related response of “It is better to display them 
only when they are needed.” We found that people usually 
prefer minimum visual information displayed in personal 
space, such as a room where people usually live. 
In Q14, we investigated whether the method of switching 
the operation target by switching the line of sight is 
-1
1
3
5
Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8
Q9
Q10
Score
Question Number
-1
1
3
5
Q11
Q12
Q13
Q14
Q15
Score
Question Number
5
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-772-6
MMEDIA 2020 : The Twelfth International Conference on Advances in Multimedia

appropriate. Most of the participants responded that “It was 
easier to switch by line of sight than to change the remote 
control.” There was also a response that “I would look at the 
operation target even if I use the remote control”. We found 
that switching the operation target by gaze is intuitive. 
In Q15, we investigated whether users can remember 
some gestures and use the gestures in their daily lives. Most 
of the participants responded that “If I get used to the system, 
I can handle gestures.” There are similar operations in the 
operation of various home appliances, such as “turning on the 
power” and “raising and lowering something”. We found that 
assigning the same gestures to similar operations makes it 
easier for users to remember and handle the gestures even if 
there are multiple gestures. There was also a response that 
“Human errors are likely to occur less often with gesture 
operations than with remote control operations.” In remote 
control operations, various operations are performed by 
pressing a button. On the other hand, operation methods using 
several gestures can be easily distinguished from one other, 
and errors due to human recognition can be reduced. 
In the interview, we also asked the question, "How would 
you place objects of home appliances in your room?". The 
most common response was "I would place them close 
together because when I look at them, I can operate various 
home appliances." One of the strengths of using augmented 
reality technology is that we can replace home appliances that 
have physical constraints with 3D virtual objects and place 
them at any position in the room without fear of them being 
lost. 
VIII. CONCLUSIONS AND FUTURE WORK  
In this paper, we proposed AR Smart Home, which uses 
augmented reality technology and gesture recognition 
technology. We also evaluated the prototype application by a 
user study. Using gestures to operate home appliances is not 
stressful, and it is intuitive to interact with 3D virtual objects 
representing home appliances instead of actual home 
appliances, so the system is acceptable in terms of usability. 
We found that visual information displayed in personal space 
is preferred to be the minimum and that switching the 
operation target by gaze is intuitive. In addition, we found that 
assigning the same gestures to similar operations makes it 
easier to remember the operation gestures. 
In the next step, we would like to remove various 
constraints in the current design. In the current design, 
gestures that can be recognized are limited to those recognized 
by Myo and HoloLens. By implementing other gestures, it 
will be possible to incorporate many other current remote-
control operations. Then, it will be necessary to investigate 
how many gestures users can remember and use in daily life. 
In the research, we conducted the user study on the premise 
that users can use augmented reality technology and gesture 
recognition technology in their daily life. However, users have 
to equip some devices in order to use the system and it may 
limit the comfort. In this aspect, we should conduct more 
study. In addition, a function that can customize the 
correspondence between operations and gestures will be 
necessary. It may also be necessary for users to be able to 
define various shapes of objects for the operation target, as 
there are various shapes of home appliances. Depending on 
the user's mood, arranging various objects and creating a 
favorite room can make the prototype more enjoyable to use. 
REFERENCES  
[1] Apple 
Inc, 
“Siri 
Remote 
– 
Apple”, 
https://www.apple.com/shop/product/MQGD2LL/A/siri-remote, 
[Dec. 2019].  
[2] Apple Inc, “TV - Apple”, https://www.apple.com/tv/, [Dec. 2019].  
[3] Google, “Google Home - Smart Speaker & Home Assistant – 
Google Store”, https://store.google.com/product/google_home, 
[Dec. 2019].  
[4] 
Amazon.com, Inc, “Amazon.com: Echo (2nd Generation) International 
Version 
– 
Charcoal 
Fabric: 
Amazon 
Devices”, 
https://www.amazon.com/Echo-2nd-Generation-International-
Version/dp/B075RSCZHD, [Dec. 2019].  
[5] Microsoft, “Microsoft HoloLens | Mixed Reality Technology 
fo 
Bussiness”, 
https://www.microsoft.com/en-us/hololens, 
[Dec. 2019].  
[6] Magic 
Leap 
Inc, 
“Home 
| 
Magic 
Leap”, 
https://www.magicleap.com/, [Dec. 2019].  
[7] Nature 
Inc, 
“Nature 
Remo 
- 
Nature”, 
https://nature.global/en/top, accessed [Dec. 2019].  
[8] North 
Inc, 
“Welcome 
to 
Myo 
Support”, 
https://support.getmyo.com/hc/en-us, [Dec. 2019].  
[9] Unity Technologies, “Unity Real-Time Development Platform 
| 3D, 2D VR &amp; AR Visualizations”, https://unity.com/, 
[Dec. 2019].  
[10] Microsoft, 
“Getting 
started 
with 
MRTK 
v2”, 
https://docs.microsoft.com/ja-jp/windows/mixed-reality/mrtk-
getting-started, [Jan. 2020].  
[11] Unity 
Technologies, 
“UnityWebRequest”, 
https://docs.unity3d.com/ja/2017.4/ScriptReference/Networki
ng.UnityWebRequest.html/, [Jan. 2020].  
[12] R. T. Azuma, “A Survey of Augmented Reality”, Presence: 
Teleoperators and Virtual Environments, Vol. 6, Issue. 4, pp. 
355–385, August 1997.  
[13] L. Kim, W. Park, H. Cho, and S. Park, “An universal remote 
controller with haptic interface for home devices”, 2010 Digest 
of Technical Papers International Conference on Consumer 
Electronics (ICCE), Las Vegas, pp. 209-210, 2010.  
[14] D. Wang, K. Sugiura, and Y. Murase, “Design and 
Implementation of User-centered Home Appliance Controlling 
Service Environment”, MoViD'14 Proceedings of Workshop 
on Mobile Video Delivery, No. 7, pp. 7:1-7:6, 2014.  
[15] S. Mihara, K. Kawai, H. Shimada, and K. Sato, "EVANS 3: 
Home appliance control system with appliance authentication 
framework using Augmented Reality technology," 2013 IEEE 
10th Consumer Communications and Networking Conference 
(CCNC), Las Vegas, pp. 849-850, 2013.  
[16] R. Umeyama, and H. Suzuki, "iHAC: Smart appliance 
controller using AR technology," 2017 IEEE International 
Conference on Consumer Electronics (ICCE), Las Vegas, pp. 
168-169, 2017.  
[17] J. Brooke, “SUS : A quick and dirty usability scale”, Taylor & 
Francis, Usability Evaluation in Industry, pp. 189-194, 1996.  
[18] A. Bangor, P. Kortum, and J. Miller, "Determining what 
individual SUS scores mean: adding an adjective rating scale", 
Journal of Usability Studies, vol. 4, Issue. 3, pp. 114-123, May 
2009
 
6
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-772-6
MMEDIA 2020 : The Twelfth International Conference on Advances in Multimedia

