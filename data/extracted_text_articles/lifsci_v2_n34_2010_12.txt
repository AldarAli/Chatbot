 
Figure 1. Enterprise levels as defined in VDI 5600 [6]. 
A Process Model for Establishment of Knowledge-Based  
Online Control of Enterprise Processes in Manufacturing 
 
Daniel Metz, Sachin Karadgi, and Manfred Grauer 
Information Systems Institute, 
University of Siegen, 
Siegen, Germany 
Email: {metz, karadgi, grauer}@fb5.uni-siegen.de 
 
 
Abstract - Today’s enterprises are operating in a complex and 
volatile business environment. To address this situation, 
enterprises endeavor to realize horizontal and vertical 
integration of enterprise processes (i.e., business and 
manufacturing processes) leading to a real-time enterprise. 
Research has been carried out in integrating data generated 
from automation devices in (milli) seconds and transactional 
data from business applications, referring to long time 
horizons (e.g., days).  However, this integrated data is not used 
extensively for online control of enterprise processes. 
Therefore to overcome this issue, a process model is presented 
for identification and assimilation of knowledge.  This process 
model comprises four steps: (i) analysis and (re-) design of 
enterprise processes to be controlled, (ii) creation of enterprise 
data model and data flow diagrams for automation devices and 
business applications, (iii) (offline) knowledge identification 
based on knowledge discovery in databases process, and (iv) 
online monitoring and control of enterprise processes using 
complex event processing. The envisaged process model is a 
prerequisite for implementation of IT-framework used for 
online monitoring and control of enterprise processes. Both, 
the process model and the corresponding IT-framework have 
been implemented and validated in a casting enterprise. 
Keywords - enterprise integration, knowledge discovery in 
databases, 
data 
mining, 
online 
control, 
complex 
event 
processing. 
I. 
 INTRODUCTION 
The business environment of an enterprise has become 
complex, volatile and mainly driven by uncertainties [1]. In 
addition, pressure on an enterprise to manufacture 
components with high quality, reduced lead time and low 
cost has been intensified. As a consequence, relevant 
enterprise (value creation) processes (i.e., business and 
manufacturing processes) have to be flexible, adaptable and 
controlled online. In this regard, the integration of enterprise 
processes in horizontal and vertical direction of an enterprise 
has become indispensable. Available enterprise application 
integration (EAI) systems can be used to horizontally 
integrate existing business applications like enterprise 
resource planning (ERP) systems, supply chain management 
(SCM) systems, and customer relationship management 
(CRM) systems [2]. Along with this horizontal integration, 
vertical integration of different enterprise levels can be seen 
as a prerequisite for establishing online control of enterprise 
processes [3], and the vision of a real-time enterprise (RTE) 
[4][5].  
According to German standard VDI 5600 [6], an 
enterprise can be classified into different manufacturing 
execution system (MES) levels as illustrated in Figure 1: (i) 
enterprise control level, (ii) manufacturing control level, and 
(iii) manufacturing level. VDI 5600 focuses on the problems 
and benefits related to MES. Similarly, standards like IEC 
62264 [7] are available and emphasis on realization of MES. 
In the current contribution, various terminologies are based 
on VDI 5600. 
At enterprise control level, business processes are 
performed to achieve the enterprise‟s long term strategies. 
Thus, business processes can be designed, configured, 
enacted, and analyzed applying four steps of a business 
process management (BPM) life cycle: (i) business process 
design, (ii) business process configuration, (iii) business 
process enactment, and (iv) business process diagnosis 
[8][9]. Process-aware information systems (PAIS) like 
workflow management systems (WMS) are in charge to 
invoke business applications (e.g., ERP system) and (web) 
services along a workflow execution (i.e., automation of a 
business process) to fulfill certain enterprise‟s strategic 
objectives [8][9]. During business process enactment at 
enterprise control level, planned performance values (i.e., 
TO-BE values) are generated offline (i.e., in months or 
weeks) and further, these values are transactional [10]. 
On the contrary, manufacturing processes are employed 
to accomplish the objectives set at the enterprise control 
188
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

level. Automation devices are available at manufacturing 
level to execute manufacturing processes. Enormous amount 
of data (e.g., sensor data) is generated by these devices 
during execution of manufacturing processes in real-time 
(i.e., seconds or milliseconds). In addition, operators provide 
necessary data related to automation devices or orders like 
pre-defined reasons for a resource breakdown, order details 
during start of order execution, and so forth. Overall, these 
values (i.e., AS-IS values) indicate the actual performance at 
the manufacturing level. 
MES solutions and business process applications are 
available to achieve computerized and automated vertical 
integration at certain MES levels [11]. However, major 
problems still remain open with respect to the interface 
between the enterprise control level and the manufacturing 
level [12]. More precisely, the realization of enterprise-wide 
multi-loop control within and across all levels from 
enterprise control level to manufacturing level is not 
adequately achieved [10][12]. Also, inadequate vertical 
integration hinders the establishment of enterprise-wide 
knowledge and learning cycles [13]. First, data from 
different MES levels is not adequately integrated and thus, it 
cannot be exploited to identify new knowledge. Second, if 
any new knowledge has been derived, it is not incorporated 
in online control of enterprise processes. As a consequence, 
concepts of RTE: sense-and-respond and learn-and-adapt are 
integrated insufficiently into enterprise processes [14]. 
The current contribution is based on the IT-framework 
for digital enterprise integration [13], and presents a 
methodology 
for 
identification 
and 
assimilation 
of 
knowledge for online control of enterprise processes in 
manufacturing. State-of-the-art on enterprise integration (EI), 
monitoring and control of enterprise processes, and data 
mining in manufacturing is summarized in Section II. A 
novel methodology is elaborated in Section III to establish 
enterprise-wide knowledge and learning cycles for online 
control of enterprise processes. Section IV describes an 
industrial case study. Finally, conclusion and future work are 
discussed in Section V. 
II. 
 STATE-OF-THE-ART 
The methodology elaborated in Section III is based on 
various concepts like EI and data mining. Therefore, the 
current section summarizes state-of-the-art research in the 
area of EI, enterprise data model, identification of 
knowledge, and utilization of knowledge for online 
monitoring and control of enterprise processes. 
Around 
the 
mid 
1990‟s, 
several 
EI 
reference 
architectures (e.g., CIMOSA, PERA, ARIS and GRAI/GIM) 
were available to guide the design and implementation of an 
integrated enterprise [15]. However, these reference 
architectures were different in terms of their theoretical 
background [15], and enterprise understanding, modeling 
approaches, and purposes [16]. Hence, GERAM - 
generalized 
enterprise 
reference 
architecture 
and 
methodology has been developed to address these 
differences [17]. Aforementioned reference architectures 
have contributed in defining GERAM and later, it was 
standardized as ISO 15704 - requirements for enterprise 
reference architecture and methodologies [18]. 
The reference architectures mentioned above do not 
reveal how to realize them in terms of technologies. Apart 
from enterprise reference architectures, several software 
vendors have developed MES solutions to bridge the vertical 
integration gap between MES levels, like MES-HYDRA 
[11]. But also with MES, the exchange of data between MES 
levels is done manually or at most semi-automatically due to 
inflexible and proprietary interfaces [12][19]. 
An agent-based production monitoring and control 
system (PMC) based on the JADE framework was 
elaborated [20]. The PMC Provis.Agent integrates various 
IT-systems and machine control devices, and establishes the 
use of information between various systems (e.g., for 
visualization). Also, NIIIP-SMART architecture provides 
horizontal and vertical integration, and interoperation 
utilizing workflow, enterprise rules, agents and STEP [21]. 
Service orientation (especially by means of web and grid 
service technology and their corresponding standards) has 
been used for EAI [22]. In service oriented architecture 
(SOA), business applications offer their functionalities as 
services. These services can be loosely coupled and 
orchestrated to complex workflows. Because of the loosely 
coupled structure, the realized IT-architecture is flexible and 
adaptable. Hence, European-funded projects SIRENA [23] 
and SOCRADES [24] aim to exploit this SOA paradigm to 
seamlessly integrate heterogeneous resources located at 
manufacturing level with business applications at enterprise 
control level. In this regard, a prototype for vertical 
integration of SOA-ready devices with SAP MII was 
presented [5]. Unlike the predominant request-reply 
communication approach of traditional SOA, an enterprise 
has to react to events online, and hence, necessitates 
implementation of publish-subscribe mechanism [25]. 
However, this doesn‟t make SOA obsolete as SOA and event 
processing are complementary concepts for achieving 
modularity, loose-coupling, and flexibility [26]. 
Enterprise data model is necessary to enable EI, i.e. to 
relate TO-BE and AS-IS values from different MES levels. 
IEC 62264-2 [7] describes models and terminologies that 
enable to implement enterprise control between enterprise 
control level and manufacturing control level. Further, this 
standard can be augmented with various technical models 
like DIN EN 61512-2 [27]. An MES database structure for 
system integration was analyzed with respect to resource, 
system plans, system status and system configurations [28]. 
A factory data model was defined to represent strategic 
intent, capability, organization structure and behavior of an 
enterprise [29]. This factory data model consists of strategy, 
facility, process, resource, token and flow classes. The token 
classes represent physical flow of material (e.g., work piece, 
invoice). Flow classes represent links to token classes and 
process classes. 
Knowledge is embedded into enterprise processes by 
enterprise members (i.e., know-who) in form of know-what, 
know-why, and know-how [30]. However, this knowledge is 
tacit and context-specific. This knowledge is externalized by 
enterprise members and can be expressed by means of 
189
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 2. IT-framework for digital enterprise integration (adapted from [13]). 
enterprise process data (i.e., TO-BE values). These process 
data are updated online during execution of enterprise 
processes in terms of feedbacks (i.e., AS IS values). TO-BE 
and AS-IS values from different MES levels are integrated 
for online control of enterprise processes [13][31]. These 
integrated values are stored in a relational database as 
historical data, which is periodically exploited in offline 
processes to calculate key performance indicators (KPIs) and 
overall equipment effectiveness (OEE), among others. 
Extensive research has been carried out to convert tacit 
knowledge embedded in processes into explicit knowledge 
using analytical methods (e.g., data mining), but this research 
focuses mostly on transactional data (e.g., finance, sales) at 
the enterprise control level (e.g., [32]). Around 7% of data 
mining methods are utilized to address problems in 
manufacturing [33]. This limited usage of data mining in 
manufacturing enterprises originated in the perception of 
relatively high efforts to achieve EI [33]. Nonetheless, data 
mining methods have been used in manufacturing domains 
like manufacturing system, and maintenance [34][35].  
A decision making process related to enterprise process 
control can be a complex task spread across different MES 
levels, and depends upon the quantity and quality of 
information. In this regard, a framework for organizing and 
applying knowledge for decision making in manufacturing 
and service applications was elaborated [36]. The decision 
making process was supported with the knowledge derived 
using data mining algorithms. 
European-funded project K-NET (sub-project of Future 
Internet Enterprise Systems (FInES) cluster) has presented 
an approach at a conceptual level to enhance, monitor and 
reuse of knowledge in a networked enterprise [37]. In 
addition, an enterprise modeling and integration framework 
was presented based on knowledge discovery in databases 
(KDD) by extending the views of CIMOSA i.e., adding 
knowledge and mining views [38]. In most of the enterprises, 
explicit knowledge is codified as rules managed in rule-
based systems (RBS) [39]. 
RBS like Drools Expert [40] are often lacking in taking 
temporal and causal relations between events into account. 
As a consequence, research attempts are been made to 
employ the externalized knowledge for creating event 
patterns utilized in a complex event processing (CEP) 
engine. Unified event management architecture was 
conceptualized to deal with primitive and complex events for 
monitoring and control of manufacturing processes [41]. 
Nonetheless, the architecture is positioned at manufacturing 
control 
level 
and 
integrates 
real-time 
data 
from 
manufacturing level but neglects to integrate transactional 
data from enterprise control level. Further, architecture for an 
extensible 
event-driven 
manufacturing 
system 
was 
elaborated [42]. This architecture was built on a MES 
solution with a tight integration with enterprise control level 
and manufacturing level, and utilized CEP engine to manage 
events triggered in manufacturing level. However, the 
presented 
approach 
does 
not 
address 
knowledge 
identification required to define event patterns. 
System Insights provides an open source framework for 
online monitoring and analysis of manufacturing enterprises 
[43]. The framework constitutes following components - 
data delivery, data collection, and data analysis. Data 
delivery from different devices is achieved through 
MTConnect standard and MTConnect data bus. Data is 
stored in (high speed) databases using functionality of data 
collection. For control of enterprise processes, data analysis 
is performed online utilizing the services of EsperTech [44] 
or Drools Fusion [45] CEP engines. Also, the stored data is 
utilized offline to calculate various metrics. 
III. 
METHODOLOGY 
 An IT-framework for digital enterprise integration was 
articulated [13][31]. This framework utilizes tracking objects 
along with a RBS. However to consider the temporal and 
causal relations between events triggered across various 
MES levels, it is essential to replace RBS with state-of-the-
art CEP engine. On basis of this framework, a methodology 
190
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 3. Flow of process data and control data in IT-framework for 
digital enterprise integration. 
is elaborated for identification and assimilation of knowledge 
for online control of enterprise processes. This methodology 
encompasses following components: (i) enterprise process 
analysis, (ii) enterprise data model and data flow diagram, 
(iii) knowledge identification, and (iv) assimilation of 
knowledge for online control of enterprise processes. In the 
following subsections, the aforesaid IT-framework is 
introduced in brief and further, the components of the 
methodology are elaborated. 
A. Overview of IT-Framework for Digital Enterprise 
Integration 
An architectural overview of the IT-framework for digital 
enterprise integration is illustrated in Figure 2. In addition, 
flow of process data and control data between various 
components of this IT-framework is depicted in Figure 3. 
The IT-framework is based on available standards (e.g., ISO 
15704 [18], IEC 62264 [7]), technologies and paradigms 
(e.g., SOA paradigm) and involves various IT-systems (e.g., 
ERP system). Enterprise processes are instantiated from 
predefined workflow patterns (see Step 1 in Figure 3) and are 
supplied with necessary planned performance or process 
values (i.e., TO-BE values) from business applications like 
ERP systems (see Figure 2 and Step 2 in Figure 3). Business 
applications or at least their crucial functionality in a certain 
context (e.g., accessing planned performance values) are 
made available as services within an SOA. 
As one of the purposes of the IT-framework is online 
control of enterprise processes, publish-subscribe mechanism 
usually applied in event-driven architectures (EDA) is 
implemented. EI layer subscribes to the events triggered by 
manufacturing resources (i.e., automation devices) at the 
manufacturing level. Three-tier architecture for physical 
integration has been implemented to collect data from these 
manufacturing resources and forward the collected data to all 
the subscribers, here EI layer (see Step 3 in Figure 3 and 
[13]). The received real-time data from the manufacturing 
level denotes actual achieved performance (i.e., AS-IS 
values). Planned performance values from enterprise control 
level (e.g., ERP system) together with actual achieved 
performance values from manufacturing level are integrated 
according to an enterprise data model, and stored in 
relational database as historical data (see Step 6 in Figure 3). 
The digital enterprise integration framework was further 
enhanced for online monitoring and control of enterprise 
processes using tracking objects [31]. Tracking objects 
represent control-relevant objects like orders, products and 
resources, and are instantiated simultaneously with a 
corresponding workflow instance in a WMS (see Step 2 in 
Figure 3). These objects are updated during enterprise 
process execution with the values acquired from different 
MES levels (see Step 4 in Figure 3). The changes in tracking 
objects‟ status can be analyzed online by a RBS (e.g., Drools 
Expert) [31]. However, the usage of RBS implicates the lack 
of taking temporal and causal relations between events into 
account. In addition, it is remarkable that only a few WMS 
support the collection and interpretation of real-time data 
[8][9]. Hence, the usage of a CEP engine (e.g., EsperTech 
[44]) instead of RBS is necessary. Here, the CEP engine is in 
charge of continuously analyzing tracking objects and 
dispatching control data to required MES levels (see Step 7 
in Figure 3). 
In addition to the control of enterprise processes 
employing CEP engine, the historical data is periodically 
utilized offline to calculate KPIs and OEE. However, 
historical data is seldom exploited to identify new 
knowledge and further this identified knowledge is not 
utilized for online monitoring and control of enterprise 
processes. To overcome the aforesaid drawbacks, a 
methodology is elaborated to identify and assimilate 
knowledge for online monitoring and control of enterprise 
processes. 
B. Methodology for Knowledge Identification and 
Assimilation in Manufacturing 
An overview of the process model towards the realization 
of digital enterprise integration has been depicted in Figure 
4. This process model consists of four process steps, which 
are unique to a particular enterprise. The process model can 
be put into practice by means of implementing the 
aforementioned IT-framework. These process steps need not 
necessarily be performed sequentially and further, individual 
process steps can be carried out from time to time to enhance 
enterprise (value creation) processes. 
Prior to the implementation of the IT-framework for 
digital enterprise integration (see Section III.A), it is 
essential to analyze and (re-) design the enterprise processes 
as it is in the case of BPM life cycle [8][9] (see Step I in 
Figure 4). An enterprise data model based on industrial 
standards (e.g., IEC 62264 [7]) and enlarged with technical 
models (e.g., DIN EN 61512-2 [27]) is in charge of relating 
AS-IS and TO-BE values from different MES levels (see 
Step II in Figure 4). Also, data flow diagrams (DFDs) can be 
created to reveal the interdependencies between business 
191
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 4. Process model towards the realization of knowledge-based 
online control of enterprise processes. 
applications and resources, and associated events triggered at 
various MES levels. 
Knowledge is embedded in enterprise process data (e.g., 
pressure, temperature) generated before and during execution 
of these processes i.e., TO-BE and AS-IS values. These 
process data is mapped onto the aforementioned enterprise 
data model and stored in a relational database as historical 
data. Subsequently, offline KDD process can be employed 
on the historical data to identify new knowledge (see Step III 
in Figure 4). Applying repeated and time-consuming 
database queries executed on the integrated database are not 
useful for online control of enterprise processes [46]. Instead, 
event streams (i.e., TO-BE and AS-IS values) created during 
process execution need to be analyzed and processed online 
using a CEP engine (see Step IV in Figure 4). Here, the 
externalized knowledge can be codified as event patterns and 
event pattern rules, and these event patterns can be used for 
detection of complex events in event streams. Along with 
this detection of complex events, event processing can be 
employed for online control of enterprise processes.  In 
following subsections, each of the process steps will be 
elaborated. 
 
1) Enterprise Process Analysis and (Re-) Design 
Enterprise process analysis and (re-) design is part of 
enterprise reference architectures (e.g., ARIS [47]) and 
business process reengineering (BPR) [48]. BPR can be 
described using four main phases: (i) identification of critical 
enterprise processes, (ii) review, update and analysis of 
enterprise processes (AS-IS analysis), (iii) (re-) design of 
enterprise processes based on AS-IS analysis, and (iv) 
implementation of (re-) designed enterprise processes. 
 Comprehension of enterprise processes and their 
integration within an enterprise‟s organizational structure is 
crucial for the implementation of online enterprise process 
control strategies. Hence, process analysis and (re-) design 
incorporates enterprise‟s organizational structure as well as 
its process-oriented organization. 
The activities and functions of an enterprise process are 
executed by various resources (e.g., IT-systems), which are 
in charge of an enterprise‟s organizational unit. Thus, the 
organizational units can be organized and modeled using 
organizational charts. In addition, functions and activities of 
an enterprise process take several kinds of inputs. These can 
be data (e.g., printed documents) but also intangible inputs 
like implicit knowledge of enterprise members. In summary, 
each function of an enterprise process can be linked with an 
organizational unit, various inputs and outputs. Further, the 
functions are orchestrated to enterprise processes using 
logical connectors like „and‟, „or‟, and „exclusive or‟. 
Several modeling languages and methodologies are 
available to model enterprise processes like event-based 
process chain (EPC) and business process modeling 
language (BPML). Apart from these modeling languages that 
focus on tangible inputs and outputs (e.g., data and 
documents), knowledge management description language 
(KMDL) can be employed to describe knowledge intensive 
processes, i.e., creation, use and necessity of knowledge 
along enterprise processes [49]. 
 
2) Enterprise Data Model and Data Flow Diagram 
Today‟s business applications and automation devices 
are complex, and several inputs are required by these 
systems to define enterprise processes. In addition, enormous 
amount of data is generated by the automation devices in 
real-time denoting information like feedbacks, product 
positions and alerts. For online monitoring and control of 
these enterprise processes, it is essential to analyze the 
business applications and automation devices, and their 
corresponding processes to identify critical control-related 
process parameters. In this regard, enterprise data modeling 
is an essential step to establish important control-relevant 
parameters. It influences the quality of information that is 
necessary to execute enterprise processes, achieve EI, and 
enhance online monitoring and control of enterprise 
processes. 
IEC 62264-2 describes models and terminologies that 
enable to implement enterprise-wide control between 
enterprise control level and manufacturing control level [7]. 
An enterprise data model based on IEC 62264-2 can be 
further augmented with technical models depending on the 
type of manufacturing process, like DIN EN 61512-2 (for 
batch manufacturing, [27]) and DIN 8582 (for metal forming 
processes, [50]). Overall, IEC 62264-2 facilitates to 
exchange structured data between business applications and 
manufacturing resources. 
Besides the static structure of an enterprise data model, 
DFDs reveal the interdependencies between processes‟ 
systems and manufacturing resources, either in isolation or in 
192
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 5. Knowledge discovery in databases (KDD) process (adapted 
from [51]). 
combination [51]. Further, DFDs identify the flow of data, 
describing the dynamic behavior of enterprise processes. 
Process data is generated and manipulated by several 
resources during process execution. The DFDs can be 
employed to expose the relationships between various IT-
systems and resources. As the number of systems and 
resources has been increased in industrial scenarios, DFDs 
are usually organized in a hierarchy of DFDs. Coarse-
grained DFD can depict an overview of the shop floor and its 
resources while a certain DFD is been created with regard to 
a certain enterprise (sub-) process.  
 
3) Knowledge Identification 
Knowledge can be defined from different perspectives. In 
the current research context, following definition is adapted: 
“Data is raw numbers and facts, information is processed 
data, and knowledge is authenticated information” [39]. As 
mentioned earlier, knowledge is embedded into enterprise 
processes as process data. This knowledge is enriched and 
enlarged during execution of enterprise processes (e.g., 
feedbacks). Further, integrated enterprise process data (i.e., 
TO-BE and AS-IS values) is stored as historical data based 
on the aforementioned enterprise data model.  
Historical data can be also exploited to derive new 
knowledge, which can be utilized in online monitoring and 
control 
of 
enterprise 
processes. 
Hence, 
knowledge 
identification can be performed utilizing KDD process, 
defined as a “process of mapping low-level data into other 
forms that might be more compact or abstract or useful” 
[52]. KDD process is depicted in Figure 5. Input to KDD 
process is historical data and outputs are patterns, subjected 
to certain defined quality known as interestingness measures 
[53]. These interestingness measures can be objective 
measures based on the statistical strengths or properties of 
the discovered patterns and subjective measures, which are 
derived from the user‟s beliefs or expectations [53]. A 
pattern is an abstract representation of a subset of data and 
needs to be evaluated by domain experts to identify 
knowledge.  KDD process consists of several steps (see 
Figure 5), which are elaborated in the following paragraphs. 
Understanding of manufacturing domain in concern is 
indispensable for successful employment of KDD process. 
This can be carried out as described in process analysis and 
(re-) design, and enterprise data model and DFDs (see Step I 
and II in Figure 4). Major activities of manufacturing 
enterprises are production, maintenance, quality and 
inventory [7], and consequently, define the goals of the KDD 
process. Depending upon the goals of the KDD process, 
specific data (target data) is selected from the historical data 
on which patterns will be searched. 
However, historical data might be inaccurate due to 
various reasons and thus influencing the identified 
knowledge. During data acquisition process, data is collected 
from operators through console, and analog equipments and 
digital measuring devices through programming logic 
controllers (PLCs) (see Figure 2). In the aforementioned IT-
framework, AS-IS values are made available to enterprise 
integration layer through object linking and embedding 
(OLE) for process control (OPC) severs (see Figure 2 and 
Step 3 in Figure 3). Data collected consists of noise or 
inaccuracies or missing values, which makes searching of 
patterns complicated [54]. This might be due to limitations of 
measuring instruments, typing errors of operator or errors in 
logic of PLCs. To overcome these inaccuracies, it is 
necessary to study and understand the domain, as described 
in Step I in Figure 4. Understanding of domain along with 
the enterprise data model will help to identify suitable 
statistical methods to remove noise, strategy to fill the 
missing values and deletion of duplicate data. Also 
periodically, data collection can be enhanced by verifying 
the collected data from manufacturing resources in 
coordination with the operators. Overall, cleaning and pre-
processing activities are carried out on the selected data for 
further processing. 
Only subset of pre-processed data is required for 
achieving the aforementioned goals of KDD process [55]. 
Hence, transformation of data involves reducing number of 
parameters in the target data or representing the target data in 
a more general or acceptable format. Filter and wrapper 
approaches can be employed to reduce number of parameters 
[56]. In addition, understanding of manufacturing processes, 
operations, and constraints will aid in transformation process 
supported with enterprise data model and DFDs. 
Data mining is a particular sub-process in KDD process. 
It is based on proven techniques like machine learning, 
pattern 
recognition, 
statistics, 
artificial 
intelligence, 
knowledge acquisition, data 
visualization, and 
high 
performance computing [57].  Data mining consists of three 
steps: (i) selection of data mining method, (ii) determination 
of appropriate data mining algorithms, and (iii) employing 
these algorithms for pattern search.  
Data mining methods have to be chosen in accordance to 
the goals of KDD process as they determine the type of 
knowledge 
to 
be 
mined 
i.e., 
concept 
description, 
classification, association, clustering and prediction [34]. 
Since the goal in current research is to enhance online 
monitoring and control of enterprise processes, knowledge to 
support decision making processes needs to be identified. In 
this regard, classification and regression methods can be 
engaged to determine new knowledge. Classification is a 
method to categorize a new instance of data into one of 
several predefined classes [52][54]. It consists of two steps 
[34]: (i) construction of a (classification) model based on the 
analysis of database tuples (i.e., a training set) described by 
193
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 6. Simple event description in an XML format. 
attributes and (ii) usage of this constructed (classification) 
model for classification of new data instances. In contrary, 
regression is a function that maps data to a real-valued 
prediction variable. 
According to previously selected data mining methods 
(e.g., classification), data mining algorithms have to be 
selected to search for patterns. For example, decision trees, 
decision rules, inductive logic programming and rough set 
methods can be utilized to determine rules [36]. Finally, the 
previously selected data mining methods and algorithms are 
employed to discover patterns.  
Discovered patterns can be sufficient large or it might be 
necessary to select a subset of discovered patterns [56]. 
Consequently, to enhance the quality of discovered patterns, 
measure of interestingness can include both subjective and 
objective approaches [56]. A discovered pattern can be 
interpreted using structured interviews with domain experts. 
If necessary, all or selected steps of KDD process need to be 
repeated in order to obtain more suitable knowledge. If 
sufficient integrated data is not available to carry out KDD 
process, structured interviews with domain experts can be 
conducted to identify initial knowledge. Later, acquired 
historical 
data 
can 
be 
exploited 
employing 
the 
aforementioned KDD process to enhance and enlarge the 
knowledge base. 
 
4) Knowledge-Based Online Control of Enterprise 
Processes 
Historical data can be employed to identify new 
knowledge as described in Section III.B.3. This identified 
knowledge can be used for control of enterprise processes by 
directly accessing the aforementioned historical data. 
However, repeated and time-consuming database queries 
[46] (e.g., applying ex-post online analytical processing 
(OLAP) queries) result in offline control of enterprise 
processes. Consequently, real-time data should be processed 
online (i.e., near real-time) for control of enterprise processes 
utilizing previously identified knowledge, tracking objects 
and CEP engine as depicted in Figure 2 and Figure 3.  
Tracking objects are representatives of process entities 
(e.g., products, orders, resources) of a particular enterprise 
process. A tracking object is instantiated simultaneously with 
a workflow in a WMS specifying a process route (see Step 1 
in Figure 3) and associated planned performance values (i.e., 
TO-BE values). During execution of enterprise processes, 
AS-IS values from manufacturing level are made available in 
OPC servers and simultaneously forwarded to EI layer 
utilizing publish-subscribe mechanism (see Step 3 in Figure 
3). These AS-IS values are integrated with corresponding 
TO-BE values from ERP system obtained using request-
reply mechanism.  
EI 
layer 
manages 
the 
integrated 
process 
data 
simultaneously in numerous ways. First, tracking objects are 
updated with corresponding integrated process data (see Step 
4 in Figure 3) and thereby, tracking objects contain up-to-
date status information of an actual enterprise entity within 
an enterprise process. Second, integrated process data is 
delivered to all subscribed clients with graphical user 
interface (GUI) for online monitoring of enterprise processes 
(see Figure 2). Finally, integrated process data is stored in a 
relational database as historical data for offline analysis (see 
Figure 2 and Step 6 in Figure 3). Tracking objects are 
constantly analyzed at manufacturing control level and 
utilized for online control of enterprise processes using CEP 
engine with the objective to enhance major activities of 
manufacturing enterprises i.e., production, maintenance, 
quality and inventory (see Step. 5 in Figure 3). Subsequently, 
CEP engine is in charge of dispatching control data to 
manufacturing resources (see Step 7 in Figure 3), and at the 
same time updating tracking objects with control data. In the 
following paragraphs, CEP and assimilation of previously 
identified knowledge is elaborated. 
An event is characterized by its event source (e.g., a 
certain automation device), event type, event attribute (i.e., 
data) and timestamp or time interval [58] and additionally, 
event sink (e.g., operator, plant manager) as depicted in 
Figure 6. As mentioned previously, events are triggered 
across different MES levels during execution of enterprise 
processes and form an event cloud [43][58]. Events can be 
classified as simple or composite events based upon their 
level of abstraction. Simple events are triggered across 
different MES levels and do not have any abstraction. Hence, 
a simple event does not provide sufficient information for 
online control of enterprise processes [41]. For instance, a 
simple event is triggered whenever a lower mold is produced 
by a molding machine. 
On contrary, a composite event with higher abstraction 
can be described with an event pattern based on simple 
events [41][59]. For example, a complex event is triggered 
whenever total of number of molds produced for a given 
order exceeds the required quantity specified in the order. 
Further, higher abstraction events can be derived from 
composite events as depicted in Figure 7. In summary, a 
composite event can be “created by combining base events 
using a specific set of event constructors such as disjunction, 
conjunction, sequence, etc” [58].  Finally, an event stream is 
a “linearly ordered sequence of events”, which are ordered 
by arrival time or bounded by a certain time interval [58]. 
Here, event streams are composed of simple events denoting 
tracking objects created or updated during process execution. 
An event pattern is a “template containing event 
templates, 
relational 
operators 
and 
variables” 
[58]. 
Relationships between different (simple and composite) 
events can be basic, temporal and spatial [43] or logical, 
temporal and causal [41][60]. Simple events are created at a 
194
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 7. Hierarchical event abstraction (adapted from [58]). 
 
Figure 8. Processing of temporal events using sliding time boundary. 
certain period in time i.e., have an associated event 
timestamp. However, enterprise members from enterprise 
control level and manufacturing control level are interested 
in aggregated events for online monitoring and control of 
products, orders, or resources [41][60]. To enable 
aggregation of events, it is necessary to utilize temporal 
event patterns and hence, support time interval with sliding 
time boundary [41][60], as depicted in Figure 8. Temporal 
event patterns include overlap, coincides, contains and 
before or after event patterns [43]. Further, operators (e.g., 
concatenation, sequence) associated with temporal event 
patterns can be identified [41]. 
CEP can be defined as “computing that performs 
operations on complex events, including reading, creating, 
transforming or abstracting them” [58][60]. The main 
purpose of the CEP engine is to control enterprise processes 
based on a continuous analysis of events streams (i.e., 
tracking objects). As described before, tracking objects 
contain up-to-date status information of an enterprise process 
entity. On update with the new incoming integrated data, 
tracking objects are analyzed within the CEP engine as 
shown in Step 5 in Figure 3. Event patterns expressed by an 
event processing language (EPL) are used within the CEP 
engine, which is capable to analyze logical, temporal, and 
causal event patterns. Further, event pattern rules (i.e., 
reactive rules) define how the CEP engine reacts to the 
occurrence of a certain event pattern [59]. An example of an 
event pattern and event pattern rule is shown in Table I, 
based on [59]. Hence, the incoming events are analyzed 
using event pattern rules and necessary control data is 
dispatched. In addition, suitable events with higher 
abstractions are created and appended to the already existing 
event cloud for future event processing. 
TABLE I.  
EVENT PATTERN AND EVENT PATTERN RULE 
Element 
Declarations 
Variables 
Order O, Order.Quantity Q, 
MoldList LM, MoldList.Count C, 
Mold M, Mold.Order M_O 
Event types 
MoldProduced(Order O, Mold M) 
Produce(Order O) 
Pattern 
MoldProduced (O, M) 
Context test 
C < Q 
Action 
Create Produce(O) 
 
In order to effectively monitor and control the enterprise 
processes, it is essential to identify and characterize events. 
Previously identified knowledge can be assimilated by 
creating event patterns and event pattern rules codified as 
EPL statements. In addition, structured interviews with the 
domain experts can be utilized to enhance and enlarge event 
patterns and corresponding event pattern rules. Finally, event 
patterns and event pattern rules can be made persistent in a 
centralized database. Enterprise members or decision makers 
are not interested in all the events. Hence, event sinks or 
event consumers can be configured by enterprise members' 
roles 
(e.g., 
supervisor, 
plant 
manager) 
and 
their 
corresponding privileges (e.g., defined in a lightweight 
directory access protocol (LDAP) server). Therefore, an 
event configuration, part of client‟s GUI provides the 
necessary functionality to define and configure events and 
event patterns. 
There are two implementations on how the CEP engine 
influences or controls the actual enterprise processes. First, 
the CEP engine uses interfaces and services provided by the 
EI layer (see Figure 2) to automatically dispatch control 
commands. 
Second, 
before 
manipulating 
enterprise 
processes, CEP engine exposes envisaged decision as a 
suggestion to clients with GUI. Here, an enterprise member 
accepts or declines the proposition. Obviously, human 
interaction is used in cases where enterprise members should 
take liability. However, access to the aforementioned 
functionality of dispatching control data depends upon the 
enterprise members' roles and their corresponding privileges. 
IV. 
INDUSTRIAL CASE STUDY 
The IT-framework as well as the corresponding process 
model for enabling digital enterprise integration and 
achieving online control of enterprise processes elaborated in 
Section III can be put into practice in different types of 
manufacturing, especially in batch manufacturing (e.g., 
195
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 9. Software screenshots of implemented IT-framework for 
enabling enterprise integration and control of enterprise processes. 
 
Figure 10. IBM® SPSS® Modeler Professional screenshots. 
casting processes) and discrete manufacturing (e.g., sheet 
metal forming processes). Here, an attempt is made to realize 
the framework for casting processes with special purpose 
resources. To efficiently utilize these capital-intensive 
resources, online monitoring and control of enterprise 
processes is mandatory. The IT-framework has been 
implemented using MicrosoftTM Visual Studio IDE and 
.NET framework 3.5. Different screenshots of the 
implemented IT-framework, stacked one over other, are 
displayed in Figure 9. 
Enterprise processes have been analyzed and modeled 
using ARIS (utilizing EPC and Entity-Relationship-Model) 
[47]. IEC 62264-2 [7] and DIN 61512-2 [27] have been 
adapted to create an enterprise data model. In addition, DFDs 
were created to reveal interdependencies, and dynamic 
behavior between various automation devices and business 
applications. 
Data is acquired from different automation devices and 
made available as OPC items in OPC servers (see Figure 2). 
This data is forwarded to EI layer. Here, the data is mapped 
onto the enterprise data model and integrated with TO-BE 
values from ERP system. EI layer manages the integrated 
data in numerous ways. First, integrated data is delivered to 
all clients with GUI for online monitoring of enterprise 
processes. The subscription of clients to process data is 
realized through a windows communication foundation 
(WCF) interface. Delivered data is displayed online by the 
clients using visual elements like charts and gauges. Second, 
integrated values are stored in an Oracle® 10g database for 
offline process analysis (see Figure 10). Client‟s GUI 
provides interfaces to track products, orders and resources 
using request-reply mechanism (i.e., accessing historical 
data). Finally, tracking objects containing integrated data are 
processed in EsperTech CEP engine [44] for online control 
of enterprise processes, especially with the objective to 
enhance productivity.  
Casting process consists of following sub-processes: 
molding to manufacture molds, melting of raw material (e.g., 
aluminum), pouring of molten material, cooling and 
finishing (e.g., cutting, grinding, reaming). Molding machine 
in consideration is capable of producing upper and lower 
molds at high production rate and influences upstream as 
well as downstream processes.  Therefore, goal of the KDD 
process is to enhance productivity of molding process by 
reducing number of rejects. Thus, enhancing productivity 
and reducing wastage (i.e., sand, molten material). 
Numerous applications are available to support steps of 
KDD process as illustrated in Figure 5. Here, IBM® SPSS® 
Modeler Professional [61] has been chosen. 
At start of KDD process, a suitable data set has been 
selected from Oracle® 10g database for utilizing in SPSS® 
Modeler as illustrated in Figure 10. Here, data set containing 
mold details is selected, with 14891 rows. Further, each 
mold detail is associated with 459 attributes, stored in 
different database tables. Molding machine simultaneously 
produces lower and upper molds, and here, lower mold 
details are considered for further analysis. Hence, structured 
interviews with domain experts were carried out to identify 
the attributes of lower mold. Therefore, only 39 attributes of 
lower mold are retained and extraneous attributes are 
discarded in SPSS® Modeler. Still, reduced data set might 
contain erroneous data, unexpected situations or many 
unrelated parameters. SPSS® Modeler provides different 
graphical tools (e.g., histogram, distribution) to analyze and 
identify aforementioned causes from the data set.  Also, 
filtering expressions are utilized to clean the data set. After 
these preprocessing and transformation, data set contains 
12799 rows.  
Classification algorithms like Chi-square Automatic 
Interaction Detectors (CHAID) algorithm provided by 
SPSS® Modeler are used to construct decision trees. Suitable 
target attribute (e.g., mold quality – good or bad) is selected. 
Remaining 38 attributes are chosen as input parameters. 
After executing the CHAID algorithm, a decision tree is 
created with depth of decision tree equal to 4 and 12 
predictors (e.g., pressure). These determined patterns 
contained in decision tree are validated and refined by 
domain experts, i.e., using subjective interestingness 
196
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 11. Event pattern codified as an EPL statement in EsperTech. 
measure. Further, validated patterns are utilized in creating 
event patterns and event pattern rules codified in EPL 
statements as shown in Figure 11. For instance, creation of 
an alarm event by analyzing applied mold pressure on last 
two molding machine‟s simple events. These EPL statements 
can be managed by domain experts with suitable privileges 
via a client‟s GUI and stored in an EPL database. 
V. 
CONCLUSION AND FUTURE WORK 
Today‟s enterprise environment is complex, volatile and 
driven by uncertainties, forcing enterprises to become more 
flexible and adaptable. Consequently, enterprises endeavor to 
overcome the aforesaid challenges by enhancing the online 
monitoring and control of their enterprise processes. This can 
be achieved by integrating the enterprise along horizontal 
and vertical direction.  As a consequence, transactional data 
from enterprise control level and real-time data from 
manufacturing level have to be integrated and stored as 
historical data in relational database. However, these 
historical data is not used extensively for identification of 
knowledge and subsequently, identified knowledge is not 
used in the control of enterprise processes. 
In the current contribution, a process model for 
identifying and assimilating knowledge for online control of 
enterprise processes has been presented. This process model 
consists of four components: (i) enterprise process analysis, 
(ii) enterprise data model and DFDs, (iii) knowledge 
identification, and (iv) assimilation of identified knowledge 
for online control of enterprise processes. These process 
steps need not necessarily be performed sequentially and 
individual process steps can be carried out from time to time 
to enhance enterprise value creation processes. 
Enterprise processes are analyzed and modeled following 
the ARIS approach. Available standards were adapted to 
derive the enterprise data model. Analyzed enterprise 
processes 
assisted 
in 
creating 
DFDs 
revealing 
interdependencies between various automation devices and 
business applications. Real-time data from manufacturing 
level and transactional data from enterprise control level are 
integrated based on enterprise data model and stored in an 
Oracle® 10g database. Also, integrated data was displayed to 
enterprise members using charts and gauges. Knowledge was 
identified using IBM® SPSS® Modeler Professional. Further, 
the identified knowledge was assimilated for online control 
of enterprise processes using EsperTech CEP engine.  
Currently, the framework has been used in an enterprise 
for online monitoring and control of batch manufacturing 
(i.e., casting processes). Future implementation is planned 
for discrete manufacturing processes i.e., for an automotive 
sheet metal component supplier. 
ACKNOWLEDGMENT 
Parts of the work presented here have been supported by 
German Federal Ministry of Economics and Technology 
(BMWi) as part of “Central Innovation Programme SME” 
(ZIM) initiative (KF2111502LL0). Also, we are thankful to 
our industrial partner Ohm & Häner Metallwerk GmbH & 
Co. KG, Germany for the opportunity to implement the 
elaborated methodology and framework in a casting 
enterprise. Especially, we would like to acknowledge Dr.-
Ing. Ludger Ohm, Dr.-Ing. Georg Dieckhues, and Jürgen 
Alfes for their valuable comments and support. 
 
REFERENCES 
 
[1] M. Grauer, D. Metz, S. S. Karadgi, and W. Schäfer, “Identification 
and Assimilation of Knowledge for  Real-Time Control of Enterprise 
Processes in Manufacturing,” Proc. 2nd Int‟l Conf. on Information, 
Process and Knowledge Management (eKNOW 2010), Feb. 2010, pp. 
13-16, doi: 10.1109/eKNOW.2010.14. 
[2] D. Linthicum, Enterprise Application Integration, Addison-Wesley 
Longman, Amsterdam, 2000. 
[3] J. Lee, K. Siau, and S. Hong, “Enterprise Integration with ERP and 
EAI,” Comm. of the ACM, vol. 46, no. 2, Feb. 2003, pp. 54-60. 
[4] A. Drobik, M. Raskino, D. Flint, T. Austin, N. MacDonald, and K. 
McGee, The Gartner Definition of  Real-Time Enterprise, tech. 
report, Gartner Inc., 2002. 
[5] S. Karnouskos, D. Guinard, D. Savio, P. Spiess, O. Baecker, V. Trifa, 
and L. de Souza, “Towards the Real-Time Enterprise: Service-based 
Integration of Heterogeneous SOA-ready Industrial Devices with 
Enterprise Applications,” Proc. 13th IFAC Symp. on Information 
Control Problems in Manufacturing (INCOM '09), June 2009, pp. 
2127-2132. 
[6] VDI 5600, Manufacturing Execution System (MES) - VDI 5600 Part 
1, Verein Deutscher Ingenieure (VDI), 2007. 
[7] IEC 62264, Enterprise-control system integration, All Parts.  
[8] W. M. P. van der Aalst, A. H. M. ter Hofstede, and M. Weske, 
“Business Process Management: A Survey,” Proc. 1st Int‟l Conf. on 
Business Process Management, Springer-Verlag, Berlin, LNCS 2678, 
2003, pp. 1-12. 
[9] M. Weske, W. M. P. van der Aalst, and H. M. W. Verbeek, 
“Advances in Business Process Management,” Data & Knowledge 
Eng., 
vol. 
50, 
no. 
1, 
July 
2004, 
pp. 
1-8, 
doi:10.1016/j.datak.2004.01.001. 
[10] A. Kjaer, “The Integration of Business and Production Processes,” 
IEEE Control Systems Magazine, vol. 23, no. 6, 2003, pp. 50-58. 
[11] J. Kletti, Ed., Manufacturing Execution System – MES, Springer, 
Berlin, 2007. 
[12] H. 
Panetto 
and 
A. 
Molina, 
“Enterprise 
Integration 
and 
Interoperability in Manufacturing Systems: Trends and Issues,” 
Computers in Industry, vol. 59, no. 7, Sept. 2008, pp. 641-646, doi: 
10.1016/j.compind.2007.12.010. 
[13] M. Grauer, D. Metz, S. Karadgi, W. Schäfer, and J. W. Reichwald, 
“Towards an IT-Framework for Digital Enterprise Integration”, Proc. 
6th Int‟l Conf. on Digital Enterprise Technology (DET 2009), AISC, 
vol. 66, Springer, Berlin, Dec. 2009, pp. 1467-1482, doi: 
10.1007/978-3-642-10430-5_111. 
[14] C. Meyer, “Keeping Pace with Accelerating Enterprise”, CIO Insight, 
Nov. 
2002; 
http://www.cioinsight.com/c/a/Expert-Voices/Expert-
Voice-Christopher-Meyer-on-the-Accelerating-Enterprise/, 
25.12.2010.  
[15] A. Chen and F. Vernadat, “Standards on Enterprise Integration and 
Engineering - State of the Art,” Int‟l J. of Computer Integrated 
197
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Manufacturing, vol. 17, no. 3, Apr. 2004, pp. 235-253, doi: 
10.1080/09511920310001607087.  
[16] S. Aier, C. Riege, and R. Winter, “Enterprise Architecture - Literature 
Overview and Current Practices,” Wirtschaftsinformatik, vol. 50, no. 
4, 2008, pp. 292-304 (in German).  
[17] P. Bernus and L. Nemes,  “The Contribution of the Generalised 
Enterprise Reference Architecture to Consensus in the Area of 
Enterprise Integration,” Proc. of ICEIMT97, K. Kosanke and J. Nell, 
Eds., Springer, 1997, pp. 175-189. 
[18] ISO 15704, Requirements for Enterprise Reference Architecture and 
Methodologies, ISO 15704:2000/Amd 1:2005, 2005. 
[19] S. Karnouskos, O. Baecker, L.  de Souza, and P.  Spiess, “Integration 
of SOA-ready Networked Embedded Devices in Enterprise Systems 
via a Cross-layered Web Service Infrastructure,” Proc. 12th IEEE 
Int‟l Conf. on Emerging Technology and Factory Automation,  Sept. 
2007, pp. 293-300. 
[20] O. Sauer and G. Sutschet, “Agent-Based Control”, Computing & 
Control Eng. J., vol. 17, no. 3, June 2006, pp. 32-37, 
doi:10.1049/cce:20060305. 
[21] C. Gilman, M. Aparicio, J. Barry, T. Durniak, H. Lam, and R. 
Ramnath, “Integration of Design and Manufacturing in a Virtual 
Enterprise Using Enterprise Rules, Intelligent Agents, STEP and 
Workflow,” Proc SPIE Int‟l Symp. on Intelligent Systems & 
Advanced Manufacturing , 1997, pp. 160-171. 
[22] D. Linthicum, Next Generation Application Integration: From Simple 
Information to Web Services, Addison-Wesley Professional, 
Amsterdam, 2003. 
[23] H. Bohn, A. Bobek, and F. Golatowski, “SIRENA - Service 
Infrastructure for Real-Time Embedded Networked Devices: A 
Service Oriented Framework for Different Domains,” Proc. Mobile 
Comm. and Learning Technologies, Apr. 2006. 
[24] L. M. S. de Souza, P. Spiess, D. Guinard, M. Köhler, S. Karnouskos, 
and D. Savio, “SOCRADES: A Web Service Based Shop Floor 
Integration Infrastructure,” Internet of Things, C. Floerkemeier, M. 
Langheinrich, E. Fleisch, F. Mattern, and S. Sarma, Eds., Springer, 
Berlin, LNCS 4952, 2008, pp. 50-67. 
[25] R. Schulte, A Real-Time Enterprise is Event-Driven, tech. report, 
Gartner Inc., 2002. 
[26] S. T. Yuan and M. R. Lu, “A Value-Centric Event Driven Model and 
Architecture: A Case Study of Adaptive Complement of SOA for 
Distributed 
Care 
Service 
Delivery”, 
Expert 
Systems 
with 
Applications, vol. 36, no. 2, Mar. 2009, 3671-3694. 
[27] DIN EN 61512-2, Batch Control - Part 2: Data Structures and 
Guidelines for Languages, Ref. Nr. DIN EN 61512-2:2003-10, 2003. 
[28] B. Zhou, S. Wang, and L. Xi, “Data Model Design for Manufacturing 
Execution System,” J. of Manufacturing Technology Management, 
vol. 16, no. 8, 2005, pp 909-935. 
[29] J. A. Harding, B. Yu, and K. Popplewell, “Information Modelling: An 
Integration of Views of a Manufacturing Enterprise,” Int‟l J. of 
Production Research, vol. 37, no. 12, Aug. 1999, pp 2777-2782. 
[30] W. M. Cheung and P. G. Maropoulos, “A Novel Knowledge 
Management Methodology to Support Collaborative Product 
Development,” Digital Enterprise Technology - Perspectives and 
Future Challenges, P. F. Cunha and P. G. Maropoulos, Eds., Springer, 
June 2007, pp. 201-208. 
[31] M. Grauer, S. S. Karadgi, D. Metz, and W. Schäfer, “An Approach 
for Real-Time Control of Enterprise Processes in Manufacturing 
using 
a 
Rule-Based 
System,” 
Proc. 
Multikonferenz 
Wirtschaftsinformatik, Feb. 2010, pp. 1511-1522. 
[32] C. Groba, I. Braun, T. Springer, and M. Wollschlaeger, “A Service 
Oriented Approach for Increasing Flexibility in Manufacturing,” 
Proc. 7th IEEE Int‟l Workshop on Factory Communication Systems, 
Communication in Automation (WFCS 2008), Dresden, May 2008, 
pp. 415-422. 
[33] H. 
Kuntze, 
T. 
Bernard, 
G. 
Bonn, 
and 
C. 
Frey, 
“Entscheidungsunterstützung im Produktionsumfeld mit Data-
Mining-Werkzeugen,” 
VDI/VDE-Gesellschaft 
Mess- 
und 
Automatisierungstechnik (GMA): AUTOMATION 2008 Lösungen 
für die Zukunft, June 2008 (in German). 
[34] A. Choudhary, J. Harding, and M. Tiwari, “Data Mining in 
Manufacturing: A Review Based on the Kind of Knowledge,”  J. of 
Intelligent Manufacturing, vol. 20, no. 5, Oct. 2009, pp. 501-521, doi: 
10.1007/s10845-008-0145-x. 
[35] J. Harding, M. Shahbaz, Srinivas, and A Kusiak, “Data Mining in 
Manufacturing: A Review,” J. of Manufacturing Science and 
Engineering, vol. 128, no. 4, Nov. 2006, pp.  969-976, 
doi:10.1115/1.2194554. 
[36] A. Kusiak, “Data Mining: Manufacturing and Service Applications,” 
Int‟l J. of Production Ressearch, vol. 44, nos. 18-19, Sept./Oct. 2006, 
pp. 4175-4191, doi:10.1080/00207540600632216. 
[37] E. Mazharsolook, S. Scholze, S. Ziplies, R. Neves-Silva, and K. Ning, 
“Enhancing Networked Enterprise Management of Knowledge and 
Social Interactions,” J. of Computing in Systems and Eng., vol. 10, 
no. 4, 2009, pp. 176-184. 
[38] E. Neaga and J. Harding, “An Enterprise Modelling and Integration 
Framework Based on Knowledge Discovery and Data Mining,” Int‟l 
J. of Production Research, vol. 43, no. 6, Mar. 2005, pp. 1089-1108, 
doi: 10.1080/00207540412331322939. 
[39] M. Alaavi and D. E. Leidner, “Review: Knowledge Management and 
Knowledge Management Systems: Conceptual Foundations and 
Research Issues,” MIS Quarterly, vol. 25, no. 1, Mar. 2005, pp. 107-
136. 
[40] Drools Expert, http://www.jboss.org/drools/, 25.12.2010. 
[41] K. Walzer, J. Rode, D. Wünsch, and M. Groch, “Event-Driven 
Manufacturing: Unified management of Primitive and Complex 
Events for Manufacturing and Control”, IEEE Int‟l Workshop on 
Factory Communication Systems, 2008. 
[42] Y. H. Zhang, Q. Y. Dai, and R. Y. Zhong, “An Extensible Event-
Driven Manufacturing Management with Complex Event Processing 
Approach”, Int‟l J. of Control and Automation, vol. 2, no. 3, Sept. 
2009, pp. 1-12.  
[43] A. Vijayaraghavan, “MTConnect for Realtime Monitoring and 
Analysis 
of 
Manufacturing 
Enterprises,” 
Dec. 
2009; 
http://www.systeminsights.com/, 25.12.2010. 
[44] EsperTech, http://www.espertech.com/, 25.12.2010. 
[45] Drools Fusion, http://www.jboss.org/drools/, 25.12.2010. 
[46] M. Cammert, C. Heinz, J. Krämer, T. Riemenschneider, M. 
Schwarzkopf, B. Seeger, and A. Zeiss, “Stream Processing in 
Production-to-Business Software,” Proc. of the IEEE Int. Conf. on 
Data Eng., pp. 168-169, 2006. 
[47] A. Scheer, Business Process Engineering. Reference Model for 
Industrial Enterprise, 2nd Edition, Springer, 1994. 
[48] M. Hammer and J. Champy, Reengineering the Corporation: A 
Manifesto for Business Revolution,  Harper Business, 1994. 
[49] N. Gronau and E. Weber, “Management of Knowledge Intensive 
Business Processes,” In: J. Desel, B. Pernici, and M. Weske, Eds., 
BPM 2004, Springer, 2004, pp. 163-178. 
[50] DIN 8582, Manufacturing Processes Forming - Classification, 
Subdivision, Terms and Definitions, Alphabetical Index, 2003. 
[51] K. Kendall and J. Kendall, Systems Analysis and Design, 6th Edition, 
Prentice Hall, 2004. 
[52] U. Fayyad, G. Piatetsky-Shapiro, and P. Smyth, “From Data Mining 
to Knowledge Discovery in Databases,” AI Magazine, vol. 17, Fall 
1996, pp. 37-54. 
[53] K. McGarry, “A Survey of Interestingness Measures for Knowledge 
Discovery,” The Knowledge Engineering Review, vol. 20, no. 1, 
2005, pp. 39-61, doi: 10.1017/S0269888905000408. 
[54] D. T. Pham and A. A. Afify, “Machine–Learning Techniques and 
their Applications in Manufacturing,” Proc. IMechE Part B: J. of Eng. 
Manufacture, 
vol. 
219, 
no. 
5, 
2005, 
pp. 
395-412, 
doi: 
10.1243/095440505X32274. 
198
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[55] M. Shahbaz, Srinivas, J. A. Harding, and M. Turner, “Product Design 
and Manufacturing Process Improvement using Association Rules,” 
Proc. IMechE Part B: J. of Eng. Manufacture, vol. 220, no. 2, 2006, 
pp. 243-254, doi: 10.1243/095440506X78183. 
[56] A. A. Freitas, “A Survey of Evolutionary Algorithms for Data Mining 
and Knowledge Discovery,” Advances in Evolutionary Computing: 
Theory and Applications, Springer-Verlag, Newyork, 2003, pp. 819-
845. 
[57] J. Han and M. Kamber, Data Mining - Concepts and Techniques, 
Morgan Kaufmann, London, 2001. 
[58] D. Luckham and R. Schulte, Eds., Event Processing Glossary - 
Version 1.1, Event Processing Technical Society, 2008. 
[59] D. Luckham, The Power of Events: An Introduction to Complex 
Event Processing in Distributed Enterprise Systems, Addison-Wesley, 
Munich, 2007. 
[60] K. Walzer, A. Schill, and A. Löser, “Temporal Constraints for Rule-
Based Event Processing”, Proc. ACM first Ph.D. workshop in CIKM, 
Nov. 2007, pp. 93-100. 
[61] IBM SPSS Modeler Professional, http://www.spss.com/, 25.12.2010. 
 
199
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

