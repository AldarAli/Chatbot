Skin Lesion Segmentation and Classification Using Deep Learning Methods 
Spyridon Vollas 
Hellenic Open University  
Patras, Greece 
std146179@ac.eap.gr 
 
 
 
 
Isidoros Perikos 
Compute Engineering & Informatics 
Department 
University of Patras  
and Hellenic Open University  
and Computer Technology Institute 
and Press Diophantus  
Patras, Greece 
perikos@ceid.upatras.gr 
Michael Paraskevas 
Department of Electrical & Computer 
Engineering Engineering 
University of Peloponnese 
and Computer Technology Institute & 
Press Diophantus 
Patras, Greece 
mparask@cti.gr 
 
Abstract— Melanoma is the most dangerous type of skin 
cancer. Every year hundreds of thousands of people are 
affected by this form of cancer, with tens of thousands of them 
leading to death. The diagnosis at an early stage is crucial and 
can lead to a complete cure of patients making it the most 
important parameter in the fight against it. The aim of this 
paper is to design and formulate deep learning methods and an 
ensemble schema for the accurate recognition of melanoma as 
well as of other skin lesions. The methods and the deep 
learning architectures that were designed and tested are 
convolutional neural networks, deep convolutional neural 
networks, deep residual networks as well as capsule networks. 
An ensemble method which consists of the DesNet121 and 
ResNet50 architectures is also designed and introduced. For 
the DenseNet121 and ResNet50 methods, the transfer learning 
technique was used for the phase of training. The experimental 
study revealed quite interesting results on the HAM10000 and 
ISIC 2019 datasets. The best performance among the methods 
was achieved by the DenseNet121 network with an accuracy up 
to 81%.  
Keywords- melanoma; deep learning; ensemble learning; 
convolutional neural networks; capsule networks. 
I. 
 INTRODUCTION 
Skin is the larger organ of the human body. Its main 
contributions are both avoiding infections and injuries and 
regulating body temperature. As with other organs of the 
body, the skin can be affected by cancer. Indeed, there are 
several types of skin cancer. The four main types are the 
Basal cell carcinoma, Squamous cell carcinoma, Merkel cell 
cancer and Melanoma [22]. 
Melanoma is the most dangerous type of skin cancer, and 
it is developed by melanocytes. These cells are responsible 
for the production of the natural skin pigment, melanin. Ιt 
can metastasize to lymph nodes and internal organs of the 
human body. Untimely diagnosis leads in most cases to the 
death of patients. It can be developed in various parts of the 
human body and can progress in various ways. The main 
reasons that can lead to the appearance of melanoma are the 
exposure to ultraviolet (UV) radiation, especially from 
people with low levels of melanin (light skin), the possession 
of a large number of moles (>50), the presence of dysplastic 
nevus as well as some family (first-degree relatives) or 
personal history of melanoma or other types of skin cancer. 
According to the Global Cancer Observatory (GCO) in 
2020 324,635 new cases of melanoma were recorded 
worldwide (54% men and 46% women). There were also 
57,043 new deaths with 57% of these being male. The 
continent most affected by skin cancer is that of North 
America at 32.4% of new cases.  
As with all types of cancer, early diagnosis is crucial for 
the treatment of patients suffering from melanoma. For this 
purpose, several clinical methods have been developed for 
dermatologists to be able to identify and then proceed with 
the appropriate treatment of the disease [13][20]. Perhaps the 
most widespread technique is the ABCD mnemonic rule [3]. 
According to research studies, the characteristics of early-
staged melanoma are similar regardless of the area in which 
they are located. These features can be easily remembered by 
thinking about the ABCD where, A refers to the asymmetry 
of the lesion, B refers to the fuzzy boundaries of the lesion, C 
refers to the uneven color of the lesion, D refers to the 
diameter of the lesion when it exceeds 6 mm. 
The accurate diagnosis of skin cancer is considered to be 
a very challenging task, even for the most experienced 
dermatologists. Indeed, dermatologists with more than 10 
years’ of experience can achieve diagnostic accuracy of 
around 80% with the usage of clinical methods [10]. This is 
even lower for dermatologists with less experience. Thus, the 
development of an intelligent system with high accuracy in 
the classification of skin lesions is necessary for early 
diagnosis in a short time [16][18].  
However, the automatic analysis of skin lesions is a very 
difficult and quite tricky task [8][11]. There are several 
reasons for that. First, there are cases where it is not easy to 
differentiate between benign and malignant skin lesions. 
Also, in most cases, the small diameter of the lesions does 
not allow to take high-resolution photographs with 
conventional cameras. Another reason that can lead to poor 
results is the slight contrast in the colors of the lesion and the 
patient's skin. This can make the boundaries of the lesion in-
distinguishable [2]. Finally, the presence of noises and 
artifacts inside a digital image can affect the task of 
classification. In general, noise is the result of errors in the 
image capture process that result in pixel values that do not 
reflect the actual intensities of the actual scene [17].  
The purpose of this study is to design and develop deep 
neural networks and assess their performance in skin cancer 
5
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-075-9
SPWID 2023 : The Ninth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

recognition. To that end, we formulate various deep learning 
methods and more specifically Convolutional Neural 
Netwotks (CNN), DenseNet121, ResNet50 and a capsule 
network. The designed methods were trained on various 
datasets and after that, an ensemble method that consists of 
DenseNet121 and ResNet50 networks was designed and 
developed.  
II. 
RELATED WORK 
Through the years, many studies have been conducted 
regarding the diagnosis and classification of skin cancer 
[5][19] and many works focus on the efficiency of 
convolutional neural networks in skin cancer recognition 
[1][12]. Authors in [14] proposed a method that consists of 
three 
stages. 
Firstly, 
for 
image 
preprocessing, 
the 
morphological closure function is applied to remove 
unwanted information from the images. Then the images 
were resized to have a size of 227x227 pixels. The faster-
RCNN architecture was used to extract the features. This 
technique can detect and classify lesions of different types 
using the fully convolutional Region Proposal Network 
(RPN) and Fast-RCNN modules. The experiments showed 
that this method is robust to different image artifacts. Also, 
its performance can outperform existing techniques. 
Zhang [21] used the EfficientNet network as the 
backbone of his architecture. More specifically, this network 
was used to extract features from the images contained in the 
dataset. For this purpose, transfer learning was used, where 
the weights of the pre-trained EfficientNet on the ImageNet 
dataset were used. The dataset used in this study was ISIC 
2020 Challenge Dataset which was divided into a ratio of 
7:2:1 for training, validation, and testing purposes 
respectively. The performance achieved by the proposed 
architecture is an AUK-ROC Score of 0.917 outperforming 
VGG16 and VGG19 networks.  
In the work presented in [7], authors trained and tested 
eleven CNN architectures. Then the best-performing method 
was selected so that a mobile application could be created. 
The goal of this application will be to obtain images of skin 
lesions and be able to classify them into benign and 
malignant cases. The best performance of the networks 
tested was achieved by DenseNet169 which was the one 
chosen for the development of the Android application. 
The authors in [6] proposed an architecture that is 
inspired by several advanced frameworks that are designed 
for the identification of skin lesions. This architecture which 
was named Lesion Classification Network (LCNet), consists 
of 11 blocks, and was trained end-to-end on dermoscopic 
skin cancer images. The experimental results showed that 
LCNet works better on large and balanced datasets and is 
reliable in predicting the correct lesion category. 
The authors in [9] developed a two-stage model which 
will be responsible for melanoma detection. The first stage 
aims to accurately segment skin lesions images by using the 
U-Net architecture which was built on top of a Fully 
Convolutional Network (FCN). The second stage aims to 
predict the presence of melanoma using a deep residual 
network. The categorization results showed that the Dilated 
Residual Network (DRN) should be fine-tuned for achieving 
better performance. 
The aim of the study conducted by Ningrun et al. [15] 
was to create a melanoma detection model that can operate 
on devices with low computational power. For this purpose, 
they developed a framework that includes two architectures, 
one CNN and one that is a combination of CNN and an 
Artificial Neural Network (ANN). The experimental results 
showed the superiority of the CNN + ANN model in both 
performance and resistance to overfitting. 
III. 
METHODOLOGY 
In this section, we present the methodology of our work. 
The designed deep learning methods and the ensemble deep 
learning schema are illustrated and the exact way that they 
were trained is presented. Also, the dataset are presented too. 
A. Datasets 
As stated in Section I, the HAM10000 and ISIC 2019 
datasets were used for both training and evaluation of the 
CNN architectures. These are two publicly available datasets 
containing RGB images in JPG format. HAM10000 is 
known as the Human Against Machine dataset and contains 
10015 color images of skin lesions all 600x450 pixel size 
which were collected from dermatoscopic images from 
different populations. The ISIC 2019 contains a total of 
33569 images of various sizes and the corresponding 
metadata, with entries such as age, sex, and general anatomic 
site. Here only the images belonging to the training set were 
used with their number being equal to 25331. These images 
are distributed to different classes depending on the type of 
skin lesion. The number of classes in HAM10000 is seven 
while ISIC 2019 has eight. The seven classes of HAM10000 
are the Actinic keratoses (akiec), the Basal cell carcinoma 
(bcc), 
the 
Benign 
keratosis-like 
lesions 
(bkl), 
the 
Dermatofibroma (df), the Melanoma (mel), the Melanocytic 
nevi (nv) and the Vascular lesions (vasc). As HAM10000 is 
one of the datasets that constitutes the ISIC 2019 dataset, the 
latter contains the same classes as the former, with the one 
additional class being Squamous cell carcinoma (SCC). 
For image preprocessing at first, we resize them for 
training more efficiently the CNN models. More specifically, 
the HAM10000 images were transformed from 600x450 
pixels to 200x150 pixels, while the images of ISIC 2019 
were transformed to have a size of 227x227 pixels. The 
images of both datasets were then normalized so that the 
values of each pixel were in the range [0, 1].  
A very important technique that helps to train deep CNNs 
more efficiently, is that of data augmentation. Its use is 
considered particularly useful when the number of data is not 
sufficient for training deep architectures, as well as in cases 
where the distribution of data is uneven across the different 
classes of the dataset. Here, various augmentation techniques 
were used, such as random rotations at different angles, 
random zoom, random shear, vertical flips, as well as 
changes in the brightness of the images. Also, we random 
deleted 50% of the images belonging to class nv which was 
the dominant class of HAM1000. 
6
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-075-9
SPWID 2023 : The Ninth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

For the augmentation of ISIC 2019 dataset, the 
ImageDataGenerator class of Keras was used. It can perform 
various image transformations in real time while the neural 
network is still in the training phase. One of the advantages 
of using this class is the fact that the architecture will receive 
new image transformations at each epoch, to reduce the 
possibility of overfitting. It also uses a small amount of 
RAM. The augmented datasets were split in a 70:20:10 ratio 
for training, evaluation, and testing purposes respectively. 
Finally, it is worth mentioning that the data is fed in the 
architectures in random order at each iteration during the 
phase of training.  
B. Designed Deep CNN architectures 
The main objective of this study is to design, examine 
and 
compare 
the 
performance 
of 
different 
CNN 
architectures. The methods that were used, are mainly CNN 
and Deep CNN techniques, an ensemble technique as well as 
a capsule network. 
Firstly, for the experiments, a simple CNN architecture 
was used. It consists of 6 convolutional blocks with the first 
one containing one convolutional layer, one max pooling 
layer and one batch normalization layer. Blocks 2 and 3 are 
consisted of a convolutional and a max-pooling layer each, 
while blocks 4 and 5 contained a convolutional, a max-
pooling and a dropout layer each. Finally, the last 
convolutional block has the same structure as blocks 2 and 3. 
On top of these, there are one flatten and 2 fully connected 
layers, the latter of which is responsible for the task of 
classification. The HAM10000 dataset was used for training 
the model. A visualization of the described method can be 
seen in the image below: 
 
 
Figure 1.  CNN model visualization 
The first deep CNN network used for the experiments 
was the DenseNet121 network. The main advantage of this 
architecture is the resolution of the vanishing gradient 
descent 
problem. 
This 
problem 
occurs 
during 
backpropagation, and it can be more severe as new layers are 
added to a neural network. To address this problem, the 
researchers modified the connectivity pattern between layers. 
The standard CNN architecture connects each layer directly 
with the next one, while in DenseNet each layer is connected 
directly with every layer that exists after it. This is 
accomplished by the dense blocks, one of the constituent 
elements of DenseNet. Inside a dense block, the size of the 
feature maps remains the same but the number of filters in 
each of them are different. Also, between them, layers that 
reduce the number of existing channels to half are placed. 
Those layers are called transition layers. Another benefit of 
DenseNet is the need of fewer parameters during training, 
making the network easier to train. DenseNet121 contains 
121 layers, and the exact characteristics of it are illustrated in 
Table I. 
TABLE I.  
STRUCTURE OF DENSENET121 
Layers 
Output size 
DenseNet121 
Convolution 
112x112 
7x7 conv, stride 2 
Pooling 
56x56 
3x3 max pool, stride 2 
Dense Block (1) 
56x56 
 x 6 
Transition Layer 
(1) 
56x56 
28x28 
1x1 conv 
2x2 average pool, stride 2 
Dense Block (2) 
28x28 
 x 12 
Transition Layer 
(2) 
28x28 
14x14 
1x1 conv 
2x2 average pool, stride 2 
Dense Block (3) 
14x14 
 x 24 
Transition Layer 
(3) 
14x14 
7x7 
1x1 conv 
2x2 average pool, stride 2 
Dense Block (4) 
7x7 
 x 16 
Classification 
Layer 
1x1 
7x7 average global pool 
1000D fully connected, 
softmax 
 
From the structure above, the last layer which is 
responsible for classifying the data into the 1000 classes of 
ImageNet dataset was removed. After that, a dropout layer 
was added to deal with the problem of overfitting. A dropout 
layer randomly ignores the outputs of certain neurons of the 
previous layer. So, these outputs are not considered during 
backpropagation 
or 
forward 
propagation. 
Generally, 
overfitting occurs when the model has high variance. That 
means that the network performs well on the training dataset 
while on the evaluation dataset, its performance is degraded. 
In other words, the model learns to memorize the patterns 
existing in the training set. However, it does not have the 
ability to generalize for new data. Reasons such as the large 
number of hidden layers, usage of small datasets and data 
that contains noise can lead to overfitting. Finally, two dense 
layers were added with the last one having as a task the 
categorization of images into the classes ISIC 2019. 
Next, we experimented with the ResNet50 architecture. It 
belongs to the family of Deep Residual Networks (DRNs) 
[4]. DRNs make use of residual blocks to overcome the 
problems associated with training deeper convolutional 
neural networks. In a network with residual blocks, a 
technique called skip connections is used. According to this, 
7
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-075-9
SPWID 2023 : The Ninth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

training from a few layers can be bypassed if one of them 
harms the performance of the architecture. Thus, adding new 
layers will not affect the performance of the model, as 
normalization will override them if they are not useful. The 
ResNet50 is a fifty-layer deep architecture and a summary of 
the layers of which it is composed can be found in Table II. 
TABLE II.  
STRUCTURE OF RESNET50 
Layers 
Output size 
DenseNet121 
conv1 
112x112 
7x7, 64, stride 2 
conv2_x 
56x56 
3x3 max pool, stride 
 x 3 
conv3_x 
28x28 
 x 4 
conv4_x 
14x14 
 x6 
conv5_x 
7x7 
 
 x 3 
Classification layer 
1x1 
average pool, 1000-d fc, softmax 
As with DenseNet121, the last layer was removed. In its 
place were added two dropout and two dense layers. The first 
of the dense layers contains 256 nodes while the second one 
8, one for every class of ISIC 2019. 
C. Designed Ensemble Deep learning architectures 
Ensemble learning is a deep learning approach in which 
the predictions of two or more methods are combined in 
order to achieve better results during categorization. There 
are different ensemble learning techniques. Here the 
weighted average was selected where different weights were 
assigned to each technique. More specifically, each model is 
multiplied by a weight, which value ranges between 0 and 1 
and then their average is calculated.  
For 
achieving 
better 
results 
during 
training 
of 
DenseNet121 and ResNet50 transfer learning was used. 
According to this technique an architecture that has been pre-
trained on a larger dataset, can be used in a similar 
categorization task where the dataset is not so large. This 
leads to greater classification results. Here the pre-trained 
weights of ImageNet were used. 
In addition to convolutional neural networks, we attempt 
to experiment with a special type of neural networks, which 
are the capsule networks. The main structural elements of 
these architectures are called capsules. A capsule consists of 
several neurons, each of which stores different information 
about the object it is trying to identify, into a 
multidimensional vector. Such information may be the 
position, the rotation, the scale of the object. Each capsule 
encodes the probability of an object being present in the 
image. One of the great advantages they offer is the 
elimination of the problem that can arise from the pooling 
operation. The purpose of this operation is to reduce the size 
of the feature maps produced by convolutional layers. This is 
done to achieve the spatial invariance or in simpler words, 
regardless of the position of an object in the image, the 
method will be able to detect it and categorize it in the 
correct class. When reducing the dimension of the feature 
maps, useful information related to the rotation, position, 
scale, and various positional features of the object may be 
lost. Thus, the object detection and segmentation process 
becomes a quite challenging task. Finally, other advantages 
that capsule networks provide are that they need less amount 
of data during the phase of training, and their ability to better 
model hierarchical relationships. 
The Capsule Network (CapsNet) designed and developed 
in our study, consists of an encoder and a decoder, each with 
a set of three layers. The encoder consists of a convolutional 
layer, a PrimaryCaps layer and a SkinCaps layer. On the 
other hand, the decoder consists of 2 fully connected layers. 
More specifically, the encoder consists of a convolutional 
layer which contains 256 filters of size 9x9, and ReLu is 
used as the activation function. Next, we have the 
PrimaryCaps layer. This is a convolutional layer which has 
32 channels of eight-dimensional convolutional capsules 
(each capsule has 8 convolutional units with filters of size 
9x9). Finally, the SkinCaps layer has 16 capsules per class, 
where each capsule receives input from the low-level 
capsule. A reconstruction loss is used to encode the 
initialization parameters. The decoder receives the correct 
16-dimensional capsule and decodes it into an image. None 
of the incorrect capsules are considered. The loss is 
calculated by finding the Euclidean distance between the 
input image and the reconstructed one. 
The experiments were conducted using Tensorflow and 
Keras libraries. More specifically, for the training and 
evaluation of CNN, DenseNet121 and ResNet50 methods 
Tensorflow version 2.8.2 and Keras version 2.8.0 were used. 
The goal was to find those that would give the best possible 
performance. The parameters used for tuning the networks 
are seen in Table III. 
TABLE III.  
MODEL TRAINING PARAMETERS 
Model 
Paramet
er 
CNN 
DenseNet121 
ResNet50 
CapsNet 
Optimizer 
Adam  
(lr=3e-4) 
Adam  
(lr=5e-5) 
Adam 
(lr=3e-5) 
Adam 
(lr=0.001) 
Loss 
Function 
Categorical  
crossentropy 
Categorical  
crossentropy 
Categorical  
crossentropy 
Mean 
Absolute 
Error 
Batch Size 
16 
32 
32 
32 
Epochs 
100 
30 
30 
25 
 
An optimizer is an algorithm used to increase the 
efficiency of the neural network. It depends by the learning 
parameters of the neural network, the weights, and biases, 
and help us to know how these parameters should be 
changed in order to reduce the losses during categorization. 
Categorical cross-entropy loss function measures the 
8
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-075-9
SPWID 2023 : The Ninth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

performance of a classification model whose output is a 
probability value between 0 and 1. This value is being 
increased as the predicted probability deviates from the 
actual class. It is used in cases where the data is categorized 
into more than two classes. As for the Mean Absolute Error, 
this function calculates the absolute difference between the 
current output and the expected output divided by the 
number of outputs. Its objective is to minimize these absolute 
differences. Finally, batch size is a hyperparameter that 
determines the number of data instances that the network 
must process before it updates its internal parameters. 
IV. 
EXPERIMENTAL STUDY 
A concrete experiment was designed and conducted with 
the aim to assess the performance of the deep learning 
methods and the ensemble schema. Publicly available 
datasets were utilized and different types of data were used 
to assess the performance of the methods, and also provide a 
deeper insight into their performance on heterogeneous data 
from different sources. The experiments were conducted in 
the virtual environment of Google Colab. This is a Google 
Research product which allows anyone to write and execute 
Python code via a hosted Jupyter notebook service. To 
measure the performance of the designed methods accuracy, 
precision, recall and F1-score were used and were calculated. 
The main results are presented in Table IV. 
TABLE IV.  
PERFORMANCE OF TESTED MODELS DURING THE TRAINING 
PHASE 
Model 
Accuracy 
Precision 
Recall 
F1-Score 
CNN 
81.05% 
85.14% 
75.54% 
80.06% 
DenseNet121 
81% 
85.09% 
77.73% 
81.24% 
ResNet50 
79.5% 
84.53% 
75.25% 
79.64% 
Ensemble 
Method 
80.85% 
- 
- 
- 
CapsNet 
66.89% 
- 
- 
- 
 
As illustrated in Table IV, the best performance among 
all the designed and developed models, was achieved by the 
DenseNet121 network. It can be alos observed that the 
architecture that was most prone to overfitting was the 
ResNet50 network. So, that was the main reason why two 
dropout layers were added to the network just after the main 
pre-trained method (as opposed to DenseNet121 network in 
which only one dropout layer was desided to be added). In 
the figures below, we present the loss and the accuracy 
diagrams of all the designed methods. 
 
 
 (a) 
 (b) 
 
 
 (c) 
 (d) 
 
 
 (e) 
 (f) 
 
 
 (g) 
 (h) 
Figure 2.  Accuracy and loss of tested methods during training: (a), (b) 
Loss and accuracy diagrams of CNN method; (c), (d) Loss and accuracy 
diagrams of DenseNet121; (e), (f) Loss and accuracy diagrams of 
ResNet50; (g), (h) Loss and accuracy diagrams of CapsNet. 
The lowest performance of the architectures is that of the 
capsule network. As mentioned in the previous section these 
architectures have several advantages over traditional CNNs. 
However, in our study, they only achieved very good 
performance 
on 
simple 
datasets 
without 
having 
a 
correspondingly good performance on more complex ones.  
V. 
CONCLUSIONS 
In the context of our work, various deep learning 
architectures as well as an ensemble deep-learning schema 
was designed and formulated. The datasets used were 
HAM10000 and ISIC 2019. The best performance was 
achieved by the method Dense-Net121 with an accuracy of 
81% and F1-Score = 81.24%. The ensemble method which 
consisted of the DenseNet 121 and ResNet50 networks, 
achieved slightly lower results when the weighted averaging 
technique was used for calculating its performance.  
There are many directions that future work could 
examine. First, experiments with additional dermoscopic 
datasets can be conducted. Such datasets can be the ISIC 
9
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-075-9
SPWID 2023 : The Ninth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

2020 which contains 33126 images of skin lesions which is 
significantly bigger than the datasets used in this study. 
Another step that we can take into consideration is the study 
and experimentation with more sophisticated ensemble 
learning techniques in order to achieve better results during 
the classification. For example, stacking multiple machine 
learning models is an advanced ensemble learning technique 
in which different models are trained and their combined 
outputs are used as inputs to another machine learning 
algorithm called a meta-learner.  
REFERENCES 
[1] A. Adegun and S. Viriri, “Deep learning techniques for skin 
lesion analysis and melanoma cancer detection: a survey of 
state-of-the-art,” Artificial Intelligence Review, 2021, 54(2), 
pp. 811-841. 
[2] A. Dutta, M. K. Hasan, and M. Ahmad, “Skin Lesion 
Classification Using Convolutional Neural Network for 
Melanoma 
Recognition,” 
bioRxiv, 
2020. 
https://doi.org/10.1101/2020.11.24.20238246. 
[3] R. J. Friedman, D. S. Rigel, and A. W. Kopf, “Early Detection 
of Malignant Melanoma: The Role of Physician Examination 
and Self-Examination of the Skin,” CA Cancer J. Clin. 1985, 
35 (3), pp. 130–151.  
[4] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual 
Learning for Image Recognition,” In 2016 IEEE Conference 
on Computer Vision and Pattern Recognition, IEEE, 2016. 
[5] R. Javed, M. S. M. Rahim, T. Saba, and A. Rehman, “A 
comparative study of features selection for skin lesion 
detection from dermoscopic images,” Network Modeling 
Analysis in Health Informatics and Bioinformatics, 2020. 
[6] R. Kaur, H. GholamHosseini, R. Sinha, and M. Lindén, 
“Melanoma Classification Using a Novel Deep Convolutional 
Neural Network with Dermoscopic Images,” Sensors (Basel) 
2022, 22 (3), pp. 1134. https://doi.org/10.3390/s22031134. 
[7] I. Kousis, I. Perikos, I. Hatzilygeroudis, and M. Virvou, 
“Deep Learning Methods for Accurate Skin Cancer 
Recognition and Mobile Application,” Electronics (Basel) 
2022, 
11 
(9), 
pp. 
1294. 
https://doi.org/10.3390/electronics11091294. 
[8] S. Manzoor et al., “Melanoma Detection Using a Deep 
Learning Approach,” Vol 4 Issue 1 2022, 4 (1), pp. 222–232. 
https://doi.org/10.33411/ijist/2022040117. 
[9] J. Millenia, M. F. Naufal, and J. Siswantoro, “Melanoma 
Detection Using Convolutional Neural Network with Transfer 
Learning on Dermoscopic and Macroscopic Images,” J. inf. 
syst. 
eng. bus. 
intell. 
2022, 
8 
(2), 
pp. 149–161. 
https://doi.org/10.20473/jisebi.8.2.149-161. 
[10] C. A. Mortonand R.M. Mackie, “Clinical Accuracy of the 
Diagnosis of Cutaneous Malignant Melanoma,” Br. J. 
Dermatol. 
1998, 
138 
(2), 
pp. 
283–287. 
https://doi.org/10.1046/j.1365-2133.1998.02075.x. 
[11] I. Mporas, I. Perikos, and M. Paraskevas, “Color models for 
skin lesion classification from dermatoscopic images”. In 
Advances in Integrations of Intelligent Methods: Post-
workshop volume of the 8th International Workshop CIMA 
2018, Volos, Greece, November 2018 (in conjunction with 
IEEE ICTAI 2018) (pp. 85-98). Springer, 2020. 
[12] A. Naeem, M. S. Farooq, A. Khelifi, and A. Abid, “Malignant 
melanoma classification using deep learning: datasets, 
performance measurements, challenges and opportunities,” 
IEEE Access, 2020, 8, pp. 110575-110597. 
[13] P. Naronglerdrit, I. Mporas, I. Perikos, and M. Paraskevas, 
“Pigmented skin lesions classification using convolutional 
neural networks”. In 2019 International Conference on 
Biomedical Innovations and Applications (BIA), pp. 1-4, 
IEEE. 2019. 
[14] M. Nawaz et al., “Melanoma Localization and Classification 
through Faster Region-Based Convolutional Neural Network 
and 
SVM,” 
Multimed. 
Tools 
Appl. 
2021. 
https://doi.org/10.1007/s11042-021-11120-7. 
[15] D. N. A. Ningrum et al.“Deep Learning Classifier with 
Patient’s Metadata of Dermoscopic Images in Malignant 
Melanoma Detection,” J. Multidiscip. Healthc. 2021, 14, pp. 
877–885. 
[16] S. Sonthalia S. Yumeen and F. Kaliyadan, “Dermoscopy 
Overview and Extradiagnostic Applications,” [Updated 2022 
Aug 8]. In: StatPearls [Internet]. Treasure Island (FL): 
StatPearls 
Publishing; 
Jan. 
2022, 
Available 
from: 
https://www.ncbi.nlm.nih.gov/books/NBK537131  
[17] K. Thurnhofer-Hemsi and E. Domínguez, “A Convolutional 
Neural Network Framework for Accurate Skin Cancer 
Detection,” Neural Process. Lett. 2021, 53 (5), pp. 3073–
3093, https://doi.org/10.1007/s11063-020-10364-y  
[18] S. Tiwari, “Dermatoscopy using multi-layer perceptron, 
convolution neural network, and Capsule network to 
differentiate malignant melanoma from benign nevus,” Int. J. 
Healthc. Inf. Syst. Inform. 2021, 16 (3), pp. 58–73. 
https://doi.org/10.4018/ijhisi.20210701.oa4. 
[19] B. N. Vinay, P. J. Shah, V. Shekar, H. R. Vanamala and V. 
Krishna, “Detection of Melanoma Using Deep Learning 
Techniques,” 
In 
2020 
International 
Conference 
on 
Computation, Automation and Knowledge Management 
(ICCAKM), IEEE, 2020. 
[20] H. Zanddizari, N. Nguyen, B. Zeinali, and J. M. Chang, “A 
New Preprocessing Approach to Improve the Performance of 
CNN-Based Skin Lesion Classification,” Med. Biol. Eng. 
Comput. 
2021, 
59 
(5), 
pp. 
1123–1131. 
https://doi.org/10.1007/s11517-021-02355-5  
[21] R. Zhang, “Melanoma Detection Using Convolutional Neural 
Network,” 2021 IEEE International Conference on Consumer 
Electronics 
and 
Computer 
Engineering 
(ICCECE), 
Guangzhou, 
China, 
2021,, 
pp. 
75-78, 
doi: 
10.1109/ICCECE51280.2021.9342142  
[22] Cancer 
types, 
2022, 
https://www.cancer.net/cancer-
types/skin-cancer-non-melanoma/introduction 
 
10
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-075-9
SPWID 2023 : The Ninth International Conference on Smart Portable, Wearable, Implantable and Disability-oriented Devices and Systems

