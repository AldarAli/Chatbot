268
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Air Trafﬁc Representation and Analysis
Through Local Covariance
Georges Mykoniatis†, Florence Nicol‡, Stephane Puechmorel (*)
Ecole Nationale de l’Aviation Civile
Toulouse France
Email: †georges.mykoniatis@enac.fr, ‡florence.nicol@enac.fr, (*)stephane.puechmore@enac.fr
Abstract—Air trafﬁc is generally characterized by simple
indicators like the number of aircraft ﬂying over a given area or
the total distance ﬂown during a time window. As an example,
these values may be used for estimating a rough number of
air trafﬁc controllers needed in a given control center or for
performing economic studies. However, this approach is not
adapted to more complex situations such as those encountered
in airspace comparison or air trafﬁc controllers training or for
adapting dynamically the airspace conﬁgurations to the trafﬁc
conditions. An innovative representation of the trafﬁc data,
relying on a sound theoretical framework, is introduced in this
work. It will pave the way to a number of tools dedicated to
trafﬁc analysis. Based on an extraction of local covariance, a grid
with values in the space of symmetric positive deﬁnite matrices
is obtained. It can serve as a basis of comparison or be subject
to ﬁltering and selection to obtain a digest of a trafﬁc situation
suitable for efﬁcient complexity assessment.
Keywords—Air trafﬁc complexity; spatial data; manifold valued
images; covariance function estimation; non-parametric estimation.
I. INTRODUCTION
This article is an extension of a methodology introduced
in [1] for the complexity. It introduces a way of representing
the air trafﬁc such that salient features are intrinsically taken
into acccount. The theoretical material underlying this new
approach to trafﬁc characterization is a Gaussian ﬁeld model.
Namely, the speed vectors of the aircraft at given positions
are assumed to be sampled from an unknown underlying
Gaussian vector ﬁeld. Letting the point of observation ﬁxed,
the mean value of the ﬁeld is also the most probable direction
of the aircraft, while the variance is an indicator of the local
disorder: a fully organized trafﬁc in parallel tracks will have
zero covariance, thus a very low complexity while at the
other range an isotropic one will be the hardest to predict
and control.
Complexity is not the only feature of the trafﬁc that can
be captured by a Gaussian ﬁeld model. Considering once
again the mean and covariance at a point, one can infer a
geometrical characterization of the area around the reference
point. When the covariance matrix is close to singular, it
indicates a situation with a very low probability of crossings,
and thus a well deﬁned major ﬂow for the aircraft. Computing
at several points of the airspace allows the extraction of
the most probable routes. When the rank of the covariance
matrix increases and eventually become full, a route crossing
occurs with high probability. Looking at the neighboring points
the geometry of the crossing can be reconstructed. Applied
to a whole airspace, the above procedure may be used to
produce a graph of ﬂight paths, that is representative of the
trafﬁc geometry at a given time. The resulting data structure
is a decorated graph, with the vertices corresponding to the
crossings along with the covariance information while the
edges are described only using the mean value of the ﬁeld.
In all cases, the most efﬁcient way of gathering the relevant
information from the Gaussian ﬁeld model is to sample the
mean and variance of the ﬁeld on a evenly spaced grid
of points covering the airspace of interest. It gives a rep-
resentation of trafﬁc situations as images whose pixels are
covariance matrices, and if needed mean value. This is a
work in progress that will ultimately allow the use of deep
learning on such pseudo-images in conjunction with a database
already analyzed by experts, to produce a complexity metric
with low tuning requirements. A by product is the ability
to compute distances between trafﬁc situations, allowing for
efﬁcient indexing in dedicated databases. The graph structure
described above is also a direction of implementation for the
trafﬁc data, since several tools exist for dealing with such
objects [2].
The rest of the paper is structured as follows. In Section II,
the trafﬁc is modeled after a Gaussian random ﬁeld, whose
covariance function is estimated on two dimensional grid.
In Section III, tools dedicated to the processing of such
grids of symmetric positive deﬁnite matrices are introduced.
Finally, in Section IV, a conclusion is drawn, introducing
the next generation of algorithms able to exploit this novel
representation.
II. STATE OF THE ART
Key performance indicators (KPI) are of common use in air
transportation. However, they are designed mainly to address
global aspects of the systems and cannot address problems,
where it is mandatory to be able to distinguish between
trafﬁc situations based on the structure of the trajectories.
As an example, the training of air trafﬁc controllers relies

269
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
on carefully selected trafﬁc patterns that are presented to
the trainees in an order of increasing perceived complexity.
Creating such scenarios is quite a lengthy process, involving
hundreds of hours of works by experienced controllers. On
the other hand, it is easy to start from real situations, with
known ﬂight plans, and to use a trafﬁc simulator to put the
trainees in a nearly operational setting. The drawback of this
approach is the need to evaluate the trafﬁc patterns in order to
assess a complexity value for each of them. It has to be done
automatically, to avoid having to resort to human experts.
In a more operational context, nearly the same question
arises when trying to ﬁnd the right number of controllers
needed at a give time to take care of the incoming ﬂights
in their assigned airspace. Too many controllers induces an
extra cost and too few put a high pressure on the operators,
with possible detrimental effects on ﬂight safety. Assessing the
right level of complexity of the expected trafﬁc may greatly
improve over the current state of the art that simply estimates
the number of aircraft that will be present. Once again, it
is mainly a matter of ﬁnding an adequate trafﬁc complexity
indicator [3] [4].
In the Air trafﬁc ﬂow management context, it is important
to identify areas where the complexity of the trafﬁc does not
allow to split the work between two controllers. These areas
will then be used as not sequable (Sector Building Blocks)
in order to be grouped with others not contrained (Sharable
Airspace Modules) for building sectors of control adapted to
the trafﬁc situation, This approach is used in the dynamic and
evolutive airspace conﬁgurations.
A lot of work was dedicated to the issue of air trafﬁc
complexity measurement. Unfortunately, no really satisfactory
solution exists, as the problem itself is ill posed: depending on
the point of view, the complexity may be a concept roughly
equivalent to the cognitive workload or, on the contrary, be
based on purely structural features, without any reference
to the way it will be used. One of the most widely used
complexity measures is the dynamic density [5], that com-
bines several potential indicators, like number of maneuvering
aircraft, number of level changes, convergence and so on. All
these values are used as inputs of a multivariate linear model,
or in recent implementations, of a neural network. The tuning
of the free parameters of the predictors is made using examples
coming from an expertized database of trafﬁc situations. While
being quite efﬁcient for assessing complexity values in an
operational context, the method has two important drawbacks:
• The tuning procedure requires a sufﬁcient number of
expertized samples. A costly experiment involving several
air trafﬁc controllers must be set up.
• The indicator is valid only in a speciﬁc area of the
airspace. Adaptation to other countries or even control
centers requires a re-tuning that is almost as complicated
as the ﬁrst one.
The last point is a severe ﬂaw if one wants to use dynamic
complexity in the context of air trafﬁc databases, as a world
covering has to be obtained ﬁrst. Even for country sized
databases, some geographical tuning has to be added.
Another way to deal with complexity is through purely
geometrical indicators [6] [7]. Within this frame, there is no
reference to a perceived complexity but only to structural
features. An obvious beneﬁt is that the same metric may
be used everywhere, without needing a speciﬁc tuning. It is
also the weak point of the method as the relation with the
controllers workload is not direct.
III. TRAFFIC DATA
In many situation, the structure of the data available is
dictated by the technology used to collect them and only in a
few cases the converse will be true. In the ﬁeld of air trafﬁc
control (ATC), not only technological breakthroughs impact
the data available but they also change the way operators are
perceiving and using them in their work. It is thus mandatory
to understand the operational practices of air trafﬁc controllers
(ATCOs) in order to ﬁnd a sound model for the trafﬁc data.
A. A brief introduction to air trafﬁc control
In the early days of ATC, separation between aircraft was
ensured using procedures: pilots were bound to follow their
ﬁlled ﬂight plan, that is be at a given report position at a given
time. Assuming a constant speed. a simple linear interpolation
between two report points allowed then controllers to estimate
the intermediate positions at any time and check that no pairs
of aircraft come to close to each other. In oceanic areas,
this mean of controlling the trafﬁc is still in use, although
the accuracy of on-board inertial measurement units (IMUs)
makes the estimation of aircraft positions much more accurate.
A major breakthrough was the introduction of the radar in
civil aviation: ATC switched then from procedure based to
surveillance based control. It is the current ATC framework for
which ATCOs are trained. Surveillance based control makes it
natural to represent the air trafﬁc in an given airspace as a set
of plots, that are dated positions and speed samples, since it is
the way radars collect the information. Aircraft are identiﬁed
by a four digit code, sent by the on-board transponder as a
response to the radar beam. It is non-unique, assigned by the
controller in charge of the ﬂight within a control sector and
may change along the aircraft trajectory. Correlation with the
ﬂight plan is thus not automatic and must be done prior to any
further processing.
Finally, future air systems are undergoing a paradigm shift
with the introduction of trajectory based operations (TBO),
that are going to succeed the current surveillance based
operations. It contrast with the current air trafﬁc management
(ATM) system, the trajectory information will be the primary
data available to ATCOs. This paradigm shift is planned to
occur within 20 years, so that the model chosen to represent
the trafﬁc has to be TBO compliant.
When dealing with a trafﬁc situation, ATCOs have to
forecast the aircraft positions some minutes ahead in order

270
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
to detect encounters below separation norms (such a situation
is termed as a conﬂict in ATC) and give appropriate headings
to avoid them. Only in rare occasions altitude changes are
needed. Conﬂict resolution by velocity increase or decrease it
not uncommon in the US airspace where trafﬁc is organized in
miles in trails, but almost never used in Europe. In all cases,
a very inﬂuential factor on complexity is the organization
level of the trafﬁc, that impacts also the ability to forecast
its evolution through time. It is intrinsic to the trafﬁc situation
and does not depend on a particular airspace structure. Please
note that even in the context of future TBO, it remains a
valid indicator as near random situation is highly sensitive to
uncertainties and thus requires large enough safety margins,
even for an automated trajectory planner.
B. Data sources
Air trafﬁc data come from various sources with different
conﬁdence levels. Highest quality is reached by surveillance
data gathered by air services navigation providers (ANSPs),
which are generally not publicly available. In the mid-range,
ADSB data is easy to obtain from both commercial or free
providers. Low to medium accuracy data can be generated
by trafﬁc simulators, using ﬁlled or estimated ﬂight plans.
The present work makes use of raw radar data collected by
the French civil aviation authority, converted from the binary
format ASTERIX [8] to a textual form. Each day of trafﬁc is
saved in a compressed ﬁle, for a total duration of one month.
ADSB data was not considered in the study, but will be used
in ongoing work to address wider airspaces.
Due to the physics underlying the radar measurements and
the low level preprocessing algorithms, some errors are present
in the original dataset:
• Noisy observations. They appear as small oscillations
around a mean trajectory and can be attenuated by using
either a Kalman ﬁlter or a local linear model. However,
the covariance estimation procedure that will be described
later tends to smooth out the noise, so that its effect is
very limited, and is too low to be noticed in practice.
• Bad correlation between trajectories and measurements.
In such a case, there is a mixing of two or more ﬂight
paths, resulting in several jumps across them. This kind
of error has no impact on the computation of local
covariance matrices since the trajectory information is not
used.
Finally, some atypical ﬂights are related to radio electric
navigation means calibration, or to training or experiments.
They are easily identiﬁed and can be discarded automatically
from the dataset. It is the only preprocessing stage that was
applied to the raw dataset to get the working dataset.
C. Database setup
Raw radar data are organized as records separated by new-
line delimiters in compressed text ﬁles. Each record comprises
the following ﬁelds, separated by the delimiter ’—’:
• A Unique identiﬁer of type int32. It identiﬁes the ﬂight
and is assigned by a low-level tracking algorithm.
• A time stamp, formatted as a posix date time.
• Three real numbers representing respectively the x,y
position in the so-called CAUTRA coordinate system and
the altitude in feet.
• Three real numbers representing respectively the velocity
in knots, the heading in degrees and the vertical speed in
feet per minute.
• The name of the ﬂight, as displayed on the controller’s
screen.
• The aircraft type.
• The departure and arrival airport codes.
The last four ﬁelds are uniquely associated with a ﬂight identi-
ﬁer. The coordinate system in which the position is expressed
is speciﬁc to the French ATC system: horizontal positions
are in nautical miles, obtained by applying a stereographic
projection centered at 0 deg. longitude, 45 deg. latitude.
Altitude is expressed in ﬂight levels.
A conversion to a more generic unit system must be done
prior to storage in a database. The following transformations
are thus applied:
• Horizontal positions are converted to longitude and lat-
itude in the WGS84 ellipsoid and expressed in degrees.
The transformation is done using the open source proj4
software [9].
• Vertical position is converted to meters.
• All velocities are converted to meters per second.
The sampling rate is 4 seconds, resulting in approximately
6-7 million records per day, yielding a grand total of roughly
200 million records for the complete dataset. Based on that,
the expected dataset size for a year of worldly trafﬁc will be
in the order of 31010 records. Since the ﬁnal goal of this work
is to release a tool able to characterize the complexity of the
trafﬁc in any area and for at least ten years, the database must
accommodate 31011 records. The storage needed for tha raw
radar data can be thus estimated roughly to 15T-20To, which
is a very tractable value for modern hardware.
Given the above remarks, the main point that remains
is to choose between a SQL (Postgresql) or a document-
oriented (MongoDB) database. For raw radar data coming
from the French civil aviation authority, both solutions are ﬁne.
However, keeping in mind that different sources will be added
in the future, the MongoDB implementation was selected as it
offers an extra degree of ﬂexibility. Please note that this does
not preclude the use of a SQL database for serving speciﬁc
queries: in such a case, the document-oriented database acts
as data pool feeding the SQL one.
A dedicated tool has been developed to automatically read
incoming raw radar ﬁles from a directory and store the samples
into a mongoDB database after unit and coordinate system
conversion . A complementary tool receiving online ADSB
trafﬁc from the Opensky network [10] is also available but
not yet in operation.

271
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
IV. TRAFFIC MODELING
A. A Gaussian ﬁeld approach
An mentioned above, all samples are assumed to be plots
(t, x, v) where t is the sampling time, x ∈ R3 is the sample
position and v ∈ R3 the aircraft speed. As a consequence, a
trafﬁc dataset is a sequence (ti, xi, vi)i=1...N of plots collected
in a given time interval and spatial area. Please note that plots
do not incorporate trajectory information, so that different
ﬂight patterns may generate exactly the same dataset. How-
ever, if the sampling rate is high enough, and if (t0, x0, v0)
and (t1, x1, v1) are successive samples belonging to the same
trajectory, the distance between x1 and x0 + (t1 − t0)v0
is small, so that no confusion between trajectories can be
made unless a true encounter occurs, which is of course
unlikely to occur on real trafﬁc. This remark also suggests
a representation of the trafﬁc as a dynamical system, in which
the aircraft trajectories are integral lines of a time varying
vector ﬁeld. To put it in a more formal way, an explicit asso-
ciation between the plots and the trajectories must be assumes,
namely the observations come as a sequence of labeled plots
(tij, xij, vij)i=1...M,j=1...Ni, where i is the trajectory number
and j the index of the plot on the trajectory. Please note that
the number of points sampled on each trajectory is generally
varying. A continuous model of the trafﬁc is then deﬁned as
a smooth mapping X : [t0, t1] × Ω → R3 such that its integral
lines:
γi : t ∈ [ti1, tiNi] 7→
xi1 +
Z t
ti1
X (u, X(u, γi(u)) du, i = 1 . . . M
(1)
satisfy the interpolation condition:
∀i = 1 . . . M, ∀j = 1 . . . Ni, γi(tij) = xij, γ′
i(tij) = vij
(2)
or equivalently:
∀i = 1 . . . M, ∀j = 1 . . . Ni, γi(tij) = xij, X(tij, xij) = vij
(3)
As is, the problem is ill-posed as inﬁnitely many such X may
be found. Adding a smoothness penalty term allows a unique
solution to be found. A possible choice is:
E(X) =
Z t1
t0
Z
Ω
λ∥∂X(t, x)
∂t
∥2 + ∥∆xX(t, x)∥2dx

dt
(4)
where the partial derivative in time accounts for time variation
and the Laplacian quantiﬁes for the departure from an orga-
nized solution where the speed value at one point is the mean
value of its neighbors speed.λ > 0 is a free parameter that
tunes the relative importance of both terms. In the sequel, it
will be set to 1, but using an arbitrary value is just a matter
of scaling the time coordinate. The original problem 3 can be
reformulated as:





argmin E(X)
γi(tij) = xij, X(tij, xij) = vij,
i = 1 . . . M, j = 1 . . . Ni
(5)
The penalized problem gives rise to a solution that is known
as a spline interpolation. In its special instance 1, the solution
can be obtained in closed form.
Proposition 1. 1 The problem has a unique solution X, that
can be expressed for the t ̸= tij, i = 1 . . . M, j = . . . Ni as a
sum:
X(t, x) =
M
X
i=1
Ni
X
j=1
aij
1
p
|t − tij|
erfc
∥x − xij∥2
|t − tij|

+ btx + cx + dt + e
(6)
with erfc the complementary error function.
Proof. The complete proof is quite long, a simpliﬁed version
is given here. The ﬁrst step is to reformulate 1, using the
extra assumption that the sought after ﬁeld must be vanishing
at inﬁnity, both in x and t. Using an integration by parts, the
criterion E(X) given in 4 can rewritten as:
E(X) =
Z
R
Z
R3 ⟨LX(t, x), X(t, x)⟩ dxdt
with L the differential operator:
L = −∂tt + ∆2
x
The space of ﬁelds X such that LX is deﬁned in weak sense
and E(X) < +∞ is a Sobolev space H, with inner product:
⟨X, Y ⟩H =
Z
R
Z
R3 ⟨LX(t, x), Y (t, x)⟩ dxdt
Let G be the Green’s function of L. The interpolation condi-
tions can be written as:
Z
R
Z
R3 ⟨LG(tij, xij, t, x), X(t, x)⟩ dxdt = vij
i = 1 . . . M, j = 1 . . . Ni
They deﬁne an afﬁne subspace A of H, so that the ﬁeld X
solving 1 is the orthogonal projection of the origin onto A.
Since the subspace of H orthogonal to A is generated by the
G(tij, xij, t, x), i = 1 . . . M, j = 1 . . . Ni, the optimal ﬁeld as
the form:
X(t, x) =
M
X
i=1
Ni
X
j=1
aijG(tij, xij, t, x) + K(t, x)
where K is an element of the kernel of L, determined by
the boundary conditions. The second step of the proof is to
ﬁnd the Green’s function of L, that can be done using a partial
fourier transform in x, in the sense of distributions. After some
computations, one can show that it is proportional to:
1
p
|t − tij|
erfc
∥x − xij∥2
|t − tij|

thus completing the proof.
Looking at the expression of X, it appears to be undeﬁned at
the sampling times tij, even if it remains integrable. In fact, the
ﬁeld involves delta distributions at the sample times.This is not

272
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
an uncommon situation, as it is encountered when computing
an harmonic ﬁeld generated by a ﬁnite set of point charges.
Nevertheless, it is a severe ﬂaw for the air trafﬁc application
and needs to be corrected. A ﬁrst approach is to replace the
exact interpolation conditions by a a mean value condition. A
possible choice is:
Z
R3 X(tij, x)
1
(2π)3/2σ exp −∥x − xij∥2
2σ2
dx = vij
yielding a simple expression for X:
X(t, x) =
M
X
i=1
Ni
X
j=1
aij
1
p
σ + |t − tij|
erfc
 ∥x − xij∥2
σ + |t − tij|

+ btx + cx + dt + e
The parameter σ must be tuned according to the typical spatial
scale of variation of the ﬁeld, in the order of 10NM for air
trafﬁc.
Another way of looking at the same problem is to assume
that the sampling positions and times are no completely
deterministic, but come from an underlying stochastic process.
Randomness in the spatial component, may represent measure-
ment errors, or uncertainties if the position is only estimated.
In the time component, it is mainly related to delays (positive
or negative) due to some unknown parameters, like the wind,
that affect the ground speed of the aircraft. In a more formal
way, the sampling process at point (t, x) is assumed to be
of the form (t, x) + U with U a random variable taking its
values in R × R3 and having a density p(t, x). The observed
ﬁeld at (t, x) becomes now a random variable of the form
X((t, x) + U). Assuming a deterministic ﬁeld of the form
6 and looking only at the part corresponding to the Green’s
functions, the expectation of X at position (t, x) is given by:
M
X
i=1
Ni
X
j=1
aij
Z
R
Z
R3 G(tij + η, xij + ξ, t, x)p(η, ξ)dηdξ
which is non longer degenerate. Letting the expected values
be the new constraints of the problem yields an expression
with Green’s function G replaced by the kernel:
˜G(t, x, u, v) =
Z
R
Z
R3 G(t + η, x + ξ, u, v)p(η, ξ)dηdξ
The two approaches are mainly equivalent, the second one
introducing a more probabilistic view.
Finding the coefﬁcients aij, a, b, c, d, e is done by solving
a linear system, and represents quite a huge amount of
computational power. Furthermore, the probabilistic or mean
value approaches do not allow a simple characterization of
the trafﬁc. However, the optimality of the reconstructed ﬁeld
with respect to a smoothness criterion is an extremely valuable
property, that worth to be preserved.
The main idea underlying the new representation that will be
introduced now is the fact that kernel functions, like ˜G, occur
in the ﬁeld expression X(t, x) as weighting factors, while
the coefﬁcients aij are linear functions of the observations,
independent of t, x. For the sake of simplicity, the explicit
time dependence will be dropped when possible in the sequel,
so that sampling positions will be in R4. Doing so, a double
indexing in i and j is no longer needed, and a single one will
be used.
Collected samples may be viewed as realizations of an
underlying stochastic process X with domain R4 and taking
its values in R3. Such a process is called a Gaussian vector
ﬁeld when for any collection of points (x1, . . . , xp), the joint
distribution of the random variables (X(x1), . . . , X(xp)) is
Gaussian. Such a process is characterized by its mean and
covariance functions:
µ(x) = E[X(x)]
(7)
C(x, y) = E

(X(x) − µ(x))(X(y) − µ(y))t
(8)
In practice, µ and C must be estimated from a dataset of
couples (xi, vi)i=1...N where vi is the observed vector value
at position xi. Available methods fall into two categories:
parametric and non parametric. In the parametric approach, µ
and C are approximated by members of a family of functions
depending on a ﬁnite number of free parameters that are
tuned to best match the observations. Considering the above
discussion about optimal ﬁeld reconstruction, its is natural to
approach µ by an expansion of the form:
µ(x) =
M
X
i=1
Ni
X
j=1
aij
1
p
σ + |xt − tij|
erfc
 ∥xs − xij∥2
σ + |xt − tij|

+ V (x)
where xt (resp. xs) denotes the time (resp. spatial) component
of x, and V accounts for the bilinear term. The covariance
function C may be represented pretty much the same way,
using tensor products of ˜G kernels. Due to the covariance
part, estimating the free coefﬁcients is even more expensive
than the deterministic problem and is intractable in practical
applications.
In the non parametric approach, a different methodology
is used: the samples themselves act as coefﬁcients of an
expansion involving the kernel functions ˜G. Apart from the
obvious beneﬁt of avoiding a costly least square procedure,
the complementary error function appearing in the kernel
expression decays very fast at inﬁnity: in practice ˜G can be
assumed to be compactly supported, so that evaluating an
approximate mean and covariance at a given location requires
far less terms that the number of samples. Due to its simplicity
and the previous property, a non parametric estimation was
selected to process the trafﬁc.
B. Mean and covariance matrix estimation
A kernel estimator of the covariance function C of a
stationary stochastic process X can be found in [11]. Using
a straightforward extension, a kernel estimator for the corre-
lation function of a locally stationary random ﬁeld is given
in [12]. Finally, a weighed maximum likelihood approach is
taken in [13], for computing at any location x the mean µ(x)

273
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
and variance C(x, x) = Σ(x) of a Gaussian random ﬁeld.
This last work can easily be generalized to yield an estimate
for the covariance function, under normality assumption for
the random ﬁeld X. Given a dataset (xi, vi)i=1...N, where the
sampling positions xi are assumed to be distinct, the weighted
joint log likelihood of the couples (xi, vi), (xj, vj), j ̸= i at
locations x, y is given, for a ﬁxed kernel bandwidth h, by:
L(x, y) =
− 1
2
N
X
i=1
N
X
j=1
V t
ijΣ−1(x, y)VijKh (xi − x) Kh (xj − y)
+ 1
2 log

274
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Algorithm 1 Mean kernel estimate
1: for i ← 0, 2L;j ← 0, 2 ∗ M do
2:
m(i, j) ← 0
3: end for
4: for k ← 0, N − 1 do
5:
(k, l) ← ClosestGridPoint(xi)
6:
for i ← −P, P;j ← −Q, Q do
7:
if k + i ≥ 0 ∧ k + i ≤ 2L then
8:
if l + j ≥ 0 ∧ l + j ≤ 2M then
9:
m(k + i, l + j) ← m(k + i, l + j) +
Kh(i, j)vi/N
10:
end if
11:
end if
12:
end for
13: end for
Algorithm 2 Covariance kernel estimate
1: for i ← 0, 2L;j ← 0, 2 ∗ M do
2:
C(i, j) ← 0
3: end for
4: for k ← 0, N − 1 do
5:
(k, l) ← ClosestGridPoint(xi)
6:
for i ← −P, P;j ← −Q, Q do
7:
if k + i ≥ 0 ∧ k + i ≤ 2L then
8:
if l + j ≥ 0 ∧ l + j ≤ 2M then
9:
A ← (vi − m(k, l))(vi − m(k, l))t
10:
C(k + i, l + j) ← C(k + i, l + j) +
Kh(i, j).A/N
11:
end if
12:
end if
13:
end for
14: end for
p(k1l1)
p(k2l1)
p(k2l2)
p(k1l2)
xi
dy
dx
Fig. 1. Bilinear interpolation
approximated as:
Kh(k1, l1) + dx
δx
a + dy
δy
b + dx
δx
dy
δy
c
(18)
with:
a = Kh(k2, l1) − Kh(k1, l1)
b = Kh(k1, l2) − Kh(k1, l1)
c = Kh(k2, l2) + Kh(k1, l1) − Kh(k2, l1) − Kh(k1, l2)
Gathering terms by tabulated values yields a kernel value:
Kh(k1, l1) (1 − sx − sy + sxsy)
(19)
+ Kh(k2, l1) (sx − sxsy)
(20)
+ Kh(k1, l2) (sy − sxsy)
(21)
+ Kh(k2, l2)sxsy
(22)
where:
sx = dx
δx
, sy = dy
δy
It
is
thus
possible
to
compute
the
mean
and
co-
variance functions on a coarser grid using Algorithms
1
and
2
by
applying
them
on
the
four
locations
(k1, l1), (k2, l1), (k1, l2), (k2, l2), with an observed value mul-
tiplied by their respective coefﬁcients (1 − sx − sy + sxsy),
(sx − sxsy),(sy − sxsy),Kh(k2, l2)sxsy.
The overall complexity of the algorithm is linear in the
number of grid points and in the number of samples. It is
similar to ﬁltering an image and can be implemented the
same way on modern Graphics Processing Units (GPU). Please
note also that for kernels with large supports, a fast Fourier
transform may be used at the expense of a slight increase in
the complexity order that will be balance by the constant term
due to the support size.
V. PROCESSING TOOLS
The preceding phase allows the computation of a trafﬁc
pattern digest as a two dimensional grid of Symmetric Positive
Deﬁnite (SPD) matrices. It may be used as is for building
an index in a database, using the same procedure as for
images. However, the geometry underlying the space of 2 × 2
positive deﬁnite matrices is not euclidean, but hyperbolic. The
proposed index is an adaptation of images distances, using
hyperbolic geometry.
A. The Riemannian structure of symmetric positive deﬁnite
matrices
The purpose of this part is to introduce at a basic level the
tools used to build the index. Results are given without proofs,
the interested reader may refer to [15] for a more in-depth
exposition.

275
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Proposition 2. The space of n × n SPD matrices, denoted
by SPD(n), may be endowed with a Riemannian manifold
structure with metric at point A given by the differential:
ds2 = tr

276
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
evaluating its pertinence by identifying hot spots of complexity
within a given airspace. Some examples are given in ﬁgure 2,
with the complexity level ranging from green (lowest) to red
(highest). Points with a complex crossing patterns are correctly
identiﬁed as hot spots, while non convergent tracks have the
lowest complexity.
Fig. 2. Clustering of the airspaces over Paris (top), Toulouse (middle) and
Lyon (bottom).
VII. ADDING DENSITY INFORMATION
In the previous computations, the number of aircraft or
the density (i.e. number of ﬂights per unit area) are not
taken in consideration, as the Gaussian ﬁeld model encodes
only the geometry of the trafﬁc. In applications however,
especially those involving complexity, theses values have a
highly inﬂuential affect. As for controller’s workload, it is
of the same order of importance as the geometry. The raw
number of aircraft is not really relevant as soon as the airspace
considered exceed the size of a control sector. The density
is a better indicator and includes the aircraft number just be
integrating over the area of interest. It is easily estimated with
kernels. Given a set of sampled ﬂight positions (xi)i=1N at a
sampling time T, the average density is given at point x by:
dT (x) =
N
X
i=1
1
hK
∥x − xi∥
h

(26)
where h > 0 deﬁnes the size of the kernel and K : R+ → R+
has the following properties:









t > 1 ⇒ K(t) = 0
R
R+ K(t)dt = 1
∀t > 0 ∈ R, K(0) > K(t)
K ∈ C1(R)
(27)
Please note that in contrast with probability density non-
parametric estimation, the value obtained after summation is
not divided by the number of samples, neither by the size of
the time window. Since the function K integrates to 1, the
overall number of aircraft present at time T can be recovered
by integration. The ﬁrst assumption is not strictly needed, but
simpliﬁes the computations by avoiding taking into account
ﬂights that are too far to be inﬂuential. The effective support of
the kernel is determined by the parameter h. In an operational
context, taking 5 to 10 horizontal separation norms, i.e. 25
NM to 50 NM is enough. The third assumption ensures that
ﬂights away from the current position cannot be as inﬂuential
as one located there. It is a very mild assumption as all the
usual kernels are strictly decreasing (whith the exception of the
rectangular one, but that does not satisﬁes the ﬁnal smoothness
assumption). Finally, the function K must be at least C1.
In contrast with the covariance based representation, the
density is easily computed by a simple trick related to Fourier
transform.
Proposition 4. The Fourier transform of the density is given
by:
ˆd(ξ) = Θ(hξ)
N
X
i=1
ei⟨ξ,xi⟩
where, if d is the dimension of the space (i.e. 2 or 3):
Θ(ξ) = ∥ξ∥−(d−2)/2
Z
R+ K(t)td/2J(d−2)/2 (∥ξ∥t) dt

277
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Proof. This is just a standard application of the well known
relation between translations and Fourier transforms:
F(f(x − x0))(ξ) = ei⟨ξ,x0⟩F(f)(ξ)
The function Θ has a special form, since it is the fourier
transform of a radial basis function [16].
The power of the Fourier transform approach lies in the
fact that Θ does not depend on the samples and can be pre-
computed. The only part to estimate is the sum of exponentials.
Here again, a computational trick allows a very efﬁcient
implementation. First of all, the problem reduces to a one
dimensional case since:
e⟨ξ,x⟩ =
d
Y
j=1
eξjxj
Assuming that points of evaluation in the Fourier domain are
located on an evenly spaced grid, then any local interpolation
formula, like Lagrange polynomial interpolation, express the
value of the function eξjxj, j = 1 . . . d as a linear combination
of the function values on grid points. The summation problem
thus further reduces to a summation of weighted complex
exponentials over a regular grid. Provided the grid size is
selected to be a power of 2, this can be accomplished through a
Fast Fourier Transform (FFT). Many efﬁcient implementations
exist for modern hardware, including GPU. Due to the ability
to compute efﬁciently in the Fourier domain, the density
estimator adds only a marginal cost to the overall computation.
Taking into account the density in the overall process of
distance computation between trafﬁc images is not straight-
forward. Two main approaches can be retained:
• Consider the density as an extra information in each
generalized pixels that will thus be made of a positive
real value (the density) and a symmetric deﬁnite positive
matrix.
• Use the density as a multiplicative weighting factor. In
this case, the distance between two symmetric positive
deﬁnite matrices will be weighted by the distance be-
tween the densities at the same points.
Both have pro and cons, and the ﬁnal choice may depend
on the target application. If complexity is considered to be
the most important features of the trafﬁc, then the additive
procedure suffers from a severe ﬂaw: since it only adds to
the overall distance, areas with little trafﬁc will contribute
nearly at the same level as crowded ones if the geometry
of ﬂight paths are very different. However, for an ATCO,
the perceived complexity may be reversed just because of
the number of aircraft that must be managed may exceed
his monitoring capacities. The weighting approach does not
exhibit such a drawback as density difference acts by product.
Another beneﬁt of the multiplicative approach is that areas
with simultaneous low density will almost not contribute.
However, a ﬂaw still exists since areas with similar densities
and very different trafﬁc conﬁgurations will be ignored.
Based on the previous remarks, an hybrid approach was
retained:
• The density is added to he generalized pixels of the trafﬁc
image and contributes in an additive manner to the overall
distance. The distance between densities is modeled after
the Hellinger distance [17]. At the same location x, the
squared distance between two densities d1(x), d2(x) is
taken to be:
p
d1(x) −
p
d2(s)
2
• The supremum of the densities sup(d1(x), d2(x)) acts as
a weighting factor for the distance between covariance
matrices at point x.
A comparison between perceived workload on the Reims
control center in France and the above indicator is currently
under progress. The results are expected to be delivered in the
ﬁrst quarter of 2019.
VIII. CONCLUSION AND FUTURE WORK
The work presented here is still under development. How-
ever, primary results on complexity assessment are promising.
Based on the experience gathered on the topic, it is expected
that the new approach presented here will outperform the
current state-of-the-art metrics. Furthermore, thanks to the
ability to compute the distance between two grids of SPD(3)
elements, it offers the unique opportunity to derive a database
index for trafﬁc situations that will be an invaluable tool for
practitioners in the ﬁeld of air trafﬁc management. One of the
main possible usage of such metrics is to feed algorithms for
Dynamic Airspace Conﬁguration function. The metric should
allow to identify areas where the complexity is too high for
sharing the work between two different controllers. These
areas will then be used as Blocks to gather with other volumes
less constrained for creating new sectors. These will allow a
dynamic airspace conﬁguration adapted to the trafﬁc situation.
A possible future work is the validation of this approach of
dynamic sectorisation by comparing on a given airspace, the
areas identiﬁed by controllers as critical and those identiﬁed
by an algorithm using the complexity metric based on local
covariance.
From a computational point of view, some work must be
done on code optimization in order to speed up the process
and allow a full spatio-temporal estimation. Parallel computing
is also under investigation.
REFERENCES
[1] G. Mykoniatis, F. Nicol, and S. Puechmorel, “A new representation of
air trafﬁc data adapted to complexity assessment,” ALLDATA 2018 April
22 2018 - Athens, Greece, 2018.
[2] N. inc., “Neo4j, a native graph database,” http://neo4j.com/, 2018.
[3] M. Prandini, L. Piroddi, S. Puechmorel, and S. Brazdilova, “Toward air
trafﬁc complexity assessment in new generation air trafﬁc management
systems,” IEEE Transactions on Intelligent Transportation Systems,
vol. 12, no. 3, pp. 809–818, Sept 2011.

278
International Journal on Advances in Intelligent Systems, vol 11 no 3 & 4, year 2018, http://www.iariajournals.org/intelligent_systems/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[4] A. Cook, H. A. Blom, F. Lillo, R. N. Mantegna, S. Miccich, D. Rivas,
R. Vzquez, and M. Zanin, “Applying complexity science to air trafﬁc
management,” Journal of Air Transport Management, vol. 42, pp. 149
– 158, 2015. [Online]. Available: http://www.sciencedirect.com/science/
article/pii/S0969699714001331
[5] L. I. S. Shelden, R. Branstrom, and C. Brasil, “Dynamic density: An
air trafﬁc management metric,” NASA, Tech. Rep. NASA/TM-1998-
112226, 1998.
[6] K. Lee, F. E., and A. Prichett, “Air trafﬁc complexity : An input-
output approach,” in Proceedings of the US Europe ATM Seminar.
Eurocontrol-FAA, 2007, pp. 2–9.
[7] D. Delahaye and P. S., “Air trafﬁc complexity based on dynamical
systems.” in Proceedings of the 49th CDC conference.
IEEE, 2010.
[8] EUROCONTROL, “All-purpose structured eurocontrol surveillance
information exchange (asterix),” https://www.eurocontrol.int/services/
asterix.
[9] PROJ contributors, PROJ coordinate transformation software library,
Open
Source
Geospatial
Foundation,
2018.
[Online].
Available:
https://proj4.org/
[10] T. opensky network, “A community-base receiver network,” http://
opensky-network.org/.
[11] P. Hall, N. I. Fisher, and B. Hoffmann, “On the nonparametric estimation
of covariance functions,” Ann. Statist., vol. 22, no. 4, pp. 2115–2134,
12 1994. [Online]. Available: https://doi.org/10.1214/aos/1176325774
[12] Y. L., N. W., M. H., N. D. Turner, J. R. Lupton, and R. J. Carroll,
“Nonparametric estimation of correlation functions in longitudinal and
spatial data, with application to colon carcinogenesis experiments,”
Ann. Statist., vol. 35, no. 4, pp. 1608–1643, 08 2007. [Online].
Available: https://doi.org/10.1214/009053607000000082
[13] J. Y., Z. G., R. L., and H. W., “Nonparametric covariance model,”
Statistica Sinica, vol. 20, no. 1, pp. 469–479, 2010. [Online]. Available:
http://www.jstor.org/stable/24309002
[14] E. A. Nadaraya, “On estimating regression,” Theory of Probability &
Its Applications, vol. 9, no. 1, pp. 141–142, 1964. [Online]. Available:
https://doi.org/10.1137/1109020
[15] F. Nielsen and R. Bhatia, Matrix Information Geometry.
Springer
Berlin Heidelberg, 2012. [Online]. Available: https://books.google.fr/
books?id=MAhygTspBU8C
[16] G. Fasshauer, Meshfree Approximation Methods with MATLAB, ser.
Interdisciplinary
mathematical
sciences.
World
Scientiﬁc,
2007.
[Online]. Available: https://books.google.fr/books?id=gtqBdMEqryEC
[17] A. van der Vaart, Asymptotic Statistics, ser. Asymptotic Statistics.
Cambridge University Press, 2000. [Online]. Available: https://books.
google.fr/books?id=UEuQEM5RjWgC

