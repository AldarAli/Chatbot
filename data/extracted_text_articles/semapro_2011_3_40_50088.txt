Query Expansion for Peculiar Images by Web-extracted Hyponyms
Shun Hattori
School of Computer Science
Tokyo University of Technology
1404-1 Katakura-machi, Hachioji, Tokyo 192-0982, Japan
Email: hattori@cs.teu.ac.jp
Abstract—Most researches on Image Retrieval have aimed at
clearing away noisy images and allowing users to retrieve only
acceptable images for a target object speciﬁed by its object-
name. We have become able to get enough acceptable images
of a target object just by submitting its object-name to a con-
ventional keyword-based Web image search engine. However,
because the search results rarely include its uncommon images,
we can often get only its common images and cannot easily get
exhaustive knowledge about its appearance. As next steps of
Image Retrieval, it is very important to discriminate between
“Typical Images” and “Peculiar Images” in the acceptable
images, and moreover, to collect many different kinds of
peculiar images exhaustively. This paper proposes a novel
method to search the Web for peculiar images by expanding or
modifying a target object-name with its hyponyms extracted
from the Web by text mining techniques, and validates its
precision by comparing with Google Image Search.
Keywords-image retrieval; query expansion; peculiar images;
hyponymy; concept hierarchy
I. INTRODUCTION
In recent years, various demands have arisen in searching
the Web for images as well as documents (text) to utilize
them more effectively. When a name of a target object is
given by a user, the main goal of conventional keyword-
based Web image search engines such as Google Image
Search [1] and most researches on Image Retrieval (IR) is to
allow the user to clear away noisy images and retrieve only
the acceptable images for the target object-name, which just
include the target object in their content, as precisely as
possible. However, the acceptable images for the quite same
object-name are of great variety. Therefore, we sometimes
want to retrieve not only vague acceptable images of a target
object but also its niche images, which meet some kind of
additional requirements. One example of more niche image
searches allows the user to get special images of the target
object with the impression [2–4].
Another example of more niche demands, when only a
name of a target object is given, is to search the Web
for its “Typical Images” [5] which allow us to adequately
ﬁgure out its typical appearance features and easily associate
themselves with the correct object-name, and its “Peculiar
Images” [6–8] which include the target object with not
common (or typical) but eccentric (or surprising) appearance
features. For instance, most of us would uppermost associate
“sunﬂower” with “yellow one”, “cauliﬂower” with “white
one”, and “sapphire” with “blue one”, while there also exist
“red sunﬂower” or “black one” etc., “purple cauliﬂower” or
“orange one” etc., and “yellow sapphire” or “pink one” etc.
When we exhaustively want to know all the appearances
of a target object, information about its peculiar appearance
features is very important as well as its common ones.
Conventional Web image search engines are mostly Text-
Based Image Retrievals by using the ﬁlename, alternative
text, and surrounding text of each Web image. When such a
text-based condition as a name of a target object is given by
a user, they give the user the retrieval images which meet
the text-based condition. It has become not difﬁcult for us to
get typical images as well as acceptable images of a target
object just by submitting its object-name to a conventional
keyword-based Web image search engine and browsing the
top tens of the retrieval results, while peculiar images rarely
appear in the top tens of the retrieval results. As next steps of
IR in the Web, it is very important to discriminate between
“Typical Images” and “Peculiar Images” in the acceptable
images, and moreover, to collect many different kinds of
peculiar images as exhaustively as possible.
My previous works [6], [7] have proposed a basic method
to search the Web for peculiar images of a target object
whose name is given as a user’s original query, by expanding
the original query with its peculiar appearance descriptions
(e.g., color-names) extracted from the Web by text mining
techniques [9], [10] and/or its peculiar image features (e.g.,
color-features) converted from the Web-extracted peculiar
color-names. And to make the basic method more robust,
my previous work [8] has proposed a reﬁned method
equipped with cross-language (translation between Japanese
and English) functions like [11], [12]. As another solution,
this paper proposes a novel method to search the Web for
peculiar images by expanding or modifying a target object-
name (of an original query) with its hyponyms extracted
from the Web by using not hand-made concept hierarchies
such as WordNet [13] but enormous Web documents and
text mining techniques.
The remainder of this paper is organized as follows.
Section II explains my proposed method for Peculiar Image
Search. Section III shows several experimental results to
validate its precision. Last, Section IV concludes this paper.
69
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

II. METHOD
This section explains my proposed method to precisely
search the Web for “Peculiar Images” of a target object
whose name is given as a user’s original query, by expanding
the original query with its hyponyms extracted from the Web
by text mining techniques.
Figure 1 gives an overview of my Peculiar Image Search
(PIS) based on Web-extracted hyponym relations, while
Figure 2 gives an overview of my previous Peculiar Image
Search based on Web-extracted color-names [6–8].
Step 1. Hyponym Extraction
When a name of a target object as an original query is
given by a user, its hyponyms are automatically extracted
from exploding Web documents about the target object by
text mining techniques [14], [15]. Of course, they could
be extracted from hand-made concept hierarchies such as
WordNet [13]. The latter is precision-oriented, while the
former is rather recall-oriented. Therefore, this paper adopts
the former as a solution of the 2nd next step of Image
Retrieval to collect many different kinds of peculiar images
as exhaustively as possible.
Object-Name
“sunflower”
Hyponym
Extraction
Hyponyms
Text DB
(Web)
Query
Expansion
Ranking
Unified
Queries
Image DB
(Web)
Peculiar
Images
OUTPUT
INPUT
Figure 1.
Peculiar Image Search based on Web-extracted Hyponyms.
The PIS system collects candidates for hyponyms of
a target object o by using two kinds of lexico-syntactic
patterns “a * o” and “the * o” where “*” is wild-card.
Next, it ﬁlters out “* o” whose frequency of Web documents
searched by submitting [" * o"] as a query to Google Web
Search [16] is less than 10, and uses only the top 100 (at
most) candidates ordered by their document frequency.
Step 2. Query Expansion by Hyponyms
Here, we have two kinds of clues to search the Web for
peculiar images: not only a target object-name o (text-based
condition) as an original query given by a user, but also its
hyponyms h (text-based condition) automatically extracted
from not hand-made concept hierarchies such as WordNet
but the whole Web in Step 1.
The original query (q0 = text:["o"] & content: null) can
be modiﬁed or expanded by its hyponym h as follows:
q1
= text:["h"] & content: null,
q2
= text:["o" AND "h"] & content: null.
This paper adopts more conditioned latter to precisely search
the Web for its acceptable images and “Peculiar Images”.
Object-Name
“sunflower”
Color-Name
Extraction
Peculiar
Color-Names
Text DB
(Web)
Conversion
Query
Expansion
Ranking
Unified
Queries
Image DB
(Web)
Peculiar
Images
OUTPUT
INPUT
Peculiar
Color-Features
Figure 2.
Peculiar Image Search based on Web-extracted Color-Names.
70
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

Step 3. Image Ranking by Expanded Queries
This paper deﬁnes two kinds of weights of Peculiar Image
Search based on the expanded query (q2 = text:["h" AND
"o"] & content: null) in Step 2.
The ﬁrst weight pis1(i, o) is assigned to a Web image i
for a target object-name o and is deﬁned as
pis1(i, o) :=
max
∀h∈H(o)
{hyponym(h, o)
rank(i, o, h)2
}
where H(o) stands for a set of hyponyms of a target object-
name o extracted from the whole Web or the hand-made
WordNet in Step 1, a Web image i is retrieved by submitting
the text-based query ["o" AND "h"] (e.g., ["sunﬂower"
AND "evening sun"]) to Google Image Search [1], and
rank(i, o, h) stands for the rank (positive integer) of a Web
image i in the retrieval results from the Google’s image
database. And hyponym(h, o) ∈ [0, 1] stands for the weight
of a candidate h for hyponyms of a target object-name o. In
this paper, for any hyponym candidates h of a target object-
name o extracted from hand-made (so certainly precise)
concept hierarchies such as WordNet, hyponym(h, o) is set
to 1. Meanwhile, for Web-extracted hyponym candidates h
of a target object-name o, hyponym(h, o) is calculated as,
hyponym(h, o) := df(["h"]) /
max
∀h∈H(o){df(["h"])}
where df([q]) stands for the frequency of Web documents
searched by submitting a query q to Google Web Search.
The second weight pis2(i, o) is assigned to a Web image
i for a target object-name o and is deﬁned as
pis2(i, o) :=
max
∀h∈H(o)
{
ph(h, o)
rank(i, o, h)
}
where ph(h, o) ∈ [0, 1] stands for the weight of a candidate
h for Peculiar(-colored) Hyponyms of an object-name o,
ph(h, o) := (ph∗(h, o) − min(o))2
(max(o) − min(o))2
ph∗(h, o) := |Ik(o)| · |Ik(o, h)| ·
√
hyponym(h, o)
∑
i∈Ik(o)
∑
j∈Ik(o,h)
sim(i, j)
max(o) := max
∀h {ph∗(h, o)}, min(o) := min
∀h {ph∗(h, o)}
where Ik(o) and Ik(o, h) stand for a set of the top k
(at most 100) Web images retrieved by submitting the
text-based query ["o"] (e.g., ["sunﬂower"]) and ["o"
AND "h"] (e.g., ["sunﬂower" AND "evening sun"]) to
Google Image Search, respectively. And sim(i, j) stands for
the similarity between Web images i and j in the HSV color
space [17] as a cosine similarity,
sim(i, j) :=
∑
∀c
prop(c, i) · prop(c, j)
√∑
∀c
prop(c, i)2
√∑
∀c
prop(c, j)2
where c stands for any color-feature in the HSV color space
where 12 divides for Hue, 5 divides for Saturation, and 1
divide for Value (Brightness), and prop(c, i) stands for the
proportion of a color-feature c in a Web image i.
III. EXPERIMENT
This section shows several experimental results for the
following six kinds of target object-names to validate my
proposed method to search the Web for their peculiar images
more precisely than conventional Web image search engines
such as Google Image Search. Table I shows the numbers
of WordNet’s and Web-extracted hyponyms for each object.
Table I
NUMBER OF WORDNET’S AND WEB-EXTRACTED HYPONYMS.
Object-Name
WordNet’s
Web-extracted
sunﬂower
19
100
(of 531)
cauliﬂower
0
100
(of 368)
praying mantis
0
100
(of 253)
tokyo tower
0
92
(of 157)
nagoya castle
0
23
(of
57)
wii
0
100
(of 297)
Figure 3 shows the top k average precision of my
proposed Peculiar Image Searches (PIS) based on Web-
extracted hyponyms or hand-made concept hierarchies such
as WordNet, and Google Image Search for the above-
mentioned six target object-names. It shows that my PIS
method by using the second (more reﬁned) ranking pis2(i, o)
is superior to my PIS method by using the ﬁrst (simpler)
ranking pis1(i, o) as well as Google Image Search, and that
my PIS method by using Web-extracted hyponym relations
is superior to my PIS method by using WordNet’s ones.
0
0.1
0.2
0.3
0.4
0.5
0
10
20
30
40
50
60
70
80
90
100
Precision
Top k
pis2 with Web-extracted Hyponyms
pis1 with Web-extracted Hyponyms
pis1/2 with WordNet's Hyponyms
Google Image Search
Figure 3.
Top k Average Precision of Google Image Search (query: q0)
vs. Peculiar Image Searches (query: q2, ranking: pis1 or pis2).
71
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

Table II
TOP 20 PECULIAR(-COLORED) HYPONYMS OF “SUNFLOWER”.
hyponym(h, o)
ph(h, o)
1
good sunﬂower
1.000
pink sunﬂower
1.000
2
tall sunﬂower
1.000
raw sunﬂower
0.789
3
ground sunﬂower
0.984
shelled sunﬂower
0.770
4
same sunﬂower
0.968
brunning sunﬂower
0.758
5
few sunﬂower
0.964
roasted sunﬂower
0.669
6
small sunﬂower
0.929
complex sunﬂower
0.645
7
ﬁrst sunﬂower
0.915
hotel sunﬂower
0.533
8
giant sunﬂower
0.913
purple sunﬂower
0.511
9
raw sunﬂower
0.910
green sunﬂower
0.493
10
growing sunﬂower
0.900
black sunﬂower
0.470
11
new sunﬂower
0.900
black oil sunﬂower
0.386
12
huge sunﬂower
0.898
gray sunﬂower
0.370
13
black oil sunﬂower
0.890
modern sunﬂower
0.357
14
complex sunﬂower
0.890
metal sunﬂower
0.335
15
brunning sunﬂower
0.878
emmanuelle sunﬂower
0.332
16
large sunﬂower
0.876
dried sunﬂower
0.331
17
toasted sunﬂower
0.875
given sunﬂower
0.289
18
tiny sunﬂower
0.868
blue sunﬂower
0.282
19
normal sunﬂower
0.856
red sunﬂower
0.277
20
u.s. sunﬂower
0.855
kids’ sunﬂower
0.223
Table III
TOP 20 PECULIAR(-COLORED) HYPONYMS OF “CAULIFLOWER”.
hyponym(h, o)
ph(h, o)
1
spicy cauliﬂower
1000
purple cauliﬂower
1.000
2
grated cauliﬂower
1.000
pink cauliﬂower
0.455
3
remaining cauliﬂower
1.000
fried cauliﬂower
0.268
4
purple cauliﬂower
0.984
spicy cauliﬂower
0.255
5
blanched cauliﬂower
0.975
yellow cauliﬂower
0.234
6
creamy cauliﬂower
0.975
few cauliﬂower
0.230
7
leftover cauliﬂower
0.965
huge cauliﬂower
0.230
8
fried cauliﬂower
0.948
grated cauliﬂower
0.191
9
raw cauliﬂower
0.948
regular cauliﬂower
0.186
10
boiled cauliﬂower
0.944
curried cauliﬂower
0.179
11
huge cauliﬂower
0.940
tiny cauliﬂower
0.168
12
yellow cauliﬂower
0.934
golden cauliﬂower
0.166
13
organic cauliﬂower
0.932
crispy cauliﬂower
0.148
14
crunchy cauliﬂower
0.928
little cauliﬂower
0.140
15
or cauliﬂower
0.905
tandoori cauliﬂower
0.139
16
baby cauliﬂower
0.904
cheddar cauliﬂower
0.129
17
tiny cauliﬂower
0.898
leftover cauliﬂower
0.123
18
golden cauliﬂower
0.884
yummy cauliﬂower
0.120
19
garlic cauliﬂower
0.877
larger cauliﬂower
0.116
20
drained cauliﬂower
0.874
braised cauliﬂower
0.115
Tables II and III show the top 20 peculiar hyponyms with
peculiar color-features of a target object-name, “sunﬂower”
and “cauliﬂower”, respectively. They show that ph(h, o) used
by the second (more reﬁned) ranking pis2(i, o) is superior to
hyponym(h, o) used by the ﬁrst (simpler) ranking pis2(i, o)
as a weighting function of peculiar hyponyms h for each
target object-name o. Figure 4 shows the top k average
precision of hyponym extraction from the Web. ph(h, o)
gives 42.5% (not much different) precision at k = 20
for hyponym extraction, while hyponym(h, o) gives 42.5%
precision. And Figure 5 shows the top k average precision
of peculiar hyponym extraction from the Web. ph(h, o) gives
16.7% (superior) precision at k = 20 for peculiar hyponym
extraction, while hyponym(h, o) gives 10.0% precision.
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
Precision
Top k
ph(h,o)
hyponym(h,o)
Figure 4.
Top k Average Precision of Hyponym Extraction from the Web.
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
Precision
Top k
ph(h,o)
hyponym(h,o)
Figure 5.
Top k Average Precision of Peculiar(-Colored) Hyponym
Extraction from the Web.
Figures 6 to 11 show the top 20 search results for
each target object-name, “sunﬂower” or “cauliﬂower”, to
compare between Google Image Search [1] as a conventional
keyword-based Web image search engine, and my proposed
Peculiar Image Search by using the ﬁrst (simpler) ranking
function pis1(i, o) or the second (more reﬁned) ranking func-
tion pis2(i, o) based on Web-extracted hyponym relations.
They show that my proposed Peculiar Image Searches are
superior to Google Image Search to search the Web for
peculiar images of a target object-name.
72
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

Figure 6.
Top 20 results of Google Image Search
(query: q0, ranking: Google, object-name: “sunﬂower”).
Figure 7.
Top 20 results of Peculiar Image Search
(query: q2, ranking: pis1(i, o), object-name: “sunﬂower”).
Figure 8.
Top 20 results of Peculiar Image Search
(query: q2, ranking: pis2(i, o), object-name: “sunﬂower”).
Figure 9.
Top 20 results of Google Image Search
(query: q0, ranking: Google, object-name: “cauliﬂower”).
Figure 10.
Top 20 results of Peculiar Image Search
(query: q2, ranking: pis1(i, o), object-name: “cauliﬂower”).
Figure 11.
Top 20 results of Peculiar Image Search
(query: q2, ranking: pis2(i, o), object-name: “cauliﬂower”).
73
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

IV. CONCLUSION AND FUTURE WORK
As next steps of Image Retrieval (IR), it is very important
to discriminate between “Typical Images” and “Peculiar
Images” in the acceptable images, and moreover, to collect
many different kinds of peculiar images exhaustively. In
other words, “Exhaustiveness” is one of the most important
requirements in the next IR. As a solution, my previous
works proposed a basic method to precisely search the
Web for peculiar images of a target object by its peculiar
appearance descriptions (e.g., color-names) extracted from
the Web and/or its peculiar image features (e.g., color-
features) converted from them. And to make the basic
method more robust, my previous work proposed a reﬁned
method equipped with cross-language (translation between
Japanese and English) functions.
As another solution, this paper has proposed a novel
method to search the Web for peculiar images by expanding
or modifying a target object-name (of an original query) with
its hyponyms extracted from the Web by using not hand-
made concept hierarchies such as WordNet but enormous
Web documents and text mining techniques. And several
experimental results have validated the retrieval precision of
my proposed method by comparing with such a conventional
keyword-based Web image search engine as Google Image
Search. They also show that my second (more reﬁned)
ranking pis2(i, o) is superior to my ﬁrst (simpler) ranking
pis1(i, o), and that using Web-extracted hyponym relations
is superior to using hand-made WordNet’s ones.
In the near future, as clues of query expansion for Peculiar
Images of a target object-name, I try to utilize both its
Web-extracted hyponym relations and hand-made concept
hierarchies, and also both its hyponyms and appearance
descriptions (e.g., color-names). In addition, I try to utilize
the other appearance descriptions (e.g., shape and texture)
besides color-names and the other image features besides
color-features in my various Peculiar Image Searches.
ACKNOWLEDGMENT
This work was supported in part by JSPS Grant-in-Aid for
Young Scientists (B) “A research on Web Sensors to extract
spatio-temporal data from the Web” (23700129, Project
Leader: Shun Hattori, 2011-2012).
REFERENCES
[1] Google Image Search，http://images.google.com/ (2011).
[2] Robert Inder, Nadia Bianchi-Berthouze, and Toshikazu Kato:
“K-DIME: A Software Framework for Kansei Filtering of In-
ternet Material,” Proceedings of the 1999 IEEE International
Conference on Systems, Man and Cybernetics (SMC’99),
Vol.6, pp.241–246 (1999).
[3] Takio Kurita, Toshikazu Kato, Ikumi Fukuda, and Ayumi
Sakakura: “Sense Retrieval on a Image Database of Full Color
Paintings,” Transactions of Information Processing Society of
Japan (IPSJ), Vol.33, No.11, pp.1373–1383 (1992).
[4] Haruo Kimoto: “An Image Retrieval System Using Impres-
sional Words and the Evaluation of the System,” Transactions
of Information Processing Society of Japan (IPSJ), Vol.40,
No.3, pp.886–898 (1999).
[5] Shun Hattori and Katsumi Tanaka: “Search the Web for
Typical Images based on Extracting Color-names from the
Web and Converting them to Color-Features,” Letters of
Database Society of Japan, Vol.6, No.4, pp.9–12 (2008).
[6] Shun Hattori and Katsumi Tanaka: “Search the Web for
Peculiar Images by Converting Web-extracted Peculiar Color-
Names into Color-Features,” IPSJ Transactions on Databases,
Vol.3, No.1 (TOD45), pp.49–63 (2010).
[7] Shun Hattori: “Peculiar Image Search by Web-extracted Ap-
pearance Descriptions,” Proceedings of the 2nd International
Conference on Soft Computing and Pattern Recognition
(SoCPaR’10), pp.127–132 (2010).
[8] Shun Hattori: “Cross-Language Peculiar Image Search Using
Translation between Japanese and English,” Proceedings of
the 2011 First IRAST International Conference on Data
Engineering and Internet Technology (DEIT’11), pp.418–424
(2011).
[9] Shun Hattori, Taro Tezuka, and Katsumi Tanaka: “Extracting
Visual Descriptions of Geographic Features from the Web as
the Linguistic Alternatives to Their Images in Digital Doc-
uments,” IPSJ Transactions on Databases, Vol.48, No.SIG11
(TOD34), pp.69–82 (2007).
[10] Shun Hattori, Taro Tezuka, and Katsumi Tanaka: “Mining the
Web for Appearance Description,” Proc. of the 18th Interna-
tional Conference on Database and Expert Systems Applica-
tions (DEXA’07), LNCS Vol.4653, pp.790–800 (2007).
[11] Oren Etzioni, Kobi Reiter, Stephen Soderland, and Marcus
Sammer: “Lexical Translation with Application to Image
Search on the Web,” Proc. of Machine Translation Summit
XI (2007).
[12] Jin Hou, Dengsheng Zhang, Zeng Chen, Lixing Jiang,
Huazhong Zhang, and Xue Qin: “Web Image Search by
Automatic Image Annotation and Translation,” Proceedings
of the 17th International Conference on Systems, Signals and
Image Processing (IWSSIP’10), pp.105–108 (2010).
[13] WordNet，http://wordnetweb.princeton.edu/ (2011).
[14] Marti A. Hearst: “Automatic Acquisition of Hyponyms from
Large Text Corpora,” Proceedings of the 14th International
Conference on Computational Linguistics (COLING’92),
pp.539–545 (1992).
[15] Shun Hattori and Katsumi Tanaka: “Extracting Concept Hier-
archy Knowledge from the Web based on Property Inheritance
and Aggregation,” Proceedings of the 7th IEEE/WIC/ACM
International
Conference
on
Web
Intelligence
(WI’08),
pp.432–437 (2008).
[16] Google Web Search，http://www.google.com/ (2011).
[17] John R. Smith and Shih-Fu Chang: “VisualSEEk: A Fully Au-
tomated Content-Based Image Query System,” Proceedings of
the 4th ACM International Conference on Multimedia (ACM
Multimedia’96), pp.87–98 (1996).
74
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

