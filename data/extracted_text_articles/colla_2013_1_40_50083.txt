  Abstract — How can we know what has happened within a 
work group? How can we visualize the non-visual? How can 
we evaluate forms of interaction in the context of group work? 
These are some of the questions we tried to answer with Qlim, 
using online brainstorming activities. To achieve this goal, 
we collected data related to users’ activities, then we used 
several visualization techniques to show the evolution of the 
interactions: zoomable graphs to get more detailed information 
and synthetic graphs to allow an overall perception of the 
activity using colorization and fill.
Keyword-Interactions; collaboration; emergence; monitoring; 
visualization.
I.  IntroductIon
Collective intelligence emerges from interactions between 
individuals when a group is involved in a creative task or in 
solving a problem [1]. The singularity of such a phenomenon 
is that the effect of the group action is greater than the sum 
of that of all individuals. Collective interaction is complex, 
involving direct and indirect causes that are difficult to 
observe and to link together.
Most of the time, the only indicator of collective 
efficiency is the final global result of the collaboration. On a 
large scale, open sources software development or Wikipedia 
are some examples of crowd sourcing results. Outside 
observation of these effects, the inner mechanisms of the 
collective phenomena are theorized, but few are measured 
in real situations. For this purpose, we developed a platform 
dedicated to supporting collective intelligence with a full 
statistical and graphical monitoring environment. This allows 
us to observe various causes and effects of the collective 
action (consensus evolutions, influence, changes of opinion, 
etc.) from a structural and temporal perspective.
The Qlim (in French: Questionnaire en Ligne Interactif 
et Malléable - Interactive, Tailorable, Online Questionnaire) 
platform was designed to support online group interaction 
on the basis of a shared feedback mechanism as occurs in 
a brainstorming session. In short, the process starts with 
few questions and answer choices (QA). Participants are 
invited by e-mail to come to answer these questions, add new 
questions and add new answer choices. They are notified by 
e-mail of all additions made during the day. They can return to 
modify their answers at any time or to make new propositions 
for question or answer choices, and so on. This system was 
tested in a dozen asynchronous brainstorming experiments, 
each involving an average of 20 people.
This paper is organized as follows. First, we will present 
Qlim and its role in supporting collective intelligence. Then, 
Exploring Collective Intelligence in Online Brainstorming
we will describe the monitoring environment, some examples 
of statistical and visualization results and an overview of 
the latest developments in the field of group dynamics 
monitoring. Finally, we will discuss these results and present 
our future work perspectives.
II.  collectIve phenomena In InteractIve 
questIonnaIres
As a tool to support collective intelligence, Qlim is a web-
application (see Figure 1) that relates to the brainstorming 
technique. It is made to build questionnaires, but like a 
brainstorming session, Qlim is useful for collecting data on 
opinions or new ideas. These questionnaires, very easy to 
use, are spread out in time, and it is up to the creator to decide 
when the questionnaire ends. Qlim presents some special 
functions. It is an interactive questionnaire, which means 
the participants are not just passive respondents. With Qlim, 
respondents can add some new answer choices, and some 
questions, which comes down to extending the questionnaire 
to suit their desires and their trends. A questionnaire can 
thus take the form of an open debate, which can stimulate 
creativity and bring a lot of new thinking. Qlim has also 
several other features. It supports the respondents by sending 
a summary in the evening in case of additions made during 
the day, to encourage them to further fuel the debate. Qlim 
also has color user guidance to highlight the news, ensuring 
the respondent will focus on the news, if he wishes.
“To solve a problem, much of the solution lies in the 
wording of the question” [2]. Qlim allows expression and 
creativity, it helps participants formalize their subjects of 
interest into a structured frame (unlike an online open debate 
forum). It is based on a question and radio buttons system, 
designed to encourage the participants to make a precise 
choice or to ask some new questions or to add new answer 
choices, to react, to criticize or to develop; it is designed to be 
creative and to give an open direction to the discussion unlike 
traditional questionnaires. The goal of Qlim is not specially 
to lead to a consensus, it is a creative space: the final question 
can be off-topic with regard to the first question.
Qlim captures what is exchanged in a group. The problem 
in common brainstorming systems is the lack of structure; 
a regular brainstorming session is not especially structured 
(it returns a raw list of ideas). However, the Qlim structure 
allows easy exploitation of the results of any interaction. Qlim 
uses the frame (textbox, radio buttons) so the participants 
have to identify and break down what they want to say, to 
be synthetic, so they structure their thoughts. This way, all 
interaction can be logged and these traces can be exploited to 
understand the behavior, developments and influences.
Yann Veilleroy
Faculté Libre de Médecine
Université Catholique de Lille
Lille, France
e-mail : yann.veilleroy@ed.univ-lille1.fr
Gabriel Eurin, Frédéric Hoogtoel, Luigi Lancieri
Laboratoire d’Informatique Fondamentale de Lille
Université Lille1 Sciences et Technologies
Villeneuve d’Ascq, France
e-mail : gabriel.eurin@polytech-lille.net,
{frederic.hoogstoel, luigi.lancieri}@univ-lille1.fr
18
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-287-5
COLLA 2013 : The Third International Conference on Advanced Collaborative Networks, Systems and Applications

Qlim’s first aspect is the enhanced use of questionnaires, 
with two kinds of people, the creator who initiates the 
questionnaire and the participants. The second aspect is the 
use of the logged traces in order to monitor the interaction.
A. Qlim usage, from the creator’s point of view
Figure 2 shows the user interface involved in this process. 
The “New questionnaire” button is available from the creator 
home menu. Creating a new questionnaire is simple. There 
are only four textboxes to fill, namely:
• 
the heading of the first question (for more questions, 
enter the questionnaire and press the “Add a question” 
button)
• 
some answer choices (if desired),
• 
the participants’ e-mail addresses
• 
a name for the questionnaire
Before pressing the Save button, one important thing 
remains to be done: to choose “With” or “Without” the scores. 
Figure 3 shows the distinctive elements displayed when 
the creator chooses with the scores, namely, the number of 
participants who answered the question at the top of the page 
and a percentage at the end of the line for each answer choice 
(the “score”). It represents the success rate of each answer 
choice among the participants who answered the question. If 
present, these data may influence the participants because it 
becomes possible to know the trend of the group.
An Administration menu gives access to private functions 
to manage participants and questionnaires. The creator is 
able to list, to add or delete a participant to/from one of his 
questionnaires; he is also able to delete, to disable or enable 
his own questionnaires.
B. Qlim usage, from the participant’s point of view
When a questionnaire is created, each participant receives 
an e-mail that is an invitation to participate in a Qlim 
questionnaire. Inside the message, a link directly leads to 
the web page with the first question. The participant makes 
a choice selecting a radio button and saves it by clicking the 
Save button. All the questions are listed in a column on the 
left side; the participant clicks the question he wants to answer 
(see Figure 1), in the order he wishes. If he changes his mind, 
he can go back to modify his answer at any time. If the existing 
answers choices do not suit him, the participant can propose 
a new one simply by writing one or more answer choices in 
the textbox just below the question. It is also possible to add 
a new question by a click on the big button “Add a question” 
Figure 1. QLIM’s page, to respond, add questions and answer choices, with guides.
Figure 2. Creation principle
Figure 3. The distinctive elements of a question -with- scores
19
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-287-5
COLLA 2013 : The Third International Conference on Advanced Collaborative Networks, Systems and Applications

(see Figure 1). This can happen if a participant wants to ask a 
question to know the opinion of the others, to fuel the debate, 
or if he finds “it’s not a good question!” or a relevant one, 
or if he wants to complete or to correct answers. He puts the 
heading and some answer choices if he wants, then clicks the 
Save button. It is also possible to add a question without any 
answer choices, in order to encourage questioning and to see 
the answers brought by the others. All new things, question 
and answer choices are available for all participants. Every 
evening, the new questions and the new answer choices are 
counted. If there were some creations, the summary of the 
day’s activity is sent by e-mail to every participant.
Participants are helped to rapidly identify changes 
through the user interface colored marks, a little bit like 
unread messages in a mailbox that are highlighted in a bold 
font (see Figure 4). A question that did not exist the last time 
the participant logged on appears in a red font and a question 
with new answer choices appears in an orange font. This is 
to draw attention to what’s new to encourage participation. 
The main menu gives access to the help function and enables 
every participant to know the results.
III.  monItorIng tool In qlIm
Usually, traditional questionnaires provide statistics and 
graphs about their results. But the traditional questionnaires 
do not use the time or interactions links, so their results are 
like a snapshot. In comparison, Qlim brings new features that 
describe the complexity of the interaction more accurately. A 
questionnaire, like a brainstorming session, needs time. So 
the results cannot be just a mere snapshot, because it would 
be impossible to understand what happened without tracking 
the chronology of the interactions. A mere snapshot would be 
a great loss of valuable information. That’s why, in addition 
to the usual standard numerical results, Qlim supplies trends 
over time, which represent, in fact, the evolution of the 
interaction. By building Qlim, our intention was to try to 
understand collective phenomena inside a group. So, from 
the beginning, Qlim was designed to record each interaction. 
Every time an interaction occurs, it is recorded. We determined 
five features that are stored in relation to the user id through 
the questionnaire’s life duration: Visit a question, Answer a 
question, Add a new response choice, Add a new question, 
Modify an answer.
Used in Creative Problem Solving, the well-known 5 Ws 
(and one H) [3] (who, what, where, when, how, with what, 
and how), is an old formula used by police, journalists and 
researchers [4]. It inspired us, and in our database, the data 
structure that store the interactions matches the five Ws, and 
was even extended to store more parameters. The Who col-
umn stores the e-mail, the What column stores the type of 
interaction, the Where column stores the page name on which 
the interaction occurred, the When column stores the date 
(and hour), and the others store values like the questionnaire 
index, the question index, etc. By consulting this table, we 
generate reports, tables of numbers and graphs.
Exploring and analyzing vast amounts of data can be very 
difficult [5], but the way we stored the data is very helpful 
(storing using this method has already been used [6]). This 
storage method simplifies the queries a lot and allows a large 
number of graphs. We made general graphs for the whole 
questionnaire (see Figure 5) with a graph for each action, to 
show their evolution, graphs (histograms and pie charts) of 
the activity of each participant, and graphs of the actions for 
each question. It becomes possible to study both individual 
behavior and collective phenomena.
The first set of graphs uses the time as the abscissa axis 
and the different actions as the ordinate axis. So, we can 
produce the evolution in time of the five actions (Visit, 
Answer, Add a new response choice, Add a new question, 
Modify). Technically, when the creator asks for graphs, a 
data set is created using several loops, then sent to a graphic 
library for display (JPGraph). We get histograms, grouped 
bar charts, accumulated bar charts showing the quantity of 
interaction in one time slot, or histogram and line combined 
showing each interaction plus accumulated visits, either for 
the whole questionnaire or for one question at a time, for all 
participants or one participant at a time.
“We showed that our eyes can quickly evaluate a situation 
of cause and effect, without the help of our cognitive system” 
said Patrick Cavanagh in January 2013 [7]. Thus, we have 
visually arranged all our graphs in vertical alignment (see 
Figure 6). The time scale is the same for all graphs, so it 
is possible to read in a set. This enables us to find parallels 
between the different actions at the same time (e.g., the effect 
caused by the arrival of a particular question). It makes it 
possible to see in one look the collective phenomena, cause 
and effect relationships, influences that could explain a 
turnaround, anything that cannot be observed with traditional 
questionnaires.
A second set of graphs has come from the use of another 
recent graphic library, D31, which is made of JavaScript and 
Ajax and allows some interaction once the graph is plotted. 
For example, the abscissa axis of the graph is “zoomable” 
using a cursor. It does not bring new data, the data remain 
the same, but it allows a larger view, which can be useful at 
times. Another feature causes a resampling of the data table 
on display, to get this time a more detailed view. To get a 
more detailed view is a shared concern, it seems [8].
Figure 4. Highlighting
Figure 5. General graph for the whole questionnaire
1 http://d3js.org (May 2013)
20
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-287-5
COLLA 2013 : The Third International Conference on Advanced Collaborative Networks, Systems and Applications

Besides the histograms, a third set of graphics is available. 
Collective intelligence stems from how well the group works 
together. Woolley [9] shows that a group where one person is 
dominant is less collectively intelligent and has poorer results 
(in solving problems - puzzles, games, etc.) than groups 
where conversational turns are more evenly distributed. 
The individual abilities of its members do not determine 
the performance of a group, and moreover a group whose 
members have higher social sensibility is more collectively 
intelligent. So, we made a view of the collective activity, of 
the distribution of the interaction and how many participants 
interacted. On a first graph (see Figure 7), we have drawn 
some donuts. The participant who made the highest number of 
interactions has a full donut, in proportion to his interactions. 
He is the maximum, the point of reference; all the others are 
calculated compared to him. We can see that even a lack of 
interaction has a specific meaning. We used the “Nothing” 
(transparent) interaction to fill the remainder of the donut to 
100% when a participant made fewer interactions than the 
reference. There is one donut per participant on the graph 
and all the participants are on the graph, so this is another 
way to measure at a glance the collective activity, how it was 
distributed and how many participants have been interacting. 
A second graph represents a table (see Figure 8) with the time 
as the abscissa axis and the participants as the ordinate axis. 
In each cell, a matrix (2x2), contains four small color squares. 
Each one of the five interactions is represented by a color, 
for this participant, at this time. Calculated on the maximum 
number of interactions, the strength of the color (pale, 
medium, dark) shows how active the participant has been. 
This way, the group can take a dominant color or be a colored 
patchwork. The group colors make it possible to perceive at 
a glance the interactions that occurred. No red means that no 
questions were added, for example. A lot of orange squares 
means that the group changed its mind many times, etc. The 
more the group is monochrome, the less variety there has 
been in the interaction. On the contrary, a patchwork of colors 
means there have been many different interactions. This is a 
way to measure at a glance the collective activity, how it was 
distributed and how many participants have been interacting. 
We also included a wordcloud which is interesting to get a 
quick look at the most used words in a questionnaire. Data 
can be exported to a .csv file for further manipulation, for 
some graphics, this is a subject for our future work.
Iv.  state of the art
Traditional questionnaires are very regulated, framed, 
constrained (check boxes, radio buttons, textboxes for open-
ended questions, etc.), impossible to go back (later) to modify 
answers. They are static: no “ping-pong” game between the 
participants, no real interaction is possible. Nevertheless, it 
was observed that the respondents respond willingly when 
they are given the opportunity to do so, and the web mode also 
appears to be easier for this: open-ended questions by e-mail 
collect longer answers and more information than a paper 
survey [10, 11, 12]. That’s why an interactive questionnaire 
can be a place to collect lots of valuable information. We have 
noticed two other questionnaire-based collective intelligence 
tools: e-Brainstorming and Real-Time Delphi.
Figure 6. Each histogram represents an interaction
21
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-287-5
COLLA 2013 : The Third International Conference on Advanced Collaborative Networks, Systems and Applications

A.  e-Brainstorming
The eBrainstorming is an initiative from the Orange Labs 
in Caen [2]. It is a computerized system of close-ended ques-
tions, a multiple choice questionnaire system (MCQ), in-
tended to simplify and synthesize the opinions of a group. 
The system allows the respondents to add new questions and 
possible answers, and they can leave a comment in a free 
comments zone inside a question. It works without a modera-
tor; the group has to be self-moderated. The questionnaire is 
scripted using simple and easy tagged language. It is written 
in one form, on a mobile phone application for example [14], 
then sent to a web server. The server generates the question-
naire, then a return mail is sent to the author with the URL 
of the web questionnaire, to be distributed to the chosen par-
ticipants. The participants can access the synthesis (statistics, 
graphics). The system uses traces to evaluate the collective 
intelligence phenomena, and data can be exported.
Face-to-face brainstorming was an idea of A. Osborn 
[15] in the nineteen-forties, introduced to make his company 
more creative. In a Brainstorming session, there must be no 
criticism in order not to hinder creativity, so any idea can 
be a starting point for creative development from other 
participants. It gives a raw list of ideas in a short time.
B.  Delphi, Real-Time Delphi
The Delphi method is a structured communication 
technique, which tries to get opinions, judgments and 
justifications from the participants. It seeks a consensus 
(if possible), with a carefully prepared predefined set of 
questions, but here the creativity is controlled and contained. 
There are multiple rounds where questionnaires allow experts 
to provide their judgment, then to revise their answers (to be 
more accurate [16]). The process stops when a pre-defined 
criterion has been reached. The reasons and arguments 
collected can be highly valuable and useful. But Delphi takes 
time and requires good time management. It may be found 
long, expensive, tedious and requires a lot of effort [17].
Real-Time Delphi [13] is a computerization of the Delphi 
method, where Artificial Intelligence and Natural Language 
replace the human monitoring. It works “roundless”: every 
participant can come at anytime to update his input. Each 
question comes with some information (the average/median 
response of the group, the number of responses, the reasons).
C.  Visualization of interactions
Wanting to know what happens during group work, and 
to read the interaction is a current need, at the origin of a 
large number of very diverse projects. In 2006, Calvani et al. 
[18] wanted to visualize effective interaction in online collab-
orative groups. They found several methods in the literature: 
Quantitative methods for content analysis, the most used (De 
Wever et al. [19] and Van Keer [20] made a review). This 
method, they say, consists roughly of coding single messages 
and statistically analyzing them to read the frequency and 
identify the relationships. Social Network analysis is another 
method used to analyze interaction among the members of a 
community, about this latter method, Calvani et al. [18] cite 
Cho et al. [21]; De Laat et al. [22]; Garton et al. [23]; Reffay 
and Chanier [24], but they found that the tools (very roughly: 
an analysis of individual messages between individuals) did 
Figure 8. The collective activity by a table graph (anonymized)
Figure 7. The collective activity by a donuts graph
22
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-287-5
COLLA 2013 : The Third International Conference on Advanced Collaborative Networks, Systems and Applications

not fit their situation. They considered quantitative methods 
based on Conversation Analysis [25, 26] to be time-con-
sumers. Calvini et al. [18] were working on a forum inside 
Moodle2, and they improved this module in order to monitor 
interaction. However, to observe interaction, a forum has one 
serious drawback, that is, the different actions are not quite 
distinct. Indeed, it is possible to add a post, for example, and 
we agree that this is an interaction which is possible to trace. 
However, one can do a large number of things in a single 
post, and it is difficult to analyze every interaction in that 
case. A forum does not seem to be the best tool to achieve that 
goal, because the actions are not distinct enough.
v.  conclusIon and future work
As we have seen, this paper presents a tool that has two 
strengths in its combined features. First, the malleability 
(tailorability) of Qlim simplifies and enhances collaboration 
within groups. This helps the emergence of creative new 
ideas and solutions. Secondly, Qlim provides monitoring 
of non-visual aspects of the collective phenomena. In this 
regard, we can say that Qlim is more a laboratory tool than an 
operational one. There remain several possible improvements, 
for example to compare various experiments. Another kind 
of representation is needed, based on new indicators of 
collective collaboration with more descriptive graphics.
references
[1] T. Malone, R. Laubacher, and C. Dellarocas, “Harnessing 
crowds: Mapping the genome of collective intelligence,” 2009.
[2] L. Lancieri, A. Lavallar, and P. Manson, “E-Brainstorming: 
Optimization of collaborative learning thanks to online 
questionnaires,” In Proceedings of CELDA IADIS International 
conference. 2005.
[3] D. Ruellan, “La routine de l’angle.” Dans Questions de 
communication, 2006, no. 10, pp. 369-390.
[4] L. Lancieri and N. Durand, “Internet user behavior: compared 
study of the access traces and application to the discovery of 
communities,” Systems, Man and Cybernetics, Part A: Systems 
and Humans, IEEE Transactions on, 2006, vol. 36, no. 1, pp. 
208-219.
[5] D.A. Keim, “Information visualization and visual data mining,” 
Visualization and Computer Graphics, IEEE Transactions on, 
2002, vol. 8, no. 1, pp. 1-8.
[6] J. Ćosić, Z. Ćosić, and M. Baća, “An Ontological Approach 
to Study and Manage Digital Chain of Custody of Digital 
Evidence,” Journal of Information and Organizational 
Sciences, 2011, vol. 35, no. 1, pp. 1-13.
[7] M. Rolfs, M. Dambacher, and P. Cavanagh, “Visual adaptation 
of the perception of causality,” Current Biology, 2013, vol. 23, 
no. 3, pp. 250-254.
[8] A. Lavallard and L. Lancieri, “Observation de l’évolution des 
communautés d’intérêts,” 2004.
[9] A.W. Woolley, C.F. Chabris, A. Pentland, N. Hashmi, and T.W. 
Malone, “Evidence for a collective intelligence factor in the 
performance of human groups,” Science, 2010, vol. 330, no. 
6004, pp. 686-688.
[10] D. Bachmann, J. Elfrink, and G. Vazzana, “Tracking the 
progress of e-mail vs. snail-mail,” Marketing Research, 1996, 
vol. 8, pp. 31-35.
[11] K.B. Sheehan, “E-mail survey response rates: A review. Journal 
of Computer-Mediated Communication,” 2001, vol. 6, no. 2.
[12] A.M. Paolo, G.A. Bonaminio, C. Gibson, T. Partridge, and 
K. Kallail, “Response rate comparisons of e-mail-and mail-
distributed student evaluations. Teaching and Learning in 
Medicine, 2000, vol. 12, no. 2, pp. 81-84.
[13] T. Gordon and A. Pease, “RT Delphi: an efficient,“round-less” 
almost real time Delphi method,” Technological Forecasting 
and Social Change, 2006, vol. 73, no. 4, pp. 321-333.
[14] K. Hamadache, P. Manson, and L. Lancieri, “Pervasive 
services, brainstorming in situation of mobility,” In : Pervasive 
Computing and Applications, 2008. ICPCA 2008. Third 
International Conference on. IEEE, 2008. pp. 709-714.
[15] A. Osborn, “Your creative power,” 1950.
[16] T.J. Gordon, “The Delphi method,” Futures research 
methodology, 1994, pp. 1-33.
[17] J.P. Ekionea, P. Bernard, and M. Plaisent, “Consensus 
par la méthode Delphi sur les concepts clés des capacités 
organisationnelles spécifiques de la gestion des connaissances. 
Recherches qualitatives, 2011, pp. 168.
[18] A. Calvani, A. Fini, M. Molino, and M. Ranieri, “Visualizing 
and monitoring effective interactions in online collaborative 
groups,” British Journal of Educational Technology, 2010, vol. 
41, no. 2, pp. 213-226.
[19] B. De Wever, T. Schellens, M. Valcke, and H. Van Keer, 
“Content analysis schemes to analyze transcripts of online 
asynchronous discussion groups: A review,” Computers & 
Education, 2006, vol. 46, no. 1, pp. 6-28.
[20] L. Rourke, T. Anderson, D.R. Garrison, and W. Archer, 
“Methodological issues in the content analysis of computer 
conference transcripts,” International Journal of Artificial 
Intelligence in Education (IJAIED), 2001, vol. 12, pp. 8-22.
[21] H. Cho, M. Stefanone, and G. Gay, “Social information sharing 
in a CSCL community,” In : Proceedings of the Conference 
on Computer Support for Collaborative Learning: Foundations 
for a CSCL Community. International Society of the Learning 
Sciences, 2002. pp. 43-50.
[22] M. de Laat, V. Lally, L. Lipponen, and R.J. Simons, 
“Investigating patterns of interaction in networked learning 
and computer-supported collaborative learning: A role for 
Social Network Analysis,” International Journal of Computer-
Supported Collaborative Learning, 2007, vol. 2, no. 1, pp. 87-
103.
[23] L. Garton, C. Haythornthwaite, and B. Wellman, “Studying 
online social networks”, Journal of Computer-Mediated 
Communication, 1997, vol. 3, no. 1.
[24] C. Reffay and T. Chanier, “How social network analysis can 
help to measure cohesion in collaborative distance-learning,” 
In : proceeding of Computer Supported Collaborative Learning 
conference (CSCL’2003). 2003. pp. 343-352.
[25] P. Ten Have, “Doing conversation analysis,” Sage Publications 
Limited, 2007.
[26] H. Sacks, “Lectures on conversation,”, 1995.
2 http://moodle.org (May 2013)
23
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-287-5
COLLA 2013 : The Third International Conference on Advanced Collaborative Networks, Systems and Applications

