This Is Not You!
Identity Crisis In the 21st Century
Andrea Alessandro Gasparini
Department of Informatics and
University of Oslo Library
University of Oslo
Oslo, Norway
Email: andreg@ifi.uio.no
Abstract —Identity today has become a complex issue. An
average user of the Internet has accounts for a number of
services, and several traces of use are gathered by large
companies. However, the same companies are using Artificial
Intelligence in their services. This paper presents possible
impacts the new wave of Artificial intelligence will have on
users’ understanding of their own identity if they approach
services where this technology is active. Moreover, the effects
of having an Artificial Intelligence-based service as a coach or
advisor will be highlighted. A pragmatic stand will be applied
to address the importance of the context in which the Artificial
Intelligence will be used to understand the effects it may have
on users’ identity. As a case study, the paper presents the
result of two design workshops where the goal was to prototype
possible solutions and scenarios to support university students
entering the academic life when Artificial Intelligence-based
services are used.
Keywords- Artificial intelligence; pragmatism; education;
Design Thinking; service design.
I.
INTRODUCTION
In the 21st century, the identity of humans has become an
issue. Not only is it highly contextualized when technology
is involved, but the way identity is used by technological
platforms is becoming a problem for some users.
In the first place, identity is difficult to define, as it has
many facets; it is highly sensible to many factors. For
instance, for a person, the social context is important and is
part of the task of defining their own identity [1]. Gender,
age, music preferences, or religion are some of the various
social categories persons may belong to, and are part of the
act of defining themselves. A good example of modern
social “tribe” offering an alternative identity to those
otherwise defined by social norms, are skaters [2]. Another
way for persons to define their own identity is the internal
process of self-verification [3]. The two stands (context and
internal processes) naturally
influence each other [3].
Humans do search for ways of defining their own identity in
several ways; some have a nomadic identity, and they easily
adapt to different context, others have hidden identities that
can emerge in specific contexts. Nevertheless, when a person
interacts with a context, a continuous renegotiation and
definition of the latter does occur [4]. This situated activity
“is conceived as an ongoing process of establishing,
affirming, modifying, and sometimes destroying situated
identities.” [5] One such example is the indigenous cultures
where, in many countries, their context is under constant
redefinition and their identity under pressure.
Another significant aspect of the human identity is when
technology has an active role in different contexts [4]. New
technologies, like Augmented Reality (AR) or Virtual
Reality (VR) act directly on the context, while the use of
smartphones, iPads, smart-clocks and computer discloses all
forms of activity and users’ habits on the Internet.
In the 21st century, the identity of a person is under
unprecedented scrutiny. Companies like Facebook, Google,
Amazon, and Netflix use the data that users produce by
gathering Big Data and then analyzing every aspect, so they
can use it later to come with possible future use of their
services. One can say they offer to us our own social
navigation [6]. Examples are Amazon and Netflix, as they
have recommendations for users to buy books or to see
movies based on prior use. The user’s voice in this context
has been not well accepted, and is often overwhelmed by
agreements with large companies which are very difficult to
understand in the first place. An answer to this issue is the
new European General Data Protection Regulation (GDPR)
giving the user rights to decide how their own data is used by
those companies [7]. One of the positive changes represents
a quantum change for users, since “It must be as easy to
withdraw consent as it is to give it.” [7] However, during the
last two years, an increased interest has been shown
regarding Artificial Intelligence (AI). Some of the same
companies not only are gathering Big Data on users, but they
are also at the frontline of innovation in the field of AI. The
dual role the AI can acquire is interesting as well. Firstly, it
has access to a huge amount of data about its users and
secondly, at the same time, it is able to understand the user in
a unique way. This dual role needs further analysis. This
paper presents possible effects and impacts the new wave of
AI will have on users’ understanding of their own identity
when they approach services where this technology is active.
Finally, the paper will look into how AI can abuse the
necessary trust the user gives to a service.
The paper is organized as follows: Section one is the
introduction; Section two is about the third wave in AI
research;
Section
three
presents
Identity,
Artificial
Intelligence and pragmatism. The fourth section is a case
study aiming to dismantle the interaction between AI and
users in the context of student’s academic life on campus.
13
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

The fifth section is a discussion. Finally, the sixth section
presents the conclusion, which also includes future works.
II.
THE THIRD WAVE OF ARTIFICIAL INTELLIGENCE
AI is not a new idea, as the approach used is to try to
mimic human cognition [8]. Until now, three waves have
occurred. The first during the 50s and 60s (cybernetics)
originated from the seminal paper written by Alan Turing [9]
and the famous Turing test; while the second wave can be
pointed out to be in the 80s where the main discussion was
around cyborgs, a hybrid of machine and organism, a
creature of social reality, also used in fiction [10]. The third
wave is now, as one of the elaborative advantages AI has is
the access to more or less open large quantities of user’s data
(termed Big Data). In addition, as mentioned before, during
the last few years this new wave of AI has been supported by
large companies like Google, Amazon, Tesla, and IBM,
where some of them are sharing the necessary technologies,
like the TensorFlow open-source software library [11], to be
used for programming AI. Machine learning, deep learning
and neural network, define some of the approaches used, all
aimed at knowledge architectures to perform analysis and
predict possible outcome, and tasks, allowing AI to learn and
therefore increase the possibility of a correct output. The
results so far have the capability to overcome what humans
can perform. For instance, IBM Watson [12] is able to read
millions of medical journals in oncology and give doctors
additional information about what and when to prescribe
cures
and
medicaments.
In
Norway,
companies
and
organizations are testing and implanting services offshore to
predict service maintenance on oil platforms. In Sweden, a
company has developed a small device that can monitor
small variations in domestic power supply and tell users
what is in use at home and how much energy each item uses
[13]. The car manufacturer Tesla is already selling cars with
ready-to-use self-driving hardware [14]. However, research
on the effects that this new wave of AI may have on users
when services are so clever, is still in its infancy. For
instance, issues with ethics, norms and lack of regulation
may have unpredicted effects on our society. For instance,
Google’s AI AlphaZero had to play in an aggressive way to
win
chess
games
against a common
chess computer
(Stockfish) [15]. The effects on a user when meeting an
aggressive AI-based service are still being uncovered.
Another relevant change in this new wave of AI is the
possibility to perform tests in vivo with functioning systems,
and not only theorizing about this type of interaction
between human and machine. For instance, during a series of
matches of the game GO between a variant of the AlphaZero
AI (AlphaGo) and a human [16], some strange forms of
behaviors from both sides were observable. In the award-
winning documentary about this series of matches [17] one
can get a first glimpse of this new landscape of interaction.
Among interesting observations to be made is the way
programmers defined the behavior of AlphaGo on some
occasions was “completely delusional”. It is also remarkable
how AlphaGo adapted and reacted to the way the human
opponent played, defined by the programmers as creative.
Finally, the sad reaction of the public and the press after the
first game, when the human player lost, turned out to be
surprising and unpredicted.
Therefore, several questions are timely to ask: Is it okay
for an AI based service to become angry? Which identity has
an intelligent AI? What are the factors provoking bias in an
AI? And what is the right pedagogy to teach an AI? Who is
programming the algorithm and how the system is trained
may also produce bias. For instance, if the user data gathered
is only from a specific context, the support given by the
service can be erroneous.
For the user, a new endeavor is on the horizon, as AI
based services are using all the gathered data users
produces, and by analyzing every aspect they will present,
in the near future, services tailored for them. Moreover the
effects are unclear when the context is also under the
influence of AI and therefore can be adapted accordingly.
Next, we consider how services based on AI may influence
the users. The paper will look into how pragmatism can be
used to understand how the context, identity and AI
influence one another.
III.
IDENTITY, ARTIFICIAL INTELLIGENCE AND
PRAGMATISM
The paper presents pragmatism [18] as a framework to
make sense of the context a user may find himself in when
using a service based on AI. To start with, the notion of
“inquiry” in pragmatism is a way to approach a not-defined
situation (for example when approaching an AI-based
identity) and try to change it in such a way that it is
“thinkable”.
“Inquiry
is
the
controlled
or
directed
transformation of an indeterminate situation into one that is
so determinate in its constituents distinctions and relations as
to convert the elements of the original situation into a unified
whole” [18, p. 108]. This passage is interesting, as it shows
how a user may try to “redefine” an AI-based service by own
parameters so it makes sense to him, i.e., make it thinkable.
What fuels an inquiry for a human is then the necessity to
react and perform thinking in a situation that is uncommon,
out of place or difficult to understand (in our case making
sense of the identity of an AI). However, pragmatism
emphasizes the difference between thought and thinking.
Thinking of sugar when looking at the snow falling in
Norway is creative, however only a thought. Thinking
consecutive thoughts like: snow, then snow on the road, then
problems with traveling, then coming late to work, is a series
of activity ending in an educated guess. Dewey writes about
this line of thinking since humans “consider the possibility
and nature of the connection between the object seen and the
object suggested” [18]. A side effect of those subsequent
thoughts is a learning effect, grounded in a reflective act.
This learning activity is also relevant when making sense of
a situation a person is involved in, for instance, in our case,
when interacting with a brand new AI-based service. As
pointed by [19], one’s way of understanding a situation is
based on prior experiences. However, since there are very
few real situations where this can be tested, one can deduce a
difficulty for users to acquire experience of interaction with
an AI-based service, who may therefore be unprepared to
14
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

tackle issues emerging from the interaction. A consequence
for the user of this insecurity is an emerging relevance of the
context where the activity is performed. In pragmatism the
“situatedness” is a way to explain that persons, objects and
phenomena are very contextually bounded, as they can only
exist in a given situation. An effect of this is a quid pro quo
between the context and its inhabitants: the situation cannot
exist without the others, and vice versa.
Dewey presents an indeterminate situation as one not so
stable and difficult to understand, in which the subjects, and
the surroundings do not play together [18]. They are not
aligned properly. An indeterminate situation, as described
above, fits well to explain a possible situation a user could
experience when approaching an AI-based service. This
indeterminate situation is also under the effects of the
continuous renegotiation and definition of the context done
by the user [4]. Simultaneously this activity has an impact on
the situated identity of the user. This process can support,
modify or even destroy an identity [5], since context and
internal processes of self-verification naturally influence
each other [3].
A possible scenario could describe a user encountering
an AI-based service so well informed about the user’s needs
and habits, able to exploit the user’s weakness so the user
cannot resist being pleased by the offer from the AI-
supported service.
Pragmatism helps understand the construction of this
specific context and why a person’s identity is under
pressure when approaching an AI-based service. The paper
will now present the results of two workshops where the goal
was to dismantle, using design methods, the interaction
between an AI-based service and the users, in the context of
students’ academic life on campus.
IV.
THE CASE
A. A design process informed by Design Thinking and
Service Design
The University of Oslo Library received a grant from the
Norwegian National Library early in 2017, to find out
possible effects the use of Artificial Intelligence could have
on services the library provided and how the user will accept
using and interacting with this new type of services. Analysis
has found out that AI-based technology will be relevant in
academia and academic libraries over four to five years from
now [20].
Opting for using an academic library constrained the type
of users (e.g. students and researchers), and controlled the
context. One of the goals of the project was to inform the
process of developing and understanding AI-based services
using a user-centered perspective and not the technology
alone.
The theoretical foundation of the project stands on
Design Thinking [21]. The goal of this approach is to support
innovation
where
the
output
has
the
connotation
of
desirability, viability, feasibility. Each of these takes care of
the user perspective, technical and business possibility. As
design method for the two workshops presented in this
paper, we opted for the use of Service Design [22], where the
goal is to map out the whole journey of the user from the
very start of using an AI-based service to the end and beyond
(aftereffects). Each time a user is in contact with a service
provider, it is possible to design, re-design or remove the
contact points (touch-points). This design approach fits well
with AI-based services, giving the opportunity to look into
each touch-point.
The goal of the two workshops was to map out a user
journey for a university student when approaching on
campus an AI-based service for the first time. In the context
of a university library, possible services to be worked with in
the workshops could include, among others, help to find a
spot to read peacefully, get help to find relevant literature or
library courses, or to find out about other possibilities and
services the university library could give the student.
The set-up of the workshop was one previously used by
the author on several occasions [23]. The participants of the
two workshops had different backgrounds, like researcher,
IT-staff, directors of the library, and librarians, however all
were from academia.
Figure 1. The photo shows the user journey for an AI-based service
developed during the workshop. On top the actual user journey is mapped
out. The second row describes the competence needed in the organization to
complete each touch-points. The last row shows the activity needed to
achieve the goal of the touch-point.
The first workshop, was a daylong activity, and used a
design approach to sort out all aspects of AI in the context of
a student’s academic life on campus. Using Giga-mapping
[24], as many perspectives as possible were addressed. The
second phase of the workshop was rapid prototyping, where
the outcome was several ideas of future services using AI.
As mentioned, during this first workshop we used Service
Design to describe how a journey for a student could be, and
several of the ideas from the rapid prototyping act were used.
The second workshop, a half day long, was used to enrich
even more the user journey developed in the first workshop.
The participants added new perspectives and issues, allowing
for a redefinition of some of the touchpoints. For both
workshops, the design act provoked several unexpected
issues.
Particularly
interesting
was
the
problem:
the
participants had to envision a future use of an AI-based
15
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

service. Additionally, the lack of arenas where it could be
possible to test and achieve more competence reinforced the
effect. The final result of the two workshops was a user
journey representing how a student approaching the service
for the first time, acted. Each touch point (see Fig. 1 and
redesigned excerpt Fig. 2) represented an interaction between
the user and the AI-based service. The user journey
highlights the need of in-depth analysis of each interaction.
For instance, already at the very start of the journey,
finalizing an agreement of data exchange is an obstacle for
both. From one side, the service provider needs to gather
relevant data, on the other side the user needs to decide to
which degree it is necessary to accommodate the request to
ensure the coaching is relevant. In the next phase, the AI-
based service will ask for some type of identification, like
ID-cards, or if allowed, to scan the face to recognize the
identity of the person. The user journey (see Fig. 1 and
redesigned excerpt Fig. 2) showed the possibility and
necessity which the AI-based service has to gather as much
as possible information about the context and the user, to be
able to deliver the service. The context gives information
about the place on campus, and possible services the user
could get access to. In addition, there is a need to update the
gathered data the AI-based services has, in case there are
recent changes.
Figure 2. Redesigned excerpt of the user journey where the goal is to use an
AI-based service. Privacy and stigmatization are critical points.
For instance, in the library it could be new books or, on
campus, relevant information about upcoming presentations
or seminars.
After
all, the
main
goal
should
be to
communicate information as correctly as possible. However,
to really help the users, the AI-service needs to gather
information
about
them.
Information
about
university
courses the user is taking, and the curriculum needed, are all
valuable information. In addition, information of possible
disabilities, like dyslexia, is needed to avoid stigmatization,
and to reconfigure the service to match the user’s needs.
Nevertheless, to really tune in the right type of help,
additional user data should be monitored and saved for future
use during the interaction. Examples of the latter are for
instance, type of questions put and answers given, recording
of interaction and video of activity performed in the physical
space. Finally, the AI-based service should gather a lot of
information online to construct a profile, so the service is
tailored as well as possible.
The
outcome
of
the
workshops
was
a
better
understanding of the implications of the invasiveness that the
user will be subject to, and the resulting effects. The user
journey pointed out the exchange of data and communication
as a Critical Point (see the touch point identification in
Figure 2) since it is necessary for the service provider to
have routines reflecting the local legislation (Privacy) and
ensuring how the data will be used (for instance to avoid
stigmatization). This information needs to be part of the
agreement made at the beginning of the interaction. In
conclusion, after the workshops it was possible to observe
that the majority of the problems happened at the very start
of the constructed user journey. Prevalent was the need to
have empathy for user needs, tacit and otherwise, to avoid
giving the user less priority.
B. Issues with business-driven developing processes for
Artifical Intelligence-based services
The approach used in the presented case was a direct
reaction
from
the
overwhelming
activity
in
business
companies in Norway [25] aimed at reducing costs and
increasing earnings using Artificial Intelligence, while the
user perspectives in many cases seem to be absent. The
author has participated in several conferences and workshops
regarding the use of AI, and during a presentation in a major
consultant company in Norway the user perspective was
completely omitted from the development process. Using the
Waterfall method to develop a service, they presented the
following chain of activities:
Project plan for an AI-based service:

Understand the business problem area

Analytical approach to the problem area

Gather large silo of curated data

Use algorithms and modelling

Evaluation of the algorithm

Evaluation

Real use

Feedback
The user perspectives and his possibilities to inform the
process are clearly very few.
V.
DISCUSSION
A. Identity and Artificial Intelligence
The identity of the user is under even greater pressure
when approaching and using AI-based services. The results
of the two presented workshops, and the observations from
the documentary, support this view and raise questions as
how users may react to this new type of technology. A
method to discuss the necessary reflectivity a human needs
to perform, named reflective thought, as a means to help
define his identity, is pragmatism. As mentioned, one of the
effects of the reflective act is learning. The problem is, as
mentioned, what happens when the self-learning mechanism
in the AI technology make its own predictions, supported by
accessing
Big
Data,
contextualized
information,
and
simultaneously acts as a coach, in this case, a helping hand
for students in an academic setting during studies?
16
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

This advantage may give unpredicted outcomes. What
happens when the user starts learning from an AI-based
service made to mimic humans? What if it is difficult to see
the difference between a real interaction and one with an AI-
based service? It may sound simplistic; however, one should
remember special moments or occasions occurring during
school. Some special events had a huge impact on how we
perceive the context (school) and the willingness to learn
later on. Therefore, when an AI-based service fits so
perfectly with the user, when it is so well informed of the
user’s needs and habits and at the same time is able to exploit
the user’s weakness in a way the user cannot resist, the
question to ask is: what kind of human identity will be the
outcome of an interaction over a long period of time. The
two workshops showed that the AI can perform this activity
and the information required is not so difficult to gather,
sometimes the users even give away that type of information
regardless of privacy issues. The user’s identity, especially in
the context of education, needs to be protected when
Artificial Intelligence is the driving force behind support
systems. Young students, in the beginning of their academic
life are eager for knowledge, and the faculty and other
university staff need to advise prudence.
As earlier described, AI-based services can be aggressive
in the way they try to solve problems [15], therefore
unforeseen issues may arise when they can be critical and
develop an opinion on their own. As the workshop showed,
there is a potential to help students with their academic life
by supporting research and study. AI-based services will
probably be a game changer as new forms of interaction will
develop new types of “hybrid selves” based on different
aspects the persons interacting with the service have.
B. Context and Artifical Intellingence
With fresh and unexpected insights, an AI-based service
may tune its identity and gain acceptance and legitimacy to
interact with users. However, the context has also a role in
defining the identity of the user. Section III explains how
pragmatism helps understand the construction of a context
since the “situatedness” explains why all the users, AI, and
the context are contextually bounded, as they can only exist
in a given situation. In addition, the “situatedness” is not
stable and requires a continuous renegotiation by the user,
which also affects his identity. In the documentary AlphaGo,
this was present as both the player and the public were
clearly sad about losing the game when the opponent was a
non-human, and therefore required a redefinition of their
own identity.
As pointed out by Dourish [4], so far there is some
difficulty in designing well-functioning systems that take the
context
into
account.
Contextualized
information,
as
mentioned, gives opportunities to gain an advantage. Context
is also easy for an AI-based service to exploit, since users
leave many traces when they are using search engines, email,
and so on. For instance, the GPS, 4G and the Wi-Fi of the
mobile phone monitors all the user’s movement when
moving from place to place, with added time stamps.
One of the results of the workshop has pointed out
several touch-points relevant for the AI-based services to
gather and adapt to the context, and in doing so support the
user. For instance, to help users with disabilities, one needs
to take into account physical issues when moving inside the
library, and at the same time try to avoid any forms of
stigmatization.
C. This is not you!
Finally the title, “This is not you!” has its own anecdotal
story and deserves to be mentioned in this paper. As the
author of this paper was in a University meeting in Spain, the
story to be told unfolds at the airport while heading back to
Norway. Unfortunately, the author had grown a large
mustache and had gained some weight. Therefore, during
check-in at the airport the author was denied a boarding card.
The lady from the flight company at the counter desk,
definitely did not believe the person in front of her was the
right owner of the passport; “This is not you!” The reaction
of the author was foremost surprise, since his identity is
available everywhere, from the biometrics information in the
passport, all the different physical cards, to all the accounts
he has online in so many platforms and services. How could
it be possible that his identity is so entangled?—Be so
present and invisible at the same time? Showing other
identity cards to the airline company did not help. After
several checks by supervisors from the flight company and
discussions, the author was finally allowed to travel. Being
the first person of the entourage from the University
participating at the meeting in Spain, it was a quite seldom
experience, one difficult to forget. The critical point in this
story was how the author experienced being mistaken for
another person, and
in
addition one not desiderated.
Considering this experience with an AI service the, outcome
could be worse. If the system does not show judicial
assessment, the only possibility the author had to react, was
to reshape and redefine the identity.
VI.
CONCLUSION
The paper presents indications about how to proceed
when Artificial Intelligence, in the near future, will become
a standard supporting system. The user’s identity has
shown, in the context of academic life, a need to be cared
for when AI is the driving forces behind support systems.
Young students, in the beginning of their academic life are
eager for knowledge, and the faculty and other university
staff need to advise wisely. The design process aiming to
prepare users when encountering AI-based services may
result in a tension about the embodiment of knowledge as it
is able to gain opinions on its own using the user’s data The
offering of coaching and support will have an impact on the
user’s identity.
Unfortunately, several signs in the market show that new
services are developed by ignoring the user’s perspective, as
the main goal is to maximize company profit. The paper has
presented how difficult it is to be reflective and think in a
“correct” way when approaching Artificial Intelligence-
based systems and services. There are many companies
outside academia who are interested in or are developing
this type of platform, however, there is a lack of arena
17
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

where this type of interaction and the effects can be
monitored over a longer period of time. The paper supports
an emerging necessity to make new legislations and new
regulations to defend the users, while the creativity and the
innovation emerging when using this new technology
should not be constrained.
ACKNOWLEDGMENT
The author is indebted to all workshop’s participants, and
the University of Oslo Library for initiating the project. The
National Library of Norway, in part, financed the project.
REFERENCES
[1]
B. E. Ashforth and F. Mael, “Social identity theory and the
organization,” Acad. Manage. Rev., vol. 14, no. 1, pp. 20–39,
1989.
[2]
A. Gasparini, “Young and creative - A designerly approach to
enhance interventions in the public space,” presented at the
ACHI
2016,
The
Ninth
International
Conference
on
Advances in Computer-Human Interactions, Venice, Italy,
2016, pp. 44–49.
[3]
S. Stryker and P. J. Burke, “The past, present, and future of
an identity theory,” Soc. Psychol. Q., vol. 63, no. 4, pp. 284–
297, 2000.
[4]
P. Dourish, “What we talk about when we talk about
context,” Pers. Ubiquitous Comput, vol. 8, no. 1, pp. 19–30,
Feb. 2004.
[5]
N. Alexander and M. G. Wiley, “Situated activity and identity
formation,” in Social Psychology: Sociological Perspectives,
M. Rosenberg and R. T. Turner., Eds. New York: Basic
Books.
[6]
A. Dieberger, P. Dourish, K. Höök, P. Resnick, and A.
Wexelblat, “Social navigation: Techniques for building more
usable systems,” Interactions, vol. 7, no. 6, pp. 36–45, Nov.
2000.
[7]
EU GDPR, “EU GDPR,” EU GDPR Portal. [Online].
Available: http://eugdpr.org/eugdpr.org.html. [Accessed: 03-
Dec-2017].
[8]
M. A. Shahin, “State-of-the-art review of some artificial
intelligence applications in pile foundations,” Geosci. Front.,
vol. 7, no. 1, pp. 33–44, Jan. 2016.
[9]
A. Turing, “Computing machinery and intelligence,” Mind,
vol. 59, no. 236, pp. 433–460, 1950.
[10] D. Haraway, “A manifesto for cyborgs: Science, technology
and socialist feminism in the 1980s,” Social. Rev., vol. 80, p.
29, 1985.
[11] TensorFlow,
“TensorFlow.”
[Online].
Available:
https://www.tensorflow.org/. [Accessed: 18-Jan-2018].
[12] IBM Watson, “IBM Watson,” IBM Watson, 2018. [Online].
Available: https://www.ibm.com/watson/. [Accessed: 15-Jan-
2018].
[13] Watty, “Watty | A simple way to keep track of what goes on
at home,” Watty, 2018. [Online]. Available: https://watty.io/.
[Accessed: 15-Jan-2018].
[14] Tesla,
“Autopilot,”
2018.
[Online].
Available:
https://www.tesla.com/autopilot. [Accessed: 16-Jan-2018].
[15] M.
Klein
(MikeKlein),
“Google’s
AlphaZero
destroys
Stockfish
in
100-game
match,”
Chess.com.
[Online].
Available:
https://www.chess.com/news/view/google-s-
alphazero-destroys-stockfish-in-100-game-match. [Accessed:
10-Dec-2017].
[16] D. Silver et al., “Mastering the game of Go without human
knowledge,” Nature, vol. 550, no. 7676, p. 354, Oct. 2017.
[17] G. Kohs, “AlphaGo Movie,” AlphaGo Movie, 2017. [Online].
Available: https://www.alphagomovie.com/. [Accessed: 18-
Jan-2018].
[18] J. Dewey, How We Think. Mineola, N.Y: Dover Publ, 1997.
[19] P. Dalsgaard, “Pragmatism and design thinking,” Int. J. Des.,
vol. 8, no. 1, pp. 143–155, 2014.
[20] NMC, “NMC horizon report library edition,” 2017.
[21] T. Brown, “Design Thinking,” Harward Bus. Rev., vol. 86,
no. 6, pp. 84–92, 2008.
[22] A. Polaine, L. Løvlie, and B. Reason, Service Design: From
Insight to Implementation. Brooklyn, N.Y.: Rosenfeld Media,
2013.
[23] A. Culén and A. Gasparini, “Find a book! Unpacking
customer journeys at an academic library,” in ACHI 2014,
The Seventh
International Conference on Advances in
Computer-Human Interactions, 2014, pp. 89–95.
[24] B. Sevaldson, “GIGA-mapping: Visualisation for complexity
and systems thinking in design,” Nordes, vol. 0, no. 4, Mar.
2011.
[25] Nordic – AI, “Nordic AI Summit Norway - Oslo Innovation
Week
2018.”
[Online].
Available:
http://oiw.no/program/nordic-ai-summit-norway.
[Accessed:
14-Dec-2017].
18
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

