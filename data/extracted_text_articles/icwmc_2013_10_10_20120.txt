An Application of Second-Order Reed-Muller Codes
for Multiple Target Localization
in Wireless Sensor Networks
Thu Lam Ngoc Nguyen‚àó, Jaejin Lee‚àó, and Yoan Shin‚àó
‚àóSchool of Electronic Engineering, Soongsil University, Seoul, Korea
Email: {ngocthu, zlee, yashin}@ssu.ac.kr
Abstract‚ÄîCompressive sensing is a new signal processing
technique for efÔ¨Åcient reconstruction of an n-dimensional signal
from m (m ‚â™ n) measurements. Most of compressive sensing
researches are based on randomization, while research on de-
terministic sampling is essential for practical implementation.
In this paper, we study m √ó n deterministic binary sensing
matrices using second-order Reed-Muller codes, which satisfy a
statistically restricted isometry property with reduced complexity
for an application of multiple target localization in wireless
sensor networks. We formulate multiple target locations as a
sparse matrix, then exploit received signal strength information to
recover noisy information using the deterministic sensing matrices
and greedy algorithms to locate each target. The simulation
results show that our scheme also achieves high accuracy in terms
of localization errors when compared to traditional approaches
with the random sensing matrices.
Keywords‚Äîwireless sensor network; multiple target localization;
compressive sensing; deterministic sensing matrix; Reed-Muller
codes.
I.
INTRODUCTION
Wireless sensor networks can play a key role in target
tracking, monitoring, environmental sensing and some other
applications. Many approaches for network localization based
on local sensor information have been developed with low-
cost, low-power and small size constraints [1]‚Äì[8]. In this
paper, we consider a scenario that the nodes are randomly
deployed in a large area, and we determine multiple target
locations based on the Received Signal Strength (RSS) in-
formation from their neighbors. Some of existing localization
algorithms for this scenario are inefÔ¨Åcient, since they require
a large number of data between transmitter and receiver [9]‚Äì
[14], [18]. Fortunately, the compressive sensing can help us
to overcome these problems. The goal of compressive sensing
is to recover an unknown signal vector x ‚àà Rn from linear
measurement y obtained by
y = Œ¶x,
(1)
where Œ¶ = {Œ¶i}m
i=1 ‚àà Rm√ón is the sensing matrix. The
most concern is when the number of measurement m is much
smaller than n, i.e., m ‚â™ n. In this case, Ô¨Ånding an exact
solution x based on the measurement y is an ill-posed problem
since the system of equations is under-determined. However,
we can deal with it by Ô¨Ånding an approximation of x by
solving this problem as
min
x ||x||0
subject to
Œ¶x = y,
(2)
where ||x||0 = |supp(x)|, and a vector is called k-sparse if it
has at most k nonzeros elements. The compressive sensing
technique guarantees exact recovery of the original signal
x with high probability if the sensing matrices satisfy the
Restricted Isometry Property (RIP). That is, for a Ô¨Åxed k, there
exists a small number Œ¥k ‚àà (0, 1) such that
(1 ‚àí Œ¥k)||xk||2
2 ‚â§ ||Œ¶xk||2
2 ‚â§ (1 + Œ¥k)||xk||2
2
(3)
for any k-sparse xk. Hence, the problem (2) can be solved
either by using greedy algorithms such as Basis Pursuit (BP)
[15], Orthogonal Matching Pursuit (OMP) [16], [17], or re-
placed by solving for sparse signal via l1 minimization as
min
x ||x||1
subject to
Œ¶x = y.
(4)
In traditional compressive sensing approach, researchers
have used random projection for the sensing matrices Œ¶ to
obtain the measurement y, since the RIP can be satisÔ¨Åed with
some random matrices with their entries following Gaussian
process, Bernoulli process, etc. [19], [20]. Thus, a k-sparse
signal x ‚àà Rn can be exactly reconstructed from m mea-
surements. However, random matrices have many drawbacks:
signiÔ¨Åcant space requirement for storage, no efÔ¨Åcient algorithm
to verify the RIP, hard to deployment in many applications,
to name a few. To this end, designing deterministic sensing
matrices is essential for practical implementation. Recently,
many advantages of deterministic sensing matrices have been
shown. The most of these advantages is their fast and efÔ¨Åcient
reconstruction nature. In [21], Calderbank constructed some
statistical RIP conditions such as Statistical Restricted Isom-
etry Property (StRIP) and Uniqueness-guaranteed Statistical
Restricted Isometry Property (UStRIP). These are weaker
versions of the RIP that allow to construct deterministic
sensing matrices. In [22], DeVore gave a generalization of
construction via algebraic curves over Ô¨Ånite Ô¨Åelds. The author
constructed binary sensing matrices of size p2 √ó2p+1 by using
polynomials over Ô¨Ånite Ô¨Åeld Fp. This idea has been developed
in many researches [23]. By choosing appropriate algebraic
curves, these deterministic sensing matrices were better than
DeVore‚Äôs one. In [24], an application of coding theory in
compressive sensing was presented, where a fast reconstruction
algorithm for deterministic compressive sensing using second-
order Reed-Muller codes was proposed. The matrix Œ¶ is said
to satisfy the StRIP (k, Œ¥) if
Pr
||Œ¶x||2 ‚àí ||x||2 ‚â§ Œ¥||x||2

‚â• 1 ‚àí œµ,
(5)
185
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

holds with probability exceeding 1 ‚àí Œ¥, and we assume that x
distributes uniformly among k-sparse vectors. They showed
that if Œ¶ satisÔ¨Åes the StRIP respect to the parameters œµ
and Œ¥, high probability reconstruction is also guaranteed. The
deterministic sensing matrices formed by Reed-Muller codes,
Bose-Chaudhuri-Hocquenghem (BCH) codes and some others
can achieve this StRIP condition.
In this paper, we study the construction of deterministic
sensing matrices formed by second-order Reed-Muller codes
and how to apply this theory to multiple target localization in
wireless sensor networks. We formulate each target location
as a sparse vector in the discrete spatial domain. Then, we
measure the RSS information from the targets and apply the
construction of deterministic sensing matrix formed by second-
order Reed-Muller codes as the measurement matrix. These
matrices satisfy the StRIP, so that the approximated solution
of (2) can be obtained by using a recovery algorithm in the
last step.
The organization of the paper is as follows. In Section
II, we explain a motivation of developing real-valued second-
order Reed-Muller codes for deterministic sensing matrices in
compressive sensing. In Section III, we formulate the multiple
target localization problem as an application of compressive
sensing by using the sensing matrices dealt in Section II.
Numerical results are considered in Section IV, followed by
concluding remarks in Section V.
II.
REAL-VALUED SECOND-ORDER REED-MULLER CODES
IN DETERMINISTIC SENSING MATRIX CONSTRUCTION
A. Main construction
Recall that for any two binary vector a = (a0, ¬∑ ¬∑ ¬∑ , ap‚àí1)
and b = (b0, ¬∑ ¬∑ ¬∑ , bp‚àí1) in Zp
2, the inner product is deÔ¨Åned as
a ¬∑ b = aT b =
p‚àí1
X
i=1
aibi
mod 2,
(6)
where (¬∑)T denote the transpose operation. The second-order
Reed-Muller code is given as follows.
œÜP,b(a) = (‚àí1)w(b)
‚àö
2p
i(2b+Pa)T a
(7)
where P is a p √ó p binary symmetric matrix, b is a p √ó 1
binary vector in Z2
p and w(b) is the weight of b, i.e.,
number of bit-1 entries. For given matrix P and vector b,
the second-order Reed-Muller code is a 2p √ó 1 vector. For
implementation purposes, the matrices P are set as all-zero
matrices or the matrices with zero-diagonals. Thus, there is
only 2p(p‚àí1)/2 matrices P satisfying this condition, which are
{P1, ¬∑ ¬∑ ¬∑ , P2p(p‚àí1)/2} and the functions {œÜP,b(a)} are real-
valued. The set
FP = {œÜP,b|b ‚àà Zp
2}
(8)
forms a basis of Zp
2. The inner product on FP is deÔ¨Åned as
follows. For any two vectors œÜP,b and œÜP‚Ä≤,b‚Ä≤ in FP
‚ü®œÜP,b, œÜP‚Ä≤,b‚Ä≤‚ü© =
(
1
‚àö
2q
2q
times,
0
2p ‚àí 2q
times,
(9)
where q = rank(P ‚àí P‚Ä≤). The deterministic sensing matrix in
[25] has the form
Œ¶RM =

UP1
UP2
¬∑ ¬∑ ¬∑
UP2p(p‚àí1)/2

2p√ó2p(p+1)/2
(10)
where UPi is unitary matrix correspoding to FPi, i
=
1, ¬∑ ¬∑ ¬∑ , 2p(p‚àí1)/2. Note that if we set m = 2p and n =
2p(p+1)/2, we get an m √ó n sensing matrix Œ¶RM. The
reconstruction problem using this matrix is to reconstruct the
k-sparse vector x from the data y given by
y = Œ¶RMx.
(11)
In [26], the Delsarte-Goethals sets DG(p, r) provide some
restricted conditions for set of matrices P. The set DG(p, r) is
a collection of p √ó p binary symmetric matrices with property
that for any distinct matrices P, Q ‚àà DG(p, r), the rank of
P + Q is greater or equal to p ‚àí 2r. This implies that these
sets are nested
DG(p, 0) ‚äÇ DG(p, 1) ‚äÇ ¬∑ ¬∑ ¬∑ ‚äÇ DG

p, p ‚àí 1
2

.
(12)
The set DG(p, 0) is called Kerdock set [27]. Setting P to range
over DG(p, (p ‚àí 1)/2), the sensing matrices made from the
matrices P are the matrices of size 2p √ó 2p(r+2).
B. Matrices with construction guarantee
Since the deterministic designs are based on the imple-
mented and practical aspects, we focus on the sensing matrices
whose entries are ¬±1 by removing the normalization factor of
1/
‚àö
2p in Œ¶RM
ÀÜŒ¶ = ‚àömŒ¶RM.
(13)
Let us denote ¬µ(A) as the largest magnitude of entries A.
¬µ(A) = max
k,j |Ak,j|.
(14)
Thus ¬µ(ÀÜŒ¶) = 1. For a Ô¨Åxed signal x ‚àà Rn where ||x||0 =
k the recovery in (2) is exact with high probability for the
number of observations m ‚â• C ¬∑ k ¬∑ log n where C is a known
small constant. We have
ÀÜŒ¶‚àó ÀÜŒ¶ = 2p(p+1)/2I = nI,
where (¬∑)‚àó denotes conjugate operation. For a small value of
Œ¥ ‚àà (0, 1), the eigeinvalues of ÀÜŒ¶‚àó ÀÜŒ¶ are close to n with high
probability. Thus, || 1
n ÀÜŒ¶‚àó ÀÜŒ¶ ‚àí I||2 ‚â§ 1/n, and we have
Pr
||ÀÜŒ¶x||2 ‚àí ||x||2 ‚â§ Œ¥||x||2

‚â• 1 ‚àí 1
n,
(15)
Hence, the matrix ÀÜŒ¶ satisÔ¨Åes the StRIP with sparsity k and œµ =
1
n. We can Ô¨Ånd some further information on binary symmetric
matrices formed by second-order Reed-Muller codes in [25],
[28], [29].
186
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

C. Examples
Let p = 2, then Z2
2 =

0
0

,

0
1

,

1
0

,

1
1

. There is
only 22(2‚àí1)/2 = 2 binary symmetric matrices P of size 2√ó2
satisfying the condition. These are
P1 =

0
0
0
0

, P2 =

0
1
1
0

(16)
Thus, the corresponding unitary matrices UP1 and UP2 are
UP1 = 1
2
Ô£Æ
Ô£ØÔ£∞
1
‚àí1
‚àí1
1
1
1
‚àí1
‚àí1
1
‚àí1
1
‚àí1
1
1
1
1
Ô£π
Ô£∫Ô£ª , UP2 = 1
2
Ô£Æ
Ô£ØÔ£∞
1
‚àí1
‚àí1
1
1
1
‚àí1
‚àí1
1
‚àí1
1
‚àí1
‚àí1
‚àí1
‚àí1
‚àí1
Ô£π
Ô£∫Ô£ª
Hence, we get the deterministic sensing matrix ÀÜŒ¶ as
ÀÜŒ¶ =
Ô£Æ
Ô£ØÔ£∞
1
‚àí1
‚àí1
1
1
‚àí1
‚àí1
1
1
1
‚àí1
‚àí1
1
1
‚àí1
‚àí1
1
‚àí1
1
‚àí1
1
‚àí1
1
‚àí1
1
1
1
1
‚àí1
‚àí1
‚àí1
‚àí1
Ô£π
Ô£∫Ô£ª
22√ó23
.
III.
AN APPLICATION ON MULTIPLE TARGET
LOCALIZATION IN WIRELESS SENSOR NETWORKS
A. Problem formulation
Consider an area which is divided into a discrete grid with
n points. Denote k as the number of targets which are located
in this area. Each target is n √ó 1 vector whose elements are
zeros, except 1 at the index of grid point where target is
located. With k targets, we get a matrix of target locations
over the grid as
Œ∏ = [Œ∏1
Œ∏2
¬∑ ¬∑ ¬∑
Œ∏k]n√ók .
(17)
We take m measurements respect to each target under matrix
Œ®, which will be explained in the next subsection. Then the
RSS signals are given by
Ô£Æ
Ô£ØÔ£ØÔ£∞
x1
x2
...
xk
Ô£π
Ô£∫Ô£∫Ô£ª
| {z }
x
=
Ô£Æ
Ô£ØÔ£ØÔ£∞
Œ®1
0
¬∑ ¬∑ ¬∑
0
0
Œ®2
¬∑ ¬∑ ¬∑
0
...
...
...
0
0
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
Œ®k
Ô£π
Ô£∫Ô£∫Ô£ª
|
{z
}
Œ®
Ô£Æ
Ô£ØÔ£ØÔ£∞
Œ∏1
Œ∏2
...
Œ∏k
Ô£π
Ô£∫Ô£∫Ô£ª
| {z }
Œ∏
(18)
We can describe the compression procedure as follows.
Ô£Æ
Ô£ØÔ£ØÔ£∞
y1
y2
...
yk
Ô£π
Ô£∫Ô£∫Ô£ª
| {z }
y
=
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£∞
ÀÜŒ¶1
0
¬∑ ¬∑ ¬∑
0
0
ÀÜŒ¶2
¬∑ ¬∑ ¬∑
0
...
...
...
0
0
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
ÀÜŒ¶k
Ô£π
Ô£∫Ô£∫Ô£∫Ô£ª
|
{z
}
ÀÜŒ¶
Ô£Æ
Ô£ØÔ£ØÔ£∞
x1
x2
...
xk
Ô£π
Ô£∫Ô£∫Ô£ª
| {z }
x
+
Ô£Æ
Ô£ØÔ£ØÔ£∞
n1
n2
...
nk
Ô£π
Ô£∫Ô£∫Ô£ª
| {z }
n
.
(19)
Our goal is to Ô¨Ånd all the locations of these targets with an
accurate, fast and efÔ¨Åcient algorithm with a small value of m.
B. Localization process
The matrix form of (19) is
y = ÀÜŒ¶Œ®Œ∏ + n.
(20)
These matrices Œ®, ÀÜŒ¶ are generated as follows.
‚Ä¢
RSS matrix Œ® = diag{Œ®1, ¬∑ ¬∑ ¬∑ , Œ®k} is made from
using the radio propagation channel model
{Œ®i}uv = PL(duv)
= PL(d0) ‚àí 10np log10
duv
d0

, u, v = 1, ¬∑ ¬∑ ¬∑ , n,
(21)
where d0 = 1m is the reference distance, duv is
the real distance between transmitter and receiver in
meters, PL(d0) is computed using the free space path
loss equation, and np is the path loss component.
‚Ä¢
In the sensing matrix ÀÜŒ¶ = diag{Œ¶1, ¬∑ ¬∑ ¬∑ , Œ¶k}, each
Œ¶i(i = 1, ¬∑ ¬∑ ¬∑ , k) is generated by the matrices satis-
fying the StRIP, as we have discussed in the previous
section.
According to the compressive sensing theory, the localization
problem is stated as the recovery of a sparse signal xi
(i =
1, ¬∑ ¬∑ ¬∑ , k) from measurement yi, which is equivalent to re-
construct target location Œ∏i from yi. Assume that ||n||2 ‚â§ œµ
where œµ is a small positive constant. Since each signal xi is
represented by a sparsity basis, each sparse vector Œ∏i can be
found either by solving the following l1-minimization problem
ÀÜŒ∏ = arg min ||Œ∏||1
subject to
y = ŒòŒ∏,
(22)
where Œò =
ÀÜŒ¶Œ®, or by solving the convex optimization
program by calling the OMP algorithm as
ÀÜŒ∏ = OMP(y, Œò, œµ).
(23)
The main idea of the OMP algorithm is to Ô¨Ånd the columns
of the matrix Œò whose linear combination is close to y. The
OMP is more simpler and faster than other alternatives. In
this paper, we have applied this algorithm to simulate and to
generate sensing matrices ÀÜŒ¶. To improve the performance and
to Ô¨Ånd the exact target locations in the grid points, a threshold
has been deÔ¨Åned to select the largest component in the location
vector of n components with minimum overal distance error.
IV.
NUMERICAL RESULTS
In this section, we examine the performance of multiple
target localization using compressive sensing under random
matrices and deterministic matrices formed by second-order
Reed-Muller codes in an indoors environment. We randomly
deployed M sensors in an area with the size of 10m√ó10m
with N grid points, and placed the targets by randomly
selecting k grid points in uniform manners. We added Gaussian
noises with zero mean and standard deviation of 0.05 to the
observation y. We used the Average Localization Error (ALE)
to quantify the localization accuracy, which is deÔ¨Åned as
ALE(p) = 1
k
q
||p ‚àí p‚àó||2
2,
(24)
187
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

0
2
4
6
8
10
0
1
2
3
4
5
6
7
8
9
10
11
x [meters]
y [meters]
 
 
Actual postion
Gaussian matrix
Deterministic matrix
(a) Position recovery performance with M = 8.
5
6
7
8
9
10
11
12
1.4
1.6
1.8
2
2.2
2.4
2.6
2.8
3
3.2
3.4
Number of measurements
Localization Error (m)
 
 
Random matrix
Deterministic matrix
(b) Average localization error respect to 5 targets.
Fig. 1.
Localization of 5 targets under random sensing matrix and determin-
istic sensing matrix.
where p is the actual point and p‚àó is the estimated point.
Each run is collected 100 times. In the simulations, each RSS
information Œ®i(i = 1, ¬∑ ¬∑ ¬∑ , k) was obtained by
{Œ®i}uv(d) = ‚àí46.2 ‚àí 10np log10(d), u, v = 1, ¬∑ ¬∑ ¬∑ , n, (25)
Each location was observed over 100 simulations.
Figure 1 shows the position recovery performance. The
area is divided by 64 √ó 64 grid points. According to the
compressive sensing approach, with 5 targets, the number of
RSS measurements required was at least M > 2k = 10 in
the random i.i.d. Gaussian matrix case and 8 in the proposed
deterministic matrix for exact solution recovery. Figure 1(a)
shows the position recovery for 5 targets with M = 8. It
shows that the proposed scheme achieves good performance
as the traditional scheme does. Note that only deterministic
sensing matrices are practically feasible when considering
actual implementation. Figure 1(b) shows the ALE versus the
number of measurements. The ALE of the traditional random
approach was more dramatically decreased than the proposed
one when the number of measurement increased.
Figure 2 shows the ALE with M randomly selected mea-
surements in a given set of sensors. M was to set at 8 and
32 in this simulation. In the case of M = 8, the ALE of
the proposed scheme is smaller than the traditional case as
0
10
20
30
40
50
60
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Number of sensors
Average Localization Error (m)
 
 
Random
Deterministic
(a) 8 √ó 64 sensing matrix.
0
10
20
30
40
50
60
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Number of sensors
Average Localization Error (m)
 
 
Random
Deterministic
(b) 32 √ó 64 sensing matrix.
Fig. 2.
Average localization error.
seen in Figure 2(a). However, when M = 32 we observe
the opposite results as in Figure 2(b). Since M is large,
the independence among columns of the deterministic sensing
matrices is not guaranteed, while the RIP holds with random
matrices in this case. Thus, the perfect reconstruction by the
proposed method may be not guaranteed, and performance by
the random matrices is better than the proposed one when the
number of measurements becomes large.
For classical approach, each sensor must be recorded n
measurements, which brings large communication cost, espe-
cially in large-scale networks. Based on the idea of reducing
cost in compressive sensing theory and the advantages of
deterministic sensing matrices formed by the second-order
Reed-Muller codes on recovery, our method reduces the over-
all communication bandwidth requirement per sensor, and
acchieve high localization accuracy. However, the trade-off
between high level of accuracy and low computational cost
should be considered as well.
V.
CONCLUDING REMARKS
In this paper, we presented an approach for multiple target
localization in wireless sensor networks using deterministic
sensing matrices. We begin with problem formulation and
present a localization method from sparse measurement based
188
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

on compressive sensing theory. Constructing a sparse measure-
ment matrix is one of the most difÔ¨Åcult part during this process.
We investigated second-order Reed-Muller codes and applied
them to form the measurement matrices in our problem. A key
advantage of compressive sensing with these matrices is that
it admits a fast reconstruction algorithm, especially for basis
pursuit, and depends only on number of measurements m and
sparsity k, not depends on the signal length n, in addition to
their deterministic structure. Numerical results show that these
matrices also guarantee to recover approximated solutions as
the traditional schemes do, especially when the signal vectors
are very sparse. We expect that this type of matrices will be
useful for various localization applications in wireless sensor
networks.
ACKNOWLEDGMENT
This research was partly supported by Mid-career Re-
searcher Program through NRF grant funded by MEST, Korea
(No. 2012-0005330), and by the MSIP, Korea in the ICT R&D
Program 2013 (KCA-2012-12-911-01-107).
REFERENCES
[1]
Y. Shang, W. Ruml, Y. Zhang, and M. Fromherz, ‚ÄúLocalization from
connectivity in sensor networks,‚Äù IEEE Trans. Parallel Distributed Syst.,
vol. 15, no. 11, pp. 961-974, Nov. 2004.
[2]
N. Patwari, J. N. Ash, and S. Kyperountas, ‚ÄúLocating the nodes:
Cooperative localization in wireless sensor networks,‚Äù IEEE Sig. Proc.
Mag., vol. 22, no. 4, pp. 54-69, July 2005.
[3]
I. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci, ‚ÄúWireless
sensor networks: A survey,‚Äù Computer Networks, vol. 38, no. 4, pp.
393-422, 2002.
[4]
J. Liu, Y. Zhang, and F. Zhao, ‚ÄúRobust distributed node localization with
error management,‚Äù Proc. ACM MobiHoc 2006, pp. 250-261, Florence,
Italy, May 2006.
[5]
X. Ji and H. Zha, ‚ÄúSensor positioning in wireless ad-hoc sensor
networks with multidimensional scaling,‚Äù Proc. IEEE INFOCOM 2004,
pp. 2652-2661, Hong Kong, China, Mar. 2004.
[6]
N. Patwari and A. O. Hero III, ‚ÄúManifold learning algorithms for
localization in wireless sensor networks,‚Äù Proc. IEEE ICASSP 2004,
vol. 3, pp. 857-860, Montreal, Canada, May 2004.
[7]
N. Patwari, A. O. Hero III, M. Perkins, N. S. Correal, and R. J. Odea,
‚ÄúRelative location estimation in wireless sensor networks,‚Äù IEEE Trans.
Sig. Proc., vol. 51, no. 8, pp. 2137-2148, Aug. 2003.
[8]
G. Mao, B. Fidan, and B. D. O. Anderson, ‚ÄúWireless sensor network
localization techniques,‚Äù Computer Networks, vol. 51, no. 10, pp. 2529-
2553, July 2007.
[9]
L. Doherty, L. E. Ghaoui, and S. J. Pister, ‚ÄúConvex position estimation
in wireless sensor networks,‚Äù Proc. IEEE INFOCOM 2002, vol. 3, pp.
1655-1663, San Francisco, USA, Apr. 2002.
[10]
P. Biswas, T. C. Liang, K. C. Toh, Y. Ye, and T. C. Wang, ‚ÄúSemideÔ¨Ånite
programming approaches for sensor network localization with noisy
distance measurements,‚Äù IEEE Trans. Auto. Sci. Eng., vol. 3, no. 4, pp.
360-371, Oct. 2006.
[11]
Q. Shi, C. He, L. Jiang, and J. Luo, ‚ÄúSensor network localization via
nondifferentiable optimization,‚Äù Proc. IEEE GLOBECOM 2008, New
Orleans, USA, Dec. 2008.
[12]
R. Zetik, S. Jovanoska, and R. Thom¬®a, ‚ÄúSimple method for localisation
of multiple tag-free targets using UWB sensor network,‚Äù Proc. IEEE
ICUWB 2011, Bologna, Italy, Sept. 2011.
[13]
A. Kushki, K. N. Plataniotis, and A. N. Venetsanopoulos, ‚ÄúKernel-based
positioning in wireless local area networks,‚Äù IEEE Trans. Mobile Comp.,
vol. 6, no. 6, pp. 689-705, June 2007.
[14]
V. Cevher, P. Boufounos, R. G. Baraniuk, A. C. Gilbert, and M.
J. Strauss, ‚ÄúNear-optimal Bayesian localization via incoherence and
sparsity,‚Äù Proc. IPSN 2009, San Francisco, USA, Apr. 2009.
[15]
W. Dai and O. Milenkovic, ‚ÄúSubspace pursuit for compressive sensing
signal reconstruction,‚Äù IEEE Trans. Info. Theory, vol. 55, no. 5, pp.
2230-2249, May 2009.
[16]
D. Needell and J. Tropp, ‚ÄúCoSaMP: Iterative signal recovery from
incomplete and inaccurate samples,‚Äù Appl. Comput. Harmon. Anal., vol.
26, no. 3, pp. 301-321, 2009.
[17]
J. Tropp and A. C. Gilbert, ‚ÄúSignal recovery from random measurements
via orthogonal matching pursuit,‚Äù IEEE Trans. Info. Theory, vol. 53, no.
12, pp. 4655-4666, Dec. 2007.
[18]
V. Cevher, M. F. Duarte, and R. G. Baraniuk, ‚ÄúDistributed target
localization via spatial sparsity,‚Äù Proc. EUSIPCO 2008, Lausanne,
Switzerland, Aug. 2008.
[19]
E. Cand`es, J. Romberg, and T. Tao, ‚ÄúRobust uncertainty principles:
Exact signal reconstruction from highly incomplete frequency informa-
tion,‚Äù IEEE Trans. Info. Theory, vol. 52, no. 2, pp. 489-509, Feb. 2006.
[20]
D. Donoho, ‚ÄúCompressed sensing,‚Äù IEEE Trans. Info. Theory, vol. 52,
no. 4, pp. 1289-1306, Apr. 2006.
[21]
R. Calderbank, S. Howard, and S. Jafarpour, ‚ÄúConstruction of a large
class of deterministic sensing matrices that satisfy a statistical isometry
property,‚Äù IEEE Trans. Info. Theory, vol. 4, no. 2, pp. 358-374, Apr.
2010.
[22]
R. DeVore, ‚ÄúDeterministic constructions of compressed sensing matri-
ces,‚Äù Jour. Complexity, vol. 23, no. 4-6, pp. 918-925, 2007.
[23]
S. Li, F. Gao, G. Ge, and S. Zhang, ‚ÄúDeterministic construction of
compressive sensing matrices via algebraic curves,‚Äù IEEE Trans. Info.
Theory, vol. 58, no. 8, pp. 5035-5041, Aug. 2012.
[24]
M. A. Tsfasman and S. G. Vladu, Algebraic-Geometric Codes, in Math.
Appl. (Soviet Series), vol. 58, Kluwer Academic Publishers, 1991.
[25]
S. Howard, A. Calderbank, and J. Searle, ‚ÄúA fast reconstruction algo-
rithm for deterministic compressive sensing using second order Reed-
Muller codes,‚Äù Proc. IEEE CISS 2008, pp. 11-15, Princeton, USA, Mar.
2008.
[26]
P. Delsarte and J. M. Gothals, ‚ÄúAlternating bilinear forms over GF(q),‚Äù
Jour. Combinatorial Theory, vol. 19, pp. 26-50, 1975.
[27]
A. Kerdock, ‚ÄúA class of low-rate nonlinear binary codes,‚Äù Info. &
Control, vol. 20, pp. 182-187, 1972.
[28]
F. J. MacWilliams and N. J. A. Sloane, The Theory of Error-Correcting
Codes, North-Holland Publishing, 1977.
[29]
A. R. Hammons, P. V. Kumar, A. R. Calderbank, N. J. A. Sloane, and
P. Sole, ‚ÄúThe Z4-linearity of Kerdock codes, Preparata, Goethals, and
related codes,‚Äù IEEE Trans. Info. Theory, vol. 40, no. 2, pp. 301-319,
Mar. 1994.
189
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

