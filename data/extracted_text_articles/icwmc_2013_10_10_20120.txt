An Application of Second-Order Reed-Muller Codes
for Multiple Target Localization
in Wireless Sensor Networks
Thu Lam Ngoc Nguyen∗, Jaejin Lee∗, and Yoan Shin∗
∗School of Electronic Engineering, Soongsil University, Seoul, Korea
Email: {ngocthu, zlee, yashin}@ssu.ac.kr
Abstract—Compressive sensing is a new signal processing
technique for efﬁcient reconstruction of an n-dimensional signal
from m (m ≪ n) measurements. Most of compressive sensing
researches are based on randomization, while research on de-
terministic sampling is essential for practical implementation.
In this paper, we study m × n deterministic binary sensing
matrices using second-order Reed-Muller codes, which satisfy a
statistically restricted isometry property with reduced complexity
for an application of multiple target localization in wireless
sensor networks. We formulate multiple target locations as a
sparse matrix, then exploit received signal strength information to
recover noisy information using the deterministic sensing matrices
and greedy algorithms to locate each target. The simulation
results show that our scheme also achieves high accuracy in terms
of localization errors when compared to traditional approaches
with the random sensing matrices.
Keywords—wireless sensor network; multiple target localization;
compressive sensing; deterministic sensing matrix; Reed-Muller
codes.
I.
INTRODUCTION
Wireless sensor networks can play a key role in target
tracking, monitoring, environmental sensing and some other
applications. Many approaches for network localization based
on local sensor information have been developed with low-
cost, low-power and small size constraints [1]–[8]. In this
paper, we consider a scenario that the nodes are randomly
deployed in a large area, and we determine multiple target
locations based on the Received Signal Strength (RSS) in-
formation from their neighbors. Some of existing localization
algorithms for this scenario are inefﬁcient, since they require
a large number of data between transmitter and receiver [9]–
[14], [18]. Fortunately, the compressive sensing can help us
to overcome these problems. The goal of compressive sensing
is to recover an unknown signal vector x ∈ Rn from linear
measurement y obtained by
y = Φx,
(1)
where Φ = {Φi}m
i=1 ∈ Rm×n is the sensing matrix. The
most concern is when the number of measurement m is much
smaller than n, i.e., m ≪ n. In this case, ﬁnding an exact
solution x based on the measurement y is an ill-posed problem
since the system of equations is under-determined. However,
we can deal with it by ﬁnding an approximation of x by
solving this problem as
min
x ||x||0
subject to
Φx = y,
(2)
where ||x||0 = |supp(x)|, and a vector is called k-sparse if it
has at most k nonzeros elements. The compressive sensing
technique guarantees exact recovery of the original signal
x with high probability if the sensing matrices satisfy the
Restricted Isometry Property (RIP). That is, for a ﬁxed k, there
exists a small number δk ∈ (0, 1) such that
(1 − δk)||xk||2
2 ≤ ||Φxk||2
2 ≤ (1 + δk)||xk||2
2
(3)
for any k-sparse xk. Hence, the problem (2) can be solved
either by using greedy algorithms such as Basis Pursuit (BP)
[15], Orthogonal Matching Pursuit (OMP) [16], [17], or re-
placed by solving for sparse signal via l1 minimization as
min
x ||x||1
subject to
Φx = y.
(4)
In traditional compressive sensing approach, researchers
have used random projection for the sensing matrices Φ to
obtain the measurement y, since the RIP can be satisﬁed with
some random matrices with their entries following Gaussian
process, Bernoulli process, etc. [19], [20]. Thus, a k-sparse
signal x ∈ Rn can be exactly reconstructed from m mea-
surements. However, random matrices have many drawbacks:
signiﬁcant space requirement for storage, no efﬁcient algorithm
to verify the RIP, hard to deployment in many applications,
to name a few. To this end, designing deterministic sensing
matrices is essential for practical implementation. Recently,
many advantages of deterministic sensing matrices have been
shown. The most of these advantages is their fast and efﬁcient
reconstruction nature. In [21], Calderbank constructed some
statistical RIP conditions such as Statistical Restricted Isom-
etry Property (StRIP) and Uniqueness-guaranteed Statistical
Restricted Isometry Property (UStRIP). These are weaker
versions of the RIP that allow to construct deterministic
sensing matrices. In [22], DeVore gave a generalization of
construction via algebraic curves over ﬁnite ﬁelds. The author
constructed binary sensing matrices of size p2 ×2p+1 by using
polynomials over ﬁnite ﬁeld Fp. This idea has been developed
in many researches [23]. By choosing appropriate algebraic
curves, these deterministic sensing matrices were better than
DeVore’s one. In [24], an application of coding theory in
compressive sensing was presented, where a fast reconstruction
algorithm for deterministic compressive sensing using second-
order Reed-Muller codes was proposed. The matrix Φ is said
to satisfy the StRIP (k, δ) if
Pr
||Φx||2 − ||x||2 ≤ δ||x||2

≥ 1 − ϵ,
(5)
185
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

holds with probability exceeding 1 − δ, and we assume that x
distributes uniformly among k-sparse vectors. They showed
that if Φ satisﬁes the StRIP respect to the parameters ϵ
and δ, high probability reconstruction is also guaranteed. The
deterministic sensing matrices formed by Reed-Muller codes,
Bose-Chaudhuri-Hocquenghem (BCH) codes and some others
can achieve this StRIP condition.
In this paper, we study the construction of deterministic
sensing matrices formed by second-order Reed-Muller codes
and how to apply this theory to multiple target localization in
wireless sensor networks. We formulate each target location
as a sparse vector in the discrete spatial domain. Then, we
measure the RSS information from the targets and apply the
construction of deterministic sensing matrix formed by second-
order Reed-Muller codes as the measurement matrix. These
matrices satisfy the StRIP, so that the approximated solution
of (2) can be obtained by using a recovery algorithm in the
last step.
The organization of the paper is as follows. In Section
II, we explain a motivation of developing real-valued second-
order Reed-Muller codes for deterministic sensing matrices in
compressive sensing. In Section III, we formulate the multiple
target localization problem as an application of compressive
sensing by using the sensing matrices dealt in Section II.
Numerical results are considered in Section IV, followed by
concluding remarks in Section V.
II.
REAL-VALUED SECOND-ORDER REED-MULLER CODES
IN DETERMINISTIC SENSING MATRIX CONSTRUCTION
A. Main construction
Recall that for any two binary vector a = (a0, · · · , ap−1)
and b = (b0, · · · , bp−1) in Zp
2, the inner product is deﬁned as
a · b = aT b =
p−1
X
i=1
aibi
mod 2,
(6)
where (·)T denote the transpose operation. The second-order
Reed-Muller code is given as follows.
φP,b(a) = (−1)w(b)
√
2p
i(2b+Pa)T a
(7)
where P is a p × p binary symmetric matrix, b is a p × 1
binary vector in Z2
p and w(b) is the weight of b, i.e.,
number of bit-1 entries. For given matrix P and vector b,
the second-order Reed-Muller code is a 2p × 1 vector. For
implementation purposes, the matrices P are set as all-zero
matrices or the matrices with zero-diagonals. Thus, there is
only 2p(p−1)/2 matrices P satisfying this condition, which are
{P1, · · · , P2p(p−1)/2} and the functions {φP,b(a)} are real-
valued. The set
FP = {φP,b|b ∈ Zp
2}
(8)
forms a basis of Zp
2. The inner product on FP is deﬁned as
follows. For any two vectors φP,b and φP′,b′ in FP
⟨φP,b, φP′,b′⟩ =
(
1
√
2q
2q
times,
0
2p − 2q
times,
(9)
where q = rank(P − P′). The deterministic sensing matrix in
[25] has the form
ΦRM =

UP1
UP2
· · ·
UP2p(p−1)/2

2p×2p(p+1)/2
(10)
where UPi is unitary matrix correspoding to FPi, i
=
1, · · · , 2p(p−1)/2. Note that if we set m = 2p and n =
2p(p+1)/2, we get an m × n sensing matrix ΦRM. The
reconstruction problem using this matrix is to reconstruct the
k-sparse vector x from the data y given by
y = ΦRMx.
(11)
In [26], the Delsarte-Goethals sets DG(p, r) provide some
restricted conditions for set of matrices P. The set DG(p, r) is
a collection of p × p binary symmetric matrices with property
that for any distinct matrices P, Q ∈ DG(p, r), the rank of
P + Q is greater or equal to p − 2r. This implies that these
sets are nested
DG(p, 0) ⊂ DG(p, 1) ⊂ · · · ⊂ DG

p, p − 1
2

.
(12)
The set DG(p, 0) is called Kerdock set [27]. Setting P to range
over DG(p, (p − 1)/2), the sensing matrices made from the
matrices P are the matrices of size 2p × 2p(r+2).
B. Matrices with construction guarantee
Since the deterministic designs are based on the imple-
mented and practical aspects, we focus on the sensing matrices
whose entries are ±1 by removing the normalization factor of
1/
√
2p in ΦRM
ˆΦ = √mΦRM.
(13)
Let us denote µ(A) as the largest magnitude of entries A.
µ(A) = max
k,j |Ak,j|.
(14)
Thus µ(ˆΦ) = 1. For a ﬁxed signal x ∈ Rn where ||x||0 =
k the recovery in (2) is exact with high probability for the
number of observations m ≥ C · k · log n where C is a known
small constant. We have
ˆΦ∗ ˆΦ = 2p(p+1)/2I = nI,
where (·)∗ denotes conjugate operation. For a small value of
δ ∈ (0, 1), the eigeinvalues of ˆΦ∗ ˆΦ are close to n with high
probability. Thus, || 1
n ˆΦ∗ ˆΦ − I||2 ≤ 1/n, and we have
Pr
||ˆΦx||2 − ||x||2 ≤ δ||x||2

≥ 1 − 1
n,
(15)
Hence, the matrix ˆΦ satisﬁes the StRIP with sparsity k and ϵ =
1
n. We can ﬁnd some further information on binary symmetric
matrices formed by second-order Reed-Muller codes in [25],
[28], [29].
186
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

C. Examples
Let p = 2, then Z2
2 =

0
0

,

0
1

,

1
0

,

1
1

. There is
only 22(2−1)/2 = 2 binary symmetric matrices P of size 2×2
satisfying the condition. These are
P1 =

0
0
0
0

, P2 =

0
1
1
0

(16)
Thus, the corresponding unitary matrices UP1 and UP2 are
UP1 = 1
2


1
−1
−1
1
1
1
−1
−1
1
−1
1
−1
1
1
1
1

 , UP2 = 1
2


1
−1
−1
1
1
1
−1
−1
1
−1
1
−1
−1
−1
−1
−1


Hence, we get the deterministic sensing matrix ˆΦ as
ˆΦ =


1
−1
−1
1
1
−1
−1
1
1
1
−1
−1
1
1
−1
−1
1
−1
1
−1
1
−1
1
−1
1
1
1
1
−1
−1
−1
−1


22×23
.
III.
AN APPLICATION ON MULTIPLE TARGET
LOCALIZATION IN WIRELESS SENSOR NETWORKS
A. Problem formulation
Consider an area which is divided into a discrete grid with
n points. Denote k as the number of targets which are located
in this area. Each target is n × 1 vector whose elements are
zeros, except 1 at the index of grid point where target is
located. With k targets, we get a matrix of target locations
over the grid as
θ = [θ1
θ2
· · ·
θk]n×k .
(17)
We take m measurements respect to each target under matrix
Ψ, which will be explained in the next subsection. Then the
RSS signals are given by


x1
x2
...
xk


| {z }
x
=


Ψ1
0
· · ·
0
0
Ψ2
· · ·
0
...
...
...
0
0
· · ·
· · ·
Ψk


|
{z
}
Ψ


θ1
θ2
...
θk


| {z }
θ
(18)
We can describe the compression procedure as follows.


y1
y2
...
yk


| {z }
y
=


ˆΦ1
0
· · ·
0
0
ˆΦ2
· · ·
0
...
...
...
0
0
· · ·
· · ·
ˆΦk


|
{z
}
ˆΦ


x1
x2
...
xk


| {z }
x
+


n1
n2
...
nk


| {z }
n
.
(19)
Our goal is to ﬁnd all the locations of these targets with an
accurate, fast and efﬁcient algorithm with a small value of m.
B. Localization process
The matrix form of (19) is
y = ˆΦΨθ + n.
(20)
These matrices Ψ, ˆΦ are generated as follows.
•
RSS matrix Ψ = diag{Ψ1, · · · , Ψk} is made from
using the radio propagation channel model
{Ψi}uv = PL(duv)
= PL(d0) − 10np log10
duv
d0

, u, v = 1, · · · , n,
(21)
where d0 = 1m is the reference distance, duv is
the real distance between transmitter and receiver in
meters, PL(d0) is computed using the free space path
loss equation, and np is the path loss component.
•
In the sensing matrix ˆΦ = diag{Φ1, · · · , Φk}, each
Φi(i = 1, · · · , k) is generated by the matrices satis-
fying the StRIP, as we have discussed in the previous
section.
According to the compressive sensing theory, the localization
problem is stated as the recovery of a sparse signal xi
(i =
1, · · · , k) from measurement yi, which is equivalent to re-
construct target location θi from yi. Assume that ||n||2 ≤ ϵ
where ϵ is a small positive constant. Since each signal xi is
represented by a sparsity basis, each sparse vector θi can be
found either by solving the following l1-minimization problem
ˆθ = arg min ||θ||1
subject to
y = Θθ,
(22)
where Θ =
ˆΦΨ, or by solving the convex optimization
program by calling the OMP algorithm as
ˆθ = OMP(y, Θ, ϵ).
(23)
The main idea of the OMP algorithm is to ﬁnd the columns
of the matrix Θ whose linear combination is close to y. The
OMP is more simpler and faster than other alternatives. In
this paper, we have applied this algorithm to simulate and to
generate sensing matrices ˆΦ. To improve the performance and
to ﬁnd the exact target locations in the grid points, a threshold
has been deﬁned to select the largest component in the location
vector of n components with minimum overal distance error.
IV.
NUMERICAL RESULTS
In this section, we examine the performance of multiple
target localization using compressive sensing under random
matrices and deterministic matrices formed by second-order
Reed-Muller codes in an indoors environment. We randomly
deployed M sensors in an area with the size of 10m×10m
with N grid points, and placed the targets by randomly
selecting k grid points in uniform manners. We added Gaussian
noises with zero mean and standard deviation of 0.05 to the
observation y. We used the Average Localization Error (ALE)
to quantify the localization accuracy, which is deﬁned as
ALE(p) = 1
k
q
||p − p∗||2
2,
(24)
187
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

0
2
4
6
8
10
0
1
2
3
4
5
6
7
8
9
10
11
x [meters]
y [meters]
 
 
Actual postion
Gaussian matrix
Deterministic matrix
(a) Position recovery performance with M = 8.
5
6
7
8
9
10
11
12
1.4
1.6
1.8
2
2.2
2.4
2.6
2.8
3
3.2
3.4
Number of measurements
Localization Error (m)
 
 
Random matrix
Deterministic matrix
(b) Average localization error respect to 5 targets.
Fig. 1.
Localization of 5 targets under random sensing matrix and determin-
istic sensing matrix.
where p is the actual point and p∗ is the estimated point.
Each run is collected 100 times. In the simulations, each RSS
information Ψi(i = 1, · · · , k) was obtained by
{Ψi}uv(d) = −46.2 − 10np log10(d), u, v = 1, · · · , n, (25)
Each location was observed over 100 simulations.
Figure 1 shows the position recovery performance. The
area is divided by 64 × 64 grid points. According to the
compressive sensing approach, with 5 targets, the number of
RSS measurements required was at least M > 2k = 10 in
the random i.i.d. Gaussian matrix case and 8 in the proposed
deterministic matrix for exact solution recovery. Figure 1(a)
shows the position recovery for 5 targets with M = 8. It
shows that the proposed scheme achieves good performance
as the traditional scheme does. Note that only deterministic
sensing matrices are practically feasible when considering
actual implementation. Figure 1(b) shows the ALE versus the
number of measurements. The ALE of the traditional random
approach was more dramatically decreased than the proposed
one when the number of measurement increased.
Figure 2 shows the ALE with M randomly selected mea-
surements in a given set of sensors. M was to set at 8 and
32 in this simulation. In the case of M = 8, the ALE of
the proposed scheme is smaller than the traditional case as
0
10
20
30
40
50
60
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Number of sensors
Average Localization Error (m)
 
 
Random
Deterministic
(a) 8 × 64 sensing matrix.
0
10
20
30
40
50
60
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
Number of sensors
Average Localization Error (m)
 
 
Random
Deterministic
(b) 32 × 64 sensing matrix.
Fig. 2.
Average localization error.
seen in Figure 2(a). However, when M = 32 we observe
the opposite results as in Figure 2(b). Since M is large,
the independence among columns of the deterministic sensing
matrices is not guaranteed, while the RIP holds with random
matrices in this case. Thus, the perfect reconstruction by the
proposed method may be not guaranteed, and performance by
the random matrices is better than the proposed one when the
number of measurements becomes large.
For classical approach, each sensor must be recorded n
measurements, which brings large communication cost, espe-
cially in large-scale networks. Based on the idea of reducing
cost in compressive sensing theory and the advantages of
deterministic sensing matrices formed by the second-order
Reed-Muller codes on recovery, our method reduces the over-
all communication bandwidth requirement per sensor, and
acchieve high localization accuracy. However, the trade-off
between high level of accuracy and low computational cost
should be considered as well.
V.
CONCLUDING REMARKS
In this paper, we presented an approach for multiple target
localization in wireless sensor networks using deterministic
sensing matrices. We begin with problem formulation and
present a localization method from sparse measurement based
188
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

on compressive sensing theory. Constructing a sparse measure-
ment matrix is one of the most difﬁcult part during this process.
We investigated second-order Reed-Muller codes and applied
them to form the measurement matrices in our problem. A key
advantage of compressive sensing with these matrices is that
it admits a fast reconstruction algorithm, especially for basis
pursuit, and depends only on number of measurements m and
sparsity k, not depends on the signal length n, in addition to
their deterministic structure. Numerical results show that these
matrices also guarantee to recover approximated solutions as
the traditional schemes do, especially when the signal vectors
are very sparse. We expect that this type of matrices will be
useful for various localization applications in wireless sensor
networks.
ACKNOWLEDGMENT
This research was partly supported by Mid-career Re-
searcher Program through NRF grant funded by MEST, Korea
(No. 2012-0005330), and by the MSIP, Korea in the ICT R&D
Program 2013 (KCA-2012-12-911-01-107).
REFERENCES
[1]
Y. Shang, W. Ruml, Y. Zhang, and M. Fromherz, “Localization from
connectivity in sensor networks,” IEEE Trans. Parallel Distributed Syst.,
vol. 15, no. 11, pp. 961-974, Nov. 2004.
[2]
N. Patwari, J. N. Ash, and S. Kyperountas, “Locating the nodes:
Cooperative localization in wireless sensor networks,” IEEE Sig. Proc.
Mag., vol. 22, no. 4, pp. 54-69, July 2005.
[3]
I. Akyildiz, W. Su, Y. Sankarasubramaniam, and E. Cayirci, “Wireless
sensor networks: A survey,” Computer Networks, vol. 38, no. 4, pp.
393-422, 2002.
[4]
J. Liu, Y. Zhang, and F. Zhao, “Robust distributed node localization with
error management,” Proc. ACM MobiHoc 2006, pp. 250-261, Florence,
Italy, May 2006.
[5]
X. Ji and H. Zha, “Sensor positioning in wireless ad-hoc sensor
networks with multidimensional scaling,” Proc. IEEE INFOCOM 2004,
pp. 2652-2661, Hong Kong, China, Mar. 2004.
[6]
N. Patwari and A. O. Hero III, “Manifold learning algorithms for
localization in wireless sensor networks,” Proc. IEEE ICASSP 2004,
vol. 3, pp. 857-860, Montreal, Canada, May 2004.
[7]
N. Patwari, A. O. Hero III, M. Perkins, N. S. Correal, and R. J. Odea,
“Relative location estimation in wireless sensor networks,” IEEE Trans.
Sig. Proc., vol. 51, no. 8, pp. 2137-2148, Aug. 2003.
[8]
G. Mao, B. Fidan, and B. D. O. Anderson, “Wireless sensor network
localization techniques,” Computer Networks, vol. 51, no. 10, pp. 2529-
2553, July 2007.
[9]
L. Doherty, L. E. Ghaoui, and S. J. Pister, “Convex position estimation
in wireless sensor networks,” Proc. IEEE INFOCOM 2002, vol. 3, pp.
1655-1663, San Francisco, USA, Apr. 2002.
[10]
P. Biswas, T. C. Liang, K. C. Toh, Y. Ye, and T. C. Wang, “Semideﬁnite
programming approaches for sensor network localization with noisy
distance measurements,” IEEE Trans. Auto. Sci. Eng., vol. 3, no. 4, pp.
360-371, Oct. 2006.
[11]
Q. Shi, C. He, L. Jiang, and J. Luo, “Sensor network localization via
nondifferentiable optimization,” Proc. IEEE GLOBECOM 2008, New
Orleans, USA, Dec. 2008.
[12]
R. Zetik, S. Jovanoska, and R. Thom¨a, “Simple method for localisation
of multiple tag-free targets using UWB sensor network,” Proc. IEEE
ICUWB 2011, Bologna, Italy, Sept. 2011.
[13]
A. Kushki, K. N. Plataniotis, and A. N. Venetsanopoulos, “Kernel-based
positioning in wireless local area networks,” IEEE Trans. Mobile Comp.,
vol. 6, no. 6, pp. 689-705, June 2007.
[14]
V. Cevher, P. Boufounos, R. G. Baraniuk, A. C. Gilbert, and M.
J. Strauss, “Near-optimal Bayesian localization via incoherence and
sparsity,” Proc. IPSN 2009, San Francisco, USA, Apr. 2009.
[15]
W. Dai and O. Milenkovic, “Subspace pursuit for compressive sensing
signal reconstruction,” IEEE Trans. Info. Theory, vol. 55, no. 5, pp.
2230-2249, May 2009.
[16]
D. Needell and J. Tropp, “CoSaMP: Iterative signal recovery from
incomplete and inaccurate samples,” Appl. Comput. Harmon. Anal., vol.
26, no. 3, pp. 301-321, 2009.
[17]
J. Tropp and A. C. Gilbert, “Signal recovery from random measurements
via orthogonal matching pursuit,” IEEE Trans. Info. Theory, vol. 53, no.
12, pp. 4655-4666, Dec. 2007.
[18]
V. Cevher, M. F. Duarte, and R. G. Baraniuk, “Distributed target
localization via spatial sparsity,” Proc. EUSIPCO 2008, Lausanne,
Switzerland, Aug. 2008.
[19]
E. Cand`es, J. Romberg, and T. Tao, “Robust uncertainty principles:
Exact signal reconstruction from highly incomplete frequency informa-
tion,” IEEE Trans. Info. Theory, vol. 52, no. 2, pp. 489-509, Feb. 2006.
[20]
D. Donoho, “Compressed sensing,” IEEE Trans. Info. Theory, vol. 52,
no. 4, pp. 1289-1306, Apr. 2006.
[21]
R. Calderbank, S. Howard, and S. Jafarpour, “Construction of a large
class of deterministic sensing matrices that satisfy a statistical isometry
property,” IEEE Trans. Info. Theory, vol. 4, no. 2, pp. 358-374, Apr.
2010.
[22]
R. DeVore, “Deterministic constructions of compressed sensing matri-
ces,” Jour. Complexity, vol. 23, no. 4-6, pp. 918-925, 2007.
[23]
S. Li, F. Gao, G. Ge, and S. Zhang, “Deterministic construction of
compressive sensing matrices via algebraic curves,” IEEE Trans. Info.
Theory, vol. 58, no. 8, pp. 5035-5041, Aug. 2012.
[24]
M. A. Tsfasman and S. G. Vladu, Algebraic-Geometric Codes, in Math.
Appl. (Soviet Series), vol. 58, Kluwer Academic Publishers, 1991.
[25]
S. Howard, A. Calderbank, and J. Searle, “A fast reconstruction algo-
rithm for deterministic compressive sensing using second order Reed-
Muller codes,” Proc. IEEE CISS 2008, pp. 11-15, Princeton, USA, Mar.
2008.
[26]
P. Delsarte and J. M. Gothals, “Alternating bilinear forms over GF(q),”
Jour. Combinatorial Theory, vol. 19, pp. 26-50, 1975.
[27]
A. Kerdock, “A class of low-rate nonlinear binary codes,” Info. &
Control, vol. 20, pp. 182-187, 1972.
[28]
F. J. MacWilliams and N. J. A. Sloane, The Theory of Error-Correcting
Codes, North-Holland Publishing, 1977.
[29]
A. R. Hammons, P. V. Kumar, A. R. Calderbank, N. J. A. Sloane, and
P. Sole, “The Z4-linearity of Kerdock codes, Preparata, Goethals, and
related codes,” IEEE Trans. Info. Theory, vol. 40, no. 2, pp. 301-319,
Mar. 1994.
189
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-284-4
ICWMC 2013 : The Ninth International Conference on Wireless and Mobile Communications

