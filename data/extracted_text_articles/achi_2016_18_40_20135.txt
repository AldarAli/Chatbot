The Analysis of the Specific Dictionaries for Compressive Sensing of EEG Signals 
 
Monica Fira 
Institute of Computer Science 
Romanian Academy 
Iasi, Romania 
mfira@etti.tuiasi.ro 
 
Victor-Andrei Maiorescu1,2, Liviu Goras1,2 
1“Gheorghe Asachi” Technical University of Iaşi, 
2Institute of Computer Science, Romanian Academy, Iasi  
mandrei@etti.tuiasi.ro 
lgoras@etti.tuiasi.ro 
 
Abstract— 
In 
this 
paper 
the 
possibility 
of 
the 
electroencephalogram (EEG) compressed sensing based on 
specific dictionaries is presented. Three types of dictionaries 
(wavelet, temporal EEG signal specific, and channel specific) 
are analyzed and the results are expressed through 
quantitative measures (distortion) and by qualitative measures 
(stimulus classification rate of the Brain Computer Interface 
(BC)I paradigm - Spelling). 
Keywords- EEG; Compressed sensing; BCI; P300. 
I. 
 INTRODUCTION 
In recent years, compressed sensing (CS) has attracted 
considerable attention in areas like applied mathematics, 
computer science, and electrical engineering by showing 
that, in certain conditions, it is possible to surpass the 
traditional limits of sampling theory. CS builds upon the 
fundamental fact that many signals can be represented using 
only a few non-zero coefficients in a suitable basis or 
dictionary. Nonlinear optimization can then be used to 
recover such signals from very few measurements [1].The 
concept of compressed sensing is an example of practical use 
of new mathematical results. The difficulties for using in 
applications of such results are related to the way such 
concepts are understood, in a more or less intuitive manner, 
in order to facilitate the fusion between theory and 
applications. 
The literature of recent years shows an impressive 
number of papers in the CS field, covering both 1D and 2D 
medical signals. Among the 1D signals the most frequently 
used in CS applications are the electrocardiogram (ECG) and 
electroencephalogram (EEG) since they are most used  in the 
medical world as well. In the case of EEG signals, there is 
often a need of records for longer periods of time (i.e., during 
the night) or for a large number of channels. 
In this paper, we propose a compression method for 
EEG signals based on CS using specific dictionaries for 
reconstruction in the sense that the atoms of the above 
dictionaries are actually segments of EEG signals and 
compare it with a wavelet representation. 
To validate the proposed method EEG recordings of the 
competition for Spelling, BCI Competition III - Dataset II 
were used, and in order to evaluate the reconstructed signal, 
two types of evaluation were used, namely: 
• 
qualitative evaluation, by P300 detection and 
prediction of the watched character in the case of the 
spelling paradigm for data taken from the “BCI III 
competition Challenge 2005” on the reconstructed EEG 
signals and using the winner scripts (Alain Rakotomamonjy 
[9]). 
• 
quantitative evaluation, using distortion measures 
such as PRDN (normalized percent of root-mean-square 
difference), NMSE (normalized Mean Square Error) and 
RMS (root mean square error) between the reconstructed 
and original signals. 
 
II. 
COMPRESSED SENSING 
Shannon’s sampling theory represents, for many signal 
classes of interest in signal processing, a condition too strict 
for acquisition and representation of signals [1]. When 
signals are known to be compressible or sparse, only a much 
smaller fraction of samples may be needed to capture all the 
signal information, at the expense of having to use nonlinear 
reconstruction techniques. This area of research has evolved 
into the technique of "compressed sensing", also known as 
compressive sensing, compressive sampling and sparse 
sampling),  perfected in the past few years by prestigious 
researchers such as D. Donoho [3], E. Candès [4] and M. 
Elad [5], and drawing the attention of many others. It 
consists in capturing the information from sparse or 
compressible signals via a set of a few linear measurements, 
possibly random, followed by reconstructing a signal using 
optimization techniques for finding sparse solutions to 
underdetermined linear systems. The generality of the 
approach coupled with the prevalence of sparsity-related 
signal processing for big data is considered to have an 
enormous potential, with multiple implications and 
applications, in numerous fields of exact sciences. 
As already mentioned, CS studies the possibility of 
reconstructing a signal x from a few linear projections, also 
called measurements, given the a priori information that the 
signal is sparse or compressible in some basis  . The 
vectors on which x is projected onto are arranged as the 
rows of a nxN projection matrix , n < N, where N is the 
size of x and n is the number of measurements. Denoting the 
measurement vector as y, the acquisition process can be 
described as: 
 
 
x
y
 
  
(1) 
380
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions





 

y
subject to
l0
arg min
ˆ
 
(2) 
 
ˆ
ˆ
x  
 
 
 
(3) 
 
The system of equations (1) is obviously undetermined. 
Under certain assumptions on   and  , however, the 
original expansion vector   can be reconstructed as the 
unique solution to the optimization problem (2); the signal 
is then reconstructed with (3). Note that (2) amounts to 
finding the sparsest decomposition of the measurement 
vector y in the dictionary   . Unfortunately, (2) is 
combinatorial and unstable when considering noise or 
approximately sparse signals. Two directions have emerged 
to circumvent these problems: (i) pursuit and thresholding 
algorithms seek a sub-optimal solution of (2) and (ii) the 
Basis Pursuit algorithm relaxes the 
0l  minimization to
1l , 
solving the convex optimization problem (4) instead of the 
original. 
 




 

y
subject to
l1
arg min
ˆ
 
(4) 
 
In the past few years, techniques inspired from the 
mathematic fundamentals of CS have also been applied in 
the field of biomedical signals, both at the level of 
processing methods for electrocardiographic (ECG) and 
electroencephalographic (EEG) signals and of practical 
implementation in applications such as compression, 
transmission and reconstruction of the ECG signal using a 
personal device such as a smart-phone. 
III. 
BCI P300 SPELLER 
The use of EEG signals as a vector of communication 
between man and machine is one of the new challenges in 
biomedical signal theory. The main element of this 
communication system known as "brain-computer interface" 
(BCI Brain-Computer Interface) is the proper interpretation 
of the EEG signals and the characteristic parameters of the 
brain electrical activity. 
The P300 speller is based on the so-called oddball 
paradigm which states that rare expected stimuli produce a 
positive deflection in the EEG after about 300 ms.  
 
A 
B 
C 
D 
E 
F 
G 
H 
I 
J 
K 
L 
M 
N 
O 
P 
Q 
R 
S 
T 
U 
V 
W 
X 
Y 
Z 
1 
2 
3 
4 
5 
6 
7 
8 
9 
 
Figure 1.  Example of a 6 × 6 user display in P300 Speller 
A P300 speller, based on this paradigm, has been 
introduced by Farwell and Donchin who developed a 
protocol whereby a subject is presented a 6 × 6 character 
matrix (see Figure 1) [11] .  
The dataset II of the BCI competition III 2005, from the 
competition webpage [10], has been recorded from two 
different subjects and 5 different spelling sessions. Each 
session is composed of runs, and for each run, a subject is 
asked to spell a word. For a given acquisition session, all 
EEG signals of a 64-channel scalp have been continuously 
collected. Before digitization at a sample rate of 240 Hz, 
signals have been bandpass-filtered from 0.1 to 60 Hz. 
Each session is composed of runs, and for each run, a 
subject 
is 
asked 
to 
spell 
a 
word. 
Row/column 
intensifications were the block is randomized in blocks of 
12. The sets of 12 intensifications were repeated 15 times 
for each character epoch (i.e., any specific row/column was 
intensified 15 times and thus there were 180 total 
intensifications for each character epoch). Each character 
epoch was followed by a 2.5sec period, and during this time 
the matrix was blank. 
The training set contains 85 characters and the test set 
consists of 100 characters for each of the two subjects A and 
B. A more detailed description of the dataset can be found 
in the BCI competition paper [10]. 
The competition winners, Alain Rakotomamonjy and 
Vincent Guigue propose a method that copes with such 
variabilities through an ensemble of classifiers approach [9]. 
Each classifier is composed of a linear Support Vector 
Machine trained on a small part of the available data and for 
which a channel selection procedure has been performed. 
Their performances are a classification rate of 95.5% for the 
15 sequences and 73.5% for 5 sequences [9]. 
IV. 
METHOD 
The key element in the success of signal compression 
based on compressed sensing is the right choice of the 
dictionary based on which the reconstruction will be done.  
Generally, the ECG and EEG biomedical signals have not a 
very high sparsity in standard wavelet dictionaries. 
Therefore, in most of cases, the authors propose specific 
dictionaries either specific to the signal or specific for the 
used database. 
In the following an analysis of how the results are 
influenced by various dictionaries is made. Three types of 
dictionaries have been analyzed as follows. 
A. Wavelet Dictionary 
The first choice was the Daubechies 10 type dictionary so 
that for all channels a single dictionary will be used [6-8]. 
B. Temporal EEG signal specific dictionary 
A second choice investigated as well in [7], was to build 
dictionaries from segments of certain predefined EEG 
channels, recorded at the same time with the target EEG 
compressed signal channel. These dictionaries are built with 
EEG signals from channels that are acquired in the classical 
381
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

way; the dictionaries are the same for all compressed sensed 
channels. 
To 
construct 
the 
necessary 
dictionaries 
for 
reconstruction, EEG signals from channels FPZ, F7, F8, C5, 
CZ, T8, PO7, PO8 and Oz were used. The rest of the 
channels, i.e. the 55 channels (Fig. 2) were segmented in 
windows with 1 second length (240 samples) and using a 
random matrix with size 240x24 we obtained EEG 
compressed signals (with size 24 and compression ratio CR 
= 10:1). In Figure 2 the red channels are used for dictionary 
construction and the signals in the white channels are 
compressed sensed. 
 
Figure 2.  Electrode placement and channel name. 
Thus, for each sample time we have one dictionary. 
Knowing the random matrix used for sensing and the 
dictionary with the EEG signals from the 9 channels 
acquired synchronously with the compressed sensed 
channels, the EEG signals for the CS channels could be 
reconstructed [7].  
C. Channel specific dictionary 
Third, for each EEG channel a dictionary has been built. 
The atoms of dictionary are actually the EEG segments of 
the training set.  In this case, for the data acquired on 64 
channels, there are 64 dictionaries. Thus, each dictionary was 
composed from 2x85 atoms; for every epoch from the 
training set, 2 segments (from 240 samples) of EEG signal 
were randomly selected as atoms in the dictionary. 
D. Evaluation of the reconstructed signals 
In order to evaluate and validate the methods, we used 
both quantitative measures (the reconstructed signal 
distortion) and signal quality measures (expressed by the 
classification rate of the characters tracked by a human 
subject, which is exactly the problem of the BCI 
Competition III 2005 - dataset II – Spelling). 
 
V. 
EXPERIMENTAL RESULTS AND DISCUSSIONS 
For the evaluation of the analyzed methods we used the 
dataset II of the BCI Competition III 2005 -P300 Spelling. 
Thus, for evaluation of compression we used the 
compression rate (CR) (5) defined as the ratio between the 
number of bits needed to represent the original and the 
compressed signal. 
 
comp
orig
b
b
CR 
 
 
 
(5) 
 
For qualitative evaluation of the method based on the 
classification rate in spelling paradigm, we used scripts from 
the winners, Alain Rakotomamonjy and Vincent Guigue [9]. 
The used scripts implement classification based on all 64 
EEG channels. 
To validate the compression we evaluated the distortion 
between the original and the reconstructed signals by means 
of the PRDN (the normalized percentage root-mean-square 
difference):  
 







N
n
N
n
x
n
x
x n
x n
PRDN
1
2
1
2
)
( )
(
~( ))
( ( )
100
%
 (6) 
 
where 
x(n)
 and 
( )
~ n
x
 are the samples of the original and 
the reconstructed signals respectively, x  is the mean value 
of the original signal, and N is the length of the window over 
which the PRDN is calculated. 
For compression, the EEG signal was segmented into 
windows of length 1 sec, i.e. 240 samples and we used a 
random matrix with size 240x24 for CR = 10:1 and a  
random matrix with size 240x48 for CR = 5:1. 
Table 1 presents the results of the three tested 
dictionaries. Note that in terms of reconstruction errors 
expressed via PDN, the smallest errors were obtained using 
specific in time EEG signal dictionaries, which consists of 
atoms regularly acquired at the same time point from the 
other channels. Considering the rate of classification for the 
spelling paradigm, the best results are obtained using 
channel-specific dictionaries. 
 
 
 
 
 
 
 
382
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

TABLE I.  
AVERAGE RESULTS: PRDN_MEAN AND CLASSIFICATION 
PERFORMANCE IN % OF CORRECTLY RECOGNIZED CHARACTERS FOR THE B 
SUBJECTS AND FOR INCREASING NUMBER OF SEQUENCES. 
 
P300 Spelling - classification performance for 
number of sequences (classification rate %) 
1     2    3   4     5    6    7    8    9   10  11  12  13  
14  15 
PRDN 
mean 
Original data – uncompressed and classificated by Alain 
Rakotomamonjy and Vincent Guigue 
- 
38  60  70  69  80  84  86  89  92  93  95  96  96  
96  95 
0 
Dict_Daubechies10 
10:1 
7    17  16  18  27  29  37  40  38  41  48  45  51  
48  54 
108.91 
Dictionary=[Signal_8(i:i+239);Signal_10(i:i+239);Signal_11(i:
i+239);Signal_12(i:i+239);Signal_14(i:i+239);Signal_27(i:i+23
9);Signal_50(i:i+239);Signal_52(i:i+239);Signal_58(i:i+239)]; 
5:1 
22  31  42  50  54  61  68  70  72  77  82  85  79 
79  81 
35.38 
10:1 
23  35  42  44  54  57  60  63  68  70  76  78  76 
78  80 
31.42 
Dictionary = 2*85 atoms from the training set for each 
channel 
5:1 
29  41  50  62  68  74  73  78  82  82  86  86  86  
87  90 
41.17 
10:1 
19  30  43  52  50  60  60  65  73  71  78  82  84  
82  89 
55.90 
 
 
In Table II PRDN vs. channel (top figure) are presented 
as well as examples of original and reconstructed EEG 
signal (figures below). The worst results are obtained using 
wavelet type dictionaries. Between the classification rate in 
spelling paradigm and error expressed as PRDN there is a 
discordance, namely not always the smallest PRDN errors 
lead to highest classification rate (see the results in table 
with bold). The explanation for the discrepancy between the 
classification rate and average PRDN is that each channel 
has a certain weight in the classification rate for the spelling 
paradigm. The obtained results lead to the conclusion that 
some channels that have a higher weight in the classification 
rate are rebuilt better than others which have lesser 
meaning. Thus it can be seen that for the channel specific 
dictionaries, in case of both compression rates of 5:1 and 
10:1, the error for the channels 22-38 is much lower 
compared to the rest of the channels. In fact one can speak 
about a group of errors in three clusters, namely, a class for 
the channels 1-21, the second class for the 22-40 channels, 
and the third class for the channels 41-64. These three 
groups are closely interlinked to the placement of the cranial 
electrodes too (see Figure 1). 
 
 
 
TABLE II PRDN_MEAN VS. CHANNEL AND ORIGINAL VS. SIGNAL RESONSTRUCTED  FOR THE THREE TESTED DICTIONARIES 
Dict_Daubechies10    
CR = 10:1   
PRDN_mean  = 108.91 
Dictionary=[Signal_8(i:i+239);Signal_10(i:i+239);Signal_11(i:i+
239);Signal_12(i:i+239);Signal_14(i:i+239);Signal_27(i:i+239);Si
gnal_50(i:i+239);Signal_52(i:i+239);Signal_58(i:i+239)] 
and  
CR = 10:1 PRDN_mean  = 31.42 
0
10
20
30
40
50
60
70
70
80
90
100
110
120
130
 
0
10
20
30
40
50
60
70
0
10
20
30
40
50
60
70
383
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

800
900
1000
1100
1200
1300
1400
1500
1600
1700
1800
-60
-40
-20
0
20
40
60
80
 
400
600
800
1000
1200
1400
1600
-60
-40
-20
0
20
40
60
 
 
Dictionary = 2x85 atoms from the training set for each channel 
with  
CR = 5:1   and PRDN_mean  = 41.17 
Dictionary = 2x85 atoms from the training set for each channel 
with  
CR = 10:1 and PRDN_mean  = 55.90 
0
10
20
30
40
50
60
70
25
30
35
40
45
50
55
60
0
10
20
30
40
50
60
70
30
35
40
45
50
55
60
65
70
400
600
800
1000
1200
1400
1600
1800
-60
-40
-20
0
20
40
60
400
600
800
1000
1200
1400
1600
-60
-40
-20
0
20
40
60
 
384
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

VI. 
CONCLUSIONS 
In this paper a comparative analysis of the results 
obtained using three types of dictionaries for EEG signals 
compressed sensing is presented. The used dictionaries are: 
Daubechies 10 wavelet dictionary and two types of EEG 
signal specific dictionaries, namely, temporal EEG signal 
specific dictionary and channel specific dictionary. 
For the evaluation of the proposed method we used the 
dataset from the BCI Competition III 2005 - P300 Spelling. 
In order to evaluate the results of the EEG signal 
reconstruction the PRDN was used in parallel with the 
classification rate of the spelling paradigm assessed using 
the scripts from the winner of the competition (the version 
of classification using all 64 channels). Based on the 
analysis it is found that the worst results are obtained when 
standard wavelet dictionaries were used. The other two EEG 
signal specific dictionaries, lead to better results. Thus, for 
the channel specific dictionaries the best results in terms of 
classification at the spelling paradigm are obtained for CR = 
5:1 and 10:1 when the achieved classification rate was 90%, 
respectively, 89% (for the original signals the classification 
rate was 95%). The temporal EEG signal specific 
dictionaries lead to the best results in terms of error 
expressed as PRDN, i.e. for a compression of 5:1  it was 
obtained a PRDN = 35.38 and for 10: 1 the obtained PRDN 
was 31.42.  
The obtained results demonstrate that channel specific 
dictionaries and temporal EEG signal specific dictionaries 
provide much improved results compared to the standard 
wavelet dictionaries. 
ACKNOWLEDGMENT 
This work was supported by a grant of the Romanian 
National Authority for Scientific Research and Innovation, 
CNCS – UEFISCDI, project number PN-II-RU-TE-2014-4-
0832 “Medical signal processing methods based on 
compressed sensing; applications and their implementation.” 
REFERENCES 
[1] M. A. Davenport, M. F. Duarte, Y. C. Eldar, and G. Kutyniok, 
"Introduction to Compressed Sensing," in Compressed 
Sensing: Theory and Applications, Cambridge University 
Press, 2012. 
[2] D. Donoho, Compressed sensing, IEEE Trans. on Information 
Theory, 52(4) (2006) 1289 – 1306 
[3] D. Donoho, Compressed sensing, Technical Report, Stanford 
Univ., 2004 
[4] E. Candè, M. Wakin, An introduction to compressive 
sampling. (IEEE Signal Processing Magazine 25(2) (2008) 
21-30 
[5] M. Elad, “Optimized Projections for Compressed Sensing”, 
IEEE Transactions on Signal Processing, 2007, Vol. 52 
[6] M. Fira, L. Goras, "A New Method for EEG Compressive 
Sensing," Advances in Electrical and Computer Engineering, 
vol. 12, no. 4, 2012, pp. 71-76 
[7] M. Fira, L. Goras , “Biomedical Signal Compression based on 
Basis Pursuit”, International Conference on Convergence and 
Hybrid Information Technology, ICHIT 2009, in Daejeon, 
Coreea de Sud; 2009,  pag. 541-545 
[8] M. Fira, L. Goras, “Biomedical Signal Compression based on 
Basis Pursuit”, International Journal of Advanced Science and 
Technology, Science and Engineering Research Support 
Center (SERSC), Vol. 14, pag. 1-14, January 2010, ISSN: 
2005-4238 
[9] A. Rakotomamonjy,  V. Guigue, BCI Competition III: Dataset 
II- Ensemble of SVMs for BCI P300 Speller, IEEE 
Transactions on   Biomedical Engineering,Volume:55,  Issue: 
3, 2008, pp. 1147 – 1154 
[10] B. Blankertz, “BCI competition III webpage.” [Online]. 
Available: 
http://ida.first.fraunhofer.de/projects/bci/competition iii 
[11] L. A. Farwellm E. Donchin, “Talking off the top of your 
head: toward a mental  prothesis utilizing event-related brain 
potentials”, Electroenceph clin Neurophysiol, Vol. 70, 1988, 
pp. 510–523 
385
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

