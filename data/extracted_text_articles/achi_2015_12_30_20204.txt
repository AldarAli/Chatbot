ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2015. ISBN: 978-1-61208-382-7
224
Two Dimensional Shapes for Emotional Interfaces:
Assessing the Inﬂuence of Angles, Curvature, Symmetry and Movement
Daniel Pacheco
Laboratory of Synthetic Perceptive,
Emotive and Cognitive Systems.
(SPECS) Universitat Pompeu Fabra.
Roc Boronat, 138. 08018
Barcelona, Spain.
Email: dapachec@gmail.com
Sylvain Le Groux
Department of Psychology
Stanford University
450 Serra Mall Stanford, CA 94305
Paul F.M.J. Verschure
Laboratory of Synthetic Perceptive,
Emotive and Cognitive Systems.
(SPECS) Universitat Pompeu Fabra.
Institució Catalana de Recerca
i Estudis Avançats (ICREA)
Barcelona, Spain
Abstract—Recent investigations aiming to identify which are
the most inﬂuential parameters of graphical representations on
human emotion have presented mixed results. In this study, we
manipulated four emotionally relevant geometric and kinematic
characteristics of non symbolic bidimensional shapes and anima-
tions, and evaluated their speciﬁc inﬂuence in the affective state of
human observers. The controlled modiﬁcation of basic geometric
and cinematic features of such shapes (i.e., angles, curvature,
symmetry and motion) led to the generation of a variety of forms
and animations that elicited signiﬁcantly different self-reported
affective states in the axes of valence and arousal. Curved shapes
evoked more positive and less arousing emotional states than
edgy shapes, while ﬁgures translating slowly were perceived as
less arousing and more positive than those translating fast. In
addition, we found signiﬁcant interactions between angles and
curvature factors both in the valence and the arousal scales.
Our results constitute a direct proof of the efﬁcacy of abstract,
non-symbolic shapes and animations to evoke emotion in a
parameterized way, and can be generalized for the development
of real-time, emotionally aware user interfaces.
Keywords–Affective Computing; Emotional interfaces; Graphi-
cal User Interfaces; Emotional Design; Expressive Interfaces.
I.
INTRODUCTION
In the recent years, several efforts have been made in the
ﬁeld of Human Computer Interaction (HCI) to design and
implement computer systems that can recognize and express
emotion. A number of models have been developed to interpret
physiological measurements [1], or behavioural records of
body and facial expression in real time [2], and today, reliable
ways of monitoring users emotions are being incorporated in
commercial systems, such as Microsoft Kinect. On the other
hand, models for the expression of emotion — which are
usually based on psychological research — have been shown to
coherently convey emotion to humans by manipulating human-
like or anthropomorphic emotional stimuli. Speciﬁcally in the
ﬁeld of Computer Graphics, models for the synthetic expres-
sion of emotion using Computer Generated Imagery (CGI)
have traditionally involved the use of so called avatars, i.e.,
virtual characters that simulate human facial expression [3][4],
or body movement [5][6], to express a particular emotion
explicitly (for a review see [7]).
However, it is well known that humans not only respond
to human-like or symbolic emotional stimuli. In the literature
on music and emotion, for instance, it has been shown that
musical parameters such as tempo, pitch or tonality may
profoundly affect a person’s affective state [8][9][10]. Since
most of the interactive systems with which we interact today
present bidimensional user interfaces that are non-symbolic /
non-anthropomorphic, it is relevant to identify what are the
most important graphical parameters of emotion in simple
forms and animations that can be used to generate such
interfaces. Furthermore, the advent of new communication
technologies allows today for the real time generation of
highly parameterized CGI which offers great possibilities for
the design and implementation of emotionally aware user
interfaces. How can we identify the geometrical and cinematic
properties of 2D shapes and animations that have more impact
on emotion, and make use of this knowledge in the design of
affective HCI systems?
Based on literature presented in Section II, we deﬁned an
experimental setup to investigate this question by assessing the
inﬂuence of four speciﬁc graphical parameters of shapes and
animations on emotion: angles, curvature, symmetry and speed
of movement (Section III). Our results show that it is pos-
sible to experimentally induce emotional states in controlled
environments by parametrically tampering these geometric and
kinematic characteristics. The speciﬁc impact of each one of
them is discussed in Section IV. In Section V, we present our
conclusions and future work.
II.
SHAPE, MOVEMENT AND EMOTION
A. Shape
The relationship between non symbolic graphic features
and emotion has been studied from different perspectives. One
approach mostly adopted in the Image Retrieval ﬁeld has been
to study global image features and assess their effectiveness
in conveying speciﬁc emotions. Several parameters of color
(i.e., hue, brightness or saturation [11]), and textures (i.e.,
coarseness, contrast and directionality [12]), have been shown
to inﬂuence the affective states of human observers. Similar
parameters have been identiﬁed in saliency-based visual mod-
els (i.e., colour, intensity, orientation and symmetry [13][14])
which can predict human ﬁxations, although, to our knowl-
edge, the relationship between saliency and emotion models
has not been studied.

ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2015. ISBN: 978-1-61208-382-7
225
A problem with the study of complex images and global
features is the great amount of dimensions in which such
stimuli can be parameterized. Real images usually involve
semantic components that can be highly inﬂuential on human
emotion. Traditional databases for emotion induction, such
as the International Affective Picture System (IAPS) [15] do
not differentiate between symbolic and non symbolic emotion
determinants, which makes them not suitable to assess the
speciﬁc role of these two key elements. Some efforts, however,
have been made to achieve this goal [16].
A different approach has been taken in the ﬁeld of visual
perception, where the synthetic generation of visual stimuli has
been adopted in early studies. The seminal work of Attneave
with bidimensional abstract shapes already showed that the
parametric variation in basic geometric characteristics of such
ﬁgures — number of turns in the contour, symmetry and angles
— evoked completely different subjective judgements about
their “complexity" [17][18].
A complexity scale was also used to rate shapes in [19]
and [20], although the concept was deﬁned in different ways
— reproduction performance for the former and difﬁculty in
providing a verbal description of an image for the latter. The
variables that were considered more inﬂuential on the per-
ceived complexity of a shape in both studies were orientation,
repetitiveness and variance in interior angles.
Can such parameters be inﬂuential on emotion? The lit-
erature on the topic is sparse. Some studies have shown that
curved shapes are better in portraying emotion than shapes
composed by straight lines [21], and that features such as
angles ratio, curvature and symmetry [22][23], can predict
the emotion induced by speciﬁc 3D shapes. Other studies
have proposed that the perceived emotion of abstract ﬁgures
is determined by internal dynamics such as the subjectively
judged “instability" of a ﬁgure. The intensity of emotions that
can be ascribed to the ﬁgures is correlated with their perceived
instability, which is deﬁned by the ﬁgure orientation with
respect to a predeﬁned ground [24].
B. Movement
The relevance of movement in the expression of emotion
has been highlighted in several studies, most of which have
focused in human — or anthropomorphic — body motion. It
has been argued that exaggerated corporal motion enables the
recognition of the intensity of the affective states that can be
attributed to body postures, and that parameters that deﬁne a
speciﬁc body conﬁguration can be correlated with the emotion
attributed to it [6]. Moreover, it has been shown that speed
and spatial amplitude play a fundamental role in emotional
perception of human-like body movement [25]. Several studies
on human body motion using point lights show that perceivers
are able to infer emotions reliably and easily basing their
judgments solely on the dynamic patterns of actions [26][27].
Abstract motion has also been studied, but in the same
way that abstract ﬁgures have captured less attention than
ﬁgurative graphical representations, the inﬂuence of non-
articulated motion on human perception is less understood than
its symbolic counterpart. Early studies already showed that
emotional descriptions can be attributed to abstract ﬁgures that
move in a non articulated, non anthropomorphic way [28][29].
In the same line, it has been suggested that the perception
of animacy of a shape can be predicted by the magnitude of
the speed change and the change of direction measured in
angles [30][31] among other parameters. What are the features
of abstract movement that most inﬂuence emotion? Density
(animated notches of the contour), strength (amplitude in the
deformation or translation), and speed were described as the
most determinant factors of the emotion elicited by abstract
shapes [25]. On the other hand, speed in the motion of abstract
patterns has been shown to be highly inﬂuential on human
emotion and behaviour in a mixed reality setup [32].
III.
METHODS
A. Description
The methodology and overall design of our experiment was
based on a previous study conducted in our laboratory [33].
Different visual samples varying among two visual deter-
minants of emotion (shape and movement) were presented
to the participants. The morphological features that were
considered — lines/curves ratio, acute/obtuse angles ratio,
and symmetry — were extracted from [22] and [23], and
adapted to our speciﬁc setup. Such parameters were the only
geometrical features of shapes studied with respect to emotion
that we found in the literature. Each one of these geometrical
parameters was tested at three different levels of movement:
low, medium and high (L/M/H). In total, 81 animations were
rendered (i.e., 27 shapes at 3 different levels of movement
each). The parameters that were manipulated are described in
the following paragraphs.
1) Lines/Curves ratio: The Lines/Curves ratio (LCR) was
calculated according to the following formula:
LCR =
Lines
Curves + Lines
(1)
A low LCR was considered under 1
3, medium between 1
3
and 2
3 and high between 2
3 and 1.
2) Acute/Obtuse angles ratio: The Acute/Obtuse angles ra-
tio (AOAR) was calculated according to the following formula:
AOAR =
Acute angles
Acute angles + Obtuse angles
(2)
A low AOAR was considered under 1
3, a medium AOAR
between 1
3 and 2
3 and a high AOAR between 2
3 and 1. AOAR
was also considered for curved shapes by counting the angles
formed by correspondent tangents of adjacent curves. Reﬂex
angles (between 180 and 360 degrees), were not considered in
the equation.
3) Simmetry: Symmetry (SYM) was considered in 2 axes.
A symmetrical ﬁgure among two axes was given a high level of
symmetry; a symmetrical ﬁgure among one axe was considered
at a medium level of symmetry, and a non symmetric ﬁgure
was given a low level of symmetry.
4) Movement: All shapes were rendered in three different
levels of movement (MOV): low, medium, high. In the low
level, the image of the shape was rendered statically. In the
medium and high level, movement was produced by translating
the shape in pseudo-random directions, determined by a perlin
noise algorithm. In the medium level, the range of translation
was set to 5 VR units and the speed of translation of the
algorithm set to 1. In the high level of movement, the range
of movement was also 5, but the speed of translation was 5
times faster than the medium level.

ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2015. ISBN: 978-1-61208-382-7
226
5) Examples: A circle has a high symmetry, low lines
curves ratio, and low acute obtuse angles ratio. An example of
a ﬁgure that has high symmetry, high LCR and high AOAR is
a star (for more examples see Figure 1).
Figure 1. Abstract shapes used in our experiment. Left: high AOAR, low
SYM and low LCR. Center: high AOAR, high LCR, high SYM. Right: high
AOAR, medium LCR and low SYM.
B. Experimental Procedure
Our experimental design included four independent vari-
ables (LCR, AOAR, SYM, MOV) with three levels each (Low,
Medium, High), and two dependent variables (arousal, valence)
— the participants ratings in a nine points self-assessment
scale (the self-assessment manikin [34], based in Rusell’s
circumplex model of emotions [35]).
Stimuli were presented in a randomized order. After eight
seconds of exposure, participants were asked to rate the shape
in the SAM scale while the stimulus remained visible. Precise
instructions were given to them in order to assess their emo-
tional states as it was at the moment of exposure. After the self-
assessment has been achieved, an in-between period of eight
seconds with no visual stimulation (black screen) preceded the
next trial. Exposure time was made two seconds longer than
the original self assessment study conducted with images [34]
to allow a good exposure to moving images (animations). An
application was developed for the generation and rendering
of the stimuli and the online recording of the participant’s
responses using the Unity3D Game Engine.
C. Participants
A total of 12 university students (5 women, MAge =
28.333, range = 22-39) participated in the experiment. All of
them had normal or corrected-to-normal vision.
IV.
RESULTS
A. Graphic representations
We carried a Two-Way Repeated Measure Multivariate
Analysis of Variance (MANOVA), followed by univariate
analysis and post hocs. Kolmogorov-Smirnov and Shapiro
Wilk tests showed that the data was not normally distributed in
valence and arousal scales; therefore, we run Kruskal-Wallis
tests in the univariate analysis to verify the results.
1) Valence: In the valence scale, shapes composed mostly
by curves were perceived signiﬁcantly more positively than
shapes composed by similar numbers of lines and curves.
Shapes composed mostly by curves were also perceived more
positively than shapes composed mostly by lines, although
this difference was not signiﬁcant. The analysis showed a
signiﬁcant multivariate effect for LCR F(2, 9) (p < 0.05).
Follow-up univariate analysis revealed an effect of LCR on
valence F(1.322,26,717) = 6.882 (p < 0.05). Mauchly tests
Figure 2. A ﬁgure composed mostly with curves is perceived signiﬁcantly
more positive than a ﬁgure composed by curves and lines.
indicated that the assumption of sphericity was not met. Hence
we corrected the F-ratios with Greenhouse-Geisser. A post-
hoc pairwise comparison with Bonferroni correction showed
a signiﬁcant mean difference of 0.4527 between Low and
Medium LCR on the valence scale (Figure 2).
Besides, a signiﬁcant interaction was found between AOAR
and LCR for valence F(4, 40) = 6,444 (p < 0.05), suggesting
than shapes composed mostly by acute angles — e.g., a star
— are perceived more positive when they are also composed
by straight lines. The analysis on valence also revealed a
signiﬁcant interaction effect in the multivariate analysis for
the AOAR*SYM interaction F(4,7) (p < 0.05), and for the
LCR*SYM interaction F(4, 7) (p < 0.05). When a shape
is symmetrical in two axes, the presence of acute angles is
perceived more positive. On the other hand, when the ﬁgure
is asymmetrical, it will be perceived as more positive if it is
composed mostly by curves.
2) Arousal: In the arousal Scale, the only signiﬁcant mul-
tivariate effect was found for the interaction between LCR and
AOAR F(4, 7) (p < 0.05), and univariate analysis conﬁrmed
this result F(4, 40) = 4.694 (p < 0.05). When a shape has High
AOAR, it tends to be perceived as more arousing if it also has
a high LCR.
B. Movement
1) Valence: No signiﬁcant multivariate effect was found
for movement on valence. However, inﬂuence of movement on
valence was reported by univariate analysis F(1.633,143.265)
= 5.969 (p < 0.05) (Figure 3).
A post-hoc pairwise comparison with Bonferroni correction
showed a signiﬁcant mean difference of -1.1023 between
Medium and High. Therefore, ﬁgures that moved slowly were
perceived as signiﬁcantly more positive that ﬁgures translating
fast.

ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2015. ISBN: 978-1-61208-382-7
227
Figure 3. Different kinds of movement elicited different reports in the
valence scale. Fast moving shapes were considered signiﬁcantly less positive
than shapes that moved slow and non-moving shapes.
2) Arousal: Movement was found to be highly inﬂuential in
on arousal. Moving shapes were perceived signiﬁcantly more
arousing than non-moving shapes, and fast-moving ﬁgures
were reported to be signiﬁcantly more arousing than slowly-
moving ﬁgures (Figure 4). The analysis showed a signiﬁcant
multivariate effect for movement F(2, 9) (p < 0.05) on arousal.
Mauchly tests indicated that the assumption of sphericity
was met. Therefore, we did not correct the F-ratios for the
following ANOVAS. Follow-up univariate analysis revealed an
effect of movement F(1.112, 1232.994) = 20.715 (p < 0.05)
on arousal. A post-hoc pairwise comparison with Bonferroni
correction showed a signiﬁcant mean difference of -0.9195
between Low and Medium movement, of -2.0231 between
Medium and High movement, and of -2.9427 between Low and
High movement (Figure 4). In our design, Low was deﬁned
as absence of movement, and Medium and High were deﬁned
as different levels of speed in random translation.
V.
CONCLUSIONS
Abstract shapes and animations varying among four emo-
tionally relevant graphical parameters (i.e., proportion of lines
and curves, proportion of acute and obtuse angles, symmetry
and movement), were presented to the participants of our
experiment and the correspondent emotional responses were
recorded using self-reports based in the circumplex model of
affect. Our results show that the manipulation of such low level
graphical parameters evoked different affective states in our
participants, and that some of them (i.e., LCR and movement)
had a speciﬁc inﬂuence in the valence and arousal scales. In
some cases, the interaction between parameters was signiﬁcant
(e.g., for curvature and angles in both the valence and arousal
scales). Our results are a contribution to the understanding
of the role that basic geometric characteristics of abstract,
bidimensional shapes play on human emotion, and may be
Figure 4. Movement signiﬁcanlty affected the participants reports in the
arousal scale. Fast moving shapes were considered signiﬁcantly more
arousing than shapes that moved slow and non-moving shapes.
useful for developers and designers wishing to develop and
implement emotional user interfaces.
We speculate that the manipulation of these parameters in
real time and in less controlled experimental conditions will
coherently inﬂuence the affective states of humans observers in
a similar manner than observed in our experiment, and plan to
reformulate our experimental design in order to include the real
time generation of the stimuli from the identiﬁed parameters.
We also plan to include more objective measurements of
emotion such physiological records — i.e., Electrodermal
Activity, Hear Rate, Respiration —, as a complement to the
self-assessment responses. Such physiological data could be
used in a second stage as an input to the system, allowing for
the controlled generation of the stimuli depending on the users
emotional states, and the development of more sophisticated,
emotionally aware user interfaces.
VI.
ACKNOWLEDGEMENTS
This research received funding from the European Com-
munity’s Seventh Framework Programme (FP7-ICT-2009-5)
under grant agreement n. 258749 [CEEDS].
REFERENCES
[1]
Z. Zeng, M. Pantic, G. I. Roisman, and T. S. Huang, “A survey of affect
recognition methods: Audio, visual, and spontaneous expressions,” Pat-
tern Analysis and Machine Intelligence, IEEE Transactions on, vol. 31,
no. 1, 2009, pp. 39–58.
[2]
M. Thrasher, M. D. Van der Zwaag, N. Bianchi-Berthouze, and J. H.
Westerink, “Mood recognition based on upper body posture and move-
ment features,” in Affective Computing and Intelligent Interaction.
Springer, 2011, pp. 377–386.
[3]
P. Weyers, A. Mühlberger, C. Hefele, and P. Pauli, “Electromyographic
responses to static and dynamic avatar emotional facial expressions,”
Psychophysiology, vol. 43, no. 5, 2006, pp. 450–453.

ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2015. ISBN: 978-1-61208-382-7
228
[4]
A. Tinwell, M. Grimshaw, D. A. Nabi, and A. Williams, “Facial
expression of emotion and perception of the uncanny valley in virtual
characters,” Computers in Human Behavior, vol. 27, no. 2, 2011, pp.
741–749.
[5]
M. Fabri, D. J. Moore, and D. J. Hobbs, “The emotional avatar:
non-verbal communication between inhabitants of collaborative virtual
environments,” in Gesture-Based Communication in Human-Computer
Interaction.
Springer, 1999, pp. 269–273.
[6]
M. Inderbitzin, A. Valjamae, J. M. B. Calvo, P. F. Verschure, and
U. Bernardet, “Expression of emotional states during locomotion based
on canonical parameters,” in Automatic Face & Gesture Recognition
and Workshops (FG 2011), 2011 IEEE International Conference on.
IEEE, 2011, pp. 809–814.
[7]
V. Vinayagamoorthy, M. Gillies, A. Steed, E. Tanguy, X. Pan, C. Loscos,
M. Slater et al., “Building expression into virtual characters,” 2006.
[8]
L.-L. Balkwill and W. F. Thompson, “A cross-cultural investigation of
the perception of emotion in music: Psychophysical and cultural cues,”
Music perception, 1999, pp. 43–64.
[9]
P. N. Juslin and J. A. Sloboda, Music and emotion: Theory and research.
Oxford University Press, 2001.
[10]
A. Goldstein, “Thrills in response to music and other stimuli.” Physio-
logical Psychology, 1980.
[11]
P. Valdez and A. Mehrabian, “Effects of color on emotions.” Journal of
Experimental Psychology: General, vol. 123, no. 4, 1994, p. 394.
[12]
H. Tamura, S. Mori, and T. Yamawaki, “Textural features corresponding
to visual perception,” Systems, Man and Cybernetics, IEEE Transac-
tions on, vol. 8, no. 6, 1978, pp. 460–473.
[13]
G. Kootstra, A. Nederveen, and B. De Boer, “Paying attention to
symmetry,” in Proceedings of the British Machine Vision Conference
(BMVC2008).
The British Machine Vision Association and Society
for Pattern Recognition, 2008, pp. 1115–1125.
[14]
L. Itti, C. Koch, and E. Niebur, “A model of saliency-based visual
attention for rapid scene analysis,” Pattern Analysis and Machine
Intelligence, IEEE Transactions on, vol. 20, no. 11, 1998, pp. 1254–
1259.
[15]
P. J. Lang, M. M. Bradley, and B. N. Cuthbert, “International affective
picture system (iaps): Technical manual and affective ratings,” 1999.
[16]
N. Liu, E. Dellandréa, B. Tellez, and L. Chen, “Associating textual
features with visual ones to improve affective image classiﬁcation,” in
Affective Computing and Intelligent Interaction.
Springer, 2011, pp.
195–204.
[17]
F. Attneave, “Some informational aspects of visual perception.” Psy-
chological review, vol. 61, no. 3, 1954, p. 183.
[18]
F. Attneave, “Physical determinants of the judged complexity of
shapes.” Journal of Experimental Psychology, vol. 53, no. 4, 1957, p.
221.
[19]
C. M. Mavrides and D. Brown, “Discrimination and reproduction of
patterns: Feature measures and constraint redundancy as predictors,”
Perception & Psychophysics, vol. 6, no. 5, 1969, pp. 276–280.
[20]
C. Heaps and S. Handel, “Similarity and features of natural textures.”
Journal of Experimental Psychology: Human Perception and Perfor-
mance, vol. 25, no. 2, 1999, p. 299.
[21]
R. Hiraga, “Emotion recognition in polygons and curved shapes,”
in Systems, Man, and Cybernetics (SMC), 2011 IEEE International
Conference on.
IEEE, 2011, pp. 3286–3291.
[22]
S. Achiche and S. Ahmed, “Mapping shape geometry and emotions
using fuzzy logic,” in Proceedings of IDETC/CIE, 2008.
[23]
S. Achiche and S. Ahmed-Kristensen, “Genetic fuzzy modeling of
user perception of three-dimensional shapes,” Artiﬁcial Intelligence for
Engineering Design, Analysis and Manufacturing, vol. 25, no. 1, 2011,
pp. 93–107.
[24]
M. Pavlova and A. Sokolov, “Perceived dynamics of static images
enables emotional attribution,” Perception-London, vol. 34, no. 9, 2005,
p. 1107.
[25]
K. Amaya, A. Bruderlin, and T. Calvert, “Emotion from motion,” in
Graphics interface, vol. 96.
Citeseer, 1996, pp. 222–229.
[26]
A. P. Atkinson, W. H. Dittrich, A. J. Gemmell, A. W. Young et al.,
“Emotion perception from dynamic and static body expressions in point-
light and full-light displays,” PERCEPTION-LONDON, vol. 33, 2004,
pp. 717–746.
[27]
W. H. Dittrich, T. Troscianko, S. E. Lea, and D. Morgan, “Perception
of emotion from dynamic point-light displays represented in dance,”
Perception-London, vol. 25, no. 6, 1996, pp. 727–738.
[28]
F. Heider and M. Simmel, “An experimental study of apparent behav-
ior,” The American Journal of Psychology, vol. 57, no. 2, 1944, pp.
243–259.
[29]
A. Michotte, “The perception of causality.” 1963.
[30]
P. D. Tremoulet, J. Feldman et al., “Perception of animacy from the
motion of a single object,” PERCEPTION-LONDON-, vol. 29, no. 8,
2000, pp. 943–952.
[31]
B. J. Scholl and P. D. Tremoulet, “Perceptual causality and animacy,”
Trends in cognitive sciences, vol. 4, no. 8, 2000, pp. 299–309.
[32]
A. Betella, M. Inderbitzin, U. Bernardet, and P. F. Verschure, “Non-
anthropomorphic expression of affective states through parametrized
abstract motifs,” in Affective Computing and Intelligent Interaction
(ACII), 2013 Humaine Association Conference on.
IEEE, 2013, pp.
435–441.
[33]
S. Le Groux and P. F. Verschure, “Subjective emotional responses
to musical structure, expression and timbre features: A synthetic ap-
proach,” 9th International Symposium on Computer Music Modelling
and Retrieval (CMMR), 2012.
[34]
M. M. Bradley and P. J. Lang, “Measuring emotion: the self-assessment
manikin and the semantic differential,” Journal of behavior therapy and
experimental psychiatry, vol. 25, no. 1, 1994, pp. 49–59.
[35]
J. A. Russell, “A circumplex model of affect.” Journal of personality
and social psychology, vol. 39, no. 6, 1980, p. 1161.

