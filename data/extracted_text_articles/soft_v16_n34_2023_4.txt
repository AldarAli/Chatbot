A UAV Based System for Real-Time Near-Infrared Monitoring of Small-Scale 
Wildfires 
 
Edwin Magidimisha 
 Optronic Sensor Systems, Defence and Security, 
Council for Scientific and Industrial Research 
 Pretoria, South Africa 
 e-mail: emagidimisha@csir.co.za 
 
Seelen Naidoo 
  e-mail: snaidoo7@csir.co.za 
 
Zimbini Faniso-Mnyaka 
e-mail:zfaniso@csir.co.za  
 
 
 
Muhammad Ahmed Nana  
e-mail: mnana@csir.co.za 
 
Shrikant Virendra Naidoo 
e-mail: svnaidoo@csir.co.za 
 
Vusi Skosana 
e-mail: vskosana@csir.co.za
 
 
 
 
Abstract‚ÄîWildfires are a global threat that is becoming more 
severe and widespread due to climate change. These fires not 
only pose a significant risk to human life, firefighters, and 
infrastructure, but also endanger forest resources, increase 
greenhouse gas emissions, and cause huge economic losses. 
Several researchers have been working to find dedicated 
solutions for early wildfire detection, tracking, and firefighting 
assistance. Traditional methods of fire detection have mainly 
been from fire lookouts in towers, infrared sensors on elevated 
platforms, surveillance of fires from aircraft, and remote 
sensing from satellites. Although these techniques have been 
proven to work in other areas, they are unsuitable or are limited 
in performance due to various reasons, e.g., human accuracy, 
sensor field of view limiting coverage to smaller areas, sensor 
cost-effectiveness, and re-visit time on a satellite. To counteract 
the problem, a real-time wildfire monitoring system that can 
detect small-scale wildfire events and that can be used for 
tactical forest firefighting operations is proposed. The concept 
takes advantage of vegetation biomass combustion by-products 
such as the alkali element Potassium (K) that is emitted at the 
flaming phase of the fire. The technique is specific to the flaming 
phase of the fire and is not affected by the fire size. It employs 
two high-resolution, cost-effective complementary metal-oxide-
semiconductors (CMOS) with high quantum efficiency within 
the near-infrared (NIR) spectrum. The sensor uses ultra-
narrow-band filtering and target-to-background rationing 
techniques for the detection of vegetation fires. The system is 
designed to be self-contained, having its supporting power, 
compact, and lightweight for easy integration on different types 
and sizes of unmanned aerial vehicles (UAV) to provide real-
time detection and support to firefighters while airborne. UAVs 
can provide a low-cost alternative for the reduction of fire 
disasters through early detection, reporting, and real-time 
support for firefighters. This paper presents the experimental 
results of an NIR optical sensor mounted on a UAV carrier that 
was used to collect data while flying at low to 200m above 
ground at the Centurion Grassland Flying Club. The results 
provide evidence of the presence of K in small-scale actively 
burning vegetation fires observed at different angles and 
detectable from a UAV. The results support the use of NIR 
sensor payload for the detection of small-scale fires from a UAV 
platform. 
Keywords - Climate; CMOS; Near-infrared; Potassium (K); UAV; 
Wildfires. 
I. 
INTRODUCTION  
The fire incidences and severity are expected to increase 
in response to climate change [1, 2, 3, 4]. Fire prevention, 
detection, monitoring, and suppression of wildland vegetation 
are key economic and public safety concerns in many parts of 
the world [5]. These wildfires further exacerbate climate 
change due to CO2 and black aerosol emissions. This serves 
as a strong motivation for the development of an optical 
surveillance system that can detect and monitor wildfires on a 
small scale. Classical remote sensing of vegetation fires has 
been through the detection of Planckian emission in the 
medium wave infrared (3-5 ¬µm, MWIR) and the long-wave 
infrared (LWIR) band of the electromagnetic spectrum 
[6,7,8]. The short wave (1 ‚Äì 2.5¬µm, SWIR) infrared band was 
exploited and deployed on the Airborne Visible Infrared 
Imaging Spectrometer (AVIRIS) platform [9] for the 
detection of wildfires. IR-based systems, whether cooled or 
uncooled, can be costly and significantly affected by other 
heat-emitting sources, leading to clutter or false alarms [10]. 
 
With the advancements in passive imaging sensors and 
filter technologies, reliable commercial-off-the-shelf (COTS) 
products are now available and more affordable. New sensor 
technologies such as high-resolution charge-coupled device 
(CCD) and complementary metal-oxide-semiconductor 
(CMOS) sensors provide an opportunity to enhance wildfire 
detection, monitoring, and reporting. As an alternative to other 
fire detection techniques, this study proposes the use of a 
compact and cost-effective system for the detection of 
wildland vegetation fires by observation of the Potassium (K) 
spectral line. An initial concept study was performed to 
characterise the various vegetation species inside and outside 
the laboratory at the Council for Scientific and Industrial 
Research (CSIR) campus in Pretoria [11]. The study was 
made to ensure the relevance of the concept to local conditions 
by investigating the use of atomic lines emission lines in 
172
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

burning South African vegetation. Vegetation plant species 
contain a series of trace elements (Na, K, Mg) that present 
unique narrowband spectral emission lines in the visible and 
near-infrared (NIR) wavelength range when biomass is heated 
to high temperatures during the combustion process [12]. 
Potassium spectral lines can be discriminated against any 
other background by detector systems that are less costly than 
the longer wavelength, actively cooled instruments most used 
in Earth Observation (EO) systems [12]. The K spectral line 
doublet located within the NIR at 766.5 and 769.9 nm is of 
particular interest for this application [10,17,19,20]. The 
current study integrates the NIR optical payload and operates 
it from an unmanned aerial vehicle (UAV) using remote 
sensing techniques. 
II. 
BACKGROUND 
In recent years, we have seen great progress in the use of 
UAVs with advanced software for forest fire monitoring, 
detection, and firefighting. Integration of UAVs with remote 
sensing techniques aims to provide rapid, mobile, low-cost, 
and powerful solutions for various fire tasks [13]. Firefighting 
agencies typically use fixed detection platforms such as 
towers, aerial patrols, and satellite imagery to directly detect 
forest fires, rather than relying on reports from the public. 
However, high-elevation platforms are not well suited for area 
coverage and can result in some areas developing fires 
unnoticed. Although aircraft are considered efficient in 
firefighting, they are expensive to keep airborne for constant 
monitoring. Compared to fixed ground-based wildfire 
detection systems, UAVs can provide a broader and more 
accurate perception of fire from above, especially in areas that 
are inaccessible or considered too dangerous for firefighting 
crews. During firefighting, UAVs provide eyes from above, 
operators can use them from a safe place and can provide 
important information on the progression of the fire. 
 
In [14], a vision-based UAV-mounted system for the 
detection of forest fires that uses both the motion and the 
chroma characteristics of the fires was proposed. The two 
characteristics were used for the decision rules to improve the 
reliability and accuracy of fire detection. A method to detect 
forest fires using a UAV equipped with an optical and an 
infrared (IR) camera has been proposed [15]. The method uses 
a LAB colour model and a motion-based algorithm, followed 
by a maximally stable extremal region (MSER) extraction 
module. For better visualisation, forest fire detections were 
combined with landscape information and meteorological 
data. In a study in [16], a convolutional neural network (CNN) 
model was trained using optical and infrared sensor data to 
detect smoke and fire. 
III. 
DETECTION PRINCIPLE 
A simplified schematic of the fire detection principle is 
shown in Figure 1. The figure illustrates a comprehensive 
outline of the fire detection system and the principle of 
operation. The principle relies on the abundant nature of 
Potassium element in vegetation species. The system 
incorporates a dual camera to capture and record images of 
burning biomass fires, specifically vegetation fires containing 
the Potassium element radiometric signature. One of the 
sensors is optimized for the detection of the K-line and the 
other for the detection of the background. The captured 
images are processed using the in-house developed CSIR 
algorithm applied during the image processing stage to 
analyse the pair of images and establish whether a fire has 
been detected.  
 
 
Figure 1: Simplified schematic depicting the overview of the fire detection 
system. 
 
A. The Potassium Element  
      Potassium belongs to the alkali metal group and is in the 
first column of the periodic table. It is one of the most 
abundant elements in vegetation species [17, 18]. It has a 
single valence electron that presents unique narrowband 
spectral emission lines within the visible and NIR wavelength 
range when biomass is heated to high temperatures in the 
flaming phase of the fire [19]. The spectral emission of K 
appears as a doublet at the 766.5 nm and 769.9 nm spectral 
bands [20].  With advances in optical filter design, filters can 
now detect low-level signals while suppressing almost all 
emissions within the outer band by targeting specific 
elemental emissions from a source signature. These advances 
in technology open the door for the development of compact 
sensors capable of detecting narrow spectral lines that can be 
advanced to compete with other passive sensors operating in 
other bands. In this study, ultra-narrow band imaging is used 
for the detection of K using CMOS detectors. The integration 
of COTS, and ultra-narrow band imaging allows the design 
of compact and less power-hungry systems, which can be 
easily integrated on a weight, size, and energy-constrained 
UAV platform. The CSIR-designed payload weighs 1.8 kg 
including power support. 
 
B. Fire detection system 
A detailed description of the current and futuristic 
practices in the context of fire detection and monitoring 
strategies is described in a review paper by F. Khan et al. [21]. 
Traditional fire detection mechanisms have been through 
thermal sensors, but other researchers are developing other 
methods to improve the detection and monitoring of fires for 
both indoor and outdoor conditions. There are also two broad 
approaches to fire detection algorithms. The first is using 
machine learning, which is still in its early stages. The second 
is to use colour, form, flicker frequency, and the dynamic 
structure of fire. The fire detection method presented here 
would fall in the second category. Using radiometric 
173
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

principles to separate the background from the target (fire) the 
aspiration is to have a very low false positive rate. 
The NIR fire detection sensor presented in this study is 
made up of two NIR imaging systems placed side-by-side 
with a common (overlapping) field of view (FOV). These 
cameras are fitted with ultranarrow band filters with 1 nm 
bandwidth sensitivity at 769.9 nm, referred to as the K-line 
band, and 757 nm, referred to as the reference band. The target 
and reference channels are temporally synchronised at the 
electronic level so that pairs of images (one from the K-line 
and the other from the reference band) are obtained at the 
same instant. Fires are detected by comparing the K-line 
channel image with the reference channel image. Pixels that 
are much brighter in the target channel relative to the reference 
channel are candidate fire detections.  
C. Image processing algorithm 
       The system‚Äôs image processing begins after the two 
images are captured, the image with K-line emission, and the 
other with the background or reference. The images from the 
two sensors are captured synchronously. The images are not 
modified with any image enhancement algorithm and are not 
compressed to preserve the fire front K-line signal emissions. 
The reference image is resampled to align with the K-line 
image pixels. This is done by mapping and using a Lucas-
Kanada optical flow algorithm [22]. Sections of the individual 
images that are not common in both are then cropped out, 
leaving two images of the exact same scene. The fire detection 
algorithm is applied to the matched cropped K-line and 
reference images. Fire detection is done using the image ratio 
technique [23]. Figure 2 illustrates a block diagram that gives 
an overview of the algorithm. 
 
Figure 2: Overview of the K-line fire detection principle. 
 
The K-line and reference images will have the same 
nominal FOV but will not be pixel-aligned. This is due to the 
following: 
a) The difficulty of perfectly mechanically aligning 
the optical axes and image plane rotations of the 
two channels and 
b) A possible slight mismatch in the effective focal 
length (EFL), which means that the two channels 
will have slightly different image scales and not 
an exact FOV. 
c) Instability of both optical channels due to 
vibrations during flight. 
d) Although the optical systems are identical, there 
will be minor differences in the image sensor and 
lens (which need to be corrected). 
It may not be possible to rely on a fixed relationship 
between the pixels of the reference channel and those of the 
K-line channel from a pre-flight calibration due to the 
instability from vibrations during flight that could shift the 
camera‚Äôs perspectives slightly. Image registration or 
alignment per image pair is performed in the following way: 
 
a) Feature detection is done by obtaining good 
features to track as described in [24]. This is done 
for each image individually, to produce two lists 
of features. 
b) These lists of features are passed to a Lucas-
Kanade optical flow algorithm to find and order 
the features that exist in both images. 
c) The features that do not co-exist in both images 
are pruned and removed from the lists. 
d) The perspective transform between the two lists 
of pruned features is then calculated using the 
RANSAC method [25, 26]. 
e) The reference image is then perspectively 
warped 
using 
the 
previously 
calculated 
perspective transforms. 
The image ratio technique is simple and is implemented as 
follows: 
a) Compute the ratio image, that is, the K-line 
image divided by the reference image. 
 
ùëñùëöùëÖùëéùë°ùëñùëú = ùëñùëöùëòùëôùëñùëõùëí ùëñùëöùëüùëíùëìùëíùëüùëíùëõùëêùëí
‚ÅÑ
 
 
b) Compute the global mean (¬µ) and variance (œÉ) of 
the image ratio. 
c) Compute the variant for each pixel in the ratio 
image as: 
ùúéùëù = ‚àö(ùëù(ùëñ, ùëó) ‚àí ùúá)2 
 
where p is at location (i, j). 
d) If the variance of a pixel is greater than the global 
variance multiplied by a user-defined sensitivity 
integer value i.e., ùúéùëù > ùëòùúé ,the pixel gets 
classified as a fire front pixel.  
e) Otherwise, the pixel is classified as a non-fire 
pixel and is discarded. 
    The result or output of the image ratio technique is a binary 
mask image that has a value of 1 when fire was detected on 
that pixel, and a value of 0 when no fire was present. The mask 
image is then passed onto a simple blob detector [27] to filter 
out any noise or false detections and automatically indicate 
when a fire was detected. Automatic flagging is possible since 
no blobs will be found when there is no fire present. 
 
    The entire image processing process was implemented in 
Python programming language using the OpenCV library. 
174
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

Processing speed can be trivially improved by using the C++ 
or CUDA implementations of the OpenCV library. 
 
IV. 
METHOD 
The field measurements test was conducted on the 18th of 
March 2022 at the Grasslands Flying Club in Pretoria West, 
South Africa. The purpose of the test was to evaluate the aerial 
performance of the NIR optical fire detection sensor onboard 
a UAV. Shown in Figure 3 is a photograph of the NIR imaging 
sensor system during its lab testing phase. 
 
 
Figure 3: A closer look at the NIR sensor with two CMOS optical sensors 
placed side by side and furnished with ultra-narrow filters. A third wide 
field-of-view visible camera is also inserted and placed above the two 
cameras. 
 
The UAV Payload uses a development board (Raspberry 
Pi4 8GB) to control the capturing of images, communication 
with a ground station, and storage of captured images. The 
captured images were stored on board a micro-SD card and 
removed after the completion of a sortie. When the memory 
card is removed from the payload and the data is retrieved for 
archival, the data is inspected while the next mission is 
ongoing. Fire detection is performed on a post-processing 
basis by automatically analysing the images stored in the 
memory card. 
 
The basic NIR sensor payload consists of the following 
components: 
‚Ä¢ 
A processor module with storage 
‚Ä¢ 
the K-line dual camera system, 
‚Ä¢ 
a viewfinder camera, 
‚Ä¢ 
a telemetry radio downlink, 
‚Ä¢ 
an analog video downlink, 
‚Ä¢ 
high-definition video downlink, 
‚Ä¢ 
a power source, and 
‚Ä¢ 
wiring harnesses. 
 
Figure 4 is a representation of the K-line NIR UAV system 
and its supporting systems in the operational environment. 
The list of systems and supporting systems follows with a 
brief description of the context of a typical operational 
scenario. 
 
 
Figure 4: UAV with functional block diagram of the NIR sensor payload 
 
The NIR UAV Payload system (required system) consists 
of the sensor modules, optics, and processing package in a 
configuration that accommodates data logging, transmission, 
and telemetry with the dedicated ground station. The video 
and telemetry transmission links are separate and isolated 
from the UAV's communication and control system. The NIR 
UAV Payload system collectively refers to the physical 
payload packaging, as well as the ground station and the 
communication interfacing modules. The use of the system 
entails the responsibilities of the operator. 
The UAV system (supporting system) refers to the UAV 
airframe (in this instance, a rotary-wing drone) and its gimbal. 
It includes the UAV pilot's ground station (typically mission 
planner / ardu pilot).  UAV control and gimbal control are 
designated responsibilities of the UAV pilot. The experiments 
required coordination between the UAV and payload 
controller personnel.      
 
The payload system operates in a free-running mode that 
is triggered by the ground station operator. In the typical 
context of a fire surveillance exercise for large, restricted areas 
or where accessibility is challenging, a UAV system is ideal 
for creating situational awareness of the fire and its spread.  
The intended mode of operation is illustrated in Figure 5. 
 
The processing module posed significant limitations when 
implementing onboard processing, making the effective 
framerate unusable. More limiting was the thermal impact of 
processing onboard with the processor exceeding its rated 
threshold. For this reason, the ground station triggered a 
recording of relevant data, captured to the storage device. 
Upon the UAV's return to the ground station, the captured data 
was manually retrieved and post-processed on the ground 
station system. The video transmission modules were not 
reliable enough to transmit processable data during flight, 
hence the decision was taken to post-process data in between 
each flight path cycle which for the DJI 600 drone was limited 
to 30 minutes. 
 
A UAV-licensed groundskeeper was tasked to pilot the 
UAV into a strategic position to capture visual data regarding 
the fire. The ground station controller has access to trigger the 
various operational modes of the system. This iteration can 
175
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

trigger free running record modes, swap between video 
transmission feeds, and provide general status feedback and 
control during the flight path. The state mode model of the 
system is illustrated below. 
 
 
Figure 5: Modes of operation for payload 
 
 
Shown in Figure 6 is the NIR fire detection payload 
onboard the UAV taken during the deployment experiment at 
the Grasslands Flying Club. 
 
 
Figure 6: UAV with NIR sensor payload on the DJI 600 drone during a field 
fire detection test of the sensor. 
 
Several sorties were carried out during deployment to test 
the new NIR payload aboard an airborne UAV. The purpose 
of the test was to determine whether the new NIR sensor can 
detect ground wildfires from the air at relatively low altitudes 
(approximately 200 m above ground level) and at different 
aspect angles from the fire. The size of the fire on the ground 
was approximately 500 cm by 500 cm. 
 
The UAV and the Payload systems are completely isolated 
with respect to power distribution and telecommunications, 
with the Payload system including its own battery and 
independent telemetry transceivers. The UAV employs a 
proprietary gimbal (3 degrees of Freedom) with a manual 
rotary clamp system. No adhesives, custom mounting 
brackets, or specialised tools were required for the mechanical 
coupling of the two systems. The following equipment was 
used during the test: 
‚Ä¢ 
M600 UAV with RONIN gimbal provided and 
piloted by UAV Industries (UAVI), 
‚Ä¢ 
UAV NIR Payload sensor, 
‚Ä¢ 
UAV Ground Control Station, 
‚Ä¢ 
FieldSpec 3 Max Analytical Spectral Device (ASD) 
with spectral range 350-2500 nm, 
‚Ä¢ 
Weather Station. 
 
A. Atmospheric Conditions 
During field measurements, the scenario demands that 
atmospheric computations be made to accommodate the 
atmospheric effects, caused by molecular absorption and 
emission (mainly water and CO2, as well as atmospheric 
scattering processes by aerosols). Atmospheric modelling 
codes such as MODTRAN, HITRAN, and others can be used 
to simulate atmospheric transmission as described below. The 
radiative transfer is conducted to confirm the detectability of 
the Potassium lines within the atmosphere.   
 
Atmospheric transmission was calculated using the 
HITRAN Radiation Transfer Model (RTM) in the NIR region, 
as shown in Figure 7. The downloaded HITRAN data were on 
a vacuum scale and converted to air using the Edlen equation 
(NIST). The following parameters were used: 20¬∞C air 
temperature, 101325 Pa air pressure, and 50% humidity [18]. 
The red lines show the K doublet at 766.5 nm and 769.9 nm. 
The 766.5 nm is absorbed by atmospheric Oxygen (O2) 
located at the O2  absorption line and therefore cannot be 
detected remotely. The K emission lines are within the range 
of the sequence of the atmospheric absorption lines that peak 
at about 762 nm [24]. 
 
Figure 7: The high spectral resolution Oxygen atmospheric transmittance 
near the wavelength location of the two Potassium emission spectral lines, 
data from HiTRAN (http://. iao.ru). 
176
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
The positions of the K-lines are indicated by two vertical 
red lines, and the deep lines show the absorption effects 
arising from the atmospheric Oxygen gas. The filter position 
choice of 769.9 nm is based on the transmission data above, 
showing that the 766.5 nm is absorbed by atmospheric 
Oxygen. 
 
B. Field UAV measurement 
 
    The test consisted of a controlled ground fire using wood 
and dried grass as fuel. An analytical spectral device was 
placed on the ground close to the fire (approximately 3 m), 
which was used to record the spectral signature of the fire as 
it burned. It provided reference spectral data of the fire from 
the ground to check whether the NIR signature was contained 
within the fire. The range at which the detection tests were 
conducted was approximately 200 m (radially) from the fire 
over various elevation angles with a centered perspective at 
the burn zone:  
‚Ä¢ 
Test point 1: The elevation angle is 0 degrees, 200 m 
from the burn zone. 
‚Ä¢ 
Test point 2: Elevation angle of 45 degrees, 200 m from 
burn zone. 
‚Ä¢ 
Test point 3: Elevation angle of 90 degrees 
(perpendicular to ground level), 200m from the burn 
zone. 
 
At these test points, the UAV pilot was unable to maintain 
rotation orientation (yaw) for data capture due to wind 
conditions. The position was confirmed through a video 
stream to the ground station with effort placed in centering the 
burn zone in the field of view only. The yaw orientation of the 
sensors had no impact on the detection. These test points 
provided sufficient data to prove the initial success of the fire 
detection system. Results are highlighted in Section V. Figure 
8 provides an illustrative overview of the mission profile test 
points used during the fire detection tests. 
 
 
Figure 8: Illustrative overview of flight mission profiles. 
 
 
C. Hardware Setup 
 
UAV, gimbal and Payload preparations required the UAV 
operator contractor to provide swappable alternating sets of 
UAV batteries for the M600 UAV and their control station. 
The M600 guaranteed a maximum flight time of 30 minutes, 
of which 20 was allocated to the experiment flight paths, the 
alternating battery sets allowed for experiment continuity. 
Similarly, the Payload battery system was designed with two 
sets of alternating batteries to facilitate the same objective 
during the experiment. The payload ground station consisted 
of two laptops in a ruggedized case requiring two operators, 
viz: a gimbal operator (laptop 1), and a Payload operator 
(laptop 2). The experimental hardware configuration for the 
experiment is illustrated in Figure 9 below. 
 
Figure 9: Experimental hardware configuration setup. 
 
V. 
RESULTS 
     In this section, the results obtained from the field 
measurements detection tests, which encompass data 
collected through both UAV NIR image sensors and spectral 
measurements recorded by the ASD spectroradiometer, are 
presented. 
A. UAV NIR image sensor data 
When examining the results derived from the UAV NIR 
image sensors, we display them in pairs for clarity. The image 
on the left represents the masked image, while the image on 
the right image showcases the target image, which exhibits the 
distinctive K-line emission signature. Following the 
application of image processing techniques, the K-line 
signature is highlighted in red as an overlay, while the black 
and white target image emphasizes the masking process, 
effectively isolating the K-line signature. 
 
177
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

B. ASD FieldSpec 3 Spectroradiometer Data 
The ASD collects a spectrum covering a broad wavelength 
region (350 nm to 2400 nm) almost instantaneously and has 
an absolute radiance calibration traceable to NIST. The ASD 
FieldSpec 3 spectroradiometer data is presented in groups of 
three images. The top image zooms in on the K-line doublet, 
offering a detailed view. The image in the middle displays 
zoomed spectra of several instances of the fire captured at 
different times, the third figure is a complete spectral image 
of the fire across the 350-2500 nm spectral band. In these 
figures, the emission spectrum of the fire becomes 
prominently visible, with the spectral radiance generally 
increasing with wavelength. It is clear from the results that the 
resolution of the ASD is too low and was unable to resolve the 
K-line doublet. 
 
    For this deployment, we conducted controlled burns of 
dried grass to capture both NIR images from the UAV and 
spectroradiometer data from the ASD FieldSpec 3. These 
results contribute to a comprehensive understanding of fire 
detection mechanisms, spectral signatures, and atomic 
compositions. Various flight profiles were flown to test the 
sensor performance at different angles as shared below.  
 
C. Test Point 1:0 Degree Aspect Angle Fire Detection 
The image below shows the setup of the NIR imaging 
sensor at zero degrees relative to the fire. 
 
 
Figure 10: Illustration of the drone viewing the fire at 0 degrees. 
 
    The sensor was able to detect fire from an angle (in this 
scenario, the angle 0¬∞ is used). The images were captured 
while the drone was at 0¬∞, as shown in the image Figure 10. 
 
 
              (a)                                                (b) 
Figure 11: NIR sensor images during the lower angle of 0 degrees detection. 
 
The sensor images are as shown above. On Figure 11(a), is the 
masked image and on the right, Figure 11(b) is the detection 
image showing the K-line detections in red.    
 
(a) 
 
(b) 
 
 
Figure 12: ASD spectral data with NIR-zoomed K-line doublet (a) and (b) 
and (c) is the full spectral set of the measurements. The Figure shows the 
spectral radiance of the fire within the NIR region. 
 
The NIR signature was successfully detected in its entirety by 
the ASD spectral sensor, strategically placed near the fire 
178
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

scene. The corresponding ASD data is presented in Figure 12. 
Throughout the airborne operation, multiple spectral 
measurements were meticulously collected, as visually 
illustrated in Figures 12(a), Figure 12(b), and Figure 12(c). A 
similar kind of information is shown in Figure 15 and Figure 
18. 
D. Test Point 2:45 Degree Aspect Angle Fire Detection 
 
Figure 13 shows the UAV carrying the NIR sensor 
payload at 45 degrees from the fire. 
 
 
Figure 13: Illustration of the UAV sensor at a 45-degree aspect angle 
 
The sensor demonstrated the ability to detect fires from an 
oblique angle, specifically at 45 degrees in this scenario. 
Images were acquired during the drone's operation at a 45¬∞ 
angle, as visually depicted in Figure 14. In Figure 14(a), we 
present the masked image that highlights the K-line emission 
originating from the fire. Meanwhile, Figure 14(b) presents 
the unmasked image, with the K-line emission accurately 
delineated in red for enhanced visibility. 
 
 
                  (a)                                           (b) 
Figure 14: NIR sensor images during angular (45 degrees) fire detection. 
 
The ASD spectral sensor was strategically positioned near 
the fire scene, to characterize the flaming vegetation fire 
spectrally and effectively within the NIR region. While the 
UAV was in flight or airborne, we conducted multiple ASD 
spectral measurements, which are illustrated in Figures 15(a), 
Figure15(b), and Figure 15(c). In particular, Figure 15(a) 
offers a close-up view of the spectra, highlighting the 
unresolved K-line doublet, a consequence of the ASD's 
modest resolution of 3nm.  
 
 
(a) 
 
(b) 
 
(c) 
Figure 15: ASD spectral data with NIR-zoomed K-line unresolved doublet. 
The fire shows the spectral radiance of the fire within the NIR region. 
 
The full fire spectrum was taken at various instances during 
the fire progression and it shows an unzoomed K-line 
presence at 769.9 nm. Visible is the continuous background 
black body spectrum that rises rapidly with increasing 
179
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

wavelength. This is purely due to the thermal excitation of all 
atomic and molecular species within the flaming region. 
Provided that the fire was flaming (as opposed to smoldering), 
the burning vegetation within the FOV of the ASD, the K-line 
doublet was readily evident in the collected spectra. 
E. Test Point 3: Flying directly above the fire (90 degrees 
aspect angle) 
Figure 16 shows the UAV carrying the NIR sensor 
payload at a 90-degree aspect angle from the fire. 
 
 
Figure 16: Image depicting the flight path of the UAV from point C TO point 
D above the fire. 
 
The sensor was able to detect from directly above, as 
shown in Figure 17. The figure shows the NIR images 
detected by the K-line band. 
 
                               (a)                                                       (b) 
Figure 17: NIR sensor images showing fire detection from directly above (90 
degrees). 
 
Successfully data logging was achieved with the ASD 
sensor, as depicted in Figure 18. Shown in Figure 18(a) are 
the zoomed and unresolved K-line doublet spectra with a peak 
at 766.5 nm and 769.9 nm respectively. The lower K-line at 
766.5 nm will be absorbed at an increased range as described 
in section IV. Figure 18(b) is a zoomed ASD spectra of the 
fire taken at different instances during the flaming phase of 
the fire. Figure 18(c) is the complete ASD spectra of the fire 
from 350 nm to 2500 nm taken at various instances during fire 
progression. A small step at 1000 nm, is a measurement 
artifact of the ASD, which switches from one internal 
spectrograph to another at this wavelength.  
 
 
(a) 
 
(b) 
 
(c) 
Figure 18: ASD spectral data with NIR-zoomed K-line unresolved doublet 
(a), zoomed spectra captured at different instances (b), and (c), the ASD 
spectra from 350nm to 2500nm. The Figure shows the spectral radiance of 
the fire within the NIR region and the short-wave band. 
 
180
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

VI. 
CONCLUSION 
 
Small-scale fires were captured using a K-line-based fire 
detection sensor mounted on an unmanned aerial vehicle 
during a field trial at the Centurion Flying Club, Pretoria, 
South Africa. The imaging results present strong evidence of 
the K-line signature within vegetation fires detectable by 
compact CMOS cameras operating within the NIR spectrum. 
The ASD spectral measurement confirmed the elemental 
composition of the vegetation species with a very dominant 
alkali metal Potassium that is embedded on the spectrum 
curve. The K element emissions are released at the 
temperature of the fire at the combustion phase. 
This study demonstrates the possibility of performing 
early fire detection of vegetation biomass using low-cost, 
higher-resolution NIR sensors integrated into unmanned 
aerial vehicles coupled with advanced image processing 
algorithms. This work is recommended as a work in progress 
to develop a system that will not only detect but track, and 
geolocate fires, enable fire progression monitoring in areas 
that are not easily accessible, and finally, facilitate the 
evolution estimates of fires in real-time.  
 The limitations on the current development board 
(RaspberryPi8) such as overheating, and inability to perform 
onboard processing are targeted as some of the improvements 
to be considered for the next version of the payload.  
 
ACKNOWLEDGMENT 
The Optronic Sensor Systems (OSS) together with all the 
team members involved in this work owes thanks to the 
Aeronautical Sciences Impact Area at the CSIR for the 
logistical assistance and technical inputs to the project. Also, 
our special thanks to the Department of Science and 
Innovation for their financial support and funding, for 
enabling this research effort, as well as UAV Industries 
(UAV-I) for support in UAV operations during the 
measurement exercise. 
 
REFERENCES 
[1] E. Magidimisha, S. Naidoo, Z. Faniso-Mnyaka, and M. Nana, 
‚ÄúDetecting Wildfires Using Unmanned Aerial Vehicle with 
Near Infrared Optical Imaging Sensor‚Äù, The Fifteenth 
International 
Conference 
on 
Advanced 
Geographic 
Information Systems, Applications, and Services, IARIA, 978-
1-68558-079-7, 2023.  
[2] Y. Liu, J. A. Stanturf, and S.L. Goodrick, ‚ÄúTrends in global 
wildfire potential in a changing climate‚Äù, Forest Ecology and 
Management, 
259(2010):685‚Äì697, 
2009. 
http://dx.doi.org/10.1016/j.foreco.2009. 09.002 (accessed Oct. 
25, 2022). 
[3] R. Kelly, L. Melissa. C. Philip, E. Higuera, I. Stefanova, B. L. 
Brubaker, and F. Sheng Hu, ‚ÄúRecent burning of boreal forests 
exceeds fire regime limits of the past 10 000 years‚Äù,  
Proceedings of the National Academy of Sciences, 
110(32):13055‚Äì13060, 2013. http://dx.doi.org/10.1073/pnas. 
1305069110 (accessed Oct. 25, 2022). 
[4] P. E. Dennison, D. A. Roberts, and L. Kammer, ‚ÄúWildfire 
Detection for Retrieving Fire Temperature from Hyperspectral 
Data‚Äù, In ASPRS 2008 Annual Conference, vol. 1, pp. 139‚Äì
146, 
2008. 
http: 
//www.asprs.org/a/publications/proceedings/portland08/0015.
pdf (accessed Oct. 25, 2022). 
[5] S. A. Robert, M. M. Joshua, J. G. Craig, and S. Jennings, 
‚ÄúAirborne Optical and Thermal Remote Sensing for Wildfire 
Detection and Monitoring‚Äù, MDPI open access article, Sensors 
2016. 
[6] J. M. Robinson, ‚ÄúFire from space: global fire evaluation using 
infrared remote sensing‚Äù, International Journal of Remote 
Sensing, vol. 12, pp. 3-24, 1991. 
[7] D. O. Fuller, ‚ÄúSatellite remote sensing of biomass burning 
using optical and thermal sensors‚Äù, Progress in Physical 
Geography, vol. 24, pp. 543-561, 2000. 
[8] L. B. Lentile, Z. A. Holden, A. M. Smith, M. J. Falkowski, A. 
T. Hudak, P. Morgan, S. A. Lewis, P. E. Gessler, and N. C. 
Benson, ‚ÄúRemote sensing techniques to assess active fire 
characteristics and post fire effects‚Äù, International Journal of 
Wildland Fire, vol. 15, pp. 319-345, 2006. 
[9] P. J. Thomas and O. Nixon, ‚ÄúNear-infrared forest fire detection 
concept‚Äù, Applied Optics, vol. 32, pp. 5348-5355, 1993. 
[10] Z. Wang, ‚ÄúModelling Wildland Fire Radiance in Synthetic 
Remote Sensing Scenes‚Äù, PhD thesis, 2007. 
[11] E. Magidimisha and D. Griffiths, ‚ÄúRemote optical observations 
of actively burning biomass fires using potassium line 
emission‚Äù, Proceedings of the SPIE, vol. 10036, pp. 331-336, 
2016.  
[12] A. Stefania, J. Martin, B. Wooster, and A. Piscini, ‚ÄúMulti-
resolution spectral analysis of wildfire potassium emission 
signatures using laboratory, airborne and spaceborne remote 
sensing‚Äù, Remote Sensing of Environment, vol. 115, pp. 1811‚Äì
1823, 2011.  
[13] R. S. Allison, A. J. M. Johnston, G. Craig, and S. Jennings, 
‚ÄúAirborne Optical and Thermal Remote Sensing for Wildfire 
Detection and Monitoring‚Äù, Sensors, 2016. 
[14] C. Yuan, Z. Liu, and Y. Zhang, ‚ÄúVision-based Forest Fire 
Detection in Aerial Images for Firefighting Using UAVs‚Äù, 
Proceedings of 2016 International Conference on Unmanned 
Aircraft Systems (ICUAS), Arlington VA, USA, 7-10 June 
2016. 
[15] S. Sudhakar, V. Vijayakumar, C. S. Kumar, V. Priya, L. Ravi, 
and V. Subramaniya, ‚ÄúUnmanned Aerial Vehicle (UAV) based 
Forest Fire Detection and monitoring for reducing false alarms 
in forest-fires‚Äù, Comput. Commun, vol. 149,  pp. 1‚Äì16, 2020. 
[16] Y. Chen, Y. Zhang, J.  Xin, Y. Yi, D. Liu, and H. Liu, ‚ÄúA UAV-
based Forest Fire Detection Algorithm Using Convolutional 
Neural Network‚Äù, Proceedings of the 37th IEEE Chinese 
Control Conference, Wuhan, China, 25‚Äì27 July, pp. 10305‚Äì
10310, 2018. 
[17] A. Vodacek, R. L. Kremens, A. J. Fordham, S. C. Vangorden, 
D. Luisi, J.R. Shott, and D. J. Latham, ‚ÄúRemote optical 
detection of biomass burning using a potassium emission 
signature‚Äù, International Journal of Remote Sensing, 23(3), pp. 
2721 - 2726, 2002.  
[18] Nist Atomic Spectral Database. URL.http://Physics.nist.gov, 
2001 (accessed Sep. 21, 2023). 
[19] S. Amici, M. J. Wooster, and A. Piscini, ‚ÄúMulti-resolution 
spectral analysis of wildfire potassium emission signatures 
using laboratory, airborne and spaceborne remote sensing‚Äù, 
Remote Sensing of Environment, vol. 115, no. 8, pp. 1811-
1823, Aug. 2011.   
[20] D. Latham, ‚ÄúNear-infrared spectral lines in natural fires‚Äù, 
Proceedings of the III International Conference on Forest Fire 
Research/14th Conference on Fire and Forest Meteorology, pp. 
513‚Äì515, 1998. 
[21] F. Khan, Z. Xu, J. Sun, F. M. Khan, A. Ahmed, and Y. Zhao, 
‚ÄúRecent Advances in Sensors for Fire Detection,‚Äù Sensors, vol. 
181
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

22, no. 9,  pp. 3310 ‚Äì 3333, Apr. 2022, doi: 
10.3390/s22093310. 
[22] "OpenCV Tutorial Optical 
Flow",‚ÄØdocs.opencv.org.  https://docs.opencv.org/4.5.1/d4/dee
/tutorial_optical_flow.html (accessed Apr. 4, 2023).  
[23] A. E. Ononye, A. Vodacek, and R. Kremens, ‚ÄúFire temperature 
retrieval using constrained spectral unmixing and emissivity 
estimation, Algorithms and Technologies for Multispectral, 
Hyperspectral, and Ultraspectral Imagery‚Äù, XI 5806, pp. 352 ‚Äì 
360, [doi: 10.1117/12.603440], 2005.  
[24] J. Shi and C. Tomasi, ‚ÄúGood features to track‚Äù,  Proceedings of 
IEEE 
Conference on 
Computer 
Vision and 
Pattern 
Recognition, pp. 593‚Äì600, IEEE, June 1994. 
[25] "OpenCV Camera Calibration and 3D Reconstruction", 
docs.opencv.org. 
https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga4a
bc2ece9fab9398f2e560d53c8c9780 (accessed Apr. 4, 2023).  
[26] M. Zuliani, ‚ÄúRansac for dummies with examples using the 
ransac toolbox for matlab & octave and more‚Äù, 2014. 
[27] "OpenCV SimpleBlobDetector Class Reference‚Äù, 
docs.opencv.orghttps://docs.opencv.org/4.x/d0/d7a/classcv_1
_1SimpleBlobDetector.html (accessed Apr. 4, 2023).  
[28] R. W. B. Pearse and A. G. Gaydon, The identification of 
Molecular Spectra (London: Chapman and Hall), 1976. 
 
182
International Journal on Advances in Software, vol 16 no 3 & 4, year 2023, http://www.iariajournals.org/software/
2023, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org

