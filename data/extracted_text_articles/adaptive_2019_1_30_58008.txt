Implementing Ethics in e-Health Applications through Adaptation: 
reflection and challenges 
Nadia Abchiche-Mimouni 
IBISC, Univ Evry, Université Paris-Saclay 
91025, Evry, France 
email: nadia.abchichemimouni@univ-evry.fr 
 
Abstract—The present contribution opens a reflection on what 
can adaptation mechanisms, inherent to multi-agent systems, 
bring for the implementation of ethical principles during the 
design and the implementation of e-health applications. 
Several works propose ethics approaches. But, since ethics 
values differ from one culture to another, it is not possible to 
have a general approach which can be used every time. The 
intuition is that adaptation capabilities is a good start. This aim 
of this paper is to raise ethics challenges in eHealth and discuss 
across interdisciplinary debate questions such as: which ethics 
to adopt for eHealth applications? How to implement ethics in 
eHealth applications? How can adaptation features help 
implementing the identified ethics challenges and questions? 
Keywords-ethics; e-Healtn; adaptation. 
I. 
INTRODUCTION 
The development of e-health, particularly thanks to 
machine learning methods and the use of Big Data places 
this type of application in the field of complex systems. In 
addition to the distributed aspect of the data and their 
heterogeneity, care units also require to be modeled as a 
complex system. The ethical issues inherent to the use of 
patients' personal data on the one hand, and the need to treat 
patients in an individualized and transparent way in the 
other 
hand, 
suggest 
that 
adaptation 
of 
paramount 
importance. Indeed, ethics requirements differ greatly 
between jurisdictions, institutions and cultures, while 
technological infrastructure is increasingly global and 
connected. 
Multi-agent system paradigm provides instruments to 
represent and manage distributed and/or heterogeneous 
entities characterized by autonomy, interaction, cooperation 
and proaction. So, adaptation characterizes such systems 
which are suitable for modelling complex systems. We think 
that Multi-agent systems provide a good omen as a tool for 
the design and implementation of ethic in eHealth 
applications. 
The aim of this paper is to raise ethics challenges in 
eHealth 
and 
discuss 
across 
interdisciplinary 
debate 
questions such as:  
• 
Which ethics to adopt for eHealth applications? 
• 
How to implement ethics in eHealth applications?  
• 
How can adaptation features help implementing the 
identified ethics challenges and questions? 
The next section illustrates why adaptation is needed in 
healthcare applications. Section III gives definition of ethics. 
Section IV gives a summary of existing computational 
approaches about ethics. The paper concludes by open 
issues. 
II. 
E-HEALTH 
E-health applications have been developed in many 
aspects of health. This concerns areas such as telemedicine, 
prevention, home care, remote chronic disease monitoring 
(diabetes, hypertension, heart failure, etc.) or electronic 
medical records. It is seen as a solution to major challenges 
such as the aging of the population and the management of 
dependence, universal access to quality care and the 
significant increase in expenditure and the explosion of 
chronic diseases. Therefore, many challenges await 
researchers and application developers in this area. The 
diversity of situations and the need to propose solutions 
adapted 
to 
individuals, 
populations 
and 
hospital 
practitioners opens the question of the adaptability and 
ethics that must be implemented [12]. 
III. 
DEFINITION OF ETHICS 
Ethics requirements differ greatly between jurisdictions 
and institutions, while technological infrastructure is 
increasingly global and connected. Moreover, ethics is not 
simply about compliance, but requires active reflection 
during 
the 
design 
process, 
especially 
for 
e-health 
applications. 
We adopt the definition of Cointe and his colleagues [5] 
because it explicitly states the ethics in a formal and easy 
way to implement when most authors remain vague. 
According to Cointe and his colleagues, ethics is a 
normative practical philosophical discipline of how one 
should act towards others. It encompasses three dimensions: 
1. Consequentialist ethics: an agent is ethical if and only if 
it weighs the consequences of each choice and chooses 
the option which has the most moral outcomes. It is 
also known as utilitarian ethics as the resulting 
decisions often aim to produce the best aggregate 
consequences. 
2. Deontological ethics: an agent is ethical if and only if it 
respects obligations, duties and rights related to given 
situations. Agents with deontological ethics (also 
known as duty ethics or obligation ethics) act in 
accordance to established social norms. 
3. Virtue ethics: an agent is ethical if and only if it acts 
13
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-706-1
ADAPTIVE 2019 : The Eleventh International Conference on Adaptive and Self-Adaptive Systems and Applications

and thinks according to some moral values (e.g., 
bravery, justice, etc.). Agents with virtue ethics should 
exhibit an inner drive to be perceived favorably by 
others. 
IV. 
IMPLEMENTING ETHICS AND ADAPTATION 
Almost all papers referring to the implementation of 
ethics in Artificial Intelligence (AI) focus on societal and 
legal aspect of the challenges. Very few works are done for 
implementing ethics values in AI. In [14], the authors have 
performed a survey from AAAI (Association for the 
Advancementof Artificial Intelligence) conférence on AI, 
AAMAS (International Conference on Autonomous Agents 
and Multiagent Systems), ECAI (European Conference on 
Artificial Intelligence) and IJCAI (International Joint 
Conference on Artificial Intelligence), as well as articles 
from well-known journals. They propose a taxonomy which 
divides the field into four areas: 
1. Exploring 
Ethical 
Dilemmas: 
technical 
systems 
enabling the AI research community to understand 
human preferences on various ethical dilemmas [1][4] 
[9]; 
2. Individual Ethical Decision Frameworks: generalizable 
decision-making 
mechanisms 
enabling 
individual 
agents to judge the ethics of its own actions and the 
actions of other agents under given contexts [3][6][7]; 
3. Collective Ethical Decision Frameworks: generalizable 
decision-making mechanisms enabling multiple agents 
to reach a collective decision that is ethical [8][10][11]; 
4. Ethics in Human-AI Interactions: frameworks that 
incorporate ethical considerations into agents which are 
designed to influence human behaviors [2][13]. 
This study offers an interesting overview of recent 
works on ethics. However, the adaptation dimension is not 
addressed when it is essential, especially for individualizing 
eHealth approaches. 
V. 
CONCLUSION AND PERSPECTIVES 
This article has outlined the elements that will help to 
draw some challenges and questions that could be raised 
about ethics, adaptation in healthcare domain. The state of 
the art in the domain of ethics in AI reveals that adaptation 
has not been addressed. Future works will concern the 
questions and scientific issues, such as adaptation 
mechanisms, raised at all the stages of the modeling, 
development, 
testing 
and 
deployment 
of 
e-health 
applications, in particular in multi-agent system domain. 
REFERENCES 
[1] M. Anderson and S. Leigh Anderson, "GenEth: A general 
ethical dilemma analyzer," In In AAAI, pp. 253–261, 2014. 
[2] C. Battaglino and R. Damiano, "Coping with moral 
emotions," In AAMAS, pages 1669–1670, 2015. 
[3] Joseph A. Blass and Kenneth D. Forbus, "Moral decision-
making by analogy: Generalizations versus exemplars," In 
AAAI, pp. 501–507, 2015. 
[4] J.F. Bonnefon, A. Shariff, and I. Rahwan, "The social 
dilemma 
of 
autonomous 
vehicles," 
In 
Science, 
352(6293):1573–1576, 2016. 
[5] N. Cointe, G. Bonnet, and O. Boissier, "Ethical judgment of 
agents’ behaviors in multi-agent systems," In AAMAS, pp. 
1106–1114, 2016. 
[6] M. Dehghani, E. Tomai, K. D. Forbus, and M. Klenk, "An 
integrated reasoning approach to moral decision-making," In 
AAAI, pp. 1280–1286, 2008. 
[7] A. Loreggia, N. Mattei, F. Rossi, and K. B. Venable, 
"Preferences and ethical principles in decision making," In 
The 2018 AAAI Spring Symposium Series, pp. 54–60, 2018. 
[8] R. Noothigattu et al., "A voting-based system for ethical 
decision making. In AAAI," pp. 1587–1594, 2018. 
[9] A. Sharif, J-F. Bonnefon, and I. Rahwan, "Psychological 
roadblocks to the adoption of selfdriving vehicles," In Nat. 
Hum. Behav., 1:694–696, 2017. 
[10] M. P. Singh, "Norms as a basis for governing sociotechnical 
systems," In ACM Trans. Intell. Syst. Technol.,5(1):21:1–
21:23, 2014. 
[11] M. P. Singh, "Norms as a basis for governing sociotechnical 
systems," In IJCAI, pp. 4207–4211, 2015. 
[12] D. F Sittig, A. Wright, E. Coiera, F. Magrabi and R. Ratwani, 
"Current challenges in healthinformation technology– related 
patient safety,"In Health Informatics Journal (Special Issue 
Article) pp. 1–9, 2018. 
[13] H. Yu, C. Miao, C. Leung, and T. J. White, "Towards AI-
powered personalization," In MOOC learning. npj Sci. Learn., 
2(15):doi:10.1038/s41539–017–0016–3, 2017. 
[14] H. Yu et al.,. "Building Ethics into Artificial Intelligence," In 
IJCAI, pp 5527–5533, 2018. 
 
14
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-706-1
ADAPTIVE 2019 : The Eleventh International Conference on Adaptive and Self-Adaptive Systems and Applications

