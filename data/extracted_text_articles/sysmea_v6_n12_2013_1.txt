Characterizing and Fulﬁlling Traceability Needs in the PREDIQT Method
for Model-based Prediction of System Quality
Aida Omerovic∗ and Ketil Stølen∗†
∗SINTEF ICT, Pb. 124, 0314 Oslo, Norway
†University of Oslo, Department of Informatics, Pb. 1080, 0316 Oslo, Norway
Email: {aida.omerovic,ketil.stolen}@sintef.no
Abstract—Our earlier research indicated the feasibility of
the PREDIQT method for model-based prediction of impacts of
architectural design changes, on the different quality character-
istics of a system. The PREDIQT method develops and makes
use of a multi-layer model structure, called prediction models.
Usefulness of the prediction models requires a structured
documentation of both the relations between the prediction
models and the rationale and assumptions made during the
model development. This structured documentation is what we
refer to as trace-link information. In this paper, we ﬁrst propose
a traceability scheme for PREDIQT. The traceability scheme
speciﬁes the needs regarding the information that should be
traced and the capabilities of the traceability approach. An
example-driven solution that addresses the needs speciﬁed
through the scheme is then presented. Moreover, we propose
an implementation of the solution in the form of a prototype
traceability tool, which can be used to deﬁne, document,
search for and represent the trace-links needed. The tool-
supported solution is applied on prediction models from an
earlier PREDIQT-based analysis of a real-life system. Based
on a set of success criteria, we argue that our traceability
approach is useful and practically scalable in the PREDIQT
context.
Keywords-traceability; system quality prediction; modeling;
architectural design; change impact analysis; simulation.
I. INTRODUCTION
ICT systems are involved in environments which are con-
stantly evolving due to changes in technologies, standards,
users, business processes, requirements, or the ways systems
are used. Both the systems and their operational environ-
ments frequently change over time and are shared. The new
needs are often difﬁcult to foresee, as their occurrence and
system life time are insufﬁciently known prior to system
development. Architectural adaptions are inevitable for ac-
commodating the systems to the new services, processes,
technologies, standards, or users. However, due to criticality
of the systems involved, planning, implementation, testing
and deployment of changes can not involve downtime or
similar degradation of quality of service. Instead, the systems
have to quickly and frequently adapt at runtime, while
maintaining the required quality of service.
Independent of whether the systems undergoing changes
are in the operation or in the development phase, important
architectural design decisions are made often, quickly and
with lack of sufﬁcient information. When adapting the
system architecture, the design alternatives may be many
and the design decisions made may have unknown implica-
tions on the system and its quality characteristics (such as
availability, security, performance or scalability). A change
involving increased security may, for example, compromise
performance or usability of a system.
The challenge is therefore how to achieve the necessary
ﬂexibility and dynamism required by software, while still
preserving the necessary overall quality. Thus, there is a need
for decision-making support which facilitates the analysis of
effects of architectural adaptions, on the overall quality of a
system as a whole.
In order to facilitate decision making in the context of
what-if analyses when attempting to understand the implica-
tions of architectural design changes on quality of a system,
models are a useful means for representing and analyzing the
system architecture. Instead of implementing the potential
architectural changes and testing their effects, model-based
prediction is an alternative. Model-based prediction is based
on abstract models which represent the relevant aspects of
the system. A prediction based on models may address a
desired number of architectural changes, without affecting
the target system. As such, it is a quicker and less costly al-
ternative to traditional implementation and testing performed
in the context of understanding the effects of changes on
system quality.
Important preconditions for model-based prediction are
correctness and proper usage of the prediction models. In
addition, the development and use of the prediction models
has to be properly documented. In practice, traceability
support requires process guidance, tool support, templates
and notations for enabling the user to eventually obtain
sufﬁciently certain predictions and document the underlying
conditions. Our recent work has addressed this issue by
proposing an approach to traceability handling in model-
based prediction of system quality [1]. This paper provides
reﬁnements and several extensions of the approach, and
elaborates further on the current state of the art with respect
to traceability in the context of model-based prediction of
system quality.
In addressing the above outlined needs and challenges re-
1
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

lated to managing architectural changes, we have developed
and tried out the PREDIQT method [2] [3] [4] aimed for
predicting impacts of architectural design changes on system
quality characteristics and their trade-offs. PREDIQT has
been developed to support the planning and analyzing the
architecture of the ICT systems in general, and to facilitate
the reasoning about alternatives for potential improvements,
as well as for the reasoning about existing and potential
weaknesses of architectural design, with respect to individual
quality characteristics and their trade-offs. The predictions
obtained from the models provide propagation paths and the
modiﬁed values of the estimates which express the degree of
quality characteristic fulﬁllment at the different abstraction
levels.
The process of the PREDIQT method guides the develop-
ment and use of the prediction models, but the correctness
of the prediction models and the way they are applied are
also highly dependent on the creative effort of the analyst
and his/her helpers. In order to provide additional help
and guidance to the analyst, we propose in this paper a
traceability approach for documenting and retrieving the
rationale and assumptions made during the model develop-
ment, as well as the dependencies between the elements of
the prediction models. This paper proposes a traceability
solution for PREDIQT to be used for predicting system
quality. To this end, we provide guidance, tool support,
templates and notations for correctly creating and using the
prediction models. The major challenge is to deﬁne accurate
and complete trace information while enabling usability and
effectiveness of the approach.
The approach is deﬁned by a traceability scheme, which
is basically a feature diagram specifying capabilities of the
solution and a meta-model for the trace-link information. As
such, the traceability scheme speciﬁes the needs regarding
the information that should be traced and the capabilities of
the traceability approach. The proposed traceability scheme
deals with quality indicators, model versioning, cost and
proﬁt information, as well as the visualization of the impact
on such values of different design choices. An example-
driven solution that addresses the needs speciﬁed through
the scheme is then presented.
Moreover, a prototype traceability tool is implemented
in the form of a relational database with user interfaces
which can be employed to deﬁne, document, search for and
represent the trace-links needed. The tool-supported solution
is illustrated on prediction models from an earlier PREDIQT-
based analysis conducted on a real-life industrial system [5].
We argue that our approach is, given the success criteria for
traceability in PREDIQT, practically useful and better than
any other traceability approach we are aware of.
This paper is a revised and extended version of a full
technical report [6]. The latter is an extended version of
a paper [1] originally presented at and published in the
proceedings of the SIMUL’11 conference. With respect to
the SIMUL’11 conference paper [1], this paper is extended
with:
1) An outline of the PREDIQT method.
2) Guidelines for application of the prediction models.
The guidelines are used for eliciting the traceability
scheme for our approach.
3) Further extensions and reﬁnements of the traceability
approach in PREDIQT with special focus on speciﬁ-
cation and handling of indicators during development
and use of prediction models; handling of quality
characteristic fulﬁllment acceptance levels; handling
of timing aspects; versioning of prediction models;
cost-beneﬁt aspects in PREDIQT; and handling of
usage proﬁle in relation to the prediction models.
4) A way of practically visualizing the design decision
alternatives has been proposed and exempliﬁed.
5) Preliminary requirements for integration of the exist-
ing PREDIQT tool with the prototype traceability tool,
have been speciﬁed and exempliﬁed.
The paper is organized as follows: Section II provides
background on traceability. An overview of the PREDIQT
method is provided in Section III. Guidelines for application
of both the prediction models and the trace-link information
are provided in Section IV. The challenge of traceability
handling in the context of the PREDIQT method is charac-
terized in Section V. The traceability scheme is presented
in Section VI. Our traceability handling approach is pre-
sented in Section VII. Section VIII illustrates the approach
on an example. Section IX argues for completeness and
practicability of the approach, by evaluating it with respect
to the success criteria. Section X substantiates why our
approach, given the success criteria outlined in Section V,
is preferred among the alternative traceability approaches.
The concluding remarks and future work are presented in
Section XI.
II. BACKGROUND ON TRACEABILITY
Traceability is the ability to determine which documenta-
tion entities of a software system are related to which other
documentation entities according to speciﬁc relationships
[7]. IEEE [8] also provides two deﬁnitions of traceability:
1) Traceability is the degree to which a relationship
can be established between two or more products of
the development process, especially products having
a predecessor-successor or master-subordinate rela-
tionship to one another; for example, the degree to
which the requirements and design of a given software
component match.
2) Traceability is the degree to which each element in
a software development product establishes its reason
for existing.
Traceability research and practice are most established in
ﬁelds such as requirements engineering and model-driven
2
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

engineering (MDE). Knethen and Paech [7] argue: “De-
pendency analysis approaches provide a ﬁne-grained impact
analysis but can not be applied to determine the impact
of a required change on the overall software system. An
imprecise impact analysis results in an imprecise estimate of
costs and increases the effort that is necessary to implement
a required change because precise relationships have to be
identiﬁed during changing. This is cost intensive and error
prone because analyzing the software documents requires
detailed understanding of the software documents and the
relationships between them.” Aizenbud-Reshef et al. [9]
furthermore state: “The extent of traceability practice is
viewed as a measure of system quality and process maturity
and is mandated by many standards” and “With complete
traceability, more accurate costs and schedules of changes
can be determined, rather than depending on the programmer
to know all the areas that will be affected by these changes.”
IEEE [8] deﬁnes a trace as “A relationship between two
or more products of the development process.” According to
the OED [10], however, a trace is deﬁned more generally as
a “(possibly) non-material indication or evidence showing
what has existed or happened”. As argued by Winkler and
von Pilgrim [11]: “If a developer works on an artifact,
he leaves traces. The software conﬁguration management
system records who has worked on the artifact, when that
person has worked on it, and some systems also record
which parts of the artifacts have been changed. But beyond
this basic information, the changes themselves also reﬂect
the developer’s thoughts and ideas, the thoughts and ideas
of other stakeholders he may have talked to, information
contained in other artifacts, and the transformation process
that produced the artifact out of these inputs. These inﬂu-
ences can also be considered as traces, even though they are
usually not recorded by software conﬁguration management
systems.”
A traceability link is a relation that is used to interrelate
artifacts (e.g., by causality, content, etc.) [11]. In the context
of requirements traceability, Winkler and von Pilgrim [11]
argue that “a trace can in part be documented as a set of
meta-data of an artifact (such as creation and modiﬁcation
dates, creator, modiﬁer, and version history), and in part
as relationships documenting the inﬂuence of a set of
stakeholders and artifacts on an artifact. Particularly those
relationships are a vital concept of traceability, and they
are often referred to as traceability links. Traceability links
document the various dependencies, inﬂuences, causalities,
etc. that exist between the artifacts. A traceability link can
be unidirectional (such as depends-on) or bidirectional (such
as alternative-for). The direction of a link, however, only
serves as an indication of order in time or causality. It does
not constrain its (technical) navigability, so traceability links
can always be followed in both directions”.
In addition to the different deﬁnitions, there is no com-
monly agreed basic classiﬁcation [11], that is, a classiﬁcation
of traceability links. A taxonomy of the main concepts
within traceability is suggested by Knethen and Paech [7].
An overview of the current state of traceability research
and practice in requirements engineering and model-driven
development is provided by Winkler and von Pilgrim [11],
based on an extensive literature survey. Another survey by
Galvao and Goknil [12] discusses the state-of-the-art in
traceability approaches in MDE and assesses them with
respect to ﬁve evaluation criteria: representation, mapping,
scalability, change impact analysis and tool support. More-
over, Spanoudakis and Zisman [13] present a roadmap
of research and practices related to software traceability
and identify issues that are open for further research. The
roadmap is organized according to the main topics that have
been the focus of software traceability research.
Traces can exist between both model- and non-model
artifacts. The means and measures applied for obtaining
traceability are deﬁned by so-called traceability schemes. A
traceability scheme is driven by the planned use of the traces.
The traceability scheme determines for which artifacts and
up to which level of detail traces can be recorded [11]. A
traceability scheme thus deﬁnes the constraints needed to
guide the recording of traces, and answers the core ques-
tions: what, who, where, how, when, and why. Additionally,
there is tacit knowledge (such as why), which is difﬁcult to
capture and to document. A traceability scheme helps in this
process of recording traces and making them persistent.
As argued by Aizenbud-Reshef et al. [9], the ﬁrst ap-
proach used to express and maintain traceability was cross-
referencing. This involves embedding phrases like “see
section x” throughout the project documentation. Thereafter,
different techniques have been used to represent traceability
relationships including standard approaches such as ma-
trices, databases, hypertext links, graph-based approaches,
formal methods, and dynamic schemes [9]. Representation,
recording and maintenance of traceability relations are clas-
siﬁed by Spanoudakis and Zisman [13] into ﬁve approaches:
single centralized database, software repository, hypermedia,
mark-up, and event-based.
According to Wieringa [14], representations and visual-
izations of traces can be categorized into matrices, cross-
references, and graph-based representations. As elaborated
by Wieringa, the links, the content of the one artifact,
and other information associated with a cross reference,
is usually displayed at the same time. This is, however,
not the case with traceability matrices. So, compared to
traceability matrices, the user is (in the case of cross-
references) shown more local information at the cost of
being shown fewer (global) links. As models are the central
element in MDE, graph-based representations are the norm.
A graph can be transformed to a cross-reference. Regarding
the notation, there is, however, no common agreement or
standard, mostly because the variety and informality of
different artifacts is not suitable for a simple, yet precise
3
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

notation. Requirements traceability graphs are usually just
plain box-and-line diagrams [14].
Knethen and Paech [7] argue that the existing traceability
approaches do not give much process support. They specify
four steps of traceability process: 1) deﬁne entities and rela-
tionships, 2) capture traces, 3) extract and represent traces,
and 4) maintain traces. Similarly, Winkler and von Pilgrim
[11] state that traceability and its supporting activities are
currently not standardized. They classify the activities when
working with traces into: 1) planning for traceability, 2)
recording traces, 3) using traces, and 4) maintaining traces.
Traceability activities are generally not dependent on any
particular software process model.
Trace models are usually stored as separate models, and
links to the elements are (technically) unidirectional in
order to keep the connected models or artifacts independent.
Alternatively, models can contain the trace-links themselves
and links can be deﬁned as bidirectional. While embedded
trace-links pollute the models, navigation is much easier
[11]. Thus, we distinguish between external and internal
storage, respectively. Anquetil at al. [15] argue: “Keeping
link information separated from the artifacts is clearly better;
however, it needs to identify uniquely each artifact, even
ﬁned-grained artifacts. Much of the recent research has
focused on ﬁnding means to automate the creation and
maintenance of trace information. Text mining, information
retrieval and analysis of trace links techniques have been
successfully applied. An important challenge is to maintain
links consistency while artifacts are evolving. In this case,
the main difﬁculty comes from the manually created links,
but scalability of automatic solution is also an issue.”
As outlined by Aizenbud-Reshef et al. [9], automated cre-
ation of trace-links may be based on text mining, information
retrieval, analysis of existing relationships to obtain implied
relations, or analysis of change history to automatically
compute links.
Reference models are an abstraction of best practice and
comprise the most important kinds of traceability links.
There is nothing provably correct about reference models,
but they derive their relevance from the slice of practice they
cover. Nevertheless, by formalizing a reference model in an
appropriate framework, a number of elementary desirable
properties can be ensured. A general reference model for
requirements traceability is proposed by Ramesh and Jarke
[16], based on numerous empirical studies.
Various tools are used to set and maintain traces. Surveys
of the tools available are provided by Knethen and Paech [7],
Winkler and von Pilgrim [11], Spanoudakis and Zisman [13],
and Aizenbud-Reshef et al. [9]. Bohner and Arnold [17]
found that the granularity of documentation entities managed
by current traceability tools is typically somewhat coarse for
an accurate impact analysis.
III. AN OVERVIEW OF THE PREDIQT METHOD
PREDIQT is a tool-supported method for model-based
prediction of quality characteristics (performance, scala-
bility, security, etc.). PREDIQT facilitates speciﬁcation of
quality characteristics and their indicators, aggregation of
the indicators into functions for overall quality characteristic
levels, as well as dependency analysis. The main objective
of a PREDIQT-based analysis is prediction of system quality
by identifying different quality aspects, evaluating each of
these, and composing the results into an overall quality
evaluation. This is useful, for example, for eliciting quality
requirements, evaluating the quality characteristics of a
system, run-time monitoring of quality relevant indicators,
as well as veriﬁcation of the overall quality characteristic
fulﬁllment levels.
The PREDIQT method produces and applies a multi-
layer model structure, called prediction models, which rep-
resent system relevant quality concepts (through “Quality
Model”), architectural design (through “Design Model”),
and the dependencies between architectural design and
quality (through “Dependency Views”). The Design Model
diagrams are used to specify the architectural design of the
target system and the changes whose effects on quality are
to be predicted. The Quality Model diagrams are used to
formalize the quality notions and deﬁne their interpreta-
tions. The values and the dependencies modeled through
the Dependency Views (DVs) are based on the deﬁnitions
provided by the Quality Model. The DVs express the inter-
play between the system architectural design and the quality
characteristics. Once a change is speciﬁed on the Design
Model diagrams, the affected parts of the DVs are identiﬁed,
and the effects of the change on the quality values are
automatically propagated at the appropriate parts of the DV.
This section brieﬂy outlines the PREDIQT method in terms
of the process and the artifacts.
A. Process and models
The process of the PREDIQT method consists of three
overall phases: Target modeling, Veriﬁcation of prediction
models, and Application of prediction models. Each phase is
decomposed into sub-phases, as illustrated by Figure 1.
Based on the initial input, the stakeholders involved
deduce a high level characterization of the target system,
its scope and the objectives of the prediction analysis, by
formulating the system boundaries, system context (includ-
ing the usage proﬁle), system lifetime and the extent (nature
and rate) of design changes expected.
As mentioned above, three interrelated sets of models
are developed during the process of the PREDIQT method:
Design Model which speciﬁes system architecture, Quality
Model which speciﬁes the system quality notions, and De-
pendency Views (DVs) which represent the interrelationship
between the system quality and the architectural design.
Quality Model diagrams are created in the form of trees,
4
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Phase 1: Target modeling
Phase 2: Verification of prediction models
Sub‐phase 1.1: Characterization of the target and the objectives
Sub‐phase 1.2: Development of  Quality Models
Sub‐phase 1.3: Mapping of Design Models
Sub‐phase 1.4: Development of Dependency Views
Phase 3: Application of prediction models
Sub‐phase 2.1: Evaluation of prediction models
Sub‐phase 2.2: Fitting of prediction models
Sub‐phase 2.3: Approval of the final prediction models
Sub‐phase 3.1: Specification of a change
Sub‐phase 3.2: Application of the change on prediction models
Sub‐phase 3.3: Quality prediction
Figure 1.
A simpliﬁed overview of the process of the PREDIQT method
Data protection
QCF=0.94
Encryption
QCF=1.00
Authentication
QCF=0.95
Authorization
QCF=0.90
Other
QCF=0.90
EI=0.25
EI=0.30
EI=0.30
EI=0.15
Figure 2.
Excerpt of an example DV with ﬁctitious values
by deﬁning the quality notions with respect to the target
system. The Quality Model diagrams represent a taxonomy
with interpretations and formal deﬁnitions of system quality
notions. The total quality of the system is decomposed
into characteristics, sub-characteristics and quality indica-
tors. The Design Model diagrams represent the architectural
design of the system.
For each quality characteristic deﬁned in the Quality
Model, a quality characteristic speciﬁc DV is deduced from
the Design Model diagrams and the Quality Model diagrams
of the system under analysis. This is done by modeling the
dependencies of the architectural design with respect to the
quality characteristic that the DV is dedicated to, in the form
of multiple weighted and directed trees. A DV comprises two
notions of parameters:
1) EI: Estimated degree of Impact between two nodes,
and
2) QCF: estimated degree of Quality Characteristic Ful-
ﬁllment.
Each arc pointing from the node being inﬂuenced is an-
notated by a quantitative value of EI, and each node is
annotated by a quantitative value of QCF.
Figure 2 shows an excerpt of an example DV with ﬁcti-
tious values. In the case of the Encryption node of Figure 2,
the QCF value expresses the goodness of encryption with
respect to the quality characteristic in question, e.g., security.
A quality characteristic is deﬁned by the underlying system
speciﬁc Quality Model, which may for example be based on
the ISO 9126 product quality standard [18]. A QCF value in
a DV expresses to what degree the node (representing system
part, concern or similar) is realized so that it, within its own
domain, fulﬁlls the quality characteristic. The QCF value is
based on the formal deﬁnition of the quality characteristic
(for the system under analysis), provided by the Quality
Model. The EI value on an arc expresses the degree of
impact of a child node (which the arc is directed to) on
the parent node, or to what degree the parent node depends
on the child node, with respect to the quality characteristic
under consideration.
“Initial” or “prior” estimation of a DV involves providing
QCF values to all leaf nodes, and EI values to all arcs.
Input to the DV parameters may come in different forms
(e.g., from domain expert judgments, experience factories,
measurements, monitoring, logs, etc.), during the different
phases of the PREDIQT method. The DV parameters are
assigned by providing the estimates on the arcs and the
leaf nodes, and propagating them according to the general
DV propagation algorithm. Consider for example the Data
protection node in Figure 2 (denoting: DP: Data protection,
E: Encryption, AT: Authentication, AAT: Authorization, and
O:Other):
QCF(DP ) = QCF(E) · EI(DP →E) + QCF(AT ) · EI(DP →AT ) +
QCF(AAT ) · EI(DP →AAT ) + QCF(O) · EI(DP →O)
(1)
The DV-based approach constrains the QCF of each node
to range between 0 and 1, representing minimal and maximal
characteristic fulﬁllment (within the domain of what is repre-
sented by the node), respectively. This constraint is ensured
through the formal deﬁnition of the quality characteristic
rating (provided in the Quality Model). The sum of EIs, each
between 0 (no impact) and 1 (maximum impact), assigned to
the arcs pointing to the immediate children must be 1 (for
model completeness purpose). Moreover, all nodes having
a common parent have to be orthogonal (independent).
The dependent nodes are placed at different levels when
structuring the tree, thus ensuring that the needed relations
are shown at the same time as the tree structure is preserved.
The general DV propagation algorithm, exempliﬁed by
(1), is legitimate since each quality characteristic speciﬁc
DV is complete, the EIs are normalized and the nodes having
a common parent are orthogonal due to the structure. A
DV is complete if each node which is decomposed, has
children nodes which are independent and which together
fully represent the relevant impacts on the parent node,
with respect to the quality characteristic that the DV is
dedicated to. Two main means can be applied in order to
facilitate that the children nodes fully represent the relevant
impacts. First, in case not all explicit nodes together express
the total impact, an additional node called “other” can
5
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

be added to each relevant sub-tree, thus representing the
overall dependencies. Second, once the EI and QCF values
have been assigned within a subtree, a possible lack of
completeness will become more explicit. In such a case,
either the EI estimates have to be modiﬁed, or additional
nodes (for the missing dependencies) need to be added either
explicitly, or in the form of an “other” node. In case “other”
is used, it is particularly important to document the rationale
(and other trace-link information) related to it.
The rationale for the orthogonality is that the resulting
DV structure is tree-formed and easy for the domain experts
to relate to. This signiﬁcantly simpliﬁes the parametrization
and limits the number of estimates required, since the
number of interactions between the nodes is minimized.
Although the orthogonality requirement puts additional de-
mands on the DV structuring, it has shown to represent a
signiﬁcant advantage during the estimation.
The “Veriﬁcation of prediction models” is an iterative
phase that aims to validate the prediction models, with
respect to the structure and the individual parameters, before
they are applied. A measurement plan with the necessary
statistical power is developed, describing what should be
evaluated, when and how. Both system-as-is and change
effects should be covered by the measurement plan. Model
ﬁtting is conducted in order to adjust the DV structure and
the parameters to the evaluation results. The objective of
the “Approval of the ﬁnal prediction models” sub-phase is
to evaluate the prediction models as a whole and validate
that they are complete, correct and mutually consistent after
the ﬁtting. If the deviation between the model and the new
measurements is above the acceptable threshold after the
ﬁtting, the target modeling phase is re-initiated.
The “Application of the change on prediction models”
phase involves applying the speciﬁed architectural design
change on the prediction models. During this phase, a
speciﬁed change is applied to the Design Model diagrams
and the DVs, and its effects on the quality characteristics at
the various abstraction levels are simulated on the respective
DVs. When an architectural design change is applied on the
Design Model diagrams, it is according to the deﬁnitions
in the Quality Model, reﬂected to the relevant parts of
the DV. Thereafter, the DV provides propagation paths and
quantitative predictions of the new quality characteristic
values, by propagating the change throughout the rest of
each one of the modiﬁed DVs, based on the general DV
propagation algorithm.
We have earlier developed tool support [5] based on
Microsoft Excel for development of the DVs, as well as
automatic simulation and sensitivity analysis in the context
of the DVs. This tool was originally developed in order
to serve as an early version providing a “proof-of-concept”
and supporting the case studies on PREDIQT. Based on the
PREDIQT method speciﬁcation, and the early tool support, a
new and enriched version of the PREDIQT tool has been de-
veloped, as presented in [19]. The former tool was developed
on proprietary software, since MS Excel provided a rather
simple and sufﬁcient environment for quick prototyping. The
last version of the tool, is however developed in the form of
an Eclipse Modeling Framework (EMF) plugin. Both tools
have recently been applied in full scale realistic industrial
case studies. The existing PREDIQT tool support will in the
following be referred to as the “PREDIQT tool.”
B. Structure of the prediction models
Figure 3 provides an overview of the elements of the
prediction models, expressed as a UML [20] class diagram.
A Quality Model is a set of tree-like structures, which clearly
specify the system-relevant quality notions, by deﬁning and
decomposing the meaning of the system-relevant quality
terminology. Each tree is dedicated to a target system-
relevant quality characteristic. Each quality characteristic
may be decomposed into quality sub-characteristics, which
in turn may be decomposed into a set of quality indica-
tors. As indicated by the relationship of type aggregation,
speciﬁc sub-characteristics and indicators can appear in
several Quality Model trees dedicated to the different quality
characteristics. Each element of a Quality Model is assigned
a quantitative normalized metric and an interpretation (qual-
itative meaning of the element), both speciﬁc for the target
system. A Design Model represents the relevant aspects of
the system architecture, such as for example process, data
ﬂow, structure, and rules.
A DV is a weighted dependency tree dedicated to a
speciﬁc quality characteristic deﬁned through the Quality
Model. As indicated by the attributes of the Class Node, the
nodes of a DV are assigned a name and a QCF. A QCF
(Quality Characteristic Fulﬁllment) is, as explained above,
the value of the degree of fulﬁllment of the quality char-
acteristic, with respect to what is represented by the node.
The degree of fulﬁllment is deﬁned by the metric (of the
quality characteristic) provided in the Quality Model. Thus,
a complete prediction model has as many DVs as the quality
characteristics deﬁned in the Quality Model. Additionally, as
indicated by the Semantic dependency relationship, seman-
tics of both the structure and the weights of a DV are given
by the deﬁnitions of the quality characteristics, as speciﬁed
in the Quality Model. A DV node may be based on a Design
Model element, as indicated by the Based on dependency
relationship. As indicated by the self-reference on the Node
class, one node may be decomposed into children nodes.
Directed arcs express dependency with respect to quality
characteristic by relating each parent node to its immediate
children nodes, thus forming a tree structure. Each arc in
a DV is assigned an EI (Estimated Impact), which is a
normalized value of degree of dependence of a parent node,
on the immediate child node. Thus, there is a quantiﬁed
dependency relationship from each parent node, to its im-
mediate children. The values on the nodes and the arcs are
6
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Dependency 
View
Design Model
Structure
Dataflow
Rule
Quality 
characteristic
Quality model
Element
Prediction 
model
Based on
1
1
1
1..*
1
1..*
1
1
1
1
-name: String
-QCF: Float
-(PropagationFunction)
Node
Quality 
Sub-characteristic
Quality Indicator
Interpretation
Metric
-EI:NormalizedFloat
Dependency
1
*
1
1
Process
*
*
Semantic
1
*Decomposed 
into                       
Figure 3.
An overview of the elements of the prediction models, expressed as a UML class diagram
referred to as parameter estimates. We distinguish between
prior and inferred parameter estimates. The former ones are,
in the form of empirical input, provided on leaf nodes and
all arcs, while the latter ones are deduced using the above
presented DV propagation model for PREDIQT. For further
details on PREDIQT, see Omerovic et al. [2], Omerovic and
Stølen [21], Omerovic et al. [22], and Omerovic [4].
IV. GUIDELINES FOR APPLICATION OF PREDICTION
MODELS
In order to facilitate quality and correct use of prediction
models, this section provides guidelines for application of
the prediction models and the trace-link information, with
the analyst as the starting point. Thus, unless otherwise
speciﬁed, all the guidelines are directed towards the ana-
lyst. Overall guidelines for the “Application of prediction
models” – phase (i.e., Phase 3 of the PREDIQT process,
see Figure 1) are presented ﬁrst, followed by detailed
guidelines for each one of its sub-phases: “Speciﬁcation of a
change”, “Application of the change on prediction models”
and “Quality prediction”, respectively. The guidelines for
each phase and sub-phase follow a standard structure:
• objective – speciﬁes the goals of the phase
• prerequisites – speciﬁes the conditions for initiating the
phase
• how conducted – presents the detailed instructions for
performing the steps that have to be undergone
• input documentation – lists the documentation that is
assumed to be ready and available upon the initializa-
tion of the phase
• output documentation – lists the documentation that is
assumed to be available upon the completion of the
(sub)phase
• modeling guideline – lists the sequence of steps needed
to be undergone in the context of modifying or applying
the relevant prediction models.
The guidelines are based on the authors’ experiences
from industrial trials of PREDIQT [5] [3]. As such, the
guidelines are not exhaustive but serve as an aid towards
a more structured process of applying the prediction models
and accommodating the trace information during the model
development, based on the needs of the “Application of
prediction models”-phase.
It should be noted that the guidelines presented in this
section only cover Phase 3 of the PREDIQT process. This
is considered as the essential phase for obtaining the predic-
tions in a structured manner with as little individual inﬂuence
of the analyst as possible. It would of course be desirable
to provide corresponding guidelines for the ﬁrst two phases
of the PREDIQT process as well. For our current purpose,
however, Phase 3 is essential and critical, while the guidance
for carrying out phases 1 and 2 currently relies on the
presentation of PREDIQT [4] and documentation of the case
studies [2] [3].
It should also be noted that in the guidelines presented
in this section, sub-phase 2 (“Application of the change
on prediction models”) is the most extensive one. In this
phase, the speciﬁed change is ﬁrst applied on the Design
Model. Then, the dependencies within the Design Model
are identiﬁed. Thereafter, the change is, based on the spec-
iﬁcation and the modiﬁed Design Model, reﬂected on the
DVs. Once the DVs are modiﬁed, the modiﬁcations are
veriﬁed. The modiﬁcations of both the Design Model and
the DVs strongly depends on the semantics of the Quality
Model which is actively used (but not modiﬁed) throughout
the sub-phase. As such, the sub-phase involves modiﬁcation
of the Design Model and the DVs, based on the change
speciﬁcation and the Quality Model. Rather that splitting
this sub-phase into two separate ones, we believe that it
is beneﬁcial to include all tasks related to application of a
change on the prediction models in one (although extensive,
yet) coherent sub-phase.
7
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

A. Guidelines for the “Application of prediction models” –
phase
Objective
During this phase, a speciﬁed change is applied to the
prediction models, and its effects on the quality character-
istics at the various abstraction levels are simulated on the
respective Dependency Views (DVs). The simulation reveals
which design parts and aspects are affected by the change
and the degree of impact (in terms of the quality notions
deﬁned by the Quality Model).
Prerequisites
• The ﬁtted prediction models are approved.
• The changes applied are assumed to be independent
relative to each other.
• The “Quality prediction” sub-phase presupposes that
the change speciﬁed during the “Speciﬁcation of a
change” sub-phase can be fully applied on the predic-
tion models, during the “Application of the change on
prediction models” sub-phase.
How conducted
This phase consists of the three sub-phases:
1) Speciﬁcation of a change
2) Application of the change on prediction models
3) Quality prediction
Input documentation
• Prediction models: Design Model diagrams, Quality
Model diagrams, and Dependency Views
• Trace-links
Output documentation
• Change speciﬁcation
• Pre- and post-change Design Model diagrams
• DVs.
People that should participate
• Analysis leader (Required). Analysis leader is also
referred to as analyst.
• Analysis secretary (Optional)
• Representatives of the customer:
– Decision makers (Optional)
– Domain experts (Required)
– System architects or other potential users of
PREDIQT (Required)
Modeling guideline
1) Textually specify the architectural design change of
the system.
2) Modify the Design Model diagrams with respect to the
change proposed. Modify the structure and the values
of the prior parameters, on the affected parts of the
DVs.
3) Run the simulation and display the changes on the
Design Model diagrams and the DVs, relative to their
original (pre-change) structure and values.
B. Guidelines for the “Speciﬁcation of a change” sub-phase
Objective
The change speciﬁcation should clearly state all deploy-
ment relevant facts necessary for applying the change on
the prediction models. The speciﬁcation should include the
current and the new state and characteristics of the design
elements/properties being changed, the rationale and the
assumptions made.
Prerequisites
The ﬁtted prediction models are approved.
How conducted
Specify the change by describing type of change, the
rationale, who should perform it, when, how and in which
sequence of events. In the case that the change speciﬁcation
addresses modiﬁcations of speciﬁc elements of the Design
Model diagrams or the DVs, the quality characteristics of the
elements before and after the change have to be speciﬁed,
based on the deﬁnitions provided by the Quality Model.
The change speciﬁcation has to be at the abstraction level
corresponding to the abstraction level of a sufﬁcient subset
of the Design Model diagrams or DVs.
Input documentation
• Prediction models
• Design Model
• Quality Model
• Dependency Views.
Output documentation
Textual speciﬁcation of a change.
Modeling guideline
1) Textually specify an architectural design change of the
system represented by the approved prediction models.
2) Specify the rationale and the process related to the
change deployment.
C. Guidelines for the “Application of the change on predic-
tion models” sub-phase
Objective
This sub-phase involves applying the speciﬁed change on
the prediction models.
Prerequisites
• The change is speciﬁed.
• The speciﬁed change is, by the analyst and the domain
experts, agreed upon and a common understanding is
reached.
How conducted
Detailed instructions for performing the six steps speciﬁed
in “Modeling guideline,” are provided here.
1) This ﬁrst step of relating the change to the Design
Model diagram(s) and their elements is a manual
effort. The analyst and the domain experts conﬁrm
that a common understanding of the speciﬁcation has
been reached. Then, they retrieve the diagrams and
the respective elements of the Design Model and
8
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

identify which elements are potentially affected by
the change, with respect to the system quality in
general. The identiﬁed elements are marked, and their
post-change status speciﬁed. The status may be of
three types: update, delete or add. The update may
involve change of a property related to design or a
quality characteristic. In the case of delete, the diagram
element is marked and its new status is visible. In the
case of add, a new diagram element is introduced.
2) The trace-links between diagrams and diagram ele-
ments are (during the “Target modeling” phase) doc-
umented in the form of a database, which they can
be retrieved from. Each one of the above identiﬁed
Design Model diagrams and diagram elements (except
the added ones) is searched in the existing trace-
link database (created during the model development).
The result displays those searched items which have
the role of the origin or the target element, and all
the elements that depend on them or that they are
dependent on, respectively. The result also displays
overall meta-data, e.g., the kinds of the trace-links
and their rationale. The domain experts and the an-
alyst identify those retrieved (linked) elements that
are affected by the speciﬁed change. Depending on
the nature of the change and the trace-link type and
rationale, each diagram or element which, according
to the search results is linked to the elements identiﬁed
in the previous step, may be irrelevant, deleted or
updated. The updated and the deleted elements are,
within the diagrams, assigned the new (post-change)
status and meta-data.
3) The trace-link database is searched for all the above
identiﬁed elements which have been updated or
deleted. The trace-links between those elements and
the DV model elements are then retrieved. Then, the
overall DV model elements that may be affected by
the change are manually identiﬁed. The rationale for
the DV structure and the node semantics regarding
all the retrieved and manually identiﬁed DV model
elements, are retrieved from the trace-link database.
It is considered whether the added design element
models require new DV nodes. The DV structure is
manually veriﬁed, based on the retrieved trace-link
information.
4) The domain experts and the analyst manually verify
the updated structure (completeness, orthogonality,
and correctness) of each DVs, with respect to the
i) quality characteristic deﬁnitions provided by the
Quality Model and ii) the modiﬁed Design Model.
5) The estimates of the prior parameters have to be
updated due to the modiﬁcations of the Design Model
and the DV structure. Due do the structural DV
modiﬁcation in the previous step, previously internal
nodes may have become prior nodes, and the EIs on
the arcs may now be invalid. New nodes and arcs may
have been introduced. All the earlier leaf nodes which
have become internal nodes, and all new internal nodes
are assumed to automatically be assigned the function
for the propagation model, by the PREDIQT tool. All
the new or modiﬁed arcs and leaf nodes have to be
marked so that the values of their parameters can be
evaluated. The overall unmodiﬁed arcs and the leaf
nodes whose values may have been affected by the
change, are manually identiﬁed. In the case of the
modiﬁed arcs and leaf nodes, trace-links are used to
retrieve the previously documented rationale for the
estimation of the prior parameter values and node
semantics. The parameter values on the new and the
modiﬁed arcs and leaf nodes are estimated based on
the Quality Model.
The leaf node QCFs of a sub-tree are estimated
before estimating the related EIs. The rationale is to
fully understand the semantics of the nodes, through
reasoning about their QCFs ﬁrst. In estimating a QCF,
two steps have to be undergone:
a) interpretation of the node in question – its con-
tents, scope, rationale and relationship with the
Design Model, and
b) identiﬁcation of the relevant metrics from the
Quality Model of the quality characteristic that
the DV is addressing, as well as evaluation of
the metrics identiﬁed.
When estimating a QCF the following question is
posed (to the domain experts): “To what degree is
the quality characteristic fulﬁlled, given the contents
and the scope of the node?” The deﬁnition of the
rating should be recalled, along with the fact that
zero estimate value denotes no fulﬁllment, while one
denotes maximum fulﬁllment.
In estimating an EI, two steps have to be undergone:
a) interpretation of the two nodes in question, and
b) determination of the degree of impact of the child
node, on the parent node. The value is assigned
relative to the overall EIs related to the same par-
ent node, and with a consistent unit of measure,
prior to being normalized. The normalized EIs
on the arcs from the same parent node have to
sum up to one, due to the requirement of model
completeness.
When estimating an EI the following question is posed
(to the domain experts): “To what degree does the
child node impact the parent node, or how dependent
is the parent node on child node, with respect to the
quality characteristic that the DV is dedicated to?”
The deﬁnition of the quality characteristic provided
by its Quality Model, should be recalled and the
estimate is provided relative to the impact of the
9
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

overall children nodes of the parent node in question.
Alternatively, an impact value is assigned using the
same unit of measure on all arcs of the sub-tree, and
normalized thereafter.
Once one of the above speciﬁed questions is posed,
depending on the kind of the DV parameter, the
domain expert panel is asked to provide the estimate
with an interval so that the correct value is within
the interval with a probability given by the conﬁdence
level [23].
6) Manually verify the updated prior parameter values,
so that the relative QCF values are consistent to each
other and the rest of the estimates, and so that EIs on
the arcs from a common parent sum up to one.
If the speciﬁed change can be fully applied, it is within
the scope of the prediction models, which is a prerequisite
for proceeding to the next sub-phase. Otherwise, the modiﬁ-
cations are canceled and the change deemed not predictable
by the models as such.
Input documentation
• Prediction models: Design Model, Quality Model, De-
pendency Views
• Speciﬁcation of the change
• The trace-links.
Output documentation
• Design Model
• DVs modiﬁed with respect to the change.
Modeling guideline
1) Relate the speciﬁed change to manually identiﬁable
Design Model diagram(s) and their elements.
2) Use the trace-links to identify the affected parts (di-
agrams and diagram elements) of the Design Model.
Apply the change by modifying (updating, deleting
or adding) the identiﬁed affected parts of the Design
Model.
3) Use the trace-links to identify the affected parts (nodes
and dependency links) of each DV, by retrieving the
traces from the modiﬁed and the deleted parts of the
Design Model to the DVs, as well as the rationale for
the DV structure and the node semantics. Modify the
structure of the affected parts of the DVs.
4) Manually verify the updated structure (completeness,
orthogonality, and correctness) of the DVs, with re-
spect to the Quality Model and the modiﬁed Design
Model.
5) Use trace-links to identify the documented rationale
for the estimation of the prior parameter values. Man-
ually identify the overall prior parameters that have
been affected by the change. Use Quality Model to
modify the values of the affected prior parameters (i.e.,
EIs and leaf node QCFs).
6) Manually verify the updated prior parameter values
(that QCFs are consistent relative to each other and
that EIs on the arcs from a common parent sum up to
one).
D. Guidelines for the “Quality prediction” sub-phase
Objective
The propagation of the change throughout the rest of each
one of the modiﬁed DVs, is performed. The propagation
paths and the modiﬁed parameter values are obtained.
Prerequisites
The speciﬁed change is within the scope of and fully
applied on the prediction models.
How conducted
Use the PREDIQT tool support to propagate the change.
The tool explicitly displays the propagation paths and the
modiﬁed parameter values, as well as the degrees of pa-
rameter value change. Obtain the predictions, in terms of
the propagation paths and the parameter value modiﬁcation.
The result must explicitly express the changes with respect
to the pre-change values. The propagation of the change
throughout each one of the modiﬁed DVs, is performed
based on the general DV propagation model, according to
which the QCF value of each parent node is recursively
calculated by ﬁrst multiplying the QCF and EI value for
each closest child and then summing up these products.
Such a model is legitimate since each quality characteristic
DV is complete, the EIs are normalized and the nodes
having a common parent are orthogonal (with respect to
the quality characteristic that the DV is dedicated to) due
to the structure. The root node QCF values on the quality
characteristic speciﬁc DVs represent the system-level rating
value of the quality characteristic that the DV is dedicated to.
If the predicted parameter values are beyond a pre-deﬁned
uncertainty threshold, the modiﬁcations are canceled and the
change deemed not predictable by the input data and the
models as such.
Input documentation
DVs.
Output documentation
• The change is propagated throughout the DVs, based
on the DV propagation model.
• Propagation paths and parameter value changes (rela-
tive to the original ones) are displayed.
Modeling guideline
1) Run the simulation on the PREDIQT tool, in order to
obtain the change propagation paths and the modiﬁed
QCF values of the affected non-leaf nodes of the DVs.
2) Display the changes performed on the Design Model
and the DVs (structure and the prior parameter values).
V. THE CHALLENGE
This section motivates and speciﬁes the success criteria
for the traceability handling approach in PREDIQT.
10
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

A. Balancing the needs
Trace-link information can be overly detailed and ex-
tensive while the solution needed in a PREDIQT context
has to be applicable in a practical real-life setting within
the limited resources allocated for a PREDIQT-based anal-
ysis. Therefore, the traceability approach should provide
sufﬁcient breadth and accuracy for documenting, retrieving
and representing of the trace-links, while at the same time
being practically applicable in terms of comprehensibility
and scalability. The right balance between the completeness
and accuracy of the trace information on the one side,
and practical usability of the approach on the other side,
is what characterizes the main challenge in proposing the
appropriate solution for traceability handling in PREDIQT.
Therefore, the trace-link creation efforts have to be concen-
trated on the traces necessary during the application of the
prediction models.
It is, as argued by Winkler and von Pilgrim [11], an open
issue to match trace usage and traceability schemes, and
to provide guidance to limit and ﬁt traceability schemes
in a such way that they match a projects required usage
scenarios for traces. One of the most urgent questions
is: what requirements a single scenario imposes on the
other activities (in particular planning and recording) in the
traceability process.
Moreover, it is argued by Aizenbud-Reshef et al. [9] that
the lack of guidance as to what link information should
be produced and the fact that those who use traceability
are commonly not those producing it, also diminishes the
motivation of those who create and maintain traceability in-
formation. In order to avoid this trap, we used the PREDIQT
guidelines (as documented in Section IV) for the analyst as a
starting point, for deriving the speciﬁc needs for traceability
support.
B. Success criteria
The speciﬁc needs for traceability support in PREDIQT
are summarized below:
1) There is need for the following kinds of trace-links:
• Links between the Design Model elements to
support identiﬁcation of dependencies among the
elements of the Design Model.
• Links from the Design Model elements to DV
elements to support identiﬁcation of DV nodes
which are based on speciﬁc elements of the De-
sign Model.
• Links from DV elements to Quality Model ele-
ments to support acquisition of traces from the
prior estimates of the DV to the relevant quality
indicators.
• Links to external information sources (documents,
cost information, proﬁt information, usage proﬁle,
indicator deﬁnitions, indicator values, measure-
ments, domain expert judgments) used during the
development of DV structure and estimation of
the parameters to support documenting the traces
from the DV to the more detailed information
sources available outside the prediction models.
• Links to rationale and assumptions for:
– Design Model elements
– the semantics of the DV elements
– the structure of the DVs
– prior parameter estimates of the DVs
The objective of these links is to support docu-
menting the relevant aspects of the development of
the prediction models, particularly the understand-
ing and interpretations that the models are based
on. Part of rationale and assumptions are also
speciﬁcations of the acceptable values of quality
characteristic fulﬁllment (also called quality char-
acteristic fulﬁllment acceptance criteria/levels) as
well as validity of input and models w.r.t. time
(timing validity applies to Design Model and the
DVs).
2) The traceability approach should have facilities for
both searching with model types and model elements
as input parameters, as well as for reporting linked
elements and the link properties
3) The traceability approach should be ﬂexible with re-
spect to granularity of trace information
4) The traceability approach should be practically appli-
cable on real-life applications of PREDIQT
These needs are in the sequel referred to as the success
criteria for the traceability approach in PREDIQT.
VI. TRACEABILITY SCHEME
We propose a traceability scheme in the form of a meta-
model for trace-link information and a feature diagram for
capabilities of the solution. The traceability scheme speciﬁes
the needs regarding the information that should be traced
and the capabilities of the traceability approach. Thus, our
traceability scheme is based on the guidelines for application
of the prediction models and the success criteria for the
traceability approach speciﬁed in the two previous respective
sections.
The types of the trace-links and the types of the traceable
elements are directly extracted from Success Criterion 1 and
represented through a meta-model shown by Figure 4. The
Element abstract class represents a generalization of a trace-
able element. The Element abstract class is specialized into
the ﬁve kinds of traceable elements: Design Model Element,
DV Element, Quality Model Element, External Information
Source, and Rationale and Assumptions. Similarly, the Trace
Link abstract class represents a generalization of a trace-link
and may be assigned a rationale for the trace-link. The Trace
Link abstract class is specialized into the six kinds of trace-
links.
11
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Element
Rationale for Trace Link
Trace Link
Design Model 
Element 
Dependency 
View Element
Quality Model 
Element
External 
Information 
Source
Rationale and 
Assumptions 
Design Model Element 
to Design Model 
Element
Design Model Element 
to Dependency View 
Element
Dependency View 
Element to Quality 
Model Element
Design Model Element to 
Rationale and Assumptions
Structure, Parameter or 
Semantics of Dependency View 
Element documented through 
Rationale and Assumptions
Structure or Parameter of 
Dependency View Element 
documented through External 
Information Source
Target
Origin
*
*
Target
Origin
*
*
Origin
*
Target
*
Origin
Target
*
*
Origin
Target
*
*
Origin
Target
*
*
Origin
Target
*
*
Figure 4.
A meta model for trace-link information, expressed as a UML
class diagram
Pairs of certain kinds of traceable elements form binary
relations in the form of unidirectional trace-links. Such
relations are represented by the UML-speciﬁc notations
called association classes (a class connected by a dotted
line to a link which connects two classes). For example,
trace-links of type Design Model Element to Design Model
Element may be formed from a Design Model Element to
a Dependency View Element. The link is annotated by the
origin (the traceable element that the trace-link goes from)
and the target (the traceable element that the trace-link goes
to) in order to indicate the direction. Since only distinct pairs
(single instances) of the traceable elements (of the kinds
involved in the respective trace-links deﬁned in Figure 4) can
be involved in the associated speciﬁc kinds of trace-links,
uniqueness (property of UML association classes) is present
in the deﬁned trace-links. Due to the binary relations (arity
of value 2) in the deﬁned trace-links between the traceable
elements, only two elements can be involved in any trace-
link. Furthermore, multiplicity of all the traceable elements
involved in the trace-links deﬁned is of type “many,” since
an element can participate in multiple associations (given
they are deﬁned by the meta-model and unique).
The main capabilities needed are represented through a
feature diagram [11] shown by Figure 5. Storage of trace-
links may be internal or external, relative to the prediction
models. A traceable element may be of type prediction
model element (see Figure 3) or non-model element. Report-
ing and searching functionality has to be supported. Trace-
link info has to include link direction, link meta-data (e.g.,
date, creator, strength) and cardinality (note that all links are
binary, but a single element can be origin or target for more
than one trace-link). Typing at the origin and the target ends
of a trace-link, as well as documenting the rationale for the
trace-link, are optional.
VII. EXAMPLE-DRIVEN SOLUTION
This section presents the main aspects of our traceability
approach for PREDIQT. We focus particularly on traceabil-
ity of indicators by elaborating on the role of indicators in
the Quality Model and the DVs and proposing a template
for speciﬁcation of indicators. Moreover, we elaborate on
how to specify quality characteristic fulﬁllment acceptance
criteria within the traceability approach. This is followed by
a proposal for how to handle validity of models w.r.t time
in the form of model versions. Furthermore, traceability of
cost and proﬁt information is discussed. Our traceability
approach also includes handling of usage proﬁle in the
prediction models. The usage proﬁle handling is presented
before proposing how to visualize the impacts of the dif-
ferent the decision alternatives on quality characteristics,
cost and proﬁt. Additionally, a prototype traceability tool
for trace-link management, implementing the needs speciﬁed
through the traceability scheme, is presented. Finally, we
propose the preliminary steps for integration of the prototype
traceability tool with the existing PREDIQT tool.
A. Traceability of indicators
As stated above in relation to Success Criterion 1, links to
external information sources include deﬁnitions and values
of indicators. In PREDIQT, indicators are used as a part of
the Quality Model in order to deﬁne the quality notions for
the system being considered. The Quality Model, however,
only deﬁnes the meaning of the terminology (i.e., quantita-
tive and qualitative aspects of the quality notions speciﬁc to
the target of analysis). Therefore, in addition to the Quality
Model, indicator deﬁnitions and values are also associated
with the DVs, through the traceability information. The
indicators deﬁned in relation to the DVs may be the same or
additional w.r.t. the ones deﬁned in the Quality Model. The
reason for this is the fact that the DVs are an instantiation
of the architectural dependency speciﬁc to the system in
question. Hence, indicators may be attached to both QCFs
and EIs at any part of the DVs. Most common use of an
12
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Tracing in PREDIQT
Traceable element
Link meta-data
Typed
Untyped
Link direction
Cardinality 0..*
Typing
Trace-link info
Storage
Internal
External
Non-model element
Model element
Reporting
Searching
Legend
mandatory
optional
alternative
Rationale
Assumptions
External information source
Rationale for trace link
Figure 5.
Main capabilities of the traceability approach, expressed as a feature diagram
indicator in the DV context is in relation to a leaf node
QCF, where the indicator serves as a partial evaluator of
the QCF value. The indicator value may be subject to
dynamic change. The relationship between the indicator and
the QCF may be linear or non-linear, and a mapping function
should be deﬁned. There may also be exceptions concerning
the impact of the indicator value on the QCF which the
indicator is related to. Moreover, one indicator may be
related to several DV parameters. The dynamics of the
indicators, their measurability in terms of empirical input,
the loose relationship with the DV parameters, their possible
relationship with several DV parameters simultaneously, and
possible deviation of the mapping function from the general
DV propagation model, distinguish the indicators from the
regular DV parameters.
In order to make the indicator speciﬁcation and evaluation
as precise and streamlined as possible, we propose a tem-
plate for speciﬁcation of indicators, as well as a template
for documenting the indicator measurement results. Table I
provides a template for the speciﬁcation of an indicator.
The ﬁrst column lists the names of the attributes relevant
for the speciﬁcation, while the second column provides the
explanation and the guidelines regarding the input needed.
Not all the attributes will be as relevant in a practical
context. For example, the ISO 9126 product quality standard
[18] deﬁnes a set of quality characteristic metrics using
a similar but smaller set of attributes. The precision of
the speciﬁcation will also depend on how automatized the
acquisition of the indicator values is, as well as how often
the indicator values have to be retrieved. For example, a
real-time monitoring environment automatically collecting
dynamic indicators in order to capture irregularities in mea-
surement patterns, will depend on a more precise deﬁnition
of an indicator than a static value being evaluated between
long intervals. Importance of the indicator also depends on
the impact of its value (and the related DV parameter) on the
rest of the model, acceptance values for the quality levels
propagated, as well as the effect of the uncertainty on the
rest of the model.
Table II provides a template for documenting the revision
history concerning an indicator speciﬁcation (deﬁned in
Table I). The relevant information regarding the revision of
a speciﬁcation is included here. The ﬁrst column lists the
names of the attributes relevant for the revision history, while
the second column provides the explanation and guidelines
regarding the input needed.
Table III provides a template for documenting the mea-
surement history of an indicator (speciﬁed through the
template in Table I). Each measurement is documented, and
the value in the ﬁrst attribute represents the instantiation of
the indicator according to its latest speciﬁcation.
Both the speciﬁcation and the instantiation of an indicator
has to be documented by a traceability approach. The
process of identifying the relevant indicators and specifying
them is a part of the development of the Quality Model
and the DVs. The measurement of the indicator values is
however only relevant in the context of the development,
validation and application of the DVs. Therefore, Table I
and Table II may be used in relation to both the Quality
Model and the DVs, while Table III will only be used in the
DV context.
B. Traceability of quality characteristic fulﬁllment accep-
tance levels
As mentioned in relation to Success Criterion 1, a part
of the trace-link information regarding the rationale and
assumptions are also speciﬁcations of the acceptable values
of quality characteristic fulﬁllment. This basically means
that for each quality characteristic deﬁned in the Quality
Model and instantiated through a DV, the acceptance levels
for the QCF of the DV root node should be deﬁned. As the
acceptance level may vary at the different levels of a DV,
it may also be deﬁned w.r.t. other nodes than the root. The
intervals between the acceptance levels depend on the risk
attitude and the utility function of the decision maker, as well
as on the predeﬁned goals of the organization/stakeholders.
The advantage of deﬁning the acceptance levels at the
different nodes of a DV, is that early symptoms of irregular-
ities or weaknesses can be captured by the model (as a part
of, for example, run-time monitoring where indicator values
are mapped to the DV-parameters), instead of waiting until
a signiﬁcant deviation has been propagated on the root node
and then detected in relation to a higher abstraction level. In
practice, this means that the acceptance scale can be even
13
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Table I
TEMPLATE FOR SPECIFICATION OF AN INDICATOR
Speciﬁcation attributes for the indicator
Explanation of the speciﬁcation attributes
Unique indicator id
Give each indicator a unique identiﬁer.
Name of the indicator
State a concise, result-oriented name for the indicator. The name should reﬂect what the indicator
expresses.
Deﬁnition
Specify the qualitative and the quantitative deﬁnition of the indicator. The deﬁnition should
include the qualitative and the quantitative deﬁnitions of the variables.
Created by
Specify the name and the afﬁliation of the person that the indicator has been speciﬁed by.
Date created
Specify the date for the speciﬁcation of the indicator.
Purpose of the indicator
Specify the purpose of the indicator, i.e., what it will be used for.
Assumptions
Specify any assumptions made for the indicator speciﬁcation and its values.
Measurement guidelines
Specify how to obtain the indicator values and who is responsible for that.
Data source
Specify where the indicator values are stored, or where they are to be retrieved or measured
from.
Measurement frequency
Specify how often the indicator values should be retrieved.
Trigger for measurement
Identify the events, states or values that initiate a new measurement of this indicator.
Preconditions
List any activities that must take place, or any conditions that must be true, before the indicator
can be measured. Number each precondition sequentially.
Postconditions
Describe the state of the system at the conclusion of the indicator measurement. Number each
postcondition sequentially.
Expected change frequency
Specify how often the value of the indicator is expected to change, i.e., the dynamics of the
indicator.
Unit of measure
Specify the unit of measure of the indicator.
Interpretation of the value measured
Specify which indicator values are: preferred, realistic, extreme, within the normal range, and
on the border to the unacceptable.
Scale
Provide the scale that should be used for the indicator measurement. (Scale types: nominal,
ordinal, interval, or ratio).
Uncertainty
Specify degree of uncertainty and sources of uncertainty. Express uncertainty in the form of
interval, conﬁdence level, variance or similar.
How related to the relevant diagram parameters
(function and instantiation coefﬁcients)
Specify which diagrams and parameters of the diagrams the indicator is related to. Specify
the mapping function, any exceptions and what values the possible coefﬁcients of the indicator
function should be instantiated with.
Notes and issues
Specify any additional notes or issues.
Table II
TEMPLATE FOR DOCUMENTING REVISION HISTORY CONCERNING AN INDICATOR SPECIFICATION
Revision attributes
Explanation of the revision attributes
Speciﬁcation last updated by
Provide the name of the person who was the last one to update the speciﬁcation.
Speciﬁcation last updated date
Provide the date when the speciﬁcation was last updated.
Reason for changes
Provide the reason to the update.
Version
Provide a version number of the speciﬁcation.
Table III
TEMPLATE FOR DOCUMENTING MEASUREMENT HISTORY CONCERNING AN INDICATOR
Measurement attributes
Explanation of the measurement attributes
Measured value
Provide the indicator value from the latest measurement.
Measured by
Provide the name of the person/service that the measurement was performed by.
Date of measurement
Provide the date/time of the measurement.
Remarks
Provide and any additional info if appropriate.
more ﬁne grained and more context speciﬁc, when mapped
to several abstraction levels of a DV.
Note that the length of the intervals between the different
acceptance levels may very signiﬁcantly. Note also that the
interpretation of a certain value of a quality characteristic (as
deﬁned through the Quality Model) is constant, while what
is the acceptable value may vary, depending on which DV
node a QCF is related to. Therefore, acceptance level and
interpretation of a QCF value are two different notions. It is
up to the stakeholders (mainly the decision makers) how
ﬁne or coarse grained the acceptance scale for a quality
characteristic fulﬁllment (at the selected parts of a DV)
should be. An example of a speciﬁcation of the acceptance
levels for root node QCF (always ranging between 0 and 1)
of a DV representing quality characteristic availability is:
• 0.999≤QCF – Very good
• 0.990≤QCF<0.999 – Acceptable and compliant with
the SLA goals
• 0.90≤QCF<0.990 – According to the sector standards,
but not sufﬁciently high for all services
14
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

• QCF<0.90 – Not acceptable
Consolidated traceability information regarding interval
speciﬁcation, interval measurement and the acceptance lev-
els, allows for relating the interval values to the acceptance
levels of the QCFs. Therefore, the sensitivity and dynamics
(i.e., the frequency of change) of the indicator value, as
well as the granularity of the acceptance level of the related
QCF, will be among the factors inﬂuencing how often the
indicator value should be measured in order to capture the
irregular patterns and generally achieve the observability of
the system and its aimed quality fulﬁllment level.
C. Traceability of model versions
As mentioned in relation to Success Criterion 1, a part
of the trace-link information regarding the rationale and
assumptions is also an explicit speciﬁcation of validity of
the input and the models w.r.t. time. The objective is to
document when and for how long a model version of ele-
ments/parameters of a model are valid. The timing validity
in the PREDIQT context applies to the Design Model and
the DVs; the Quality Model is assumed to be static.
In order to address the timing aspect in the prediction
models, we introduce the model versioning. A model or
a trace-link information which has time-dependent validity
is annotated with the versions which are valid at speciﬁed
intervals of time. As such, versioning of both the Design
Model and the DVs as well as versioning of the traceability
info, is a tool for mapping the states of the system to the
time.
The degree of the variation of models over time provides
understanding of the needs for scalability as well as the
overhead related to maintenance of an architecture. The
reason is that an architecture which seems to be optimal at a
certain point of time, may not represent the generally optimal
solution, due to the changes expected in the long term.
Therefore, in order to accommodate the long-term needs for
scaling and adoptions, the relevant prediction models should
be speciﬁed in terms of their time-dependent versions.
To support versioning, a set of attributes should be added
to a trace-link or a model. Table IV presents the attributes
needed and provides a template for speciﬁcation of timing
validity of models and trace-links. Not all the attributes
speciﬁed will be as relevant in a practical context, but
among the mandatory ﬁelds should be: “applies to trace-
link element”, “version number”, and at least one of the
following: “valid from”, “valid until”, “precondition for
validity”, “postcondition for validity.”
D. Traceability of cost and proﬁt information
As stated above in relation to Success Criterion 1, links to
external information sources also include cost information.
Often, the decision making around the architecture design
alternatives has to take into account not only impact of
changes on quality characteristics, but also on cost and proﬁt.
We argue that the traceability approach in the PREDIQT
context can accommodate such a multi-dimensional cost-
beneﬁt analysis.
A prerequisite for including cost in the prediction models,
is a cost model. By cost we mean a monetary amount that
represents the value of resources that have to be used in
relation to a treatment or deployment of a measure. A cost
model should deﬁne and decompose the notion of cost for
the architecture in question. As such, the cost model will
have the same role in the context of cost, that the Quality
Model has in the context of quality. An example of a Cost
Model is shown in Figure 6. The rightmost nodes represent
possible indicators, which should be speciﬁed using Table I
and Table II. The decomposition of the cost notions is
based on the architecture design models, and particularly
the process models related to the deployment of a measure.
Once the cost notions are deﬁned and decomposed, the
cost information may be added in the form of trace-link
information and attached to the relevant parts of the DVs.
A preferred way of instantiating the cost model, is however
by developing a dedicated DV for cost, according to the
same principles as the ones used for developing quality
characteristic speciﬁc DVs. Thus, cost will become a new
explicit and separate concern, treated equally as each qual-
ity characteristic. Consequently, the cost speciﬁc DVs will
provide predictions of impact of changes on monetary cost.
However, the proﬁt may also be of monetary kind and
it will not necessarily only be related to improved quality
characteristics. Therefore, the proﬁt should be treated in the
same manner as cost and the respective quality character-
istics, i.e., as a separate concern in the form of a Proﬁt
Model and a dedicated DV. Finally, the beneﬁt of a decision
alternative should be represented as a function of both the
cost and the proﬁt according to a speciﬁed utility function.
E. Traceability of usage proﬁle
As mentioned in relation to Success Criterion 1, usage
proﬁle is a part of the trace-link information classiﬁed
under the external information sources. Some of the DV
parameters are in fact based on the usage proﬁle. For
example, the expected licensing costs as well as scalability
needs, may be subject to to the usage proﬁle. Moreover, the
uncertainty of the estimates will be based on to what degree
the usage proﬁle is known and relevant for the parameters
under consideration. Most importantly, when considering
the alternative solutions for deployment of an architecture
design, the usage proﬁle information will be crucial, in
order to meet the needs for accommodating the operational
environment to the expected usage. The characteristics of the
usage proﬁle should be speciﬁed in terms of for example:
• number of clients
• number of servers
• number of data messages
• number of logons
15
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Table IV
TEMPLATE FOR DOCUMENTING TIMING VALIDITY OF MODELS AND TRACE-LINKS
Validity relevant attributes
Explanation of attributes
Applies to trace-link element
Specify which trace-link element this version speciﬁcation applies to.
Version number
Provide a unique version number.
Valid from
Specify exactly when the trace-link or the model element in question is valid from.
Valid until
Specify exactly when the trace-link or the model element in question is valid until.
Precondition for validity
List any events or states that must take place, or any conditions that must be true, before this
version can become valid. Number each precondition sequentially.
Postcondition for validity
Describe any events or states at the conclusion of the validity of this version. Number each
postcondition sequentially.
Preceding version
If appropriate, specify which version should be succeeded by this one.
Version which succeeds this one
If appropriate, specify the version that should become valid after this one.
Rationale for the timing limitation
Explain and substantiate why the validity of this trace-link element is limited w.r.t. time.
Assumptions for the validity
Specify the assumptions for this speciﬁcation, if any.
Cost
Cost of software
I: Cost of software integration
I: Cost of software development
I: Cost of licencing
Cost of hardware 
I: Cost of hardware maintenance
I: Cost of hardware purchase
Cost of operation
I: Cost of service provider
I: Cost of daily usage
Cost of personnel
I: Cost of user training
I: Cost of personnel for requirements specification
I: Cost of personnel for testing and verification
I: Cost of personnel for contracting
I: Cost of internal/external competence 
Figure 6.
An example of a cost model
• number of users
• number of retrievals per user and per unit of time
• size of messages.
F. Visualization of the decision alternatives
Once the complete prediction models have been devel-
oped with the trace-link information, the application of the
prediction models will result in predictions w.r.t three kinds
of concerns:
• each quality characteristic as deﬁned by the Quality
Model
• cost as deﬁned by the Cost Model
• proﬁt as deﬁned by the Proﬁt Model.
As a result, the impacts of a decision alternative w.r.t.
the current values of these three kinds of concerns may be
difﬁcult to compare. In order to facilitate the comparison,
we propose a tabular visualization of the impacts of the
alternative design decisions on each quality characteristic,
as well as cost and proﬁt. A simpliﬁed example of such a
representation is illustrated in Table V. Thus, we distinguish
between alternatives based on:
• value of each quality characteristic (i.e., the root node
QCF of each quality characteristic speciﬁc DV)
• cost value (i.e., the root node value of the cost speciﬁc
DV)
• proﬁt value (i.e., the root node value of the proﬁt
speciﬁc DV).
In order to compare the alternatives with the current solution,
one should take into account the risk attitude and the utility
function of the decision maker. A simple way of doing
this, is by weighting the quality characteristics, cost and
proﬁt with respect to each other. The constraints of the
utility function will be the quality characteristic fulﬁllment
acceptance levels, proposed in Section VII-B.
G. Prototype traceability tool
We have developed a prototype traceability tool in the
form of a database application with user interfaces, on the
top of Microsoft Access [24]. Similarly as for the ﬁrst
version of the PREDIQT tool, the proprietary development
environment (Microsoft Access) was found suitable since
it offers a rather simple and sufﬁcient toolbox for quick
prototyping of the proof-of-concept. A later version of the
traceability tool may however use another (open source
or similar) environment. The current prototype traceability
tool includes a structure of tables for organizing the trace
16
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Table V
A POSSIBLE VISUALIZATION OF THE IMPACTS OF THE DIFFERENT ARCHITECTURE DESIGN ALTERNATIVES ON QUALITY, COST AND PROFIT
Architecture design alternative
Availability QCF
Scalability QCF
Usability QCF
Cost
Proﬁt
Current architecture
0.999
0.90
0.95
85 000 EUR
120 000 EUR
Alternative 1
0.92
0.95
0.80
55 000 EUR
85 000 EUR
Alternative 2
0.90
0.85
0.99
60 000 EUR
90 000 EUR
Alternative 3
0.85
0.99
0.90
95 000 EUR
130 000 EUR
Figure 7.
Entity-relationship diagram of the trace-link database of the prototype traceability tool
information, queries for retrieval of the trace info, a menu
for managing work ﬂow, forms for populating trace-link
information, and facilities for reporting trace-links. A screen
shot of the entity-relationship (ER) diagram of the trace-
link database is shown by Figure 7. The ER diagram
is normalized, which means that the data are organized
with minimal needs for repeating the entries in the tables.
Consistency checks are performed on the referenced ﬁelds.
The data structure itself (represented by the ER diagram)
does not cover all the constraints imposed by the meta-
model (shown by Figure 4). However, constraints on queries
and forms as well as macros can be added in order to fully
implement the logic, such as for example which element
types can be related to which trace-link types.
The ﬁve traceable element types deﬁned by Figure 4
and their properties (name of creator, date, assumption
and comment), are listed in Table TraceableElementType.
Similarly, the six trace-link types deﬁned by Figure 4 and
their properties (scope, date, creator and comment), are listed
in Table TraceLinkType. Table TraceableElement speciﬁes
the concrete instances of the traceable elements, and assigns
properties (such as the pre-deﬁned element type, hyperlink,
creator, date, etc.) to each one of them. Since primary
key attribute in Table TraceableElementType is foreign key
in Table TraceableElement, multiplicity between the two
respective tables is one-to-many.
Most of the properties are optional, and deduced based on:
i) the core questions to be answered by traceability scheme
[11] and ii) the needs for using guidelines for application
of prediction models, speciﬁed in Section IV. The three
Tables TargetElements, OriginElements and TraceLink to-
gether specify the concrete instances of trace-links. Each
link is binary, and directed from a concrete pre-deﬁned
traceable element – the origin element speciﬁed in Table
OriginElements, to a concrete pre-deﬁned traceable element
– the target element speciﬁed in Table TargetElements. The
trace-link itself (between the origin and the target element)
and its properties (such as pre-deﬁned trace-link type)
are speciﬁed in Table TraceLink. Attribute TraceLinkName
(associated with a unique TraceLinkId value) connects the
three tables TraceLink, OriginElements and TargetElements
when representing a single trace-link instance, thus forming
a cross-product when relating the three tables. The MS
Access environment performs reference checks on the cross
products, as well as on the values of the foreign key
attributes. Target elements and origin elements participating
17
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 8.
A screen shot of the start menu of the prototype traceability
tool
in a trace-link, are instances of traceable elements deﬁned
in Table TraceableElement. They are connected through the
Attribute ElementId. Note that in the Tables OriginElements
and TargetElements, the Attribute ElementId has the role
of a foreign key and is displayed as ElementName. In
Tables OriginElements and TargetElements, the Element-
Name is through the ElementId retrieved from the Table
TraceableElement and therefore exactly the same as the one
in the table it originates from (i.e., TraceableElement). Thus,
multiplicity between Table TraceableElement and Table Tar-
getElements, as well as between Table TraceableElement
and Table OriginElements, is one-to-many. Similarly, since
primary key attribute in Table TraceLinkType is foreign key
in Table TraceLink, multiplicity between the two respective
tables is one-to-many.
A screen shot of the start menu is shown by Figure 8.
The sequence of the buttons represents a typical sequence
of actions of an end-user (the analyst), in the context
of deﬁning, documenting and using the trace-links. The
basic deﬁnition of the types of the traceable elements and
the trace-links are provided ﬁrst. Then, concrete traceable
elements are documented, before deﬁning speciﬁc instances
of the trace-links and their associated speciﬁc origin and
target elements, involved in the binary trace-link relations.
Finally, reports can be obtained, based on search parameters
such as for example model types, model elements, or trace-
link types.
H. Integrating the prototype traceability tool with the exist-
ing PREDIQT tool
In order to fully beneﬁt from the traceability approach,
the prototype traceability tool should be integrated with the
existing PREDIQT tool. In addition, the traceability tool
should be extended with the indicator templates and the
above proposed visualization of the impacts. The traceability
tool should moreover guide the user in the PREDIQT
process and verify that the necessary prerequisites for each
phase are fulﬁlled. The result should be seamless handling of
the trace-link information in the traceability tool during the
simultaneous development and use of DVs in the PREDIQT
tool. Moreover, exchange of the trace-link information be-
tween the traceability tool and the PREDIQT tool, as well
as a consolidated quality-cost-proﬁt visualization of the
decision alternatives in an integrated tool, is needed.
A preliminary result is exempliﬁed in Figure 9, which
shows a screen shot of the existing PREDIQT tool. The
trace-link information is shown on demand. In this partic-
ular illustrative example with ﬁctitious values, the user is
evaluating the beneﬁt of increasing the QCF of the root
node by 0.006 (i.e., from 0.919 to 0.925). To this end, he is
comparing cost of two possible alternatives: increase QCF
of “Message Routing” by 0.04 (i.e., from 0.93 to 0.97), or
increase of “Performance of the related services” by 0.025
(i.e., from 0.80 to 0.825). Both alternatives have the same
impact on the root node QCF, but the cost of the measures
(or treatments) related to achievement of the two alternatives,
is different. Note that the cost information is a part of the
trace-link information and not explicitly displayed on the DV
shown in Figure 9. The integration of the traceability tool
with the existing PREDIQT tool should therefore involve
exchange of standardized messages regarding the trace-
link information, functionality for running queries from the
existing PREDIQT tool, and possibility of retrieving the
prediction model elements (stored in the PREDIQT tool)
from the traceability tool.
VIII. SUMMARY OF EXPERIENCES FROM APPLYING A
PART OF THE SOLUTION ON PREDICTION MODELS FROM
AN INDUSTRIAL CASE STUDY
This section reports on the results from applying our tool-
supported traceability approach on prediction models, which
were originally developed and applied during a PREDIQT-
based analysis [5] on a real-life industrial system. The anal-
ysis targeted a system for managing validation of electronic
certiﬁcates and signatures worldwide. The system analyzed
was a so-called “Validation Authority” (VA) for evaluation
of electronic identiﬁers (certiﬁcates and signatures) world-
wide. In that case study, the prediction models were applied
for simulation of impacts of 14 speciﬁed architecture design
changes on the VA quality. Each speciﬁed architecture
design change was ﬁrst applied on the affected parts of
the Design Model, followed by the conceptual model and
ﬁnally the DVs. Some of the changes (e.g., change 1) ad-
dressed speciﬁc architecture design aspects, others referred
to the system in general, while the overall changes (e.g.,
changes 6 through 14) addressed parameter speciﬁcations
of the DVs. The speciﬁcation suggested each change being
independently applied on the approved prediction models.
The trace-link information was documented in the proto-
type traceability tool, in relation to the model development.
The trace-links were applied during change application,
18
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 9.
An illustrative example (with ﬁctitious values) of displaying the trace-links in the PREDIQT tool
19
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 10.
A screen shot of an extract of a trace-link report from the
prototype traceability tool
according to the guidelines for application of prediction
models, speciﬁed in Section IV. We present the experiences
obtained, while the process of documentation of the trace-
links is beyond the scope of this paper.
The prediction models involved are the ones related to
“Split signature veriﬁcation component into two redundant
components, with load balancing”, corresponding to Change
1 in Omerovic et al. [5]. Three Design Model diagrams
were affected, and one, two and one model element on
each, respectively. We have tried out the prototype trace-
ability tool on the Design Model diagrams involved, as
well as Availability (which was one of the three quality
characteristics analyzed) related Quality Model diagrams
and DV. Documentation of the trace-links involved within
the Availability quality characteristic (as deﬁned by the
Quality Model) scope, took approximately three hours. Most
of the time was spent on actually typing the names of the
traceable elements and the trace-links.
18 instances of traceable elements were registered in the
database during the trial: seven Quality Model elements,
four DV elements, four Design Model elements and three
elements of type “Rationale and Assumptions”. 12 trace-
links were recorded: three trace-links of type “Design Model
Element to Design Model Element”, three trace-links of type
“Design Model Element to DV Element”, one trace-link of
type “Design Model Element to Rationale and Assump-
tions”, three trace-links of type “DV Element to Quality
Model Element”, and two trace-links of type “Structure,
Parameter or Semantics of DV Element Documented through
Rationale and Assumptions”, were documented.
An extract of a screen shot of a trace-link report (ob-
tained from the prototype traceability tool) is shown by
Figure 10. The report included: three out of three needed
(i.e., actually existing, regardless if they are recorded in
the trace-link database) “Design Model Element to Design
Model Element” links, three out of four needed “Design
Model Element to DV Element” links, one out of one needed
“Design Model Element to Rationale and Assumptions”
link, three out of six needed “DV Element to Quality
Model Element” links and one out of one needed “Structure,
Parameter or Semantics of DV Element Documented through
Rationale and Assumptions” link.
Best effort was made to document the appropriate trace-
links without taking into consideration any knowledge of
exactly which of them would be used when applying the
change. The use of the trace-links along with the application
of change on the prediction models took totally 20 minutes
and resulted in the same predictions (change propagation
paths and values of QCF estimates on the Availability DV),
as in the original case study [5]. Without the guidelines
and the trace-link report, the change application would have
taken approximately double that time for the same user.
All documented trace-links were relevant and used during
the application of the change, and about 73% of the relevant
trace-links could be retrieved from the prototype traceability
tool. Considering however the importance and the role of
the retrievable trace-links, the percentage should increase
considerably.
Although hyperlinks are included as meta-data in the
user interface for element registration, an improved solu-
tion should include interfaces for automatic import of the
element names from the prediction models, as well as user
interfaces for easy (graphical) trace-link generations between
the existing elements. This would also aid veriﬁcation of the
element names.
IX. WHY OUR SOLUTION IS A GOOD ONE
This section argues that the approach presented above
fulﬁlls the success criteria speciﬁed in Section V.
A. Success Criterion 1
The traceability scheme and the prototype traceability
tool capture the kinds of trace-links and traceable elements,
speciﬁed in the Success Criterion 1. The types of trace-
links and traceable elements as well as their properties, are
speciﬁed in dedicated tables in the database of the prototype
traceability tool. This allows constraining the types of the
trace-links and the types of the traceable elements to only
the ones deﬁned, or extending their number or deﬁnitions,
if needed. The trace-links in the prototype traceability tool
are binary and unidirectional, as required by the traceabil-
ity scheme. Macros and constraints can be added in the
tool, to implement any additional logic regarding trace-
links, traceable elements, or their respective type deﬁnitions
and relations. The data properties (e.g., date, hyperlink, or
creator) required by the user interface, allow full traceability
of the data registered in the database of the prototype
traceability tool.
B. Success Criterion 2
Searching based on user input, selectable values from a
list of pre-deﬁned parameters, or comparison of one or more
database ﬁelds, are relatively simple and fully supported
20
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

based on queries in MS Access. Customized reports can
be produced with results of any query and show any infor-
mation registered in the database. The report, an extract of
which is presented in Section VIII, is based on a query of
all documented trace-links and the related elements.
C. Success Criterion 3
The text-based ﬁelds for documenting the concrete in-
stances of the traceable elements and the trace-links, allow
level of detail selectable by the user. Only a subset of ﬁelds
is mandatory for providing the necessary trace-link data. The
optional ﬁelds in the tables can be used for providing addi-
tional information such as for example rationale, comments,
links to external information sources, attachments, strength
or dependency. There are no restrictions as to what can be
considered as a traceable element, as long at it belongs to one
of the element types deﬁned by Figure 4. Similarly, there are
no restrictions as to what can be considered as a trace-link,
as long at it belongs to one of the trace-link types deﬁned
by Figure 4. The amount of information provided regarding
the naming and the meta-data, are selectable by the user.
D. Success Criterion 4
As argued, the models and the change speciﬁcation
originate from a real-life industrial case study in which
PREDIQT was entirely applied on a comprehensive sys-
tem for managing validation of electronic certiﬁcates and
signatures worldwide (a so-called “Validation Authority”).
Several essential aspects characterize the application of the
approach presented in Section VIII:
• the realism of the prediction models involved in the
example
• the size and complexity of the target system addressed
by the prediction models
• the representativeness of the change applied to the
prediction models
• the simplicity of the prototype traceability tool with
respect to both the user interfaces and the notions
involved
• the time spent on documenting and using the trace-links
Overall, these aspects indicate the applicability of our so-
lution on real-life applications of PREDIQT, with limited
resources and by an average user (in the role of the analyst).
The predictions (change propagation paths and values
of QCF estimates) we obtained during the application of
our solution on the example were the same as the ones
from the original case study [5] (performed in year 2008),
which the models stem from. Although the same analyst
has been involved in both, the results (i.e., the fact that the
same predictions were obtained in both trials in spite of a
rather long time span between them) suggest that other users
should, by following PREDIQT guidelines and applying
the prototype traceability tool, obtain similar results. The
process of application of the models has been documented
in a structured form, so that the outcome of the use of
the prediction models is as little as possible dependent on
the analyst performing the actions. Hence, provided the
fact that the guidelines are followed, the outcome should
be comparable if re-applying the overall changes from the
original case study.
The time spent is to some degree individual and depends
on the understanding of the target system, the models and
the PREDIQT method. It is unknown if the predictions
would have been the same (as in the original case study)
for another user. We do however consider the models and
the change applied during the application of the solution, to
be representative due to their origins from a major real-life
system. Still, practical applicability of our solution will be
subject to future empirical evaluations.
X. WHY OTHER APPROACHES ARE NOT BETTER IN THIS
CONTEXT
This section evaluates the feasibility of other traceability
approaches in the PREDIQT context. Based on our review
of the approach-speciﬁc publications and the results of the
evaluation by Galvao and Goknil [12] of a subset of the
below mentioned approaches, we argue why the alternative
traceability approaches do not perform sufﬁciently on one
or more of the success criteria speciﬁed in Section V.
The evaluation by Galvao and Goknil is conducted with
respect to ﬁve criteria: 1) structures used for representing
the traceability information; 2) mapping of model elements
at different abstraction levels; 3) scalability for large projects
in terms of process, visualization of trace information, and
application to a large amount of model elements; 4) change
impact analysis on the entire system and across the software
development life cycle; and 5) tool support for visualization
and management of traces, as well as for reasoning on the
trace-link information.
Almeida et al. [25] propose an approach aimed at simpli-
fying the management of relationships between requirements
and various design artifacts. A framework which serves as
a basis for tracing requirements, assessing the quality of
model transformation speciﬁcations, meta-models, models
and realizations, is proposed. They use traceability cross-
tables for representing relationships between application
requirements and models. Cross-tables are also applied for
considering different model granularities and identiﬁcation
of conforming transformation speciﬁcations. The approach
does not provide sufﬁcient support for intra-model mapping,
thus failing on our Success Criterion 1. Moreover, possibility
of representing the various types of trace-links and traceable
elements is unclear, although different visualizations on a
cross-table are suggested. Tool support is not available,
which limits applicability of the approach in a practical
setting. Searching and reporting facilities are not available.
Thus, it fails on our Success Criteria 1, 2, and 4.
21
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Event-based Traceability (EBT) is another requirements-
driven traceability approach aimed at automating trace-
link generation and maintenance. Cleland-Huang, Chang
and Christensen [26] present a study which uses EBT for
managing evolutionary change. They link requirements and
other traceable elements, such as design models, through
publish-subscribe relationships. As outlined by Galvao and
Goknil [12], “Instead of establishing direct and tight coupled
links between requirements and dependent entities, links are
established through an event service. First, all artefacts are
registered to the event server by their subscriber manager.
The requirements manager uses its event recognition algo-
rithm to handle the updates in the requirements document
and to publish these changes as event to the event server.
The event server manages some links between the require-
ment and its dependent artefacts by using some information
retrieval algorithms.” The notiﬁcation of events carries struc-
tural and semantic information concerning a change context.
Scalability in a practical setting is the main issue, due to
performance limitation of the EBT server [12]. Moreover,
the approach does not provide sufﬁcient support for intra-
model mapping. Thus, it fails on our Success Criteria 1 and
4.
Cleland-Huang et al. [27] propose the Goal Centric
Traceability (GCT) approach for managing the impact of
change upon the non-functional requirements of a software
system. A Softgoal Interdependency Graph (SIG) is used to
model non-functional requirements and their dependencies.
Additionally, a traceability matrix is constructed to relate
SIG elements to classes. The main weakness of the approach
is the limited tool support, which requires manual work. This
limits both scalability in a practical setting and searching
support (thus failing on our Success Criteria 4 and 2,
respectively). It is unclear to what degree the granularity
of the approach would meet the needs of PREDIQT.
Cleland-Huang and Schmelzer [28] propose another
requirements-driven traceability approach that builds on
EBT. The approach involves a different process for dynami-
cally tracing non-functional requirements to design patterns.
Although more ﬁne grained than EBT, there is no evidence
that the method can be applied with success in a practical
real-life setting (required through our Success Criterion 4).
Searching and reporting facilities (as required through our
Success Criterion 2) are not provided.
Many traceability approaches address trace maintenance.
Cleland-Huang, Chang, and Ge [29] identify the various
change events that occur during requirements evolution and
describe an algorithm to support their automated recognition
through the monitoring of more primitive actions made by a
user upon a requirements set. M¨ader and Gotel [30] propose
an approach to recognize changes to structural UML models
that impact existing traceability relations and, based on that
knowledge, provide a mix of automated and semi-automated
strategies to update the relations. Both approaches focus on
trace maintenance, which is as argued in Section V, not
among the traceability needs in PREDIQT.
Ramesh and Jarke [16] propose another requirements-
driven traceability approach where reference models are
used to represent different levels of traceability information
and links. The granularity of the representation of traces
depends on the expectations of the stakeholders [12]. The
reference models can be implemented in distinct ways
when managing the traceability information. As reported
by Galvao and Goknil [12], “The reference models may
be scalable due to their possible use for traceability activ-
ities in different complexity levels. Therefore, it is unclear
whether this approach lacks scalability with respect to tool
support for large-scale projects or not. The efﬁciency of the
tools which have implemented these meta-models was not
evaluated and the tools are not the focus of the approach.”
In PREDIQT context, the reference models are too broad,
their focus is on requirements traceability, and tool support
is not sufﬁcient with respect to searching and reporting (our
Success Criterion 2).
We could however have tried to use parts of the reference
models by Ramesh and Jarke [16] and provide tool support
based on them. This is done by Mohan and Ramesh [31]
in the context of product and service families. The authors
discuss a knowledge management system, which is based
on the traceability framework by Ramesh and Jarke [16].
The system captures the various design decisions associated
with service family development. The system also traces
commonality and variability in customer requirements to
their corresponding design artifacts. The tool support has
graphical interfaces for documenting decisions. The trace
and design decision capture is illustrated using sample
scenarios from a case study. We have however not been able
to obtain the tool, in order to try it out in our context.
A modeling approach by Egyed [32] represents trace-
ability information in a graph structure called a footprint
graph. Generated traces can relate model elements with other
models, test scenarios or classes [12]. Galvao and Goknil
[12] report on promising scalability of the approach. It is
however unclear to what degree the tool support fulﬁlls our
success criterion regarding searching and reporting, since
semantic information on trace-links and traceable elements
is limited.
Aizenbud-Reshef et al. [33] outline an operational se-
mantics of traceability relationships that capture and rep-
resent traceability information by using a set of semantic
properties, composed of events, conditions and actions [12].
Galvao and Goknil [12] state: the approach does not provide
sufﬁcient support for intra-model mapping; a practical appli-
cation of the approach is not presented; tool support is not
provided; however, it may be scalable since it is associated
with the UML. Hence, it fails on our Success Criteria 1 and
2.
Limon and Garbajosa [34] analyze several traceability
22
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

schemes and propose an initial approach to Traceability
Scheme (TS) speciﬁcation. The TS is composed of a trace-
ability link dataset, a traceability link type set, a minimal
set of traceability links, and a metrics set for the minimal
set of traceability links [12]. Galvao and Goknil [12] argue
that “The TS is not scalable in its current form. Therefore,
the authors outline a strategy that may contribute to its
scalability: to include in the traceability schema a set of
metrics that can be applied for monitoring and verifying
the correctness of traces and their management.” Hence, it
fails with respect to scalability in a practical setting, that
is, our criterion 4. Moreover, there is no tool support for
the employment of the approach, which fails on our success
criterion regarding searching and reporting.
Some approaches [35] [36] [37] that use model trans-
formations can be considered as a mechanism to generate
trace-links. Tool support with transformation functionalities
is in focus, while empirical evidence of applicability and par-
ticularly comprehensibility of the approaches in a practical
setting, is missing. The publications we have retrieved do not
report sufﬁciently on whether these approaches would offer
the searching facilities, the granularity of trace information,
and the scalability needed for use in PREDIQT context (that
is, in a practical setting by an end-user (analyst) who is not
an expert in the tools provided).
XI. CONCLUSION AND FUTURE WORK
Our earlier research indicates the feasibility of the
PREDIQT method for model-based prediction of impacts
of architectural design changes on system quality. The
PREDIQT method produces and applies a multi-layer model
structure, called prediction models, which represent system
design, system quality and the interrelationship between the
two.
Based on the success criteria for a traceability approach
in the PREDIQT context, we put forward a traceability
scheme. Based on this, a solution supported by a prototype
traceability tool is developed. The prototype tool can be
used to deﬁne, document, search for and represent the trace-
links needed. We have argued that our solution offers a
useful and practically applicable support for traceability
handling in the PREDIQT context. The model application
guidelines provided in Section IV complement the prototype
traceability tool and aim to jointly provide the facilities
needed for a schematic application of prediction models.
Performing an analysis of factors such as cost, risk,
and beneﬁt of the trace-links themselves and following the
paradigm of value-based software engineering, would be
relevant in order to stress the effort on the important trace-
links. As argued by Winkler and von Pilgrim [11], if the
value-based paradigm is applied to traceability, cost, beneﬁt,
and risk will have to be determined separately for each trace
according to if, when, and to what level of detail it will be
needed later. This leads to more important artifacts having
higher-quality traceability. There is a trade-off between the
semantically accurate techniques on the one hand and cost-
efﬁcient but less detailed approaches on the other hand.
Finding an optimal compromise is still a research challenge.
Our solution proposes a feasible approach, while ﬁnding the
optimal one is subject to further research.
PREDIQT has only architectural design as the indepen-
dent variable – the Quality Model itself is, once developed,
assumed to remain unchanged. This is of course a simpli-
ﬁcation, since quality characteristic deﬁnitions may vary in
practice. It would be interesting to support variation of the
Quality Model as well, in PREDIQT.
Development of an experience factory, that is, a repository
of the non-conﬁdential and generalizable experiences and
models from earlier analyses, is another direction for future
work. An experience factory from similar domains and
contexts would allow reuse of parts of the prediction models
and potentially increase model quality as well as reduce the
resources needed for a PREDIQT-based analysis.
Further empirical evaluation of our solution is also nec-
essary to test its feasibility on different analysts as well
as its practical applicability in the various domains which
PREDIQT is applied on. Future work should also include
integration of the PREDIQT tool with the traceability tool.
Particularly important is development of standard interfaces
and procedures for updating the traceable elements from the
prediction models into our prototype traceability tool.
As model application phase of PREDIQT dictates which
trace-link information is needed and how it should be used,
the current PREDIQT guidelines focus on the application
of the prediction models. However, since the group of
recorders and the group of users of traces may be distinct,
structured guidelines for recording the traces during the
model development should also be developed as a part of
the future work.
ACKNOWLEDGMENT
This work has been conducted as a part of the DIGIT
(180052/S10) project funded by the Research Council of
Norway, as well as a part of the NESSoS network of
excellence funded by the European Commission within the
7th Framework Programme.
REFERENCES
[1] A. Omerovic and K. Stølen, “Traceability Handling in Model-
based Prediction of System Quality,” in Proceedings of Third
International Conference on Advances in System Simulation,
SIMUL 2011.
IARIA, 2011, pp. 71–80.
[2] A. Omerovic, A. Andresen, H. Grindheim, P. Myrseth,
A. Refsdal, K. Stølen, and J. Ølnes, “A Feasibility Study
in Model Based Prediction of Impact of Changes on System
Quality,” in International Symposium on Engineering Secure
Software and Systems, vol. LNCS 5965.
Springer, 2010, pp.
231–240.
23
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[3] A. Omerovic, B. Solhaug, and K. Stølen, “Evaluation of
Experiences from Applying the PREDIQT Method in an In-
dustrial Case Study,” in Fifth IEEE International Conference
on Secure Software Integration and Reliability Improvement.
IEEE, 2011, pp. 137–146.
[4] A. Omerovic, PREDIQT: A Method for Model-based Predic-
tion of Impacts of Architectural Design Changes on System
Quality.
PhD thesis, Faculty of Mathematics and Natural
Sciences, University of Oslo, 2012.
[5] A. Omerovic, A. Andresen, H. Grindheim, P. Myrseth,
A. Refsdal, K. Stølen, and J. Ølnes, “A Feasibility Study
in Model Based Prediction of Impact of Changes on System
Quality,” SINTEF, Tech. Rep. A13339, 2010.
[6] A. Omerovic and K. Stølen, “Traceability Handling in Model-
based Prediction of System Quality,” SINTEF, Tech. Rep.
A19348, 2011.
[7] A. Knethen and B. Paech, “A Survey on Tracing Approaches
in Practice and Research,” Frauenhofer IESE, Tech. Rep.
095.01/E, 2002.
[8] “Standard Glossary of Software Engineering Terminology:
IEEE Std.610. 12-1990,” 1990.
[9] N. Aizenbud-Reshef, B. T. Nolan, J. Rubin, and Y. Shaham-
Gafni, “Model Traceability,” IBM Syst. J., vol. 45, no. 3, pp.
515–526, 2006.
[10] J. Simpson and E. Weiner, Oxford English Dictionary.
Clarendon Press, 1989, vol. 18, 2nd edn.
[11] S. Winkler and J. von Pilgrim, “A survey of Traceability in
Requirements Engineering and Model-driven Development,”
Software and Systems Modeling, vol. 9, no. 4, pp. 529–565,
2010.
[12] I. Galvao and A. Goknil, “Survey of Traceability Approaches
in Model-Driven Engineering,” in Proceedings of the 11th
IEEE International Enterprise Distributed Object Computing
Conference, 2007.
[13] G. Spanoudakis and A. Zisman, “Software Traceability: A
Roadmap,” in Handbook of Software Engineering and Knowl-
edge Engineering.
World Scientiﬁc Publishing, 2004, pp.
395–428.
[14] R. J. Wieringa, “An Introduction to Requirements Traceabil-
ity,” Faculty of Mathematics and Computer Science, Vrije
Universiteit, Tech. Rep. IR-389, 1995.
[15] N. Anquetil, U. Kulesza, R. Mitschke, A. Moreira, J.-C.
Royer, A. Rummler, and A. Sousa, “A Model-driven Trace-
ability Framework for Software Product Lines,” Software and
Systems Modeling, 2009.
[16] B. Ramesh and M. Jarke, “Toward Reference Models for
Requirements Traceability,” IEEE Transactions on Software
Engineering, vol. 27, no. 1, pp. 58–93, 2001.
[17] S. Bohner and R. Arnold, Software Change Impact Analysis.
IEEE Computer Society Press, 1996.
[18] “International Organisation for Standardisation: ISO/IEC
9126 - Software Engineering – Product Quality,” 2004.
[19] I. Refsdal, Comparison of GMF and Graphiti Based on
Experiences from the Development of the PREDIQT Tool.
University of Oslo, 2011.
[20] J. Rumbaugh, I. Jacobson, and G. Booch, Uniﬁed Modeling
Language Reference Manual.
Pearson Higher Education,
2004.
[21] A. Omerovic and K. Stølen, “A Practical Approach to
Uncertainty Handling and Estimate Acquisition in Model-
based Prediction of System Quality,” International Journal
on Advances in Systems and Measurements, vol. 4, no. 1-2,
pp. 55–70, 2011.
[22] A. Omerovic and K. Solhaug, B. Stølen, “Assessing Practical
Usefulness and Performance of the PREDIQT Method: An
Industrial Case Study,” Information and Software Technology,
vol. 54, pp. 1377–1395, 2012.
[23] A. Omerovic and K. Stølen, “Interval-Based Uncertainty
Handling in Model-Based Prediction of System Quality,” in
Proceedings of Second International Conference on Advances
in System Simulation, SIMUL 2010, August 2010, pp. 99–108.
[24] “Access
Help
and
How-to,”
accessed:
May
19,
2011. [Online]. Available: http://ofﬁce.microsoft.com/en-us/
access-help/
[25] J. P. Almeida, P. v. Eck, and M.-E. Iacob, “Requirements
Traceability and Transformation Conformance in Model-
Driven Development,” in Proceedings of the 10th IEEE
International Enterprise Distributed Object Computing Con-
ference, 2006, pp. 355–366.
[26] J. Cleland-Huang, C. K. Chang, and M. Christensen, “Event-
Based Traceability for Managing Evolutionary Change,”
IEEE Trans. Softw. Eng., vol. 29, pp. 796–810, 2003.
[27] J. Cleland-Huang, R. Settimi, O. BenKhadra, E. Berezhan-
skaya, and S. Christina, “Goal-centric Traceability for Manag-
ing Non-functional Requirements,” in Proceedings of the 27th
International Conference on Software Engineering.
ACM,
2005, pp. 362–371.
[28] J. Cleland-Huang and D. Schmelzer, “Dynamically Tracing
Non-Functional Requirements through Design Pattern Invari-
ants,” in Proceedings of the 2nd International Workshop on
Traceability in Emerging Forms of Software Engineering.
ACM, 2003.
[29] J. Cleland-Huang, C. K. Chang, and Y. Ge, “Supporting
Event Based Traceability through High-Level Recognition
of Change Events,” in 26th Annual International Computer
Software and Applications Conference.
IEEE Computer
Society, 2002, pp. 595–600.
[30] P. M¨ader, O. Gotel, and I. Philippow, “Enabling Automated
Traceability Maintenance through the Upkeep of Traceability
Relations,” in Proceedings of the 5th European Conference on
Model Driven Architecture - Foundations and Applications.
Springer-Verlag, 2009, pp. 174–189.
24
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[31] K. Mohan and B. Ramesh, “Managing Variability with Trace-
ability in Product and Service Families.”
IEEE Computer
Society, 2002, pp. 1309–1317.
[32] A. Egyed, “A Scenario-Driven Approach to Trace Depen-
dency Analysis,” IEEE Transactions on Software Engineer-
ing, vol. 29, no. 2, pp. 116–132, 2003.
[33] N. Aizenbud-Reshef, R. F. Paige, J. Rubin, Y. Shaham-Gafni,
and D. S. Kolovos, “Operational Semantics for Traceability,”
in Proceedings of the ECMDA Traceability Workshop, at
European Conference on Model Driven Architecture, 2005,
pp. 7–14.
[34] A. E. Limon and J. Garbajosa, “The Need for a Unifying
Traceability Scheme,” in 2nd ECMDA-Traceability Workshop,
2005, pp. 47–55.
[35] F. Jouault, “Loosely Coupled Traceability for ATL,” in In
Proceedings of the European Conference on Model Driven
Architecture (ECMDA) workshop on traceability, 2005, pp.
29–37.
[36] D. S. Kolovos, R. F. Paige, and F. Polack, “Merging Models
with the Epsilon Merging Language (EML),” in MoDELS’06,
2006, pp. 215–229.
[37] J. Falleri, M. Huchard, and C. Nebut, “Towards a Traceability
Framework for Model Transformations in Kermeta,” in Pro-
ceedings of the ECMDA Traceability Workshop, at European
Conference on Model Driven Architecture, 2006, pp. 31–40.
25
International Journal on Advances in Systems and Measurements, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/systems_and_measurements/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

