30
International Journal on Advances in Networks and Services, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/networks_and_services/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Object Recognition Using Neural Networks and Complex Reﬂection Signals
Short paper
Hristomir Yordanov∗ and Irina Topalova†
Faculty of German Engineering Education and Industrial Management
Technical University of Soﬁa, Soﬁa, Bulgaria
Emails: ∗yordanov@fdiba.tu-sofia.bg, †itopalova@abv.bg
Abstract—Radar based imaging techniques can be used to
collect 3D information about objects, which in turn can be used
to identify and measure speciﬁc parameters of these objects. Such
measurements need to correlate speciﬁc radar signals with the
object properties. This can be done using neural networks, as
they are designed to search for patterns, which are difﬁcult to
ﬁnd using analytic methods. This work presents a neural network
based reﬂection signal processing system for object identiﬁcation
by attempting to identify an object placed in a rectangular
waveguide. We extract both the phase and the amplitude of the
reﬂected signal and compare recognition systems using amplitude
only and using both phase and amplitude.
Keywords—Scattering signals; Object identiﬁcation; Neural Net-
works
I. INTRODUCTION
Radars ﬁnd many applications as imaging tools. Using the
property of electromagnetic waves to partially penetrate and
partially reﬂect from dielectric materials, they can provide 3D
images of a large set of objects. The development of easily
available high-frequency components up in the microwave,
millimeter wave and even terahertz ranges allows for high
spatial resolution of the obtained images. This technique ﬁnds
multiple applications in security systems, in medical systems
and in agriculture.
We can consider as an example the sensor described in
[2]. The system consists of a 24 GHz Frequency Modulated
Continuous Wave (FMCW) radar used to make 3D images of
grapevine plants in order to estimate the volume of grapes in a
given plant. The radar is equipped with a high gain antenna and
is mounted on a pan-tilt platform, which allows for performing
azimuthal and elevation scans. The radar bandwidth is 2 GHz.
This setup allows for a 7.5 cm depth resolution (that is the
precision of the measurement of the distance between the
object and the radar) and transverse resolution of 1.5 cm. Of
course, using higher signal frequency, bandwidth and more
directive antennas, resolutions in the millimeter range can be
achieved [3].
The processing of the radar signal in order to obtain
information about the object parameters of interest can be a
challenging task. The measurement system described in [2]
relies on statistical analysis in order to obtain the grapes
volume. Neural networks are optimized for pattern search in
complex data. Therefore, they can be used in radar based
measurement systems as they can extract the data of interest
from the clutter and simultaneously estimate the value of the
PSfrag replacements
2r
∆x
∆z
Excitation Port
Open boundary
(a)
PSfrag replacements
2m
∆x
∆z
x
y
z
Excitation Port
Open boundary
(b)
Fig. 1. Positioning of a ball of a diameter 2r (a) and a cube with edge 2m
(b) in a WG-12 rectangular waveguide.
parameter of interest. In the grapevines radar example, the
parameter of interest is the volume of the produced grapes
and the clutter is the signals from the plant’s trunk and leaves.
In order to develop an intelligent 3D image processing
system, we need to start by implementing simple 1D solu-
tions. In this paper, we present a neural network for shape
recognition based on the scattered signal as a benchmark
case study. The investigated object is a body of perfectly
conducting material placed in a rectangular hollow waveguide.
This limits the neural network input signal to the spectral
representation of a single point reﬂection signal. We have
previously presented identifying simple objects using just the
amplitude of the reﬂected signal [1]. In this paper we consider
both the amplitude and the phase of the scattered wave.
The setup has been modeled numerically and the scattering
paarmeters have been obtained using computer simulation.
Section II describes the setup of the performed simulation
and shows the computed reﬂected signals from the two types
of objects in a waveguide. Section III details the neural
network based signal processing used to identify the objects
based on the reﬂected signal. Section II discusses the obtained
experimental results and Section V summarizes the paper and
sketches the future work.
II. EXPERIMENTAL SETUP
The experimental setup consists of a hollow rectangular
WG12 waveguide with an object placed at distance ∆z
form the excitation port, as shown in Figure 1. The cross-
sectional dimensions of the waveguide are a = 47.5 mm

31
International Journal on Advances in Networks and Services, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/networks_and_services/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
4
4.5
5
5.5
6
-6
-5
-4
-3
-2
-1
0
Frequency, GHz
Cube
Reﬂection Coefﬁcient, dB
(a)
4
4.5
5
5.5
6
-12
-10
-8
-6
-4
-2
0
Frequency, GHz
Ball
Reﬂection Coefﬁcient, dB
(b)
Fig. 2. Family of curves showing the magnitude of the reﬂection coefﬁcient
of a waveguide with a conducting cube (a) and a sphere (b) inside. The
solid lines and the dotted lines represent varying position and size of the
sphere respectively.
and b = 22.1 mm. The scattering objects are a sphere of
radius r (Figure 1a) and a cube of length 2m (Figure 1b).
Both objects are made of a perfect electric conductor and
are placed at a distance of ∆x from the short wall of the
conductor. The objects were placed in the middle of the
waveguide in the vertical y direction. The excitation port has
been placed at the −z end of the waveguide. The opposite
end has been terminated with an open boundary in order to
model an inﬁnitely extended waveguide and thus eliminate the
reﬂections from that boundary. The model has been simulated
for the frequency range of 4 to 6 GHz, which corresponds to
the full single mode range of the waveguide. We measure the
reﬂection coefﬁcient at the excitation port. The used simulation
tool is CST Microwave studio.
Two families of results have been generated. First, we varied
the dimensions of the objects—the sphere radius r and the
4
4.5
5
5.5
6
-8
-7
-6
-5
-4
-3
Cube
d̸ Γ/df, rad/GHz
Frequency, GHz
(a)
4
4.5
5
5.5
6
-10
-9
-8
-7
-6
-5
-4
-3
Frequency, GHz
d̸ Γ/df, rad/GHz
Ball
(b)
Fig. 3. Family of curves showing the derivative of the phase with respect to
frequency of the reﬂection coefﬁcient of a waveguide with a conducting
cube (a) and a sphere (b) inside. The solid lines and the dotted lines
represent varying position and size of the sphere respectively.
cube edge 2m respectively—while keeping both objects at
ﬁxed position ∆z = 100 mm and ∆x = a/2, that is 100
mm from the excitation port and in the middle along the x
direction. The size parameters r and m varied from 4 to 10 mm
in 0.6 mm steps. Then, we held the object dimensions ﬁxed at
r, m = 7 mm and varied the offset dimension as follows:
∆z = 0 to − 30 mm in 10 mm steps,
∆x = 0 to 10 mm in 5 mm steps.
The full combination of offset coefﬁcients has been modeled.
We consider both the amplitude and the phase of the re-
ﬂected signal, relative to the incident one. This is deﬁned as the
complex reﬂection coefﬁcient Γ of the perturbed waveguide
[4]. The amplitude and the phase are two independent variables
and we can get more information about the shape of the
object in the waveguide if we consider both of them instead

32
International Journal on Advances in Networks and Services, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/networks_and_services/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
of just one. The information carried by the distribution of the
amplitude of the reﬂection coefﬁcient in frequency Γ(f) can
be extracted straightforward by feeding it directly to a neural
network, as we proceed in Section III. There is an intrinsic
difﬁculty in working with the phase, though, because we can
not distinguish a 2π phase increment: ̸ Γ = ̸ Γ ± n2π. In
other words, the reﬂection coefﬁcient generated by a perfectly
conducting transverse wall, shorting a lossless waveguide, will
be the same as the one when the wall is moved ±λg/2 in
longitudinal direction, where λg is the length of the guided
wave. This can cause signiﬁcant difﬁculties for an intelligent
system, trying to identify the shape of the object irrespective
of the distance of interrogation.
We attempt to circumvent this problem by using the deriva-
tive of the phase of the reﬂection coefﬁcient with respect to the
frequency d̸ Γ/df, measured in rad/Hz, instead of the phase
itself. In this way we disregard any ±n2π uncertainty while
keeping the information about the distribution of the phase in
frequency.
The results for the amplitude of the reﬂection coefﬁcient
for a cube and a ball are presented in Figures 2a and 2b,
respectively, where the dotted lines show the family of curves
for varying object size, while the position is held ﬁxed, and the
solid lines show the results for ﬁxed size and varying offset.
The dotted lines show a greater reﬂection coefﬁcient ans the
object dimensions r and m increase, which can be expected as
larger objects create larger echo. The derivative of the phase
with respect to frequency for a cube and a ball is presented in
Figures 3a and 3b respectively.
We have used a combination of the frequency distribution of
the magnitude and phase of the reﬂection coefﬁcient in order
to generate an input for the shape recognition neural network.
We have used 11 points from each of the curves from Figures 2
and 3, as the frequency response varies slowly and using this
representation we lose no information. Thus we get an input
signal of 22 points for each size and position of the respective
object. As the number of size and position varying simulations
is also 22, we get 22 input signals of 22 points each for each
object. We use 14 of those signals to train the network and 8
to test it.
We compare the efﬁciency of a shape recognizing neural
network working with reﬂection coefﬁcient amplitude and
phase versus a system working with amplitude only. We use
11 points from each amplitude curve, presented in Figure 2 in
order to train and test such a network.
III. NEURAL NETWORK SIGNAL PROCESSING
There are various studies concerning the pre-processing of
input data for the recognition system to improve its efﬁciency
and accuracy. In order to make a correct choice of the
recognition method, it is necessary to analyze the data deﬁning
the parametric descriptions of the objects. This analysis is
based on the calculation of the statistical parameters of the data
as well as the determination of the degree of similarity between
the parametric descriptions of the objects. Since our study in-
volves highly correlated input parametric vectors representing
parametric descriptions of the reﬂected radar signal for the
-8
-7
-6
-5
-4
-3
-2
-1
0
1
2
3
4
5
6
7
8
9
10
11
Magnitude of the re
ection coef
cient
Mean parametric vector of "Ball" train samples
Mean parametric vector of "Cube" train samples
Fig. 4. Mean parametric vectors over the magnitudes of the reﬂection
coefﬁcients for 14 train samples of “ball” and “cube”.
-0.015
-0.01
-0.005
0
1
2
3
4
5
6
7
8
9
10
11
Derivative of the phase of the reflection
coefficient
Mean parametric vector of "Ball" train samples
Mean parametric vector of "Cube" train samples
Fig. 5. Mean parametric vectors over the derivative of the phase of the
reﬂection coefﬁcients for 14 train samples of “ball” and “cube”.
two objects under study, we have chosen the adaptive neural
network method, that provides the most effective recognition
of similar input data. As the two 3D objects have similar
shapes, it is necessary to use an adaptive and precise method
for recognition and classiﬁcation of the two objects. The Deep
Learning method using a Multi-Layered-Perception (MLP)
feed forward Neural Network (NN), trained by the Back-
propagation (BP) algorithm, gives satisfactory results in the
cases described in [5], [6]. This allows precise placement of
boundaries between object classes with overlapping parametric
descriptions – in our case very similar reﬂection signals. In or-
der for the neural network to be “assisted” in advance, different
linear transformations (mostly scaling to the ranges of (0, 1)
or (−1, 1)) [7], [8], statistical standardization (using deviation
from the mean) or various other appropriate mathematical
transformations over the input data [9], [10] are suggested. In
our study, in order to reduce the preliminary calculations and
simplify the method, we choose an appropriate combination
of independent parameters of the reﬂected radar signal, such
as magnitude and phase of the reﬂection coefﬁcient.

33
International Journal on Advances in Networks and Services, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/networks_and_services/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
TABLE I. STANDARD DEVIATION AND CORRELATION BETWEEN THE
MEAN PARAMETRIC VECTORS
Input data
Standard deviation
Correlation between
mean parametric
vectors
Ball
Cube
|Γ|
0.801
0.179
−0.337
d̸ Γ/df
1.05 · 10−3
8.29 · 10−4
0.972
Γ
3.217
1.337
0.976
A. Preprocessing stage
In this stage some statistical parameters of the signals are
calculated, in order to evaluate the correlation between the
signals representing the two objects and the mean square
deviation of the signal parameters concerning the training
samples for each of the two objects. For this purpose, the
mean parametric vectors of the magnitude, of the derivative
of the phase of the reﬂection coefﬁcient and of the complex
signal (combining both of them) are calculated. The obtained
mean parametric vectors for 14 train samples of “ball” and
“cube” are shown in Figures 4 and 5, respectively.
The next step is to evaluate the standard deviation for each
of these two signals and calculate the correlation between the
mean parametric vectors of “ball” and “cube”. Considering
these two parameters, it is easier to make decision what kind of
a recognition method to apply, since with a high correlation of
interclass parametric descriptions, it is recommended to choose
an adaptive recognition method, such as a neural network.
On the other hand, the adaptation of the neural network and,
respectively, the accuracy of recognition in this case would be
much more efﬁcient, if the standard mean square deviation of
the input training parameter vectors within the class is higher.
The correlation between the mean parametric vectors over
the magnitudes, the derivative of the phase of the reﬂection
coefﬁcients and over the complex (magnitude and derivative
of the phase) signal for 14 training samples of “ball” and
“cube” respectively, is has been calculated using the Pearson
correlation coefﬁcient [11]:
ρball,cube =
Pn
i=1(Bi − B)(Ci − C)
qPn
i=1(Bi − B)2(Ci − C)2
,
(1)
where Bi, Ci is the current component of the input vector
“cube/ball”, and n is the number of components (n = 11
for input vector “magnitude” and “derivative of the phase”;
n = 22 for the “complex” vector). The achieved results for
the discussed calculated parameters are shown in Table I,
where Γ is the complex reﬂected signal, |Γ| is its magnitude,
and d̸ Γ/df is the derivative if the phase of the reﬂection
signal with respect to the frequency. The obtained results
show that the correlation has the lowest values for input
data “magnitude”, but the standard deviation is highest at the
complex signal. Thus we will train a MLP neural network
(MLP NN) with “magnitude” and “complex” signals, aiming
to compare the recognition accuracy results.
-2,5
-2
-1,5
-1
-0,5
0
0,5
1
1,5
2
2,5
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Output neuron value
Test signal number
MLP-11-8-5-2
Ideal values output neuron 1(ball)
Learned values output neuron 1
Ideal values output neuron2 (cube)
Learned values output neuron 2
Fig. 6. MLP NN (11-8-5-2) output results for Output neuron 1 (ball) and for
Output neuron 2 (cube) when recognizing the 8 exemplars of objects ball
and cube with “magnitude” input vector
B. Neural network: structure and training method
We have trained the MLP NN in two cases: ﬁrst only with
“magnitude” input signal, sampling 11 points from each curve,
as they vary slowly in frequency and second with “complex”
signal having 22 points respectively. In both cases the training
set contains 14 curves with varying offset and object size.
The test set contains 8 specimens, representing the two types
of objects, whose reﬂected signals have not participated in
the training set. For the ﬁrst case we have designed the MLP
NN by adding two hidden layers and increasing the number
of neurons in each layer until satisfactory recognition was
achieved. The best recognition results were obtained in the
case MLP 11-8-5-2 structure (with two hidden layers, having
8 and 5 neurons and 2 output neurons, representing the two
recognizable objects), with a reached minimum Mean Square
Error (MSE-ε) of 5%. For the second case we train different
MLP structures of 22-10-2; 22-15-2 and 22-20-2 neurons with
a reached a few times less minimum MSE–ε) of 0.02 and
0.04%.
In both cases a step by step “continue” stage of the training
has been applied, reducing the error achieved and accepted
at each previous stage. We use steps obtaining MSE of 5%;
1%; 0.8%; 0.4%; 0.1%; 0.08%; 0.04%; 0.02%. This method
permits ﬁne tuning (FT) of a pre-trained network using slightly
changed training data.
IV. EXPERIMENTAL RESULTS
The MLP NN output results when recognizing the 8 spec-
imens, representing the two objects, whose reﬂected signals
have not participated in the training set, are shown in Figures 6
to 10. Figure 6 represents the NN outputs 1 and 2, when
training the network only with “magnitude” input data for
a 11-8-5-2 MLP NN. In this case the obtained recognition
accuracy is 75% for both objects, that is, 2 samples of each
object are falsely recognized. The training iterations were
stopped when the MSE has reached 5%. Figures 7, 8 and
9 show the NN outputs 1 and 2, when training the network
with “complex” input data, respectively with different MLP
NN structures: 22-10-2; 22-15-2 and 22-20-2. In order to put

34
International Journal on Advances in Networks and Services, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/networks_and_services/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
-5
-4
-3
-2
-1
0
1
2
3
4
5
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Output neuron value
Test signal number
MLP-22-10-2
Ideal values output neuron 1(ball)
Learned values output neuron 1
Ideal values output neuron 2(cube)
Learned values output neuron 2
Fig. 7. MLP NN (22-10-2) output results for Output neuron 1 (ball) and for
Output neuron 2 (cube) when recognizing the 8 exemplars of objects ball
and cube with “complex” input vector
-8
-6
-4
-2
0
2
4
6
8
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Output neuron value
Test signal number
MLP-22-15-2
Ideal values output neuron 1(ball)
Learned values output neuron 1
Ideal values output neuron 2(cube)
Learned values output neuron 2
Fig. 8. MLP NN (22-15-2) output results for Output neuron 1 (ball) and for
Output neuron 2 (cube) when recognizing the 8 exemplars of objects ball
and cube with “complex” input vector
more precise boundaries between the object classes and to
improve the accuracy of recognition, it is necessary to increase
the number of neurons in the hidden layer of the MLP NN.
Thus, each subsequent train and test step is made with an
increased number of neurons in the hidden layer. It is good
recognizable that the approximation of ideal/ learned values
is improved after each subsequent increase of neurons in the
hidden layer. For object “ball” the accuracy increases from
87.5% to 100% and for “cube” – from 62.5% (3 samples
out of 8 are misidentiﬁed) to 87.5% (1 sample out of 8
is misidentiﬁed). Figure 10 represents the NN outputs in
test phase, when ﬁne tuning train method was applied. The
obtained approximation error for the various structures is
shown in Figure 11. Obviously, the best approximation was
achieved in the case of MLP 22-20-2 and ﬁne tuning training.
The summary of the achieved recognition accuracy and the
reached MSE for all tested cases, is shown in Table II.
V. CONCLUSION
This paper shows the initial work on identifying suitable
neural network signal processing tools for radar based shape
-6
-4
-2
0
2
4
6
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Output neuron value
Test signal number
MLP-22-20-2
Ideal values output neuron 1(ball)
Learned values output neuron 1
Ideal values output neuron 2(cube)
Learned values output neuron 2
Fig. 9. MLP NN (22-20-2) output results for Output neuron 1 (ball) and for
Output neuron 2 (cube) when recognizing the 8 exemplars of objects ball
and cube with “complex” input vector
-5
-4
-3
-2
-1
0
1
2
3
4
5
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Output neuron value
Test signal number
MLP-22-20-2 - Fine tuning
Ideal values output neuron 1 (ball)
Learned values output neuron 1
Ideal values output neuron 2 (cube)
Learned values output neuron 2
Fig. 10. MLP NN (22-20-2) output results for Output neuron 1 (ball) and
for Output neuron 2 (cube) when recognizing the 8 exemplars of objects
ball and cube with “complex” input vector applying ﬁne tuning training
recognition techniques. The achieved recognition results show
that it is very appropriate to implement MLP NN for 3D
object recognition, when using radar reﬂection signals. The
good approximation abilities of the MLP NNs make it possible
to recognize even objects of very similar shapes. It has been
shown that a complex signal that has a higher value for
standard deviation, results in effective training and therefore
in better recognition accuracy. As future work, we intend to
test the method for a larger number of objects with similar 3D
TABLE II. RECOGNITION ACCURACY FOR DIFFERENT MLP STRUCTURES
AND INPUT SIGNALS
Input Data
MLP
Recognition Accuracy, %
structure
Ball
Cube
MSE-ε
Magnitude
11-8-5-2
75%
75%
5%
Complex
22-10-2
87.5%
62.5%
0.02%
Complex
22-15-2
100%
75%
0.02%
Complex
22-20-2
100%
87.5%
0.04%

35
International Journal on Advances in Networks and Services, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/networks_and_services/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
0
0.5
1
1.5
2
2.5
Appro
ximation error
ball
cube
M
