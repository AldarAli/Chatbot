Implementation of Chatbots in Mental Healthcare:
A Human Factor Perspective
Zhenqi Zhao
Department of Business Information Technology
University of Twente
Enschede, Netherlands
e-mail: z.zhao-2@student.utwente.nl
Onur Asan
School of Systems and Enterprises
Stevens Institute of Technology
Hoboken, USA
e-mail: oasan@stevens.edu
Mo Mansouri
School of Systems and Enterprises
Stevens Institute of Technology
Hoboken, USA
e-mail: mmansour@stevens.edu
Abstract—The global prevalence of mental health disorders,
accentuated by the COVID-19 pandemic, emphasizes an urgent
need for efficient solutions. This paper explores the potential of
chatbots in addressing the mental health situation from a human
factor perspective. Using stakeholder analysis, we identified and
categorized various entities that influence or are influenced by
the integration of chatbots in mental healthcare. A shaping
forces analysis revealed driving factors such as increasing student
mental health needs, existing therapy system limitations, and
technological advancements. While chatbots serve as promising
alternative solutions for mental health crisis, they come with
challenges. This study offers a fresh perspective on understanding
the interaction between chatbots and mental healthcare. It
underscores the effects of this transition not only on directly
affected stakeholders but also on participants who might be
indirectly influenced within the system.
Keywords—Chatbot; Mental Health; Artificial Intelligence;
Human Factors.
I. INTRODUCTION
Nearly 970 million individuals worldwide grapple with
mental illnesses, with the most common symptoms of anxiety
and depression [1]. The outbreak of COVID-19 in 2020 exac-
erbated the situation [2]. Within a year, the number of people
with anxiety disorders increased by 26% and the number
of people dealing with depressive disorders grow by 28%
[3]. Despite the availability of effective treatments, existing
mental health care solutions remain insufficient for the global
population. Chatbot applications, however, offer a promising
solution.
Recent years have seen a growing interest in the integration
of chatbots within the healthcare domain, leading to a variety
of applications [4]. In an effort to mitigate the mental health
crisis and ensure more accessible care, several public projects
have been launched. In Europe, for instance, the Mental Health
Monitoring Through Interactive Conversations (MENHIR)
project was initiated, offering 24-hour mental health support
via a chatbot [5]. Similarly, Ulster University introduced a
chatbot called iHelpr, designed primarily to facilitate users
in self-assessing stress, anxiety, and depression levels [6].
However, these tools are not yet broadly adopted.
This paper is structured into 5 sessions. Following this
introduction, Section 2 covers background on mental health
challenges, chatbots in the mental health field, and advance-
ments in related technologies. Section 3 presents a stakeholder
analysis. Section 4 discusses the shaping forces influencing
chatbot adoption, and Section 5 concludes with findings and
recommendations for future work.
II. BACKGROUND
The background section provides an overview of the current
global mental health situation, the integration of chatbots in
mental health, and the technological advances that power
chatbots.
A. Current Mental Health Situation
Mental health conditions have become an increasing con-
cern globally. Roughly one in eight individuals worldwide
cope with mental disorders, with anxiety and depressive dis-
orders being most common [7]. In the U.S., nearly 22.8% of
adults faced mental illness in 2021 [8]. Despite the Netherlands
having a slightly lower rate, the state of mental health is at its
poorest in two decades, with 15% of the population admitting
to psychological issues according to the Netherlands Statistical
Office (CBS).
The COVID-19 pandemic only exacerbated these mental
health challenges. Many studies point out a surge in depres-
sion, anxiety, and stress during the pandemic [2]. Factors such
as enforced self-isolation and disruptions in daily routines
might be attributed to increased loneliness, anxiety, insomnia,
and even self-harm or suicidal tendencies [9].
Overall, the rising incidence and awareness of mental health
issues reflect the need for timely solutions to address these
challenges.
B. Chatbots in Mental Health
Conversational agents have been defined as ”software sys-
tems that mimic interactions with real people” [10] through
various means such as text, spoken language, and gestures. A
subset of these agents, chatbots, have gained attention in the
healthcare sector due to their accessibility and efficiency. For
instance, “Wysa” is a chatbot that engages users in written
dialogues, recognizing their emotions and guiding them to
build emotional resilience skills [11]. Another example, Emo-
haa, functions as a generative dialogue platform that facilitates
open-ended conversations about emotional concerns, offering
emotional support [12].
1
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

However, current healthcare chatbots serve as supplemen-
tary tools rather than replacing medical professionals [13]. The
majority of these chatbots develop based on decision trees.
Only a small percentage utilize more advanced machine learn-
ing techniques [14]. Relying heavily on decision trees limits
user inputs to predefined phrases and words and constrains the
user’s initiative in the conversation [4].
C. Related Technologies
The field of Artificial Intelligence (AI) has witnessed rapid
advancements in recent years, notably advancing chatbot ca-
pabilities through two elements: Machine Learning (ML) and
Natural Language Processing (NLP) [15]. Machine learning
is a statistical technique for interpreting data, recognizing
patterns, and utilizing historical conversation to generate ap-
propriate responses [16]. Natural language process focuses
on analyzing the nature of human language and facilitating
machine comprehension and interpretation of user inputs [15].
Within healthcare, natural language learning has a multi-
faceted role, including interpreting user utterances, identifying
significant changes, analyzing emotion, and extracting entities.
Combined with ML, it can be used to predict or pinpoint
behaviors in real-time, like identifying self-harm or suicide
risk from interaction [15]. On the other hand, natural language
learning can process unstructured patient notes and medical re-
ports and transcribe patient discussions to provide unstructured
data for facilitating relevant research [15].
However, the integration of chatbots into the mental health
arena faces several challenges. One primary concern is the
reliability of responses [4]. Due to the inherent design of
machine learning, machine learning does not always guarantee
consistent or desired outputs. In healthcare, particularly mental
health, this unpredictability can pose risks. The integration of
chatbots into daily clinical practice presents another challenge
[16]. Gaining clearance from regulatory bodies often requires a
thorough and extensive evaluation process. Lastly, the quality
of chatbots is a salient issue. Many users feel that current
chatbot dialogues lack depth and clarity, leading to confusion
[17].
III. STAKEHOLDER ANALYSIS
A stakeholder analysis was conducted to better understand
the diverse interests and potential impacts of involved groups.
This section encompasses identifying possible stakeholders
and classifying them based on the power-interest matrix.
A. Identification of Stakeholders
The current practice of chatbots in mental therapy is limited,
necessitating a deeper exploration of their implications for
stakeholders. Identifying the relevant stakeholders is the pri-
mary action. This study emphasizes three primary dimensions:
the individual, organizational, and national levels, as illustrated
in Figure 1.
At the individual level, the foremost affected stakeholders
are the patients and the therapists. Subsequently, patients’
family members bear indirect influences. Studies have shown
Figure 1. Identification of Stakeholders
that mental illness not only has the potential to cause physical
illness in patients but also has the potential to jeopardize their
lives. For instance, bipolar disorder has been linked to a higher
cardiovascular disease rate [18]. Moreover, the study has
demonstrated an association between suicidality and chronic
insomnia [19]. Given the chronic and demanding nature of
illness, the family caregivers often experience burnout and
negative emotion, thereby imperiling their own well-being
[20]. The widespread use of chatbots in the therapy field
will grant more patients and their family members easier
access to relevant information and treatments, helping their
recovery. The health chatbots support therapists in managing
their own health [21]; however, this trend may pose challenges
to therapists in terms of job opportunities.
On the organizational level, both insurance companies and
universities are likely to be affected. With the growing recog-
nition of mental health, people are leaning towards insurance
options covering therapy costs. Given that chatbots typically
charge less than traditional face-to-face therapists due to the
lack of need for physical workspace and human resource
saving, this could lead to reducing expenses for insurance
companies. Simultaneously, for universities, these digitized
conversations offer invaluable firsthand data for research pur-
poses.
Lastly, from a national perspective, governments should
also focus on the mental health system. According to World
Health Organization, over 700,000 people were estimated to
have committed suicide in 2019 [7], which is one of the
leading causes of death among young people [22]. In the
U.S., a significant 16.5% of teenagers aged from 6 to 17 were
diagnosed with mental disorders in 2016 [23]. It underscores
the necessity for governments to address both physical and
mental well-being of their citizens.
2
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

B. Mapping of Stakeholders
Utilizing the power-interest matrix, stakeholders are cat-
egorized into four different groups based on their relative
influences and interests in adapting the system. This mapping
is depicted in Figure 2.
Figure 2. Power-Interest Matrix of Stakeholders
The government, a stakeholder at the national level, wields
considerable influence but has a limited interest in chatbot
development in the mental health field. The surge in mental
health issues can be attributed to various causes, so the gov-
ernment has alternative solutions to address these issues. For
instance, mental health challenges resulting from lockdown or
quarantine are likely to subside post-pandemic. Therapists, on
the other hand, have significant influence due to two primary
reasons. First, developing chatbots requires extensive real data
from past therapy sessions. Second, the sensitive nature of
therapy demands rigorous validation before its widespread.
However, many therapists favor direct interaction with patients
and value immediate feedback, explaining their limited interest
in chatbots.
Despite outstanding achievements in artificial intelligence
and the deployment of chatbots by industries, the unclear
commercial potential has limited private sector investment in
this domain. In contrast, extensive research has been conducted
in the academic sector, positioning universities as influential
stakeholders. The wealth of data serves as an enticing factor
for universities as well. Conversely, insurance companies ex-
hibit both limited influence and interest due to a minor portion
of insurance companies’ claim expenses.
Patients and their families stand to benefit from the imple-
mentation of chatbots that may reduce associated costs. The
limited understanding and social prejudices associated with
mental disorders often deter many from seeking help. Chatbots
offer a more private consultation environment, mitigating these
concerns. However, due to the limited resources available to
patients and their families, their influence remains modest.
IV. SHAPING FORCES ANALYSIS
This shaping forces analysis examines key drives behind
implementation of chatbots in the mental health field. As
shown in Figure 3, three primary forces were discussed,
including the demands of potential patients (students), the
drawbacks of the current therapy system, and the burst of
technologies.
Figure 3. Shaping Forces Analysis
A.
The Demands of Potential Patients (Students)
The attractiveness of diverse cultures has seen an uptick in
students pursuing education abroad. However, this transition,
coupled with rigorous academic demands, induces negative
emotional states such as homesickness and loneliness. For
instance, 45% of Chinese students at Yale exhibited depres-
sion symptoms, with 29% displaying anxiety symptoms [24].
Contributing factors include loss of familiar support networks,
daily language barriers, and cultural adjustments [25]. Despite
these challenges, international students often hesitate to seek
help because of unfamiliar practice processes, cultural barriers,
shameful feelings, and linguistic challenges.
Chatbots offer a potential solution by providing conversation
in the student’s native language. By leveraging data sourced
from the native country, chatbots can effectively mitigate
cultural barriers. Furthermore, the private platform can sig-
nificantly reduce the stigma.
B. Drawbacks of the Current Therapy System
While seeking a recommendation for a cancer specialist
is relatively straightforward, finding the right therapist is
often more complex. Individuals’ perceptions and feelings
toward therapists can vary greatly, so it is necessary to make
several attempts before finding a compatible fit. This journey,
from searching for information to booking sessions, often
becomes tedious, causing loss of motivation. Common barriers
include the challenges of scheduling appointments and the
overwhelming uncertainty of where to find help [25]. Another
significant concern is cost. Notably, mental health treatments
are not generally covered by private insurance policies, making
it unaffordable for numerous families [26]. To compound these
challenges, some countries, like China, face a shortage of
qualified therapists and social workers [26].
3
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

Chatbots, with their 24/7 availability, can efficiently over-
come the challenges of appointment scheduling, potentially
reducing therapy costs, and bridging the professional shortage
gap.
C. Burst of Technologies
Figure 4 shows the number of publications related to
Artificial Intelligence in mental health domain from 2013 to
2022, sourced from Scopus. This data was gathered using
search terms: (”Mental Health” AND (”Artificial Intelligence”
OR ”Machine Learning” OR ”Natural Language Process”)).
The search was confined to the past decade and restricted to
English language publications.
Figure 4. Publications Per Year
As mentioned before, the innovation of technology will be
the gasoline for developing more advanced chatbots. A notable
surge in publications is evident from 2017 onwards, offering
a glimpse into the prospective growth trend in this area.
V. CONCLUSION AND FUTURE WORK
The mental health situation is critical. As patient numbers
surge, the apparent insufficiency of professionals becomes
more pronounced. Despite society’s efforts to diminish the
stigma associated with mental illness, many individuals still
hesitate to seek help due to stigma. Additionally, the expense
of therapy remains a financial burden for many. Chatbots offer
a potential solution by providing 24-hour remote sessions.
While earlier studies largely centered on the technological
aspects of incorporating chatbots into mental healthcare or
evaluated their impact solely from patient or therapist view-
points, this paper broadens the scope. It not only considers the
patients and therapists but also seeks to identify and analyze
other stakeholders who may indirectly be impacted by, or have
an influence on, the system.
However, potential challenges must be acknowledged. Data
security stands out as a paramount concern. The related data
requires meticulous storage to avoid any breaches and strict
regulations to prevent any misuse. Another central issue is
trust. Besides data security, patients must trust the advice
offered by the chatbot and be willing to open up to chatbots.
Since effective therapy hinges on trust, its absence could risk
the therapeutic process being ineffective.
Future advancements should explore the potential of Large
Language Models (LLMs) and Explainable AI. Large language
models have demonstrated proficiency in simulating human-
like conversations and achieving tasks in other domains. The
integration could foster the development of AI-driven chatbots
in therapeutic contexts. Explainable AI, meanwhile, can in-
terrupt the decision-making process, minimizing inappropriate
responses.
In conclusion, introducing chatbots in the mental health
sector could promise unforeseen shifts, presenting both unique
opportunities and challenges for the industry and patients.
REFERENCES
[1] Institute
of
Health
Metrics
and
Evaluation,
May.
2022.,
“Global
Health
Data
Exchange
(GHDx).”
[Online].
Available:
https://vizhub.healthdata.org/gbd-results/
[2] C. Moreno et al., “How mental health care should change as a conse-
quence of the covid-19 pandemic,” The lancet psychiatry, vol. 7, no. 9,
pp. 813–824, 2020.
[3] World Health Organization, “Mental health and covid-19: early evidence
of the pandemic’s impact: scientific brief, 2 march 2022,” Tech. Rep.,
2022.
[4] L. Laranjo et al., “Conversational agents in healthcare: a systematic
review,” Journal of the American Medical Informatics Association,
vol. 25, no. 9, pp. 1248–1258, 2018.
[5] Z. Callejas, K. Benghazi, M. Noguera, M. I. Torres, and R. Justo,
“Menhir: Mental health monitoring through interactive conversations,”
Procesamiento del Lenguaje Natural, vol. 63, pp. 139–142, 2019.
[6] G. Cameron et al., “Assessing the usability of a chatbot for mental
health care,” in Internet Science: INSCI 2018 International Workshops,
St. Petersburg, Russia, October 24–26, 2018, Revised Selected Papers
5.
Springer, 2019, pp. 121–132.
[7] World Health Organization, “Suicide worldwide in 2019: global health
estimates,” Tech. Rep., 2021.
[8] Substance Abuse and Mental Health Services Administration, “Key
substance use and mental health indicators in the united states: Results
from the 2020 national survey on drug use and health,” Center for
Behavioral Health Statistics and Quality, Substance Abuse and Mental
Health Services Administration, Tech. Rep., 2021.
[9] A. Kumar and K. R. Nayar, “Covid-19 and its mental health conse-
quences,” Journal of Mental Health, vol. 30, no. 1, pp. 1–2, 2021.
[10] C. Khatri, A. Venkatesh, B. Hedayatnia, R. Gabriel, A. Ram, and
R. Prasad, “Alexa prize state of the art in conversational AI,” AI
magazine, vol. 39, no. 3, pp. 40–55, 2018.
[11] B. Inkster, S. Sarda, and V. Subramanian, “An empathy-driven, conversa-
tional artificial intelligence agent (wysa) for digital mental well-being:
real-world data evaluation mixed-methods study,” JMIR mHealth and
uHealth, vol. 6, no. 11, p. e12106, 2018.
[12] S. Sabou et al., “A chatbot for mental health support: exploring the
impact of emohaa on reducing mental distress in china,” Frontiers in
Digital Health, vol. 5, p. 1133987, 2023.
[13] M. Jovanovi´c, M. Baez, and F. Casati, “Chatbots as conversational
healthcare services,” IEEE Internet Computing, vol. 25, no. 3, pp. 44–51,
2020.
[14] A. A. Abd-Alrazaq, M. Alajlani, A. A. Alalwan, B. M. Bewick,
P. Gardner, and M. Househ, “An overview of the features of chatbots
in mental health: A scoping review,” International Journal of Medical
Informatics, vol. 132, p. 103978, 2019.
[15] K. Denecke, A. Abd-Alrazaq, and M. Househ, “Artificial intelligence
for chatbots in mental health: opportunities and challenges,” Multiple
perspectives on artificial intelligence in healthcare: Opportunities and
challenges, pp. 115–128, 2021.
[16] T. Davenport and R. Kalakota, “The potential for artificial intelligence
in healthcare,” Future healthcare journal, vol. 6, no. 2, p. 94, 2019.
[17] A. A. Abd-Alrazaq, M. Alajlani, N. Ali, K. Denecke, B. M. Bewick, and
M. Househ, “Perceptions and opinions of patients about mental health
chatbots: scoping review,” Journal of medical Internet research, vol. 23,
no. 1, p. e17828, 2021.
4
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

[18] D. J. Kupfer, “The increasing medical burden in bipolar disorder,” Jama,
vol. 293, no. 20, pp. 2528–2530, 2005.
[19] K. C. Cukrowicz, A. Otamendi, J. V. Pinto, R. A. Bernert, B. Krakow,
and T. E. Joiner Jr, “The impact of insomnia and sleep disturbances on
depression and suicidality.” Dreaming, vol. 16, no. 1, p. 1, 2006.
[20] R. K. Chadda, “Caring for the family caregivers of persons with mental
illness,” Indian journal of psychiatry, vol. 56, no. 3, p. 221, 2014.
[21] A. Palanica, P. Flaschner, A. Thommandram, M. Li, and Y. Fossat,
“Physicians’ perceptions of chatbots in health care: cross-sectional web-
based survey,” Journal of medical Internet research, vol. 21, no. 4, p.
e12887, 2019.
[22] World Health Organization, “World mental health report: transforming
mental health for all,” Tech. Rep., 2022.
[23] D. G. Whitney and M. D. Peterson, “Us national and state-level
prevalence of mental health disorders and disparities of mental health
care use in children,” JAMA pediatrics, vol. 173, no. 4, pp. 389–391,
2019.
[24] X. Han, X. Han, Q. Luo, S. Jacobs, and M. Jean-Baptiste, “Report
of a mental health survey among chinese international students at yale
university,” Journal of American college health, vol. 61, no. 1, pp. 1–8,
2013.
[25] H. Forbes-Mewett and A.-M. Sawyer, “International students and mental
health,” Journal of International Students, vol. 6, no. 3, pp. 661–677,
2019.
[26] A. Carbonell, J.-J. Navarro-P´erez, and M.-V. Mestre, “Challenges and
barriers in mental healthcare systems and their impact on the family: A
systematic integrative review,” Health & social care in the community,
vol. 28, no. 5, pp. 1366–1379, 2020.
5
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

