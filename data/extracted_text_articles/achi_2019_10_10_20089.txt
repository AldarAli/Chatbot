Assessing the Impact of Muscular Fatigue on Myoelectric Signals Using Myo Armband
Sudhir Sharma
School of Engineering and Computing
University of Hertfordshire, UK
Email: s.sharma25@herts.ac.uk
Volker Steuber
School of Engineering and Computing
University of Hertfordshire, UK
Email: v.steuber@herts.ac.uk
Farshid Amirabdollahian
School of Engineering and Computing
University of Hertfordshire, UK
Email: f.amirabdollahian2@herts.ac.uk
Abstract—This paper investigates the impact of muscular
fatigue on myoelectric signals in order to incorporate biological
feedback acquired wirelessly into a game interaction intended
for rehabilitation. The study was conducted in four phases:
Familiarisation, Training-1, Dumbbell exercises and Training-2
with 20 healthy participants. During the two training phases,
each participant performed 5 hand gestures, each gesture was
performed in 5 iterations. Each iteration lasted 5 seconds and
consisted of 5 repetitions of each gesture, visually guided to last
a second each. The logged data was recorded into CSV (Comma-
Separated Values) ﬁles at a rate of 200Hz. In order to compare
grasps before and after the fatiguing exercise, we used SVM
(Support Vector Machine), using the capability to judge grasp
accuracy for each phase. By comparing the grasp accuracy pre
and post exercise, we found that muscular fatigue can negatively
impact on gesture accuracy. The gesture accuracy detected after
dumbbell exercises was signiﬁcantly lower than that of the
gestures performed before exercise. The data collected through
subjective questionnaires also supports the results. In this study,
we identiﬁed that fatigue, caused by interaction intensity and
effort, can affect the accuracy of gesture detection. This has a
further implication for cases where EMG (Electromyography) is
used as the biofeedback involved in human-machine interactions,
such as gameplay. While it is thought that more intensive
interaction may beneﬁt recovery after stroke, it is possible to
optimise interactions towards reducing fatigue, for example by
pacing the game difﬁculty based on detected level of fatigue.
Index Terms—Gesture detection; fatigue; electromyography.
I. INTRODUCTION
Humans utilise their hands to accomplish tasks, interact with
their environments and also for communication via gestures.
Human-computer interaction utilising hand gestures can play a
signiﬁcant role in this smart world. The way of interaction with
devices and applications has been completely changed, smart
devices use new interaction techniques such as voice com-
mands, mimics, and gestures to communicate with humans.
The hand gesture based technique is a unique approach which
provides a natural way of interaction and communication [1].
In the past, researchers have used various methods such as
vision-based and glove-based methods to detect hand gestures.
Vision-based solutions often involve detecting the ﬁngertips or
ﬁngers and inferring joint-articulations using inverse kinematic
models of the hand and wrist skeleton [2][3]. They are
susceptible to changes in illumination, rotation problem, and
occlusion [4]. Glove-based methods reduce the computation
time by having a direct measurement of the articulation [2]
[3] of the hand and wrist joints. Glove-based techniques
require the user to wear a glove, sometimes uncomfortable to
wear and requiring a correct size/handedness. Also position
encoders may have connection cables limiting free motion
and interfere with the donning and dofﬁng and comfort.
Furthermore, gloves may impact on tactile sensations of the
ﬁngers when interacting with objects.
In our previous research, Leon et al. [5] achieved more than
90% of accuracy in gesture recognition using Support Vector
Machines (SVM) while applying the technique to recordings
from hand ﬂexion and extension measured by a glove using
its bending sensors. Tavakolan et al. [6] used SVM for
pattern recognition of surface electromyography signals of four
forearm muscles in order to classify eight hand gestures. They
concluded that it was feasible to identify gestures using the
four locally placed electrodes. Similarly, Wang et al. [7] used
linear discriminant analysis to achieve an average accuracy of
around 98% in detecting 8 hand gestures using two electrodes
placed on the forearm. Using the Myo armband, researchers
in our group initially achieved low accuracies using k-nearest
neighbours [8] and changing the machine learning method to
SVM, they achieved an overall recognition accuracy of 94.9%
detecting hand and wrist gestures [9].
Similarly, in our current study, a series of dumbbell exer-
cises were performed between two training sessions to assess
the impact of muscular fatigue on myoelectric signals. This
study focused on assessing gesture recognition accuracies in
fatigued muscles prior to incorporating them into a rehabilita-
tion game. While our earlier recognition results were promis-
ing, they required a training of 2.5s per gesture, repeated
25 times before a gesture could be automatically detected
in 0.2s. A limitation of this approach is that incorporating
such techniques in an interactive game may result in delays
to gameplay due to training needed for each gesture. Hence
in current study, we explore if SVM is able to perform with
1s of training data, and if such amount is suitable in detecting
gestures in fatigued muscles.
The rest of the paper is organised as follows. In section II,
we introduce fatigue and its potential role in machine-mediated
rehabilitation. Section IV presents methodologies used for data
acquisition, experiment, analysis and evaluation. Section V
provides the results of the experiment with statistical analysis
and section VI provides an analysis of the results. Finally,
159
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-686-6
ACHI 2019 : The Twelfth International Conference on Advances in Computer-Human Interactions

section VII draws conclusion from the work presented.
II. FATIGUE
Fatigue is a common problem among stroke survivors
performing physical activities for rehabilitation [10]. Stroke
patients often suffer from weariness, tenderness and lack of
energy, initiative, and motivation. Fatigue is a condition in
which a person lacks the physical and mental energy that is
perceived by the individual to interfere with usual and desired
activities [11]. Staub and Bogousslavsky deﬁned fatigue in
stroke patient as a feeling of early exhaustion developing
during activity with lack of energy and aversion to effort
[12]. It can be differentiated into two categories, subjective
fatigue, and objective fatigue [13]. The subjective fatigue
corresponds to the symptom that is felt by the patient, which
can be estimated by self-reported questionnaires. The objective
fatigue corresponds to a decrease in measured physical or
mental performance over the set duration of a task [13].
In using machine learning for fatigue detection, a study
was carried out by Nourhan et al. [14] using Electromyo-
graphy (EMG) electrodes to measure the muscle activity
during dynamics contractions. In this work, the Myo armband
device was used to assess the viability of using Myo to
quantify muscle fatigue. During the experiment a set of muscle
fatiguing exercises was conducted where elbow ﬂexion and
extension were performed. The acquired EMG signals from
muscles were analysed and features such as Root Mean
Square and Median Frequency were used as indicators of
fatigue using adaptive neural networks. Results show that
automating the process of localised muscle fatigue detection
shows higher accuracy using supervised techniques compared
to thresholding or observation techniques.
III. MACHINE-MEDIATED REHABILITATION AND GAMES
In the context of rehabilitation for stroke, more recent
machine-mediated tools often incorporate functional activities
such as grasping and manipulation of objects [5], as in daily
living activities. It is believed that the repetition of these
training activities inﬂuence the neuromodulation needed for
re-learning and performing of the activities affected by stroke
[15][16].
Studies exploring the machine-mediated rehabilitation of-
ten utilise the sensory recording from robots. These include
kinematic data, such as position and orientation, that can be
utilised alongside other dynamic models [17], to infer on
active involvement of the patient, and also to provide input
for assessing the movement performance. However, rarely
these methods consider fatigue that is accumulated over the
interaction time, and those studies that consider fatigue, often
rely on measuring fatigue using indirect methods, such as
measurement of movement error [18].
Games are seen as a good medium for practicing activities
of daily living. Robot-mediated activity is often limited to
worn devices that are cumbersome and heavy, and cannot be
utilised for a prolonged period of time. Also, robots are often
tethered to their controller and therefore it is not possible to
practice exercises freely. Wireless myoelectric devices such
as Myo armband offer a potential solution for receiving hand
gestures and incorporating them into rehabilitation games. The
study conducted by Oskoei et al. [19] focused on manifestation
of fatigue in myoelectric signals during dynamic contractions
produced during playing PC games. The study results show
that there is a signiﬁcant decline in signal frequency after a
period of operation, which is linked to fatigue in the muscles
[20]. This led to our research question exploring suitability of
machine learning in detecting fatigue from interactions sensed
using the Myo armband.
IV. MATERIAL AND METHODS
The Myo armband [21] depicted in Figure 1 is a gesture
recognition device worn on the forearm. It enables a user to
control ICT technology wirelessly using various hand/wrist
motions. It is designed with 8 EMG electrodes which are
placed equidistantly around the arm. The armband is built
with an ARMCortex M4 processor and a rechargeable lithium-
ion battery allowing it to be used while communicating via
Bluetooth 4. The armband is equipped with accelerometers,
gyroscope and magnetometers, and also provides haptic feed-
back in form of vibration. It can be worn easily without any
assistance.
Fig. 1. Myo Armband from Thalmic Labs
Experiment Design: The proposed study was designed to
assess gesture recognition before and after a series of fatiguing
dumbbell exercises. It also focused on using shorter grasp
cycles of 1 second in order to train the support vector machines
for gesture recognition. This was to reduce the training time
needed for in-game calibration of gestures at a later time.
The experiment was designed in four phases, Familiarisation,
Training-1, Dumbbell Exercises and Training-2 shown in
Figure 2. Subjective fatigue was assessed using a questionnaire
prior to, and after the last phase of the experiment.
The experiment protocol was approved by the University of
Hertfordshire’s ethics committee under the approval number
160
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-686-6
ACHI 2019 : The Twelfth International Conference on Advances in Computer-Human Interactions

COM/PGR/UH/02741. A total number of 20 participants con-
sented to take part in the study with their demographics pre-
sented in summary table I. As an exploratory study, a sample
size of 20 was seen as sufﬁcient to search for initial evidence
for impact of fatigue on recognition accuracy. Participants sat
in front of a 21” monitor, wearing the Myo armband on their
dominant arm.
TABLE I. DEMOGRAPHIC DATA
Gender
Participants
Age (m ± std)
Female
6
28.5 ± 3.5
Male
14
34.2 ± 7.3
Fig. 2. Experiment Setup
Familiarisation: In this phase, participants interacted with
the Myo armband and learned its operation. They performed
5 gestures shown in Figure 4, which were displayed in form
of an animated image on screen (Figure 3). Each animated
gesture repeated 5 times, each lasting 1 second. The familiari-
sation process cycled through the 5 gestures, until participants
were conﬁdent in using the device.
Fig. 3. Gesture image and gesture animation
Fig. 4. Designed poses for Familiarization: (a) OK, (b) Rock, (c) Pointer,
(d) Gun, (e) Phone
Training-1: During this phase, participants performed ﬁve
gestures consisting of cylindrical, lateral pinch, spherical,
tripod and hook grasps displayed on the screen. These ges-
tures were randomised to appear on screen in 5 iterations.
Participants were asked to perform and repeat each presented
gesture 5 times as shown by the animated image on screen.
The animated image timed each gesture to one second, thus
5 repetitions were expected to last 5 seconds. Based on this,
each of the gestures in the list was performed 25 times, lasting
approximately 25 seconds.
Fig. 5. Designed poses for Training-1: (a) Cylindrical, (b) Lateral Pinch, (c)
Spherical, (d) Tripod, (e) Hook
Dumbbell Exercises: Next phase required performing of a
series of Dumbbell exercises. During this phase, participants
performed some dumbbell exercises which varied in difﬁ-
culty between male and female participants, while applying
a gradual increase of weight up to 10Kg for male and 7.5Kg
for female participants on advise received from sport science
colleagues. They performed repeated elbow ﬂexion/extension
(biceps curls) and stopped the exercise when they felt personal
fatigue or tiredness.
Training-2: This phase was an exact replica of the Training-
1 phase, with the only difference being that this phase occurred
after the fatiguing dumbbell exercise.
Data Acquisition: Data was captured by placing the arm-
band on the forearm making direct contact with skin. The Myo
armband must be tight enough to stay in one place without
losing contact with skin for better signal transmission. Data
were collected at 200Hz sampling rate and logged into comma
delimited text ﬁles. Each subject completed 2 training sessions,
each training contained 5 iterations, each iteration containing 5
different gestures. Each gesture was performed 5 times making
5 repetitions. Overall, each participant performed 5 gestures
under Training-1 and the same gestures under Training-2, and
hence each gesture class contains 25 seconds of gesture data,
corresponding with 25 repetitions of each gesture.
Feature Selection: One of the ﬁrst steps to SVM analysis
is the feature selection step. Oskoei and Hu showed that the
waveform length (WL) feature is capable of detecting gestures
with an accuracy of more than 90% [20]. Huang and Chen
(1999) [22] deﬁne the waveform length as:
W L =
PN
k=1 |Xk−Xk−1|
Features were selected using N = 40 in the above equation.
This allows to reduce 200 data samples to only 5 rows, where
40 samples are reduced to one waveform length value. These
values are then used for training and recognition. The choice
of N is due to research by [23] that showed 200ms of data is
sufﬁcient to detect intention in muscle EMG.
SVM Classiﬁcation: The classiﬁcation process involves
learning features in a training set, and testing the learning
161
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-686-6
ACHI 2019 : The Twelfth International Conference on Advances in Computer-Human Interactions

using what is labeled as a recognition set. We used libsvm
and Python libraries for this assessment.
Our earlier study had identiﬁed optimal length of training
and recognition sets for testing the SVM detection accuracy. In
that study, gestures were held for 5 seconds; e.g. a cylindrical
gesture was produced and held, and the data from the 5-second
recording was used to train the SVM engine and to recognise
gestures. In our results a potential drop in some recorded
accuracies were linked to the delay in perceiving an action
command, before it is executed. We did not try to control the
task onset using audio-visual commands or screen animation
[9].
In our current study, we were concerned about the speed
of gesture detection in order to have a utility for seamless
gameplay. A subsequent research question was raised regard-
ing reliability of SVM if produced gestures were maintained
for a shorter time. So, here we asked our participants to repeat
the gesture 5 times within each iteration while providing an
on-screen animation showing the gesture start and ﬁnish, ac-
companied by audible signals. As a post-process, we explored
different lengths of training and recognition ﬁles versus their
accuracies in classiﬁcation.
Model: An SVM model was constructed with three iter-
ations {1,2,3} from both training sets (Training-1 and 2) as
Train and remaining two iterations{4,5} from both training
sets as Recognition sets. This includes 15 repetitions of each
training gesture in the training set, and 10 repetitions of each
gesture in the recognition set. Data in both sets are labelled
with their right classiﬁcation, for example G12I4 is labelled as
the 1st gesture, 2nd repetition, 4th iteration. After recognition
process, the SVM engine compares the label given by the SVM
recognition, to the one being set for the data as its label, and
comparing right and wrong recognitions lead to a recognition
accuracy, at gesture and overall levels. We are also able to
draw a confusion matrix that presents the reliability of our
method. The resulting recognition accuracies are then gathered
in a comma delimited text ﬁle and analysed using IBM SPSS
version 25.
Fig. 6. The data was recorded containing 5 gestures in each iteration and 5
iterations in each Training-1 and Training-2 datasets. Each iteration consists
of 5 iteration for each gesture.
V. RESULTS
This section presents the results of the experiment anal-
ysed based on gesture accuracy along with the participant’s
response about fatigue before and after dumbbell exercise
performance. Results shows that overall gesture accuracy was
higher ( 52.4 ± 28.54 (m ± std)) before dumbbell exercise
compared to gesture accuracy after the dumbbell exercises
(30.0 ± 4.144) with statistical signiﬁcance (p < 0.01) also
graphically shown in Figure 8. The data presented in Table
II shows the median accuracy for each gesture pre and post-
fatigue.
Questionnaire data scored the level of fatigue on a scale of
1 to 10, 10 being most fatigued. The results show that the
fatigue status of participants pre-exercise (median fatigue = 0,
0.65 ± 1.137 (m ± std) ) and post-exercise (median fatigue
= 8, 7.5 ± 2.1) were signiﬁcantly different. (p < 0.01) shown
in Figure 7.
TABLE II. MEDIAN ACCURACY FOR EACH GESTURE
Type
Gestures
Gesture Accuracy
Pre-Exercise
Post-Exercise
1
Cylindrical
52
35
2
Lateral
57
27
3
Spherical
50
27
4
Tripod
49
35
5
Hook
54
25
Fig. 7. Represents the impact of muscular fatigue on gesture accuracy of
post-exercise compared to pre-exercise (top), and also subjective status of
fatigue can be seen in post-exercise compared to pre-exercise evaluation
(bottom).
162
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-686-6
ACHI 2019 : The Twelfth International Conference on Advances in Computer-Human Interactions

Fig. 8. Line graph on the top represents the lower gesture accuracy for
post-fatigue (red line) compared to pre-fatigue (blue line), Boxplot on the
bottom represents the median gesture accuracy for pre and post fatigue.
VI. ANALYSIS & DISCUSSION
This study was focused on the impact of muscular fatigue
on hand gesture detection using myoelectric signals acquired
from the Myo Armband. The result shows that muscular
fatigue does affect the gesture accuracy negatively. The gesture
accuracy detected after dumbbell exercises was signiﬁcantly
lower than that for the gestures performed before the fatiguing
exercise. The data collected through the questionnaires about
participants fatigue conﬁrms the presence of fatigue in each
participant. The gesture accuracy analysed separately for each
of the ﬁve gestures also shows a signiﬁcant reduction for each
gesture performed before and after the exercise.
Observation of gesture detection accuracy pre-fatigue, com-
pared to our earlier study shows a signiﬁcant drop in gesture
accuracy (reduction from 95% to 52% overall). This could be
due to a number of variations between the two studies:
a) Reducing the length of training datasets for the SVM
engine, from 2.5 second to only 1s in each training repetition.
This was done to allow for a practical length of training data
that would suit a game calibration phase. However, the drop
in accuracies, pre and post-fatigue does not support using less
data in training phase.
b) The current study used one gesture per second instead
of a static gesture produced and maintained over 5 seconds.
We intend to explore inﬂuence of these differences. We
suspect that holding a gesture for a period of time greater
than the amount of training data needed, allows for least
variations in gesture data, while doing one gesture per second
includes ﬂexion and extension articulations that can introduce
additional variability and hence, reduce recognition accuracy.
We are currently assessing this using a further pilot study,
thus to ensure correct choice of learning gestures and optimal
parameters for best accuracies in fatigued interaction.
c) Here we used 200Hz sampling and a different reduction
factor to arrive at the same waveform length, and different
method to acquire the data. It could be possible that the new
method to acquire the data from Myo has applied ﬁlters to the
data which has negatively impacted on recognition accuracies.
The experiment was conducted with voluntary participation of
20 healthy individuals. Each participant performed 5 gestures
for 5 seconds for 5 times displayed on the screen in animated
form. Among all of 5 gestures, the Lateral gesture was detected
with the highest accuracy 57%, Hook 54%, Cylindrical 52%,
Spherical 50% and Tripod gestures was the lowest 49% shown
in Table II.
In a rehabilitation scenario, it is expected that patients
involved in training process will fatigue with effort and
exercise intensity. Using the wireless armband may therefore
offer unreliable results given the observed drop in recognition
accuracy, comparing fatigue and non-fatigue conditions. In
this regard, further improvements to recognition accuracy is
needed, prior to incorporating our method in rehabilitation
games for stroke patients.
VII. CONCLUSIONS
The objective of our analysis was to focus on hand gesture
detection inﬂuenced by muscular fatigue and optimise gestures
prior to incorporating them into a rehabilitation game. The
conclusion drawn from this study was that muscular fatigue
does signiﬁcantly affect the gesture accuracy. We observed
that using accuracy of recognition, it is possible to identify
163
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-686-6
ACHI 2019 : The Twelfth International Conference on Advances in Computer-Human Interactions

fatigue and non-fatigued myoelectric signals. The data col-
lected through questionnaires about participants fatigue status
support our results.
We noted a signiﬁcant drop in accuracy of detection, com-
paring non-fatigued muscles in this study and those reported
in our earlier work. It is possible that our choice of recording
from a steady gesture held for 5 seconds offers a more reliable
and accurate data for the machine learning. This aspect would
beneﬁt from further investigations to identify best training
setups.
Our approach was intended for using the SVM classiﬁer as
an online adjustment tool for exercise intensity within a serious
game designed for stroke rehabilitation. While we observed
that the Myo armband is reliable with data acquisition, given
the low accuracies in detecting fatigued gestures, further work
is needed to improve recognition accuracies. In a rehabilitation
context, patients often suffer from fatigue or are easily fa-
tigued. Given this, more work is needed to ensure recognition
accuracy remains within a reliable gameplay range.
Considering motivational factors, we remain convinced
that the Myo armband or similar wireless electromyographic
sensors allow for free movement in space, which does not
interfere with performing activities of daily living. Hence we
continue our work on EMG assessment using machine learning
algorithms, thus to identify best set of learning mechanisms
that could enable using the armband in a rehabilitation context.
ACKNOWLEDGMENT
The authors would like to thank the volunteers who have
participated in this study contributing to our understanding of
fatigue and optimal gesture detection algorithms.
REFERENCES
[1] V. I. Pavlovic, R. Sharma, and T. S. Huang, “Visual interpretation
of hand gestures for human-computer interaction: A review,” IEEE
Transactions on Pattern Analysis & Machine Intelligence, no. 7, 1997,
pp. 677–695.
[2] F. Amirabdollahian and M. L. Walters, “Application of support vector
machines in detecting hand grasp gestures using a commercially off the
shelf wireless myoelectric armband,” in 2017 International Conference
on Rehabilitation Robotics (ICORR), July 2017, pp. 111–115.
[3] A. Chaudhary, J. L. Raheja, K. Das, and S. Raheja, “Intelligent
approaches to interact with machines using hand gesture recognition
in natural way: A survey,” CoRR, vol. abs/1303.2292, 2013. [Online].
Available: http://arxiv.org/abs/1303.2292
[4] R. Z. Khan and N. A. Ibraheem, “Comparative study of hand gesture
recognition system.”
Citeseer, 2012.
[5] B. Leon. et. al, “Grasps recognition and evaluation of stroke patients
for supporting rehabilitation therapy,” BioMed research international,
vol. 2014, 2014, pp. 1–14.
[6] M. Tavakolan, Z. G. Xiao, and C. Menon, “A preliminary investigation
assessing the viability of classifying hand postures in seniors,”
BioMedical Engineering OnLine, vol. 10, no. 1, Sep 2011, p. 79.
[Online]. Available: https://doi.org/10.1186/1475-925X-10-79/[accessed:
2019-01-6]
[7] N. Wang, Y. Chen, and X. Zhang, “The recognition of multi-ﬁnger
prehensile postures using lda,” vol. 8, 11 2013, p. 706712.
[8] F. Amirabdollahian, M. Walters, R. Heffernan, S. Fletcher, and P. Webb,
“Using myoelectric signals for gesture detection: a feasibility study,” 4
2017, pp. 353–358. [Online]. Available: http://www.ehf2017.org.uk/
[9] F. Amirabdollahian and M. L. Walters, “Application of support vector
machines in detecting hand grasp gestures using a commercially off the
shelf wireless myoelectric armband,” in 2017 International Conference
on Rehabilitation Robotics (ICORR), July 2017, pp. 111–115.
[10] J. L. Ingles, G. A. Eskes, and S. J. Phillips, “Fatigue after stroke,”
Archives of physical medicine and rehabilitation, vol. 80, no. 2, 1999,
pp. 173–178.
[11] T. J. Braley and R. D. Chervin, “Fatigue in multiple sclerosis: mecha-
nisms, evaluation, and treatment,” Sleep, vol. 33, no. 8, 2010, pp. 1061–
1067.
[12] F. Staub and J. Bogousslavsky, “Fatigue after stroke: a major but
neglected issue,” Cerebrovascular Diseases, vol. 12, no. 2, 2001, pp.
75–81.
[13] C. Lan Nguyen Hoang. et. al, “Physical factors associated with fatigue
after stroke: an exploratory study,” Topics in stroke rehabilitation,
vol. 19, no. 5, 2012, pp. 369–376.
[14] T. Nourhan, M. Piechnick, J. Falkenberg, and T. Nazmy, “Detection
of muscle fatigue using wearable (myo) surface electromyography
based control device,” in Information Technology (ICIT), 2017 8th
International Conference on.
IEEE, 2017, pp. 44–49.
[15] J. H. Carr and R. B. Shepherd, A motor relearning programme for stroke.
Aspen Pub, 1987.
[16] P. Kan, R. Huq, J. Hoey, R. Goetschalckx, and A. Mihailidis, “The
development of an adaptive upper-limb stroke rehabilitation robotic
system,” Journal of neuroengineering and rehabilitation, vol. 8, no. 1,
2011, p. 33.
[17] Y. Qin, N. Rahman, and F. Amirabdollahian, “Asymmetrical perfor-
mance and abnormal synergies of the post-stroke patient wearing script
passive orthosis in calibration, exercise and energy evaluation,” Adv
Robot Autom, vol. 3 (2): 1000122, June, 2014.
[18] A. Basteris, S. M. Nijenhuis, J. H. Buurke, G. B. Prange, and F. Amirab-
dollahian, “Lag–lead based assessment and adaptation of exercise speed
for stroke survivors,” Robotics and autonomous systems, vol. 73, 2015,
pp. 144–154.
[19] M. A. Oskoei, H. Hu, and J. Q. Gan, “Manifestation of fatigue in
myoelectric signals of dynamic contractions produced during playing pc
games,” in Engineering in Medicine and Biology Society, 2008. EMBS
2008. 30th Annual International Conference of the IEEE.
IEEE, 2008,
pp. 315–318.
[20] M. A. Oskoei∗ and H. Hu, “Support vector machine-based classiﬁcation
scheme for myoelectric control applied to upper limb,” IEEE Transac-
tions on Biomedical Engineering, vol. 55, no. 8, Aug 2008, pp. 1956–
1965.
[21] Myo
Armband
from
Thalmic
Labs.
[Online].
Available:
https://www.thalmic.com/[accessed: 2019-01-7]
[22] H.-P. Huang and C.-Y. Chen, “Development of a myoelectric dis-
crimination system for a multi-degree prosthetic hand,” in Proceedings
1999 IEEE International Conference on Robotics and Automation (Cat.
No.99CH36288C), vol. 3, 1999, pp. 2392–2397 vol.3.
[23] J. Valls-Sol´e, J. C. Rothwell, F. Goulart, G. Cossu, and E. Munoz,
“Patterned ballistic movements triggered by a startle in healthy humans,”
The Journal of physiology, vol. 516, no. 3, 1999, pp. 931–938.
164
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-686-6
ACHI 2019 : The Twelfth International Conference on Advances in Computer-Human Interactions

