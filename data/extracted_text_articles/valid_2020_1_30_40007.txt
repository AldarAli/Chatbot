Toward an Exact Simulation Interval for
Multiprocessor Real-Time Systems Validation
Joumana Lagha, Jean-Luc B¬¥echennec, S¬¥ebastien Faucou and Olivier-H Roux
Universit¬¥e de Nantes, ¬¥Ecole Centrale de Nantes, CNRS, LS2N, UMR 6004, F-44000 Nantes, France
Email: Ô¨Årstname.lastname@ls2n.fr
Abstract‚ÄîIn order to study the schedulability of complex real-
time systems, simulation can be used. Of course, to achieve formal
validation of schedulability, simulations must be run long enough
such that the schedule repeats. An upper bound on the length
of the simulation that is valid for a very wide class of systems
running on top of identical multiprocessor platforms is given
in a previous work. It is known that this bound is pessimistic.
In this paper, we derive a characterization of the exact bound
for the same class of systems and describe an algorithm for
its computation. We use it to quantify the pessimism of the
upper bound on a set of synthesized systems. We also give some
directions to explore the complexity vs. tightness trade-off for
this problem.
Keywords‚ÄìReal time scheduling; Multiprocessor; Simulation.
I.
INTRODUCTION
The correctness of real-time software systems does not
depend only on the value of results, but also on the date they
are produced. A real-time software is usually composed of a set
of recurring tasks that spawns jobs. Each job must be executed
within a given deadline. Scheduling algorithms are used to
allocate execution time to jobs. Schedulability analysis is used
to validate that the resulting schedule meets all deadlines.
For well-deÔ¨Åned classes of systems, efÔ¨Åcient schedulability
tests exist [1]. For complex systems, that are not in one of
these classes, it is sometimes possible to rely on simulation.
More precisely, this is possible if the context does not yield
scheduling anomalies, ie. when response times variations are
monotonic with regards to other system parameters. In this
paper, we will assume work under this hypothesis and refer
the reader to Section 7 of [2] for a discussion on this point.
To achieve formal validation of the system, the simulation
must be run on an interval long enough such that the schedule
repeats. If the scheduler is deterministic and memoryless, then,
if in this interval all jobs meet their deadline, it can be safely
concluded that the system is schedulable. The length of this
interval can be discovered during simulation by comparing
each new state to those encountered so far. The main drawback
of this approach is that it requires to memorize all states,
so it quickly becomes intractable. An alternative consists of
computing an upper bound B on the length of the simulation
interval and then simulate the system on [0, B). In 2016,
Goossens et al. [2] proposed an upper bound that is valid
for a wide class of systems: periodic asynchronous tasks with
arbitrary deadlines and structural constraints (such as prece-
dence, mutual exclusion and self-suspension) scheduled on top
of an identical multiprocessor platform by any deterministic
and memoryless algorithm.
It is known that this bound is pessimistic, especially
because it does not take into account the processing power
of the platform. Before looking for possible improvements,
it is interesting to evaluate how pessimistic it is. To answer
this question, we derive a characterization of the exact bound
for the same class of systems and describe an algorithm for
its computation. The algorithm relies on an enumeration of
the state space and has factorial time complexity. On a set of
synthetic systems, we Ô¨Ånd out that the pessimistic bound is
at least twice too long when the number of tasks is greater
than three times the number of processors. Based on the exact
formulation of the bound, we also suggest directions to explore
tightness vs. complexity trade-off for this problem.
The paper is organized as follows: in Section II, we review
related works. In Section III, we deÔ¨Åne notations and expose
the state-of-the-art. In Section IV, we give a characterization of
the exact bound and derive an algorithm for its computation. In
Section V, we compare the state-of-the-art and the exact bound
on a set of synthetic benchmarks to quantify its pessimism.
In Section VI, we present possible directions to explore the
tightness vs. complexity trade-off before concluding the paper.
II.
RELATED WORKS
The Ô¨Årst result on simulation intervals is obtained by Leung
and Merrill [3] in 1980, with Omax + 2H (where Omax is
the maximum activation offset and H is the hyperperiod) as
an upper bound for independent asynchronous task systems
with constrained deadlines scheduled with a Ô¨Åxed-task priority
algorithm. The same bound was later deemed valid for systems
with arbitrary deadlines by Goossens and Devillers [4]. For
multiprocessor platforms, Cucu and Goossens [5] derive in
2007 a result for independent asynchronous task systems (a
task system is asynchronous if at least two tasks have their
Ô¨Årst activation on different dates) with arbitrary deadlines
scheduled by a global Ô¨Åxed-task priority algorithm. They also
prove that any feasible schedule generated by a deterministic
and memoryless scheduler is ultimately periodic. In 2012, Baru
et al. [6] proposed an upper bound on the simulation interval
for asynchronous task systems with constrained deadlines sub-
ject to simple precedence constraints running on an identical
multiprocessor platform and scheduled by any deterministic
and memoryless algorithm. The same interval is used and
tuned for Ô¨Åxed-job priority schedulers and independent tasks
in N¬¥elis et al. [7]. The most recent and general result is the one
proposed by Goossens et al. [2] in 2016, that applies to a very
large class of systems: asynchronous task systems with arbi-
trary deadlines, subject to structural constraints (precedence,
mutual exclusion, self suspension), scheduled on an identical
7
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

multiprocessor platform by any deterministic and memoryless
scheduler. This bound has a low complexity, is safe but not
always tight. For many systems, it is very pessimistic and too
big to be used for practical purpose. Thus, in this paper, we aim
at deriving an exact bound. To do so, we relax the constraint on
the complexity of the computation. Dues to its complexity, our
bound can be computed for a restricted class of systems. For
these systems, it provides an exact simulation interval. While
deriving an exact bound, we also highlight how to explore
the complexity vs. precision trade-off, paving the way to the
development of low complexity yet precise bounds.
III.
UPPER BOUND ON THE SIMULATION INTERVAL [2]
A. Model, notations, and deÔ¨Ånitions
N is the set of integer numbers. Let v be a vector of NN.
‚àÄi ‚àà [1, N], v[i] is the ith element of the vector v. We note that
0 the null vector: ‚àÄi ‚àà [1, N]. 0[i] = 0. The usual operators
+, ‚àí, √ó, < and = are used on vectors of NN and are the point-
wise extensions of their counterparts in N. {x | P(x)} is set
set of all x such that predicate P(x) is true. [x | P(x)] is the
list of all x such that predicate P(x) is true.
Let Œò = {œÑ1, œÑ2, . . . , œÑN} be a set of N asynchronous
periodic tasks, where each task œÑi is the 4-tuple of non negative
integers ‚ü®Oi, Ci, Ti, Di‚ü©, where Oi is the release time of the
Ô¨Årst job of œÑi, Ci is the execution time of œÑi, Ti is the period of
œÑi, and Di its deadline. We assume that periods and deadlines
are unrelated (i.e., Di can be smaller than, equal to, or greater
than Ti). H = lcmœÑi‚ààŒò{Ti} is the hyperperiod of Œò.
At runtime, each task œÑi spawns an inÔ¨Ånite sequence of
jobs œÑi,1, œÑi,2, . . .. Job œÑi,j enters the system at date ai,j =
Oi+(j‚àí1)Ti. It must be executed before date di,j = ai,j+Di.
Let S(t) be the state of the system at date t. It is deÔ¨Åned
by S(t) = (Crem1(t), . . . , Cremn(t), ‚Ñ¶1(t), . . . ‚Ñ¶n(t)), where
Cremi is the remaining work to process for the jobs of task œÑi
activated prior to t, and ‚Ñ¶i(t) is a decrementing clock counting
the time until the next release of a job of œÑi.
Œò is executed on a platform composed of m identical pro-
cessors. Jobs are scheduled by a deterministic and memoryless
scheduler (see below). A given job is executed sequentially
(no inner parallelism) but can migrate from one processor to
another during its execution. It is assumed that there is no
penalty to migrate from one processor to another. Moreover, it
is assumed that a job cannot start its execution while all jobs
of the same task activated before are not Ô¨Ånished.
DeÔ¨Ånition 1 (Feasible schedule): A feasible schedule for
Œò is an inÔ¨Ånite schedule such that every job œÑi,j is fully
executed in its time window [ai,j, di,j].
DeÔ¨Ånition 2 (Deterministic and memoryless scheduler):
A scheduler such that the scheduling decision at time t is
unique and depends only on the current state of the system.
DeÔ¨Ånition 3 (Valid simulation interval): Interval [0,B) is a
valid simulation interval for Œò scheduled with a determin-
istic and memoryless scheduler if and only if ‚àÉ(t1, t2) ‚àà
[0, B]2.
t1 Ã∏= t2 ‚àß S(t1) = S(t2).
The model has two features that make its schedulability
analysis complex: arbitrary deadlines and asynchronous acti-
vation. Both are sources of backlog between hyperperiods.
DeÔ¨Ånition 4 (Backlog): The backlog Œ≤i(t) of a task œÑi at
date t is deÔ¨Åned as the remaining work to be processed for
jobs of œÑi activated strictly before t.
In the following, we assume that all hypotheses formulated
in this section hold.
B. Ruling out asynchronous activations
To rule out the complexity arising from asynchronous task
activation, Goossens et al. observe that a simple transformation
can be applied to an asynchronous task set Œò to obtain a
synchronous task set Œò‚Ä≤ such that the length of the simulation
interval of Œò‚Ä≤ (considering any deterministic and memoryless
scheduler) is not smaller than that of Œò. For each task œÑi =
‚ü®Oi, Ti, Di‚ü©, the transformation yields œÑ ‚Ä≤
i = ‚ü®0, Ti, Oi + Di‚ü©.
The idea is that all feasible schedules of Œò are also feasible
schedules of Œò‚Ä≤. Thus, if a simulation is run for a duration long
enough to validate any feasible schedule of Œò‚Ä≤, it is also long
enough to validate any feasible schedule of Œò. A detailed proof
is given in [2].
Given this result, we can now reason as if we only had
to handle synchronous task sets. Thus, we can now give a
trivial upper bound on the backlog of a task at the end of a
hyperperiod: ‚àÄq > 0. Œ≤i(qH) ‚â§ (Oi + Di) ‚àí Ti. From now
on, we note Œ≤max
i
= max{0, (Oi + Di) ‚àí Ti} the maximum
backlog for task œÑi at any date t = qH in any feasible schedule,
and we note Œ≤max = maxœÑi‚ààŒò Œ≤max
i
.
C. Extension to structural constraints
The approach used to rule out asynchronous activation
can be used to extend the result to systems with structural
constraints. Structural constraints are deÔ¨Åned as ‚Äúa relation
between jobs or subjobs, forbidding some execution orders,
preemptions, or insuring a minimal delay between the end
of a job (or sub-job) and the start of another one‚Äù [2].
Let Œò a system with structural constraints. Let Œò‚Ä≤ denote
the same system where all structural constraints have been
removed. Obviously, all feasible schedules of Œò are also
feasible schedules of Œò‚Ä≤. Thus, a valid simulation interval for
Œò‚Ä≤ is also a valid simulation interval for Œò.
D. Deriving the bound
In any non trivial synchronous system such that at least two
tasks have different periods, the search for the upper bound of
a valid simulation interval can be reduced to solutions of the
form B = qH (with q a positive integer) by deÔ¨Ånition of H
(the hyperperiod of Œò) since local clocks are equal in S(0)
and S(qH).
By deÔ¨Ånition, for any non negative integer q, Cremi(qH) =
Œ≤i(qH), so in any feasible schedule, Cremi(qH) ‚â§ Œ≤max
i
.
Then, we can bound the number of different states of the
system in any feasible schedule at the end of a hyperperiod:
|{S(qH) | q ‚àà N}| ‚â§ Q
i‚àà[1,N] (Œ≤max
i
+ 1). Using the
assumption that the scheduler is deterministic and memoryless,
it is sufÔ¨Åcient to run the simulation long enough to cover a
number of hyperperiods equal to the number of different states
at the end of a hyperperiod. If the schedule is not feasible then
a deadline miss will be discovered. If the schedule is feasible,
8
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

either the same state will have been encountered twice, or all
states will have been explored. This yields the bound:
B0 = H √ó
Y
i‚àà[1,N]
(Œ≤max
i
+ 1)
(1)
E. Non tightness of B0
As claimed by the authors in [2], the bound is safe but
not tight. This is illustrated in Figure 1. Let us consider a
system with two tasks œÑ1 and œÑ2 such that 0 < Œ≤max
1
< Œ≤max
2
,
running on a monoprocessor platform. The size of the state
Œ≤1
Œ≤2
Œ≤max
1
Œ≤max
2
Œ≤1 + Œ≤2 = max{Œ≤max
1
, Œ≤max
2
}
Figure 1. Illustration of the non-tightness of the bound: states in the red
dotted area do not belong to any feasible schedule.
space considered by the bound B computed above is the
number of points with integer coordinates in the rectangle
of width Œ≤max
2
and height Œ≤max
1
. Now, let us consider the
points in the red dotted area. They correspond to a pending
work at the end of a hyperperiod, which is strictly greater than
max{Œ≤max
1
, Œ≤max
2
} = Œ≤max
2
. Starting from such a state at any
t = qH, in any schedule, at least one job activated before t will
Ô¨Ånish after t + Œ≤max
2
thus missing its deadline. We conclude
that this state can not belong to any feasible schedule.
IV.
EXACT BOUND ON THE SIMULATION INTERVAL
A. Characterization
We have seen with Figure 1 that B0 fails to take into
account diagonal constraints arising from the fact that the plat-
form limits the execution parallelism and thus the maximum
amount of cumulative backlog at the end of a hyperperiod.
We can generalize this argument to derive a characterization
of the bound as a set of linear constraints. Let Œõ ‚äÜ Œì be
a subset of the task set. On a monoprocessor platform, the
cumulative backlog at the end of a hyperperiod generated by
tasks in Œõ is bounded by max[Œ≤max
i
| œÑi ‚àà Œõ] where max
returns the maximum value of a list. On a 2-processor platform,
execution parallelism allows us to achieve a higher bound:
max2[Œ≤max
i
| œÑi ‚àà Œõ] where max2 returns the sum of the 2
greatest values of a list. Indeed, even if two jobs can be exe-
cuted in parallelism, in a feasible schedule, they cannot overrun
their deadlines. Thus, when the time is past the penultimate
deadline, only one job among the jobs activated before the end
of the hyperperiod, has not reached its deadline, so in a feasible
schedule only this job could be running. Further generalizing
this argument, on a m-processor platform, every Œõ ‚äÜ Œì yields
the constraints P
œÑi‚ààŒõ Œ≤i ‚â§ maxm[Œ≤max
i
| œÑi ‚àà Œõ] where
maxm returns the sum of the m greatest values of a list. This
allows us to characterize the number of possible states at the
end of a hyperperiod (since we know that all local clocks
are null at such instants, the state is truncated to its Cremi(t)
components).
S =
n
x |x ‚àà NN ‚àß
‚àÄŒõ ‚äÜ Œò.
X
œÑi‚ààŒõ
x[i] ‚â§ maxm[Œ≤max
i
| œÑi ‚àà Œõ]
o
(2)
From this, we can derive the exact value of the bound on
the simulation interval:
B1 = H √ó |S|
(3)
Note that using 2 to compute B involves computing the
power set of Œò (to enumerate all possible values of Œõ), which
has 2|Œò| elements, and then enumerating the number of integer-
coordinate points over a linear polyhedron deÔ¨Åned by 2|Œò|
constraints. It must also be noticed that B0 corresponds to
the enumeration of the points with integer coordinates of the
smallest hyperrectangle that contains S and is exact when the
deÔ¨Ånition of S involves no diagonal constraints, i.e., when the
number of tasks is not greater than the number of processors.
B. Computation of B1
To count the number of states in S, we rely on a Ô¨Åxed
point computation. We start from state 0 and date qH. We
expand the set of states time unit per time unit. Each time
unit, we add states that have a cumulative backlog that Ô¨Åts in
this extra time unit while taking into account platforms and
tasks constraints. We stop once we have reached a Ô¨Åxed point
over the set of states. We Ô¨Årst describe the algorithm, then
prove its termination, soundness, completeness, and apply it
to a simple example.
1) One time unit mappings: Let us consider Act : N ‚Üí
{0, 1}N such that ‚àÄt ‚àà [0, Œ≤max). ‚àÄi ‚àà [1, N]. Act(t)[i] =
0 iff t ‚â§ Œ≤max
i
, and Act(t)[i] = 1 otherwise. That is to
say Act(t)[i] = 1 iff a job of œÑi activated before t has not
necessarily reached its deadline at date t.
Let Incr = {v | v ‚àà {0, 1}N ‚àß PN
i=1 v[i] ‚â§ m}. An
element of Incr is a mapping of tasks to processors (remember
that jobs of the same task must execute sequentially). As an
example, for N = 3 tasks and m = 2 processors we have:
Incr =
0
0
0

,
0
0
1

,
0
1
0

,
1
0
0

,
1
1
0

,
0
1
1

,
1
0
1

Let incr be a function from date to parts of Incr such
that incr(t) = {v|v ‚àà Incr ‚àß v √ó Act(t) = v}. incr(t)
describes the mappings of tasks to processors for [t, t + 1) in
any feasible schedule, discarding those which execute a job
of a task that has already missed its deadline. For example,
9
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

assuming N = 3 tasks, m = 2 processors, and Act(1) =
0
0
1

,
then we have:
incr(1) =
0
0
0

,
0
0
1

Lemma 1: A one time unit mapping of tasks onto pro-
cessor inc for interval [qH + t, qH + t + 1) for any non
negative integer q is part of a feasible schedule if and only
if inc ‚àà incr(t).
Proof: Follows from the deÔ¨Ånition of incr.
DeÔ¨Ånition 5 (Possible mapping): A possible mapping is a
one time unit mapping of tasks onto processor inc ‚àà incr(t).
2) Fixed point algorithm: Let S be a set of states. We
deÔ¨Åne the successor of S by elapsing one time unit from date
qH + t to qH + t + 1 as follows:
next(S, t) = {s + inc | s ‚àà S ‚àß inc ‚àà incr(t)}
(4)
Given this deÔ¨Ånition of next, the set of possible states of
the system at the end of a hyperperiod in any feasible schedule
is the smallest Ô¨Åxed point of:

S0 = {0}
Sn+1 = Sn ‚à™ next(Sn, n)
(5)
The resulting bound B1 can be computed with algorithm
in Figure 2 below.
Figure 2. Fixed point algorithm for the computation of the exact bound B1.
3) Termination: Recall that Œ≤max
= maxœÑi‚ààŒò{Œ≤i} is
the greatest possible backlog of any task at the end of a
hyperperiod. From the deÔ¨Ånition of function incr, we have
incr(Œ≤max) = {0} and then the smallest Ô¨Åxed point is met at
worst in Œ≤max steps. During the computation of B1 each state
of S has to be stored. The number of states is upper bounded
by the B0. During the computation of B1, each new state has
to be compared to the set of states already explored. Hence
our algorithm has also a factorial complexity in the state space
size. A more detailed analysis, including a complexity analysis
of the problem is out of the scope of this paper.
4) Soundness and Completeness :
Theorem 1 (Completeness and Soundness): s ‚àà S if and
only if s is reachable by a feasible schedule from 0 .
Proof: Soundness. Ab absurdo. Assume that there exists
a state s ‚àà S which is not reachable by a feasible schedule
from 0. Then, there exists t ‚àà [0, Œ≤max), a state st ‚àà St that is
reachable through possible mappings from 0 and a state st+1 ‚àà
St+1 that is not reachable through possible mappings from
0 such that st+1 ‚àà next({st}, t). Then, there exists inc ‚àà
incr(t) such that st+1 = st + inc whereas inc is not possible
at date t contradicting Lemma 1.
Completeness. Ab absurdo. Assume that there exists a state
s which is reachable through possible mappings from 0 and
such that s Ã∏‚àà S. Then, there exists t ‚àà [0, Œ≤max) and a state
st+1 that is reachable by a possible mapping from st ‚àà St
such that st+1 Ã∏‚àà next({st}, t). Then, there exists inc such
that sk+1 = sk + inc and inc Ã∏‚àà incr(t) whereas inc is
possible at date t contradicting Lemma 1.
5) Example: Consider a system with N = 3 tasks running
on a platform with m = 2 processors. The charactetistics of
the tasks are such that
Œ≤1
Œ≤2
Œ≤3
=
1
1
3

. The possible mappings of
tasks to processors in the Ô¨Årst time unit after a hyperperiod is
given by:
incr(0) = Incr =
0
0
0

,
0
0
1

,
0
1
0

,
1
0
0

,
1
1
0

,
0
1
1

,
1
0
1

and possible mappings in the following time units are given
by:
incr(1) = incr(2) =
0
0
0

,
0
0
1

and incr(3) =
0
0
0

Now, let us compute the smallest Ô¨Åxed point.
S0 =
0
0
0

, S1 =
0
0
0

,
0
0
1

,
0
1
0

,
1
0
0

,
1
1
0

,
0
1
1

,
1
0
1

,
S2 =
0
0
0

,
0
0
1

,
0
1
0

,
1
0
0

,
1
1
0

,
0
1
1

,
1
0
1

,
0
0
2

,
1
1
1

,
0
1
2

,
1
0
2

and then
S = S3 =
0
0
0

,
0
0
1

,
0
1
0

,
1
0
0

,
1
1
0

,
0
1
1

,
1
0
1

,
0
0
2

,
1
1
1

,
0
1
2

,
1
0
2

,
0
0
3

,
1
1
2

,
0
1
3

,
1
0
3

We obtain B1 = H√ó|S| = 15H. With the same system, we
have B0 = H√ó(2√ó2√ó4) = 16H. The state that was discarded
in B1 is
1
1
3

because it requires 5 time units of computation
but a valid schedule cannot have more than max2{1, 1, 3} = 4
time units of pending work.
V.
EXPERIMENTATION
A. Setup
The computation of B1 has factorial time complexity so it
does not scale to big systems. Its main interest is to provide
a reference to assess the tightness of approximate bounds.
In particular, it is worth asking when B0 is a reasonable
10
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

TABLE I. DETAILS AND PARAMETERS FOR THE 5 SERIES OF EXPERIMENTS
Series
N
m
Œ≤max
Watchdog expiry time
Timeout (%)
1
1 ‚â§ N ‚â§ 12
1 ‚â§ m ‚â§ 8
20
15 min for N ‚â§ 9 and 20 min for N > 9
18.47
2
1 ‚â§ N ‚â§ 12, 11 excluded
1 ‚â§ m ‚â§ 8
10
15 min for N ‚â§ 10 and 45 min when N is 12
8.92
3
1 ‚â§ N ‚â§ 12
1 ‚â§ m ‚â§ 8
5
15 min
7
4
k ‚â§ N ‚â§ 9 with k = 2 √ó m
1 ‚â§ m ‚â§ 4
(10 ‚àí N) √ó 8
10 min
0.75
5
16
4
2 ‚â§ Œ≤max ‚â§ 6
10 min
29
approximation, and if it is worth searching for less pessimistic
approximations for certain systems. Thus, in this section,
we evaluate the pessimism of bound B0 with respect to
B1. We also provide some results concerning the resource
consumptions of the computation of B1 to characterize the
range of systems that it can solve.
We implemented algorithm 2 in C, using red-black trees
as the data structure for state sets. Computations have been
run on a Debian GNU/Linux 8.8 system (kernel 3.16.0-4)
with Intel(R) Xeon(R) CPU E5-2620 @ 2.00GHz and 128GB
RAM. The evaluation set is based on Ô¨Åve series of experiments.
In each case, we take 20 samples per point (a point is
deÔ¨Åned by a number of tasks, a number of processors, and
a value for Œ≤max), and the algorithm is applied to each
point. For each sample, the maximum backlog of each task
is randomly generated between 1 and Œ≤max using a uniform
distribution. The code is instrumented to report execution time
and maximum memory consumption of the computation of B1.
Lastly, a watchdog is used to stop the computation of B1 after
a pre-deÔ¨Åned amount of time. Parameter values for each series
are shown in Table I.
We provide a set of graphs that have been chosen to be
as representative as possible of the data set. For each point,
we represent the arithmetic average as well as minimum and
maximum values among all 20 samples. In each Ô¨Ågure the y-
axis represents the ratio B1/B0 as a percentage. The quantity
associated with the x-axis varies so it is speciÔ¨Åed in each Ô¨Ågure.
B. Pessimism of B0
Figure 3 shows the result when the number of tasks
increases for a given number of processors. Figure 4 shows
the result when the number of processors increases for a given
number of tasks. As expected, both Ô¨Ågures show that when
the number of diagonal constraints increases, B0 becomes
more pessimistic. From 2, diagonal constraints appear for sets
Œõ ‚äÜ Œò such that |Œõ| > m, i.e., when the platform does
not offer enough parallelism. Thus, the number of diagonal
constraints increases with N
m. Figure 5 plots B1
B0 against N
m. It
shows that, on this data series, B0 quickly becomes a loose
approximation of B1: when N
m becomes greater than 3, B1
B0 falls
to 50 %, and below for higher values of N
m. The complexity
of the computation of B1 does not allow us to extend the plot
further but it is expected that, as the number of linear constraint
increases, B1
B0 asymptotically tends to zero.
Figure 7 plots B1
B0 against the standard deviation computed
over the list [Œ≤max
i
| œÑi ‚àà Œò]. Although it is not as clear as
the impact of N
m, it shows that when the standard deviation
is small, B0 tends to be more pessimistic. Figure 7 also
shows that similar values of B1
B0 can be reached for different
values of Œ≤max with similar dispersion of values of Œ≤max
i
. An
2
3
4
5
6
7
8
9
0
20
40
60
80
100
Number of tasks
Relative number of states (%)
m=1
m=2
m=4
Figure 3. N = 1 to 9 tasks, m = 1 to 4 processors, Œ≤max = 20.
1
2
3
4
5
6
7
8
0
20
40
60
80
100
Number of processors
Relative number of states (%)
N=6
N=8
N=10
N=12
Figure 4. N ‚àà {6, 8, 10, 12} tasks, m = 1 to 8 processors, Œ≤max = 10.
intuitive interpretation can be formulated from the example
of Ô¨Ågure 1: if Œ≤max
1
= Œ≤max
2
then the diagonal constraints
Œ≤1 + Œ≤2 ‚â§ max{betamax
1
, Œ≤max
2
} removes half of the points
of B0 and this is the worst case. So, the closer the values of
Œ≤max
i
in numerous mismatch, the more states it removes. And
of course, a small standard deviation denotes a system with a
small dispersion of Œ≤max
i
values.
C. Scalability of algorithm 2
The computation of B1 requires a factorial number of
comparisons with regards to the size of the state space of the
system. Thus, it is sensible to every parameter that has an
impact on the state space: number of tasks N, of processors
m, and the maximum backlogs of tasks Œ≤max
i
.
Table II groups results for N = 16 and m = 4. In this
case, the average execution time increases from 6.25 s to 385 s
11
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

2
3
4
0
20
40
60
80
100
N
m
Relative number of states (%)
Figure 5. N = 1 to 12 tasks, m = 1 to 4 processors, Œ≤max = 20.
2
3
4
5
6
5
10
15
Œ≤max
Relative number of states (%)
Figure 6. N = 16 tasks, m = 4 processors, Œ≤max = 2 to 6.
1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6 6.5 7
65
70
75
80
85
90
95
100
standard deviation of [Œ≤max
i
| œÑi ‚àà Œò]
Relative number of states (%)
Œ≤max = 5
Œ≤max = 10
Œ≤max = 20
Figure 7. N = 8 tasks, m = 4 processors, Œ≤max ‚àà {5, 10, 20}.
TABLE II. EXECUTION TIME (IN SECONDS), WHEN N = 16 AND
m = 4
Œ≤max
Average
Maximum
Minimum
Standard deviation
3
6.25
22
microseconds
6.146244039
4
124.68
364
2
143.8439944
5
385
599
94
169.7838733
TABLE III. EXECUTION TIME (IN SECONDS), WHEN m = 4 AND
Œ≤max = 20
N
Average
Maximum
Minimum
Standard deviation
6
5.95
33
microseconds
9.827324956
7
124.2
511
1
136.6607786
8
254.54
701
18
302.4903777
just by increasing Œ≤max from 3 to 5. Table III groups results
for m = 4 and Œ≤max = 20. In this case, the average execution
time increases from 5.95 s to 254.54 s just by increasing N
from 6 to 8. Lastly, Table IV groups results for N = 8 and
Œ≤max = 20. In this case, the average time increases from 1.05 s
to 130.4 s just by increasing the m from 1 to 3. From these
three tables, the inÔ¨Çuence of the individual Œ≤max
i
values on
the overall execution time can also be seen: in Table II for
example, with N = 16, m = 4 and Œ≤max = 5, the execution
time varies from 94 s to 599 s.
Similar results are observed for memory occupation. In-
deed, the whole state space has to be stored. Table V shows for
instance the maximum memory occupation for varying values
of N and m when Œ≤max = 20. As expected, the time and
space complexity of algorithm 2 makes it impossible to deal
with systems that have too large a state space. Nevertheless,
many industrial systems use small multicore platforms. For in-
stance, the 32 bit Microcontroller TriCore family developed by
InÔ¨Åneon for the embedded automotive market offers platforms
with 1 to 6 cores. Moreover, not all tasks in these systems have
a non null backlog at hyperperiod boundaries, so B1 could be
of practical use for these systems. Additional experiments on
industrial benchmarks are required to provide an answer to this
question and it is out of the scope of this paper.
VI.
CONCLUSION
The problem addressed in this paper is to compute an exact
bound on the simulation interval for systems of asynchronous
periodic tasks with arbitrary deadlines subject to structural
TABLE IV. EXECUTION TIME (IN SECONDS), WHEN N = 8 AND
Œ≤max = 20
m
Average
Maximum
Minimum
Standard deviation
1
1.05
6
microseconds
1.637552731
2
98
343
4
95.8200067
3
130.4
899
1
361.2071865
TABLE V. RESIDENT SET SIZE USED (IN MB), WHEN Œ≤max = 20
N
m
Average
Maximum
Minimum
Std dev.
5
1
4.056
5.492
3.980
0.3380934782
6
1
13.935
47.980
3.988
13.92257703
7
1
108.555
640.840
3.812
166.1081405
8
1
1398.797
8286.392
66.756
2350.883606
9
1
15832.102
103894.004
640.600
28790.4245
5
2
8.250
19.372
3.980
5.43988676
6
2
35.805
168.132
3.988
39.78900124
7
2
238.146
940.680
10.796
229.4609528
8
2
3027.923
10032.492
147.412
3030.038648
9
2
27974.981
95923.060
1027.404
15778.69099
12
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

constraints scheduled by any deterministic and memoryless
algorithm on a uniform multiprocessor platform. A very simple
yet pessimistic solution for this problem is already known
in the state-of-the-art. We formulate a characterization of the
bound that involves the cardinal of the set of points with
integer coordinates in a polyhedron deÔ¨Åned by an exponential
number of linear constraints. We propose and prove a Ô¨Åxed
point algorithm to compute this set, which has factorial time
complexity.
We rely on an implementation of this algorithm to estimate
the pessimism of the bound known from the state-of-the-
art through a set of experiments on synthetic systems. In
the results of these experiments we observe two points: (i)
the bound from the state-of-the-art quickly becomes a loose
estimation of the exact bound when the number of tasks
becomes greater than the number of processors of the platform;
(ii) the time complexity of our algorithm is too high to deal
with anything but small systems. From these two points, we
conclude that there is an interest in looking at approximate
bounds that lie in the middle between the state-of-the-art
and the exact bound. Our formulation of the problem as a
linear system already gives us a direction. The state-of-the-art
provides a simple but pessimistic solution by discarding all
diagonal constraints, while the exact bound does the opposite.
So, as a direct follow-up to the work described here, we will
now explore the idea to take into account a subset of the
diagonal constraints to Ô¨Ånd a good trade-off between precision
and time complexity.
REFERENCES
[1]
R. I. Davis, A. Zabos, and A. Burns, ‚ÄúEfÔ¨Åcient exact schedulability tests
for Ô¨Åxed priority real-time systems,‚Äù IEEE Transactions on Computers,
vol. 57, no. 9, 2008, pp. 1261‚Äì1276.
[2]
J. Goossens, E. Grolleau, and L. Cucu-Grosjean, ‚ÄúPeriodicity of real-
time schedules for dependent periodic tasks on identical multiprocessor
platforms,‚Äù Real-Time Syst, vol. 52, no. 6, 2016, pp. 808‚Äì832.
[3]
J. Leung and J. Merrill, ‚ÄúA note on preemptive scheduling of periodic,
real-time tasks,‚Äù Information Processing Letters, vol. 11, no. 3, 1980, p.
115‚Äì118.
[4]
J. Goossens and R. Devillers, ‚ÄúFeasibility intervals for the deadline
driven scheduler with arbitrary deadlines,‚Äù in Proceedings Sixth Interna-
tional Conference on Real-Time Computing Systems and Applications.
RTCSA‚Äô99 (Cat. No.PR00306), 1999, pp. 54‚Äì61.
[5]
L. Cucu and J. Goossens, ‚ÄúFeasibility intervals for multiprocessor Ô¨Åxed-
priority scheduling of arbitrary deadline periodic systems,‚Äù in 2007
Design, Automation Test in Europe Conference Exhibition, 2007, pp.
1‚Äì6.
[6]
J. Baro, F. Boniol, M. Cordovilla, E. Noulard, and C. Pagetti, ‚ÄúOff-
line (optimal) multiprocessor scheduling of dependent periodic tasks,‚Äù in
Proceedings of the 27th annual ACM symposium on applied computing
(SAC), 2012, pp. 1815‚Äì1820.
[7]
V. N¬¥elis, P. Yomsi, and J. Goossens, ‚ÄúFeasibility intervals for homoge-
neous multicores, asynchronous periodic tasks, and fjp schedulers,‚Äù in
Proceedings of the 21st international conference on real-time networks
and systems, 2013, pp. 277‚Äì286.
13
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-830-3
VALID 2020 : The Twelfth International Conference on Advances in System Testing and Validation Lifecycle

