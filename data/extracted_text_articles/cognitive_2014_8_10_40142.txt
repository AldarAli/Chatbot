A Comparative Study of Neural Network Techniques to Perform Early Diagnosis of
Alzheimer’s Disease
Lara Dantas and Mˆeuser Valenc¸a
Polytechnic School of Pernambuco
University of Pernambuco
Recife, Brazil
Email: {ldc, meuser}@ecomp.poli.br
Abstract—The life expectancy of the population in most developed
countries is growing every day and hence there is an increase of
several age-related diseases. In Brazil, about 1.2 million people
have Alzheimer’s disease (AD), now considered the most common
type of dementia in the population. Although it is a degenerative
and irreversible disease, if diagnosed early, medications may be
administered to slow the progression of symptoms and provide
a better quality of life for the patient. Previous studies with
classiﬁers contained in the software Weka using a database with
values of 120 blood proteins, and they noticed that they could
classify the patient may or may not be diagnosed with AD
with an accuracy rate of 94% and 85%, respectively. Thus, this
study aims to use a new connectionist approach called Reservoir
Computing (RC) to perform early diagnosis of a patient with or
without AD, also compare these results with those obtained using
a Neural Network Multi-Layer Perceptron (MLP). This article
also envisions to utilize the Random Forest Algorithm to select
proteins from the original set and, thus, create a new protein
signature.
Keywords–Reservoir Computing; Alzheimer’s Disease; Neural
Network.
I.
INTRODUCTION
More developed countries are undergoing a major demo-
graphic shift. The older segments of the population are growing
at a faster rate, and therefore, there is an increase in age-related
diseases, especially progressive dementia disorders. First de-
scribed by psychiatrist Alois Alzheimer in 1907, Alzheimer’s
Disease (AD) is today the most common cause of dementia in
the elderly population.
According to the Brazilian Institute of Geography and
Statistics (IBGE) and the World Health Organization (WHO),
there are 1.2 million people with AD in Brazil. It is believed
that only 5% of the patients developed the disease at an early
stage, i.e., before 65 years of age. In patients where the AD
started after 65 years old, it is estimated that between 10%
and 30% of cases started after 85 years old [1].
AD is a degenerative disease that causes irreversible death
of several brain cells, the neurons. The patient suffering from
this disease has a brain with microscopic pathologic lesions,
known as neuritic plaques, and neuroﬁbrillary tangles [2]. In
addition, the brain of a person with Alzheimer’s is much
smaller than the brain of a healthy person.
This disease develops in each patient in a unique way;
however, there are several symptoms common to all of them,
for example, loss of memory, language disorders, depression,
aggression, among others.
Initially, the patient loses episodic memory, i.e., memory
that holds information of events and their spatio-temporal
relations. Thus, the old facts and the facts that just happened
are easily forgotten.
With the progress of the disease, semantic memory is also
lost, i.e., lexical knowledge, rules, symbols are forgotten and
the patient begins to lose its cultural identity [3].
Although it is an irreversible disease, if it is discovered in
its early stage, medications may be administered to slow the
progression of symptoms and prolong the patient’s welfare [4].
Thus, it is extremely important that mechanisms are developed
for the prediction of AD in the whole population.
In the literature, Herbert et al. [5] conducted a study
using a database of 120 samples of proteins contained in
plasma of several patients. He concluded in his research that
a combination of 18 of the 120 available proteins enabled the
realization of early diagnosis of AD with a accuracy rate of
91% using a set of tests with data from 92 patients who were
diagnosed with AD or not.
In addition, he also used another set of tests containing data
from 47 patients diagnosed with Mild Cognitive Impairment
(MCI). For this set, the accuracy rate was 81%. These values
were calculated from the average success rates found for all
classiﬁers used in clinical trials for both sets [6].
Afterwards, G`omez [6] conducted a study using 20 differ-
ent classiﬁers available in the software Weka and set various
signatures with 18, 10, 6 and 5 proteins. These proteins were
all contained in the set described by Herbert et al. The 10
protein signature reached a accuracy rate of 89% using the
AD test set and of 66% for the MCI test set. These success
rates were also calculated from the average values of the 20
classiﬁers used [6].
Since the results available in the literature use only clas-
siﬁcation techniques provided by the software Weka [7], this
work will use a new connectionist approach called Reservoir
Computing (RC) [15] to perform the classiﬁcation of a patient,
given the set of 5 and 10 proteins deﬁned by G`omez et al.
In order to compare the results obtained using the RC,
the classiﬁcation was also performed using a Multiple-Layer
Perceptron neural network (MLP). This topology is widely
used and it has a good performance for classiﬁcation problems
[8].
In addition to that, a study using the Random Forest
Algorithm [9] was conducted in order to select a new signature
of 10 proteins for the prediction of the Alzheimer’s Disease and
another for the diagnosis of MCI. This step was performed to
reduce costs for the diagnosis since G`omez used paid sofware
and other techniques for variable selection.
178
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

This article is organized into several sections. The ﬁrst
section contains information about the operation, structure and
simulation of Reservoir Computing. The next section describes
the methodology used throughout this work, i.e., what is
the database used and how it is organized, the experiments
and statistical analysis that was performed. Finally, there is
a section that displays the results and the last one with the
conclusions obtained in this work.
II.
Reservoir Computing
Recurrent Neural Networks (RNN) were created to en-
able the solution of dynamic problems. This is accomplished
through a feedback of a neuron in a layer i to that found in
some previous layer, i − j. This neural network topology has
a better resemblance to the operation and behaviour of the
human brain [10].
In 2001, a new approach for the design of the training of
a RNN was proposed by Wolfgang Mass called Liquid State
Machine (LSM) [11]. At the same time, but independently,
the same approach was described by Herbert Jaeger and called
Echo State Machine (ESN) [12].
Both ESN and LSM networks have the Echo State Property
(ESP) [13], i.e., due to the recurrent network connections,
information from previous entries are stored. However, these
data are not stored for an inﬁnite period of time, and as well
as the human brain, old information must be forgotten over
time. Thus, the neural network has a rich set of information
from the past and present therefore enhancing its applicability
to dynamic systems [14].
In 2007, Verstraeten coined the term Reservoir Computing
(RC) that uniﬁed the concepts described in ESN and LSM.
Since then, this term is used in literature to illustrate learning
systems which are represented by a dynamic recurrent neural
network [15].
The RC is composed of three parts: an input layer, which
as the MLP, represents the input variables of the problem, a
reservoir, which can be seen as a large distributed and dynamic
RNN with ﬁxed weights, and a linear output layer called
readout.
Figure 1 represents the RC topology with two neurons in
the input layer, three in the reservoir and one neuron in the
output layer.
A. Construction and Simulation of RC
The RC used in this work was developed in the Java
programming language to make use of the object-oriented
paradigm. This framework was created in order to solve
classiﬁcation and prediction problems and it was validated by
three Benchmarks available: Iris species, Thyreoide cancer and
diabetes.
The ﬁrst step to be taken in order to prepare the RC and
perform the data set classiﬁcation is conﬁguring its architec-
ture. Thus, it is necessary the amount of neurons that will
be used in input and output layers and the reservoir itself is
deﬁned.
Furthermore, several RC parameters should also be deter-
mined. Being a recent methodology, there are no studies that
Figure 1: RC architecture. The dashed lines represent the
weights that should be adjusted during the training of the
network.
prove how many neurons in the reservoir are necessary so
that the neural network has better performance, or the rate of
connectivity between these neurons. Therefore, for this work,
values were deﬁned based on some empirical tests performed.
Once the architecture of the neural network is determined,
the next step is to generate the weight matrices connecting
the input layer to the reservoir, Win, and the matrix with the
weights between neurons in the reservoir, Wres. Both matrices
are generated with random values between -1 and 1.
Studies claim that the matrix Wres must have a spectral
radius equal to 1 to provide a more numerical stability [16],
i.e., when Wres is initialized, it must have its values changed
as follows:
•
Initially it must be decomposed into singular values;
•
Then, Wres should have its values changed until the
maximum value of the main diagonal of the eigenval-
ues matrix is less than or equal to 1.
To perform the simulation of the RC, the database is
divided into three sets: training, used to perform the update
of the states of the neurons of the reservoir, cross-validation,
used to stop the training of the neural network, and test set,
used to calculate the RC classiﬁcation rate [17].
The states of the neurons in the reservoir must be initialized
to zero. Since this is a recurrent network and RC stores
its states (Mest) in a matrix, it is necessary that the ﬁnal
values found by the network are not so inﬂuenced by this
initialization. Therefore, the literature suggests that before start
training, a set of cycles called warm up is executed in order
to perform updates in the states of the neurons in the reservoir
and overlook the inﬂuence of the initial value. The states are
updated according to (1) [15]:
x[k + 1] = f(Wresx[k] + Winu[k])
(1)
where, Winu[k] represents the matrix containing the result
of the product of the values derived from the input layer by the
weights connecting these neurons to the reservoir at a time k
and Wresx[k] is the matrix with the states of the neurons from
179
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

the reservoir at the same time k. The result will be assigned to
x[k + 1], i.e., the state of the neuron RC in an instant forward
will be the result of calculating the activation function of the
neuron from the sum of the two parcels described above. In this
work, the activation function used was the hyperbolic tangent
according to 2.
f(neti) = eneti − e−neti
eneti + e−neti
(2)
Once the period of warm up is over, the training of the RC
can be initialized. The ﬁrst step should be to load the training
set and perform the update of the states of the reservoir, noting
that the matrices Win and Wres should not be changed. They
are randomly generated during construction of the RC, as
described in the previous section, and should not be adjusted.
Still during training, the weights matrix that connects the
neurons of the input layer to the output (Winout) and the one
that connects the reservoir to the output must be calculated
by the pseudo-inverse of Moore-Penrose. As they are non-
square matrices and their determinants can approach zero, it
is necessary to calculate the pseudo-inverse.
At the end of each training cycle, a cross validation cycle
should be initiated. This process should be repeated until the
stopping criteria is reached and the training set is ﬁnalized.
During the process of cross-validation, the matrices Winout
and Wout should remain being readjusted.
When the process of training is ﬁnished, the testing process
begins. The set of tests is presented to the RC and at this
time, all the weights matrices, Win, Wres, Winout and Wout,
should remain unchanged, as the matrix Mest. At this point,
the classiﬁcation error is calculated. These values will be used
in the future to make the necessary comparisons.
The behaviour of the RC can be best viewed through the
algorithm described in Figure 2.
III.
METHODOLOGY
A. Database
The database used in the development of this work was
the same used by G`omez et al. in his publication. It has
values of 120 proteins found by analysis of blood samples
from different patients. The ultimate goal of the database is to
classify whether a patient can be diagnosed or not with AD or
MCI [6].
In his work, G`omez et al. [6] subdivided the database in 2
sets. The ﬁrst set contained the results of blood samples of 83
patients. Of these 83 patients, 68 were allocated to the training
process of the chosen classiﬁer. The data for the remaining 15
patients were used in the process of cross-validation of the
classiﬁer, i.e., a process that determines the optimal point to
stop its training [8].
The second set, used in the testing process of the classiﬁer,
has two options. It could be used to diagnosis AD and in this
case, this set will contain the samples related to the 92 patients
that could be diagnosed with AD. The second option is use
this set to perform diagnosis of MCI. In this other case, the
Figure 2: Reservoir Computing pseudocode
test set will contain blood samples related to 47 patients with
a possible diagnosis of MCI.
Aiming a comparison with the signatures previously de-
ﬁned by G`omez et al. [6], two new signatures of 10 proteins
were proposed. One of them used to perform the diagnosis of
Alzheimer’s Disease and another for MCI.
The Random Forest algorithm was executed 30 times and
in each of the simulations, a signature of 10 proteins was
deﬁned. To choose the best signature among 30 proposals, a
new classiﬁer was used to determine which one got a better
classiﬁcation rate.
Thus, the Support Vector Machine (SVM) was chosen to
perform 30 executions with each signature. Thus, an average
of the classiﬁcation rates was calculated, besides the analysis
of the standard deviations. The signature that obtained the best
average classiﬁcation rate was chosen to be used later by the
RC and the MLP.
It is important to mention that G`omez deﬁned the same
signature for both cases, that is, the signature composed by 10
proteins is used for the AD and MCI testing sets.
Table I shows the signatures of proteins that are contained
in G`omez et al. work and which are used in this study.
In this work, 4 databases were prepared in order to re-
produce the experiments described by G`omez et al., using the
MLP and the RC. They were:
•
1 database for testing the signature of 10 proteins
deﬁned by G`omez et al. with the DA set of tests, called
180
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

TABLE I: Representation of the proteins contained in each
one of the signatures used.
Abbreviation
Signature
Proteins
S1
10
proteins
sig-
nature deﬁned by
G`omez et al.
CCL7/MCP-3,
CCL15/MIP-1d,
EGF, G-CSF, IL-1a, IL-3, IL-6,
IL-11, PDGF-BB, TNF-a [6]
S2
10 proteins signa-
ture deﬁned by the
Random Forest for
AD test set
IL-1a,
TNF-a,
G-CSF
,PDGF-
BB, IGFBP-6, M-CSF, EGF, IL-3,
GDNF, Eotaxin-3
S3
10 proteins signa-
ture deﬁned by the
Random Forest for
MCI test set
IL-1a, PDGF-BB, EGF, TNF-a,
RANTES, FAS, GCSF, MIP-1d,
FGF-6, IL-11
now by Database 1;
•
1 database for testing the signature of 10 proteins
deﬁned by G`omez et al. with the MCI set of tests,
called now by Database 2;
•
1 database for testing the signature of 10 proteins
deﬁned by Random Forest Algorithm with the DA set
of tests, called now by Database 3;
•
1 database for testing the signature of 10 proteins
deﬁned by Random Forest Algorithm with the MCI
set of tests, called now by Database 4;
All databases described above maintained the organization
used by G`omez et al. regarding the division of values for the
training, cross validation and testing set.
1) Pre-processing of data: To properly execute the training
of the neural network it is necessary that your data is nor-
malized, i.e., the input values of the neural network must be
contained in the same numerical range. This is important since
very different values can inﬂuence the training and generate a
loss in the generalization ability of the neural network [8].
One of the most commonly used normalization techniques
in literature is the linear transformation and it was the one
chosen for this work. Equation (3) is the formula used to
normalize the values of the database.
y = ((b − a) × (
x − xmin
xmax − xmin
)) + a
(3)
In (3), a and b represent the maximum and minimum values
that the data should take. In this work, it was used the value
of -0.85 for a and 0.85 for b, as the activation function chosen
for this neural network is the Hyperbolic Tangent. Therefore,
the values contained in the database must be between -1 and
1.
B. Simulations
As described above, in order to compare the results ob-
tained with RC, it was used a neural network MLP. Table II
shows which parameters were chosen to perform the simu-
lations with the RC and MLP. They were obtained through
empirical testing and the settings that showed the lowest mean
squared errors in the cross-validation procces were chosen.
After deﬁning the settings of the RC and the MLP, 30
simulations were performed with each of the databases in
TABLE II: Representation of the parameters used for the
simulations with the RC and MLP
Parameters
RC value
MLP value
RC connectivity
20%
Not applicable
Number of neurons in
the input layer
10
10
Number of neurons in
the RC
4
Not applicable.
Number of neurons in
the hidden layer
Not applicable
20
Number of neurons in
the output layer
2
2
Number of warm up
cycles
100
Not applicable.
Activation function of
neurons in the reservoir
or hidden layer
Hyperbolic Tangent
Hyperbolic Tangent
Activation function of
neurons in the output
layer
Linear
Linear
Learning rate
Not applicable.
0.7
Momentum
Not applicable.
0.4
each of the chosen neural network topologies in this work.
This number is considered ideal to perform more meaningful
statistical comparisons [18].
C. Statistical Analysis
When all the simulations were completed, it was necessary
to perform a sequence of statistical tests in order to scientiﬁ-
cally validate the results. For this, it was used the R mathemat-
ical software, since it contains all the implementations of the
tests used. This software uses as default a level of signiﬁcance
(α) previously deﬁned with the value of 0.05.
Before using a parametric test on a data set is necessary to
check whether the samples are normally distributed and if they
have statistically equal variances. If these two assumptions are
validated, one can apply a parametric test, otherwise it must
be used a non-parametric test.
Thus, it was applied the Shapiro-Wilk test to verify whether
or not the samples were normally distributed and the F-test to
verify whether or not the samples were drawn from the same
population, i.e., if their variances were statistically equal.
As none of the four datasets met these two premises at the
same time, it was not possible to perform the Student’s T-test.
Thus, it was chosen the Wilcoxon Rank-Sum Test, since it is
a non-parametric test, i.e., makes no assumptions about the
probability distribution of the samples.
IV.
RESULTS
After all simulations were performed with the databases, it
was calculated the arithmetic mean for each set of simulations
and Table III displays those values found.
When applied the Wilcoxon Rank-Sum Test for each of
the four cases, the results found were that the MLP has a
statistically better performance than the RC, except for the case
2. Thus, with the 10 proteins signature deﬁned by G`omez et
al. and MCI test set, the test indicated there is not statistical
differences between the results obtained with both techniques.
In order to verify the performance of the new proposed
signatures, simulations with RC and MLP topologies were
181
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

TABLE III: Representation of the average accuracy rates
after the 30 experiments
Database
Average accuracy rate
with RC / Standard De-
viation
Average accuracy rate
with MLP / Standard
Deviation
Database 1
86.62% / 0.026
93.44% / 0.017
Database 2
69.29% / 0.024
68.15% / 0.018
Database 3
90.57% / 0.022
94.31% / 0.008
Database 4
76.59% / 0.047
78.86% / 0.031
TABLE IV: Comparison of the results with the new protein
signature proposal obtained with RC, MLP and the ones
available in literature.
Protein
Signature
RC
-
Maxi-
mum value
MLP - Maxi-
mum value
Results
found
by
G`omez
et
al.
New
10-
protein
signature
for AD
96.73%
95.65%
93%
New
10-
protein
signature
for MCI
89.36%
82.97%
66%
performed for both the diagnosis of AD and MCI. The results
were compared with those found by the same neural networks
when the signatures used were the ones deﬁned by G`omez et
al.
In all cases, the classiﬁcation rate showed improvement
when the new signatures were used for both architectures. Af-
ter the Wilcoxon Rank-Sum test, this statement was conﬁrmed
statistically. The maximum and average values are also bigger
than those described by G`omez et al.
Table IV summarizes the maximum values found in the
simulations of the RC and MLP. Those results were found
using the new signature proposoal with 10 proteins. The
Table IV also display the results obtained in the work of
G`omez et al. using ther own signature [6].
From Table IV, it can be concluded that the RC obtained
results consistent with those described by G`omez et al. and
succeeded in reaching a maximum value greater than the
average found in the literature.
V.
CONCLUSION AND FUTURE WORK
Nowadays, Alzheimer’s disease is one of the most common
diseases in the elderly population. More recently, the number
of patients has grown signiﬁcantly since the life expectancy in
most developed countries has increased.
AD is a degenerative disease, i.e., brain cells will deterio-
rate and there is no way to reverse the disease. However, the
earlier the drugs are administered, the better the quality of life
of the patient since the medication will slow the progression
of symptoms.
Thus, this study aimed to verify the performance of a
new connectionist neural network approach called Reservoir
Computing to early classify if a patient can be diagnosed with
AD or not. Moreover, another goal was to make a comparison
of the performance of the RC with the MLP neural network,
and also with the results available in the literature.
From the statistical tests and simulations, it can be con-
cluded that the MLP presented a superior performance in most
cases, although the RC have obtained maximum values higher
than the MLP and available in the literature. This can be
explained by the fact that the RC is more suitable for use
in dynamic systems as it has a good storage capacity.
It is also possible to conclude that the 2 new signatures
proposed achieved better results when compared to those
showed by G`omez et al. Furthermore, they also had better
perfomance when compared to the results obtained from the
same neural network topologies when the signatures used were
the ones proposed by G`omez et al.
Unlike the RC, the MLP has a better ability to approximate
non-linear functions and does not contain the property to store
the previous state of its neurons, i.e., does not have recurrence.
As future work, it is intended to conduct a comparative
study between the RC non-linear approach capability and stor-
age capacity of the network, in order to assess the appropriate
parameters to obtain better results.
It will be also carried out a thorough study on parametriza-
tion of the RC, such as the deﬁnition of the spectral radius size,
how many neurons should be placed in reservoir, the degree
of connectivity between these neurons. Furthermore, in order
to address dynamic problems, recurrence will be implemented
between the neurons of the output layer with the reservoir.
Finally, it is intended to invest in more variable selection
techniques in order to further optimize the results and to reduce
the number of proteins in the signatures used to perform early
diagnosis of Alzheimer and MCI.
REFERENCES
[1]
H. Portal. Portal of the brazilian health [retrieved March, 2014]
[Online]. Available: http://portal.saude.gov.br/saude/ (2012)
[2]
R. Green, Diagnosis and Treatment of Alzheimer’s Disease and Other
Dementias.
Editora de Publicac¸˜oes Cient´ıﬁcas Ltda., 2001.
[3]
M. Paulo, Dementia of Alzheimer type: diagnostic, treatment and social
aspects.
Editora de Publicac¸˜oes Cient´ıﬁcas Ltda., 1997.
[4]
E. Giusti and V. Surdo, Alzheimer’s care and family counseling:
psychological needs and treatment of dementia.
Gryphus, 2010.
[5]
H. Charles, Y. Takeda-Uchimura, B. Adam, S. Ray and B. Markus.
“Classiﬁcation and prediction of clinical Alzheimer’s diagnosis based
on plasma signaling proteins” Nat Med, vol. v13, 2007, pp. 1359 -
1362.
[6]
M. G´omez and P. Moscato, “Identiﬁcation of a 5-protein biomarker
molecular signature for predicting alzheimer’s disease,” PLos One,
vol. v3, 2008, p. 12p.
[7]
S. David and R. Peter, WEKA Experimenter Tutorial for Version 3-5-8,
2008.
[8]
M. Valenc¸a, Fundamentals of Neural Networks: Examples in Java,
2nd ed.
Livro R´apido, 2009.
[9]
StatSoft. Random forests. https://www.statsoft.com/Textbook/Random-
Forest. [retrieved: May, 2014]
[10]
M. Valenc¸a, Applying Neural Networks: A Complete Guide, 1st ed.
Livro R´apido, 2005.
[11]
W. Maass, Motivation, theory, and applications of liquid state machines.
Imperial College Press, 2011.
[12]
H. Jaeger, “The echo state approach to analysing and trainning recurrent
neural networks,” German National Resource Center for Information
Technology, Tech. Rep., 2010.
[13]
M. Massar and S. Massar, “Mean-ﬁeld theory of echo state networks,”
PHYSICAL REVIEW E, vol. 87, 2013.
182
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

[14]
M. Lukoˇseviˇcius, A practical guide to applying echo state networks.
Springer Berlin Heidelberg, 2012, pp. 659-686.
[15]
D. Verstraeten, “Reservoir computing : computation with dynamical
systems,” Ph.D. dissertation, Ghent University. Faculty of Engineering,
Ghent, Belgium, 2009.
[16]
A. Ferreira, Ara´ujo, “A method for design and training reservoir
computing applied to prediction of time series,” Ph.D. dissertation,
Universidade de Federal de Pernambuco, 2001.
[17]
M. Kulkarni and C. Teuscher, “Memristor-based reservoir comput-
ing,” in Proceedings of the IEEE/ACM International Symposium on
Nanoscale Architectures (NANOARCH’12), Amsterdam, 2012, pp.
226-232.
[18]
N. Juristo and A. Moreno, M., Basics of Software Engineering Exper-
imentation.
Kluwer Academic Publishers, 2001.
183
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

