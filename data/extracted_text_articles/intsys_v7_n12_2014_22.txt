267
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
MobileSage – A Prototype Based Case Study for
Delivering Context-Aware, Accessible, and
Personalized On-Demand Help Content
Till Halbach & Trenton Schulz
Norwegian Computing Center
Oslo, Norway
Email: {till.halbach,trenton.schulz}@nr.no
Abstract—We present the system design decisions for the Mo-
bileSage prototypes, a service for the on-demand delivery of
multimodal and accessible help content to anyone in general
and seniors in particular. Findings from user-centered research
formed the system requirements, as well as design considerations
and decisions. The design of the system also includes availability,
relevance, accessibility, conciseness, and comprehensiveness of
multimodal content. The prototypes have been evaluated in
multiple user trials with good results, showing the participants’
high appreciation of such a service and a moderate to high degree
of satisfaction with the prototypes.
Keywords–Mobile; smartphone; application; assistance; guid-
ance; help on demand; personalization; adaptive; accessible; us-
able; multimodal; context; location aware; content management,
Ambient Assisted Living, AAL JP.
I.
INTRODUCTION
Previous work [1] has documented that the ever increasing
number of machines and devices surrounding us in our every-
day lives poses a challenge to many, and elderly persons in
particular. Many senior citizens view solutions based on Infor-
mation and Communication Technology (ICT), such as ticket
machines and web services, with anxiety. These solutions add
to an experienced rise of complexity in their life and, instead of
being task enablers, hinder their ability to accomplish the task.
At the same time, modern elderly – here deﬁned as people aged
65 and older – live longer, are healthier, more active, mobile,
independent, and more demanding customers than ever [2].
Estimates mention approximately 87 million elderly in Europe
[3]. They are increasingly looking for useful, user-friendly, and
personalized ICT services that add value to their active and
mobile life, that help them solve everyday tasks instead of
complicating them, and they also desire services that can help
them stay active despite various impairments.
MobileSage provides a timely approach and solution to
these problems. Its main idea is to provide assistance to
virtually anybody, but particularly elderly, in solving everyday
tasks. Someone with interest in assisting an individual can reg-
ister instructional help content, potentially split up into several
steps, in multiple languages and multiple modalities, such as
images, text, video, audio, and accompanied by geo-locational
data. The content can then be accessed upon demand; for
instance, upon scanning a QR code, scanning an NFC tag,
through plain text search, and through location search.
This work is based on a previous conference article [1].
The article has been extended with related research and the
description and results from two more user evaluations. Its
contributions include:
•
an overview of related solutions and research projects,
•
the discussion of technical considerations and deci-
sions regarding system architecture, functionality, and
design,
•
the results from a three user evaluations, and
•
a method for efﬁcient user involvement throughout IT
projects.
The article is organized as follows: First, we give an
overview of MobileSage and related research, before present-
ing the system architecture and all main components. Next,
we lay out the requirements for these components and their
consequences for system design and content production. Then,
we present and discuss the three user evaluations in Norway
and their results. Finally, we present conclusions from the
project.
II.
MOBILESAGE OVERVIEW
MobileSage stands for Situated Adaptive Guidance for the
Mobile Elderly. The name refers to the project and its main
deliverable, a mobile app. The consortium was a mix of
software companies, research institutions, industry partners,
and end-user organizations from Norway, Romania, and Spain.
The project lasted from July 2010 through April 2014 and
was funded by the Ambient Assisted Living Joint Programme
(AAL JP).
This program had been created to fund ICT-based inno-
vation projects targeting elderly individuals [4]. The main
goal of AAL is to improve “the quality of life, autonomy,
participation in social life, skills, and employability of older
people”, while service delivery enhancement and care costs
reduction are secondary targets. Solutions in form of products,
services, and systems should aim at a market introduction
within the next 2-3 years after the project end. The third AAL
JP Call was issued in April 2010 with the title “ICT-based
Solutions for Advancement of Older Persons’ Independence
and Participation in the ’Self-Serve Society”’ [5].

268
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The Call also speciﬁes the target groups that the projects
should be tailored for. The primary end-user group, consisting
of elderly individuals with or without impairments (motor,
perception, cognition), might have little or no familiarity with
technology. Ideally, these individuals have the explicit wish to
remain active members in the digital society.
Then, there are family members and care persons, both of
whom stand close to the primary end-users, and which add up
to the secondary user group. As amateurs, they may have an
interest in producing or ﬁnding help content relevant for the
primary users.
The group of tertiary end-users denotes NGOs teaching
digital literacy to the elderly, public actors like city authorities,
and private actors such as transport companies and machine
vendors. As with the secondary user group, tertiary users may
want to produce, modify, or make help content available to the
primary users.
III.
RELATED RESEARCH
As part of the preparation of the project, an effort mapping
updated information about state of the art in the ﬁeld was
carried out1. The study revealed that there are few, if any,
existing solutions as described in the MobileSage project. Es-
pecially rare are related projects and solutions of this particular
kind directed towards elderly and impaired users. However, the
study showed that there is a number of recent and ongoing
international projects related in various ways to the topics
addressed by MobileSage; they are discussed subsequently.
A number of international projects fall within the same
scope.
The (ongoing) APSIS4ALL project – Accessible Person-
alised Services In Public Digital Terminals for all – deals
with personalizing public digital terminals such as ATMs and
ticket machines [7]. An adaptive interface and personalized
interaction is achieved by the human communicating with the
machine through a smartphone.
The ASK-IT project – Ambient Intelligence System of
Agents for Knowledge-based and Integrated Services for Mo-
bility Impaired users – developed a framework that provides
intelligent agents for service provision and search for suitable
semantics [8]. It also allows to personalize service and content,
and personalizes user interfaces. The project focused on daily
life and travel scenarios.
The ongoing MyUI project – Mainstreaming Accessibility
through Synergistic User Modeling and Adaptability – ad-
dresses speciﬁc user needs towards ICT products in general
through adaptive personalized interfaces [9]. Its ontology-
based framework collects user and context information in real-
time during use in order to establish an evolving user model
to which user interfaces of various personal applications can
adapt, by means of empirically based design patterns, as such
data is shared among services.
GUIDE – Gentle User Interfaces for Elderly People – is
an ongoing project to design tools and aids for developers to
efﬁciently integrate personalization, user-friendly interaction,
1This section was ﬁrst presented in a conference [6].
and accessibility features into applications [10]. Here, the focus
is on Web, TV, and middleware like set-top boxes.
The goal of the DIADEM project – Delivering Inclusive
Access for Disabled or Elderly Members of the Community
– was to make electronic and online forms adaptable to the
cognitive skills of the user [11]. It employed an expert system
that monitored the user actions and behavior; it personalized
and tailored the user interface based on this observation.
The ongoing GPII Project – Global Public Inclusive In-
frastructure – is building a framework that stores universal
user proﬁles in the cloud [12]. The proﬁle can be accessed
to adapt the user interface of any device to a user’s needs
and preferences. Also, a marketplace will be established for
developers to share assistive-technology tools for accessible
services and content.
The following research projects are related to user interface
aspects of MobileSage.
The aim of SNAPI was to develop a data format for the
storage of user proﬁles, with a focus on smartcards [13].
Personal preferences and other settings could be stored in the
user proﬁle to personalize the human computer interface of
public digital terminals and adapt it to the user’s needs. The
format has recently become a CEN European standard [14].
The objective of the ongoing GoldUI project – Adaptive
embedded human interfaces designed for older people – is
to offer the elderly a number of cloud services that are
deemed useful in the everyday life [15]. These services can be
accessed through a variety of platforms, including telephone,
smartphone, tablet PC, TV, and radio. The services include
traditional broadcast services like news syndication, music
playback, and weather forecast, combined with services like
calendar, task lists, online shopping, and social media.
The following research projects address transportation.
The ongoing WayFiS project – Way Finding for Seniors –
addresses the topic of travel challenges [16]. The project plans
include both a web based pre-planning service and a mobile
application. Route calculations take account an individual’s
desired physical activity, nutrition needs, necessary facilities
along the route, and disease restrictions, while trying to avoid
inaccessible places.
Mediate – Methodology for Describing the Accessibility of
Transport in Europe – is a completed project that has developed
criteria and tools to measure accessibility in public transport,
including accessible ticketing and information systems [17].
Also, a database has been erected with accessibility informa-
tion of public transport system in Europe.
In the Access2all project – Mobility Schemes Ensuring Ac-
cessibility of Public Transport for All Users – the accessibility
of public transport was considered [18]. Concrete outcomes
of the project were a number of guidelines, recommendations,
roadmaps, and new research initiatives.
The AmbienNet – Ambient Intelligence Supporting Navi-
gation for People with Disabilities – created an indoor location
system based on intelligent infrastructure and a sensor network
has been developed [19]. The resulting navigation system could
assist users with and without disabilities.
The following projects address multimodality.

269
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The ongoing HAPTIMAP project – Haptic, Audio, and
Visual Interfaces for Maps and Location Based Services
– develop a cross-platform toolkit for the design of user
interfaces incorporating haptic, audio, and video input and
output that goes beyond guidelines and checklists [20]. The
project focuses on the retrieval, storing, and manipulation of
geographic data.
The MAPPED project – Mobilisation and Accessibility
Planning for People with Disabilities – developed a mobile
application that provides accessibility information on buildings
and traveling on buses or trains [21]. The service employed
localization techniques to increase the relevance of the infor-
mation.
The HearMeFeelMe project – Compensating for Eyesight
with Mobile Technology – aimed at replacing visual and
textual information with audio, combined with touch-based
interfaces for information access [22]. The project included
a mobile application and a system for object mapping and
tracking in indoor environments. The application employed
near-ﬁeld technology to gather information about items to buy,
such as food and medication [23].
IV.
MOBILESAGE COMPONENTS
The MobileSage prototype consists of two components: the
Help-on-Demand (HoD) mobile application and the Content
Management Service (CMS). Figure 1 shows the overall ar-
chitecture.
A. Help-on-Demand Service
The HoD application is a personal agent, i.e., a thick-client
application running on a smartphone. It is built up in a service-
oriented manner, as shown in Figure 1. The user interacts with
the Dialog Manager through the User Interface. The Dialog
Manager uses information from the Proﬁle Service, which
takes care of the user proﬁle. The user proﬁle stores personal
preferences and usage patterns. User behavior and User In-
terface events are logged and analyzed by the Personalization
Service, upon which the user proﬁle is re-adjusted [24–28].
The Dialog Manager is in contact with the Reasoning Ser-
vice to help determine the user’s context. Reasoning makes use
of network services such as Media Service, Search Service, and
the Content Service. The Reasoning Service gets help from the
Localization Service, which can determine the user’s location
based on technologies like A-GPS, WLAN, GSM/GPRS, NFC,
and triangulation methods.
The HoD Service requests any content from the CMS upon
initiation of the user.
B. Content Management Service
The CMS is a cloud service running on a web server.
Content producers interact with the service’s Dialog Manager,
which in turn controls the User Interface on a User Agent
like a web browser. The logic for handling the multimodal
content lies in the Content Manager, which has a modular
design to be able to add additional modalities in a simple way.
The prototype supports the modules Video (with or without
captions), Animation, Image, Audio, Text, and Formatted Text
(basically simpliﬁed HTML). The content is stored by the
Content Service. It is also possible to refer to content located
elsewhere (e.g., from other video services) through proper
hyperlinking and HTML redirects.
There is no limitation to the kind of content that can be
served. This includes manuals, usage instructions, descrip-
tions of travel routes, and geographical points of interest.
We anticipate that machine makers and service providers
will generate most of the content. For instance, a particular
vendor might provide manuals for their ticket machines, or
the railway operator that runs these machines might do so.
Even a municipality might be interested in producing such
help content as a special service for their citizens and visitors.
Other interested parties are expected to add content to the CMS
to ﬁll in the gaps left behind by product makers and service
providers, like caregivers, relatives, and friends, as they are
likely to have a direct interest in helping particular individuals.
Finally, there is nothing that prevents users of the HoD from
producing and making help content available themselves.
V.
USER AND SYSTEM REQUIREMENTS
The following sections address the formulation of the
requirements and constraints for the system design.
A. Requirements for Primary Users
The derivation of the requirements of primary users is split
into the gathering of the users’ expectations towards the system
(user needs analysis), and the collection of user requirements.
The system requirements were derived from the latter.
1)
User Needs Analysis: Focus group work was con-
ducted in the three countries Norway, Romania, and Spain to
ﬁnd the needs of primary users [29]. The focus groups had
39 participants and represented a broad range of parameters,
including age (48 to 96), gender (24 female vs. 15 male),
disabilities (sensory and cognitive impairments), nationality
(four foreigners), and ICT experience and usage. Two scenarios
were presented to the participants: a traveller with reduced
vision in a foreign country who was not proﬁcient in the
language, and an elderly lady at home trying to understand
how to use an electric household appliance.
The focus groups’ results show that “modern elderly per-
sons” are a heterogeneous group with a wide range of – some-
times contradictory – needs and wishes. This applies also to the
users’ familiarity with ICT in general and mobile technology,
which ranges from none to advanced users. However, it was
possible to identify themes of functionality the solution should
have [29]. More speciﬁcally, the solution should
•
lead to higher independence of elderly people accord-
ing to the help-for-self-help principle,
•
increase a person’s mobility and be usable for trans-
portation and travel, including holidays and visits,
•
be applicable in the home environment and throughout
daily living,
•
provide
relevant,
useful,
context-
and
location-
sensitive and multimodal (and hence accessible) as-
sistance in an on-demand manner,

270
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Figure 1.
System architecture and major building blocks for HoD (left) and CMS (right)
•
be accessible, user-friendly, designed for all, possible
to personalize or customize, adaptive, social, and
•
honor privacy, security, and trust matters.
2)
User Requirements:
The results from the user
needs analysis were collected and formulated as user require-
ments [30]. The roughly 50 requirements mirror the expecta-
tions of primary users regarding HoD, but were extended to
be valid for the CMS as well. The user requirements served as
input to the process of formulating the ﬁrst draft of the system
requirements for the service’s two components.
3)
System Requirements: The technical requirements
for the Help on Demand and Content Management services
were derived from the user requirements.
The requirements speciﬁcation for HoD has over 60 re-
quirements [31], while the CMS speciﬁcation contains only
40 [32]. Both address topics such as system functionality,
user interface, and input and output matters. Also included
are sections on the technology choice and mockup examples
regarding the services’ user interfaces.
B. Requirements For Secondary and Tertiary Users
MobileSage’s focus is on primary users. Secondary and
tertiary users have been accounted for by formulating a set of
requirements representing the needs of the transport company
participating in the project. These are as follows:
•
It should be possible to identify one or several points
of interests with a unique ID.
•
There could be multiple help topics per ID.
•
One topic could be presented in multiple languages.
•
The service should support content hosted elsewhere
(“upload once, available everywhere”).
•
It should be possible to edit help content in order to
add locations, languages, and modalities.
VI.
SYSTEM DESIGN
For the HoD service, a user proﬁle lays the ground for
personalization and adaption of the service. It contains the
user’s settings and preferences, such as font size, emergency
number, accepted media types, and additional languages. Also
other parameters are stored there, including usage log. This
log is the basis for system adaptation. Screenshots of the HoD
are shown in Figure 3.
Both primary and tertiary users have requested that it
should be possible to associate content with speciﬁc locations
or points of interest. However, it should also be possible to
link certain content to several locations (e.g., “how to buy a
ticket” could be valid for any ticket machine in a municipal
area). Moreover, there are situations where several pieces of
content are relevant at a single location (e.g., how to validate
a ticket, arrival time of the next bus, or choosing the correct
platform for departure).
These issues have been solved by the Content Item, see
Figure 2. This uniquely identiﬁable item is a logical unit to
gather content that is related to each other. Multiple locations
in terms of latitude, longitude, and altitude can be linked to a

271
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Figure 3.
Screenshots of the Help-on-Demand application (V1.0): set up (left), home screen (middle), and search (right)
ID
Title
Language
Locations
Media type
Summary
URI
Step
Record
Content
item
Steps
Records
Figure 2.
Data model of the content
single Content Item, and so can Records, each representing a
particular topic. The topic itself is described by a Record’s title
together with a language identiﬁer. Language translations of a
topic become a new Record. To avoid topics being mixed in
the result listing, the results are ordered according to language
ﬁrst, and alphabetically by topic. The user needs analysis
recommended further to split content into several steps or
segments, and to promote segmented content, something the
presented data model is capable of by combining multiple
Steps into a Record. A Step has the same language as the
Record it belongs to and has one of the Media Types: text,
formatted text (HTML), audio, an image or animation, video,
or a video with captions. Further elements are a brief Summary
and an URI/URL pointing to the media itself. The URI can
point to a server that is part of the CMS, but it may also
point to external resources (e.g., a video on YouTube). For
such external resources, the CMS effectively functions as a
service holding metadata on indexed resources. This model
supports multiple media types not only for the same Step
but also mixing of media types per Record (i.e., several
Steps) depending on what type suits a particular step best. For
instance, video might be best suited to illustrate a movement,
while often a still image is beneﬁcial for highlighting a speciﬁc
region of a visual.
MobileSage is about just-in-time guidance and on-demand
assistance. Based on suggestions from the primary-user stud-
ies, it was deemed too intrusive to let the mobile application
initiate requests for help based on the location of the phone
at points of interest, nearby radio ﬁelds, etc. Thus, the user
indicates a wish for assistance either by scanning a QR code or
NFC tag, or by sending a text phrase to the CMS. In the former
case, the code or tag carries the ID of a particular Content Item
that is read by the mobile app and sent to the CMS, resulting
in a list of all topics associated with that ID. Regarding the
search phrase, topics are viewed as relevant regardless of the
ID, accounting for both Record titles and Step summaries.
One of the challenges of MobileSage is to ﬁnd relevant
content and not to confuse the user with extraneous informa-
tion [32], which helps individuals with orientation and problem
solving challenges. The key to this problem is determining the
user’s context, in terms of location, time and date, user habits,
and other aspects. Nearby objects are considered relevant in
the CMS by calculating a proximity radius around the user’s
current position; only Content Items with a location within this
circle are returned as results to the phone. The exact radius of
the circle was based on heuristics and set to roughly 40 m.

272
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Records are sent in “pages” to the phone, meaning that
HoD tells the server how many results per request to return.
This is done ﬁrst of all for practical reasons, i.e., bandwidth
limitation, and second because the user is likely to be interested
only in the most relevant results, which are presented ﬁrst. The
client on the phone keeps track of the number of transmitted
records and is hence able to request a particular page with
results, say, page 3 with the records 21 through 30 in case of
10 allowed records per page. If the user scrolls down while
being at the bottom of the results list, the client fetches more
results if available.
For simplicity, any media content is offered to the HoD
as a ﬁle for download through HTTP. While this works great
with text-based content, the performance in terms of respon-
siveness of the playback on the media player is suboptimal
when connected over a channel with very limited capacity,
as discussed in Section VIII-B because media downloads in
most clients have to ﬁnish before the media is rendered on
an output device. Clients that support (true) media streaming
and pseudo streaming methods like HTTP Live Streaming will
start rendering the output as soon as sufﬁcient data become
available. These methods would require the proper setup of a
streaming media server.
VII.
CONTENT PRODUCTION
This section focuses on the production of content for Mo-
bileSage in particular, and educational and instructive content
in general.
The content found should be relevant, concise, and compre-
hensive. However, as recent research surveys show [33–36], it
is extremely difﬁcult to develop methods that can check exactly
these properties in a satisfactory manner. MobileSage offers a
manual approach in its CMS [32]. As mentioned before, the
splitting of longer content into shorter steps is encouraged. The
content producer now provides the content abstraction on two
levels: A summary of the step itself, and a title wrapping-up
of the entire record (see Figure 4). The content producer must
tag the content with the proper descriptors for language and
its location, if applicable.
Currently, the content must be uploaded in a format ac-
cepted by Android OS. This applies to both the format of the
content tracks, be it video, audio, or captions, and the format
of the embedding media container. In the future, the CMS
could be extended to accept any format with transcoding into
a proper format supported by the OS.
While the video material could be presented at any resolu-
tion, we chose to encode video with a resolution of 480 × 360
pixels and a bitrate of roughly 200 Kbps @12 fps in H.264
Baseline Proﬁle Level 2.2 format, and embedded in an MP4
transport container. The audio tracks (both stand-alone and
as part of a video) had a rate of roughly 48 Kbps @22 KHz
mono and were encoded in AAC format. A video containing
one visual and one audio track thus had a bitrate of roughly
260 Kbps, which includes overhead data used for track muxing
and the container format. The length of the content varied
from approximately 10 s to 4 min, but most of the content was
between 30 s and 45 s.
We used open-captioning, where the titles (captions) of the
voices’ transcript are always visible on the screen, instead of
Figure 4.
Screenshot from the uploading of new content to the CMS (V1.0)
composing a separate captions track. This avoided the extra
work of producing a captions ﬁle and ensured that the video
player always worked properly, without requiring the user to
turn it on. We chose a “slab serif” font that was originally
designed for fax machines, with a size of at least 36 points.
One disadvantage of this approach is that more space is taken
up on the content server to store each captioned video, but as
the videos were short and at a low resolution, we believe this
is a minor issue.
The content is currently provided in a single quality
in terms of resolution, sampling frequency and bitrate as
mentioned above. Both have implications for the bandwidth
necessary to transmit a given content ﬁle to the client’s media
player: the larger a picture (in pixels), and the higher the
audio sampling frequency (in Hz), the more bandwidth will be
necessary. Likewise, the higher the encoder bitrate (in bps), the
more bandwidth is required. Channel capacity of the cellular
link, however, is a limited resource for physical reasons. It
takes time to transmit a particular amount of data over a
channel, which also has an impact on the user experience. The
service is thus required to respond to user interaction within a
reasonably short time span [30].
This requirement is honored by measuring the duration
of packet downloads at the client side (which may vary
over time according to the signal strength and coverage), and
including this information in the server requests, together with
information about the phone’s screen size. Content can now be
provided in several resolutions or sampling frequencies, and
several bitrates. Media searches at the server side can then use
this information about the channel conditions and limit the

273
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
results to media qualities that meet the bandwidth constraints.
For example, a phone with a 480 × 800-pixel screen is con-
nected to the network over a GSM (2G), and the bandwidth
averaged over 20 s is measured to be 100 Kbps. Based on
the different resolutions and bandwidth, the server decides
that a 480 × 360-pixel video will still render acceptable to
good quality. Yet, the 480 × 360-pixel video comes in two
different bitrates; one encoded at a rate of 260 Kbps, and one
encoded with 130 Kbps (assuming a constant encoding bitrate).
The latter is closest to (but still above) the estimated channel
capacity and will be sent to the phone to minimize the service’s
responsiveness, together with a notiﬁcation about poor channel
conditions.
VIII.
USER EVALUATIONS
The MobileSage prototype was developed in three major
iterations where the release of a software deliverable – dubbed
Beta, V1.0, and V2.0 – marked the end of an iteration. Each
release was evaluated involving end-users. The ﬁrst and the
second evaluations were carried out in Norway, Romania, and
Spain; the last evaluation was conducted in Norway only. In
total, around 70 informants were part of the evaluations in the
three countries.
The subsequent sections summarize the ﬁndings from all
iterations, with a focus on the set up in Norway.
A. Beta setup
The Beta evaluation in Norway consisted of a travel situ-
ation at a subway station in Oslo where participants used the
Beta prototype to ﬁnd help with getting to a subway station,
ﬁnding a ticket machine, buying and validating a ticket, and
choosing the correct platform. We created content for all of
these scenarios, with a minimum of audio and video for each.
All but one of the scenarios had captioned video, and some had
a textual modality in addition. Each of audio, text, and video
was done both in Norwegian and in English to allow users to
choose an additional content language. We then created several
NFC tags for each of the scenarios and used it as a way of
getting the information. Testing of QR codes was postponed
to a later evaluation due to its unreliability in the Beta version
of the app. We tested on two smartphones with an Android
OS 4.1 and screen sizes of 480 × 800 and 720 × 1184 pixels
without any discernible difference in the results.
Eight participants were recruited for the evaluation. They
were between 65 and 76 years old, and four of them had no
experience with smartphones; however, they were somewhat
experienced with computers, and a few of them were familiar
with the area. A session consisted of a short introduction to
the MobileSage idea, followed by a brief interview concerning
their experience with mobile phones. Then, we demonstrated
the application and let the informants work on the tasks. One
evaluator took notes, while the other would guide the partic-
ipant to make sure a task wasn’t forgotten. After completing
all of them, there was a short follow-up interview about the
service and the participant’s experience about it.
B. Beta results
In the ﬁrst task, the participants had to create a proﬁle
that matched their preferences for text size, language, and
types of media they wanted to receive help in. The users
understood the concept of several content languages, and
the majority (75%) added English to their proﬁle. The user-
speciﬁc media types ranged from a single one to the entire
range as detailed in Section VI, where captioned video, i.e.,
the richest media type, was chosen most often. The majority
(90%) of test persons checked 4–5 media types including
audio, even though some participants said they would avoid
wearing earbuds or headphones. Text was never requested.
Choosing video and captioned video was inconsistent, hinting
on a potential misunderstanding of the user concerning the
meaning of “captioning”. It was recommended to improve the
description of media types or show brief examples of them.
All participants but one expressed that making the proﬁle was
sufﬁciently easy.
The second task concerned navigation, where the parti-
cipants had to get from their current location to the nearest
subway station. All were able to enter the information needed,
but the phone’s ability to ﬁnd the participants’ location was
unreliable, sometimes placing a participant a block further
south or facing the wrong direction. This issue sorted itself
out when walking to the location.
The next task dealt with getting help at the ticket machine.
Two participants were not able to ﬁnish this task due to a
technical issue that caused no results to be returned from the
CMS, which was corrected subsequently. All others succeeded
with using NFC tags or by manually searching for information
about where the ticket machine was, how to purchase a ticket,
how to validate the ticket, and which platform they had to go
to. Though only one was familiar with the technology, two had
heard about it, and the rest were unaware of what it was; all
participants really liked the technology and experienced it as
easy to use.
One problem encountered was the effect the environment
had on the signal strength in the phones. While above ground,
it was possible to get video and audio without any issues,
and the selected item would show up almost instantly. Yet,
underground in the subway station, it became very troublesome
for the phone to contact the content server. The main reason
for this is that the only connections that are currently available
in this particular station are so-called Edge (2G) connections,
which are much slower compared to a 3G connection, and
also very latent. This was no big issue when retrieving, say,
the results list. Participants had to wait a long time, though, if
they wanted to watch a video. The audio fared a little better,
but downloading would not always complete. Sometimes,
the application on the phone would simply give up and it
would be necessary to download the audio or video from the
beginning. Most participants noted that it took a while to get
the information in this case. With the continuing widespread
of 2G connections in many countries, it is recommended
to produce at least one version of low-resolution low-bitrate
content, and to use techniques that increase the responsiveness
of media players, such as media streaming, as discussed in
Section VI.
No users complained about the size, resolution, quality,
frame rate, or length of the video. Some participants noted
that the font used for the captions indeed was sufﬁciently large
and easy to read. There was only one instance where people

274
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
commented on unclear information, where a video showed an
unreadable display on a ticket machine.
All participants felt that a help-on-demand system was
something that would be useful for them. One even claimed
that she was scared of using the ticket machine and always
went to a counter instead, but now she would continue to use
the machine since she felt conﬁdent to manage buying a ticket
based on the app and the provided instructions. Concerning
potential improvements, the most popular suggestions were
a shorter response time for videos (when in the subway
station) and dynamic information, such as time schedules.
Those familiar with mobile applications suggested to include
MobileSage’s functionality in the public transport provider’s
current smartphone application.
C. V1.0 setup
In the V1.0 evaluation all of the attention was given to
the user experience when using the HoD app. The Norwegian
evaluation involved 10 informants from the local senior user
group, aged 67 to 83, from both genders, all with varying
ICT and mobile-phone experience (though none were novice
ICT users), and a few with a mother tongue different from
Norwegian. All informants received a small ﬁnancial gratituity
for the participation. Two Android phones (Galaxy Nexus and
Nexus S) were used in the tests.
The scenario’s focus was on matters not tested in the last
trials and emphasized multilingual content, the concept of
steps, and QR codes. The following tourist situation was con-
sidered: A visitor to Norway arrives at the tourist information
center in Oslo, and a poster mentioning the famous Kon-Tiki
Museum catches the visitor’s eye. The poster provides both
an NFC tag and a QR code. The visitor scans either of them
with the MobileSage app, and several pieces of information
are presented: information about the museum and how to get
there from the user’s current position, how to buy a ticket at
the nearby machine, how to ﬁnd the proper bus stop, when the
next bus is arriving, and when to get off the bus while riding
to the museum.
Most of these ﬁve steps were presented in multiple modal-
ities, such video, audio, and formatted text, others were avail-
able just in a single media type. The latter two steps – the
expected duration of the waiting time for the next bus and
the expected duration of the arrival of the bus at the proper
bus stop – showed dynamic content (real-time data) from the
servers of the municipality’s transport company Ruter. This
was achieved by HTML redirects from the content provided
by the CMS to Ruter’s server.
The informants were ﬁrst brieﬂy introduced to the Mo-
bileSage idea in general, and scanning of NFC/QR in particu-
lar. After that we went to the nearby tourist information where
we had hung up some of the poster as described above, and
simply watched as the participants went through the steps of
travelling to the museum. In case of problems we would also
assist the user with clariﬁcation and also give some technical
aid (Figure 5). Throughout a single trial, the participant moved
from the poster to the ticket machine, and then to the bus stop;
the last step (the bus ride to the museum) was simulated only
for practical reasons. After that, the user was questioned about
their user experience and had to ﬁll out a brief questionnaire
to gather their opinion.
Figure 5.
Example situation in a user trial, a participant scans a QR code
D. V1.0 results
Subsequently, the ﬁndings from the Norwegian trials are
presented as an excerpt from a larger report [37].
Overall, the English MobileSage version was acceptable for
the English-speaking testers, even though they commented on
several non-translated page elements in the dynamic webpages
from the travel company. Integration of services, including
the proper communication of the user’s language, is key here,
besides the mandatory translation of all language strings.
The participants found the prototype in general accessible,
but there were several issues related to real-life situations:
trafﬁc, crowd, and town noise was a problem when trying
to hear the sound of the videos, both indoors and outdoors.
All participants would use the relatively weak speakers in
the smartphones. As one of the participant remarked, “elderly
never use headphones, you know.” Here, video captions were
useful to the participants. Next, bright outside sunlight reduced
the screen contrast, making it difﬁcult to read what was dis-
played. Here, automatic adjustment of the display’s brightness
and contrast and improved displays would help, but this is
beyond the scope of this project. Some participants found
the text size and also the virtual-keyboard letters too small.
However, even though it had been pointed out to participants
that they could adjust the settings according to their own
preferences, none actually changed the default text size. The
size of the keyboard letters could not be changed, and this
might be the reason why the users found NFC and QR codes
so attractive when searching for information.

275
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The informants all agreed that the ability to customize and
personalize media modalities and output was valuable for them
and other elderly as well. Due to time constraints, though,
this topic was not tested systematically. The fact that no user
changed the settings shows on the other hand the necessity
for suitable default values, such as captioned videos as default
media type as it combines a visual with audio and text.
Regarding adaptivity, the trial observers noticed that the
most used functionality was automatically placed in a promi-
nent position in the user interface (on top). However, the
participants did not seem to notice. We did collect usage data
for each participant, but due to the small duration of each
trial, a sufﬁcient amount of data for each participant was never
generated. Future work should test out adaptivity in a realistic
manner.
The participants had quick access to the content and were
all satisﬁed with the response time. It surely helped that the
evaluations were held in an area with a good GSM signal,
but contributing to this was also the strategy to switch from
plain downloading in the ﬁrst trial to HTTP pseudo streaming,
which shortens the time after which the media player starts
playing drastically.
Most informants had heard about QR codes or at least said
they had noticed them, but very few knew about NFC, let
alone its logo. All participants preferred scanning over text-
based search during the trial. Here, nine out of 10 found that
NFC was easier to use than QR due to a shorter response
time. With QR, many found it cumbersome to ﬁnd the correct
distance and angle between the smartphone camera and the
QR code on the poster. In contrast to the beta trial, NFC tag
scanning went smoother, mainly because we now carefully had
placed the tags with some distance to any metal surfaces.
As opposed to the beta evaluation, the app now rendered the
content of the result directly if only one had been found. Most
participants preferred this, but were in turn confused when the
result consisted of several steps, as showing a step overview
had been omitted. Other than that, steps as a concept was well
understood and accepted.
As one of the outcomes from the user interviews, Table I
shows the general user acceptance, measured by means of the
System Usability Scale (SUS). The table clearly documents
the improvements in user experience on almost all topics as
compared to the Beta version. The largest positive change
occurs related to the app’s ease of use, with an increase from
3.1 (uncertain) to 4.4 (clear agree) average score. Overall, our
participants had a positive view on the MobileSage system and
found it useful and relevant. The scale also shows potential for
improvement, however, when it comes to opinions concerning
the app’s ease of use.
E. V2.0 setup
The following paragraphs are an excerpt from the more
detailed evaluation report [38].
In the V2.0 evaluation, we looked at the ﬁnal version of
the CMS to see how well it worked, and the ﬁnal version of
the HoD app to get feedback on changes to the app. It was a
limited evaluation held in cooperation with three participants
from the local senior user group that had been involved in the
project. Due to time constraints, the evaluation was held as
a workshop with all three participants using the system and
giving comments simultaneously.
The participants were given a short introduction about the
CMS and were then asked to create instructional content that
they subsequently uploaded to the CMS. Participants chose
to create a video in three parts (steps) for heating water in a
microwave. They shot the video on one of the phones, copied
the videos over to laptop, and proceeded to put them on the
CMS.
For the HoD part, many of the tasks were borrowed
from the previous evaluation. We gave the informants a short
introduction to the HoD, speciﬁcally focusing on the media
types setting. The participants were then instructed to ﬁnd
a video about tickets by using the scanning functionality
after having changed the media type settings to accept only
formatted text and plain text.
The session was concluded with a short discussion about
the app and the CMS.
F. V2.0 results
Concerning the CMS, participants were in the beginning
confused about how content was organized and had in par-
ticular problems to understand that a record can consist of
multiple steps. Related to this is that a user needs to ﬁll in
two titles, one for a step, and another for the entire record.
This information was not included on the web page itself
and needed to be explained by the trial observers. Once the
concept was understood, participants were able to create and
add content containing multiple steps.
Participants encountered problems related to the media
type of the content to upload. Depending on the ﬁle type
(MIME type), particular buttons (“Continue”, “Publish”) were
shown or hidden. As mentioned in Section VII, only a limited
number of formats are allowed to be uploaded in the CMS.
However, the negative result from the media type check was
not communicated to the user who then had to assume that the
upload form did not work. Hence, the user needs to be properly
informed about each requirement to an input ﬁeld, and each
conducted check. On the other hand, the participants were able
to complete all the steps and ﬁll in the content summary, but
they could not actually add the content to the CMS.
All participants commented on the necessity of extra infor-
mation for creating and adding content in terms of tips on how
to create videos so the videos would be most instructional. One
participant was afraid to pack too much information into the
content. A take-away here may be to provide thought-through
tools and also assistance for proper content generation.
The CMS makes content available for all, which turned
out to be of concern for some participants. They commented
that users could hesitate to upload information if it was
public for everyone, even though the trial observers pointed
out that the location information helps to limit exposure for
information, and that the majority of all information intended
for MobileSage is designed to be for public access. It is noted
here that it is technically possible to restrict access to a record
say with a passphrase, but this of course adds to the complexity
of the system.

276
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
TABLE I.
THE SYSTEM USABILITY SCALE COMPARISON BETWEEN BETA AND V1.0; 1=STRONGLY DISAGREE, 5=STRONGLY AGREE.
Question
Beta
V1.0
I think that I would like to use this system frequently
3.5
4.0
I found the system unnecessarily complex
1.6
1.7
I thought the system was easy to use
3.1
4.4
I think that I would need the support of a technical person to be able to use this system
1.7
1.9
I found the various functions in this system were well integrated
3.0
3.8
I thought there was too much inconsistency in this system
2.5
1.4
I would imagine that most people would learn to use this system very quickly
3.8
4.3
I found the system very cumbersome to use
1.3
1.3
I felt very conﬁdent using the system
2.6
3.2
I needed to learn a lot of things before I could get going with this system
3.5
2.3
In the settings of the app, when choosing media types,
users were presented with the jargon terms for the types in the
database and not a suitable translation in their own language,
leading to questions about the meaning of each term. The built-
in help in the app does indeed explain these types without using
jargon, but this help is not available when choosing types. The
conclusion here is that technical jargon should be avoided, and
that concise and explaining help should be available where
challenges might arise.
Using the different help-on-demand functions in the HoD
app, including scanning of QR codes and NFC tags, worked as
expected. One phone, however, was a bit large, and users had
to move the phone forth and back to get to read the tag. We
believe this problem would vanish as the users become used
to their phone.
Generally, the participants were excited about the possibili-
ties of the MobileSage service and wanted to use both systems
(app and CMS) more. We are going to address a number of the
issues found in the various evaluations before a ﬁnal version
of each system is released. The CMS is currently available
online [39], and the HoD app will shortly be offered through
Google Play [40] and the MobileSage website [41].
IX.
CONCLUSION AND OUTLOOK
We presented MobileSage, a service for delivery of context-
aware, accessible, and personalized help content in an on-
demand manner, exampliﬁed by two prototypes, a smartphone
application and a content management system.
In the prototypes, we incorporated results from related
research as well as the needs of the primary, secondary,
and tertiary users. The system employs multimodality as an
accessibility measure, as well as internationalization and data
mining for user personalization, multi-resolution and multi-rate
transmission techniques for device adaptivity, and location-
aware media searches for relevance. The system can index
both internal and external media databases.
The ﬁndings from our focus groups and the three user
evaluations show that there is a strong desire for context-
dependent and adaptive help content, and that such a service is
highly appreciated by its end-users. Moreover, the high degree
of user involvement in the project ensured products which
reﬂect the wishes and needs of all stakeholders in general, and
the primary users in particular. The prototypes have improved
quite a bit throughout the user evaluations, as reﬂected by
increases in the System Usability Scale.
At the end of the project, we now have the proof of
concepts and the proper technology with development matu-
rity, as according to the AAL JP vision. A ﬁnal service with
production maturity could be released within 1–2 years time.
Among remaining issues are: the proper handling of ofﬂine
and low-signal situations, proper tools and an improved user
interface for the generation of content, including content access
control, and assistance and guidelines for the production of
usable and accessible content, such as the length of timed
media, phrasing of information, and how multimedia content
should be organized. Also, the integrity of the content is
currently not controlled in any way. Here, a review system and
content credibility management could offer a proper solution.
Another area for future exploration is a long-term evalu-
ation of the adaptation module. All of our evaluations were
too short to see how much adaptivity affected the participants.
One way to solve this is to provide the HoD app to users for
a longer period (weeks or months), to see how the app adapts
to their usage, and if users would notice and appreciate these
changes.
ACKNOWLEDGMENTS
This work was partly funded by the European Commission
through the AAL Joint Programme, the Norwegian Research
Council, and national bodies in Spain and Romania. The
authors thank the consortium members for their valuable
contributions and all individuals involved in the user studies
for their feedback.
REFERENCES
[1] T.
Halbach
and
T.
Schulz,
“Mobilesage
–
A
prototype based case study for delivering context-aware,
personalized, on-demand help content,” in Proceedings
of the Sixth International Conference on Advances
in
Human
oriented
and
Personalized
Mechanisms,
Technologies, and Services, IARIA.
Venice (Italy):
IARIA XPS Press, Oct. 2013. [Online]. Available:
http://www.iaria.org/conferences2013/CENTRIC13.html
[2] D. Metz and M. Underwood, Older, Richer, Fitter: Identi-
fying the Consumer Needs of Britain’s Ageing Population.
Age Concern England, 2005.
[3] European Commission, “Digital Agenda: Commission
proposes rules to make government websites accessible
for all,” retrieved 2014-05-20. [Online]. Available: http:
//europa.eu/rapid/press-release\ IP-12-1305\ en.htm

277
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[4] AAL Association, “Innovative ict solutions for ageing –
ambient assisted living,” retrieved 2014-05-20. [Online].
Available: http://www.aal-europe.eu/
[5] ——, “Ict-based solutions for advancement of older
persons’ independence and participation in the “self-
serve society”,” 3rd Call for Proposals (2010). [Online].
Available: http://www.aal-europe.eu/
[6] T. H. Røssvoll, “The European MobileSage Project –
– Situated adaptive guidance for the mobile elderly,”
in Electronic Government and Electronic Participation,
Joint Proceedings of Ongoing Research and Projects of
IFIP EGOV and IFIP ePart 2012, H. J. Scholl, L. S.
Flak, M. Janssen, A. Macintosh, C. E. Moe, Øystein
Sæbø, E. Tambouris, and M. A. Wimmer, Eds., vol.
Schriftenreihe Informatik 39, International Federation for
Information Processing. Kristiansand (Norway): Trauner
Verlag, Sep. 2012, pp. 215–222.
[7] APSIS4ALL Project Consortium, “The APSIS4ALL
project,”
retrieved
2014-05-20.
[Online].
Available:
http://www.apsis4all.eu/
[8] ASK-IT Project Consortium, “The ASK-IT project,”
retrieved 2014-05-20. [Online]. Available: http://www.
ask-it.org/
[9] MyUI Project Consortium, “The MyUI project,” retrieved
2014-05-20. [Online]. Available: http://www.myui.eu/
[10] Guide
Project
Consortium,
“The
Guide
project,”
retrieved
2014-05-20.
[Online].
Available:
http:
//www.guide-project.eu/
[11] DIADEM Project Consortium, “The DIADEM project,”
retrieved 2014-05-20. [Online]. Available: http://www.
project-diadem.eu/
[12] GPII Project Consortium, “The GPII project,” retrieved
2014-05-20. [Online]. Available: http://gpii.org/
[13] Snapi Project Consortium, “The Snapi project,” retrieved
2014-05-20. [Online]. Available: http://www.snapi.org.
uk/
[14] CEN (European Committee for Standardization) TC224
WG6, “En-1332-4: Coding of user requirements for peo-
ple with special needs,” 2012.
[15] GoldUI Project Consortium, “The GoldUI project,”
retrieved 2014-05-20. [Online]. Available: http://www.
goldui.eu/
[16] WayFiS Project Consortium, “The WayFiS project,”
retrieved 2014-05-20. [Online]. Available: http://www.
wayﬁs.eu/
[17] Mediate Project Consortium, “The Mediate project,”
retrieved 2014-05-20. [Online]. Available: http://www.
mediate-project.eu/
[18] Access2all Project Consortium, “The Access2all project,”
retrieved 2014-05-20. [Online]. Available: http://www.
access-to-all.eu/
[19] A. J., S. J.L., and A. J.I., “Ambiennet – ambient intelli-
gence supporting navigation for people with disabilities,”
Jornada de Seguimiento de Proyectos, 2009.
[20] HAPTIMAP Project Consortium, “The HAPTIMAP
project,”
retrieved
2014-05-20.
[Online].
Available:
http://www.haptimap.org/
[21] MAPPED Project Consortium, “The MAPPED project,”
retrieved 2014-05-20. [Online]. Available: http://services.
txt.it/MAPPED
[22] E. M., I. M., and L. I., “Touch- and audio-based medi-
cation management service concept for vision impaired
older people,” IEEE International Conference on RFID-
Technologies and Applications (RFID-TA), 2011.
[23] V. G., K. D., S. O., M. S., and T. S., “Indoor localization
using passive RFID,” Proceedings of Signal Processing,
Sensor Fusion, and Target Recognition, 2011.
[24] K. Skillen, L. Chen, C. D. Nugent, M. P. Donnelly,
and I. Solheim, “A user proﬁle ontology based approach
for assisting people with dementia in mobile environ-
ments,” in Engineering in Medicine and Biology Society
(EMBC), 2012 Annual International Conference of the
IEEE.
IEEE, 2012, pp. 6390–6393.
[25] W. Burns, L. Chen, C. Nugent, M. Donnelly, K.-L.
Skillen, and I. Solheim, “A conceptual framework for
supporting adaptive personalized help-on-demand ser-
vices,” in Ambient Intelligence. Springer, 2012, pp. 427–
432.
[26] K.-L. Skillen, L. Chen, C. Nugent, M. Donnelly,
W. Burns, and I. Solheim, “Using swrl and ontological
reasoning for the personalization of context-aware assis-
tive services,” in Proceedings of the 6th International
Conference on PErvasive Technologies Related to Assis-
tive Environments.
ACM, 2013, p. 48.
[27] W. Burns, L. Chen, C. Nugent, M. Donnelly, K. L.
Skillen, and I. Solheim, “Mining usage data for adap-
tive personalisation of smartphone based help-on-demand
services,” in Proceedings of the 6th International Con-
ference on PErvasive Technologies Related to Assistive
Environments.
ACM, 2013, p. 39.
[28] K.-L. Skillen, L. Chen, C. D. Nugent, M. P. Donnelly,
W. Burns, and I. Solheim, “Ontological user modelling
and semantic rule-based reasoning for personalisation
of help-on-demand services in pervasive environments,”
Future Generation Computer Systems, 2013.
[29] Øystein
Dale,
“User
needs
analysis,”
MobileSage
Consortium,
Tech.
Rep.
MobileSage
Deliverable
D2.1, 2012. [Online]. Available: http://mobilesage.eu/
public-documents/public-deliverables
[30] T.
H.
Røssvoll,
“User
requirements
speciﬁcation,”
MobileSage Deliverable D2.2, MobileSage Consortium,
Tech.
Rep.,
Feb.
2012.
[Online].
Available:
http:
//mobilesage.eu
[31] L.
Curescu,
I.
Anghelache,
and
T.
H.
Røssvoll,
“System requirements speciﬁcation for help-on-demand
service,” MobileSage Deliverable D2.3, MobileSage
Consortium, Tech. Rep., Apr. 2012. [Online]. Available:
http://mobilesage.eu
[32] T.
H.
Røssvoll
and
V.
A.
Gracia,
“System
requirements
speciﬁcation
for
content
management
service,” MobileSage Deliverable D2.4, MobileSage
Consortium, Tech. Rep., Apr. 2012. [Online]. Available:
http://mobilesage.eu
[33] R. Mohamad Rasli, S. C. Haw, and R. Mohamad Rasli,
“A survey on optimizing image, video, and audio query
retrieval in multimedia databases,” International Journal
of Advanced Computer Science, vol. 2, no. 6, 2012.
[34] D. Das and A. F. Martins, “A survey on automatic text
summarization,” Literature Survey for the Language and
Statistics II course at CMU, vol. 4, pp. 192–195, 2007.
[35] D. Brezeale and D. J. Cook, “Automatic video classiﬁ-
cation: A survey of the literature,” Systems, Man, and
Cybernetics, Part C: Applications and Reviews, IEEE
Transactions on, vol. 38, no. 3, pp. 416–430, 2008.

278
International Journal on Advances in Intelligent Systems, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/intelligent_systems/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[36] W. Hu, N. Xie, L. Li, X. Zeng, and S. Maybank, “A sur-
vey on visual content-based video indexing and retrieval,”
Systems, Man, and Cybernetics, Part C: Applications and
Reviews, IEEE Transactions on, vol. 41, no. 6, pp. 797–
819, 2011.
[37] I. Solheim, T. Halbach, T. Schulz, J. R. Simon, I. Turcu,
A. Sterea, I. Anghelache, and L. Spiru, “D4.3 evaluation
report,”
MobileSage
Deliverable
D4.3,
MobileSage
Consortium, Tech. Rep., Oct. 2013. [Online]. Available:
http://mobilesage.eu
[38] T. Schulz, “CMS & HOD test at Seniornett,” MobileSage
Consortium, Tech. Rep. Internal MobileSage Report,
2014.
[39] MobileSage Consortium, “Content management system.”
[Online]. Available: http://mobilesage.nr.no
[40] ——,
“Help-on-demand
application,”
available
after
2014-04-01. [Online]. Available: https://play.google.com/
store/search?q=mobilesage
[41] V. S´anchez, “The MobileSage Project,” retrieved 2014-
05-20. [Online]. Available: http://mobilesage.eu

