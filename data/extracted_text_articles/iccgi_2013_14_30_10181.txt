Predicting Early Students with High Risk to Drop Out of University using a Neural 
Network-Based Approach 
Miguel Gil, Norma Reyes, María Juárez, Emmanuel Espitia, Julio Mosqueda and Myriam Soria  
Information Technologies 
Universidad Tecnológica de León 
León, Guanajuato, México 
e-mail: mgil@utleon.edu.mx, navila@utleon.edu.mx, mdjuarez@utleon.edu.mx, eespitia.celula@utleon.edu.mx, 
jmosqueda@utleon.edu.mx, msoria@utleon.edu.mx  
 
Abstract—This research is focused on the use of an Artificial 
Neural Network-based prototype in order to measure and 
predict the probability that students drop out of university. 
This probability is calculated in an early stage when the 
students get enrolled in some of the university study programs. 
Once we obtain the results they are analyzed and compared in 
order to know how the factors affect to the model behavior and 
the predicted result. Finally, we describe how this research can 
assist student advisors by using a support tool that helps them 
to identify in a fast way those students with a high risk of 
dropping out of university, and help them before they quit 
school. 
Keywords-artificial neural networks; students drop out; early 
prediction; university drop out 
I. 
 INTRODUCTION 
Dropping out of university is a common problem with 
students in México [1]. For governments, this is a worrisome 
situation since the state must provide all support to students 
in order to allow them to graduate with a professional college 
degree and advanced technical skills. 
Providing higher education to all sectors of a nation’s 
population means confronting social inequalities deeply 
rooted in history, culture and economic structure that 
influence an individual’s ability to compete. Quality 
assurance in higher education has raised to the top of the 
policy agenda in many nations [2][3]. 
Some studies show that students’ previous behavior is a 
good predictor of future behavior [4][5][6]. This way, the 
Universidad Tecnológica de León (UTL) applies a survey to 
know some aspects about the students’ life. This survey 
involves questions about students’ family and their 
relationship which each member, vices, health and frequent 
diseases, skills and assignments that are relevant to them 
finishing the program successfully. However, this survey 
many times is not used correctly, since it collects too much 
information and it is hard to understand for most of the 
teachers and advisors, since they are not trained as 
psychologists and by consequence they do not have this 
profile. 
In the scholar model of the UTL, students are grouped 
and each group has a teacher that acts as an advisor for the 
group. Advisors are responsible to follow the academic 
performance of their groups. They do some activities related 
to the students’ behavior in order to detect those students 
with a high risk to drop out of university. The most valuable 
instrument that advisors have in order to detect those 
students with a high risk is the information provided by a 
personal interview with each student of the group. This is a 
highly time-consuming task, and it requires a lot of days 
even weeks since some groups have up to 30 students. Many 
times, students drop out of university before attending an 
interview with the advisor and the advisor is unable to detect 
students’ problems. Detection of student’s problems is a hard 
task since most of the teachers have not been trained as a 
psychologist. This way, the proposed solution is very 
important, since it can be used as an advice tool in order to 
help advisors to detect those students with a high risk to drop 
out of university, since the very first course. 
In this research, a Back Propagation Artificial Neural 
Network-based system is proposed in order to measure the 
university students dropping out probability once they are 
enrolled in some university academic study program. This 
research was developed at the UTL and it was applied to 
students enrolled in the Information and Communication 
Technologies academic programs. In the second section, an 
introduction to educational data mining is described since 
this research is related with educational purposes but also, it 
involves data analysis and pattern discovery to estimate a 
future behavior. In the third section, the dataset used for 
prediction is described. In the fourth section, the neural 
network architecture is analyzed but also, the reason why 
that technique was used is described. In the fifth section, the 
prototype development is described. In the sixth section, the 
obtained results are discussed. Finally, in the seventh section, 
conclusions and future research are described. 
II. 
EDUCATIONAL DATA MINING 
Into the educational field, there is a wide variety of 
problems concerning students’ behavior and some kind of 
development using intelligent computational techniques and 
algorithms are well documented. For example, some 
researches are focused to discover if a student is cheating on 
an online assessment when he/she is taking it [7][8]. Others 
are focused on studying how students learn [9]. 
In all cases mentioned above, data mining plays a very 
important role in order to provide with solutions in each 
described scenario and it is called “educational data mining”.  
Educational data mining is an emerging discipline, 
concerned with developing methods for exploring the unique 
types of data that come from the educational context [10]. 
289
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

Close works with this paper are the research works 
related with the students’ successful academic performance. 
Nearly all works try to identify the main factors that could be 
used as the best predictors for successful students more than 
measure or build a computational predictive model 
[7][8][9][11][12]. However, that approach is complex to be 
applied for most of teachers in their advisory sessions, and 
they must follow the educational model including 
procedures, formats and surveys and its implementation may 
require a lot of effort and spent time since in the UTL, the 
number of factors to be considered to predict are too many. 
The closest work to this research that was found was [3]. In 
that research, a Bayesian classification model is proposed in 
order to classify students in one of two groups: performance 
or underperformance. This classification is made using a 
dataset that includes some students’ features. However, in 
this research, since the number of features is considerably 
large and the features relationship is unknown, a Bayesian 
based-model was not used. Instead, an Artificial Neural 
Network-based (ANN) [13] approach was used since it is a 
more soft-classification technique and they are widely 
applied in pattern recognition and prediction problems when 
data nature, mean or relationships between them are 
unknown [13]. 
III. 
THE TRAINING DATASET 
The dataset used in this research includes many features 
from students. Those features are collected from a survey to 
all new students when they get enrolled in the UTL. The 
survey features include information about high school name 
and type (government or private), high school final grade, 
vices and addictions (alcohol, smoke, drugs, etc.), common 
diseases, relationship with parents, brothers and family, 
different 
kinds 
of 
problems: 
economics, 
transport, 
delinquency, etc. The dataset had 302 total historic records 
with 34 features. The dataset was split in two parts: 219 
records were used to train the neural network and the 
remaining 83 records were used in prediction. The used 
records correspond to historical data in order to allow 
measuring the neural network accuracy. Fig. 1 shows the 
factors taken from the initial survey, which students 
previously answered when they get enrolled into the 
university. 
 
Figure 1.  Survey factors that are used in order to predict graduate 
students’  probability. 
The survey is answered by new students when they get 
enrolled in the UTL. It has been applied since year 2000 and 
it was applied on paper. Only until year 2010, the survey 
began to be applied on a web-based system. This means that 
a large number of surveys remained on paper. However, 
many of them no longer exist because teachers and advisors 
got rid of them every three years. For this reason, only 302 
surveys could be found for the Information Technologies 
area. This scenario is similar for the other areas in the UTL. 
IV. 
NEURAL NETWORKS  
A. Neural Network Architecture 
The main ANNs’ advantage is learning capability. ANN's 
are very important in many technological fields; for example, 
biometric recognition sensors (fingerprints, retinal scanners, 
etc.), pattern recognition (handwriting recognition, face 
recognition, etc.) [14][15][16][17][18]. Neural networks 
have demonstrated they are functional because they have 
achieved good results. For example, in diagnosis of breast 
cancer, neural networks performance was in 89% to detect 
positive cases and the average for the same task performed 
by specialists was 84% [14]. Artificial neural networks are 
often compared with logistic regression, and it can be seen 
that both models perform on about the same level more often 
than not, with the more flexible neural networks generally 
outperforming logistic regression in the remaining cases 
[23]. 
A wide range of types of neural networks has been 
developed to date; for example, Radial Base [27][28][29], 
Hopfield [30][31][32][33] and Back Propagation (with many 
variants) [13][34]. Many of them are based on the basic 
Perceptron ARN [19][20][21][22]. In this research, a 
multilayer neural network with error back propagation and 
momentum was used [22][34]. 
B. Neural Network Design 
The neural network input layer was designed using all 
dataset features and one additional threshold neuron (33 + 1 
neurons). The final number of nodes for the hidden layer was 
69. One layer of hidden neurons is generally sufficient for 
classifying most data sets. The number of neurons in the 
hidden layer needs to be set empirically, e.g., by cross-
validation or bootstrapping [23]. The output layer has only 
one neuron with two limit values: 0 and 1, since only two 
possibilities are considered to measure the final status for the 
students when they leave the university. The two possible 
scenarios for any student that leaves the university are: 1: if 
the student successfully finished his studies and gets 
graduated; 0: if the student drops out the university. 
However, an interesting approach with ANN’s is that their 
output values may have intermediate values between 0 and 1, 
considering that output value as the probability that any 
student have to finish his studies. A higher value in the 
output neuron means that the student has major probability to 
successfully finish his studies. For this research, if the 
neuron is activated (with a value major or equals to 0.50) is 
considered that the student will have a good probability to 
 
290
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

finish his studies successfully and advisors could be focused 
firstly on those students for whom its output value was less 
than 0.5. Fig. 2 shows the neural network design 
architecture. 
 
Figure 2.  Neural network design architecture. 
Fig. 2 shows the architecture design for the used neural 
network. In the model of an ANN, the most important part is 
the neuron. The neuron receives a set of input signals from 
the environment (each survey factor) or from another neuron. 
 
Figure 3.  Illustration of an artificial neuron. 
As shown in Fig. 3, an artificial neuron receives input 
signals, and each input signal has a weight. Also, each 
neuron computes a net input signal using the input signals 
and the weight of each input signal. Net input signal was 
calculated using Equation (1): 

netii

where net is the net input signal, Wi is the current weight for 
each neuron and Xi is each input value. Once the net input 
signal was calculated, the output (also called activation 
signal) must be calculated. The output signal was calculated 
using a sigmoid function: 

enet

where  is a parameter to control the steepness of the 
function and usually equals to 1, q is a bias or threshold 
value. When simple neurons implement, for example, 
Boolean functions, it is easy to calculate them. But, when 
prior knowledge about the function is missing - except for 
data -, the  and i values are adjusted through training [13]. 
The neural network training was performed using the 
Neuroph Studio software [25]. The optimal neural network 
parameters were: learning rate = 0.1428; momentum = 
0.8192; training error = 0.01. Fig. 4 shows the training 
performance. 
 
Figure 4.  Neural network raining performance. 
As it is shown in Fig. 4, approximately 135 iterations 
were needed in order to achieve the training error. After the 
neural network was trained, it was used with the test records 
in order to calculate and evaluate the results. 
V. 
PROTOTYPE BUILDING 
In order to use the neural network designed and trained 
previously, a software prototype was developed. It was 
developed in the Java programming language [24]. Fig. 5 
shows the main user interface. 
 
Figure 5.  Prototype main user interface. 
Into the main interface, the user must select and load the 
neural network file (created with Neuroph Studio in the 
neural network design stage). The prototype uses the Encog 
framework in order to manipulate and use the neural network 
[26]. 
Once the neural network is loaded, the next step is load a 
file containing the students’ enrollment key field. Then, the 
system queries for those students’ data into a database, in 
order to compute their success probability, and finally it will 
display a table containing all students’ data including their 
success probability. Fig. 6 shows an example of a table 
results displayed by the program. 
 
Figure 6.  Results table example. 
Fig. 6 shows how the system calculates and presents the 
results. Each part of the survey is marked with a distinct 
 
 
 
 
291
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

color and the last column represents the probability that 
students successfully finish their studies. 
VI. 
RESULTS 
To measure the results, sample records were taken from 
the original dataset. Table 1 shows how the sample is 
distributed. 
TABLE I.  
SAMPLE DATASET SUMMARY 
Gender 
Finished 
Successfully 
Dropout 
Female 
12 
29 
Male 
18 
24 
Total 
30 
53 
As it is shown in Table 1, the sample contains 41 records for 
women (12 finished successfully, 29 dropped out) and 42 
records for men (18 finished successfully, 24 dropped out). 
In a first-view, major drop outs are for women (29) and a 
woman is ranking less on successfully finishing her studies. 
In the sample, only 29% of women finished successfully 
their studies and the other 71% dropped out. For male data, 
43% finished successfully their studies and the other 57% 
dropped out.  
Unfortunately, the university does not know the factors 
that cause those students’ drop out. The only evidence, in 
most cases is that the student fails to assist to his courses, but 
underlying causes remain unknown for nearly all cases. 
Teachers including the advisor know the causes why 
students that dropped out but, this only happens when 
students tell them why they are leaving the school. However, 
even in these cases, the cause or factor is not recorded. This 
is important to be mentioned because the students’ data that 
we have in order to predict their probability to finish their 
studies successfully is the survey that they must answer once 
they are enrolled into the university programs.  
Fig. 7 shows the results produced by the system using the 
dataset mentioned in Table 1. It is divided in two sections. 
On the left section, the results for students that drop out of 
university are shown. In the right section, the results of the 
students that finished their studies successfully are shown. 
That records was subtracted randomly from the original 
dataset and it was not used on the training stage. Record Id 
column is a unique id assigned to each record. Desired 
output column means the student real result: 0 if the student 
drops out, 1 if the student finished successfully. The output 
column shows the result produced by the system. System 
error column is calculated as: 

Desired output - System output

Based on the obtained results by the program, reliability 
was in a 76%. That means that program failed to predict 20 
cases and asserts to predict the remaining 63 cases. 
 
 
Record Id Desired Output System Output System Error Gender
Record Id Desired Output System Output System Error Gender
1876
0
0.1085
-0.1085
M
1890
1
0.9994
0.0006
F
1826
0
1
-1
F
1857
1
0.1552
0.8448
F
1884
0
0.9994
-0.9994
F
1821
1
1
0
M
1855
0
0.9989
-0.9989
F
1901
1
0.9916
0.0084
M
1832
0
0.1175
-0.1175
F
1868
1
1
0
F
1825
0
0.1175
-0.1175
M
1899
1
1
0
M
1834
0
0
0
F
1858
1
0.9995
0.0005
M
1851
0
0
0
F
1894
1
0.1668
0.8332
F
1864
0
0.1174
-0.1174
F
1887
1
1
0
F
1867
0
0.1275
-0.1275
F
1829
1
0.0044
0.9956
M
1830
0
0.7853
-0.7853
F
1896
1
1
0
M
1846
0
0.9994
-0.9994
M
1822
1
0
1
M
1866
0
1
-1
M
1892
1
0.1199
0.8801
M
1838
0
0.3756
-0.3756
F
1895
1
0.9996
0.0004
M
1845
0
0.9996
-0.9996
M
1882
1
0.0882
0.9118
F
1842
0
0.1153
-0.1153
F
1878
1
0.0169
0.9831
M
1848
0
0.8919
-0.8919
F
1885
1
0.1183
0.8817
M
1833
0
0
0
M
1820
1
1
0
F
1880
0
0.1219
-0.1219
M
1893
1
1
0
M
1871
0
1
-1
M
1890
1
0.9994
0.0006
F
1859
0
1
-1
F
1823
1
0.1177
0.8823
F
1862
0
1
-1
M
1892
1
0.1199
0.8801
M
1849
0
0
0
M
1883
1
0.9898
0.0102
M
1852
0
0.1182
-0.1182
F
1897
1
1
0
F
1850
0
0.1247
-0.1247
M
1898
1
0.0002
0.9998
F
1853
0
0.1176
-0.1176
M
1858
1
0.9995
0.0005
M
1835
0
0.1182
-0.1182
F
1819
1
0.3581
0.6419
F
1869
0
0.9991
-0.9991
F
1874
1
0.9996
0.0004
M
1872
0
0.114
-0.114
F
1887
1
1
0
F
1839
0
0.9988
-0.9988
F
1857
1
0.1552
0.8448
F
1825
0
0.1175
-0.1175
M
1821
1
1
0
M
1828
0
0.3945
-0.3945
M
1886
1
0.9967
0.0033
M
1865
0
0.1179
-0.1179
F
1889
1
1
0
M
1879
0
0
0
F
1868
1
1
0
F
1863
0
0.117
-0.117
F
1861
1
0.211
0.789
F
1888
0
1
-1
M
1878
1
0.0169
0.9831
M
1824
0
0.9996
-0.9996
F
1894
1
0.1668
0.8332
F
1870
0
0.9276
-0.9276
M
1885
1
0.1183
0.8817
M
1841
0
0.1174
-0.1174
M
1881
1
0.9994
0.0006
M
1840
0
0
0
F
1891
1
0.5898
0.4102
M
1900
0
1
-1
M
1822
1
0
1
M
1836
0
0.9973
-0.9973
F
1892
1
0.1199
0.8801
M
1860
0
0.1178
-0.1178
M
1882
1
0.0882
0.9118
F
1856
0
1
-1
M
1883
1
0.9898
0.0102
M
1849
0
0
0
M
1897
1
1
0
F
1847
0
0.069
-0.069
F
1898
1
0.0002
0.9998
F
1854
0
0.0661
-0.0661
M
1820
1
1
0
F
1844
0
0.9902
-0.9902
F
1893
1
1
0
M
1877
0
0.0006
-0.0006
M
1831
0
0.1475
-0.1475
F
1872
0
0.114
-0.114
F
1837
0
0.1175
-0.1175
F
1827
0
0.0763
-0.0763
F
1843
0
0.0005
-0.0005
M
1873
0
0.1162
-0.1162
M
1875
0
0.3821
-0.3821
M
1849
0
0
0
M
 
 
Figure 7.  Results obtained by the system. 
A failed prediction means that desired output was 0, and 
program output value was major or equals to 0.5. The 0.5 
value is the output neuron’s threshold activator and, while 
the output value is greater, the probability for students finish 
their studies successfully increased. 
An interesting aspect in the survey is the “main factor” 
column. In this part, the students must select their main issue 
that could impede them to finish the school program. Fig. 8 
shows the frequency of answers for this column. 
 
Figure 8.  Frequency of responses for column “main factor”. 
292
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

Fig. 9a shows the frequency of answers in the training 
dataset, and Fig. 9b corresponds to the test dataset. In both 
cases, the major frequency is the economic factor. However, 
the second factor varies from males and females. 
 
Figure 9.  Drop out frequency of responses for column “main factor”. 
As it is shown in Fig. 9, the second most frequent factor 
for drop out in female students was “none” (9a), while for 
males was “academic” (9b). On the skills part, frequencies 
are shown in Table 2. 
TABLE II.  
SKILLS FREQUENCY FOR MEN AND WOMEN 
Assignment skills 
frequency 
Gender 
Female 
Male 
Spanish Skill 
97.56% 
85.71% 
Spanish Dificult 
2.44% 
4.76% 
Spanish No Answer 
0.00% 
4.76% 
 
  
  
Computer Skill 
73.17% 
80.95% 
Computer Diificult 
21.95% 
9.52% 
Computer No Answer 
4.88% 
4.76% 
 
  
  
Mathematics Skill 
41.46% 
33.33% 
Mathematics Diificult 
53.66% 
59.52% 
Mathematics No Answer 
4.88% 
2.38% 
 
  
  
English Skill 
34.15% 
42.86% 
English Diificult 
65.85% 
50.00% 
English No Answer 
0.00% 
2.38% 
 
  
  
Technology Skill 
56.10% 
85.71% 
Technology Diificult 
36.59% 
4.76% 
Technology No Answer 
7.32% 
4.76% 
 
In Table 2, major frequency skills are in Spanish course, 
but more difficult courses are mathematics and English for 
both, men and women. The difficult issue for computers and 
technology are more frequent on women than on men. An 
important aspect here is that neural network cannot be 
trained if we skip the survey’s skills section. A deeper study 
is needed in order to understand how these factors alter the 
final result, but it requires some data mining techniques to 
achieve that goal since we are dealing with a considerably 
amount of data and fields. 
VII. CONCLUSIONS AND FUTURE RESEARCH 
This information is relevant in a first-stage, because it 
allows advisors to identify those students with a high risk to 
drop out of university from the beginning. For the cases 
where the program fails to predict the correct result, some 
inconsistences in the survey answers were found. For 
example, some students indicated to have high ability in 
math, but in another survey section, they wrote comments 
indicating that they felt concern by math. Additionally, as 
seen on Fig. 8, in the results section, those women that 
dropped out the school and where the system predicted a 
high probability to finish successfully, the second major 
cause was “none”. This can be explained in an empirical way 
because teachers are noticed frequently by female students 
that they have unplanned pregnancies. This type of 
information cannot be inferred by the survey. Maybe a new 
question about the student’s sexual life could be useful to 
predict this type of drop outs. The UTL continues to support 
this research in order to implement this prototype as an 
active module on its scholar control system to be used by 
teachers and advisors as a complementary advice tool. 
Future research will include modifications to the survey 
to add more information features. Is planned to add more 
neurons to the neural network output layer in order to have 
multiple outputs and, later calculate their average and use it 
as the result. Also, is necessary a deeper study in how the 
survey’s factors affect to the students behavior and their 
decision to leave the school. 
ACKNOWLEDGMENT 
Thanks to the Universidad Tecnológica de León by 
supporting this research. 
REFERENCES 
 
[1] UTL, UTL statistics, Universidad Tecnológica de León, 2012, 
In: 
http://www.utleon.edu.mx/index.php?option=com_content&v
iew=article&id=229&Itemid=59 [retrieved: July, 2013]. 
[2] P. Altbach, L. Reisberg, and L. Rumbley, Trends in Global 
Higher Education: Tracking an Academic Revolution, 
UNESCO, 2009. 
[3] U. Kumar and S. Pal, “Data Mining : A prediction of 
performer 
or 
underperformer 
using 
classification,”  
International Journal of Computer Science and Information 
Technologies, vol. 2, Apr. 2011, pp. 686-690. 
[4] W. Camara and E. Kimmel, “Choosing students: Higer 
education admissions tools for the 21st century,” Lawrence 
Erlbaum Associates, Publishers, 2005, pp. 53–79. 
293
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

[5] K. Frome, W. Corbin, and M.  Kruze,  “Behavioral risks 
during the transition from high school to college. U.S.,”  
National Institutes of Health's National Library of Medicine: 
Developmental Psychology, Sep. 2008,  pp. 1497–1504. 
[6] C. Noyes, J. Gordon, and J. Ludlum, “Engagement Half-Life: 
The Impact of Incoming Student Characteristics throughout 
the College Career ,” Georgia Institute of Technology, Jun. 
2006. In: 
https://www.assessment.gatech.edu/documents/  
[retrieved: July, 2013]. 
[7] J. Hernández, A. Ochoa, J. Muñoz, and G. Burlak,  “Detecting 
cheats in online student assessments using Data Mining,” 
DMIN’06 , Las Vegas, NV: Conference on Data Mining, 
2006, pp. 204-210. 
[8] B. Whitley, “Factors associated with cheating amoung college 
students: A review,” Springer, vol. 39, 1998, pp. 235-274. 
doi: 10.1023/A:1018724900565. 
[9] A. El-Halees, “Mining Students Data to Analyze e-learning 
Behavior: A Case Study,” Islamic University of Gaza , 2009. 
In:  
http://uqu.edu.sa/files2/tiny_mce/plugins/filemanager/files/30/
papers/f158.pdf  [retrieved: July, 2013]. 
[10] C. Romero, S. Ventura, and E. García, “Data mining in course 
management systems: Moodle case study and tutorial,”  
Computers & Education: Elsevier. vol. 51, Aug. 2008, pp. 
368–384. 
[11] M. Pritchard and G. Wilson, “Predicting Academic Success in 
Undergraduates”, Boise State University, vol. 11, Oct. 2007, 
pp. 201-206. In:   
http://scholarworks.boisestate.edu/psych_facpubs/10/ 
[retrieved: July, 2013]. 
[12] S. Senanayaque, K. Liyanege, and P. Dadigamuwa, “Factors 
Affecting on Student Unsuccessfulness in Engineering 
Programmes in Distance Education,” International Journal of 
Instructional Technology & Distance Learning, vol. 2 Jun. 
2005. In: http://www.itdl.org/Journal/Jun_05/article07.htm 
[retrieved: July, 2013]. 
[13] A. 
Engelbrecht, 
“Computational 
Intelligence, 
An 
Introduction,” University of Pretoria South Africa; Wiley, 
2007, pp. 7, 15, 17-53. 98-102. 
[14] Y. Wu, et al., “Artificial neural networks in mammography: 
application to decision making in the diagnosis of breast 
cancer,” US National Library of Medicine, Apr. 1993, pp.81-
87.  In:   
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122
.5805&rep=rep1&type=pdf  [retrieved: July, 2013]. 
[15] G. Gross, J. Boone, V. Greco-Hunt, and B. Greenberg, 
“Neural networks in radiologic diagnosis: II. Interpretation of 
neonatal chest radiographs”, Investigative Radiology, vol. 25, 
Sep. 1990, pp. 1017-1023. 
[16] P. Lisboa, “A review of evidence of health benefit from 
artificial neural networks in medical intervention,” Elsevier, 
vol. 15, Jan. 2002, pp. 11-39. 
[17] M. Joo, S. Wu, J. Lu, and H. Lye, “Face recognition with 
radial basis function (RBF) neural networks,” IEEE 
Transactions on Neural Networks, vol. 13, Aug. 2002, pp. 
697-710. 
[18] J. Lin, P. Ligomenides, M. Freedman, and S. Mun, 
“Application of artificial neural networks for reduction of 
false-positive detections in digital chest radiographs,” 
Proceedings of annual symposium on Computers Applied to 
Medical Care, Nov. 1993, pp. 434-438. 
[19] L. Fausett, “Fundamentals of Neural Networks,” Pearson,  
1993, pp. 59-76. 
[20] C. Bishop, “Pattern Recognition and Machine Learning,” 
Springer, 2006, pp. 225-272. 
[21] X. 
Basogain, 
“Redes 
neuronales 
artificiales 
y 
sus 
aplicaciones,” Universidad del País Vasco, 2008,  pp. 22-25. 
[22] K. Carbajal, “Introducción de la inteligencia artificial en la 
ingeniería civil a través de las redes neuronales artificiales,” 
Congreso Nacional de Ingenierá Civil: ICG , 2003 In 
http://www.bvsde.paho.org/bvsacd/cursouni/EM-53.pdf 
[retrieved: July, 2013]. 
[23] S. Dreiseitl and L. Ohno-Machado, “Logistic regression and 
artificial neural network classification models: a methodology 
review,”  Journal of Biomedical informatics, vol. 35, Oct. 
2002, pp. 352-359. 
[24] Oracle, Java platform web page, Oracle, 2013. In:     
http://www.oracle.com/technetwork/es/java/javase/downloads
/index.html [retrieved: July, 2013]. 
[25] Z. Sevarac, et al. Neuroph,  Sourceforge, 2013. In: 
http://neuroph.sourceforge.net/neuroph-2.5-released.html 
[retrieved: July, 2013] 
[26] Heaton Research , Encog, Heaton Research, Inc., 2012. In: 
http://www.heatonresearch.com/encog [retrieved: July, 2013] 
[27] A. Sagahyroon and J. Abdalla, “Area and Timing Estimation 
in Register Files Using Neural Networks,” Circuits and 
Systems, 
vol. 
3, 
Jun. 
2012, 
pp. 
269-277, 
doi: 
10.4236/cs.2012.33037. 
[28] A. Cai,X. Xiong, Y. Liu, W. An, J. Tan, “Artificial neural 
network modeling of reduced glass transition temperature of 
glass forming alloys,”  Applied Physics Letters, vol. 92, Mar. 
2008, doi:10.1063/1.2899633. 
[29] G. Bingjun and Y. Jinshou, “ A single-neuron PID adaptive 
multicontroller scheme based on RBFNN,”  Transactions Of 
The Institute Of Measurement and Control, vol. 274, pp. 243-
259. doi:10.1191/0142331205tm147oa. 
[30] L. Maldonado, A.Peña, and O. Gualdrón, “Identificación 
Automática de Cilindros de Almacenamiento de Gas 
Utilizando Redes Neuronales Tipo Hopfield,” Revista UIS 
Ingenierías, vol. 11 Jun. 2012, pp.103-111. 
[31] G. Pajares, C. López-Martínez, J. Sánchez-Lladó,  and  I. 
Molina, “Improving Wishart Classification of Polarimetric 
SAR Data Using the Hopfield Neural Network Optimization 
Approach,”  Remote Sensing, vol.  4, Nov. 2012, pp. 3571-
3595, doi:10.3390/rs4113571. 
[32] E. Konishi . “Modeling quantum mechanical observers via 
neural-glial networks,” International Journal Of Modern 
Physics B, vol. 26, Jul. 2012, pp. 1250060-1-1250060-24, doi: 
10.1142/S0217979212501111. 
[33] A. Tatem, H. Lewis, P. Atkinson, and M. Nixon,  “Increasing 
the spatial resolution of agricultural land cover maps using a 
Hopfield neural network,”  International Journal Of 
Geographical Information Science, vol. 17, Oct. 2003, pp. 
647-672. doi:10.1080/1365881031000135519. 
[34] M. Watson, “Practical Artificial Intelligence programming 
with 
Java,” 
, 
2008, 
pp. 
110-128. 
In: 
http://www.markwatson.com/opencontent_data/JavaAI3rd.pd
f [retrieved: July, 2013]. 
294
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

