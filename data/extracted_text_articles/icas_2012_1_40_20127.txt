State-Space Feedback Control for Elastic
Distributed Storage in a Cloud Environment
M. Amir Moulavi, Ahmad Al-Shishtawy, and Vladimir Vlassov
KTH Royal Institute of Technology
Stockholm, Sweden
Email: {moulavi,ahmadas,vladv}@kth.se
Abstract—Elasticity in Cloud computing is an ability of a
system to scale up and down (request and release resources)
in response to changes in its environment and workload. Elas-
ticity can be achieved manually or automatically. Efforts are
being made to automate elasticity in order to improve system
performance under dynamic workloads. In this paper, we report
our experience in designing an elasticity controller for a key-
value storage service deployed in a Cloud environment. To
design our controller, we have adopted a control theoretic
approach. Automation of elasticity is achieved by providing a
feedback controller that automatically increases and decreases
the number of nodes in order to meet service level objectives
under high load and to reduce costs under low load. Every
step in the building of a controller for elastic storage, including
system identiﬁcation and controller design, is discussed. We have
evaluated our approach by using simulation. We have developed
a simulation framework EStoreSim in order to simulate an
elastic key-value store in a Cloud environment and be able to
experiment with different controllers. We have examined the
implemented controller against speciﬁc service level objectives
and evaluated the controller behavior in different scenarios.
Our simulation experiments have shown the feasibility of our
approach to automate elasticity of storage services using state-
space feedback control.
Keywords-elasticity; key-value store; Cloud; state-space feedback
control
I. INTRODUCTION
Web-based services frequently experience high workloads
during their lifetime. A service can become popular in just
an hour, and the occurrence of such high workloads has
been observed more and more recently. Cloud computing has
brought a great solution to the problem by requesting and
releasing VM (Virtual Machine) instances that provide the
service on-the-ﬂy. This helps to distribute the loads among
more instances. However, the high level load typically does
not last for long and keeping resources in the Cloud costs
money. This solution has led to Elastic Computing where a
system running in the Cloud can scale up and down based on
a dynamic property that is changing from time to time.
In 2001, P. Horn from IBM [1] marked the new era of
computing as Autonomic Computing. He pointed out that the
software complexity would be the next challenge of Infor-
mation Technology. Growing complexity of IT infrastructures
can undermine the beneﬁts IT aims to provide. One traditional
approach to manage the complexity is to rely on human inter-
vention. However, considering the expansion rate of software,
there would not be enough skilled IT staff to tackle the
complexity of its management. Moreover, most of the real-time
applications require immediate administrative decision-making
and actions. Another drawback of the growing complexity is
that it forces us to focus on management issues rather than
improving the system itself.
Elastic Computing requires automatic management that can
be provided using results achieved in the ﬁeld of Autonomic
Computing. Systems that exploit Autonomic Computing meth-
ods to enable automated management are called self-managing
systems. In particular, such systems can adjust themselves ac-
cording to the changes of the environment and workload. One
common and proven way to apply automation to computing
systems is to use elements of control theory. In this way a
complex system, such as a Cloud service, can be automated
and can operate without the need of human supervision.
In this paper, we report our experience in designing an
elasticity controller for a key-value storage service deployed
in a Cloud environment. To design our controller, we have
adopted a control theoretic approach. Automation of elas-
ticity is achieved by providing a feedback controller that
continuously monitors the system and automatically changes
(increases or decreases) the number of nodes in order to
meet Service Level Objectives (SLOs) under high load and
to reduce costs under low load. We believe that this approach
to automate elasticity has a considerable potential for practical
use in many Cloud-based services and Web 2.0 applications
including services for social networks, data stores, online
storage, live streaming services.
Our second contribution presented in this paper is an open-
source simulation framework called EStoreSim (Elastic key-
value Store Simulator) that allows developers to simulate an
elastic key-value store in a Cloud environment and be able to
experiment with different controllers.
The rest of the paper is organized as follows. In Section II,
we deﬁne the problem of automated elasticity and describe the
architecture of an elastic Cloud-based key-value store with
feedback control. Section III presents different approaches
to system identiﬁcation. In Section IV, we show how we
construct a state-space model of our elastic key-value store. We
continue in Section V by presenting the controller designing
for our storage. Section VI summarises steps of controller
design including system identiﬁcation. In Section VII, we
describe the implementation of our simulation framework
18
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

EStoreSim. Experimental results are presented in Section VIII
followed by a discussion of related work in Section IX. Finally,
our conclusion and our future work are given in Section X.
II. PROBLEM DEFINITION AND SYSTEM DESCRIPTION
Our research reported here aims at automation of elasticity
of a key-value store deployed in a Cloud environment. We
want to automate the management of elastic storage instances
depending on workload. a Cloud environment allows the
system that is running in the Cloud to scale up and down in
few minutes in response to load changes. In-time and proper
decisions regarding the size of the system in response to the
changes in the workload is very critical when it comes to
enterprise and scalable applications.
In order to achieve elasticity of a key-value store in the
Cloud, we adopt a control theoretic approach to designing a
feedback controller that automatically increases and decreases
the number of storage instances in response to changes in
workload in order to meet SLOs under high load and to reduce
costs under low load. The overall architecture of the key-value
store with the feedback controller is depicted in Fig. 1.
Fig. 1.
Architecture of the Elastic Storage with feedback control of elasticity
End-users request ﬁles that are located in the storage Cloud
nodes (instances). All the requests arrive at the Elastic Load
Balancer (ELB) that sits in front of all storage instances. The
Elastic Load Balancer decides to which instance the request
should be dispatched. In order to do this, the Elastic Load
Balancer tracks the CPU load and the number of requests sent
previously to each instance and based on that it determines the
next node that can serve the incoming request. In addition to
the performance metrics that it tracks, ELB has the ﬁle tables
with information about ﬁle replica locations since more than
one instance can have a replica of the same ﬁle in order to
satisfy the replication degree.
The Cloud Provider (Fig. 1) is an entity that is responsi-
ble for launching a new storage instance or terminating the
existing one on requests of the Elasticity Controller.
Our system contains the Elasticity Controller, which is
responsible for controlling the number of storage instances
in the Cloud in order to achieve the desired SLO (e.g.,
download time). The Controller monitors the performance of
the storage instances (and indirectly the quality of service)
and issues requests to scale the number of instances up and
down in response to changes in the measured quality of service
(compared to the desired SLO). These changes are caused
by changes in the workload, which is not controllable and
is considered to be a disturbance in terms of control theory.
In the following two sections, we provide the relevant
background and present steps of the design of the controller
including system identiﬁcation [2].
III. APPROACHES TO SYSTEM IDENTIFICATION
In this section, we present methods of system identiﬁcation,
which is the most important step in the design of a controller.
It deals with how to construct a model to identify a system.
System identiﬁcation allows us to build a mathematical model
of a dynamic system based on measured data. The constructed
model contains a number of transfer functions, which deﬁne
how the output depends on past/present inputs and outputs.
Based on the transfer functions and desired properties and
objectives, a control law is chosen. System identiﬁcation can
be performed using one of the following approaches.
First principle approach is one of the de facto approaches
to identiﬁcation of computer systems [3]. It can be considered
as a consequence of the queue relationship. The ﬁrst principle
approach is developed based on knowledge of how a system
operates. For example, this approach has been used in some
studies and systems like [4], [5], [6], [7], [8], [9], [10], [11],
[12], [13], [14]. However, there are some shortcomings with
this approach that have been stated in [2]. It is very difﬁcult
to construct a ﬁrst principle model for a complex system.
Since this approach considers detailed information about the
target systems, it requires an ongoing maintenance by experts.
Furthermore, this approach does not address model validation.
Empirical approach starts by identifying the input and out-
put parameters like the ﬁrst principle approach. But rather than
using a transfer function, an autoregressive moving average
(ARMA) model is built and common statistical techniques
are employed to estimate the ARMA parameters [2]. This
approach is also known as Black Box [3]; and it requires
minimal knowledge of the system. Most of the systems in our
studies have employed a black-box approach rather than a ﬁrst-
principle approach for system identiﬁcation, e.g., [2], [15],
[16], [17], [18], [19]. This is mainly because the relationship
between inputs and outputs of the system is complex enough
so that the ﬁrst-principle system identiﬁcation cannot be done
easily. One of the empirical approaches is to build a State-
Space Model, which requires more knowledge of the internals
of the system. We use the state-space model approach for
system identiﬁcation as described in the next section.
IV. STATE-SPACE MODEL OF THE ELASTIC KEY-VALUE
STORE
A state-space model provides a scalable approach to model
systems with a large number of inputs and outputs [3]. The
state-space model allows dealing with higher order target
systems without a ﬁrst-order approximation. Since the studied
system executes in a Cloud environment, which is complex and
19
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

dynamic in a sense of dynamic set of VMs and applications,
we have chosen state-space modeling as the system identiﬁca-
tion approach. Another beneﬁt of using the state-space model
is that it can be extended easily. Suppose that after the model is
built, we ﬁnd more parameters to control the system. This can
be accommodated by the state-space model without affecting
the characteristic equations as shown later in Section VI where
we summarize a generic approach for system identiﬁcation and
controller design
The main idea of the state-space approach is to characterize
how the system operates in terms of one or more variables.
These variables may not be directly measurable. However, they
can be sufﬁcient in expressing the dynamics of the system.
These variables are called state variables.
A. State Variables and the State-Space Model
In order to deﬁne the state variables for our system, ﬁrst
we need to deﬁne the inputs and measured outputs since the
state variables are related to them. In particular, state variables
can be used to obtain the measured output. It is possible for
a state variable to be a measured output like it is in our case.
In our case, the system input is the number of nodes
(instances) denoted by NN(k) at time k. The measured system
outputs (and hence state variables) are the following:
• average CPU load CPU(k): the average CPU load of all
instances currently running in the Cloud during the time
interval [k − 1, k];
• interval total cost TC(k): the total cost of all instances
during the time interval [k − 1, k];
• average response time RT(k): the average time required
to start a download during the time interval [k − 1, k].
The value of each state variable at time k is denoted by
x1(k), x2(k) and x3(k). The offset value for input is ¯u1(k) =
NN(k) − c
NN, where c
NN is the operating point for the input.
The offset values for outputs are
¯y1(k)
=
CPU(k) − d
CPU
(1)
¯y2(k)
=
TC(k) − c
TC
(2)
¯y3(k)
=
RT(k) − c
RT
(3)
where d
CPU, c
TC and c
RT are operating points for corresponding
outputs.
The state-space model uses state variables in two ways [3].
First, it uses state variables to describe the dynamics of the
system and how x(k + 1) can be obtained from x(k). Second,
it obtains the measured output y(k) from state x(k).
State-space dynamics for a system with n states is described
as follows
x(k + 1)
=
Ax(k) + Bu(k)
(4)
y(k)
=
Cx(k)
(5)
where x(k) is a n × 1 vector of state variables, A is a n × n
matrix, B is a n × mI matrix, u(k) is a mI × 1 vector of
inputs, y is a mO × 1 vector of outputs and C is a mO × n
matrix.
According to equations 4 and 5, we can describe dynamics
of our system as follows:
• Average CPU Load (CPU) is dependant on the number
of nodes in the system and previous CPU load, thus it
becomes
x1(k + 1) = CPU(k + 1) =
a11CPU(k)+
(6)
b11NN(k)+
0 × TC(k) + 0 × RT(k)
• Total Cost (TC) is dependant on the number of nodes in
the system (the more nodes we have, the more money we
should pay) and the previous TC, hence it becomes
x2(k + 1) = TC(k + 1) =
a21TC(k)+
(7)
b21NN(k)+
0 × RT(k) + 0 × CPU(k)
• Average Response Time (RT) is dependant on the number
of nodes in the system and the CPU load, so it is
x3(k + 1) = RT(k + 1) =
a31CPU(k) + a33RT(k)+
(8)
b31NN(k)+
0 × TC(k)
In each equation (6, 7, 8) terms with zero factor include
those state variables that do not affect the corresponding state
variable deﬁnition. Thus their coefﬁcient is zero. This is to
ensure that there is no relation between those state variables
or the relation is negligible and can be ignored. Their presence
in the equations is for the sake of clarity and completeness. In
order to prove that there is no relation or that it is negligible
one should do a sensitivity analysis to investigate this, but it
is out of the scope of this paper.
The output for the system at each time point k is equivalent
to the corresponding state variable:
y(k) = I3x(k)
(9)
The outputs are the same as the internal state of the systems
at each time. That is why the matrix C is an identity matrix,
i.e., a diagonal matrix of 1’s. The matrices of coefﬁcients are:
A =


a11
0
0
0
a22
0
a31
0
a33


(10)
B =


b11
b21
b31


(11)
C =


1
0
0
0
1
0
0
0
1


(12)
20
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

B. Parameter Estimation
In Section IV-A, we have derived the State-Space model
(Equations 6-12) that describes the dynamics of an elastic key-
value store. There are two matrices A and B that contain the
unknown coefﬁcients for the equations 6-8. In order to use
the model to design the controller we need to estimate the
coefﬁcient matrices A and B.
Parameter estimation is done using experimental data. In
this research, we use data obtained from the simulation frame-
work EStoreSim that we have built, rather than from a real
system, because the major focus is on controller design and the
simulation framework allows us to experiment with different
controllers. We have implemented a simulation framework
EStoreSim (described in Section VII) of a Cloud system.
Using the framework we can obtain experimental data for
system identiﬁcation.
To get the data, we have designed and run an experiment,
in which we feed the system with an input signal and observe
the output and internal state variable periodically. We change
the input (which is the number of nodes in the system) by
increasing it from a small number of nodes a to a large
number of nodes b and then back from b to a in a ﬁxed period
of time, and measure outputs (CPU load, cost, and response
time). In this way, we ensure the complete coverage of the
output signals in their operating regions by the input signal
(the number of nodes). Load should be generated according to
an arbitrary periodic function to issue a number of downloads
per seconds. The period of the function should be chosen such
that at least one period is observed during the time of changing
the input between [a, b].
For example, using the modeler component of our frame-
work EStoreSim (Section VII), we scale up the number of
nodes from 2 to 10 and then scale down from 10 to 2. Every
225 seconds a new node is either added or removed (depending
on whether we scale up or down); sampling of training data
(measuring outputs) is performed every 10 seconds.
When identifying the system, the workload is modeled as a
stream of requests issued by the request generator component
where the time interval between two consecutive requests
forms a triangle signal in the range [1, 10] seconds as follows:
the ﬁrst request is issued after 10 seconds, the second after 9
seconds, etc. The requests are received by the load balancer
component in the Cloud provider component. After each
scaling up/down the system will experience 2 triangle loads
of requests between 1 to 10 seconds. The time needed to
experience 2 triangles is 4 P10
i=1 i, which is 220 seconds. That
is why we have selected 225 seconds as the action time.
Once training data are collected, they can be used to
compute the matrices A and B using the multiple linear
regression method. We use the regress(y,X) function of
Matlab to calculate matrices:
A =


0.9
0
0
0
0.724
0
5.927
0
0.295


B =


2.3003
0.0147
77.8759


V. CONTROLLER DESIGN
In this section, we describe how the feedback controller
for the elastic storage deployed in a Cloud environment is
designed. The controller design starts by choosing an appro-
priate controller architecture according to system properties.
There are three common architectures for state-space feedback
control, namely, Static State Feedback, Precompensated Static
Control and Dynamic State Feedback. A good comparison
between these architectures can be found in [3]. A close
investigation in this comparison reveals that dynamic state
feedback control is more suitable for a Cloud system since
it has disturbance rejection that the other two architectures
lack. Disturbance (in terms of control theory) is observed in a
Cloud in the form of changes in the set of virtual machines and
workload of Cloud applications. Thus we choose dynamic state
feedback control as our controller architecture for autonomic
management of elasticity.
A. Dynamic State Feedback
Dynamic state feedback can be viewed as a State-Space
analogous to PI (Proportional Integral) control that has good
disturbance rejection properties. It both tracks the reference
input and rejects disturbances. We need to augment the state
vector with the control error e(k) = r − y(k) where r is
the reference input. We use integrated control error, which
describes the accumulated control error. The integrated control
error is denoted by xI(k) and computed as
xI(k + 1) = xI(k) + e(k)
The augmented state vector is
 x(k)
xI(k)

. The control law is
u(k) = −

Kp
KI
  x(k)
xI(k)

(13)
where Kp is the feedback gain for x(k) and KI is the gain
associated with xI(k).
B. LQR Controller Design
An approach to controller design is to focus on the trade-
off between control effort and control errors. The control error
is determined by the squared values of state variables, which
are normally the difference from their operating points. The
control effort is quantiﬁed by the square of u(k), which is
the offset of the control input from the operating point. By
minimizing control errors we improve accuracy and reduce
both settling times and overshoot and by minimizing control
effort, system sensitivity to noise is reduced.
Least Quadratic Regulation (LQR) design problem is
parametrized in terms of relative cost of control effort (deﬁned
by matrix R) and control errors (deﬁned by matrix Q). The
quadratic cost function to minimize is the following [3]:
21
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

J = 1
2
∞
X
k=0

x⊤(k)Qx(k) + u⊤(k)Ru(k)

(14)
where Q must be positive semideﬁnite (eigenvalues of Q must
be nonnegative) and R must be positive deﬁnite (eigenvalues
of R must be positive) in order for J to be nonnegative.
After selecting the weighting matrices Q and R, the con-
troller gains K can be computed using the Matlab dlqr
function that takes as parameters the matrices A, B, Q,
and R. The performance of the system with the designed
controller can be evaluated by simulation. If the performance
is not appropriate, the designer can select new Q and R and
recompute the vector gain K.
In our example, the matrices Q and R are deﬁned as follows:
Q =


100
0
0
0
1
0
0
0
1


R =
1
We have given 100 to the element that corresponds to
CPU Load to emphasize that this state variable is more
important compared to the others. One can give a high weight
to total cost TC to trade off cost for performance. Using
the Matlab dlqr function we compute the controller gains
K = dlqr(A, B, Q, R). For example, using the results
of system identiﬁcation in the example in Section IV-B, the
controller gains (corresponding to the measured outputs of the
elastic storage, CPU, TC, and RT) are:
K =
0.134
1.470162e − 06
0.00318
C. Fuzzy Controller
The main purpose in using an additional fuzzy controller is
to optimize the control input produced by the Dynamic State
Feedback Controller that we have designed in Section V-B. A
fuzzy controller uses heuristic rules that deﬁne when and what
actions the controller should take. The output of the Dynamic
State Feedback Controller (control input) is redirected together
with measured outputs to the fuzzy controller, which decides
if the control input should affect the system or not. The overall
architecture for controllers is demonstrated in Fig. 2.
There is one important case that the dynamic state feedback
controller cannot act accordingly. Let us assume that there are
some instances with high CPU load. Since the average is high,
the controller will issue a control request to add a number of
new instances. The new instances will be launched and will
start to serve requests. But at the beginning of their life cycle
they have low CPU load, thus the average CPU load that is
reported back to the controller can be low. The controller then
assumes that the CPU load has dropped, and it requests to
remove some nodes.
A closer look at the CPU loads reveals that we can not judge
the system state by only the average CPU load. Hence the
fuzzy controller also takes into account the standard deviation
Fig. 2.
Controllers Architecture
of CPU load. In this way, if the feedback controller gives
an order to reduce the number of nodes when there is high
standard deviation for CPU loads, the fuzzy controller will not
allow this control input to affect the system, thus reducing the
risk of unexpected results and confusions for the controller
that may cause oscillations. This will lead to a more stable
environment without so many unnecessary ﬂuctuations.
D. Stability Analysis of Controller
A system is called stable if all bounded inputs produce
bounded outputs. The BIBO theorem [3] states that for a
system to be stable, its poles must lie within the unit circle
(have magnitude less than 1). In order to calculate the poles
for the controller we need to get the eigenvalues of matrix
A that are 0.2951, 0.9 and 0.7247. As it is obvious from the
values, all of the poles reside within the unit circle thus the
controller is stable.
VI. SUMMARY OF STEPS OF CONTROLLER DESIGN
This section summarizes the steps needed to design a
controller for an elastic storage in a Cloud environment.
The steps described below are general enough to be used
to design a controller for an elastic service in a Cloud. The
design process consists of two stages: system identiﬁcation and
controller design. The design steps are as follows: the system
identiﬁcation stage includes steps 1-9; and the remaining steps
(10-12) belong to the stage of the controller design.
1) Study system behavior in order to identify the inputs
and outputs of the system.
2) Place inputs and outputs in u(k) and y(k) vectors
respectively.
3) Select n system outputs that you want to control and
place them in state variable vector x. The outputs should
be related to SLOs and performance metrics.
4) Select m system inputs that you will use to control.
These system inputs will be the outputs of your con-
troller. The system outputs should depend on the system
inputs These inputs should have the highest impact in
your system. In some systems there might be only one
22
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

input that has high impact whereas in other systems there
might be several inputs that together have high impact.
To assess the impact you might need to do sensitivity
analysis.
5) Deﬁne state variables that describe the dynamics of
the system. State variables can be equivalent to system
outputs selected in step 3. Each state variable can depend
on one or more other state variables and system inputs.
Find the relation between the next value for a state
variable to other state variables and system inputs and
construct the characteristic equations as follows (see also
Equation 4).
x1(k + 1) = a11x1(k) + . . . + a1nxn(k)
+b11u1(k) + . . . + b1mum(k)
x2(k + 1) = a21x1(k) + . . . + a2nxn(k)
+b21u1(k) + . . . + b2mum(k)
...
xn(k + 1) = an1x1(k) + . . . + annxn(k)
+bn1u1(k) + . . . + bnmum(k)
6) Place coefﬁcients from the previous equations into two
matrices A and B. Some of the coefﬁcients can be zero:
An×n =


a11
. . .
a1n
...
...
...
an1
. . .
ann


Bn×m =


b11
. . .
b1m
...
...
...
bn1
. . .
bnm


7) In order to simplify the design of controller, one can
assume that outputs of the systems are equal to state
variables, thus matrix C is an identity matrix:
Cn×n =


1
0
. . .
0
0
1
. . .
0
...
...
...
...
0
0
. . .
1


8) Design an experiment, in which the system is fed with
its inputs. Inputs in the experiment should be changed
in such a way that they cover their ranges at least
one time. A range for an input is the interval that the
values of the input will most likely belong to when the
system operates. The selection of ranges can be based on
industry’s best practices. All inputs and outputs should
be measured periodically with a ﬁxed time interval T .
Store collected data for each equation in a separate ﬁle
called xi.
9) In Matlab, for each ﬁle xi, load the ﬁle and extract each
column of data in a separate matrix. Use the function
regress to calculate the coefﬁcients. Repeat this for
every ﬁle. At the end you will have all the coefﬁcients
that are required for matrices A and B.
10) Choose a controller architecture for feedback control:
such as dynamic state feedback control, which is, in
our opinion, more appropriate for a Cloud based elastic
service (as discussed in Section V).
11) Construct matrices Q and R as described in Section V-B.
Remember to put high weights in matrix Q for those
state variables that are of more importance.
12) Use the Matlab function dlqr with matrices A, B, Q
and R as parameters to calculate the vector K of con-
troller gains. Perform stability analysis of the controller
checking whether its poles reside within the unit circle
(Section V-D).
VII. ESTORESIM: ELASTIC KEY-VALUE STORE
SIMULATOR
We have implemented a simulation framework, which we
call EStoreSim, that allows developers to simulate an elastic
key-value store in a Cloud environment and to experiment
with different controllers. We have selected Kompics as the
implementation tool. Kompics [20] is a message-passing com-
ponent model for building distributed systems using event-
driven programming. Kompics components are reactive state
machines that execute concurrently and communicate by pass-
ing data-carrying typed events through typed bidirectional
ports connected by channels. For further information please
refer to the Kompics programming manual and the tutorial on
its web site [20].
Implementation is done in Java and Scala languages [21]
and the source is publicly available at [22]. The overall
architecture of EStoreSim is shown in Fig. 3. The simulator
includes the following components.
Fig. 3.
Overall Architecture of the EStoreSim Simulation Framework
Cloud Instance Component represents an entire storage
instance within a Cloud. The component architecture for
instance is shown in Fig. 4.
Cloud Provider Component represents an important unit
in the implementation. It is the heart of a simulated Cloud
computing infrastructure and provides vital services to manage
and administer the nodes (VM instances) within the Cloud.
The Cloud provider component architecture is shown in Fig. 5.
Elasticity Controller represents the controller that can
connect to the Cloud provider and retrieve information about
the current nodes in the system. The main responsibility of
the controller component is to manage the number of nodes
currently running in the Cloud. In other words, it attempts
to optimize the cost and satisfy some SLO parameters. The
overall component architecture is shown in Fig. 6.
For further information on EStoreSim please refer to [22].
23
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

Fig. 4.
Cloud Instance Component
Fig. 5.
Cloud Provider Component
Fig. 6.
Elasticity Controller Component
VIII. EXPERIMENTS
We have conducted a number of simulation experiments
using EStoreSim in order to evaluate how the use of an
elasticity controller in a Cloud-based key-value store improves
the operation of the store by reducing the cost of Cloud
resources and the number of SLO violations. The baseline
in our experiments is a non-elastic key-value store, i.e., a key-
value store without the elasticity controller.
For evaluation experiments, we have implemented a dy-
namic state feedback controller with the parameters (controller
gains) calculated according to the controller design steps
(Section V-B). The controller is given reference values of the
system outputs that correspond to SLO requirements. Values
of system outputs (average CPU load CPU, Total Cost TC, and
average Response Time RT) are fed back into the controller
periodically. When the controller gets the values, it calculates
and places the next value of the number of nodes NN on its
output. The controller output is a real number that should be
rounded to a natural integer. We round it down in order to
save the total cost the Cloud generates. One can assume two
boundaries, which are deﬁned as follows:
• L (Lower boundary): the minimum number of instances
that should exist in the Cloud at all times;
• U (Upper boundary): the maximum number of instances
that is allowed to exist in the Cloud at all times.
Hence if the value of controller output is smaller than L
or greater than U, then the value should be discarded. If the
calculated output of the controller is Θ, the number of nodes
is deﬁned as follows:
NN =



L
if
Θ ⩽ L
Θ
if
L < Θ < U
U
if
U ⩽ Θ
(15)
If the number of current nodes in the system is NN′ and the
control input (output of the controller) is NN, then the next
control action is determined as follows:
Next action =



scale up with NN − NN′ nodes
if
NN′ < NN
scale down with NN′ − NN nodes
if
NN < NN′
no action
otherwise
(16)
We have conducted two series of experiments to prove our
approach to elasticity control. By these experiments we check
whether the elasticity feedback controller operates as expected.
In the ﬁrst series (which we call SLO Experiment), the load
is increased to a higher level. This increase is expected to
cause SLO violation that is detected by the feedback controller,
which adds nodes in order to meet SLO under high load.
In the second series (which we call Cost Experiment), the
load decreases to a lower level. This causes the controller
to release nodes in order to save cost under low load. The
instance conﬁguration for these experiments are as follows:
• CPU frequency: 2 GHz;
• Memory: 8 GB;
• Bandwidth: 2 MB/s;
• Number of simultaneous downloads: 70.
There are 10 data blocks in the experiments with sizes between
1 to 5 MB. Note that the same conﬁguration is used in the
system identiﬁcation experiments.
A. SLO Experiment: Increasing Load
In this series we conducted two experiments: one with
controller and another without controller. In the results and
ﬁgures presented below, they are denoted by w/controller
and w/o controller, respectively. Each experiment starts
with three warmed up instances. By a warmed up instance we
mean that in this instance each data block is requested at least
once thus it resides in the memory of this instance.
Workload that is used for this experiment is of two levels:
normal and high. Under the normal load the time interval be-
tween consecutive requests is selected from a uniform random
distribution in the range [10, 15] seconds that corresponds to
an average request rate of 4.8 requests per minute. Under the
high load the time interval between consecutive requests is
selected from a uniform random distribution in the range [1,
5] seconds that corresponds to an average request rate of 20
requests per minute. The experiment starts with normal load
and after 500 seconds the workload increases to the high level.
This is shown in Fig. 7.
Sensing of instance output is done every 25 seconds. In the
case of controller, actuation is performed every 100 seconds.
Thus there are 4 sets of measured data at each actuation time
that the controller should consider. In order to calculate values
of the system output, the controller computes averages of data
24
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

Fig. 7.
SLO Experiment Workload
TABLE I
SLO VIOLATIONS
SLO Parameter Violation (%)
w/ Controller
w/o Controller
CPU Load
17.94
72.28
Response Time
2.12
7.073
Bandwidth
35.89
74.69
sets. The duration of each experiment is 2000 seconds with
warm up of 100 seconds. SLO requirements are as follows:
• Average CPU Load: ⩽ 55%
• Response Time: ⩽ 1, 5 seconds
• Average Bandwidth per download: > 200000 B/s
For each experiment the percentages of SLO violations are
calculated for each aforementioned SLO requirement based on
Equation 17. The result is shown in Table I.
SLO Violations = 100% ×
Number of SLO Violations
Total Number of SLO Checks
(17)
Checking of SLO is done at each estimate (sensing) of the
Average CPU Load and Average Bandwidth per download and
each estimate of Response Time.
This experiment gives us interesting results that are dis-
cussed in this section. NL and HL in ﬁgures 8-12 indicate
periods of Normal Load and High Load respectively.
Fig. 8 depicts the Average CPU Load for the aforementioned
experiments. The Average CPU Load is the average of all
nodes’ CPU Loads at each time the sensing is performed. As
one can see in Fig. 8, CPU loads for the experiment with the
controller is generally lower than the same experiment without
the controller. This is due to the controller that launches new
instances under high workloads causing a huge drop in average
CPU Load.
Fig. 9 depicts the Average Response Time for the experi-
ments. By response time we mean the time that it takes for
an instance to respond to a request that download is started
and not the actual download time. As it is seen from the
diagram, the average response time for the experiment with
the controller is generally lower than the experiment without
controller. This is because in case of having a ﬁxed number of
instances (3 in this experiment), there would be congestion by
0
200
400
600
800
1000
1200
1400
1600
1800
2000
0
20
40
60
80
100
120
Average CPU Load
Time (s)
Average CPU Load (%)
 
 
↑SLA Requirement < 55%
NL
HL
w/ controller
w/o controller
Fig. 8.
SLO Experiment - Average CPU Load
w/ controller
w/o controller
Total Cost ($)
14.4528
8.6779
TABLE II
TOTAL COST FOR EACH SLO EXPERIMENT
the number of requests an instance can process. This increases
the responsivity of an instance. However, in the case that the
controller launches new instances, no instance will actually go
under high number of requests.
0
200
400
600
800
1000
1200
1400
1600
1800
2000
100
200
300
400
500
600
700
800
900
1000
1100
Average Response Time
Time (s)
Average Response Time
 
 
NL
HL
w/ controller
w/o controller
Fig. 9.
SLO Experiment - Average Response Time
Fig 10 shows the total cost for the experiments. Interval
total cost means that total cost is calculated for each interval
in which the senses are done. As can be observed from the
diagram, the interval total cost for the experiment with the
controller is much higher than the experiment without the
controller. This is because launching new instances will cost
more money than having a ﬁxed number of instances available
in the Cloud. This experiment has high load of requests for the
system in which the controller is more likely to scale up and
resides in that mood than to scale down. It should be noted
that costs are computed according to Amazon EC2 price list.
Calculated total cost for each experiment is given in Table II.
Fig. 11 depicts the Average bandwidth per download. If
an instance has a bandwidth of 4 Mb/s and has two current
downloads running, the bandwidth per download is 2 Mb/s. As
25
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

0
200
400
600
800
1000
1200
1400
1600
1800
2000
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Interval Total Cost
Time (s)
Interval Total Cost ($)
 
 
NL
HL
w/ controller
w/o controller
Fig. 10.
SLO Experiment - Interval Total Cost
can be seen from the diagram, the experiment with controller
shows signiﬁcantly higher bandwidth per download. This is
mainly because the instances receive less number of requests
and bandwidth is divided among less requests also. This will
end up having higher bandwidth available on each instance.
0
200
400
600
800
1000
1200
1400
1600
1800
2000
0
2
4
6
8
10
12
14
16
18
x 10
5
Average Bandwidth per download
Time (s)
Average Bandwidth (B/s)
 
 
↓SLA Requirement > 200 KB/s
NL
HL
w/ controller
w/o controller
Fig. 11.
SLO Experiment - Average Bandwidth per download (B/s)
Fig 12 shows the number of nodes for each experiment.
As we discussed earlier the number of nodes is constant for
experiment without controller. However, for the experiment
with the controller the number of nodes is changed over time
hence the SLO requirements can be met.
B. Cost Experiment: Decreasing Load
The purpose of this series of experiments is to show that the
controller can save the total cost by releasing instances when
the load is low. Each experiment in this series starts with 7
instances. The duration of the experiment is 2000 seconds.
In this series we use different workloads of two levels: high
and low. In the high load the time interval between consecutive
requests is selected from a uniform random distribution in the
range [1, 3] seconds that corresponds to a request rate of 30
requests per minute. In the low load the time interval between
consecutive requests is selected from a uniform random dis-
tribution in the range [15, 20] seconds that corresponds to a
0
200
400
600
800
1000
1200
1400
1600
1800
2000
3
4
5
6
7
8
9
Number of Nodes
Time (s)
Number of Nodes
 
 
NL
HL
w/ controller
w/o controller
Fig. 12.
SLO Experiment - Number of Nodes
w/ controller
w/o controller
Total Cost ($)
10.509
16.5001
TABLE III
TOTAL COST FOR COST EXPERIMENT
request rate of about 3.4 requests per minute. Unlike the SLO
experiment, the cost experiment starts with a high load, which
changes to a low load after 500 seconds as shown in Fig. 13.
Fig. 13.
Cost Experiment workload
The result of the cost experiment shown in Table III is
interesting. It is observed that the total cost in the experiment
with the controller is actually lower than the total cost in
the experiment without the controller unlike in the SLO
experiment. This is because the controller removes instances
under low load and that results in cost savings. The reason
that this experiment has lower cost than the previous one is
that L (lower bound on number of nodes) is not equal to the
initial number of nodes and it is smaller. Hence controller can
scale down the number of nodes to L.
IX. RELATED WORK
There are many projects that use elements of control theory
for providing automated control of computing systems includ-
ing Cloud-based services [2], [7], [8], [9], [12], [15], [16],
[17], [18], [19], [23]. Here we consider two related pieces of
work [17], [23], which are the closest to our research aiming
at automation of elasticity of storage services.
The SCADS Director proposed in [23] is a control frame-
work that reconﬁgures a storage system at run time in
response to workload ﬂuctuations. Reconﬁguration includes
26
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

adding/removing servers, redistributing and replicating data
between servers. The SCADS Director employs the Model-
Predictive Control technique to predict system performance for
the given workload using a performance model of the system
and make control decisions based on prediction. Performance
modeling is performed by statistical machine learning.
Lim et al. [17] have proposed a feedback controller for elas-
tic storage in Cloud environment. The controller consists of
three components: Horizontal Scale Controller responsible for
scaling the storage; Data Rebalancer Controller that controls
data transfer for rebalancing after scaling up/down; and the
State Machine that coordinates the actions of the controllers in
order to avoid wrong control decisions caused by interference
of rebalancing with applications and sensor measurements.
To our knowledge both aforementioned projects do not
explicitly use cost as a controller input (state variable, system
output) in the controller design. In contrast, we use state-space
feedback control and explicitly include the total cost of Cloud
instances as a state (system output) variable in the state-space
model (when identifying the system) and as a controller input
in the controller design (when determining controller gains).
This allows us to use a desired value of cost in addition to
the SLO requirements to automatically control the scale of the
storage by trading off performance for cost.
X. CONCLUSION AND FUTURE WORK
Elasticity in Cloud computing is an ability of a system to
scale up and down (request and release resources) in response
to changes in its environment and workload. Elasticity pro-
vides an opportunity to scale up under high workload and
to scale down under low workload to reduce the total cost
for the system while meeting SLOs. We have presented our
experience in designing an elasticity controller for a key-
value store in a Cloud environment and described the steps
in designing it including system identiﬁcation and controller
design. The controller allows the system to automatically scale
the amount of resources while meeting performance SLO,
in order to reduce SLO violations and the total cost for
the provided service. We also introduced our open source
simulation framework (EStoreSim) for Cloud systems that
allows to experiment with different controllers and work-
loads. We have conducted two series of experiments using
EStoreSim. Experiments have shown the feasibility of our
approach to automate elasticity control of a key-value store in a
Cloud using state-space feedback control. We believe that this
approach can be used to automate elasticity of other Cloud-
based services.
In our future work, we will study other controller ar-
chitectures such as model predictive control, and conduct
experiments using real-world traces. We will also research on
using feedback control for other elastic Cloud based services.
ACKNOWLEDGMENTS
This research is supported by the End-to-End Clouds project
funded by the Swedish Foundation for Strategic Research, the
Complex Service Systems focus project, a part of the ICT-
TNG Strategic Research Area initiative at the KTH Royal
Institute of Technology, and by the Testbed for E2E Clouds
RCLD-project funded by EIT ICT Labs.
REFERENCES
[1] P. Horn, “Autonomic computing: IBM’s perspective on the state of
information technology,” IBM, Tech. Rep., October 2001.
[2] S. Parekh, N. Gandhi, J. Hellerstein, D. Tilbury, T. Jayram, and J. Bigus,
“Using control theory to achieve service level objectives in performance
management,” Real-Time Syst., vol. 23, pp. 127–141, July 2002.
[3] J. L. Hellerstein, Y. Diao, S. Parekh, and D. M. Tilbury, Feedback
Control of Computing Systems.
Wiley-IEEE Press, September 2004.
[4] D. Chiu and R. Jain, “Analysis of the increase and decrease algorithms
for congestion avoidance in computer networks,” Computer Networks
and ISDN, vol. 17, no. 1, pp. 1–14, 1989.
[5] S. Keshav, “A control-theoretic approach to ﬂow control,” SIGCOMM
Comput. Commun. Rev., vol. 21, pp. 3–15, August 1991.
[6] B. Li and K. Nahrstedt, “A control-based middleware framework
for quality-of-service adaptations,” Selected Areas in Communications,
IEEE Journal on, vol. 17, no. 9, pp. 1632 –1650, sep 1999.
[7] A. Kamra, V. Misra, and E. M. Nahum, “Yaksha: A self-tuning controller
for managing the performance of 3-tiered web sites,” In International
Workshop on Quality of Service (IWQoS, pp. 47–56, 2004.
[8] T. F. Abdelzaher, K. G. Shin, and N. Bhatti, “Performance guarantees
for web server end-systems: a control-theoretical approach,” IEEE
Transactions on Parallel and Distributed Systems, vol. 13, no. 1, pp.
80–96, August 2002.
[9] A. Robertson, B. Wittenmark, and M. Kihl, “Analysis and design
of admission control in web-server systems,” in American Control
Conference. Proceedings of the 2003, vol. 1, june 2003, pp. 254–259.
[10] T. Abdelzaher and N. Bhatti, “Web content adaptation to improve server
overload behavior,” in WWW8 / Computer Networks, 1999, pp. 1563–
1577.
[11] B. Li and K. Nahrstedt, “A control theoretical model for quality of
service adaptations,” in In Proceedings of Sixth International Workshop
on Quality of Service, 1998, pp. 145–153.
[12] H. D. Lee, Y. J. Nam, and C. Park, “Regulating i/o performance of shared
storage with a control theoretical approach,” NASA/IEEE conference on
Mass Storage Systems and Technologies (MSST), April 2004.
[13] S. Mascolo, “Classical control theory for congestion avoidance in high-
speed internet,” in Decision and Control, 1999. Proceedings of the 38th
IEEE Conference on, vol. 3, 1999, pp. 2709 –2714 vol.3.
[14] D. C. Steere, A. Goel, J. Gruenberg, D. McNamee, C. Pu, and J. Walpole,
“A feedback-driven proportion allocator for real-rate scheduling,” in
Proceedings of the third symposium on Operating systems design
and implementation, ser. OSDI ’99.
Berkeley, CA, USA: USENIX
Association, 1999, pp. 145–158.
[15] M. Karlsson, C. Karamanolis, and X. Zhu, “Triage: Performance
isolation and differentiation for storage systems,” in In International
Workshop on Quality of Service (IWQoS), 2004, pp. 67–74.
[16] N. Gandhi, D. Tilbury, Y. Diao, J. Hellerstein, and S. Parekh, “Mimo
control of an apache web server: modeling and controller design,” in
American Control Conference, 2002. Proceedings of the 2002, vol. 6,
2002, pp. 4922 – 4927 vol.6.
[17] H. C. Lim, S. Babu, and J. S. Chase, “Automated control for elastic
storage,” International Conf. on Autonomic Computing, pp. 1–10, 2010.
[18] P. Padala, K.-Y. Hou, K. G. Shin, X. Zhu, M. Uysal, Z. Wang, S. Singhal,
and A. Merchant, “Automated control of multiple virtualized resources,”
in 4th ACM European conf. on Computer systems, 2009, pp. 13–26.
[19] C. Lu, T. Abdelzaber, J. Stankovic, and S. Son, “A feedback control
approach for guaranteeing relative delays in web servers,” in Real-Time
Technology and Applications Symposium, 2001. Proceedings. Seventh
IEEE, 2001, pp. 51–62.
[20] “Kompics,” http://kompics.sics.se/, accessed Oct 2011.
[21] “Scala language,” http://www.scala-lang.org/, accessed Oct 2011.
[22] “EStoreSim: Elastic storage simulation framework,” https://github.com/
amir343/ElasticStorage, accessed Oct 2011.
[23] B. Trushkowsky, P. Bod´ık, A. Fox, M. J. Franklin, M. I. Jordan, and
D. A. Patterson, “The scads director: scaling a distributed storage system
under stringent performance requirements,” in Proceedings of the 9th
USENIX conference on File and stroage technologies, ser. FAST’11.
Berkeley, CA, USA: USENIX Association, 2011.
27
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-187-8
ICAS 2012 : The Eighth International Conference on Autonomic and Autonomous Systems

