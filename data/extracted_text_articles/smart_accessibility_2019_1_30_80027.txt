 
Preliminary Experiments on Driver Assistance System in Remote Control 
-Effects of Communication Delays, Video Resolution and Frequency- 
Kohei Kadowaki 
Dept. of Applied 
Electronics 
Tokyo University of 
Science 
Tokyo, Japan 
e-mail: 
8118513@ed.tus.ac.jp 
Naohisa Hashimoto 
Robot Innovation 
Research Center 
National Institute of 
AIST 
Tsukuba, Japan 
e-mail: naohisa-
hashimoto@aist.go.jp 
Simon Thompson 
/Yusuke Takinami 
Robot Inmovation 
Research Center 
National Institute of 
AIST 
Tsukuba, Japan 
Shin Kato 
Intelligent System 
Research Institute 
National Institute of 
AIST 
Tsukuba, Japan 
e-mail: Shin-
kato@aist.go.jp 
Makoto Itami 
Dept. of Applied 
Electronics 
Tokyo University of 
Science 
Tokyo, Japan 
e-mail: 
itami@te.noda.tus.ac.jp 
 
 
Abstract— Automated vehicles are expected to solve traffic 
issues. We proposed a prototype of remote type automated vehicle 
system. However, the lack of information due to the limited 
number of cameras and signal delay makes the system difficult to 
control. To improve accurate remote control and compensate the 
delay, a method of trajectory prediction with changing fps or 
resolution is proposed. This demonstration paper introduces the 
automated vehicle system and explains the system configuration, 
communication and results. The experiment in this paper is 
measuring the delay at each fps and resolution. 
Keywords—Smart mobility; Automated Vehicles; Remote 
Control System; Vehicle to Infrastructure; Communication 
Network; Intelligent Transport System. 
I. INTRODUCTION 
There are researches in areas of intelligent vehicles in a 
roadway environment, and in particular in automated vehicles 
[1]. Introduction of automated vehicles for smart city is expected 
to solve traffic problems [2][3]. Figure 1 shows the concept 
image of the smart mobility [4]. The objectives of the mobility 
are the establishment of public acceptance, the clarification of 
business model, the establishment of social system and the 
establishment of automated driving technology [5][6]. However, 
automated vehicles without a driver is not allowed under current 
low in Japan. National police agency released the new guideline 
for remote type automated vehicle system for the real world 
experiments in 2017 [7]. In order to proceed them, a prototype 
of remote type automated vehicle system is proposed. In the 
system, the automated vehicle moves above a magnetic wire. 
The intensity of the signal from the wire is captured by the 
vehicle with algorithm of feedback control scheme. The scheme 
makes the vehicle able to follow the wire. However, if obstacles 
on the way, the vehicle must be remotely controlled to avoid the 
obstacles and go back to the magnetic wire again. The remote 
driver watches the live video from the front camera at the same 
time to operate the vehicle.  
Remote type automated vehicle system has two main 
problems: the lack of information due to the limited number of 
cameras and signal delay. These problems makes operating 
vehicles difficult. Therefore, the assistance of driving is 
necessary for the remote driver to better understand the 
surrounding environment. By showing the trajectory prediction 
of the vehicle, the remote driver is assumed to better control the 
vehicle to avoid the obstacles [8]. The experiments in this paper 
are designed for the assistance system using video camera and 
OpenCV (ver.3.4.2). In the system, the video consists of still 
images that are captured consecutively and played back in quick 
succession. A frame is a single one of those images, and the 
frame rate is a measure of frequency: how often the video is 
updated with a new frame. Frame rate is measured in Frames Per 
Second (FPS). FPS is the number of frames of video in one 
second. 
 
 
Figure 1. Concept image of the project. 
1 pixel of an image has 8 bits, which shows depth of color 
and 3 channels, which shows 3 primary colors of light. The more 
pixels an image contains, the more transmission takes long time. 
Also, the more frames are sent, the more transmission takes long 
time. few frames and pixels make transmission quickly. This 
system is supposed to be used mainly in depopulated areas 
where the communication system is not well established. 
Communication delay is the trade-off between image resolution 
and frame rate. This paper shows limit value of image resolution 
and FPS to control cart correctly. Section 2 shows the 
configuration of the remote control system. Section 3 shows the 
experiments to quantify the correctness of prediction by using 
Global Positioning System (GPS). 
II. REMOTE TYPE AUTOMATED VEHICLE  
This section shows how to remote control the cart and 
calculate future prediction.  
A. System Configuration 
Figure 2 shows the system configuration. The system 
consists of automated vehicles, a remote-control server, a 
monitors and communication tools. Wi-Fi or Long-Term 
Evolution (LTE) is used for wireless communication in this 
10
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-692-7
SMART ACCESSIBILITY 2019 : The Fourth International Conference on Universal Accessibility in the Internet of Things and Smart Environments

system. If an operator changes the mode to take over an 
automated vehicle, the operator teleoperate the vehicle by using 
speed and steering controller. The whole program is composed 
of three functions running in parallel. User Datagram Protocol 
(UDP) sender function keeps sending the current steering angle 
and speed obtained from the game controller. UDP receiver 
function keeps listening to the message which is sent from the 
vehicle and updates the real time steering angle and speed. Show 
function captures the input of the controller and calculates the 
 
 
Figure 2. System Configuration 
future path based the steering angle and speed of the vehicle then 
project to the image captured from the stream data. 
 
B. Contents of Communication 
Table 1 shows the contents of communication between the 
remote server and automated vehicles. Automated vehicles in 
the system communicate with the remote server by using shared 
memory. If the communication between the remote server and 
automated vehicles is unavailable for some reasons, automated 
vehicles stop.  
TABLE I.  
CONTENTS OF COMMUNICATION (LEFT: FROM VEHICLE TO 
REMOTE SERVER, RIGHT: FROM REMOTE SERVER TO VEHICLE)  
 
 
In the system, an occurrence of no communication in 2 
seconds leads to communication failure and automated vehicles 
automatically stop.  
C. Trajectory Prediction 
The trajectory prediction is calculated based on the steering 
angle and velocity by applying the simplified vehicle dynamic 
model. Figure 3 shows the procedure of calculating the 
coordinates of 10 discrete points in the case of turning procedure 
and Figure 4 shows the motion of turning vehicle. Trajectory 
prediction in this paper are composed of three parts: left wheel, 
right wheel and middle between both wheels. Each trajectory is 
composed of 10 discrete points which are calculated with speed 
and steering angle. Once the trajectory is obtained, by projecting 
the trajectory in real world coordinates, the ideal path will be 
shown in the 2D image from the front camera, which will help 
the driver to better predict where the vehicle is going.  
 
Figure 3. Motion model of vehicles 
The program needs to project a path by taking account the 
operator’s input and must be able to track any obstacle in the 
environment, as well as determine if the current trajectory may 
lead to a collision.  
Figure 4.  Trajectory prediction for turning 
PC
•
Sender & receiver  function
•
Showing trajectory function
Router 
Remote Type Automated System
LAN
Speed &
steering 
controller
USB
Emergency switch
PC
USB
Steering controller
CAN
LAN
Monitors
HDMI
LAN,
CAN, 
RS-232c
Automated Vehicle 1
For Remote control 
operator, Dispatcher
Sensors for obstacles and
position estimation 
Router 
Communication
sm[n]
Contents (from vehicle to server)
10 Vehicle mode
11 Shift position
12 Vehicle speed
13 Vehicle steering angle
14 Brake status
15 Alive counter (not used)
16 Winker status
17 Obstacle information
18 Obstacle position X
19 Obstacle position Y
20 Flasher
21 Counter
sm[n]
Contents (from sever to vehicle)
500 Datacount
501 Target speed
502 Target steering angle
503 Shift position
504 Brake status
505 Driving mode
506 Winker status
507 Permission from oparator
508 Horn instruction
2.2 m
3.3 m
1.4 m
1.0 m
 
O      
 
     
     
 
 
1. 
Input:  Tread 𝑊, wheelbase 𝐿, current speed 𝑠𝑝𝑑, 
current steering angle α 
2. 
Output: 10 discrete points of trajectory ( 𝑖  𝑖), 𝑖 ∈ (0 1 ⋯  9) 
3. 
Step1: calculating turning radius   
4. 
 =
{
 
 
 
 √𝐿2 + (𝑟 +
𝑊
2 )
2
 𝑟 =
𝐿
tan 𝛼                 𝑙𝑒𝑓𝑡
𝐿
tan 𝛼                                                    𝑚𝑖𝑑𝑑𝑙𝑒
𝑟 −
𝑊
2                      𝑟 =
𝐿
tan 𝛼               𝑟𝑖𝑔ℎ𝑡
 ; 
5. 
Step2: calculating the length 𝑆 of the trajectory in 3 second. 
6. 
𝑆 = 𝑠𝑝𝑑 ∗ 3; 
7. 
Step3:caluculating the central angle    
8. 
 =
𝑆
𝑅∗   ; 
9. 
Step4: calculating ( 𝑖  𝑖) for each point 
10. 
If (𝛼 > 0) then 
11. 
[ 𝑖
 𝑖] = [(  −   ) cos( ∗ 𝑖) − (  −   ) sin( ∗ 𝑖) +   
(  −   ) sin( ∗ 𝑖) + (  −   ) cos( ∗ 𝑖) +   
] ; 
𝑖 ∈ (0 1 ⋯  9)  
12. 
If (𝛼 < 0) then 
13. 
[ 𝑖
 𝑖] = [(  −   ) cos( ∗ 𝑖) − (  −   ) sin( ∗ 𝑖) +   
(  −   ) sin( ∗ 𝑖) + (  −   ) cos( ∗ 𝑖) +   
] ; 
𝑖 ∈ (0 1 ⋯  9)  
14. 
end if 
11
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-692-7
SMART ACCESSIBILITY 2019 : The Fourth International Conference on Universal Accessibility in the Internet of Things and Smart Environments

 
Figure 5. Relative distance model of vehicle and obstacle 
The program is designed to display a project path to aid an 
operator when remotely maneuvering a vehicle through an 
obstacle course. Figure 5 shows the model of relative distance 
of vehicle and obstacle and the distance is calculated in 
 
√( 𝑖 −  𝑜𝑏𝑠)2 + ( 𝑖 −  𝑜𝑏𝑠)2 ≤ 𝑑. 
(1) 
 
 
 
Figure 6. World coordinate (Left: Avoided obstacle, Right: Collided 
obstacle) 
Figure 6 shows the result of collision detection from 
equation (1).  
 
 
Figure 7. Image coordinate (Left: Avoided obstacle, Right: Collided 
obstacle) 
The result of the transformation between world coordinate 
and image coordinate can be seen in Figure 7. 
III. EXPERIMENTS 
Figure 8 shows the automated vehicle which is controlled 
by an operator and the camera on the front of the vehicle. There 
are two laser range finders on front edge of the vehicle and GPS 
antenna on the top of the vehicle.  
 
 
Figure 8. Automated vehicle (Left: Electronic vehicle, Right: Front camera) 
Remote type automated system is on another vehicle which 
is shown in Figure 9. The system shows the trajectory which 
calculated by the speed and steering angle obtained from the 
automated vehicle on the monitor. During experiments, the data 
value of time, speed, steering angle, resolution and fps are 
logged. 
 
Figure 9. The vehicle with remote type automated system 
Experimental scene is shown in Figure 10. A slalom course 
was employed in the experiment. There are 10 obstacles which 
are putted in zigzag on the course. An operator needs to operate 
the vehicle to avoid the obstacles. 
 
Figure 10. Test course 
 
 
     
     
 2  2
Obstacle
 𝑜𝑏𝑠  𝑜𝑏𝑠
𝑑
12
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-692-7
SMART ACCESSIBILITY 2019 : The Fourth International Conference on Universal Accessibility in the Internet of Things and Smart Environments

The experiment is to check whether low resolution of small 
fps makes the signal delay short. However, low resolution and 
small fps also makes teleoperation difficult. Figure 11 shows 
high and low resolution images from camera.  
 
 
Figure 11. Camera images (Left: 1001×667, Right: 100×67) 
In this experiment, there are 2 patterns of resolutions, 
2patterns of frequency of frames, and 2 patterns of 
communication delay before sending value of velocity and 
steering angle from operator to cart. This system can change the 
timing of sending input data, thus this system can add the 
communication delay intentionally in addition to the constant 
delay. First, The GPS data of the target course is taken by 
driving the cart. Second, the subject control the cart to drive on 
the course by remote control system while taking GPS real data.  
In this experiment, the quantity of correctness of prediction in 
each frame rate and image resolution is shown as the difference 
of the GPS target data and real data. Each experiment was done 
10 times. 
IV. CONCLUSION 
This paper introduces the driving assistance system for 
remote control and explained the system configuration, contents 
of communication, results and the plan of experiments in the real 
field, as a short paper. The results of the experiments have not 
been concluded yet. The experiment will be continued, analyzed 
and shared the experimental results after the completion of the 
project as a future work. 
ACKNOWLEDGMENT 
The study has been supported by Ministry of Economy, 
Trade and Industry in Japan and Ministry of Land, Infrastructure 
and Transport in Japan. 
REFERENCES 
[1] F. Granda et al., “Deterministic Propagation Modeling for Intelligent 
Vehicle Communication in Smart Cities,” Sensors, Vol.18, no.7, pp.1-28, 
July 2018, doi:10.3390/s18072133. 
[2] J. L. Zambrano-Martinez, C. T. Calafate, D. Soler, J. C. Cano, and P. 
Manzoni,  “Modeling and Characterization of Traffic Flows in Urban 
Environments,” 
Sensors, 
vol.18, 
no.7, 
pp.1-19, 
July 
2018, 
doi:10.3390/s18072020. 
[3] M. D. Cia et al., “Using Smart City Data in 5G Self-Organizing Networks,” 
IEEE 
IoT 
J., 
vol.5, 
no.2, 
pp.645-654, 
Apr. 
2018, 
doi:10.1109/JIOT.2017.2752761. 
[4] N.Hashimoto et al., “Introduction of Prototype of Remote Type 
Automated Vehicle System by using Communication between Operator 
and Vehicles in Real Environment”, Proceedings of ITST 2018, 2018 
[5] A. K. Tripathy, K. Pradyumna, N. K. Ray, S. P. Mohanty, “iTour: The 
future of Smart Tourism: An Iot Framework for the Independent Mobility 
of Tourists in Smart Cities,” IEEE Consumer Electronics Magazine, vol.7, 
no.3, pp.32-37, Apr. 2018, doi:10.1109 / MCE. 2018.2797758. 
[6] I. Docherty, G. Marsden, J. Anable, “The governance of smart mobility,” 
Transporttation Research Part A: Policy and Practice, vol.115, pp.114-
125, Sep. 2018, doi: 10.1016/j.tra.2017.09.012.  
[7] National Police Agency in Japan. Automated driving System 2.0: A Vision 
for Safety. [Online]. Available from: https://www.npa.go.jp/bureau/traffic 
/selfdriving/index.html, retrieved: Dec. 2018 
[8] Ruike Ren, Wei Wang, Jinze Liu, Yan Li, Li Wang, “Teleoperation of 
unmanned ground vehicle based on 3D trajectory prediction,” IEEE 
Advanced Information Management, Communicates, Electronic and 
Automation Control Conference (IMCEC 2016), Oct. 2016, pp.790-794, 
doi:10.1109/IMCEC.2016.7867318 
13
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-692-7
SMART ACCESSIBILITY 2019 : The Fourth International Conference on Universal Accessibility in the Internet of Things and Smart Environments

