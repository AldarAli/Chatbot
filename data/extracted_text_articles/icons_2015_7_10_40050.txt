Meta-Theory and Machine-Intelligent Modeling of Systemic Changes  
for the Resilience of a Complex System 
Roberto Legaspi 
Transdisciplinary Research Integration Center 
The Institute of Statistical Mathematics 
10-3 Midori-cho, Tachikawa, Tokyo, Japan 
e-mail: legaspi.roberto@ism.ac.jp 
Hiroshi Maruyama 
Department of Statistical Modeling 
The Institute of Statistical Mathematics 
10-3 Midori-cho, Tachikawa, Tokyo, Japan 
e-mail: hm2@ism.ac.jp
 
 
Abstract— Resilience is the ability of a complex system to 
persist in, adapt to, or transform from dramatically changing 
circumstances. Our objective is to characterize the resilience of 
a complex system in depth by looking at what fundamentally 
constitutes and leads to system changes and how the system 
can be resilient to these changes. Our characterization is by a 
two-fold framework, i.e., with a meta-theory that integrates 
long-standing foundational theories of systemic change and a 
two-part 
machine-intelligent 
computational 
modeling, 
specifically, using network analysis and machine learning 
models, to realize our meta-theory. By starting with a meta-
theory as background knowledge to guide our modeling, we 
avoid irrelevant, scattered and loosely knitted paradigms. 
Complementary, any truth presented by the inferred models 
that are not accommodated in the meta-theory may correct 
flaws in the meta-theory. To our knowledge, our framework 
that uses this linking of meta-theory and machine-intelligent 
modeling to characterize resilience is novel. The results we 
obtained from our simulations show that our framework is a 
systematic and pragmatic way of inferring predictive models of 
the contextual interaction behaviors of a resilient system. 
Keywords-dynamic system theories; resilience theories; 
system evolution theories; intelligent systems. 
I. 
 INTRODUCTION 
We have witnessed in the past 10 years unprecedented 
massive devastations in terms of human lives, livelihoods 
and infrastructures brought about by strong natural hazards, 
such as Hurricane Katrina in 2005 that is considered to be 
one of the deadliest hurricanes in U.S. history, the Haiti 
earthquake of 2010 with its catastrophic magnitude of 7.0Mw, 
the 9.0Mw undersea megathrust earthquake off the Pacific 
coast of Tōhoku Japan and the Fukushima nuclear power 
plant disaster that happened in its wake, and Haiyan in 2013 
that is one of the strongest trophical cyclones ever recorded. 
To say, however, that our reality is mostly a series of mild 
and insignificant events punctuated by only a handful of 
massive devastations is inaccurate. The reality is that the 
occurrences of car, train and airplane crashes, sinking ships, 
oil, chemical and radiation spills and leaks, terrorist attacks, 
and spread of viruses, among others, are more frequent than 
we think. These so-called normal accidents [42] dictate the 
quick, frequent and incremental critical adaptations of our 
systems [27]. Then we can add to these the catastrophic 
events that are difficult to model and predict given their ill-
defined and non-computable nature, or the so-called Black 
Swans and X-events (citations in [26][32]), which compel our 
systems to carry out dramatic and novel adaptations in order 
to survive and sustain their existence. 
In other words, accidents and disasters are actually 
common and inevitable [27][47], hence, our systems that 
keep us, our way of life, and our world existing and 
flourishing must be resilient, i.e., able to withstand even 
large perturbations and dramatically changing circumstances 
and preserve its core purpose and integrity [53], and achieve 
generalized recovery once failure due to perturbation is 
inevitable [32]. While resilience theory has been adopted in 
various fields including ecology, biology, economics, 
finance, engineering, social science, and of course, human 
development (noteworthy surveys can be found in [31][32]), 
we argue for deepening further the analysis of what makes a 
system resilient through a deeper understanding of what 
fundamentally (foundational) constitutes and leads to 
systemic changes and how the system can be resilient 
through undesirable changes. To be resilient also means to 
embrace change [31]. We position our argument with the 
long-standing theories of system complexity, chaos, self-
organization, and criticality, all of which are interesting 
emergent properties shared by complex systems and have 
been used to explain biological evolution [23][24], capacity 
for computation in physical systems [39][25][36], evolution 
of natural and socio-ecological systems [2][21][40][41], and 
the collapse of social systems [46][35][13][9]. We integrate 
essential concepts of these theories in varying grains of 
analyses and view this integration as a meta-theory. 
We also argue for the use of a two-part machine-
intelligent modeling, specifically, using network analysis and 
machine learning approaches, to automatically discover the 
hidden rules of contextual interaction behaviors of a complex 
system. By starting with a meta-theory as background 
knowledge to guide our modeling, we avoid scattered and 
loosely knitted paradigms. Complementary, any truth present 
in the inferred models that is not accommodated in the meta-
theory shall correct flaws in the meta-theory. Our meta-
theory and machine-intelligent models can evolve together 
with increasing predictive isomorphism [34] to accurately 
represent the phenomena present in, i.e., endogenous (e.g., 
emergent properties, complexity, chaos, adaptation, and 
transformation, among others) and with, i.e, exogenous (e.g., 
disturbances, stress, and shocks), a complex system. To our 
knowledge, this linking of a meta-theory and two-part 
intelligent modeling to automatically characterize the 
contextual interaction behaviors of a resilient system is novel. 
102
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

Our paper is structured as follows. We elucidate in detail 
our meta-theory in Section II and discuss in length our 
machine-intelligent modeling approaches and simulation 
results in Section III. We make a final defense of our 
framework in Section IV and then conclude in Section V. 
II. 
OUR META-THEORY 
Figure 1 shows our meta-theory that cohesively puts 
together theories on complexity, chaos, self-organization, 
critical transition and resilience. The complex system 
evolution cycle in our meta-theory involves three regimes, 
namely, order, critical, and chaos. The second ordered 
regime, however, may be novel in the sense that it required 
the system to transform when adaptation back to the previous 
state was no longer attainable. The moving line indicates 
system “fitness”, i.e., the changing state of the system in 
terms of its capacity to satisfy constraints, its efficiency and 
effectiveness in performing tasks, its response rate (time to 
respond after experiencing the stimuli), returns on its 
invested resources or capital, and/or its level of control.  
It is through our meta-theory that we can view a complex 
system as open, i.e., always in the process of change and 
actively integrating from, and disseminating new information 
to, changing contexts, as well as open-ended, i.e., it has the 
potential to continuously evolve, and evolve ways of 
understanding and manipulating the contexts (endogenous 
and exogenous) that embed it [48]. Both characteristics are 
vital for the complex system to be resilient. 
Our succeeding elucidation of our meta-theory, and the 
references that accompany our elucidation, would attest to 
the fact that the individual components, i.e., theories, which 
comprise our meta-theory are neither from a vacuum nor just 
mere speculations as they are evident in physics, ecology, 
biology, and system dynamics. What we are presenting here, 
however, is a plausible integration of these theories. 
While complexity theory focuses on how systems 
consisting of many diverse elements give rise to well-
organized, predictable behavior, chaos theory concerns itself 
with how simple systems pave the way for complicated 
nonlinear unpredictable behavior. Self-organization holds 
that structures, functions, and associations emerge from the 
interactions between system components and their contexts. 
The critical regime, which we pay special attention to due to 
its importance, holds significant paradoxes – it may herald an 
unwanted collapse or become a harbinger of positive change 
[44], and while it may signal hidden fragilities [12], it is also 
theorized to facilitate complex computations, maximize 
information storage and flow, and be a natural target for 
selection because of its hidden characteristics to adapt 
[25][23][36]. While we adopt the terms order, critical, and 
chaos from dynamical systems theory [49], to persist, adapt, 
and transform is resilience thinking [14][8][10]. 
In the ordered regime, connections, interdependencies, 
and correlations begin to emerge. In this stage, the system 
will control and manage change. It will always attempt to re-
establish equilibrium in order to persist in its ordered state 
each time it is perturbed (indicated by the dents in fitness). 
When it encounters a perturbation, it should readily bounce 
back and recover. System adaptations, however, will only be 
small, moderate, segmented and gradual, which are sufficient 
to handle only the manageable perturbations. The system 
changing or becoming permanently damaged from shock is 
not a major concern in this phase. To resume normal 
operations immediately and distort less in the face of minor 
perturbations is an increasing trait. 
The ordered regime is a slow process characterized by 
increasing system efficiency and optimization of processes. 
What is also increasing, however, is the connectedness or 
tight coupling of the system components. Furthermore, the 
system’s self-regulation becomes more finely tuned to the set 
of perturbations and responses it became familiar with. 
These tight coupling and rigidity only make the impact of 
any perturbation, regardless of its magnitude, to also increase. 
All this build-up is like an accident in the wings waiting to 
happen. Eventually, the system shall converge to a state that 
makes itself less adaptive to perturbations and therefore 
brings itself to the critical regime, which is at times also 
called the “edge of chaos” [25][23][36]. 
Scheffer et al. [44] elucidate the behaviors displayed by 
the system in the critical regime. One is a critical slowing 
down, i.e., the rate at which a system recovers from small 
perturbations becomes slow. Flickering may also be 
observed wherein a highly stochastic system flips to an 
alternative basin of attraction when exposed to strong 
perturbations. Page [40] added diminishing returns, which is 
the decrease in some system performance measure such as 
efficiency, robustness, or accuracy. 
Comes a point when complexity can no longer be 
sustained and persistence and small adaptations are no longer 
possible, and so the system enters the chaotic regime. The 
building up of complexity becomes a constraint to adaptation 
and eventually leads to chaos. In the chaotic phase, the 
system will need larger adaptations, otherwise, it will need to 
transform to a new ordered regime to survive – one that will 
require dramatic change of structure and function. 
Systems that demonstrate a transformative capacity can 
generate novel ways of operating or novel systemic 
associations and can recover from extreme perturbations [31]. 
Such systems learn to embrace change [31], and instead of 
bouncing back to specification, which is proved vulnerable 
and led to chaos, they bounce forward to a new form [29]. 
Figure 1. We integrate in varying grains of analyses how the different 
theories are plausibly related – hence,  a meta-theory. 
103
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

 
Figure 2. Our entire complex systems resilience modeling architecture, which includes our two-fold framework (enclosed in dotted lines). 
III. 
MACHINE-INTELLIGENT MODELING OF THE 
RESILIENCE OF A COMPLEX SYSTEM 
When we speak of complex system properties, we speak 
of system-wide behaviors emerging from the interaction and 
interdependencies of diverse system components. To be 
more concrete, our long-term objective is to model a socio-
ecological urban system (SEUS), as shown at the right side 
of Figure 2, where diverse components, which can be 
systems in themselves [5][50], are intricately connected and 
may at times display rather extreme interdependencies. This 
SEUS contains continuous flow of resources, information, 
energy, capital, commerce, and people. The sustainability of 
a component will critically depend on its place in the system 
and how it, and the entire SEUS, can withstand perturbations. 
The meta-theory shall be the by-product of integrated 
transdisciplinary perceptions of what characterizes systems 
resilience. We can develop social computing platforms for 
the collaboration and integration of expert and experiential 
knowledge (e.g., of aborigines and natives whose breadth 
and depth of experiential knowledge make their lack of 
formal education insignificant) [26]. We can also develop 
knowledge extraction and integration technologies that can 
infer relationships that exist among knowledge from largely 
varying domains and can synthesize individualized, micro-
level, and domain-dependent knowledge towards contextual 
systemic knowledge that can lead to actionable information 
for resilience. Such actionable information, for example, can 
be in the form of a repository of evidences of what works 
(predictive) and may work (innovative) in a situation (e.g., 
disaster prevention, mitigation and management). 
To gather large amount of data to model the SEUS, 
ubiquitous smart and interacting daily-living objects can 
offer a wide range of possibilities [6][43]. Urban services, 
such as vehicular traffic, banking, purchasing, personal 
security for citizens, social services, and tourism support, 
among others, have been recently enhanced by digital 
networks and mobile technology. Digital networks may also 
control sanitation and waste, water, traffic, communication, 
and energy. Tiny interacting embedded systems could also 
play a valuable role in protecting the environment from 
perturbations, e.g., sensors so minute, as the size of dust 
particles, but can detect the dispersion of oil spills or forest 
fires [6]. Furthermore, signals can come from volunteered 
data of people’s use of mobile devices, social media, web 
searches, and online transactions, among others, which 
reflect human cognitive, affective and social behavior 
patterns. Using distributed multisensing capabilities and 
information processing, it is possible for the machine 
intelligence in the SEUS to infer accurate and informative 
models for situation analysis, situation awareness, decision-
making and response, and component feedback in order for 
the SEUS to sense and shape the contexts that embed it. 
Heterogeneous data related to humans, environments, 
and technologies, and their interactions will often be reported 
or obtained from a multiplicity of sources, each varying in 
representation, granularity, objective, and scope. Data pre-
processing techniques can be employed to organize, align, 
and associate input data with context elements. With feature 
selction, it can also reveal which features can help improve 
concept recognition, generalization and analysis. Lastly, data 
fusion can address data and algorithmic complexities and the 
associated challenges that arise when independent data 
sources are combined to improve the quality of information.  
All the pertinent features, contexts and interactions 
inferred in the preprocessing stage will be used in our two-
part machine intelligent modeling. First, these information 
will be organized, represented and analyzed as a network. 
Paperin et al. [41] provide an excellent survey of previous 
works that demonstrated how complex systems are 
isomorphic to networks and how many complex properties 
emerge from network structure rather than from individual 
constituents. Second, using as inputs the network and 
resilience properties of the system, machine learning will be 
used to infer the relational rules of system contextual 
interaction 
behaviors 
that 
define 
its 
adaptive 
and 
transformative walks and therefore define its resilience. Our 
modeling will capture how the complex system’s ability to 
vary, adjust or modify the connectivity, dynamism, topology, 
and linkage of its components (endogenous features), and its 
capacity to withstand the disturbances (exogenous feature) 
that perturb it, will dictate its resilience. 
104
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

A. Simulation of a Complex System  and its Properties 
Although our aim is to model a socio-ecological urban 
system and its intricate properties, our major concern at this 
time, however, is that we have yet to embark on this 
endeavor. However, as a more than plausible work-around to 
this lack of complex system to analyze the viability of our 
framework, we used random Boolean networks (RBNs) to 
simulate the behavior of a complex system. The question, 
however, is whether the use of a RBN in lieu of an actual 
complex system plausible in demonstrating our concepts?  
The literature is rich with RBNs being models of large 
scale complex systems [1][20]. RBNs are idealizations of 
complex systems where its systemic elements evolve [11]. 
They are general models that can be used to explore theories 
of evolution or even alter rugged adaptive landscapes [16]. 
Furthermore, although RBNs were originally introduced as 
simplified models of gene regulation networks [22][23][24], 
they gained multidisciplinary interests since they could 
contribute to the understanding of underlying mechanisms of 
complex systems, albeit their dynamic rules are simple [52], 
and because their generality surpassed the purpose for which 
they were originally designed [34][52][30][17]. 
A RBN consists of N Boolean nodes, each linked 
randomly by K connections. The state of a node at time t+1 
depends on the states of its K inputs at time t by means of a 
Boolean function. The randomly generated Boolean 
functions can be represented as lookup tables that represent 
all possible 2K combinations of input states. N represents the 
number of significant components comprising an adapting 
entity, such as gene, chromosome, trait, species, process, 
business unit, firm, traders, bankers, or workers – generally 
the number of agents attempting to achieve higher fitness 
[34]. The Boolean values may represent, for example, 
contrasting views, beliefs and opinions, or alternatives in 
decision-making (e.g., buying or selling a stock [24], 
cooperating with community or not).  We can view K 
conceptually as affecting the mutual influence among nodes 
in an information network [52] since a directed edge <x, y> 
means that agent y can obtain information from, and can be 
influenced by, agent x. In this way, K is proportional to the 
quantity of information available to the agent [52]. 
How complex can a RBN be? Given N and K, there can 
be (N!/(N-K)!)N possible connectivity arrangements, (
)N 
possible N Boolean function combinations, and ((
N!)/(N-
K)!)N RBNs [19]! This is not counting the many possible 
updating schemes [16], and possibly extending to have nodes 
with multiple states [45]. With these huge number of 
possibilities, it is therefore possible to explore with RBNs the 
various properties of even large-scale complex systems and 
their many possible contexts [20]. 
Inherent to RBNs are certain parameters that we found 
having accounted for by our meta-theory. At the same time, 
these parameters can be the controlling variables that the 
system can modify or adjust to demonstrate its resilient 
capabilities. In a plausible sense, these parameters can be 
viewed as simulated (but possible) outputs of the pre-
processing stage of our architecture (in Figure 2) that led to 
the construct of the network. The parameters are as follows: 
 Connectivity (K). This refers to the maximum or average 
number of nodes in the input transition function of a 
network component. As we increase K, nodes in the 
network becomes  more connected or tightly coupled, and 
more inputs affect the transition of a node.  
 Dynamism (p). A Boolean function computes the next 
state of a node depending on the current state of its K 
inputs subject to a probability p of producing 1 in the last 
column of the lookup table. If p=1 or p=0, then there is 
no actual dynamics, hence low activity, in the network. 
However,  p close to 0.5 gives high adynamical ctivity 
since there is no bias as to how the outputs should be 
[17]. High dynamical activity means high variability. 
 Topology (or link distribution). A RBN may have a fixed 
topology, i.e., all transition functions of the network 
depend on exactly K inputs, or a homogeneous topology, 
i.e., there is an average K inputs per node. Another type 
of topology is scale-free, where the probability 
distribution of node degree obeys a power law. In an 
information network, a scale-free property means that 
there is a huge heterogeneity of information existing [52], 
hence, there is more variation in the network. Following 
[38], the number of inputs for the scale-free topology is 
drawn from a Zeta distibution where most nodes will 
have few inputs, while few nodes will have high number 
of inputs. The shape of the distribution can be adjusted 
using the parameter γ (set to 2.5) – when γ is small/large, 
the number of inputs potentially increases/decreases. 
 Linkage (or link regularity). The linkage of a RBN can be 
uniform or lattice. If the linkage is uniform, then the 
actual input nodes are drawn uniformly at random from 
the total input nodes. Following [38], if the linkage is 
lattice, only input nodes from the neighbourhood (i-
latticei*ki):(i+latticei*ki) are taken, where i is the position 
of the node in the RBN and latticei is its lattice dimension 
whereby nodes are dependent to those in the direct 
neighborhood. A wider lattice dimension can lead to a 
RBN with highly interdependent nodes. 
B. Simulation Models, Results, and Analyses 
We now discuss our various simulation models starting 
with the base case. Our base case is a “conventional” RBN 
wherein the topology is fixed and the nodes are updated at 
the same time by the individual transition functions assigned 
to each, i.e., synchronous update. With several conditions to 
check, we used for now a single value for N (i.e., 20). 
The simulations we conducted involved testing the 
RBN's robustness when faced with perturbations. We 
applied the program of Müssel et al. as outlined in their 
BoolNet vignette [38] as follows. A perturbation is achieved 
by randomly permutating the output values of the transition 
functions, which although preserved the numbers of 0s and 
1s, may have completely altered the transition functions. For 
each simulation a total of 1,000 perturbed copies of the 
network were created, and the occurences of the original 
attractors in the perturbed copies were counted. Attactors are 
the stable states to which transitions from all states in a RBN 
eventually lead. The robustness, R, value is then computed as 
the percentage of occurrences of the original attractors. 
105
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

 
Figure 3. Base case: map of the different regimes based on the sensitivity 
of conventional RBNs to perturbations. 
It is very important to realize that robustness here is not 
resilience per se, since resilience refers to what enables a 
system (such as change in connectivity, dynamism,  topology, 
and linkage, among others) to preserve its core identity when 
faced with perturbations [53]. We used R to quantify the 
amount of RBN core identity that was preserved. Hence, R is 
an indicator or measure of systems resilience. 
Figure 3 shows our base case R-matrix in a dynamism-
connectivity space, where each component is a R value. We 
can observe that it is at K=1 that the RBNs were most robust. 
The RBNs losing robustness at K=2 is indicative of critical 
slowing down and the system may therefore be tipped more 
easily into an alternative state [44], i.e., from order to chaos, 
which therefore reflects criticality. Hence, the ordered phase 
is found when K<2, the chaotic phase occurs for K>2, while 
the critical regime lies at the phase transition, i.e., at K=2 
[16]. We can therefore observe from the base case the 
regimes present in our meta-theory (blue is order, purple is 
critical, and red is chaos). 
We now move on to the results of the various simulation 
models we ran, beginning with the one in Figure 4. Each 
rectangle in the 35 topology-linkage space is a R-matrix 
with p-K dimensions. For example, R23 corresponds to the 
robustness matrix of RBNs with homogeneous topology and 
lattice linkage of size 2.5. R11 is the same R-matrix in Figure 
3. We can see from the R-matrices the interesting properties 
that emerged. We can observe the critical regime broadening 
to K=3 (e.g., R12, R22, R23, etc.), or reoccurring at K>2 
(e.g., R13 and R15) in between chaotic regimes, in the fixed 
and homogeneous RBNs with wider lattice. These extensions 
and reoccurrences of the critical regime mean alternative 
opportunities for the system to take advantage of the benefits 
of the critical regime and the balance of stability and chaos 
[17]. The wider lattice led to more interdependencies among 
nearest neighbors, which formed small world networks that 
brought about such behaviors of the critical regime. This is 
consistent with the findings of Lizier et al. [28] that a small 
world topology leads to critical regime dynamics. 
Furthermore, 
the 
ordered 
regime 
expands 
with 
homogeneous RBNs. Since the number of input nodes is 
drawn independently at random, there is more variation in 
the way components influence each other. This also means 
that with less tighter connections among components (i.e., as 
the couplings in the network are loosened), the system 
becomes less vulnerable to perturbations. R21, for example, 
shows how the system could transform to the next ordered 
state from a critical phase instead of deteriorating to a 
chaotic regime. With the scale-free topology, however, we 
can see highly robust RBNs. Since few nodes have more 
connections, and most nodes have few connections, changes 
can propagate through the RBN only in a constrained fashion. 
We also have evidence wherein the over-all mean robustness 
began to continuously decrease towards zero for the fixed 
and homegeneous topology at K=2, which we interpret as a 
form of diminishing returns before transitioning to the 
chaotic regime. The over-all mean robustness values for the 
scale-free RBNs, however, remained satisfactory throughout. 
A complex system may therefore demonstrate resilience by 
broadening (extending) the critical regime, making the 
critical regime reoccur, or changing to a scale-free topology. 
Lastly, by applying again the methods of Müssel et al. 
[38], we tested for the sensitivity of the RBNs to greater 
perturbations. In each network transition, the transition 
function of one of the components is randomly selected, and 
then five bits of that function is flipped. Figure 5 shows the 
results we obtained. The first interesting phenomenon is the 
multiple occurrences of the ordered (e.g., in R21 and R24) 
and critical regimes (e.g., in R14, R23, R24, and R31), even 
after the chaotic regimes, which can point to resilience. The
 
 
Figure 4. Map of the different regimes based on the sensitivity of RBNs to perturbations when activity, connectivity, topology, and linkage values were 
varied. The R-value ranges for each regime are as follows – order: [43,100] (in blue), critical: [22, 43) (in purple), and chaos: [0, 22) (in red). 
106
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

 
Figure 5. Map of the different regimes based on the sensitivity of RBNs to greater perturbations. 
 
Figure 6. We simulated what will happen with changing γ values. The tables show that with other γ comes more expansions of the critical regime. 
second is that we can obviously see how the behavior of the 
scale-free RBNs changed drastically, i.e., we could not find 
any ordered regime. This is consistent with the findings of 
Barabási and Bonabeau [3] that scale-free networks are very 
robust against random failures but vulnerable to elaborate 
attacks. In our case, flipping bits in each transition of the 
network was too much perturbation for the scale-free RBN. 
But this does not mean, however, that its resilience is entirely 
lost. When we varied the parameter γ of the Zeta distribution, 
another interesting phenomenon emerged as shown in Figure 
6 – we see more expansions and reoccurrences of the critical 
regime given other γ values. Again, to be capable of 
prolonging or increasing the number of critical regime 
occurrences is indicative of a system being resilient. 
C. Machine-Intelligent Modeling 
We can see from our simulation results that the various 
parameters we used can quantitatively explain our meta-
theory. It is clear that the combinations of their specific 
values can be used to predict system states and changes and 
steer the system to desirable regimes, i.e., resilient states. 
The question now is how to infer these parameter relations 
that can be used as rules of contextual interaction behaviors 
that define the complex system’s adaptive and transformative 
walks and therefore define its resilience. 
Our solution is to use machine learning (ML) to 
automatically discover the hidden relations from the data we 
obtained about the complex system. We represent system 
contextual interaction behaviors as sets of feature vector and 
label pairs. Each feature vector is represented as a tuple of 
attribute values, i.e., <topology, linkage, lattice, gamma, 
connectivity, activity, perturbation>, and labeled with the 
corresponding R value that is indicative of system regime. 
The ML algorithm should infer a model that is predictive 
– given the feature vector, what is the system regime (and its 
robustness)? Furthermore, the predictive model is one that 
can be used to help steer the system to a desirable regime – 
from the current feature vector that indicates the contextual 
situation of the system, which may be undesirable given R, 
which features can or should be modified to achieve a 
desirable regime. This capacity to modify the contexts and 
predict the resulting behavior can make the system resilient. 
Our dataset consisted of 7,120 feature vectors, which 
corresponds to the various simulation scenarios we ran using 
our different RBN models. It is important to note that even 
though our data can still be considered minimal (considering 
for example that we only used one value for N, limited value 
ranges for the parameters, and only synchronous updates), 
the advantage of using a data-centric approach is that as the 
data further increases, ML can be used to automatically 
handle growing intricacies and complexities, as well as 
automatically infer the new relations emerging from the data. 
To obtain the model with the best predictive capacity, we 
ran several well-known ML algorithms that are (a) function-
based: linear regression models (LRM), multi-layer 
perceptrons (MLP), radial basis function networks (RBFN),
107
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

 
Figure 7. Prediction accuracy of the various models using %-split validation with increasing % values 
and support vector machines for regression (SMOR), (b) 
instance-based or lazy: K* and k-nearest neighbor (Ibk), and 
(c) tree-based: fast decision tree (REPTree) and MP5 model 
tree (MP5Tree), using the WEKA open-source software. Due 
to space constraints, it is best that we refer the reader to the 
documentation [51] of these algorithms. We used %-split 
validation where x% of the data was used for training and the 
rest for testing the accuracy of the model. We measured the 
performance of the regression analysis in terms of correlation 
coefficient and root mean squared error to show the strength 
of prediction or forecast of future outcomes through a model 
or an estimator on the basis of observed related information. 
The correlation coefficient is also indicative of how good the 
approximation function might be constructed from the target 
model. We constructed several models by increasing the size 
of the training set from 10% to 90% of the total data, with 
increments of 10% (horizontal axis of the graphs in Figure 7), 
which allowed us to see the performance of the inferred 
models with few or even large amount of data, and also gave 
us the feel of an incremental learning capacity 
Figure 7 shows the accuracy of prediction of the models. 
We can see that the models inferred by the decision tree-
based (REPTree and MP5Tree) and instance-based k-nearest 
neighbor (Ibk) algorithms outperformed the others. These 
models can accurately predict in more than satisfactory 
levels the contextual interaction behaviors of the system even 
with only 10% of the data. We note that our goal at this time 
is not to improve the algorithms or discover a new one, but 
to prove the viability of our framework. We anticipate, 
however, that as the complexity of the system and the data 
grows, our algorithms may also need to improve. 
The other advantage of the tree-based models is that the 
relation rules can be explicitly observed from the tree. Model 
trees are structured trees that depict graphical if-then-else 
rules of the hidden or implicit knowledge inferred from the 
dataset [4][18]. Model trees used for numeric prediction are 
similar to the conventional decision trees except that at the 
leaf is a linear regression model that predicts the numeric 
class value of the instances reaching it [18]. Figure 8 shows 
the upper portion (we could not show the entire tree of size 
807 due to space constraints) of the REPTree we obtained 
using 10%-split validation with the elliptical nodes 
representing the features (colored so as to distinguish each 
feature), the edges specifying the path of the if-then-else 
rules, and the square leaf nodes specifying the corresponding 
R-values depending on which paths along the tree were 
selected. We can see how the rules delineated in a fine-
grained manner the attribute values that eventually led to 
satisfactory predictions. We can also see how certain features 
are more significant to the classification task even early in 
the tree. The connectivity feature, for example, is prominent 
in both sides of the tree, and that the dynamism feature is not 
as significant in the upper levels of the tree as compared to 
the lattice feature. All these mean that by observing the tree, 
we can determine which features are significant not only to 
the classification task, but more importantly to a more 
relevant sense, which features are actually influential to the 
resilient (as well as vulnerable) walks of the system. 
 
 
Figure 8. REPTree generated using Weka with a 10%-split validation. The size of the tree is 807, but only parts of it can be shown due to space constraints. 
The nodes specify the features (colored so as to distinguish each) with the edges as attribute values, and the leaf nodes as R-values. 
108
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

 
Figure 9. Illustration of how the strength of the predicitve models can be used to find the desirable regime states. The regime states (colored blocks) and their 
contextual features (in angle brackets) were taken from the robustness maps, i.e., R23, R13, and R33, in  Figure 4. 
Lastly, we refer to Figure 9 to illustrate how our strong 
predictive model can be used to help steer the system to a 
desirable regime. The regime states shown in the figure, 
which were taken from the regime maps in Figure 4 
(specifically, from R23, R13, and R33), are obviously only a 
tiny portion of the possible entire regime search space since 
each cell in every R-matrix in Figures 4 to 6 is a regime state. 
Let us say that the system landed in the chaotic regime SI, 
hence undesirable, as a result of the situational context 
(indicated by the feature vector shown below it) it found 
itself into. The predictive model can be used to predict the 
resulting regime when one or more of the SI contextual 
features are changed. Hence, from the current regime state SI, 
depending on which features are changed, the system may 
enter in one of the many possible SI+1 regime states. 
Although it seems elementary for the system to follow the 
prediction that suggests changing to scale-free topology with 
γ=2.5 in order to immediately reach a new ordered state, 
what should be considered is the high cost of changing to a 
topology that will necessitate breaking many of the current 
ties (e.g., geophysical, relational, monetary, etc.). Hence, it 
may be more advantageous for the long haul for the system 
to seek alternative paths with longer chaos, but less painful 
and costly. This capacity to modify contextual features and 
predict the resulting regime demonstrates systems resilience. 
The next challenges we need to consider in our future 
work towards a truly strong predictive capacity is greater. 
One formidable challenge in determining the optimal path to 
the desirable regime is the possibly thousands, millions or 
even astronomical number of potential paths, each with its 
own set of multiple candidate divergence. Without special 
algorithms to find the correct paths efficiently, the required 
computing time might be prohibitive. Equally challenging is 
the notion that the shortest path is not necessarily the optimal 
one. Again, the longer path may in fact possess the more 
bearable pain, trauma and adjustment compared to the 
immediate, but extreme and radical, change. Hence, what is 
significantly missing in our modeling is the quantifiable cost 
associated to each change. Although we can account for the 
actual cost accurately only in retrospect, the challenge is for 
us to find the function that can meaningfully approximate the 
cost of system adaptation and transformation. 
IV. 
IN DEFENSE OF OUR FRAMEWORK AND APPROACH 
With our world witnessing critical systemic changes [26], 
we are concerned with how our systems can be resilient, i.e., 
it is able to persist in, adapt to, or transform from 
dramatically changing circumstances. We believe that a 
deeper understanding of what fundamentally constitutes and 
leads to critical system changes sheds light on our 
understanding of the resilience of our systems. 
Our solution of mutual reinforcing between theoretic and 
data-centric models allows for less perfect theory and 
inferred models to begin with, but with both components 
learning mutually and incrementally towards improved 
accuracy. Through our meta-theory we are able to have a 
strong basis of what will constitute our machine intelligent 
modeling. What the meta-theory can take from the inferred 
models, however, is to improve its knowledge by 
incorporating the fine-grained features, e.g., changing lattice 
and γ values, as well as the magnitude of the perturbations, 
which can have specific influences towards specific regimes. 
The meta-theory has to incrementally improve its knowledge 
based on what is being discovered by the intelligent 
modeling component. Our theoretic and data-centric models 
will surely need to co-evolve as we collect more data with 
increased range of network parameter values, other ways of 
introducing perturbations, using different transition schemes 
[16], and with agents having multiple states [45], among 
others. Furthermore, as nonlinear and unpredictable system 
intricacies become more detailed and pronounced, our 
machine intelligent modeling should account for emerging 
algorithmic and data complexities. This mutual reinforcing 
of theory and intelligent models is not found even in well-
established frameworks, such as the Adaptive Cycle [21], 
Self-organized Criticality [2], and Dual-Phase Evolution [41].  
Our framework is data-centric as opposed to using formal 
verifications. We can argue that formal or mathematical 
verification does not always guarantee reality and is not 
absolutely reliable. It can even fall short given the 
computational intractability of complex systems. The 
intractability of a complex system state space leads to issues 
of big data, which is where machine learning inference 
becomes viable. Furthermore, formal models tend to abstract 
109
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

much of the realistic nonlinear and stochastic intricacies of 
the system’s internal workings [37].  
Due to the absence of our intended real world complex 
system data, we simulated the viability of our framework 
using random Boolean networks (RBNs). If RBNs are in fact 
general models of complex systems, then our simulations 
would have sound basis – which is actually the case. RBNs 
are models of self-organization in which both structure and 
function emerge without explicit instructions [54]. Secondly, 
it is by the random nature of RBNs, albeit the transition 
functions are fixed, that systemic behaviors that emerge from 
known 
individual 
component 
behaviors 
cannot 
be 
determined a priori (e.g., exact number and characteristics of 
possible basins of attractions). All these and that a RBN’s 
“infusion of historical happenstance is to simulate reality” 
[11, p.88] may attest to the fact that our meta-theory being 
demonstrated by RBNs is not at all forced. 
Lastly, we also believe that our proposed framework’s 
contribution is to help solve the problem of persistently 
having linear, fragmented and incomplete knowledge in our 
theories and models. This insufficiency of knowledge is 
because our system and the contexts that engulf it are 
complex, indeed chaotic, and their behaviors are nonlinear, 
spanning multiple simultaneous temporal and spatial scales, 
and with large interrelations and interdependencies among 
variables. And even though we are fully cognizant of their 
non-computable aspects [7][15], we continue to wrap our 
minds around what is only computable [7]. All these lead to 
shallow and disconnected understanding of the evolving 
nature of our systems and the phenomena that consist and 
embed them. We address this problem by having knowledge 
integration and incremental learning in our framework, i.e., 
(i) the integration of transdisciplinary knowledge via our 
meta-theory, (ii) the integration into data-centric models of 
low-level signals or features of various phenomena that are 
endogenous (e.g., interdependencies, dynamism, topology, 
connectivity, etc.) and exogenous (e.g., perturbations) to the 
complex system, and (iii) the mutual reinforcing and 
incremental 
knowledge 
learning 
of 
the 
meta-theory 
(theoretic) and intelligent models (data-centric) that shall 
lead to increased predictive isomorphism [33][34]. 
V. 
CONCLUSION 
We argued for a framework that characterizes what 
fundamentally constitutes complex system change by 
cohesively integrating concepts in complexity, chaos, self-
organization and critical transition theories into one meta-
theory. The meta-theory states that what comprises system 
change are the changing contexts, the fitness of the system to 
continuously evolve, and the capacity of the system to evolve 
its understanding and manipulation of the context. 
We then argued for the use of networks and machine 
learners to quantitatively explain what leads to system 
change and how the system can adapt to and transform 
through change. Our network-centric analyses show that the 
ability by which the system can vary, adjust or modify its 
controlling variables, specifically those that pertain to the 
connectivity, dynamism, topology, and sphere of influence 
of its components (all endogenous), and its capacity to 
withstand the disturbances (exogenous) that perturb it, will 
dictate the rules of its adaptation and transformation. We 
obtained these rules as relations of system controlling 
variables by mining the data using ML algorithms instead of 
the conventional abstract mathematical formulations. 
The meta-theory and intelligent modeling link will need 
to evolve as we collect more data with increased range of 
system endogenous and exogenous parameter values and 
more ways of introducing perturbations. 
REFERENCES 
[1] R. Albert and A.-L. Barabási, “Dynamics of complex 
systems: scaling laws for the period of boolean networks,” 
Phys. Rev. Lett., vol. 84, no. 24, June 2000, pp. 5660-5663. 
[2] P. Bak, How Nature Works: The Science of Self-Organised 
Criticality. New York, NY: Copernicus Press, 1996. 
[3] A.-L. Barabási and E. Bonabeau, "Scale-free networks," 
Scientific American, vol. 288, no. 5, May 2003, pp. 60-69. 
[4] R.C. Barros, M.P. Basgalupp, D.D. Ruiz, A.C.P.L.F. de 
Carvalho, and A.A Freitas, "Evolutionary model tree 
induction," Proc. ACM Symposium on Applied Computing 
(SAC ’10), 2010, pp. 1131-1137. 
[5] Ö. Bodin and Maria Tengö, “Disentangling intangible social-
ecological systems,” Global Environmental Change, vol. 22, 
no. 2, May 2012, pp. 430-439. 
[6] J. Bohn, V. Coroamă, M. Langheinrich, F. Mattern, and M. 
Rohs, “Social, economic, and ethical implications of ambient 
intelligence 
and 
ubiquitous 
computing,” 
in 
Ambient 
Intelligence, W. Weber, J.M. Rabaey, and E. Aarts, Eds. 
Springer Berlin Heidelberg, 2005, pp. 5-29. 
[7] S.R. Carpenter, C. Folke, M. Scheffer, and F. Westley, 
“Resilience: accounting for the noncomputable,” Ecology and 
Society, vol. 14, no. 1, article 13, 2009. Available online 
from: 
http://www.ecologyandsociety.org/vol14/iss1/art13/ 
2015.03.05 
[8] S.R. Carpenter et al., “General resilience to cope with extreme 
events,” Sustainability, vol. 4, 2012, pp. 3248-3259. 
[9] J. Casti, X-Events: The Collapse of Everything. New, York, 
NY: HarperCollins Publishers, 2012. 
[10] L. Chelleri, J.J. Waters, M. Olazabal, and G. Minucci, 
“Resilience trade-offs: addressing multiple scales and 
temporal aspects of urban resilience,” Environment & 
Urbanization, 2015, pp. 1-18. Available online from:  
http://eau.sagepub.com/content/early/2015/01/09/0956247814
550780.full.pdf+html 2015.03.05 
[11] R.S. Cohen, “How useful is the complexity paradigm without 
quantifiable data? A test case: the patronage of 5th-6th century 
Buddhist caves in India,” in Chaos and Society (Frontiers in 
Artificial Intelligence and Applications), A. Albert, Ed. 
Amsterdam, The Netherlands: IOS Press, 1995, pp. 83-99. 
[12] J.P. Crutchfield, "The hidden fragility of complex systems – 
consequences of change, changing consequences," in Cultures 
of Change: Social Atoms and Electroniuc Lives, G. Ascione, 
C. Massip, J. Perello, Eds. Barcelona, Spain: ACTAR D 
Publishers, 2009, pp. 98-111. 
[13] J. Diamond, Collapse: How Societies Choose to Fail or 
Survive. England: Penguin Publishing Group, 2011. 
[14] C. Folke et al., "Resilience thinking: integrating resilience, 
adaptability, and transformability," Ecology and Society, vol. 
15, no. 4, article 20, 2010. Available online from: 
http://www.ecologyandsociety.org/vol15/iss4/art20/ 
2015.03.05 
[15] T.B. Fowler and M.J. Fischer, Eds., Rare Events: Can We 
Model the Unforeseen? Sigma, vol. 10, no. 1. Noblis, 
September 
2010. 
Available 
online 
from: 
110
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

http://www.noblis.org/noblis-media/20f758e0-b3b9-4b76-
8b81-4cde0d7341f9 2015.03.05 
[16] C. Gershenson, "Updating schemes in random Boolean 
networks: do they really matter?" Proc. Ninth International 
Conference on Simulation and Synthesis of Living Systems 
(Artificial Life IX). MIT Press, 2004, pp. 238-243. 
[17] C. Gershenson, "Guiding the self-organization of random 
Boolean networks," Theory in Biosciences, vol. 131, no. 3, 30 
Nov 2011, pp. 181-191. 
[18] M. Göndör and V.P. Bresfelean, “REPTree and M5P for 
measuring fiscal policy influences on the Romanian capital 
market 
during 
2003-2010,” 
International 
Journal 
of 
Mathematics and Computers in Simulation, vol. 6, no. 4, pp. 
378-386, 2012. 
[19] I. Harvey and T. Bossomaier, "Time out of joint: attractors in 
asynchronous random Boolean networks," Proc. Fourth 
European Conference on Artificial Life, 1997, pp. 67-75. 
[20] K.A. Hawick, H.A. James, and C.J. Scogings, “Simulating 
large random Boolean networks,” Res. Lett. Inf. Math. Sci., 
vol. 11, 2007, pp. 33-43. 
[21] C.S. Holling, "Understanding the complexity of economic, 
ecological, and social systems," Ecosystems, vol. 4, no. 5, 
2001, pp. 390-405. 
[22] S.A. Kauffman, "Metabolic stability and epigenesis in 
randomly constructed genetic nets,” Journal of  Theoretical 
Biology, vol. 22, no. 3, March 1969, pp. 437-467. 
[23] S.A. Kauffman, “Antichaos and adaptation,” Scientific 
American, vol. 265, no. 2, August 1991, pp. 78-84. 
[24] S.A. Kauffman, The Origins of Order: Self-Organization and 
Selection in Evolution. New York, NY: Oxford University 
Press, 1993. 
[25] C.G. Langton, “Computation at the edge of chaos: Phase 
transitions and emergent computation,” Physica D, vol. 42, 
1990, pp. 12-37. 
[26] R. Legaspi, H. Maruyama, R. Nararatwong, and H. Okada, 
“Perception-based resilience: accounting for the impact of 
human perception on resilience thinking,” Proc. 2014 IEEE 
Fourth International Conference on Big Data and Cloud 
Computing, December 2014, pp. 547-554. 
[27] T.G. Lewis, Bak’s Sand Pile: Strategies for a Catastrophic 
World. Williams, CA: Agile Press, 2011. 
[28] J.T. Lizier, S. Pritam, and M. Prokopenko, "Information 
dynamics in small-world Boolean networks," Artificial Life, 
vol. 17, no. 4, Fall 2011, pp. 293-314. 
[29] P.H. Longstaff, T.G. Koslowski, and W. Geoghegan, 
“Translating 
resilience: 
a 
framework 
to 
enhance 
communication and implementation,” Proc. 5th International 
Symposium on Resilience Engineering, June 2015.  
[30] A.M. Machado and A.L.C. Bazzan, "Self-adaptation in a 
network of social drivers: using random Boolean networks," 
Proc. Workshop on Organic Computing, 2011, pp. 33-40. 
[31] P. Martin-Breen and J.M. Anderies, “Resilience: a literature 
review,” The Rockefeller Foundation, September 18, 2011. 
Available 
online 
from: 
http://www.rockefellerfoundation.org/blog/resilience-
literature-review 2015.03.05 
[32] H. Maruyama, R. Legaspi, K. Minami, and Y. Yamagata, 
“General resilience: taxonomy and strategies,” Proc. IEEE 
2014 International Conference and Utility Exhibition on 
Green Energy for Sustainable Development (ICUE), IEEE 
Press, March 19-21 2014, pp. 1-8, ISBN: 978-1-4799-2628-2. 
[33] B. McKelvey, "Towards a Campbellian realist organization 
science," in Variations in Organization Science: In Honor of 
Donald T. Campbell, J.A.C. Baum and B. McKelvey, Eds.,  
Thousand Oaks, Calif: SAGE Publications, 1999, pp. 383-411. 
[34] B. McKelvey, "Self-Organization, complexity catastrophe, 
and microstate models at the edge of chaos," in Variations in 
Organization Science: In Honor of Donald T. Campbell, 
J.A.C. Baum and B. McKelvey, Eds.,  Thousand Oaks, Calif: 
SAGE Publications, 1999, pp. 279-307. 
[35] D. Meadows, J. Randers, and D. Meadows, Limits to Growth: 
The 30-Year Update. White River Junction, VT: Chelsea 
Green Publishing Company, 2004. 
[36] M. Mitchell, P.T. Hraber, P.T., and J.P. Crutchfield, 
“Revisiting the edge of chaos: evolving cellular automata to 
perform computations,” Complex Systems, vol. 7, no. 2, 1993, 
pp. 89-130. 
[37] F. Morrison, The Art of Modeling Dynamic Systems: 
Forecasting for Chaos, Randomness and Determinism. 
Mineola, NY: Dover Publications, 2008. 
[38] C. Müssel, M. Hopfensitz, and H.A. Kestler, BoolNet 
package vignette, 2014. Available online from: http://cran.r-
project.org/web/packages/BoolNet/vignettes/BoolNet_packag
e_vignette.pdf 2015.03.05 
[39] N.H. Packard, “Adaptation toward the edge of chaos,” in 
Dynamic Patterns in Complex Systems, J.A.S. Kelso, A.J. 
Mandell, M.F. Shlesinger, Eds. Singapore: World Scientific, 
1988, pp. 293-301. 
[40] S.E. Page, Diversity and Complexity. Princeton, NJ: 
Princeton University Press, 2011. 
[41] G. Paperin, D.G. Green, and S. Sadedin, "Dual-phase 
evolution in complex adaptive systems," Journal of the The 
Royal Society Interface, vol. 8, no. 58, 2011, pp. 609-629. 
[42] C. Perrow, Normal Accidents: Living with High Risk 
Technologies. Princeton, NJ: Princeton Univ Press, 1999. 
[43] S. 
Poslad, 
Ubiquitous 
Computing: 
Smart 
Devices, 
Environments and Interactions. Wiley, 2009. 
[44] M. Scheffer et al., "Anticipating critical transitions," Science, 
vol. 338, no. 6105, 19 October 2012, pp. 334-348. 
[45] R.V. Solé, B. Luque, and S. Kauffman, “Phase transitions in 
random networks with multiple states,” Technical Report 00-
02-011, Santa Fe Institute, 2000. 
[46] J.A. Tainter, The Collapse of Complex Societies. Cambridge, 
UK: Cambridge University Press, 1988. 
[47] N.N. Taleb, The Black Swan – The Impact of the Highly 
Improbable. New York: Random House, 2007. 
[48] T. Taylor, "Exploring the concept of open-ended evolution," 
Proc.Thirteenth International Conference on the Simulation 
and Synthesis of Living Systems (Artificial Life 13), C. 
Adami, D.M. Bryson, C. Ofria, and R.T. Pennock, Eds. MIT 
Press, 2012, pp. 540-541. 
[49] E. Thelen, "Dynamic systems theory and the complexity of 
change," Psychoanalytic Dialogues vol. 15, no. 2, 2005, pp. 
225-283. 
[50] R. Valerdi et al., “A research agenda for systems of systems 
architecting,” Int. J. of System of Systems Engineering, vol. 1, 
no. 1/2, 2008, pp. 171-188. 
[51] Weka 3: Data Mining Software in Java. Available online 
from: 
http://www.cs.waikato.ac.nz/ml/weka/index.html 
2015.03.05 
[52] T. Zhou, B.-H. Wang, P.-L. Zhou, C.-X. Yang, J. Liu, "Self-
organized Boolean game on networks," Physical Review E, 
vol. 72, no. 046139, 28 October 2005, pp. 1–6. 
[53] A. Zolli and A.M. Healy, Resilience: Why Things Bounce 
Back. New York, NY: Free Press, July 2012. 
[54] H. Atlan, F. Fogelman-Soulie, J. Salomon, and G. Weisbuch, 
“Random Boolean Networks,” Cybernetics and Systems: An 
International Journal, vol. 12, nos. 1-2, 1981, pp. 103-121. 
 
111
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-399-5
ICONS 2015 : The Tenth International Conference on Systems

