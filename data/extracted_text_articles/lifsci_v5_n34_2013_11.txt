Multimodal Cognitive Nonverbal and Verbal 
Interactions: the Neurorehabilitation of Autistic 
Children Via Mobile Toy Robots  
Irini Giannopulu 
Cognitive Neuroscience 
Pierre & Marie Curie University 
email: igiannopulu@psycho-prat.fr 
!
Abstract—Multimodal cognitive nonverbal processes could 
be thought as a building block from which emotional and 
verbal expressions could emerge. With the intention to 
explore this hypothesis, we studied the interaction between 
autistic children and mobile toy robots during free 
spontaneous game play both quantitatively and qualitatively. 
Cognitive nonverbal criteria (eye contact, touch, 
manipulation, and posture) were analyzed, firstly in a dyadic 
interaction and secondly in a triadic interaction. The 
frequency of nouns and verbs including those which express 
positive emotion was figured out only in dyadic interaction. 
Once the cognitive nonverbal state between the child and the 
robot established, the child interacts with a third person 
displaying positive emotion. A positive correlation exists 
between multimodal cognitive nonverbal processes and 
verbal expression when the free game play with the robot is 
possible. This data suggests that in free spontaneous game 
play (i.e., ecological situation) the mobile toy robots could be 
used as a neural orthesis to enhance severe, middle and 
moderate autistic children’s brain multimodal activity. The 
findings allow us to infer that this neural orthesis could pave 
the way for the development of synergistic dialogues between 
autistic children and human environment.  
Keywords-multimodal verbal and nonverbal interactions; 
autism; mobile toy robots; free game play; positive emotion; 
neural orthesis. 
!
I. INTRODUCTION 
Robots are utilized in training, and education of 
autistic children. The studies we develop aim to analyze 
the multimodal cognitive nonverbal and verbal 
interactions of autistic children, during free game play 
with mobile toy robots [1].  
Autism spectrum disorder is a complex and 
heterogeneous neurological disorder that affects cognitive 
functioning but also emotional, social behavior and 
language development [2]. Language problems appear 
early and persist. Severe autistic children do not develop 
expressive language. However, when the children do 
acquire expressive language, it is often lacking any depth, 
it is echolalic and it is characterized by an absence of 
imagination [3]. Genetic studies have highlighted the 
complexity of the genetic architecture underlying autism. 
They consider autism as a complex multifactor disorder 
involving many genes [4], [5], [6]. These studies have 
given rise to new insights into neuronal circuits relevant to 
autism disorders. Post-modern analysis had demonstrated 
evidence of altered brain development, which strongly 
affects the formation of a multimodal neural network. The 
analysis shown that the neural substrate underlying 
cognitive, social, emotional and linguistic impairment 
involves multimodal areas such as the exterior superior 
temporal sulcus [6], the interior temporal lobe, amygdala 
included [7], as well as the ventral part of the prefrontal 
cortex, i.e., orbitofrontal cortex [8]. The autistic brain is 
also characterized by aberrant brain connectivity and 
disruption of white matter tracts between temporal regions 
[9], which disrupt verbal and nonverbal acquisition, 
consolidation as well as social interaction [10], [11], [12], 
[13]. These functional studies provide the basis for 
concluding that in autism the more impaired cortical areas 
are those that are involved in complex cognitive functions 
such as perception, social interaction, emotion and 
language. Such complex expression of autism necessitates 
a more generic consideration of this disorder at the 
multimodal neural level. 
Developmentally speaking, the most widely accepted 
hypothesis in autism is the theory-of-mind deficit [14]. 
Even if this theory cannot account for the whole spectrum 
of autistic disorders, it raises many issues that not only 
involve mental representation of others but also social 
skills such as posture [15], eye contact [16], touching [9] 
and manipulation [17] that express social interaction [18]. 
Game play is a very important feature of early 
childhood and is of particular importance for children 
with autism. Play in children with autism is more like 
"learned routine" rather than "spontaneous" [19]. Autistic 
children show difficulty in their play activities, which 
could be associated with their deficit in cognitive, and 
emotional development, i.e., multimodal cognitive 
nonverbal and verbal interactions. Free game play 
characterized by spontaneity could allow children with 
autism the possibility to express themselves and engage in 
satisfying social activity, which in turn, could lead to 
development of their cognitive nonverbal and verbal skills 
[20], [21], [22]. 
Different approaches are being utilized to better 
understand the capacity of autistic children to interact 
with a robot [23]. The Aurora’s project aim was to create a 
tool based on an autonomous robot (e.g., Labo-1, Kaspar, 
Robota doll) that convinces autistic children to engage in 
a process of interaction [24], [25], [26] [27]. A sensitive 
robot named Tito was employed in social interaction [28], 
[29]. Keepon, a very small fixed robot, can capture and 
maintain visual contact with the child [30]. Roboto uses 
the form of an animated face (mouth, eyebrows, eyes) to 
cause behavior imitation [31]. The dinausor Pleo seems 
214
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

reinforce social behavior [32]. All these studies have 
shown that animated robots, humanoid or not, using 
different stimulation encourage interaction in autistic 
children. Even if quantitative metrics of social response 
for autism diagnosis including robots were developed 
[33]; only one study has used a quantitative technique for 
analyzing dyadic (child-robot) interaction for autism 
therapy [34]. With the exception of Labo-1 in the Aurora 
project, and Roball in Michaud's project so far, only fixed 
robots have been utilized reducing the child’s spontaneity 
and self– expression in game play. 
We used a mobile toy robot named “GIPY 1” (Figure 
1), which incites the child to engage in interaction. On the 
hypothesis that autistic children will be in quasi-constant 
interaction with the robot, the cognitive behavior of severe 
autistic children in interactive activities with a robot, i.e., 
dyadic interaction, during spontaneous game play using 
multimodal cognitive nonverbal criteria was analyzed. In 
addition, we hypothesized that once dyadic interaction is 
established, the child could use the robot as a mediator to 
initiate the interaction with the third person, an adult, and 
express emotion, i.e., triadic interaction. This cognitive 
and emotional interaction of the autistic child with a third 
person was investigated, once again, in spontaneous, free 
game play by means of a multimodal approach.  
Under the hypothesis that multimodal cognitive 
nonverbal interactions could be thought of as the building 
block from which expressive language could emerge, we 
used a new mobile toy robot named “POL” (Figure 4), 
which incites the middle and moderate autistic children to 
engage in dyadic (i.e., child-robot) interaction and express 
language. The relationship between multimodal cognitive 
nonverbal criteria (visual, tactile, manipulation and 
posture) with verbal behavior (including positive or 
negative emotion) was analyzed “with” and “without” free 
game play.  
The present studies are part of our project actually in 
progress concerning multimodal interactions in typically 
and atypically developing children using natural and/or 
artificial environments. 
Beginning with the design of the studies, we will 
continue with the analysis of the results of both 
multimodal cognitive nonverbal interactions in dyadic 
and triadic situation. Then, we will describe the 
correlation between multimodal cognitive nonverbal and 
verbal interaction in dyadic interaction before discussing 
the embodiment of multimodal information during free 
spontaneous game play between mobile toy robots and 
autistic children. 
II. METHOD  
A.
Dyadic and triadic nonverbal interaction 
1. Participants 
• Dyadic nonverbal interaction 
Four severe autistic children (3 boys and 1 girl) 
participated in this study. Their chronological ages ranged 
from 7 to 9 years old (mean 8.3 years). Their 
developmental age ranged from 2 to 4 years old. The 
children were diagnosed according to the D.S.M. IV-TR 
criteria of autism [35]. The C.A.R.S [36] had been 
administered at the age of 6 years by an experienced 
clinical psychologist. The C.D.I [37] was used to estimate 
intellectual disability (Table I). !
TABLE I. GENERAL CHARACTERISTICS OF POPULATION 
A) CHILDHOOD AUTISM RATING SCALE B) INTERNATIONAL 
CLASSIFICATION OF DISEASES 
!
 • Triadic nonverbal & emotional interaction: Case 
Study 
   “A” is a right-handed young boy. He exhibits mental 
retardation as per the C.D.I. [37]. His chronological age is 
8 years old and his developmental age is 2 years old. The 
child was diagnosed with autism when he was 3 years old 
and still displays all characteristics of autism according to 
the D.S.M IV-TR [35]. In addition, the C.A.R.S. [36] has 
shown severe autism with a score of 43 points. “A” has 
deficits in reciprocal social interactions and 
communication (speech and language), stereotyped 
behavior and restricted interests and activities.  
At the time of the experiment all of the children were 
attending special education classes of autism for both 
studies. The study was conducted in a day hospital outside 
of Paris. The experiment took place in a familiar room. 
The study was approved by the local ethics committee and 
was in accordance with the Helsinki convention. All the 
parents were formally informed and agreed to the 
participation of their children in this study. Anonymity 
was guaranteed. 
   2. Material 
      • Room 
 The room was 4.56 m by 3.34 m. A chair, a small 
wardrobe and a table on which the equipment needed for 
the framework of the study was placed (laptop and 
joystick), were used. In order to reduce the presence of 
disruptive elements and so as to avoid autistic bend, the 
room was left bare [38]. 
• Robot 
   A mobile robot, called “GIPY-1”, which is cylindrical 
shaped with a diameter of 20 cm and a height of 30 cm, 
was created for use in the experiment. A representation of 
a neutral facial expression constitutes the cladding of the 
robot: the round eyes and nose triangle were dyed olive 
green and the elliptical mouth was dyed red (Figure 1). 
Everything was covered with a transparent plastic sheet. 
The simplicity of the robot was driven by the preference 
of autistic children for simple and predictable toy design 
[39]. An operator manipulated the robot via a wireless 
remote control using a joystick connected to a laptop. The 
robot could move forward, backward and turn on itself at 
low speed. These movements were constant. 
Children
Developmental 
age
Sex
C.A.R.S 
(a)
C.D.I  
(b)
1
4
M
46.5
20 to 34
2
3.6
M
35.5
35 to 49
3
2.1
F
31.4
20 to 34
4
3.7
M
43.5
20 to 34
215
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

!
!
!
!
!!!!!!!!!!!
Figure 1. GIPY I 
!
!
• Protocol for the dyadic and the triadic interactions  
The duration of the session was 5 minutes. The robot 
was placed on the ground beforehand, in the center of the 
room, its stylized face toward the entrance. The game play 
session began as follows: when the child and the adult 
entered the room, the tele-operated robot carried out three 
movements (move forward, move back, 360° swivel). As 
in real social interaction, the child and the robot altered 
their responses. If the child approached, the robot moved 
back and conversely. If the child moved away from the 
robot, i.e., ignored the robot, the robot followed the child 
in order to attract its attention. If the child remained 
motionless, the robot approached or turned itself around in 
order to focus the attention of the child. All movements 
were standardized. 
• Analysis for the dyadic and the triadic interactions  
Two independent judges unfamiliar with the aim of 
the study completed the observations of the game play 
skills. Both performed the analyses of video sequences 
with Elan software [40]. Prior to assessing game play 
improvement, inter-judge reliability was assessed to 
ensure that both judges who analyzed videotapes were 
consistent in their analyses. Inter-judge reliability was 
assessed using intra-class coefficients to make the 
comparison between them. The inter-judge reliability was 
good (Cohen’s kappa=0.63). 
The dependent variable was the time of child-robot 
interaction for the dyadic interaction and the time of child- 
robot and adult for the triadic interaction. Accordingly, we 
calculated the duration of all the characteristics of each 
criterion. This was defined as the duration between the 
onset time and the offset time of each child’s behavior 
toward the robot. Four criteria were defined for the dyadic 
interaction: 1) eye contact, 2) touching, 3) manipulation, 
4) posture. Based on the hypothesis that cognitive 
interaction could be lead to the expression of an emotional 
state, an additional fifth criterion (5) was defined for the 
triadic interaction. This criterion was: positive emotion 
(Table II).  
!!!!!!
TABLE II. CHARACTERIZATION OF EACH CRITERION 
The duration of each criterion was calculated in 
seconds and was considered independent of the others. 
Concerning, for example, the characteristic “s/he looks at 
the immobile robot” (“eye contact”) the onset time 
corresponded to the time when the child looked at the 
robot and the offset time to the moment when the child 
looked away from the robot. We calculated the duration of 
all the characteristics of each criterion. We summed up the 
duration corresponding to each criterion. Only the total 
duration is presented in the results section. 
3. Results 
• Dyadic interaction 
   The mean time of dyadic interaction was 238.7 sec. In 
other words, the children spent nearly 80% of their time 
(156 seconds for the first, 289 seconds for the second, 269 
seconds for the third and 241 seconds for the forth child) 
playing with the robot. The duration of each robot-child 
interaction is presented in Figure 2. The duration of “eye 
contact” is similar for all the children. However, the 
analysis of the duration of “touching”, “manipulating” and 
“posture” possibly reflects inter-individual differences 
related to different forms of autism. This analysis also 
showed how autistic children’s behavioral interaction with 
the robot changes over a period of time. As such, this 
analysis suggests that in free game play a mobile toy robot 
could help autistic children to reduce repetitive and 
stereotypical behavior. 
!
!!!!
!
!
Posture
Touching
Eye contact
Manipulation
Positive 
Emotion
S/he sits 
downs in 
front 
of robot; !
S/he bends 
towards 
the robot; 
S/he bends 
over the 
robot; !
S/he squats 
and bends 
over the 
robot;  !
S/he steps 
over the 
robot
S/he puts 
the left 
hands on 
the robot; !
S/he puts 
the right 
hand on the 
robot; !
S/he 
touches the 
robot with 
both hands
S/he looks at 
the immobile 
robot; !
S/he watches 
the robot 
turning; !
S/he watches 
the robot 
going away; 
!
S/he watches 
the robot 
approaching 
S/he seizes 
and blocks the 
robot with the 
two hands; 
S/he lifts of 
the robot;  
S/he stops the 
robot  with 
both hands; 
S/he catches 
the robot;  
S/he returns 
the robot; 
S/he tilts the 
robot around 
itself and 
looks of its 
wheel; 
S/he puts back 
the robot 
upright
S/he smiles to 
the adult; !
S/he laughs to 
the adult; !
S/he expresses 
tenderness to 
the adult; !
S/he looks 
happy with 
the adult; !
S/he looks 
pleased to the 
adult
216
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 2. Duration of dyadic interaction for each criterion 
Figure 3. Duration of dyadic and triadic interactions for 
each criterion 
• Triadic nonverbal and emotional interaction 
The mean time of dyadic interaction was 25 sec; the 
mean time of triadic interaction was 30 sec. In other 
words, the child spends half the time playing with the 
robot and the half the time playing with the robot and the 
adult. 
The duration of dyadic and triadic interaction is 
presented in Figure 3. The duration of “eye contact” and 
of “touching” is similar in both situations. However, the 
duration of “manipulation”, of “posture” and of “positive 
emotion” differs between the two situations. As we can 
observe, positive emotion is more easily expressed when 
the child interacts with the adult and the robot than when 
the child interacts only with the robot. This difference 
reflective of the changes in autistic child behavior with the 
robot over a period of time also tells us that a mobile 
robot could be used as a mediator for social and emotional 
interaction. This is an encouraging conclusion with regard 
to the potential of human-to-human interaction. 
B. Dyadic verbal and nonverbal interaction 
1. Participants 
Eleven children (8 boys and 3 girls) participated in 
this study. Their chronological ages ranged from 7 to 8 
years old (mean 7.3 years; sd 6 months); their 
developmental age ranged from 5 to 6 years old (mean 6 
years; sd 4 months). The mean age when first words 
appeared was 38 months (sd 5 months). The children were 
diagnosed according to the DSM IV-TR criteria of autism 
[20]. The Childhood Autism Rating Scale [21] had been 
administrated at the age of 6 years by an experienced 
psychiatrist. The present population is composed by 
middle and moderate autistic children. They were all 
verbal (Table III). The study was approved by the local 
ethics committee and was in accordance with the Helsinki 
convention. All the parents were formally informed and 
agreed to the participation of their children in this study. 
Anonymity was guaranteed. 
TABLE III. GENERAL CHARACTERISTIC OF POPULATION 
A. CHILDHOOD AUTISM RATING SCALE 
!!
2. Material  
• Robot 
A mobile robot, called “POL”, which is animal-
shaped, was used: a mobile chicken (Figure 4). An 
operator manipulated the robot via a wireless control. 
• Protocol 
The study was conducted in two day hospitals: one 
outside and one inside of Paris. The experiment took place 
in a familiar room to all the children. We have defined two 
conditions: one “with” and another “without” game play. 
“Without game play”: Children’s observation 
behavior with the immobile robot placed on the ground 
beforehand, in the center of the room. There is no game 
play session.  
“With game play”: Children’s observation with the 
mobile robot. The robot was placed on the ground 
beforehand, in the center of the room. The game play 
session was unfolded as in the previous studies (see the 
protocol described previously).  
The two conditions were counterbalanced across the 
children. The inter-condition interval was about 2 
minutes. The duration of each condition was 10 minutes. 
!!
Subjects
Developmental age
Sex
C.A.R.S a
1
5.7
M
34
2
6.2
M
35
3
5.6
F
32
4
6.5
M
36
5
5.9
M
36
6
6.7
M
34
7
5.8
F
32
8
6.7
M
36
9
5.7
F
34
10
5.7
M
33
11
5.5
M
35
seconds
0
22
44
66
88
110
eye contact
touching
manipulation 
posture
child 1
child 2
child 3
child 4
seconds
0
10
20
30
40
50
60
70
80
90
positive emotion
touching
posture
dyadic situation
triadic situation
manipulation
eye contact
217
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 !!!!!!!!!!
Figure 4. Child during game play with “POL“ robot 
!
• Analysis  
In both conditions, two dependent variables (DV) 
were utilized: a) the duration of child-robot interaction; b) 
the frequency of nouns and verbs expressed by the 
children.  
For the first DV, four criteria defined as in the 
previous analysis (dyadic and triadic nonverbal 
interaction). As in the above studies, we have measured 
the duration of all the characteristics of each criterion 
(Table II). 
For the second DV, we have calculated the frequency 
of nouns and verbs, i.e., expressive language.  
As in our previous studies, two independent judges 
unfamiliar with the aim of the study completed the 
observations of the whole protocol (“with” and “without” 
game play) performing the analyses of video sequences 
with Elan software [40]. The inter-judge reliability was 
good (Cohen’s kappa =0.67).  
!
3. Results 
The distribution of duration according to the criteria 
in the two conditions approximates a non parametric 
shape. With such distribution, the median has been chosen 
as a central index for the comparisons. The statistical 
comparisons have been conducted with the Chi-Square 
Test (χ2 Test); relationship between cognitive nonverbal 
and verbal interactions was analyzed with the 
nonparametric Spearman rank correlation coefficient 
(Spearman’s ρ correlation coefficient).  
In “without game play” condition, the children 
interact less with the robot (1 minute and 57 sec) than in 
“with game play” (8 minutes and 40 seconds) (χ2=6.89, 
p<0.01). The results show that the median duration of 
“eye contact” is longer in the “with game play” condition 
(4.27 sec) than in the “without game play” (1.48 sec) 
(χ2=7.12, p<0.01). Similarly, the median duration of 
”touching”, “manipulating” and “posture” is higher in 
“with game play” condition than in “without game play” 
condition, i.e., 2.36 sec vs. 1.24 sec; 1.16 sec vs. 0.66 sec; 
1.51 sec vs. 0.97 sec respectively; (χ2=6.07, p<0.025; 
χ2=4.7, p<0.05; χ2=4.01, p<0.05 respectively) (Figure 5). 
!!!!!!!!
!!!!!!!!!!!!!!!!!!!
Figure 5. Duration of multimodal cognitive nonverbal 
interactions 
!!!!!!!!!!!!!!!!!
       !
Figure 6. Median frequency of nouns and verbs!
!
As the Figure 6 shows verbal expression was more 
frequent in “with game play” condition (7.45 median 
frequency for nouns; 4.36 for verbs) than in “without 
game play” condition (0.73 median frequency for nouns; 
0.64 for verbs) (χ2=7.16, p<0.01 for the nouns; χ2=6.99, 
p<0.01 for the verbs) (Figure 3). Only in “with game 
play” condition, the children express three nouns (nice, 
beautiful, good) and one verb (like), which involve 
positive emotion (χ2=3.99, p<0.05 for the nouns; χ2=3.88, 
p<0.05 for the verbs).  
!!!!!!!!!!
median duration time and IQR / minutes
0
1
2
3
4
eye contact
touching
manipulation
posture
without game play
with game play
median frequency and IQR 
0
3
7
10
nouns
verb
without game play
with game play
218
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

!!!!!!!!!!!!!!!!!!!!!
Figure 7. Relation between multimodal cognitive nonverbal 
and verbal (positive and neutral) information 
!
A positive correlation exists between expressive 
language (nouns and verbs) and multimodal cognitive 
information in the “with game play” condition 
(Spearman’s ρ correlation coefficient=0.747, p=0.01 one-
tailed Test) (Figure 7). 
In contrast, there is no positive correlation between 
expressive language (nouns and verbs) and multimodal 
cognitive information in “without game play” condition 
(Spearman’s ρ correlation coefficient=0.23, p >0.05 one-
tailed Test). 
!
III. DISCUSSION 
!
• Dyadic nonverbal interaction 
Consistent with our hypothesis, the children were 
quasi-constantly in interaction with the mobile robot using 
a variety of ways. As autism is a spectrum disorder where 
a large variation in abilities and interests among autistic 
children is apparent, the interaction of children and robots 
was evaluated on the level of each individual child. 
Coherent with various studies, the present study shows 
that the use of robots engages autistic children in 
interaction [25], [29-32], [41-44]. In our case, we have 
computed the duration of robot-child cognitive nonverbal 
interaction during free, spontaneous game play. By doing 
so, the behavior of autistic children vis-a-vis the robot 
based on four nonverbal criteria has been analyzed and a 
temporal quantification of dyadic interaction with respect 
to the duration was performed. The analysis revealed that 
the duration of “eye contact” behavior was similar for 
each child. Inter-individual differences were identified for 
the duration of “touching”, “manipulating” and “posture” 
behavior. These differences might be related to different 
expression of autism. The data demonstrated that the 
autistic children not only visually explored the robot [34] 
but also engaged in different kinds of play with the robot. 
In other words, the autistic children seem take an interest 
in playing  with the mobile robot. It seems that free game 
play could be a relevant ecological situation, i.e., near to 
everyday life, where an autistic child spontaneously 
interacts with the robot. Moreover, mobile toy robot could 
help autistic children to reduce repetitive and stereotypical 
behavior. These findings also reveal that free, spontaneous 
game play with robots is possible with severe autistic 
children and could better facilitate the transfer of social 
and learnt abilities to everyday life. 
Nevertheless, what is important to demonstrate is 
whether and how autistic children could generalize learnt 
abilities during play with the robot to adults, i.e., proving 
that the robot could be used as a neural mediator tool for 
the enrichment of child-human interaction. This later 
assumption has been analyzed using a triadic approach. 
!
• Triadic nonverbal and emotional interaction 
   In this case study, we analyzed the ingredients of child-
robot two-pronged interaction and child-robot-adult three-
pronged interaction. Consistent with our hypothesis, the 
child first establishes a relationship with the robot and 
then uses the robot as an “instrument” to initiate the 
interaction with the adult (study 3). At first glance, our 
results are compatible with recent findings according to 
which the presence of a robot, are more effective than 
other environments in allowing autistic children to express 
social interest towards the robot [27-28], [30], [39], 
[45-46]. In these studies, researchers have used robots for 
treating autistic children. However, the relationship 
between robot and child has been studied solely based on 
the analysis of a single mode of interaction. Furthermore, 
the studies have been conducted using fixed robots. Our 
results go beyond these findings because we have 
demonstrated, as far we know for the first time, that in 
spontaneous, free game play, an autistic child uses the 
robot to interact with the adult and to express positive 
emotion. As such, on the one hand, we have shown that 
the dyadic interaction is based on a cognitive state and, on 
the other, that the child uses the robot as a mediator to 
express positive emotion playing with the adult. 
More precisely, in this study, as in our previous 
studies [47-48], we have demonstrated that visual, haptic, 
tactile perception and posture, i.e., multimodal perception, 
are on the basis of the interest the child displays towards 
the robot. This is because, in our approach (as in Quinn & 
Eimas approach [53]), perception and cognition are 
considered to be a single domain rather than two distinct 
entities. The criteria we have chosen are assumed to 
represent the state of the child's cognitive nonverbal 
processes, as expressed by the interest the child exhibits 
towards the robot in spontaneous, free game play. As the 
present study has shown, once this state is established, the 
child develops a triadic relation, i.e., with the robot and 
the adult, thereby displaying enjoyment, which is a 
positive emotion. The expression of positive emotion 
could be related to the emergence of a cognitive state, 
which is multimodal in our case. This expression appears 
when the child interacts with the adult using the robot. In 
our study, the child “A” is in constant interaction with the 
robot, expressed by a multimodal cognitive state that, 
according to us, allows him to express positive emotion 
with the adult. When “A” interacts with both the robot and 
the adult, he changes his behavior. We think that the robot 
as a mediator could bring about neurocognitive 
improvements to the autistic child. 
rang of multimodal cognitive interaction
0
2
4
6
8
10
rang of verbal expression
0
2
3
5
6
8
219
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

In both studies, the findings seem indicate that free 
game play, i.e., near to everyday life, encourages an 
autistic child to interact with the robot in a spontaneous 
manner and could reduce repetitive and stereotypical 
behavior. They also reveal that free, spontaneous game 
play with robots is possible with autistic children and 
could better facilitate the transfer of learnt abilities to 
everyday life. 
One limitation of these studies is the small number of 
autistic children, which makes impossible inferential 
analysis. Additional studies are required with a substantial 
number of children. We also need to confirm the 
importance of free game play in improving children’s 
nonverbal but also verbal performances. In that context, 
we have explored the multimodal cognitive nonverbal and 
verbal interactions between a mobile toy robot and autistic 
children with and without free game play.  
!
• Dyadic verbal and nonverbal interaction 
  In that study, our results indicated that the duration 
of multimodal cognitive nonverbal interactions (visual 
contact, manipulation, touching, posture) is longer when 
free spontaneous game play with the robot is possible 
(with game play condition) than when game play is 
impossible (without game play condition). Consistent with 
the studies presented here above, these new results show, 
once again, that a mobile toy robot engages autistic 
children in multimodal nonverbal interactions (visual, 
tactile, manipulation, posture). Taken together, these 
studies seem demonstrate that autistic children’s 
behavioral interaction with a mobile robot changes over a 
period of time. Free game play, which is very close to a 
everyday life situation, encourages autistic children to 
interact with the robot in a spontaneous manner [22].  
  Coherent with the above is the fact that language is 
expressed only during free game play. Even if the children 
of our study suffer from middle or moderate autism and 
are verbal, these results show that the expression of 
language is possible when the children interact with the 
robot (in free game play) using a multimodal mode. In the 
same vein, children produced three nouns and one verb, 
which connote positive emotion only during game play. 
Moreover, positive correlation between multimodal 
cognitive nonverbal information and verbal expression is 
significant when the children spontaneous interact with 
the mobile robot: the more the multimodal nonverbal 
interaction, the more the verbal expression. As such, these 
results are consistent with our hypothesis suggesting that 
multimodal cognitive nonverbal interactions could be 
considered as the basis of verbal expression. 
• Dyadic, triadic verbal, nonverbal and emotional 
interaction 
The present three studies seem indicate that mobile 
robots could not only be used as a mediator for nonverbal 
[48] and emotional interaction ([1], [22], [50], [51]) but 
also for verbal expression ([52]), which is the 
distinguishing characteristic of the inter-human 
communication. This is a comforting issue with regard to 
the potential of human-robot interaction. As such, the data 
suggests, that more mobile that immobile robots could be 
efficient for training, education and neurorehabilitation of 
autistic children. In other words, an artificial environment 
such as mobile toy robots could provide the source of 
emergence of multimodal cognitive nonverbal 
information, which in turn, could be combined with 
emotional [49], [50] and verbal information [52] in a 
coordinated manner. The mobile robots (which can be 
considered as a neural orthesis), could pave the root for 
the development of synergistic dialogues between autistic 
children and human environment. As our data has shown 
free game play (which is close to everyday life) is more 
auspicious than the absence of free game play to improve 
severe, middle and moderate autistic children’s brain 
multimodal activity.  
The reporting data converges to say that autistic 
behavior can be improved via mobile robots, i.e., artificial 
environments. This is coherent with the assumption that 
cognitive nonverbal/verbal and emotional development is 
the result of a complex process with three foci at least, 
one in the central nervous system, one in the mind and 
one in the child’s dynamic interactions with the 
environment [22]. The human brain undoubtedly has its 
own dynamic that allows neurons to interact, which in 
turn, affects the development and function of the brain 
areas [21]. In the case of autism, the brain activity is 
characterized by an hypofunctioning. An artificial 
environment like a mobile robot, i.e., neural orthesis 
seems improve the neural activity (and consequently) the 
behavior of autistic children: autistic children interact with 
the robot multimodally only in free game play (Figure 8). 
!
    Figure 8. Principle of Neurorehabilitation during free 
game play  
!
Our hypothesis is that this emerging brain 
multimodality is crucially shaped by the children’s 
interactions with the environment during free game play. 
Nonverbal cognition, language and emotion develop at the 
interface between neural processes. They arise from the 
dynamic interaction between the developing brain and the 
artificial environment, i.e., the robot [22]. 
!
Our approach, actually in progress, attempts to 
understand "how" artificial environments could be 
considered as the root of neuronal organization and 
reorganization ([21], [22]). Based on the brain’s intrinsic 
properties, neuroplasticity and the fact that the brain is 
neurodynamic, our studies try to demonstrate that a 
mobile robot could be used as a neural orthesis with the 
220
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

intention to support the embodiment of cognitive 
nonverbal, emotional and verbal information processing in 
free game play. 
!
To our knowledge, this data represents some of the 
first to analyze the relationship between multimodal 
cognitive nonverbal information and verbal expression 
during spontaneous free game play in severe, middle and 
moderate autistic children using mobile toy robots.  
!
IV. CONCLUSION 
With these studies (part of our project actually in 
progress), we have demonstrated evidence for the view 
that spontaneous free game play with toy robots could be 
a source from which the brain of autistic children can take 
advantage. This condition could become the beginning of 
most of one’s knowledge base for autistic children: visual, 
haptic, tactile perception, body posture as well as verbal 
expression. It is of great interest, particularly when 
considering that nonverbal information is probably at the 
origin of what is arguably one of the trademarks of human 
cognition: the capacity to generate thoughts and concepts 
for ourselves and for the others, which can be verbally 
expressed. To better understand the base and the nature of 
the verbal expression we observed, future studies should 
extend this work through systematic analyses within a 
larger sample of autistic children in a follow up design. 	

!
ACKNOWLEDGMENT	

The author would like to thank all the children who 
participated to the studies, their parents, ANR's supporting, as 
well as the French Department of Education.  
REFERENCES 
[1] I. Giannopulu, “Multimodal Human-Robot 
Interactions: the Neurorehabilitation of Severe 
Autistic Children,” Proceedings of the Sixth 
International Conference on Advances in Computer-
Human Interactions (ACHI), IARIA, 2013, pp. 68-73. 
[2] L. Crane, S.E. Lind, and D.M. Bowler, 
“Remembering the past and imaging the future in 
autism spectrum disorder,” Memory, vol. 21, no. 2, 
pp. 157-166, 2013. 
[3] J.B. Plavnick and S.J. Ferreri, “Establish verbal 
repertoires in children with autism using function-
based video medeling”, J Appl Beh Analysis, vol. 44, 
pp. 747-766, 2011. 
[4] L. Jorde et al. “Complex segregation analysis of 
autism,” Am. J. Hum. Genet., vol. 49, pp. 932-938, 
1991. 
[5] N.H. Sykes and J.A. Lamb, “Autism: The quest for 
the genes,” Exp. Mol. Med., vol. 9, pp. 1-15, 2007. 
[6] P. Szatmari et al. “Mapping autism risk loci using 
genetic linkage and chromosomal rearrangements,” 
Nat. Genet., vol. 39, pp. 319-328, 2007. 
[7] K.A. Pelphrey and E.J. Caster, “Charting the typical 
and atypical development of the social brain,” Dev. 
Psychopathol., vol. 20, pp. 1081-1102, 2008. 
[8] B.A. Corbett et al. “A functional and structural study 
of emotion and face processing in children with 
autism,” Psych. Res., vol. 30, 173, pp. 196-205, 2009. 
[9] L. Brothers, “The social brain: a project for 
integrating primate behaviour and neurophysiology in 
a new domain,” Concepts. Neurosc., vol. 1, pp. 27–
51, 1990. 
[10] U. Frith and C.D. Frith, “Development and 
neurophysiology of mentalizing,” Philos. Trans. R. 
Soc. London, vol. 358, pp. 459-473, 2003. 
[11] A. Saitovitch et al. “Social cognition and the superior 
temporal sulcus: Implications in autism,” Rev. Neurol. 
(Paris), 2012 Sep 13. pii: S0035-3787(12)00902-2. 
doi: 10.1016/j.neurol.2012.07.017.  
[12] R. Adolphs and D. Tranel, «Intact recognition of 
emotional prosody following amygdala damage,” 
Neuropsychol., vol. 37, pp. 1285–1292, 1999. 
[13] J.P. Aggleton, The Amygdala: A Functional Analysis. 
Oxford: University Press, 2000. 
[14] B.M. Nacewicz et al. “Amygdala Volume and 
Nonverbal Social Impairment in Adolescent and Adult 
Males with Autism,” Arch. Gen. Psychiatry., vol. 63, 
pp. 1417-1428, 2006. 
[15] U. Frith, J. Morton, and A.M. Leslie, "The cognitive 
basis of a biological disorder: autism,” TIN14, pp. 
433-438, 1991. 
[16] A.M. Leslie, “Pretending and believing: issues in the 
theory of ToMM," Cognition, vol. 50, pp. 211-238, 
1994. 
[17] T. Reed and C. Peterson, “ A comparative study of 
autistic subjects' performance at two levels of visual 
and cognition perspecctive taking,” J. Autism. Dev. 
Disord., vol. 20, pp. 555-567, 1990. 
[18] A. Escalona, T. Field, J. Nadel, and B. Lundy, “Brief 
report: Imitation effects on children with autism,” J. 
Autism. Dev. Disord., vol. 32, pp. 141-144, 2002. 
[19] B.A. Taylor et al. “Manipulating establishing 
operations to promote initiations toward peers in 
children with autism,” Res. Dev. Disabil., vol. 26, pp. 
385-392, 2005. 
[20] E. Williams, V. Reddy, and A. Costal, “Taking a 
closer look at functional play in children with 
autism,” J. Autism. Dev. Disord., vol. 31, pp. 67-77, 
2001. 
[21] I. Giannopulu, “Contribution à la compréhension des 
représentations multimodales chez l’homme sein et 
chez des patients avec atteinte neuropsychologique: 
une approche life span”. H.D.R, UPMC-Paris VI, 
2011. 
[22] I. Giannopulu, “Multimodal interactions in typically 
and atypically developing children: natural vs. 
artificial environments”, Cogn Proc., vol. 14, pp. 
323–331, 2013.  
[23] B. Scassellati, H. Admoni, and M. Mataric, “Robots 
for use in autism research,” An. Rev. Biomed. Eng., 
vol. 14, pp. 275-294, 2012.  
[24] M. Davis, B. Robins, K. Dautenhahn, C.L. Nehaniv, 
and S. Powell editors. “A comparison of interactive 
and robotic systems in therapy and education for 
children with autism,” European Conference for the 
Advancement of Assistive Technology in Europe 
(AAATE’05), pp. 353-357, September 6-9 2005, IOS 
Press Lille.  
221
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[25] F. Michaud and S. Caron, “Roball, the rolling robot,” 
Auto. Rob., vol. 12, pp. 211-222, 2002. 
[26] K. Dautenhahn, “Socially intelligent robots: 
dimensions of human-robot interaction,” Philos. 
Trans. R. Soc., vol. B.362, pp. 679- 704, 2007. 
[27] B. Robins, K. Dautenhahn, and K. Dubowski, 
“Robots as Isoalators or Mediators for children with 
autism ? A Cautionary Tale,” Proc's of the AISB 05 
Symposium on Robot Companions, pp. 82-88, 2005. 
[28] A. Duquette, F. Michaud, and H. Mercier, 
“Exploring the use of a mobile robot as an imitation 
agent with children with low- functioning autism,” 
Auto. Rob. – Special Issue., vol. 2, pp. 147-157, 2004. 
[29] F. Michaud, T. Salter, A. Duquette, and J.F. Laplante, 
“Perspectives on mobile robots used as tools for 
pediatric rehabilitation,” Assist. Technol., vol. 19, pp. 
14-19, 2007. 
[30] H, Kozima, C Nakagawa, and Y. Yasuda, “Children-
robot interaction: a pilot study in autism therapy,” 
Prog. Brain. Res., vol. 164, pp. 385-400, 2007. 
[31] J. Nadel, A. Revel, P. Andry, and P. Gaussier, 
“Toward communication: first imitations in infants, 
low-functioning children with autism and robots,” 
Inter St: Soc. Beh. Commun. Biol. Syst., vol. 5, pp. 
45-54, 2004. 
[32] E.S. Kim, L.D. Berkovits, E.P. Bernier, D. Leyzberg, 
F. Shic, R. Paul, B. Scassellati, “Social Robots as 
Embedded Reinforcers of Socail Behavior in Children 
with autism,” J Autim Dev Disord, DOI 10.1007/
s10803-012-1645-2, 2012. 
[33] B. Scassellati, “Quantitative metrics of social 
response for autism Diagnosis,” IEEE International 
Conference on Intelligent Robots and Systems, pp. 
1134-1138 vol.2, 2002. 
[34] K. Dautenhahn, and I. Werry, “A quantitative 
technique for analysing robot-human interactions,” 
IEEE/RSJ International Conference on Intelligent 
Robots and Systems, pp. 1132-1138, 2002.  
[35] DSM-IV-TR Manuel diagnostique et statistique des 
troubles mentaux, Paris, Editions Masson, 2003. 
[36] E. Schopler, R.J. Reichler, R.F. De Vellis, and K. 
Daly, “Toward objective classification of childhood 
autism: Childhood Autism Rating Scale (CARS),” 
JADD10, pp. 91-103, 1980. 
[37] International Classification of Diseases, Revision, 
10, 1990.  
[38] P. Planche E. Lemonnier, K. Moalic, C. Labous, and 
A. Lazartigues, “Les modalités de traitement de 
l’information chez les enfants autistes,” Ann. Med. 
Psychol., vol. 160, pp. 559-564, 2002.  
[39] J. Pedersen and J. Schelde, “Behavioral aspects of 
infantile autism: an ethological description”, Eur. 
Child. Adolesc. Psy., vol. 6, pp. 96-100, 1997. 
[40] M. Tacchetti, Elan Linguistic Annotator. The 
Language Archive MPI for psycholinguistics 
Nijmegen, The Netherlands. 2006.  
[41] K. Dautenhahn and I. Werry, “Towards interactive 
robots in autism therapy,” P & CT, 121, pp. 1–35, 
2004. 
[42] H. Kozima and H. Yano, Designing a robot for 
contingency- detection game. Working Notes 
Workshop Robotic & Virtual Interactive Systems in 
Autism Therapy, 2001 27-28 September, 
U.K.Hatfield. University of Hertfordshire, 2001, 
Technical Report No 364. 
[43] J. Martineau, S. Cochin, R. Magne, and C. 
Barthelemy, “Impaired cortical activation in autistic 
children: Is the mirror neuron system involved?” Int. 
J. Psychophysiol., vol. 68, pp. 35–40, 2008.  
[44] T. Salter, I.P. Werry, and F. Michaud, “Going into the 
wild in child-robot interaction studies-Issues in social 
robotic development,” Int. J. Robot., vol. 1, pp. 93-98, 
2007. 
[45] Y. Yokoyama, “The Possibility of the Psychiatric 
Treatment with a Robot as an Intervention From the 
Viewpoint of Animal Therapy,” Proc. of Joint 1st 
International Conference on Soft Computing and 
Intelligent Systems and 3rd International Symposium 
on Advanced Intelligent Systems, paper number 
23Q1-1, in CD-ROM Proc. 2002.  
[46] C. Kozima and Y. Yasuda, “Children-robot 
interaction: a pilot study in autism therapy,” Prog. 
Brain. Res., vol. 164, pp. 385-400, 2007. 
[47] I. Giannopulu and G. Pradel, Mobile toy robots can 
be used in autism therapy: an example of application. 
IEEE Proceedings in the IROS 2009 paper number 
SuT8.pdf in the workshop CD Proc. 2009a.  
[48] I. Giannopulu and G. Pradel, “Interactions 
multimodales en situation de jeu libre entre enfants 
autistes et un robot mobile”. 7ème Journée Nationale 
d e l a re c h e rc h e e n R o b o t i q u e , h t t p : / /
jnrr09.lms.sp2mi.univ poitiers.fr/IMG/pdf/
Giannopulu_Pradel. Novembre, Domaine de La 
Grande Garenne 18330 Neuvy-sur- Barangeon, 
2009b. 
[49] I. Giannopulu and G. Pradel, “Multimodal 
interactions in free game play of children with autism 
and a mobile robot,” NeuroRehabilitation., vol. 27, 
pp. 305-311, 2010. 
[50] I. Giannopulu, “Cognitive and emotional 
interactions between autistic child, mobile toy robot 
and therapist,” Front Comput Neuro, doi:10.3389/
conf.fncom.2011.52.00002, 2011. 
[51] I. Giannopulu and G. Pradel, “From child-robot 
interaction to child-robot-therapist interaction: a case 
study in autism,” Appl Bio Biomech., vol 9, pp. 
173-179, 2012. 
[52] I. Giannopulu “Embedded Multimodal Nonverbal 
and Verbal Interactions Between a Mobile Toy Robot 
and Autistic Children,” Late Breaking Paper, HRI 
2013, Proceeding of the  8th ACM/IEEE International 
Conference on Human-robot Interaction, pp. 127-128, 
IEEE Press Piscataway, NJ. USA.  
[53] P.C. Quinn and P.D. Eimas, “The emergence of 
category representations during infancy: are separate 
perceptulal and conceptual processes required?” J. 
! Cogn. Dev., vol. 1, pp. 55-61, 2000. 
!!
!!
222
International Journal on Advances in Life Sciences, vol 5 no 3 & 4, year 2013, http://www.iariajournals.org/life_sciences/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

