Use of Augmented Reality in Sport Performance Visualization: Media Tools for
Prosumers
Satu-Marja Mäkelä1, Marko Palviainen2, Markus Ylikerälä2, Johannes Peltola1
VTT Technical Research Centre of Finland Ltd.
1 Kaitoväylä 1, Oulu, Finland
2 Tekniikantie1, Espoo, Finland
e-mail:firstname.lastname@vtt.fi
Abstract—This
paper
describes
a
proof
of
concept
demonstrator and a prototype system for sport analytics, as
well as data visualization designed for sport event spectators to
get
more
insight
on
the
athletes’
performance.
The
demonstrator highlights fully scalable Augmented Reality (AR)
based sport analysis data visualization for engaging consumers
and sports fans, and gives them a possibility to become more
appealing prosumers. The aim is to combine elements of
professional sport event visualization with the crowd generated
content and social media communications. The AR sport
demonstrator consists of two main parts: a) an AR Sport
application, and b) AR Sport HTML5 Web service. The AR
Sport application is based on the embedded sensor, which is
worn by an athlete to collect acceleration data, and Android
software that analyzes movement and produces visualizations
about the sport performance. The AR Sport service uses the
NUBOMEDIA cloud computing multimedia platform with AR
capabilities and augments a user generated video stream with
athlete specific overlay data. The spectator can use the AR
Sport service via a mobile browser and view the augmented
video stream on his/her mobile device.
Keywords-augmented reality; sport analytics; visualization;
multimedia cloud computing
I.
INTRODUCTION
Augmented Reality (AR) is a technology for overlaying
artificial content to the real world view in real time. The
mainstream AR applications have often been mobile device
applications targeted for personal use, but, recently, AR
applications have also been developed for industrial use and
for maintenance and building visualization purposes. There
exist fewer applications focusing on utilizing AR for real-
time sensor information in specific Internet of Things (IoT)
environments, such as in sports analytics, where digital
devices are hidden in the environment to enable athletes to
provide information on their athletic performance.
The rise of the IoT sensors and IoT environments brings
a
lot
of
digital
information
available
for
ambient
environments, but efficient access to
this information
requires new type of user interfaces. AR will empower
bringing the services and information visualizations of
invisible digital world to our sight in real time through our
mobile devices. AR can assist the use of digital services and
the users in decision-making, being capable of representing
the services’ information directly in physical environments.
We have developed a prototype of service that is easily
accessible and scalable for an audience utilizing IoT sensor
data analysis and augmented reality visualization. In Section
III,
we
explain
how
WebRTC
based
multimedia
communication based on the NUBOMEDIA cloud platform
with AR technologies were used in the demonstrator. In
Section IV, we explain the functionalities of the AR Sports
Web service that allows a sport event spectator to receive
visualizations for athlete’s performance analysis information
augmented on the video stream. The innovation of the
system is in visual pairing of the athlete’s performance
analysis and the AR service request, and in the use of the
NUBOMEDIA cloud platform, where rendering of the
augmented information for the video stream takes place on
the
server
side.
The
system
enables
the
real
time
visualization of the data utilizing the AR technologies, as
well as a multiuser scenario in which many spectators can
easily receive information about an athlete’s performance.
II.
STATE OF THE ART
The sports domain has recently started to extensively use
sensors both in the amateur and professional level of athletes.
There exist numerous solutions for monitoring the personal
fitness and sports data from activity and physiological
signals. These solutions are mainly used for monitoring and
improving individual performance. Advanced sport analytics
is using all kinds of data for creating the insights, and
analyzing the team and its performance for the benefit of
coaching. Visualization of the analytics for a variety of
sports is also a well known topic in the research field for
team and individual performance [1][2].
Recently, the miniaturizing of the IoT sensors and
wireless signal components has also brought the sensors into
the equipment, providing very rich data sources for athletic
performance analytics. Examples include bats [3], balls [4],
and footwear [5].
Personal fitness analysis gadgets [6][7] often display the
real time analysis results on the device display or through a
smart phone. Additional Web services or mobile device
applications are also provided commonly for further analysis
and tracking of the athletic performance and achievements
1
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

[7]. On the other hand, the IoT sensors that are connected to
the sport gear are often used to produce force, position, and
acceleration information that is either shown to the person
after the action on e.g., a phone’s display or reconstructed to
the virtual animation of the event [3] [10].
For
a
long
time,
broadcasters
have
augmented
visualizations of analytics on the sport feeds to create
alluring sports visualizations either of game dynamics or of
individual performance. For example, BBC has recently
published a web article about these advances [8]. As the
sports domain is increasingly interested in innovative and
fresh tools for interactive visualization in different contexts
and purposes from individual analytics to team performance,
the topic has gained wide academic interest [1][2][12][13].
With this technology, we can bring similar informatics to the
consumer devices on the sport events and videos. At the
same time, the consumer can provide news feed to social
media and even to professionals, as they are able to catch the
moment with the analytics.
Since there are more data sources available, more
attention needs to be paid to real time visualisation of sports
data. In addition, developers should study what type of
services can be built on top of the emerging technologies.
Unifying IoT, AR and sport data analysis will provide a
potential to create new services from coaching to engaging
the fans of the athletes.
The first AR solutions running on mobile platforms were
implemented locally on the client. Until recently, this has
been the dominating way to implement mobile AR solutions
and one of the well-known bottlenecks in delivery of the AR
applications to end users. The WebRTC protocol [11] is
changing the playground for multimedia communication
systems that have AR capabilities by bringing standardized
means of real time video communication to the Web
applications. WebRTC allows use of AR services without a
need for the installation of special AR-specific software
components on a client device. Only access to Internet and
HTML5 browser is enough. This tackles one obstacle for AR
to become mainstream, as the population of supported
devices is extremely large. In addition, this means Web-
based development of AR applications is nowadays cost-
efficient and it is easy to find expertise. There are also other
approaches for Web based AR solutions, for example [14]
and [15], but they are using a modified browser to achieve
good computational performance for AR tracking.
In addition, requirements for computational power in AR
have increased and so it has been natural to distribute the
architecture. The advances in development of cloud services
and infrastructures have offered solutions for distributed
mobile platforms. Many commercial players already use
distributed architectures e.g., Vuforia, but this is also an
active research topic [16][17], too.
III.
SPORT DATA VISUALISATION CLOUD ARCHITECTURE
A.
NUBOMEDIA PaaS
NUBOMEDIA is a cloud and PaaS platform supporting
development of real-time multimedia applications and a
deployment of cloud based multimedia services utilizing
WebRTC video communication. The platform provides
interfaces that assist development of complex multimedia
applications
for
multiple
platforms
including
HTML5/Javascript,
native
Android
and
iOS
mobile
platforms.
NUBOMEDIA
provides
interfaces
and
core
functionality
for
media
streaming,
processing,
PaaS-
management, virtualization and load balancing, and an
application
server
for
managing
users’
requests
and
controls. The platform’s interfaces provide a modular
structure for the core design and implementation, and tools
for developers for using the platform’s functionalities in
their applications. This paper focuses on the application
development capabilities of the platform, especially tailored
to support AR visualization of the sport sensor data. The
PaaS control functionality and resource management is
described in more details in [18].
B.
NUBOMEDIA Media Plane
The target of the NUBOMEDIA media plane is to
provide comprehensive media streaming and processing
capabilities that assist application developers to deploy real-
time multimedia communication supporting one-to-one,
one-to-many and many-to-many communication models,
and processing of the video streams including transcoding,
visual content analysis, augmented reality, adding overlay
graphics and many other capabilities. The media capabilities
are provided by the Kurento media server [19] component
of the NUBOMEDIA platform. Kurento is an open source
WebRTC media server targeted mainly to provide a Multi-
Conference Unit (MCU) for WebRTC based end-user
clients. Kurento also supports Selective Forwarding Unit
(SFU)
operations,
but,
in
this
case,
many
extended
capabilities, such as media processing operations, cannot be
efficiently utilized. In addition Kurento offers stream
management and stream processing for WebRTC clients
allowing
clients
to
create
different
multiparty
communication models that application developers can
easily embed into their applications.
A particularly interesting feature of Kurento is its
pluggable media processing architecture and the capability
to manipulate the content of the served video streams. The
audio/video stream inside the server can be routed to media
elements capable of manipulating or analyzing the content,
and thus, providing server side capabilities to provide rich
application
dependent
modifications
to
the
raw
A/V
streams. The media elements can be chained together. Thus,
it
is
possible
to
create
complex
video
manipulation
processing
chains
simply
by
concatenating
primitive
processing blocks together. The default installation of
Kurento contains a basic set of media elements capable of
recording,
mixing,
augmenting,
blending,
routing
and
analyzing video streams, for example detecting faces from
video streams. Application developers may extend the
2
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

Figure 1.
A NUBOMEDIA media pipeline example from Cheambe & al.
[18]
media processing capabilities by creating new media
elements. The Kurento framework provides a GStreamer
based template to assist creation of application specific
media elements.
Figure 1 presents a typical set-up for creating a
processing
and
transmission
pipeline
for
a
specific
multimedia application [18]. WebRTCEndpoints are used to
connect the Kurento server to the WebRTC A/V streams
that are transmitted between the client and the server. These
endpoints can be connected to any media elements for
manipulating or analyzing a stream before routing the
stream back to the receiving clients. Kurento also offers
client
libraries
for
JAVA
and
Javascript
to
assist
development of Kurento-based applications. It is also
possible to control the Kurento server with WebSocket and
JSON-RPC in other development environments.
C.
Sport data visualization extension for
NUBOMEDIA PaaS
The NUBOMEDIA platform provides a comprehensive
basis
for
creation
of
multimedia
communication
applications. We extended the NUBOMEDIA capabilities
for providing a framework for efficient development of
applications that augment image data to video streams and
in this way allows visualization of sensor data of athletes for
their audience in different kinds of sport competitions. The
requirements for such applications include distributed and
scalable platform for managing large amounts of audience
and athletic related sensor data. The framework supports
development of Web based multimedia applications that
allow the audience to use their mobile phones’ cameras in
capturing video streams of athletes and Web browsers in
watching of augmented video stream. The augmentation
contains measured performance data about the athletes of
the sport competition. Depending on the requirements of
each specific sport event and properties of the sensor data,
the visualization of the performance data may be presented
as augmented reality graphics or simple overlay graphics.
IV.
MEDIA TOOLS FOR PROSUMER PROROTYPE
APPLICATION
A.
Use case of the AR Sports prototype
A
long
jumper
Alan
is
participating
in
a
local
competition. His sport top has an AR marker printed on it
and he is wearing an embedded sensor. An Android mobile
unit is next to the long jump track and, thus, does not disturb
the athlete. Lisa is an enthusiastic fan of long jumping. She is
watching the competition and wants to know all the facts.
She takes her smart phone out of her pocket and turns on the
browser for navigating to the Web page of the AR Sport
service. She is pointing the camera at the athlete and the
marker on the sport top. The marker is detected by the AR
Sport service. Alan makes his jump and, as long as Lisa
points the camera at the marker, the analysis of the jump
performance is augmented on the video feed and is visible on
the screen. Lisa shares the video clip immediately via the
social media to celebrate the successful performance of her
idol.
In
addition,
Lisa
can
easily
get
more detailed
information of the different performances, which encourages
engaging in sports experience as a fan.
B.
Proof of concept instance
The
high
level
architecture
of
Sport
Analysis
performance visualization prosumer tool is depicted in
Figure 2. The usage of the system is based on two main
parts: 1) IoT sport data analysis and visualisation of athletic
performances and 2) Use of AR Sports services.
IoT sport data analysis and visualisation of athletic
performances is depicted in the upper half of Figure 2. This
process collects acceleration data from the sensors, analyses
the acceleration data, and creates a visualisation canvas for
the athletic performance.
Use of AR Sports services is depicted in the bottom half
of Figure 2. The sport spectator launches a mobile browser
on his/her mobile device and navigates to the Web page of
the AR sport service in the browser. The Web page opens a
camera
view
and
transmits
the
video
feed
to
the
NUBOMEDIA
server.
The
spectator
can
watch
the
augmented video stream on his/her device or NUBOMEDIA
supports distributing the video stream to a larger audience.
The system presented in Figure 2 contains the following
components:
Athletes – An athlete will have an AR marker (e.g. a
marker that is attached to his/her t-shirt), 3D accelerometer
sensors, a mobile device (an Android device) within the
Bluetooth range, and the IoT sport data analysis and
visualisation application installed to the device that acts as a
mobile computation node.
Sport spectators – A sport spectator uses the AR Sport
service on a mobile device with a browser (e.g., in a Firefox
browser) supporting WebRTC and Web connection to the
NUBOMEDIA service through the Web page of the AR
sport service. The following paragraphs describe the core
parts of the architecture in more detail.
AR Sport application is an Android application that scans
available BLE (Bluetooth low energy) devices, which are in
our case VTT Tiny Node sensors [21] (in Figure 3) that are
used for measuring the athlete’s performance. The Tiny
Node
consists
of
integrated
sensors
including
3D
accelerometer, pressure, temperature, and humidity sensors.
The AR Sport Application allows selecting a desired Tiny
Node sensor and for the selected Tiny Node sensor,
3
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

Figure 2.
High level architecture of Sport Analysis performance
visualization prosumer tool
the application opens a Bluetooth connection. For IoT sport
data analysis, the application will first send a message to the
Tiny Node for activating collection of acceleration data in
the sensor that, in turn, delivers the collected sensor data via
Bluetooth for the AR Sport application. The AR Sport
application contains analysis and visualisation components.
In
the
prototype,
the
analysis
component
uses
the
acceleration meter data achieved form the Tiny Node
sensor. The analysis is performed as follows: recognition of
jumps and direction of the jumps by using sliding averages
for the x- and y-acceleration data. The jump power is
estimated by using maximum vertical acceleration in
percentages compared to the best jump of the athlete in the
current use session. These values are visualized as depicted
on the left in Figure 4. The visualisation shows the direction
of the jump (arrow for the jump), name for the athlete,
running number for the jump, and power of the jump in
percentages compared to the best jump in the use session.
Visualization server receives the produced 2D image
visualization canvas by using the HTTP post method. The
visualization server handles the connection of AR marker
ID
and
the
image
that
are
further
passed
to
the
NUBOMEDIA PaaS.
NUBOMEDIA Paas is responsible for real time video
service utilising AR capabilities of the VTT ALVAR library
[20] that supports marker, planar and 3D tracking based
tracking, accurate pose estimation, two types of square
matrix markers, and recovering from occlusion. An example
of an ALVAR marker is depicted on the left in Figure 3. The
NUBOMEDIA service detects the AR marker from a video
stream coming from sport spectator’s device, and pairs the
information
of
corresponding
AR
marker
with
the
visualisation of the athlete’s performance and augments the
image on the video stream. An example of the visualization
of acceleration data, video stream from AR Sport Service
and augmentation is depicted in Figure 4.
Figure 3.
Example of ALVAR AR marker on the left and VTT Tiny Node
sensor on the right.
Figure 4.
Visualization example of AR Sport Application
The sport spectator can access the analysed performance
results through the Web page of the AR Sport service. When
(s)he access the Web page, the camera of the mobile phone
is turned on and the video is streamed to the NUBOMEDIA
server by using the HTML5 camera interface input and
WebRTC streaming. The Web page is created by an
application server that also initializes the AR processing
chain in the Kurento media server. The NUBOMEDIA
service analyses the video stream and when an AR marker is
identified,
the
NUBOMEDIA
service
renders
a
corresponding
visualisation
canvas
of
the
athletic
performance over the video stream and sends the stream
back to the browser.
The current prototype implementation assumes that there
is
only one athlete with
a
marker and performance
visualization that is overlaid on the AR marker. In the future,
the system should be extended to use multiple AR markers
on separate athletes as the system is capable of visual tagging
and pairing of multiple athletes. As each AR marker can be
uniquely identified and mapped to the ID of the Tiny Node
sensor of an athlete, the corresponding data can be overlaid
on the each individual AR marker or an another AR tracking
target. In the current implementation, the augmentation is
placed on the top of the marker and can be seen only when
the marker is visible in the video stream. As the athlete
moves, this could become a problem when the marker is out
line of sight, but this could be avoided by developing more
sophisticated service and user interface. For example, the
marker can be used as a trigger for starting the augmentation
of the athlete’s performance information. In addition,
another problem could arise from multiple markers on the
camera view as multiple visualizations in the video stream
would not be reasonable on a small screen. In this case, the
spectator could be given control for choosing the athlete on
the display the athlete whose information will be augmented
and the system would visualize one performance at the time.
4
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

V.
CONCLUSIONS
This paper describes the AR Sport demonstrator system
that utilizes NUBOMEDIA PaaS for multimedia application
development. The AR Sport service identifies the athlete and
his/her sensor based on an AR marker and connects the
visual tag with the visualization canvas created by the IoT
sport data analysis software on an Android device. The sport
event spectator is able to see the analysis results on the top of
the athlete in an augmented reality video stream in real time.
The demonstrator showcased that we can create cloud based
AR services for sport events for creating totally new type of
engaging
experiences
for
the
enthusiastic
fans.
The
increasing number of sensors worn by athletes will provide
new opportunities to offer visualization applications for the
spectators, and it creates a possibility to consumers, such as
sports fans, to become more interesting prosumers in sport
events. The linking of the information allows tagging of
video streams with local sensor data and also with additional
information, such as an athlete name, nationality, ranking
etc. Future plans include enhancing the user interface based
on wider testing and integration of advanced performance
analysis on the AR Sport application.
ACKNOWLEDGEMENT
This work has been funded by EU- NUBOMEDIA (FP7-
ICT-2013-1.6., GA-610576) project and VTT’s internal
Productivity with Internet of Things research program.
REFERENCE
[1]
A. G. Losada, R. Therón, and A. Benito, "BKViz: A
Basketball
Visual
Analysis
Tool,"
in
IEEE
Computer
Graphics and Applications, vol. 36, no. 6, pp. 58-68, Nov.-
Dec. 2016. doi: 10.1109/MCG.2016.124
[2]
J, Wood, “ Visualizing Personal Progress in Participatory
Sports Cycling Events,” 2015. IEEE Computer Graphics and
Applications, vol. 35, no. 4, pp. 73-81, July-Aug. 2015.
[3]
https://www.zepp.com/en-us/smartbat/powered-by
[accessed
October 2017]
[4]
http://www.adidas.com/us/micoach-smart-soccer-
ball/G83963.html. [accessed October 2017]
[5]
http://www.lechal.com. [accessed October 2017]
[6]
https://www.fitbit.com/fi/home. [accessed October 2017]
[7]
https://www.polar.com/en?nogeo. [accessed October 2017]
[8]
https://www.polarpersonaltrainer.com/
[accessed
October
2017]
[9]
http://www.bbc.com/news/business-40636746.
[accessed
October 2017]
[10] https://wearnotch.com. [accessed October 2017]
[11] https://webrtc.org/. [accessed October 2017]
[12] M. Stein et al., "Bring it to the Pitch: Combining Video and
Movement Data to Enhance Team Sport Analysis," IEEE
Transactions on Visualization and Computer Graphics, vol.
PP,
no.
99,
pp.
1-1.
doi: 10.1109/TVCG.2017.2745181
[13] A. Raina, T. G. Lakshmi and S. Murthy, "CoMBaT: Wearable
Technology Based Training System for Novice Badminton
Players," IEEE 17th International Conference on Advanced
Learning Technologies (ICALT), Timisoara, 2017, pp. 153-
157. doi: 10.1109/ICALT.2017.96
[14] B. MacIntyre, A. Hill, H. Rouzati, M. Gandy, and B.
Davidson, "The Argon AR Web Browser and standards-based
AR application environment," 2011 10th IEEE International
Symposium on Mixed and Augmented Reality, Basel, 2011,
pp. 65-74. doi: 10.1109/ISMAR.2011.6092371
[15] R. R. Srinivasa, U. P. Veluchamy, and J. Bose, "Augmented
Reality adaptive web content," 2016 13th IEEE Annual
Consumer
Communications
&
Networking
Conference
(CCNC),
Las
Vegas,
NV,
2016,
pp.
107-110.
doi:
10.1109/CCNC.2016.7444740
[16] Y. Chen, L. Xiang, J. Zhang, and L. Liu, “Research about
mobile AR system based on cloud computing” 2013 22nd
Wireless
and
Optical
Communication
Conference,
Chongqing,
2013,
pp.
355-359.
doi:
10.1109/WOCC.2013.6676392
[17] P. H. Chiu, P. H. Tseng, and K. T. Feng, "Cloud computing
based mobile augmented reality interactive system," 2014
IEEE Wireless Communications and Networking Conference
(WCNC),
Istanbul,
2014,
pp.
3320-3325.
doi:
10.1109/WCNC.2014.6953084
[18] A. Cheambe et al., ”Design and Implementation of a High
Performant PaaS Platform for Creating Novel Real-Time
Communication
Paradigms”,
2016
19th
International
Innovation
in
Clouds,
Internet
and
Networks
(ICIN)
Conference, (Paris, March 1-3.2016)
[19] L. López et al., “Kurento: The WebRTC Modular Media
Server”, 2016 ACM Multimedia Conference (MM '16).
ACM,
New
York,
NY,
USA,
1187-1191.
DOI:
https://doi.org/10.1145/2964284.2973798
[20] Alvar.
2000.
http://virtual.vtt.fi/virtual/proj2/multimedia/alvar/
Accessed:
2017- 2-3.
[21] VTT
IoT
Solutions.
2015.
http://www.vtt.fi/files/events/Teollinen_Internet_ja_Digitalisa
atio_2015/TinyNode.pdf .
[accessed
October
2017]
5
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

