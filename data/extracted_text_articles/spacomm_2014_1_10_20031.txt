Estimation Quality of High-dimensional Fields in
Wireless Sensor Networks
Siyuan Zhou
DET, Politecnico di Torino
Torino, Italy
Email: siyuan.zhou@polito.it
Alessandro Nordio
IEIIT-CNR
Torino, Italy
Email: alessandro.nordio@ieiit.cnr.it
Carla-Fabiana Chiasserini
DET, Politecnico di Torino
Torino, Italy
Email: chiasserini@polito.it
Abstract—In the ﬁelds of wireless communications, network-
ing and signal processing, systems can be often modeled through
a linear relationship involving a random Vandermonde matrix
V, and their performance can be characterized through the
eigenvalue distribution of the Gram matrix VVH. In spite of its
key role, little is known about the eigenvalue distribution of such a
matrix and only few of its moments are known in closed form. In
this work, we obtain a lower and an upper bound to the eigenvalue
distribution of VVH, as well as an excellent approximation based
on entropy maximization. As an application, we consider the case
of a wireless sensor network sampling a physical phenomenon to
be estimated. We characterize the quality of the estimate through
the eigenvalue distribution of VVH by adopting an asymptotic
approach, which well suites medium-large scale networks. The
proposed method is particularly efﬁcient when dealing with
physical phenomena deﬁned over a d-dimensional support, with
d > 2.
Keywords—sensor networks; Signal estimation; Vandermonde
matrices.
I.
INTRODUCTION
Recently, random Vandermonde matrices have attracted a
great deal of interest since they play an important role in ﬁelds
such as wireless communications, sensor networks, and image
processing. In these contexts, signals estimation systems can
often be modeled as [1]–[3]:
y = VHa + n ,
(1)
where the vector y represents a set of measurements, the
vector a denotes the system input that has to be estimated,
V is a random Vandermonde matrix representing the system
transfer function, and n is the additive noise, uncorrelated
with respect to a and V. Bold lowercase and uppercase
letters denote column vectors and matrices, respectively. The
conjugate transpose operator is denoted by (·)H, and the
identity matrix is denoted by I. In particular, the model in (1)
can represent a physical phenomenon sampled by a wireless
sensor network composed of nodes randomly deployed on a
d-dimensional support. The physical phenomenon is speciﬁed
by the vector a which has to be estimated from the set of
noisy measurements y, collected by the sensors. In this case,
the matrix V accounts for the positions of the sensor nodes.
In [4], it has been shown that the performance of linear
estimation techniques can be accurately described through
the eigenvalue distribution (or matrix spectrum) of the Gram
matrix associated to V, i.e., VVH. In particular, a key role is
played by the asymptotic spectrum of VVH, which is obtained
by letting the size of the matrix V tend to inﬁnity while
keeping the ratio of the number of rows to the number of
columns constant. Unfortunately, such asymptotic spectrum is
still unknown and very few results exist that can shed light
on this important issue. For example the results presented
in [1], [2] were obtained by using a Monte Carlo approach
which, although accurate, turns out to be computationally
expensive when the physical phenomenon to be estimated is
deﬁned over d > 2 dimensions. In this work, we leverage the
existing results on the moments of the asymptotic spectrum
of VVH and contribute to ﬁlling the aforementioned gap by
providing (i) a lower and an upper bound to the asymptotic
cumulative distribution function of the eigenvalues of VVH,
and (ii) an approximation of the asymptotic spectrum (both the
cumulative and the density functions), which proves to be very
accurate. Through such results, we are able to characterize the
performance of linear reconstruction techniques by avoiding
the need of computationally expensive Monte Carlo methods.
The rest of the paper is organized as follows. First, in
Section II we provide some background on the system model
and performance metric, as well as on fundamental concepts
related to Vandermonde matrices that we use in our analysis.
We then present our bounds and approximation of the asymp-
totic eigenvalue distribution in Section III and Section IV,
respectively. Finally, we show numerical results in Section V,
and we conclude the paper in Section VI.
II.
SIGNAL RECONSTRUCTION IN WSN AND RANDOM
VANDERMONDE MATRICES
We consider m sensors sampling a spatially-ﬁnite physical
phenomenon s(x) (hereinafter also called signal), deﬁned over
a d-dimensional hypercube H = [0, 1)d, d ≥ 1, and with
ﬁnite energy. The signal can be approximated by its truncated
Fourier series expansion so that the sample of the q-th sensor
(q = 1, . . . , m) can be modeled as [1]
sq = s(xq) = n−d/2 X
ℓ
aν(ℓ)ej2πℓTxq
(2)
where n is the approximate bandwidth (per dimension) of
the ﬁeld and ℓ = [ℓ1, . . . , ℓd]T is a vector of integers, with
ℓj = 0, . . . , n − 1, j = 1, . . . , d. The coefﬁcient n−d/2 is
a normalization factor and the function ν(ℓ) = Pd
j=1 nj−1ℓj,
maps uniquely the vector ℓ into {0, . . . , nd−1}. The term aν(ℓ)
denotes the ν(ℓ)-th entry of the vector a = [a0, . . . , and−1]T,
which represents the approximated signal spectrum, while the
vectors xq ∈ H, represents the coordinate of the q-th sampling
point (i.e., the position of the q-th sensor), which is assumed
to be known. We assume that xq, q = 1, . . . , m, are i.i.d.
random vectors having a generic continuous distribution over
the hypercube H. Also, since in general we do not have any
information on the signal spectrum a, we assume it has zero
1
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-317-9
SPACOMM 2014 : The Sixth International Conference on Advances in Satellite and Space Communications

mean and covariance σ2
aI. Without loss of generality and for
normalization reasons, we set σ2
a = 1.
The vector of samples s = [s1, . . . , sm]T can be rewritten
in a compact form as s = VHa where V is an nd ×m random
Vandermonde matrix whose generic entry
(V)ν(ℓ),q = n−d/2 exp

The above inequality is valid for ζ ≥ 0, i.e., z ≤ µ1/p
p
. When
z > µ1/p
p
, we assume Fλ(d, β, z) ≤ 1. Then, if the moments
µp are available for p = 1, . . . , ⌊P/2⌋, we have:
Fλ(d, β, z) ≤ min
p
(
µ2p−µ2
p
µ2p−2µpzp+z2p
if z ≤ µ1/p
p
1
else.
(12)
IV.
APPROXIMATION OF fλ(d, β, z) AND Fλ(d, β, z)
The reconstruction of a probability density function from
its moments is known as the Classical Moment Problem.
Unfortunately, the knowledge of a ﬁnite set of moments does
not guarantee the uniqueness of the solution [8]. In general a
good solution must be selected from a solution space according
to some cost metric. A method to solve the problem has been
proposed in [9], and it is based on the entropy maximization
approach.
In practice, an approximation to fλ(d, β, z) can be found
by maximizing its entropy, under the constraint that the p-
th moment of the distribution must be equal to µp, for
p = 1, . . . , P. More formally, we have to solve the following
constrained optimization problem:
max −
Z +∞
0
fλ(d, β, z) log fλ(d, β, z) dz
s.t.
Z +∞
0
zpfλ(d, β, z) dz = µp, p = 0, . . . , P .
(13)
When the number of known moments is low, i.e., for P ≤
2, fλ(d, β, z) can be reconstructed analytically [11]. If only µ1
is known, we have fλ(d, β, z) = exp(−z). If µ1 and µ2 are
known, fλ(d, β, z) behaves as Gaussian function and is given
by fλ(d, β, z) = exp(−(1 + a + bz + cz2)), where a, b and c
are solutions of the following multivariate equations:
e−1−a

b2
2 +c
4
p π
c5 e
b2
4c

1 − erf

b
2√c

−
b
4c2

= µ2
e−1−a 
1
2c − b
4c
p π
c e
b2
4c

1 − erf

b
2√c

= µ1
e−1−ap π
4ce
b2
4c

1 − erf

b
2√c

= 1
However, for a larger number of moments, i.e., P > 2, (13)
is in general intractable analytically. We therefore solve it
numerically by resorting to the stable algorithm in [8], which
is based on the discretization of the integrals through an N-
points Gaussian quadrature rule [10]. The method consists in
approximating the function to be integrated with the product
of a polynomial function and a weighting function w(x), and
then in discretizing the latter two. Speciﬁcally, we can write:
−
Z +∞
0
fλ(d, β, z) log fλ(d, β, z) dz ≈ −
N
X
j=1
wjfj log fj
and
Z +∞
0
zpfλ(d, β, z) dz ≈
N
X
j=1
wjzp
j fj, p = 0, . . . , P
where, for j = 1, . . . , N, fj = fλ(d, β, zj) while zj and wj
are, respectively, the abscissae of the Gaussian quadrature rule
and the corresponding values of the weighting function.
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 0.5
 1
 1.5
 2
 2.5
 3
 3.5
 4
 4.5
 5
Fλ(d,β,z)
z
 LB
 UB
 Empirical
 Estimate
Fig. 1.
Comparing bounds, maximum entropy approximation of the CDF,
and the empirical distribution, with d = 1 and for β = 0.1.
V.
ESTIMATION PERFORMANCE
We validate our proposed approach by comparing the
bounds and approximation against the empirical distribution.
The latter has been obtained by computing the eigenvalues of
several realizations of VVH for n = 100 and a number of sen-
sors m = n/β, while the maximum entropy approximation has
been computed by using the ﬁrst 12 moments of the asymptotic
eigenvalue distribution. All results refer to the case where the
phases of the Vandermonde matrix are uniformly distributed
over [0, 1)d; note, however, that other phase distributions could
be considered as well by leveraging the results in [1], [2].
The curves depicted in Figure 1 depict the CDF Fλ(d, β, z),
and have been obtained with d = 1 and β = 0.1. Observe that
our bounds follow the behavior of the empirical distribution
very well, and there is an excellent match between the latter
and the maximum entropy approximation.
Figure 2 compares our approximation to the probability
density function, fλ(d, β, z), against the empirical results,
when d = 1 and for β = 0.2 (top plot) and β = 0.7 (bottom
plot). As expected, in this case the differences between the
approximation and the empirical results are more evident than
in the case of the CDF, however our approximation still shows
to be very tight, even for β as high as 0.7. In addition, the top
plot compares the analytical solution of (13), obtained using
µ1 and µ1,2, to our approximation and the empirical results.
Clearly, the higher the number of considered moments, the
better the approximation accuracy with respect to the empirical
results. We also stress that, by deﬁnition of β, meaningful
values of such a parameter are limited to the [0, 1] interval,
as the number of sensors (m) should always outnumber the
signal harmonics (nd).
Figure 3 shows the asymptotic MSE, M∞, achieved by the
ZF and LMMSE ﬁlters for d = 1, 4 and for a noise variance
σ2
n = 0.01. The curves were obtained by computing (6) where
the distribution of λ was approximated by solving the problem
in (13). As expected, the LMMSE ﬁlter performs better than
the ZF ﬁlter since it minimizes the MSE. Also, the ﬁgure
shows that given number of harmonics per dimension, n,
3
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-317-9
SPACOMM 2014 : The Sixth International Conference on Advances in Satellite and Space Communications

 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0
 0.4
 0.8
 1.2
 1.6
 2
 2.4
 2.8
 3.2
 3.6
 4
fλ(d,β,z)
z
 Empirical
 Estimate
 p=1
 p=1,2
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0
 0.4
 0.8
 1.2
 1.6
 2
 2.4
 2.8
 3.2
 3.6
 4
fλ(d,β,z)
z
 Empirical
 Estimate
Fig. 2.
Comparison between the empirical results and the maximum entropy
approximation of the probability density function, with d = 1 and for β = 0.2
(top) and β = 0.7 (bottom). In the upper plot, it is shown also the analytical
solution with p=1, and p=1,2.
10-3
10-2
10-1
100
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
Asymptotic MSE
β
 d=1, ZF
 d=1, LMMSE
 d=4, ZF
 d=4, LMMSE
Fig. 3.
Comparison between the asymptotic MSE, M∞, achieved by the
ZF and the LMMSE ﬁlters, for d = 1, 4 and σ2
n = 0.01.
the asymptotic MSE decreases with the number of available
measurements m, i.e., it increases with β = nd/m. More
importantly, we remark that the maximum entropy approach
proposed here, allows to efﬁciently estimate fλ(d, β, z) and
M∞ for any d, thus avoiding to resort to the numerical
computation of the eigenvalues of large matrices.
VI.
CONCLUSIONS AND FUTURE WORK
We studied the asymptotic eigenvalue distribution of the
Gramian of random Vandermonde matrices, which has an
important role in determining the performance of many sys-
tems for signal estimation. In particular, we derived a lower
and an upper bound to the asymptotic cumulative distribution
function. Additionally, we provided an approximation of both
the cumulative distribution and the probability density func-
tions, which showed to be very accurate, without applying the
cumbersome computation of empirical results.
Our future work will mainly focus on the application of this
approximation method to the achievable mutual information
of systems, when the channel behavior can be represented by
Vandermonde matrix [2]. In this case, we are able to compute
the achievable mutual information by deriving the eigenvalue
distribution through its moments. Other possible extensions
will consider the mutual information in multi-user MIMO
systems, and multifold scattering scenarios.
ACKNOWLEDGMENT
This paper was made possible by NPRP grant ♯ 5 − 782 −
2−322 from the Qatar National Research Fund (a member of
Qatar Foundation). The statements made herein are solely the
responsibility of the authors.
REFERENCES
[1]
A. Nordio, C.-F. Chiasserini, and E. Viterbo, “Reconstruction of mul-
tidimensional signals from irregular noisy samples,” IEEE Trans. on
Signal Processing, Vol. 56, No. 9, Sept. 2008, pp. 4274–4285.
[2]
O. Ryan, and M. Debbah, “Asymptotic Behavior of Random Vander-
monde Matrices with Entries on the Unit Circle”, IEEE Trans. on
Information Theory, Vol. 55, No. 7, July 2009, pp. 3115–3147.
[3]
A. Nordio, G. Alfano, C.-F. Chiasserini, and A. M. Tulino, “Asymptotics
of Multifold Vandermonde Matrices with Random Entries,”, IEEE
Trans. on Signal Processing, Vol. 59, No. 6, June 2011, pp. 2760–2772.
[4]
A. Nordio, C.-F. Chiasserini, and E. Viterbo, “Performance of linear
ﬁeld reconstruction techniques with noise and uncertain sensor loca-
tions,” IEEE Trans. on Signal Processing, Vol. 56, No. 8, Aug. 2008,
pp. 3535–3547.
[5]
A. Nordio, and C.-F. Chiasserini, “Field Reconstruction in Sensor
Networks with Coverage Holes and Packet Losses,” IEEE Trans. on
Signal Processing, Vol. 59, No. 8, Aug. 2011, pp. 3943–3953.
[6]
G. H. Tucci, and P. A. Whiting, “Eigenvalue Results for Large Scale
Random Vandermonde Matrices with Unit Complex Entries,” IEEE
Trans. on Information Theory, Vol. 57, No. 6, June 2011, pp. 3938–3954.
[7]
R. Tempo, G. Calaﬁore, and F. Dabbene, Randomized Algorithms for
Analysis and Control of Uncertain Systems, Springer-Verlag, 2005.
[8]
K. Bandyopadhyay, K. Bhattacharya, P. Biswas, and D. A. Drabold,
“Maximum Entropy and the Problem of Moments: A Stable Algorithm,”
Physical Review E 71, 057701, 2005.
[9]
L. R. Mead, and N. Papanicolaou, “Maximum Entropy in the Problem
of Moments,” J. Math. Phys. 25, 2404, Aug. 1984, pp. 2404–2417.
[10]
M. Hazewinkel, “Gauss Quadrature Formula,” Encyclopedia of Mathe-
matics, Springer, 2001.
[11]
F. Socheleau, C. Laot, and J. Passerieux, “Concise Derivation of
Scattering Function from Channel Entropy Maximization,” IEEE Trans.
on Communications, Vol. 58, No. 11, Nov. 2010, pp. 3098–3103.
4
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-317-9
SPACOMM 2014 : The Sixth International Conference on Advances in Satellite and Space Communications

