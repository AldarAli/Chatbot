A Computational Intelligence Algorithm for
Simulation-driven Optimization Problems
Yoel Tenne
Faculty of Engineering,
Kyoto University, Japan
yoel.tenne@ky3.ecs.kyoto-u.ac.jp
Kazuhiro Izui
Faculty of Engineering,
Kyoto University, Japan
izui@prec.kyoto-u.ac.jp
Shinji Nishiwaki
Faculty of Engineering,
Kyoto University, Japan,
shinji@prec.kyoto-u.ac.jp
Abstract—Modern engineering design optimization often re-
places laboratory experiments with computer simulations, re-
sulting in what is commonly termed as expensive black-box
optimization problems. In such problems, there will often exist
candidate solutions which ‘crash’ the simulation and can thus
lead to search stagnation and to a poor ﬁnal result. Existing
approaches to handle such solutions include discarding them alto-
gether or assigning them a penalized ﬁtness, but such approaches
have signiﬁcant demerits. Accordingly, this paper explores the
fusion of a classiﬁer into the optimization search to predict
which solutions are expected to crash the simulation, and uses
a modiﬁed objective function to bias the search towards valid
ones, namely, which are expected not to crash the simulator.
The further improve its performance, the proposed algorithm
also continuously selects during the search an optimal type of
classiﬁer out of a family of candidates. To ensure the progress of
the optimization search, it also employs a trust-region approach.
Performance analysis using a representative real-world shape
design optimization test case shows the efﬁcacy of the proposed
algorithm.
Keywords-expensive optimization problems, computational in-
telligence
I. INTRODUCTION
In the modern design process, engineers often replace labo-
ratory experiments with computer simulations. This transforms
the design process into an optimization problem having three
distinct characteristics [20]:
• The simulation acts as the objective function, assigning
candidate designs their corresponding objective values.
However, the simulation is often a legacy or a commer-
cial code available only as an executable, and so there
is no analytic expression for this “objective function”.
Accordingly, it is referred to as a black-box function, and
requires using gradient-free optimizers.
• Each simulation run is computationally expensive, that
is, having a lengthy execution time, and this severely
restricts the number of evaluations allowed during the
optimization search.
and
• Often, both the underlying physics being modelled, and
the numerical simulation, may result in a complicated,
multimodal objective landscape, which makes it difﬁcult
to locate an optimum.
A promising optimization strategy for such expensive black-
box problems is to couple a computational intelligence (CI)
optimizer, which is gradient-free and handles complicated
landscapes well, with models, namely, mathematical approx-
imations of the true expensive objective function, but which
are signiﬁcantly cheaper to evaluate. During the optimization,
the model replaces the expensive function (simulation), and
economically provides the CI optimizer with approximate
objective values.
While this approach works well, in practise another dif-
ﬁculty arises, as often some candidate solutions will cause
the simulation to fail. We refer to such vectors as simulator-
infeasible (SI), while those for which the simulation completes
successfully and provides the objective value are simulator-
feasible (SF). SI vectors have two main implications for the
optimization problem: a) as they do not have an objective
value assigned to them, since the simulation has crashed, the
objective function becomes discontinuous, which increases the
optimization difﬁculty, and b) they can consume a large portion
of the limited number of calls to the expensive simulation
without providing new information to the optimizer, thus
potentially leading to search stagnation and a poor ﬁnal result.
Numerous papers, for example [1, 15, 16], have mentioned the
difﬁculties SI vectors introduce, and so it is important effec-
tively to handle them. Common strategies include discarding
them altogether, or incorporating them into the model with
a penalized ﬁtness. However, both of these strategies have
signiﬁcant demerits, for example, they discard information
which can be beneﬁcial to the search, or they result in a model
with a severely deformed landscape.
Accordingly, to effectively handle such SI vectors in
model-assisted optimization, this paper explores the fusion of
a classiﬁer into the optimization search, and offers two main
contributions. First, a classiﬁer is used to predicts if a new
vector is SI or not, and the proposed algorithm then combines
this prediction with the model’s prediction to bias the search
to vectors predicted to be SF via a dedicated modiﬁed
objective function. Second, to further enhance performance,
the proposed algorithm continuously selects during the search
an optimal classiﬁer type from a family of candidates. To
ensure convergence to an optimum of the true expensive
function, the proposed algorithm also employs a trust-region
(TR) approach. Performance analysis using an engineering
127
FUTURE COMPUTING 2011 : The Third International Conference on Future Computational Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-154-0

design application of airfoil shape optimization shows the
efﬁcacy of the proposed algorithm. The remainder of this
paper is as follows: Section II describes existing approaches
and open challenges in handling SI vectors, Section III
describes the proposed algorithm and Section IV gives a
detailed performance analysis. Lastly, Section V summarizes
this paper.
II. EXISTING APPROACHES AND CHALLENGES
As mentioned in Section I, SI vectors are a common in
simulation-driven optimization problems, and numerous stud-
ies mention their existence and the difﬁculties they introduce,
for example [1, 5, 12, 15, 16].
As such vectors are both common in real-world applications,
and pose the risk of hampering the optimization search,
several approaches have been proposed to handle them. In
reference [17], the authors used an evolutionary algorithm
(EA) as the optimizer and proposed using a classiﬁer to screen
vectors before evaluating them. Those predicted to be SI were
assigned a ‘death penalty’, that is, a ﬁctitious and highly
penalized objective value, to quickly eliminate them from the
population. The study did not consider models, and the EA
evaluated the expensive function directly. In a related approach
described in reference [5], severely penalized SI] vectors and
incorporated them into the model in order to bias the search
away from them. Alternatively, in reference [1] the authors
proposed to completely discard SI vectors from the training
set of the model.
However, within the domain of model-assisted optimization
such approaches suffer from several shortcomings: a) assign-
ing SI vectors a ﬁctitious penalized objective value and then
incorporating them into the training set can result in a model
with a severely deformed landscape, while b) excluding SI
vectors altogether discards information which may be ben-
eﬁcial to the optimization search. As an example, Figure 1
compares two Kriging models of the Rosenbrock function:
(a) shows a model trained using 30 vectors which were all
SF, while (b) shows the resultant model when the sample was
augmented with 20 SI vectors which were assigned a penalized
ﬁtness, taken as the worst objective value from the baseline
sample. The resultant model has a landscape which is severely
deformed and contains many false optima, making it difﬁcult
to locate an optimum of the true objective function.
Such issues have motivated alternative approaches to handle
SI vectors in model-assisted optimization. For example, in
reference [19] the authors proposed a dual model approach,
where one model interpolated the objective function and
the other interpolated the penalty value between SF and SI
vectors. Other studies have explored the use of classiﬁers
for constrained non-linear programming (not focusing on SI
vectors), for example reference [6]. Further exploring the
use of classiﬁers, reference [21] presented preliminary results
with a classiﬁer-assisted algorithm for handling SI vectors.
−10
0
10−10
0
10
0
0.5
1
·106
(a)
−10
0
10−10
0
10
0
5
·106
(b)
Fig. 1.
Kriging models of the Rosenbrock function trained using: (a) a
baseline sample of 30 vectors all SF, and (b) the baseline sample augmented
with 20 SI vectors which were assigned the worst objective value from the
baseline sample.
III. PROPOSED ALGORITHM
To address the issues introduced by SI vectors, as discussed
in Section I and Section II, this paper proposes a model-
assisted CI algorithm which incorporates a classiﬁer into the
search. To further improve the search efﬁcacy, the algorithm
continuously selects during the search an optimal type of
classiﬁer, out of a prescribed family of candidates. To ensure
convergence to an optimum of the true expensive function,
the algorithm also employs a TR approach. The following
sections describe the model, the candidate classiﬁers, the
classiﬁer selection stage, and lastly, the overall workﬂow of
the algorithm.
A. Modelling
As mentioned, the proposed algorithm uses a model to
approximate the true expensive objective function. The algo-
rithm does not impose any restrictions on the model type,
and in this study the well-established Kriging model was used
[11]. This model takes a statistical approach to interpolation
by combining two components: a ‘drift’ function, which is a
global coarse approximation to the true expensive function,
and a local correction based on the correlation between the
interpolation points. Given a set of evaluated vectors, xi ∈ Rd ,
i = 1...n , the Kriging model is trained such that it exactly
interpolates the observed values, that is, m(xi) = f(xi), where
m(x) and f(x) are the model and true objective function, re-
spectively. Using a constant drift function, as in reference [11],
gives the Kriging model
m(x) = β +κ(x),
(1)
with the drift function β and local correction κ(x) . The latter
is deﬁned by a stationary Gaussian process with mean zero
and covariance
Cov[κ(x)κ(y)] = σ2R(θ ,x,y),
(2)
where R is a user-prescribed correlation function. A common
choice for the correlation is the Gaussian function [11], which
is deﬁned as
R(θ ,x,y) = Πd
i=1 exp

and combining it with the constant drift function transforms
the model from Equation (1) into the following form
m(x) = ˆβ +r(x)TR−1(f−1 ˆβ).
(4)
Here, ˆβ is the estimated drift coefﬁcient, R is the symmetric
matrix of correlations between all interpolation vectors, f is the
vector of objective values, and 1 is a vector with all elements
equal to 1. rT is the correlation vector between a new vector
x and the sample vectors, namely,
rT = [R(θ,x, x1),... ,R(θ ,x, xn)].
(5)
The estimated drift coefﬁcient ˆβ and variance ˆσ2 are obtained
from
ˆβ =

[23]. As mentioned in Section III-B, in this study, the proposed
algorithm selects between three well-established classiﬁers,
namely k-NN, LDA, and SVM. The algorithm selects the
classiﬁer type having the smallest prediction error, as deﬁned
in Equation (12), and then uses all the cached vectors, namely,
both SF and SI, to train a new classiﬁer with the selected
type, which serves as the classiﬁer during the TR trial step,
as explained in the following section.
D. Workﬂow
The algorithm begins by sampling a set of vectors which
will serve as the initial training sample. The vectors are
generated using the Latin hypercube design (LHD) method
for experiments design [14], as it provides a space-ﬁlling
sample which improves the accuracy of the model. Brieﬂy,
for a sample of k vectors the range of each variable is split
into k equal intervals, and one point is sampled at random
in each interval. Next, a sample point is selected at random
(without replacement) for each variable, and these samples are
combined to give a vector. This procedure is repeated for k
times to generate the complete sample. After generating the
sample, the vectors are evaluated with the expensive function
and are then cached.
The main optimization loop then begins, where the algo-
rithm ﬁrst trains a Kriging model using all the SF in the
cache. It then uses the procedure described in Section III-C
to select a classiﬁer type, and then trains a classiﬁer using all
the cached vectors, namely, both SF and SI, as these are two
vector classes.
Next, the proposed algorithm performs an optimization
search, and to ensure convergence to an optimum of the true
expensive function it follows the trust-region (TR) approach.
Speciﬁcally, the TR is the region where the model is assumed
to be accurate, and deﬁned as
T = {x : ∥x−xb∥2 ⩽ ∆},
(13)
where xb is the best vector found so far, and is taken as the TR
centre, and ∆ is the TR radius. The proposed algorithm seeks
the optimum of the model in the TR, and as the optimizer it
uses the real-coded EA from reference [2]. Since evaluating
the model is computationally cheap, the EA uses a large
population and many generations to improve its search, and
Table I gives the complete EA parameter settings. During
this optimization trial-step the EA does not use the model
predictions directly, but instead it obtains the ﬁtness values
from the following modiﬁed objective function, deﬁned as
¯m(x) =
(
m(x)
if c(x) is SF
p
if c(x) is SI
(14)
where m(x) is the model prediction, and p is a penalized ﬁtness
taken to be the worst function value from the initial Latin
hypercube (LH) sample. As such, the EA receives the model
prediction if the classiﬁer predicts a vector is SF, but receives
the penalized ﬁtness otherwise. In this setup, the information
about SI vectors is preserved in the classiﬁer, but they are not
incorporated into the model with a penalized ﬁtness and hence
do not deform its landscape.
The optimum found by the EA, designated as x⋆ , is then
evaluated with the true expensive function at a cost of one
function evaluation, which provides f(x⋆) . Following the
classical TR framework [3], the algorithm manages the model
and TR based on the outcome of the trial step, as follows:
• A successful trial step: The trial step located a new
optimum which is better than the current best, that is,
f(x⋆) < f(xb) . Following the classical TR approach, the
new optimum is taken as the new the TR centre, and the
TR is enlarged by doubling its radius.
• An unsuccessful trial step: The trial step did not locate a
new optimum, that is, f(x⋆) ⩾ f(xb) . This can happen
since either the TR is too large, or since there are not
enough vectors in the TR, resulting in a model which
is too inaccurate. Accordingly, to gauge the accuracy of
the model, the proposed algorithm checks the number of
vectors inside the TR. This number is then compared to
the dimension of the objective function (d), as it is an
indicator to the number of function evaluations required
to estimate the gradient by ﬁnite-differences and hence
is indicative of the number of function evaluation needed
to ﬁnd a new optimum. To manage the accuracy of the
model, the following steps are performed:
– If there are less than d SF vectors inside the TR: The
unsuccessful step may be since the model or classiﬁer
are inaccurate in the TR. As such, the algorithm
adds a new point (xn) inside the TR to improve their
local accuracy. The procedure for adding the point is
explained below.
– If there are more than d SF vectors in the TR: The
model and classiﬁer are considered to be sufﬁciently
accurate in the TR. In this case, and following the clas-
sical TR framework, the TR is contracted by halving
its radius.
Compared to the classical TR framework, the above steps also
monitor the number of interior vectors in the TR, since they
determine the local model accuracy. Monitoring the number
of these vectors ensures the TR is not contracted too quickly
when the search stagnates due to poor accuracy of the model
or the classiﬁer [3].
Another change from the classical framework is the addition
of a new vector (xn) to improve the local model accuracy. To
accomplish this, the new vector should be far from existing
ones, so it improves the model in an region sparse with
TABLE I
EA PARAMETERS
population size
100
generations
100
selection
stochastic universal selection (SUS), p = 0.7
recombination
intermediate, p = 0.7
mutation1
Breeder Genetic Algorithm (BGA) mutation, p = 0.1
elitism
10%
1 Based on [2]
130
FUTURE COMPUTING 2011 : The Third International Conference on Future Computational Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-154-0

sampled points [13]. Mathematically, ﬁnding such a point
translates to the following max-min optimization problem,
xn : max
x∈T min
xi∈T {∥x−xi∥2}
(15)
where xi , i = 1...r , are the existing interior TR points [9]. To
simplify the solution of Equation (15), the proposed algorithm
generates a LH sample in the TR and chooses the sample point
with the largest minimum distance.
Lastly, if the TR has been contracted for q consecutive
iterations, which suggests convergence to a local optimum,
the algorithm adds a point outside the TR to improve the
accuracy of model globally, which assists in locating new
optima. The point is generated using the same procedure
described above for the new interior point, namely, xn , but
now considering the entire search space instead of just the
TR. Based on numerical experiments, we identiﬁed q = 2 as
a suitable setting. To complete the description, Algorithm 1
gives the pseudocode of the proposed algorithm.
Algorithm 1: Proposed Optimization Algorithm with
Adaptive Model and Classiﬁer
generate an initial LHD sample;
evaluate and cache the sample vectors;
repeat
train a new Kriging model using all SF vectors in the
cache;
/* classifier selection
*/
for candidate classiﬁer = {k-NN, LDA, SVM} do
use CV to ﬁnd the classiﬁcation error (12);
select the classiﬁer with the lowest error and train a
new classiﬁer using all the vectors in the cache;
/* TR trial step
*/
set the best vector in the cache as the TR centre;
search for the model optimum using an EA and the
modiﬁed objective function (14);
evaluate the predicted optimum with the expensive
objective function;
/* manage the model and TR
*/
if the new optimum is better than the TR centre then
increase the TR radius
else if the new optimum is not better than the TR
centre and there are insufﬁcient vectors in the TR then
add a new vector in the TR to improve the model
and classiﬁer;
else if the new optimum is not better than the TR
centre and there are sufﬁcient vectors in the TR then
decrease the TR radius;
/* check search stagnation
*/
if there have been q consecutive TR contractions then
add a new vector outside the TR to improve the
accuracy of the model globally;
cache all new vectors evaluated;
until optimization budget exhausted;
IV. PERFORMANCE ANALYSIS
For its evaluation, the proposed algorithm was applied to
an engineering application of airfoil shape optimization. The
problem is pertinent to this study as it is both representative
of real-world expensive black-box optimization problems, and
contains SI vectors, as explained below.
The setup of the problem is as follows. During ﬂight an
aircraft generates lift, namely, the beneﬁcial aerodynamic force
which keeps it airborne, and also drag, that is, an aerodynamic
friction force which obstructs the aircraft’s movement. Accord-
ingly, the optimization goal is to ﬁnd an airfoil shape which
maximizes the ratio of the lift to drag at some prescribed ﬂight
conditions, namely, the ﬂight altitude, the ﬂight speed, and the
angle of attack (AOA) which is the angle between the airfoil
chord and the aircraft velocity. Figure 2(a) shows the physical
quantities involved.
To ensure structural integrity, the minimum airfoil thickness
(t) between 0.2 to 0.8 of the airfoil chord must be equal to or
larger than a critical value t⋆ = 0.1 . Also, in practise the design
requirements for airfoils are speciﬁed in terms of the non-
dimensional lift and drag coefﬁcients, cl and cd, respectively,
deﬁned as
cl =
L
1
2ρV 2S
(16a)
cd =
D
1
2ρV 2S
(16b)
where L and D are the lift and drag forces, respectively, ρ is
the air density, V is aircraft speed, and S is a reference area,
such as the wing area. Accordingly, maximizing the lift and
minimizing the drag is formulated as a minimization problem
using the following objective function
f = − cl
cd
+ p,
(17a)
where cl and cd were deﬁned above, and p is a penalty for
airfoils which violate the thickness constraint, and is deﬁned
as
p =



t⋆
t ·

cl
cd

if t < t⋆
0
otherwise
(17b)
Airfoils were represented with the Hicks-Henne parameter-
ization [8], which uses a baseline airfoil and adds the basis
functions
bi(x) =

sin

πx
log(0.5)
log(i/(h+1))
4
,
(18)
with i = 1...h , where h is user-prescribed, to smoothly modify
the baseline shape [22]. The lower and upper curves of a
candidate airfoil are then given by
y = yb +
h
∑
i=1
αibi(x),
(19)
where yb is the baseline upper/lower curve, which was taken as
the NACA0012 symmetric airfoil, and αi ∈ [−0.01,0.01] are
131
FUTURE COMPUTING 2011 : The Third International Conference on Future Computational Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-154-0

the coefﬁcients (design variables) to be found. In this study, we
used h = 10 functions for the upper and lower curve, respec-
tively, or a total of 20 coefﬁcients, namely, design variables,
per airfoil. To obtain the lift and drag of candidate airfoils,
we used XFoil–a computational ﬂuid dynamics simulation
for analysis of subsonic airfoils [4]. Each airfoil evaluation
required up to 30 seconds on a desktop computer. Figure 2(a)
gives the layout of the Hicks-Henne parametrization.
As mentioned above, the airfoil optimization problem is a
pertinent test case since it contains SI vectors. The prevalence
of these vectors depends on two major factors: the AOA and
the operating conditions, namely, the altitude and velocity. To
illustrate the effect of the AOA, 30 different airfoils were
evaluated at identical ﬂight conditions, except for the AOA
which was increased from 0◦ to 40◦ , and the number of
failed evaluations, namely, SI vectors, was recorded at each
AOA. Figure 2(b) shows the obtained results, which indicate
a consistent trend where a higher AOA resulted in more
failed evaluations, namely, more SI vectors. Accordingly, we
have selected the settings AOA = 20◦ ,30◦ , and 40◦ for the
optimization tests. With respect to the altitude and velocity,
we have experimented with different operating conditions, and
have chosen a speed of Ma = 0.775 , namely, 0.775 of the
speed of sound, and an altitude of 32 kft.
For a comprehensive evaluation, the proposed algorithm
was also benchmarked against the following two representative
model-assisted EAs:
• Model-assisted EA with periodic sampling (EA–PS) [18]:
The algorithm begins by generating an initial LH sample
and training a Kriging model. A real-coded EA then runs
for 10 generations while evaluating only the model, and
next, the top 10 elites in the population are evaluated with
the true expensive function and are incorporated into the
model. The goal of this procedure is to safeguard the
accuracy of the model by periodically updating it with
the evaluated elites. This optimization loop repeats until
the optimization budget is exhausted. In the benchmarks,
the EA was identical to the one in the proposed algorithm,
and SI vectors were assigned a ﬁctitious penalty taken to
be the mean objective value in the initial LH sample.
• Expected-Improvement with a model-assisted CMA-ES
(EI–CMA-ES) [1]: The algorithm begins by generating
an initial sample of points and trains an initial Kriging
model. The main loop then begins, where at each gener-
ation the algorithm trains a local Kriging model around
the current elite using both the recently evaluated vectors,
and the cached vectors which are nearest to the elite. The
algorithm excludes SI vectors from the model training
set. A covariance matrix adaptation evolutionary strategy
(CMA-ES) algorithm then searches for an optimum of
the model in a bounded region deﬁned by the latter two
sets of solutions, namely, the recently evaluated ones and
the nearest neighbours, and in the spirit of the Expected-
Improvement framework [10], uses the merit function
ˆf(x) = m(x)−ρζ(x),
(20)
AOA
velocity
Lift
Drag
0.2
0.4
0.6
0.8
1
−0.2
−0.1
0
0.1
0.2
+
x
z
baseline airfoil: NACA0012
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
x
z
basis functions
(a)
0
20
40
0
20
40
angle of attack (AOA), degrees
% of failed evaluations
(b)
Fig. 2.
Aspects of the airfoil optimization problem. (a) shows the physical
quantities and Hicks-Henne airfoil parametrization setup. (b) shows the effect
of the AOA on the prevalence of SI vectors.
where m(x) is the Kriging model prediction, ρ is a
prescribed coefﬁcient, and ζ(x) is the estimate of the
Kriging model prediction error, which is zero at sampled
points since there the true objective value is known.
The search is repeated for ρ = 0,1,2, and 4 to obtain
four solutions corresponding to different search proﬁles,
namely, ranging from a local search (ρ = 0) to a more
explorative one (ρ = 4). All non-duplicate solutions found
are evaluated with the true expensive function and are
cached. In case no new solutions were evaluated, for
example, because they already exist in the cache, the
algorithm generates a new solution by perturbing the
current elite. Following reference [1], the algorithm used
a training set of 100 vectors (50 most recently evaluated
ones and 50 nearest-neighbours) and the CMA-ES used
the default values in the source code [7].
We have also used a variant of the proposed algorithm
with a ﬁxed classiﬁer type, namely, only k-NN, to gauge
the contribution of the classiﬁer selection step. The variant
is designated KK (Kriging–k-NN).
In all tests the optimization budget was 200 evaluations of
the true objective function, that is, simulation runs, and the
132
FUTURE COMPUTING 2011 : The Third International Conference on Future Computational Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-154-0

size of the initial sample was 20. To support a valid statistical
analysis, 30 trials were repeated for each algorithm–test case
combination.
Table II gives the test statistics for the three AOA cases,
as well as the signiﬁcance-level (α) at which the proposed
algorithm was better than each of the other algorithms, namely,
EA–PS, EI–CMA-ES, and KK, where an empty entry indicates
no statistically-signiﬁcant difference up to the 0.05 level. Sta-
tistical signiﬁcance tests were done using the Mann–Whitney
nonparametric test. For each AOA case, the best mean and
median results are emphasized. From studying the test results
for each AOA setting it follows:
• AOA=20◦: The proposed algorithm obtained the best
mean
score,
and its performance
was
statistically-
signiﬁcant better than the KK and EA–PS variants at the
α = 0.01 level. The EI–CMA-ES algorithm had the best
median result. followed by the proposed algorithm. With
respect to the standard deviation, the EA–PS algorithm
had the best (lowest) result, followed by the proposed
algorithm.
• AOA=30◦: The KK variant obtained the best mean,
followed by the proposed algorithm, a setup which was
also repeated for the median statistic. The proposed
algorithm was statistically-signiﬁcant better than the EI–
CMA-ES algorithm at the 0.01 level. With respect to
the standard deviation, the KK algorithm had the best
result, followed by the EA–PS algorithm, followed by
the proposed algorithm.
• AOA=40◦: The proposed algorithm had the best statistic,
while the EA–PS algorithm had the best median, closely
followed by the proposed algorithm. The proposed al-
gorithm was statistically-signiﬁcant better than the EI–
CMA-ES algorithm at the 0.01 level. With respect to the
standard deviation, the KK algorithm had the best result,
followed by the proposed algorithm.
Overall, results show the proposed algorithm performed
well, as it obtained either the best or near-best mean statis-
tic, and consistently obtained the near-best median statistic,
showing its performance was robust across different problem
settings. Its standard deviation was intermediate between the
extremal results by the other algorithms, indicating there was
some variability in its performance, but it was still competitive
and never the worst performing algorithm with respect to this
statistic. Results also highlight the contribution of the classiﬁer
selection stage, as in two cases (AOA = 20◦ and 40◦) the
proposed algorithm outperformed the KK variant which does
not select a classiﬁer, and obtained results which were nearly
as good in the AOA = 30◦ case.
Lastly, to demonstrate the optimization outcomes, Figure 3
shows representative airfoils obtained by the proposed algo-
rithm at each of the three optimization cases.
V. SUMMARY
The
modern
engineering
design
process
is
often
a
simulation-driven optimization problem. In practise, there
may exist candidate designs which ‘crash’ the simulation and
TABLE II
STATISTICS FOR OBJECTIVE VALUE
AOA
P
KK
EA–PS
EI–CMA-ES
20◦
mean
-1.035e+01
-8.091e+00
-6.889e+00
-1.023e+01
SD
1.326e+00
1.697e+00
6.526e-01
2.025e+00
median
-1.049e+01
-7.283e+00
-6.843e+00
-1.107e+01
min
-1.302e+01
-1.138e+01
-8.837e+00
-1.192e+01
max
-7.143e+00
-5.880e+00
-5.794e+00
-5.442e+00
α
0.01
0.01
30◦
mean
-3.155e+00
-3.192e+00
-3.146e+00
-2.910e+00
SD
4.694e-02
3.105e-02
3.345e-02
4.761e-02
median
-3.140e+00
-3.183e+00
-3.140e+00
-2.916e+00
min
-3.270e+00
-3.298e+00
-3.223e+00
-3.005e+00
max
-3.091e+00
-3.145e+00
-3.092e+00
-2.813e+00
α
0.01
40◦
mean
-2.793e+00
-2.784e+00
-2.784e+00
-2.552e+00
SD
3.380e-02
2.230e-02
4.732e-02
4.249e-02
median
-2.785e+00
-2.782e+00
-2.786e+00
-2.557e+00
min
-2.875e+00
-2.827e+00
-2.869e+00
-2.637e+00
max
-2.726e+00
-2.742e+00
-2.717e+00
-2.455e+00
α
0.01
P: proposed algorithm with model and classiﬁer adaptation.
KK: proposed algorithm restricted to a Kriging model and a k-NN classiﬁer.
EA–PS: EA with periodical sampling [18].
EI–CMA-ES: Expected Improvement framework with a CMA-ES optimizer
[1].
0
0.5
1
−0.1
0.0
0.1
AOA=20◦
0
0.5
1
−0.1
0.0
0.1
AOA=30◦
0
0.5
1
−0.1
0.0
0.1
AOA=40◦
Fig. 3.
Representative airfoils obtained by the proposed algorithm, shown
in black. For comparison, the baseline NACA0012 airfoil is shown in gray.
thus can lead to search stagnation and to a poor ﬁnal result.
To effectively handle this scenario, this paper has proposed
a
model-assisted
computational
intelligence
optimization
algorithm which introduces a classiﬁer into the search. The
latter predicts which solutions are expected to crash the
simulation, and its prediction is incorporated with the model
prediction to bias the search towards valid solutions, that is,
which are expected not to crash the simulator. To improve its
efﬁcacy, the proposed algorithm continuously selects during
the search an optimal type of classiﬁer, out of a prescribed
family of candidates. To safeguard the optimization search
in the face of model inaccuracy, the proposed algorithm
also employs a TR approach. Performance analysis using
a
representative
real-world
application
of
airfoil
shape
optimization showed the efﬁcacy of the proposed algorithm.
In future work, we consider applying the proposed algorithm
to additional challenging real-world applications with SI
vectors.
ACKNOWLEDGEMENT
The ﬁrst author thanks the Japan Society for Promotion of
Science for its support.
REFERENCES
[1] D. Büche, N. N. Schraudolph, and P. Koumoutsakos.
Accelerating
evolutionary algorithms with Gaussian process ﬁtness function models.
IEEE Transactions on Systems, Man, and Cybernetics–Part C, 35(2):183–
194, 2005.
133
FUTURE COMPUTING 2011 : The Third International Conference on Future Computational Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-154-0

[2] A. Chipperﬁeld, P. Fleming, H. Pohlheim, and C. Fonseca.
Genetic
Algorithm TOOLBOX For Use with MATLAB, Version 1.2. Department
of Automatic Control and Systems Engineering, University of Shefﬁeld,
Shefﬁeld, 1994.
[3] A. R. Conn, N. I. M. Gould, and P. L. Toint. Trust Region Methods.
SIAM, Philadelphia, Pennsylvania, 2000.
[4] M. Drela and H. Youngren. XFOIL 6.9 User Primer. Department of
Aeronautics and Astronautics, Massachusetts Institute of Technology,
Cambridge, MA, 2001.
[5] M. T. M. Emmerich, A. Giotis, M. Özedmir, T. Bäck, and K. C.
Giannakoglou.
Metamodel-assisted evolution strategies.
In J. J.
Merelo Guervós, editor, The 7th International Conference on Parallel
Problem Solving from Nature–PPSN VII, number 2439 in Lecture Notes
in Computer Science, pages 361–370. Springer, Berlin, 2002.
[6] S. Handoko, C. K. Kwoh, and Y.-S. Ong. Feasibility structure modeling:
An effective chaperon for constrained memetic algorithms.
IEEE
Transactions on Evolutionary Computation, 14(5):740–758, 2010.
[7] N. Hansen and A. Ostermeier. Completely derandomized self-adaptation
in evolution strategies. Evolutionary Computation, 9(2):159–195, 2001.
http://www.lri.fr/~hansen/cmaes_inmatlab.html.
[8] R. M. Hicks and P. A. Henne. Wing design by numerical optimization.
Journal of Aircraft, 15(7):407–412, 1978.
[9] M. E. Johnson, L. M. Moore, and D. Ylvisaker. Minimax and maximin
distance designs. Journal of Statistical Planning and Inference, 26(2):
131–148, 1990.
[10] D. R. Jones, M. Schonlau, and W. J. Welch. Efﬁcient global optimization
of expensive black-box functions. Journal of Global Optimization, 13:
455–492, 1998.
[11] J. R. Koehler and A. B. Owen. Computer experiments. In S. Ghosh,
C. R. Rao, and P. R. Krishnaiah, editors, Handbook of Statistics, pages
261–308. Elsevier, Amsterdam, 1996.
[12] K.-H. Liang, X. Yao, and C. Newton. Evolutionary search of approx-
imated N-dimensional landscapes. International Journal of Knowledge-
Based Intelligent Engineering Systems, 4(3):172–183, 2000.
[13] W. R. Madych. Miscellaneous error bounds for multiquadric and related
interpolators.
Computers and Mathematics with Applications, 24(12):
121–138, 1992.
[14] M. D. McKay, R. J. Beckman, and W. J. Conover. A comparison of
three methods for selecting values of input variables in the analysis of
output from a computer code. Technometrics, 21(2):239–245, 1979.
[15] T. Okabe. Stabilizing parallel computation for evolutionary algorithms
on real-world applications.
In Proceedings of the 7th International
Conference on Optimization Techniques and Applications–ICOTA 7,
pages 131–132. Universal Academy Press, Tokyo, 2007.
[16] C. Poloni, A. Giurgevich, L. Onseti, and V. Pediroda. Hybridization
of a multi-objective genetic algorithm, a neural network and a classical
optimizer for a complex design problem in ﬂuid dynamics. Computer
Methods in Applied Mechanics and Engineering, 186(2–4):403–420,
2000.
[17] K. Rasheed, H. Hirsh, and A. Gelsey. A genetic algorithm for continuous
design space search. Artiﬁcial Intelligence in Engineering, 11:295–305,
1997.
[18] A. Ratle.
Optimal sampling strategies for learning a ﬁtness model.
In The 1999 IEEE Congress on Evolutionary Computation–CEC 1999,
pages 2078–2085. IEEE, Piscataway, New Jersey, 1999.
[19] Y. Tenne and S. W. Armﬁeld. A versatile surrogate-assisted memetic
algorithm for optimization of computationally expensive functions and
its engineering applications.
In A. Yang, Y. Shan, and L. Thu Bui,
editors, Success in Evolutionary Computation, volume 92 of Studies
in Computational Intelligence, pages 43–72. Springer-Verlag, Berlin;
Heidelberg, 2008.
[20] Y. Tenne and C. K. Goh, editors.
Computational Intelligence in Ex-
pensive Optimization Problems, volume 2 of Evolutionary Learning and
Optimization. Springer, 2010. URL http://www.springerlink.
com/content/v81864.
[21] Y. Tenne, K. Izui, and S. Nishiwaki.
Handling undeﬁned vectors in
expensive optimization problems. In C. Di Chio, editor, Proceedings
of the 2010 EvoStar Conference, volume 6024/2010 of Lecture Notes in
Computer Science, pages 582–591. Springer, Berlin, 2010.
[22] H.-Y. Wu, S. Yang, F. Liu, and H.-M. Tsai.
Comparison of three
geometric representations of airfoils for aerodynamic optimization. In
Proceedings of the 16th AIAA Computational Fluid Dynamics Confer-
ence. American Institute of Aeronautics and Astronautics, 2003. AIAA
2003-4095.
[23] X. Wu, V. Kumar, R. J. Quinlan, J. Ghosh, Q. Yang, H. Motoda, G. J.
McLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach, D. J.
Hand, and D. Steinberg. Top 10 algorithms in data mining. Knowledge
and Information Systems, 14:1–37, 2008.
134
FUTURE COMPUTING 2011 : The Third International Conference on Future Computational Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-154-0

