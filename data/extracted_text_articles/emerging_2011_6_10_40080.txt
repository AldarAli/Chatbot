Multipath Routing for Survivability of Complex
Networks Under Cascading Failures
Preetha Thulasiraman
Department of Electrical and Computer Engineering
Naval Postgraduate School
Monterey, CA, USA
pthulas1@nps.edu
Abstract—Complex infrastructure networks have been charac-
terized as being scale-free and therefore maintain a heterogeneous
node distribution. While scale free networks (SFN) have been
investigated using vulnerability assessments, particularly that of
cascading node failures, existing research has not dealt with the
aftermath of these failures. This paper addresses the problem of
discovering end to end paths in a SFN in the presence of cascad-
ing failures such that survivability is achieved for each source-
destination pair. We ﬁrst develop a model to capture cascading
failures in SFNs while redistributing trafﬁc load to neighboring
nodes. Given the trafﬁc distribution after the cascade of failures,
we develop a routing algorithm such that backup connections are
constructed for each source-destination pair. We formulate the
routing algorithm by exploiting the multipath topology of SFNs
and the different priorities of the trafﬁc ﬂows. We compare our
routing approach in a SFN with that of a random network in
which node distributions are homogeneous. We show that our
routing algorithm performs well under intentional node attacks
and efﬁciently considers the classiﬁcation of the trafﬁc when
constructing alternate routing paths.
Keywords – scale free networks; multipath routing; cascading
failures; load redistribution
I. INTRODUCTION
Complex networks such as the Internet, electrical power
grid and telecommunication and transportation systems are
an essential part of the global society. These infrastructure
networks are not random but rather known to be scale free,
with some nodes having a tremendous number of connections,
whereas others have only a few connections [1]. This highly
heterogeneous node distribution has led researchers to prove
that the degrees of the nodes in scale free networks (SFN)
follow a power law distribution: the probability that any node
is connected to k other nodes, P(k), is proportional to
1
kn ,
where n is a parameter whose value is typically in the range
2 < n < 3 [1]. Due to its topology, SFNs are robust against
accidental failures (which tend to affect low degree nodes),
but are vulnerable to coordinated attacks that target highly
connected nodes in order to inﬂict maximum damage by
disabling numerous connections.
The fragile properties of SFNs become more evident when
the intrinsic dynamics of the network ﬂows are taken into
account. Speciﬁcally, due to the existence of many simul-
taneous trafﬁc ﬂows, the removal of a single, highly or
moderately connected node can cause large scale cascading
failures. This domino effect results in the interruption of trafﬁc
ﬂow, service, and distribution of network resources. Thus, the
vulnerability and reliability of SFNs in the face of attacks must
be investigated.
The notion of survivability is an essential aspect of reliable
communications. Survivability consists of the ability of the
network to continue to deliver and preserve essential services
in the presence of failures. These failures can occur due to
natural faults and other unintentional errors or due to malicious
adversaries. From the viewpoint of network resilience and
survivability, a key question is whether a SFN can, in the
face of dependent and correlated node failures, retain its
functionality in terms of maintaining some sense of global
communication. In this regard, trafﬁc redistribution and robust-
ness of routing policies for SFNs is a central problem which
is gaining increased attention with a growing awareness to
safeguard critical infrastructure networks.
A. Related Work and Motivations
Over the years, researchers have investigated the cascade
based attack vulnerability of either speciﬁc infrastructure
SFNs, such as the power grid [2], [3], or that of general SFNs
with heterogeneous trafﬁc load distributions [4], [5], [6]. In
these works, different cascading failure models are analyzed
to determine the best manner in which trafﬁc load should
be redistributed to maintain service. With advances in cyber
based communication systems and their logical coupling to
infrastructure networks [7], it is imperative that the vulnera-
bilities and consequences of node failures are studied from the
perspective of network survivability [8], [9]. Survivability of
networks depends on three key capabilities: resistance, recog-
nition, and recovery [10]. While resistance repels failures from
happening, recognition and recovery deal with and evaluate
the failures to provide network restoration protocols. Thus
far, the research on providing survivable network solutions to
infrastructure networks has been tailored to focus on failure
modeling and vulnerability assessments rather than network
management [11], [12]. It is important not only to understand
how to recognize faults and vulnerabilities but also how to
recover from them.
Multipath routing has long been recognized as an effective
strategy to increase reliability. To improve the transmission
reliability, the multiple paths can be selected to be node
106
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-174-8
EMERGING 2011 : The Third International Conference on Emerging Network Intelligence

disjoint. Disjoint multipath routing provides better robustness
and a greater degree of fault tolerance than compared to the
generic multipath routing scheme. Due to these advantages,
disjoint multipath routing has been researched in order to
enhance network survivability [13], [14].
SFNs are inherently highly connected, thus there always
exists two or more paths between each source-destination pair.
When a node fails in a SFN, potentially causing a cascade of
node failures, the trafﬁc ﬂows that use the failed node should
be maintained and the services they provide must be sustained.
The aim of this paper is to ensure end to end survivability by
bypassing failed nodes using efﬁcient, robust multipath routing
in the presence of cascading failures, while redistributing the
corresponding trafﬁc loads accordingly.
B. Contributions and Organization
The contributions of this paper are two-fold. First, we
develop a local trafﬁc redistribution model for a failed node by
redistributing its load uniformly among its neighbors, taking
into consideration that this redistribution can possibly overload
the neighboring nodes, causing a series of cascading failures.
Second, given the redistribution of the load, we establish
survivable shortest disjoint multipath routes that bypass the
failed node(s). The shortest disjoint paths are determined by
the priority of the trafﬁc ﬂows; some ﬂows, due to its service
requirements, require backup paths that are more reliable
than others (i.e., to ensure service availability). Therefore, the
backup path for each trafﬁc ﬂow should be determined using
local topological and connection information. In other words,
the shortest paths for increasing trafﬁc ﬂow priority are those
between a source and destination that cumulatively traverse
the least number of highly connected nodes.
The rest of this paper is organized as follows: Section II
discusses the system model. Section III discusses the load re-
distribution model based on cascading failures and Section IV
develops the disjoint multipath route selection procedure based
on trafﬁc priority. We show our performance analysis using
simulations in Section V and conclude the paper in Section VI.
II. SYSTEM MODEL
The topology used in this paper is that of a SFN. The
Barabasi-Albert (BA) model is used to generate SFNs with a
power law degree distribution. The BA model is a well known
algorithm for generating random SFNs using a preferential
attachment mechanism [15]. Without loss of generality, for
the purposes of this work, we construct the underlying network
structure using the BA network model.
We consider a SFN consisting of N nodes (n = 1, ..., N)
and A directed arcs (a = 1, ..., A). We assume that there
are K (k = 1, ..., K) different trafﬁc ﬂows that are routed
through the SFN, where a trafﬁc ﬂow is deﬁned as a set of
demands from a source to destination. Each trafﬁc ﬂow has a
level of service that has to be maintained, therefore a certain
amount of capacity is required along each arc of the route
taken by a trafﬁc ﬂow, k. Within these K trafﬁc ﬂows, there
are M classes of priority numbered from 0 to M − 1, where
Class 0 represents the highest class and M − 1 represents
the lowest class. Because highly connected nodes in a SFN
are more vulnerable to outside attack, it is critical that high
priority trafﬁc ﬂows route along paths that contain the least
number of highly connected nodes to ensure end to end route
survivability.
A manner in which node connectivity is measured is by
the betweenness centrality (BC) parameter of SFNs. The BC
is a measure of the number of shortest paths that go through
a node n [1]. Nodes that occur on many shortest paths have
higher betweenness than those that do not and are therefore
more vulnerable to a coordinated attack. The BC of a node is
denoted as
BC(n) =
X δn(p, q)
δ(p, q)
(1)
where δn(p, q) is the number of shortest paths between nodes
p and q and δn(p, q) is the number of shortest paths between
p and q that run through node n. The BC parameter provides
information about the physical connectivity of each node for
the purposes of routing.
For the purpose of modeling network node failures, the
actual trafﬁc load of a node (the amount of trafﬁc that each
node processes) must be considered. The trafﬁc load of a node
is directly related to its BC; the higher the BC, the higher the
trafﬁc load that the node has to support. In this paper we
assume that highly connected nodes are more susceptible to
attacks than those that are not highly connected. Therefore,
our proposed cascading failure model and routing algorithm
are developed under the scenario that a highly connected node
has failed and has caused a series of cascading failures.
III. CASCADING FAILURE MODEL: LOCAL
REDISTRIBUTION OF FAILURE LOAD
Each source-destination pair in a SFN has an active path.
This is the path on which a trafﬁc ﬂow is typically routed.
Active paths often run through highly connected nodes and
are thus exposed to attacks. In order to ﬁnd active paths on a
shortest path basis, a cost is deﬁned, κa, of an arc a as
κm
a =
m
M − 1da + (M − 1) − m
M − 1
BC(n)
(2)
where
m
is
the
current
class
of
trafﬁc
ﬂow,
m
=
0, 1, 2, ..., M − 1, da is the length of arc a, and BC(n) is
the betweenness centrality parameter.
The active paths that are determined with the above cost
are used as the default routing connection. However, when a
node fails, the path that uses this node and its load has to be
redistributed. The redistribution of the load may cause further
node failures due to overload. Fig. 1 illustrates an example
of a failed node’s trafﬁc being redistributed to its neighbors.
Note that SFNs are always at least 2-connected, meaning that
each node will have at least two disjoint paths to every other
node in the network [16]. Not all the connections for each
node to show 2-connectivity are shown in Fig. 1. The network
of Fig. 1 is simply for illustration of the load redistribution
concept.
Within a SFN, we assume that every node has a minimum
load value, Lmin and a maximum value, Lmax. All nodes have
107
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-174-8
EMERGING 2011 : The Third International Conference on Emerging Network Intelligence

Fig. 1.
Illustrates the load redistribution triggered by the failure of node i
due to a coordinated attack. Node i is removed and its load is redistributed
to the neighboring nodes
the same limit of operation, Lfail, beyond which they fail. To
start the cascade, an initial disturbance causes the failure of
a node. The algorithm for simulating the cascading failures
proceeds in successive stages as shown in Fig. 2.
Cascading Failure Model
Step1: At stage i = 0, all N nodes are initially working
under independent uniformly random initial loads
L1, L2, ..., LN ∀ [Lmin, Lmax], with Lmax < Lfail.
Step2: An initial disturbance, causes a node to fail. This
initial disturbance can either be a direct attack
on the node itself or an overload.
Step3: The nodes’ loads are incremented taking into
account the neighboring topology of the failed node.
Given that a node n has failed, L∗n > Lfail, its load
L∗n is spread uniformly among its neighbors. Each
neighbor receives L∗n
dn portion of the load where dn
is the degree of the failed node. That is the total
load of the failed node n is divided by the number
of nodes to which node n is connected to in order to
determine the amount of load each neighbor is
incremented with.
Step4: If the neighborhood of the failed node is empty
(i.e., if there are no functioning nodes connected to it),
then the failure propagation comes to an end.
Fig. 2.
Steps to model cascading failures given an initial disturbance
IV. DISJOINT MULTIPATH SURVIVABLE ROUTING UNDER
CASCADING FAILURES
Once load is redistributed, the new topology conﬁguration
has to be considered when shortest paths are determined for
each source-destination pair. When a node fails, the trafﬁc
ﬂows that traverse that node need to be routed on alternate
shortest paths that are disjoint from the original active paths.
These backup paths allow for redistribution of end to end
routing between nodes. The backup paths are determined based
on the priority of the trafﬁc ﬂow. In this paper, our objective is
to protect infrastructure networks against coordinated attacks
on highly connected nodes. Therefore, high priority trafﬁc
must traverse the least number of highly connected nodes. This
can deliver backup paths that are longer in length than other
possible paths. Low priority trafﬁc, if link capacities allow, can
use backup paths with shortest hops as long as they are not
taking away resources for high priority trafﬁc. We formulate
the discovery of backup paths as an integer linear program
(ILP). We assume that a series of cascading failures does not
partition the network, meaning that there will always exist at
least one path between each pair of nodes in the network. The
nomenclature used in the ILP formulation is shown in Table I.
TABLE I
NOMENCLATURE USED IN ILP
pk - source node of a trafﬁc ﬂow k
qk - destination node of a trafﬁc ﬂow k
λa - number of available channels on arc a
αλ
k,a - takes value of 1 if channel λ of an arc a is
used by an active path of trafﬁc ﬂow k; 0 otherwise
βλ
k,a - takes values of 1 is channel λ of an arc a is
used by a backup path of trafﬁc ﬂow k; 0 otherwise
κm
a - cost of arc a (shown in Eq. 2)
sk,a - cost of an arc a calculated for trafﬁc ﬂow k
on the backup path
Ca - capacity of an arc a
x - vector of all components of ﬂows (variables)
Before developing the ILP, two boundary cases are worth
mentioning. For Class 0, the highest priority class of trafﬁc
ﬂow, the cost of an arc is calculated only on the basis of
the BC(n). This can be seen from Eq. 2. This results in
ﬁnding backup paths that omit highly connected nodes. This
causes the backup connections of Class 0 trafﬁc to have a low
probability of breaking. However, the backup paths may not be
the shortest ones. For Class M − 1, the lowest priority trafﬁc
ﬂow, the backup connections do not have to be guaranteed
service continuity. For these ﬂows, the cost of each arc is
determined solely by the length of the arc, da. For all other
classes of trafﬁc ﬂows, the cost of the arcs are determined
using Eq. 2.
The ILP shown below ﬁnds backup paths while minimizing
the linear cost of the paths.
Objective Function
ϕ(x) = minimize
K
X
k=1
A
X
a=1
λa
X
λ=1
(κm
a · αλ
k,a + sk,a · βλ
k,a) (3)
subject to the following constraints
a) Capacity constraints on the number of available channels
on an arc a
λa
X
λ=1
K
X
k=1
(αλ
k,a + βλ
k,a) ≤ Ca, ∀a ∈ A
(4)
108
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-174-8
EMERGING 2011 : The Third International Conference on Emerging Network Intelligence

b) Flow balance constraints for each channel λ and for
each demand k
For a source node of an active path
X
a=(qk,j),j̸=qk
αλ
k,a −
X
a=(i,pk),i̸=pk
αλ
k,a = 1,
∀i, j ∈ N, ∀k ∈ K, ∀a ∈ A, ∀λ ∈ λa
(5)
For a destination node of an active path
X
a=(qk,j),j̸=qk
αλ
k,a −
X
a=(i,pk),i̸=pk
αλ
k,a = −1,
∀i, j ∈ N, ∀k ∈ K, ∀a ∈ A, ∀λ ∈ λa
(6)
For intermediate nodes of an active path
X
a=(i,j),i,j̸=qk,i,j̸=pk
αλ
k,a −
X
a=(i,j),i,j̸=qk,i,j̸=pk
αλ
k,a = 0,
∀i, j ∈ N, ∀k ∈ K, ∀a ∈ A, ∀λ ∈ λa
(7)
For a source node of a backup path
X
a=(qk,j),j̸=qk
βλ
k,a −
X
a=(i,pk),i̸=pk
βλ
k,a = 1,
∀i, j ∈ N, ∀k ∈ K, ∀a ∈ A, ∀λ ∈ λa
(8)
For a destination node of a backup path
X
a=(qk,j),j̸=qk
βλ
k,a −
X
a=(i,pk),i̸=pk
βλ
k,a = −1,
∀i, j ∈ N, ∀k ∈ K, ∀a ∈ A, ∀λ ∈ λa
(9)
For intermediate nodes of a backup path
X
a=(i,j),i,j̸=qk,i,j̸=pk
βλ
k,a −
X
a=(i,j),i,j̸=qk,i,j̸=pk
βλ
k,a = 0,
∀i, j ∈ N, ∀k ∈ K, ∀a ∈ A, ∀λ ∈ λa
(10)
c) Constraints to ensure node disjointness of active and
backup paths.
λa
X
λ=1
X
a=(i,j),j̸=i,i̸=pk
(αλ
k,a + βλ
k,a) ≤ 1,
∀i, j ∈ N, ∀a ∈ A, ∀k ∈ K
(11)
λa
X
λ=1
X
a=(i,j),j̸=i,j̸=pk
(αλ
k,a + βλ
k,a) ≤ 1,
∀i, j ∈ N, ∀a ∈ A, ∀k ∈ K
(12)
The constraint given in Eq. 4, assures that the total number
of channels, reserved for survivable connections on an arc a,
will not exceed the capacity of this arc. For each channel and
each demand, ﬂow balance for the active paths is assured by
Eqs. 5-7. Eq. 7 simply states that the intermediate nodes do not
store trafﬁc. Eqs. 8-10 describe the ﬂow balance constraints
for backup paths. Eqs. 11 and 12 reﬂect the requirement that
the active and backup paths be node disjoint.
V. PERFORMANCE EVALUATION
In this section, we evaluate the performance of our cascad-
ing failure model and end to end survivable routing algorithm
via simulations. We consider a SFN generated by the BA
model [15] and compare it to a random graph generated by
the algorithm given in [17]. For fairness, the number of nodes
and number of links in both are randomly set to be 1470 and
3131, respectively. The number of nodes and links chosen
generate networks that are at least two connected to ensure
disjoint paths can be obtained for each node in the face of a
cascading failure. The BA model follows the power law degree
distribution, while the degree distribution of a random graph
is Poisson. Unlike a SFN, the random graph is a homogeneous
network, in which there is no node with an enormous number
of connections. In each network, we randomly generate 4000
trafﬁc ﬂows (i.e., K=4000). The source and destination nodes
for each ﬂow are chosen randomly. Once a source-destination
pair is chosen, a shortest path between them is determined
using the cost metric given in Eq. 2. The capacity of the links
in the network are determined by the trafﬁc loads. Intuitively,
links from highly connected nodes need larger capacity since
more trafﬁc loads go through them. Thus, the capacity of an
arc (i, j) is given as
Cij ∝ BC(i) + BC(j)
(13)
where Cij is the capacity of the arc, which is proportional to
the sum of the betweenness of node i and node j. Comparing
the deﬁnition of betweenness with the routing rule of the trafﬁc
ﬂows, it can be concluded that the betweenness characterizes
the average trafﬁc load of a node [18]. In addition, each
directed arc in the networks have 8 channels (i.e., λa = 8)
available to them and are of equal length (i.e., da = 175km).
A. Simulation Results and Discussion: Cascading Failure
Model
Given a network, to start a cascade, an initial disturbance
is imposed on a node in the form of an extra load, D,
which results in the failure of that node due to overload.
This failure occurrence leads to the redistribution of the load
to neighboring nodes, which may cause further failures. As
the nodes become progressively more loaded, the cascade
continues. The cascade propagation algorithm is embedded in
a Monte Carlo simulation framework implemented in Matlab
version 7.11.0. The damage caused by the cascades for any
initial load, [Lmin, Lmax], is quantiﬁed in terms of the number
of nodes that have failed on average. This is referred to as the
cascade size, S. It is assumed that each node operates in such
a manner that the initial node loads are normalized between
the range Lmin = 0 to Lmax = Lfail = 1. Large load values
109
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-174-8
EMERGING 2011 : The Third International Conference on Emerging Network Intelligence

represent highly loaded nodes where each node is on average
operating close to its limit capacity, Lfail = 1. The range of
load conditions is normalized from 0 to 1 so that the model for
cascading failures is not limited to the propagation of failures
in speciﬁc applications. As the simulation is repeated for
different ranges of initial load, [Lmin, Lmax], with Lmax = 1
and Lmin ∈ [0, 1] the pair (L, S) is recorded.
Fig. 3 portrays the effect of propagation of failure. The anal-
ysis is performed for values of D that span the entire feasibility
range D ∈ [0, 1]. Eight different initial disturbance values
are used D ∈ [0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001, 0.0001]. The
results reﬂect the simulation of the generated SFN.
Fig. 3.
Illustrates the average cascade size, S, versus the average initial
load, L, for eight different values of the initial disturbance D. Each point is
averaged for the same range of initial load [Lmin, Lmax]
From Fig. 3, it can be seen that a low D value causes
almost no cascading failures, thus as D increases, the number
of failures also increases. This intuitively makes sense since
the value of D determines the strength of the disturbance.
B. Simulation Results and Discussion: Disjoint Multipath Sur-
vivable Routing Algorithm
To evaluate the performance of our disjoint multipath rout-
ing algorithm, we adopt the following performance metrics:
• Restoration time: restoration time is deﬁned as the
amount of time needed by the algorithm to construct an
alternate path after the failure of a node.
• Bandwidth utilization ratio: the utilization ratio of the
bandwidth is the total bandwidth used by the backup path
to the total bandwidth provided (capacity) for different
classes of trafﬁc. This metric describes how well the
backup paths use the bandwidth for different classes of
trafﬁc.
The routing algorithm was implemented using Matlab
7.11.0 and IBM’s ILOG CPLEX optimizer. In these simula-
tions we do not consider any route signalling mechanisms. We
ﬁrst look at the average restoration time of broken connections
due to node failure as a function of the class of service. The
results are shown in Fig. 4. We assume that there are 5 trafﬁc
classes, with Class 0 being the highest and Class 5 the lowest.
The results shown were averaged over 10 simulation trials in
which each trial has a different node failing, thereby causing
a different cascading failure sequence and load distribution.
It can be seen that the proposed multipath routing algorithm
leads to a signiﬁcant reduction in the restoration time for high
trafﬁc classes versus lower priority trafﬁc. Thus, our routing
algorithm efﬁciently takes into consideration the priority of
the connection when constructing a backup path between a
source-destination pair. Given the limited published research
in routing for networks with cascading failures, the restoration
time of our approach can not be compared at this time with
existing fast recovery techniques.
Fig. 4.
Illustrates the average restoration time in milliseconds for 6 classes
of trafﬁc
We next look at the bandwidth utilization ratio for different
classes of trafﬁc versus the total capacity available. Fig. 5
shows the performance of the SFN network generated by the
BA algorithm for a random failure and intentional failure (i.e.,
highly connected node removed) compared to the utilization
for the original intact network for Class 0 trafﬁc. The random
attack curve in Fig. 5 overlaps with the original one, whereas
the intentional attack curve is approximately 14% lower in
terms of bandwidth utilization. The utilization ratio of the
bandwidth decreases as the total capacity rises, which means
that a higher percentage of bandwidth is wasted. The results
obtained for Class 5 trafﬁc are shown in Fig. 6. It can be seen
that the bandwidth utilization for Class 5 trafﬁc is higher than
the Class 0 trafﬁc results. This difference in utilization ratio
results from the backup paths being longer for lower priority
connections and therefore using more bandwidth. The results
of both Figs. 5 and 6 indicate that the BA generated SFN is
robust under random attack but fragile under intentional attack.
By contrast, Fig. 7 shows the results for a randomly gen-
erated graph. It can be seen that the random graph is robust
to both random and intentional attacks; both curves perform
similarly to the original curve. There is only a slight decline
in utilization ratio when the network is intentionally attacked.
Because the random graph is homogeneous, the trafﬁc is well
distributed among all the nodes. Therefore, the attack on one
node (no matter randomly or intentionally) has little effect on
the trafﬁc performance of the whole network. Due to space
limitations, only the results for Class 0 trafﬁc are shown for the
random graph. Similar results were obtained for lower trafﬁc
110
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-174-8
EMERGING 2011 : The Third International Conference on Emerging Network Intelligence

Fig. 5.
Utilization ratio of the bandwidth in a BA generated SFN for Class
0 trafﬁc (highest priority)
Fig. 6.
Utilization ratio of the bandwidth in a BA generated SFN for Class
5 trafﬁc (lowest priority)
classes.
Fig. 7.
Utilization ratio of the bandwidth in a randomly generated network
for Class 0 trafﬁc (highest priority)
VI. CONCLUSION
In this paper we have developed an end to end disjoint
multipath survivable routing algorithm for SFNs in the pres-
ence of cascading node failures. We show that our algorithm
effectively constructs alternate paths in a SFN considering the
priority of the different trafﬁc classes. We also show that our
routing algorithm fares well when an intentional attack occurs.
In our future work, we will look at improving the cascading
failure model by redistributing load onto neighboring nodes
based on the capacity of the nodes rather than using a uni-
form distribution. We will also introduce resource allocation
mechanisms into the cascading failure routing scheme.
ACKNOWLEDGEMENT
This work was funded by the Research Initiation Program
(RIP) at the Naval Postgraduate School, Monterey, CA, USA.
REFERENCES
[1] A. Laszlo and E. Bonabeau, “Scale free networks,” Scientiﬁc American,
pp. 50–59, May 2003.
[2] I. Dobson, B.A. Carrerras, V.E. Lynch, and D.E. Newman, “Complex
systems analysis of series of blackouts: Cascading failure, critical points
and self-organization,” Chaos, American Institute of Physics, vol. 17,
no. 2, pp. 1–13, June 2007.
[3] J.-W. Wang and L.-L. Rong, “Cascade-based attack vulnerability on the
US power grid,” Safety Science (Elsevier), vol. 47, no. 10, pp. 1332–
1336, December 2009.
[4] H.J. Sun, H. Zhao, and J.J. Wu, “A robust matching model of capacity to
defense cascading failure on complex networks,” Physica A (Elsevier),
vol. 387, no. 25, pp. 6431–6435, November 2008.
[5] X. Wang, S. Guan, and C.H. Lai, “Protecting infrastructure networks
from cost-based attacks,” New Journal of Physics, vol. 11, no. 3, pp.
1–9, March 2009.
[6] J.-W. Wang and L.-L. Rong, “A model for cascading failures in scale-
free networks with a breakdown probability,” Physica A (Elsevier), vol.
388, no. 7, pp. 1289–1298, April 2009.
[7] J. Kopylec, A. D’Amico, and J. Goodall, Visualizing Cascading Failures
in Critical Cyber Infrastructures, Springer, 2007.
[8] R. Zimmerman, “Decision-making and the vulnerability of interdepen-
dent critical infrastructure,” in Proceedings of the IEEE International
Conference on Systems, Man and Cybernetics, 2004, pp. 4059–4063.
[9] R. Zimmerman and C. Restrepo, “The next step: Quantifying infras-
tructure interdependencies to improve security,” International Journal
of Critical Infrastructures, vol. 2, no. 23, pp. 215–230, February 2006.
[10] “Survivable mobile wireless networks: Issues, challenges, and research
directions,”
in Proceedings of ACM Workshop on Wireless Security,
2002, pp. 31–40.
[11] Y.Y. Haimes, B.M. Horowitz, J.H. Lambert, J.R. Santos, C. Lian, and
K.G. Crowther,
“Inoperability inputoutput model for interdependent
infrastructure sectors,” Journal of Infrastructure Systems, vol. 11, pp.
67–709, June 2005.
[12] Y. Xia and D.J. Hill, “Attack vulnerability of complex communication
networks,”
IEEE Transactions on Circuits and Systmes-II: Express
Briefs, vol. 55, no. 1, pp. 65–69, January 2008.
[13] X. Huang and Y. Fang,
“Multiconstrained qos multipath routing in
wireless sensor networks,” Wireless Networks, vol. 14, no. 4, pp. 465–
478, 2008.
[14] P. Thulasiraman, J. Chen, and X. Shen, “Multipath routing and max-min
fair qos provisioning under interference constraints in wireless multihop
networks,” IEEE Transactions on Parallel and Distributed Systems, vol.
22, no. 5, pp. 716–728, 2011.
[15] A.-L. Barabasi and R. Albert,
“Emergence of scaling in random
networks,” Science, vol. 286, no. 5439, pp. 509–512, October 1999.
[16] P. Thulasiraman, S. Ramasubramanian, and M. Krunz, “Disjoint multi-
path routing to two distinct drains in a multi-drain sensor network,” in
Proceedings of IEEE International Conference on Computer Communi-
cations (INFOCOM), 2007, pp. 643–651.
[17] P. Erdos and A. Renyi,
“On the evolution of randome graphs,”
in
Mathematical Institute of Hungarian Academy of Sciences, 1960, pp.
17–60.
[18] K.-I Goh, B. Kahng, and D. Kim,
“Universal behavior of load
distribution in scale free networks,” Physical Review Letters, vol. 87,
no. 27, pp. 278–281, December 2001.
111
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-174-8
EMERGING 2011 : The Third International Conference on Emerging Network Intelligence

