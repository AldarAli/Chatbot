EEG based Valence Emotion Recognition by the Cognitive Model of Emotion
Jun-Su Kang and Minho Lee* 
School of Electronics Engineering  
Kyungpook National University 
Taegu, South Korea  
E-mails: {wkjuns, mholee}@gmail.com 
 
Abstract—In this study, we propose a valence emotion 
recognition model based on the cognitive model of emotion. The 
cognitive model of emotion consists of a perceptual system, body 
response system, schematic system, and propositional system. In 
the implementation, we build the computational model without 
the perceptual system. To demonstrate our proposed method, 
we design an experiment on valence emotion task. From the 
results, we confirm that the proposed model gives the best 
results with the most significant electrode pairs (MSP) 15 at the 
theta band. 
Keywords-EEG; emotion; cognitive model of emotion; phase 
locking value. 
I. 
 INTRODUCTION  
In day to day life, humans encode their emotional state in 
activities such as writing, drawing, speaking, etc. Therefore, 
decoding or understanding their emotional state plays an 
essential role in creating social linkages and supporting 
efficient service [1]. The encoded information of emotion is 
represented through explicit and implicit expressions [2].  
Proposed method uses an EEG signal which is a kind of 
implicit expressions to recognize human valence emotion as 
two classes (positive and negative). EEG signal is acquired 
from the scalp-level of the brain non-invasively and provides 
good temporal resolution. It is important to identify the 
differences in brain activities in different regions of the brain 
to understand brain cognition in EEG analysis. Connectivity 
analysis can identify the differences in brain activities in 
different sensor locations of EEG device [3]. Among several 
connectivity calculations, Phase Locking Value (PLV) 
method [4] has an advantage over other methods because it is 
more discriminative. EEG phase differences are used to 
estimate conduction velocity and synaptic integration time [5]. 
Phase information is also robust to fluctuation in amplitude. 
PLV is a possible means to represent the synchronization of 
EEG signals. In our previous work [6], we successfully 
classify the human intention using PLV which only considers 
the relative phase between two different sensors.  
The proposed emotion understanding system is based on 
Leventhal’s cognitive model of emotion processing [7], which 
is primarily derived from the perceptual motor model of 
emotion. We apply the PLV extraction as the body response 
system, Fuzzy C-Means clustering (FCM) [8] and Adaptive 
Neuro-Fuzzy Inference System (ANFIS) [9] are applied for 
the schematic system and the propositional system, 
respectively. ANFIS is the implementation of the fuzzy 
inference system to adaptive networks for developing fuzzy 
rules with suitable membership functions given the inputs and 
outputs. This paper is organized as follows. In Section 2, the 
proposed method is presented. In Section 3, the experimental 
setup is represented. Results and conclusion are presented in 
Section 4 and 5, respectively. 
II. 
PROPOSED METHOD 
In the proposed hierarchical and multilevel process theory, 
Leventhal attempted to incorporate biological as well as 
conceptual aspects of emotion processing. Figure 1 shows the 
cognitive model of emotion which consists of four systems, 
and Figure 2 shows the computational model of emotion 
corresponding to Figure 1. First, the stimuli are perceived 
through senses (sight, hearing, touch, etc.) in Perceptual 
system. Then body responds implicitly (feeling, thought, etc.) 
or explicitly (facial expression, voice, tone, gesture, etc.) to 
stimuli in Body response system. Third, in the Schematic 
system the emotional clusters for building abstracts of current 
emotional states are made. Finally, in the last system, called 
Propositional system, labels are given to these emotional 
clusters. 
 
 
Figure 1. Cognitive model of emotion 
 
 
Figure 2. Overall structure of the proposed model 
 
In this study, implementation of the perceptual system 
remains as future work. In the body response system, which 
is the first system in our model, the EEG signal is recorded 
when participants are watching a movie clip. From the 
acquired EEG signal, the emotional features are extracted by 
10
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

using PLV, which calculates the phase stability between two 
different EEG sensors. After extracting the PLV feature, 
MSP are selected [6]. We then build the PLV tensor to 
represent the dynamics of brain state. The second system in 
our model is called schematic system wherein the abstract 
representations 
of 
emotional 
features 
such 
as 
the 
belongingness of each representation (level of phase stability) 
are formed by FCM. The PLV descriptor is clustered in three 
clusters using FCM. The last system of our model is called 
propositional system wherein the decision process is 
performed by ANFIS. 
III. 
EXPERIMENTAL SETUP 
A. Dataset description 
Twenty-five healthy university students (twenty-four 
males and one female) participated in the study. Their mean 
age was 22.70 years (±2.01 years). Data of 7 participants 
could not be analyzed because of missed-trigger information 
(1 participant, male) and noise in EEG signals (6 participants, 
5 males and 1 female). There are total 6 blocks for emotion 
task. Figure 3 shows experiment procedure of this study.  
 
 
Figure 3. Experiment procedure 
 
After watching the emotion eliciting movie, the subjects were 
asked to rate the video on a discrete scale ranging from 1 to 7. 
If the response score of a subject is over 4, we consider it as 
positive status, otherwise, it is considered as negative status. 
B. Preprocessing of EEG data 
EEG Data is acquired by Biosemi ActiveTwo system. 
Total 32 channels (Fp1/2, AF3/4, F3/4/7/8, Fz, FC1/2/5/6, 
C3/4, Cz, T7/8, CP1/2/5/6, P3/4/7/8, Pz, PO3/4, O1/2, and Oz) 
are used, and the sampling rate is set as 2048Hz. Notch filter 
is applied to remove the electric line noise, and bandpass filter 
is applied to extract the 3 to 50Hz frequency representation. 
C. Data processing 
PLV feature is extracted using 2.5 seconds window from 
the preprocessed EEG data, and FCM is applied to set the PLV 
level to the three membership. The output of FCM is used as 
an input to ANFIS. Parameters of ANFIS are default setup of 
MATLAB R2018b, namely the number of nodes is 12, the 
number of fuzzy rules are 2, etc. 
IV. 
RESULTS  
Based on the cognitive model of emotion processing, the 
proposed system attempts to determine the negative and 
positive emotional states by EEG signals while participants 
watch movie clips. For the performance evaluation, subject-
wise Leave-One-Out cross validation was used. In Figure 4, 
average results of the proposed system are summarized, and 
white and gray bars are average train and test accuracy, 
respectively.  
 
Figure 4. Average train and test performance of the proposed method 
according to the number of MSP 
 
The best test accuracy (61.904%) in criteria of average 
accuracy is given with MSP 15 at theta frequency band.  
V. 
CONCLUSION  
In this study, we implemented the computational model of 
valence emotion classification based on the cognitive model 
of emotion. The proposed model was successfully 
implemented and the best test performance is given from MSP 
15 at the theta frequency band. In the future work, we will 
implement the perceptual system and link this to the current 
computational model. 
ACKNOWLEDGMENT 
This work was supported by the National Research 
Foundation of Korea (NRF) grant funded by the Korea 
government (MSIP) (No. NRF-2016R1A2A2A05921679). 
REFERENCES 
[1] A. Esposito, A. M. Esposito, and C. Vogel, “Needs and 
challenges in human computer interaction for processing social 
emotional information,” Pattern Recognition Letters, vol. 66, 
pp. 41-51, 2015. 
[2] A. Wood, M. Rychlowska, S. Korb, and P. Niedenthal, 
“Fashioning the face: sensorimotor simulation contributes to 
facial expression recognition,” Trends in cognitive sciences, 
vol. 20, no. 3, pp. 227-240, 2016. 
[3] J. Dauwels, F. Vialatte, T. Musha, A. Cichocki, “A 
comparative study of synchrony measures for the early 
diagnosis of Alzheimer’s disease based on EEG,” NeuroImage, 
vol. 49, no. 1, pp. 668-693, 2010. 
[4] J. P. Lachaux, E. Rodriguez, J. Martinerie, and F. J. Varela, 
“Measuring phase synchrony in brain signals,” Human brain 
mapping, vol. 8, no. 4, pp. 194-208, 1999. 
[5] H. Suzuki, “Phase relationships of alpha rhythm in man,” The 
Japanese journal of physiology, vol. 24, no. 6, pp. 569-586, 
1974. 
[6] J. S. Kang, U. Park, V. Gonuguntla, K. C. Veluvolu, M. Lee, 
“Human implicit intent recognition based on the phase 
synchrony of EEG signals,” Pattern Recognition Letters, vol. 
66, pp. 144-152, 2015. 
[7] H. Leventhal, "A perceptual-motor theory of emotion," 
Advances in experimental social psychology, pp. 117-182: 
Elsevier, 1984. 
[8] J. C. Bezdek, R. Ehrlich, and W. Full, “FCM: The fuzzy c-
means clustering algorithm,” Computers & Geosciences, vol. 
10, no. 2-3, pp. 191-203, 1984. 
[9] J. S. Jang, “ANFIS: adaptive-network-based fuzzy inference 
system,” IEEE transactions on systems, man, and cybernetics, 
vol. 23, no. 3, pp. 665-685, 1993. 
11
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

