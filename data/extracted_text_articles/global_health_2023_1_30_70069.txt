Considerations for Applying MediaPipe to Gait Analysis 
Comparison with Commercial Software 
 
Yasutaka Uchida 
Dept. of Life Science 
Teikyo University of Science 
Tokyo, Japan 
e-mail: uchida@ntu.ac.jp 
 
Eiichi Ohkubo 
Dept. of Life Science 
Teikyo University of Science 
Tokyo, Japan 
e-mail: ohkubo@ntu.ac.jp 
Tomoko Funayama 
Dept. of Occupational Therapy 
Teikyo University of Science 
Yamanashi, Japan 
e-mail: funayama@ntu.ac.jp 
 
Yoshiaki Kogure 
Professor Emeritus 
Teikyo University of Science 
Tokyo, Japan 
e-mail: kogure@ntu.ac.jp
 
 
Abstract— MediaPipe, which enables skeletal analysis using 
videos of walking subjects without the use of markers, can be 
easily introduced into rehabilitation sites. Because the video 
used for analysis is captured from a smartphone or video 
camera, the viewpoint is obtained from a single camera. 
Therefore, the skeletal coordinates cannot be recognized during 
analysis and the obtained coordinates are relative values. In this 
study, we used data obtained from MediaPipe to calculate stride 
length, walking speed, knee height change, and ankle angle and 
compared them with commercially available software. During 
the measurements, a pseudo-motor restriction was applied by 
wearing a supporter on the right knee. We found that the 
presence of motion restriction and various parameters during 
gait can be obtained by combining the confirmation of gait 
trajectory with 3D analysis and clarifying the measurement 
range. 
Keywords-MediaPipe; skeletal analysis; smartphone; 3D 
analysis. 
I. 
 INTRODUCTION 
Measures are urgently required to prepare for a rapidly 
aging population. Falling is a significant problem among the 
elderly, as it causes them to be bedridden and places a heavy 
burden on their caregivers [1]-[8]. Therefore, motion analyses 
have been conducted using insoles [9][10] and mat-like 
pressure sensors arranged two-dimensionally [11], wearable 
devices [12], and images [13]. For gait analysis, 
measurements using multiple cameras with attached markers 
have been used in rehabilitation facilities, as typified by the 
Vicon system [14][15]. A camera called Kinect [16]-[19] has 
also been used to analyze the movement of a camera linked to 
game software. However, problems remain, such as the need 
for an expensive dedicated system, space for recognizing the 
markers, and an operator who is familiar with the dedicated 
software. The rapid spread of smartphones has facilitated the 
capturing of pictures anytime and anywhere, and the threshold 
for capturing pictures has decreased. Moreover, affordable 
and easy-to-use software is available. The introduction of a 
system requires continuous cost. For this reason, it is currently 
in a state where it cannot be sufficiently spread. 
Software that can perform skeleton authentication 
includes OpenPose [20][21] developed by Carnegie Mellon 
University and MediaPipe [22]-[24] released by Google. Both 
use deep learning and have a high certification system. 
In our previous work [25], we presented a basic 
application of MediaPipe in the field of rehabilitation. 
Furthermore, for the use of a walking assist device, we 
reported that the effect continued even approximately 5 min 
after the walking assist device was removed. In this paper, we 
report the results of additional research on the accuracy and 
application range of walking parameters obtained using 
MediaPipe. If the analysis results from front filming can be 
utilized, data captured in hallways can also be used. In this 
study, we performed the analysis using front filming. 
MediaPipe, which can use Python, has the potential to be 
used by healthcare and welfare professionals who are not 
analysis experts. The ability to analyze videos from the front 
view using MediaPipe can also enable filming in 
rehabilitation rooms and hallways of hospitals and facilities; 
thus, healthcare and welfare professionals can use it 
themselves.  
Section II describes the experimental methodology, 
including the software used and the commercially available 
equipment and software. Section III shows the results using 
MediaPipe and commercial software. Section IV discusses 
the results obtained with the two types of software. Section V 
presents the conclusions. 
This study was approved by the Ethics Committee on 
Research with Humans as Subjects of the Teikyo University 
of Science. 
12
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

II. 
EXPERIMENTS 
The participant was a male in his 60s. During the 
measurement, his right knee was fixed with a supporter to 
pseudo-restrict his movement, and a comparison was made 
using the tool ORPHE ANALYTICS [26] to confirm the 
accuracy of the calculation results obtained from the 3D 
coordinate data obtained using MediaPipe. This software 
enabled us to attach ORPHE CORE®, which utilizes 
acceleration and angular rate meters, to the instep of a shoe 
using a special attachment device that can be fixed to the 
shoelace. The data obtained from these sensors could be 
analyzed to display various analysis results. A photograph of 
the ORPHE CORE® attached to the shoelaces of a shoe is 
shown in Figure 1.  
 
 
 
Figure 1. ORPHE CORE® attached to the shoelaces using an attachment. 
 
Owing to the limitations of the laboratory, we could not 
use the timed up and go method, in which the participant 
stands from a seated position in a chair, walks around a cone 
3 m away, and sits down again while being observed and 
photographed from the lateral direction. Therefore, to enable 
analysis using ORPHE ANALYTICS from the front, we used 
an iPhone with ORPHE TRAC installed to receive 
acceleration signals from ORPHE CORE via Bluetooth; 
simultaneously, the data of the walking state were uploaded 
to the cloud service.  
A video of the walking condition displayed on the ORPHE 
ANALYTICS screen was recorded at 720p using the free 
software AG Desktop Recorder [27]. This screen was loaded 
into MediaPipe, which was operated using Jupyter Notebook 
in Python, to obtain 3D data corresponding to 33 locations on 
the Land Marker. From these data, we extracted data for the 
left and right hips, knees, ankles, and toes. Based on these 
data, Python displayed the trajectories of the knees and other 
parts of the body in 3D. In addition, Microsoft Excel was used 
to calculate the change in the difference between the knee and 
ankle. The angle of the ankle was calculated using vectors 
connecting the ankle and knee and the ankle and toe. 
Figure 2 shows examples of measurements using 
MediaPipe. The image on the left shows the measurement 
without motion restriction, and that on the right shows that 
with motion restriction. 
 
 
Figure 2. Examples of measurement results. 
 
The supporter that restricts movement is worn on the right 
knee, although it is difficult to see from the photo. 
III. 
EXPERIMENTAL RESULTS 
A. Measurement of Strides  
The right-foot ankle trajectory measured with the 
MediaPipe is shown in Figure 3. Only one round trip was 
used in the analysis. This is because plotting the trajectory of 
a round-trip walking state would cause the trajectories to 
cross each other, making them difficult to read. Because the 
camera is fixed, the coordinate data are x and y values 
corresponding to the 2D screen, except for the z-axis 
coordinates in the depth direction, which are relative, a 
characteristic of MediaPipe. Therefore, the data for one round 
trip were used in this study because performing a simple 
analysis is difficult. The amplitude increased until the change 
of direction occurred, indicating that the z-axis value did not 
change significantly during the change in direction. The area 
from the start of the walking to the change in direction was 
obtained. 
The z-axis values for walking when approaching the 
camera are shown in Figure 4. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. Right-foot ankle trajectory measured with MediaPipe. 
 
turn 
start 
end 
13
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

 
 
Figure 4. Z-axis values for walking when approaching the camera. 
 
 
 
Figure 5. Result of modifying the effect of walking direction. 
 
Numerical data were displayed in Excel, and the 
inclination due to the walking direction was obtained; the 
corrected results are shown in Figure 5. Using this diagram, 
we considered the point corresponding to the landing to be the 
minimum value based on the change in amplitude. As the 
figure shows, the amplitude increased as the participant 
approached the camera, and the center of the amplitude also 
increased. Therefore, the center of the amplitude was 
approximated as increasing with a linear function, and the 
difference from the coordinate data was considered. The 
minimum value was set as the landing point of the foot when 
the amplitude varied periodically, although a certain variation 
was observed. The actual measurement was obtained from the 
screen position, and the stride length was determined as the 
distance between the landing points. Walking speed was 
calculated from the respective times. 
In the MediaPipe, the stride length was 0.80–0.90 m, and 
the velocity obtained was 0.8 m/s. The stride lengths of the 
left and right legs were 0.70 and 0.80 m, respectively. In the 
right leg with restricted motion, the stride length was larger 
owing to the hip motion. 
The left and right stride lengths obtained from ORPHE 
were 0.75 and 1.0 m, respectively, which were larger than the 
values obtained from MediaPipe. In both cases, the value for 
the right leg was larger. The walking speeds on the left and 
right sides were 0.78 and 0.76 m/s, respectively, which were 
almost the same. 
B. Results of knee height measurements 
Figure 6 shows the results of MediaPipe for the changes in 
the right and left knee height during walking. Red indicates 
the right knee with limitation of motion by the supporter, and 
blue indicates the left knee without limitation of motion. Here, 
the results are also shown from the beginning of walking to 
turning, considering the effect of rotation. 
 
 
 
Figure 6. Height of the knee position evaluated using MediaPipe. 
 
The results of the ORPHE ANALYTICS measurement of 
knee height are shown in Figure 7. The upper-left corner of 
the screen is the origin, and the maximum y-axis 
corresponding to the vertical direction is represented by 352 
pixels. Therefore, the height of the right knee, which is a small 
value in the figure, had a higher value. The horizontal axis 
represents the number of measurement points for data analysis 
and not the time axis. The y-axis value for the x-axis, which 
corresponds to the direction of motion, changed significantly 
when the participant changed the direction of gait during the 
measurement. When comparing knee heights, we used not 
only moving images but also changes in the x-axis direction, 
which is characteristic of a change in direction, and deleted 
data from points in the range that appeared to indicate a 
change in the turn direction. 
 
 
Figure 7. Knee height measurements with ORPHE ANALYTICS. 
14
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

C. Measurement Results of the ankle angle 
The results of the evaluation of the right ankle angle with 
and without pseudo-motor restriction are shown in Figure 8. 
(a) shows results with motion restriction added and (b) 
without. For the right foot with pseudo-motor restriction, 
almost no change in the ankle angle was observed during 
walking, whereas for the right foot without motor restriction, 
the amplitude of the angle widened in the last part of the gait, 
although it was very slight. 
For comparison, Figure 9(a) shows the left ankle angle 
without pseudo-motor restriction, and (b) shows the left ankle 
angle change without restriction. The values were large owing 
to the shooting angle. No characteristic waveform changes 
were observed in the left foot. This may reflect the difference 
in flexion and dorsiflexion of the participant’s left and right 
feet. 
The ORPHE ANALYTICS data were not directly 
displayed as an ankle angle, but the Euler angle obtained from 
the accelerometer was considered to correspond to it. The 
angle changed abruptly at regular intervals, which was 
considered to correspond to the kicking of the foot. The plastic 
fixture was used to hold the shoelaces in place; therefore, the 
changes may have been large and different, but we considered 
that more absorption changes could be measured with the 
plastic fixture than with MediaPipe. 
 
 
 
        (a)  
 
 
 
  (b) 
Figure 8. Angles of the right ankle without restriction. 
 
 
     (a) 
 
 
 
 
 
(b) 
Figure 9. Angles of the left ankle without restriction. 
 
 The ORPHE ANALYTICS data did not directly display 
this as an ankle angle, but the Euler angle obtained from the 
accelerometer was considered to correspond to it. The results 
of the motion restriction are shown in Figure 10. (a) and (b) 
for the left and right ankles, respectively.  
 
 
 
 
  
(a) 
 
 
 
 
 
(b) 
 
Figure 10. Euler angle of the right ankle. 
15
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

The angle changed abruptly at regular intervals, which was 
considered to correspond to the kicking of the foot. The angle 
was already approximately 30° because a plastic fixture was 
used to hold the shoelaces in place. Although a large change 
in the measurement angle may have been measured owing to 
the fixing method, a more absorbing change was considered 
to be measured compared with MediaPipe. 
 
IV. 
DISCUSSION 
In this experiment, the main reason for the difficulty in 
analysis was that the measurement had to be performed under 
conditions where frequent changes in direction occurred 
owing to the limitations of the measurement location. Because 
the left and right foot coordinate values were different owing 
to the camera angle, simple comparison and analysis were not 
possible, and a combination of 3D plots is considered 
necessary for motion analysis of the knee and ankle. In 
contrast, ORPHE ANALYTICS®, a commercially available 
software, provided data with correction, but although it 
provided sufficient characteristic data of gait in terms of 
coordinate values, it was more difficult to handle than 
MediaPipe owing to the limited number of pixels; therefore, it 
may have not provided sufficient accuracy. However, owing 
to the limitation of the number of pixels, it was more difficult 
to handle than MediaPipe. 
Because only one participant was used in this 
measurement, the data were limited to a specific individual. It 
would be important to increase the number of participants in 
the future. In addition, an accurate evaluation can be 
conducted by changing the fixation position of the ORPHE 
CORE® to the inside of the shoe for measurement and 
comparison. 
V. 
CONCLUSIONS 
The values obtained through calculation from MediaPipe, 
which can display skeletal certification, were compared with 
those of commercially available gait measurement systems to 
investigate the differences. The study revealed that the effects 
of different angles of video recording during gait should be 
considered in programming and in determining the results 
obtained with MediaPipe. However, MediaPipe can be an 
effective tool for determining walking conditions when the 
cost of implementing the system and the data required are 
limited. 
ACKNOWLEDGMENT 
This work was supported by JSPS KAKENHI Grant 
Numbers JP20K11924and JP23K11207. 
 
REFERENCES 
[1] Y. Uchida, T. Funayama, and Y. Kogure, “Investigation of the 
Application of MediaPipe to Gait Analysis,” in GLOBAL 
HEALTH 2022, pp. 1-6, IARIA, 2022. ISBN: 978-1-61208-
995-9.  
[2] L. G-Villanueva, S. Cagnoni and L. Ascari, “Design of a 
Wearable Sensing System for Human Motion Monitoring in 
Physical Rehabilitation,” Sensors, vol. 13, pp. 7735-7755, 
2013. 
[3] Y.-L. Zheng et al., “Unobtrusive Sensing and Wearable 
Devices for Health Informatics,” IEEE Trans. Biomedical 
Engineering, vol. 61, pp. 1538-1554, 2014. 
[4] M. M. Alam and E. B. Hamida, “Surveying Wearable Human 
Assitive Technology for the Life and Safty Critical 
Applocations: Standards, Challenges and Opportunities,” 
Sensors, pp. 9153-9209, 2014. 
[5] M. J. Deen, “Information and Communications Technologies 
for Elderly Ubiquitous Healthcare in a Smart Home,” Personal 
and Ubiquitous Computing, pp. 573-599, 2015. 
[6] S. Hong and K. S. Park, “ Unobtrusive Photoplethymographic 
Monitoring Under the Foot Sole while in a Standing Posture,” 
Sensors, pp.3239, 2018. 
[7] V. Bucinskas et al., “Wearable Feet Pressure Sensor for Human 
Gait and Falling Diagnosis,” Sensors, pp. 5240, 2021. 
[8] P. M. Riek, A. N. Best and R. Wu, “Validation of Inertial 
Sensors to Evaluate Gait Stability,” Sensors, vol. 23, pp. 1547, 
2023. 
[9] T. Funayama, Y. Uchida and Y. Kogure, “Assessment of 
Walking Condition Using Pressure Sensors in the Floor Mat,” 
in GLOBAL HEALTH 2022, IARIA, pp. 7-12 , November 
2022, ISBN: 978-1-61208-995-9. 
[10] T. Funayama, Y. Uchida and Y. Kogure, “Detection of motion 
restriction with smart insoles,” Sensors & Transducers Journal, 
Vol. 259, Issue 5, pp. 61-68, 2022. 
[11] Y. Uchida, T. Funayama, K. Hori, M. Yuge, N. Shinozuka and 
Y. Kogure, “Possibility of Detecting Changes in Health 
Conditions using an Improved 2D Array Sensor System,” vol. 
259, pp. 29-36, 2022.  
[12] S. Diaz, J. B. Stephenson and M. A. Labrador, “Use of 
Wearable Sensor technology in Gait, Balance, and Range of 
Motion Analysis,” Applied Sciences, vol. 10, pp. 234, 2020. 
[13] S. Majumder et al., “Smart Homes for Elderly Healthcare-
Recent Advances and Research Challenges,” Sensors, vol. 17, 
pp. 2496, 2017. 
[14] M. Windolf, N. Gotzen and M. Morlock, “Systematic 
Accuracy and Precision analysis of Video motion Capturing 
Systems-Exemplified on The Vicon-460 system,” Journal of 
Biomechanics, vol. 41, pp.2776-2780. 
[15] T. B. Rodrigues, D. P. Salgado1, C. O. Cathain, N. O’Connor 
and N. Murray, “Human Gait Assessment Using a 3D Marker-
less Multimodal Motion Capture System,” Multimedia Tools 
and Applications vol. 79, pp. 2629-2651, 2020. 
[16] P. Plantard, E. Auvinet, A. S. Le Pierres and F. Multon,”Pose 
Estimation with a Kinect for Ergonomic Stuidies: Evaluation 
of the Accuracy Using a Virtual Mannequin,” Sensors, pp. 
1785-1803, 2015. 
[17] R. A. Clark, B. F. Mentiplay, E. Hough and Y. H. Pus, “Three-
Dimensional Cameras and Skeleton Pose Tracking for Physical 
Function Assessment: A Review of Use, Validity, Current 
Developments and Kinect Alternatives,” Gait & Postture, vol. 
68, pp. 193-200, 2019.  
[18] Y. Ma, K. Mithratatne, N. Wilson, Y. Zhang and X. Wang, 
“Kinect v2-Based Gait Analysis for Children with Cerebral 
Palsy: Validity and Reliability of Spaial Margin of Stability ad 
Spationtemporal Vaiables,” Sensors, vol. 21, pp. 2104, 2021. 
[19] D. Imoto, S. Hirano, M. Mukaino, E. Saitoh and Y. Otaka, “A 
Novel Gait Analysis System for Detecting Abnormal 
Hemiparetic Gait Patterns during Robo-assisted Gait Training: 
A Criterion Validity Study among Healthy Adults,” Frontiers 
in Neurorobotics, 16:1047376, 2022. 
[20] M. Ota, H. Tateuchi, T. Hahiguti and N. Ichihasi, “Verification 
of validity of gait analysis systems during treadmill walking 
and running using human pose tracking algorithm,” Gait and 
Posture, vol. 85, pp. 290-297, 2021. 
16
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

[21] Y. Saiki et al., “Reliability and validity of OpenPose for 
measuring hip knee ankle angle in patients with knee 
osteoarthritis,” Scientific Reports, vol. 13, pp. 3297, 2023. 
[22] V. Bazarevsky et al., “BlazePose: On-device Real-time Body 
Pose tracking,” arXiv:2006.1204v1 [cs.CV] 2020.  
[23] G. Kaur, G. Jaju, D. Agawal, K. Lyer and C. M. Prashanth, 
“Implementation of Geriatric Agility Detection Using 
MediaPipe Pose,” International Journal of Recent Advances in 
Multidisciplinary Topics, vol. 3, pp. 119-124, 2022, 
ISSN:2582-7839.  
[24] J.-L. Vhung, L.-Y. Ong and M-C. Leow, “Comparative 
Analysis of Skelton-Based Human Pose Estimation,” Future 
Internet, vol.14, pp. 380, 2022.  
[25] Y. Uchida, T. Funayama, and Y. Kogure, “Possibility of Gait 
Analysis with MediaPipe and Its Application in Evaluating the 
Effects of Gait-assist Devices”, International J. of Advances in 
Life science, vol.15, no 1&2, pp. 45-55, 2023. 
[26] Y. Uno et al., “Validity of Spatio-Temporal Gait Parameters in 
Healthy Young Adults Using a Motion-Sensor-Based Gait 
Analysis System (ORPHE ANALYTICS) during Walking and 
Running,” Sensors, vol.  23, pp. 331, 2023. 
[27] AG Desktop Recorder: https://streamgaga.com/how-to-use-ag-
desktop-recorder, retrieved: August, 2022. 
 
 
17
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-112-1
GLOBAL HEALTH 2023 : The Twelfth International Conference on Global Health Challenges

