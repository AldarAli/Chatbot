A Web-Based Communication Tool for
Arabic-Speaking Newcomers to Canada
Fatma Ben Mesmia
dept. of Computer Science)
University of Regina
Saskatchewan, Canada
Fatma.Ben.Mesmia@uregina.ca
Malek Mouhoub
dept. of Computer Science
University of Regina
Saskatchewan, Canada
malek.mouhoub@uregina.ca
Abstract—The development of a communication aid tool for
Non-English-Speaking newcomers to Canada is very important
for their integration, self-reliance and contribution to the new so-
ciety. Such a tool will indeed overcome the language barriers that
the newcomers might be challenged with, which will ease their
struggle in their ﬁrst days in a foreign country. Following on a
previous work extending the Pictopages software to address these
challenges for the Arabic-speaking new comers to Saskatchewan,
Canada, we propose a new web-based communication tool relying
on a multilingual ontology. More precisely, the multilingual
ontology is used to structure items, extracted automatically from
Wikipedia via a Natural Language Processing (NLP) module. Our
proposed communication tool allows newcomers to communicate
and to interact with the target community via audio, text
and visual symbols. In this regard, the tool includes several
functionalities, such as a multilingual automatic speech-to-speech
translation, localisation via Google Maps web mapping service,
and important information and resources for newcomers. The
latter are well-organized in a hierarchical manner, thanks to our
proposed multilingual ontology.
Keywords- Communication aid; Pictogram; Audio-visual
strategy; Multilingual ontology; NLP.
I. INTRODUCTION
Communication aid tools that target people with intellectual
or developmental disabilities have demonstrated their capa-
bility to help communicating successfully with others. The
provided tools play a signiﬁcant role to overcome commu-
nication issues as they are based on several technologies,
including pictograms (clear symbols in black and white) and
audio messages. Nowadays, it is important to make these
communication aid tools available to newcomers. These tools
will not only help to communicate but encourage users to
engage a discussion in the new language. In other words,
through a well-developed communication assistant system,
newcomers will overcome their language barriers and be able
to better share and transmit their opinions, ideas and thoughts.
This will lead to improve their communication skills in the
target language and facilitate their integration in the new
society.
In [1], a new methodology has been proposed to develop
a communication aid tool for Arabic-speaking new comers to
Saskatchewan, Canada. The target tool extends the Pictopages
software by attaching Arabic and English audio messages to
a set of pictograms. More precisely, the user will commu-
nicate by selecting the appropriate pictogram symbol, which
will output an audio sound in both languages (Arabic and
English). Indeed, pictograms are symbols that express a clear
and adequate visual representation of a given item, concept,
location, service, etc. The methodology and the related tool
do however have the following limitations. First, Pictopages
software is only available for IPads, which limits its usability
by newcomers. Second, while Pictopages allows the addition
and customization of new pictograms, audio messages have
to be produced and added manually. This is a tedious task
especially given that users have different needs, over time,
which will translate to a large number of items that have to be
added dynamically. Finally, the methodology requires a face
to face interaction with a set of participants to evaluate the
new tool. This latter phase is not practical due to the current
COVID-19 measures, among other challenges.
Our main goal in this paper is to follow up on the work in
[1], and to address its limitations. More precisely, we propose
a new Web-based communication tool for Arabic-speaking
newcomers to Canada, meeting the following main objectives.
1) Facilitate the communication (of Arabic-speaking new-
comers) in the two ofﬁcial languages of the host country
(English and French),
2) improve communication skills in the two target lan-
guages,
3) encourage community engagement,
4) and accelerate newcomers integration, self-reliance and
contribution to society.
Our proposed tool relies on a multilingual ontology,
Wikipedia and Application Programming Interfaces (APIs). In
addition to Arabic, English and French, our tool can be easily
extended to other languages. Besides, different scenarios from
a daily life/needs of a newcomer are represented and updated
via a large set of items that are extracted automatically from
Arabic Wikipedia. Also, these items are structured into a mul-
tilingual ontology created via an NLP module, and annotated
through a Web Ontology Language (OWL) language. Indeed,
the multilingual aspect is ensured by an API that extracts infor-
mation from Wikipedia articles. Furthermore, audio messages
associated with items are also recorded through an API. This
latter API allows the recording of the same tone of a male
40
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

or a female voice, and reads a word or a phrase based on its
punctuation. Moreover, our proposed tool helps newcomers
to ﬁnd geographic locations of the important places that they
might be looking for, such as hospitals, schools and grocery
stores. Finally, the tool is linked to Websites for public services
like emergency services, such as police and ﬁre departments.
The evaluation of the tool is conducted through a feedback
survey component for end-users. This will help performing a
perfective maintenance of the software.
The rest of the paper is structured as follows. In the next
section, we present an overview of the different commu-
nication aid methods. In this regard, we will ﬁrst present
a classiﬁcation of the known methods. Then, we present
previous communication aids based on pictograms. Section
3 is dedicated to a related work that has been conducted
to address the communication aid for non English-speakers,
using Pictopages. In Section 4, we describe our proposed
methodology. Section 5 provides the details of the multilingual
ontology we have adopted. Section 6 presents the different
components of our web-based application. Finally, concluding
remarks and ideas for future works are listed in Section 7.
II. OVERVIEW OF COMMUNICATION AID METHODS
A communication aid is a means of connection to help
people who are struggling with troubles of speech and commu-
nication. Likewise, this aid assists individuals through facilitat-
ing their interaction and discussion with people around them.
Besides, it allows them to share meanings more effectively [2].
Initially, a communication aid was just a simple letter written
on a board. Nowadays, this communication aid has evolved to
complex systems relying on sophisticated electronic devices.
A. Augmentative and Alternative Communication
Augmentative and Alternative Communication (AAC) is a
generic term that refers to those communication methods sup-
porting or replacing speech. AAC helps people to convey their
thoughts and encourages them to express their needs. More-
over, AAC provides an opportunity for individuals to connect
non only with family and friends but also to understand and
interact with their environment, such as in a workplace or
a shopping center [3]. AAC methods are classiﬁed into two
main classes; the ﬁrst one, named “aided AAC”, comprises
two sub-classes: “non electronic” and “electronic tools”. The
second class is called “Unaided AAC” as it does not require
the use of material or equipment. In what follows, we will
describe brieﬂy each class and sub-class.
B. Unaided Communication
Unaided communication methods are based on sign lan-
guage, gestures and body movements. This kind of communi-
cation methods are frequently used and understood by people.
According to gestures and body movements, the majority of
people are able to recognize facial expressions, communication
through eye looking, and pre-verbal gestures such as pointing.
However, a sign language is needed for individuals with
hearing and speech impairment. Besides, a sign language
has different types related to several cultures; among these
languages, we quote American Sign Language and British Sign
Language [3].
C. Aided Communication
Communication methods become sophisticated and as they
keep pace with technological progress. In this context, we
list aided communication methods, which are based on the
use of equipment. Moreover, there are two sub-classes of
aided communication methods; ”Low-tech” and ”High-tech”.
These sub-classes differ in terms of the used technologies.
Low-tech methods use old techniques characterized by their
simplicity. On the other hand, High-tech tools are based on
modern techniques using advanced features. In what follows,
we present each sub-class.
1) Low-tech communication aid: Low-tech communication
aids use writing methods to transmit the information. These
methods can be boards and books, which include signiﬁcant
symbols, meaningful letters or words and relevant pictures.
Symbols could be described graphically as in Blissymbolics
[4], which is a language containing thousands of symbols and
in Boardmaker [5], which is a graphic database dedicated to
make communication aids. The communication aids made via
Boardmaker can contain thousand symbols translated into var-
ious languages. In this kind of communication aid, individuals
can rely on eye-pointing to select a symbol or touch it directly
through ﬁngers or other movements, assuming they have the
ability to move. Otherwise, symbol selection can be done by
another person that follows the individual’s instructions until
getting the desired symbol [3] [6].
2) High-tech communication aid: High-tech communica-
tion aids allows to store and retrieve messages, having an elec-
tronic format, which helps individuals communicating through
a speech output [7]. The High-tech communication aids can
also be named SGD and VOCA, which stand respectively for
Speech Generating Devices and Voice Output Communication
Aids [8]. For these types of communication aids, the output
speech can be generated through two manners, digitized and
synthesized. According to digitized output speech, the devices
play words or completed phrases, which are recorded. In
general, these devices are the most understandable. For the
synthesized output speech, the devices exploit a text to speech
software for those who are not capable to spell words. High-
tech communication aids have two categories of devices. The
ﬁrst one is called “dedicated devices” developed exclusively
for AAC, while the second one (“non-dedicated devices”)
refers to computers running a software, to mimic AAC devices.
High-tech communication aids can be classiﬁed into static
and dynamic devices. Static devices, which can be modiﬁed
manually, contain symbols having a position ﬁxed on a paper
overlays. On the other hand, dynamic devices contain symbols,
which can be modiﬁed through a page linked to vocabularies
and messages [7] [9].
D. Communication aids based on Pictograms
Pictograms are methods of communication that are consid-
ered as ﬁgurative and informative drawings. Pictograms can
41
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

substitute written instructions to express information that can
be quickly processed, such as road trafﬁc signs. This kind of
warning and mandatory information requires clear symbols
acting as indicators. In addition, pictograms can provide a
compromise between native and non-native speakers for a
given language or between users with low level of literacy.
Through pictogram symbols, old people suffering from vi-
sual impairment can interact with other people. Moreover,
pictograms are useful for industries to spread legal information
to their workers, such as the use of dangerous and hazardous
materials [10] [11] [12]. In what follows, we present some
previous communication aids based on pictograms.
In 1976, Maharaj S. developed a visual strategy based
on pictograms, which aims to ensure the communication for
non-verbal individuals. In 1980, Maharaj’s pictogram appli-
cation started to be used internationally. As a main goal,
this application aims to offer a communication strategy for
both children and adults with disabilities that impaired their
verbal communication capabilities, such as cerebral palsy,
autism and Alzheimer [13]. The provided symbols consist
of a white symbol (corresponding to a simpliﬁed “picture”)
on a black background. The white symbol refracts light to
provide the strongest impact for communication while the
black background removes the possibility of ﬁgure ground
confusions. The proposed symbols can illustrate objects, con-
cepts or actions. They can also provide adaptive opportunities
for communication especially for those who require such
assistance for communicating with people around them, as
well as providing a platform to create classroom materials for
their beneﬁt.
Similarly, low-tech to high-tech aids are available, from
symbol-based communication boards (e.g., printable from soft-
ware applications) to symbol and picture-based applications
on mobile devices, as well as specialized, and dedicated
messaging devices. Similarly, there has also been some use of
pictograms to assist in the teaching of alternate languages [14],
or in discordant language situations for speciﬁc needs (e.g.,
delivery of healthcare services) [15]. We also note some use
of pictograms to help refugees to communicate in the language
of their host countries [16] [17].
In [14], the author reports on a work using a method based
on pictograms for teaching Turkish as a new foreign language.
The proposed method uses both pictograms and sentences
based on a context to build a new Turkish vocabulary. Besides,
this work lists original pictogram patterns to show the value
of this technique. In this regard, the author aims to help
Turkish learners to use pictograms in a context to enhance
their communication skills level in this target language. The
proposed approach described uses a bold, high impact, text-
based style of pictograms, where words are shown in a variety
of fonts, sizes, alignments, and colors with added images, such
as a leaf growing out of a letter, a cartoon drawing of a sad man
sitting on a letter (with pools of tears below), a backdrop of
a sun peeking above the clouds, letters with eyes and mouths,
and “cold” blue letters (one with a toque) in what appears to
be a snowfall. These teaching aids were intended for use in
a classroom setting. It was reported that this approach was
not only effective for teaching Turkish vocabulary, but it also
increases the ease of learning and the vocabulary.
In [18], a teaching strategy is proposed for kindergarten
students based on pictograms’ assistance, which is based
on mixing words with symbolic pictures. Indeed, the author
believes that students can understand the relationship linking
oral and written languages through learning how to recount,
read and write short poems and rhymes in Spanish. Moreover,
pictograms are used to illustrate poems and to ease not only
students’ understanding but to enhance their reading level
so they become ﬂuent. Pictograms, considered among the
ﬁrst writing forms, help boosting students’ ability to learn
and communicate (talking, listening, writing and reading).
Furthermore, students start reading a poem with a short form,
and identify pictograms in rhyme. Then, they practice the
identiﬁed words and end up by composing and reciting their
own poems.
In [15], the authors discuss the use of pictograms for
health care in the context of US Navy exercises intended
to provide training for humanitarian and disaster relief to
U.S. military, Non-Governmental Organization (NGO), and
other associated personnel. This work is motivated by the
fact that communication between those providing medical care
and those receiving it was problematic. This is due to either
a lack of skilled translators or to translators who had little
or no knowledge of medical terminology and practice. In
most cases, it was not possible for English-speaking medical
personnel to determine whether the message transmitted was
correctly translated. In some cases where NGO translators
were available to monitor local translators, it was found that
the information was not being accurately delivered, with some
of the information being highly inaccurate. Consequently,
there was a need to provide medical staff with alternate
methods of communication; additionally, those methods would
require testing for effectiveness and validity before being
put into practice. One potential method identiﬁed was the
use pictograms representing common medical conditions and
symptoms. To determine whether such pictograms would be
capable of meeting the 85% level of accuracy speciﬁed by
the American National Standards Institute (ANSI), thirty-six
images (including three duplicates) were provided to medical
personnel for interpretation. It was found that over 75% of
the (unique) images met the ANSI criterion. This suggested
that the use of pictograms could be a viable communication
method when the medical staff and patients do not speak the
same language.
Some research work have been conducted to manage the
knowledge behind the graphic display of pictograms. By doing
so, these pictograms could rely on an important semantic level
of the associated vocabularies. In [19], the authors present
an AAC device, called “Pictogrammar”, to assist people with
language impairments. Pictogrammar is based on two types
of ontology. The ﬁrst one, called Simple Upper Ontology
(SUpO), is deﬁned as a formal semantic ontology describing
detailed knowledge of actualities. The latter can be simple
42
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

words, with an important interest, to avoid and solve linguistic
issues in order to automate the grammatical supervision. The
second type, called PictOntology, is deﬁned as an ontology
developed to manage a set of pictograms linked to SUpO.
Furthermore, PictOntology has four main properties. The ﬁrst
one is to share a common ontology for students, language
pathologists, family and caregivers. The second property con-
sists in implementing an effective predictive parser. Then,
the third one is the motor planning overload, and the last
property consists in generating a natural language, which is
grammatically correct even if the input is not.
In order to encourage pictogram-based communication
within medical settings, [20] developed a smartwatch appli-
cation that offers a small number of pictogram’s symbols that
are designed speciﬁcally for emergency medical applications.
The proposed application is developed through intuitive icons
and interactive symbols. It is composed of four basic parts. The
ﬁrst one, Band aid, describes how to communicate a need for
medical aid, while the second part is designated for moods
and emotions via smiley face icons. Then, the third part is an
apple icon to describe diet and allergy issues. Finally, the last
one is a call out balloon for the chat.
In regards to developing health care applications, several
research work on the use and evaluation of pictograms have
been reported in the literature. In [21], the authors assess and
investigate the impact of pictograms on the medication adher-
ence through relevant articles from medical databases, such
as PubMed and MEDLINE. The experimental investigation
show that ten of seventeen studies have reported the signiﬁcant
role of pictograms, which complement the textual and oral
information associated with medication. According to the re-
ported studies, pictograms are efﬁcient to illustrate graphically
medical instructions and improve patient’s understanding.
Following on the success in the pharmaceutical area, the
impact of using meaningful pictograms is sill increasing.
Besides, the graphical representations offered by pictograms
are considered as an important means to convey clear and
understandable messages. For instance, the target people, low-
literacy patients, might need pictograms to remind them about
the time to take a given medicine [22].
In the agriculture ﬁeld, a new application based on pic-
tograms is proposed in [23] to help low-literacy farmers. The
proposed application allows farmers to manipulate complex
machines. The authors relied on an artist to create graphics
related to the instructions to operate the machines. In addition,
the authors added some sketches following the work in [24].
Note that the use of pictograms is not the only approach
adopted to develop communication aid. Smart devices are
also used to assist in communication and engagement. In
[25], the authors conducted an evaluation of a smartphone
application, to assist individuals having intellectual, visual
and motor disabilities, to use Whats-App messages, telephone
calls, and access to leisure activities. The proposed application
relies on a smartphone (Samsung A3) having an automated
process via a MacroDroid application [26]. It has been found
that, without this tool, the participants’ performance is close
to zero on communication and leisure activities. During the
conducted experiment, the authors observe that the frequency
of sending and receiving Whats-App messages and the use of
leisure activities increases.
In [27], the authors evaluate an extended version of a smart-
phone aided application, which supports daily communication
and leisure activities for individuals with intellectual and/or
visual disabilities. The involved participants have participated
in the program listed in [25]. In addition, the extended appli-
cation depends on a new smartphone (a Samsung Galaxy J4
Plus device, which is operated by an Android 9.0 operating
system and MacroDroid). This application relies on alternated
periods dedicated for the participants to be engaged in commu-
nication and leisure with periods in which they were provided
with instructions for daily activities. With the smartphone-
aided application in [25], the participants were engaged in
communication and leisure. However, they did not use any
activity. It has been noted that, with the extended smartphone
aided application, the participants maintain successful com-
munication and leisure engagement. The participants also start
carrying out activities with success.
III. EXTENDING PICTOPAGES FOR ARABIC-SPEAKING
NEWCOMERS TO CANADA
In [1], a methodology has been proposed to develop a
communication aid tool based on Pictopages software to
allow Arabic-speaking newcomers to select, from a list of
pictrograms, the message to be communicated. Upon selection,
the communication aid provides a recorded audio output of
the corresponding word, phrase, or sentence in Arabic and
English. Pictopages is available on iOS devices and has been
commonly adopted for special needs individuals. The idea
is to extend it to assist the Arabic-speaking refugees new
community in Saskatchewan, Canada. The methodology and
the related tool (extending Pictopages) has the following
limitations. First, Pictopages software is only available for
iPads, which makes it out of reach to newcomers. Second,
Pictopages requires a manual addition and customization of
new pictrograms. Moreover, audio messages related to the
added pictograms have then to be manually produced and
added. This manual process is a tedious task especially given
that we will expect to add a large number of items meeting the
users’ needs and requirements. In [28], the authors highlight
and criticize the manual aspect of creating pictograms, and
consider this process as time consuming, and causing compli-
cated navigation by the end-users. Moreover, the methodology
in [1] for building and evaluating the tool requires the recruit-
ment and face-to-face interaction with a set of volunteers, from
the Arabic-speaking refugee community. These two tasks have
been facilitated by the Regina Public Library (RPL), and initial
meetings have been conducted to collect feedback on common
interest areas (as shown in Figure 1). However, face to face
interaction with the participants to evaluate the new tool is
not currently possible due to the current COVID-19 measures.
Regardless of the situation with the pandemic, the recruitment
procedure is restricted to those individuals in connection with
43
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

RPL. This limits the diversity in terms of literacy level, English
skills, age group and others.
Fig. 1. Newcomers’ areas of interest
IV. PROPOSED SYSTEM
Our proposed system is meant to address the objectives and
overcoming the limitations of the tool reported in the previous
section [1]. More precisely, our ultimate goal is to facilitate
the communication in the host country ofﬁcial languages
(English and French), improve verbal communication skills,
encourage community engagement, and accelerate newcomers
integration, self-reliance and contribution to society. Therefore,
our objective consists in building a web-based communication
system that assists newcomers in different scenarios, such as
daily routine, seeking a service, and when facing emergency
situations. In this regard, we ﬁrst start by gathering an initial
study corpus containing more than 800 unstructured articles
from Arabic Wikipedia. The corpus is then provided as an
input to an NLP module to extract and annotate Arabic items,
thanks to the Finite-State transducer formalism. Furthermore,
all the established Finite-State transducers will merge extrac-
tion paths and annotation nodes, which deﬁnes the OWL
syntax to generate a structured output. Besides, these Finite-
State transducers are regrouped in a cascade acting on the
study corpus in a precise order to reduce the execution time
and to minimize the extraction and annotation errors. This
way, the NLP process leads to the generation of an Arabic
ontology that becomes multilingual by adding English and
French (and other languages) via a translation API related to
Wikipedia. Thereafter, all the annotated and structured items
go through a process consisting in organizing them based on
our multilingual ontology’s levels and calling the adequate
image and link to Wikipedia. The organization process is
included in the creation of the Web pages composing our
communication tool using Web design languages. Likewise,
important functionalities, such as automatic audio message
for each item’s label in three languages, are also added.
Finally, we propose new features, such as translation (text-to-
text and speech-to-speech), text-to-speech conversion, speech
recognition and localization via APIs. In what follows, we
present the architecture of our proposed system.
Our proposed system evolves over time (according to users’
needs) and can easily be extended, thanks to its dynamic mul-
tilingual ontology and other features. Moreover, our system
follows a three-layer architecture, as shown in Figure 2.
Fig. 2. Architecture of our proposed system
The ﬁrst one (leftmost layer), called “Presentation”, aims to
present a Web-based GUI in an ergonomic view, in order to
interact with users and collect their requests and feedback.
The received feedback can be seen as a form of learning
users’ requirements and preferences, in order to achieve a
perfective maintenance of our system. The second layer, called
“Application” layer, is the heart of our system. This layer
works behind the “Presentation” layer, and executes users
requests through a communication with APIs and the “Data”
layer.
V. MULTILINGUAL ONTOLOGY
Our proposed multilingual ontology has been created by
following two main phases. In the ﬁrst phase, an NLP process
is conducted to extract and annotate Arabic items. Then, the
second phase consists in translating these Arabic items in
English and French, based on a Wikipedia API. The NLP
process exploits a deep linguistic study that we have done
using an Arabic Wikipedia corpus. Analyzing this corpus
allows us to identify the candidate items through studying
their forms or context, and to explore the related concepts and
sub-concepts. Furthermore, the resulting conceptualization has
an important level of granularity that increases based on the
richness of the article content. A linguistic study has been
performed to match the identiﬁed terms and their associated
concepts with the OWL annotation syntax. This permits to
specify the annotation path that will be exploited during the
NLP process. Figure 3 describes our multilingual ontology
with its concepts and sub-concepts.
After conducting the NLP process corresponding to phase
one, we generate the OWL ﬁles from the semi-structured
articles storing the extracted and annotated Arabic items
thanks to an extractor that we have implemented in PHP.
These generated OWL ﬁles are the input to the second phase,
we described earlier for translating items from Arabic to
English and French, to obtain the ﬁnal multilingual form of
our ontology. This translation process is also ensured by a
PHP code that sends the queries to a Wikipedia API and
organizes the obtained results to facilitate their integration in
44
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

Fig. 3. Proposed Multilingual Ontology
our Web-based communication tool. Figure 4 illustrates an
example taken from the OWL ﬁle associated with the sub-sub-
concept “Fruits”, which belongs to the sub-concept “Food”.
The latter belongs in its turn to the main concept “Household
Consumables”, as shown in Figure 3.
Fig. 4. Example of extracted items annotated in OWL
VI. WEB-BASED APPLICATION
Our proposed communication tool is a dynamic Web-based
application, which belongs to the High-tech category. The
related Web-pages are coded using HTML, PHP, JavaScript
and CSS. The main page contains ﬁve main sections re-
spectively describing; the tool’s objective, the ten main items
representing the topics of interest, the translation module, the
map localisation module and the Contact us/Survey rubric. In
what follows, we describe each section.
Figure 5 lists the ten main topics of interests. Upon selection
of the chosen item, an audio message is generated to read the
item’s label in the appropriate language. To navigate, the end-
user needs to click on the chosen topic to get the related subset
of items, in a hierarchical manner. Figure 3 in Section V lists
the hierarchy of the different items. Among the main items, we
added new information related to the COVID-19 pandemic, as
shown in Figure 6.
Fig. 5. Main items of our communication aid
Fig. 6. Covid-19 information
These information are presented in an animated way, with
audio messages, in order to attract users’ attention. In this
regard, we provided two links where the ﬁrst one reports on
daily information regarding the pandemic in Saskatchewan.
The second link displays the disease’s portal provided by
Wikipedia.
A. Multilingual, Linked and Acoustic Items
Our communication aid contains items, which are associated
with concepts corresponding to our ontology’s levels listed in
Figure 3. These items are represented by a colorful picture
and buttons in three languages. We choose the 3D design to
create these buttons in order to adapt our communication aid
to new devices using touch screen features. Figure 7 shows
45
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

an item called “air mattress”, which belongs to the furniture’s
items.
Fig. 7. Example of a multilingual item with audio output messages
The three labels related to this item are generated auto-
matically via an API called MediaWiki API [29]. This API
accepts several parameters, and the user can select the target
language. We should mention that the generation of audio
messages is done automatically via a Google API taking the
labels as an input and generating an audio output. At ﬁrst,
we store this audio output after giving it a key in a hidden
HTML tag. Then, we call the audio via a JavaScript instruction
added to a “Onclick” function in the target button. The picture
related to each item is linked to Arabic Wikipedia to help those
newcomers who can read to get more information. Figure 3
also shows the difference between a colorful symbol and a
picture, for recognizing a given item.
B. Translation and Speech Recognition
Translation is among the most important features for new-
comers. Our tool provides three options for this feature: text-
to-text, speech-to-speech, and text-to-speech. The ﬁrst module,
related to a text-to-text translation is illustrated in Figure 8.
Fig. 8. Text to text translation
The second module, related to text-to-speech conversion,
helps newcomers to learn and improve their pronunciation in
English and French. This module can also be used to learn
the Arabic language. The third module, related to speech-to-
speech translation (see Figure 9), can be handy for those with
visual impairment. This service allows users to speak into the
microphone using their native language. The listener will then
receive the translated speech in the target language.
Fig. 9. Speech to speech translation
For each recognized language, we start by translating tran-
scripts, thanks to the used API, into the target language. Then,
we convert the translated transcript into a voice record. By
doing so, the ﬁnal audio message is added and ready to be
played by the listener. Here, the voice recognition is ensured
through a Speech Recognition API [30]. As mentioned earlier,
the three modules can be extended to other natural languages.
C. Geographic Localisation
A localisation service is provided via Google Maps web
mapping service. Through this feature, the user can see the
map and locates the target destination before going out thanks
to the street view option. Figure 10 illustrates the result for
searching “University of Regina” using the localisation service
that we provide.
Fig. 10. Geographic localisation of the University of Regina
D. Feedback survey
To collect users’ feedback, we implemented a survey that
allows to improve our tool’s functionalities, features and
services. This survey includes a set of Yes/No questions, and
rating, in three languages. Figure 11 shows the survey form,
which aims to measure the end-users’ satisfaction. Feedback
are anonymous so participants feel more comfortable, as their
privacy is protected.
46
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

Fig. 11. Survey to collect users’ feedback
VII. CONCLUSION AND FUTURE WORK
We propose an extensible and dynamic Web-based commu-
nication tool for Arabic-speaking newcomers to Saskatchewan,
Canada. Our communication tool follows a three-layer ar-
chitecture designed to efﬁciently process end-users’ requests.
The top-layer (“Presentation layer”) corresponds to a Web-
based interface including ﬁve main sections, offering different
services to the end-user. Among these services, a large set of
items, corresponding to the main common information to new-
comers, are arranged in a hierarchical manner, thanks to our
multilingual ontology. These items are linked to Wikipedia,
and are presented with text and audio sound messages, in
three languages, generated automatically through an audio
API. The other services include the speech/text translation
module, the map localisation module, and a feedback survey.
The speech/text translation module is particularly important
as it allows a real-time verbal/text translation in the three
languages. This can be a very useful communication tool for
newcomers, especially in their ﬁrst days in the host country.
In the near future, we plan to improve our tool’s features
and add new ones based on users’ feedback. Then, we will
enrich the textual communication of the chat-bot that we
have implemented by adding an auditory option. This latter,
aims to accelerate the time response and decision making,
especially when the end-user has an emergent query requiring
a quick response. Moreover, we will develop a learning module
for young children in order to improve and develop their
communication skills in the host country language(s). This
will be done using known cartoon characters in animated
conversations.
REFERENCES
[1] M. Al-Ageili and M. Mouhoub, “Communication aid for non-english
speaking newcomers,” arXiv preprint arXiv:2101.08319, 2021.
[2] K. U. Rani, “Communication barriers,” Veda’s Journal of English
Language and Literature, vol. 3, no. 2, pp. 74–76, 2016.
[3] I. E. Britannica. (1957) Encyclopædia britannica, incorporated 1957.
[Online]. Available: https://www.britannica.com/., urldate = 2021-06
[4] Blissymbolics.
(2021)
Blissymbolics
communication
international.
[Online]. Available: https://www.blissymbolics.org/
[5] Boardmaker.
(2021)
Boardmaker.
[Online].
Available:
https://goboardmaker.com/pages/boardmaker-online
[6] J. Scott, “Low tech methods of augmentative communication,” Augmen-
tative Communication in Practice 2, 1998.
[7] S. Glennen and D. C. DeCoste, The handbook of augmentative and
alternative communication.
Cengage Learning, 1997.
[8] R. Schlosser, “Roles of speech output in augmentative and alternative
communication: Narrative review,” Augmentative and Alternative Com-
munication, vol. 19, no. 1, pp. 5–27, 2003.
[9] D. Jans and S. Clark, “High technology aids to communication,”
Augmentative Communication in Practice 2, 1994.
[10] C. Tijus, J. Meunier, B. Cambon de Lavalette, and J. Barcenilla,
“Chapter 2: the design, understanding and usage of pictograms,” Written
Documents in the Workplace,(Leiden, The Netherlands: BRILL, 2007)
doi: https://doi. org/10.1163/9789004253254 003, 2007.
[11] S. M. Otsubo, “A behavioral study of warning labels for consumer
products: Perceived danger and use of pictographs,” in Proceedings of
the Human Factors Society Annual Meeting, vol. 32, no. 9.
SAGE
Publications Sage CA: Los Angeles, CA, 1988, pp. 536–540.
[12] T. P. A. of Pictogram, Encyclopædia britannica.
Swedish Institute for
Special Needs Education, 2001.
[13] S. MAHARAJ. (2017) Pictocom international. [Online]. Available:
http://www.pictoworld.com/presentations.html
[14] N.-B. Takil, “Vocabulary acquisition with pictograms and contextual
sentences in teaching turkish as a foreign language,” Turkish Studies
International Periodical for the Languages, Literature and History of
Turkish or Turkic, vol. 11/3, no. 1, pp. 2133–2136, 2016.
[15] T. H. Clawson, J. Leafman, G. M. Nehrenz Sr, and S. Kimmer, “Using
pictograms for communication,” Military medicine, vol. 177, no. 3, pp.
291–295, 2012.
[16] M. Miller. (2016) A pictogram language designed for the displaced.
[Online]. Available: http://www.fastcompany.com/3063452/a-pictogram-
language-designed-for-the-displaced
[17] G.
McNeill.
(2015)
Refugee
communication
board
using
symbols. [Online]. Available: http://www.callscotland.org/blog/refugee-
communication-board-using-symbols
[18] A. Hart and S. I. Kindergarten, “Ancient forms of communication in
the spanish immersion classroom: The use of pictograms and rebuses
to promote the development of spanish language literacy,” Charlotte
Teachers Institute, 2015.
[19] F. Mart´ınez-Santiago, M. ´A. Garc´ıa-Cumbreras, A. Montejo-R´aez, and
M. C. D´ıaz-Galiano, “Pictogrammar: an aac device based on a semantic
grammar,” in Proceedings of the 11th Workshop on Innovative Use of
NLP for Building Educational Applications, 2016, pp. 142–150.
[20] K. Wołk, A. Wołk, K. Marasek, and W. Glinkowski, “Pictogram-based
mobile ﬁrst medical aid communicator,” Procedia computer science, vol.
121, pp. 3–10, 2017.
[21] H. Sletvold, L. A. B. Sagmo, and E. A. Torheim, “Impact of pictograms
on medication adherence: A systematic literature,” Patient Education
and Counseling, 2020.
[22] M. Montagne, “Pharmaceutical pictograms: a model for development
and testing for comprehension and utility,” Research in Social and
Administrative Pharmacy, vol. 9, no. 5, pp. 609–620, 2013.
[23] W. S. Kisaalita and E. J. Sempiira, “Development of pictograms to
communicate technological solution instructions (labeling) among low-
literacy users,” Ergonomics in Design, p. 1064804620959145, 2020.
[24] L. N. Ngoh and M. D. Shepherd, “Design, development, and evaluation
of visual aids for communicating prescription drug instructions to non-
literate patients in rural cameroon,” Patient education and counseling,
vol. 31, no. 3, pp. 245–261, 1997.
[25] G. E. Lancioni, N. N. Singh, M. F. O’Reilly, G. Alberti, V. Chiariello,
C. Campanella, G. Grillo, and V. Tagliente, “A program based on
common technology to support communication exchanges and leisure in
people with intellectual and other disabilities,” Behavior Modiﬁcation,
vol. 43, no. 6, pp. 879–897, 2019.
[26] MacroDroid.
(2021)
Macrodroid.
[Online].
Available:
http://macrodroid.com/
[27] G. E. Lancioni, N. N. Singh, M. F. O’Reilly, J. Sigafoos, G. Alberti,
V. Chiariello, and S. Buono, “Extended smartphone-aided program to
sustain daily activities, communication and leisure in individuals with
intellectual and sensory-motor disabilities,” Research in Developmental
Disabilities, vol. 105, p. 103722, 2020.
[28] D. Schwab, P. Trial, C. Vaschalde, L. Vial, E. Esperanc¸a-Rodier, and
B. Lecouteux, “Providing semantic knowledge to a set of pictograms
for people with disabilities: a set of links between wordnet and arasaac:
Arasaac-wn,” in LREC, 2020.
[29] MediaWiki.
(2021)
Mediawiki
api.
[Online].
Available:
https://www.wikidata.org/w/api.php?
[30] M.
W.
Docs.
(2021)
Speech
recognition.
[Online].
Available:
https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition
47
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-870-9
ACHI 2021 : The Fourteenth International Conference on Advances in Computer-Human Interactions

