Sharing Emotional Information Using A Three Layer Model
Imen Tayari Meftah1,2 and Nhan Le Thanh1
1University of Nice Sophia Antipolis and CNRS
I3S Laboratory
Sophia Antipolis, France
Email: tayari@i3s.unice.fr, nhan.le-thanh@unice.fr
Chokri Ben Amar2
2University of Sfax and ENIS
REGIM laboratory
Sfax, Tunisia
Email: chokri.benamar@enis.rnu.tn
Abstract‚ÄîIn this study, we present a generic model to
exchange emotional states information between heterogeneous
multi-modal applications. Our proposal is composed of three
distinct layers: the psychological layer, the formal computa-
tional layer and the language layer. The Ô¨Årst layer represents
the psychological theory adopted in our approach, The second
layer is based on a formal multidimensional model. It matches
with the psychological approach of the previous layer. The
Ô¨Ånal layer uses XML to generate the Ô¨Ånal emotional data to
be transferred through the network. The remainder of this
article describes each layer of our model. The proposed model
enables the exchange of the emotional states regardless to the
modalities and sensors used in the detection step. Moreover our
model permits to model not only the basic emotions (e.g., anger,
sadness, fear) but also different types of complex emotions like
simulated and masked emotions.
Keywords-emotion,
multimodality,
three
layers
model,
Plutchik model, emotional exchanges, multidimensional spaces.
I. INTRODUCTION
The use of emotion in computers is becoming an increas-
ingly important Ô¨Åeld for human-computer interaction. In-
deed, affective computing is becoming a focus in interactive
technological systems and more essential for communica-
tion, decision-making and behavior. There is a rising need
for emotional state recognition in several domains, such
as health monitoring, video games and human-computer
interaction. The emotional information exchange between
applications entails many problems such as application het-
erogeneity, complexity of emotional states, diversiÔ¨Åcation
of capture tools and dependence between treatment and
physical sensors. The lack of a standard in human emotions
modeling hinders the sharing of affective information be-
tween applications. As part of the research project Emotica,
we deÔ¨Åne a generic model facilitating communication be-
tween heterogeneous multi-modal applications. Our proposal
is composed of three distinct layers: the psychological layer,
the formal computational layer and the language layer. This
generic model is designed to be usable in a wide range of use
cases, including modeling and representation of Emotional
States. In this paper, we explain the role of each layer of
our generic model. The remainder of this paper is organized
as follows. In Section 2, we present the problem statement.
In Section 3, we describe the different parts of our model.
Finally, we conclude in Section 4.
II. PROBLEM STATEMENT
Emotions are an important key component of human
social interaction. Today there is a need for computers to un-
derstand this component in order to facilitate communication
between users and to improves the credibility of interactions
human-computer. Sharing emotional states becomes more
and more important in human-machine interactive systems.
Nevertheless, it entails many problems due to complexity
of emotional states, diversiÔ¨Åcation of capture tools and de-
pendence between treatment and physical sensors. Emotion
is a complex concept. Indeed there is no agreed model
for the representation of emotional states. Many theories
focused only on basic emotions [1]. Another ones introduced
some complex emotions [2] but does not encompass all the
emotional states. Moreover, in a natural setting, emotions
can be manifested in many ways and, expressed and per-
ceived through multiple modalities, such as facial expression
,gesture, speech, or physiological variation. Each modality
need a speciÔ¨Åc processing and use special techniques for
the recognition step. The difÔ¨Åculty of sharing emotional
information between many applications which use different
modalities coming from the dependance between treatment
and physical sensors and the lack of a standard human
emotions modeling.
Current works on modeling and annotation of emotional
states like Emotion Markup Language (EmotionML) [3] or
Emotion Annotation and Representation Language (EARL)
[4] aim to provide a standard for emotion exchange between
applications, but they use natural languages to deÔ¨Åne emo-
tions. They use words instead of concepts. For example, in
EARL, joy would be represented by the following string
‚Äù<emotion category=‚Äùjoy‚Äù />‚Äù, which is the English word
for the concept of joy and not the concept itself, which could
be expressed in all languages (e.g., joie, farah, gioia). In this
article, we propose a generic model, which can model any
kind of complex emotion, and permits the exchange of emo-
tional states between heterogeneous applications regardless
to the modalities and sensors used in the detection step.
130
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

data
XML data
Emotions 
Emotions 
exchange
exchange
XML data
language layer
formal representation and computational layer
psychological  layer (Plutchik)







	

	


	


	

global schema of exchange of emotion
global schema of exchange of emotion
Figure 1.
The Three-layer model
III. THE PROPOSED MODEL
Our approach is based on a hierarchical representation
model composed by three distinct layers which are interde-
pendent to ensure a maintenance of coherence of the model.
Figure 1 shows a global schema of our proposed model. It
is composed of three distinct layers: the psychological layer,
the formal representation layer and the language layer.
A. The psychological layer
The psychological layer is the Ô¨Årst layer of our model
and it represents the psychological model that we chosen to
represent the emotional state of users. Emotion is a com-
plex concept. There is no consensus among psychological
and linguistic theories on emotions. According to research
in psychology, three major approaches to affect model-
ing can be distinguished [5]: dimensional, categorical, and
appraisal-based approach. The dimensional approach mod-
els emotional properties in terms of emotion dimensions.
It decomposes emotions over two orthogonal dimensions,
namely arousal (from calm to excitement) and valence (from
positive to negative) [6]. In the Appraisal theory, emotions
are obtained from the subjective evaluations (appraisals)
of events/stimulus that cause speciÔ¨Åc reactions in different
people. Finally, categorical approach focus on identifying a
small number of primary and distinct emotions. the number
of basic emotions varies from one theory to the next: for
instance, there are 6 basic emotions in the Fridja‚Äôs theory
[7], 9 in the Tomkins‚Äôs theory [8] and 10 in the Izard‚Äôs the-
ory [9]. Plutchik proposed a three-dimensional circumplex
model (Figure 2) which describes the relationships between
emotions. His model is very intuitive and easy including the
idea that complex emotions are obtained by mixing primary
ones. We opted for his approach as the basis of our model
and will thus describe it in details.
1) Plutchik model:
Robert Plutchik adopted a color
metaphor for the combination of basic emotions [10]. He
proposed a three-dimensional ‚Äùcircumplex model‚Äù (Figure
2), which describes the relationships between emotions. He
argued for eight primary emotion arranged as four pairs of
opposites: (Joy-Sadness, Fear-Anger, Surprise-Anticipation,
Disgust-Trust) [10]. The vertical dimension represents in-
tensity or level of arousal, and the circle represents degrees
of similarity among the emotions. He suggested that non-
basic emotions are obtained through the addition of basic
emotions (color analogy, Plutchik, 1962) [11]. In his model,
for instance, Love = Joy + trust and Delight = Surprise +
Joy. Plutchik deÔ¨Åned rules for building complex emotions
out of basic ones. In practice, combination of emotions
follows the method ‚Äùdyads and triads‚Äù [12]. He deÔ¨Åned the
primary dyads emotions as the mixtures of two adjacent
basic emotions. Secondary dyad includes emotions that are
one step apart on the ‚Äùemotion wheel‚Äù, for instance Fear
+ Sadness = Despair. A tertiary emotion is generated from
a mix of emotions that are two steps apart on the wheel
(Surprise + Anger = Outrage).
In our work, we chose the Plutchik model to represent
the psychological layer because it veriÔ¨Åes many important
conditions for the elaboration of our model and it explains
emotions in terms of formulas that can be universally applied
to all human beings [13]. First, the Plutchik model is based
on 8 basic emotions encompassing the common Ô¨Åve basic
emotions. Then, it takes into account the intensity of emotion
i.e., the level of arousal or the feeling degree of each basic
emotion for example (terror, fear, apprehension). Finally,
the Plutchik model is intuitive, very rich and it is the
most complete model in literature because it permits to
model complex emotions by using basic ones. Indeed, as we
have seen, Plutchik deÔ¨Åned the dyads and the triads which
are combinations of basic emotions describing complex
emotions which are regarded as emotions in usual life.
B. The formal computational layer
The formal computational layer is the second layer of
our model. It matches the psychological approach of the
Ô¨Årst layer. It is the formal representation of Plutchik‚Äôs
model and it is based on an algebraic representation using
multidimensional vectors. In this layer, we represent every
emotion as a vector in a space of 8 dimensions where every
axis represents a basic emotion deÔ¨Åned on the Plutchik
theory .
First, we deÔ¨Åne our Base by (B) = (joy, sadness, trust,
disgust, fear, anger, surprise, anticipation), which are the
basic emotions on the Plutchik theory. So every emotion (e)
can be expressed as a Ô¨Ånite sum (called linear combination)
of the basic elements.
(e) =
8
X
i=1
‚ü®E, ui‚ü©ui
(1)
Thus, (e)
=
Œ±1Joy + Œ±2sadness + Œ±3trust + .. +
Œ±7surprise + Œ±8anticipation
where Œ±i are scalars and ui(i = 1..8) elements of the basis
131
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

Figure 2.
Plutchiks three-dimensional circumplex model
(B). Typically, the coordinates are represented as elements
of a column vector E
E =
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
Œ±1
Œ±2
.
.
Œ±8
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
B
where Œ±i ‚àà [0, 1] represent the intensity of the respective
basic emotion. More the value of Œ±i gets nearer to 1, more
the emotion is felt.
The proposed model takes into account the property of
the intensity of the emotion. Indeed, each emotion can
exist in varying degrees of intensity. The coefÔ¨Åcients Œ±i
determine the emotion intensity. According to the value of
the coefÔ¨Åcients Œ±i we can make the difference between
annoyance, anger and rage or pleasure, joy and ecstasy. So,
rage is the basic emotion anger with high intensity. The
multidimensional representation of the formal computational
layer provides the representation of an inÔ¨Ånity of emotions
and provides also a powerful mathematical tools for the
analysis and the processing of these emotions. Indeed we
can apply the usual basic algebraic operations on vectors like
the addition, the scalar multiplication, the projection and the
distance in an Euclidean space. We are going to detail only
the addition, and the Euclidean distance. for more detail you
can see [14].
1) Vector addition:
We have seen in the previous
paragraphs that the mixture of pairs of basic emotions
resulted of complex emotion. Joy and trust for example
produce the complex emotion ‚Äùlove‚Äù. In this part we deÔ¨Åne
the combination between emotions as the sum of two
emotion vectors. This addition is deÔ¨Åned as the maximum
Figure 3.
Combination and opposites on the Plutchik‚Äôs model
value of coefÔ¨Åcients (term by term) [14]. Let E1u and
E2u be two emotional vectors expressed in the basis (B)
respectively by (Œª1, Œª2, .., Œª8) and (Œª
‚Ä≤
1, Œª
‚Ä≤
2, .., Œª
‚Ä≤
8). The
addition of these two vectors is deÔ¨Åned as:
E
‚Ä≤ = E1u
M
E2u = max(Œªi, Œª
‚Ä≤
i)for0 ‚â§ i ‚â§ 8
(2)
In this sense, the vector representing the emotion love, which
is mixture of joy and trust, is deÔ¨Åned as:
Elove = EJoy
L
Etrust
Elove =
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
Œ±1
0
0
0
0
0
0
0
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
B
L
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
0
0
Œ±3
0
0
0
0
0
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
B
=
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
Œ±1
0
Œ±3
0
0
0
0
0
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
B
where Œ±1 Ã∏= 0 et Œ±3 Ã∏= 0
In the same way we can obtain the ‚Äùvector form‚Äù of the
other complex emotions states deÔ¨Åned by Plutchik. These
emotions combinations are shown on Figure 3. Figure 4
shows an example of the using of the add operation on appli-
cation of emotion detection. On this example the detection is
done using two modalities. Each modality gives an emotion
vector. The vector V1 is given by the facial modality and
the vector V2 is given by the physiological modality. The
Ô¨Ånal emotion vector Vf is given by the addition of this two
vectors using equation 2.
132
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

Figure 4.
Multi-modality emotion recognition system
2) Euclidean distance (2-norm distance):
d(E, Y ) =
v
u
u
t
n
X
i=1
(yi ‚àí xi)2
(3)
with E
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
x1
x2
.
.
xn
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
B
and Y
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
y1
y2
.
.
yn
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
B
are two vectors.
The proposed model is a continuous model providing the
representation of inÔ¨Ånity of emotions. Thus, to analyse a
given vector and determine the nearest emotion from the
known ones we need a tool to calculate the similitude
from the vector and the known emotions. For this, we
propose to use the Euclidean distance (2-norm distance)
deÔ¨Åned by equation 3. First, we have to generate a data
base of emotions composed by the vectors of all emotions
proposed by Plutchik given by Figure 2 and Figure 3. So,
our emotion data base is composed by approximately 50
emotions and can be extended by others emotions. Then we
have to compute for a given vector V1 the Euclidean distance
between it and all the vectors of the data base. Finally we
keep the vector of the data base minimizing this distance.
This vector represents the nearest emotion of V1 and the
computed distance gives an idea of the precision of this
interpretation. For example, we can found that the nearest
emotion for the vector V1 is ‚Äùlove‚Äù with a distance equals
to zeros. We can afÔ¨Årm without doubts that V1 represents
the emotion ‚Äùlove‚Äù. More the distance from the nearest
vector is important, less the interpretation is accurate. So
the proposed method, using the Euclidean distance, permits
to analyse automatically a given vector and provides the best
interpretation of this vector.
C. The language layer
The third layer of our model is the language layer.
This layer provides encoding emotional information. We
propose to use the eXtensible Mark-Up Language (XML)
developed by the World Wide Web Consortium to annotate
and represent emotional states of users.
XML, is a method for describing and encoding data.
It is used for representation and transmission of data be-
tween application and organization. It is a text-based system
meaning that both humans and machines can understand
it directly, and is self-describing in so much as each data
element can be traced to a deÔ¨Ånition [15]. For example,
annotating a complex emotion detected using the voice
modality (microphone) give the following XML structure:
<emotion>
<modality set= ‚Äùbasic-modality‚Äù >
<vector mode=‚Äùvoice‚Äù>
<intensity axis=‚Äùjoy‚Äù>0.8</intensity >
<intensity axis=‚Äùsadness‚Äù>0.0</intensity >
<intensity axis=‚Äùtrust‚Äù>0.6</intensity >
<intensity axis=‚Äùdisgust‚Äù>0.0</intensity >
<intensity axis=‚Äùfear‚Äù>0.0</intensity >
<intensity axis=‚Äùanger‚Äù>0.0</intensity >
<intensity axis=‚Äùsurprise‚Äù>0.0</intensity >
<intensity axis=‚Äùanticipation‚Äù>0.0</intensity >
</vector>
</emotion>
The numeric values for the tag ‚Äùintensity ‚Äù indicate the
intensity of the respective basic emotion going on, on a scale
from 0 (emotion is not felt) to 1 (more the emotion is felt).
Using the computational layer we can conclude that the felt
emotion is a complex one because there is more than one
axis with a value different from zeros. Moreover, using our
algorithm based on the Euclidean distance, deÔ¨Åned on the
formal computational layer, we can conclude that the felt
emotion is ‚Äùlove‚Äù.
The next example was generated using two modalities:
the heart rate modality and the facial expression modality.
Each modality will give a vector with different coefÔ¨Åcients.
<emotion>
<modality set= ‚Äùmulti-modality‚Äù count=‚Äù2‚Äù>
<vector mode=‚Äùheart-rate‚Äù>
<intensity axis=‚Äùjoy‚Äù>0.0</intensity >
<intensity axis=‚Äùsadness‚Äù>0.4</intensity >
<intensity axis=‚Äùtrust‚Äù>0.0</intensity >
<intensity axis=‚Äùdisgust‚Äù>0.0</intensity >
<intensity axis=‚Äùfear‚Äù>0.8</intensity >
<intensity axis=‚Äùanger‚Äù>0.2</intensity >
133
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3


[8] S. Tomkins, ‚ÄúAffect as ampliÔ¨Åcation: some modiÔ¨Åcations in
theory,‚Äù Theories of emotions, vol. 1, New York, Academic
Press., pp. 141‚Äì165, 1980.
[9] C. E. Izard, Human emotions, S. Verlag, Ed.
Plenum Press,
New York, 1977.
[10] R. Plutchik, Emotion, a psychoevolutionary synthesis. Harper
and Row, New York, 1980.
[11] ‚Äî‚Äî, The Emotions: Facts, Theory and a New Model, ser.
Studies in psychology.
Random House, New York, 1962.
[12] M. de Bonis, Connaitre les ¬¥emotions humaines, Mardaga, Ed.
Psychologie et sciences humaines, 1996, vol. 212.
[13] T. Jonathan H and S. Jan E, The Sociology of Emotions.
Cambridge University Press, 2005.
[14] I. Tayari Meftah, N. L. Thanh, and C. Ben Amar, ‚ÄúTowards an
algebraic modeling of emotional states,‚Äù in Internet and Web
Applications and Services (ICIW), 2010 Fifth International
Conference on, May 2010, pp. 513 ‚Äì518.
[15] T. Bray, J. Paoli, C. M. Sperberg-Mcqueen, Eve, and
F. Yergeau, Eds., Extensible Markup Language (XML) 1.0,
4th ed., ser. W3C Recommendation.
W3C, August 2003.
[Online]. Available: http://www.w3.org/TR/REC-xml/
135
ICIW 2011 : The Sixth International Conference on Internet and Web Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-124-3

