Human Emotion and Machine Emotion - Studies of Emotion in AI
Wang Shuo
School of New Media and Art Design, Beihang University
Beijing, China
email: wangshuo_ws@buaa.edu.cn
Yang Shuo
Art Criticism, Chinese National Academy of Arts
Beijing, China
email: flyingonbird@126.com
Abstract—Artificial Intelligence (AI) is undoubtedly a hot
word in the field of contemporary art in recent years. The
consciousness, intuition and emotion of AI have attracted the
attention of artists in particular, and many art works have
explored this topic. Does AI have the emotional characteristics
of humans? Is the emotion of AI equal to the emotion that
defines human beings? This paper attempts to step out of the
anthropocentric
perspective,
examine
the
boundary
and
relationship between human emotion and machine emotion,
and inject a new theoretical perspective into the AI artistic
practice. This paper first discusses what emotion is in the
biological sense, analyzes whether a machine can have emotion
from both positive and negative aspects, and puts forward the
definition of "machine emotion". This paper also reviews some
theories and practices related to emotion in the AI field. The
conclusion of this paper is that although artificial intelligence
cannot possess human emotions, it can possess “machine
emotions” beyond the narrow sense of human emotions, and
the construction of emotional mechanisms inside AI may
become a new research direction in this field.
Keywords-Emotion;
Artificial
Intelligence;
Machine
Emotion.
I.
INTRODUCTION
Picard [27] told the story that children think Barney the
toy dinosaur produces emotions, and Barney's conscious
expression encourages them to believe that Barney has
emotions. As far as we know, children have always attached
their emotions to dolls and stuffed animals, and we all agree
with the experience that toys never have and cannot have
emotions. So, drawing an analogy between a toy dinosaur
and Artificial Intelligence (AI), we have to ask: why would
humans think about whether AI can have emotions?
Arkin [3] believes that roboticists mostly focus on
pragmatic functionality and ignore emotional features. As
humans demand more of AI's ability to communicate,
researchers
are
increasingly
assigning
some
of
the
characteristics of human emotions to machines. So, are the
emotional features of the AI (as Barney the dinosaur) merely
empathic effects of human beings projecting their own
emotions onto
the machine? However, the emotional
interaction between AIs and humans goes far beyond what
humans and toys can do, and AI’s emotional capacity brings
to mind the term “machine emotion”. At this point, it seems
necessary to re-examine the definition of human emotion. Is
the definition of emotion based solely on anthropocentrism
insufficient to include machine emotion? Can we go beyond
human
or
biological
emotions
to
redefine
machine
emotions? These are the questions that this paper wants to
discuss.
In Section 1, we discuss the emotion in the general
biological sense from the aspects of its origin, definition and
classification. In Section 2, we argue the motive and purpose
of humans giving emotion to AIs, and then analyze whether
AIs can have emotion from both positive and negative
aspects, and
put forward the definition of “machine
emotion”. In Section 3, we review human-based and
machine-based emotions ontologies. In Section 4, by
reviewing relevant literatures in recent years, we find that
more and more researchers are trying to explore the
construction
of
“machine
emotion”
inside
artificial
intelligence machines. The last section is the conclusion of
this paper.
II.
WHAT IS EMOTION
From a neurobiological point of view, the source of
emotion lies in the tight interaction between the amygdala
and the cerebral cortex [2]. We know that the emotional
expression
of
organisms
is
directly
related
to
the
transmission of facial expressions, which belongs to the
emotion
within
organisms.
In
brain
movement,
the
observation of facial expressions can activate the amygdala.
If the amygdala is damaged or defective, it will lead to
confusion of emotional expression, making it difficult to
observe
and
recognize
facial
expressions
[31].
The
amygdala and the prefrontal cortex of the brain are also
involved in the construction of social emotions, which are
key components of social interaction [10]. The amygdala,
for example, is the mechanism by which organisms make
judgments about sensory events by triggering the system of
expectation, punishment
or evaluation associated
with
emotion, in response to neural stimulation.
Different scholars define emotion from different angles.
Mayers [24] defined emotion by relationship between
emotion and body: “Emotions are our body’s adaptive
response”. R. Lazarus and B. Lazarus [21] laid emphasis on
how emotion reacts to external environment: “Emotions are
organized psycho-physiological reactions to news about
ongoing relationships with the environment”. Plutchik [29]
deemed that emotions are involved in all parts of the link
from psychological to actual actions, a continuous status:
"Emotion is a complex chain of loosely connected events
which begins with a stimulus and includes feelings,
psychological changes, impulses to action and specific,
goal-directed behavior".
Nowadays, there are two major emotion classification
models. One is basic emotion theory, and the other is
emotion dimension theory. In the context of psychological
science, the concept of basic emotions is deemed as a
classification that defines a group of similar emotions with
specific color. Emotions are marked by extents such as joy,
happiness, or ecstasy [19]. Ekman proposed that the “basic”
term has three layers of indication: first, the perspective of
basic
emotions
could
help
us
to
distinguish
those
perspectives that believe emotions are consistent and only
differs in intensity and extent of joy, such as some simple
classifications
that
counterpose
negative
and
positive
emotions; second, basic emotional states reflect the fact that
9
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

emotions are of adaptive value evolution when dealing with
basic life tasks. It is embodied in human's status when they
handle repeated tasks (such as, response to interpersonal
relationship, response to emotional reaction to personal life.
Basic emotional states are also related to our intuitive
characters and life experience); third, basic emotions are
also used to describe components that constitute complex
emotions. For instance, smugness might be considered to be
a blend of the two elemental emotions, happiness and
contempt [12].
Many scholars have tried to classify basic emotions (for
some attempts in this direction, see [4][11][17][25][28]
[38]-[41]. For example, facial emotions of human, according
to Ekman's model, have six identifiable basic emotion states,
which are, respectively: Anger, Fear, Distress/Sadness,
Enjoyment/Happiness, Disgust, and Surprise [11]. Silvan
Tomkins [38]-[41] describes innate emotions that are
exhibited
by
toddlers
since
birth
as
affects:
anger,
embarrassment, sorrow, fear, interest, happiness, surprise,
disgust. In Minsky's six-element model, it is believed that
basic emotions include empathy, envy, love, aggression,
awe, respect [25].
In psychological science, there is another classification
model called the dimensional emotion, which is frequently
utilized in recent emotion measurement research. The
dimensional emotion uses some indicators to measure
emotional intensity - the extent of how behavior is affected
by emotions, such as stimulation, energy, and activation
[19]. The first scholar who proposed emotion dimension
theory is Russell. He believed that emotions could be
indicated and measured by two dimensions of a circumplex:
1) valence, which indicates extent of joy when an individual
experienced the state; 2) arousal, which indicates possibility
of the individual to take certain action due to its specific
state [18].
Afterwards, many scholars conducted their development
and exploration about dimension models of emotions [23]
[28]-[30][36][37]. Thereinto, Thayer’s circle of emotion,
Plutchik emotional wheel and Lövheim’s cube of emotions
are regularly used in recent research [13][32][33][43].
III. WHETHER MACHINES CAN HAVE EMOTIONS
A. Why do humans endow machines emotions?
Why do humans endow machine with emotions? Picard
[27] identifies four motivations for human beings to endow
machines with certain emotional abilities: 1) The first goal is
to build robots and synthetic characters that can emulate
living humans and animals – for example, to build a
humanoid robot；2) The second goal is to make machines
that are intelligent, even though it is also impossible to find a
widely accepted definition of machine intelligence; 3) The
third goal is to try to understand human emotions by
modeling them; 4) The fourth goal is to make machines less
frustrating to interact with. All four of Picard's motivations
seem to be human-centric: hoping machines become more
human-like in appearance, intelligence, and behavior, and
further
exploring
the
intellectual
pedigree
of
human
emotions through machines.
Arbib and Fellous [2], on the other hand, point out four
reasons why people are interested in giving emotions to
machines from the perspective of anthropocentrism: 1) the
current technology already shows the value of providing
robots with ‘emotional’ expressions (e.g., computer tutors)
and bodily postures (e.g., robot pets) to facilitate human–
computer interaction; 2) They raise the question that the
value of robots in the future may not just be to simulate
human
emotional
expression,
but
to
actually
“have
emotions”; 3) It, in turn, requires us to revisit the
neurobiology of emotion to generalize some new concepts,
because what we know was first proposed for humans and
then extended to organisms and machines, which makes it
interesting to study emotions in robots; 4) It suggests that
building “emotional robots” can also provide a novel
test-bed for theories of biological emotion. Arbib and
Fellous posed a series of related questions: Will machines in
the future actually “have emotions”, in addition to imitate
human emotional expression? Will theories and concepts
based on human beings (e.g., neurobiology, biological
emotion theory) lead to new research directions with the
birth of robots? This article can't help but ask a further
question: how to define “having emotions”? Can robots be
included in the category of “living things” like humans and
animals? Does “having emotions” mean that robots produce
emotions, or even thoughts, that are independent of humans?
B. Machines cannot have emotions
Opponents often argue that machines cannot have
emotions
in
three
ways:
First of all,
the emotional
transmission and recognition system of the machine is
related to its ability to comprehend, recognize and execute
tasks. However, when the designers put too much emphasis
on the technical execution of the machine in terms of
communication and cognition, this shaping method exposes
certain emotional defects. As stated by Parisi and Petrosino
[26],
the
actions
of
existing
"emotional
robots"
are
controlled by symbolic, role-based systems.
Second, AI is based on, but also limited to, human
emotions. Becker [5] 's research explores the passive role of
machines in human-computer interaction. According to him,
machine’s
emotion
is
positioned
only
in
its
ability
performing in activities of social networks; AI entities are
artificial objects constructed according to the model of
human communication and cognitive ability. They have no
personality and are relegated to being an interaction partners
of humans.
For example, the Embodied Conversational Agents
(ECAs) project attempted to build embodied emotional
entities of AIs. In order to enable machines to generate
special
activities
related
to
human
emotions
and
to
regenerate new activities reconstructed by the machine itself,
ECAs classifies human emotions to construct samples for
emotion recognition. Through psychological experiments,
they set up seven basic emotions, including "angry, sad,
happy,
frightened,
ashamed,
proud,
despairing"
[34].
However, Becker [5] believes
that
these patterns of
subjective
feelings
and
the
variety
of
associated
physiological processes are only taken into account in a
highly reductionist manner. On the one hand, ECAs takes
human beings as the basic reference model for the emotional
entities of AI, which is an extension of human emotion
based on machines. On the other hand, it also reflects the
human-centered perspective in the process of emotion
observation. Therefore, machine emotions, which are set as
samples, have regular processing patterns that limit the
scope of machine emotions. Becker [5] believes that when a
human makes an observation based on his perspective and
interest, he can get the specific emotion he wants to collect.
This is a perspective from the observer, which implements a
certain
dominance
for
machine
emotion.
Then,
the
"emotion" generated by the emotional robot is derived from
the designer's understanding and construction of the human
emotion
model. The ability of
machines
to
perform
10
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

emotional tasks contributes to the misconception and
illusion that machines have emotions.
Finally, from the point of view of motivation selection,
the machine is not capable of producing emotion. The
implementation of behavior is directly related to biological
motivation.
When
organisms
face
competition
among
various motivations, they will make a choice and trigger
strategic emotions.
Arbib's Schema Theory reveals the generation process of
various biological motivations and analyzes the strategic
emotions caused by biological selections of behaviors. With
the praying mantis as a model, he explained that the actions
of organisms are not only affected by the changes of external
environment, but also related to the visual stimulus situation
in which the praying mantis is located, the internal variables
of the living body, and the existing experience about the
stimulus [5]. Compared with motivation, emotion can
provide organisms a more efficient, accurate and rapid
channel for their actions [5]. Emotions arise from biological
body/brain sensations that present a special state when a
creature makes a choice among motivations [5]. For
example, feeding and mating are competitive behavioral
motivations
among
different
activities
of
organism.
Emotional states, then, combine the creature's perception of
the external environment to help it make choices and act on
them.
Fellous and Arbib [14] argued that machines could not
be considered as having emotions at this point, because they
could not control their own behavior to make motivational
choices in a given situation. Moreover, in the construction
system of AI, motivation is the driving mechanism of the
machine and the main manifestation of functionality. The
motivation control of artificial intelligence lies with the
designer and its communication user. The robot only realizes
the technical action, and there is no strategic or motivational
response action. As Parisi and Petrosino [26] put it, if a
robot does not have autonomous motivation, it will not have
emotions.
C. Machine emotion
Arbib and Fellous [2] divide the application of emotion
in AI into two parts: one is the external aspect of emotion,
which
refers
to
the
emotional
expression
made
for
communication and social collaboration; the other is the
inner aspect of emotion, which can influence behaviors
(such as action selection, attention and learning).
Researches concerning the external (or social) aspects of
emotion,
following
the
anthropomorphic
tendencies,
promote the production of robots with emotional and
empathic relationships between robots and human beings.
Researches concerning the intrinsic (or individual)
aspects of emotion focus on the production of robots’
subjectivity whose behavior is influenced by endogenous
regulatory processes modelled on natural emotion regulation
mechanisms [8]. Parisi and Petrosino [26] point out that
“current emotional robots can express emotions or recognize
our emotional expressions, but they cannot be considered to
have emotions because emotions do not play any functional
role in their behavior”. According to them, AI that simulates
or identifies human expressions of emotion is not considered
to “have emotion”, but only if it interferes with and
influences behaviors. In other words, the inner aspect of
emotion more closely meets the criteria that “AIs have
emotion”.
Giving a robot a mechanism of subjective emotional
regulation is considered to be an attempt to truly generate
“artificial emotion” [8]. In sum, machine emotion is not the
same as human emotion. However, machine can form an
autonomous regulation mechanism just like human beings,
which can play an important role in influencing its
behaviors.
IV. THEORIES ABOUT EMOTIONS AND MACHINE
A. Picard's 4 emotional components
Picard
[27]
believes
that
the
four
emotional
components of human beings could be a part of machines,
thus, to help machines to better adapt to human beings. The
components include emotional appearance, multiple levels
of
emotion
generation,
emotional
experience
and
mind-body interaction. The first component she proposed,
emotional appearance, includes some actions and behavior
with emotional appearance expressed by systems. Machines
could simulate facial expression, voice, and physical
language of human beings to express emotional appearance
similar with the emotion expression of human beings. Such
emotional appearance is based on learning by machines of
human beings’ emotion appearance data, thus enabling the
establishment of communication mechanism with human's
emotions.
The second component is “multiple levels of emotion
generation”: human's emotions are of different levels.
Different external stimulation triggers different levels of
reactions. Machines could use this rule to learn about
emotions of human beings, or synthesize an internal
emotional status tag for themselves to trigger appropriate
reactions.
Emotion
levels
include
quick-response
sub-consciousness,
moderate-
response
and
acquired
pre-consciousness, and slow-response reaction generated by
rationality [27].
The third component is emotional experience, which
actually relates to AI's cognition about the emotional field
of its own. Emotional experience refers to the generation by
machines of emotional status and series of feelings similar
with those sensed by human being. Moreover, machines
could also sense the thing their bodies are doing [27].
Though “human feelings” is definitely different from
“machine feelings”, machines could use such feelings and
experience to adjust and improve their behavior.
The
fourth
component
is
mind-body
interaction:
emotions include both physical system changes outside and
inside the brain. The interaction between emotions, bodies
and cognition status is very active. For example, when
someone's required to express love, his behavior of telling
truth or a lie is totally different.
In other words, emotion
expression of his body is selectively interfered by status of
telling truth or lie. “If a machine wants to copy human
being's feelings, the extent of such copy must involve
components like signals and adjustment of such emotions.
They constitute interactive connection between the body
and mental status” [27].
B. Somatic theory and appraisal
In psychology science, there are two major theoretical
factions in discussion about emotions: somatic theory and
appraisal.
The
somatic
theory
fraction
believes
that
emotions are prior to the cognitive processes: “Before
analyzing a sensed entity or even recording of any
impressions, the brain could instantly call for emotions
related to such entity” [19]. Cañamero [7] proposed that
emotions (at least part of emotions) are mechanisms used
by biological factors against the environment. This makes
generation of autonomy and adaptation easier. Bellman [6]
agreed with Cañamero's opinions. He believes that animals
11
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

with emotions could survive better than animals without
emotions. Cañamero [7] proposed that emotions’ function
in this aspect could be applied to design an autonomous
robot. Emotions could enable robots to: 1) react faster; 2)
make better decision about choosing among several options;
3) send signals about important events to others.
The appraisal, on the contrary, believes that analysis
on process of cognizing stimulation is prior to generation of
emotions.
Many
scholars
who
research
on
machine
emotions build their emotion model with appraisal as the
starting point. Some researchers do their consideration from
the actual aspect of engineering. They deem that the
function of emotions in cognition (see Figure 1) could
strengthen the robots’ expression in the establishment of
emotion models [7][15]. Furthermore, it has been proven by
neurological research that emotions' influence to human
beings does not interfere with rationality. On the contrary,
emotions are of critical function to some basic rational
behavior in our general understanding, such as perception,
learning, attention,
memory and
some other abilities
[1][9][22]. Gadanho and Hallam [16] deem that emotions
could also affect several basic cognition mechanisms like
perception, attention, memory and reasoning.
Gadanho and Hallam [16] further proposed that some
features of emotions could be transferred to AIs:
a)
Attention control: emotions could, by affecting
perception and reasoning mechanisms, force the subject to
focus on the most urgent problems;
b)
Adaptability
strengthening
of
the
subject:
emotions could check on behavior of the subject, thus to
change plans and actions of the subject when necessary;
c)
Memory filtration: emotions could better call up
memories consistent with current emotion status. Such
memory could help the subject to learn about happiness or
sadness they once experienced, thus influence the final
decision.
d)
Reasoning auxiliary: the actor's emotion system
could rapidly acquire perceptive clues that could be used to
guide acquisition of cognitive information, so as to support
thinking of the cognition system.
e)
Behavior
trend
related
to
certain
emotional
scenes or even rigid response: these built-in responses
enable automatic triggering of appropriate behavior under
urgent circumstances, and thus avoid spending unnecessary
time on complicated reasoning.
f)
Physiological
activation
of
body:
intense
emotions are usually related to energy release of anticipated
necessary action response. Its application into AI system
could include adjustment to system parameters, such as
speed of behavior actions;
g)
Support
to
social
interactions:
emotion
expression
enable
individuals
to
deliver
information
essential to their own survival to others, thus gives it high
value of adaptability.
It is deemed by many scholars that emotions could
affect cognition process, especially in two aspects of
issue-solving and decision-making [9] [26] [44]. For them,
the most basic and common function of emotions is to
“realize
more
efficient
operation
of
the
intentional
decision-making mechanism of the body” [26].
Cognition is a periodical behavior that could be
classified into several levels. For example, Sloman [35]
proposed that cognitive behavior of robots include three
major stages: 1) reactive (direct actions); 2) review stage
(selecting better and
more effective behavior among
optional behaviors); 3) integrated management (allowing
monitoring,
classification,
evaluation
and
control
on
internal stages). Moreover, Ortony also analyzed mutual
influence,
motivation
(action
trend)
and
cognition
(definition) of emotions, as well as three-stage behavior in
information
processing,
respectively
are
reactive
(electronically set action mode- primary level emotions),
daily (practiced automatic behaviors- primitive emotions),
and reflex (senior cognitive functions, comprehensive
cognition, non- consciousness, self-reflected- high level
emotions). If third-stage cognitive capability is realized,
robots would be required to be capable of handling tasks
without preset rules in unpredictable environment. Such
machine could be enabled of curiosity and self-awareness,
so as to get better ability in problem-solving.
Figure 1.
Five aspects of how emotions affect cognition
V.
THE STUDIES OF EMOTION IN AI AREA
As
mentioned
earlier,
machines
that
simulate
or
recognize human emotional expressions are not considered
to have emotions, but are considered to have “machine
emotions” only when a machine, as human beings, generates
an autonomic regulatory mechanism that plays a role in
influencing the machine’s behavior planning. It is found
that, although many studies of emotion in AI area still
focusing on making AI stimulate or recognize human
emotional
expressions,
more
and
more
attempts
and
explorations have been made in recent years to construct
“machine emotion” inside AI machines.
Parisi and Petrosino [26] built an emotional circuit with a
neural network to control the behavior of the AI. This
mechanism would allow the AI to make more accurate
motivational choices. The neural network can break through
the rules of motivation and behavior set by human beings
and activate the robot's motivational decision-making and
emotional representation in response to the situation. This
emotional state, dominated by virtual dialogue, can realize
machine function in different ways of, from executing
aimlessly to behaving under multiple motives. In addition,
thanks to AI's computational and mechanical mechanism, it
can disassemble the original motive selection of human
beings or other creatures with the help of algorithm.
According to evaluation theory, among several competing
motives or emotions, AI can evaluate the next action that
human beings or other creatures are about to take. This
decision is made by the AI, which will react to the motives
or emotions and affect the future actions of the living
creature.
In addition, some studies try to build a bridge between
physiological emotions and computer computation. They try
to reflect changes of some neuro-modulating substances in
human
bodies
through
number
changes
of
computer
computation, so as to present own emotion changes of
Attention
Learning
Memory
Reasoning
Perception
Cognition
12
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

machines.
For
example,
Kugurakova,
Talanov,
and
Manakhov [20] tried to build a human-simulated subject
which has internal emotional statuses, can make responses to
emotional stimulation and may show emotions such as
sympathy or infringement towards the one it talks with. As
believed by them, the real AI feelings need a complicated
structure which can decide responses and emotional states of
a machine subject. Based on the Emotion Rubik’s Cube
theory of Lövheim and the chemical and physiological
process mechanisms in human brains, they simulated
dopamine, serotonin and noradrenaline in a machine model
and manifested machine emotions through changes of these
neuro-modulating
substances.
Vallverdú,
Talanov,
Distefano,
Mazzara,
Tchitchigin,
and
Nurgaliev
[43]
proposed a similar model: Neuromodulating Cognitive
Architecture (NEUCOGAR). NEUCOGAR, “based on the
architecture of Von Neuman, aims to recognize the mapping
from influences of serotonin, dopamine and noradrenaline to
computer programs, so as to realize emotion phenomena
which can be operated in a Turning machine model”.
Different from the research of Kugurakova, Talanov, and
Manakhov, they expanded the Emotion Rubik’s Cube of
Lövheim using indexes of the architecture of Von Neuman.
Besides reflection of machine emotion changes based on
neuro-modulating substance changes in human bodies, some
scholars tried to use some tools, such as variable fuzzy sets
and fuzzy cognitive maps, to compute original data, reflect
changes in machine emotions, predict these emotions, design
an emotion decision making system, etc. For example, Fan
Deng, Su, and Cheng [13] presented a prediction model of
machine emotions based on emotional dimensions and the
theory of variable fuzzy sets. As found in the research, any
original data input can be computed by a variable fuzzy set,
which provides a mathematical method to express emotion
changes which are quantitative, gradually qualitative and
mutation qualitative. For another instance, in the thesis
published by Salmeron [32], based on the Thayer’s emotion
model and Fuzzy Cognitive Maps (FCMs), a new method
was proposed for prediction of machine emotions and design
of an emotion decision making system. As found in his
research, machine emotions can be predicted by original
data generated by a FCMs sensor. Based on this paper,
Salmeron [33] proposed again in 2015: taking Fuzzy Grey
Cognitive Maps (FGCMs) as an effective tool to predict
machine emotions of an autonomous system immersed in a
highly uncertain and complicated environment.
VI. CONCLUSION
As early as 1950s, Alan Turing already asked the
question “whether a machine can think” [42]. A lot of
researchers have explored this topic, while “emotion” has
always been mentioned in particular as the most outstanding
feature that can distinguishes humans from machines, and as
believed, perceptual emotions can play a crucial role in
rational behaviors. Therefore, scholars mainly focus on the
problem whether a machine can have emotions just like
humans or not.
First of all, this paper describes the definition of
emotions in the general biological sense and tries to explore
whether an AI machine can own such emotion. As found in
the research, humans give machines the emotions mainly
because they want to make machine behaviors further
similar with those of humans and then machines can serve
humans better. Because of the human centered standpoint,
machines
cannot
possess
an
independent
emotion
mechanism. Scholars argue that the expression of simulating
or recognizing human emotions cannot be deemed as
possession of emotions, so they further propose the concept
of “machine emotions” – it can form an automatic regulation
mechanism in machines just like human emotions and can
influence behavioral organization.
Based on reviewing some theoretical and practical
application of emotions in AI during recent years, the
research finds that emotion cognition, emotion prediction,
emotion-aided decision making or the like are still core
topics in the field of emotion and machine research (see
Figure 2). However, it is also found in this paper that this
field has a new trend to build a machine emotion mechanism
inside AI machines. These new studies try to break the
borders between creatures and machines, and build a bridge
between them. They try to simulate humans’ emotion
change mechanism in machines rather than implant human
emotions in the form of inputting, so that influences of
external surroundings on machine emotions are further
emphasized.
Figure 2.
Conclusion
Limitation of
human emotion
model
Unable to make
strategic
decisions
Machine cannot
have emotion
EMOTION
Machine can have emotion
Internal
External
Cognition
Decision
Autonomy
Exchange
13
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

REFERENCES
[1]
R.
Adolphs,
“Is
the
human
amygdala
specialized
for
processing social information?” Annals of the New York
Academy of Sciences, vol. 985, No. 1, pp. 326–340, 2003.
[2]
M. A. Arbib and J.-M. Fellous, “Emotions: from brain to
robot,” Trends in cognitive sciences, vol. 8, no. 12, pp. 554–
561, 2004.
[3]
R. C. Arkin, “Moving up the food chain: Motivation and
Emotion in behavior-based robots,” in Who needs emotions?:
The brain meets the robot. J.-M. Fellous & M. A. Arbib, Eds.
New York: Oxford University, pp. 245–269, 2005.
[4]
M.
B.
Arnold,
Emotion
and
Personality.
New
York:
Columbia University Press, 1960.
[5]
B. Becker, “Social robots-emotional agents: Some remarks
on
naturalizing
man-machine
interaction,”
International
review of information ethics, vol. 6, no. 12, pp. 37–45, 2006.
[6]
K. L. Bellman, “Emotions: Meaningful mappings between
the individual and its world,” in Emotions in Humans and
Artifacts. R. Trappl, P. Petta, and S. Payr Eds. Cambridge:
The MIT Press, pp. 149–188, 2003.
[7]
L. D. Cañamero, “Designing emotions for activity selection
in
autonomous
agents,”
in
Emotions
in
Humans
and
Artifacts. R. Trappl, P. Petta, and S. Payr Eds. Cambridge:
The MIT Press, pp. 115–148, 2003.
[8]
L. Damiano, P. Dumouchel, and H. Lehmann, “Towards
human–robot affective co-evolution overcoming oppositions
in constructing emotions and empathy,” International journal
of social robotics, vol. 7, no. 1, pp. 7–18, 2015.
[9]
A. R. Damasio, Descartes’ Error: Emotion, Reason and the
Human Brain. New York: Putnam, 1994.
[10] R. J. Davidson, “Darwin and the Neural Bases of Emotion
and Affective Style,” Annals of the New York academy of
sciences, vol.1000, pp. 316–336, 2010.
[11] P. Ekman, “An argument for basic emotions,” Cognition and
emotion, vol. 6, no. 3/4, pp. 169–200, 1992.
[12] P. Ekman, “Basic emotions,” in Handbook of Cognition and
Emotion. New York: Wiley, pp. 45–60, 1999.
[13] K. -K. Fan, S. -Y. Deng, C. -H. Su, and F. -Y. Cheng,
“Theory of variable fuzzy sets for artificial emotions
prediction,” Mathematical
problems
in
engineering,
vol.
2015, 2015.
[14] J.-M. Fellous and M. A. Arbib, Eds. Who needs emotions?:
The brain meets the robot. New York: Oxford University
Press, 2005.
[15] N. H. Frijda and J. Swagerman, “Can computers feel? Theory
and design of an emotional system,” Cognition and emotion,
vol.1, No. 3, pp. 235-257, 1987.
[16] S. C. Gadanho and J. Hallam, “Robot learning driven by
emotions,” Adaptive behavior, vol. 9, No. 1, pp. 42–64, 2001.
[17] C. E. Izard, Human Emotions. NewYork: Springer, 1977.
[18] A. R. James, “A circumplex model of affect,” Journal of
personality and Social Psychology, vol. 39, no. 6, pp. 1161–
1178, 1980.
[19] Z. Kowalczuk and M. Czubenko. “Computational approaches
to modeling artificial emotion–an overview of the proposed
solutions,” Frontiers in robotics and AI, vol. 3, pp. 1–12,
2016.
[20] V. Kugurakova, M. Talanov, N. Manakhov, and D.
Ivanov,
“Anthropomorphic artificial social agent with simulated
emotions
and
its
implementation,” Procedia
computer
science, vol. 71, pp. 112–118, 2015.
[21] R. S. Lazarus and B. N. Lazarus. Passion and Reason:
Making sense of our emotions. NewYork: Oxford University
Press, 1996.
[22] J. E. LeDoux, “Emotion circuits in the brain,” Annual review
of neuroscience, vol. 23, No. 1, pp. 155–184, 2000.
[23] H. Lövheim, “A new three-dimensional model for emotions
and monoamine neurotransmitters,” Medical hypotheses, vol.
78, no. 2, pp. 341–348, 2012.
[24] D. J. Mayers, Eds. “Emotions, stress, and health,” in
Psychology. NewYork: Worth Publishers, 2010.
[25] M. Minsky, The Emotion Machine and the Society of Mind.
NY: Simon and Schuster, 2006.
[26] D.
Parisi
and
G.
Petrosino,
“Robots
that
have
emotions.” Adaptive behavior, vol. 18, no.6, pp. 453–469,
2010.
[27] R. W. Picard, “What does it mean for a computer to have
emotions? ” in Emotions in humans and artifacts, R. Trappl,
P. Petta and S. Payr, Eds. Cambridge: The MIT Press, pp.
213–235, 2003.
[28] R.
Plutchik,
“A
general
psychoevolutionary
theory
of
emotion,” in Emotion: theory, research, and experience, vol.
1, R. Plutchik and H. Kellerman, Eds. New York: Academic,
pp. 3–33, 1980.
[29] R. Plutchik, “The nature of emotions: Human emotions have
deep evolutionary roots, a fact that may explain their
complexity and provide tools for clinical practice,” American
scientist, vol. 89, no. 4, pp. 344–350, 2001.
[30] J. Posner, J. A. Russell, and B. S. Peterson, “The circumplex
model of affect: An integrative approach to affective
neuroscience, cognitive development, and psychopathology,”
Development and psychopathology, vol. 17, no. 3, pp.715–
734, 2005.
[31] E. T. Rolls and S. M. Stringer, “Neurophysiology of the
primate hippocampus leading to a model of its functions in
episodic and spatial memory,” 2004 IEEE International Joint
Conference on Neural Networks (IEEE Cat. No.04CH37541),
Budapest,
Hungary,
2004,
pp.
631–636,
doi:
10.1109/IJCNN.2004.1379988.
[32] J. L. Salmeron, “Fuzzy cognitive maps for artificial emotions
forecasting,” Applied soft computing, vol. 12, no. 12, pp.
3704–3710, 2012.
[33] J. L. Salmeron, “Simulating Synthetic Emotions with Fuzzy
Grey Cognitive Maps,” Emergent trends in robotics and
intelligent systems. Cham: Springer, pp. 39–46, 2015.
[34] K. R. Scherer, Eds, “Facets of emotion: Recent research,” in
Lawrence Erlbaum Assoiates. New York: Lawrence Erlbaum
Associates, 1988.
[35] A. Sloman, “How many separately evolved emotional
beasties live within us,” in Emotions in Humans and
Artifacts. R. Trappl, P. Petta, and S. Payr Eds. Cambridge:
The MIT Press, pp. 35–114, 2002.
[36] A. Takanishi, “An anthropomorphic robot head having
autonomous
facial
expression
function
for
natural
communication with humans,” in Robotics research. London:
Springer, pp. 297–303, 2000.
[37] R. E. Thayer, The Biopsychology of Mood and Arousal. New
York: Oxford University Press, 1989.
[38] S. S. Tomkins, Affect Imagery Consciousness: Volume I:
The Positive Affects. Springer Publishing Company, 1962.
14
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

[39] S. S. Tomkins, Affect Imagery Consciousness: Volume II:
The Negative Affects. Springer Publishing Company, 1963.
[40] S. S. Tomkins, Affect Imagery Consciousness: Volume III:
The Negative Affects：Anger and Fear. Springer Publishing
Company, 1991.
[41] S. S. Tomkins, “The quest for primary motives: biography
and autobiography of an idea,” Journal of personality and
social psychology, vol. 41, No. 2, p. 306–329, 1981.
[42] A. M. Turing, “Computing machinery and intelligence,”
Mind, vol. 59, No. 236, pp. 433–460, 1950.
[43] J. Vallverdú, M. Talanov, S. Distefano, M. Mazzara, A.
Tchitchigin, and I. Nurgaliev, “A cognitive architecture for
the implementation of emotions in computing systems,”
Biologically inspired cognitive architectures, vol. 15, pp. 34–
40, 2016.
[44] J. D. Velásquez, “When robots weep: emotional memories
and decision-making,” AAAI-98 Proceedings, pp. 70–75,
1998.
15
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-839-6
MMEDIA 2021 : The Thirteenth International Conference on Advances in Multimedia

