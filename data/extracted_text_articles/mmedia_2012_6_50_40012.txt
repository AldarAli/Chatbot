 
 
Distribute the Video Frame Pixels over the Streaming Video Sequence as Sub-
Frames 
 
Hussein Muzahim Aziz  
School of Computing 
Blekinge Institute of 
Technology,  
371 79 Karlskrona, Sweden 
+46455385876 
hussein.aziz@bth.se 
 
Markus Fiedler 
School of Computing 
Blekinge Institute of 
Technology,  
371 79 Karlskrona, Sweden 
+46455385653 
markus.fiedler@bth.se 
 
Håkan Grahn 
School of Computing 
Blekinge Institute of 
Technology,  
371 79 Karlskrona, Sweden 
+46455385804 
hakan.grahn@bth.se 
 
Lars Lundberg 
School of Computing 
Blekinge Institute of 
Technology,  
371 79 Karlskrona, Sweden 
+46455385833 
lars.lundberg@bth.se 
 
 
Abstract—Real-time video streaming over wireless channel has 
become an important issue due to the limited bandwidth that is 
unable to handle the flow of information of the video frames. 
The characteristics of wireless networks in terms of the 
available bandwidth, frame delay, and frame losses cannot be 
known in advance. As the effect of that, the user may notice a 
frozen picture in the mobile screen. In this work, we propose a 
technique to prevent freezing frames in the mobile devices 
based on spatial and temporal locality for the video stream, by 
splitting the video frame into four sub-frames and combining 
them with another sub-frames from different sequence 
positions in the streaming video. In case of frames losses, there 
is still a possibility that one fourth (one sub-frame) of the 
frame will be received by the mobile device. The received sub-
frames will be reconstructed based on the surrounding pixels. 
The rate adaptation mechanism will be also highlighted in this 
work, by skipping sub-frames from the video frames. We show 
that the server can skip up to 75% of the frame’s pixels and 
the receiving pixels (sub-frames) can be reconstructed to 
acceptable quality in the mobile device. 
Keywords-streaming video; wireless network; frame splitting; 
sub-frame crossing; rate adaptation. 
I. 
 INTRODUCTION   
Nowadays mobile cellular networks provide different 
type of services and freedoms to the mobile users anywhere 
and at any time while the mobile users on the move. 
Streaming services become an important application to the 
mobile user, while streaming video is the classical technique 
for achieving smooth playback of video directly over the 
network without downloading the entire file before playing 
the video [1][5][14].   
The unpredictable nature of wireless networks in terms 
of bandwidth, and loss variation, remains one of the most 
significant challenges in video communications [9]. In this 
context, video streaming needs to implement an adaptive 
techniques in terms of transmission rates in order to cope 
with the erroneous and time variant conditions of the 
wireless network [9][10].  
Bandwidth is one of the most critical resources in 
wireless networks, and thus, the available bandwidth of 
wireless networks should be managed in an efficient manner 
[7]. Therefore, the transmission  rate of  the streaming video  
 
 
should be maintained according to the networks bandwidth 
[2][6][11].  
Network adaptation refers to how many network 
resources (e.g., bandwidth) a video stream should utilize for 
video content, resulting in designing an adaptive streaming 
mechanism for video transmission [15]. To stream video, it 
is desirable to adjust the transmission rate according to the 
perceived congestion level in wireless networks, to maintain 
the suitable loss level and fairly shared bandwidth with 
other connections. Furthermore, it is favorable for the 
streaming video to be aware of the transmission level in 
order to obtain good streaming quality by appropriate error 
protection. 
In this paper, we proposed a sub-frame crossing 
technique based on frames splitting. The video frame will be 
split into four sub-frames, and combine the sub-frame with 
another sub-frame from different sequence position and 
from different spatial data in the streaming video. The 
crossing frames in the streaming video will carry pixels 
from four different frames that belong to four different 
positions and will transmit over a single wireless channel. In 
case of sequence of frames losses or frames corruption from 
the streaming video, the losses of the sub-frames will be 
distributed on the streaming video and there is still a 
possibility that one of the fourth sub-frames will be received 
by the mobile device, while the missing sub-frames from the 
frames will be reconstructed based on the surrounding 
pixels. 
The remainder of this paper is organised as follows. 
Section II provides background and related work. Section III 
explain the proposed of streaming the video as sub-frames 
crossing. The rate adaption mechanism is presented in 
Section IV. The results are discussed in Section V, while the 
conclusion is presented in Section VI. 
II. 
BACKGROUND AND RELATED WORK 
Various techniques are proposed by many researchers 
for video frame slicing and reconstruction. The proposed 
techniques are based on H.264/AVC standard tools[20], 
where the Flexible Macroblock Ordering (FMO) slicing 
type dispersed to split the video frames and streaming them 
over the networks, while adaptive the slices is needed to 
send the highest priority information. 

 
 
Huang [13] proposed a scheme for Adaptive Region of 
Interest (AROI) extraction and adaptation by integrating the 
visual attention model in the human visual system. The 
scheme are applied to the Region of Interest (ROI) based on 
video coding for adaptation and delivery, by embedding the 
anchor point of focusing Macroblock (MB) in each key 
frame and motion vectors in other frames in the coded video 
stream or the sequence parameter set in the Scalable Video 
Coding (SVC). The error resilience tool FMO can be used 
to define certain of ROI in SVC, while the slice groups can 
be used to constitute a number of columns covering the 
frame by some elaborated tiled partitions in order to meet 
the mobile terminals with different resolutions. 
Wang and Tu [16] introduce an adapter FMO type, 
which classifies the MBs into important and unimportant 
slices. The important slice involves the details of the frames 
which represent the important contents. The complexity of 
MB content and texture change which are used to judge the 
importance of the MB. The unimportant MBs are divided 
into two slices based on edge match rule, which contributes 
to the error concealment in the decoder. The important slice 
is protected than the unimportant slice in the receiver so that 
the subjective quality of the reconstruction frame will be 
improved greatly. The proposed of adapter FMO scheme is 
to increase the error resilience of the encoded video stream 
and contribute to the error concealment realization in the 
decoder. The adapter FMO strategy is suitable technique for 
the video transmission over low bandwidth. 
Aziz et al. [3] present a technique to overcome the 
freezing frames problem on the mobile device and providing 
a smooth video playback over a wireless network. The 
frames in the streaming video will be splitted into four sub-
frames on the server side and transmitted over Multiple-
Input Multiple-Output (MIMO) by using the Multiple 
Descriptions Coding (MDC) technique. Where an initial 
delay time had been set between different channels to avoid 
the interruption on the sub-frames that are belong to the 
same frame. In case of the sub-frames that belonging to any 
subsequence 
are 
lost 
during 
the 
transmission, 
a 
reconstruction mechanism will be applied in the mobile 
device to recreate the missing pixels that are belongs to the 
missing sub-frames based on the average of the 
neighbouring pixels.  
To overcome the transmission of each frame over 
MIMO and to increases the ability to handle long losses 
during the transmission over unreliable network. A splitting 
technique is proposed to deal with the sub-frames as equally 
important, by splitting the frames into sub-frames and cross 
them with another sub-frame from different sequence 
position.  
The initial idea is been proposed in [4], where the frames 
been splitted into two sub-frames, where one sub-frame 
contains the even pixels and another contains the odd pixels. 
The combination of the sub-frame with another sub-frame 
from different sequences positions within the same 
transmission rate. The combined sub-frames will be 
streamed over a single wireless channel. In case of the frame 
being lost the available sub-frame in the mobile device will 
be reconstruct based on the surrounding pixels, while the 
maximum frames sequence lost that can be tolerated is half 
second.  
The work has been extended to tolerate a maximum 
frame sequence lost up to six seconds (in worst cases), while 
the adaption mechanism allow us to stream up to one fourth 
(skipping three sub-frames) of the video frames to the 
mobile device according to the proposed technique. The 
reconstruction to the sub-frames in the video sequence will 
be measured by the Structural Similarity (SSIM) index. 
III. 
THE PROPOSED TECHNIQUE 
Mobile video streaming is characterized by low 
resolutions and low bit rates. The bit rates are limited by the 
capacity of UMTS radio bearer and the restricted processing 
power of the mobile terminals. The commonly used 
resolution is Quarter Common Intermediate Format (QCIF, 
176 x 144 pixels) for mobile phones [8].  
Mobile real time applications like video streaming suffer 
from high loss rates over the wireless networks [12] and the 
effect of that the mobile users may notice some sudden stop 
during the playing video, the picture is momentarily frozen. 
The frozen pictures could occur if a sequence of video 
frames is lost.  
Distribute the frame’s pixels as sub-frames over the 
streaming video is considered in this work by splitting each 
frame into four sub-frames [3], where each sub-frame 
contains one fourth of the main frame pixels, as shown in 
Figure 1. The crossing technique will be applied after 
splitting the frames as sub-frames and it will be crossed with 
other sub-frames that are from different frame sequence 
position. 
During the interactive mode where the mobile clients 
request the connection to the video server, the server will 
start streaming the frames based on the frames splitting and 
frames crossing technique, as shown in Figure 2, 3 and 4, 
respectively.  
 
 
 
 
Figure 1. Snapshot of Akiyo frame splitting. 

 
 
 
 
Figure 2. Streaming video as sub-frame crossing over wireless network. 
 
Each video frame is splitted into s sub-frames, where s = 
0,…S-1, where s is four sub-frames (A, B, C, D), as shown 
in Figures 1 and 3(a), respectively. 
Each sub-frame contains different pixels information 
which make it possible to implement the frames crossing 
technique among the frames groups to created the new 
frames crossing (FC).    
The sequence of the video frames will be grouped in the 
streaming server according to the transmission rate per 
second as a frames group (FG), as shown in Figure 3(a), 
where g is the index of the frames group, g = 0,…, G-1.  
To implement the frames crossing technique between 
different frames in different group where i is the index of 
the frames group crossing (FGC) where i = 0,…, S-1, where 
the sub-frames  s  of  group  g  of the FGC  i  is obtained as  
 
FGCi (g,s) = sF(G. ((s + i) mod S ) + g , s),                  (1) 
 
and are illustrated in Figures 3 and 4, respectively. 
Crossing the sub-frames among the frames groups is 
required s buffers to queue the FGs, where the buffer size is 
equal to the frames rate, as shown in Figure 2. As an 
example, the first frames group FG0 will be queued in 
buffer 0, and the second FG1 will be queued in buffer 1, the 
third FG2 will queued in buffer 2, and the fourth FG3 will 
be queued in buffer 3. During the process of each buffer the 
next arrival group of frames, which is the fifth FG4, will be 
queued in buffer 0 and so on. 
The transmission rate are considered in this work is 30 
frames per second, where the frames group (FG) size will 
be 30 frames, during the arrival of the streaming video; the 
first 30 frames (FG0) will be splitted into four sub-frames, 
as shown in Figure 1 and 3(a). The same technique will be 
applied to the arrival of the second 30 frames (FG1) and so 
on. 
When the first frame from the fourth group (FG3) of 30 
frames arrived, the frames will be splitted into four sub-
frames and the crossing technique will be applied 
immediately to distribute the frames pixels among the four 
groups in the streaming video, as shown in Figure 3. 
 
 
a. 
The sub-frames that are related to the original frame sequence. 
 
 
 
b. 
The crossing frames position for FGC1. 
 
 
 
c. 
The crossing frames position for FGC2. 
 
 
 
d. 
The crossing frames position for FGC3. 
 
 
 
e. 
The crossing frames position for FGC4. 
 
Figure 3. The position of the sub-frames in the video sequence. 

 
 
 
 
FC0 
 
FC30 
 
FC0 
 
FC30 
 
FC60 
 
FC90 
 
FC60 
 
FC90 
a. 
Akiyo 
b. 
Foreman 
 
FC0 
 
FC30 
 
FC0 
 
FC30 
 
FC60 
 
FC90 
 
FC60 
 
FC90 
c.     News 
d.   Waterfall 
 
Figure 4. Snapshot for the Sub-frame crossing. 
 
The crossing technique is implemented based on the 
frames crossing; where the frames crossing (FC) contains 
four different sub-frames from different FGs that belong to 
the same group. As an example, the first frame crossing 
FC0 will contains the sub-frame A from frame number 0, 
sub-frame B from frame number 30, sub-frame C from 
frame number 60, and sub-frame D from frame number 90, 
while the second FC1 will contains the sub-frame A from 
frame number 1, sub-frame B from the frame number 31, 
sub-frame C from frame number 61, and sub-frame D from 
frame number 91. In another way, the streaming video will 
be based on the sub-frames crossing and it will be 
transmitted as; 
 
FC0(A0,B30,C60,D90),FC1(A1,B31,C61,D91),…, 
FC30(A30,B60,C90,D120),FC31(A31,B61,C91,D1),…,    
FC60(A60,B90,C120,D30),FC61(A61,B91,C1,D31),..., 
FC90(A90,B120,C30,D60),FC91(A91,B1,C31,D61),…, 
FC120(A120,B30,C60,D90),.., and so on, as shown in 
Figures 3 and 4 respectively. 
 
The cost for implementing the proposed technique will 
be 3 seconds as an initial delay time, where the delay time is 
the time to queue FG0, FG1, FG2, for splitting and waiting 
for the fourth FG3, the time of the first frame from FG3 
arrived it will be split and combine them with another 
frames from FG0, FG1, FG2 based on the proposed 
technique been described early. In this case we manage to 
distribute the frames pixels from different frame numbers 
and from different frames positions in the streaming video.  
The crossing technique will be applied to all the frames 
in the video streaming sequence and it will be transmitted 
over a single channel. The reason behind that, if there is lost 
or dropped of sequence of frames from the streaming video 
and under different networks condition. The effect will be 
on at least one fourth of the sub-frames from the four 
different sub-frames that are in different positions.  
The quality of the video will be affected and it will be 
distributed on the streaming video frames. 
After each frame has been received by the mobile 
device, a splitting frame technique will be applied. The sub-
frames will be held in different buffers and according to the 
order they been splitted at the server side, as shown in 
Figure 2. The sub-frames will be distributed to the relevant 
buffers and the combination of the sub-frames that are 
related to the same frame and according to their sequence 
positions based on switching between buffers to create the 
original frames sequences for the streaming video.    
 
 
 
 
a. One sub-frame is 
missing 
 
b. Two sub-frames is 
missing 
 
c. Three sub-frames is 
missing 
 
 
 
d. Reconstruct one 
missing sub-frame  
e. Reconstruct two 
missing sub-frames  
f. Reconstruct three 
missing sub-frames  
 
Figure 5. Akiyo snapshots of the missing and the reconstruction to the sub-
frames. 
The check frame sequence (CFS) procedures will take 
place in the mobile device, to check the availability of the 
sub-frames. The CFS and the reconstruction mechanism are 
used to identify the missing sub-frames and to reconstruct 
the missing pixels from the frames by considering the 
following checking procedures [3], and as shown in Figure 
5; 
• The first CFS will check whether all the sub-frames that 
are related to the same original frame are available. If 
the four related sub-frames are available, then a joining 
mechanism will be applied to return the frame to it is 
original shape.  
• The second CFS will check if at least three sub-frames 
are available. If one sub-frame is missing, then the 
average of the neighbouring pixels will be calculated to 
replace the missing frame pixels. 

 
 
• The third CFS will check if at least two sub-frames are 
available. If two sub-frames are missing, then the 
average of the neighbouring pixels will be calculated to 
replace the missing sub-frame pixels. 
• The fourth CFS will check if at least one sub-frame is 
available. If three sub-frames are missing, then the 
average of the neighbouring pixels will be calculated 
twice, the first time to find the half of the frame and the 
second time to return the full frame to it is normal shape. 
 
IV. 
RATE ADAPTION 
Rate adaptation for streaming video is regarded as it 
necessary mechanism to handle the network conditions, and 
the fluctuations of the network bandwidth.  
The adaption rate for the sub-frames crossing technique 
should be considered carefully to avoid skipping the sub-
frames that belonging to the same frame and with the 
consideration of the available bandwidth and network 
interruption to the streaming video.  The adaption rate can 
be implemented by not considering the combination of the 
four sub-frames and transmitting either three or two or one 
sub-frame to the mobile device and according to the 
following adjustments cases: 
 
• 25% adjustment, the streaming server will skip only 
one sub-frame from the video frames sequence, as 
shown in Figure 5 (a). 
• 50% adjustment, the streaming server will skip two 
sub-frames from the video frames sequence, as shown 
in Figure 5 (b). 
• 75% adjustment, the streaming server will skip three 
sub-frames from the video frames sequence, as shown 
in Figure 5 (c). 
 
The rate adaptation mechanism is needed to adjust the 
transmission rate based on the congestion level. The server 
will adjust the transmission rate by skipping the sub-frames 
that are not related to each other and the skipping rate limits 
shouldn’t cross 75% from the frames pixels to avoid discard 
to the sub-frames that are related to the same video frame. 
The receiving sub-frames will be reconstruct to it is original 
frames, as shown in Figure 5. 
V. 
RESULTS AND DISCUSSIONS 
In the normal situation, when the streaming video is 
transmitted over a single channel, the mobile device will 
start receiving the video frames and it will be held in the 
buffers until the mount of frames rate are arrived to start 
playing the video. While real time video streaming suffers 
from high loss rates over wireless networks [17], the result 
of that, the users may notice a sudden stop during the video 
playing. The picture is momentarily frozen, followed by a 
jump from one scene to a totally different one. 
The proposed technique is based on sub-frames crossing 
for the video test sequences Akiyo, Foreman, News, and 
Waterfall, as it is a well known professional test sequences 
[19], with a transmission rate of 30 frames per second.  
The quality to the reconstructed sub-frames is expressed 
in terms of the Structural Similarity (SSIM) Index [18]. The 
SSIM index will measure the reconstructed video frames to 
the reference frames, as shown in Figures 6, 7, and 8 
respectively. 
Considering the same losing frame sequence in [3], 
where the number of frames are lost are 20 frames as light 
lost  rate from the streaming video, then the affect of losing 
frames will be distributed on the streaming sequence and the 
affect will be on 80 frames, as these frames will loss one 
sub-frame. As an example, if the frame losses is started 
from frame 121 to 140, then the effect of losing one sub-
frame will affect the frames sequence from 121 - 140, 151 - 
170, 181 - 200, and from 211 - 230, as the losses of these 
frames are fall in the same crossing group. The frames that 
lost the sub-frame it will be reconstructed and therefore, the 
quality level of the frames will be affected. 
If the numbers of frames are lost are 40 frames as 
medium lost rate from the streaming video, then the affect 
of losing frames will be distributed on the streaming 
sequence and the affect will be on 120 frames, as some 
frames will lose one sub-frame while others will lose two 
sub-frames. As an example, if the loss of frames starts from 
frame 121 to 160 then the effect of losing one sub-frame 
from 131-150, 161-180, 191-210, 221-240. While the 
following frames sequence will lose two sub-frames will 
affect the frames 121-130, 151-160, 181- 190, 211-220. 
Therefore, the quality level of the video will be distributed 
on the video sequence after been reconstructed as some 
video frames loss one sub-frame and others will loss two 
sub-frames. 
If the numbers of frames are lost are 60 frames as high 
lost rate from the streaming video, then the effect of losing 
frames will be distributed on the streaming sequence and the 
effect will be on 120 frames. As an example, if the falls of 
frame losses are started from frame 121 to 180, then the 
affect of losing sub-frames will affect the frames from 121 
to 240 as all the effected frames will loss two sub-frames. 
The receiving sub-frames will be reconstructed in the 
mobile devices to return the missing pixels for each frame 
and played in the mobile screen with less quality than the 
original frames.  
The losses duration can be handle in this technique is up 
to six seconds, as shown in Figure 3. If the losses occur in 
the FGC1, FGC2, FGC3, FGC4, FGC5, and FGC6, the 
mobile device will received the following sequence of one 
sub-frame from 0 until 239, as these sub-frames are received 
by FGC0 and FGC7.  
The adaption rate is also considered in this paper, where 
the server can skip either one, or two, or three sub-frames, 
where the quality level of the video will be affected 
according to the adaption rate, as shown in Figure 8. 
Skipping three sub-frames shows low quality than skipping 
two or one sub-frame. The Waterfall video shows better 
results as the pixels of the video frames have similar data 
where the reconstruction mechanism didn’t been effected 
that much, while the News video is been effected highly by 
the reconstructions mechanism as it is quite motion video 
and it can be seen clearly in Figure 6. 

 
 
 
 
 
 
Original frame 
The reconstruction for one sub-
frame missing 
Original frame 
The reconstruction for one 
sub-frame missing 
 
SSIM     : 0.955 
 
SSIM     :  0.948 
 
 
 
 
The reconstruction for two 
sub-frames missing 
The reconstruction for three sub-
frames missing 
The reconstruction for two sub-
frames missing 
The reconstruction for three 
sub-frames missing 
SSIM     :  0.929 
SSIM     :  0.911 
SSIM     :  0.941 
SSIM     :  0.907 
a. 
Akiyo 
 
b. 
Foreman 
 
 
 
 
 
Original frame 
The reconstruction for one sub-
frame missing 
Original frame 
The reconstruction for one 
sub-frame missing 
 
SSIM     : 0.939 
 
SSIM     :  0.982 
 
 
 
 
The reconstruction for two sub-
frames missing 
The reconstruction for three sub-
frames missing 
The reconstruction for two sub-
frames missing 
The reconstruction for three 
sub-frames missing 
SSIM     :  0.923 
SSIM     :  0.874 
SSIM     :  0.972 
SSIM     :  0.945 
c. 
News 
d. 
Waterfall 
Figure 6. The SSIM for the frame number 140. 
 

 
 
 
 
 
 
 
 
a. 
Akiyo 
 
b. 
Foreman 
 
 
 
 

 
 
 
 
 
 
c. 
News 
d. 
Waterfall 
 
Figure 7. The SSIM for video frames after the lost been distributed and reconstructed to the sub-frames. 
 
 
 
a. Akiyo 
b. Foreman 
 
 
c. New  s 
d. Waterfall 
 
Figure 8. The SSIM for the reconstruction sub-frames for the adaption rate to the video frames sequence. 

 
 
VI. 
CONCLUSION 
In this paper, we proposed a sub-frames crossing 
technique to distribute the pixels as sub-frames in different 
positions in the sequence of the streaming video by 
combining it with other sub-frames from different positions. 
The idea behind that is to eliminate the losses of the 
complete single frame and allow at least one fourth of the 
frame (one sub-frame) to be received by the mobile device. 
The receiving sub-frames will reconstruct based on the 
neighboring pixels to replace the missing pixels. 
From the results, it is shown that our proposed technique 
provides a promising direction for eliminating the frozen 
picture in the mobile screen, that been caused by missing 
frames from the streaming sequence. Adjusting the number 
of frames according to the bandwidth changes is highly 
needed to reduce the amount of data to be transmitted to the 
mobile device in a congested network.  
However, the quality of the played video is degraded 
and it depends on the number of frames that are lost or 
skipped. The numbers of buffers are needed will be 
equivalent to the number of crossing group, while the initial 
delay time it needed to implement the crossing technique. 
ACKNOWLEDGMENT 
We would like to thank Katarzyna Wac from University 
of Geneva for her helpful discussions. We would like to 
thank also the Swedish Knowledge Foundation for 
sponsoring a part of this work through the project QoEMoS 
(21601420). 
REFERENCES 
[1] G. Bai and C. Williamson, “The Effects of Mobility on 
Wireless Media Streaming Performance,” Proc. of the 
Wireless Networks and Emerging Technologies (WNET 04), 
July 2004, pp. 596-601. 
[2] G.-R. Kwon, S.-H., Park, J.-W.  Kim, and S.-J.  Ko, “Real-
Time R-D Optimized Frame-Skipping Transcoder for Low 
Bit Rate Video Transmission,” Proc. of the 6th IEEE 
International Conference on Computer and Information 
Technology (CIT 06), Sept. 2006, pp. 177-177,doi: 
10.1109/CIT.2006.158. 
[3] H. M. Aziz, M. Fiedler, H. Grahn, and L. Lundberg, 
“Streaming Video as Space – Divided Sub-Frames over 
Wireless Networks,” Proc. of the 3rd Joint IFIP Wireless and 
Mobile Networking Conference (WMNC 10), Oct. 2010, 
pp.1-6, doi: 10.1109/WMNC.2010.5678760.   
[4] H. M. Aziz, H. Grahn, and L. Lundberg, “Sub-Frame 
Crossing for Streaming Video over Wireless Network,” Proc. 
of the 7th International Conference on Wireless On-demand 
Network Systems and Services (WONS 10), Feb. 2010, pp. 
53 – 56, doi: 10.1109/WONS.2010.5437132. 
[5] H. Zhu, H. Wang, I. Chlamtac, and B. Chen, “Bandwidth 
Scalable Source-Channel Coding for Streaming Video over 
Wireless Access Networks,” Proc. of Wireless Networking 
Symposium (WNCG 03), Oct.  2003.  
[6] H. Luo, M.-L., Shyu, and S.-C. Chen, “An End-to-End Video 
Transmission 
Framework 
with 
Efficient 
Bandwidth 
Utilization,”   Proc. of the IEEE International Conference on 
Multimedia  and  Expo  (ICME 04),  June  2004, pp. 623-626,  
 
 
doi: 10.1109/ICME.2004.1394269. 
[7] J.-Y. Chang and H.-L. Chen, “Dynamic-Grouping Bandwidth 
Reservation Scheme for Multimedia Wireless Networks,” 
IEEE Journal on Selected area in Communications, vol. 21, 
Dec. 2003, pp. 1566-1574, doi: 10.1109/JSAC.2003.814863. 
[8] M. Ries, O. Nemethova, and M. Rupp, “Performance 
Evaluation of Mobile Video Quality Estimators,” Proc. of the 
European Signal Processing Conference (EUSIPCO 07), Sept. 
2007, pp. 159-163. 
[9] P. Antoniou, V. Vassiliou, and A. Pitsillides, “ADIVIS: A 
Novel Adaptive Algorithm for Video Streaming over the 
Internet,” Proc. of the 18th Annual IEEE International 
Symposium on Personal, Indoor and Mobile Radio 
Communications 
(PIMRC’07), 
Dec. 
2007, 
doi: 
10.1109/PIMRC.2007.4394583. 
[10] R. Weber, M. Guerra, S. Sawhney, L. Golovanvsky, and M. 
Kang, “Measurement and Analysis of Video Streaming 
Performance in Live UMTS Networks,” Proc. of the 13th 
International Symposium on Wireless Personal Multimedia 
Communications (WPMC 06), Sept. 2006, pp. 1-5. 
[11] S. Cen, C. Pu, and R. Staehli, “A Distributed Real-time 
MPEG Video Audio Player”, Proc. of the 5th International 
Workshop on Network and Operating System Support of 
Digital Audio and Video, LNCS, 1995, pp. 142-153, doi: 
10.1007/BFb0019263.  
[12] T. Nguyen, P. Mehra, and A. Zakhor, “Path Diversity and 
Bandwidth Allocation for Multimedia Streaming,” Proc. of 
the International Conference on Multimedia and Expo (ICME 
03), July 2003, pp. 1-4. 
[13] T.Y. Huang, “Region of Interest Extraction and Adaptation in 
Scalable Video Coding,” Proc. of the  7th International 
Conference on Fuzzy Systems and Knowledge Discovery 
(FSKD 
10), 
Aug. 
2010, 
pp. 
2320-2323, 
doi: 
10.1109/FSKD.2010.5569822. 
[14] X. Cao, G. Bai, and C. Williamson, “Media Streaming 
Performance in a Portable Wireless Classroom Network,” 
Proc. of IASTED European Workshop on Internet Multimedia 
Systems and Applications (EuroIMSA´05), Feb. 2005, pp. 
246-252.  
[15] X. Zhu and B. Girod, “Video Streaming over Wireless 
Networks,” Proc. of the European Signal Processing 
Conference (EUSIPCO 07), Sept. 2007, pp: 1462-1466. 
[16] X. Wang and X. Tu, “Adaptive FMO Strategy for Video 
Transcoding,” Proc. of the International Conference on 
Communications, Circuits and Systems (ICCCAS 09), July 
2009, pp. 540 – 544, doi: 10.1109/ICCCAS.2009.5250462. 
[17] Y. Wang, A. R. Reibman, and S. Lin, “Multiple Description 
Coding for Video Delivery,” Proc. of the IEEE Journal, vol. 
93, Dec. 2004 pp. 57-70, doi: 10.1109/JPROC.2004.839618. 
[18] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, 
“Image Quality Assessment: From Error Visibility to 
Structural 
Similarity,” 
IEEE 
Transactions 
on 
Image 
Processing, vol. 13, April 2004, pp. 600-612, doi: 
10.1109/TIP.2003.819861. 
[19] http://trace.eas.asu.edu/yuv/index.html (visited, 1/11/2011) 
[20] H. Schwarz, D. Marpe, and T. Wiegand, “Overview of the 
Scalable Video Coding Extension of the H.264/AVC 
Standard,” Proc. of the IEEE Transactions on Circuits and 
Systems for Video Technology, vol. 17, Sept. 2007, pp.1103-
1120, doi: 10.1109/TCSVT.2007.905532.  

