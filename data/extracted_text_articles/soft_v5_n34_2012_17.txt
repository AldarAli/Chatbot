358
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Restoration of Blurred Images Using Revised
Bayesian-Based Iterative Method
Sigeru Omatu,
Hideo Araki, and
Yuka Nagashima
Osaka Institute of Technology, Kyocera Ltd
Asahi-ku, Osaka, 535-8585, Osaka, Japan,
Hirakata, Osaka, Japan, Fushimi-ku, Kyoto, 612-8501, Japan
omatu@rsh.oit.ac.jp, araki@is.oit.ac.jp, naga@sig.cs.osakafu-u.ac.jp
Abstract—A restoration method of degraded images based on
the Bayesian-based iterative method is proposed. An iterative
method is developed by regarding the observed degraded im-
ages as probabilities and point spread functions as the condi-
tional probabilities. The restored images are estimated by using
Bayesian rule. We have proposed two kinds of the iterative
method. One is to use the observed images as the initial values of
the estimated images when we estimate the point spread function.
The other method is to estimate the initial values of the point
spread function by using the logarithmic amplitude spectrum of
the blurred image. The simulation results show that the proposed
methods are effective to restore the blurred images.
Keywords-point spread function; Bayesian rule
I. INTRODUCTION
To make a clear image from degraded image, many
enhancement techniques have been developed until now
[1],[2],[3],[4],[5]. There are so many papers published until
now about restoration algorithms. Those papers can be clas-
siﬁed into two categories. One is a model-based approach
[2],[3],[4] and the other is a learning-based approach.
The main technique for the former approach is to de-
velop sharpness ﬁlters [2],[3]. More masks to approximate a
derivative operation have been developed. By using the ﬁlters
they could enhance the image. But they also enlarge pixel
noise. The learning-based approach is to develop an iterative
algorithm such that a criterion function could be minimized.
We adopt the second approach to enhance images by using
the Bayesian rule. This method was ﬁrst proposed by [5].
The Bayesian rule reﬂects optimal estimation in a sense to
minimize the cost function under noisy observation and an
iterative algorithm was proposed to ﬁnd the optimal solution
[6] and [7]. The algorithm include two parts, the ﬁrst one is to
estimate a point spread function from the estimated image and
the second one is to estimate the original image by using the
estimated point spread function. Thus, this algorithm might
be optimal when the observed image is similar to the original
image, that is, in case of a high S/N ratio. Therefore, the
results will depend on the initial guesses of point spread
function although the previous reports are assumed to be
ﬁxed [5],[6],[7].
In this paper, we propose two methods. One is to use the
observation image instead of the estimated image when we
estimate the point spread function (Algorithm I). The other
method is to use an estimated point spread function as the
initial guess of the point spread function in the Bayesian-based
iterative procedure.
First, we will show the principle of the Bayesian-based
iterative method proposed by Richardson [5]. Then, we will
propose two methods. After that the simulation results are
illustrated to show the effectiveness of the proposed methods.
II. PRINCIPLE OF IMAGE RESTORATION
In image enhancement, the ultimate goal of restoration tech-
niques is to improve a given image in some sense. Restoration
is a process that attempts to recover an image that has been
degraded by using a priori knowledge of the degradation
phenomenon. As shown in Fig. 1, the degradation process may
be modeled as an operator H in case of noiseless situation.
It operates on an input image f(x, y) to produce a degraded
image g(x, y). For the sake of simplicity, we denote f(x, y)
by f(x) , g(x, y) by g(x), h(x, y) by h(x), etc. In equation
form, we have
g(x) = Hf(x) = h ∗ f(x) =
∞
X
y=−∞
h(x − y)f(y)
(1)
where h(x) is an impulse response and * denotes the operation
of convolution.
Based on the convolution theorem, the frequency domain
representation of Eq. (1) becomes
G(jω) = H(jω)F(jω)
(2)
where G(jω), H(jω), and F(jω) are Fourier transforms of
g(x), h(x − y), and f(y), respectively. As shown in Fig. 1,
given G(jω) and some knowledge about H(jω), the objective
of restoration techniques is to recover F(jω) which means
to recover the original image f(x) via the inverse Fourier
transform.
III. RICHARDSON’S ITERATIVE METHOD
We will review an iterative method by Richardson [5] in
this section. Given the degraded image g, the point spread
function h and the original image f are estimated based on
Bayes’ theorem. It will be effective to estimate the original
image f from the observed image g. It was assumed that g,
h, and f are discrete and are not necessarily normalized. The
numerical values of g, h, and f are considered as measures of
the frequency of the occurrence of them at those points. h is
usually in normalized form. Energy of f originating at a point

359
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Original image
 
Degraded image
*
  f(x)      h(x)  =   g(x)
 =
h(x)
F Transform
*
X   H(jω) = 
X   H(jω) = G(jω)
 F(jω)
  f(x) = F    {G(jω) / H(jω)} 
-1
Fig. 1.
The restoration principle.
is distributed as g at points according to the energy indicated
by h. Thus, g represents the resulting sums of the energy of
f originating at all points.
In the notation of this problem the usual form of the Bayes’
theorem is stated as the conditional probability of f, given g.
It was assumed that the degraded image g was of the form
g = h ∗ f, where * denotes the operation of convolution such
that
g(x) = h ∗ f(x) =
∞
X
y=−∞
h(x − y)f(y).
(3)
Note that f and g are intensity functions of the original
image and observed image, respectively and h is the weight-
ing function depending on image measurement devices. We
assume that the input image and the weighting function are
unknown. The values of f, g, and h are not limited within
[0,1]. We normalize and denote them by f ′, g′, and h′. Thus,
we have
f ′(x)
=
f(x)
∞
X
x=−∞
f(x)
= f(x)
F
(4)
g′(x)
=
g(x)
∞
X
x=−∞
g(x)
= g(x)
G
(5)
h′(x)
=
h(x)
∞
X
x=−∞
h(x)
= h(x)
H
(6)
where F,G, and H could be equal since the restoration
process is conservative. Note that f, g, and h are nonnegative
and the total sums are equal to one. Thus, we could regard
them as probability measures and f ′(x1) as the probability
measure of the original image f(x1) at x1. This means that
the possibility of the existing intensity of the original image
f(x1) at x1. Similarly, g′(x2) and h′(x1) mean the possibility
of the existing intensity of the observed image g′(x2) at x2 and
the possibility of the transition weight from the input image
f(x1) at x1 to the output image g(x2) at x2. Therefore, we
have
P(g(x2)|f(x1)) = P(h(x2 − x1)) = h′(x2 − x1).
(7)
The above relation can be derived by using the following
relation.
P(g(x2), f(x1))
=
P(g(x2)|f(x1))P(f(x1))
=
P(h ∗ f(x2), f(x1))
=
P(h(x2 − x1), f(x1))
=
P(h(x2 − x1))P(f(x1))
where we have used independence assumption between orig-
inal image and restoration mechanism.
Using the Bayes’ theorem we have
P(f(x)|g(x2))
=
P(g(x2)|f(x))P(f(x))
∞
X
x1=−∞
P(g(x2)|f(x1))P(f(x1))
=
f ′(x)h′(x2 − x)
∞
X
x1=−∞
f ′(x1)h′(x2 − x1)
.
(8)
If we multiply the both sides of Eq. (8) by P(g(x2)) = g′(x2)
and take the summation with respect to x2, we get
P(f(x))
=
f ′(x)
=
f ′(x)
∞
X
x2=−∞
h′(x2 − x)g′(x2)
∞
X
x1=−∞
f ′(x1)h′(x2 − x1)
.(9)
Considering F = G = H and multiplying them both sides of
the above equation, we have
f(x) = f(x)
∞
X
x2=−∞
h(x2 − x)g(x2)
∞
X
x1=−∞
f(x1)h(x2 − x1)
.
(10)
Using the above equation, Richardson[5] proposed the follow-
ing recurrence procedure to ﬁnd the original image f(x).
fn+1(x)
=
fn(x)
∞
X
x2=−∞
hn(x2 − x)g(x2)
∞
X
x1=−∞
hn(x2 − x1)fn(x1)
,(11)
n
=
0, 1, 2, . . . .
In order to derive the recursive equation of the point spread
function h(x), we will set x3 = x2 − x. Then from Eq. (8)
we have
P(f(x2 − x3)|g(x2)) =
f ′(x2 − x3)h′(x3)
∞
X
x1=−∞
f ′(x1)h′(x2 − x1)
.
(12)

360
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Multiplying both sides of the above equation by P(g(x2)) =
g′(x2), we have
P(f(x2 − x3)|g(x2))P(g(x2))
(13)
= g′(x2)
f ′(x2 − x3)h′(x3)
∞
X
x1=−∞
f ′(x1)h′(x2 − x1)
.
Using the Bayes’ rule, we have
P(f(x2 − x3)|g(x2))P(g(x2))
= P(f(x2 − x3), g(x2))
= P(g(x2)|f(x2 − x3))P(f(x2 − x3))
= h′(x3)f ′(x2 − x3).
(14)
From Eqs. (14)and (14), we have
h′(x3)f ′(x2 − x3)
= g′(x2)
f ′(x2 − x3)h′(x3)
∞
X
x1=−∞
f ′(x1)h′(x2 − x1)
.
(15)
Taking the summation of both sides of Eq. (15) with respect
to x2, using the relation of Eqs. (4), (5), and (6), and noting
that
∞
X
x2=−∞
f ′(x2 − x3) = 1,
(16)
we have the following relation.
h(x) = h(x)
∞
X
x2=−∞
f(x2 − x)g(x2)
∞
X
x1=−∞
f(x1)h(x2 − x1)
.
(17)
Thus, using the same recursive relation as Eq. (11), we have
hm+1(x) = hm(x)
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
fn(x1)hm(x2 − x1)
.
(18)
In order to check the convergences of the recursive relations
given by Eqs. (11) and (18), the following relations are used.
∞
X
x2=−∞
h(x2 − x)g(x2)
∞
X
x1=−∞
h(x2 − x1)fn(x1)
= 1,
(19)
∞
X
x2=−∞
f(x2 − x)g(x2)
∞
X
x1=−∞
f(x1)h(x2 − x1)
= 1.
(20)
(21)
Thus, we use the following criteria to stop the iterations.
1 − ϵ <
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
< 1 − ϵ,
(22)
1 − ϵ <
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
fn(x1)hm(x2 − x1)
< 1 − ϵ.
(23)
Using the above relations, Richardson has proposed the fol-
lowing iterative algorithm(Richardson’s Iterative Method).
Step 1. Set n = 0, m = 0, the initial guesses of h0(x), and
f0(x), and small positive number ϵ.
Step 2. Solve the following equations:
fn+1(x) = fn(x)
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
(24)
hm+1(x) = hm(x)
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
fn(x1)hm(x2 − x1)
.
(25)
Step 3. If the following inequalities hold
¯¯¯¯¯
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
¯¯¯¯¯ < 1 − ϵ
(26)
and
¯¯¯¯¯
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
fn(x1)hm(x2 − x1)
¯¯¯¯¯ < 1 − ϵ,
(27)
then stop, otherwise n ← n + 1, m ← m + 1 go to Step 2.
The above iteration has no proof of convergence that means
the results obtained by the above iteration may result in the
good results or may not.
IV. PROPOSED ALGORITHM I
In order to get better results compared with Richardson’s
algorithm, we consider a new method based on the property
of degraded images such that the blurred images are similar
to the original images. In the Richardson’s algorithm, if the
bad estimation of hm(x) at the beginning stage, corresponding
recovered images would become different images. After ob-
taining the bad estimation of recovered images, estimation of
the point spread function turns worse. As a result, the iteration
will produce worse and worse estimation of the point spread
function and recovered images. Assuming the degraded images
are not so far from the original images, we use the blurred
image to estimate the point spread function hm(x) instead of
the recovered image that is the estimated image. Therefore,
we have proposed the following steps:

361
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Algorithm I
Step 1. Set n = 0, m = 0, small positive number ϵ, and
f0(x) = g(x). Set the initial guesses of h0(x).
Step 2. Solve the following equations:
fn+1(x) = fn(x)
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
(28)
hm+1(x) = hm(x)
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
g(x1)hm(x2 − x1)
. (29)
Step 3. If the following inequalities hold
¯¯¯¯¯
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
¯¯¯¯¯ < 1 − ϵ
(30)
and
¯¯¯¯¯
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
fn(x1)hm(x2 − x1)
¯¯¯¯¯ < 1 − ϵ,
(31)
then stop, otherwise n ← n + 1 and go to Step 2.
V. VARIATION USING THE REVERSE FUNCTION
We consider a more simple form of the proposed algorithm.
We set the denominator of Eq. (38) by
Lnm(x2) =
∞
X
x1=−∞
hm(x2 − x1)fn(x1).
(32)
It is the convolution sum between the original image fn(x1)
and the point spread function hm(x2 − x1). Therefore, if
Lnm(x2) = g(x2), then the estimated image fn(x1) becomes
the true original image. Furthermore, we have
fn+1(x) = fn(x)
∞
X
x2=−∞
hm(x2 − x)g(x2)
Lnm(x2)
.
(33)
We deﬁne rnm(x2) by
rnm(x2) =
g(x2)
Lnm(x2)
(34)
which means the ratio between the observed degraded image
and the degraded image obtained by using the estimated point
spread function. Then Eq. (33) becomes
fn+1(x) = fn(x)
∞
X
x2=−∞
hm(x2 − x)rnm(x2).
(35)
We deﬁne the reverse function of k(x) by k(x) = h(−x).
Then Eq. (33) becomes
fn+1(x) = fn(x)
∞
X
x2=−∞
km(x2 − x)g(x2)
Lnm(x2)
.
(36)
If we represent the convolution sum by Fourier transform, we
have
fn+1(x)
=
fn(x)FT −1(FT(km(x − x2))FT(rnm(x2)))
=
fn(x)FT −1(Km(jω)Rnm(jω))
(37)
where FT and FT −1 denote the Fourier transform and inverse
Fourier transform. Since Km(jω) = Hm(−jω), we could save
the computational time by half.
VI. SIMULATION RESULTS OF THE PROPOSED
ALGORITHM I
In order to show the effectiveness of the proposed method,
we will consider gray image (Example 1)and two of color
images(Example 2, Example 3). The computer speciﬁcation
used here is shown in TABLE I. In Example 1 the gray image
of 64 × 64 was made using Photoshop. The color images
of512 × 512 of Example 2 and Example 3 were cropped
from the standard sample data of high-resolution color images
[8]. The degraded images are made by using Gaussian ﬁlters
with the standard deviation σ = 3.3. We used the stopping
parameters of m and n when maximum iteration number k
is given. In these simulations, we changed those parameters
(m, n, k) as (10,100,10), (5,100,10), and (5,5,100). TABLE
II shows simulation results for three cases with PSNR (Peak
Signal-to-Noise Ratio) in case of Example 2. Fig. 2 shows
the simulation results of the gray image with (10,100,10).
From this Fig. 2 the proposed method restored a clearer image
compared with the results of Richardson’s method [5]. In
Figs.3-10 we show the simulation results of Example 2 and
Example 3 with images obtained from [8]. The original images
are shown in Fig. 3 and Fig. 7. The degraded images are
shown in Fig. 4 and Fig. 8. The restored images by [5] and
the proposed method are shown in Fig. 5 and Fig. 9.
 
 
 
 
          (a)                                       (b) 
        (c)                                       (d) 
Fig. 2.
The comparison for Example 1.

362
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Fig. 3.
Original image for Example 2: Cafeteria.
Fig. 4.
Degraded image for Example 2.
 
Fig. 5.
Richardson’s method for Example 2.
 
Fig. 6.
Proposed Algorithm I for Example 2.
TABLE I
COMPUTING ENVIRONMENT
OS
Windows XP
CPU
AMD Athlon(tm)64 X2 Dual Core
Memory
2GB
VII. PROPOSED ALGORITHM II
The above algorithm has some problems. One is a conver-
gence problem for iteration. We must select a suitable initial
function of the point spread function to obtain good results.
TABLE II
PSNR BETWEEN ORIGINAL IMAGE AND RESTORED IMAGE
Threshold value(m,n,k)
Degraded image
Richardson
Authors
(10,100,10)
14.5
15.7
16.6
(5,100,10)
14.5
16.5
16.0
(5,5,100
14.5
9.2
16.2
The other problem is the speed of convergence. To solve these
problems, we assume that the logarithmic amplitude spectrum
of the point spread function is Gaussian distribution. This is

363
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Fig. 7.
Original image for Example 3: Fruits basket.
Fig. 8.
Degraded image for Example 3.
Fig. 9.
Richardson’s image for Example 3.
Fig. 10.
Proposed Algorithm I for Example 3.
based on the fact that the power spectrum of the point spread
function is equi-uniform for each frequency. To speed up the
computation to estimate the point spread function, we select
a small area of the image where the low frequency seems to
be dominant.
A. Estimation of the Point Spread Function
It is well-known that the spectrum of the point spread
function includes the low frequencies compared with those
of the original images. From Eq. (2) we can see that the
spectra of the observed image are almost similar to the spectra
of the point spread function. Thus, we can estimate the
spectrum region of the point spread function from the blurred
image (observed image). Since the major part of the low
frequency region is affected by the zero frequency component,
we adopt the logarithmic amplitude spectrum of the blurred
image to remove the zero frequency. Thus, the computation
process to estimate the point spread function is given by the
following steps.
Step 1. Applying the Hamming window to the blurred
image, ﬁnd the logarithmic amplitude spectrum of the obtained
image.
Step 2. Normalize the logarithmic amplitude spectrum
within [0, 255] and threshold it with 128. The image is called
a binary image.
Step 3. To remove the impulsive noise, apply 5 × 5 median
ﬁlter to the binary image.
Step 4. Find the center of the binary image and determine
the radius r by using the least mean squres method.
Step 5. Set r = 3σ and ﬁnd the Gaussian distribution
function.
Step 6. Using inverse Fourier transform, ﬁnd the point
spread function h(x).
To show the process stated above, we will use a sub-area

364
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Fig. 11.
The original image: Wine and tableware and sub-image to estimate
the point spread function. Here, the sub-image is denoted by the square area
and it is assumed to be known the point spread function with the spectrum
as shown in the image.
of the original image with the known point spread function
as shown in Fig. 11. Using this sub-image, we apply the
procedure to an image given by Fig. 12.
B. Algorithm II
The estimate of the point spread function by using Step 1 to
Step 6 is used as a rough estimate of the point spread function
in order to converge the iteration algorithm in Algorithm I.
Thus, Algorithm II is given by the following steps:
Step 1. Set n = 0, m = 0, small positive number ϵ.
Furthermore, f0(x) = g(x) and h0(x) = hp(x) where hp(x)
denotes the estimated h(x) in the above Section.
Step 2. Solve the following equations:
fn+1(x) = fn(x)
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
(38)
hm+1(x) = hm(x)
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
g(x1)hm(x2 − x1)
. (39)
Step 3. If the following inequalities hold
¯¯¯¯¯
∞
X
x2=−∞
hm(x2 − x)g(x2)
∞
X
x1=−∞
hm(x2 − x1)fn(x1)
¯¯¯¯¯ < 1 − ϵ
(40)
and
¯¯¯¯¯
∞
X
x2=−∞
fn(x2 − x)g(x2)
∞
X
x1=−∞
fn(x1)hm(x2 − x1)
¯¯¯¯¯ < 1 − ϵ,
(41)
then stop, otherwise n ← n + 1 and go to Step 2.
TABLE III
COMPUTING TIME
Algorithm I
Algorithm II
Time [s]
38179.56
846.95
C. Speed-Up of Algorithm II
In order to speed up the algorithm, we should use the small
size training image as shown in Fig. 11 instead of the full size
image. the selection of the sub-image is the most important to
obtain a better estimation of the point spread function. Since
we can assume that he point spread function is the same even
if the image sizes are different, we use a small size image
instead of a large size image. We use images with 2560×2048
and select 256×256 to estimate the point spread function. The
problem is where we should select the sub-images for training
the point spread function. Estimation of Bayesian principle
requires the broad band input data as in the system parameter
identiﬁcation to get the high performance. Thus, we select the
high frequency images which include many edges. To ﬁnd
the edges, we use the Laplacian ﬁlter and take the area with
large variance. Therefore, we select the sub-image area by the
following steps:
Step 1. Apply the Laplacian ﬁlter to the observed image.
Step 2. Select the sub-image with 256 × 256.
Step 3. Find an area with the largest variance from the above
sub-images.
By the above steps we will select the training area to
estimate the point spread function stated in Section VII-A.
VIII. SIMULATION RESULTS
We consider Cafeteria, Fruits and basket, and Wine and
tableware whose true images are known in advance. After
applying Algorithm I and Algorithm II to those images, we
check the case where the true image is not obtained and the
blurred images are taken by using a high resolution camera
without adjusting so precisely which results in a little bit
blurred images. We show the simulation results for the former
case in Figs. 13-15 which are corresponding to Figs. 2, 7,
and 11, respectively.
Compared with the restored images by Algorithm I, the
restored images seem to be similar to the original ones.
Furthermore, the computational time by Algorithm II is faster
than that of AlgorithmI as shown in Table III.
Finally, we have applied Algorithm I and Algorithm II to
the blurred images which are taken by using a high resolution
camera. Here, we took artiﬁcially blurred images without auto-
focus operation. Restored images are shown in Figs. 16 and
17. The case of high density camera makes clear images when
the image scales are small. But if we enlarge them, then the
difference become clear as shown in Fig. 17. From this result,
the Algorithm II could be used to restore the blurred images.
IX. CONCLUSIONS
In this paper, methods of restoration of the degraded images
by using the Bayesian-based iterative method are proposed.

365
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The simulation results showed that the proposed method could
restore the degraded images more clearly compared with the
Richardson’s method while the threshold values of (n, m, k)
must be determined by trial and error.
Furthermore, the computation load has been decreased by
half by introducing the ratio between the observed degraded
image and the degraded image by using Algorithm I. Algo-
rithm II could restore the blurred images more precisely and
faster compared to Algorithm I since the latter method has
only selected the initial image as the observed image without
considering the initial guess of the point spread function.
Algorithm II takes more time to estimate the point spread
function. But taking into consideration that the point spread
function does not vary from place to place in the same image,
we can select small region to estimate the function. In this
paper, we select the sub-image where the variation of the
image is rather high, that is, the image includes many edges.
Since we took the sub-image with 256 × 256 size, it did not
require so much time.
An open problem is that the Bayesian approach might not
have a solution since the convergence of the iterative method
has not been proved. But the initial guess may not be so far
from the solution of the Bayesian equation since the blurred
image structure will keep the similar behavior to the original
images.
ACKNOWLEDGMENT
This work was supported by JSPS KAKENHI Grant-in-Aid
for Scientiﬁc Research (B) (23360175). The authors would
like to thank JSPS to support this research work.
REFERENCES
[1] S. Omatu and H. Araki, Image Restoration by Revised Bayesian-Based
Iterative Method, ADVCMP 2011, Lisbon, Portugal, (2011)
[2] T. Young and K. Fu, Handbook of Pattern Recognition and Image
Processing Independent Component, Academic Press, New York, (1986)
[3] R. Duda, P. Hart, and D. Stork, Pattern Classiﬁcation, John Wiley &
Sions, New York, (2001)
[4] Y. Yizhaky, I. More, A. Lantzman, and N. S. Kopeika, Direct Method
for Restoration of Motion-Blurred Images, Journal of Optical Society of
Amarica, Vol. 15, pp. 1512-1519, (1998)
[5] W. Richardson, Bayesian-Based Iterative Method of Image Restoration,
Journal of Optical Society of America, Vol. 62, pp.55-59, (1972)
[6] B. Lucy, An Iterative Method for the Rectiﬁcation of Observed Distribu-
tions, JAston. Journal, Vol. 79, pp. 745-754, (1974)
[7] R. G. Lane, Methods for Maximum-Likelihood Deconvolution, Journal
of Optical Society of America,A, Vol. 13, pp. 1992-1998, (1972)
[8] Standard Color Digital Images of High-Resolution(CMYK/SCID), JIS X
9201:2001, (2001)
Fig. 12.
The estimation process of the point spread function. Here, (a)
is the blurred image denoted in Fig. 11, (b) is the logarithmic amplitude
spectrum of (a), (c) is the blurred image ﬁltered by the hamming window, (d)
is the logarithmic amplitude spectrum of (c), (e) is the estimated logarithmic
amplitude spectrum of (d) after processing of Step 2 and Step 3, (f) is
estimated Gaussian distribution of (e) after processing Step 4 and Step 5,
(g) is the estimated point spread function, and (h) is the true point spread
function.

366
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Fig. 13.
The simulation results for the image: Cafeteria. Here, (a) is the
original image, (b) is the blurred image, and (c) is the image by Argorithm
I, and (d) is the image by Argorithm II.
Fig. 14.
The simulation results for the image: Fruits basket. Here, (a) is the
original image, (b) is the blurred image, and (c) is the image by Argorithm I,
and (d) is the image by Argorithm II.
Fig. 15.
The simulation results for the image: Wine and tableware. Here,
(a) is the original image, (b) is the blurred image, and (c) is the image
by Argorithm I, and (d) is the image by Argorithm II. known point spread
function with the spectrum as shown in the image.

367
International Journal on Advances in Software, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
(a)
(b)
(c)
Fig. 16.
The simulation results for the blurred image: Osaka Prefecture
University. (a) is the blurred image, (b) is the image by Argorithm I, and (c)
is the image by Argorithm II. known point spread function with the spectrum
as shown in the image.
Fig. 17.
The comparison of the small area. (a) is the blurred image, (b) is
the image by Argorithm I, and (c) is the image by Argorithm II.

