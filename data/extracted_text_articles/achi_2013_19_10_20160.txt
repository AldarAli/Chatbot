Proposal of an Automobile Driving Interface Using 
Gesture Operation for Disabled People 
 
Yoshitoshi Murata, Kazuhiro Yoshida 
Faculty of Software and Information Science 
Iwate Prefectural University 
Takizawa, Japan 
y-murata@iwate-pu.ac.jp, kyoshida@ipu-office.iwate-
pu.ac.jp 
Kazuhiro Suzuki, Daisuke Takahashi 
JFP Inc. 
Morioka, Japan 
ss@jfp.co.jp, takahashi@jfp.co.jp
 
 
Abstract— A steering operation interface has been designed for 
disabled people that uses gesture operation. It incorporates both 
non-linear and semi-automatic steering control. Experiments 
using a gyro sensor and a driving simulator demonstrated that 
the driving operation is close to that achieved with conventional 
steering wheel operation. Sufficient practice in using the 
proposed interface should therefore enable a user to achieve 
steering control closer to that achieved with a steering wheel. 
Keywords-automobile driving interface; disabled people; gyro 
sensor; gesture operation; body part operation 
I. 
 INTRODUCTION 
 Disabled people generally want to stand on their own two 
feet, and achieving mobility is an important step in doing this. 
One way to enhance mobility is through the use of an 
automobile to which a driving-assistance device has been 
attached. However, there has been a lack of development of                                                                                             
auxiliary devices and systems that would enable disabled 
people, especially people with arm and wrist disabilities, to 
drive a car. For example, the first such system, the original of 
Honda’s Franz system [1], was developed in the 1960s. With 
this system, a car is operated with only the feet. Since the 
steering wheel is turned by pumping the pedals, its operation is 
not intuitive. 
With the system developed by Wada and Kameda, the 
steering wheel is controlled with a joystick, and the brake and 
accelerator are controlled with another joystick [2][3]. This 
system has aided many disabled people, but strength is needed 
to operate the joysticks. Moreover, the levers onto which the 
joysticks are fixed have to be customized for the hand positions 
of each user.  
In any case, mechanical devices such as these lack 
flexibility and have to be customized for the user. Hence, they 
are inherently expensive.  
The on-going shift from hydraulic to electronic driving 
interface systems (steering, braking, etc.) means that systems 
combining computer chips with sensors can now be used to 
easily control these driving interfaces. Candidate sensors 
include the KINECT sensor, a gyro sensor and so on. 
We have designed a steering operation interface for 
disabled people that is operated by gestures, developed a 
prototype control device that uses a gyro sensor, and evaluated 
it by using a driving simulator as the initial stage of our 
research. 
After discussing related work in Section II, we describe the 
gestures, i.e., body-part movements assigned to the various 
functions in Section III, the driving simulator we developed to 
evaluate our proposed driving interface in Section IV, and the 
experimental evaluation we conducted in Section V. The key 
points are summarized and future work is mentioned in Section 
VI. 
II. 
RELATED WORKS 
A. Driving Interface for Disabled people 
The Franz system used by Honda was aimed at people who 
have difficulty moving their arms and/or hands. The user 
operates a car using only his or her feet [1]. It was originally 
implemented in the Honda Civic in 1982, creating the first 
Funding for this work was received from the Iwate Strategic Research 
Foundation. 
(1) Steering pedal
(2) Steering box
(3) Brake lock button
(4) Selection bar for feet
(5) Side brake for knee
(6) Sub‐brake for exercise
Wiper lever for  left knee
Winker lever for  right knee
Combination switch es
Figure 1. Honda’s Franz system 
472
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

vehicle for disabled people in Japan. It has now been 
implemented in the Honda Fit. 
The steering wheel is turned right or left by pumping a 
steering pedal (see Fig. 1). The transmission is shifted into 
drive by lifting the selection bar, into reverse by pushing it 
down, and into park by pushing it further down. The turn 
signals and windshield wipers are operated by turning levers 
using the right and left knees. Power windows, lights, and so 
on are controlled by flipping switches up or down using the 
right foot or knee. 
Wada and Kameda developed a joystick car driving 
interface for wheelchair users. In the initial version [2][3], the 
steering, braking, and acceleration were controlled with one 
joystick. In the latest version, two joysticks are used, as shown 
in Fig. 2. The right joystick controls the steering, and the left 
one controls the acceleration and braking. The relationship 
between the angle of the steering wheel and the angle of the 
joystick is a polyline, as shown in Fig. 3. This means that a 
driver can sensitively control the steering wheel around the 
neutral position and can turn the wheel quickly when making a 
wide turn. People who can freely move their hands can drive an 
automobile using this device. 
In any case, such mechanical devices must be customized 
to fit the user’s disability and physical form. 
B. Sensors for gesturing 
Several driving interfaces using the KINECT sensor have 
been developed. With the “Air Driving” interface developed by 
Forum8, a user can drive a virtual car in a simulated world by 
moving his or her hands and feet in front of the sensor [4]. 
Since there must be at least 50 cm between the sensor and the 
gesturing body part, it cannot be used in an actual car. Rahman 
et al. developed a car audio operation interface that uses a 
KINECT sensor [5]. Although this interface has been 
demonstrated in an actual car, its use as a driving interface 
(steering, braking, etc.) has not been examined.  
Döring et al. developed a multi-touch steering wheel that 
can control not only the steering but also the car audio [6]. 
However, users with an arm disability have trouble operating it. 
Other examples of using an acceleration sensor and/or a 
gyro sensor as a gesture operation interface include video 
games and home appliance remote controls [7]. 
III. 
GESTURES (BODY-PART MOVEMENTS) FOR OPERATION 
A. Operating functions 
Door open/close, window open/close, wiper on/off, and 
turn signal on/off functions are needed to drive an automobile 
in addition to the basic operations of steering, braking and 
accelerating. Moreover, since automobiles typically have an 
audio system, a navigation system, and a climate control 
system, a driver should be able to operate these systems as well. 
Other than for the basic operating functions, a fine degree of 
control is not needed for the operating functions—they can 
generally be controlled by flipping a switch, as in Honda’s 
Franz system. Moreover, voice-command control systems like 
that used for Samsung’s SMART TV [8] could also be used. 
Of the basic operations requiring a fine degree of real-time 
control (steering, braking and accelerating), we focused on 
steering, which requires the finest degree of control. Our 
research results should be easily transferable to braking and 
accelerating. 
B. Steering operation requirements 
Steering an automobile by moving a body part should 
produce the same results as steering by turning the wheel by 
hand. Given this basic requirement, we derived several specific 
requirements. 
1) The automobile should be steerable within ± several ten 
degrees from the neutral position. 
- There should be a fine degree of steering control 
around the neutral position. 
- Steering should be quick when making a wide turn. 
2) The driver should be able to keep the vehicle within the 
lane on both straightaways and curves of various radii 
at a normal driving speed. 
 
Figure 2. Wada and Kameda’s joystick driving interface 
 
50
100
－50
－100
50
100
－50
－100
Angle of joystick (%)
Angle of steering
wheel (%)
 
 
Figure 3. Relationship between angle of joystick and angle of steering 
wheel 
473
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

3) The driver should be able to drive stably, not zigzag, on 
straightaways  
4) The driver should be able to traverse a curve while 
keeping the steering wheel at a position fixed 
immediately before entering the curve and then exit the 
curve into a straightaway by gradually returning the 
steering wheel to the neutral position. 
C. Candidate sensors or devices 
We considered four types of sensors or devices for 
controlling steering. 
- KINECT sensor 
- Video camera 
- Rotary encoder 
- Gyro sensor 
Using a KINECT sensor or video camera is problematic 
because the unit has to be attached to the car, and the locations 
for possible attachment are limited. Moreover, as mentioned 
above, there must be at least 50 cm between a KINECT sensor 
and the gesturing body part, which greatly limits the possible 
attachment locations. 
A rotary encoder requires the use of a mechanical adapter 
to measure the joint angle of a finger, an elbow, an ankle, and 
so on. 
Since a gyro sensor is affected by not only the joint angle 
but also the vehicle motion, it must be attached to the vehicle to 
eliminate this effect. Moreover, a gyro sensor has a drift error 
that increases cumulatively. Since it is very difficult to remove 
the cumulative error completely, the measurement angle has to 
be reset using reliable data measured by another means. 
A strain gauge does not have a drift error and is not affected 
by vehicle motion, so it should be better suited for measuring 
joint angles than a gyro sensor. We plan to investigate its 
usefulness in future work. 
In this work, we investigated the use of a gyro sensor (ATR 
Promotion WAA-010) as well as a joint angle such as a finger, 
an elbow, or an ankle for driving a car. 
D. Steering control 
The steering wheel in an actual automobile can be turned 
about three complete revolutions from wheel lock to wheel 
lock (about 1080°). In contrast, the movable angle of a joint 
angle is about 20–90°, much less than that of a steering wheel. 
Hence, it is impossible to control the steering with a joint angle 
the same as is done with a steering wheel. 
We thus introduce non-linear steering control and semi-
automatic steering control. The direct operation angle and 
automatic steering angle are determined as shown in Fig. 4, 
which illustrates steering control using a foot and ankle. A 
driver operates the steering using the non-linear steering 
control within the direct operation angle. Whereas Wada and 
Kameda used a polyline function for their joystick steering 
control, we use a non-linear function (y = xn). We set n = 3 on 
the basis of our experimental results, which are described in 
Section V. The steering angle increases automatically when it 
is beyond the direct operation angle. The rate of increase 
depends on the speed of the car: the faster the car, the lower the 
rate. The driver can stop a further increase in the steering angle 
by lifting his or her toes (about 20° for the case illustrated in 
Fig. 4). The driver can return the steering angle to the neutral 
position by lowering his or her toes. The drift error is canceled 
by performing this operation while the car is running straight.  
 
E. Sensor attachment and actions 
We measured the car control characteristics for several 
actions: rolling the ankle, moving the forefinger, moving the 
wrist, rolling the lower arm, moving the lower arm backward 
and forward, and moving the upper arm backward and forward. 
The position of the sensor and the motion of each body part are 
as follows. 
[Rolling the ankle] 
We considered using knee turning and knee movement for 
moving the gyro sensor. However, these movements produce a 
narrow movable angle, so we used rolling the ankle. The sensor 
is placed on top of the feet, as shown in Fig. 4. The sensor 
moves when the foot is pivoted right or left on the heel. 
[Moving the forefinger] 
The sensor is placed on the top portion of the top joint of 
the forefinger and is moved as shown in Fig. 5. 
[Moving the wrist] 
The sensor is placed on the back of the hand and is moved 
as shown in Fig. 6. 
[Rolling the lower arm] 
The sensor is placed on the lower arm and is rolled as 
shown in Fig. 7. 
[Moving the lower arm backward and forward] 
The sensor is placed on the back of the lower arm and is 
moved as shown in Fig. 7. 
[Moving the upper arm backward and forward] 
The sensor is placed on the upper arm and is moved as 
shown in Fig. 8. 
 
 
Direct operation
angle
Automatic
steering range
Automatic
steering angle
Sensor
20°
Figure 4. Example of controlling the steering by foot 
474
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
IV. 
DRIVING SIMULATOR 
We evaluated our driving interface by using a driving 
simulator. We used OpenGL [9] as the 3D program interface 
and developed the program using the “glut”, “sdl” [10], “glew”, 
and “OpenAL” tools [11]. The simulated car was operated by 
using a gyro sensor as the steering controller, the brake pedal, 
and the acceleration pedal.  
A. Driving course 
Our ultimate aim is to help disabled people obtain a driver’s 
license, so we designed the driving course on the basis of a 
typical driving school course (Fig. 9). It comprised a 
rectangular outer course, two crank-shaped courses, two S-
shaped courses, and two parallel parking courses. The outer 
course was 300 × 120 m and had a corner radius of 20 m. A 
3.3-m-wide driving lane ran in each direction.   
 
Figure 9. Driving course for simulation 
B. Motions 
Two motions were simulated: gyration and acceleration 
[13]. 
1) Gyration 
A steady gyrating motion was applied to the car under the 
following assumptions. 
- The movement of the car was the broadside motion of 
a rigid body. That is, the car was rigid and free of 
distortion. 
- The speed was constant throughout each curve. 
- The characteristics of the right-side tires were the same 
as those of the left-side tires. 
The radius of the gyrating movement is given by the following 
equation in which V is the running speed and δ is the steering 
angle. 
δ
) 1
1(
CV 2
R
+
=
 
 
 
(1) 
The C is given by the following equation, in which the mass of 
the car is m, the cornering force on the front tires is Kf, that on 
the rear tires is Kr, the wheel base is l, and the distances 
between the car’s center of gravity and the front and rear axles 
are lf and lr. 
r
f
r
r
f
f
K
K
l K
K
l
l
m
C
−
= −
2 2
 
 
(2) 
Each parameter was set to produce driving characteristics 
similar to those of an actual car. The cornering force was 
controlled by adjusting the radius of the gyrating movement: 
the larger the radius, the stronger the cornering force. 
 
2) 
Acceleration 
The acceleration Ac of an actual car depends on the engine 
torque, the transmission gear ratio, the tire radius, the vehicle 
weight, and the engine speed. The engine speed depends on the 
degree to which the accelerator pedal is pressed. 
Air resistance Ra and rolling resistance Rr are considered to 
be the total running resistance. 
2
2
1
SV
C
R
d
a
ρ
=
 
 
 
(3) 
Sensor
 
Figure 5. Moving the forefinger 
 
Sensor
 
Figure 6. Moving the wrist 
 
Sensor
Moving forth 
and back
Rolling right and left
 
Figure 7. Rolling and moving the lower arm 
 
Sensor
 
Figure 8. Moving the upper arm 
475
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

where Cd is the aerodynamic coefficient, ρ is the fluid density 
of the air, and S is the gross surface area of the car.  
 
C mg
R
rr
r =
 
 
 
 
(4) 
 
where m is the mass of the car, Crr is the rolling coefficient, 
and g is the gravitational acceleration. Resultant acceleration A 
is given by 
 
)
(
r
a
c
R
R
A
A
+
−
=
 
 
 
(5) 
 
C. Simulation display 
An example view through the windshield is shown in Fig. 
10. The upper right portion shows the position of the car on the 
course. The operation monitoring tool we developed to 
facilitate operation is shown in Fig. 11. It helps the driver 
recognize the angle of the sensor as the angle of the steering 
wheel and the angle of the toes. It also displays the degree to 
which the accelerator or brake pedal has been pushed.   
 
D. Measured data 
Nine data items were measured. 
1) Steering angle 
2) Running speed 
3) Distance driven and driving time 
4) Position of car on course 
5) Distance between left side of car and left-side lane 
marker line 
6) Distance between right side of car and right-side  lane 
marker line 
7) Degree to which accelerator pedal was pushed 
8) Depth to which brake pedal was pushed 
9) Angle of car relative to driving direction  
V. 
EVALUATION 
A. Steering control 
To analyze performance against the 2nd and 3rd steering 
operation requirements described in Section III-B, we 
calculated the ratio of lane departure (RLD) and the standard 
deviation of the driving gap (SDDG). 
- As illustrated in Fig. 12(a), lane departure means that 
one or more of the tires run on or across a lane marker 
line. RLD is the ratio between the distance driven and 
the distance during which the car departed the lane. 
- As illustrated in Fig. 12(b), the driving gap is the 
distance between the lane center and the car’s center 
line. A value of zero means that the car is centered in 
the lane. SDDG was calculated using the values 
obtained for the car running on a straight portion of the 
course. 
Figure 12. Lane departure and driving gap 
 
Since the first objective of this research is to develop a 
driving interface for arm and finger disabled people, we 
focused on foot-controlled steering, as illustrated in Fig. 4. 
A non-linear function (y = xn) was used to control the 
steering within the direct operation angle. We measured the 
position of car on course and calculated the RLD and SDDG 
for n=1 – 4 in y = xn. We also measured and calculated the 
same data using a steering-wheel-type game controller for 
comparison. The measured and calculated data used for the 
non-linear function are listed in Table I for one of the four 
participants, a person with much experience driving a car using 
his foot with the proposed driving interface. Since the details of 
the experiment by Wada and Kameda were not published, we 
did not compare the performance of our control function with 
theirs. 
We initially thought that a driver could easily operate the 
car by using semi-automatic steering control. However, the 
RLD and SDDG were much worse than with the game 
controller when the direct operation angle was ±15° and the 
corresponding steering wheel angle was ±30°. We observed 
that it was very difficult to drive the car using semi-automatic 
steering control during typical driving maneuvers. As 
illustrated in Fig. 13, neither of the two participants in this 
experiment negotiated the corners of the rectangular outer 
Figure 10. Example view through front window 
 
(Operation monitor)
(Steering wheel)
(Sensor output)
(Brake/Acceration)
Figure 11. Operation monitoring tool 
Departure
No departure
Lane line
Lane line
Car is on the lane line
or over the lane line
+
－
0
Center of lane
Driving gap
 
(a) Lane departure                                   (b) Driving gap 
476
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

course smoothly under those conditions. We concluded that 
semi-automatic steering control is suitable only for parking and 
traversing a crank-shaped course and that non-linear steering 
control is better for typical driving maneuvers. As shown in 
Table I, RLD and SDDG were the smallest for n = 1. But, the 
difference in values between n = 1 and n = 3 is negligible. RLD 
was the smallest for n = 3 during the latter laps, as shown in 
Fig. 14. This means that a driver tends to continue to drive 
longer when n = 3.  
We measured and calculated the same data for three other 
participants (students) for y = x3 (DOA=±20°, SWA±180°) for 
comparison with y = x1 (DOA=±15°, SWA±30°) to see 
whether other drivers showed the same tendencies as 
participant Y. There were four participants in total, but not all 
of them participated in each experiment. The measured and 
calculated data are listed in Table II. The values for “Other” are 
the averages for the other participants. 
TABLE I.  
MEASURED AND CALCULATED DATA FOR NON-LINEAR 
CONTROL FUNCTION 
 
y=x 
y=x2 
y=x3 
y=x4 
y=x 
Game str. 
wheel 
Operating 
body part 
Left feet 
DOA* 
±20° 
±15° 
 
SWA** 
±180° 
±30° 
 
Distance 
driven (m) 
 
791.3 
 
790.9 
 
790.9
 
790.9 
795.4 
790.0 
Ave.  speed 
(km/h) 
26.6 
26.3 
25.5 
27.3 
14.3 
30.4 
RLD (%) 
0.15 
0.38 
0.24 
0.91 
9.8 
0 
SDDG (m) 
0.21 
0.24 
0.27 
0.29 
0.15 
0.11 
*DOA: Direct operation angle 
**SWA: Corresponding steering wheel angle 
TABLE II.  
MEASURED AND CALCULATED DATA FOR MULTIPLE 
PARTICIPANTS 
 
y = x1 
y = x3 
Game str. wheel 
Participant 
Y 
Other 
Y 
Other 
Y 
Other
Operating 
body part 
Left foot 
Hand 
DOA 
±15° 
±20° 
— 
SWA 
±30° 
±180° 
— 
Distance driven 
(m) 
795.4
807.0 
794.3 
791.9 
790.0 
794.5
Ave.  speed 
(km/h) 
14.3
18.3 
28.1 
27.8 
30.4 
33.5 
RLD (%) 
9.8 
52.3 
3.3 
12.5 
0 
2.3 
SDDG (m) 
0.15
1.31 
0.35 
0.46  
0.11 
0.21 
 
Each participant’s RLD and SDDG for y = x3 (DOA=±20°, 
SWA±180°) was better than for y = x1 (DOA=±15°, 
SWA±30°). Example cornering performances for two of the 
participants are shown in Fig. 13. Although every participant 
smoothly traversed the corners when y = x3 (DOA=±20°, 
SWA±180°), none of them achieved driving operation 
comparable to that achieved with a steering wheel. However, it 
should be possible to eliminate the difference and achieve 
operation closer to that with a steering wheel through more 
practice and experience. 
 We calculated the RLD for the crank- and S-shaped 
courses for four participants as well. The measured and 
calculated data are listed in Table III. The values are the 
averages for them. Traversing the crank- and S-shaped course 
was more difficult than traversing the rectangular course. The 
driver had to use both non-linear and semi-automatic steering 
control. Driving performance for these two courses differed 
greatly. As shown in Figs. 15 and 16, the performance of 
participant D was very close to that with the game steering 
wheel while that of participant C substantially diverged from it. 
This indicates that performance with the proposed steering 
operation interface should approach that with a steering wheel 
as the amount of practice and experience increases. 
TABLE III.  
MEASURED AND CALCULATED DATA FOR CRANK- AND S-
SHAPED COURSE 
 
Crank-shaped course 
S-shaped course 
Operation device 
Game 
wheel 
Sensor 
Game 
wheel 
Sensor 
DOA 
±20° 
SWA 
±180° 
Cont. function 
y = n3 and semi-automatic steering control 
Distance driven (m)
79.9 
78.2 
123.6 
125.8 
Ave. speed 
(km/h) 
9.7 
8.3 
15.0 
12.9 
RLD-Ave. (%) 
17.2 
22.9 
8.9 
16.8 
RLD-Max. (%) 
26.6 
42.8 
21.2 
40.8 
RLD-Min. (%) 
6.6 
8.5 
0 
1.2 
 
y = x1
(DOA=±15°, SWA±30°)
y = x3
(DOA=±20°, SWA±180°)
Participant
A
Participant
B
 
Figure 13. Cornering performance for participants A and B 
0.00%
0.50%
1.00%
1.50%
2.00%
2.50%
3.00%
3.50%
1
2
3
4
5
6
7
8
9
10
n=1
n=2
n=3
n=4
Number of laps
RLD
 
Figure 14. RLD against no. of laps 
477
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
B. Results by body part 
To examine the applicability of the proposed driving 
interface to various types of disabilities, we measured and 
calculated the RLD and SDDG for steering control using the 
forefinger, the wrist, the lower arm, the upper arm, and the 
foot. The data measured for participant Y are listed in Table 
IV. The movements are illustrated in Figs. 5–8. The RLDs and 
the SDDGs for each body part were roughly the same except 
for the upper arm. The data for the upper arm was the worst 
because it is difficult to precisely move the upper arm (and 
shoulder). Although the forefinger had the largest DOA, its 
RLD was worse than that for the foot. The reason is that it is 
too easy to move the finger. An adapter might be useful in 
achieving steady forefinger movement. 
 
TABLE IV.  
MEASURED AND CALCULATED DATA BY BODY PART 
 
Fore-
finger 
Wrist 
Lower 
arm 1*
Lower 
arm 2* 
Upper 
arm 
Foot 
DOA 
±70° 
±50° 
±40° 
±40° 
±40° 
±20° 
SWA 
±180° 
Cont. function 
y = n3 
Distance 
driven (m) 
791.0 
791.3 
791.3 
792.0 
796.0 
794.3
Ave.  speed 
(km/h) 
26.3 
26.0 
26.0 
28.4 
24.8 
28.1 
RLD (%) 
3.8 
3.2 
4.7 
4.2 
17.6 
3.3 
SDDG (m) 
0.35 
0.26 
0.26 
0.26  
0.33 
0.35 
*Lower arm 1: Moving lower arm forward and backward 
*Lower arm 2: Rolling lower arm right and left. 
 
VI. 
CONCLUSION 
Our proposed steering operation interface for disabled 
people uses gesture operation. It incorporates both non-linear 
and semi-automatic steering control. Simulation experiments 
using foot control and a gyro sensor showed that semi-
automatic steering control is suitable only for parking and 
traversing a crank- or s-shaped course and that non-linear 
steering control is better for typical driving maneuvers. The 
driving operation for each body part except for the upper arm 
was close to that achieved with a steering wheel. More practice 
in using the proposed interface should enable a user to achieve 
steering control closer to that with a steering wheel. 
We plan to develop a prototype control device using a 
strain gauge instead of a gyro sensor and evaluate its driving 
operation for many participants. We also plan to evaluate our 
proposed interface in an actual car. 
REFERENCES 
[1] Development of Honda's Franz System Car; 
http://world.honda.com/history/challenge/1982franzsystemcar/index.html, 
January 2013. 
[2] Joystick Driving System: allows wheelchair users to drive a car; 
 
http://www.itechdiary.com/joystick-driving-system-allows-wheelchair-
users-to-drive-a-car.html, January 2013. 
[3] Masayoshi Wada, Fujio Kameda, “A joystick car drive system with 
seating in a wheelchair”, IEEE IECON ’09, pp. 2163-2168, November 
2009. 
[4] FORUM8 Air Driving and RoboCar 
http://www.youtube.com/watch?v=LMr2dyfAzl0, January 2013. 
[5] A.S.M. Mahfujur Rahman, Jamal Saboune, Abdulmotaleb El Saddik, 
“Motion-path based in car gesture control of the multimedia devices,” 
ACM DIVANet '11, Proceedings of the first ACM international 
symposium on Design and analysis of intelligent vehicular networks and 
applications, pp.69-75, November 2011. 
[6] Tanja Döring, Dagmar Kern, Paul Marshall, Max Pfeiffer, Johannes 
Schöning, Volker Gruhn, Albrecht Schmidt, “Gestural interaction on the 
steering wheel: reducing the visual demand,” ACM CHI '11, Proceedings 
of the 2011 annual conference on Human factors in computing systems, 
pp.483-492, May 2011. 
[7] Yoshitoshi Murata, Nobuyoshi Sato, Tsuyoshi Takayama, Shinetsu 
Onodera, “A Gesture-based Remote Control for Finger Disabled People”, 
IEEE, GCCE 2012, pp.411-415, October  2012. 
[8] Samsung SMART-TV,  
http://www.samsung.com/us/2012-smart-tv/, January 2013. 
[9] 
OpenGL – The Industry Standard for High Performance Graphics,  
http://www.opengl.org/, January 2013. 
[10] Simple DirectMedia Layer, http://www.libsdl.org/, January 2013. 
[11] Home – OpenAL, http://connect.creativelabs.com/openal/default.aspx, 
January 2013 
[12] Masato 
Abe, “Automotive Vehicle 
Dynamics 
- 
Theory and 
Applications,” Tokyo Denki University Press, (2008). 
[13] Giancalro Genta, “We apply the steady gyrating movement to a car under 
following assumptions,” World Scientific Publishing, 1997 
‐55
‐45
‐35
‐25
‐55
‐45
‐35
‐25
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
‐55
‐45
‐35
‐25
‐55
‐45
‐35
‐25
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
Participant C
Participant D
Figure 15. Crank-shaped course performance for participants C and D 
 
‐40
‐30
‐20
‐10
25
35
45
55
65
75
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
Participant C
Participant D
‐40
‐30
‐20
‐10
25
35
45
55
65
75
Y axis
X axis
1st lap
2nd lap
3rd lap
Game steering wheel
Figure 16. S-shaped course performance for participants C and D 
478
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

