An Error Analysis Model for Adaptive Deformation Simulation
Umut Koc¸ak, Karljohan Lundin Palmerius, and Matthew Cooper
C-Research
Link¨oping University, ITN
Norrk¨oping, SWEDEN
Email: umut.kocak@liu.se, karljohan.lundin.palmerius@liu.se, matthew.cooper@liu.se
Abstract—With the widespread use of deformation sim-
ulations in medical applications, the realism of the force
feedback has become an important issue. In order to reach
real-time performance with sufﬁcient realism the approach
of adaptivity, solution of different parts of the system with
different resolutions and refresh rates, has been commonly
deployed. The change in accuracy resulting from the use of
adaptivity, however, has been been paid scant attention in the
deformation simulation ﬁeld. Presentation of error metrics is
rare, while more focus is given to the real-time stability. We
propose an abstract pipeline to perform error analysis for
different types of deformation techniques which can consider
different simulation parameters. A case study is also performed
using the pipeline, and the various uses of the error estimation
are discussed.
Keywords-physically
based;
deformation;
multi-resolution;
perception; error; analysis.
I. INTRODUCTION
The integration of haptics, the sense of touch, in human
computer interaction has increased the immersion effect
of virtual environments. Haptics has been used to serve
different aims such as guidance, visualization, and realism
in various computer applications. Considering the growing
use of haptics in medical applications, such as in virtual
simulations for training and rehearsal purposes, the degree
of realism has become a crucial issue.
Achieving a compromise between realism and stability
has always been a major challenge in haptics, especially for
deformable objects. High refresh rates (1 kHz) are necessary
to achieve a stable and continuous force feedback, while
solution of the physical models with desired resolutions
comes with a heavy computational burden. Adaptive mul-
tiresolution techniques have been among the most popular
methods proposed to achieve desired refresh rates with
required resolution. A major problem with this approach,
however, has been a lack of focus on the reduced realism
due to the error introduced by adaptivity, and the lack of
standard error metrics.
In the literature it can be seen that consideration of the
error is usually superseded by stability concerns but there
are some error estimation techniques, widely studied in the
context of Finite Element Methods (FEM) (e.g., [1], [2],
[3], [4]), and adaptive studies [5] suitable for real-time use.
Exploiting such methods to choose optimal solutions which
minimize error while maintaining sufﬁcient performance to
ensure stability would be beneﬁcial. The common approach
in the real-time deformation simulation ﬁeld, however, is
simply to include the maximum number of nodes which
can be solved in real-time while keeping the simulation
stable. Presentation of numerical values for the element
sizes, time-steps and how they affect the accuracy is rare,
however. One possible reason is the fact that estimating
an error is not a trivial process, especially for adaptive
simulations which vary parameters in real-time. In addition
to deciding which parameter to consider (strain, stress, force)
for error estimation, one also has to choose a reference.
Therefore presentation of the numerical values without any
error analysis is usually avoided in the literature.
In this study, we propose a pipeline used to analyze force
feedback error caused by adaptive solution of deformation
simulation. The idea depends on creating an ofﬂine error
mapping of a deformation model for a set of parameters such
as user inputs, material properties and adaptivity parameters.
The potential uses of the ofﬂine error mapping include: (1)
surveying correlations between error and parameters, (2)
real-time quality assessment, and (3) real-time parameter
adjustment to keep the error below some desired limits. The
pipeline is applied in a case study by performing experiments
in the simulation environment.
The outline of the paper is as follows: related work
and theoretical background are presented in the second and
third sections, respectively. The motivation for the work is
discussed in the fourth section, followed by the explanation
and the case study of the pipeline in the ﬁfth and the sixth
sections. The conclusions are presented in the ﬁnal section
of the paper.
II. RELATED WORK
The main challenge in deformation simulation is reaching
sufﬁcient realism while maintaining the desired refresh rates.
There are a variety of different deformation models and
optimization techniques available. Among the deformation
models, FEM is commonly considered to provide the most
realistic behaviour and so, despite the substantial computa-
tional load it incurs, is the focus of most optimization and
error analysis studies. In this section studies about adaptivity
applied to FEM and the error analysis are summarized.
192
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

A common technique to achieve sufﬁcient performance
while retaining required realism around the point of contact
is adaptivity. There are several approaches (for example [5],
[6], [7]) which exploit adaptive spatial multiresolution mod-
els to keep the accuracy higher around the contact point
while reducing computational load in the less precisely
modelled parts.
Despite this frequent use of adaptive element size and
time-step, the effects of such approaches on the perceived
force feedback have not been comprehensively surveyed.
The common method in real-time applications is, if error is
considered at all, to use an error measure for each element
and adapt the element size and the time-step for elements.
The error estimation has, however, been more thoroughly
studied in FEM (i.e, [1], [2], [3], [4]) although the real-time
aspect is not, generally, as important there. Designing an
‘ideal-error-estimator-solution’ which is reliable and sufﬁ-
ciently computationally inexpensive that it can be used in
real-time is an unsolved issue, as discussed in [3].
In this study, we propose a general pipeline to analyze
the behaviour of the force error with respect to the level
of detail in both time and spatial domains. The direct
relationship between the force response and the solution of
the whole model with different frequencies was presented
in [8] for mass-spring models. In the pipeline we propose,
the error can be analyzed for different deformation models
and different parameters, such as material properties, and
input types. An analysis of the error for a special case is
also presented.
III. BACKGROUND: STABILITY AND ACCURACY
The deformation simulation on a mesh depends on dis-
cretizing a continuous domain into elements. In addition,
the iterative solution of the resulting differential equations
depends on discrete time-steps. There are two main issues
to be considered in the discretization: stability and accuracy.
The adjustment of element size and and time-step includes a
compromise between these two concepts, therefore adaptive
simulations should take these two concepts into consid-
eration in real-time. Keeping the simulation stable means
having a deformation model which always converges to the
result. The accuracy, on the other hand, affects the error in
the deformation.
A. Stability
The deployment of iterative solvers is generally preferred
over analytical ones in deformation simulation because of
their superior speed. The iteration process requires the
choice of a time-step, which affects the accuracy and stabil-
ity of the simulation. The two main categories of iterative
solvers, implicit and explicit, have different behaviour in
terms of stability. Implicit solvers are unconditionally stable,
which means that the solution converges to the ﬁnal value no
matter how large the time-step. On the other hand, the time-
step is limited in the case of explicit solvers, where having an
eigenvalue of greater than 1 in the stiffness matrix will result
in divergence. The time-step limit depends on the maximum
natural frequency which, in turn, depends on the material
properties and the element size. The time-step limit can be
physically interpreted to be that it must be small enough that
no information propagates more than one mesh element per
step. To achieve stability it is therefore necessary to consider
the time-step and the element size together.
B. Accuracy
Increasing the time-step results in increasing error. In
the case where a single ordinary differential equation is
considered, the time-step is crucially important to achieve
acceptable accuracy. In the case of a large number of
differential equations, however, keeping the time-step just
under the stability limit provides sufﬁcient accuracy. The
reason for this is the fact that a stiff system of differential
equations covers a wide spectrum of natural frequencies.
The stability limit is evaluated with respect to the highest
frequency of the system. Therefore for a time-step which
is close to the critical stability time-step limit, the response
of the model for the highest frequencies will not have high
accuracy. Fortunately, the structural response of the objects
is dominated by much lower frequencies which are sufﬁ-
ciently more accurate for the chosen time-step. Therefore,
for explicit solutions of a large number of equations, the
accuracy is not an issue as long as the stability condition is
satisﬁed [9].
The discretization in the spatial domain is another factor
affecting accuracy. For instance, in case of FEM, the type,
shape and size of the elements also play a role in the
accuracy. Once the shape of the element is chosen, the
order of the polynomial used to calculate the shape functions
of the element can also vary. While increasing the order
results in higher accuracy, using lower orders is common
in real-time applications because of its drastic effect on the
stability condition. The error of a quantity is of the order
of O(hp+1−m) [10]; where h is the element size, p is the
degree of the polynomial used to calculate shape functions,
and m is the order of the highest derivative in the governing
equilibrium equation expressed in terms of displacements.
IV. MOTIVATION
The common approach followed in deformation simula-
tions is to choose the maximum time-step which guarantees
stability for a given mesh resolution. As long as the sta-
bility conditions are satisﬁed, the accuracy criteria are also
satisﬁed for large deformable meshes, as discussed in the
previous section. It is not only the time-step but also the
element size which affects the accuracy of the deformation
behaviour. In real-time deformation simulation studies, it is
usually considered to be sufﬁcient to include the number
193
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

of nodes required for the mesh to be solved stably. The
presentation of numerical values for the element sizes and
how they affect the accuracy, however, is rare in this ﬁeld.
Another issue which has been largely ignored in adaptive
haptic applications where both the resolution and time-step
are adjusted in real-time, is the potential to exploit the
perception limits of human beings for optimization purposes.
There have been numerous studies which have surveyed the
different human perception limits but ways to exploit these
limitations in hardware and software solutions are rarely
explored. The research (for example [11], [12]) shows that
there are just-noticeable-differences in force magnitude and
in force direction. The threshold for force magnitude has
been found to be around 7% in [11]. Similarly, the average
force direction discrimination thresholds are 18, 26, and 32
degrees, depending on the accompanying visual input [12].
One could exploit these thresholds to save computational
power by simplifying the force calculation while ensuring
that the error in the force remains below the limit of
perceivability.
In this work we propose a pipeline which analyzes the
error due to the various parameters, including adaptivity
parameters, and deploys a mechanism, without additional
computational burden, to control the simulation parameters
in real-time, according to the error criteria.
V. PERCEPTUAL ADJUSTMENT MODEL
In order to introduce the facility to adjust the computa-
tional complexity without perturbing the user’s perception of
the represented forces it is necessary to examine the explicit
correlation between force error and parameters, assessing
quality of simulation at run-time, and adjusting adaptivity
parameters to maintain the error under desired limits. The
abstract pipeline is explained in this section while a case
study performed by experiments is presented in the next
section.
A. Error Identiﬁcation Principle
Achieving exact solution in real life scenarios is very
rare for deformation simulations. There are several steps
in the process contributing to the error, such as modelling,
discretization and numerical errors. The pipeline proposed
in this study focuses on the error caused by the deployment
of adaptivity with varying element sizes and time steps in
the simulation. In addition, a so-called goal-oriented [3]
approach is followed by analysing the force feedback error
of a contact node. In other words, the error considered in
this model refers to the force error introduced by varying
element sizes and time-steps while one must keep in mind
the other contributions to the total error. For a given mesh
and deformation model, the solution for the whole mesh with
the highest resolution, and with a sufﬁciently low enough
time-step to maintain stability, is considered as a ‘reference’
force with no error.
B. Ofﬂine Error Characterization
The idea of calculating an ofﬂine error mapping depends
upon applying Monte Carlo simulation for a set of param-
eters to obtain a force feedback value for each sample.
One needs to maintain stability while varying the tested
parameters in a reasonably wide range. To maintain stability,
the time-step needs to be smaller than a critical time-step
which depends on a number of parameters including the
element size, elasticity, mass and poisson ratio. This causes
different stability behaviour in the simulation for different
materials. The choice of time-step for real-time solutions
is also dependent on the computational power available and
the number of nodes required. Considering the limitations on
the time-step and its effects on the range of parameters to be
tested, ofﬂine deformation solutions are preferred to create
the error mapping. This allows the exploration of time-steps
decoupled from the limits imposed on computational power
and number of nodes in addition to maintaining the stability
for a wide range of parameters for a given time-step.
The idea of ofﬂine error mapping is illustrated in Figure 1.
The pipeline uses a number of types of input parameters to
a chosen deformation model and creates an error mapping
speciﬁc to these parameters which can be categorized as
user input, material properties and adaptive simulation pa-
rameters. The amount of strain, input frequency, and choice
of contact node can be named as examples of user input.
The material properties include the physical properties of
the object such as elasticity, mass, poisson ratio, or damping,
while the deformation model can be any deformation algo-
rithm such as FEM, mass-spring etc. The adaptive simulation
parameters include the distribution of element sizes and time
steps throughout the mesh.
The ﬁrst step in creating the error mapping is an ofﬂine
evaluation of the reference force explained in Section V-A
for a range of user input and material properties parameters.
The force feedback is then calculated again for the same
set of parameters but deploying adaptivity with varying ele-
ment sizes and time-steps. The force feedback obtained by
deploying adaptivity for this set of parameters is compared
with the corresponding reference force, evaluated without
adaptivity, to calculate the error. This procedure applied to
a speciﬁc case is explained in more detail in Section VI-C.
C. The Uses of Error Mapping
One of the potential uses of an error mapping is surveying
explicit correlation between force error caused by adaptivity
and material or input parameters. This might be used to
gain more insight about the effects of adaptivity for different
deformation models and materials leading to better choices
of algorithms for different types of applications. Another use
would be assessing quality of simulation at run-time without
a major computational burden. Since the error mapping has
been pre-calculated ofﬂine, the only extra work introduced
is to ﬁnd the corresponding error in real-time, by using a
194
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

Figure 1.
The ofﬂine error mapping procedure: The user input, material
properties and adaptive simulation parameters are given as input to the
deformation model. The force feedback for each trial is compared with the
solution of the whole object with highest resolution and an error mapping
is created for each trial.
Figure 2.
The online error assessment and quality adjustment: For a given
set of material properties, adaptive simulation parameters and user input,
the error mapping is used to determine the current error. This can either
be used purely for quality assessment purposes or the adaptive simulation
parameters can be fed back to the deformation model at run-time aiming
for a compromise between target error value and stability.
lookup table, as described in the results section. Figure 2
illustrates the online uses of the error mapping. In addition to
just evaluating the current error for assessment purposes, the
adaptive simulation parameters can be adjusted and fed back
to the deformation model in order to to maintain the error
under desired limits. This real-time adjustment, however,
has to consider the stability issues which are coupled with
the available computational power to achieve a compromise
between error and stability. In the event that both constraints
cannot be simultaneously met during real-time use, the
system must ensure that stability is retained while recording
the fact that the error limitations have been exceeded and,
perhaps, informing the user that this failure has occurred.
VI. EXPERIMENTS
Experiments have been performed to apply the abstract
pipeline proposed to a speciﬁc scenario for a chosen de-
formation model and a set of parameters. We foresee no
obstacles to applying the same principles and performing
a more elaborate analysis by extending the number of
parameters.
Linear FEM, where performance is a less serious con-
cern compared with non-linear FEM, was chosen as the
deformation model. The adaptive solutions, however, are
still needed for larger numbers of nodes even for linear
FEM. Considering the deformation characteristics in real
life situations, complex properties such as viscoelasticity
Figure 3.
The allocation of asynchronous regions in the object. Different
regions have different mesh resolutions in addition to being solved with
different time-steps. The primary region (local neighbourhood of the
contact) is shown with red, and the secondary regions are shown in green
and blue.
and anisotropy are also commonly observed in addition
to non-linearity. The error analysis for tissue deformation
is, therefore, a non-trivial process which needs to consider
different physical properties. The reason we chose the linear
FEM is to make the proof of concept of the pipeline in a
relatively simpler model, and analyze more complex models
as future work. Clearly the structure of the pipeline presents
no obstacles to either changing the deformation model or
extending the set of parameters.
A. Deformation Model
A dynamic linear ﬁnite element model with a cubic
element is used. The simulation time is discretized into time-
steps to evaluate the numerical integration of (1):
M¨u + C ˙u + Ku = f
(1)
where the stiffness, mass and damping matrices are repre-
sented by K, M, and C respectively, while u, ˙u, ¨u and f refer
to displacement, velocity, acceleration and force vectors. The
mass matrix is diagonalized and a constant damping for each
node is used. The reader is encouraged to see [10] for further
details of the ﬁnite element method.
B. Parameters
Adaptive Simulation Parameters: There are different
ways to implement adaptive deformation (for example [5],
[13]). In our framework the deformation is calculated with
different resolutions and at different update rates for dif-
ferent regions of the object. The local neighbourhood of
the contact point maintains higher resolution and smaller
time-steps than the more remote regions, illustrated in
Figure 3. The corresponding FEM equations for different
regions are solved asynchronously with different time-steps
and resolutions. The regions, therefore, are referred to as
asynchronous regions. Throughout the rest of the paper
the local neighbourhood of the contact node, having the
highest frequency, will be referred as the primary region
and the others as the secondary regions. The framework
used allows real-time adaptation of regions and their sizes
195
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

as the nature of the contact is changed. The details of
the implementation, however, are out of the scope of this
study and the reader can see different examples of adaptive
simulations (for example [5], [13]) for further details.
In this system, the force at the contact node depends on
the resolutions, time steps and the sizes of the regions. Two
asynchronous regions have been employed throughout the
experiments presented here. The primary region’s spatial
and time resolution has been ﬁxed for all experiment sets.
The spatial resolution (2.5 cm) has been chosen to be the
highest resolution used during the reference force calculation
without adaptivity and the time-step has been kept at 1 kHz
throughout for the primary region.
The secondary region frequency is one of the parameters
being varied using rates of 1 kHz, 900, 800, 700, and
600 Hz. The use of lower time-steps was possible for some
of the data sets, however not for all. For a given resolution,
for instance, the refresh rates need to be higher for more
stiff materials, or lower mass densities. In order to be able
to analyze a wider range of parameters, higher stiffness
or lower mass densities, with the same frequency values
the refresh rates were chosen to be high. As explained in
Section III-B, the accuracy is not affected by the time-step
as long as the stability criteria are met. This is also observed
in the results showing that the frequency does not affect the
error. The choice of high refresh rates to cover a wider range
of material properties therefore has no effect on the error
analysis.
The resolution of the the secondary region is another
parameter under consideration and has been varied over
multiples of the primary region resolution which are 1×,
2×, and 3 × 2.5 cm.
The third parameter surveyed is the size of the primary
region. The size has been measured as the number of nodes
in all directions from the contact node homogeneously and
changed between 1, 2, 3 and 4 in three dimensions. To
illustrate, a region with value of 1 as size includes 3×3×3
nodes in three dimensions, including the contact node.
User Input:
To apply a deformation to the model, a simulated haptic
device was used allowing the application of a precise and
reproducible input. While it is possible to apply deformation
to a chosen set of contact nodes, the deformation was applied
to a ﬁxed contact node throughout the experiments. Two
parameters have been changed for the deformation applied:
Strain and frequency. To obtain a realistic response from
linear FEM the maximum amount of strain applied has been
kept limited, typically to less than 10% [14] of the mesh
size. The amount of strain has been chosen to be 0.5, 1.0
or 1.5 cm. The frequency of the input has been changed
between 0.5, 1.0 and 1.25 Hz.
Material Properties: Physical properties like elasticity,
mass, damping and poisson ratio have been varied during
the experiments. The ranges have been chosen according
Figure 4.
The experiments have been performed with a cube composed
of 13 × 13 × 13 nodes. The deformation is shown on the right half side
of the ﬁgure.
to the soft tissue properties described in the literature.
The elasticity values measured in the different studies are:
between 5 and 35 kPa in [15], 6 and 11 kPa in [16], 0 and
3.5 kPa in [17]. The differences between the results of the
studies mentioned are due to the tissue type, the magnitude
of deformation, the non-linear behaviour of the elasticity
and the level of precompression as discussed in [18]. Con-
sequently, the elasticity has been set to 5, 10, 15 and 20 kPa
in the experiments. The mass density has been found to be
1 g/cm3 in [19] and was set to 0.8, 1.0 and 1.2 g/cm3 for the
experiments. Measurement and modelling of the damping
for soft tissue is non-trivial since the coefﬁcient depends
on stress level [9] and vibration frequency. The damping
for a human thigh has been measured for different applied
force magnitudes and frequencies and angles of ﬂexion of
the knee in [20]. The damping varies between 7 and 102 s−1
for a force applied normal to the skin. The response of the
deformation behaviour in pilot studies was also considered
while deciding the damping values and they were set to 10,
20, 30 and 40 s−1 during the experiments. Poisson ratios
of both fat and muscle tissue have been measured to be
approximately 0.49 in [21] and have been set to 0.40, 0.45
and 0.49 for the experiments.
C. Procedure
A deformation is applied to the model by a simulated
haptic device which provides a precise and reproducible
input. A reference force is evaluated at the contact node
by solving the whole mesh without any adaptivity. The
same input is then applied by employing two asynchronous
regions with varying parameters. The force responses of the
asynchronous regions are compared to the reference force to
obtain an error value. This procedure is repeated for the full
set of ranges of material user input and material parameters.
A cube, shown in Figure 4, with edge length of 25 cm
and 13×13×13 nodes is used for the experiments. The four
corner nodes on the back face are ﬁxed and input is applied
to the middle node on the front face. For deformation, an
explicit central-difference solver is employed with cubic
ﬁnite element type together with linear FEM.
196
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

Figure 5.
Parallel coordinates allow restriction of some parameters in
order to observe the effects of the others. The use of colours enables
the observation of how each parameter affects the error. In this case the
material properties other than poisson ratio, resolution of secondary region
and primary region size are ﬁxed, and colours are used to distinguish the
effect of poisson ratio on the error. The right-most axis is error and the
left-most the poisson ratio. The colours identify three different levels of
poisson ratio.
D. Results
The error mapping obtained can be used to analyze
the effect of each parameter on the force, seperately. The
correlations between the error and the individual parameters
are presented in this subsection. A data set consisting of
62208 sample points has been obtained by a Monte Carlo
simulation. After elimination of the divergent sets, the num-
ber was reduced to 54083 samples. Visualization techniques
and statistical tests have been used to analyze the data.
Parallel coordinates, as illustrated in Fig. 5, are used to
visualize the effect of each variable on the force. The use
of parallel coordinates allows the user to keep all of the
parameters but one ﬁxed or restricted so that the effects of
the free parameter on the error can be observed. Parallel
coordinates provide a general picture of how the error is
affected by each parameter. However, to convey a quantiﬁed
measurement between the error and the parameters, statisti-
cal tests can be performed. Two different partial correlation
tests have been carried out.
To observe how the error is affected by a single parameter,
eliminating the effects of the other parameters, two common
partial correlation tests are applied. Table I illustrates the
correlation coefﬁcients of error and the p-values for each
parameter obtained by the Pearson and Spearman tests. The
former is suitable for linear relations and assumes normal
gaussian distribution for each variable. Since the ranges used
during the experiments do not meet the gaussian distribution
requirement, and the linearity of the relations cannot be
known in advance, the Spearman test is more suitable for the
data. If the Spearman parameter is larger than the Pearson in
absolute value, however, one can conclude that the variables
are consistently correlated but not in a linear fashion. The
correlation coefﬁcient varies between -1 and 1. The higher
the absolute value of the coefﬁcient the more correlated the
parameters are with the error. To determine the signiﬁcance
of covariance, a t-test with a conﬁdence level of 95% is
typically applied, the p-values of which are also presented in
Table I
THE PARTIAL CORRELATION BETWEEN ERROR AND THE PARAMETERS
Error Correlation
Pearson
Spearman
Coefﬁcient
p
Coefﬁcient
p
Poisson Ratio
0.5837
0
0.5488
0
Mass
0.0166
0.0001
0.0053
0.2152
Damping
0.0216
0
-0.1691
0
Elasticity
0.4746
0
0.2712
0
Input Strain
0.4377
0
0.158
0
Input Frequency
0.0119
0.0058
-0.1244
0
Level of Detail
0.4582
0
0.7033
0
Pr. Reg. Size
-0.5624
0
-0.6243
0
Sec. Reg. Freq.
-0.0015
0.7354
0.0003
0.9403
Force
-0.5073
0
-0.1827
0
Table I. P-values below 0.05 can be interpreted as indicating
that the correlation is very unlikely to be different from zero
by chance. The correlation coefﬁcients are interpreted as
small between 0.0 and 0.1, medium between 0.1 and 0.3,
and large between 0.5 and 1.0 [22].
For the scenario considered in these experiments, the
analysis of the correlation indicates the following. Amongst
the material properties, the poisson ratio is the one most
correlated with the error with a p-value of < 0.01. Increasing
the poisson ratio causes the error to increase signiﬁcantly.
One cannot say the same for the mass from the p-value.
Therefore parallel coordinates are used to manually check
the relationship between the mass and the error, and it can
be said that no visually observable signiﬁcant change occurs
in error due to changing mass. The elasticity has a positive,
and the damping has a negative correlation with the error,
but neither is as strong as that of the poisson ratio.
Of the input parameters, frequency and strain show neg-
ative and positive correlation, respectively. The strength of
the correlations are not, however, signiﬁcant and they can
be grouped into medium correlation.
One can see the high positive and negative correlation
with the element size of the secondary region and the
primary region size, respectively. Both correlations can be
said to be nonlinear since the Spearman coefﬁcient is larger
than the Pearson. The refresh rate of the secondary region
has no correlation with the error. This can be explained by
the fact that, as explained in Section III-B, a small enough
time-step for stability also satisﬁes the accuracy criteria as
long as the solution system is stiff enough [9].
E. The Real-Time Uses of Error Mapping
The error mapping can be used to determine the force
error in real-time. This can allow some simulation param-
eters to be adjusted to keep the error below limits such
as those set by human perception. The adaptive simulation
parameters, such as element size and time-steps, can be
197
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

adjusted depending on the error. The material properties
are measured physical values and the input parameters
are determined by the user. These two should be used in
obtaining the real-time error from the mapping rather than
being adjusted to achieve a desired error.
Real-time determination of the error from the error map-
ping might be non-trivial and depends on how the mapping
is obtained. A look-up table, as shown in Table II, is
then used to determine the error for the current parameters
and simulation state. Some issues such as continuously
varying input frequency, heterogeneous material properties
or changing contact node might require special solutions
during the error mapping lookup phase.
The real-time measurement of input frequency may not be
practical, instead one can exploit the fact that human beings
have limited bandwidth while touching objects. An upper
bound for a force control was found to be 25 Hz in [23] and
20 Hz in [24]. From the human output perspective 10 Hz is
considered to be more than sufﬁcient according to [25]. For
the presented error mapping in the example, the lowest input
frequency results in the highest error. Therefore the lowest
frequency can be considered to determine a maximum bound
for the effect of input frequency on the error.
Another issue is the deformation of objects with hetero-
geneous material properties making the use of a look-up
table non-trivial. One alternative to address this problem is to
check the material properties within a local neighbourhood
and consider the combination of material properties with
the highest error in the neighbourhood. For example consid-
ering the maximum elasticity, poisson ratio and minimum
damping will ensure the error constraint is on the safe side
by assuming the worst case scenario. Another alternative,
which is less safe, would be to take average of each material
property within the local neighbourhood to determine error.
The limitation of this technique is the existence of rigid sub-
objects, the effects of which on asynchronous regions will
be explored in future studies.
The number of contacts considered during the creation of
the error mapping determines how elaborate the mapping is.
Creating an error mapping for each node in the mesh can be
quite expensive. A mapping with few nodes and real-time
interpolation of the error between these nodes provides an
error value for each node of the mesh.
VII. CONCLUSIONS AND FUTURE WORK
In this study, we have proposed a pipeline to survey the
varying accuracy of the force feedback due to adaptivity with
respect to a number of parameters of a deformation model.
First, an error mapping with respect to certain number of
parameters, including user inputs, material properties and
adaptive simulation parameters is created. The deformation
is ﬁrst solved off-line for the whole object with the highest
resolution mesh and the force response saved as a reference.
The adaptivity is then employed with different parameters
Table II
THE LOOK-UP TABLE FOR THE ERROR
Material Prop.
Applied Input
Asynch. Reg.
P.R.
M
D
E
Strain
Freq.
Lod
Pr.Reg
Err
0.49
0.8
10
5000
0.005
0.5
2
1
56.7
0.49
0.8
10
5000
0.005
0.5
2
2
15.7
0.49
0.8
10
5000
0.005
0.5
2
3
8
0.49
0.8
10
5000
0.005
0.5
2
4
1.6
0.49
0.8
10
5000
0.005
0.5
3
1
66.7
0.49
0.8
10
5000
0.005
0.5
3
2
60.4
0.49
0.8
10
5000
0.005
0.5
3
3
6.8
0.49
0.8
10
5000
0.005
0.5
3
4
4.1
0.49
0.8
10
5000
0.005
1.0
2
1
60
and the force output is compared with the reference force to
estimate an error for the given parameters. This procedure is
repeated for a range of different material properties, and user
inputs. In addition to providing an error measure without any
serious real-time computational burden, the ofﬂine solution
of the deformation decouples computational power from the
stability requirement. The whole stable range of parameters
for a given deformation model can, therefore, be solved
ofﬂine and conveyed through the error mapping.
The error mapping obtained ofﬂine can be used to survey
the correlation between force error and material properties,
user input and adaptive simulation parameters. One can
compare how different deformation models, such as linear
FEM, non-linear FEM, or mass-spring are affected by adap-
tivity. This exploration has the potential to help in choosing
algorithms and adaptivity parameters for different types of
application. At run-time the quality of the force feedback can
be continuously monitored with the help of error mapping,
allowing the adaptive parameters to be adjusted to keep the
error below the desired limits while maintaining stability.
Experiments have been performed on an example applica-
tion of the proposed pipeline. The error mapping was created
for a linear FEM. Material properties such as elasticity, mass
density, damping, poisson ratio and user input parameters
like strain, input frequency have been changed in addition
to adaptive simulation properties. Observed correlations be-
tween the error and the input parameters have been presented
and an example use of a look-up table for error mapping in
real-time was proposed.
One must keep in mind that the example presented in
the experiments section is a special case of the pipeline
proposed in this study. In real life situations, more complex
material properties such as nonlinearity, viscoelasticity, or
anisotropy are commonly observed. Consequently achieving
an ideal error estimation is non-trivial [3] in deformation
simulation. We used a linear FEM to visualize an application
of the pipeline because of its relatively simple structure. The
possible challenges that might occur during the real-time
use of the error mappings for models exhibiting material
inhomogeneity, interpolation of error for contact nodes, and
corresponding solutions have also been discussed.
198
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

In future work we will study the pipeline with alternative
parameters and deformation models. The effect of different
contact nodes, shapes, the use of mapping for heterogeneous
materials, nonlinearity, and viscoelasticity can be named
among the concepts to be surveyed. A user-centred study
employing the error mapping with just noticeable differences
will be very interesting to study in the subsequent phases.
ACKNOWLEDGMENTS
We thank Camilla Forsell for her help with the statistical
analysis applied in this work. This work has been funded
by the Swedish Science Council through grant number 621-
2005-3609, the Foundation for Strategic Research (SSF) un-
der the Strategic Research Center MOVIII, and the Swedish
Research Council Linnaeus Center CADICS.
REFERENCES
[1] M. Bercovier and O. Pironneau, “Error estimates for ﬁnite
element method solution of the stokes problem in the primi-
tive variables,” Numerische Mathematik, vol. 33, pp. 211–224,
1979.
[2] E. Rank and O.C. Zienkiewicz, “A simple error estimator
in the ﬁnite element method,” Communications in Applied
Numerical Methods, vol. 3, pp. 243–249, 1987.
[3] T. Gratsch and K.J. Bathe, “A posteriori error estimation
techniques in practical ﬁnite element analysis,” Computers
& Structures, vol. 83, pp. 235–265, 2005.
[4] M.J. Aftosmis and M.J. Berger, “Multilevel error estimation
and adaptive h-reﬁnement for cartesian meshes with embed-
ded boundaries,” in 40th AIAA Aerospace Sciences Meeting
and Exhibit, AIAA Paper, 2002.
[5] G. Debunne, M. Desbrun, M. Cani, and A. Barr, “Dynamic
real-time deformations using space & time adaptive sam-
pling,” in Proc. Annual conference on Computer Graphics
and Interactive Techniques (SIGGRAPH 01), 2001, pp. 31–
36.
[6] S. Capell, S. Green, B. Curless, T. Duchamp, and Z. Popovi´c,
“A multiresolution framework for dynamic deformations,”
in Proc. SIGGRAPH/Eurographics Symposium on Computer
Animation, 2002, pp. 41–47.
[7] E. Grinspun, P. Krysl, and P. Schroder, “Charms: A simple
framework for adaptive simulation,” in Proc. Annual con-
ference on Computer Graphics and Interactive Techniques
(SIGGRAPH 02), 2002, pp. 281–290.
[8] M. Cavusoglu and F. Tendick, “Multirate simulation for high
ﬁdelity haptic interaction with deformable objects in virtual
environments,” in Proc. Robotics and Automation, 2000, pp.
2458–2465.
[9] R.D. Cook, D.S. Malkus, and M.E. Plesha, Concepts and
Applications of Finite Element Analysis, 3rd ed.
John Wiley
and Sons, 1989.
[10] O.C. Zienkiewicz, R.L. Taylor, and J.Z. Zhu, The Finite Ele-
ment Method: Its Basis and Fundamentals, 6th ed.
Elsevier
Butterworth Heinemann, 2005.
[11] X.D. Pang, H.Z. Tan, and N.I. Durlach, “Manual discrimi-
nation of force using active ﬁnger motion,” Perception and
Psychophysics, pp. 531–540, 1991.
[12] F. Barbagli, K. Salisbury, C. Ho, C. Spence, and H.Z. Tan,
“Haptic discrimination of force direction and the inﬂuence of
visual information,” ACM Trans. Appl. Perception, vol. 3, pp.
125–135, 2006.
[13] U. Koc¸ak, K. Palmerius, and M. Cooper, “Dynamic deforma-
tion using adaptable, linked asynchronous fem regions,” in
Proc. Spring Conference on Computer Graphics, 2009, pp.
213–220.
[14] G. Picinbono, H. Delingette, and N. Ayache, “Non-linear
anisotropic
elasticity
for
real-time
surgery
simulation,”
Graph. Models, pp. 305–321, 2003.
[15] V. Egorov, S. Tsyuryupa, S. Kanilo, M. Kogit, and A. Sar-
vazyan, “Soft tissue elastometer,” Medical Engineering and
Physics, pp. 206–212, 2008.
[16] X. Li, G. Wang, L. Huang, and G. Zhang, “Young’s modulus
extraction methods for soft tissue from ultrasound measure-
ment system,” Instrumentation Science and Technology, pp.
393–404, 2006.
[17] R. Sinkus, J. Lorenzen, D. Schrader, M. Lorenzen, M. Dar-
gatz, and D. Holz, “High-resolution tensor mr elastography
for breast tumour detection,” Physics in Medicine and Biol-
ogy, pp. 1649–1664, 2000.
[18] A. Samani, J. Bishop, C. Luginbuhl, and D.B. Plewes, “Mea-
suring the elastic modulus of ex vivo small tissue samples,”
Physics in Medicine and Biology, pp. 2183–2198, 2003.
[19] P.C. Johns and M.J. Yaffe, “X-ray characterisation of normal
and neoplastic breast tissues,” Physics in Medicine Biology,
pp. 675–695, 1987.
[20] J.M. Wakeling and B.M. Nigg, “Soft-tissue vibrations in the
quadriceps measured with skin mounted transducers,” Journal
of Biomechanics, vol. 34, pp. 539–543, 2001.
[21] G. Rus and J.G. Martnez, “Ultrasonic tissue characterization
for monitoring nanostructured tio2-induced bone growth,”
Physics in Medicine and Biology, vol. 52, pp. 3531–3547,
2007.
[22] A. Field, Discovering Statistics Using SPSS, 2nd ed.
Sage
Publications Ltd, 2005.
[23] R.N. Stiles and J.E. Randall, “Mechanical factors in human
tremor frequency,” Applied Physiology, vol. 23, pp. 324–330,
1967.
[24] M.A. Srinivasan and J.S. Chen, “Human performance in
controlling normal forces of contact with rigid objects,” in
Winter Annual Meeting of the American Society of Mechani-
cal Engineers, 1993, pp. 119–125.
[25] T.L. Brooks, “Telerobotic response requirements,” in IEEE
Int. Conf. on Systems, Man, and Cybernetics, 1990, pp. 113–
120.
199
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

