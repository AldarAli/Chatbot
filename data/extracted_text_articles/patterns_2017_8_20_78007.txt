Obtaining Shape from Endoscope Image Using Medical Suture with Two Light Sources
Hiroyasu Usami
Yuji Iwahori
Department of Computer Science
Chubu University
Kasugai, 487-8501 Japan
Mail:usami@cvl.cs.chubu.ac.jp
Mail:iwahori@cs.chubu.ac.jp
Boonserm Kijsirikul
Dept. of Computer Engineering
Chulalongkorn University
Bangkok, 10330 Thiland
Mail:Boonserm.K@chula.ac.th
M. K. Bhuyan
Dept. of Electronics
and Electrical Engineering
Indian Institute of Technology Guwahati
Guwahati, 781039 India
Mail:mkb@iitg.ernet.in
Aili Wang
Higher Education Key Lab
Harbin University of Science and Technology
Harbin, 150080 China
Mail:aili925@hrbust.edu.cn
Kunio Kasugai
Dept. of Gastroenterology
Aichi Medical University
Nagakute, 480-1195 Japan
Mail:kuku3487@aichi-med-u.ac.jp
Abstract—Obtaining polyp size and shape is important for the
medical diagnosis. In this paper, a 3-D shape reconstruction of
computer vision technology is introduced in the medical diagnosis
for this purpose. Some approaches based on Shape from Shading
have been proposed for polyp in endoscope image. Previous
approaches need some parameters such as depth parameter
Z from endoscope lens to the surface point and reﬂectance
parameter C. In the endoscope image, it is important to obtain
these parameters for accurate polyp shape recovery. This paper
proposes a new approach for obtaining parameters Z and C from
one endoscope image where a medical suture is taken. A medical
suture is used to estimate the horizontal plane locally and an
observation model of medical suture is used with the horizontal
plane. Two light sources endoscope observation system is assumed
based on the actual endoscope for improving the accuracy of the
polyp shape recovery. Experiments are conducted to validate the
proposed approach.
Keywords–Shape from Shading; Endoscope; Point Light Source;
Perspective Projection; Camera Calibration; Reﬂectance Parameter.
I.
INTRODUCTION
The size of a colonic polyp is a biomarker that correlates
with its risk of malignancy and guides its clinical management.
Given this central role of polyp size as a biomarker, the
precision and accuracy of polyp measurement is an important
issue [1]. In addition, advanced adenomas are those that are
larger (≥ 1cm) or that contain appreciable villous tissue or
high-grade dysplasia [2]. Therefore, obtaining polyp size and
shape is important for the precise diagnosis.
For these situations, it becomes more important to develop
a medical supporting application of computer vision in the
medical ﬁeld, where the 3-D shape reconstruction is expected
to be practically used in the medical diagnosis. As a 3-D
shape reconstruction technology, Shape from Shading (SFS)
[3] is one valuable approach of 3-D reconstruction. SFS uses
the image intensity directly to recover the surface orientation
of a target object from a single image. Based on SFS, some
approaches [4] [5] have been proposed to recover polyp shape
from endoscope images. The paper [4] proposes a polyp
recovering approach using both photometric and geometric
constraints, assuming an endoscope with one light source.
Another approach [5] recovers polyp shape assuming a more
actual endoscope, which has two light sources, and it uses a
neural network to modify the obtained surface gradients.
These polyp shape recovery approaches based on SFS
assume a Lambertian image and need some parameters such
as a depth parameter Z from the endoscope lens to the
surface point. To obtain the depth Z, paper [6] proposes an
approach using two images using a medical suture between
the movement of Z direction in endoscope video under the
assumption of one light source.
To relax the constraint for shape recovery, this paper
proposes a novel approach for obtaining depth Z and surface
reﬂectance parameter C from a single endoscope image of
medical suture. Medical suture is used to estimate its horizontal
plane locally and observation model of medical suture is
used with the horizontal plane. In addition, two light source
endoscope is assumed to improve the accuracy of polyp shape
based on the actual endoscope.
Experiments of polyp shape recovery are conducted with
the estimated parameters and it is shown that polyp shape is
recovered with its absolute size.
The rest of the paper is structured as follows. In section II,
the logic of the proposed approach is explained. In section III,
experiments are conducted to validate the proposed approach
and the conclusion of the proposed method is referred in
section IV.
II.
PROPOSED APPROACH
A. Procedure
The proposed approach consists of the following steps.
First, camera calibration is conducted to obtain the inner
103
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

parameters of the endoscope and subsequent steps are based on
these obtained parameters. Second, the horizontal plane of the
medical suture for the lens plane is estimated locally. Third,
depth Z and the reﬂectance parameter C are obtained by using
the estimated horizontal plane and its observation model of
horizontal plane of medical suture. Finally, the polyp shape
is recovered using the obtained Z and C based on two light
sources photometric constraint.
Step1
Estimating inner parameters of the endoscope by con-
ducting camera calibration.
Step2
Estimating the horizontal plane of medical suture to
the lens plane locally.
Step3
Obtaining Z and C using observation model of hori-
zontal plane of medical suture.
Step4
Recovering polyp shape using obtained depth Z and
reﬂectance parameter C assuming two light source
endoscope based on the approach [5].
B. Camera Calibration
First, the inner parameters of the endoscope are obtained
by a camera calibration assuming two light source endoscope
for the subsequent approaches.
1) Observation System: The observation system of endo-
scope is assumed to be a point light source and perspective
projection. According to the actual environment of the en-
doscope, two light point sources are assumed to obtain the
accurate results in parameter estimation and shape recovery.
The observation system of two light sources endoscope is
shown in Figure 1. Here, let the coordinate of the center of lens
be (0, 0, 0), f be the focal length, S1 and S1 be the distances
from the lens to the surface point and n be the normal surface
vector.
2) Estimating Inner Parameters of Endoscope: Estimating
inner parameters of the endoscope is performed using multiple
images of checker board taken by the endoscope based on the
camera calibration techniques [7] [8]. An example of checker
board images used in the proposed approach is shown in Figure
2.
Figure 2. Examples of Checker Board Images
Figure 1. Observation System of Two Light Source Endoscope.
C. Estimation of Parameters Using Medical Suture
1) Estimation of Parameters: Parameters Z and C for
shape recovery under SFS approach are obtained by estimating
the horizontal plane of medical suture locally using its obser-
vation system. The procedures for obtaining parameters Z and
C are shown in the following steps.
Step1
Estimating horizontal plane of medical suture locally
from a single image.
Step2
Obtaining the depth Z using the horizontal plane of
medical suture using its observation system.
Step3
Obtaining C using two light source photometric con-
straint.
The details of these steps are described below.
2) Estimation of Horizontal Plane: The horizontal planes
of columnar forms against the lens can be obtained by con-
sidering the continuity of width from the columnar centerline
to both end edges. The columnar width cut out by horizontal
plane against the lens (as shown in Figure 3) continues while
the cropped region is horizontal against the lens. The horizontal
planes of medical suture can be obtained locally based on this
property from one endoscope image.
The procedure of obtaining the horizontal plane is as
follows.
Step1
Extract the medical suture region5 from original im-
age4.
Step2
Extract the medical suture centerline by applying
thinning processing as shown in Figure 6.
104
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

Step3
Extract medical suture edge using the morphology
operation as shown in Figure 7.
Step4
Draw a line orthogonal to the centerline and crop the
line by both end edges. Finally, extract regions where
the cropped line continues the same width as shown
in Figure 8.
Figure 3. Horizontal Plane of Columnar against Lens
Figure 4. Original Image of
Medical Suture
Figure 5. Example of
Extracted Medical Suture Region
Figure 6. Example of
Line Thinning Processing
Figure 7. Example of
Edge Extraction
Figure 8. Example of
Estimation of Horizontal Plane
3) Estimation of Depth Z: Here, an observation system of
the horizontal plane of medical suture is proposed to obtain
the depth parameter Z from the endoscope lens to the surface
point. The observation system is shown in Figure 9.
Depth Z from the lens can be calculated using the model
with respect to the estimated horizontal plane of medical
suture. The procedure for calculating parameter Z is described
below.
Figure 9. Observation System of Horizontal Plane
From △LOIi ∼ △LSoSi, ̸ LSiSo is an external angle of
105
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

△LSoSi, ̸ LSiSc is obtained by Equation (1).
̸ LSiSc = π − ̸ LIiO
(1)
From △LOIc ∼ △LSoSc, △LScSo is given by Equation
(2).
̸ LScSi = ̸ LIcO
(2)
̸ SiLSc = π − ̸ LSiSc − ̸ LScSi
(3)
Similarly, ̸ LScPi can be obtained from Equation (4).
̸ LScPi = π − π
2 − ̸ SiLSc
(4)
Focusing on the hypotenuse from the lens L to the center of
the suture center Si in △LScSi, distance LSc can be obtained
from Equation (5). Here, distance PcSc is the same as the
suture radius.
LSc =
PiSc
cos̸ LScPi
(5)
The distance from the lens L to the surface of the suture
Pc can be obtained from Equation (6). Here, PcSc is the same
as the suture radius.
LPc = LSc − PcSc
(6)
Finally, from △LZPc ∼ △LOIc, the depth Z can be given
by Equation (7).
Z = LPcsin̸ LIcO
(7)
4) Estimation of Reﬂectance Parameter C: The reﬂectance
parameter C is calculated using the obtained Z and two light
sources photometric constraint. Let the coordinate of the center
of lens be (0,0,0) as shown in Figure 1.
The image intensity E can be expressed using the inverse
square law of illuminance, as shown in Equation (8).
E = C(n · s1
l2
1
+ n · s2
l2
2
)
(8)
Here, n is the normal surface vector represented using
gradient parameters (p, q)=(∂Z/∂X, ∂Z/∂Y ) as
n =
[p, q, −1]
√
p2 + q2 + 1
(9)
s1 and s2 are the light sources direction vectors for light
sources 1 and 2, respectively. l1 and l2 are the distances from
light sources 1 and 2, respectively to the surface point.
Let the light sources direction vectors be s1 and s2, and
let the position of light source 1 be (a, b, 0), let the position of
light source 2 be (c, d, 0). Light source direction vectors are
represented by Equation (10) as unit vectors.
s1 =
[a − x, b − y, −Z]
√
(a − x)2 +
√
(b − y)2 + Z2
s2 =
[c − x, d − y, −Z]
√
(c − x)2 +
√
(d − y)2 + Z2
(10)
Distances l1 and l2 are represented using the coordinates
of each light sources as Equation (11).
l1 =
√
(a − x)2 + (b − y)2 + Z2
l2 =
√
(c − x)2 + (d − y)2 + Z2
(11)
Substituting Equation (9), Equation (10) and Equation (11)
into s1, s2, n, l1 and l2 gives
C =
E
{{
(a−x)2+(b−y)2+f 2} 3
2 Z2√
p2+q2+1
f 2(−p(a−x)−q(b−y)+f)
+
{
(c−x)2+(d−y)2+f 2} 3
2 Z2√
p2+q2+1
f 2(−p(c−x)−q(d−y)+f)
}
(12)
where f is the focal length.
D. Shape Recovery Using Obtained Z and C
Shape recovery is performed using the obtained Z and C
based on the paper [5]. The procedure for shape recovery is
as follows.
Step1
Uniform Lambertian image is generated by the method
[9] which is converted from the original RGB (red,
green, and blue) color model endoscope image.
Step2
Recover the initial depth by optimization using pho-
tometric constraints under the condition of two light
sources and using obtained Z and C.
Step3
Apply NN (Neural Network) learning using gradient
parameters (p, q) of a Lambertian sphere, which is
used to modify the obtained surface gradient (p, q).
Step4
Update the depth Z using optimization by treating the
obtained gradient parameters (p, q) as constants again.
III.
EXPERIMENTS
Experiments were performed to evaluate the proposed
method using actual endoscope images. Here, a medical suture
with size 1-0 silk suture and its diameter 0.33mm is used in
the endoscope image.
A. Result of Camera Calibration
The result of the camera calibration is shown in Table
I. The inner parameters of the endoscope are focal length,
principal point and radial distortion and those parameters were
obtained by the camera calibration.
Here, two parameters were obtained respectively based on
the aspect ratio of image.
TABLE I. RESULT OF ESTIMATION
Parameter
Result of Calibration
Focal length (pixels)
[ 718.7447 + / - 0.8387, 718.3827 + / - 0.8654 ]
Principal point (pixels)
[ 879.0439 + / - 0.4669, 533.5813 + / - 0.4240 ]
Radial distortion
[ - 0.3913 + / - 0.0010,
0.1178 + / - 0.0008 ]
106
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

B. Result of Estimated Depth Z
Depth Z was estimated using the obtained inner parameters
of the endoscope. The results of estimating the horizontal plane
of medical suture are as shown in Figures 10 to Figure 17,
respectively. Here, more than 6 continuous regions with same
width are adapted as the horizontal plane section in tracing the
suture center line.
Figure 10. Scene1
Original Image
Figure 11. Scene1
Horizontal Plane
Figure 12. Scene2
Original Image
Figure 13. Scene2
Horizontal Plane
Figure 14. Scene3
Original Image
Figure 15. Scene3
Horizontal Plane
Figure 16. Scene4
Original Image
Figure 17. Scene4
Horizontal Plane
TABLE II. RESULT OF ESTIMATED Z
Scene
Section
Estimated Z [mm]
MEAN
STD
1
1
34.3456
0.0000
2
34.3424
0.0044
3
34.2384
0.0051
4
34.1847
0.0081
5
34.9362
0.0086
2
1
30.8150
7.7443
2
17.0185
0.0000
3
1
34.5360
0.0028
4
1
13.9666
2.6010
2
15.1002
0.0000
The result of depth Z estimation for each scene and
estimated horizontal section are shown in Table II. From these
results, the horizontal section of medical suture within [nm]
level variation of the depth Z could be obtained in each scene.
It is shown that the horizontal plane of the medical suture and
depth Z were obtained with high accuracy in each endoscope
image.
C. Result of Shape Recovery
Polyp shape recovery was performed using calculated Z
and C. The results of polyp shape recovery are shown in
Figures 18 to 21. Here, some regions which interfere with
the shape recovery such as a hood cover of the endoscope
were cut out. From the recovered shapes, it is conﬁrmed
that approximate polyp shape could be recovered using the
calculated parameters Z and C of the proposed approach.
Figure 18. Recovered Shape of Scene1
107
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

Figure 19. Recovered Shape of Scene2
Figure 20. Recovered Shape of Scene3
Figure 21. Recovered Shape of Scene4
IV.
CONCLUSION
This paper proposed a new approach for obtaining depth
parameter Z from endoscope lens to the surface point and
reﬂectance parameter C from one endoscope image of medical
suture by estimating the horizontal plane of medical suture
locally and its observation model. The result shows that ap-
proximate polyp shape could be recovered using the calculated
parameters Z and C. Applying this proposed method to the
blood vessel for mitigating constraint conditions and improving
the accuracy of shape recovery are left as future works.
ACKNOWLEDGEMENT
Iwahori’s research is supported by JSPS Grant-in-Aid
for Scientiﬁc Research (C)(26330210) and Chubu University
Grant.
REFERENCES
[1]
R. M. Summers, “Polyp size measurement at ct colonography: What do
we know and what do we need to know? 1,” Radiology, vol. 255, no. 3,
2010, pp. 707–720.
[2]
J. H. Bond, “Polyp guideline: diagnosis, treatment, and surveillance for
patients with colorectal polyps,” The American journal of gastroenterol-
ogy, vol. 95, no. 11, 2000, p. 3053.
[3]
B. K. Horn, “Obtaining shape from shading information,” in Shape from
shading.
MIT press, 1989, pp. 123–171.
[4]
Y. Iwahori, K. Tatematsu, T. Nakamura, S. Fukui, R. J. Woodham,
and K. Kasugai, “3d shape recovery from endoscope image based
on both photometric and geometric constraints,” in Knowledge-Based
Information Systems in Practice.
Springer, 2015, pp. 65–80.
[5]
H. Usami, Y. Hanai, Y. Iwahori, and K. Kasugai, “3d shape recovery of
polyp using two light sources endoscope,” in Computer and Information
Science (ICIS), 2016 IEEE/ACIS 15th International Conference on.
IEEE, 2016, pp. 1–6.
[6]
Y. Iwahori, Y. Daiki, T. Nakamura, K. Boonserm, B. M. K., and
K. Kunio, “Estimating reﬂectance parameter of polyp using medical
suture information in endoscope image,” in ICPRAM, 2016, pp. 503–
509.
[7]
Z. Zhang, “A ﬂexible new technique for camera calibration,” IEEE
Transactions on pattern analysis and machine intelligence, vol. 22, no. 11,
2000, pp. 1330–1334.
[8]
J. Heikkila and O. Silv´en, “A four-step camera calibration procedure with
implicit image correction,” in Computer Vision and Pattern Recognition,
1997. Proceedings., 1997 IEEE Computer Society Conference on. IEEE,
1997, pp. 1106–1112.
[9]
Y. Shimasaki, Y. Iwahori, D. R. Neog, R. J. Woodham, and M. Bhuyan,
“Generating lambertian image with uniform reﬂectance for endoscope
image,” in PRoceedings of the International Workshop on Advanced
Image Technology (IWAIT’13), 2013, pp. 60–65.
108
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-534-0
PATTERNS 2017 : The Ninth International Conferences on Pervasive Patterns and Applications

