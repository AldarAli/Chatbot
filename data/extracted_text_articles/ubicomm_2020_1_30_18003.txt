Edge-Centric Video Data Analytics for Smart Assistance Services in Industrial Systems
Nikita A. Bazhenov, Artur E. Harkovchuk, Dmitry G. Korzun
Department of Computer Science
Petrozavodsk State University (PetrSU)
Petrozavodsk, Russia
e-mail: {bazhenov, harkovch, dkorzun}@cs.petrsu.ru
Abstract—Video data analytics has now become essentially ori-
ented on edge-centric computing in Internet of Things (IoT). In
this paper, we consider such video services that provide analytics
to smart assistance in industrial IoT systems. We identify the
opportunities of industrial video data analytics. We present
an edge-centric architecture for constructing smart assistance
services. Based on this architecture, we implemented several pilot
services that demonstrate the opportunities of industrial video
data analytics. The services are deployed and experimented in a
real enterprise for monitoring industrial production equipment
(technical state and its evolution, ongoing production processes,
equipment operating conditions).
Keywords–Video data analytics; Internet of Things; Smart
Assistance Services; Edge-Centric Computing.
I.
INTRODUCTION
Internet of Things (IoT) supports the development of smart
environments, where the key element is a smart service [1].
The service intelligence is essentially based on data analytics.
In the case of video data, a smart service provides video
surveillance and visual interactivity with the user [2]. Such a
service provides analytical information about the object under
monitoring [3].
Video data analytics has now become essentially oriented
on edge-centric computing in the Internet of Things (IoT) [4],
[5]. In this paper, we consider services that provide video
data analytics to smart assistance in industrial IoT systems.
Our Industrial Partner to deploy and experiment with the
services is Petrozavodskmash, which is a branch of AEM-
technology JSC in the Petrozavodsk city (Republic of Karelia,
Russia). The company is one of the largest machine-building
enterprises based on the following industries: foundry, welding,
and mechanical assembly production.
The challanging problem is performing video data process-
ing on edge devices, which are of low capacity and computing
power [1]. In this paper, we show that a solution to this
problem moves industrial video data analytics to the next
level with respect to the “real-time assistance” property of the
smart services. We consider an edge-centric architecture for
constructing such smart assistance services in Industrial IoT
(IIoT) systems.
Based on this architecture, we implemented several pilot
services to demonstrate the opportunities for industrial video
data analytics.
•
Monitoring mechanical components of equipment to
detect deviations in machine operations;
•
Operator presence in the area to control production
processes;
•
Screen image text analysis from the Computer Numer-
ical Control (CNC) display monitor to detect errors.
The services are deployed and experimented for monitor-
ing industrial production equipment (technical state and its
evolution, ongoing production processes, equipment operating
conditions).
The rest of the paper is organized as follows. Section II
considers existing methods and example services in edge-
centric video data analytics. Section III identiﬁes the op-
portunities of video data analytics based on the needs of
our Industrial Partner. Section IV presents our edge-centric
architecture for constructing smart assistance services. Finally,
Section V concludes the paper.
II.
RELATED WORK
The current focus on edge-centric in IoT systems sup-
ports high efﬁciency and throughput of the processed in-
formation [6], as well as provides additional opportunities
for connecting multiple devices. Edge-centric allows us to
organize decentralized computing on multiple edge devices,
using limited resources between participants in the space.
Many systems use mobile devices at the edge [7], which
allows for more efﬁcient distribution between devices. The
organization of such a computation model makes it possible to
reduce the computation time of the most complex algorithms
that require a large resource of time for preprocessing and
analysis.
Many solutions integrate existing IoT concepts into more
comprehensively organized structures. A particular example is
the combination of several video surveillance devices into a
common video system behind a complex object: the smart
home. Smart homes are combined into smart cities [8], which
makes it possible to control systems such as ecology, security,
safety, and health of citizens on a global level. Modern
monitoring systems are able to diagnose the working condition
of machines in real-time. This allows for early detection of
deviations and breakdowns that occur with equipment during
active production [9]. As monitoring tools, sensors, or sensor
networks is mainly used to measure various indicators of the
current state of machines (e.g., current consumption, temper-
ature, accelerometer values). Such sensors are installed in the
internal system of the equipment or are connected separately
from the equipment.
During the operation, machines generate vibrations which
result in the deterioration of machine tools eventually causing
failure of some subsystems or the machine itself [10]. The
vibration signatures analysis can be used to detect the nature
13
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-811-2
UBICOMM 2020 : The Fourteenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

and extent of any damage in machines and components or
any maintenance decisions related to the machine. However,
modern industrial monitoring systems mainly use sensors to
detect a large number of defects. Thus, the breakage veriﬁ-
cation criterion is based solely on sensor readings. The use
of video services makes it possible to expand the empirical
picture of the breakdown of machinery, even when a video
camera is watching an object.
Thus, the closest solutions to the developed solution are the
following scientiﬁc works: recognition of worker activity in a
factory using convolutional neural networks [11], recognition
of workers who are not wearing a safety helmet [12], error
recognition based on text from CNC monitor [13].
III.
INDUSTRIAL VIDEO DATA ANALYTICS
The Petrozavodskmash company is a machine-building
enterprise with a huge database of machine tools working in
various industries. We use our industrial partner to deploy
and experiment with our pilot smart assistance services for
monitoring industrial production equipment (technical state
and its evolution, ongoing production processes, equipment
operating conditions).
A. Methods
The key solution of the method is the use of edge com-
puting, which includes well-known mathematical processing
algorithms (for example, motion recognition on a video cam-
era, image rendering, combining information video streams),
semantic data mining (separation of relationships and rela-
tionships between streams) and performing calculations using
several heterogeneous resources of video cameras and personal
mobile devices available in the peripheral IoT environment on
different mobile platforms.
Semantic integration will take place at the level of the IoT
environment, using the available resources of the surrounding
equipment to obtain data for observing objects. In particular,
efﬁciency gains will be achieved through: connecting a large
number of video cameras and processing on devices with low
performance; the use of Artiﬁcial Intelligence (AI) technolo-
gies; calculating heterogeneous data analyzed on the basis of
images from a video camera; using the Semantic Web and
ﬁnding connections between video streams. Modern video data
analysis systems for recognizing people, objects and zones, are
described in [14].
The integration between smart video surveillance and IoT
is described in [15]. The authors show how different objects,
cameras, and sensors can process various pieces of information
in the network. The authors propose an innovative topology
paradigm that shows better communication between different
video camera surveillance systems provided by IoT.
B. Multi-platform monitoring and computing
Multi-platform development of the mobile applications [16]
refers to applications that can work both on mobile (Android,
Apple) and desktop (PC, Windows) devices. One of the impor-
tant advantages is the development of a distributed application
that can run on several platforms at the same time, including
adjusting to its interface depending on the mobile platform,
screen resolution, orientation, and the user’s own wishes. The
main requirement is to create a combined desktop and Web
application presented as a single development environment.
However, the most efﬁcient implementation of multiplat-
form is to create a hybrid application [17] that runs on mul-
tiple platforms simultaneously. The simplest implementation
method is to integrate applications into the user’s Web browser
that is used on each platform. Thus, the display of services will
be implemented using their uniform representation for users in
the form of an HTML page. All the user needs to do is have
Internet access or a local router connection.
C. Edge analytics
An edge-centric parametric predictive analytics methodol-
ogy is shown in [18]. The use of such a methodology uses
predictive data analytics and ensures that only the information
that is needed is transmitted. This point is especially important
during analysis on the IoT edge, as video data is generally very
large for processing and transmission, which creates a huge
load on the server and network.
The main advantage is the extraction of the necessary video
frames from the stream. Thus, processing incoming frames in
real-time, although it will take up most of the processor time,
will reduce the load on the network and the occupied space
on the local data storage.
D. Heterogeneous data
Knowledge graphs can be used to implement edge analytics
in some heterogeneous environments [4]. Since video analytics
will be performed in real-time, various pieces of information
will be received by users. Instead of the entire video stream,
only keyframes that are meaningful to users will be used.
Moreover, these frames will be preprocessed in advance and
they will contain information that is important for solving
a particular task (for example, determining the number of
workers in the machine tool area). In addition, instead of
frames, it can only be a text or graphic notiﬁcation about
the current state of the equipment. The most complete and
advanced delivery option will be the use of graphs, charts,
histograms with distribution over time.
Let us count the time between the incident and the opera-
tor’s reaction. The system requires an average of 1 to 2 seconds
to compute. Visible cases (defects) can be detected manually
by a person within a few seconds or minutes. Invisible cases
(which cannot be detected immediately) can be detected within
hours or days. Manual viewing of all video recordings from
cameras requires man-hours and also involves all the problems
associated with the human factor.
The Video Event Representation Model is shown in Fig. 1.
As an example, a service for recognizing people and cal-
culating the distance to a person and equipment is used.
The ﬁrst video camera mounted on top of the machine area
contains a video stream with people (machine operators) and
also contains a video stream with the equipment. The second
video camera is located at the level of human height and
is necessary to recognize the helmets worn on the heads
of operators (to comply with safety regulations). The third
video camera is located at the level of the CNC monitor
and is designed to recognize the error code that appears on
the screen. Other IoT elements are also located next to the
video cameras: an accelerometer, current clamp, temperature,
tachometer (however, we will not discuss it at the level of the
architecture). First, the connection to the database is initialized,
from where the current information about the availability of
14
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-811-2
UBICOMM 2020 : The Fourteenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

Figure 1. Video Event Representation Model
personnel in the area is taken, as well as the distance to the
machinery. Cameras are connected to a router and transmit
information to video processing modules. The video analytics
modules (module for recognizing a person and calculating the
distance) determine the presence of a person in the frame and
also determine the distance to him by the silhouette of a person
(it is assumed that the silhouette of a person in the frame
is always fully visible). Further, events are generated using
the monitor and sent to the MongoDB database, as well as
to the RabbitMQ message broker. Further, the information is
converted into the information necessary for users (building
graphs and diagrams) and displayed in video services on the
Web on end devices.
Each of the video cameras is used to provide the user with
the speciﬁc information he needs. This allows the operator to
receive real-time information about incidents involving people
and machinery in the plant. Let us discuss the beneﬁts of
our solution. The applied architectural approach allows us to
consider speciﬁc services from a practical point of view and
deploy and use them in a speciﬁc enterprise. In particular,
this approach is easy to understand and does not require
a detailed explanation of the details. High performance is
achieved through the use of automated recognition tools.
IV.
EDGE-CENTRIC VIDEO DATA ANALYTICS
The proposed architecture is based on the following prop-
erties:
•
multiple video cameras to use, which provide various
video data ﬂows to be processed and analyzed;
•
microservices to construct a dynamic system of ser-
vices;
•
edge-centric to implement an essential part of analyt-
ics locally (near the data sources).
In conditions of work in an unfavorable environment, a
video surveillance camera protected from moisture and dust is
used to obtain a video stream in real-time with its subsequent
processing. The use of cameras that are not equipped with this
protection requires the use of external protective boxes.
A. Monitoring mechanical components of equipment to detect
deviations in machine operations
Consider the following objects for monitoring.
•
Shock detection of moving parts of equipment [19].
•
Detection of mounted rotary swivel head.
•
Counterweight detection.
Monitoring the mechanical elements of the machine using
video cameras allows us to automatically monitor the perfor-
mance of the machine elements for the smooth operation of
the machine. Elements that are attachments for the operation
of the machine are tracked: counterweight and swivel head.
For mounted elements, it is required to monitor: whether it
is necessary to install, what is installed, whether it is installed
correctly. External inﬂuences on the machine (impacts) are also
monitored.
The use of the multi-platform allows the operator to control
the correct operation of the machine, using a smartphone,
without being at his work computer. The use of a smartphone
allows us to increase efﬁciency and response to an event that
has occurred since when an abnormality occurs, the operator
processes all receive notiﬁcations in real-time.
Calculations are carried out on a central computer located
near the machine. Computing near the machine helps to avoid
the problem of transmitting large amounts of data over the
network and to increase the processing speed.
The operator is provided with information about the rotary
heads located on the storage rack, as well as the set angles
of rotation of each of the heads. Depending on the head
and the angle of rotation, a composite event is generated
that notiﬁes the operator whether the head is correctly or
incorrectly positioned. The impacts of the moving parts of the
machine are monitored and the information is transferred to the
operator. The presence of the installed counterweight on the
head is monitored. Depending on whether the counterweight
is installed and the type of installed head, a composite event
is generated about the requirement to install a counterweight
to avoid incorrect operation of the machine.
15
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-811-2
UBICOMM 2020 : The Fourteenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

B. Operator monitoring in the area to control production
processes
1)
Operator memorization and identiﬁcation by his ex-
ternal characteristics:
•
Work uniform recognition;
•
Helmet recognition;
•
Human and face recognition;
•
Operator identiﬁcation to gain access to the
machine area.
2)
Determination of the presence of the operator in the
danger zone of the equipment:
•
Operator recognition [5];
•
Equipment recognition [20];
•
Detection of current distance to operator, to
equipment;
•
Operator is in the danger zone of the equip-
ment based on distances.
Tracking the presence of the operator on the site allows us
to ensure the safety of the work process and control access to
the elements of the machine. Recognition of the work uniform
and helmet allows to track that the worker is observing safety
measures. Face recognition allows us to identify a person
and check his competence to work with a speciﬁc machine.
Determining the operator’s presence in the hazardous area
is a means of maintaining safety at the machine. Finding
the distance between the operator and the elements of the
machine allows us to determine the physical interaction with
the machine.
The use of a multi-platform allows the operator to receive
information on interaction with the machine without the neces-
sary equipment on his smartphone and quickly prevent safety
violations. The operator can view the list of current persons in
the area of the machine for quick interaction with personnel.
Calculations are carried out on a central computer server,
which is located near the machine. Fast data transfer and
processing is ensured.
The operator receives a large number of basic events related
to the presence of uniform elements, person identiﬁcation, and
distance determination. A composite event about the presence
of the necessary uniform consists of the presence of a work
uniform and a work helmet. Also, a composite event is the
presence of a person in the danger zone without the necessary
authority. This event consists of identifying persons, ﬁnding
the distance, and information about the level of access and
competence of a person.
C. Screen image text analysis from CNC display monitor to
detect errors
Recognition of the CNC error code from the control panel
screen allows us to receive errors that occurred during the
operation of the machine in real-time without interfering with
the operation of the system. The errors received are analyzed
and the results are presented to the operator.
The use of a multi-platform allows us to interact with
the system not only while at the work computer but also
during absence from the workplace. The operator can receive
information about the appeared and recognized the error in
smartphone in the form of a PUSH notiﬁcation, for a timely
response and troubleshooting the equipment.
Computations for error recognition are carried out on an
intermediate device when information is transmitted to the
main computer server. Using the computing device directly
next to the webcam will reduce the load on the central
computing device.
The operator is presented with the last recognized error
and history with time stamps. For each recognized error, a
composite event is generated in which its description is shown
with the methods for eliminating the error described in the ofﬁ-
cial CNC manual. An event consisting of several errors is also
a composite event. The operator is offered recommendations
for their elimination, described by a person working with the
machine. Providing the operator with analyzed data increases
efﬁciency and reduces problem resolution time.
To deploy services, we need the installation of IP67,
IP68 video cameras. The installation of protected cameras is
required to prevent damage from dust and water exposure
that can occur in a factory environment. The use of a twisted
pair cable allows the camera to be powered via PoE (Power
over Ethernet) and provides speeds up to 10 Mbps. A switch
equipped with PoE ports is used for power supply. It is required
to select the correct switch, since with a large number of
connected cameras, the switch will not be able to provide
enough power for all cameras.
D. Basic and composite events
The correct connection of all services to video devices for
receiving data is provided by a user-deﬁned conﬁg. The conﬁg
includes network data for correct connection, authentication
data for security, parameters of the received video stream, and
the requirements for the video stream imposed by the service.
The service results are saved in the MongoDB database.
Events:
•
Events deﬁnition and speciﬁcation: basic and compos-
ite events [21] [22].
•
Composite events operators based on Snoop expres-
sions.
•
Table with examples of basic and composite events.
The event-driven data model allows us to organize inter-
action between software modules within the framework of a
given application function. Software modules can be loosely
coupled, i.e. to create a module, only the speciﬁcation of the
events to be processed with the rules for their inference is
needed, which allows organizing a distributed microservice
software infrastructure. Moreover, such a model allows us
to combine heterogeneous data sources, forming a single
consistent view with a high level of abstraction for a more
accurate way of identifying events that occur.
An event in industrial equipment video monitoring sys-
tems is determined by a ﬁnite time interval at which some
integral (indivisible) industrial phenomenon occurs, i.e. such
a phenomenon either occurs entirely or does not occur at all.
An industrial phenomenon occurs when the state is changed
in the physical environment of an industrial enterprise. The
environment is equipped with a video surveillance system that
allows recording such events at a certain point in time.
In this case, an event occurring in the time interval between
two consecutive points is considered to have occurred at the
time of the endpoint of the interval.
16
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-811-2
UBICOMM 2020 : The Fourteenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

At the initialization stage, it is necessary to describe the
events that will be ”tracked” based on video streams received
from CCTV (Closed-circuit television) cameras. The following
are suggested as basic rules: each video camera generates a
separate video stream, which can contain many key elements
(phenomena and anomalies) that make up a basic event. At
the request of the developer, the underlying event can change
depending on time, space, and context. The number of basic
events from one video stream can be unlimited. Several video
streams contain main events. Several major events make up
a composite event (based on video streams 1 . . . n). A basic
event depends on time, space, and context. Basic events can
be independent and observed in different periods of time
with different durations. Composite events can include several
simple sequential or simultaneous basic events, as well as
depend on other composite events. Composite events represent
the end result, which can be presented in the form of a graph,
diagram, text. The result, in turn, should be understandable
and representative of the user.
Table I shows the composite events that result from the
service. Composite events are made up of some basic and
composite events functionality required by operators to service
the machine.
The service for monitoring mechanical components mon-
itors basic events: head type recognition, head rotation angle
detection, shock detection. The composite head positioning
event uses basic head type and angle detection events. For
composite event tracking, the head type is determined based on
its position in the storage rack and its external characteristics.
The angle of rotation is tracked using visual elements on the
head and displaceable when it is rotated. Tracking the correct
positioning allows us to avoid breakdowns when installing the
head on the machine since the machine does not check the
current angle of rotation of the head and the installation is an
automatic process of the machine and is little controlled by the
operator. The tracking of counterweight installation depends on
basic impact detection events and the type of head installed.
Tracking the type of head installed allows us to know if a
counterweight is needed on a given head. Impact tracking
allows us to determine if the head is balanced. Installing a
counterweight prevents incorrect machining of parts and is a
necessary element for some machining heads.
The operator monitoring in the area of the machine mon-
itors basic events: work uniform recognition, helmet recogni-
tion, human and face recognition, object distance detection.
A composite event indicating that the operator is wearing ap-
propriate clothing and protective equipment uses basic helmet
and uniform recognition events. Every employee working in
the plant must wear a special work uniform and be equipped
with a helmet to protect the head. Wearing this uniform is
required to comply with safety regulations and to save the
life of employees. To track illegal access to the machine,
human and face recognition events, object distance detection,
as well as a database of employees with their competencies
and access levels are used. Composing a composite event
requires recognizing people’s faces and distance to objects.
If a person is in the service area, then his competence to
work with this machine is checked. In a factory environment,
with a large space and a large number of workers, it is
required to control the level of access to equipment. It is
required not to allow unqualiﬁed personnel to work with the
machine without the participation of the machine operator. It
is also required to track who at what time worked with the
machine. The composite event of recognition of a person in
a danger zone consists of human and face recognition, object
distance detection. Recognition of a person and the distance to
dangerous objects occurs, if the distance is less than a certain
one, then the person is considered to be in the danger zone.
An important element when working in a factory is compliance
with safety measures; this can be solved by detecting a person
in the hazardous area next to the machine in operation.
The screen image text analysis monitors a basic event
- the appearance of error code on the screen. A composite
event showing the operator a detailed description of the error
consists of an error tracked on the screen and a database with
a description of all available CNC errors. Obtaining a detailed
description saves the operator from searching for information
and provides information about the description and the method
for resolving the error that has occurred. A composite event of
related errors consists of several events of the occurrence of
an error code at a time interval. It allows us to track errors that
appear in a group for accurate identiﬁcation of the malfunction
and quick correction.
TABLE I. BASIC AND COMPOSITE EVENTS
Service
Composite
event
Basic event
Functionality
Monitoring
for
position
and
move-
ment of
mechani-
cal
components
Correct
head
positioning
Head type recog-
nition, head rota-
tion angle detec-
tion
Prevention of breakage of
parts of the head mounts,
due to incorrect positioning
of the head during its instal-
lation
Counterweight
Installation
Requirements
Head type recog-
nition, shock de-
tection
Prevention of the appear-
ance of defects on the ob-
ject being processed by the
machine, due to the appear-
ance of vibration on the
processing head
Monitoring
for
operator
(human)
presence
in the
area
Full
uniform
availability
Work
uniform
recognition,
helmet
recognition
Ensures the implementation
of safety measures to pro-
tect the health of personnel
Determining
the
access
level
Human and face
recognition,
a
database
of
employee
qualiﬁcations and
access
levels,
object
distance
detection
Prevention of access to per-
sonnel not qualiﬁed to oper-
ate the machine, to prevent
damage due to poor quality
maintenance
Recognition of
a person in a
danger zone
Human and face
recognition, object
distance detection
Protection
of
personnel
from being in hazardous
areas where a person can
be injured as a result of the
operation of the machine
Monitoring
for text
messages
observed
on the
equip-
ment
display
Error
code
with
detailed
description
Error code recog-
nition, a database
compiled from the
ofﬁcial CNC error
manual
Providing the operator with
real-time error information,
which will allow faster cor-
rection of errors and ensure
the smooth operation of the
machine
Related errors
Recognition of er-
ror codes
Tracking error chains when
a lot of errors appear, to ac-
curately identify the prob-
lem and ﬁx it as soon as
possible
Table II shows the current capabilities of the service and
possible improvements. Current capabilities refers to the capa-
bilities that are currently provided by the installed services at
the factory. Possible improvements refer to additional service
capabilities that can be implemented to help workers and
management.
17
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-811-2
UBICOMM 2020 : The Fourteenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

TABLE II. SERVICE CABILITIES AND OPPORTUNITIES
Service
Cabilities
Opportunities
Monitoring
mechanical
components
Determining the angle of
installation of the pro-
cessing head and the type
of installed head, as well
as
determining
the
in-
stallation of the counter-
weight
Recognition of the type of
processing of parts in the
working area
Operator
presence
in
the area
Identiﬁcation of a person
in the danger zone and
identiﬁcation by face, the
presence of a helmet and
uniform
Tracking a worker’s wear-
ing a medical mask
Screen
image
text
analysis
Error code recognition
Recognition of X Y Z co-
ordinates published on the
CNC screen
V.
CONCLUSION
This paper discussed the service development problem of
industrial video data analytics when services provide close to
real-time assistance. We presented an edge-centric architecture
for constructing such smart assistance services. Based on
this architecture, we implemented several pilot services to
demonstrate the opportunities of industrial video data analytics.
•
Monitoring mechanical components of equipment to
detect deviations in machine operations;
•
Operator presence in the area to control production
processes;
•
Screen image text analysis from CNC display monitor
to detect errors.
The services are deployed and experimented for monitor-
ing industrial production equipment (technical state and its
evolution, ongoing production processes, equipment operating
conditions). Our early experiemnts show the high potential of
edge-centric video data analitics for smart assistance in IIoT
systems.
ACKNOWLEDGMENT
This research is implemented in Petrozavodsk State Uni-
versity (PetrSU) with ﬁnancial support by the Ministry of
Science and Higher Education of Russia within Agreement
no. 075-11-2019-088 of 20.12.2019 on the topic “Creating
the high-tech production of mobile microprocessor computing
modules based on SiP and PoP technology for smart data
collection, mining, and interaction with surrounding sources”.
The reported research study is supported by RFBR (research
project # 19-07-01027). The work is implemented within the
Government Program of Flagship University Development for
Petrozavodsk State University (PetrSU) in 2017–2021.
REFERENCES
[1]
D. Korzun, E. Balandina, A. Kashevnik, S. Balandin, and F. Viola,
Ambient Intelligence Services in IoT Environments: Emerging Research
and Opportunities.
IGI Global, 2019.
[2]
K. Schoeffmann, M. A. Hudelist, and J. Huber, “Video interaction tools:
A survey of recent work,” ACM Computing Surveys (CSUR), vol. 48,
no. 14, Sep 2015.
[3]
Y. Chen, Y. Xie, Y. Hu, Y. Liu, and G. Shou, “Design and implemen-
tation of video analytics system based on edge computing,” in 2018
International Conference on Cyber-Enabled Distributed Computing and
Knowledge Discovery (CyberC), 2018, pp. 130–137.
[4]
N. Anand, A. Chintalapally, C. Puri, and T. Tung, “Practical edge analyt-
ics: Architectural approach and use cases,” in 2017 IEEE International
Conference on Edge Computing (EDGE), 2017, pp. 236–239.
[5]
N. Bazhenov and D. Korzun, “Event-driven video services for moni-
toring in edge-centric internet of things environments,” in Proc. 25th
Conf. Open Innovations Association FRUCT, Nov. 2019, pp. 47–56.
[6]
K. Yeow, A. Gani, R. W. Ahmad, J. J. P. C. Rodrigues, and K. Ko,
“Decentralized consensus for edge-centric internet of things: A review,
taxonomy, and research issues,” IEEE Access, vol. 6, 2018, pp. 1513–
1524.
[7]
D. Wu, J. Yan, H. Wang, and R. Wang, “User-centric edge sharing
mechanism in software-deﬁned ultra-dense networks,” IEEE Journal on
Selected Areas in Communications, vol. 38, no. 7, 2020, pp. 1531–1541.
[8]
E. Kim, “Smart city service platform associated with smart home,”
in 2017 International Conference on Information Networking (ICOIN),
2017, pp. 608–610.
[9]
M. A. Fabr´ıcio, F. H. Behrens, and D. Bianchini, “Monitoring of indus-
trial electrical equipment using iot,” IEEE Latin America Transactions,
vol. 18, no. 08, 2020, pp. 1425–1432.
[10]
A. Rastegari, A. Archenti, and M. Mobin, “Condition based mainte-
nance of machine tools: Vibration monitoring of spindle units,” 01 2017.
[11]
W. Tao, Z.-H. Lai, M. C. Leu, and Z. Yin, “Worker activity
recognition in smart manufacturing using imu and semg signals
with convolutional neural networks,” Procedia Manufacturing, vol. 26,
2018, pp. 1159 – 1166, 46th SME North American Manufacturing
Research Conference, NAMRC 46, Texas, USA. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S235197891830828X
[12]
M. Darji, J. Dave, N. Asif, C. Godawat, V. Chudasama, and K. Upla,
“Licence plate identiﬁcation and recognition for non-helmeted mo-
torcyclists using light-weight convolution neural network,” in 2020
International Conference for Emerging Technology (INCET), 2020, pp.
1–6.
[13]
S. Shetty, A. S. Devadiga, S. S. Chakkaravarthy, and K. A. V. Kumar,
“Ote-ocr based text recognition and extraction from video frames,” in
2014 IEEE 8th International Conference on Intelligent Systems and
Control (ISCO), 2014, pp. 229–232.
[14]
P. L. Venetianer and H. Deng, “Performance evaluation of an intelligent
video surveillance system – a case study,” Computer Vision and Image
Understanding, vol. 114, no. 11, 2010, pp. 1292 – 1302, special issue
on Embedded Vision.
[15]
C. Stergiou, K. E. Psannis, A. P. Plageras, G. Kokkonis, and Y. Ishibashi,
“Architecture for security monitoring in iot environments,” in 2017
IEEE 26th International Symposium on Industrial Electronics (ISIE),
2017, pp. 1382–1385.
[16]
P. Gokhale and S. Singh, “Multi-platform strategies, approaches and
challenges for developing mobile applications,” in 2014 International
Conference on Circuits, Systems, Communication and Information
Technology Applications (CSCITA), 2014, pp. 289–293.
[17]
M. K. et al., “Hybrid software development approaches in practice: A
european perspective,” IEEE Software, vol. 36, no. 4, 2019, pp. 20–31.
[18]
N. Harth and C. Anagnostopoulos, “Edge-centric efﬁcient regression
analytics,” in 2018 IEEE International Conference on Edge Computing
(EDGE), 2018, pp. 93–100.
[19]
H. Wei, L. Gui, and F. Li, “A review of shock detection technology
based on embedded system,” in 2013 25th Chinese Control and Decision
Conference (CCDC), 2013, pp. 2336–2341.
[20]
N. Bazhenov and D. Korzun, “Smart video services based on edge com-
puting with multiple cameras,” in Proc. 26th Conf. Open Innovations
Association FRUCT, Apr. 2020, pp. 485–490.
[21]
S. Chakravarthy and D. Mishra, “Snoop: An expressive event speciﬁ-
cation language for active databases,” Data & Knowledge Engineering,
vol. 14, no. 1, 1994, pp. 1 – 26.
[22]
R. Adaikkalavan and S. Chakravarthy, “Snoopib: Interval-based event
speciﬁcation and detection for active databases,” Data & Knowledge
Engineering, vol. 59, no. 1, 2006, pp. 139 – 165.
18
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-811-2
UBICOMM 2020 : The Fourteenth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

