An Implementation Approach for Inter-Cloud Service Combination
Jie Tao, Daniel Franz, Holger Marten, and Achim Streit
Steinbuch Center for Computing
Karlsruhe Institute of Technology, Germany
{jie.tao, holger.marten, achim.streit}@kit.edu, daniel2712@gmx.de
Abstract—Increasing cloud platforms have been developed
in the recent time and are provisioning different services to
customers. The existence of different cloud provides offers the
users an opportunity of combining different cloud services
to run their scientiﬁc workﬂows with lower cost and higher
performance. In this work we developed a framework to
allow combining individual services of different clouds to solve
complex problems with efﬁciency. The framework contains a
workﬂow management system that processes users workﬂow
descriptions and starts the related services automatically on
the target clouds. A data management component takes care of
the data exchange between the underlying clouds. Moreover, a
prediction model computes the potential cost and performance
of running a workﬂow on existing clouds, giving users help
in selecting the execution target for better performance/cost
effect.
Keywords-Service Composition, Cloud Computing, Workﬂow
Engine, Cloud Interoperability
I. INTRODUCTION
Cloud Computing is an emerging technology for pro-
viding IT capacities as services. Increasing number of
customers is using the resources, such as computational
power, software, storage, and network, offered by various
cloud providers for their daily computation requirement.
However, inter-cloud computing is still a novel topic. We
developed a workﬂow framework to enable the interaction
across different cloud infrastructures [1].
The service concept has been proposed for several
decades. However, the term of Cloud Computing was known
ﬁrst in 2008 as Amazon published its Elastic Compute
Cloud (EC2) [2] and Simple Storage Service (S3) [3]. Cloud
Computing became thereafter a hot topic in both industrial
and academic areas. There exist different deﬁnitions of
Cloud Computing, including our earlier contribution [4].
Recently, the National Institute of Standards and Technology
(NIST) provides a speciﬁc deﬁnition: Cloud Computing
is a model for enabling convenient, on-demand network
access to a shared pool of conﬁgurable computing resources
(e.g., networks, servers, storage, applications, and services)
that can be rapidly provisioned and released with minimal
management effort or service provider interaction [5].
A speciﬁc feature of Cloud Computing is that computation
and storage resources are provided as services. In this
way, applications/software can be executed or maintained on
the cloud without the necessity of operating an own local
infrastructure. Such a computing model signiﬁcantly reduces
the cost for resource and software management, which is
clearly an attractive beneﬁt for small business companies
and research groups. In addition to cost-efﬁciency, Cloud
Computing shows other advantages such as on-demand re-
source provision, supporting legacy codes, service reliability,
easy management, and so on. Therefore, more and more
cloud infrastructures are established and increasing numbers
of users are joining the cloud world.
The fact that different cloud providers exist brings a
chance to users: combining different cloud services to efﬁ-
ciently solve a complex problem. However, it also introduces
difﬁculties for deciding to choose which cloud in case
of multiple identical services. Depending on the size and
requirement of tasks as well as the hardware conﬁguration
of clouds the tasks may perform better on some platforms
than on others.
The goal of this work is to design and prototypically
implement a management system that combines different
cloud services to run a user-deﬁned workﬂow with an
additional functionality of helping users select the cloud
providers.
A workﬂow is a methodology that splits the computation
of a complex problem into several tasks. A well-known
scenario is to run scientiﬁc experiments on the Grid [6],
where an entire computation is partitioned and distributed
over several computing nodes with a result of being able
to process large data sets. This scenario can also occur
on the cloud when scientiﬁc applications move to them.
Furthermore, there are other scenarios on the cloud, where
users require the workﬂow support. For example, users may
compose the services provided by different clouds to beneﬁt
from their diverse functionality and to achieve a better
performance/cost ratio.
Currently, it is possible to run a workﬂow on the cloud
[7]. However, running workﬂows is still limited to a single
cloud platform. The partitions (called tasks) of a workﬂow,
however, may have different behavior on different clouds,
indicating a requirement of running workﬂows across several
cloud platforms.
To enable this execution mode we developed a workﬂow
management system with a workﬂow engine, a data man-
agement component, and a mathematical model for perfor-
mance and cost prediction. In difference to Grid workﬂow
65
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

implementations that target on a uniﬁed interface [8], a
cloud workﬂow system has to cope with different interfaces
and features of individual clouds. In order to enable the
combination of single workﬂow tasks running on various
clouds, we implemented a cloud abstraction layer to deliver
common access interfaces. The developed framework was
tested with several sample workﬂows.
The remainder of the paper is organized as following.
Section II gives a short introduction of Cloud Computing,
together with some related work. Section III analyzes the
requirement on a cloud workﬂow framework and presents
the designed software architecture. Section IV describes our
initial prototypical implementation of the workﬂow frame-
work in detail. Section V shows the experimental results
with sample workﬂows. The paper concludes in Section VI
with a short summary and several future directions.
II. BACKGROUND AND RELATED WORK
Cloud Computing introduces a new computing paradigm.
This paradigm uses virtualization as its fundamental technol-
ogy. A traditional computer system runs applications directly
on the complete physical machine. Using virtualization, ap-
plications are executed on virtual machines (VM), with each
VM typically running a single application and a different
operating system.
Cloud Computing distinguishes itself from other comput-
ing paradigms, like Grid Computing, Global Computing, and
Internet Computing, in the following aspects:
• Utility computing model: users obtain and employ com-
puting platforms in computing clouds as easily as they
access a traditional public utility (such as electricity,
water, natural gas, or telephone network).
• On-demand service provisioning: computing clouds
provide resources and services for users on demand.
Users can customize and personalize their computing
environments later on, for example, software instal-
lation, network conﬁguration, as users usually own
administrative privileges.
• QoS guaranteed offer: the computing environments
provided by computing clouds can guarantee QoS for
users, e.g., hardware performance like CPU speed, I/O
bandwidth and memory size. The computing cloud
renders QoS in general by processing Service Level
Agreement (SLA) with users.
• Autonomous system: the computing cloud is an au-
tonomous system and it is managed transparently to
users. Hardware, software and data inside clouds can
be automatically reconﬁgured, orchestrated and con-
solidated to present a single platform image, ﬁnally
rendered to the users.
• Security: the host system monitors the communication
to the VMs, restricting the number of successful at-
tacks. Even if an attack is effective, the attack could
only compromise one VM, while the other applications
and operating systems maintain a secure state.
• Availability: VMs can be easily migrated increasing the
system’s fault tolerance and availability.
Currently established cloud infrastructures mainly deliver
three kinds of services: Infrastructure as a Service (IaaS),
Software as a Service (SaaS), and Platform as a Service.
IaaS targets on an on-demand provision of the computa-
tional resources. The commercial computing cloud Amazon
EC2 and its non-commercial implementation Eucalyptus [9]
are well-known examples of IaaS-featured cloud platforms.
SaaS allows the consumers to use the provider’s applications
running on a cloud infrastructure. The applications are
accessible from various client devices through a thin client
interface [5]. An example of SaaS is Web-based email.
PaaS targets on an entire platform including the hardware
and the application development environment. Google App
Engine [10] and Microsoft Azure [11] are examples of PaaS-
featured clouds.
The concept of resource sharing in Cloud Computing is
similar to Grid Computing. Cloud Computing allows on-
demand resource creation and easy access to resources,
while Grid Computing developed standards and provides
various utilities. Table I shows several major features of both
computing paradigms. A detailed comparison between Grid
and Cloud Computing can be found in [12].
One utility implemented on the Grid is the workﬂow
management system. Production Grids, such as WLCG [13],
TeraGrid [14], and EGEE [15], commonly support the exe-
cution of scientiﬁc workﬂows on the underlying resources.
There are also various implementations of workﬂow engines
on the Grid. Examples are ASKALON [16], Unicore [17],
Kepler [18], GridAnt [19], Pegasus [20], and GridFlow [21].
An overview of these workﬂow systems is presented in [22].
The research work on workﬂow management systems on
the cloud has been started. A well-known project is the
Cloudbus Toolkit [23] that deﬁnes a complete architecture
for creating market-oriented clouds. A workﬂow engine is
also mentioned in the designed architecture and described
in detail in [24]. The authors analyzed the requirement and
changes needed to be incorporated when moving scientiﬁc
workﬂows to clouds. They also described the visions and
inherent difﬁculties when a workﬂow involves various cloud
services.
In the sense of service combination, there are several
efforts on automated processes [25]–[27]. For service com-
position on the cloud research issues have been discussed
[28], [29] and practices have been conducted as well [30]. In
addition, there are also activities on preparing and executing
workﬂows [31] on such composite services. Recently, sci-
entists proposed the idea of “federated clouds” [32], which
can effectively utilize several clouds to enhance the QoS.
Existing work on cloud workﬂow systems is either in the
research phase or an implementation work within a single
66
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Table I
CLOUD VS. GRID: A FUNDAMENTAL COMPARISON.
Cloud Computing
Grid Computing
Objective
Provide desired computing platform
Resource sharing
via network enabled services
Job execution
Infrastructure
One or few data centers
Geographically distributed,
heterogeneous/homogeneous resources
heterogeneous resources,
under central control
no central control, VO
Industry and business
Research and academic organization
Middleware
Proprietary, several reference implementations
Well developed, maintained,
exist, e.g., Amazon
and documented
Application
Suited for general applications
Special application domains
like High Energy Physics
User interface
Easy to use/deploy, no complex user
Difﬁcult to use and to deploy
interface required
Need new user interface,
e.g., commands, APIs, SDKs, services
Business model
Commercial: pay-as-you-use
Publicly funded: use for free
Enabling technology
Virtualization, SaaS, Web 2.0, Web service, ...
HPC, Grid infrastructure, middleware
QoS
Possible
Little support
On-demand provisioning
Yes
No
cloud platform. The work presented in this paper aims at
a prototypical implementation of a workﬂow engine that
enables the execution of a workﬂow across different cloud
platforms thereby using their individual services. Such a tool
is currently still not available. Our goal is to simply provide a
new functionality rather than to investigate a comprehensive
solution. Therefore, we majorly focus on the design of an
architecture and a prototypical implementation with basic
functionalities. Our main contributions are the workﬂow
engine that enables inter-cloud service combination and the
proposal of a prediction model for estimating the execution
time of tasks on different clouds.
III. ARCHITECTURE DESIGN
Grid Computing has been investigated for more than a
dozen of years and established standards. Cloud Computing,
in contrast, is a novel technology and has not been standard-
ized. The speciﬁc feature of each cloud brings additional
challenges to implementing a workﬂow engine on clouds.
A. Design Challenges
Grid workﬂows may be executed in several resource
centers but the involved resources are contained in a single
Grid infrastructure and hence can be accessed with the
same interface. Cloud workﬂows, however, run usually on
different clouds.
Figure 1 shows a sample scenario of running workﬂows
on clouds. While some tasks may be executed on the same
cloud, e.g., cloud C1, some others may run on different
cloud platforms. The data are transferred from one cloud
to another in order to deliver the output of one task to
other tasks. Unfortunately, different clouds use also different
data format. Furthermore, existing clouds have their own
access interfaces. A standard, called Open Cloud Computing
Interface (OCCI) [33], has been proposed and several imple-
mentations are currently available. However, this standard is
C6
C1
C2
C3
C4
C5
Figure 1.
A sample execution scenario of cloud workﬂows.
only supported by a few cloud infrastructures. To link the
services of different clouds, an abstraction layer is therefore
required for providing an identical view with the data and
interfaces of the target cloud infrastructures.
Additionally,
the
service
price
varies
across
cloud
providers. Cloud users usually expect an optimal perfor-
mance vs. cost tradeoff: i.e., acquiring the best service
with the lowest payment. While increasing number of cloud
infrastructures is emerging, there may be several choices to
run a workﬂow task. A prediction model, which is capable
of estimating the performance and cost of an execution on
a speciﬁc cloud, can help users select an appropriate cloud
for their tasks.
Based on the aforementioned observations, we designed
a software architecture for the proposed cloud workﬂow
engine and deﬁned a performance-cost model. The following
two subsections give some details.
B. Software Architecture
Figure 2 demonstrates the software architecture of the pro-
posed workﬂow engine for Cloud Computing. It contains a
67
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

      Mediator
       Cloud API
Example: RunNode(User, ResourceID)
RunServer(UserID, RamSize, CPUCount)
StartNode(UserHandle, NodeHandle, ImageHandle)
Access Interface
      Cloud A
Workflow Runtime
      Cloud B
Access Interface
Figure 2.
Software architecture of the workﬂow engine.
workﬂow runtime system, the cloud API, and the underlying
cloud infrastructures. Users submit their workﬂows using
a client side interface. Based on the description of tasks
in a workﬂow, the execution time of the tasks on different
clouds is predicted. Using this information users extend the
workﬂow description by specifying a target cloud for each
task. In the following, the workﬂow runtime handles the
execution of tasks on the clouds and delivers the results to
the users.
An important component in the architecture is the cloud
abstraction layer, shown in the middle of Figure 2. The task
of this layer is to implement a uniﬁed API for accessing
different clouds. The runtime environment of the workﬂow
engine uses this API to run the tasks in a workﬂow.
The abstraction layer deﬁnes common functions for cloud
activities. It also contains a mediator that translates the func-
tions in the uniﬁed API to concrete calls to the underlying
cloud platforms. For example, the function RunNode() is
provided for running a virtual machine instance on any IaaS-
featured cloud. During the runtime the mediator replaces
the function by a cloud speciﬁc one, in this example, either
StartNode for cloud A or RunServer for cloud B. It also
maps the function parameters in the functions of the uniﬁed
API to the functions of the APIs of individual clouds. Fur-
thermore, the mediator handles the authentication/security
issues.
C. Prediction Model
Cloud users not only take care of the execution perfor-
mance but pay more attention to the payment for using
resources on the clouds. As an initial design, we bring the
two most important metrics, application execution time and
the cost, into the prediction model. Workﬂows in this work
are deﬁned as: A workﬂow is comprised of several tasks,
each is combined with an application/software that is either
executed on an IaaS-cloud or hosted as a Web service on a
SaaS/PaaS-cloud.
The execution time of a workﬂow (EoW in short) can be
calculated with the following mathematical form:
EoW = EoT1 + DT1 + EoT2 + DT2 + .... + EoTn
(1)
where EoTi is the execution time of task i and DTi is the
time for transferring data from Ti to Ti+1. Note that we
ignore the time to start a service on the cloud as well as
data transfers from and back to the customer environment.
The execution time of a single task depends on the
features of the host machine on which the task is running.
Roughly, it can be presented with:
EoT = f(Scomp, Fcpu, Smem, SI/O)
(2)
where the parameters are size of the computation, frequency
of CPU, size of memory and cache, and size of the input/out-
put data. For parallel applications, an additional parameter,
the communication speed, has to be considered.
The price of a service on a cloud is usually determined by
the node type and the location of the resource. Each cloud
provider maintains a price table, where concrete payment (in
US$ per hour) is depicted. Based on this table, we calculate
the cost of a workﬂow task with:
CoT = f(EoT, $/h)
(3)
The cost of executing a workﬂow is then calculated as
following:
CoW = CoT1 + CoT2 + .... + CoTn
(4)
The functions for computing the execution time of a
task can be designed differently with a tradeoff between
complexity and accuracy. We implemented a simple model,
which is detailed in the next section.
IV. INITIAL IMPLEMENTATION
Based on the designed architecture described above, we
implemented a prototype of the cloud workﬂow framework.
This initial implementation focused on the following com-
ponents:
• Cloud abstraction
• Runtime execution environment and data management
• Prediction model
A. Cloud Abstraction
To run a workﬂow on diverse clouds, an abstraction layer
is required for the purpose of hiding the different access
interface each cloud presents to the users. We use jClouds
[34] as the base of this work. jClouds provides a framework
for transferring programs and their data to an IaaS-cloud and
then starting an instance to execute the program on the cloud.
The current release of jCloud can connect several IaaS-
clouds including Amazon EC2. There are other IaaS cloud
68
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

abstraction libraries, such as libcloud [35] and deltacloud
[36]. We use jCloud as the base of this work due to its
feature of supporting SSH and a number of cloud providers.
jClouds deﬁnes an API for accessing the underlying
IaaS platforms. For SaaS/PaaS-featured clouds, however,
there exists currently no implementation for an abstraction
layer. Our main task in extending jClouds is to develop an
S+P abstraction that interacts with SaaS-featured and PaaS-
featured clouds.
The S+P abstraction contains two kinds of functions, GET
and POST, for transferring data and service requests. Their
input and output are deﬁned in XML documents. This is
identical to all clouds. Each cloud, however, requires speciﬁc
input and output formats as well as different parameters for
service requests. Our solution is to use XSL Transformation
(XSLT) [37] to map the input and output of the service
functions to the required data format and service parameters.
XSLT is a part of the Extensible Stylesheet Language
(XSL) family and usually adopted to transform XML doc-
uments. An XSLT ﬁle describes templates for matching the
source document. In the transformation process, XSLT uses
XPath, an interface for accessing XML, to navigate through
the source document and thereby to extract information or to
combine/reorganize the separate information elements. For
this work an XSLT document is introduced for some data
formats, like SOAP. For others, such as binary and JSON
(JavaScript Object Notation), a data transformation is not
needed.
SaaS/PaaS services are started via HTTP-based protocols.
A service request is sent to the service URL via GET/POST.
Information like Cookies, SOAP actions and other parame-
ters can be wrapped in the message head. The content of the
call is either contained in the body of the HTTP message
in case of POST calls or coded in the URL in case of GET
calls.
The process of invoking a SaaS or PaaS service with the
developed S+P abstraction contains the following steps:
• Processing the input data of the service request.
• Constructing a URL for the service. Information about
Cookies, SOAP actions, and other parameters, is con-
tained in the head of the message, while the body of
the message deﬁnes the request.
• A service request is sent to the aforementioned URL,
together with the data.
• The results of the service are downloaded as raw data.
For the data formats like SOAP, where the results are
coded, an XSLT document is deﬁned to extract the
useful information.
B. Workﬂow Execution and Inter-Cloud Data Transfer
In order to allow an easier understanding of the tasks for a
cloud workﬂow execution engine, we take a simple workﬂow
as an example. Figure 3 demonstrates the sample workﬂow
consisting of eight tasks, T-a to T-f, which are combined
T−f               
T−d1               
T−d2               
SaaS
SaaS
T−d3               
IaaS
T−e               
SaaS
IaaS
  T−c               
T−b               
SaaS
IaaS
  T−a               
IaaS
Figure 3.
A simple cloud workﬂow.
through a respective data ﬂow. A task can be a program or
an available Web service on a SaaS or PaaS cloud. For the
former, the program is executed on an IaaS cloud, while
for the latter the cloud provides resources for running the
software. The workﬂow and its tasks are deﬁned by the user
in the following XML ﬁle:
<w o r k f l o w d e f i n i t i o n>
<t a s k name=”a ”>
<i n p u t
f i l e t y p e =”some / type ” name=” i n ”
/>
<out put
f i l e t y p e =”some / type ” name=” oa ”
/>
</ t a s k>
<t a s k name=”b”>
<i n p u t
f i l e t y p e =”some / type ” name=” oa ”
/>
<out put
f i l e t y p e =”some / type ” name=”ob ”
/>
</ t a s k>
<t a s k name=”c ”>
<i n p u t
f i l e t y p e =”some / type ” name=” oa ”
/>
<out put
f i l e t y p e =”some / type ” name=” oc ”
/>
</ t a s k>
<t a s k name=”d1”>
<i n p u t
f i l e t y p e =”some / type ” name=”ob”
/>
<out put
f i l e t y p e =”some / type ” name=” od1 ”
/
>
</ t a s k>
<t a s k name=”d2”>
<i n p u t
f i l e t y p e =”some / type ” name=”ob”
/>
<out put
f i l e t y p e =”some / type ” name=” od2 ”
/
>
</ t a s k>
<t a s k name=”d3”>
<i n p u t
f i l e t y p e =”some / type ” name=”ob”
/>
<out put
f i l e t y p e =”some / type ” name=” od3 ”
/
>
</ t a s k>
<t a s k name=”e ”>
<i n p u t
f i l e t y p e =”some / type ” name=” oc ”
/>
<out put
f i l e t y p e =”some / type ” name=” oe ”
/>
</ t a s k>
<t a s k name=” f ”>
<i n p u t
f i l e t y p e =”some / type ” name=”od1 ”
/>
<i n p u t
f i l e t y p e =”some / type ” name=”od2 ”
/>
<i n p u t
f i l e t y p e =”some / type ” name=”od3 ”
/>
<i n p u t
f i l e t y p e =”some / type ” name=” oe ”
/>
<out put
f i l e t y p e =”some / type ” name=” of ”
/>
</ t a s k>
69
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

<workflow from=” a ”
t o=”b”
/>
<workflow from=” a ”
t o=” c”
/>
<workflow from=”b”
t o=”d1”
/>
<workflow from=”b”
t o=”d2”
/>
<workflow from=”b”
t o=”d3”
/>
<workflow from=” c ”
t o=” e”
/>
<workflow from=”d1”
t o=” f ”
/>
<workflow from=”d2”
t o=” f ”
/>
<workflow from=”d3”
t o=” f ”
/>
<workflow from=” e ”
t o=” f ”
/>
</ w o r k f l o w d e f i n i t i o n>
The workﬂow deﬁnition mainly describes the input and
output of each task and thereby also speciﬁes the data ﬂow
between the tasks. In the concrete example the root element
workﬂowdeﬁnition is speciﬁed by the tasks to be executed,
where each task is combined with an input node and an
output node. The last task f, for example, has four input
nodes describing the source of its input as shown in Figure
3. The last few lines of the XML document deﬁne the data
ﬂow between individual tasks, with help of the workﬂow
element. The data ﬂow from task a to task b and task c,
from task b to task d1, task d2, and task d3, and so on.
The tasks, however, are not deﬁned in the workﬂow
document but described in a separate conﬁguration ﬁle. An
example is a task for extracting texts from a video. This
task is used in a language translation workﬂow that will
be introduced in the next section. The following XML ﬁle
deﬁnes this task:
<t a s k name=” v i d e o t o t e x t ”
type =” IaaS ”>
<bi nary
name=” j u l i u s ”
p a r a l l e l =”
s e q u e n t i a l ”>
<i n p u t
type =” video / f l v ” param=” ”
/>
<out put
type =” t e x t / p l a i n ” param=” ”
/>
</ bi nary>
</ t a s k>
In the example, the IaaS task videototext is deﬁned with a
binary called julius that will be sequentially executed on an
IaaS cloud. The type of its input and output is also speciﬁed
in the XML ﬁle.
The primary work of the workﬂow execution engine is
to interpret the workﬂow deﬁnition and starts each of the
tasks on a cloud, based on the conﬁguration XML ﬁles. In
addition, the engine is also responsible for transferring the
result of one task to its successor and downloading the ﬁnal
results to the user. The ﬁrst task is performed within a single
cloud and contains the following steps, which are all covered
by the cloud abstraction described above:
• Transferring data (program or service parameters) to
the target cloud.
• Executing the program on an IaaS cloud or invoking
the Web service on the SaaS or PaaS cloud. In the case
of IaaS, a virtual machine instance has to be started
and some scripts are executed for conﬁguration and
program installation.
• Extracting the results out of the cloud.
To deliver the output of one task to the next task as
input, the workﬂow execution engine has to interact with
both participating clouds and to handle the inter-cloud com-
munication. We implemented mechanisms for the following
data transfers:
• IaaS to SaaS/PaaS: We use SSH to transfer data from
the IaaS node to the local host and then use HTTP to
deliver the data further to the SaaS/PaaS request;
• SaaS/PaaS to SaaS/PaaS: Data are extracted from the
HTTP stream, stored temporally on the host, and then
applied to the next HTTP request;
• SaaS/PaaS to IaaS: Locally storing the data, which
are again extracted from an HTTP stream, and then
transferring them to the IaaS node via SSH;
• IaaS to IaaS: We transfer the data directly from one
IaaS node to the other that is potentially located on a
different cloud. This is an optimization for removing
the overhead caused by an intermediate storage.
Finally, the result of the entire execution is downloaded
to the user or stored on the last cloud.
C. Performance & Cost Prediction
The proposed prediction model, as described in the pre-
vious section, involves several hardware parameters that can
be only acquired at the runtime by accessing the cloud
resources. For the prototypical implementation, we devel-
oped a simple model without using the runtime resource
information of the underlying infrastructures.
Our model is based on the execution history of similar
tasks, which are deﬁned as tasks executing the same pro-
gram. The execution history is stored in a user database that
contains the following main data structures:
• tasks: identiﬁes each individual task with a unique ID
and the associated program.
• I/O: deﬁnes the size of input and output ﬁles of tasks.
• node class: describes a computing node with node ID,
node name, cloud name, payment cycle, and startup
time.
• execution: describes an execution of a task on a
node with several attributes including program name,
node class, size of I/O, and execution time.
• node price: gives the per-cycle-price of the computing
nodes.
• node location: gives the country and continent the node
is located.
We use an SQLite [38] database system to store the
data structures. Figure 4 shows a screenshot of the SQLite
database browser, where the data structures and the stored
data are presented. The database browser allows us to simply
modify the data items and to view the data. As examples,
Figure 5 and 6 show the node and execution data collected
during our tests. The browser depicts the data in the form
of tables.
70
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 4.
The data structures in an SQLite database.
Figure 5.
Node class information stored in the SQLite database.
The concrete table in Figure 5 lists all possible computing
nodes on the Amazon EC2. EC2 uses a unit of one hour to
calculate the cost of running instance leading to a payment
cycle of 3600 (in seconds). We tested three different EC2
nodes and the startup time of these nodes can be seen in the
last column of the table.
We also tested different tasks on various computing nodes.
The table in Figure 6 depicts the execution information of
the ﬁrst twelve tests, with the data size of the task on the
Figure 6.
Task execution information stored in the SQLite database.
ﬁrst column, the ID of the target computing node on the
second, the task ID on the third, the number of nodes used
for the test on the fourth, and the execution time on the
last column. The sixth line, for example, shows that task 2
with an input data of 65964 bytes was executed on two EC2
“c1.medium” nodes (node ID 8) in 47 seconds.
For each task in a new user-deﬁned workﬂow, the potential
execution time is calculated for all registered clouds and
their associated computing nodes. The payment is then
calculated according to the price published by the cloud
providers. The ﬁrst ﬁve {cloud, node} pairs with the best
performance vs. cost tradeoff are shown to the users to help
them select the optimal target platforms.
We use the following algorithm to predict the execution
time of a new task presented with t(p,s), where the ﬁrst
attribute is the program to be executed and s is the size of
the input data.
First, the average execution time of the program on a node
ns is calculated with the following equation:
t(p,ns) =
nP
i=1
ti(p,ns,si)
n
where ti(p,ns,si) is the time measured with the recorded
ith execution of program p on node ns with a data size of si,
and n is the number of executions. Here, t(p,ns) is associated
with the average data size s(p,ns), which is calculated in a
similar way. The execution time of the new task t(p,s) can
then be estimated with
t(p,s) =
s
s(p,ns) · t(p,ns)
Wdata
71
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Table II
AN EXAMPLE OF EXECUTION HISTORY.
Tests
Size of data (KB)
Execution time (seconds)
1
300
15
2
100
12
3
200
13
4
250
14
5
300
14
We introduce a weight variable Wdata to represent the
inﬂuence degree of the input size on the execution time.
The value of this variable may vary from task to task and
shall be choosen based on experimental results.
Now we show an example for a better understanding of
the prediction model. The sample data is depicted in Table II,
which contains ﬁve history executions on a computing node.
The size of data is presented in Kbytes while the execution
time in seconds.
According to the data in the table, we acquire the calcu-
lation results as:
t(p,ns) = 15 + 12 + 13 + 14 + 14
5
= 13.6
s(p,ns) = 300 + 100 + 200 + 250 + 300
5
= 230
The execution time of task t(p,150) on the related comput-
ing node is:
150
230 · 13.6
0.7
= 12.67
where we assume an I/O inﬂuence of weight 0.7 to the
execution of the program.
V. EXPERIMENTAL RESULTS
To evaluate the developed framework, several workﬂows
were tested. In this section, we present the results with two
examples. The ﬁrst workﬂow processes 3D scenes with a
result of creating a video. The second workﬂow performs
ﬁlm synchronization whereby to translate the spoken text
from Japanese to English.
The ﬁrst workﬂow, depicted in Figure 7, contains two
main tasks, 3dscenetopictures (the raytracer) and picture-
tovideo. The raytracer acquires a scene ﬁle and a camera ﬁle
as input and splits the scene into single pictures based on the
position deﬁned in the camera ﬁle. The single pictures are
then processed by the second task to produce a continuous
video.
We apply the Tachyon [39] raytracer for the ﬁrst task
which needs an MPI cluster on an IaaS cloud because the
software is parallelized with MPI. To combine the pictures
to a video, the program FFmpeg [40] is applied. We run this
task on a single IaaS node. The workﬂow is deﬁned in the
following XML ﬁle:
<w o r k f l o w d e f i n i t i o n>
<t a s k name=”3 d s c e n e s t o p i c t u r e s ”>
<i n p u t
f i l e t y p e =” ∗. dat ” name=” scene ”
/>
<i n p u t
f i l e t y p e =” ∗. cam” name=” camera ”
/>
<out put
f i l e t y p e =” image / ppm” name=” images
”
/>
</ t a s k>
<t a s k name=” p i c t u r e s t o v i d e o ”>
<i n p u t
f i l e t y p e =” image / ppm” name=” images ”
/>
<out put
f i l e t y p e =” video / avi ” name=” video ”
/>
</ t a s k>
<workflow from=”3 d s c e n e s t o p i c t u r e s ”
t o =” p i c t u r e s t o v i d e o ”
/>
</ w o r k f l o w d e f i n i t i o n>
The second workﬂow, as shown in Figure 8, is comprised
of four components: the language identiﬁer (task videoto-
text), a translator (task translatejatoen), the text synthesizer
(task texttospeech), and the task jointovideo. The language
identiﬁer acquires a video ﬁle as input and outputs its text
in Japanese. The output is then delivered to the language
translator, where an English text is produced. In the follow-
ing, the text synthesizer converts the text to speech, which
is combined with the video via the last task of the workﬂow.
We apply the language identiﬁer Julius [41] to process the
audio that is extracted from the video by FFmpeg. In order
to speed up the process, an audio is ﬁrst partitioned and
the partitions are then processed in parallel. Hence, an MPI
cluster is required for this task. For language translation, the
translation service of Google is applied. In order to model a
SaaS to SaaS data transfer and to verify our cloud abstrac-
tion, the Japanese text is ﬁrst translated to German and then
to English. The task texttospeech is implemented using the
speech synthesizer eSpeak [42]. Finally, the aforementioned
FFmpeg program combines the audio with the video. The
workﬂow deﬁnition is as following:
<w o r k f l o w d e f i n i t i o n>
<t a s k name=” v i d e o t o t e x t ”>
<i n p u t
f i l e t y p e =” video / f l v ” name=” video ”
/>
<out put
f i l e t y p e =” t e x t / p l a i n ” name=”
j a t e x t ”
/>
</ t a s k>
<t a s k name=” t r a n s l a t e j a t o d e ”>
<i n p u t
f i l e t y p e =” t e x t / p l a i n ” name=” j a t e x t
”
/>
<out put
f i l e t y p e =” t e x t / p l a i n ” name=”
d e t e x t ”
/>
</ t a s k>
<t a s k name=” t r a n s l a t e d e t o e n ”>
<i n p u t
f i l e t y p e =” t e x t / p l a i n ” name=” d e t e x t
”
/>
<out put
f i l e t y p e =” t e x t / p l a i n ” name=”
e n t e x t ”
/>
</ t a s k>
<t a s k name=” t e x t t o s p e e c h ”>
<i n p u t
f i l e t y p e =” t e s t / p l a i n ” name=” e n t e x t
”
/>
72
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 7.
Data ﬂow of the 3D-render workﬂow.
Figure 8.
Data ﬂow of the workﬂow ﬁlm synchronization.
<out put
f i l e t y p e =” audio / wave” name=” audio
”
/>
</ t a s k>
<t a s k name=” j o i n t o v i d e o ”>
<i n p u t
f i l e t y p e =” video / f l v ” name=” video ”
/>
<i n p u t
f i l e t y p e =” audio / wave ” name=” audio ”
/>
<out put
f i l e t y p e =” video / f l v ” name=”
r e s u l t v i d e o ”
/>
</ t a s k>
<workflow from=” v i d e o t o t e x t ”
t o =”
t r a n s l a t e j a t o e n ”
/>
<workflow from=” t r a n s l a t e j a t o d e ”
t o=”
t r a n s l a t e d e t o e n ”
/>
<workflow from=” t r a n s l a t e d e t o e n ”
t o=”
t e x t t o s p e e c h ”
/>
<workflow from=” t e x t t o s p e e c h ”
t o =”
j o i n t o v i d e o ”
/>
</ w o r k f l o w d e f i n i t i o n>
For the experiments we requested an account on EC2. The
test results are shown in Table III and Table IV for each
workﬂow. The tables show the execution time of tasks of a
single workﬂow on different nodes of EC2. In the case of
Google, the Web service is executed on a Google machine,
which cannot be speciﬁed by the user.
The execution time of a task is presented with the mea-
sured time and the predicted one, where the former was
acquired at runtime by measuring the duration of a task
from submission to termination and the latter was calculated
using the developed prediction model. It can be seen that the
accuracy of our model varies between the tasks, where the
value with the second workﬂow is relative better. For the
3D render, the model underestimates the execution time in
most cases, while an alternating behavior can be seen with
the second workﬂow. Altogether, we achieved the best case
with a difference of 3.4% between the real execution time
and the predicted one, while the worse case shows a value
of -21.2%. The difference is caused by the fact that the
time for executing a program can vary signiﬁcantly from
one execution to the other, even though the executions are
performed successively. This indicates that a more accurate
model is required for a better prediction, which shall be our
future work.
The values in the last column of the tables are calculated
by multiplying the real execution time by the payment. It
is expected that both the execution time and the payment
are low. Hence, we use the values in the last column to
represent the performance vs. cost tradeoff, where a lower
value indicates a better behavior. Observing Table III it can
be seen that the nodes “m1.small” have a better behavior.
This may be associated with the concrete tasks, which do not
demand a high computation capacity. With larger programs,
e.g., the task videototext in the second workﬂow, a node
with higher capacity, “m1.large” in this case, behaves better.
However, the best choice is to use the free services provided
by some clouds, such as the translation service on Google.
VI. CONCLUSIONS AND FUTURE WORK
As various cloud platforms are emerging, it is possible
for users to involve several clouds to run a complex job,
73
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Table III
EXPERIMENTAL RESULTS WITH THE 3D RENDER WORKFLOW (85 CAMERA POSITIONS).
Task
Node
Execution time
Performance vs. Cost
Measured
Predicted
Difference (%)
m1.small
145
138
-4.8
12.40
3dscenetopictures
c1.medium
56
52
-7.1
19.03
m1.large
48
42
-12.5
17.97
m1.small
59
48
-18.6
5.01
picturetovideo
c1.medium
47
37
-21.2
15.97
m1.large
44
36
-18.2
14.96
Table IV
EXPERIMENTAL RESULTS WITH THE WORKFLOW OF SYNCHRONIZING A FOUR MINUTES VIDEO.
Task
Node
Execution time
Performance vs. Cost
Measured
Predicted
Difference (%)
m1.small
665
688
3.4
168.04
videototext
c1.medium
341
355
4.1
116.30
m1.large
257
271
5.4
87.20
translatejatoen
45
40
-11.1
0
m1.small
26
22
-15.4
1.87
texttospeech
c1.medium
22
20
-9.1
7.47
m1.large
19
17
-10.5
6.46
m1.small
89
104
16.8
7.60
jointovideo
c1.medium
87
94
8.0
29.60
m1.large
97
75
-12.4
33.02
for example, a workﬂow. For this functionality, users need
a framework to manage the execution of single tasks on
different clouds and to deliver the result of one task to
another task that may run on a different infrastructure.
We designed and implemented such a workﬂow manage-
ment system for cloud users. The main components of the
framework includes a workﬂow engine for task execution, a
cloud abstraction to enable the interoperability of different
cloud platforms, a data management component that handles
inter-cloud communications, and a prediction model for
estimating the cost and performance of running the workﬂow
tasks on different cloud nodes. Initial experiments on the
prototypical implementation showed the functionality of the
framework.
In the next step of this work we will improve the predic-
tion model with involvement of the runtime information of
the cloud platforms. We will also provide the users with
a more friendly interface to describe their workﬂows. A
resource broker is planed as well to serve as a mediator
for users to detect the best cloud services.
REFERENCES
[1] D. Franz, J. Tao, H. Marten, and A. Streit, “A Workﬂow
Engine for Computing Clouds,” in Proceedings of the 2nd
International Conference on Cloud Computing, GRIDs, and
Virtualization (CLOUD COMPUTING 2011). ISBN: 978-1-
61208-153-3, Roma, Italy, September 2011.
[2] “Amazon Elastic Compute Cloud,” [Online], http://aws.
amazon.com/ec2/ (accessed: 2012-06-20).
[3] “Simple Storage Service,” [Online], http://aws.amazon.com/
s3/ (accessed: 2012-06-20).
[4] L. Wang, M. Kunze, and J. Tao, “Performance evaluation of
virtual machine-based Grid workﬂow system,” Concurrency
and Computation: Practice & Experience, vol. 20, pp. 1759–
1771, October 2008.
[5] P. Mell and T. Grance, “The NIST Deﬁnition of Cloud
Computing,” [Online], http://csrc.nist.gov/publications/drafts/
800-145/Draft-SP-800-145 cloud-deﬁnition.pdf
(accessed:
2012-06-20).
[6] B. Asvija, K. V. Shamjith, R. Sridharan, and S. Chattopad-
hyay, “Provisioning the MM5 Meteorological Model as Grid
Scientiﬁc Workﬂow,” in Proceedings of the International
Conference on Intelligent Networking and Collaborative Sys-
tems, 2010, pp. 310–314.
[7] Y. Wei and M. B. Blake, “Service-Oriented Computing and
Cloud Computing: Challenges and Opportunities,” IEEE In-
ternet Computing, vol. 14, no. 6, pp. 72–75, 2010.
[8] G. Fox and D. Gannon, “Special Issue: Workﬂow in Grid
Systems,” Concurrency and Computation: Practice and Ex-
perience, vol. 18, no. 10, pp. 1009–1019, 2006.
[9] D. Nurmi, R. Wolski, C. Grzegorczyk, G. Obertelli, S. Soman,
L. Youseff, and D. Zagorodnov, “The Eucalyptus Open-source
Cloud-computing System,” in Proceedings of Cloud Com-
puting and Its Applications, October 2008, available: http:
//eucalyptus.cs.ucsb.edu/wiki/Presentations (accessed: 2012-
06-20).
[10] “Google
App Engine,”
[Online], http://code.google.com/
appengine/ (accessed: 2012-06-20).
[11] “Windows Azure Platform,” [Online], http://www.microsoft.
com/windowsazure/ (accessed: 2012-06-20).
74
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[12] I. Foster, Y. Zhao, I. Raicu, and S. Lu, “Cloud Computing and
Grid Computing 360-Degree Compared,” in Proceedings of
the Grid Computing Environments Workshop, 2008. GCE’08,
2008, pp. 1–10.
[13] WLCG,
“Worldwide
LHC
Computing
Grid,”
[Online],
http://lcg.web.cern.ch/lcg/ (accessed: 2012-06-20).
[14] P. H. Beckman, “Building the TeraGrid,” Philosophical trans-
actions - Royal Society. Mathematical, physical and engineer-
ing sciences, vol. 363, no. 1833, pp. 1715–1728, 2005.
[15] EGEE, “Enabling Grids for E-sciencE,” [Online], project
homepage: http://www.eu-egee.org/ (accessed: 2012-06-20).
[16] T. Fahringer, A. Jugravu, S. Pllana, R. Prodan, C. S. Jr,
and H. L. Truong, “ASKALON: a tool set for cluster and
Grid computing,” Concurrency and Computation: Practice &
Experience, vol. 17, pp. 143–169, February 2005.
[17] M. Riedel, D. Mallmann, and A. Streit, “Enhancing Scientiﬁc
Workﬂows with Secure Shell Functionality in UNICORE
Grids,” in Proceedings of the IEEE International Conference
on e-Science and Grid Computing.
IEEE Computer Society
Press, December 2005, pp. 132–139.
[18] D. Barseghian, I. Altintas, M. B. Jones, D. Crawl, N. Potter,
J. Gallagher, P. Cornillon, M. Schildhauer, E. T. Borer, E. W.
Seabloom, and P. R. Hosseini, “Workﬂows and extensions to
the Kepler scientiﬁc workﬂow system to support environmen-
tal sensor data access and analysis,” Ecological Informatics,
vol. 5, pp. 42–50, 2010.
[19] G. von Laszewski, K. Amin, M. Hategan, N. J. Z. S. Hampton,
and A. Rossi, “GridAnt: A Client-Controllable Grid Workﬂow
System,” in 37th Hawaii International Conference on System
Science.
IEEE CS Press, January 2004.
[20] S., D. Karastoyanova, and E. Deelman, “Bridging the Gap
between Business and Scientiﬁc Workﬂows: Humans in the
Loop of Scientiﬁc Workﬂows,” in IEEE International Con-
ference on eScience, 2010, pp. 206–213.
[21] J. Cao, S. A. Jarvis, S. Saini, and G. R. Nudd, “Grid-
Flow:Workﬂow Management for Grid Computing,” in Pro-
ceedings of the International Symposium on Cluster Comput-
ing and the Grid, May 2003, pp. 198–205.
[22] J. Yu and R. Buyya, “A Taxonomy of Workﬂow Management
Systems for Grid Computing,” Journal of Grid Computing,
vol. 3, no. 3-4, pp. 171–200, September 2005.
[23] R. Buyya, S. Pandey, and C. Vecchiola, “Cloudbus Toolkit
for Market-Oriented Cloud Computing,” in Proceeding of the
1st International Conference on Cloud Computing, December
2009, pp. 978–642.
[24] S. Pandey, D. Karunamoorthy, and R. Buyya, Cloud Comput-
ing: Principles and Paradigms. Wiley Press, February 2011,
ch. 12, pp. 321–344.
[25] S. McIlraith, T. C. Son, and H. Zeng, “Semantic web ser-
vices,” IEEE Intelligent Systems, vol. 16, pp. 46–53, 2001.
[26] D. Fensel and C. Bussler, “The web service modeling frame-
work WSMF,” Electronic Commerce Research and Applica-
tions, vol. 1, pp. 113–117, 2002.
[27] R. Aggarwal, K. Verma, J. Miller, and W. Milnor, “Con-
straint driven Web service composition in METEOR-S,” in
Proceedings of the IEEE International Conference on Service
Computing, 2004, pp. 23–30.
[28] F. Tao, L. Zhang, and Y. Hu, Cloud Manufacturing: Develop-
ment and Commerce Realization of MGrid, in Resource Ser-
vice Management in Manufacturing Grid System. John Wiley
& Sons, Inc, 2012, ch. 15, doi: 10.1002/9781118288764.
[29] C.-H. Hsuand and H. Jin, “Services Composition and Vir-
tualization Technologies,” IEEE Transactions on Services
Computing, vol. 4, no. 3, pp. 181–182, 2011.
[30] S. Wang, Q. Sun, H. Zou, and F. Yang, “Particle Swarm Op-
timization with Skyline Operator for Fast Cloud-based Web
Service Composition,” Mobile Networks and Applications,
April 2012, online available: DOI: 10.1007/s11036-012-0373-
3.
[31] “The OASIS committee, Web Services Business Process
Execution Language (WS-BPEL),” [Online], http://www.
oasis-open.org/committees/tc home.php?wg abbrev=wsbpel
(accessed: 2012-06-20).
[32] B. Rochwerger, D. Breitgand, A. Epstein, D. Hadas, I. Loy,
K. Nagin, J. Tordsson, C. Ragusa, M. Villari, S. Clayman,
E. Levy, A.Maraschini, P. Massonet, H. Munoz, and G. Tof-
fetti, “Reservoir - When One Cloud Is Not Enough,” IEEE
computer, vol. 44, no. 3, pp. 45–51, March 2011.
[33] “Open Cloud Computing Interface,” [Online], http://occi-wg.
org/ (accessed: 2012-06-20).
[34] “jclouds,” [Online], http://www.jclouds.org/ (accessed: 2012-
06-20).
[35] “Apache Libcloud – a uniﬁed interface to the cloud,” [Online],
http://libcloud.apache.org/ (accessed: 2012-06-20).
[36] “Deltacloud – an API that abstracts the difference between
clouds,” [Online], http://incubator.apache.org/deltacloud/ (ac-
cessed: 2012-06-20).
[37] M. Kay, XSLT 2.0 Programmer’s Reference. Wrox, 3 edition,
August 2004.
[38] “SQLite,” [Online], http://www.sqlite.org/ (accessed: 2012-
06-20).
[39] J. Stone, “An Efﬁcient Library for Parallel Ray Tracing and
Animation,” In Intel Supercomputer Users Group Proceed-
ings, Tech. Rep., 1995.
[40] “FFmpeg,” [Online], http://www.ffmpeg.org/ (accessed: 2012-
06-20).
[41] “Open-Source
Large
Vocabulary
CSR
Engine
Julius,”
[Online], http://julius.sourceforge.jp/en index.php (accessed:
2012-06-20).
[42] “eSpeak text to speech,” [Online], http://espeak.sourceforge.
net/ (accessed: 2012-06-20).
75
International Journal on Advances in Software, vol 5 no 1 & 2, year 2012, http://www.iariajournals.org/software/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

