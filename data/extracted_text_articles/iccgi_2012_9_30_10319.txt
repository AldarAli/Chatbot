Multi-modal Optimization using a Simple Artificial Immune Algorithm 
Tad Gonsalves 
Dept. of Information & Communication Sciences, 
Sophia University, 
Tokyo, Japan 
E-mail: tad-gonsal@sophia.jp 
 
 
 
 
Yu Aiso 
Dept. of Information & Communication Sciences, 
Sophia University, 
Tokyo, Japan 
E-mail: yu.aiso.0920@gmail.com 
 
Abstract— 
Evolutionary 
Algorithms 
have 
an 
inherent 
parallelism that should enable them to locate several optima of 
a multi-modal function. However, in practice they are found to 
converge to a single (global) optimum. This has led to the 
research in the design of highly specialized evolutionary 
algorithms to obtain the maximum number of global and local 
optima of multi-modal functions. However, this is an over-kill, 
since in most cases the management needs no more than a 
handful of optima to make decisions. We demonstrate that the 
ordinary 
CLONALG 
algorithm, 
without 
any 
special 
modification to handle multi-modal optimization, is powerful 
enough to obtain several global and local optima to support the 
decision-making process.  
Keywords 
- 
evolutionary 
computation; 
multi-modal 
optimization; artificial immune algorithm;  
I. 
 INTRODUCTION  
In real-world optimization problems, sometimes we are 
not satisfied with only one optimal solution. The demand for 
multiple solutions is more prominent when there exist 
several near optimal answers to a problem. Evolutionary 
Algorithms (EA) are widely used for function optimization. 
The EAs have an inherent parallelism that should enable 
them to locate several optima of a multimodal function. 
However, in practice they are found to converge to a single 
(global) optimum. The Genetic Algorithm (GA), in particular, 
is found to converge to a single solution when attempting to 
optimize a multimodal function [10]. 
The inability of EAs to handle Multi Modal Optimization 
(MMO) has led to an extensive research in the design of new 
algorithms. Extended EAs are devised to locate all the global 
optima and as many local optima as possible. However, at a 
practical level, the effort and the cost of designing such high-
caliber and computationally expensive EAs do not seem to 
be justified, since the management cannot possibly refer to 
all the global and the local optima in making important 
managerial decisions. Knowledge of a handful of optima in 
the multi-modal problem is sufficient to make quick and 
speedy decisions.  
In this paper, we demonstrate that an implementation of 
the simple CLONALG algorithm meets this end. This 
algorithm need not be stretched to locate all the optima of a 
multi-modal function. It has an inherent mechanism to locate 
some of the global and local optima, which presents a 
sufficiently comprehensive scenario to aid the managerial 
decision making process.  
The Artificial Immune System (AIS) algorithm is 
inspired by the biological immune system [5,21]. The 
biological immune system is made up of primarily two types 
of cells - B cells which are produced in the bone marrow and 
T cells which are produced in the thymus. The pathogens 
like bacteria and viruses invading the body are called 
antigens. Both the antigen and the receptors on the surface of 
the B cells have three-dimensional structures. The affinity 
between the structure of the receptors and that of the antigen 
is a measure of the complementarities between the two. 
When an antigen invades the body, the immune system 
generates antibodies to diminish the antigen. Initially, the 
invaded antigen is recognized by a few of the B cells with 
high affinity for the antigen.  Stimulated by the helper T 
cells, these high affinity B cells proliferate by cloning. This 
process is called clonal selection principle. The new cloned 
cells undergo a high rate of somatic mutations called hyper-
mutation. The mutations undergone by the clones are 
inversely proportional to their affinity to the antigen. The 
highest affinity antibodies experience the lowest mutation 
rates, whereas the lowest affinity antibodies have the highest 
mutation rates. The high affinity B cells and their clones 
proliferate and differentiate into plasma cells. Finally, the 
plasma cells generate a large number of antibodies to 
neutralize and eliminate the antigens. 
After the cloning and hyper-mutation stage, the immune 
system must return to its normal condition, eliminating the 
extra cells. However, some cells remain circulating 
throughout the body as memory cells. When the immune 
system is later attacked by the same type of antigen (or a 
similar one), these memory cells are activated, presenting a 
better and more efficient secondary response. 
Among the various mechanisms in the biological 
immune system that are explored as AISs, negative selection 
[12], immune network model [6] and clonal selection [7] are 
the most discussed models. The CLONALG algorithm based 
on the above clonal selection principle is also use in 
optimization [7-8]. In this study, we show that the 
CLONALG algorithm routinely locates several global and 
local optima of a multi-modal function.  
This paper is organized as follows: Section II presents a 
review of the literature on multi-modal optimization 
functions. Section III explains the CLONALG algorithm in 
detail and introduces the multi-modal test functions. The 
experimental results are presented in section IV. The paper 
ends with a brief conclusion in section V. 
183
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

II. 
LITERATURE REVIEWED 
EAs are either extended or hybridized with other 
optimization techniques to solve the MMO problems. In 
addition, new algorithms are also designed. This section 
presents a review of the algorithms found in literature. 
A. Extended Algorithms  
The standard Genetic Algorithm (GA) is extended 
towards multi-modal function optimization by introducing a 
niche-preserving technique [10]. The technique deals with 
finding and preserving multiple stable niches of the solution 
space possibly around multiple solutions so as to prevent 
convergence to a single solution [11]. Niching methods 
maintain diversity in the population and permit the EA to 
find many optima in parallel. Clearing [18], Crowding [9,16], 
Clustering[19], Sharing [3, 11], Restricted Selection [13], 
Species [19] and Conserving [14] are some of the notable 
niching techniques employed to extend EAs to find solutions 
to the multi-modal optimization problems.  
The Particle Swarm Optimization (PSO) is a simple, but 
efficient algorithm based on the swarm intelligence metaphor. 
NichePSO is an extended form of PSO designed to handle 
multi-modal optimization. The Species-based PSO (SPSO) 
implements proximity-based speciation and creates turbulent 
regions around the already found solutions to prevent 
unnecessary function evaluations [2]. The Bottleneck 
Assigned Binary Any System is inspired by the traffic 
organization in real ants under crowded conditions [24]. 
B. Hybrid Algorithms 
Memetic algorithm which introduces local search 
techniques in PSO is developed by Wang et al. [23]. The 
PSO disperses the solutions in diverse sub-regions, where an 
adaptive local search takes place to locate the optima. The 
Niche Hybrid Algorithm (NHGA) is a hybrid form of the 
Nelder-Mead’s Simplex Method and GA and is used in the 
multi-modal optimization of vehicle suspension system [1].  
An agent-based hybrid algorithm is found in [15] and a 
Differential Evolution hybrid algorithm is found in [20]. 
C. New Algorithms 
The Artificial Immune Network Algorithm for multi-
modal optimization (opt-aiNet) is a novel algorithm [12]. 
One of the salient features of this algorithm is the increase in 
population at every iteration. The increasing population is an 
indication that the problem has many local optima which the 
algorithm finds efficiently. Estimation of distribution 
algorithms (EDAs) are a new set of algorithms used in MMO. 
Unlike most EAs, EDAs do not make use of variation 
operators 
(e.g., 
crossover 
and/or 
mutation) 
in 
the 
combination step.  Instead, EDAs generate the offspring 
population at each iteration by learning and subsequent 
simulation of a joint probability distribution for the 
individuals selected [17]. The ensemble of niching 
algorithms (ENA) approach uses several niching methods in 
parallel in order to preserve diversity of the populations and 
to benefit from the best method [22]. Other miscellaneous 
evolutionary approaches, including the Multi-objective 
Optimization 
(MO) 
algorithms 
are 
found 
in 
the 
comprehensive survey on MMO by Das et al. [4]. 
 
III. 
AIS FOR MMO ALGORITHMS 
In this section, we define the objective functions and the 
AIS clonal selection algorithm that is used in finding a set of 
global and local optima in these MMO benchmark test 
functions.   
A. AIS Algorithm 
 
The AIS clonal algorithm described below consists of 
the following steps: 
 
Generation of antibody population 
 
A population consisting of N antibodies (Abs) is 
randomly generated. Each antibody represents a feasible 
solution to the optimization problem. The Abs in our 
application are represented as binary bit strings or as real 
numbers. 
 
Objective function evaluation 
 
The multimodal test functions (Equations 1 ~ 4) are 
evaluated numerically for each of the antibodies.  
 
Affinity Calculation 
 
The affinity (or the fitness) of each individual antibody 
is evaluated based on the value of the objective functions 
mentioned in this sub-section.   
 
Clone Selection 
 
A certain percentage of the antibodies with greater 
affinities are selected from the population. These are then 
cloned to produce additional antibodies. 
 
Affinity Proportional Mutation 
 
The clones produced in the above step are subjected to 
mutations in proportion to their affinities. 
 
Memory Renewal 
 
The antibodies with relatively lower affinities (i.e., with 
higher values of the objective function) are eliminated. The 
selected clones are introduced into the antibody population 
as the immune memory cells.  The above steps are iterated 
for M number of cycles. The Ab with the highest affinity 
(maximum values) found in all the iterations is the optimal 
solution. 
B. Test Functions 
We have chosen the following benchmark multi-modal 
maximization functions to demonstrate the applicability of 
the simple CLONALG algorithm: Rastrigin (1), Schaffer (2), 
Multi-function (3) and Roots function (4).  
  (   )         ∑(  
          (    ))
 
   
 
 
 (1) 
 
184
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

Population
(N)
Total generations
(Ngen)
Mutation
Probability
PSO
40
200
-
GA
100
200
0.01
AIS (binary)
100
200
0.01
AIS (real)
100
200
0.01
Algorithm
Parameter
                         
 
 
 (   )           (√         )
(       (     )) 
 
 (2) 
 
 (   )  [      ] 
 
 
 
 (   )       (   )       (     )    
(3) 
 
(   )  [    ] 
 
 
 
  ( )   
 
  |    | 
(4) 
 
            (   )  [    ] 
 
 
IV. 
EXPERIMENTAL RESULTS 
The different parameters of the algorithms used to 
produce the experimental results are shown in Table 1. The 
table shows a modest number of populations evolving 
through a modest number of generations (iterations). Since 
our aim is to demonstrate that the CLONALG algorithm 
produces a good number of optima under ordinary 
performance conditions, we have tried not to vary the 
(default) parameters used in conventional test runs.  
TABLE I.  
EXECUTION  PARAMETERS OF ALGORITHMS 
 
 
 
 
 
 
 
 
The test results are plotted as 3D graphs (Figure 1 to 
Figure 4). In our experiments, PSO is coded as real-valued, 
while GA is coded as binary. However, in the case of the 
CLONALG algorithm, binary as well as real-valued 
algorithm is implemented. Both the implementations of 
CLONALG find a good deal of the global and local optima 
of the multi-modal test functions as explained below. 
a) Rastrigin function: PSO and GA converge to  a 
single global optimum (shown as black dots) (Figure 1 a, b). 
As to which optimum these algorithms converge to, depends 
on the randomly generated initial populations. But the 
binary as well as the real version of the CLONALG 
algorithm locate at least one of the global maxima and a 
couple of the local maxima (Figure 1 c, d). 
b) Schaffer’s function: All the particles in PSO rapidly 
converge to the central ridge of the function (Figure 2 a), 
while the GA is spreadout onto a few global optima. Some 
of the solutions are cearly sub-optimal. But the binary as 
well as the real version of the CLONALG algorithm locate 
at least 2~3 central peaks of the function (Figure 2 c, d). 
c) Multi-function:  PSO easily converges to the global 
optimum (Figure 3 a), while the GA surrounds the global 
optimum and is spreadout in the search space (Figure 3 b). 
d) Roots function:  PSO locates two of the six peaks  
(Figure 4 a). On the other hand, GA locates just one of the 
peaks and is rather spread out  (Figure 4 b). Both the 
versions of CLONALG successfully locate all the six peaks 
of the Roots function (Figure 4 c, d). In all the experiments, 
the simple CLONALG algorithm finds a number of global 
and local optima without using the MMO techniques.  
V. 
CONCLUSION 
In spite of their inherent parallelism, Evolutionary 
Algorithms are found to converge to a single global optimum 
when they attempt to optimize multi-modal functions. 
Extensive research has been done to design EAs to locate all 
the global optima and as many local optima as possible. 
However, the effort and the cost of designing such high-
caliber and computationally expensive EAs do not seem to 
be justified, since the management cannot possibly refer to 
all the global and the local optima in making important 
managerial decisions. Knowledge of a handful of optima in  
the multi-modal problem is sufficient to make quick and 
speedy decisions. We demonstrated through a series of 
multi-modal test functions that an implementation of the 
simple CLONALG algorithm, without any special modi-
fication toward multi-modal optimization, meets this end. 
REFERENCES 
[1] Alugongo, A.A. ;Lange, J.M., Optimization of multimodal 
models in mechanical design by a Niche Hybrid Genetic 
Algorithm, AFRICON 2009, pp.1- 6 
[2] H. Cho, D. Kim, F. Olivera, S. D. Guikema, Enhanced 
speciation in particle swarm optimization for multi-modal 
problems, European Journal of Operational Research,  (2011), 
213(1):15-23 
[3] A.D. Cioppa, C. De Stefano, A. Marcelli, Where are the 
niches? Dynamic fitness sharing, IEEE Transactions on 
Evolutionary Computation 11 (2007) 453-465. 
[4] S. Das, S. Maitya, B-Y. Qub, P.N. Suganthanb, Real-
parameter evolutionary multimodal optimization — A survey 
of 
the 
state-of-the-art, 
Swarm 
and 
Evolutionary 
Computation,1(2)71-88, (2011) 
[5] de Castro L.N., Von Zuben, F.J.: Artificial immune systems: 
Part II—A survey of application. State Univ. Campinas, 
Campinas, Brazil, Tech. Rep. RT DCA 02/0065 (2000) 
[6] de Castro L.N., Von Zuben, F.J.: aiNet: An artificial immune 
network for data analysis. In: Data Mining: A Heuristic 
Approach, H.A. Abbass, R.A. Sarker, and C.S. Newton (eds). 
Idea Group Publishing, USA, pp. 231--259 (2001) 
[7] de Castro L.N., Von Zuben, F.J.: Learning and optimization 
using the clonal selection principle. IEEE Trans. Evol. 
Comput., 6(3): 239-251 (2002) 
[8] de Castro L.N., Timmis, J.: An artificial immune network for 
multimodal function optimization. In: Proc. IEEE Congress 
on Evolutionary Computation, vol. 1, 699-674 (2002) 
[9] K.A. De Jong, An Analysis of the Behavior of a Class of 
Genetic Adaptive Systems, Doctoral Dissertation, University 
of Michigan, 1975.  
185
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

[10] Goldberg, D. E. and Richardson, J. (1987). Genetic 
algorithms with sharing for multimodal function optimization. 
In Grefenstette, J. J., editor, Genetic Algorithms and their 
Applications: Proceedings of the Second International 
Conference on Genetic Algorithms, pp. 41-49, New Jersey. 
[11] D.E. Goldberg, L. Wang, Adaptive niching via coevolutionary 
sharing, Genetic Algorithms and Evolution Strategy in 
Engineering and Computer Science (1997) 21–38. 
[12] Hart, E., Ross, P.: Exploiting the analogy between 
immunology and sparse distributed memories: A system for 
clustering non-stationary data. 1st International Conference 
on Artificial Immune Systems (ICARIS), pp. 49-58, (2002). 
[13] J.-K. Kim, D.-H. Cho, H.-K. Jung, C.-G. Lee, Niching genetic 
algorithm adopting restricted competition selection combined 
with pattern search method, IEEE Transactions on Magnetics 
38 (2) (2002) 1001-1004. 
[14] Li, J-P., Balazs, M. E., Parks, G. T., and Clarkson, P. J. 
(2002). A Species Conserving Genetic Algorithm for 
Multimodal 
Function 
Optimization. 
Evolutionary 
Computation, 10(3):207-234. 
[15] R. I. Lung, C. Chira, and D. Dumitrescu. An agent-based 
collaborative 
evolutionary 
model 
for 
multimodal 
optimization. GECCO ’08, pp. 1969-1976. 
[16] S.W. Mahfoud, Crowding and preselection revisited, Parallel 
Problem Solving from Nature 2 (1992) 27-37. 
[17] J. M. Pena, J. A. Lozano, and P. Larranaga. Globally             
multimodal problem optimization via an estimation of 
distribution algorithm based on unsupervised learning of 
bayesian networks. Evolutionary Computation,13(1):43-66, 
2005.  
[18] A. Pétrowski, A clearing procedure as a niching method for 
genetic algorithms, IEEE International Conference on 
Evolutionary Computation, New York, 1996, pp. 798-803. 
[19]  G. Singh and D. Kalyanmoy Deb. Comparison of multi-
modal optimization algorithms based on evolutionary 
algorithms, GECCO ’06, pp. 1305-1312. 
[20] Thangaraj, R., Pant, M., Abraham, A., and Badr, Y. (2009). 
Hybrid evolutionary algorithm for solving global optimization 
problems. Lecture Notes in Computer Science, 5572:310–
318.  
[21] Timmis, J., Knight, T., de Castro L.N., Hart, E.: An Overview 
of artificial immune systems. In: Computation in Cells and 
Tissues: 
Perspectives 
and 
Tools 
Thought. 
Natural     
Computation Series, Springer-Verlag, 51-86 (2004) 
[22] E. L. Yu, P. N. Suganthan, Ensemble of niching algorithms, 
Information Sciences: an International Journal, 180(15):2815-
2833, (2010) 
[23] H. Wang ; N. Wang; D. Wang, A memetic particle swarm 
optimization algorithm for multimodal optimization problems, 
CCDC, 2011, pp. 3839-3845  
[24] J. Zhao; C. Yan; A Bottleneck Assigned Binary Ant System 
for multimodal optimization,  Conference on Decision and 
Control, 2009, China, pp.6195-6200  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Rastrigin’s function 
                                   (a)  PSO locates a single global peak      
 
                                            (b) GA locates a single global peak 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
(c)  CLONALG (binary) locates all global and a few local optima      (d)  CLONALG (real) locates all lobal and a few local optima  
186
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. Schaffer’s function 
(a) PSO converges to the central peak   
 
 
             (b) GA is spread out with some sup-optimal solutions   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 (c) CLONALG (binary) locates 2 global maxima  
 
      (d) CLONALG (real) locates 3 global maxima 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. Multi-function 
(a) PSO converges to the global optima   
 
 
             (b) GA surrounds the global optima and is spread out   
 
 
187
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
           (c) CLONALG (binary) locates the global and some local optima 
                   (d) CLONALG (real) locates the global and some local optima 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 4. Roots function 
(a) PSO locates 2 global optima    
 
                             (b) GA locates 1 global optimum and is spread out   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
          (c) CLONALG (binary) locates all the global optima 
 
            (d) CLONALG (real)  locates all the global optima 
 
188
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

