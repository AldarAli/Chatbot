Application of  Feature Point Detection and Matching 
in 3D Objects Reconstruction  
 Jie Yuan, Ting Feng, Yu Zhou, Yao Yu 
School of Electronic Science and Engineering,   Nanjing University, Nanjing 210093, China 
Email: yuanjie@nju.edu.cn, fengnju1988@gmail.com, nackzhou@nju.edu.cn, allanyu@nju.edu.cn 
 
 
Abstract— In this paper, we present a novel wide baseline based 
approach to detect and match feature points in image series. We 
found the wide baseline correspondence problem with large scale, 
rotation, illumination and affine transformations is still not 
tackled very well. We proposed a new matching method which 
based on multi-scale Harris algorithm and two-way guided 
matching 
to 
achieve 
large 
number 
of 
accurate 
point 
correspondences between un-calibrated image sequences of the 
same scene for wide baseline. We apply our method in the 
experiments of 3D object reconstruction with satisfied results. It 
shows that the guided matching method can be used for severe 
scene variations and provide evidence of improved performance 
with respect to the SIFT distance and Harris matchers. It is also 
useful to the matching in short baseline, and the results of this 
method are better than that of the traditional method.  
Keywords-feature 
points; 
image 
matching; 
3D 
object 
reconstruction 
 
I. 
INTRODUCTION  
Wide Baseline Matching (WBM) is one of the most 
important issues that have been extensively studied in the field 
of computer vision, as well as the foundation of many 
computer vision theory and applications [1][2][3] such as 
object identification, camera calibration, 3D reconstruction, 
and motion analysis. Meanwhile, WBM is a bottleneck in the 
field of computer vision research. Therefore, research on 
WBM is of significant importance. WBM primarily divides 
into two parts: feature point detection and matching. 
The primary methods of feature point detection are Harris 
feature point extraction algorithm and Scale Invariant Feature 
Transform (SIFT [14]) feature point extraction algorithm. 
Both of them have their own advantages and disadvantages. 
To get better corner detection results, Keju [6] combined the 
two algorithms during 3D reconstruction on demand. But this 
method has limited the range of application, which means that 
it is not applicable if we merely to get more and more accurate 
feature points. Schmid [5] reported that corner extraction 
algorithm, being invulnerable to camera pose and sunlight, 
performs the best currently. However, as for vision systems 
with large scale changing, this method can hardly guarantee 
invariability of the feature points. In this case, the paper 
provides a novel multi-scale corner detection approach which 
combines scale space theory and Harris feature point detection 
algorithm. 
To match feature points, generally, the relative methods 
are used to achieve the correspondence of two images’ point 
sets. Considering noise interference, light conditions, and 
other factors which may result in a great number of 
mismatches, however, removing mismatches is essential. One 
of the direct ways to remove mismatches is to find an affine 
transformation which is applicable to all the feature points in 
the image, and then use it to pre-estimate the position of these 
feature points located in the other image [4]. Nevertheless, it is 
not applicable to complicated scenes. To solve this problem, 
Ferrari et al. [3] proposed to estimate local affine 
transformation matrix for every pair of corresponded feature 
points, using least mean square method. Later it was suggested 
in another approach that this affine transformation matrix 
should be compared to the predetermined threshold to gather 
the most similar points to the affine transformation matrix. 
Although this method has been proven to be effective in 
confirming mismatches, it pays a high cost of computational 
complexity. Currently, a comparatively better method in the 
field of removing mismatches is to use epipolar geometry 
restriction proposed by Zhang [9]. This method can produce 
excellent results on the condition that matching points are less 
in quantity and parallax is small.  However, there are two 
issues remained to be solved. One is that the quantity of 
matching points is relatively small. The other is the restriction 
of disparity. Increasing the disparity means enlarging the 
match searching window, while enlarged match searching 
window will probably introduce mismatches. 
  In response to the above problems, we propose a novel 
approach combining epipolar geometry, homograph constraint, 
mismatch detection and guided matching which, to some 
extent, greatly make up the deficiency in these two areas 
mentioned above. At first, we use relative method to conduct 
initial match of the image feature points set. Secondly, we use 
RANSAC (Random Sample Consensus) method to estimate 
fundamental matrix and homography matrix and remove 
mismatches in correspondence. Then, we remove mismatches 
again according to euclidean distance. Finally, we use 
optimized fundamental and homography matrix guiding the 
matching to get more and more accurate matching points.  
In 3D objects reconstruction, the quality of WBM will 
affect the result of reconstruction directly. The purpose of this 
paper is to get a better algorithm in WBM, and apply it to 3D 
reconstruction. Then the accuracy of 3D objects reconstruction 
will be enhanced, and fewer cameras or video cameras will be 
used in experiment.  
19
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

 
II. 
 FEATURE POINT DETECTION  
An effective feature point detection algorithm is 
introduced in this section. We introduce the scale space theory 
at first. 
A. Scale Space Theory 
Scale space theory is carried out by scaling the original 
image to obtain multi-scale sequence of scale space, and 
extracting the main contour based on the sequence as a feature 
vector, to achieve edge detection, corner detection and feature 
extraction on different resolutions. As an important concept in 
scale space theory written by Lindbergh [12][13] that scale 
space is describing original image at different levels, each layer 
has a scale parameter which may be discrete and also can be 
continuous. All scales of space should have the following 
properties: 
 
All the signals should be defined in the same domain. 
 
With the growth of scale parameters, the output image 
is increasingly blurred. 
 
Details contained at the coarse level of a signal are 
less than that at the fine level. If the local maximum is 
a measure of smoothness, as the scale blurred, extreme 
non-increasing, this property is known as the “scale 
space causality”. 
 
All that is generated by a convolution operator. 
Scale space kernel is defined as: 
              ܮሺݔ,ݕ,ߪሻ ൌܭሺݔ,ݕ,ߪሻ ൈܫሺݔ,ݕሻ                        (1) 
In (1),  Iሺx, yሻ is the original image, σ is the scale parameter. 
For all the images I, if the extremes of the image Lሺx, y, σሻ 
obtained after its convolution with transform kernel K is less 
than the extremes of original image, then we call K the scale 
space kernel. Generally we only use the Gaussian kernel as the 
scale convolution. Because in Gauss scale space, fine-scale 
information on the parameter value with the increase in scale 
was inhibited in the scale of the change from coarse to fine 
process, no new structure. However, since Gauss kernel is 
linear, translation invariant, rotation invariant, has subset 
features and many other properties, it can be proved that Gauss 
kernel is the only transform kernel to achieve scale space 
transformation [8]. Feature points and edges of the same type at 
different scales have a causal relationship, which means that 
when scale changes, new feature points may arise while old 
ones may be displaced or disappear. The ambiguity brought by 
the causal relationship is inherent and inevitable which should 
never be expected to be eliminated but it can be decreased. 
B. Multi-Scale Harris Feature Point Detection Algorithm  
Multi-scale Harris feature point detection algorithm was 
introduced and the experimental results of this method was 
given in this section.  
1) 
Harris Operator of  Scale Space 
Harris operator R can be represented as: 
ܴ ൌ ݀݁ݐሺܥሻ െ ݇ݐݎଶሺܥሻ                                      (2)                             
In (2), ܥሺݔሻ ൌ ൤ܫ௨
ଶሺݔሻܫ௨௩ሺݔሻ
ܫ௨௩ሺݔሻܫ௩
ଶሺݔሻ ൨ , k is empirical value, 
which usually between 0.04~0.06. To obtain the presentation of 
Harris operator, I୳, I୴ can respectively be represented as ： 
            ܫ௨ሺݔ,ݏߪ௡ሻ ൌܫ௨ሺݔሻ ∗ܩ௨ሺݔ,ݏߪ௡ሻ                            (3)                
ܫ௩ሺݔ,ݏߪ௡ሻ ൌܫ௩ሺݔሻ ∗ܩ௩ሺݔ,ݏߪ௡ሻ                            (4).                  
Then the Cሺxሻ function of Harris algorithm will become               
ܥመሺݔ,ߪூ,ߪ஽ሻ ൌߪ஽
ଶܩሺߪூሻ ∗ ൤ܫ௨
ଶሺݔ,ߪ஽ሻܫ௨௩ሺݔ,ߪ஽ሻ
ܫ௨௩ሺݔ,ߪ஽ሻܫ௩
ଶሺݔ,ߪ஽ሻ ൨          (5)                
In (5),  σ୍ ൌ σ୬ is the selected scale parameter to calculate 
feature points; σୈ ൌ sσ୬  is the differential scale; Gሺσ୍ሻ  is 
Gaussian function. Through judging to detect the feature corner 
under σ୬ scale level 
                    ܴ ൌ ݀݁ݐ൫ܥመ൯ െ ݇ݐݎଶ൫ܥመ൯ ൐ ܶ                         (6).                 
2) 
Multi-Scale Harris Feature Point Detection Algorithm 
Arithmetic operator  LOG׏ଶg  is forwarded by [7]. Two-
dimensional LOG operator can be represented as:  
  ߘଶ݃ ൌ ቀ
௫మିఙమ
ఙర ቁ ݁ݔ݌ ቀെ
௫మ
ଶఙమቁ  ݂ሺݔ,ݕሻ                    (7) 
Where fሺx, yሻ is the function to be detected. Using a typical 
template LOG operator in the text to detect whether the corner 
point measured under a certain specified scale level is the 
extreme value, which result in an invariant scale feature corner. 
The procedure of multi-scale Harris feature point detection 
algorithm procedure is as follows: 
 
Primarily select scale variables σ୬ and the threshold 
value T, using formula (6) and (7) to calculate the 
candidate feature corner of each scale level. 
 
Use iterative algorithm to detect whether the LOG 
operator of each scale level candidate corner points to 
obtain the maximum value, and determine the results 
in the location and scale of the final feature corner. 
Consider the entire scale space of the image, assumed 
to detect the corner set C୭୮୲ under σ୬ ൌ σ଴ large-scale 
level. Decrease the image scale coordinate to σ୬ ൌ σଵ, 
and detect new corner set  C୬ୣ୵ in the neighborhood 
of the image. If there is  C୬ୣ୵ , regard  C୬ୣ୵ as the 
corner feature set of the current image. Repeat the 
above process until there is no change of C୬ୣ୵, or 
until the scale is small enough.  
3) 
Compare Experimental Results of multi-scale Harris 
Feature Point  Detection Algorithm with That  of Ordinary 
Harris Algorithm  
During 
experiment, 
taking 
the 
standard 
deviation 
proportional constant of Gaussian kernel function S ൌ 0.7 , 
k ൌ 0.04 [7], use a typical 5 ൈ 5 LOG operator.  
ۏ
ێ
ێ
ێ
ۍ00
െ1
0
0
0
െ1
0
െ1
െ2
െ1
െ2
െ16
െ2
െ1
െ2
െ1
0
െ1
0
0
0
െ1
0
0ے
ۑ
ۑ
ۑ
ې
 
20
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

 
fea
hig
per
of 
thr
ini
det
inc
cri
cha
rep
(8)
sta
cor
is 
po
rat
Fig
cha
Ha
rat
is 
sca
When σ୬ is 
ature point ext
ghlighted are s
Figure1.  Tradit
compare
Stability cr
rformance can
the detection
ree criteria are
itial detection
tected after th
crease of the n
iteria of the m
anging the sca
                     
In (8),  C୧   
presents the nu
) shows that 
able the algor
rner detection 
the corner se
ints set with t
te of  Cଵ and C
gure 2. 
Figure 2. Com
It can be see
anges, repeata
arris feature p
te is significan
to say, Harris
ale space theor
taken as 2, 1
tracting of the
shown as follo
tional Harris featu
ed with multi-sca
riteria, reliab
n be applied to
n algorithm in
e determined 
n of the corn
he change of p
noise. In our 
multi-scale H
are. 
  ߛ ൌ
|஼భ ⋂ ஼
௠௜௡ሺ|஼భ|,
denotes the 
umber of elem
the bigger th
rithm will be.
to the origina
et with fixed 
the scale of σ୬
Cଶ respectively
mparison of 2 kind
en from the a
ability of the sc
point detection
ntly higher than
s feature point
ry is more stab
1 and multi-s
e original ima
ows: 
ure point detectio
ale Harris feature p
 
bility criteria
o evaluate the 
n a certain cor
by the repetit
ner and the 
arameters, thr
experiment, w
Harris feature 
஼మ|
,|஼మ|ሻ ൈ 100% 
detected featu
ments in the col
he repetition r
. Results of d
al image is sho
scale of σ ൌ
୬ ∈ ሾ2,6ሿ , calc
y. See the exp
ds Harris feature p
 
above graph th
cale space the
n method for 
n the original H
t detection me
ble and reliabl
cale, the resu
age which is s
on of different sca
point detection
a, and anti
superior or in
rner [8][12]. 
tion rate  γ  of
corner points
reshold value, 
we test the sta
point detectio
                       
ure points se
llection C୧. Fo
rate γ  is, the 
different scale
owed in Figure
1, Cଶ is the c
culate the repe
perimental resu
 
point repetition ra
hat, when the
eory which bas
duplicate det
Harris  method
ethod that bas
e . 
ults of 
shown 
        
ales 
-noise 
nferior 
These 
f both 
s that 
or the 
ability 
on by 
    (8) 
et. |C୧| 
ormula 
more 
es for 
e 1, Cଵ 
corner 
etition 
ults in 
ate 
e scale 
sed on 
tection 
d, that 
sed on 
     I
con
gui
A. 
spe
resp
poin
larg
con
of t
whi
a re
ther
y an
The
poin
less
from
one
cor
con
sym
B. 
mat
sam
1)
epip
cor
coll
mat
mat
mis
usu
doe
[10
pro
of r
2)
plan
kee
the 
to f
mis
epip
II
In this sect
nstraint and ho
ded matching 
Initial Matchi
Initial match 
ecific 
matchi
pectively calc
nts of the two
ger than a give
nsidered to be 
the correspond
ile xᇱ is the fe
eal correspond
re might be m
nd yᇱ are resp
e necessary co
nt ሺx, xᇱሻ is: th
s than the pre
m the neighbo
e feature poin
rresponding po
nsider the max
mmetry of such
Using Epipola
Eliminate Mis
In this sectio
trix H are calc
me time. 
) 
Epipolar G
In two imag
polar geometr
rresponding po
lecting. It can 
trix. 
                     
In (9), F is 
tching points
smatches amo
ual least square
es not achiev
0][11] method
ocess of using 
removing the m
) 
Homograp
Homography
ne surface to 
eping linear. m
two images, s
                     
During exper
find the soluti
smatches. The
polar geometr
II. 
FEATURE
tion, initial 
omography con
is proposed.  
ing 
consists of tw
ing. General
culating the c
o images. Wh
en threshold v
reciprocal, and
ding feature po
ature point of 
ding feature po
more correspon
ectively within
ondition that ሺy
he angle betw
eliminary set 
orhood to accu
nt can match 
oint has supp
ximum suppor
h support. 
ar Geometry a
smatches 
on, fundamen
culated, and th
Geometry Con
ges that view
ry constraint 
oints of the s
be algebraica
           ݉ᇱ்ܨ݉
fundamental 
 of two ima
ng the initial 
es method to c
ve good resu
d, which is th
RANSAC me
mismatches.
phy Constrain
constraint m
another. It is 
m and  mᇱ are
so that the hom
       ݉ᇱ ൌܪ݉
riment, we app
ion for H, at t
e polar line ru
ry constraint, 
E  POINT MATCH
matching, e
nstraint are int
wo steps: gen
l 
matching 
orrelation coe
hen the correla
value, both the
d therefore bec
oints. x Is the f
f  Iଶ. First of al
oint, then withi
nding feature p
n the neighbo
y, y′ሻ is suppor
weenx,  y  and
value.  Searc
umulate match
more than on
ort strength. T
rt of each neig
and Homograp
ntal matrix F
he mismatches 
nstraint  
w from diffe
is the certain 
ame physical 
ally described b
݉ ൌ 0             
matrix, m an
ages. Because
matching poin
calculate the f
ults. We choo
hought to be 
ethod to get F 
nt 
maps the points
a reversible m
 correspondin
mography H sh
݉                     
ply the RANS
the same time
uns through th
which still h
HING 
epipolar geom
troduced. Two
neral matching
is achieved
efficient of fe
ation coefficie
e feature point
come the cand
feature point o
ll, assume ሺx,
in its neighbor
point ሺy, yᇱሻ, w
orhood of  x an
rted by real fe
d xᇱ,  yᇱ shou
ch support stre
hing strength. S
ne candidate, 
Therefore, we
ghborhood an
phy Constrain
 and homogr
are removed a
erent view po
limit between
space point w
by the fundam
                       
nd mᇱ  is a pa
e there are m
nts, directly u
fundamental m
ose the RAN
more robust.
is also the pr
s of one geom
mapping and o
ng match poin
hould obey: 
                    
SAC method 
e, further elim
he entire ima
has relatively 
metry 
o-way 
g and 
d by 
eature 
ent is 
ts are 
didate 
of  Iଵ, 
xᇱሻ is 
rhood 
where 
nd xᇱ. 
eature 
uld be 
ength 
Since 
each 
e just 
nd the 
nt to 
raphy 
at the 
oints, 
n the 
when 
mental 
   (9) 
air of 
many 
use of 
matrix 
NSAC 
. The 
ocess 
metry 
obeys 
nts of 
   (10)  
again 
minate 
ge in 
large 
21
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

 
ma
the
geo
me
tha
fro
ina
Ne
cha
go
3
of 
sam
of 
ma
Iଶ 
ma
nec
to 
mෝ ୧
ᇱ
the
Fig
in 
ran
mi
cal
ma
euc
Fu
me
Th
wit
gu
mo
gu
the
and
rou
po
thi
atching space.
ere are still 
ometry constr
ethod above c
at matching p
om one geom
applicable to 
evertheless, m
ange, by appro
od results can 
3) 
Guided M
Homogra
The above m
mismatches, 
me time. In or
epipolar geo
atching. Redire
 to get more a
The epipolar
atching point o
cessarily adjac
homography 
୧
ᇱ. S3 the inter
e approximate
gure 3below. 
 
                     
Fig
 
Compared w
S3 to guided m
nge of finding 
ismatching. Ap
lculate the eu
atching points
clidean distan
urther diminish
ethod, and us
hen to guided 
th  the euclide
ided matching
ore accurate m
ided matching
e same method
d then take the
Our experim
und of guided
ints, because e
IV
The procedu
is section. 
 As for the im
plenty of m
raint. The me
can further dim
precision is pr
metric plane 
the images 
most physical 
opriately broad
be achieved in
Matching by U
aphy Constrain
matching proc
but it gets les
rder to solve th
ometry and ho
ect and match 
ccurate match
r geometry con
of m୧ (m୧ is th
cent to the cor
constraint, m୧
ᇱ
rsection of the
e area where t
   
gure 3. The search
with the initial 
matching have
 matching poi
pply the euclid
uclidean distan
s from short 
nce, and select
h the threshold
e top-ranked 
match and sel
ean distance ag
g to obtain m
matching. The 
g of the featur
d to guided m
eir union set. 
ment guides all
d matching ra
each round wil
V. EXPERIMEN
ures and result
mages with lot
mismatches af
entioned hom
minish the sco
roved. H is a 
surface to 
 of significa
scene image
dening the thr
n practice. 
Using Epipolar
nt  
ess has remov
ss correct mat
his problem, w
omography co
all feature po
hing points.  
nstraint show t
he feature poin
rresponding po
୧
ᇱ is also near 
e above two m
the matching 
hing scope of guid
match, selecti
e greatly dimin
ints and reduce
dean distance 
nce between m
to long in ac
t the top-ranke
d for interior p
matching poi
lect the accura
gain, see Figur
more accurate F
above steps h
re points of  Iଵ
matching the fe
l the feature po
ather than kee
ll get even bet
NTS AND RESU
ts of our exper
ts of feature p
fter using ep
mography cons
ope of matchi
mapping of p
another, whi
ant depth ch
s have little 
reshold of matc
r Geometry an
ved a large nu
tching points
we integrated th
onstraint to g
ints of image 
that m୧
ᇱ which 
nts detected in
olar line. Acco
to estimation 
mentioned are
points locate
 
ded matching 
ing the area de
nished the sear
ed but cannot 
detection meth
m୧
ᇱ and mෝ ୧
ᇱ, so
ccordance wit
ed matching p
points of RAN
ints to solve
ate matching p
re 4, use two c
F and H and 
have complete
ଵ . Similarity, 
feature points 
oints for the s
ep only top-r
tter. 
ULT 
riment are sho
points, 
pipolar 
straint 
ing so 
points 
ich is 
hange. 
depth 
ching, 
nd 
umber 
at the 
he use 
guided 
Iଵ and 
is the 
n Iଶ) is 
ording 
point 
as are 
d, see 
efined 
rching 
avoid 
hod to 
ort the 
th the 
points. 
NSAC 
F, H. 
points  
cycles 
make 
ed the 
apply 
of  Iଶ, 
second 
ranked 
own in 
A.
in F
B.
this
cap
poin
we 
mat
the 
7 s
hom
gui
bef
poin
from
amo
oth
feat
box
con
con
eve
deg
Fig
pro
eas
algo
ther
 Experimenta
The entire pr
Figure 4: 
(1)Feature      
points  
detection 
(2)Initial 
Matching
Begin
                     
 Experimenta
In order to 
s paper conduc
ptured by an u
nts, and the p
used are as fo
The results a
tching points
figure. Figure
shows the m
mography con
ded matching
fore guided m
nts after two-w
m the correspo
ount of the fea
er accurately, 
tures of the bo
x are not matc
nstraint can f
nstraint cannot
en applicable t
grees, but it is
gure 9-Figure 1
oposed images
ily find out t
orithm, nearly
re is no error m
al Operation  
rocess of expe
(3)Calculating 
t h e  F  a n d  H 
base on I1
(4)g
t h e
poin
(6)Opera
matching p
follow (3)
 Figure 4. Flow c
al Results 
verify the fe
cted experimen
un-calibrated S
parallax angle
ollow: 
Figure 5. Or
are showed in 
in Iଵ and Iଶ is
e 6 shows the r
matching resu
nstraint. Figure
g. The numbe
matching is 10
way guided m
onding matchi
ature points is
but the match
ox, such as fea
ched by our m
fit the whole
t. In our expe
to the image p
s more suitab
11 are the resu
s whose parall
that after appl
y all feature p
matching at all
erimental test o
guided match 
e  f e a t u r e 
nts of I1
(5)Sel
relativ
matchin
te on the 
point of I 2 
(4)(5)
Cycle 
twice
chart of the whole
asibility of pr
nts with two d
SLR camera fr
e is 85 degree
riginal images 
 
Figure 6-Figu
s connected by
results of initia
ults of epipo
e 8 shows the 
er of accurate
02, and the nu
matching is 320
ing points from
s relatively lar
hing points wh
ature points at
method for the 
e image, but
eriment, the m
pairs whose pa
ble to that les
ults of our app
lax angle is 6
lying two-way
oints are matc
l.  
operation is sh
(7)
Merging 
the 
results
ecting the 
ve accurate 
ng point
End
 experiment 
roposed algor
downloaded im
from different 
s. The two im
 
ure 8. Every p
y a straight li
al matching, F
lar geometry
results of two
e matching p
umber of matc
0 pairs. We ca
m Figure 8 tha
rge and match 
hich can expres
t the top side o
epipolar geom
t the homogr
method of WB
arallax angle a
s than 80 deg
proach by usin
5 degrees. We
y guided matc
ched correctly
hown 
 
rithm, 
mages 
view 
mages 
air of 
ine in 
Figure 
y and 
o-way 
points 
ching 
an see 
at the 
h each 
ss the 
of the 
metry 
raphy 
BM is 
are 85 
grees. 
ng the 
e can 
ching 
y, and 
22
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

 
Figgure 7. The results
Figur
Figure 
homograp
Figure 6. In
s of using epipola
remove mism
re 8. Two-way gu
Figure 9.  I
10. The results of 
phy constraint to r
nitial matching 
 
ar geometry and ho
matches (102 pairs)
 
uided matching (32
 
Initial matching 
 
f using epipolar ge
remove mismatch
 
omography constr
) 
20  pairs) 
eometry and 
hes (198 pairs) 
 
 
raint to 
 
 
 
the 
fou
calc
ang
  
mat
gre
to o
bas
are 
algo
and
whi
suff
the 
dist
mo
bas
wit
the
sho
it a
cor
incr
enh
the 
use
usu
in f
Figure 
To verify the
parallax angle
ur groups of e
culated paralla
gle. 
 
Figure 12 s
tching error ra
atly reduces th
V. C
In this paper
obtain sufficie
seline image p
detected by
orithm. Then, 
d homography
ich effectively
fficient matchi
matching po
tance to filter
re precise. F
seline image p
th illumination
excellent res
ow that this alg
also has better
rner detection 
rease the qu
hance the accu
homography
ed in this algo
ually get poor 
future research
 
0%
20%
40%
60%
Error Rate
11.  Two-way Gu
e correctness 
e of the image
error rate test
ax angle is in a
Figure 12.   R
 
hows the ini
ate. As can be 
he matching er
CONCLUSION A
, we successfu
ent and reliable
pairs. First, a 
y using multi
we comprehe
y constraint t
y settle the con
ing points wi
oints. Meanwh
r the matchin
Finally, we h
pairs under d
n changes, sel
sults for all o
gorithm can e
match proper
and matchin
antity of com
uracy of 3D r
y constraint o
orithm, the pi
test results, w
h. 
   Exp1  Exp
uided matching (6
 
of our algorit
es and conduc
ting. The resu
accordance wi
Results Statistics 
itial matching
seen from the
rror rate. 
 
AND FUTURE W
fully solved th
e matching po
large number
i-scale Harris
ensively apply
to guided ma
nflict between
ithout reducin
hile we have 
ng points, mak
have tested a 
different sever
f-similarities, 
of the images
effectively dete
rty compared w
ng algorithm. 
mmon points 
reconstruction
of geometric p
ictures with g
which still nee
p2    Exp3    E
685 pairs) 
thm, we calcu
ted experimen
ults show tha
ith the real par
g and the gu
e chart, this me
WORK 
he problem of
oints over two
r of feature p
s corner dete
y epipolar geom
atching algor
n wide baselin
ng the accurac
applied Eucli
king the matc
number of
re camera mo
and have obta
. The experim
ect and match
with the tradit
This method
in 3D and 
n. However, d
plane surface
great depth ch
eds to be impr
Exp4
Initial
Match
Guide
Match
 
ulated 
nts on 
at the 
rallax 
 
uided 
ethod 
f how 
wide 
points 
ection 
metry 
rithm, 
e and 
cy of 
idean 
ching 
wide 
otions 
ained 
ments 
h, and 
tional 
d can 
then 
due to 
e that 
hange 
roved 
hing
e‐
hing
23
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

 
VI. ACKNOWLEDGEMENT 
This paper is supported by the Fundamental Research 
Funds for the Central Universities, Number: 1107021051, and 
National Natural Science Fundation of Jiangsu Province of 
China, Number:  BK2010386. 
 
REFERENCES 
[1] 
V. Kolmogorov and R. Zabih, “Computing visual correspondence with 
occlusions via graph cuts”, Proceedings of International Conference on 
Computer Vision, 2001, pp. 508–515. 
[2] 
O. Chum and J. Matas. “Matching with prosac” Progressive sample 
consensus”. Proceedings of IEEE Conference on Computer Vision and 
Pattern Recognition, 2005, pp. 220–226. 
[3] 
P. Pritchett and A. Zisserman., “Matching and reconstruction from 
widely separated views”, Proceedings of the European Workshop on 3D 
Structure from Multiple Images of Large-Scale Environments, 1998, pp. 
78–92. 
[4] 
C. Wang, K.K. Ma, T. Khim, and D. Guo, “Mismatch Removal for Wide 
baseline Image Matching via Coherent Region-to- Region”, Proceedings 
of Fourth Pacific-Rim Symposium on Image and Video Technology, 
2010, pp. 101-106 
[5] 
C. Schimid, R. Mohr, and C. Bauckhage, “Evaluation of interest point 
detectors”, International Journal of Computer Vision, 2000 37(2), pp. 
151-172  
[6] 
K. Peng, X. Chen, D. Zhou, and Y.H. Liu, “3D Reconstruction Based on 
SIFT and Harris Feature Points”, Proceedings of International 
Conference on Robotics and Biomimetics, 2009, pp. 960-964  
[7] 
C. Harris and M. Stephens. “A combined corner and edge detector”, 
Proceedings of 4th Alvery Vision Conference, 1988, pp. 147-151 
[8] 
D. Lowe. “Distinctive Image Features from Scale-Invariant Interest 
Points”. International Journal of Computer Vision 2004, 60(2), pp. 91-
110 
[9] 
Z. Zhang, R. Deriche, and O. Faugeras, “A robust technique for 
matching two uncalibrated images trought the unknown epipolar 
geometry”. Artificial Intelligence, Special volume on computer vision, 
1995, 78(1-2), pp. 87-119 
[10] L. Tony. “Seale-space A framework for handing image structures at 
multiple Seales”. Proceedings of the conference Eurean organization for 
Nuclear Research school of computing, Egmond aan zee, The 
Netherland, 1996, pp. 8-21. 
[11] L. Tony. “Scale-space for Discrete signals”. IEEE transactions on pattem 
Analysis and machine intelligence, 1990, pp. 233-253 
[12] Y. Yang and T.W. Zhang. “Assessing criterion of corner finders” 
Journal of Harbin Institute of Technology, 1998, 30(2), pp. 7-10.   
[13] R. Hartley and A. Zisserman, “Multiple view geometry in computer 
vision”. Cambridge University Press, 2000, pp. 237-259. 
[14] Lowe and G. David G "Object recognition from local scale-invariant 
features". Proceedings of the International Conference on Computer 
Vision. 2. pp. 1150–1157 
 
24
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

