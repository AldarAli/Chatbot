Adaptive Experience-Based Composition of Continuously Changing Quality of 
Context 
 
Mats Neovius 
Department of Computer Science 
Ã…bo Akademi University  
Turku, Finland 
e-mail: mneovius@abo.fi 
 
 
Abstractâ€”Contemporary systems increasingly rely on 
information provided by autonomous agents. The autonomous 
agents provide inherently inaccurate information due to, for 
example, rounding, calibration error or subjectivity. Moreover, 
the level of information inaccuracy may change without notice. 
Regardless the reason of the inaccuracy, a system relying on 
such information needs to adapt to the quality of the momentary 
information. In this paper, we propose a method for this 
adaption. The method bases on evidence theory and probability 
theory to compose a ground truth from disjoint information in 
a proposition. This ground truth is used to evaluate the disjoint 
information and determine this experienceâ€™s score. Each 
experience adds to the history of experiences in an agent, i.e., to 
the amount and character of evidence an agent has on anotherâ€™s 
performance. Moreover, the method features a forgetting 
parameter facilitating adaption in case of, for example, 
maintenance to the providing agent. The method output is one 
parameter denoting the level of confidence the system certifies 
the composed information with. The presented method is 
validated by a case study on a dataset of in-house temperature 
data. 
Keywords-Experience-based 
trust; 
adaptive 
systems, 
reputation-based trust, evidence theory; uncertainty, trust model. 
I. 
 INTRODUCTION 
In the era of big data and cloud computing, a system 
manifests in an application providing a human user a means 
to perform a task [1 â€“ 2]. The device, in this case, functions as 
the mere portal to the userâ€™s application space and information 
enhanced environment; with the application providing the 
user-interface and the gateway to the Internet scale 
information 
enhanced 
environment. 
This 
information 
enhanced environment is stored, maintained, updated and 
provided by autonomous agents connected â€˜all the time 
everywhereâ€™ [3]. Hence, the application produces automated 
transactions in the Information Revolution [4] without any 
conception of the momentary level of confidence that may 
justifiably be placed on the information it relies on.  
In this setting, each piece of information is subject to the 
context in which it was created. For example, consider a 
measurement value of an elementary sensor, the information 
imperfection includes: imprecision when being inexact, 
ambiguity when non-unanimous data are available, error 
when a mismatch is found between the actual and reported 
value and unknown when the properties are not fully known 
[5]. On these, van Bunningen et al. [6] note that information 
dependent on the context of its measurement is continuously 
changing, imperfect and uncertain. In wireless sensor 
networks, Nakamura et al. [7] list reasons including variations 
of temperature, pressure, electromagnetic noise, radiation and 
conclude that sensorsâ€™ measurements may be rendered 
imprecise (or even useless). These inaccuracies and 
ambiguities, being the context of the information, count for 
the inherent inaccuracy that all contextual information is 
subject to.  
This inaccuracy is captured by the concept of Quality of 
Context (QoC) [8]. In QoC, context is defined as â€œâ€¦any 
information that can be used to characterize the situation of 
an entityâ€¦â€ [9] and it describes the contextual informationâ€™s 
distance from the real world  [10]. QoC is defined on the 
information, not the provider, with parameters including: 
precision, 
probability 
of 
correctness, 
trustworthiness, 
resolution and up-to-dateness [8]. Of these, trustworthiness is 
noted as the rated certainty of the other QoC parameters. That 
is, trustworthiness is the information providing agentâ€™s level 
of certification on the information it provides. Thus, the 
parameter of trustworthiness outlines a level of confidence 
and (un)certainty in the information.  
McKnight and Chervaney [11] define the trusting 
intension as â€œThe extent to which one party is willing to 
depend on the other party in a given situation with a feeling 
of relative security, even though negative consequences are 
possibleâ€. From this definition we note that the parties are 
agents, called trustor and trustee, where a trustor willingly 
trusts a trustee despite a risk of a negative outcome. Thus, trust 
is valid only when something can go wrong. Moreover, as the 
feeling of relative security may vary by trustor and situation, 
the level of trust is subjective. With respect to confidence, 
(un)certainty and the ever changing context, we further stress 
that a level of trust needs to continuously adapt. For this, we 
use Dempster-Shafer (DS) theory of evidence and its 
extension called Subjective Logic (SL). 
SL is a probabilistic logic originally proposed by JÃ¸sang 
[12]. It may be used to analyse Bayesian networks [13]. SL 
provides a computational logic for calculating subjective trust 
by a three-valued parameter called an opinion. Moreover, it 
features second-hand evidence. A mapping function between 
21
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-391-9
ADAPTIVE 2015 : The Seventh International Conference on Adaptive and Self-Adaptive Systems and Applications

a SL opinion and the Beta probability density function (Î’pdf) 
have been devised [12] [14]. To provide the input to SL and 
Î’pdf, we outline an experience in line with Teacy [15] and 
Neovius [16] as a four tuple. Each experience is a piece of 
evidence of an agentâ€™s evaluated transaction with another 
agent. The set of experiences is the history of an agentâ€™s 
evaluated transactions. Hence, the experience-based trust; 
sometimes used interchangeably with the concept of 
reputation-based.  
In this paper, we outline the logics of a trust calculation 
and present a computational model for adaption by trust 
levels. The modelâ€™s output is a tuple, called the abstract score 
that complies with the Î’pdf type and thus, with SL 
framework. We extend on previous work [17] by the 
generality, motivating and presenting the mathematical 
treatment of uncertainty in DS theory and by highlighting the 
adaptive behaviour. Moreover, we elaborate on the history of 
experiences; motivating the experience-based approach. This 
is also the main contribution of this paper; as the history of 
experiences builds up and decays, the level of trust adapts. 
Based on the findings, we claim that the adaptive behaviour 
enables correction of inherently inconsistent and inaccurate 
information. To the best of our knowledge, this paper is the 
first to study the combination of context, adaption and 
subjective trust from a mathematical-logical point of view. In 
addition, this paper elaborates on the limitations of the 
approach by presenting assumed properties of a trust relation. 
Thus, this paper takes a more general view on experience-
based trust and uses the in-house case study as validation; as 
opposed to the case study walk-through provided in previous 
work [17]. The most severe limitation of the approach is the 
need of a ground truth. If such a ground truth cannot be 
devised, the method is void. However, a ground truth may be 
defined by a human evaluation, derived indirectly or, as in the 
case study, derived as a variant of redundant measurements.  
The general plot of this paper is depicted in Fig. 1 featuring 
three kinds of agents, inspired by related work [18] - [22]. Top 
left agent observes a property of a phenomenon transforming 
a real world event to a software event. Realistically, this is a 
temperature sensor. Bottom left, in the middle and bottom 
right are agents that rely on observations and other providing 
agents for supplying information needed for inference. The 
inference may, or may not give rise to triggering an actuator 
(top right) transforming the software event back to a real 
world event. We note, however, that the inference is out of the 
scope of this paper.  
The reminder of this paper is organized as follows: In 
Section II, we outline the basics for evidence theory. Section 
III describes the experience-based trust including the level of 
trust, experiences, score type, decay function and a means to 
abstract the history of experiences to outline a subjective level 
of trust. Section IV describes the case study and highlights a 
clear point of adaption. Section V concludes the paper 
followed by references in Section VI. 
II. DEMPSTER-SHAFER THEORY OF EVIDENCE 
As noted, a level of trust encompasses the level of 
confidence as dependence and reliance and a level of 
(un)certainty. For this, DS theory of evidence [23], also 
known as a belief function fits well. A belief function relies 
on a set of known outcomes ğœ , called the frame of 
discernment. This frame denotes the exclusive and 
exhaustive outcomes, e.g., in case of determining the colour 
of a ball, all possible colours. On a frame, the mass (certainty) 
ğ‘š: 2ğœ â†’ [0, 1]  denotes the level of evidence for each 
outcome. The probabilistic view on the evidence assigns m to 
each element 2ğœ and is called basic belief assignment where 
ğ‘š(âˆ…) = 0 and âˆ‘
ğ´âˆˆ2ğœ ğ‘š(ğ´) = 1
. This additivity denotes that 
an evaluation is performed each time. In case the observer is 
uncertain, e.g., in case a red-green colour blind person 
evaluates a red ball on mass space ğœ = {ğ‘¥ğ‘Ÿğ‘’ğ‘‘, ğ‘¥ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘›, ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘’} 
the evaluation is ({ğ‘¥ğ‘Ÿğ‘’ğ‘‘, ğ‘¥ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘› }). That is, the evaluation 
provides a piece of evidence for â€œnot ğ‘¥ğ‘ğ‘™ğ‘¢ğ‘’â€.  
In addition to the mass m, the belief bel is defined ğ‘ğ‘’ğ‘™(ğ´) 
= âˆ‘
ğµâŠ†ğ´ ğ‘š(ğµ)
. Hence, bel denotes the â€˜certaintyâ€™ or 
â€˜evidenceâ€™ in a set as the sum of masses of its subsets, e.g., 
ğ‘ğ‘’ğ‘™({ğ‘¥1, ğ‘¥2}) =  ğ‘š({ğ‘¥1}) +  ğ‘š({ğ‘¥2}) +  ğ‘š({ğ‘¥1, ğ‘¥2}). The 
mass of the total set ğ‘š(ğœ)  may not be 0, i.e., 
ğ‘š({ğ‘¥1, ğ‘¥2, ğ‘¥3}) â‰   0. Realistically, this is the case when a 
blind person would evaluate a ballâ€™s colour. Plausibility pl 
denote the â€˜max probabilityâ€™; or that â€˜there is evidence 
against this propositionâ€™. Thus, ğ‘ğ‘™ â‰¥  ğ‘ğ‘’ğ‘™  and ğ‘ğ‘™(ğ´) =
 âˆ‘
ğ´âˆ©ğµâ‰ âˆ… ğ‘š(ğµ)
; the sum of non-empty intersecting masses or 
more conveniently, ğ‘ğ‘™(ğ´) =  1 âˆ’ ğ‘ğ‘’ğ‘™(ğ´Ì…) where ğ´Ì… denotes 
complement of A. Thus, belief and plausibility provides the 
 
Figure 1. The adaptive agent 
22
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-391-9
ADAPTIVE 2015 : The Seventh International Conference on Adaptive and Self-Adaptive Systems and Applications

lower (bel) and upper (pl) bounds of evidence with the 
uncertainty as the difference between these. Consequently, 
DS theory provides a foundation for evidence-based trust. 
Readers interested in this relation and its theoretical 
foundations with trust are directed elsewhere [24] [25].  
III. EXPERIENCE-BASED TRUST 
An experience is an evaluation generated by a trustor A 
on a transaction it had with a trustee B. Obviously, when the 
evaluation is subject to bias or appreciation, Aâ€™s evaluation is 
subjective. This implies that if agents B and C share an 
experience on a matter, Aâ€™s and Câ€™s evaluations may 
justifiably be different without anyone â€œlyingâ€. Moreover, 
Aâ€™s trust in B does not indicate anything of Bâ€™s trust in A, 
hence trust is asymmetric. On the history of experiences, it is 
motivated that more recent experiences weighs heavier. 
Hence, the level of trust is incomplete, i.e., it is non-absolute 
and non-dogmatic. This implies that trust evolves over time 
and is non-monotonic. Non-monotonicity fundamentally 
differentiates experience-based trust from statistical model 
checking methods. Moreover, as B may provide information 
regarding disjoint frames, e.g., observing the colour of a ball 
and its elasticity, the trust level is proposition specific. That 
is, given disjoint ğœ1 and ğœ2, Aâ€™s level of trust on B in ğœ1 and 
ğœ2 may be different [26]. The proposition specificity also 
encapsulates a frame of discernment from other frames, thus, 
voiding cross-layer effects of unforeseen dependencies. 
The property of trust transitivity is discussed in literature 
[13] [27] -  [29] with motivations for and against. In the 
presented method, positive trust is considered transitive, but 
negative trust (distrust) is not [30]. That is, if agent A trusts B 
and B trusts C, then by transitivity A trusts C. If distrust were 
transitive solving whether your enemyâ€™s enemy is your friend 
[25] would be required, i.e., if A distrust B and B distrust C, 
does this indicate that A trusts C? This motivates our view 
that distrust indicates not to trust any information provided 
by a distrusted agent, here B. More on these trust properties 
and their foundations is found elsewhere [27].  
A. The Level of Trust  
Let a trust relation derived from experiences between two 
agents, A and B, be denoted by T. Moreover, let the level of 
trust be denoted ğœ”. Thus, agent Aâ€™s trust in B in a proposition 
is denoted ğ´ğœğ‘‡Ï‰ğµ. Whenever the proposition ğœ âŠ‚ 2ğœ âˆ§  ğœ â‰ 
âˆ…, this level is subadditive. A subadditive level of trust 
features the levels of confidence as (dis)belief and 
(un)certainty. Here, uncertainty must not be confused with 
(dis)belief, also known as distrust [31] [32]. Moreover, the 
uncertainty enables implementation of decay reducing 
evidence without subverting the experience.  
In addition to the level, we distinguish between first-hand 
and second-hand trust levels as in SL [12]. A first-hand trust 
level is derived from first-hand direct (d) experiences with 
the trustee in a proposition. A second-hand trust level is an 
indirect (i) level, where referral agentsâ€™ experiences are used 
to strengthen an agentâ€™s evidence. Moreover, trusting an 
agent as a referral is a meta proposition in its own right; thus 
we consider trust either referral (r) or functional (f). Indirect 
functional trust when ğ´ğœğ‘‡ğ‘‘ğ‘ŸÏ‰ğµ and ğµğœğ‘‡ğ‘‘ğ‘“Ï‰ğ¶ between agent 
A and C is denoted ğ´ğœğ‘‡ğ‘–ğ‘“Ï‰ğ¶, depicted in Fig. 2. 
 
 
Figure 2. Trust transitivity 
B. The Experiences 
In order to derive a level of experience-based trust, we 
need to define the experience type. The type is defined a four 
tuple (ğ›¿, ğœ–, ğœ, ğœ‚), inspired by Krukow [33] Teacy et. al [15] 
first introduced in Neovius [16]. The elements of the tuple 
are: ğ›¿ âˆˆ {âŒ©ğ‘ğ‘”ğ‘’ğ‘›ğ‘¡ğ‘ âŒª}, ğœ– as the datum,  ğœ âŠ† {âŒ©ğ‘“ğ‘Ÿğ‘ğ‘šğ‘’âŒª} and 
ğœ‚ âˆˆ {âŒ©ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’âŒª} . Realistically, the datum ğœ–  is time. An 
experience generated by agent A on B at x in proposition y 
with score z is denoted ğ¸ğ‘¥ğ‘ğ´(ğœ–) = (ğµ, ğ‘¥, ğ‘¦, ğ‘§). The history 
of agent Aâ€™s experiences ğ¸ğ‘¥ğ‘ğ´(ğœ–ğ‘–) for i = 1, â€¦, n is a set of 
disjoint experience, i.e., {(ğ›¿, ğœ–, ğœ, ğœ‚)} . Adding a new 
experience (ğ›¿, ğœ–0, ğœ, ğœ‚) at datum ğœ–0 to the history is straight 
forward ğ¸ğ‘¥ğ‘ğ´(ğœ–ğ‘—) = (ğ›¿, ğœ–0, ğœ, ğœ‚) âˆª {(ğ›¿, ğœ–ğ‘–, ğœ, ğœ‚)} where j = 1, 
..., n, ğœ–0.  
On this experience type, projections provide specific 
experiences. Consider agent A to have interacted with B, then 
experiences on B at ğœ–  are projected by ğ¸ğ‘¥ğ‘ğ´(ğµ, ğœ–) =
{(ğµ, ğœ–, ğœ, ğœ‚)} where {(ğµ, ğœ–, ğœ, ğœ‚)} âŠ† {(ğ›¿, ğœ–ğ‘–, ğœ, ğœ‚)}. Projecting 
on any element is done similarly, e.g., ğ¸ğ‘¥ğ‘ğ´(ğµ, ğœ–ğ‘, ğ‘¥) =
{(ğœ–ğ‘–, ğœ‚)} for ğ‘¥ âŠ† ğœ and ğœ–ğ‘– â‰¤ ğœ–ğ‘ for i = 0, 1, â€¦ p.  
C. Type of Score 
We propose a versatile score type as a tuple (sat, usat) for 
satisfactory and unsatisfactory. Here ğ‘ ğ‘ğ‘¡, ğ‘¢ğ‘ ğ‘ğ‘¡ âˆˆ [0, 1] and 
ğ‘ ğ‘ğ‘¡ + ğ‘¢ğ‘ ğ‘ğ‘¡ â‰¤ 1 . 
Subadditivity 
is 
fundamental 
for 
implementing uncertainty and decay without subverting the 
semantics of the experiencesâ€™ score. A score is dogmatic 
whenever ğ‘ ğ‘ğ‘¡ + ğ‘¢ğ‘ ğ‘ğ‘¡ = 1 . Coarsening a multinomial 
proposition |ğœ| â‰¥ 3 to a binomial |ğœ| = 2 is done by summation, 
i.e., considering the coloured balls ğœ = {ğ‘¥ğ‘Ÿ, ğ‘¥ğ‘”, ğ‘¥ğ‘}  with 
ğ¸ğ‘¥ğ‘ğ´ (ğ´, ğœ–, (ğ‘¥ğ‘Ÿ, ğ‘¥ğ‘”)) = {(ğœ–ğ‘–, (ğ‘ ğ‘ğ‘¡, ğ‘¢ğ‘ ğ‘ğ‘¡))}  providing the 
evidence against ğ‘¥ğ‘ . Related work considering a similar 
score type includes Noorian et al. [34] model.  
With this score type, vacuous experiences are expressed 
with the score (0, 0); dogmatic scores (the probabilistic view) 
ğ‘ ğ‘ğ‘¡ + ğ‘¢ğ‘ ğ‘ğ‘¡ = 1; and absolute scores (binary view) when 
(sat, usat) = (0, 1) or (sat, usat) = (1, 0). Thus, a score is valid 
with a certainty of sat + usat, e.g., given sat = 0.3 and usat = 
0.5, the certainty is 0.8. From this, uncertainty u is easily 
23
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-391-9
ADAPTIVE 2015 : The Seventh International Conference on Adaptive and Self-Adaptive Systems and Applications

derived, ğ‘¢ = 1 âˆ’ ğ‘ ğ‘ğ‘¡ âˆ’ ğ‘¢ğ‘ ğ‘ğ‘¡ as is the dogmatic expectation 
value of satisfyability as ğ‘ ğ‘ğ‘¡ / (ğ‘ ğ‘ğ‘¡ +  ğ‘¢ğ‘ ğ‘ğ‘¡). 
D. Decay of an Experience Score 
Decay of an experience score is the act of forgetting or 
forgiving. This is fundamental in case of transient faults or 
maintenance / update on the data provider having an effect on 
the data quality. Fundamental for decay is that it must not 
subvert the score of experiences, only reduce its weight [34]. 
Let the decay factor be denoted by ğœ†  where 0 â‰¤ ğœ† â‰¤ 1 . 
Decay relies on a continuous factor by which it decays, here 
datum ğœ–. We define the general decay function ğ‘‘ at datum ğœ–ğ‘š 
called ğ‘‘ğœ–ğ‘š on an experience ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘–) where ğœ–ğ‘– â‰¤ ğœ–ğ‘š as:  
ğ‘‘ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘–)) = (ğ›¿â€², ğœ–ğ‘–, ğœ, ğœ†ğœ–ğ‘šâˆ’ğœ–ğ‘– âˆ— ğœ‚) 
(1) 
Dually, this decay may be applied on the history of 
experiences where ğœ–ğ‘› =  1, â€¦ , ğ‘š and ğœ–ğ‘› â‰¤ ğœ–ğ‘š: 
ğ‘‘ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘›)) = {(ğ›¿â€², ğœ–ğ‘›, ğœ, ğœ†ğœ–ğ‘šâˆ’ğœ–ğ‘› âˆ— ğœ‚)} 
(2) 
With equations (1) and (2), the closer ğœ† is to 1 the slower 
the speed of decay with ğœ† =  1 indicating no decay at all. No 
decay is motivated in, among others, quantitative statistical 
analysis. Contrary, ğœ† =  0 indicates complete decay as in a 
stochastic process [35].  
E. Abstracting Experiences 
To calculate with the experiences, the projection on 
the experiencesâ€™ scores needs to be composed. We call 
this an abstract experience Abs at datum ğœ–ğ‘š , hence 
ğ´ğ‘ğ‘ ğœ–ğ‘š. If this abstraction is done on decayed experiences, 
such a composition outlines the momentary decayed 
score, the abstracted score absscore. We define this for ğœ–ğ‘› = 
1, â€¦, m and ğœ–ğ‘› â‰¤ ğœ–ğ‘š: 
ğ´ğ‘ğ‘ ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘š)) = (ğ›¿â€², ğœ–ğ‘š, ğœ, âˆ‘
ğ‘‘ğœ–ğ‘šğ¸ğ‘¥ğ‘ğ›¿(ğ›¿â€²,ğœ–ğ‘›,ğœ) ğœ‚)
 (3) 
With this, ğ´ğ‘ğ‘ ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğ›¿â€², ğœ–ğ‘š, ğœ))  score absscore âˆˆ â„+ 
relies on summation defined (abssat, absusat).  
 Not surprisingly, as ğ´ğ‘ğ‘ ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘–))  denotes the 
absscore decayed at datum ğœ–ğ‘š , an updated abstract view 
ğ´ğ‘ğ‘ ğœ–ğ‘šâ€² (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘–)) where m â‰¤ mâ€™ is a recursive function [36] 
whenever the decaying factor is universal, continuous and 
applied on all experiences locally, e.g., decay by time. Hence, 
updating ğ´ğ‘ğ‘ ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘–))  to ğœ–ğ‘šâ€²  where ğœ–ğ‘šâ€²  = ğœ–ğ‘š + ğ‘–  is 
straightforward: 
 ğ´ğ‘ğ‘ ğœ–ğ‘šâ€² (ğ¸ğ‘¥ğ‘ğ›¿(ğœ–ğ‘–)) = ğ›¿â€², ğœ–ğ‘šâ€², ğœ, (ğ¸ğ‘¥ğ‘ğ›¿(ğ›¿â€², ğœ–ğ‘šâ€², ğœ, ğœ‚) +
 ğ´ğ‘ğ‘ ğœ–ğ‘š (ğ¸ğ‘¥ğ‘ğ›¿(ğ›¿â€², ğœ–ğ‘š, ğœ)) âˆ— ğœ†ğ‘–) (4) 
Here, ğ¸ğ‘¥ğ‘ğ›¿(ğ›¿â€², ğœ–ğ‘šâ€², ğœ, ğœ‚)  is the new experience. Thereby, 
abstraction is an irreversible function that provides some 
level of privacy that decay enhances on. This abstracted 
experience with a score (abssat, absusat) may be depicted as 
a Î’pdf and is, hence, mappable to an opinion in SL. Examples 
may be found elsewhere [36] - [38]. Computationally, the 
method is very light thus, facilitating scalability. 
IV. 
IN-HOUSE CASE STUDY 
As proof of concept, we have applied the presented 
method on an in-house temperature measurement system. 
This system encompasses a dataset of four disjoint points of 
temperature measurement with 10 seconds interval over a 
time span of one year; a total of ~12 million readings. We 
filtered the dataset from impossible measurements such as -
49950Â°C by disregarding readings outside the interval 
[âˆ’50Â°ğ¶, 50Â°ğ¶]. We used Î» = 0.95 as in eq. (1, 2, 4).  
The purpose is to model an â€œin-house temperature agentâ€ 
that composes the disjoint measurements to the most 
probable temperature and certifies this by a level of trust. For 
this, the method provides a weighted mean temperature (wmt) 
and a weighted level of trust (wlt). The wlt defines the 
momentary level of trust that the in-house temperature agent 
certifies the wmt with that sets the ground truth. An 
elementary temperature measurement experienceâ€™s score is 
generated by the three-sigma rule of standard deviation from 
the normal distribution of the posterior wmt. Thus, initially 
with no experiences (equal trust on all measurements) the 
wmt is the arithmetic mean.  
A snapshot of the analysis is depicted in Fig. 3. The 
abbreviations in the legend of Fig. 3 are as follows. On the 
left scale: FiPl = fireplace sensor, LiRo = living room sensor, 
wlt, Hallway = hallway sensor, BedR2ndF = bedroom 2nd 
floor sensor; and on the right scale: Mean temp. = arithmetic 
mean temperature in Â°C, Daily mean = the daily mean 
temperature outdoor in Â°C and wmt in Â°C. The primary 
vertical axis denotes the trust level, the secondary vertical 
axis denotes the temperature Â°C, and the horizontal axis 
denotes time as mm.dd.yyyy hh:min.  
TABLE I.  
A SAMPLE OF TEMPERATURES AND TRUST LEVELS 
Fig. 3 reveals that FiPl is malfunctioning by a close to 0 
level of trust. Table 1 depicts this inconsistency as a more 
specific snapshot. Fig. 3 also reveals that once the outdoor 
temperature (daily mean) exceeds approximately 19Â°C, the 
trustworthiness levels start to deviate. This holds true when 
inspecting the raw data, with the conclusion that LiRo and 
Temperat
ure 
Measurements (4000sec. interval) in Â°C 
Arith. 
mean 
LiRo 
temp 
EnWa 
temp 
B2F 
temp 
FiPl 
temp 
wmt 
wlt 
6.15.2013  
3:13 â€“3:46 
21,68 
26,40 
17,77 
18,82 
21,60 
21,64 
23,55 
23,55 
23,55 
23,55 
23,55 
23,55 
22,75 
22,42 
22,42 
22,42 
22,42 
22,55 
23,26 
23,26 
23,26 
23,26 
23,26 
23,26 
17,18 
36,37 
1,8 
5,67 
17,18 
17,18 
23,19 
23,08 
23,08 
23,08 
23,08 
23,12 
0,72 
0,79 
0,80 
0,81 
0,80 
0,81 
â€¦ 
â€¦ 
â€¦ 
â€¦ 
â€¦ 
â€¦ 
â€¦ 
â€¦ 
6.27.2013 13:37 â€“
6.27.32013 14:26 
26,65 
28,29 
24,45 
24,44 
24,45 
21,56 
21,58 
23,48 
29,35 
23,43 
23,43 
23,43 
23,43 
23,43 
23,43 
23,43 
26,36 
26,36 
26,36 
26,29 
26,36 
26,29 
26,36 
26,29 
29,88 
27,01 
27,01 
27,01 
27,01 
27,01 
27,01 
27,01 
21,02 
36,37 
21,02 
21,02 
21,02 
9,51 
9,51 
17,18 
28,59 
25,64 
25,67 
25,66 
25,69 
25,69 
25,69 
25,68 
0,77 
0,76 
0,75 
0,75 
0,71 
0,66 
0,74 
0,74 
24
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-391-9
ADAPTIVE 2015 : The Seventh International Conference on Adaptive and Self-Adaptive Systems and Applications

BedR2ndF correlates and vary more heavily depending on 
the time of day and outdoor temperature, whereas Hallway is 
more stable. To illustrate this, Fig. 3 plots a timespan of late 
June 2013, when the outdoor temperature at the location of 
the house was higher than the adjusted indoor temperature 
resulting in deviations in the levels of trust.  
Notable in the graph is the sudden drop of trust levels of 
LiRo, BedR2ndF and the relative increase of Hallway points 
of measurement 06.27.2013 at around 13:40. The reason for 
this is a thunder storm. Fig. 3 plots this as a drop in wmt and 
inconsistency in trust levels in a reasonable manner only to 
recover gradually, with a lower Î» the recovery is faster. 
Hence, the system adapted to the change in information 
quality. Moreover, it reasonably dropped the weighted mean 
temperature and the weighted mean trust during the 
inconsistent event of the thunder storm.  
V. 
CONCLUSIONS 
The trend in contemporary computerised systems is 
towards agent and system autonomy. Concepts like system of 
systems, software as a service and many alike are proofs of 
this. In all these cases, the application performing a task for a 
stakeholder is assumed to rely on information provided by 
agents not in its control. As there is no guarantee on the 
providing agentsâ€™ reliability, a consuming agent may only 
adapt to the momentary best-effort perception on the 
providing agent. A survey may be found elsewhere [39]. This 
paper motivates, define and use a level of trust as the basis 
for adaption.  
The approach is implemented on a dataset of four 
temperature sensors. Though this dataset is very well fitted 
for this particular approach, the underlying mathematics is 
described in detail sufficient to be applied on related problem 
scenarios. We believe that the results will be good if done; an 
issue that remains as future work. Moreover, the method scale 
as it is computationally light. In addition, the case-study 
sensors could be replaced by an adaptive agent as in Fig. 1, 
e.g., being provided by a service.  
ACKNOWLEDGMENT 
This research is funded by the Academy of Finland 
project â€œFResCo: High - quality Measurement Infrastructure 
for Future Resilient Control Systemsâ€ (Grant nr. 264060). 
REFERENCES 
[1]  G. Banavar, J. Beck, E. Gluzberg, J. Munson, J. Sussman and 
D. Zukowski, â€œChallenges: an application model for 
pervasive computing.,â€ In Proceedings of the 6th Annual 
international Conference on Mobile Computing and 
Networking, 2000.  
[2]  G. Banavar and A. Bernstein, â€œSoftware infrastructure and 
design challenges for ubiquitous computing applications,â€ 
Commun. ACM, vol. 45, nr 12, pp. 92-96, 2002.  
[3]  S. Marzano and E. Aarts, The New Everyday View on 
Ambient Intelligence, Uitgeverij 010 Publishers, 2003.  
[4]  H. Alesso and C. Smith, Thinking on the web, Wiley Inc. 
ISBN-13: 978-0-471-76814-2, 2006.  
[5]  K. Henricksen and J. Indulska, â€œModelling and Using 
Imperfect Context Information,â€ In Proceedings of the 
Second IEEE Annual Conference on Pervasive Computing 
and Communications Workshops (PERCOMW '04), 2004.  
[6]  A. van Bunningen, L. Feng and P. Apers, â€œContext for 
ubiquitous data management,â€ International Workshop on 
Ubiquitous Data Management, 2005.  
[7]  E. Nakamura, A. Loureiro and A. Frery, â€œInformation fusion 
for wireless sensor networks: Methods, models, and 
classifications,â€ ACM Comput. Surv. , vol. 39, nr 3, 2007.  
Figure 3. Indoor temperature and measurement processesâ€™ trust levels with Î» = 0.95 (June 2013) 
10
15
20
25
30
35
40
45
50
0
0,1
0,2
0,3
0,4
0,5
0,6
0,7
0,8
0,9
1
 06.16.2013 00:00
 06.16.2013 06:27
 06.16.2013 12:54
 06.16.2013 19:22
 06.17.2013 01:48
 06.17.2013 08:15
 06.17.2013 14:42
 06.17.2013 21:09
 06.18.2013 03:36
 06.18.2013 10:03
 06.18.2013 16:30
 06.18.2013 22:57
 06.19.2013 05:24
 06.19.2013 11:51
 06.19.2013 18:17
 06.20.2013 00:44
 06.20.2013 07:11
 06.20.2013 13:38
 06.20.2013 20:04
 06.21.2013 02:32
 06.21.2013 08:58
 06.21.2013 15:30
 06.21.2013 21:57
 06.22.2013 04:24
 06.22.2013 10:50
 06.22.2013 17:20
 06.22.2013 23:50
 06.23.2013 06:17
 06.23.2013 12:44
 06.23.2013 19:11
 06.24.2013 01:37
 06.24.2013 08:04
 06.24.2013 14:31
 06.24.2013 20:58
 06.25.2013 03:24
 06.25.2013 09:51
 06.25.2013 16:18
 06.25.2013 22:44
 06.26.2013 05:11
 06.26.2013 11:38
 06.26.2013 18:04
 06.27.2013 00:43
 06.27.2013 07:10
 06.27.2013 13:39
 06.27.2013 20:07
 06.28.2013 02:34
 06.28.2013 09:00
 06.28.2013 15:27
 06.28.2013 21:54
 06.29.2013 04:21
 06.29.2013 10:47
 06.29.2013 17:14
 06.29.2013 23:41
 06.30.2013 06:07
 06.30.2013 12:34
 06.30.2013 19:10
FiPl
LiRo
wlt
Hallway
BedR2ndF
Mean temp.
Daily mean
wmt
25
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-391-9
ADAPTIVE 2015 : The Seventh International Conference on Adaptive and Self-Adaptive Systems and Applications

[8]  T. Buchholz, A. KÃ¼pper and M. Schiffers, â€œQuality of Context 
Information: What it is and why we need it,â€ In proc. of the 
10th HPOVUA workshop , 2003. 
[9]  A. Dey and G. Abowd, â€œTowards a Better Understanding of 
Context and Context-Awareness,â€ Workshop on the What, 
Who, Where, When, Why and How of Context-Awareness, 
2000.  
[10]  C. Villalonga, D. Roggen, C. Lombriser, P. Zappi and G. 
TrÃ¶ster, â€œBringing quality of context into wearable human 
activity recognition systems.,â€ In Proceedings of the 1st 
international Conference on Quality of Context, 2009. 
[11]  H. McKnight and N. Chervaney, â€œThe Meanings of Trust,â€ 
Technical Report Working Paper Series 96-04, 1996. 
[12]  A. JÃ¸sang, â€œArtificial Reasoning with Subjective Logic,â€ 
Second Australian Workshop on Commonsense Reasoning, 
1997.  
[13]  A. JÃ¸sang, R. Hayward and S. Pope, â€œTrust network analysis 
with subjective logic,â€ In Proceedings of the 29th 
Australasian Computer Science Conference, 2006.  
[14]  A. JÃ¸sang, â€œTrust-Based Decision Making for Electronic 
Transactions,â€ Proceedings of the 4th Nordic Workshop on 
Secure Computer Systems (NORDSECâ€™99), 1999.  
[15]  W. Teacy, J. Patel, N. Jennings and M. Luck, â€œTRAVOS: 
Trust and Reputation in the Context of Inaccurate Information 
Sources,â€ Autonomous Agents and Multi-Agent Systems, 
vol. 12, nr 2, pp. 183-198. , 2006.  
[16]  M. 
Neovius, 
â€œTrustworthy 
Context 
Dependency 
in 
Ubiquitous Systems,â€ PhD thesis, TUCS Dissertations, 2012. 
[17]  M. Neovius, M. Stocker, M. RÃ¶nkkÃ¶ and L. Petre, 
â€œTrustworthiness Modelling on Continuous Environmental 
Measurement,â€ In Proceedings of the 7th International 
Congress on Environmental Modelling and Software, 2014.  
[18]  J. Coutaz and G. Rey, â€œFoundations for a Theory of 
Contextors,â€ Proceedings of the Fourth International 
Conference on Computer-Aided Design of User Interfaces, 
2002.  
[19]  G. Rey and J. Coutaz, â€œThe Contextor Infrastructure for 
Context-Aware 
Computing,â€ 
Component-oriented 
Approaches to Context-aware Computing ECOOP'04, 2004.  
[20]  P. Gray and D. Salber, â€œModelling and Using Sensed Context 
Information in the Design of Interactive Applications,â€ In 
Proceedings of the 8th IFIP international Conference on 
Engineering For Human-Computer interaction, 2001.  
[21]  G. Biegel and V. Cahill, â€œA Framework for Developing 
Mobile, Context-aware Applications,â€ In Proceedings of the 
Second IEEE international Conference on Pervasive 
Computing and Communications (Percom'04) , 2004.  
[22]  A. Fitzpatrick, G. Biegel, S. Clarke and V. Cahill, â€œTowards 
a Sentient Object Model,â€ Workshop on Engineering 
Context-Aware Object Oriented Systems and Environments 
(OOPSLA/ECOOSE'02), 2002.  
[23]  A. Dempster, â€œUpper and lower probabilities induced by a 
multivalued mapping,â€ The Annals of Mathematical Statistics 
, vol. 38, nr 2, p. 325â€“339, 1967.  
[24]  A. JÃ¸sang, â€œSubjective Logicâ€, Draft book available 
http://folk.uio.no/josang/papers/subjective_logic.pdf , visited 
12.2.2015.  
[25]  A. JÃ¸sang and S. Pope, â€œDempster's Rule as Seen by Little 
Colored Balls,â€ Computational Intelligence, vol. 28, nr 4, pp. 
453-474, 2012.  
[26]  R. Falcone and C. Castelfranchi, Social trust: a cognitive 
approach, C. C. a. Y. Tan, Red., In Trust and deception in 
virtual societies, Kluwer Academic Publishers, 2001, pp. 55-
90. 
[27]  T. Grandison and M. Sloman, â€œA Survey of Trust in Internet 
Applications,â€ IEEE Communications Surveys and Tutorials, 
vol. 3, nr 4, 2000.  
[28]  A. JÃ¸sang and S. Pope, â€œSemantic constraints for trust 
transitivity,â€ In Proceedings of the 2nd Asia-Pacific 
conference on Conceptual modelling , 2005.  
[29]  B. Christianson and W. Harbison, â€œWhy isn't trust 
transitive?,â€ In Proceedings of the Security Protocols 
International Workshop, 1996.  
[30]  T. DuBois, J. Golbeck and S. A., â€œPredicting Trust and 
Distrust in Social Networks,â€ In IEEE Third Intâ€™l Conference 
on Privacy, Security, Risk and Trust and IEEE Third Int. 
Conference on Social Computing, 2011.  
[31]  M. Carbone, M. Nielsen and V. Sassone, â€œA Formal Model 
for Trust in Dynamic Networks,â€, BRICS Report Series 
Publications. RS-03-4, 2003. 
[32]  S. Marsh, â€œFormalizing Trust as a Computational Concept,â€ 
PhD thesis, University of Stirling, 1994. 
[33]  K. Krukow, â€œTowards a theory of trust for the global 
ubiquitous computer,â€, PhD thesis, Uni. of Aarhus 2006. 
[34]  Z. Noorian, S. Marsh and M. Fleming, â€œMulti-layer cognitive 
filtering by behavioral modeling,â€ In The 10th International 
Conference on Autonomous Agents and Multiagent Systems, 
2011.  
[35]  A. Whitby, A. Josang and J. Indulska, â€œFiltering out unfair 
ratings in bayesian reputation systems,â€ Proceedings of the 
Third International Joint Conference on Autonomous Agenst 
and Multi Agent Systems, 2004.  
[36]  A. JÃ¸sang and R. Ismail, â€œThe beta reputation system,â€ In 
Proceedings from the 15th Bled Conference on Electronic 
Commerce, 2002.  
[37]  V. Cahill, E. Gray, J. Seigneur, C. Jensen, Y. Chen, B. Shand, 
N. Dimmock, A. Twigg, J. Bacon, C. English, W. Wagealla, 
S. Terzis, P. Nixon, G. Serugendo, C. Bryce, M. Carbone, K. 
Krukow and M. Nielsen, â€œUsing Trust for Secure 
Collaboration in Uncertain Environments,â€ IEEE Pervasive 
Computing vol. 2, nr 3, pp. 52-61, 2003.  
[38]  L. Mui, M. Mohtashemi and A. Halberstadt, â€œA 
Computational Model of Trust and Reputation for E-
businesses,â€ In Proceedings of the 35th Annual Hawaii 
international Conference on System Sciences Hicss, 2002.  
[39]  A. JÃ¸sang, R. Ismail and C. Boyd, â€œA survey of trust and 
reputation systems for online service provision,â€ Decis. 
Support Syst., vol. 43, nr 2, pp. 618-644, 2007.  
 
 
 
 
26
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-391-9
ADAPTIVE 2015 : The Seventh International Conference on Adaptive and Self-Adaptive Systems and Applications

