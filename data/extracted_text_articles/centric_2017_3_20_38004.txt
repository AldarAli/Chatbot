Quantifying Mobile User Experience
Status quo, Implementation Challenges, and Research Agenda
Maria Lusky and Stephan B¨ohm
CAEBUS Center of Advanced E-Business Studies
RheinMain University of Applied Sciences
Wiesbaden, Germany
Email: {maria.lusky, stephan.boehm}@hs-rm.de
Abstract—In the last years, mobile applications (apps) have
spread out to all parts of everyday life and the app market is
growing rapidly. As developers and providers of mobile applica-
tions need to stay competitive in this environment, measuring
the user experience (UX) of mobile applications is crucial in
developing and maintaining mobile apps. In this context, methods
for measuring user experience have to be applied to speciﬁc
characteristics of mobile apps, such as context awareness, instable
internet connections, small displays and alternative operating con-
cepts. Against this background, this paper provides an overview of
recent methods for measuring the user experience in the context
of mobile applications and thus reveals research needs in this
topic. We conduct a literature survey on UX related studies in
the context of mobile applications of the last ﬁve years, taking
into account generic methods that have been directly applied to
the mobile context, methods that had been adapted, and new,
mobile speciﬁc approaches. Furthermore, we propose a research
agenda for the topic of mobile UX measuring.
Keywords–User Experience (UX); Mobile User Experience;
Human Computer Interaction (HCI); Mobile Applications; User
Centered Design
I.
INTRODUCTION
In the last years, mobile applications (apps) have been
expanding to all parts of everyday life, including education,
health, games, travel, shopping and work. The growing global
app market is predicted to reach a total spend of over six
trillion USD in 2021, which means an increase of almost
four times its value [1]. According to a recent global study
by the research agency App Annie, on a global average, one
person uses nine apps per day and installs at least one new
app per month [2]. Not only have mobile apps become an
integral part in our everyday lives, but also the number of
apps in the app stores is increasing. For every need, there are
several alternative apps, and good user experience is needed
to stay competitive. Moreover, smartphones as well as apps
are becoming more complex, and challenge developers and
publishers of mobile apps to sustain a good user experience. In
this context, user experience does not only cover the usability
of apps, but reaches out to emotional and motivational aspects
of use. In order to generate a good user experience, user
(experience) research needs to be a part of the conception,
development and maintenance of a mobile app. Also, user
analysis allows for insights in the users’ habits and preferences.
To reach this aim, there is a growing number of varying user
experience evaluation methods for assessing different types of
user experience data. Existing methods for user experience
research are applied and adapted to the context of mobile
applications, but there are also new approaches that have been
developed speciﬁcally for this area.
Against this background, the main contribution of this work
is on the one hand to provide an overview of recent methods
for measuring the user experience in the speciﬁc context of
mobile applications on smartphones and on the other hand to
reveal research needs in this topic.
This paper is structured as follows: In Section II, the
theoretical background of this work is outlined, covering
general user experience models and models for measuring user
experience. Section III focuses on the user experience in the
context of mobile applications and smartphones. In Section IV,
the results of the literature survey are presented. In Section
V, the implications are discussed and challenges as well as
research needs are pointed out based on the study ﬁndings.
Section VI summarizes key ﬁndings and concludes this work.
II.
THEORETICAL BACKGROUND
User experience (UX) in the ﬁeld of human computer
interaction describes end users’ experiences on interacting with
a system or service. The concept of user experience can be
seen from different perspectives, as a phenomenon, a ﬁeld of
study, or a practise. According to Roto et al. [3], the ﬁeld of
study investigates the experiences a person can make and how
they develop. The ways to design systems in order to create a
particular UX and methods for assessing UX are also subject
of this research. In [4], several deﬁnitions of UX from industry
and academia have been collected. Based on this work, Roto
et al. [3] have developed the following deﬁnition:
”The ﬁeld of UX deals with studying, designing for and
evaluating the experiences that people have through the use of
(or encounter with) a system. This use takes place in a speciﬁc
context, which has an impact on, or contributes to, the UX.”
This deﬁnition underlies the work that is presented in this
paper. In order to approach this topic, we will ﬁrst give an
overview of different user experience models and based on
that introduce models for measuring user experience.
A. User Experience Models
There is a variety of user experience models, such as
[5]–[8]. In this Section, we will give a brief overview of
two models from user experience practise and the description
of UX in an ISO standard. The standard EN ISO 9241
describes guidelines of human computer interaction. Following
53
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

this standard, user experience, as described in EN ISO 9241-
210, can be applied to three phases of interaction: previous to
the interaction, during the interaction, and after the interaction.
Furthermore, EN ISO 9241-11 describes usability as one
aspect of user experience that is located in the phase during
the interaction.
In [7], Garrett introduces his model ”the elements of
user experience”. According to this model, user experience
comprises ﬁve levels –strategy, scope, structure, skeleton,
and surface– that together form every digital product and,
during the development process, have to be taken into account
successively. At the ﬁrst level of strategy, the purpose and goal
of a product, as well as user requirements are speciﬁed. On the
scope level, functional speciﬁcations and content requirements
are determined. After that, the general structure is deﬁned,
comprising the information architecture and the interaction
design that forms the background of the product’s skeleton.
On this next level, information, navigation and the interface
are designed. At the top level, the surface, the sensory design
of the product is made. While the ﬁrst levels are rather abstact,
the top levels are concrete and at all levels, the users’ needs
have to be taken into account.
Another, more comprehensive model is given by Stern
[8]: The CUBI model conceptualizes user experience as four
overlapping circles – content, user goals, business goals, and
interaction (CUBI). Each of the circles is speciﬁed in ﬁve
additional layers representig aspects that have to be considered
for dealing with the particular ﬁeld. The intersections of
each two circles represent the four steps of a process that
describes a user journey: attraction, reactions, actions and
transactions. The intersections where three circles overlap are
called experience factors and constitute primary factors of an
effective user experience: branded experience, comprehensive
experience, useful experience and usable experience. While the
ﬁrst model is more practically oriented and addressed to people
who plan or develop products, the second one is theoretical and
more suitable for business processes. However, both models
have in common that UX is a concept that consists of several
aspects where content, interaction, the users’ needs and the
goals of a product or service are closely intertwined. Each
of these different aspects can be measured in order to assess
different aspects of user experience.
B. Models for Measuring User Experience
There is a large variety of metrics and methods for measur-
ing user experience, that are comprehensively described in user
experience literature [9][10]. Prominent research in this ﬁeld
was done by Vermeeren et al. [11], who collected 96 methods
from industry and academia and described how to use them.
Though uniﬁed models for quantifying user experience are
missing, there are several approaches to organize and classify
existing evaluation methods. Vermeeren et al. [11] classify
them regarding certain properties, such as the type of the
collected data, the study type, or the development phase that
the method can be used in.
Likewise, Albert and Tullis [9] established a categorization
for different types of UX evaluation methods, distinguishing
ﬁve types: (1) methods for assessing the performance, com-
prising task success, task completion time, occurring errors,
efﬁciency, and learnability of the system; (2) issue-based
methods, i.e., usability methods; (3) self-reported methods,
such as rating scales and questionnaires; (4) behavioral and
physiological methods, for example eye tracking, emotion
tracking, heart rate and skin conductance; (5) combined meth-
ods. Our literature survey on UX evaluation methods aligned to
the speciﬁties of mobile apps and smartphones presented in the
following sections will be oriented towards this classiﬁcation.
Though Vermeeren et al. continued research in the ﬁeld
of UX measuring, as Law et al. [12], their work does not
indicate, if the methods can be applied to the context of
mobile applications on smartphones. However, this is a key
issue for measuring UX, since mobile user experience differs
from desktop user experience.
III.
MOBILE USER EXPERIENCE
To our understanding and in the scope of this work, mobile
apps are application software to run on mobile devices, such as
smartphones, with which the functionality given by hardware
and operating software can be applied to solve user-speciﬁc
problems. Typically, mobile apps consist of programs and
data that will be installed by the end users themselves to the
devices and thus are also an important element of handset
personalization. One main characteristic of mobile applications
compared to classic desktop software is that they are smaller
and more speciﬁc. Different from mobile web usage, mobile
apps can integrate a broader spectrum of smartphone hardware
functionalities and interfaces, such as taking pictures with the
camera, scanning a bar code or sending voice messages using
the microphone. Another characteristic of mobile applications
is that its sensoric functions can contextualize the usage
situation with regard to current location, phone orientiation
or other ambient conditions.
Hart [13] summarizes characteristics that distinguish mo-
bile devices from desktop computers: Mobile phones have
smaller screens with fewer pixels and therefore can display
less information in a less detailed way. Also, smartphones
are equipped with slower processors, making them less per-
formant, and have access to less bandwidth than desktop
computers. Rather than a mouse, they have a touch-based
input and a small, hard to access keyboard, making them less
precise and more challenging for text input. In addition, mobile
phones often provide no or only limited multitasking, meaning
that it is difﬁcult to work with more than one app at once.
Different from desktop browsers, with mobile phones websites
can be run in browser applets inside an app, which leads to
different functionalities and views while interacting with a web
page. The portrait screens are another challenge for mobile
application design, since they are unfavorable for displaying
more than two colums or showing overly-wide elements. Thus,
navigation in mobile apps is rather guided along the top than
the side. Lastly, users are using mobile devices differently,
in different settings, locations and situations that desktop
computers, which has a crucial inﬂuence on the UX of mobile
applications.
Due to these speciﬁcs, practitioners and academics in UX
often differentiate between desktop UX and mobile UX, e.g.,
in [14]–[18]. There are several studies that are approaching
the differences between desktop and mobile UX: Selke [19]
points out that due to the smaller displays, reduced bandwidth
and touch technology, users feel less comfortable while using
smartphones or tablets than they do with desktop computers.
Furthermore, mobile usage leads to different user behavior,
54
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

such as a different search behavior, a lower rate of exploration
in browsing, ﬁnishing different process steps in a task, and
receiving, reading and understanding a different amount of
information [19]. Additionally, the UX with using mobile web
and mobile apps also differs. According to Maurer et al. [20],
users prefer native apps over mobile websites, and likewise
Serrano et al. [21] conclude that native apps provide a richer
and more solid user experience.
Against this background, content and functionalities for
mobile apps need to be designed differently in order to meet
these speciﬁc challenges and create a good user experience.
As a result, the methods for assessing the user experience in
mobile app usage also need to be suitable for this context,
in order to capture the mobile UX adequately. One of the
challenges for mobile UX measuring is the mobile context
of use ”in the wild”. We assume that not all methods for
measuring UX can be directly applied to this context. And
since there is no overview on methods for measuring mobile
UX up-to-date, we conducted an initial literature survey that
provides an overview of the current status quo of academic
user experience evaluation methods for mobile applications on
smartphones.
IV.
LITERATURE SURVEY
The literature survey focused on academic research pa-
pers listed in Google Scholar, as this is one of the most
comprehensive and publisher-independent scientiﬁc literature
databases available. As we are focusing on a smartphone-
based understanding of mobile applications for our analysis,
we excluded publications older than ﬁve years (before 2012)
from our study. The UX evaluation methods we found in the
literature were divided into three groups: (1) methods that have
been directly applied from classical desktop UX scenarios to
mobile applications without modiﬁcation (generic methods);
(2) methods that are adapted in order to be applicable to mobile
applications (mobile adapted methods); (3) new approaches
that have been developed for measuring UX speciﬁcally in the
context of mobile applications on smartphones (mobile speciﬁc
methods). For each of these three groups, we searched for
methods of the ﬁve categories deﬁned by Albert and Tullis
[9]: Performance methods, usability methods, self-reporting
methods, behavioral and physiological methods, and combined
methods.
TABLE I. CATEGORIZED NUMBER OF UX STUDIES
ON MOBILE APPS
Mobile
Mobile
Generic
Adapted
Specific
Methods
Methods
Methods
Performance Methods
0
0
2
Usability Methods
2
0
4
Self-Reporting Methods
4
1
0
Behavioral and
Physiological Methods
0
0
6
Combined Methods
1
0
2
Sum
7
1
14
An overview on our results is displayed in Table I. In total,
22 studies were found. For a list of all studies that were used
in the literature survey, see the Appendix. Though almost two
thirds of the methods that we found –14 out of 22– were new
approaches, there were seven methods that have been directly
applied to the mobile context without being changed. There
was only one approach that had been adapted to the context
of mobile usage. In the following subsections, a qualitative
description provides a deeper insight in the studies that were
found.
A. Generic Methods
Whereas we found no example of performance methods
that were directly applied or adapted to mobile apps, there are
several usability studies that prove that issue-based methods
work out ﬁne for mobile apps as well. In [22], a classical
usability lab study is conducted, supported by the use of
two non-standardized questionnaires. Likewise, Habermann et
al. [23] evaluated a public transportation app regarding its
usability by observing users while they are solving prototypical
tasks.
Dhir and Al-kahtani [24] used three standardized self-
reported UX methods to evaluate a mobile app, i.e., the
AttrakDiff questionnaire [25]. These methods have been di-
rectly applied to the mobile context without modiﬁcation.
Likewise, the standardized System Usability Scale (SUS) has
been applied to various objects by Kortum and Bangor [26],
but is also proven to be feasible for mobile apps in [27], using
the questionnaire with ten mobile apps on smartphones as
well as tablets while gaining meaningful results. Additionally,
Ferreira et al. [28] used different self-reporting methods for
mobile app UX evaluation: In the Expressing Experiences
and Emotions (3E) method, as well as the Empathy Map
(EM), users have to draw or write their feelings on a sheet
of paper. Using Method of Assessment of EXperience (MAX),
the participant has to sort cards on a board. In addition, the Self
Assessment Manikin (SAM) questionnaire and Think Aloud
were used. The methods were used to evaluate UX for apps
on smartpones. However, all the studies were conducted in lab
environments with no further consideration of the impact of a
mobile usage situation. This might be the reason why none of
them required particular adaptation for the mobile context.
As one example for a comprehensive combined approach,
Yao et al. [29] conducted a mobile application user study in
a lab setting, collecting task performance data, self-reported
data, EEG data and skin conductance data. The results showed
that these methods can be generically used in the context of
mobile apps. Nevertheless, since all of them have been used
in a lab study, their applicability depends on the mobility of
the sensors that are used. We have no information about their
operational capability in a real mobile context of use.
B. Mobile Adapted Methods
While several questionnaires and self-reported methods
have been directly applied for mobile apps, there is also one
study where an adapted method was used: The goal of Kujala
and Miron-Shatz [30] is capturing the user experience from
the actual context of smartphone use. In a long-term study,
users have to ﬁll out an initial questionnaire and two follow-up
questionnaires after 2.5 and ﬁve months. They use a version of
the Day Reconstruction Method (DRM) questionnaire, that is
adapted to the context of the actual product use by adding new
questions. In doing so, the users had to reconstruct and report
55
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

the most important episodes of their day and their experiences
and emotions during the episodes of smartphone use.
Apart from that, no studies on mobile adapted methods
from the ﬁelds of performance, usability, behavioral and phys-
iological methods, and combined methods could be found.
C. Mobile Speciﬁc Methods
Regarding the ﬁeld of performance methods, there are some
new approaches. Ravindranath et al. [31] introduce a new tool
that monitors performance of mobile apps in the wild and helps
diagnosing problems. Likewise, Liang et al. [32] developed a
cloud service that traces mobile app performance and helps
reducing crashes and performance bugs.
For measuring the usability of mobile apps, several new
approaches have been introduced. Inspired by existing usability
models, Harrison et al. [33] create People At the Center of
Mobile Application Development (PACMAD), a model that
conceptualizes usability particularly for the context of mobile
applications. Igler et al. [34] show a framework that enables
usability evaluation in the actual context of use instead of a
lab setting. Olsina et al. [35] follow a novel holistic quality
approach for the evaluation of usability and user experience of
mobile applications. Furthermore, Hoehle and Venkatesh [36]
developed a survey instrument based on a concept for mobile
app usability that they derived from Apple’s user experience
guidelines.
In the ﬁeld of behavioral and physiological methods, differ-
ent mobile speciﬁc approaches have been developed. Yang et
al. [37] use the front camera of smartphones to track the users’
face expressions in order to enable facial aware applications.
In [38], a software for mobile face tracking is presented, that
analyzes emotions with an accuracy of 86 percent. Regarding
brain activity measurement, there are some new approaches
[39][40]. Both of them use a cap with EEG sensors that can
be worn outside a lab scenario, while only Stopczynski et al.
[39] combine it with open source software in order to visualize
brain activity during smartphone use. However, both studies
show the potential that lies within this method. Paletta et al.
[41] and Kassner et al. [42] both used mobile eye tracking
devices and their own software for collecting gaze data during
smartphone usage. Paletta et al. [41] introduce the Smartphone
Eye Tracking Toolbox (SMET), a software that i.a. records
screencasts and collects data during an experiment. In their
setting, eye tracking glasses are used, whereas Kassner et al.
[42] developed a headset-like device for mobile eye tracking,
that can not only be used for studies with mobile devices, but
also for interaction with everyday objects.
In the ﬁeld of combined methods, Maly et al. [43] introduce
a new tool including usability measurement as well as skin
conductance and heart rate in real mobile usage contexts.
Participants are asked to walk along a pre-deﬁned route
in a building while assessing comprehensive data on their
interactions, movements, stress level and physiological state.
Noldus et al. [44] use both movement tracking and logging for
automatically assessing mobile user experience. In their study,
participants could move freely, while their movements were
logged.
V.
DISCUSSION
The literature survey provided us with an overview of
generic as well as mobile speciﬁc methods for evaluating the
user experience of mobile applications. Though almost two
thirds of the methods that we found were new mobile speciﬁc
approaches, almost one third of the methods was directly
applied to the mobile context without being changed. We found
only one approach that had been adapted to the context of
mobile usage.
The new approaches show that regarding performance
measurement, evaluations of mobile apps often take place in
lab settings and that for ﬁeld studies with mobile devices, novel
approaches are required. Though we identiﬁed several of these
new methods, the topic still needs more coverage.
Regarding usability methods, the literature we found
showed that usability methods have been directly applied to
the mobile context, as far as they take place in a lab setting.
For collecting usability information ”in the wild”, different and
combined new approaches have been developed.
In the ﬁeld of self-reporting methods, most of them have
been directly applied to the mobile context without being
modiﬁed, while there is no example for a new approach. One
explanation may be that existing self-reported methods and
questionnaires are standardized and seem sufﬁcient for all
contexts of use, since the only restriction for using them is
the interaction with a system that is given with both desktop
systems and mobile apps. In addition, questionnaires and
reports can be ﬁlled in online and therefore are location-
independent. Also, it lies within the nature of these methods
that they are mostly carried out after the episode of interaction
and therefore, the application exactly during the use of an app
is not crucial for the use of these methods. One challenge in
this ﬁeld is constituted in those self-reporting methods that
need moderation or guidance, since they require that both
persons –moderator and participant– are in the same room,
and often involve desk-bound actions like writing, drawing
or sorting. To solve theses issues, new approaches for self-
reported methods should be taken into account.
The behavioral and physiological methods that were found
involved unexceptionally new, mobile speciﬁc approaches. The
reason for that might be that all of the approaches in this
topic are quite new, since the topic itself was only recently
discovered in the context of user experience measurement
and so far there are no established standards for this kind of
methods. The fact that existing mobile hardware for measuring
physiological conditions, such as caps with EEG sensors or
eye tracking glasses, are ﬁt for use in the mobile context, is
clearly a chance for this ﬁeld. On the other hand, these kind of
measurements have to cope with a high amount of inﬂuences
from the environment that makes the collected data hard to in-
terpret. Thus, Maly et al. [43] point out that ”such an approach
brings numerous methodological challenges as researchers do
not control the environment setting and parameters [...]”. To
our knowledge, to this point there is no solution to solve this
issue.
Regarding the last ﬁeld, we found only few studies with
combined methods – one that could be directly applied to
mobile context and two new approaches. The one that was
directly applied to smartphone use was set in a controlled lab
environment, so that under these circumstances, the mobile
context is not given anymore. We therefore assume that there is
a demand for comprehensive combined UX evaluation methods
in the context of mobile applications.
56
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

VI.
CONCLUSIONS AND FURTHER RESEARCH
In this paper, we have presented a literature survey on
user experience evaluation methods for mobile applications on
smartphones. We identﬁed academic research papers from ﬁve
categories of UX methods and assigned them to three groups –
generic methods, mobile adapted methods, and mobile speciﬁc
approaches. As key ﬁndings, we can conclude that classic UX
evaluation methods have been applied directly to the mobile
context, as long as they are used in a lab setting, and that
the main challenge of measuring mobile is data aquisition
”in the wild”, in the actual context of use. Based on our
literature survey, we can furthermore identify several research
needs for mobile UX research: (1) New approaches for self-
reported methods should be taken into consideration; (2) new
approaches for behavioral and physiological methods should be
further developed towards standardized methods; (3) methods
and frameworks for coping with physiological data collected
via studies in uncontrolled environments are required.
APPENDIX
TABLE A.1. STUDIES USED IN THE LITERATURE SURVEY
Authors
Classification
Wei et al. (2015)
Generic methods - Usability
Habermann et al. (2016)
Generic methods - Usability
Dhir and Al-kahtani (2013)
Generic methods - Self-reporting
Kortum and Bangor (2013)
Generic methods - Self-reporting
Kortum and Sorber (2015)
Generic methods - Self-reporting
Ferreira et al. (2016)
Generic methods - Self-reporting
Yao et al. (2014)
Generic methods - Combined
Kujala and Miron-Shatz (2013)
Mobile adapted methods - Self-reporting
Ravindranath et al. (2012)
Mobile speciﬁc methods - Performance
Liang et al. (2014)
Mobile speciﬁc methods - Performance
Harrison et al. (2013)
Mobile speciﬁc methods - Usability
Igler et al. (2013)
Mobile speciﬁc methods - Usability
Olsina et al. (2014)
Mobile speciﬁc methods - Usability
Hoehle and Venkatesh (2015)
Mobile speciﬁc methods - Usability
Yang et al. (2012)
Mobile speciﬁc methods - Behavioral
Suk and Prabhakaran (2014)
Mobile speciﬁc methods - Behavioral
Stopczynski et al. (2014)
Mobile speciﬁc methods - Behavioral
Kranczioch et al. (2014)
Mobile speciﬁc methods - Behavioral
Paletta et al. (2014)
Mobile speciﬁc methods - Behavioral
Kassner et al. (2014)
Mobile speciﬁc methods - Behavioral
Maly et al. (2013)
Mobile speciﬁc methods - Combined
Noldus et al. (2014)
Mobile speciﬁc methods - Combined
ACKNOWLEDGMENT
This work was funded by the German Federal Ministry
of Education and Research, grant no. 03FH032PX5; the
PROFRAME project at RheinMain University of Applied
Sciences. All responsibility for the content of this paper lies
with the authors.
REFERENCES
[1]
AppAnnie, “The app economy forecast: $6 trillion in new value.”
[Online].
Available:
https://www.appannie.com/de/insights/market-
data/app-store-revenue-forecast-139-billion-2021/ 2017.08.30.
[2]
AppAnnie, “Spotlight on consumer app usage: Part 2.” [Online].
Available: https://www.appannie.com/de/insights/market-data/new-app-
usage-report-how-many-apps-do-users-install-a-month/ 2017.08.30.
[3]
V.
Roto,
E.
L.-C.
Law,
A.
P.
O.
S.
Vermeeren,
and
J.
Hoonhout,
“User
experience
white
paper:
Bringing
clarity
to
the
concept
of
user
experience.”
[Online].
Available:
http://www.allaboutux.org/uxwhitepaper 2017.08.30
[4]
V. Roto, “User experience deﬁnitions - all about ux,” 2010. [Online].
Available: http://www.allaboutux.org/ux-deﬁnitions 2017.08.29.
[5]
P. Morville, “User experience design,” 2004. [Online]. Available:
http://semanticstudios.com/user experience design/ 2017.08.30.
[6]
M. Hassenzahl, “The hedonic/pragmatic model of user experience,”
Towards a UX Manifesto, vol. 10.
[7]
J. J. Garrett, Elements of user experience, the: user-centered design for
the web and beyond.
Pearson Education, 2010.
[8]
C. Stern, “Cubi: A user experience model for project success,” 2014.
[Online]. Available: https://uxmag.com/articles/cubi-a-user-experience-
model-for-project-success 2017.08.29.
[9]
W. Albert and T. Tullis, Measuring the user experience: collecting,
analyzing, and presenting usability metrics.
Newnes, 2013.
[10]
J. Sauro and J. R. Lewis, Quantifying the user experience: Practical
statistics for user research.
Morgan Kaufmann, 2016.
[11]
A. P. O. S. Vermeeren et al., “User experience evaluation methods,”
in Proceedings of the 6th Nordic Conference on Human-Computer
Interaction, E. T. Hvannberg, Ed.
New York, NY: ACM, 2010, pp.
521–530.
[12]
E. L.-C. Law, P. van Schaik, and V. Roto, “Attitudes towards user ex-
perience (ux) measurement,” International Journal of Human-Computer
Studies, vol. 72, no. 6, 2014, pp. 526–541.
[13]
S.
Hart,
“Mobile
vs.
desktop:
10
key
differences,”
2017.
[Online].
Available:
https://www.paradoxlabs.com/blog/mobile-vs-
desktop-10-key-differences/ 2017.08.31.
[14]
J. Nielsen and R. Budiu, Mobile usability.
MITP-Verlags GmbH &
Co. KG, 2013.
[15]
M. Firtman, Programming the mobile web.
” O’Reilly Media, Inc.”,
2010.
[16]
C. P. Furner, P. Racherla, and J. S. Babb, “Mobile app stickiness (mass)
and mobile interactivity: A conceptual model,” The Marketing Review,
vol. 14, no. 2, 2014, pp. 163–188.
[17]
C. Furner, P. Racherla, and J. Babb, “What we know and do not know
about mobile app usage and stickiness: A research agenda,” Geospatial
Research: Concepts, Methodologies, Tools, and Applications, vol. 1,
2016, pp. 117–141.
[18]
A. Mendoza, Mobile user experience: Patterns to make sense of it all.
Waltham, MA: Morgan Kaufmann, 2014.
[19]
A.-L.
Selke,
“Desktop
vs
mobile:
Do
de-
vices
change
our
behaviour?”
2015.
[Online].
Avail-
able:
https://www.nathalienahai.com/2015/11/desktop-vs-mobile-do-
devices-change-our-behaviour/ 2017.08.31.
[20]
M.-E. Maurer, D. Hausen, A. De Luca, and H. Hussmann, “Mobile or
desktop websites?: Website usage on multitouch devices,” in Proceed-
ings of the 6th Nordic Conference on Human-Computer Interaction:
Extending Boundaries, ser. NordiCHI ’10. New York, NY, USA: ACM,
2010, pp. 739–742.
[21]
N. Serrano, J. Hernantes, and G. Gallardo, “Mobile web apps,” IEEE
software, vol. 30, no. 5, 2013, pp. 22–27.
[22]
Q. Wei, Z. Chang, and Q. Cheng, “Usability study of the mobile library
app: An example from chongqing university,” Library Hi Tech, vol. 33,
no. 3, 2015, pp. 340–355.
[23]
A. L. Habermann, K. Kasugai, and M. Zieﬂe, “Mobile app for public
transport: A usability and user experience perspective,” in Internet
of Things. IoT Infrastructures, ser. Lecture Notes of the Institute
for Computer Sciences, Social Informatics and Telecommunications
Engineering, B. Mandler, J. Marquez-Barja, and M. E. Mitre Campista,
Eds., 2016.
[24]
A. Dhir and M. Al-kahtani, “A case study on user experience (ux)
evaluation of mobile augmented reality prototypes,” J. UCS, vol. 19,
no. 8, 2013, pp. 1175–1196.
57
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

[25]
User Interface Design GmbH, “AttrakDiff,” 2017. [Online]. Available:
http://attrakdiff.de/index-en.html 2017.09.28.
[26]
P. T. Kortum and A. Bangor, “Usability ratings for everyday products
measured with the system usability scale,” International Journal of
Human-Computer Interaction, vol. 29, no. 2, 2013, pp. 67–76.
[27]
P. Kortum and M. Sorber, “Measuring the usability of mobile applica-
tions for phones and tablets,” International Journal of Human-Computer
Interaction, vol. 31, no. 8, 2015, pp. 518–529.
[28]
B. M. Ferreira et al., “Evaluation of ux methods: Lessons learned when
evaluating a multi-user mobile application,” in International Conference
on Human-Computer Interaction.
Springer, 2016, pp. 279–290.
[29]
L. Yao et al., “Using physiological measures to evaluate user experience
of mobile applications,” in International Conference on Engineering
Psychology and Cognitive Ergonomics.
Springer, 2014, pp. 301–310.
[30]
S. Kujala and T. Miron-Shatz, “Emotions, experiences and usability in
real-life mobile phone use,” in CHI 2013, W. E. Mackay, S. Brewster,
and S. Bødker, Eds.
New York, NY: ACM, 2013, p. 1061.
[31]
L. Ravindranath et al., “Appinsight: Mobile app performance monitoring
in the wild.” in OSDI, vol. 12, 2012, pp. 107–120.
[32]
C.-J. M. Liang et al., “Caiipa,” in Proceedings of the 20th International
Conference on Mobile Computing and Networking, September 7 - 11,
2014, Maui, HI, USA, S.-J. Lee, Ed.
New York, NY: ACM, 2014, pp.
519–530.
[33]
R. Harrison, D. Flood, and D. Duce, “Usability of mobile applications:
Literature review and rationale for a new usability model,” Journal of
Interaction Science, vol. 1, no. 1, 2013, pp. 1–42.
[34]
B. Igler, T. Braumann, and S. B¨ohm, “Evaluating the usability of
mobile applications without affecting the user and the usage context,”
International Journal Of Business and Management Studies, vol. 5,
no. 1, 2013, pp. 93–102.
[35]
L. Olsina, L. Santos, and P. Lew, “Evaluating mobile app usability:
A holistic quality approach,” in Web engineering, ser. Lecture Notes
in Computer Science, S. Casteleyn, G. Rossi, and M. Winckler, Eds.
Cham: Springer, 2014, vol. 8541, pp. 111–129.
[36]
H. Hoehle and V. Venkatesh, “Mobile application usability: Conceptu-
alization and instrument development,” Mis Quarterly, vol. 39, no. 2,
2015, pp. 435–472.
[37]
X. Yang et al., “Visage: A face interpretation engine for smartphone
applications,” in International conference on mobile computing, appli-
cations, and services.
Springer, 2012, pp. 149–168.
[38]
M. Suk and B. Prabhakaran, “Real-time mobile facial expression recog-
nition system - a case study,” in Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition Workshops, 2014.
[39]
A. Stopczynski et al., “Smartphones as pocketable labs: Visions for
mobile brain imaging and neurofeedback,” International journal of
psychophysiology, vol. 91, no. 1, 2014, pp. 54–66.
[40]
C. Kranczioch, C. Zich, I. Schierholz, and A. Sterr, “Mobile eeg and its
potential to promote the theory and application of imagery-based motor
rehabilitation,” International journal of psychophysiology, vol. 91, no. 1,
2014, pp. 10–15.
[41]
L. Paletta et al., “Smartphone eye tracking toolbox: Accurate gaze
recovery on mobile displays,” in Proceedings of the Symposium on
Eye Tracking Research and Applications, ser. ETRA ’14.
New York,
NY, USA: ACM, 2014, pp. 367–68.
[42]
M. Kassner, W. Patera, and A. Bulling, “Pupil: An open source platform
for pervasive eye tracking and mobile gaze-based interaction,” in Pro-
ceedings of the 2014 ACM International Joint Conference on Pervasive
and Ubiquitous Computing: Adjunct Publication, ser. UbiComp ’14
Adjunct.
New York, NY, USA: ACM, 2014, pp. 1151–1160.
[43]
I. Maly, Z. Mikovec, J. Vystrcil, J. Franc, and P. Slavik, “An evaluation
tool for research of user behavior in a realistic mobile environment,”
Personal and Ubiquitous Computing, vol. 17, no. 1, Jan 2013, pp. 3–14.
[44]
L. P. Noldus, M. K. Ben Loke, and A. J. Spink, “Automated mobile
user experience measurement: Combining movement tracking with app
usage logging,” Creating the Difference, vol. 31, 2014.
58
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

