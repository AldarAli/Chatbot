Automatic Traffic Light Recognition for Mobile Robot Applications 
 
Chi-Hsun Chiang 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 70101 
Email: a0921986456@gmail.com 
Cheng-Kang Wen 
Department of Information Management 
Tainan University of Technology 
Tainan, Taiwan 71002 
Email: ckwenisme@gmail.com 
Chun Mu Wu 
Department of Mechanical and Automation Engineering 
Kao Yuan University 
Kaohsiung, Taiwan 82151 
 Email: wtm@cc.kyu.edu.tw 
Jung-Hua Chou* 
Department of Engineering Science 
National Cheng Kung University 
Tainan, Taiwan 70101 
*Corresponding author, email: jungchou@mail.ncku.edu.tw 
 
 
Abstract—In this study, we present a method to enhance the 
quality of traffic light images captured by a webcam using 
hardware filters for mobile robot applications. The images are 
processed through pre-processing, detection, and recognition 
steps to recognize the status of traffic lights. The results show 
that the status of traffic lights is recognized successfully; the 
overall recognition rate is about 99% while the recognition 
time is about 41ms to 76ms per frame. By using the method of 
support vector machine (SVM), the recognition rate is higher 
with the cost of a larger processing time.  
Keywords-traffic light; image processing; HOG; SVM; filters. 
I. 
 INTRODUCTION 
With the growing concern about the traffic accidents 
around the world yearly, the big auto industry set the goal of 
achieving automatic driving by the year of 2025. However, 
with the progress being made, now the target time is moved 
forward to the year around 2020 or 2021. The ambition is 
admirable and the challenge is by no means simple. 
Researches on Advanced Driver Assistance System (ADAS) 
are becoming deeper and more extensive in recent years. A 
tremendous amount of efforts have been put into developing 
related techniques. Among them, real time recognition of 
traffic lights in the street is of a necessity. Automatic traffic 
light recognition plays an important role in traffic safety and 
traffic flow smoothness. However, traffic lights are hard to 
detect just by image processing in urban driving conditions 
due to the complex backgrounds and different illuminations. 
A worse situation is that some objects may even have visual 
features similar to traffic lights. Therefore, it is difficult to 
develop a universal real-time and robust traffic light 
recognition system for different environments, illuminations, 
and weather conditions. 
Because of its importance, various traffic light 
recognition algorithms based on image processing have 
been proposed in the literature [1]-[6], even with machine 
learning [7] via Adaboost algorithm [8]. In general, 
researchers are usually divided into traffic light detection 
and traffic light recognition for the whole recognition 
algorithm of traffic lights. This is because traffic lights are 
very small as compared to other objects in the road 
environment, which may have street lights of similar 
geometric shapes. Thus, it is necessary to detect the region 
of interest for traffic lights first to exclude unnecessary 
background objects to verify the status of traffic lights more 
easily. 
 Since the goal of this study is traffic light recognition for 
mobile robot applications, all of the information has to be 
processed by the on-board computing facility without relying 
on external extensive computing powers. That is, an on-
board notebook computer was used for all of the image 
processing task. The images were captured by a webcam 
(Logitech C525).  
Following this Introduction section, Section II describes 
the methodology, Section III presents the results and 
discussion, and Section IV draws the conclusions. Details are 
as follows. 
 
II. 
METHODOLOGY 
As mentioned above, Logitech Webcam C525 was used 
to capture the traffic light images for the present application. 
Its resolution is 1280 by 720 pixels with a frame rate of 30 
frames per second. In capturing the images, two types of 
filters were applied. One is a Circular Polarizer (CPL) filter 
and the other is a Neutral Density (ND) filter. The CPL filter 
was used to enhance the color contrast and to reduce light 
reflection to improve the image quality. The ND filter [9] 
was used to avoid image over exposure and to remove the 
halo around the traffic lights due to improper background 
lighting conditions, especially in the evening situations. 
The effects of CPL and ND filtering can be clearly 
observed from the photos shown in Figures 1-4. The former 
two for CPL filtering; whereas the latter two for ND filtering. 
By comparing the original and the corresponding filtered 
photos, it is clear that the CPL filter enhances the color 
contrast to make the objects in the photos more 
distinguishable. For the ND filter, both light effect and halo 
around the traffic light are removed; the traffic light shows 
its complete round shape. Thus, by these two filters, the 
46
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

image quality captured by the webcam is improved greatly to 
ease and facilitate subsequent image processing.  
 
 
 
 
 
 
 
 
 
 
 
 
   
Figure 1. Original photo without CPL filtering. 
      
 
 
 
 
 
 
 
 
 
 
 
Figure 2. CPL filtered photo of Figure 1. 
      
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. Original traffic light photo. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 4. ND filtered photo of Fig. 3. 
 
After the image was filtered and captured by the webcam, 
it is processed to determine whether it is a traffic light. If it is 
a traffic light, its status is further determined. All of this 
processing was performed by using Visual Studio C++ and 
OpenCV function libraries, executed by the notebook 
computer on the mobile robot designed for validating the 
recognition methods.  
As shown in Figure 5, the traffic light recognition from 
the images captured by the webcam consists of mainly three 
steps in sequence: One is the pre-processing, the second is 
the detection of the traffic light, and the third is the 
recognition of the status of the traffic light. For the first step 
of image pre-processing, the red, green, and blue 
components (referred to as RGB colors hereafter) of the 
color image captured by the webcam is converted into H 
(hue), S (saturation), and V (value) color space as the latter is 
less sensitive to the environmental lighting conditions. Then, 
the region of interest, which contains the traffic light, is 
selected to increase the speed of processing.  
For the second step of traffic light detection, typical 
image operations were conducted, including erosion/dilation, 
open/close operations to remove the noises embedded in the 
image. Thus, connected regions of interest can be deduced. 
Then, morphological operations taking care of the geometry, 
size, and aspect ratio of the traffic light were performed to 
segment out the traffic light for its status recognition. 
In the last step of the recognition, the method of 
histogram of gradients (HOG) [10][11] is used to extract the 
features of the traffic light. A database of red, green, yellow, 
and non-traffic light was also established using the HOG 
descriptors. This database is constructed mainly for the 
recognition of using the approach of support vector machine 
(SVM) [12], which is also trained by the information in the 
database. That is, recognition is divided into two parts: one 
for daytime and the other for nighttime.  For daytime traffic 
lights, HOG is combined with SVM for the recognition. For 
nighttime traffic lights, only features in the color space are 
used to recognition. If we detect zero or more than one 
candidate region, the loop will break back to the beginning 
of the input images for restarting. The image processing 
algorithm is verified by experiments using a mobile robot  
Figure 5. Flow of the traffic light algorithm. 
 
 
 
 
 
47
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

In this study, SVM was selected for enhancing image 
recognition with HOG. The reasons for this choice are two. 
One is that the environment around the traffic light is fairly 
complex, especially at night when lighting sources around 
the street become the noise of traffic lights. The other is that 
SVM guarantees a convex space for classification, which can 
effectively avoid the trapping of the recognition algorithm to 
local maximum as compared to other classifiers. 
III. 
RESULTS AND DISCUSSION 
 
The experimental environments with traffic light images 
are shown in Figure 6 and Figure 7 for the red lights at 
daytime and nighttime, respectively. It is evident that in the 
daytime, surrounding objects are all captured in the image; 
whereas, at the nighttime, the lights have halos around them. 
The recognition process and result are shown in Figure 8, 
taking the green light recognition as a typical example. The 
result shows that even under a fairly complex background 
and illumination of the traffic light, the detection and 
recognition are successfully achieved.  
In order to understand the details of the recognition 
results, we record every experimental result in different 
environments and the computation time from traffic light 
recognition. The results indicate that for the sunny daytime, 
the recognition rate is about 99.7%, for cloudy day about 
99.8%, and 99.1% for nighttime. For the process time, it 
takes 76ms/frame and 41ms/frame for the daytime and 
nighttime, respectively. Most of the time is spent in the 
process of detecting the traffic light while recognition by 
using SVM also consumes about the same amount of time as 
the detection process. That is, it takes less time for the 
method through color recognition, but the correct rate is also 
slightly lower due to difficulties in distinguish the red from 
yellow lights. 
 
 
 
 
 
 
 
 
 
     
Figure 6. Daytime traffic light captured and recognized. 
 
Figure 7. Nighttime traffic captured and recognized. 
IV. 
CONCLUSIONS 
A notebook computer based algorithm for real-time robust 
traffic light recognition using images captured from a 
webcam is developed. The goal is to design a traffic light 
recognition system which can conquer influences from 
complex backgrounds and different illuminations for mobile 
robot applications. Thus, mobile robots can recognize traffic 
light signals automatically and work in an appropriate way. 
This algorithm adopts filters to enhance the captured images 
for detecting traffic lights.  
Overall results show that the developed method 
performs well for image detection in a general environment. 
The SVM method combines with HOG feature extraction 
not only can reach real time but also has high accuracy for 
recognition. Although the recognition method with color 
feature takes less time than that of the SVM method, it is 
not efficient to recognize the difference between red and 
yellow lights. The experimental results show that our 
algorithm can detect and recognize circular lights in 
different environment robustly and in real-time with 
recognition rate around 99%. Further studies are being 
conducted to improve this recognition rate. 
 
REFERENCES 
 
[1] C. Yu, C. Huang and Y. Lang, “Traffic light detection during 
day and night conditions by a camera,” IEEE 10th 
International Conference on Signal Processing Proceedings, 
pp. 821-824, 24-28 Oct., 2010. 
[2] H. Moizumi, Y. Sugaya, M. Omachi, S. Omachi, “Traffic 
light detection considering color saturation using in-vehicle 
stereo camera,” Journal of Information Processing, vol. 24, no. 
2, pp. 349-357, 2016. 
[3] O. Masako and O. Shinichiro, “Traffic light detection with 
color and edge information,” 2009 2nd IEEE International 
Conference 
on 
Computer 
Science 
and 
Information 
Technology, pp. 284-287, 8-11 Aug., 2009. 
[4] M. Diaz-Cabrera, P. Cerri, P. Medici, “Robust real-time 
traffic light detection and distance estimation using a single 
camera,” Expert Systems with Applications, vol. 42, no. 8, pp. 
3911-3923, 2015. 
[5] S. Sooksatra and T. Kondo, “Red traffic light detection using 
fast radial symmetry transform,” International Conference on 
Electrical 
Engineering/Electronics, 
Computer, 
Telecommunications and Information Technology (ECTI-
CON), pp. 1-6, 2014. 
[6] Y. Jie, C. Xiaomin, G. Pengfei, X. Zhonglong, “A new traffic 
light detection and recognition algorithm for electronic travel 
aid,” 2013 Fourth International Conference on Intelligent 
Control and Information Processing (ICICIP), pp. 644-648, 9-
11 June 2013. 
[7] J. Gong, Y. Jiang, G. Xiong, C. Guan, G. Tao, H. Chen, “The 
recognition and tracking of traffic lights based on color 
segmentation and CAMSHIFT for intelligent vehicles,” 2010 
IEEE Intelligent Vehicles Symposium, pp. 431-435, 21-24 
June, 2010. 
[8] J. Zhu, H. Zou, S. Rosset, T. Hastie, “Multi-class adaboost,” 
Statistics and its Interface, vol. 2, no. 3, pp. 349-360, 2009. 
[9] R. Robilotto and Q. Zaidi, “Perceived transparency of neutral 
density filters across dissimilar backgrounds,” Journal of 
Vision, vol. 4, no. 3, pp. 5-5, 2004. 
 
 
48
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

[10] K. v. d. Sande, T. Gevers, C. Snoek, “Evaluating color 
descriptors for object and scene recognition, ”  IEEE 
Transactions on Pattern Analysis and Machine Intelligence, 
vol. 32, no. 9, pp. 1582-1596, 2010. 
[11] T. Barbu, “Pedestrian detection and tracking using temporal 
differencing and HOG features,” Computers and Electrical 
Engineering, vol. 40, no. 4, pp. 1072-1079, 2014. 
[12] C.-C. Chang and C.-J. Lin, “LIBSVM: a library for support 
vector machines,” ACM Transactions on Intelligent Systems 
and Technology (TIST), vol. 2, no. 3, pp. 27, 2011. 
 
 
 
 
Figure 8. Overall recognition process and result. 
 
 
 
. 
49
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-638-5
SIGNAL 2018 : The Third International Conference on Advances in Signal, Image and Video Processing

