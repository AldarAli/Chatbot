1
Analysing security requirements formally and
ﬂexibly based on suspicion
Nuno Am´alio
Abstract—Increasingly, engineers need to approach security
and software engineering in a uniﬁed way. This paper presents
an approach to the formal analysis of security requirements that
is based on model-checking and uses the concept of suspicion
to guide the search for threats and security vulnerabilities in
requirements. It proposes an approach to security analysis that
favours exploration of a system’s state space based on what is
abnormal or suspicious to ﬁnd threats and vulnerabilities, instead
of ironclad security proofs that try to demonstrate that a system
is secure; as this paper shows, such security proofs can often be
misleading. The approach is tested and illustrated by conducting
two experiments: one focussing on a system with a conﬁdentiality
security property, and another with an integrity security property
enforced through the separation of duty principle. One of the
advantages of the approach presented here is that threats are
derived directly from a model of requirements and no prior
knowledge about possible attacks is necessary to perform the
analysis. The paper shows that suspicion is an effective search
criteria for ﬁnding vulnerabilities and security threats in require-
ments, and that the feedback generated by the analysis helps in
elaborating security requirements.
Index Terms—Security, requirements, formal analysis, Event-
Calculus, planning, conﬁdentiality, separation of duty.
I. INTRODUCTION
Traditional approaches to software engineering and current
practice tend to treat security concerns as an after-thought [1].
Security requirements are handled as non-functional require-
ments and are kept separate from their functional counter-parts
until design or implementation-time. This raises problems for
the whole software development process because (as demon-
strated in this paper) functionality has an impact on security.
If security aspects are not treated properly at the requirements
phase, then the resolution of the problem will inevitably be
deferred but at a much higher cost, which is a well known
software engineering problem [2]. This issue can be resolved
by integrating security into the requirements engineering phase
of the software life-cycle [1], [3]. However, the best way to
capture, model and analyse security and system requirements
in a uniﬁed way is still an open problem.
Security requirements have proved tricky to formulate and
reason about [4]. There are several methods for reasoning
about properties that a system must satisfy. Traditionally,
properties are classiﬁed as either safety or liveness [5], [6].
Safety properties say that something bad must not happen,
and liveness properties say that something good must eventu-
ally happen. We check safety to ensure that bad states are
not reachable, and liveness to ensure that good states are
eventually reachable. This is used to check that invariants
are preserved, that operations are applicable when certain
N. Am´alio is with the University of Luxembourg.
conditions are met (pre-conditions) and that operations have
the desired effect taking the system into a valid state. However,
important classes of security requirements are either difﬁcult
to express using traditional safety or liveness properties, or
they are just not possible to express at all [7], [4], [8].
This paper claims that, from a practical point of view, not
only it is important to verify safety (that some unsecure state
is not reached) and liveness (that the security measures do
what is expected from them), but also in ﬁnding security
vulnerabilities and possible security threats that give attack
opportunities to malicious users: we need to look for what
can happen under certain suspicious conditions. Traditionally,
such possibilistic properties [7] are hard to formulate and
reason about. This paper proposes a practical approach for
dealing with such properties.
This paper presents a practical approach to the formal
analysis of security requirements based on model-checking,
where the search for threats and vulnerabilities in requirements
is based on what is suspicious from a security point of view.
This is inspired by anomaly-based approaches to intrusion
detection [9], where the search for intrusions at run-time
is driven by abnormal (or suspicious) behaviour of system
use. The approach presented here takes a formal model of
requirements and an analysis goal (a description of suspicious
states from the analysis point of view), which are used by the
model checker to generate traces of events describing how
the analysis goals is reached. Each trace gives a scenario
illustrating a possible threat or security vulnerability. The
generation of plans is done automatically with tool support.
The approach is illustrated with the Event-Calculus temporal
logic [10] and the analysis is conducted with tool support using
the discrete event calculus reasoner1 (decreasoner).
The remainder of this paper starts by giving a brief in-
troduction to event calculus (section II). Then it presents
the approach to the formal analysis of security requirements
that is proposed here (section III). After this, the analysis
approach is used to conduct two experiments: analysis of
a simple health-care system with a conﬁdentiality security
requirement (section IV), and analysis of a business system
with an integrity requirement enforcing separation of duty
(section V). Then, the paper summarises the experimental
results that we obtained (section VI), discusses the paper’s re-
sults (section VII), presents some related work (section VIII),
and takes the conclusions.
1http://decreasoner.sourceforge.net/
344
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

2
Fig. 1.
Planning-based formal analysis. EC model of requirements, and EC
description of analysis goal are fed into decreasoner tool to obtain a set of
plans (scenarios) that achieve the goal.
II. THE EVENT CALCULUS
Event Calculus (EC) [10], [11], a temporal logic based
on ﬁrst-order predicate calculus designed for common-sense
reasoning, enables representation and reasoning about action
and change. Its basic ontology comprises events, ﬂuents and
timepoints. An event is an action that may occur in the world.
A ﬂuent is a time varying property of the world. A timepoint
is an instance of time. EC includes a set of basic predicates to
describe happening of events, their effects and state of ﬂuents.
An EC model is built by describing two types of facts: the fact
that an event occurs at a timepoint, and the fact that a property
holds at a timepoint [11]. These facts are either true or false.
The basic predicates of EC are as follows:
• HoldsAt (f, t) says that ﬂuent f is true at timepoint t.
• Happens (e, t) says that event e may occur at timepoint
t.
• Initiates (e, f, t) says that if event e occurs at timepoint
t, then ﬂuent f is true after t.
• Terminates (e, f, t) says that if event e occurs at
timepoint t, then ﬂuent f is false after t.
• Initially (f) says that ﬂuent f holds at timepoint 0.
III. FORMAL THREAT ANALYSIS BY STUDYING
REACHABILITY
The analysis proposed here is essentially a study of reach-
ability: it checks whether certain states are reachable from
a model of the requirements. The actual generation of threat
scenarios is based on AI planning [12] and uses the decresoner
tool, which is based on a SAT approach to EC reasoning [13]2.
This is related to what is known in software engineering as
model-checking [14]: the exploration of all possible states and
transitions of a model to determine if a certain property holds
or not
Figure 1 depicts the analysis approach followed here. The
EC model and EC description of analysis goals are given
as inputs to decreasoner, which generates a set of plans (or
traces) that satisfy the goal. Each plan describes a scenario
comprising a sequence of events (a trace) that takes the system
from the initial state to one of the states described by the goal.
The goal (a predicate) describes a set of states that are
interesting from the analysis point of view. Planning generates
plans that reach such a state. If there are plans, then the goal is
satisﬁable: a state as described by the goal can be reached in
the model. If no plans can be found, then no state as described
by the goal is reachable. If the goal state describes something
that should not happen, then the resulting plans (scenarios)
2Appendix A shows sample outputs given by decreasoner for the suspicion-
based analysis conducted in this paper.
R1
Doctors must be able to access their patient’s medical data to
provide effective medical care.
R2
A doctor may nominate a substitute who may be able to access
the patient’s medical data only when main doctor is on leave.
TABLE I
THE REQUIREMENTS OF SIMPLE MEDICAL INFORMATION SYSTEM.
Fig. 2.
The SMIS with one patient, Anderson, his doctor Jones, and another
doctor, Smith, who is able to replace Jones while he is on leave.
describe a sequence of events that reach such a state; thus
exposing a way to reach something undesired.
Two strategies are used to formulate the goal. There is a
more traditional strategy that does a safety analysis by formu-
lating a goal describing states where security is violated and
that must not happen; these goals are called security violation
goals. The other strategy applies suspicion by deﬁning a goal
describing suspicious states deserving investigation that may
expose possible vulnerabilities and threats. These are called
suspicious goals.
IV. CONFIDENTIALITY
Conﬁdentiality is about protecting information. It tries to
ensure that sensitive information is accessible only to those
authorised to access it. Analysis of conﬁdentiality involves
checking ways in which conﬁdential information may be
accessed by those who are not authorised. Here, conﬁdentiality
is studied using a case study of a domain where it is a
professional ethical principle: health-care [15].
The case study is a simple medical information system
(SMIS) that manages patient information. Due to its sensi-
tive nature, patient information is subject to conﬁdentiality
constraints to protect patient’s privacy. The requirements of
SMIS are summarised in table I. Figure 2 depicts a concrete
system scenario of SMIS.
A. EC Model
To satisfy the requirements of SMIS, EC model presented
here introduces a protection mechanism based on credentials:
doctors need to request a credential prior to accessing the data;
credentials have a validity period.
The building blocks of an EC model are sorts, events and
ﬂuents. EC model of SMIS comprises sort Delay, representing
345
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

3
time delays used in credential mechanism, and domain sorts
User, representing a user of SMIS, Doctor, a sub-sort of
User that represents doctors using SMIS, and Patient, which
represents the patients recorded in the system.
EC model of SMIS comprises the following events:
• AuthoriseAccess (d, p): occurs when doctors (d) re-
quest a credential for accessing some patient’s data (p).
• GetMD (d, p): occurs when doctors (d) actually access
patient’s medical data (p).
• SetSubstituteDoctor (u, d1, d2): occurs when a user
(u) sets some doctor (d1) as substitute of another (d2).
• SetDoctorOnLeave (u, d): occurs when a user (u)
informs system that some doctor (d) is on leave.
• DoctorNoLongerOnLeave (u, d): occurs when a user
(u) informs system that a doctor (d) is no longer on leave.
EC model deﬁnes the following ﬂuents to hold state:
• IsDoctorOf (d, p) says who is doctor (d) of some
patient (p).
• CredentialMD (d, p, t) says that a doctor (d) has been
issued a credential to access data of some patient (p) at
time-point t.
• ExposedToAt (d, p, t) says that a doctor (d) has seen
the medical data of some patient (p) at time-point t.
• IsSubstituteDoctor(d1, d2) says that d1 is substitute
doctor of d2.
• OnLeave (d) says that doctor d is on leave.
EC model of SMIS starts by constraining Duration pred-
icate, which gives actual time associated with delays (of
Delay sort). Next EC equation says that Duration relation is
functional; each delay has at most one duration (a time point):
∀ d : Delay; t1, t2 : Time |
Duration (d, t1) ∧ Duration (d, t2) ⇒ t1 = t2
(1)
Next EC equation says that Duration is total; all delays of
the model must have a duration associated:
∀ d : Delay | (∃ t : Time) Duration (d, t)
(2)
Next EC equation says that IsDoctorOf is a surjective
relation; each patient must have a doctor:
∀ p : Patient; t : Time |
(∃ d : Doctor) HoldsAt (IsDoctorOf (d, p), t)
(3)
Next EC equation deﬁnes predicate CanAccessMD, de-
scribing conditions ruling doctors’ access to patient’s data:
∀ d : Doctor; p : Patient; t : Time |
HoldsAt (CanAccessMD (d, p), t)
⇔ HoldsAt (IsDoctorOf (d, p), t)
∨ ((∃ d′ : Doctor) HoldsAt (IsDoctorOf (d′, p), t)
∧ HoldsAt (IsSubstituteDoctor (d, d′), t)
∧ HoldsAt (OnLeave (d′), t))
(4)
This says that a doctor can access some patient’s medical data
at some time point provided doctor is either (a) patient’s doctor
(ﬂuent IsDoctorOf) or (b) substitute doctor of patient’s
doctor (ﬂuent IsSubstituteDoctor) who is on leave at that
time (ﬂuent OnLeave). This formalises requirements R1 and
R2.
Next EC equation describes how doctors get creden-
tials to access patient’s data by describing effect of event
AuthoriseAccess:
∀ d : Doctor; p : Patient; t : Time |
HoldsAt (CanAccessMD (d, p), t)
⇒ Initiates (AuthoriseAccess (d, p),
CredentialMD (d, p, t), t)
(5)
This says that some doctor gets a credential to access a
medical ﬁle (ﬂuent CredentialMD is initiated) upon event
AuthoriseAccess, provided doctor can access patient’s data
(predicate CanAccessMD deﬁned above). This formalises
the scheme of credential-based protection.
Model objects of Delay sort have a duration, as deﬁned by
Duration predicate deﬁned above. Next EC equation deﬁnes
delay credentialV alidity representing validity period of a
credential:
credentialV alidity : Delay
(6)
Next EC equation deﬁnes validity conditions of credentials,
which are captured by predicate HasV alidCredential:
∀ d : Doctor; p : Patient; t : Time |
HoldsAt (HasV alidCredential (d, p), t)
⇔ (∃ t2, t3 : Time)
HoldsAt (CredentialMD (d, p, t2), t)
∧ Duration (credentialV alidity, t3)
∧ (t2 + t3) ≥ t
(7)
This says that a credential is valid for the duration period
deﬁned by credentialV alidity.
Next EC equation deﬁnes precondition of event GetMD,
which may happen provided requesting doctor has a valid
credential to access requested patient’s data:
∀ d : Doctor; p : Patient; t : Time |
Happens (GetMD (d, p), t)
⇒ HoldsAt (HasV alidCredential (d, p), t)
(8)
Next EC equation describes how event GetMD initiates
(sets to true) ﬂuent ExposedToAt that records exposure to
patient’s data has been accessed:
∀ d : Doctor; p : Patient; t : Time |
Initiates (GetMD (d, p), ExposedToAt (d, p, t), t)
(9)
Next equation constrains ﬂuent IsSubstituteDoctor to be
non-reﬂexive; that is, a doctor may not be set as a substitute
of himself:
∀ d : Doctor; t : Time |
¬ HoldsAt (IsSubstituteDoctor (d, d), t)
(10)
Next
equation
describes
effect
how
event
SetSubstituteDoctor initiates ﬂuent IsSubstituteDoctor
to record that some doctor is substitute of another:
∀ u : User; d1, d2 : Doctor; t : Time |
Initiates (SetSubstituteDoctor (u, d1, d2),
IsSubstituteDoctor (d2, d1), t)
(11)
Next equation describes how event SetDoctorOnLeave
initiates (sets to true) ﬂuent OnLeave; some user (u) informs
system that some doctor (d) is on-leave:
∀ u : User; d : Doctor; t : Time |
Initiates (SetDoctorOnLeave (u, d), OnLeave (d), t)
(12)
346
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

4
Next
equation
describes
how
event
DoctorNoLongerOnLeave
terminates
(sets
to
false)
ﬂuent DoctorNoLongerOnLeave; this used so that users u
inform system that a doctor (d) is no longer on leave:
∀ u : User, d : Doctor; t : Time |
Terminates (DoctorNoLongerOnLeave (u, d),
OnLeave (d), t)
(13)
Next equations describe the initial condition of SMIS:
∀ d : Doctor; p : Patient; t : Time |
Initially (¬ ExposedToAt (d, p, t))
(14)
∀ d1, d2 : Doctor |
Initially (¬ IsSubstituteDoctor (d1, d2))
(15)
∀ d : Doctor | Initially (¬ OnLeave (d))
(16)
Above, initially no one has been exposed to medical data
(ﬂuent ExposedToAt), no doctors are set as substitutes, and
there are no doctors on leave.
This completes EC model of SMIS’s requirements (table I).
Next section, formally analyses this model.
B. Model Analysis
Analysis uses conﬁguration depicted in Fig. 2. There are two
doctors, Jones and Smith, and a patient of Jones, Anderson.
This is formulated in EC as:
jones, smith : Doctor
(17)
anderson : Patient
(18)
Initially (IsDoctorOf (jones, anderson))
(19)
Conﬁguration for model analysis also needs to deﬁne dura-
tion of credentialV alidity delay, which is deﬁned as taking
three time-points:
Duration (credentialV alidity, 3)
(20)
Analysis starts by formulating a security violation goal:
it asks whether it is possible to reach a state where patient
conﬁdentiality is compromised. In the context of SMIS, this
happens when some doctor accesses some patient’s data with-
out a valid security credential; the goal expressing this is
formulated as:
∃ d : Doctor; p : Patient; t1, t2 : Time |
HoldsAt (ExposedToAt (d, p, t2), t1)
∧¬ HoldsAt (HasV alidCredential (d, p), t2)
(AG1)
For this goal, decreasoner does not ﬁnd any traces (a
fragment of decreasoner’s output for this goal is given ap-
pendix A1). This means that the modelled system cannot reach
one of the goal’s states. At this point, one could argue that the
modelled system is secure because it is not possible to reach
an unsecure state, but it isn’t so.
Analysis proceeds by applying suspicion. The substitute
doctor rule (Requirement R2) enables access to patient’s data
by doctors other than the main patient’s doctor. This should
occur, but not very often; the situations under which this occurs
are suspicious and deserve investigation. Analysis investigates
states where those other than the main doctor access the
patient’s data. This is formulated as the goal:
∃ d : Doctor; p : Patient; t1, t2 : Time |
HoldsAt (ExposedToAt (d, p, t2), t1)
∧¬ HoldsAt (IsDoctorOf (d, p), t2)
(AG2)
R3
Only the doctors themselves or one of their administrators are
allowed to nominate a substitute, and inform the system of
their absence (on-leave) or return to duty.
s
TABLE II
REQUIREMENTS EMERGING AFTER ANALYSIS OF SMIS INITIAL
REQUIREMENTS.
For this goal, decreasoner generates traces exposing a
security vulnerability, which enables doctors to access patient’s
data in non-legal ways (see appendix A2 for output generated
by decreasoner). In some scenarios, the system behaves as
intended: Jones sets Smith as his substitute, at a later time
Jones informs system that he is on leave, and so Smith is
able to access the medical data (model 5 in appendix A2).
Other scenarios are more unusual. In some of them, it is
possible that Smith himself requests to be the substitute
of Jones (model 1 in appendix A2), and that it is Smith
who informs the system that Jones is on-leave (model 1 in
appendix A2). Obviously this is strange and could be explored
by a malicious doctor determined to get some patient’s medical
data: (a) he sets himself as substitute of another doctor, then
(b) he informs the system that main doctor is on-leave and (c)
ﬁnally he is able to access the patient’s data.
Such
scenarios
are
possible
because
events
IsSubstituteDoctor and SetDoctorOnLeave (equations 10
and 11) are unconstrained: any user may execute them, which
introduces a loophole providing an opportunity for access to
patient’s data in ways that are not intended.
We can conﬁrm the vulnerability by posing an analysis
question. We want to know if it is possible that some user
can nominate himself as some other doctor’s substitute and
then to be able to access the data of a patient that is not his
own. This is formulated as:
∃ d1, d2 : Doctor; p : Patient; t1, t2, t3 : Time |
Happens (SetSubstituteDoctor (d1, d2, d1), t2)
HoldsAt (ExposedToAt (d1, p, t3), t1)
∧¬ HoldsAt (IsDoctorOf (d1, p), t3) ∧ t2 ≤ t3
(AG3)
For this goal, descreasoner is able to identify many scenarios,
thus conﬁrming the identiﬁed vulnerability.
C. Fixing the Model
The analysis’ ﬁndings are used to elaborate the require-
ments. We try to remove the vulnerability that has been
identiﬁed. The requirements that emerge as a result of this
elaboration are given in table II; here, R1 and R2 of table I
still hold, and there is new requirement R3, which introduces
users of type administrators that execute administration tasks
on behalf of doctors.
This new requirement needs to be reﬂected in the EC model.
New version of EC model introduces sort Admin, subsort of
User sort, and which is disjoint from Doctor sort. It also
introduces a new ﬂuent:
• HasAdmin (d, a) indicates administrator user (a) doing
administrative tasks on behalf of some doctor d.
This new sort and ﬂuent are used to describe the new
requirement. Next EC equation constrains HasAdmin to be a
total relation; each doctor must have at least one administrator:
347
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

5
∀ d : Doctor; t : Time |
(∃ a : Admin) HoldsAt (HasAdmin (d, a), t)
(21)
Next EC equation constrains HasAdmin to be a surjective
relation; each administrator must be associated with a doctor:
∀ a : Admin; t : Time |
(∃ d : Doctor) HoldsAt (HasAdmin (d, a), t)
(22)
Next EC equation deﬁnes predicate CanDoAdmin, which
indicates users (u) that can do administrative tasks on behalf
of some doctor (d):
∀ u : User; d : Doctor; t : Time |
HoldsAt (CanDoAdmin (u, d), t)
⇔ u = d ∨ ((∃ ad : Admin ) u = ad
∧ HoldsAt (HasAdmin (d, ad), t))
(23)
Next
EC
equations
use
predicate
CanDoAdmin
to
deﬁne a pre-condition for events SetSubstituteDoctor,
DoctorOnLeave and DoctorNoLongerNoLeave. These
events may occur provided CanDoAdmin is true; that is,
user executing them can do administrative tasks on behalf of
affected doctor:
∀ u : User; d1, d2 : Doctor; t : Time |
Happens (SetSubstituteDoctor (u, d1, d2), t)
⇒ HoldsAt (CanDoAdmin (u, d1), t)
(24)
∀ u : User; d : Doctor; t : Time |
Happens (SetDoctorOnLeave (u, d), t)
⇒ HoldsAt (CanDoAdmin (u, d), t)
(25)
∀ u : User; d : Doctor; t : Time |
Happens (DoctorNoLongerOnLeave (u, d), t)
⇒ HoldsAt (CanDoAdmin (u, d), t)
(26)
D. Re-analysing the Model
The analysis conﬁguration is reﬁned by introducing two
administrators; one for each doctor:
alice, sue : Admin
(27)
Initially (HasAdmin (jones, alice))
(28)
Initially (HasAdmin (smith, sue))
(29)
Under the revised EC model, we re-submit the model to the
security violation and suspicion goals:
• For the security violation goal (equation AG1 above), we
still get no plans (not possible to break conﬁdentiality in
an obvious way).
• For the reﬁned suspicious goal (equation AG3 above),
we no longer get any plans. Meaning that the loophole
has been eliminated.
• For the more abstract suspicious goal (equation AG2
above) we no longer get obvious security threats, but
the results still prompt interesting requirements questions,
such as: the system allows doctors to operate the system
while they are recorded as being on leave, should this be
allowed?
R1
There are two types of users clerks and managers. Managers
can performs the tasks that usually the clerks do, but clerks
should not usually perform manager’s tasks (exception is
delegation, below).
R2
Clerks are responsible for starting the refund procedure, and
for issuing or cancelling the refund.
R3
The refund shall be issued by a clerk if approved by the
managers, or cancelled otherwise.
R4
A refund must by approved by two different managers.
R5
A clerk shall not both prepare and issue or cancel a refund.
R6
Managers can delegate the authority on approval of refunds
to one of their administrators.
TABLE III
REQUIREMENTS OF PAYMENT PROCESSING WORKFLOW.
Fig. 3.
The payment processing workﬂow.
V. SEPARATION OF DUTIES
Separation of Duties (SoD) [16], [17] is a security mech-
anism used to prevent fraud and errors. It aims to prevent
a single individual from executing business-critical tasks of
some transactions or business processes. SoD requires such
tasks to be performed by different users acting in cooperation
(e.g by requiring two persons to sign a cheque). Here, SoD is
studied using a classical case study: a workﬂow of payment
processing; SoD is used to enable payment authorisations to
be performed by different users.
The requirements of this workﬂow system are given in
table III; Fig. 3 depicts underlying workﬂow. The two tasks
involving approval of payments to be carried out by managers,
and the tasks prepare payment and issue/void payment, to be
carried out by clerks, are subject to SoD.
A. EC Model
The EC model presented here models a workﬂow as a set
of activities. Each activity is made of several alternative tasks;
one of the tasks must be carried out to complete the activity.
In workﬂow of Fig. 3, activity Approve/Refuse Pay comprises
tasks approve pay and refuse pay, and activity Issue/Void Pay
comprises tasks issue pay and void pay. There is always some
active activity in some running workﬂow session.
Workﬂow tasks are executed by users who have different
task execution permissions. Task permissions are deﬁned at
the level or rˆoles; a user is assigned one or more user rˆoles.
In Fig. 3, users that have rˆole clerk may execute tasks Prepare
Pay, Issue Pay and void Pay; users of rˆole manager may exe-
cute tasks Approve Pay and Refuse Pay and all other tasks that
clerks do. The model also enables delegation; administrators
of managers may also execute tasks on managers’ behalf.
348
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

6
The following describes the following elements of EC
model: sorts; activities; tasks, rˆoles and delgation; task exe-
cution; and payment processing workﬂow.
1) Sorts: EC model introduces sorts Activ, Task, Session
and User. Activ represents activities of a workﬂow; Task
represents a workﬂow task that is executed by users; Session
represents a running session of a workﬂow; and User rep-
resents users that can execute tasks. Rˆoles are modelled as
sub-sorts of sort User; rˆoles of payment processing workﬂow
are deﬁned below (section V-A5).
2) Activities:
Fluent CurrActiv (a,
s) of EC model
records current activity (a) of some workﬂow session (s). Next
EC equations constrain ﬂuent CurrActiv to say that there is
at most one current activity per workﬂow session:
∀ a1, a2 : Activ; s : Session; t : Time |
HoldsAt (CurrActiv (a1, s), t)
HoldsAt (CurrActiv (a2, s), t)
⇒ a1 = a2
(30)
Next EC equation gives initial state of ﬂuent CurrActiv,
saying that initially there are no current activities:
∀ a : Activ; s : Session |
Initially (¬ CurrActiv (a, s))
(31)
To represent workﬂow conﬁgurations in terms of its con-
stituent activities, EC model uses predicates OccursBefore.
This indicates the ordering of activities in a workﬂow. Predi-
cate OccursBefore is deﬁned below for payment processing
workﬂow (section V-A5, equation 50).
Predicate IsStartActiv indicates start activity of a work-
ﬂow; it is deﬁned from predicate OccursBefore as:
∀ a1 : Activ |
IsStartActiv (a1)
⇔ ¬ ((∃ a2 : Activ) OccursBefore (a2, a1))
(32)
In model proposed here, separation of duties is enforced on
activities. In workﬂow of Fig. 3, we have a SoD constraint
between activities Approve/Refuse Pay 1 and Approve/Refuse
Pay 2 and Prepare Pay and Issue/Void Pay. In EC model,
such constraints are represented using predicate SoD, which
is deﬁned for each workﬂow that is to be described and
analysed (described below for payment processing workﬂow
in equation 51).
To deﬁne a precondition for event StartWrkf, EC model
introduces predicate Started, which indicates whether some
session has been started or not:
∀ s : Session; t : Time |
HoldsAt (Started (s), t)
⇔ (∃ a : Activ; t2 : Time) t2 ≥ t
∧ HoldsAt (CurrActiv (a, s), t2)
(33)
Event StartWrkf starts a workﬂow session. Next EC equa-
tion deﬁnes pre-condition of event StartWrkf; a workﬂow
session may start if it has not already been started:
∀ s : Session; t : Time |
Happens (StartWrkf (s), t)
⇒ ¬ HoldsAt (Started (s), t)
(34)
Next EC equation says how event StartWrkf initiates
ﬂuent CurrActiv; when a workﬂow starts, current activity
becomes workﬂow’s start activity (predicate IsStartActiv):
∀ s : Sesstion; a : Activ; t : Time |
IsStartActiv (a)
⇒ Initiates (StartWrkf (s), CurrActiv (a, s), t)
(35)
3) Tasks, rˆoles and delegation: As said above, tasks are
associated with activities. This association is deﬁned through
predicate IsTaskOfActiv; this predicate is deﬁned for each
workﬂow being described and analysed (it is deﬁned in
equation 49, below, for payment processing workﬂow).
To know whether some task can be executed in a workﬂow,
EC model introduces predicate IsTaskOfCurrActiv, which
indicates whether some task belongs to the current activity
of some workﬂow session. Next EC equation deﬁnes this
predicate; it says that some task belongs to current activity
of some session if it is a task of session’s current activity:
∀ ta : Task; s : Sesstion; t : Time |
HoldsAt (IsTaskOfCurrActiv (ta, s), t)
⇔ (∃ a : Activ) HoldsAt (CurrActiv (a, s), t)
∧ IsTaskOfActiv (ta, a)
(36)
Predicate CanDo (u, t) indicates the rˆoles (r) that are
allowed to execute workﬂow tasks (t). Certain users may del-
egate their rˆoles; predicate MayDelegTo (u1, u2) says that
some user (u1) is allowed to delegate his rˆoles to another user
(u2). Both CanDo and MayDelegTo are deﬁned for each
workﬂow being described and analysed; it is described below
for payment processing workﬂow in equations 52 and 53.
Event DelegsTo occurs whenever a rˆole delegation takes
place. Next EC equation deﬁnes this event’s pre-condition;
users delegate to others provided they are allowed to do so:
∀ u1, u2 : User; t : Time |
Happens (DelegsTo (u1, u2), t)
⇒ MayDelegTo (u1, u2)
(37)
Fluent Delegated (u1, u2) says that some user (u1) has del-
egated to another. Next EC equation says that event DelegsTo
initiates (sets to true) ﬂuent Delegated to enable system to
keep track of rˆole delegations:
∀ u1, u2 : User; t : Time |
Initiates (DelegsTo (u1, u2), Delegated (u1, u2), t)
(38)
Next EC equation deﬁnes initial condition of ﬂuent
Delegated; initially, no rˆole delegations have taken place:
∀ u1, u2 : User |
Initially (¬ Delegated (u1, u2))
(39)
To capture permissions related with delegations, next EC
equation introduces predicate CanExecAsDelegate, which
indicates whether some user can execute a task as delegate:
∀ u : User; ta : Task; t : Time |
HoldsAt (CanExecAsDelegate (u, ta), t)
⇔ ¬ CanDo (u, ta)
∧ ((∃ u2 : User) HoldsAt (Delegated (u2, u), t)
∧ CanDo (u2, ta))
(40)
This predicate is used to deﬁne predicate HasPerm, which
indicates whether some user has the required permissions to
349
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

7
execute some workﬂow task; this is true if user has required
permissions to execute task with his rˆole or if he has been
delegated the rˆole of someone else with required permissions:
∀ u : User; ta : Task; t : Time |
HoldsAt (HasPerm (u, ta), t)
⇔ CanDo (u, ta)
∨ HoldsAt (CanExecAsDelegate (u, ta), t)
(41)
4) Task execution: Event ExecTask happens whenever
some workﬂow task is executed. Next EC equation deﬁnes
predicate ExecutedTaskOfActiv, which indicates whether
some user executed a task of some activity in some workﬂow
session:
∀ u : User; a : Activ; s : Session; t : Time |
HoldsAt (ExecutedTaskOfActiv (u, a, s), t)
⇔ (∃ ta : Task; t2 : Time) t2 < t
∧ Happens (ExecTask (ta, u, s), t2)
∧ HoldsAt (CurrActiv (a, s), t2))
(42)
Predicate ExecutedTaskOfActiv is used to deﬁne predi-
cate BreachesSoD, which indicates whether some user can
breach SoD in some workﬂow session. BreachesSoD is true
whenever some user executed some task of some activity for
which there is a SoD constraint with current activity in some
workﬂow session; it deﬁned as:
∀ u : User; s : Session; t : Time |
HoldsAt (BreachesSoD (u, s), t)
⇔ (∃ a1, a2 : Activ) HoldsAt (CurrActiv (a1, s), t)
∧ (SoD (a1, a2) ∨ SoD (a2, a1))
∧ HoldsAt (ExecutedTaskOfActiv (u, a2, s), t))
(43)
When event ExecTask happens, current activity changes to
be next activity in the workﬂow; this goes on until the work-
ﬂow session ﬁnishes. There are several restrictions associated
with execution of tasks in a workﬂow; these are modelled
as event pre-conditions of event ExecTask: (a) the task be-
longs to the current activity (predicate IsTaskOfCurrActiv,
equation 36), that (b) the user has the required permissions
to execute the task (predicate HasPerm, equation 41), and
that (c) the execution of the task by the user does not break
separation of duties (predicate BreachesSoD, equation 43).
This is deﬁned in EC by the equation:
∀ u : User; ta : Task; s : Session; t : Time |
Happens (ExecTask (ta, u, s), t)
⇒ HoldsAt (IsTaskOfCurrActiv (ta, s), t)
∧ HoldsAt (HasPerm (u, ta), t)
∧ ¬ HoldsAt (BreachesSoD (u, s), t)
(44)
As said above, when a task is executed the current activity
must change. This requires an EC equation deﬁning a termi-
nates predicate to set the current activity to false if there is
a current activity. It also requires an initiates predicate to set
the current activity to the next activity of the workﬂow. These
are deﬁned as:
∀ u : User; a : Activ; ta : Task;
s : Session; t : Time |
HoldsAt (CurrActiv (a, s), t)
⇒ Terminates (ExecTask (ta, u, s),
CurrActiv(a, s), t)
(45)
∀ u : User; a1, a2 : Activ; ta : Task;
s : Session; t : Time |
HoldsAt (CurrActiv (a1, s), t)
∧ OccursBefore (a1, a2))
⇒ Initiates (ExecTask (ta, u, s),
CurrActiv (a2, s), t)
(46)
5) Payment processing workﬂow: EC equations above de-
ﬁne infrastructure necessary to describe workﬂows with SoD
constraints. The following EC equations actually deﬁne the
payment processing system workﬂow of Fig. 3.
We start by deﬁning the rˆoles of the workﬂow. Rˆoles are
modelled as sub-sorts of sort User; and so we have User sub-
sorts Clerk and Manager. Rˆole administrator is modelled as
the predicate IsAdminOf.
Next EC equation deﬁnes the tasks and activities of the
workﬂow:
prepPay, approvePay1, approvePay2,
FinPay : Activ
(47)
tPrepPay, tApprovePay, tRefusePay, tIssuePay,
tV oidPay : Task
(48)
This says that the workﬂow activities are those identiﬁed
in Fig. 3, prepare payment (prepPay), approve payment
(approvePay1 and approvePay2), and ﬁnalise payment
(FinPay), and that the tasks are also those of Fig. 3, prepare
pay (tPrepPay), approve payment (tApprovePay), refuse
payment (tRefusePay), issue payment (tIssuePay) and
void payment (tV oidPay).
Next equation deﬁnes the relation that exists between tasks
and activities by deﬁning predicate IsTaskOfActiv:
∀ ta : Task; a : Activ | IsTaskOfActiv (ta, a)
⇔ (a = PrepPay ∧ ta = tPrepPay)
∨ ((a = ApprovePay1 ∨ a = ApprovePay2)
∧ (ta = tApprovePay ∨ ta = tRefusePay))
∨ (a = IssueOrV oidPay
∧ (task = tIssuePay ∨ task = tV oidPay))
(49)
This says that prepare payment activity is made of prepare
payment task, approve payment activities (ApprovePay1 and
ApprovePay2) are composed of tasks approve pay and refuse
pay, and that FinPay activity is composed of tasks issue pay
and void pay.
Next equation deﬁnes the OccursBefore predicate. It Says
that Prepay must occur before ApprovePay1, which must
occur before approvePay2, and that approvePay2 must
occur before issueOrV oidPay:
∀ a1, a2 : Activ | OccursBefore (a1, a2)
⇔ (a1 = PrepPay ∧ a2 = ApprovePay1)
∨ (a1 = approvePay1 ∧ a2 = approvePay2)
∨(a1 = approvePay2 ∧ a2 = issueOrV oidPay)
(50)
Next equation deﬁnes the SoD constraints of the payment
processing workﬂow by deﬁning predicate SoD. It says that
there is a SoD constraint between activities PrepPay and
350
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

8
IssueOrV oidPay, and between activities ApprovePay1 and
ApprovePay2:
∀ a1, a2 : Activ | SoD (a1, a2)
⇔ (a1 = PrepPay ∧ a2 = IssueOrV oidPay)
∨ (a1 = ApprovePay1 ∧ a2 = ApprovePay2)
(51)
Next equation deﬁnes the permissions of workﬂow tasks by
deﬁning predicate CanDo. Equation says that mnagers can
execute any task and that clerks can execute tasks prepare,
issue and void payments:
∀ u : User; ta : Task | CanDo (u, ta)
⇔ ((∃ ma : Manager) u = ma)
∨ ((∃ cl : Clerk) (ta = tPrepPay
∨ ta = tIssuePay ∨ ta = tV oidPay))
(52)
Next EC equation deﬁnes the delegation rule of the payment
processing workﬂow. It says that managers may delegate tasks
to their administrators:
∀ u1, u2 : User | MayDelegTo (u1, u2)
⇔ ((∃ ma : Manager) u1 = ma
∧ IsAdminOf (u2, u1))
(53)
A payment is issued provided both managers approve it.
Next EC equation deﬁnes predicate PayApproved, which
deﬁnes what it means for a payment to be approved:
∀ s : Session; t : Time |
HoldsAt (PayApproved (s), t)
⇔ ((∃ u1, u2 : User; t2, t3 : Time; ta : Task)
u1 ̸= u2 ∧ t2 < t ∧ t3 < t
∧ ta = tApprovePay
∧ Happens (ExecTask (ta, u1, s), t2)
∧ Happens (ExecTask (ta, u2, s), t3))
(54)
This
says
that
a
payment
is
approved
provided
task
tApprovePay has been executed at two different time-points
by two different users in context of a workﬂow session.
Next two EC equations deﬁne the constraints associated
with tasks tIssuePay and tV oidPay. They say that task
tIssuePay may be executed provided the payment has been
approved, and that task tV oidPay may be executed provided
it has not been approved:
∀ u : User; s : Session; t : Time |
Happens (ExecTask (tIssuePay, u, s), t)
⇒ HoldsAt (PayApproved (s), t)
(55)
∀ u : User; s : Session; t : Time |
Happens (ExecTask (tV oidPay, u, s), t)
⇒ ¬ HoldsAt (PayApproved (s), t)
(56)
This completes EC model of payment processing workﬂow
requirements (table III). Next section analyses this model.
B. Model Analysis
Analysis is conducted in a conﬁguration made of three
managers, Bob, John and Martin, and three clerks Sam, Alice
and Sue; Sue also works as an administrator for John. This is
deﬁned in EC as:
bob, john, martin : Manager
(57)
alice, sam, sue : Clerk
(58)
∀ u1, u2 : User | IsAdminOf (u1, u2)
⇔ u1 = sue ∧ u2 = john
(59)
Analysis starts with a security violation goal to know if it
is possible to reach a state where SoD is breached. Next EC
equation deﬁnes what it means to breach SoD; that is, a user
executed tasks belonging to activities constrained under SoD:
∀ u : User; s : Session; t : Time |
HoldsAt (BreachedSoD (u, s), t)
⇔ ((∃ a1, a2) a1 ̸= a2
∧ HoldsAt (ExecutedTaskOfActiv (u, a1, s), t)
∧ HoldsAt (ExecutedTaskOfActiv (u, a2, s), t)
∧ (SoD (a1, a2) ∨ SoD (a2, a1)))
(60)
This predicate is used to formulate the goal:
∃ u : User; s : Session; t : Time |
HoldsAt (BreachedSoD (u, s), t)
(AG4)
For this goal, decreasoner does not ﬁnd any plans. This
means that it is not possible to reach a state where SoD is
breached. Again, one could argue that SoD is preserved and
the system is secure, but it isn’t so.
Analysis proceeds by investigating the suspicious space.
Although a user is allowed to execute more than one task in
some workﬂow session, this should not happen very often and
is suspicious. The idea is to explore this somehow suspicious
or abnormal situation in order to ﬁnd clues that help in ﬁnding
security vulnerabilities. First, we deﬁne a predicate describing
the suspicious system condition of having a user executing
two tasks in a workﬂow session:
∀ u : User; s : Session; t : Time |
HoldsAt (ExecutedTwoTasks (u, s), t)
⇔ ∃ ta1, ta2 : Task; t2, t3 : Time |
∧ Happens (ExecTask (ta1, u, s), t2)
∧ Happens (ExecTask (ta2, u, s), t3)
∧ ta1 ̸= ta2 ∧ t2 ≤ t ∧ t3 ≤ t
(61)
Since we are interested in scenarios involving com-
plete workﬂow runs, next EC equation deﬁnes predicate
IsWrkfComplete, which says whether some workﬂow ses-
sion is complete or not:
∀ s : Session; t : Time |
HoldsAt (IsWrkfComplete (s), t)
⇔ HoldsAt (Started (s), t)
∧¬ ((∃ a : Activ) HoldsAt (CurrActiv(a, s), t))
(62)
From these two predicates, we deﬁne the suspicious goal
by describing states where some user executes two different
tasks in some workﬂow run:
∃ u : User; s : Session; t : Time |
HoldsAt (IsWrkfComplete (s), t)
∧ HoldsAt (ExecutedTwoTasks (u, s), t)
(AG5)
For this goal, decreasoner generates interesting plans. We
have scenarios where a manager prepares the payment and then
approves it, or that he approves and then issues the payment.
This happens because managers may act as clerks and there is
no SoD constraint between tasks that managers do and clerks
do. As this may give a fraud opportunity, it is important to
clarify the requirements regarding this issue.
351
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

9
R6’
Managers can delegate authority on approval of refunds to one
of their administrators, but when administrators executes such
tasks system should consider that they have been executed on
behalf of manager and are is manager had executed them.
R7
The same person may perform tasks as either manager or
clerk, but not both, in any workﬂow session.
TABLE IV
REQUIREMENTS RULING THE PROCESSING OF TAX REFUNDS THAT
EMERGED AFTER ANALYSIS.
C. Clarifying the requirements
Clariﬁcation of the issue exposed by the analysis results in
new requirement R7 (table IV), which says that a person can
execute tasks under at most one rˆole in any workﬂow session.
To take this new requirement into account, EC model intro-
duces predicate RolesRequiredDiffer, which says which
workﬂow tasks require different rˆoles to execute them. This
predicate is deﬁned for workﬂow of payment processing as:
∀ ta1, ta2 : Task |
RolesRequiredDiffer (ta1, ta2)
⇔ (ta1 = tPrepPay ∨ ta1 = tIssuePay
∨ ta1 = tV oidPay)
∧ (ta2 = tApprovePay ∨ ta2 = tRefusePay)
(63)
This predicate says that the roles required for tasks
tPrepPay, tIssuePay and tV oidPay is different for those
of tasks tApprovePay and tRefusePay.
Predicate RolesRequiredDiffer is used to state the re-
quired requirement by constraining event ExecTask. Next
EC equation describes this constraint by saying that if some
user executes two different tasks then roles required to execute
them must not differ:
∀ u : User; s : Session; ta1, ta2 : Task;
t1, t2 : Time |
Happens (ExecTask (ta1, u, s), t1)
∧ Happens (ExecTask (ta2, u, s), t2)
∧ ta1 ̸= ta2
⇒ ¬ RolesRequiredDiffer (ta1, ta2)
(64)
D. Re-Analysing the model
After the ﬁx, the vulnerability identiﬁed above that that
could give a fraud opportunity is no longer allowed. We re-
submit the analysis goal above and decreasoner no longer
generates scenarios with those possible fraudulent behaviours.
Analysis turns to delegation, which is known to generate
security vulnerabilities. Someone executing a task on behalf
of someone is legal but suspicious and deserves investigation.
Again, the idea is too look in behaviours involving delegation
for clues on possible system vulnerabilities. We introduce a
predicate to say whether some user executed some task as
delegate; next two EC equations deﬁne this predicate:
∀ u : User; ta : Task; s : Session; t : Time |
HoldsAt (DelegExecutedFor (u, ta, s), t)
⇔ ((∃ t2 : Time) t2 < t
∧ DelegExecutedForAt (u, ta, s, t2))
(65)
∀ u : User; ta : Task; s : Session; t : Time |
DelegExecutedForAt (u, ta, s, t)
⇔ ((∃ u2 : User)
Happens (ExecTask (ta, u2, s), t)
∧ HoldsAt (Delegated (u, u2), t)
∧ HoldsAt (CanExecAsDelegate (u2, ta), t))
(66)
Above, predicate DelegExecutedFor says whether some
task was executed by delegate for some user. This is deﬁned
from predicate DelegExecutedForAt, which says whether
some user executed the task as delegate.
Goal is deﬁned from DelegateExecutedFor by describing
states of complete workﬂow runs where someone executes a
task on behalf of someone else. This results in the goal:
∃ u : User; ta, : Task; s : Session; t : Time |
HoldsAt (IsWrkfComplete (s), t)
∧ HoldsAt (DelegExecutedFor (u, ta, s), t)
(AG6)
Plans generated by decreasoner result in what is normally
expected under delegation (someone executes a task on behalf
of someone else), but they also result in plans that may be
possible frauds: a delegate approves a payment on behalf of
the manager and the same manager also approves the same
payment.
E. Clarifying and elaborating the requirements
From this, we elaborate the requirements, and we get R6′
(table IV) an elaboration of requirement R6. This says that
system must consider tasks executed by administrators acting
as delegates as if they had been executed by the managers
themselves.
To accommodate this new requirement, we introduce the
predicate ExecutedTask, which indicates whether some user
executed some task, either directly or indirectly through a
delegate. This is deﬁned as:
∀ u : User; ta : Task; s : Session; t : Time |
HoldsAt (ExecutedTask (u, ta, s), t)
⇔ (∃ t2 : Time) t2 < t
∧ ExecutedTaskAt (u, ta, s, t2))
(67)
∀ u : User; ta : Task; s : Session; t : Time |
ExecutedTaskAt (u, ta, s, t)
⇔ Happens (ExecTask (ta, u, s), t)
∨ DelegExecutedForAt (u, ta, s, t)
(68)
Predicate ExecutedTask deﬁned above is used to redeﬁne
predicate ’ExecutedTaskOfActiv’ equation 42). New formula-
tion of this predicate is deﬁned by EC equation:
∀ u : User; a : Activ; s : Session; t : Time |
HoldsAt (ExecutedTaskOfActiv (u, a, s), t)
⇔ (∃ ta : Task; t2 : Time) t2 < t
∧ HoldsAt (ExecutedTask (u, ta, s), t2)
∧ HoldsAt (CurrActiv (a, s), t2))
(42′)
In this revised EC model, the possible fraudulent behaviour
identiﬁed above is no longer allowed.
VI. EXPERIMENTAL RESULTS
In both experiments presented above, formal analysis ver-
iﬁed a straightforward safety security property, which could
mislead analysts in concluding that an unsecure state would
not be reached in the modelled system. However, suspicion-
based analysis demonstrated that the modelled systems were
in fact not secure.
Section IV analyses a simple medical information system
that includes a conﬁdentiality requirement. Following the
352
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

10
Case Study
Anaysis Goal
Time
SMIS
Security Violation (AG1)
3.6s
SMIS
Suspicion goal 1 (AG2)
4.9s
SMIS
Suspicion goal 2 (AG3)
12.6s
SMIS
Security Violation (AG1), after ﬁx
14.s
SMIS
Suspicion goal 1 (AG2), after ﬁx
15.8s
SMIS
Suspicion goal 2 (AG3), after ﬁx
21.1s
Workﬂow
Security violation (AG4)
235.9s (3.9m)
Workﬂow
Suspicion goal 1 (AG5)
600.7s (10.0m)
Workﬂow
Suspicion goal 1, after ﬁx (AG5)
476.9s (7.9m)
Workﬂow
Suspicion goal 2 (AG6)
619.2s (10.3m)
Workﬂow
Suspicion goal 2 (AG6), after ﬁx
611.11s (10.2m)
TABLE V
RUNNING TIMES FOR ANALYSIS OF EC MODELS WITH decreasoner. TABLE
INDICATES CASE STUDY, ANALYSIS GOAL AND TIME TAKEN TO GENERATE
PLANS.
traditional route of safety analysis, it was not possible to
ﬁnd ways in which conﬁdentiality would be compromised:
without a valid credential it would not be possible to obtain
the patient’s medical data. Analysis based on suspicion then
uncovered a security vulnerability (or loophole) that would
enable a malicious user to obtain the required credentials in a
non-legal way.
Section V analyses a business process whose security
requirements included two integrity requirements enforced
through SoD. Again, SoD could be breached, but not in
an obvious way. Following the traditional safety analysis
route, we checked that it was not possible that the same
user would be able to execute two different tasks protected
by SoD. Analysis-based on suspicion, however, uncovered
several problems: the same user could execute different tasks
in a workﬂow session under different roles, and delegation
introduced a loophole that would enable users to indirectly
breach SoD.
Table V presents the running times of the formal analysis
based on planning with decreasoner3. For each case study, it
shows how much time it took to carry out the analysis for each
analysis goal. We can see that the analysis of the workﬂow
model of section V takes substantially longer than SMIS model
because it is more complex.
VII. DISCUSSION
This paper proposes suspicion as a concept driving the anal-
ysis of security requirements. Through experiments, it argues
that, from a practical point of view, in security the interesting
question is not only to verify the in-existence of a state
compromising some security property (safety), but also to look
for what is suspicious in order to ﬁnd security vulnerabilities
and threats. The experiments conducted in the context of the
EC temporal logic, planning and the decreasoner tool. They
demonstrate the usefulness of suspicion. The traditional safety
analysis route, which checks whether some security property
is violated, would not expose any security issues; this can
mislead analysts in concluding that the system being analysed
is secure. Analysis based on suspicion uncovered security
3Model analysis carried out on an Apple iMac, with a 2.93 Ghz Intel Core
2 Duo processor and 4GB memory RAM.
vulnerabilities and threats; such ﬁndings drive elaboration of
the requirements.
One of the advantages of the approach presented here is
that security threats can be derived directly from a model of
requirements. The analysis that does not need prior knowledge
about possible attacks to the modelled system, and so no
need to enrich the model with attacker or intruder models.
Instead, using the suspicion-based approach proposed here, it
is possible to derive threats from a requirements model by
posing the model questions based on what is suspicious.
All the vulnerabilities exposed by suspicion-based analysis
are related with delegation or passing of capabilities, which
are known in security as non-interference properties [18]. The
formulation and veriﬁcation of such properties have proved
to be far from trivial [4]. The analysis conducted in this
paper conﬁrms that delegation can be trick and hard to get
right. Suspicion-based analysis helped in identifying security
problems with delegation, and in elaborating the security
requirements in order to eliminate such problems. The paper
also shows that proof of a straightforward safety property
related with security does not deem a system secure. Often, as
shown in this paper, the secure question is more involved and
requires more in-depth knowledge of the requirements. As this
paper shows, it can be more revealing to analyse the system in
order to explore the consequences of the requirements, which
leads to a better understanding of the security needs and issues
of the modelled system, rather than trying to prove that a
system is secure. For the delegation-related issues explored in
these two experiments, such proofs are far from trivial.
The approach presented here generates automatically possi-
ble scenarios of misuse (threats) from a statement describing
some security violation or suspicious condition (the goal). This
provides a ﬂexible and illuminating scheme to the analysis of
security requirements. Rather then ﬁnding themselves possible
threats, analysts describe instead what would constitute a
violation of security or a suspicious system condition. Analysis
goals require an understanding of the requirements domain,
and should be described with some security asset in mind.
The security vulnerabilities exposed by the analysis illus-
trate the sort of vulnerabilities that attackers exploit to intrude
into today’s software systems. The vulnerabilities identiﬁed
in the health-care system give insiders the opportunity to
perpetrates attacks on the system; the insider threat has
been identiﬁed as one of the main sources of attacks in the
medical domain [15]. Once a source of threats is identiﬁed
in the requirements, two decisions can be made: (a) introduce
further constraints by elaborating the requirements so that the
source of threats is eliminated, or (b) do nothing in terms
of requirements, but take the problem into account in terms
of run-time intrusion and threat detection which then has to
judge whether some uses of the system are malicious or not.
The latter must be considered because it is not possible to
eliminate all possible security threats; doing so could result
in a system design that is rigid and over-constrained. The
approach presented here enables the detection of threats or
vulnerabilities in the system, which also constitutes valuable
information for run-time intrusion and threat detection.
The experiments conducted here conﬁrm the importance
353
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

11
of modelling and analysing security together with system
requirements. Both case studies show how a functionality
of the system, delegation, have a serious impact on security
and how it was necessary to further elicit and elaborate the
requirements in order to eliminate threats.
Formal security analysis with tool support is capable of
exposing many unexpected situations, providing a level of
assurance not guaranteed by semi-formal approaches. The
drawback of the analysis with decreasoner lies in the efﬁ-
ciency of the tool: as models get more complex, the solution to
analysis problems take more time to the point that the analysis
becomes unpractical. The workﬂow model of section V is a
simpliﬁcation of an earlier model to enable practical analysis.
As usual, the secret is in getting the right abstraction in order
to analyse the property of interest.
It is interesting to comment on the usability of the approach
presented here. The process of deﬁning analysis goals may
require domain knowledge and skill in building and analysing
models. However, the process can be partially or fully au-
tomated by following the pattern-based approach proposed
of [19], which uses the Formal Template Language [20],
[21] to represent patterns of EC models together with their
associated security monitoring goals. [19] deﬁnes templates
security violation goals, but patterns of suspicious goals can
also be deﬁned if we know in advance what can arouse
suspicion. In our experiments, delegation was the focus of
our suspicious goals; this is something that can be known in
advance and captured using patterns. Following [19], we can
have goals that capture what is known to arouse suspicion;
actual suspicious goals would then be automatically generated
from templates. [19] also uses UML models to enable intuitive
requirements modelling; the same approach can also be used
to enhance the usability of the approach proposed here.
VIII. RELATED WORK
This paper is a revised and extended version of the work
presented in [22]. It shows in detail the EC models that are
used to illustrate the analysis based on suspicion with EC,
and provides a more in-depth discussion on the veriﬁcation of
security properties, such as the one explored in the paper.
The results of this paper argue against ironclad proofs of
security and how one needs to be careful in interpreting formal
demonstrations of security properties. This theme is not new;
in [23], McLean refutes what used to be a widely held belief:
that the security model of Bell and LaPadula [24] and its
basic security theorem would capture the essence of security
and that implementations following it would be secure4. This
refutation was done by stating a similar theorem for a model
that is clearly not secure. Both experiments of this paper
demonstrated that the modelled system would not breach a
straightforward safety property of security (conﬁdentiality and
separation of duty), and how that could mislead analysts in
concluding that the system was secure. However, more ﬂexible
means of analysis exposed vulnerabilities showing that the
systems being analysed were in fact not secure; the paper
4This was not claimed by the authors of [24], but others that interpreted
their work believed that that was the case.
suggests analysis lead by what is suspicious in order to ﬁnd
security vulnerabilities in models of requirements.
The case studies used in this paper illustrate behaviours
that are usually tricky to be veriﬁed using safety or liveness
arguments. Most vulnerabilities identiﬁed in sections IV and V
are related to delegation, which has traditionally proved to
be tricky; [18] introduces non-interferance, a conﬁdentiality
policy that deals with delegation-based functionality. The
veriﬁcation of non-interference is far from trivial, and requires
a simpliﬁed model of a system that is difﬁcult to obtain when
modelling requirements. Such behaviours or properties have
also been termed possibilistic [7] and it is known that certain
security policies cannot be expressed using safety or liveness
properties represented as sets of traces [7], [8]. It is also known
that, in general, non-interferance policies cannot be expressed
as safety or liveness properties [8]. In [8], the authors propose
hyperproperties, which are deﬁned as sets of properties (sets
of sets of traces), to represent what is not normally captured
with traditional properties. This paper provides a pragmatic
approach to formally ﬁnd security vulnerabilities involving
delegation in models of security requirements.
There has been substantial interest on security requirements
threat analysis [25], [3], [26], [27]. In [26], [27], speciﬁers
need to explicitly identify scenarios or use-cases of abuse and
misuse; here, such scenarios are generated automatically from
a description of suspicious states (the goal).
[25] proposes a method based on the more ﬂexible abuse
frames, specifying undesirable phenomena that the system
should prevent from happening. The approach presented here
enables the speciﬁcation of such undesirable phenomena as
goals (here called security violation goals). However, it does
not only consider what should not happen, but also considers
speciﬁcation of ﬂexible suspicious conditions that (as shown
here) have the potential of exposing unnown threats.
[3] proposes a goal-based method that is similar to the
approach presented here. Security goals, such as conﬁdential-
ity, integrity and availability, are negated to obtain goals that
specify what should not happen (our security violation goals).
Then, these negations are reﬁned to obtain more ﬂexible goals.
The approach presented here is more ﬂexible in that it does
not only allow speciﬁcation of goals that come from negation
and reﬁnement security goals, but also leaves the speciﬁer the
ﬂexibility of deﬁning what constitutes a suspicious condition.
Since it is based on tool support, the speciﬁer can use the
feedback coming from the tool to either reﬁne existing analysis
goals or specify entirely new ones. Essentially, the work
presented here is complementary to the body of work on
security requirements threat analysis. It explores automated
formal analysis (missing in the works above) and provides
experimental evidence to the usefulness and effectiveness of
security threat analysis.
Suspicion is ubiquitous in intrusion detection [9]. Anomaly-
based approaches to intrusion detection [9] are so called
because the search for intrusions is driven by abnormal (or
suspicious) behaviour patterns of system use. [28] proposes
the inclusion of suspicion as a concept driving the models of
misuse-based intrusion detection; it proposes models based on
suspicious activities that may lead to an attack, as opposed
354
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

12
to models based on actual attacks. Instead, the approach
presented here detects abuse by identifying suspicious states
in a model of normal system behaviour.
The approach presented here emerges from its preceding
work on threat detection [19]. [19] uses an EC model of
requirements and planning to ﬁnd threats at run-time. In [19],
however, the goals used to detect threats are more rigid than
the ones used here; they say with absolute certainty whether
there is an attack or not when the goal is satisﬁed. In the
approach presented here, there is no certainty of attack if
a suspicious goal is satisﬁed, the plans that reach the goal
just give us threats (possible attacks). It would be possible
to incorporate our approach based on suspicion as a strategy
in looking for threats at run-time. Then, the probabilistic
component of such a system (like the one of [19]) would try
to assign a probability to the computed threats. Here we use
suspicion to look for threats in requirements to avoid systems
with security vulnerabilities.
The approach presented here analyses requirements auto-
matically using a tool based on SAT-solving. The advantage
of this method with respect to other approaches based on
theorem-proving [29], [21] is that the reasoning is automatic,
avoiding the need for user-intervation as it is usually the
case with theorem proving. The disadvantages are that only
a portion of the state space is analysed, and that the models
that can be handled need to be small; this problem can be
mitigated by using abstraction to produce smaller models
enabling analysis of property of interest. Another disadvantage
to the work in [29], [21] is that there is no visual description
of requirements and properties to check; the user needs to be
an expert in the formal language (here EC).
IX. CONCLUSIONS
This paper proposes a practical approach to the formal
analysis of security requirements based on planning guided
by the concept of suspicion. One of the advantages of the
approach presented here is that threats can be detected directly
from a requirements model, where no prior knowledge about
possible attacks is needed to perform the analysis. Instead,
the analysis derives threats automatically by posing the model
questions based on what is suspicious. The approach was illus-
trated using the EC and the decreasoner tool by performing
two experiments: one involving a simple health-care system
with a conﬁdentiality requirement and another a business
system with an integrity requirement enforced through SoD.
It showed that the more obvious way of analysing security,
by doing the traditional safety veriﬁcation would not give any
useful results: following this path analysts could be mislead
in concluding that an unsecure state could not be reached.
However, it was through more ﬂexible analysis based on
suspicion that we could obtain useful results exposing subtle
security vulnerabilities.
The main contributions of this paper are: (a) the proposal
of suspicion as a driving concept in the analysis of security
requirements, and (b) the experimental conﬁrmation that, from
a practical point of view, it is important to use ﬂexible criteria
for the security analysis in order to ﬁnd vulnerabilities in
system requirements (suspicion was proposed as basis for such
criteria). The paper also provides experimental evidence to
certain claims made in the security requirements literature: (a)
it conﬁrmed that it is important to model security requirements
together with other functional requirements because function-
ality impacts on security; (c) it conﬁrmed the existence of
security relevant phenomena that is hard or impossible to
capture as safety or liveness properties; and (d) demonstrated
the importance of formality and tool support and usefulness
of automated reachability analysis of requirements.
REFERENCES
[1] P. T. Devanbu and S. Stubblebine, “Software engineering for security:
A roadmap,” in The Future of Software Engineering.
ACM, 2000, pp.
227–239.
[2] B. W. Boehm, “Software engineering,” IEEE Transactions on Comput-
ers, pp. 1266–1241, 1976.
[3] A. van Lamsweerde, “Elaborating security requirements by construction
of intentional anti-models,” in Proc. ICSE’04, 2004, pp. 148–157.
[4] J. Rushby, “Security requireemnts speciﬁcations: How and what? (ex-
tended abstract),” in Symp. on Requirements Engineering for information
security, 2001.
[5] L. Lamport, “Proving the correctness of multiprocess programs,” IEEE
Trans. on Software Engineering, vol. 3, no. 2, pp. 125–143, 1977.
[6] B. Alpern and F. B. Schneider, “Recognizing safety and liveness,”
Distributed Computing, vol. 2, pp. 117–126, 1987.
[7] J. McLean, “A general theory of composition for a class of “possibilistic”
properties,” IEEE Trans. on Software Engineering, vol. 22, no. 1, pp.
53–66, 1996.
[8] M. R. Clarkson and F. B. Schneider, “Hyperproperties,” in Computer
Security Foundations Symposium.
IEEE, 2008.
[9] D. Denning, “An intrusion detection model,” IEEE Trans. on Software
Engineering, vol. 13, no. 2, pp. 222–232, 1987.
[10] M. Shanahan, “The event calculus explained,” in Artiﬁcial Intelligence
Today, ser. LNCS.
Springer, 1999, vol. 1600, pp. 409–430.
[11] E. T. Mueller, “Automating commonsense reasoning using the event
calculus,” Communications of the ACM, vol. 52, no. 1, pp. 113–117,
2009.
[12] J. Allen, J. Hendler, and A. Tate, Eds., Readings in planning.
Morgan
Kaufmann, 1990.
[13] E. T. Muller, “Event calculus reasoning through satisﬁability,” Journal
of Logic and Computation, vol. 14, no. 5, pp. 703–730, 2004.
[14] E. M. Clarke, O. Grumberg, and D. Peled, Model checking. MIT Press,
1999.
[15] R. J. Anderson, “A security policy model for clinical information
systems,” in Proc. of SP ’96.
IEEE, 1996.
[16] D. D. Clark and D. R. Wilson, “A comparison of commercial and
military computer security policies,” in Proc. IEEE Symp. Research in
Security and Privacy, 1987, pp. 184–194.
[17] M. J. Nash and K. R. Poland, “Some conundrums concerning separation
of duty,” in Proc. IEEE Symp. Research in Security and Privacy, 1990,
pp. 201–207.
[18] J. A. Goguen and J. Mesenguer, “Security policies and security models,”
in IEEE Symposium on Security and Privacy, 1982, pp. 11–20.
[19] N. Am´alio and G. Spanoudakis, “From monitoring templates to security
monitoring and threat detection,” in Proc. of SECURWARE ’08.
IEEE,
2008, pp. 185–192.
[20] N. Am´alio, S. Stepney, and F. Polack, “A formal template language
enabling meta-proof,” in FM 2006, ser. LNCS, vol. 4085.
Springer,
2006, pp. 252–267.
[21] N. Am´alio, “Generative frameworks for rigorous model-driven devel-
opment,” Ph.D. dissertation, Dept. Computer Science, Univ. of York,
2007.
[22] ——, “Suspicion-driven formal analysis of security requirements,” in
SECURWARE’2009.
IEEE, 2009, pp. 217–223.
[23] J. McLean, “A comment on the “basic security theorem” of bell and
lapadula,” Information Processing Letters, vol. 20, pp. 67–70, 1985.
[24] D. E. Bell and L. J. Padula, “Secure computer systems: a mathematical
model,” Mitre Corporation, Bedford, MA, Tech. Rep. MTR-2547 Vol.
II, 1996.
[25] L. Lin, B. Nuseibeh, D. Ince, and M. Jackson, “Using abuse frames to
bound the scope of security problems,” in Proc. RE ’04.
IEEE, 2004,
pp. 354–355.
355
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

13
[26] I. Alexander, “Misuse cases: Use cases with hostile intent,” IEEE
Software, vol. 20, no. 1, pp. 58–66, 2003.
[27] J. McDermott and C. Fox, “Using abuse case models for security require-
ments analysis,” in Annual computer security applications conference.
IEEE, 1999.
[28] T. Hollebeek and R. Waltzman, “The role of suspicion in model-based
intrusion detection,” in Proc. of NSPW ’04.
ACM, 2004, pp. 87–94.
[29] N. Am´alio, S. Stepney, and F. Polack, “Formal proof from UML
models,” in Proc. ICFEM 2004, ser. LNCS, vol. 3308.
Springer, 2004,
pp. 418–433.
APPENDIX
A. Sample outputs of decreasoner
This appendix presents sample outputs generated by the
decreasoner tool, while carrying out the model analysis pre-
sented in this paper.
1) Security Violation Goal (AG1): The output generated
by decreasoner for the security violation goal (AG1) of sec-
tion IV-B is:
no models
found
This means that decreasoner could not ﬁnd any solutions
for the analysis goal.
2) Suspicion Goal 1 (AG2): The following output of de-
creasoner shows one sample solution for the security violation
goal (AG1) of section IV-B is:
−−−
model
1:
0
CanAccessMD ( Jones ,
Anderson ) .
IsDoctorOf ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
0 ) .
1
+CredentialMD ( Jones ,
Anderson ,
0 ) .
+ H a s V a l i d C r e d e n tia l ( Jones ,
Anderson ) .
Happens ( SetDoctorOnLeave ( Smith ,
Jones ) ,
1 ) .
2
+OnLeave ( Jones ) .
Happens ( S e t S u b s t i t u t e D o c t o r ( Smith ,
Jones ,
Smith ) ,
2 ) .
3
+CanAccessMD ( Smith ,
Anderson ) .
+ I s S u b s t i t u t e D o c t o r ( Smith ,
Jones ) .
Happens ( AuthoriseAccess ( Smith ,
Anderson ) ,
3 ) .
4
−Ha s V a l i d C r e d e nt ial ( Jones ,
Anderson ) .
+CredentialMD ( Smith ,
Anderson ,
3 ) .
+ H a s V a l i d C r e d e n tia l ( Smith ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
4 ) .
5
+CredentialMD ( Jones ,
Anderson ,
4 ) .
+ H a s V a l i d C r e d e n tia l ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
5 ) .
6
+CredentialMD ( Jones ,
Anderson ,
5 ) .
Happens (GetMD( Smith ,
Anderson ) ,
6 ) .
7
−Ha s V a l i d C r e d e nt ial ( Smith ,
Anderson ) .
+ExposedToAt ( Smith ,
Anderson ,
6 ) .
+ G o a l S a t i s f i e d ( ) .
The
sample
above
says
that
event
AuthoriseAccess (Jones, Anderson) happens at timepoint
0, and that SetDoctorOnLeave (Smith, Jones) happens
at timepoint 1. The analysis goal is satisﬁed by event
GetMD(Smith, Anderson) that happens at timepoint 6.
The remaining 4 sample solutions generated by decreasoner
for analysis goal AG2 are as follows:
−−−
model
2:
0
CanAccessMD ( Jones ,
Anderson ) .
IsDoctorOf ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
0 ) .
1
+CredentialMD ( Jones ,
Anderson ,
0 ) .
+ H a s V a l i d C r e d e n t i a l ( Jones ,
Anderson ) .
Happens ( SetDoctorOnLeave ( Smith ,
Jones ) ,
1 ) .
2
+OnLeave ( Jones ) .
Happens ( S e t S u b s t i t u t e D o c t o r ( Jones ,
Jones ,
Smith ) ,
2 ) .
3
+CanAccessMD ( Smith ,
Anderson ) .
+ I s S u b s t i t u t e D o c t o r ( Smith ,
Jones ) .
Happens ( AuthoriseAccess ( Smith ,
Anderson ) ,
3 ) .
4
−H a s V a l i d C r e d e n t i a l ( Jones ,
Anderson ) .
+CredentialMD ( Smith ,
Anderson ,
3 ) .
+ H a s V a l i d C r e d e n t i a l ( Smith ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
4 ) .
5
+CredentialMD ( Jones ,
Anderson ,
4 ) .
+ H a s V a l i d C r e d e n t i a l ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
5 ) .
6
+CredentialMD ( Jones ,
Anderson ,
5 ) .
Happens (GetMD( Smith ,
Anderson ) ,
6 ) .
7
−H a s V a l i d C r e d e n t i a l ( Smith ,
Anderson ) .
+ExposedToAt ( Smith ,
Anderson ,
6 ) .
+ G o a l S a t i s f i e d ( ) .
−−−
model
3:
0
CanAccessMD ( Jones ,
Anderson ) .
IsDoctorOf ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
0 ) .
1
+CredentialMD ( Jones ,
Anderson ,
0 ) .
+ H a s V a l i d C r e d e n t i a l ( Jones ,
Anderson ) .
Happens ( SetDoctorOnLeave ( Jones ,
Jones ) ,
1 ) .
2
+OnLeave ( Jones ) .
Happens ( S e t S u b s t i t u t e D o c t o r ( Jones ,
Jones ,
Smith ) ,
2 ) .
3
+CanAccessMD ( Smith ,
Anderson ) .
+ I s S u b s t i t u t e D o c t o r ( Smith ,
Jones ) .
Happens ( AuthoriseAccess ( Smith ,
Anderson ) ,
3 ) .
4
−H a s V a l i d C r e d e n t i a l ( Jones ,
Anderson ) .
+CredentialMD ( Smith ,
Anderson ,
3 ) .
+ H a s V a l i d C r e d e n t i a l ( Smith ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
4 ) .
5
+CredentialMD ( Jones ,
Anderson ,
4 ) .
+ H a s V a l i d C r e d e n t i a l ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
5 ) .
6
+CredentialMD ( Jones ,
Anderson ,
5 ) .
Happens (GetMD( Smith ,
Anderson ) ,
6 ) .
7
356
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

14
−Ha s V a l i d C r e d e nt ial ( Smith ,
Anderson ) .
+ExposedToAt ( Smith ,
Anderson ,
6 ) .
+ G o a l S a t i s f i e d ( ) .
−−−
model
4:
0
CanAccessMD ( Jones ,
Anderson ) .
IsDoctorOf ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
0 ) .
1
+CredentialMD ( Jones ,
Anderson ,
0 ) .
+ H a s V a l i d C r e d e n tia l ( Jones ,
Anderson ) .
Happens ( SetDoctorOnLeave ( Jones ,
Jones ) ,
1 ) .
2
+OnLeave ( Jones ) .
Happens ( S e t S u b s t i t u t e D o c t o r ( Smith ,
Jones ,
Smith ) ,
2 ) .
3
+CanAccessMD ( Smith ,
Anderson ) .
+ I s S u b s t i t u t e D o c t o r ( Smith ,
Jones ) .
Happens ( AuthoriseAccess ( Smith ,
Anderson ) ,
3 ) .
4
−Ha s V a l i d C r e d e nt ial ( Jones ,
Anderson ) .
+CredentialMD ( Smith ,
Anderson ,
3 ) .
+ H a s V a l i d C r e d e n tia l ( Smith ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
4 ) .
5
+CredentialMD ( Jones ,
Anderson ,
4 ) .
+ H a s V a l i d C r e d e n tia l ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
5 ) .
6
+CredentialMD ( Jones ,
Anderson ,
5 ) .
Happens (GetMD( Smith ,
Anderson ) ,
6 ) .
7
−Ha s V a l i d C r e d e nt ial ( Smith ,
Anderson ) .
+ExposedToAt ( Smith ,
Anderson ,
6 ) .
+ G o a l S a t i s f i e d ( ) .
−−−
model
5:
0
CanAccessMD ( Jones ,
Anderson ) .
IsDoctorOf ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
0 ) .
1
+CredentialMD ( Jones ,
Anderson ,
0 ) .
+ H a s V a l i d C r e d en tia l ( Jones ,
Anderson ) .
Happens ( S e t S u b s t i t u t e D o c t o r ( Jones ,
Jones ,
Smith ) ,
1 ) .
2
+ I s S u b s t i t u t e D o c t o r ( Smith ,
Jones ) .
Happens ( SetDoctorOnLeave ( Jones ,
Jones ) ,
2 ) .
3
+CanAccessMD ( Smith ,
Anderson ) .
+OnLeave ( Jones ) .
Happens ( AuthoriseAccess ( Smith ,
Anderson ) ,
3 ) .
4
−Ha s V a l i d C r e d e nt ial ( Jones ,
Anderson ) .
+CredentialMD ( Smith ,
Anderson ,
3 ) .
+ H a s V a l i d C r e d en tia l ( Smith ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
4 ) .
5
+CredentialMD ( Jones ,
Anderson ,
4 ) .
+ H a s V a l i d C r e d en tia l ( Jones ,
Anderson ) .
Happens ( AuthoriseAccess ( Jones ,
Anderson ) ,
5 ) .
6
+CredentialMD ( Jones ,
Anderson ,
5 ) .
Happens (GetMD( Smith ,
Anderson ) ,
6 ) .
7
−Ha s V a l i d C r e d e nt ial ( Smith ,
Anderson ) .
+ExposedToAt ( Smith ,
Anderson ,
6 ) .
+ G o a l S a t i s f i e d ( ) .
357
International Journal on Advances in Security, vol 2 no 4, year 2009, http://www.iariajournals.org/security/

