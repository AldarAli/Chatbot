Automatically Checking Conformance on Asynchronous Reactive Systems
Camila Sonoda Gomes
Computing Department
UEL - State University of Londrina
Londrina, Brazil
Email: camilasonoda@uel.br
Adilson Luiz Bonifacio
Computing Department
UEL - State University of Londrina
Londrina, Brazil
Email: bonifacio@uel.br
Abstract—Software testing is an important issue in the software
development process to ensure the quality of products. Formal
methods have been promising on testing reactive systems, where
accuracy is mandatory and any fault can cause severe damage.
Systems of this nature are characterized by receiving messages
from the environment and producing outputs in response. One of
the biggest challenges in model-based testing is the conformance
checking of asynchronous reactive systems. The aim is to verify
if an implementation complies with its respective speciﬁcation. In
this work, we study conformance checking for reactive systems
speciﬁed by Input Output Labeled Transition Systems (IOLTS).
We develop a practical tool to check the conformance relation
between reactive models using the classical ioco relation and a
more general theory based on regular languages. In addition,
we present some testing scenarios in practical applications and
compare them to other tools from the literature using both notions
of conformance.
Keywords–model-based testing; conformance testing; automatic
veriﬁcation; reactive systems.
I.
INTRODUCTION
Automatic testing tools have been proposed to support the
development process of reactive systems that are characterized
by continuous interaction with the environment. In this setting,
systems receive external stimuli and produce outputs, asyn-
chronously, in response. In addition, systems of this nature are
usually critical and require more accuracy in their development
process, especially in the testing activity, where appropriate
formalisms must be used as the basis [1]–[3]. IOLTSs [2]–[5]
are traditional formalisms usually applied to model and test
reactive systems.
In model-based testing, an IOLTS speciﬁcation can model
desirable and undesirable behaviors of an Implementation
Under Test (IUT). The aim is to ﬁnd faults in an IUT according
to a certain fault model [1] [6] in order to show if requirements
are satisﬁed regarding its respective system speciﬁcation. The
well-established ioco conformance relation [3] requires that
outputs produced by an IUT should also be produced by its re-
spective speciﬁcation. A more recent and general conformance
relation [1] speciﬁes desirable and undesirable behaviors using
regular languages to deﬁne the testing fault model.
In this work, we address the development of an automatic
tool for conformance veriﬁcation of asynchronous reactive
systems modeled by IOLTSs. We introduce both notions of
conformance in our practical tool to provide a wider appli-
cation range compare to other tools. JTorx [7], for instance,
is a tool from the literature that also implements a con-
formance testing veriﬁcation process, but only based on the
classical ioco relation. Our tool comprises both the classical
ioco relation and also the more general conformance based
on regular languages. We also run some practical scenarios to
evaluate aspects related to the effectiveness and usability of
both conformance theories and these tools. We show scenarios
where the language-based conformance is able to ﬁnd faults
which cannot be detected by the classical ioco conformance.
We organize this paper as follows. Section II describes
the conformance veriﬁcation methods using regular languages
and the ioco relation. The practical tool which implements the
more general method of conformance checking is presented
in Section III. Some applications and a comparative study
are given in Section IV. Section V describes the comparative
analysis of tools. Section VI offers some concluding remarks.
II.
CONFORMANCE VERIFICATION
The conformance checking task can determine if an IUT
complies with its speciﬁcation when both are modeled by
appropriate formalisms. The classical ioco conformance re-
lation [3] [5] establishes the compliance between IUTs and
speciﬁcations when they are speciﬁed by IOLTS [2]–[5].
An IOLTS is a variation of the Labeled Transition Systems
(LTS) [8]–[11] with the partitioning of input and output labels.
Deﬁnition 1: An IOLTS S is given by (S, s0, LI, LU, T)
where: S is the set of states; s0 ∈ S is the initial state; LI is a
set of input labels; LU is a set of output labels; L = LI ∪ LU
and LI ∩ LU = ∅; T ⊆ S × (L ∪ {τ}) × S is a ﬁnite set of
transitions, where the internal action τ /∈ L; and (S, s0, L, T)
is the underlying LTS associated with S.
A transition (s, l, s′) ∈ T indicates that from the state s ∈ S
with the label l ∈ (L ∪ {τ}) the state s′ ∈ S is reached in an
LTS/IOLTS model. When we have a transition (s, τ, s′) ∈ T
with an internal action, it means that an external observer can
not see the movement from state s to state s′ in the model.
We may also have the notion of quiescent states. If a state
s of an IOLTS has no output x ∈ LU and internal action τ
deﬁned on it, we say that s is quiescent [3]. When a state s is
quiescent we then add a transition (s, δ, s), where δ /∈ Lτ. Note
that we denote L ∪ {τ} by Lτ in order to ease the notation.
In a real scenario of black-box testing where an IUT sends
messages to a tester and receives back responses, quiescence
indicates that an IUT could no longer respond to the tester, or
it has timed out, or even it is simply slow.
We also need to deﬁne the semantics of LTS/IOLTS
models. But ﬁrst, we introduce the notion of paths.
17
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

Deﬁnition 2: ( [1]) Let S = (S, s0, L, T) be a LTS and
p, q ∈ S. Let σ = l1, · · · , ln be a word in L⋆
τ. We say that σ
is a path from p to q in S if there are states ri ∈ S, and labels
li ∈ Lτ, 1 ≤ i ≤ n, such that (ri−1, li, ri) ∈ T, with r0 = p
and rn = q. We say that α is an observable path from p to q
in S if we remove the internal actions τ from σ.
A path can also be denoted by s
σ−→ s′, where the behavior
σ ∈ L⋆
τ starts in the state s ∈ S and reaches the state s′ ∈ S.
An observable path σ, from s to s′, is denoted by s
σ=⇒ s′.
We can also write s
σ−→ or s
σ=⇒ when the reached state is not
important.
Paths that start from state s are called paths of s, and the
semantics of an LTS model is given by the paths that start from
their initial state. Now we give the semantics of LTS models.
Deﬁnition 3: ( [1]). Let S = (S, s0, L, T) be a LTS and
s ∈ S: (1) The set of paths of s is given by tr(s) = {σ|s
σ−→}
and the set of observable paths of s is otr(s) = {σ|s
σ=⇒}.
(2) The semantics of S is tr(s0) or tr(S) and the observable
semantics of S is otr(s0) or otr(S).
The semantics of an IOLTS is deﬁned by the semantics of the
underlying LTS.
Conformance checking can be established between IOLTS
models over the ioco relation. When we apply input stimuli to
both a speciﬁcation and an IUT, if the IUT produces outputs
that are also deﬁned in the speciﬁcation, we say that the IUT
conforms to the speciﬁcation. Otherwise, we say that they do
not conform [3].
Deﬁnition 4: ( [3]). Let S = (S, s0, LI, LU, T) be a spec-
iﬁcation and I = (Q, q0, LI, LU, R) be an IUT. We say that
I ioco S if, and only if, out(q0 after σ) ⊆ out(s0 after σ)
for all σ ∈ otr(S), where s after σ = {q|s
σ=⇒ q} for all
s ∈ S and all σ ∈ otr(S), and the function out(V ) = S
s∈V
{l ∈
LU|s
l=⇒}.
The more general conformance relation is established over
regular languages. This approach provides a wider fault cover-
age for both LTS and IOLTS models. Basically, desirable and
undesirable behaviors are speciﬁed by regular languages, D
and F, respectively. Given an implementation I, a speciﬁcation
S, and regular languages D and F, I complies with S
according (D, F), i.e, I
confD,F
S if, and only if, no
undesirable behavior of F is observed in I and is speciﬁed
in S, and all desirable behaviors of D are observed in I and
also are speciﬁed in S.
Deﬁnition 5: ( [1]) Let a set of symbols L, and the
languages D, F ⊆ L⋆ over L. Let S and I, LTS models,
with L as their set of labels, IconfD,F S if, and only if: (1)
σ ∈ otr(I) ∩ F, then σ /∈ otr(S); and (2) σ ∈ otr(I) ∩ D,
then σ ∈ otr(S).
We remark that an ordinary LTS can be checked using the
language-based approach using only the notion of desirable
and undesirable behaviors. In this case, we do not need to
partition the alphabet into input and output labels, as required
by IOLTS models and crucial for ioco relation. The next
proposition states the language-based conformance checking.
Proposition 1: ( [1]). Let the speciﬁcation S and the IUT
I be LTS models over L, and the languages D, F ⊆ L⋆ over
L. We say that I confD,F S if, and only if, otr(I) ∩ [(D ∩
otr(S))∩(F ∩otr(S))] = ∅, where otr(S) is the complement
of otr(S) given by otr(S) = L⋆ − otr(S).
On the other hand, the next lemma shows that the more
general notion of conformance relation given in Deﬁnition 5
restrains the classical ioco conformance relation.
Lemma 1: (
[1]).
Let
a
speciﬁcation
S
=
(S, s0, LI, LU, T) and an IUT I
=
(Q, q0, LI, LU, R)
be IOLTS models, we have that I ioco S if, and only if,
I confD,F S when D = otr(S)LU e F = ∅.
Clearly, the ioco relation can be given by the more general
conformance relation using regular languages.
The conformance checking can be obtained using the
automata theory [12] as proposed by Bonifacio and Moura [1].
We transform LTS/IOLTS models into Finite State Automa-
tons (FSAs) and apply union, intersection, and complement
operations over regular languages. An FSA is formally given
by A = (S, s0, L, T, F), where S = (S, s0, L, T) is the
underlying LTS associated with A. Note that the set of ﬁnal
states in A is deﬁned by all states of S, i.e., F = S. Since
the semantics of an FSA is given by the language it accepts,
a language R ⊆ L⋆ is regular if there is an FSA M such
that L(M) = R, where L is an alphabet [12]. Hence, we
can effectively construct the automatons AD and AF such
that D and F are regular languages and D = L(AD) and
F = L(AF ).
The notions of the test case and test suite according to
formal languages are given as follows.
Deﬁnition 6: ( [1]). Let a set of symbols L, the test suite
T over L is a language, where T ⊆ L⋆, so that each σ ∈ T is
a test case.
If the test suite is a regular language, then there is an FSA A
that accepts it, such that the ﬁnal states of A are fault states.
The set of undesirable behaviors, deﬁned by these fault states,
is called by fault model of S [1].
A complete test suite can be obtained from an IOLTS
speciﬁcation S and a pair of languages (D, F) using the
Proposition 1. The test suite T = [(D∩otr(S))∪(F ∩otr(S))]
is able to identify the absence of desirable behaviors speciﬁed
by D and the presence of undesirable behaviors speciﬁed by
F in the speciﬁcation S. We declare that an implementation I
complies with a speciﬁcation S if there is no test case of the
test suite T that is also a behavior of I [1].
We also provide the determinization of models which is
useful in this method. Therefore, from a deterministic IOLTS
S we can obtain the automaton A1 induced by S that is
also deterministic. We write L(A1) = otr(S). Hence, we can
effectively obtain an FSA A2 such that L(A2) = L(AF ) ∩
L(A1) = F ∩ otr(S). Also, consider the FSA B1 obtained
from A1 by reversing its set of ﬁnal states, that is, a state s is
a ﬁnal state in B1 if, and only if, s is not a ﬁnal state in A1.
Clearly, L(B1) = L(A1) = otr(S). We can now effectively get
an FSA B2 such that L(B2) = L(AD)∩L(B1) = D ∩otr(S).
Since A2 and B2 are FSAs, we can construct an FSA C such
that L(C) = L(A2) ∪ L(B2), where L(C) = T. We can
conclude that when D and F are regular languages and S
is a deterministic speciﬁcation, then a complete FSA T can
be constructed such that L(T ) = T.
Next proposition states an algorithm with a polynomial
time complexity for the language-based veriﬁcation.
18
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

Proposition 2: ( [1]) Let S and I be the deterministic
speciﬁcation and implementation IOLTSs over L with nS and
nI states, respectively. Let also |L| = nL. Let AD and AF be
deterministic FSAs over L with nD and nF states, respectively,
and such that L(AD) = D and L(AF ) = F. Then, we can
effectively construct a complete FSA T with (nS + 1)2nDnF
states, and such that L(T ) is a complete test suite for S and
(D, F). Moreover, there is an algorithm, with polynomial time
complexity Θ(n2
SnInDnF nL) that effectively checks whether
IconfD,F S holds.
Next, we obtain a similar result for ioco using Lemma 1.
Theorem 1: ( [1]) Let S and I be deterministic speciﬁ-
cation and implementation IOLTSs over L with nS and nI
states, respectively. Let L = LI ∪ LU, and |L| = nL. Then,
we can effectively construct an algorithm with polynomial time
complexity Θ(nSnInL) that checks whether I ioco S holds.
III.
A TESTING TOOL FOR REACTIVE SYSTEMS
In this section, we present the automatic checking con-
formance tool Everest (conformancE Veriﬁcation on tEsting
ReactivE SysTems) [13]. Our tool supports the more general
notion of conformance based on regular languages and also the
classical ioco relation when testing reactive systems modeled
by LTS/IOLTS. Everest has been developed in Java [14] using
the Swing library [15], providing a yielding and friendly
usability experience through a graphical interface.
Some features provided by the Everest tool are: (i) check
conformance based on regular languages and ioco relation;
(ii) describe desirable and undesirable behaviors using reg-
ular expressions; (iii) specify formal models in Aldebaran
format [16]; (iv) generate test suites when non-conformance
verdicts are obtained; (v) provide state paths, i.e, the sequence
of states induced by a test case over the IUT and speciﬁcation;
and (vi) allow the graphical representation of the models.
The tool’s architecture is organized into four modules as
depicted in Figure 1. The modules are given by rectangles and
Figure 1. Tool’s Architecture
the data ﬂow between them is denoted by the arrows. The
input data and the output results are represented by ellipses.
The
View
module
implements
an
intuitive
graphi-
cal
interface
with
three
different
views:
conﬁguration;
ioco conformance; and language-based conformance.
The Parser module reads the input data with the de-
scriptions of IUT and speciﬁcation, and turn them into data
structures to internally represent their respective models. The
Automaton Construction module transforms the LTS/IOLTS
models into their respective ﬁnite automatons which, in turn,
are used to construct the fault model together with the automa-
tons obtained by means of regular languages.
The Conformance Veriﬁcation module provides all neces-
sary operations over regular languages such as union, inter-
section, and complement [12]. This module also constructs
the ﬁnite automaton that represents the complete test suite
and comprises both conformance veriﬁcation techniques. The
conformance checking processes and their essential algorithms
are described in [17].
Everest deﬁnes a standard representation of LTS/IOLTS
models over the Aldebaran [18] format as a set of transitions.
Figure 2a presents an example of Aldebaran format and
Figure 2b shows its respective IOLTS model. The header
des(s0, 9, 4) indicates the initial state, the number of transi-
tions and the number of states. The set of transitions follows
the header line by line, where each transition (s, a, q) is deﬁned
such that s is the source state, a is the label associated to the
transition and q is the target state. Input and output labels can
be indicated by the special markers “?” and “!”, respectively.
But we remark that the special markers just ease the graphical
visualization. Everest constructs, internally, a list of input and
output labels even if these labels have the special markers or
they are settled by the sets of input and output, LI and LU,
respectively (Figure 2b).
des (s0,9,4)
(s0,?a,s1)
(s0,?b,s3)
(s1,?b,s2)
(s1,!x,s2)
(s1,?a,s3)
(s2,?b,s2)
(s2,!x,s3)
(s3,?b,s0)
(s3,?a,s3)
(a) S in Aldebaran format
s0
s3
s1
s2
a
b
a
b, x
x
b
b
a
(b) IOLTS speciﬁcation S
Figure 2. An example of Aldebaran ﬁle format
In Figure 3, we can observe the conﬁguration view, where
speciﬁcation and the implementation models are selected, in
the Aldebaran format. When the model type is an LTS, the
parameters Label, Input labels, and Output labels are
omitted. If IOLTS models are given then we need to inform
how the input/output labels are distinguished (ﬁeld Label),
informing below the Input and Output labels or the special
markers are assumed in the Aldebaran ﬁles, as in Figure 3.
Figure 4 presents the interface for ioco conformance veriﬁ-
cation. Note that in both conformance veriﬁcation views all in-
formation from the conﬁguration view remains visible to ease
the reference. Also, the buttons view model and view IUT
allow the graphical visualization of the implementation and
speciﬁcation models. The verdict is displayed by clicking the
button V erify. In case of non-conformance, the tool presents a
set of paths induced by the test suite that detects the faults. The
tool also informs incorrectly ﬁlled ﬁelds in the conﬁguration
view in the text box Warnings.
19
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

Figure 3. Conﬁguration view
Figure 4. ioco veriﬁcation view
In Figure 5, we present the language-based conformance
veriﬁcation view. Desirable and Undesirable behaviors must
Figure 5. Language-based veriﬁcation view
be speciﬁed by regular expressions. When no regular expres-
sion is provided the Kleene closure [12] is assumed over the
alphabet to identify faults when models are not isomorphic.
After the compliance check, the verdict is displayed similarly
to the ioco veriﬁcation conformance.
IV.
PRACTICAL APPLICATION
This section describes some practical testing scenarios
applied to the Everest and JTorx tools. Let S be the IOLTS
speciﬁcation of Figure 2b and let R and Q be implementa-
tions candidates as depicted in Figures 6a and 6b. Also, let
LI = {a, b} and LU = {x} be the input and output alphabets,
respectively. All models here are deterministic [19] [20] but we
remark that our tool also deals with non-deterministic models.
q0
q3
q1
q2
a
b
a
b, x
a
b
b,x
a
(a) Implementation R
q0
q3
q1
q2
a
b
a
b, x
a,x
b
b
a
(b) Implementation Q
Figure 6. IOLTS Models
In the ﬁrst scenario, we check if IUT R conforms to
speciﬁcation S. Everest tool has returned a non-conformance
verdict using ioco relation and generated the test suite
{b, aa, ba, aaa, ab, ax, abb, axb}. The subset of test cases
{b, aa, ba, aaa} induces state paths from s0 to s3 in S and
from q0 to q3 in R, where the output x is produced by R but
S does not. Note that s3 in S is a quiescent state whence no
output is deﬁned on it. The subset {ab, ax, abb, axb} induces
state paths to state s2 in S and q2 in R. In this case, the
output δ is produced by IUT R whereas S produces x. That
is, a fault is detected according to ioco relation. Note that both
tools modify the formal models by adding self-loops labeled
with δ [21] on quiescent states.
The same scenario has been also applied to JTorx tool,
resulting in the same verdict, as expected, but it generates
the test suite {b, ax, ab}. Notice that the test suite generated
by JTorx is a subset of the test suite generated by Everest.
That is, Everest shows all test cases and associated state paths
related to each fault according to a transition cover criteria
over the speciﬁcation, differently from JTorx which does not
apply transition coverage to test suite derivation. Everest also
allows state coverage as criteria to obtain the test suite using
only one path per fault when checking conformance over an
IUT. But, in this case, we reduce not only the number of test
cases, but also the information that might be useful to aid the
tester in the fault mitigation process.
In the second scenario (Figure 5), when checking the IUT
Q against the speciﬁcation S, the language-based conformance
veriﬁcation was able to detect a fault that was not detected by
the ioco conformance relation (Figure 4). We have obtained
the fault model using the regular expressions D = (a|b)∗ax
and F = ∅. Language D clearly expresses behaviors that
ﬁnish with a stimulus a followed by an output x produced
in response. Since the only complete test suite is given by
[(D ∩ otr(S)) ∪ (F ∩ otr(S))] and F ∩ otr(S) = ∅, so we
check the condition D ∩ otr(S) ̸= ∅, i.e., a fault is detected
when behaviors of D are not present in S. Everest then results
in a verdict of non-conformance and produces the test suite
{ababax, abaabax} reaching a fault that is not detected by
JTorx using the ioco relation.
The speciﬁcation S (Figure 2b) and the candidate imple-
mentation Q (Figure 6b) are IOLTS models which, after being
20
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

converted into underlying automatons respectively, AS and
AQ, have all their states deﬁned as ﬁnal states. Figure 7a
displays the complement automaton of the speciﬁcation.
The ioco conformance veriﬁcation ﬁrst obtains the un-
derlying automata, AS and AQ, from the IOLTS models.
The automaton D (Figure 7b) is constructed to obtain the
fault model (Figure 7c) by the intersection of the language
otr(S)Lu, which is captured by D, and complement language
of the speciﬁcation (Figure 7a). The automaton that represents
the test suite (Figure 7d) is obtained by the intersection
between the fault model and the AQ. Since the resulting
automaton has no ﬁnal state, the verdict between models is
that I ioco conforms to S.
s0
s3
s1
s2
c
a
b
x
a
b, x
x
b
a
b
x
a
a, b, x
(a) Automaton AS
s0
s3
s1
s2
f
a
b
x
a
b, x
x
b
b
a
x
(b) Automaton D
s0s0
s3s3
s1s1
s2s2
cf
a
b
x
a
b, x
x
b
b
a
x
(c) Fault model automaton
q0s0s0
q3s3s3
q1s1s1
q2s2s2
a
b
a
b, x
b
x
b
a
(d) Test suite automaton
Figure 7. Automatons: ioco conformance veriﬁcation
In language-based conformance veriﬁcation, the underlying
automatons, AS and AQ, are also obtained from the IOLTS
models depicted in Figures 2b and 6b, respectively. From
the regular expression (a|b)∗ax we obtain the automaton
(Figure 8a) that accepts the respective language. Since the
fault model is given by [D ∩ otr(S)] ∪ [(F ∩ otr(S))] and no
undesirable behavior F is deﬁned, then F ∩ otr(S) = ∅, and
the fault behaviors are reduced to D ∩ otr(S). The automaton
that represents the fault model is illustrated in Figure 8b.
The automaton that represents the test suite is illustrated in
Figure 8c. Note that this automaton contains a ﬁnal state,
indicating that the words accepted by the automaton are part
of the test suite that reveals the faults and, consequently, the
non-conformity between the models. The test suite generated
by the Everest tool is {ababax, abaabax}.
Also, we have performed a practical study over a simple
version, but a real scenario, of a vending machine. The
IOLTS speciﬁcation N of the vending machine is depicted
in Figure 9a. Now consider an IUT P of this vending ma-
chine as given in Figure 9b. The input alphabet is given by
LI = {1, 3, 5} which means input stimuli are received from
the environment. In this case, labels 1, 3, 5 represent coins
provided by users according to the desired drinks. On the other
d0
d1
d2
b
a
a
x
b
(a) Automaton D
s0d0
s1d1
s3d0
s3d1
s2d0
s2d2
cd2
cd1
cd0
a
b
a
b
x
a
b
a
b
x
b
a
a
b
x
a
b
(b) Fault model automaton
s0d0q0
s1d1q1
s2d2q2
s3d0q3
s3d1q3
cd1q3
s2d0q2
cd0q2
cd1q1
cd0q0
cd0q3
cd2q2
a
b
a
b
x
b
a
a
b
a
b
a
b
a
b
a
b
a
x
b
a
b
(c) Test suite automaton
Figure 8. Automatons: language-based conformance veriﬁcation
hand, the output alphabet is deﬁned by LU = {cof, tea}, that
is, the vending machine gives back to the user the requested
drink, a coffee or a tea.
s1
s0
s2
5
1
cof
tea
(a) Speciﬁcation N
q1
q0
q2
5
1,3
cof
tea
(b) IUT P
Figure 9. Vending machine
When checking whether N conforms to P using the
language-based method, Everest was able to detect faults
that were not detected by JTorx. The desirable behaviors are
expressed by D = 3cof and the undesirable behaviors are
speciﬁed by F = 1(cof|tea). The former expression says that
after a user gives the coin 3 the vending machine is supposed
to give back a coffee. Similarly, the undesirable expression
establishes that after a user gives the coin 1 the vending
machine should return neither a coffee nor a tea.
Everest then results in a non-conformance verdict between
N and P, producing the test suite {1cof, 3cof}. The test case
1cof is generated because N and P specify that after a coin
1 is provided by the user the vending machine must return a
cof which, in turn, is undesirable according to F. The test case
3cof reaches a fault because the desirable behavior requires the
21
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

vending machine gives back a coffee if a coin 3 is inserted into
the vending machine. However, this property is not speciﬁed
on N and the IUT P allows such situation.
V.
COMPARATIVE ANALYSIS OF TOOLS
In this section, we perform a comparative analysis between
Everest and JTorx. Both tools implement the conformance
veriﬁcation between a speciﬁcation and an IUT based on
ioco theory [3], but only Everest implements the more general
conformance relation based on regular languages. Table I
summarizes the comparative analysis.
TABLE I. COMPARATIVE ANALYSIS
JTorx
Everest
Conformance veriﬁcation
ioco
X
X
Language-based
-
X
Restrictions over the models
Support underspeciﬁed models
X
X
Require input-enabledness
X∗
-
Support quiescence
X
X
∗ JTorx adds self-loops with input labels
The classical ioco relation imposes some restrictions and
properties over the models, for instance, underspeciﬁed mod-
els [22] are not allowed on IUT models. In contrast, the
language-based conformance relation can deal with speciﬁca-
tion and implementation models that are not input-enabled.
Everest implements the language-based conformance relation
and also the classical ioco relation, which is reduced from the
former. We remark that both relations developed in Everest do
not require any of these restrictions over the formal models
(See Lemma 1). But JTorx requires, for instance, the input
enabledness over the IUT models. To overcome the problem of
underspeciﬁed models, JTorx adds self-loops with input labels
that are not deﬁned in the states. However, such changes can
result in unreliable verdicts since transitions are added to the
model, modifying its original behavior. Everest treats under-
speciﬁed models with no change and keeping the reliability
over the original behavior of the models.
Another important issue over underspeciﬁed models is
quiescence. In this case, Jtorx and Everest add self-loops
labeled by δ on states that no output is speciﬁed for both
speciﬁcation and implementation models.
VI.
CONCLUSION
Testing of reactive systems is an important and complex
activity in the development process for systems of this nature.
The complexity of such systems and, consequently, the com-
plexity of the testing task requires high costs and resources in
software development. Therefore, automation and accuracy on
the testing activity have become essential in this process. Sev-
eral studies have addressed the testing of reactive systems [23]
[24] using model-based testing. More precisely, many works
have focused on the conformance checking [1]–[3] between
IUTs and speciﬁcations to guarantee more reliability.
In this work, we have developed an automatic tool for
checking conformance on asynchronous reactive systems. We
have implemented not only the classical ioco theory but also
the more general language-based relation for checking confor-
mance between IOLTS models. We observe by the practical
applications that Everest could ﬁnd faults using the language-
based conformance veriﬁcation process which was not detected
by JTorx using the classical ioco relation. Everest then gives us
an advantage with a wider range of testing scenarios and a full
fault detection coverage according to a deﬁned fault model.
There are several tools from the literature that implement
conformance checking based on ioco relation and its varia-
tions [18] [20] [22] [25]–[28]. But, we are not aware of any
other tool that implements a different conformance notion,
such as the language-based relation. So, the main contribution
of this work is the design of Everest tool and its more
ﬂexible conformance checking, in addition to its algorithms,
the intuitive graphical interface, the practical applications and
comparative studies.
A new module of Everest tool is already being developed to
provide the test suite generation in a black-box setting. We also
intend to perform more experiments using real-world problems
with Everest and similar tools from the literature. In this way,
we may give a more precise analysis regarding conformance
checking for asynchronous reactive models, usability, and
performance of these tools.
REFERENCES
[1]
A. L. Bonif´acio and A. V. Moura, “Complete test suites for input/output
systems,” CoRR, vol. abs/1902.10278, 2019, accessed on: 2019-06.
[Online]. Available: http://arxiv.org/abs/1902.10278
[2]
A. da Silva Sim˜ao and A. Petrenko, “Generating complete and ﬁnite
test suite for ioco: Is it possible?” in Proceedings Ninth Workshop
on Model-Based Testing, MBT 2014, Grenoble, France, 6 April
2014., 2014, pp. 56–70, accessed on: 2019-07. [Online]. Available:
https://doi.org/10.4204/EPTCS.141.5
[3]
J. Tretmans, Model Based Testing with Labelled Transition Systems.
Berlin, Heidelberg: Springer Berlin Heidelberg, 2008, pp. 1–38,
accessed on: 2019-07. [Online]. Available: https://doi.org/10.1007/
978-3-540-78917-8 1
[4]
B. K. Aichernig and M. Tappler, “Symbolic input-output conformance
checking for model-based mutation testing,” Electronic Notes in
Theoretical Computer Science, vol. 320, 2016, pp. 3 – 19, accessed on:
2019-06. [Online]. Available: http://www.sciencedirect.com/science/
article/pii/S1571066116000037
[5]
J. Tretmans, “Testing concurrent systems: A formal approach,” in
CONCUR’99 Concurrency Theory, J. C. M. Baeten and S. Mauw, Eds.
Berlin, Heidelberg: Springer Berlin Heidelberg, 1999, pp. 46–65.
[6]
B. K. Aichernig, M. Weiglhofer, and F. Wotawa, “Improving fault-
based conformance testing,” Electronic Notes in Theoretical Computer
Science, vol. 220, no. 1, 2008, pp. 63 – 77, proceedings of the
Fourth Workshop on Model Based Testing (MBT 2008). Accessed on:
2019-08. [Online]. Available: http://www.sciencedirect.com/science/
article/pii/S157106610800443X
[7]
“JTorX
a
tool
for
model-based
testing,”
https://fmt.ewi.utwente.nl/redmine/projects/jtorx/wiki/,
accessed
on:
2018-06.
[8]
G. Tretmans, “A formal approach to conformance testing,” Ph.D.
dissertation, University of Twente, 1992.
[9]
P. Daca, T. A. Henzinger, W. Krenn, and D. Nickovic, “Compositional
speciﬁcations for ioco testing,” in 2014 IEEE Seventh International
Conference on Software Testing, Veriﬁcation and Validation, March
2014, pp. 373–382.
[10]
F. Zeng, Z. Chen, Q. Cao, and L. Mao, “Research on method of object-
oriented test cases generation based on uml and lts,” in 2009 First
International Conference on Information Science and Engineering, Dec
2009, pp. 5055–5058.
[11]
E. G. Cartaxo, F. G. O. Neto, and P. D. L. Machado, “Test case
generation by means of uml sequence diagrams and labeled transition
systems,” in 2007 IEEE International Conference on Systems, Man and
Cybernetics, Oct 2007, pp. 1292–1297.
22
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

[12]
M. Sipser, Introduction to the Theory of Computation, 2nd ed.
Course
Technology, 2006.
[13]
C. Sonoda, “Everest website,” https://everest-tool.github.io/everest-site,
accessed on: 2019-07.
[14]
Oracle,
“Java
se
development
kit
8,”
http://www.oracle.com/
technetwork/pt/java/javase/, accessed on: 2019-07.
[15]
——, “Package javax swing,” https://docs.oracle.com/javase/7/docs/api/
javax/swing/package-summary.html, accessed on: 2019-06.
[16]
“AUT manual page,” https://cadp.inria.fr/man/aut.html, accessed on:
2019-08.
[17]
C.
S.
Gomes
and
A.
L.
Bonif´acio,
“Automatically
checking
conformance
on
asynchronous
reactive
systems,”
CoRR,
vol.
abs/1905.08914, 2019, accessed on: 2019-08. [Online]. Available:
http://arxiv.org/abs/1905.08914
[18]
J. Calam´e, “Speciﬁcation-based test generation with tgv,” Software
Engineering Notes, 2005.
[19]
J. E. Hopcroft, R. Motwani, and J. D. Ullman, Introduction to Automata
Theory, Languages, and Computation (3rd Edition). Boston, MA, USA:
Addison-Wesley Longman Publishing Co., Inc., 2006.
[20]
B. L. Mark Utting, practical model-based testing a tools approach,
1st ed.
Elsevier, 2007.
[21]
G. Tretmans, Test Generation with Inputs, Outputs and Repetitive
Quiescence, ser. CTIT technical report series.
Netherlands: Centre for
Telematics and Information Technology (CTIT), 1996, no. TR-CTIT-
96-26, cTIT Tecnnical Report Series 96-26.
[22]
A. Belinfante, “Jtorx: Exploring model-based testing,” Netherlands, 9
2014, iPA Dissertation series no. 2014-09.
[23]
B. K. Aichernig, E. J¨obstl, and S. Tiran, “Model-based mutation testing
via symbolic reﬁnement checking,” Science of Computer Programming,
vol. 97, 2015, pp. 383 – 404, special Issue: Selected Papers from
the 12th International Conference on Quality Software (QSIC 2012).
[Online].
Available:
http://www.sciencedirect.com/science/article/pii/
S0167642314002329
[24]
S. Anand et al., “An orchestrated survey of methodologies for automated
software test case generation,” Journal of Systems and Software, vol. 86,
no. 8, 2013, pp. 1978 – 2001, accessed on: 2019-08. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0164121213000563
[25]
W. Mostowski, E. Poll, J. Schmaltz, J. Tretmans, and R. Wich-
ers Schreur, “Model-Based Testing of Electronic Passports,” in Formal
Methods for Industrial Critical Systems, M. Alpuente, B. Cook, and
C. Joubert, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2009,
pp. 207–209.
[26]
A. Belinfante, L. Frantzen, and C. Schallhart, 14 Tools for Test
Case Generation.
Berlin, Heidelberg: Springer Berlin Heidelberg,
2005,
pp.
391–438,
accessed
on:
2019-06.
[Online].
Available:
https://doi.org/10.1007/11498490 18
[27]
P. Bhateja, “A tgv-like approach for asynchronous testing,” in
Proceedings of the 7th India Software Engineering Conference, ser.
ISEC ’14.
New York, NY, USA: ACM, 2014, pp. 13:1–13:6, accessed
on: 2018-05. [Online]. Available: http://doi.acm.org/10.1145/2590748.
2590761
[28]
C. Jard and T. J´eron, “Tgv: theory, principles and algorithms,”
International Journal on Software Tools for Technology Transfer,
vol. 7, no. 4, Aug 2005, pp. 297–315, accessed on: 2019-08. [Online].
Available: https://doi.org/10.1007/s10009-004-0153-x
23
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-752-8
ICSEA 2019 : The Fourteenth International Conference on Software Engineering Advances

