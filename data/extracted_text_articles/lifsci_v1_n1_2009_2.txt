A Stratiﬁed Beta-Gaussian Finite Mixture Model
for Clustering Genes With Multiple Data Sources
Xiaofeng Dai
Department of Signal Processing,
Tampere University of Techonology
Tampere, Finland
Email: xiaofeng.dai@tut.ﬁ
Harri Lähdesmäki
Department of Signal Processing,
Tampere University of Technology
Tampere, Finland
Helsinki University of Technology
Department of Information and Computer Science
Helsinki, Finland
Email: harri.lahdesmaki@tut.ﬁ
Olli Yli-Harja
Department of Signal Processing,
Tampere University of Techonology
Tampere, Finland
Email: yliharja@cs.tut.ﬁ
Abstract—This paper presents a stratiﬁed mixture model based
clustering framework, sBGMM. It is an extension of one of our
previously developed models, BGMM (beta-Gaussian mixture
model), which can not only cluster genes based on beta and
Gaussian distributed data but also convert information from a
third data source to the priors based on which genes are pre-
partitioned into several groups. By assigning genes in the same
pre-group the same prior probabilities of belonging to a certain
cluster, sBGMM transfers information from a third data source
into the results and allows a high level of ﬂexibility in the choice
of the third data source. Different from data sources that are
modeled as the component of the joint model, information used
for prior construction can be from any sources and of any level of
sparsity. Besides the extremely ﬂexible choice of prior, sBGMM
can also be extended to other parametric distributed data, which
adds even more ﬂexibility to this model-based clustering frame-
work. We developed an expectation maximization algorithm for
jointly estimating the parameters of sBGMM, and propose to
tackle model selection problem by approximation based model
selection criteria, where four well-known penalized methods,
Akaike information criterion, a modiﬁed Akaike information
criterion, the Bayesian information criterion, and the integrated
classiﬁcation likelihood-Bayesian information criterion, are tested
and compared. Both simulation and real case study indicate
that information from different data sources can reinforce each
other and utilizing information from one data source to stratify
the model can improve the clustering accuracy especially when
the noise is comparatively high in both beta and Gaussian
distributed data. Applications with full set of real mouse gene
expression data (modeled as Gaussian distribution) and protein-
DNA binding probabilities (modeled as beta distribution) not only
yield more biologically reasonable results compared to its non-
stratiﬁed version, but also discovered the relationship between
two set of genes and eight TFs, which are all likely to be involved
in Myd88-dependent Toll-like receptor 3/4 (TLR-3/4) signaling
cascades.
Keywords—stratiﬁed ﬁnite mixture model; gene clustering;
multiple data fusion; prior
I. INTRODUCTION
Gene clustering has become one of the most explosively
expanding tools for genome-level data analysis, such as in-
ferring gene functions [34] and identifying genes involved
in a particular molecular pathway [28]. Numerous compu-
tational methods have been developed for it, among which
the most prevalent ones include hierarchical clustering [9], K-
means [15], and Self-Organizing Maps [32]. These approaches
are generally applied to gene expression data [16], which al-
though have demonstrated their usefulness in applications [29],
are over dependent on the similarity among gene expression
patterns, rendering the results less accurate due to the varied
transcriptional coherence in response to diverse environmental
stresses and vulnerable to system or experimental error be-
cause of using single data source alone and no reinforcement
from other data sources.
Multiple data fusion has been widely applied to many prob-
lems in the ﬁeld of system biology, assuming that information
from different data sources reinforce each other and can offer
us a general view of the system from different perspectives.
Nowadays, as more and more different biological data sources,
such as protein-DNA binding probabilities, protein-protein
interactions, evolutionary conservations histone modiﬁcations
and methylation information, et cetera, are becoming avail-
able since new experimental techniques keep emerging, it is
possible to cluster genes based on multiple data sources and
promising to group genes based on multiple criteria. Therefore,
how to efﬁciently utilize heterogeneous data sources has
become one of the most challenging problems in this ﬁeld.
Gene clustering method can be roughly classiﬁed into three
categories, which are heuristic, iterative relocation and model-
based methods [11]. Common restrictions of using methods
that belong to the ﬁrst two categories are the determination of
the number of clusters and handling with the outliers, which
however can be easily solved by model-based methods. Due
to the clear deﬁnition of what a cluster is, a subpopulation
with a certain distribution, model-based methods handle with
outliers by recasting it as the model selection problem and
adding one or more components, respectively [11], [17], [24].
Also, model-based method beats the ﬁrst two approaches in
its statistical nature [11].
In the realm of standard model based gene clustering, be-
sides the most commonly used statistically method, Gaussian
mixture model (GMM) [3], [10], [12], [18], [20], [24], [31],
[37], mixture models of some other distributions have also
14
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

been developed to solve various problems, such as using a two-
component beta mixture model (BMM) to cluster correlation
coefﬁcients [17] and applying multinomial models to high
dimensional text clustering [22], [36]. While most works
on model based methods are devoted to exploring novel
applications or improving the computational complexity of the
algorithm regardless of the information source, [25] proposed
a GMM that can incorporate priors beyond expression data by
allowing genes that share the same biological function to have
an equal prior probability while differ from the other genes in
gene clustering.
Inspired by the promising results brought out by stratifying
the priors in GMM [25] and the obvious superiority of data
fusion over using single data sources alone, we developed a
stratiﬁed joint mixture model, sBGMM, to cluster genes based
on beta and Gaussian distributed data and stratify the prior
according to a third data source. This algorithm differs from
our previously developed joint mixture model, BGMM [7], in
its utilization of three data sources by converting information
from a third one to the prior of the joint mixture model.
Also, it exceeds the work of [25] by integrating multiple data
sources. Moreover, besides the ﬂexible framework inherited
from BGMM, sBGMM assigns more freedom to the choice
of prior, which is not restricted to any distribution or limited
to the completeness of the data.
We have previously developed an approximated (optimize
the complete log-likelihood instead of its expectation) expecta-
tion maximization (EM) algorithm for BMM, and a hybrid EM
algorithm, where EM for beta and Gaussian distributions are
approximated and standard version, respectively, for sBGMM.
Encouraged by the ﬂexibility provided by sBGMM and its
excellent simulation performance shown in [1], we further
extend the hybrid EM for sBGMM to the standard EM in
this paper, and test it under more simulation scenarios and
with real data.
Many statistical methods can be applied to solve the model
selection problem, where four well known penalized likelihood
criteria (which belong to approximation-based model selection
criteria [30]), Akaike information criterion (AIC) [2], [4],
modiﬁed AIC (AIC3) [4], [5], Bayesian information criterion
(BIC) [25], [27], and integrated classiﬁcation likelihood-BIC
(ICL-BIC) [17] are compared in sBGMM in this study. Based
on the simulation results, where sBGMM was compared with
BGMM under different scenarios, ICL, other than AIC3 which
is proposed for being used in the approximated version of
sBGMM [1], performs best in sBGMM.
The following sections are organized as ‘Methods’, ‘Re-
sults’, and ‘Conclusions’, where mixture model based cluster-
ing and EM algorithm are heavily discussed in ‘Methods’,
results of performance test with simulations and real data,
as well as a real case application are shown in different
subsections of ‘Results’, and in ‘Conclusions’ we ﬁrst summa-
rized this work, and then discussed its limitation and possible
extensions.
II. METHODS
This section introduces the proposed algorithm, including
the clustering framework, EM algorithm, prior construction,
model selection, and its initialization and convergence.
A. Stratiﬁed beta-Gaussian mixture model clustering frame-
work
In model-based clustering methods, each observation xj,
where j = 1, . . . , n and n is the number of genes, is drawn
from a ﬁnite mixture distribution with the prior probability
πi, component-speciﬁc distribution f (g)
i
and its parameters θi.
The formula is given as [21]
f(xj|θ) =
g
X
i=1
πif (g)
i
(xj|θi),
(1)
where θ = {(πi, θi) : i = 1, . . . , g} is used to denote all the
unknown parameters, with the restriction that 0 < πi ≤ 1
for any i and Pg
i=1 πi = 1. Note that g is the number of
components in this model. In the following texts, we ignore
the superscript (g) from f (g)
i
for simplicity.
In order to integrate as many information sources as possi-
ble, we propose in this paper an sBGMM
f(k)(xj|θ(k)) =
g
X
i=1
π(k),if (g)
i
(xj; θi),
(2)
where 1 ≤ k ≤ K. It means that the genes can be partitioned
into several groups, say G1, . . . , GK, based on additional prior
before EM is run, and the K stratiﬁed models share the same
set of component distributions while differ in their usage of
stratum-speciﬁc prior probabilities.
Deﬁne
θ
=
[π, θ1, θ2]T ,
π
=
£
π(1), . . . , π(K)
¤T ,
θ1
=
[α11, . . . , αgp1, β11, . . . , βgp1]T ,
and
θ2
=
£
µ11, . . . , µgp2, σ2
1, . . . , σ2
p2
¤T ,
where
p1
and
p2
each
represents the dimension of the observations in BMM and
GMM, respectively, and π(k) = [π(k),1, . . . , π(k),g] where
k = [1, . . . , K] for K stratiﬁed models. We also denote Y
and Z as the observations of beta distributed and Gaussian
distributed data, respectively, function f of y and f of z
as the density function of beta and Gaussian distribution,
respectively, and x = [yT , zT ]T .
Apart from adding the prior, sBGMM is built from BMM
and GMM with the assumption that, for each component i, the
beta distributed and Gaussian distributed data are independent.
In the BMM part, each component is assumed to be the
product of p1 independent beta distributions, whose probability
density function is deﬁned as
fi(y|θ1i) =
p1
Y
u=1
yαiu−1
u
(1 − yu)βiu−1
B(αiu, βiu)
,
(3)
where
θ1i
=
[αi1, . . . , αip1, βi1, . . . , βip1]
and
y
=
[y1, . . . , yp1]T . Likewise, each component is assumed to follow
a Gaussian distribution in the GMM part, whose probability
density function of each component for each gene is deﬁned
15
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

as
fi(z|θ2i) =
1
(2π)
p2
2 |V |
1
2 exp
¡
− 1
2(z − µi)T V −1(z − µi)
¢
,
(4)
where
θ2i
=
[µi1, . . . , µip2, σ2
1, . . . , σ2
p2],
µi
=
[µi1, . . . , µip2]T ,
V
=
diag(σ2
1, σ2
2, . . . , σ2
p2)
and
|V | = Qp2
v=1 σ2
v. Notice that diagonal covariance matrix
is assumed in the Gaussian part, which is especially useful
for high-dimensional data since it can signiﬁcantly reduce the
number of parameters that are needed to be estimated from
data.
B. EM algorithm
The standard EM algorithm is applied to estimate the param-
eters θ in sBGMM iteratively, whose derivation is similar with
one of our previously developed model, BGMM, as proposed
in [6].
The data log-likelihood (natural logarithm is referred to
throughout this paper) can be written as
log L(θ) =
n
X
j=1
log(
" g
X
i=1
π(k),ifi(xj|θi)
#
),
(5)
given X = {xj : j = 1, ..., n}, whose direct maximization,
however, is difﬁcult.
In order to make the maximization of Equation 5 tractable,
the problem is casted in the framework of incomplete data.
Since we assume that the beta and Gaussian distributed data
are independent, the complete data likelihood, Lc, can be
factored as
Lc(θ) = f(Y |c, θ)f(Z|c, θ)f(c|θ).
(6)
If we deﬁne cj ∈ {1, . . . , g} as the clustering membership of
xj, then the complete data log-likelihood can be written as
log Lc(θ) =
n
X
j=1
g
X
i=1
χ(cj = i) log (π(k),ifi(xj|θi)),
(7)
where χ(cj = i) is the indicator function of whether xj is
from the ith component or not.
In the EM algorithm, E step computes the expectation of
the complete data log-likelihood
Q(θ|θ(m))
=
Ec|X,θ(m)(log Lc)
=
n
X
j=1
Ecj|yj,zj,θ(m) [log (f(yj|cj, θ1))]
+
n
X
j=1
Ecj|yj,zj,θ(m) [log (f(zj|cj, θ2))]
+
K
X
k=1
X
j∈Gk
Ecj|yj,zj,θ(m)
£
log
¡
f(cj|π(k))
¢¤
,
(8)
where θ(m) represents the parameters estimated in the mth
iteration, and details of the derivation of Q can be found
in [21]. By computing the expectation, Equation 8 becomes
Q(θ|θ(m)) =
n
X
j=1
g
X
i=1
τ (m)
ji
log(π(k),ifi(yj|θ1i)fi(zj|θ2i)),
(9)
where
τ (m)
ji
=
p(cj = i|xj, θ(m))
=
π(m)
(k),ifi(yj|θ(m)
1i )fi(zj|θ(m)
2i )
Pg
i′=1 π(m)
(k),i′fi′(yj|θ(m)
1i′ )fi′(zj|θ(m)
2i′ )
, (10)
is the estimated posterior probability of xj, which belongs to
the kth layer according to the prior, coming from component
i at iteration m according to Bayes’ rule. Note that we
can assign each xj to the component i0 that maximizes
its estimated posterior probability, i.e., {i0|τji0 = maxi τji}.
Also, the assumption that the beta distributed and Gaussian
distributed data are independent is carried over to the expected
log-likelihood as shown by Equations 8 and 9.
To derive the closed form or numerical optimization formula
for updating parameters in sBGMM, we used Lagrange multi-
pliers to solve this constrained optimization problem, with the
Lagrangian function shown in Equation 11.
L(θ)
=
n
X
j=1
g
X
i=1
τ (m)
ji
log (fi(yj|θ1i))
+
n
X
j=1
g
X
i=1
τ (m)
ji
log (fi(zj|θ2i))
+
K
X
k=1
X
j∈Gk
g
X
i=1
τ (m)
ji
log(π(k),i)
+
K
X
k=1
λk
Ã
1 −
g
X
i′=1
π(k),i′
!
(11)
Parameters
of
BMM
part,
θ1i
=
[αi1, . . . , αip1, βi1, . . . , βip1]
1 ≤ i ≤ g, are optimized
by Newton-Raphson method and updated by
θ(m+1)
1i
= θ(m)
1i
− H−1(θ(m)
1i )∇θ1iL(θ(m)
1i ),
θ1i ≥ 1,
(12)
where H−1(θ(m)
uated at θ(m)1i ) is the inverse of the Hessian matrix eval-
1i , and L(θ(m)
1i ) is the Lagrangian function of
Q(θ(m)
1i ).
Parameters
of
the
GMM
part,
θ2i
=
[µi1, . . . , µip2, σ2
1, . . . , σ2
p2]
1 ≤ i ≤ g, in sBGMM can
be estimated by the standard EM algorithm of GMM with
diagonal covariance matrix as shown in the following closed
form formula
ˆµ(m+1)
iv
=
n
X
j=1
τ (m)
ji
zjv/
n
X
j=1
τ (m)
ji
,
(13)
ˆσ2,(m+1)
v
=
n
X
j=1
g
X
i=1
τ (m)
ji
(zjv − µ(m)
iv )2/n,
(14)
which can be obtained by plugging Equation 4 in Equation 11
16
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

and taking the derivatives of Equation 11 with respect to µiv
and σ2
v, respectively.
Optimization of the prior probability of each gene’s clus-
tering membership, π, can be derived by taking the derivative
of Equation 11 with respect to π(k),i, i.e.,
∂L(θ)
∂π(k),i
=
X
j∈Gk
τ (m)
ji
1
π(k),i
− λk,
ˆπ(m+1)
(k),i
=
X
j∈Gk
τ (m)
ji
/λk.
Moreover, since
1
=
g
X
i=1
π(k),i
=
g
X
i=1
1
λk
X
j∈Gk
τji
=
1
λk
X
j∈Gk
g
X
i=1
τji
=
1
λk
X
j∈Gk
1,
thus, λk = nk. Consequently, the updates of π is given by
ˆπ(m+1)
(k),i
=
X
j∈Gk
τ (m)
ji
/nk,
(15)
where Gk is the kth group with nk genes, according to the
prior.
From the above equations, it is easy to see that the EM of
sBGMM will reduce to the EM of BGMM if K = 1, and will
further reduce to BMM or GMM, respectively, as p2 or p1
equals to zero.
1) Prior construction: Priors of Equation 2 can be deter-
mined from any possible data sources. It can be either another
complete data source different from what have been used
in the component models (BMM and GMM), e.g., the pre-
cluster results obtained from PPI data [35], or some incomplete
information relevant to our problem, e.g., information retrieved
from database. In the following study, we employ a complete
PPI data set for simulation test, and obtain a set of incomplete
information from a database for real case study. Conversion
of PPI data into prior is described below.
PPI data, which is typically a binary square matrix, is
ﬁrst converted into contact matrix (denoted as A) and then
transformed into pathlength matrix (denoted as P). Contact
matrix is in the form of
A =
(
1
if i ⇔ j
0
if i ⇎ j,
(16)
where i ⇔ j means the existence of a connection between
node i and j while i ⇎ j denotes the other way around. In
the pathlength matrix, the pathlength between nodes i and j
is denoted as Pij and characterized as the smallest integer
k ≥ 1 such that (Ak)ij ̸= 0. P contains all the path lengths
for all pairs of nodes which are calculated by the ‘pathlength’
function of the ‘CONTEST’ toolbox in matlab [33]. We use
the pathlength matrix to pre-cluster the genes (corresponding
to the proteins they encode) using a simple hierarchical
clustering algorithm which employs Euclidean distance as the
distance matrix and nearest neighbor algorithm as the linkage
construction method, and matlab function ‘clusterdata’ is used
here for this purpose. Then we assume that genes from the
same pre-cluster share the same prior probability π(k),i of
coming from the same cluster i, and allow them coming from
different clusters.
C. Model Selection
Four well-known approximation-based model selection cri-
teria, BIC [25], [27], ICL [17], AIC [2], [4], and AIC3 [4],
[5] are compared in sBGMM, according to which the best-
performing criterion within the tested scope is chosen. Calcu-
lations for the above criteria are deﬁned as
AIC
=
−2 log L(ˆθ) + 2d,
(17)
AIC3
=
−2 log L(ˆθ) + 3d,
(18)
BIC
=
−2 log L(ˆθ) + d log(nM),
(19)
ICL
=
−2 log L(ˆθ) + d log(nM)
−2
n
X
j=1
g
X
i=1
τji log(τji),
(20)
where d is the number of free parameters, and M (in equa-
tions 19 and 20) is the total amount of the data (M =
PW
w=1 Mw, Mw is the size of data set w and W is the num-
ber of input data sets). Note that −2 Pn
j=1
Pg
i=1 τji log(τji)
is the estimated entropy of the fuzzy classiﬁcation matrix
Cji = (τji) [17].
sBGMM has K − 1 more free πi’s than BGMM because
of the K stratiﬁed layers. In BGMM, the number of free
parameters d is the summation of those in BMM and GMM
minus one set of redundant free πi’s, which is dBG
=
2gp1 + p2 + p2g + (g − 1). Therefore, the number of free
parameters in sBGMM is dsBG = 2gp1+p2+p2g+K(g−1).
D. Initialization and convergence
In this study, parameters αiu’s and βiu’s for each dimension
of beta distribution u (u ∈ {1, . . . , p1}) are initialized by
method-of-moments so that their means are randomly dis-
tributed within the range of y1u, . . . , ynu and variances are
equal for all clusters (g), µiv’s and σ2
v’s are obtained from the
randomly initialized fuzzy c-means clustering results, and πi’s
are initialized with the same random value within each group
Gk, and the sum of the probabilities of g components is one.
In order to avoid the possible local maxima, we run the
algorithm multiple (100) times with different initial values.
The convergence threshold (where Q is used to monitor the
convergence) and maximum number of iterations were set to
0.0001 and 100, respectively, for all the tested models, and all
the simulations have reached their convergence according to
the statistics stored during the simulations.
17
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

III. RESULTS
We ﬁrst tested the performance of sBGMM with artiﬁcial
and real data, respectively, and then applied it to a real
biological case, which are discussed separately below.
A. Performance test with artiﬁcial data
According to work done in [19] only part of protein-DNA
binding data and gene expression data agree with each other
(consisting of the same number of clusters), and data can fall
into three regions as illustrated in Figure 1. Beta and Gaussian
distributed data may share the same number of underlying
clusters (denoted as ‘Region 1’) or may not, and we denote
the scenario that beta distributed data has more underlying
clusters as ‘Region2’, and ‘Region3’ for the scenario of the
other way around. To match the three scenarios, we designed
data sets 1 to 3 for data of both beta and Gaussian distributions,
respectively, whose parameters are listed in Table I. Each
artiﬁcial data set is designed to fall into ﬁve categories:
‘good Beta’ (gB), ‘bad Beta’ (bB), ‘good Gaussian’ (gG),
‘bad Gaussian due to close means’ (bGm), and ‘bad Gaussian
due to large variances’ (bGv), where ‘good’ stands for low
noise level, and ‘bad’ means the opposite. The dimensions
are designed to be n = 100 and p = 4 for both data sets.
We also designed three PPI data sets to test the inﬂuence of
different priors on the clustering results. Prior 1 and 2 are
constructed based on the same underlying ground truth (the
same number of underlying clusters and the same clustering
membership of each gene) but differ in their noise levels, while
prior 3 contains some mis-clustering (clustering membership
of some genes are not consistent with the designed Gaussian
and beta distributed data) information and shares the same
noise level with Prior 1. All sparsity patterns are shown in
Figure 2, where the three priors are denoted as ‘T9’, ‘T2’, and
‘F9’, respectively, with the capital letter representing ‘true’ or
‘false’ (meaning that there is or there is not mis-clustering
information, respectively), and the following number standing
for the noise level (the higher the number the lower the noise),
e.g., 9 means the intensity of signal over background is 9. All
the simulations are repeated 10 times with randomly generated
data sets (including the data used for prior construction).
We used the same scoring system as developed in [7] for
performance evaluation, which is denoted as ‘E score’
ej(r)
=
(
1
if
ˆzji = 1 and ri = Tj
0
otherwise
E
=
max
r∈R
n
X
j=1
ej(r)/n
(21)
R
=
©
r = (r1, . . . , rˆg) : ∀i ̸= j ri ̸= rj;
ri ∈ {1, . . . , max{ˆg, g}}
ª
.
Notations of in this scoring system are deﬁned as follows.
Tj denotes the ground truth clustering membership of data
j. R stands for all possible associating ways between the
estimated and the true clusters, where ri is the label of
data belonging to component i predicted by the clustering
 
 
Binding Data
Region 1
Region 2
Region 3
Expression Data
Figure 1.
Region divisions of input data. In Region 1 gene expression and
protein-DNA binding data have the same number of underlying components;
in Region 2 binding data has more components; in Region 3 expression data
has more components.
algorithm, and r is chosen from labels 1, 2, . . . , max{ˆg, g}
(ˆg and g are the largest labels in the estimated and ground
truth clustering respectively). Denote also e as the individual
score of each gene, E as the average score of all the genes
for each repetition, ‘E score’ of each repetition as the one
corresponding to the optimal Q, and the ﬁnal ‘E score’ of
each data set as the median of the 20 ‘E score’s. This scoring
system evaluates the overall performance of the model since
it not only records the accuracy of the results but also reﬂects
the inﬂuence of the criterion for model selection.
We compared the performance of sBGMM and its non-
stratiﬁed version, BGMM, with data set 1 to data set 3, each
coupled with prior ‘T9’, ‘T2’ and ‘F9’. Before performance
test, we ﬁrst compared each model selection criterion in
handling different scenarios in each model, whose results are
shown in Table II. According to the average E scores shown in
Table II, there is no universal optimal criterion for sBGMM or
BGMM, but ICL is much safer to choose for sBGMM since
it selects most of the correct models.
Performance comparison results of sBGMM with its non-
stratiﬁed version under different scenarios with different priors
are shown in Figure 3, where the E scores are calculated
with the assumption that the real number of underlying
clusters is three (therefore the prior is designed to contain
three underlying clusters) and the model is chosen by the
criterion that generates the highest average E score under
each scenario. It is seen from Figure 3 that sBGMM and
BGMM perform equally well when at least one type of data
(excluding the prior) contains less noise and has the correct
number of underlying clusters for data within ‘Region 1’,
anything combined with ‘gB’ for data within ‘Region 2’, and
anything combined with ‘gG’ for data within ‘Region 3’. This
indicates that our joint models (both sBGMM and BGMM)
have the ability to offset the noisy or incorrect information
within one type of data by utilizing information from the
other one. However, when the noise level, including noise and
18
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

T9
(a)
T2
(b)
F9
(c)
Figure 2.
Sparsity patterns of the contact matrix of the artiﬁcial PPI data
sets. (a) ‘T9’: true prior with noise level equals 9. (b) ‘T2’: true prior with
noise level equals 2. (c) ‘F9’: false prior with noise level equals 9.
incorrect number of underlying clusters, is too high for both
types of data, using additional information becomes important
as shown by ‘yellow’ and ‘carmine’ in ‘Region 1’, ‘blue’,
‘yellow’ and ‘carmine’ in ‘Region 2’, and ‘cyan’, ‘yellow’,
‘red’ and ‘carmine’ in ‘Region 3’. It is also clear that there
is no signiﬁcant difference for using different priors (‘T9’,
‘T2’, and ‘F9’) in sBGMM if the prior does not contain too
much mis-clustering information, which means that sBGMM
is not sensitive to the noise and is tolerant of small amount of
inconsistent information in the prior. All together, these results
indicate that adding additional prior can utilize information
M
P
R
AIC
AIC3
BIC
ICL
BGMM
R1
0.8270
0.8325
0.8459
0.8464
R2
0.7855
0.7796
0.7663
0.7723
R3
0.7763
0.7803
0.7910
0.7849
sBGMM
T9
R1
0.8545
0.8680
0.8806
0.8845
T9
R2
0.7434
0.7714
0.8376
0.8430
T9
R3
0.7820
0.7995
0.8188
0.8270
sBGMM
T2
R1
0.8459
0.8636
0.8844
0.8820
T2
R2
0.7653
0.8001
0.8305
0.8391
T2
R3
0.7699
0.7941
0.8323
0.8343
sBGMM
F9
R1
0.8444
0.8600
0.8881
0.8881
F9
R2
0.7430
0.7674
0.8406
0.8430
F9
R3
0.7575
0.7900
0.8295
0.8295
Note: Values shown here are the averages of E scores
over all the tested cases (‘gG+gB’, ‘gG+bB’, ‘bGm+gB’,
‘bGm+bB’, ‘bGv+gB’, ‘bGv+bB’) selected by each cri-
terion in each model. ‘P’ column shows the priors. ‘M’
column lists the name of the tested models. ‘R’ column
shows the region that beta and Gaussian distributed data
belong to. ‘ICL’ is short for ‘ICL-BIC’. E scores shown
in bold face are the selected best criterion with respect to
highest average E scores and used in drawing Figure 3. All
values are rounded to four decimal points.
Table II
COMPARISON OF DIFFERENT MODEL SELECTION CRITERIA IN SBGMM
AND BGMM.
from more data sources, rendering sBGMM more robust in
handling with various scenarios than BGMM.
B. Performance test with real data
We applied our methods to mouse protein-DNA bind-
ing probabilities (modeled as beta distribution) and gene
expression data (modeled as Gaussian distribution). The
protein-DNA binding data contains the probabilities of 266
TFs binding to 20397 genes, which were calculated with
mouse-speciﬁc position weight matrices from the TRANS-
FAC database (the web server and data are available at
http://xerad.systemsbiology.net/ProbTF/ [14]). The gene ex-
pression data is composed of 1960 genes measured from 95
conditions [26], where six Toll-like receptor (TLR) agonists
(CpG, Pam2CSK4, Pam3CSK4, LPS, poly I:C and R848) were
used as the treatments, and four gene knock-out mutants and
different time points were included to increase the diversity
of the TLR-stimulated gene expression data set and the
number of measurements. There are 1766 genes measured in
both datasets. We removed the genes whose gene expression
proﬁles have low absolute values (less than 10th percentile)
with matlab function ‘genelowvalﬁlter’, and then chose genes
whose annotations are available through the functional classiﬁ-
cation tool of DAVID database (whose web server is available
at http://david.abcc.ncifcrf.gov/home.jsp [13]). In the end, 673
genes are chosen for the following studies. The chosen protein-
DNA binding data (beta distributed data that are used in this
study) is composed of the binding probabilities of the 673
19
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
E score
Region1
 
 
gG+gB
gG+bB
bGm+gB
bGm+bB
bGv+gB
bGv+bB
(a)
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
E score
Region2
 
 
gG+gB
gG+bB
bGm+gB
bGm+bB
bGv+gB
bGv+bB
(b)
1
2
3
4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
E score
Region3
 
 
gG+gB
gG+bB
bGm+gB
bGm+bB
bGv+gB
bGv+bB
(c)
Figure 3.
Simulation results. Performance comparison of sBGMM with
BGMM for (a) region 1 data, (b) region 2 data, and (c) region 3 data. In x-
axis of each region, ‘1’ to ‘4’ represent different models, each corresponds to
BGMM, sBGMM (‘T9’), sBGMM (‘T2’), sBGMM (‘F9’), accordingly. The
y-axis represent the E scores.
genes for six TFs (‘Junb’, ‘Jund1’, ‘Jun’, ‘Fos’, ‘Fosb’, and
‘Cebpb’) which are involved in AP1 gene regulatory network
in mouse according to TRED (Transcriptional Regulatory El-
ement Database, which is available at http://rulai.cshl.edu/cgi-
bin/TRED/tred.cgi?process=home). The Gaussian distributed
data that are ﬁtted in the model are the gene expression data
of these 673 genes at 23 conditions, which are the midpoint
of each time series (selected time point for each treatment are
shown in Table III).
Point
Treatment
Time
1
Atf−
3
0
2
CpG+Atf−
3
120
3
LPS+Atf−
3
240
4
Pam2CSK4+Atf−
3
120
5
poly I:C+Atf−
3
120
6
Crem−
0
7
LPS+Crem−
240
8
poly I:C+Crem−
360
9
Myd88−
0
10
LPS+Myd88−
60
11
Pam3CSK4+Myd88−
60
12
poly I:C+Myd88−
60
13
TicamI−
0
14
LPS+TicamI−
120
15
LPS+Pam2CSK4+TicamI−
120
16
no
0
17
CpG
60
18
LPS
360
19
Pam2CSK4
80
20
Pam3CSK4
240
21
Pam3CSK4+poly I:C
60
22
poly I:C
120
23
R848
120
Note: ‘Point’ refers to the labels of the
x axis; ‘-’ means the mutant strain that
does not have the particular gene; time
point chosen for the treatment is shown in
the column ‘Time’, and time unit is ‘min’.
Treatments after point 16 were all applied
to the wild type.
Table III
TREATMENTS OF THE GENE EXPRESSION DATA
We constructed two types of priors for real case performance
test. Type 1 prior contains two priors (denoted as ‘P1a’, ‘P1b’)
which both utilize the transcriptional regulation information
stored in TRED. Curation of transcriptional regulation in
TRED are done with both experimental evidence and pro-
moter ﬁnding tools, and currently involves genes within 36
cancer-related TF families. ‘P1a’ is built from the clustering
information of AP1 network, where 10 genes are assigned
to two clusters, and the memberships of the rest genes are
left unspeciﬁed. ‘P1b’ keeps all the clustering membership in
‘P1a’ intact, and speciﬁes the rest memberships from all the
other networks in TRED by removing genes that are involved
in several networks or form singleton clusters (resulting in
16 more memberships speciﬁed). Type 2 priors are obtained
from an online classiﬁcation tool DAVID (the web server is
available at http://david.abcc.ncifcrf.gov/gene2gene.jsp [13]), a
20
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

database for annotation, visualization and integrated discovery.
Different thresholds (‘Highest’, ‘Medium’, ‘Lowest’) were set
to obtain different functional classiﬁcation results, resulting in
three different type 2 priors, which are denoted as ‘P2a’, ‘P2b’,
‘P2c’, respectively.
We tested the performance of sBGMM by comparing its
performance on clustering the 673 genes (with both types 1
and type 2 priors) with its non-stratiﬁed form (BGMM), and
both of its component models (BMM, GMM). We employed
Gene Ontology (GO) in this study to validate the clustering
results. In order to ﬁnd the most signiﬁcant annotated terms
by looking at the probabilities that the terms are counted by
chance, we used the hypergeometric probability distribution
to calculate the p-values of gene enrichment score (called ‘p-
values’ for simplicity) for each cluster by each model with
each model selection criterion (Bioinformatics Toolbox 3.1
in Matlab). We compared the means and medians of each
clustering results by each model with respect to different
aspects (molecular function, cellular component, biological
process, and all aspects, which are denoted as ‘F’, ‘C’, ‘P’
and ‘All’), whose results are shown in Table IV. To see how
stable the algorithms work with our test data set, or in other
words, whether 100 iterations are enough for convergence, we
repeated each set of iterations (100) three times for different
models, with one repetition for each model shown in Table IV.
There are at least four pieces of information unveiled
by Table IV. First, BGMM works better than BMM and
GMM with respect to smaller means and medians of the
group p-values. Second, sBGMM can signiﬁcantly improve
the clustering performance compared with BGMM and its
component models when the prior is properly chosen. As
shown in this table, results generated with type 1 priors are
better than those with type 2 priors, whose means and medians
are signiﬁcantly smaller than those of BGMM, BMM and
GMM; moreover, sBGMM with type 1 priors generate more
stable results than the other models, i.e., two out of three
repetitions of sBGP 1a and all three repetitions of sBGP 1b
converge to the same clustering, respectively. This is because
information delivered by type 1 priors are consistent with that
used for choosing TFs of protein-DNA binding probabilities,
while type 2 priors, which are the classiﬁcation results from
an online functional classiﬁcation tool, might group the same
gene into another cluster based on its own criteria (DAVID
groups genes by measuring the functional relationship of
gene pairs based on the similarity of their global annotation
proﬁles [13]). Third, P1b is denser than P1a, and generates
more stable results (three vs. two repetitions converge to
the same result), which indicates that the more consistent
(consistent with data) information carried out by the prior
the more accurate the results will be. However, both type 1
priors used here are quite sparse, therefore, we expect to get
even higher accuracy if denser and consistent (consistent with
data) prior is available. Fourth, sBGMM with type 1 prior
works better than DAVID functional classiﬁcation tool. As
shown in Table IV, all the evaluated quantities of the results
obtained from DAVID (P2a, P2b, P2c) are worse than those
of sBGMM (coupled with type 1 priors), BGMM, and even
some of the results of GMM. Although the improved accuracy
can not show the superiority of sBGMM over DAVID since
totally different types of data sources are used, the results
demonstrate the power of employing gene expression and
protein-DNA binding data in gene clustering over relying on
global annotation proﬁles.
C. Biological application with sBGMM
After performance test, we further analyzed all the 1766
genes in our data set. We compared the 1766 genes with
the genes involved in all the 36 cancer related gene networks
stored in TRED, and decided to extract the information from
the network that has the largest overlap with our gene set
(NFKB network) for further analysis. There are seven TFs
involved in this network, out of which ﬁve (which are ‘Rel’,
‘Nfkb1’, ‘Msx1’, ‘Rela’, ‘Myb’, and named TFnormal for con-
venience) are available in our data set. Protein-DNA binding
probabilities of those ﬁve TFs to all the 1766 genes and gene
expression data of the 23 midpoint conditions (midpoint of
each time series) were chosen as the beta distributed and
Gaussian distributed data set, respectively. Genes involved in
NFKB network are grouped into six clusters by TRED, among
which 42 are present in our data set. We constructed a type
‘P1b’ prior for the whole gene set since it tends to have a
more stable behavior compared with ‘P1a’ according to the
real case performance test (see the previous subsection).
There are 34 genes that encode TFs (named TF genes)
among the whole data set. We ﬁrst clustered the 34 TF
genes with BGMM, for three times, and chose the TF gene
cluster which has the smallest enrichment p-values for further
analysis. There are 11 genes in the selected TF gene group,
out of which eight are repeated clustered together among three
repetitions and, for convenience, we call them the ‘core TF
genes’ and denoted as TFcore in the following text.
To ﬁnd the inﬂuence of the choice of protein-DNA binding
probabilities on the clustering accuracy of sBGMM and ﬁnd
a set of protein-DNA binding probabilities as suitable as
possible for further analysis, we ﬁrst clustered the 1766 genes
by sBGMM with binding data corresponding to TFnormal,
and then re-clustered them with those selected by TFcore,
each with three repetitions. For comparison purpose, we also
clustered the 1766 genes by BGMM with binding data of the
core TF genes, and the result of one repetition from each
clustering were compared and shown in Table V. Note that
the expression data and the prior are the same in the models
where they were used.
It is interesting to see from Table V that the group p-values
are signiﬁcantly dropped after using the core TF genes for gene
clustering, and the group p-values obtained with sBGMM are
overwhelmingly lower than those obtained by BGMM. This
means that the core TF genes are more responsible to TLR-
stimulated macrophage activation than the TFs chosen based
on the prior information obtained from NFKB network, and
again demonstrates the superiority of sBGMM over its non-
stratiﬁed version.
21
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

We further analyzed the causal relationship between the
set of core TFs and the whole set of genes. We notice that
among the eight core TF genes, ‘E2F6’, ‘E2f7’, ‘Foxm1’ and
‘Nfatc1’ are clustered together with 363 other genes, and
‘Rest’, ‘Rfx5’, ‘Mxd1’ and ‘Stat1’ fall into the same group
with 305 other genes. Moreover, by examining the expression
proﬁles of the two sets of genes under different treatment
(shown in Figure 4), it is clear that there is a plateau existed in
all proﬁles from point 26 and 48 where either mutant Myd88−
or TicamI− is used, or no treatment is applied or CpG is added.
This indicates that genes Myd88 and Ticam1 are crucial for
the system (which involves the genes that belong to the four
clusters) to response to the external stimuli, and agonist CpG
does not have so much inﬂuence on it. Moreover, whenever
LPS or poly I:C is added to the wild type (regions between
points 5 and 10, 14 and 16, 18 and 22, 23 and 26, 48 and 59, 79
and 87), there is a sharp drop in the red proﬁle while there is a
peak in the green curve. This feature indicates that the two set
of genes (including the core TF genes) are sensitive to LPS and
poly I:C, and behave in an opposite way after being stimulated.
Genes that are clustered with ‘E2F6’, ‘E2f7’, ‘Foxm1’ and
‘Nfatc1’ are activated by them while repressed by TFs ‘Rest’,
‘Rfx5’, ‘Mxd1’ and ‘Stat1’; while operation goes the other
way around for the other set of genes. Moreover, since poly
I:C, LPS and CpG are TLR-3, TLR-4 and TLR-9 agonists,
respectively, and Myd88 and Ticam1 are adaptors involved in
TLR-3/4 signaling according to [23], we can deduce that most
of the two set of genes (including TF genes) are involved in
Myd88-dependent TLR-3/4 signaling cascades.
IV. CONCLUSION AND FUTURE WORK
This paper presents a novel method based on stratiﬁed
beta-Gaussian mixture model, sBGMM, for gene clustering
from multiple data sources. In addition to integrating beta
distributed and Gaussian distributed data, sBGMM can also
facilitate clustering by employing priors which come from
a third data source. A stratiﬁed version of EM algorithm is
developed for jointly estimating parameters from beta and
Gaussian distributions, and is used as the core of sBGMM.
sBGMM differs from its non-stratiﬁed version (BGMM) by
setting the same prior probabilities of coming from each
cluster to genes that belong to the same layer which are
stratiﬁed according to the additional prior. In principle, any
relevant information can be used as priors, whereas in this
study, we built the prior from PPI data in simulations, and
retrieved it from database TRED in the real case study.
Simulation results show that sBGMM works better than its
non-stratiﬁed version especially when both beta and Gaussian
distributed data contain too much noise, and certain mis-
clustering information in the prior is tolerable. In real case
study we not only demonstrated the superiority of sBGMM
compared with BGMM and a gene annotation based clas-
siﬁcation method (DAVID functional classiﬁcation tool) by
analyzing 673 genes, but also revealed the relationship of two
sets of genes and eight TFs in TLR-stimulated macrophage
signaling through analyzing the full data set (1766 genes).
5
10 141618 22 26
48
59
79
87
5
5.5
6
6.5
7
7.5
8
8.5
9
9.5
10
(a)
5
10 141618 22 26
48
59
79
87
5
5.5
6
6.5
7
7.5
8
8.5
9
9.5
10
(b)
Figure 4.
Median gene expression proﬁles of the (a) interested genes and
(b) TFs. Solid curves represent the median expression proﬁle of the genes or
TFs. Horizontal dot lines stand for the expression level of wild type without
treatment. Vertical blue lines divides the whole plane into different regions,
where in each region different treatment is applied.
This work demonstrates one approach of utilizing multiple
data sources in gene clustering, and data of other distributions
can also be incorporated into this framework by joining EM
algorithm of that particular distribution in a similar way. So
in a sense, the framework proposed in this paper is applicable
to many problems and not limited to the particular problem
considered here [8].
Although, sBGMM is tolerant to some mis-clustering infor-
mation in the prior, its performance might not be improved
or even dragged down if the prior is built under differ-
ent criterion and totally irrelevant to the focused problem.
Moreover, although sBGMM is extremely useful when only
sparse prior is available, it might not be able to efﬁciently
utilize the third data source whose information is complete
(such as PPI data). Moreover, since PPI data is one direct
22
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

measure of the regulatory network and is commonly used in
gene clustering for many applications, such as inferring gene
functions [34] and discovering genes involved in a particular
molecular pathway [28], it is important to develop a model
that can make as efﬁcient use of PPI data as possible. In the
future, instead of utilizing PPI data as prior, we could model
it as Bernoulli distribution and treat it as one component of
the joint model-based clustering framework.
ACKNOWLEDGMENT
This work was supported by the Academy of Finland
(application number 129657, Finnish Programme for Center
of Excellence in Research 2006-2011). We would also like
to thank the Tampere Graduate School in Information Science
and Engineering (TISE) for its ﬁnancial support in this project.
REFERENCES
[1] X. F. Dai, H. L¨ahdesmaki, and O. Yli-Harja, sBGMM: a stratiﬁed
Beta-Gaussian mixture model for clustering genes with multiple data
sources.
International Conference on Biocomputation, Bioinformatics,
and Biomedical Technologies (BIOTECHNO 2008), Bucharest, Roma-
nia, 29 June - 5 July 2008, pp. 94-99.
[2] H. Akaike, A new look at the statistical identiﬁcation model.
IEEE
Transactions on Automatic Control, vol. 19, no. 6, pp. 716-723, 1974.
[3] J. D. Banﬁeld and A. E. Raftery, Model-based Gaussian and non-
Gaussian clustering.
Biometrics, vol. 49, no. 3, pp. 803-821, 1993.
[4] C. Biernacki and G. Govaert, Choosing models in model-based clus-
tering and discriminant analysis.
J. Statis. Comput. Simul., vol. 64,
pp. 49-71, 1999.
[5] H. Bozdogan, Model Selection and Akaike Information Criterion (AIC):
The General Theory and its Analytic Extensions.
Psychometrika,
vol. 52, pp. 345-370, 1987.
[6] X. F. Dai, T. Erkkil¨a, O. Yli-Harja, and H. L¨ahdesmaki, A joint ﬁnite
mixture model for clustering genes from independent Gaussian and beta
distributed data.
BMC Bioinformatics, accepted.
[7] X. F. Dai, H. L¨ahdesmaki, and O. Yli-Harja, BGMM: a Beta-Gaussian
mixture model for clustering genes with multiple data sources.
Fifth
international workshop on computational system biology (WCSB 2008),
Leipzig, Germany, 11 - 13 June 2008, pp. 25-28.
[8] X. F. Dai, O. Yli-Harja, and A. S. Ribeiro, Determing noisy attractors
of delayed stochastic Gene Regulatory Networks from multiple data
sources. submitted.
[9] M. B. Eisen, P. T. Spellman, P. O. Brown, and D. Botstein, Cluster
analysis and display of genome-wide expression patterns.
Proceedings
of the National Academy of Sciences of the United States of America,
vol. 95, pp. 14863-14868, 1998.
[10] C. Fraley, Algorithms for model-based Gaussian hierarchical clustering,
SIAM Journal on Scientiﬁc Computing, vol. 20, no. 1, pp. 270-281,
1999.
[11] C. Fraley and A. E. Raftery, Model-based clustering, discriminant
analysis, and density estimation,
Journal of the American Statistical
Association, vol. 97, no. 458, pp. 611-631, 2002.
[12] D. Ghosh and A. M. Chinnaiyan, Mixture modeling of gene expression
data from microarray experiments.
Bioinformatics, vol. 18, no. 2,
pp. 275-286, 2002.
[13] G. D. Jr, B. T. Sherman, D. A. Hosack, J. Yang, W. Gao, H. C. Lane,
and R. A. Lempicki, DAVID: Database for Annotation, Visualization,
and Integrated Discovery,
Genome Biology, vol. 4, no. 9, pp. R60,
2003.
[14] H. Lähdesmäki, A. G. Rust, and I. Shmulevich, Probabilistic Inference
of Transcription Factor Binding from Multiple Data Sources,
PLoS
ONE, vol. 3, no. 3, pp. e1820, 2008.
[15] R. Herwig, A. J. Poustka, C. Muller, C. Bull, H. Lehrach, and J. O’Brien
Large-scale clustering of cDNA-ﬁngerprinting data,
Genome Research,
vol. 9, no. 11, pp. 1093-1105, 1999.
[16] D. X. Jiang, C. Tang, and A. D. Zhang, Cluster analysis for gene
expression data: a survey,
IEEE Transactions on knowledge and data
engineering, vol. 16, no. 11, pp. 1370-1386, 2004.
[17] Y. Ji, C. Wu, P. Liu, J. Wang, R. K. Coombes, Applications of beta-
mixture models in bioinformatics.
Bioinformatics, vol. 21, no. 9,
pp. 2118-2122, 2005.
[18] H. Li and F. Hong Cluster-rasch models for microarray gene expression
data,
Genome Biology, vol. 2, no. 21, pp. research0031.1-0031.13,
2001.
[19] M. J. Herrgard, B. Lee, V. Portnoy, and B. Palsson, Integrated analysis of
regulatory and metabolic networks reveals novel regulatory mechanisms
in Saccharomyces,
Genome Research, vol. 16, pp. 627-635, 2006.
[20] G. Mclachlan and K. Basford, Mixture Models: Inference and Applica-
tions to Clustering,
Marcel Dekker, New York, 1988.
[21] G. Mclachlan and D. Peel, Finite mixture models,
John Wiley & Sons,
Manhattan, USA, 2000.
[22] M. Meila and D. Heckerman, An experimental comparison of model-
based clustering methods,
Machine Learning, vol. 42, pp. 9-29, 2001.
[23] L. A. O’Neill, K. A. Fitzgerald, and A. G. Bowie, The Toll-IL-1 receptor
adaptor family grows to ﬁve members,
Trends in Immunology, vol. 24,
no. 6, pp. 286-290, 2003.
[24] W. Pan, J. Z. Lin, and C. T Le, Model-based cluster analysis of gene
expression data.
Genome Biology, vol. 3, no. 2, pp. research0009.1-
0009.8, 2002.
[25] W. Pan, Incorporating gene functions as priors in model-based cluster-
ing of microarray gene expression data.
Bioinformatics, vol. 22, no. 7,
pp. 795-801, 2006.
[26] S. A. Ramsey, S. L. Klemm, D. E. Zak, K. A. Kennedy, V. Thorsson,
B. Li, M. Gilchrist, E. S. Gold, C. D. Johnson, V. Litvak, G. Navarro,
J. C. Roach, C. M. Rosenberger, A. G. Rust, N. Yudkovsky, A. Aderem,
and I. Shmulevich, Uncovering a Macrophage Transcriptional Program
by Integrating Evidence from Motif Scanning and Expression Dynamics,
PLoS Computational Biology, vol. 4, no. 2, pp. e1000021, 2008.
[27] G. Schwarz, Estimating the dimension of a model.
Annals of Statistics,
vol. 6, pp. 461-464, 1978.
[28] E. Segal, H. Wang, and D. Koller Discovering molecular pathways from
protein interaction and gene expression data,
Bioinformatics, vol. 19,
no. 1, pp. i264-i272, 2003.
[29] G. Sherlock Analysis of large-scale gene expression data,
Brieﬁngs
in Bioinformatics, vol. 2, no. 4, pp. 350-362, 2001.
[30] P. Smyth, Model selection for probabilistic clustering using cross-
validated likelihood.
Statistics and Computing, vol. 9, pp. 63-72,
2000.
[31] M. Symons, Clustering criteria and multivariate normal mixtures,
Biometrics, vol. 37, pp. 35-43, 1981.
[32] P. Tamayo, D. Slonim, J. Mesirov, Q. Zhu, S. Kitareewan, E. Dmitrovsky,
E. S. Lander, and T. R. Golub, Interpreting patterns of gene expression
with self-organizing maps: methods and application to hematopoietic
differentiation,
Proceedings of the National Academy of Sciences of
the United States of America, vol. 96, pp. 2907-2912, 1999.
[33] A. Taylor and D. J. Higham, Contest: A controllable test matrix toolbox
for MATLAB.
Genome Research, vol. 16, pp. 627-635, 2007.
[34] K. Tu, H. Yu, and Y. X. Li, Combing gene expression proﬁles and
protein-protein interaction data to infer gene functions,
International
Journal of Biotechnology, vol. 124, no. 3, pp. 475-485, 2006.
[35] N. Tuncbag, T. Haliloglu, O. Keskin, Correspondence between function
and interaction in protein interaction network of Saccaromyces cere-
visiae.
International Journal of Biomedical Sciences, vol. 1, no. 1,
pp. 1306-1216, 2006.
[36] S. Vaithyanathan and B. Dom, Model-based hierarchical clustering,
Proceedings of the 16th conference on Uncertainty in Artiﬁcial Intelli-
gence, Stanford, California, USA, 30 June - July 3, 2000, pp. 599-608.
[37] K. Y. Yeung, C. Fraley, A. Murua, A. E. Raftery, and W. L. Ruzzo,
Model-based clustering and data transformation for gene expression
data,
Bioinformatics, vol. 17, no. 10, pp. 977-987, 2001.
23
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

Data set 1
cluster 1
cluster 2
cluster 3
gB
α
20
5
3
30
20
25
30
35
2
15
33
4
β
2
15
33
4
20
25
30
35
20
5
3
30
bB
α
33
30
22
20
30
27
20
18
27
24
18
16
β
30
33
20
22
27
30
18
20
24
27
16
18
gG
µ
5
-8
20
15
10
1
-20
0
-10
8
5
15
σ
1
2
3
2.5
1
2
3
2.5
1
2
3
2.5
bGm
µ
3
15
5
11
2
13
6
9
1
14
7
10
σ
1
2
3
2.5
1
2
3
2.5
1
2
3
2.5
bGv
µ
5
-8
20
15
10
1
-20
0
-10
8
5
15
σ
10
20
30
25
10
20
30
25
10
20
30
25
Data set 2
cluster 1
cluster 2
cluster 3
gB
α
20
5
3
30
20
25
30
35
2
15
33
4
β
2
15
33
4
20
25
30
35
20
5
3
30
bB
α
33
30
22
20
30
27
20
18
27
24
18
16
β
30
33
20
22
27
30
18
20
24
27
16
18
gG
µ
10
1
-20
0
-10
8
5
15
σ
1
2
3
2.5
1
2
3
2.5
bGm
µ
2
13
6
9
1
14
7
10
σ
1
2
3
2.5
1
2
3
2.5
bGv
µ
10
1
-20
0
-10
8
5
15
σ
10
20
30
25
10
20
30
25
Data set 3
cluster 1
cluster 2
cluster 3
gB
α
20
5
3
30
2
15
33
4
β
2
15
33
4
20
5
3
30
bB
α
30
27
20
18
27
24
18
16
β
27
30
18
20
24
27
16
18
gG
µ
5
-8
20
15
10
1
-20
0
-10
8
5
15
σ
1
2
3
2.5
1
2
3
2.5
1
2
3
2.5
bGm
µ
3
15
5
11
2
13
6
9
1
14
7
10
σ
1
2
3
2.5
1
2
3
2.5
1
2
3
2.5
bGv
µ
5
-8
20
15
10
1
-20
0
-10
8
5
15
σ
10
20
30
25
10
20
30
25
10
20
30
25
Note: ‘gB’ and ‘bB’ each stands for ‘beta’ distributed data that are of ‘good’ and ‘bad’ quality
respectively; ‘gG’, ‘bGm’ and ‘bGv’ each represents ‘Gaussian’ distributed data that are of
‘good’ quality and ‘bad’ quality with respect to close means and large variances respectively;
‘||’ separate the parameters of different clusters, and ‘|’ separate the parameters of different
dimensions (2nd dimension) within the same cluster.
Table I
PARAMETERS OF BETA AND GAUSSIAN DISTRIBUTED DATA.
24
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

All
F
C
P
Model
Criterion
M1
M2
M1
M2
M1
M2
M1
M2
N
BMM
1∼4
0.2487
0.2945
0.3546
0.3484
0.3579
0.3479
0.3498
0.3423
4
GMM
1∼2
0.1889
0.1756
0.2640
0.3149
0.2924
0.3451
0.2740
0.3334
13
3∼4
0.2112
0.1914
0.2955
0.3027
0.3239
0.3587
0.3019
0.3356
29
BGMM
1∼4
0.1351
0.1350
0.2369
0.2681
0.2847
0.3117
0.2506
0.2976
4
sBGMMP 1a
1∼4
0.0848
0.0710
0.2128
0.2021
0.2503
0.2483
0.2290
0.2307
4
sBGMMP 1b
1∼4
0.0913
0.0747
0.1947
0.2174
0.2272
0.2684
0.2110
0.2409
4
sBGMMP 2a
1∼4
0.1740
0.1840
0.2911
0.3279
0.3173
0.3337
0.2963
0.3225
16
sBGMMP 2b
1∼4
0.1506
0.1291
0.3000
0.3536
0.3218
0.3700
0.3098
0.3638
9
sBGMMP 2c
1∼4
0.1817
0.1785
0.2429
0.2926
0.2697
0.3083
0.2556
0.3040
8
P2a
0.1948
0.1810
0.2610
0.2530
0.2833
0.3035
0.2649
0.2609
8
P2b
0.2055
0.2167
0.2707
0.2736
0.2970
0.3074
0.2768
0.3043
29
P2c
0.2216
0.2286
0.2726
0.2577
0.2999
0.2938
0.2815
0.2862
31
Note: ‘F’, ‘C’, ‘P’ represent the three aspects of gene ontology, and ‘All’ means all three aspects
are included. ‘M1’ and ‘M2’ stand for the mean and median of the p-values across all the clusters,
respectively. ‘Model’ and ‘Criterion’ represent the model and model selection criteria, respectively.
Subindexes of sBGMM indicate the prior that is used, e.g. sBGMMP 1a stands for using prior ‘P1a’.
‘1’ to ‘4’ each represents model selection criterion BIC, ICL, AIC, AIC3 respectively. ‘N’ means the
number of clusters generated by each model. The last three lines show the corresponding statistics
for the clusters given by DAVID. The smallest p-value in each column is shown in bold face. All
fractions are rounded to four decimal points.
Table IV
PERFORMANCE TEST RESULTS OF SBGMM WITH REAL DATA.
All
F
C
P
Moldel
Crit
M1
M2
M1
M2
M1
M2
M1
M2
N
sBGMMnormal
1∼4
0.1662
0.1002
0.2356
0.2776
0.2797
0.3222
0.2441
0.2976
13
sBGMMcore
1∼4
0.0557
0.0308
0.1418
0.1492
0.1922
0.1595
0.1617
0.1551
5
BGMMcore
1∼4
0.1279
0.0714
0.2259
0.2701
0.2682
0.2833
0.2373
0.2637
8
Note: ‘F’, ‘C’, ‘P’ represent the three aspects of gene ontology, and ‘All’ means all three aspects
are included. ‘M1’ and ‘M2’ stand for the mean and median of the p-values across all the clusters,
respectively. ‘Model’ and ‘Crit’ represent the model and model selection criteria, respectively. ‘bef’
and ‘aft’ in the subindexes of sBGMM represent that the clustering is done before and after knowing
the core TF genes, respectively, and the last digit ‘i’ (i ∈ 1, . . . , 3)in the subindex represents the ‘ith’
repetition of clustering with this model. ‘1’ to ‘4’ each represents model selection criterion BIC, ICL,
AIC, AIC3 respectively. ‘N’ means the number of clusters generated by each model. The smallest
p-value in each column is shown in bold face. All fractions are rounded to four decimal points.
Table V
CLUSTERING RESULTS WITH WHOLE DATA SET.
25
International Journal On Advances in Life Sciences, vol 1 no 1, year 2009, http://www.iariajournals.org/life_sciences/

