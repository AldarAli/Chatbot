Addressing Prerequisites for STEM Classes Using an Example of Linear Algebra
for a Course in Machine Learning
Genady Grabarnik
Department of Math & CS
St. John’s University
Queens, NY, USA
email: grabarng@stjohns.edu
Luiza Kim-Tyan
Department of Mathematics
NUST MISIS
Moscow, Russia
email: kimtyanlr@gmail.com
Serge Yaskolko
AD&D
College Board
Pittsburgh, PA, USA
email: syaskolko@collegeboard.com
Abstract—While teaching Science, Technology, Engineering,
and Mathematics (STEM) subjects, we frequently encounter
situations where we have several prerequisites for a particular
course. We anticipate that students will have different levels of
knowledge in these prerequisites. A prerequisite (Linear
algebra for Machine Learning course) was implemented as an
interactive
online
course
using
Jupyter
Notebooks
and
nbgrader. A preliminary survey shows a preference by
students and instructors for this interactive implementation.
Keywords- prerequisites; machine learning; linear algebra;
interactive self-study course; Jupyter Notebooks.
I.
INTRODUCTION
While teaching STEM subjects, we frequently encounter
situations where we have several prerequisites for a
particular course. We expect these students will have
different levels of knowledge regarding these prerequisites.
In most cases, a conceptual understanding and an ability to
apply the prerequisite material are sufficient for most
students. Students are not expected to know details, such as
proofs, etc.
We encountered one such situation while teaching a
Machine Learning (ML) course to first-year graduate
students. An ML course relies on knowledge of linear
algebra, multi-dimensional calculus and probability. The
standard approach is to provide material for student self-
study in addition to refresher material, so called crash
course material given during the course. The advantage here
is that students get at least the minimum amount of the
required material, with an option for additional self-learning
if desired.
We also encounter multiple disadvantages, however,
with such an approach. For one, time needed for the main
subject
is
spent
on
prerequisites.
Review
time
for
prerequisites should be limited as it is very challenging to
cover necessary material at a sufficiently high level. While
students have the option to self-study, learning with an
instructor is significantly more effective and efficient.
Another disadvantage: neither students nor instructors could
verify whether the necessary level of understanding and
application of prerequisite material had been achieved. This
may be remedied with quizzes or tests, which in turn require
additional precious instruction time.
To address these issues, we decided to use an available
teaching
technology:
we
would
organize
prerequisite
material in the form of interactive online self-study. We
used Jupyter Notebook [1] - based technology flexible
enough
to
create
an
interactive
course
with
proper
mathematical typesetting as well as programming support
(Python) in case we had to do modifications which we
assumed should allow us to address these issues.
Thus, instead of providing generic self-study materials
for prerequisites in the form of a book or pdf, we provided a
concise Interactive Online self-study course that covers
prerequisites and offers Concept Inventory (IOCI) based
short tests, which evaluate students’ understanding of the
main concepts and their ability to apply the material. Hence,
we precisely target the goals of the course prerequisites.
We implemented the course using iPython Notebook [2]
software
with
additional
course
management
support
provided by the nbgrader plugin [16]. The course was
developed on Amazon’s c9 cloud and was available to
students online. The course works in an automated or semi-
automated way, allowing the instructor to see test results by
topic or intervene and comment on student answers.
In our specific case, we started with linear algebra (LA)
prerequisite material for the ML graduate course. We
developed prerequisite self-study course material with CI-
based tests. Students can return to topics already studied,
advance upon completion of an appropriate test, or skip tests
altogether and concentrate on study material alone.
Our
course
offers
a
two-part
novelty:
making
prerequisite material in the form of interactive online
course; incorporating quizzes and homework in the form of
Concept Inventory (CI), which addresses only required for
prerequisite understanding of concepts and notions and
ability to apply the material in the main course context. To
the best of our knowledge, such combinations were not used
before. The course was also translated into Russian and
deployed at two universities: St John’s University (New
York)
and
the
National
University
of
Science
and
Technology, MISIS (Moscow). It covered two experimental
groups with a total of 30-plus students. According to the
preliminary survey, both students and instructors prefer the
interactive Jupyter Notebook-based study approach to the
standard prerequisite classes.
This paper proceeds as follows. In Section II, we describe
existing CIs and state-of-the-art Interactive Online Systems.
In Section III, we proceed to a description of LA as a
prerequisite material to the Machine Learning course. We
57
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-764-1
eLmL 2020 : The Twelfth International Conference on Mobile, Hybrid, and On-line Learning

show how CI addresses the requirement of the specific
prerequisite material. In Section IV, we describe the cloud
system used for the initial implementation of the course as
well as hardware requirements for running a test experiment
of about 200 software simulated test students. In Section V,
we provide a preliminary (proof of concept) evaluation of
our approach. We end our paper with a conclusion and
discussion of future work.
II.
STATE OF THE ART
The purpose of a prerequisite class differs from a
“normal” class. It prepares a student for another class, not
directly for a future career. Hence, it is often perceived as
something less necessary. As observed in [10][13], students
often see prerequisites as a waste of time and avoidable. If
handled appropriately, a prerequisite course would solve
motivational issues. One way to
minimize time and
resources spent is to make it self-paced so that a student
goes through it at a comfortable pace and when time is
available.
The first part of the outlined program – teaching only the
material actually needed - is course-specific and should be
addressed on case-by-case basis.
The second part about level and form of material taught,
however, can be answered in general, at least for STEM
classes.
A. Notion of Concept Inventory
While teaching STEM classes, as we observed in most
cases, a conceptual understanding and an ability to apply the
prerequisite
material
are
sufficient.
Students
are
not
expected
to
know
details,
such
as
proofs,
etc.
The CI is the best existing approach to assessing conceptual
understanding rather than memorization of a set of facts. CI
as a form of an assessment is based on checking if a student
understands basic concepts of a given subject as opposed to
reciting a number of subject specific facts, equations, etc.
As David Hestenes states in his paper, Force Concept
Inventory, [17] CI Assessment is “not a test of intelligence”
but rather, “it is a probe of belief systems”.
An immediate advantage of CI is that it can be used for
any student.
That is, it does not matter, what the subject
specific background of the student is, since, as stated above,
CIs do not test formal knowledge but rather understanding
of basic concepts. For example, as was demonstrated in
[11], there is no significant difference observed between the
test results even if the class time, class readiness, or type of
class are different. That includes even classes that lack
traditional lectures, such as Matematica-based classes.
Typically, CIs are created and delivered as multiple-choice
tests. However, as opposed to standard tests CIs are not
comparison tests but norm-referenced tests.
The main goal of CIs, as stated above, is to test the
students understanding of basic concepts. However, a
typical CI test also checks for typical misconceptions.
There are two typical types of misconceptions: general
scientific misconceptions and misconceptions introduced
during the teaching process – so-called didaskalogenic
misconceptions. The tool CIs use for testing misconceptions
is known as distractors. Basically, distractors are the answer
choices, which are specifically designed to imitate typical
misconceptions. Summarizing, a CI test is a multiple-choice
test consisting of problems with “distractors” as incorrect
options that represent typical
misconceptions. Typical
multiple-choice
problems
of
this
type
would
be:
The following are temperatures for a week in August:
94, 93, 98, 101, 98, 96, and 93.
By how much could the highest temperature increase
without changing the median?
A. Increase by 8°
B. Increase by 2°
C. It can increase by any amount
D. It cannot increase without changing the median.
To answer this question, a student needs nothing more
than to understand the concept of median. Yet, at the same
time, the problem does check for typical misconceptions,
providing possible answers that conform to concepts of
midrange or mean. Indeed, option D would be true if the
question would be about midrange or mean, not about
median and is, therefore, a typical example of a “distractor.”
The first CI was developed and published by David
Hestenes in 1992 [17]. It is known now as the Force
Concept Inventory (FCI) and covers Newtonian Mechanics
concepts. It had immediate success and was recognized and
accepted by thousands of educators. Hestenes coined the
term “modeling” to describe the conceptual approach to
teaching – as opposed to the traditional factual approach. By
now
“modeling”
approach
covers
well
over
100,000
students each year. As a result of CI’s popularity, the
American Modeling Teachers Association (AMTA) was
created and grew into a nationwide community. Moreover,
CIs began in various fields of engineering, science and
mathematics.
CI assessment in introductory and prerequisite classes
was studied, in particular in [8][9][12][20][22]. With CI the
subject specific background of a given student is not
significant as stated above because CIs do not test formal
knowledge, but rather test the student’s understanding of
related concepts, which is the student’s working knowledge.
An understanding of related concepts is exactly what is
needed
in
prerequisite
classes.
Mastering
prerequisite
material at a working knowledge level in order to apply it to
the upcoming class.
Another advantage of using Cis in that they are already
developed for a wide variety of the subjects including, but
not limited to:
58
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-764-1
eLmL 2020 : The Twelfth International Conference on Mobile, Hybrid, and On-line Learning

1)
Natural Sciences:
a)
Physics
i)
Force and Motion
ii)
Electricity and Magnetism
iii) Statics
b)
Chemistry
c)
Geoscience
2)
Engineering
a)
Material Sciences
b)
Fluid Mechanics
3)
Life Sciences:
a)
Basic Biology
b)
Natural Selection
c)
Genetics
4)
Mathematics & Statistics:
a)
Calculus
b)
Statistics
Therefore, there already exist large depositories of test
problems for many subjects in case a need to create a
prerequisite class for one of such subjects.
The last aspect – the interactive, self-paced form of the
class – can be addressed only through the use of technology.
B. Existing Interactive Online Systems
By now numerous Interactive Online Systems exist,
including ALEKS [24], Cengage WebAssign [25], Knewton
[26], Pearson MyMathLab Study Plan [27], Acrobatiq [28],
Adapt
[29],
etc.
All
these
systems
offer
self-paced
automatically graded classes for various subjects. Typically,
each such class offers an Initial Assessment and then, based
on the output each student gets, activities and learning
material to work on with regular re-assessments to check on
progress. Such re-assessment outputs, in turn, are again used
to adjust the assigned activities and learning material.
For instance, ALEKS provides the following self-
description: “ALEKS uses adaptive questioning to quickly
and accurately determine exactly what a student knows and
doesn't know in a course. ALEKS then instructs the student
on the topics she is most ready to learn. As a student works
through a course, ALEKS periodically reassesses the
student to ensure that topics learned are also retained.
ALEKS courses are very complete in their topic coverage
and ALEKS avoids multiple-choice questions. A student
who shows a high level of mastery of an ALEKS course
will be successful in the actual course she is taking.”
According to [18], “When asked if there are pieces of
the traditional classroom setting that are lost in an online
course, the overwhelming response by all recipients was the
lack
of professor
to
student
and
student
to
student
interaction and communication.”
However, the classes based on such systems have
several advantages over traditional classes. Such advantages
include flexibility, adjustability to a student’s knowledge
base, pace, availability of various learning tools, timely
feedback, etc. And as stated in [18], “All respondents
unanimously answered that they would take an online
course in the future, regardless of the challenges that they
may have experienced.”
The
largest
summary
of
online
vs.
classroom
comparison research [19] concludes that “students in online
conditions performed modestly better, on average, than
those learning the same material through traditional face-to-
face instruction. Learning outcomes for students who
engaged in online learning exceeded those of students
receiving face-to-face instruction, with an average effect
size of +0.20 favoring online conditions.”
At
the
same
time,
the
same
source
states
that
“instruction combining online and face-to-face elements had
a larger advantage relative to purely face-to-face instruction
than did purely online instruction. The mean effect size in
studies comparing blended with face-to-face instruction was
+0.35, p < .001.” The existing systems, however, all
emulate traditional classes in terms of curricula and syllabi.
The only difference is the form in which the material and
assessment are presented.
On the one hand, it makes the comparison quoted above
reliable since there is an objective expected output for each
curriculum – and the only difference is the form of
presenting the material. Indeed, according to the study itself
“analysts examined the characteristics of the studies in the
meta-analysis to ascertain whether features of the studies’
methodologies could account for obtained effects. Six
methodological
variables
were
tested
as
potential
moderators: (a) sample size, (b) type of knowledge tested,
(c) strength of study design, (d) unit of assignment to
condition, (e) instructor equivalence across conditions, and
(f) equivalence of curriculum and instructional approach
across conditions. Only equivalence of curriculum and
instruction emerged as a significant moderator variable (Q =
6.85, p < .01).”
On the other hand, simply emulating the existing
traditional classes does not allow the online interactive form
to use completely its intrinsic advantages. We do believe
that prerequisite classes can benefit more from advantages
that the online interactive form offers.
While a variety of platforms exist for creating online
accessible interactive classes, Jupyter Notebook looks to be
one of the best fits here. Jupyter Notebook makes it easy to
start, further develop, and support a class. It is also quite
easy to create interactive auto-graded assignments using
Jupyter Notebook.
As stated in [1], “Project Jupyter is three things: a
collection of standards, a community, and a set of software
tools. Jupyter Notebook, one part of Jupyter, is software that
creates a Jupyter Notebook. A Jupyter Notebook is a
59
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-764-1
eLmL 2020 : The Twelfth International Conference on Mobile, Hybrid, and On-line Learning

document that supports mixing executable code, equations,
visualizations, and narrative text. Specifically, Jupyter
Notebooks allow the user to bring together data, code, and
prose, to tell an interactive, computational story. Whether
analyzing a corpus of American Literature, creating music
and art, or illustrating the engineering concepts behind
Digital Signal Processing, the notebooks can combine
explanations
traditionally
found
in
textbooks
with the
interactivity of an application.”
To summarize, Jupyter Notebook allows putting together
a comprehensive custom-tailored text using both newly
written lectures and excerpts from existing textbooks while
also supplementing the text with interactive auto-graded
assignments.
Putting
these
three
aspects
together
facilitates
the
creation of prerequisite classes that cover only the material
really needed and taught in a conceptual form, assessed using
the CI approach and put in a form of a self-paced interactive
online class using Jupyter Notebook, or a similar platform.
III.
LINEAR ALGEBRA AS A PREREQUISITE COURSE FOR
MACHINE LEARNING
The LA prerequisite class for Machine Learning class is
an online interactive self-paced class built on the Jupyter
Notebook platform. The lectures are based on “Linear
Algebra Review and Reference” by Zico Kolter and consist
of four chapters:
1.
Basic Concepts and Notation
2.
Matrix Multiplication
3.
Operations and Properties
4.
Matrix Calculus
The material presents basic definitions and concepts of
LA necessary for studying Machine Learning. Each chapter
is divided into smaller sections. For example, the “Matrix
Multiplication” chapter is divided as follows:
2.1
Vector-Vector Products
2.2
Matrix-Vector Products
2.3
Matrix-Matrix Products
Each
section
is
supplemented
by
an
auto-graded
assessment based on CI principles.
A typical problem for Basic Concepts would be:
Find the dimensions of the matrix
ܣ= ቂ1
2
3
4
5
6ቃ
A.
2x3 (*)
B.
3x2
C.
1x6
D.
6x1
Option A is a key since the matrix has two rows and
three columns.
Option B is a distractor that checks for a misconception
that mixes rows with columns.
Option C is a distractor that checks for a misconception
that considers a matrix as one long row with six elements.
Option D is a distractor that checks for a misconception
that considers a matrix as one long column with six
elements.
Another typical example:
Matrix
ቂ−1
0
0
2ቃ
has eigenvalues:
A.
-1 and 0
B.
-1 and 2 (*)
C.
0 and 2
D.
It has no eigenvalues
Option B is a key since (-1-x)(2-x)-0·0=0 has two roots:
-1 and 2.
Option A is a distractor that checks for a misconception
that defines the eigenvalues as the values of the first row
elements.
Option C is a distractor that checks for a misconception
that defines the eigenvalues as the values of second row
elements.
Option D is a distractor that checks for a misconception
that defines a characteristics polynomial as -1·2-(0-x) (0-x).
In the final version assessments will be based on a
sufficiently large pool of problems and will be randomly
generated for each student and for each attempt.
A student is able to take this class any time before taking
the Machine Learning class, at the pace that fits her or his
schedule and degree of prior knowledge. In addition to the
lectures, we include the option of having students ask the
instructor questions or discussing any aspect of the class
60
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-764-1
eLmL 2020 : The Twelfth International Conference on Mobile, Hybrid, and On-line Learning

with other classmates. Each assessment is auto graded but
also can be graded by the instructor in case a student
challenges the grade.
IV.
SYSTEM IMPLEMENTATION
The system was initially implemented on Cloud 9
(currently Amazon c9) virtual machines with 20 Gb. hard-
drive and 2 Gb RAM running Ubuntu v. 14, with Python
3.6,
miniconda
and
installation
of
JupyterHub
with
nbgrader.
Installation was almost straightforward, the only issue
being restriction on use of miniconda instead of full
anaconda installation. This is due to restriction of the
provided hard-drive size. The main benefit of the system
was its low cost: VMs are available for free from AWS. We
would like to thank Amazon for providing Cloud based
virtual hardware. This essentially made our work possible.
While
sufficient
for
development,
the
system
nonetheless had performance issues. Thus, we had a choice
either to proceed to paid Cloud based virtual machines or
moved to dedicated home hosted hardware. Our choice was
to move the developed system to a Lenovo P-520C
workstation with Intel Xeon 6 core W-2133 Processor with
vPro, 32 Gb. of RAM with dual hard-drive 512 Gb SSD and
2 Tb. HDD and 2 GB Nvidia P2000. This PC configuration
proved to be sufficient to run up to 200 test students. We did
not try IOCI to stress the system to run for more students.
V.
EVALUATION OF THE APPROACH
We evaluated standard and interactive approaches by
running parallel classes for over 30 graduate students taking
the Machine Learning course. Half of the students studied
the LA prerequisite material in the form of provided reading
material. Another half used the interactive Jupyter/nbgrader
online system, with a built-in auto-graded CI based tests
provided for both self and regular assessment. We ran pre-
and post- preparation CI-based tests that check the required
comprehension of the LA material as well as a one-question
survey for both instructors and students. The survey seeks to
discover if the student/instructor prefers reading material or
an interactive prerequisite course. An outline of the
measurements approach may be found in [19]-[21][23].
Both classes offered a sample that shows prerequisite
materials used by their counterparts. Both tests and survey
showed a statistically significant preference of interactive
prerequisite materials for students with 5% significance
level.
Tests results analysis is summarized in Table 1 and uses
standard t – test with a different standard deviation for
testing if one of the means is larger than the other. The value
of the test t shows statistical significance with a confidence
level of α = 5%.  Here the value df is degree of freedom, d is
value of statistics, t is value of t-test corresponding values d
and df.
TABLE I. ONE SIDED TWO MEANS T-TEST FOR GRADES IOCI VS
READING
IOCI
Read
N
16
15
mean
88
84
std
6
6.75
df (degree of freedom)
28.05503
d (see formula (1))
1.739542
t
0.046462
Survey preference is analyzed in Table 2 using small
samples t-test for population proportion, see [14][15]. A
summary of analysis is offered below in the Table 2. Here,
the value of N-2 is the degree of freedom, the value d is
calculated as [14][15]:
݀ = (ܽ݁ − ܾܿ) ቀ
ேିଶ
ே(௡௔௖ା௠௕௘)ቁ
భ
మ
(1)
and values of the variables a, e, b, c, N, n, m used in the
formula are the corresponding ones in the numerical data
below.
TABLE II. SMALL SAMPLES T- TEST FOR POPULATION
PROPORTIONS COMPARISON
IOCI Users
Read Users
Total
Prefer IOCI
a = 14
b = 8
s = 22
Prefer Read
c = 2
e = 7
f = 9
Total
m = 16
n = 15
N = 31
N-2
29
d
2.186271331
t
0.018506791
A similar implementation with similar results (translation
of the material into Russian) was done at the National
University of Science and Technology, MISIS (Moscow).
VI.
CONCLUSION AND FUTURE WORK
The issue of prerequisites impacts many STEM courses
because many major courses require a deep understanding
of Mathematics, Statistics, etc. This may be challenging in
situations where graduate students wish to enroll in major
courses at the start of their studies. We encountered such a
situation with Machine Learning courses, which require
knowledge (or at least a conceptual understanding and
hands-on ability) of LA, Matrix Calculus, Probability and
Statistics. Standard approaches require that students wait a
61
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-764-1
eLmL 2020 : The Twelfth International Conference on Mobile, Hybrid, and On-line Learning

year during which they complete all prerequisites or attack
prerequisites as reading material. As the latter approach has
several disadvantages, we decided to make prerequisite
material
more
attractive
by
implementing
it
using
JupyterHub and nbgrader as a self-study interactive course
with auto-grading. CIs are used to check how well students
understand the material. Students have access to self-check
exercises and feedback; instructors can monitor student’
success and, if needed, recommend some adjustments. We
ran it on an experimental group of students, and both
students and instructors prefer this form of study over
reading material.
We would like to emphasize that this approach can by
no means compare in depth and outcome to regular courses
on the topic. As we saw in multiple cases, this approach is
used mainly because of students schedule conflicts or a
desire to expose students to major courses as soon as
possible.
We plan to run the LA prerequisite course by larger
numbers
of
instructors
and
students
and
incorporate
comments and suggestions from all participants. We further
intend to offer the course as open source available to anyone.
REFERENCES
[1]
L. A. Barba et al., “Teaching and Learning with Jupyter”,
https://github.com/jupyter4edu/jupyter-edu-book,
retrieved
January, 2020
[2]
F. Perez and B. E. Granger, "IPython: A System for
Interactive Scientific Computing," in Computing in Science &
Engineering, vol. 9, no. 3, pp. 21-29, 2007.
[3]
F. Perez, B. E. Granger, and J. D. Hunter, "Python: An
Ecosystem for Scientific Computing," in Computing in
Science & Engineering, vol. 13, no. 2, pp. 13-21, March-April
2011.
[4]
K.J. O'Hara, D.S. Blank, and J.B. Marshall, "Computational
Notebooks for AI Education", Proceedings of FLAIRS, pp.
263-268, 2015
[5]
S.
Freeman
et
al.,
“Active
learning
increases
student
performance in science, engineering, and mathematics.”
Proceedings of the National Academy of Sciences, 111(23),
pp. 8410–8415, 2014.
[6]
M. G. Moore, "Three types of interaction", The American
Journal of Distance Education 3(2), pp. 1-6, 1989.
[7]
J.
Libarkin,
"Concept
inventories
in
higher
education
science." BOSE Conf. pp. 1-10, 2008.
[8]
G. Ya. Grabarnik, M. Guysinsky, and S. Yaskolko. "An
integrated approach to using statistics concept inventories in
instruction" Integrated STEM Education Conference (ISEC),
2014 IEEE.
[9]
S. Krause, J. C. Decker, and R. Griffin, “Using a materials
concept inventory to assess conceptual gain in introductory
materials engineering courses”, Frontiers in Education, 2003.
FIE 2003 33rd Annual, Volume 1, pp 7-11.
[10] B. K. Sato et al., "What’s in a Prerequisite? A Mixed-
Methods Approach to Identifying the Impact of a Prerequisite
Course", CBE Life Sci Educ. 2017 Spring; 16(1): ar16
[11] J. Epstein, The Calculus Concept Inventory — Measurement
of the Effect of Teaching Methodology in Mathematics,
Notices of the AMS Volume 60, N. 8, 2013, pp 1018-10.
[12] G. Ya. Grabarnik, and S. Yaskolko. "Teaching statistics to
non-mathematics majors: Interdisciplinary integration with R
and
EDA."
2013
IEEE
Integrated
STEM
Education
Conference. IEEE, 2013.
[13] G. Ya. Grabarnik, L. Kim-Tyan, S. Yaskolko, "Improving
STEM’s
Calculus
education
using
cross-countries
best
teaching practices." 2018
IEEE
Frontiers in
Education
Conference (FIE). IEEE, 2018.
[14] R. B. D'Agostino, W. Chase, and A. Belanger, 1988.'The
Appropriateness of Some Common Procedures for Testing the
Equality of Two Independent Binomial Populations', The
American Statistician, August 1988, vol. 42, no. 3, pp. 198-
202.
[15] G. J. G. Upton, "A comparison of alternative tests for the 2
times 2 comparative trial." Journal of the Royal Statistical
Society: Series A (General) 145.1 , 1982, pp. 86-105.
[16] A system for assigning and grading Jupyter Notebooks.
https://github.com/jupyter/nbgrader, retrieved Jan. 2020.
[17] D. Hestenes, Force concept inventory. The Physics Teacher,
30(3), 1992, p. 141.
[18] Gilbert, Brittany, Online Learning Revealing the Benefits and
Challenges,
St.
John
Fisher
College
Fisher
Digital
Publications,
http://fisherpub.sjfc.edu/cgi/viewcontent.cgi?article=1304&co
ntext=education_ETD_masters, retrieved Jan. 2020.
[19] U.S.
Department
of
Education,
Office
of
Planning,
Evaluation, and Policy Development, Evaluation of Evidence-
Based Practices in Online Learning: A Meta-Analysis and
Review of Online Learning Studies, Washington, D.C., 2010.
https://www2.ed.gov/rschstat/eval/tech/evidence-based-
practices/finalreport.pdf, retrieved Jan. 2020.
[20] D. Sands, M. Parker, H. Hedgeland, S. Jordan, and R.
Galloway,
Using
concept
inventories
to
measure
understanding. Higher Education Pedagogies, 3(1), 173-182.
2018.
[21] C. Evans, K. Howson C, and A. Forsythe, Making sense of
learning
gain
in
higher
education.
Higher
Education
Pedagogies. 2018 Jan 1;3(1), pp.1-45.
[22] A. Madsen, S.B. McKagan, and E.C. Sayre, Best practices for
administering concept inventories. The Physics Teacher. Dec.
2017, 55(9). pp. 530-6.
[23] P. Gossman and S. Powell, Learning Gain: Can It Be
Measured?.
InEmployability
via
Higher
Education:
Sustainability as Scholarship 2019, pp. 37-51. Springer,
Cham.
[24] ALEKS, www.aleks.com, accessed Jan. 2020.
[25] WebAssign, WebAssign.net, accessed Jan. 2020.
[26] Knewton, www.knewton.com, accessed Jan. 2020.
[27] MyLab
Math,
Pearson,
www.pearsonmylabandmastering.com, accessed Jan. 2020.
[28] Acrobatiq, acrobatiq.com, accessed Jan. 2020.
[29] Adapt, https://www.adaptlearning.org/, accessed Jan. 2020.
62
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-764-1
eLmL 2020 : The Twelfth International Conference on Mobile, Hybrid, and On-line Learning

