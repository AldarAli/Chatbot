Introduction to being a Privacy Detective: Investigating and Comparing Potential
Privacy Violations in Mobile Apps Using Forensic Methods
Stefan Kiltz and Robert Altschaffel and Thorsten Lucke and Jana Dittmann
Otto von Guericke University Magdeburg
Magdeburg, Germany
Email: Kiltz@iti.cs.uni-magdeburg.de
Abstract—This paper discusses means to evaluate the potential
impact of data ﬂows caused by the use of smartphone apps
(applications) on the privacy of the user. While the data ﬂows
are often caused by trackers, permissions set the framework on
which data can ﬂow between the smartphones and the remote
party. Hence, we devise a concept to examine privacy violations
caused by trackers and permissions in mobile apps and to render
the results of said examination more comparable and reliable
based on the characteristics of the examination methods (custody,
examined forensic data streams and type of communication).
We deﬁne two different examination scenarios in which this
approach can be deployed and conduct practical tests in these
two scenarios. For the ﬁrst scenario, the concept is applied to
the static evaluation of 8 exemplary mobile apps running on
the Android platform using 3 different methods (Exodus Privacy,
Exodus Standalone and AppChecker) identifying 162 permissions
and 42 trackers in total. The second scenario employs these three
methods in order to examine the extent to which three mobile
browsers reveal information towards the respective developers.
Our main contributions are the application of a model of the
forensic process to the examination of the loss of potential privacy
due to the use of mobile apps in order to provide comparability
of the ﬁndings. In addition, a proposal for a visualization scheme
capable of displaying test results from privacy examinations
covering a large number of examination items is proposed.
Keywords–Privacy Measurement; Data sovereignty.
I.
INTRODUCTION
Privacy and data protection are very relevant topics from
a legal and data sovereignty perspective. While the legal
perspective is no part of this paper, the Principles relating
to processing of personal data of Article 5 of the GDPR[1]
provide a useful overview on the topic of privacy related data.
These principles include data minimisation, storage limitation
and lawfulness, fairness and transparency - principles often
not used in app deployment, most apps contain trackers [2].
This paper aims at supporting privacy and data protection
by providing the user with methods to identify data ﬂows
caused by the use of mobile apps (executed on the smart-
phone), which could threaten the privacy. Knowledge about
these data ﬂows is essential to obtain some degree of data
sovereignty. These data ﬂows could be used by third parties to
identify customers, create proﬁle, send targeted advertisement
(including those leading to generally known negative social
consequences like advertisement for alcohol or micro-targeting
during political campaigns) or exclude customers from services
based on their liquidity. In addition, these trackers use unnec-
essary resources (e.g., CPU power, bandwidth, energy) without
a beneﬁt to the user and the environment. This increased need
for resources also leads to a more negative global ecological
footprint.
The discussion whether certain data ﬂows violate the right
of privacy of an user relies on legal background and a review
of the relevant laws. However, this paper focuses on a purely
technical approach based on the technical properties we can
identify. However, knowledge about the presence of these data
ﬂows is by itself a necessary requirement to achieve data
sovereignty. This is of relevance when deciding whether an
app is appropriate for a given use case, e.g., the use in an
educational or corporate setting. In these scenarios, a teacher
or IT specialist could be the data detective identifying various
trackers.
This knowledge can be used to prevent privacy-related
leakage. Users can prevent trackers by using various blocking
mechanisms like NoScript [3] or the use of a Pi-hole [4].
However, these mechanisms all have their limitations and
require installation and conﬁguration for use. The knowledge
about tracker detection techniques has other uses; developers
of apps can also use the knowledge about trackers within their
apps to remove such trackers, introduced by e.g., software
development kits or libraries.
A necessary property to identify trackers is the destination
of a given data ﬂow. During the course of this paper, we
identify two different potential destinations for data ﬂows
common in the use of mobile apps:
•
Data ﬂow to the service provider (DFfp)
•
Data ﬂow to a third party (DFtp)
The second property catches the aspect of whether the
data ﬂow is necessary in order for the app to provide the
functionality. Either the app is able to provide the functionality
without this data data or it is not. Hence, we can further specify
the potential data ﬂows:
•
Data ﬂow to the service provider necessary for the
functionality of the app (DFfp.req)
•
Data ﬂow to the service provider not necessary for the
functionality of the app (DFfp.nrq)
•
Data ﬂow to a third party necessary for the function-
ality of the app (DFtp.req)
•
Data ﬂow to a third party not necessary for the
functionality of the app (DFtp.nrq)
A common example for those data ﬂows unnecessary to
provide the functionality intended by the user include trackers.
60
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

These trackers are embedded into many apps in order to gather
data about the user and the use patterns of the given tools.
This is often used as a foundation for the identiﬁcation of
users which can in turn be used for ads targeted at speciﬁc
users. These trackers pose a risk to the privacy of the user. In
disconnect-tracking-protection [5] a detailed description based
on a technical review is given as to why a speciﬁc item is
listed as a tracker and might be used as guideline to discern
whether the data ﬂows identiﬁed using the approach in this
paper are threats to privacy.
For the sake of simplicity, we refer to any data ﬂow not
necessary to provide the functionality intended by the user as a
tracker during the course of this paper. Various tools designed
to identify these trackers are available with an overview on
these provided in Section II-C. A fundamental problem is
that the results provided by these tools are not comparable.
This increases the difﬁculty of verifying the results provided
by one such tool through the use of a different tool. This is
due to different underlying criteria used for the identiﬁcation
of trackers and a varying degree of documentation provided
to the examiner by these tools. This paper explores the use
of a structured investigative approach as used in the ﬁeld of
computer forensics to achieve this comparability in ﬁnding
unnecessary data ﬂows.
However, the absence of any unnecessary data ﬂows does
not guarantee the absence of risk for the user’s privacy. For
example, the service provider could aggregate DFfp.req or
DFtp.req over the course of various requests and compile
them to form an user proﬁle. However, the data that could be
transferred is limited by the access the speciﬁc app has to the
operating system. This is controlled by permissions. Hence,
identifying these permissions offers additional information
relevant to judge potential data protection violations.
In general, we identify two different scenarios in which the
approach presented in this paper can be used:
•
Examination Scenario 1 (ES1): one (or multiple)
app(s) are examined for trackers and permissions
•
Examination Scenario 2 (ES2): various alternative
apps for a speciﬁc use case are compared with regards
to potential privacy violations
Due to the complexity of this topic this paper focuses
on the identiﬁcation of the four formerly deﬁned data ﬂows
during the use of mobile apps as well as the permissions
used by these apps. In order to achieve this goal, this paper
is structured as follows: Section II gives an overview on
the domain investigated in this paper, the current tools used
to identify trackers and permissions in mobile apps and the
structured approach to perform an investigation as used in the
ﬁeld of computer forensics. Section III applies the structured
approach of a forensic investigation to the identiﬁcation of
trackers (and data ﬂows in general). This includes a discussion
on how the tools detecting trackers and identifying permissions
work in detail and how this type of examination is currently
conducted showing the challenges of the speciﬁc domains
in question. Section IV describes the creation of a testbed
which includes the tool sets necessary to conduct such an
investigation following the structured approach. It also shows
how this testbed is then used to identify and categorize various
data ﬂows during the use of eight selected exemplary mobile
apps in ES1. In addition, three exemplary selected different
browser are compared as an example for ES2 providing a more
in-depth comparison on what the achieved results reveal about
potential violation of the user privacy by the use of these apps.
This paper closes with an overview and an outlook provided
in Section V.
II.
FUNDAMENTALS
This section provides some background helpful to follow
the discussions laid out during the subsequent chapters. An
overview on the various approaches to evaluate the privacy of
websites and apps is provided. This includes the identiﬁcation
of various data ﬂows. In addition, the properties speciﬁc to
apps in the mobile domain affecting the identiﬁcation of
trackers are explored.
A. Exemplary selection of approaches to evaluate the privacy
of websites and apps
Several approaches to determine the privacy and IT security
of websites exist. In [6] a system to improve the privacy and
IT security is described, which analyses selected privacy and
IT security aspects. A special feature of the resulting analysis
site privacyscore.org [7] is that arbitrary users can supply a
single URL to be tested or a list thereof (crowd-sourced list).
The system design allows revisiting those existing URL(s) and
thus enables an analysis of the privacy and IT situation of said
URL(s) over time and for privacyscore.org users alike.
One empirical study to systematically determine the pri-
vacy and IT security of apps for the android operating envi-
ronment is described in [2]. It reveals that most apps contain
trackers, that the tracking is category-sensitive and a highly
trans-national phenomenon. A guideline on how Apps are
tested for trackers is provided by various sources. One example
includes mobilsicher.de [8] which provides an outline of their
approach in German.
B. Mobile Apps
The topics discussed in this paper are also relevant in the
domain of desktop computer systems. Indeed, some of the
concepts presented in this paper can be transferred to this
domain. However, for the sake of brevity, this paper focuses
on the mobile domain in order to discuss some of the speciﬁc
challenges of this domain when investigating potential privacy
leaks. Hence, for the course of this paper, an app(lication)
refers to any type of application that is executable on a
smartphone and which is distinguishable from the operating
environment (for example in that it is downloaded or updated
separately).
Apps use the resources of the smartphone as provided by
an underlying operating system. During the course of this
paper, all apps examined and methods used are running on the
Android platform [9]. This does not represent any inclination
of the authors towards this platform nor should it indicate
that the methods used in this paper are not applicable to
different platforms. In the case of Android operating systems,
the access of the apps is restricted by the use of various
permissions. Permissions describe the access rights granted
for a speciﬁc app. In essence, they restrict access to given
information. Examples include the access to camera or the
address book. Hence, these permissions are useful to discern
which information could be communication within the speciﬁc
data ﬂows.
61
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

C. Methods to identify data ﬂows
Identifying data ﬂows forms the foundation of identifying
potential privacy violations. Two principal approaches exist to
identify such data ﬂows in mobile apps. These approaches are
implemented in various tools but these tools represent insulated
solutions rather than a comprehensive approach providing
comparable results.
a) Static Analysis: Static Analysis describes analysis
performed by investigating the binary representation of an
app. This binary representation can be interpreted in order to
identify certain functions. Trackers for example usually employ
a set of speciﬁc function calls or employ communication to cer-
tain known servers. Such patterns are referred to as signatures.
As long as the signature for a given tracker is known, it can
be identiﬁed. The complexity of this interpretation depends on
the complexity of the programming technology used to develop
the app. Some apps might use standardized development tools
while others might have their binary formats obfuscated to
prevent such analysis.
A tool implementing static analysis of mobile apps is
Exodus Privacy [10]. The characteristics and the operations
methods of this tool are described in III-B. The tool is then
used during the case study as described in IV-B providing
insight into its use and usefulness.
b) Dynamic Analysis: Dynamic Analysis investigates
the runtime behaviour of an app during its execution. In the
context of this paper, this mostly includes the communication
behaviour of the app. Hence, the data ﬂows are observed while
they occur. A tool useful for the capturing of data ﬂows is
Wireshark [11].
c) Speciﬁcs of mobile apps relevant during examina-
tion: There are some factors which impact the capabilities to
examine apps in the mobile domain:
•
Prop1: large amount of background processes: in
general, many background processes are active on a
mobile system implying the presence of background
noise which must be taken into account
•
Prop2: very low control over operating system: mobile
operating systems generally limit the user in the access
to various system information
•
Prop3: standardization of development tools: apps are
developed using standard frameworks and languages
which makes analysis easier
•
Prop4: reliance on system functions: apps often use li-
braries and operating system calls which are protected
or obfuscated against analysis
•
Prop5: apps contain a manifest: this gives some
information about the use of certain system permission
by the app, but practical tests have shown that these
are not necessarily conclusive
•
Prop6: various variants: there are usually various
variants of apps in the mobile domain compiled for
various architectures and operating systems with a
potentially different behaviour in regards to data ﬂows
•
Prop7: App bundles: sometimes these different vari-
ants are combined into an App Bundle which includes
various resources necessary in order to create a device
speciﬁc installation
Prop1 and Prop2 have a negative impact on the capabilities
to perform dynamic analysis in the context of mobile apps,
while Prop5 eases the complexity of of detecting permissions
during static analysis. Prop6 and Prop7 raise the difﬁculty of
obtaining the correct binary for analysis in the ﬁrst place. Here,
the use of checksums and other methods in order to identify
the speciﬁc binaries is necessary.
D. The structured approach of Computer Forensics
According to [12] computer forensics is The use of scien-
tiﬁcally derived and proven methods toward the preservation,
collection, validation, identiﬁcation, analysis, interpretation,
documentation and presentation of digital evidence derived
from digital sources for the purpose of facilitating or furthering
the reconstruction of events found to be criminal, or helping
to anticipate unauthorized actions shown to be disruptive to
planned operations.
Such an approach implies the use of proven methods in
a structured process in order to document various traces with
the overall aim to present them in a manner which enables a
person reviewing the result to form a well-founded conclusion
based on these traces. When investigating potential privacy
violations during the use of mobile apps the same traceability
and comparability of the results is intended. Hence, methods
from the ﬁeld of computer forensics could potentially be used
to achieve this.
In general, computer forensic investigations follow a struc-
tured process. This process is often described by forensic
process models. During the course of this paper, we employ
a forensic process model based on the one described in [13]
(which is based on [14]) as it offers some advantages for the
task at hand.
This forensic process model structures the forensic process
along the lines of six Investigation Steps. A main advantage
of this forensic process model is the inclusion of a Strategic
Preparation (SP) which covers measures taken by the operator
of an IT-system in order to support a forensic investigation
prior to an incident [14].
The forensic traces originate from three distinct forensic
Data Streams as described in [15]. These data streams identify
the various sources of forensic evidence within the forensic
process and assign general properties to these sources:
•
Non-volatile Memory: Memory inside a computing
unit which maintains its content after the unit is dis-
connected from its respective power supply. (denoted
as DST in this paper)
•
Volatile Memory: Memory inside a computing unit
which loses its content after the unit is disconnected
from its respective power supply. ( denoted as DSM)
•
Communication: All the data transmitted to other
computing units via communication interfaces. (de-
noted as DSN)
The potential traces relevant during the forensic investiga-
tion are categorized into nine Data Types based on how the
respective data is handled during the forensic process. The
following relevant Data Types are identiﬁed in [13]:
•
hardware data (DT1): Data in a computing unit which
is not, or only in a limited way, inﬂuenced by software.
62
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

•
raw data (DT2): A sequence of bits within the data
streams of a computing systems not (yet) interpreted.
•
details about data (DT3): Data added to other data,
stored within the annotated chunk of data or externally
•
conﬁguration data (DT4): Data which can be changed
by software and which modiﬁes the behaviour of
software and hardware, excluding the communication
behaviour
•
network conﬁguration data (DT5): Data that modiﬁes
system behaviour with regards to communication
•
process data (DT6): data about a running software
process within a computing unit
•
session data (DT7): data collected by a system during
a session, which consist of a number of processes with
the same scope and time frame
•
application data (DT8): data representing functions
needed to create, edit, consume or process content
relied to the key functionality of the system
•
functional data (DT9): data content created, edited,
consumed or processed as the key functionality of the
system
Six Classes of Methods describe the requirements for the
use of the various forensic methods by categorizing them
based on what kind of software provides said method. This
corresponds to the use of speciﬁc tools (or tool chains) in order
to investigate a certain type of data. Some of these classes of
methods deﬁned in [14] are relevant for this paper. These are
the Operating system (OS - methods provided by the operating
system [...]), Explicit means of intrusion detection (EMID -
methods provided by additional software [...] being executed
autonomously on a routine basis and without a suspicion of
an incident), IT application (ITA - methods provided by IT-
Applications that are operated by the user [...]) and Scaling
of methods for evidence gathering (SMG - methods to further
collect evidence to be used if a suspicion is raised [...]).
III.
STRUCTURED APPROACH TO INVESTIGATE AND
COMPARE POTENTIAL PRIVACY VIOLATIONS IN MOBILE
APPS
In this section, the approach for digital forensics discussed
in Section II-D is applied to achieve comparability between
the various methods to examine third and ﬁrst party tracking
employed in mobile apps.
A. System landscape analysis and its resulting forensic process
as part of Strategic Preparation (SP) and its impact on
comparability
The investigation step of Strategic Preparation (see Section
II-D) plays a decisive role during this process in trying and
testing the measures ahead of an incident and setting the
system boundaries of systems which are examined and those
used for examination. Hence, this step directly impacts the
results and their credibility. Setting these boundaries is done
during a system landscape analysis. Such an analysis for
our use case of identifying third and ﬁrst party tracking by
apps via employing static analysis is depicted in Figure 1.
It also introduces a possible extension enabling the analysis
of websites. The system landscape analysis allows for the
identiﬁcation of various characteristics in which the employed
Website Evidence 
Collector 
Internet
Privacy 
Examiner's 
System
Tested Provider's 
System 
(dynamic)
Privacy 
Examiner's 
System
T
AppChecker/
Exodus standalone
tested app
(static) 
DSN
DS
T
tested app
(dynamic) 
DS
N
Wireshark
tested webservice
(static/dynamic) 
DSN
T
tested webservice
(dynamic) 
DSN
privacyscore.org/
webkoll.dataskydd.net
Off-premises
On-premises
DS
T
tested app 
(static)
exodus-
privacy.eu.org
apps
websites
DT2
DT2
analysis 
report
DT4
DT5
analysis 
report
DT4
DT5
DT5
DT4
DT4
DT5
DT2
DT5
DT3
DT4
DT2
DT5
DT3
DT4
External
data
External
data
DT2
DT2
DT5
Figure 1. System landscape analysis of the examination of apps and
websites regarding ﬁrst and third party tracking using the categorization into
custody, data streams, and type of examination
methods differ. These characteristics carry some implications
on how these methods can be used in order to identify third and
ﬁrst party tracking. This affects the credibility of the results.
The ﬁrst identiﬁed characteristic is custody. This character-
istic encompasses two aspects. These aspects are custody over
the method used for the examination and custody over the
examination item which is an app in the context of this paper.
This custody can either be on-premises (the examiner has
custody over this component) or off-premises (another entity
has custody over this component). If two different methods
share the same characteristic in terms of custody, we refer
to them as intra-premises. If they differ in this respect, we
refer to them as inter-premises. Generally speaking, having
custody of these two aspects implies a greater control over
them and, hence, a higher credibility. Secondly, we identify the
data stream examined by the given method as another relevant
characteristic (see II-D for an introduction into the various
forensic data streams). A method could analyse the binary
obtained from the non-volatile memory (DST ), the volatile
memory obtained during the execution of a binary (DSM)
or the communication observed during execution (DSN).
Finally, we can categorize the type of examination into a static
examination (a single snapshot of the behaviour of the website
or the app) and a dynamic examination (a change in behaviour
of an app over time).
With our stated goal of achieving comparability of tools
and services for privacy examination, i.e., the sets of methods
63
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

from the model from [14], this categorization provides a struc-
ture supporting the comparability between various methods.
This is not affected whether these methods rely on the same
internal engine (intra-engine) or not (inter-engine).
B. Comparison of methods within the forensic framework
The forensic data types shown in Section II-D are generally
applicable to all data streams (see Section III-A and can be
used to indicate privacy issues (primarily by their presence
but also by their absence). Also they can be used to describe
the methods employed to identify and examine data ﬂows and
their respective actions in a comparable manner.
One such example is shown in Table I. This table provides
an overview on the three methods used for identifying trackers
and permission during this paper. It includes an intra-engine
comparison of two different means to employ the Exodus
Privacy Engine and well as an inter-engine comparison to a
third method.
The two means to employ the Exodus Privacy Engine are
Exodus Privacy ([10], in short: EPO) and Exodus Standalone
([16], in short: ESA). EPO is a web-based service which
runs remotely (off-premises). The user sends a request to the
service which then downloads an app (in form of an .APK
ﬁle) from the Google Play Store. Neither the method itself
nor the examination item are in the custody of the examiner.
ESA is a console application which runs on a local system and
is supplied with a local .APK ﬁle to examine (on-premises).
In this case, method and examination item in the custody of
the examiner. Both variants examine a binary ﬁle which has to
be downloaded and stored before the examination, hence the
data stream DST is examined. Both employ static measures
as its type of examination.
AppChecker ([17], in short: APC) provides an inter-engine
comparison. This tool is a console application running on a
local system (on-premises) with the method and examination
item being in the custody of the examiner. Again, it employs
static measures (type of examination) on a binary ﬁle (DST ).
With this in mind, a closer look on the exact nature of the
examination performed by these three methods is necessary
with a speciﬁc focus on comparability and documentation. In
both cases, access to the speciﬁc app (in form of an .APK)
is required. In the case of ESA and APC, this .APK might
already be available so the ﬁrst action is optional. Whether the
.APK has to be downloaded ﬁrst (in case of EPO), copied from
another medium or is already present on the examiners system,
it represents raw data (DT2). This .APK is then extracted to
reveal the binary (DT2) and the manifest which represents
information about this binary (DT3). Following this, various
pieces of information are extracted from the present data. The
binary (DT2) is searched for hosts and ip addresses leading to
a list of potential communication partners (representing DT5).
The manifest (DT3) is investigated in order to compile a list of
the various permissions the app is supposed to be granted by
the system it runs on (representing DT4). In the next step, both
lists are compared to external data which does not originate
from the examined source but contributes to the examination
result. This external data represents signatures which could
include hosts known to be used for advertisement. In essence,
these data represents a list of known trackers (in case of
host names or ip addresses) or unwanted permissions. This
leads to a reduced list of relevant trackers (DT5) or relevant
permissions (DT4). In the ﬁnal step, this data is then compiled
into a report.
While the operations are identical for each three methods,
the visibility to the examiner is different. In the case of ESA
and APC every action was performed locally and was hence
observable to the investigator. At every action, inputs and
outputs could be documented in detail. In the case of EPO
every action taking place after the process is started is not
observable for the examiner. The examiner has to rely on
the summary provided by EPO after the method is ﬁnished.
However, the use of EPO requires far less effort from the
examiner in terms of required resources.
TABLE I. FORENSIC DATA TYPES PROCESSED DURING THE
INTERNAL ACTIONS AND THEIR VISIBILITY TO THE EXAMINER
DURING STATIC ANALYSIS
Internal Action
Data Types
observable in ...
EPO - [10]
ESA - [16]
APC - [17]
Download .APK
DT2



Extract .APK
DT2, DT3



Binary: Extract Hosts
DT2 → DT5



Manifest: Extract
DT3 → DT4



Permission
Host: Compare
DT5, ext → DT5



Manifest: Compare
DT4, ext → DT4



Generate Report
DT4, DT5 →



Report
C. Visualization of examinations results
Since the tools and services (i.e., sets methods from
[14]) typically gather a large number of results, an efﬁcient
visualization of the results of their usage is paramount. This
visualization should support an easy comparison of different
methods and should be easily extensible with regards to new
result categories (horizontal view in Figure 2) and new tested
apps and websites (vertical view).
We choose a DNA-graph-style representation as it allows
for the additional integration of information regarding the data
type (e.g., URLs of known trackers as DT3 in the the network
data stream DSN, app permissions as conﬁguration data DT4)
using colouring/shading. A very important property of this
visualization type is that it also depicts the absence using
marked positions, which greatly supports the comparison of
different methods to examine potentially privacy violating data
ﬂows.
IV.
CASE STUDY
This section describes the creation of a test environment in
order to apply various methods to examine potentially privacy
violating data ﬂows in a sample of selected apps (ES1) or to
examine various alternative apps usable for web browsing with
regards to potential privacy violations (ES2).
A. Building a test environment
A test environment should fulﬁll a number of requirements
that apply to both dynamic and static tests (see Section II).
To ensure the authenticity of the tested app, it should be
acquired from the ofﬁcial distribution system. One means to
access these stores and extract the app as it was downloaded
is to use an Android Emulator such as the Emulator from
the ofﬁcial AndroidSDK [18] or using dedicated emulators
such as Genymotion [19]. If the option of shared access to
64
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

the emulated system is used, access to the ofﬁcial .APK of
a given app is possible. Thus, the app can be downloaded
from the ofﬁcial distribution and yet is accessible to the tools
for static evaluation by means of accessing the mass storage
of the emulated system. AppChecker and Exodus Standalone
as well as Exodus Privacy compute a SHA265 cryptographic
hash, enabling also an integrity check. The maintenance of
both security aspects are vital for the forensic process (see
Section II-D).
Although dynamic analysis is only included in a minor
role in this paper for the sake of brevity, a few short notes
for a successful conduct of such a structured examination
shall be provided. In this case, the creation of a ”low-noise”
environment is of great help for the examiner. Since in dy-
namic analysis the network trafﬁc is analysed, any interference
from other parts of the Android operating system should
be minimized. While we consider a complete exclusion of
all surplus network trafﬁc impossible with current mobile
operating systems, at least a reduced interference should be
achieved by the removal of all apps and services not needed
to execute a given app for testing.
B. (ES1): Testing eight different apps for potential privacy
violations
For the tests a set of eight different apps suited for use
in an educational institution was selected. The tests were
conducted using the guidelines provided in Section IV-A.
Genymotion 3.1.1 [19] was used on a Lenovo T61 Laptop
with 4GB RAM running Ubuntu18.04 [20]. The Android
emulator was run within a virtualized system (realized using
VirtualBox [21] with the necessary conﬁguration for shared
access to the virtual ﬁle system. The respective apps where
then downloaded from the respective Playstore on the emulated
phone (emulating an Android 7.1). The downloaded binary
ﬁle was then transferred using the Terminal App [22] to the
shared folder. Here, the sha256sum for the speciﬁc binary was
calculated and documented.
This binary was then examined using Exodus Standalone
and AppChecker. The execution of both methods can be
documented on the command line and the outputs created
can be stored. Since the SHA256 checksum of the binaries
are known, the results of these two methods running on-
premises can be compared to the results provided by the off-
premises method of Exodus Privacy. The three used methods
are explained in detail in Section III-B including the use of
forensic data types during the application of these methods.
The execution of all methods on the eight selected spec-
imen was successful. Based on the considerations for the
visualization made in Section III-C, the results are shown in
Figure 2. It shows the three different methods of investigations
for each of the eight different specimen as the rows while the
columns show the different identiﬁed trackers (DT5) and the
identiﬁed permissions (DT4). A colored box indicates that the
speciﬁc tracker or permission was identiﬁed within the speciﬁc
specimen using the speciﬁc method.
For the trackers, it is notable that there are very few intra-
engine differences between EPO and ESA. The exception is
Moodle, where EPO identiﬁes the Google Firebase Analytics
tracker and ESA does not. This might be due to a difference
in the list of known tracker signatures between these versions.
However, since no information on the exact version of this list
used is provided by the two methods, a further examination
is not possible. While ESA could be modiﬁed to store this
list of signatures for documentation purposes (due to being
open source and on-premises), this is not possible for EPO.
Generally, both methods provide the same results, albeit the
use of ESA provides for a better documentation on how these
results are achieved. There are, however, some notable inter-
engine differences in the results when compared to APC. This
can be seen, for example, with DropBox, or Shazam. The
reason here are different heuristics (including the signatures
for the identiﬁcation of trackers). An overview on these results
is provided in Table II. In general, there is usually a core of
trackers for any given app identiﬁed by all methods. Some
trackers are only found by EPO and ESA and some only by
APC. A review of the identiﬁed trackers show that all of them
fall under DFtp) since they represent connections to a third
party. Based on external knowledge about the speciﬁc names of
the identiﬁed trackers, these most likely all represent DFtp.nrq.
TABLE II. NUMBER OF IDENTIFIED TRACKERS DURING ES1 ON
EIGHT SELECTED APPS AS PERFORMED IN SECTION IV-B
Application Name
ESA
EPO
APC
common
and Version
to all
Corona-Warn 1.2.1
0
0
1
0
Dropbox 194.2.6
5
5
4
2
GuitarTuna 6.4.0
10
10
11
9
Moodle 0.0.0
0
1
2
0
Pixabay 1.1.3.1
2
2
2
0
QR & Barcode
5
5
6
4
Scanner 2.1.32
Shazam
4
4
5
2
10.38.0-200709
Signal 4.69.4
0
0
1
0
TABLE III. NUMBER OF IDENTIFIED PERMISSIONS DURING ES1
ON EIGHT SELECTED APPS AS PERFORMED IN SECTION IV-B
Application Name
ESA
EPO
APC
common
and Version
to all
Corona-Warn 1.2.1
8
8
8
8
Dropbox 194.2.6
23
23
23
23
GuitarTuna 6.4.0
9
9
9
9
Moodle 0.0.0
30
30
30
30
Pixabay 1.1.3.1
9
9
9
9
QR & Barcode
13
13
13
13
Scanner 2.1.32
Shazam
14
14
14
14
10.38.0-200709
Signal 4.69.4
65
65
65
65
For the permissions, the results are identical for all methods
applied to all apps as can be seen in Table II. This is based
on the reason that same approach for detecting permissions
is used by all these methods. All the methods discussed here
perform a review of the manifest to identify trackers.
C. (ES2): Examining various alternative apps usable for web
browsing with regards to potential privacy violations
For this test, three exemplary selected apps for web brows-
ing are examined with regards to potential privacy violations.
The three mobile browsers are Chrome, F-Droid Fennec and
Mozilla Firefox.
The tests employed the same examination setup as used
in ES1 (see Section IV-B). This includes the three methods
Exodus Standalone, AppChecker and Exodus Privacy used for
65
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

!"#$%$&'
!"()*+
!&*,-.*
!//0$12&
!//*3%'-.
4)5*&65
367-8$$9:!"*
367-8$$9:!&6%'+27*
367-8$$9:0$52&
367-8$$9:;%67-*
367-8$$9:<=6.-
3%)..'
>$$5%-:!"?$8
>$$5%-:!"*
>$$5%-:!&6%'+27*
>$$5%-:#.6*=0'+27*
>$$5%-:@$)8%-#%279
>$$5%-:32.-86*-:!&6%'+27*
>$$5%-:A65:?6&65-.
0-6&;%)B
$%! !"# $"& $%! !"# $"& $%! !"# $"& $%! !"# $"& $%! !"# $"& $%! !"# $"& $%! !"# $"& $%! !"#
$"&
!!#0
!!30
!!?0
!#
!#;
!>!
!C!
!C#$
!C#
!CD<
!C?
!C;<
!C<?<
!<<?<
!E#
!E#$
!ED<
!CF;
!<!E
!4<
!!!
!4E;
!3
!?!
!?!<
!C!4
!C#<
!C;
!CA;
!CG
!H#
!E;
!E<
7I"?
7IC
76%/F<
76%/H#
7614
74>FC<
7#4
7"6*!F!A
7=C<
7=E<
7BH4
7$C<
7$E<
7C<
7*!@
7*44
7*7I?
7*;F4
7*C
7*E
7H<
B4#C
B4#E
$!<
!!J;
!!J<
!!E<
!4
!#J<
!#E?<
!@K
!#E<
!F<
!3<
!F
!C4#
!CF4L
!C<
!C<<
!<E
!H3
!H3<F
!G
!E<<
!E0
!!"#$%%%%%%%%&'()*+(,-.)/+00+*',!""1223"4!5213#4"!6748
!!9#$%%%%%%%%&'()*+(,-.)/+00+*',!""122397813#4"!6748
!!:#$%%%%%%%%&'()*+(,-.)/+00+*',!""1223:1;7!3#4"!6748
!!82$%%%%%%%%&'()*+(,-.)/+00+*',!""1223816<45=326!61
!!8>$%%%%%%%%&'()*+(,-.)/+00+*',!""1223846797"!67483>4#7"?
!!<2$%%%%%%%%%&'()*+(,-.)/+00+*',!""1223<797326!61
!!!$%%%%%%%%%&'()*+(,-.)/+00+*',!@6A1867"!613!""4@862
!B$%%%%%%%%&'()*+(,-.)/+00+*',B#@16446A
!B2$%%%%%%%%&'()*+(,-.)/+00+*',B54!;"!263267"=?
!B<>$%%%%%%%%%&'()*+(,-.)/+00+*',B54!;"!263<!>3>@2A
!">$%%%%%%%%&'()*+(,-.)/+00+*',"!##3>A481
!"$%%%%%%%%&'()*+(,-.)/+00+*',"!:15!
!"82$%%%%%%%%&'()*+(,-.)/+00+*',"A!8C13816<45=326!61
!"<:2$%%%%%%%%&'()*+(,-.)/+00+*',"A!8C13<7973:@#67"!26326!61
!"<2$%%%%%%%%&'()*+(,-.)/+00+*',"A!8C13<797326!61
!;=$%%%%%%%%&'()*+(,-.)/+00+*',;72!B#13=1?C@!5;
!9$%%%%%%%%&'()*+(,-.)/+00+*',9#!2A#7CA6
!92$%%%%%%%%&'()*+(,-.)/+00+*',9451C54@8;3215D7"1
!C!$%%%%%%%%&'()*+(,-.)/+00+*',C163!""4@862
!72$%%%%%%%%&'()*+(,-.)/+00+*',7826!##32A456"@6
!7$%%%%%%%%&'()*+(,-.)/+00+*',78615816
!:!$%%%%%%%%&'()*+(,-.)/+00+*',:!8!C13!""4@862
!:!2$%%%%%%%%&'()*+(,-.)/+00+*',:4;79?3!@;743216678C2
!56>$%%%%%%%%&'()*+(,-.)/+00+*',5!721;36A51!;3>574576?
!5!B$%%%%%%%%&'()*+(,-.)/+00+*',51!;3!>>3B!;C1
!5"$%%%%%%%%&'()*+(,-.)/+00+*',51!;3"!#18;!5
!5"2$%%%%%%%%&'()*+(,-.)/+00+*',51!;3"!##326!61
!5"*$%%%%%%%%&'()*+(,-.)/+00+*',51!;3"486!"62
!512$%%%%%%%%&'()*+(,-.)/+00+*',51!;31E6158!#32645!C1
!5>2$%%%%%%%%&'()*+(,-.)/+00+*',51!;3>A481326!61
!5>$%%%%%%%%&'()*+(,-.)/+00+*',51!;3>5497#1
!52$%%%%%%%%&'()*+(,-.)/+00+*',51!;32:2
!522$%%%%%%%%&'()*+(,-.)/+00+*',51!;32?8"3216678C2
!5B"$%%%%%%%%&'()*+(,-.)/+00+*',51"17D13B4463"4:>#161;
!5:$%%%%%%%%&'()*+(,-.)/+00+*',51"17D13::2
!52:2$%%%%%%%%&'()*+(,-.)/+00+*',51"17D132:2
!5!$%%%%%%%%&'()*+(,-.)/+00+*',51"45;3!@;74
!5D$%%%%%%%%&'()*+(,-.)/+00+*',51"45;3D7;14
!57B4$%%%%%%%%&'()*+(,-.)/+00+*',51F@12637C84513B!6615?34>67:7G!67482
!57>$%%%%%%%%&'()*+(,-.)/+00+*',51F@12637826!##3>!"=!C12
!22:2$%%%%%%%%&'()*+(,-.)/+00+*',218;32:2
!2<$%%%%%%%%&'()*+(,-.)/+00+*',2163<!##>!>15
!2!<$%%%%%%%%&'()*+(,-.)/+00+*',2?261:3!#1563<78;4<
!@"$%%%%%%%%&'()*+(,-.)/+00+*',@213"51;1867!#2
!@9$%%%%%%%%&'()*+(,-.)/+00+*',@213978C15>5786
!@927$%%%%%%%%&'()*+(,-.)/+00+*',@2139@##32"51183786186
!D$%%%%%%%%&'()*+(,-.)/+00+*',D7B5!61
!<#$%%%%%%%%&'()*+(,-.)/+00+*',<!=13#4"=
!<"$%%%%%%%%&'()*+(,-.)/+00+*',<57613"!#18;!5
!<"*$%%%%%%%%&'()*+(,-.)/+00+*',<57613"486!"62
!<12$%%%%%%%%&'()*+(,-.)/+00+*',<576131E6158!#32645!C1
!<>$%%%%%%%%&'()*+(,-.)/+00+*',<57613>5497#1
!<2$%%%%%%%%&'()*+(,-.)/+00+*',<576132:2
!<22$%%%%%%%%&'()*+(,-.)/+00+*',<576132?8"3216678C2
H&I-@"$%%%%%%%%H*/,&'((*.0,I&J'HK.),-.)/+00+*',@>;!613"4@86
H&I-72$%H*/,&'()*+(,I&J'HK.),-.)/+00+*',7826!##32A456"@6
H&LB$%%%%%%%%H*/,&'()*+(,L.'(+'M,B7##78C
H(&0!7!6$%%%%%%%%H*/,()*-N*O,&'()*+(,0.)L+H.,!""4@86378943!#!5:3657CC15
HP5$%%%%%%%%H*/,M**MI.,&'()*+(,HP(/,-.)/+00+*',51"17D1
HBC752$%%%%%%%%H*/,M**MI.,&'()*+(,Q'0RS,-.)/+00+*',B78;3C1637826!##3519155153215D7"1
H52$%%%%%%%%H*/,KTH,I&J'HK.),-.)/+00+*',51!;3216678C2
H@2$%%%%%%%%H*/,KTH,I&J'HK.),-.)/+00+*',@>;!6132A456"@6
H"B$%%%%%%%%H*/,KJ&U.+,&'()*+(,I&J'HK.),-.)/+00+*',"A!8C13B!;C1
HK52$%%%%%%%%H*/,KJ&U.+,&'()*+(,I&J'HK.),-.)/+00+*',51!;3216678C2
HK<2$%%%%%%%%H*/,KJ&U.+,&'()*+(,I&J'HK.),-.)/+00+*',<57613216678C2
H/@B$%%%%%%%%H*/,/&V.J),I&J'HK.),-.)/+00+*',@>;!613B!;C1
H*52$%%%%%%%%H*/,*--*,I&J'HK.),-.)/+00+*',51!;3216678C2
HP(:$%%%%%%%%H*/,-+O&N&S,-+O&N&S&--,-.)/+00+*',"P;3:122!C1
H05$%%%%%%%%H*/,0.H,&'()*+(,-)*L+(.),N&(M.,-.)/+00+*',51!;
H0<$%%%%%%%%H*/,0.H,&'()*+(,-)*L+(.),N&(M.,-.)/+00+*',<5761
H0P:$%%%%%%%%H*/,0K&W&/,&'()*+(,-.)/+00+*',"P;3:122!C1
H0!;$%%%%%%%%H*/,0K&W&/,&'()*+(,-).I*&(+'X*,-)*L+(.),!""1223;!6!
H0BB$%%%%%%%%H*/,0*'S.)+H00*',K*/.,-.)/+00+*',B54!;"!263B!;C1
H0>7B$%%%%%%%%H*/,0*'S/*N+I.,K*/.,-.)/+00+*',>54D7;1537821563B!;C1
/B"5$%%%%%%%%/.,.L.)STK+'M,N&(M.),-.)/+00+*',B!;C13"4@86351!;
/B"<$%%%%%%%%/.,.L.)STK+'M,N&(M.),-.)/+00+*',B!;C13"4@863<5761
*!2$%%%%%%%%*)M,TK*JMKTH)+/.,0.HJ).0/0,!""122321"5162
!"#$%#&'())(*+),$%&*-#.-(*+$/#0#/)1
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$2&*-#.-(*+$3#0#/1$45+6#&*7)
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$2&*-#.-(*+$3#0#/1$8(6+5-7&#
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$9*$:5-5;9*-$.5-#6*&(<#:
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$2&*-#.-(*+$3#0#/1$9*&'5/
?-+=$"*:$M:D?F@N
!;#:O:!//#=-79-.
D<!:O:DP$")*:<+6&"6%$&-
D;L:O:DP$")*:;.2167':L&%2&-
"*)*'&Y<&)'
;)*-N*O
CJ+T&)6J'&
:**(I.
F5%Z%B&)H*(.
2H&''.)
>+O&N&S
2K&W&/
2+M'&I
@A:Q:::::::::::::::::::::::::::::::::::::::::::::@A:R
Figure 2. Trackers and permissions identiﬁed during ES1 on eight selected apps as performed in Section IV-B
static analysis. These three methods and the forensic data types
used during their application are discussed in detail in Section
III-B. However, in this case dynamic analysis was employed
for a more detailed insight into the results.
The execution of all methods on the three selected apps was
successful. Based on the considerations for the visualization
made in Section III-C, the results are shown in Figure 3.
Again, the rows show the three different methods of inves-
tigation for each of the three specimen. The columns show the
identiﬁed trackers (DT4) or permissions (DT5). Colored boxes
indicate that a method identiﬁed the tracker or permission
within the speciﬁc specimen.
In case of trackers no intra-engine differences between
EPO and ESA are visible. There are some differences when
compared to the ﬁndings of APC. Chrome contains two track-
ers (Google Ads and Facebook Ads) according to APC. Fennec
F-Droid contains Mozilla Telemetry which EPO and ESA iden-
tify as a tracker. Mozilla Firefox has three trackers common
to all methods. These are Facebook Ads, Google Firebase
Analytics and LeanPlum. APC also identiﬁes GoogleAds as
a tracker. EPO and ESA identify GoogleAdMob instead. All
three methods identify the same set of permissions.
Dynamic analysis can be used in order to verify these
observations. The setup described in IV-A was used to exe-
cute Fennec F-Droid within a ”low-noise” environment using
Wireshark [11] to record the network trafﬁc before reviewing
said trafﬁc in order to identify the data ﬂows. In order to
reduce the inﬂuence of background noise, Fennec F-Droid
was started multiple times and the resulting communication
behaviour observed. Every time the app started, a connection
to ﬁrefox.settings.services.mozilla.com was attempted. Hence,
we can conclude a DFtp, since the host does not correspond
to the provider of app. This conﬁrms the result of the static
analysis with regards to Fennec F-Droid.
Example ES2 clearly shows the limitations of the approach
presented here. The identiﬁcation of trackers only yields DFtp)
and does not identify DFfp). This leads to the good results
of Chrome in this comparison without taking into account any
DFfp), which might cause privacy violations. Here, a thorough
dynamic analysis might provide additional insight. Either
66
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

!"#$%&
'()*+,,-.!"%
/,,01*.!"2,+
/,,01*.!"%
/,,01*.'34*+(%*.!5(16&3)%
7*(581$9
2,:311(.;*1*9*&46
!"#
$%!
$"&
!"#
$%!
$"&
!"#
$%!
$"&
!!<7
!!'7
!<
!/!
!=!
!=>?
!@>?
!@?
!?!@
!!!
!A@B
!2!
!C<
)(<DA2
)(E?
)(=FG
)(=@G'
)(;H?
)(C?
)(@FG
))A>
)*2A2
)0G/E
)0<!!
)0=
)0=/?
)%@C!
,9<DA2
,98!
!!B?
!!@?
!<@?
!'?
!E
!2!?
!B'<
!I!8
!=G<
!=??
!=?J?
!CG
!C'
!K
!@7
!@?J?
!!"#$%%%%%%%%&'()*+(,-.)/+00+*',!""1223"4!5213#4"!6748
!!9#$%%%%%%%%&'()*+(,-.)/+00+*',!""122397813#4"!6748
!!82$%%%%%%%%&'()*+(,-.)/+00+*',!""1223816:45;326!61
!!:2$%%%%%%%%&'()*+(,-.)/+00+*',!""1223:797326!61
!!!$%%%%%%%%&'()*+(,-.)/+00+*',!<6=1867"!613!""4<862
!"$%%%%%%%%&'()*+(,-.)/+00+*',"!>15!
!":2$%%%%%%%%&'()*+(,-.)/+00+*',"=!8?13:797326!61
!@:8$%%%%%%%%&'()*+(,-.)/+00+*',@4:8#4!@3:76=4<63846797"!6748
!92$%%%%%%%%&'()*+(,-.)/+00+*',9451?54<8@3215A7"1
!?!$%%%%%%%%&'()*+(,-.)/+00+*',?163!""4<862
!7$%%%%%%%%&'()*+(,-.)/+00+*',78615816
!>!$%%%%%%%%&'()*+(,-.)/+00+*',>!8!?13!""4<862
!>!2$%%%%%%%%&'()*+(,-.)/+00+*',>4@79B3!<@743216678?2
!89"$%%%%%%%%&'()*+(,-.)/+00+*',89"
!C!D$%%%%%%%%&'()*+(,-.)/+00+*',C<15B3!##3D!";!?12
!512$%%%%%%%%&'()*+(,-.)/+00+*',51!@31E6158!#32645!?1
!522$%%%%%%%%&'()*+(,-.)/+00+*',51!@32B8"3216678?2
!52B2$%%%%%%%%&'()*+(,-.)/+00+*',51!@32B8"326!62
!5F"$%%%%%%%%&'()*+(,-.)/+00+*',51"17A13F4463"4>D#161@
!5!$%%%%%%%%&'()*+(,-.)/+00+*',51"45@3!<@74
!2!:$%%%%%%%%&'()*+(,-.)/+00+*',2B261>3!#1563:78@4:
!<F$%%%%%%%%&'()*+(,-.)/+00+*',<213F74>1657"
!<"$%%%%%%%%&'()*+(,-.)/+00+*',<213"51@1867!#2
!<9$%%%%%%%%&'()*+(,-.)/+00+*',<213978?15D5786
!A$%%%%%%%%&'()*+(,-.)/+00+*',A7F5!61
!:#$%%%%%%%%&'()*+(,-.)/+00+*',:!;13#4";
!:12$%%%%%%%%&'()*+(,-.)/+00+*',:576131E6158!#32645!?1
!:2$%%%%%%%%&'()*+(,-.)/+00+*',:57613216678?2
!:2B2$%%%%%%%%&'()*+(,-.)/+00+*',:576132B8"3216678?2
G&5=F$%%%%%%%%G*/,&'()*+(,H)*I0.),-.)/+00+*',51!@3=72645B3F44;>!5;2
G&:=F$%%%%%%%%G*/,&'()*+(,H)*I0.),-.)/+00+*',:57613=72645B3F44;>!5;2
G&"J@>$%%%%%%%%G*/,&'()*+(,GK)*/.,-.)/+00+*',"J@3>122!?1
G&5:F9$%%%%%%%%G*/,&'()*+(,GK)*/.,-.)/+00+*',51!@3:57613F44;>!5;394#@152
G&642$%%%%%%%%G*/,&'()*+(,GK)*/.,6423!";1@
G&72$%%%%%%%%G*/,&'()*+(,L&M'GK.),-.)/+00+*',7826!##32=456"<6
G&<2$%%%%%%%%G*/,&'()*+(,L&M'GK.),-.)/+00+*',<87826!##32=456"<6
GG@1$%%%%%%%%G*/,GK)*/.,-.)/+00+*',@1A7"131E65!2
GN"!!$%%%%%%%%G*/,N**NL.,&'()*+(,&--0,'*I,"<551863!""4<863!""122
GN5$%%%%%%%%G*/,N**NL.,&'()*+(,GJ(/,-.)/+00+*',51"17A1
GNF?7$%%%%%%%%G*/,N**NL.,&'()*+(,O'0PQ,-.)/+00+*',F78@3?1637826!##3519155153215A7"1
GN5?2$%%%%%%%%G*/,N**NL.,&'()*+(,-)*R+(.)0,N0S,-.)/+00+*',51!@3?215A7"12
G0:<!$%%%%%%%%G*/,0&/0M'N,&'()*+(,-)*R+(.)0,G*'T.UT,-.)/+00+*',:57613<213!DD391!6<5132<5A1B
G.>@>$%%%%%%%%G*/,0.G,.'T.)-)+0.,P'*U,>@>3"4861863D54A7@15
*/"J@>$%%%%%%%%*)N,/*V+LL&,S.''.G3S()*+(,-.)/+00+*',"J@3>122!?1
*/D!$%%%%%%%%*)N,/*V+LL&,S.''.G3S()*+(3SU&GG*M'T,-.)/+00+*',D153!""4<8636BD1
2*&L,"%.,M.>2EAN
!8<N.!OO<L*)-*4
>?!N.>P,"$%.?&(5"(1,5*
>8HN.>P,"$%.843Q()6.H5135*
A;.R....................A;S
"K)*/.
9.''.G%9W@)*+(
!"#$%%&'($)*+",
Figure 3. Trackers and permissions identiﬁed during ES2 performed on three different web browser apps performed in Section IV-C
examining the speciﬁc data ﬂow or blocking the speciﬁc data
ﬂow and then checking if the app still performs its function can
be used to discern whether a data ﬂows represents DFfp.req or
DFfp.nrq respectively. This approach is also usable to separate
DFtp.req from DFtp.nrq.
V.
CONCLUSION
This paper discusses potential privacy violations during the
use of mobile apps caused by data ﬂows to the ﬁrst party and
third parties. It introduces four different types of data ﬂows
with potential privacy implications and some means to detect
these data ﬂows. It discusses how the results originating from
various methods can be made more reliable and more compa-
rable. This is achieved by applying practices from computer
forensics to this ﬁeld and describing the examination processes
from the viewpoint of a forensic investigation. This enables
the identiﬁcation of a set of relevant factors for selecting
the methods of examination. In addition, considerations on a
suitable visualization and an example for such an visualization
are provided.
The approach is applied to two different Examination
Scenario. In this ﬁrst scenario, three different methods of static
analysis to examine the potential data ﬂows in a set of eight
different apps are used. This leads to the identiﬁcation of 42
trackers with 20 of them being different. In addition, 167
permissions are identiﬁed with 77 of them being different.
The second scenario examines three different browser apps
and identiﬁes trackers and permissions. It shows the limits of
the presented approach and gives a short example of a dynamic
analysis.
The approach presented in this paper relies on static
analysis and shows the limitations of this approach. The
identiﬁcation of trackers should use varied methods in order
to achieve conclusive results since the methods presented here
might provide differing results. In addition, they do not identify
DFfp. This would require additional methods. The advantage
of the approach presented within this paper is that it provides
comparability of the achieved results, which is not provided if
only a single isolated method of examination is used.
The approach presented within this paper focuses on the
identiﬁcation of trackers from a purely technical standpoint
and hence gives no guidance whether a speciﬁc tracker would
violate the privacy of the user from a legal perspective. In
67
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

this technological view, the approach presented within this
paper supports data sovereignty. Judging the impact a speciﬁc
tracker has on the privacy of the user is a difﬁcult task. Good
guidelines are provided by the Principles relating to processing
of personal data of Article 5 of the GDPR [1]. Chief among
these is data minimisation. A negative example is the approach
of marking tracking from certain providers as less critical since
these providers already have access to similar data (like done
in the grading scheme seen in [8]). If certain providers obtain
personal data through the use of a speciﬁc tracker, they can use
the personal data obtained through different trackers in order
to create a proﬁle.
The prevention of tracking is a complex topic. Users
(including administrators or teachers in care of students) can
try to block trackers using technical means. Also developers
who might unwittingly include trackers in their software might
take steps to remove these trackers. However, these methods
are beyond the scope of this paper.
A. Future Work
The approach presented here deals with the identiﬁcation of
trackers (representing DFtp.nrq) but also provides a foundation
to examine DFfp. This would include dynamic analysis and
would entail blocking speciﬁc data ﬂows and reviewing the
apps functionality following. This remains an open topic as
well as the potential inclusion of code review in order to
improve results.
Additional future work should include research the pro-
vision of an environment that only captures the network
trafﬁc of a given app during dynamic analysis. At present,
other processes can trigger trafﬁc, creating false positives. In
addition, a future extension could include the examination of
websites using the same approach.
ACKNOWLEDGMENT
This document is partly funded by the European Union
Project ”CyberSec LSA OVGU-AMSL”.
REFERENCES
[1]
European Union, “General Data Protection Regulation (GDPR),” 2020,
https://gdpr.eu/article-5-how-to-process-personal-data/ [November 05.
2020].
[2]
R. Binns, U. Lyngs, M. Van Kleek, J. Zhao, T. Libert, and N. Shadbolt,
“Third party tracking in the mobile ecosystem,” in Proceedings of the
10th ACM Conference on Web Science, ser. WebSci ’18.
New York,
NY, USA: Association for Computing Machinery, 2018, p. 23D31.
[Online]. Available: https://doi.org/10.1145/3201064.3201089
[3]
G. Maone, “NoScript,” 2020, https://addons.mozilla.org/de/ﬁrefox/
addon/noscript/ [November 05. 2020].
[4]
pi-hole.net, “pi-hole,” 2020, https://pi-hole.net/ [November 05. 2020].
[5]
P.
Jackson,
“disconnectme
-
Tracker
Descriptions,”
2020,
https://github.com/disconnectme/disconnect-tracking-protection/blob/
master/descriptions.md [November 05. 2020].
[6]
M. Maaß and D. Herrmann, “Privacyscore: Improving privacy and
security via crowd-sourced benchmarks of websites,” CoRR, vol.
abs/1705.05139, 2017. [Online]. Available: http://arxiv.org/abs/1705.
05139
[7]
privacyscore.org,
“PrivacyScore,”
2020,
https://privacyscore.org/
[November 05. 2020].
[8]
mobilsicher.de,
“So
testen
wir,”
2020,
GERMAN
https:
//appcheck.mobilsicher.de/allgemein/so-testen-wir-schnelltest
[November 05. 2020].
[9]
android.com, “Android Operating System,” 2020, https://www.android.
com/ [November 05. 2020].
[10]
Exodus Privacy, “Exodus Privacy,” 2020, https://exodus-privacy.eu.org/
en/ [November 05. 2020].
[11]
wireshark.org, “Wireshark,” 2020, https://www.wireshark.org/ [Novem-
ber 05. 2020].
[12]
“A Road Map for Digital Forensic Research,” DFRWS, Tech. Rep.,
2001.
[13]
R. Altschaffel, M. Hildebrandt, S. Kiltz, and J. Dittmann, “Digital
Forensics in Industrial Control Systems,” in Proceedings of 38th In-
ternational Conference of Computer Safety, Reliability, and Security
(Safecomp 2019).
Springer Nature Switzerland, 2019, pp. 128–136.
[14]
S. Kiltz, J. Dittmann, and C. Vielhauer, “Supporting Forensic Design - A
Course Proﬁle to Teach Forensics,” in IMF ’15: Proceedings of the 2015
Ninth International Conference on IT Security Incident Management &
IT Forensics (imf 2015).
IEEE, 2015.
[15]
R. Altschaffel, K. Lamsh¨oft, S. Kiltz, M. Hildebrandt, and J. Dittmann,
“A Survey on Open Forensics in Embedded Systems of Systems,”
International Journal on Advances in Security, vol. 11, 2018, pp. 104–
117.
[16]
Exodus
Privacy,
“Exodus
Standalone,”
2020,
https://github.com/
Exodus-Privacy/exodus-standalone [November 05. 2020].
[17]
J. Alemann and N.Baier and M.Streuber and T. D. Nam and L. Peters,
“AppChecker,” 2020, https://github.com/Tienisto/AppChecker [Novem-
ber 05. 2020].
[18]
android.com, “Android Studio,” 2020, https://developer.android.com/
studio [November 05. 2020].
[19]
genymotion.com, “GenyMotion,” 2020, https://www.genymotion.com/
[November 05. 2020].
[20]
ubuntu.com, “Ubuntu 18.04,” 2020, https://releases.ubuntu.com/18.04/
[November 05. 2020].
[21]
virtualbox.org,
“VirtualBox,”
2020,
https://www.virtualbox.org/
[November 05. 2020].
[22]
J. Palevich, “Android Terminal Emulator,” 2020, https://play.google.
com/store/apps/details?id=jackpal.androidterm& [November 05. 2020].
68
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-821-1
SECURWARE 2020 : The Fourteenth International Conference on Emerging Security Information, Systems and Technologies

