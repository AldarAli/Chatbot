STP-Net: Semi-Tensor Product Neural Network for Image Compressive Sensing 
 
Youhao Yu1,2,   Richard M. Dansereau1 
 
Department of Systems and Computer Engineering, Carleton University, Ottawa, Canada1 
School of Information Engineering, Putian University, Fujian, China2 
e-mail: youhaoyu@sce.carleton.ca              e-mail: rdanse@sce.carleton.ca 
 
Abstract—Semi-tensor product (STP) is developed into a neural 
network in this paper and applied to image compressive sensing 
(CS). Large matrix computation for fully connected layers 
results in a large number of weight coefficients that need long 
training times. Instead of using an M×N measurement matrix, 
according to the theory of STP a smaller measurement matrix of 
size M/t×N/t can be applied, where t is a shrinkage factor. STP 
only needs N/t elements of the original signal for one 
measurement and the measurement matrix is shrunk to 1/t2 that 
of traditional CS. The shrinkage factor t is adjustable. To 
demonstrate the effectiveness of the STP-based neural network, 
we apply it to image reconstruction. The goal is to sample and 
recover larger images, without partitioning into smaller blocks 
that introduces block artifacts, and provide good initial 
reconstruction for subsequent networks. 
Keywords-compressive sensing; convolutional neural network; 
semi-tensor product; image reconstruction. 
I. 
INTRODUCTION 
Compressive sensing (CS) has become a significant 
research field in analog information processing, image 
compression, machine learning and so on [1]–[3]. The 
fundamental issue in CS is to reconstruct a sparse signal from 
few measurements. Since natural images are intrinsically 
sparse in some domain, they can be restored efficiently from 
CS measurements. Sparse signal reconstruction is an inverse 
problem that can be solved by techniques like basis pursuit 
(BP) [4], matching pursuit (MP) [5], orthogonal matching 
pursuit (OMP) [6], approximate message passing (AMP) [7], 
and least absolute shrinkage and selection operator (LASSO) 
[8], to name a few, but these tend to be time-consuming. 
CS acquires signals that are sparse in a certain basis in a 
compressed form. The sparsifying basis and the measurement 
matrix should be incoherent [3]. According to CS theory, a 
high dimension sparse signal x is sampled by a measurement 
matrix Φ resulting in a low dimension measurement y as 
 
y = Φx 
(1) 
where x is an N×1 vector, y is an M×1 vector and Φ is an M×N 
matrix (M<<N). The measurement matrix should satisfy the 
restricted isometry property (RIP) [9]. 
Each measurement yi is the linear combination of the 
elements in x through a row of Φ as 
 
𝑦𝑖 = 𝜙𝑖,1𝑥1 + ⋯ + 𝜙𝑖,𝑗𝑥𝑗 + ⋯ + 𝜙𝑖,𝑁𝑥𝑁 
(2) 
where xj, yi, and 𝜙𝑖,𝑗 are elements of x, y, and Φ. In (2), all N 
elements in x are used to obtain one measurement yi, which 
causes large computational cost when x is long since the 
measurement matrix Φ will be large. 
There are numerous data reconstruction approaches for 
compressive sensing. In [10][11], STP is adopted and an 
iterative optimization approach used for image CS 
reconstruction. While the approach in [10][11] produces good 
results at a high measurement rate, it is time consuming, needs 
many iterations, and a wavelet transform is used before CS and 
an inverse wavelet transform after CS reconstruction. 
In this paper, we propose developing the Semi-Tensor 
product into a neural network (NN). Such a network uses 
fewer parameters to train and provides theoretical foundation 
for a layer to be designed. The proposed NN needs fewer 
layers and less training time for efficient measurement and a 
good initial reconstruction compared to others, performing 
better than other full convolutional NN systems. Given the 
efficiency, the developed NN is used for whole image CS 
reconstruction using no block partitioning. 
The rest of this paper is organized as follows. Section II is 
an overview of previously proposed CS reconstruction 
methods. Section III describes the measurement and the initial 
reconstruction of CS based on STP. Section IV gives a detailed 
description of STP-Net. Our experiments are set up to 
demonstrate the outstanding performance of STP-Net in 
Section V. Finally, we conclude with a discussion of our 
findings in Section VI. 
II. 
RELATED WORK 
Many NN algorithms have been studied for CS 
measurement reconstruction, such as [12]–[18]. Among them, 
[12] develops a good framework for sensing and recovering 
structured signals, but a few full connection layers make it less 
efficient. [13] and [14] use convolutional layers or residual 
blocks to refine the initial reconstruction of every image block. 
After that, they use block-matching and 3-D filtering (BM3D) 
[15] to remove block artifacts, which is an image denoising 
strategy based on an enhanced sparse representation in the 
transform domain. [16][17] give novel methods that measure 
an image using convolutional layers. However, our 
experiments show that when the sampling rate is 1% the 
reconstructed image is affected by block artifacts, especially 
at the edges of the image, even with a residual network 
(ResNet) after initial reconstruction as they did to improve 
performance. [18] introduces an interpretable optimization-
7
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-970-6
SIGNAL 2022 : The Seventh International Conference on Advances in Signal, Image and Video Processing

inspired deep network for image compressive sensing. They 
cast the iterative shrinkage-threshold algorithm (ISTA) into a 
deep network that produces good performance. 
To overcome the limitation of GPU memory, existing 
methods usually divide an image into blocks and vectorize the 
blocks before measurement. Then, the image is reconstructed 
block-by-block, making block artifacts inevitable [16] and 
requiring denoising to remove block artifacts. 
Our method is different from others since we process an 
image as a whole rather than block-by-block, which avoids the 
block artifacts because the structure information of an image 
is preserved. Normally, operating on the full image would be 
computationally costly but the proposed STP-Net helps reduce 
that computational cost. 
III. STP APPROACH FOR CS 
STP approach can be applied for CS measurement and its 
initial reconstruction of 1D and 2D signal. 
A. 
Measurement 
According to the theory of Semi-Tensor product [19], a 
smaller measurement matrix Φ(𝑡)  can be obtained with 
dimensions 𝑀/𝑡 × 𝑁/𝑡. Here, t is a shrinkage factor which is 
a common divisor of M and N. (𝑀, 𝑁, 𝑡, 𝑀/𝑡 and 𝑁/𝑡 are all 
positive integers) [11]. Only 𝑁/𝑡 elements of the signal are 
needed for one measurement. The dimension of the 
measurement matrix is shrunk by 1/t2 of that for traditional CS. 
Using the left product operator ⋉ for STP, (1) is rewritten as 
𝑦 = Φ(𝑡) ⋉ 𝑥.        
 
(3) 
For clarity, the signal 𝑥 and its measurements 𝑦 can be 
segmented into groups and every group only has 𝑡 points. So, 
𝑥 is divided into 𝑁/𝑡 fragments and 𝑦 is divided into 𝑀/𝑡 
fragments. Reshaping the vectors 𝑥 ∈ ℝ𝑁×1 and 𝑦 ∈ ℝ𝑀×1 
into matrix form 𝑋 ∈ ℝ𝑡×𝑁
𝑡 and 𝑌 ∈ ℝ𝑡×𝑀
𝑡 , we rewrite (3) to 
maintain column-wise order as 
𝑌 = 𝑋 ∙ Φ(𝑡)𝑇.      
 
  (4) 
Considering 𝑋 as an image, this means an image can be 
sampled directly by matrix multiplication.  
For our work, 𝑡 is set to the number of rows the image. 
Our method takes an image as a whole without dividing it into 
blocks or vectorizing the image. 
B. 
Initial Reconstruction 
Typically, the rows of the measurement matrix Φ are 
chosen to be orthonormal and the least-squares solution 
(minimum energy reconstruction) as the initial estimate for x 
[20]. Let Φ be an M×N matrix and let y be a vector in RM. 
The least-squares solution of Φx = y is the solution of ΦTΦx 
= ΦTy [21]. If Φ has orthonormal rows, ΦΦT is an M×M 
identity 
matrix. 
Using 
Φ𝑇𝑦  is 
a common initial 
reconstruction. 
STP maintains the above-mentioned property [11]. If 
Φ(𝑡) is a matrix with orthonormal rows and 𝑦 = Φ(𝑡) ⋉ 𝑥, 
the least-squares solution for x is the solution of [Φ(𝑡)]𝑇 ⋉
𝑦 = [Φ(𝑡)]𝑇 ⋉ Φ(𝑡) ⋉ 𝑥
. 
Since 
Φ(𝑡) ⋉ [Φ(𝑡)]𝑇 =
Φ(𝑡)[Φ(𝑡)]𝑇 = 𝐼 , 𝑥̃ = [Φ(𝑡)]𝑇 ⋉ 𝑦  is an initial estimate. 
The result can be written in matrix form as 𝑋̃ = 𝑌 ⋅ Φ(𝑡). 
C. 
2D Compressive Sensing 
According to compressive sensing theory [1]–[3], a signal 
that is sparse in a certain domain can be sampled at a rate less 
than the Nyquist sampling rate. In Fig. 1, (a) is an image with 
size 256 × 256. Usually, a natural image is sparse in the 
frequency domain, as in Fig. 1(b) where a 2D discrete cosine 
transform (DCT) has been applied using matrix D. Most 
energy is concentrated on top-left corner. If measurement 
matrix Φ(𝑡) = 𝑃, where P is a random matrix, then the image 
measured by (4) produces Fig. 1(c) with smaller size. 
Since t is set to the number of rows, the measurement 
matrix has effectively measured each column separately. As 
shown in Fig. 1(d), the measurement results are still sparse 
with the right choice of sparsifying basis D; most energy 
concentrates in the top area. Following CS theory, the 
measurements can be sampled and compressed again using 
𝑌 = Φ1(𝑡) ∙ 𝑋 ∙ Φ2(𝑡)𝑇.              (5) 
In Fig. 1, since the image is square, we suppose Φ1(𝑡) =
Φ2(𝑡) = 𝑃, where P is a random matrix. Let us now map 
image 𝑋 and its measurements 𝑌 into vectors 𝑥 and 𝑦 by 
column ordering, it is equivalent to (1) when Φ = Φ1(𝑡) ⊗
Φ2(𝑡) where ⊗ is the Kronecker product. In this case, the 
1D operation of (1) is expressed as the separable 2D operation 
that reduces the computational complexity [22]. 
It has been shown that a sparse matrix 𝑋̂ (i.e, 𝑋̂ = 𝐷𝑋𝐷𝑇) 
can be recovered from its matrix sketching 𝑌 = Φ1 ∙ 𝑋̂ ∙ Φ2
𝑇 
[23][24][25]. Here, we assume 𝑋  has size 𝑡 × 𝑡  where 
𝑡2 = 𝑁 . The dimension of 𝑌  is 𝑚 × 𝑚  with 𝑚 = 𝑀/𝑡 
and 𝑚 ≪ 𝑡. Φ1 and Φ2 are two 𝑚 × 𝑡 matrices that can 
be seen as measurement matrices. It is equivalent to 𝑦 =
(Φ1 ⊗ Φ2) ⋅ 𝑥. The initial estimate of the image can then be 
𝑋̃ = Φ1
𝑇 ∙ 𝑌 ∙ Φ2. 
As shown in the dashed box of Fig. 2, an image is 
effectively measured and compressed twice and its initial 
reconstruction uses two corresponding steps. 
IV. STP-NET: NEURAL NETWORK LAYER 
Inspired by the flexibility of STP, we build a neural 
network layer to implement it. The sampling and initial 
recovery process of the proposed STP neural network (STP-
Net) for compressive sensing can be implemented by building 
layers of an NN in two ways. One is defining a custom deep 
learning layer with learnable parameters in forward and 
backward propagation [26], and the other is by means of 
ready-made 
convolutional 
layers, 
like 
in 
MATLAB, 
 
Figure 1.  Image measurements and sparsity: (a) original image, (b) 
1D sparsifying basis D applied along rows and columns, (c) 
measurement of (a) using random matrix P, (d) result showing 
measurement is still sparse, and (e) image sampled along rows and 
columns. Sampling rate = (81/256)2  10%. 
 
 
8
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-970-6
SIGNAL 2022 : The Seventh International Conference on Advances in Signal, Image and Video Processing

TensorFlow, or PyTorch, followed by a custom reshape layer. 
A. 
Defining a Custom Deep Learning Layer 
A custom STP layer has a forward pass, a backward pass, 
and learnable parameters including weights and biases. It can 
be used as a measurement matrix by setting the biases to zero 
and the learning rates to zero so that the set weights remain 
static. It also can be used in initial reconstruction through a 
least-squares like solution. 
Reconstruction of a signal is a regression problem, so the 
output layer is a regression layer. The loss function of the 
regression layer is the half-mean-square-error (HMSE) [27] 
 
𝐿 =
1
2𝑆 ∑
∑
(𝑡𝑖𝑗−𝑦𝑖𝑗)2
𝑅
𝑅
𝑗=1
𝑆
𝑖=1
 
(6) 
where 𝑆 is the number of observations in a mini-batch, 𝑅 is 
the number of responses, 𝑡𝑖𝑗 is the target output, and 𝑦𝑖𝑗 is 
the network’s prediction for the response variable 
corresponding to observation 𝑖. 
For a semi-tensor product layer, the derivative of the loss 
function with respect to the input data of the custom layer are 
 
𝜕𝐿
𝜕𝑥𝑖,𝑗 = ∑
𝜕𝐿
𝜕𝑦𝑖,𝑎 𝜙𝑎,𝑗
𝑀/𝑡
𝑎=1
 
(7) 
where 𝑖 = 1, , 𝑡, 𝑎 = 1, , 𝑀/𝑡, and 𝑗 = 1, , 𝑁/𝑡. 
The derivatives of the loss with respect to the weights are  
 
𝜕𝐿
𝜕𝜙𝑎,𝑗 = ∑
𝜕𝐿
𝜕𝑦𝑖,𝑎 𝑥𝑖,𝑗
𝑡
𝑖=1
 
(8) 
where 𝑖 = 1, , 𝑡, 𝑎 = 1, , 𝑀/𝑡, and 𝑗 = 1, , 𝑁/𝑡. 
For better performance, it could have biases 𝐵 added to 
the STP layer. Since 𝑌 = 𝑋 ∙ Φ(𝑡)𝑇 + 𝐵, the derivatives of 
the loss with respect to the biases 𝐵 have the same size with 
output 𝑌 and the values are 
 
𝜕𝐿
𝜕𝐵𝑖𝑗 =
𝜕𝐿
𝜕𝑦𝑖𝑗 
(9) 
where 𝐵𝑖𝑗  and 𝑦𝑖𝑗 are the elements of 𝐵  and 𝑌  ( 𝑖 =
1, , 𝑡 and 𝑗 = 1, , 𝑀/𝑡). 
Obtaining the derivative of the loss with respect to the 
measurement matrix and the biases, the learnable parameters 
are updated with 
 
 𝜙𝑎,𝑏
𝑘
= 𝜙𝑎,𝑏
𝑘−1 − 𝜂
𝜕𝐿
𝜕𝜙𝑎,𝑏 
(10) 
 
𝐵𝑖𝑗
𝑘 = 𝐵𝑖𝑗
𝑘−1 − 𝜂
𝜕𝐿
𝜕𝐵𝑖𝑗 
(11) 
where 𝑘 is the iteration number, 𝜂 is the learning rate, 𝑎 =
1, , 𝑀/𝑡, 𝑏 = 1, , 𝑁/𝑡, 𝑖 = 1, , 𝑡 and 𝑗 = 1, , 𝑀/𝑡. 
The initial reconstruction would be 𝑋̃ = 𝑌 ∙ Φ(𝑡) + 𝐵 . 
The traditional compressive sensing measurement paradigm 
applies fixed linear measurement [12], which is easy to 
implement in practical applications. Biases are not added with 
the measurement results, but they are added during initial 
reconstruction to have better results.  
B. 
Ready-made Convolutional Layer 
The CS measurement process based on STP is similar to 
dilated convolution (also known as “à trous” convolution). 
STP can be implemented by means of a dilated convolutional 
layer with factor t used to increase the receptive field (the area 
of the input signal which the layer can detect) of the layer 
without increasing the number of parameters and computation 
[28]. Since the number of rows of the measurement matrix 
correspond to the number of neurons in the convolutional layer 
and every filter produces one channel output, this layer should 
be followed by a reshaping, which makes the measurements in 
the same channel. 
V. 
EXPERIMENTS 
In this section, we conduct a series of experiments to test 
the measurement and reconstruction performance of STP-Net. 
A. 
Implementation Details 
The experiments are conducted on MATLAB R2019a. The 
computer is equipped with Intel i7-8700K, GeForce GTX 
1080 CPU with frequency of 3.7 GHz and 16 GB RAM. 
Natural images from the ILSVRC2014 ImageNet dataset are 
adopted. Here, 20k images are chosen: 14k (70%) for training, 
3k (15%) for validation, and 3k (15%) for testing. We 
extracted the central 256×256 part of each image and 
converted them to 8-bit grayscale. Training used stochastic 
gradient descent with momentum, minibatch size of 64, 
maximum epoch of 40, learning rate of 2e-03, drop factor of 
0.10, and drop period of 15. For comparison, we also utilize 
the widely used benchmark dataset Set11 [13] during testing. 
Data In 
STP-Mea1 
STP-Mea2 
STP-Rec1 
STP-Rec2 
U-Net 
Data Out 
256×256       256×26        26×26        256×26       256×256      256×256 
STP-Net 
Figure 2.  STP-Net connected with U-Net for deblurring (Sampling rate:1%). 
9
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-970-6
SIGNAL 2022 : The Seventh International Conference on Advances in Signal, Image and Video Processing

B. 
Measurement Matrix Based on STP 
Every image has 65536 pixels. A sampling rate of 1% will 
produce 655 measurements. The size of such a measurement 
matrix is 655×65536, which needs more than 300 MB of 
memory to store the measurement matrix (with double 
precision matrix elements). According to the STP method, if 
the parameter t is 256, then a measurement matrix with size 
equal to ceiling(256×1%)×256 can be used that satisfies RIP 
[9]. It needs 6 kB of memory and is much smaller than the full 
measurement matrix. Too small of a measurement matrix 
leads to excessive information loss, so we implement CS 
measurement in two steps. As mentioned in Section III, we can 
use two 1D projections for the 2D image, which can be done 
by applying STP twice. For a target of 1%, one option is that 
the first pass compresses the signal by 10% and the second 
pass compresses by another 10%. The size of measurement 
matrix would be ceiling(256×10%)×256 with t equal to 256. 
C. 
Proposed Structure 
Fig. 2 shows the structure of the neural network. STP-Net 
samples the image and provides initial reconstruction that can 
be passed to subsequent networks. U-Net [29] has proved to 
work well with semantic segmentation, which motivates us to 
apply it for reconstruction as a deblurring step. To set up an 
image regression network, we remove the last two layers (soft 
max and segmentation layers) of a U-Net with an encoder-
decoder depth of 3 and add a regression layer. In Fig. 4, STP-
Net is connected with ISTA-Net and STP layers are used 
repeatedly as measurement and reconstruction for each 
iteration. Our experiments adopt five ISTA iterations (phases) 
and every convolutional layer uses 16 kernels.  
D. 
Experimental Results 
For the sampling process, we applied different sampling 
rate combinations (20%+5%, 10%+10% and 5%+20%) in the 
two measurement layers to reach total measurement rate of 1%. 
The mean peak signal-to-noise ratio (PSNR) of the 3000 test 
images with these sampling rate combinations are 20.55, 21.50 
and 20.64 dB, respectively, without U-Net. It seems that the 
square root (10%+10%) of the total measurement rate could 
be a better choice. Tables I to III show that the proposed 
method has better performance than other methods and has 
higher PSNR and structural similarity measure (SSIM). 
From Fig. 3, we see that other methods have block artifacts. 
For DR2-Net [14], the image is measured block-by-block and 
reconstructed with 4 residual blocks. Then, they use BM3D 
[15] to remove the artifacts caused by block-wise processing. 
We modified the process by composing an intermediate 
reconstructed image with their initial reconstruction and then 
using the 4 residual blocks to remove block artifacts. It has 
better performance than their original method even without 
 
Figure 3.  Reconstruction results for parrot and pepper from noiseless CS measurements at measurement rate of 1%. It is evident that STP based 
method restores more visually appealing images than the competitors. 
Parrot
Original
Pepper
Original
Modi-DR2
SSIM:0.5197, PSNR:19.18dB
FCMN
SSIM:0.6494, PSNR:20.12dB
FC-Res
SSIM:0.6537, PSNR:21.42dB
STP
SSIM:0.7145, PSNR:22.17dB
STP-Unet
SSIM:0.7512, PSNR:22.96dB
SSIM:0.4059, PSNR:17.24dB
SSIM:0.5206, PSNR:19.07dB
SSIM:0.5344, PSNR:19.45dB
SSIM:0.5540, PSNR:20.48dB
SSIM:0.6242, PSNR:21.28dB
Output0                   0   Output1                                  0  Outputk 
  
𝐹1 
𝐹̃1 
𝑆𝑜𝑓𝑡(∙, 𝜃1) 
∙∙∙ 
  
𝐹k 
𝐹̃k 
𝑆𝑜𝑓𝑡(∙, 𝜃𝑘) 
  
∙∙∙ 
𝑋    𝑌    𝑋0   𝑌0   𝑅1                𝑋1            𝑋𝑘−1  𝑌𝑘−1  𝑅𝑘                𝑋𝑘 
1
st Phase                                           k-th Phase 
− 
− 
− 
− 
STP   STP      STP   STP                                                         STP   STP 
STP-Net 
STP-Net 
STP-Net 
ISTA-Net 
Figure 4.  Connect STP-Net with ISTA-Net and use STP layers for measurement and reconstruction in every phase. 
10
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-970-6
SIGNAL 2022 : The Seventh International Conference on Advances in Signal, Image and Video Processing

BM3D. Full convolutional measurement network (FCMN) has 
block artifacts too, especially at the four edges of a 
reconstructed image. We apply one residual block after it as 
the authors did in [16]. The block artifacts are alleviated, but 
the four corners of restored image are darker. From Tables I to 
IV, it shows that STP-Net provides an attractive initial 
reconstruction quality for another network. Table III shows 
that STP-Net works well in less time. In Table IV, ISTA-Net 
and ISTA-Net+ adopt nine ISTA iterations with every 
convolutional layer having 32 kernels. STP-Net provides 
ISTA-Net 
with 
information-rich 
measurements 
and 
reasonable initial reconstruction, that enable it to simplify its 
structure with fewer ISTA iterations and kernels to have better 
performance. 
VI. CONCLUSION 
We have presented an STP-based neural network to the 
problem of CS image reconstruction. The measurement and 
initial reconstruction process are efficiently implemented 
through STP without dividing the image into blocks and 
vectorizing. At different measurement rates, our algorithm 
yields superior quality reconstructions than other methods. 
The method does not have block artifacts that many people try 
to solve. It makes the sampling process convenient and 
provides good initial reconstruction for subsequent network, 
such as U-Net or ISTA-Net. In future work, we are going to 
apply it in deep equilibrium architecture to develop an efficient, 
high performance fixed-point iteration layer [30]. 
TABLE I.  PSNR VALUES IN DB ON SET11 WITH DIFFERENT ALGORITHMS AT 1% MEASUREMENT RATE 
Image Name 
ReconNet 
+BM3D [13] 
DR2-Net 
[14] 
DR2+BM3D 
[14] 
Modified 
DR2-Net [14] 
FCMN 
[16] 
FC-Res 
[16] 
STP-Net 
STP-UNet 
Barbara 
19.08 
18.65 
19.10 
19.02 
20.38 
20.97 
21.83 
22.10 
Boat 
18.83 
18.67 
18.95 
18.82 
19.96 
20.57 
21.46 
22.23 
Cameraman 
17.49 
17.08 
17.34 
17.72 
19.16 
19.68 
20.14 
21.25 
Fingerprint 
14.88 
14.73 
14.95 
14.92 
15.56 
15.83 
16.16 
16.16 
Flintstones 
14.08 
14.01 
14.18 
13.29 
14.46 
14.77 
15.28 
15.37 
Foreman 
20.33 
20.59 
21.08 
22.54 
21.08 
23.72 
27.15 
27.00 
House 
19.52 
19.61 
19.99 
20.61 
20.93 
22.38 
23.16 
24.47 
Lena 
18.05 
17.97 
18.40 
18.51 
20.49 
21.15 
21.95 
22.72 
Monarch 
15.49 
15.33 
15.50 
15.52 
17.20 
17.58 
18.28 
18.79 
Parrot 
18.30 
18.01 
18.41 
19.18 
20.12 
21.42 
22.17 
22.96 
Pepper 
16.96 
16.90 
17.11 
17.24 
19.07 
19.45 
20.48 
21.28 
(For ReconNet, we use the results reported in [13]. For DR2-Net and DR2+BM3D, we use the results reported in [14]. For the other algorithms, the 
experiments use MATLAB with networks trained from the same dataset with the same images.) 
 
TABLE II.  SSIM VALUE FOR 11 EXTRA IMAGES 
Image Name 
ReconNet [13] 
Modified DR2-
Net [14] 
FCMN [16] 
FC-Res [16] 
STP-Net 
STP-UNet 
Barbara 
0.3730 
0.3578 
0.4555 
0.4575 
0.5024 
0.5271 
Boat 
0.4140 
0.3838 
0.4729 
0.4771 
0.4950 
0.5587 
Cameraman 
0.4517 
0.4391 
0.4998 
0.5389 
0.5503 
0.6565 
Fingerprint 
0.1641 
0.0708 
0.0853 
0.0858 
0.0884 
0.0886 
Flintstones 
0.2733 
0.1789 
0.2386 
0.2429 
0.2580 
0.2871 
Foreman 
0.5647 
0.6078 
0.6680 
0.6849 
0.7536 
0.7869 
House 
0.5278 
0.5282 
0.5809 
0.5948 
0.6291 
0.7056 
Lena 
0.4418 
0.4344 
0.5364 
0.5489 
0.5765 
0.6324 
Monarch 
0.3802 
0.3427 
0.4683 
0.4816 
0.5003 
0.5578 
Parrot 
0.5329 
0.5197 
0.6494 
0.6537 
0.7145 
0.7512 
Pepper 
0.4002 
0.4059 
0.5206 
0.5344 
0.5540 
0.6242 
Mean SSIM 
0.4112 
0.3881 
0.4705 
0.4819 
0.5111 
0.5615 
(For ReconNet, we calculate the values of SSIM from the images the authors provide.) 
 
TABLE III.  RESULTS OF 3000 TEST IMAGES 
Evaluation index  Modified DR2-Net [14] 
FCMN [16] 
FC-Res [16] 
STP-Net 
STP-UNet 
Mean SSIM 
0.3696 
0.4347 
0.4563 
0.4911 
0.5301 
Mean PSNR 
18.72 
19.26 
20.45 
21.50 
22.06 
Elapsed Time(s) 
56.62 
10.70 
22.02 
9.36 
41.33 
(The number in the table are the mean of 10 times experiments.) 
11
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-970-6
SIGNAL 2022 : The Seventh International Conference on Advances in Signal, Image and Video Processing

TABLE IV.  AVERAGE PSNR (DB) PERFORMANCE COMPARISONS ON SET11 WITH DIFFERENT CS RATIOS 
Sampling 
rate 
ReconNet 
+BM3D 
[13] 
DR2-Net 
[14] 
DR2+BM3D 
[14] 
FCMN 
[16] 
FC-Res 
[16] 
ISTA-Net 
[18] 
ISTA-
Net+ 
[18] 
STP-Net 
STP-
ISTA-Net 
1% 
17.55 
17.44 
17.73 
18.95 
19.77 
17.30 
17.34 
20.65 
21.30 
4% 
20.44 
20.80 
21.29 
23.14 
24.22 
21.23 
21.31 
23.39 
24.92 
10% 
23.23 
24.32 
24.71 
25.36 
27.30 
25.80 
26.64 
26.02 
28.65 
25% 
25.92 
28.66 
29.06 
28.69 
31.15 
31.53 
32.57 
30.06 
33.54 
 (The best performance is labeled in bold.) 
 
ACKNOWLEDGEMENT 
This research was partially funded through a grant from 
the Natural Sciences and Engineering Research Council 
(NSERC) of Canada. 
REFERENCES 
[1] E. J. Candes and J. K. Romberg, “Signal recovery from random 
projections,” Comput. Imaging III, vol. 5674, pp. 76–86, 2005. 
[2] R. G. Baraniuk, V. Cevher, and M. F. Duarte, “Model-based 
compressive sensing,” IEEE Trans. Inf. Theory, vol. 56, no. 4, 
pp. 1982–2001, 2010. 
[3] D. L. Donoho, “Compressed sensing,” IEEE Trans. Inf. Theory, 
vol. 52, no. 4, pp. 1289–1306, 2006. 
[4] S. S. Chen, D. L. Donoho, and M. A. Saunders, “Atomic 
decomposition by basis pursuit,” SIAM, vol. 43, pp. 129–159, 
2001. 
[5] S. G. Mallat and Z. Zhang, “Matching pursuits with time-
frequency dictionaries,” IEEE Trans. Signal Process., vol. 41, 
no. 12, pp. 3397–3415, 1993. 
[6] Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad, “Orthogonal 
matching pursuit: recursive function approximation with 
applications to wavelet decomposition,” Conf. Rec. Asilomar 
Conf. Signals, Syst. Comput., vol. 1, pp. 40–44, 1993. 
[7] J. Zammit and I. J. Wassell, “Adaptive block compressive 
sensing: 
Toward 
a 
real-time 
and 
low-complexity 
implementation,” IEEE Access, vol. 8, pp. 120999–121013, 
2020. 
[8] R. Tibshirani, “Regression shrinkage and selection via the 
Lasso,” J. R. Stat. Soc. Ser. B, vol. 58, no. 1, pp. 267–288, 1996. 
[9] E. J. Candès, J. K. Romberg, and T. Tao, “Stable signal 
recovery from incomplete and inaccurate measurements,” 
Commun. Pure Appl. Math., vol. 59, no. 8, pp. 1207–1223, 
2006. 
[10] J. Wang, S. Ye, Y. Ruan, and C. Chen, “Low storage space for 
compressive sensing: Semi-tensor product approach,” Eurasip 
J. Image Video Process., vol. 2017, no. 1, pp. 1-13, 2017. 
[11] J. Wang, Z. Xu, Z. Wang, S. Xu, and J. Jiang, “Rapid 
compressed sensing reconstruction: A semi-tensor product 
approach,” Inf. Sci. (Ny)., vol. 512, pp. 693–707, 2020. 
[12] A. Mousavi, A. Patel, and R. Baraniuk, “A deep learning 
approach to structured signal recovery,” 53rd Annu. Allert. 
Conf. Commun. Control. Comput. Allert. 2015, pp. 1336–1343, 
2016. 
[13] K. Kulkarni, S. Lohit, P. Turaga, R. Kerviche, and A. Ashok, 
“ReconNet: Non-iterative reconstruction of images from 
compressively sensed measurements,” Proc. IEEE Comput. 
Soc. Conf. Comput. Vis. Pattern Recognit., vol. 2016, pp. 449–
458, 2016. 
[14] H. Yao, F. Dai, S. Zhang, Y. Zhang, Q. Tian, and C. Xu, “DR2-
Net: Deep residual reconstruction network for image 
compressive sensing,” Neurocomputing, vol. 359, pp. 483–493, 
2019. 
[15] K. Dabov, A. Foi, and K. Egiazarian, “Image denoising by 
sparse 3-D transform-domain collaborative filtering,” IEEE 
Trans. IMAGE Process., vol. 16, no. 8, pp. 2080–2095, 2007. 
[16] J. Du, X. Xie, C. Wang, G. Shi, X. Xu, and Y. Wang, “Fully 
convolutional measurement network for compressive sensing 
image reconstruction,” Neurocomputing, vol. 328, pp. 105–112, 
2019. 
[17] J. Du, X. Xie, C. Wang, and G. Shi, “Perceptual compressive 
sensing,” Lect. Notes Comput. Sci, vol. 11258 LNCS, pp. 268–
279, 2018. 
[18] J. Zhang and B. Ghanem, “ISTA-Net: Interpretable 
optimization-inspired deep network for image compressive 
sensing,” IEEE/CVF Conf. Computer Vision and Pattern 
Recognition, pp. 1828–1837, 2018. 
[19] Qi, Hongsheng and Daizhan Cheng. "Analysis and control of 
boolean networks: A semi-tensor product approach." 2009 7th 
Asian Control Conference. IEEE, pp. 1352–1356, 2009. 
[20] Candes E, Romberg J. “L1-magic : Recovery of sparse signals 
via convex programming,” April 2022. [Online]. Available:  
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.212
.9120&rep=rep1&type=pdf. 
[21] D. Margalit and J. Rabinoff, Interactive Linear Algebra. 
Georgia Institute of Technology, 2019. 
[22] A. Akansu, R. Haddad, and P. Haddad, Multiresolution signal 
decomposition: transforms, subbands, and wavelets. Academic 
Press, 2001. 
[23] T. Wimalajeewa, Y. C. Eldar, and P. K. Varshney, “Recovery 
of sparse matrices via matrix sketching,” CoRR, vol. 2, no. 5, 
pp. 1–5, 2013. 
[24] G. Dasarathy, P. Shah, B. Bhaskar, and R. Nowak, “Sketching 
sparse matrices,” arXiv Prepr. arXiv1303.6544, pp. 1–33, 2013. 
[25] G. Dasarathy, P. Shah, B. Bhaskar, and R. Nowak, “Sketching 
sparse matrices, covariances, and graphs via tensor products,” 
IEEE Trans. Inf. Theory, vol. 61, no. 3, pp. 1373–1388, 2015. 
[26] MathWorks, “Define Custom Deep Learning Layer with 
Learnable Parameters,” April 2022. [Online]. Available: 
https://www.mathworks.com/help/deeplearning/ug/define-
custom-deep-learning-layer.html. 
[27] MathWorks, “Specify Layers of Convolutional Neural 
Network,” 
April 
2022. 
[Online]. 
Available: 
https://www.mathworks.com/help/deeplearning/ug/layers-of-
a-convolutional-neural-network.html. 
[28] MathWorks, “2-D Convolutional Layer,” April 2022. [Online]. 
Available: https://www.mathworks.com/help/deeplearning/ref
/nnet.cnn.layer.convolution2dlayer.html. 
[29] O. Ronneberger, P. Fischer, and T. Brox, “U-Net: 
Convolutional networks for biomedical image segmentation,” 
Int. Conf. Med. Image Comput. Comput. Interv., pp. 234–241, 
2015. 
[30] D. Gilton, G. Ongie, and R. Willett, “Deep equilibrium 
architectures for inverse problems in imaging,” arXiv Prepr. 
arXiv2102.07944, pp. 1–21, 2021. 
 
12
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-970-6
SIGNAL 2022 : The Seventh International Conference on Advances in Signal, Image and Video Processing

