Human to Artificial (H2A): from Duets with Robot to a New Model of Relationship
Stefania Palmieri
Design Department
Politecnico di Milano
Milano, Italy
email: stefania.palmieri@polimi.it
Mario Bisson
Design Department
Politecnico di Milano
Milano, Italy
email: mario.bisson@polimi.it
Marco Di Noia
Italian Order of Journalist
Milano, Italy
email: marco@marcodinoia.it
Alessandro Ianniello
Design Department
Politecnico di Milano
Milano, Italy
email: alessandro.ianniello@polimi.it
Abstract— The current technological revolution is significantly
transforming different sectors and areas, creating new cross-
cutting  and  disruptive  opportunities.  Aware  that  the
pervasiveness  of  certain  technologies  -in  particular,  those
falling under definition 4.0- will be increasingly horizontal, it is
necessary to try to hypothesize, at this time, new forms of
interaction and relationships. It could serve as pillars for a
change and development that defines technology as a means
for innovation and not as the end of it. This research was born
from the meeting between a design research group and an
innovative  Italian  singer-songwriter,  who  study  and
experiment, each with their own skills, new possible kinds of
relationship stimulated by the digital transformation that is
investing our society: the research therefore aims to highlight
the opportunities that may arise from the intersection between
the creative and design worlds and the technologies of robotics
and Artificial Intelligence used in music. Starting from the last
artistic project of one of the authors, which fits perfectly in the
highlighted  area  of  interest,  a  second  goal  is  to  try  to
hypothesize a new paradigm of relationships between human
beings and the aforementioned technologies, defined Human
To  Artificial  (H2A),  which  can  be  a  starting  point  to
understand  and  further  develop  new  approaches  to
technologies that will be increasingly present in everyday life,
starting from creative stimuli.
Keywords-Design  of  the  new  relations;  robot;  artificial
intelligence; artistic process; music piece
I.
 INTRODUCTION
The continuous and recent innovations in information
technology have led to the fourth industrial revolution and
introduced the concept of Industry 4.0: this term refers to a
group of technological advances that implement the degree
of digitization of a sector [1].  Four key components (Cyber-
Physical Systems, Internet of Things, Internet of Services
and smart factory) and six disruptive technologies (Industrial
Internet of Things, digital production, Big Data, Artificial
Intelligence, collaborative robots and Virtual Reality) are
normally identified as pillars of the Industry 4.0 concept [2].
Until  now,  the  attention  to  these  technologies  has  been
focused almost exclusively on the technical improvements
that their implementation can guarantee. In fact the term
Industry 4.0 connote this technological set from a productive
point  of  view,  not  considering  the  potential  and  the
opportunities that could arise if they are able to intersect with
less technical  fields, such as critical-design thinking and
creative  thinking. Some  authors  [3]  already  refer  to  the
concept  of  Industry  5.0,  in  which  the  different  4.0
technologies collaborate and interact in a more humanized
way. They hope and hypothesize a further evolution of this
concept, defining a new model of society 5.0 [4], where the
cooperation  and  the  relationship  between  men  and
technologies such as Artificial Intelligence and robots, are
realized in order to seek the well-being of people and not
only for the sake of technology itself [5]. 
Two concepts prove to be fundamental to hypothesize
and  describe  new  possible  forms  of  interaction  between
human  beings  and  4.0  technologies,  which  can  direct
innovation towards this goal: design and creativity. In design
and in the design process, it is recognized the ability to
rationalize inputs from many different areas and to abstract
the  horizontal  peculiarities,  in  order  to  conceive  and
conceptualize new approaches, ways of use and relationship
with technologies. Creativity and the creative process are
instead  a  stimulus  for  the  construction  of  disruptive
interconnections between human capabilities and artificial
faculties,  which  can  be  a  source  to  develop  these
relationships. The construction process and objectives of this
paper are based on what has been stated so far: musical
creativity meets innovation, generating an experience that,
interpreted and analysed through design, allows to outline
the distinctive features of a new approach between people
and technology.
In  Section  2,  a  brief  description  of  the  EDME
Interdepartmental Laboratory of Politecnico di Milano will
1
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-849-5
CONTENT 2021 : The Thirteenth International Conference on Creative Content Technologies

be provided in order to better grasp the background of the
actors and researchers involved in the project; in Section 3,
the main questions and the core of the research will be
highlighted,  and  the  case  study,  which  will  be  further
analysed in Section 4, will be introduced. Section 5 will be
dedicated  to  the  introduction  and  the  description  of  the
suggested new model of relationship between human and
digital technologies. Finally, in Section 6 a resume and the
conclusions of the paper will be presented.
II.
EDME LABORATORY
The  Environmental  Design  Multisensory  Experience
Laboratory  (EDME),  established  within  Politecnico  di
Milano, is the first result of a multidisciplinary integration
path that synthesizes, in a systemic optics, the multiscale
relationships that contribute to delineate the complex identity
of  instruments  of  investigation,  interpretation  and
representation  of  experiential  scenarios.  The  EDME
Laboratory has been organized and managed to focus on
multisensory  interactive  experiences,  and  combines,  in a
physical space, innovative Information and Communication
Technology,  sensors  and  latest  generation  materials.
Research  and  experimentation  activities  are  based  on  a
system able to simulate complex actions and interactions,
and to generate useful data. Further research activities of the
Laboratory will concern the implementation of theoretical
and applicative models with the aim of investigating and
creating  new  relationships  between  physical  and  digital
dimension.  Marco  Di  Noia's  experience  and  knowledge,
described in details in the following paragraphs, are helping
to  lay  the  foundations  for  the  development  of  further
research patterns able to investigate the relationship between
sound and music and the digital domain.
III.
THE ARTISTIC PROJECT MEETS INDUSTRY 4.0
In  2016,  the  Sony  Computer  Science  Research
Laboratory (CSL) released “Daddy’s Car”, a song created in
the  style  of  The  Beatles,  composed  by  an  Artificial
Intelligence called Flow Machines. The new hit was created
with a software, which used a database of 13,000 existing
songs. The catchy track, that could be easily found on the
web, was later arranged and produced by Benoît Carré. This
song is both a great example of interaction between man and
Industry  4.0  technologies  -in  this  case,  an  Artificial
Intelligence- and the source for different questions: are they a
tool to help artists or an artificial alternative to them? Or
neither of them? 
Creativity and creative process, guided by a design mindset,
could  solve  these  questions,  leading  to  new  ways  of
perceiving  some  technologies,  neither  tools  nor  a
replacements, but participants themselves in the process. So,
how can these technologies contribute in the artistic process,
acting as cooperative actors for its development?
In the following paragraphs, the featuring experience with
two real robots -iCub and TeoTronico- within two recorded
songs will be described. These experiences may be the first
evidence of new possible models of interactions between
human beings and robots or Artificial Intelligence. 
IV.
CASE STUDY: THE EP “LA SOVRANITÀ DEI ROBOT”
“La Sovranità dei Robot” (The Sovereignty of Robots),
released on the 22nd of October, is a music EP whose lyrics
are dedicated to some of the most popular robots, replicants,
androids and cyborgs of the fiction. The EP is enriched with
some pioneering elements and audio experiences: in this
case, the recording of TeoTronico, conceived by the Italian
Matteo Suzzi, which plays the piano in one of the tracks; and
the  recording  of  iCub,  one  of  the  world  most  evolved,
relevant  and  popular  platform  to  support  research  in
embodied  artificial  intelligence,  created  by  the  Istituto
Italiano di Tecnologia, that reads a poem as the last track of
the EP.
A.
TeoTronico
TeoTronico,  shown  in  figure  1,  is  a  pianist  robot,
conceived  and  designed  by  Matteo  Suzzi  at  TeoTronica
company, an Italian Start-Up based in Imola. Version 1.0,
with  29  fingers,  was  completed  in  2007.  Starting  from
version  3.0  (2012),  it  was  implemented  with 53  fingers
dynamically driven by electromagnets, able to control the
gradations  of  any  acoustic  piano.  TeoTronico  can  read
musical scores in digital format, playing them on the piano in
a literal way. Since 2017 it is also equipped with feet to
control the sustain pedal of the piano. It can also play some
“mirror-pianist” if connected to a digital piano played by a
person. In the “mirror-pianist” mode, TeoTronico can also
play as a solo pianist with orchestra, in chamber ensembles
and accompanist with singers, even remotely, miles away.
Teo can also talk and sing. It can reproduce written texts,
grant or be dubbed in real time: in both modes, its lips
movements are synchronized to the speech, in any language.
Thus TeoTronico can interact with its interlocutors, even
with its facial expressions: moves its head, mouth, eyes,
eyelids and eyebrows. Equipped with proximity sensors, it
can turn to the people who are approaching it. When dubbed
in real time, it can answer questions from the audience. It can
also  perform  with  other  musicians  with  an  impressive
versatility. Even if TeoTronico had never recorded any tracks
before, it had a long international career on different stages. 
Figure 1. Photo of the robot TeoTronico (retrieved from
http://www.teotronico.it/who/).
2
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-849-5
CONTENT 2021 : The Thirteenth International Conference on Creative Content Technologies

TeoTronico recorded a solo, on an acoustic piano, and
some vocals on the 13th September 2020 for the track “La
Sovranità dei Robot”, a song inspired by Isaac Asimov’s
anthology “I, Robot”. The musical instrument used by the
robot  was  a  Yamaha  C3  Coda,  recorded  with  a  usual
microphone set for acoustic piano. A couple of episodes are
remarkable about this session: as TeoTronico recorded the
solo three times, the team expected to listen to three identical
performances. On the other hand, the three recordings were
slightly different each other. So, the sound engineer had to
pick  the  best  part  of  each  recording,  and  he  made  a
composite, as it happens with human pianists. This charming
evidence could have happened because the springs below the
piano keys do not always react in the same way, even if they
are pushed with the same force; or because TeoTronico’s
plastic fingers got loose more and more during the playing.
Or, maybe, because of some kind of noise in the circuits.
This episode could be intended as a clue for the embryo of a
new  model  that  will  be  further  presented  in  the  next
paragraphs: exposed to the same task and activity, robots
could act in slightly different ways, because of variations in
sets and environments, or because minor instabilities within
their  system.  Furthermore,  before  the  recording  started,
TeoTronico “warmed up” on the piano, playing the file of
“Bohemian Rhapsody” by Queen. The singer was near the
robot and kept singing the song along with him, and the
result was a jam session warmly appreciated by the people
standing in the room, probably because of the funny facial
expressions of the robot, which was playing and singing
together with the artist, moving its head, mouth, eyes and
eyebrows during the performance. 
As anticipated, TeoTronico could sing and speak as a
simple speaker, with an already recorded audio file playing
from a computer, or a microphone connected to it for a live
interaction. The movement of its mouth and face could be
programmed with a MIDI file, or go random. By the way, the
team decided to record TeoTronico in a vocal booth. Its voice
had been recorded seven times (verses and refrains), with a
different vocoder associated for each recording. Finally, in
the control room the one which sounded better in the mix
was picked. After the performance, TeoTronico had been
interviewed: using its second vocal interaction mode, the one
connected to a human (Andrea Messieri) speaking into a
microphone, it was possible for the robot to answer the
questions.
B.
iCub
The robot iCub, shown in figure 2, is a humanoid robot
developed  by  the  researchers  of  the  Istituto  Italiano  di
Tecnologia  and  adopted  by  more  than  40  research
laboratories in Europe, USA and Japan.  The robot iCub of
the IIT laboratories in Genova is the version 1.4, with the
following skills: it recognizes and uses objects, it learns to
act and interact with people and the environment, he has got
the senses of sight, hearing and touch – represented by an
artificial skin which covers its body. The iCub has been
specifically  designed  to  support  research  in  embodied
Artificial Intelligence. At 104 cm tall, the iCub has the size
of a five-year-old child. It can crawl on all fours, walk and sit
Figure 2. Photo of the robot iCub (retrieved from
https://robots.ieee.org/robots/icub/)
up to manipulate objects. Its hands have been designed to
support  sophisticate  manipulation  skills.  The  iCub  is
distributed as Open Source following the General Public
License/Lesser General Public License, and can now count
on a worldwide community of enthusiastic developers. The
iCub has 53 degrees of freedom with the majority in the
upper body and 9 in each hand. The iCub sensors include
cameras, microphones, force/torque sensors, a full body skin,
gyros and accelerometers and encoders in every joint. The
iCub controllers have been designed to be programmable and
its software system as a state-of-the-art middleware called
YARP.
The recording  of iCub’s voice took place at the IIT
Center  for  Human  Technologies  of  Genova,  on  the  5th
October  2020.  The  sound  environment  around  the  IIT
symbol’s voice has been designed using synths and space
sounds  publicly  released  by  NASA on  its  own  website
(Kepler Star, First Likely Marsquake Heard, Jupiter Sounds,
Cassini Saturn Radio Emissions etc.). Moreover, the audio
track finally published has been mixed binaural (so called
“3D audio”). As it had been done with TeoTronico, the desire
was to record iCub’s voice with microphones, and getting the
video of the experiment, instead of having its voice sent by
email as a simple file to insert in the mix; although this last
process would have been surely faster and easier.  iCub has a
vocal system different from TeoTronico: the IIT robot speaks
with a speech synthesis system. The vocal timber of iCub
and its pitch was chosen by the IIT researchers, but it was
decided to record also the noise made by the machines used
provide energy to it, that, in a sense, represents part of its
true sound emission. Anyway, if TeoTronico is a robot made
just for entertainment, iCub is a humanoid platform used
mainly for research purposes in scientific environments. So,
the IIT staff set up iCub standing still on a trailer, with the
movements of  its mouth, legs and arms, disabled.  Even
though, factually, only its voice was needed, the experience
resulted a little bit cold. So, the researchers in the room were
asked to activate iCub’s mouth, arms and hands, through
strings of programming language, which made easy to ask it
to say particular words in real time, making the experience
richer and warmer. This episode is also interesting to get
3
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-849-5
CONTENT 2021 : The Thirteenth International Conference on Creative Content Technologies

partial  answers  to  the  overarching  questions  posed
throughout the paper: is it possible to hypothesize a new
model of relationship with this technology? Which should be
its characteristics and shapes? When the robot started to act
like a human, it became easier to be involved with it and to
collaborate towards the mutual goal.
C.
Other experiment: sound morphing
The  EP  “La  Sovranità  dei  Robot”  includes  a  third
experiment,  which  doesn’t  feature  real  robots,  but  it  is
inspired by fictional robots: in this case, replicants. The
hosting  song  is  titled  “Westworld”,  whose  lyrics  are  a
reference to the homonymous modern TV series based on
Michael Crichton’s movie. In quite the same way, the song is
enriched with the digital replicas of two human musicians, a
woman  and  a  man,  playing  two  acoustic  musical
instruments.  To  achieve  the  expected  results,  the  sound
engineers tried to recreate the sound and the touch produced
by the musicians. In practice, the musicians were asked to
write and record their parts with their instruments and send
the  scores  to  the  team,  to  generate  Musical  Instrument
Digital Interface (MIDI) files. Thus, the engineers recreated
the  two  musicians’ sound,  using  virtual  instruments  and
audio  editing  software,  and  their  “touch”,  working  on
dynamics.  Finally,  they  made  a  morphing  of  the  real
registrations and the virtual ones to have “sound replicants”
for confusing the listeners’ perception. 
V.
TOWARDS A NEW MODEL OF RELATIONSHIP: HUMAN
TO ARTIFICIAL
When  robots  are  not  considered  just  instruments  to
improve the artistic activities, like any other editing software
or MIDI execution devices, but they are involved as co-
performers  or  co-artists,  they  can  succeed  in  creating  a
relationship with humans that can move beyond the master-
slave paradigm: through the explanation of the case studies,
we wanted to show that it is already possible to interact in a
less detached way with robots and Artificial Intelligence.
Collaborating to achieve an objective needs all the actors
involved to communicate and to coordinate in the right way,
to  trust  each  other,  and  to  act  with  a  mutual  approach
towards the goals [6]. This, as stated before, can be applied
to the reference scenario, especially because in this case the
artist and the robot were expected to join forces in order to
achieve a shared goal [7]: the creation of a track. So, as these
relationships  will  for  sure  continue  to  grow  and  to  be
improved exponentially, the interactions between human and
robots will have to change: today, the perception of their
roles is moving fastly to higher expectations [8]. 
Despite  the  always  growing  numbers  of  interactions
between us and computers and machines, we need to feel and
perceive that these interactions are taking place with another
individual. This phenomenon is known as social presence
[9],  and  it  can  be  used  to  introduce  the  concept  of
believability [10] as one of the most relevant in this kind of
relationships: how much an individual can forget that a robot
is artificial and not in possession of typically human abilities.
Other authors [11] affirm that to make socially acceptable
robots they should have a high level of reliability, simplicity
of use, and a human friendly design. So, for sure, if we
analyze the relationship in the direction that moves from
artificial to human is easy to define its foundations through
the merge of the previous characteristics: it can be sum up in
the concept of human friendship, conceived as the grade of
reliability and believability a robot should have. Higher the
grade, deeper the level of the involvement they will achieve,
and major the suspension of belief regarding their artificiality
will be, while relating with them.
As  stated  in  the  introduction,  these  technologies  are
going to be even more innovated and implemented, and so
their  presence  and  influence  in  our  lives  will  grow
dramatically. What we want to try to highlight with this
contribution  is  the  necessity  to  design  a  bidirectional
relationship with the aforementioned technologies, in order
to let everyone be prepared for the upcoming changes that
will  not  only  invest  the  technological  fields,  but  also
different  areas  of  human  activities.  We  can  adapt  to
technology and we have done it several times before. Let us
think about the evolution of User Interface (UI): we were not
used to the gestures (scrolling, swiping, pinching) when they
were once introduced in smartphone interfaces, but we have
learnt how to use them without even thinking. When the
disruptive power of a technology can deeply modify the way
we conceive our existences, its development must be also
guided by seeking innovative approaches, modalities of use,
opportunities for well-being, and not only by the search for
progress itself. The period we are experiencing right now is
showing  us  how  much  we  are  not  aware  of  their
potentialities and of the possibilities they can open up to
conceive different aspects of our daily life. So, by taking into
account the other direction of the relationship, from human
to artificial, and, thus, addressing what we need to do in
order to facilitate this new relation, some concepts become
fundamental. At first, we must acknowledge the importance
of  constant  updates  within  the  domains  regarding
technologies, their potential impacts on our life, and the
languages they use to communicate. We must not fear them,
but always try to convert into opportunities what we first saw
as a threat. This should be the approach that guide us in this
relationship, because it implies the need for continuative
learning and updating regarding technologies. Thus, learning
is what become essential and, in first place, comprehending
not only what concerns our interactions with technologies,
but especially the logic behind them, their history and their
influence on culture and other factors that not only interest
their  technical  side  [12].  We  need  to  spread  model  of
distributed knowledge in order to accelerate this process.
Therefore, creating a rich, diffuse and distributed body of
knowledge in regards of robotics and Artificial Intelligence
would enable an increasing number of people to interact
more smoothly and naturally with these technologies. This
would create a mature environment for the implementation
of certain innovations, lowering the possibilities for misuse
or unjustified fears.
We must understand that we are not dealing just with
instruments, but with beings increasingly looking and acting
like companions. In a metaphorical perspective, we have to
let our counterpart build trust in us. How should we do it? By
4
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-849-5
CONTENT 2021 : The Thirteenth International Conference on Creative Content Technologies

implementing and not replacing them, as we do with our
household appliances. Again, as stated before, distributed
knowledge and Open Source models must be spread in order
to let more individuals get to understand how to act with
these technologies, repair, update and get used to them.
VI.
CONCLUSION
First  of  all,  with  this  paper  and  by  showing  the
experiences presented as case study and applied research, we
want  to  stress  the  importance  of  creative  mindsets  and
approaches,  which  can  be  found  in  music  and  song
production  and  composing,  towards  technology  and  its
possible uses: it is already a powerful and helpful tool for
musicians and music producers, but it can become a real
companion, someone that should be able to participate in the
process of creation, by means of something more than mere
instrumental functions. Furthermore, and in the regard of the
aforementioned  questions,  we  want  to  try  to  understand
which elements and features of robots are contributing in the
shift regarding their conception from tools to co-actors of
creative processes.  This passage helped us in defying the
initial  and  possible  characteristics  of  a  new  model  of
relationship between human and artificial, which highlights
the importance of a biunivocal direction, while keeping in
mind  the  next  technology  developments  and  their
consequences.
We recognize in design one of the discipline able to
further deepen this area of research for its attitude to see
technological innovation as a catalyst for other forms of
innovation:  compared  to  engineering  and  hard  sciences,
design  surely  lacks  the  capabilities  and  the  know-how
needed  to  fully  grasp  every  aspects,  features  and
characteristics of technology. Nevertheless, design analyses
and uses it guided by needs and aims which differs from the
improvement  and  the  innovation  of  technology  itself:
directed by this different point of view, it could bring to
disruptive and innovative applications, uses, and modalities
which, therefore, could shape new relations, mediated by and
together  with  the  reference  innovations. In  this  way, an
already  thriving  and  established  connection  between
engineering and design disciplines could become one of the
most suitable methodology to address the deep changes at
various levels, caused by technological innovations.
REFERENCES
[1]
L. Yang, “Industry 4.0: A survey on technologies, applications
and open research issues”, in Journal of Industrial Information
Integration, vol. VI, pp. 1-10, 2017.
[2]
V. Saurabh, A. Prashant, and B. Santosh, “Industry 4.0. A
Glimpse”, in Procedia Manufacturing, vol. XX, pp. 233-238,
2018.
[3]
P.O. Skobelev and S.Y. Borovik, “On the way from Industry
4.0  to  Industry  5.0: from digital manufacturing  to  digital
society”, in Industry 4.0, vol. II(6), pp. 307-311, 2017.
[4]
F. Kayano, “Science, technology and innovation ecosystem
transformation toward society 5.0”, in International Journal of
Production Economics vol. CCXX, pp. 217-231, 2020.
[5]
Y. Shiroishi, K. Uchiyama, and N. Suzuki, “Society 5.0: For
Human Security and Well-Being”, in  Computer, vol. LI(7),
pp. 91-95, 2018.
[6]
J.  A.  Ruiz-Vanoye  et  al.,  “Can  Machines  Play  Musical
Instruments?”,  in  International  Journal  of  Combinatorial
Optimization Problems and Informatics, vol. X(3), pp. 1-6,
2019.
[7]
V.  Groom  and  C.  Nass,  “Can  robots  be  teammates?
Benchmarks for human-robot teams”, in Interaction Studies,
vol. VIII(3), pp. 483-500, 2007.
[8]
S. Garver, C. Harriott, K. Chauncey, and M. Cunha, “Co-
adaptive  Relationships  with  Creative  Tasks”.  Proc.
ACM/IEEE  International  Conference  on  Human-Robot
Interaction, 2017, vol. 15, pp. 123-124.
[9]
F. Biocca, C. Harms, and J.K. Burgoon, “Toward a more
robust theory and measure of social presence: Review and
suggested  criteria”,  in  Presence  Teleoper.  Virtual
Environment, vol. XII(5), pp. 456–480, 2003.
[10] C.  Breazeal,  Designing  Sociable  Robots,  MIT  Press,
Cambridge, MA, USA, 2004. 
[11] R. S. Aylett, G. Castellano, B. Raducanu, A. Paiva, and M.
Hanheide,  “Long-term  socially  perceptive  and  interactive
robot companions: challenges and future perspectives”. Proc.
of International Conference on Multimodal Interfaces, 2011,
vol.  XIX,  pp.  323-326  [13th  international  conference  on
multimodal interfaces].
[12] R. Cingolani and G. Metta: Human and humanoids – live with
robots. Il Mulino, Bologna, Italy, 2015.
5
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-849-5
CONTENT 2021 : The Thirteenth International Conference on Creative Content Technologies

