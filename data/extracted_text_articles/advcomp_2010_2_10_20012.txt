Optimal Selection of Sampling Rate in Multiple H2 Control Loops
Antonio Sala
AI2 Institute
Technical University of Valencia
Valencia, Spain
asala@isa.upv.es
Carlos Ari˜no, Julio Romero, Roberto Sanchis
ESID Department
Universitat Jaume I,
Castell´on de la Plana, Spain
arino,romeroj,rsanchis@esid.uji.es
Abstract—In this paper, the scheduling of the sampling fre-
quencies of a set of independent controllers that share a limited
resource is addressed. Bandwidth or CPU time limitations are
assumed to be translated to constraints on the sum of the
sampling frequencies. For the individual loops, H2 sampled-
data controllers are proposed, whose performance indexes can
be calculated for the different sampling frequencies. A weighted
sum of the individual loop performance conforms a global cost
index. The problem is then posed as an optimization one, and
some sensible simplifying alternatives are proposed, based on
a grid of frequency points, that allow to solve it with Linear
Programming (and hence with a low computing cost).
Keywords-network control; optimal sampling frequency; net-
work resource sharing
I. INTRODUCTION
In digitally controlled systems, limitations on the fre-
quency of the control computations are frequent. They
may arise from multiple tasks running on the same pro-
cessor so that a higher frequency of the control tasks
would saturate the CPU load; they may also arise when a
communication network between process and controllers is
present and it has a limited bandwidth to be shared between
multiple controllers, Programmable Logic Controllers and
other information-processing elements. Apart from band-
width limitations, increasing the network or computer load
also gives rise to increased delays and sampling jitter, which
might as well result in a performance loss in the tasks
requiring the limited resource.
In most control literature, criteria for selection of sam-
pling time do not usually consider the underlying resource
limitation. Basically, the desired settling time, performance
attenuation level, etc. result in a recommended sampling
period, in most cases with practical “rules of thumb” (see
[1] or [2]); it is left to the underlying real-time scheduler to
achieve such a period with a reduced jitter, by dedicating
to the task whichever computing/network resources are
necessary.
The so-called co-design research line [3] tries to consider
the design of both the control system and the communication
and multi-tasking structures as a joint problem. Basically,
the idea is combining restrictions on the sampling period
arising from schedulability issues and bandwidth limitation
(computation and transmission cost) and sampling-period
dependent controller performance measures in order to solve
a joint optimization whose results are the scheduler sampling
periods and the controllers to be applied.
For instance Branicky et al. [3] proposed an optimality-
based choice of sampling period for a multiple-loop control
over a network based on a performance measure for each
loop and some schedulability constraints. In [4] the objective
was stability robustness, although ﬁrst-order systems were
only considered. Integral of Absolute Error as a function of
sampling period was considered in [5]. Interestingly, Cervin
et al. [6] discuss a generic approach in which the sampled-
data cost of a controller is evaluated.
This paper roots on the last of the above cited works,
formalizing the ideas to sampled-data output-feedback H2
control, and proposing a linear programming approximation
on a ﬁnite grid of sampling frequency points.
The structure of the paper is as follows. Next section
discusses some preliminary ideas and states the problem to
be solved. Section III reviews sampled-data H2 control. Off-
line (ﬁxed rate) scheduling is discussed on Section IV. An
example section and some conclusions are also provided.
II. PRELIMINARIES AND PROBLEM STATEMENT
Consider a network that is shared by several control loops
(controllers, sensors and actuators).
The network resources used by each control loop and the
achieved performance depend on the sampling frequency of
that loop and the controller designed for it. Hence, each loop
will be characterized by:
• Its sampling frequency fi
• A controller scheduling policy C(fi)
• A theoretical performance measure with that controller
Ji(fi)
Therefore, due to the overall bandwidth limitations, if
the performance of one loop needs to be improved by
increasing its sampling frequency, other loops must reduce
their frequency and, hence, their performance. The problem
to be discussed in this paper is how to apportion the limited
resource between loops while trying to maximize the overall
performance by minimizing a global cost index (composed
23
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

of the weighted sum of individual indices), such as:
J(f1, . . . , fr) =
r
X
i=1
hiJi(fi)p
(1)
where hi are weights allowing the designer to emphasize
the need of more accurate control of some processes. As
commented in the introduction, this idea has been previously
explored in literature. The result is an optimal sampling
frequency distribution given the network constraints.
This paper has chosen the H2 performance measure as
cost index (minimum-variance controller when subject to
white-noise inputs). Indeed, if H2 sampled-data optimal
controllers are used in the loops, the optimal performance
of each loop can be calculated as a function of its sampling
period via well-known sampled-data H2 formulae.
III. SAMPLED-DATA OPTIMAL CONTROL
The main issues in H2 sampled-data optimal control are
reviewed next.
Consider a linear time-invariant continuous-time process
given by:
˙x = Ac
1x + Bcu + Gc
1v
(2)
˙ψ = Ac
2ψ + Gc
2w
(3)
z = Cx + Du
(4)
y = C2x + C3ψ + D2u
(5)
so that it has a transfer function representation given by:
z = G11(s)v + G13(s)u
(6)
y = G21(s)v + G22(s)w + G23(s)u
(7)
where z denotes the variables to be controlled, u are the
manipulated inputs, y are the measurements and v, w are
assumed to be white-noise disturbances to be denoted as
process noise and measurement noise, respectively, with unit
variance (all variance information is included in matrices Gc
1
ad Gc
2). The state variables x are denoted as process state,
whereas the state variables ψ are states of the measurement
noise generator subsystem, assumed to evolve uninﬂuenced
by x.
Given a sampling period T, a sampled-data controller
will be designed so that its input will be the sequence of
sampled outputs yk and its output will be a sequence of
control actions uk to be fed to the continuous-time plant via
a zero-order hold.
The control objective is to obtain the controller that
minimizes the variance of z, tr(E(zzT )) for a given, ﬁxed,
sampling period T. Such a problem is denoted in literature as
the H2 sampled-data optimal control problem. It was shown
in [7], [8] that such a problem can be cast as a pure discrete-
time H2 optimal control problem for the discretized model
given by:
xk+1 = A1xk + Buk + G1vk
(8)
ψk+1 = A2ψk + G2wk
(9)
zk = C1xk + D1uk
(10)
yk = C2xk + C3ψk + D2uk
(11)
where the above discrete-time matrices are given by:
A1 = eAc
1T , A2 = eAc
2T
(12)
B =
Z T
0
eAsBds
(13)
and G1, G2, C1 and D1 are any matrices satisfying:
GiGT
i =
R T
0 eAc
i sGc
i(Gc
i)T e(Ac
i )T sds
(14)
(C1D1)T (C1D1) =
R T
0 eA
T s(CD)T (CD)eAsds (15)
where:
A =

A
B
0
0

(16)
and all of the above matrices can be obtained from matrix
exponential formulae without the need of actually carrying
out any integration [9].
The obtained variance approaches that of the continuous-
time H2 controller when the sampling period tends to zero
[10]. Indeed, as a piecewise-constant control is a valid pos-
sibility for the optimal control action u(t), the continuous-
time solution of the above minimum-variance problem will
be equal or better than any sampled-data optimal solution.
The sampled-data system will have a closed-loop H2 norm
given by that of the above discrete system plus a factor given
by [10]:
1
T
Z T
0
Z T −s
0
trace(C2eAc
i τGc
i(Gc
i)T e(Ac
i )T τC2dτds (17)
It is well known that the optimal controllers have the
form of a Kalman ﬁlter observer plus a static state feedback,
and that optimal control weights in classical linear quadratic
regulator setups can be translated to the above H2 problems
by a suitable choice of C and D.
If the measurement-noise dynamics G22 is sufﬁciently
fast, the measurement noise will appear as a constant-
variance stationary process when sampled at all except very
small sampling periods; in that case, the dynamics of the
states ψ can be eliminated in practice and C3ψ replaced
by a discrete stochastic process with a constant variance
equal to the stationary variance of the continuous one. This
yields the classical “measurement noise variance” in discrete
stochastic process models.
24
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

IV. RESOURCE SCHEDULING
Basically, the computing and network resources required
by a control task will be proportional to the sampling
frequency. Hence, the objective is achieving maximum
performance (in terms to be later detailed) given a ﬁnite
“bandwidth” bound, β, set up from computer and network
load analysis.
The objective of this paper is proposing an scheduling
methodology that allows an efﬁcient use of the assigned
control bandwidth by devoting more resources to processes
that need a better control and, hence, must be operated at
a higher sampling rate. The ideas in the previous section
allow to easily obtain the optimal performance as a function
of the sampling rate of a particular process. Considering
now r independent control loops, which should share a
computer or a network, we will denote as γi(f) the optimal
disturbance-rejection H2 performance obtained for process i
by a controller operating at frequency f (i.e., with sampling
period T = 1/f).
Taking into account all loops simultaneously, an overall
performance measure may be deﬁned as:
J(f1, . . . , fr) =
r
X
i=1
hiγi(fi)p
(18)
where hi are weights allowing the designer to emphasize
the need of more accurate control of some processes. The
selection of these weights should depend on the disturbances
acting on each loop, and on the economic cost derived from
the resulting loop error. The higher the disturbance and the
cost, the higher the weight.
The needed resources as a function of controller frequency
may be expressed as:
R(f1, . . . , fr) =
r
X
i=1
difi
(19)
for some given constants di to be determined based on
processor load and number of bits transmitted by each
control task (transmission time plus computation time). On
the sequel, the vector of frequencies for each control loop
will be denoted as F.
The goal of the bandwidth scheduling will be to obtain
the sampling frequencies fi for each of the control loops
taking into account the performance and resource measures
deﬁned above.
Then, some scheduling problems of interest may be
conceived:
• Given a resource constraint
R(F) ≤ β
(20)
obtain the lowest J(F).
• Given a performance objective J0, obtain the lowest
level of resources needed to achieve it: minimize R(F)
constrained to J(F) < J0.
• variations of the above problems including some perfor-
mance requirements for individual loops γi(fi) ≤ J0,i
or multi-criteria settings (obtaining, for instance, a
Pareto front on performance vs. available bandwidth).
A. Alternatives for the optimization problems
Depending on the shape of γi, the allowed values for the
decision variables F, the value of the exponent parameter p
in (18) and the chosen problem formulation from the options
above, the required optimization algorithm will be different.
Several interesting options are discussed below:
1) Discrete optimization over a ﬁnite set of alternatives:
Set up two or three performance levels for each process, say:
high-frequency, normal-frequency, low-frequency sampling.
Then, the problem gets transformed to a choice between a
ﬁnite set of decision variables and it can be explored by
brute force if the number of controlled loops is small.
2) Linear (approximate) optimization: Set up a dense
enough grid of points f ∗
j . Then, for each individual γi(·)p
function, compute the linear interpolation between the avail-
able frequency points, giving rise to a piecewise-linear γ∗
i (·)
interpolation function. Subsequently, determine an interval
of interest [f −
i , f +
i ] where individual performances γ∗
i (·) are
convex functions. Doing this for all the controlled loops, the
controller cost will then be the sum of univariate convex
functions and, hence, a convex piecewise-afﬁne function.
It is well known that piecewise-afﬁne functions can be
optimized via Linear Programming. Let us describe the basic
idea below:
Denote as f ∗
k, k = 0, . . . , ¯k the grid points in the above
interval [f −
i = f ∗
0 , f ∗
1 , . . . , f +
i = f ∗
¯k].
In that interval, γ∗
i (f) may be approximately expressed
as the piecewise-linear interpolation between grid points,
to be denoted as ¯γ∗
i (f) ≈ γ∗
i (f) . Conveniently, such
linear interpolation can be rewritten as a linear-programming
optimization:
¯γ∗
i (f) = γi(f −
i ) + min
ϵk
¯k
X
k=0
αkϵk
(21)
subject to the linear constraints
ϵk ≤ f ∗
k − f ∗
k−1,
¯k
X
k=0
ϵk = f − f −
i
(22)
and where αk are the piecewise slopes, deﬁned as
αk = γi(f ∗
k+1) − γi(f ∗
k)
f ∗
k+1 − f ∗
k
that fulﬁls the condition αk+1 ≥ αk due to the assumed
convexity of γ∗
i (·) in the given interval.
Carrying out a similar derivation for each of the loop
performances (choosing a gridding with ¯ki intervals for each
25
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

i), the overall cost can be expressed as:
J(F) = min
ϵi,k
r
X
i=1
hi

γi(f −
i ) +
¯ki
X
k=0
αi,kϵi,k


(23)
subject to ϵi,k ≤ f ∗
i,k −f ∗
i,k−1, P¯ki
k=0 ϵi,k = fi −f −
i . Hence,
the optimization problem to be solved consists of the above
problem constrained to the additional condition P difi ≤
β. Such problem is a linear programming one that can be
efﬁciently solved.
Remark: An interesting particular case results when the
weights di = 1, and the grid points f ∗
j are uniformly spaced
so the distance between the grid points is an exact divisor of
the bound β. In that case, as LP optimal solutions always lie
at slope changes or constraint bounds, the result of the LP
optimization will always lie at one of the grid points, i.e., the
optimum frequencies always belong to a predeﬁned set. This
would be especially useful for an on-line scheduling, where
the switching between a ﬁnite set of controllers could be a
simple solution. This issue will be studied in future works.
3) Generic nonlinear optimization.: If a non-linear (poly-
nomial, spline, etc.) interpolation were chosen to approx-
imate γi(·), the scheduling problem would be a nonlinear
optimization problem. That would also be the case if the
intervals [f −
i , f +
i ] were too small for the particular appli-
cation. If the number of simultaneous loops were small,
a subdivision of the interpolation table in a ﬁnite number
piecewise convex (or concave) regions would allow for
solving a linear programming problem for each of such
regions and computing the global minimum as the minimum
of the local optimizers (details omitted for brevity).
V. EXAMPLES
Considerer the simple case of controlling two identical
SISO systems whose disturbance inputs might, however,
be not identical. Under limited resources, the effort should
concentrate on the process subject to larger disturbances,
which must be known a priori and cast into the optimization
index in the off-line scheduling case.
Each of the systems can be represented by the state space
model (24) where x are the state variables, y is the output, v
are the white noise variables and z represents the weighted
controlled variables.
˙x
=
Ax + Bu + Gv
y
=
Cx
(24)
z
=
Czx + Dzu
where
A =

−20
−12.5
8
0

, B =

16
0

(25)
G =

1
0
0
1

(26)
C =

and the other one in open-loop. This has not been the case
for the simulations in this paper’s examples.
In order to solve a convex problem we approximate the
cost function J following the methodology in Section IV-A2
at the convex range of J as
γ∗2
1
=
γ2
1(f −
1 ) + min
ϵ1,k
X
k
αkϵ1,k
(30)
γ∗2
2
=
γ2
1(f −
2 ) + min
ϵ2,k
X
k
βkϵ2,k
(31)
Note that, in this case αk = βk because the systems have
the same dynamic model. The candidate sampling frequen-
cies vectors F1 and F2 are taken also identical for both
systems, uniformly distributed from 12 to 60Hz, computing
approximation points every 2 Hz (i.e., f −
1
= f −
2
= 12,
f +
1
= f +
2
= 60, f ∗
i,k = 12 + 2k). Then the optimization
problem can be approached by the linear programming
problem procedure presented in the referred section.
As a result, we obtain the optimal H2 norm bound at
frequencies f1 = 42 and f2 = 18. The controllers’ state
space gains (Ki) and Kalman ﬁlter gains (Li) that minimize
J∗ are presented in (32) and (33) below, respectively.
K1 = (−4.228 − 25.16),
L1 = (−0.014 0.0622)T (32)
with the sampling time T1 = 1/42.
K2 = (−1.839 − 6.4171),
L2 = (−0.0275 0.0548)T
(33)
with the sampling time T2 = 1/18.
A contour plot of the cost function J(f1, f2) is repre-
sented at Figure 2 with its constraints.
50
60
60
70
70
70
80
80
90
90
100
100
110
110
120
120
130
15
20
25
30
35
40
45
50
55
60
15
20
25
30
35
40
45
50
55
60
f1
f2
Figure 2.
Contour plot of the cost function J and the constraint f1+f2 ≤
60.
VI. CONCLUSION AND FUTURE WORK
This paper has presented an optimal scheduling of a set
of independent H2 sampled-data controllers operating on
a shared resource, which gives rise to sampling frequency
constraints. The problem has been posed as an optimization
one and some sensible simplifying alternatives have been
proposed, based on a grid of frequency points, that allow
to solve it with Linear Programming, and hence, with a
low computing cost. Some examples have illustrated the
approach. As a future work, the online scheduling of the
sampling rates will be studied. The idea will be to adapt the
scheduling to changes in the available resources or in the
process disturbances. The simpliﬁed Linear Programming
based optimization presented in this paper will be a key
point in that work.
ACKNOWLEDGMENT
The authors are grateful to the ﬁnancial support of Span-
ish Ministry of Education grants DPI2008-06731-C02-01,
DPI2008-06731-C02-02 and Generalitat Valenciana grant
PROMETEO/2008/088.
REFERENCES
[1] K. Astrom and B. Wittenmark, Computer-controlled systems:
theory and design.
Prentice Hall New York, 1996.
[2] P. Albertos, A. Sala, and M. Chadli, “Multivariable control
systems—an engineering approach,” Automatica, vol. 41,
no. 9, pp. 1665–1666, 2005.
[3] M. Branicky, S. Phillips, and W. Zhang, “Scheduling and
Feedback Co-Design for Networked Control Systems (I),” in
IEEE Conference on Decision and Control, vol. 2.
Citeseer,
2002, pp. 1211–1217.
[4] L. Palopoli, C. Pinello, A. Vincentelli, L. Elghaoui, and
A. Bicchi, “Synthesis of robust control systems under re-
source constraints,” Lecture Notes in Computer Science, pp.
337–350, 2002.
[5] C. Peng, D. Yue, Z. Gu, and F. Xia, “Sampling period
scheduling of networked control systems with multiple-
control loops,” Mathematics and Computers in Simulation,
vol. 79, no. 5, pp. 1502–1511, 2009.
[6] A. Cervin, M. Velasco, P. Marti, and A. Camacho, “Opti-
mal on-line sampling period assignment,” Automatic Con-
trol Department, Technical University of Catalonia, Tech.
Rep. ESAII-RR-09-04, December 2009, available as http:
//paginespersonals.upcnet.es/∼pmc16/0910RR04.pdf.
[7] B. Bamieh and J. Pearson Jr, “A general framework for
linear periodic systems with applications to H∞ sampled-data
control,” IEEE Transactions on Automatic Control, vol. 37,
no. 4, pp. 418–435, 1992.
[8] P. Khargonekar and N. Sivashankar, “H2 optimal control for
sampled-data systems,” Systems & Control Letters, vol. 17,
no. 6, pp. 425–436, 1991.
[9] V. Loan, “Computing integrals involving the matrix exponen-
tial,” IEEE Transactions on Automatic Control, vol. AC-23,
no. 3, pp. 395–404, 1978.
[10] H.
Trentelman
and
A.
Stoorvogel,
“Sampled-data
and
discrete-time H-2 optimal control,” SIAM Journal on Control
and Optimization, vol. 33, no. 3, pp. 834–862, 1995.
27
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

