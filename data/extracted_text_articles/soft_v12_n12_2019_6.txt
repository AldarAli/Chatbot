68
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
An Explorative Study on Motion as Feedback: 
Using Semi-Autonomous Robots in Domestic Settings 
 
Diana Saplacan, Jo Herstad 
Department of Informatics 
University of Oslo, UiO, 
Oslo, Norway 
email: {diana.saplacan; jo.herstad}@ifi.uio.no 
 
 
Abstract—This paper presents motion as feedback. The study is 
based on empirical data from an explorative study of semi-
autonomous robots used in domestic settings. We explore 
feedback received from stationary technology, 
e.g., a 
smartphone, and technology that is self-propelled, e.g., a semi-
autonomous robot. The paper has its theoretical foundation in 
the familiarity concept used as a contextual and analytical tool 
for unpacking feedback. The data analysis is done through 
thematic analysis. The findings are structured in: feedback 
received from a smartphone app technology, feedback received 
from the robot-mediated via an app; and motion as feedback 
received from the robot. Motion as feedback is discussed in 
terms of: (a) what type of emotions feedback triggers in the 
users, and (b) making sense of the motion as positive, negative, 
homeostatic, archival and transition feedback. We argue that 
having familiarity in mind when designing new technologies, 
can make it easier for the user to know-how to engage with the 
technology. Our conclusion is that: a semi-autonomous robot 
technology can become more familiar to the user if it triggers 
positive feelings, if its motion is coherent, if its navigation is 
appropriate to the situation, and if its motion is not disturbing 
or interrupting the user; and lastly, familiarity needs to be 
considered when designing for a robot for the elderly. 
Keywords – feedback; motion as feedback; semi-autonomous 
robot; familiarity; emotions. 
I. 
 INTRODUCTION 
This paper builds further on our reported work on how 
feedback from digital technologies may trigger the feeling of 
fear for technology when using those [1]. We have in our 
previous work used fear as an umbrella term for emotions, 
such as angst, anxiety, concern, doubt, dread, unease, 
uneasiness, worry, aversion, fright, phobia, and presentiment  
[2]. In this paper, we extend this work by looking at the 
motion of robots as a type of feedback. We do this by 
running a study where researchers test out a robot, and by 
introducing a robot in the homes of the elderly.  
The questions that we address are: 1) What kind of 
emotions are triggered in the user by improper or lack of 
feedback when engaging with digital technology: a 
smartphone app or a semi-autonomous robot? 2) How is a 
motion made sense of by the users when engaging with a 
semi-autonomous robot, in their homes? Moreover, if motion 
is illustrated as a type of feedback – what do we learn from 
their experiences?  
The rest of this paper is organized as follows. We 
continue by introducing some terminology used in this paper 
and a short background for the study. Section II gives an 
overview of the current state of the art on different types of 
robots used in home and outside the home. Section III 
elaborates on feedback as understood within Human-
Computer Interaction (HCI). We introduce feedback as 
visual and textual feedback. Based on the literature, we 
describe polarity-, homeostatic, and archival feedback, 
which we later use in our mapping of motion as feedback. 
We continue then by introducing the reader briefly to motion 
as feedback and the robot’s navigation. Section IV continues 
with positing this paper on a theoretical level, elaborating on 
the familiarity concept grounded in literature. Section V 
gives a detailed account of the methodology and methods for 
this study. Section VI presents in details the findings based 
on empirical data. Section VII discusses the findings through 
the lens of familiarity while elaborating on the motion as 
feedback. Finally, Section VIII concludes the paper and gives 
directions for further work.  
A. Terminology 
A domestic setting provides the opportunity for those who 
live there, or are around, to use technologies that are still, 
such as a smartphone, or technologies that move, such as a 
semi-autonomous robot.  
A smartphone is still technology. We define still 
technology as a technology that does not move by itself; it is 
not self-propelled, i.e., it does not change its location without 
the continuous intervention of a human or another object. 
Examples of analog and digital still technologies are a table, 
a sofa, a notebook, a speaker, a lamp, a mobile phone, or a 
smartphone. One could argue that a smartphone is indeed a 
mobile technology. We agree with this if we talk about the 
way it is used. However, when it comes to its form of motion 
or locomotion, a smartphone or mobile phone does not move 
around by itself and change its location, unless they are 
moved by someone or something that can move. However, a 
smartphone or a mobile phone can vibrate, and one could 
argue that vibration is a type of movement. However, this 

69
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
type of movement is not an intended movement of changing 
its location, or of navigating an environment.  
We define a semi-autonomous robot as an in-motion 
technology that can move by itself; it can be self-propelled, 
that follows a locomotion process, i.e., it can change its 
location without a necessary and continuous intervention of 
a human or another object. Examples of in-motion analog 
and digital technologies are mechanical robots and semi-
autonomous robots, which can navigate a place by 
themselves, such as semi-autonomous vacuum cleaner 
robots, or lawn mowers. 
In this paper, we use this terminology interchangeably: 
smartphone app technology, in order to refer to still 
technology; and semi-autonomous robot technology for 
referring to in-motion technologies, here a semi-autonomous 
vacuum cleaner robot.  
B. Background 
According to the literature, robots are defined as: 
“physically embodied systems capable of enacting physical 
change in the world.” [3]. Following [4], industrial robots 
refer to robots that move around or transport things, and 
usually operate on conveyor belts, in packaging, and 
assembling [4]. Industrial robots usually perform repetitive 
routine tasks, often having a predefined navigation path. 
Professional service robots are similar to industrial robots, 
but they are used outside the industrial setting: they can 
transport things, by navigating around the environment [4]. 
To these, robots used in healthcare also add up [3]. They 
refer to the micro-robotics that are used inside the body, 
protheses robotics that are used on the body, and robotics 
that are used outside the body. Other robots are used to 
support mental or behavioral therapy, such as those used for 
people with diagnoses on the autism spectrum disorder, 
those with cognitive impairments, or as companions [3]. 
However, they usually perform tasks to assists people: 
cleaning nuclear waste [4], supporting surgeries in hospital 
settings, or carrying around medicines or instruments, see 
for example the work from [5] or [6]. The robots that are 
outside the body and can move semi-autonomously usually 
have pre-defined paths and navigate in uncluttered 
environments.  
Further, the third wave in HCI discusses digital 
technology in our homes [7]. However, we still seem to 
have less knowledge on the use of moving objects in the 
home than about the use of stationary technology – although 
several existent projects are studying the use of robots in the 
home. These are usually included under the category of 
personal service robots, following [4]. Amongst personal 
service robots are: robotic vacuum cleaners, lawn mowers, 
and assistive robots for the elderly or the un-abled [4].  
This study is part of the Multimodal Elderly Care Systems 
(MECS) [8]. The project focuses on the design of a robot for 
the independently living elderly. We define elderly as old 
adults (≥ 65 years), according to definitions used in 
gerontology [9][10]. However, within the frame of the 
MECS project, this study consists of a qualitative 
interpretative phenomenological evaluation of the interactive 
systems as experienced by participants in their daily lives, 
and the phenomena surrounding them. We followed the HCI 
definition - a “discipline concerned with the design, 
evaluation, and implementation of interactive computing 
systems for human use and with the study of major 
phenomena surrounding them.” [11, 15, emphasis added]. 
The setting for this study was the homes of our participants.  
II. 
STATE OF THE ART 
According to state of the art in robotics, published in 
2016 U.S. Robotics Roadmap, the focus area of the field is 
currently on: aging well and quality of life, robotics used in 
the medical field in surgeries and interventions, and the 
robots used as “clinical workforce support” [3, 73]. The 
study also says that a one-size fits all approach is hard to be 
achieved in robotics [3].  
A thorough overview of the robots used in studies for 
supporting independent living is given in [12]. There are 
several projects studying the use of robots in the home. A 
project concerning the care of the elderly is Acceptable 
robotiCs COMPanions for AgeiNG Years (ACCOMPANY) 
[13][14]. ACCOMPANY developed Care-O-Bot robot. 
Care-O-Bot is amongst one of the robot assistants used for 
housekeeping and home care [13][14][15][16]. Care-O-Bot 
is a state-of-the-art robot designed to be used in the home 
[17]. A couple of other projects studying these type of 
robots are named in the work of [17], such as Handy 1, 
Movaid, and Nursebot built for the elderly or the disabled; 
GuideCane, Hitomi, PAM-AID, PAMM, Smart-Cane 
PAMM, 
and 
Smart-Walker 
PAMM. 
These 
robotic 
prototypes were built to be walking aid for the blind, 
elderly, or the disabled [17]. 
At EU-level, several projects studied the use of robots in 
the home. Amongst the European Union projects are: 
Robot-Era Project [3], MARIO Project on Managing active 
and healthy aging with use of caring service robots, 
EURON 
RoboEthics 
Roadman, 
EP6, 
ETHICBOTS, 
BREATHE, and ICT & Ageing Project [18]. Another 
project was the Multi-Role Shadow Robotic System for 
Independent Living (SRS) [19]. The project focused on 
studying the frail elderly people: the elderly whose 
Activities of Daily Living (ADL) are limited by their health 
problems [19]. Many of the frail elderlies use walking 
chairs, sticks, or wheelchairs [19]. The study shows that 
teleoperated robots may be accepted in some situations, 
whereas direct physical interaction with a service robot can 
be, at times, difficult [19]. It seems that “housing-related 
needs” are central for learning and adopting the technology 
if these technologies function well [19, 303]. For instance, 
the study also indicates that men have more difficulties than 
women with housekeeping tasks, while women have 
difficulties in reaching things [19]. A similar study to ours 
talks about introducing personal service robots, a Roomba 
Discovery vacuum cleaner, in homes [20]. The home is 

70
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
viewed as an ecology of products, people, activities, a social 
and cultural context of use, and a place – a bounded 
environment [20]. It seems that the expectations one has of 
technology are highly related to shaping the initial 
expectations of technology. The use of the robot also 
influenced the practice of housekeeping: in some 
households, the male participants set-up the robot; in others, 
only the women use it [20].  
Companion robots are also used in studies with the 
elderly. An example of a companion robot is PARO, the 
seal robot [21][22][23]. The seal robot PARO was used in 
facilities for the elderly in the Nursing-care Robot 
Promotion Project, in Japan [22]. An initial study showed 
that the elderly participants suffering from various mental or 
behavioral issues, but who interacted with PARO over time 
improved their communication, reduced their aggression 
and wandering, as well as improved the sociability of the 
participants, over time [22]. PARO also seems to be widely 
accepted across cultures [24]. Other examples of companion 
robots are Pepper and NAO used in exploratory studies, as 
shown in [25]. AIBO, Furby, and NeCoRo are a few other 
robots representing animals that were used in therapy with 
children, or in nursing homes with the elderly [21][22].   
Another project from the EU project within the Ambient 
Assisted Living (AAL) is Enabling Social Interaction 
Through Ambient (EXCITE) [26]. The project introduced 
the Giraff robot in several homes with the purpose of 
studying “social interaction through robotic telepresence” 
[26, 827], an idea that stemmed from the RoboCare project 
[27]. 
Finally, it seems that “20% of the world’s population 
experience difficulties with physical, cognitive, or sensory 
functioning, mental health or behavioral health” [3]. In 
numbers, there are around 190 million people experiencing 
difficulties with ADL, including physical tasks and 
cognitive tasks [3]. Further, it seems that the aging of the 
workforce has consequences within the healthcare field 
[28][29]. A study from [30] shows that, for instance, in 
Sweden, the cost for the home care for the elderly would 
increase between 20 and 35% between 2013 to 2020, 
whereas this could instead be reduced by 50% as of 2020, 
with the digitalization of the home care services [30]. In 
Norway, the elderly population will increase by 21% by 
2050 [31]. Furthermore, the active working force will not be 
able to tackle the healthcare needs imposed by this increase 
[31] and yet among the action plans taken at the European 
Union’s level, regarding this societal challenge, is the 
digitalization of health through the use of Information 
Communication Technologies (ICT’s) [32]. Moreover, 
several studies address directly or indirectly the issue of the 
digital divide between users with ICT literacy and those, 
with reduced ICT literacy. Elderly are often included in the 
group of users with reduced ICT literacy as shown in 
[33][34][35][36]. Yet, all the above yield at how important 
it is to make sense of the design of today’s technologies, 
including those that move: semi-autonomous robots for the 
use in the homes of the elderly. Nevertheless, one of the 
designing principles for designing good smartphone 
technologies and semi-autonomous robots is to give 
informative feedback when an error occurs [37][38]. 
Understanding feedback is, therefore, highly relevant in this 
context. Next section gives an introduction to the main topic 
discussed in this paper: feedback.  
III. 
FEEDBACK 
In this section, we describe how feedback is currently 
discussed in the HCI literature.  
Feedback is an abstract concept that was used in a number 
of disciplines. Diverse elaborations and explorations of 
feedback definitions are encountered from control theory and 
cybernetics to the definitions used in HCI [1][39]. Before 
going further, we wish to turn to the definition of feedback, 
within HCI, as explained by Norman (2013): informing the 
user, in some way, that the system is working, as a response 
to the user’s action [40].  
Feedback in the interaction with a desktop computer 
interface was well established a long time ago and often 
already understood by the user [41]. Here are a few examples 
based on Apple’s User Interface Guidelines dating back to 
1992: feedback to the user when typing in passwords by 
displaying a bullet character for each typed character by the 
user; feedback of a cursor showing a delay after user has 
moved a big document to the trash bin; a dialogue box 
feedback informing the user about his or her actions’ result; 
when the user deletes everything from the trash bin, an empty 
trash text should be displayed; when selecting an option in a 
radio button, the user should see a bullet in the selected 
option; when an option from a menu is chosen by the user, 
the option is hoovered or the background color is changed; 
when an item is selected from a palette of patterns or colors, 
that option is highlighted or outlined; moving around 
windows on the desktop is illustrated immediately to the user 
through the windows new position; an active window is 
highlighted or outlined; when a user shall be informed about 
potential dangers, such as an unsafe document to be opened, 
or a non-reversible action, the user should be informed 
through a caution alert box, where the user has the possibility 
to cancel the action or to proceed further; or a button that is 
clicked or hoovered over shall be highlighted [41].  
According to [42], feedback is an important concept that 
is studied, especially within education. However, within the 
HCI field, it seems still to remain ambiguous and primitive, 
and “is oversimplified” [42, 253]. While some of the 
literature identifies feedback as a response to the user’s 
action [9], others talk about feedback as a way “to 
communicate the state of the system independently of the 
user’s action” [43, 316]. Feedback can be visual, auditory, 
haptic, and some talk about it as bio-feedback in HCI studies 
that measure or self-track the human [1]. Others talk about 
eco-feedback in sustainability and environmental HCI 
studies, or affective feedback [1].  

71
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Further, language seems to play a central role in HCI, in 
auditory and textual feedback. However, we have also seen 
that language per se used in the interaction with computers 
or machines does not always work: see for instance the 
example of the natural language processing ELIZA used in 
early days of Artificial Intelligence (AI), mentioned in [44]; 
or the example of textual feedback using technical language 
of “it cannot connect to the cloud services” [1, 176]. [44] 
talked about how the HCI field evolved based mainly on 
conversational and linguistic development, a common 
language [44]. This was mainly a question of mutual 
intelligibility through language.  
But the HCI field has evolved, and while visual, auditory 
and textual feedback still remain essential, it also seems to 
become more common to interact with things that move. As 
[45] has earlier put it: the conditions for the possibility that 
the world as an adjacent to everyday interaction becomes an 
interface for computation, we could, in his words, through 
this type of interaction “capitalize our familiarity, skill and 
experience in dealing with the everyday world around us” 
[44, 1]. In addition to the development of a common 
language, we also need to develop a shared understanding, 
mutual intelligibility of the motion of the robot: “A robot in 
the real world, however, must consider the execution of the 
plan as a major part of every task. Unexpected occurrences 
are not unusual, so that the use of sensory feedback and 
corrective action are crucial” (Raphael, cited in McCorduck, 
1979, p. 224), in [44, 23]. How can then the movement itself 
of things be applied in order to facilitate human interaction 
with things? What experience of the robot’s movements 
should be designed for? And what do these movements 
communicate to the user? How are these movements 
interpreted by the user as feedback? How do we describe 
patterns of movements, styles of movement, or ways of 
moving? How can these movement styles be mapped as 
feedback to the user?  
Before going further, we would like to explain polarity 
feedback, homeostatic feedback, and archival feedback – 
types of feedback that we found in the existent literature. 
This is later our departure point for discussing motion as 
feedback. 
A. Polarity Feedback: Positive and Negative 
Polarity feedback can be regarded as positive or negative 
[42], depending on how the feedback is interpreted by the 
user, compared to the user’s expectations. According to [42], 
feedback as information retrieval, in the broader sense of it, 
is formed by a message, a cognitive interpretation, and its 
context. For instance, a user sets the temperature on a 
thermostat in a room to be 25°C degrees. In this situation, the 
visual feedback can be translated as positive, if it shows the 
temperature set by the user, or at least close to what the user 
has set (23°C degrees, or perhaps 26°C degrees) could still 
be accepted. However, if the temperature of the room does 
not seem to be close to what the user has set, say 15°C 
degrees or 35°C degrees, the feedback is translated as 
negative feedback. In other words, positive feedback is when 
the system responds accordingly or at least close enough to 
the input of the user, meeting the user’s expectations. On the 
other hand, negative feedback is when the system does not 
respond exactly or close enough to the user’s input, resulting 
in a high difference between the system response and the 
user’s expectations. Negative feedback does not necessarily 
need to have a negative value, (+)15 °C can still be 
considered a negative value.  
B. Homeostatic Feedback 
Feedback has a polarity, positive, and negative, but it can 
also be homeostatic [46]. Homeostatic feedback is a type of 
feedback that is constant, regardless if the feedback is 
positive or negative; the state of the feedback is the same 
over a longer time period. Polarity feedback and homeostatic 
feedback are not mutually exclusive: positive or negative 
feedback can also be at the same time homeostatic [42]. 
Taking the same example of receiving feedback from a 
thermostat on a room’s temperature homeostatic feedback is 
when the thermostat shows over a longer period of time 
exactly 25°C degrees, according to the user’s input. But 
homeostatic feedback can also be negative feedback of 15°C, 
or 30°C degrees, over a longer period of time. If the 
thermostat does not start, although the user has pressed a 
start button, it can also be translated into a homeostatic 
negative feedback. 
C. Archival Feedback 
The literature discusses archival feedback [46]. This type 
of feedback is distinguished from immediate feedback [46]. 
Such a type of feedback logs and remembers the system’s 
previous actions, in such a way that it can return to a 
previous state. A concrete example is when the user uses the 
UNDO button: if the actions of the user were logged over 
time, then the UNDO button performs a positive action, e.g., 
the system goes back to a previous state. This type of 
feedback that logs and remembers previous states of the 
system is called archival feedback. If the UNDO button 
cannot perform this operation, pressing the UNDO button 
gives a negative feedback, e.g., nothing changes – the system 
stays the same. However, the system should inform the user 
anyway, that nothing was changed. This is then not an 
archival feedback, but rather the user receives a negative 
feedback on its input regarding the archival feedback.  
D. On Motion - As Feedback 
Following Mitcham’s (1978) in [47] it seems that a tool 
is activated by the human agency, while a machine can, to a 
certain degree, operate independently [47]. Following this 
definition, we could say that a semi-autonomous robot used 
at home is in a way a machine – something that acts 
independently, but also a tool, since it is controlled at some 
degree by the user: through a button, or by using an app as a 
remote controller, or through a remote controller.  

72
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
In general, humans know where they are, or how to 
navigate their way where they want to get [47]. One can 
navigate his or her way based on own knowledge or 
familiarity with the place, or by using a map. This is done 
through their own body’s locomotion [47]. Wayfinding is 
different from navigation, by moving from a location to 
another region (compared to navigation, which is moving 
from one location to another location) [47, 219-242]. A 
semi-autonomous robot is moving within a home through 
both types of motion: first, through wayfinding, by creating a 
map of the place; and second, through navigation, moving 
around on the already mapped space. These types of 
movement can be classified as locomotion, or a global 
movement, according to [48]. Besides these movements, a 
robot also has its own motions, such as moving the head of a 
robot, moving an arm, without changing the robot’s location. 
The authors classify this type of movement as a local 
movement, or to use the term from robotics, configuration 
movement [48]. In this paper, the local movement is 
considered as still type of motion.  The paper is mainly 
concerned with the locomotion type of movement. Rather 
than going into the depths of motion and animation 
techniques here, we would like instead to focus on exploring 
further domestic robot’s motion as feedback: What kind of 
feedback does the user receive and in, which situations? 
What are the implications of the motion for the feedback? 
How is the robot motion perceived by the users in terms of 
feedback? 
We have earlier conceptualized feedback [39] based on 
Hall et al. (1968) proxemics [49]. We have identified that a 
semi-autonomous robot includes the same types of feedback 
as a smartphone app technology, but in addition, it has the 
motion element [39]. We observed that the motion of  
the robot could be considered as a type of feedback that it is 
manifested through distributed feedback, via extended 
proxemics, when the feedback from a robot is given via an 
app [39]. We noticed that this type of feedback was 
distributed when using an app. To simplify the discussions 
later, we illustrate (a) getting feedback from a smartphone 
app technology vs. (b) getting feedback from a robot (Fig. 1). 
We also noticed that while feedback from a smartphone is 
direct, feedback from a robot can be both direct, from the 
robot, or distributed, via an appWe build in this paper further 
on the earlier reported work, the motion as a form of 
feedback, by investigating the motion of the robot, and by 
looking at how it is made sense by the users. We do this by 
bringing up examples from our empirical data (Section VI). 
We make sense of motion as feedback based on our 
empirical data, by distinguishing between feedback from a 
smartphone and a semi-autonomous technology, reshaping 
and molding the notion, understanding and making sense of 
the motion as feedback. In this way, can these various types 
of motions be perceived as feedback by the participants? 
How can we classify then these motions as feedback? 
Introducing a common vocabulary may help us to talk about 
motions of semi-autonomous things in homes in a better 
way, similarly to perspectives from other fields, such as 
mathematics, 
physics, 
medicine, 
or 
biology: 
anthropomorphizing – moving like a human; zoomorphic – 
animal movement, robot morphing – moving like a machine. 
We continue in the next section by laying our theoretical 
foundation: the familiarity concept. The concept will later in 
the paper help us to unpack and understand the feedback 
notion.  
 
Figure 1. The user receives feedback 

73
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
IV. 
THEORETICAL FOUNDATIONS: ON FAMILIARITY 
According to [50], theory helps us “to structure 
knowledge, to evaluate and assess it, to construct it and share 
it” [50, 126]. Amongst their six models of using theory, there 
are also: theory as a contextual tool, where the researchers 
start with a research question and take a position, often 
referring to theory as concepts, ideas, or perspectives; and 
theory as an analytical tool, where the researchers use the 
theory to analyze and interpret the findings in the light of the 
theory [50]. In this paper, we have used both these types of 
using theory: for both the former and the latter one, we posit 
the paper within the frame of the familiarity concept used in 
HCI. 
The concept of familiarity is illustrated in Heidegger’s 
Being and Time as “[knowing] its way about” [51]. 
Familiarity can be described as an intimate, close, and 
friendly state, or interaction [52]. In Dreyfus’ view, 
familiarity gives one the tools to respond correspondingly to 
different situations [53]. In HCI, familiarity has been used as 
a base for the design. For instance, this concept can be used 
in the skeuomorphic design. Skeuomorphic design refers to 
when the digital interface adopts some of the physical 
artifact’s properties in order to accommodate better the user 
by making the digital artifact looking more familiar [54]. 
Such an example is, for instance, when a digital interface 
imitates the paper look of an old book. Others have used it 
within the design of tangible systems [55]. However, it 
seems the concept is still underexplored within HCI, while it 
seems to be important in the sense-making of using 
technology. For instance, [56] found that familiarity plays a 
central role in individuals’ relationships with technology 
[56]. Later, [57] pointed out that familiarity concept did not 
get too much attention in the field of HCI, besides his 
previous work together with Van de Walle [57]. 
Inspired by the work of Heidegger, Mereleu-Ponty, and 
Dreyfus, [58] tried to make sense of everyday’s examples of 
interacting with technology, the readiness of coping with it in 
everyday life situations. Further, familiarity is based on 
several key points [55]. Among these are: familiarity with 
digital technology depicts a “know-how” relationship [58] 
based on a tacit knowledge; familiarity is based on everyday 
use, on reading about it, and being taught how to use it; 
familiarity with digital technology means knowing how to 
use it, or using Turner’s words, “to be ready to cope with it” 
[55, 25, emphasis added]. Familiarity is also a form of 
engagement, of what Heidegger calls involvement [59]. 
However, familiarity with technology is more difficult 
because involvement with technology can become complex 
[59]. Involvement represents a form of care, enfoldment, 
entanglement, according to [55]. Familiarity also has an 
affective part that builds upon feelings of closeness, of being 
at home, feelings of comfort, ownership, and warmness [55]. 
Inspired perhaps by Heidegger’s “being-in-the-world,” he 
calls this relationship of co-existence with technology as 
being-with [55]. According to the author, an appropriate way 
of becoming familiar with technology is to integrate it within 
the participants’ everyday life [59]. He sees this type of 
relationship as a co-existence relationship with technology 
[59]. Turner (2008) also says that familiarity can be 
illustrated as one’s perception change rather than knowledge 
creation [57] . 
Finally, [60] also argued for familiarity as a basis for 
universal design. They mean that HCI is based on the 
distinction between man and machine [60]. Furthermore, 
[61] described it as an intimate or close relationship, where 
humans engage with- and try to understand the technology 
[61]. The authors propose a salutogenic approach, as a way 
of focusing on the factors that contribute to well-being and 
health, rather than treating or fixing a disability, incapability 
or weakness [61]. In this paper, we try to understand the 
participants’ engagement with the technology, by making 
sense of the feedback received from the technology, being it 
a smartphone app or a semi-autonomous robot.  
In the next section, we continue by introducing our 
methodology and methods used in this study. 
V. 
METHODOLOGY AND METHODS 
According to [62], interpretive research is afforded 
through “language, consciousness, and shared meanings” 
[62, 2]. Boland (1985) in [62, 2], says that “the philosophical 
base 
of 
interpretive 
research 
is 
hermeneutics 
and 
phenomenology.” Further, we followed one of Ricoeur’s 
thesis that hermeneutics builds upon phenomenology [63].  
In addition to the earlier reported work [1], we have now 
included both researchers and several elderly people in the 
study. We describe next our study context, study design, the 
robots used in this study, selection of robots, participants, 
data collection, and data analysis, as well as ethical 
considerations.  
A. Study Context 
The study was performed in the old district area of Oslo, 
Norway. The area has approximately 3000 senior citizens, 
over 67 years old. Some of these elderlies choose to live in 
accommodation facilities for the elderly. The elderly usually 
live there independently, or together with their partners. 
However, the accommodation is provisioned with a 24/7 
reception staffed with at least two personnel, available for 
the elderly, a gym, a restaurant for taking breakfast or lunch, 
which is also open to the public, a library where meetings or 
various courses are held, and an open area for coffee breaks 
and other events. Several studies have been performed in 
such facilities [64][65][66][67][68], but none of these report 
data on the use of robots or semi-autonomous robots in the 
homes of the independent living elderly. 
B. Study Design 
This study was divided into three stages. The first stage 
was a pilot phase, with the purpose of learning, and getting a 
pre-understanding of the context (stage 1). Next, several of 
the researchers involved in the project tried out the semi-
autonomous robots in their homes (stage 2). After some of 

74
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the researchers have tried out the semi-autonomous robots, 
we started introducing the first available robot in the homes 
of the elderly (stage 3). In some cases, the robots were run in 
parallel in both homes of the elderly, and homes of the 
researchers.  
C. Robots in this Study 
In this study, we have used semi-autonomous vacuum-
cleaner robots in the homes of our participants. Selecting 
such a robot was a bi-informed choice. On the one hand, our 
elderly participants reported earlier familiarity with semi-
autonomous robots, such as vacuum-cleaners and lawn-
mowers that they have seen on TV and were keen to test out. 
These types of robots are sometimes referred to as domestic 
robots or domotics. On the other hand, the study is part of the 
MECS project, that aims to develop a robot for independent 
living elderly. This study was made at an incipient phase of 
the project. The project did not have yet any fully developed 
robot for the independent living elderly, such as a safety 
alarm robot, in place at the time. Therefore, we chose to 
build on our senior participants’ familiarity with the robots, 
e.g., by selecting semi-autonomous vacuum cleaners to be 
used in their homes.  
We have initially investigated several potential robots to 
acquire for our study. We finally selected three of them for 
the purpose of our study: iRobot Roomba 980 [69], Neato 
BotVac, and Samsung PowerBot VR20H. Table I below 
gives a summary of the technical specifications of the robots. 
 
TABLE I. SUMMARY: TECHNICAL SPECIFICATIONS OF THE SELECTED 
ROBOTS 
D.  Selection of the Robots to be Used in the Elderly’s 
Homes 
When the robots were introduced in the homes of the 
researchers in the first stage of the project, we noticed soon 
that iRobot Roomba 980 and Neato were the most 
appropriate for the elderly, due to their reduced sizes, 
compared to BotVac robot. This led us to make the choice of 
only using iRobot Roomba 980 and Neato in the elderly’s 
homes. 
E. Participants 
13 participants took part in this study: seven (7) of the 
participants were researchers that tested the robots as part of 
the pilot study, including the authors (SD, HJ), during the 
period of times ranging from about one week to about one 
month. At this stage, 2 females and 5 males participated. Six 
(6) elderly persons used the semi-autonomous vacuum 
cleaner for about one month: 5 females, and 1 male. Three of 
the elderly participants were included in the previously 
reported 
work 
[1]. 
The 
participants 
had 
different 
backgrounds and presented different levels of interest in 
modern technologies.  
The researchers are represented in this study by both 
junior and senior researchers. The elderly participants (≥65 
years), part of the MECS project, were recruited through 
MECS’ partner organization. Due to the high commitment 
that the study required, including weekly visits, the use of the 
robot, photos, participant diary notes as domestic probes, 
observations, and interviews, only six elderly participants 
were willing to participate within the timeframe of study data 
collection. The participants were self-selected and took part 
in the study based on their free will. Some of the participants 
took part in the study through the snowball effect by finding 
out about the study from others.  
F. Data Collection 
The data was collected from researchers and the elderly. 
The data collected from researchers was retrieved through 
diary notes and photos (Table II). The data collected from 
the elderly participants were retrieved through interviews, 
elderly’s diary notes used as domestic probes, photos, 
researcher’s notes, and headnotes (Table III on the next 
page).  Headnotes are “experiences, impressions, encounters, 
and evaluations that are continuously present in [the] 
memory,” according to [70] following [71]. Each senior 
participant received a notebook to be used for their diary 
notes. We kindly asked the elderly participants to note down 
in their diaries the situations they encounter. These notes, or 
posts, as we named them, were written by the elderly, 
especially when something unusual or unfamiliar occurred. 
 
TABLE II. OVERVIEW OF THE DATA COLLECTED FROM RESEARCHERS 
 
Robot 
 
Specifications 
iRobot 
Roomba 
980 
Neato  
BotVac 
Samsung 
POWERbot  
Dimensions (Depth x 
Width x Height) 
35 x 14 x 
9.2 (cm) 
33.5 x 32.1 
x 10 (cm) 
37.8 x 13.5 x 
36.2 (cm) 
Weight 
4 kg 
Ca 4.1kg 
Cca 4.8 kg 
App 
as 
a 
remote 
controller 
YES. 
iRobot 
Home App 
Yes. Neato 
Robotics 
Yes. 
Powerbot, 
smart 
home 
app. 
Charging  
Battery 
and 
electricity 
Battery and 
electricity 
Battery 
and 
electricity 
 
Data collection methods - Researchers 
# 
Timeframe 
Documentation 
Robot used 
1  
One week  
Yes. Diary notes, seven posts (one 
per day), ca 4 and a half A4 pages, 
analog format, 28 photos 
Neato 
2 
Ca two week  
Yes. 3 pages of A4 notes, digital 
format, 4 photos enclosed 
Neato 
3 
Ca one week  
Yes. Short notes on strengths and 
weaknesses of using such a robot, 
digital format 
iRobot 
4  
One week 
Yes. 1 page of notes, digital 
format  
Samsung 
PowerBot 
5  
Ca one week 
Yes. Half page was written notes 
on strengths and weaknesses, 
digital format 
Neato  
6  
Ca one month 
Yes. Four pages of written notes, 
22 posts, digital format 
Neato  
7  
Ca one month 
Yes. Ca 19 A4 pages of written 
notes, analog format 
Neato 

75
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
G. Data Analysis 
The process of analysis started already while being in the 
field, as a form of doing some preliminary work [72]. This 
has been followed by a multiple stage analysis process, 
where the data went through some analytical filters. 
Specifically, we have followed thematic analysis from V. 
Braun & V. Clarke to analyze the data collected in stage 2) 
and 3) [73]. This was done in 5 steps. We have first started 
by trying to familiarize ourselves with the data (step 1). We 
did this by creating a map of data and resources, which later 
resulted in Table II, respectively Table III.  At this stage, we 
had put aside the initial research question, to be open for 
novelty, for what may come up and we did not think of, 
trying to focus on what the participants found interesting. 
Thereafter, our analysis was done in a bottom up fashion 
starting from coding each of the resources (step 2). We have 
then grouped the resources in three categories based on the 
data sources: researcher’s diary, researcher’s observation 
notes during elderly’s observation and elderly’s own diary 
notes, and interviews. At this point, the raw data became 
textual data, in the form of transcribed interviews, notes, or 
interview summaries. All the interviews with the elderly 
were transcribed verbatim by author SD. The transcribed 
interviews alone resulted in around 26000 words exclusive 
the pilot interview (circa 33500 words together with the pilot  
 
TABLE III.  OVERVIEW OF THE DATA COLLECTED FROM THE ELDERLY 
interview). At the same time, the author (SD) went through 
the photos taken (n=147). The coding was done by reading 
the material “line-by-line to identify and formulate all ideas, 
themes, or issues they suggest, no matter how varied and 
disparate" [74, 143]. This resulted in a variety of scattered 
codes.  
Next step was collating the codes further into sub-
categories for each of the data sources (step 3). This was 
done through color coded post-it notes by the author (SD). 
We cannot claim a full inter-reliability of the study, as the 
coding was done by one author (SD) [75]. However, 
following [75], validity, in this case, is not of "a particular 
concern", as the study focuses on exploring the potential 
challenges one may encounter when a robot is introduced in 
the home [75, 212]. Moreover, the findings were discussed 
at different points during data collection amongst the 
researchers in the project. In addition, the collated codes 
were discussed by the authors (SD, HJ) during the data 
analysis.  
As a result, the data collected through researcher’s diary, 
researcher’s observation notes and elderly’s diary notes, and 
interviews resulted in [n=51], [n=47], respectively [n=124] 
collated codes: a total of [n=222] codes. At this stage, we 
were searching for themes. We observed that some of the 
collated codes were present across several of the resources: 
written utterances during our drop-in visits (usually once per 
week, or on request), and utterances from the interviews. We 
# 
Data collection methods - elderly 
Gender 
(Female 
F, Male 
M) 
Interview 
Elderly’s Diary 
notes 
Researcher’s 
notes 
Photoswe
re taken 
by the 
researche
rs 
Eventual details about the robot used, if any 
assistive technologies were used, and level of 
information technology literacy 
1 
F 
Circa 1 hour, audio-recorded 
pilot interview, transcribed 
verbatim (SD) 
AND 
Circa 1 hour and 45 minutes 
of 
untranscribed 
audio-
recording 
from 
the 
installation of the robot 
Yes. Circa 5 A4 
pages, analogue 
format. 
Yes. Circa 2 
A4 pages. 
Yes. 36 
photos 
iRoomba, 87 years old, walking chair, did not 
use the app 
2 
F 
Circa 40 minutes, audio-
recorded, 
transcribed 
verbatim (SD) 
 
Yes. Circa 3 A4 
pages notes, 
analogue format 
Yes. Circa 2 
A4 pages. 
Yes. 4 
photos. 
iRoomba, walking chair, necklace alarm that she 
does not wear it, high interest in technology, used 
the app, has a smartphone,  
3 
M 
Circa 25 minutes, audio-
recorded, 
transcribed 
verbatim (SD) 
 
Yes. One letter-
size page, analog 
format, 
short 
notes. 
Yes. Circa 4 
letter-sized 
pages. 
Yes. 10 
photos. 
Neato, wheelchair, not interested in technology, 
did not used the app, easy to use, has a wearable 
safety alarm 
4 
F 
Circa 33 minutes audio-
recorded, 
transcribed 
verbatim (SD) 
 
Yes. One A4 
page, analog 
format 
Yes. Circa 2 
A4 pages. 
Yes. 36 
photos 
iRomba, wheelchair, interested in technology, 
did not use the app, easy to use, does not have a 
smartphone, wearable safety alarm 
5 
F 
Circa 45 minutes audio-
recorded, 
transcribed 
verbatim (SD) 
 
Yes. One letter 
size page, analog 
format. 
Not available 
Yes. 13 
photos 
Walker, did not use the app, not interested in 
technology, does not have a smartphone, 
wearable safety alarm 
6 
F 
Circa 43 minutes, audio-
recorded, 
(transcribed 
verbatim) (SD) 
Yes. 4 letter-size 
pages, analog 
format. 
 
Yes. Circa 1 
letter-sized 
page. 
Yes. 16 
photos 
Interested in technology, no walker, wanted to 
use the app, but gave up, does not have any 
wearable alarm 

76
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
looked for performative utterances [76]. This was carefully 
paid attention to due to two main reasons: in order to observe 
whether or not the researchers and elderly encounter the 
same type of challenges with the robot, and how information 
technology literacy influenced the attitudes towards the 
robot.  
Finally, the collated codes and findings were discussed 
between the authors (SD, HJ) at multiple times. At this stage, 
we reviewed the themes resulted (step 4). The final analysis 
resulted in three main themes: robot, home space, and human 
emotions and perspectives on perceived autonomy (step 5). 
H. Ethical Considerations  
The project is in line with the ethical guidelines from the 
Norwegian Center for Research Data (NSD) (ref. nr: 50689). 
The data collected during this study were stored on the 
Services for Sensitive Data (TSD) facilities, owned by the 
University of Oslo, Norway, operated and developed by the 
TSD service group at the University of Oslo, IT-Department 
(USIT). All the data was anonymized. Prior to starting the 
study, the participants were given detailed information about 
the study. The participants could withdraw at any time 
without 
giving 
any 
explanation 
and 
without 
any 
consequences for them. The participants willing to 
participate signed informed consent before taking part in the 
study. 
During the study, we had constant contact with our 
participants, through regular visits, often each Wednesday, 
on pre-agreed times, but also on demand, if they needed any 
support or had questions. Sometimes, we called them on the 
phone just to check if there was anything they wondered 
regarding the robot. They also received our contact details 
and could contact us at any time.  
VI. 
FINDINGS  
This section presents the findings from this study. The 
findings are structured in three categories: the user receives 
feedback from a smartphone technology (Sub-section A), 
the user receives distributed feedback via an app (Sub-
section B), and robot motion as feedback and its implication 
for the user (Sub-section C). The findings are supported by 
empirical examples. A detailed account is given below for 
each of these. 
A. Findings:  The User Receives Feedback From A 
Smartphone Technology 
In this section, we present a situation where the user 
receives feedback from a smartphone app technology. This is 
illustrated through textual feedback that is either improper or 
lacking. Fig. 2 illustrates the situation presented here.  
 
 
Figure 2. Feedback between smartphone technology and a (human) as user 
1) Providing Improper Feedback 
The user is provided with improper textual feedback [1]: 
a)  “SMS shows full. Do I need to buy a new phone?”: 
One of the participants told us about her experience with the 
mobile phone and the feedback of SMS - full blinking icon. 
Her concern was that she could not store any longer the 
photos she received from her family. The participant was 
concerned that she had to buy a new phone, and that this 
would lead to losing the existent photos. 
b) “Where is the ‘No’ option when updating 
software?”: Another situation described by one of the 
participants was related to getting constant updates, where 
she gets either the option ‘Now’ or ‘Later,’ but not a ‘No’ 
option. She contacted the company providing the operating 
system via a handwritten letter and asked about this option. 
To her surprise, she got called up by the customer service, 
and got offered help on how to deal with the two options 
available, ‘Now’ and ‘Later,’ but the company had no plan 
to introduce a No-option. The participant explained that she 
knew how to deal with the updates, but what she wanted 
was that the feedback should embed a ‘No’-option 
alternative. Regarding this design issue, this has to do with 
the continuous update of software and the point of view of 
the elderly on these always encountering updates. This 
example illustrates a situation where feedback messages do 
not provide enough options.  
2) Lack of feedback 
 “You were terribly afraid of doing something wrong”: In 
one of our interview sessions, one participant describes that 
when she learns using new technologies, she is so afraid of 
doing something wrong. A concrete example is that the 
technology, being it smartphone or tablet, does not provide 
any feedback on how to get back to basics: “so you were 
very afraid that... I did not feel I could come back to the 
base. But I was afraid to do something wrong.”  
 By this, the participant means that the applications are 
built in such a way, that one is expected to have that intuitive 
knowledge, but for new users, it can be difficult to 
understand how to navigate within an app, and one can easily 
get stuck. 

77
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
B. Findings:  The User Receives Distributed Feedback 
From A Robot via an App 
This sub-section illustrates the situation when a user 
receives feedback from a semi-autonomous robot technology 
via a smartphone, through an app. We illustrate first some of 
the implications that the use of such an app has for the user 
at the installation time. Thereafter, we illustrate some 
situations where the users received either improper feedback, 
or the feedback was lacking. An illustration of the situation 
is presented in Fig. 3 below. 
Some of the participants have chosen to install the app in 
order to control the robot remotely. Several steps had to be 
followed in order to install the app. As the diary notes show, 
for Neato robotics app, for instance, one should create an 
online account. This, required an email address. This 
required a Wi-fi connection to the network. One of the issues 
that occurred during this step at the installation of the robot 
in one of the participants’ homes was that the robot required 
a 5 GHz Wi-fi, while the participant’s router had only 2.4 
GHz.  
The next step was to choose the right robot amongst 
several robots listed in the app. The final step was to connect 
to the robot. Once the app was installed, a map of the local 
space was created within the app after the robot has moved 
around. The map provided the approximate area, including 
obstacles, edges of space, and door limits (Fig. 4). 
One of the participants gives a rich description of his 
experience on installing the app: “Today, it's time to get this 
thing going. First, I need to connect to the vacuum. This 
involves enabling Wi-fi on the vacuum, then connect your 
phone to the vacuum's Wi-fi access point (yes, the vacuum 
has its own Wi-fi access point). Then you can use  
 
   
 
 
Figure 4. Example on the map is shown in a robot app that was generated 
by the robot 
the Neato app to choose the actual Wi-fi point to connect to. 
On the one hand, this makes it easier to configure the robot 
since you connect only to it and you get the richness of a 
mobile app to input information (including passwords to 
access point), but it's not without some flaws. First, I 
assumed it would show the access points right away; it 
didn't. So, I typed in the access point and the password. I 
should also point out that I connected it to the "guest" Wi-fi, 
not our main Wi-fi.  It's suddenly at this point that I realize 
how little I trust this thing belonging to the main network, 
and I start to think about other ways to partition the 
network. […] Regardless, the phone tells me that the 
process may take up to 3 minutes and that I should watch 
Figure 3. Feedback from a semi-autonomous robot technology to a (human) user mediated via an app 
Figure 1.   

78
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the robot's display screen during this time. I do, but it only 
shows the current setting of Wi-fi on. When I try to move 
back, I accidentally turn off Wi-fi, and I put the system in an 
uncertain state. I try to re-enable the wi-fi, but now the 
phone and the robot are confused. The phone, after 3 
minutes, reports that the wi-fi information was "incorrect" 
and urges me to try again. But the robot refuses to 
rebroadcast its Neato access point. […] I switch the vacuum 
off using its hardware switch and then turn it back on. I go 
through the process again (with a lighter touch on my 
fingers). […] Then, I can choose the network and enter the 
password. This time it connects shortly thereafter. At this 
point, the robot asks for a name, I just give it Neato, and I 
set it out for its first vacuum tour” (Diary notes, 
Researcher). 
Further, we found out that many of the in-app 
instructions and paper instructions that came along with the 
robot were available only in English. Many of the elderly 
participants pointed out that they do not feel comfortable 
about using technologies in English, and it would have been 
better to have it in their mother tongue, Norwegian. Here is 
an example of what one of the participants say: 
(Participant): “Yes. So it was another time when it got stuck 
in the charger, and it blinked. It was something about the 
light, but I did not understand what it was. I have missed a 
Norwegian instruction manual. It would have been very nice 
to have one.” (Interviewer): “You are not the first person 
saying this. […]” (Participant): “Because even if I 
understand pretty well English, these technical things are a 
lot worse, because you do not understand them so well: 
technical language is more difficult!”  (Interview, Elder 
person). 
1) Providing Improper Feedback:  
Another issue that seems relevant to the use of the app 
was when a power outage occurred, and the app stopped 
working, as it required an Internet connection. During a 
power outage, the app controlling the domestic robot 
stopped working, according to one of the elderly 
participants. The participant got a message that the app 
“cannot connect to the cloud services”. The use of technical 
terms, such as “cloud service” when giving feedback to the 
user, seems to be inappropriate. She said: “It was just 
standing still there, or when I pressed on it where it says 
something about cloud-service. It didn’t do anything, but I 
thought you would come tomorrow” [1]. The technical term 
“cloud service” confused the elderly user. The user, in this 
case, relied on the researchers help to come along the next 
days. 
Another participant wrote in his diary notes that the robot 
urged for attention through a feedback message: “Please 
clear my path (2000) and a red cross” (Diary notes, 
Researcher), without understanding the meaning of the error 
2000. Another participant referred to the message he 
received from the app as a “cryptic message.” One of the 
participants explained that the app does not give proper 
feedback regarding the area of the room: “The area cleaned 
shown on the map is 4 mp2. But the hall and room 3 are 
more than 4 mp2.” (Diary notes, Researcher). 
2) Lack of Feedback: 
It seems that one of the participants has used the app to 
schedule the robot. However, the participant did not get any 
notification (e.g., lack of feedback) when the robot once 
started to run: “Went out to meet some friends, when I got 
home, I found the robot running. Apparently, I had turned 
on a schedule when I had last used the app. I'm not sure 
*how* I did this, but I did it. The Wife was home, so she 
picked up the rug in the entryway.” (Diary notes, 
Researcher) Another similar situation is illustrated in one of 
the participant’s diary notes: “We went out for a walk, and 
when we came home the robot was vacuuming, it had sort 
of cleaned the rug in the entryway, but not really. […] A bit 
annoyed, I looked at its schedule. It seems it will be going at 
9:30 tomorrow evening. We'll be ready for it this time. I 
enjoy that it has created a staggering vacuuming schedule, 
but a bit annoyed that it just launches itself out there.” 
(Researcher, Diary notes). 
C. Findings: Robot Motion as Feedback  and its 
Implications for the User 
In this section, we present situations where the users 
interact or engage with semi-autonomous robot technology. 
We make sense of the movements illustrated as feedback, as 
they 
happened. 
The 
situations 
illustrated 
that: 
the 
incoherence semi-autonomous robot’s motion triggered 
various feelings, including stress, anger or other feelings 
related to robot personification; the users received indirect 
feedback to do facilitation work, such as moving things 
around in home, lift the robot and move it manually to 
another place; and that the robot’s motion creates noise. An 
illustration of the situations described here is given in Fig. 5. 
1) Movement Triggers Feelings 
a) Feelings of Incoherence in Robot’s Motion: Some 
participants pointed out incoherence in the robot’s 
movement. The feeling of incoherence was triggered by the 
non-regular pattern of the movement, the user not being able 
to predict it. Indirectly, the robot motion gave a feeling of 
incoherence. Here are some examples: “I think it starts in 
one room, and then it goes to another, and then it goes again 
to the first room. I think it is a bit strange that it does not 
finish in the first room, and it goes perhaps to the kitchen, 
and then it comes back, and it continues likes this, and then 
goes out again. I think it was very strange (break), really, 
very strange.” (Interview, Elder participant); “[…] And 
suddenly it started going by itself one morning. I thought it 
was very strange.” (Interview, Elder participant); “One time 
when I pressed on HOME, it started going around by itself, 
so I had to carry it back” [the participant means here that she 
pressed on the HOME button, but she had to carry manually 
the robot back to its charging station]. 
b) Feelings of Anger, Stress, or Annoyance: Some of 
the participants found it stressful to follow the robots’ 

79
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
movement: “There? [it reads out loud from own diary notes]: 
Puhhh… It was a bit stressful to keep an eye on it. […] Yes, 
I think it was a bit stressful because it went so many times 
over the same place. And I think it is a waste, such a waste. 
It went back and forward, and I wanted then to... I just put 
my foot in his way, so it couldn’t go another way. You 
decide very little over it.” (Interview, Elder participant); In 
another elderly’s participant diary notes was written: “[…] Is 
this helping, or it will be Stressful [note that the participant 
writes the word Stressful starting with capital S]” (Diary 
notes, Elder participant). Another participant points out 
feelings of anger triggered by the robot motion: “So it was a 
bit stressful there! I was angry at it.” (Interview, Elder 
participant). Another participant said: “At the beginning, it 
was a little odd to have a device moving on its own while we 
are sitting in the living room or having dinner. Since this was 
our first experience with this kind of technology, it makes 
sense to be annoyed or even scared by this robot at the 
beginning. However, having a remote control to terminate 
the robot manually or to change the current function 
overcomes the fear!” (Diary notes, Researcher). 
c) Feelings 
of 
Personification 
– 
Robot 
as 
a 
Companion: However, besides feelings of incoherence in 
movement, stress, and anger, the robot also awaked feelings 
of personification – they viewed the robot like a pet, or 
someone in the home, that they talked to (Interview, Elder 
participant). Some of the participants personified the robots 
by giving them names such as King Robot, Frida, or Snilla. 
2) Robot Enacts the User to do Facilitation Work 
a) The Robot gets Stuck in Obstacles: There were 
several situations when the robot got stuck, in curtains, under 
the bed or sofa, in cables, or things around the home. Here 
are some exemplifications from both elderlies and 
researchers: “I got my brother fixing the cables under the 
bed, so they are not in its way. […] If it had gotten stuck 
there, I wouldn’t have been able to come down there. I was 
very afraid of this. So no cables were supposed to be there! I 
felt so much better then!” (Interview, Elder participant); 
(Interviewer): “Okay… But you also wrote in your diary 
notes that you had to clean a bit before you could run the 
robot.”; (Participant): “[…] I have lots of chairs here. I have 
put those two on top of each other because otherwise, it stops 
all the time. So I have removed them. And the cables […] 
Yes, I have cleaned a bit.”; (Interviewer):” Did they get stuck 
in the cables on the floor?” (Participant): “I have tried to 
remove those. Yes, because it stopped a bit... or it brought 
those with it. So I had to clean.” (Interview, Elder 
participant). Some situations are illustrated below (Fig. 6). 
 
 
Figure 6. Situations where the robot got stuck and needed facilitation work 
Figure 5. Feedback from a semi-autonomous robot technology directly to the (human) user   
 

80
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
A few other examples are: “[…] A chair had to be taken 
outside of the room, two pillows and a basket were set on a 
table, two cables had to be taken up. Two doors had to be 
closed. […]” (Diary notes, Elder participant); “The robot 
got stuck in the carpet’s tassels and stayed still. It took some 
time to free R from the tassels, so I took away the carpet. 
[…]” (Diary notes, Elder participant); “R got stuck under a 
little table, I have freed R and lifted the machine to the 
charging 
station.” 
(Diary 
notes, 
Elder 
participant); 
(Interviewer): “Do you see this as a problem?” (Participant): 
“Well… As I am quite strong, it works. But not everyone 
can lift and carry it.” (Interview, Elder participant); “On a 
shelf, it was a lamp, but its cable was down on the floor. 
The robot got stuck, and it dragged the lamp down. As a 
result, the lamp got disassembled in 2 pieces. Luckily it was 
a plastic lamp & it didn’t break. I could put it together.” 
(Diary notes, Researcher). One of the commented on how a 
robot generates other types of work – additional and 
facilitation work is needed to be done. “[…] The goal I had 
was to make the floor clean; but to get to this – I needed to 
install something on the floor…  A paradox.” (Diary notes, 
Researcher). 
Several participants suggested that one needs to do 
some facilitation work regarding the surface where the robot 
should navigate: “It started working, but it got stuck on the 
TV stand. I got a message about 10 minutes out. I then came 
back and freed it. It went for a while but got lost under the 
table. I pulled out the chair, and it seemed to go OK. 
Afterward, it did OK, though it tried to climb the entrance to 
the laundry room.” (Diary notes, researcher); “I pressed 
“HOME” button, it started.  After a while, it got stuck.  I 
remembered the previous installation at home when the app 
gave notifications about this – when I was out-of-the-house.  
This information was disturbing at that time since I did not 
want to do anything with it.  It interrupted a nice train 
journey I remember now and started off a train of thoughts 
of where it was stuck, and why (since I had done my best to 
make a “clean floor” there as well.” (Diary notes, 
Researcher). Another participant pointed out: “Managed to 
move small, light things like a tiny rug, map tube” (Diary 
notes, researcher). A few others said: “After getting tired of 
the robot getting stuck, I put the stripe on the area it always 
got stuck, and it worked fine. Yay!” (Diary notes, 
researcher); “I had to move the chairs that were under the 
table because it was too small. I’ve noticed that it didn’t 
reach.” (Interview, Elder participant); “Yes, it pulled the 
cables a few times. Especially those behind the sofa, it is a 
long cable, and it pulled it out. Now I have fastened it, so it 
doesn’t go on it any longer.” (Interview, Elder participant); 
“Isn’t it supposed that robots do their job on their own, 
without needing one’s assistance?” (Diary notes, Elder 
participant); “A few times I had to move because it got 
stuck a lot. So next time I had to move those things out 
[talks about furniture] But I think it is a bit confused 
because it seems to have memory. When I moved the 
furniture, I think it was a bit confused, I think. But yes, I 
had to move the furniture.” (Paraphrasing from an interview 
with an elder participant). 
b) The Robot Escapes and Indirectly Asks for 
Facilitation Work: Two of the elderly participants 
encountered situations when the robot would escape from 
their apartment. Here are some examples from our data: 
(Participant): “[reads out loud from his diary notes] Her 
name is Frida. It behaved well. It got away one of these 
days. I forgot to lock the entrance door, and it disappeared 
in the hall.”; (Interviewer 1): “[surprised] Okay. So it 
disappeared??”; (Participant): “Yes, yes. That one is wild. It 
went fast over the doorstep.“; (Interviewer 1): “So you had 
to go and bring it back.”; (Participant): “Yes, yes, yes. Yes, 
but maybe after it finished, it would have come back by 
itself. I don’t know.”; “I also had that door open, and it was 
out in the hall. But after, I closed the door, and it had to stop 
there.”. Some examples when the robot tries to go over the 
doorsteps are exemplified in the images below (Fig. 7). 
 
 
 
Figure 7. Robot escapes 
c) Motion Creates Noise 
Several participants, both researchers and elderly, 
reported that the motion of the robot created noise. Noise, in 
this case, can be accounted as a form of feedback for the 
motion, with the meaning of: “the robot is ON, and 
navigating around.” Here are a few excerpts from our data 
exemplifying this: “R has started just now. The Radio 
attenuates the sound from R.” (Diary notes, Elder 
participant); “[…] I have pressed on clean, but it was just 
standing there and making noise. I had to lift it to the 
charging station, press clean and R continued its tour.” 
(Diary notes, older participant); “Back to the engine sound.  
I guess this is to be worked with; to make it quieter.  
Perhaps it could be possible to make user settings; how 
much power should be used, and this will again regulate the 
sound/noise.  It is hard to think of the sound as nothing but 
noise… The sound from the movement is very low in 
comparison to the sound from the vacuum engine.  It is also 
more pleasant to the ear.” (Diary notes, researcher 
participant); “Checked the schedule, and thought nothing 
was on. So, I went out, but it turned out that it was actually 

81
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
going at 9:30. I wasn't there, but the wife was trying to sleep 
and complained about all the noise it made. But it got stuck 
somewhere, constantly asking for attention. When I finally 
got home, it was waiting at the front door, stuck in the 
carpet. It complained that it wanted the roller cleaned. I just 
put it away for tomorrow.” (Diary notes, researcher 
participant); “Noise, can't use together with TV watching” 
(Diary notes, researcher participant); “Any way to pause 
cleaning once it starts, e.g., to take a phone call? Via app?” 
(Diary notes, researcher participant). 
 
Finally, in this section, we have illustrated situations on 
the motion as feedback and its implications for the user, 
based on empirical data. In the next Section, we continue 
with discussing and unpacking further motion as feedback 
through the lens of familiarity based on the situations 
presented here, and also coming back to our initial stated 
research questions.  
VII. DISCUSSION 
“The designer of any artifact that is a tool must 
communicate the artifact's intended use and, in some cases, 
the rationale for its behavior, to the user. There is a strong 
sense, therefore in, which the problem with such a premise, 
however (as archaeologists well know), is that while the 
attribution of some design intent is a requirement for an 
artifact's intelligibility, the artifact's design per se does not 
unequivocally convey either its actual, or its intended use. 
While this problem in the interpretation of artifacts can be 
alleviated, it can never fully be resolved, and it defines the 
essential problem that the novice user of the artifact 
confronts. Insofar as the goal of design is that the artifact 
should be self-evident; therefore, the problem of deciphering 
an artifact defines the problem of the designer as well.” [44, 
14-15, emphasis added].  
What kind of emotions are triggered by improper or lack 
of feedback when engaging with a smartphone app or semi-
autonomous robot technology? How is a motion made sense 
of and understood by the users when engaging with a semi-
autonomous robot, in their homes? If the motion is 
illustrated as a type of feedback – what do we learn from 
their experiences?  
It seems that emotion and motion are, at least 
etymologically, interconnected. Etymologically, emotion 
dates back to the 12th century from the old Franch emovoir, 
which means to stir up, and from the Latin emovere, which 
means to move out, remove, agitate [77]. In the late 17th and 
18th century, the term illustrated “a sense of strong feeling,” 
and later was extended to any feeling, according to the 
Online Etymological Dictionary [77]. The term motion dates 
back to 13th -14th centuries and it means “the process of 
moving,” movement, change, coming from the Old French 
mocion, and from the Latin motionem, with the meaning of 
“a moving, a motion, an emotion” [78]. The term 
locomotion dates back to the 17th century and is formed 
from the Latin locus, which stands for a place, and the term 
motion [79]. Further, findings from our data present issues 
related to the robot, to the home space, and to human’s 
emotions and perspectives on perceived autonomy. We 
choose to limit our discussions related to the issues 
encountered that are related to the robot’s movement. The 
research questions are analyzed and reflected upon, based 
on the findings presented in Section VI, the Sub-sections A-
C. We do this through the lens of the familiarity concept by 
reflecting on the motion as feedback.  
A. The Role of Familiarity for the Emotions Triggered by 
the Engagement with Technology 
The first question that we address is: What kind of 
emotions are triggered in the user by improper or lack of 
feedback when interacting or engaging with a smartphone 
app or a semi-autonomous robot technology?  
An intuitive interface is an interface that the user 
naturally knows how to use it, whereas a familiar interface 
is an interface that the user has been exposed to over time 
and learned how to use it [80]. Raskin (1994) suggested that 
we should use the word familiar instead of intuitive 
[57][80]. We have earlier noticed that elderly participants 
feared interaction with unfamiliar digital technology 
because they did not master it, they did not feel able to learn 
it, and it was not in their zone of proximal development. At 
the same time, we also noticed that the language used for 
giving feedback to the users, in a breakdown situation, was 
often inappropriate: either by providing improper feedback 
or through lack of feedback. We talked about improper 
feedback as textual feedback using technical terms for 
transmitting a message. This triggered in the elderly feelings 
of fear, including its derivatives: angst, anxiety, concern, 
doubt, dread, unease, uneasiness, worry, aversion, fright, 
phobia, and presentiment [81].  
Many of the studies on feedback within HCI are inspired 
by human-to-human conversational interactions [43][46]. 
However, specifically, [44] noticed earlier that human-
machine communication was using English as the “natural 
language” for communicating between humans and 
machines [44, p. 28]. This choice was anchored in Austin’s 
(1962) “How to do things with words,” that language 
through its utterances can be a form of action, but this 
requires an appropriate interpretation of its interlocutor [76]. 
We noticed in our study that the interlocutor could not 
always interpret the use of technical terms. This is an issue 
of mutual intelligibility, as [44]  would call it. Therefore, 
designers should consider avoiding the use of those in 
textual feedback. Similar findings to ours were presented in 
the study of eco-feedback from [82], that pointed out that 
householders participants did not understand the language 
used in the textual feedback. In addition, the Macintosh 
User Interface Guidelines, dating back to 1992, pointed out 
that feedback should be proper, and inform the user as much 
as possible, instead of providing the user with a technical 
language such as: “The computer unexpectedly crashed. ID 
= 13” [41, 9]. We encountered a similar situation in our 

82
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
findings when one of the participants received the error 
message: “Please clear my path (2000) and a red cross”. 
This type of error message is improper because it did not 
make sense for the participant. Feedback should be 
appropriate and timely [41]. In addition, another study 
showed that seniors that are not familiar with particular 
technical terminology do not use these words [60]. In our 
findings, a similar situation occurred when one of the 
participants pointed out the use of technical language in the 
feedback they received via an app: “it cannot connect to the 
cloud services.” [1, 176]. These are, however, examples 
from the everyday’ participants’ interaction with the robot 
but are nevertheless important to be accounted to make 
sense of them. [58] explained that making sense of everyday 
examples of interacting with technology, of coping with it in 
everyday life situations is an indication of our familiarity 
with the technology. This relies upon the know-how, 
following Dreyfus in [59].  
Feedback, however, has cognitive attributes that can be 
interpreted by the users. For instance, [42] talks about the 
mind and the text, and how the information transmitted can 
change the state of someone’s mind and/or affect, depending 
on the conceptualization and interpretation of the 
information. We have seen concrete examples in this study 
of how someone’s interpretation of robot motion changed 
his/her state of mind to stress, anger, or feelings of 
personification. However, apart from the emotions triggered 
by smartphone app technologies, moving further to the 
emotions triggered by the semi-autonomous robot, we 
noticed the following: the incoherence in motion triggered 
various feelings, including stress, anger or other feelings 
related to robot personification. When a technology triggers 
emotions within a user, being positive or negative, it means 
that the user engages with it, rather than interacts with it 
[83]. Interaction is a form of “’dialogue’ with the 
technology” [83, 62]. Engaging with the technology also 
has an affective part, in comparison to interaction [83]. We 
have also observed that amongst different mechanisms to 
engage with technology, to be able to maintain a dialogue 
with it, to cope, to co-exist with it, one is feedback. If, for 
instance, motion feedback supports this engagement with the 
technology in itself, rather than just the interaction with it, 
we become more familiar with it. The repertoire of emotions 
awaken by the participants’ experience of the robot is the 
result of their interaction, engagement, or even familiarity 
with it. The emotions triggered in both elderly and 
researcher participants were often of stress, anger, 
annoyance. However, we observed that, in general, elderly 
often felt as non-experts when using the robot and did not 
have the same deep tacit knowledge as the researchers in 
this study, that seemed to be more familiar with using the 
same technologies, or similar ones. We also observed that 
both the independent living elderly and the researchers in 
this study were challenged in many ways by interacting with 
a semi-autonomous robot technology: perhaps more than 
with a smartphone app technology. Many of these 
challenges arose due to additional interaction elements: the 
(sometimes incoherent) motion of the robot and the use of 
the app. The participants often had to learn the know-how, to 
co-exist with the robot, and to accommodate it: not the 
opposite – the robot did not necessary accommodated them, 
although it was its purpose. On the other hand, [84] talk 
about unfamiliarity of the users with a new technological 
machine makes it more difficult to cope with it – this does 
not mean that the machine lacks technological advancement, 
but perhaps it is not designed in a familiar way for the 
users. 
Finally, we have noticed that the robot, through its 
motion, did not only trigger negative feelings but also 
feelings of personification: the participants associated the 
motion feedback of the robot with aliveness. The movement 
of the robot put the robot somewhere in between a static 
object, and a fully autonomous object: it was something that 
could move by itself, be self-propelled, i.e., it could change 
its location without a necessary and continuous intervention 
of a human or another object. Nevertheless, this idea of 
aliveness as a familiar characteristic has been earlier 
noticed, based on “autonomous motion, or reactivity” [44]. 
These feelings of personification can be translated as 
awaking positive emotions in the elderly. However, making 
sense of the motion itself as feedback, and how it can be 
understood through the lens of familiarity remains to be 
discussed. We explore this next. 
B. Making Sense of the Motion as Feedback  
The second set of questions addressed in this paper is: 
How is a motion made sense of and understood by the users 
when interacting or engaging with a semi-autonomous 
robot, in their homes? If the motion is illustrated as a type 
of feedback – what did we learn from their experiences?  
Humans are usually familiar with their own movement, 
with seeing things that move around outdoors: bicycles, 
cars, trains, ships, airplanes. However, one is not yet 
familiar with semi-autonomous things that move within a 
home. This phenomenon has been discussed within 
Robotics and Human-Robot Interaction (HRI), but it still 
remains to be explored within HCI. A home is not a static 
linear environment, but rather things happen in a dynamic 
and non-linear fashion: people in the home move objects 
around: a chair is moved to another place, a bag is placed on 
the floor, a sock is forgotten on the floor and so on. A robot, 
whose main surface of navigation is the floor, may 
encounter these objects and treat them as obstacles: both in 
its wayfinding and in its navigation. Familiarity is also a 
form of engagement, or what Heidegger calls involvement 
[83]. One becomes familiar with the technology through 
repeated, everyday exposure to it [59][60]. But a semi-
autonomous robot that moves within the home seems to be 
still unfamiliar so far: perhaps because we are not yet 
exposed in our daily lives to robots that move semi-
autonomously in our homes. Turner (2011) talks about the 
inclusiveness of technology, that it must fit users’ everyday 

83
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
lives [58]. Did the robot fit the participants’ everyday lives? 
The elderly in this study were willing to adopt a robot in 
their homes, out of curiosity, willing to learn more about 
such semi-autonomous robot technologies, to become 
familiar with it, but also perhaps they sought out some sort 
of practical coping, that ameliorate some of the direct 
consequences of aging, such as bending while doing 
cleaning work. Housekeeping, for instance, seems to be 
considered not only a physical task, but also a goal-oriented 
task that requires some degree of cognitive functioning [3]. 
However, the authors refer to information retrieval only 
as a text regarding these types of feedback, not as a motion 
[42][46]. The human is considered here as an interpreter of 
the motion as feedback. Motion feedback, similarly to visual 
feedback, can also be translated into positive, negative, 
homeostatic feedback, or archival feedback. Based on our 
study, we have observed that the motion as feedback can be 
mapped out to four situations: (1) when the robot is still, (2) 
when the robot goes from a still state to motion, (3) when 
the robot goes from a motion state to a still state, and 
finally, (4) when the robot is in motion. We ground our 
mapping on empirical examples from our data to illustrate 
motion as feedback, but we do not argue that other ways of 
are not possible. Besides polarity feedback, homeostatic 
feedback, and archival feedback, we introduce the notion of 
transition feedback. Transition feedback emerged during 
our mapping of motion as feedback. Transition feedback 
refers to motion as feedback when the robot changes its state 
from still to motion (2), or from motion to a still state (3). 
Next, we map polarity feedback, homeostatic feedback, and 
archival feedback to motion as feedback.    
1) When the Robot is Still 
When the robot stands still, the motion as feedback can be 
translated into homeostatic feedback: the robot does not 
perform any change in its motion state. The homeostatic 
feedback can be either positive or negative, depending on if 
the user has previously pressed the button to start it, or not. 
For instance, if the user presses the CLEAN button, which 
means that the change of the robot should be changed from 
still to motion, but the robot remains still, the feedback is 
negative.  
2) When the Robot Goes from a Still to a Motion State 
The transition between the still state to a motion state of a 
robot can be translated as positive or negative feedback, 
depending on the correspondence between the user’s input 
and expectations. Positive feedback is given when the user 
presses the CLEAN button, and the robot moves around 
cleaning. This is also transitioning state feedback, as the 
robot changes its state. An example of negative feedback for 
this situation is when the robot starts moving around by 
itself, without being enacted by the user. 
3) When the Robot Goes from a Motion State to a Still 
State 
The robot turns back to its charging station when the user 
presses the HOME button can be translated into positive 
feedback, as the robot responds to the user’s input. At the 
same time, this can also be translated into transitioning 
feedback since the robot changes its state, from motion to a 
still state. A second situation is when the robot turns back to 
its charging station when it is almost out of battery. This 
motion feedback can be translated as positive archival 
feedback since the robot acts accordingly to its resources, 
e.g., needs to be charged. However, from the point of view 
of the user, this can be translated as negative feedback, since 
the robot does not meet the expectation of the user: to be in 
motion once that the user has pressed CLEAN. It can also 
be translated into transition motion feedback since it is 
changing its state. A third situation is when the robot 
remembers the path and turns back to its charging station 
after finishing cleaning. This can be translated as positive 
archival feedback because it remembers its way back, based 
on a logged history or a previously created map. A fourth 
situation is when the robot gets stuck and enacts the users 
through indirect or invisible feedback to do facilitation 
work. In other words, the robot gives a negative transition 
motion feedback to the user by changing its state, from 
motion to a still state. 
4) When the Robot is in Motion 
We could see in our findings that when the user presses 
the HOME button, but the robot does not go back to its 
home station, and yet here the archival feedback was 
missing. This can be translated as negative homeostatic 
motion feedback. We can say that when the user presses the 
HOME button and the robot returns to the home station, the 
user understands the robots’ navigation to the base station as  
immediate positive feedback: it responded to the user’s 
action. Another situation is illustrated when the motion of 
the robot is incoherent: it only cleans a small surface, 
without navigating the whole area. This can be translated as 
negative homeostatic motion feedback. When the robot is in 
motion, and the motion feedback is manifested through the 
noise, it can be translated into positive homeostatic 
feedback. However, in the view of the user, this is translated 
as negative feedback since the noise itself creates feelings of 
annoyance, disturbing the user.  
When the robot remembers the map of the rooms when is 
not running for the first time in the area (coherent 
navigation), the motion of the robot can be translated into 
positive archival homeostatic motion feedback, since the 
robot remembers the map of the room and can navigate 
accordingly. Opposite to this situation is when the robot 
escapes a room previously navigated, i.e., the navigation 
path of the robot does not respect the boundaries. This can 
be translated as negative motion feedback.  
We illustrate some examples of positive, negative, 
homeostatic and archival motion feedback in Table IV. 
C. Familiarity with the Motion as Feedback 
Based on this study, we have observed that the 
familiarity, or for that matter unfamiliarity, of the motion as  
feedback can be based on already established notions of the 
polarity of feedback, homeostatic feedback, and archival 

84
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
feedback. However, these notions were used so far in 
relation to textual or visual feedback [55][60]. We have 
classified motion as feedback, based on the motion state of 
the robot and empirical examples from our data: 1) motion 
as feedback when the robot is still, 2) motion as feedback 
when the robot is transitioning from a still state to a motion 
state, 3) motion as feedback when the robot is transitioning 
from a motion state to a still state, and 4) motion as 
feedback when the robot is in motion. To the already 
existent types of feedback, we have observed that for semi-
autonomous robots, transitioning feedback for situation 2) 
and 3) is a new type of feedback. We have mapped and 
illustrated the four situations based on the robot’s states and 
their corresponding feedback (Fig. 8 on the next page). 
Further, [85] compared and synthesized the design 
principles 
from 
Schneider 
(1999) 
[37][38], 
from 
Constantine & Lockwood (1999) [86], and from Nielsen 
(2005) [87]. The author found out that the principles related  
to error handling and error recovery, based on the three 
named guidelines are necessary for any type of interactive 
system [85, 45]. Specifically, the author means that errors 
should be avoided [85, 45]. If we translate this to the 
familiarity of motion as feedback, it implies that any 
feedback that can be translated as a form of negative 
 
TABLE IV.  MAKING SENSE OF MOTION AS FEEDBACK 
feedback illustrates some sort of unfamiliarity: either of the 
robot as a response to a user action, or of the emotions 
triggered in the user. The authors say: “in other words, the 
environment would behave in a manner familiar to the user 
as if they were not actually using a computer system.” [85, 
45]. We can observe that negative feedback occurred in all 
types of situations. This means that the semi-autonomous 
robot did not respond or act in a familiar way. Further, 
according to the authors the concept of UNDO, of archival 
feedback, which we translated as a way for the robot for 
going to a previous state, is “unnatural” and conflicts “with 
the principle of familiarity” [85, 45]. We observed this type 
of archival feedback in situation 3) when the robot 
transitioned from a motion state to a still state, and in 4) 
when the robot maintained its motion state. For motion as 
feedback, this idea that the archival feedback is unnatural 
and conflicts with the familiarity concepts seems to do not 
always hold. We argue rather that there are situations when 
the robot acts in a familiar way for the user. Here are our 
arguments: the robot turns back to its charging station when 
the user presses HOME button – this is in line with the 
user’s expectations; the robot turns back to its charging 
station when it is almost out of battery – the robot is at least 
in line with the needs of its system for more resources; the 
robot remembers the path and turns back to its charging 
Robot state 
Example of situation 
Motion 
as 
negative 
feedback 
Motion as 
positive 
feedback 
Motion 
as 
homeostatic 
feedback 
Motion as 
archival 
feedback 
 
1) 
The robot is 
still 
The robot stands still. 
 
 
X 
 
The user presses the button, but nothing happens. 
X 
 
X 
 
 
2) 
The robot is 
transitioning 
from a still 
state to a 
motion state 
(transition 
feedback) 
The user presses the CLEAN button and the robot moves 
around cleaning. 
 
 
X 
X 
 
The robot starts moving around by itself without being enacted 
by the user. 
X 
 
X 
 
 
 
3) 
The robot is 
going from a 
motion state 
to a still state 
(transition 
feedback) 
The robot turns back to its charging station when the user 
presses HOME button. 
 
 
X 
 
X 
The robot turns back to its charging station when it is almost 
out of battery. 
 
X 
X 
 
X 
The robot remembers the path and turns back to its charging 
station after finishing cleaning. 
 
 
X 
 
X 
The robot gets stuck and enacts the users through indirect or 
invisible feedback to do facilitation work. 
X 
 
X 
 
 
 
 
 
4) 
The robot is 
in motion 
Motion feedback manifested through noise. 
 
X 
X 
X 
 
The robot remembers the map of the rooms when is not running 
for the first time in the area (coherent navigation). 
 
 
X 
X 
X 
The motion of the robot is incoherent (it only cleans a small 
surface, without navigating the whole area). 
 
X 
 
X 
 
The robot escapes (e.g., the navigation path of the robot does 
not respect the boundaries). 
 
X 
 
X 
 

85
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
station after finishing cleaning – the robot is acting in a 
familiar way to user’s expectations, it acts accordingly after 
finishing its job.  
Further, in this section, we have followed Turner (2011), 
of making sense everyday examples of interacting with 
technology, the readiness of coping with it in everyday life 
situations [58]. This sense-making lead us to a mapping 
between 
polarity 
feedback 
(positive 
or 
negative), 
homeostatic feedback, and archival feedback to motion as 
feedback. In addition, we observed that doing this mapping 
by using the states of a robot, still and in motion, and their 
corresponding transitions, we could define the transition 
feedback type. We have also observed that different 
feedback for different states can trigger emotions (positive 
or negative) in the user. If we follow the idea that the 
interaction is a form of dialogue’ with the technology, we 
are still concerned that current design remains unfamiliar to 
the user in specific situations, regardless if the user is 
experienced or not. To come back to Suchman’s (1986) idea 
that a “tool must communicate”, and that “the artifact 
should be self-evident” [44, 14-15], it seems that our artifact, 
tool, and machine, the robot, was not able to communicate in 
a number of situations that we illustrated based on our 
empirical data. This problem of unfamiliarity, as opposed to 
familiarity, reveals a deeper underlying problem: “the 
problem of deciphering an artifact defines the problem of the 
designer as well.” [44, 14-15]. 
If the robot does not follow a familiar way of navigating a 
space, responding to the user’s expectations, this may lead, 
in the case of the elderly and their use of a safety alarm 
robot, to additional falls for them. A concrete example is 
when the robot transitions from a still state to a motion state, 
without giving any feedback to the user, besides the 
feedback in the form of transition motion feedback, and 
noise as homeostatic feedback. Falls amongst elderly is a 
well-known problem [88]. The situation presented above 
may lead the user to additional falls if the user is not aware 
of the transition and homeostatic feedback. Introducing a 
robot that does not respond accordingly, by giving negative 
feedback, being it homeostatic or archival, may have 
negative consequences on the user. Further, the report about 
falls amongst the elderly shows that fall may lead to fear of 
falling, and other negative physical and mental health 
consequences [88]. The literature also shows that falls 
amongst elderly people (≥65 years old) are very common, 
and hospitalized due to fall injuries seem to occur five times 
more than due to other causes [89]. Another problem with 
the motion as feedback is when the robot escapes. In the 
situation of the use of a robot in the home, e.g. a safety alarm 
robot for the elderly, such a type of negative and homeostatic 
feedback may lead to a non-detected fall. The situation of the 
robot getting stuck, as negative and homeostatic motion 
feedback, may also lead in a real situation to a non-detected 
fall, and in other implications for the user: bending over to 
move the robot.  
Lastly, we can say that looking at the motion as feedback 
with the help of familiarity concept contributed to understand 
the potential challenges and implications when introducing a 
robot in the homes of the independent living elderly. 
Moreover, it also contributed to map and discusses motion as 
a positive, negative, homeostatic, archival, and transition 
motion feedback. 
VIII. CONCLUSION AND FUTURE WORK 
In this paper, we have presented motion as feedback 
through empirical data from an explorative study of semi-
autonomous robots used in domestic settings. We started the 
Figure 8. Motion as feedback based on the semi-autonomous robot’s states 
 
Figure 8. Motion as feedback based on the semi-autonomous robot’s states 
 

86
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
paper by stating our research questions, introducing some 
terminology and the background for this study. In Section 
II, we gave an account on the state-of-the-art. Section III 
introduced the reader to the concept of feedback within 
HCI, where it often is understood and designed as visual, 
auditory, haptic, or textual. We drew attention upon the 
significance of the use of natural language when interacting 
with computers, or designing feedback, dating back to the 
work of Suchman (1985) [41][44]. We elaborated on 
polarity-, homeostatic, and archival feedback based on the 
existent literature. We briefly described motion as feedback 
based on robot navigation. We have framed feedback from a 
smartphone app and semi-autonomous robot technology, to 
be able to discuss robot’s motion as feedback, and 
differentiate it from feedback received from stationary 
technology, we have framed feedback from smartphone app 
and semi-autonomous robot technology. 
Further, in Section IV, we have elaborated on our 
theoretical foundations, explaining the familiarity concept. 
Section V illustrated in detail the methodology and methods 
for this study, including the ethical aspects. In Section VI, 
we have presented our findings structured in: the user 
receives feedback from a smartphone technology; the user 
receives distributed feedback from a robot - mediated via an 
app; and motion as feedback and its implications for the user. 
Finally, in Section VII, we discussed the motion as feedback: 
the role of familiarity for the emotions triggered by the 
engagement with the technology, discussing how feedback 
can support familiarity with technology; and making sense of 
the motion as feedback, based on polarity-, homeostatic-, and 
archival feedback. The transitioning feedback emerged here. 
We continued by discussing familiarity with the motion as 
feedback. We argue that having familiarity in mind when 
designing new technologies, can make it easier for the user 
to know-how to use the technology.  
Our conclusion is that a semi-autonomous robot 
technology can become more familiar to the user if it 
triggers (more often) positive feelings in the user (than 
negative feelings). Finally, from a System Engineering 
perspective, following HCI requirements derive from the 
findings: if its motion is coherent, if its navigation is 
appropriate to the situation (e.g., going back to the charging 
station when it is out of battery, not getting stuck, 
remembering the map of the rooms to be navigated, without 
“escaping”), and if its motion is not disturbing or 
interrupting the user (e.g., when taking a phone call, or 
when eating). Taking a being-with approach to familiarity 
for semi-autonomous robot technology to make sense of the 
robot’s motion helped us in being able to distinguish 
amongst motion as positive, negative, homeostatic, archival, 
and transitioning feedback. This approach changed how we 
view that the participants engaged with the technology: it 
changed their routines at home through the enactment of 
facilitation work, their schedule, their relationship with the 
technology itself and with others that live or visit the same 
home – once part of the home or one’s daily’s live, it 
became a subject for discussion suddenly. It was part of 
their everyday lives. However, we can conclude that 
through making sense of motion as the feedback, we may 
observe that the semi-autonomous robot was part of, but not 
yet integrated within their homes and their daily lives. The 
robot did not accommodate the participants, but rather, the 
participants had to accommodate the robot. Familiarity was 
defined as an intimate, close, and friendly state, or 
interaction [81]. However, we showed through this study 
that while using familiarity as a lens to analyze the 
participants’ experiences with the semi-autonomous robot 
technology, the relationship between the participants and the 
robot remains unfamiliar in many situations. The robot still 
remains in many situations un-familiar to the participants, 
the know-how relationship is not fully developed, and the 
participants do not always have tacit knowledge on how to 
interact with it. Finally, the co-existence with such robots in 
domestic settings is not fully developed yet. We can 
conclude that familiarity per se plays a central role in 
individuals’ relationships with technology [56].  
Coming back to the State of the Art described in Section 
II, this study supports the findings from the ACCOMPANY 
project and Care-O-Bot robot [13][14][15][16]: many of the 
elderly need support with the ADL. Specifically, the need 
for support with the housekeeping related needs was 
nevertheless present also in this study, along with the 
findings from [19]. However, some of the studies made with 
the robots used in Robot-Era Project [3], ACCOMPANY 
[13][14], MARIO, EURON RoboEthics Roadman, EP6, 
ETHICBOTS, BREATHE, or ICT & Ageing Project [18] 
were centering their focus around the functionalities of the 
robot, and the user acceptance of the robots. These robots 
were also specifically designed for home care of the elderly. 
The studies made on the companion robots: PARO 
[21][22][23], AIBO, Furby, NeCoRo [21][22], Pepper and 
NAO [25], or Giraff [26] focused nevertheless on how a 
robot may impact the elderly’s behavior across time. Many 
of the studies used quantitative statistical data for the 
evaluation of the robots. While this is nevertheless 
important, our study provides an example on how existent 
robots on the market can be used instrumentally in 
explorative 
interpretative 
qualitative 
studies 
for 
understanding more about the participants’ everyday 
experiences, and how their daily activities may change when 
introducing such robot in their homes. The study is 
primarily about the lived experiences of the participants. 
These experiences are instrumentally used as a foundation 
for understanding more about design, design of robots for 
their use at home, design implications of feedback, and 
motion as feedback distributed or not via an app. 
We suggest as future work to elaborate further on the 
relationship between motion, transitioning motion feedback, 
and the role of familiar feedback in engaging with 
technology, rather than interacting with it. Further, one 
could explore more the affordances of motion as feedback, 
following the definition of affordances as given by [90], or 

87
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
as seen in HCI. Introducing moving technologies in the 
home lays the foundation for further explorations. One way 
to build further on this study is by conducting a quantitative 
statistical study on the acceptance of the robots in the home, 
on the movement types of robot, or by using the concept of 
animacy as shown in [48]. Exploring the abstract concept of 
feedback as a coordination mechanism and/or as a boundary 
object is also of high interest and relevance for those 
interested in theoretical anchored explorations. Another way 
for continuing this study is by conducting a qualitative 
interpretative study by analyzing the division of work tasks 
and types of work performed by the human and the robot. 
Here we encourage the analysis of work tasks and types of 
works to be done by borrowing established concepts used 
outside of HCI field, such as Computer Supported 
Cooperative Work. Nevertheless, studying the boundaries 
between when the interaction between the human and a 
robot becomes a cooperation between the human and the 
robot is of high relevance, especially now with faceless 
interaction devices: conversational based devices on face- or 
faceless interactions based mainly on speech, such as, e.g., 
Sophia the Robot, or with Google Home Mini.  
Finally, this study was conducted to understand the 
potential challenges (e.g., robot motion as feedback is not 
understood by the participants, the robot motion enacts the 
participants to do facilitation work, the robot escapes, etc.) 
that may occur when introducing a robot in the homes of the 
independent living elderly. Introducing modern technologies 
in the homes of the elderly, such domestic robots requires 
scrutiny of the design of current and eventual future 
technologies that will be used by them. Understanding which 
challenges the elderly encounter when they interact with a 
semi-autonomous robot, in their everyday lives in domestic 
settings, contributes to our understanding on potential 
challenges on the future home care robots for the 
independent living elderly.  
ACKNOWLEDGMENTS 
This work was part of the MECS project funded by the 
Norwegian Research Council IKTPluss Program (Grant 
agreement no: 247697). We would like to thank our project 
funders, partners, especially to Kampen Omsorg Pluss, and 
the project manager, Jim Tørresen. Special thanks to 
colleagues Trenton Schulz, Fahd Newaz, and Rebekka Soma 
for our time at KO++. Nevertheless, we would like to 
warmly thank the reviewers for their time, effort, and 
valuable input on making this work better.  
REFERENCES 
[1] 
D. Saplacan and J. Herstad, “Fear, Feedback, Familiarity... 
How are These Connected? - Can familiarity as a design 
concept applied to digital feedback reduce fear?,” 
Proceedings of The Eleventh International Conference on 
Advances in Computer-Human Interactions (ACHI). Mar-
2018. 
[2] 
Dictionary.com, 
“Thesaurus.com 
| 
Meanings 
and 
Definitions of Words at Thesaurus.com,” Thesaurus.com, 
2016. [Online]. Available: http://www.thesaurus.com/, 
http://www.thesaurus.com/. [Accessed: 26-Jul-2017]. 
[3] 
L. D. Riek, “Healthcare Robotics,” ACM Communications, 
vol. 60. pp. 68–78, Nov-2017. 
[4] 
S. Thrun, “Toward a Framework for Human-robot 
Interaction,” Hum-Comput Interact, vol. 19, no. 1, pp. 9–24, 
Jun. 2004. 
[5] 
R. Soma, V. Dønnem Søyseth, M. Søyland, and T. Schulz, 
“Facilitating 
Robots 
at 
Home: 
A 
Framework 
for 
Understanding Robot Facilitation,” presented at the ACHI 
2018, The Eleventh International Conference on Advances 
in Computer-Human Interactions, 2018, pp. 1–6. 
[6] 
J. S. Oskarsen, “Human-supported robot work,” Master 
Thesis, University of Oslo, Department of Informatics, 
Faculty of mathematics and natural sciences, Oslo, Norway, 
2018. 
[7] 
S. 
Bødker, 
“Third-Wave 
HCI, 
10 
Years 
Later—
Participation and Sharing,” interactions, vol. 22. ACM New 
York, NY, USA, pp. 24–31, 2015. 
[8] 
“MECS,” Multimodal Elderly Care Systems (MECS), About 
the 
project, 
17-Oct-2016. 
[Online]. 
Available: 
http://www.mn.uio.no/ifi/english/research/groups/robin/rese
arch-projects/mecs/. [Accessed: 17-Oct-2016]. 
[9] 
P. B. Baltes and J. Smith, “New frontiers in the future of 
aging: from successful aging of the young old to the 
dilemmas of the fourth age,” Gerontology, vol. 49, no. 2, 
pp. 123–135, Apr. 2003. 
[10] 
D. Field and M. Minkler, “Continuity and change in social 
support between young-old and old-old or very-old age,” J. 
Gerontol., vol. 43, no. 4, pp. P100-106, Jul. 1988. 
[11] 
T. T. Hewett et al., “ACM SIGCHI Curricula for Human-
Computer Interaction : 2. Definition and Overview of 
Human-Computer Interaction.” ACM SIGCHI, 1996-1992. 
[12] 
S. Bedaf, G. J. Gelderblom, and L. De Witte, “Overview 
and Categorization of Robots Supporting Independent 
Living of Elderly People: What Activities Do They Support 
and How Far Have They Developed,” Assist. Technol. Off. 
J. RESNA, vol. 27, no. 2, pp. 88–100, 2015. 
[13] 
S. Bedaf, H. Draper, G.-J. Gelderblom, T. Sorell, and L. de 
Witte, “Can a Service Robot Which Supports Independent 
Living of Older People Disobey a Command? The Views of 
Older People, Informal Carers and Professional Caregivers 
on the Acceptability of Robots,” Int. J. Soc. Robot., vol. 8, 
no. 3, pp. 409–420, Jun. 2016. 
[14] 
F. Amirabdollahian et al., “Accompany: Acceptable 
robotiCs 
COMPanions 
for 
AgeiNG 
Years 
— 
Multidimensional aspects of human-system interactions,” in 
2013 6th International Conference on Human System 
Interactions (HSI), 2013, pp. 570–577. 
[15] 
B. Graf, M. Hans, and R. D. Schraft, “Care-O-bot II—
Development of a Next Generation Robotic Home 
Assistant,” Auton. Robots, vol. 16, no. 2, pp. 193–205, Mar. 
2004. 
[16] 
M. Hans and W. Baum, “Concept of a hybrid architecture 
for Care-O-bot,” in Proceedings 10th IEEE International 
Workshop 
on 
Robot 
and 
Human 
Interactive 
Communication. ROMAN 2001 (Cat. No.01TH8591), 2001, 
pp. 407–411. 
[17] 
B. Graf, “Reactive navigation of an intelligent robotic 
walking aid,” in Proceedings 10th IEEE International 
Workshop 
on 
Robot 
and 
Human 
Interactive 

88
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Communication. ROMAN 2001 (Cat. No.01TH8591), 2001, 
pp. 353–358. 
[18] 
H. Felzmann, K. Murphy, D. Casey, and O. Beyan, “Robot-
assisted care for elderly with dementia: is there a potential 
for genuine end-user empowerment?,” in The Emerging 
Policy and Ethics of Human Robot Interaction, Portland, 
Oregon, USA, 2015. 
[19] 
L. Pigini, D. Facal, L. Blasi, and R. Andrich, “Service 
robots in elderly care at home: Users’ needs and perceptions 
as a basis for concept development,” Technol. Disabil., vol. 
24, no. 4, pp. 303–311, 2012. 
[20] 
J. Forlizzi and C. DiSalvo, “Service Robots in the Domestic 
Environment: A Study of the Roomba Vacuum in the 
Home,” in Proceedings of the 1st ACM SIGCHI/SIGART 
Conference on Human-robot Interaction, New York, NY, 
USA, 2006, pp. 258–265. 
[21] 
S. A. McGlynn, S. Kemple, T. L. Mitzner, C.-H. A. King, 
and W. A. Rogers, “Understanding the potential of PARO 
for healthy older adults,” Int. J. Hum.-Comput. Stud., vol. 
100, pp. 33–47, Apr. 2017. 
[22] 
K. Wada, Y. Takasawa, and T. Shibata, “Robot therapy at 
facilities for the elderly in Kanagawa prefecture - a report 
on the experimental result of the first month,” in The 23rd 
IEEE International Symposium on Robot and Human 
Interactive Communication, 2014, pp. 193–198. 
[23] 
L. Giusti and P. Marti, “Interpretative Dynamics in Human 
Robot Interaction,” in ROMAN 2006 - The 15th IEEE 
International Symposium on Robot and Human Interactive 
Communication, 2006, pp. 111–116. 
[24] 
K. Wada and T. Shibata, “Robot Therapy in a Care House - 
Change of Relationship among the Residents and Seal 
Robot during a 2-month Long Study,” in RO-MAN 2007 - 
The 16th IEEE International Symposium on Robot and 
Human Interactive Communication, 2007, pp. 107–112. 
[25] 
J. Hoefinghoff, A. R. der Pütten, J. Pauli, and N. Krämer, 
“‘Yes Dear, that Belongs into the Shelf!’ - Exploratory 
Studies with Elderly People Who Learn to Train an 
Adaptive Robot Companion,” in Social Robotics, 2015, pp. 
235–244. 
[26] 
J. González-Jiménez, C. Galindo, and J. R. Ruiz-Sarmiento, 
“Technical improvements of the Giraff telepresence robot 
based on users’ evaluation,” in 2012 IEEE RO-MAN: The 
21st IEEE International Symposium on Robot and Human 
Interactive Communication, 2012, pp. 827–832. 
[27] 
A. Cesta, G. Cortellessa, A. Orlandini, and L. Tiberio, 
“Long-Term Evaluation of a Telepresence Robot for the 
Elderly: Methodology and Ecological Case Study,” Int. J. 
Soc. Robot., vol. 8, no. 3, pp. 421–441, Jan. 2016. 
[28] 
eurostat, “Population structure and ageing - Statistics 
Explained,” Population structure and ageing, 20-Jul-2017. 
[Online]. Available: http://ec.europa.eu/eurostat/statistics-
explained/index.php/Population_structure_and_ageing. 
[Accessed: 20-Jul-2017]. 
[29] 
ssb, “Next million reached set to be the fastest,” ssb.no, 
2017. 
[Online]. 
Available: 
http://www.ssb.no/en/befolkning/statistikker/folkfram/aar/2
016-06-21. [Accessed: 20-Jul-2017]. 
[30] 
M. Forzati and C. Mattson, “Effekter av digitala tjänster för 
äldrevård - ekonomisk studie,” ssnf.org, acr057005, Jan. 
2014. 
[31] 
J. Ramm, “Health and care. Use of services among the 
elderly,” 
ssb.no, 
2013. 
[Online]. 
Available: 
http://www.ssb.no/en/helse/artikler-og-publikasjoner/eldres-
bruk-av-helse-og-omsorgstjenester. 
[Accessed: 
20-Jul-
2017]. 
[32] 
European Commision, “eHealth Action Plan 2012-2020: 
Innovative healthcare for the 21st century,” Digital Single 
Market, 
07-Dec-2012. 
[Online]. 
Available: 
https://ec.europa.eu/digital-single-market/en/news/ehealth-
action-plan-2012-2020-innovative-healthcare-21st-century. 
[Accessed: 20-Jul-2017]. 
[33] 
J. A. Delello and R. R. McWhorter, “Reducing the Digital 
Divide: Connecting Older Adults to iPad Technology,” J. 
Appl. Gerontol., vol. 36, no. 1, pp. 3–28, Jan. 2017. 
[34] 
Y.-H. Wu, S. Damnée, H. Kerhervé, C. Ware, and A.-S. 
Rigaud, “Bridging the digital divide in older adults: a study 
from an initiative to inform older adults about new 
technologies,” Clin. Interv. Aging, vol. 10, pp. 193–201, 
Jan. 2015. 
[35] 
T. Halbach and T. Schulz, “MobileSage - A Prototype 
Based 
Case 
Study 
for 
Delivering 
Context-Aware, 
Personalized, On-Demand Help Content,” presented at the 
CENTRIC 2013, The Sixth International Conference on 
Advances 
in 
Human 
oriented 
and 
Personalized 
Mechanisms, Technologies, and Services, 2014, vol. 
International Journal on Advances in Intelligent Systems, 7, 
nos. 1–2, pp. 267–278. 
[36] 
M. Anerson and A. Perrin, “1. Technology use among 
seniors,” Pew Research Center: Internet, Science & Tech, 
17-May-2017. . 
[37] 
B. Shneiderman, Designing the User Interface: Strategies 
for Effective Human-computer Interaction. Boston, MA, 
USA: Addison-Wesley Longman Publishing Co., Inc., 
1986. 
[38] 
E. Wong, “Shneiderman’s Eight Golden Rules Will Help 
You Design Better Interfaces,” The Interaction Design 
Foundation, 
2019. 
[Online]. 
Available: 
https://www.interaction-
design.org/literature/article/shneiderman-s-eight-golden-
rules-will-help-you-design-better-interfaces. [Accessed: 07-
Feb-2019]. 
[39] 
D. Saplacan and J. Herstad, “A Quadratic Anthropocentric 
Perspective on Feedback - Using Proxemics as a 
Framework,” Conference Proceedings of BritishHCI 2017. 
Sunderland, U.K., 03-Jul-2017. 
[40] 
D. A. Norman, The design of everyday things, Revised and 
expanded edition. New York, New York: Basic Books, 
2013. 
[41] 
I. Apple Computer, Macintosh Human Interface Guidelines. 
USA: Addison-Wesley Publishing Company, 1992. 
[42] 
A. Spink and T. Saracevic, “Human-computer interaction in 
information 
retrieval: 
nature 
and 
manifestations 
of 
feedback,” Interact. Comput., vol. 10, no. 3, pp. 249–267, 
Jun. 1998. 
[43] 
M. A. Pérez-Quiñones and J. L. Sibert, “A Collaborative 
Model of Feedback in Human-computer Interaction,” in 
Proceedings of the SIGCHI Conference on Human Factors 
in Computing Systems, New York, NY, USA, 1996, pp. 
316–323. 
[44] 
L. Suchman, Plans and situated actions: The problem of 
human-machine communication. Palo Alto, California 
94304: Xerox Corporation Palo Alto Research Centers, 
1985. 

89
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[45] 
P. Dourish, “What we talk about when we talk about 
context,” Pers. Ubiquitous Comput., vol. 8, no. 1, pp. 19–
30, Feb. 2004. 
[46] 
K. Renaud and R. Cooper, “Feedback in human-computer 
interaction - characteristics and recommendations,” South 
Afr. Comput. J., vol. 2000, no. 26, pp. 105–114, Nov. 2000. 
[47] 
T. Ingold, The perception of the environment: essays on 
livelihood, dwelling and skill. London ; New York: 
Routledge, Taylor & Francis Group, 2011. 
[48] 
T. Schulz, J. Torresen, and J. Herstad, “Animation 
Techniques in Human-Robot Interaction User Studies: a 
Systematic Literature Review,” ArXiv181206784 Cs, Dec. 
2018. 
[49] 
E. T. Hall, The hidden dimension. New York: Anchor 
Books, 1990. 
[50] 
J. Beck and E. Stolterman, “Examining Practical, Everyday 
Theory Use in Design Research,” She Ji J. Des. Econ. 
Innov., vol. 2, no. 2, pp. 125–140, Jun. 2016. 
[51] 
M. Heidegger, Being and time. Oxford, U.K.: Blackwell 
Publishers Ltd, 1967. 
[52] 
“familiarity, n.,” OED Online. Oxford University Press. 
[53] 
H. Dreyfus, Being-in-the-world: A Commentary on 
Heidegger’s Being and Time, Division I. Massachusetts 
Institute of Technology, 1991. 
[54] 
N. Backhaus, A. K. Trapp, and M. Thüring, “Skeuomorph 
Versus Flat Design: User Experience and Age-Related 
Preferences,” in Design, User Experience, and Usability: 
Designing Interactions, 2018, pp. 527–542. 
[55] 
P. Turner, How We Cope with Digital Technology. San 
Rafael: Morgan & Claypool Publishers, 2013. 
[56] 
G. Van de Walle, P. Turner, and E. Davenport, “A study of 
familiarity,” in Human-Computer Interaction-INTERACT, 
2003, vol. 3, pp. 463–70. 
[57] 
P. Turner, “Towards an account of intuitiveness,” Behav. 
Inf. Technol., vol. 27, no. 6, pp. 475–482, Nov. 2008. 
[58] 
P. Turner, “Everyday Coping: The Appropriation of 
Technology,” in Proceedings of the 29th Annual European 
Conference on Cognitive Ergonomics, New York, NY, 
USA, 2011, pp. 127–133. 
[59] 
P. Turner, “Being-with: A study of familiarity,” Interact. 
Comput., vol. 20, no. 4, pp. 447–454, Sep. 2008. 
[60] 
P. Turner and G. van de Walle, “Familiarity as a basis for 
universal design,” Gerontechnology, vol. 5, no. 3, pp. 150–
159, Jan. 2006. 
[61] 
J. Herstad and H. Holone, “Making Sense of Co-creative 
Tangibles Through the Concept of Familiarity,” in 
NORDICHI’12, Proceedings of the 7th Nordic Conference 
on Human-Computer Interaction: Making Sense Through 
Design, New York, NY, USA, 2012, pp. 89–98. 
[62] 
M. Myers D., “Qualitative Research in Information 
Systems,” MISQ Discovery, 1997. 
[63] 
P. Ricoeur, “Phenomenology and Hermeneutics,” Noûs, vol. 
9, no. 1, pp. 85–102, 1975. 
[64] 
S. G. Joshi, “Designing for Experienced Simplicity. Why 
Analytic and Imagined Simplicity Fail in Design of 
Assistive Technology,” Int. J. Adv. Intell. Syst., vol. 8, no. 3 
and 4, pp. 324–338, Dec. 2015. 
[65] 
S. 
G. 
Joshi, 
“Designing 
for 
Capabilities: 
A 
Phenomenological Approach to the Design of Enabling 
Technologies for Older Adults,” 2017. 
[66] 
R. B. Rosseland, “Exploring Movement-Based Rhythmic 
Interaction with Senior Citizens,” University of Oslo, 
Department of Informatics, Faculty of mathematics and 
natural sciences, Oslo, Norway, 2018. 
[67] 
A. Woll, “use of Welfare Technology in Elderly Care,” 
University of Oslo, Oslo, Norway, 2017. 
[68] 
S. G. Joshi and T. Bratteteig, “Assembling Fragments into 
Continuous Design: On Participatory Design with Old 
People,” in Nordic Contributions in IS Research, 2015, pp. 
13–29. 
[69] 
iRobot Corporation, “Roomba Robot Vacuum | iRobot.” 
[Online]. 
Available: 
http://www.irobot.com/For-the-
Home/Vacuuming/Roomba.aspx. [Accessed: 22-Mar-2017]. 
[70] 
G. Verne, “‘The winners are those who have used the old 
paper form’. On citizens and automated public services,” 
University of Oslo, Oslo, Norway, 2015. 
[71] 
S. Ottenberg, “Thirty Years of Fieldnotes: Changing 
Relationships to the text,” in The Making of Anthropology, 
R. Sanjek, Cornell University Press, 1990, pp. 139–160. 
[72] 
M. Crang and I. Cook, Doing Ethnographies. SAGE 
Publications, Inc., 2007. 
[73] 
V. Braun and V. Clarke, “Using thematic analysis in 
psychology,” Qual. Res. Psychol., vol. 3, no. 2, pp. 77–101, 
Jan. 2006. 
[74] 
R. M. Emerson, R. I. Fretz, and L. L. Shaw, “Processing 
Fieldnotes: Coding and Memoing (Chapter 6),” in Writing 
Etnographic Fieldnotes, Chigago and London: University 
of Chicago Press, 1995, pp. 142–168. 
[75] 
J. Lazar, J. H. Feng, and H. Hochheiser, Research Methods 
In Human-Computer Interaction. West Sussex, United 
Kingdom: Jon Wiley & Sons Ltd, 2010. 
[76] 
W. J. Austin, How to do things with words. Great Britain, 
Guernesey, Channel Islands: Oxford University Press, 1962. 
[77] 
Online Etymology Dictionary, “emotion,” 15-Feb-2019. 
[Online]. 
Available: 
https://www.etymonline.com/word/emotion. [Accessed: 15-
Feb-2019]. 
[78] 
Online Etymology Dictionary, “motion | Search Online 
Etymology Dictionary,” 15-Feb-2019. [Online]. Available: 
https://www.etymonline.com/search?q=motion. [Accessed: 
15-Feb-2019]. 
[79] 
Online Etymology Dictionary, “locomotion,” 15-Feb-2019. 
[Online]. 
Available: 
https://www.etymonline.com/word/locomotion. [Accessed: 
15-Feb-2019]. 
[80] 
J. Raskin, “Viewpoint: Intuitive Equals Familiar,” Commun 
ACM, vol. 37, no. 9, pp. 17–18, Sep. 1994. 
[81] 
OED, “fear, n.1,” Oxford Engglish Dictionary Online. 
Oxford University Press, 2017. 
[82] 
Y. A. A. Strengers, “Designing Eco-feedback Systems for 
Everyday Life,” in Proceedings of the SIGCHI Conference 
on Human Factors in Computing Systems, New York, NY, 
USA, 2011, pp. 2135–2144. 
[83] 
P. Turner, “The Anatomy of Engagement,” in Proceedings 
of the 28th Annual European Conference on Cognitive 
Ergonomics, New York, NY, USA, 2010, pp. 59–66. 
[84] 
L. Suchman, J. Blomberg, J. E. Orr, and R. Trigg, 
“Reconstructing Technologies as Social Practice,” Am. 
Behav. Sci., vol. 43, no. 3, pp. 392–408, Nov. 1999. 
[85] 
R. Picking, V. Grout, J. McGinn, J. Crisp, and H. Grout, 
“Simplicity, Consistency, Universality, Flexibility and 
Familiarity: The SCUFF Principles for Developing User 
Interfaces for Ambient Computer Systems,” Int. J. Ambient 
Comput. Intell. IJACI, vol. 2, no. 3, pp. 40–49, 2010. 

90
International Journal on Advances in Software, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/software/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[86] 
L. L. Constantine and L. A. D. Lockwood, Software for 
Use: A Practical Guide to the Models and Methods of 
Usage-Centered Design, 1 edition. Boston, Mass.: Addison-
Wesley Professional, 1999. 
[87] 
J. Nielsen, “10 Usability heuristics.” Nielsen, Jakob, 2005. 
[88] 
“Seniors’ falls in Canada - protecting Canadians from 
Illness,” Ministery of Health, Canada, Second Edition, 
2014. 
[89] 
A. Danielsen, H. Olofsen, and B. A. Bremdal, “Increasing 
fall risk awareness using wearables: A fall risk awareness 
protocol,” J. Biomed. Inform., vol. 63, pp. 184–194, Oct. 
2016. 
[90] 
J. J. Gibson, The ecological approach to visual perception. 
New York, London: Psychology Press, 2015. 
 

