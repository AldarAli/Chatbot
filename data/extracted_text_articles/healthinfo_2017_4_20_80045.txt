Detecting Agitation Onset in Individuals with Dementia Using  
Smart Phone Sensors 
 
Christianne Fowler, Ajay Gupta, Kurt Maly, Karen Karlowicz, Maheedhar Gunnam, Rohila Gudipati, 
Mahesh Kukunooru, and Rahul Rachamalla 
Old Dominion University, Norfolk, Virginia, USA 
E-mail: cfowler@odu.edu 
 
 
Abstract—Individuals living with dementia (ILWD) often 
experience problematic agitated behaviors, this occurs in up to 
80% of ILWD. These behaviors lead to stress for caregivers 
and increased frequency of institutionalization. There are 
many proven methods to intervene during agitated behavior 
outburst and the earlier these methods are used the better the 
results. Technology has been used successfully to monitor 
many aspects of health monitoring for older adults. 
Technology is now being investigated to evaluate the 
effectiveness of predicting the onset of problem behaviors, 
especially escalating agitation in ILWD. Off the shelf 
technology, smart watches and android phones, are being 
tested to measure limb movements, vocalizations, heart rate 
and location in facility, to evaluate their ability to provide data 
that is helpful in predicting agitated behaviors about to occur. 
This project is a collaboration between nursing and computer 
science in a major university setting. Currently, work has been 
completed on volunteers acting as patients to evaluate the 
ability of this technology to measure the desired parameters. 
Positive results have been obtained; the goal is to trial this 
technology on ILWD that have documented history of 
agitation in an assisted living environment. 
Keywords- 
dementia; 
behavior 
problems; 
wearable 
technology; bio measures 
I. 
 INTRODUCTION  
Dementia affects over 5 million in the U.S and the 
numbers are projected to climb to over 7 million by 2025 
[1]. Additionally, it is estimated that over 46 million people 
worldwide are living with dementia with the fastest growing 
population of older adults occurring in China, India, South 
Asia and the Western Pacific [2]. Those with Alzheimer’s 
and other forms of dementia often go through a period of 
significant behavioral symptoms of dementia (BSD). It is 
estimated that between 60 and 80% of these individuals will 
suffer from BSD during the time they are dealing with this 
disease [3]. BSD’s are generally divided into several 
categories; 
physical 
and 
non-physical 
agitation 
or 
aggression and verbal agitation. Non-physical behaviors 
include, disrobing, hording, hiding things, and exit seeking 
behavior. Physically aggressive behaviors include biting, 
hitting, kicking, pushing, scratching, and unwanted sexual 
advances. There can also be verbal concerns such as 
cursing, yelling and repeated calling out attention seeking 
behavior [4]. These behaviors are very difficult for 
caregivers to manage and are positively correlated with 
caregiver distress [5]. They also contribute to increased cost 
of care for persons with dementia and are a primary reason 
for institutionalization [6] [7] [8]. Behavioral problems are a 
safety concern for family members and professional 
caregivers as well as other older adults living in communal 
environments. 
There are well-validated non-pharmacologic methods to 
deal with BSD. These methods include redirection, music 
therapy, one-on-one socialization, art therapy and animal 
assisted therapy [9]. A pressing issue concerning BSD is the 
recognition of triggers – those events that can precede an 
unwanted behavior [10] [11]. In an attempt to identify these 
antecedents, various technologies have been used to 
augment or enhance the input from staff in a facility or 
caregivers at home. These technologies include video 
monitoring to capture the event and review the events 
surrounding 
the 
behavioral 
incident 
[12]. 
Another 
technology that is less intrusive to the communal living or 
home environment involves using actigraphy sensor 
technology to monitor disruptive behaviors [13] [14]. One 
group of researchers used this technology by placing a 
wearable device that measured movement at the wrist, waist 
and ankle on individuals identified as having dementia and 
behavioral 
issues 
[14]. 
The 
wearable 
technology 
demonstrated usefulness by measuring the severity of 
agitation and showing it compared well to a more 
established observer measures, such as the Cohen-Mansfield 
Agitation Inventory (CAMI) [14] although accuracy 
depended on the time of the day measurements were taken.  
There is currently very little known about the ability to 
use technology to predict agitation in persons with dementia 
in real time. Over the years, use of smart devices and 
wearables has increased dramatically in the field of 
healthcare. These wearables are used for a variety of 
applications ranging from safety to monitoring health 
measures such as sleep quality and quantity [15]. Pansiot et 
al discussed how ambient and wearable sensors could be 
used in health monitoring of patients by recognizing the 
human activity [16]. Sudden agitated behaviors can be 
harmful to these individuals and the caregivers or others 
around them, often leading to aggressive behaviors that are 
more difficult to ameliorate when they occur. 
 
42
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-597-5
HEALTHINFO 2017 : The Second International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

 
 
In this paper we discuss the various tools and methods 
used for data collection followed by a description of the 
experiment.  Finally we discuss the results and state our 
conclusions for this study. 
 
II. 
METHODS 
Our hypothesis is that we will be able to first detect 
agitated behavior and second recognize the onset of agitated 
behavior in dementia patients using regular, off-the-shelf 
sensors that can be found in smart watches and/or smart 
phones. We report in this paper on the development of a 
feasibility study that is planned to ascertain whether or not 
we can recognize agitated behavior in actors that simulate 
such behavior using the fusion of three sensors:  a tri-axial 
accelerometer, an optical heart rate monitor, and a 
microphone.  
The preliminary data was obtained from a series of 
experiments consisting of five volunteers acting in the role of 
a patient. Each person was instructed to wear an android 
Moto 360, which sends the accelerometer and the heart rate 
values to a server. The volunteers were asked to show 
agitation or aggressive behaviors  that includes random arm 
movements, such as punching in the air for 2 minutes and 
then they were instructed to be stable (sitting, sleeping, 
walking, eating) which involves hand movements but not at 
a pace as before. Each volunteer performed these actions 10 
times wearing the wearable on both the right and left hands. 
There was a time gap between the actions while training to 
allow us to label the data with the specific activity 
performed. 
Standard machine learning algorithms used for 
classification cannot be directly used to predict the mood of a 
person from the raw data obtained from the wearable. As the 
device’s sensor readings contribute to a lot of noise in the 
data due to its hardware sensitivity, there is a need of 
filtering to attenuate the spikes in the data. We used 3rd 
order low-pass Butterworth filter with a cutoff frequency of 
25Hz which removed the outliers in the data. We then used a 
low pass filter to smooth the remaining spikes in the data, 
experimenting with different threshold values. We set the 
threshold to 0.3 by comparing filtered data to well-known 
data. 
According to our experiments, any agitated human 
activity takes 1-2 seconds to get completed, so we divided 
the entire data into continuous windows of 2 seconds and all 
the relevant activities were then captured. Each sample has a 
length of 2 seconds with 50% overlap so that we do not lose 
the data in between the samples as we are considering real 
time data. 
The architecture shown in Fig. 1 consists of wearable 
sensors attached to patients where the sensors send a stream 
of data over a Wi-Fi to a processing module at a backend 
server. Heart rate is measured through a smart watch which 
also measures limb movement through its accelerometer. 
 
 
Figure 1. Architecture of the Monitoring System 
 
Audio is sensed by a smart phone and also transmitted to 
the processing module. Bluetooth beacons are installed in the 
lab at the University; the smart phone will be able to sense 
how far it is from what beacon and transmit a stream of 
location data to the processing unit. The processing unit 
stores the raw data in a data base for later report analysis and 
it also produces output data sent to an observer’s smart 
phone. That observer can then display the status of any 
patient being monitored. 
III. 
EXPERIMENT 
The experiment collected data on several measurement 
parameters. The limb movements of the dominant arm, the 
emotions and decibel level of the voice, the heart rate and 
specific location. 
A. Limb movement 
We attached to an actor a wearable and send the sensor 
values to the backend server in 5 second intervals. The range 
of values is [0.0 - 6.0] measured in g. (1g =9.8m/s2); 0 m/s2 
is the lowest value recorded when the wearable device is 
kept on the table without movement;  6.0 m/s2 is the highest 
value recorded when a normal person wearing device 
punches into a wall with extreme force. At the server, we 
pre-process the raw values obtained from the sensor using 
the box filter and Butterworth filter of 3rd order to remove 
outliers from the data, after which the values are normalized. 
We next invoke a machine learning module for further 
processing. We have used three different models: Support 
Vector Machine (SVM), Random forests and K Nearest 
Neighbors (KNN). Among the three algorithms, SVM gave 
us the results with highest accuracy of 87% and hence we are 
using this model for all our studies. The features we select 
include the mean of four seconds of accelerometer values, 
standard deviation, relative differences between the vectors, 
angle between them, interquartile values, correlation between 
values obtained from different axes, so that we can increase 
the accuracy of prediction. 
43
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-597-5
HEALTHINFO 2017 : The Second International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

 
 
B. Emotions 
Using a smart phone that was located at a fixed position 
on the actor’s waist, we recorded the audio on the phone and 
send it to a server for analysis. For the analysis of emotion, 
we used the default natural language processing techniques 
provided by the Vokaturi software. The training set of the 
Vokaturi software consist of speech databases like Emo_DB 
and Savee. The contents of these databases store annotated 
speech recordings to predict the patient’s emotional state. 
During the training phase, we verified the accuracy of the 
model by correlating the results with the observations 
recorded by human observers who are visually observing the 
patient and making notes on the emotional state of the 
patient. On the backend, Vokaturi extracts the acoustic 
features of a user’s voice including: pitch, intensity, spectral 
scope, which is the energy difference between the frequency 
bands and computes the relative emotion probabilities for 
fear, anger, sadness, happiness and no emotion. This is 
computed with a neural network with three levels of linear 
connections (2 hidden layers). Once the analysis on the audio 
is done, the raw audio data is deleted to ensure patient 
privacy. We focused on predicting aggression, and only 
considered the probabilities of anger and fear. For both of 
these emotions the software produces values in the range [0 - 
1];   ranging from 0 meaning  not being angry/fearful at all 
through 0.2 meaning somewhat angry/fearful, to,…, 1 
meaning extremely angry/fearful. 
C. Heart rate 
We collected heart rate readings of the patients and also 
pitch of the audio from sensors in the wearable devices. The 
sensor produces values in the range [40-130] heartbeats per 
second; 40 hbps corresponds to a very low resting rate of an 
extremely athletic person; 130 hbps is the maximum heart 
rate for a 60-year-old person. So far, our experiments have 
not shown any significant correlation between aggression 
and changes in heart rate. The same is also true with the 
pitch of the voice. We are currently sending the data 
collected from the wearable instantly to the server, analyzing 
it and storing the data. We have a website to view the current 
status of each patient and we present the readings from the 
wearable in the form of graphs. 
D. Decibel level 
We also have the emotion software produce a loudness 
measure. The values range in the interval [20 – 80] decibel 
(dB); 20dB corresponds to whisper or rustling of 
leaves;   80dB corresponds to the sound the typical garbage 
disposal makes. 
E. Bluetooth 
We use Bluetooth beacons to track the patient's location 
and this information can be provided to the caregiver making 
it easier to locate the patient exhibiting changes. We plan to 
place the Rad beacons at pre-determined locations in the 
facility. We then use the signal from the Bluetooth of the 
android phone to identify the position of the patient in the 
facility. We make use of the push notifications to update the 
caregiver on the patient’s location and the status of a patient. 
IV. 
RESULTS 
We have obtained useful results from our initial volunteer 
patient trials. The wearable devices are able to measure 
changes in movements and voice pitch and then relay this 
change to a volunteer caregiver. In Fig. 2 we show the output 
of the system for a patient that has been identified by the 
system as behaving aggressive. The figure shows a red 
threshold line that is being crossed by the accelerometer 
reading. At this time the red line is simply one deviation 
from the average. In the future we want to use machine 
learning techniques that will analyze the five measurements 
streams and produce a classification of agitated or not. We 
will use various algorithms such as simply summing the 
values of the streams to more complicated ways of defining 
agitation such as a weighted sum of the streams. We will use 
the observations of trained nurses that have categorized 
patients as being agitated at various points as the gold 
standard for the machine learning algorithm to decide which 
the best predictor of agitation is. 
 
 
 
Figure 2. Alert by system 
 
 
 
 
Figure 3. Caregiver monitoring 
 
The details of our volunteer patients’ wearable’s and their 
status, whether they are aggressive or stable, are presented in 
44
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-597-5
HEALTHINFO 2017 : The Second International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

 
 
a mobile application. Fig. 3 displays the list of users wearing 
the wearable. Each cell in the view represents a user with 
their name on the left and action by which we are 
recognizing the user is agitated. The background color of 
each user cell represents the status of the user where red 
means the person is agitated, yellow means the person is 
slightly agitated and green means the person is stable. 
V. 
CONCLUSION 
We will perform a study with patients in an assisted living 
facility specializing in dementia care. This study will 
evaluate how accurate the various algorithms of our system 
detect agitation and whether or not we will be able to 
identify the onset so that caregivers can be alerted and 
deliver remedial actions. This next phase of our work will 
involve 6-10 individuals with documented BSD such as, 
unsafe wandering, resisting care, striking out at staff and 
other individuals, throwing objects, yelling, screaming or 
likely a combination of these behaviors. Individual residents 
displaying these behaviors will be selected and their medical 
power of attorney will be approached for consent to have 
their loved one participate. These patients will wear the 
devices for 4-hour blocks of time over several days, totaling 
24 hours of monitoring. Each patient will be followed by a 
trained person (student nurses) that will record any behavior 
as identified on the CAMI scale. We have already developed 
a convenient interface that will automate the recording and 
send the data to the database on the backend server. The 
major emphasis of this next study will be to ensure that the 
data streams from the sensors on the patients agree with 
observations the trained persons have recorded. The IRB of a 
major research university has approved this research plan. 
Once this next phase is complete and all of our data is 
evaluated, if the systems provides helpful for these 
individuals with dementia and their caregivers, we plan to 
perform a larger study. The larger study would involve 
individuals in various settings, those living in other 
institutions as well as at home. This system could also be 
considered for other populations that also have potential 
adverse behavior issues such as those with traumatic brain 
injury (TBI) or special needs children for example. Finding 
methods to intervene earlier when behavior problems occur 
can reduce caregiver stress, overall cost of care and likely 
reduce the amount of medications provided to individuals 
with BSD. The emotions experienced by people with BSD 
are real, and developing tools to predict outbursts will 
improve their overall wellbeing as well. 
REFERENCES 
[1] Alzheimer’s Association. 2016 Alzheimer’s disease facts and 
figures. Retrieved from:  
http://www.alz.org/alzheimers_disease_stages_of_alzheimers.
asp, 2016. 
[2] Alzheimer’s Disease International. Dementia Statistics. 
Retrieved 
from: 
https://www.alz.co.uk/research/statistics, 
2017. 
[3] D. L. Woods, M. Yefimova, and M. L. Brecht,“A method for 
measuring person-centered interventions: detecting and 
characterizing complex behavioral symptoms of persons with 
dementia,” Clinical Gerontologist, 37(2), pp. 139-150, 2014. 
[4] J. Cohen-Mansfield, “Agitated behavior in persons with 
dementia: the relationship between type of behavior, its 
frequency, and its disruptiveness,” Journal of psychiatric 
research, 43(1), 64-69. 
[5] L. L. Tan, H. B. Wong, and H. Allen,  “The impact of 
neuropsychiatric symptoms of dementia on distress in family 
and professional caregivers in Singapore,” International 
Psychogeriatrics 17(2), pp. 253–263, 2005. 
[6] H. Brodaty, M. H. Connors, J. Xu, M.  Woodward, and D. 
Ames, “Predictors of institutionalization in dementia: a three 
year longitudinal study,” Journal of Alzheimer's  Disease, 
40(1), pp. 221-226, 2014. 
[7] M. E. de Vugt, F. Stevens, P. Aalten, R.  Lousberg, N. 
Jaspers, and F. R. Verhey, “A prospective study of the effects 
of behavioral symptoms on the institutionalization of patients 
with dementia,” International Psychogeriatrics, 17(04), pp. 
577-589, 2005. 
[8] D. L. Murman, Q. Chen, M. C. Powell, S. B.  Kuo, C. J. 
Bradley, and C. C.  Colenda, “The incremental direct costs 
associated with behavioral symptoms in AD,” Neurology, 
59(11), pp. 1721-1729, 2002. 
[9] J. Cohen-Mansfield, K. Thein, M. S. Marx, M.  Dakheel-Ali, 
and 
L. 
Freedman, 
“Efficacy 
of 
nonpharmacologic 
interventions for agitation in advanced dementia: a 
randomized, placebo-controlled trial,” The Journal of clinical 
psychiatry, 73(9), pp. 1255-1261, 2012. 
[10] K. Pillemer, E. K. Chen, K. S. Van Haitsma, J.  Teresi, M.  
Ramirez, S.  Silver, G. Sukha, and M. S.  
 Lachs, 
“Resident-to-resident aggression in nursing homes: results 
from a qualitative event reconstruction study,” The 
Gerontologist, 52(1), pp. 24-33, 2013. 
[11] N. Ferrah, B. J Murphy, J. E. Ibrahim, L. C. Bugeja, M. 
Winbolt, D. LoGiudice, L. Flicker, and D. L. Ranson, 
“Resident-to-resident physical aggression leading to injury in 
nursing homes: a systematic review,” Age and ageing, 44(3), 
pp. 356-364, 2015. 
[12] K. Williams, A. Arthur, M. Niedens, L.  Moushey, and L. 
Hutfles, “In-Home Monitoring Support for Dementia 
Caregivers A Feasibility Study,” Clinical nursing research, 
22(2), pp. 139-150, 2013. 
[13] M. Yefimova, and D. L. Woods, “Using Sensor Technology 
to Monitor Disruptive Behavior of Persons With Dementia,” 
In AAAI Fall Symposium: Artificial Intelligence for 
Gerontechnology. October, 2012. 
[14] A. Bankole, M. Anderson, T. Smith-Jackson, A. Knight, K. 
Oh, J. Brantley, A. Barth, and J. Lach,  “Validation of 
noninvasive body sensor network technology in the detection 
of agitation in dementia,” American journal of Alzheimer's 
disease and other dementias, 27(5), pp. 346-354, 2012. 
[15] C. N. Fowler, K. Kott, M. N. Wicks, and C.  Rutledge, “Self-
Efficacy and Sleep Among Caregivers of Older Adults With 
Dementia: Effect of an Interprofessional Virtual Healthcare 
Neighborhood,” Journal of Gerontological Nursing, 42(11), 
pp, 39-47, 2016. 
[16] J. Pansiot, D. Stoyanov,  D. McIlwraith, B. P. Lo and G. Z. 
Yang,  “Ambient and Wearable Sensor Fusion for Activity 
Recognition 
in 
Healthcare 
Monitoring 
Systems,” 
In: 
Leonhardt S., Falck T., Mähönen P. (eds) 4th International 
Workshop on Wearable and Implantable Body Sensor 
Networks (BSN 2007). IFMBE Proceedings, vol 13. Springer, 
Berlin, Heidelberg,2007. 
45
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-597-5
HEALTHINFO 2017 : The Second International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

