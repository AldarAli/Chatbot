Using Autarky to Evaluate Quantiﬁed Boolean Formulae
Jens Rühmkorf
Simulation and Software Technology
German Aerospace Center (DLR)
Linder Höhe, D-51147 Köln, Germany
E-mail: Jens.Ruehmkorf@dlr.de
Abstract— In this paper, we discuss algorithmical implica-
tions for the extension of autarky from propositional logic
to evaluate quantiﬁed boolean formulae (QBF). First, the
Davis-Putnam procedure for the satisﬁability problem (SAT)
is described. Then we explain efﬁcient known data structures
for SAT and extensions to QBF which we used in our solver.
Finally, we introduce the concept of autarky and describe how
detecting 2-autarky structures in a given QBF formula helps
pruning the search tree. To the best of our knowledge we are
the ﬁrst to describe such techniques for QBF.
Keywords—Autarky; Davis-Putnam; SAT; QBF
I. INTRODUCTION
In recent years, the language of quantiﬁed boolean formu-
lae (QBF) has gained importance for practical applications.
QBF allows for a concise representation of many classes of
problems [1], [2]: Gopalakrishnan et al. study the problem of
formally verifying shared memory multiprocessor executions
against memory consistency models for the Intel Itanium by
translating occurring problems to the satisﬁability problem
(SAT) and QBF [1]. Mneimneh et al. also consider the ap-
plication area of formal hardware veriﬁcation and transform
the diameter problem — determining the length of a longest
of all shortest paths — for a class of large digraphs to QBF,
but end up converting their problem to SAT, because no
existing QBF solver is able to solve their problems [2].
The paper is organized as follows: Section II introduces
preliminary deﬁnitions and concepts. Section III describes
the Davis-Putnam procedure for SAT along with efﬁcient
data structures. Section IV discusses efﬁcient data structures
used for extending Davis-Putnam to QBF. Based on our
experimental results (due to space limitations not discussed
in this paper). Sections V and VI derive enhancements to
the current algorithm by extending the concept of autarky to
QBF and discuss possible implementation approaches. Sec-
tion VII concludes the paper by brieﬂy evaluating the current
status and provides information on future development.
II. PRELIMINARIES
A quantiﬁed boolean formula Φ = q1z1 · · · qnzn ϕ con-
sists of a sequence of quantiﬁed variables, the so-called
preﬁx, followed by a quantiﬁer free SAT formula ϕ, the
matrix of the formula. The preﬁx q1z1 · · · qnzn contains
universal ∀ and existential ∃ quantiﬁers for propositional
variables zi occurring in ϕ. The evaluation problem for a
given QBF Φ is to decide whether Φ is true or not. Example
QBF formulas are ∀y1∃x2 (y1 ∨ ¬x2) ∧ (¬y1 ∨ x2) which
is true and ∀y1∀y2 (y1 ∨ y2) which is false.
A literal L is a variable z or ¬z. For two different literals
Li, Lj with corresponding variables zi, zj of a QBF formula
Φ we may write Li < Lj if zi occurs to the left of zj in the
preﬁx of Φ. We use Lit(Z) as shorthand notation for the set
of literals for a given set of variables Z. Similarly, Var(Φ)
and Var(ϕ) are used for the variable sets occurring in a QBF
formula Φ and a SAT formula ϕ, respectively. A clause is
a formula κ = (L1 ∨ · · · ∨ Lk) with literals Li; the second
clause of the ﬁrst example is (¬y1 ∨ x2) with literals ¬y1
and x2. We say a SAT formula ϕ is in conjunctive normal
form (CNF), if it is expressed by a conjunction of clauses
ϕ = κ1 ∧ · · · ∧ κℓ.
III. DAVIS-PUTNAM FOR SAT
Both SAT and QBF describe prototypical complete prob-
lems for the important complexity classes NP and PSPACE,
respectively. Syntactically restricted forms of QBF describe
complete problems for ΣP
k and ΠP
k within the polynomial
time hierarchy PH. For the remainder of this paper, we
consider only quantiﬁed boolean formulae Φ whose matrix
ϕ is in CNF. Indeed, for a given QBF formula Φ we may
generate in linear time an equivalent quantiﬁed boolean
formula whose matrix is in CNF [4, ch. 7].
The evaluation algorithm used within this paper is a
generalization of the Davis-Putnam procedure for SAT [5]
to QBF [6]. Figure 1 on the following page describes the
Davis-Putnam algorithm as recursive function. The algo-
rithm utilizes the following two fundamental observations:
Lemma 1 (monotone literal [5]) If the literal L is mono-
tone, i.e. by deﬁnition, L occurrs only positive (L = x) or
negative (L = ¬x) within the CNF formula α, then α is
equivalent to α[L/1] or α[L/0], respectively.
□
Lemma 2 (unit clause [5]) Let L be the literal of a unit
clause of the CNF formula α. Then α is satisﬁable if and
only if α[L/1] is satisﬁable.
□
Here α[L/ǫ] denotes the formula obtained from α by re-
placing each occurrence of L with ǫ ∈ {0, 1}. Furthermore,
154
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

a clause κ is called k-clause, if κ contains only k literals
(L1 ∨ · · · ∨ Lk), a 1-clause (L) is called unit clause.
Function boolean Davis-Putnam(CNF formula* α)
Input: Pointer to CNF formula α.
Output: true if α is satisﬁable and false otherwise.
begin
if α = 1 then return true;
if α = 0 then return false;
L ← Pure-Literal(α);
if L ̸= NULL then
return Davis-Putnam(α[L/1]);
L ← Unit-Literal(α);
if L ̸= NULL then
return Davis-Putnam(α[L/1]);
L ← Choose-Literal(α);
if Davis-Putnam(α[L/1]) then
return true;
return Davis-Putnam(α[L/0]);
end
Figure 1: The Davis-Putnam algorithm for SAT.
Function Pure-Literal corresponds to lemma 1: it
returns for a formula α a pointer to a monotone literal if
it exists and NULL otherwise. Function Unit-Literal
utilizes lemma 2 and returns a unit clause if it exists and
otherwise NULL. The function Choose-Literal deﬁnes
the heuristic which literal to use next for branching. Good
experimental results are obtained by using the lexicograph-
ical heuristic [7]: Let hi(L) be the number of clauses of
length i in which a given literal L occurs. Then calculate:
Hi(A) = max

connects the list heads of all positive literals, whereas the
list
neg
connects the list heads of all negative literals.
These two lists represent the yet unassigned literals in the
given formula.
When
applying
changes
within
the
data
structure,
bookmarking links are set to be able to easily revert
changes made when traversing the execution tree. Fig-
ure 4 on the preceding page shows the changes to the datas-
tructure when removing a clause (e.g. when performing
α[L/1]) and similarly ﬁgure 5 shows the changes performed
when shortening a clause (e.g. when performing α[L/0]).
Operation
Runtime
Unassign(α,L), Assign(α, L)
O

The choice of a literal out of Lit(Yi) respectively Lit(Xj)
is then determined by the function Choose-Literal().
For the lexicographic heuristic for SAT described by equa-
tion (1), the literal is chosen which occurs most often in the
shortest clauses of a given formula. Translated to QBF, a
literal with such properties out of the leftmost preﬁx group
is chosen. For QBF, the length of a clause is measured
by counting the number of ∃-quantiﬁed literals whithin a
clause, irrespective of its corresponding position within the
clause (see [8] for a similar approach). For example: a clause
(x1 ∨ y2 ∨ y3) is treated by this modiﬁed heuristic just like
the clause (y4 ∨x5 ∨y6 ∨y7), while the unmodiﬁed heuristic
from equation (1) would rank the literals of the ﬁrst clause
better than literals from the second clause.
V. UTILIZING AUTARKY FOR QBF
A function I : {x0, x1, x2, . . .} → {0, 1} for variables xi
is called a truth assignment. If I is a partial assignment
that operates on a subset of the variables Var(ϕ) of a
SAT formula ϕ, then I(ϕ) denotes the formula obtained by
assigning truth values to this subset’s variables accordingly.
Deﬁnition 6 (autark assignment [9]) A truth assignment
I of some variables {xi1, . . . , xik} of a SAT formula ϕ is
called autark, if the following holds: every clause of ϕ that
contains a variable xij is already satisﬁed by I.
If such an I “touches” a clause of ϕ, this clause is already
satisﬁed by I: every clause of I(ϕ) occurs in ϕ. Autarky
has the nice property that we may remove all clauses with
variables xij from ϕ without changing the satisﬁability of
ϕ. The following easy remark gives further insight:
Remark 7 (Satisﬁability of autark assignments) If I is
an autark assignment of variables Vaut = {xi1, . . . , xik}
for a SAT formula ϕ, then ϕ is satisﬁable if and only if an
assignment I′ exists that satisﬁes ϕ and the restriction of I′
to Vaut is identical to I, i.e., I′|Vaut = I.
Proof. Let I be an autark assignemnt for ϕ, with variable
set Vaut and let H be a thruth assignment that satisﬁes ϕ. We
may alter I in accordance to H by deﬁning I′(x) = I(x)
if x belongs to Vaut and I′(x) = H(x) otherwise. Then I′
satisﬁes ϕ.
□
For the easy case of 1-autarky with |Vaut| = 1 remark
7 corresponds to lemma 1 on page 1, the rule monotone
literal. Our experiments showed that this rule lead to good
results for quantiﬁed formulas, i.e. to considerably less
branching nodes within our execution tree.
Therefore we examine how to extend the concept of
autarky to quantiﬁed boolean formulae. We consider the case
of 2-autarky for a QBF formula Φ. Without loss of generality
Φ may contain no monotone literals. That means we examine
all variable subsets from Var(Φ) with size 2, respecting their
order in the preﬁx. The idea is to compute these subsets in
advance and later utilize them for search tree pruning. For
this, the following cases need to be considered:
Case 1: 2-∃∃-autarky {xi1, xi2}. If an autark truth assign-
ment exists for two ∃-quantiﬁed variables xi1 < xi2, we
have an already known case: all clauses, that contain either
xi1 oder xi2 may be removed. This is also true if xi1 and
xi2 do not belong to the leftmost preﬁx group.
Case 2: 2-∀∀-autarky {yi1, yi2}. For this case we closer
examine the structure of all clauses that contain yi1 or yi2.
There are eight possibilites for membership of yi1 or yi2
within a clause. Figure 8(a) shows the four possible ways
that a clause contains either yi1 or yi2, positive or negative.
Figure 8(b) shows the four possibilities that yi1 as well as
yi2 are contained in a clause. There • describes a positive
literal, • describes a negative literal, and ◦ shows that the
variable in question is not contained in the clause.
•
◦
•
◦
◦
•
◦
•
(a) 1-structure.
•
•
•
•
•
•
•
•
(b) 2-structure
Figure 8: Clause structure for 2-autarky.
We have 28 = 256 possible structural occurrences of two
given distinct variables in the clauses of a CNF formula. Of
these occurrences only those need to be considered where
both variables occur at least once in a clause; so seven cases
may be rejected. By a combinatorical argument with some
case distinctions we may identify 90 cases of 2-autarkies
and therefore 159 cases of not-2-autarkies — this includes
symmetries and renamings of the kind z ← ¬z.
⇓
⇓
⇓
•
•
•
•
•
•
1
1
1
0
0
1
1
0
1
1
0
0
0
1
0
0
1
1
0
0
0
1
1
0
(a) Three necessary branchings.
⇓
⇓
•
◦
•
•
•
•
1
1
0
0
1
1
1
1
0
0
0
0
0
1
1
0
0
1
1
0
(b) Two necessary branchings.
Figure 9: Branchings for 2-∀∀-autarky.
We discuss essential ideas with the help of some exam-
ples. Figure 9(a) shows a 2-autarky with three possible types
of clause-structures (. . . yi1 ∨ yi2 . . .), (. . . yi1 ∨ ¬yi2 . . .) as
well as (. . . ¬yi1 ∨ yi2 . . .). First we consider the case that
both variables are part of the leftmost preﬁx group. Then
branching according to the ﬁrst column (i.e. I(yi1) = 1 und
I(yi2) = 1) does not make sense due to the 2-∀∀-structure.
157
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

Then, in the worst case, each of the other branchings needs
to be considered.
How does the preﬁx order inﬂuence the algorithm? If
yi1 belongs to the leftmost preﬁx group we may branch
immediately. Because we have 2-autarky, the assignment of
yi1 leads to a monotone literal yi2 in the reduced formula
(which may be pruned, column 2). If this branch does not
lead to an abort, columns 3 and 4 need to be considered.
Here we must wait with the assignment of yi2 until either
allowed by the preﬁx ordering or a special rule (monotone
quantiﬁed literal, unit existential clause) applies.
For the case that yi1 does not belong to the leftmost
preﬁx group we may bookmark the 2-autarky for later
consideration.
⇓
⇓
•
◦
•
•
•
•
1
1
0
0
1
1
1
1
0
0
0
0
0
1
1
0
0
1
1
0
Figure 10: Two branchings for 2-∀∃-autarky.
For the case of ﬁgure 9(b) on the preceding page we
have a different situation. Here also three different clause
types need to be considered, but with only two meaningful
branchings. Just like for ﬁgure 9(a) we do not need to branch
as described in column 1. This also holds for column 4 due
to the structure of column 3. Furthermore the same remarks
as above apply with regard to the moment we are allowed
to branch.
Case 3: 2-∀∃-autarky {yi1, xi2}, with yi1 ∀-quantiﬁed and
xi2 ∃-quantiﬁed, and yi1 < xi2. We look at the preceeding
example: In case I(yi1) = 1, then xi2 becomes monotone,
and only branching for column 1 is necessary. If I(yi1) =
0, also because of monotony only column 4 needs to be
considered.
Case 4: 2-∃∀-autarky {xi1, yi2}, with xi1 ∃-quantiﬁed,
yi2 ∀-quantiﬁed, and xi1 < yi2. For a structure analogous
to ﬁgure 9(b) on the previous page we only need to branch
for columns 2 and 3 (similar to the 2-∀∀-autarky).
z
}|
{
•
◦
◦
•
•
•
•
•
1
1
0
1
0
0
1
0
0
0
0
1
0
1
0
1
1
0
0
0
0
0
1
1
Figure 11: Two branchings for not-2-autarky.
All four cases have in common, that one reduction occurs
because of the rule monotone literal. This may ease the later
implementation. Also, not-autarky allows for simpliﬁcations
as well, as shown in column 3 and 4 of ﬁgure 11.
VI. CHANGES TO QBF DATA STRUCTURES
From existing experiments with the rule monotone literal
for SAT formulas it is known [7], that this rule does not
lead to considerable improvements and is usually left out.
For SAT solvers which use the described data structure
the heuristic (and its computation cost) has considerable
implications on the overall practical runtime of the solver.
For QBF formulas the heuristic has less choice due to
the preﬁx, on the other hand a wrong choice has stronger
implications. Here we consider how to practically implement
the proposed considerations by integrating them into our data
structure.
For a quantiﬁed k-CNF clause α with n variables and m
clauses the data structure requires O(k · 2n + k · m) space
so far: each literal L has a ﬁeld of length k that counts
occurrences of L in clauses of length 1, . . . , k, where k ·
m is the size of the matrix. Therefore, the runtime of the
lexicographic heuristic is O(k · 2n). For QBF formulas the
heuristic requires O(k · 2 · |Z1|) time, where Z1 denotes the
leftmost preﬁx group.
In order to consider structural information for a given vari-
able pair (z1, z2) for the heuristic Choose-Literal(),
a ﬁeld s of length 8 is used for each relevant combination,
which counts the occurrence of the pairs (z1, z2) in the
clauses of the formula. Only combinations of pairs are
relevant that occur at least once together in a clause. For
example: if x1 and y2 occur only as (. . . ∨ x1 ∨ . . .) or
(. . . ∨ ¬x1 ∨ . . .) and (. . . ∨ y2 ∨ . . .) or (. . . ∨ ¬y2 ∨ . . .),
the removal of a clause containing x1 or ¬x1 may not lead
to y2 becoming monotone. Therefore, structural information
of at most O(k2 ·m) many of O(n2) possible pairs needs to
be kept: for each of the m clauses only up to k·(k−1)
2
new,
so far not considered pairs may be introduced.
The fact that the set of O(k2 · m) many ﬁeld addresses is
static for a given input formula may be used for accelerated
access: A supporting data structure must provide for fast
access for any given variable pair. A possible solution for
this is to use corresponding hash functions.
When using hashing, a set of keys S ⊆ U with universe
U = {1, . . . , N} and |S| ≪ |U| is mapped to numbers
0, . . . , t − 1 with t ≥ s := |S|. Here, a hash function
h : U → {0, . . . , t − 1} is used. In case h|S is one-
to-one, we call it a perfect hash function, which is per
deﬁnitionem collision free. We cite from [10] the result:
for every t ≥ 3 · s there exists a perfekt hash function,
which can deterministically be computed in time O(s · N)
and probabilistically in time O(s) and whose execution
requires time O(1). One such hash function is described
by a program with O(s · log N) bits. For a short overview
on the subject we refer to [11].
Aside from hash functions we may also consider a hybrid
data structure like the trie or preﬁx trie for our purposes. So
[12] describes a variant of such a trie data structure suitable
for storing a set S ⊆ U, where s := |S| and N := |U| are
as above, with O(s) memory slots with O(log s) bits each
and worst-case access of O

is polynomial in s = k2 · m = k2 · r · n, which leads to
the access time of O

