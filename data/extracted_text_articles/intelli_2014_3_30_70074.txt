A Method for Evolutionary Decision Reconciliation,  
and Expert Theorems 
 
Vladislav Protasov, Zinaida Potapova, and Eugene Melnikov 
Center of Computing for Physics and Technology 
Moscow, Russia 
protvlad@gmail.com, zinaida.potapova@gmail.com, apinae1@gmail.com 
 
 
Abstract—The author believes that the lack of a theory behind 
collective intelligence systems and efficient information 
technologies is one of the reasons for slowing down the 
development of e-democracy processes. Existing government 
system, the democracy of the voting majority, is based on ideas 
that are more than 200 years old and on the well-known 
Condorcet’s jury theorem. One of this theorem’s corollaries is 
that a decision made by the majority vote of a group is worse 
than a decision made by a single member of the same group if 
the members of this group make incorrect decisions more often 
than they make correct decisions. This paper provides proof of 
two expert theorems proposed by the author. These theorems 
apply to groups of experts making joint decisions, and they 
propose that a group of experts involved in reconciliation 
increase the probability of correct decision if the experts have 
an opportunity to select and vote on the best third-party 
decisions. Conditions are provided under which the probability 
of correct decision by the group of experts approaches 1 as the 
number of the experts increases. These theorems indicate the 
direction for development of network programs helping groups 
of low-competence experts to overcome the Condorcet’s 
border. 
Keywords- collective intelligence systems; Condorcet’s jury 
theorem; e-democracy; crowdsourcing; evolutionary decision 
reconciliation. 
I. INTRODUCTION 
The development and use of collective intelligence 
systems is a popular trend, with individual intelligence no 
longer being able to keep the pace with the development of 
our civilization. More than 700 crowdsourcing platforms 
have been developed and are in use today [1]. Some of them 
are used directly in e-democracy initiatives [2]. There is an 
opinion 
that 
development 
of 
network 
information 
technologies will inevitably lead to the emergence of 
planetary intelligence and the new type of public 
government—direct e-democracy [3]. The author believes 
that the lack of a theory behind collective intelligence 
systems and efficient information technologies is one of the 
reasons for slowing down this process. Existing government 
system—the democracy of the voting majority—is based on 
more than 200-year-old ideas and works by Marquis de 
Condorcet [16], and no longer fits the spirit of the times. 
Modern times require a more progressive democracy system 
relying on the latest network technologies and, most 
importantly, the new organizational principles for collective 
intelligence systems.  
Collective intelligence is a term first used in mid-1980s 
in sociology in research of collective decision-making 
process. NJIT (New Jersey Institute of Technology)  
researchers defined collective intelligence as the ability of a 
group to find solutions to a problem that are more efficient 
than any of the solutions found by individual members of 
the same group[4].  This concept is used in sociobiology, 
political science, group reviewing and crowdsourcing 
applications[5]. It can also be defined as the product of 
collaboration between the people and data processing 
methods.  In this definition, collective intelligence is 
referred to as “symbiotic intelligence” and is described by 
Norman Lee Johnson[6].  According to Lévy, this 
phenomenon is related to the ability of network information 
and communication technologies to expand the common 
body of social knowledge and the range of possible 
collaboration among people [7]. 
As described in [8], certain factors related to challenges 
in human interactions often make a consolidated group 
decision unreachable, and these environments require the 
use 
of 
efficient 
coordination 
methods 
for 
group 
collaboration and the involvement of facilitators in charge 
of such coordination.  
A method for evolutionary decision reconciliation 
currently researched in Russia is, to a large degree, free of 
these limitations [9][10].   Specially designed rules for 
interactions between group members based on genetic 
algorithms are used as facilitators.  
This method can be briefly described as follows. A 
group of experts receives a problem with a clear goal and 
clear requirements for solution, which should be presented 
in text form. Experts work anonymously and interact by 
exchanging partial solutions with one another via a 
computer network.   
The first stage is solution generation stage when experts 
create variants of partial solution to the problem based on 
the project goal.  The second and further stages are iterative 
reconciliation stages when experts evaluate others' solutions 
and select what they believe to be the best parts of these 
solutions. Number of variants to be evaluated depends on 
the interaction rules. Others' solutions for reconciliation are 
chosen randomly, just like in genetic algorithms. Iterations 
continue until the allocated time runs out or more than half 
43
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-352-0
INTELLI 2014 : The Third International Conference on Intelligent Systems and Applications

experts end up with identical solutions. In the first case, 
group solution is created as a combination of parts of 
individual solutions with the largest number of matches. In 
the second case, group solution is the solution chosen by the 
majority of experts.  
The paper is structured as follows. The next section after 
introduction describes the new technology developed by the 
authors that is based on the Evolutionary Decision 
Reconcillation method. In the third section the Condorcet’s 
theorem is described with discussing the conditions of 
obtaining the solution with probability, close to one, for 
crowdsourcing systems.The fourth section presents and 
proves basic theorems of the new technology that allows 
experts to overcome the “Condorcet’s border”. In the fifth 
section possible areas of the technology application are 
given. The sixth section concludes the paper. 
II. METHOD FOR EVOLUTIONARY DECISION RECONCILIATION 
This paper discusses several recent results that, in the 
author’s opinion, may support the principles of metasystem 
transitions offered by Turchin [11]. Groups of individuals 
and basic computers were used as components of a system 
representing the next-generation intelligence. This system 
demonstrated considerably higher “intelligence” than the 
combined intelligence of its isolated constituents. 
Proposed approach can prove useful in the development 
of artificial intelligence. This method could help to design 
symbiotic architectures from neuronets and neurocomputers, 
computers and their networks, groups of people and genetic 
rules working as a single unit. Protasov successfully applied 
these rules to improve human intelligence [12] and the 
“group intelligence” of robot groups [13]. A similar 
approach could perhaps be used to construct hierarchical 
networks with cascaded “intelligence” gains at each level. 
For example, a popular target distribution problem can 
be formulated as follows: there are m robots with calculators 
and n targets. Each calculator has coordinates of all robots 
and all targets. The goal is to split robots and targets in pairs 
so that if m < n or m = n, then there is at least one robot for 
every target, and if m > n, then there is at least one target for 
every robot, and the sum of distances S between robots and 
their paired targets is minimal. 
Experience shows that the generic method is sufficiently 
effective in solving this type of problems. The most trivial 
solution would be as follows: since the every calculator of 
every robot i has location data for all robots and targets, it 
can build a set of possible target distributions using standard 
crossover, mutation, estimation and selection operations, 
through some iterations will result in less than optimal 
solutions. Since all calculators use the same algorithm and 
have identical data sets, they generate identical solutions 
when they operate independently, and each robot will 
choose its target. The advantage of the proposed method is 
that it can be used to speed up the calculations by a factor of 
m by making a more efficient use of resources. 
In [13], a method for distributed calculations was 
proposed whereby one super-calculator coordinates the 
work of other calculators to reduce the overall time required 
to make a decision. 
For the target distribution problem, the following 
algorithm was proposed: each calculator will use its own 
random number generator to create one possible solution, 
which will likely be far from optimal. All proposed 
solutions will be different. Then the calculators will 
communicate and exchange proposed solutions. After that, 
the calculators reject the worst half of the overall number of 
solutions, certain mutations in proposed solutions, and 
exchange solutions again. This process will continue until 
only one solution remains. Then the calculations will stop, 
and each robot will have the best solution in its possession. 
A demo program called COLLINTROB was developed 
and tested on Delphi platform. It demonstrated that the time 
to reach a common decision was inversely proportional to 
the number of calculators in system. Some experiments 
simulated failures of a certain number of calculators and 
demonstrated that calculator failures did not degrade the 
quality of solution (the result was within 5% from the ideal 
solution), but the time required to reach the decision 
increased proportionally M / (m-k), where k is the number of 
failed calculators. 
The analysis of these experiments suggests that the 
“collective intelligence” of calculators incorporated in the 
super-calculator increases  and it becomes greater than the 
intelligence of individual calculators on a certain class of 
problems. In other words, in this case we see the 
metasystem transition resulting in the occurrence of “greater 
mind” consisting from artificial components with a lower 
level of “intelligence”. 
The same rules of interaction between the individual 
components of such a “collective mind” were used in tests 
using human subjects and were applied to create the new 
kind of collective intelligence in the so-called Method for 
Evolutionary Decision Reconciliation (MER) [9]. 
The variables, such as the number of participants or the 
number of proposals discarded at each step, can vary 
depending on the type of problem and can be selected 
experimentally. 
The Method for Evolutionary Decision Reconciliation 
was tested in groups of 4 to 20 male students in different 
areas including collective poetry, music composition, 
creation of psychological portraits, development of simple 
computer program, selection of the best move in a chess 
game, direct sales, portrait painting, and creation of abstract 
diagrams. 
These experiments confirmed that collective intelligence 
exceeds the combined intelligence of individual contributors 
and shows the phenomenon of knowledge transition from 
the strongest contributors to the weakest. This method also 
44
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-352-0
INTELLI 2014 : The Third International Conference on Intelligent Systems and Applications

allows ranking the contribution of individual participants to 
the final product. It usually did not take long to solve simple 
tasks, and as a rule, the duration of experiments did not 
exceed two hours, with Eysenck tests taking approximately 
30 minutes). Students were quite enthusiastic about these 
experiments, and excited about being a part of collective 
mind exceeding their individual capabilities. 
III. CONDORCET’S JURY THEOREM 
Protasov et al. [14] provide the results of computer 
modeling for a collective decision-making process using the 
new technology. Certain specific competence levels of 
experts, who generate ideas and evaluate others’ solutions, 
were shown to amplify the intelligence when the experts 
were working with the group. This paper contains the proofs 
of theorems confirming this effect. 
Let us start with discussing the limitations of collective 
intelligence systems following from Condorcet’s jury 
theorem.  
One of the definitions of Condorcet’s jury 
theorem [15] is as follows:  
Let us assume that one of the two decisions proposed to 
the jury is correct, and each jury member, on average, 
makes correct decisions more often than not. The theorem 
claims that as the number of participants increases, the 
probability that the correct decision is made tends to one. 
The probability that the group of М experts makes correct 
decision, assuming that each of these experts makes correct 
decision with the probability of G,  can be calculated as 
follows: 
i
i
M
M
i
i
M
G
G
K
)
1(
)
(
2
1
0
0





                      (1) 
With G>0.5 and 
M 
, we have the Condorcet effect, 
and the probability of correct decision by the group of 
experts
K0 1
, but with G<0.5, the probability
K0  0
. In 
other words, G=0.5 is the border value that weak experts are 
unable to overcome.  
 
  
The Condorcet’s effect is used in modern crowdsourcing 
systems where tens and hundreds of thousands of users find 
the best decisions. Unfortunately, G is not guaranteed to be 
always greater than 0.5. We will show that if we give experts 
with 0<G<0.5, who did not make their decisions for any 
reason, an opportunity to view decisions of other people and 
select the best of them, then under certain conditions the 
probability that a group of such experts makes a correct 
decision by majority vote tends to 1 with the increase of the 
number of experts in the group, or in other words, such a 
group is able to overcome the Condorcet’s border.  
The purpose of this research is to evaluate the 
competence of experts that guarantees that the probability 
that the group of experts makes the correct decision 
approaches 1 as the number of experts increases.  
Experts are supposed to use evolutionary decision 
reconciliation in their collective work.  
This work presents proofs for two theorems that help to 
forecast the results of group effort based on expert 
competence levels, offers several corollaries and discusses 
benefits and use cases of the new technology.  
IV. EXPERT THEOREMS 
A. Theorem 1 
Let us assume that at the individual decisions stage, each 
expert makes correct decision with the probability 
5.0
0


GP
, incorrect decision with the probability 
5.0
0


GN
, or no decision with the probability 
)
(
1
N
P
V
G
G
G

 
, and at the group decisions stage, an 
expert that did not make any decision selects correct decision 
out of several third-party decisions with the probability 
P
E  
(assuming it is available), incorrect decision with the 
probability 
EN
, or no decision. The theorem proposes that 
when 
5.0
)
1 (





N
P
N
P
P
P
E
E
G
G
E
G
 condition is met, the 
probability that correct decision is selected by majority vote 
at reconciliation stage increases and tends to one as the 
number of experts increases.  
Proof. At the individual decisions stage, the expected 
value of the number of experts 
0
P  who make the right 
decision (subgroup P) is 
GPM
 (where M  is the total number 
of experts); the expected value of the number of experts 
0
N  
who make the wrong decision (subgroup N) is 
GN M
; and 
the expected value of the number of experts 
0
V  that make no 
decision (subgroup V) is
M
G
G
G M
N
P
V
)
1(



.  
At reconciliation stage, experts from subgroup V will join 
experts in subgroups P and N in proportion to 
P
E  and
N
E , 
while 
subgroup 
V 
will 
reduce 
in 
proportion 
to
N
P
V
E
E
E

1
. Let us designate
iP , 
i
N  and 
iV  as the 
expected values of the number of experts in respective 
subgroups at the i-th iteration of the reconciliation stage.  
Iteration 1:
M
E G
G
P
V
P
P
)
(
1


,  
M
E G
G
N
V
N
N
)
(
1


,  
E G M
V
V V
1 
. 
Iteration 
2: 
M
E E G
E G
G
P
V
V
P
V
P
P
)
(
2



, 
M
E E G
E G
G
N
V
V
N
V
N
N
)
(
2



, 
E G M
V
V
V
2
2 
. 
… 
Iteration i: 





1
0
i
k
K
V
V
P
P
i
E
E G M
G M
P
,          





1
0
i
k
K
V
V
N
N
i
E
E G M
G M
N
,         
E G M
V
V
i
i  V
.  
With
i  
, if we replace 


1
0
i
k
K
EV
 with its limiting value 
 EV
1
1
 and the last term of geometric progression 
iV  with 
zero, we will get the expected values 
B
P , 
NB
 and 
B
V  for 
the numbers of experts in groups P, N and V: 
M
E
E G
G
P
V
V
P
P
B
)
1
(
 

 , 
M
E
E G
G
N
V
V
N
N
B
)
1
(



 , 
VB  0
.  
(2) 
45
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-352-0
INTELLI 2014 : The Third International Conference on Intelligent Systems and Applications

With 
5.0
)
1 (





N
P
N
P
P
P
E
E
G
G
E
G
, the majority of the 
group will make the right decision. Since with 
M  
, the 
PB / M
 ratio is the probability that the expert makes correct 
decision at the end of reconciliation stage, the condition of 
Condorcet’s theory is met, and our theorem is therefore 
proven.  
For practical use and theoretical research, the condition 
of this theorem can be expressed as 
N
P
N
P
G
G
E
E
2
1
2
1

 
.                  
 (3) 
Let us review several corollaries of (3): 
If the experts in the group have weak decision-making 
capability (
N
P
G  G
), then for the probability that they make 
correct decision to be more than 0.5, they need strong 
evaluation capability (
N
P
E
E

).  
If the experts in the group have strong decision-making 
capability (
N
P
G
G

), then for the probability that they make 
correct decision to be higher than 0.5, even weak evaluation 
capability is sufficient (
N
P
E
E

).  
If both capabilities are weak in the group, experts will not 
be able to make correct decision with probability higher than 
0.5. Moreover, the probability that the vote results in correct 
decision decreases and tends to zero as the number of such 
experts increases.  
 
B. Theorem 2 
 
Suppose that at the individual decision stage, every 
expert makes correct decision with the probability of 
5.0
0


GP
, incorrect decision with the probability of 
5.0
0


GN
, or no decision with the probability of 
)
(
1
N
P
V
G
G
G

 
; and at the first iteration of reconciliation 
stage, each expert who did not make a decision receives a 
randomly selected third-party decision, and then the expert 
correctly evaluates the correctness of this decision with the 
probability of 
R
E , and as a consequence, either submits or 
does not submit this decision for a vote.  
 The 
theorem 
proposes 
that 
when 
P
P
N
P
N
P
R
G
G
G
G
G
G
E
2
1 2
)
1 (





 condition is met, the probability 
that correct decision is selected by majority vote at the first 
iteration of reconciliation stage increases and tends to one as 
the number of experts increases.  
Proof. At the individual decisions stage, the expected 
value of the number of experts 
0
P  who make the right 
decision is 
GPM
; the expected value of the number of 
experts 
0
N  who make the wrong decision is 
GN M
; and the 
expected value of the number of experts  that make no 
decision 
0
V  is 

M
G
G
G M
N
P
V
)
1 (



. At the first iteration 
of the reconciliation stage, the number of correct decisions 
will increase by 
M
G
G
G G
E
N
P
V
P
R

, because the probability that 
correct decision is selected out of all decisions made is 
N
P
P
G
G
G

; the probability that this selection is made by an 
expert who did not make a decision is 
GV
; and the 
probability that this decision is included in the group’s 
decision is 
R
E . Therefore, the expected value of the number 
of 
correct 
decisions 
at 
the 
first 
iteration 
is 
M
G
G
G
G
E G
G M
P
N
P
N
P
P
R
P





)
(
1
1
 . Let us make the same 
condition we used in the previous theorem, that 
5.0
1 
M
P
 
when 
M  
, or after transformations, the condition of the 
theorem 
P
P
N
P
N
P
R
G
G
G
G
G
G
E
2
1 2
)
1 (





. Since when 
M  
, 
the 
P / M
1
 ratio is the probability that the expert makes 
correct decision at the first iteration of reconciliation stage, 
the condition of Condorcet’s theory is met, and our theorem 
is therefore proven.  
V. TECHNOLOGY FOR EVOLUTIONARY DECISION 
RECONCILIATION 
There are many groups of experts that are not capable of 
making their first opinion correct with probability higher 
than 0.5. Theorems proven above give us a hope for 
development of modern network programs that are able to 
overcome Condorcet’s border and can be used efficiently in 
e-democracy systems.  
The phenomenon when the probability that a group of 
experts makes correct decision increases due to the use of 
abilities of experts in selection of best decisions gave an 
opportunity to develop a new information technology for 
evolutionary 
decision 
reconciliation 
[9]. 
Multiple 
experiments in different creative fields confirmed the 
efficacy of the new approach. For example, collective 
intelligence was used to solve complex chess problems 
beyond the capabilities of individual group members; a 
group of witnesses effectively built a facial composite; a 
group of automated translators translated texts with higher 
quality than that of individual translations. IQ measurements 
using Eysenck verbal tests demonstrated group intelligence 
when the group was able to find correct answers to all 50 
questions within a limited period of time [16]. One of the 
benefits of the new technology is that it gives an opportunity 
for 
objective 
measurements 
of 
individual 
expert 
contributions to the group project—both as idea generators 
and as evaluators of third-party decisions—and for 
development of hierarchical collective intelligence systems 
based on these measurements.  
VI. CONCLUSION 
The aforementioned results suggest that the evolutionary 
decision reconciliation technology is advisable for use in 
project management systems and e-democracy systems.  
New opportunities offered by this technology can expand the 
circle of potential contributors to collective solutions. 
Anonymous group effort, when experts work with ideas in 
text form without the need for personal contact with 
46
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-352-0
INTELLI 2014 : The Third International Conference on Intelligent Systems and Applications

individuals with whom such contact is difficult due to 
psychological reasons, helps to fully unleash the intellectual 
potential of every expert. Use of genetic algorithms as group 
facilitators ensures quick convergence of the iterative 
process used to generate consolidated text. The technology 
based on evolutionary reconciliation method provides an 
opportunity to evaluate objectively the contribution of each 
expert to the consolidated product, and to establish a 
hierarchically 
organized 
self-governing 
crowdsourcing 
community[16]. Expert theorems proved in this work allow 
forecasting the probability that the decision will be correct as 
long as expert competence levels are known. The author and 
his colleagues are planning to continue research focused on 
practical use of this method to solve a variety of creative 
problems that expert communities are facing, and on the 
measurement of expert competence levels. 
ACKNOWLEDGEMENTS 
 This work was supported by the Russian Foundation for 
Basic Research, grant #13-07-00958 “Development of the 
theory and experimental research of a new information 
technology of self-managed crowdsourcing”. 
 
REFERENCES 
[1]     http://crowdsourcing.ru/sites/17, [retrieved: 04, 2014]. 
[2]  Dutton W. H., “Networked Citizens and e-Democracy”, 
Conference on Citizenship and the Information Society, 1999, 
Lisbon, December 10, pp. 47-68 in Portugese, pp. 171-187 in 
English. 
[3] http://andreo.li/blog/2-0-government-direct-democracy/, 
[retrieved: 05, 2014]. 
[4[   http://www.njit.edu/, [retrieved: 05, 2014]. 
[5]   J. Howe,  “Crowdsourcing: Why the Power of the Crowd Is 
Driving the Future of Business”, Crown Business , 2008, p. 
320. 
[6] http://collectivescience.com/symintel.html, 
[retrieved: 
05, 
2014]. 
[7]  P. Lévy, “Collective Intelligence: Mankind's Emerging World 
in Cyberspace”, 1994, p. 13. 
[8]   A. W. Woolley, C. F. Chabris, A. Pentland, N. Hashmi, T. W. 
Malone, “Evidence for a Collective Intelligence Factor in the 
Performance of Human Groups”, Science, 2010, V. 330 , pp. 
686–688. 
[9]   V. Protasov,  “Design of metasystem transitions”, Moscow,  
Physical and Technical Informatics Institute Press, 2009, p. 
186. 
[10]  V. Protasov, Z. Potapova, “Self-Governing Crowdsourcing. 
Theory, Technology and Practice.”, Conference material of 
the 3rd International Conference on Control Automation, 
Intelligent Systems and Environments. Makhachkala, 2012, 
RAS Kabardino-Balkar Science Center Press, Vol. 1, pp. 91-
99. 
[11] V. F. Turchin., “The phenomenon of science a cybernetic 
approach to human evolution”, New York, Columbia 
University Press, 1977. 
[12] V. Protasov, “Generation of new knowledge by network 
human-machine intelligence. Statement of the problem”, J. 
Neurocomputers. Development and application,, Moscow, 
200,, vol.7-8, pp.94 – 103. 
[13] V. Protasov, N. Vitiska, L.  Shelhkova, “Use of collective 
intelligence of group of robots for acceleration of acceptance 
expedient decision”, Conf.“Intellectual robotic system”, 
Russia, Gelendjik, Oct.  2001, pp. 187— 189.  
[14]  V. Protasov, Z. Potapova, E. Melnikov,  Overcoming the 
Condorcet's Border in Collective Intelligence Systems, “The 
Second International Conference on Intelligent Systems and 
Applications”, INTELLI 2013 April 21 - 26, 2013 - Venice, 
Italy, pp. 314-317. 
[16] Le Marquis de Condorcet, “Essay on the Application of 
Analysis to the Probability of Majority Decisions”, 1785,  Les 
Archives de la Revolution Française, Pergamon Press, pp. 9-
23. 
[16] V. Protasov, Z. Potapova, “Self-Governing Crowdsourcing. 
Theory, Technology and Practice. Conference material of the 
3rd International Conference on Control Automation”, 
Intelligent Systems and Environments. Makhachkala, 2012, 
RAS Kabardino-Balkar Science Center Press, Vol. 1, pp. 91-
99. 
  
47
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-352-0
INTELLI 2014 : The Third International Conference on Intelligent Systems and Applications

