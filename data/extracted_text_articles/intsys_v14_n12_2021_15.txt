153
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Implementing Ethical Issues into the Recommender Systems Design Using the Data 
Processing Pipeline 
Olga Levina  
Brandenburg University of Applied Sciences 
Brandenburg an der Havel, Germany 
e-mail: levina@th-brandenburg.de 
 
Abstract—Applying information systems within a business 
process requires a good understanding of the expected benefits, 
system requirements as well as of the effects that the process 
change will have on its actors and stakeholders. Integrating 
machine learning based systems (MLS) into a business process 
requires an even broader focus on potentially affected users 
and stakeholders. Leading to changes in the process, but also 
in the user and stakeholder behavior, ethical values are 
directly influenced by the decisions taken during the data 
processing stages within system development. In this paper, a 
scenario of an MLS, a fictional recommender system for food 
delivery, is used to identify potential ethical issues that occur 
during the composition and usage of the artifact. Data centered 
analysis of the system development is applied to identify, which 
ethical values are mostly affected in each data processing stage. 
It is argued that even when the used data for MLS is not 
originated from an individual, and thus is not necessarily 
subject to privacy regulations, ethical analysis and socially-
aware engineering of the information system are still required. 
Suggestions what ethical aspects can be implemented into the 
design of the MLS are derived here based on the presented 
scenario. The effects of MLS application in a business process 
are furthermore briefly outlined for every stage of data 
processing. Using this scenario-based approach allows 
identification of social and technical aspects that can be 
affected by the application of MLS in business context. 
Keywords- socio-technical systems; machine learning based 
systems design; ethical values; ethical analysis; business process. 
I. 
INTRODUCTION 
The challenge of the integration of ethical issues in the 
information systems design has been specifically laid out by 
Levina in [1]. 
The pervasiveness of algorithmic systems in our daily 
lives is stimulating public and research debate about their 
potential effects on the individual behavior and also on the 
society as a whole. Several companies and governmental 
initiatives react to this development by publishing ethical 
principles on how their Information Technology (IT) 
artifacts that involve Machine Learning (ML) components 
are created, leading to the so called “principle proliferation” 
[2]. Evidently, Information Systems Research (ISR) should 
manifest its leading role in pursuing practices for the creation 
of IT artifacts that are not only technically innovative but 
also socially acceptable.  
This paper provides a contribution by presenting and 
discussing the outcomes of the ethical analysis of a 
paradigmatic case of a Machine Learning-based System 
(MLS) application. Here, an MLS is an Information and 
Communication Technology (ICT) that is composed of one 
or more algorithms working together and capsuled into one 
or more executable software components [3]. The ethical 
analysis demonstrates what ethical values are affected the 
most in which data processing stage. These insights allow 
software developers and system architects to focus the 
introduction of socio-technical activities accordingly. The 
results of the applied analysis approach lay the ground for 
theoretical development of a mixed methods approach that is 
focused on ethical reasoning in ISR and engineering of 
socio-technical systems [4]. 
The presumption of this mixed methods approach is, that 
ethical compliance of an IT-system is an integral part of the 
design process, as well as the product use. The linkage to 
ethical questions and the design of an IT artifact can be 
historically established in several ways. First of all, the core 
of the engineering activities, such as software engineering 
and IT systems design, is the solution to the design problem 
[5]. Since there are multiple possibilities to solve a problem, 
(software) engineers weight one alternative against another. 
The decision criteria for the design alternatives can be 
financial restrains, user requirements and functional fit of the 
alternatives. Once the chosen alternative is realized as an 
artifact, it will have good and bad effects. Hence, one 
obvious moral obligation of a (software) engineer in the role 
of the solution creator is to pick a design alternative that does 
not induce harm [5]. Thus, to create an IT system that takes 
into account the effects of its application on the business 
processes, users, as well as the effected parties, theses 
potential effects need to be taken into account in its design 
[4][5]. It is e.g., the case, when digital systems such as a 
recommender or a digital assistant system provide a service 
for its user.  
A service, in the physical world, as well as digital, comes 
with costs that are not only monetary. It entails partial loss of 
autonomy in the realm it is being offered. User accepts the 
service if the assessed amount of the autonomy loss is 
acceptable and thus the user provides consent to this loss by 
agreeing to use the service instead of performing the offered 
function him- or herself. The engagement with the service 
can furthermore be associated by the user with loss of 
autonomy due to opaque processes of result generation. 
Social reluctance of these practices is evident. Only 19% of 
surveyed users of digital services believe that tech companies 
design their services with people’s best interests in mind and 

154
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
47% feel they have no choice but to sign up to services 
despite having concerns [8].  
Identifying and complying to ethical issues in the MLS 
design can thus enable autonomous decisions for the user 
within the interaction with the service. In addition, this 
quality can provide a distinctive feature on the market of IT 
products. 
Following this reasoning, the goal of this research is to 
expand the present literature on potential ethical issues of 
MLS. The structure of the paper follows this reasoning. An 
example scenario is presented in Section V using the data 
process centered ethical analysis [7] described in Section IV 
and requirements of socio-technical system design in 
Sections II and III. Suggestions about how the identified 
ethical issues in Section VI can be integrated into the IT 
system are provided in Section VII. Using the offered 
scenario, the process and supplementary effort to include 
these aspects into the artifact design can be assessed by the 
system designer or business engineer, providing an 
actionable radius to create socially acceptable IT products, as 
well as to lay the ground for future research questions. 
Conclusion and outlook on the future work finish the paper. 
II. 
STATE OF THE ART IN SOCIO-TECHNICAL ASPECTS OF 
RECOMMENDER SYSTEMS 
Socio-technical systems are described via Baxter and 
Sommerville [4] as systems that involve a complex 
interaction 
between 
humans, 
machines 
and 
the 
environmental aspects of the work system. Machine 
learning-based systems incorporate this interaction already in 
their input, i.e., the data from which patterns are derived and 
test data sets for the mathematical models are the result of an 
interaction between a human and a business information 
system. Thus, their implementation into the organizational 
processes has an intermediate effect on the actors on the 
outside and inside of the organization. Specifically, in this 
context, socio-technical considerations are not just a factor 
within the systems development process, but they have to be 
considered at all stages of the development life-cycle.  
For MLS the system development life-cycle includes data 
processing. Data processing is furthermore divided into 
phases of data collection, data processing, model definition, 
model training and calculation of the results. The socio-
technical factors are triggered when the MLS results are 
implemented into a business process, requiring a human 
decision or a decision that concerns human actors. To catch 
these challenges the ALTAI principles were established by 
the European Commission [9] to help evaluate a socially 
aware MLS design. These are: Participation, Transparency, 
Human Autonomy and Auditability. These principles are 
considered here as facilitators for the software design 
approach that focuses on the person affected by the software 
result rather than the direct user of the software.  
Identifying ethical issues that might occur during the 
system design allows conclusions on the ethical values that 
are affected in different stages of system design. This activity 
is considered here the first step of the incorporation of these 
values into the design of a socially-aware information 
system. Hence, a scenario for an MLS, a recommendation 
application, is described Section V and used to demonstrate 
an approach to identifying ethical issues. 
III. 
OVERVIEW OF THE STATE OF THE ART OF ETHICAL 
ANALYSIS APPROACHES FOR RECOMMENDER SYSTEMS 
Ethical issues in the context of IT-artifacts have gained 
increasing attention in research over the last decade. 
Paraschakis [10][11] explores e-commerce recommender 
applications and suggests five ethically problematic areas: 
user profiling, data publishing, algorithms design, user 
interface design and online experimentations, i.e., exposing 
selected groups of users to specific features before making 
them available for everybody. Milano et al. [12] conduct an 
exhaustive literature review of the research on recommender 
systems and their ethical aspects and identify six areas of 
ethical concern: ethical content, i.e., content that is or can be 
filtered according to societal norms; privacy as one of the 
primary challenges of a recommender system; autonomy and 
personal identity, opacity, i.e., lack of explaining how the 
recommendations are generated; fairness, i.e., the ability to 
not 
reflect 
social 
biases; 
polarization 
and 
social 
manipulability by insulating users from different viewpoints 
or specifically promoting one-sided content. Milano et al. 
[12] also show that the recommender systems are designed 
with the user in mind, neglecting the interests of the variety 
of other stakeholders, i.e., interest groups that are being 
directly or indirectly affected by the recommendation. 
Polonioli [13] presents an analysis of the most pressing 
ethical challenges posed by recommender systems in the 
context of scientific research. He identifies the potential of 
these systems to isolate and insulate scholars in information 
bubbles. Also, popularity biases are identified as an ethical 
challenge potentially leading to a winner-takes-all scenario 
and reinforcing discrepancies in recognition. Karpati et al. 
[14] analyse food recommendation systems and identify 
several ethically questionable practices. They name the 
commitment to already given preferences and thus to the 
values of the designers as a contradiction to the potential for 
ethical content. Privacy, autonomy and personal identity that 
the authors identify as potentially vulnerable and hence 
suggest need to be realized via an informed concern and a 
disclosure about the business model used. Opacity about the 
origin of the recommendations as well as of the criteria and 
algorithms used to generate the recommendations. Fairness, 
polarization and social manipulability as well as robustness 
of the system complete the list of identified ethical issues for 
a food recommender.  
These 
approaches 
discuss 
ethical 
impacts 
of 
recommender systems from the perspective of the receivers 
of the recommendations. Milano et al. [12] argue that the 
social effects such as manipulability and personal autonomy 
of the user are hard to address, as their definitions are 
qualitative 
and 
require 
the 
implementation 
of 
the 
recommender system in the context they operate, while 
Karpati et al. [14] offer a multi-stakeholder approach to 
address these issues. The data process-centered approach to 
analyzing ethical issues suggested by Levina [15] identifies 
the decision points during the MLS development, while 
advocating the inclusion of a laboratory phase into the 

155
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
system design to assess the potential consequences (see also 
[16]).  
This research applies a combination of data processing 
and ethical analysis in the attempt to identify how or whether 
the identified threads to ethical values that can be realized 
and mitigated in an MLS design. 
IV. 
ANALYZING ETHICAL ISSUES WITHIN THE DATA 
PROCESSING 
The general process for analyzing ethical issues within 
the design of machine learning- based systems has already 
been roughly outlined in [15]. Here the process is explained 
in detail and its exemplary application using a scenario of a 
food recommendation application is presented in Section V.  
Fig. 1 shows the stages of data processing according to 
[17] as well as the aspects that are relevant for discovering 
potential ethical issues within this specific stage. Although, 
the Apply stage is not an integral part of the data processing 
pipeline, the effects of the application of the MLS on user 
behavior are important for its design and are thus included in 
this analysis. Furthermore, the ethical analysis differentiates 
between the MLS-user, i.e., a person using the MLS directly 
within a business process, and an MLS-affected user, i.e., a 
person or a stakeholder that is affected by the results of 
application of the MLS within a process. 
 
 
 
Figure 1.  Data processing and relevant aspects for ethical design [18] 
In the Sense phase the data needs to be collected, pre-
processed and stored, i.e., detected for further application. 
The data features that are relevant to the business problem 
need to be selected. In the Transform phase data analysis 
methods, i.e., the mathematical model(s) used in the MLS, 
are in focus. Ethical issues can furthermore arise along the 
aspects of data manipulation, such as defining the test dataset 
and its features, as well as the entire software system in 
which the trained ML model is integrated and that has to be 
integrated into the business process to provide an added 
value. In the Act phase the integrated MLS in enacted within 
a business process to provide support for the selected tasks, 
i.e., to generate business value. To do so, the software 
system as a whole needs to adhere to the user’s expectations 
towards usability, supported functions and expected output. 
The Apply phase is not included in the data processing 
pipeline. Nevertheless, to be able to analyze the potential 
effects of MLS applications, this phase needs to be included 
to reflect the view of the affected party, i.e., the external 
party that receives the results of the MLS application at the 
end of the (business) process.  
Hence, this data-centered approach reflects different 
viewpoints on the data processing and use. While the first 
two phases, Sense and Transform, focus on the data and their 
sources, the last two phases are governed by the values of the 
(business) user and the affected user respectively. Thus, even 
when the input data for the MLS is machine-generated, the 
data processing phases require a socio-ethical approach to 
the requirements analysis and implementation.  
In the following subsections the potential aspects that 
may arise in each phase are presented in more detail and 
structured along the three sub-categories: ethical aspects, 
technical aspects and existing methods of risk mitigation for 
raised technical or ethical questions (see Figures 2-5). While 
the ethical aspects address value-based issues within the data 
processing pipeline, technical issues address the technical 
means and tools that exist and can lead to the raise of ethical 
issues. 
A. Sense Phase and potential ethical issues 
In the sense phase of the data processing pipeline it needs 
to be assured that the data have been collected with the 
informed consent and voluntariness of the data subject. 
Hence, Fig. 2 shows the sub-division of the phase into the 
individual categories that can also be extended to 
accommodate further potential ethical issues.  
The ethical value as defined by the European 
Commission in its ALTAI checklist [9] that is affected the 
most in the Sense phase, is the value of privacy and data 
governance. Being an issue that is subject to legislation and 
public debate, a research direction emerges in the 
philosophical community calling for empirical investigation 
of the effects of data collection under the term of ethics of 
influence [19]. It aims at further investigating of ethical 
questions in this data processing stage. 
Issues associated with data collection have already been 
addressed in the legal form such as European GDPR 
legislation. Thus, legal compliance is part of the risk 
mitigation activities that can be taken by the enterprise 
applying the MLS. Risk mitigation activities may help to 
catch ethical issues that occur in the context of appropriation 
and necessity of data collection. They require, e.g., informed 
consent of the user to provide interaction or behavioral data. 
Informed consent also includes the statement of the purpose 
of data collection implying an opt-in function for data 
collection. What data is being collected is normally 
described in the terms and conditions document of the MLS. 
Nevertheless, data-based devices that can contain sensors 
and processing units might collect more data that the terms 
and conditions statement declare. These data can be 
considered a by-product of the service offered, but 
nevertheless, their collection and potential distribution need 
to be kept transparent for the future user and affected users. 

156
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 2.  Potential ethical issues in the select stage 
The technical realization of the data collection can thus 
be the origin of ethical issues. Such as the use of dark 
patterns in system design [20] is attempted at keeping the 
user engaged with the system are often aimed at collecting 
more data. The so called smart environments, such as the 
Internet of Things, are also potential sources for data 
collection with the focus on specific user behavior [21]. 
Tracking technologies, such as health tracker or internet 
cookies, are also technical mechanisms aimed at collecting 
behavioral data that might exceed the amount of the data 
required for the original purpose. 
B. Transform Phase and potential ethical issues 
In the Transform phase, technical aspects of model 
building and training are put into focus, while the ethical 
values that are most influenced in this phase are the values of 
transparency of the technical process as well as the societal 
and environmental well-being as described in the ALTAI 
checklist [9].  
The model construction, i.e., the applied algorithms for 
pattern recognition, as well as the definition of the thresholds 
for the MLS results are decision points in the development 
process that carry potential for ethical issues. Depending on 
the choice of the algorithms, e.g., the energy efficiency of the 
performed computation is affected. Using pre-trained models 
to solve frequently occurring business problems, reduces the 
resources needed to train the model on the one hand, but on 
the other hand, this technique has also the potential to lead to 
homogenous and generalized results [22], i.e., potentially 
aggravating the ethical issues associated with the value of 
non-discrimination and fairness. The selection of the 
computational algorithm is also defined by the expected 
quality of the results [23]. Hence, the choice is partly made 
based on the expected quality metrics such as accuracy of the 
calculates prediction or recommendation by the MLS. 
Pursuing better accuracy can potentially mean choosing a 
more resource intensive mathematical model. Hence, this 
mathematical problem can directly relate to ethical issues. 
 
 
Figure 3.  Potential ethical issues in the transform stage 
Furthermore, the definition of the thresholds for accuracy 
or correctness require further ethical decisions [24], e.g., in 
favor of reduction of false negative or false positive results, 
depending on the problem at hand. To mitigate these issues, 
pre-trained models can be used that have already been 
applied on a similar problem, or industry standards can be 
addressed. Using industry standards bears nevertheless the 
negative potential, that the same thresholds would be applied 
in different use cases, leading to de facto standard values that 
might in the future lose their semantic correctness. Further 
potential risk mitigation measures might include meticulous 
description of the data set used to train the pre-trained model, 
description of model thresholds and parameters as well as 
stakeholders involved. Having this description may allow the 
software developers and model engineers to make an 
informed decision about the fitness of the model to the 
problem and data population at hand. 
C. Act Phase and potential ethical issues 
The Act phase focuses on the business process that is 
supported using the MLS in question. The results generated 
by the MLS and the usability of the MLS need thus to adhere 
to the expectations and requirements of its users. Hence, 
human-computer-interaction and usability aspects as well as 

157
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the control concepts such as human-in-the-loop are put in 
focus of the ethical analysis here. Human agency and 
oversight as well as communication are the values that are 
mostly affected in this phase. These values should guide the 
result integration from the social aspect as well as the 
technical system integration as the technical aspect of the 
MLS.  
The value of human agency and oversight is also 
addressed by the handling and interpretation of the MLS 
results for the following process tasks. The information on 
the meaning of the calculated results in the context at hand as 
well as their interpretation is crucial for the meaningful 
application and generation of true added value of the system. 
  
 
Figure 4.  Potential ethical issues in the act stage 
Failure to interpret the results might lead, e.g., to false 
decisions and thus negative consequences for the actors and 
stakeholders involved in the process. Also occurrence of 
false positive or negative results, their consequences for the 
actors involved as well as handling these errors should be 
included into the business process. Hence, a thorough user 
training for the process actors involved in the process using 
MLS is an essential tool for risk mitigation in the act as well 
as in the apply phase. 
D. Apply Phase and potential ethical issues 
While the apply phase does not belong to the technical 
data processing, it is involved in the ethical analysis of 
handling data in business context. The values accountability, 
communication and human agency and oversight as 
described in the ALTAI checklist [9] are mostly affected 
here, when the MLS application is realized.  
The application of MLS in a business process requires 
good knowledge of the process and of the consequences that 
should be addressed, e.g., in user trainings. But it may also 
lead to the loss of previously present skills for the process 
actors such as moral [25] or decisional [7] de- skilling. 
To mitigate these threads to human autonomy, control, 
expertise, and behavioral change [26] guidelines for MLS 
development can be applied as well as scheduled audits of 
the process and the effects on the process performance 
before and after MLS application can be helpful. Also, 
changes in the process environment should be monitored 
using, e.g., performance indicators from the domain of Green 
BPM [27]. 
 
 
 
Figure 5.  Potential ethical issues in the apply stage 
V. 
AN EXAMPLE APPLICATION: FOODAPP- THE 
APPLICATION FOR MEAL DELIVERY 
The FoodApp is a fictional application based on a three-
sided digital platform that is implemented as a mobile app. It 
is a branch of a fictional large company Acima that offers 
on-demand individual transportation provided by freelancing 
drivers. To further explore the transportation market, Acima 
started FoodApp, a fast growing food delivery platform 
connecting the customer, restaurant owner and the delivery 
partner. It allows the customer to choose from a large 
database of participating restaurants and order a menu to be 
delivered to the customer’s address via delivery partners. 
The eater can choose a specific delivery partner based on the 
ratings of the currently available partners. The payment 
process is integrated into the platform as is the real-time 
tracing of the order delivery.  
The platform business goal is the “fast and easy food 
delivery whenever, wherever”. To achieve this goal a MLS, 
a recommender system, is used to provide the best food 
suggestions for the user in accordance to the indicated 
preferences and the order history. The business performance 
indicators for the FoodApp include the return and re-order 
customer rates, as well as customer number growth rates. 
The implemented ML-model is thus optimized to drive 
user’s re-ordering on the platform.  
To use the FoodApp the customer downloads it on the 
mobile device granting permissions for it to access the 
location of the device. Further, a profile including 
information on delivery address, name, e-mail and phone 
number is required. Payment methods and login to the 
payment 
provider 
is 
further 
required. 
No 
manual 
modifications concerning the data collection by the app is 
possible. Then, the meal preferences such as preferred 
cuisine or menu item need to be indicated or a meal can be 
chosen from the provided suggestions. The first suggestions 
are based on the historical frequency of the orders made 
within the community in the area of eater’s location. A rating 

158
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
system for restaurant and delivery partner performance is 
implemented.  
The platform gains revenues from the customer via 
convenience charge, fixed commissions and marketing feeds 
from the restaurants, while providing the assignments and 
the payment to the delivery partners, as well as the technical 
infrastructure for the platform participants. The application is 
a key driver of Acima’s revenue and is a fast- growing meal 
delivery service with over 15 million users worldwide. 
Additionally, the platform includes an app for delivery 
partners that provides the possibility to accept or decline a 
specific delivery job, monitor the revenues, rate the 
restaurant’s delivery process, as well as provide directions to 
the restaurant and to the eater. 
VI. 
IDENTIFYING ETHICAL ISSUES USING THE ACENARIO-
BASED APPROACH 
To identify ethical issues in the MLS used by FoodApp, 
data process-oriented analysis [15] has been conducted. 
Since the core component of the FoodApp MLS converts 
(user) data into a food recommendation, ethical issues are 
explored using the data-centered ethical analysis approach 
described in Section IV. The ethical analysis looks at the 
data process within the system’s design and identifies some 
of the relevant aspects, where ethical values are affected and 
ethical questions arise influencing the system design. To 
identify potential ethical issues, questions along the data-
processing stages are asked, as suggested by [15]. 
First potential questions for the first stage, sense, are 
structured along the sub-stages: collect, detect and select. For 
the act of collection, some of the central questions are:  
• 
Was the user aware of the mode or amount or 
content or context of data collection?  
• 
Was the data collection conducted with sufficient 
legal compliance?  
• 
Were any dark patterns [20] involved in the 
obtainment of the data? 
• 
Are the data collected necessary for the MLS to 
function according to its purpose? 
• 
Are there opt-in possibilities for different types of 
data collection? 
FoodApp’s business goal is to engage the user in the re-
ordering of the food via FoodApps’s digital platform. The 
user interacts with the app aiming for a comfortable 
provision of the favorite food in an efficient way. Therefore, 
as described in Section I, the user is inclined to give up some 
autonomy within this process. Nevertheless, in the digital 
realm the user is often not aware of what elements of his/her 
autonomy are jeopardized when the digital service, here food 
selection and ordering via a digital platform, is created 
[12][13]. E.g., in the FoodApp the location information of 
the device is transferred per default to the platform. Also the 
app has default access to the microphone and camera of the 
device. While the user can still change these settings, s/he is 
often unaware of the default access requirements of the app 
or does not know what access is needed for the app to 
function. Thus, the questions that arise in the collect sub-
phase should address the actual data collection and their 
relation to the function of the service provided by the app. 
Also the questions on whether the data are stored 
permanently at the platform or have an expiration date are 
crucial in the detect sub-phase. In the select sub-phase, the 
questions about:  
• 
data quality  
• 
data sufficiency 
• 
data sources 
• 
representativeness for the solution of the given 
problem  
will have to be addressed. Since data are the fundament for 
the further model building, their amount, quality, focus in 
relation to the problem solution (here: providing a food 
recommendation) as well as the rightfulness of its collection 
are essential for a mathematically good model design, 
representative training dataset as well as a socially-aware 
information system.  
Additionally, the amount and sources of the collected 
data are mostly defined by the business model. As FoodApp 
would like their users to return to the app, it will need among 
other factors, very good recommendation results as well as a 
frictionless ordering process together with a reliable problem 
handling mechanisms to fulfill basic customer expectations 
[14]. The business model provides essential guidelines for 
the sense and transformation phases, including the type of 
information system that can be used to support the business 
goals. The first requirement, i.e., very good recommendation 
results in terms of user’s preferences, can be realized using a 
recommendation algorithm based on the collected data from 
the user as well as from the users with similar preferences or 
history on the platform [14]. Since the user activity data 
might provide additional patterns for the recommendation, it 
also provides a potential reason to keep the user engaged on 
the app for the longest possible time, which might involve 
the use of dark patterns in the app design [20].  
Beside from the user data, FoodApp database should 
include data on the restaurants available for ordering and 
delivery through the platform. Addressing the restaurants is 
part of the business model and might also be part of the 
business focus, as restaurants can be included on the 
platform according to specific criteria, e.g., reviews on other 
platforms, personal preferences, number of years in business, 
etc. leading to a potential pre-selection of available food 
choice on the platform. To avoid subjectivity in this dataset, 
a neutral source for the identification of the restaurants and 
confirmation of their availability should be considered. 
Additionally, the delivery network of partners that will pick 
up food at the restaurants and deliver it to the customer’s 
door need to be established and equipped with the means to 
be contacted, payed and managed by the platform.  
Hence, FoodApp needs to establish an ecosystem, similar 
to a classic supply chain, to be able to fulfill its business goal 
or even to be able to operate according to its business model. 
Building up such an ecosystem as well as the potential to 
manage the orders for delivery, provides Acima as a digital 
platform with a specific power over the delivery partners as 
well as the restaurants that can have extensional effects on 
the partners involved in the ecosystem as well as the bigger 
area of stakeholders. See [30] for the discussion of potential 

159
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
ethical issues emerging from the digital platform as an 
ecosystem.  
FoodApp’s user profile provides the information that is, 
among others, needed for the algorithms in the MLS to 
derive food recommendations. The user does not have any 
information about the exact purpose of the provided datasets, 
the data lifecycle, nor about who has access to the (possibly) 
un-anonymized profile or historical data and about the data 
state timeline, i.e., when the data are transferred or deleted. 
These aspects can be categorized as “transparency issues”, 
since the user does not have the information about 
FoodApp’s processes s/he might need or would like to have.  
The FoodApp is designed in a way that on the home 
screen the most frequent orders for eater’s automatically 
identified location are presented. The user can filter the 
suggestions using the provided filter categories. These 
categories, defined by the MLS-engineers and designers, 
include cuisine and menu item names, as well as the ratings 
of the accordant restaurants. In future interactions with the 
FoodApp its home screen offers the meals and food items 
that are most frequently ordered by the eater or users that 
were identified to have a similar ordering behavior, thus 
nudging the eater to order the same or similar kind of food 
[31].  
All these features and filtering categories were created as 
a part of the data transform phase, i.e., the model creation 
and training phase. The first and most significant question in 
the beginning of the transformation phase is: 
• 
Is the use of machine learning techniques, especially 
the resource hungry ones such as the neural 
networks, essential for the solving of the business 
problem at hand?  
The FoodApp has based its business model on the data-
based provision of food recommendations and the 
forwarding of the recommendations to the restaurants and 
delivery partners. Thus, being data-based, these business 
questions would require the use of data analysis tools, 
although the added value of the neuronal networks for the 
recommendations depends on the quality of data and the 
accuracy thresholds defined by the product designers.  
The model quality is in the center of the ethical inquiry in 
the transformation phase. The set thresholds define 
mathematical methods, e.g., neural networks vs., e.g., 
support vector machines, and thus the resources needed to 
train the model as well as to generate the recommendation. 
The transform phase does not only include the training and 
optimization of the models used for the recommendation, it 
also considers the inclusion of the ML-models into the 
information systems context.  
While definition of food categories as well as the 
selection of the included cuisines and restaurants is part of 
the sense phase and especially the select sub-phase, 
questions in the transform phase focus on the mathematical 
transformation of these selected details. Inclusion of, e.g., 
nudging techniques is also part of the sense phase and the 
collect sub-phase, but it is strongly defined by the business 
model. Thus, for the transform phase ethical questions could 
be among others: 
• 
What categories of the collected data are included in 
the statistical model? 
• 
What is the category that the model is being 
optimized for? 
• 
What are the quality criteria for the results derived 
by the MLS? 
• 
What are the thresholds for the quality criteria? 
In the act phase of data processing, the MLS is integrated 
into the business process such as its calculated results are 
being used to create business value and trigger the following 
business step. For Acima, the value is created when the food 
delivery order is completed in the FoodApp. Hence, the 
ordering process is organized in a way that no extended 
explications or additional information are given so that the 
user does not have to choose, decide or react during the 
interaction process. This design allows a fast phase-out 
between opening the FoodApp and ordering the food. This 
effect can be expected to contribute to user satisfaction and 
thus re-visiting the platform for the next order.  
The process efficiency offered by the FoodApp is also 
built on the lack of decision possibilities and a limited items 
selection that is based on the historic and profile preferences 
for the user. Additionally, the gained comfort for the user in 
terms of food selection and delivery has implications on the 
ecosystem of the FoodApp. The restaurant partners will be 
faced with the increased amount of reviews from the delivery 
customers, potentially forcing them to concentrate on robust 
packaging to ensure the sound condition of the meal for 
delivery. More or more robust packaging means more 
damage to the environment but potentially better ratings from 
the FoodApp users [32].  
Furthermore, the food recommendations based on 
historic and similar orders might lead to homogenization of 
the food offered and prepared in the participating restaurants, 
as menu items that are ordered less often might not be 
prepared by the restaurants anymore, potentially leading to 
the decreasing of skills of the cooking staff. The individual 
delivery of the food orders requires reliable and efficient 
delivery partners. Acima relies here on its network of drivers 
for personal transportation that are also incentivized to 
transport food orders via reward programs. This efficient and 
effortless 
process 
of 
ordering 
food 
for 
individual 
consumption can and does cause significant environmental 
damage in terms of air pollution through traffic and waste 
[32].  
Further effects on the social environment can also occur. 
The eater rates the restaurant on the food quality and the 
delivery partner on the quality of the delivery. The rating is 
based on eaters’ satisfaction with the end result, whereat the 
traffic situation and other external effects of the 
recommendation 
process 
are 
not 
considered. 
This 
relationship pattern causes societal effects that are visible in 
the traffic situation, environmental damages as well as 
reduction 
of 
labor 
costs 
and 
conditions 
[34][35]. 
Furthermore, usage of an MLS is probable to change user’s 
behavior [35]. The questions that can be asked in this 
scenario to identify potential ethical issues are: 

160
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
• 
Is it clear for the user that his/her choice of delivery 
partner would lead to potential loss of jobs for other 
delivery partners? 
• 
Is it clear for the user what impact her or his order 
deliver has on traffic or environmental indicators? 
• 
Is it clear for the user what consequences his or her 
ratings of the restaurant will have on the restaurant? 
• 
Is it clear for the user what effects his or her order 
will have on his or her recommendations profile? 
• 
Is it clear for the user what are the basics for the 
recommendations of food/ cuisine/ delivery partner 
or restaurant within the application? 
• 
Is it possible for the user to change or manage the 
filtering categories in the app? 
• 
Is it possible for the user to change the profile? 
In the apply phase, the effects of the integrated MLS are 
in focus. Here the consequences of the provided food 
recommendations based on user’s historic behavior could 
lead to decisional de-skilling [7] or in this case potentially 
homogeneous food preferences for the eater. Such an 
automated decision support can also potentially result in the 
de-skilling of the evaluation abilities [25] for the eater in the 
given context. 
The apply phase demands for user training (see Fig. 5) or 
to a smaller degree an explanation of the mechanisms behind 
the results of the application. So that the model specifications 
as well as the usability and settings questions can be 
addressed. User training is here mostly out of scope, since it 
needs to be implemented as an inherent feature of the 
FoodApp and would affect the efficiency of the ordering 
process.  
Rating of the delivery partners results in an increasing 
number of orders for high ranked drivers and in a reduction 
of delivery orders for the worse ranked drivers. Hence 
promoting the reviews into the main factor for job 
acquisition, and thus income, for the drivers. This type of job 
market is known as the gig economy [36]. It provides income 
potential for the workers while creating an interdependency 
between the platform customer and the gig worker. This 
relation seems to remain unclear for the platform customer 
and is often debated by the platform owners [18][19]. 
Consequently, the OECD stated in 2016 that digital 
platforms need social values to be reflected in the platform 
governance [39].  
VII. INTEGRATING THE ETHICAL ISSUES INTO THE SYSTEM 
DESIGN 
Based on the ethical analysis of the previous section, 
Table 1 provides a synthesis of the identified ethical issues 
and the hereby affected ethical values as defined by the 
ALTAI checklist. Also, an example how the identified issue 
can be integrated into the IT system is provided.  
The recommendations are structured along the following 
levels: business level, User Interface (UI) and system level. 
While business level addresses the definition of the business 
model and business goals, the system level considers the 
systems design, including the design of the algorithms. The 
UI aspects can be used to balance the business goal, i.e., 
eater’s re-ordering behaviour, and the eater’s interaction 
expectations with the digital platform.  
This paradigmatic nature allows an insight into the 
application of the ethical analysis during the MLS design. A 
more detailed analysis would be needed to provide specific 
insights on the algorithm level. 
TABLE I.  
ETHICAL ISSUES OF THE FOODAPP AND SUGGESTIONS FOR 
THEIR IMPLEMENTATION 
Ethical issues 
Affected 
value(s) 
Suggestion for 
implementation 
No explanation on 
the  data storage 
Communicati
on; 
Data 
governance 
System/UI: Include clear and 
transparent information for the 
user about the data storage, in 
e.g., in individual contracts or 
in 
general 
terms 
and 
conditions.  
System: Develop a concept for 
deletion routines if the purpose 
of the data processing is no 
longer applicable. Accordant 
selection 
of 
the 
storage 
location. 
No explanation on 
the purpose of data 
collection 
Communicati
on, 
Data 
governance 
UI: Provide information, e.g., 
via mouse hover, about the 
purpose of the data collected in 
the 
field, 
as 
concrete 
as 
possible 
System: To collect data that are 
not essential for the provision 
of the service, provide opt-in 
options by asking the user 
directly, e.g., “Would you like 
to help us to improve our 
service by providing your 
automated location data?” 
Lack of an opt-out 
for specific data 
type collection 
Privacy, 
Accountabilit
y 
System/UI: Privacy friendly 
default settings, e.g., opt-in 
function for every data item 
collected 
instead 
of 
the 
implementation 
of 
the 
“required” fields. 
Lack 
of 
the 
possibility 
to 
manually adjust the 
collected data 
Human 
agency 
and 
oversight 
System: Possibility to add or 
correct data manually, e.g., to 
type the address for delivery. 
Establish a reporting system 
for customers if they wish to 
have data corrected. 
The 
fact 
that 
stakeholders 
have 
access 
to 
the 
collected data 
by 
FoodApp 
Privacy 
and 
Data 
govvernance, 
Communicati
on 
Business: No data exchange 
between 
other 
stakeholders 
without agreements; user can 
be asked if s/he wants specific 
data to be shared for a specific 
purpose 
with 
the 
specific 
partner (a reimbursement could 
be offered) 
 
Implement an accordant opt-in 
or rewarding mechanisms for 
the user in the settings. 

161
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Data life cycle is 
unclear for the user 
Communicati
on, 
Accountability 
System: Describe the data life-
cycle to the user, e.g., on the 
FAQ page. 
 
Integrate an automated deletion 
routines after the needed data 
are collected; inform the user 
about the routine in the FAQs, 
provide opt-ins for further data 
collection 
if 
needed; 
implement a reward system for 
additional data collection. 
Data state: Is the 
data 
anonymized 
before the analysis? 
Privacy, 
Accountabilit
y 
System: Make clear in FAQ 
that 
data 
is 
processed 
anonymously. 
If 
this 
is 
fulfilled, the GDPR does not 
apply for the processing.  
Implement 
anonymization 
process via e.g.,  distributed 
data bases. If anonymization is 
not possible, secure data by 
pseudonymisation 
and 
encryption. 
Lack of feedback 
from stakeholders. 
Communicati
on, 
Human 
Agency 
and 
Oversight  
System/business: 
Provide 
a 
transparent feedback system 
from and to every actor in the 
ecosystem; 
provide 
an 
explanation of the ratings and 
their effects for the actors on 
the FAQ. Eliminate one-sided 
rating mechanisms. 
Lack of tracing of 
(e.g.,societal) 
changes induced by 
the app. 
Transparency, 
Accountabilit
y, 
Societal 
and 
Environmenta
l well-being 
Business: 
Schedule 
surveys 
regularly 
with 
eaters, 
restaurants 
and 
delivery 
partners to assess the changes 
induced in those ecosystems; 
perform simulations to define 
potential changes to the traffic 
in the delivery area; establish 
contact to the traffic agency; 
include 
actionable 
changes 
suggestions, 
e.g., 
provide 
contact 
to 
a 
sustainable 
packaging producer for the 
restaurant partners; make these 
actions 
transparent 
on 
the 
FAQ. 
Optimizing 
the 
algorithm for user 
re-ordering 
Privacy 
and 
Data 
Governance, 
Communicati
on 
System/Business: Include other 
stakeholders 
such 
as 
restaurants, delivery partners 
and the environmental effects 
with similar weights into the 
recommendation 
algorithm; 
evaluate the systems on a 
regular basis. 
UI: 
Provide 
different 
recommendations foci for the 
user, e.g., focus on preferences, 
focus 
on 
restaurant 
convenience, etc. 
Lack of a test phase 
about the effects of 
app usage on the 
society 
Accountabilit
y 
Business: Include a laboratory 
phase, where the app is tested 
by the users and stakeholders 
with evaluation of the UI, UX, 
legal and ethical aspects plus 
relevant simulations on the 
ecosystem 
e.g., 
food 
and 
restaurant landscapes before 
release. 
Definition 
of 
the 
parameters for food 
selection 
by 
the 
engineers 
Accountabilit
y, Privacy and 
Data 
governance, 
Communicati
o, 
Transparency  
Business/system: 
Include 
a 
customer survey on which 
categories they would like to 
have; change categories or 
filters for sorting and extend 
these cate-gories regularly. 
Live 
roll-out 
of 
changes to the MLS, 
i.e.,online 
experimentation 
Accountabilit
y 
Business: 
Perform 
changes 
roll-out during the laboratory 
phase and simu-lation; when 
approved, 
roll-out 
for 
the 
whole community. 
Usage 
of 
power 
resources to train the 
(modifications 
to) 
ML-model 
recommendations 
are 
based 
on 
a 
selection of pre-set 
parameters 
Societal 
and 
Environmenta
l well-being 
Business: Change and train the 
model as rarely as possible, 
e.g., once a year. 
UI: Provide information why 
the 
recommendation 
was 
generated and what impact the 
change of the parameters (e.g., 
delivery time) would have on 
the results;  
Provide possibilities to have 
parameters 
adjusted 
or 
included into the list. 
 
Lack 
of 
understanding of the 
rating mechanism 
Communicati
on, 
Transparency, 
Human 
agency 
and 
oversight 
UI: Provide an explanation of 
the 
rating 
mechanism 
containing 
a 
relative 
comparison to other ratings, as 
well as potential consequences 
(e.g., in a dialog: “Your rating 
will decrease the number of 
suggested 
orders 
to 
this 
delivery partner by 0.2% per 
cent”). 
Tendency 
of 
the 
user to accept the 
MLS suggestions 
Communicati
on, 
Accountabilit
y 
UI: Include a “surprise me” 
function, where a product is 
suggested to the eater that does 
not adhere to his/her top 
preferences; add a reminder 
function: “you have already 
ordered this meal n times this 
month. Would you like to try Y 
(second 
choice) 
today 
instead?”.  
System: Perform an assessment 
on how ML might impact user 
behaviour and present the 
results on the website. 
Effects on the eco-
system of the app 
are not clear for the 
user 
Societal 
and 
Environmenta
l 
well-being, 
Communicati
on 
Business: Make the results of 
the conducted surveys and 
traffic analysis accessible to 
the users on the website. 
System: Carry out an impact 
assessment on the rights of 
users and also on those of the 
stakeholders.  
Individual 
food 
delivery 
Human 
Agency 
and 
Oversight  
System: Include environmental 
concerns into the algorithm 
evaluation;  
Business: Provide rewards for 
environmentally 
friendly 
behaviour 
of 
the 
partners 
(using e-vehicles, e.g., or using 
environmentally 
friendly 
packaging). 

162
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Recommendations 
presentation 
to 
optimize 
the 
business goal 
Accountability
, 
Transparency 
UI: Change the UI to be more 
intuitive for the user with the 
goal of finding favourite food 
selection. 
 
The suggestions provided in Table 1 are centred on 
mainly two aspects: providing information about every data 
element collected by the FoodApp, i.e., the facet of 
transparency, and establishing a reward system for the user 
in return to providing data to the company, i.e., a reward. 
The implementation of a reward system would implicitly 
make the data life-cycle more transparent for the user, as 
well as provide the user with more autonomy within the 
engagement with the service. It would also help the user to 
understand that the data is a resource that is traded and thus 
has a value. 
Identified issues that go beyond the business processes 
might be subject to the interpretation of the regulation or the 
business ethics. Furthermore, due to the context of the 
example, some identified ethical aspects are due to the 
example being positioned in the platform economy and 
therefore are not specific for every MLS. Nevertheless, 
bigger negative effects such as the effects on the 
environment or the society are part of the social awareness 
and responsibility that are not (and maybe should not be) 
regulated, but can be supported by socially acceptable IT 
artefacts. 
Therefore, the term of socially acceptable IT has been 
introduced in [1] to describe a system that considers and 
integrates ethical requirements into its design. The added 
effort but also the value of the implementation of the 
suggestions of the ethical considerations in Table 1 could 
lead to socially acceptable IT products and thus a realization 
of a socio-technical IT systems. To ensure the remaining and 
homogeneous quality adherence, inter-company assessment 
mechanisms, i.e., ethical quality audits, could be put in place. 
VIII. CONCLUSION 
Here a scenario of a fictional food ordering platform that 
uses a MLS for item recommendations was used to perform 
an ethical analysis of an MLS. This scenario was chosen as a 
realisation of a socio-technical system that incorporates 
system designers, users and stakeholders affected by the 
system design and process implementation. 
The results showed that users of digital services need to 
be integrated into the design of a socio-technical system as 
they may have expectations and values that rely on the 
ethical awareness of the company and thus need to be 
implemented into the workflow. The examples of how to 
address these issues demonstrated that changes in the UI, 
system design but also in the business model can be 
realistically made to accommodate these challenges. Hence, 
designing socially acceptable socio-technical IT systems can 
be a chance to find a niche on the growing and competitive 
market of consumer-oriented digital services.  
Although, the provided approach needs validation and 
verification in a rea-life environment, it can already be used 
by the designers and architects of information systems, 
business developers considering a data-based business 
model, as well as ISR scientists as it shows how ethical 
aspects can be incorporated into the context of IT design.  
Therefore, future work will aim at establishing the 
criteria for the definition of the quality requirements for the 
social acceptable IT, evaluation of the suggested measures, 
as well as developing methods for the assessment of the 
effort of their implementation. 
REFERENCES 
[1] O. Levina, “Towards Implementation of Ethical Issues into 
the Recommender Systems Design,” in ICCGI 2021, The 
Sixteenth International Multi-Conference on Computing in the 
Global Information Technology, 2021, pp. 6–11, [Online]. 
Available: 
http://thinkmind.org/index.php?view=article&articleid=iccgi_2
021_1_20_18002. 
[2] L. Floridi and M. Taddeo, “What is data ethics?,” 
Philosophical 
Transactions 
of 
the 
Royal 
Society 
A: 
Mathematical, Physical and Engineering Sciences, vol. 374, no. 
2083. 
The 
Royal 
Society, 
Dec. 
28, 
2016, 
doi: 
10.1098/rsta.2016.0360. 
[3] Comission on data ethics: "An assessment of the comission 
on the data ethics" (in German: Datenethikkommission, 
“Gutachten 
der 
Datenethikkommission,”), 
https://www.bmi.bund.de/SharedDocs/downloads/DE/publikati
onen/themen/it-digitalpolitik/gutachten-
datenethikkommission.pdf?__blob=publicationFile&v=4 
(Accessed, July 12 2021), 2018. 
[4] G. Baxter and I. Sommerville, “Socio-technical systems: 
From design methods to systems engineering,” Interact. 
Comput., 
vol. 
23, 
no. 
1, 
pp. 
4–17, 
2011, 
doi: 
10.1016/j.intcom.2010.07.003. 
[5] W. 
L. 
Robison, 
Ethics 
Within 
Engineering: 
An 
Introduction. Bloomsbury Academic, 2016. 
[6] V. Dignum, “Responsible Artificial Intelligence: Ethical 
Thinking by and about AI,” 2019. Accessed: Oct. 07, 2019. 
[Online]. 
Available: 
https://icps.gwu.edu/sites/g/files/zaxdzs1736/f/downloads/Virgi
nia%20Dignum_%20Responsible%20Artificial%20Intelligence
%20(1).pdf. 
[7] L. Floridi and M. Taddeo, “What is data ethics?,” Philos. 
Trans. A. Math. Phys. Eng. Sci., vol. 374, no. 2083, 2016, doi: 
10.1098/rsta.2016.0360. 
[8] Doteveryone, “People, Power and Technology: The 2020 
Digital Attitudes Report,” 2020. Accessed: May 13, 2020. 
[Online]. 
Available: 
https://www.doteveryone.org.uk/2020/05/people-power-and-
technology-the-2020-digital-attitudes-report/. 
[9] European Commission, “Assessment List for Trustworthy 
Artificial Intelligence (ALTAI) for self-assessment | Shaping 
Europe’s digital future,” 2020. https://ec.europa.eu/digital-
single-market/en/news/assessment-list-trustworthy-artificial-
intelligence-altai-self-assessment (accessed Feb. 07, 2021). 
[10] D. Paraschakis, “Towards an ethical recommendation 
framework,” 2017, doi: 10.1109/RCIS.2017.7956539. 
[11] D. Paraschakis, “Recommender Systems from an Industrial 
and Ethical Perspective,” in 10th ACM Conference on 

163
International Journal on Advances in Intelligent Systems, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/intelligent_systems/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Recommender Systems - RecSys ’16, 2016, pp. 463–466, doi: 
10.1145/2959100.2959101. 
[12] S. Milano, M. Taddeo, and L. Floridi, “Recommender 
Systems and their Ethical Challenges,” Minds Mach., vol. 2, pp. 
187–191, 2019, Accessed: Aug. 29, 2019. [Online]. Available: 
https://philpapers.org/archive/MILRSA-3.pdf. 
[13] A. Polonioli, “The ethics of scientific recommender 
systems,” Scientometrics. Springer Science and Business Media 
B.V., pp. 1–8, Oct. 29, 2020, doi: 10.1007/s11192-020-03766-
1. 
[14] D. Karpati, A. Najjar, and D. Agustin Ambrossio, “Ethics 
of 
Food 
Recommender 
Applications,” 
2020, 
doi: 
10.1145/3375627.3375874. 
[15] O. Levina, “A Research Commentary- Integrating Ethical 
Issues into the Data Process,” 2020, [Online]. Available: 
https://library.gito.de/open-access-pdf/Z3-
EMoWI_2020_paper_3.pdf. 
[16] A. Coravos, I. Chen, A. Gordhandas, and A. D. Stern, “We 
should treat algorithms like prescription drugs,” Quartz, pp. 1–
8, Apr. 2019, Accessed: Jan. 08, 2020. [Online]. Available: 
https://digital.hbs.edu/artificial-intelligence-machine-
learning/we-should-treat-algorithms-like-prescription-drugs/. 
[17] R. Schutt and C. O’Neil, Doing Data Science- Straight 
Talk from the Frontline. O’Reilly Media, 2013, p. 51. 
[18] O. Levina, “AI and ethics in medical research. AI-based 
research in medicine and its ethical challenges,” gesundhyte.de, 
pp. 8–11, 2020. 
[19] D. Susser and V. Grimaldi, “Measuring Automated 
Influence: Between Empirical Evidence and Ethical Values,” 
2021. 
[20] C. M. Gray, Y. Kou, B. Battles, J. Hoggatt, and A. L. 
Toombs, “The Dark (Patterns) Side of UX Design,” Proc. 2018 
CHI Conf. Hum. Factors Comput. Syst., 2018, doi: 
10.1145/3173574. 
[21] G. Baldini, M. Botterman, R. Neisse, and M. Tallacchini, 
“Ethical Design in the Internet of Things,” Sci. Eng. Ethics, vol. 
24, no. 3, pp. 905–925, Jun. 2018, doi: 10.1007/s11948-016-
9754-5. 
[22] M. Sullivan, “Tech-industry AI is getting dangerously 
homogenized, say Stanford experts,” FastCompany, 2021. 
[23] Y. Wang, Y. Ning, I. Liu, and X. X. Zhang, “Food 
Discovery with Uber Eats: Recommending for the Marketplace 
| 
Uber 
Engineering 
Blog,” 
Uber 
Engineering, 
2018. 
https://eng.uber.com/uber-eats-recommending-marketplace/ 
(accessed Mar. 17, 2020). 
[24] J. Stray, S. Adler, and D. Hadfield-Menell, “What are you 
optimizing for? Aligning Recommender Systems with Human 
Values,” 
2020, 
[Online]. 
Available: 
https://participatoryml.github.io/papers/2020/42.pdf. 
[25] S. Vallor, “Moral Deskilling and Upskilling in a New 
Machine Age: Reflections on the Ambiguous Future of 
Character,” Philos. Technol., vol. 28, no. 1, pp. 107–124, 2015, 
doi: 10.1007/s13347-014-0156-9. 
[26] X. Zhao, M. Maimaiti, M. Jia, Y. Ru, and S. Zhu, “How 
we eat determines what we become: opportunities and 
challenges brought by food delivery industry in a changing 
world in China,” Artic. Eur. J. Clin. Nutr., vol. 72, pp. 1282–
1286, 2018, doi: 10.1038/s41430-018-0191-1. 
[27] O. Levina and M. Behrend, “Assessing the Environmental 
Impact: A Case of Business Process Analysis in the Automotive 
Industry,” 2016. 
[28] A. Rao, F. Schaub, N. Sadeh, A. Acquisti, and R. Kang, 
Expecting the Unexpected: Understanding Mismatched Privacy 
Expectations Online. 2016. 
[29] M. Hatamian, A. Kitkowska, J. Korunovska, and S. 
Kirrane, ““It’s shocking!": Analysing the impact and reactions 
to the A3: Android apps behaviour analyser,” in Lecture Notes 
in Computer Science (including subseries Lecture Notes in 
Artificial Intelligence and Lecture Notes in Bioinformatics), Jul. 
2018, vol. 10980 LNCS, pp. 198–215, doi: 10.1007/978-3-319-
95729-6_13. 
[30] O. Levina, “Digital Platforms and Digital Inequality-An 
Analysis 
from 
Information 
Ethics 
Perspective,” 
2019, 
Weizenbaum 
Conference, 
doi: 
https://doi.org/10.34669/wi.cp/2.4. 
[31] R. Zhou, S. Khemmarat, and L. Gao, “The impact of 
YouTube recommendation system on video views,” in 
Proceedings of the ACM SIGCOMM Internet Measurement 
Conference, 
IMC, 
2010, 
pp. 
404–410, 
doi: 
10.1145/1879141.1879193. 
[32] R. Zhong and C. Zhang, “Food Delivery apps are drowning 
china in plastic,” New York Times, pp. 1–8, 2019, Accessed: 
Apr. 
25, 
2020. 
[Online]. 
Available: 
https://www.nytimes.com/2019/05/28/technology/china-food-
delivery-trash.html. 
[33] K. Griesbach, A. Reich, L. Elliott-Negri, and R. Milkman, 
“Algorithmic Control in Platform Food Delivery Work,” Socius 
Sociol. Res. a Dyn. World, vol. 5, p. 237802311987004, Jan. 
2019, doi: 10.1177/2378023119870041. 
[34] V. Dorner, O. Ivanova, and M. Scholz, “Think twice 
before you buy! how recommendations affect three-stage 
purchase decision processes,” in International Conference on 
Information Systems (ICIS 2013): Reshaping Society Through 
Information Systems Design, 2013, vol. 5, pp. 4278–4297. 
[35] M. De-Arteaga, R. Fogliato, and A. Chouldechova, “A 
Case for Humans-in-the-Loop: Decisions in the Presence of 
Erroneous Algorithmic Scores,” Conf. Hum. Factors Comput. 
Syst. - Proc., Apr. 2020, doi: 10.1145/3313831.3376638. 
[36] G. Friedman, “Workers without employers: Shadow 
corporations and the rise of the gig economy,” Rev. Keynes. 
Econ., vol. 2, no. 2, pp. 171–188, Apr. 2014, doi: 
10.4337/roke.2014.02.03. 
[37] J. Staufenberg, “Deliveroo courier strike: Employers 
cannot ‘simply opt out of the National Living Wage’, says 
Government,” The Independent, 2016. 
[38] M. Dewhurst, “Deliveroo couriers are right to strike: the 
company’s claims of freedom are a sham,” The Guardian, 
2016. 
https://www.theguardian.com/commentisfree/2016/aug/16/deliv
eroo-couriers-strike-freedom-william-shu (accessed May 11, 
2020). 
[39] OECD, “Protecting Consumers In Peer Platform Markets: 
Exploring The Issues Background report for Ministerial Panel 
3.1,” 
Nov. 
2016.

