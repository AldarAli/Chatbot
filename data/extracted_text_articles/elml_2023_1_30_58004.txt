Learning Time Patterns: Many Study Times To
Consider When Designing Digital Learning
Sara Zuzzi, Laura Ducci, Claudia Falconio, Daniela Pellegrini
Research and Development Division
Piazza Copernico s.r.l.
Roma, Italy
emails: {szuzzi, lducci, cfalconio, dpellegrini} @pcopernico.it
Mario Santoro
Istituto per le Applicazioni del Calcolo
Consiglio nazionale delle Ricerche
Roma, Italy
email: m.santoro@iac.cnr.it
Abstract—One of the most important issues in digital learning
is understanding the time dimension and its impact on the
design and study of different teaching methodologies. This paper
analyses learning time from user data to identify the relationships
between performance, methods used and the characteristics of
learning materials. This paper investigates aspects oﬂearning time
for three different methodologies: smartlearning; videolearning;
tutorial-storytelling. The analysis shows that tutorial-storytelling
is an appropriate and effective methodology from multiple
perspectives; smartlearning does not guarantee completion or an
adequate study pace and uses time; videolearning is positioned
in an intermediate level: it performs well, with a more than
satisfactory results, but in the face of more difﬁcult and strenuous
study, so there is ample room for improvement in this type of
course from a technical and a purely methodological point of
view.
Keywords—Learning KPI; Learning Times; Digital Learning
Design
I. INTRODUCTION
Learning time is a key factor in any training project. In
particular, it is crucial in digital learning and all self-led
learning projects. In addition, study time also drives in the
digital content market, just as it does for the enjoyment of
in-depth content (e.g., estimated reading time in newspaper
articles, time listening to an audio or viewing a video) and is
at the same time also a factor in motivation and engagement.
However, there are many dimensions of time in an online
course to be taken into account and better investigated (Fig-
ure 1):
• technical time, i.e., the running time of an instructional
resource measured in minutes/hours;
• organizational time, i.e., availability of teaching resources
(time of course opening);
• individual study time (dedicated time) overall and per
session, also related to personal characteristics (learning
style), availabilities, engagement, and reporting time;
• learning time (related to understanding and acquisition of
content);
• commercial time (standard duration).
Therefore, effectively designing the time of a course and
deﬁning access rules is a nontrivial problem for the instruc-
tional designer.
Another emerging theme is the diversity between intrinsic
study times and those provided by teaching materials in
Figure 1: The different dimensions of time.
different methodologies. Video learning, webinars, and digital
materials involve different instructional dynamics speciﬁc to
each methodology. Investigating time differences means being
able to give instructional designers clearer information to
design teaching, taking into account cognitive load and usage
patterns of training materials. In Section II we brieﬂy review
models of learning times in literature. In Section III we
describe the courses’ data and the methods of analysis. In the
following Section IV, we will describe our main results on
learning time patterns. Finally, in Section V, we will present
our ﬁndings and some lines for future works.
II. THE DIFFERENT TIMES IN LEARNING
Time is an essential variable to be investigated in under-
standing learning processes, as it is an important predictor of
learning outcomes. However, it is still little studied [1]. Time
patterns are crucial to understanding the factors contributing
to effective learning. As collected by Cortès et al.[2], several
studies assess the impact of time on:
• outcomes: group exercises or discussions/sharing tend to
improve training outcomes [3]. Outcomes include both
satisfaction and knowledge acquisition;
• satisfaction: time use is a factor in measuring satisfaction
with a course [4][5];
• learning: participants who devote adequate time per week
to study have better satisfaction. Knowledge transfer
is associated with time spent online per day studying.
9
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

Participants who spend more time daily online (social and
internet) have more signiﬁcant levels of learning. Then
time spent on academic tasks during the day is associated
with more learning (mainly using the morning hours).
More digitized users (more hours online) have skills in
applying knowledge to different contexts (both academic
and work) [2].
According to [6], learning is related to prior experience with
distance learning, individual preferences, and average study
time. More interest has been devoted to analyzing study hours
over available time. Time-of-day (TOD) is a valuable key to
understanding differences in use/access to courses and devices.
Some studies delve into learning time patterns, using in-
structional conditions [7], i.e., the way courses are delivered
and the level of autonomy or individual organization [8].
Stockwell [9] highlights how students use different study
modes based on other times of the day and devices used.
For example, Casany et al. [10] highlighted the greater use
of mobile devices at night.
Sher et al. [11] point out that the study and the modes used
to depend on the time of day it is carried out. In particular,
there are better results for students who used different method-
ologies to perform the assigned tasks (with a predominance
of computer and intensive learner type). Intensive learners,
such as users with little use of technology, did not show
signiﬁcant differences in study days but signiﬁcantly different
results. The study showed that computer use for students is
related to a meticulous mode of study [9] compared to mobile
service for tasks that require precision. Students who used
multiple study modes and tools tended to use them during
the daytime, preferring the computer during nighttime hours.
Online study sessions are primarily performed in the afternoon
for all students [10], identifying this behavior as related to
students’ commuting hours on campus.
The temporal dimension is, therefore, a source of informa-
tion about learning patterns that can help support learners and
improve the accuracy and reproducibility of the predictivity
of learning outcomes [1]. These studies are also critical to
understanding how to design learning paths, test the most
effective and agile teaching methodologies based on content,
and make the use of time explicit for the learner to equip
themselves with strategies for effectiveness and efﬁciency in
studying.
From the perspective of content creators, the time concerns
the commercial duration of the courses and the availability
of the license. It follows that it is essential to make explicit
all dimensions of time in training to effectively govern this
variable in the different steps of the life of an online course.
Therefore, time is a very complex variable composed of
different measures.
A comparative examination between teaching methodolo-
gies of adequate study time (i.e., related to passing ﬁnal tests)
is proposed in this article to investigate whether different pat-
terns of time of use, behavior, and performance are present, the
latter analyzed with the LearnalyzeR tool [12]. The ﬁndings
will be helpful in both the design and organizational phases.
III. DATA AND METHODS
The study involved a sample of different methodologies
courses on a client’s (insurance company). The courses are
delivered over the past year. The data are representative of the
types of courses listed in the Piazza Copernico srl catalog.
The teaching methodologies analyzed were:
• Videolearning: an effective type of Digital Learning
Course designed according to various levels of complex-
ity. Divided into two groups:
– Graphic videos, very suitable for explaining short
concepts clearly and simply and creating stories.
More or less sophisticated graphic input depending
on the client’s needs.
– Teaching Pills (videos with actors)video-Lessons
with a lecturer or actor playing a lecturer, made at a
desk, or otherwise with static ﬁlming.
• Smartlearning: particularly useful for print and ofﬂine
study. The development involves transposing the client
slides onto SCORM content pages plotted within LMS,
using special authoring tools, with an accompanying
narrative voice created by a professional (multimedia)
speaker.
• Tutorial_storytelling: is mainly used for training and
updating different types of content, technical manuals,
description of procedures, and corporate information.
Content pages come with text, images, graphics, and
audio. The movement of elements on the page results
from animated effects of graphics chosen from an in-
ternal library. Games with low-complexity interactions,
test pages, and exercises also selected from a predeﬁned
internal library can be provided, taking into account
customer needs and learning objectives. Similar is the
Storytelling version suitable for training and updating on
different types of content, soft skills, business processes,
corporate reporting, regulations, and safety. This type
involves a high level of multimedia, animation of objects
and interaction types (SVG), case scripts, and stories that
provide concreteness to the content covered.
Twelve courses of the same client of three different types
were analyzed: smartlearning (5 courses for a total of 5
editions, 7052 users), tutorial_storytelling (3 courses for a total
of 4 editions, 3545 users), videolearning (4 courses for a total
8 of editions, 5605 users); participants took the courses in the
year 2022; the selection neglected editions with less than 10
participants.
Starting from the use of the LearnalyzeR tool [12], which
analyzes critical issues by supporting tutor intervention on
a day-to-day basis and divides the users of a course into
performance classes, the present investigation turned toward
the study of the Macro Performance Index (MIP) (composite
index) by investigating its different aspects (sub-indicators):
Results (IR), Study Pace (ISP), Course Structure (ICS), Com-
puter Adequacy (ICA) (composite sub-indicators), and ﬁnally
highlighting, with a descriptive analysis, the link between these
indicators, time of use and course types.
10
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

(a) Violin-Box-Plot
(b) Continuos Distribution
Figure 2: MIP distribution by course type.
As mentioned above, the LearnalyzeR tool calculates
the
MIP
and
divides
users
into
performance
classes:
Lukers (MIP=[0;30)), Latecomers (MIP=[30;50)), Regulars
(MIP=[50;70)), Hard Workers (MIP=[70;80)), Top Performers
(MIP=[80;100]).
The performance index was constructed with the interaction
of a group (panel) of individuals (experts) who identiﬁed
all aspects (indicators) of the phenomenon (the perfomace);
using the same method, a set of independent variables were
identiﬁed for each indicator, which could be obtained from the
platform data. Once the indicators and variables were deﬁned,
the weighted arithmetic mean was chosen as the aggregation
function and the Analytic Hierarchy Process (AHP) [13] was
used to calculate the weights. This method makes it possible to
understand opinions on a speciﬁc topic without complicating
matters for the respondent. By processing the answers, it
allows the decision-making process of the weights to be
constructed.
IV. RESULTS
A ﬁrst exploration analysis for the relations between MIP
and courses type shows:
• Smartlearning courses. From Figure 2a, there is a
broadened peak around 80 and a few pegs in the left tail
(red line); analyzing Figure 2b, the MIP shifted toward
performance values below 80, with a median at 76, so at
least 50% of users have performance values below that;
there is also a long tail down where at least 25% of users
have performance below 71. In these courses, at least
50% of users are not at a MIP level above the Regulars
class.
• Storytelling Tutorial courses. From Figure 2, one can
observe a narrow peak above 80 (green line); in Fig-
ure 2b, the MIP shifted toward performance values above
80 (median 83) with a fairly homogeneous behavior of
the population (narrow distribution); 75% of the users
have performance between 80 and 86, so they belong to
the Top Performers class.
• Vidolearning courses. From Figure 2a, one can observe
different levels of performance: a narrow peak around
80 and a second peak around 60 (blue line); analyzing
Figure 2b, the MIP is around 80 (median 79), and there
is a consistent tail down; however, at least 75% of the
users have performance above 73. In this type of course,
despite the unevenness of performance, at least 75% of
the users are above the Regulars class.
An exploratory analysis was carried out to identify the
reasons for the observed performance by relating the sub-
indicators, which constitute the MIP, to the type of course.
The following was obtained:
Results (IR)
• Smartlearning. From Figure 3, we observe a pronounced
problem in the indicator I~R, the behavior of users for
this indicator is uneven, and four main types of behavior
11
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

Figure 3: IR distribution by course type.
are presented. At least 25% of users have an IR indicator
value of 79, and only 25% have a value above 89. Only
a small number of users (about 8%) reach the value of
100; analyzing the IR indicator [12], it is observed that
this criticality is due to the variable course completion.
• Tutorial_storytelling.The
participants
have
homoge-
neous behavior. At least 75% of the users have an IR
sub-index value of 100 (Figure 3).
• Videolearning. Participants have a rather homogeneous
behavior. At least 75% of the users have a sub-index
value IR of 100; however, there is a tail downward at sub-
index values around 50 (Figure 3), indicating a problem
completing the course for a group of users (about 10%).
Analyzing the problems encountered in smartlearning
courses for the indicator IR shows that in all methods of
this type, there is a completion problem. In all smartlearning
editions, at least 75% of users do not complete the course.
While in videolearning courses, there is a problem with one
speciﬁc edition (361 participants) in which at least 30% of
users do not complete the course. So in smartlearning courses,
the characteristic of not completing is widely spread in the
population under analysis. At the same time, for videolearning,
it is a point problem with a single edition.
Study Pace (ISP)
From Figure 4, one can observe that:
• In smartlearning courses, the median of ISP is 66 with
a tail downward.
• In tutorial_storytelling courses, the median ISP is 69
with a very elongated distribution structure, but at least
25% of the users have an ISP value above 84 (3rd
quartile).
Figure 4: ISP distribution by course type.
• in videolearning courses, the median ISP value is 66 with
a tail downward, and only a small number of users have
an ISP value above 75 (a tapering upward shape of the
blue distribution), at least 75% of users have an ISP value
below 70.
All course types have a very uneven behavior for Study
Pace, with values tending to the low end, more evident in
videolearning.
The sub-indicator ISP is highly dependent on the fruition
time, the quantity we want to study. By analyzing the trend
of fruition time concerning the expected time of the course
structure, it is better to deﬁne the Normalized Use Time (NUT
= fruition time/expected time) quantity. One can observe that
all three types of the course show uneven fruition behavior
(Figure 5), as for the ISP index.
In particular:
• Smartlearning, at least 25% of users, in all editions, have
a fruition time less than the time assumed in the course
structure (the I quartile of NUT per edition varies between
0.7 and 0.9); at least 50% of the users have a fruition time
equal to the time assumed in the course structure (median
NUT for editions is around 1.02); ﬁnally, for two editions
(of 516 and 1799 users) at least 25% of the users have a
fruition time consistently greater than that assumed (3rd
quartile of NUT between 1.6 and 1.7).
• Tutorial_storytelling, at least 50% of users have a time
roughly equal to that assumed in the course structure
(median NUT for editions varies between 0.9 and 1.2),
but at least 25% of users have a longer time (3rd
quartile of NUT between 1.8 and 2.0). The latter mainly
concentrated on two courses ( 1619 and 1882 users).
12
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

Figure 5: NUT distribution by course type.
• Videolearning, at least 25% of the users, in all editions,
have a fruition time roughly equal to the time assumed in
the course structure (NUT varies between 0.9 and 1.2). In
contrast, in two editions, the ﬁrst quartile has NUT values
between 1.5 and 1.7 (361 and 302 users, respectively).
Looking at the median, 50% of the users have a NUT
between 1.5 and 2.8; these participants are in 4 editions
(11, 302, 361, and 2565 participants, respectively). For
all editions, at least 25% of users consistently use more
time than assumed in the course structure (3rd quartile
of NUT between 1.6 and 4.3).
To summarize, in all course types, there is evidence of a long
time in a signiﬁcant percentage of the population. However,
while it is present in smartlearning and tutorial_storytelling
for a few courses/editions, on videolearning, it is widespread
across all courses. Finally, in smartlearnig, it is observed that a
substantial percentage have a shorter than expected completion
time. This ﬁts what was observed in the Results indicator
analysis, as course completion is critical for this type of course.
For completeness of analysis, a view of the sub-indices
Course Structure (ICS) and Computer Adequacy (ICA) by
course type:
• The ICS indicator in the smartlearning type has an iden-
tical value of 63 for all editions (medium complexity);
videolearning also has a homogeneous complexity with
ICS between 50 and 57 (medium-low complexity), while
the tutorial_storytelling editions have a very uneven
structure of low complexity (about 55% of users take
courses with an ICS value of 39) and medium-high
complexity (about 45% of users an ICS value of 75).
• In smartlearning and tutorial_storytelling courses,
Figure 6: Distribution of connections by time slot and course
type.
there is a good Computer Adequacy (ICA greater than
90), only 25% of the users with a value of ICA less than 90
(1st quartile: smartlearning ICA= 89, tutorial_storytelling
ICA = 84); while for videolearning courses at least 50%
of users have ICA values less than 89 and even at least
25% are below 79. The problems relate to linking and
uploading videos; those critical issues are present in all
the videolearning editions under analysis (except one).
Then, the analysis of the time slots and days of the week
by course type give:
• From Figure 6 and Figure 7, for all course types, there
is a utilization preference for the 11 a.m.-1 p.m. time
slot (the off-hours time slot has a low, but not zero, link
frequency), while there is no difference in link frequency
for weekdays (holidays have a low, but not zero, link
frequency).
• From the exploratory analysis so far, it can be inferred
that the videolearnig course type has a criticality of a
long time more evident than the other types because it is
spread over all editions, with an issue related to linking
and video uploading; in a subsequent analysis, it will be
investigated whether and how these two criticalities are
associated with each other. In contrast, the smartlearnig
course type has a widespread completion issue across all
editions.
Finally, a heatmap (Figure 8) is presented to get an overview
of the above analysis. Looking at Figure 8, patterns between
course types emerge:
• Smartlearning courses: all have the same complexity
(always the exact value of ICS), and, in general, users do
13
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

Figure 7: Distribution of connections by day and course type.
not have Computer Adequacy (ICA) problems, but there
are different patterns for Performace (MIP), Results (IR),
Study Pace (ISP) and Normalized Use Time (NUT). Low
values of MIP are found at dark IR and ISP (low values)
and very dark NUT (less than expected fruition time);
therefore, poor performance (MIP with low values) is a
consequence of less than expected fruition time. There
are bands where IR and ISP alternate between light and
dark. There are good ISP (light bands) at adequate NUT
(fruition time around the expected time), but low IR
values (dark bands) or conversely low ISP values (dark
bands) at high NUT (fruition time much greater than
the expected time), but good IR (light bands). It can
be concluded that to achieve the required results, it is
necessary to have a greater fruition time than expected.
• Tutorial_storytelling courses users do not have partic-
ular Computer Adequacy (ICA) problems, patterns of
Performace (MIP), Results (IR), Study Pace (ISP), Course
Structure (ICS), and Normalized Use Time (NUT) can
be seen. A very narrow band has low MIP values cor-
responding to dark IR and ISP (low values), a very dark
NUT (fruition time less than expected time), and low
complexity; this can be said to be punctual because this
aggregate contains a small number of users. The most
full-bodied aggregate is a trend of IR with good values
(users achieve the required results, clear band) but with
bands in which ISP and ICS alternate between light and
dark. It is possible to highlight that when there is low
complexity (low ICS, dark band), there is good ISP (light
band) and adequate NUT (fruition time equal to the
expected time). In contrast, for more complex courses
(high ICS, light band), there are low ISP values (dark
band) and high NUT (fruition time much greater than
the expected time). We conclude that the results can be
achieved within the expected time when the complexity
is low. At the same time, when the complexity increases,
the required results are achieved by increasing the fruition
time from one and a half times to more than twice the
expected time.
• The videolearning courses have similar complexity (ICS),
but the patterns are more confusing. There are cases with
low MIP values, despite good IR corresponding to low ICA
and ISP values and a high NUT; low MIP values, with low
IR values (dark bands) corresponding to adequate or too
high NUT. In general, compared to the other course types,
it is observed that NUT values are much clearer, thus a
much longer than expected time of use and Computer
Adequacy with problems (low values of ICA).
In Figure 8, we can also observe dendrograms. On the left
are aggregations of users by MIP level in the three-course
types; at the top are the two aggregates of sub-indexes: ICA
with IR and ISP with ICS.
V. CONCLUSIONS
The analysis shows that storytelling is an appropriate
and effective methodology from multiple perspectives, which
performs best regardless of content and editions. One point
of attention is the complexity of the structure directly related
to the spent study time. It is also clear that smartlearning
satisﬁes the needs for low time-to-market and low impact
on the training budget, but it responds less well in terms of
results achieved, with lower performance indices (MIP). The
simplicity of the course, in terms of instructional design and
methodological format, on the one hand,encourages the use of
courses outside of working hours, but on the other hand, it does
not guarantee completion or an adequate study pace and uses
time. The risks associated with using smartlearning in training
can be traced to potential problems with staff preparation and
additional costs associated with necessary re-training.
Videolearning is positioned at an intermediate level: it
performs well, with more than satisfactory results, but in the
face of more difﬁcult and strenuous study. In the unevenness
of some of the data, there is ample room for improvement in
this type of course:
• from a technical point of view, for example, the increasing
enhancement of storage and delivery infrastructures for
video content, both server-side and client-side, can make
the Computer Adequacy values higher;
• from a purely methodological point of view, to manage
the high value of uses time, instructional designs can
distribute the “weight” of the topics and include more
interactions, useful to scan the individual study time
and create moments of self-assessment and knowledge
reinforcement.
Starting from this analysis on the time issue in e-learning,
always open and little explored on data, there emerges the need
14
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

Figure 8: Heatmap. The quantities on the horizontal axis at the bottom are: Course Type (smartlearning, tutorial_storytelling,
videolearning); Macro Index of Performance (MIP) is a continuous variable; the scale grows from left to the right, so the
(left) peaks represent low values of MIP; Normalized Use Time (NUT), a variable divided into classes as reported in the
legend; in the deﬁned intervals the square bracket indicates that the extreme is included, the round bracket that the extreme is
excluded. Computer Adequacy (ICA), Results (I~R), Study Pace (ISP), Course Structure (ICS). On the left and top, the observed
dendrograms deﬁne aggregates of users and sub-indexes, respectively.
15
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

to continue the research including in the analysis framework
other information, such as the period of fruition; the per-
ceived usefulness to understand the impact of the time learn-
ing patterns identiﬁed for types and formats of multimedia
courses. This analysis will be extended to other instructional
methodologies (classroom, game, webinar) because the goal
is to give time its proper value for designers, salespeople,
and end-users who must have adequate time to learn, i.e,
the month of the year in which the course is opened; the
characteristics of the target audience; the content, i.e., the
thematic area; the connecting device; the perceived usefulness
to understand the impact the time learning patterns identiﬁed
for types and formats of multimedia courses. This analysis will
be extended to other instructional methodologies (classroom,
game, webinar) because the goal is to give time its proper
value for designers, salespeople, and end-users who must have
adequate time to learn.
REFERENCES
[1]
M. Saqr, J. Nouri, and U. Fors, “Time to focus on the
temporal dimension of learning: A learning analytics
study of the temporal patterns of students’ interac-
tions and self-regulation,” Int. J. Technol. Enhanc.
Learn., vol. 11, no. 4, pp. 398–412, Jan. 2019, doi:
10.1504/ijtel.2019.102549. [Online]. Available: https:
//doi.org/10.1504/ijtel.2019.102549
[2]
A. Cortés and B. Elena, “Time patterns and perceptions
of online learning success factors,” eLearn Center
Research Paper Series, no. 7, pp. 39–48, Jan. 2013
[Online]. Available: https://raco.cat/index.php/eLearn/
article/view/272018
[3]
C. Zhu, “Student satisfaction, performance, and knowl-
edge construction in online collaborative learning,”
Journal of Educational Technology and Society, vol.
15, no. 1, pp. 127–136, 2012.
[4]
P.
Arneberg
et
al.,
“Analyses
of
european
megaproviders of e-learning,” Megatrends Project,
2007.
[5]
S. Y. McGorry, “Measuring quality in online pro-
grams,” The Internet and Higher Education, vol. 6, no.
2, pp. 159–177, 2003.
[6]
D. H. Lim and M. L. Morris, “Learner and instruc-
tional factors inﬂuencing learning outcomes within a
blended learning environment,” Journal of Educational
Technology and Society, vol. 12, no. 4, pp. 282–293,
2009.
[7]
A. van Leeuwen, N. Bos, H. van Ravenswaaij, and
J. van Oostenrijk, “The role of temporal patterns in
students’ behavior for predicting course performance:
A comparison of two blended learning courses,” British
Journal of Educational Technology, vol. 50, no. 2, pp.
921–933, 2019.
[8]
J. Malmberg, S. Järvelä, and H. Järvenoja, “Capturing
temporal and sequential patterns of self-, co-, and so-
cially shared regulation in the context of collaborative
learning,” Contemporary Educational Psychology, vol.
49, pp. 160–174, 2017.
[9]
G. Stockwell, “Tracking learner usage of mobile
phones for language learning outside of the classroom,”
Calico Journal, vol. 30, pp. 118–136, 2013.
[10]
M. J. Casany Guerrero, M. Alier Forment, N. Galanis,
E. Mayol Sarroca, and J. Piguillem Poch, “Analyz-
ing moodle/LMS logs to measure mobile access,” in
UBICOMM 2012: The sixth international conference
on mobile ubiquitous computing, systems, services and
technologies, 2012, pp. 35–40.
[11]
V. Sher, M. Hatala, and D. Gaševi´c, “When do learners
study? An analysis of the time-of-day and weekday-
weekend usage patterns of learning management sys-
tems from mobile and computers in blended learning,”
Journal of Learning Analytics, vol. 9, no. 2, pp. 1–23,
2022.
[12]
D. Pellegrini, M. Santoro, and S. Zuzzi, “Learning an-
alytics and governance of the digital learning process.”
in teleXbe, 2021.
[13]
R. W. Saaty, “The analytic hierarchy process—what it
is and how it is used,” Mathematical modelling, vol. 9,
no. 3–5, pp. 161–176, 1987.
16
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-081-0
eLmL 2023 : The Fifteenth International Conference on Mobile, Hybrid, and On-line Learning

