Trends in Local Telecommunication Switch Resiliency 
 
 
Andrew P. Snow 
School of Information & Telecommunication Systems 
Ohio University 
Athens, Ohio, USA 
e-mail: asnow@ohio.edu 
Gary Weckman  
Department of Industrial & Systems Engineering  
Ohio University 
Athens, Ohio, USA 
e-mail: weckmang@ohio.edu
 
 
Abstract— This paper presents a time series analysis of outage 
causality trends for local telecommunication switches in the 
United States. Additionally, the resiliency of local switches is 
assessed by examining changes in severity of outages over time 
by causality. Almost 13,000 Public Switched Telephone 
Network (PSTN) switch outages are examined over a 14-year 
period. Causality trends were examined from both resiliency 
and reliability perspectives, for scheduled outages, and failure 
induced cause categories such as procedural errors, design 
errors, random hardware failures, and external events. 
Examples of reliability growth, constancy, and deterioration 
are noted among these casual categories. Likewise, examples of 
increasing, constant and decreasing impact trends are also 
noted. To examine resiliency, a novel severity index metric is 
introduced that is not only intuitive, but also robust, given the 
long tailed distribution of outage impact. The new index allows 
time series comparison between causality reliability and outage 
impact trends.  Interestingly, in some instances causality 
reliability trends were different from the corresponding impact 
trends. For example, when all outage causes are combined, a 
reliability growth trend is indicated while outage impact is 
constant. To get a good perspective on resiliency, both 
reliability and outage impact trends must be examined. Trends 
are assessed both graphically and analytically, and conclusions 
are reached with strong statistical inference.  
Keywords- reliability growth; resiliency, outage index; 
homogeneous poisson process (HPP), non-homogeneous poisson 
process (NHPP), Laplace trend test, time series of events, fault 
management. 
 
I. 
 INTRODUCTION  
Telecommunication switches are an important subsystem 
of the Public Switched Telephone Network (PSTN). Along 
with the transmission and signaling subsystems, these 
switches provide end to end connections to subscribers. 
Although the PSTN in the U.S. is used predominantly for 
landline voice services, many wireless calls use many of the 
same facilities, especially for regional calls. Additionally, 
PSTN and wireless switches are often different models of the 
same switch vendor product line, as the switching functions 
are very similar. So wireline switches, besides serving 
millions of subscribers and deserving of study in their own 
right, are also good proxies  for wireless mobile switching 
centers [1]. The PSTN is certainly migrating to voice over 
internet protocol (VoIP), but this migration will take many 
years, and local switches are likely remain in service for 
years to come [2]. At the beginning of 2011, there were 117 
million subscribers connected over local loops to circuit 
switched local switches, and 32 million VoIP subscribers [3].  
Additionally, local switches are access nodes, and access 
nodes, be they in a circuit or a packet switch networks, are 
very important as they represent the gateway to network 
services for users. For instance, the methods presented in this 
paper, and the types of insights that can be gleaned from 
failure and outage data are as relevant for local PSTN 
switches, as they are for Internet Service Provider (ISP) 
access nodes. 
Trends are important in the dependability of systems, 
subsystems, and components. Statisticians identify trends – 
engineers endeavor to embrace favorable trends and 
influence for the better negative trends. A key to 
understanding reliability trends is to recognize and identify 
the hazards in which the item, system or service operates. 
Additionally, management must make reliability programs a 
priority [4]. In order to change a trend, we look for 
approaches offering insights into why failures are occurring. 
Telecommunication switch reliability results from complex 
interaction between software, hardware, operators, traffic 
load, and many environmental factors. By knowing failure 
causes and trends, switch vendors and service providers may 
take actions to change trends.  Barnard argues that reliability 
engineering must endeavor to continually improve systems 
and products before and during the operational phase, using 
such techniques as the Failure Reporting, Analysis and 
Corrective Action System (FRACAS) [5]. In network 
management, this is a fault management function. 
Additionally, all outages are not equal, as some might 
affect hundreds for long periods, while others might affect 
hundreds of thousands for short periods.  Outages represent 
resiliency deficits, and trends in resiliency are as important 
as trends in reliability. This paper endeavors to examine 
reliability and resiliency trends, as they relate to outage 
causality. In this way, we can not only arrive at an overall 
assessment, but also assessments segregated by cause.  
This study uses local switch outage data reported to the 
Federal Communications Commission (FCC) representing 
individual switch outage incidents of at least two minutes in 
duration from 1996 through 2009, collected from [6]. 
Unfortunately, after 2009, the FCC no longer required 
carriers to report this data.  As each reported switch outage 
includes date, time, and outage cause, a time series by cause 
was created by us to assess causality trends. In addition, as 
the reports also included the size of each switch out (in 
178
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

access lines) and duration, time series outage impact trends 
could also be assessed. The reporting Carrier classified each 
incident using one of fifteen different cause codes. We 
further aggregated the fifteen causes into six outage causality 
categories. Causality trends are of paramount interest if the 
objective is to understand failure and outage patterns. This 
way, remedial action plans can be taken by network 
operators to improve network performance. 
Section II presents a literature review of outage impact, 
local switch reliability, and reliability of repairable systems. 
Section III introduces the specific research questions being 
addressed in this paper while Section IV overviews the time 
series methods used to assess local switch reliability and 
resiliency, including a new resiliency metric. Section V 
presents the causality trends in graphical and tabular form, 
including reliability ad resiliency comparisons. Section VI 
summarizes conclusions while Section VII addresses 
research limitations and suggests future research directions. 
 
II. 
LITERATURE REVIEW 
A. Outage Impact 
A system is resilient when it has “the capability of a 
system to maintain its functions and structure in the face of 
internal and external change and to degrade gracefully when 
it must.” [7]. The role of modeling in understanding and 
promoting the resilience of critical infrastructures, including 
wireline and wireless telecommunications, has been argued. 
Before these processes can be modeled, they need to be 
characterized and understood. [8].  
Large-scale telecommunication outages can result in 
heavy losses to business and society at large. Also, 
colocation 
and 
the 
resulting 
concentration 
of 
telecommunications assets represent “serious risk posed to 
small and mid-sized businesses from disruptions in 
telecommunications service.” [9]. Local switches are in end 
offices that can represent concentrations. Additionally, 
although end offices are susceptible to power loss, they are 
typically protected by generator and battery backup power 
sources. However, damages to the AC power grid are 
common in hurricane prone areas, which causes outages to 
“wire-line networks, wireless networks, transmission links, 
cable TV grids, and TV and radio facilities...”. The major 
causes of telecommunication outages from hurricane 
Katrina was found to be power loss because of fuel supply 
disruptions, flooding and security in low-lying areas [10]. 
Recently, Lyons, et al empirically assessed the economic 
impact of telecommunication outages [11]. In that paper, the 
economic costs of telecommunication outages, for fixed line 
networks, is estimated for both a complete sector outage and 
local exchange outages. The costs estimates are based on 
actual business and residential demographics, including 
service and manufacturing areas. For seven local exchange 
outages in Ireland, these costs ranged from €370,000 to €1.1 
million per day. Unfortunately, the number of lines for local 
switch in each of the exchanges are not given. 
The User Lost Erlang (ULE) was introduced by 
McDonald in [12] as an impact metric for large-scale 
outages. The ULE is the logarithm of the magnitude of an 
outage, or ULE = log10(Magnitude), where magnitude is the 
number of users impacted. For instance, the impact of an 
outage affecting 10,000 lines would be 4 ULE. Because of 
the range of outages could be many orders of magnitude, 
McDonald thought such a metric would be easy to use and 
understandable by the public, much like the logarithmic 
Richter scale for earthquake intensity. Of course, the 
disadvantage of the ULE is that although size is taken into 
account, the duration of the outage is not.  So an outage has 
both size and duration as variables. The Federal 
Communication System used the Lost Line Hour (LLH) 
metric, the product of the number of lines out times the 
duration in hours. For instance, a 10,000 line switch out for 
2 hours would be an equivalent outage of 20,000 LLH, or 
20,000 lines out for an hour. Although the LLH incorporates 
both the time and duration of an outage, it does not capture 
blocked calls. Additionally, the LLH has no logarithmic 
transformation to tame outliers in size or duration of 
outages. Committee T1 in the US, published an American 
National Standards Institute (ANSI) sponsored metric called 
the Outage Index (OI). This metric included the product of 
two weightings, one for size, and another for duration. 
Additionally, given the long tailed distributions of size and 
duration, each weight included logarithmic transformations. 
However, further analysis of the OI indicated a network 
administrator 
perspective 
rather 
than 
a 
subscriber 
perspective, in that the index was insensitive to long 
duration outages and very sensitive to large size outages 
[13]. For instance, assume a local switch with 10,000 lines 
experiences an outage: if a 1 day outage the OI is 0.519 
while if an 8 day outage the OI is 0.532 [14]. This 
discounting of duration masked significant impact of 
outages below a regulatory reporting threshold, which 
according to the OI impact metric was minimal [15].  
More recently, in [16], resiliency was defined as the 
percentage of users deriving successful service over time. 
Although a reasonable metric, the number of users impacted 
is not provided by this metric. 
B. Local Switch Reliability 
In the late 90s, Kuhn reported on the sources of major 
outages in the PSTN, including local switches, tandem 
switches, signaling, and transmission facilities. However, 
this work assessed but a few years of outages, and only 
those outages that exceeded impacting 30,000 or more 
subscribers for at least 30 minutes or more [17]. 
Time series analysis on local switch outages lasting 2 
minutes or more was first reported by Snow in [18], 
examining trends, causes and impact of outages occurring 
from 1992 to 1995. In [19], Snow noted that some 
individual switches seemed to experience many outages. 
Recently, local switch outages were examined by Snow, et 
al in [1], from 1996 to 2009, extending the work in [18] but 
179
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

with the primary focus on switches suffering more frequent 
outages. Although summary statistics for causality and 
survivability were presented, causality trends, and the 
corresponding outage impact trends, were not investigated. 
C. Reliability Assessments of Repairable Systems 
A system is reliable when it carries out its intended 
functions over a specified period of time, without failure. 
The probability of this happening is the definition of 
reliability. Said another way, reliability is the probability a 
system will perform its intended function, in the intended 
environment and at a particular level of performance. 
Thresholds are very commonly used to declare a system as in 
either an “operational” or “degraded” mode [20]. Others 
define reliability as “conformance to specifications over 
time” [21]. 
As pointed out by Louit, et al. [22], reliability of systems 
are best assessed by time to failure (ttf) models and analysis. 
Because local switches are repairable systems, stochastic 
point processes must be applied, since the ttfs can be 
systemically changing over time. Said another way, the 
failure arrival process might be non-stationary, so ttfs cannot 
simply be fitted to a distribution unless they can be shown 
to be a renewal process (RP, independent and identically 
distributed) or a special case of renewal process, the 
homogeneous Poisson process (HHP, independent and 
identically exponentially distributed). So, the presence of 
trends are of paramount interest as they indicate 
improvement or deterioration. 
Additionally, Louit, et al. [22], point out that methods for 
trend analysis are graphical and analytical. Graphical 
methods culminate in visual assessments of cumulative 
plots of outages versus time. Straight lines represent 
constancy, or no trend. Where the curve that bends up, 
represents an upward trend, and where a curve bends down, 
represents a downward trend of failures over time. Analytic 
trends are indicated when the visual trend evidence from the 
graph is slight, or to assess the strength of the trends. The 
Laplace trend test is well known, having a null hypothesis 
of HPP and an alternative hypothesis of a non-homogeneous 
Poisson process (NHPP). For no trend, renewal processes 
are often used, as it is hoped the system is made “good as 
new” through modular replacement. However, switches 
involve software and hardware changes, wherein some 
repairs result in a slightly different switch. This means that 
failures are not independent or identically distributed. The 
NHPP, is the most popular nonstationary model used in 
reliability for monotonically increasing or decreasing trends.  
The Laplace statistic is zero for the null hypothesis of no 
trend. A statistic less than zero is a decreasing trend 
(reliability growth) while a statistic greater than 0 indicates 
an increasing trend (reliability deterioration). The Laplace 
score (L) asymptotically approaches a normal score, so if 
one chooses a critical value of 0.05, L is non-zero, 
representing a statistically significant trend, if -1.96 ≥ L ≥ 
+1.96. The Laplace score for a truncated time series of 
events is: 
L   
∑
ti-(1
 )n 
n
i 1
√n 1 
⁄
                (1) 
 
where ti is the time of the ith failure, n is the number of 
failures over the time observed time period T. 
Lastly, Louit, et al. [22], point out that in cases as this 
study, where failures are from thousands of different local 
switches of different manufacturer and models, the 
superposition of many processes tend to converge to a 
Poisson process, either homogeneous or nonhomogeneous. 
 
III. 
RESEARCH QUESTIONS 
This research 
addresses 
the 
following 
questions 
regarding telecommunication local switch outage causality 
trends over a 14 year period: 
 
Are failure trends the same or different for 
different causal categories? 
 
Can causality failure processes be characterized 
as HPP or NHPP? 
 
Can a new impact metric be devised to provide 
insights into resiliency trends? 
 
For each causal category, are resiliency trends 
discernable from reliability and outage impact 
trends? 
In this work, the PSTN is viewed as a single system, made 
up of switching, signaling and transmission segments. The 
switching segment is made up of the tandem and local switch 
subsystems. The purpose of this paper is to investigate the 
reliability and resiliency trends of the local exchange 
switching subsystem as a whole, by investigating the pooled 
failures of all individual local switches in the PSTN. There 
are a large number of different manufacturers and models of 
local switches in this infrastructure. Even the same model 
switch varies substantially from serial to serial because of 
differences in customers served and features offered.  By 
pooling failures from different switches, we may assess the 
resiliency and reliability of local switching as a whole, rather 
than the reliability of a single switch. Then, failures and 
outages can be subdivided by causality and examined further 
for trends. 
 
IV. 
TIME SERIES ANALYSIS METHODS 
Two different time series methods are used. The first is 
the aforementioned graphical and analytical time-to-failure 
techniques, of Louit, et al. [22]. The second consists of 
methods developed for this paper: graphical plots of outage 
resiliency and linear regression, where indicated by visual 
assessment. 
A. Causal Trend Analysis of Events 
By combing similar cause codes reported to the FCC into 
categories, we reduced the fifteen causes reported to the FCC 
down to six causality codes: 
• 
Scheduled 
outage: 
An 
intentional 
outage 
for 
maintenance purposes.  
180
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

• 
Procedural error:  Procedural errors made in 
installation, maintenance or other activities by Telco 
employees, contractors, switch vendors, or other 
vendors.  
• 
Design error:  Software or hardware design errors 
made by the switch vendor prior to installation. 
• 
Hardware error: A random hardware failure, which 
causes the switch to fail.   
• 
External circumstances: An event not directly 
associated with the switch, which causes it to fail or 
be isolated from the PSTN. 
• 
 Other/unknown: A failure for which the cause was 
not ascertained by the carrier. 
These categories, their composition, and the distribution 
of failures to each category are shown in Table I. For each of 
these processes, time series were created for study over a 14 
year period. 
B. Causal Resiliency Trend Analysis 
Manifold shortcomings of the aforementioned outage 
index indicate a different resiliency metric is needed for this 
analysis. Given the long tailed distribution of both switch 
lines and outage duration, LLH ranges from very small to 
very large, indicating a logarithmic transformation is 
desirable. However, a major problem with the outage index 
is a non-intuitive lack of reference and insensitivity to long 
duration outages, while a major advantage of LLH is that it 
represents switch size and duration equally. 
TABLE I.  
LOCAL SWITCH OUTAGE CAUSE CATEGORY DISTRIBUTION 
Outage Category 
No. 
% 
Scheduled 
3,885 
30% 
Procedural Error 
1,394 
11% 
Design Error 
1,214 
9% 
Random HW Failure 
2,951 
23% 
Ext. Circumstances 
2,900 
23% 
Other/Unknown 
516 
4% 
Total 
12,860 
100% 
 
To develop a new metric, we borrow from the field of 
communications engineering, where power is represented by 
decibels, referenced to a power level of interest. For 
instance, dBm is power in decibels referenced to one 
milliwatt (mW), while dbW is power represented to one 
watt. For example: 
 
             
 
     
(2) 
 
The nice feature about the dBm is that 0 dBm is 1 mW (the 
reference power), and a 10 dB increase/decrease is a tenfold 
increase/decrease, and a 3 dB increase/decrease represents a 
doubling /halving. 
The new metric used here is as follows: 
 
               
   
           (3) 
 
This new metric is called an outage index, referenced to 
1,000 LLH. So now, an OIdBk of 20 represents two orders of 
magnitude above 1,000 LLH, or 100,000 LLH, while an 
OIdBK of 23 represents a doubling above 20, or 200,000 
LLH. Also, -3 OIdBK represents 500 LLH while -6 OIdBK 
represents 250 LLH.  his new metric should “tame” the 
wide swings of LLH, and give an intuitive reference when 
doing time series plots and regression of outage resilience 
over time. Of course, if desirable, we can also have OIdBM 
which references the severity to one million LLH. 
 
V. 
RESULTS 
Here we present tabular, graphical, and analytic results to 
assess reliability and resiliency and causal trends. First, the 
cumulative outage plot for all outages is seen in Figure 1. 
This is not a monotonic trend, as the failure rate (failures per 
unit time, the derivative of the cumulative graph) represents 
a “bathtub” curve: a region of high failure rate, followed by a 
region of lower failure rate, then an increasing failure trend. 
A. Causal Reliability Trends 
A summary of causal trend analysis is provided in Table 
II, while sample casual trend graphic results are shown in 
Figures 2 through 4 show sample cumulative plots. In Table 
II, we see three cause categories that show overall 
improvement and three that overall show deterioration.  
 
 
 
 
 
 
0
1000
2000
3000
4000
5000
6000
7000
8000
9000
10000
11000
12000
13000
14000
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
Cumulative Number of Outages
Years
All Outages
 
Figure 1. Cumulative Outage Plot: All Outages 
 
 
 
 
 
 
 
 
181
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

TABLE II.  
OUTAGE FREQUENCY TRENDS BY CAUSE 
 
 
 
 
 
Figure 2. Cumulative Outage Plot: Procedural Outages 
 
 
 
 
Figure 3. Cumulative Outage Plot: Random HW Failures 
 
 
 
 
Figure 4. Cumulative Outage Plot: External Circumstance Outages 
 
 
These trends are statistically very strong, as evidenced by the 
p-values. Several categories showed monotonic trends, good 
candidates for NHPP. Two showed bathtub type failure rates, 
and could be examined in a piecewise linear fashion. 
Interestingly, none showed promise of a renewal process, for 
which distributions could be fitted, as all six processes are 
nonstationary over the 14-year study period. 
 
B. Causal Impact Trends 
A summary of causal impact trends is shown in Table III, 
where we observe instances of increasing, constant and 
decreasing outage impact. The trends were determined by 
linear regression models, which were all statistically 
significant at the 0.05 critical value, for each model’s F-test 
and coefficient t-tests. The trend constant and slope are 
provided for each model. Several observations can be made 
from this table. First, note that since the scheduled outage 
constant is about 3 dBK higher than design error constant, on 
average, scheduled outage severity is about double that of 
design error. Secondly, however, using the regression 
constant, note that over 14-years, scheduled outage resiliency 
improved 17 dBK while design error resiliency improved 
13.2 dBK. So by the end of the period, the aforementioned 3 
dBK difference evaporated. Lastly, note that over the 14-year 
period, external circumstance resiliency worsened by 7.4 
dBK, meaning its worsening more than quadrupled (6 dB). 
 
TABLE III.  
OUTAGE IMPACT TRENDS BY CAUSE 
 
 
 
Next, we show the impact charts (OIdBK quarterly plots), 
Figures 5 through 8, corresponding to the four cumulative 
outage plots, followed by an example LLH plot for outages 
due to external circumstances (Figure 9). The LLH plot in 
Figure 9 not only demonstrates the difficulty in determining 
trends, but also that LLH is a poor resiliency impact metric, 
compared to Figure 8. 
 
 
 
Figure 5. Outage Impact Plot: All Outages 
 
 
Cause Category
L
p-Value
Trend
Type
Scheduled
-58.41
0.0000
Decreasing Monotonic
Procedural Errors
-14.42
0.0000
Decreasing Monotonic
Design Errors
-27.61
0.0000
Decreasing Monotonic
Random HW Fail.
3.0
0.0012
Increasing
Bathtub
External Circum.
28.33
0.0000
Increasing
Monotonic
Unknown/Other
3.34
0.0004
Increasing
Bathtub
Cause Category
Impact Trend
Regression Const.
OIdbk/Yr
OIdbk/14Yr
Scheduled
Decreasing
26.3 OIdbk
–1.22 OIdbk
OIdbk
Procedural Errors
No
NA
NA
NA
Design Errors
Decreasing
23.4 OIdbk
–0.94 OIdbk
OIdbk
Random HW Fail.
No
NA
NA
NA
External Circum.
Increasing
24.9 OIdbk
0.53 OIdbk
OIdbk
Unknown/Other
No
NA
NA
NA
182
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

 
 
Figure 6. Outage Impact Plot for Procedural Error Outages 
 
 
 
 
Figure 7.  Outage Impact Plot: Random HW Failures 
 
 
 
 
Figure 8. Outage Impact Plot: External Circumstance Outages 
 
 
 
 
Figure 9. LLH Plot for External Circumstance Outages 
 
 
 
VI. 
SUMMARY OF FINDINGS  
The research questions listed in Section III are addressed 
here in turn.  
A. Are outage/failure trends the same or different for 
different causal categories?  
All failure/outage trends were markedly different. 
However, three causality trends were found to be decreasing 
over the study period, indicating reliability growth. Likewise, 
three other causality trends were found to be increasing, 
indicating reliability deterioration. In addition, some of the 
trends were monotonically increasing or decreasing, and 
others 
indicated 
bathtub 
processes, 
which 
indicate 
deterioration towards the end of the study period.  
B. Can causality failure processes be characterized as 
either HPP or NHPP? 
None of the six processes studied passed the test for HPP 
as all showed strong visual signs of nonstationary processes. 
The monotonically increasing and decreasing trends looked 
like good candidates for the power law model. The causality 
trends exhibiting bathtub characteristics are candidates for 
investigating piecewise linearity, or piecewise HPP. 
C. Can a new impact metric be devised to provide insights 
into resiliency trends? 
The new impact metric, the OIdBK , showed promise as it 
controlled outliers through a logarithmic transformation and 
easily allowed trend analysis for resiliency. Also, it is 
referenced to a benchmark loss of 1,000 LLH, making it 
intuitive. This metric overcomes shortcomings in both the 
LLH and the ANSI outage index metrics. Unlike the ANSI 
outage index, it is not insensitive to long duration outages, 
giving equal weight to both outage magnitude and duration. 
Unlike the LLH, it does not have extreme range of values. 
D. For each causal category, are failure/outage trends and 
impact trends in agreement? 
For scheduled and design error outage categories, both 
impact and outage trends decreased (deterioration in both) 
while for external circumstance outages, both trends 
increased (improvement in both). Interestingly, although 
procedural error outages decreased, there 
was 
no 
improvement in outage impact. In addition, random 
hardware failures and unknown/other outages increased 
(deterioration), with no concomitant deterioration outage 
impact. 
 
VII. CONCLUSIONS 
This work shows that to assess resiliency, both reliability 
and outage impact offers valuable insights. It also indicates 
the 
importance 
of 
posterior 
perspectives 
of 
these 
dependability attributes, as an important part of the fault 
management aspect of the network management function. 
More research can be performed to gain additional 
perspectives. For instance, besides investigating the trends 
183
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

for the casual categories here, all fifteen cause codes can be 
examined for resiliency trends. Preliminary investigations 
indicates presence of possible renewal processes, including 
HPP. For those cases, event independence can be 
investigated using the coefficient of variation and presence 
of significant first order autocorrelation coefficients. 
Additionally, piecewise linear and power law modeling 
could be used to further characterize these causal processes. 
 
REFERENCES 
 
[1] Andrew Snow, Aimee Shyirambere, Julio Arauz, and Gary 
Weckman, “A reliability and survivability analysis of local 
telecommunication switches suffering frequent outages”,  he 
Twelfth International Conference on Networks, IARIA, 
Seville Spain, 2013. 
[2] J. Gillan, and D. Malfara, The transition to an all-IP network: 
a 
primer 
on 
the 
architectural 
components 
of 
IP 
interconnection, National Regulatory Research Institute, May 
2012. 
[3] FCC, Local telephone competition: status as of december 31, 
2010, Industry Analysis and Technology Division, Wireline 
Competition Burea, October 2011. 
[4] P. D. T O’Conner, Practical reliability engineering, Fourth 
edition, John Wiley & Sons, England, 2001. 
[5] R. W. A. Barnard, “Reliability engineering : futility and 
error”, Second Annual Chapter Conference, South African 
Chapter, International Council on Systems Engineering 
(INCOSE), 31 August, September 2004. 
[6] FCC Report 43-05, ARMIS Service Quality Report Table 
IVa, downloaded from http://transition.fcc.gov/wcb/armis/ 
September 2012. 
[7] B. Allenby and J. Fink, “ oward inherently secure and 
resilient societies,” Science 309, August 2005, pp. 1034. 
[8] Laura J. Steinberg, Nicholas Santella, and Corri Zoli, “Rouge 
post-katrina: the role of critical infrastructure modeling in 
promoting resilience”, Homeland Security Affairs, Vol 7, 
Article 7, 2011.  
[9] Ginger Armbrustera, Barbara Endicott-Popovsky, and Jan 
Whittington, “Are we prepared for the economic risk resulting 
from telecom hotel disruptions?”, International Journal of 
Critical Infrastructure Protection Volume 5, Issue 2, July 
2012, pp 55–65. 
[10] A. Kwasinski, W. W. Weaver, P. L. Chapman, and P. T. 
Krein, 
“ elecommunications 
Power 
Plant 
Damage 
Assessment Caused by Hurricane Katrina – Site Survey and 
Follow-Up 
Results”, 
28th 
Annual 
International 
Telecommunications Energy Conference, INTELEC '06, 
IEEE, ISBN: 1-4244-0430-4, 2006. 
[11] S. Lyons, Edgar Morgenroth, and Richard Tol, “Estimating 
the value of lost telecoms connectivity”, Electronic 
Commerce Research and Applications 12, 2013, pp. 40–51. 
[12] J. C. McDonald, “Public network integrity-avoiding a crisis in 
trust” Journal on Selected Areas in Communications, IEEE 
Journal, Volume: 12 , Issue: 1, 1994. 
[13] A. Snow, “A survivability metric for telecommunications: 
insights and shortcomings”, IEEE Computer Society, 
Proceedings, Information Survivability Workshop – ISW’98, 
1998, pp. 135-138. 
[14] A. Snow and Y. Carver, “Carrier-industry, fcc and user 
perspectives of a long duration outage: challenges in 
characterizing impact”, T1A1.2/99- 026, Contribution to 
Committee T1 – Telecommunications, Boulder Colorado, 
1999. 
[15] A. P. Snow, “Assessing pain below a regulatory outage 
reporting threshold”, Telecommunications Policy, Vol. 28, 
Issue 7-8, 2004, pp. 523-536. 
[16] M. Omer, R. Nilchiani, and A. Mostashari, "Measuring the 
resilience of the global internet infrastructure system", 3rd 
Annual IEEE Systems Conference, March 2009, pp. 152-162. 
[17] R. Kuhn, Sources of failure in the public switched telephone 
network, IEEE Computer, 1997. 
[18] A. P. Snow, “ he reliability of telecommunication switches”, 
Six 
International 
Conference 
on 
Telecommunications 
Systems: Modeling and Analysis, March 1997, pp. 288-295. 
[19] A. P. Snow, “Internet implications of telephone access”, IEEE 
Computer 32 (9) , September 1999, pp.108-110. 
[20] M. A. Levin and T. T. Kalal, Improving Product Reliability, 
Strategies and Implementation, John Wiley & Sons, England, 
2011. 
[21] R. J. Ellison, D. A. Fisher, R. C. Linger, H. F. Lipson, T. 
Longstaff, and N. R. Mead, Survivable Network Systems: An 
Emerging Discipline, Carnegie-Mellon Software Engineering 
Institute Technical Report CMU/SEI-97-TR-013, 1997, 
revised 1999. 
[22] D. M. Louit,  et al, “A Practical procedure for the selection of 
time-to-failure models based upon the assessment of trends in 
maintenance data”, Reliability Engineering and System Safety 
94, 2011, pp. 1618-1628. 
 
                                                           
 
184
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

