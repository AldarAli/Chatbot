Toward Emotional Internet of Things for Smart Industry
David Antonio G´omez J´auregui
ESTIA
F-64210 Bidart, France
Email: d.gomez@estia.fr
Abstract—In this paper, an approach to design and implement
non-invasive and wearable emotion recognition technologies in
smart industries is proposed. The proposed approach beneﬁts
from the interconnectivity of Internet of Things (IoT) to recognize
and adapt to complex negative emotional states of employees
(e.g., stress, frustration, etc.). Two types of connected objects are
proposed: emotional detectors and emotional actors. The steps to
design and implement these connected objects are described. The
proposed approach is expected to ensure and maintain a healthy
work environment in smart industries.
Keywords–Emotion recognition; Internet of Things; Smart In-
dustry.
I.
INTRODUCTION
The proposed approach contributes to the development of
new smart interfaces capable of adapting efﬁciently to users’
emotions in the context of smart industries. Smart industry
(also called Industry 4.0) is the current trend in which the
industrial production, computing and communication technolo-
gies converge [1]. Smart industries are expected to increase
operational effectiveness of employees as well as provide
new services, new types of products, business models and
reduction of pollution [2]. In order to work efﬁciently, smart
industries must support interconnection of wireless devices,
sensors, and people through the Internet of Things (IoT) [3].
Interconnected objects will provide new ways of collaboration
between humans and machines in order to reach common
goals in the manufacturing process. Studies have shown that
the productiveness of employees are heavily inﬂuenced by
their emotional states [4]. Negative emotions, such as stress,
frustration and anxiety are strongly correlated with counter-
productive work behavior [5]. Automatic emotion recognition
could be an important requirement in smart industries in
order to ensure and maintain the well-being of employees
during the manufacturing process. However, despite recent
advances in affective computing, emotion recognition in real-
world conditions remains a challenging task. Existing sensors
that can extract physiological signals associated to emotions
(e.g., hearth rate (HR) [6], skin conductance [7], blood volume
pressure [8], etc.) often require invasive technologies (e.g.,
electrodes), and hence may interfere with the users’ production
tasks. Smart interfaces could beneﬁt from IoT devices in order
to provide emotion recognition from employees using non-
invasive and wearable devices (e.g., cameras, microphones,
wearable hearth rate monitors, smartphones, etc.). These inter-
connected devices could be able to collect and exchange multi-
modal signals associated with speciﬁc emotions of employees.
Once a negative emotion is recognized, the interconnected
objects can control actions to respond and adapt to this emotion
in order to maintain a healthy working environment.
In this paper, a proposed approach to design and implement
emotional IoT devices in smart industry is described. Section
2 reviews the state of the art regarding emotion recognition
from non-invasive and wearable technologies. Section 3 de-
scribes the proposed approach. Conclusions and perspectives
are discussed in Section 4.
II.
EMOTION RECOGNITION FROM NON-INVASIVE AND
WEARABLE TECHNOLOGIES
A number of researchers in affective computing seek to
recognize emotional states through the use of wearable and/or
non-invasive technologies. Many of these technologies could
be used in the context of industries or manufacturing tasks
since they do not interfere with the user behavior. Recent
advances in computer vision and speech recognition have led to
the design of non-invasive systems capable of inferring user’s
emotions from voice [9], facial expressions [10], gestures [11],
and body movements [12]. The advantage of these systems
is that they do not require users to wear any sensors on
their bodies since only cameras or microphones are needed.
However, these techniques could not be precise under certain
manufacturing tasks as they require users to face a camera (or a
kinect) to recognize the emotion correctly. In addition, speech
recognition systems require to isolate the user’s voice from
backgroung noise. The recent development of wearable com-
puting devices has prompted a growing interest in using them
for emotion recognition. Recent works [13] [14] have proposed
intelligent wristbands including multiple sensors capable of
acquiring physiological signals related to different emotions.
Gao et al. [15] used wearable EEG headset technology to
detect the brain’s activity in response to different emotional
states. Olsen et al. [16] showed that the accelerometer data
recorded from a smartphone can be used to infer the user’s
emotional state. Despite many advances in emotion recogntion
through wearable and/or non-invasive technologies, few works
have been interested in detecting more complex emotional
states such as stress, frustration, depression, pain etc. In addi-
tion, most of the proposed approaches do not benefﬁt of the
interconnectivity of these devices to improve the recognition
accuracy. Finally, using emotion recognition technologies in
the context of industries or real-world manufacturing tasks is
still unexplored.
III.
PROPOSED APPROACH
The proposed approach consists in harnessing the intercon-
nectivity of the Internet of Things to detect and respond to neg-
ative complex emotions of employees performing manufactur-
ing tasks, thus ensuring a healthy working environment. In or-
der to implement this approach, two types of connected objects
79
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-565-4
SMART 2017 : The Sixth International Conference on Smart Cities, Systems, Devices and Technologies

are proposed: emotional detectors and emotional actors. Emo-
tional detectors are wearable and/or non-invasive devices (e.g.,
cameras, microphones, wristbands, smartphones, etc.) capable
of recognizing, in real-time, complex negative emotions (e.g.,
stress, frustration, anxiety, etc.) during the realization of several
tasks involved in manufacturing processes. Emotional actors
are smart systems or devices capable to respond properly to
negative emotions of the employees. For example: adapting
the difﬁculty of the task with respect to frustration levels of
employees or activating stress management training systems
installed in smartphones of employees. In order to design
and implement emotional detectors and emotional actors, the
following steps are proposed:
1)
Task identiﬁcation: manufacturing tasks inducing
negative emotions will be identiﬁed. This identiﬁca-
tion can be achieved by applying psychological ques-
tionnaires to employees (e.g., anxiety scores [17])
before and after each task.
2)
Emotion induction protocols: protocols capable of
inducing identiﬁed negative emotions will be de-
signed based on identiﬁed tasks. In these protocols,
negative emotion-induction tasks will be similar to
real-world manufacturing tasks.
3)
Multimodal data collection: emotional induction
protocols will be tested with a large population of
employees. During these protocols, wearable and
non-invasive devices will be used to collect multi-
modal data (e.g., physiological signals, video, audio,
psychological questionnaires) from these employees.
4)
Analysis of emotional features: multimodal data
collected in the previous step will be processed and
analyzed in order to ﬁnd the most relevant features
(e.g., facial expressions, body movements, hearth rate
variability, etc.) associated with different negative
emotions.
5)
Recognition of negative emotions: the relevant fea-
tures found in the previous step will be used to
train machine learning models capable of reconizing
negative emotions from different wearable and/or
non-invasive devices.
6)
Emotional detectors: wearable and non-invasive de-
vices will be integrated into real-world manufacturing
tasks. Wearable devices wil be used by employees
while non-invasive devices will be located in speciﬁc
positions where they will capture data from employ-
ees. Each device will integrate a computer system ca-
pable of extracting relevant features associated to neg-
ative emotions as well as providing syncrhonization
(interconnectivity) with other devices. Each relevant
feature extracted will be sent to a central computer
system capable of recognizing negative emotional
states using trained machine learning models.
7)
Emotional actors: IoT systems capable of decreasing
levels of negative emotions wil be designed and
integrated into manufacturing tasks or wearable de-
vices of employees (e.g., applications installed on
smarthphones of employees).
IV.
CONCLUSIONS AND PERSPECTIVES
A novel approach to integrate emotion recognition IoT
devices in smart industries is presented and described. The
main objective of the proposed approach is to increase the pro-
ductiveness of employees by maintaining a healthy work en-
vironment. Two types of IoT devices are proposed: Emotional
detectors and Emotional actors. Emotional detectors will be
used to recognize negative emotions from employees, while
emotional actors will be used to decrease levels of negative
emotions. Before implementing the proposed approach in real
industries, a more detailed study of different IoT devices and
manufacturing tasks will be required. In this study, several
characteristics will be considered, such as perceived comfort
of wearable devices, possibility of integration in different
manufacturing tasks, etc. Finally, the social acceptability of
using emotional IoT devices in industries must be considered.
REFERENCES
[1]
M. Hermann, T. Pentek, and B. Otto, “Design principles for industrie 4.0
scenarios,” in 49th Hawaii International Conference on System Sciences
(HICSS), 2016, pp. 3928–3937.
[2]
H. Lasi, P. Fettke, H.-G. Kemper, T. Feld, and M. Hoffmann, “Industry
4.0,” Business & Information Systems Engineering, vol. 6, no. 4, 2014,
pp. 239–242.
[3]
D. Giusto, A. Iera, G. Morabito, and L. Atzori, The Internet of Things.
Springer, 2010.
[4]
C. Fisher and N. Ashkanasy, “The emerging role of emotions in work
life: An introduction,” Journal of Organizational Behavior, vol. 21, no. 2,
2000, pp. 123–129.
[5]
P. Spector, S. Fox, and T. Domagalski, “Emotions, violence and
counterproductive work behavior,” in Handbook of workplace violence,
J. B. E.K. Kelloway and J. Hurrell, Eds.
SAGE Publications, Inc,
2005, pp. 29–46.
[6]
D. S. Quintana, A. J. Guastella, T. Outhred, I. B. Hickie, and A. H.
Kemp, “Heart rate variability is associated with emotion recognition:
Direct evidence for a relationship between the autonomic nervous
system and social cognition,” Int J Psychophysiol, vol. 86, no. 2, 2012,
pp. 168–72.
[7]
C. Holmgard, G. N. Yannakakis, H. P. Martinez, and K.-I. Karstoft,
“”to rank or to classify? annotating stress for reliable ptsd proﬁling,”
in ACII 2015, 2015, pp. 719–725.
[8]
M. Khezri, S. M. P. Firoozabadi, and A. Sharafat, “Reliable emotion
recognition system based on dynamic adaptive fusion of forehead biopo-
tentials and physiological signals,” Computer Methods and Programs in
Biomedicine, vol. 122, no. 2, 2015, pp. 149–164.
[9]
C. Parlak and B. Diri, “Emotion recognition from the human voice,” in
21st Signal Processing and Communications Applications Conference
(SIU), 2013, pp. 1–4.
[10]
D. McDuff, “Discovering facial expressions for states of amused,
persuaded, informed, sentimental and inspired,” in ICMI 2016, 2016,
pp. 71–75.
[11]
S. Piana, A. Staglian`o, F. Odone, and A. Camurri, “Adaptive body
gesture representation for automatic emotion recognition,” ACM Trans-
actions on Interactive Intelligent Systems, vol. 6, no. 1, 2016, pp. 1–31.
[12]
G. Castellano, S. D. Villabla, and A. Camurri, “Recognising human
emotions from body movement and gesture dynamics,” in ACII 2007,
2007, pp. 71–82.
[13]
A. M. Khan and M. Lawo, “Wearable recognition system for emotional
states using physiological devices,” in eTELEMED 2016, 2016, pp.
131–137.
[14]
J. A. Rincon, A. Costa, P. Novais, V. Julian, and C. Carrascosa1, “Using
non-invasive wearables for detecting emotions with intelligent agents,”
in SOCO-CISIS-ICEUTE, 2016, pp. 73–84.
[15]
Y. Gao, H. J. Lee, and R. M. Mehmood, “Deep learning of eeg signals
for emotion recognition,” in ICMEW, 2015, pp. 1–5.
[16]
A. F. Olsen and J. Torresen, “Smartphone accelerometer data used for
detecting human emotions,” in ICSAI, 2016, pp. 410–415.
[17]
C. Reynolds and B. Richmond, Revised Childrens Manifest Anxiety
Scale (RCMAS) Manual.
Los Angeles: Western Psychological Ser-
vices, 1985.
80
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-565-4
SMART 2017 : The Sixth International Conference on Smart Cities, Systems, Devices and Technologies

