In the Depths of Hyponymy: A Step Towards Lifelong Learning
Tommaso Boccato∗, Timothy Patten†, Markus Vincze† and Stefano Ghidoni∗
∗Department of Information Engineering, Universit`a degli Studi di Padova, Padova, Italy
Email: tommaso.boccato@studenti.unipd.it, stefano.ghidoni@unipd.it
†Automation and Control Institute, TU Wien, Vienna, Austria
Email: {patten, vincze}@acin.tuwien.ac.at
Abstract—This paper proposes a novel framework for lifelong
learning of semantic classes in order to extend the operational
time of robots deployed in real-world and uncontrolled envi-
ronments. In contrast to the common approach that assumes
ﬁxed object classes, the proposed framework keeps track of
the intra-class variability over time in order to reﬁne the class
deﬁnition encoded into a classiﬁer. A carefully designed metric is
also presented to quantify the intra-class variability, which leads
to automatic triggering of the class restructuring. Experiments
performed with the CIFAR-100 dataset validate the framework
and the measure of intra-class variability.
Keywords–Classiﬁcation; Lifelong learning; Open set learning.
I.
INTRODUCTION
The applications in which a robot should be able to
understand what it sees are countless: human-robot interac-
tion, healthcare, service robotics, industrial robotics, logistics,
connected and autonomous vehicles. A deep knowledge of
the visual properties and functionalities that characterize the
objects is vital in the application of the robot itself, allowing
for better manipulation, navigation or exploration. Very often,
this knowledge is manually encoded into the deployed com-
puter vision algorithms during their training process. Lifelong
learning capabilities [1], however, represent a desirable feature.
The last decade of advancements in deep learning have
led to astonishing results in the applications that respond to
the so called closed-world assumption (i.e., the assumption
that the object classes encountered during the operational
life of a robot are known and ﬁxed a-priori) [2]. Robots,
however, operate in dynamic and uncontrolled environments.
As such, the use of standard approaches in these environments
usually reveals performance drops. A continuous update of
the semantic structure on which a classiﬁer works requires
the introduction of additional complexity in the system [3] [4]
[5]. Moreover, the update should be efﬁcient and downtimes
minimized.
In the presented work, with reference to the classiﬁcation
task, a step is taken towards relaxing the aforementioned
assumption by introducing a novel framework capable of
allowing the reﬁnement of the classes encoded into a classiﬁer
during its operational life. Speciﬁcally, the framework keeps
track of the intra-class variability temporal evolution linked to
the various categories in such a way as to trigger meaningful
class reconﬁguration. In other words, classes characterized by
high intra-class variabilities should be divided into sets of sub-
classes whose labels are related to the original ones through
hyponymy relationships (i.e., words of more speciﬁc meaning
than general or superordinate terms applicable to them). An
example of such a scenario is shown in Figure 1. Clearly, a
(a) poppies
(b) sunflowers
(c) orchids
(d) tulips
Figure 1. Randomly sampled batches extracted from 4 different
CIFAR-100 [6] classes (poppies, sunflowers, orchids,
tulips). All classes belong to the same super-class of flowers. Images
in the top rows show homogeneous visual properties while images in the
bottom rows are characterized by very different visual properties. Yet, all the
batches belong to speciﬁc categories. A question arises: How does the
intra-class variability impact a classiﬁer, and how can an agent (e.g., a
robot) recognize and exploit this phenomenon?
metric capable of quantifying the abstract intra-class variability
concept plays a key role within the framework. Therefore, we
also propose a suitable metric design.
The remainder of the paper is organized as follows. Section
II discusses related work. Section III outlines the lifelong
learning framework and Section IV describes the metric for
intra-class variability. Section V presents the experiments and
results. Section VI concludes and discusses future work.
II.
RELATED WORK
According to survey [7], the classiﬁcation task introduced
within the proposed framework can be categorized as hierarchi-
cal. In particular, the so called “ﬂat classiﬁcation approach” is
pursued. The class hierarchy, a tree data structure representing
hyponymy relationships, is indeed ignored by the classiﬁer,
103
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

that only acts on its leaves. A possible class hierarchy imple-
mentation can follow the WordNet [8] [9] hyponymy network.
However, most of the hierarchical classiﬁcation literature as-
sumes subsets of directed acyclic graphs to be trees in order to
simplify their manipulation. We are currently unaware of works
that exploit incremental or online hierarchical classiﬁcation for
lifelong learning purposes. On the other hand, parallel paths
have been explored in robotics. This section continues with an
overview of relevant literature addressing the open set recog-
nition problem as well as measuring intra-class variability.
The Open World Recognition (OWR) framework is for-
mally deﬁned in [3], with the introduction of the Nearest
Non-Outlier algorithm and the design of a suitable evaluation
protocol; the algorithm is able to incrementally add object
categories while detecting outliers. The OWR framework rep-
resents a starting point for [4] that proposes a deep extension
of a non-parametric model that learns additional categories
without retraining the whole system from scratch. The possi-
bility of retrieving annotated images by autonomously mining
the web constitutes a major contribution of the work. An
attempt to extract label uncertainty from state-of-the-art object
detection systems via dropout sampling is performed in [10].
Novel objects are also introduced to robots by means of
pointing gestures and verbal communication [11]. Finally,
an incremental version of the Regularized Least Squares for
Classiﬁcation algorithm is tested in [12]. The authors also
address the problem of having an unbalanced proportion of
training samples during the algorithm operational life. The
work addressing the open set recognition problem all assume
a deﬁnitive set of training classes. In contrast, we propose a
framework capable of managing concept drifts introduced in
all the classes encoded into the considered classiﬁer.
The treatment of intra-class variability in the literature is
scattered across several diverse ﬁelds, none that are speciﬁc to
robotics or machine vision. For example, the intra-class vari-
ability affecting winter wheat mapping from multi-temporal
Moderate Resolution Imaging Spectroradiometer (MODIS)
Enhanced Vegetation Index (EVI) images is addressed by
generating multiple training sub-classes to decrease the intra-
class differences for the crop type detection [13]. The sep-
arability of the generated sub-classes exploits the Jeffries-
Matusita (JM) Distance; such separability reﬂects the intra-
class variability of the associated original class. A similar
approach is used for liver lesion detection [14] where a multi-
class convolutional neural network (CNN) categorizes image
patches into sub-categories, which are then fused to obtain a bi-
nary lesion/non-lesion classiﬁcation. A novel ofﬂine approach,
instead, is proposed in [15] to model biometric data intra-class
variability and typicality. The method consists of a two stage
algorithm: the former is represented by the clustering of the
input images while the latter performs a template extraction
from the clustered data. Finally, [16] reports a few functions to
represent the covariance matrix of a multi-variate distribution
as a scalar. While these works consider intra-class variability, it
has mainly been investigated from a qualitative and high-level
point of view. Additionally, the concept is applied in domains
different to our study: they do not speciﬁcally address lifelong
learning for a robotic system.
III.
LIFELONG LEARNING FRAMEWORK
Our work builds on the Open Set Learning paradigm and
its framework [3] [4] in order to explore an alternative path
towards the development of an agent characterized by lifelong
learning capabilities. The objective pursued by the deﬁnition of
the framework is to theoretically describe the operational life
of a classiﬁer trained on a set of semantic categories or classes
labeled by the positive integers K1 = {1, . . . , N1}, with
|K1| = N1. The considered model thus reﬁnes its semantic
categories every time the intra-class variability associated to
a speciﬁc category proves to be sufﬁciently high according
to a pre-deﬁned criterion; this concept, as well as the whole
framework deﬁnition, is presented generically in order to
allow the framework to enclose a large variety of future
works. It is therefore natural to deﬁne Kt ⊆ N+ as the set
of classes encoded into the classiﬁer at time t. Moreover,
|Ki| = Ni ≤ |Kj| = Nj when i < j. An example of class
structure temporal evolution is shown in Figure 2.
Let x ∈ Rd be the features associated to a new sample
seen by the classiﬁer. Let Tt ⊆ Rd × St
j=1 Kj be the set
containing all the samples, with the respective labels, seen
by the classiﬁer up to time t (the deﬁnition of Tt does not
allow the repetition of a speciﬁc pair, but such scenario can be
veriﬁed in the operational life of a real classiﬁer; the problem
can be overcome by adding an auxiliary dimension to the space
of features used to enumerate the samples). The set cardinality
can be expressed as |Tt| = Mt + t: the former term refers to
the model training (ground truth labels) while the latter refers
to the model operational life (labels provided by the classiﬁer).
A model, to function within the deﬁned framework, must be
characterized by the following main ingredients.
A. Multi-class Recognition Function
The multi-class recognition function Ft : Rd −→ Kt
exploits the vector function
ψt(x) = [f i
t(x)], ∀i ∈ Kt,
(1)
where the generic per-class recognition function f i
R belongs to a suitable space H. Typically, f i t : Rd −→
t(x) reports
the likelihood of being in class i, the values of f i
t(x) are
normalized across the respective semantic categories and the
multi-class recognition function is implemented as:
Ft(x) = arg max
i∈Kt f i
t(x).
(2)
B. State Update Function
For each semantic category, the corresponding element of
the set should contain all the necessary information to compute
its intra-class variability after the classiﬁcation performed in
the previous time step. The nature of the generic element si
t
is not speciﬁed: it could represent a scalar, a matrix or any
other kind of data structure depending on the needs. Every
time a new sample is classiﬁed, the state St = {si
t}, ∀i ∈ Kt
must be updated accordingly. The state update function U :
St × Rd −→ St+1 is exploited for the purpose. Speciﬁcally,
si
t+1 = U(si
t, x),
(3)
if x is recognized as belonging to class i. Clearly, sj
t+1 =
sj
t, ∀j ̸= i.
At this point, the intra-class variability computation can
ﬁnally be formalized through the function V : St+1 −→ R.
Intuitively, the intra-class variability of class i at time t should
depend on T i
t
= {(x, k) s.t. k = i}; si
t+1 encapsulates
this information allowing an efﬁcient sequential update of the
104
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

metric. Indeed, it could not be feasible to store the entire T i
t
or to use the set for a direct intra-class variability computation.
The additional state St is also motivated by the fact that the V
function, in general, is not invertible; this means that V (si
t+1)
may not be obtainable starting from V (si
t).
Hence, a trigger T : R −→ {0, 1} is deﬁned in accordance
with a criterion selected by the designer in order to establish
whether class i needs to be split or not; it returns 1 if the
considered semantic category has to be replaced by more
speciﬁc sub-classes, 0 otherwise.
C. Labeling Process and Data Retrieval Functions
The labeling process function Lt : P(T i
t ) −→ P(N+ \
St
j=1 Kj), where P(•) denotes the power set, aims to retrieve
the sub-class labels of class i when its split is triggered (i.e.,
T(V (si
t+1)) = 1). It is important to remember that the used
labels are excluded from the function codomain. Again, a
subset T i
t can be exploited to overcome possible limitations in
the available spatial and temporal computational resources.
Once the new categories are collected, the classiﬁer class
structure has to be updated. The following rule is exploited:
Kt+1 = Kt \ i ∪ Nt+1,
(4)
where i is the label of the considered class and Nt+1 represents
the set of labels returned by the labeling process after the
classiﬁcation of the t-th sample.
The data retrieval function R : P(Kt+1) −→ P(Rd ×
Kt+1) is responsible for retrieving the new data Dt+1 ∈
P(Rd × Kt+1) for the incremental training of the model. The
function domain is chosen as to allow approaches capable of
mitigating the effect of catastrophic forgetting [5]. Addition-
ally, it is worth noting that the Lt and R functions must rely
on an external source of information (e.g., the web) and the
performance of their implementations could not be error free.
D. Incremental Learning Function
The incremental learning function is deﬁned as It : P(Rd×
Kt+1)×HNt −→ HNt+1, where Nt+1−Nt = |Nt+1|−1. The
objective of the function is to incrementally update the model
by replacing the obsolete per-class recognition function f i
t(x)
with the ones related to the new |Nt+1| semantic categories.
The retrieved data Dt+1 is exploited for the purpose. Hence,
the state St+1 has to be expanded and the added entries must
be initialized properly. If possible, the model should gradually
adapt to the new class structures without completely retraining.
Every time T(V (si
t+1)) = 0, a simple implicit update of
the Kt, Ft, f i
t subscripts (time steps) has to be performed.
IV.
METRIC FOR INTRA-CLASS VARIABILITY
This section describes the design of a suitable metric for
quantifying the intra-class variability. This can then be used
to trigger the splitting event and therefore the update of the
classiﬁcation model.
Let X be the matrix whose columns are the vectors
belonging to the set {x s.t. (x, k) ∈ T i
t }. In other words,
X contains all the samples, belonging to or classiﬁed as
belonging to class i ∈ Kt, seen by the considered model
up to time t. The matrix can be thought of as the repeated
sampling of a probability distribution over Rd associated with
the environment in which the model is immersed (when the
d-th dimension is reserved for the sample enumeration, the
(a) t = t1
(b) t = t2
(c) t = t3
Figure 2. Example of class structure temporal evolution for the semantic
categories in Figure 1. The leaves (i.e., white nodes) of the trees represent
the classes encoded into the classiﬁer at the considered time steps, where
t1 < t2 < t3. Clearly, classes that are present at time t are labeled by the
elements of Kt. The orchid class is the ﬁrst to be split (t = t2), the
tulip class follows (t = t3). Trees follow the hyponymy in [8] [9].
(a) φ(Xpoppies)
(b) φ(Xorchids)
(c)
φ(Xaerides), φ(Xangrecums)
Figure 3. Our formulation of intra-class variability. The setup is the same
reported in Figure 1 and 2. The intra-class variability of the category shown
in (a) is low while the intra-class variability of the category shown in (b) is
high (sub-classes are shown in (c) for comparison). The shape of the deep
representations reﬂects the hypothesis: φ(Xpoppies) approximates a
hyperball better than φ(Xorchids).
underlying probability distribution should be deﬁned over the
ﬁrst d − 1 dimensions).
If the used classiﬁer belongs to the category of deep
models, φ : Rd −→ Rn can be deﬁned as the function
responsible for extracting deep representations (e.g., the output
of the last layer before the linear ones in ResNet [17] or VGG
[18]) from the generic sample features x ∈ Rd. For simplicity,
the φ notation is overloaded by deﬁning φ(X) as the matrix
obtained applying function φ to X columnwise. Also, φ(X)
can be thought of as the repeated sampling of a new probability
distribution derived from the original one by applying φ to the
multivariate random variable x (depending on the context, x
105
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

can be regarded as the features of a generic image sample or
the associated random vector).
The intuition, therefore, is to link the abstract concept of
intra-class variability to the shape of the φ(X) sampling in the
space of the deep representations. The formulated hypothesis
follows: The lower the intra-class variability of class i, the
better the sampling φ(X) approximates a hyperball. Given
the metric space (Rn, d), with the distance function set to be
d : Rn × Rn −→ R+ ∪ {0}
(x, y) 7−→ d(x, y) = ∥x − y∥,
(5)
the hyperball of radius r > 0 centered in p is deﬁned as
Br(p) = {x ∈ Rn s.t. d(x, p) < r}. Figure 3 provides
a visual explanation of this hypothesis. It is worth noting
that the sampling shape depends on key important elements:
the original probability distribution of the sample features,
the sampling X and, consequently, the exploited dataset; and
function φ, hence, the considered model. Clearly, the concept
of approximation introduced in the formulated hypothesis
needs to be formalized.
A ﬁrst proposal consists of analyzing the per-component
variances of the random vector φ(x). Assuming that φ(x) is
a zero mean vector (otherwise, the mean can be subtracted),
its (sample) covariance matrix can be computed as
Cφ(X) =
1
|T i
t | − 1φ(X)φ(X)T .
(6)
Hence, the considered variances can be identiﬁed in the
diagonal terms of Cφ(X); let
σ = [σ2
1, . . . , σ2
n],
(7)
be the vector containing these terms and
˜σ = [˜σ2
1, . . . , ˜σ2
n]
(8)
=
"
σ2
1
Pn
i=1 σ2
i
, . . . ,
σ2
n
Pn
i=1 σ2
i
#
,
(9)
be its normalized counterpart. Two borderline cases can there-
fore emerge from the analysis of ˜σ:
˜σ2
i = 1
n, ∀i ∈ [1, n],
(10)
is the best approximation of the introduced hyperball and
∃i ∈ [1, n] s.t. ˜σ2
j =
1 if j = i,
0 otherwise,
(11)
is the worst one. The former case characterizes samples that
are homogeneously spread across the n dimensions while the
latter characterizes samples that are spread along a preferential
dimension. At this point, an aggregate score of the ˜σ terms
needs to be computed in accordance with the approximation
introduced in (10) and (11). Consequently, the concept of
entropy is borrowed from Information Theory for the purpose.
Let H(p) = − Pn
i=1 pi log2 pi be the entropy of the generic
distribution p = [p1, . . . , pn]. With reference to the framework
of Section III, the proposed metric is deﬁned to be
V (Cφ(X)) = H(˜σ),
(12)
where the state si
t+1 is set to be Cφ(X) and the vector ˜σ
can be straightforwardly obtained from the diagonal of matrix
(a) Cφ(X)0◦ =

1
0
0
0.01

(b) Cφ(X)45◦ =

0.505
0.495
0.495
0.505

Figure 4. Rotated versions of the same set of samples. The two cases lead to
different aggregated scores.
Cφ(X). It is easy to prove that (10) leads to the maximum
value reachable by metric (12),
H
 "
1
n, . . . , 1
n
#!
= −
n
X
i=1
1
n log2
1
n
(13)
=
n
X
i=1
1
n log2 n
(14)
= log2 n,
(15)
while (11) leads to the minimum one, 0. Note that, in the
presented scenario, the original entropy meaning is abandoned.
The measure, indeed, is only exploited in order to quantita-
tively describe the shape of the considered samples.
Here, a subtle problem arises. The basis in which the set
of deep representations is expressed could not be the most
meaningful one according to the way in which the proposed
metric is computed. In other words, rotated versions of the
same sampling could lead to different aggregated scores;
certainly, such behavior is not desired. Figure 4 shows a
concrete example of the mentioned scenario. The samples in
Figure 4b, φ(X)45◦, are obtained from the ones in Figure 4a,
φ(X)0◦, through φ(X)45◦ = R45◦φ(X)0◦, with
R45◦ =
1
√
2

1
−1
1
1

(16)
Consequently, Cφ(X)45◦ can be computed as Cφ(X)45◦ =
R45◦Cφ(X)0◦ RT
45◦. As reported by the captions, σ0◦2
x ≫ σ0◦2
y
while σ45◦2
x = σ45◦2
y leading to two different aggregated
scores.
A possible solution to overcome the issue is inspired by
Principal Component Analysis (PCA) [19]. The linear relation-
ship shown in Figure 4b is measured by the off-diagonal terms
of Cφ(X) (i.e., the covariances). The larger the magnitudes of
the terms, the higher the redundancy associated to the data. The
goal, therefore, becomes to re-express the original sampling
φ(X) into Y = Rφ(X) according to a new orthonormal basis
(i.e., a rotation) in which the covariance magnitudes related to
CY are minimized: matrix CY should be diagonal. For a
symmetric matrix A, the following decomposition holds [19]:
A = EΛET ,
(17)
where E is a matrix whose columns are the orthogonal
eigenvectors of A and Λ is a diagonal matrix. Recognizing that
Cφ(X) is symmetric [19] and setting A = Cφ(X), R = ET
can be identiﬁed as the required solution (the orthogonal
106
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

eigenvectors stored in E can always be normalized in order
to obtain an orthonormal change of basis):
CY =
1
|T i
t | − 1Y Y T
(18)
=
1
|T i
t | − 1(ET φ(X))(ET φ(X))T
(19)
=
1
|T i
t | − 1ET φ(X)φ(X)T E
(20)
= ET
 
1
|T i
t | − 1φ(X)φ(X)T
!
E
(21)
= ET Cφ(X)E
(22)
= ET (EΛET )E
(23)
= (ET E)Λ(ET E)
(24)
= Λ,
(25)
where (17) is exploited in (23). It is important to highlight
how the diagonal terms of Λ (i.e., the eigenvalues of Cφ(X)),
denoted as
λ = [λ1, . . . , λn],
(26)
represent the variances associated to the sampling φ(X) ex-
pressed in the new selected basis.
Let
˜λ = [˜λ1, . . . , ˜λn]
(27)
=
"
λ1
Pn
i=1 λi
, . . . ,
λn
Pn
i=1 λi
#
,
(28)
be the distribution extracted from λ. The ﬁnal proposal,
therefore, consists of modifying (12) into
V (Cφ(X)) = H(˜λ).
(29)
Again, the borderline cases (10) and (11) can be trivially
translated into the new setup, as well as the metric minimum
and maximum values.
V.
EXPERIMENTS & RESULTS
The presented experiments, and the respective results, aim
to verify the hypothesis formulated in Section IV, and prelim-
inarily investigate the employability of the deﬁned metric in a
real application scenario.
A. Dataset
The experiments exploit the CIFAR-100 dataset [6], a
popular benchmark for testing Computer Vision algorithms.
The dataset consists of 100 “ﬁne” classes (or sub-classes)
containing 600 32 × 32 pixel color images each. All the sub-
classes are grouped into 20 “coarse” classes (or super-classes).
Moreover, CIFAR-100 is divided into 50000 training images
and 10000 testing images.
B. Classiﬁer
The DeepNCM classiﬁer [20] is selected for the experi-
ments. The model is a distance-based classiﬁer that assigns a
sample to the class with the closest mean:
Ft(x) = arg max
i∈Kt −d(φ(x), µi
t−1)
(30)
= arg min
i∈Kt d(φ(x), µi
t−1),
(31)
where
d(φ(x), µi
t−1) = (φ(x) − µi
t−1)T (φ(x) − µi
t−1),
(32)
and
µi
t−1 =
1
|T i
t−1|
X
x s.t. (x,i)∈T i
t−1
φ(x).
(33)
The incremental update of the model is granted by (33). The
exploited implementation of DeepNCM relies on ResNet for
the extraction of the deep representations. Hence, function φ
corresponds to the network layers that precede the classiﬁca-
tion one, as anticipated in Section IV.
It is important to highlight that the class means {µi
t}
and covariance matrices {Cφ(Xi
t)} can be updated sequen-
tially [21] according to:
µi
t = |T i
t−1|µi
t−1 + x
|T i
t−1| + 1
,
(34)
Cφ(Xi
t) = |T i
t−1| − 1
|T i
t−1|
Cφ(Xi
t−1)
+
1
|T i
t−1| + 1(x − µi
t−1)(x − µi
t−1)T .
(35)
Therefore, with reference to the framework of Section III,
the additional state information of the model can naturally be
set to si
t+1 = Cφ(Xi
t) = U(Cφ(Xi
t−1), x) = U(si
t, x). Re-
computing class means and covariance matrices by scratch,
indeed, is prohibitively computationally expensive for large
amounts of samples.
Hence, the choice of the classiﬁer is motivated by the ease
with which the DeepNCM framework can be extended in order
to incorporate St, U and V .
C. Qualitative Hypothesis Veriﬁcation
To verify the presented hypothesis, DeepNCM is trained
(200 epochs, further details on the training procedure can
be found in [20]) on 20 modiﬁed CIFAR-100 super-classes,
250 samples per super-class, made of only one randomly
selected sub-class. This change is introduced to start the metric
computation from an initial set of super-classes that have a
low intra-class variability. Subsequently, 5000 unseen samples
belonging to the same sub-classes exploited during the model
training (i.e., 250 samples per super-class) are supplied to the
classiﬁer. After each classiﬁcation, the experiment assigns the
samples to the respective ground truth categories in order to
evaluate the metric regardless of the accuracy achieved during
the classiﬁer training. The model state is updated and the score
produced by the metric computation is stored. Then, the model
state is re-initialized. Again, 5000 unseen samples (i.e., 250 per
super-class), from randomly chosen sub-classes, different from
the ones of the training phase, are supplied to the classiﬁer and
the corresponding metric scores are computed and stored.
Note that misclassiﬁcations can impact the intra-class
variability. The consequence, however, could be mitigated by
the labeling process function Lt. For example, the function
might be able to recognize if the images in T i
t belong to the
hyponyms of the considered super-class label i in accordance
with the exploited external source of information.
The ﬁrst part of the experiment analyzes the metric behav-
ior in a scenario in which the intra-class variability is expected
to remain constant (referred to as “constant”), while the second
107
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

Figure 5. Metric scores for 4 randomly chosen example classes. Top row reports computations with the V (Cφ(X)) = H(˜σ) deﬁnition while the bottom row
reports computations with the V (Cφ(X)) = H(˜λ) deﬁnition. Solid lines show the “constant” scenario and dashed lines show the “drift” scenario.
Figure 6. Quantitative evaluation of the considered scores/trigger pairs. The
plot on the left reports the produced ROC curves while the plots on the right
report the computed accuracies. White dotted lines refer to the
V (Cφ(X)) = H(˜σ) deﬁnition while black dotted lines refer to the
V (Cφ(X)) = H(˜λ) deﬁnition.
part investigates a scenario in which the intra-class variability
is expected to increase (referred to as “drift”). Moreover, the
metric scores are computed in accordance with both deﬁnition
(12) and (29); this is necessary to understand the beneﬁts
introduced with the computation of the eigenvalues.
Figure 5 shows the obtained results for some example
classes. Considering each super-class separately, most cases
present lower metric values, under the same number of classi-
ﬁed samples, for the “drift” scenario conﬁrming the correctness
of the formulated hypothesis with respect to the considered
dataset/classiﬁer pair. With reference to the V (Cφ(X)) =
H(˜λ) ﬁnal metric deﬁnition, it is interesting to notice that the
“constant” scenario is also characterized by slightly decreasing
trends. The limited amount of training samples, indeed, leads
to an adjustment of the scores during the testing phase.
However, the initial values of the metric are spread into a large
interval resulting in a partial overlapping of the curves related
to the different tested scenarios; such data represents the legacy
of the criterion with which the CIFAR-100 authors decided
to collect the images in the different classes. Additionally,
the initial scores assume intermediate values between 0 and
log2 n = 9. Hence, it is immediate to infer that the considered
initial conﬁguration is placed in an intermediate position
between the borderline cases described in (10) and (11).
D. Quantitative Metric Evaluation
In order to quantitatively evaluate the performance of the
deﬁned metric, the separability of the scores associated to the
“constant” and “drift” scenarios is investigated. Deﬁning
T(V (si
10001)) =
0 if V (si
10001) ≥ θ
1 if V (si
10001) < θ,
(36)
as the family of threshold triggers acting on the metric scores
after the 10000 sample classiﬁcations of the experiment, with
i ∈ K10000 = Kconst ∪ Kdrift (the super-class labels must be
doubled in order to keep track of the model states deleted with
the re-initialization performed after the ﬁrst experiment part)
and θ ∈ R, a True Positive (TP) is denoted as V (si
10001) s.t. i ∈
Kdrift ∧ T(V (si
10001)) = 1 while a True Negative (TN) as
V (si
10001) s.t. i ∈ Kconst ∧ T(V (si
10001)) = 0. The False
Positive (FP) and False Negative (FN) deﬁnitions immediately
follow. Hence, the investigation is performed by computing the
Receiver Operating Characteristic (ROC) curves for both the
V (Cφ(X)) = H(˜σ) and V (Cφ(X)) = H(˜λ) deﬁnitions, and
the respective Area Under the ROC Curve (AUC) integrals.
Figure 6 shows the produced ROCs and two additional
accuracy evaluations. The computation of the eigenvalues
reveals to be necessary with a ﬁnal AUC of 0.79, a net
improvement over the direct use of the per-component vari-
ances, characterized by an AUC of 0.56. The statement is
also conﬁrmed by the binary accuracy plots, with an accuracy
peek of 0.80 for the V (Cφ(X)) = H(˜λ) deﬁnition. Deﬁnition
V (Cφ(X)) = H(˜σ), instead, reveals a performance similar to
that of a random trigger.
It is important to emphasize the naivety of the family of
triggers considered in the evaluation process. Therefore, the
presented results leave room for a promising future application
of the metric in a real scenario.
VI.
CONCLUSION
This paper presented a novel lifelong learning framework
and metric in order to manage and quantify the intra-class
variability of a trained classiﬁer. The proposed work is an
important step to extend the life of robots, thus enabling them
to operate longer in real uncontrolled environments without
the luxury of the closed-world assumption. For future work,
we intend to fully implement the introduced framework (i.e.,
Ft, St, U, V , T, Lt, R and It) and test the full framework’s
real-world performance on a robot platform.
ACKNOWLEDGMENT
The research leading to these results has received funding
from the Austrian Science Fund (FWF) under grant agreement
No. I3969-N30 (InDex). This work was partly supported by
MIUR (Italian Minister for Education) under the initiative
Departments of Excellence (Law 232/2016).
REFERENCES
[1]
S. Thrun and T. M. Mitchell, “Lifelong robot learning,” in The Biology
and Technology of Intelligent Autonomous Agents, 1995, pp. 165–196.
108
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

[2]
A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Advances in Neural
Information Processing Systems 25, 2012, pp. 1097–1105.
[3]
A. Bendale and T. Boult, “Towards open world recognition,” in Proc. of
IEEE Conference on Computer Vision and Pattern Recognition, 2015,
pp. 1893–1902.
[4]
M. Mancini, H. Karaoguz, E. Ricci, P. Jensfelt, and B. Caputo,
“Knowledge is never enough: Towards web aided deep open world
recognition,” in Proc. of IEEE International Conference on Robotics
and Automation, 2019, pp. 9537–9543.
[5]
V. Losing, B. Hammer, and H. Wersing, “Incremental on-line learning:
A review and comparison of state of the art algorithms,” Neurocomput-
ing, vol. 275, 2018, pp. 1261–1274.
[6]
A. Krizhevsky, “Learning multiple layers of features from tiny images,”
Department of Computer Science University of Toronto, Tech. Rep.,
2009.
[7]
C. Silla and A. Freitas, “A survey of hierarchical classiﬁcation across
different application domains,” Data Mining and Knowledge Discovery,
vol. 22, 2011, pp. 31–72.
[8]
G. A. Miller, “WordNet: A lexical database for english,” Communica-
tions of the ACM, vol. 38, no. 11, 1995, pp. 39–41.
[9]
D. Jurafsky and J. Martin, Speech and Language Processing: An In-
troduction to Natural Language Processing, Computational Linguistics,
and Speech Recognition.
Upper Saddle River, N.J.: Pearson Prentice
Hall, 2008.
[10]
D. Miller, L. Nicholson, F. Dayoub, and N. S¨underhauf, “Dropout
sampling for robust object detection in open-set conditions,” in Proc.
of IEEE International Conference on Robotics and Automation, 2017,
pp. 3243–3249.
[11]
S. Valipour, C. Perez, and M. Jagersand, “Incremental learning for robot
perception through hri,” in Proc. of IEEE/RSJ International Conference
on Intelligent Robots and Systems, 2017, pp. 2772–2777.
[12]
R. Camoriano et al., “Incremental robot learning of new objects with
ﬁxed update time,” in Proc. of IEEE International Conference on
Robotics and Automation, 2017, pp. 3207–3214.
[13]
Y. Yang et al., “An improved approach considering intraclass variability
for mapping winter wheat using multitemporal MODIS EVI images,”
Remote Sensing, vol. 11, no. 10, 2019, p. 1191.
[14]
M. Frid-Adar et al., “Modeling the intra-class variability for liver
lesion detection using a multi-class patch-based CNN,” in Proc. of
International Workshop on Patch-based Techniques in Medical Imaging,
2017, pp. 129–137.
[15]
A. J. Abboud and S. A. Jassim, “Image quality guided approach for
adaptive modelling of biometric intra-class variations,” in Proc. of SPIE
7708, Mobile Multimedia/Image Processing, Security, and Applications,
2010, pp. 189–198.
[16]
D. Paindaveine, “A canonical deﬁnition of shape,” Statistics Probability
Letters, vol. 78, no. 14, 2008, pp. 2240–2247.
[17]
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proc. of IEEE Conference on Computer Vision and
Pattern Recognition, 2016, pp. 770–778.
[18]
K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” in Proc. of International Conference on
Learning Representations, 2015.
[19]
J. Shlens, “A tutorial on principal component analysis,” ArXiv, vol.
abs/1404.1100, 2014.
[20]
S. Guerriero, B. Caputo, and T. Mensink, “DeepNCM: Deep nearest
class mean classiﬁers,” in Proc. of International Conference on Learning
Representations - Workshop, 2018.
[21]
D. Savransky, “Sequential covariance calculation for exoplanet image
processing,” The Astrophysical Journal, vol. 800, no. 2, 2015.
109
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

