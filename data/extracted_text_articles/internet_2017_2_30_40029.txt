An Investigation of Tweets Submited by Using Music Player Applications
Yasuhiko Watanabe, Kenji Yasuda, Ryo Nishimura, and Yoshihiro Okada
Ryukoku University
Seta, Otsu, Shiga, Japan
Email: watanabe@rins.ryukoku.ac.jp, t130522@mail.ryukoku.ac.jp,
r nishimura@afc.ryukoku.ac.jp, okada@rins.ryukoku.ac.jp
Abstract—What users are doing at a certain point in time is
important for designing various services and applications in social
media, such as targeted advertisement, news recommendation,
and real-world analysis. As a result, in this study, we investigated
tweets which users submitted when they were listening to music
by using music player applications. We collected 2,000 tweets
including hashtags generated by music player applications and
found about 65% of them were tweets where impressions were
described, 15 % of them were tweets where reasons why users
were listening to music were described, and 10 % of them were
tweets where actions while listening to music were described. We
applied machine learning techniques to detect tweets where two
kinds of actions while listening to music, moving to somewhere
or going to bed, were described. The experimental result shows
that our method is useful for providing behavior based services
and applications in social media.
Keywords–music player application; music content; behavior
based service; Twitter; social media.
I.
INTRODUCTION
Social media, such as Twitter and Facebook, generate large
quantities of data about where users are and what they are
thinking or doing at a certain point in time. Take tweets on
Twitter, (exp 1) and (exp 2), for example. We can understand
the submitters of these two tweets were listening to music. This
is because #nowplaying in (exp 1) and (exp 2) show that these
tweets were submitted by using music player applications.
Users who are using music player applications are thought
to be listening to music.
(exp 1) #nowplaying: ”soundscape” from ”soundscape -
Single” by TRUE (saisei kaisuu: 35) #songsinfo
(#nowplaying: ”soundscape” from ”soundscape -
Single” by TRUE (plays: 35) #songsinfo)
(exp 2) #nowplaying kagerou by ONE OK ROCK on
#onkyo #hfplayer
#nowplaying is a hashtag generated by various music player
applications [1]. Furthermore, #songsinfo in (exp 1) is a
hashtag generated by a music player application, SongsInfo.
Also, #onkyo and #hfplayer in (exp 2) are hashtags generated
by a music player application, HF Player. These hashtags and
the other words in (exp 1) and (exp 2) were all generated
and embedded into these tweets automatically by music player
applications when users submitted these tweets by using them.
As a result, these hashtags enable us to understand that these
users were listening to music when they submitted these tweets
by using music player applications. As mentioned, (exp 1)
and (exp 2) consist of words and hashtags all of which were
generated by music player applications. On the other hand,
(exp 3), (exp 4), and (exp 5) include words generated not only
by music player applications but by users.
(exp 3) #nowplaying: ”Grow Slowly” from ”Hafa Adai”
by iguchi yuka (saisei kaisuu: 3) #songsinfo suki
desu motto kiiteiru
(#nowplaying: ”Grow Slowly” from ”Hafa Adai”
by Iguchi Yuka (plays: 3) #songsinfo I like and
listen to it so many times)
(exp 4) basu wo nogashita node aruki masu !!#now-
playing: ”walk on Believer ♪” from ”walk on
Believer ♪” by toyosaki aki (saisei kaisuu: 96)
#songsinfo
(I will walk because I missed the bus !! #nowplay-
ing: ”walk on Believer ♪” from ”walk on Believer
♪” by toyosaki aki (plays: 96) #songsinfo)
(exp 5) tenshon age te yakin ikuzo #nowplaying NIGHT
FLIGHT by Perfume on #onkyo #hfplayer
(I cheer myself up and go to night shift #now-
playing NIGHT FLIGHT by Perfume on #onkyo
#hfplayer)
Speciﬁcally, the following words in (exp 3), (exp 4), and (exp
5) were generated not by music player applications but by
users.
•
suki desu motto kiiteiru (I like and listen to it so many
times) in (exp 3),
•
basu wo nogashita node aruki masu !! (I will walk
because I missed the bus !!) in (exp 4), and
•
tenshon age te yakin ikuzo (I cheer myself up and go
to night shift) in (exp 5)
In this study, we describe user generated words in tweets
submitted by using music player applications as comments.
We will explain comments in tweets submitted by using music
player applications in Section III. The comments in (exp 3),
(exp 4), and (exp 5) express user’s impression, action, and
reason, respectively.
We can know that the submitters of (exp 3), (exp 4),
and (exp 5) were listening to music when they submitted
these tweets into Twitter. Furthermore, comments in these
tweets enable us to understand what they were thinking and
doing while listening to music. What users are thinking and
doing at a certain point in time is important for designing
various services and applications on social media, such as
targeted advertisement, news recommendation, and real-world
analysis. As a result, in this paper, we investigate tweets
submitted by using music player applications and show what
Twitter users are thinking and doing while listening to music.
Furthermore, we discuss whether tweets submitted by using
music player applications can be classiﬁed by using machine
learning techniques.
The rest of this paper is organized as follows: In Section
II, we survey related works. In Section III, we investigate
24
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-574-6
INTERNET 2017 : The Ninth International Conference on Evolving Internet

tweets submitted by music player applications and show what
the users are thinking and doing while listening to music. In
Section IV, we apply machine learning techniques to classify
tweets submitted by music player applications and discuss
whether we can detect what the users are doing while listening
to music. Finally, in Section V, we present our conclusions.
II.
RELATED WORKS
Twitter enables us to easily submit short messages in
real time from anywhere with internet access. As a result,
Twitter data is a valuable resource for predicting various
trends and events. Taking this in consideration, there are
many studies that have treated Twitter as a social sensor [2].
Aramaki et al. reported that Twitter messages reﬂect the real
world and inﬂuenza related tweets can be extracted by using
Twitter API and NLP techniques [3]. Also, Culotta showed
that inﬂuenza-related Twitter messages can be identiﬁed by
using a document classiﬁcation method and a small number
of ﬂu-related keywords can forecast future inﬂuenza rates [4].
Sakaki et al. investigated the real-time nature of Twitter and
proposed an event notiﬁcation system that monitors tweets and
delivers notiﬁcation promptly [5]. Jansen et al. reported that
microblogging is an online tool for customer word of mouth
communications and potentially rich for companies to explore
as part of their overall branding strategy [6].
Timestamps and geotags embedded into tweets are useful
for treating Twitter as a social sensor. Some researchers con-
ducted studies for event detection using geotags embedded into
tweets. Lee and Sumiya proposed a method for detecting local
events by applying a k-means clustering method to geotagged
Twitter documents [7]. Kamath et al. studied the spatio-
temporal dynamics of Twitter hashtags by using a sample
of 2 billion geo-tagged tweets [8]. However, Watanabe et
al. reported that less than one percent of Twitter posts are
associated with a geolocation [9]. This is because Twitter
users have been slow to adopt geospatial features and only
a small amount of tweets comes with location information
[10]. As a result, recent work has focused on geoinference
for inferring the locations of posts. Yamaguchi et al. pointed
out that most existing methods can be categorized into two
kinds of approaches [11].
•
a content-based approach or
•
a graph-based approach
First, we discuss studies based on the content-based ap-
proach. The content-based approach leverages user-generated
contents in the form of texts. Cheng at al. proposed a method
for estimating a Twitter user’s city-level location based purely
on the content of the user’s tweets [10]. Eisenstein et al.
proposed a method of multi-level generative model that enables
prediction of an author’s geographic location from tweets
[12]. Hecht et al. reported that user’s home country and state
can be reasonably inferred by using simple machine learning
techniques [13]. Han et al. proposed a method of ﬁnding
location indicative words via feature selection and examined
whether the reduced feature set boosts geolocation accuracy
[14]. Schulz et al. proposed a multi-indicator approach for
determining the location where a tweet was created and
the location of the user’s residence [15]. Yamaguchi et al.
proposed an online location inference method that can update
inference results using only newly arriving contents without
using previous contents [11].
Next, we discuss studies based on the graph-based ap-
proach. The graph-based approach is based on the structure
of social graphs where friends are connected. This approach
is based on an idea: users’ social networks are useful for
revealing their locations. For example, Twitter users are more
likely to follow others that are geographically closer to them.
As a result, Rout et al. described this approach as network-
based approach [16]. Wang et al. used communication records
of 6 million mobile phone subscribers and found that the
similarity between individuals’ movements, their social con-
nectedness and the strength of interactions between them are
strongly correlated with each other [17]. Backstrom et al.
pointed out that, by using user-supplied address data and the
network of associations between members of the Facebook
social network, we can directly observe and measure the
relationship between geography and friendship [18]. Rout et
al. proposed an approach to geolocating users of online social
networks, based solely on their friendship connections [16].
Sadilek et al. reported that we can infer people’s ﬁne-grained
location, even when they keep their data private and we can
only access the location of their friends [19].
Kinsella et al. pointed out that understanding where users
are can enable a variety of services that allow us to present
information, recommend businesses and services, and place
advertisements that are relevant to where they are [20]. We
also may say that understanding what users are thinking
and doing can enable a variety of services that are relevant
to what they are thinking and doing. However, few studies
have been made on inferring what users are thinking and
doing while many studies have been made on inferring where
users are. As a result, in this paper, we investigate tweets
submitted by using music player applications and show what
Twitter users are thinking and doing while listening to music.
Furthermore, we discuss whether tweets submitted by using
music player applications can be classiﬁed by using machine
learning techniques.
III.
INVESTIGATION OF TWEETS SUBMITTED BY USING
MUSIC PLAYER APPLICATIONS
In this section, we investigate tweets submitted by music
player applications and show what the users are thinking and
doing while listening to music.
A. The investigation object
Tweets can be classiﬁed into three types [21]:
•
reply
A reply is submitted to a particular person. It contains
“@username” in the body of the tweet. For example,
(exp 6) is a reply to @eitaso.
(exp 6) @eitaso ore to nagoya de seigi no uta wo
utawanaika ? (ˆLˆ) #nowplaying futten
toppa ☆ LOVE IS POWER ☆ / chikyu
bouei bu
(@eitaso Let’s sing a song of justice
in Nagoya? (ˆLˆ) #nowplaying futten
toppa ☆ LOVE IS POWER ☆ / chikyu
bouei bu)
•
retweet
A retweet is a reply to a tweet that includes the original
tweet.
25
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-574-6
INTERNET 2017 : The Ninth International Conference on Evolving Internet

•
normal tweet
A normal tweet is neither reply nor retweet. For
example, (ex 3), (ex 4), and (ex 5) are normal tweets.
Normal tweets are generally submitted to general
public.
In order to investigate tweets submitted by music player
applications and what users are thinking and doing while
listening to music, we collected the following 2000 tweets:
•
1,000 Japanese normal tweets including hashtag
◦
#nowplaying
◦
#songsinfo
obtained from 13 October 2016 to 11 December 2016.
These 1,000 tweets were submitted by 244 users.
•
1,000 Japanese normal tweets including hashtag
◦
#nowplaying
◦
#onkyo
◦
#hfplayer
obtained from 13 October 2016 to 1 December 2016.
These 1,000 tweets were submitted by 345 users.
We did not collect the following tweets even if they include
the hashtags above.
•
replies,
•
retweets, and
•
tweets that include no comments generated by users.
As a result, (exp 1), (exp 2), and (exp 6) were not included in
the collected 2000 tweets. Then, we extracted user generated
comments from them by eliminating the following words.
•
Uniform Resource Locators (URL),
•
hashtags, and
•
words generated automatically by music player appli-
cations.
As a result, we extracted suki desu motto kiiteiru (I like and
listen to it so many times) from (exp 3) as an user generated
comment. Also, we extracted basu wo nogashita node aruki
masu !! (I will walk because I missed the bus !!) and tenshon
age te yakin ikuzo (I cheer myself up and go to night shift)
from (exp 4) and (exp 5), respectively.
B. Tweets which users submit when they use music player
applications
We classiﬁed comments in tweets submitted by using music
player applications into the following four types:
impressions
comments expressing users’ impressions
and evaluations of contents which they played by
using music player applications,
reasons comments expressing reasons why users played
contents by using music player applications,
actions
comments expressing actions which users carried
out when they used music player applications, and
others
comments that cannot be classiﬁed into the three
types above.
Figure 1 shows the classiﬁcation result of the obtained 2,000
Japanese tweets. These tweets were classiﬁed by human ex-
perts. We should notice that some comments can be classiﬁed
into two types. For example, yoi kyoku da! (Good music!) in
(exp 7) is classiﬁed into impressions. On the other hand, ekurea
Figure 1. The classiﬁcation result of the 2,000 tweets which users submit
when they use music player applications (by human experts).
katte kaero! (Let’s buy an eclair and go home!) is classiﬁed
into actions.
(exp 7) yoi kyoku da! ekurea katte kaero!
(Good music! Let’s buy an eclair and go home!)
We shall discuss the following kinds of comments in detail.
•
comments expressing impressions,
•
comments expressing reasons, and
•
comments expressing actions.
1) Comments expressing impressions:
We found many
comments expressing users’ impressions and evaluations of
contents which they played by using music player applications.
Figure 1 shows that more than half of the obtained 2000 tweets
were classiﬁed into ones expressing users’ impressions, such
as (exp 8) and (exp 9).
(exp 8) yoi. suki.
(Good. I like it.)
(exp 9) natsukashi sugi te naki sou
(I was close to tears)
In addition, we found that many comments expressing users’
impressions were related to time, such as (exp 10) and (exp
11).
(exp 10) kono jikantai ni kiku jazz ha, honto ni kimochi ga
ii.
(It’s fun listening to jazz in this time period.)
(exp 11) shinya no Neptunus ha kakubetsu.
(It is wonderful to listen to Neptunus very late at
night.)
Especially, most of them were related to time periods when
users played music by using music player applications.
2) Comments expressing actions: For many years, psychol-
ogy research has shown that people can attend to only one task
at a time [22]. Hyman et al. reported that people talking on
their cell phones while walking ran into people more often,
and did not notice what was around them [23]. However,
listening to music is an exception. We often do something
while listening to music. Actually, we found many tweets
where users described their actions while using music player
applications. (exp 12), (exp 13), (exp 14), and (exp 15) are
examples of comments expressing users’ actions.
(exp 12) tsuukin chu.. sawayakana hare.
26
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-574-6
INTERNET 2017 : The Ninth International Conference on Evolving Internet

Figure 2. The classiﬁcation result of the tweets expressing users’ actions (by
human experts).
(On my way to work.. It ’ s a crisp day.)
(exp 13) oyasumi nasai
(Good night)
(exp 14) desaki deno gyomu shuryo. kiro he. yokohama live
no set list.
(I have ﬁnished my business out of the ofﬁce. On
my way home. The set list of the Yokohama live.)
(exp 15) italo pop kiki nagara kare- shikomu yo
(I will make curry with listening to Italo pop)
In our investigation, three kinds of most commonly actions
described in tweets submitted by using music player applica-
tions are move, sleep, and work. For example, (exp 12) shows
that the submitter was going to work with listening to music.
(exp 13) shows that the submitter was going to sleep, and (exp
14) shows that the submitter had ﬁnished the job. As shown
in Figure 1, we found 215 tweets expressing users’ actions
in the obtained 2,000 tweets which users submit when they
use music player applications. We classiﬁed these 215 tweets
expressing actions into four types:
•
move
•
sleep
•
work
•
others
Figure 2 shows the classiﬁcation result of the tweets expressing
users’ actions. We found some tweets expressing users’ actions
can be classiﬁed into two types. For example, (exp 14) was
classiﬁed into work and move. In particular, user’s action
expressed in desaki deno gyomu shuryo (I have ﬁnished my
business out of the ofﬁce) of (exp 14) was classiﬁed into work.
On the other hand, user’s action expressed in kiro he (On my
way home) of (exp 14) was classiﬁed into move. Further-
more, some tweets expressing users’ actions were classiﬁed
into others. This is because they were classiﬁed into neither
move, sleep, nor work. For example, (exp 15) was classiﬁed
into others. As shown in Figure 2, many tweets expressing
users’ actions were classiﬁed into move and sleep. Hamamura
and Iwamiya conducted the survey on the use of portable
music player [24]. The survey was conducted on 72 college
students, and 65 students and 39 students of them used portable
music players while moving and working, respectively. This
investigation result is in good agreement with ours. On the
other hand, in their investigation result, there were no students
who used portable music players while sleeping. The result
is not in good agreement with ours. Furthermore, Hamamura
and Iwamiya reported that 19 students used portable music
players while shopping. On the other hand, we found only one
comment, (exp 16), submitted by an user who were shopping
while listening to music.
(exp 16) osanpo & okaimono !
(walk & shopping !)
3) Comments expressing reasons: We found many com-
ments expressing users’ reasons why they were listening to
music by using music player applications.
(exp 17) kibun teki ni kikitaku natta
(I have a craving for music)
(exp 18) katte shimatta
(I ﬁnally bought it!)
(exp 17) and (exp 18) shows the reasons why the submitters
of them were listening to music by using music player appli-
cations, feeling and acquisition, respectively. The submitter of
(exp 17) felt an impulse and listened to music. On the other
hand, the submitter of (exp 18) bought music contents and
listened to it.
IV.
DETECTION OF TWEETS EXPRESSING USERS’
ACTIONS
What users are doing at a certain point in time is important
to design various services and applications in social media that
are relevant to what they are doing. If we detect users’ actions
while listening to music automatically, we can design behavior
based services and applications in social media more precisely.
For example, users may have free time to use services and
applications when they are listening to music and going to
somewhere. On the other hand, users may not want to be
disturbed when they are lying down on their beds and listening
to music. As a result, in this section, we discuss whether we
can detect tweets including hashtags generated by music player
applications by using machine learning techniques.
In this study, we used the 2,000 tweets investigated in
Section III for the experimental data. The experimental data
include
•
99 comments expressing users’ actions (move) and
•
62 comments expressing users’ actions (sleep).
In this experiment, we used the support vector machine (SVM)
and maximum entropy method (ME) for data training and
classifying. Table I shows feature s1 ∼ s15 used in machine
learning on experimental data. s1 ∼ s7 were obtained by using
the results of morphological analysis on experimental data. In
the experiments, we used a Japanese morphological analyzer,
JUMAN, for word segmentation of tweets [25]. s8 ∼ s10
and s12 ∼ s14 were obtained by extracting character N-gram
from experimental data. Odaka et al. reported that character
3-gram is good for Japanese processing [26]. s4 ∼ s7 and
s12 ∼ s15 were obtained from ﬁrst sentences of tweets. This
is because, we thought, clue expressions of users’ actions are
often found at ﬁrst sentences of tweets. We conducted this
experiment using TinySVM [27] and maxent [28]. Table II and
Table III show the SVM classiﬁcation result of users’ actions,
move and sleep, in the 2,000 tweets, respectively. Also, Table
IV and Table V show the ME classiﬁcation result of users’
27
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-574-6
INTERNET 2017 : The Ninth International Conference on Evolving Internet

TABLE I. THE FEATURES USED IN MACHINE LEARNING METHODS FOR
DATA TRAINING AND CLASSIFYING TWEETS EXPRESSING USERS’ ACTIONS
WHILE LISTENING TO MUSIC
s1
word unigrams of the comment
s2
word bigrams of the comment
s3
the number of words in the comment
s4
word unigrams of the ﬁrst sentence of the comment
s5
word bigrams of the ﬁrst sentence of the comment
s6
the number of words in the ﬁrst sentence of the comment
s7
the last word of the ﬁrst sentence of the comment
s8
character unigrams of the comment
s9
character bigrams of the comment
s10
character 3-grams of the comment
s11
the length of the comment
s12
character unigrams of the ﬁrst sentence of the comment
s13
character bigrams of the ﬁrst sentence of the comment
s14
character 3-grams of the ﬁrst sentence of the comment
s15
the length of the ﬁrst sentence of the comment
actions, move and sleep, in the 2,000 tweets, respectively. The
experimental result was obtained with 10-fold cross-validation.
As shown in Table II and Table III, we obtained 97% and
99% accuracy when we applied SVM machine learning tech-
niques to detect tweets including comments expressing user’s
move and sleep, respectively. Also, we obtained 97% and 99%
accuracy when we applied ME machine learning techniques
to detect tweets including comments expressing user’s move
and sleep, respectively. Furthermore, the SVM precision of
tweets including comments expressing user’s move and sleep
were 91% and 100%, respectively. Also, the ME precision of
tweets including comments expressing user’s move and sleep
were 95% and 100%, respectively. As a result, our method
is useful to collecting tweets including comments expressing
user’s move and sleep, precisely. On the other hand, the SVM
recall of tweets including comments expressing user’s move
and sleep were 48% and 79%, respectively. Also, the ME
recall of tweets including comments expressing user’s move
and sleep were 41% and 73%, respectively. The reason why
the recall of tweets including comments expressing user’s sleep
was better than that of move was that typical expressions,
such as “oyasuminasai (good night)”, were often used in
comments expressing user’s sleep than move. The experimental
results show that our method is not enough to detect tweets
expressing users’ actions precisely. However, the precisions of
our method show that tweets detected by our method are useful
for understanding what users were doing. As a result, our
method is useful for providing social media services, such as
targeted advertisement, news recommendation, and real-world
analysis.
V.
CONCLUSION
Social media, such as Twitter, generate large quantities of
data about what users are thinking and doing at a certain point
in time. What users are thinking and doing at a certain point in
time is important to design various services and applications
in social media, such as targeted advertisement, news recom-
mendation, and real-world analysis. As a result, in this study,
we investigate tweets submitted by music player applications
and show what users are thinking and doing while listening
to music. Furthermore, we apply machine learning techniques
TABLE II. THE SVM CLASSIFICATION RESULT OF USERS’ ACTIONS
(MOVE) IN THE 2,000 TWEETS INCLUDING HASHTAGS GENERATED BY
MUSIC PLAYER APPLICATIONS.
SVM results
users’ actions
move
others
recall
move
48
51
0.48
others
5
1896
1.00
precision
0.91
0.97
TABLE III. THE SVM CLASSIFICATION RESULT OF USERS’ ACTIONS
(SLEEP) IN THE 2,000 TWEETS INCLUDING HASHTAGS GENERATED BY
MUSIC PLAYER APPLICATIONS.
SVM results
users’ actions
sleep
others
recall
sleep
49
13
0.79
others
0
1938
1.00
precision
1.00
0.99
TABLE IV. THE ME CLASSIFICATION RESULT OF USERS’ ACTIONS
(MOVE) IN THE 2,000 TWEETS INCLUDING HASHTAGS GENERATED BY
MUSIC PLAYER APPLICATIONS.
ME results
users’ actions
move
others
recall
move
41
58
0.41
others
2
1899
1.00
precision
0.95
0.97
TABLE V. THE ME CLASSIFICATION RESULT OF USERS’ ACTIONS
(SLEEP) IN THE 2,000 TWEETS INCLUDING HASHTAGS GENERATED BY
MUSIC PLAYER APPLICATIONS.
ME results
users’ actions
sleep
others
recall
sleep
45
17
0.73
others
0
1938
1.00
precision
1.00
0.99
to detect tweets submitted by music player applications and
discuss whether we can detect tweets expressing what users
are doing while listening to music. The experimental results
show that our method is not enough to detect tweets expressing
users’ actions precisely. However, tweets detected by our
method are useful for understanding what users were doing. As
a result, our method is useful for providing social media ser-
vices, such as targeted advertisement, news recommendation,
and real-world analysis. We are now investigating the phases of
users’ actions, such as start, middle, and end. This is because
the phases of users’ actions enable us to provide more precise
services and applications relevant to users’ actions.
REFERENCES
[1]
Twitter,
“Using
hashtags
on
twitter,”
https://support.twitter.com/articles/49309# [accessed: 2017-6-6].
[2]
T. Sakaki and Y. Matsuo, “Twitter as a social sensor : Can social sensors
exceed physical sensors?” Journal of Japanese Society for Artiﬁcial
Intelligence, vol. 27, no. 1, jan 2012, pp. 67–74.
[3]
E. Aramaki, S. Maskawa, and M. Morita, “Twitter catches the
ﬂu: Detecting inﬂuenza epidemics using twitter,” in Proceedings
28
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-574-6
INTERNET 2017 : The Ninth International Conference on Evolving Internet

of the Conference on Empirical Methods in Natural Language
Processing, ser. EMNLP ’11.
Stroudsburg, PA, USA: Association for
Computational Linguistics, 2011, pp. 1568–1576. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2145432.2145600 [accessed: 2017-6-
6]
[4]
A. Culotta, “Towards detecting inﬂuenza epidemics by analyzing twitter
messages,” in Proceedings of the First Workshop on Social Media
Analytics, ser. SOMA ’10. New York, NY, USA: ACM, 2010, pp. 115–
122. [Online]. Available: http://doi.acm.org/10.1145/1964858.1964874
[accessed: 2017-6-6]
[5]
T. Sakaki, M. Okazaki, and Y. Matsuo, “Earthquake shakes twitter
users: Real-time event detection by social sensors,” in Proceedings of
the 19th International Conference on World Wide Web, ser. WWW ’10.
New York, NY, USA: ACM, 2010, pp. 851–860. [Online]. Available:
http://doi.acm.org/10.1145/1772690.1772777 [accessed: 2017-6-6]
[6]
B. J. Jansen, M. Zhang, K. Sobel, and A. Chowdury, “Twitter power:
Tweets as electronic word of mouth,” J. Am. Soc. Inf. Sci. Technol.,
vol. 60, no. 11, Nov. 2009, pp. 2169–2188. [Online]. Available:
http://dx.doi.org/10.1002/asi.v60:11 [accessed: 2017-6-6]
[7]
R. Lee and K. Sumiya, “Measuring geographical regularities of
crowd behaviors for twitter-based geo-social event detection,” in
Proceedings of the 2Nd ACM SIGSPATIAL International Workshop
on
Location
Based
Social
Networks,
ser.
LBSN
’10.
New
York,
NY,
USA:
ACM,
2010,
pp.
1–10.
[Online].
Available:
http://doi.acm.org/10.1145/1867699.1867701 [accessed: 2017-6-6]
[8]
K. Y. Kamath, J. Caverlee, K. Lee, and Z. Cheng, “Spatio-temporal
dynamics of online memes: A study of geo-tagged tweets,” in
Proceedings of the 22Nd International Conference on World Wide
Web, ser. WWW ’13.
New York, NY, USA: ACM, 2013, pp. 667–
678. [Online]. Available: http://doi.acm.org/10.1145/2488388.2488447
[accessed: 2017-6-6]
[9]
K. Watanabe, M. Ochi, M. Okabe, and R. Onai, “Jasmine: A real-
time local-event detection system based on geolocation information
propagated
to
microblogs,”
in
Proceedings
of
the
20th
ACM
International Conference on Information and Knowledge Management,
ser. CIKM ’11.
New York, NY, USA: ACM, 2011, pp. 2541–
2544. [Online]. Available: http://doi.acm.org/10.1145/2063576.2064014
[accessed: 2017-6-6]
[10]
Z.
Cheng,
J.
Caverlee,
and
K.
Lee,
“You
are
where
you
tweet: A content-based approach to geo-locating twitter users,”
in
Proceedings
of
the
19th
ACM
International
Conference
on
Information and Knowledge Management, ser. CIKM ’10.
New
York, NY, USA: ACM, 2010, pp. 759–768. [Online]. Available:
http://doi.acm.org/10.1145/1871437.1871535 [accessed: 2017-6-6]
[11]
Y. Yamaguchi, T. Amagasa, H. Kitagawa, and Y. Ikawa, “Online
user location inference exploiting spatiotemporal correlations in social
streams,” in Proceedings of the 23rd ACM International Conference
on Conference on Information and Knowledge Management, ser.
CIKM
’14.
New
York,
NY,
USA:
ACM,
2014,
pp.
1139–
1148. [Online]. Available: http://doi.acm.org/10.1145/2661829.2662039
[accessed: 2017-6-6]
[12]
J. Eisenstein, B. O’Connor, N. A. Smith, and E. P. Xing, “A latent
variable model for geographic lexical variation,” in Proceedings of
the 2010 Conference on Empirical Methods in Natural Language
Processing, ser. EMNLP ’10.
Stroudsburg, PA, USA: Association for
Computational Linguistics, 2010, pp. 1277–1287. [Online]. Available:
http://dl.acm.org/citation.cfm?id=1870658.1870782 [accessed: 2017-6-
6]
[13]
B.
Hecht,
L.
Hong,
B.
Suh,
and
E.
H.
Chi,
“Tweets
from
justin
bieber’s
heart:
The
dynamics
of
the
location
ﬁeld
in
user
proﬁles,”
in
Proceedings
of
the
SIGCHI
Conference
on
Human
Factors
in
Computing
Systems,
ser.
CHI
’11.
New
York, NY, USA: ACM, 2011, pp. 237–246. [Online]. Available:
http://doi.acm.org/10.1145/1978942.1978976 [accessed: 2017-6-6]
[14]
B. Han, P. Cook, and T. Baldwin, “Geolocation prediction in
social media data by ﬁnding location indicative words,” in COLING
2012, 24th International Conference on Computational Linguistics,
Proceedings of the Conference: Technical Papers, 8-15 December
2012, Mumbai, India, M. Kay and C. Boitet, Eds.
Indian Institute
of Technology Bombay, 2012, pp. 1045–1062. [Online]. Available:
http://aclweb.org/anthology/C/C12/C12-1064.pdf [accessed: 2017-6-6]
[15]
A. Schulz, A. Hadjakos, H. Paulheim, J. Nachtwey, and M. M¨uhlh¨auser,
“A multi-indicator approach for geolocalization of tweets.” in ICWSM,
E. Kiciman, N. B. Ellison, B. Hogan, P. Resnick, and I. Soboroff, Eds.
The AAAI Press, 2013.
[16]
D. Rout, K. Bontcheva, D. Preot¸iuc-Pietro, and T. Cohn, “Where’s
@wally?:
A
classiﬁcation
approach
to
geolocating
users
based
on
their
social
ties,”
in
Proceedings
of
the
24th
ACM
Conference on Hypertext and Social Media, ser. HT ’13.
New
York,
NY,
USA:
ACM,
2013,
pp.
11–20.
[Online].
Available:
http://doi.acm.org/10.1145/2481492.2481494 [accessed: 2017-6-6]
[17]
D.
Wang,
D.
Pedreschi,
C.
Song,
F.
Giannotti,
and
A.-L.
Barabasi, “Human mobility, social ties, and link prediction,” in
Proceedings of the 17th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, ser. KDD ’11.
New
York, NY, USA: ACM, 2011, pp. 1100–1108. [Online]. Available:
http://doi.acm.org/10.1145/2020408.2020581 [accessed: 2017-6-6]
[18]
L. Backstrom, E. Sun, and C. Marlow, “Find me if you can:
Improving geographical prediction with social and spatial proximity,”
in Proceedings of the 19th International Conference on World Wide
Web, ser. WWW ’10.
New York, NY, USA: ACM, 2010, pp. 61–
70. [Online]. Available: http://doi.acm.org/10.1145/1772690.1772698
[accessed: 2017-6-6]
[19]
A. Sadilek, H. Kautz, and J. P. Bigham, “Finding your friends
and following them to where you are,” in Proceedings of the Fifth
ACM International Conference on Web Search and Data Mining,
ser. WSDM ’12.
New York, NY, USA: ACM, 2012, pp. 723–
732. [Online]. Available: http://doi.acm.org/10.1145/2124295.2124380
[accessed: 2017-6-6]
[20]
S. Kinsella, V. Murdock, and N. O’Hare, “”i’m eating a sandwich
in glasgow”: Modeling locations with tweets,” in Proceedings of the
3rd International Workshop on Search and Mining User-generated
Contents, ser. SMUC ’11.
New York, NY, USA: ACM, 2011, pp. 61–
68. [Online]. Available: http://doi.acm.org/10.1145/2065023.2065039
[accessed: 2017-6-6]
[21]
Y.
Watanabe,
K.
Nakajima,
H.
Morimoto,
R.
Nishimura,
and
Y. Okada, “An investigation of a factor that affects the usage of
unsounded code strings at the end of japanese and english tweets,”
in Proceedings of the Seventh International Conference on Evolving
Internet (INTERNET 2015), Oct 2015, pp. 50–55. [Online]. Available:
https://www.thinkmind.org/index.php?view=article&articleid=internet
2015 2 40 40038 [accessed: 2017-6-6]
[22]
S. Weinschenk, 100 Things Every Designer Needs to Know About
People, 1st ed.
Thousand Oaks, CA, USA: New Riders Publishing,
2011.
[23]
I. E. Hyman, S. M. Boss, B. M. Wise, K. E. McKenzie, and J. M.
Caggiano, “Did you see the unicycling clown? inattentional blindness
while walking and talking on a cell phone,” Applied Cognitive
Psychology, vol. 24, no. 5, 2010, pp. 597–607. [Online]. Available:
http://dx.doi.org/10.1002/acp.1638 [accessed: 2017-6-6]
[24]
M. Hamamura and S. Iwamiya, “Survey on the use of portable audio
devices by university students,” The Journal of the Acoustical Society
of Japan, vol. 69, no. 7, jul 2013, pp. 331–339.
[25]
S. Kurohashi and D. Kawahara, JUMAN Manual version 5.1 (in
Japanese).
Kyoto University, 2005.
[26]
T. Odaka et al., “A proposal on student report scoring system
using
n-gram
text
analysis
method,”
The
transactions
of
the
Institute of Electronics, Information and Communication Engineers.
D-I, vol. 86, no. 9, sep 2003, pp. 702–705. [Online]. Available:
http://ci.nii.ac.jp/naid/110003171273/en/ [accessed: 2017-6-6]
[27]
Taku Kudoh. TinySVM: Support Vector Machines. [Online]. Available:
http://chasen.org/˜taku/software/TinySVM/index.html [accessed: 2017-
6-6]
[28]
M. Utiyama, “Maximum entropy modeling packages,” http://mastarpj.
nict.go.jp/˜mutiyama/software/maxent [accessed: 2010-7-27], 2008.
29
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-574-6
INTERNET 2017 : The Ninth International Conference on Evolving Internet

