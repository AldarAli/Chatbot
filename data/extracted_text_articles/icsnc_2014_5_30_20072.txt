Improving Network Trafﬁc Anomaly Detection for Cloud Computing Services
Ana Cristina Oliveira∗†, Marco Spohn†‡, Reinaldo Gomes†, Do Le Quoc§ and Breno Jacinto Duarte¶
∗Research Group on Convergent Networks (GPRC) - Federal Institute of Paraíba (IFPB)
Campina Grande, Paraíba, Brazil
†Systems and Computing Department (DSC) - Federal University of Campina Grande (UFCG)
Campina Grande, Paraíba, Brazil
‡Federal University of Fronteira Sul (UFFS)
Chapecó, Santa Catarina, Brazil
§Systems Engineering Group (SE Group) - Technical University of Dresden (TU Dresden)
Dresden, Germany
¶Research Group on Usable Security and Ubiquitous Communications - Federal Institute of Alagoas (IFAL)
Maceió, Alagoas, Brazil
Emails: ana.oliveira@ifpb.edu.br,{maspohn,reinaldo}@dsc.ufcg.edu.br,
do@se.inf.tu-dresden.de,brenojac@ifal.edu.br
Abstract—Efﬁcient network trafﬁc anomaly detection is a widely
studied problem on avoiding attacks and unwanted use of
communication infrastructures. Existing techniques to detect,
prevent or monitor these attacks are usually based on known
thresholds, on the construction of proﬁles of normal trafﬁc
patterns, or on signature pattern matching of anomalous behavior
(i.e., viruses and attacks). On the other hand, there are dynamic
techniques that strive to predict the system’s clutter degree;
i.e., the system entropy, supposing that outliers translate to
anomalies. We have developed and analyzed the accuracy of a
network anomaly detector for Cloud Computing Systems based
on the entropy of network trafﬁc metrics. Although entropy-based
solutions do not suppose hard knowledge of the system, the
results point out to the need for more accurate adjustment of
system parameters, taking into consideration the nature of the
data, frequency of events, and the variation of metric values. To
improve the results, unsupervised machine learning algorithms
were added to the anomaly detection process.
Keywords–Network
trafﬁc
anomaly
detection;
Cloud
Computing; Entropy; Machine learning.
I.
INTRODUCTION
Network trafﬁc analysis in cloud environments is one of
the most important tasks in cloud management to guarantee the
quality of services, validate performance of new applications
and services, build accurate network models and detect
anomalies in the cloud. The network trafﬁc produced by
cloud computing systems reveals users’ behavior regarding
service utilization, once all services are accessed via the
network. Trafﬁc analysis and the recognition of all signiﬁcant
application ﬂows are important tools for modeling service
usage, building up patterns for identifying normal system
operations [1].
Additionally,
network
communication
between
cloud
provider and its customers affects signiﬁcantly the performance
of most cloud-based applications [2]. Analyzing network trafﬁc
will provide insights on the performance and behavior of
application and services deployed in clouds. Therefore, it is
necessary to develop network trafﬁc measurement and analysis
techniques to improve availability, performance and security in
cloud computing environments.
On the other hand, managing and analyzing network trafﬁc
of large scale cloud systems is a challenging task. The
techniques used to monitor and analyze trafﬁc in conventional
distributed systems differ from cloud computing systems. In
conventional approaches, assumptions are made that network
ﬂows follow some patterns, which is acceptable for corporate
applications, but cloud applications may have signiﬁcant
changes in trafﬁc patterns [3].
The
term
anomaly
is
fairly
generic
and
it
covers
attacks, unwanted trafﬁc on the network due to misbehaving
applications, packet loss, and undesired trafﬁc injection from
not allowed applications. In this context, one question is raised:
can we actually have a monitoring system able to detect any
sort of network anomaly without looking speciﬁcally for it?
There are works that proposed the idea of identifying any
type of anomaly by monitoring metrics’ entropy [4][5][6]; i.e.,
analyzing the behavior of an application by monitoring the
degree of concentration or dispersion of the target metrics’
distribution.
In this paper, we focus on investigating techniques to detect
anomalies within cloud computing network trafﬁc. We adapted
and implemented the Entropy-based Anomaly Testing (EbAT)
methodology into the context of cloud computing network
trafﬁc monitoring [7]. We strived to identify if EbAT is suitable
for monitoring cloud computing systems. Considering it is a
scalable and lightweight technique, which is a non functional
requirement for cloud computing systems, since they strongly
depend on the network support in large scale.
We concluded that the EbAT technique by itself can be
improved to monitor network trafﬁc, especially for dynamic
systems that may change the network load quickly. To improve
the anomaly detection accuracy for cloud computing network
trafﬁc, we developed a new lightweight approach based on
the EbAT method and unsupervised machine learning anomaly
detection.
The
contributions
of
this
work
are
fourfold:
(i)
implementation and analysis of the EbAT technique applied
to cloud computing network trafﬁc; (ii) feasibility analysis
of the entropy-based method to anomaly detection of cloud
107
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

computing network trafﬁc; (iii) implementation and analysis
of unsupervised machine learning technique for anomaly
detection; (iv) proposal and implementation of a novel
lightweight method to improve network trafﬁc anomaly
detection for cloud computing systems.
The remainder of this paper is organized as follows.
Related work is presented in Section II. The entropy-based and
the machine learning anomaly detection methods are described
in Section III. The novel approach is proposed in Section IV.
The validity of the proposed technique is addressed in Section
V. To conclude, Section VI contemplates ﬁnal remarks.
II.
RELATED WORK
Wang [7] proposed a method for online generic anomaly
detection based on the entropy of any sort of metric distribution
or composition of metrics. Such technique is called EbAT.
The results are achieved by establishing entropy time series
resulting from visual spike detection, or wavelet analysis,
instead of the observation of individual thresholds for the
metrics. However, it assumes that some parameters are
statistically estimated.
Wang et al. [5] conducted an experiment to demonstrate the
feasibility and accuracy of the EbAT method in comparison
with threshold-based anomaly detection procedures. They
injected faulty operations at the application level, which were
analyzed using CPU and memory metrics, and correlation
between read and write operations at virtual disks.
Wang et al. [6] compared the EbAT technique and Gaussian
model for anomaly detection of system metrics (e.g., CPU
and memory). According to their study, the Gaussian model
presented lower values for the recall metric. Notwithstanding,
we believe those techniques may be applied together to support
the anomaly detection decisions.
Benetazzo et al. [8] proposed the analysis of aggregate
trafﬁc by determining empirical rate-interval curves (RICs),
which consist of dividing the ﬂow measurements in quantiles,
striving to delineate scaling properties and other metrological
diagnostics. The RIC-based method characterizes network
trafﬁc without requiring a priori knowledge of the underlying
ﬂow model; however, the proposed method is quite costly.
Nychis et al. [9] analyzed the anomaly detection ability
of different entropy-based metrics. They pointed out that the
port and address distributions are strongly correlated to the
detection capacity. In other words, both metrics provide similar
results when detecting network trafﬁc anomalies. In addition,
the metrics have limited utility in detecting port scan attacks
and ﬂood attacks. The authors also found that behavioral
metrics are less correlated with other metrics. However, their
work was applied in a university network backbone; thus, the
characteristics of the metrics would be different from a cloud
computing environment.
Quan et al. [10] compared two entropy methods, network
entropy and normalized relative network entropy (NRNE)
to classify network behaviors. Two different probability
distributions could share the same entropy value, even
having discrepant probability vectors, and it is a problem
regarding the technique. To avoid this problem, the authors
employed the concept of relative entropy, or Kullback-Leibler
(KL) deviation, which represents the difference between two
probability distributions. The NRNE performed better; on
the counterpart, it demands more input attributes to detect
abnormal network behaviour.
Smith et al. [11] proposed an autonomic mechanism for
detecting anomalies in cloud computing systems similar to
EbAT. The authors deﬁned a set of techniques involving data
transformation to standardize the data format for analysis, an
extraction phase to reduce data size, and unsupervised learning
using clustering algorithms to detect which nodes are behaving
in a different manner from the others (outliers). The anomalies
are computed based on the system behavior.
III.
FUNDAMENTALS
A. Entropy-Based Anomaly Detection
We may divide the EbAT [5][7] technique in three steps:
(a) metric collection; (b) construction of entropy time series;
and (c) processing of entropy time series. This technique
is metric-independent, i.e., we may collect and analyze the
most important metrics related to network trafﬁc, or to
application-level performance, for instance. Those steps are
described in the following sections.
1) Construction of Entropy Time Series: The metrics being
analyzed at a moment are placed into a look-back window of
size n, where n means the number of samples for the metric
(or metrics) that will take part of the analysis. That window
slides as the new metrics are being produced.
Note that multiple types of metrics may be monitored
and analysed altogether. Before constructing the entropy
time series, the data is pre-processed. This pre-processing
consists of normalizing and binning the data. Those phases
are characterized as follows:
Data Normalization Phase: it consists of dividing all
sample values in the current look-back window by the mean
of all values of the same type that belong to the window in
question.
s
′
i,j =
si,j
1
n
Pn
i=1 si,j
(1)
Where:
•
i = {1, .., n} represents the index of the sample that
will be binned in the look-back window;
•
j = {1, .., k} represents the index of the metric, and
k is the number of metrics that are being monitored;
•
si,j is the i-th sample value of the window of the j-th
metric;
•
s
′
i,j is the i-th normalized sample value of the window
of the j-th metric.
Data Binning Phase: it takes all normalized values and
inserts them into a bin, which represents an interval for the
data. The equation that represents the binning is:
108
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

bi,j =





m,
s
′
i,j > r
j s
′
i,j
r/m
k
,
s
′
i,j ⩽ r
(2)
Where:
•
bi,j is the corresponding bin index for s
′
i,j;
•
r is the range of the normalized data. An [0, r] interval
is deﬁned to represent the most representative data;
•
m is the greatest bin index. Since the ﬁrst index is 0,
than there are m+1 bins.
The bin index, bi,j, of the normalized sample value s
′
i,j
will be the last bin index, m, if the sample value is greater
than the range expected, r. The greatest sample values of the
look-back window are placed into the m bin. The rest of the
values are placed into the bins in the range [0, r]. To choose
the adequate bin for those remaining values, we divide the
normalized sample value by the ratio, which give us an idea
of a fair placement of the values into m equal sized intervals.
Finally, the bin index is the ﬂoor value of this division, as
shown in (2).
Let C be the set of metrics being monitored. We may
deﬁne C = {c1, .., ck} , k = 1 .. |C|. We may monitor any
number of metrics. For each metric being monitored, there
is one sample value, and one corresponding bin. Examples
of metrics at application-level are CPU and memory, and at
network-level we may consider delay, bandwidth, and jitter,
for instance.
Event Creation Phase: after normalizing and binning the
data, the next step deals with representing the metrics as events.
Those events are named measurement events, or m-events. One
event, ei, is a vector that contains the bins of all the j metrics
analyzed. One m-event is deﬁned as: ei = ⟨bi,1, bi,2, ..., bi,k⟩.
Entropy Computation and Aggregation Phase: we will
compute the entropy of the events. Then, we may deﬁne E as
the set containing all events in the current look-back window
as:
E = {e1, e2, ..., ev}
Where:
•
Let v be the number of distinct events in the look-back
window, then v ̸= n if there is more than one equal
event;
•
The event ea is equal to event eb if ba,j = bb,j; ∀j ∈
[1, k], ∀ba,j ∈ ea, ∀bb,j ∈ eb, k = |ea| = |eb| .
We will compute the entropy of E, H(E). Firstly, we will
count the number of occurrences of event ei and represent it
by ni, ∀i = [1, v]. In the sequence, the local entropy may be
calculated as stated in (3), where ni/n is the probability of
occurring the event ei [4].
H(E) = −
v
X
i=1
ni
n log ni
n
(3)
2) Processing of Entropy Time Series: The processing
of the entropy time series consists of applying one or
more methods striving to ﬁnd out anomalous patterns. Those
methods may be a combination of spike detection, signal
processing, and subspace analysis, for instance.
B. Machine Learning Anomaly Detection
The unsupervised machine learning technique for anomaly
detection technique is based on ﬁtting the data to a Gaussian
Distribution. The values with very low probability are
considered anomalies. The goal of this probability analysis
is to ﬁnd out a probability threshold that maximizes the
detection accuracy. In this section we will describe how one
can implement such a technique.
We start by collecting measurements of the features (or
metrics, in the context of network performance) that we call
training set (TS). The next step is to ﬁt a Gaussian distribution
on the TS, calculating the probability of every value (the pair
of features).
Given a training set x(1), ..., x(m) (where x(i) ∈ Rn ), let
us estimate the Gaussian distribution for each of the features
xi. For each metric i = 1, ..., n, we need to ﬁnd the parameters
µi and σ2
i that ﬁt the data in the i-th dimension x1
i , ..., xm
i (i.e.,
the samples collected for metric i). The Gaussian distribution
is given by (4), where µ is the mean and σ2 is the variance.
We estimate the parameters µi and σ2
i of the i-th metric by
using (5) and (6), respectively [12].
p(x; µ, σ2) =
1
√
2πσ2 e− (x−µ)2
2σ2
(4)
µi = 1
m
m
X
j=1
x(j)
i
(5)
σ2
i = 1
m
m
X
j=1
(x(j)
i
− µi)2
(6)
After calculating the mean and variance, we ﬁt the data to
the Gaussian model. Then, we observe which values have a
very high probability according to the Gaussian distribution,
and which have a very low probability. The low probability
samples are anomalies. We predict which metric samples are
anomalies by deﬁning a threshold. We choose the threshold,
ϵ, that maximizes the accuracy on a cross validation set [12].
Let
the
cross
validation
set
be
CV
=
{(x(1)
cv , y(1)
cv ), . . . , (x(mcv)
cv
, y(mcv)
cv
)},
where
the
label
y = 1 corresponds to an anomalous metric sample, and
y = 0 corresponds to a normal sample. For each cross
validation element, we computed p(xi
cv), which is the
mass probability of that element according to the Gaussian
distribution. Let the vector of all of these probabilities be
P =
D
p(x(1)
cv ), . . . , p(x(mcv)
cv
)
E
.
We deﬁne the threshold probability, ϵ, by selecting it at a
range from the minimum and maximum values for p(xi
cv) ∈ P.
The ϵ value that maximizes the accuracy will be chosen as an
anomaly indicator to the detection process [12].
109
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

IV.
EFFICIENT ENTROPY-BASED AND MACHINE
LEARNING-BASED ANOMALY DETECTION
We argue that the anomaly detection based on the Gaussian
model may help to set up the input parameters of the EbAT. We
may use the EbAT to label the cross validation set adaptively.
On the other hand, as time passes by, both techniques will
work in synergy.
It is difﬁcult to conﬁgure the input parameters of the EbAT
technique, and to validate the identiﬁed alarms. On the other
hand, from the machine learning perspective, it is difﬁcult to
label the samples without prior knowledge.
The proposed technique has 5 phases: (i) trafﬁc capture;
(ii) threshold estimation with machine learning; (iii) cloud
services’ monitoring; (iv) entropy estimation; (v) anomaly
detection.
We
have
summarized
the
processes
of
both
techniques, described in Sections III-A and III-B, and how
they interact in those phases in Figure 1. The idea is that the
alarms generated by the EbAT will feed the subprocess of
labeling the anomalous trafﬁc packets, and that the threshold
obtained by the machine learning-based technique will also
become a proof when testing if the service metrics contains or
not anomalous packets.
Figure 1. Proposed anomaly detection method.
V.
VALIDATION
A. Methodology
We are going to validate the accuracy of the detection
system using the F-measure metric, also named accuracy, or
F1-score. It represents the harmonic mean of the precision
and recall metrics [13]. Those metrics are described along this
section.
The precision metric is the ratio of the anomalies correctly
detected and the total number of anomalies detected, either
correct or wrong, shown in (7). Then, it characterizes the
percentage of correctly detected anomalies; i.e., if a prediction
algorithm has precision of 90%, then we understand that 90%
of alerts are correct, and, thus, 10% of them are false positives,
or false alarm rate (FAR, 1-Precision).
Precision = # of successful detections
# of total alarms
(7)
The recall metric, in turn, represents the ratio of anomalies
correctly detected and the actual number of anomalies, as
shown in (8). For example, if the recall metric is 55%,
it denotes that 55% of the abnormalities were detected;
consequently, there were 45% of missing alerts.
Recall = # of successful detections
# of total anomalies
(8)
The analysis of those two metrics better expresses the
degree of quality of the anomaly detector. How can we
interpret the precision and recall metrics? When the same
weights are assigned to the two metrics, one obtains the value
of F-measure by (9). The larger the value of F-measure, the
higher the quality predictor.
F1 = 2 ∗ Precision ∗ Recall
Precision + Recall
(9)
B. Experiment Description
To analyze the behavior of the system, we adopted the
model 23-factorial experimental design, which makes up a
total of 8 different treatments. For each treatment, we have
analyzed 3 factors (n, m, and r), each one varying at two
levels, according to Table I. We have analyzed how the three
factors and their interactions inﬂuenced the overall accuracy.
TABLE I. ANALYSED TREATMENTS.
Parameter
# Scenario
1
2
3
4
5
6
7
8
n
5
5
5
5
10
10
10
10
m
6
6
7
7
6
6
7
7
r
5
10
5
10
5
10
5
10
1) DoS
Attack
to
Cloud
Computing
Services:
We
performed a VM-to-VM attack using the open-source tool
Hping3 [14] within a cloud system running one application
called Nutch, which digs up the Web searching for pages. The
tool Hping3 allows us to generate arbitrary packets to ﬂood a
victim host. We set Hping3 on three VMs in a cloud to generate
TCP SYN packets of the Hadoop application targeted to attack
Hadoop ports on two victim VMs. The VMs are part of the
same cloud, including one master node and one slave node, as
shown in Figure 2. The timestamp of the attacks are detailed
in Table II [15].
Figure 2. Nodes that are part of the DoS attack [15].
Then, we have measured the following metrics: (i) number
of packets generated by the Hadoop Distributed File System
(HDFS); (ii) number of packets generated by the MapReduce
110
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

TABLE II. TCP SYN FLOOD ATTACK LIST [15].
Start Time
Finish Time
Attackers
Victims
1
18:23:32
18:29:10
VM3, VM4, VM5
VM1, VM2
2
18:40:14
18:47:58
VM3, VM4, VM5
VM1, VM2
3
19:20:35
19:28:15
VM4, VM5
VM1
4
19:36:29
19:39:35
VM3
VM1, VM2
5
20:09:37
20:11:06
VM4
VM1
6
20:16:36
20:19:08
VM4
VM1
application. The packet rate of those two applications is shown
in Figure 3(a), and the scatterplot of the Map Reduce versus
HDFS application packets is shown in Figure 3(b). We may
observe that the packet rate series shown have correlation,
however they are not synchronized.
0
10
20
30
0
5000
10000
15000
Time (s)
Packets/s (Kpps)
application
HDFS
MapReduce
Income Packet Rate for MapReduce and HDFS
(a) time series
GGGGGGGGGGGGGGGGGGGGG
GG
GGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGGGGGGGGGG
GGGGGGGGGGGGGG
GGGGGGGGGGGGGG
GGGGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGG
GGG
GG
GGG
GGGGGGG
GG
GGGGGG
GGGGGGGGGGGGGGGGGGGGGG
G
GGGGGGGGGGG
GGGGGGGGGGG
GGGGGGGGGGGGGGGG
G
GGGGGG
GGGGGGGGGGGGGG
G
GGGGGGGGG
GGGGGGGGG
GGGGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
G
GG
GGGGGG
GGGGGGGGGG
G
GGGGGGGGGGGGGGGGGG
GGGGG
GG
GGGGGGGGGG
GGGGGGGGGGGGGGGGGG
GG
GGG
G
GG
GGGG
GGGGGG
G
GGGGGGGGGGGGGGG
GG
GGGGGGGGGGGGGGGGGG
GGGGGGGGGG
GGGGG
GG
G
GGGGGGGGGG
GGGGGGG
GGGGGGGGGGGGGG
GGGG
GG
GGGGGG
GGGGGGGG
GG
GGGGG
GGG
GGGGGGGGG
GGGGGG
GGGGG
GG
GGGGGGGGGGGGGGGGGGG
GGG
GGGGGGGGGGGGGGGGG
G
GG
GGGGGGGGGGGGGGG
G
GGGGGGGGGGGGGGGG
GG
GGGGGGG
GGGGGGGGGG
GGGGGGGGG
G
GG
GGG
GG
G
G
GGGGGGGGGG
GGGG
GG
GG
GG
GGGG
GGG
G
GG
GGGGG
G
GGGG
GGGGG
GGGG
GGGG
GG
GGGGGGGGGGGGGGGG
GGGGG
GGGGGGG
GG
GG
GG
GGGGGGGGGGGGGGGGGG
G
GG
G
G
G
G
G
GGGGG
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G GG
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G G
G
G
G
G
G
G
G
G G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G G
G
G
GG
G
G
G
G
G
G G
GGG
G
G
GGG
G GG
G
GG
GGG
GG G
G
GGGG
GGGGG
G
GGG
G
GGGGGGGGGG
GGGGGGGGGGGGGG
GGGGGGGG
GGGGGG
G
GGGGG
GGG
GGGGGGG
GGGGG
GGGGGGGG
GGG
GG
GGGGG
GG
G
GGGGGGGGGGGGG
G
GG
GGGGG
GGGG
GGGG
GGGGGGGGGGGGGG
GGGGGGGGGGGGG
GGGGGGGGGGGGG
G
GGGGG
GGG
GGG
GG
GG
GGG
GGG
GGGGGG
GGGGGG
GGGGG
GG
GG
GGGGGG
GGGGG
GGGGGG
GG
GGG
G
GGG
GGGGGGGGGGGGGG
GGGGG
GGG
GGGGGGGGGGGG
G
GGGGGGGGGGGG
G
GGGGGGGGGGGG
GGGGGGGGGGGGG
GGGGGGGGGG
G
GGGGGGGGGG
GGGG
GGGGGGGG
G
GG
GG
GGG
GGGGG
GGGGGGGG
GGGGG
GGGGGGGGG
GGG
G
GGGGGGGGGG
GGGGGG
GGG
GGG
G
GGGGGGGGGG
GG
GGGGGG
GGGGG
G
GG
GGG
GGGGGGG
GGGGGGGGGGG
G
GGGGGGGGGGG
G
G
GGGGGG
G
GG
G
G
GG
GG
G
G
G
GG
G
GG
G
GG
G
G
GG
G
G
G
G
G
GGG
G
G
G
G
G
GG
G
G
GGG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
GG
G
G
G
G
GG
G
G
G
G
G
GGG
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
GG
G
G
GG
G
G
G
G
G
G
G G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G GG
G G G
G
G
G
G
G G
G
G
G
GGG
G
G
G
GG
G
G
GG
G
GG
G
G
G G
G
G
G
G
G G
G G
G
G G
G
G G
G
G
G
G
G
G
G G
G
G
GG
G
G G
G
G
G G
G
G
G
G GG
GGG
G GG
G
G
G
G
G
G
G
G
G G
GG
G
G
GG
GG
GGGG
GG
GGGG
G
GGGGGG
GGGG
GGGGG
GGGGG
G
GGGG
GGGGGG
GGGG
GGGG
GGG
GGG
GGGGGGGG
GG
G
GGGGGG
GG
GGGGGG
GGG
G
GGG
GGG
GGGGG
GGGGGGGG
G
GGG
GGG
GGGG
G
GGGGGG
GGGG
G
GGGGGGGGGG
G
GGGGGGGGG
GGGGGGGGG
GGGGGGGGGG
GGGGGGGGGG
GGGGGG
GGG
G
GGGGGGGGGG
GG
GGGGGGGG
GGGGG
GGGG
G
GGGGGGGGGG
GG
GGGGGGGG
GGGG
GGGGGG
GGG
GGGGGGG
GG
GGGG
GGG
G
GGGGG
GGGGG
GGGGGG
GGG
G
GGG
GGG
GGGG
GG
GGGGGGGG
GGGGGGGGGG
GGGGGGGGGG
GGG
GGGGGGG
GGGGGGGGGG
GGG
GGGGGGG
GGGG
GGGGGGG
GGGGGGGGGG
GGGGGGGGG
G
GGGGGGGGGG
GGG
GG
GGG
GG
GG
GGGG
GG
GG
GGGGGGGGGG
GGGGGGGGGG
GGGGGG
GGG
G
GGGGGGG
GGG
GGG
GGGG
GGGG
GGGGGG
GGGG
GGGGGGGGGG
GGGGGGGGG
GG
GGGGGGG
G
GGGGGGGG
G
GG
GG
GG
GGGG
GGGGGG
GGG
G
GGGGG
GGGG
GGG
G
GG
GGGG
GGGGGGGGG
GGGG
GGGGGGG
GG
GGGGG
GGGGGGG
GG
GG
GGG
GGGG
G
GGG
GGG
GGG
GGGGGG
GGG
GGGG
GGG
GG
GGGGGGGGGG
G
GGGGG
GG
GGGGGGGGGGGGGGGGG
G
GGG
GGGGGGGGGGGG
GG
GG
GGGGG
GG
GGGG
GG
GG
G
GGGGGGG
GG
GGGGGGG
G
G
GGGGGGG
GG
GGG
GGG
GG
GGG
GGGGGG
GGGGG
GGG
G
GGGGGGGGG
GGGGG
GG
GG
GGG
GGGGGG
GGGGG
GGGG
GGGGGGGGG
GGGGG
GGGG
GGGGGGG
GG
GGGGGG
GGGGG
GG
GGGG
G
GGGGG
GGG
G
GG
GGGGGG
G
GGGGGG
G
GG
GGGG
GG
G
GGG
GGGGGG
GGG
GGGGGG
GGG
GGGGGG
GGGG
GG
GG
G
GGGGGGGG
G
GGGG
GGG
GG
GGGGGGGGG
GG
G
GGGGGG
GG
GGGGG
G
GGG
G
GG
GG
GGGG
GGGG
GGGGGGGG
G
GG
GGG
GG
GGGGGG
GGG
GG
GG
GG
GGGGGGGG
GGGGGGGG
GGGG
GG
GG
GGGGG
GG
GGGGGG
G
GG
GGG
GG
G
GGG
GG
GG
G
GGGG
GGG
GGGGGGGG
G
GGGGGG
G
GGG
GGGG
GGGGGG
G
GGGGGG
GGGGGGG
GGGGGG
GGGGGGG
G
GGGGGG
GGGGGG
GG
GGGG
GGGGGGG
G
GGGGGGG
GGG
GG
GGG
GGGGGG
G
GGGGGG
G
GGGGGG
GGGGGG
GG
G
GGGGG
GG
G
GGGGGGG
GGG
GGGG
GGGG
GGGG
G
GGGGGGG
GG
GGGGG
GGG
GGG
GGGGGGGG
GGGGGGGG
GGG
GGGGG
GGG
GGGGGG
GG
GGG
GG
GGGGG
GGG
GG
GGGG
G
GGGGGG
GGG
GGG
GGGGG
G
GGG
GGGG
G
GGGG
GGG
GGG
GGGG
G
GGGGGGGG
GGG
GGG
GG
GGG
GGG
G
GGGGG
GG
GGGGG
GG
G
GGGGGGG
G
GGGGGG
G
GG
GGGGG
GGGGGGGG
GGGGG
GGG
GGGGG
GG
GGGG
GGG
G
GGGGGGG
G
GG
GGG
GGGGGGG
G
GGG
GGGG
GGGGGGG
G
GGGGGGG
GGGGGG
GG
GGGG
GGG
GGGGGG
G
GGGG
GGGG
GGGG
GGGGGG
GGG
GGGGGG
G
GGGGGG
G
GG
GGGGG
G
GGGGGGG
G
GGGGGG
GGGGG
G
GGGGGGG
GGGGGGG
GGGGGG
G
GGGGGGG
GGGGGG
GG
GGGGGGGG
GGGG
GGG
GGGG
GGG
G
GGGGGGGG
GGGGG
G
GG
GGGGGG
GGGGGGG
G
GGGGGG
G
GGGGG
GGG
GGGGGGG
G
GGGGG
GG
GGGG
GGGG
GGGG
GGG
G
GGGGGG
GG
GGGGGG
G
GGGGGGG
G
GGGGGG
G
GGGGG
G
GG
GGGGG
GG
G
GGG
G
GGGG
G
GG
GG
GGG
GGGGGGGG
G
GGGG
G
G
G
G
GGG
G
G
G
G
G
G
G
GG
G
G
G
GG
G
GGG
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
GGG
GG
G
GG
GGG
G
G
G
G
GG
G
G
GGG
G
G
GGG
GG
G
GG
G
G
G
G
G
GG
GGGGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
GGG
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G G
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G GG
G
G G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G GG
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G G
GG
G
G G
G
G
G
G
G
G
G
GG G
GG
G
GG
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G G G
G
G
G
G
G
G G
G
GG
G
G G
GG
GG G
G
G
GG
G
G
G G
G
G
G
G
G G
G
G G
G
G G
G
G
GG G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G GGGG
G G
G
G
G
G
G
G
G G
G
G
G
G
G
GG
G
GG
G
GGG
GGG
GG
GG
GGGG
GGG
GG
G
G
GG
G
G
GGGG
GG
GG
G
GGG
GGG G
G G
G
GG G
GGGG
GG
G
G G
G G
G GG
G G
GG
GGG G
G
GGGG
G
G
G G
G G
G G
GGG
G
G
GGG
G G
G
GGGGG
G
G
GG G
GG G
G
GGGGG
GGGGG
GGGG
GGG
GGGGGGG
GGGGGG
GG
GGGGG
GGGG
GGG
GGG
GGGG
G
GG
GGGGGGG
GG
GG
GG
GGGG
G
GGGG
GGG
GGGGGGG
GG
GGGG
G
GGGGGG
GGGG
GGG
GGGGGGG
GGGGGGG
GGGGGG
G
GG
GGGGG
GGG
GG
GG
GG
GG
GGG
GGG
GGGGGG
GGG
GGGGGG
G
GG
GGGGG
GGGGG
GG
GGG
GG
G
GGGGGGG
GG
G
GGGG
GG
GGGG
GG
GG
GGGG
G
GGGGG
G
G
GGG
GGG
GGGGGGG
GG
G
GGG
GGG
GGGG
GGGGGGG
GGG
GG
G
GGGGG
GG
GG
GGGGG
GGGG
G
G
GGG
GGG
GGGGG
G
GGGGGG
G
GGG
GGG
G
GGGG
GG
GGG
GG
GG
GGGGG
GG
GGGGGG
GGGGGGG
GGGG
GGG
GGG
GGG
G
GGG
GGG
GGGGGGG
GGGG
GGG
GGGGGG
GGGGGGG
GGG
GGG
G
G
G
GGG
G
GGG
GGG
G
GG
GGGG
GG
GGGGG
GGGGGGG
GGG
GGG
GGGGGG
G
G
GGG
G
G
G
G
G
GG
G
G
G
GG
GGGG
G
GGG
GG
G
G
GGG
GG
G
GGGGGGG
GGGGGG
GG
GG
GGG
G
GGG
GG
GG
GGGGG
G
GGG
G
G
GG
G
GGG
G
GGG G
G
GG
GGG
G
G
G
G
GG
G
G
GG
G
G
GGG
GG
G
GG
GGGGG
G
G
G
G
GGG
G
GG G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G GGG
GG
GGG
GGGG
GGGG
G
G
GGGG
G G
GG
G
GGG
G
GGG
GG
GGG
G
GG
GG
G
GG
GG
GG
GGGGG
G G
G
G
G
G
G GG
G
GG
GGG
G
G
GGG
G
GGGGG
G
G G
G
G
G GGG
GG
G
G
G
G
G G
G
GG
GG
GG
G
G
G
G
G
G
GGGGG
G
GGGGG
GG
GGGGGG
GG
GGGG
GGGGGG
G
GGGGGG
GGGG
GG
GGGGGG
G
GGGGGG
GGGGG
G
GGG
GGG
GG
GG
G
GG
GGGGG
G
GGGGGG
GGGG
G
GGGGGGG
GGGGG
GGG
GGG
GGG
GGG
GGGG
GG
GGGGG
G
GGGG
G
GGGGG
G
GGGGGG
G
GGGGG
G
GGGG
G
G
GG
GGGG
GGGGGGG
GG
GGGG
GGG
GGG
GGG
GGG
GG
GGGG
G
GGGGG
G
GGGGG
G
GGGGG
G
GG
GGGGG
GGGGGG
GGGGG
G
GGGGGG
GGGGG
GG
GGGGG
G
GGGGG
G
GGG
GG
G
GGGG
GGG
GGGGGG
GGG
GGG
GGGGGG
GGGGGGG
GGGGG
GGGGG
G
GGGGGGGGG
G
GG
GGGGGG
GGGGGG
GGGG
GG
GG
GGG
G
GGGGGG
GGGGGG
G
GGGGG
G
GG
GGG
G
GGGGG
G
GGGGG
G
G
GGGGGG
GGGGG
GG
GG
GG
G
GGG
GGGG
GG
GGGG
G
GGGGG
G
GGGGG
G
GG
GGGG
GGGGG
G
GGGG
GG
GGGGGG
GGGGG
G
GGG
GGG
GGGGG
G
GG
GG
GG
G
GGG
GGG
GGGG
GG
GG
G
GGG
GGGGGG
GGG
GGG
GGG
GGG
GGGGG
G
GGGGG
G
GGGGGG
GGGGGG
GG
GGGG
G
GGGG
G
G
GGGGG
G
GGG
GG
G
GGGGGG
GGGGG
G
GGGG
GG
GGGGGG
GGGGGG
GGGGGG
GGGGG
G
GG
GG
GG
GGGGG
G
GGGGG
GGGGGG
GGG
GGG
GGGGG
G
GGGGGG
GGGGGG
GG
GGG
G
GGG
GGG
GGGGG
G
GGGGG
G
GGG
GG
GGGGG
G
GGGGGG
GGG
GGG
G
GGGG
G
GGGGGG
GGGGGG
GGG
G
GG
GGGGG
G
GG
GGGG
GGGGG
GGGGG
G
GGGG
GG
GGGG
GG
GG
GGG
GG
GG
G
GG
GGG
GGG
GG
GGG
GGG
GGG
GGGGG
G
GGGG
GGGGG
G
GG
GGGG
GG
GGGG
GGGGG
G
GG
GGG
G
GGGGG
G
GGG
GG
G
GGG
GGG
GGGG
G
GGGG
GG
GG
GG
GG
GGGG
GG
GG
GG
G
GGGGG
G
GGG
GG
G
GGGG
GG
GG
GGGG
GGG
G
GG
GG
GGG
G
GGG
GG
G
GGGGG
GG
GGGG
GG
GG
GG
GGGGGGGGG
G
GGGGG
G
GGGGG
G
GGG
G
GGG
GGG
G
GGGGG
G
GGGGG
GGGGG
G
GGG
GGG
GGG
G
GG
GGGGGG
GGGG
G
GGGGGG
GG
GGG
GGGGGG
GGGGG
G
GGGG
G
GGG
GGG
GGGG
G
GGGGG
G
GGG
GGG
GGGG
G
GGGGG
G
GGGGG
GGGGG
G
GG
GGG
G
GGGGG
GGGG
GG
GGGGG
GGGGG
G
GGGGGG
GGGG
G
GGGGG
GGGG
G
GGG
GG
G
GGGGG
G
GGGG
G
GGGGG
G
GGG
GGGGGGG
GGGGG
G
GGGGG
GGG
GGG
GGGG
G
G
GGG
GG
GGG
GGG
GGGGG
GGGGG
GG
GGGG
GGGGG
GGG
GGG
GGGGGG
GGG
GG
GGGGGG
GGGGG
GGGGG
G
GGGG
GGG
GG
G
GGGG
GG
GG
GGG
GGGG
GG
GGGGG
GGGGGG
GGG
GG
GG
GGG
G
GG
GGG
GGGG
GG
GGGG
GGGGG
G
GGGG
G
GGG
G
GG
G
GGG
GG
GGG
GG
G
GG
GGG
GGGGG
G
GGGG
GGG
GG
G
GGGGG
G
GGGGG
GG
GG
GG
GGGGG
GGGGGGGGG
G
GGGGG
GGGGG
GGGG
G
GGGG
G
G
GGGGG
GG
GGG
GGG
GGG
GGGGG
GGGGG
G
GGGGG
GGGGG
GGGGG
GGGGG
G
GGGG
G
GGGGG
GGG
GGG
GGGG
G
GGG
G
G
GGG
GGG
GGG
GG
GGGGG
GGGGGG
GGGGG
GG
GG
GG
GGG
GG
GGGGG
GGGG
G
GG
GGG
GG
GGG
G
GG
GGG
GGG
GG
GGGG
G
GGGGGG
GGGG
G
GGGGG
G
GGGGG
GGGGG
GGG
GGG
GG
GGG
GGGG
G
GGGG
GG
GGG
GG
GGGG
G
GGG
G
GG
GGG
GG
G
GGGG
G
GGGG
G
GGG
GG
GGGG
G
GGG
GG
G
GGGGG
GG
GG
G
GGGGG
GGG
G
G
G
GGG
GG
G
GG
G
G
G
G
G
G
GGG
GG
GG
G
GG
GG
G
GG
G
GG
GG
GG
G
G
GG
GG
G
GGG
G
G
G
GGG
G
G
GGGG
G
GGGG
G
GGGG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
GGG
GGG
G
G
GGGG
GG
GGG
GG
GGGG
G
G
GG G
GG
G
GGG
G
G
G
GG
GG
GG
G
GG
GG
G
G G
GG G
G
GG
G
G
G G
GG G
G G
G G
G
G
GGG
G
GG
G G
G
G
GG
GG
G G G
GG
G
GG
GG GG
G
G
G
G
GG
G
G
G G
GG
G
GG
GGGGG
G
GGGG
G
GGG
G
G
GG
GG
G
GGGGG
GGGG
G
GGGG
G
GGGG
G
GGGGG
GGGGGG
GGG
G
GGGGG
GGG
G
G
GG
GGG
GGG
GG
GG
GGG
GGGGG
GGGGG
GGGGG
GGGG
GG
GGG
GG
GGGG
G
GGGG
GGGGG
GGGGG
GGGGG
GGG
GG
GG
GG
GG
GGG
G
G
GG
GG
G
GGG
GG
GGGGG
GGGG
GGG
GG
GGG
GGG
G
GG
GGG
GGGG
GGGG
GGG
GGG
G
GGGGGGG
G
G
GG
G
GGG
GGGG
G
G
G
G
G
G
G
GG
GG
G
GG
G
GG
G
G
GG
G
GGGG
G
GGGG
G
GGGGG
G
G
G
G
G
GGGG
G
GG
GGG
GGG
GG
G
GGGG
GG
GGG
G
G
GG
G
G
GG
GG
G
G
G
G
G
G
G
GG
G
G
G
GGG
GGG
G
GG G
GG
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G G
GG
G
G
G
G
G
GGG
G
G
G
G
G
G
GG G
GG
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
GGGGG
G G
GGG
G
G G
GG
GG G
G
GG
G G
G
G
G
GGG
G
GG
GGGG
GGG
GGG
G
G
G
GG
G G
G
GG G
G
G
G GG G
G
GG
GG
G G
GGG
G G
G
GGG G
G
G
G
G
GGG
G
GGGG G
G G
G
GG
G
GGGGG
G
G
GG
GG
GGGG
G
GG
GG
GG
GG
G
GGGGG
GGG
GG
GGG
GG
GGGGG
GG
GG
G
GGG
G
G
GG
GGG
GGGGG
GGGG
GGG
GG
GGGG
G
GG
GGG
GG
GG
G
GG
GGG
GGGG
GGG
GG
GGGGG
GG
GG
GGG
GG
GGGGG
GGGGG
GG
GG
G
GGGG
G
GGG
GG
GGG
GG
GGG
G
G
GGGG
G
GGGG
GG
GGG
GGG
G
GGG
G
G
GG
GGG
GGGGG
GG
GG
GGG
GG
GGGG
G
GGGG
G
GGG
G
GGGG
G
GG
GG
G
GGG
G
GGGGG
GGGGG
GGG
G
G
GG
GG
G
GGGG
GG
GG
G
GG
GG
GG
GG
G
GGG
G
GGGG
G
GGG
G
GG
GG
G
GGGG
G
GGGG
G
GG
GGG
GGG
G
GGGGG
GGGG
G
GGGGG
GGGG
G
GGG
GG
GGGGG
GG
G
GG
GG
GG
G
GG
GGGG
GG
GGGG
G
GGG
GG
GG
GG
G
GG
GGG
GGGGG
GG
GGG
GGGGG
GGG
G
GGG
GG
GG
GG
G
GGGG
G
GG
GG
G
GGGGG
GGGG
G
GGG
GG
GGGG
G
GGGGG
GGGGG
GGGG
G
GG
GG
G
GGGGG
GGGG
G
GGGGG
GGG
GG
GGG
G
GGGGG
GG
GG
GG
G
GGGG
GGGGG
GGGG
G
GGG
GG
GGGGG
GG
GG
G
GGGG
G
GG
G
G
GGGG
G
GGGG
GG
GGGGG
GGGG
G
GG
GG
G
GGGG
G
GGG
G
GGGG
G
GG
GG
G
GG
GGG
GGG
G
G
GG
GG
GG
GGG
GGGGG
GGGGG
GGG
G
GGGG
GGG
GG
GGGG
G
GGG
GG
GGGG
G
GGG
G
G
GGG
G
GGGGG
GGGG
G
GGG
GG
GGG
G
GGGGG
GGG
GG
GG
GGG
GG
G
GG
G
GG
GG
GGGGG
GGGG
G
GGGGG
GGG
G
GG
GGG
GGGG
G
GGGG
GGGGG
GGG
GG
GGGG
G
GG
GG
GGGG
G
GGGGG
GG
GG
GGGGG
GGGGG
GGGGGGGG
GGGG
G
GGG
GG
GGG
G
GGGG
G
GGG
GG
GGGGG
GG
GG
GGG
GG
GGG
GG
GGGG
GGG
GG
GGGGG
GGG
GG
GG
GG
GGG
G
G
GG
GGG
GG
GG
GGG
GG
GGG
GG
GGG
GG
GG
GG
GG
GG
G
GG
G
GG
GG
GGG
GGG
G
GGGG
G
GGGG
G
GG
GG
GGGGG
GGG
G
G
GGG
G
GGGGG
GG
GG
G
GGGG
G
GGG
G
GG
GGG
GGGG
G
GGG
GG
GG
G
GGGG
G
GGGG
GGG
G
GGGGG
GGGG
G
GGG
G
GGG
G
GGGG
G
GG
G
G
GGG
GG
GG
GG
G
GGG
G
G
GGG
G
GGGGG
GGGG
G
GGGG
GG
GG
G
GGGG
G
GG
GG
GG
GGG
GGG
GG
GGGG
GG
GG
GG
GG
GG
G
GGG
GGGG
G
GGGGG
GGG
G
GGG
GG
GGGG
G
GG
G
G
GG
GG
G
GGGG
G
GG
GG
GGGGG
GG
G
GG
GGG
GG
GGGG
G
GGG
GG
GG
GG
GG
G
GG
GGG
G
GG
GG
G
GG
G
GG
GGGG
GGG
GG
GGGG
GGGGG
GGG
G
GGGG
G
GGGG
G
GGG
G
GG
GGG
GGGG
GGGGG
GGG
GG
GGG
G
GG
GG
G
GGG
G
GGGG
G
GGG
G
GGGG
G
GG
GG
GGGGG
GGGGG
GGG
GG
GG
GGGGG
GG
GGG
GGG
G
GGGGG
GGGG
GGGG
G
GG
GG
GGGGG
GGGG
GGGG
G
GGG
G
GGG
GG
GGG
G
GG
GG
G
GGGGG
GGGG
GGGG
G
GGG
G
GGG
GG
GGG
G
G
GGGG
GG
GGG
GGGG
GG
GGG
GG
GG
GGGG
G
GGGG
GGGG
G
GGG
GGG
GG
GGGG
G
GG
GG
GGG
GG
GGGG
GGG
GG
GGG
G
GGG
G
G
GGG
G
GGG
G
G
GGG
G
GGG
GG
GGG
G
G
GGG
G
GGGG
G
GG
GG
GGGG
G
GGG
G
GG
GG
G
GGGG
GGGGG
GGGG
GGG
GG
GGGG
GG
GGG
GGG
G
GGG
GG
GGG
G
GG
GGG
GGG
GG
GGGG
GG
GGG
GG
G
G
GGGG
G
GGG
G
GG
GGG
GGG
GG
GGG
G
G
GGGG
GGG
GG
GGG
G
GG
GGG
GG
GG
G
GG
GG
GG
GG
G
GG
GG
GGGGG
GGG
G
GGG
G
G
GGG
G
GG
GG
GG
GGG
GG
GG
GGGG
G
GGG
G
GG
GG
G
GGG
G
GGGGG
GGG
G
GGG
G
G
GG
GG
GG
GG
G
GG
GG
GGGGG
GGG
G
GG
GGGG
G
GG
GG
GGGG
G
GG
GG
GGG
GG
GGG
G
GGG
GG
GGG
G
GGGGG
GGGGG
GGG
G
GGG
GG
GG
GG
GGG
GG
GGG
G
GGG
GGG
G
G
GGG
G
GGGG
G
GG
G
G
GGG
G
G
GGGG
GG
GGG
GGG
GGGG
GG
GG
GG
GG
GG
GGG
GGG
G
GG
G
GGGGG
GG
GG
GGG
G
GGG
GG
GGG
G
GGG
G
GGG
G
GG
GG
GGG
GG
GGG
G
GGG
GG
GG
GGG
G
GGG
G
GGG
G
GG
GG
GG
GG
G
GG
GG
GGGG
GGGGG
GGG
G
GGGG
G
GGGG
GGGG
GGGG
G
GG
G
G
GGG
GG
GGG
GG
GG
GGGG
GG
GG
GGG
G
GG
GG
G
GGG
G
GGGG
GGGGG
GGGG
GGGG
GGG
G
GGG
G
GG
GG
G
GGG
GG
GGGG
GGG
GG
GGG
G
GG
GG
GGGG
G
GG
GG
GGG
G
GGG
G
GGG
G
GGG
G
G
GGG
G
GGG
G
GGGGG
GG
GG
G
GGG
G
GG
G
GGG
GG
GGG
G
GGGG
GGGGG
GGG
G
GGGG
G
GG
GG
GGG
G
GGGG
G
GGGG
GGG
G
GGGG
GGG
G
GGGG
G
GGG
G
GG
G
G
GGGGG
GG
GG
GGGG
GGG
GG
GGGG
GGG
GG
GGG
G
GGG
GG
GG
G
GGGG
GGGG
G
GG
G
G
GGG
G
GGGGG
GGG
GGGG
GG
GG
G
GGGG
GG
GG
GGG
GG
GGG
G
GG
GG
GGG
G
G
GG
GG
GGGG
GGGG
G
GGG
G
GGGG
GGGG
G
GGGG
GG
GG
GGG
G
GGG
GG
GGG
G
GGG
G
GG
G
GG
GGG
G
GGGG
G
GG
G
G
GGGG
GGGG
G
GGGG
GG
GG
GGG
G
GGGGG
GGGG
GG
GG
GG
G
G
GGGG
G
GGG
G
GGG
GG
GGGG
GGG
GG
GG
GG
GGGG
GGGGG
GG
GG
GGG
G
GG
GG
GGGG
GGGG
G
GGG
G
GG
GG
GGG
G
GGG
G
GG
G
G
GG
GG
GGGG
GGGG
GGGGG
GGG
G
GGGG
GGGG
GGGG
GGGG
G
GGGG
GG
GG
GG
GGG
GGGG
GGGG
GG
GG
GGG
G
GGG
GG
GGG
G
GGG
G
GGG
G
GGGGG
GGG
G
GGG
G
GGGG
GGGG
GGGGG
GGG
GGGG
GGG
G
GG
GG
G
GGG
G
GG
G
GGG
GG
GGG
GGGG
GGGG
GGG
GGGG
G
GGG
G
GGG
G
GGGGG
GGG
GG
GG
GGGG
GGGG
GG
GGG
GG
G
G
GGG
G
GGG
G
GGGG
GGGG
GGG
G
GGG
G
GGGG
GG
GGG
GGGG
GGG
G
GG
GG
GGGG
GGGG
GGG
G
GG
GG
GG
GG
GGGG
G
GGG
G
GGGG
GG
GGG
GGGG
G
GGG
G
GGG
G
GGG
G
GGGG
G
GGG
G
GGGG
GGGG
GGGG
GGGG
G
GGGG
GGG
G
GGGG
GGG
G
GG
GG
G
GGGG
G
GG
GGG
GGGG
GGGG
GGGGG
GGG
G
GGGG
GGG
G
GGGG
GG
GG
G
GGG
G
GGG
G
GGGG
GGGG
GGGG
GGGG
GG
GG
G
GGG
G
GGGG
GGGGG
GGG
G
GG
GGGG
G
G
GGGG
GGG
G
GGGG
GGG
G
GGG
G
GG
GG
G
GGG
G
G
GG
GG
GGGGG
GG
GG
GGGG
GGG
G
GG
GG
GGGGG
GG
GG
GGGG
G
GGG
G
GG
GG
GGGG
GG
GG
GGGG
GGG
G
GGG
G
GGGG
GGG
G
GG
GG
G
GG
GG
GG
GG
GGG
G
GGG
G
GG
GG
GGG
G
GGG
G
GGG
G
GGG
G
GG
GG
G
GGGG
GGGG
GGG
G
GGG
G
GGGG
GGGG
GGGGG
GGGG
GG
GG
GGGG
GGG
G
GGG
G
GGG
G
GGGG
GGGG
GGGG
GGGGG
GGGG
GGGG
GGGG
GGGG
GGG
G
GGG
G
GGG
G
GG
GG
GG
GG
GGGG
GGGGGG
G
GGG
G
GGG
G
GGG
G
GG
GG
GGG
G
GGG
GG
GG
GGGGG
GG
GGGG
G
GG
GG
GGGG
GG
G
G
GGG
G
GGGG
GGGG
GGG
G
GG
GG
GGGG
GGGG
G
GGGG
GGGG
GGG
G
GGG
G
GGG
G
GG
GG
GGG
G
GGG
G
GGGG
GGGG
G
GG
GG
GGGG
GGG
G
GG
GG
GG
GGGG
GGG
G
GGGG
GGGG
GGGG
GG
GGG
GG
G
GGG
GG
GGGG
GGGG
GGGG
GGGG
GG
G
G
GGG
G
GG
G
G
GG
GG
GGG
G
GGG
G
GG
GG
GG
GG
GGGG
GGGG
GGGG
GG
G
GG
G
GG
GG
GG
GGG
G
GG
GG
GGG
GG
GG
GGG
G
GG
G
GG
GGG
G
GG
GG
GGGG
G
GGGG
GG
GG
GGG
G
GGG
G
GGGG
GGGG
GGG
G
GGGG
GG
G
G
GGGG
GGG
G
GGGG
GGG
G
GGG
G
GG
GG
GG
GG
GG
G
G
GGG
GG
GGGG
GG
GG
GGG
G
GG
GG
GGGG
GGG
G
GGG
G
GGG
G
GG
G
G
GG
GG
GG
G
G
GGG
GG
GG
GG
GG
GG
GG
GGGG
GGG
G
GGG
G
GGGG
GGG
G
GG
GG
GG
GG
GGG
G
GGG
G
GG
G
G
GG
GGGGGG
GG
G
GGGG
GG
G
G
GG
G
GG
G
GGGG
GG
GG
GG
GG
GGG
G
GGG
G
GGGG
GGG
G
GGGG
GGG
G
GG
GG
GGG
G
GGGG
GG
GG
GG
G
G
GGG
GGGG
GGG
G
GGG
G
GG
GG
GGGG
GG
GG
GG
GG
GGGG
GGGG
GG
GG
GGG
GG
GGGG
G
GGG
GGG
G
GGGG
GG
GG
GG
GG
GGG
G
GGG
G
GGG
G
GG
G
GG
G
G
GGG
G
GG
GG
GGG
G
GGGG
GGGG
GG
GG
GG
GG
GGG
G
GGGG
GGG
G
GGG
G
GGG
G
GGGG
GG
GGGG
GG
GG
GGGG
GGG
G
GGG
G
GGG
G
GGGG
G
GGG
GG
GG
GG
GGG
G
GGGG
GGG
GGGG
GGG
G
GG
GG
GG
GG
GG
GG
GG
GG
GG
G
G
GGG
G
GG
GG
GG
G
GG
GG
GGGG
GGGG
GGG
G
GGG
G
GGGG
GG
GG
GGG
G
GGGGG
G
GGGG
GG
GG
GGGG
GGGG
GGGG
GG
GG
GGG
G
GG
GG
GG
GG
GG
GG
GG
GGG
G
GGG
G
GG
GG
GGG
G
GGG
GGG
G
GGG
G
GG
G
G
GGGG
GG
GG
GGG
G
GG
G
GG
G
GGGG
GGG
G
GG
GG
GGGG
GGGG
GGG
G
GGG
GG
GG
GGG
G
GG
GG
GG
GG
GGGG
GGG
G
GG
G
GGGG
GG
GG
GGGG
GGGG
GGG
G
GGGG
GGG
GGGG
GG
G
G
GGG
G
GGGG
GGGG
GG
GG
GGG
GG
GG
GGG
G
GGG
G
GG
GG
GGG
G
GGGG
GG
G
GG
GG
GGG
G
GGGG
G
GG
G
GGGG
GGG
G
GGG
G
GG
G
GGGG
GGGG
GG
GG
GGG
G
GGG
GGG
G
GG
G
G
GG
G
G
GGGG
GGG
G
GGG
GG
GG
GGGG
GG
GG
GGG
G
GG
GG
GG
G
G
GGG
GGG
G
GG
GG
GGGG
GGGG
GGG
GGG
G
GG
GG
GG
GG
GGG
G
GGG
GGG
G
GGGG
GGG
GG
GGG
G
GGGG
G
G
GGGG
GGG
G
GG
GG
GG
G
GGGG
GGG
G
GG
GG
GGG
G
GG
G
GGG
G
GGG
G
GGG
G
GG
GG
GG
GGG
G
GGGG
GG
G
GG
GG
G
GGG
G
GGG
GG
GGG
G
GG
G
G
GGG
GGG
G
GGGG
GGG
G
GGG
GG
GG
GGG
G
GGG
G
GGG
GG
GG
GG
GG
GGG
G
GGG
GGGG
GGGG
GGGG
GGGG
G
G
GGGG
GGG
G
GGG
G
GGG
G
GGG
GGGG
GG
G
G
GG
G
G
GG
G
G
GG
G
GG
GG
GG
G
G
GG
G
G
GGG
GGGG
GGG
G
GGG
GG
G
GG
G
G
GG
GG
GG
GG
GGG
GGG
G
GGG
G
GG
GG
GG
G
GGG
G
GG
GG
GGGG
GG
G
GG
GG
GGGG
GGG
G
GGG
GG
GG
GGGG
GG
GG
GG
G
G
GG
G
GGGG
GG
GG
GG
GG
GGG
GGGG
GG
GG
GGG
G
GGG
GG
GG
GGGG
GGGG
GG
G
GGGG
GG
GG
GGG
G
GGG
GG
GG
GG
GG
GGG
G
GGG
GG
GG
GGGG
GGGG
GGG
GG
GG
GGG
G
GG
GG
GG
GG
GG
G
GGGG
G
GGG
GGG
G
GG
GG
GG
GG
GG
G
GG
GG
GGGG
GGGG
GG
G
GGGG
GGG
G
GGG
G
GGG
G
GGG
GGG
G
GGGG
GG
GG
GGG
GGGG
GGGG
GG
GG
GG
G
GGG
G
GG
GG
GG
GG
GG
G
GG
GG
GG
GG
GG
G
G
GGGGGG
GG
GG
GGG
G
GGGGG
G
GGG
G
GG
GG
GGG
G
GG
GGG
G
GGG
G
GGG
G
GGG
GG
GG
GGG
G
GGG
G
GGG
GGGG
GG
GG
GG
GG
GGG
GGGG
GG
GG
GGG
G
GGG
GGGG
GG
GGG
GGGG
GGG
G
GG
G
GG
G
G
GGG
G
GGG
G
GG
G
GG
G
G
GGG
G
GG
G
G
GG
G
GGG
G
GG
GG
GG
GG
GG
G
GG
GG
GGG
GG
GGGG
GGG
GGG
G
GGGG
GG
G
GGG
G
GG
GG
GG
GG
GG
G
GG
G
GGG
G
GGG
GGG
G
GGG
G
GGG
GGG
GGG
G
GGG
G
GGG
GGG
G
GGG
GG
GG
G
GGGGG
GGG
G
GGG
G
GGG
GG
GG
GGGG
GG
G
GG
G
G
GGG
G
GGG
GG
GG
GG
GG
GGG
GGG
G
GGGG
GGG
GGGG
GG
G
G
GG
G
GGG
G
GGG
GG
GGG
GG
GG
GGG
G
GGG
GGG
G
GG
GG
GG
G
GGG
G
GG
G
GG
GG
GGGG
GG
G
GGG
G
GG
GG
GGGG
GGG
GG
GG
GGG
G
GG
G
GGG
G
GGGG
GGG
GGG
G
GG
G
G
GG
G
GGG
G
GGG
G
GGG
GG
GG
GGG
G
GGG
GG
GG
GGG
GG
GG
GGGG
GG
G
GGGG
GGGG
GGG
GGG
G
GGG
G
GGG
GGGG
GGGG
GG
G
GGGG
GG
GG
GGG
GG
GG
GGG
GGG
G
GG
GG
GGG
GGG
G
GG
G
G
GG
G
GGG
G
GGGG
GGG
GG
GG
GGG
G
GG
G
GG
G
G
GGGG
GG
G
GG
GG
GGGGG
G
GGG
G
GG
GG
G
G
GGGG
GGG
GG
GG
GGG
G
GG
G
GGGG
GGG
G
GGG
GGGG
GGG
G
GGG
GG
GG
GG
GG
GGG
GGG
G
GG
GG
GG
G
GGGG
GGG
G
GGG
GGG
G
GGG
GGGG
GGGG
GG
G
GGG
G
GG
GG
GG
G
GGG
G
GGG
G
GGG
GGG
G
GGGG
GGG
GGG
G
GG
GG
GG
G
GGG
G
GGGG
GGG
GGG
G
GG
G
GG
G
G
GGGG
GG
G
GGGG
GG
GG
GG
G
GGGG
GGGG
GGG
GGG
G
GGG
G
GGG
GG
GG
GG
GG
GGG
GG
GG
GGG
G
GG
G
GG
GG
GGG
GG
GG
GG
GG
GGG
GG
GG
GGGG
GGG
GG
G
G
GGG
G
GG
G
GG
GG
GGGG
GGG
GGGG
GG
G
GGG
GGG
G
GGGG
GG
G
G
GGG
GGG
G
GGGG
GG
GGGG
GGG
GG
GG
GGGG
GGG
GG
GG
GGG
G
GGG
GGG
G
GG
G
GGGG
GGGG
GGG
GGG
G
GG
G
G
GG
G
GGG
G
GG
G
GGGG
GGG
G
GGGG
GG
GGGG
GGG
GGG
G
GGGG
G
G
GG
GG
G
GG
G
GG
GG
GG
GGG
GG
G
G
GGG
GG
GG
GGG
G
GG
G
GGG
GG
GGGG
GG
GG
GGGG
GG
G
GGG
G
GG
G
GG
G
GGGG
GG
G
GGG
G
GG
G
GG
G
G
GGG
G
GGG
GG
GG
GG
G
GGGG
GG
G
GG
GG
GGG
G
GGG
GGG
G
GG
GG
GGG
GGG
G
GGGG
GG
G
GGG
G
GGG
GG
GG
GG
G
GGGG
GGG
G
GG
G
GGG
G
GGG
GGG
G
GGG
GGGG
GGG
GG
GG
GG
GGG
G
GGG
G
GGG
GGGG
GGG
GG
GG
GGG
GGGG
GG
G
GG
GG
GGG
G
GGG
GGG
G
GG
G
GGG
G
GG
G
GGG
G
GGGG
GG
G
GGGG
GGG
GGGG
GGG
GGGG
GG
GG
GG
G
GGGG
GG
G
GG
G
G
GGG
GGG
G
GG
G
GG
GG
GGG
G
GG
G
GGGG
GGG
GGG
G
GG
G
GGGG
GGG
G
GG
GGGG
GG
G
GGG
G
GG
G
GG
G
GGG
GG
G
G
GGG
GG
GG
GGG
GG
GG
GGG
G
GG
G
GGG
G
GGG
GGG
G
GGG
GGG
G
GGG
GG
G
G
GGGG
GG
G
GGG
G
GGG
GGG
G
GGG
GGGG
GGG
GG
GG
GGGG
GGG
GGG
G
GGG
GG
GG
GG
G
GGG
G
GG
GG
GGG
GGG
G
GG
G
GG
GG
GGG
GGG
G
GG
G
G
GGG
GGG
G
GG
G
GGG
G
GGG
GG
GG
GGG
GGGG
GGG
G
GG
G
GGG
G
GG
G
GGG
G
GGG
GGG
GGG
G
GGG
GG
G
G
GG
G
GGG
G
GGG
GG
G
GG
GGGG
GG
G
GG
GG
GG
G
GG
GG
GG
G
GGG
G
GG
G
GG
GG
GGGG
GG
G
GGGG
GGG
G
GGG
GG
GG
GGG
GGGG
GGGG
GG
G
GGG
GG
GGG
GGG
GG
GGG
GG
GG
GG
G
GGG
G
GGG
GGG
G
GGG
GGG
G
GGG
GG
GG
GGG
GGGG
GGG
GG
GG
GGGG
GGG
GG
GG
G
GGG
GGG
G
GGG
GGGG
GGG
GG
GG
GGG
GG
GG
GG
G
GGGG
GGG
GGG
G
GG
G
GG
G
G
GGG
GG
G
G
GG
G
GG
GG
GG
G
GG
GG
GG
G
GGGG
GG
G
GG
GG
GGG
GGGG
GGG
GG
GG
GG
G
GGGG
GG
G
GG
GG
GG
G
GG
G
GG
G
GGG
G
GG
G
GGGG
GG
G
GG
GG
GG
G
GG
GG
GG
G
GGG
G
GGG
GG
GG
GGG
GGG
GG
G
GGG
G
GG
G
GG
G
G
GG
G
GGG
G
GG
G
GGG
G
GGG
GGGG
GG
G
GGGG
GG
G
GG
G
G
GG
G
GGGG
GG
G
GGG
G
GG
G
GG
GG
GGG
GGG
GGG
GG
G
GGGG
GGG
GG
GG
GGG
GGG
G
GG
G
GGGG
GGG
GGG
G
GGG
GGG
G
GG
G
GG
GG
GG
G
GGG
G
GG
G
GGG
G
GGG
GG
G
G
GGG
GG
GG
GG
G
GG
G
G
GGG
GGG
G
GG
G
GG
GG
GG
G
GG
G
G
GGG
G
GGG
GG
GG
GGG
GGGG
GGG
GG
GG
GGG
GGGG
GG
G
GG
0
10
20
30
0
3
6
9
12
MapReduce
HDFS
Packets/s (Kpps)
(b) scatterplot
Figure 3. MapReduce and HDFS packet rate.
We have calculated the entropy values for the pair of
metrics measured in Figure 4. We may observe that the
results are visually difﬁcult to interpret, and establish the right
parameters to propose the anomalous values.
Table III summarizes the results presented in Figure 4.
0.0
0.5
1.0
0
50
100
150
200
250
Time (min)
Entropy
r
5
10
Entropy Time Series for Map Reduce − n=5 and m=6
(a) n = 5; m = 6
0.0
0.5
1.0
0
50
100
150
200
250
Time (min)
Entropy
r
5
10
Entropy Time Series for Map Reduce − n=5 and m=7
(b) n = 5; m = 7
0.0
0.5
1.0
0
50
100
150
200
250
Time (min)
Entropy
r
5
10
Entropy Time Series for Map Reduce − n=10 and m=6
(c) n = 10; m = 6
0.0
0.5
1.0
1.5
0
50
100
150
200
250
Time (min)
Entropy
r
5
10
Entropy Time Series for Map Reduce − n=10 and m=7
(d) n = 10; m = 7
Figure 4. Entropy time series with: n = 5 a, b); n = 10 (c, d).
We observe that the scenario 3 has the best results, i.e., the
precision is 100 %. Although, there are others that provide
good accuracy results as well, e.g., over 90 %.
2) DoS Attack to a Network Provider Backbone: We have
validated our work using a trace from the Pohang University
111
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

TABLE III. SUMMARY OF THE RESULTS OF THE ANOMALY
DETECTION METRICS OF THE CLOUD DOS.
#Scenario
TP
FP
FN
Recall
Precision
F1
1
9967
711
1077
0.902481
0.933414
0.917687
2
543
0
10501
0.0491670
1
0.093726
3
11044
0
0
1
1
1
4
2181
0
8863
0.1974828
1
0.329830
5
10397
1749
647
0.941416
0.856002
0.896680
6
153
9
10891
0.013854
0.944444
0.027308
7
10638
1773
406
0.963238
0.857143
0.907099
8
2402
155
8642
0.217494
0.939382
0.353209
of Science and Technology (POSTECH) that contains trafﬁc
of a famous DDoS attack to government and commercial
websites in South Korea in July 7th, 2009. Those attacks were
probably launched by a special cyber warfare unit belonging
to North Korean Army. During the attack, many computers in
POSTECHs network campus were zombies. We have analysed
one hour of network capture that contains the packets from the
attack [16].
We measured and analysed two features of the network
trafﬁc: (i) the income throughput, and (ii) the outgoing
throughput. The throughput series are depicted in Figure 5(a),
and the scatterplot is in Figure 5(b). For this trace, we have
applied the Gaussian model on a cross validation set to identify
the threshold probability of having an anomalous sample.
Then, we have used this value to predict which packets took
part of the DoS attack.
0
50
100
150
200
0
20
40
60
Time (min)
Throughput (Mbps)
Direction
In
Out
Income and Outgoing Throughput
(a) time series
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
GG
G
G
G
G
GGG
G
G
G
GG
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
GG
G
G
GG
G
GG
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GGG
G
GG
GG
G
G
G
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
GGG
GG
GG
G
G
G
GG
G
G
GG
G
G
G
G
G G
G
G
G
G
GG
GG
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G G
G
G
G
G
GG
G
G
G
G
G
GGG
G
G
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
GG
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
GG
GG
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
GGG
G
G
G
G
GG
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
GGG
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
GG
G
G
G
GG
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
GGG
G
G
G
G
G
G
G
GG
G
GG
G
GGG
G
GGG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
GG
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
GGG
G
G
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
GG
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
GGG
G
G
GG
G
GGG
GG
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
GG
G
GG
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
GG
GGG
G
G
G
G
G
G
GG
G
GG
G
GG
G
G
G
G
GG
G
G
GG
GG
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
GG
G
G
G
G
G
G
GG
GG
G
G
G
G
G
G
G
G
G
G
G
G
G
30
40
50
0
50
100
150
200
Income
Outgoing
Throughput (Mbps)
(b) scatterplot
Figure 5. Income and outgoing throughput.
We have summarized the mean results obtained for the 8
different treatments in Table IV. We may realize that there are
two treatments that contributes to the best accuracy results,
which are the ﬁrst and third scenario (in bold font). In this
sense, we restricted our scope, and may also choose setup
parameters from one of them both that lead this particular
system to provide the best predictions about the presence of
anomalies in the trafﬁc. In our case, we selected the third
scenario, which parameters are n = 5, m = 7, and r = 5.
At those conﬁgurations, the F-measure reached 100 %.
TABLE IV. SUMMARY OF THE RESULTS OF THE ANOMALY
DETECTION METRICS OF THE NETWORK PROVIDER.
#Scenario
TP
FP
FN
Recall
Precision
F1
1
13
0
0
1
1
1
2
0
0
13
0
NA
NA
3
13
0
0
1
1
1
4
0
0
13
0
NA
NA
5
12
9
1
0.923077
0.571429
0.705882
6
5
2
8
0.384615
0.714286
0.5
7
10
8
3
0.769231
0.555556
0.645161
8
0
0
13
0
NA
NA
We found out that the accuracy of the entropy-based
anomaly detection mechanism itself directly depends on a
further analysis of the trafﬁc. Those assumptions, however,
are too strong for a detection system and constitute barriers to
the implementation of such a technique.
VI.
FINAL REMARKS
Cloud computing systems have peculiar characteristics,
such as aggregation of many different services, which makes it
difﬁcult to classify applications either by techniques based on
packet payload signature matching, or probabilistic methods
for the identiﬁcation of trafﬁc patterns, and proﬁle of trafﬁc
normal behaviors. Those characteristics bring up challenges
regarding online trafﬁc monitoring and analysis, which should
be done at wire speed while digging a high volume of data.
Choosing one optimal trafﬁc anomaly detection technique
is a complex task, because in order to have good results, we
may have to know several characteristics of the trafﬁc that are
not known in practice. Another challenge is to develop high
performance network packet sampling, and speeding up data
processing, since the volume of trafﬁc that traverses the cloud
service provider is of the order of gigabits per second.
The obtained results show that when applying the EbAT
itself, there is still the need to better analyze and comprehend
the trafﬁc patterns, ﬁnding out the normal behavior of the
monitored systems, based on predictions using historical data,
or feedback from experts on the business and network trafﬁc,
or by making new assumptions regarding the trafﬁc. In this
sense, we argue that the accuracy results may be improved by
the aid of probability models, such as anomaly detection using
the Gaussian model.
As a conclusion, we found out that it was still necessary
to investigate new solutions to the cloud computing network
anomaly detection problem. As future work, we intend to
improve the anomaly detection mechanism by developing and
analyzing new techniques to increase the detection accuracy,
112
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

and to propose a parallel model for capturing and processing
the network packets at wire speed.
REFERENCES
[1]
A. C. Oliveira, H. Chagas, M. Spohn, R. Gomes, and B. J. Duarte,
“Efﬁcient network service level agreement monitoring for cloud
computing systems (to appear),” in Computers and Communications
(ISCC), 2014 IEEE Symposium on, June 2014.
[2]
S.
Shetty,
“Auditing
and
analysis
of
network
trafﬁc
in
cloud
environment,”
in
Proceedings
of
the
2013
IEEE
Ninth
World
Congress on Services, ser. SERVICES ’13.
Washington, DC, USA:
IEEE Computer Society, 2013, pp. 260–267. [Online]. Available:
http://dx.doi.org/10.1109/SERVICES.2013.42
[3]
Q.
Zhang,
L.
Cheng,
and
R.
Boutaba,
“Cloud
computing:
state-of-the-art and research challenges,” Journal of Internet Services
and Applications, vol. 1, no. 1, Apr. 2010, pp. 7–18. [Online]. Available:
http://www.springerlink.com/index/10.1007/s13174-010-0007-6
[4]
C. Wang, “Ebat: online methods for detecting utility cloud anomalies,”
in Proceedings of the 6th Middleware Doctoral Symposium, ser.
MDS ’09.
New York, NY, USA: ACM, 2009, pp. 4:1–4:6. [Online].
Available: http://doi.acm.org/10.1145/1659753.1659757
[5]
C. Wang, V. Talwar, K. Schwan, and P. Ranganathan, “Online
detection of utility cloud anomalies using metric distributions,”
in 2010 IEEE Network Operations and Management Symposium
-
NOMS
2010.
Ieee,
2010,
pp.
96–103.
[Online].
Available:
http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5488443
[6]
C. Wang, K. Viswanathan, L. Choudur, V. Talwar, W. Satterﬁeld, and
K. Schwan, “Statistical techniques for online anomaly detection in data
centers,” in Integrated Network Management (IM), 2011 IFIP/IEEE
International Symposium on, May 2011, pp. 385–392.
[7]
S. C. Wang, K. Q. Yan, and S. S. Wang, “Achieving High Efﬁcient
Agreement with Malicious Faulty Nodes on a Cloud Computing
Environment,” Industrial Engineering, 2009, pp. 3–8.
[8]
L. Benetazzo, G. Giorgi, and C. Narduzzi, “On the analysis of
communication and computer networks by trafﬁc ﬂow measurements,”
Instrumentation and Measurement, IEEE Transactions on, vol. 56, no. 4,
Aug 2007, pp. 1157–1164.
[9]
G.
Nychis,
V.
Sekar,
D.
G.
Andersen,
H.
Kim,
and
H.
Zhang,
“An
empirical
evaluation
of
entropy-based
trafﬁc
anomaly detection,” in Proceedings of the 8th ACM SIGCOMM
Conference
on
Internet
Measurement,
ser.
IMC
’08.
New
York, NY, USA: ACM, 2008, pp. 151–156. [Online]. Available:
http://doi.acm.org/10.1145/1452520.1452539
[10]
Q. Quan, C. Hong-Yi, and Z. Rui, “Entropy based method for network
anomaly detection,” in Dependable Computing, 2009. PRDC ’09. 15th
IEEE Paciﬁc Rim International Symposium on, Nov 2009, pp. 189–191.
[11]
D.
Smith,
Q.
Guan,
and
S.
Fu,
“An
Anomaly
Detection
Framework for Autonomic Management of Compute Cloud Systems,”
2010
IEEE
34th
Annual
Computer
Software
and
Applications
Conference Workshops, Jul. 2010, pp. 376–381. [Online]. Available:
http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5615245
[12]
A. Ng, “Machine learning: Anomaly detection,” Lecture Notes,
Coursera Course, Standford University, September 2014. [Online].
Available: https://www.coursera.org/course/ml
[13]
F.
Salfner,
M.
Lenk,
and
M.
Malek,
“A
survey
of
online
failure
prediction
methods,”
ACM
Computing
Surveys,
vol.
42,
no.
3,
Mar.
2010,
pp.
1–42.
[Online].
Available:
http://portal.acm.org/citation.cfm?doid=1670679.1670680
[14]
Hping,
“Hping
3,”
September
2014.
[Online].
Available:
http://www.hping.org/hping3.html
[15]
D. L. Quoc, L. Yazdanov, and C. Fetzer, “Dolen: User-side multi-cloud
application monitoring,” in Future Internet of Things and Cloud. IEEE,
2014.
[16]
D. L. Quoc, T. Jeong, H. E. Roman, and J. W.-K. Hong, “Trafﬁc
dispersion graph based anomaly detection,” in Proceedings of the
Second Symposium on Information and Communication Technology,
ser. SoICT ’11.
New York, NY, USA: ACM, 2011, pp. 36–41.
[Online]. Available: http://doi.acm.org/10.1145/2069216.2069227
0.0
0.5
1.0
0
20
40
60
Time (min)
Entropy
r
5
10
Entropy Time Series − n=5 and m=6
(a) n = 5; m = 6
0.0
0.5
1.0
0
20
40
60
Time (min)
Entropy
r
5
10
Entropy Time Series − n=5 and m=7
(b) n = 5; m = 7
0.0
0.5
1.0
0
20
40
60
Time (min)
Entropy
r
5
10
Entropy Time Series − n=10 and m=6
(c) n = 10; m = 6
0.0
0.5
1.0
0
20
40
60
Time (min)
Entropy
r
5
10
Entropy Time Series − n=10 and m=7
(d) n = 10; m = 7
Figure 6. Entropy time series with: n = 5 (a, b); n = 10 (c, d).
113
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-368-1
ICSNC 2014 : The Ninth International Conference on Systems and Networks Communications

