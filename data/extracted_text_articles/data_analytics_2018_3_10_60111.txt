Analysis of Twitter Communication During the 2017 German Federal Election
Marek Opuszko, Laura Bode, Stephan Ulbricht
Friedrich-Schiller-University Jena
Department of Business Informatics, Jena, Germany
Email: marek.opuszko@uni-jena.de, laura.bode@uni-jena.de, stephan.ulbricht@uni-jena.de
Abstract—Even before 2016 elected US president Donald Trump
made the microblogging service Twitter a tool for political
campaigning and broadcasting, the online service with millions of
users gained attention in public events, scandals or sport events.
The question still remains open to what extent the analysis of
Twitter communication reveals insights into to political discurse
during elections. This study uses the context of the 2017 German
federal election to investigate the political communication within
the Twitter network during 10 weeks leading to the election
in September 2017. Almost 1,500,000 million tweets are ana-
lyzed using three different lexica: SentiWS, Linguistic Inquiry
Word Count (LIWC) and German Political Sentiment Dictionary
(GPSD). In order to gain deeper insights, the users producing the
tweets are investigated. The results show that users strongly differ
in their activity on the network and perform statistical tests to
evaluate differences among the user groups.
Keywords–Social Media; Twitter; Sentiment; Elections
I.
INTRODUCTION
Political communication via social media and especially
microblogging services, such as Twitter have intensiﬁed in
recent years. Digital platforms are used by numerous actors
to inform themselves politically and to exchange thoughts
and ideas [1]. In many countries, social media are used by
politicians and political parties more frequently as a medium
for election campaigns and political marketing [2]. Especially
negative political statements can often attract people’s attention
and gain high efﬁcacy and attention [3].
As the popularity of social media increases, so does the
likelihood that people will ﬁnd ways to abuse them for their
own purposes. One type of abuse in the political online
debate is the so-called Astroturf, in which politically motivated
individuals and organizations use several remote controlled
accounts to give the appearance of broad and spontaneous
support for a candidate or opinion [4]. Symptoms include
various types of unlawful use, such as spam inﬁltrating social
networks [5]. In addition, in recent years, political actors
around the world have begun to use the digital power of
automated programs called social bots [6]. They purposefully
mimic human behavior, actively engage in the opinion-forming
process and have the potential to distort discussions in social
networks and manipulate public opinion [7], [8].
Twitter, in particular, has become an ideal destination for
exploiting automated programs through its growing popularity
and open nature [9]. Automated accounts are often character-
ized in Twitter by high activity in terms of large tweets, which
are generated in connection with political events during very
short timespans.
From the growing need to identify highly active, opinion-
forming actors in the digital political discourse, the task of
this work is to quantify the message trafﬁc in the context of
the 2017 German federal election on Twitter and to quantify
the inﬂuence of highly active users on the general mood in
the election campaign debate. Important questions include the
contribution of highly active users to political communication
for the 2017 federal elections and their potential inﬂuence on
other users. In addition, it should be determined whether the
generated mood of highly active users, in polarity or strength,
agrees with or differs from the majority tonality of the users.
The question is whether highly active users differ signiﬁcantly
in their behavior from other users. This is especially interesting
due to the fact that a new party, called the “Alterantive f¨ur
Deutschland (AfD)”, entered the stage of German politics and
vies for attention.
The paper is organized as follows. In Section II we will
provide the research background on election analysis in twitter
and the special features to this subject. Section III we will
lay out the research method and details of the data collection.
Furthermore, the different lexica used in this work are intro-
duced. Another aspect is the meassurement of user activity,
which is also addressed in this section. The results of the
analyses are presented in Section IV. The result presentation
is divided into a descriptive analysis, results from investigating
the different user groups and the sentiment investigations. The
work concludes with a summary and interpretation of the
results and gives indications of future investigations.
II.
RESEARCH BACKGROUND
In our study, we use 1,475,838 tweets published in the
months leading up to the federal election of the national
parliament in Germany in 2017. The election took place on
September 24th 2017. The elections in 2017 are entering a
new chapter in the history of the Federal Republic of Germany,
as in this election for the ﬁrst time a new party, the AfD,
by many considered a “right-wing” or populist party enters
the stage [10], [11]. The German party landscape consists of
7 relevant parties, Social Democratic Party SPD, Christian
Democratic Union CDU, Christian Social Union in Bavaria
CSU, Alternative for Germany AfD, Free Democratic Party
FDP, The Left LINKE or DIE LINKE and Alliance 90/The
Greens GR ¨UNE, where CDU and CSU form a federal union
called CDU/CSU or short Union. The strongest group in
the new Bundestag, with a share of 32.9%, was the CDU /
CSU parliamentary group. The SPD reached 20.5%. The AfD
made its ﬁrst entry into the Bundestag with 12.6%. The FDP
managed with 10.7% to return to parliament. The Left achieved
9.2% and The Greens 8.9% of the votes [12].
Not only since the 2016 elected US president Donald
Trump uses the online service Twitter to process political
statements, microblogging services are in the focus of science
[13]–[15]. Many researchers investigate the effects on the
political landscape or the reﬂections of real world events in
online social networks like Twitter [16]. It remains unclear
33
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

whether networks like Twitter either mirror or shape political
discurs and if so, to what degree [17]. Despite this uncertainty,
there is an ongoing discussion about the inﬂuence of possible
bots or agents from other countries on local political events,
such as the Brexit [17], [18] or the 2016 US elections [19],
[20].
Despite the unique properties of tweets compared to other
textiles, they have proven to be a reliable source for sentiment
analysis. One of the earliest works in which Twitter data was
used for sentiment analysis is by Go et al. [21]. They used
tweets with emoticons to train a machine learning algorithm
and were able to predict the mood in tweets with high accuracy
(about 83%). Bermingham and Smeaton also announced in
2010 that classifying short microblogging entries is much eas-
ier than classifying longer blog entries [22]. Barbosa and Feng
showed that the performance of sentiment analysis in Twitter
can be improved by incorporating social relationships and
connections, for example a user’s followers [23] on Twitter.
Further work has been done to introduce new automated meth-
ods of sentiment analysis and to optimize existing approaches
to increase the classiﬁcation accuracy of Twitter texts in a
variety of contexts. This emphasizes the ability of Twitter
sentiment analysis as a scientiﬁc tool to investigate human
communication, hence, political communication. Tumasjan et
al. found out that political sentiment towards parties and
politicians can be linked to real events and political demands
of the actors using sentiment analysis of the 2009 general
election [16]. The results showed both, a lively discussion and
conversations among the users. The study was further able to
attribute the election result to the proportion of tweets which
mentioned a speciﬁc party. Furthermore, research has shown,
that Twitter usage varies signiﬁcantly among its users [24].
In the political context regarding Twitter sentiment, neg-
ative moods are frequently identiﬁed. For example, news
coverage of the 2008 US presidential election revealed negative
sentiment rather than positive sentiment in response to speciﬁc
political events, such as television debates [25]. Another work
showed that the general mood of the Twitter debate on the
2008 US presidential election was also rather negative [26].
III.
METHOD
The data used in this work was collected in a 10 week
period leading to the federal elections in Germany on 24th
September 2017 using the ofﬁcial Twitter API [27], [28].
During this period, all tweets containing at least one hashtag
reference to one of the top parties SPD, CDU, CSU, AfD, FDP,
LINKE, GR ¨UNE were collected. The resulting raw dataset
comprised 1,475,838 tweets. Since only German tweets are
evaluated, the tweets were extracted from the multilingual
tweets for further use. Language recognition was performed
using the N-gram based text classiﬁcation of Cavnar and
Tenkle [29]. The described speech recognition process clas-
siﬁed 1,255,666 tweets as German. The dataset also included
225,371 entries with hashtags of the two chancelor canididates
Merkel und Schulz which have been removed in this work,
since we concentrate on party related content. The resulting
dataset then comprised 1,030,295 entries. All relevant hashtags
are listed in Table I. They are already subdivided into hash tag
groups with subsequent hashtags.
In a further step, additional special characters and HTML
elements, such as “&amp;” were removed from the text corpus.
TABLE I. NUMBER OF HASHTAG ENTRIES BY HASHTAG
Party hashtag
Number of entries
Asigned hashtags
AFD
515,615
#AFD, #AfD, #afd, #TrauDichDeutschland,
#traudichdeutschland, # noAfd, #NoAfD,
#AfDwaehlen, #NeinZuAFD, #afdstoppen,
#fckafd, #FCKAfD, #AberKeineAFD,
#afdverhindern
SPD
154,397
#SPD, #Spd, #spd, #spdde,
#EsistZeit, #esistzeit, #EsIstZeit
CDU
149,980
#CDU, #Cdu, #cdu, #fedidwgugl
FDP
71,570
#FDP, #Fdp, #fdp
LINKE
31,206
#LINKE, #Linke, #linke, #DIELINKE,
#dielinke, #DieLinke, #Linken,
#NURDIELINKE
GR ¨UNE
46,794
#GR ¨UNE, #Gr¨une, #Gruene, #Gr¨unen,
#Gruenen, #DieGruenen, #DarumGr¨un,
#GrueneVersenken
CSU
54,649
#CSU, #Csu, #csu
To determine the mood of a text by means of lexicon-based
sentiment analysis, different dictionaries can be used. In the
past, several such directories have been developed. Each with
different strengths and weaknesses [30]. Due to the focus
on a German text corpus, the use of dictionaries is limited
to German lexica. In this work, three word-based sentiment
lexica will be used: SentimentWS [31], Linguistic Inquiry
Word Count [32] and German Political Sentiment Dictionary
[33].
SentiWS is a publicly available, German-language dictio-
nary provided by the University of Leipzig and is suitable for
sentiment analysis based on the German language [31], [34].
The words are weighted in the interval -1 to 1, depending on
the level of expressiveness. SentiWS includes 1,818 positive
and 1,650 negative words, or 16,406 positive and 16,328
negative word forms, and includes nouns and verbs in addition
to sentiment-bearing adjectives and adverbs. SentiWS is based,
among other enhancements, on the General Inquirer, a popu-
lar English language sentiment dictionary whose words have
been systematically translated into German and then manually
reworked [31].
The LIWC is a text analysis software with an integrated
dictionary [32]. It was published in 2001 by Pennebacker et
al. [35] and has been developed for the automatic analysis
of texts in the one-word-procedure and provided by Dr. med.
phil. Markus Wolf from the University of Zurich. With the aid
of the stored dictionary, words are assigned to one or more
predeﬁned language categories. The language categories cover
grammatical-linguistic characteristics of the text as well as
thematic-content-related aspects, such as positive and negative
emotions or the presence of social and cognitive speech
content. The program also tracks how many words in a text
could be assigned to categories and considers this in relation
to the length of the text. The precission rate of the German
LIWC dictionary was cited with 63% in the past while the
English dictionary is cited with 73% [32]. In the context of
the general election in 2009, the LIWC software was used in
2010 by Tumasjan et al. [16] for political sentiment analysis
in Twitter.
The GPSD is a German lexicon by Haselmayer and Jenny
[33] especially developed for the analysis of political com-
munication. The words contained are weighted along a 5-step
negativity scale from 0 (not negative) to 4 (very strong neg-
ative). Assuming swarm intelligence, Haselmayer and Jenny
34
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

used the crowd-coding method and had texts reviewed by
a large number of anonymous non-experts. They achieved
reliable results through crowd-coding and advocated the use
of custom dictionaries.
To address the questions of user activity differences it
is necessary to determine a users’ activity in the Twitter
network. According to Bruns and Stieglitz, a user’s activity
can be described in the simplest way by the number of tweets
generated by a user for a certain hashtag [36]. If this activity
is determined for all users, the relative contribution of users
or user groups to the overall communication for a hashtag
can be determined. User activity in communicative situations
on Twitter and other platforms is likely to be described by a
long-tail distribution: a comparatively small group of highly
active users generate most of the content, while a much larger
number of less-active users only account for a small amount
of Tweets [37]. According to Bruns and Stieglitz, it is often
meaningful to group the users into groups based on this law.
They work with a 90/9/1 distribution established by Tedjamulia
et al. [38], which allows users of social networks to be divided
into the following three groups:
•
The most active 1% of users
•
The other, still very active 9% of users
•
The remaining, less active 90% of users
In this way, it can be examined how dominant the most
active 1% of users are within the entire hashtag conversation
on Twitter and whether there are obvious differences between
the activity patterns of these groups [39].
IV.
RESULTS
A. Descriptive Analysis
As highlighted in Table I, the number of hashtag entries
strongly differs by party (hashtag) and does not reﬂect the
election outcomes. In particular, the hashtag group #AFD
shows an extremely frequent occurrence with over 500,000
cases, which corresponds to a share of almost 50% of all
entries, yet having an election result of 12.6% of the votes.
On the other hand, the strongest group in the elections, the
CDU/CSU union with 32.9% of the votes only accounted for
14.64% of the entries of party hashtags. As a short conclusion,
the users mentioning the AFD hashtag are either very active or
there is a big controversy around that hastag within the Twitter
community. This is further highlighted in Figure 1 where the
percentage of each hashtag of the 7 party hashtag groups is
stacked upon reﬂecting the percentage of entries per day. The
AFD hashtag dominates the whole timespan having numerous
days when the percentage reaches values higher than 50%.
To assess possible activity differences, all users producing
tweets where grouped in three activity groups. The classiﬁca-
tion of users based on their activity was based on the 90/9/1
distribution presented in Section III. The division of the data
set into the three activity groups was realized by quantile
division. For quantile formation, users were sorted by their
tweet frequency (activity) in descending order, and then the
100%, 99%, and the 90% quantiles were determined to create
the 1%, 9%, and 90% user groups. Each of the three subgroups
of the activity groups created included the proportion of tweets
generated by the Twitter users of each group.
Figure 2 shows the number of tweets by each user group.
The results clearly show that 1% of the Twitter users in the
0.00
0.25
0.50
0.75
1.00
Jul 15
Aug 01
Aug 15
Sep 01
Sep 15
Date
Percent of Tweets with Hashtag
variable
Tweets AFD
Tweets CSU
Tweets CDU
Tweets FDP
Tweets SPD
Tweets GRUENEN
Tweets DIELINKE
Figure 1. Hashtag share in tweets per day in percent
dataset account for the majority of all tweets in the dataset. The
1% group even accounts for more tweets than the lower 90%
of the users. This conﬁrms the presumption of the existence
of a long tail in the user activity.
0
250000
500000
750000
1000000
1%
9%
90%
Total
 
 
Tweet_Type
Replies
Retweets
Tweets
Cumulated tweets of the activity groups by tweet type
Figure 2. Cumulated tweets of the activity groups by tweet type
B. User Groups
TABLE II. USER AND TWEET PERCENTAGE OF USER GROUPS
Group
Users
Tweets per User
Tweets (%)
1%
1,043
160-3365
38.30%
9%
8,851
16-159
38.07%
90%
93,816
1-15
23.63%
Total
103,701
1-3365
100%
Table II lists the number of user per group and the
percentage each group accounts for. To answer the question
wheter one user group shows a higher “reach” in terms
of “Twitter reach”, the reach R has to be determined. The
35
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

potential reach R of an activity group was deﬁned as the sum
of the possible reach indicators of the Twitter API (number of
followers, number of retweets and number of favorites) across
all tweets of an activity group. Followers are the number of
users subscribed to the twitter user posting a tweet. Figure 3
shows the mean potential reach of all user groups in terms
of followers and retweets. The ﬁrst group (1%) showes the
highest numbers of average followers per tweet with 5097.46.
Also the number of retweets is the highest in this group with
a value of 0.83 retweets per tweet on average.
0
1,000
2,000
3,000
4,000
5,000
1%
9%
90%
 
 
Follower
A
0.0
0.2
0.4
0.6
0.8
1%
9%
90%
 
 
Retweets
B
Mean reach of user groups
Figure 3. Mean reach of user groups
C. Sentiment of Election Tweets
As highlighted in Table III, the mean sentiment values of
the activity groups SentiWS [-0.099; -0.073] and GPSD [-
2.721; -2.591] were mainly in the negative and LIWC [1.302;
2.404] exclusively in positive territory. The difference between
the activity groups was particular large in LIWC. The standard
deviation (SD) was very high for all three procedures and for
all activity groups. This was especially true for the lexica
SentiWS and LIWC. It is noticeable that despite different
scales of measurement, all three lexica displayed the same
trend: the average sentiment value was highest in the 90%
group of users, lower in the 9% group and lowest in the 1%
group. This observation was signiﬁcant at a level of p < 0.001
for all dictionaries.
TABLE III. MEAN SENTIMENT VALUES OF DICTIONARIES
Group
SentiWS
LIWC
GPSD)
1%
-0.099 (SD 0.331)
1.302 (SD 9.242)
-2.721 SD(1.528)
9%
-0.089 (SD 0.328)
1.723 (SD 9.143)
-2.669 SD(1.504)
90%
-0.073 (SD 0.325)
2.404 (SD 9.283)
-2.591 SD(1.449)
D. Sentiment in Hashtag Groups
In this section, a sentiment comparison of the hashtag
groups introduced in Table I was performed. Figure 4 visual-
izes the proportionate (A) and mean (B) sentiments of the hash-
tag groups. The generated sentiment of the hashtag conversa-
tions were very different. The highest sentiment was generated
by the AfD (41.20%), followed by BTW17 (20.62%), SPD
(12.31%) and CDU (11.33%) and again with a considerable
distance FDP (4.89%), CSU (4.10%), GR ¨UENE (3.67%) and
LINKE (1.90%). The proportionate sentiment of the hashtag
conversations were related to their tweet proportions. For
example, the AFD with 41.2% had the highest sentiment shares
and was with 39.98% the most sentiment-bearing Hashtag.
The average sentiment per tweet slightly varied from -2.59
(LINKE) to -2.75 (AfD). The standard deviation was very high
for all hashtag conversations.
0
10
20
30
40
AfD
CDU
CSU
FDP
Grüne
Linke
SPD
 
 
Proportionate Sentiment
A
−4
−3
−2
−1
0
AfD
Grüne
SPD
CDU
FDP
Linke
CSU
 
 
Mean Sentiment per Hashtag
B
Sentiment in Hashtag Groups
Figure 4. Sentiment per Hashtag Group
To investigate signiﬁcant differences among the hashtag
groups and the user groups in terms of sentiment, a Dunn test
was performed [40] to compare group differences. Prior to
the Dunn Test a Kruskal-Wallis test was performed to prove
an existing effect of the actitivity and hastag groups on the
sentiment. Table IV contains the associated p-values of the
multiple mean comparisons.
TABLE IV. P-VALUES OF THE MULTIPLE MEAN COMPARISONS WITH THE
DUNN TEST
Hashtag Group
1:9
1:90
9:90
AfD
0.349
0.047*
0.029*
CDU
0.018*
0.000***
0.000***
CSU
0.091
0.001**
0.017*
SPD
0.005**
0.000***
0.000***
LINKE
0.446
0.010*
0.002**
GR ¨UENE
0.188
0.225
0.329
FDP
0.000***
0.000***
0.180
*p < 0.05, **p < 0.01, ***p < 0.001
For CDU and SPD, there were signiﬁcant differences
in moods between all activity groups (see Table IV). The
36
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

sentiment becomes increasingly negative from the 90% group
through the 9% group to the 1% group). For AfD, CSU and
LEFT, the 90% group differed signiﬁcantly from the other
activity groups. Conversely, the pairwise comparisons of 1%
and 9% showed no signiﬁcant differences. For FDP, the 1%
group differed signiﬁcantly from the other two groups and for
GR ¨UENE there were no signiﬁcant differences between the
activity groups.
E. Interpretation
The 10% of the most active users (1% and 9% together)
generate more than three quarters of the content, while the
remaining 90% together make up just under a quarter of the
tweets. Reach via followers and retweets increases with user
activity: the mood of highly active users (1% group) reaches on
average more followers and their tweets are retweeted more of-
ten than those of the other activity groups. Tweets from the 9%
group are most often favored. Around 68% of the total tweets
produced are retweets, just under 25% are tweets and about
7% are answers. The sentiment polarity for the 2017 general
election is positive after evaluation of the LIWC software and
negative according to the results from SentiWS and GPSD.
The sentiment between the activity groups shows signiﬁcant
differences and becomes more negative as users become more
active. This trend is evident in all dictionaries. Especially the
hashtag groups on CDU and SPD follows this observation,
while other hashtags do not always show signiﬁcant results.
Although the sentiment differences are highly signiﬁcant, the
overall effect is rather low.
V.
CONCLUSION AND FUTURE WORK
We analyzed over one million tweets during the pre-
election phase of the German federal elections in 2017. The
overall results show that twitter is indeed an online platform
for political discussion.
First, it will be discussed which spectrum of activity,
expressed in terms of tweet share and reach, of highly active
users on the political discussion on the 2017 German federal
election on Twitter. The participation of highly active to active
(1% - and 9% - group) and less active users (90% - group)
is in the ratio 3: 1 (see Table II). 75% of the content is
thus generated by a small, very active group. A similar trend
was also observed in other political debates on Twitter: For
example, in the Twitter debate on the 2009 general election,
more than 40% of the news was produced by only 4% of
the users [16]. This effect has been shown multiple times in
past. News tweets comprising the standard political hashtag for
political discussions #auspol in Australia, more than half were
generated by the 1% most active users, while the majority of
users remained inactive [36]. Howard and Kollanyi’s (2017)
Brexit referendum investigations also found that less than 1%
of accounts accounted for almost one third of all content [17].
This strong imbalance in users’ communication shares, which
seems to emerge in political discussions on Twitter, can also be
seen during the communication to the 2017 general election.
The participation of the users in this dataset most likely seems
to follow the rule that Bruns and Stieglitz refer to: A small
minority of Twitter users dominate the discussion with their
content.
However, the user groups not only generate different num-
bers of tweets, their contents are also differentially visible to
the Twitter community: the average reach in terms of followers
and retweets increases with the activity of the groups and
peaks in the highly active user group. This suggests that highly
active users may pass the generated mood to more users than
the less active users due to the higher number of followers.
Their content is also retweeted more frequently, reaching more
potential readers. The level of inﬂuence of highly active users
on the Twitter community about their increased reach therefore
seems to be higher than that of less active accounts.
The SentiWS and GPSD lexicons produced negative av-
erages for mood in the dataset, while the LIWC software
was positive. It can be assumed that negative tweets and
thus negative moods dominate the data set and the general
communication surrounding the election. As described in Sec-
tion II, there seems to be a trend towards negative overall
attitudes in political debates on Twitter. This trend was largely
conﬁrmed in the present work. Negative sentiment during the
election campaign could be attributed to the fact that negative
campaigns against parties, and in this case against their party-
speciﬁc hashtags, seem to have proven effective considering
Twitter reach.
In contrast to Tumasjan et al. [16], this study could not
directly link the amount of tweets posted to election results.
Nevertheless, the study shows that Twitter can serve as a tool
to study the political debate during an electoral phase. Since
the hashtags in all hashtag groups contain both, positive and
negative sentiment, the sole number of hashtag per group is a
limited predictor for election outcome. The study has, however,
several limitations. The integration of other linguistic methods,
which take into account sentence structure, part of speech and
word location (part of speech tagging, negation, reinforcing
words) would be another step to increase the classiﬁcation
accuracy.
In addition, sentiment values could be calculated on the
basis of ﬁxed expressions and phrases instead of words.
It might also be useful to introduce special adjustments to
informal texts and the Twitter-speciﬁc language by, for exam-
ple, incorporating common typos, urban speech, speller and
Twitter-speciﬁc vocabulary into the algorithm. Samples from
the data set in this context gave the impression that only few
spelling and grammatical errors were made. This could be
related to the seriousness of the issue: Actors in the political
discussion want to preserve their reputation and credibility
through clear and correct language.
Furthermore, emoticons could be investigated, since they
have already been successfully embedded in the sentiment
analysis of Twitter data in other works [21]. In the tweet
texts, however, no signiﬁcant amount of emoticons could be
identiﬁed, which may be related to the fact that the polit-
ical discussion is a more serious topic in which emotional
expressions about emoticons are rather avoided. In order to
increase the accuracy of classiﬁcation, the calculation of the
sentiment values at the sentence level could also be varied by
calculating not the sum of all values, but the mean value. This
standardization could more accurately capture the polarity of
the text. At the same time, however, the information about the
intensity of the mood would be lost.
REFERENCES
[1]
C.
Thimm,
J.
Einsp¨anner,
and
M.
Dang-Anh,
“Twitter
als
wahlkampfmedium [Twitter as a campaign medium ],” Publizistik,
vol. 57, no. 3, 2012, pp. 293–313.
37
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

[2]
M. Meckel, C. Hoffmann, A. Suphan, and R. Po¨ell, “Politiker im
netz: Treiber und h¨urden der social media-nutzung unter bundes-und
landtagsabgeordneten. [Politicians online: Drivers and barriers of social
media use among members of federal states parliaments and national
parliaments],” vol. 24, 2013 (accessed September 3, 2018), pp. 1–71.
[Online]. Available: http://www.isprat.net
[3]
H. D. Wu and N. S. Dahmen, “Web sponsorship and campaign effects:
Assessing the difference between positive and negative web sites,”
Journal of Political Marketing, vol. 9, no. 4, 2010, pp. 314–329.
[4]
J. Ratkiewicz, M. D. Conover, M. Meiss, B. Goncalves, A. Flammini,
and F. Menczer, “Detecting and tracking political abuse in social media,”
Proceedings of the 5th AAAI International Conference on Weblogs and
Social Media (ICWSM’11), 2011, pp. 297–304.
[5]
A. H. Wang, “Don’t follow me: Spam detection in twitter,” International
Conference on Security and Cryptography (SECRYPT), 2010, pp. 142–
151.
[6]
S. Hegelich and D. Janetzko, “Are social bots on twitter political actors?
empirical evidence from a ukrainian social botnet,” ICWSM, 2016, pp.
579–582.
[7]
C. Freitas, F. Benevenuto, S. Ghosh, and A. Veloso, “Reverse engineer-
ing socialbot inﬁltration strategies in twitter,” in Proceedings of the 2015
IEEE/ACM International Conference on Advances in Social Networks
Analysis and Mining 2015 - ASONAM ’15, J. Pei, F. Silvestri, and
J. Tang, Eds.
New York, New York, USA: ACM Press, 2015, pp.
25–32.
[8]
S. C. Woolley and P. N. Howard, “Political communication, computa-
tional propaganda, and autonomous agents - introduction,” International
Journal Of Communication, vol. 10, no. 9, 2016, pp. 4882–4890.
[9]
Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia, “Who is tweeting
on twitter: Human, bot, or cyborg?” in Proceedings of the 26th Annual
Computer Security Applications Conference on - ACSAC ’10, C. Gates,
M. Franz, and J. McDermott, Eds.
New York, New York, USA: ACM
Press, 2010, pp. 21–30.
[10]
F. Decker, “The alternative for germany: factors behind its emergence
and proﬁle of a new right-wing populist party,” German Politics and
Society, vol. 34, no. 2, 2016, pp. 1–16.
[11]
N. Berbuir, M. Lewandowsky, and J. Siri, “The afd and its sympathisers:
ﬁnally a right-wing populist movement in germany?” German Politics,
vol. 24, no. 2, 2015, pp. 154–178.
[12]
B¨uro des Bundeswahlleiters, “Bundestagswahl 2017: Endg¨ultiges
ergebnis
[Federal
election
2017:
Final
results
of
the
federal
returning ofﬁcer],” 12.10.2017 (accessed September 3, 2018). [Online].
Available:
https://www.bundeswahlleiter.de/info/presse/mitteilungen/
bundestagswahl-2017/34 17 endgueltiges ergebnis.html
[13]
B. L. Ott, “The age of twitter: Donald j. trump and the politics of
debasement,” Critical Studies in Media Communication, vol. 34, no. 1,
2017, pp. 59–68.
[14]
A. Ceron and G. d’Adda, “E-campaigning on twitter: The effectiveness
of distributive promises and negative campaign in the 2013 italian
election,” New Media & Society, vol. 18, no. 9, 2016, pp. 1935–1955.
[15]
S. Wattal, D. Schuff, M. Mandviwalla, and C. B. Williams, “Web
2.0 and politics: The 2008 u.s. presidential election and an e-politics
research agenda,” MIS Quarterly, vol. 34, no. 4, 2010, pp. 669–688.
[16]
A. Tumasjan, T. O. Sprenger, P. G. Sandner, and I. M. Welpe, “Predict-
ing elections with twitter: What 140 characters reveal about political
sentiment,” Proceedings of the Fourth International AAAI Conference
on Weblogs and Social Media, 2010, pp. 178–185.
[17]
P. N. Howard and B. Kollanyi, “Bots, #strongerin, and #brexit:
Computational propaganda during the UK-EU referendum,” CoRR,
vol.
abs/1606.06356,
2016,
pp.
1–6.
[Online].
Available:
http:
//arxiv.org/abs/1606.06356
[18]
A. Bakliwal, J. Foster, J. van der Puil, R. O’Brien, L. Tounsi, and
M. Hughes, “Sentiment analysis of political tweets: Towards an accurate
classiﬁer,” Proceedings of the Workshop on Language in Social Media
(LASM 2013), 2013, pp. 49–58.
[19]
A. Bessi and E. Ferrara, “Social bots distort the 2016 u.s. presidential
election online discussion,” First Monday, vol. 21, 11 2016, p. 1.
[20]
N. Persily, “The 2016 us election: Can democracy survive the internet?”
Journal of democracy, vol. 28, no. 2, 2017, pp. 63–76.
[21]
A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classiﬁcation
using distant supervision,” Processing, no. 150, 2009, pp. 1–6.
[22]
A. Bermingham and A. F. Smeaton, “Classifying sentiment in mi-
croblogs,” in Proceedings of the 19th ACM international conference
on Information and knowledge management - CIKM ’10, J. Huang,
N. Koudas, G. Jones, X. Wu, K. Collins-Thompson, and A. An, Eds.
New York, New York, USA: ACM Press, 2010, pp. 1833–1837.
[23]
L. Barbosa and J. Feng, “Robust sentiment detection on twitter from
biased and noisy data,” Coling 2010 - 23rd International Conference on
Computational Linguistics, Proceedings of the Conference, 2010, pp.
36–44.
[24]
C. Honey and S. C. Herring, “Beyond microblogging: Conversation and
collaboration via twitter,” in System Sciences, 2009. HICSS’09. 42nd
Hawaii International Conference on.
Ieee, 2009, pp. 1–10.
[25]
F. Wanner, C. Rohdantz, F. Mansmann, D. Oelke, and D. A. Keim,
“Visual sentiment analysis of rss news feeds featuring the us presidential
election in 2008,” Visual Interfaces to the Social and the Semantic Web
(VISSW 2009), Sanibel Island, Florida, 8th February 2009, 2009, pp.
1–8.
[26]
N. A. Diakopoulos and D. A. Shamma, “Characterizing debate per-
formance via aggregated twitter sentiment,” in Proceedings of the 28th
international conference on Human factors in computing systems - CHI
’10, E. Mynatt, D. Schoner, G. Fitzpatrick, S. Hudson, K. Edwards, and
T. Rodden, Eds.
New York, New York, USA: ACM Press, 2010, pp.
1195–1198.
[27]
I. Twitter, “Instant historical access to tweets,” 2018 (accessed
September 3, 2018). [Online]. Available: https://developer.twitter.com/
en/products/tweets
[28]
——,
“Tweet
data
dictionary,”
2018
(accessed
September
3,
2018). [Online]. Available: https://developer.twitter.com/en/docs/tweets/
data-dictionary/overview/tweet-object
[29]
W. B. Cavnar and J. M. Trenkle, “N-gram-based text categorization,”
Proceedings of SDAIR-94, 3rd Annual Symposium on Document
Analysis and Information Retrieval, 1994, pp. 161–175.
[30]
M. Taboada, J. Brooke, M. Toﬁloski, K. Voll, and M. Stede, “Lexicon-
based methods for sentiment analysis,” Computational linguistics,
vol. 37, no. 2, 2011, pp. 267–307.
[31]
R. Remus, U. Quasthoff, and G. Heyer, “Sentiws - a publicly available
german-language resource for sentiment analysis,” Proceedings of the
7th International Language Ressources and Evaluation (LREC’10),
2010, pp. 1168–1171.
[32]
M. Wolf, A. B. Horn, M. R. Mehl, S. Haug, J. W. Pennebaker, and
H. Kordy, “Computergest¨utzte quantitative textanalyse,” Diagnostica,
vol. 54, no. 2, 2008, pp. 85–98.
[33]
M. Haselmayer and M. Jenny, “Sentiment analysis of political commu-
nication: Combining a dictionary approach with crowdcoding,” Quality
& quantity, vol. 51, no. 6, 2017, pp. 2623–2646.
[34]
Universit¨at Leipzig, “Sentiws,” 2018 (accessed September 3, 2018).
[Online]. Available: http://wortschatz.uni-leipzig.de/de/download
[35]
J. W. Pennebaker, M. E. Francis, and R. J. Booth, Linguistic Inquiry
and Word Count – LIWC2001.
Mahwah, N.J: Erlbaum, 2001.
[36]
A. Bruns and S. Stieglitz, “Towards more systematic twitter analysis:
Metrics for tweeting activities,” International Journal of Social Research
Methodology, vol. 16, no. 2, 2013, pp. 91–108.
[37]
K. Weller, A. Bruns, J. Burgess, and M. Mahrt, Eds., Twitter and
society, ser. Digital formations.
New York, NY: Lang, 2014, vol. 89.
[Online]. Available: https://www.peterlang.com/view/product/30225
[38]
S. J. Tedjamulia, D. L. Dean, D. R. Olsen, and C. C. Albrecht,
“Motivating content contributions to online communities: Toward a
more comprehensive theory,” in System Sciences, 2005. HICSS’05.
Proceedings of the 38th Annual Hawaii International Conference on.
IEEE, 2005, pp. 193b–193b.
[39]
A. Bruns and S. Stieglitz, “Quantitative approaches to comparing
communication patterns on twitter,” Journal of Technology in Human
Services, vol. 30, no. 3-4, 2012, pp. 160–185.
[40]
O. J. Dunn, “Multiple comparisons among means,” Journal of the
American Statistical Association, vol. 56, no. 293, 1961, pp. 52–64.
38
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-681-1
DATA ANALYTICS 2018 : The Seventh International Conference on Data Analytics

