Reversible Watermarking Based on Histogram Shifting of Difference Image
between Original and Predicted images
Su-Yeon Shin, Hyang-Mi Yoo, Jae-Won Suh
School of Electrical and Computer Engineering
Chungbuk National University
Cheongju, Korea
Email: ssy6061@naver.com, hmyoo82@cbnu.ac.kr, sjwon@cbnu.ac.kr
Abstract—Reversible watermarking is a technique that can re-
cover an undistorted original image from a watermarked image.
The proposed watermark embedding algorithm uses histogram
shifting of the difference image between a modiﬁed original image
and its predicted one. In the proposed algorithm, the predicted
image that works well increases the embedding capacity, so that
the reference pixels for prediction are adaptively selected and ﬁl-
tered and the other predicted pixels are directionally interpolated
with the reference pixels. The simulation results demonstrate that
the proposed algorithm generates good performances in the peak
signal-to-noise ratio (PSNR) values and the embedding capacity.
Keywords–Reversible watermarking; Histogram shifting; Pre-
dicted image; Reference pixel; Directional interpolation
I.
INTRODUCTION
Illegal copies of digitized image can be easily and widely
distributed through various communication channels and stor-
age devices and be a serious problem for content owners.
Watermarking technique can be a good solution to prevent
the use of illegal contents. Watermarking technique can be
categorized into three classes by the purpose: robust, fragile,
and reversible watermarking. In the robust watermarking, the
watermarked message must survive the various attacks such as
resizing, cropping, ﬁltering. For the fragile watermarking, the
embedded watermark should be easily broken from the attacks.
Reversible watermarking means that the original image and
the watermark message can be completely recovered from the
watermarked image without any distortion.
Reversible watermarking algorithms are studied many ways.
The difference expansion scheme proposed by Tian [1] se-
lected some expandable difference values of neighboring two
pixels and embedded one bit into each of them. Ni et al. [2]
found the maximum and the minimum pixel levels of the image
histogram and shifted the histogram to embed the secrete
data. Luo et al. [3] utilized the interpolation error, which is
the difference between the interpolated pixel value and the
corresponding pixel value. However, although these reversible
watermarking algorithms based on histogram shifting make
sufﬁcient space for the watermark embedding, they suffer from
the overﬂow and underﬂow problems because of the wrap
around pixel levels caused by histogram shifting. Hong et al.
[4] has extended Luo’s work by generalizing the distribution
of the reference pixels. However, if the distance between
reference pixels become longer, the performance of Hong’s
algorithm get worse and worse. In this paper, we propose a
new reversible watermarking algorithm tho overcome these
problems.
The rest of this paper is organized as follows. Section
II and Section III describe the watermark embedding and
extracting procedures of the proposed algorithm, respectively.
In Section IV, we demonstrate the effectiveness of the proposed
algorithm. Finally, conclusions are drawn in Section V.
II.
WATERMARK EMBEDDING PROCEDURE
The proposed reversible watermarking algorithm uses his-
togram shifting of the difference image between a modiﬁed
original and its predicted images. Fig. 1 shows the proposed
watermarking embedding procedure. A full explanation of each
procedure is given below.
Location Map LMi, j
Difference Image Di, j
Watermarked
Difference Image WDi, j
Watermarked Image Wi, j
Input Image Ii, j
Reference Map Ri, j
Modified Image Mi, j
Predicted Image Pi, j
Watermark Embedding
Watermark Data
-
Side Information
-
Pure Data
Figure 1.
Watermark embedding procedure
A. Location Map and Modiﬁed Image
To overcome the wrap around problem, we need to monitor
the lower bound pixel value “0” and the upper bound pixel
value “255”. Regarding the original image Ii,j for 0 ≤ i < M
and 0 ≤ i < N, if the pixel value is equal to the lower
bound pixel value or the upper bound pixel, we assign a “1”
into the corresponding pixel location. Consequently, we obtain
147
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-353-7
UBICOMM 2014 : The Eighth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

an M × N binary image called as a location map. Next,
we make a modiﬁed image Mi,j by changing “0” into “1”
and “255” into “254”. Finally, the location map is losslessly
compressed by using the joint bi-level image experts group
(JBIG) compression algorithm and is inserted into some part
of the embedded watermark data.
B. Predicted Image
The embedding capacity is proportional to the number of
the most frequent pixel value at the difference image Di,j,
which can be obtained by obtaining a well predicted image.
To do so, the predicted image Pi,j is obtained by directional
interpolation based on the proposed reference map Ri,j.
0
0
0
0
0
0
0
0
1
1
1
1
1
1
0
1
1
1
1
1
1
0
1
1
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
0
0
1
1
1
1
1
1
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
∆
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
(a) If ∆ ≤ 5 (∆ = 5)
(b) If ∆ > 5 (∆ = 6)
Figure 2.
Reference map
1) Reference Map: As shown in Fig. 2, we deﬁne two
different types of reference map Ri,j, where ∆ is a pre-
deﬁned integer and the reference pixels are differently deﬁned
by ∆ along the vertical and horizontal directions. If the spatial
mesh interval for ∆ gradually becoming wider, the prediction
performance goes from bad to worse. To prevent the decrease
of the prediction performance, if ∆ is greater than 5, the
reference pixels are located in a line. The positions associated
with the reference pixels are notiﬁed by “0” and the others are
“1”, which is expressed in (1)
if∆ ≤ 5 :
Ri,j =
{
0
if i%∆ = 0 and j%∆ = 0
1
otherwise
if∆ > 5 :
Ri,j =
{
0
if i%∆ = 0 or j%∆ = 0
1
otherwise
(1)
The reference pixels once selected should be preserved and
the other pixels surrounded by the reference pixels are inter-
polated.
Next, we ﬁnd the complex area and skip the prediction
by using the reference map. It is very important because the
complex area does not affect the embedding capacity and
only causes the visual quality degradation of the watermarked
image. To determine the complex area, we use the range
function in (2). It returns the absolute difference between the
maximum and minimum values of the given values.
Range(x1,x2, x3, x4) =
|Max(x1, x2, x3, x4) − Min(x1, x2, x3, x4)|
(2)
If the given values are the equally spaced four corner
reference pixel values and the return value of range function is
greater than a pre-deﬁned threshold T0, the area surrounded by
the four reference pixels are considered as a complex area. In
this case, all pixels in the complex area are marked as reference
pixels to prevent them from being interpolated in the process
of making predicted image [4].
0
1
1
1
1
0
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
0
1
1
1
1
0
40
40
45
45
48
50
45
47
49
50
52
53
50
50
53
53
53
55
52
55
60
65
70
72
55
60
63
65
70
72
60
62
62
65
65
70
40
42
44
46
48
50
44
47
49
50
52
54
48
50
53
53
53
58
52
55
60
65
70
62
56
60
63
65
70
66
60
62
64
66
68
70
(a) Ri,j for ∆ ≤ 5
(b) Corresponding Mi,j
(c) Interpolation result
Figure 3.
Interpolation of boundary pixels
2) Pre-Processing of Boundary Pixels: As shown in Fig. 3,
we calculate an imaginary boundary pixel values for smooth
area by applying linear interpolation or low pass ﬁltering
to increase the prediction accuracy for the predicted image.
In case of ∆ ≤ 5, the boundary pixel values between two
reference pixels are linearly interpolated as shown in Fig. 3.
In case of ∆ > 5, low pass ﬁltering is applied to the reference
pixels. The low pass ﬁltered reference pixels are calculated by
MRi,j =
{
1/4(Mi−1,j + 2 × Mi,j + Mi+1,j)
if j%∆ = 0
1/4(Mi,j−1 + 2 × Mi,j + Mi,j+1)
if i%∆ = 0
(3)
The interpolated or low pass ﬁltered boundary pixels are
treated as reference pixels but are not reference pixels. They
are only used for prediction mode decision and directional
interpolation to make a predicted image.
47
49
50
52
50
53
53
53
55
60
65
70
60
63
65
70
47
49
50
52
50
53
53
53
55
60
65
70
60
63
65
70
40
42
44
46
48
50
44
54
48
58
52
62
56
66
60
62
64
66
68
70
40
42
44
46
48
50
44
54
48
58
52
62
56
66
60
62
64
66
68
70
(a) Diagonal
(b) Vertical
47
49
50
52
50
53
53
53
55
60
65
70
60
63
65
70
47
49
50
52
50
53
53
53
55
60
65
70
60
63
65
70
40
42
44
46
48
50
44
54
48
58
52
62
56
66
60
62
64
66
68
70
40
42
44
46
48
50
44
54
48
58
52
62
56
66
60
62
64
66
68
70
(c) Horizontal
(d) Backward Diagonal
Figure 4.
Prediction mode
3) Prediction Mode and Directional Interpolation:
As
shown in Fig. 4, the pre-processed boundary pixels are used
for prediction mode decision. There are ﬁve prediction modes:
diagonal mode, vertical mode, horizontal mode, backward
diagonal mode, and plane mode. The mode having the smallest
mean sum of absolute difference (MSAD) between far away
shaded pixels is determined as the prediction mode of the
148
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-353-7
UBICOMM 2014 : The Eighth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

current block. The MSAD is given by (4).
MSAD = 1
n
n
∑
l=1
|xl − yl|
(4)
For examples of the above Fig. 4, the MSADs for diagonal
mode, vertical mode, horizontal mode, and backward diagonal
mode are 26, 20, 10, and 9, respectively. Therefore, the predic-
tion mode of the current block is the backward diagonal mode.
Therefore, the pixels of the current block are directionally
interpolated by the backward diagonal mode. However, if the
MSAD is larger than pre-deﬁned threshold T1, the block is
decided as a plane mode and bilinear interpolated.
C. Data Structure of the Watermark Message
In order to be able to recover the original image and the
watermark message from a watermarked image, the embedded
watermark data have to be designed considering the extraction
rule. The data structure of the embedded message is shown in
Fig. 5 [5].
A
B
C
D
JBIG file size/256 +1
JBIG file size
JBIG data
Pure payload data
Fixed length
Variable length
•
“A” ﬁeld: An eight bit integer indicating how many next bytes
are used for notifying the length of the compressed location
map.
•
“B” ﬁeld: Representing the real ﬁle size of the compressed
location map by JBIG.
•
“C” ﬁeld: Compressed bitstream of the location map.
•
“D” ﬁeld: Pure watermark data.
Figure 5.
Data structure of the watermark message
D. Watermark Embedding by Histogram Shifting
The ﬁrst thing for watermark embedding is making a his-
togram of difference image Di,j. The difference image Di,j
is obtained by subtracting the predicted image Pi,j from the
modiﬁed image Mi,j for 0 ≤ i < M and 0 ≤ j < N. Fig.
6(a) shows the histogram of the difference image.
Secondly, the histogram shifting is performed around the
ﬁrst and the second maximum peak point (PP) pixel values in
order to make the data embedding space. “PP1” and “PP2”
are the pixel values that have the ﬁrst and second highest
number of pixels in ascending order. As shown in Fig. 6(b),
we empty the “PP1 − 1” and “PP2 + 1” levels using bi-
directional histogram shifting. It means that if the pixel value
of Di,j is less than or equal to “PP1 − 1”, the corresponding
pixel value is decremented by “1” throughout the whole image.
If the pixel value of Di,j is greater than or equal to “PP2+1”,
the corresponding pixel value is incremented by “1”.
Therefore, the shifted difference image SDi,j can be ex-
pressed as
SDi,j =
{
Di,j − 1
if Di,j ≤ PP1 − 1
Di,j + 1
if Di,j ≥ PP2 + 1
(5)
PP1PP2
(a) Histogram of Di,j
PP1 - 1
PP2 + 1
(b) Histogram shifting
PP1 - 1
PP2 + 1
(c) Watermark Embedding
Figure 6.
Structure of the watermark data
Next, the watermark message W(k) is embedded into the
two PP values. The shifted difference image is scanned again
using its raster scan order. Once the “PP1” are “PP2” values
are encountered, we sequentially check the watermark message
W(k). If the checked bit is a “1”, the pixel value “PP1” or
“PP2” is changed into “PP1 − 1” or “PP2 + 1”, respectively.
If the checked bit is a “0”, there is no change as shown in
Fig. 6(c). As a result, we can get the watermarked difference
image WDi,j and ﬁnally obtain the watermarked image Wi,j
by adding with the predicted image Pi,j.
III.
PROPOSED WATERMARK EXTRACTION
If the receiver has the watermarked image and the key infor-
mation for extraction, the watermarked image can be separated
into the original image and the watermarked data. The key
information for watermark extraction are pre-determined T0
and T1, ∆, PP1 and PP2.
First, we make the predicted image Pi,j by using ∆, T0 and
T1. Because the reference pixels are not changed during the
embedding process, the predicted image is exactly the same
as that obtained in the embedding procedure.
Second, we generate difference image Di,j between the
watermarked image Wi,j and the predicted image Pi,j. During
the scanning the difference image Di,j, we can extract the
embedded watermark data W(k) using the PP1 and PP2.
149
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-353-7
UBICOMM 2014 : The Eighth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

0
0.05
0.1
0.15
0.2
45
50
55
60
65
70
75
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Luo [3]
Hong [4]
0
0.01
0.02
0.03
0.04
0.05
0.06
40
45
50
55
60
65
70
75
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Luo [3]
Hong [4]
(a) LENA
(b) BABOON
0
0.05
0.1
0.15
0.2
45
50
55
60
65
70
75
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Luo [3]
Hong[4]
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
45
50
55
60
65
70
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Luo[3]
Hong [4]
(c) AIRPLANE
(d) PEPPER
Figure 7.
Results for ∆ = 3
Whenever the corresponding pixel level is equal to “PP1” or
“PP2”, the extracted bit is “0”. If the corresponding value is
“PP1 − 1” or “PP2 + 1”, the extracted bit “1”.
Third, we re-scan the entire difference image Di,j and
recover the histogram of the difference image. If the corre-
sponding value is less than or equal to “PP1 − 1”, “1” is
added and if the corresponding value is greater than or equal
to “PP2+1”, “1” is subtracted. The returned difference image
generates the modiﬁed image Mi,j by adding the predicted
image Pi,j.
Next, we parse the compressed location map information
from the extracted watermark message W(k). Finally, we
recover the original image Ii,j by using the modiﬁed image
Mi,j and the decompressed location map data.
IV.
EXPERIMENTAL RESULTS
In order to evaluate the performance of the proposed re-
versible watermarking algorithm, we performed computer sim-
ulations on typical 512×512 8-bit images: LENA, BABOON,
AIRPLANE, and PEPPER. The performance of the proposed
reversible watermarking algorithm has been compared to those
presented by Luo et al. [3] and Hong et al. [4] in terms of
the embedding capacity versus the PSNR of the watermarked
image. In Fig. 7 and Fig. 8, we just showed two simulation
results: ∆ = 3 and ∆ = 6. The simulation conditions are like
this: various T1 (1, 2, ..., 10, 20, ...80) and ﬁxed T2 = 10.
In both results, we can ﬁnd the common property that
the small T1 generates high PSNR value but low embedding
capacity. In Fig. 7, the proposed algorithm achieves slightly
better embedding efﬁciency than that of the Hong’s algo-
rithm. The superiority is from the low pass ﬁltering of the
reference pixels and directional interpolation according to the
prediction mode in the proposed algorithm. The excellence
of the proposed algorithm is clearly shown in the case of
∆ = 6. By adapting the new structure of the reference pixels
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
45
50
55
60
65
70
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Hong [4]
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0.04
0.045
45
50
55
60
65
70
75
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Hong [4]
(a) LENA
(b) BABOON
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
45
50
55
60
65
70
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Hong[4]
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
45
50
55
60
65
70
75
Capacity (bpp)
PSNR (dB)
 
 
Proposed
Hong [4]
(c) AIRPLANE
(d) PEPPER
Figure 8.
Results for ∆ = 6
for prediction, the prediction errors are reduced and then it
increases the embedding capacity.
V.
CONCLUSIONS
In this paper, we have proposed a reversible watermarking
algorithm based on the histogram shifting of the difference
image between a original image and a predicted image. In
order to solve the underﬂow and overﬂow problems, a location
map is generated, compressed, and embedded as a part of
the watermark message. In previous works, the reference
pixels are distributed by equally spaced interval and the pixels
surrounded the reference pixels are just bi-linearly interpolated.
To enlarge the embedding capacity while keeping the visual
quality of the watermarked image, we have suggested the
alternative way to make reference pixel map and predicted the
smooth area by directional interpolation. From the simulation
results, we can conclude that the the proposed algorithm
generates good watermarked image quality and embedding
capacity.
REFERENCES
[1]
J. Tian, “Reversible Watermarking by Difference Expansion,” IEEE
Trans. on Circuits and Systems for Video Technology, vol. 13, no. 8,
Aug. 2003, pp. 890-896.
[2]
Z. Ni, Y.Q. Shi, N. Ansari, and W. Su, “Reversible Data Hiding,” IEEE
Trans. on Circuits and Systems for Video Technology, vol. 16, no. 3, Mar.
2006, pp. 354-362.
[3]
L. Luo, Z. Chen, M. Chen, and X. Zeng, “Reversible Image Water-
marking Using Interpolation Technique,” IEEE Trans. on Information
Forensics and Security, vol. 5, no. 1, Mar. 2010, pp. 187-193.
[4]
W. Hong, and T. Chen, “Reversible Data Embedding for High Quality
Images Using Interpolation and Reference Pixel Distribution Mecha-
nism,” Journal of Visual Communication and Image Representation, vol.
22, no. 2, Feb. 2011, pp. 131-140, 2011.
[5]
H.M. Yoo, S.K. Lee, and J.W. Suh, “High capacity reversible data hiding
using the histogram modiﬁcation of block image,” in Proc. ISCAS, May
2010, pp. 1137-1140.
150
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-353-7
UBICOMM 2014 : The Eighth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

