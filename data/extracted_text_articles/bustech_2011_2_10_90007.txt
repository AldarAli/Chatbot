Towards "Executable Reality”: Business Intelligence on Top of Linked Data
Vagan Terziyan
Department of Mathematical Information Technology, 
University of Jyvaskyla
P.O. Box 35 (Agora), 40014, Jyvaskyla, Finland
e-mail: vagan@jyu.fi
Olena Kaykova
Industrial Ontologies Group, Agora Center,
University of Jyvaskyla
P.O. Box 35 (Agora), 40014, Jyvaskyla, Finland 
e-mail: olena@cc.jyu.fi
Abstract—Tight competition within mobile technology domain 
resulted to quite advanced applications and services for the 
users. Among them there are mobile (augmented and mixed) 
realities  as an  effort  to enhance  real-world observation  by 
bridging it with virtual worlds of relevant data and services. At 
the same time, due to emerging Semantic Technology, the Web 
content  moves  rapidly  towards  Linked  Data.  The  layer  of 
machine-processable semantics allows automated processing of 
the  content  by  Web-based  Business  Intelligence  (BI) 
applications  and  services.  Real-time  analytics  related  to 
various real-life objects provided to the users of Mixed Reality 
by online BI services would be a nice enhancement  of the 
technology. In this paper we propose “Executable Reality” as 
an enhancement of the “Mixed Reality” concept within two 
dimensions (utilization of Linked Data and BI on top of it). We 
present “Executable Knowledge” as a tool to enable Linked 
Reality  and  “Executable  Focus”  to  control  it  by  a  user. 
Executable knowledge in addition to subject-predicate-object 
semantic  triplet  model  (in  ontological  terms)  contains  also 
subject-predicate-query  triplets.  Actual  value  for  the 
properties based on a new triplet will be computed “on-the-fly” 
(based on user request navigated by executable focus) by some 
online BI service or other computational capability provider at 
a right time and place according to the dynamic user context. 
Keywords-  Business  Intelligence;  Linked  Data;  Mixed 
Reality; Executable Reality; Executable Knowledge
I.
 INTRODUCTION
Business intelligence (BI) can be considered as a set of 
methods, techniques and tools utilized on top of business 
data  to  compute (acquire,  discover)  additional  (implicit) 
analytics out of it and to present it in a form suitable for 
decision-making,  diagnostics  and  predictions  related  to 
business.  Taking  into  account  that  “business  data”  is 
becoming highly heterogeneous, globally distributed (not 
only in  the  Internet  space  but  also  in  time),  huge  and 
complex,  extremely  context  sensitive  and  sometimes 
subjective,  the  ways  the  BI  is  utilized  have  to  be 
qualitatively changed. Semantic (Web) Technology [1, 2, 3] 
is  known  to  be  a  suitable  approach  to  enable  more 
automation within BI-related data processing. The vision of 
BI 2.0 [4]  includes  also issues  related  to SOA, mobile 
access, context handling, social media, etc. All these issues 
will also definitely benefit from adding semantics [5, 6]. It 
is however a known fact that there is not much semantically 
annotated data available for BI. We have to live with data 
sets created independently, according to different schemas 
or even data model types. The realistic role of Semantic 
Technology for such data would be linking related “pieces” 
of it with some semantic connections and by doing this 
transforming the original data into Linked Data.
There are no doubts that such semantically interlinked 
“islands”  of  data  have  a  lot  of  hidden  (implicit)  and 
potentially interesting information that none of separate data 
sets has alone. Now the challenge would be how to utilize 
BI on top Linked Data to be able to get all the benefits from 
semantic enhancement of the data.
Another  trend  is  related  to  fast  development  of 
technology,  tools  and  devices  for  better  delivery  and 
visualization of information to a user. Among those there 
are  technologies  like  Augmented  Reality  [11],  Mixed 
Reality [14] and mobile versions of both [12, 13, 15]. These 
technologies are based on automated interlinking of various 
Web-based digital data collections with the real-time data 
from sensors about physical world and presenting it in a 
useful  form  for  a  user.  An  interesting  topic  would  be 
considering these technologies in the context of business 
data or even BI-provided analytics. This may inspire more 
professional  use  of  Augmented  and  Mixed  Reality  in 
addition to public use of it. 
In this paper we propose “Executable Reality” as an 
enhancement of the “Mixed Reality” concept within two 
dimensions (utilization of Linked Data and BI on top of it). 
We present “Executable Knowledge” as a tool to enable 
Linked Reality and “Executable Focus” to control it by a 
user. Executable knowledge in addition to subject-predicate-
object semantic triplet model (in ontological terms) contains 
also subject-predicate-query triplets. Actual value for the 
properties based on a new triplet will be computed “on-the-
fly” (based on user request navigated by executable focus) 
by some online BI service or other computational capability 
provider in a right time and place and according to dynamic 
user context.
The rest of the paper is organized as follows: in Section 
II we discuss Linked Data issues and its enhancement by 
context-sensitive similarity links; in Section III we present 
(Mobile)  Augmented  and  Mixed  Reality technology  and 
challenges; In Section IV we show how these technologies 
can be further developed towards “Executable Reality” on 
top of enhanced Linked Data and BI services (there we also 
present concept of “Executable Knowledge”);  we discuss 
Related Work in Section V; and we conclude in Section VI.
26
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

II.
LINKED DATA AND SEMANTIC SIMILARITY
Linked Data is a concept closely related to the Semantic 
Web yet providing some specific facet into it. According to 
Tim  Berners-Lee  “The  Semantic  Web  is  not  just  about 
putting data on the web. It is about making links, so that a 
person or machine can explore the web of data. With linked 
data, when you have some of it, you can find other, related, 
data”  (http://www.w3.org/DesignIssues/LinkedData.html). 
The  so called “5 stars” advice from Tim Berners-Lee to 
enable Linked Data includes: making data available on the 
web (whatever non-proprietary format) as machine-readable 
structured data, utilizing open standards from W3C (RDF 
and SPARQL) to identify things and finally linking the data 
to other people’s data to provide context.
According to Kingsley Idehen (OpenLink Software CEO), 
due  to  development  of  Semantic  Technology,  meshing (or 
natural data  linking) will replace  mashing (brute-force data 
linking) and therefore mesh-ups can be considered as a next 
step comparably to the mash-ups in the sense to merge and 
integrate different data sources and processing devices  to 
provide new information services.
Linked Data can be considered as an outcome of the 
technology, which semantically interconnects heterogeneous 
data “islands” (e.g., as shown in Figure 1). Even if the 
original sources of data are highly heterogeneous (not just 
only different schema of data within the same data model 
type but also different data model types), still it is possible to 
build  some  “bridges”  between  entities  from  these  data 
sources  utilizing  semantic  technology.  The  traditional 
Semantic Web approach would be: (a) creating semantic 
model of the domain (ontology), (b) replacing original data 
from each source with full semantic (RDF) representation of 
its resources in terms of the ontology.   Of course such 
approach enables seamless integration of the original data 
and simplifies the usage of it. However with distributed and 
dynamic sources of data, which are managed and constantly 
updated independently, it would be difficult to provide such 
“semantic synchronization” (updating metadata and mapping 
it to the ontology) in real time. Therefore Linked Data would 
be less ambitious and more practical approach: data sources 
are managed independently as they used to be; semantic 
connections between  appropriate  resources  from  different 
sources will be either automatically discovered or manually 
created  whenever  appropriate.  Usage  experience  and 
usability performance for each separate data source will be 
preserved. The usability of such “virtually integrated” data 
storages will increase with the increase of the amount of the 
semantic “bridges”.
Figure 1. Linked Data: “bridges” between heterogeneous “islands” of data 
According to [7] there are three important types of RDF 
links within Linked Data: (a) “relationship links” that point 
at  related  things  in  other  data  sources  (like  “object 
properties”  in terms of OWL:  owl:  ObjectProperty);  (b) 
“identity links” that point at URI aliases used by other data 
sources to identify the same real-world object or abstract 
concept (e.g., owl: sameIndividualAs, owl: equivalentClass); 
(c) vocabulary links that point from data to the definitions of 
the vocabulary terms that are used to represent the data (like 
“datatype  properties”  in  terms  of  OWL:
 owl: 
DatatypeProperty).
We think it would be reasonable to extend traditional 
explicit semantic links within Linked Data with the implicit 
ones, e.g., those, which could be automatically derived by 
various reasoners. Among those special attention should be 
paid to the “semantic similarity” links. Usually, when one 
queries a data, she looks for the resource(s), which are “the 
same” as the one specified in the query. However often there 
are none of such found. In many cases there is a sense to find 
“similar” to a target one resources. Similarity search was 
always  a  big  issue  within  many  disciplines  and  it  is 
especially important  for  the Linked  Data.  The reason  is 
related to the fact that actually same resources in different 
“islands” of data may have different URIs and often quite 
extensive work should be done to recognize same resources. 
Usually first we see that some resources look similar and 
27
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

therefore in practice could be the same ones and then we 
perform some check on the identity of the resources. Another 
use  of similarity measure  is when  one is looking for a 
capability providing resource (e.g., a service), cannot find 
exactly the one she wants but still will be satisfied by finding 
a  resource  with  similar  functionality.  Therefore  explicit 
similarity links between data entities would be reasonable to 
have as a result of appropriate similarity search procedures. 
The two major challenges here are: (a) a resource within one 
data “island” may have very different model of description 
when  compared  to  some  resource  within  another  data 
“island” (e.g., a human documented in a relational database 
will not be easily compared with a human from some XML 
storage or from some html document); (b) some resources 
being  very  different  in  one  particular  context  could  be 
considered as similar ones in some other context. 
We  consider  three  types  (sub-properties  in  terms  of 
OWL)  of  semantic  similarity  based  on  common  ternary 
object property relation named  isSimilarGivenContext and 
they are: (1)  isSimilarGivenQuery; (2)  isSimilarGivenRole; 
and  (3)  isSimilarGivenGoal.  The  first  type  of  similarity 
assumes that two resources can be considered as similar ones 
(in  the  context  of  some  semantic  query,  e.g.,  SPARQL 
query) if this query, being applied over the locations of these 
two resources, returns both of them as a result. For example, 
resources “Mikhail S. Gorbachev” and “George W. Bush” 
will be considered as similar ones, given query “Former 
president, male with at least one daughter”. The second type 
of similarity assumes that two resources will be used as 
similar ones if they both can fill some slot in a business 
process with the specified role.  For example, some instance 
of class “Lamp” can be considered similar to some instance 
of class “Candle”, given role “Lightening”. The third type of 
similarity applies to the resources which can be replaced 
with each other as input parameters needed to perform some 
function (action) or utilize some external capability (service) 
without affecting expected outcome. For example, a “Bottle 
of vodka” would be a similar resource to e.g., “Pack of beer” 
as  an  “input”  (“natural  payment”)  to  a  ferry  service 
somewhere in Siberia countryside, given goal “To cross the 
river”. More information about our approach for defining 
context  in  various  practical  applications  and  semantic 
similarity search within context can be found in [8, 9, 10]. 
The major challenge is how to provide support for automated 
utilization  of  Linked  Data,  which  in  fact  remains 
heterogeneous, and how to get added value of additional 
semantic connections between data components. Anyway we 
claim that providing similarity links, in addition to traditional 
types of RDF links described in [7], can be very helpful for 
practical utilization of Linked Data and we will try to show 
this in the following sections of the paper.
III.
AUGMENTED AND MIXED REALITY
Augmented Reality (AR) [11] is a technology aimed to 
enhance the traditional perception of a reality (real-world 
environment), which elements are augmented by computer-
generated sensory input (e.g., data, sound or graphics). AR 
enriches real world for the user rather than replaces it. By 
contrast,  virtual  reality  replaces  the  real-world  with  a 
simulated one. Emerging development of mobile computing 
has naturally resulted to growing interest towards Mobile AR 
[12] and also to Ubiquitous Mobile AR [13] for successfully 
bridging the  physical  world  and  the  digital  domain for 
mobile users. The AR concept has been further developed to 
Mixed Reality [14], which means merging of real and virtual 
worlds  to  produce  new  environments  and  visualizations 
where physical and digital objects co-exist and interact in 
real time. In June 2009, Nokia Research Center announced 
the vision [15] of Mobile Mixed Reality, according to which 
a phone becomes a “magic lens” (smart and context-aware), 
which lets users look through the mobile display at a world 
that  has  been  supplemented  with  information  about  the 
objects that it sees.  The users simply point their phone’s 
camera, and look “through” the display. Objects of interest 
visible in the current view  will be  gathered from existing 
Point-Of-Interest databases or created by the user and will be 
highlighted. They can be associated with physical objects or 
featureless spaces like squares and parks. Once selected, 
objects provide access to additional information from the 
Internet  and  hyperlinks  to  other  related  objects,  data, 
applications and services.  Context-awareness is guaranteed 
by various rich sensors that are being incorporated into new 
phones  (GPS  location,  wireless  sensitivity,  compass 
direction,  accelerometer  movement,  sound  and  image 
recognition, etc.). Therefore the new technology is going to 
actively utilize acquired dynamic context to better filter and 
select  relevant  information  about  surrounding  real-world 
objects for a user.
In the following section we further develop the concept 
of (mobile) mixed reality within two dimensions: the first 
one is related to Linked Data utilization and the second one 
will be related with the utilization of Business Intelligence 
through “Executable Knowledge”. 
IV.
TOWARDS “EXECUTABLE” REALITY
The  concept  of  “Executable  Reality”  and  associated 
technology, which we are offering, should be considered as 
an extension of the (Mobile) Mixed Reality concept and the 
technology. If the traditional technology assumes that the 
explicitly  available  relevant  data  about  some  real-world 
object will be taken from some database and delivered to the 
user on demand (based on her attention focus pointed to this 
object), the Executable Reality in addition is able to provide 
online  BI  computation  on  similar  demand  (we  call  it 
“Executable  Focus”)  and  present  to  the  user  results  of 
computed analytics adapted for the current context. Two use-
case  scenarios  for  the  Executable  Reality  are  shown  in 
Figure 2 (a, b).  In the first one, the user (maintenance 
engineer  of the  power  network  company)  is  putting the 
executable focus (smart phone camera) into direction of the 
power line and by doing this makes implicit request for the 
last 24 hours  performance statistics of this power line. The 
query will go further to server; appropriate BI service will be 
selected  and  automatically  invoked;  resulting  page  with 
numbers,  graphics  (and  sounds  if  appropriate)  will  be 
generated and delivered back to the terminal and shown in 
appropriate window of the screen as shown in Figure 2 (a). 
28
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

Figure 2. Executable Reality use case examples: (a) on-the-fly computed statistics about power line performance is delivered to mobile terminal of the 
maintenance engineer on implicit demand; (b) research performance statistics is delivered to the user based on chosen unit (click on the building where the 
university department is located and selecting context “research” for filtering appropriate data from the unit needed for research performance calculations)
29
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

Another  scenario  in  Figure  2  (b)  shows  that  a  user 
observes the campus map of some university and selects the 
building where a particular department is located. The user 
also  selects  the  context  in  which  she  wants  to  get 
performance statistics of the unit, e.g., “research”. Chosen 
object and the context together form the executable focus, 
which will automatically generate the query for the required 
computation. Then the process goes in a similar way as with 
previous scenario and the user will get  “fresh” statistics 
concerning research performance of the department chosen.
To enable Executable Reality we have to find effective 
way to utilize Linked Data, which is natural source for online 
BI  computations, and also to enable  BI  functionality as 
semantically  annotated  Web  services.  We  propose  to 
organize Linked Data in form of “Executable Knowledge”.
Executable Knowledge can be considered as distributed 
(or organized as a cloud) set of heterogeneous data storages 
and computational services (e.g., BI) interconnected with 
semantic (RDF) links. The major feature here is that, in 
addition  to  the  traditional  (“subject-predicate-object”  or 
“resource-property-value”)  triplet-based  semantics  of  an 
RDF link (either “datatype” property, where “value” is a 
literal;  or  “object”  property,  where  “value”  is  another 
resource), the new model will have new property type named 
“executable property” with the structure: “subject-predicate-
query”.  It is supposed that reasoners, engines, etc. working 
with such knowledge will execute query within target triplet 
and treat obtained result as a value for the property.  Two 
immediate advantages of this extension are: (a) triplet will 
always implicitly keep knowledge about most recent value 
for the property because query to some data storage or to 
some BI function will be executed only on demand when 
needed and the latest information will be delivered; (b) query 
may  be  written  according  to  different  standards,  data 
representation  types,  models  and  schemas  so  that 
heterogeneity of original sources of data and capabilities will 
not be a problem. Therefore distributed data collections can 
be maintained independently (autonomously) and “queried” 
in real time by executable RDF links.
Consider  simple  example  in  Figure  3.  Here  the 
executable statement in RDF (N3 syntax) actually means: “If 
you want to know with whom John is currently in love, 
execute the query Q1”. The query Q1 (prefix “exe:” points to 
Executable Knowledge ontology of various query types and 
indicates that the RDF statement is executable) in this case is 
semantically described as SPARQL query to the RDF data 
storage  and  it  means:  “Select  the  girl  from  the  current 
database of staff, who is colleague of John, has red hair and 
is 25 years old”. When the SPARQL query engine executes 
the query and finds that “Mary” fits it, the executable RDF 
statement is transformed into the traditional one (reference to 
the query “exe:Q1” is replaced with actual value “Mary”). 
Notice that, if the same knowledge will be explored after 1 
year, then the same executable statement will be transformed 
into:  “John  is  in  love  with  Anna”,  because  staff  data 
(separate  source)  will  be  autonomously  updated  (Anna 
becomes 25 years old) and RDF connections (semantic layer 
of Linked Data) on top will be updated when executed. 
Consider similar example in Figure 4 and notice that here 
we  have  an  SQL  query  to  some  relational  database  as 
implicit value of executable RDF statement. The query Q2 
means  request  for  computing  average  journal  papers’ 
publication performance of young (< 30) PhD students. The 
original executable RDF statement means: “If you want to 
know average performance of young doctoral students in AI 
Department, execute query Q2”. When the query returns 
computed  value  the  executable  RDF  statement  is 
transformed  into  the  traditional  one  (reference  to  query 
“exe:Q2” is replaced with actual value “7”, which means that 
“executable” RDF property is replaced with “datatype” one).
Figure 3. Example of processing executable RDF statement, which contains implicit value as SPARQL query to RDF storage 
30
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

Figure 4. Example of processing executable RDF statement, which contains implicit value as SQL query to a relational database
Figure 5. Example of processing executable RDF statement, which contains implicit value as S-APL query to BI software as a service
Consider example in Figure 5. Here we have executable 
RDF statement that can be interpreted like: “If you want to 
get basic BI-statistics report for the AI Department for last 3 
years, execute query Q3”. Behind this query there is a Java 
software  module  “UnitReportGenerator”  provided  as-a-
service  from online software  library.  The query itself is 
written in S-APL (Semantic Agent Programming Language 
[16]) used for UBIWARE-based applications [17]. S-APL is 
31
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

RDF-based language for multi agent systems, in which both 
data and actions are described semantically. UBIWARE [18] 
(“Smart Semantic Middleware for Ubiquitous Computing”) 
has  been  developed  by  Industrial  Ontologies  Group 
(http://www.cs.jyu.fi/ai/OntoGroup).  It  as  a  software 
technology and a tool to support design and installation, 
autonomic operation and interoperability among complex, 
heterogeneous,  dynamic  and  self-configurable  distributed 
systems,  and  to  provide  coordination,  collaboration, 
interoperability,  data  and  process  integration  service. 
UBIWARE  platform  is  used  actually  to  deal  with 
“Executable Knowledge” and its utilization for “Executable 
Reality” services. In the example, when the BI software is 
executed, it generates the html page where all analytics is 
visually presented with different BI widgets. The URI for 
this page will replace the implicit “exe:Q3” value from the 
original  RDF  statement  and  creates  traditional  RDF 
statement with object property connecting two resources (AI 
Department URI and BI statistics Report URI). 
There is also a possibility to compute semantic similarity 
between  resources  from  different  data  storages  and 
automatically create appropriate RDF connections for similar 
(same)  instances.  As  it  was  shown  in  Section  II,  some 
instances can be considered as similar ones in one context 
and can be considered otherwise in other context. Therefore, 
similarly  to  the  examples  above,  the  “Executable 
Knowledge”  supports  also  RDF  statements  with  implicit 
similarity search queries, in which needed query parameters 
are automatically taken from the current context. Change of 
context can be considered as implicit query (if appropriate 
setup is made) to re-compute similarity links, which makes 
RDF graph on top of Linked  Data very dynamic.   Our 
approach for context-sensitive semantic similarity computing 
and its implementation is discussed in [10].
Mixed  Reality  is  just  one  possible  way  to  utilize 
Executable Knowledge concept. There should be definitely 
other  application  areas  for  it.  Generally  many  industrial 
applications,  which  require  dynamic  self-configurable 
solutions, applications and architectures, will benefit from 
the flexible Executable Knowledge, as our experience with 
UBIWARE industrial cases demonstrates [18].
V.
RELATED WORK
Concepts  of  “virtual”,  “augmented”,  “mixed”,  etc., 
realities discussed in Section 1 are being actively developed 
into  various  services  for  public.  There  are  many  other 
relevant concepts and activities, which have many common 
features with the above, having however some specifics. One 
such abstraction is so-called “Mirror World” [19], which is a 
representation of the real world in digital form mapped in a 
geographically accurate way. Mirror worlds are can be seen 
as  an  autonomous  manifestation  of  digitalized  reality 
including  virtual  elements.  Other  relevant  concept  is 
“Metaverse”  (http://metaverseroadmap.org),  which  is  the 
convergence  of  virtually-enhanced  physical  reality  and 
physically persistent virtual space being a fusion of both. The 
“Second Life” (http://secondlife.com/) is a 3D virtual world 
enhanced  by  social  networks  and  communication 
capabilities. “Lifelogging” [20] is continuous capturing from 
a human and sharing through the Web various data, events 
and activities collected by various devices, sensors, cameras, 
etc.  Other  slightly  different  concept  is  “Lifeblog” 
[http://europe.nokia.com/support/product-support/nokia-photos], 
which is also known as popular service for collecting and 
putting into a timeline (mobile) user activities and creating 
data in the form of complex multimedia diary.
Our intension was to find out reasonable services out of 
these concepts suitable not just for public use but mostly for 
professionals. For that we explored the possibility to utilize 
Business Intelligence as an additional capability. Preliminary 
information  on  the  interesting  relevant  effort  named 
“Augmented Business Intelligence” has appeared in the Web 
[21]  just  a  couple  of  months  ago.   Augmented  BI  is 
considered in [21] as a process of using a mobile device to 
scan an image or a barcode and overlaying metrics and or 
charts onto the image. This supposes to facilitate the process 
of a store manager moving around a retail store and would 
like more information about that products sales performance. 
See Figure 6, which demonstrates possible use case for the 
Augmented BI. There are some evident similarities with our 
use-cases shown in Figure 2, however our implementation 
benefits from the Linked Data utilization and allows context-
sensitive view to the BI-enhanced reality.
Figure 6. Demonstration of possible Augmented Business Intelligence 
utilization scenario [21].
Our solution related to BI-enhanced mixed reality (or 
Executable  Reality)  is  based  on  Executable  Knowledge 
concept. The Executable Knowledge inherits some features 
from  a  Dynamic  Knowledge  (see,  e.g.,  [22]),  which  is 
actually dynamically changing knowledge and according to 
(www.imaginatik.com)  providing  on-demand,  in-context, 
timely,  and  relevant  information.  Issues  related  to  such 
knowledge  include  power  and  expressive  tools  and 
languages  (as,  e.g.,  LUPS  [23])  for  representing  such 
knowledge and proper handling of conflicting updates as 
addressed in [22].  Given an initial knowledge base (as a 
logic  program)  LUPS  provides  a  way  for  sequentially 
updating it.
Since  executable  knowledge  is  definitely  a  kind  of 
dynamic  knowledge,  other issue would be  whether  it  is 
declarative  or  procedural  knowledge.
 A  procedural 
knowledge  (or  knowledge  on  how  to  do  something)  is 
32
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

known to be a knowledge focused on obtaining a result and 
exercised in the accomplishment of a task, unlike declarative 
knowledge (propositional knowledge or knowledge about 
something)  [24].  Procedural  knowledge  is  usually 
represented as finite-state machine, computer program or a 
plan. It is often a tacit knowledge, which means that it is 
difficult to verbalize it and transfer to another person or an 
agent.  The  opposite  of  tacit  knowledge  is  explicit 
knowledge.
The concept of executable knowledge can be actually 
considered as a kind of hybrid of declarative and procedural 
knowledge. As it can be seen from the examples in Section 
4, by “executing” knowledge one actually transforms tacit 
(procedural)  knowledge  into  explicit  (declarative  one). 
Therefore  an  executable  knowledge  contains  explicit 
procedural  (meta-)  knowledge  on  how  to  acquire (or 
compute) declarative knowledge. Such capability means that 
the  executable  knowledge  is  naturally  self-configurable 
knowledge (or more generally – self-managed knowledge). 
We use S-APL (Semantic Agent Programming Language 
[16]) for its representation, which is based on RDF (N3) 
syntax and which is equally suitable to manage declarative 
and procedural knowledge.
Our implementation of the executable knowledge on top 
of  UBIWARE  [17,18]  agent-driven  platform  allows 
UBIWARE agents autonomously “execute” knowledge by 
following explicit  procedural  instructions for BI  services 
execution  and  therefore  updating  (or  making  explicit) 
appropriate declarative beliefs.   
VI.
CONCLUSIONS
In this paper, we presented one way on how Linked Data 
(from  heterogeneous  sources)  can  be  automatically 
processed by various BI services; and also how the results of 
BI processing can be shown through the (Mobile) Mixed 
Reality technology. Data heterogeneity problem is handled 
by  the  “Executable  Knowledge”  approach,  according  to 
which semantic (RDF) links include explicit queries to data 
or to (BI) services and other capabilities based on various 
possible data models and the context.
REFERENCES
[1]
Berners-Lee, T., Hendler, J., and Lassila, O., The Semantic Web. 
Scientific American, 284(5), 2001, pp. 34–43.
[2]
Sheth, A. and Ramakrishnan, C., Semantic (Web) Technology in 
Action: Ontology Driven Information Systems for Search, Integration 
and Analysis, IEEE Data Eng. Bulletin, 26(4), 2003, pp. 40-48.
[3]
Hitzler, P., Krötzsch, M. and Rudolph, S., Foundations of Semantic 
Web Technologies, Chapman&Hall/CRC, 2009, 455 pp.
[4]
Nelson,  G.,  Business  Intelligence  2.0:  Are  we  there  yet?  In: 
Proceedings of the SAS Global Forum 2010, Seattle, USA, 11-14 
April, 2011, paper 040-2010.
[5]
Domingue,  J.,  Fensel,  D.,  and  González-Cabero,  R.,  SOA4All, 
Enabling  the  SOA  Revolution  on  a  World  Wide  Scale,  In: 
Proceedings of the 2nd IEEE International Conference on Semantic 
Computing (ICSC 2008), August 4-7, 2008, Santa Clara, California, 
USA, IEEE CS Press, 2008, pp. 530-537.
[6]
Sell, D., Cabral, L., Motta, E., Domingue, J. and Pacheco, R., Adding 
Semantics  to  Business  Intelligence,  In:  Proceedings  of  16th 
International  Workshop  on  Database  and  Expert  Systems 
Applications, Copenhagen, 26 August, 2005, pp. 543 – 547.
[7]
Heath, T., and Bizer, C.,  Linked Data: Evolving the Web into a 
Global Data Space. Synthesis Lectures on the Semantic Web: Theory 
and Technology, Morgan & Claypool, 2011, 136 pp.
[8]
Khriyenko, O., and Terziyan, V., A Framework for Context-Sensitive 
Metadata Description, International Journal of Metadata, Semantics 
and Ontologies, 1(2), 2006, Inderscience Publishers, pp. 154-164.
[9]
Terziyan,  V.,  Predictive  and  Contextual  Feature  Separation  for 
Bayesian Metanetworks, In: B. Apolloni et al. (Eds.), Proceedings of 
KES-2007 / WIRN-2007, Vietri sul Mare, Italy, September 12-14, 
Vol. III, Springer, LNAI 4694, 2007, pp. 634–644.
[10] Khriyenko,  O., Terziyan, V., Similarity/Closeness-Based Resource 
Browser, In: J.J. Zhang (Ed.), Proceedings of the Ninth IASTED 
International  Conference  on  Visualization,  Imaging  and  Image 
Processing (VIIP-2009), July 13-15, 2009, Cambridge, UK, ACTA 
Press, pp. 184-191.
[11] Azuma, R., A Survey of Augmented Reality, Presence: Teleoperators 
and Virtual Environments 6 (4), 1997, MIT Press,  pp. 355-385.
[12] Hollerer,  T.,  Feiner, S., Terauchi, T., Rashid,  G.,  Hallaway,  D., 
Exploring MARS: Developing Indoor and Outdoor User Interfaces to a 
Mobile Augmented Reality System, Computers & Graphics, 23, 1999, 
Elsevier, pp. 779-785.
[13] Henrysson, A., Ollila, M., UMAR: Ubiquitous Mobile Augmented 
Reality, In:  Proceedings of  the  Third International Conference on 
Mobile  and  Ubiquitous  Multimedia (MUM-2004),  College  Park, 
Maryland, USA, 2004, pp. 41-45.
[14] Ohta, Y., Tamura, H. (Eds.), Mixed Reality: Merging Real and Virtual 
Worlds, 1999, Springer, 418 pp.
[15] Mobile Mixed Reality: The Vision, Nokia Technology Insights Series, 
Nokia  Research  Center,  June  2009,  4  pp.,  Available  online  in: 
http://research.nokia.com/files/insight/NTI_MARA_-_June_2009.pdf.
[16] Katasonov,  A.  and  Terziyan,  V.,  SmartResource  Platform  and 
Semantic Agent Programming Language (S-APL), In: P. Petta et al. 
(Eds.), Proceedings of the 5-th German Conference on Multi-Agent 
System Technologies (MATES’07), 24-26 September, 2007, Leipzig, 
Germany, Springer, LNAI 4687 pp. 25-36.
[17] Katasonov, A., Terziyan, V., Implementing Agent-Based Middleware 
for  the  Semantic  Web,  In:  Proceedings  of  the  Second  IEEE 
International  Conference  on  Semantic  Computing  (ICSC-2008)  / 
International  Workshop  on  Middleware  for  the  Semantic  Web, 
August 4-7, 2008, Santa Clara, USA, IEEE CS Press, pp. 504-511.
[18] UBIWARE:   http://www.cs.jyu.fi/ai/OntoGroup/UBIWARE.htm  , 
Project Web Site, Industrial Ontologies Group,  2008-2011.
[19] Gelernter, D., Mirror Worlds: or the Day Software Puts the Universe 
in a Shoebox...How It Will Happen and What It Will Mean, 1st ed., 
Oxford University Press, 1992.
[20] O’Hara, M., Tuffield, M., Shadbolt, N.,  Lifelogging: Privacy and 
Empowerment with Memories for Life, In: Identity in the Information 
Society, Vol. 1, No.1, Springer, pp. 155-172.
[21] Husting, P., Augmented Business Intelligence in Retail, In: Microsoft 
BI Collaboration and Community Blog,  3 March 2011, Available 
online  in:  http://blog.extendedresults.com/2011/03/03/augmented-
business-intelligence-in-retail/ (accessed 15 June 2011).
[22] Alferes,  J.,  Pereira,  L., Przymusinska,  H., Przymusinski,  T., 
Quaresma,  P., Dynamic  Knowledge  Representation  and  its 
Applications, In: Proceedings of the 9th International Conference on 
Artificial  Intelligence:  Methodology,  Systems,  and  Applications 
(AIMSA '00), Varna, Bulgaria, September 20-23, 2000, LNCS, Vol. 
1904, Springer, pp. 1-10.
[23] Alferes, J., Pereira, L., Przymusinska, H., Przymusinski, T., LUPS - 
A Language for Updating Logic Programs, In: Proceedings of the 5th 
International Conference on Logic Programming and Nonmonotonic 
Reasoning (LPNMR’99), El Paso, Texas USA, December 2-4, 1999, 
LNAI, Vol. 1730, Springer, pp. 162-176.
[24] Berge, T., Hezewijk, R., Procedural and Declarative Knowledge. An 
Evolutionary  Perspective,  Theory  &  Psychology,  1999,  Sage 
Publications, Vol. 9(5), pp. 605–624.
33
BUSTECH 2011 : The First International Conference on Business Intelligence and Technology
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-160-1

