Vision-based Inspection Algorithm for Identifying the Carbide Phase State in 
12CrMoV Steel 
 
 
Alexander Tzokev 
Theory of Mechanisms and Machines 
Technical University of Sofia 
Sofia, Bulgaria 
alextz@tu-sofia.bg 
Irina Topalova 
Automation of Discrete Production Engineering  
Technical University of Sofia 
Sofia, Bulgaria 
itopalova@tu-sofia.bg 
 
Anton Mihaylov 
Materials Science and Technology 
Technical University of Sofia 
Sofia, Bulgaria 
amm@tu-sofia.bg 
 
Tzanko Georgiev 
Industrial Automation 
Technical University of Sofia 
Sofia, Bulgaria 
tzg@tu-sofia.bg 
Abstract—Thе paper presents a vision-based inspection 
algorithm for identifying the carbide phase state in 12CrMoV 
steel microstructures. The algorithm uses image preprocessing, 
anisotropic 
segmentation, 
discriminant 
analysis 
and 
mathematical model for calculating the residual life of the 
material. Based on the state of the carbide phase, the residual 
life can be precisely calculated. By implementing automated 
vision inspection, the subjective evaluation of microstructures 
by experts will be avoided. 
Keywords-vision inspection; discriminant analysis; steel 
microstrucutres;  carbide phase; 12CrMoV steel 
I. 
 INTRODUCTION 
The properties and the residual life of many types of 
steels (heat-resistant steels, tool steels, high strength steels, 
etc.) depend on the carbide phase, the quantity and the type 
of carbides, their shape and distribution. The state of the 
carbide phase is defined by heat treatment and can be altered 
by the working conditions [1,2]. 
The 12CrMoV steel pipes are used in thermal power 
plants for building superheaters with working temperature of 
up to 580°C.  The microstructure of the metal alters (the 
properties of the material degrade) during exploitation based 
on the working temperature and the applied pressure. Visual 
analysis by experts shows that the carbide state in the 
microstructure is modified during the exploitation of the 
metal. This alteration is the main assessment factor for the 
structural state of the material and standard scales are used. 
The analysis is performed mainly by experts and consists in 
comparing the analyzed and standard scale images. This 
evaluation is subjective, uses a qualitative rather than a 
quantitative method and the results depend on the expert’s 
qualification level, competence and experience [1,3,4]. 
At the moment, there are no integrated systems for 
performing this assessment. Some companies offer partial 
software and hardware solutions. 
The microstructure state and the level of spheroidization 
(carbide phase) are used for calculating the time remaining 
until metal destruction - the residual life of the material. An 
automated carbide phase vision-based inspection algorithm 
(CPVBIA) will minimize the subjective evaluation and will 
help the experts in making their final decision for the 
residual life of the material. The CPVBIA applies 
quantitative assessment methods for achieving a qualitative 
result. 
Fig. 1 shows the structural alterations of the 12CrMoV 
steel and the corresponding level of the spheroidization 
based on the adopted standards [1,3]. 
The photos in Fig. 1 show a metal structure with ferrite 
(bright zones) and carbide phases (dark zones and grains). 
Level 1 corresponds to new material and level 5 corresponds 
to a material with exhausted residual life which must be 
replaced.  
The presented CPVBIA is based only on computer vision 
algorithms without implementing any adaptive technologies 
such as neural networks, genetic algorithms or fuzzy logic. 
The presented approach has 4 general stages, as shown in 
Fig. 2. 
 
Figure 1. Level of spheroidization in 12CrMoV steel microstructures. 
 
 
53
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

Stage 1
Image 
Preprocessing
Stage 2
Vision-based 
Feature Extraction
Stage 3
Mathematical 
Model for Level of 
Spheroidization
Stage 4
Mathematical 
Model for Residual 
Life
 
 
Figure 2. General stages of the CPVBIA 
 
The first stage contains the entire image preprocessing - 
image resizing, converting to grayscale, filtration, etc. In 
stage 2, vision algorithms are applied for extracting 
crystallite borders and for identifying interesting zones that 
may contain the carbide phase. The result from the second 
stage is an array of 5 different morphological parameters for 
the carbide phase. In stage 3, a mathematical model based on 
morphological parameters is used to define the level of 
spheroidization. The final fourth stage calculates the residual 
life of the material based on external variables (working 
pressure and working time), the calculated carbide phase 
level and mathematical model of linear approximation, 
derived from CTO 1723082.100.005-2008 [1]. 
100 sample images (20 for each level of spheroidization) 
were used in the study. All of these images were analyzed 
and classified by experts. 
II. 
IMAGE PREPROCESSING (STAGE 1) 
In this study, all input images are acquired by digital 
microscope camera with 2Mpix resolution. If the input image 
is not a grayscale one, then color to grayscale conversion is 
applied.  
The time needed for anisotropic segmentation (cf. III. 
Vision-based feature extraction) depends on the size of the 
input images. Therefore, in order to achieve higher 
performance, the algorithms in stage 1 resize the input image 
to 800x600 pixels if the original image is larger than that. To 
determine the relation between the size of the input image 
and the achieved recognition accuracy, a separate study can 
be conducted. An empirical analysis shows that 800x600 
pixels are sufficient for fast and reliable feature extraction. 
In general, stage 1 has only two steps: 
1. Grayscale conversion 
2. Image resizing 
III. 
VISION-BASED FEATURE EXTRACTION (STAGE 2) 
The second stage of CPVBIA extracts features from the 
image for further analysis and calculation of the 
spheroidization level. The extracted set of features must 
identify the carbide phase precisely and provide numerical 
data for stage 3. Two general types of features are extracted: 
1. Crystallite borders 
2. Interesting zones possibly containing carbide phase 
blobs 
Fig. 3 shows the analyzed image, the interesting zones 
and the extracted borders of the grains. 
 
 
a) Analyzed image 
b) Extracted border 
 
 
c) Interesting zones 
d) Merged image 
 
Figure 3. General stages of the CPVBIA 
A. Extracting borders of the crystallites 
To extract the borders of the grains after the image 
preprocessing, an anisotropic segmentation algorithm is 
applied. This segmentation algorithm is based on the method 
proposed by Malik [5]. This algorithm  can  segment  
grayscale  images  in  disjoint  regions  of  coherent  
brightness  and contrast. Contours are treated in the 
intervening contour framework, while texture is analyzed 
using textons.  Each  of  these  cues  has  a  domain  of  
applicability,  so  to  facilitate  cue combination  the  authors  
introduce  a  gating  operator  based  on  the  texturedness  of  
the neighborhood at a pixel. Having obtained a local measure 
of how likely two nearby pixels are to belong to the same 
region, the algorithm uses the spectral graph theoretic 
framework of normalized cuts to find partitions of the image 
into regions of coherent texture and brightness [5]. 
Two parameters are used for the anisotropic filtration - 
the threshold K and the number of iteration (I). Fig. 4 shows 
blob extraction with different values for K and I. 
Experiments show that the best border extraction is achieved 
when K=2 and I=500.  
After the anisotropic segmentation, a connected 
component labeling is applied for blob detection. The 
majority of the borders are connected so the biggest blob is 
extracted. 
 
Figure 4. Border extraction with different values for K and I 
 
54
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

B. Extracting interesting zones 
To define the interesting zones that may contain the 
carbide phase, a Bradley local threshold algorithm [6] is 
applied to the analyzed image. This algorithm is a simple 
extension of Wellner’s method [6] in which each pixel is 
compared to an average of the surrounding pixels and an 
approximate moving average of the last N pixels seen is 
calculated while traversing the image. If the value of the 
current pixel is T percent lower than the average, then it is 
set to black, otherwise it is set to white [6]. 
In the Bradley’s algorithm, by using the integral image 
(also known as a summed-area table) instead of computing a 
running average of the last S pixels seen, the average of an 
SxS window of pixels centered on each pixel is calculated. 
This is a better average for comparison since it considers 
neighboring pixels on all sides. The average computation is 
accomplished in linear time by using the integral image [7]. 
A previous study shows that this algorithm is suitable for 
extracting the sigma phase and non-metal inclusions in 
austenitic stainless-steel microstructures [8]. The sigma 
phase has similar image features as the carbide phase for 
12CrMoV steel. After the local threshold is applied, the 
resulting image is inverted and hit and miss filter is applied. 
The result is image containing the interesting zones. 
A connected component labeling is used for blob 
detection. These blobs contain the carbide phase, noise in 
the image and other detected particles. To extract the sigma 
phase blobs from the noise, a simple filtration is applied – 
all blobs with height and width of the bounding rectangular 
less than 3 pixels are removed.  
C. Morphological parameters 
The result from stage 2 of the CPVBIA must be a 
numerical set of data describing the carbide phase. This data 
contains the following information for each blob: 
1. Total number of blobs in the image. 
2. Total area of the blobs in the image, measured in 
pixels. 
3. Number of blobs inside the grains and on the 
borders. 
4. Number of blobs on borders. 
5. Average height of the bounding rectangular for all 
blobs, measured in pixels. 
6. Average width of the bounding rectangular for all 
blobs, measured in pixels. 
7. Average area of the blobs in the image. 
8. Average fullness (area of the blob divided by the 
surface of the bounding rectangle) for all blobs in 
the image. 
9. Average aspect (maximum of the height or width of 
the bounding rectangular, divided by the minimum 
of the height or width) for all blobs. 
The numbers of blobs inside the grains and on the 
borders are used for final decision by the expert and are not 
used in stage 3. Fig. 5 shows subset analysis of the 
morphological parameters based on the sample images. 
1
2
3
4
5
440
640
840
1040
1240
1440
Blobs count
Class
1
2
3
4
5
0
40
80
120
160
200
Area - average
Class
1
2
3
4
5
0
4
8
12
16
20
Height  - average
Class
1
2
3
4
5
5
8
11
14
17
20
Width  - average
Class
1
2
3
4
5
1,3
1,34
1,38
1,42
1,46
1,5
1,54
Aspect  - average
Class
1
2
3
4
5
0,38
0,4
0,42
0,44
0,46
0,48
0,5
Fullness  - average
Class
1
2
3
4
5
0
2
4
6
8
10
(X 10000,0)
Total area of blobs
Class
 
Figure 5. Subset analysis of the morphological parameters 
 
The subset analysis shows that there is no only one 
morphological parameter that can classify the blobs. Each of 
the morphological parameters has some overlapping 
between the classes and a combination of two or more 
parameters should be used to correctly distinguish all 5 
classes. 
The summary statistics for the analyzed data is shown in 
Table I. 
TABLE I.  
SUMMARY STATISTICS FOR THE MORPHOLOGICAL 
PARAMETERS 
Class Count Average Standard 
Deviation 
Coefficient 
of variation Minimum Maximum 
1 
20 
517,6 
59,5752 
11,5099% 
445,0 
654,0 
2 
20 
815,1 
84,2514 
10,3363% 
661,0 
932,0 
3 
20 
1278,2 
110,928 
8,67849% 
1079,0 
1431,0 
4 
20 
844,4 
87,631 
10,3779% 
676,0 
1056,0 
5 
20 
1095,5 
53,7181 
4,90352% 
998,0 
1182,0 
Total 
100 
910,16 
273,071 
30,0025% 
445,0 
1431,0 
 
Class Range Standardized Skewness 
Standardized Kurtosis 
1 
209,0 
1,5628 
0,374479 
2 
271,0 
-0,583478 
-0,914204 
3 
352,0 
-0,170449 
-1,11532 
4 
380,0 
0,821561 
0,695647 
5 
184,0 
0,0152641 
-0,919001 
Total 
986,0 
0,0752718 
-1,80172 
IV. 
CALCULATING THE LEVEL OF SPHEROIDIZATION 
(STAGE 3) 
A discriminant analysis based on the morphological data 
from 100 images was used to calculate the parameters for 
classification functions. Table II contains the classification 
function coefficients. 
 
55
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

TABLE II.  
CLASSIFICATION FUNCTION COEFFICIENTS 
 
1 
2 
3 
4 
5 
CBlobs 
0,0280909 
0,00172282 
0,0926188 
-0,020431 
0,0405502 
CArea 
-9,09884 
-9,65378 
-11,0216 
-10,1958 
-11,0222 
CHeight 
125,935 
128,924 
144,078 
130,624 
139,747 
CWidth  
112,696 
95,9607 
111,781 
101,348 
116,161 
CFullness 
5471,58 
5255,23 
5589,67 
5561,88 
5876,29 
CAspect 
2508,6 
2701,41 
2721,89 
2861,86 
2831,37 
CTotalArea 
-0,0192403 
-0,0185858 
-0,0205796 
-0,0208617 
-0,0218383 
CONST 
-3382,34 
-3338,62 
-3729,97 
-3632,74 
-3909,51 
 
 
( )
ln
.
.
.
.
.
.
.
i
i
i
i
i
i
i
Blbos
Area
i
Height
Width
Ful
ess
Aspect
TotalArea
y
CONST
C
Blob Count
C
Averagearea
C
Averageheight
C
Averagewidth
C
Average fullness
C
Averageaspect
C
Total area
=
+
+
+
+
+
+
+
+
+
+
 
(1) 
where 
i =1..5
 and the level of the spheroidization is 
calculated by (2). 
( ( )
i )
Level of spheroidization
= MAX y
 
(2) 
The classification with prior probability of 0,2 for all 
levels is shown in Table III. 
TABLE III.  
CLASSIFICATION TABLE FOR DISCRIMINANT ANALYSIS 
Actual 
Class 
Group 
Size 
Predicted Class 
1 
2 
3 
4 
5 
1 
20 
20 
0 
0 
0 
0 
(100,00%) 
(  0,00%) 
(  0,00%) 
(  0,00%) 
(  0,00%) 
2 
20 
0 
20 
0 
0 
0 
(  0,00%) 
(100,00%) 
(  0,00%) 
(  0,00%) 
(  0,00%) 
3 
20 
0 
0 
20 
0 
0 
(  0,00%) 
(  0,00%) 
(100,00%) 
(  0,00%) 
(  0,00%) 
4 
20 
0 
0 
0 
19 
1 
(  0,00%) 
(  0,00%) 
(  0,00%) 
( 95,00%) 
(  5,00%) 
5 
20 
0 
0 
0 
0 
20 
(  0,00%) 
(  0,00%) 
(  0,00%) 
(  0,00%) 
(100,00%) 
The summary statistics by each group is shown in Table IV. 
TABLE IV.  
SUMMARY STATISTICS BY GROUP 
Class 
1 
2 
3 
4 
5 
TOTAL 
COUNTS 
20 
20 
20 
20 
20 
100 
MEANS 
Blobs count 
517,6 
815,1 
1278,2 
844,4 
1095,5 
910,16 
Area 
average 
164,978 
72,2296 
40,8611 
13,0502 
24,8825 
63,2003 
Height 
average 
16,0838 
10,282 
9,30539 
5,32764 
6,94183 
9,58813 
Width 
average 
17,3916 
11,2668 
9,46961 
5,7954 
7,3866 
10,262 
Fullness 
average 
0,411401 
0,3996 
0,4436 
0,427 
0,4725 
0,430824 
Aspect 
average 
1,44945 
1,46447 
1,45718 
1,39305 
1,42559 
1,43795 
Total area 
of blobs 
84434,6 
58818,1 
51339,6 
11120,6 
27269,2 
46596,4 
STD. DEVIATIONS 
Blobs count 
59,5752 
84,2514 
110,928 
87,631 
53,7181 
273,071 
Area 
average 
18,5875 
8,4545 
8,95146 
2,00407 
1,61811 
55,7795 
Height 
average 
1,20869 
0,630084 
0,90664 
0,38898 
0,2901 
3,77871 
Width 
average 
1,04933 
0,790887 
1,04796 
0,43678 
0,43977 
4,11296 
Fullness 
average 
0,012544 
0,00770 
0,00952 
0,02654 
0,02439 
0,0311191 
Aspect 
average 
0,035857 
0,042157 
0,02393 
0,02766 
0,0278 
0,0409149 
Total area 
of blobs 
3647,13 
8959,74 
7020,1 
2638,28 
2343,12 
26143,4 
 
Fig. 6 shows sample plots for some of the discriminant 
functions. 
 
-15
-11
-7
-3
1
5
9
Function 1
-8
-5
-2
1
4
7
Function 2
Class
1                                       
2                                       
3                                       
4                                       
5                                       
-2,6
-1,6
-0,6
0,4
1,4
2,4
Function 4
-15
-11
-7
-3
1
5
9
Function 1
Class
1                                       
2                                       
3                                       
4                                       
5                                       
-5,3
-3,3
-1,3
0,7
2,7
4,7
6,7
Function 3
-2,6
-1,6
-0,6
0,4
1,4
2,4
Function 4
Class
1                                       
2                                       
3                                       
4                                       
5                                       
-5,3
-3,3
-1,3
0,7
2,7
4,7
6,7
Function 3
-15
-11
-7
-3
1
5
9
Function 1
Class
1                                       
2                                       
3                                       
4                                       
5                                       
 
 
Figure 6. Classification functions 
V. 
CALCULATING THE RESIDUAL LIFE (STAGE 4) 
The residual life is defined by the standard curves 
published in [1] and according to the same metallography 
standard several parameters are used to calculate this value: 
1. Working hours 
2. Nominal pressure 
3. Level of spheroidization 
 As it was already defined, this analysis is subjective and 
highly dependent on the proficiency level of the expert. One 
of the main advantages of CPVBIA is removing the human 
factor. 
56
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

From stage 3 the level of spherodization is calculated. By 
using linear approximation and the exponential equations 
from the nomograms the residual life can be precisely 
calculated avoiding the subjective factor. 
VI. 
CPVBIA COMPLETE STRUCUTRE 
The complete structure of the CPVBIA algorithm is 
shown in Fig. 7. 
 
 
 
Figure 7. Complete structure of CPVBIA algorithm  
VII. EXPERIMENTS AND RESULTS 
To test and to validate the proposed algorithm, two 
groups of images were used. Group A contains images of 
steel microstructures of 12CrMoV steel for levels 1 to level 
5. Group B contains images with varying contrast, 
microstructures of different steel type, larger optical 
magnification or insufficient preparation of the steel 
specimen. The results expected by experts are high 
classification accuracy within group A and high number of 
wrong classifications in group B. 
All of the images in group A and group B were not used 
in the preliminary discriminant analysis. 
Table V shows the results from the analysis. 
TABLE V.  
EXPERIMENTAL DATA 
Test Group 
Description 
Count 
Correctly 
classified 
Wrong 
classification 
Group A 
Level 1 
8 
8 
0 
Level 2 
13 
10 
3 
Level 3 
6 
5 
1 
Level 4 
18 
18 
0 
Level 5 
11 
10 
1 
Group B 
Modified Contrast 
4 
0 
4 
Different steel type 
1 
0 
1 
Bigger optical 
magnification 
8 
0 
8 
Not  well developed 
borders 
2 
0 
2 
Wrong amount of 
ferrite 
1 
0 
1 
 
Fig. 
8 
shows 
graphical 
representation 
for 
the 
classification accuracy in group A. 
 
 
 
Figure 8. Recognition accuracy for group A 
 
The classification accuracy for group A is 91.07% and 
0.00% for group B, and these results confirm the 
expectations of experts. According to CTO 1723082.100.005-
2008, the calculation of the carbide phase should be made on 
multiple microstructure images from the same steel exemplar 
[1].  
57
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

Further analysis shows that two of the wrongly classified 
images in group A contain high amount of non-metal 
inclusion in the material, and one image has blurred zones. 
To improve the recognition accuracy, some images with 
small amount of non-metal inclusions can be added to the 
discriminant analysis for each level. 
A detailed analysis of the algorithm parameters for group 
B shows that the error percentage between the correct level 
(classified by an expert) and the wrong level (classified by 
the CPVBIA) varies depending on the image type. Table VI 
contains the average of the classification functions and 
y
∆ (see (3)). 
Correct
Wrong
y
y
y
∆ =
−
 
(3) 
TABLE VI.  
EXPERIMENTAL DATA FOR GROUP B 
Description 
Classification function - average 
Avg  
ΔY 
y1 
y1 
y2 
y4 
y5 
Modified 
contrast 
817.23 
845.71 
855.76 
857.18 
857.73 
-1.41 
Different 
steel type 
1025.8 
1025.4 
1028.1 
1035.5 
1041.5 
-15.70 
Bigger 
optical 
magnification 
896.90 
916.76 
919.90 
928.95 
929.74 
-7.32 
Poorly 
developed 
borders 
903.46 
919.47 
921.56 
928.56 
931.1 
-4.24 
Wrong 
amount of 
ferrite 
1109.8 
1104.4 
1110.4 
1117.4 
1126.3 
-16.50 
 
If the algorithm is used in an application, two of the most 
common problems with the input images will be the different 
contrast and the borders development. The contrast may vary 
due to different light conditions and the camera – Fig. 9a. 
Improper preliminary preparation and polishing of the steel 
specimen can lead to blurred or missing borders of the 
crystallites (see Fig. 9b). 
 
 
 
a) 
b) 
Figure 9. Input images with dissimilar contrast (a) and with poorly 
developed borders (b) 
 
The 
∆y
 for these two types of images is low. If the 
images used in the discriminant analysis contain samples 
with varying contrast and poorly developed borders, the 
overall classification accuracy of the algorithm can be 
increased.  
The analysis time for a single test image with the 
proposed algorithm parameters is around 170 seconds and 
depends on the hardware used. The slowest function is the 
anisotropic segmentation. By modifying the K and 
decrementing the number of iterations (cf. III, part A) the 
algorithm will be faster. In this type of analysis the overall 
inspection time is not important, but faster execution will 
allow the usage of the CPVBIA in more complex systems.  
If a faster execution time is required (for application in 
real-time systems), an adaptive approach can be adopted. In 
this case the CPVBIA can be used in parallel for later 
validation or comparison of the results. 
VIII. CONCLUSIONS 
A vision-based inspection algorithm for identifying the 
carbide phase and calculating the level of spheroidization in 
12CrMoV is developed. 
The algorithm is stable and the calculation accuracy for 
the carbide phase is very high – 91.07% (based on 
experiments).  
The algorithm can be used in automated applications for 
carbide phase identification and calculation of the residual 
life of the material. 
The overall execution time is slow due to the large 
number of iterations in the anisotropic segmentation 
function. 
The CPVBIA can be used in parallel with adaptive 
approach (neural network) for result comparison. 
Future studies can be performed with high resolution 
images and the algorithm can be tested for real-time 
application. 
REFERENCES 
[1] CTO 1723082.100.005-2008, Russia, 2008. 
[2] I. Savova, N. Petrov, “Vacuum Heat Treatment of Tool Steels 
and Its Impact on the Operational Qualities of the Tools”, 
Academic Open Internet Journal, Vol. 8, 2002. 
[3] DL/T 773-2001, Spheroidization evaluation standard of 
12Cr1MoV steel used in power plants, 2002. 
[4] “ASM Handbook – Metallography and Microsotructures”, 
Volume 9, ASM, USA, 2004. 
[5] J. Malik, S. Belongie, T. Leung and J. Shi, “Contour and 
Texture Analysis for Image Segmentation”, Internationa 
Journal of Computer Vision 43(1), Kluwer, Academic 
Publishers, Netherlands, pp. 7-27. 
[6] 
A. Wellner, “Adaptive thresholding for the digitaldesk”, Tech. Rep. 
EPC-93-110, EuroPARC, 1993. 
[7] D. Bradely and G. Roth, “Adaptive Thresholding Using the 
Integral Image”, Journal of Graphics Tools, A K Peters Ltd, 
Vol 12,  USA, pp. 13-22. 
[8] A. Tzokev, I. Topalova, and A. Mihaylov, “Adaptive 
Approach for Filtering the Sigma Phase in Austenitic 
Stainelss 
Steel 
Metallographic 
Mictrostructures”, 
Mediterranean Conference on Control and Automation, 
Greece, 2011, pp. 1259-1264. 
 
 
 
58
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

