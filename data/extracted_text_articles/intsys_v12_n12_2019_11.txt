123
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Governing Roles and Responsibilities in a Human-Machine Decision-Making 
Context: A Governance Framework 
 
Koen Smit 
Digital Smart Services 
HU University of Applied Sciences Utrecht 
Utrecht, the Netherlands 
koen.smit@hu.nl 
 
Martijn Zoet 
Optimizing Knowledge-Intensive Business Processes 
Zuyd University of Applied Sciences 
Sittard, the Netherlands 
martijn.zoet@zuyd.nl 
 
 
 
Abstract—Proper decision-making is one of the most important 
capabilities of an organization. Therefore, it is important to 
have a clear understanding and overview of the decisions an 
organization makes. A means to understanding and modeling 
decisions is the Decision Model and Notation (DMN) standard 
published by the Object Management Group in 2015. In this 
standard, it is possible to design and specify how a decision 
should be taken. However, DMN lacks elements to specify the 
actors that fulfil different roles in the decision-making process 
as well as not taking into account the autonomy of machines. 
In this paper, we re-address and - present our earlier work [1] 
that focuses on the construction of a framework that takes into 
account different roles in the decision-making process, and also 
includes the extent of the autonomy when machines are 
involved in the decision-making processes. Yet, we extended 
our previous research with more detailed discussion of the 
related literature, running cases, and results, which provides a 
grounded basis from which further research on the governance 
of (semi) automated decision-making can be conducted. The 
contributions of this paper are twofold; 1) a framework that 
combines both autonomy and separation of concerns aspects 
for decision-making in practice while 2) the proposed theory 
forms a grounded argument to enrich the current DMN 
standard. 
Keywords-Decision-Making; DMN; RAPID; Autonomy. 
I. 
 INTRODUCTION  
In September 2015, the Object Management Group 
(OMG) released a new standard for modelling decisions and 
underlying business logic, DMN [2]. In line with the DMN 
standard, a decision is defined as: “A conclusion that a 
business arrives at through business logic and which the 
business is interested in managing.” [3]. Furthermore, 
business logic is defined as: “a collection of business rules, 
business decision tables, or executable analytic models to 
make individual decisions.” [2]. 
Proper decision-making is one of the most important 
capabilities of an organization [4]. In the previous decades, 
decision making was a capability only executed by human 
actors. However, given the technical developments in 
computer hard- and software, the possibilities to automate 
decision-making increases. Examples of techniques applied 
during automated decision making are: business rules 
systems, expert systems, and neural networks [5]. To achieve 
proper decision-making, organizations must design and 
specify their decisions and decision-making processes. One 
aspect that influences the specification of the decision and 
the decision-making process is the level of automated 
decision-making. Machines can execute decisions only when 
the decision and the underlying business logic is specified 
formally [6]. Furthermore, when organizations choose to 
specify their decisions and decision-making processes, the 
level of detail is of importance. This is based, amongst 
others, on the type of decision and the actor that executes the 
decision. For example, a strategic decision needs to be 
specified on a different level of detail compared to an 
operational decision and therefore needs a different type of 
specification and a different decision-making process.  
While DMN is mainly applied to express operational 
decisions that will be automated, it can also be used for 
manual (strategic) decision-making. In this paper, the focus 
is on operational decision-making. Yet, the current DMN 
standard lacks a formal concept to specify a governance 
structure for each decision. In this context, a governance 
structure is defined to express the roles and responsibilities 
relevant to a decision and the underlying decision-making 
process. This becomes important when a decision is 
executed by instantiating a decision-making process that 
features both human and machine actors. Research on 
specifying a proper governance structure for decision-
making already concluded that assigning clear roles and 
responsibilities are the most important steps in the design 
and specification of decisions and result in better 
coordination and quicker response times [3][6]. 
Another aspect of designing and specifying decisions 
and decision-making is the use of machine actors instead of 
human actors. Assigning machine actors to parts of the 
decision-making process requires organizations to evaluate 
the autonomy of the machine. Machine autonomy refers to 
the system’s capability to carry out its own tasks and making 
decisions [8]. As Parasuraman, Sheridan and Wickens [9]  
stated in their work, the question now is: “which system 
functions should be automated, and to what extent?” For 
example, when possible, do we want to let a machine decide 
whether a person should or should not be admitted to enter a 
given country, based on the premise that the machine is more 

124
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
accurate compared to a human actor in determining the 
eligibility of a person.  
One reason why it is essential to include proper 
governance structure when designing and specifying 
decisions 
and 
decision-making 
processes 
are 
the 
increasingly stricter laws and regulations on digital privacy 
and data regulation, i.e., the Health Insurance Portability and 
Accountability Act (title II) and the General Data Protection 
Regulation [10]. Such laws and regulations can prohibit the 
use of machine actors in decision-making, and when it 
allows organizations to include them, poses exactly what is 
allowed and what is not allowed. For example, how exactly 
personal data is processed, and which roles have access to it. 
Thus, to design compliant decisions and decision-making, an 
organization must be able to define exactly what actors are 
responsible for what, and when a machine is made 
responsible, how autonomous it will operate.  
In literature, studies are conducted that resulted in a 
model to define, for example, the autonomy of a machine in 
decision-making 
[8][10][11]. 
Moreover, 
studies 
are 
conducted that specify the roles that are used to design 
decision-making processes between stakeholders [3][12]. 
However, to the knowledge of the authors, no studies exist 
that combine both. One notable industry in which roles and, 
to some extent, responsibilities are explored and made 
explicit is the medical domain. Examples are [14][15][16], 
and [17]. However, these are, to the knowledge of the 
authors, not explored in a human-machine context. 
Therefore, in this paper, a model is proposed that 
includes the roles and responsibilities aspect, taking into 
account human-machine interaction, while also including the 
autonomy level of a machine as part of the human-machine 
interaction in decision-making. To be able to do so, the 
following research question is addressed: “How can a 
governance structure of the decision making process be 
made explicit?” 
The remainder of this paper is organized as follows. First, 
a literature overview is presented in section two in which the 
existing models that define the possible interaction between a 
human and a machine are explored and compared. This is 
followed by the construction of the model in section three. 
Next, in section four, the case to demonstrate and validate 
the model is described, which is followed by the actual 
demonstration of the model. Lastly, the conclusions are 
drawn and we propose directions for future research in 
section five.  
II. 
BACKGROUND AND RELATED WORK 
The DMN standard consists of two levels; the Decision 
Requirements Level (DRD) and the Decision Logic Level 
(DLL). The DRD level consists of four concepts that are 
used to capture essential information with regards to 
decisions; 1) the decision, 2) business knowledge, which 
represents the collection of business logic required to 
execute the decision, 3) input data, and 4) a knowledge 
source, which enforces how the decision should be taken by 
influencing the underlying business logic, see Figure 1. The 
contents of the DLL level are represented by the business 
knowledge container in the DRD level. In the current 
version of DMN, two standard languages are suggested for 
expressing business logic, FEEL and SFEEL. However, it 
also allows the use of other, more adopted languages like 
JavaScript, Groovy, and Python. Still, the language 
selected to represent the decision logic does not influence 
the decision requirements level. Analysis of the DMN 
standard reveals that no formal elements exist to specify 
roles in the decision-making process. To add to the DMN 
standard, roles and responsibilities should be taken into 
account. 
 
 
 
Figure 1. DRD-level elements 
A. Roles and responsibilities in decision-making 
In the current body of knowledge, frameworks that define 
roles and responsibilities in decision-making processes exist. 
These studies focus on different perspectives in the decision-
making process. For example, there are studies that focus on 
the influences of decision-making roles, i.e., family/collegial 
pressure and gender or cultural preferences [13][14].  In 
addition, there are also studies that focus on specific 
application areas for decision-making, i.e., transportation, 
medical, financial and governance [15][16]. For example, in 
a patient-doctor context where a treatment has to be decided, 
multiple roles are relevant, i.e., the patient, different medical 
specialists, the doctor, a nurse, and in some cases family 
members of the patient [21].  
Another research stream in decision-making comprises 
group-based decision-making. Group-based decision-making 
is explored because the context comprises multiple 
stakeholders that should be taken into account during 
decision-making, 
thus 
fulfilling 
roles 
and 
having 
responsibilities during the decision-making process. To the 
knowledge of the authors, a lot of contributions have been 
published on group-based decision-making processes, e.g., 
on group-based decision-making in the utility industry to 
determine wind farm site locations [22], trip planning as part 
of the transport industry [23], the allocation of primary 
health care services [24], group-based R&D project selection 
[25], and the performance of group-based decision making 
[26]. 
However, as the scope of this paper lies on the creation 
of a framework which can be applied to define the 
governance structure of any decision, a more generic set of 
roles and responsibilities is required. 
The work of Rogers and Blenko [4] features a generic 
model titled RAPID, which presents five different roles that 
are applied during the decision-making process. However, 
one limitation of the original study is the focus on decisions 

125
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
that are only executed by human actors. To ground our 
framework construction, a detailed description of the RAPID 
framework is provided here.   
RAPID focuses on assigning a set of specific roles with 
regards to a decision. This framework is characterized by a 
simple, yet grounded in practice approach and consists of 
five different roles and underlying responsibilities that are 
related to a decision. The first role is Recommend, which is 
responsible for making a proposal and gathering input for 
decision-making. This role communicates with the input role 
to 
ensure 
their 
viewpoints 
are 
embedded 
in 
the 
recommendation. The second role is Agree, which is 
responsible for evaluating a proposal provided by the 
recommender. This role has veto power over the 
recommendation. When this role declines a recommendation, 
a modified proposal has to be made. The third role is Input, 
which is responsible for providing input (data) to make the 
decision and are typically consulted on the decision. The 
opinion of this role is non-binding, but should be taken into 
account to ensure the decision does not falter during its 
execution. The fourth role is Decide, which is responsible as 
the formal decision maker and is accountable for the decision 
and its results. This role has the most authority compared to 
the other roles as it is able to resolve the decision-making 
between the previous roles by making the actual decision. By 
doing so, this role has the power to commit an organization 
to action based on decision-making. Lastly, the fifth role 
stands for Perform, which is responsible for executing the 
actual decision of the organization after it is decided by the 
previous role.  
Based on RAPID, Taylor [13], in a professional article, 
adapted the RAPID model but made a distinction between a 
human and a machine for decision-making processes in 
which he stresses that the action component can be different 
between these two. For example, when a decision must be 
executed in an organization, human actors perform the actual 
decision and also handle possible exceptions. When a 
machine executes decisions, exceptions are filtered out and 
send to human actors for further examination. Another 
significant difference between a human and a machine actor 
is the explicitness of business rules that a machine must be 
able to execute, and therefore must be maintained adequately 
versus the implicit knowledge for the decision-making 
utilized by human actors in the actual decision-making 
process. 
A non-generic framework which originates from the 
military domain is the Observe, Orient, Decide and Act 
(OODA) loop [27]. The OODA loop is arguably the basis for 
decision-making for many succeeding decision-frameworks 
in the military domain and also shown to influence decision-
making processes and frameworks outside of the military 
domain as well [28][29]. OODA features four activities that 
represent the roles and responsibilities that should be adhered 
to in order to make grounded decisions in military situations. 
The comparison shows that RAPID and OODA show 
overlap in roles, e.g., decide (identical in both frameworks) 
and Act (OODA) versus Perform (RAPID). Multiple 
extensions have been proposed, based on the original OODA 
framework [30]. These extensions are proposed  due to the 
fact that OODA is considered 1) a very high-level 
representation with abstract concepts that do not provide the 
kind of details needed for the OODA loop to be used as an 
analytical tool for improving decision-making, and 2) It has 
no representation of the feedback or feed-forward loops 
needed to effectively model dynamic decision-making [31]. 
The latter, however, is included in the RAPID framework.   
B. Autonomy level of stakeholders in human-machine 
interaction 
      Machine autonomy broadly refers to a machine’s 
capability to carry out its own processes and tasks, along 
with the decision-making needed to do so [8]. 
With regards to machine autonomy, also referred to as 
robot autonomy or computer autonomy, many authors added 
a framework to the body of knowledge that defines 
autonomy 
levels. Both 
general 
and 
context-specific 
frameworks for levels of autonomy (LOA) exist, while some 
define very detailed levels of autonomy, others utilize 
autonomy as a concept without exactly defining the spectrum 
of autonomy [32]. In this paper, the focus is on generic LOA 
frameworks. Regarding generic LOA frameworks, the work 
of Sheridan and Verplanck [33] and later Parasuraman, 
Sheridan and Wickers [9] defined ten levels of autonomy for 
decision-making with automation (i.e., machines/computers), 
also abbreviated to LOADAS. Their classification ranks 
from full human decisions and actions (level 1) until full 
autonomy without interaction with humans (level 10) and 
takes into account several variants with alternatives. For 
example, veto voting by human actors and the level of 
interaction between a machine and human actor. This LOA 
framework is, to the knowledge of the authors, the most 
popular work as it is cited numerous times and used in the 
construction of many other theoretical and practical 
constructs. However, the ten LOA levels described in the 
work of Parasuraman, Sheridan and Wickers [9] are too 
much prone to interpretation, which can be concluded by 
how the different authors of subsequent LOA frameworks 
and related work described this framework. For example, the 
work of Endsley and Kaber [34] describes that the first of the 
ten levels is not fully manual as it is handed over to the 
machine to execute it. This is in contrast with the 
interpretation and description by Miller and Parasuraman 
[35], which describes that a human actor is responsible for 
everything in the decision-making process, including the 
execution of the decision. A second example of an 
interpretation that is not specific enough with regards to this 
framework is the notion of levels one and two in the work of 
Beer, Fisk and Rogers [8], which states that these two levels 
are exactly the same. This would mean that the model 
contains a redundant level.  
Endsley and Kaber [11] defined in their work ten 
categories of the level of automation along with definitions 
for the level of autonomy for each category, based on earlier 
work by Endsley [34]. However, the ten levels, which are all 
activity focused, are grounded by five levels of autonomy 
defined by Endsley [34], which are: 1) manual support, 2) 
decision support, 3) consensual AI, 4) monitored AI, and 5) 
full automation. This framework’s strength is its simplistic 

126
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
approach to autonomy, which is also its drawback. 
Compared to the framework of Parasuraman, Sheridan and 
Wickers [9], this framework lacks proper detail with regards 
to the possibilities a machine nowadays has. For example, 
based on the five levels of autonomy it is based on, it is 
unclear how recommendations are provided and how the 
human actor is informed about executing the actual decision 
or the result of the decision after execution by a machine.  
A third generic framework is the Autonomy Levels For 
Unmanned Systems (ALFUS) [12]. This framework includes 
increasingly complex environments in which a machine 
makes decisions and executes actions. The LOA levels 
included in ALFUS, range from zero (remote control) to ten 
(full intelligent autonomy). At the lowest LOA, there is 
100% interaction between a human and machine actor, while 
at the 10th LOA, almost no interaction between a human and 
machine actor is present. While ALFUS describes in more 
detail the amount of interaction between human and machine 
actors, the composition of this interaction is left implicit as it 
requires the ALFUS generic framework to be instantiated 
into program specific ALFUS frameworks [12].  
The currently available frameworks very accurately 
describe what levels of autonomy could be taken into 
account and how the interaction is possible between human 
and machine actors. However, as pointed out earlier, the 
existing frameworks lack the exact separation of tasks and 
responsibilities in complex human-machine interaction 
environments. Therefore, in the next section, a framework is 
proposed that combines both the roles relevant for decision 
making with the different levels of autonomy possible for 
machines in human-machine interaction to overcome this 
gap. 
III. 
GOVERNANCE FRAMEWORK CONSTRUCTION 
For the construction of our framework that fills the gaps 
identified in the previous section, two perspectives have to 
be merged: detailed decision-making roles and detailed 
LOA’s. Regarding the decision-making roles, the RAPID 
framework [4] is adopted due to its generic nature, thus is 
applicable in all contexts. Then, with regards to autonomy, 
the LOADAS framework [8] has been adopted due to the 
fact that it is utilized by many newer autonomy frameworks. 
However, the low level of detail and different interpretations 
of this framework and those that preceded LOADAS were 
already considered a drawback for the design and 
specification of decisions and decision-making as discussed 
in the previous section. Therefore, these theories have been 
analyzed to identify Situational Factors (SFs) that need to be 
taken into account for the construction of the governance 
framework. By doing so, the governance framework adopts 
all essential constructs from related work on the subject of 
autonomy. Analysis of the models resulted in five SF’s. The 
five SFs identified from the literature are: 1) type of actor, 2) 
alternatives, 3) veto, 4) inform, and 5) deadline. 
The first SF is the type of actor, see for example “The 
computer informs the human only if asked” [9]. Simply 
stated, when decision-making is defined, a choice has to be 
made whether this should be performed by a human actor 
only (variant one), a combination of a human and a machine 
actor (variant two) or solely by a machine (variant three). 
The second SF concerns the alternatives and the number of 
alternatives that are provided by a machine actor to the 
human actor, see for example “The computer narrows the 
selection down to a few alternatives” [9]. This SF comprises 
three possible variants. The machine actor could provide a 
full list of possible alternatives to the human actor, offering 
no filtering or selection at all (variant one). In the second 
variant, the machine actor could provide a selected set of 
alternatives for evaluation by a human actor. This means that 
the machine actor already filtered out one or more 
alternatives. The amount of alternatives in this variant 
depends on the context of the decision-making, and therefore 
is not fixed compared to the first and third variant. Lastly, 
the machine actor could provide one alternative to the human 
actor, which means that the machine actor performs the 
complete selection for the human actor, which only has to 
decide whether to execute the provided alternative or not 
(variant three). The third SF is veto, which encompasses the 
time a human actor is provided by the machine actor to 
activate a veto over the decision-making by the machine 
actor, see for example “Allows the human a restricted time to 
veto…” [9]. The amount of time provided by the machine 
actor to veto depends on the context of the decision-making, 
which results in two possible variants, decision-making 
including a veto possibility regardless of the time specified 
to do so (variant one) or decision-making without the 
possibility to veto (variant two). The fourth SF comprises the 
interaction between the human and machine actor regarding 
the output of the decision-making, see for example “Informs 
the human only if the computer decides to” [9]. This 
interaction could entail four possible variants. The first 
variant requires the machine actor to always inform the 
human actor with the result of the decision-making by the 
machine actor. The second variant requires the human actor 
to file a request for information about the decision-making 
by the machine actor. The third variant leaves the 
responsibility to inform the human actor about the decision-
making in the hands of the machine actor, which has to 
decide whether it is necessary. For example, this could be 
determined by the machine actor based on pre-programmed 
or self-learned exceptions. The fourth variant is a fully 
autonomous state regarding decision-making by the machine 
actor, ignoring the human actor. The fifth SF comprises the 
maximum amount of time (predetermined or calculated) a 
role has to execute a certain activity, e.g., the input role 
gathering and sensing decision-making essential data, which 
must be completed within a timeframe of 24 hours. This SF 
must be considered for each step in the decision-making 
process as a decision can be time-critical for an organization, 
ranging from a product or service that need to be delivered in 
a normal timeframe to military [36] or High Frequency 
Trading (HFT) [37] contexts in which decisions need to be 
executed within a minute or even a second [36]. 
Combining the RAPID roles and the five identified SFs a 
framework is created that supports the detailed design for a 
governance structure, see Figure 3. In the governance 
framework, each role involved (five in total) is characterized 

127
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
by five SFs in the decision-making process and should be 
specified accordingly.  
 
 
 
Figure 2. Governance structure to complement DMN 1.1 
 
 
Figure 3. Governance Framework for Decision-making 
 
Based on Figure 3, a governance structure for each 
decision can be taken into account. Therefore, an additional 
element to enrich the current DMN standard is proposed, see 
Figure 2.  
IV. 
CASE DESCRIPTION & APPLICATION 
The hypothesized application of the framework is 
demonstrated using three scenarios with three variants each, 
the first two variants are based on case study data, while the 
third variant is based upon a real-world situation, but is not 
an exact real-life organizational interpretation of it 
(simulation). In the next section, a demonstration on case 
study data is applied. This allows us to use data from an 
actual case while fully controlling the execution of the 
framework and input variables. The selection of the 
scenario’s was based on three criteria: 1) the scenario must 
be a decision on the operational level, 2) the scenario’s must 
significantly 
differ 
from 
each 
other 
in 
terms 
of 
industry/application, and 3) the data must be accessible for 
the research team. 
A. Description of scenario 
The first scenario used to demonstrate the framework 
embodies a governmental institution that is responsible for 
providing digital services to apply for child benefits, see 
Figure 4. In this scenario, civilians need to provide 
information for the governmental institution to be assessed 
whether the household is eligible to receive child benefits, 
and when this is the case, the amount of the child benefits 
and for what period the child benefits can be received. In this 
scenario, a citizen applies for child benefits, see for example 
[38].  
The second scenario used to demonstrate the framework 
embodies trading and High-Frequency Trading (HFT). In 
this context, the focus lies on the decision to buy or sell 
stocks. To be able to do so, certain criteria need to be taken 
into account. When humans are involved, HFT is not 
possible, however, in this scenario, we cover the differences 
between human and machine decision making roles in the 
determination to buy/sell stocks, see for example [39].  
The third scenario used to demonstrate the framework 
embodies the usage of drones by a military institution. In this 
scenario, a drone is utilized to determine whether a target 
should be terminated or not. This scenario progresses from 
the full control by human actors towards fully autonomous 
control by the drone itself, see for example [40]. 
B. Application of the model 
The application of the framework is demonstrated by 
using three variants per scenario. Each of the variants is 
characterized by a different composition of roles and 
corresponding SFs. In the context of this demonstration, 
three steps are required before the framework can be 
demonstrated; 1) the decision has to be modelled in DMN. In 
this context, this means that the DRD for this particular 
decision has to be established (the decision, its input data, its 
ruleset and relevant sources), see Figure 1. 2) The 
governance structure element has to be added to the DRD, 
connected to the appropriate decision, see Figure 2. Lastly, 
3) The roles and SFs need to be specified. An example 
template to do so is presented in Table I.  
 
 
 
Figure 4. DRD for the decision: determine eligibility for child benefits 
 

128
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
Figure 5. DRD for the decision: Determine action (buying/selling) of stock 
 
 
 
Figure 6. DRD for the decision: Determine termination of target 
 
To demonstrate the usefulness of this template, the 
governance structure for the scenario in this demonstration is 
also specified in Table I. For each variant, the design is 
changed and depicted in a new table. 
 
Scenario 1: Governmental service context 
 
Variant 1: Manual human decision-making 
 
TABLE I. GOVERNANCE STRUCTURE FOR VARIANT ONE 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Human 
(applicant) 
N.A. 
N.A. 
Always 
N.A. 
R Human 
(template) 
N.A. 
N.A. 
Never 
N.A. 
A Human 
(manager) 
N.A. 
N.A. 
Never 
7 days 
D Human 
(employee) 
N.A. 
N.A. 
Always 
7 days 
P Human 
(employee) 
N.A. 
N.A. 
Always 
14 days 
 
In the first variant, the applicant fills in a paper template 
and delivers it to the governmental counter (Input). Then, 
the governmental employee assesses the situation by 
analyzing the information in the template (Recommend) and 
decides for which benefits the household is eligible (Decide) 
based on a discussion about the case with the manager 
(Agree). In practice, it can be the case that one actor fulfils 
multiple decision-making roles. When the decision is made, 
the governmental employee enters the outcome into the 
governmental system (Perform). This allows the applicant 
to, on a monthly basis, pick up the appointed benefits at the 
governmental counter. Lastly, the applicant is informed by 
letter regarding the outcome of the decision and is able to 
make an appeal within two weeks.  
The template used contains information about the 
different benefits available and thus guides the decision-
making for both the input and decide roles. 
 
Variant 2: Machine-supported decision-making 
 
In this variant, see Table II, the applicant fills in an 
application template and uploads it to the online 
governmental portal (Input). Then, the governmental 
employee receives a notification of the system, which also 
provides a suggestion (Recommend) with regards to the 
eligibility of the application. The governmental employee 
decides (Decide) based on a discussion about the case with 
the manager (Agree), taking into account the suggestion of 
the system. Next, the system notifies the applicant and 
transfers the benefits automatically once a month (Perform).  
In this variant, the machine generates a suggestion and is 
provided with the result of the decision as it needs to apply 
machine-learning to increase and maintain the accuracy of 
suggestions. 
 
TABLE II. GOVERNANCE STRUCTURE FOR VARIANT TWO 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Human 
(applicant) 
N.A. 
None 
Always 
N.A. 
R Machine 
(system) 
One 
None 
Always 
10 
seconds 
A Human 
(manager) 
N.A. 
N.A. 
Always 
7 days 
D Human 
(employee) 
N.A. 
N.A. 
Never 
7 days 
P Machine 
(system) 
N.A. 
None 
On 
request 
1 day 
 
Variant 3: Autonomous decision-making 
 
TABLE III. GOVERNANCE STRUCTURE FOR VARIANT THREE 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Machine 
(system) 
None 
None 
Always 
364 
days 
R Machine 
(system) 
None 
None 
Never 
1 day 
A Human 
(citizen) 
None 
30 
days 
Always 
30 days 
D Machine 
(system) 
None 
None 
On 
request 
1 day 
P Machine 
(system) 
None 
None 
Always 
1 day 
 
In this variant, see Table III, the citizen’s data (all 
digitally available) is evaluated on a yearly basis by a 
machine to determine the eligibility for benefits (Input). 
Based on this, the citizen is informed about the pre-filled 
applications and is able to veto the data in the pre-filled 
applications or veto the eligibility in general. For this 

129
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
example, the time to veto is one month (Agree). When no 
veto is cast by the citizen, the system decides to process the 
relevant benefits (Recommend & Decide) and the benefits 
are automatically transferred once a month (Perform).  
In the last variant, the citizen is informed about his/her 
pre-filled and analyzed data on top of the actual confirmation 
after the benefits are approved after no veto has been cast by 
the citizen. 
 
Scenario 2: (High-Frequency-)Trading context 
 
Variant 1: Manual human decision-making 
 
In the first variant, see Table IV, the stock trader collects 
information by conducting a technical and financial analysis 
of corporate performance, which is used in determining 
whether to buy or sell stocks per given portfolio (Input). 
Then, based on a holistic overview of information, 
experience, and gut feeling, the stock trader aims to buy a 
large amount of stock of an organization, for which the stock 
trader contacts the financial office he or she works for to 
provide a recommendation (Recommend). This is required 
because the financial organizations’ policy states that very 
large buy orders should be verified by a second opinion 
(human) before being processed (Agree). Based on the 
collected input of the stock trader and the received agree on 
the decision, the stock trader processes the buy order, but 
with a reduced order amount of 25% (Decide). This is 
followed by a verification of the stock exchange against 
certain financial rules of conduct. When the result of this 
verification process is positive, the stock trader processed the 
buy order into the system of the financial organization he or 
she works for (Perform). 
 
TABLE IV. GOVERNANCE STRUCTURE FOR VARIANT ONE 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Human 
(Trader) 
N.A. 
N.A. 
Always 
2 
minutes 
R Human 
(Trader) 
N.A. 
N.A. 
Always 
2  
minutes 
A 
Human 
(Risk 
Officer) 
Three 
N.A. 
Always 
5 
minutes 
D Human 
(Trader) 
N.A. 
N.A. 
Always 
5 
minutes 
P Human 
(Trader) 
N.A. 
N.A. 
Always 
5 
minutes 
 
Variant 2: Machine-supported decision-making 
 
In this variant, see Table V, the stock trader is provided 
technical and financial information from a machine that 
collects data from multiple in-company and online sources 
(Input). Based on the data collected and provided to the 
stock trader, the machine also provides a best next action 
(Recommend). By default, this action is processed by the 
machine after 60 minutes (Decide), however, only when no 
veto is cast by the stock trader (Agree). When no veto is 
cast, the machine processes the buy order into the system of 
the financial organization (Perform). 
In this variant, the machine generates a suggestion and is 
provided with the result of the decision as it needs to apply 
machine-learning to increase and maintain the accuracy of 
recommendation. 
 
TABLE V. GOVERNANCE STRUCTURE FOR VARIANT TWO 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Machine 
(system) 
N.A. 
None 
Always 
1 
minutes 
R Machine 
(system) 
One 
None 
Always 
5 micro 
seconds 
A Human 
(Trader) 
None 
60 
minutes  
On 
request 
5 
minutes 
D Machine 
(system) 
None 
None 
Always 
1 
minute 
P Machine 
(system) 
None 
N.A. 
On 
request 
1 micro 
second 
 
Variant 3: Autonomous decision-making 
 
In this variant, see Table VI, one trading machine collects 
data (e.g., financial, performance, sentiment) 24/7 (Input). 
Based on the data, the machine considers buy/sell orders per 
stock in the portfolio. In this variant, another machine, solely 
focused on calculation tasks, provides predictions that 
represent recommendations for the algorithm to take into 
account (Recommend). Furthermore, as is usual with HFT, 
performance is critical for the profit margin, so redundant 
activities should be prevented as much as possible. However, 
another machine of the stock trader simultaneously needs to, 
independently, come to the same conclusion regarding the 
considered stock in order to execute a buy or sell order 
(Agree). When both machines agree, the order is sent 
(Decide). Because the machine (and its underlying 
algorithms) is validated for its compliance, the stock 
exchange does not have to verify the transaction and can 
instantly process the change of ownership of the given 
stocks. Then, the machine processes the buy order into the 
system of the financial organization (Perform). 
 
TABLE VI. GOVERNANCE STRUCTURE FOR VARIANT THREE 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Machine 1 
(system) 
None 
None 
Never 
1 
minute 
R Machine 2 
(system) 
One 
None 
On 
request 
5 micro 
seconds 
A Machine 3 
(system) 
None 
None 
Never 
5 micro 
seconds 
D Machine 4 
(system) 
None 
None 
On 
request 
1 micro 
second 
P Machine 
(system) 
None 
None 
On 
request 
1 micro 
second 

130
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Scenario 3: Military use of drones context 
 
Variant 1: Manual human decision-making 
 
      In the first variant, see Table VII, a human operator fully 
controls the military drone that is on patrol in a conflict 
territory, defending certain strategic assets. Human mission 
specialists provide data that the drone and its human operator 
requires to operate in the mission area (Input). When on 
patrol, the drone’s infrared sensor detects two heat signatures 
and alerts the human operator, providing two possible 
scenarios that could be relevant in the given context. Based 
on the data and sensor readings, the drone provides two 
recommendations 
with 
probability 
percentages 
(Recommend). 
The 
human 
operator 
considers 
the 
recommendations, assesses the situation via the drone’s 
sensors, and considers to execute a given action (Agree). 
Depending on the situation at hand, the human operator 
controlling the drone could veto the agree role, e.g., when the 
context drastically changes in a very short amount of time in 
combination with human assets that could be at risk. Based 
on all data relevant to making the decision, the human 
operator, which is always the highest ranking employee 
present, decides upon the best next action to proceed 
(Decide), and orders the drone to eliminate the targets 
(Perform). 
 
TABLE VII. GOVERNANCE STRUCTURE FOR VARIANT ONE 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Human 
(specialist) 
N.A. 
None 
N.A. 
12 
hours 
R Machine 
(drone) 
Two 
None 
Always 
5 
minutes 
A Human 
(operator) 
N.A. 
None 
N.A. 
5 
minutes 
D 
Human 
(highest 
rank) 
N.A. 
None 
N.A. 
10 
minutes 
P Machine 
(drone) 
None 
None 
Always 
1 
minute 
 
Variant 2: Machine-supported decision-making 
 
      In this variant, see Table VIII, the drone receives input 
data from mission specialists beforehand, using machine 
parameters so that the machine can operate autonomously 
(Input). In this variant, the human operator does not control 
the drone constantly as described in the previous variant. 
However, the human operator controls the drone only when 
an alert is generated by the drone indicating a situation that 
needs human attention. Before the alert is generated, the 
drone autonomously calculates, based on mission and sensor 
data, one next best action with a probability percentage 
(Recommend). Then, the human operator consults the 
highest ranked employee present to ask permission to 
execute a given action (Agree). Based on the previous 
interaction the human operator approves or rejects the 
recommended next best action proposed by the drone 
(Decide). The outcome of the decision is executed by the 
drone, in this case resulting in either returning to patrol 
pattern, keep monitoring the situation or eliminating the 
target (Perform). 
 
TABLE VIII. GOVERNANCE STRUCTURE FOR VARIANT TWO 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Human 
(specialist) 
N.A. 
None 
N.A. 
1 hour 
R Machine 
(drone) 
None 
None 
Always 
2 
minutes 
A 
Human 
(highest 
rank) 
N.A. 
None 
N.A. 
5 
minutes 
D Human 
(operator) 
N.A 
None 
N.A. 
1 
minute 
P Machine 
(drone) 
None 
None 
Always 
1 
minute 
 
Variant 3: Autonomous decision-making 
 
In this variant, see Table IX, the drone collects mission 
parameters and data from different military sources 
autonomously to assess the mission context (Input). The 
drone’s sensors detect suspicious behavior and generates 
likely scenarios and corresponding recommendations in 
terms of actions (Recommend). Based on these scenarios, 
several additional data sources are evaluated and a next best 
action is calculated by the drone. The drone communicates to 
mission command that it detected suspicious behavior in the 
mission area and reports upon the derivation towards the 
next best action and the corresponding actions the drone is 
going to execute (Agree). Then, mission command has three 
minutes to evaluate the situation and the drone’s decision 
and veto the decision if required (Decide). When no veto is 
cast by the human operators’ part of mission control, the 
drone executes the next best action, returning to the original 
patrol protocol (Perform).  
 
TABLE IX. GOVERNANCE STRUCTURE FOR VARIANT THREE 
 
 
SF1:  
 
SF2: 
 
SF3: 
 
SF4: 
 
SF5: 
I Machine 
(drone) 
N.A. 
None 
On 
request 
1 
minute 
R Machine 
(drone) 
None 
None 
Always 
1 
minute 
A Human 
(operator) 
N.A. 
3 
minutes 
N.A. 
3 
minutes 
D Machine 
(drone) 
N.A. 
None 
Always 
5 
seconds 
P Machine 
(drone) 
None 
None 
Always 
30 
seconds 
 
The three scenario’s each accompanied by three variants 
provide an overview of a decision-making process, the role 

131
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
distribution between humans and machines, the autonomy of 
the machine, and SF’s that have to be taken into account. 
The framework can also be applied to guide the creation of a 
roadmap, as it shows how decision-making processes can be 
further automated and plan accordingly. 
V. 
FRAMEWORK VALIDATION 
       To validate the framework, a qualitative research 
approach is selected given the first cycle of validation 
required [41]. Qualitative research aims to capture 
phenomena and its relationships using rich data sources. 
Data sources are always real-world context-based, and 
therefore support the exploration of a phenomenon in its 
natural context [42]. One widely-accepted qualitative 
research technique is a focus group.  
      A focus group is a qualitative face-to-face data 
collection technique that allows for broad interactions on a 
topic [43]. It is a more efficient method of data collection 
than qualitative interviews because, physically, more 
participants can be involved at a given point in time. 
Furthermore, utilizing focus groups also allows for cross-
participant discussion about a subject to achieve a greater 
sense of detail about that subject as well as shared decision-
making, i.e., validating artifacts [43]. Before a focus group 
can be executed, a number of factors need to be considered; 
1) the goal of the focus group, 2) the selection of 
participants, 3) the number of participants, 4) the selection 
of the facilitator, 5) the information recording facilities, and 
6) the protocol of the focus group [43], [44].  
      (1) For the research team, the goal of the focus group 
was to validate the framework.   
      (2) The selection of participants should be based on the 
group of individuals, organizations, information technology, 
or community that best represents the phenomenon studied 
[42]. In this study, organizations and individuals that deal 
with (semi)automated decision making processes at a large 
scale form the phenomenon studied; examples are financial 
and governmental institutions. To find relevant experts on 
this topic, the research team requested that the framework 
could be discussed during the monthly meeting of the 
Business Rules Management (BRM) expertise forum. This 
group consists of experts working for different Dutch 
governmental institutions, namely the Dutch Tax and 
Customs 
Administration, 
Dutch 
Immigration 
and 
Naturalization Service, Netherlands Enterprise Agency, 
Dutch Employee Insurance Agency, Dutch Education 
Executive Agency, Ministry of Education, Culture and 
Science, the Department of Waterways and Public Works, 
and Dutch Social Security Office. All of such governmental 
institutions are responsible for executing law and 
regulations.  
       (3) In total, six experts were present during the meeting 
that agreed to participate. Each participant represented one 
Dutch governmental institution and are all involved in 
designing 
semi(automated) 
decision 
making. 
The 
respondents had following roles: one enterprise architect, 
two business rules analysts, business rules architect, one 
business analyst, and one BRM project manager. Each of 
the participants had at least five years of experience within 
the domain of decision-making using BRM.  
       (4) Delbecq and van de Ven [44] and Glaser [45] state 
that the facilitator should be an expert on the topic and 
familiar with group meeting processes. The selected 
facilitator has a Ph.D. in BRM, has conducted seven years 
of research on the topic, and has facilitated many (similar) 
focus group meetings before.  
       (5) The focus group could not be recorded due to 
confidentiality of the decision-making cases discussed 
alongside the framework. However, the facilitation made 
notes regarding a prepared set of questions per participant. 
The duration of the focus group was approximately one 
hour.  
       (6) The focus group had a protocol that consisted of 
three phases. The first phase comprised the preparation of 
the participants where they were invited to already study the 
framework, its concepts and their definitions. The 
framework’s documentation was sent three days in advance 
to the participants. The second phase comprised the actual 
focus group in which the following questions where 
addressed: 1) “Do you believe that the framework adds 
value for the governance of decision management?” 2) “Are 
the roles described recognizable?”, 3) “Are  additional 
roles needed, and why?”, 4) “Are all SF’s recognizable?”, 
5) “Are there SF’s that are missing?”, and 6) “Do you 
believe that DMN will be enriched using the proposed 
element?” 
      The facilitator started with a short presentation about the 
framework and its components (i.e., the roles, their 
responsibilities, and the SF’s that need to be taken into 
account per role). Regarding question one, the participants 
agreed with each other that the information in the 
framework needs to be captured, thus are recognizing the 
need for such an addition for DMN. Note that DMN is 
becoming an accepted standard, especially in the Dutch 
governmental. An example mentioned that also shows the 
need to structure and capability to share decision-making 
data is the new General Data Protection Regulation [10] 
which states that automated decisions must be explainable 
to both regulators, but more importantly to, European 
civilians. Furthermore, from a theoretical point of view, the 
participants agreed that a lot of research is conducted and 
published regarding the design and production of decisions 
and underlying rules, but lacking contributions regarding the 
governance of decisions. Then, with regards to question two 
and three, the participants stated that the roles were 
recognizable and that none are missing. This was mainly 
because the participants were aware of a close variant of the 
RAPID model, the RACI model. However, there was some 
discussion about the absence of a dedicated role for 
informing relevant stakeholders, when necessary. When the 
facilitator explained that the ability to inform is actually a 
separate SF designed to be taken into account for each role 

132
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
the respondents agreed that it is not an actual role but indeed 
a situational factor.  Furthermore, there was some discussion 
regarding the labelling of the roles. The main discussion 
was about the fact that specific roles, e.g., recommend and 
perform, are formulated as activity names and not real role 
names. Although three participants identified this as a 
problem, the other three did not agree and thought the role 
labels were clear. As we adopted these best practice labels 
from existing literature, the research team chose to not 
change the labels as is. Lastly, the participants argued that, 
depending on the input of a given decision, the stakeholders 
can differ in practice. The participants discussed the 
possibility to define multiple governance structures based on 
the input for the same decision, however, this would lead to 
(too) much extra administration, i.e., when more than two or 
three variants need to be defined. This is followed by 
question four and five. Discussion regarding both questions 
mainly was about the SF inform. This is due to the fact that 
informing stakeholders can be done on different levels. The 
framework does not take this into account. An example is 
the difference between informing a stakeholder about the 
outcome of the decision made versus informing about the 
outcome of the decision made in addition with extra 
information, for example, information on how the decision 
is executed, how the decision has been made  as well as 
which data is used in the decision-making process. The 
participants added that this difference significantly affects 
how the decision-making process is facilitated by both 
tooling as well as the stakeholders involved, and should be 
taken into account as part of the inform SF. Furthermore, 
regarding the inform role, when multiple stakeholders from 
different organizations are involved in decision-making, the 
framework should take into account possible conflicts of 
interest and provide the possibility to specify how 
stakeholders are involved. As our current definition of the 
SF inform does not dictate who to inform and how the 
actual role/person should be informed. Organizations are 
free to apply additional localized business rules on the 
framework, thereby managing conflict of interest. For 
example, one organization can define inform to only inform 
customers about the outcome of the decision, while other 
organizations want to inform their customers on a different 
level, by communicating the outcome of the decision-
making as well as the data and rules utilized. Lastly, one of 
the participants argued that the deadline SF is not always 
relevant and should be interchangeable with other SF’s. 
While the other participants disagreed, on this topic the 
framework allows to change SF’s (the example of budget 
was mentioned by the participant as a replacement for 
deadline). With regards to question six, the participants 
agreed that DMN could benefit from the element proposed 
to support the registration of important governance 
information about decisions modelled. 
       One general remark was about the presentation of the 
governance framework and its contents. Although not in 
scope of this study, the participants added that the 
presentation is important for acceptance, as the contents are 
usually read and utilized by people instead of machines. 
They argued that the current proposed element for DMN 
presented in Figure 2 seems simple yet very appropriate. 
VI. 
DISCUSSION AND CONCLUSION 
Since the DMN standard is getting more commonly 
utilized in practice, more decisions are being modelled 
explicitly for documentation or automation. However, the 
current DMN standard does not take into account roles and 
autonomy regarding decisions and the underlying decision-
making process. In this paper, a governance structure 
framework is being proposed to complement the design and 
specification of decisions in the DMN standard. To do so, 
the theoretical constructs of decision-making roles (RAPID) 
and autonomy levels together with five SFs (LOADAS) are 
combined to answer the following research question: ‘How 
can a governance structure of the decision making process 
be made explicit?’. One could solely consider the currently 
available models and frameworks (i.e., RAPID and OODA) 
to answer this question. However, this results to an 
incomplete assessment of the situation. To illustrate this 
finding we this base our example on the drone usage by 
military institutions. When an analysis of this situation is 
made based on the RAPID model, an overview of the 
different stakeholders is provided in the decision to assess 
the use of lethal force. The autonomy of each role is not 
described. In a normal military operation this is tackled by 
the normal hierarchy of command. However, machines 
(killer drones) are increasingly being utilized and their 
decision power progressively becomes larger. As such 
drones are designed to analyze and act themselves, without 
human intervention. So, in the context of the military usage 
of drones, it is unclear what the drone can decide on its own 
and whether it should or should not inform human operators, 
since only the roles and their activity is clear. 
The other way around, when solely considering 
autonomy levels for machines in decision-making (i.e., 
LOADAS and ALFUS), it is explicit how machines operate 
in 
a 
decision-making 
process. 
For 
example, 
what 
responsibilities the drone has with regards to informing 
human operators after executing lethal force to eliminate 
targets or the whether a human operator has the possibility to 
override a decision made by the drone. However, in such a 
situation it is unclear what roles and responsibilities are 
involved in the decision-making and how they work together 
to achieve a certain added value. Thus, for this example, the 
drone does not know which role is able to veto the decision 
and therefore the combination adds value 
The proposed governance structure framework has been 
presented using three scenario’s each based on three variants. 
For each variant, the roles, responsibilities and SF’s (human-
machine, alternatives, veto and inform) are different. These 
variants demonstrate that various choices in decision-making 
processes lead to design considerations that should be taken 
into account. For example, when machines autonomously 
decide on which benefits are relevant, what is the best 
method of informing humans in a specific context, or the 

133
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
appropriate timeframe applicable to veto a decision by a 
human, in a specific context. 
The suggested framework has its limitations. The 
framework is a suggested solution derived from the existing 
knowledge base in the area of decision management, 
decision-making and machine autonomy, and thereby the 
result of a ‘generate design alternative’ phase [46]. However, 
we believe that the proposed framework reached a level of 
maturity such that it can enter a detailed validation phase. In 
a planned study, a collection of cases will be used to further 
validate the framework and to further demonstrate its 
practical usefulness. We note that the framework is widely 
applicable if every decision-making context can be modelled 
so that all stakeholders are aware of their roles and 
responsibilities in a given decision-making context. 
Lastly, several future research directions are described, 
which are based on the theoretical findings as well as the 
focus group conducted.  
The first direction comprises the need for a practical 
approach when a decision has multiple, i.e., more than three, 
variants of which the governance structure must be made 
explicit with the framework. For example, the decision-
making to grant a work visa for a county could be very 
diverse based on the data inserted by the applicant. When an 
applicant enters that a work visa has been revoked earlier, 
additional criteria, actors and decision-making factors (such 
as deadlines or the possibility to veto) are relevant, yet for 
the same decision. Future research should therefore focus on 
the incorporation (and how that could be achieved) of 
multiple layers for the same decision, as the Subject Matter 
Experts (SME’s) suggested that the framework could 
become difficult to use in practice otherwise.  
The second research direction comprises the presentation 
of the element in DMN (DRD level) as well as the 
presentation of the governance information in the matrices 
e.g., in tables IV-VI. Although not in the scope of this 
research study, the SME’s stated that this is an important 
factor to take into account. This partly overlaps with the 
previous research direction as the presentation of multiple 
possible variants of the same decision needs to be presented 
effectively, according to the SME’s. It is therefore likely that 
the current proposed matrix changes to accommodate 
effective information transferal. 
As this study proposes an addition to enrich the DMN 
standard, future steps should focus on approaching the OMG 
to discuss incorporation of governance structures in the next 
version of the DMN standard. However, before such steps 
are taken, it is imperative that the framework undergoes 
more validation rounds to ensure more SME’s and even 
whole organizations endorse the framework. Future research 
would therefore mean that more SME’s are included as well 
as from industries other than the governmental setting, which 
was the demarcation of the SME selection for the focus 
group in this study. Involving different industries for the 
validation of the framework would probably yield other 
interesting improvements as well as future research 
directions.   
 
REFERENCES 
[1] 
K. Smit and M. Zoet, “A Governance Framework for 
(semi) Automated Decision-making,” in Proceedings of 
the Tenth International Conference on Information, 
Process, and Knowledge Management (eKNOW), 2018, 
pp. 83–88. 
[2] 
Object Management Group, “Decision Model And 
Notation (DMN), Version 1.1,” 2016. 
[3] 
Object 
Management 
Group, 
“ArchiMate® 
3.0 
Specification,” 2016. 
[4] 
P. Rogers and M. Blenko, “Who has the D?,” Harv. Bus. 
Rev., vol. 84, no. 1, pp. 52–61, 2006. 
[5] 
M. Zoet, Methods and Concepts for Business Rules 
Management, 1st ed. Utrecht: Hogeschool Utrecht, 2014. 
[6] 
B. Hnatkowska and J. M. Alvarez-Rodriguez, “Business 
Rule Patterns Catalog for Structural Business Rules,” in 
Software Engineering: Challenges and Solutions, 1st ed., 
Springer International Publishing, 2017, pp. 3–16. 
[7] 
M. W. Blenko, M. C. Mankins, and P. Rogers, “The 
Decision-Driven Organization,” Harv. Bus. Rev., vol. 88, 
no. 6, pp. 54–62, Jun. 2010. 
[8] 
J. Beer, A. D. Fisk, and W. A. Rogers, “Toward a 
framework for levels of robot autonomy in human-robot 
interaction,” J. Human-Robot Interact., vol. 3, no. 2, p. 
74, 2014. 
[9] 
R. Parasuraman, T. B. Sheridan, and C. D. Wickens, “A 
model for types and levels of human interaction with 
automation,” IEEE Trans. Syst. man, Cybern. A Syst. 
Humans, vol. 30, no. 3, pp. 286–297, 2000. 
[10] 
European Commission, “Protection of personal data - 
GDPR,” 
2017. 
[Online]. 
Available: 
http://ec.europa.eu/justice/data-protection/. [Accessed: 14-
Aug-2017]. 
[11] 
M. R. Endsley and D. B. Kaber, “Level of automation 
effects on performance, situation awareness and workload 
in a dynamic control task,” Ergonomics, vol. 42, no. 3, pp. 
462–492, 1999. 
[12] 
H. M. Huang, K. Pavek, B. Novak, J. Albus, and E. 
Messin, “A framework for autonomy levels for unmanned 
systems (ALFUS),” in Proceedings of the AUVSI’s 
Unmanned Systems North America, 2005, pp. 849–863. 
[13] 
J. Taylor, “Who has the ‘D’ when the ‘D’ is automated?,” 
2007. 
[Online]. 
Available: 
http://www.beyeblogs.com/edmblog/archive/2007/02/who
_has_the_d_w_2.php. [Accessed: 01-Dec-2017]. 
[14] 
A. Edwards and G. Elwyn, Shared decision-making in 
health care: Achieving evidence-based patient choice. 
Oxford University Press, 2009. 
[15] 
H. M. Davey et al., “Medical tests: women’s reported and 
preferred decision‐making roles and preferences for 
information on benefits, side‐effects and false results,” 
Heal. Expect., vol. 5, no. 4, pp. 330–340, 2002. 
[16] 
J. R. Adams, R. E. Drake, and G. L. Wolford, “Shared 
decision-making preferences of people with severe mental 
illness,” Psychiatr. Serv., vol. 58, no. 9, pp. 1219–1221, 
2007. 
[17] 
N. K. Arora and C. A. McHorney, “Patient preferences for 
medical 
decision 
making: 
who 
really 
wants 
to 
participate?,” Med. Care, vol. 38, no. 3, pp. 335–341, 
2000. 
[18] 
B. W. Husted and D. B. Allen, “Toward a model of cross-
cultural business ethics: The impact of individualism and 

134
International Journal on Advances in Intelligent Systems, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/intelligent_systems/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
collectivism on the ethical decision-making process,” J. 
Bus. Ethics, vol. 82, no. 2, pp. 293–305, 2008. 
[19] 
A. Ho, “Relational autonomy or undue pressure? Family’s 
role in medical decision‐making,” Scand. J. Caring Sci., 
vol. 22, no. 1, pp. 128–135, 2008. 
[20] 
P. 
S. 
Scherrer, 
“Directors’ 
responsibilities 
and 
participation in the strategic decision making process,” 
Corp. Gov. Int. J. Bus. Soc., vol. 3, no. 1, pp. 86–90, 
2003. 
[21] 
C. Charles, A. Gafni, and T. Whelan, “Decision-making 
in the physician–patient encounter: revisiting the shared 
treatment decision-making model,” Soc. Sci. Med., vol. 
49, no. 5, pp. 651–661, 1999. 
[22] 
P. V. Gorsevski, S. C. Cathcart, G. Mirzaei, M. M. Jamali, 
X. Ye, and E. Gomezdelcampo, “A group-based spatial 
decision support system for wind farm site selection in 
Northwest Ohio,” Energy Policy, vol. 55, pp. 374–385, 
2013. 
[23] 
M. Sigala, “The impact of geocollaborative portals on 
group decision making for trip planning,” Eur. J. Inf. 
Syst., vol. 21, no. 4, pp. 404–426, 2012. 
[24] 
P. Jankowski, N. Andrienko, and G. Andrienko, “Map-
centred exploratory approach to multiple criteria spatial 
decision making,” Int. J. Geogr. Inf. Sci., vol. 15, no. 2, 
pp. 101–127, 2001. 
[25] 
Q. Tian, J. Ma, C. J. Liang, R. C. W. Kwok, O. Liu, and 
Q. Zhang, “An organizational decision support approach 
to R and D project selection,” in Proceedings of the 35th 
Annual Hawaii International Conference on System 
Sciences, 2002, pp. 3418–3427. 
[26] 
N. L. Kerr and R. S. Tindale, “Group performance and 
decision making,” Annu. Rev. Psychol, vol. 55, pp. 623–
655, 2004. 
[27] 
J. Boyd, “A discourse on winning and losing,” 1987. 
[28] 
D. G. Ullman, “OO-OO-OO!” the sound of a broken 
OODA loop,” CrossTalk-The J. Def. Softw. Eng., pp. 22–
25, 2007. 
[29] 
E. Shahbazian, D. E. Blodgett, and P. Labbé, “The 
extended OODA model for data fusion systems,” in 
Proceedings 
of 
4th 
International 
Conference 
on 
Information Fusion, 2001. 
[30] 
R. Breton and R. Rousseau, “The C-OODA: A cognitive 
version of the OODA loop to represent C2 activities,” in 
Proceedings of the 10th International Command and 
Control Research Technology Symposium, 2005. 
[31] 
R. Rousseau and R. Breton, “The M-OODA: A model 
incorporating control functions and teamwork in the 
OODA loop,” in Proceedings of the 2004 Command and 
Control Research Technology Symposium, 2004, pp. 14–
16. 
[32] 
C. Bartneck and J. Forlizzi, “A design-centred framework 
for social human-robot interaction,” in Proceedings of the 
13th IEEE International Workshop on Robot and Human 
Interactive Communication, 2004, pp. 591–594. 
[33] 
T. B. Sheridan and W. Verplank, “Human and Computer 
Control of Undersea Teleoperators,” Cambridge, MA, 
1978. 
[34] 
M. R. Endsley, “The application of human factors to the 
development of expert systems for advanced cockpits.,” in 
Proceedings of the Human Factors Society Annual 
Meeting, 1987, pp. 1388–1392. 
[35] 
C. A. Miller and R. Parasuraman, “Designing for flexible 
interaction between humans and automation: Delegation 
interfaces for supervisory control,” Hum. Factors, vol. 49, 
no. 1, pp. 57–75, 2007. 
[36] 
R. Azuma, M. Daily, and C. Furmanski, “A review of 
time critical decision making models and human cognitive 
processes,” in Aerospace Conference, 2006, pp. 1–9. 
[37] 
E. Budish, P. Cramton, and J. Shim, “The high-frequency 
trading arms race: Frequent batch auctions as a market 
design response,” Q. J. Econ., vol. 130, no. 4, pp. 1547–
1621, 2015. 
[38] 
Canadian Government, “Apply for Child Benefits,” 2018. 
[Online]. Available: https://www.canada.ca/en/revenue-
agency/services/child-family-benefits/canada-child-
benefit-overview/canada-child-benefit-apply.html. 
[Accessed: 14-Aug-2018]. 
[39] 
R. J. Kuo, C. H. Chen, and Y. C. Hwang, “An intelligent 
stock trading decision support system through integration 
of genetic algorithm based fuzzy neural network and 
artificial neural network,” Fuzzy sets Syst., vol. 118, no. 
11, pp. 21–45, 2001. 
[40] 
N. Sharkey, “Saying ‘no!’to lethal autonomous targeting,” 
J. Mil. Ethics, vol. 9, no. 4, pp. 369–383, 2010. 
[41] 
A. Hevner and S. Chatterjee, Design research in 
information systems: theory and practice, 22nd ed. 
Springer Science & Business Media, 2010. 
[42] 
A. Strauss and J. Corbin, Basics of Qualitative Research: 
Techniques and Procedures for Developing Grounded 
Theory, 3rd ed., vol. 3. Thousand Oaks, CA: SAGE 
Publications Ltd., 2015. 
[43] 
D. L. Morgan, Focus groups as qualitative research, 16th 
ed. Sage publications, 1996. 
[44] 
A. L. Delbecq and A. H. Van de Ven, “A group process 
model for problem identification and program planning,” 
J. Appl. Behav. Sci., vol. 7, no. 4, pp. 466–492, 1971. 
[45] 
B. G. Glaser, Theoretical sensitivity: Advances in the 
methodology of grounded theory. Sociology Press, 1978. 
[46] 
A. R. Hevner, S. T. March, J. Park, and S. Ram, “Design 
Science in Information Systems Research,” MIS Q., vol. 
28, no. 1, pp. 75–105, 2004. 
 

