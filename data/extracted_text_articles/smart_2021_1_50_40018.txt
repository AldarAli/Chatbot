Towards the Implementation of Ship Recognition and Identification System in 
Costal and River Information Services 
 
Natalia Wawrzyniak 
Marine Technology Ltd. 
Szczecin, Poland 
e-mail: n.wawrzyniak@marinetechnology.pl 
Tomasz Hyla 
West Pomeranian University of Technology 
Szczecin, Poland 
e-mail: thyla@zut.edu.pl 
 
Abstract— The scope of the ship recognition and identification 
(SHREC) project covers development of three main system 
modules based on: detection and tracking, classification, and 
identification methods. First method allows to detect and track 
a moving ship while maintaining system performance, so it can 
be used to process data from multiple cameras (20 and more). 
Second method allows for classification of non-conventional 
ships into 5 to 7 classes using two Convolutional Neural 
Networks (CNN). This allows to recognize a type of ships when 
the identification is not possible. The identification method 
locates and recognizes hull inscriptions of detected units and 
matches them with records from available ships registers. 
Obtained information on ships can be automatically pushed 
into service oriented architecture of River Information 
Services (RIS) for alerting, statistics and authentication 
purposes. Currently, the integration and performance tests in 
marine and inland on-shore environment are close to finish. 
The obtained results imply that the SHREC is suitable for 
further integration with smart city services. 
Keywords- surveillance; ship identification; detection and 
tracking; river information services. 
I. 
 INTRODUCTION 
Ships identification problems is addressed by many 
existing systems, as it is vital for safety and security of all 
on-water traffic participants and facilities on shore. Most 
solutions are directed in identifying large ship covered by 
Safety Of Life At Sea (SOLAS) [1] convention, which are 
oblige to use Automatic Identification System (AIS) 
transponders, have assigned unique International Maritime 
Organization (IMO) numbers, and have their hulls properly 
marked. The Ship Recognition and Identification System 
(SHREC) is being developed to automate the identification 
of non-conventional vessels in ports, harbors of both marine 
and inland waterways. It uses both traditional image 
processing and artificial intelligence methods (deep neural 
networks) to analyze video streams from existing 
monitoring systems as part of ship and port information 
systems. 
In addition to the detection, classification and 
identification of units, the system's task is to transmit 
information about the ship to other system services and their 
recipients. This allows the information to be marked on 
electronic navigational charts and sent to interested services 
and authorities for notification, warning or statistical 
analysis. 
The paper is organized as follows. Section 2 contains the 
description of three main modules of the system – detection 
and tracking, classification and identification. Section 3 
summarizes the research emphasizing obtained results and 
pointing out some main constraints of the proposed solution. 
II. 
GENERAL SYSTEM OVERVIEW 
The system contains three main modules related to three 
main tasks of the system, together with an operator console 
module, the interfaces to the external systems, and a system 
core 
that 
contains 
systems 
logic 
that 
allows 
for 
interoperability between all mentioned parts. The core also 
stores the data and feeds the operator application with it. The 
system can use existing video monitoring system by 
capturing an analyzing its streams. These surveillance 
systems are usually part of vessel traffic information services 
implemented in critical water areas of moderate to heavy 
traffic or in proximity to crucial on-shore facilities. The 
services usually store or use information on ships coming 
from different hull registries of different kinds of vessels 
scattered in different authorities. SHREC system exchanges 
the data with such services by using it as reference data for 
ship identification 
purposes 
and 
sending back 
the 
information on detection, recognition or classification to 
RIS/VTS. For the communication with on-shore monitoring 
system 5G network is used together with a radio line set up 
between nodes further away from the city or port. Achieved 
results of systems main methods are presented below.  
A. Detecting and Tracking 
The method assumes that for each camera view there is a 
determined detection zone that eliminates areas of the scene 
where either ships cannot appear (e.g., on land) or they are 
too far for the detection process to make sense. The 
background subtraction algorithm is used for each frame 
from a video stream to obtain foreground objects, find their 
contours, and to obtain bounding boxes for each detected 
ship. The method is designed to detect all kinds of moving 
vessels and to work efficiently, so it can be used to process 
data from multiple cameras (20 or more) with usage of 
economically acceptable amount of server resources. The 
algorithm works in variable lightning conditions and with 
slight changes of the background. It detects water artefacts 
(by measuring number and length of edges). Furthermore, it 
identifies the same ship across the frames and is able to filter 
29
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-863-1
SMART 2021 : The Tenth International Conference on Smart Cities, Systems, Devices and Technologies

out artifacts based on a 5 frame window. Exemplary scene is 
presented in Figure 1. Green frame shows a detected ship, 
yellow show places from 8 second were the ship was spotted, 
other colors show other objects (not ships) that were 
correctly rejected Movement direction is detected based on 
camera location. The HD resolution 1280x720 and GSOC 
background subtraction algorithm provide best results 
considering performance. 
The method was tested using a test computer (Core i7-
8700K, 32GB RAM, SSD 1TB, NVIDIA 311 Quadro 
P4000). The method returned around 90% of correct 
detection events for test sets of good quality scenes and 
around 80% for test sets of streams of bad quality. The 
incorrect detection events mainly arose from a few video 
samples with unfavourable lightning conditions. Some errors 
are corrected during later identification stage. More details 
can be found in [2]. 
 
 
Figure 1. Detection method in action.  
B. Classification 
The 
module 
has 
two 
classification 
algorithms 
implemented. The first one is an implementation of the 
original CNN developed for the project, described in detail 
in [3]. Using only own-gathered data (recorded ships 
images) on 16 different architectures gave maximum ~20% 
efficiency during training. Training with the additional older 
database attached was ~41%. Finally, classification 
accuracy between 60 and 70% was achieved, but for only 5 
classes. 
For the purpose of achieving a proper classification 
quality, a second one was implemented using existing 
GoogleNet solution trained with thousands of images of 
non-SOLAS ships acquired during last 3 years the area 
cover by Lower Oder RIS System (Figure 2). The result that 
was achieved gave a classification accuracy of 84% for 7 
classes (barge - together with pushed kit, motorboat, sailing 
yacht, kayak, service unit, passenger, and others). More 
information can be found in [4]. 
SHREC 
classification 
service 
can 
execute 
both 
classification algorithms at once. It also displays the last 
classified ship. Classification module is especially needed 
when identification is not possible due to unreadable vessel 
inscriptions. 
 
 
 
Figure 2. Exemplary confusion matrixes for different number of classes in 
pre-trained GoogleNet solution [4] 
C. Identification 
Vessel identification is based on the location and 
recognition of the hull inscriptions of the detected ship by 
the detection module. Our hybrid approach uses three text 
localization methods (CCA [5], MSER [6], EAST [7]) and 
Tesseract OCR to recognize inscriptions. The module uses 
its own ship registry (that can be fed from ships data bases 
from external services) and compares the found inscriptions 
with its records. It runs in near real time, in 5-second-
rounds. 
The degree of correct identification is determined 
depending on the degree of text matching. Conducted tests 
showed that the proposed method produced the 69% full 
matches of hull inscriptions (matched with no errors), 25% 
high matches (matched with one allowed error), 3% low 
matches (matched with two allowed errors), 3% multiple 
matches (matched simultaneously with more than one ship), 
and 9% of vessels were not identified. The methods 
architecture and tests were described in detail in [8]. 
30
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-863-1
SMART 2021 : The Tenth International Conference on Smart Cities, Systems, Devices and Technologies

The method works well identifying commercial vessels, 
as their inscriptions are placed according to the binding 
rules. With the recreational craft situation varies. When the 
visible inscription exceeds 10-12 pixels in height, the OCR 
returns satisfying results. Usually, the module analyses 10 to 
20 vessels frames per vessel passage in front of the camera, 
while one with clear, visible characters is enough for proper 
recognition (identification). 
III. 
SUMMARY 
The tests results show that the system is able to 
recognize and identify all kids of ships using only video 
surveillances that are part of many already existing vessel 
monitoring systems. In a case when the identification is 
impossible, it classifies passing vessels into one of 
determined categories. The system detects vessels in less 
than a second with the background model updating 3 times 
per second during that process. Pre-identification is 
performed once per five-second round and the final 
identification outcome is given after the ships pass (after a 
round where tracking ID of the passing ship is lost).  
Deployment of proposed solution enables for automatization 
of operators work in monitoring centres and significantly 
reduces its cost. At the same time, it offers historical logs of 
identified and classified units and allows pushing statistics 
or alerting information to other services. This system is a 
smart management system for port and costal traffic 
services. The approach is in line with current trends for 
digitization, data sharing, and the development of the 
information society. 
The main constrain of this solution is that the system is 
usable mainly in the daytime, in moderate to good weather 
conditions. Its operability is directly dependant on the 
quality of used cameras. A good night operability requires 
better than average hardware solution, such as CMOS 
sensors with low noise and suitable sensitivity, deliberated 
cameras placement, and the artificial source of light. 
Additionally, the classification module of the system was 
not trained using night-time ships’ images as the traffic 
during night in summer months is very low and therefore, 
the classification accuracy during the night is unknown. 
ACKNOWLEDGMENT 
This work was supported by the National Centre for 
Research and Development (NCBR) of Poland under grant 
No. LIDER/17/0098/L-8/16/NCBR/2017. 
REFERENCES 
[1] IMO (1974) “SOLAS International Convention for the Safety 
of Life at Sea”. International Maritime Organisation. 
[2] N. Wawrzyniak, T. Hyla, and A. Popik, A. “Vessel Detection 
and Tracking Method Based on Video Surveillance”. Sensors 
2019, 19, 5230, pp 1-14 
[3] M. 
Wlodarczyk-Sielicka 
and 
D. 
Polap,“Automatic 
Classification Using Machine Learning for Non-conventional 
Vessels on Inland Waters”, Sensors, 2019, 19(14), 3051., pp 
1-17  
[4] K. Bobkowska and I. Bodus-Olkowska, “Potential and use of 
the GogleNet Ann for the purposes of Inland Water Ship 
Classification,” Polish Maritime Research, vol. 4 (108), vol. 
27, pp.170-178, 2020, doi:10.2478/pomr-2020–0077. 
[5] S. Mule and S. N. Holambe, “Detecting Text in Natural 
Scenes with Connected Component Clustering and Nontext 
Filtering”, IRJET, 2016, vol. 03(09), pp. 625-629. 
[6] J. Matas, O. Chum, M. Urban, and T. Pajdla. “Robust Wide 
Baseline Stereo from Maximally Stable Extremal Region”, in 
David Marshall and Paul L. Rosin, editors, Proceedings of the 
British Machine Conference, pp. 36.1-36.10, BMVA Press, 
September 2002, doi:10.5244/C.16.36. 
[7] X. Zhou, et al., “EAST: An Efficient and Accurate Scene Text 
Detector”. In Proceedings of the IEEE Conference on 
Computer Vision and Pattern Recognition (CVPR), Honolulu, 
HI, USA, 21–26 July 2017. 
[8] T. Hyla and N.Wawrzyniak, “Identification of Vessels on 
Inland 
Waters 
Using 
Low-Quality 
Video 
Streams”, 
Proceedings of the 54th Hawaii International Conference on 
System Sciences, 2021. 
 
31
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-863-1
SMART 2021 : The Tenth International Conference on Smart Cities, Systems, Devices and Technologies

