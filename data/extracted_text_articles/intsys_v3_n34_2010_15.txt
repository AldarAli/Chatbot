Unscented Transform-based Dual Adaptive Control
for Mobile Robots: Comparative Analysis and
Experimental Validation
Marvin K. Bugeja and Simon G. Fabri
Department of Systems and Control Engineering
University of Malta
Msida, Malta
Email: marvin.bugeja@um.edu.mt, simon.fabri@um.edu.mt
Abstract—Adaptive control involves both estimation and con-
trol, which are generally interdependent and partly in conﬂict.
Yet, the majority of adaptive controllers separate the two by
assuming that certainty equivalence holds, even if this is not the
case. In contrast a dual adaptive controller, based on the idea
postulated by A. Fel’dbaum in the early 1960s, aims to strike
a balance between estimation and control at all times. In this
manner, the control law is a function of the estimates’ uncertainty,
besides the estimates themselves, thereby leading to improved
control performance. Few such controllers have ever been im-
plemented and tested in practice, especially within the context
of intelligent control, and to the best of our knowledge none
on mobile robots. This paper present two novel dual adaptive
neural control schemes for the dynamic control of mobile robots
in the presence of functional uncertainty. Furthermore, by means
of realistic Monte Carlo simulations and real-life experiments, a
thorough comparative analysis is performed. A notable novel
contribution of this work is the use of the unscented transform
within the context of dual adaptive control, aimed at improving
further the performance of the system.
Index Terms—Dual adaptive control; nonlinear stochastic con-
trol; neural networks; unscented transform; mobile robots.
I. INTRODUCTION
A major motive for adaptive control is the need to have
automatic systems that operate satisfactorily in the ambience
of uncertainty. The uncertainty is typically due to unknown
and/or time-varying structure or parameters pertaining to the
system or process under control. Hence, in addition to keeping
the controlled variable tracking its reference, an adaptive con-
troller needs to simultaneously estimate the unknown system
functions or parameters. These two objectives, termed control
and estimation respectively, are generally interdependent and
partly in conﬂict, in that typically estimation improves with
perturbing (persistently exciting) input signals, while tracking
performance does not. On the other hand, good tracking
performance still requires good estimates.
Most of the adaptive controllers proposed over the past
ﬁfty-ﬁve years, including the well-established model-reference
adaptive systems (MRAS) and self-tuning regulators (STRs),
artiﬁcially separate estimation and control via the heuristic
certainty equivalence (HCE) assumption. In this manner the
This work was supported by National RTDI under Grant RTDI-2004-026.
parameter estimates are used in the control law as if they were
the true values of the unknown parameters, without any due
consideration to their inherent uncertainty. Though simple to
implement, and adequately applied in many applications, HCE
adaptive control can lead to large tracking errors and excessive
control actions, which can excite unmodelled dynamics or even
lead to instability and possibly physical damage [1]. These
effects are more pronounced in situations characterized by high
uncertainty, short control horizon and/or time-varying system
parameters [2], [3].
The issue of simultaneous estimation and control is best
addressed via stochastic adaptive control theory. Unlike deter-
ministic approaches, in stochastic adaptive control the uncer-
tainty in the system; be it due to unknown process parameters,
noisy measurements, or both; is characterized by probability
distributions and their associated statistical measures. Con-
sequently, the whole system is described via a stochastic
dynamic model, and the simultaneous estimation and control
problem boils down to the minimization of the expected value
of a pre-speciﬁed cost function. However, this task is rarely
straightforward and the general conditions guaranteeing the
existence of an optimal control scheme are yet unknown [2].
A major contribution in the ﬁeld of stochastic adaptive
control was made by A. A. Fel’dbaum in his seminal work on
optimal control [4]–[6]. Fel’dbaum postulated that the control
signal of an optimal adaptive system should have dual goals,
namely: (i) to ensure that the controlled variable tracks the
desired reference signal, with due consideration given to the
estimates’ uncertainty, and (ii) to perturb the plant sufﬁciently
so as to accelerate estimation, thereby reducing quickly the
uncertainty in future estimates. These two properties are
commonly known as caution and probing respectively, or
in Fel’dbaum’s own terminology directing and investigating.
Controllers exhibiting these features are named dual adaptive.
In contrast to an HCE controller, a dual adaptive control law is
dependent on the estimates’ uncertainty, besides the estimates
themselves, and aims to strike a balance between estimation
and control at all times. Fel’dbaum also showed that the exact
solution to the optimal adaptive dual control problem can be
derived using dynamic programming, speciﬁcally by solving
358
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the Bellman equation. However, in almost all practical situa-
tions, with the exception of a few very simple examples [7], the
Bellman equation is impossible to solve, both analytically or
numerically, due to the very large dimensions of the underlying
space [2], [3], [8], [9].
The difﬁculty in ﬁnding the optimal dual adaptive control
law in almost every practical case, led to the development of a
number of simpliﬁed approaches, that though suboptimal, still
exhibit the dual properties of caution and probing featured
by the optimal dual solution. These suboptimal dual adaptive
control schemes can be coherently divided into two groups,
namely implicit and explicit methods. Implicit solutions try
to introduce approximations to render the Bellman equation
tractable [10], while explicit solutions reformulate the problem
via modiﬁed cost functions that explicitly include a term
related to parameter estimation, in order to induce a form of
probing [8], [9], [11]. As pointed out on several occasions [8],
[9], implicit solutions are typically more complex and more
computationally intensive.
Dual adaptive control has been applied successfully in a
number of practical applications [12]–[15]. However none
of these applications involve mobile robots. Motion control
of mobile robots has captured the interest of numerous re-
searchers over the past three decades [1], [16]–[26]. This in-
terest stems from a vast array of existing and potential practical
applications [27]–[31], as well as from a number of particu-
larly interesting theoretical challenges enriching this ﬁeld of
study. In particular, due to their mechanical conﬁguration most
wheeled mobile robots (WMRs) manifest restricted mobility,
giving rise to nonholonomic constraints in their kinematics.
Moreover, many of these WMRs are also underactuated since
they exhibit less control inputs than degrees of freedom. Con-
sequently, the linearized kinematic model of these robots lacks
controllability, full-state feedback linearization is out of reach
[18], and pure smooth time-invariant feedback stabilization of
the Cartesian model is unattainable [32].
Most of the early contributions in the ﬁeld of WMR motion
control focus solely on the kinematic/steering control problem
[16]–[18], [33]. In other words they base their designs on
a robot model with velocity control inputs, rather than the
more realistic model with torque control inputs. In doing so
the controller is completely ignoring the vehicle dynamics
due to mass, inertia and friction. This is known as the
perfect velocity tracking assumption [19]. When it comes to
the practical implementation of these kinematic controllers,
this approach assumes that there is an independent low-level
velocity control loop (usually implemented via a proportional-
integral-derivative (PID) controller), that ascertains that the
actual wheel velocities track precisely those requested by
the kinematic control law [34]. However, while the use of
independent PID velocity control loops is convenient and leads
to acceptable performance in many applications involving
slow-moving robots tracking low-acceleration trajectories, it
can lead to high tracking errors, possibly resulting in total
mission failure, in the face of more challenging tasks charac-
terized by high reference velocities and accelerations [19]. In
such situations, the robot nonlinear dynamics are no longer
negligible and a better approach would be to replace the
PID controller by a superior, though generally more complex,
velocity controller whose design is based on a model relating
the wheel velocities to the input torques. Such a controller
would explicitly account for the vehicle’s dynamic effects due
to mass, friction and inertia. One such example is the well-
established computed-torque approach [19], [34].
However, the dynamic model of a mobile robot is not only
nonlinear but includes parameters or functions; such as mass,
frictional terms and inertia; that are highly uncertain, time-
varying or even unknown. Consequently, a number of adaptive
control methods for the dynamic control of mobile robots
have been proposed. These include both parametric adaptive
control [20] and functional adaptive control [22], [25], [35]–
[37]. The latter differs from the former in that the uncertainty
is not restricted to parametric terms, but covers the dynamic
functions themselves. We consider functional adaptive control
to be more general and superior in handling higher degrees of
uncertainty and unmodelled dynamics. Yet, all the mentioned
adaptive robot controllers rely on the HCE assumption and
so are prone to suffer from the aforementioned ill effects.
In contrast, in our recent works [1], [26], we propose dual
adaptive control techniques, rooted in computational intelli-
gence, to address the problem of mobile robot control with
uncertain/unknown dynamics.
In [26] we propose two novel dual control schemes employ-
ing two different kinds of artiﬁcial neural networks (ANNs),
namely Gaussian radial basis functions (GaRBFs) and multi-
layer perceptrons (MLPs) [38], to estimate the WMR dynamic
functions in real-time. The advantage of GaRBFs over MLPs
lies in the fact that with GaRBFs the unknown ANN weights
appear linearly in the stochastic state-space model formulated
for estimation. This permits the use of the Kalman ﬁlter (KF)
[39] for the recursive optimal ANN weight-tuning. However
in the MLP case, this desirable property of linearity in the
network parameters is not preserved, and the KF weight-
tuning algorithm has to be replaced by a suboptimal nonlinear
stochastic estimator, such as the extended Kalman ﬁlter (EKF)
[40], which not only complicates the derivation of the control
law, but introduces several approximations. On the other hand,
unlike the activation functions employed in GaRBF ANNs, the
sigmoidal functions in MLPs do not have localized receptive
ﬁelds. This implies that typically MLP networks require less
neurons than GaRBF ANNs to achieve the same degree of
accuracy. Consequently, MLPs tend to be less computationally
demanding, especially in the case of high-order systems, since
the number of neurons need not rise exponentially with the
number of states as in the case of GaRBF ANNs. The latter
effect is known as the curse of dimensionality [41].
In the light of these arguments, the MLP dual adaptive
scheme we proposed in [26] uses the EKF to estimate the
nonlinearly-appearing ANN optimal parameters in real-time.
The EKF approximates the state (in this case parameter)
distribution by a Gaussian random variable (GRV) and prop-
agates it analytically through the ﬁrst-order linearization of
359
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the nonlinear stochastic model. Moreover, the dual adaptive
control law proposed for that scheme, is based on another
ﬁrst-order Taylor approximation of the measurement equation
in the stochastic model. This adds further to the suboptimality
of the proposed approach.
To lessen the extent of these approximations, in this paper,
which extends on our recent preliminary work [1], we propose
a novel MLP dual adaptive control scheme that uses a speciﬁ-
cally devised form of the unscented Kalman ﬁlter (UKF) [42],
[43] as a recursive weight-tuning algorithm, instead of the EKF
employed in [26]. In addition, we propose a new dual adaptive
control law that employs the unscented transform (UT) [42]
to improve on the ﬁrst-order Taylor approximation used in
deriving the EKF-based controller in [26].
It should be pointed out that the convergence and stability
analysis of dual adaptive control schemes presents a very
difﬁcult challenge, mainly due to the stochastic and adaptive
nature of the problem. The few works that address these
issues consider only linear systems of a particular form and
are characterized by a number of nontrivial assumptions [9],
[44]. Consequently, in contrast to the case of deterministic
approaches, to prove convergence and stability for a dual
adaptive nonlinear controller, is still considered to be an open
problem within the research community. Hence in practice,
as argued in [9], the stability of dual adaptive controllers is
commonly demonstrated by computer simulations and real-life
experiments.
The contribution of this paper comprises a detailed treat-
ment of the two dual adaptive MLP control schemes mentioned
previously and a set of verifying and comparative results, com-
prising realistic Mont Carlo simulations backed by rigourous
statistical analysis and real-life experiments. In particular, we
show that the proposed UT-based dual adaptive controller
brings about signiﬁcant improvements in tracking performance
over the EKF-based dual adaptive scheme recently proposed in
[26], while still employing the same computationally-friendly
MLP architecture. To the best of our knowledge this is the ﬁrst
work in which the UT is being used in the context of dual
adaptive control. In addition, one should note that very few
adaptive controllers have ever been implemented and tested
on a physical WMR, amongst which one ﬁnds [45], [46].
However, none of these address fully the uncertainty in the
WMR dynamic functions nor take a dual adaptive control
approach.
The rest of the paper is organized as follows. Section II
contains preliminary material, including the development of
the discrete-time dynamic model of the WMR considered in
this work, and a formulation of the WMR trajectory tracking
control problem. Section III presents the design of both the
EKF-based and the proposed UT-based dual adaptive MLP
control schemes. Monte Carlo simulation results supported by
statistical hypothesis comparative tests and real-life experi-
ments are then presented in Section IV, which is followed
by a brief conclusion in Section V.
II. PRELIMINARIES
In this work we address the trajectory tracking problem of
the differentially driven WMR depicted in Figure 1. However,
the framework we adopt in our design is completely modular.
Consequently, the dual adaptive dynamic control scheme pro-
posed in this paper can be easily adopted to address different
navigation problems such as posture stabilization and path
following [34], possibly even for different types of robotic
conﬁgurations. In this section we outline the development of
the dynamic model of the differentially driven WMR and
formulate the trajectory tracking problem considered in this
work.
A. Modelling
With reference to the WMR conﬁguration in Figure 1,
we ignore the passive caster wheels and adopt the following
notation throughout the article:
Po:
axle midpoint between the two wheels
Pc:
centre of mass of the platform without wheels
d:
distance between Po to Pc
b:
distance from the centre of each wheel to Po
r:
radius of each wheel
mc: mass of the platform without wheels
mw: mass of each wheel
Ic:
moment of inertia of the platform about Pc
Iw:
moment of inertia of each wheel about the axle
Im: moment of inertia of each wheel about its diameter
The
robot
coordinate
vector
is
denoted
by
q = [x y φ θr θl]T ,
where
(x, y)
is
the
Cartesian
coordinate of Po, φ is the robot’s orientation with reference
to the x-axis, and θr, θl are the angular displacements about
the axle of the right and left motorized wheels respectively.
The pose of the robot refers to the vector p = [x y φ].
1) Kinematic Model: The differential conﬁguration of this
WMR is subject to three kinematic constraints, stemming from
x
y
r
b
d
φ
Motorized wheels
Centre of
mass Pc
Geometric
centre Po
Caster wheels
Fig. 1.
Differentially driven wheeled mobile robot.
360
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the fact that the translational velocity of the geometric centre
Po is always in the direction perpendicular to the driving
axle, and the two driving wheels roll without slipping. The
former leads to a holonomic constraint while the latter leads
to two nonholonomic constrains [47]. Mathematically this is
described by A(q) ˙q = 0, where
A(q) =


− sin φ
cos φ
0
0
0
cos φ
sin φ
b
−r
0
cos φ
sin φ
−b
0
−r

 .
These three kinematic constraints, along with a few other
relationships arising from the geometry of the WMR depicted
in Figure 1, can be used to show that the kinematic model of
this differentially driven WMR is given by
˙q = S(q)ν,
(1)
where
S(q) =


r
2 cos φ
r
2 cos φ
r
2 sin φ
r
2 sin φ
r
2b
− r
2b
1
0
0
1


,
and ν denotes a vector composed of the angular velocities of
the two motorized wheels, that is, ν = [νr νl]T =
h
˙θr
˙θl
iT
.
It is important to note that:
Remark II.1. The two independent columns of S(q) are in
the null space of A(q), that is, A(q)S(q) = 0.
2) Dynamic Model: The equations of motion of this WMR
can be derived using Lagrangian mechanics. The Euler-
Lagrange equation for the nonholonomic WMR considered in
this paper is given by
d
dt
∂K
∂ ˙qi

− ∂K
∂qi
= Qi −
3
X
c=1
aciλc,
(i = 1, 2, . . ., 5) , (2)
where K(q, ˙q) is the total kinetic energy of the WMR, qi is the
ith element of the coordinate vector q, Qi is the ith Lagrange
force, aci is the (c, i)th element of the constraints matrix A(q)
and λc is the cth element of the vector of Lagrange multipliers
λ. It can be shown that the total kinetic energy of the WMR
is given by
K(q, ˙q)
=
m
2

The following conditions are assumed to hold:
Assumption II.1. The control input vector τ remains constant
over a sampling interval of T seconds (zero-order hold).
Assumption II.2. The sampling interval T is chosen low
enough for the Euler approximation error to be negligible.
B. Trajectory Tracking
The trajectory tracking task of WMRs is commonly deﬁned
via the concept of the virtual vehicle [17]. In this formulation,
the time-dependent reference trajectory is designated by a
nonstationary virtual vehicle, kinematically identical to the real
vehicle. The control task is for the real vehicle to track the
virtual vehicle at all times, in both pose and velocity. It is
important to note that this problem is different and generally
more challenging than path-following. This stems from the fact
that in trajectory tracking the reference path is time-indexed
(hence dictating speed as well as position), while in path-
following the reference contains no temporal information and
the vehicle speed is typically ﬁxed and predetermined [34].
The trajectory tracking error in discrete-time is commonly
deﬁned by a tracking error vector ek = [e1k e2k e3k]T , ex-
pressed pictorially in Figure 2, and mathematically deﬁned by
ek =


cos φk
sin φk
0
− sin φk
cos φk
0
0
0
1

 (prk − pk) ,
(8)
where prk = [xrk yrk φrk]T denotes the virtual vehicle
pose vector. Hence, in trajectory tracking the objective is to
make ek converge to zero, so that pk converges to prk.
III. CONTROL DESIGN
As argued in Section I, the motion control of WMRs is
commonly addressed as two separate tasks, namely kinematic
and dynamic control [19], [34], [37]. Kinematic control is
concerned solely with the steering system (1). Speciﬁcally its
x
y
e1
e2
e3
real vehicle
virtual vehicle
Fig. 2.
Trajectory tracking via the concept of the virtual vehicle.
aim is to devise a control law for the robot wheel velocities,
so as to stabilize the pose of the robot as required by
the navigation task at hand; be it trajectory tracking, path-
following or posture stabilization. In the case of trajectory
tracking, the aim of the kinematic controller is to compute
the wheel velocities required to minimize the robot tracking
error ek. On the other hand, the aim of the dynamic controller
is to compute the wheel torques required in order to ensure
that the robot accurately tracks the velocities computed by
the kinematic controller. Hence, the two control loops operate
in cascade; with the kinematic controller’s output (a velocity
command) serving as the reference input of the cascaded
dynamic controller, which computes the torque required to
drive the WMR wheels at the speciﬁed velocities. This ap-
proach renders the overall control architecture modular, since
the kinematic controller, which is speciﬁc to the navigation
problem at hand, can be easily replaced while still retaining the
same dynamic controller. In our work we adopt this modular
architecture, depicted in Figure 3, and design the dynamic
controller to be dual adaptive as detailed in the rest of this
section.
A. The Kinematic Controller
As argued earlier, the role of the kinematic controller in
trajectory tracking is to make ek converge to zero, so that
pk converges to prk. To address this well-researched problem
we opt to adopt an established kinematic controller, originally
presented in [17], and convert it to discreet-time so as to
integrate it in our formulation. The resulting kinematic control
law is given by
νck = C
"
vrk cos e3k + k1e1k
ωrk + k2vrke2k + k3vrk sin e3k
#
,
(9)
where νck is the wheel velocity command vector issued by
the kinematic controller, k1, k2, and k3 are positive design
parameters, vrk > 0 and ωrk are the translational and angular
virtual vehicle velocities respectively (assumed to be continu-
ous functions, at least know one sampling interval ahead), and
C is a velocity conversion matrix given by
C =
"
1
r
b
r
1
r
− b
r
#
.
Stability analysis and the corresponding necessary conditions
of this controller in continuous-time are detailed in [17].
Trajectory
generator
Kinematic
controller
Dynamic
controller
Wheeled
Mobile
Robot
1st order
hold


pr
vr
ωr


k+1
νck+1
νk
τk
pk+1
pk
Fig. 3.
Dynamic control architecture.
362
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

B. Nonadaptive Dynamic Control
If the nonlinear dynamic functions fk and Gk are perfectly
known, the computed-torque control law
τk = G−1
k
(νck+1 − νk − fk + kd (νck − νk)) ,
(10)
with the design parameter −1 < kd < 1, yields the following
closed-loop stable linear dynamics
νk+1 = νck+1 + kd (νck − νk) ,
when substituted in the dynamic model in (6). This ensures
that |νck − νk| → 0 as k → ∞. It is important to note that:
Remark III.1. Control law (10) requires the velocity com-
mand vector νck+1 to be available at instant k. For this rea-
son, the kinematic control law (9) is advanced by one sampling
interval. This means that at instant k, the values of vrk+1,
ωrk+1 and ek+1 need to be known. Additionally, from (8) it
is clear that prk+1 and pk+1 are needed to determine ek+1.
Having the values of reference signal prk+1, vrk+1 and ωrk+1
available at instant k is easy, since it simply means that the
path-planning algorithm is required to generate the reference
trajectory one sampling interval ahead. On the other hand,
for the non-reference signal pk+1, we propose to estimate its
value via the ﬁrst-order approximation pk+1 ≈ 2pk − pk−1.
This is justiﬁed in the light of Assumption II.2.
Remark III.2. The case with kd = 0 in (10), corresponds to
deadbeat control associated with digital control systems [48].
C. Dual Adaptive Dynamic Control using MLPs
The computed-torque dynamic control law (10) driven by
the kinematic law (9), is a solution to the trajectory tracking
problem only if the WMR dynamic functions fk−1 and Gk−1
in (6) are perfectly known. As emphasized in Section I, this is
rarely the case in real-life robotic applications commonly ex-
hibiting: unmodelled dynamics, unknown/time-varying param-
eters, and imperfect/noisy sensor measurements. Most works,
address these issues via some form of HCE adaptive control.
In contrast, the two schemes presented in this paper not only
consider fk−1 and Gk−1 to be completely unknown to the
controller, but also feature dual adaptive properties to handle
the issue of uncertainty as explained in Section I. The two
dual adaptive schemes, detailed in this section, both employ
a stochastically-trained ANN-based algorithm to approximate
these functions recursively in real-time.
Speciﬁcally, a sigmoidal MLP ANN with one hidden layer
is used to approximate the nonlinear vector-valued function
fk−1, as depicted in Figure 4. Its output is given by
˜
fk−1 =
"
φT (xk−1, ˆak) ˆ
w1k
φT (xk−1, ˆak) ˆ
w2k
#
,
(11)
in the light of the following statements:
Deﬁnition III.1. xk−1 = [νk−1
1] denotes the ANN input.
The augmented constant serves as a bias input. This selection
of the ANN input stems from the fact that fk−1 is effectively
a function of νk−1.
˜
fk−1
xk−1
+
+

 ˆ
w1k
ˆ
w2k


φ1 (s1k)
φ2 (s2k)
φL (sLk)
Fig. 4.
Sigmoidal Multilayer Perceptron neural network.
Deﬁnition
III.2.
φ(·, ·)
is
the
vector
of
sigmoidal
activation
functions,
whose
ith
element
is
given
by
φi = 1/

treated as a random variable, with the initial condition
p(z∗
0) ∼ N(ˆz0, P0), meaning that z∗
0 is normally distributed
with mean ˆz0 and covariance P0. This notation is adopted
throughout the article. Effectively, the covariance value P0
reﬂects the conﬁdence in the initial guess ˆz0.
By (11), (12), all previous deﬁnitions and assumptions,
it follows that the model in (6) can be represented in the
following stochastic state-space form
z∗
k+1
=
z∗
k + ρk
yk
=
h (xk−1, τk−1, z∗
k) + ǫk,
(13)
where the vector-valued function h (xk−1, τk−1, z∗
k) is non-
linear in z∗
k, and is given by
h (·) = ˜
f(xk−1, r∗
k) + ˜
G(g∗
k)τk−1.
(14)
In this model, the unknown optimal parameter vector z∗
k is
characterized as a stationary process corrupted by an artiﬁcial
process noise ρk, which aids convergence and tracking during
estimation. In addition, observation uncertainty is catered for
by augmenting a random measurement noise ǫk to yk.
It is evident, from (14), that the use of the MLP ANN,
which brings about certain practical advantages over GaRBF
as argued in Section I, results in a nonlinear measurement
equation in the stochastic state-space model (13) formulated
for estimation. In order to address this issue in a stochastic
framework, we have to employ a nonlinear recursive estimator.
The two dual adaptive schemes presented in this paper
depart from this point in our formulation and proceed to
tackle the estimation and control problems in different ways,
as detailed next.
1) EKF-based Dual Adaptive Scheme: For the sake of
clarity and completeness, the MLP dual adaptive scheme
proposed in [26] and used for comparisons in this paper is
revisited in this section. In this scheme, we employ the EKF
in prediction mode for the recursive real-time estimation of
z∗
k+1 as follows.
Deﬁnition III.6. The information state denoted by Ik, consists
of all measurements up to instant k and all previous inputs.
Assumption III.3. ǫk and ρk are both zero-mean white
Gaussian processes with covariances Rǫ and Qρ respectively.
Moreover ǫk, ρk and z∗
0 are mutually independent ∀k.
Lemma III.1. In the light of (13), Deﬁnition III.6, and As-
sumption III.3, it follows that p(z∗
k+1|Ik) ≈ N(ˆzk+1, Pk+1),
where ˆzk+1 and Pk+1 are computed at each control step
according to the EKF Algorithm III.1. Consequently, ˆzk+1
is considered to be the estimate of z∗
k+1 conditioned on Ik,
and Pk+1 can be viewed as a measure of this estimate’s
uncertainty.
Proof: The proof of this lemma follows directly that of
the EKF in prediction mode, when applied to the nonlinear
stochastic state-space model in (13).
Given the previous prediction

Cov

2) UT-based Dual Adaptive Scheme: The EKF-based dual
adaptive scheme just presented employs the EKF algorithm
to address the ANN weight-tuning task. Moreover, the corre-
sponding dual adaptive control law in (18) relies on a ﬁrst-
order Taylor approximation of p(yk+1|Ik), as detailed in
Lemma III.2. In contrast, the novel UT-based dual adaptive
scheme detailed in the following paragraphs uses a speciﬁcally
devised form of the UKF [42], [43] as a recursive weight-
tuning algorithm, to replace the less accurate EKF algorithm
of the previous scheme, and in addition employs a novel dual
adaptive law that uses the UT to improve on the ﬁrst-order
Taylor in Lemma III.2 which leads to the EKF-based control
law in (18).
As argued in [43] the UKF, originally proposed by Julier et.
al. in [42], provides a better alternative to the well established
EKF to address the problem of stochastic nonlinear estimation.
Both the EKF and UKF approximate the state (or parameter)
distribution by a GRV. However, while the EKF propagates
the mean and covariance of this GRV through the ﬁrst-order
linearization of the nonlinear system, the UKF uses a minimal
set of deterministically chosen sample points, termed sigma
points, that capture completely the true mean and covariance
of the GRV, and propagates them through the true nonlinear
system, yielding a posterior mean and covariance that are
accurate up to the second order Taylor series expansion for any
nonlinearity. In contrast, the EKF is accurate only up to the
ﬁrst-order Taylor series expansion [43]. Moreover, the UKF is
a derivative-free algorithm and as shown later in Section IV-B,
it is still computationally efﬁcient enough to be implemented
on available hardware in real-time practical applications.
Starting from the MLP ANN formulation of Section III-C
leading to (14), we now proceed to propose the use of an UKF
algorithm in prediction mode for the real-time estimation of
z∗
k+1 as follows.
Lemma III.3. In the light of (13), Deﬁnition III.6, and As-
sumption III.3, it follows that p(z∗
k+1|Ik) ≈ N(ˆzk+1, Pk+1),
where ˆzk+1 and Pk+1 are computed at each control step
according to the UKF Algorithm III.2. Consequently, ˆzk+1
is considered to be the estimate of z∗
k+1 conditioned on Ik,
and Pk+1 can be viewed as a measure of this estimate’s
uncertainty.
Proof: The UKF algorithm in prediction mode, presented
in Algorithm III.2, is effectively the standard UKF algorithm
as stated in [43] for parameter estimation, with the difference
that the measurement-update step precedes that for time-
update. In addition, the time-update step is advanced by one
sample to obtain ˆzk+1|k at instant k. Hence, the proof of
Lemma III.3 follows directly that of the UKF (additive noise
version) when applied to the nonlinear stochastic state-space
model in (13).
Lemma III.4. On the basis of Lemma III.3, it follows that
p(yk+1|Ik) is approximately Gaussian with mean ˆyk+1 and
covariance Pyyk+1 given by:
ˆyk+1 = ˆ
fk + ˆ
Gkτk,
(22)
Given the previous prediction

Pyyk+1 in (24) one needs to advance the equation for Pyyk
in Algorithm III.2 by one sampling instant, and substitute for
Yi,k+1|k and ˆyk+1, using the relations leading to (21) in the
same algorithm.
Remark III.6. One should particularly note that in Lemma
III.4, the evaluation of the approximate mean and covariance
of p(yk+1|Ik) are not based on a ﬁrst-order Taylor approxi-
mation, as in the case of the EKF-based scheme speciﬁcally
in Lemma III.2, but are generated through the more accurate
method for approximating the statistics of random variables
which undergo a nonlinear transformation, namely the UT
[42].
Algorithm III.2, in the light of Lemma III.3 constitutes
the weight adaptation law for the novel UT-based MLP dual
adaptive scheme. In addition, Lemma III.4 provides a real-
time update of the probability density function p(yk+1|Ik).
This information is employed by the UT-based dual adaptive
control law stated in the theorem below.
Theorem III.2. The control law minimizing performance
index Jinn in (17), subject to the WMR dynamic model (6),
Deﬁnitions III.7 and III.8, Remark III.3 and Lemmas III.3 and
III.4, is given by
τk
=

ˆ
GT
k Q1 ˆ
Gk + Q2 + NGGk+1
−1
×

ˆ
GT
k Q1

TABLE I
WMR PHYSICAL PARAMETERS (NEUROBOT WITH NO LOAD).
Parameter
Value
d
0 m
b
22.95 cm
r
6.25 cm
mc
21.0 kg
mw
1.5 kg
Ic
0.55 kgm2
Iw
0.0006 kgm2
Im
0.01 kgm2
robot dynamic parameters, speciﬁcally: ¯d = 0 m, ¯
mc = 26 kg,
¯Ic = 0.87 kgm2 and the diagonal values of ¯
Fc both set to 0.25.
It is important to appreciate that this is the best a nonadaptive
controller can do when the exact robot parameters are un-
known to the controller, as in the case of these simulations and
typical real-life applications; (2) a perfectly-tuned nonadaptive
(PTNA) controller, which is effectively the computed-torque
control law (10) with kd = 0, pre-tuned with the exact values
of the robot parameters. The latter is the best theoretical
controller since it perfectly cancels the nonlinearities and
yields deadbeat control. Naturally this controller is unrealistic
since the exact robot parameter values are never known in
practice and are generally prone to change. Hence we use this
controller solely to provide an ideal reference for quantitative
comparisons. In contrast, the HCE, cautious and dual adaptive
controllers assume no preliminary information about the robot
dynamics whatsoever, since closed-loop control is activated
immediately with the initial parameter estimate vector ˆz0
generated randomly from a zero-mean, Gaussian distribution
with variance 0.025.
For the sake of fair comparison the same control sampling
interval (T = 50 ms), velocity measurement noise sequence
p(ǫk) ∼ N(0, 0.0001I2), reference trajectory, initial condi-
tions, initial ﬁlter covariance matrix (P0 = 0.5I27), artiﬁcial
process noise covariance (Qρ = 10−8I27), tracking error
penalty (Q1 = I2), and control input penalty (Q2 = 0), are
used in each controller simulation in a particular simulation
trial. In addition, the sigmoidal MLP ANN used in each of
the two schemes under test contains ﬁve neurons (L = 5 ⇒
N = 27). Our experiments indicated that adding more neurons
did not improve the control performance signiﬁcantly. In the
UT-based scheme, the UKF scaling parameters are set to
α = 1, κ = 0 and β = 2.
1) Single Trial Analysis: A number of simulation results
typifying the performance of the three control modes of the
proposed UT-based adaptive scheme as well as the EKF-
based adaptive scheme revisited in this paper are depicted
in Figure 5. It should be emphasized at the outset that these
results are only included to depict the typical performance
of each adaptive control mode (HCE, cautious and dual) of
each scheme, and not to be used to compare the two schemes
(the UT-based and the EKF-based) themselves. The reason
for this is that the results shown in Figure 5 correspond to
single simulation trials, and since the nature of the simulation
is stochastic, it is inappropriate to draw general conclusions
based solely on the result of one or two simulation trials.
The Monte Carlo analysis that follows later in this section
is designed to address this issue and leads to a more fair
and scientiﬁcally sound comparison of the proposed schemes.
However, the single trial results presented in Figure 5 do give
a number of important indications on the relative performance
of the HCE, cautious and dual adaptive control modes, which
we have found to be highly consistent and independent on the
number of trials and even the scheme itself.
In Figure 5, the plots labelled (.i) correspond to the proposed
UT-based scheme while those marked (.ii) correspond to the
EKF-based scheme. The following comments and observations
apply to both schemes. Plots (a.i) and (a.ii) depict the WMR,
controlled by the respective adaptive controller in dual mode,
tracking a demanding reference trajectory with nonzero initial
tracking error. It is clear that the robot converges quickly
to the reference trajectory and keeps tracking it with high
precision, even when it reaches high speeds of around 1 m/s.
Plots (b) to (e) focus on the transient of another simulation
trial that uses the same reference trajectory, but purposely
initiated with zero tracking error conditions. In this manner,
any transient errors can be attributed to the capability of the
respective controller to cope with the initially high levels of
uncertainty in the estimates. Plots (b.i) and (b.ii) compare
the Euclidean norm (denoted by ∥·∥ throughout the paper)
of the x − y position error vector. This is computed via
∥xyerror∥ =
p
(xr − x)2 + (yr − y)2. Plots (c.i) and (c.ii)
show the magnitude of the WMR orientation error for the three
control modes. Plots (d.i) and (d.ii) show the error in the robot
pose while Plots (e.i) and (e.ii) compare the corresponding
control inputs, more speciﬁcally the Euclidian norm of the
torque vector. As can be seen in Plots (e.i) and (e.ii), the HCE
controller leads to very high transient control inputs. This is a
direct results of its aggressive and incautious nature, stemming
from the fact that it completely ignores the high uncertainty in
the initial estimates. Plots (b) to (d) clearly indicate that this
leads to relatively high transient errors in both position and
orientation. The cautious mode, which leads to lower transient
errors relative to the HCE, is slightly more sluggish than the
dual mode. This can be seen in Plots (e), where the initial
control input issued by the cautious controller is the lowest.
This leads to a slower (relative to the dual mode) decay of the
pose error as indicated in Plots (d.i) and (d.ii). It is clear that
the dual mode manages to strike a balance between these two
extremes and leads to the best transient performance in both
schemes. All these observations are in accordance with the
anticipations of Remark III.4. In addition, the three adaptive
modes in each scheme converge to the same performance at
steady-state. This is not unexpected due to the fact that by the
time steady-state is reached the parameter estimates would
have practically converged to the actual parameters, meaning
that the robot would have adapted well to its own current
dynamics.
368
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

−3
−2
−1
0
1
2
3
−4
0
4
(a.i)
y (m)
x (m)
−3
−2
−1
0
1
2
3
−4
0
4
(a.ii)
x (m)
y (m)
0
2
4
6
8
10
0
5
10
(b.i)
||xyerror|| (cm)
 
 
0
2
4
6
8
10
0
5
10
(b.ii)
||xyerror|| (cm)
0
2
4
6
8
10
0
5
(c.i)
|φr − φ| (deg)
0
2
4
6
8
10
0
5
(c.ii)
|φr − φ| (deg)
0
2
4
6
8
10
0
0.1
(d.i)
||pr − p||
0
2
4
6
8
10
0
0.1
(d.ii)
||pr − p||
0
0.5
1
1.5
2
0
50
100
(e.i)
time (s)
||τ|| (Nm)
0
0.5
1
1.5
2
0
50
100
(e.ii)
time (s)
||τ|| (Nm)
 
 
t = 0s
40s
40s
t = 0s
HCE
CAUTIOUS
DUAL
UT-based Scheme
EKF-based Scheme
Fig. 5.
Simulation results for the (i) UT-based and (ii) EKF-based schemes: (a) reference (green ×) and actual (red ⃝) trajectories, (b) position error
∥xyerror∥ =
p
(xr − x)2 + (yr − y)2, (c) orientation error, (d) pose error, (e) control input. N.B. (a) controller in dual mode with non-zero initial error,
(b) to (e) transients for zero initial error.
2) Monte Carlo Analysis: To quantify the controllers’ per-
formance objectively, a Monte Carlo simulation involving 500
simulation trials was performed. For each of the eight con-
troller simulations in a trial, the reference trajectory depicted
in Figure 5a, but with zero initial tracking error, is used and the
simulation settings and conditions speciﬁed earlier apply. At
the end of each trial, the following accumulated cost function
C(kend) is calculated:
C(kend) =
kend
X
k=1
∥prk − pk∥2.
This cost function, based on the robot pose error over the
whole time horizon (kend sampling instants), serves as a per-
formance measure for each of the eight controllers operating
under the same conditions, where lower values of C(kend) are
naturally preferred.
The salient statistical features of the resulting eight cost
distributions resulting from this Monte Carlo simulation, are
depicted in the boxplot of Figure 6. Additionally, the median,
interquartile range (IQR), mean and variance of each of these
distributions are given in Table II. Due to the skewness of
these distributions and the high number of outliers in some
of the cases, the median is preferred over the mean as a
measure of central tendency while the IQR is preferred over
the variance as a measure of dispersion (spread). The results
in Figure 6 and Table II provide the ﬁrst indications how
one would rank the general performance of the controllers
369
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

EKF−HCE
EKF−CAU
EKF−DUA
UT−HCE
UT−CAU
UT−DUA
NTNA
PTNA
0
10
20
30
40
50
60
70
80
ACCUMULATED COST
outliers up to 226
outliers up to 174
Fig. 6.
Boxplot of the cost distributions.
TABLE II
STATISTICAL MEASURES OF THE COST DISTRIBUTIONS.
Controller
Median
IQR
Mean
Variance
Rank
EKF-HCE
1.20
4.16
7.24
471.12
6
EKF-CAU
0.37
0.87
1.18
14.07
4
EKF-DUA
0.27
0.85
0.91
5.06
3
UT-HCE
0.44
1.22
4.65
303.79
5
UT-CAU
0.12
0.13
0.19
0.14
2
UT-DUA
0.09
0.11
0.15
0.08
1
NTNA
6.36
7.38
6.86
21.06
-na-
PTNA
0.003
0.004
0.004
<0.000
-na-
under investigation, where lower values of the median and
IQR are obviously preferred. From the outset one can easily
notice that the NTNA controller yields the highest median
and IQR, implying that in general it leads to the highest pose
error and deviation in performance. This is not unexpected
since this controller is not adaptive and so unable to cope
well with the robot parameters that are constantly changing
from one simulation trial to another. In fact, its performance
could be much worse if the nominal parameters, to which
it is tuned, are unknown or the model variations are higher.
For this reason there is no scope in comparing it further to
the other adaptive controllers, and so it is withdrawn from the
following comparative analysis. Consequently in the following
comparative treatment we focus solely on the remaining six
adaptive controllers since the PTNA results are included only
for reference.
Focusing back on the six adaptive controllers, one notices
that the two HCE controllers yielded a relatively high number
of extreme outliers (refer to Figure 6). This is the reason
why in Table II the mean and variance corresponding to
these controllers are exceptionally high. This implies that in
a number of trials the HCE mode led to very high transient
errors. Again, this implies that the complete lack of sensitivity
exhibited by HCE adaptive controllers in the face of the highly
uncertain estimates characterizing the startup phase, can lead
to excessively high control inputs and tracking errors which
can potentially result in mission failure and possibly hardware
damage in a practical situation. This strengthens our previous
results in Section IV-A1 and again consolidates the arguments
in Remark III.4. The results in Table II also indicate that
within each scheme the dual mode outperforms the cautious
and HCE modes. In addition, it is evident that each mode
in the UT-based scheme outperforms its counterpart in the
EKF-based scheme. The latter implies that the proposed UT-
based scheme brings by a considerable improvement over the
EKF-based scheme, originally proposed in [26]. However, in
order to strengthen these claims further and to ascertain that
the observed differences in the performance of each controller,
indicated by the results in Table II, are statistically signiﬁcant
and cannot be attributed to chance, we employed a statistical
inference procedure via the following hypothesis test.
The One-Way Analysis of Variance (ANOVA) is a powerful
statistical procedure used to make inferences on the population
means of several independent samples. Like all other para-
metric tests it relies on a number of assumptions [51]. Most
importantly, the samples should be independent, normally
distributed and exhibit fairly similar variances. It is also known
that ANOVA is quite robust in the face of violations to its
assumptions, mostly so when the sample sizes are large and
equal. However, the cost distributions corresponding to the
six adaptive controllers left for investigation are all positively
370
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

skewed, and therefore cannot be closely approximated to
normal distributions. Hence, the original cost observations
were all transformed using the natural logarithm function. The
transformed samples were found to be fairly Gaussian (skew-
ness and kurtosis in the range of ±1). This was veriﬁed by
investigating the histogram and the normal quantile-quantile
(Q-Q) plots of each transformed sample [51]. However, the
Levene’s test for homogeneity of variance [51] indicated that
equal variances among the six transformed samples still could
not be assumed. In such cases it is suggested that the Brown-
Forsythe F statistic or the Welch’s F statistic are used instead
of the standard F statistic in the ANOVA test [51].
Based on these results, the log transformed cost values were
used in the ANOVA test, aimed to compare the population
means of the six cost distributions. The null and alternative
hypotheses for this two-tailed test are:
H0 :
In general the six adaptive controllers perform
equally well. In other words: in an inﬁnite number
of Monte Carlo simulation trials the six controllers
would yield the same mean cost.
H1 :
Some controllers perform better than the others. In
other words: in an inﬁnite number of Monte Carlo
simulation trials two or more controllers would yield
a different mean cost.
The resulting p-values [51], corresponding to the Brown-
Forsythe and the Welch tests, were both approximately zero.
Hence, since the p-value is smaller than the chosen level of
signiﬁcance α = 0.05, the null hypothesis H0 is rejected. This
implies that at least one of the six controllers is signiﬁcantly
better (cost-wise) than the others. In order to investigate
the underlying differences further and be able to rank the
controllers according to their performance we employed the
Games-Howell post-hoc test, which is highly recommended in
the case of unequal variances [51]. The result was conspicuous,
since all the p-values resulting from all pair-wise combinations
were much lower than the chosen level of signiﬁcance α. This
implies that the means of the transformed samples, depicted
in Figure 7, are all signiﬁcantly different and can be used to
rank the general performance of the six adaptive controllers
as given in the last column of Table II. In addition, a non-
parametric test using the original cost distributions instead of
UT−DUA
UT−CAU
EKF−DUA
EKF−CAU
UT−HCE
EKF−HCE
−2.5
−2
−1.5
−1
−0.5
0
0.5
MEAN OF THE LOG TRANSFORMED
COST DISTRIBUTIONS
Fig. 7.
Means plot of the log transformed cost distributions.
the transformed distributions, namely the Kruskal-Wallis test
[51] was also employed to test the set hypothesis. The ﬁnal
result of this analysis fully conﬁrms that of the ANOVA.
The results from this Monte Carlo comparative analysis
fully support those derived from Table II and Figure 5. Hence,
we can conﬁdently claim that:
Remark IV.1. The proposed UT-based scheme brings about
a signiﬁcant improvement in tracking performance over the
EKF-based scheme, independent of the controller mode (HCE,
cautious or dual). We associate this to the better estimations
of the UKF over those of the EKF in the ANN training
algorithm, and to the better (second-order) approximations
of the UT-based control law as opposed to the ﬁrst-order
approximations inherent in the EKF-based control algorithm.
Moreover, within each scheme the dual mode is superior to
both the cautious and HCE modes. This complies with the
dual control philosophy that a balance between caution and
probing yields the best performance in adaptive control. It
is also not surprising that the performance of the adaptive
controllers is generally better than that of the computed-torque
nonadaptive controller which assumes nominal values for the
robot dynamic parameters, when these are prone to change.
B. Experimental Results
The
UT-based
and
EKF-based
dual
adaptive
neuro-
controllers presented in this article were both implemented
successfully on a physical WMR, named Neurobot, which was
designed and built by the authors as an experimental research
testbed. This section introduces Neurobot and reports a number
of experimental results that compliment those acquired by
simulation and reported in the previous section.
Neurobot, pictured in Figure 8, is a differentially driven
WMR. Each of the two 125 mm diameter, solid-rubber, mo-
torized wheels, is independently driven by a 70 W, 24 V per-
manent magnet dc motor (from maxon motor [52]), equipped
with a 113:1 planetary reduction gearbox and a 500 pulses per
revolution incremental optical encoder. Each of the two motors
is driven via the LMD18200 H-Bridge IC which is controlled
by a 20 kHz pulse-width modulation (PWM) reference signal.
The instantaneous current in each motor is measured using the
LEM HX-03-P/SP2 Hall effect current transducer, and ﬁltered
by a 4th-order continuous-time Bessel low-pass anti-aliasing
ﬁlter, tuned for a corner frequency of 2 kHz, and implemented
via the MAX275 ﬁlter IC. Neurobot is powered by four 12 V,
9 Ah sealed lead acid (SLA) batteries.
The algorithms controlling Neurobot were all implemented
on a MicroAutoBox embedded computer system from dSPACE
[53]. The MicroAutoBox is a compact stand-alone prototyping
unit designed speciﬁcally for rapid-prototyping of computa-
tionally demanding real-time control systems, typically re-
quiring a number of general and specialized analogue/digital
input and output channels. A digital pole-placement torque
controller with integral action, was designed and implemented
completely in software to account for the motor electrical dy-
namics. This inner torque control loop uses the motor current
371
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Fig. 8.
Neurobot: the WMR built for the purpose of this research.
measurement as feedback and issues voltage commands to the
motors. This ascertains that the actual torques at the wheels
track those issued by the outer loop control law (the robot
dynamic controller) and that motor current never exceeds a
predeﬁned safe value. This cascade approach imposes that the
inner loop operates at a much faster rate than the outer loop.
The sampling rates for the inner and outer loops were chosen
to be 10 kHz and 200 Hz respectively.
A desktop computer was used to implement the control
algorithms in Simulink® using the system blocks provided
by the dSpace Real-Time Interface. Real-Time Workshop® is
then used to automatically generate the required code which
is then downloaded to the MicroAutoBox via the dSpace Link
Board installed in the desktop computer. The system states and
parameters along with other information about the real-time
execution of each task running on the MicroAutoBox, such as
sampling times, priorities and execution times, could also be
monitored in real time via ControlDesk, also from dSPACE.
The initial network parameter vector ˆz0 was generated
randomly. In addition, the MLP ANN contained ﬁve neurons
(L = 5 ⇒ N = 27) and the UKF scaling parameters were
set to α = 10−3, κ = 3 − N and β = 2. The initial covari-
ance matrix P0 = 0.5I27 and the process and measurement
noise covariance matrices were set to 10−8I27 and 10−4I2
respectively. In addition, Q1 and Q2 were ﬁxed to I2 and 0
respectively in all cases.
A number of experimental results, validating the proposed
schemes and conﬁrming the simulation results of this section,
are presented in Figure 9. Plots (a) and (b) correspond to
a challenging trajectory tracking experiment that tests the
overall performance of the UT-based and EKF-based dual
adaptive controllers in a real-life application. Plots (a.i) and
(a.ii) show that in both cases Neurobot swiftly adapts to
its own dynamics (with no preliminary ofﬂine training) and
simultaneously converges smoothly to the reference trajectory,
which it keeps tracking at very high precision for the rest of
the experiment. Plots (b.i) and (b.ii) focus on the pose error
vector norm ∥prk − pk∥ measured during this experiment.
In each case, the red trace corresponds to the dual adaptive
controller while the black trace corresponds to a nonadaptive
computed-torque controller subjected to the same experiment.
This nonadaptive controller employs the control law in (10)
with kd = 0 and is tuned for Neurobot’s physical parameters
reported earlier in Table I. It is clear that the two dual adaptive
schemes performed much better than the nonadaptive con-
troller in steady-state. We attribute this results to the fact that
the nonadaptive controller is based on a theoretical dynamic
model (6), which like any other of its sort, is imperfect
and relies on several physical parameters, such as friction
and inertia, which are very difﬁcult to measure precisely in
practice. On the other hand, the adaptive controllers assume no
preliminary information about the robot dynamics but acquire
this knowledge autonomously in real-time. In addition, if
one compares the pose error of the UT-based dual adaptive
controller in Plot (b.i) to that of its EKF-based counterpart in
Plot (b.ii), it is easy to notice that the steady-state performance
of the former is relatively better than that of the latter. This
result is in accordance to Remark IV.1 derived from our
simulation results.
Plots (c) and (d) correspond to a different experiment with
Neurobot. This experiment was designed speciﬁcally to test
and compare the transient performance of the two adaptive
schemes and their HCE, cautious and dual modes on a real
WMR. In this experiment the reference trajectory follows a
straight line along the x-axis, with a speed of 0.1 m/s. At
t = 5 s, well after the robot has reached steady-state operation,
the estimate vector ˆzk+1 is instantaneously reset to some
randomly generated values, hence erasing all the knowledge
acquired by the ANN estimator up to that point in time. In
addition, the covariance matrix Pk+1 is reset to its initial
relatively high value, to reﬂect the high uncertainty in the
new set of random network parameters. In this manner one
can objectively compare the transient performance of the three
control modes when faced with extremely high uncertainty in
the robot dynamics. In practice, similar scenarios may arise
during faults and jump variations in the robot dynamics. The
question in these cases is not simply whether or not the robot
adapts to the new situation, but also how smoothly and quickly
it will do so. In Plots (c.i) and (c.ii), it is evident that the
HCE mode (blue trace) by far yields the highest transient
pose error, as a result of the sudden estimator disturbance
at t = 5 s. As argued previously, this is clearly the result of
372
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

−0.5
0
0.5
0
(a.i)
y (m)
x (m)
−0.5
0
0.5
0
(a.ii)
x (m)
y (m)
0
5
10
15
20
25
30
0
0.02
0.04
(b.i)
||pr − p||
 
 
0
5
10
15
20
25
30
0
0.02
0.04
(b.ii)
||pr − p||
5
6
7
8
9
10
0
0.004 (c.i)
||pr − p||
5
6
7
8
9
10
0
0.008 (c.ii)
||pr − p||
4.8
4.9
5
5.1
5.2
5.3
5.4
0
5
10
15 (d.i)
time (s)
||τ|| (Nm)
4.8
4.9
5
5.1
5.2
5.3
5.4
0
5
10
15(d.ii)
time (s)
||τ|| (Nm)
 
 
HCE
DUAL
NONADAPTIVE
DUAL
CAUTIOUS
0s
30s
30s
0s
UT-based Scheme
EKF-based Scheme
Fig. 9.
Experimental results for the (i) UT-based and (ii) EKF-based schemes: (a) reference (green ×) and actual (red ⃝) trajectories, (b) pose error
(corresponding to the trajectory in (a)), (c) pose error (the line test), (d) control input (the line test). N.B. In (a) the controller is in dual mode (red trace) with
non-zero initial error, (c) and (d) depict the line test results.
the relatively persistently aggressive and sudden control input
issued by the HCE mode, which can be seen in Plots (d.i)
and (d.ii) (blue trace). Speciﬁcally, these two plots depict the
Euclidean norm of the actual torque vector developed by the
motors and not that requested by the adaptive controller. In
theory these are equal, but in our physical implementation we
had to limit the requested torque via a saturation function so
as not to damage the electronic circuitry driving the motors.
If it were not for this safety feature, the situation would be
closer to that depicted in Plots (e.i) and (e.ii) of Figure 5.
These results also indicate that out of the three adaptive modes
in each scheme, the dual mode (red traces) by far exhibits
the best transient performance, due to the very low transient
errors and the very quick recovery exhibited in this experiment.
Moreover, it is also evident that the three controller modes in
the UT-based scheme yielded lower pose errors, and hence
better performance than their EKF-based counterparts. This
can be clearly seen when one compares the magnitude of the
pose errors depicted in Plot (c.i) with that of the errors in Plot
(c.ii). One should particularly note the different scales used
for the y-axes.
The experimental results presented in this section strongly
endorse the simulation results, including those from the Monte
Carlo analysis, reported previously in Section IV-A. Conse-
quently they extend the arguments expressed in Remark IV.1
to the case of a real-life robotic application.
V. CONCLUSION
In this paper we have presented a novel MLP dual adaptive
control scheme for the dynamic control of WMRs. The design
employs the UKF and the UT to improve on the EKF-based
MLP dual adaptive scheme we recently proposed in [26].
The presented designs are validated and compared extensively
via both realistic Mont-Carlo simulations, backed by rigorous
373
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

statistical analysis and real-life experiments with Neurobot,
the WMR designed and built by the authors for the purpose
of this research. All the results conspicuously show that:
1) The proposed UT-based scheme outperforms the EKF-
based scheme.
2) In both schemes, the dual mode is superior (in transient
performance) to both the cautious and the HCE con-
troller modes.
3) The steady-state performance of the adaptive controllers
is generally better than that of the computed-torque
nonadaptive controller.
To the best of our knowledge this is the ﬁrst time that the
UT is being used in the context of dual adaptive control and
where a dual adaptive controller is implemented and tested on
a real mobile robot.
REFERENCES
[1] M. K. Bugeja and S. G. Fabri, “Dual-adaptive computer control of a
mobile robot based on the unscented transform,” in Proc. of the 3rd Int.
Conference on Advanced Engineering Computing and Applications in
Sciences (ADVCOMP’ 09), Sliema, Malta, Oct. 2009, pp. 136–141.
[2] K. J. ˚Astr¨om and B. Wittenmark, Adaptive Control, 2nd ed.
Reading,
MA: Addison-Wesley, 1995.
[3] B. Wittenmark, “Adaptive dual control methods: An overview,” in 5th
IFAC Symp. on Adaptive Systems in Control and Signal Processing,
Budapest, Hungary, Jan. 1995, pp. 67–72.
[4] A. A. Fel’dbaum, “Dual control theory I-II,” Automation and Remote
Control, vol. 21, pp. 874–880, 1033–1039, 1960.
[5] ——, “Dual control theory III-IV,” Automation and Remote Control,
vol. 22, pp. 1–12, 109–121, 1961.
[6] ——, Optimal Control Systems. New York, NY: Academic Press, 1965.
[7] J. Sternby, “A simple dual control problem with an analytical solution,”
IEEE Trans. Autom. Control, vol. 21, no. 6, pp. 840–844, 1976.
[8] S. G. Fabri and V. Kadirkamanathan, Functional Adaptive Control: An
Intelligent Systems Approach.
London, UK: Springer-Verlag, 2001.
[9] N. M. Filatov and H. Unbehauen, Adaptive Dual Control: Theory and
Applications.
London, UK: Springer-Verlag, 2004.
[10] Y. Bar-Shalom and E. Tse, Concept and Methods in Stochastic Control,
ser. Control and Dynamic Systems, C. T. Leondes, Ed.
New York, NY:
Academic Press, 1976.
[11] R. Milito, C. S. Padilla, R. A. Padilla, and D. Cadorin, “An innovations
approach to dual control,” IEEE Trans. Autom. Control, vol. 27, no. 1,
pp. 133–137, Feb. 1982.
[12] G. A. Dumont and K. J. ˚Astr¨om, “Wood chip reﬁner control,” IEEE
Control Syst. Mag., vol. 8, no. 2, pp. 38–43, 1988.
[13] N. M. Filatov, U. Keuchel, and H. Unbehauen, “Dual control for an
unstable mechanical plant,” IEEE Control Syst. Mag., vol. 16, no. 4, pp.
31–37, 1996.
[14] B. J. Allison, J. E. Ciarniello, P. J.-C. Tessier, and G. A. Dumont, “Dual
adaptive control of chip reﬁner motor load,” Automatica, vol. 31, no. 8,
pp. 1169–1184, 1995.
[15] A. Ismail, G. A. Dumont, and J. Backstrom, “Dual adaptive control of
paper coating,” IEEE Trans. Contr. Syst. Technol., vol. 11, no. 3, pp.
289–309, May 2003.
[16] T. Tsumura, N. Fujiwara, T. Shirakawa, and M. Hashimoto, “An exper-
imental system for automatic guidance of robot vehicle, following the
route stored in memory,” in Proc. 11th Int. Symp. on Industrial Robots,
Oct. 1981, pp. 187–193.
[17] Y. Kanayama, Y. Kimura, F. Miyazaki, and T. Noguchi, “A stable
tracking control method for an autonomous mobile robot,” in Proc. IEEE
Int. Conference of Robotics and Automation, Cincinnati, OH, May 1990,
pp. 384–389.
[18] C. Canudas de Wit, H. Khennoul, C. Samson, and O. J. Sordalen,
“Nonlinear control design for mobile robots,” in Recent Trends in Mobile
Robots, ser. Robotics and Automated Systems, Y. F. Zheng, Ed.
World
Scientiﬁc, 1993, ch. 5, pp. 121–156.
[19] R. Fierro and F. L. Lewis, “Control of a nonholonomic mobile robot:
Backstepping kinematics into dynamics,” in Proc. IEEE 34th Conference
on Decision and Control (CDC’95), New Orleans, LA, Dec. 1995, pp.
3805–3810.
[20] T. Fukao, H. Nakagawa, and N. Adachi, “Adaptive tracking control of a
nonholonomic mobile robot,” IEEE Trans. Robot. Autom., vol. 16, no. 5,
pp. 609–615, Oct. 2000.
[21] A. De Luca, G. Oriolo, and M. Vendittelli, “Control of wheeled mobile
robots: An experimental overview,” in RAMSETE - Articulated and
Mobile Robotics for Services and Technologies, ser. Lecture Notes in
Control and Information Sciences, S. Nicosia, B. Siciliano, A. Bicchi,
and P. Valigi, Eds.
Springer-Verlag, 2001, vol. 270, pp. 181–223.
[22] C. de Sousa, E. M. Hemerly, and R. K. H. Galvao, “Adaptive control for
mobile robot using wavelet networks,” IEEE Trans. Syst., Man, Cybern.,
vol. 32, no. 4, pp. 493–504, 2002.
[23] M. L. Corradini, G. Ippoliti, and S. Longhi, “Neural networks based
control of mobile robots: Development and experimental validation,”
Journal of Robotic Systems, vol. 20, no. 10, pp. 587–600, 2003.
[24] M. Oubbati, M. Schanz, and P. Levi, “Kinematic and dynamic adap-
tive control of a nonholonomic mobile robot using RNN,” in Proc.
IEEE Symp. on Computational Intelligence in Robotics and Automation
(CIRA’05), Helsinki, Finland, Jun. 2005.
[25] T. Das and I. N. Kar, “Design and implementation of an adaptive fuzzy
logic-based controller for wheeled mobile robots,” IEEE Trans. Contr.
Syst. Technol., vol. 14, no. 3, pp. 501–510, 2006.
[26] M. K. Bugeja and S. G. Fabri, “Dual adaptive dynamic control of
mobile robots using neural networks,” IEEE Trans. Syst., Man, Cybern.
B, vol. 39, no. 1, pp. 129–141, 2009.
[27] F. Lamiraux, J. P. Laumond, C. VanGeem, D. Boutonnet, and G. Raust,
“Trailer truck trajectory optimization: the transportation of components
for the Airbus A380,” IEEE Robot. Autom. Mag., vol. 12, no. 1, pp.
14–21, 2005.
[28] R. Murphy, “Rescue robotics for homeland security,” Communications
of the ACM, vol. 27, no. 3, pp. 66–69, 2004.
[29] P. Debanne, J. V. Herve, and P. Cohen, “Global self-localization of a
robot in underground mines,” in Proc. Systems, Man, and Cybernetics -
Computational Cybernetics and Simulation, Orlando, FL, Dec. 1997.
[30] M. Long, A. Gage, R. Murphy, and K. Valavanis, “Application of the
distributed ﬁeld robot architecture to a simulated demining task,” in
Proc. IEEE Int. Conference on Robotics and Automation (ICRA’05),
Barcelona, Spain, Apr. 2005.
[31] D. Ding and R. A. Cooper, “Electric-powered wheelchairs,” IEEE
Control Syst. Mag., vol. 25, no. 2, pp. 22–34, 2005.
[32] R. W. Brockett, Asymptotic Stability and Feedback Stabilisation, ser.
Differential Geometric Control Theory, R. S. Millman and H. J. Suss-
man, Eds.
Boston, MA: Birkh¨auser, 1983.
[33] I. Kolmanovsky and N. H. McClamroch, “Developments in nonholo-
nomic control problems,” IEEE Control Syst. Mag., vol. 15, no. 6, pp.
20–36, 1995.
[34] P. Morin and C. Samson, “Motion control of wheeled mobile robots,”
in Springer Handbook of Robotics, B. Siciliano and O. Khatib, Eds.
Berlin Heidelberg: Spinger-Verlag, 2008, ch. 34.
[35] R. Fierro and F. L. Lewis, “Control of a nonholonomic mobile robot
using neural networks,” IEEE Trans. Neural Netw., vol. 9, no. 4, pp.
589–600, Jul. 1998.
[36] M. K. Bugeja and S. G. Fabri, “Neuro-adaptive dynamic control for
trajectory tracking of mobile robots,” in Proc. 3rd Int. Conference on
Informatics in Control, Automation and Robotics (ICINCO’06), Set´ubal,
Portugal, Aug. 2006, pp. 404–411.
[37] Z.-G. Hou, A.-M. Zou, L. Cheng, and M. Tan, “Adaptive control of
an electrically driven nonholonomic mobile robot via backstepping and
fuzzy approach,” IEEE Trans. Contr. Syst. Technol., vol. 17, no. 4, pp.
803–815, 2009.
[38] S. Haykin, Neural Networks: A Comprehensive Foundation, 2nd ed.
London, UK: Prentice Hall, 1999.
[39] R. E. Kalman, “A new approach to linear ﬁltering and prediction
problems,” Trans. ASME J. Basic Eng., vol. 82, pp. 34–45, 1960.
[40] P. S. Maybeck, Stochastic Models, Estimation and Control, ser. Math-
ematics in Science and Engineering, R. Bellman, Ed.
London, UK:
Academic Press Inc., 1979, vol. 141-1.
[41] R. Bellman, Adaptive Control Processes: A Guided Tour.
Princeton,
NJ: Princeton University Press, 1961.
374
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[42] S. J. Julier and J. K. Uhlmann, “A new extention of the Kalman ﬁlter
to nonlinear systems,” in Proc. of AeroSense: The 11th Int. Symp. on
Aerospace/Defence Sensing, Simulation and Controls, 1997.
[43] E. A. Wan and R. van der Merwe, “The unscented Kalman ﬁlter,” in
Kalman Filtering and Neural Networks, ser. Adaptive and Learning Sys-
tems for Signal Processing, Communications, and Control, S. Haykin,
Ed.
John Wiley & Sons, Inc., 2001, ch. 7, pp. 221–280.
[44] M. S. Radenkovic, “Convergence of the generalised dual control algo-
rithm,” Int. J. Control, vol. 47, no. 5, pp. 1419–1441, 1988.
[45] A. D’Amico, G. Ippoliti, and S. Longhi, “A radial basis function
networks apporach for the tracking problem of mobile robots,” in Proc.
IEEE/ASME Int. Conference on Advanced Intelligent Mechatronics,
Como, Italy, 2001, pp. 498–503.
[46] T.-Y. Wang and C.-C. Tsai, “Adaptive trajectory tracking control of a
wheeled mobile robot via Lyapunov techniques,” in Proc. 30th Annual
Conference of the IEEE Industrial Electronics Society, Busan, Korea,
Nov. 2004, pp. 389–394.
[47] Y. Yamamoto, “Control and coordination of locomotion and manipu-
lation of a wheeled mobile manipulator,” Ph.D. dissertation, Univ. of
Pennsylvania, Philadelphia, USA, Aug. 1994.
[48] K. J. ˚Astr¨om and B. Wittenmark, Computer Controlled Systems: Theory
and Design, 3rd ed.
Upper Saddle River, NJ: Prentice Hall, 1997.
[49] K.
B.
Petersen
and
M.
S.
Pedersen.
(2008,
oct)
The
matrix
cookbook.
Version
20081110.
[Online].
Available:
http://www2.imm.dtu.dk/pubdb/p.php?3274
[50] N. M. Filatov and H. Unbehauen, “Survey of adaptive dual control
methods,” Proc. IEE Control Theory Applications, vol. 147, no. 1, pp.
118–128, Jan. 2000.
[51] A. Field, Discovering Statistics using SPSS, 2nd ed. London, UK: Sage
Publications Ltd., 2005.
[52] (2010) maxon motor. [Online]. Available: http://www.maxonmotor.com
[53] (2010) dSPACE. [Online]. Available: http://www.dspaceinc.com
375
International Journal on Advances in Intelligent Systems, vol 3 no 3 & 4, year 2010, http://www.iariajournals.org/intelligent_systems/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

