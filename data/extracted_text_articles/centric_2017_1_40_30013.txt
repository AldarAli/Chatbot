Dynamic Scrutable User Modeling utilizing Machine Learning 
Dima S. Mahmoud 
ADAPT Centre 
School of Computer Science and Statistics, Trinity College Dublin 
Dublin, Ireland 
dima.mahmod@adaptcentre.ie 
 
Abstract— 
Personalization 
generally 
attempts 
to 
offer 
information and services that are delivered to meet user's 
individual preferences. It helps by providing the appropriate 
services in a dynamic and automatic manner. Involving the 
user in this process may enhance how tailored information and 
services are delivered. However, there is a challenge in 
engaging users in the user modeling process. Building user 
models in a manner that engages the user in a feedback cycle 
may improve the quality of the model and the user’s control 
over the personalization. Allowing such user control over 
machine learning-derived user models is a significant research 
challenge as such models are often difficult to scrutinize. This 
is the main challenge addressed in this early stage research. 
This work proposes using ontology-based domain models to 
provide a means for users to engage with ML-derived models. 
Moreover, such an approach may enable the user model scope 
to grow as a user’s preferences grow. 
Keywords-Personalization; 
User 
Modeling; 
Machine 
Learning; Scrutability. 
I. 
 INTRODUCTION 
Personalization has the potential to play an important role 
in supporting the tailoring of system behavior in ways that fit 
each individual user’s preferences. Personalization reduces 
information overload and facilitating targeted access to 
relevant information objects in an information system [1]. 
However, it depends on creating and maintaining an 
adequate set of information about the user’s preferences [2]. 
Generally, personalization is achieved whenever the 
behavior of a system is adjusted by information about the 
user [3]. Postma and Brokke defined personalization as "a 
segmented form of communication that sends (groups of) 
different recipients different messages tailored to their 
individual preferences" [4] and this is the definition adopted 
in this work. A key challenge lies in delivering the right 
information at any time, at any place, while respecting the 
user interests [5]. These interests are continuously evolving 
and changing, generally at a rate that is faster than most 
implicit approaches, which create a user model from 
observed behavior in a system, can keep pace with. 
Capturing the right information about the user at the right 
time in the right way is the main concept of user modeling 
[5][6]. A user model is the collection of personal information 
associated with a specific user. So, it is the fundamental basis 
for any personalization changes to a system. It is also 
potentially a key instrument through which the user can 
adjust and control how a personalization system works for 
them. 
Machine learning has recently attracted much attention 
and has been employed for user modeling [7]. Much research 
is concerned with utilizing machine learning for building 
intelligent user models [8]. Generally, the internet evolution 
was the motivating force underlying the recent surge of 
research in this field [9]. However, the user is not engaged in 
most of these studies leading to models which are difficult to 
represent to a user and nearly impossible for users to control. 
M. E. Muller summarized the idea  in one sentence: 
"machine learning in user modeling tries to mimic a user’s 
behavior, but it does not model a user" [8]. We believe that 
modeling the user, while providing them with control over 
the model, is the main contribution in the work proposed in 
this paper. 
The research outlined in this paper is concerned with 
developing an approach that incorporates dynamic machine 
learning with user scrutability to facilitate effective user 
modeling. The ML processes will operate over a large corpus 
of email messages that will enable the modeling of a variety 
of dimensions of the users in the corpus. There are three 
main aspects under consideration in this study: user 
preferences, 
actionable 
items 
and 
machine 
learning 
techniques. This combination is responsible for building the 
user model, taking into consideration the user’s control over 
the user model. 
This paper is structured as follows: Section II discusses 
the background and related work. Section III states the 
research question and the intended contribution. After that, 
the design of the proposed solution is outlined and the final 
section will state the progress of this work so far.  
II. 
BACKGROUND AND RELATED WORK 
 
This section discusses personalization and user modeling 
in more detail. It then illustrates the relationship between 
them. 
A. Personalization and User Modeling 
A fundamental objective of research in personalization 
and adaptation is to make systems more usable, more useful, 
and to provide users with experiences fitting their specific 
background knowledge and objectives [10]. What is really 
challenging in a world loaded with a large volume of 
information, is not only to make information available at 
anytime, anywhere and in any form, but to precisely specify 
the "right'' thing, at the "right'' time and in the "right'' way.  
Personalization has become of major concern across all 
industries and interest in tailoring customer/user experiences 
has increased significantly [11]. In general, it is hard to have 
18
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

a broader definition of personalization [3]. It is mainly the 
concept of using a user profile that may include personal 
information and sometimes their preferences. Accordingly, 
this has received significant consideration both as a way for 
offering appealing services and locking these users into the 
appropriate services [12].  
Once information is collected about a certain user, the 
system can evaluate that data by a preset analytical algorithm 
and then personalize it to meet the user's needs [13]. This 
adaptation considers every feature of the system's behavior. 
The user profile affects how information and functions are 
displayed. In the case of [13], profiles highlight only relevant 
aspects and hide knowledge that is not needed by the user; 
this is in addition to providing offers and proposals [14].  
There are three main mechanisms for handling system 
personalization. To date, personalization and profile 
modeling have mainly fallen into two categories: explicit and 
implicit techniques [15]. However, the hybrid approach was 
added and followed afterward [2][16]. 
• 
Explicit modeling: In the beginning, the user was the 
main item in the personalization process. It depends 
completely on them to set their personal information 
and manage their interests. Explicit personalization 
may reduce somehow the effort of resource 
management, as well as assuring the data precision 
However, managing an entire preference set 
manually means putting a burden on the user to carry 
out the profile management responsibilities [17]. In 
other words, the user has the mission to update their 
profile whenever a new service is encountered in 
order to refine and update interests in their profile. 
This approach fundamentally engages the user in the 
whole task and places the onus on the user. They set 
their profile manually in order to keep their interests 
up to date (maybe through an appropriate GUI). 
Although in this technique, the user is in charge of 
the whole management process, the responsibility of 
maintaining such potentially large profile is a 
burden. This can often lead to a sparse preference set 
and hence inaccurate personalization [2]. In fact, this 
is the main shortcoming of this mechanism as this 
undermines the strength of personalization.  
• 
Implicit modeling: This approach is considered the 
other extreme in the personalization process. It 
primarily uses various techniques for monitoring and 
learning the user’s preferences without engaging the 
user directly. The system tends to maintain the user 
profile and the preferences set on behalf of the user. 
This depends mainly on the intelligence level of the 
system. This may affect the information accuracy 
and accordingly the environment personalization  
[18]. 
• 
Hybrid implicit and explicit modeling: The learning 
approaches employed by such systems often fall 
under two types: rule-based learning algorithms 
(which store preferences as rules) and network 
algorithms (which store preferences in some network 
structure). Rule-based learning algorithms have the 
advantage that their output is easily translated into a 
human-readable form allowing their knowledge to 
be understood  [16]. 
The benefit of the hybrid approach is the minimal burden 
on the user, however, care must be taken to provide some 
method of user control. Without such functionality, the user 
cannot alter system behavior to reflect new situations or 
behaviors in a rapid way. Therefore, for more successful 
systems, 
hybrid 
personalization 
providing 
implicit 
personalization must be employed where possible, but also 
providing a GUI through which the user can manually 
manipulate their preferences and take final control. 
B. User Models 
Capturing the right thing at the right time in the right way 
is the main concept of user modeling [5][6]. A user model is 
the collection of personal information associated with a 
specific user. So, it is the basis for any personalized changes 
made by a system. 
This research is concerned mainly with saying the "right" 
thing. Selecting which data is used and employed in the 
model depends on the goal of the application and the output 
required. It can include personal information [19] such as 
users' names, ages, their interests, their skills and knowledge, 
their goals and plans, their preferences and their dislikes, or 
data about their behavior and their interactions with the 
system. There are different design patterns for user models, 
though often a mixture of them is used. 
• 
Static user models: Static models are the primary 
type of user models. As the name indicates, the 
model does not change; once data is collected they 
are normally not changed again. Changes in user's 
information do not affect the model and no learning 
algorithms are used to alter the model [5][20]. 
• 
Dynamic user models: Dynamic models allow a 
more active representation of users' preferences. The 
model can dynamically adapt to the different shifts 
in users' interests or their interactions with the 
model. This adaptation helps meeting the different 
needs of the users [5][20][21]. 
• 
Static and Dynamic (SaD) User Models: We can 
easily imagine that SaD as a hybrid modeling 
technique. It can be more common to allow the 
modeler to move from just using a one level standard 
static user model that uses static unchangeable 
information to a more thorough two-level model. 
This combines a static with a dynamic user model 
thus containing user preferences alters and various 
interactions with the system [20]. 
Since user modeling is fundamentally based on personal 
information, user control over the model may bring value, 
particularly when pertinent information about the user may 
not be implicitly observed by the system. Such a model with 
user control mechanisms is described as scrutable model 
[22]. It is designed so that a person has the option, but not an 
obligation, to determine what is modeled about them and 
how it is used. 
Personalization generally aims to unburden the user of 
profile and preferences management tasks, adjusting the 
system to meet the user interests, thus leaning more towards 
19
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

implicit modeling with no user control. Also, in order to 
enhance the interaction between the user and a personalized 
environment, information systems must be capable of 
dynamically personalizing the system content [23]. For this 
reason, many pervasive and ubiquitous systems include 
machine learning techniques coupled with user behavior 
monitoring systems to provide the implicit personalization 
part, where preferences can be created and managed which 
may be coupled with user control (explicit engagement) for 
better results [1][2]. 
III. 
RESEARCH QUESTION AND INTENDED MAIN 
CONTRIBUTIONS 
The ultimate goal of this research is building a dynamic 
scrutable user model while utilizing machine learning. The 
key idea of this work is to merge the three aspects: dynamic 
user modeling, scrutable user modeling, and machine 
learning. We believe that this combination would provide the 
optimum balance between implicit modelling, dynamic 
model growth towards new domains of interest and user 
control. The target is defining an approach to facilitate this 
balance. 
The strategy of this study will start by building a case 
study as shown in Figure 1 - which is discussed in detail later 
- that demonstrates the idea as a proof of concept. Then the 
next step is the evaluation of the approach and presenting the 
results and comparing the results with and without the user 
control and discussing how far the user control over the user 
model affects the results. 
 
 
Figure 1.  Classification model design 
 
The case study has been designed to provide and promote 
to users services that suit their interests with taking in 
consideration the user feedback. We are working on this 
target by exploring large set of user data [24]. This data 
contains important and unimportant information for these 
participants. This work needs to process a very large number 
of facts and capture the vital chunks from it. This selected 
important data indicates each user's likes and dislikes. This 
information then goes through the learning phase in order to 
build a customized user model. The model will be capable of 
selecting the appropriate service for each user. These 
promotions should suit each user preferences.  
The second aspect that plays the main role in this 
research is the system re-learning. In other words, how is 
user control exerted and maintained over the model? How to 
blend the machine learning and user control is envisaged a 
key outcome of this work. 
The other dimension in this research is what these 
services are and how we can feed the model with different 
alternatives for the same subject. We are proposing to use an 
ontology-based domain, which uses terms from a domain 
model to indicate a user’s relationship to different concepts. 
The Domain Model describes how concepts are connected to 
each other defining a semantic relationship between them 
[25][26]. We believe that using this ontology-based approach 
will enrich the system with various substitution potentials. 
This is discussed in detail later in the design section. 
The main data source for this case study was selected to 
enable user profiles to be built from users' email messages. 
This is used to construct the initial user models. These emails 
are rich with personal information: inbox messages, sent 
messages, folders messages, outgoing messages, email 
subject, and time stamps are all used. The privacy of this 
personal data is an important aspect in this context; however, 
this is out of scope as we are using a publicly published 
dataset in this study. 
The crucial research questions here are: 
1) How far can we support the user in controlling and 
improving their user model? 
2) How will we use the user feedback loop for improving 
the model? 
3) How can we prioritize this data in order to get the best 
results of the model? 
4) What is the level of detail in the model that we should 
consider? 
We can observe that our proposed model is founded on 
three dimensions: 1) user modeling using machine learning, 
2) user control, and 3) ontology-based domains as input for 
the model. 
The overarching research question is: How far can we 
merge these three dimensions in order to construct a dynamic 
and controllable user model? 
IV. 
METHODOLOGY AND DESIGN OF THE SYSTEM 
This section discusses the methodology approached in 
this research. Then, it mentions the technologies used in the 
case study. 
A. Methodology 
Generally, building predictive data analytics solutions 
for this kind of problems involves a lot more than choosing 
the right machine learning algorithm. One of the most 
frequently used methodologies for this is the CRoss Industry 
Standard Process for Data Mining (CRISP-DM) [27]. The 
six key steps of the predictive analytics project lifecycle that 
are defined by the CRISP-DM are; problem understanding, 
data understanding, data preparation, Modeling, evaluation, 
and deployment. These steps are expanded in the context of 
this work below. 
 
 
20
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

Step 1: Problem Understanding 
The target is to build a personalized predictive data 
analytics model that provides services to number of users 
according to their general interests. These preferences are 
collected from their email messages. The system can read 
the email documents, build and train a model, and hence 
decide whether this person is interested in a certain topic. 
The emails of participants are explored and scanned in 
order to find topics of interest for a person from his email 
history. Then, email messages are then classified using the 
appropriate machine learning technique.  
Step 2: Data Understanding 
It is critical to find the right data in order to be able to 
solve the problem in hand. In this research, we are working 
on Enron email dataset [24], which will be described later in 
detail. It is a huge dataset that contains about 0.5M 
messages. This step is concerned with selecting the subset 
of all available data that we will be working with. 
There is always a strong desire for including all data that 
is available, that the maxim “more is better” will hold. We 
need to consider what data we really need to address the 
problem in hand. We have to be more disciplined in our data 
selection then handling to achieve more consistent and 
accurate results that are likely to attain. 
Step 3: Data Preparation 
After selecting the data, we needed to study how we are 
going to use the data. This preprocessing phase is mainly 
about getting the selected data into a form that we can work. 
The data preprocessing is divided into three stages; 
formatting, cleaning, and sampling: 
• 
Formatting: We have selected a format that is 
suitable to work with. All the mail messages are now 
in comma separated file format. 
• 
Cleaning: Quality data is a prerequisite for quality 
predictive models. So, to avoid "garbage in, garbage 
out" and improve data quality, we have to work this 
crucial step carefully. Sometimes we find some data 
instances that are incomplete and do not carry the 
data there should be. So, we removed all the records 
of incomplete, noisy, or inconsistent data. In our 
research, there is a mandatory task which is text 
preparation. Text cleaning phase includes stripping 
whitespace, 
removing 
stop 
words, 
numbers, 
punctuation, URLs, and links. 
• 
Sampling: In working on this huge data dataset 
(Enron emails dataset), sampling is an important 
factor that we have to take into consideration at least 
in the early learning stages. We have to experience 
the performance before deciding whether we need to 
carry on this step. We think that we can start with 
working on the whole dataset. If we found out that 
this is inefficient, then we could use a smaller 
representative sample of the selected data. The target 
of this step is to be much faster in exploring and 
prototyping solutions instead of considering the 
whole dataset. 
• 
Data Transformation: This step is also referred to as 
feature engineering. As per the problem we are 
targeting, we are concerned mainly with the text 
included in the data. we are principally working on 
analytics for the text data in the users' email 
messages. Data transformation here is mainly text 
normalization which means converting it to a more 
convenient and standard form. For example, most of 
what we are going to do with language rely on first 
separating out or tokenizing words from running 
tokenization text, the task of tokenization. Another 
part of text normalization is Stemming which refers 
to a simpler version of lemmatization, in which we 
mainly strip suffixes from the end of the word. 
Step 4: Modeling 
The Modeling phase of the CRISP-DM process is when 
the machine learning work occurs. Different machine 
learning algorithms are used to build a range of prediction 
models from which the best model will be selected. The 
knowledge of the problem domain will influence this step 
and we will very likely have to be revisited to achieve the 
optimal solution for the problem in hand. 
Step 5: Evaluation 
This stage covers all the evaluation tasks required to 
show that a prediction model will be able to make accurate 
predictions after being used and that it does not suffer from 
overfitting or underfitting. This step would be clearer 
through different experiments in this research journey as 
this is vague in this stage of study. 
Step 6: Deployment 
Eventually, the last phase of CRISP-DM covers the 
work done to successfully integrate a machine learning 
model into the process within an organization. This phase is 
not applicable in our research. 
The second part of this research is to feed the user model 
with a wide range of words that enriches it and help it for 
better understanding the user. This enhancement will 
improve the prediction accuracy of the model and get better 
results. 
B. Technologies 
• 
Enron Email Dataset 
Enron email dataset was primarily gathered and prepared 
by the CALO Project (Cognitive Assistant that Learns and 
Organizes) [28]. It was formerly posted to the web and 
made public by the Federal Energy Regulatory Commission 
[24]. It includes a huge amount of data. It is corpus for 
about 150 persons, which mostly senior managements of 
Enron. The dataset contains a total of about 0.5M messages 
that are organized into folders.  
There are some modifications done on the original data 
collected. All attachments were removed. Some messages 
have been deleted. The deletion was part of a reduction 
effort that was requested by some employees. There were 
some invalid email addresses converted to something 
21
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

different. For example, when no recipient was specified, 
user@enron.com is converted to no_address@enron.com 
[24]. 
• 
Development  
In this work, we tended to find integrated machine 
learning tools and programming languages. R and Python 
were primarily popped up in our search space due to the 
availability of multiple open source machine learning 
libraries. Python is selected as the core programming 
language 
including 
NumPy, 
SciPy, 
and 
Python 
visualization tools. 
SciKitLearn API is a free software machine learning 
library. It provides an implementation of a wide range of 
machine learning algorithms and data preparation 
methods. SciKitLearn is a simple and efficient tool for 
data mining and data analysis.  It is built on NumPy, 
SciPy, and matplotlib. This is in addition to that it is open 
source and commercially usable (BSD license) [29]. 
V. 
PROGRESS TO DATE AND PLAN OF FURTHER 
RESEARCH 
To build the target user predictive model and to be able 
to evaluate it, we applied the model in a usecase, then we 
divided the journey to number of phases. 
Phase 1: One user only 
This is the current experiment we are working on. The 
target of this part of research is to work on the email dataset 
for one user only and build a model that can predict the 
points of interest for this user.  And at an incoming 
message, the model can predict whether the user would be 
interested in this message or the message needs an action 
from them. And then, it takes the user's feedback and 
retrains the model to enhance its prediction accuracy. The 
early results of this experiment show promising prediction 
accuracy results; however, it still needs more work in the 
evaluation phase to ensure reliable results. 
Phase 2: Classifying the whole dataset  
The next phase is to build a model on the whole dataset, 
the model should be trained on the whole data, and then it 
can classify the users according to their preferences. At an 
incoming message for any of the users, the model could 
predict whether it would be interesting to the user. And 
then, the users' feedback is gathered and employed to retrain 
the classification model. This feedback should enhance the 
model prediction accuracy. 
Phase 3: Providing services from Ontology-based domain 
The last stage of this study will work on the model built 
in the previous step. And then we will try to feed the model 
in a certain domain with words that describe this domain 
(vocabulary alternatives, different subject, etc.). For 
example, if we are concerned with football, we have to 
search for the words football, David Beckham, Manchester 
United, etc. In such case, we will take these words from an 
Ontology concerned with football (DBPedia for example). 
Then, this will feed the model with a big range of words that 
helps it to understand more about the users and hence 
improve the results of the model. 
VI. 
CONCLUSION 
Generally, the main goal of personalizing a system is to 
provide the right information and services to meet user's 
individual preferences. Recently, it has become increasingly 
important to deliver not just the right information, but to do 
so in a highly dynamic way. This makes the environment 
more reliable and tailored to the change in the user 
preferences. The other important feature that this work is 
trying to offer is to incorporate user control in the feedback 
cycle in machine learning-derived user modeling. This has 
an advantage over some classical interpretations of 
personalization. 
In this study, we are employing machine learning 
techniques to achieve this goal. Enabling the user control 
over a machine learning-derived model is a significant 
research challenge. This is the main challenge addressed in 
this early stage of this research. In this paper, we discussed 
this research idea, current plan, and progress to date. 
At this stage of the research there are three core 
concerns. First, to what extent can we support the user in 
controlling and improving the model? Future work will 
require examining user intervention in building a dynamic 
user model using machine learning. 
Secondly, where should the user feedback dimension be 
placed in the modeling cycle? This will involve identifying 
a balance between the model intelligence whilst maintaining 
the scrutability in a machine learning-derived user model. 
The third challenge is concerned with the model 
evaluation and how to evaluate the efficacy, efficiency and 
reliability of the proposed system. 
ACKNOWLEDGMENT 
This research is enhanced by ADAPT Centre at Trinity 
College Dublin. ADAPT Centre for Digital Content 
Technologies is funded under support from Science 
Foundation Ireland (SFI) Research Centres Programme and 
co-funded under the European Regional Development Fund. 
Special thanks to Prof. Owen Conlan for his continuous 
guidance, support, and fruitful advice. 
REFERENCES 
[1] C. Niederée, A. Stewart, B. Mehta, and M. Hemmje, “A 
multi-dimensional, unified user model for cross-system 
personalization,” in Proceedings of the AVI 2004 Workshop 
on Environments for Personalized Information Access, 2004, 
pp. 34–54. 
[2] S. McBurney, N. Taylor, H. Williams, and E. Papadopoulou, 
“Giving 
the 
user 
explicit 
control 
over 
implicit 
personalisation,” in Procs. of Workshop on Intelligent 
Pervasive 
Environments 
(under 
AISB’09), 
Edinburgh, 
Scotland, 2009. 
[3] D. Ralph and S. Searby, Location and personalisation: 
delivering online and mobility services, vol. 8. IET, 2004. 
22
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

[4] O. J. Postma and M. Brokke, “Personalisation in practice: The 
proven effects of personalisation,” J. Database Mark. Cust. 
Strateg. Manag., vol. 9, no. 2, pp. 137–142, 2002. 
[5] G. Fischer, “User modeling in human--computer interaction,” 
User Model. User-adapt. Interact., vol. 11, no. 1, pp. 65–86, 
2001. 
[6] A. D. A. Daniela Petrelli and G. Convertino, “A User-
Centered Approach to User Modeling,” in UM99 User 
Modeling: 
Proceedings 
of 
the 
Seventh 
International 
Conference, 2014, vol. 407, p. 255. 
[7] M. E. Müller, “Learning scrutable user models,” 2002. 
[8] M. E. Muller, “Can user models be learned at all? Inherent 
problems in machine learning for user modelling,” Knowl. 
Eng. Rev., vol. 19, no. 1, pp. 61–88, 2004. 
[9] D. Billsus and M. J. Pazzani, “User modeling for adaptive 
news access,” User Model. User-adapt. Interact., vol. 10, no. 
2–3, pp. 147–180, 2000. 
[10] Y. Yang, M. H. Williams, L. M. MacKinnon, and R. Pooley, 
“A service-oriented personalization mechanism in pervasive 
environments,” in Web Intelligence, 2005. Proceedings. The 
2005 IEEE/WIC/ACM International Conference on, 2005, pp. 
132–135. 
[11] D. Buhalis and A. Amaranggana, “Smart tourism destinations 
enhancing tourism experience through personalisation of 
services,” in Information and Communication Technologies in 
Tourism 2015, Springer, 2015, pp. 377–389. 
[12] O. Conlan, A. Staikopoulos, C. Hampson, S. Lawless, and I. 
O’keeffe, “The narrative approach to personalisation,” New 
Rev. Hypermedia Multimed., vol. 19, no. 2, pp. 132–157, 
2013. 
[13] I. O’Keeffe et al., “Personalized activity based eLearning,” 
Proc. 12th Int. Conf. Knowl. Manag. Knowl. Technol. - i-
KNOW ’12, p. 1, 2012. 
[14] A. F. Monk and J. O. Blom, “A theory of personalisation of 
appearance: quantitative evaluation of qualitatively derived 
data,” Behav. Inf. Technol., vol. 26, no. 3, pp. 237–246, 2007. 
[15] H. Fan and M. S. Poole, “What is personalization? 
Perspectives 
on 
the 
design 
and 
implementation 
of 
personalization in information systems,” J. Organ. Comput. 
Electron. Commer., vol. 16, no. 3–4, pp. 179–202, 2006. 
[16] D. Godoy and A. Amandi, “User profiling in personal 
information agents: a survey,” Knowl. Eng. Rev., vol. 20, no. 
4, pp. 329–361, 2005. 
[17] T. Joerding, “A temporary user modeling approach for 
adaptive shopping on the Web,” in Proceedings of Second 
Workshop on Adaptive Systems and User Modeling on the 
World Wide Web, Toronto and Banff, Canada. Computer 
Science Report, 1999, pp. 7–99. 
[18] E. Rich, “Users are individuals: individualizing user models,” 
Int. J. Man. Mach. Stud., vol. 18, no. 3, pp. 199–214, 1983. 
[19] A. Kobsa, “Generic user modeling systems,” User Model. 
User-adapt. Interact., vol. 11, no. 1, pp. 49–63, 2001. 
[20] J. Hothi and W. Hall, “An evaluation of adapted hypermedia 
techniques using static user modelling,” in Proceedings of the 
second workshop on adaptive hypertext and hypermedia, 
1998, pp. 45–50. 
[21] M. A. Girolami and A. Kabán, “Simplicial Mixtures of 
Markov Chains: Distributed Modelling of Dynamic User 
Profiles.,” in NIPS, 2003, vol. 16, pp. 9–16. 
[22] M. Assad, D. Carmichael, J. Kay, and B. Kummerfeld, 
“PersonisAD: Distributed, active, scrutable model framework 
for context-aware services,” Pervasive Comput., pp. 55–72, 
2007. 
[23] A. Staikopoulos et al., “AMASE : A Framework for 
Composing Adaptive and Personalised Learning Activities on 
the Web,” pp. 190–199, 2012. 
[24] W. W. Cohen, “Enron Dataset,” 2015. [Online]. Available: 
https://www.cs.cmu.edu/~./enron/. [Accessed: 12-Jun-2017]. 
[25] J. Ahn, P. Brusilovsky, D. He, J. Grady, and Q. Li, 
“Personalized web exploration with task models,” in 
Proceedings of the 17th international conference on World 
Wide Web, 2008, pp. 1–10. 
[26] P. De Bra, G. Houbeny, and H. Wu, “AHAM: A Dexterbased 
Reference 
Model 
for 
Adaptive,” 
in 
Hypermedia". 
Proceedings of the ACM Conference on Hypertext and 
Hypermedia, 2009. 
[27] J. D. Kelleher, B. Mac Namee, and A. D’Arcy, 
“Fundamentals of Machine Learning for Predictive Data 
Analytics.” MIT Press, 2015. 
[28] “The 
PAL 
Framework.” 
[Online]. 
Available: 
https://pal.sri.com/. [Accessed: 12-Jun-2017]. 
[29] F. Pedregosa and G. Varoquaux, “Scikit-learn: Machine 
learning in Python,” … Mach. Learn. …, vol. 12, pp. 2825–
2830, 2011. 
 
 
23
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-592-0
CENTRIC 2017 : The Tenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

