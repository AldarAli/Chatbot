 
 
Literature Review of Ethical Concerns in the Use of Disruptive Technologies in 
Government 3.0 
Alexander Ronzhyn 
University of Koblenz-Landau, 
Universitätsstr. 1, 56070 Koblenz, Germany 
Nationales E-Government Kompetenzzentrum e.V., 
Schiffbauerdamm 40 – 10117 Berlin, Germany 
e-mail: ronzhyn@uni-koblenz.de 
Maria A. Wimmer 
University of Koblenz-Landau, 
Universitätsstr. 1, 56070 Koblenz, Germany 
Nationales E-Government Kompetenzzentrum e.V., 
Schiffbauerdamm 40 – 10117 Berlin, Germany 
e-mail: wimmer@uni-koblenz.de 
 
 
Abstract— ‘Government 3.0’ as the new paradigm brings in new 
disruptive technologies in the digitization process of the public 
sector.  The massive use of Artificial Intelligence, Machine 
Learning, Big Data Analytics, Internet of Things and other 
technologies in public service provisioning that have a potential 
to significantly influence the life of a large number of citizens 
demands for a thorough investigation of the ethical concerns. 
Along a literature review, this paper investigates the ethical 
issues associated with the implementation of disruptive 
technologies in the public sector. In the first part of the paper, 
ten categories of ethical concerns in e-government are identified. 
Subsequently, these ten categories guide a more detailed review 
of 74 articles dealing with specific ethical concerns in relation to 
the implementation of Artificial Intelligence and Big Data in e-
government. The literature review revealed important 
similarities and differences in ethical issues relating to the two 
technologies. 
Keywords-ethics, government 3.0, e-government, disruptive 
technologies. 
I. 
 INTRODUCTION 
The discussion of ethics should be an integral part of e-
government research, in particular when new disruptive 
technologies are to be deployed. Often however, ethical 
considerations are relegated to the “Discussion” or “Future 
research” sections of the papers. This paper therefore studies 
existing literature on ethics in e-government. Furthermore, 
ethical implications of the introduction of new disruptive 
technologies in e-government are identified. 
Ethics has been defined as “the art of living well” by 
Aristotle (cited in [1]) and has been one of the most discussed 
philosophical concept ever since [2]. Treviño et al. define 
ethical behavior as “doing the right thing, showing concern 
for people and treating people right, being open and 
communicative, and demonstrating morality in one’s personal 
life” [3, pp. 131–132]. Ethics in government refers to ethical 
behavior and to the approach of organizing the processes and 
rules of governance in a way that shows concern for citizens, 
is transparent and accountable (cf. good governance principles 
[4]).  
Discussion of ethics in e-government lies on the 
intersection of the areas of the ethics in government and the 
Information and Communication Technologies (ICT) ethics. 
In his paper of 1986, Anderson identified four major ethical 
issues in ICT: privacy, accuracy, property and accessibility 
[5]. More than thirty years later these issues are even more 
important and contentious than at the dawn of the Internet era, 
for several reasons (particularly in regards to e-government): 
firstly, the relationship between the government and a citizen 
is unequal one: citizen is dependent and vulnerable [6]; 
secondly, ICTs have an effect on public values, and their 
transformative potential should be also viewed in this 
dimension [7][8]; thirdly, the landscape of the public sphere is 
different from the private sphere as the ultimate aims of the 
organizations involved are very different [9]. 
This paper studies the subject of ethical implementation of 
e-government and the ethical introduction and use of the ICTs 
in public sphere, while we do not discuss questions of ethical 
decision-making by individual officials in government. The 
research is a part of the Erasmus+ Gov 3.0 project 
(https://www.gov30.eu), 
which 
aims 
to 
establish 
Government 3.0 as a research domain. The project team 
defines Government 3.0 as follows: 
Government 3.0 refers to the use of new disruptive ICTs 
(such as blockchain, big data and artificial intelligence 
technologies), in combination with established ICTs (such 
as distributed technologies for data storage and service 
delivery) and taking advantage of the wisdom of crowd 
(crowd/citizen-sourcing and value co-creation), towards 
data-driven and evidence-based decision and policy 
making. [10, p.2] 
The Gov 3.0 project identifies and describes new 
technologies, trends and concepts associated with the 
Government 3.0 paradigm. Some of these technologies are 
termed “disruptive” as they are likely to have significant 
impact on how e-government will be shaped in the future. 
Along the project, the authors conducted several workshops 
discussing the Government 3.0 concept and the use of 
disruptive technologies in public spheres. Ethical issues were 
one of the most discussed topics along these workshops. Yet 
despite ethics being one of the biggest concerns of academics 
along the implementation of new technologies, no systematic 
review of literature on ethics in e-government has been found. 
In this paper, we therefore investigate ethics in the implemen- 
tation of the most significant disruptive technologies, namely 
Artificial Intelligence (AI) and Big Data.  
The structure of the paper is as follows: Section II presents 
the research methodology of the paper and outlines the 
research questions, Section III presents results of the literature 
review of the ethical considerations in e-government, 
85
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
identifying main ethical themes in the research. In Section IV, 
we present the results of the literature review of the ethical 
issues concerning AI and Big Data use in Government 3.0. 
Section V discusses the results of the literature review and 
concludes with an outlook on future research on ethics in e-
government and by reflecting the limitations of the paper.  
II. 
METHODOLOGY 
The aim of the paper is to scope the understanding of 
ethics in e-government and spotting the needs for ethical 
considerations in Government 3.0, specifically with new 
disruptive technologies and technological trends. The paper is 
descriptive and based on a systematic literature review. 
Three research questions guide this research: 
1. 
What are the main ethical considerations within the 
e-government domain? 
2. 
What ethical issues can be identified concerning the 
implementations of AI and Big Data within e-government? 
3. 
What are the research needs concerning ethical 
issues of disruptive technologies in e-government? 
Following Kitchenham and Charters [11], the articles were 
collected 
from 
the 
four 
databases: 
SpringerLink 
(http://link.springer.com/), 
IEEE 
Xplore 
(http://ieeexplore.ieee.org/Xplore/), ACM (http://dl.acm.org/) 
and DGRL (V. 14, only for the first stage). The search was 
carried out in autumn 2018. Search was restricted to the title 
and abstract of the papers and was with the search string: 
“ethics AND (‘digital government’ OR ‘e-government’)”. 
This allowed identifying main ethical considerations and 
themes in e-government, presented in Section III. Reviewing 
the results of the searches ensured that chosen papers focus on 
ethical issues, i.e., papers that did not include ethical issues as 
a main or at least a secondary topic, were not published in a 
peer-reviewed journal or conference proceeding or were not 
accessible in full-text were excluded (exclusion criteria). 
For the second stage, literature on ethical issues of the 
specific technologies was searched and reviewed. The search 
strings “AI | Artificial Intelligence | Big Data AND (‘ethical 
issues’ OR ‘ethics’)” were used, resulting initially in 645 
references. After the exclusion criteria were applied, 74 papers 
were left (27 AI, 47 Big Data papers). First exclusion was 
made after examining metadata of the articles, while the 
second exclusion was based on full-text scans of the articles. 
Out of the remaining papers, we extracted ethical issues 
applicable to the use of these technologies in e-government.  
To analyze ethics aspects specifically related to the 
disruptive technologies, we used the concept-centric approach 
suggested by Webster and Watson [12]. For example, the list 
of broad ethical themes resulting from the first review cycle 
of ethics was used to codifying the presence or absence of the 
theme in each paper on ethics in AI and Big Data. The results 
of this literature review are described in Section IV.  
III. 
ETHICS IN E-GOVERNMENT 
Literature review identified 22 articles focusing on ethics 
in e-government. Table I lists the ten ethical considerations in 
e-government along with the literature. Subsequently, we 
summarize the main aspects of these ethical considerations.  
 
TABLE I.  
ETHICAL CONSIDERATIONS IN E-GOVERNMENT 
Ethical considerations in  
e-government 
Articles reviewed 
Inclusivity 
[6], [7], [9], [13]–[18] 
Privacy 
[6], [16], [17], [19]–[25] 
Data use 
[6], [21], [24], [26] 
Quality/ Accuracy of information 
[9], [23], [25] 
Transparency 
[7] 
Accountability 
[19], [27] 
Information ownership 
[20], [23] 
Trust  
[6], [7], [9], [19], [23], [28] 
Alignment of values 
[13], [17], [23], [29], [30] 
Cost 
[6], [16], [25] 
Inclusivity refers to the concern about the inability of some 
groups of citizens to make use of the digital government 
services. It is discussed in the context of the digital divide 
either within a society or between countries. Most common 
factors causing digital divide are disparity in access to 
technology, wealth, education or age-related differences [14]. 
Inclusivity is a significant concern as in some cases e-
government services are replacing the traditional ways to 
interact with the government, so citizens who are unable to 
use the new services are put in significant disadvantage. 
Privacy is the concern about the unauthorized or 
inappropriate use of individual information by the government 
or other actors. Privacy is the most discussed ICT-related 
ethical issue, especially after the advent of social media and 
large-scale personal data collection [31]. 
Data use refers to the concern about inappropriate use of 
collected data. This includes for example the aggregation of 
data from different sources to infer new information or to de-
anonymize individual citizens. This is not a new issue [32], 
however with the increase of the amount of data about any 
particular person, cross-referencing different databases has 
become a significant concern, threatening citizens’ privacy. 
Concerns on quality and accuracy of information relate to 
the imperfect digitalization of certain data in the transition to 
digital services. Data errors or incomplete information in 
databases may result in additional costs for a citizen [25]. 
Transparency is a concern that certain processes in e- 
government may become black boxes, impossible to 
understand by individual citizens. Lack of transparency may 
lead to the inequality of treatment, when certain decisions are 
made using invisible decision processes based on data only 
available to the system [24].  
Accountability is related to transparency and concerns the 
responsibility of government toward an individual citizen in 
case of problems with or misuse of the digital government 
system. Accountability is necessary to improve citizen trust in 
e-government [33].  
Information ownership is about the possibility of the 
digital government system’s user to change or restrict access 
to one’s own information. It also concerns the re-use of certain 
information from the e-government systems by the third 
parties [34][35]. 
Trust is a general consideration of the effect that the 
automatization (and associated de-humanization) of the 
government services may have on an individual citizen. It also 
encompasses the issues of government control and 
surveillance [7][31].  
86
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
Alignment of values refers to the mismatch between the 
values of the government and the citizens. Sometimes 
motivation of the government to introduce digital services 
(e.g. cutting costs, improving efficiency) may not be aligned 
with the interests of the citizens, who value accountability and 
inclusivity of the services [6][16]. This concern is connected 
to the inclusivity and trust concerns. The discussion of values 
in this context also touches on the differences of attitudes to 
the free speech versus security dilemma [17][36] and the 
difference between values across countries, i.e., imposing 
western values in the developing countries [13]. 
Cost consideration refers not only to the financial cost of 
implementing and running the digital government services but 
also trade-offs for the citizens, associated with the 
implementation of e-government services: ensuring inclusive 
access to government services may increase the workload for 
the civil servants and thus the cost of public services [6].  
IV. 
ETHICAL ISSUES IN GOVERNMENT 3.0 
The second stage of the literature review identifies specific 
ethical issues related to the new disruptive technologies AI 
and Big Data in e-government. The issues are categorized 
along the 10 ethical considerations identified in Section III.  
A. Artificial Intelligence 
The use of AI in government is expected to increase as 
well as the significance of its effects on issues with moral 
component [37][38]. Literature distinguishes between 
‘Artificial Intelligence’ (AI) and ‘Artificial General 
Intelligence’, A(G)I. “AI in e-government” refers to the use of 
elements of artificial intelligence to facilitate some of the 
services and processes, while A(G)I relates to autonomous 
decision-making and AI-supported robots in the society in 
future [39]. While the latter has implication for government as 
well [37], it is not part of our current investigations, as we 
focus on current implementations of AI in e-government. 
TABLE II.  
ETHICAL CONSIDERATIONS OF AI IN E-GOVERNMENT 
Ethical consideration in  
e-government 
Supporting literature 
Inclusivity 
[40]–[45] 
Privacy 
[45]–[49] 
Quality/ Accuracy of 
information 
[46] 
Transparency 
[37], [47] 
Accountability 
[37], [45], [47]–[52] 
Information ownership 
[53] 
Trust  
[37], [40], [47], [54], [55] 
Alignment of values 
[37], [42], [44]–[48], [53], [55]–[60] 
Cost 
[41], [42], [48], [61], [62] 
 
Of the literature reviewed, 27 papers (Table II) are dealing 
with ethical issues in the application of AI. Most common 
categories of the ethical concerns mentioned are values (14), 
accountability (9), privacy (8), inclusivity (6) and cost (6). In 
most of the cases, the issues relate to the AI-assisted Big Data 
use for decision making (both autonomous by AI or AI-
assisted). The most common ethical issues in each category 
are described below. 
 
1) Major issues  
Accountability: The concerns of this category relate to the 
automated decision-making by AI systems. Who is 
responsible or liable for AI making a bad decision (ethically, 
legally or otherwise)? This is a significant concern in private 
sector (especially relating to the autonomous vehicles), but 
also a huge issue in government, where decisions can have 
implications on a very large scale [52]. Thus the question of 
liability should not be only discussed when implementing the 
decision-making systems but also be explicitly addressed in 
laws [50][51]. 
Value alignment: while the decisions made by the 
autonomous AI systems should be ideally based on hard data, 
there is a concern that such decisions might not be objective 
[48]. What values should be programmed into the AI making 
complex data-based decisions is an open question [50][59]. 
For simple decisions, rules may be straightforward. For some 
other, choosing between two sub-optimal options may amount 
to the value judgment [55]. Ensuring transparency and 
providing sufficient discussions of such algorithms may help 
address such concerns [55][56].  
Privacy: Ethical concerns include using AI for surveil-
lance [45], for profiling [46] and the leakage of personal data 
(especially in sensitive settings like healthcare) [48][49]). 
Inclusivity: AI may also increase inequality between those 
who control AI and other people [44][45]. The effect of AI on 
the society needs to be studied to ensure inclusive realization 
with respect to human rights [40][42][43]. 
Cost: AI can be a costly endeavor, especially in regard to 
indirect costs: the increase of automation and move towards 
automated decision-making is forecast to lead to a profound 
shift in the structure of the labor market [42][48][61]. Brandy 
argues that changes may affect public services twofold: 
directly, when some public officials will lose their jobs as 
services will be automated; and indirectly, when the increase 
in unemployment will lead to the increasing pressure on the 
public sector [62].   
2) Minor issues 
Transparency: AI systems need to be able to "explain" 
why a certain decision has been made [37]. 
Trust: There is an issue of trust towards autonomous or AI-
assisted decisions [40][55], especially in sensitive settings like 
healthcare [54]. 
B. Big Data 
Big Data already plays an important role in many 
domains, for example: disaster management [63], healthcare 
[64][65], food security [66], law enforcement [67] and smart 
cities [68]. In some cases, Big Data is used for automated 
decision making, sometimes in conjunction with AI [69]. 
Ethics and ethical issues emerged as one of the important 
topics in the Big Data literature review by Lu and Liu [70] 
appearing in 97 of the collected sources. Other major topics 
included healthcare applications of Big Data and privacy 
(which was the fourth most prominent topic related to Big 
Data overall, trailing only behind technology-related 
keywords). 
87
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
The review identified 47 papers dealing with ethical 
issues in Big Data as shown in Table III. Most named ethical 
concerns are privacy (40), data ownership (10), data accuracy 
(9), values (9), data use (6) and inclusivity (6). The 
descriptions of these ethical concerns along Big Data use in 
e-government follow below. 
TABLE III.  
ETHICAL CONSIDERATIONS OF BIG DATA IN E-
GOVERNMENT 
Ethical consideration in e-
government 
Supporting literature 
Inclusivity 
[67], [69], [71]–[74] 
Privacy 
[34], [48], [65], [67], [71]–[106] 
Data use 
[77], [79], [86], [90], [107], [108] 
Quality/ Accuracy of 
information 
[65], [77], [95]–[97], [99], [100], 
[102], [109] 
Transparency 
[74], [81], [110] 
Accountability 
[48], [74], [75], [110] 
Information ownership 
[34], [48], [69], [71], [78], [85], 
[97], [98], [106], [111] 
Trust  
[95], [105] 
Alignment of values 
[34], [48], [77], [81], [91], [94], 
[102], [107], [109] 
Cost 
[48], [65], [95], [98], [103] 
 
1) Major issues: 
Privacy: The main concern about Big Data is the ever-
increasing amount of personal information collected 
[34][82], often without the subjects being aware of that 
collection [90]. Even with de-personalised information there 
is a significant concern about the cross-reference of data 
between different datasets to identify the anonymised 
individuals 
[76][80][112]. 
Given 
large 
amounts 
of 
information collected and the improvements in Big Data 
Analytics and Machine Learning technologies, it is very 
difficult to guarantee full anonymity of data [78][96]. In the 
government context, this concern is connected to the worry 
about the surveillance state, when government "knows 
everything" [88][104]. The benefits of the use of Big Data for 
security and surveillance needs to be balanced against 
personal freedom and privacy, otherwise it may lead to 
significant erosion of trust towards government [100][101]. 
Data ownership: Organisations involved in data collection 
(e.g. social media companies [113]) may accumulate very 
large amounts of personal data. While the data may include 
identifiable and potentially sensitive information, it does not 
actually belong to the person: often individuals do not even 
know what kind of information is collected about them 
[90][106]. Ethical concerns regard making use of personal 
data by organisations for their own benefit (or even for the 
benefit of society), without explicit consent from individuals 
[48][85]. 
Data accuracy: in e-government contexts, the collected 
data can be used for decision making or provision of 
personalised 
e-government 
services. 
Inaccurate 
or 
incomplete data can lead to erroneous or biased decisions 
[95][100][102]. These issues are more significant in the 
public sector, as citizens cannot always opt-out of a service 
and potential harm from incorrect data can be larger [109].  
Data use: data misuse is a concern about the use of citizen 
data for purposes other than ones, for which an explicit 
consent has been given [86][90][108] or a legal ground exists. 
However, in a dynamically evolving field of e-government it 
may not be easy to predict every possible scenario, in which 
the data might be used. A balance should be found for ethical 
use of data, which would still allow creating innovative 
public services [79][107]. 
Alignment of values: similar to the issues discussed in AI, 
the use of Big Data may lead to the conflict between the 
values of the government and citizens: between individual 
and public good [81][94]. It is also necessary to consider the 
implications of the decisions based on the biased Big Data for 
the societal stability [48][102]. 
2) Minor issues 
Inclusivity: there is a certain risk of the discrimination 
based on the dataset used. This can lead to stigmatisation 
[72], wrong identification in criminal cases [67] and 
increasing digital divide [71]. 
Transparency and accountability: in public sector it is 
important to indicate when and how the data is collected and 
for what purposes is it used [74][92], while the algorithm 
creators need to be accountable for their product [48][110]. 
Trust: improper management of data may lead to the 
issues with citizen trust towards government. Data 
management becomes an important concern for the agencies 
dealing with Big Data, requiring skills and effort [95][105]. 
Costs: there are cost issues related to the storage and 
processing of Big Data. By definition Big Data requires 
significant resources that need to be diverted from elsewhere. 
Implementing Big Data-based decision making systems, it is 
necessary to assess the possible trade-offs [48][65][98].  
V. 
DISCUSSION AND CONCLUSIONS 
Deploying disruptive technologies in public services 
brings new ethical challenges that need to be addressed by the 
researchers and practitioners of e-government. From the 
literature research, we extracted ten ethical considerations 
that should be carefully reflected along each project aiming 
at deploying disruptive technologies in e-government. 
Ensuring that the implementation of new services properly 
addresses the inclusivity, privacy, data use, data accuracy, 
accountability, ownership, trust, alignment of values and cost 
concerns will help to move towards more responsible design 
and implementation of the new Government 3.0 paradigm. 
This research provides a description of ethical issues in AI 
and Big Data along the ten ethical considerations. Ethical 
concerns in the use of AI relate mostly to the accountability 
of autonomous decision-makers (who is accountable for AI 
making wrong decision?) and value alignment (what will be 
the basis for AI decisions?). Privacy and inclusivity are other 
important issues. 
In Big Data, the main concern is privacy: what data should 
be collected and for what purposes? Information ownership 
and consent are important ethical issues as well. There is a 
significant worry about the improper use of Big Data for 
88
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
surveillance, there is an apparent need for ethical discussion 
regarding the limits of data collection and balancing the 
benefits of Big Data with its drawbacks. 
Finally, the need for legal frameworks and regulation of 
the use of disruptive technologies arises in both, AI and Big 
Data ethical discussions [37][51][85][95]. 
Kidder [114] argues that ethical responsibilities increase 
with the increase of potential harm resulting from an unethical 
decision. Both AI and Big Data offer significant benefits for 
public sector, at the same time having considerable potential 
for misuse. With the widespread use of ICTs by the 
governments and digital transformation of governance 
processes, main ethical concerns shift from the individual 
decision-making by government officials to the discussion of 
ethical implementation and management of ICTs and tools in 
public sector. 
Therefore, further research is needed to provide adequate 
frameworks along the introduction of disruptive technologies 
in e-government, which help to provide answers to the ethical 
considerations described in Sections III and IV guiding 
researchers and practitioners in the assessment of ethics. 
Further empirical and theoretical research is necessary to 
address the issues arising from the implementation of 
disruptive technologies and provide a basis for drafting legal 
framework regulating these technologies. 
Future research should also assess ethics in the 
implementation of other disruptive technologies identified as 
a part of the Government 3.0 paradigm [115] (e.g., 
Augmented and Virtual Reality (see [116] for a discussion of 
ethical challenges), Internet of Things, Blockchain, etc.). 
Limitations of the research conducted in this paper may be 
imposed by the methodology chosen: some relevant papers 
dealing with ethical issues may have been excluded if they had 
no “ethics/ ethical issues” in their title or abstract. Likewise, 
there are some papers that might not be in any of the databases 
used for the literature review, but still contain valuable 
information. A more extensive literature review is needed to 
overcome these limitations. Despite these limitations, we are 
confident that the literature review presented here is 
representative enough to provide valuable insights in the 
ethical issues in e-government and provide useful outline of 
the future research directions. 
ACKNOWLEDGMENT 
This research is developed in the context of the Gov 3.0 
Project. It was funded by the Erasmus+ Knowledge Alliance, 
Project Reference No. 588306-EPP-1-2017-1-EL-EPPKA2-
KA. 
REFERENCES 
[1] E. M. Hartman, “Socratic questions and aristotelian answers: 
A virtue-based approach to business ethics,” J. Bus. Ethics, vol. 
78, no. 3, pp. 313–328, 2008. 
[2] D. Guttmann, Ethics in social work: A context of caring. 
Routledge, 2013. 
[3] L. K. Treviño, L. P. Hartman, and M. Brown, “Moral Person 
and Moral Manager: How Executives Develop a Reputation for 
Ethical Leadership,” Calif. Manage. Rev., vol. 42, no. 4, pp. 
128–142, 2000. 
[4] OECD, OCDE, “The OECD principles of corporate 
governance,” Contaduria y Adm., no. 216, pp. 183–194, 2004. 
[5] R. O. Mason, “Four Ethical Issues of the Information Age,” 
MIS Q., vol. 10, no. 1, pp. 5–12, 1986. 
[6] J. B. Berger, “Coercive E-Government Policy Imposing Harm: 
The Need for a Responsible E-Government Ethics,” Proc. 49th 
Hawaii Int. Conf. Syst. Sci., pp. 2830–2839, 2016. 
[7] F. Bannister and R. Connolly, “ICT, public values and 
transformative government: A framework and programme for 
research,” Gov. Inf. Q., vol. 31, no. 1, pp. 119–128, 2014. 
[8] L. Royakkers, J. Timmer, L. Kool, and R. van Est, “Societal 
and ethical issues of digitization,” Ethics Inf. Technol., vol. 20, 
no. 2, pp. 127–142, 2018. 
[9] H. Mullen and D. S. Horner, “Ethical Problems for e-
Government: An Evaluative Framework,” Electron. J. e-
Government, vol. 2, no. 3, pp. 187–196, 2004. 
[10] G. V. Pereira et al., “Scientific foundations training and 
entrepreneurship activities in the domain of ICT-enabled 
governance,” in Proc. 19th Annu. Int. Conf. dg.o ’18, pp. 1–2. 
[11] B. Kitchenham and S. Charters, “Guidelines for performing 
Systematic Literature reviews in Software Engineering 
Version 2.3.,” EBSE, UK, 2007. 
[12] J. Webster and R. T. Watson, “Analyzing the past to prepare 
for the future,” MIS Q., pp. xiii–xxiii, 2002. 
[13] S. Basu, “Digital Divide, Digital Ethics, and E-government,” 
in ICTs in Developing Countries, London: Palgrave Macmillan 
UK, 2016, pp. 161–169. 
[14] E. Mordini et al., “Senior citizens and the ethics of e-
inclusion,” Ethics Inf. Technol., vol. 11(3), pp. 203–220, 2009. 
[15] E. Easton-Calabria and W. L. Allen, “Developing ethical 
approaches to data and civil society: from availability to 
accessibility,” Innovation, vol. 28(1), pp. 52–62, 2015. 
[16] B. N. Fairweather and S. Rogerson, “Towards morally 
defensible e-government interactions with citizens,” J. Inf., 
Commun. Ethics Soc., vol. 4(4), pp. 173–180, 2006. 
[17] N. Kapucu, “Ethics of Digital Government,” in Encyclopedia 
of Digital Government, A.-V. Anttiroiko and M. Malkia, Eds. 
IGI Global, 2007, pp. 745–748. 
[18] J. W. Weiss, G. J. Gulati, D. J. Yates, and L. E. Yates, “Mobile 
broadband affordability and the global digital divide - An 
information ethics perspective,” Proc. HICSS, vol. 2015–
March, pp. 2177–2186, 2015. 
[19] J. Lodge, “The dark side of the moon: Accountability, ethics 
and new biometrics,” in Second generation biometrics: The 
ethical, legal and social context, Springer, 2012, pp. 305–328. 
[20] R. Heersmink, J. van den Hoven, N. J. van Eck, and J. den van 
Berg, “Bibliometric mapping of computer and information 
ethics,” Ethics Inf. Technol., vol. 13(3), pp. 241–249, 2011. 
[21] R. Domanski, E. Estevez, E. Styrin, M. Alfano, and T. M. 
Harrison, “Toward an ethics of digital government,” Proc. 19th 
Annu. Int. Conf. dg.o ’18, pp. 1–4, 2018. 
[22] I. Büschel, R. Mehdi, A. Cammilleri, Y. Marzouki, and B. 
Elger, “Protecting Human Health and Security in Digital 
Europe: How to Deal with the ‘Privacy Paradox’?,” Sci. Eng. 
Ethics, vol. 20(3), pp. 639–658, 2014. 
[23] G. Kaisara and S. Pather, “Relevance of Ethics in e-
Government: An Analysis of Developments in the WWW era,” 
in Proceedings of the 6th International Conference on E-
Government, 2010, pp. 45–53. 
[24] P. Henman, “E-Government, Targeting and Data Profiling,” J. 
E-Government, vol. 2, no. 1, pp. 79–98, Dec. 2005. 
[25] R. E. Anderson, “Ethics and Digital Government,” in Digital 
89
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
Government: Principles and Best Practices, 2004. 
[26] D. Goroff, J. Polonetsky, and O. Tene, “Privacy Protective 
Research: Facilitating Ethically Responsible Access to 
Administrative Data,” Ann. Am. Acad. Pol. Soc. Sci., vol. 
675(1), pp. 46–66, 2018. 
[27] P. Henman, “E-Government, Targeting and Data Profiling,” J. 
E-Government, vol. 2(1), pp. 79–98, Dec. 2005. 
[28] G. Sharma, X. Bao, and L. Peng, “Public Participation and 
Ethical Issues on E-governance: A Study Perspective in 
Nepal,” Electron. J. e-Government, vol.12(1), pp. 82–96, 2014. 
[29] E. Wihlborg, H. Larsson, and K. Hedström, “‘The computer 
says no!’ - A case study on automated decision-making in 
public authorities,” Proc. HICSS, vol. 2016–March, pp. 2903–
2912, 2016. 
[30] A. V. Roman, “Framing the Questions of E-Government 
Ethics: An Organizational Perspective,” Am. Rev. Public Adm., 
vol. 45(2), pp. 216–236, 2015. 
[31] F. Belanger and J. S. Hiller, “A framework for e-government: 
Privacy implications,” Bus. Process Manag. J., vol. 12(1 
SPEC. ISS.), pp. 48–60, 2006. 
[32] R. O. Mason, “Four Ethical Issues of the Information Age,” 
MIS Q., vol. 10(1), pp. 5–12, 1986. 
[33] E. W. Welch, C. C. Hinnant, and M. J. Moon, “Linking citizen 
satisfaction with e-government and trust in government,” 
Journal of Public Administration Research and Theory, pp. 
371–391. 2005. 
[34] L. Voronova and N. Kazantsev, “The Ethics of Big Data: 
Analytical Survey,” in 2015 IEEE 17th Conf. on Business 
Informatics, 2015, pp. 57–63. 
[35] R. Heersmink, J. van den Hoven, N. J. van Eck, and J. den van 
Berg, “Bibliometric mapping of computer and information 
ethics,” Ethics Inf. Technol., pp. 241–249, 2011. 
[36] G. A. Sandy, “Mandatory ISP filtering for a clean feed to 
australian internet subscribers,” 15th Am. Conf. Inf. Syst. 2009, 
AMCIS 2009, vol. 10, pp. 6951–6958, 2009. 
[37] A. Dameski, “A Comprehensive Ethical Framework for AI 
Entities: Foundations,” in Artificial General Intelligence, M. 
Iklé, A. Franz, R. Rzepka, and B. Goertzel, Eds. 2018, pp. 42–
51. 
[38] A. Smith and J. Anderson, “Digital Life in 2025: AI, Robotics 
and the Future of Jobs,” Pew Res. Cent., 6. 2014. 
[39] M. Anderson and S. L. Anderson, “Machine ethics,” IEEE 
Intelligent Systems, 2006. 
[40] M. Brundage, “Artificial Intelligence and Responsible 
Innovation,” in Fundamental Issues of Artificial Intelligence, 
Cham: Springer International Publishing, 2016, pp. 543–554. 
[41] F. Kile, “Artificial intelligence and society: a furtive 
transformation,” AI Soc., vol. 28(1), pp. 107–115, 2013. 
[42] W. Zhao, “Research on Social Responsibility of Artificial 
Intelligence Based on ISO 26000,” 2019, pp. 130–137. 
[43] P. Boddington, “Some Characteristic Pitfalls in Considering 
the Ethics of AI, and what to do about them,” 2017, pp. 85–97. 
[44] M. Drev, “Work Task Automation and Artificial Intelligence: 
Implications for the Role of Government,” in At His 
Crossroad, Cham: Springer, 2019, pp. 35–41. 
[45] T. Meek, H. Barham, N. Beltaif, A. Kaadoor, and T. Akhter, 
“Managing the ethical and risk implications of rapid advances 
in artificial intelligence: A literature review,” in 2016 PICMET, 
2016, pp. 682–693. 
[46] K. Y. Lee, H. Y. Kwon, and J. I. Lim, “Legal Consideration on 
the Use of Artificial Intelligence Technology and Self-
regulation in Financial Sector: Focused on Robo-Advisors,” 
2018, pp. 323–335. 
[47] K. Shahriari and M. Shahriari, “IEEE standard review — 
Ethically aligned design: A vision for prioritizing human 
wellbeing with artificial intelligence and autonomous 
systems,” in 2017 IEEE Canada IHTC, 2017, pp. 197–201. 
[48] B. C. Stahl and D. Wright, “Ethics and Privacy in AI and Big 
Data: Implementing Responsible Research and Innovation,” 
IEEE Secur. Priv., vol. 16(3), pp. 26–33, 2018. 
[49] K. Miller, “Can We Program Ethics into AI? [Reflections],” 
IEEE Technol. Soc. Mag., vol. 36(2), pp. 29–30, 2017. 
[50] A. Etzioni and O. Etzioni, “AI assisted ethics,” Ethics Inf. 
Technol., vol. 18(2), pp. 149–156, 2016. 
[51] R. Rault and D. Trentesaux, “Artificial Intelligence, 
Autonomous Systems and Robotics: Legal Innovations,” 2018, 
pp. 1–9. 
[52] Y.-J. Lee and J.-Y. Park, “Identification of future signal based 
on the quantitative and qualitative text mining: a case study on 
ethical issues in artificial intelligence,” Qual. Quant., vol. 
52(2), pp. 653–667, 2018. 
[53] D. Helbing et al., “Will Democracy Survive Big Data and 
Artificial Intelligence?,” in Towards Digital Enlightenment, 
Cham: Springer International Publishing, 2019, pp. 73–98. 
[54] J. Danaher, “Toward an Ethics of AI Assistants: an Initial 
Framework,” Philos. Technol., vol. 31(4_, pp. 629–653, 2018. 
[55] V. Vakkuri and P. Abrahamsson, “The Key Concepts of Ethics 
of Artificial Intelligence,” in 2018 IEEE ICE/ITMC, 2018, pp. 
1–6. 
[56] E. Yudkowsky, “Complex Value Systems in Friendly AI,” 
2011, pp. 388–393. 
[57] J. M. Kizza, “New Frontiers for Computer Ethics: Artificial 
Intelligence, Virtualization, and Cyberspace,” 2016, pp. 207–
225. 
[58] S. D. Baum, “Social choice ethics in artificial intelligence,” AI 
Soc., pp. 1-12, 2017. 
[59] A. Giubilini and J. Savulescu, “The Artificial Moral Advisor. 
The ‘Ideal Observer’ Meets Artificial Intelligence,” Philos. 
Technol., vol. 31(2), pp. 169–188, 2018. 
[60] S. A. Sora, “Artificial intelligence in a value based 
management system,” Int. J. Value-Based Manag., vol. 1(1), 
pp. 27–33, Feb. 1988. 
[61] G. Su, “Unemployment in the AI Age,” AI Matters, vol. 3(4), 
pp. 35–43, Feb. 2018. 
[62] J. Bandy, “Automation moderation,” AI Matters, vol. 3(4), pp. 
59–62, Feb. 2018. 
[63] S. Akter and S. F. Wamba, “Big data and disaster management: 
a systematic review and agenda for future research,” Annals of 
Operations Research, pp.1–21, 2017. 
[64] L. Yin, D. Fassi, H. Cheng, H. Han, and S. He, “Health Co-
Creation in Social Innovation: Design Service for Health-
Empowered Society in China,” Des. J., vol. 20(sup1), pp. 
S2293–S2303, 2017. 
[65] A. Stylianou and M. A. Talias, “Big data in healthcare: a 
discussion on the big challenges,” Health Technol., vol. 7(1), 
pp. 97–107, Mar. 2017. 
[66] B. Evans, “Using Big Data to Achieve Food Security,” in Big 
Data Challenges, London: Palgrave, 2016, pp. 127–135. 
[67] M. Phillips, E. S. Dove, and B. M. Knoppers, “Criminal 
Prohibition of Wrongful Re‑identification: Legal Solution or 
Minefield for Big Data?,” J. Bioeth. Inq., vol. 14(4), pp. 527–
539, Dec. 2017. 
[68] M. Batty, “Big data, smart cities and city planning,” Dialogues 
Hum. Geogr., vol. 3(13), pp. 274-279, 2013. 
90
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
[69] S. Monteith and T. Glenn, “Automated Decision-Making and 
Big Data: Concerns for People With Mental Illness,” Curr. 
Psychiatry Rep., vol. 18(112), p. 1-12, Dec. 2016. 
[70] L. Y. Y. Lu and J. S. Liu, “The Major Research Themes of Big 
Data Literature: From 2001 to 2016,” in 2016 IEEE CIT, 2016, 
pp. 586–590. 
[71] C. F. Breidbach, M. Davern, G. Shanks, and I. Asadi-Someh, 
“On the Ethical Implications of Big Data in Service Systems,” 
2019, pp. 661–674. 
[72] H. Mamiya, A. Shaban-Nejad, and D. L. Buckeridge, “Online 
Public Health Intelligence: Ethical Considerations at the Big 
Data Era,” 2017, pp. 129–148. 
[73] L. Kammourieh et al., “Group Privacy in the Age of Big Data,” 
in Group Privacy, Cham: Springer, 2017, pp. 37–66. 
[74] M. Cuquet, A. Fensel, and L. Bigagli, “A European research 
roadmap for optimizing societal impact of big data on 
environment and energy efficiency,” in 2017 GIoTS, 2017, pp. 
1–6. 
[75] A. Zwitter, “The Network Effect on Ethics in the Big Data 
Age,” in Big Data Challenges, London: Palgrave, 2016, pp. 
23–34. 
[76] P. A. Chow-White, M. MacAulay, A. Charters, and P. Chow, 
“From the bench to the bedside in the big data age: ethics and 
practices of consent and privacy for clinical genomics and 
personalized medicine,” Ethics Inf. Technol., vol. 17(3), pp. 
189–200, Sep. 2015. 
[77] J. S. Saltz, “A Framework to Explore Ethical Issues When 
Using Big Data Analytics on the Future Networked Internet of 
Things,” in FNSS 2018, 2018, pp. 49–60. 
[78] A. 
Richterich, 
“Using 
Transactional 
Big 
Data 
for 
Epidemiological Surveillance: Google Flu Trends and Ethical 
Implications of ‘Infodemiology,’” in The Ethics of Biomedical 
Big Data, Cham: Springer, 2016, pp. 41–72. 
[79] G. O. Schaefer, M. K. Labude, and H. U. Nasir, “Big Data: 
Ethical Considerations,” in The Palgrave Handbook of 
Philosophy and Public Policy, Springer, 2018, pp. 593–607. 
[80] J. N. Gathegi, “Clouding Big Data: Information Privacy 
Considerations,” in IMCW2018, 2014, pp. 64–69. 
[81] C. Garattini, J. Raffle, D. N. Aisyah, F. Sartain, and Z. 
Kozlakidis, “Big Data Analytics, Infectious Diseases and 
Associated Ethical Impacts,” Philos. Technol., Aug., pp. 1–17, 
2017. 
[82] J.-L. Monino, “Data Value, Big Data Analytics, and Decision-
Making,” J. Knowl. Econ., pp.1–12, Aug. 2016. 
[83] D. Nunan and M. Di Domenico, “Big Data: A Normal Accident 
Waiting to Happen?,” J. Bus. Ethics, vol. 145(3), pp. 481–491, 
Oct. 2017. 
[84] J. Collmann, K. T. FitzGerald, S. Wu, J. Kupersmith, and S. A. 
Matei, “Data Management Plans, Institutional Review Boards, 
and the Ethical Management of Big Data About Human 
Subjects,” in Ethical Reasoning in Big Data, Cham: Springer, 
2016, pp. 141–184. 
[85] K. Pormeister, “The GDPR and Big Data: Leading the Way for 
Big Genetic Data?,” in Annual Privacy Forum, 2017, pp. 3–
18. 
[86] N. Dorasamy and N. Pomazalová, “Social Impact and Social 
Media Analysis Relating to Big Data,” in Data Science and Big 
Data Computing, Cham: Springer, 2016, pp. 293–313. 
[87] M. Steinmann et al., “Embedding Privacy and Ethical Values 
in Big Data Technology,” in Transparency in Social Media, 
Cham: Springer, 2015, pp. 277–301. 
[88] H. Hijmans, “Internet and Loss of Control in an Era of Big Data 
and Mass Surveillance,” 2016, pp. 77–123. 
[89] A. Narayanan, J. Huey, and E. W. Felten, “A Precautionary 
Approach to Big Data Privacy,” 2016, pp. 357–385. 
[90] B. van der Sloot, “Is the Human Rights Framework Still Fit for 
the Big Data Era? A Discussion of the ECtHR’s Case Law on 
Privacy Violations Arising from Surveillance Activities,” 
2016, pp. 411–436. 
[91] B. Mittelstadt, “From Individual to Group Privacy in Big Data 
Analytics,” Philos. Technol., vol. 30(4), pp. 475–494, 2017. 
[92] M. Andrejevic, “Surveillance in the Big Data Era,” in PICT, 
Dordrecht: Springer, 2014, pp. 55–69. 
[93] Y. Wang, “Big Opportunities and Big Concerns of Big Data in 
Education,” TechTrends, vol. 60(4), pp. 381–384, Jul. 2016. 
[94] M. Fuller, “Some Practical and Ethical Challenges Posed by 
Big Data,” 2016, pp. 119–127. 
[95] D. Helbing, “Societal, Economic, Ethical and Legal Challenges 
of the Digital Revolution: From Big Data to Deep Learning, 
Artificial Intelligence, and Manipulative Technologies,” in 
Towards Digital Enlightenment, Springer, 2019, pp. 47–72. 
[96] X. Zhang and S. Xiang, “Data Quality, Analytics, and Privacy 
in Big Data,” 2015, pp. 393–418. 
[97] V. Morabito, “Big Data and Analytics for Government 
Innovation,” in Big Data and Analytics, 2015, pp. 23–45. 
[98] L. Taylor and C. Richter, “Big Data and Urban Governance,” 
in Geographies of Urban Governance, Cham: Springer, 2015, 
pp. 175–191. 
[99] Aqeel-ur-Rehman, I. U. Khan, and S. ur Rehman, “A Review 
on Big Data Security and Privacy in Healthcare Applications,” 
in Big Data Management, Cham: Springer, 2017, pp. 71–89. 
[100]I. Stanier, “Enhancing Intelligence-Led Policing: Law 
Enforcement’s Big Data Revolution,” in Big Data Challenges, 
London: Palgrave, 2016, pp. 97–113. 
[101]A. Gerdes, “Big Data—Fighting Organized Crime Threats 
While Preserving Privacy,” in Using Open Data to Detect 
Organized Crime Threats, Cham: Springer International 
Publishing, 2017, pp. 103–117. 
[102]R. Kitchin, “The real-time city? Big data and smart urbanism,” 
GeoJournal, vol. 79(1), pp. 1–14, Feb. 2014. 
[103]I. Olaronke and O. Oluwaseun, “Big data in healthcare: 
Prospects, challenges and resolutions,” in 2016 FTC, 2016, pp. 
1152–1157. 
[104]J. Richards, “Needles in Haystacks: Law, Capability, Ethics, 
and Proportionality in Big Data Intelligence-Gathering,” in Big 
Data Challenges, London: Palgrave, 2016, pp. 73–84. 
[105]M. Mulqueen, “Sustainable Innovation: Placing Ethics at the 
Core of Security in a Big Data Age,” in Big Data Challenges, 
London: Palgrave, 2016, pp. 61–71. 
[106]M. Alemany Oliver and J.-S. Vayre, “Big data and the future 
of knowledge production in marketing research: Ethics, digital 
traces, and abductive reasoning,” J. Mark. Anal., vol. 3(1), pp. 
5–13, Mar. 2015. 
[107]P. Prinsloo and S. Slade, “Big Data, Higher Education and 
Learning Analytics: Beyond Justice, Towards an Ethics of 
Care,” in Big Data and Learning Analytics in Higher 
Education, Cham: Springer, 2017, pp. 109–124. 
[108]R. Finn and A. Donovan, “Big Data, Drone Data: Privacy and 
Ethical Impacts of the Intersection Between Big Data and Civil 
Drone Deployments,” 2016, pp. 47–67. 
[109]W. J. Radermacher, “Official statistics in the era of big data 
opportunities and threats,” Int. J. Data Sci. Anal., vol. 6(3), pp. 
225–231, Nov. 2018. 
[110]M. Whitman, C. Hsiang, and K. Roark, “Potential for 
91
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

 
 
participatory big data ethics and algorithm design,” in 
Proceedings of the 15th PDC ’18, 2018, pp. 1–6. 
[111]M. Sax, “Big data: Finders keepers, losers weepers?,” Ethics 
Inf. Technol., vol. 18(1), pp. 25–31, Mar. 2016. 
[112]V. Narayanan, P. N. Howard, B. Kollanyi, and M. Elswah, 
“Russian Involvement and Junk News during Brexit,” 2017. 
[113]L. Sax, S. Gilmartin, and A. Bryant, “Assessing response rates 
and nonresponse bias in web and paper surveys,” Res. High. 
Educ., vol. 44(4), pp. 409–432, 2003. 
[114]R. M. Kidder, “Ethics: A matter of survival,” Futurist, vol. 
26(2), p. 10, 1992. 
[115]Z. Lachana, C. Alexopoulos, E. Loukis, and Y. Charalabidis, 
“Identifying the Different Generations of Egovernment: an 
Analysis Framework,” in The 12th MCIS 2018, 2018, pp. 1–
13. 
[116]C. Botella, A. Garcia-Palacios, R. M. Baños, and S. Quero, 
“Cybertherapy: Advantages, limitations, and ethical issues,” 
PsychNology J., 2009.
 
92
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-685-9
ICDS 2019 : The Thirteenth International Conference on Digital Society and eGovernments

