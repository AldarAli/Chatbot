Wearable Recognition System for Sports Activities
Ali Mehmood Khan, Michael Lawo
Universität Bremen
TZi
Bremen, Germany
{akhan, mlawo}@tzi.de
Abstract— Physical activity is a major part of a user's context 
for wearable computing applications. The system should be 
able to acquire the user's physical activities by using body 
worn  sensors.  We  want  to  develop  a  sports  activities 
recognition system that is practical, reliable, and can be used 
for health-care related applications. We propose to use the 
axivity device which is a readymade, light weight, small and 
easy  to  use  device  for  identifying  basic  physical  training 
activities (i.e., using elliptical trainer, butterfly, bench-press 
and pull down ) and different swimming styles (i.e., dolphin, 
back-stroke, breast-stroke and free-style) using decision tree 
classifier, Averaged one-dependence estimators (AODE) and 
Neural networks. In this paper, we present an approach to 
build  a  system  that  exhibits  this  property  and  provides 
evidence based on data for 8 different activities collected from 
20 different subjects. Our results indicate that the system has a 
good rate of accuracy. 
Keywords- Physical activities; accelerometer sensor; 
classifier.
I.
 INTRODUCTION 
Human activity recognition by using body worn sensors 
has received attention in recent years. An activity recognition 
system in health care support, especially in elder care, long-
term  health/fitness  monitoring,  and  assisting  those  with 
cognitive  disorders  is  demanded.  Therefore,  recognizing 
human physical activities with body worn sensors is not a 
new research field; most research has already been done in 
this area. We can identify users' physical movements using a 
body movement suit [2]; we also have other research projects 
where researchers identify the users' physical activities using 
some sensors like [3][4][5][6][7][8].
With  some  diseases  like  diabetes,  heart  problems, 
mentally disabled persons, elderly patients are required to 
perform  some physical  activities  or training  exercises  in 
order to make them physically fit. Similarly, in some cases, 
patients need to be monitored by nurses/trainers which is 
very time consuming and expensive.
Modern day lifestyle has lead to various physical and 
mental  diseases  such  as  diabetes,  depression  and  heart 
diseases  as  well.  According  to  the  World  Health 
Organization, there are at least 1.9 million people annually 
dying as a result of physical inactivity [10].
Although people are aware of the importance of exercise, 
there is a lack of motivation due to their busy schedules. 
People  need  to  be  urged  and  reminded  about  physical 
training  exercises.  Probably  automatic  and  personal 
reminders can be very helpful if they can monitor one’s 
physical training exercises and persuade people to perform 
them regularly.
Activity recognition technology can tackle this problem 
as it is able to monitor an individual’s physical training 
exercises and their duration in order to estimate how much 
calories are being consumed on a daily basis. Those systems 
can also provide recommendation when they fail to complete 
enough exercise and it also encourages people to conduct 
more activities [12][13][14].
In  some  cases,  especially  in  heart  diseases,  physical 
activities  are  also  required  along  with  the  physiological 
information for doctors in order to examine their patient's 
conditions when he is away from the doctor's clinic [19].
We want to develop an activity recognition system using 
a minimum amount of sensors which should be able in 
identifying  different  physical  exercises(using  elliptical 
trainer, butterfly, bench-press and pull down) and different 
swimming  styles  (i.e.,  dolphin,  back-stroke,  breast-stroke 
and free-style). 
In our research, we want to prove that it is possible to 
identify  the  aforementioned  activities  by  using  a  3D 
accelerometer.  In  next  section,  the  related  work  will  be 
discussed.  Hypothesis  and  research  question  will  be 
discussed in the section III. Experimental methodology will 
be discussed in the section IV. Evaluation will be discussed 
in the section V, and conclusion and future work will be in 
the last.
II.
RELATED WORK
There are several ways to recognize a person’s physical 
activities.  One  way  is  using  cameras  to  visually  detect 
people’s motion [15][16].
The drawback of this solution is that a large number of 
cameras would be required in order to monitor a moving 
person.  This  system  would  also  need  to  be  designed  to 
compute information from each camera and deal with other 
factors such as light, distance and angle, which make the 
system impractical.
Researchers  already  have  identified  various  physical 
activities  using wearable  sensors  like sitting  [3][6][7][8], 
standing [3][6][7][8], lying [6], walking [3][4][5][6][7][8], 
climbing stairs [3][4][6][7][8], running [5][7][8], cycling [5]
[8], strength training [8], etc. However, for their recognition 
system, they have used more than one sensor. For example, 
some  researchers  identified  around  20  activities  using  5 
sensor boards [8]. They identified walking, walking carrying 
items, sitting & relaxing, working on computer, standing 
still,  eating  or  drinking,  watching  TV,  reading,  running, 
bicycling,  stretching,  strength-training,  scrubbing, 
1
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

vacuuming,  folding  laundry,  lying  down  &  relaxing, 
brushing teeth, climbing stairs, riding elevator and riding 
escalator, by using Decision Table, Instance-based learning 
(IBL),  C4.5 and Naive Bayes  algorithms [26]. Similarly, 
researchers identified 12 activities using 3 sensor boards [3]. 
Researchers  identified  3  activities  i.e.,  walking,  climbing 
stairs and descending stairs using 9 tilt switches, by using K-
means clustering and brute force algorithms; these sensors 
were worn just above the right knee [4]. Researchers also 
identified  a  few  physical  activities  and  strength-training 
techniques using a 3D accelerometer sensor [9][20][21]. 
Researchers  also  have  identified  different  swimming 
styles by using wearable devices [22][23][24][25]. 
In our work, we want to develop a single system for 
recognizing  few  physical  training  exercises  (i.e.,  using 
elliptical trainer, butterfly, bench-press and pull down) and 
different swimming styles (i.e., dolphin, back-stroke, breast-
stroke and free-style).
Physical training exercises are already identified by using 
a 3D accelerometer [21], but we found following drawbacks:
- Data were not preprocessed before applying machine 
learning algorithms.
- Only two machine learning algorithms were used.
- It is stated that "For every user, the system needs to be 
trained with the sensor data so that it would be able to predict 
physical training exercises using the axivity device" [21].
In this work, we want to pre-process our data before 
applying any machine learning algorithms. Additionally, we 
want to use Neural networks [26] because it is known for 
pattern  recognition.  We  also  want  to  develop  a  generic 
system for both physical training activities and swimming 
styles.
III.
HYPOTHESIS AND RESEARCH QUESTION
The acceleration  measured  by a 3 axis accelerometer 
(X,Y,Z)  at  a  specific  point  (upper-arm),  indicates  which 
activity  a  person  is  performing  (using  elliptical  trainer, 
butterfly,  bench-press,  pull  down,  dolphin,  back-stroke, 
breast-stroke and free-style), by using J48 [26], AODE [26] 
and Neural Networks [26].
In  this  paper,  we  investigate  the practical  aspects  of 
creating an automatic, personal activity recognition system. 
Through our experiments, we want to find the answer of the 
following question: Is it possible to identify which activity 
the person is performing (using elliptical trainer, butterfly, 
bench-press, pull down, dolphin, back-stroke, breast-stroke 
and free-style) by using a 3D wearable accelerometer sensor 
on participants' arm?
IV.
EXPERIMENTAL METHODOLOGY
We  used  AX3  data  logger  [1]  in  order  to  identify 
physical activities which is also a water proof device (as 
shown in Figure: 1).
Figure 1: Axivity device
It was worn on the participants' arm and they wore it on the 
right hands’ upper arm (as shown in Figure: 2).
Figure 2:  Location for axivity device
The AX3 data logger contains 3-axis of accelerometer with 
flash memory and clock. This device is small and easy to 
use, its dimensions are 6x21.5x31.5 mm and its weight is 9 
grams. The device comes with pre-installed software with 
the possibility to configure its settings. For example, we can 
configure sample rate,  gravity, etc. It  continuously logs 
contextual information (time; hh:mm:ss and axis; X, Y, Z) 
to its internal memory. We can also set the duration for 
logging  this  information.  There  is  also  a  possibility  to 
export the logged data from the device to a computer in 
comma-separated values (CSV) format.
 We implemented an application for ‘Pocket PC’, where we 
can state the starting and ending time for each physical 
activity during experiments. This application generates text 
files with this information for each physical activity for 
training  data.  It  also  stores  the  participants’  personal 
2
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

information  i.e.,  age,  gender,  height,  and  weight.  We 
implemented another application in Java for analysis. This 
application requires two input files: time stamp for physical 
activities from ‘Pocket PC’, as well as the CSV file from 
the axivity device. Firstly, it filters needed data from the 
CSV file based on the time stamp from the files from the 
‘Pocket PC for each physical activity and generates training 
data files in ARFF format. Later, it pre processes the data 
(which is described below) and then we applied machine 
learning algorithms (J48, AODE and Neural Networks) on 
training data in order to get  results from all mentioned 
algorithms (as shown in Figure 3).
Figure 3: Architecture
A.
Data collection from Axivity device
We  conducted  two  user  studies  in  order  to  prove  our 
hypothesis.  One  was  for  identifying  physical  training 
exercises  and  other  one  was  for  identifying  different 
swimming styles.
For identifying physical training exercises, we recruited 14 
participants (9 males, 5 females) for our experiment setup 
as shown in Figure 3. The range of participants' age was 
from 20 to 41 (mean 29.14, SD 10.11) and ranged in BMI 
(body mass index) [10] from 19.6 to 27.8 (mean 23.03, SD 
2.39).  They  performed  each  physical  training  exercises 
(using  elliptical  trainer,  butterfly,  bench-press  and  pull 
down) for a minute.
For identifying different swimming styles, we recruited 6 
participants (5 males, 1 female) for our experiment setup as 
shown in Figure 3. The range of participants' age was from 
19 to 42 (mean 29.17, SD 19.58) and ranged in BMI (body 
mass index) [10] from 19 to 24.8 (mean 21.48, SD 2.16). 
They were required to swim 30 meters in each swimming 
style  (dolphin, back-stroke,  breast-stroke and free-style). 
Our participants had different swimming levels, some of 
them were beginners and some of them were expert in 
swimming. Some participants were not able to swim in 
dolphin style.
In order to attach this device on the participants’ back, we 
used sticky tape which was directly placed on the skin. We 
logged continuous data with 8G and the sample rate was 
100 Hz. At the end, we collected data from 20 participants 
out  of  both  studies  (physical  exercise  activities  and 
swimming styles).
B.
Ground truth
Participants'  were  continuously  observed  during 
experiments. An observer was stating starting/ending time 
of each activity.
C.
Pre-processing
Each window represents a data of 5 seconds and it contains 
correlation of (X, Y), correlation of (Y, X), correlation of 
(Z, X), average of X, average of Y and average of Z.
D.
Classifications
The 10-fold cross-validation is used to evaluate the J48, 
AODE  and  Neural  networks  (Multilayer  perceptron) 
models. We used WEKA toolkit [17] for evaluating our 
results.
V.
EVALUATION
Our results (Table 1) show that “Using elliptical trainer” 
activity was predicted with an accuracy of 90.64% by the 
J48. J48 was also able to predict other activities with better 
accuracy  than other classifiers except “Back-stroke”  and 
“Breast-stroke” activities. “Back-stroke” activity was better 
recognized by AODE classifier and “Breast-stroke” activity 
was better recognized by Neural Networks. “Free-style” was 
recognized by all classifiers with same accuracy.
TABLE I. 
COMPARISON WITH OTHER CLASSIFIERS 
J48
AODE
Neural 
networks
Using elliptical 
trainer 
90.64%
68.98%
89.84%
3
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

Butterfly
74.42%
47.09%
66.86%
Pull down
83.15%
79.35%
76.63%
Bench-press
77.66%
45.74%
68.09%
Dolphin
80.00%
80.00
26.67%
Back-stroke
64.52%
70.37%
68.97%
Breast-stroke
77.78%
59.26%
81.48%
Free-style
52.38%
52.38%
52.38%
VI.
CONCLUSION AND FUTURE WORK
Our system is able to recognize a high percentage of the 
aforementioned activities with the help of the J48 (decision 
tree) classifier. These preliminary results have shown that 
one 3D accelerometer sensor may be enough for identifying 
a few physical activities (using elliptical trainer, butterfly, 
bench-press, pull down, dolphin, back-stroke, breast-stroke 
and free-style). We may get different results when we use 
another 40 or more samples, this prototype is only a "proof 
of  concept"  and  our  results  show  that  a  single  3D 
accelerometer  sensor  can  identify  the  above  mentioned 
physical activities independent of BMI (body mass index) 
and age group. The accelerometer sensor has to be fixed 
properly on the participants' backbone in order to predict the 
participants'  activities  successfully.  We  will  put  the 
accelerometer sensor on other parts of the body in order to 
identify some other physical activities and we will use it for 
online machine learning. 
ACKNOWLEDGMENT
This research was funded by USEFIL [27].
REFERENCES
[1] Axivity - 
http://axivity.com/v2/index.php?
page=product.php&product=index.php?
page=product.php&product=ax3 (01/04/2014)
[2] Xsens MVN - http://www.xsens.com/en/general/mvn
(01/04/2014)
[3]  J.  Lester,  T.  Choudhury,  and  G.  Borriello,  “A  practical 
approach  to  recognizing  physical  activities,”  Lecture  Notes  in 
Computer Science 3968 (2006): 1–16.
[4] K. Laerhoven and A. K. Aronsen, “Memorizing what you did 
last week: Towards detailed actigraphy with a wearable sensor,” in 
Distributed Computing Systems Workshops, 2007. ICDCSW'07, 
27th International Conference
[5]  T.  Choudhury  et  al.,  “The  mobile  sensing  platform:  An 
embedded  activity  recognition  system,”  IEEE  Pervasive 
Computing (2008): 32–41.
[6] N. Kern, B. Schiele and A. Schmidt, “Multi-sensor activity 
context  detection  for  wearable  computing,”  Lecture  Notes  in 
Computer Science (2003): 220–234.
[7]  U.  Maurer,  A.  Rowe,  A.  Smailagic  and  D.  Siewiorek, 
“Location and Activity Recognition Using eWatch: A Wearable 
Sensor Platform,” Lecture Notes in Computer Science3864 (2006): 
86.
[8]  L.  Bao  and  S.  S.  Intille,  “Activity  recognition  from 
userannotated  acceleration  data,”  Lecture  Notes  in  Computer 
Science (2004): 1–17
[9] A. M. Khan 2011, "Recognizing Physical Activities using Wii 
remote", ICIKM 2011; Haikou, China.
[10]  World  Health  Organization:  Move  for  Health, 
http://www.who.int/moveforhealth/en (01/04/2014)
[11] J. E. Manson, P. J. Skerrett, Philip and B. Theodore, “The 
Escalating Pandemics of Obesity and Sedentary Lifestyle: A Call 
to Action for Clinicians”, Arch. Intern.  Med. 164(3), 249–258 
(2004)
[12] S. Consolvo et al, “Activity Sensing in the Wild: A Field Trial 
of UbiFit Garden”, CHI 2008 (2008)
[13] J. J. Lin, L. Mamykina, S. Lindtner, G. Delajoux and H. B. 
Strub, “Fish’n’Steps: Encouraging Activitiy with  an Interactive 
Computer Game”, Dourish, P., Friday, A. (eds.) UbiComp 2006. 
LNCS, vol. 4206, pp. 261–278. Springer, Heidelberg (2006)
[14] I.  Anderson,  J.  Maitland,  S.  Sherwood,  L.  Barkhuus, M. 
Chalmers, M. Hall, B. Brown and H. Muller, “Shakra: Tracking 
and  Sharing  Daily  Activity  Levels  with  Unaugmented  Mobile 
Phones”, Mobile Networks and Applications, 185–199 (2007).
[15] P. Turaga, R. Chellappa, V. S. Subrahmanian and O. Udrea, 
“Machine  Recognition  of  Human  Activities:  A  survey”,  IEEE 
Transactions on Circuits and Systems for Video Technology
18(11) (2008) 
[16] W. Hu, T. Tan, L. Wang and S. Maybank, “A survey on 
Visual  Surveillance  of  Object  Motion  and  Behaviors”,  IEEE 
Transactions  on  Systems,  Man,  and  Cybernetics.  Part  C: 
Applications and Reviews 34(3) (2004).
[17] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann 
and I. H. Witten, “The WEKA Data Mining Software: An Update”, 
SIGKDD Explorations, Volume 11, Issue 1.
[18]  Body  Mass  Index  -  http://www.nhlbisupport.com/bmi/ 
(01/04/2014)
[19] A.  M.  Khan,  “Personal state and emotion  monitoring  by 
wearable  computing  and  machine  learning”,  BCS-HCI  2012, 
Newcastle, UK
4
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

[20]  A. M.  Khan, "Recognizing  Physical  Activities  Using  the 
Axivity Device", eTELEMED 2013; Nice, France. IARIA, ISBN: 
978-1-61208-252-3 : 147-152.
[21] A.M. Khan, G. Kalkbrenner, M. Lawo, "Recognizing Physical 
Training  Exercises  Using  the  Axivity  Device",  ICT  meets 
Medicine and Health 2013; Bremen, Germany.
[22] P. Siirtola, P. Laurinen, J. Röning and H. Kinnunen, "Efficient 
Accelerometer-Based Swimming Exercise", Paris, CIDM 2011.
[23]  M.  Bächlin,  K.  Förster  and  G.  Tröster,  "SwimMaster:  a 
wearable assistant for swimmer", Florida, UbiComp 2009.
[24] M. Bächlin and G.  Tröster, "Swimming  performance  and 
technique  evaluation  with  wearable  acceleration  sensors", 
Pervasive and Mobile Computing 8 (2012), 68–81.
[25] J. Pansiot, B. Lo and G. Yang, "Swimming Stroke Kinematic 
Analysis  with  BSN",  BSN  '10  Proceedings  of  the  2010 
International Conference on Body Sensor Networks.
[26] R. S. Michalski, J. G. Carbonell and T. M. Mitchell, Machine 
learning, 1986, Los Altos, CA: Morgan Kaufmann Publishers.
[27] www.usefil.eu (01/04/2014)
5
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-327-8
eTELEMED 2014 : The Sixth International Conference on eHealth, Telemedicine, and Social Medicine

