Virtual Reality Assessment of Usability and Ergonomics in Hand Vein Biometric 
Systems 
 
 
Septimiu Crisan, Bogdan Tebrean  
Faculty of Electrical Engineering 
Technical University of Cluj-Napoca 
Cluj-Napoca, Romania 
email: septimiu.crisan@ethm.utcluj.ro 
email: bogdan.tebrean@ethm.utcluj.ro  
Simina Emerich  
Faculty of Electronics, Telecommunications and 
Information Technology 
Technical University of Cluj-Napoca 
Cluj-Napoca, Romania 
email: simina.emerich@com.utcluj.ro 
 
 
Abstract—Vein pattern recognition is a relatively new 
biometric technique that has gained recognition and traction in 
the last years. Still, for active researchers of this domain, one of 
the problems that can be identified is the lack of end-user 
feedback regarding the usability and ergonomics of proposed 
biometric scanners. In addition, touch-free scanners introduce 
more issues regarding the pose and postures of users 
interacting with a biometric device. With the recent advent of 
virtual reality devices and motion capture systems, large scale 
tests can be conducted with commercially available packages at 
a fraction of the price and resource allocation of a real-life 
usability study. This paper aims to give an insight into the 
practical implementation of a virtual reality study applied to 
biometric usability and attempts to offer a possible roadmap 
where these technologies are complementing behavioral 
experiments in biometrics.  
Keywords-vein patterns; biometric recognition; virtual 
reality; motion capture; inertial sensors. 
I. 
 INTRODUCTION  
Vein pattern recognition is a biometric technique that has 
gained significant traction in the last decade. Mostly 
employed on the hand area, common blood vessels for visual 
extraction are the veins in the back of the hand, palm, 
forearm or fingers [1][2]. While the underlying science is 
thoroughly understood, the technology has rarely left the 
confines of academic research and there are few mainstream 
applications, usually from large industrial players [3][4].  
As a long time research interest of the authors, vein 
biometrics, especially the veins in the back of the hand, have 
been analyzed and described in various scientific papers [5-
9]. As a direct result of the research, several hardware 
devices and software algorithms have been devised by the 
authors for this biometric parameter. New sensing topics, 
such as unconstrained hand acquisition scenarios; posture, 
pose and angle of attack for users presenting biometric data 
and general ergonomics have also been recently discussed 
[10][11]. 
The underlying problem is represented by the lack of 
information 
regarding 
user 
preference 
-posture 
and 
ergonomics- and the degree of usability that a biometric 
system might have. There is little feedback in the creation of 
new hardware devices except for the intrinsic technical 
prowess of a newer prototype. A full-scale experiment 
involving several tangible mockup devices, where subjects 
are filmed on location interacting with the biometric systems 
is difficult to implement due to higher cost and required post-
analysis. In addition, changes to real devices in order to 
account for the ongoing experimental data is difficult to 
achieve. Even small scale adjustments such as angle of 
positioning or distance between sensing elements and hand 
position are challenges for a real hardware device.  
Virtual reality has advanced significantly in the last 5 
years and commercially available headsets exhibit sufficient 
resolution and tracking speed for such an experiment. The 
participants’ movements are tracked in real time while using 
virtual assets and exploring false environments. This 
technology transposes easily to behavioral data, biometric 
systems’ assessment being a valid use case with no 
significant prior work being identified by the authors during 
the state of the art research.  
Since the procedure used to acquire the veins of the hand 
in biometric systems is most often contactless [3]10], there 
are palpable advantages when using a virtual reality device. 
In an unconstrained hand scenario, the lack of physical 
objects to interact with increases immersion since there is no 
disconnect between what the user sees and feels. In addition, 
most users unconsciously refuse to walk through solid 
objects or touch objects that are undesirable to be touched in 
the real world [12].  
With the help of a secondary inertial system, experiments 
have been carried out related to biometric presentation using 
free hand rotation with sub-millimeter tracking accuracy on 
various hand angles on all axes. Also, ergonomic data has 
been 
recorded 
and 
analyzed 
for 
future 
hardware 
implementations.  
After the introduction in Section 1, Section 2 presents the 
experimental setup mentioned earlier and Section 3 unveils 
the experiments that were perform for the virtual reality 
usability study. The conclusions of the article are depicted in 
Section 3. 
II. 
EXPERIMENTAL SETUP 
The experimental setup consists of a combination of 
several consumer level technologies. The general availability 
7
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-567-8
INFOCOMP 2017 : The Seventh International Conference on Advanced Communications and Computation

of these systems and devices, together with the reduced 
pricing, allows for reproducible virtual reality research due 
to early standardization efforts.  
The Virtual Reality System chosen for this research is an 
Oculus Rift CV1 comprised of a headset, hand controllers 
and external reference cameras for position tracking 
[13][14]. Orientation tracking is performed using the 
integrated inertial sensors and the drift is corrected every 
20ms by the reference infrared cameras providing a tracking 
accuracy of 0.5mm and a display refresh rate of 90Hz. The 
experimental setup involved the placement of four cameras 
in opposing corners denoting a movable testing space of 3.5 
x 3.5m.  
 
 
Figure 1. Virtual Reality station and reference sensors. The steering wheel 
and throttle and stick levers are not used in this particular set of experiments 
but they are employed for other behavioral studies using virtual reality in 
biomedical applications.  
The Virtual Reality station can be observed in Figure 1 
and the tracking area in Figure 2. Figure 1 also reveals other 
hardware devices used to monitor behavior and posture in 
multiple biomedical use-cases (intoxicated driving, day – 
night cycles for workers etc.) 
The users of the system can move freely in the 
designated area; the only inconvenience is the headset cord 
(carrying video and sensor data) that can get tangled around 
the user.  
A complete untethered package has also been created 
with the use of an older Oculus headset, the Developer Kit 2. 
Due to the reduced computational requirements, the headset 
has been paired with a laptop carried by the user for the 
duration of the experiments. While this technique has 
provided substantial data regarding user behavior, the 
reduced resolution and diminished moving space have been 
detrimental to the immersion level. The decision has been 
made to use the powerful but tethered modern system. 
 
 
Figure 2. Area trackable by the Oculus Rift headset. [15]. 
Since the system is only able to distinguish position and 
orientation of the head and the hands, an extra hardware 
package has been employed for full body orientation 
acquisition. The secondary system is a Perception Neuron 
motion capture suit with 32 individual nodes called 
“neurons” [16]. Each node is a 9 Degree of Freedom (DoF) 
sensor (tri-axis accelerometer, gyroscope and magnetometer) 
that relays the orientation data to a central hub for further 
processing. Using inverse kinematics and considering the 
rigid model of the human body, fine movements of the limbs 
and body can be sensed. Due to the placement of nodes on 
the fingers of the hand, accurate orientation and position of 
the user’s hand can be inferred, allowing the system to gather 
sensor data for the main battery of experiments related to 
usability in hand vein biometrics.   
The conforming elastic glove, the active sensing 
elements and the connections to the central hub are shown in 
Figure 3. 
The glove has 9 sensors capable of detecting minute 
movements of the hand and fingers in all axes and, due to the 
inclusion of two extra sensors on the wrist and forearm, the 
relative angles between the torso and the hands are correctly 
measured.  
The stream of data is very stable if the user has the feet 
planted on the ground, as the system has a robust detection 
algorithm based on the fixed position of two neurons on the 
upper plantar area if the user is not moving. However, being 
an inertial system with no frame of reference, it is very 
susceptible to drift if the user displaces the feet from the 
ground either by walking or jumping.  
In order to accurately track body stances and dynamic 
behavior -while allowing the subjects to move freely- both 
systems are needed. The difficulty in processing the data 
from two separate tracking entities arises from the mismatch 
between the coordinate systems. In addition, the Oculus Rift 
headset is tracked at the head level while the center node for 
8
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-567-8
INFOCOMP 2017 : The Seventh International Conference on Advanced Communications and Computation

the Perception Neuron Suit is situated in the middle of the 
body. 
 
 
Figure 3. Perception Neuron inertial glove, sensing elements and 
connections. 
Two approaches have been identified and implemented 
during the experimental phase: 
• 
Fusing the sensor data from the Oculus Rift CV1 
with the orientation information gathered from the 
Perception Neuron suit -using the head as a base 
node in the kinematics chain. 
• 
Using the Oculus Rift hand controllers- since they 
are not needed on the hands if the motion capture 
gloves are employed- rigidly attached to the back 
and front of the body at the height of the original 
primary node of the suit. 
While both solutions allow the data to be unified for 
further processing, using the head as a primary node creates 
additional tracking inaccuracies. This is in part due to the 
increased number of joints from the head node to the feet and 
several user poses will allow excessive drift to accumulate 
over short periods of time.  
Using the touch controllers preserves the original point of 
reference for the inertial suit while offering the same level of 
accuracy provided by the Rift headset. Employing both hand 
controllers – while slightly adding difficulty to the pose 
estimation- offers a higher degree of resistance against 
optical occlusion, a four-sensor setup detects the position of 
one or both of the controllers at all positions inside the 
testing area. 
This provides one complete solution for full body 
tracking in a virtual world with added emphasis on the hand 
and fingers.  
Simulations have been created using Epic Unreal Engine, 
a photorealistic graphics engine. Asset geometry data has 
been devised and rendered in Autodesk 3dStudio Max 
including all the virtual objects, biometric scanners and 
environments, subsequently being imported in Unreal 
Engine.  
Creating a virtual asset is significantly less expensive and 
time consuming than creating a real asset. In addition, the 
use of virtual reality provides multiple scenarios, difficult or 
impossible to recreate in real life. For the usability 
experiments, indoor and outdoor scenarios have been 
employed where the user position and relation to the virtual 
biometric scanner have been assessed. Initial tests and 
reactions allowed for a rapid evolution of the virtual 
prototypes in order to identify a suitable ergonomic and 
appealable biometric device that offers the highest usability 
score from the test group. 
Data arriving from the Perception Neuron motion capture 
suit have been processed in real time using the Axis Neuron 
Pro application and relayed as a BVH stream (Biovision 
Hierarchical Data) of skeleton hierarchy and motion data to 
the simulation using the Unreal plugin of the Axis 
application. The motion to photon latency measured in the 
full pipeline is 27ms resulting in an adequate dynamic 
response of the virtual reality system while decreasing the 
risk of simulator sickness for the participants of the usability 
study. 
 
 
Figure 4. Experimental setup and sensor fusion results. Test-person in 
front of VR station wearing Oculus Rift headset with Neuron Perception 
suit. 
Figure 4 shows the experimental setup in the post 
calibration stage. 
III. 
TESTING PROCEDURE AND RESULTS 
A group of 37 people has been enrolled in the 
experiments. The experiments were detailed and an informed 
9
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-567-8
INFOCOMP 2017 : The Seventh International Conference on Advanced Communications and Computation

consent was obtained from all participants. The age interval 
is intentionally reduced and spans from 20 to 26 years. For 
this particular testing, the age constraint has been put in 
place to avoid potential false results due to different 
understanding and acceptance of cutting edge technology at 
different stages in life. The age group will be widened  to be 
statistically relevant in future experiments after determining 
optimum positions and hand placement from users 
accustomed with the technology. All users have had a 
previous encounter with the same variant of a biometric vein 
scanner and have used the virtual reality device used in the 
experiments. In order to minimize external influences on the 
perception of the virtual system – nausea or dizziness 
associated with some applications of VR systems, excessive 
arm fatigue or altered proprioception due to sensory 
mismatch- several rules have been devised: 
• Each user is presented with only 6 different virtual 
vein scanners starting from the known one.  The goal 
is to avoid arm fatigue due to the position of the 
hand in the virtual scanner, a condition very similar 
to the “gorilla arm syndrome” exhibited by users of 
vertical touch screens [17]. 
• Movement is performed on a 1 to 1 scale and there is 
no vection and therefore no vestibular mismatch 
[18]. The user is free to roam the play area and the 
edges of the virtual space are marked with a subtle 
but easy to understand virtual grid that appears when 
the user is touching the borders of the play space. 
• For each user, the Intra-Pupillary Distance (IPD) is 
measured and the height of the individual is also 
entered in the simulation thus preventing eye fatigue 
and disorientation.  
• The virtual wall of the simulation is complemented 
by a real separator shifted 40cm outside the 
experiment area to increase immersion and in the 
same time to avoid users bumping into real walls 
since the virtual grid acts as an early alert system. 
• There are no movable parts in the simulations or 
objects that might entice the user to lean on or touch, 
in part to avoid sensory disconnections and to 
prevent potential injuries. 
• Generic, low feature avatars are used for the virtual 
bodies of the users involved in the usability 
experiments – setup does not elicit additional 
behavioral impulses [18]. 
For each individual user, a configuration file has been 
created based on their biometric data (height, IPD, vision 
correction parameters). In addition, every participant in the 
test received a 10-minute accommodation period in the 
testing area using the Oculus Rift headset and the Perception 
Neuron suit- with no biometric hardware setups shown at 
this stage.  
Three sets of experiments have been performed using the 
virtual reality setup.  
For experiment 1, each virtual scanner has a working 
area that has not been previously disclosed to the 
participants. Using a modified variant of the tests performed 
in [20], the users were asked to scan their vein patterns on a 
“contactless” device. The number of tries has been recorded 
as well as the distance of the user’s hand to the biometric 
scanner. In addition, the ability of a user to quickly find the 
optimum position has been recorded as the total time 
between the start of the simulation and the successful scan.  
Experiment 2 has been necessitated by current research 
of the authors in orientation and position invariant scanning 
algorithms. Calibration of the algorithms for hard angles 
(users inserting their hands in the scanning area at angles 
above 15°) is difficult to achieve in part due to the occlusion 
of veins when the hand is tilted too much. Experiments have 
determined that the overwhelming majority of users are 
below these limits and several steps can be introduced in the 
creation of biometric scanners to visually guide the user’s 
hand placement.  
For the last experiment, in order to verify the perceived 
accuracy and immersion of the experimental setup, a 
biometric system using a physical support handle for the 
hand has been modeled in the CAD software used 
previously. The part of the system that the user interacts with 
has also been physically created in Polylactic Acid (PLA) 
with the use of a general purpose Ultimaker 3D printer -
employing the Cura software package for toolpath 
generation. The printed handle and support have been placed 
in a precise manner in the experimental area in order to 
match the position of the virtual handle module. This allows 
a level of interaction more common to an AR (Augmented 
Reality) setup and reveals both physical and behavioral user 
information.  
Table 1 shows the results for the first virtual scanner- 
resembling the real device previously presented to the test 
participants.   
TABLE I.  
USABILITY RESULTS FOR SCANNER 1 
Sca
nner 
1 
Contactless scanner usability 
Parameters 
Number  
Obs. 
Exp. 
1 
Number of succesful first 
tries 
31 
 
Total number of tries (all 
users) 
44 
5 double tries 
and one triple 
attempt 
Average 
distance 
of 
hovering hand to scanner 
12cm 
86 % of test-
users in 
optimum range 
of 10-15cm 
Average 
time 
from 
simulation 
start 
to 
successful scan 
9.2 s 
37 
people 
sample size 
Lower 
back 
angle 
compensation for scanner 
height 
>11° for 15% 
of users 
Consistent with 
height  
Exp. 
2  
Average angle of attack 
for vertical axis (roll on 
horizontal axis) 
6° 
96% of users 
between -
15°…+15° 
Average angle of attack 
for horizontal axis (yaw 
on vertical axis) 
4° 
90% users 
between 
 -10°…+8° 
Average angle of attack 
for horizontal axis (pitch 
on horizontal axis) 
11° 
68% users 
between 
 -10°…+9° 
Percentage of clenched 
fist vs. open hand 
94% 
Previously 
instructed to 
10
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-567-8
INFOCOMP 2017 : The Seventh International Conference on Advanced Communications and Computation

Sca
nner 
1 
Contactless scanner usability 
Parameters 
Number  
Obs. 
use clenched 
fist posture 
Exp. 
3 
Number of succesful first 
tries 
(reaching 
and 
touching real handle) 
35 
2 users required 
multiple tries- 
eye conditions 
Willingness to retouch – 
number of users 
32 
5 users 
expressed 
anxiety over 
retouching 
sensor 1 -either 
due to different 
feel of the 
texture or slight 
miscalibration 
of the visual 
cues. The 
general 
consensus was 
“lack of 
realism” 
 
Complete experimental results have been gathered for all 
six virtual biometric scanners and the designs have been 
updated to take into account the usability impact assessed in 
the tests. In order to aim for a standardization proposal for a 
modular vein pattern biometric scanner, usability and 
ergonomics data gathered in this research will allow an 
academic device to gain commercial attributes difficult to 
quantify in a real-life experiment.  
IV. 
CONCLUSIONS 
As part of an ongoing research into the involvement of 
virtual reality in biometrics, this paper has attempted to 
depict the general hardware and software implementation of 
a virtual reality usability study concerning vein pattern 
recognition systems. Using the combination of a precise 
position acquisition from a virtual reality setup with the full 
body pose assessment of an inertial motion capture system, a 
complete real time user tracking system has been 
implemented.  
The general workflow of the communication between 
these heterogenous systems has also been presented in the 
experimental setup description. 
The participants in the experiments have been virtually 
placed in a false environment with various designs of hand 
vein biometric systems present in the simulation. Starting 
from a known, real biometric scanner, users have been asked 
to place their hands above or below 5 proposed scanner 
designs. 
Several pieces of information have been successfully 
extracted from the experiments that add in the design of real-
life biometric scanners. The paper has presented results 
concerning height variance and comfort rating for different 
scanner position and geometry. In addition, a battery of tests 
dealing with angle of attack measurement for unconstrained 
hand position has led directly to a simplification of 
algorithms for an orientation invariant hand vein biometric 
scanner. These results are relevant in both pure biometric 
studies and real security applications.  
In order to cement the presence of virtual reality in the 
world of biometrics, a new experiment is underway where 
users are instructed to enroll in a multimodal biometric setup 
using five technologies (retina scan, iris recognition, finger 
vein, voice and fingerprints). A real setup with access to 
these scanning methods would be extremely difficult to 
construct.  
By using virtual reality, small changes in the user 
position and behavior, coupled with the willingness to 
provide the biometric parameter (retinal scans perceived as 
intrusive and dangerous, face scanners easy to comply or 
fingerprint scanners -simple but carrying a “crime stigma”) 
offer valuable data regarding user perception of different 
scanning technologies. 
ACKNOWLEDGMENT 
This work was supported by a grant of the Romanian 
National Authority for Scientific Research and Innovation, 
CNCS-UEFISCDI, project number PN-II-RU-TE-2014-4-
2196 
REFERENCES 
 
[1] A. K. Jain, A. Ross, S. Prabhakar, “An Introduction to 
Biometric Recognition”, Invited paper in IEEE Transactions 
on circuits and systems for video technology, Vol. 14, No. 1. 
2004. 
[2] C. Wilson, “Vein pattern recognition: a privacy-enhancing 
biometric”, Taylor & Francis, ISBN 978-1-4398-2137-4I, 
2010. 
[3] Fujitsu Develops Technology for World's First Contactless 
Palm Vein Pattern Biometric Authentication System , Fujitsu 
Laboratories 
Limited, 
Tokyo 
Japan 
Available 
from 
http://www.fujitsu.com/global/news/pr/archives/month/2003/
20030331-05.html, 2014.09.02 
[4] Introducing Hitachi Finger Vein Authentication (2005). 
Hitachi 
Corporation 
Japan. 
Available 
from 
http://www.hitachi.co.jp/Prod/comp/fingervein/global, 
2015.12.13 
[5] S. Crisan, I. G. Tarnovan, T. E. Crisan, “A Low Cost Vein 
Detection System Using Near Infrared Radiation”, IEEE SAS, 
San Diego, USA, 2007 
[6] S. Crisan, I. G. Tarnovan, T. E. Crisan, “Radiation 
optimization and image processing algorithms in the 
identification of hand vein patterns”, Computer Standards and 
Interfaces, Volume 32, Issue 3, pp 130, Elsevier, 2010 
[7] S. Crisan, “Researches concerning the development of 
biometric applications using infrared radiation”, PhD Thesis, 
Technical University of Cluj-Napoca, 2008 
[8] S. Crisan, I. G. Tarnovan, B. Tebrean, T. E Crisan, 
“Corellation of near and far infrared vein recognition for 
unified processing and simulation”, XIX IMEKO World 
Congress Fundamental and Applied Metrology, Lisbon, 
Portugal. 2009 
[9] S. Crisan, I. G. Tarnovan, B. Tebrean, T. E. Crisan, “Hand 
Vein Biometric Authentication in Optical Multi-touch 
Systems” In International Conference on Advancements of 
Medicine and Health Care through Technology (pp. 124-127). 
Springer Berlin Heidelberg, 2011 
[10] S. Crisan, B. Tebrean, S. Emerich, “Optimized Vein Pattern 
Recognition for Biometric Applications, a Modern Approach” 
14th IMEKO TC10 Workshop Technical Diagnostics New 
Perspectives in Measurements, Tools and Techniques for 
11
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-567-8
INFOCOMP 2017 : The Seventh International Conference on Advanced Communications and Computation

system’s reliability, maintainability and safety Milan, Italy, 
June 27-28, 2016  
[11] S. Crisan “A Novel Perspective on Hand Vein Patterns for 
Biometric 
Recognition. 
Problems, 
Challenges 
and 
Implementations”. Chapter in Biometric Security and Privacy. 
Opportunities & Challenges in The Big Data Era. Signal 
Processing for Security Technologies series.  Jiang, R., Al-
Madeed, S., Bouridane, A., Crookes, D., Beghdadi, A. (Eds.) 
2017 
[12] S. M. Lavalle, Virtual Reality, Cambridge University Press, 
2017 
[13] P. R. Desai, P. N. Desai, K. D. Ajmera, K.  Mehta, “A review 
paper on oculus rift-a virtual reality headset”. arXiv preprint 
arXiv:1408.1173, 2014 
[14] D. Sharma, “A Review Paper On Virtual Reality Oculus Rift 
And Augment Reality”, International Journal of Current 
Research, Vol. 8, Issue 9, pp. 37941-37945, 2016 
[15] Oculus 3-Sensor 360° Experimental Setup, Upload VR, 
Available 
from 
https://uploadvr.com/oculus-guides-show-
smaller-multi-sensor-tracked-spaces-htc-vive/, 2017.02.04 
[16] W. Mason “Perception Neuron Review: In-Depth With The 
$1,500 
Motion 
Capture 
Suit”, 
Available 
from 
http://uploadvr.com/perception-neuron-review/, 2015.11.04 
[17] S. Boring, J.  Marko , A. Butz. "Scroll, tilt or move it: using 
mobile phones to continuously control pointers on large 
public displays." Proceedings of the 21st Annual Conference 
of the Australian Computer-Human Interaction Special 
Interest Group: Design: Open 24/7. ACM, 2009. 
[18] A. I. Mallinson, "Visual Vestibular Mismatch." PhD diss., 
Université Henri Poincaré, 2011. 
[19] J. Blascovich, J.  Bailenson, “Infinite reality: Avatars, eternal 
life, new worlds, and the dawn of the virtual revolution”,  
William Morrow & Co, 2011 
[20] M. Jokisch, T. Bartoschek, A. Schwering, “Usability testing 
of the interaction of novices with a multi-touch-table in semi 
public space”, Institute for Geoinformatics, University of 
Münster, 2010 
 
 
12
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-567-8
INFOCOMP 2017 : The Seventh International Conference on Advanced Communications and Computation

