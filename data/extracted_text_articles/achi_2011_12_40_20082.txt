Exploring Trust in Personal Learning Environments 
Na Li, Maryam Najafian-Razavi, Denis Gillet 
Ecole Polytechnique Fédérale de Lausanne (EPFL) 
1015 Lausanne, Switzerland 
{na.li, maryam.najafian-razavi, denis.gillet}@epfl.ch 
 
 
Abstract—The design of effective trust and reputation 
mechanisms for personal learning environments (PLEs) is 
believed to be a promising research direction. In this paper, we 
propose a 4-dimensional trust model that complies with the 
specific requirements of PLEs. Trust is explored in four 
dimensions: trustor, trustee, context and visibility. The 
importance of these four dimensions is investigated through a 
number of scenarios. The model is implemented in a PLE 
platform named Graaasp. Preliminary evaluation of usefulness 
is conducted through a user study and some interesting 
findings are discussed in the end. 
Keywords-trust; reputation; personal learning environment; 
rating; ranking 
I. 
 INTRODUCTION  
Benefiting from the success of Web 2.0 social media, 
interactive information sharing has become pervasive. For 
users surrounded by an abundance of information, the 
challenge now is how to determine which resources can be 
relied upon and who is reliable enough to interact with. To 
solve this problem, a number of trust and reputation systems 
have been developed in various platforms, including e-
commercial sites, product review systems, and professional 
communities. Trust and reputation measures can help users 
decide whether or not to interact with a given party in the 
future, or whether it is safe to depend on a given resource 
[1]. This creates an incentive for good behavior, therefore 
inducing a positive effect on the quality of interaction in 
online communities. 
As a particular support framework for interaction in 
online communities, personal learning environments (PLEs) 
embed tools, services, content and people involved in the 
digital part of the learning process [2] [3]. Web 2.0 
functionalities like blogging, tagging, rating and commenting 
are gradually incorporated into learners’ overall learning 
ecology, contributing to increasing learning incentives and 
enhancing the learning experience [4]. On one hand, these 
Web 2.0 features enable learners to express opinions easily 
and facilitate accumulating domain knowledge. On the other 
hand, learners’ active contributions produce a large amount 
of user-generated content, which may lead to information 
overflow. In such an open learning environment, it is not 
easy for learners to find suitable people to learn from or 
collaborate with. Moreover, the flood of data might bring 
about the challenge of selecting useful learning resources 
depending on personal learning goals. Therefore, research 
efforts are needed to design appropriate trust and reputation 
mechanisms for PLEs, aiming at expertise assessment and 
quality assurance to support self-directed learning activities. 
As a complex social concept, trust reflects the subjective 
perception one party holds about another party. It’s 
asymmetrical, transferable, dynamic, and context-dependent, 
and can be influenced by various factors. Trust has been 
interpreted in different ways to comply with specific 
requirements of various domains. In this paper, a usable trust 
model for personal learning environments is investigated and 
implemented in a PLE prototype named Graaap 1 . 
Preliminary evaluation of usefulness has been conducted 
through a user study. The rest of this paper is organized as 
follows. Section II introduces the existing trust and 
reputation schemes, and discusses the specific aspects of 
PLEs that call for different trust and reputation models. A 
trust model dedicated to PLEs is proposed in Section III. 
Section IV introduces the Graaasp prototype and illustrates 
the implementation of the proposed trust model in it. User 
evaluation and main findings are addressed afterwards in 
Section V. Finally, Section VI concludes the paper and 
discusses the future work. 
II. 
RELATED WORK 
In order to develop effective trust and reputation 
mechanisms, a number of attempts have been made in both 
literature and practice. The simplest but most widely used 
scheme is to compute an average or summary of all ratings 
for an entity. The reputation systems used by eBay 2 , 
Epinions3 and Amazon4 fall into this category. However, this 
scheme is primitive and therefore gives a poor picture on an 
entity’s reputation score [5].  
Google’s PageRank [6], Advogato’s reputation scheme 
[7], and EigenTrust model [8] can be categorized as flow 
models, where trust or reputation is computed by transitive 
iteration through looped or arbitrarily long chains. In short, a 
participant’s trust or reputation score increases as a function 
of incoming flow, and decreases as a function of outgoing 
flow. Flow model-based schemes adopt global trust metrics, 
where a single trust or reputation score is associated with 
each participant and displayed to all members in the 
community. 
Some researchers have proposed to use mathematical 
models in an attempt to measure trust, including Bayesian 
algorithm-based metrics [9] and belief theory-based models 
                                                             
1 Graaasp (graaasp.epfl.ch): a PLE prototype. 
2 eBay (www.ebay.com): an online auction and shopping website. 
3 Epinions (www.epinions.com): a consumer review website 
4 Amazon (www.amazon.com): an e-commercial website. 
274
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

[10]. These models provide a theoretically sound basis for 
computing reputation scores, but they are too complex for 
average users to understand and too difficult to implement in 
real systems. 
There are also some approaches using rating similarity to 
predict trust. Golbeck [11], for example, proposes an 
approach for computing trust in which several aspects of 
rating similarity that are believed to affect trust opinion in 
movies are integrated to compute trust values between 
people. The approach is based on the observation that, in 
many Web-based social networks, a significant percentage of 
users are completely isolated from most others, thus the 
social network-based trust measures are not applicable. 
However, those isolated users are usually the inactive ones 
who rarely contribute to the system and hence provide few 
ratings. Lack of ratings would probably be a problem for 
trust metrics relying on rating similarity. 
A general observation of existing trust and reputation 
systems is that they tend to adopt global trust metrics, where 
for each entity in the community, a reputation score is 
computed to reflect how much the community as a whole 
trusts this specific entity. However, trust is more of a 
personalized concept greatly depending on personal 
experience, which means that the trust score of an entity 
could be different from the point of view of different users. 
Furthermore, each of the current trust and reputation systems 
targets to a particular domain, including e-commercial, 
product review, and movie review. In each domain, the 
context of trust is a shared belief in the whole community, 
such as the quality of service in case of e-commercial 
domain, or the usability of product in case of product review 
domain. In comparison, a PLE is a multi-disciplinary and 
multi-dimensional environment where resources and services 
are aggregated from heterogeneous sources. The contexts of 
trust could be diverse depending on different learning 
scenarios like group project of physic course, discussion of 
English 
learning, 
online 
meeting 
about 
Web 
2.0 
technologies, and so on. Thus, there is a clear need for a 
context-dependent trust model that accounts for various 
learning contexts in such an environment. Last but not least, 
instead of designing complex mathematical model-based 
metrics, the trust model should be simple enough for non-
technical users to use. Given these requirements, effective 
trust and reputation mechanisms in PLE should take users’ 
subjective views and learning context into account, as well as 
making it easy for average users to understand. 
III. 
TRUST MODEL IN PLE 
Intuitively, trust can be affected by a variety of factors, 
including personal experience, rumor, social rules and so on. 
There is no single trust model that will be suitable in all 
domains and applications. To comply with the specific 
requirements and constraints of PLE, trust is explored in four 
dimensions: trustor, trustee, context and visibility. The idea 
is to describe who trusts what in which context with which 
degree of visibility. In this section, we propose a 4-
dimensional trust model dedicated to PLEs. The importance 
of these four dimensions is illustrated through example 
scenarios. 
A. Trustor 
The two parties involved in a trust relationship are 
referred to as trustor and trustee respectively. As mentioned 
previously, for a particular trustee, the trust value varies from 
the standpoints of different trustors, depending on various 
personal experiences. As an example, Alice strongly trusts 
Bob since they have been working together on the same 
project for several months. While Claire does not trust Bob 
at all as they have not collaborated with each other before. In 
short, personalization is a crucial characteristic that should 
be accounted for when computing trust. However, with 
incorporation of personalization into the trust model, 
computation complexity increases accordingly, which might 
bring about confusion for users. Therefore, the personalized 
trust metrics must be designed and presented in a 
straightforward way so that average users can easily 
understand and use them. 
Although personalized trust metrics are more precise and 
tailor-made for individual users, they are still not sufficient 
to measure an entity’s trustworthiness in the learning 
community. For new users who do not have much 
experience in the community and have no knowledge of 
entities’ trustworthiness, it is more important to refer to 
others’ trust opinions towards an unknown entity to reduce 
transaction risk. To this end, the global reputation score of a 
particular entity should also be considered as an essential 
factor, in terms of representing the trust opinion held by the 
community as a whole. In this paper, we integrate global and 
personalized trust metrics for the purpose of providing both a 
general and a personalized view of trust opinions. Concrete 
application of the two trust mechanisms will be illustrated in 
detail in Section IV. 
B. Trustee 
In a trust relationship, trustor is usually a person or an 
agent. While as the receiver of trust, trustee can be a person, 
a resource, a tool or any other entities in the system. For 
instance, a professor can be trusted because of his/her 
expertise, a book can be trusted because of its quality, and a 
tool can be trusted because of its utility. For a specific type 
of trustee, people tend to use a certain set of criteria to 
evaluate the trustworthiness. It’s relatively easier to evaluate 
the trustworthiness of a document than a person, since the 
characteristics of a person are much more complex and could 
change over time. How the type of trustee influences trust 
relationship between two entities will be investigated in the 
user study hereafter. 
C. Context 
PLE is an open environment that aggregates people, 
resources, and services from a large variety of disciplines, 
such as physics, computer science, electrical engineering, 
and any other learning domain. Depending on different 
learning goals, the learning activities in PLE could also vary 
from group projects to independent study, forum discussion, 
and online courses. In such a complex environment, context 
plays an important role in how people assign trust. As an 
example, Alice trusts Bob in the context of English learning 
since Bob is a native English speaker, whereas she does not 
275
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

trust him in the context of ski learning as Bob is a ski 
beginner. Therefore, it’s essential to integrate the factor of 
context into the trust model of PLE. 
However, as a controversial concept, context is too 
complicated to define and represent. Major research efforts 
have been made to develop ontology-based context 
frameworks [12] [13], but the problem is that ontologies are 
very difficult to agree on in that different communities use 
different naming standards and interpret entities in different 
ways. Moreover, from a user’s point of view, ontology-based 
context models impose an inconvenient way of organizing 
and classifying entities. To solve this problem, a simple and 
understandable approach to identify context and incorporate 
it into the trust mechanism is introduced in Section IV. 
D. Visibility 
The trust scores in existing trust and reputation systems 
are mostly publicly available to all members of the 
community. For instance, all eBay users can see what 
feedback (positive, neutral, or negative) a particular user has 
given to another user. Nevertheless, in some cases, people 
might feel uncomfortable to share their trust opinions with 
others. Especially when people express negative trust 
opinions, they might prefer to make them private in order to 
avoid retaliation from others or limit the negative social 
impact of the trust values they assign. Furthermore, these 
psychological reasons have been proven to lead to a positive 
bias of ratings in most reputation systems [5]. 
Due to these privacy concerns, three visibility types of 
trust are considered in our model: public, private and 
anonymous. Public trust score is globally visible in the entire 
community. Private trust score assigned by a user is 
particularly accessible to himself/herself or a certain group of 
users indicated by him/her. Anonymous trust score is 
accessible to all members anonymously. 
Based on the analysis above, a 4-dimensional trust model 
is proposed by integrating the four factors that are believed 
to effectively describe how people assign trust in PLE. Let Tr 
denote trustor, Te denote trustee, Tc denote context, and Tv 
denote visibility. A trust value can then be defined using the 
term < Tr, Te, Tc, Tv >. As an example, < Alice, Bob, English 
learning, public > represents the trust value Alice assigns to 
Bob in the context of English learning publicly. The 
implementation of the trust model in a PLE platform is 
addressed in detail in Section IV. 
IV. 
TRUST APPLICATION IN GRAAASP 
A. Graaasp 
Graaasp can be described as a Web 2.0 application that 
can 
serve 
simultaneously 
as 
an 
aggregation, 
contextualization, discussion, and networking platform, a 
shared asset repository, or an activity management system. 
The user interface of Graaasp is illustrated in Fig. 1. The 
structure of Graaasp relies on the extension of the 3A 
interaction model [14], which is intended for designing and 
describing social and collaborative learning environments. 
The 3A model consists of three main constructs or entities: 
Actors represent entities capable of initiating an event in a 
collaborative environment, such as regular users or virtual 
 
Figure 1.  Graaasp User Interface 
276
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

agents. Actors create collaboration spaces where they 
conduct personal and group Activities to reach specific 
objectives. In each of these activities, actors can take 
different roles, each of which consisting of a label and an 
associated set of rights. In addition, Actors produce, edit, 
share and annotate Assets in order to meet activities 
objectives. Assets can consist of simple text files, RSS feeds, 
wikis, videos or audio files. A fourth structural entity 
Application is added into the model to describe widget or 
gadget [15] that can be installed and executed within the 
Web pages. Applications can be any tools created or linked 
by actors. 
As shown in Fig. 1, the user interface of Graaasp mainly 
consists of two parts: the focal part on the left side and the 
contextual part on the right side. The focal part shows the 
entity that is currently selected by the user. It can be a human 
(actor), an activity (space), an asset or an application (tool). 
The contextual part consists of the four columns of items, 
each of which represents one type of entities (actors, assets, 
activity spaces, tools) linked to the focal entity.  
Instead of integrating complicated context framework, 
we simply define the current learning context as the 
combination of the focal entity and its related entities. A 
further explanation of the learning context is described 
through the following scenario: A group project called “HCI 
Project of Group One” is selected as the focal entity, within 
which there are four group members (“Na Li”, “Evgeny 
Bogdanov”, “Sandy El Helou”, “Andrijana”), several activity 
spaces (“Main Page Design”, “Assignment Space”, “Discuss 
Space”, 
“Scenario 
Development”, 
and 
“Interface 
Sketching”), a set of assets (“HCI Guidelines”, “Dialog 
Design”, “Graphic Design”, “User Study”, and “User 
Centered Design”) created by group members, and a number 
of tools (“Color Scheme”, “Picture Library”, and “Art 
Painter”) linked by them. These entities, as a whole, 
construct the learning context.  
B. Applying Trust in Graaasp 
Different ways to apply and represent trust can be found 
in various online systems. Rating with the scale of five is the 
most widely used method to assign trust, which has been 
applied by eBay, Epinions, Amazon, and so on. Voting as 
“like” or “dislike” is also used to express trust opinions in a 
handful of systems including Youtube 5 and Facebook 6. 
Additionally, LinkedIn7 and CouchSurfing8 adopt a reference 
or recommendation mechanism to capture the trust 
relationship between participants. There are other platforms 
like AllExperts 9  using ranking and FilmTrust 10  using 
numerals to represent the trustworthiness of users. In 
Graaasp, we use rating to capture and manifest global trust, 
                                                             
5 Youtube (www.youtube.com): a video sharing website. 
6 Facebook (www.facebook.com): a social network website. 
7 LinkedIn (www.linkedin.com): a business-oriented social network 
website. 
8 CouchSurfing (www.couchsurfing.org): a social network website for 
travelling. 
9 AllExperts (www.allexperts.com): a website for asking and answering 
questions. 
10 FilmTrust(trust.mindswap.org/FilmTrust): a movie review website. 
and ranking to present contextualized and personalized trust, 
as rating and ranking are intuitive ways for average users to 
express their trust opinions. The trust model proposed in 
Section III is implemented into the system, where we 
integrate the four dimensions to construct the trust 
mechanism.  
The detailed illustration of the global rating in Fig. 1 (a) 
is shown in Fig. 2. When a user selects an entity as the focal 
one, a rating score can be given to this particular entity in the 
scale of five. People, activity spaces, assets, and tools can all 
be rated once selected. Regarding the visibility of the rating 
score, three alternatives are provided: public, private and 
anonymous. The user is able to decide whether to make the 
rating opinion accessible to all the community members 
(public, anonymous) or restrict it only to a particular group 
of users (private). For every entity, an average score of all 
the ratings is computed, which is considered as the reputation 
score of this specific entity. This reputation score, which is 
visible in the entire community, represents the global trust 
perception 
and 
thus 
provides 
a 
social 
metric 
of 
trustworthiness associated with the entity.  
As mentioned previously, the learning context in 
Graaasp is defined by the combination of the focal entity 
and four columns of entities that are related to it. Within a 
particular context, users can rank the entities in each of the 
four entity lists by “drag and drop” action. As an example, 
the original ranking of activity spaces is presented in Fig. 1 
(b). How the activity space of “Interface Sketching” is 
ranked at the top of the space list is shown in Fig. 3. This 
user-defined ranking of entities (generated by a specific user 
depending on a specific learning context) can then be 
considered as the personalized and contextualized trust 
 
Figure 2.  Three Visibility Types of Rating 
 
Figure 3.  Ranking by “Drag and Drop” Action 
 
277
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

assigned by the user. Explicitly ranking “Interface 
Sketching” at the top of the list suggests that this specific 
user strongly trusts this activity space within the current 
context. The customized ranking not only provides users a 
convenient way to organize content according to their 
preferences, but also enables the system to capture users’ 
trust opinions for future use including context-dependent 
recommendation and effective search. As far as the visibility 
of trust is concerned, the user is able to keep the ranking only 
to himself/herself or share it with a certain group of 
community members indicated by the user. 
V. 
PRELIMINARY EVALUATION 
To evaluate the usefulness of the trust mechanism in 
Graaasp, a user study is conducted with participants who 
would be typical users of the system. The evaluation 
methodology and main findings are discussed in this section. 
A. Evaluation Methodology 
Typically, user studies are used to confirm the design 
decisions and find any problems that have been overlooked. 
They can range from closely controlled experimental studies 
testing specific hypotheses to field studies where the system 
is deployed for real usage and interviews are used to assess 
its usefulness and usability [16]. Our study falls into the first 
category, where the Graaasp system is introduced to 
potential users and in-depth interviews are carried out, 
aiming at determining whether the design of the trust model 
is suitable for the intended audience and for its intended 
purpose. 
For each participant, the study consists of two parts. The 
first part is an introduction of the overall Graaasp system 
and the particular features related to trust mechanisms. The 
second part is an individual interview with carefully defined 
user questionnaire. During the study, participants are 
encouraged to “think aloud”, in order to obtain running 
commentary while they are interacting with the system. 
The user questionnaire is composed of Likert-scale 
questions [17] with 5-point preference scale (strongly 
disagree, disagree, neutral, agree, and strongly agree), 
multiple choice questions and open questions. The questions 
can be grouped into the following categories: usefulness of 
global trust, usefulness of trust visibility specification, 
usefulness of personalized and contextualized trust, and 
influence of trustee on trust. The user questionnaire is 
summarized in Table I. 
B. Data Collection 
The user study is conducted with ten engineering 
university students, who are the intended audience of the 
Graaasp system. All of them are graduate students between 
the age of 20 and 30. All participants are frequent Web users 
who visit the Internet daily and most of them have some 
experience of using online learning systems. All informants 
claimed that they were familiar with the rating, voting, 
ranking or similar features in online systems and used them 
from time to time.  
Data was collected through user questionnaires and 
interviews. Two experimenters stayed with each participant 
throughout the session, observing his/her reactions, asking 
questions, and noting feedback of the participant. Ten 
individual interviews were carried out and ten questionnaires 
were successfully completed. 
TABLE I.  
USER QUESTIONNAIRE 
I 
Usefulness of global trust 
 
I would like to see the global average rating score for entities. 
 
I would like to provide rating scores to entities. 
II 
Usefulness of trust visibility specification 
 
Can you think of a scenario where you would like to give a 
public rating? 
 
Can you think of a scenario where you would like to give an 
anonymous rating? 
 
Can you think of a scenario where you would like to give a 
private rating? 
 
When you provide a private rating, to whom do you think it 
should be displayed? 
III 
Usefulness of personalized and contextualized trust 
 
I would like to rank by myself the entity lists (Actors, Activity 
Spaces, Assets, and Tools). 
 
I would like to share my personal ranking of entities with the 
following people. (None, Friends, People in current learning 
context, Others) 
IV 
Influence of trustee on trust 
 
I find it useful to rate one or several types of entities. (People, 
Assets, Activity Spaces, Tools, None) 
 
C. Results and Discusstion 
All participants stated that the global rating score was 
useful in providing a general assessment of the quality of 
entities, which would assist them to select and filter content 
before going into details of it. They also requested for rating-
based search and top-N recommendations. Some indicated 
that besides rating score, comments would also be valuable 
to give references of quality. Compared to viewing a global 
rating score, 9 out of 10 participants were willing to provide 
rating scores, whereas the remaining one explained that he 
would just like to view the Web content instead of reviewing 
it. The results suggest that with regard to the rating system, 
most users would not only be a viewer or consumer, but also 
a contributor in the rating system. This facilitates fostering a 
collaborative assessment environment in PLE, which is the 
exact objective of the trust mechanism. 
Regarding visibility of trust, 7 participants pointed out 
that they would mostly make ratings public since they 
wanted to share their rating opinions with other community 
members. This is consistent with our previous finding that 
users were shown to be willing to contribute and offer 
guidance to others in the system. As far as anonymous rating 
is concerned, 4 students claimed that they would use it for 
negative rating opinion. We believe that the reason behind 
this is trying to avoid retaliation from the recipient of the 
rating. However, there are also other students indicating that 
anonymous rating would cause unfair cheating rating 
behaviors, since it is possible for a malicious user to abuse 
the anonymous rating to sabotage others. As for the private 
rating, 8 out of 10 participants thought that it was useful for 
confining the rating opinion within a small range of users 
278
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

instead of spreading it among the entire system. It is worth 
mentioning that they also preferred to define by themselves 
the group of users who had access to the private rating 
scores. 
Furthermore, all participants stated that the personalized 
and contextualized ranking feature was helpful for 
prioritizing and organizing entities according to their own 
preferences. They thought that ranking by “drag and drop” 
action was quite practical and convenient. 7 participants 
were willing to share their personalized rankings with others, 
especially with users in the same learning context. While 3 
participants preferred to keep the ranking private, because 
they thought that the personal ranking did not concern others. 
Another interesting finding is that 9 out of 10 participants 
indicated that while they would like to rate assets, activity 
spaces, and tools, they felt uncomfortable to rate people. The 
reason behind this was explained to be the fact that they 
usually did not like to judge others directly since the 
characteristics of a person were multi-dimensional and hence 
difficult to assess with only a single numerical score. Instead, 
they felt more comfortable to evaluate the products or 
contributions of a person, as the quality and utility of items 
were easier to assess. This provides us with some insights as 
to how to improve the trust and reputation metrics for people 
in the future. A possible approach could be to calculate a 
person’s trust and reputation score based on his/her 
contributions and behaviors in the system, rather than 
computing others’ rating opinions for him/her. 
To sum up, the evaluation results reveals that users not 
only accept the proposed trust mechanism as a way to get a 
general assessment of content quality, but also use it for 
representing personalized and contextualized preferences. 
Moreover, users are satisfied with being able to define the 
visibility of their trust opinions. Last but not least, rating 
people directly is not considered as a suitable approach to 
assess the trustworthiness of them. 
VI. 
CONCLUSION AND FUTURE WORK 
The popularity of Web 2.0 social media has brought 
about a large amount of user-generated content. To design 
effective trust and reputation mechanisms that facilitate 
selecting and recommending trustworthy content becomes 
the recent research challenge. Particularly, in PLE platforms 
where 
multi-disciplinary 
resources 
and 
services 
are 
aggregated from heterogeneous sources, there is a clear need 
for personalized and contextualized trust metrics depending 
on different learning goals. In this paper, to comply with the 
specific requirements of PLEs, we explore trust in four 
dimensions: trustor, trustee, context and visibility. A trust 
model has been proposed and implemented within a PLE 
prototype. To evaluate the usefulness of the trust model, a 
user study has been carried out through questionnaires and 
interviews. The results show that users are satisfied with the 
mechanism where trust is tackled not only on a global scale, 
but also on a personal and contextual scale. Being able to 
fully control the audience of trust opinions is also accepted 
as a useful feature. However, suitable trust and reputation 
metrics for people still need to be investigated in the future. 
ACKNOWLEDGMENT 
The research work described in this paper is partially 
funded through the ROLE Integrated Project; part of the 
Seventh 
Framework 
Programme 
for 
Research 
and 
Technological Development (FP7) of the European Union in 
Information and Communication Technologies. 
REFERENCES 
[1] 
A. Josang, “Trust and reputation systems”, Lecture Notes in 
Computer Science, vol. 4677, pp. 209-245, 2007. 
[2] 
O. Casquero, J. Portillo, R. Ovelar, M. Benito, and J. Romo, “iPLE 
Network: an integrated eLearning 2.0 architecture from a university’s 
perspecitve”, Interactive Learning Environments, vol. 18, pp. 293-
308, 2010. 
[3] 
D. Gillet, E.L.-C. Law, and A. Chatterjee, “Personal learning 
environments in a global higher engineering education Web 2.0 
realm”, Education Engineering, pp. 897-906, 2010. 
[4] 
G. Heiberger and R. Harper, “Have you facebooked Astin lately? 
Using technology to increase student involvement”, New Directions 
for Student Services, vol. 124, pp. 19-35, 2008. 
[5] 
 A. Josang, R. Ismail, and C. Boyd, “A survey of trust and reputation 
systems for online service provision”, Decision Support Systems, vol. 
43, pp. 618-644, 2007. 
[6] 
L. Page, S. Brin, and R. Motwani, “The PageRank citation ranking: 
bringing order to the Web”, Technical Report Standford Digital 
Library Technologies Project, 1998. 
[7] 
R. Levien, “Attack resistant trust metrics”, PhD thesis, University of 
California at Berkeley, 1998. 
[8] 
S.D. Kamvar, M.T. Schlosser, and H. Garcia-Molina, “The 
EigenTrust algorithm for reputation management in P2P networks”, 
12th International World Wide Web Conference, pp. 640-651, 2003. 
[9] 
A. Withby, A. Josang, and J. Indulska, “Filtering out unfair ratings in 
Bayesian reputation systems”, International Workshop on Trust in 
Agent Societies (at AAMAS’04), ACM, 2004. 
[10] A. Josang, “A logic for uncertain probabilities”, International Journal 
of Uncertainty, Fuzziness and Knowledge-Based Systems, vol. 9, pp. 
279-311, 2001. 
[11] J. Golbeck, “Trust and nuanced profile similarity in online social 
networks”, ACM Transactions on the Web, vol. 3, 2009. 
[12] F. Bobillo, M. Delgado, and J. Gomez-Romero, “Representation of 
context-dependant knowledge in ontologies: a model and an 
application”, Expert Systems with Application, vol. 35, pp. 1899-
1908, 2008. 
[13] R. Reichle, M. Wagner, M. Ullah Khan, K. Geihs, J. Lorenzo, M. 
Valla, C. Fra, N. Paspallis, and G. A. Papadopoulos, “A 
comprehensive context modeling framework for pervasive computing 
systems”, 8th International Conference on Distributed Applications 
and Interoperable Systems, pp. 281-295, 2008. 
[14] S. El Helou, N. Li, and D. Gillet, “The 3A interaction model: towards 
bridging the gap between formal and informal learning”, 3rd 
International 
Conference 
on 
Advances 
in 
Computer-Human 
Interactions, pp. 179-184, 2010. 
[15] Gadgets 
Specification, 
http://code.google.com/apis/gadgets/docs/spec.html, retrieved Oct. 
2010. 
[16] S. Chiasson, P.C. Van Oorschot, and R. Biddle, “A usability study 
and critique of two password managers”, 15th conference on USENIX 
Security Symposium, vol. 15, pp. 1-16, 2006. 
[17] R. Likert, “A technique for the measurement of attitudes”, Archives 
of Psychology, vol. 140, 1932. 
 
279
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

