Forex Trading using MetaTrader 4 with the Fractal Market Hypothesis
Jonathan Blackledge
School of Electrical Engineering Systems,
Dublin Institute of Technology,
Kevin Street, Dublin 8, Ireland.
Email: jonathan.blackledge@dit.ie
http://eleceng.dit.ie/blackledge
Kieren Murphy
Currency Traders Ireland,
Dublin Docklands Innovation Park,
128-130 East Wall Road Dublin 3, Ireland
Email: kieran@tradersnow.com
http://www.tradersnow.com
Abstract—This paper reports on the results of a research
and development programme concerned with the analysis of
currency pair exchange time series for Forex trading in an
intensive applications and services environment. In particular,
we present some of the preliminary results obtained for Forex
trading using MetaTrader 4 with a new set of trend indicators
deigned using a mathematical model that is based on the
Fractal Market Hypothesis. This includes examples of various
currency pair exchange rates considered over different time
intervals and use of the indicators in a live trading environment
to place a buy/sell order.
Keywords-Economic/Financial systems, Currency pair trad-
ing, Forex markets, Fractal Market Hypothesis, Intensive
applications and services (RIAS)
I. INTRODUCTION
This paper reports on a research and development pro-
gramme undertaken in the Information and Communications
Security Research Group http://eleceng.dit.ie/icsrg which
has led to the launch of a new SME - Currency Traders
Ireland Limited - funded by Enterprise Ireland. Currency
Traders Ireland Limited has been provided with an exclusive
license based on [1] and [2] to develop a new set of
indicators for analysing currency exchange rates and Forex
trading. We consider the background to the approach and
present examples of the results obtained to date.
A. The Problem with Current Economic Models
The principal aim of a ﬁnancial trader is to attempt to
obtain information that can provide some conﬁdence in
the immediate future of a stock. This is often based on
repeating patterns from the past, patterns that are ultimately
based on the interplay between greed and fear. One of the
principal components of this aim is based on the observation
that there are ’waves within waves’ known as Elliot Waves
after Ralph Elliot who was among the ﬁrst to observe this
phenomenon on a qualitative basis in 1938. Elliot Waves
permeate ﬁnancial signals when studied with sufﬁcient detail
and imagination. It is these repeating patterns that occupy
both the ﬁnancial investor and the ﬁnancial systems modeler
alike and it is clear that although economies have undergone
many changes in the last one hundred years, ignoring scale,
the dynamics of market behaviour does not appear to have
changed signiﬁcantly.
In modern economies, the distribution of stock returns
and anomalies like market crashes emerge as a result of
considerable complex interaction. In the analysis of ﬁnancial
time series it is inevitable that assumptions need to be made
with regard to developing a suitable model. This is the most
vulnerable stage of the process with regard to developing a
ﬁnancial risk management model as over simplistic assump-
tions lead to unrealistic solutions. However, by considering
the global behaviour of the ﬁnancial markets, they can be
modeled statistically provided the ‘macroeconomic system’
is complex enough in terms of its network of interconnection
and interacting components.
Market behaviour results from either a strong theoretical
reasoning or from compelling experimental evidence or
both. In econometrics, the processes that create time series
have many component parts and the interaction of those
components is so complex that a deterministic description
is simply not possible. When creating models of complex
systems, there is a trade-off between simplifying and de-
riving the statistics we want to compare with reality and
simulation. Stochastic simulation allows us to investigate
the effect of various traders’ behaviour with regard to the
global statistics of the market, an approach that provides
for a natural interpretation and an understanding of how the
amalgamation of certain concepts leads to these statistics
and correlations in time over different scales. One cause
of correlations in market price changes (and volatility) is
mimetic behaviour, known as herding. In general, market
crashes happen when large numbers of agents place sell
orders simultaneously creating an imbalance to the extent
that market makers are unable to absorb the other side
without lowering prices substantially. Most of these agents
do not communicate with each other, nor do they take
orders from a leader. In fact, most of the time they are
in disagreement, and submit roughly the same amount of
buy and sell orders. This provides a diffusive economy
which underlies the Efﬁcient Market Hypothesis (EMH) and
ﬁnancial portfolio rationalization. The EMH is the basis
for the Black-Scholes model developed for the Pricing of
1
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

Options and Corporate Liabilities for which Scholes won
the Nobel Prize for economics in 1997. However, there is a
fundamental ﬂaw with this model which is that it is based on
a hypothesis (the EMH) that assumes price movements, in
particular, the log-derivate of a price, is normally distributed
and this is simply not the case. Indeed, all economic time
series are characterized by long tail distributions which do
not conform to Gaussian statistics thereby making ﬁnancial
risk management models such as the Black-Scholes equation
redundant.
B. What is the Fractal Market Hypothesis?
The Fractal Market Hypothesis (FMH) is compounded
in a fractional dynamic model that is non-stationary and
describes diffusive processes that have a directional bias
leading to long tail distributions.
The economic basis for the FMH is as follows:
• The market is stable when it consists of investors
covering a large number of investment horizons which
ensures that there is ample liquidity for traders;
• information is more related to market sentiment and
technical factors in the short term than in the long
term - as investment horizons increase and longer term
fundamental information dominates;
• if an event occurs that puts the validity of fundamen-
tal information in question, long-term investors either
withdraw completely or invest on shorter terms (i.e.
when the overall investment horizon of the market
shrinks to a uniform level, the market becomes unsta-
ble);
• prices reﬂect a combination of short-term technical and
long-term fundamental valuation and thus, short-term
price movements are likely to be more volatile than
long-term trades - they are more likely to be the result
of crowd behaviour;
• if a security has no tie to the economic cycle, then there
will be no long-term trend and short-term technical
information will dominate.
Unlike the EMH, the FMH states that information is
valued according to the investment horizon of the investor.
Because the different investment horizons value information
differently, the diffusion of information is uneven. Unlike
most complex physical systems, the agents of an economy,
and perhaps to some extent the economy itself, have an extra
ingredient, an extra degree of complexity. This ingredient
is consciousness which is at the heart of all ﬁnancial risk
management strategies and is, indirectly, a governing issue
with regard to the fractional dynamic model used to develop
the algorithm now being used by Currency Traders Ireland
Limited. By computing an index called the L´evy index,
the directional bias associated with a future trend can be
forecast. In principle, this can be achieved for any ﬁnancial
time series, providing the algorithm has been ﬁnely tuned
with regard to the interpretation of a particular data stream
and the parameter settings upon which the algorithm relies.
II. THE BLACK-SCHOLES MODEL
For many years, investment advisers focused on returns
with the occasional caveat ‘subject to risk’. Modern Portfolio
Theory (MPT) is concerned with a trade-off between risk
and return. Nearly all MPT assumes the existence of a risk-
free investment, e.g. the return from depositing money in a
sound ﬁnancial institute or investing in equities. In order to
gain more proﬁt, the investor must accept greater risk. Why
should this be so? Suppose the opportunity exists to make
a guaranteed return greater than that from a conventional
bank deposit say; then, no (rational) investor would invest
any money with the bank. Furthermore, if he/she could also
borrow money at less than the return on the alternative
investment, then the investor would borrow as much money
as possible to invest in the higher yielding opportunity. In
response to the pressure of supply and demand, the banks
would raise their interest rates. This would attract money
for investment with the bank and reduce the proﬁt made
by investors who have money borrowed from the bank. (Of
course, if such opportunities did arise, the banks would prob-
ably be the ﬁrst to invest savings in them.) There is elasticity
in the argument because of various ‘friction factors’ such
as transaction costs, differences in borrowing and lending
rates, liquidity laws etc., but on the whole, the principle
is sound because the market is saturated with arbitrageurs
whose purpose is to seek out and exploit irregularities or
miss-pricing.
The concept of successful arbitraging is of great im-
portance in ﬁnance. Often loosely stated as, ‘there’s no
such thing as a free lunch’, it means that one cannot ever
make an instantaneously risk-free proﬁt. More precisely,
such opportunities cannot exist for a signiﬁcant length of
time before prices move to eliminate them.
A. Financial Derivatives
As markets have grown and evolved, new trading contracts
have emerged which use various tricks to manipulate risk.
Derivatives are deals, the value of which is derived from
(although not the same as) some underlying asset or interest
rate. There are many kinds of derivatives traded on the
markets today. These special deals increase the number of
moves that players of the economy have available to ensure
that the better players have more chance of winning. To
illustrate some of the implications of the introduction of
derivatives to the ﬁnancial markets we consider the most
simple and common derivative, namely, the option.
1) Options: An option is the right (but not the obligation)
to buy (call) or sell (put) a ﬁnancial instrument (such as a
stock or currency, known as the ‘underlying’) at an agreed
date in the future and at an agreed price, called the strike
price. For example, consider an investor who ‘speculates’
2
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

that the value of an asset at price S will rise. The investor
could buy shares at S, and if appropriate, sell them later at
a higher price. Alternatively, the investor might buy a call
option, the right to buy a share at a later date. If the asset is
worth more than the strike price on expiry, the holder will
be content to exercise the option, immediately sell the stock
at the higher price and generate an automatic proﬁt from the
difference. The catch is that if the price is less, the holder
must accept the loss of the premium paid for the option
(which must be paid for at the opening of the contract). If
C denotes the value of a call option and E is the strike
price, the option is worth C(S, t) = max(S − E, 0).
Conversely, suppose the investor speculates that an asset
is going to fall, then the investor can sell shares or buy
puts. If the investor speculates by selling shares that he/she
does not own (which in certain circumstances is perfectly
legal in many markets), then he/she is selling ‘short’ and
will proﬁt from a fall in the asset. (The opposite of a short
position is a ‘long’ position.) The principal question is how
much should one pay for an option? If the value of the
asset rises, then so does the value of a call option and vice
versa for put options. But how do we quantify exactly how
much this gamble is worth? In previous times (prior to the
Black-Scholes model which is discussed later) options were
bought and sold for the value that individual traders thought
they ought to have. The strike prices of these options were
usually the ‘forward price’, which is just the current price
adjusted for interest-rate effects. The value of options rises in
active or volatile markets because options are more likely to
pay out large amounts of money when they expire if market
moves have been large, i.e. potential gains are higher, but
loss is always limited to the cost of the premium. This gain
through successful ‘speculation’ is not the only role that
options play. Another role is Hedging.
2) Hedging: Suppose an investor already owns shares
as a long-term investment, then he/she may wish to insure
against a temporary fall in the share price by buying puts
as well. The investor would not want to liquidate holdings
only to buy them back again later, possibly at a higher price
if the estimate of the share price is wrong, and certainly
having incurred some transaction costs on the deals. If a
temporary fall occurs, the investor has the right to sell
his/her holdings for a higher than market price. The investor
can then immediately buy them back for less, in this way
generating a proﬁt and long-term investment then resumes.
If the investor is wrong and a temporary fall does not occur,
then the premium is lost for the option but at least the stock
is retained, which has continued to rise in value. Since the
value of a put option rises when the underlying asset value
falls, what happens to a portfolio containing both assets
and puts? The answer depends on the ratio. There must
exist a ratio at which a small unpredictable movement in
the asset does not result in any unpredictable movement
in the portfolio. This ratio is instantaneously risk free. The
reduction of risk by taking advantage of correlations between
the option price and the underlying price is called ‘hedging’.
If a market maker can sell an option and hedge away all the
risk for the rest of the options life, then a risk free proﬁt is
guaranteed.
Why write options? Options are usually sold by banks to
companies to protect themselves against adverse movements
in the underlying price, in the same way as holders do.
In fact, writers of options are no different to holders; they
expect to make a proﬁt by taking a view of the market.
The writers of calls are effectively taking a short position in
the underlying behaviour of the markets. Known as ‘bears’,
these agents believe the price will fall and are therefore also
potential customers for puts. The agents taking the opposite
view are called ‘bulls’. There is a near balance of bears and
bulls because if everyone expected the value of a particular
asset to do the same thing, then its market price would
stabilise (if a reasonable price were agreed on) or diverge (if
everyone thought it would rise). Thus, the psychology and
dynamics (which must go hand in hand) of the bear/bull
cycle play an important role in ﬁnancial analysis.
The risk associated with individual securities can be
hedged through diversiﬁcation or ‘spread betting’ and/or var-
ious other ways of taking advantage of correlations between
different derivatives of the same underlying asset. However,
not all risk can be removed by diversiﬁcation. To some
extent, the fortunes of all companies move with the econ-
omy. Changes in the money supply, interest rates, exchange
rates, taxation, commodity prices, government spending and
overseas economies tend to affect all companies in one way
or another. This remaining risk is generally referred to as
market risk.
B. Black-Scholes Analysis
The value of an option can be thought of as a function of
the underlying asset price S (a Gaussian random variable)
and time t denoted by V (S, t). Here, V can denote a call
or a put; indeed, V can be the value of a whole portfolio or
different options although for simplicity we can think of it
as a simple call or put. Any derivative security whose value
depends only on the current value S at time t and which
is paid for up front, is taken to satisfy the Black-Scholes
equation given by[3]
∂V
∂t + 1
2σ2S2 ∂2V
∂S2 + rS ∂V
∂S − rV = 0
where σ is the volatility and r is the risk. As with other
partial differential equations, an equation of this form may
have many solutions. The value of an option should be
unique; otherwise, again, arbitrage possibilities would arise.
Therefore, to identify the appropriate solution, certain initial,
ﬁnal and boundary conditions need to be imposed. Take for
example, a call; here the ﬁnal condition comes from the
3
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

arbitrage argument. At t = T
C(S, t) = max(S − E, 0)
The spatial or asset-price boundary conditions, applied at
S = 0 and S → ∞ come from the following reasoning:
If S is ever zero then dS is zero and will therefore never
change. Thus, we have
C(0, t) = 0
As the asset price increases it becomes more and more likely
that the option will be exercised, thus we have
C(S, t) ∝ S,
S → ∞
Observe, that the Black-Sholes equation has a similarity
to the diffusion equation but with additional terms. An
appropriate way to solve this equation is to transform it
into the diffusion equation for which the solution is well
known and, with appropriate Transformations, gives the
Black-Scholes formula [3]
C(S, t) = SN(d1) − Eer(T −t)N(d2)
where
d1 = log(S/E) + (r + 1
2σ2)(T − t)
σ
√
T − t
,
d2 = log(S/E) + (r − 1
2σ2)(T − t)
σ
√
T − t
and N is the cumulative normal distribution deﬁned by
N(d1) =
1
√
2π
d1
Z
−∞
e
1
2 s2ds.
The conceptual leap of the Black-Scholes model is to
say that traders are not estimating the future price, but are
guessing about how volatile the market may be in the future.
The model therefore allows banks to deﬁne a fair value of
an option, because it assumes that the forward price is the
mean of the distribution of future market prices. However,
this requires a good estimate of the future volatility σ.
The relatively simple and robust way of valuing options
using Black-Scholes analysis has rapidly gained in popular-
ity and has universal applications. Black-Scholes analysis
for pricing an option is now so closely linked into the
markets that the price of an option is usually quoted in
option volatilities or ‘vols’. However, Black-Scholes analysis
is ultimately based on random walk models that assume
independent and Gaussian distributed price changes and is
thus, based on the EMH.
The theory of modern portfolio management is only
valuable if we can be sure that it truly reﬂects reality for
which tests are required. One of the principal issues with
regard to this relates to the assumption that the markets are
Gaussian distributed. However, it has long been known that
Figure 1.
Financial time series for the Dow-Jones value (close-of-day)
from 02-04-1928 to 12-12-2007 (top), the derivative of the same time series
(centre) and a zero-mean Gaussian distributed random signal (bottom).
ﬁnancial time series do not adhere to Gaussian statistics.
This is the most important of the shortcomings relating
to the EMH model (i.e. the failure of the independence
and Gaussian distribution of increments assumption) and is
fundamental to the inability for EMH-based analysis such
as the Black-Scholes equation to explain characteristics of
a ﬁnancial signal such as clustering, ﬂights and failure
to explain events such as ‘crashes leading to recession.
The limitations associated with the EMH are illustrated in
Figure 1 which shows a (discrete) ﬁnancial signal u(t), the
derivative of this signal du(t)/dt and a synthesised (zero-
mean) Gaussian distributed random signal. There is a marked
difference in the characteristics of a real ﬁnancial signal and
a random Gaussian signal. This simple comparison indicates
a failure of the statistical independence assumption which
underpins the EMH and the superior nature of the L´evy
based model that underpins the Fractal Market Hypothesis.
The problems associated with ﬁnancial modelling using
the EMH have prompted a new class of methods for investi-
gating time series obtained from a range of disciplines. For
example, Re-scaled Range Analysis (RSRA), e.g. [4], [5],
which is essentially based on computing and analysing the
Hurst exponent [6], is a useful tool for revealing some well
disguised properties of stochastic time series such as persis-
tence (and anti-persistence) characterized by non-periodic
cycles. Non-periodic cycles correspond to trends that persist
for irregular periods but with a degree of statistical regularity
often associated with non-linear dynamical systems. RSRA
is particularly valuable because of its robustness in the
presence of noise. The principal assumption associated with
RSRA is concerned with the self-afﬁne or fractal nature
of the statistical character of a time-series rather than the
statistical ‘signature’ itself. Ralph Elliott ﬁrst reported on
the fractal properties of ﬁnancial data in 1938. He was the
4
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

Figure 2.
The ﬁrst and second moments (top and bottom) of the Dow
Jones Industrial Average plotted sequentially.
ﬁrst to observe that segments of ﬁnancial time series data of
different sizes could be scaled in such a way that they were
statistically the same producing so called Elliot waves. Since
then, many different self-afﬁne models for price variation
have been developed, often based on (dynamical) Iterated
Function Systems (IFS). These models can capture many
properties of a ﬁnancial time series but are not based on
any underlying causal theory.
III. FRACTAL TIME SERIES AND RESCALED RANGE
ANALYSIS
A time series is fractal if the data exhibits statistical self-
afﬁnity and has no characteristic scale. The data has no
characteristic scale if it has a PDF with an inﬁnite second
moment. The data may have an inﬁnite ﬁrst moment as well;
in this case, the data would have no stable mean either.
One way to test the ﬁnancial data for the existence of these
moments is to plot them sequentially over increasing time
periods to see if they converge. Figure 2 shows that the ﬁrst
moment, the mean, is stable, but that the second moment, the
mean square, is not settled. It converges and then suddenly
jumps and it is observed that although the variance is not
stable, the jumps occur with some statistical regularity. Time
series of this type are example of Hurst processes; time series
that scale according to the power law,
⟨u(t)⟩t ∝ tH
where H is the Hurst exponent and ⟨u(t)⟩t denotes the mean
value of u(t) at a time t.
H. E. Hurst (1900-1978) was an English civil engineer
who built dams and worked on the Nile river dam project.
He studied the Nile so extensively that some Egyptians
reportedly nicknamed him ‘the father of the Nile.’ The
Nile river posed an interesting problem for Hurst as a
hydrologist. When designing a dam, hydrologists need to
estimate the necessary storage capacity of the resulting
reservoir. An inﬂux of water occurs through various natural
sources (rainfall, river overﬂows etc.) and a regulated amount
needed to be released for primarily agricultural purposes.
The storage capacity of a reservoir is based on the net
water ﬂow. Hydrologists usually begin by assuming that the
water inﬂux is random, a perfectly reasonable assumption
when dealing with a complex ecosystem. Hurst, however,
had studied the 847-year record that the Egyptians had
kept of the Nile river overﬂows, from 622 to 1469. Hurst
noticed that large overﬂows tended to be followed by large
overﬂows until abruptly, the system would then change
to low overﬂows, which also tended to be followed by
low overﬂows. There seemed to be cycles, but with no
predictable period. Standard statistical analysis revealed no
signiﬁcant correlations between observations, so Hurst de-
veloped his own methodology. Hurst was aware of Einstein’s
(1905) work on Brownian motion (the erratic path followed
by a particle suspended in a ﬂuid) who observed that the
distance the particle covers increased with the square root
of time, i.e.
R ∝
√
t
where R is the range covered, and t is time. This relationship
results from the fact that increments are identically and
independently distributed random variables. Hurst’s idea was
to use this property to test the Nile River’s overﬂows for
randomness. In short, his method was as follows: Begin with
a time series xi (with i = 1, 2, ..., n) which in Hurst’s case
was annual discharges of the Nile River. (For markets it
might be the daily changes in the price of a stock index.)
Next, create the adjusted series, yi = xi − ¯x (where ¯x is the
mean of xi). Cumulate this time series to give
Yi =
i
X
j=1
yj
such that the start and end of the series are both zero and
there is some curve in between. (The ﬁnal value, Yn has to
be zero because the mean is zero.) Then, deﬁne the range
to be the maximum minus the minimum value of this time
series,
Rn = max(Y ) − min(Y ).
This adjusted range, Rn is the distance the systems travels
for the time index n, i.e. the distance covered by a random
walker if the data set yi were the set of steps. If we set
n = t we can apply Einstein’s equation provided that the
time series xi is independent for increasing values of n.
However, Einstein’s equation only applies to series that are
in Brownian motion. Hurst’s contribution was to generalize
this equation to
(R/S)n = cnH
where S is the standard deviation for the same n obser-
vations and c is a constant. We deﬁne a Hurst process to
be a process with a (fairly) constant H value and the R/S
is referred to as the ‘rescaled range’ because it has zero
mean and is expressed in terms of local standard deviations.
In general, the R/S value increases according to a power
5
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

law value equal to H known as the Hurst exponent. This
scaling law behaviour is the ﬁrst connection between Hurst
processes and fractal geometry.
Rescaling the adjusted range was a major innovation.
Hurst originally performed this operation to enable him to
compare diverse phenomenon. Rescaling, fortunately, also
allows us to compare time periods many years apart in
ﬁnancial time series. As discussed previously, it is the
relative price change and not the change itself that is of
interest. Due to inﬂationary growth, prices themselves are
a signiﬁcantly higher today than in the past, and although
relative price changes may be similar, actual price changes
and therefore volatility (standard deviation of returns) are
signiﬁcantly higher. Measuring in standard deviations (units
of volatility) allows us to minimize this problem. Rescaled
range analysis can also describe time series that have no
characteristic scale, another characteristic of fractals. By
considering the logarithmic version of Hurst’s equation, i.e.
log(R/S)n = log(c) + Hlog(n)
it is clear that the Hurst exponent can be estimated by
plotting log(R/S) against the log(n) and solving for the
gradient with a least squares ﬁt. If the system were inde-
pendently distributed, then H = 0.5. Hurst found that the
exponent for the Nile River was H = 0.91, i.e. the rescaled
range increases at a faster rate than the square root of time.
This meant that the system was covering more distance than
a random process would, and therefore the annual discharges
of the Nile had to be correlated.
It is important to appreciate that this method makes
no prior assumptions about any underlying distributions, it
simply tells us how the system is scaling with respect to
time. So how do we interpret the Hurst exponent? We know
that H = 0.5 is consistent with an independently distributed
system. The range 0.5 < H ≤ 1, implies a persistent
time series, and a persistent time series is characterized by
positive correlations. Theoretically, what happens today will
ultimately have a lasting effect on the future. The range
0 < H ≤ 0.5 indicates anti-persistence which means that
the time series covers less ground than a random process.
In other words, there are negative correlations. For a system
to cover less distance, it must reverse itself more often than
a random process.
IV. L´EVY PROCESSES
L´evy processes are random walks whose distribution
has inﬁnite moments and ‘long tails’. The statistics of
(conventional) physical systems are usually concerned with
stochastic ﬁelds that have PDFs where (at least) the ﬁrst two
moments (the mean and variance) are well deﬁned and ﬁnite.
L´evy statistics is concerned with statistical systems where
all the moments (starting with the mean) are inﬁnite. Many
distributions exist where the mean and variance are ﬁnite but
Figure 3.
Comparison between a Gaussian distribution (blue) for β =
0.0001 and a L´evy distribution (red) for γ = 0.5 and p(0) = 1.
are not representative of the process, e.g. the tail of the dis-
tribution is signiﬁcant, where rare but extreme events occur.
These distributions include L´evy distributions [7],[8]. L´evy’s
original approach to deriving such distributions is based on
the following question: Under what circumstances does the
distribution associated with a random walk of a few steps
look the same as the distribution after many steps (except
for scaling)? This question is effectively the same as asking
under what circumstances do we obtain a random walk that
is statistically self-afﬁne. The characteristic function P(k)
of such a distribution p(x) was ﬁrst shown by L´evy to be
given by (for symmetric distributions only)
P(k) = exp(−a | k |γ),
0 < γ ≤ 2
where a is a constant and γ is the L´evy index. For γ ≥ 2,
the second moment of the L´evy distribution exists and the
sums of large numbers of independent trials are Gaussian
distributed. For example, if the result were a random walk
with a step length distribution governed by p(x),
γ ≥ 2,
then the result would be normal (Gaussian) diffusion, i.e.
a Brownian random walk process. For γ < 2 the second
moment of this PDF (the mean square), diverges and the
characteristic scale of the walk is lost. For values of γ
between 0 and 2, L´evy’s characteristic function corresponds
to a PDF of the form
p(x) ∼
1
x1+γ ,
x → ∞
A. Long Tails
If we compare this PDF with a Gaussian distribution given
by (ignoring scaling normalisation constants)
p(x) = exp(−βx2)
which is the case when γ
=
2 then it is clear that
a L´evy distribution has a longer tail. This is illustrated
in Figure 3. The long tail L´evy distribution represents a
stochastic process in which extreme events are more likely
when compared to a Gaussian process. This includes fast
moving trends that occur in economic time series analysis.
Moreover, the length of the tails of a L´evy distribution is
determined by the value of the L´evy index such that the
6
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

larger the value of the index the shorter the tail becomes.
Unlike the Gaussian distribution which has ﬁnite statistical
moments, the L´evy distribution has inﬁnite moments and
‘long tails’.
B. L´evy Processes and the Fractional Diffusion Equation
L´evy processes are consistent with a fractional diffusion
equation [9].
σ ∂
∂tu(x, t) = ∂γ
∂xγ u(x, t),
γ ∈ (0, 2]
where σ is the coefﬁcient of diffusion. For unit coefﬁcient
of diffusion, we consider the equation
 ∂γ
∂xγ − ∂
∂t

u(x, t) = δ(x)n(t),
q > 0,
x → 0
where n(t) is ‘white noise’ whose solution is, ignoring
scaling constants, given by
u(t) =
1
t1−1/γ ⊗ n(t)
This solution is consistent with the solution to the fractional
diffusion equation
 ∂2
∂x2 − ∂q
∂tq

u(x, t) = δ(x)n(t),
where γ−1 = q/2 [10] and where q - the ‘Fourier Dimen-
sion’ - is related to the Hurst exponent by q = 2H+1. Thus,
the L´evy index γ, the Fourier Dimension q and the Hurst
exponent H are all simply related to each other. Moreover,
these parameters quantify stochastic processes that have
long tails and thereby by transcend ﬁnancial models based
on normal distributions such as the Black-Scholes model
discussed in Section II. In this paper, we study the behaviour
of q focusing on its predictive power for indicating the
likelihood of a future trend in Forex time series.
V. FOREX MARKET
The Forex or Foreign Exchange market is the largest
and most ﬂuid of the global markets involving trades
approaching 4 Trillion per day. The market is primarily
concerned with trading currency pairs but includes currency
futures and options markets. It is similar to other ﬁnancial
markets but the volume of trade is much higher which
comes from the nature of the market in terms of its short
term proﬁtability. The market determines the relative values
of different currencies and most banks contribute to the
market as do ﬁnancial companies, institutions, individual
speculators and investors and even import/export companies.
The high volume of the Forex market leads to high liquidity
and thereby guarantees stable spreads during a working week
and contract execution with relatively small slippages even
in aggressive price movements. In a typical foreign exchange
transaction, a party purchases a quantity of one currency by
paying a quantity of another currency.
The Forex is a de-centralised ‘over the counter market’
meaning that there are no agreed centres or exchanges which
an investor needs to be connected to in order to trade. It is
the largest world wide network allowing customers trade 24
hours per day usually from Monday to Friday. Traders can
trade on Forex without any limitations no matter where they
live or the time chosen to enter a trade. The accessibility
of the Forex market has made it particularly popular with
traders and consequently, a range of Forex trading software
has been developed for internet based trading. In this paper,
we report on a new indicator based on the interpretation
of q computed via the Hurst exponent H that has been
designed to optimize Forex trading through integration into
the MetaTrader 4 system.
VI. METATRADER 4
MetaTrader 4 is a platform for e-trading that is used by
online Forex traders [11] and provides the user with real
time internet access to most of the major currency exchange
rates over a range of sampling intervals including 1 min,
4 mins, 1 hour and 1 day. The system includes a built-in
editor and compiler with access to a user contributed free
library of software, articles and help. The software utilizes
a proprietary scripting language, MQL4 [12] (based on C),
which enables traders to develop Expert Advisors, custom
indicators and scripts. MetaTrader’s popularity largely stems
from its support of algorithmic trading. This includes a range
of indicators and the focus of the work reported in this
paper, i.e. the incorporation of a new indicator based on
the approach considered in Section III and Section IV.
A. Basic Algorithm - The ‘q-Algorithm’
Given a stream of Forex data un,
n = 1, 2, ..., N where
N deﬁnes the ‘look-back’ window or ‘period’, we consider
the Hurst model
un = cnH
which is linearised by taking the logarithmic transform to
give
log(un) = log(c) + H log(n)
where c is a constant of proportionality
The basic algorithm is as follows:
1) For a moving window of length N (moved one el-
ement at a time) operating on an array of length L,
compute qj = 1 + 2Hj,
j = 1, 2, ..., L − N using
the Orthogonal Linear Regression Algorithm [13] and
plot the result.
2) For a moving window of length M compute the
moving average of qj denoted by ⟨qj⟩i and plot the
result in the same window as the plot of qj.
3) Compute the gradient of ⟨qj⟩i using a different user
deﬁned moving average window of length K and a
forward differencing scheme and plot the result.
7
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

4) Compute the second gradient of ⟨qj⟩i after applying
a moving average ﬁlter using a centre differencing
scheme and plot the result in the same window.
B. Fundamental Observations
The second gradient is computed to provide an estimate
of the acceleration associated with moving average charac-
teristics of qj. However, the gradient of ⟨qj⟩i denoted by
⟨qj⟩′
i provides the most signiﬁcant behaviour in terms of
assessing the point in time at which a trend is likely to occur,
in particular, the points in time at which ⟨qj⟩′
i crosses zero.
The principal characteristic is compounded in the following
observation:
⟨qj⟩′
i > 0 correlates with an upward trend
⟨qj⟩′
i < 0 correlates with a downward trend
where a change in the polarity of ⟨qj⟩′
i < 0 indicates
a change in the trend subject to a given tolerance T. A
tolerance zone is therefore established | ⟨qj⟩′
i |∈ T such
that if the signal ⟨qj⟩′
i > 0 enters the tolerance zone, then
a bar is plotted indicating the end of an upward trend and
if ⟨qj⟩′
i < 0 enters the tolerance zone then a bar is plotted
indicating the end of a downward trend.
C. Examples Results
Figure 4 shows an example of the MetaTrader GUI
with the new indicators included operating on the sig-
nal for the Euro-USD exchange rate with 1 min sampled
data. The vertical bars clearly indicate the change in a
trend for the window of data provided in this example.
The parameters settings (N, M, K, T) for this example are
(512, 10, 300, 0.1). Figure 5 shows a sample of results for
the Euro-GBP exchange rate for 1 hour sampled data with
parameter settings (512, 10, 300, 0.5) and Figure 6 shows
a sample for 1 day sampled data using the parameter set
(512, 10, 300, 1.0). In each case, a change in the gradient
correlates with a change in the trend of the time series in a
way that is reproducible at all scales.
VII. BENIFITS OF THE q-ALGORITHM
For FOREX data q(t) varies between 1 and 2 as does γ
for q in this range since γ−1(t) = q(t)/2. As the value
of q increases, the L´evy index decreases and the tail of
the data therefore gets longer. Thus as q(t) increases, so
does the likelihood of a trend occurring. In this sense, q(t)
provides a measure on the behaviour of an economic time
series in terms of a trend (up or down) or otherwise. By
applying a moving average ﬁlter to q(t) to smooth the data,
we obtained a signal ⟨q(t)⟩(τ) that provides an indication of
whether a trend is occurring in the data over a user deﬁned
window (the period). This observation reﬂects a result that
is a fundamental kernel of the Fractal Market Hypothesis,
namely, that a change in the L´evy index precedes a change
Figure 4.
MetaTrader 4 GUI for new indicators. Top window: Euro-
USD exchange rate signal for 1 min sampled data using Japanese Candles
(Green=up; Red=down); Center window: qj (cyan) and moving average of
qj (Green); Bottom window: ﬁrst (red) and second (cyan) gradients of the
moving average for (N, M, K, T) = (512, 10, 300, 0.1).
Figure 5.
MetaTrader 4 GUI for new indicators. Top window: Euro-
GBP exchange rate signal for 1 hour sample data using Japanese Candles
(Green=up; Red=down); Center window: qj (cyan) and moving average of
qj (Green); Bottom window: ﬁrst (red) and second (cyan) gradients of the
moving average for (N, M, K, T) = (512, 10, 300, 0.5)
Figure 6.
MetaTrader 4 GUI with new indicators. Top window: Euro-
GBP exchange rate signal for 1 day sampled data using Japanese Candles
(Green=up; Red=down); Center window: qj (cyan) and moving average of
qj (Green); Bottom window: ﬁrst (red) and second (cyan) gradients of the
moving average for (N, M, K, T) = (512, 10, 300, 3.0)
8
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

in the ﬁnancial signal from which the index has been
computed (from past data). In order to observe this effect
more clearly, the gradient ⟨q(t)⟩′(τ) is taken. This provides
the user with a clear indication of a future trend based on
the following observation: if ⟨q(t)⟩′(τ) > 0, the trend is
positive; if ⟨q(t)⟩′(τ) < 0, the trend is negative; if ⟨q(t)⟩′(τ)
passes through zero a change in the trend may occur. By
establishing a tolerance zone associated with a polarity
change in ⟨q(t)⟩′(τ), the importance of any indication of
a change of trend can be regulated in order to optimise a
buy or sell order. This is the principle basis and rationale
for the ‘q-algorithm.
VIII. CONCLUSION
The Fractal Market Hypothesis has many conceptual and
quantitative advantages over the Efﬁcient Market Hypothesis
for modelling and analysing ﬁnancial data. One of the most
important points is that the Fractal Market Hypothesis is
consistent with an economic time series that include long
tails in which rare but extreme events may occur and, more
commonly, trends evolve. In this paper we have focused on
the use of the Hypothesis for modelling Forex data and have
shown that by computing the Hurst exponent, an algorithm
can be designed that appears to accurately predict the upward
and downward trends in Forex data over a range of scales
subject to appropriate parameter settings and tolerances.
The optimisation of these parameters can be undertaken
using a range of back-testing trials to develop a strategy
for optimising the proﬁtability of Forex trading. In the trials
undertaken to date, the system can generate a proﬁtable
portfolio over a range of currency exchange rates involving
hundreds of Pips1 and over a range of scales providing the
data is consistent and not subject to market shocks generated
by entirely unpredictable effects that have a major impact on
the markets. This result must be considered in the context
that the Forex markets are noisy, especially over smaller
time scales, and that the behaviour of these markets can,
from time to time, yield a minimal change of Pips when
⟨q(t)⟩′(τ) is within the tolerance zone establish for a given
currency pair exchange rate.
The use of the indicators discussed in this paper for Forex
trading is an example of a number of intensive applications
and services (RIAS) being developed for ﬁnancial time
series analysis and forecasting. MetaTrader 4 is just one of
a range of ﬁnancial risk management systems that are being
used by the wider community for de-centralised market
trading, a trend that is set to increase throughout the ﬁnancial
services sector given the current economic environment. The
current version of MetaTrader 4 described in this paper
is undergoing continuous improvements and assessment,
details of which can be obtained from TradersNow.com.
1A Pip (Percentage in point) is the smallest price increment in Forex
trading.
ACKNOWLEDGMENT
Professor J M Blackledge is supported by the Science
Foundation Ireland and Mr K Murphy is supported by
Currency Traders Ireland through Enterprise Ireland. Both
authors are grateful to Dublin Institute of Technology and
to the Institute’s ‘Hothouse’ for its support with regard to
Licensing the Technology and undertaking the arrangements
associated with the commercialisation of the Technology to
License described in [1], [2].
REFERENCES
[1] http://www.dit.ie/hothouse/media/dithothouse/
techtolicensepdf/Financial%20Risk%20Management.pdf
[2] http://www.dit.ie/hothouse/technologiestolicence/videos/
ictvideos/
[3] F. Black and M. Scholes, The Pricing of Options and Cor-
porate Liabilities, Journal of Political Economy, Vol. 81(3),
637-659, 1973.
[4] H. Hurst, Long-term Storage Capacity of Reservoirs, Trans.
of American Society of Civil Engineers, Vol. 116, 770-808,
1951.
[5] B. B. Mandelbrot and J. R. Wallis, Robustness of the Rescaled
Range R/S in the Measurement of Noncyclic Long Run
Statistical Dependence, Water Resources Research, Vol. 5(5),
967-988, 1969.
[6] B. B. Mandelbrot, Statistical Methodology for Non-periodic
Cycles: From the Covariance to R/S Analysis, Annals of
Economic and Social Measurement, Vol. 1(3), 259-290, 1972.
[7] Shlesinger, M. F., Zaslavsky, G. M. and Frisch U. (Eds.), L´evy
Flights and Related Topics in Physics, Springer 1994.
[8] Nonnenmacher T. F., Fractional Integral and Differential
Equations for a Class of L´evy-type Probability Densities, J.
Phys. A: Math. Gen., Vol. 23, L697S-L700S, 1990.
[9] Abea, S. and Thurnerb, S., Anomalous Diffusion in View of
Einsteins 1905 Theory of Brownian Motion, Physica, A(356),
Elsevier, 403-407, 2005.
[10] Blackledge, J. M., Application of the Fractional Diffusion
Equation for Predicting Market Behaviour, IAENG Interna-
tional Journal of Applied Mathematics, Vol. 40, Issue 3, 130
-158, 2010.
[11] MetaTrader 4 Trading Platform,
http://www.metaquotes.net/en/metatrader4
[12] MQL4 Documentation,
http://docs.mql4.com/
[13] Nonlinear Regression and Curve Fitting: Orthogonal Regres-
sion, http://www.nlreg.com/orthogonal.htm
9
INTENSIVE 2011 : The Third International Conference on Resource Intensive Applications and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-135-9

