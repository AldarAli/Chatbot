 
 
Ideating XAI: An Exploration of User’s Mental Models of an AI-Driven 
Recruitment System Using a Design Thinking Approach 
 
Helen Sheridan 
School of Computer Science 
TU Dublin 
Dublin, Ireland 
Email: D20128656@mytudublin.ie 
 
 
Dympna O’Sullivan 
School of Computer Science 
TU Dublin 
Dublin, Ireland 
Email: dympna.osullivan@tudublin.ie 
 
 
Emma Murphy 
School of Computer Science 
TU Dublin 
Dublin, Ireland 
Email: emma.x.murphy@tudublin.ie 
Abstract— Artificial Intelligence (AI) is playing an important 
role in society including how vital, often life changing decisions 
are made. For this reason, interest in Explainable Artificial 
Intelligence (XAI) has grown in recent years as a means of 
revealing the processes and operations contained within what 
is often described as a black box, an often-opaque system 
whose decisions are difficult to understand by the end 
user.  This paper presents the results of a design thinking 
workshop with 20 participants (computer science and graphic 
design students) where we sought to investigate users' mental 
models when interacting with AI systems. Using two personas, 
participants were asked to empathise with two end users of an 
AI driven recruitment system, identify pain points in a user’s 
experience and ideate on possible solutions to these pain points. 
These tasks were used to explore the user’s understanding of 
AI systems, the intelligibility of AI systems and how the inner 
workings of these systems might be explained to end users. We 
discovered that visual feedback, analytics, and comparisons, 
feature highlighting in conjunction with factual, counterfactual 
and principal reasoning explanations could be used to improve 
user’s mental models of AI systems. 
Keywords - Artificial Intelligence; Explainable Artificial 
Intelligence; Design Thinking; User-Centred AI. 
I. 
 INTRODUCTION 
AI is reforming the way that many processes and services 
are delivered in society. From deciding who is granted 
access to credit, who gains a place in third level education to 
which CV is chosen to progress to interview for 
employment [1]. Complex algorithms processing big data 
sets, which would otherwise be beyond the scope of human 
processing, are often making life-changing decisions with 
little human intervention and with even less explanation. 
This has given rise to an emerging field of XAI in which the 
results of AI systems and algorithms can be understood by 
humans. Of the XAI solutions which currently exist, many 
are designed by software developers for other software 
developers to explain how computer code and algorithms 
work [2]. Such approaches often rely on developers’ own 
“intuition of what constitutes a ‘good’ explanation” [3]. 
Some useful solutions have been developed around text 
classification including the TextPlanation demonstrator 
which uses graphical means to display the results for 
different Machine Learning (ML) libraries including LIME, 
SHAP, LRP, SKATER and ELI5 [4] and the XPlainIT tool 
which visually explains the decision-making process of deep 
learning models [5].  Few XAI solutions are aimed at the 
end users of AI systems. This can be problematic when we 
consider the diversity of users who engage with AI systems, 
many of whom may have no technical knowledge of such 
systems. Other modalities have been explored such as the 
potential of virtual agents [6] and saliency based 
explainability models [7], which show potential and 
highlight areas of further research. To better understand end 
users’ mental models of AI systems, cross collaboration and 
a more user-centred approach have been suggested [8]-[10], 
as well as drawing from Human Computer Interaction (HCI) 
philosophy and psychology [9]. Ultimately, understanding 
people informs explaining AI [9].  
This paper seeks to describe our investigation into users’ 
mental models for AI and ideate XAI solutions using cross 
collaborative, interdisciplinary participants using a design 
thinking methodology. Design thinking workshops were 
conducted using an AI design problem statement within a 
relevant discipline - recruitment, that could be well 
understood by lay users. Design Thinking activities were 
carried out with participants from both graphic design and 
computer science backgrounds which were used to explore 
how users understood the proposed AI system and to 
uncover blind spots in their understanding and associated 
challenges.  We hoped to explore what users’ “internal 
representations” [11] of AI systems that might be based on 
their real-world experiences and build on this to develop 
ideas as to how these AI systems might be more usefully 
explained. The rest of this paper is structured as follows: In 
Section II, we describe related work on Design Thinking 
and mental models, in Section III, we describe our approach 
to ideating XAI using design thinking, in Section IV, we 
describe the results of the design thinking session including 
users’ approaches to solve AI system pain points. We 
conclude by highlighting areas for future work.  
II. 
BACKGROUND 
2.1 Design Thinking 
Over the course of the last century, the professional 
practice of design has evolved to include a much wider 
1
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

 
 
range of disciplines including addressing social problems, 
business management and within the world of information 
technology design. It has been suggested that those who are 
non-designers could benefit from thinking like designers 
[12]. One approach which has emerged within the field of 
user experience design to help bridge this gap is design 
thinking. Design thinking can be described as a problem-
solving approach which prioritises users’ needs using a non-
linear or iterative process with well-defined stages: 
empathise, define, ideate, prototype, test [25]. Our study 
focuses primarily on two stages: empathising and ideation 
as two of the most useful stages for determining users’ 
mental models. Further research will concentrate on other 
phases. Fundamental to design thinking is the concept of 
empathy, connecting with those who use our products or 
services on a deeper level by considering what a user might 
do, say, think and how they might feel whilst engaging with 
a product or service. Persona development and empathy 
mapping are two design thinking activities which can be 
used to facilitate this [15] in conjunction with pain point 
identification, big ideas ideation and prioritisation [16].  
2.2 Mental Models 
Mental models describe what a user believes they know 
about a system such as an information system. The ultimate 
goal of any software designer or developer is to build a 
system where users can build accurate and as a result useful 
mental models [17]. In essence mental models refer to a 
user’s expectation of how a system should work [18].  In the 
case of predictable systems within digital technology the 
theory of mental models has proven useful [19]. However, 
within AI where systems are complex, less predictable and 
change over time this approach can be difficult to apply. It 
has been argued that explainability and comprehensibility, 
with regard to user interaction, should employ the use of 
specific use cases, putting the user at the centre of XAI [20]. 
As well as the ethical need for explanations in AI, 
legislation such as the EUs General Data Protection 
Regulation (GDPR), the USAs Algorithmic Accountability 
Act 2022 and the UKs Digital Regulation Plan demonstrate 
that lawmakers realise the importance of accountability and 
transparency of algorithms [21]-[23]. 
III. 
PARTICIPANTS 
We conducted a design thinking workshop with students 
from an Irish College of Further Education. University 
ethical approval for the workshop was sought in advance 
and consent forms acquired. Inclusion criteria for the study 
included expertise in Computer Science and/or Design. 
Participants were invited to partake via email. The final 
participants included 20 students. Prior to the workshop, a 
Microsoft Forms survey was distributed to establish 
demographics and their knowledge, if any, of AI, XAI and 
Design Thinking. 20 participants in total were divided into 4 
groups of 5 participants. 
Group 1: 2 designers & 3 computer scientists, 5 males: 
Andrew Wilson Persona. 
Group 2: 2 designers & 3 computer scientists, 1 female & 4 
males: Andrew Wilson Persona. 
Group 3: 3 designers & 2 computer scientists, 3 females & 
2 males: Maria Atkins Persona. 
Group 4: 2 designers & 3 computer scientists, 5 males: 
Maria Atkins Persona. 
The participants comprised 11 computer science students 
and 9 design students supporting our interdisciplinary, 
collaborative approach [9]-[12]. 11 participants identified as 
undergraduate students while 9 identified as mature student 
/ professional returned to education. 11 participants were 
aged 18-24, 5 were aged 25-34 and 3 were aged 35-54. 4 
participants were female and 16 were male. See Figure 1. 4 
groups of 5 participants were formed for 1 design thinking 
workshop. 
 
                                Figure 1.  Participant Profile. 
IV. 
METHODS 
4.1 Persona Design 
It has been estimated that at least three quarters of all 
CVs submitted for jobs in the US are processed by AI [14]. 
Efficiency and cost savings are the main motives for 
employing AI in candidate selection; however, a recent 
report from Harvard Business School showed that 88% of 
employers agree that suitable candidates are vetted out of 
the system because they do not match exact criteria [29]. 
 
After selecting the problem domain, 2 design problem 
statements were presented which introduced participants to 
2 personas: How can we help Maria (a recruiter) understand 
the CV filtering systems she is using and ensure possible 
suitable candidates aren’t slipping through the net? And, 
how can we help Andrew (a job seeker) understand the 
process involved in how his CV is being screened for 
interview selection and increase his confidence in the 
system? Personas are an important tool which are used to 
align designers and developers to user experience and in at 
least some settings can be used to great effect [13]. To better 
understand end user problems related to AI systems for 
employment and recruitment, we designed two personas 
reflecting differing user experiences. Andrew Wilson was 
designed as a job seeker engaging with a recruitment 
application whereas Maria Atkins was designed as a 
2
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

 
 
recruiter using the application for processing candidates for 
interview. See Figure 2. 
 
 
 
Figure 2. Personas referenced during workshops [30][31]. 
Andrew is a recent highly qualified computer science 
graduate but has some characteristics which may be 
considered atypical, for example, his relatively older age 
and his background when compared to other university 
graduates. These characteristics were by design as such 
features may exacerbate historical biases in datasets used by 
AI systems [1]-[14]. Maria was designed to reflect the 
experiences of many working in the recruitment sector 
where algorithms are now commonly used to filter 
candidates 
without 
providing 
explanations 
of 
why 
candidates are selected or not [1]. 
4.2 Design Thinking  
The design thinking process begins with empathising, 
followed by pain point definition and finally ideation and 
evaluation.  
4.2.1 Empathy mapping & As is scenario 
Participants engaged in two empathising activities 
1. Empathy mapping: considering persona’s thinking, 
feeling, saying and doing 
2. As is scenario: Identification of steps and persona’s 
thinking, feeling and doing 
These activities are to facilitate pain point identification.  
4.2.2 Pain Point Identification 
Pain point identification was carried out using 5 sticky 
dots per participant. This was followed by a playback or 
presentation of each group's main findings. 
4.2.3 Big ideas & Prioritisation 
Ideation in the form of big ideas and prioritisation 
follows pain point identification. This involves: 
1. Grouping of similar pain points 
2. Identification of 4 pain points 
3. Design of 3 solutions and 1 absurd solution for 
each pain point 
4. Voting using 5 sticky dots on most feasible and 
important solutions 
5. Prioritisation using XY grid, X Axis = feasibility 
for us, Y Axis = importance to the user. This 
categorises solutions into no brainers (High 
Importance to the user & High Feasibility for us), 
big bets (High Importance to the user & Low 
Feasibility for us), unwise (Low Importance for the 
user & Low Feasibility for us), utilities (Low 
Importance for the user & High Feasibility for us).  
4.3 Data Collection and Analysis 
At each stage of the design thinking workshop, data was 
collected using digital photographs of each activity sheet 
with post its and voting sticky dots included. Playbacks of 
critical moments were recorded for transcription post 
workshop. The workshop concluded with a short group 
interview with questions designed to ascertain participants' 
engagement with the processes and to further explore their 
mental models regarding XAI. Audio was also recorded of 
post workshop interviews. Content analysis followed 
identifying common categories linked to pain points. 
 
V. 
RESULTS 
Results are divided into two parts. Firstly, we present an 
overview of the findings from the design thinking activities 
which includes participants' responses to empathy mapping 
and as is scenarios to identify pain points in users' 
engagement with AI. We follow with a content analysis of 
participants “big ideas” or ideation linked to pain points 
identified earlier. We interpret the findings of this 
analysis with an emphasis on presenting common categories 
identified during workshop exercises. 
  
To 
categorise 
our 
results 
more 
effectively, we 
combined the findings for each persona. Findings for groups 
1 and 2, those that empathised with Andrew Wilson, were 
grouped together as were findings for groups 3 and 4, who 
empathised with Maria Atkins. 
5.1 Empathy Map & As is Scenario Groups 1 & 2 
Groups 1 & 2 associated the process of making job 
applications and continually being rejected as being a 
negative experience, which is to be expected. Emotions such 
as 
“Depressed”, 
“Upset”, 
“Angry” 
and 
“Unmotivated” featured predominantly. Empathy mapping 
was followed by an As Is Scenario where groups broke 
Andrew's process into steps and delved further into the 
thoughts, feelings and actions associated with each. Group 1 
broke a job application process for Andrew into the 
following steps: search, apply, receive replies, analyse, 
revise CV and call or reapply. Group 2 broke a job 
application process for Andrew into the following steps: 
Revise CV, Internship application, email the companies 
about what he should do and look outside this country.  
3
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

 
 
5.2 Pain Point Identification 
Voting followed using sticky dots where each participant 
used 5 sticky dots to vote on the areas of most pain for our 
persona. Both groups identified similar pain points which 
included the process of applying and reapplying, continually 
revising CV, receiving a negative response and lack of 
feedback. 
 
 
           Figure 3. Graphical Representation of Empathy Map Group 4 [30]. 
5.3 Empathy Map & As is Scenario Groups 3 & 4 
Groups 3 & 4 associated Maria’s engagement with the 
recruitment system as being opaque and confusing. They 
described Maria as feeling “Confused”, ``Powerless” and 
having a sense of “Guilt”. See Figure 3. 
 
 
Figure 4.  Graphical Representation of  As is Scenario with Pain Point 
Voting Group 4. 
   To further empathise with Maria an As Is Scenario 
exercise followed. Group 3 broke Maria’s steps into the 
following stages: logs into system, researches, documents 
her concerns, contacts management, voices concerns. Group 
4 took a slightly different approach and looked at Maria’s 
initial steps in dealing with both successful and unsuccessful 
candidates. Group 4 steps included: review successful 
applicants, manually send out successful emails, review 
unsuccessful applicants, message unsuccessful applicants, 
call the IT person, inform senior management of concerns. 
Although slightly different, both groups ended with Maria 
documenting her concerns and voicing them to those in 
authority in the hope that a solution can be found. See 
Figure 4. 
5.4 Pain Point Identification 
Both groups continued to the next activity, pain point 
voting using 5 sticky dots each. Figure 4 represents the 
findings of Group 4 with pain point voting represented and 
4 pain point areas circled. Similar pain points emerged from 
both groups which included the process of researching or 
reviewing 
the 
system, 
reviewing, 
and 
messaging 
unsuccessful applicants, identifying who can help and 
conveying her concerns. See Figure 5. 
 
 
   Figure 5. Graphical  Representation of  Pain Point Identification Group 4. 
5.5 Big Ideas & Prioritisation Groups 1 &2 
In response to these pain points groups 1 & 2 began the 
process of big ideas ideation and prioritisation. Each 
participant designed 3 solutions for each pain point and one 
absurd solution. After a second round of voting using 5 
sticky dots each the most promising big ideas were 
identified. These were then placed on a prioritisation grid 
the main findings of which can be seen in Table I. 
5.6 Big Ideas & Prioritisation Groups 3 & 4 
Groups 3 & 4 carried out the same process of ideating on 
big ideas to solve the pain points for our persona Maria 
which were identified earlier. This followed with voting on 
the potential of these ideas and placement on a prioritisation 
grid. Table II documents the main findings of this process. 
   Participants' final task, playback of big ideas and 
prioritisation gave an opportunity for each group to explain 
in more detail their big ideas and reasoning for their choice 
of placement on the prioritisation grid.  
   We consolidated findings from our design thinking 
workshop and conducted a categorisation exercise to cluster 
or group common big ideas into similar topic areas. Our 
findings identified three categories associated with each 
persona and interestingly two overlapping categories for 
each. We coded each big idea as follows: 
4
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

 
 
• 
Visual feedback & analytics: 01 
• 
Visual comparisons: 02 
• 
Highlight problems & offer chances to rectify: 03 
• 
Criteria manipulation / tracking: 04 
 
 
Figure 6. Categories for both personas to understand AI system [30][31]. 
Visual feedback and analysis and visual comparisons 
were considered necessary for both Andrew and Maria to 
understand the AI-driven recruitment system. Highlighting 
problems and offering chances to rectify were considered 
necessary for Andrew and criteria manipulation and tracking 
was considered necessary for Maria. See Figure 6. Tables I 
& II document big idea categorisation.  
TABLE I. BIG IDEAS, PRIORITY, CATEGORY GROUPS 1 & 2 
Pain Point > Big Idea > Priority > Category 
Pain Point 
Big Idea 
Priority 
Category 
Negative 
replies & 
Rejection 
Call for interview 
No 
brainer 
01 
Ask for feedback 
No 
brainer 
01 
Revise CV 
Compare past & present CV 
No 
brainer 
02 
Highlight problems on CV 
Big bet 
03 
Score in categories 
Big bet 
01 
Check CV similarity stand 
out 
No 
brainer 
03 
Search & 
Apply 
Create dashboard of 
applicants & show success 
Big bet 
01 
Template CVs 
Utilities 
02 
Guides 
Utilities 
02 
Reapply / 
Apply 
again 
Visual results 
No 
brainer 
01 
Rating (stars) 
No 
brainer 
01 
AI that creates data that helps 
person change parts in CV 
Big bet 
03 
Make it fun / a game 
Big bet 
03 
Ask for 
feedback 
Analytics / visual feedback 
No  
brainer 
01 
Virtual Agent / Concierge 
Utilities 
01 
Clippy 
Unwise 
01 
Pain Point > Big Idea > Priority > Category 
Pain Point 
Big Idea 
Priority 
Category 
Visual CV feedback 
No 
brainer 
01 
TABLE II.  BIG IDEAS, PRIORITY, CATEGORY GROUPS 3 & 4 
Pain Point > Big Idea > Priority > Category 
Pain Point 
Big Idea 
Priority 
Category 
Researching / 
Reviewing 
system 
Provide visual statistics to 
explain AI system's decision 
No 
brainer 
01 
Category / criteria selection 
or manipulation 
No 
brainer 
04 
Hire someone else to fix 
system 
Big bet 
 
Reviewing & 
messaging 
unsuccessful  
Multiple job to candidate 
criteria matching  
 
No 
brainer 
02, 04 
Candidate pooling 
No 
brainer 
02, 04 
Double validation: checking 
successful and unsuccessful 
candidates' data for errors or 
untruths 
No 
brainer 
04 
Bias tracking 
Big bet 
04 
Theme identification related 
to unsuccessful applicants 
No 
brainer 
04 
Inform applicant how to 
improve 
No 
brainer 
02 
Identify who 
can help 
Clippy 
No 
brainer 
01 
Virtual agent  
Utilities 
01 
Inform senior 
management 
of concerns 
Visual Record 
No 
brainer 
 
01 
Audit report to share with 
management 
No 
brainer 
01 
Compare / track old system 
with new one 
No 
brainer 
02 
   One area of interest which we used to interpret our 
findings was the participants' use of drawing and visual 
ideation to explain their concepts in how both personas 
might better understand AI.  
 
Figure 7. Participants visualisation of visual feedback & analytics. 
       Since drawing is encouraged as an integral part of 
design thinking activities, participants’ visual interpretations 
5
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

 
 
of how AI might be explained resulted in thought-provoking 
ideas which informed our allocation of categories [24]. For 
example, participants described visual analytics showing a 
job applicant’s score in categories related to keyword 
matching. “Here are analytics with tables and charts so you 
can see if you want to hire someone…some sort of visuals or 
charts to say this is your rating for your employment history 
or this is your rating for your software skills…stars even”. 
See Figure 7. Highlighting perceived flaws or poor keyword 
matching in an applicant's data was also considered.“We 
looked at comparing past and present CVs and highlighting 
problems on a CV so if the person’s CV is lacking or they 
have something written on it that they shouldn’t, highlight 
those” See Figure 8. 
 
Figure 8. Participants visualisation of highlighting problems & offering 
chances to rectify. 
VI. 
DISCUSSION 
Our findings support research into the use of feature 
highlighting using factual explanations, for example, why 
the system produced certain results, versus counterfactual 
explanations, why the system produced one result over 
another, to better explain AI to users [26]. When a user’s 
expectation is matched to the output of the system, in this 
case a job applicant believes they are suitable for a role or a 
recruiter expects certain applicants to receive an interview, 
factual explanations should be used. In the case of our 
personas, Andrew would expect CV rating, analytics or 
visual feedback if his application was successful or 
unsuccessful: “You scored 1 star in team working skills” or 
“You scored 20% in years’ experience”. However, a more 
useful explanation would be found in a counterfactual 
explanation when Andrew’s expectation of the system is not 
met. Explanations highlighting why one decision was made 
over another would better explain the system’s decisions 
[27]. “You were unsuccessful as your score of 1 star in team 
working skills should be at least 5 to progress to the next 
stage”. This can be further explained using principal reason 
explanations where the factors which dominated the 
system’s decision are explained but allow the user to act and 
receive a different result [27] which in Andrew’s case would 
include being given an explanation highlighting features on 
his application which determined a negative result and 
allowing updates and reapplication. As such “You were 
unsuccessful for this job application because you only have 
one previous role which included team working skills. You 
should have at least 5 team working roles. Is this 
information 
correct?”. 
For 
our 
recruiter, 
Maria, 
counterfactual explanations could be used to explain 
candidate selection not only for those that are successful but 
also for those that are unsuccessful and principal reason 
explanations to allow her to manipulate criteria and allow 
for a different result [30]. For example, “No female 
candidates were offered interviews due to CV gaps of over 6 
months. Would you like to disregard CV gaps?” Although 
dealing with the domain of recruitment our findings could 
be useful within many other domains which utilise AI for 
data processing. Interestingly many of these mental models 
align with Nielsen’s usability heuristics such as visibility of 
system status, match between system and real world and 
help users recognise, diagnose, and recover from errors [28]. 
Challenges 
encountered 
during 
workshops 
included 
logistical difficulties related to audio recording of large 
groups and photographing participants work. Audio tests 
carried out preworkshop concluded that one recording 
device located at each group, in this instance 4 audio 
recording devices, were necessary. Also, we found that 
recording of playbacks at significant stages, 
after 
empathising and pain point identification and after big ideas 
and prioritisation, was crucial in understanding participants 
contributions. Essential to successful data collection was the 
photographing of participants worksheets after each stage. 
We also engaged workshop facilitators to ensure that groups 
were focused on the problem statement, personas’ 
engagement with the AI system, rather than solving the 
issue of recruitment in general. 
VII. CONCLUSION 
We present an exploration of user’s mental models of an 
AI driven recruitment system where we put the user at the 
centre of our study. By engaging a design thinking approach 
with  interdisciplinary participants, we discovered novel 
approaches 
for 
participants 
to 
communicate 
their 
understanding of AI systems and for researchers to 
understand their internal representations. Future work in this 
area should also centre around usability heuristics, more 
commonly referenced in HCI and user interface design, 
which should  also be applied to more complex systems 
such as AI.  
REFERENCES 
[1] Executive Office of the President, “Big Data: A Report on 
Algorithmic Systems, Opportunity, and Civil Rights”, Executive 
Office of the President, The White House, Washington, May 2016, 
pp. 8–9.   
[2] T. Miller, P. Howe, and L. Sonenberg, “Explainable AI: 
Beware of Inmates Running the Asylum Or: How I Learnt to Stop 
Worrying and Love the Social and Behavioural Sciences”, Dec 
2017, arXiv:1712.00547 [cs.AI].  
6
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

 
 
[3] T. Miller, “Explanation in artificial intelligence: Insights from 
the social sciences”, Artificial Intelligence, vol. 267, February 
2019, pp. 1-38.  
[4] CeADAR, “TextPlanation: Explainable Machine Learning for 
Text Data”, Applied Research Group, UCD, 2022, [Online]. 
Available 
from: 
https://ceadar.ie/blog/explainable-machine-
learning-for-text-data/ [Retrieved: July, 2022] 
[5] S. McKeever, I. Ullah, A. Ríos, and V. Galla, “XPlainIT, 
Explainable Artificial Intelligence,” ceADAR, Applied Research 
Group, 
UCD, 
2022, 
[Online]. 
Available 
from: 
https://ceadar.ie/blog/xplainit-explainable-ai-for-deep-models/ 
[Retrieved: July, 2022] 
[6] K. Weitz, D. Schiller, R. Schlagowski, T. Huber, and E. André, 
“Let me explain!”: exploring the potential of virtual agents in 
explainable AI interaction design”, Journal on Multimodal User 
Interfaces, 2021, pp. 87–98, https://doi.org/10.1007/s12193-020-
00332-0 
[7] S. Z. S. Samuel, V.  Kamakshi,  N. Lodhi, and N. C. Krishnan, 
“Evaluation of Saliency-based Explainability Methods”, 24 Jun 
2021, arXiv:2106.12773v1 [cs.LG].  
[8] A. Abdul, J. Vermeulen, D. Wang, B. Y. Lim, and M. 
Kankanhalli, 
“Trends 
and 
Trajectories 
for 
Explainable, 
Accountable and Intelligible Systems: An HCI Research Agenda”, 
CHI 2018, April 21–26, 2018, pp. 1 – 18, Montréal, QC, Canada  
[9] D. Wang, Q Yang, A. Abdul, and B. Y. Lim, “Designing 
Theory-Driven User-Centric Explainable AI”, CHI 2019, May 4–9, 
2019, pp. 1 – 15, Glasgow, Scotland, UK  
[10] Q. V. Liao, D. Gruen, and S. Miller, “Questioning the AI: 
Informing Design Practices for Explainable AI User Experiences”, 
CHI 2020, April 25–30, 2020, pp. 1-15,  Honolulu, HI, USA  
[11] T. Kulesza, S. Stumpf, M. Burnett, and I. Kwan, “Tell Me 
More? The Effects of Mental Model Soundness on Personalizing 
an Intelligent Agent”, CHI 2012, May 5–10, 2012, pp. 1-10, 
Austin, Texas, US  
[12] T. Brown and B. Katz, “Change by design”, Journal of 
Product Innovation Management, May 2011, vol. 28, issue 3, pp. 
381 - 383. 
[13] J. Grudin and J. Pruitt, “Personas, participatory design and 
product development: An infrastructure for engagement.” In Proc. 
PDC, vol. 2, 2002, June, pp. 144-152. 
[14] H. Schellman, “Out of sight: the algorithms running our lives: 
Finding it hard to get a job? Robot recruiters might be to blame”, 
2022, [Online]. Available from: https://www.theguardian.com/us-
news/2022/may/11/artitifical-intelligence-job-applications-screen-
robot-recruiters 
[15] W. V. Siricharoen, “Using empathy mapping in design 
thinking process for personas discovering.” In Context-Aware 
Systems and Applications, and Nature of Computation and 
Communication, 2020, pp. 182-191. Springer, Cham. 
[16] IBM, “Learn the Enterprise Design Thinking Framework - 
Enterprise 
Design 
Thinking” 
[Online]. 
Available 
from: 
https://www.ibm.com/design/thinking/page/framework/keys/playb
acks [Retrieved: July, 2022] 
[17] J. Nielsen, “Mental Models and User Experience Design”, 
2010, 
[Online]. 
Available 
from: 
https://www.nngroup.com/articles/mental-models/ [Retrieved: 
July, 2022] 
[18] P.N. Johnson-Laird, “Mental Models” Cambridge University 
Press, 1983. 
[19] D. Norman, “Some observations on mental models”, In 
Mental Models. Lawrence Erlbaum Associates, 1983. 
[20] A. Kirsch, “Explain to whom? Putting the User in the Center 
of Explainable AI.”  Proceedings of the First International 
Workshop on Comprehensibility and Explanation in AI and ML 
2017 co-located with 16th International Conference of the Italian 
Association for Artificial Intelligence (AI*IA 2017), 2017, Bari, 
Italy. Hal-01845135. 
[21] Dept for Digital Culture Media & Sport, “Policy paper Digital 
Regulation: Driving growth and unlocking innovation”, 2022, 
[Online] 
Available 
from: 
https://www.gov.uk/government/publications/digital-regulation-
driving-growth-and-unlocking-innovation/digital-regulation-
driving-growth-and-unlocking-innovation#our-digital-regulation-
principles [Retrieved: July, 2022] 
[22] Federal Trade Commission, “Algorithmic Accountability 
Act”, 
2022, 
[Online] 
Available 
from: 
https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Ac
countability%20Act%20of%202022%20Bill%20Text.pdf 
[Retrieved: July, 2022] 
[23] EPRS | European Parliamentary Research Service Scientific 
Foresight Unit (STOA), “The impact of the General Data 
Protection Regulation (GDPR) on artificial intelligence”, 2020 
[Online] 
Available 
from: 
https://www.europarl.europa.eu/RegData/etudes/STUD/2020/6415
30/EPRS_STU(2020)641530_EN.pdf [Retrieved: July, 2022] 
[24] C. R. Becker, “UX sketching: the missing link. I recognize 
this will make me sound… | by Chris R Becker | UX Collective”, 
2019, [Online] Available from: https://uxdesign.cc/ux-sketching-
the-missing-link-4ac2f5bcc8be [Retrieved: July, 2022] 
[25] Stanford, Hasso Plattner, Institute of Design at Stanford, “An 
Introduction to Design Thinking Process Guide” (N.D.) [Online] 
Available 
from: 
https://web.stanford.edu/~mshanks/MichaelShanks/files/509554.pd
f [Retrieved: July, 2022] 
[26] M. Riviero and S. Thill, “That's (not) the output I expected!” 
On the role of end user expectations in creating explanations of AI 
systems” Artificial Intelligence, 2021, Volume 298, 103507 
[27] S. Barocas, A. D. Selbst, and M.  Raghavan, “The Hidden 
Assumptions Behind Counterfactual Explanations and Principal 
Reasons.” In Conference on Fairness, Accountability, and 
Transparency (FAT* ’20), January 27–30, 2020, Barcelona, Spain. 
ACM, 
New 
York, 
NY, 
USA, 
10 
pages. 
https: 
//doi.org/10.1145/3351095.3372830 
[28] J. Nielsen, “10 Usability Heuristics Applied to Complex 
Applications“, 
2021, 
[Online] 
Available 
from: 
https://www.nngroup.com/articles/usability-heuristics-complex-
applications/ [Retrieved: July, 2022] 
[29] J. B. Fuller, M. Raman, E. Sage-Gavin, and K. Hines, 
“Hidden Workers: Untapped Talent”, 2021, [Online]. Available 
from 
https://www.hbs.edu/managing-the-future-of-
work/Documents/research/hiddenworkers09032021.pdf 
[Retrieved: July, 2022] 
[30] E. Dantes, “Woman Holding a Laptop”, 2020, [Online] 
Available from: https://www.pexels.com/photo/woman-holding-a-
laptop-4347368/ [Retrieved: June, 2022] 
[31] L. Kelley,  “Man Wearing Black Jacket Sitting on Gray Stone 
Near 
River”, 
2016, 
[Online] 
Available 
from: 
https://www.pexels.com/photo/man-wearing-black-jacket-sitting-
on-gray-stone-near-river-192468/ [Retrieved: June, 2022] 
 
7
Copyright (c) IARIA, 2023.     ISBN:  978-1-61208-999-7
CENTRIC 2022 : The Fifteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

