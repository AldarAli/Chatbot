Dynamic Local Search Algorithm for Solving Traveling Salesman Problem 
 
Kambiz Shojaee Ghandeshtani 
Low-Power High-Performance Nanosystems Lab. 
University of Tehran 
Tehran, Iran 
E-mail: k.shojaee@ece.ut.ac.ir 
Seyed Mohammad Hossein Seyedkashi 
Dept. of Mechanical Engineering 
Tarbiat Modares University 
Tehran, Iran 
E-mail: seyedkashi@modares.ac.ir 
Mojtaba Behnam Taghadosi 
Mechatronics Laboratory (LIM) 
Politecnico di Torino 
Torino, Italy 
E-mail: mojtaba.behnam@polito.it 
Keyvan Shojaii 
Dept. of Electrical Engineering 
Sadjad Institute of Higher Education 
Mashhad, Iran 
E-mail: keyvan_shojaii@yahoo.com
 
 
Abstract— In this paper, developing a new local search 
approach based on 2-Opt operator and its implementation for 
TSP solution in SA algorithm (as a global search algorithm) is 
purposed. It is shown that more favorable results are expected 
by meaningful correlation between local search approach and 
global search algorithm in annealing process. In order to 
compare the performance of the proposed operator with the 2-
Opt as a basic operator, 24 benchmarks of TSP is selected from 
TSPLIB and both algorithms are implemented for 20 times for 
solving these benchmarks. The results show the improvement 
of error average for about 27%. 
Keywords- TSP; Local search; 2-Opt; Global search; 
Simulated annealing 
I. 
 INTRODUCTION 
Traveling Salesman Problem is the problem of searching 
the shortest closed route (shortest Hamiltonian cycle) among 
N cities, the cities which the traveling salesman has passed 
one and only one time and in the end has returned to the 
start point. TSP problem is one of the combinatorial 
optimization problems and includes all aspects of a 
combinatorial optimization problem in addition to a very 
simple definition. Needed time to solve this problem using 
algebraic algorithms is a non-polynomial function of the 
problem size [1]. This is why this problem is also 
categorized in NP-complete problems. Traveling sales man 
problem has many practical applications in science and 
engineering such as vehicle routing, integrated circuits 
design, automated guided vehicles scheduling, robot control 
and etc. 
In recent decades, many researchers have tried to solve 
TSP problem using metaheuristic methods such as Neural 
Network (NN) [2-4], Simulated Annealing (SA) [5-12], 
Genetic Algorithm (GA) [13-15], Tabu Search (TS) [16-18], 
Ant Colony Optimization (ACO) [19-21], and Particle 
Swarm Optimization (PSO) [22-23]. Also, integration of 
these algorithms is widely used, i.e., integration of 
Simulated Annealing and Genetic Algorithm [6, 11], 
Simulated Annealing and Neural Network [7] and Simulated 
Annealing and Particle Swarm Optimization algorithm [23].  
In this paper, solving the traveling salesman problem 
using modified 2-Opt  [25] operator in Simulated Annealing 
algorithm is proposed. Consequently, a new operator for 
local searching is proposed. So in Section 2, basic simulated 
annealing algorithm is defined. In Section 3, with 
redefinition of 2-Opt operator, a dynamic operator is 
introduced according to the existing conditions in simulated 
annealing algorithm. Simulation results and their comparison 
on presented benchmarks in TSPLIB site [25] are presented 
in Section 4 and the authors’ suggestions and conclusion are 
given in the final section. 
II. 
BASIC SIMULATED ANNEALING ALGORITHM 
The idea of simulated annealing was first presented by 
Nicholas Metropolis in 1953 as a modified Monte Carlo 
integration method [26]. He resembled the paper to the 
material which is made by cooling after heating of them. 
Simulated annealing for integrated optimization applications 
such as Travelling Salesman Problem was introduced the 
first time by Kirkpatrick et al. [5] in 1983 inspired from 
Metropolis algorithm. This algorithm is adapted from the 
cooling process which metal is heated to its melting point 
and then cools gradually. This temperature decrease is such 
that the system is approximately in thermodynamic 
equilibrium. During the process of gradual reduction of 
temperature, system becomes more regular and moves 
toward steady state with minimum energy. The main 
Metropolis scheme in determination of temperature and the 
initial energy state of thermodynamic system is that if the 
energy changes are negative, new structure (energy and 
temperature) will be accepted but if the energy changes are 
positive, the acceptation is subjected to the Boltzmann 
distribution function with exp(-ΔΕ/κBΤ) in which κB is 
Boltzmann's constant with positive value [27]. The whole 
process will be repeated until the energy is minimized and 
the system reaches a steady state. This algorithm is suitable 
for solving mixed discrete problem and complicated 
53
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

nonlinear problem. In simulated annealing algorithm, 
cooling schedule parameters have role of process controlling 
in the search algorithm. Cooling schedule has three 
parameters which are:  
1) Initial temperature (T0). 
2) Convergence criterion or Freezing temperature (TF).  
3) Cooling function.  
In this algorithm, if initial and final temperature are 
appropriately defined and temperature reduction is selected 
so that the slope of temperature reduction curve is less  
than the slope of TK+1=T0/(1+log(k+1)), then simulated 
annealing algorithm will converge to the absolute minimum 
when the number of iterations (k) tends to infinity [28] but 
the temperature reduction based on this slope requires a  
lot of computational times. So faster cooling functions are 
used 
such 
as 
TK+1=α.TK 
in 
which 
0.8<α<1 
or  
TK+1=TK/(1+log(k+1)). The number of temperature change 
steps from melting temperature to freezing point will have a 
considerable 
reduction 
using 
these 
functions 
and 
subsequently the probability of passing through suitable 
temperature range for optimum search will also decrease.  
Therefore, in each temperature, it is tried to give 
sufficient search time to the algorithm in suitable 
temperature range by defining several iterations in inner 
search loop including new generation, evaluation and 
decision making. In the algorithm, the number of repetitive 
frequencies in a constant temperature is named Markov 
Chain Length. What distinguishes this algorithm in discrete 
or continuous problems is how it generates a new generation 
based on the current generation. In continuous problems, 
some definitions such as neighborhood radius are used for 
production of new generation in a neighborhood of the 
current generation, so that the next generation will be 
produced by determination of random changes around the 
variables of the current generation with value of the 
neighborhood radius. In simulated annealing process, 
neighborhood radius is reduced proportional to temperature 
reduction in order to increase convergence speed. The same 
production of new generation is performed in discrete 
problems using some operators which generate the next 
generation implicit in a radius of the neighborhood of 
current generation. These operators are also called Move 
Set. Some of the effective operators in generation of discrete 
problems such as Traveling salesman are the following. In a 
TSP problem we need a means of representing the tour. 
Each tour can be described by a permuted list of the 
numbers 1 to N, which represents the cities in TSP. 
1) Switching: Randomly selects two nodes from tour and 
replaces with each other. 
2) Translation: randomly selects a portion of a tour and 
enters between another randomly selected node.  
3) Inversion: Or 2-Opt which is a state of k-Opt 
operator. In 2-Opt move, the tour is broken into 2 
parts, then the 2 parts are reconnects in the other 
possible way. 
4) Lin-Kernigan, which is a kind of variable-Opt, was 
presented in 1973 [29] and many researchers 
have tried for efficient implementation of this 
operator. One of the most efficient LK operators is 
proposed by Helsguan [30], which employs a number 
of important innovations including sequential 5-opt 
moves and the use of sensitivity analysis to direct the 
search.  
In fact, these operators are used as local search 
approaches in global search approaches such as Tabu search, 
Simulated annealing and Genetic algorithm. 
III. 
DYNAMIC 2-OPT 
In this paper, a new operator inspired by 2-Opt and the 
neighborhood radius concept in generation of continuous 
problems is developed. 2-Opt is used as the base operator in 
definition of this operator but in this new definition, the 
operator’s behavior will change dynamically according to 
the behavior of algorithm in search process. Kirkpatrick et 
al. [5] have emphasized that simulated annealing algorithm 
will show a more efficient behavior in its intelligent search 
process in the temperature range of the annealing process, 
called as intermediate temperatures. With this explanation, it 
will be seen in TSP problem solving that the algorithm is 
not able to do direct search in initial stages of algorithm and 
initial temperatures, and will make mistake in its 
orientation. But over time and its entrance to the algorithm 
intermediate temperature range, it will have a suitable 
orientation for achieving the global minimum in addition to 
have the probability of passing through local minimums and 
hill-climbing ability. After temperature reduction and 
passing through intermediate range it will be seen that in the 
simulated annealing algorithm is only able to perform minor 
changes in TSP problem solving to improve goal function. 
In definition of the new operator, different steps of the 
search algorithm has been considered and change ranges of 
the 2-Opt operator is restricted according to each step and 
proportional to its requirements. 
In this method, 2-Opt operator starts dynamically from 
its local search behavior at the beginning of the algorithm 
and with reduction of effective amplitude in its inversing 
operation performs a better search according to the 
algorithm progress and temperature reduction in comparison 
with its normal operation. In fact, the idea of such definition 
from local search operator of SA algorithm is how this 
algorithm converges to the absolute minimum in its search 
process. In SA algorithm, hilling up possibility is reduced 
by passing time. In fact searching with long steps in the 
search space of a problem has less chance for acceptance. 
Thus, acceptance chance and convergence to the improved 
results have been provided by reduction of inversion 
amplitude in 2-Opt operator. 
In definition of 2-Opt operator, two random numbers  
(i, j) are produced which their generation amplitude is the 
number of cities in TSP. then the tour sequence is reversed 
between these 2 nodes. In fact, in Dynamic 2-Opt both nodes 
are not selected randomly. i is a random number and j is a 
random number in neighborhood radius of i. Using this 
technique, both indices for reversing operation will have 
correlation with each other in addition to randomly selection.  
54
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

This correlation quantity increases with temperature 
reduction. At the beginning of the SA algorithm when the 
temperature is high, neighborhood radius is equal to half 
number of cities (N/2) in Traveling Salesman problem and 
the behavior of 2-Opt operator is like normal condition. 
 
0
10
20
30
40
50
60
70
0
10
20
30
40
50
60
70
 
Figure 1. Sample Tour for eil51 at the beginning of SA algorithm 
0
10
20
30
40
50
60
70
0
10
20
30
40
50
60
70
 
Figure 2. Improved by Dynamic 2-Opt in one operation 
But with temperature decrease in next steps, this 
neighborhood radius will reduce with a multiplication of 
0.9. Dynamic 2-Opt operator Pseudo-Matlab code is 
illustrated as follows. 
NewTour =  Tour; 
i = round(rand*N + 0.5); 
j = round((rem((rand*(N/2)*NR + i) , N)) + 0.5); 
2-Opt_Index = (min([ i ; j]):max([ i ; j])); 
NewTour(2-Opt_Index) = fliplr(Tour(2-Opt_Index)); 
Where: 
N = Number of cities in Traveling Salesman problem. 
NR = Neighborhood Radius. 
With this method in lower temperatures j will be 
generated in nearer radius to i and will have a narrower 
search space. Therefore, the operator’s behavior will be 
dependent to the algorithm’s temperature and will change 
dynamically during the search process based on the 
algorithm‘s condition. In other words, with this operator a 
correlation is developed between local search algorithm and 
global search algorithm which will result in a more 
intellectual search.  
For instance, Figure 1 illustrates eil51 TSP benchmark. 
In this figure there is a Tour at the beginning of the SA 
algorithm. Figure 2 shows the results of Dynamic 2-Opt 
when operates in Tour which is shown in Figure 1. By this 
move set, the tour length is improved by 10% in one 
operation (Tour length in Figure 1 is 1123, which is 
improved to 1016 in Figure 2). 
Figure 3 shows a sample condition near the end of SA 
algorithm which is improved by Dynamic 2-Opt in Figure 4. 
In these four figures, we explain the requirement of SA 
algorithm to improve the tours according to the algorithm's 
progress. In other words, the SA algorithm needs to have a 
long step in 2-Opt operator to improve the search results but 
during the algorithm progress it is required to reduce the 
neighborhood radius in generation of 2-opt index in order to 
improve the local cross. At the beginning of search process, 
when the neighborhood radius is N/2, the possible amplitude 
for generation of j is such that all other nodes are possible to 
be selected. But by passing time in search process, the 
amplitude of generation of node j (second selection) will 
decrease proportional to temperature reduction and will 
make inversion possible in smaller range. This matter is 
provable in discussion of the algorithm’s behavior in TSP 
problem solving in such a way that at the beginning of the 
algorithm, the inversion operation with wide change ranges 
is efficient in passing through local minimums and proper 
orientation in optimal tour selection and also the reduction in 
inversion change range in operator will provide the 
possibility of minor changes at the end of the process. 
 
0
10
20
30
40
50
60
70
0
10
20
30
40
50
60
70
 
Figure 3. Sample Tour for eil51 near the end of SA algorithm 
The results obtained by this operator are compared with 
2-Opt normal performance in the next section, which 
declares the acceptable performance of this operator in SA 
algorithm. 
IV. 
RESULT AND COMPARISON 
In this section, performance of two operators “2-Opt” 
and “Dynamic 2-Opt” is  compared  in  simulated annealing 
55
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

0
10
20
30
40
50
60
70
0
10
20
30
40
50
60
70
 
Figure 4. Figure 3 improved by Dynamic 2-Opt in one operation 
algorithm process under the same conditions. The initial 
temperature is defined so that the initial acceptance rate in a 
first Markov chain is about 50%. Final temperature is 
defined in a condition that the acceptance condition in 
internal loop will not be concluded for any variable during 
two consecutive Markov Chain. Also the cooling function 
Tk+1=α*Tk is used in this algorithm so that α=0.9. The 
proposed algorithm is implemented for two operators of  
2-Opt and Dynamic 2-Opt for 24 benchmarks listed in 
TSPLIB [46] for 20 times and the results are compared in 
Table I with [7] and [9]. 
It is quite easy to realize that using the new operator 
(Dynamic 2-Opt) has improved performance of SA 
significantly. The optimal values given by the TSBLIB site, 
for each case are listed in the second column of the table. 
We have compared the best, the worst and the average of 
the error in the results obtained by the new approach with 
other results given by other works (if the best and/or the 
worst cases are available). The error percentage is calculated 
by: 
δ = 100 (E – E*) / E* 
where E* is the optimal (minimum) energy. 
The first method chosen for comparison is the 
Constructive 
Optimizing 
Neural 
Network 
(CONN) 
proposed in [2], for which it is claimed that all runs has led 
to the same results, so that the best, the worst and the 
average of  the solutions are the same. We have compared 
our results with the best and the average error percentages 
of the results given in [4] for its memetic neural network. 
Table I demonstrates an enhancement in the results of 
SA algorithm implemented by "Dynamic 2-Opt" operator 
rather than regular "2-Opt" operator. As it's clear to see, the 
results of implementing the "Dynamic 2-Opt", has gotten 
0.35 percentage improvement in the average error of the 
best results, 0.49 percentage improvement in the average 
error of the average results and finally 1.1 percentage 
improvement in the average error of the worst results. 
Also Table I states that the results of SA algorithm with 
regular 2-Opt operator have obtained 2.14 percentage 
improvement in the average error of the average results (for 
24 benchmarks) in comparison with CONN method, which 
indicates the high ability of SA algorithm for solving these 
kind of problems. As well, the 2.71 percentage improvement 
in implementing the SA algorithm with Dynamic 2-Opt 
operator toward CONN method, predicates the possibility of 
enhancement in SA algorithm. 
As well, Table I includes the comparison between 
"memetic neural network" results [4] and SA algorithm 
results implemented by "2-Opt" and "Dynamic 2-Opt" 
operators that respectively indicates 1.41 and 1.88 
percentage improvements in the average error of the best 
results and 1.76 and 2.41 percentage improvements in the 
average error of the average results. 
To accomplish our comparison, we have added another 
set of methods from  [11], in which 11 methods are run on 24 
benchmarks from lin105 to rat783. For brevity purpose, the 
problems are categorized into 3 groups, namely: small, 
medium and large size benchmarks. The results are given in 
Table II, where the average of the average error in each 
group is shown. For detailed explanation of each method 
see  [11]. 
In [10], the result of ABD (Annealed Bounded Demon) 
algorithm is better than the results of other SA algorithm's 
family. In this paper, the SA algorithm with implementing 
"2-Opt" and "Dynamic 2-Opt" operators respectively has 
obtained 1.05 and 1.28 percentage improvements in the 
average error of the average results for small size problems.  
In medium size problems, the SA algorithm with "2-Opt" 
operator shows weaker results than ABD algorithm (0.41 
percentage error more) but with using the "Dynamic 2-Opt" 
operator, the amount of improvement in the average error of 
the average results has reached 0.44 percentage that it's an 
evidence of good performance of proposed algorithm.  
For solving this problem a PIV computer with 1.8GHz 
CPU and 512MB RAM is used in MATLAB7.7 environment. 
As it shown in Table II, with definition of Dynamic 2-
Opt the average of SA algorithm results are improved 27% 
which shows the effect of the redefinition of 2-opt operator 
in this paper on efficiency of SA algorithm. 
V. 
CONCLUSION 
In this paper, a new definition of 2-Opt operator was 
presented, which will result in correlation of local search 
approach and global search algorithm. Using Simulated 
Annealing algorithm and proportional with temperature 
reduction in this algorithm, a new operator is designed for 
generation of new generation in neighborhood of current 
generation, so that its operation is variable during search 
process and will orient the local search method according to 
temperature reduction and the algorithm’s correlation. This 
algorithm is implemented on 24 benchmarks of TSPLIB site 
for 20 times and its results are categorized in order to be 
compared with the base algorithm and other algorithms’ 
results. The obtained results show the improvement of SA 
algorithm efficiency up to 27% which proved the 
performance of this operator.  
Application of this operator in global search algorithms 
such as Ant colony or Genetic algorithm may have a good 
effect on their efficiency. Also since recent researches are 
focused on integrated metaheuristic methods, an integration 
of this method with others may result in better conclusions. 
56
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

TABLE I. COMPARISON BETWEEN D2-OPT AND OTHER METHODS FOR 24 BENCHMARKS  
(THE AVERAGE Δ OF THE AVERAGE ERROR IN 20 RUNS) 
TSP Benchmark 
Optimal Solution 
With 2-Opt 
With Dynamic 2-Opt 
CONN  [7] 
Memetic 
neural 
network  [9] 
Best  δ 
Average δ 
Worst   δ 
Best  δ 
Average δ 
Worst  δ 
Best  δ 
Average δ 
Worst  δ 
Best  δ 
Average  δ 
lin105 
14379 
0 
0.9 
2.55 
0 
0.18 
0.87 
0.38 
0.38 
0.38 
0 
0.34 
pr107 
44303 
0.05 
0.51 
1.51 
0 
0.3 
0.71 
2.77 
2.77 
2.77 
0.14 
0.67 
pr124 
59030 
0 
0.68 
2.22 
0 
0.29 
0.88 
1.74 
1.74 
1.74 
0.26 
1.52 
pr136 
96772 
0.67 
1.98 
3.53 
0.37 
1.42 
2.33 
2.27 
2.27 
2.27 
0.73 
3.1 
pr144 
58537 
0 
0.94 
4.02 
0 
0.93 
4.15 
2.34 
2.34 
2.34 
- 
- 
pr152 
73682 
0.21 
0.85 
2.15 
0 
0.91 
3.93 
0.79 
0.79 
0.79 
1.57 
2.6 
u159 
42080  
0 
1.62 
3.8 
0 
2.38 
6.34 
- 
- 
- 
- 
- 
rat195 
2323 
1.76 
3.18 
4.69 
0.6 
2.04 
3.18 
5.64 
5.64 
5.64 
4.69 
6.89 
d198 
15780 
0.2 
0.86 
1.66 
0.37 
1.22 
2.64 
4.16 
4.16 
4.16 
- 
- 
pr226 
80369 
0.99 
1.68 
4.62 
0.58 
1.31 
1.94 
1.93 
1.93 
1.93 
- 
- 
gil262 
 2378 
1.35 
2.34 
3.24 
0.92 
1.98 
2.94 
- 
- 
- 
- 
- 
pr264 
49135 
0.54 
2.3 
5.45 
0 
2.11 
5.62 
3.58 
3.58 
3.58 
- 
- 
pr299 
48191 
0.5 
1.92 
4.32 
0.6 
1.69 
3.92 
4.8 
4.8 
4.8 
- 
- 
lin318 
42029 
1.32 
2.77 
4.23 
1.2 
2.45 
3.05 
- 
- 
- 
3.63 
5.51 
rd400 
15281 
1.26 
2.66 
4.25 
0.84 
2.13 
3.30 
5.77 
5.77 
5.77 
- 
- 
pr439 
107217 
1.06 
3.44 
7.31 
1.05 
1.78 
3.24 
6.03 
6.03 
6.03 
- 
- 
Pcb442 
50778 
2.06 
4.68 
7.00 
1.86 
2.81 
3.68 
5.77 
5.77 
5.77 
3.57 
6.08 
d493 
35002 
1.58 
2.47 
5.07 
1.21 
2.10 
2.82 
5.83 
5.83 
5.83 
- 
- 
u574 
36905 
1.86 
2.75 
4.46 
1.40 
2.04 
3.03 
5.90 
5.90 
5.90 
4.09 
5.08 
rat575 
6773 
3.47 
3.94 
6.84 
1.89 
2.91 
4.08 
6.72 
6.72 
6.72 
4.31 
5.47 
p654 
34643 
0.67 
1.81 
5.94 
0.80 
1.70 
3.48 
4.13 
4.13 
4.13 
2.51 
5.13 
d657 
48912 
2.59 
3.36 
4.15 
1.82 
2.50 
3.32 
7.58 
7.58 
7.58 
3.97 
5.02 
u724 
41910 
3.16 
3.62 
4.07 
1.93 
2.44 
3.11 
6.97 
6.97 
6.97 
4.64 
5.36 
rat783 
8806 
2.12 
3.05 
5.59 
1.45 
2.87 
3.70 
7.59 
7.59 
7.59 
5.46 
5.95 
Average 
1.14 
2.26 
4.28 
0.79 
1.77 
3.18 
4.41 
4.41 
4.41 
2.83 
4.19 
With 2-Opt 
- 
- 
- 
1.14 
2.26 
4.28 
1.18 
2.27 
4.35 
1.42 
2.43 
With D2-Opt 
0.79 
1.77 
3.18 
- 
- 
- 
0.80 
1.70 
3.04 
0.95 
1.78 
 
 
ACKNOWLEDGMENT 
This work is supported by Nano-Age Technology Group 
in Mashhad, Iran (www.nanoage.ir). 
REFERENCES 
[1] 
C. H. Papadimitriou, "The Euclidean Traveling Salesman Problem is 
NP-complete", Theoretical Computer Science, 4(3): 237-244, 1977. 
[2] 
M. Saadatmand-Tarzjan, M. Khademi, M. R. Akbarzadeh-T., and H. 
A. Moghaddam, "A Novel Constructive-Optimizer Neural Network 
for the Traveling Salesman Problem", IEEE Transaction on Systems, 
Man and Cybernetics, Part B: Cybernetics, Vol. 37, No. 4, pp.754-
770 Aug. 2007. 
[3] 
Sitao Wu and T. W. S. Chow, "Self-Organizing and Self-Evolving 
Neurons: A New Neural Network for Optimization", IEEE 
Transaction on Neural Networks, Vol. 18, No. 2, pp. 385-396, Mar. 
2007. 
[4] 
J. C. Creput and A. Koukam, “A memetic neural network for the 
Euclidean traveling salesman problem”, Neurocomputing Accepted 
22 Jan. 2008. 
[5] 
S. Kirkpatrick, C. D. Gelatt, Jr., and M. P. Vecchi, "Optimization by 
Simulated Annealing", SCIENCE, Volume 220, Number 4598, pp. 
671-680, 13 May 1983. 
[6] 
F. T. Lin, C. Y. Kao, and C. C. Hsu, "Applying the Genetic Approach 
to Simulated Annealing in Solving Some NP-Hard Problems", IEEE 
Transaction on Systems, Man and Cybernetics, Vol. 23. No. 6, pp. 
1752-1767, Nov./Dec. 1993. 
[7] 
L. Wang, S. Li, F. Tian, and X. Fu, "A Noisy Chaotic Neural Network 
for Solving Combinatorial Optimization Problems: Stochastic Chaotic 
Simulated Annealing", IEEE Transaction on Systems, Man and 
Cybernetics, Part B:Cybernetics, Vol. 34, No.5, pp. 2119-2125, 2004. 
57
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

TABLE II. COMPARISON OF D2-OPT WITH OTHER METHODS GIVEN IN [10]  
(THE AVERAGE OF THE AVERAGE ERROR IN 20 RUNS) 
Algorithms in [10] 
Average Error in 
Small Size 
 
Average Error in 
Medium Size 
SA (Simulated Annealing) 
2.76 
3.25 
TA (Threshold Accepting) 
5.37 
4.18 
RRT (Record-to-Record 
Travel) 
4.22 
6.79 
BD (Bounded Demon) 
5.26 
4.44 
RBD (Randomized Bounded 
Demon) 
4.33 
9.38 
AD (Annealed Demon) 
3.24 
3.27 
RAD (Randomized Annealed 
Demon) 
2.82 
4.38 
ABD (Annealed Bounded 
Demon) 
2.65 
2.77 
RABD (Randomized 
Annealed Bounded Demon) 
2.63 
3.64 
ADH (Annealed Demon 
Hybrid) 
2.97 
2.95 
ABDH (Annealed Bounded 
Demon Hybrid) 
2.69 
2.89 
MSSA (the proposed method) Min. Ave. 
Max. 
Min. Ave. Ma
x 
With  2-Opt 
0.54 1.60 
3.42 
1.98 3.18
5.47
With D2-Opt 
0.33 1.37 
3.04 
1.43 2.33
3.38
 
[8] 
L. Wang, S. Li, F. Tian, and X. Fu, "A Noisy Chaotic Neural Network 
for Solving Combinatorial Optimization Problems: Stochastic Chaotic 
Simulated Annealing", IEEE Transaction on Systems, Man and 
Cybernetics, Part B: Cybernetics, Vol. 34, No. 5, pp. 2119-2125, Oct. 
2004 
[9] 
S. Andrew, "Parallel N-ary Speculative Computation of Simulated 
Annealing", IEEE Transaction on Parallel and Distributed Systems, 
Vol. 6, No. 1O, pp. 997-1005, Oct. 1995. 
[10] 
D. C. W. Pao, S. P. Lam, and A. S. Fong, "Parallel implementation of 
simulated annealing using transaction processing", IEE Proc-Comput. 
Digit. Tech.. Vol. 146, No. 2, pp. 107-113, March 1999. 
[11] 
J. W. Pepper, B. L. Golden, and E. A. Wasil, "Solving the Traveling 
Salesman 
Problem 
With 
Annealing-Based 
Heuristics: 
A 
Computational Study", IEEE Transaction on Systems, Man and 
Cybernetics —Part A: Systems and Humans, Vol. 32, No. 1, pp. 72-
77, Jan. 2002. 
[12] 
H. Chen, N. S. Flann, and D. W. Watson, "Parallel Genetic Simulated 
Annealing: 
A 
Massively 
Parallel 
SIMD 
Algorithm", 
IEEE 
Transaction on Parallel and Distributed Systems, Vol. 9, No. 2, 
pp.126-136, Feb. 1998. 
[13] 
H. Shakouri G., K. Shojaee, and M. Behnam T., "Investigation on the 
choice of the initial temperature in the Simulated Annealing: A 
Mushy State SA for TSP", 17th Mediterranean Conference On 
Control And Automation, Thessaloniki, Greece, 24-26 June 2009. 
[14] 
G. Magyar, M. Johnsson, and O. Nevalainen, "An Adaptive Hybrid 
Genetic Algorithm for the Three-Matching Problem", IEEE 
Transaction on Evolutionary Computation, Vol. 4, No. 2, pp. 135-
146, Jul. 2000. 
[15] 
C. H. Cheng, W. K. Lee, and K. F. Wong, "A Genetic Algorithm-
Based Clustering Approach for Database Partitioning", IEEE 
Transaction on Systems, Man and Cybernetics —Part C: Applications 
and Reviews, Vol. 32, No. 3, pp. 215-230, Aug. 2002. 
[16] 
H. D. Nguyen, I. Yoshihara, K. Yamamori, and M. Yasunaga, 
"Implementation of an Effective Hybrid GA for Large-Scale 
Traveling Salesman Problems", IEEE Transaction on Systems, Man 
and Cybernetics —Part B: Cybernetics, Vol. 37, No. 1, pp. 92-99, 
Feb. 2007. 
[17] 
F. Glover, "Tabu Search Fundamentals and Uses", Graduate School 
of Business, University of Colorado, Boulder, 1995. 
[18] 
Y. Peng, B. H. Soong, and L.P. Wang, "Broadcast scheduling in 
packet radio networks using a mixed tabugreedy algorithm", 
Electronics Letts., vol.40, no.6, pp.375-376, Mar., 2004. 
[19] 
A. Miseviˇcius, “Using iterated tabu search for the traveling salesman 
problem,” Informacin˙es Technologijos ir Valdymas, vol. 3, no. 32, 
pp. 29–40, 2004. 
[20] 
M. Dorigo, Member, ZEEE, V. Maniezzo, and A. Colorni, "Ant 
System: Optimization by a Colony of Cooperating Agents", IEEE 
Transaction on Systems, Man and Cybernetics —Part B: Cybernetics, 
Vol 26, No. 1, pp. 29-41, Feb. 1996. 
[21] 
M. Dorigo, Senior, and L. M. Gambardella, "Ant Colony System: A 
Cooperative Learning Approach to the Traveling Salesman Problem", 
IEEE Transaction on Evolutionary Computation, Vol. 1, No. 1, pp. 
53-66 Apr. 1997. 
[22] 
L. Wang and Q. Zhu, "An Efficient Approach for Solving TSP: the 
Rapidly Convergent Ant Colony Algorithm", Fourth International 
Conference on Natural Computation pp. 448-452, 2008. 
[23] 
X. H. Shi , Y. C. Liang, H. P. Lee, C. Lu, and Q. X. Wang, "Particle 
swarm optimization-based algorithms for TSP and generalized TSP", 
Information Processing Letters, No. 103, pp. 169–176, 2007. 
[24] 
H. Shakouri G., K. Shojaee, and H. Zahedi, "An Effective Particle 
Swarm Optimization Algorithm Embedded in SA to solve the 
Traveling Salesman Problem", 21sh Chinese Control and Decision 
Conference (CCDC09), Guilin, China, 17-19, Jun. 2009. 
[25] 
D. Johnson and L. McGeoch, “The Traveling Salesman Problem: A 
Case Study in Local Optimization” chapter of “Local Search in 
Combinatorial Optimization”, pp. 215-310, London 1997. 
[26] 
G. Reinelt. Tsplib95, 1995. Available at: http://www.iwr.uni-
heidelberg.de/groups/comopt/software/TSPLIB95. 
[27] 
N. Metropolics, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. 
Teller, “Equation of State Calculations by Fast Computing 
Machines,” J. Chem. Phy, vol.21, pp. 1087-1092, 1953. 
[28] 
V. Cerny, “Thermodynamical Approach to the Traveling Salesman 
Problem: An Efficient Simulation Algorithm,” J. Opt. Theory Appl, 
vol.45, pp. 41-51, 1985. 
[29] 
E. Aarts and J. Korst, "Simulated Annealing and Boltzmann 
Machines: A Stochastic Approach to Combinatorial Optimization and 
Neural Computing", New York: Wiley, 1989. 
[30] 
S. Lin and B. Kernighan, “An effective heuristic algorithm for the 
traveling salesman problem,” Oper. Res., vol. 21, no. 4598, pp. 498–
516, 1973. 
[31] 
K. Helsgaun, “An effective implementation of the Lin–Kernighan 
traveling salesman heuristic,” European Journal of Operational 
Research, vol. 126, no. 1, pp. 106-130, 2000. 
58
ADVCOMP 2010 : The Fourth International Conference on Advanced Engineering Computing and Applications in Sciences
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-101-4

