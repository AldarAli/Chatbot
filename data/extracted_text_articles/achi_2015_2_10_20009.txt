Evaluation of a Vibrotactile Device For Outdoor and
Public Transport Pedestrian Navigation Using Virtual
Reality
Olivier Hugues and Philippe Fuchs
Lucie Brunet and Christine Megard
MINES ParisTech, PSL Research University
CEA-LIST
Center For Robotics
Sensory and Ambient Interfaces Laboratory
Paris, France
Fontenay-aux-Roses, France
ﬁrstname.lastname@mines-paristech.fr
ﬁrstname.name@cea.fr
Abstract—It can be difﬁcult to ﬁnd your way in public transport,
especially when the journey combines indoor and outdoor trans-
portation. We designed an innovative vibrotactile device dedicated
to guide a pedestrian in public transport. This multi-modal
interface can be used to guide a pedestrian in unknown public
transport. The device can be used by visually impaired person.
The device has been tested during two main phases. The ﬁrst
step was to test the device using virtual reality while the second
step test was to test the device in a real environment. This paper
presents the ﬁrst part of the evaluation of the device. We have
developed a virtual reality scenario to assess the objective and
subjective utility of the device. The results showed that the device
could properly guide users. We also evaluated the usefulness of
a warning vibration preceding a message. It was found that the
vibration seems to introduce confusion to the pattern recognition
by the user.
Keywords–Vibrotactile device evaluation;multi-modal interface;
tourism mobile device; public transport; virtual reality.
I.
INTRODUCTION
In a large city, the range of public transport servicies is wide
–buses, subways, trams, bicycles, electric cars– making the
transportation network more and more complex. To address
this complexity and facilitate the movement of users, infor-
mation systems are available in many guises such as signs,
information boards or mobile device applications. However,
existing systems to assist pedestrians mostly offer visual cues,
sometimes combined with sound. The need to inform the
pedestrian can lead to saturation of these sensory modalities,
making it difﬁcult to grasp information during the journey.
The problem is even more serious if the user is not familiar
with the transport system, or if it’s his ﬁrst time navigating.
These observations led us to consider the development of a
new way to interact with the navigation aid systems. There
are two objectives in this paper. The ﬁrst one is to evaluate,
using virtual reality, the potential interest of a preliminary alert
to draw the user’s attention. The second one is to evaluate a
vibrating wristband to help pedestrians to navigate the city and
public transport.
In Section II, we present related work on devices used
to guide pedestrians using multi-modality. In Section III, we
describe the device and give some details about the design of
the hardware and the software. Then, in Section IV, we present
the user study which was conducted using virtual reality.
Finally, we present the results and discussions in Section V.
II.
RELATED WORK
Pedestrian navigation aid systems mainly employ visual
and auditory modality [1][2][3][4]. Indeed, cognitive resources
for visual and auditory modality are already heavily used in
mobile environments [5]. The solicitation of visual modalities
when interacting with navigation aid systems strongly degrades
the performance of pedestrian mobility [6]. In this case, the
pedestrian must perform several tasks simultaneously. He must
look at the screen of his mobile interface and pay attention
to the environment at the same time. The auditory modality,
slightly less used, is not the best communication channel in
public transport. In a noisy acoustic environment saturated
with visual information, the haptic modality seems to be more
promising and worth exploring to provide information to trav-
elers. The haptic perception is deﬁned as a perceptual system
composed of two subsystems: tactile –cutaneous channel–
and proprioceptive –kinesthetic channel [7][8]. We believe
that the use of the haptic channel is useful for navigational
interfaces because it does not overlap with the main channels
(auditory and visual) used during the journey. This is based on
the theory of Wickens [9], which highlights the existence of
different resource reservoirs, each associated with a particular
processing channel. The processing channels are independent.
In other words, when two different tasks are performed at the
same time by different processing channels, the model predicts
no performance degradation. In addition,Lee et al. [10] also
shows that a vibration can automatically draw the driver’s
attention to information delivered by the system. Another
experiment conﬁrmed this hypothesis, indicating that a vibra-
tory stimulation serves to focus the driver’s attention on the
driving situation in order to pay attention to potential risks.
For example, a study was conducted consisting of sending
vibration signals to the conductor’s waist [11] or through
the seat [12]. The haptic modality was shown relevant to
pay attention to information about the environment without
24
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

disrupting the visual and auditory channels. This validates the
choice to create devices for pedestrian navigation employing
the haptic modality. It is important to keep in mind that the
user is continually confronted with multiple sensory stimuli.
Some of them are useful while others are irrelevant. The
users’ perception has to ﬁlter information in order to limit
the number of informations to be processed [13]. This system
may be faulty when the user faces an unexpected situation.
This can be caused, for example, by performing recreational
activities not related to the principal activity of transport such
as reading/writing an SMS. In this case, there is a shift in
focus from relevant information to the secondary activity [14].
However, we know that the appearance of an event is similar
to a distraction, induces an automatic attention redirection to
this event. It was in 1980 that Posner [15] described this loss
of concentration as “exogenous focus of attention.” Haptic
stimulation, used as a distraction, could therefore help to focus
the user’s attention back to commute.
Issues regarding the displacement in virtual worlds have
been widely studied [16] and especially for large virtual envi-
ronments [17][18] to avoid the cyber-sickness [19]. Slater [20]
showed that the sense of immersion is impacted by the
metaphor of displacement and a system allowing the user
to walk under degraded conditions is better than a classical
interface with buttons and joysticks. This is why we choose a
particular metaphor to help the user in his displacement and
given below are some details about the design of this user
experience.
III.
DESIGN DETAILS
The
activities
extracted
from
the
study
conducted
by Brunet et al. [21] allowed us to select 8 functions
to assist the user. According to this study, there are two main
functions: one for guidance and one for warning the user.
These two functions are represented by two different devices
shown on Figure 1. Guiding is provided by D1, a hand-held
device composed of a body (in white) and a small movable
part (in black). This part can be tilted in 8 directions (cardinal
and diagonal). It is used to indicate the direction by putting
a ﬁnger on the tilting part. For reassurance and warning
functions, the second part, D2, is worn around the wrist and
is composed of 8 vibrating units. This setup allows creating
speciﬁc vibration patterns for each information and alert.
Changing the following settings creates different patterns of
vibration:
•
Vibration time
•
Vibrator sequence
•
Delay between each pulse
A. Wayﬁnding in virtual environment
The commute consists of following a path through nodes
and segments. The participant must move from one node to
another. This is done to simplify the interaction needed for
the displacement. When he reaches a node, the movement
automatically stops. Then, he can move his head to choose
an orientation he wants to take. Once a direction has been
Figure 1. Illustration of the device. Right: Hand-held device (D1) used to
indicate the direction by tilting the small black part. Left: Worn around the
wrist (D2) composed by 8 vibrators.
TABLE I. VIBRATIONAL MESSAGES ASSOCIATED WITH THEIR
IMAGES AND RELATED CONCEPTS.
Name
Sign
Concept
Knock-knock
Vehicle Alert: you need to get in/out
from the vehicle.
Siren
Incident Alert: incident on your route.
Bug
Unavailability Alert: technical issue (es-
calator...).
Half-lap
Wrong road alert: you’re going the
wrong way.
Heart
Point of interest alert: you are next to
one of your POI.
Waltz
Information Alert: you’re next to an
information center.
It’s Ok
Reassurance Alert: you’re on your way,
no problem.
selected, the participant must step forward (beyond a mark on
the ground). His foot must remain in front of the mark until he
reaches the next node. Between two nodes, the participant can
stop moving forward by repositioning his foot behind the mark
on the ground. When he decides to move again, he simply puts
his foot forward and movement resumes.
The general concept of this device is based on the dif-
ferences between each haptic pattern. The interaction mainly
consists of seven vibrating messages delivered to the user
through the bracelet. Each vibration pattern is associated with
an image, which is an activity related to the user’s commute
(see Table I). Please ﬁnd details about the signal used for each
pattern in the study of Brunet et al. [22].
25
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

IV.
USER STUDY
The use of Virtual Reality (VR) to realize the evaluation
of our prototype will help us to shape the next user study
that will take place in a real environment. VR allows us to
perform device evaluation faster than in a real environment
and with better control of many constraints [23]. Furthermore,
VR helps us to make few design choices and minimize the cost
of producing devices that would neither be used nor accepted
by users [24]. In addition, VR allows the control of parameters
that we could not manage in the real world such as the noise
level of the environment to assess the impact of this parameter
on the user’s activity.
A. Hypothesis
The ﬁrst hypothesis (H1) we wish to verify is that the pres-
ence of a preliminary vibrational message before the vibration
itself will improve pattern detection during the commute in
the virtual environment. This hypothesis is focused on D2.
It postulates that the presence of this message should reduce
the number of misinterpretations. The second hypothesis (H2)
consists of testing if D1 is well designed for guiding partici-
pants. This will be conﬁrmed by obtaining a minimum number
of misorientations.
The system is designed for a wide population range so
we want to verify if the devices D1 and D2 are easy to
use for a large portion of the population. We also want to
compare results among different age groups. Finally, the third
hypothesis (H3) consists in verifying, by questionnaires, if the
device improves the user experience. In this study, participants
experience immersion in a virtual environment representing
a metro station and its external surroundings. The user’s
dominant hand holds the device D1. Around his dominant
wrist, the user wears the device D2 to receive vibration alerts
and reassurance. The study was conducted in four steps. The
ﬁrst one (E1) is dedicated to learn how to employ devices D1
and D2. The second one (E2) is needed to learn how to move
through the virtual environment with D1 and D2. The third
(E3) is the user study itself and the fourth (E4) is assigned to
ﬁlling out a questionnaire. We will describe each step in the
following sections.
B. Tasks
Step E1 is dedicated to familiarizing the participant with
devices D1 and D2. The user starts by learning 5 vibration
patterns: The experimenter says the name of a pattern, sends
it to the device (worn by the participant) and then says
the name again. This procedure is repeated for each of the
ﬁve different vibration patterns randomly. The procedure is
repeated a second time without saying the name. We then move
to the stage of verbalization by the participant itself. Each
vibrational pattern is sent to the device and the participant must
identify the pattern by its name. This phase is repeated as long
as the participant makes errors. The participant learns how to
move in the virtual environment in step E2. In this preliminary
step, the device D2 is worn by the participant for practical
reasons, but is inactive. Moreover, the participant does not
have access to the device D1 during the ﬁrst few minutes. The
participant moves along a predetermined path (the same for
all subjects) and is guided by the experimenter who tells him
the directions to take. When the subject comes to a particular
node (same for all participants), the experimenter allows the
participant to use device D1. At this step, the participant can
move without guidance from the experimenter, but helped by
D1. During the movement, vibration patterns are sent to the
participant through D2. For each pattern, the participant must
tell the experimenter the name of the pattern recognized. The
experimenter valids the name of the pattern and repeats the
vibration in case of error. After several nodes, the participant
reaches the end of the learning path.
The next step (E3) is the user study itself. A scenario
is proposed to the participant before he starts. The scenario
begins on the platform. He must go downtown, to a street next
to the subway entrance in order to go shopping. He must then
join a friend next to a subway entrance to visit a museum. To
do this, the participant and his “virtual friend” should take the
metro. During the scenario, the participant is only guided by
D1 and D2. Prior to joining his friend, the participant is asked
to send an SMS to agree on the meeting place. The message
to be sent is the same for all participants. The experimenter
gives the participant a mobile phone at that time. While writing
the SMS, D2 vibrates. This operation is used to assess the
ability of the device D2 to be understood, even if the user
is doing many different tasks at the same time –commuting,
writing SMS–. During the commute to the subway, an incident
on the line is announced (by D2) and it is recommended
to take another line by making a U-turn. Once back on the
platform, the experiment ends. During the scenario, cultural
and commercial points of interest or alerts are presented to the
participant through D2. During the experiment, the software
logs steering errors. An error is recognized whenever the
subject wishes to leave a node towards another node in a
direction which is inconsistent with that indicated by D1. The
experimenter also records misunderstood vibration alerts.
C. Implementation
A 3D model of the metro station was implemented in
Unity3D (Figure 2). The station had to be large enough so that
the path can be complex so we modeled one of the largest Paris
metro station. The virtual environment was rendered on a back-
projected wall (3.1m × 1.7m) with monoscopic rendering.
We use of ART cameras for motion tracking: both the head
and the dominant foot of the user were tracked in real time
thanks to passive markers. The two devices were connected to
a computer using Bluetooth. Keyboard control was available
for the experimenter to record errors.
V.
RESULTS AND DISCUSSIONS
A total of 21 subjects participated in this study. The duration
of the experiment for each subject was about 1 hour. We
chose to separate subjects randomly into two groups: during
the experiment, the ﬁrst group (G1) received a vibrational
warning before the vibration itself, whereas the second group
(G2) received the vibrational messages without this vibration
26
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

(a) A view of the metro station 3D model.
(b) The signs are modeled in the 3D model.
Figure 2. An example of the virtual metro station.
warning. The age distribution of our population was 37.5
years on average with a median of 32.5 years. The gender
distribution was balanced with 11 men and 10 women. We
will discuss the results related to data acquisition in the next
section and we will deal with the subjective experience in the
following one.
A. User Study Measures
For both groups G1 and G2 (the entire population), we
observed a tolerable error rate of 5.39% for D1, while the error
rate was relatively large for D2 with 28.95%. We performed 1-
way ANOVAs to detect any signiﬁcant effects of the vibration
alert. There was no signiﬁcant inﬂuence on the user’s errors on
D1 and whether or not they received the preliminary message
via D2 (F (20,1) = 0.29, p = 0.59). D1 allowed to properly
guide participants in the virtual environment, and was not
affected by the different modes of D2, which validates H2.
We found a signiﬁcant inﬂuence of the preliminary message
on the vibration pattern recognition (F (20,1)=3.22, p=0.09).
The G1 group experienced more difﬁculties recognizing the
vibration pattern with an error rate of 40.47% than the G2
group with an error rate of 15.39%. Many participants made a
confusion between the preliminary alert and the message itself
and few users tried to recognize a pattern when the preliminary
alert was started and not when the message itself started. These
error rates were quite large, so we have suggestions for pos-
sible improvements. We could increase the amount of time to
learn how to use D2 or simply reduce the number of messages
required (5 in this study). In addition, another clue about this
high error rate was the device itself. During the experiments,
the vibrating motors of the prototype occasionally lost contact
with the skin of the participant due to his movements.
Analysis relating to age has shown interesting results. We
decided to divide our population into two groups. The sep-
aration was the average age (37.5 years old). A signiﬁcant
difference (F(20.1)=7.41, p=0.01) was observed for D1 error
rates. On average with D1, participants under 37.5 years old
(12 people) made 1 error, whereas participants over 37.5
years old (8 people) made 3.4 errors. The older age group
experienced more difﬁculties in recognizing the vibrational
patterns of D2 (F (20,1)=3.35, p=0.08). Age seems to be a
signiﬁcant factor for the perception of the vibration of D2.
We will now look at the particular case of the vibration
recognition when the participant was asked to write an SMS
during his commute. We saw a signiﬁcant impact of the
preliminary vibration when writing an SMS with an error rate
of 18% for G2 and an error rate of 50% for G1 (F (20,1)=5.35,
p=0.03). This result conﬁrms the previous results that showed
a greater error rate for G1 than for G2.
B. Subjective user experience
To evaluate the subjective user experience it was necessary
to collect subjective data reﬂecting the experience felt by
each participant during interaction with the prototype. The
subjective aspect of the user experience takes into account the
emotion felt during the session. According to the work in this
ﬁeld, we use some classic usability tests to evaluate the user
experience starting with an evaluation of presence and immer-
sion. All participants were asked to answer the questionnaire
“presence and immersion” from [25]. Participants could give a
score between 1 and 7 (the higher the better) on the control of
events, system responsiveness, the naturalness of interaction,
visual appearance, consistency of movement and involvement.
Results are shown in Figure 3.
All responses were above average. We have not noticed any
particular problems during the experiment, such as simulator
sickness potentially caused by the commute except for one
person prone to vertigo at the top of the virtual stairs.
We can observe a signiﬁcant difference (Student’s t-test)
between the two groups for the ﬁrst question regarding the
level of control (Figure 4). We see that the older group felt
less control over the system than the younger group.
C. Overall user experience
Mood can be experienced directly or at a reﬂexive level.
Mood can be organized into two main dimensions: pleas-
ant/unpleasant and calm/excitement. To extract the mood expe-
rienced, all participants were asked to ﬁll out the Brief Mood
Introspection Scale (BMIS) [26] and the SAM scale [27] at the
27
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

Control
Responsive
Interaction
Visual
Natural
Involvement
4
4.5
5
5.5
6
Figure 3. Response to the questionnaire on presence and immersion for the
entire population.
Control
Responsive
Interaction
Visual
Natural
Involvement
4
5
6
>37,5 years old.
<37,5 years old.
Figure 4. The answer averages to the question of presence and immersion
for both age groups.
Pleasant
Arousal
Positive
Negative
0.4
0.5
0.6
0.7
Figure 5. The BMIS mood scale in average for the entire population.
end of the user study. The well-known BMIS scale consists of
16 adjectives. Two adjectives are selected for each of the eight
emotional states. The adjectives are: Lively, drowsy, happy,
grouchy, sad, peppy, tired, nervous, caring, calm, content,
loving, gloomy, fed up, jittery and active. Participants had
indicate how well each adjective describe their mood by
choosing among the different sentences:
•
deﬁnitely do not feel;
•
do not feel;
•
slightly feel;
•
deﬁnitely feel.
The BMIS questionnaire allowed us to assess the emotion
felt during the interaction. Positive mood was observed for
all participants with a pleasant and positive experience with
a lower level of excitement for negative sentiment (Figure 5).
Figure 6 shows the result averages of the BMIS questionnaire
for both age group.
Emotions can be described in terms of three independent
dimensions: pleasure/displeasure, degree of arousal, domina-
tion/submission (PAD model) [28]. These three elements are
independent and may occur without impacting each other. The
SAM questionnaire [27] is an instrument to measure emotional
states based on pictures to achieve a self-evaluation of an
object or event based on the three main emotional dimensions.
SAM provides a list of pictures for each dimension of the PAD
model associated to a scale from 1 to 9. It has the advantage of
being ﬁlled out very quickly, hence there are no mistranslation
issues and both children and adults can ﬁll it out. The SAM
scale allows us to extract a general emotional state of the
participants. Figure 7 shows the score averages for all the
participants. It can be seen that participants had fun during the
experiment. Younger participants felt more pleasure than the
older group, and they also felt a stronger sense of dominance
compared to the older participants (Figure 8). The feeling of
excitement is relatively low for both groups, which conﬁrms
28
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

Pleasant
Arousal
Positive
Negative
0.4
0.5
0.6
0.7
0.8
>37,5 years old.
<37,5 years old.
Figure 6. The score averages of the BMIS questionnaire for each group.
Pleasure
Excitement
Dominance
3
4
5
6
Figure 7. The SAM scale score averages for the entire population.
that the participants were relaxed during interactions with the
device.
We will now discuss the user experience for both devices
D1 and D2 separately. Using a Likert scale, we will be able
to evaluate the usability of each device.
D. User experience with D1
Concerning D1, it can be noted that the score is never below
7 out of 10 except for the liveliness (Figure 9). The subjects
perceived a slow interaction with D1.
Table II summarizes the responses to open-ended questions
about D1. Four participants thought that D1 was simple and
an intuitive guide during the commute and ﬁve participants
felt that the system properly indicated the direction. However,
Pleasure
Excitement
Dominance
3
4
5
6
7
>37,5 years old.
<37,5 years old.
Figure 8. The score averages of the SAM scale for each age group.
Learning
Displacement
Objectiveness
Appropriate
Reliability
Serenity
Actractive
Liveliness
Control
4
5
6
7
8
9
Figure 9. The score averages for all the participants regarding their feelings
about interaction with D1.
ﬁve respondents indicated that they preferred to ﬁnd their way
using a map or a GPS-based application.
E. User experience with D2
Use of D2 is overall lower than the score of D1 as shown
by Figure 10 especially for the training phase. Subjects were
able to adapt to the device and seemed not to have trouble
memorizing the patterns. Table III summarizes the responses
to open-ended questions about D2. Three participants thought
that device D2 provided good vibration recognition and two
29
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

TABLE II. SUMMARY OF COMMENTS REGARDING THE USE OF D1.
Positive points - D1
Number of people
Simple and intuitive guide
4
Properly indicates the direction
5
Usefulness in open space without signs
2
Useful if I’m in a hurry
1
Useful for a blind or visually impaired person
4
No opinion
5
Negative points - D1
Number of people
It would be easier if the button were still
ahead when we have to go forward
1
Cumbersome
3
I prefer to ﬁnd my way using a map/GPS
5
Lack of independence
1
Smartphone is sufﬁcient
1
Using signs is easier
1
Requires concentration
2
Lack of autonomy
1
Lack of direction update
3
No opinion
5
Training
Agreeableness
Adapted
Memorizing
5
6
7
8
Figure 10. The score in average for all the participants regarding their
feelings about the interaction with D2.
participants have highlighted the fun aspect of D2. However,
six participants have noted difﬁculties to distinguish patterns
(lack of discrimination) and ﬁve participants have found im-
portant memorization effort.
F. Impact of the alert
Based on answers to the question (does the jingle allow
to anticipate the identiﬁcation of the vibration?), participants
said yes up to 6.9/10. Depending on the different conditions
during the commute (walking, walking and writing an SMS,
walking in a noisy environment), some participants seemed
to be distracted by the SMS (Figure 11) and indicated that
they had experienced difﬁculties related to the recognition of
vibration. This is conﬁrmed by the observed error rate of 50%
for the pattern recognition.
TABLE III. SUMMARY OF COMMENTS REGARDING THE USE OF
D2.
Positive points - D2
G1 (10)
G2 (10)
Number (20)
Good vibration recog-
nition
2
1
3
Provides vital infor-
mation
1
1
Not
encumbered
hands
1
1
Fun aspect
1
1
2
Discrete interaction
1
1
2
No opinion
12
12
Negative points - D2
G1 (10)
G2 (10)
Number (20)
Cognitive load
3
3
6
Lack of discrimina-
tion
2
4
6
Smartphone is sufﬁ-
cient
1
1
Prefer to use eyes and
ears
1
1
Memorization effort
1
4
5
Lack of control
1
1
Vibrations
disturbance
2
2
No opinion
3
2
5
Walking
Walking+SMS
Walking+Noise
4
5
6
7
8
Figure 11. Feeling for G1 on the impact of the preliminary alert during
different commuting conditions.
We can note that the alert seems not to be useful while
writing a text message for G1, the group which received the
alert (Figure 11). This has been conﬁrmed by observations
with a signiﬁcant recognition error rate during this phase
(more than 60%). We can observe (Figure 12) that the alert
was well received for the younger group during all three
phases (walking, walking + SMS, walking + noise) unlike the
other group where the alert was rather negative while writing
an SMS. Table IV summarizes the responses to open-ended
questions about the alert. Five participants thought that the
alert helped them to listen to the message but two participants
said that the presence of the alert was annoying and caused
30
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

Walking
Walking+SMS
Walking+Noise
2
4
6
8
10
>37,5 years old.
<37,5 years old.
Figure 12. Feeling averages for each age group regarding the vibration
pattern recognition.
confusion with the message itself.
TABLE IV. SUMMARY OF COMMENTS FORM PARTICIPANTS IN
GROUP G1 REGARDING THE ALERT.
Positive points - Alert
G1 (10)
Helps prepare to “listening” the message - promotes wakeful-
ness - caution - concentration
5
No opinion
4
Negative points - Alert
G1 (10)
Not essential
2
Presence of alert is annoying and causes confusion with the
message itself
2
No opinion
3
VI.
LIMITATIONS AND FUTURE WORK
As we said earlier, the used device was a prototype and still
has many possibilities of evolution. Indeed, the bracelet could
rarely not have been in perfect contact with the skin of the
user, which could have lead to a loss of information.
Following this study using virtual reality, we conducted a
study in a real environment. We designed the test protocol for
the real environment following the results of the study pre-
sented here, and we have, for example, speciﬁcally emphasized
the appearance of the jingle. Results of the study conducted
in real environment will be presented in another paper.
Today, we plan to target a population with visual impair-
ments to conﬁrm the interest of this device for this population.
VII.
CONCLUSION
This paper focused on the evaluation of a vibrotactile device
for outdoor and public transport pedestrian navigation using
virtual reality. A user case was implemented in which a
pedestrian had to commute in a large virtual metro station. In
this study, we evaluated each of the four proposed hypotheses.
We note that our ﬁrst hypothesis is not validated because
the preliminary alert seems to bring confusion to pattern
recognition with lower performance for participants compared
with those who did not receive the preliminary message. This
result, however, can be addressed due to the fact that the device
used is only a prototype. The second hypothesis was to assess
the guide performance of the device and the data shows that
the system is useful to guide users through the station. We
noticed a signiﬁcant difference concerning the age of users.
People in the younger age group generally report that it is
easier for them to recognize a vibration. Finally, the analysis
of questionnaires allows us to conclude that the user experience
is quite positive. However, it is difﬁcult to decouple the impact
of the experience in the virtual environment with the use of
the device itself, which is why we will conduct another user
study in the real environment of the metro station modeled in
this paper.
VIII.
ACKNOWLEDGMENTS
We would like to thank all the subjects that participated in
the user study. We also want to thank the National Research
Association who is founding this work and the RATP Group
(R´egie Autonome des Transports Parisiens).
REFERENCES
[1]
Y. Miyazaki and T. Kamiya, “Pedestrian navigation system for mobile
phones using panoramic landscape images,” in Applications and the
Internet, 2006. SAINT 2006. International Symposium on, 2006, pp. 7
pp.–108.
[2]
S. Kaiser, M. Khider, and P. Robertson, “A pedestrian navigation
system using a map-based angular motion model for indoor and outdoor
environments,” Journal of Location Based Services, vol. 7, no. 1, 2013,
pp. 44–63.
[3]
H. Furukawa and Y. Nakamura, “A pedestrian navigation method
for user, save and easy wayﬁnding,” in Human-Computer Interaction.
Users and Contexts of Use, ser. Lecture Notes in Computer Science,
M. Kurosu, Ed. Springer Berlin Heidelberg, 2013, vol. 8006, pp. 156–
165.
[4]
M. Kluge and H. Asche, “Validating a smartphone-based pedestrian
navigation system prototype: an informal eye-tracking pilot test,” in
Proceedings of the 12th international conference on Computational
Science and Its Applications - Volume Part II, ser. ICCSA’12.
Berlin,
Heidelberg: Springer-Verlag, 2012, pp. 386–396.
[5]
A. Oulasvirta, S. Tamminen, V. Roto, and J. Kuorelahti, “Interaction
in 4-second bursts: the fragmented nature of attentional resources
in mobile hci,” in Proceedings of the SIGCHI Conference on
Human
Factors
in
Computing
Systems,
ser.
CHI
’05.
New
York, NY, USA: ACM, 2005, pp. 919–928. [Online]. Available:
http://doi.acm.org/10.1145/1054972.1055101
[6]
M. Pielot and S. Boll, “Tactile wayﬁnder: Comparison of tactile
waypoint navigation with commercial pedestrian navigation systems,”
in Pervasive Computing, ser. Lecture Notes in Computer Science,
P. Flor´een, A. Kr¨uger, and M. Spasojevic, Eds.
Springer Berlin
Heidelberg,
2010,
vol.
6030,
pp.
76–93.
[Online].
Available:
http://dx.doi.org/10.1007/978-3-642-12654-3-5
[7]
K.
E.
Maclean,
“Haptics
in
the
Wild:
Interaction
Design
for
Everyday Interfaces,” In Carswell, M. (Eds.), Review of Human
Factors and Ergonomics (HFES). Santa Monica: United States,
2008. [Online]. Available: http://www.cs.ubc.ca/labs/spin/publications/
spin/maclean2008hfes.pdf
31
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

[8]
S. Lederman and R. Klatzky, “Haptic perception: A tutorial,” Attention,
Perception, and Psychophysics, vol. 71, no. 7, 2009, pp. 1439–1459.
[Online]. Available: http://dx.doi.org/10.3758/APP.71.7.1439
[9]
C. D. Wickens, “Processing resources in attention, dual task perfor-
mance, and workload assessment.” DTIC Document, Tech. Rep., 1981.
[10]
J. D. Lee, J. D. Hoffman, and E. Hayes, “Collision warning
design to mitigate driver distraction,” in Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems, ser. CHI ’04.
New York, NY, USA: ACM, 2004, pp. 65–72. [Online]. Available:
http://doi.acm.org/10.1145/985692.985701
[11]
C. Ho, N. Reed, and C. Spence, “Assessing the effectiveness of
“intuitive” vibrotactile warning signals in preventing front-to-rear-end
collisions in a driving simulator,” Accident Analysis & Prevention,
vol. 38, no. 5, 2006, pp. 988–996.
[12]
J. B. V. Erp, H. A. V. Veen, C. Jansen, and T. Dobbins, “Waypoint
navigation with a vibrotactile waist belt,” ACM Transactions on Applied
Perception (TAP), vol. 2, no. 2, 2005, pp. 106–117.
[13]
D. E. Broadbent, “The role of auditory localization in attention and
memory span.” Journal of experimental psychology, vol. 47, no. 3, 1954,
p. 191.
[14]
C. Lemercier and J.-M. Cellier, “Les d´efauts de l’attention en conduite
automobile: inattention, distraction et interf´erence. [attention deﬁcits
in car driving: Inattention, distraction and interference.],” Le travail
humain, vol. 71, no. 3, 2008, pp. 271–296.
[15]
M. I. Posner, C. R. Snyder, and B. J. Davidson, “Attention and the
detection of signals.” Journal of experimental psychology: General, vol.
109, no. 2, 1980, p. 160.
[16]
K. M. Stanney, R. R. Mourant, and R. S. Kennedy, “Human factors
issues in virtual environments: A review of the literature,” Presence:
Teleoper. Virtual Environ., vol. 7, no. 4, Aug. 1998, pp. 327–351.
[Online]. Available: http://dx.doi.org/10.1162/105474698565767
[17]
R. Darken, T. Allard, and L. Achille, “Spatial orientation and wayﬁnd-
ing in large-scale virtual spaces: Guest editors’ introduction,” Presence:
Teleoperators and Virtual Environments, vol. 8, no. 6, 1999, pp. 3–6.
[18]
J. L. Chen and K. M. Stanney, “A theoretical model of wayﬁnding
in virtual environments: Proposed strategies for navigational aiding,”
Presence: Teleoper. Virtual Environ., vol. 8, December 1999, pp. 671–
685.
[19]
M. Usoh, K. Arthur, M. C. Whitton, R. Bastos, A. Steed, M. Slater,
and F. P. Brooks Jr, “Walking¿ walking-in-place¿ ﬂying, in virtual
environments,” in Siggraph, vol. 99, 1999, pp. 359–364.
[20]
M. Slater, M. Usoh, and A. Steed, “Taking steps: The inﬂuence
of a walking technique on presence in virtual reality,” ACM Trans.
Comput.-Hum. Interact., vol. 2, no. 3, Sep. 1995, pp. 201–219.
[Online]. Available: http://doi.acm.org/10.1145/210079.210084
[21]
L. Brunet, C. Megard, S. Paneels, G. Changeon, J. Lozada, M. P.
Daniel, and F. Darses, “”invitation to the voyage”: The design of
tactile metaphors to fulﬁll occasional travelers’ needs in transportation
networks,” in World Haptics Conference (WHC), 2013.
IEEE, 2013,
pp. 259–264.
[22]
L. Brunet, C. Megard, S. Paneels, G. Changeon, J. Lozada, M. Daniel,
and F. Darses, “Invitation to the voyage: The design of tactile metaphors
to fulﬁll occasional travelers’ needs in transportation networks,” in
World Haptics Conference (WHC), 2013, April 2013, pp. 259–264.
[23]
P. Fuchs and G. Moreau, “Le Trait´e de la R´ealit´e Virtuelle,” Presse de
l’Ecole des Mines de Paris, Troisi`eme Edition. Mars 2006.
[24]
J.-M. Burkhardt, R´ealit´e virtuelle et ergonomie : quelques ap-
ports r´eciproques, PUF, Le travail humain ed., ser. 1, DOI :
10.3917/th.661.0065, 2003, vol. 66.
[25]
G. Robillard, S. Bouchard, T. Fournier, and P. Renaud, “Anxiety and
presence during vr immersion: A comparative study of the reactions
of phobic and non-phobic participants in therapeutic virtual environ-
ments derived from computer games,” Cyberpsy., Behavior, and Soc.
Networking, vol. 6, no. 5, 2003, pp. 467–476.
[26]
J. D. Mayer and Y. N. Gaschke, “The experience and meta-experience
of mood,” Journal of Personality and Social Psychology, no. 55, 1988,
pp. 102–111.
[27]
P. J. Lang, “Behavioral treatment and bio-behavioral assessment: com-
puter applications,” in Technology in Mental Health Care Delivery
Systems, J. B. Sidowski, J. H. Johnson, and T. H. Williams, Eds.
Norwood, NJ: Ablex, 1980, pp. 119–137.
[28]
A. Mehrabian, “Pleasure-arousal-dominance: A general framework
for describing and measuring individual differences in temperament,”
Current Psychology, vol. 14, no. 4, 1996, pp. 261–292. [Online].
Available: http://dx.doi.org/10.1007/BF02686918
32
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

