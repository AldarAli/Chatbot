 
Figure 1.  Virtual object presentation by haptic mouse 
1 DOF Tabletop Haptic Mouse for Shape Recognition of 3D Virtual Objects 
 
Hiroshi Suzuki, Hiroaki Yano, Hiroo Iwata 
Department of Intelligent Interaction Technologies 
University of Tsukuba 
Tsukuba, Japan 
{suzuki, yano, iwata}@vrlab.esys.tsukuba.ac.jp 
 
 
Abstract—In this paper, we propose a 1 Degree-Of-Freedom 
(DOF) mouse- shaped haptic device for shape perception of 3D 
virtual objects. Decrement of DOF of haptic device brings 
advantages, such as a miniaturization, solidity, and a weight 
reduction. A 1 DOF haptic device that consists of a built-in 
optical shaft encoder, two position sensors and a motor, has 
been developed. This device is easier to integrate with a 
tabletop system compared to multiple DOF haptic devices. We 
propose some haptic algorithms, which are effective to 1 DOF 
haptic device, and two types of pointing environments with a 
multi-touch overlay. Some experiments were conducted to 
evaluate the effectiveness of the proposed system. The elements 
required to make the system functional were clarified. 
Keywords-1 DOF;Mouse Device; Haptic; Image Display; 
Direct Pointing; Multi-touch Overlay 
I. 
 INTRODUCTION  
Many haptic devices have been used in the field of 3D 
shape modeling. They make it possible for users to design 
virtual characters with intricate shapes, and so on. However, 
because most haptic devices have multiple DOFs, they tend 
to be bulky, heavy and expensive. Also, their control 
algorithms become complex. These factors obstruct the use 
of haptic devices in general. In terms of the operation of a 
GUI, we believe that adding „force feedback‟ to a tabletop 
display system is an effective way of further improving its 
usability and of enhancing its own powers of expression. 
However, it is difficult to integrate multiple DOF devices 
with a tabletop display interface because the hardware that is 
required is quite bulky. We considered that a reduction in the 
number of degrees of freedom of the haptic interface could 
be one solution to overcome this issue, since the further the 
number of degrees of freedom of the haptic device can be 
reduced, the simpler the hardware that is required becomes. 
In 3D shape modeling, we initially not only observe, but 
also touch the surface of a virtual object to recognize its 
shape precisely. If a user touches a virtual object on a 
tabletop display, the user will expect to feel the unevenness 
of the object. In this process, we assume that there is a 
principal force vector that is incorporated in the shape 
recognition process. In order to feel information concerning 
the unevenness of the surface, depth information regarding 
the virtual object is a key element in shape recognition. 
Therefore the „up-and-down‟ direction force vector is chosen 
to present depth information on a tabletop display in this 
study. As shown in Figure 1, a user can get a sense of 
touching a virtual object by raising or lowering their 
fingertip according to the unevenness of the virtual object 
with visual feedback. 
In this research, we developed a prototype system that 
consists of a 1 DOF mouse-like haptic device and a tabletop 
display with a multi-touch overlay sensor. The haptic device 
is small and safe to use. It has the ability to present an 
„up-and-down‟ force to the user‟s fingertip. It can be 
controlled in a stable manner by using a simple control 
algorithm. In addition, we realized a “What You See is What 
You Touch” (WYSWYT) environment as the pointing 
environment. In this system, the user can see virtual objects 
and can also touch the virtual objects directly with his/her 
fingertip. A number of experiments were conducted to 
demonstrate the effectiveness of the system.  
The remaining of the paper is organized as follows. 
Section II describes related work. Section III describes the 
design principle of a haptic interface. Section IV describes 
the system configuration of our prototype system and its 
haptic rendering algorithm. Section V describes an 
evaluation experiment conducted and its results. Finally, the 
results are discussed in Section VI before concluding. 
II. 
RELATED WORK 
Akamatsu reported that providing the sensation of 
touching a virtual object by imparting vibration to a user's 
index finger on a mouse interface in a GUI environment is 
effective for reducing the completion time of a pointing task 
[1]. Fukunaka proposed a method of presenting a sense of 
resistance or confliction by using a mouse-shaped device 
containing a magnetorheological fluid (MR fluid) [2]. 
However, these devices cannot present the reaction force 
from the virtual object. They can only present a sense of 
vibration or collision. 
309
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
Figure 2.  1 DOF haptic mouse 
Marquardt reported how adding a haptic layer to the 
interactive surface experience can augment the existing 
visual and touch modalities by using a “haptic tabletop pack”, 
which can present vertical relief, malleability of materials, 
and horizontal friction on the surface [3]. But it cannot 
present shape of the virtual object. 
Howe et al. developed the first motion compensated 
actuated catheter system that enables haptic perception of 
fast moving tissue structures for surgery of the beating heart. 
This system enables physicians to operate on the beating 
heart without caring about deformation of the heart caused 
by the heart beating, but this system does not enable the user 
to perceive its shape[4]. 
The "Touch the Untouchable" system has been developed 
as an example of a 1 DOF haptic device. This device 
measures the distance to a remote object by using a laser 
range sensor, and presents the shape of the object by using 
the distance data [5]. Alternatively, the "Beyond" system can 
present virtual objects beyond the display by using a 
pen-shaped device [6]. 
The above studies did not reveal a haptic rendering 
method for complex shaped virtual objects, or consider the 
influence of reducing the number of degrees of freedom of 
the interface device. In this study, a prototype 1 DOF haptic 
mouse has been developed that is suitable for use on a 
tabletop display. By using this mouse, the effectiveness and 
limitations of this method were evaluated through a number 
of experiments. 
III. 
DESIGN PRINCIPLE 
In this study, even though the number of degrees of 
freedom of the haptic device were reduced, we assumed that 
the „visual dominance‟ effect imparted by the users could 
assist the user's shape recognition process. Therefore, as a 
visual display system, a tabletop GUI environment was 
selected. 
Since the tabletop environment is a flat surface display, 
the motion of a haptic device on the tabletop is limited by the 
surface. By combining the limited horizontal motion and 
depth (up-and-down) motion of the haptic device, the user 
can recognize the shape of a virtual object stably. 
Tabletop haptic interface requires small size, high 
accuracy, high speed measurement of a user's fingertip 
position, and sufficient output torque. Furthermore, we 
assumed to use this device on a tabletop display with visual 
feedback. Therefore its movable area should be greather or 
equal to the area of the display area 
In order to accomplish this specification, we designed a 
prototype un-restraining device with built-in sensors and an 
actuator to securing large movable region. Considering to 
use the device on a display, the screen of the display should  
not be coverd over by the device. Hence, a pen shaped 
device and mouse shaped device can be considered as a 
structure. However, it is difficult to build in an actuator 
which can generate sufficent torque on the pen shaped device. 
Therefore the mouse shaped device, which can store various 
modules underneath the user's palm, was used in this study. 
In order to realize a simple and robust mechanism, the haptic 
device consists of an end effector, a position sensor, a control 
PC, and a visual display. The end effector is a lever that can 
be rotated around a horizontal axis by a DC servomotor so 
that it can generate an up-and-down force directly to the 
user's index fingertip. The range of up-and-down motion of 
the end effector is about 60 mm, taking into account the 
range of movement of the index finger. The end effector and 
its base should be transparent to avoid hiding the visual 
image on the display. An accelerometer, a camera with 
image processing, an optical mouse sensor are candidates for 
the position detection sensor. Since the accelerometer has 
undesireable drift characteristics, and the camera is bulky, 
two optical mouse sensors are used in this study. They can 
be measure the position and orientation of the mouse device 
in un-restraining manner. Also they are cheap and has easy 
to operate. Moreover the position of the fingertip on the 
display should be detected without hiding images under the 
end effector. Therefore, unlike a conventional mouse, neither 
a position sensor for the mouse nor a stylus could be placed 
under the end effector. Hence, it is necessary to detect both 
position and orientation when using this system to calculate 
the fingertip position. Therefore, 2 sensors are required to 
detect both position and orientation. However, since the 
optical sensors can detect only the relative position change of 
the device, the precise absolute position of the mouse on the 
display is unacquirable. The direct pointing environment, 
which is one of the purposes of this research, is difficult by 
using the sensors. A method to measure the absolute position 
by using an infrared multi-touch overlay is mentioned later.  
IV. 
1 DOF HAPTIC MOUSE 
A. System configration 
Figure 2 shows an overview of our prototype for a 1 
DOF haptic mouse system. The system consists of a haptic 
mouse unit, a position detection unit, a control unit, and a PC 
(OS Windows7 Professional 64bit CPU IntelCorei5 650). 
The haptic mouse unit is composed of just a geared(gear 
ratio 5:1) DC servomotor (RE25, made by maxon Inc) and an 
end effector. Since the gear ratio is small enough, the user 
can move an index finger up-and-down without feeling 
resistance. The end effector makes contact with the tip of the 
user‟s index finger. It rotates around a horizontal axis so that 
it moves the user‟s index finger vertically, as shown in 
Figure 1. The height of the fingertip is calculated from the 
value of the optical shaft encoder in the motor. The 
maximum force on the fingertip is 8 N. Two optical mouse 
310
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
Figure 5.  Haptic rendering with a height map data 
 
Figure 3.  Concept of the penalty method 
 
Figure 4.  Typical locus of fingertip during touching a virtual pyramid 
sensors (made by PixArt Imaging Inc) were used to maintain 
operability as far as possible. By obtaining the values from 
the sensors and taking their difference, the relative position 
and orientation of the device can be calculated. There is an 
accumulation error of about 4% in terms of the migration 
distance.  
As the control unit, the “Device Art Toolkit” [7] was 
used to control the optical mouse sensors and the motor of 
the mouse. This is a controller in which the user can freely 
change the number and the function of the input-output 
channels by plugging in various module boards. In this 
research, a serial communication module, an encoder counter, 
a PWM output for controlling the motor‟s output torque, and 
a motor driver were used.  
B. Haptic Rendering Algorithm 
1) Penalty method 
In this research, we presented a reaction force in the 
vertical direction based on the „penalty method‟. As shown 
in Figure 3, the reaction force was calculated by adding a 
reaction force and an impulsive force. The reaction force is 
proportional to the penetration depth (difference between the 
height of a virtual object and the height of the fingertip 
position). The impulsive force is proportional to the 
penetration speed to the object (Equation 1); 

F = Kp(Zobj – Zfin) + Kd(Zfin – Zfin_p)

where Zobj means the height of the virtual object at the 
current fingertip position, Zfin means the height of the current 
fingertip in the case where (Zobj - Zfin) > 0: Kp > 0. In other 
cases, Kp = 0, Zfin_p means the height of the fingertip in one 
program loop, in the case of (Zfin – Zfin_p ) > 0 and (Zobj - Zfin) 
< 0:Kd < 0, in other cases: Kd = 0． 
A typical example of the locus during touching of a 
virtual object using the haptic mouse is shown in Figure 4. 
The green line indicates the locus of the user's fingertip 
during operation. You can see that the fingertip was moving 
on the object's surface. 
2) Haptic rendering technique using height map data 
This system can render a virtual object with haptic 
sensation by using data from a height map, as opposed to the 
fundamental haptic rendering method using virtual objects 
defined by some equations or polygons. Since this system 
renders a virtual object by using only 1 DOF for the upward 
reaction force, it is possible to render an object by using the 
height information of the object corresponding to the 
two-dimensional coordinates on the display surface. We 
achieved haptic presentation using a height map by utilizing 
this technique. 
A height map records height information as brightness 
information at each pixel of the image. If the color of a pixel 
is close to black, the height is low. If the color is close to 
white, the height is high. This system can present a reaction 
force by using the penalty method described in the previous 
section by analyzing 24bit bitmap image data. It is possible 
to render a complex shape of a virtual object by using this 
technique, even if the shape is difficult to define using 
equations or a polygon model, as shown in Figure 6. 
3) Haptic rendering method of a virtual wall that is 
perpendicular to the ground 
When rendering a shape like a cube, which has side 
surfaces perpendicular to the ground, the user‟s fingertip is 
forced to move rapidly upwards. Sometimes this may cause 
an unwanted vibration and make the user feel uncomfortable. 
In this study, some small steps were placed on the surfaces to 
overcome this incongruity. After trial and error, the size of 
the small steps was set to 1 mm in width and 20 mm in 
height to reduce the unwanted vibration.  The user's 
fingertip climbs up two steps in a very short time if the 
virtual wall has a height of 40 mm. 
Figure 6 shows a typical locus of a user‟s fingertip with 
the haptic mouse when he touches a virtual cube from left to 
right. By using the proposed technique, the heights of the 
overshoots are reduced compared with a method that does 
not include the small steps described in previous section. 
When the fingertip moves from the upper surface of the cube 
to the ground, the end effector falls slowly according to the 
input force at the fingertip. This causes the gently-sloping 
trajectories on the right side of the cube that are shown in 
Figure 6. 
311
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
Figure 9.  Position detection with two kinds of sensors (250mm/sec) 
 
Figure 6.  Typical locus of a user‟s fingertip during touching a virtual 
cube 
 
Figure 7.  System overview of tabletop haptic interface 
 
Figure 8.  Position detection with two kinds of sensors (100mm/sec) 
V. 
1 DOF HAPTIC MOUSE WITH MULTI-TOUCH OVERLAY 
 When using the developed 1 DOF haptic mouse, the 
spatial relationship between the visual presentation and the 
haptic presentation was in agreement, and it was thought that 
presentation closer to the appearance of a real object would 
be realizable by building a direct pointing environment in 
which a haptic presentation is shown when touching a visual 
representation with direct feedback. In this research, in order 
to harness the characteristics of a 1 DOF haptic mouse that is 
not grounded, a direct pointing environment was created by 
combining it with an infrared multi-touch overlay that can 
detect the positions of two points in an unrestrained manner 
(Figure 7). 
A. Adding a multi-touch overlay for precise measuring 
A multi-touch overlay (made by PQLabs) was used in 
this section. Although the position of an object on the display 
could be detected accurately by using the multi-touch 
overlay, there was a time delay of approximately 0.15 s. 
Since the response of the multi-touch overlay with the 
infrared sensor was insufficient, we added positional data 
from the optical mouse sensors during the preceding 0.15 s 
to the positional data from the multi-touch overlay. In this 
way, the sensor can avoid an accumulation of errors from the 
optical sensor, and real-time precise measurements could be 
realized on the tabletop system. Figure 8 shows a typical 
measured trajectory of the mouse by using the proposed 
method at a velocity of 100 mm/s, which is the average 
velocity when virtual objects are touched by users. The 
measured data is almost the same as the true trajectory. 
However, if the velocity is increased to 250 mm/s, 
approximately 20 mm of overshoot is observed when the 
mouse decelerates to a halt (Figure 9) due to the delay of the 
multi-touch overlay.  In normal usage, this does not become 
a concern, since the user does not touch a virtual object at 
such a high speed or does not stop the mouse suddenly. 
The system can measure the position of the fingertip with 
high precision in real time. The frequency of the 
measurement was about 1 kHz. 
B. Comparison of direct pointing with indirect pointing 
An experiment was conducted to evaluate the effects of 
differences in the pointing environment when using the 
developed system. In a feasibility study, some users reported 
that they felt the sense of the presence of the displayed 
virtual objects with the direct pointing environment 
compared to the indirect one.  
Therefore we aimed to reveal the key issues of the 
different feeling in this experiment. 
1) Experimental details 
Subjects were asked to perform the task of tracing round 
a virtual Torus-like object, and their EMG data were 
recorded, the operation time, the pressure on their fingertip, 
and the operating locus. In this experiment, „direct pointing‟ 
means a state in which the pointing position on the virtual 
plane and the position of the subject‟s fingertip corresponded 
without displaying the pointer, while „indirect pointing‟ 
means a state in which the position did not corresponded 
with the displayed pointer (Figure 10). EMG data were 
measured using an electromyograph (Active Two, made by 
Biosemi) fitted around the extensor digitorum muscle and 
the flexor digitorum superficialis muscle, which both 
contribute to the operation of the index finger. A pressure 
sensor (FlexiForce, made by TECKSCAN) was stuck onto 
the end-effector, and the pressure on the fingertip was 
measured. Six male subjects conducted 3 trials each under 
each of these conditions. The order of presentation was 
randomized in order to negate the influence of the order of 
the tests. 
2) Results 
The average of all subjects' operating time is 11.891 
seconds in the indirect pointing and 10.745 seconds in the 
312
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
Figure 10.  Experimental environment 
 
Figure 11.  Time series valuation of the average EMG of the flexor 
digitorum superficialis muscle (top) and average pressure on the end 
effector of the haptic mouse (bottom) 
direct pointing. Operating time was slightly shortened in the 
direct pointing but there was no significant difference. The 
average error between each position of a fingertip and target 
position (peak of Torus) was 2.017 mm in the indirect 
pointing and  2.112 mm in the direct pointing respectively. 
Although there was slightly difference of error value 
between each pointing environment, there was no significant 
difference.  
The root mean square (RMS) values of the EMG 
measurements were determined in order to perform a 
waveform comparison. The resulting data was smoothed 
using a moving-average interval of 200. Moreover, in order 
to negate the differences between subjects, the peak value of 
the EMG data for each muscle in the indirect pointing 
environment was made equal to 100%, the EMG was 
normalized, and was also normalized with respect to 
operating time. Next, a conventional „t test‟ was performed 
to investigate the difference in EMG for the different types 
of pointing environments. 
Figure 11 shows the average time series of the EMG of 
the flexor digitorum superficialis muscle obtained as a result 
of the experiment. The values of EMG, for indirect pointing 
were stronger in the flexor digitorum superficialis muscle (t 
= 15.7969, df = 17987 p < 0.01). This means the subjects 
tended to press the object firmly in the indirect pointing 
environment. Also, we noted a significant difference in 
pressure (t = 17.1802, df = 17987 p < 0.01); stronger 
pressure occurred at the fingertip for the indirect pointing 
environment. This result is consistent with the EMG data.  
In this experiment, the subjects should pay attention to 
move the mouse pointer on the center of the arc of the virtual 
circular ring. The subjects tended to place the pointer at the 
center by using visual information usually. In addition, 
haptic feedback gave additional information to the subjects. 
The reaction force rapidly decreased out of the center. If the 
subject pressed the ring harder, he/she could discriminate the 
position change easy. 
 In the indirect pointing environment, since the subjects 
watched the display and couldn't watch their own hand, 
which held the mouse, they tended to use not only the visual 
information but also the haptic information. On the other 
hand, in the direct pointing environment, the subjects were 
easy to adjust the position of the mouse by watching their 
own hand.  
These caused the results that the pressure and the EMG 
in the indirect environment were larger than these in the 
direct one. In addition, in the direct pointing environment, 
the subjects tended to press the ring lower pressure at the left 
or right edge (time of 25% or 75%). Because the ring 
extends up-and-down direction at these points, the subjects 
could adjust the position of the fingertip easy.  
Moreover, when the subjects were asked to give their 
impressions after the experiment, a variety of opinions were 
expressed as to which environment the operativity best 
supported; the overall opinion was that both environments 
were almost the same. 
VI. 
DISCUSSION 
When compared with an indirect pointing environment, it 
turned out that the EMG generated in the flexor digitorum 
superficialis muscle and the pressure on the fingertip in the 
direct pointing environment were lower. Since the portion of 
the finger that was directly touching the object in this 
situation was hidden like it is in the real world, it was 
believed to influence the subject to touch more carefully. 
In the operation of a two-dimensional vision display, it 
has been reported that, when making a comparison between 
an indirect pointing environment using a pointing device and 
a direct pointing environment in which the target is touched 
with a finger, the direct pointing is superior in terms of 
operating time and operability [8]. However, there is no 
significant difference in terms of operating time or the locus 
of operation in this study. A direct pointing environment has 
predominance when operating using vision alone, but when 
haptic presentation is also involved, it can be said that 
differences in the pointing environments do not have a big 
influence on the performance of haptic presentation. The 
direct pointing environment has advantages. It enables a user 
to touch an object by using his/her own fingertip similar to 
the real world. Also the user can perceive the shape of a 
virtual object by combining the device and a real object such 
as a ruler and so on. However, since implementation of direct 
313
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

pointing environment is required capabilities of high 
accuracy and high-speed position measurement, it is difficult 
to develop such environment usually. From the previous 
study, direct pointing visual feedback environment shows 
superior task performance than that of indirect pointing 
environment. However, our result means same task 
performances of the direct pointing environment can be 
realized with the indirect environment by adding haptic 
sensation. 
When developing a lower DOF haptic device, the haptic 
rendering algorithm for compensating the decrement of DOF 
is required. Because 1 DOF mouse , which developed in this 
research, has only up-and-down haptic presentation function, 
some techniques are required. For example, as mentioned in 
this study, a gradually force increasing method to the user's 
finger to avoid unwanted vibration when presenting a wall of 
a large cube is required.  
Moreover, when a user traces the surface of a 
quadrangular pyramid with the multiple DOF haptic device, 
the user can perceive the edge of the pyramid, because the 
reaction force vector is rapidly change on the edge. However, 
with 1 DOF device, it has ability to present the up-and-down 
direction only. When the user's finger overcomes an edge, 
the reaction force is not change hardly, since the device 
cannot present horizontal force vector. The user tend to feel a 
blur edge. In order to solve this, when a reaction force vector 
changes, increasing method of the feeling of an edge, such as 
adding vibration is required. 
When building a direct pointing environment, it is 
necessary to implement high-speed and highly precise 
position detection for optimum fingertip operation. Since the 
infrared multi-touch overlay used in this research was 
insufficient in respect of speed, this issue was solved by 
using a set of optical sensors collectively. To build a direct 
pointing environment, it would be necessary to solve this 
problem, possibly by using multiple sensors. 
As a result of the experiment, users can trace target 
positions in high accuracy in both pointing environments. 
As an application of the proposed system, the operativity of 
a GUI can be improved. In addition, our system can be 
applied to a computer aided surgery (CAS) and a surgical 
training system because the system has capability to present 
various shapes and elasticity of virtual organs. 
 There was a report of incongruity about equipment. 
Since the end effector is a plane attached to the linkage. It is 
inclined according to the finger‟s position even though the 
inclination of a touched surface is not changing. To solve 
this issue, it should be fabricated with a thimble and a 
gimbal which center is identical to the center of the fingertip. 
We plan to change the mechanism of the current end 
effector. 
VII. CONCLUSION AND FUTURE WORK 
In this research, we developed a prototype system, 
consisting of a 1 DOF mouse-like haptic device and a 
tabletop display with a multi-touch overlay sensor. 
By actually constructing such a system including a  
haptic presentation device featuring a low DOF, the elements 
required to make the system functional were clarified. 
Moreover, it was shown that the pointing environment 
does not contribute greatly to the performance in haptic 
presentations by measuring EMG etc. 
As a haptic rendering technique, we proposed a virtual 
wall rendering method that is perpendicular to the ground. 
As one of other solutions is a method of using the 'visual 
dominance' in haptic presentation. We think it is possible to 
touch the vertical wall freely without sense of incongruity 
by presenting a steep slope as haptic sensation, and an 
image of the vertical wall as visual sensation simultaneously. 
We plan to develop such haptic rendering technique. 
We also plan to use „Pseudo-haptics‟ [9] with our system 
as a technique for increasing the capability of haptic 
expression. If a low DOF device is supplemented by visual 
information, the flexibility of the system can be extended to 
use with the pseudo haptics technique. 
Moreover, although this current system only receives 
haptic presentation, we plan to improve the system so that a 
user can change the shape of virtual objects etc. 
ACKNOWLEDGMENT 
This work was supported by JSPS KAKENHI Grant 
Number 22500103. 
 
REFERENCES 
[1] Motoyuki Akamastu, Sigeru Sato, “A multi-modal mouse 
with tactile and force feedback,” International Journal of 
Human-Computer Studies, Volume 40, Issue 3, pages 
443-453, 1994. 
[2] Ken‟ichi Fukunaka, Masataka Imura, Yoshihiro Yasumoto, 
Yoshitsugu Manabe, Kunihiro Chihara, “Evalution of Haptic 
Display for Presentation of Softness by MR-Fluid,” 
Proceedings of the Virtual Reality Society of Japan Annual 
Conference, Volume 9, pages 1C1-3,2004. 
[3] Nicolai Marquardt, Miguel A. Nacenta, James E. Young, 
Sheelagh Carpendale, Saul Greenberg, Ehud Sharlin, “The 
haptic tabletop pack: Tactile feedback for interactive 
tabletops,” ITS '09 Proceedings of the ACM International 
Conference on Interactive Tabletops and Surfaces, pages 
85-92, 2009. 
[4] Samuel B. Kesner, Robert D. Howe, “Discriminating Tissue 
Stiffness with a Haptic Catheter:Feeling the Inside of the 
Beating Heart”, IEEE-World Haptics Conference 2011, 
pp.13-18, 2011. 
[5] Yuichi Miyamoto, Hiroaki Yano, Hiroo Iwata, “Remotr 
Haptic Preception System Using a Laser Range Finder,” 
Proceedings of the Virtual Reality Society of Japan Annual 
Conference ,Vol.014, No.HDC03, p.19-22 ,2009. 
[6] Jinha Lee and Hiroshi Ishii, “Beyond, collapsible tools and 
gestures for computational design,” Proc of CHIEA ‟10,pp. 
3931-3933, 2010. 
[7] Yu-uki Enzaki, Ryota Sato, Hiroaki Yano, Hiroo Iwata, 
“Development of Device Art Toolkit,” Proceedings of the 
Virtual Reality Society of Japan Annual Conference, Vol. 15 
No. 3, pp.417-426, 2010. 
[8] Evan D. Graham, Christine L. MacKenzie, “Physical versus 
virtual pointing,” CHI '96 Proceedings of the SIGCHI 
Conference on Human Factors in Computing Systems, pages 
292 – 299, 1996. 
[9] Anatole Lécuyer, “Simulating Haptic Feedback Using 
Vision,” A Survey of Research and Applications of 
Pseudo-Haptic Feedback, Precence,18(1)pp.39-53, 2009. 
314
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

