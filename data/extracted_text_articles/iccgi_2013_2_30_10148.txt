Administration of Knowledge Assessment at Riga Technical University 
Natalija Prokofjeva, Alla Anohina-Naumeca, Olga Lebedeva 
Faculty of Computer Science and Information Technology 
Riga Technical University 
Riga, Latvia 
e-mail: Natalija.Prokofjeva@rtu.lv, Alla.Anohina-Naumeca@rtu.lv, o.lebedeva@inbox.lv
 
Abstract—This paper is devoted to administration of students' 
knowledge assessment at the Faculty of Computer Science and 
Information Technology of Riga Technical University. The 
faculty uses a number of computer-based software systems for 
this purpose. The goal of the research is to evaluate them from 
the perspective of their usefulness for administration of 
students’ 
knowledge 
assessment. 
This 
paper 
provides 
description of each system and the results of the analysis made 
on the basis of the experts’ survey.  
Keywords- computer-based learning; knowledge assessment; 
experts' survey 
I. 
 INTRODUCTION 
Due to the rising speed of scientific and technical 
progress, the volume of knowledge and skills needed by 
contemporary specialists is continuously growing. This 
substantially 
increases 
requirements 
in 
relation 
to 
organization of the study process in educational institutions 
and especially to selection of an appropriate knowledge 
assessment strategy. Nowadays, computer-based knowledge 
assessment is of special interest because it allows 
administration of knowledge assessment activities at all 
stages of the study process, it substantially reduces both 
workload of teachers and time spent for preparation and 
evaluation of students’ assignments, as well as it assures the 
objectivity of assessment process.  
The Faculty of Computer Science and Information 
Technology of Riga Technical University (RTU) is not an 
exception. Its staff is making research in the field of 
computer-based learning already for 40 years. Today, both 
traditional methods of knowledge assessment and computer-
based software systems (electronic textbooks, the learning 
management 
system, 
the 
Moodle-based 
e-learning 
environment, and the concept map based intelligent 
knowledge assessment system) developed for this purpose 
are used in the educational process. 
The goal of the research presented in this paper is to 
evaluate the developed computer-based software systems 
from the perspective of their usefulness for administration of 
students’ knowledge assessment. This paper contains 
description of the mentioned systems, as well as results of 
their analysis and comparison. 
This paper is organized as follows. Section II presents a 
brief overview of related works. Section III contains 
descriptions of the software systems used in the study 
process at the faculty. Section IV presents research 
methodology and results of the analysis made. Conclusions 
are given at the end of this paper. 
II. 
RELATED WORK 
Many international scientific conferences (such as IEEE 
ICALT, IADIS e-Learning, IASTED CATE, etc.) and e-
journals [5][6][7] are dedicated to research in the field of 
computer-based learning and knowledge assessment. 
Researchers 
in 
this 
field 
are 
developing 
and 
implementing new methods of knowledge assessment 
[1][2][3][4]. The implementation of these methods can be 
found in modern e-learning systems. Latest research 
indicates that the use of such systems has a positive effect on 
students’ progress in studies, it increases their motivation, 
and they appreciate this kind of approach to learning process 
[16][17][18]. 
However, the evaluation of e-learning systems from the 
perspective of students’ benefits doesn’t let to evaluate the 
usefulness of these systems for students’ knowledge 
assessment. That’s why this paper aims to compare e-
learning systems that are used in RTU and to determine 
whether they are close to the benchmark – the model of an 
ideal system, which is based on the features chosen by 
experts. 
III. 
SOFTWARE SYSTEMS USED IN THE STUDY PROCESS 
A. The Electronic Textbook for HTML Language 
The electronic textbook “Learn HTML from scratch” is a 
computer-based learning program, which includes eight 
topics on HTML language: structure of a document, text, 
graphics, references, tables, frames, styles, and dynamic 
HTML [8]. Each topic contains theoretical material 
supplemented by several examples and a series of 
assessment questions. Fig. 1 displays the structure of the 
electronic textbook. 
Three modes of operation (self-assessment, testing, and 
reference mode) and a variety of knowledge assessment 
methods and models [9] are implemented in the electronic 
textbook. Two types of questions (multiple choice questions 
and text/numerical input) are available for assessment 
activities. 
A method called “Strict sequence” is used in the mode of 
self-assessment. It means that a set of assessment tasks is 
prepared prior to the test and tasks are offered to all students 
in the form of the same fixed set. In this mode, students 
answer questions and receive a short overview of their 
performance (number of correct answers, time for 
completing a specific task, and average score). 
34
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

 
 
Figure 1. Structure of the electronic textbook. 
 
In the testing mode, a method called “Random selection” 
is used for creating and issuing a set of assessment tasks. 
Therefore, the set contains n tasks, which are selected in a 
random fashion from a task pool. 
A test for final examination is implemented in the 
textbook. It is composed of questions from all eight topics. 
Therefore, it allows assessing of students' knowledge in 
relation to the whole course. A set of assessment tasks is 
formed suing the method “Strict sequence”.  
Student’s score is the average score obtained taking into 
account the student's number of correct answers and 
completion time of assessment tasks. 
The electronic textbook „Learn HTML from scratch” 
was applied as a learning tool in the course "Development of 
Web Applications for Internet". Results of the research made 
in 2003 showed that students actively used the textbook both 
for learning and for knowledge assessment [10]. However, 
the electronic textbook had a number of significant 
drawbacks: a) it could be used only for one study course, b) 
learning materials (content of topics, sections, examples, and 
a set of assessment tasks) were embedded into the book, 
thus, making difficult their modifications and changing, and 
c) the electronic textbook was available for use only from 
RTU local network. However, the major disadvantage was 
related to usage of inappropriate methods („Strict sequence” 
and „Random selection”) for forming a set of assessment 
tasks for continuous and final assessment [11]. 
B. The Universal Electronic Textbook 
The universal electronic textbook was developed in 2005. 
The drawbacks of the previous book were eliminated and its 
functionality was extended [12]. Fig. 2 shows the structure of 
the universal electronic textbook. 
The textbook allows the teacher a) to develop new 
courses by determining their structure - number of sections 
and topics, b) to change and/or to add learning materials of a 
course, c) to create a set of assessment tasks, d) to choose a 
topic or topics for knowledge assessment, and e) to obtain 
assessment results of a student or a group of students. The 
main advantage of the universal electronic textbook is a 
teacher's possibility to administer different types of 
knowledge assessment: prior, continuous, and final 
assessment. 
In assessment of prior knowledge, the methods “Strict 
order” and “Random selection” are used for creating and 
issuing a set of assessment tasks. They were selected on the 
basis of recommendations concerning usage of different 
methods for creation of a set of assessment tasks in different 
types of knowledge assessment. Recommendations were 
acquired through the experts’ survey presented in [11]. In 
the universal electronic textbook, the teacher can perform 
continuous and final knowledge assessment according to the 
sequence, in which learning material was mastered by 
preparing a test from assessment tasks related to one or 
more topics. 
 
 
 
Figure 2. Structure of the universal electronic textbook. 
 
With the help of the universal electronic textbook a 
student can master a chosen study course (learning mode), 
as well as he/she can assess knowledge in a particular topic 
or in the entire course (testing mode). Two types of 
questions are used: multiple choice questions and 
text/numerical input. However, comparing with the first 
electronic textbook, this book allows the teacher to specify 
the difficulty level of an assessment task (minimal, average, 
or maximal).  
The mentioned textbook was used in the study course 
„Development of Web Applications for Internet” from 2005 
till 2007. 
C. The Learning Management System 
Learning Management System (LMS) [13] includes two 
modes of operation that are directly related to knowledge 
assessment: random selection of tasks and/or questions for 
assessment and training mode (Fig. 3). Both modes can be 
used for knowledge self-assessment as well. 
The mode of the random selection uses the non-adaptive 
assessment method. In this case the number of questions for 
knowledge assessment in a group of students is defined by 
the teacher, who also determines the number of tasks of 
different difficulty level (maximal, average, or minimal), 
which should be included in each set of assessment 
questions. Moreover, the teacher specifies type of comments, 
which will be provided as a reaction to student’s answers: 
short (right, partly right, or wrong) or detailed with 
explanation of a mistake made. In case of self-assessment, 
the student chooses and sets these parameters by him/herself. 
35
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

 
 
Figure 3. Structure of the LMS 
 
Depending on the choice, the training mode performs 
non-adaptive assessment, when the student completes either 
all or a selected number of assessment tasks, or partly 
adapted assessment (taking into account student’s answers), 
when the number of tasks provided to the student depends on 
his/her overall success. In this mode, type of comments, 
which will be provided by the system, can also be chosen.  
After completion of the test, the student gets a grade, 
which takes into account both correctness of answers and 
difficulty level of questions. 
At present, the LMS includes 9 e-courses related to the 
study courses „Software Engineering”, “Software Metrology 
and 
Planning”, 
“Software 
Development 
Tools 
and 
Environments”, and “Programming Languages”. During the 
period from 2004 till 2006, students had possibility to use the 
courses included in the system for self-assessment, training, 
and/or learning. Since 2007, students’ knowledge assessment 
in the mentioned courses is compulsory and is usually 
performed during practical assignments in class. Usually, 
each student receives from 8 to 10 assessment tasks. At the 
same time, in order to improve the grade in a test, students 
are allowed to take the test repeatedly in 2 days’ time. In this 
case the grade is determined by the teacher. Students can 
also use other modes of system’s operation at any time. 
D. ORTUS Portal 
RTU has developed the portal ORTUS, which provides 
administrative, scientific, and educational support for 
students and university staff. One part of this portal is a 
Moodle-based e-learning environment that allows creation of 
e-learning courses starting from uploading of different 
learning materials and finishing with developing tests and 
administering knowledge assessment activities.  
ORTUS portal has been used in the study process since 
2008. In relation to knowledge assessment, the teacher can 
create a test, set the time for its completion and the number 
of attempts. The test can be completed in class (one attempt) 
or at a distance (more than one attempt). It is possible to 
create tests from different categories and types of questions. 
All together, 10 types of questions are available. The teacher 
has possibility to assign number of points for each question 
taking into account its difficulty level. Comments for all 
kinds of questions are envisaged. The only drawback of the 
ORTUS e-learning environment is availability of only one 
method of knowledge assessment, namely, “Random 
selection”. 
E. IKAS system 
IKAS is a web-based intelligent knowledge assessment 
system, which is intended for assessment of students’ 
structural knowledge through the use of concept maps [14]. 
It has been developed since 2005 and, therefore, the system 
is described in many publications, for example [3][15][16]. 
As a result below only the general overview of the system is 
given. 
The main goals of the system are the following: a) to 
promote students’ structural knowledge self-assessment and 
b) to support teachers in improvement of study courses 
through systematic assessment and analysis of students’ 
knowledge 
structures. 
Knowledge 
self-assessment 
is 
supported by automatic evaluation of students’ concept 
maps and provision of informative and tutoring feedback. 
Systematic knowledge assessment is based on the 
possibility to extend an initially created concept map for 
other assessment stages. Statistics on differences between 
students’ and teacher’s concept maps allow teachers to 
improve their courses. 
IKAS supports three categories of users: a) an 
administrator, b) a teacher, and c) a student. The 
administrator prepares the system for use by other users and 
manages its default parameters and data related to 
knowledge assessment process and its participants. 
Activities directly related to knowledge assessment are split 
between the teacher, the student, and the system and they 
include: 1) creation of a concept map by the teacher; 2) 
reproduction of the teacher’s concept map by the student 
during completion of concept map based tasks; 3) 
comparison of the teacher’s and student’s concept maps by 
the system; 4) generation of feedback by the system. 
Six tasks of different degrees of difficulty are 
implemented. Four of them are ‘fill-in-the-map’ tasks where 
an obligatory component is the structure of a concept map, 
which must be filled-in by students using available concepts 
and/or linking phrases. Last two tasks are ‘construct-the-
map’ tasks where the student constructs a concept map from 
provided concepts and/or linking phrases. Ten transitions 
between tasks are realized: five of them increase the degree 
of task difficulty and another five reduce it.  
The system provides rich student’s support and includes 
a number of adaptive, adaptable, and intelligent features. 
Student’s support is comprised of possibility to change the 
degree of task difficulty, to insert in automatic way some 
concepts into the provided structure of the concept map, to 
explain a concept, to check a created proposition, as well as 
quantitative data (like score received, time spent, number of 
help used, etc.) and qualitative data (concept mastering 
degrees, individual study plan). The main task of the system 
36
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

is to perform automatic evaluation of students’ concept 
maps. This is done in intelligent way by using the teacher’s 
concept map as a reference map and a comparison algorithm 
that is based not only on the isomorphism of both graphs 
representing concept maps, but which is sensitive to the 
arrangement and coherence of concepts in students’ concept 
maps and is capable to recognize partly correct patterns of a 
student’s solution. Operation of the IKAS is based on 
interpretation of values of parameters available in a student 
model. The student model supports four adaptation 
operations in the IKAS: selection of the initial degree of 
task difficulty at the first assessment stage and its changing 
at next assessment stages, as well as setting and changing 
priorities of types of concept explanation. Adaptable 
features of the system available to students include the 
following ones: 1) adjusting the degree of task difficulty by 
directly changing the knowledge level of the course in the 
student model or reducing the degree of task difficulty 
during the completion of CM based tasks; 2) adjusting 
settings of the user interface such as language, theme, etc.; 
3) changing approach for receiving of explanations and 
priorities for different types of concept explanation. 
Since 2005, IKAS has been evaluated in more than 20 
courses. Typically the system is used in content-rich 
courses, which include a lot of closely interrelated concepts, 
for example, “Fundamentals of Artificial Intelligence”, 
“Methods of Systems Theory”, “Discrete Structures in 
Computer Science”. As a rule, a teacher prepares a concept 
map for a logically completed part of a course (module or 
topic block) and gives it to students at the end of this part. 
After completion of concept map based tasks by students, 
the teacher examines statistical data about students’ 
incorrect or missing relationships and makes corrections in 
further curriculum of the course. Therefore, during the 
course students work with concept maps 3-4 times. 
F. Summary of the Described Systems 
Table 1 specifies the main characteristics of the 
previously described software systems. These systems are 
successfully used at the Faculty of Computer Science and 
Information Technology of RTU for knowledge assessment 
and self-assessment in the following study courses: “Data 
Structures”, 
”Programming 
Languages”, 
„Software 
Engineering”, 
“Software 
Metrology 
and 
Planning”, 
“Fundamentals of Artificial Intelligence”, “Methods of 
Systems Theory”, “Discrete Structures in Computer 
Science”, etc. Results of the research presented in 
[16][17][18] show how use of the systems improves 
progress of students, motivates students, and increases 
quality of their knowledge at a stage of the final knowledge 
assessment (examination). 
IV. 
ANALYSIS OF THE SYSTEMS 
The next sections discuss the methodology and results of 
the research. 
A. Research Methodology 
During the research presented in this paper the experts’ 
survey was performed with aim to determine features of e-
learning systems, which are most significant for knowledge 
assessment. The group of experts was selected by studying 
literature in the field of e-learning and through direct 
communication between the authors of this paper and 
experts at international workshops and conferences devoted 
to problems of computer-based knowledge assessment. As a 
result, nine experts participated in the survey.  
The questionnaire used in the survey asked experts to 
evaluate importance of different features of e-learning 
systems, e.g. the processing of student’s answer given in 
natural language, the management of knowledge assessment 
on the bases of mathematical models, etc., in relation to 
administration of students’ knowledge assessment in such 
systems. Thirty features were included. Authors offered the 
following scale for evaluation of importance of each feature:  
10 
 an important and useful feature, but it is 
possible that it cannot be implemented at the 
moment (such features should not be in a 
large number); 
8 ÷ 6 
 a feature, which can be implemented and 
should be implemented in the system; 
4 
 a useful, but not so important feature 
(moreover, it can be easily implemented); 
1 ÷ 2 
 a feature, without which the quality of the 
system will not suffer significantly; 
0 
 a useless feature. 
Data acquired through the questionnaire were processed 
in 2 stages. First of all, the coefficient of concordance W 
characterizing agreement between experts was calculated 
taking into account the methodology presented in [19].  
After that, importance (Sj) of each feature of e-learning 
systems was identified and the list of features in the 
decreasing order (the most important feature has the 
smallest Sj value) was created. 
At the end, the ordered list of features was used for 
evaluation of software systems described in this paper. For 
this purpose the following indicator was introduced: 
,
1
j
n
j
S jC
Z 


 
(1) 
where Sj – importance of j–th feature; Cj – the coefficient 
characterizing extent of implementation of the feature in a 
system under evaluation, the value of this coefficient is 
determined by the reviewer of the system and depends on 
the level of feature implementation, but the range of values 
is permanent: Cj = [0..1]. 
The authors of this paper determined the following 
levels of feature implementation: 
 
if a feature is fully implemented in the system, then 
Cj = 1; 
 
if a feature is implemented, but it has some 
shortcomings, then Cj = 0.8; 
 
if a feature is under implementation, then Cj = 0.4; 
37
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

 
if a feature is not implemented, then Cj = 0. 
Further an indicator of relativity z was calculated: 
benchmark
Z
Z
z 
 
(2) 
It characterizes the degree of compliance of a system 
under evaluation to a benchmark. The benchmark is 
calculated when values of the coefficient for all features are 
equal to 1. The value of the coefficient z is in the range from 
0 to 1. The closer this coefficient is to 1, the closer the 
system is to the ideal system. 
B. Results of the survey 
The range of values for the coefficient of concordance 
W can vary from 0 to 1. In our case W = 0.64, so we can 
conclude that the agreement between experts is high. The 
involved experts considered the following features as the 
most important ones: 
 
Management of the knowledge assessment process 
on the basis of mathematical models;  
 
Possibility to analyze different types of answers 
(word, phrase, hotspot on an image, etc.); 
 
System’s openness for further improvements and 
development; 
TABLE I.  
SUMMARY OF SYSTEMS 
 
Electronic Textbook 
Universal Electronic 
Textbook 
LMS 
ORTUS 
IKAS 
Users 
Student 
Student; Teacher 
Student; Teacher; 
Author; Administrator 
Student; Teacher 
Student; Teacher; 
Administrator 
Courses 
HTML language 
Any course 
Any course 
Any course 
Any course 
Mode 
Testing; Reference; 
Self-assessment 
Learning; Testing 
Random selection of 
tasks and/or questions 
for assessment; 
Training; Self-
assessment 
Training; 
Knowledge assessment 
Knowledge 
assessment; 
Knowledge self-
assessment with 
tutoring component 
Methods 
Fixed sequence 
 
Fixed sequence; 
Random selection 
 
Fixed sequence; 
Random selection 
 
Random selection 
 
The student starts with 
teacher’s specified 
degree of task 
difficulty. Further the 
degree can be changed 
on the basis on 
student’s request or in 
adaptive manner 
Adaptive 
knowledge 
assessment 
No 
No 
No 
Yes 
Yes 
Task type 
Multiple choice 
questions; 
Text/numerical input 
Multiple choice 
questions; 
Text/numerical input 
Multiple choice 
questions; Multiple 
response questions; 
Matching; 
Text/numerical input 
Description; Essay; 
Multiple choice 
questions; Multiple 
response questions; 
Matching; True/False; 
Text/numerical input; 
Equation input; 
Sentence input 
“Fill-in-the-map”; 
“Construct-the-map” 
 
 
Possibility of using data from a domain model 
during knowledge assessment; 
 
Possibility of performing adaptive knowledge 
assessment; 
 
Support of different types of users (student, author, 
teacher, administrator, etc.). 
As the most unimportant features the experts mentioned 
the following ones: 
 
System’s functioning in a network (Internet, a local 
network, etc.); 
 
Provision of the certain response time to users’ 
actions; 
 
Possibility of using of probabilistic assessment 
models. 
Table II presents results of evaluation of the software 
systems taking into account the coefficients Z and z. 
TABLE II.  
RESULTS OF EVALUATION 
  
Electronic 
Textbook 
Universal 
Electronic 
Textbook 
LMS 
ORTUS 
IKAS 
Benchmark 
Z 
64.8 
136.4 
209.6 
298.4 
242.6 
465 
z 
0.14 
0.29 
0.45 
0.64 
0.52 
1 
 
The systems “Electronic Textbook” and “Universal 
Electronic Textbook” received the smallest evaluation 
(z=0.14 and z=0.29 accordingly), but ORTUS portal is 
closest to the benchmark (z=0.64). 
CONCLUSION 
Taking into account experts' opinion about the most 
important features of e-learning systems for students’ 
knowledge assessment, the methodology for the usefulness 
38
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

evaluation of such systems 
were developed. This 
methodology can be used in a combination with other 
methodologies for the evaluation of any e-learning system, 
as well as for comparison of this kind of systems between 
themselves. Five systems for administering students' 
knowledge assessment were evaluated using the developed 
methodology. Evaluation results showed that ORTUS and 
IKAS are the closest to the benchmark. These systems 
implements methods of adaptive assessment of students' 
knowledge, and they are open for further improvement and 
development. Therefore, the further work will be related to 
the improvement of ORTUS and IKAS considering the list 
of the most important features for knowledge assessment, 
determined by experts. 
ACKNOWLEDGMENT 
Travel costs and participation fee for this conference are 
financially supported by ERDF project „The development of 
international cooperation, projects and capacities in science 
and 
technology 
at 
Riga 
Technical 
University” 
Nr.2DP/2.1.1.2.0/10/APIA/VIAA/003. 
REFERENCES 
[1] C. Gütl, K. Lankmayr, J. Weinhofer, and M. Höfler, 
"Enhanced Automatic Question Creator – EAQC: Concept, 
Development and Evaluation of an Automatic Test Item 
Creation Tool to Foster Modern e-Education", Electronic 
Journal of e-Learning, Vol. 9, Issue 1, 2011, pp. 23 – 38. 
[2] P. N. K. Lau, S. H. Lau, K. S. Hong, and H. Usop, “Guessing, 
Partial Knowledge, and Misconceptions in Multiple-Choice 
Tests”, Journal of Educational Technology & Society, Vol. 
14, Issue. 4, Special Issue on "Advanced Learning 
Technologies", 2011, pp. 99 – 110. 
[3] A. Anohina-Naumeca, J. Grundspenkis, and M. Strautmane, 
“The Concept Map Based Assessment System: Functional 
Capabilities, 
Evolution, 
and 
Experimental 
Results”, 
International Journal of Continuing Engineering Education 
and Life-Long Learning, Vol. 21, Issue. 4, 2011, pp. 308-327. 
[4] R. Z. Cabada et al., „EDUCA: A Web 2.0 Collaborative, 
Mobile and E-learning Authoring System”, Proceedings of 
IEEE International Conference on Advanced Learning 
Technologies (ICALT-2009), Riga, Latvia, Jul. 2009, pp. 287 
– 289. 
[5] The Electronic Journal of e-Learning (EJEL) [Electronic 
resource] / – http://www.ejel.org/main.html [retrieved: May, 
2013]. 
[6] Journal of Educational Technology & Society [Electronic 
resource] / – English version: http://www.ifets.info/, Russian 
version: 
http://ifets.ieee.org/russian/periodical/journal.html 
[retrieved: May, 2013]. 
[7] International Academy, Research, and Indusrty Association 
(IARIA) 
[Electronic 
resource] 
/ 
– 
http://www.iariajournals.org/ [retrieved: April, 2013]. 
[8] L. Zaitseva, N. Prokofyeva, and V. Popko, Electronic 
Textbook 
«Study 
HTML» 
// 
Proceedings 
of 
TECHNOMAT&INFOTEL 2004. Materials, methods and 
technology. Scientific articles. - Vol.1. - Bulgaria, 2004. – p. 
63 - 70. 
[9] N. Prokofjeva, “Computer knowledge control models and 
methods”, Proceedings of First International Conference 
“Information Technologies in Education for All”, ITEA - 
2006, Ukraine, IRTC – Kiev, 2006, p. 231 – 240 (in Russian). 
[10] V. Popko and N. Prokofjeva, “Elektroniskās mācību grāmatas 
izstrāde”, RTU zinātniskie raksti. 5. sērija. Datorzinātne. 
Lietišķās datorsistēmas. 18. sējums. Rīga: RTU, 2004, - 103. - 
109. lpp.(in Latvian) 
[11] N. Prokofjeva, “The Methodical and Technical Aspects of 
Students Knowledge Control”, Proceedings of the 13th 
Education and Virtuality International Conference, VIRT - 
2011, Ukraine – Yalta, 2011, pp. 263 – 272. (in Russian). 
[12] L. Zaitseva and J. Bule, “Electronic Textbook and E-Learning 
System in Teaching Process”, Proceedings of E-learning 
conference'06 
Computer 
Science 
Education, 
Coimbra, 
Portugal, Sept. 2006, pp. 189 – 192. 
[13] L. Zaitseva, J. Bule, and U. Kuplis, “Advanced e-learning 
system development”, Proceeding of International Conference 
“Advanced Learning Technologies and Applications”, ALTA-
2003, Kaunas, Lithuania, 2003, pp. 14-18. 
[14] J. D. Novak and D. B. Gowin, “Learning How to Learn”, 
Cambrige University Press, 1984, 199 p. 
[15] A. Anohina-Naumeca and J. Grundspenkis, “Concept Maps as 
a Tool for Extended Support of Intelligent Knowledge 
Assessment”. Proceedings of the 5th International Conference 
on Concept Mapping, Malta, Sept. 2012. 
[16] J. Grundspenkis, “Concept Map Based Intelligent Knowledge 
Assessment System: Experience of Development and 
Practical Use”, Multiple Perspectives on Problem Solving and 
Learning in the Digital Age, Springer, pp. 179-198. 
[17] L. Zaitseva, “E-courses using Results and Efficiency”, 
Proceedings of  the 11th IASTED International Conference 
“Computers and Advanced Technology in Education”, CATE 
– 2008, Crete, Greece,Sept. 2008, pp. 90 – 93. 
[18] L. Zaiceva and N. Prokofjeva, “Knowledge control during the 
preparation of IT specialists in Riga Technical University”, 
International Conference on Information Technologies (ICIT 
2012): Information and Communication Technologies in 
Education, Manufacturing and Research, Russia, Saratov, Jun. 
2012, pp 1-10. 
[19] S. D. Beshelev and F. G. Gurevich, Mathematical and 
statistical methods of expert evaluation. Moscow: Statistica, 
1980 (in Russian). 
 
39
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-283-7
ICCGI 2013 : The Eighth International Multi-Conference on Computing in the Global Information Technology

