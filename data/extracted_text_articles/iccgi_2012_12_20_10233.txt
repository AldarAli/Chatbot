An Implementation of Discriminative Common Vector Approach Using Matrices 
 
Mehmet Koc, Atalay Barkana 
Electrical and Electronics Engineering 
Anadolu University 
Eskisehir, Turkey 
{mkoc6, atalaybarkan}@anadolu.edu.tr 
 
 
Abstract— If one sample per class is available in a face 
recognition problem, vector-based methods which use within-
class scatter will fail.  The reason for that is the zero within-
class matrix. In this paper a two dimensional extension of the 
discriminative common vector approach (2D-DCVA) is 
proposed. The performance of the proposed method is 
compared with discriminative common vector approach (1D-
DCVA) and two dimensional Fisher linear discriminant 
analysis (2D-FLDA) in ORL, FERET, YALE, and UMIST face 
databases in one sample problem. Our proposed method 
outperforms 1D-DCVA and 2D-FLDA in all databases. 
Keywords- one sample problem; common vector; DCVA; two 
dimensional FLDA  
I. 
 INTRODUCTION  
Face recognition has many application areas such as 
security, law enforcement, person identification [1,2]. If 
only one sample per person is available, then the problem 
gets difficult. This situation is called one sample problem 
[3]. Methods which use within-class scatter such as 
conventional Fisher discriminant analysis (1D-FLDA) will 
suffer from one sample problem because within-class matrix 
is a zero matrix. Many algorithms have been proposed to 
overcome this challenge [3,4,5,6,7]. General tendency at 
these methods is generating the virtual samples to increase 
the training set size. But this is not the solution of the 
singularity problem because in face recognition problems 
dimension of the feature space is high with respect to the 
number of feature vectors. This problem is called small 
sample size problem [8]. One solution to overcome the 
singularity problem is using the two dimensional variant of 
one dimensional methods. Two dimensional Fisher 
discriminant analysis (2D-FLDA) [9] is a solution of the 
singularity problem in 1D-FLDA. This method was used in 
[4] and [5] after generating virtual samples. Also 
discriminative common vector approach (1D-DCVA) which 
is a variation of FLDA comes up with a solution that 
overcomes the singularity problem of 1D-FLDA [10].  
In this work we proposed a two dimensional extension 
of the discriminative common vector approach. In order to 
obtain unique common vector for each class, we use feature 
vectors instead of feature matrices in the first stage of this 
method. Then we convert the common vectors into matrices 
and calculate the discriminative common matrices. In [11], 
feature matrices are used to obtain common vectors. This 
method though cannot get unique common vectors. A brief 
review of the discriminative common vector approach    
(1D-DCVA) is given in Sec.II.  Two dimensional extension 
of the discriminative common vector approach is given in 
Sec.III. We used QR decomposition with column pivoting 
(QRCP) method to generate the virtual samples. QRCP 
method is given in Sec.IV. We tested the performance of 
2D-DCVA 
in 
four 
different 
databases. 
Database 
descriptions and the experiments are given in Sec.V, and 
finally the results are discussed in Sec.VI. 
 
II. 
DISCRIMINATIVE COMMON VECTOR APPROACH 
Discriminative common vector approach (1D-DCVA) is 
first introduced in [10]. The method gives a solution to the 
limitations of methods that use the null space of the within-
class scatter matrix.   
Let   be the number of classes,   be the number of 
feature vectors from each class, and let   
  be the     
feature vector from     class. Then the within-class scatter 
matrix can be written as  
 
   ∑ ∑(  
    )(  
    ) 
 
   
 
   
  
(1) 
 
where      
⁄
∑
  
 
 
   
 is the mean of the     class. The 
method can be summarized as follows: 
 
Obtain the projection matrix   [          ] 
where                 are the eigenvectors 
corresponding to the nonzero eigenvalues of   . 
 
Obtain the common vectors by projecting any 
feature vector from each class onto the null space of 
  . 
    
 
   
        
                  
(2) 
 
 
Compute the eigenvectors    of the scatter matrix 
of the common vectors     , corresponding to the 
nonzero eigenvalues and obtain the projection 
matrix   [         ]  . In here       is 
defined as 
260
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

 
     ∑(    
 
     )(    
 
     ) 
 
   
   
(3) 
 
where      is the mean of the common vectors, i.e., 
       
⁄
∑
    
 
 
   
. 
 
Obtain the discriminative common vectors by 
projecting any sample from each class onto the 
range space of     . 
    
 
      
                  
(4)  
Let      be the test vector to be classified. Then 
classification can be done according to the following 
decision rule. 
         
 
{‖    
 
        ‖}              
(5)  
III. 
TWO DIMENSIONAL EXTENSION OF DCVA 
Let   be the number of image classes,  , be the number 
of feature vectors in each class and,   
   be the     two 
dimensional p  by  q pixel  image of the     class. We 
convert the image matrix   
 
 to a vector   
  in the            
      dimensional space.  
It is proved in [10] that the common vectors obtained 
from total within-class scatter matrix are unique for each 
class. In the first stage of the proposed method, we use    , 
to take the advantage of the uniqueness of the common 
vectors. We apply the eigen decomposition to    and 
obtain the projection matrix    of its null space using the 
eigenvectors corresponding to the zero eigenvalues   , 
   (   )       .    can be calculated as follow, 
 
    
∑
    
 
 
   (   )  
 
(6) 
 
Then the common vector of    class is calculated as 
 
     
 
     
                         
(7) 
 
It should be noted that (2) and (7) give exactly the same 
results. We convert the common vectors      
 
into p by q 
matrices,      
 
. The covariance matrix of the common 
matrices can be calculated as 
 
     ∑(    
 
     ) (    
 
     )
 
   
   
(8) 
 
where        
⁄
∑
    
 
 
   
 is the mean of the common 
matrices. We are trying to find the optimal projection 
vectors   [          ]  which maximizes the 
criterion  ( )         . Here d can be at most 
   (     ).  
We use the nearest neighbor classifier for classification. 
The discriminant features of an image     is calculated as 
 
        [  
    
      
 ]  
(9) 
 
Let       be the test image to be classified. The optimal 
projection vectors of the test image can be given as        
       [  
       
         
    ]. Then the test image is 
classified according to the following decision rule. 
 
         
 
{∑‖  
       
 ‖
 
   
}  
(10) 
 
IV. 
IMAGE DECOMPOSITION WITH QR 
QR decomposition is a well-known matrix factorization 
method [12]. If       , then it can be decomposed as 
     where        with orthogonal columns which 
span the same subspace with the columns of  , and   is an 
upper triangular matrix. QR-decomposition with column 
pivoting (QRCP) [13,14] is a modified version of QR. In 
this method the column of the matrix   are sorted such that 
the absolutes values of the diagonal elements of the matrix 
  are sorted in descending order. In this way, most of the 
energy of an image is concentrated into some basis images 
[5]. The basis images of   can be calculated as      where 
   is the     column of   and    is the      row of  . The 
orders of columns of   are stored in a permutation matrix   
such that the equation        holds. Let the 
approximation of an image matrix   be  ̂. Then it can be 
calculated as  
 
  ̂  ∑     
 
   
  
(11) 
 
Here   is selected according to the ratio   given below. 
 
∑
  
 
   
∑
  
 
   
    
(12) 
 
             are the absolute values of the diagonal 
elements of  . In experiments we selected       as in 
[5]. In Figure 1 a sample image selected from YALE face 
database and its two approximations evaluated from image 
and its transpose are shown. The image and two 
reconstructed images evaluated from the image and its 
transpose are labeled as the training images of that subject.  
 
261
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

 
Figure 1. Sample image and its virtual variants evaluated from the image 
and its transpose. 
V. 
EXPERIMENTS 
In the experimental stage, the performances of DCVA, 
our proposed method 2D-DCVA, and 2D-FLDA are 
compared in four face databases namely, ORL [15], FERET 
[16], YALE [17], and UMIST [18].  
ORL face database contains 10 grayscale images from 
each 40 subjects which are taken in the lab. Images contain 
different lighting conditions and facial expressions (e.g., 
closed eyes, glasses, smile). Also images were taken at dark 
background and subjects are in the frontal position with 
tolerance to some side movement. The original size of the 
images is       . In the experiments we used the original 
images of this database. FERET database contains 14,051 
grayscale images from 1199 subjects. In the experiments a 
subset of the database that contains 200 subjects is used. 
Each subject has two images from fa and fb probes. YALE 
face database contains 11 images from each 15 subjects. 
Database 
includes 
different 
facial 
expressions 
and 
illumination conditions (i.e., with/without glasses, happy, 
sad, sleepy, surprised, wink, center-light, right-light, 
normal). UMIST database contains 20 individuals. The 
number of pictures per person varies from 19 to 36. Images 
were taken at various angles from left profile to right 
profile.  
We preprocessed the images by cropping, scaling, 
resizing. In TABLE I. , the number of subjects, the number 
of images from each subject, and the size of the images 
taken from ORL, FERET, YALE, and UMIST databases 
after the preprocessing operations are summarized.  
TABLE I.  THE SUMMARY OF THE DATABASES AFTER THE 
PREPROCESSING STEP 
 
In the experiments we randomly select an image from 
each class. Two virtual images are constructed using this 
image with the QRCP decomposition. The original image 
and the two virtual images are used to generate the training 
set images of the subject. The remaining images are used as 
test images. This procedure is repeated 5 times and the 
recognition rates are obtained by averaging each run. We 
implement this process to all databases. The top recognition 
rates of DCVA, 2D-DCVA, and 2D-FLDA and their 
standard deviations on the databases are shown in TABLE 
II.  
TABLE II.  
THE RECOGNITION RATES ON THE DATABASES 
 
VI. 
RESULTS AND CONCLUSION 
One sample problem is an important challenge in face 
recognition. Methods which use within-class scatter matrix 
fail. In this work we proposed a two dimensional extension 
of the discriminative common vector approach. The 
performance of the proposed method is tested on four 
different databases namely, ORL, FERET, YALE, and 
UMIST. 2D-DCVA gave the best recognition results in all 
databases. 2D-FLDA outperformed 1D-DCVA in all 
databases. This may be due to fact that the matrix-based 
methods generally outperform vector based methods [19].  
 
REFERENCES 
[1] W. Zhao, R. Chellappa, P.J. Phillips, and A. Rosenfeld, 
"Face Recognition: A Literature Survey," ACM 
Computing Surveys, vol. 35, no. 4, pp. 399-458, 2003. 
[2] Z. 
Daugman, 
"Face 
and 
gesture 
recognition: 
Overview," IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 19, no. 7, pp. 675-676, 1997. 
[3] X. Tan, S. Chen, Z.-H. Zhou, and F. Zhang, "Face 
recognition from a single image per person: a survey," 
Pattern Recognition, vol. 39, no. 9, pp. 1725-1745, 
2006. 
[4] Q.-x. Gao, L. Zhang, and D. Zhang, "Face recognition 
using FLDA with single training image per person," 
Applied Mathematics and Computation, vol. 205, no. 
2, pp. 726-734, 2008. 
[5] M. Koç and A. Barkana, "A new solution to one 
sample problem in face recognition using FLDA," 
Applied Mathematics and Computation, vol. 217, no. 
24, pp. 10368-10376, 2011. 
[6] H. Yin, P. Fu, and S. Meng, "Sampled FLDA for face 
recognitionwith single training image per person," 
Neurocomputing, vol. 69, no. 16-18, pp. 2443-2445, 
2006. 
[7] M. Apaydın, Ü.Ç. Turhal, and A. Duysak, "An SVD 
based common matrix method for face recognition: 
Single 
image 
per 
person," 
25th 
International 
Symposium on Computer and Information Sciences, 
2010, pp. 289-292. 
Methods 
Databases 
ORL (%) 
FERET (%)  YALE (%)  UMIST(%) 
1D-DCVA 
69.8± 3.7 
88.8± 0.9 
58.3± 5.6 
55.9± 3.6 
2D-DCVA 
76.4± 2.4 
90.3± 0.3 
61.6± 5.2 
64.4± 4.1 
2D-FLDA 
76.0± 2.5 
90.1± 0.2 
59.5± 5.4 
61.3± 3.7 
Database 
Number of 
classes 
Number of images 
per class 
Dimension 
ORL 
40 
10 
112x92 
FERET 
200 
2 
100x100 
YALE 
15 
11 
120x110 
UMIST 
20 
19 
112x92 
262
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

[8] S. 
Theodoridis, 
and 
K. 
Koutroumbas, 
Pattern 
Recognition, Academic Press, USA, 1999. 
[9] H. 
Kong, 
E.K. 
Teoh, 
J.G. 
Wang, 
and 
R. 
Venkateswarlu, "Two dimensional Fisher discriminant 
analysis: Forget about small sample problem," Proc. 
IEEE Intern. Conf. on Acoustics, Speech, and Signal 
Processing, 2005, pp. 761-764. 
[10] H. Çevikalp, M. Neamtu, M. Wilkes, and A. Barkana, 
"Discriminative 
Common 
Vectors 
for 
Face 
Recognition," IEEE Trans. on Pattern Analysis and 
Machine Intelligence, vol. 27, no. 1, pp. 4-13, 2005. 
[11] V.D.M. Nhat and S. Lee, "Discriminative common 
images for face recognition," In proceedings of ICANN 
- Part I, vol. 3696, pp. 563-568, 2005. 
[12] T. Kailath, A.H. Sayed, and B. Hassibi, Linear 
Estimation, Prentice Hall, 1999. 
[13] S. Chakroborty and G. Saha, "Feature Selection Using 
Singular Value Decomposition and QR Factorization 
with Column Pivoting for Text-Independent Speaker 
Identification," Speech Communication, vol. 52, no. 9, 
pp. 693-709, 2010. 
[14] S. Ari and G. Saha, "In Search of an SVD and QRcp 
Based Optimization Technique of ANN for Automatic 
Classification 
of 
Abnormal 
Heart 
Sounds," 
International Journal of Biological and Life Sciences, 
vol. 2, no. 1, pp. 1-9, 2007. 
 
 
[15] ORL 
Face 
Database, 
AT&T 
Laboratories 
Cambridge1992-1994. 
[16] P.J. Phillips, H. Moon, S.A. Rizvi, and P. Rauss, "The 
FERET Evaluation Methodology for Face Recognition 
Algorithms," IEEE Transactions on Pattern Analysis 
and Machine Intelligence, vol. 22, no. 10, pp. 1090-
1104, 2000. 
[17] P. Belhumeur, J. Hespanha, and D. Kriegman, 
"Eigenfaces vs. Fisherfaces: Recognition Using Class 
Specific Linear Projection," IEEE Transactions on 
Pattern Analysis and Machine Intelligence, vol. 19, no. 
7, pp. 711-720, 1997. 
[18] D.B. Graham and G.N.M. Allinson, "Characterizing 
Virtual Eigensignatures for General Purpose Face 
Recognition," Face Recognition: From Theory to 
Applications, (Ed: Wechsler, H. ve ark.), NATO ASI 
Series / Computer and Systems Sciences, 1998, ch. 
163, pp. 446-456. 
[19] W.-S. Zheng, J.H. Lai, and S.Z. Li, "1D-LDA vs. 2D-
LDA: When is vector-based linear discriminant 
analysis 
better 
than 
matrix-based?," 
Pattern 
Recognition, vol. 41, no. 7, pp. 2156-2172, 2008. 
 
263
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

