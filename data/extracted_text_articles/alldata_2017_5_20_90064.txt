Statistical Analysis of Aircraft Trajectories: a Functional Data Analysis Approach
Florence Nicol
Universit´e F´ed´erale de Toulouse
Ecole Nationale de l’Aviation Civile
Toulouse, FRANCE
Email: florence.nicol@enac.fr
Abstract—In Functional Data Analysis, the underlying structure
of a raw observation is functional and data are assumed to
be sample paths from a single stochastic process. When data
considered are functional in nature thus inﬁnite-dimensional, like
curves or images, the multivariate statistical procedures have to
be generalized to the inﬁnite-dimensional case. By approximating
random functions by a ﬁnite number of random score vectors, the
Principal Component Analysis approach appears as a dimension
reduction technique and offers a visual tool to assess the dominant
modes of variation, pattern of interest, clusters in the data and
outlier detection. A functional statistics approach is applied to
univariate and multivariate aircraft trajectories.
Keywords–curve clustering; principal component analysis; func-
tional statistics; air trafﬁc management.
I.
INTRODUCTION
In many ﬁelds of applied research and engineering, it is
natural to work with data samples composed of curves. In
air transportation, aircraft trajectories are basically smooth
mappings from a bounded time interval to a state space.
The dimension of the state space may considerably increase
if Quick Access Recorders (QARs) provide a full bunch of
ﬂight parameters. Most of the time, aircraft trajectories are
observed on a ﬁne grid of time arguments that span the time
interval. The size and the dimension of the observed samples
are usually important, especially if the ﬂight data recorders are
used. Data collected in air transportation thus present some
characteristics of big data: complexity, variety and volume.
These characteristics are inherent to air trafﬁc and require
using speciﬁc statistical tools that take into account the diverse
and complex nature of data and efﬁcient numerical algorithms.
In Air Trafﬁc Management (ATM), analyzing aircraft tra-
jectories is an important challenge. A huge amount of data
is continuously recorded (ﬂight data recorder, maintenance
softwares, Radar tracks) and may be used for improving ﬂight,
as well as airport safety. For instance, trajectories coming
from ﬂight data recorders might help the airlines to identify,
measure and monitor the risk of accidents or to take preventive
maintenance actions. On airports, landing tracks observations
may indicate bad runway or taxiway conditions. Therefore, it
is of crucial importance to propose relevant statistical tools
for visualizing and clustering such kind of data, but also for
exploring variability in aircraft trajectories.
Aircraft trajectories, that are basically mappings deﬁned on
a time interval, exhibit high local variability both in amplitude
and in dynamics. Because of the huge amount of data, visu-
alizing and analyzing such a sample of entangled trajectories
may become difﬁcult. A way of exploring variability is then
to identify a small number of dominant modes of variation
by adapting a Principal Component Analysis (PCA) approach
to the functional framework. Some of these components can
help to visualizing how major trafﬁc ﬂows are organized. This
approach can also address the aircraft trajectories clustering
that is a central question in the design of procedures at take-
off and landing. Moreover, identifying atypical trajectories may
be of crucial importance in aviation safety. Resulting clusters
and outliers may be eventually described relatively to other
variables such as wind, temperature, route or aircraft type.
In this study, we will focus on Functional Principal Com-
ponent Analysis (FPCA) which is a useful tool, providing
common functional components explaining the structure of
individual trajectories. First, in Section II and III, the state of
the art and the general framework for functional data analysis
are presented. Next, in Section IV, the PCA approach is
generalized to the functional context. The registration problem
is then considered when phase variation due to time lags and
amplitude variation due to intensity differences are mixed.
Finally, in Section V, FPCA is applied to aircraft trajectories
that can be viewed as functional data.
II.
PREVIOUS RELATED WORKS
Most of the time, aircraft trajectories are observed on a
ﬁne grid if time arguments that span the time interval. Data are
ﬁrst sampled then processed using multivariate statistics. While
simple, this process will forget anything about the original
functional dependency. Most of studies conducted on air trafﬁc
statistics make use of the sampled data only as is proposed
in [1] and forget all about their functional nature, dropping
some extremely valuable information in the process. One of
the most salient shortcoming of the discrete samples methods
is they do not take into account with the correlation in the
data while functional data exhibit a high level of internal
structure and intrinsic characteristics (geometry of trajectories).
Moreover, as noted in [2], standard methods of multivariate
statistics have became inadequate, being plagued by the “curse
of dimensionality”. In a standard multivariate approach, a
PCA is performed on matrix data in which the number of
variables may be much more important than the number of
individuals. As a result, statistical methods developed for
multivariate analysis of random vectors are inoperative and
trying to crudely apply traditional statistical algorithms on this
kind of data may induce some severe numerical instabilities.
The quite recent ﬁeld of functional statistics [2] [3] pro-
vides a more adequate framework for dealing with such data
that are assumed to be drawn from a continuous stochastic
51
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-552-4
ALLDATA 2017 : The Third International Conference on Big Data, Small Data, Linked Data and Open Data (includes KESA 2017)

process taking its value in an Hilbert space. Data are no
longer point values but the complete trajectories, all statistical
procedure being performed on them. A major asset of working
with functional data instead of points is the ease of adding a
priori information by carefully selecting the Hilbert space. In
air transportation, few studies using the functional framework
have been carried out.
In [4], random forest for functional data are used for
minimizing the risk of accidents and identifying explanatory
factors in the context of aviation safety. This approach is not
suitable to visualizing how major trafﬁc ﬂows are organized.
In [5] [6], a new approach based on entropy minimization
and Lie group modeling is presented, in which the geometry
of trajectories are taken into account to cluster the trafﬁc in
groups of similar trajectories. Although this approach deals
with the aircraft trajectories clustering, the objective is quite
different. Indeed, this metod is intended to be a part of a
future automated trajectory planner. Given a sample of planned
trajectories, the classiﬁcation algorithm creates clusters such
that the mean line of each of them is similar to an airspace
route. Geometrical constraints have then to be considered.
In [7], a FPCA was performed on a sample of unidi-
mensional aircraft trajectories, especially trajectory altitudes.
This approach generalizes the standard multivariate principal
component analysis described in [1] to the functional context.
In the following, this approach is extended to the multivariate
FPCA (MFPCA), in which we want to study the simultaneous
modes of variation of more than one function. Particularly, the
simultaneous statistical analysis of the longitude and latitude
coordinates may give some insights on the nowadays trafﬁc
and then allow to forecast the expected one.
III.
DEALING WITH RANDOM FUNCTIONS
A. Problem statement
Functional Data analysis (FDA) deals with the study of
inﬁnite dimensional objects with a time or spatial structure
to be processed, such as curves or images. This point of
view differs from standard statistical approaches, the under-
lying structure of a raw observation being functional. Rather
than on a sequence of individual points or ﬁnite-dimensional
vectors as in a classical approach, we focus on problems
raised by the analysis of a sample of functions. Functional
data x1(t), . . . , xn(t) are the observations of a sample of
n independent and identically distributed random functions
X1(t), . . . , Xn(t) that are assumed to be drawn from a con-
tinuous stochastic process X={X(t), t ∈ J}, where J is a
compact interval. It makes sense to interpret functional data as
n realizations of the stochastic process X, often assumed with
values in a Hilbert space H, such as L2(J), the space of square
integrable functions deﬁned on the interval J. The associated
inner product for such functions is ⟨x, y⟩ =
R
x(t)y(t)dt and
the most common type of norm, called L2-norm, is related to
the above inner product through the relation ∥x∥2 = ⟨x, x⟩. In
a functional context, equivalence between norms fails and the
choice of semi-metrics is driven by the shape of the functions,
as noted in [2]. For instance, semi-metrics based on derivatives
suppose that the functions are not too rough.
Let X be a square integrable functional variable with values
in the separable Hilbert space H. As noted in [7], we can
deﬁne a few standard functional characteristics of the random
function X, such as the theoretical mean function and the
theoretical covariance function, for s, t ∈ J,
µ(t) = E [ X(t) ] ,
(1)
σ(s, t) = E [ X(s)X(t) ] − E [ X(s) ] E [ X(t) ] ,
(2)
that play a crucial role in FPCA as we will see in Section IV.
In the following, we will assume that X is centered, that is
µ = 0, otherwise, subsequent results refer to X − µ. From (1)
and (2), we can derive the equivalent empirical characteristics.
Note that no notion of probability density exists in the inﬁnite
dimensional Hilbert space as mentioned in [8].
B. Trajectories smoothing
Usually, in practice, functional data, such as position and
speed measurement, are observed discretely: we only observe
a set of function values on a set of arguments that are not nec-
essarily evenly space times or the same for all functions. Some
preprocessing of the discretized data has to be made in order
to recover the functional statistics setting, especially when
observations are noisy. Most procedures developed in FDA
are based on the use of interpolation or smoothing methods in
order to estimate the functional data from noisy observations
[3]. This problem can be solved by representing a trajectory as
a linear combination of known basis function expansions such
as a Fourier basis, wavelets or spline functions. Functional
data are estimated by their projections onto a linear functional
space spanned by K known basis functions ψ1, . . . , ψK such
as
exi(t) =
K
X
k=1
θikψk(t) = θT
i ψ(t),
(3)
where the unknown coefﬁcient vectors θi = (θi1, . . . , θiK)T
have to be estimated from the data and ψ(t) denotes the vector-
valued function (ψ1(t), . . . , ψK(t))T .
Let us consider a set of sampled trajectories {(yij, tij), i =
1, . . . , n, j = 1, . . . , Ni} where yij and tij are the respective
j-th sample position and time on the i-th trajectory. The
argument values tij may be the same for each recorded
trajectory or also vary from one trajectory to another one.
For simplicity, we will assume that the functional data are
observed on the same time grid t1, . . . , tN, usually equally
spaced. The expansion coefﬁcient vector (θi) is the solution
of the following least squares minimization problem
min
θi
X
j=1,...,N

yij − θT
i ψ(tj)
2 = ∥yi − Ψθi∥2 ,
(4)
where yi is the vector of the observed functional data and Ψ
is the N × K matrix containing the values ψk(tj).
Note that this representation in a truncated basis functions
takes into account the functional nature of the data and makes
it possible to discretize the inﬁnite dimensional problem by
replacing the functional data xi(t) by its coefﬁcient vector
θi, i = 1, . . . , n. While a probability density notion on
an inﬁnite dimensional Hilbert space cannot be deﬁned [8],
the expansion of the curves on a truncated Hilbert basis
allows to ﬁt a distribution on the coefﬁcient vectors. Usually,
multivariate statistical procedures are next performed on the
set of coefﬁcients such as clustering techniques.
The choice of the number K of basis functions depends on
the complexity of the curves. The larger is K in the expansion,
52
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-552-4
ALLDATA 2017 : The Third International Conference on Big Data, Small Data, Linked Data and Open Data (includes KESA 2017)

the better is the ﬁt but we then may capture undesirable noise.
If K is too small, we may increase smoothness and some
important characteristics of the functions may be vanished.
Fixing the dimension of the model is not easy and a major
drawback is due to the fact that the degree of smoothing is
driven by the discrete choice of the parameter K. We can get
better results by using roughly penalty approaches [3].
IV.
A PRINCIPAL COMPONENT APPROACH
Multivariate Principal Component Analysis is a powerful
exploratory statistical method which synthesizes the quantity
of data information by creating new descriptors in limited num-
ber [9] [10]. FPCA was one of the ﬁrst methods of multivariate
analysis that has been generalized to a functional setting. As
for the covariance matrix in the multivariate standard case, the
covariance function of functional variables are difﬁcult to inter-
pret and FPCA goals to analyze the variability of the functional
data around the mean function in an understandable manner.
By approximating inﬁnite-dimensional random functions by a
ﬁnite number of random score vectors, FPCA appears as a
dimension reduction technique just as in the multivariate case
and cuts down the complexity of the data. For this reason, this
approach is commonly used in FDA.
A. Generalization to the inﬁnite-dimensional case
Let X1, . . . , Xn be a sample of independent centered
random functions. One wants to ﬁnd weight functions γi
that preserve the major variation of the original sample. The
criterion is then the sample variance of the projections of the
random functions X1, . . . , Xn into the weight functions, called
principal component functions. These principal component
functions are the solution of the maximizing problem:
max
γi∈H
1
n
n
X
j=1
⟨Xj, γi⟩2,
(5)
under the constraint:
⟨γi, γk⟩ = δik, k ≤ i, i = 1, . . . , n.
(6)
At each step, each principal component function represents the
most important mode of variation in the random functions. The
orthogonality constraint then provides an orthogonal basis for
the linear subspace spanned by the random functions sample.
The solutions are obtained by solving the Fredholm func-
tional eigenequation that can be expressed by means of the
sample covariance operator bΓ induced by the sample covari-
ance function bσ:
bΓnv(t) =
Z
J
bσn(s, t)v(s)ds
(7)
= 1
n
n
X
j=1
⟨Xj, v⟩Xj(t),
v ∈ H.
(8)
such that
bΓγi(s) = λiγi(s),
s ∈ J.
(9)
The principal component functions γ1, . . . , γn are then the
eigenfunctions of bΓn, ordered by the corresponding eigenval-
ues bλ1 ≥ bλ2 ≥ · · · ≥ bλn ≥ 0. The projections Aij = ⟨γi, Xj⟩,
j = 1, . . . , n are random variables, called principal component
scores of Xj into the γi-direction [3]. These scores are cen-
tered, uncorrelated random variables accross j with variance
equal to λi.
Another important property for FPCA involves the best
L-term approximation property, meaning that the truncated
expansion PL
i=1 Aijγi is the best approximation of Xj with
a given number L of components in the sense of the mean
integrated error. Because each functional variable Xj admits
the empirical Karhunen-Lo`eve decomposition,
Xj(t) =
n
X
i=1
Aijγi(t),
j = 1 . . . , n,
(10)
the random scores Aij = ⟨γi, Xj⟩ can be interpreted as propor-
tionality factors that represent strengths of the representation
of each individual trajectory by the ith principal component
function. Furthermore, FPCA provides eigenfunction estimates
that can be interpreted as “modes of variation”. These modes
have a direct interpretation and are of interest in their own
right. They offer a visual tool to assess the main directions
in which functional data vary. As in the multivariate case,
pairwise scatterplots of one score against another may reveal
patterns of interest and clusters in the data. In addition, these
plots may also be used to detect outliers and explain individual
behavior relatively to modes of variation.
As in the multivariate PCA, we can easily measure the
quality of the representation by means of the eigenvalue esti-
mators. The ith eigenvalue estimator bλi measures the variation
of the scores into the bγi-direction. The percentage of total
variation τi explained by the ith principal component and
the cumulative ratio of variation τ C
L explained by the ﬁrst L
principal components are then computed from the following
ratio
τi =
bλi
Pn
i=1 bλi
,
τ C
L =
PL
k=1 bλk
Pn
i=1 bλi
.
(11)
The amount of explained variation will decline on each step
and we expect that a small number L of components will be
sufﬁcient to account for a large part of variation. Determining a
reasonable number L of components is often a crucial issue in
functional analysis. Indeed, choosing L = n components may
be inadequate and high values of L are associated with high
frequency components which represent the sampling noise. A
simple and fast method to choose the dimension L is the scree
plot that plots the cumulated proportion of variance explained
by the ﬁrst L components against the number of included
components L. Alternative procedures to estimate an optimal
dimension can be found in [11] and [12].
B. Estimation
Several estimation methods of scores and principal com-
ponent functions were developed for FPCA and asymptotic
results was studied in [13]. The earliest method applied to
discretized functional data to a ﬁne grid of time arguments
is based on numerical integration or quadrature rules [14]
[15]. Numerical quadrature schemes can be used to involve
a discrete approximation of the functional eigenequation (9)
ΣnWeγm = eλmeγm,
(12)
where Σn = (bσn(ti, tj))i,j=1,...,N is the sample covariance
matrix evaluated at the quadrature points and W is a diagonal
53
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-552-4
ALLDATA 2017 : The Third International Conference on Big Data, Small Data, Linked Data and Open Data (includes KESA 2017)

matrix with diagonal values being the quadrature weights. The
solutions eγm = (eγm(t1), . . . , eγm(tN)) are the eigenvectors
associated with the eigenvalues eλm of the matrix ΣnW. The
eigenvectors eγm form an orthonormal system relatively to the
metric deﬁned by the weight matrix W. When the weight
matrix W is not the identity matrix, an orthonormalization
correction is needed using Gramm-Schmidt procedure. We
can express the functional eigenequation in an equivalent
symmetric eigenvalue problem
W 1/2ΣnW 1/2um = eλmum
(13)
under the constraint:
uT
l um = δlm,
l, m = 1, . . . , N.
(14)
where um = W 1/2eγm. Note that, if the discretization values
tj are closely spaced, the choice of the interpolation method
should not have a great effect compared to sampling errors,
even if the observations are corrupted by noise [3].
A more sophisticated method is based on expansion of
functional data on known basis functions such as a Fourier
basis or spline functions as described in Section III. This
method takes into account the functional nature of the data and
makes it possible to discretize the problem by replacing the
functional data xi(t) by its coefﬁcient vector θi, i = 1, . . . , n.
The sample covariance function of the projected data
eσn(s, t) = 1
n
n
X
i=1
exi(s)exi(t) = ψ(s)T Θψ(t),
(15)
can be expressed by means of the K × K matrix Θ =
1
n
Pn
i=1 θiθT
i
which represents the covariance matrix of
the coefﬁcient vectors. Consider now the basis expansion
of the eigenfunctions eγm(s)
=
bT
mψ(s) where bm
=
(bm1, . . . , bmK)T is the unknown coefﬁcient vector to be
determined. This yields the discretized eigenequation
ΘWbm = eλmbm,
(16)
where W = (⟨ψi, ψj⟩)i,j=1,...,K is the matrix of the inner
products ⟨ψi, ψj⟩ =
R
ψi(t)ψj(t)dt of the basis functions.
The solutions bm are then the eigenvectors associated with
the eigenvalues eλm of the matrix ΘW. The orthonormality
constraints on the principal components functions satisfy
bT
l Wbm = δlm,
l, m = 1, . . . , K.
(17)
Note that this method looks like the discretization method
for which the coefﬁcient vectors θi = (θi1, . . . , θiK)T play
the role of the discretized functional data. FPCA is then
equivalent to a standard multivariate PCA applied to the matrix
of coefﬁcients with the metric deﬁned by the inner product
matrix W = (⟨ψi, ψj⟩)i,j=1,...,K.
C. The registration problem
The process of registration, well known in the ﬁeld of
functional data analysis [16] [17] [3], is an important pre-
liminary step before further statistical analysis. Indeed, a
serious drawback must be considered when functions are
shifted, owing to time lags or general differences in dynamics.
Phase variation due to time lags and amplitude variation due
to intensity differences are mixed and it may be hard to
identify what is due to each kind of variation. This problem
due to such mixed variations can hinder even the simplest
analysis of trajectories. Firstly, standard statistical tools such
as pointwise mean, variance and covariance functions, may
not be appropriate. For example, a sample mean function
may badly summarize sample functions in the sense that it
does not accurately capture typical characteristics. In addition,
a FPCA procedure applied to the unregistered curves will
produce too many principal components, some of them being
not of interest for the analysis of the variability of the curves.
In addition, phase variation may inﬂuence the shape of the
principal component functions that may not be representative
of the structure of the curves. Finally, the scores may present
a kind of correlation.
A registration method consists in aligning features of a
sample of functions by non decreasing monotone transforma-
tions of time arguments, often called warping functions. These
time transformations have to capture phase variation in the
original functions and transform the different individual time
scales into a common time interval for each function. Generally
speaking, a non decreasing smooth mapping hi : [a, b] →
[ci, di], with [ci, di] the original time domain of the trajectory,
is used to map each trajectory yi to a reference trajectory x,
usually called target or template function, already deﬁned on
[a, b]. In this way, remaining amplitude differences between
registered (aligned) trajectories yi ◦ hi can be analyzed by
standard statistical methods. The choice of a template function
is sometimes tricky and it may be simply selected among
the sample trajectories as a reference with which we want to
synchronize all other trajectories. Note that warping functions
hi have to be invertible so that for the same sequence of events,
time points on two different scales correspond to each other
uniquely. Moreover, we require that these functions are smooth
in the sense of being differentiable a certain number of times.
Most of literature deals with two kinds of registration
methods: landmark registration and goodness-of-ﬁt based reg-
istration methods. A classical procedure called marker or land-
mark registration aims to align curves by identifying locations
ti1, . . . , tiK of certain structural features, such as local minima,
maxima or inﬂexion points, which can be found in each curve
[18] [19] [17]. Curves are then aligned by transforming time
in such a way that marker events may occur at the same time
t01, . . . , t0K, giving hi(t0k) = tik, k = 1, . . . , K. Complete
warping functions hi are then obtained by smooth monotonic
interpolation. While this non-parametric method is able to
estimate possibly non-linear warping functions, marker events
may be missing in certain curves and feature location estimates
can be hard to identify. Finally, phase variation may remain
between too widely separated markers. An alternative method
is based on goodness-of-ﬁt by minimizing distance between
registered trajectories and a template trajectory, with possible
inclusion of a roughness penalty for hi [20] [21]. Note that
this latter registration method, as well as landmark registration
are implemented in softwares R and Matlab [22] and can be
downloaded through the website [23].
V.
APPLICATION TO AIRCRAFT TRAJECTORIES
A. The aircraft trajectory dataset
We now apply the previously described FPCA technique
to a 161 aircraft trajectory dataset. These data consist of
radar tracks from Paris Charles de Gaulle (CDG) to Toulouse
Blagnac airports recorded during two weeks. Most of the
54
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-552-4
ALLDATA 2017 : The Third International Conference on Big Data, Small Data, Linked Data and Open Data (includes KESA 2017)

aircrafts are Airbus A319 (20%), A320 (18%) and A321
(33%), followed by Boeing B733 (15%), B463 (8%) a member
of British Aerospace BAe 146 family and AT type (6%). Radar
measurements are observed in the range of 4-6960 seconds at
4 seconds intervals. The assumption that all trajectories are
40
60
80
100
120
−200
−150
−100
−50
0
50
100
Longitude−Latitude
X(t) (Nm)
Y(t) (Nm)
Figure 1. Trajectories from Paris CDG airport to Toulouse airport.
sample paths from a single stochastic process deﬁned on a time
interval is clearly not satisﬁed in the case of aircrafts: departure
times are different, even on the same origin-destination pair
and the time to destination is related to the aircraft type and the
wind experienced along the ﬂight. Without loss of generality,
we will assign a common starting time 0 to the ﬁrst radar
measurement of the ﬂights. Trajectories in Figure 1 exhibit
high local variability and may be studied by using a FPCA
approach. As observed raw data were passed through pre-
processing ﬁlters, we get radar measurements at a ﬁne grid
of time arguments with few noise. We have then used the
discretization method described in Section IV.
B. Multivariate FPCA
We now apply the FPCA procedure to multidimensional
trajectories. Each trajectory data fi(t) = (xi(t), yi(t)), i =
1, . . . , n, collected over time are effectively producing two
dimensional functions over the observed intervals [0, Ti]. Tra-
jectories have been registered by using the landmarks used in
[7] for the univariate altitude trajectories. Figure 2 displays the
ﬁrst four principal components for the latitude and longitude
trajectories after the overall mean has been removed from
each track. The ﬁrst component in X and Y -coordinates
0
1000
2000
3000
4000
−0.02
−0.01
0.00
0.01
0.02
0.03
Principal Components X(t)
time (sec)
PC1 
PC2 
PC3 
PC4 
0
1000
2000
3000
4000
−0.02
−0.01
0.00
0.01
0.02
Principal Components Y(t)
time (sec)
Figure 2. The ﬁrst four principal component functions for the latitude
trajectories X(t) and the longitude trajectories Y (t).
explain 58.7% of total variation whose 98% is due to the
longitude trajectories Y (t). We can visualize this effect on the
overall mean function in Figure 3 by adding and subtracting
a suitable multiple of the ﬁrst principal component for each
coordinate. This component quantiﬁes an overall decrease in
longitude that we can call overall effect (PC1) between the two
different routes from Paris (CDG) to Toulouse airports, more
and more important when one moves towards Toulouse airport.
Aircrafts with high negative scores would show especially
above-average tracks, mainly due to the Y -coordinate. As the
50
60
70
80
90
100
−200
−150
−100
−50
0
50
100
PC1  58.7 %
X(t) (en Nm)
Y(t) (en Nm)
50
60
70
80
90
100
−200
−150
−100
−50
0
50
100
PC2  14.7 %
X(t) (en Nm)
Y(t) (en Nm)
50
60
70
80
90
100
−200
−150
−100
−50
0
50
100
PC3  12.9 %
X(t) (en Nm)
Y(t) (en Nm)
50
60
70
80
90
100
−200
−150
−100
−50
0
50
100
PC4  6 %
X(t) (en Nm)
Y(t) (en Nm)
Figure 3. The effects on the mean aircraft trajectory (solid curve) of adding
(red curves) and substracting (blue curves) a multiple of each of the ﬁrst
four principal components.
second principal component is orthogonal to the ﬁrst one,
the corresponding mode of variation is less important and
accounts for 14.7% of total variation. The contributions of both
coordinates are of the same importance, with 48% and 52%
of total variation respectively explained by X(t) and Y (t). In
Figure 2, we can observe an overall effect due to the X(t)
trajectories increasing with time and a distortion in the timing
for the Y (t) trajectories. In Figure 3, we can visualize that the
closer we get to Toulouse airport, the more aircraft trajectories
are separated relatively to the X-coordinate. Moreover, the
separation between the arrivals at Toulouse airport are slightly
inﬂated relatively to the Y -coordinate. We call this effect the
landing effect (PC2). The third component accounts for 12.9%
and the main contribution comes from the X-coordinate with
86%. This component depicts an overall effect relatively to
the X-coordinate that separates the two routes, immediately
after the take-off from Paris CDG airport. We call this effect
the separation effect (PC3). Finally, the fourth principal com-
ponent accounting for 6% of the total variation, whose 66%
is explained by the X-coordinate, highlights an inversion of
route, probably due to a change of take-off procedures at Paris
CDG airport or landing procedures at Toulouse airport. We call
this effect the change effect (PC4).
A k-means clustering is next performed on the score matrix.
In Figure 4, we can visualize the mean cluster trajectories for
three and ﬁve clusters. The ﬁrst cluster (blue line) contains
all aircraft types except the AT type while the third one (red
line) is mainly composed of AT type. The mean trajectory
of the ﬁrst cluster displays the overall ﬂight paths from Paris
55
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-552-4
ALLDATA 2017 : The Third International Conference on Big Data, Small Data, Linked Data and Open Data (includes KESA 2017)

40
60
80
100
120
−200
−150
−100
−50
0
50
100
Three clusters
X(t) (Nm)
Y(t) (Nm)
Clusters
C1
C2
C3
40
60
80
100
120
−200
−150
−100
−50
0
50
100
Five clusters
X(t) (Nm)
Y(t) (Nm)
Clusters
C1
C2
C3
C4−5
Figure 4. Mean cluster trajectories and the overall mean (black curve).
CDG airport to Toulouse airport. The second cluster (green
line) displays a rerouting, probably due to a change in landing
procedures at Toulouse airport. This cluster can be interpreted
by means of the fourth principal component. The third cluster
shows that AT type aircrafts ﬂight along a very speciﬁc airway,
far from the ﬁrst two one, and may be explained by the third
principal component. When clustering is performed with ﬁve
clusters, the two last clusters are composed of atypical aircraft
trajectories and the ﬁrst three clusters are more representative.
TABLE I. CONTINGENCY TABLE OF THE COUNTS
Aircraft type
Cluster 1
Cluster 2
Cluster 3
A319
15
18
0
A320
14
14
1
A321
25
28
0
AT
2
0
8
B463
10
0
2
B733
22
1
2
TABLE II. CONTINGENCY TABLE OF THE COUNTS
Aircraft type
Cluster 1
Cluster 2
Cluster 3
Cluster 4-5
A319
9
16
0
8
A320
10
13
0
6
A321
18
13
0
6
AT
0
0
8
2
B463
10
0
2
0
B733
17
0
1
6
VI.
CONCLUSION AND FUTURE WORKS
FPCA is a powerful tool to analyze and visualize the main
directions in which trajectories vary. We have successfully
applied this technique to analyze aircraft trajectories and it can
be easily extended to the multivariate case. FPCA has many
advantages. By characterizing individual trajectories through
an empirical Karhunen-Lo`eve decomposition, FPCA can be
used as a dimension reduction technique. Moreover, rather than
studying inﬁnite-dimensional functional data, we can focus on
a ﬁnite-dimensional vector of random scores that can be used
into further statistical analysis such as cluster analysis.
The FPCA approach seems promising, as indicated by the
results obtained on a real data set. However, the registration
problem remains crucial because the assumption that all trajec-
tories are sample paths from a single stochastic process is not
satisﬁed and may be complex in the case of multidimensional
aircraft trajectories. In this work, we have used a landmark
registration technique. In future works, we will use more
sophisticated procedures such as arclength parametrization.
Moreover, we should add heading and velocity information
by combining functional data and vector of data, inducing an
extra level of complexity.
REFERENCES
[1]
A. Eckstein, “Data driven modeling for the simulation of converging
runway operations,” in Proceedings of the 4th International Conference
on Research in Air Transportation (ICRAT) June 1–4, 2010, Budapest,
Hungary, Jun. 2010, URL: http://www.icrat.org/.
[2]
F. Ferraty and P. Vieu, Nonparametric Functional Data Analysis: Theory
and Practice, ser. Springer Series in Statistics.
Springer, 2006.
[3]
J. O. Ramsay and B. Silverman, Functional Data Analysis, ser. Springer
Series in Statistics.
Springer, 2005.
[4]
B. Gregorutti, B. Michel, and P. Saint-Pierre, “Grouped variable impor-
tance with random forests and application to multiple functional data
analysis,” Computational Statistics and Data Analysis, vol. 90, 2015,
pp. 15 – 35.
[5]
S. Puechmorel and F. Nicol, “Entropy Minimizing Curves with Appli-
cation to Flight Path Design and Clustering,” Entropy, vol. 18, no. 9,
2016, pp. 337–352.
[6]
F. Nicol and S. Puechmorel, “Unsupervised curves clustering by
minimizing entropy: implementation and application to air trafﬁc,”
International Journal on Advances in Software, vol. 9, no. 3-4, 2016,
pp. 260–271.
[7]
F. Nicol, “Functional principal component analysis of aircraft trajec-
tories,” in 2nd International Conference on Interdisciplinary Science
for Innovative Air Trafﬁc Management (ISIATM) July 8–10, 2013,
Toulouse, France, Jul. 2013, http://isiatm.enac.fr/.
[8]
A. Delaigle and P. Hall, “Deﬁning probability density for a distribution
of random functions,” The Annals of Statistics, vol. 38, no. 2, 2010,
pp. 1171–1193.
[9]
K. Pearson, “On lines and planes of closest ﬁt to systems of points in
space,” Philosophical Magazine, vol. 2, no. 6, 1901, pp. 559–572.
[10]
H. Hotelling, “Analysis of a complex of statistical variables into
principal components,” J. Educ. Psych., vol. 24, 1933, pp. 498–520.
[11]
A. Kneip, “Nonparametric estimation of common regressors for similar
curve data,” Ann. Statist., no. 3, 09, pp. 1386–1427.
[12]
P. Besse, “Pca stability and choice of dimensionality,” Statistics and
Probability Letters, vol. 13, no. 5, 1992, pp. 405 – 410.
[13]
J. Dauxois, A. Pousse, and Y. Romain, “Asymptotic theory for the
principal component analysis of a vector random function: Some
applications to statistical inference,” Journal of Multivariate Analysis,
vol. 12, no. 1, 1982, pp. 136 – 154.
[14]
C. R. Rao, “Some statistical methods for comparison of growth curves,”
Biometrics, vol. 14, no. 1, 1958, pp. 1–17.
[15]
L. R. Tucker, “Determination of parameters of a functional relation by
factor analysis,” Psychometrika, vol. 23, no. 1, 1958, pp. 19–23.
[16]
H. Sakoe and S. Chiba, “Dynamic programming algorithm optimization
for spoken word recognition,” IEEE Transactions on Acoustics, Speech,
and Signal Processing, vol. 26, no. 1, Feb 1978, pp. 43–49.
[17]
T. Gasser and A. Kneip, “Searching for structure in curve sample,”
Journal of the American Statistical Association, vol. 90, no. 432, 1995,
pp. 1179–1188.
[18]
F. Bookstein, Morphometric Tools for Landmark Data: Geometry and
Biology, ser. Geometry and Biology.
Cambridge University Press,
1997.
[19]
A. Kneip and T. Gasser, “Statistical tools to analyze data representing a
sample of curves,” Ann. Statist., vol. 20, no. 3, 09 1992, pp. 1266–1305.
[20]
J. O. Ramsay and X. Li, “Curve registration,” Journal of the Royal
Statistical Society: Series B (Statistical Methodology), vol. 60, no. 2,
1998, pp. 351–363.
[21]
J. O. Ramsay, “Estimating smooth monotone functions,” Journal of the
Royal Statistical Society: Series B (Statistical Methodology), vol. 60,
no. 2, 1998, pp. 365–375.
[22]
J. O. Ramsay, G. Hooker, and S. Graves, Functional data analysis with
R and Matlab, ser. Springer Series in Statistics.
Springer, 2009.
[23]
“Functional Data Analysis,” URL: http://www.functionaldata.org/.
56
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-552-4
ALLDATA 2017 : The Third International Conference on Big Data, Small Data, Linked Data and Open Data (includes KESA 2017)

