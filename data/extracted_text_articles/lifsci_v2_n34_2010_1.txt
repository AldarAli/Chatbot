A Micro-Biomanipulation Training System based on Mixed-Reality 
 
Leonardo S. Mattos, Darwin G. Caldwell 
Advanced Robotics Department 
Italian Institute of Technology (IIT) 
Genoa, Italy 
{leonardo.demattos, darwin.caldwell}@iit.it 
 
 
Abstract— Within neuroscience, micromanipulation and 
microinjection of cells (blastocysts and neurons) are essential 
and highly skilled tasks that can require years of training. 
These tasks are traditionally performed via direct manual 
control of the biomanipulation equipment while looking 
through a microscope. Yet, even after extensive training, yield 
can be low (40 – 70%). This paper presents a mixed-reality 
system for the training of operators (biologists/neuroscientists) 
on a new fully teleoperated biomanipulation system with 
reduced training requirements and much higher yields. Two 
mixed-reality training scenarios were designed, implemented 
and tested for this purpose: A “move-and-inject” task focused 
on precise positioning training; and a trajectory following 
scenario intended to develop precise motion control skills in 
new operators. Preliminary experiments performed with 20 
totally novice operators demonstrate that this new training 
system is effective in terms of the initial development of control 
skills for real teleoperated biomanipulations. Experimental 
metrics demonstrate an exponential learning curve for these 
novice operators, who achieve good performance values after 
only two practice runs on the system. In addition, this training 
is shown to be safe and inexpensive since no real cells, 
biochemical products, or several pipettes are needed for this 
initial training phase. 
Keywords-mixed-reality; 
teleoperation; 
biomanipulation; 
micromanipulation 
I. 
INTRODUCTION 
Biomanipulation, in the context of this work, involves 
the transportation, orientation and injection of microscopic 
biological structures such as single cells and early embryos. 
These operations are normally performed under high-
magnification microscopes using glass pipettes with very 
fine tips (2-50µm), which are attached to micromanipulators 
and microinjectors.  Micromanipulators are mechanical or 
electro-mechanical devices that scale down the operator’s 
motions to enable precise control of tools in the micrometer 
range.  Microinjectors are devices used for precise control 
of fluid motion inside the pipettes.  
Modern biomanipulation devices are motorized and 
capable of high-resolution control. For example, commonly 
used Eppendorf equipment, such as the TransferMan NK2 
micromanipulator and the FemtoJet microinjector, offer 
motion resolution down to 40ηm and the capability of 
injecting volumes down to the femtolitre into cells. 
However, under direct operator control these high-resolution 
motion capabilities are difficult to achieve and do not easily 
translate into accurate control and successful manipulations. 
As a result of these operational difficulties the training 
period required to achieve proficiency in biomanipulations 
is normally high, reaching up to one year for operations 
such as embryo microinjection [2]. In addition, the training 
process is expensive, involving not only the costs of the 
underperforming operator, but also expenses associated with 
wasted materials, samples preparation, cell culture, etc. 
Furthermore, even after extensive training, the success rates 
of biomanipulations are found to be less than ideal (40 - 
70% for embryo microinjections [3]), pointing to problems 
related to the user interface and ergonomic factors of the 
microscope/micromanipulation setup [4]. Typical issues  
include: high susceptibility to human errors, such as 
unintentional erroneous motions; and the tiring working 
conditions, where operators spend hours looking through 
microscopes 
while 
simultaneously 
controlling 
micromanipulators and microinjectors. 
Improvements to the biomanipulation setup and to its 
control interface can be achieved using teleoperation 
techniques whereby the operator controls the system from a 
computer station, looking at the live video captured from the 
microscope and displayed on the computer screen. The 
control of the micromanipulators can be accomplished 
through the computer keyboard [5]; game joysticks [6]; or 
even through haptic devices [7][8].  
A teleoperated system has the potential to greatly 
improve biomanipulations by offering supervised control of 
the micromanipulator motions, which can filter hand 
tremors and even block erroneous motions [9][10]. In 
addition, a single teleoperated system can offer different 
control modalities for the micromanipulators, including 
position [11], velocity [6] and force control [12], which can 
be selected according to the specific biomanipulation task or 
user preference. Furthermore, the speed and precision of the 
micromanipulator can be dynamically adjusted in a 
teleoperated system, both automatically [13][14] or 
manually, further improving manual operations.  
Additional benefits of a teleoperated biomanipulation 
system include the automatic execution of motions that are 
virtually impossible under direct manual control of the 
micromanipulators. Examples are simultaneous motions in 
three dimensions, e.g. fast and precise motions such as 
“stabbing” movements used to penetrate some cells; and 
slow linear motions often desired for retracting the pipette 
from injected cells along the entry path. Another obvious 
73
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

benefit is the creation of a more ergonomic and intuitive 
work environment by careful arrangement of the display 
screen and the interfaces to enhance hand-eye collocation 
and co-ordination. This is less tiring, since the operator can 
sit comfortably in front of a computer display. In fact, this is 
a familiar environment to most people, including new 
operators that should learn biomanipulation tasks, making 
us hypothesize that teleoperation can enable faster learning 
at least in part due to this simple reason.  
Mixed-reality systems have been developed and used in 
teleoperations to achieve a diverse range of goals. For 
instance, they have been used to increase the safety of 
operations through the creation of virtual barriers in the 
operating field [10][15]; and also to assist in cell 
microinjection tasks by providing a preferred direction of 
motion [3]. Mixed reality has also been used in predictive 
displays, assisting the planning and execution of robot 
motions [16]; and in nanomanipulations to provide “haptic” 
sense in intangible tasks [17]. They have also been used in 
many training systems for tasks varying from aircraft 
piloting [18] to minimally invasive surgery [19]. 
The use of an assistive mixed-reality system can also 
improve the training and the yield of biomanipulations. For 
example, our teleoperated system [6] allows the definition 
of operating zones directly on the live video display, which 
are used to dynamically adjust the speed and precision of 
the micromanipulator during operation.  This is useful to 
prevent errors and contributes to increased operation yields 
because 
the 
micromanipulator 
precision 
can 
be 
automatically increased when the biomanipulation pipette is 
near a target cell or a danger area. 
This paper focuses on the training benefits of a mixed-
reality biomanipulation system. Our goal is to show that 
initial operator training can be done “off-line,” without the 
need for real cells, biochemical products, or the numerous 
pipettes that are needed when learning biomanipulations on 
the traditional manually controlled systems.  To this end, a 
fully teleoperated biomanipulation system [6] was used as 
the real setting for operator training, and target cells were 
replaced by virtual targets and virtual obstacles. Training 
was performed in two different mixed-reality scenarios: A 
move-and-inject task focused on training precise pipette 
positioning; and a trajectory following scenario, intended to 
train operators on precise control of the pipette motions.  
Evaluation of training metrics from 20 totally novice 
operators are presented here, showing that user learning 
improved exponentially and demonstrating the great value 
of this mixed-reality training system. 
II. 
BIOMANIPULATION TASKS 
Within the broad field of biomanipulation and 
particularly microinjection, which is the primary focus of 
this research, two tasks are of special interest due to their 
importance and frequency in neuroscience research: 
adherent cell microinjections and blastocyst microinjections. 
Adherent cell microinjection is a delicate and 
complicated operation that involves the manipulation of 
cells with dimensions down to 10µm. Figure 1(a) shows 
adherent cells commonly used in biological and medical 
 
Fig. 2. Synchronized motions on the X- and Z-axis are necessary to create a
linear microinjection action when the pipette is positioned on an angle.  
X
Z
θ
θ
cell
Petri dish
pipette
 
 
(a)   
(b) 
Fig.1. (a) Microinjection of CHO-K1 cells under bright-field imaging. (b) Microinjection of neurons using phase contrast imaging. Scale bars on the pictures
read 10µm. The diminutive size of these adherent cells require the use of high-magnification objectives, complicating precise pipette positioning over the
target cells due to the shallow focal depth of these lenses. 
74
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

research, the CHO-K1 cells [20]. Other examples are 
neurons, as in Fig.1(b), and endothelial cells. Since these 
cells adhere to the bottom of the Petri dish, only one 
pipette/micromanipulator is required to perform the 
microinjections. However, the pipette needs to be lifted 
when moving from one cell to another to avoid collisions 
with other cells and pipette tip breakage. Then, the pipette  
should be precisely positioned on the upper surface of the 
next target cell. This operation is complicated by the fact 
that the diminutive cells require the use of microscope 
objectives with high magnification factors (40 - 100x), 
which have a shallow focal depth. This means the pipette tip 
goes completely out of focus when lifted, making precise 
positioning difficult. In addition, the injection motion 
involves simultaneous and coordinated motion in two axes 
when 3-axis micromanipulators are used, e.g., injection at 
angle from the top involves simultaneous motions in X and 
Z (see Fig. 2). 
Blastocyst microinjections can be considered as a form 
of suspension cell microinjection, even though the 
blastocysts (early embryos) are composed of many cells. In 
this case, the (mouse) blastocyst moves freely on the bottom 
of the Petri dish, so injection normally requires the use of 
two moveable pipettes: one to hold the blastocyst; and the 
second to perform the actual injection. Figure 3 shows this 
operation, from which it can be seem that mice blastocysts, 
measuring around 100µm in diameter, are much larger than 
the adherent cells mentioned above. Nonetheless, blastocyst 
microinjections are equally delicate and difficult since even 
a small error can kill the embryo. One complication here 
comes from the fact that this task requires coordinated 
control of two micromanipulators; and another from the 
need 
to 
also 
control 
two 
microinjectors. 
These 
complications contribute to increasing the training time 
required to attain proficiency on this operation, which can 
typically take up to one year.  
As a result of the long training periods and susceptibility 
to small errors, our research aims at increasing the 
consistency and efficiency rates attained in manually 
controlled 
operations 
through 
assisted 
teleoperation. 
Consequently, we have developed a teleoperated system that 
allows 
easy 
and 
precise 
control 
of 
the 
entire 
biomanipulation setup from a user-friendly interface. 
Nonetheless, efficient operation of this new system also 
requires some training to attain optimum performance, 
which motivated the development of the mixed-reality 
training system described in this paper. The next sections 
present the system created, the training procedure, and 
initial training experiments performed with completely 
novice operators. 
III. 
BIOMANIPULATION SYSTEM CONFIGURATION 
The teleoperated biomanipulation system used in this 
research was created by the integration of high-end 
commercial equipment commonly found in neuroscience 
research laboratories.  This was done in favor of: 1) creating 
a flexible system applicable to a large range of 
biomanipulation 
applications; 
2) 
minimizing 
extra 
investment from the laboratories that already possess 
biomanipulation equipment; and 3) increasing the system’s 
acceptance by the biology/neuroscience community, which 
is already familiar with and trusts the equipment used. 
Equipment selection and configuration was performed in 
collaboration with neuroscience researchers.  Based on the 
mix of their research needs with engineering specifications 
for automation, the developed system included:  
• one Leica DMI6000B inverted microscope 
• two 
Eppendorf 
TransferMan 
NK2 
motorized 
micromanipulators 
• one Eppendorf Femtojet microinjector 
• one Marzhauser SCAN IM 120x100 motorized 
scanning microscope stage 
• two 
Eppendorf 
CellTram 
Vario 
microinjectors 
incorporating custom computer-controlled driving 
systems 
• a desktop computer with an Intel Core2 Quad 2.83 
GHz CPU, WindowsXP, and 3GB RAM 
• an AVT Guppy F-080C firewire camera 
• two Saitek Cyborg Evo Force joysticks 
These devices are shown in Fig. 4, which presents the 
two workstations that constitute the developed teleoperated 
biomanipulation system: The microscope station and the 
control station. 
                     
 
Fig. 3. Blastocyst microinjection and high-level algorithm describing this delicate operation. Coordinated and meticulous control of two micromanipulators 
and two microinjectors is required in this case, making this operation difficult to master and characterizing its results by low success rates. 
75
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

The selected devices are appropriate for many different 
biomanipulation procedures, including the microinjection of 
blastocysts and adherent cells.  These operations can be 
precisely performed using the selected micromanipulators 
(which have three translation axes with resolution of 40ηm 
and a maximum speed of 7.5 mm/s) and the FemtoJet 
microinjector, which can deliver volumes down to the 
femtolitre.    
IV. 
SYSTEM CONTROL AND TELEOPERATION 
Control and teleoperation of the devices were achieved 
through 
standard 
2-way 
communication 
interfaces, 
including RS-232C and CAN.  This was possible because 
all of the selected devices supported external control 
through a serial communications port.  Therefore, the type 
of connection between the controlling computer and a 
system device was dictated by the device’s supported 
interface.   
All system devices were integrated by software, and 
could be simultaneously controlled from a graphical user 
interface (GUI) running on the desktop computer (see Fig. 
5). User commands were received via the joysticks, 
computer mouse or computer keyboard. These commands 
were processed and then forwarded to the appropriate 
biomanipulation equipment.  
Feedback from the micro-world was obtained through the 
video camera, which provided live video feed from the 
microscope’s field of view. 
The virtual features used during this research were 
created using graphics overlaid on the live video stream. The 
interaction of these virtual features with real system 
components created the mixed-reality biomanipulation 
environment. These interactions were enabled by mapping 
the micromanipulator coordinates to the image space, as 
described in [21] and summarized below. Using this 
mapping the system was able to compute the image 
coordinates of the tool (pipette) without the need for image-
based localization software. This created a robust and fast 
system capable of generating an operating environment 
influenced by both real and virtual objects. Figure 5 shows 
some of the virtual features that could be created, including; 
   
 
 
(a)   
(b) 
Fig. 4. Teleoperated biomanipulation system configuration: (a) the microscope station; (b) the computer/control station.  
Fig. 5.The mixed-reality biomanipulation system setup and examples of virtual features defined on the operating environment. 
Commands
Commands
Feedback
Home region
Targets
Danger region
Obstacles
76
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Fig. 6: Method used to compute the rotation between the robot and the 
video coordinate frames. P0 and P1 were points with known coordinates 
on both frames. 
targets, obstacles and a danger region. All regions were 
customizable in terms of maximum speed allowed and 
repelling force. These virtual components were the basis of 
the two mixed-reality training scenarios described in section 
V.  
A. System Calibration 
The calibration procedure used to compute the mapping 
between the video and robot coordinate frames assumed 
zero image distortion by the system optics and perfect 
parallelism between the camera plane and the robot’s X-Y 
plane.  Considering these two simplifying assumptions, the 
calibration procedure consisted of finding the translation, 
rotation and scaling factors required to map points between 
the two frames.  This was realized by requesting the user to 
click on the tool tip seen on the live video at five different 
robot locations.  These operations defined {ܲ଴, ܲଵ, ܲଶ, ܲଷ, 
ܲସ}, five reference points described with coordinates ܲ௡
௏
 in 
the video frame and ܲ௡
ோ
 in the robot frame.  The first two 
points were initially used to compute the rotation, ߠ, 
between the coordinate frames according to the method 
described in Fig. 6; and later to compute the frame 
transformation described by: 
 
௏ܲ
ൌ ܵ • ܴ݋ݐ•
ோ
௏
൫ ܲ
ோ
െ
ோܲ଴
൯ ൅
௏ܲ଴
  
(1) 
 
where P is a point of interest; ܴ݋ݐ
ோ
௏
 is the rotation matrix 
from the robot to the video coordinate frame; and S is the 
scaling matrix.  These were defined as:  
 
ோܴ݋ݐ
௏
ൌ ቂcosߠ
െ sinߠ
sinߠ
cosߠ ቃ 
(2) 
 
ܵ ൌ ൤ܵ௑
0
0
ܵ௒൨ 
(3) 
 
The scaling factors SX and SY were measured in 
pixels/micrometers.  They were computed using Eq. 1 and 
the acquired points ܲ଴ and ܲଵ.  
After this initial mapping estimation, the entire set of 
reference points was used to improve the mapping 
parameters.  This was achieved by minimization of the error 
function defined by (4), which represents the RMS error 
between the real and the computed tool positions in robot 
coordinates. 
 
 ߳ ൌ ඨ∑
൜ቀ
ೃ௑෠೔
ି
ೃ௑೔
ቁ
మ
ାቀ
ೃ௒෠೔
ି
ೃ௒೔
ቁ
మ
ൠ
೙
೔సబ
௡
  
(4) 
 
In (4),  ൫ ܺ௜ ,
ோܻ௜
ோ
൯ represents the ith actual x-y robot 
position, ൫ ܺ෠௜
ோ
,
ோܻ෠௜
൯ represents the ith computed x-y robot 
position, and n is the number of calibration points used for 
the computations. 
V. 
TRAINING SCENARIOS 
The main goal of the developed training scenarios was 
familiarize new users with the teleoperated system 
environment, introducing them to the system control and 
joystick functions. Training using mixed-reality is a safe, 
fast and inexpensive way of developing the necessary 
control skills with new operators. Therefore, two tasks were 
developed to provide the basic training that could guarantee 
high levels of performance and safe operations even on the 
very first real biomanipulations. 
For evaluation purposes, both tasks always start at the 
same point, i.e., with the pipette tip inside a fixed virtual 
home region (see Fig. 5). In addition, the last task of a 
training session has the exact same configuration (in terms 
of target locations or trajectory to be followed) as the first 
test attempted, enabling a fair comparison between initial 
and final operator performances.  
A. Move-and-inject scenario 
This task was created to focus operator training on 
precise teleoperated positioning of the pipette tip. In this 
case, several virtual targets are randomly overlaid on the live 
video captured from the microscope’s field of view, as 
shown in Fig. 5. The task of the operator is to move the 
pipette’s tip to each of these targets. When the pipette is over 
a target, the operator should “inject” it by pressing the 
joystick’s trigger button. This action corresponds to an 
automatic injection motion when manipulating real cells, 
which is customizable in terms of distance, direction and 
speed, and is triggered by the same joystick button. When a 
target is successfully injected, it disappears from the screen. 
The operator’s goal is to eliminate all targets displayed. 
Completion of this goal finalizes the task. 
Different levels of difficulty can be set in this scenario by 
changing: 1) the number of targets; 2) the size of the targets; 
3) the number of obstacles; 4) the size of the obstacles; and 
5) the maximum time allowed to complete the task. Making 
the targets smaller increases task difficulty because it 
requires better precision in pipette positioning. The presence 
of obstacles also increases game difficulty because this 
means the user has to learn to control the pipette’s trajectory, 
not simply go straight to the targets.  
77
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Experimental data collected during this task includes the 
pipette tip position in image coordinates, recorded at 25Hz; 
the number of collisions with virtual obstacles; and the total 
duration of the task, i.e., the amount of time spent to “inject” 
all targets. Saving the pipette tip positions enables offline 
analysis of the user’s skills and strategies. Here, these data 
were used to measure the total distance travelled by the 
pipette during the test, which was then normalized by the 
absolute minimum travel distance computed using a version 
of the travelling salesman algorithm. This normalized 
distance was used as a performance metric. In addition, the 
average pipette speed during the experiment was also 
computed and used as a performance metric. 
B. Trajectory following scenario 
The goal of this task was to train new users on the 
dynamic control of the micromanipulation pipette motions, 
focusing on speed and direction control skills. Here, a 
desired trajectory was randomly defined, but always started 
in the centre of the home region and finished on a target 
located at the opposite side of the video panel. The 
operator’s task consisted of guiding the pipette tip from the 
 
 
 
(a) 
 (b) 
 
 
 
 
(c) 
 (d) 
Fig. 8. Examples of game data and metrics collected for the move-and-shoot game played by a novice operator: (a) Data from the first training session game;
(b) Data from the last training session game; (c) Average pipette speed on each game played; (d) Normalized distance travelled on each game played. 
0
200
400
600
800
1000
0
100
200
300
400
500
600
700
Experiment 1
pixels
pixels
 
 
Teleoperated Trajectory
Minimum Distance Path
Target Areas
0
200
400
600
800
1000
0
100
200
300
400
500
600
700
Experiment 10
pixels
pixels
 
 
Teleoperated Trajectory
Minimum Distance Path
Target Areas
Fig. 7. The trajectory following game scenario. 
78
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

home region to the final target following the given trajectory. 
A typical task is shown in Fig. 7. 
As in the previous scenario, the difficulty level could also 
be adjusted. This was achieved by changing the number of 
waypoints selected for the trajectory definition. Increasing 
the number of waypoints creates more twists and turns on the 
desired trajectory, requiring better motion and speed control 
to achieve  a good performance. The trajectory was defined 
using spline interpolation, i.e., as a smooth curve passing 
through all given waypoints. Randomness came from the fact 
that the y-coordinate of the waypoints were defined 
randomly (but not the x-coordinates – these were regularly 
spaced between the home region and the target). 
Evaluation of the operator performance was based on the 
root-mean-squared-error (RMSE) between the trajectory 
followed and the desired trajectory. This error was computed 
offline, based on the recorded pipette tip coordinates. The 
error from a sampled pipette coordinate to the desired 
trajectory was assumed to be the smallest distance between 
those two entities. This measure is represented by the green 
lines in Fig. 9, which displays experimental data from one of 
the novice operators.  
Another two measures obtained from this task were the 
total distance travelled by the pipette and the amount of time 
required to complete the given task. These were used to 
generate two metrics: the average pipette speed; and the 
normalized distance travelled, which was computed using 
the length of the desired trajectory as the normalizing factor. 
VI. 
TRAINING EXPERIMENTS 
The two mixed-reality training scenarios were used to 
train 20 totally novice operators on the control of the 
teleoperated biomanipulation system. All of these operators 
had no prior experience with biomanipulations or any other 
type of micromanipulation, and each of them went through 
only one training session in the teleoperated system. Here, a 
training session consisted of attempting only one of the 
scenarios 10 times. Therefore, the group of novice operators 
 
       
 
 
(a) 
(b) 
 
  
 
(c) 
(d)  
(e) 
Fig. 9. Examples of task data and metrics collected for the trajectory following scenario played by a novice operator: (a) Data from the first training 
session, with green lines showing the smallest distance from a sampled pipette coordinate to the desired trajectory; (b) Data from the last training session; 
(c) Average pipette speed on each task played; (d) Normalized distance travelled; (e) RMSE of the trajectory following task. 
0
200
400
600
800
1000
0
100
200
300
400
500
600
700
Experiment 1
pixels
pixels
 
 
Teleoperated Trajectory
Final Target Area
Desired Trajectory
0
200
400
600
800
1000
0
100
200
300
400
500
600
700
Experiment 10
pixels
pixels
 
 
Teleoperated Trajectory
Final Target Area
Desired Trajectory
79
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

was divided in two sets for the experiments: One half 
performed the move-and-shoot scenario and the other 
attempted the trajectory following scenario. 
The difficulty level of the tasks was kept constant during 
the training sessions, and was the same for all users. For the 
move-and-shoot task, the number of targets selected was 
four; the diameter of the targets was set to 90 pixels; no 
obstacle was present; and there was no time limit to finish 
the task. For the trajectory following case, the desired path 
was defined from four random waypoints plus the fixed 
initial point at the centre of the home region. Once again 
there was no time limit to finish the task. 
Examples of “move-and-inject” tests and of the data 
collected during a training session are shown in Fig. 8. Both 
the first and the last test completed by an operator are 
presented, from which a great performance improvement 
can be readily seen. The metrics obtained during this 
training session show an exponential learning curve, which 
was typical for operators that classified themselves as non 
video game players. On average, operators reached a 
performance level within 10% of their final performance by 
the third test. An interesting observation was the good 
performance of operators that classified themselves as 
gamers. In these cases, little improvement was noticed 
during the training sessions because these operators 
performed well from their very first trial.  
An example of a trajectory following training session is 
presented in Fig. 9. In this case a great performance 
improvement is also clearly seen when comparing data from 
the first and last games played by the operator. Additionally, 
the experimental metrics show, once again, an exponential 
learning curve, which was typical for the non-gamer 
operators. This learning trend allows us to conclude that the 
teleoperated biomanipulation system is user-friendly and 
easy to operate.  
The overall average of the trajectory following RMSE 
computed for all operators decreased from an initial 66.9 
pixels to a final 20.3 pixels, demonstrating an error 
reduction of almost 70% after only one training session. In 
addition, the overall change in normalized distance travelled 
between the first and the last scenario of the training 
sessions was -25.2% for the move-and-inject  task, and        
-21.5% for the trajectory following task, indicating good 
improvements in pipette motion control for both groups of 
operators. Another interesting observation from overall 
average data was the speedup measured for the move-and-
inject scenario. On average, the operators are 66.3% faster 
in precise pipette positioning after undergoing the move-
and-inject training session. A much smaller speedup was 
found for the trajectory following scenario, only 5.5%, 
which can be explained by the fact that operators learned to 
keep the speed low to better control the pipette trajectory. 
These data are summarized in Table I. 
VII. CONCLUSION AND FUTURE WORK 
A mixed-reality training system for teleoperated 
biomanipulations has been developed and tested during this 
research. The training platform consisted of a previously 
developed fully teleoperated biomanipulation system, which 
was augmented by a new mixed-reality interface developed 
for operator training. Here, the biomanipulation system 
provided the real setting for training, while virtual targets 
and virtual obstacles replaced the real cells to be 
manipulated.  Setup time for training in this system was 
short, only 3 to 5 minutes, and the pipette was practically 
impossible to break because it was positioned far away from 
any physical obstacle. 
Two mixed-reality training scenes were designed, 
implemented and tested during this research: One focused on 
precise positioning training using a “move-and-inject” task; 
and the other aimed to develop precise motion control skills 
in new operators, based on trajectory following tasks.  
Results from preliminary experiments with 20 totally novice 
operators demonstrated that this training system was 
effective in terms of initial development of the necessary 
control skills for real teleoperated biomanipulations. 
Training here was shown to be fast, safe, and inexpensive 
since no real cells, biochemical products, or pipettes were 
needed for this initial phase. 
The experiments demonstrated that learning on this new 
system was exponential, enabling operators to reach, on 
average, a performance level within 10% of their final 
performance by the third training run. In addition, all 
operators were able to achieve precise positioning at an 
average rate greater than 8.18 targets/min, and trajectory 
following with RMSE less than 27.9 pixels after only 10 
practice runs. Furthermore, operators that classified 
themselves as gamers demonstrated this level of performance 
from their very first trial. These observations not only 
reiterated that training on the developed mixed-reality 
system is fast, but also tells us that, as younger generations 
become more familiar with games, virtual realities, and the 
use of technologies, the value of a teleoperated system that 
feels like a computer game tends to increase. 
Future training sessions will evaluate the impact of 
progressively increasing the level of difficulty of the 
developed scenarios. The goal will be to maintain the 
operator’s initial learning rate for a longer period of time, 
hopefully taking their final control skills to a more advanced 
level without increasing the number of practice sessions. In 
addition, a group of operators will be trained on a mix of 
both scenarios, and later will be asked to perform real cell 
TABLE I.       OVERALL AVERAGE OF GAME METRIC CHANGES
A 
Metric 
Percentage Change 
Move-and-shoot 
game 
Trajectory following 
game 
Average Speed 
+66.3% 
+5.5% 
Normalized 
Distance Travelled 
-25.2% 
-21.5% 
Trajectory 
Following RMSE 
― 
-48.9% 
 
a. computed from data from the first and last games played by each operator. 
80
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

microinjections. This will be the final training system test, 
which will evaluate the hypothesis that teleoperated skills 
acquired in the mixed-reality trainer do transfer to real 
biomanipulations.  
REFERENCES 
[1] 
L. S. Mattos and D. G. Caldwell, “A Mixed Reality Training System 
for Teleoperated Biomanipulations,” Proceedings of International 
Conferences on Advances in Computer-Human Interactions, ACHI 
2010, February 2010. 
[2] 
D. Kim, S. Yun, B. Kim, “Mechanical force response of single living 
cells using a microrobotic system,” 2004 IEEE International 
Conference on Robotics and Automation, New Orleans, USA, April 
2004. 
[3] 
A. Kapoor, R. Kumar, R. H. Taylor, “Simple biomanipulation tasks 
with Steady Hand cooperative manipulator,” Medical Image 
Computing and Computer-Assisted Intervention - MICCAI 2003, 
Lecture Notes in Computer Science, vol. 2878, pp. 141-148, ISBN: 3-
540-20462-8, 2003. 
[4] 
N. Stylopoulos and D. Rattner, “Robotics and ergonomics,” Surgical 
Clinics of North America, vol. 83(6), pp. 1321-1337, 2003. 
[5] 
S. Ogawa, H. Takahashi, J. Mizuno, N. Kashiwazaki, M. Yamane, E. 
Narishige, “Personal computer-controlled microsurgery of fertilized 
eggs and early embryos,” Theriogenology, vol. 25(2), 1986. 
[6] 
L. 
Mattos 
and 
D.G. 
Caldwell, 
“Interface 
design 
for 
microbiomanipulation and teleoperation,” Second International 
Conference on Advances in Computer-Human Interactions, ACHI 
2009, Mexico, February 2009. 
[7] 
D. Kim, B. Kim, S. Yun, and S. Kwon, “Cellular force measurement 
for force reflected biomanipulation,” 2004 IEEE International 
Conference on Robotics and Automation, New Orleans, USA, April 
2004. 
[8] 
A. Pillarisetti, M. Pekarev, A. D. Brooks, J. P. Desai, “Evaluating the 
effect of force feedback in cell injection,” IEEE Transactions on 
Automation Science and Engineering, Vol. 4, No. 3, July 2007. 
[9] 
G. H. Ballantyne and F. Moll, “The da Vinci telerobotic surgical 
system: the virtual operative field and telepresence surgery,” Surgical 
Clinics of North America, vol. 83(6), pp. 1293–1304, 2003. 
[10] L. B. Rosenberg, “Virtual fixtures: Perceptual tools for telerobotic 
manipulation,” 
IEEE 
Virtual 
Reality 
Annual 
International 
Symposium, pp. 76–82, 1993. 
[11] O. Tonet, M. Marinelli, G. Megali, A. Sieber, P. Valdastri, A. 
Menciassi, P. Dario, “Control of a teleoperated nanomanipulator with 
time delay under direct vision feedback,” 2007 IEEE International 
Conference on Robotics and Automation, pp. 3514-3519, Rome, Italy, 
2007. 
[12] X.Y. Liu, K.Y. Kim, Y. Zhang, and Y. Sun, “NanoNewton force 
sensing and control in microrobotic cell manipulation,” International 
Journal of Robotics Research, vol. 28(8), pp. 1065-1076, 2009. 
[13] N. Turro, O. Khatib, E. Coste-Maniere, “Haptically Augmented 
Teleoperation,” 2001 IEEE International Conference on Robotics and 
Automation, pp. 386- 392, 2001. 
[14] N. Garcia-Hernandez and V. Parra-Vega, “Haptic Teleoperated 
Robotic System for an Effective Obstacle Avoidance,” Second 
International 
Conference 
on 
Advances 
in 
Computer-Human 
Interactions, ACHI 2009, Mexico, February 2009. 
[15] B.L. Davies, S. Harris, M. Jakopec, J. Cobb, “A novel hands-on robot 
for knee replacement surgery,” Computer Assisted Orthopaedic 
Surgery USA (CAOS USA), A. DiGioia and B. Jaramaz, Eds. 
Pittsburgh: UPMC Medical Center, pp. 70-74, 1999. 
[16] A.K. Bejczy, W.S. Kim, S. Venema, “The phantom robot: predictive 
displays for teleoperation with time delay,” 1990 International 
Conference on Robotics and Automation, 1990. 
[17] M. Ammi, A. Ferreira, J-G. Fontaine, “Virtualized reality interfaces 
for telemicromanipulation,” 2004 IEEE International Conference on 
Robotics and Automation, New Orleans, USA, April 2004. 
[18] Finnair Flight Training Center, www.finnairflighttraining.com 
[19] G. Lacey, D. Ryan, D. Cassidy, D.Young, “Mixed-reality simulation 
of minimally invasive surgeries,” IEEE MultiMedia, vol.14(4), p.76-
87, October 2007. 
[20] K. Jayapal, K. Wlaschin, M. Yap, W-S Hu, “Recombinant protein 
therapeutics from CHO cells - 20 years and counting,” Chemical 
Engineering Progress, vol. 103(7), October, 2007. 
[21] L. Mattos and D. G. Caldwell, “A fast and precise micropipette 
positioning system based on continuous camera-robot recalibration 
and visual servoing,” IEEE Conference on Automation Science and 
Engineering, CASE 2009, August 2009. 
 
81
International Journal on Advances in Life Sciences, vol 2 no 3 & 4, year 2010, http://www.iariajournals.org/life_sciences/
2010, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

