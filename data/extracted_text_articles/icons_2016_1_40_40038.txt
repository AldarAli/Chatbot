On the Riding Aids Recognition System for Horse Riding Simulators 
 
Sangseung Kang            Kyekyung Kim            Suyoung Chi 
Intelligent Cognitive Technology Research Department, 
Electronics and Telecommunications Research Institute 
Daejeon, Korea 
e-mail: {kss, kyekyung, chisy}@etri.re.kr 
 
 
 
Abstract—Riding aids are instruction signals from a rider to a 
horse in the horse riding. In this paper, we present a study on 
the riding aids recognition system for horse riding simulators 
using multimodal sensing data. The riding aids recognition 
system provides an effective interactive function based on the 
riding intentions. The system has three types of sensors 
including vision, voice, and touch sensors. It has adopted 
certain schemes for multimodal data acquisition, feature 
extraction, data fusion, template matching, and intention 
classification. The system can provide recognition means for a 
riding aid so as to provide sense of reality such as actual horse 
riding to the user. 
Keywords-riding aids; riding intention; horse riding; sports 
simulator. 
I. 
 INTRODUCTION 
The horse riding simulator is a machine that simulates the 
riding motion through an imitation of the basic movements 
of a real horse [1][2]. A current simulator is developed to 
move like an actual horse so that similar exercise effects to 
actual riding are provided to a user. The effects of exercise 
and recreational elements are also taken into account. 
However, it is not easy to provide continuous interest to 
users when operating a simulator. To solve this problem, it is 
necessary to develop hardware and software platform. Our 
approach infers the intention recognition using multimodal 
sensing data in a horse riding simulation environment.  
In this paper, we propose a riding aids recognition system 
with multimodal sensing in horse riding simulator 
environments. The proposed system consists of sensor data 
acquisition modules, a feature extraction and fusion module, 
and a class generation and template matching module for 
intention classification. It is possible to increase the sense of 
the real for the user by enabling the horse riding simulator 
user to perform similar interaction to actual horse riding, and 
to increase effects of horse riding training using the horse 
riding simulator. Particularly, it is possible to provide an 
effective method for recognition of the intention of the rider 
in the horse riding simulation environment. 
II. 
HORESE RIDING SIMULATOR 
We developed a horse riding simulation system for 
replicating the mechanistic movements of realistic riding 
motions [3]. The interaction control module performs a 
controlling function for the interaction between the rider and 
several different functional components. The simulation 
hardware control module drives the movements of the 
hardware apparatus including horse body and the peripheral 
devices, and detects the movement of the rider using 
mounted multi-modal sensor devices. The riding content 
display module presents the relative contents on a large 
interactive screen that enables the user to actually ride the 
device, and returns feedback notifications generated within 
the content environment. The logging and coaching database 
manages the user’s historical and specialized coaching 
information for personalized exercise mode and systematic 
training. 
This paper is organized as follows. Section 2 presents our 
developed system related to the horse riding simulator. 
Section 3 describes the structure of the proposed riding aids 
recognition in the simulation environment and functional 
components of that. Conclusions are given in Section 4. 
III. 
RIDING AIDS RECOGNITION 
A riding aid which is an instruction signal from a rider to 
a horse in the horse riding means enabling the horse to 
TABLE I.  
NATURAL RIDING AIDS 
Applying methods 
Reactions 
Seat collection, balance, steering, 
forward movement 
stop, go forward, turn 
Leg
applying equal pressure 
against the horse's sides 
increase in speed, upward 
transition 
one leg in a neutral position 
when applied
turn on the haunches or turn 
on the forehand, pirouette
one leg farther back, with the 
other leg in a neutral position 
actively encouraging the 
horse forward 
Hand
direct rein (one rein pulls 
straight back)
turn in the direction of 
pressure 
indirect rein or bearing rein 
(pulls back inward)
correct straightness, lateral 
movements 
opening rein (does not pull 
back, moves his hands away) 
turn in the air when 
jumping a fence
neck rein (laying the rein) 
turn a horse without bit 
contact 
Voice calming tone 
slow down 
upbeat voice
move forward 
14
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-451-0
ICONS 2016 : The Eleventh International Conference on Systems (includes EMBEDDED 2016)

recognize user intention [4][5]. Riding aids are the cues a 
rider gives to a horse to communicate what they want the 
animal to do [6][7]. Riding aids are broken into the natural 
aids and the artificial aids. The natural aids that the rider uses 
are the hand, leg, seat and voice aids, as shown in Table I. 
The artificial aids are used to backup natural aids using 
equipment such as a whip or spur, as shown in Table II. 
Our horse riding simulation system has three types of 
sensors. The touch sensors detect movements of the rider. 
The touch sensors are mounted on the artificial body of the 
simulator. They include six photo interrupter sensors for 
bridle rein and two film-type pressure sensors for detection 
of a spur. The voice sensor detects voice intentions of the 
rider. It is possible to provide a speech-based control 
function for the simulator. The voice sensor is mounted on a 
riding helmet using a condenser microphone. The vision 
sensors detect postural intentions of the rider using two depth 
sensing devices. The vision sensors are installed in positions 
such as the left and the reverse side. 
The data acquisition module uses multiple combinations 
of touch, voice, vision and other sensors to sense rider’s 
commands or movements. The key data of user’s movements 
are balanced sitting, drawing or pulling reins, spur, whip, and 
the like. The verbal commands are results of speech 
detection with minimum pulse length and endpoint detection. 
For the postural intentions, the module collects image and 
depth data for riding postures of the rider. Feature extraction 
and fusion module extracts each feature data from the 
relevant collected sensing information. It generates a feature 
data set through data fusion of the extracted feature 
information. The class generation module combines the 
extracted feature information from the feature data set, and 
generates a combination class depending on a predefined 
template type. The intention recognition module performed 
the recognition function based on the above generated class 
as the riding aids.  
The riding action of the user is predefined and converted 
into an object model. The action is stored in the database as 
the riding aids class. The class includes the following: 
 
- start - spurring (if stop state) 
- acceleration - continuously spurring 
- left turn - pulling a left portion of the bridle 
- right turn - pulling a right portion of the bridle 
- deceleration/stop - simultaneously pulling the bridle 
- stop - pulling back an upper portion (while pulling the bridle) 
- balancing - bending the upper portion forward (if walking) 
- propulsive force increase - leg pressure 
- exercise maintenance - leg release or bridle release 
 
The classes include strength information expressed 
through the action of the user as a parameter. The parameter 
includes gait level, driving velocity, pulling degree of the 
bridle, spurring strength, acoustic score, and rider’s joint 
degree. The template class matching function compares the 
generated combination class with the intention class stored in 
the intention database. Based on a result of the comparison, 
the system recognizes the intention of the action of the user. 
Using information on the recognized user action intention, 
the system sends the feedback, including changes for the gait 
level and driving velocity, and the simulation hardware 
control module controls the artificial body. We performed an 
experiment on the six classes such as start, acceleration, left 
turn, right turn, deceleration, and stop. In the initial 
experiment, the average recognition rate of ten subjects was 
around 90.5 percent overall. 
IV. 
CONCLUSION 
A substantial interactive process between human and 
horse riding simulator system must be provided for natural 
interaction. The process usually requires continuous riding 
aids recognition. In this paper, we present a riding aids 
recognition system using multimodal sensing data in horse 
riding simulator environments. The system can provide an 
effective interactive function based on the riding intention 
recognition. 
ACKNOWLEDGMENT 
This work was supported by Institute for Information & 
communications Technology Promotion (IITP) grant funded 
by the Korea government (MSIP) (10041627, Development 
of the 5-senses convergence sports simulator based on multi-
axis motion platform) 
REFERENCES 
[1] G. Chen, et al., “Biofeedback Control of Horseback Riding 
Simulator,” In Proceedings of the First International 
Conference on Machine Learning and Cybernetics, 2002, pp. 
1905-1908. 
[2] R. Eskola and H. Handroos, “Novel horseback riding 
simulator based on 6-DOF motion measurement, a motion 
base, and interactive control of gaits,” Advanced Robotics, 
Vol. 27, No. 16, 2013, pp. 1249-1257. 
[3] S. Kang, K. Kim, S. Chi, and J. Kim, “Interaction Control for 
Postural Correction on a Riding Simulation System,” In 
Proceedings of the 9th ACM / IEEE International Conference 
on Human-Robot Interaction, HRI 2014, 2014, pp. 195-196. 
[4] S. Qu, J. and Y. Chai, “Beyond Attention: The Role of Deictic 
Gesture 
in 
Intention 
Recognition 
in 
Multimodal 
Conversational Interfaces,” In Proceedings of the 13th 
international conference on Intelligent user interfaces, IUI'08, 
2008, pp. 237-246. 
[5] K. A. Tahboub, “Intelligent Human-Machine Interaction 
Based on Dynamic Bayesian Networks Probabilistic Intention 
Recognition,” Journal of Intelligent and Robotic Systems, Vol. 
45, No. 1, 2006, pp. 31-52. 
[6] Wikipedia, Riding aids, https://en.wikipedia.org/wiki/Riding 
_aids. [retrieved: October, 2015] 
[7] A. M. Swinker, New Hampshire 4-H Horse Project Member's 
Manual, University of New Hampshire, 2004. 
TABLE II.  
ARTIFICIAL RIDING AIDS 
Applying methods 
Reactions
Whip training tool, using light taps collect gaits or perform 
movements 
Spur brief, light touch, sharp jab 
encourage more impulsion, 
go forward  
 
15
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-451-0
ICONS 2016 : The Eleventh International Conference on Systems (includes EMBEDDED 2016)

