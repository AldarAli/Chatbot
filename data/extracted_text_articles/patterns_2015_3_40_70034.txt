Assessment of Fuzzy Gaussian Naive Bayes for Classiﬁcation Tasks
Jodavid A. Ferreira, Elaine A. M. G. Soares, Liliane S. Machado and Ronei M. Moraes
Laboratory of Statistics Applied to Image Processing and Geoprocessing
Federal University of Paraiba
Jo˜ao Pessoa, Brazil
Email: jodavid.arts@gmail.com, elaine.soares@ci.ufpb.br,
liliane@di.ufpb.br, ronei@de.ufpb.br
Abstract—Statistical methods have been used in order to classify
data from random samples. In general, if we know the statistical
distribution of data, we can use speciﬁc classiﬁers designed for
that distribution and expect good results. This work assesses the
accuracy of a Fuzzy Gaussian Naive Bayes (FGNB) classiﬁer
for tasks using data from ﬁve different statistical distributions:
Negative Binomial, Logistic, Log-Normal, Weibull and Gamma.
The FGNB classiﬁer was recently proposed as a fuzzy extension
of Gaussian Naive Bayes for training assessment in virtual
environments. Results of assessment are provided and show
different accuracy according to the statistical distribution of data.
Keywords–Fuzzy Gaussian Naive Bayes Classiﬁer, Classiﬁca-
tion, Accuracy Assessment.
I.
INTRODUCTION
Statistical methods have been widely used in order to
classify data from random samples [1]. In general, if we know
the statistical distribution of data, we can use speciﬁc classiﬁers
designed for that distribution and we can expected good results
from that use [2]. Classiﬁers based on Gaussian distribution
were exhaustively studied in the literature [3][4] and applied
in several kinds of problems [5][6][7]. Some of their variations
are known as Classical Bayes Rule [8] and Gaussian Naive
Bayes [9].
However, in several kind of applications, it is not possible
to afﬁrm the sample data were measured with accuracy. In
these cases, the imprecision on data should be incorporated
in the classiﬁcation method. Nowadays, a possible approach
for this modelling is using fuzzy sets proposed by Lofti A.
Zadeh [10]. Several classiﬁcation methods based on fuzzy
sets can be found in the literature and some of them are
based on probability measures of fuzzy events [11]. Among
them, the Fuzzy Gaussian Naive Bayes (FGNB) method was
proposed by Moraes and Machado [12] and has been applied
to classiﬁcation and training assessment problems [13][14][15]
achieving good results.
The main question about the classiﬁers based on Gaussian
distribution is related to some classiﬁcation problems in which
data did not follow Gaussian distribution. So, it is interesting to
know the limitations when those methods are used. This paper
aims to verify if the FGNB method has good performance
when classifying data given by the Logistic, Gamma, Weibull,
Log-Normal and Negative Binomial distributions. For each
statistical distribution were used data dimensions from 1 to
4.
The FGNB classiﬁer was proposed recently; then it is
necessary to know its accuracy. A preliminary performance
analysis from these authors using FGNB classiﬁer and other
statistical distributions was performed [15]. In this paper, we
enlarge the ¿ range of distributions used to verify the accuracy
of the method. The results of those comparisons are analysed
with respect to the better statistical distribution of data to
be used for better FGNB performance, according to each
dimension of data.
Section 2 presents the Fuzzy Gaussian Naive Bayes
(FGNB) classiﬁcation method which was used for data classiﬁ-
cation. In Section 3, the methodological part is described: the
data used and how the samples were generated. In Section
4, the classiﬁcation results for the 5 distributions statistics
are detailed. The conclusion of the study, highlighting the
distribution that was not well sorted, is in Section 5.
II.
FUZZY GAUSSIAN NAIVE BAYES (FGNB)
Formally, let the classes of performance in space of de-
cision be Ω = {1, ..., M} where M is the total number of
classes. Let X be a vector of training data, according to sample
data D, where X is a vector with n distinct features, i.e.,
X = {X1, X2, , Xn} and wi, i ∈ Ω is the class in space
of decision for the vector X. So, the probability of the class
wi, given the vector X, can be estimated using the Bayes
Theorem:
P(wi|X) = P(X|wi)P(wi)
P(X)
= [P(X1, X2, . . . , Xn|wi)P(wi)]
P(X)
(1)
Let us assume a naive hypothesis, in which each feature Xk
is conditionally independent of every other feature Xl , for all
k ̸= l ≤ n. This hypothesis, though sometimes it is not exactly
realistic, enables an easier calculation of (1). An advantage of
that assumption is the robustness acquired by classiﬁer that
now can classify data for which it was not trained for [16].
So, unless a scale factor S, which depends on X1, X2, . . . , Xn,
the equation (1) can be expressed by:
P(wi|X1, X2, . . . , Xn) = P(wi)
S
n
Y
k=1
P(Xk|wi)
(2)
A possible approach is to assume Gaussian distribution
for X and compute its parameters from D, i.e., mean vector
64
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-393-3
PATTERNS 2015 : The Seventh International Conferences on Pervasive Patterns and Applications

and covariance matrix [17]. From equation (2) it is possible
to use the logarithm function in order to simplify the ex-
ponential function in the Gaussian distribution formula and,
consequently, to reduce computational complexity replacing
multiplications by additions:
g(wi, X1, X2, . . . , Xn) = log[P(wi|X1, X2, . . . , Xn)] = (3)
= log P(wi)
S
+ Pn
k=1 log[P(Xk|wi)]
where g is the classiﬁcation function.
At this point, it is assumed that random variables
X1, X2, . . . , Xn are also fuzzy variables because we are going
to use their membership functions µwi(Xk) for this calculus
[18]. Then, based on probability of a fuzzy event [11], the
FGNB is done by [12]:
gf(wi, X1, X2, . . . , Xn) = log[P(wi|X1, X2, . . . , Xn)] =
(4)
log P(wi)
Sf
+ Pn
k=1 logµwi(Xk)P(Xk|wi)
where gf is the new classiﬁcation function and Sfis a new
scale factor.
The necessary parameters to compute P(Xk|wi) and
µwi(Xk) should be learned from sample data D. The better
estimation for class of the vector X can be obtained from the
highest values of the classiﬁcation function gf. However, as
Sf is a scale factor, it is not necessary to compute it for this
maximization process. Then:
X ∈ wilogP(wi) +
n
X
k=1
log[µwi(Xk)P(Xk|wi)] >
(5)
logP(wj) + Pn
k=1 log[µwj(Xk)P(Xk|wj)]
is the classiﬁcation rule for FGNB.
III.
ASSESSMENT METHODOLOGY
Several studies show that assessment methods present
better results when they are applied with data from a par-
ticular statistical distribution. In general, each method can
achieve better results when data follow some speciﬁc statistical
distributions [14]. In a previous work, Moraes [14] studied
the FGNB method for classiﬁcation tasks using six different
statistical distributions: Binomial, Continuous and Discrete
Uniform, Exponential, Gaussian and Poisson [15]. However,
since the FGNB is a recent method, its performance is not clear
with this other ﬁve statistical distributions: Negative Binomial,
Logistic, Log-Normal, Gamma and Weibull. In this paper,
we use the Monte Carlo simulation [19] to investigate the
behaviour of this method.
For our implementation, the samples were generated with
Monte Carlo simulation for 1, 2, 3, 4 and dimensions for
the ﬁve distributions in two different formats. One is used
for training the FGNB method and the other for testing the
method. Their settings obey the following rules:
a) Random training sample: used for the training of the
method, this sample has 40000 observations for all the 4
classes.
b) Random test sample: after the training, the method used
this to the assessment. This sample was composed by 30000
observations for each class, totaling 120000 observations.
The assessment method FGNB was implemented to all
the variety of dimensions and the respective classiﬁcation
matrices can be stored in order to assess the accuracy of this
methodology in practical applications. In particular, we had
used FGNB as a kernel of an online assessment method of
virtual reality simulators for training [12][13].
A. SIMULATION
To use the method, random samples were generated for
the 5 statistical distributions. The samples were generated
in software R [20] using the following parameters for each
distribution:
1) Negative Binomial: For the Binomial distribution de-
noted by X ∼ BN(p, k), 2 parameters are necessary for
samples generation. The parameters used were:
TABLE I. PARAMETERS OF THE NEGATIVE BINOMIAL
DISTRIBUTION.
NEGATIVE BINOMIAL
CLASS 1
CLASS 2
CLASS 3
CLASS 4
X ∼ BN(p, k)
DIMENSION 1
(0.4,10)
(0.4,30)
(0.2,30)
(0.4,130)
DIMENSION 2
(0.6,10)
(0.3,30)
(0.4,20)
(0.5,140)
DIMENSION 3
(0.4,30)
(0.4,10)
(0.4,130)
(0.3,47)
DIMENSION 4
(0.3,10)
(0.4,80)
(70,0.5)
(0.4,130)
2) Logistic: Samples were generated from the logistics
distribution, using the following parameters:
TABLE II. PARAMETERS OF THE LOGISTIC DISTRIBUTION.
LOGISTIC
CLASS 1
CLASS 2
CLASS 3
CLASS 4
X ∼ L(µ, σ)
DIMENSION 1
(0,2)
(20,2.5)
(43,2)
(60,3)
DIMENSION 2
(13,3)
(60,4)
(35,2)
(90,4)
DIMENSION 3
(20,3)
(40,2)
(108,4)
(72,4)
DIMENSION 4
(79,5)
(6,3)
(110,2)
(40,4)
3) Log-Normal: For the generation of Log-Normal distri-
bution samples, the following parameters were used:
TABLE III. PARAMETERS OF THE LOG-NORMAL DISTRIBUTION.
LOG-NORMAL
CLASS 1
CLASS 2
CLASS 3
CLASS 4
(µ, σ)
DIMENSION 1
(2,0.2)
(3,0.3)
(3.8,0.3)
(4.5,0.2)
DIMENSION 2
(2.8,0.2)
(2,0.3)
(4.7,0.2)
(3.7,0.3)
DIMENSION 3
(2,0.3)
(2.65,0.2)
(3.7,0.3)
(4.5,0.2)
DIMENSION 4
(4.2,0.2)
(3.5,0.1)
(2,0.4)
(3,0.3)
4) Gamma: The gamma distribution has the following
notation X ∼ Gamma(shape, scale) and the parameters used
for generation of the samples were:
65
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-393-3
PATTERNS 2015 : The Seventh International Conferences on Pervasive Patterns and Applications

TABLE IV. PARAMETERS OF THE GAMMA DISTRIBUTION.
GAMMA
CLASS 1
CLASS 2
CLASS 3
CLASS 4
(shape, scale)
DIMENSION 1
(20,0.25)
(40,0.25)
(60,0.25)
(90,0.25)
DIMENSION 2
(12,1.0)
(32,1.0)
(65,1.0)
(110,1.0)
DIMENSION 3
(50,0.33)
(80,0.33)
(120,0.33)
(170,0.33)
DIMENSION 4
(80,0.17)
(130,0.17)
(190,0.17)
(250,0.17)
5) Weibull: The Weibull distribution has two parameters
called shaped parameter and scale parameter. The parameters
used to generate the samples were:
TABLE V. PARAMETERS OF THE WEIBULL DISTRIBUTION.
WEIBULL
CLASS 1
CLASS 2
CLASS 3
CLASS 4
(shape, scale)
DIMENSION 1
(50,5)
(100,10)
(150,20)
(200,20)
DIMENSION 2
(50,5)
(100,10)
(150,20)
(200,20)
DIMENSION 3
(50,5)
(15,20)
(100,10)
(200,20)
DIMENSION 4
(200,20)
(50,5)
(150,20)
(100,10)
B. KAPPA COEFFICIENT
The Kappa Coefﬁcient K proposed by Cohen [21] is a
robust pondered measure which takes into account agreements
and disagreements between two sources of information from
a classiﬁcation matrix [22]:
K = (P0 − Pc)
(1 − Pc)
(6)
where: P0 =
PM
i=1 nii
N
and Pc =
PM
i=1 ni+n+i
N 2
, where nii is the
total of main diagonal in the classiﬁcation matrix; ni+ is the
total of line i in this matrix, n+i is the total of colum in the
same matrix, M is the total number of classes and N is the
total number of possible decisions presented in the matrix.
The variance of Kappa Coefﬁcient K, denoted by σ2
K , is
done by:
σ2
K = θ1 + θ2 + θ3.
(7)
where θ1 , θ2 , and θ3 are given by:
θ1 = P0(1 − P0)
N(1 − Pc)2
(8)
θ2 = 2(1 − P0) + 2P0Pc − θ4
N(1 − Pc)3
(9)
θ3 = (1 − P0)2θ5 − 4P 2
c
N(1 − Pc)4
(10)
and the parameters θ4 and θ5 are done by:
θ4 =
PM
i=1 nii(ni+ + n+i)
N 2
(11)
θ5 =
PM
i=1 nii(ni+ + n+i)2
N 3
(12)
An approximation to the ﬁrst component of 7 can be used
for calculations. However, in this paper, we used the complete
formula for variance and the Kappa Coefﬁcient was computed
for the best results. This coefﬁcient is widely used in the
literature of pattern classiﬁcation [2].
According to Landis and Koch, the Kappa coefﬁcient can
be interpreted as presented in Table VI [23]. By these interpre-
tation it is possible to distinguish where lies the classiﬁcation
data.
TABLE VI. CLASSIFICATION OF KAPPA COEFFICIENT.
Kappa Statistic
Strength of Agreement
<0.00
Poor
0.00-0.20
Slight
0.21-0.40
Fair
0.42-0.60
Moderate
0.61-0.80
Substantial
0.81-1.00
Almost Perfect
IV.
RESULTS
A. Negative Binomial Distribution
Figure 1. Random numbers generated for Negative Binomial distribution
four sets of training and test samples (lines) for four classes (columns).
The negative binomial distribution is a discrete distribution,
in which are considered some conditions: the experiment
consists on an undetermined amount of repeated attempts, the
probability of success is the same in each trial and the trials are
independent. Using the method FGNB on Negative Binomial
distribution with one dimension, was obtained a percentage
accuracy of 69.91% and Kappa coefﬁcient of 59.88% with a
variance of 9.29×10−6 . To dimension of size 2, the percentage
of correct answers was 93.94%, the Kappa cefﬁcient 91.92%
and variance 2.53 × 10−6. With the dimension equal to 3, the
percentage accuracy and Kappa coefﬁcient were greater than
66
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-393-3
PATTERNS 2015 : The Seventh International Conferences on Pervasive Patterns and Applications

99% and the variance obtained was 2.62 × 10−7. The best
results were obtained with the data dimension equal to 4: the
percentage of right classiﬁcations was 99.9%, the Kappa 99.8%
and the coefﬁcient variance 6.10×10−8. The histograms of the
samples for this distribution are available in Figure 1, where
the red and blue ones represent the training sample and the
test samples, respectively. In each histogram, we represent the
dimensions on the lines and the classes on the columns.
B. Logistic Distribution
Figure 2. Random numbers generated for Logistic distribution four sets of
training and test samples (lines) for four classes (columns).
The logistics distribution is a continuous distribution used
in studies of population growth and agricultural production.
It is also used in replacement of normal distribution due
to the shape similarity of them in some speciﬁc studies.
Figure 2 shows samples from logistics distribution used in
this study. For a dimension equal to 1, the method proved
to be more efﬁcient for the logistic distribution than to the
negative binomial distribution. The percentage accuracy was
84.41% and the Kappa coefﬁcient was 79.22% with a variance
of 1.94 × 10−6. With dimension 2, the percentage of right
classiﬁcations was 98.49%, with Kappa coefﬁcient 97.99% and
variance 2.19 × 10−7.
The percentage of right classiﬁcations reached 99.9% when
the point size was 3 under these conditions the Kappa co-
efﬁcient was 99.5% and the variance 1.64 × 10−8. For a
dimension equal to 4, the method for distribution logistics
FGNB achieved 99.9% of right classiﬁcations with a Kappa
coefﬁcient of 99.7% and variance 3.45 × 10−9.
C. Log-Normal Distribution
The Log-Normal distribution is continuous and can be
used to feature the lifetime of products and materials (semi-
Figure 3. Random numbers generated for Log-Normal distribution four sets
of training and test samples (lines) for four classes (columns).
conductors, diodes and electrical insulation, among others).
The histograms of random numbers generated for simulations
using Log-Normal distribution are presented in Figure 3.
In a simulation with only one dimensional data, the Kappa
coefﬁcient was 67.69% with variance 2.71 × 10−6 and 29074
misclassiﬁcations. With two dimensions was obtained Kappa
equal to 83.35% with 1.61 × 10−6 of variance. When using
3 dimensions, the results were 84.62% and 1.50 × 10−6
for Kappa and its variation. And with 4 dimensions, 13513
misclassiﬁcations occurred and the kappa was 84.98% with
1.47 × 10−6.
D. Gamma Distribution
The Gamma distribution is a continuous probability distri-
bution, which has two parameters, the ﬁrst one for shape and
the second one for scale, and it requires that both parameters
are greater than zero. The use of the FGNB method on the
samples of the Gamma distribution that are present in Figure
4 produced the following results: 1 dimension, the percentage
of right classiﬁcations was 72.33%, with a Kappa coefﬁcient
of 63.11% and variance of 2.92 × 10−06. For dimension
2, the percentage of right classiﬁcations was 87.96%, with
Kappa coefﬁcient 83.96% and variance 1.57 × 10−06. The
percentage accuracy, for 3 dimensions, was greater than 97%,
the Kappa coefﬁcient 97.06% and the variance 3.199×10−07.
With dimension equal to 4, the kappa coefﬁcient was 99.8%
with a variance of 1.89 × 10−08 and the percentage of right
classiﬁcations 99.87% with 153 misclassiﬁcations.
67
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-393-3
PATTERNS 2015 : The Seventh International Conferences on Pervasive Patterns and Applications

Figure 4. Random numbers generated for Gamma distribution four sets of
training and test samples (lines) for four classes (columns).
E. Weibull Distribution
Figure 5. Random numbers generated for Weibull distribution four sets of
training and test samples (lines) for four classes (columns).
The Weibull distribution is an important tool in the analysis
of reliability and durability of equipment, such as resistance
to fracture of the glass and ﬂaws in semiconductors and
capacitors. The histograms of random numbers generated for
simulations using Continuous Uniform distribution are pre-
sented in Figure 5. In a simulation with one dimensional data
and continuous uniform distribution, the best Kappa result
was 66.72% with variance of 2.67 × 10−6. The number of
misclassiﬁcations was 29952. When dimension of data was
increased for 2, the Kappa coefﬁcient resulted in 99.93% with
variance of 6.78 × 10−9, and 55 misclassiﬁcations. For three
dimensional data, the results were 99.48% and 5.74 × 10−8
for Kappa and its variance, respectively. For last, the Kappa
coefﬁciente pointed out 99.98% with variance of 1.48 × 10−9
for 4 dimensional data.
TABLE VII. SUMMARY OF BEST RESULTS, BY STATISTICAL
DISTRIBUTION, ACCORDING TO THE KAPPA COEFFICIENT
.
Statistical
Number of
Kappa
Distribution
Dimensions
Coefﬁcient
Negative Binomial
2 or more
> 90.0 %
Logistic
2 or more
> 95.0 %
Log-Normal
2 or more
> 80.0 %
Gamma
3 or more
> 95.0 %
Weibull
2 or more
> 99.9 %
Table VII presents a summary of the best results ob-
tained by each statistical distribution in the simulations. For
the Negative Binomial and Logistic distributions used in the
FGNB classiﬁer with three or more dimensions, was possible
to achieve more than 99% of correct classiﬁcation, according
to the Kappa Coefﬁcient. In a similar way, using the Gamma
distribution with four dimensions, the FGNB classiﬁer achieve
more than 99% of accuracy. However, for Log-Normal distri-
bution, the FGNB performance is reasonable, but its results
are better in higher dimensions of data. The classiﬁcation
of the Weibull distribution presented excellent results. From
the dimension two, the Kappa coefﬁcient obtained was above
99.9%.
V.
CONCLUSION AND FUTURE WORK
In this paper, we presented an assessment of FGNB accu-
racy for classiﬁcation tasks using data with different statistical
distributions. We made simulations with ﬁve different statis-
tical distributions: Negative Binomial, Logistic, Log-Normal,
Weibull and Gamma. For each statistical distribution were
analysed four different dimensions according to number of
misclassiﬁcations, Kappa Coefﬁcient and its variance. Accord-
ing to the results obtained, FGNB could be recommended
to classify data from all distributions studied in this paper.
For the distributions Negative Binomial, Logistic, Weibull and
Gamma, the Kappa coefﬁcient exceeded 90%. For the Log-
Normal distribution, with maximum possible dimensions, the
Kappa coefﬁcient reached approximately 85%.
As future work, we would like to analyse the performance
of this method with a database where each dimension can be
given by a different statistical distribution. For instance, in a
case of three dimensions, the ﬁrst one would be a sample of
Weibull distribution, the second one would be a sample of
Gamma distribution and the last one would be a sample of
Logistic distribution.
68
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-393-3
PATTERNS 2015 : The Seventh International Conferences on Pervasive Patterns and Applications

VI.
ACKNOWLEDGMENTS
This project is partially supported by grants 310561/2012-4
and 310470/2012-9 of the National Council for Scientiﬁc and
Technological Development (CNPq) and is related to the Na-
tional Institute of Science and Technology “Medicine Assisted
by Scientiﬁc Computing”(181813/2010-6) also supported by
CNPq.
REFERENCES
[1]
A. R. Webb and K. D. Copsey, Statistical Pattern Recognition., 3rd ed.
Chichester: Wiley, 2011.
[2]
R. O. Duda, P. E. Hart, and D. G.Stork, Pattern Classiﬁcation, 2nd ed.
Wiley Interscience, 2000.
[3]
P. Domingos and M. Pazzani, “On the optimality of the simple bayesian
classiﬁer under zero-one loss.” Machine Learning, no. 29, 1997, pp.
103–130.
[4]
G. John and P. Langley, “Estimating continuous distributionsin bayesian
classiﬁers.” in 11th Conference on Uncertainy in Artiﬁcial Intelligence,
Montreal, Canada, 1995, pp. 338–345.
[5]
J. Hilden, “Statistical diagnosis based on conditional independence does
not require it.” Computers in Biology and Medicine, 14, 429–435, 1984.
[6]
N. Friedman, D. Geiger, and M. Goldszmidt, “Bayesian network
classiﬁers,” Machine Learning, no. 29, 1997, pp. 131–163.
[7]
S. Monti and G. F. Cooper, “A bayesian network classiﬁer that combines
a ﬁnite mixture model and a naive bayes in model.” in 15th Conference
on Uncertainy in Artiﬁcial Intelligence,, Stockholm, Sweden, 1999.
[8]
C. M. Bishop, Pattern Recognition and Machine Learning., 1st ed.
Singapure: Springer, 2007.
[9]
R. M. Moraes and L. S. Machado, “Gaussian naive bayes for online
training assessment in virtual reality-based simulators.” Mathware &
Soft Computing, no. 16, 2009, pp. 123–132.
[10]
L. A. Zadeh, “Fuzzy sets,” Information Control, no. 8, 1965, pp. 338–
353.
[11]
L. A. Zadeh., “Probability measures of fuzzy events,” J. Math. Anal.
Applic., no. 10, 1968, pp. 421–427.
[12]
R. M. Moraes and L. S. Machado, “Fuzzy gaussian naive bayes applied
to online assessment in virtual reality simulators.”
World Scientiﬁc,
2010, pp. 243–248.
[13]
R. M. Moraes and L. S. Machado., “Online assessment in medical
simulators based on virtual reality using fuzzy gaussian naive bayes,”
Journal of Multiple-Valued Logic and Soft Computing, no. 18, 2012,
pp. 479–492.
[14]
R. M. Moraes, “Performance analysis of evolving fuzzy neural networks
for pattern recognition,” Mathware & Soft Computing, no. 20, 2013, pp.
63–69.
[15]
J. A. Ferreira, E. Soares, and R. M. Moraes, “Assessment of fuzzy
gaussian naive bayes classiﬁer using data with different statistical dis-
tributions,” in III Congresso Brasileiro de Sistemas Fuzzy (CBSF2014),
Joao Pessoa, Brazil, August 2014.
[16]
M. Ramonia and P. Sebastiani, “Robust bayes classiﬁers,” Artiﬁcial
Intelligence, vol. 125, January 2001, pp. 209–226.
[17]
R. A. Johnson and D. W. Wichern, Applied Multivariate Statistical
Analysis, 4th ed.
Prentice Hall, 1998.
[18]
G. J. Klir and B. Yuan, Fuzzy Sets and Fuzzy Logic: Theory and
Applications.
Prentice Hall, 1995.
[19]
J. Gentle, Elements of Computational Statistics.
Springer, 2005.
[20]
R Development Core Team. R: A language and environment for
statistical computing., R Foundation for Statistical Computing, 2009.
[21]
J. Cohen, “A coefﬁcient of agreement for nominal scales,” Educational
and Psychological, no. 20, 1960, pp. 37–46.
[22]
R. M. Moraes and L. S. Machado, “Psychomotor skills assessment in
medical training based on virtual reality using a weighted possibilistic
approach,” Knowledge-Based Systems, no. 70, 2014, pp. 97–102.
[23]
J. R. Landis and G. G. Koch, “The measurement of observer agreement
for categorical data.” Biometrics, vol. 33, no. 1, 1977, pp. 159–174.
69
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-393-3
PATTERNS 2015 : The Seventh International Conferences on Pervasive Patterns and Applications

