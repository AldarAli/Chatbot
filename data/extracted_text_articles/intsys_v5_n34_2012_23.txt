533
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Enabling User Involvement in Trust Decision Making
for Inter-Enterprise Collaborations
Puneet Kaur, Sini Ruohomaa, and Lea Kutvonen
Department of Computer Science
University of Helsinki
PO Box 68, FI-00014 University of Helsinki, Finland
puneet.kaur@cs.helsinki.ﬁ, sini.ruohomaa@cs.helsinki.ﬁ, lea.kutvonen@cs.helsinki.ﬁ
Abstract—Trust decisions on inter-enterprise collaborations
involve a trustor’s subjective evaluation of its willingness to
participate in a speciﬁc collaboration, given the risks and in-
centives involved. We have built support for automating routine
trust decisions based on a combination of risk, reputation
and incentive information. To handle non-routine decisions, we
must provide human users with a way to interface with this
system and gain access to supporting information. Current
collaboration management systems are missing the concepts,
processes and interfaces for enabling user involvement. In
this paper, we present two key contributions towards enabling
user involvement in trust decision making for inter-enterprise
collaborations: i) We have studied existing literature on human
trust decision making perspectives, and produced a set of
criteria for trust decisions. We analyze how three collaboration
management systems support these criteria. ii) We provide a
more detailed case study of enabling these features in our Pilar-
cos collaboration management system through implementing a
trust decision expert tool prototype, and report the results of
our user experiments on it.
Keywords-trust decisions; inter-enterprise collaborations; col-
laboration management middleware; user interfaces
I. INTRODUCTION
Networked business is moving from closed strategic net-
works into open business ecosystems where inter-enterprise
collaborations, i.e., business networks, are facilitated. In
an inter-enterprise collaboration, services from independent
organizations are brought together by interrelated business
processes to achieve a shared goal for end users as a
composed service. An online travel agency, for example, can
compose travel packages for its customers by utilizing a set
of services provided by its partners for payment handling,
booking ﬂights, hotel itinerary, car rental and other location-
speciﬁc arrangements, where each partial service is provided
by a separate autonomous enterprise [1].
We deﬁne a service as a network-accessible object with
a published interface. It can consist entirely of software,
or be a software interface to a physical system, such as a
logistics service that can be reserved online. Inter-enterprise
collaborations composed of these services involve multiple
interdependent parties, extending beyond isolated provider
and consumer interactions.
Inter-enterprise collaborations are particularly useful for
small and medium-sized enterprises, which hold expertise
in their own domain but have limited resources. By collab-
orating with other enterprises, they can attain a competitive
edge in ﬁelds outside their individual scope, and also join
forces to expand their business into ﬁelds dominated by large
enterprises [2], [3]. Large enterprises can apply the same
methods to organize their production life-cycles in-house, or
to experiment on new service concepts together with external
collaborators.
As the demand for easily set up collaborations between
interoperable services grows in both the number and the
scale of the collaborations themselves, ad hoc collaboration
establishment and decision-making solutions are no longer
cost effective.
The success of inter-enterprise collaborations relies on
dynamically evolving open service ecosystems, supported
by a ﬂexible infrastructure that reduces the cost of setting
up and managing the collaborations. This infrastructure
ensures that individual enterprises do not need to solve issues
of interoperability management, collaboration coordination,
breach recovery and trust management using costly manual
administration solutions.
The emergence of technology support, ranging from
service-oriented architecture and Web Services to cloud
infrastructures, are paving the way for semi-automated and
low-cost setup and management of inter-enterprise collabo-
rations. The Pilarcos open service ecosystem that we have
proposed in earlier work [3] provides infrastructure services
for ﬁnding potential partners and ensuring service interoper-
ability, collaboration management and semi-automated trust
decisions [2], for example; in this paper, we focus on the
trust management support speciﬁcally.
The service provider enterprises operating in open service
ecosystems are autonomous, and new service providers
can join the ecosystem to offer new types of services by
publishing service offers. The continuously evolving group
of service providers and their independence makes trust
management both important and challenging. Fine-grained
routine decision-making and the monitoring to support the
decisions should be automated to not form a bottleneck

534
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
in otherwise highly automated collaboration management,
but the organizational and individual users’ decision-making
process and the conceptual basis required by them are not
sufﬁciently supported by automation tools yet.
Automated trust decisions can only be relied on in rou-
tine cases: human intervention is required for making trust
decisions in situations where the risk or incentives are par-
ticularly high, or the information available for supporting the
decisions is insufﬁcient. Current collaboration management
systems are missing the concepts, processes and interfaces
for enabling user involvement.
In earlier work, we have set the basis for how to iden-
tify points where human intervention is needed through
metapolicy, including support for measuring the amount
and quality of the input information [2], [4]. We have also
analyzed different existing models for the trust building of
individual [5] and organizational users.
In this paper, we present two key contributions towards
enabling user involvement in trust decision making for
inter-enterprise collaborations: i) We have studied existing
literature on human trust decision making perspectives, and
produced a set of criteria for trust decisions. We analyze
how three collaboration management systems support these
criteria. ii) We provide a more detailed case study of
enabling these features in our Pilarcos collaboration manage-
ment system through implementing a prototype of an expert
tool for trust decisions, and report the results of our user
experiments on it.
The rest of the paper is organized as follows: Section II
provides an overview of the problem environment of making
trust decisions on inter-enterprise collaborations. Section III
presents our model of human decision-making criteria, based
on existing literature on human perspectives on trust, and
compares it to existing collaboration management systems
to analyze how well the concepts are supported there.
Section IV provides a detailed case study of enabling these
features in Pilarcos: we have implemented an expert tool
user interface prototype and present the results of user
evaluations. Section V concludes the paper.
II. TRUST IN INTER-ENTERPRISE COLLABORATIONS
Inter-enterprise collaboration depends on trust, as the au-
tonomy of partners causes uncertainty and risk, which must
be found acceptable for the collaboration to be established
and for it to proceed. In this section, we discuss the basis of
trust decisions on inter-enterprise collaborations and present
three example trust management systems, which we will
compare against our human trust decision-making criteria
in Section III.
A. Trust Decisions on Inter-Enterprise Collaborations
For our context of inter-enterprise collaborations, we
deﬁne trust as “the extent to which one party is willing to
participate in a given action with a given partner in a given
situation, considering the risks and incentives involved” [2].
Trust is crucial for the sustainability, existence and stabil-
ity of any inter-enterprise collaboration, particularly when
possibilities of direct interaction are limited [6], [7]. The
stronger the willingness to depend on and cooperate with
the other party is, the less need there is for explicit risk
reduction, monitoring and other protective structures. In this
sense, a strong trust relationship improves the performance
and overall efﬁciency of the established inter-enterprise
collaboration. On the other hand, the open service ecosystem
will inevitably have untrustworthy actors as well, and each
service provider must protect themselves against such risks.
The goal of trust management is to identify the appropriate
level of caution for different situations.
A trust decision compares the risks and incentives in-
volved in a given decision context; at the basic level, the
outcome is either positive (yes, collaborate) or negative (no,
withdraw). A reduction in perceived risk or increase in
incentives can be introduced to change the result through
application of additional protection mechanisms or contract
negotiations, for example.
Trust decisions are made during the establishment of
inter-enterprise collaborations, and routinely during their
operation, whenever new resources are committed. In the
establishment phase, explicit trust decisions are needed
because some of the actors in the ecosystem are previously
unknown or little known: we argue that not ﬁxing the set
of possible collaborators beforehand to a well-weathered
strategic network of enterprises provides competitive ad-
vantage [2]. The decision made in the establishment phase
does not have complete information available on how the
collaboration will span out. Instead, during the operation
of a collaboration, committing more resources or observing
signiﬁcant behavioural deviations trigger the need for new
trust decisions.
Trust decisions measure the subjective willingness of a
trustor to perform a given action with a given trustee. In
the context of our work, both the trustors and trustees are
business services; this level of abstraction reﬂects the fact
that two services even within the same enterprise may hold
different information, have a different effect on assets, and
be governed by different policies. When a trust decision is
delegated to a human user, therefore, the interventions are
made on behalf of a speciﬁc service, not the entire enterprise.
Some of the expected risks and gains can be estimated
based on the trustee’s past behaviour, represented by their
reputation. The balancing incentives are created by the
business importance of the activity itself, such as a need
to fulﬁll existing contracts, or a desire to try out a new way
of making business or a new set of partners.
A large body of existing work on reputation systems
has focused on electronic markets, aiming to support either
human or automated decisions speciﬁcally. Work in this
environment involves one-on-one transactions to purchase

535
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
goods or services, and often focuses on a relatively narrow
view of reputation information only [8].
A common approach focusing on the reputation man-
agement aspect in particular applies Bayesian modelling to
estimating the trustee’s likely future behaviour. In a nutshell,
this branch of research focuses effort on mathematically
credible calculation of the probability of different possible
outcomes for the next event based on past information. The
Beta reputation system [9] is a well-known example of this
group. As its name implies, the system ﬁts binary positive
or negative experiences into a beta distribution [9]. Other
work building on this approach proposes ways to extend this
approach either from binary to discrete scales [10], [11] or
to collecting binary data on more than one dimension, such
as prompt delivery and overall approval of the product [12].
Aspects such as how to weigh experiences reported by other
parties by their credibility are considered as well [11], [12].
From our point of view, research on Bayesian reputation
and trust management systems focuses on a mathematically
elegant transformation of reputation information into a risk
evaluation. In other words, Bayesian trust and reputation
systems seek to ﬁnd a good pair of reputation update and
trust decision policies, given a relatively simple baseline
information model. We ﬁnd that Bayesian policies can
operate within our information model [13, ch. 4.3], although
they only use a part of the provided input. Within this
subﬁeld, the search for well-performing policies has led to
a need to ﬁx the problem ﬁeld reasonably early, and the
information model assumptions warranted by this compa-
rability requirement may prove to be too rigid for more
general use [8]. On the other hand, for automation purposes
the line must always be drawn somewhere. While we have
chosen a tradeoff of increased information model complexity
in exchange for capturing more aspects of trust decisions that
we consider important, our model remains a simpliﬁcation
as well.
For a broader overview on related work on trust mod-
elling, we refer to surveys on reputation systems [14], [15]
and their robustness [8], [16]. Robustness in the face of
attacks and other misbehaviour is one of the key issues that
demand a holistic and high-complexity model of the opera-
tional environment to properly address. As trust management
falls under the category of protective systems, robustness is
an essential requirement; we discuss it more extensively in
earlier work [13].
We have found that inter-enterprise collaborations, which
involve multiple partners and a wide range of interdependent
services, require a broader information model in order to
capture the variety of risks and incentives as well as their
dependence on the decision context [2]. While additional
factors make the system more complex to understand,
they vastly improve its conﬁgurability through policy and
metapolicy [13].
In addition to Pilarcos, explicit risk information and
the separation of risk calculation policy from reputation
management has been proposed by the SECURE project [17]
for ubiquitous computing either between private users or in
client-to-business settings. As SECURE aimed to produce
a personal general-purpose trust decision assistant to carry
with the user, it also had to address the requirement for
a ﬂexible and conﬁgurable trust information model. For
Bayesian systems, on the other hand, the chosen approach
seems to reﬂect the target application area as well: in
eBay [18], a typical electronic market where goods are
bought and sold, a user’s most visible reputation has long
consisted of counters of the positive, neutral and negative
feedback they have received [19].
In a recent paper, Marsh et al. specify a set of require-
ments for trust models from a usability perspective [20]:
understandability by the actual users, support for monitor-
ing and user intervention, actively prompting for input in
uncertain situations, extensive conﬁgurability by the user
delegating the decisions to the system, catering for different
time frames for when the decision responses are needed,
accepting the incompleteness of available information, and
allowing the user to ﬁnd out more about the decision context.
This call for usability of trust models matches our goals well;
we ﬁnd that being able to understand and control the system
is a requirement for users to trust the system to handle their
trust decisions for them.
In terms of state of the art in information representation
for nontrivial trust models, Ries has proposed and conducted
user experiments on a two-dimensional graphical represen-
tation of positive outcome probability and the amount of
available information in his thesis [21]. Research shows
that the explicitly presented reputation information is not
the only element affecting a trust decision: users may be
inﬂuenced by unexpected user interface elements as well,
such as decorative images [22], [23].
B. Trust Support in Inter-Enterprise Collaboration Manage-
ment Systems
In preparation for comparison of the human and organi-
zational decision-making perspectives in various trust man-
agement systems, we brieﬂy introduce three inter-enterprise
collaboration management systems that have suitably similar
goals: i) TrustCoM, ii) ECOLEAD and iii) Pilarcos. The last
of these will be further detailed to provide insight for the
integration of the proposed interface.
TrustCoM is a large European Union project in the do-
main of inter-enterprise collaborations. The main contribu-
tion of TrustCoM has been the architectural and conceptual
framework addressing trust, security and contractual issues
from the perspective of inter-enterprise collaborations [24],
[25]. The TrustCoM framework [24], [26] supports trust
decisions during the joining and continuation of the col-
laboration. In TrustCoM, trust decisions are made when
a new partner needs to be added or a previous partner

536
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
needs to be replaced. The trust decisions are made based
on reputation information measuring trustee capabilities, in-
tegrity and benevolence, in addition to functional deﬁnitions
of the role, requirements of quality of service, cost and
security. The TrustCoM framework also involves an initial
user interface in the form of an eLearning portal in a scenario
demonstrator [26], helping users ﬁnd the service best suited
for them. In the general case, the design of trustworthy and
secure user interfaces falls outside the scope of TrustCoM,
although their importance is acknowledged.
ECOLEAD is also a European Union Integrated Project.
It
introduces
a
plug-and-play,
pay-per-use,
platform-
independent and secure ICT infrastructure for the initiation
and functioning of the inter-enterprise collaborations [6],
[27]. The project addresses interoperability, trust, security,
transparency, and affordability
[27]. In ECOLEAD [6],
[27], trust decisions are made at two points: base trust is
established during the entry into the ecosystem, and speciﬁc
trust is evaluated when each inter-enterprise collaboration is
set up. For base trust, all enterprises entering the ecosystem
answer a questionnaire on, e.g., organizational competences,
prior successful collaborations, prior engagement in op-
portunistic behaviour, and adherence to technology stan-
dards and delivery dates [28]. Collaboration-speciﬁc trust
is established in a hierarchical manner, starting from the
speciﬁcation of objectives in terms of measurable elements.
The ICT infrastructure of ECOLEAD also provides support
for portlets, pluggable user interface elements, for interaction
with the users [27]. The trust prototype has a web and mobile
portlet, providing a list of potential partners for collabora-
tion, where the users can select those found most suitable
for the task. Like TrustCoM, ECOLEAD does not focus on
user interfaces for trust decision making speciﬁcally.
The Pilarcos open service ecosystem we have proposed
in earlier work [3] aims to help service providers to ﬁnd
and collaborate with partners from the open service market.
Collaborations are deﬁned by a chosen business network
model, which deﬁnes roles consisting of speciﬁc service
types that the participanting services implement, and the
shared business processes. Due to some of the potential
partners being unknown or little known, trust management
requires explicit support.
Pilarcos includes infrastructure services for ﬁnding and
selecting potential partners and ensuring service interoper-
ability, eContracting and collaboration management, local
monitoring to collect evidence of trustworthiness, and semi-
automated trust decisions [2]. The distributed infrastructure
services in Pilarcos allow the enterprises to make local,
private trust decisions on whether they want to join or
continue in an inter-enterprise collaboration. Other decision
policies are also needed to ensure that the automation tools
act in accordance to the strategy and privacy requirements
of the enterprise, for example [2].
While TrustCoM makes trust decisions when partners are
added or changed in an operating collaboration, Pilarcos
trust decisions are made both at the start of a collaboration
and when new resources are committed, in which case the
decision may trigger partner changes as well. The trust
decisions in Pilarcos compare the subjective risks, calculated
on the basis of the past behaviour of the trustee as encoded in
its computational reputation, and incentives involved in the
endeavour, such as the business importance of the collabo-
ration [29]. The incentives are reﬂected on how much risk is
tolerated. Routine decisions are automated, following local
policies [2]; however, there are always situations that require
human intervention. To allow for this, the decision policies
deﬁne risk tolerance ranges for automatic acceptance, au-
tomatic rejection, and for requesting input from the human
user [1]. Possible reasons for requiring human intervention
include high risks combined with high incentives, or too
little reputation information available on the trustee.
III. DECISION-MAKING PERSPECTIVES
Designing a trust decision expert tool meant for humans
requires understanding the process of human trust decision
making in general. The reviewed research on human needs
for decision-making has been conducted both in the context
of electronic commerce and more general settings. The
domain of inter-enterprise collaborations speciﬁcally has
remained relatively unresearched, while the focus has been
on business-to-consumer (B2C) settings. Considering the
underlying problem, we believe that ﬁndings regarding hu-
man trust decision making in the B2C electronic commerce
domain, for example, can be applied in the case of inter-
enterprise collaborations with adaptations.
In this section, we present our model of human decision-
making criteria, which is based on existing literature on hu-
man perspectives on trust. We then compare the three inter-
enterprise collaboration management systems presented in
the previous section in order to study how well the concepts
we have extracted are supported in them.
We have studied the research literature from two perspec-
tives: First, approaches to human trust development, and
second, qualitative and quantitative criteria for trust decision
making.
A. Human Preferences on Trust Decision Making
1) Approaches to Human Trust Development: The exist-
ing literature reveals two different approaches to modelling
human trust development: cyclic and staged [30]. Table I
summarizes the reviewed approaches.
The cyclic approach to trust development was introduced
by Fung et al. [31]. It relies on the development of the
trustor’s conﬁdence based on the satisfaction of prior be-
havioural outcome expectations. However, continuous dis-
trust at any phase has a negative effect on the existing
trust levels. Fung et al. [31] and Deelman et al. [32] have
proposed two different models for cyclic trust development.

537
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Table I A SUMMARY OF THE REVIEWED APPROACHES TO HUMAN TRUST DEVELOPMENT.
Author
Approach
Summary
Fung et al.
Cyclic
•
Factors affecting initial trust establishment: information quality, interface design and
reputation
•
Future trust is based on the satisfaction of prior expectations
Deelman et al.
Cyclic
•
Factors affecting initial trust establishment: willingness to trust, estimation of trust-
worthiness of trustee, evaluation of past experiences, situation and risk inherent in
current situation
•
Future trust is based on the satisfaction of prior expectations
Shapiro et al.
Three-stage
•
Deterrence-based trust: relies on measures preventing occurrence of misbehaviour
•
Knowledge-based trust: relies on a knowledge gained as a result of direct interaction
with trustee, and satisfaction of prior expectations
•
Identiﬁcation-based trust: highest trust level, relies on the outcomes or experiences
gained as a result of repeated interactions with trustee
Ba
Three-stage
•
Calculus trust: relies on comparison of gains versus possible losses
•
Information-based trust: relies on information gained as a result of direct interaction
with trustee and satisfaction of prior expectations
•
Transference-based trust: highest trust level, relies on the outcomes or experiences
gained as a result of repeated interactions with trustee
Kim et al.
Two-stage
•
Initial stage: marked by either no or low trust
•
Commitment stage: high-trust stage, where the trust relies on prior direct interactions
with trustee
McKnight et al.
Two-stage
•
Exploratory stage: marked by either no or low trust
•
Commitment stage: high-trust stage, where the trust relies on prior direct interactions
with trustee
Fung et al. [31] present the basic model where informa-
tion quality, interface design and reputation are the factors
contributing to the initial trust development. Building on
this, Deelman et al. [32] have further elaborated the original
model by proposing additional factors: willingness to trust,
estimation of the trustworthiness of the trustee, evaluation
of past experiences, situation, and risk inherent in the
current situation. The most notable point about the model
of Deelman et al. is that it is applied to trust development
in the domain of inter-enterprise e-commerce.
When we consider inter-enterprise collaborations in par-
ticular, the needs of trust modelling are slightly different. As
regards to domain-speciﬁc needs, we would like to enhance
the cyclic models proposed by Deelman et al. [32] and Fung
et al. [31] in the following three ways: First, shared vision,
contracts and legal conditions also play a signiﬁcant role,
especially during the initial stages of trust development;
they should therefore also be considered as factors affecting
trust development. Second, distrust development should be
covered by the models as well, as services may change their
behaviour and trust relationships may degrade or be broken
off as a result. Third, while Deelman et al.’s model suggests
that the given factors should be followed in sequential order,
we ﬁnd that the factors collectively affect trust development
and their order completely depends on human preference.
Staged trust development models exist in different forms,
with a different number of stages proposed for trust de-
velopment. Shapiro et al. [33] and Ba [34] have both
proposed a three-stage trust development model. The stages
proposed by Shapiro et al. are deterrence-based, knowledge-
based and identiﬁcation-based trust. Ba instead proposes
that the stages are calculus-based, information-based and
transference-based. Kim et al. [35] and McKnight et al. [36]
have suggested two-stage trust development models, which
both call the ﬁnal stage of trust development the commitment
stage. Kim et al. refer to the ﬁrst stage as initial trust
development, while McKnight et al. call it the exploratory
stage.
The staged trust development models cover different an-
gles, but problems remain for applying them to the domain
of inter-enterprise collaborations. The three-stage models
do not consider the effect of opportunistic behaviour, such
as degrading quality of service or contract violations due
to changes in the priorities of an enterprise. Similarly,
McKnight et al.’s model does not discuss the possibility
of degrading or withdrawing from the existing trust rela-
tionship. As the ﬁnancial situation and motivation of an
enterprise can change at any time, its behaviour can notably
change as well, and we believe that the trust development
models should be able to capture this.
The three-stage trust development models are also limited
in the sense of assuming that trust development proceeds
in a sequential order. We noted a similar issue with the
sequential order in Deelman et al.’s cyclic model; in this
case we ﬁnd that two stages of trust development could
well be in use simultaneously. For example, Shapiro et
al.’s knowledge-based and Ba’s information-based trust are
ﬁxed as the second stage, which occurs after a series of
direct interactions. We ﬁnd that information from third-party
reputation networks can be used also during the ﬁrst stage,

538
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
before ﬁrst-hand interactions have taken place. Apart from
this, the model of Kim et al. does not propose a precise list
of factors affecting trust development in the initial stage, and
do not discuss the shift from initial to committed stage.
2) Criteria for Trust Decision Making: The second tar-
get of our literature research involves identifying different
factors that affect trust decision making. The term ’criteria’
refers to the various qualitative and quantitative factors that
play a signiﬁcant role in the process of human trust decision
making [37], [38], [30]. Criteria for trust decision mak-
ing in business-to-consumer (B2C) e-commerce can relate
to institutional, environmental, website, trustor and trustee
metrics, for example. The different criteria are applied in
trust decision making to help analyze the situation that has
called for a decision. They should be considered because
they are necessary to complete the human trust decision
making process.
The following section presents the different criteria we
have selected for trust decision making in the domain of
inter-enterprise collaborations within four categories: trustor,
trustee, contextual and collaboration-speciﬁc criteria. The
criteria have been gathered based on the process of human
trust decision making, extended to suit the needs of inter-
enterprise collaborations in particular.
Trustor Criteria: The trustor criteria are attributes of
the trusting entity that affect the process of trust decision
making. The personality and thinking of the trustor have a
major inﬂuence on the ﬁnal decision. The trustor criteria are
propensity to trust, emotions and culture.
Propensity to trust is deﬁned as a human behavioural
trait, reﬂecting their inherent willingness or attitude towards
trusting humanity, independent of any information regarding
the entity to be trusted [35]. It makes the trustor risk-seeking,
risk-averse or risk-neutral. The establishment of propensity
to trust is based on prior experiences, starting from infancy.
It can also be viewed as dispositional in nature, as human
beings are taking their propensity to trust from one situation
to another [38]. Propensity to trust plays a signiﬁcant role
during the initial stages of trust establishment in the case of
previously unknown or little known entities [39].
Emotions can be deﬁned as a cognitive approach to trust
decision making [40], [41]. They are also independent of
any kind of information regarding the target entity. Emotions
bring in “temporal irrationality” in the process of trust
decision making [41]. They might instigate a positive trust
decision if the person is in a happy mood even in a
situation that does not warrant trust at all otherwise, for
example. Emotions acquire a dominant role in trust decision
making by formulating a viewpoint regarding the available
information and the current situation requiring the trust
decision.
Culture is another personality trait of the trustor. It im-
pacts the trustor’s attitude, which plays a signiﬁcant role in
perceiving available information [41]. This way it also has
an inﬂuence on the other two trustor criteria. For example, a
small or medium-sized enterprise may be less willing to take
a certain measure of risk as compared to large enterprises,
owing to limited resources affecting their general tendency
to trust. Shoorman et al. [41] state that the relationship
versus task dimension of culture plays a major role in
the process of trust decision making. This means that a
task-oriented culture will be more risk-seeking, while a
relationship-oriented culture invests particularly in building
and maintaining long-lasting trust relationships.
We believe that all the aforementioned trustor criteria are
a good ﬁt with the domain of inter-enterprise collaborations.
Their role becomes evident when we consider human trust
decision making. However, they are also reﬂected in the
automated trust decision making through the use of private,
local or mutually decided and negotiated policies, contracts,
rules and regulations. The mutual decision and negotiation
is being carried out through either machine agents that are
administered and conﬁgured by human users, or through the
human users themselves.
Trustee Criteria: The trustee is the entity targeted by trust.
As trust balances for risks that are inherent and not easily
eliminated from the decision-making situation, the attributes
of the trustee have a major role in the process of trust
decision making as well. We consider trustee reputation to
be the key trustee criterion.
Reputation information refers to the knowledge about the
past and present behaviour of the trustee [6], [2], [37]. When
coupled with an assumption of behavioural consistency, this
historical information is used for making predictions about
the trustee’s future behaviour, and assessing the overall
trustworthiness of the trustee. According to Mayer et al. [38],
trustworthiness can be perceived in terms of ability, benev-
olence and integrity. Here, ability refers to the skill set and
expertise of the trustee in some speciﬁc ﬁeld. Benevolence
refers to the extent to which the trustee will satisfy the
behavioural expectations and avoid opportunistic behaviour.
Finally, integrity pertains to the tendency of adhering to the
agreed terms and conditions.
Reputation information can be collected from two dif-
ferent sources: direct interactions, and through third-party
reputation networks. In the case of previously unknown
entities, the third-party reputation networks are the primary
source of reputation information. First-hand experiences,
as they become available through direct interactions, are
valuable as they can be relied on to be both truthful and
apply well to the speciﬁc trustor’s context. A combination
of both sources can be used to reason about little-known
entities. The assumption of behavioural consistency that any
reputation-based predictions rely on can be broken by the
trustee at any time; a key measure of the quality of reputation
information is whether the actor is also known to behave
consistently [4], while the reputation tracking itself also
discourages misbehaviour [13].

539
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Contextual Criteria: Contextual criteria comprise factors
that vary from situation to situation. They might change even
in the presence of the same trustor and trustee. We categorize
the key contextual criteria as pertaining to system trust, user
interface aiding decision making, and external environmental
conditions.
The
concept
of
system
trust
was
introduced
by
McKnight et al. [39], [42], who proposed it to consist
of two components: structural assurances and situational
normality. Another component of facilitating factors was
later added by Pavlou [43]. Structural assurances consist of
legal and governmental impersonal structures, such as legal
contracts, safety nets, legal regulations, guarantees and insur-
ances [39], [30]. Structural assurances prove to be a reliable
aid for the establishment of trustee trustworthiness during
the trust decision making. They are especially useful for
trust establishment in the initial stage of trust development,
when collaborating with previously unknown or little known
entities [30]. Situational normality reﬂects the trustor’s belief
that the situation requiring trust decision making is safe and
positive for attaining the desired gains [39], [30]. Structural
assurances and trustor criteria contribute to the formulation
of the trustor’s belief. Facilitating factors refer to non-
governmental structures, such as shared standards, protocols,
relationships, goals or beliefs, which lead to the formulation
of a positive perception about the integrity and adherence of
the trustee [43].
The user interface acts as an important tool for enabling
human trust decision making, as it is responsible for pre-
senting the required information to the users. Our research
aims at providing user interfaces to support a range of trust-
decision-related tasks, and towards this goal we have built
an initial version of the trust decision expert tool that will be
providing a user interface for semi-automated trust decisions
in Pilarcos (see Figure 1). A literature review reveals the
existence of interfaces for making human queries for the
existing trust management systems of ECOLEAD [27] and
TrustCoM [26] as well. During the initial stage, navigational
ease, user-friendly interface, clarity, accuracy and reduced
error rate have a positive impact on trust decision mak-
ing [44], [45]. On the other hand, interactivity, usefulness,
accurate transactions together with zero error rates are
dominant during the committed stage [44], [46].
External environmental factors refer to the set of social,
economic and technological aspects inﬂuencing trust de-
cision making. For example, recession could be a major
environmental factor affecting trust decisions. The external
environmental factors are independent of the trustor, trustee
or the contextual trust decision making criteria.
Collaboration-speciﬁc criteria: Collaboration-speciﬁc cri-
teria refer to the individual objectives and perspectives
of the collaborating enterprises that affect trust decision
making [6]. The objectives of the enterprises refer to their
pre-established intentions about what they wish to gain from
the collaboration. These objectives target the perspective
the adopts on the trust development. For example, if an
enterprise aims at earning money from the collaboration,
then it gives an economic perspective to trust development.
The perspective reﬂects the trustor’s viewpoint towards trust
establishment [6].
We have identiﬁed seven different perspectives on trust es-
tablishment and decision making: service [47], [6], [2], [25]
organizational [6], [2], [25], social [6], [2], economic [6],
[2], psychological [24], [25], behavioural [6], [2], [24], [25]
and technological [6], [2].
The service perspective refers to taking into consideration
the details of service offers. Service offers are made by
enterprises who are willing to collaborate [2], [24]. The
organizational perspective is made out of enterprise char-
acteristics such as its size and setup [6], [2]. The social
perspective for trust decision making targets the outcomes
of the interaction of the enterprise with its external envi-
ronment. One example could be the activities and offerings
made by the enterprise towards the surrounding society,
through the proper consideration of mutually established
contracts, security mechanisms and monitoring [24], [6]. The
economic perspective to trust decision making comprises of
the involvement of monetary risks or possibilities of making
monetary incentives in addition to the ﬁnancial situation of
the enterprise [2], [6]. The psychological perspective refers
to the intentions of the enterprise [24]. The behavioural
perspective concerns the past and present behaviour of
the enterprise [2], [24], [6]. Finally, the technological per-
spective to trust decision making covers the abilities and
competencies of the enterprise [2], [6].
B. Comparison of Trust Management Systems
We will now compare the perspectives on human trust de-
cision making discovered in the literature to the three inter-
enterprise collaboration management systems presented in
Section II-B. The comparison follows the structure of Sec-
tion III-A. The key points of the comparison are summarized
in Table II.
1) Approaches to Trust Development: TrutCoM follows
a cyclic approach to trust establishment [24], [25]. The
monitoring of the collaboration is performed during the
operational phase. Any kind of misbehaviour is dealt with
by activating the appropriate clauses in General Virtual
Organisation Agreement (GVOA) and Service Level Agree-
ment (SLA). For example, monetary compensation may
be required due to service downtime. Furthermore, all the
collaborating enterprises are informed about the observed
bad behaviour. This immediate incorporation of any detected
breach by taking required actions during the operational
phase itself makes their approach to trust decision making
cyclic in nature.
In ECOLEAD, trust establishment is carried out in a
hierarchical manner [6], [28]. The establishment of speciﬁc

540
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Table II SUMMARY OF THE COMPARISON BETWEEN TRUSTCOM, ECOLEAD AND PILARCOS [48].

541
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
trust begins with specifying the underlying objectives which
are further categorised into a number of perspectives. Each
perspective consists of a set of requirements which are, in
turn, divided into value measurement scales and constraints.
The measurable elements act as the basis for monitoring.
Result updating takes place during the termination phase,
so that they can be used during the establishment of future
inter-enterprise collaborations. The hierarchal nature of trust
establishment and the use of monitoring results only in
future collaborations indicate the ECOLEAD approach is
staged.
The Pilarcos approach to trust establishment, management
and decision making is hybrid, i.e., both cyclic and staged
by nature [2], [29]. The Pilarcos middleware performs mon-
itoring during the operational phase, using monitors local
to each enterprise. As in the case of TrustCoM, the detec-
tion of any signiﬁcant misbehaviour leads to compensation
processes, possible partner reorganization and information
dissemination among collaboration enterprises being done
during the operational phase of the collaboration. In other
words, the information from the current collaboration is
being applied both within it and for future collaborations.
The results of the monitoring constitute local reputation
information, which is fed into third-party reputation systems
during the collaboration termination phase [13]. The two
kinds of trust decision points makes the Pilarcos approach
staged as well. On one hand, trust decisions are made on
entering into collaborations with enterprises that carry differ-
ent levels of familiarity from before. Therefore, especially in
the case of previously unknown or little known enterprises,
this point is characterized by either no or very low trust,
which is equivalent to the situation during the initial stage
of trust development. On the other hand, decisions are also
made when more resources need to be committed into the
collaboration; here the decision can be made based on the
experiences gained through the direct interaction with the
collaborating enterprises.
2) Criteria for Trust Decision Making: As mentioned
before, there is no direct involvement of trustor criteria
in the automated trust decision making process of all three
trust management systems. However, they are reﬂected in
the involvement of human-conﬁgured machine agents and
humans themselves during policy establishment and contract
negotiations. The risk attitudes of the trustor have an effect,
for example, as policies are conﬁgured for decision-making,
and contract templates established for automatically negoti-
ated contracts.
Propensity to trust: The mutually agreed contracts and
policies among the collaborating enterprises during the ne-
gotiation phase reﬂect the propensity to trust in Pilarcos
middleware [49], [50], [3]. The negotiated contract can be
understood as an active and distributed agent containing all
the meta-information that governs the working of the inter-
enterprise collaboration [47]. The General Virtual Organi-
zation Agreement (GVOA) and Service Level Agreement
(SLA) reﬂect the existence of propensity to trust in the case
of TrustCoM [51], [24], [25]. Similarly, both GVOA and
SLA comprise a set of policies that deﬁne the legal frame-
work for the operation of the inter-enterprise collaboration
as a whole, and speciﬁc to all the services provided by
collaborating enterprises. For ECOLEAD, mutually nego-
tiated contracts and criteria directing the trust establishment
reﬂect the propensity to trust in the system [52]. In general,
the trustor’s propensity to trust is reﬂected in contracts
particularly through any pre-established contract templates
and negotiation policies. The speciﬁc clauses selected for a
particular collaboration can be inﬂuenced by these criteria
as well, for example through requiring an additional trusted
third party to mediate transactions.
Emotions: The user interface of the trust decision expert
tool that has been designed and implemented as a result of
this research brings the direct involvement of emotions into
the workings of the Pilarcos middleware. TrustCoM includes
an eLearning portal demo, which has a user interface used
for scenario demonstration to the users for ﬁnding suitable
collaboration partners [26]. Similarly, ECOLEAD also has
web and mobile portlets for handling human queries related
to the search for potential partners [27]. The user interface
is the main channel through which the user’s emotional state
can strongly affect a trust decision.
Culture: In the case of Pilarcos, the Business Network
Model (BNM) constitutes the culture affecting the trust
decision making process [49]. The BNM contains infor-
mation regarding the organisation of the inter-enterprise
collaboration. It speciﬁes the policies based on the legal and
regulatory systems of the strategic business domain under
consideration, roles to be played by the different collab-
orating enterprises and interaction among them. Similarly,
the Business Process Model (BPM) represents culture in
the TrustCoM framework [24], [25]. The initiator enterprise
willing to establish a collaboration deﬁnes the BPM, which
contains information about business processes, roles to be
fulﬁlled by the collaborating enterprises, and functional re-
quirements of the collaboration. In the case of ECOLEAD’s
ICT infrastructure, culture is deﬁned by the administrator
through a process referred to as business opportunity char-
acterisation [53]. As in the case of other trust management
systems, the business opportunity characterisation process
outlines the roles which will be played by the different
collaborating enterprises.
The trustee criterion of reputation is to a degree supported
in all three systems. The TrustCoM framework makes use
of reputation information for trust establishment during the
collaboration establishment and SLA generation in the ne-
gotiation phase. The reputation information exists as service
quality, time, cost, integrity, consistency, capabilities, benev-
olence and past experiences. It is obtained from two different
sources: service offers made by the enterprises willing to

542
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
collaborate, and the Enterprise Network (EN) gathering it
through monitoring the collaboration during the operational
phase of the collaboration. The ECOLEAD infrastructure
also makes use of reputation information taken from two
sources: a baseline trust questionnaire, and the Virtual
Breeding Environment (VBE) [6]. The trust questionnaire
is ﬁlled by all the enterprises willing to collaborate through
the VBE, and it gathers information such as organisational
size, setup, ﬁnancial stability, reliability and experience of
similar previous collaborations. The VBE contains repu-
tation information gathered by monitoring the functioning
of the collaboration. In Pilarcos, reputation information
is gathered locally by monitors at each service provider
during the operational phase, and from external reputation
networks. The reputation information is used for making
risk calculations regarding the inter-enterprise collaboration
under establishment or in operation. Both local and external
reputation information is transformed into a uniform format
of number of experiences. Each experience is represented in
terms of four assets, reﬂecting what kind of impact, positive
or negative, major or minor, the collaboration in question has
had on the assets. The asset types considered are monetary,
the service’s own reputation, its autonomy and security, and
satisfaction of the contract and goals of the collaboration.
We will return to the Pilarcos information model in the next
section.
Contextual criteria are considered in various ways by
the three reviewed systems. For system trust, the existence
of monitoring, legally binding contracts and their negotia-
tion possibilities act as its most notable forms. However,
in addition to these elements all three trust management
systems have certain individual factors contributing to this.
In the case of Pilarcos, automated interoperability checking
is an additional factor constituting system trust. The presence
of communication standards and avoidance of information
transformation are extra elements reﬂecting system trust
in TrustCoM. Similarly, the systematic and hierarchical
approach to trust establishment support system trust in
ECOLEAD.
User Interface: The user interface and the information
it provides inﬂuences the user’s trust in the system itself,
in addition to facilitating trust establishment and evaluation
towards the trustee in a given collaboration situation. All
three trust management systems provide user interfaces for
trust management, in varied forms. For Pilarcos, we propose
a trust decision expert tool whose user interface presents
the users with information on risk, reputation, collabora-
tion context and collaboration progress. The proposed trust
decision expert tool targets non-routine cases that require
human intervention for trust decision making. TrustCoM
also supports information-providing user interfaces and re-
alizes their importance [24], [25]. However, their design
falls outside the scope of the TrustCoM project. ECOLEAD
facilitates possibilities of user interaction via computer-
supported collaborative tools such as mails, chat, calendar
and notiﬁcations, in addition to the simulated partner search
service provided by its test prototype [27].
The exact form of inﬂuence the interface has on the user
is an interesting research problem in itself. Karvonen et al.
have found cultural differences in how users experience the
trustworthiness of an online service [54]. An earlier research
collaboration in the Trustworthy Widget Sharing (WiSh)
project studied how private people interact with the user
interface when making decisions to download software for
mobile phones provided by other users [55], [23], but more
research is needed on the more complex user interfaces for
trust management in inter-enterprise collaborations.
External Environmental Factors: We ﬁnd that all three
trust management systems indicate implicit or explicit sup-
port for external environmental factors. Pilarcos explicitly
supports them through using context as one of the parameters
for automated trust decision making. The sources provid-
ing the information for the context parameter reﬂect both
internal and external environmental factors, encompassing
the internal state of the service, the business state of the
service provider enterprise, and the state of the collabora-
tion the enterprise is involved in [29], [2]. On the other
hand, TrustCoM and ECOLEAD implicitly support external
environmental factors. TrustCoM has adopted the notion that
“trust is always set within a social context” [24]. We believe
that the social context is affected by different external social,
technological and economic factors. Similarly, ECOLEAD
also considers social factors as one of the perspectives for
assessing trustworthiness of the target entity [6].
Collaboration-speciﬁc criteria are similar in terms of
objectives, while varying in the selection of perspectives
among the three systems.
Perspectives: All three trust management systems have
their independent and overlapping perspectives to trust deci-
sion making. Pilarcos considers service, economical, techno-
logical and behavioural perspectives for trust establishment
[49], [50], [29], [2]. Similarly, TrustCoM also considers trust
decision making from four different perspectives: service,
psychological, behavioural and social [24], [25]. ECOLEAD
relies on ﬁve different perspectives: organisational, social,
economical, technological and behavioural [6].
Objectives: As mentioned previously, there are either
shared or individual objectives involved in any inter-
enterprise collaboration. Therefore, the dimension of objec-
tives applies equally to all three systems. In each of them, the
inter-enterprise collaboration have some shared objectives, in
addition to which collaborating enterprises have their own
individual objectives behind their participation.
IV. PILARCOS TRUST DECISION SUPPORT
In this section, we present the design of the user interface
for supporting human interventions on trust decisions. The

543
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
presented user interface extends the Pilarcos trust manage-
ment system.
A. Pilarcos Trust Management System
In Pilarcos, local trust decisions are made by agents within
the enterprise, on behalf of a single service provided by it.
The decisions are based on a combination of local, private
and shared information, and both the decision policies and
policies for collecting and processing the relevant informa-
tion are speciﬁc to a service. Decisions are triggered when
a new collaboration is joined, or at points where signiﬁcant
new resources are committed in an ongoing collaboration.
The goal of the decisions is to protect the enterprise’s assets
through evaluating whether the risks and beneﬁts of the
given collaboration are in balance.
The Pilarcos trust management system makes automated
trust decisions based on seven different parameters: trustor,
trustee, action, risk, reputation, importance and context [2].
As discussed previously, the trustor and trustee are business
services operating within their respective enterprises. The
action represents a collaboration task that needs to be per-
formed, involving a commitment of the trustor’s resources.
The risk and reputation factors are closely connected: risk
estimates present probabilities of different outcomes calcu-
lated based on reputation information, which in turn is stored
as experience counters of different observed outcomes so
far. These experiences are gathered both directly through
local monitoring, and as shared information through rep-
utation networks [2]. While shared reputation information
may be erroneous and is therefore locally evaluated for
credibility, it provides a valuable extension to the ﬁrst-hand
information particularly in the case of actors that are not
previously known, and actors who have recently changed
their behaviour.
The representation of the experience information deter-
mines how it can be used. The classical value imbalance
problem [8], for example, stems from experiences only
measuring the positive or negative outcome of an action: four
small-value transactions weigh four times more than a single
large-value transaction. In some cases the costs and beneﬁts
of a collaboration cannot easily be measured in monetary
terms: a collaborator may pay an agreed-upon service fee,
but then violate the contract terms or overload the service to
make it fail for other users, causing lost business elsewhere.
In order to balance between better capturing complex
outcomes and supporting automated real-time processing of
the experience information, Pilarcos represents the effects of
the collaboration outcomes on the enterprise, or the business
service more speciﬁcally. We have applied the idea of asset-
based risk analysis to form our model, and introduce four
high-level asset classes: monetary, reputation, control and
satisfaction [2]. The outcome effects are then represented
on the scale of large negative effect, slight negative effect,
no effect, slight positive effect and large positive effect that
the action or collaboration task has been observed to have on
that asset. This condensation of possible outcomes to a set
of categories for affected assets improves the reusability and
interoperability of reputation information across different
enterprises; for example the monetary value of reputation
gains is not universal, but highly subjective and even time-
dependent.
The monetary asset denotes any resources that can be
represented in monetary terms. The reputation asset reﬂects
the trustor’s own public relations, appearance in the me-
dia, and attitudes of their customers and partners towards
them [2]; in contrast, the reputation information discussed
above concerns the past behaviour of the trustee. The need
for security, privacy and other aspects related to autonomy
are represented by the control asset. This amalgam category
aims to capture general threats that do not directly translate
to monetary or reputation terms, such as threats towards
the trust management system itself, service availability, or
capacity to enter into new beneﬁcial collaborations coming
up during the given deal. Lastly, the degree of fulﬁllment
of the trustor’s expectations by the trustee is represented
by the satisfaction asset: it is used to measure whether the
trustee tends to respect its agreements [2]. While contract
satisfaction by itself is not generally considered an asset in
the sense of organizational risk analysis, it is such a central
part of reputation information that most systems ignore
all other dimensions of experience. An organization can
decide whether it enters into a given contract with another
organization, but it cannot control whether the counterparty
follows the contract.
The reputation counters of observed outcomes are con-
verted into a risk estimate by transforming the absolute
numbers into ratios: essentially, 5 major positive experiences
out of 10 total experiences translates into a probability of
50% of a major positive outcome for that asset. Relevant
adjustments are made to accommodate low-stake actions
that cannot have a large monetary effect, for example,
and credibility-based weighting between local and shared
reputation information.
The risk estimate is compared to risk tolerance formulae
to determine the outcome of the decision. Risk tolerance
checks may be adjusted automatically according to the
strategic importance speciﬁed for the action; this essentially
represents the known beneﬁts of a positive decision, such
as not having to compensate other collaborators due to
withdrawal from the collaboration during its operation. In
the automated trust decision making process, the different
factors are also subject to change by the context parame-
ter, which manifests as conditional ﬁlters, or modiﬁers, of
the data to allow temporary situational adjustments in the
system. One example of a context modiﬁer is insurance,
which can apply to all actions in one speciﬁc collaboration
and either reduce or altogether eliminate the monetary risk
involved. The information model and policy options are

544
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
discussed in more detail in earlier work [2], [13].
The information and process model for trust management
forms the basis for automation as well as the information that
can be shown to the user to support a human intervention
in a situation where an automated decision cannot be made.
Factors to consider in handling human intervention for semi-
automated trust decisions include the phenomenon of human
trust decision making and information requirements of the
human users, which we have discussed in the previous
sections. Further into the design phase, additional factors
to consider include the appropriate way of presenting the
information, and reducing the frequency of calls for human
intervention in the future, to ensure that the efﬁciency of
collaboration management is maintained. We discuss these
factors in the next section.
B. User Interface
The user interface design of the proposed trust decision
expert tool was gained from Nielsen’s usability principles
for designing user interfaces [44] and different cognitive
strategies: Cognitive Fit Theory, Cognitive Load Theory,
Uniﬁed Theory of Acceptance and Use of Technology and
Technology Acceptance Model [56], [57], [58].
In accordance with the Pilarcos trust information model,
the user interface presents information about risk, reputation,
goals affecting the importance of the action, and con-
text [48]. Within its main information views, it presents fur-
ther details on the credibility of the information, behavioural
changes that can affect the validity of the reputation infor-
mation, assets endangered according to the risk tolerance
comparison, and the progress status of the collaboration
when trust decisions need to be made during the operational
phase of the collaboration. The information is presented as
a combination of textual and graphical formats. Figure 1
shows an example risk view of the user interface; the other
major views of reputation, context and progress information
are minimized in the screenshot.
On the top, the user interface presents the goals of
the inter-enterprise collaboration, such as earning money,
gaining experience or building reputation. The importance
of the goals that the enterprise has set for the collaboration
encourage a positive trust decision. In addition to the goals,
the deadline for making the trust decision is prominently
shown. Both these information elements and their placement
promote transparency.
The risk view presented in the ﬁgure shows the produced
risk estimate, represented in the form of probabilities of
different outcomes. These outcomes for different assets
follow the trust information model of Pilarcos, as described
in the previous section. The four asset classes correspond
to four graphs in the risk information view. The effects on
different assets are independent of each other. In the ﬁgure,
the probability of a slight negative effect on the monetary
asset is 0.35, and the probability of a slight reputation
gain is 0.4, for example, but it is entirely possible for the
collaborator to both cost money and cause negative publicity.
When forming a risk estimate, the total probability of 1 is
divided between different outcomes towards a speciﬁc asset
based on the experience information and context ﬁlters.
The risk information can be studied through two different
views: collaborative and enterprise view. The collaborative
view presents collective risk probabilities for the collabo-
ration as a whole; it reﬂects the fact that even though a
trust decision is generally made concerning a one-on-one
interaction within a larger collaboration, other participants in
the collaboration may have a strong inﬂuence on the eventual
outcome of the action. A manager may consider placing
an order to a generally reliable contractor, for example, yet
decide against the plan due to not being able to trust its
proposed subcontractors for this collaboration. In contrast,
the enterprise view provides information about the risk posed
by the single trustee individually. The current version of
the trust decision expert tool presents the collaborative and
enterprise view in the exact same format, as shown in
Figure 1. As an item of future work, we study ways of
visualizing an overview of multiple collaborators’ reputation
and risk information individually to avoid the information
loss of automatically merging them into one, such as by
weighted averages or selecting the worst case.
The reputation view provides background information to
the risk estimate. Reputation information is presented as
graphs, as shown in Figure 2. It consists of experiences,
which reﬂect the past and present behaviour of the trustee
on the same outcome scale as the risk information. The view
also shows the estimated credibility of the shared reputation
information, and presents whether the trustee’s behaviour
has been consistent or not, which may have an impact on
the validity of the available reputation information.
Behavioral consistency is expressed through the number
of times the system has detected a change in the actor’s
behaviour [4], and by showing both the overall experiences
and the experiences based on the current period of consistent
behaviour. Each period of internally consistent behaviour
is referred to as a reputation epoch, and the number of
epochs reﬂects the number of times an inconsistency has
been observed. In this view, the total number of experiences
observed on the trustee is 37, and they are divided into two
reputation epochs. In other words, after the ﬁrst 8 experi-
ences, the trustee’s behaviour pattern changed enough that
a new reputation epoch was started. The current reputation
epoch has lasted for the 29 most recent experiences, 17 (8+9)
of which are negative, 7 (4+3) positive and 5 neutral.
The underlying system supports unknown outcomes in
experiences as well, due to an implementation convention
that each stored experience item contains an outcome value
for all four assets. We do not show any unknown outcomes
in this version of the user interface, however. Instead, the
total number of experiences for, say, the control asset could

545
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Figure 1.
Risk information view of the trust decision expert tool [1].
be lower than the number of experiences for the monetary
asset, if the outcome could not be measured in some cases
or a reputation source only provided experiences from the
monetary and satisfaction points of view, for example.
In Figure 2, the overall view credibility for reputation
from the monetary point of view (0.9) is higher than that
of the current reputation epoch (0.5), which implies that
the recent experiences have come from lower-credibility
sources, while the early experiences would be ﬁrst-hand
or from equally trustworthy sources. The exact calculation
formula for derived factors such as the view credibility
depends on the speciﬁc policies in use. To support the
repeatability of the user experiments, we have manually
conﬁgured a ﬁxed output shown to all the users, so they
do not directly reﬂect speciﬁc policies in the system.
Finally, the view uses colours to indicate the assets for
which the risk estimate is not within the automatically
acceptable risk tolerance bounds, as the actor’s reputation
information for these speciﬁc assets may be of particular
interest. This information is communicated on the reputation
view, where the user interface element doubles as a means
to look at the reputation information of a speciﬁc asset. The
red colour for monetary asset means that the high number of
negative experiences gained on the actor, when measuring
the monetary effects that collaborating with it has had,
translates to a monetary risk estimate that is not considered
acceptable for an automated decision. As with risk estimates,
the collaborative view of reputation is identical in format
to the enterprise view, which means that the reputations of
the individual participants must be ﬂattened into a single
collection by weighted averages, for example. A way to
visualize a collaboration-wide overview that retains relevant
information better is an interesting item of future work.
In automated trust decisions in Pilarcos, risk estimates
are compared against risk tolerance, which is in turn based
on the strategic importance of the action at hand. While
the importance is represented through the goals of the
collaboration, and tolerance constraints are partially visible

546
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Figure 2.
Reputation information view of the trust decision expert tool [48].
through the assets shown not to be within limits, in manual
trust decisions the human user is responsible for analyzing
and setting the actual risk tolerance limits for the decision.
In the expert tool, the context information view presents
the currently active context items to the human users through
simple textual phrases, such as “Enterprise A is an important
strategic partner” or “The current collaboration is covered
by insurance”. This information is collected from the de-
scriptive metadata of any active context ﬁlters; we do not
consider the formulas of the context ﬁlters themselves to be
particularly informative to the user.
Finally, the progress information view of the expert tool
supports trust decisions on ongoing collaborations. The
view presents the progress of the collaboration in graphical
format, visualizing the tasks completed by different partners.
The views not shown in this paper can be found in the
accompanying technical report [48].
The eventual user decision is either to accept and approve
the action or reject it, which generally results in a withdrawal
from the collaboration. In addition, the tool will ask the
user to provide a scope for the trust decision: whether it
applies for the remainder of the contract, or for a given time
period, or for this speciﬁc decision only. This helps reduce
the frequency of requests for human intervention, as further
decisions needed within the set scope can be automated. The
scope information is stored as a context ﬁlter, which over-
rides the risk tolerance formulae appropriately to automatic
rejection or acceptance for future decisions within the given
scope.
C. User Evaluation
The usability of the trust decision making tools is an
important part of enabling user involvement in trust decision
making for inter-enterprise collaborations. The tools will not
be deployed if are too difﬁcult to use, cannot reﬂect the
user’s information needs, or are conceptually incompatible
with human trust decision making processes. We have im-
plemented the trust decision expert tool as a part of enabling
user involvement in the Pilarcos collaboration management
system, and present here the user study setup and initial
results of the user evaluations of the expert tool [48].
We have evaluated the trust decision expert tool interface
from four points of view: (i) sufﬁciency of the presented
information, (ii) usability, (iii) user performance and (iv)
quality. All ﬁve participants in the initial evaluation are
researchers in the ﬁeld of computer science, and one of them
was somewhat familiar with the underlying Pilarcos trust
management software speciﬁcally from before. The main
objective behind recruiting technically savvy participants
was to gather feedback from users who are representative
of the actual target user base of the Pilarcos expert tool.
The user study took around one hour per user.
The user studies were conducted in three phases: in-
troduction, solving test tasks and debrieﬁng. During the
introduction phase, test participants were ﬁrst explained the
purpose of the study, study setup and details regarding task

547
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
performance. Following this, they were informed about the
code of ethics and asked to sign the permission form. After
the introduction by the moderator, the test participants were
presented with the following test scenario:
“You are running an enterprise named ‘Quick Service,’
which provides online logistic services within Europe. Your
enterprise is involved in collaborating online with other
enterprises throughout the world. You are using the Pilar-
cos middleware for managing your online collaborations.
Usually, Pilarcos middleware makes automated decisions
regarding your enterprise’s participation in the online col-
laborations, but now you have received an email, containing
a link, asking you to make a decision regarding your
continuation in an ongoing collaboration.”
Based on the test scenario, the participants were asked to
write down their expectations about information that they
would like to have for making trust decisions in such a
situation. After the introductory phase, the test participants
were allowed to study the user interface to familiarize
themselves with it. During the second phase of the user
evaluation, the test participants were presented with a set
of tasks they are asked to perform using the user interface,
one by one. An example of a test task is as follows:
“After reading the email, you already started thinking
about the assets that might be endangered by further par-
ticipating in the collaboration. You ﬁgure out money is the
most important asset for your enterprise. You decide to ﬁnd
out the risks that the collaboration poses economically to
your enterprise.”
Each task was further divided into three to four sub-
tasks which involved ﬁnding required information from
the user interface. The sub-tasks, handled one at a time,
were provided on paper slips which consisted of a question
statement and multiple choices where the participants could
mark their answers using a pen or pencil. The decision
on presenting the sub-tasks on pieces of paper was made
in order to reduce moderator inﬂuence. Furthermore, they
enabled concluding the test at any time when desired by the
test participant, without making them feel uncomfortable for
not completing the test.
The test participants were encouraged to think aloud while
performing the test tasks. The “think aloud” methodology
has been employed to gain insights into the problems and
thought process of the participants while they are performing
the test tasks [44]. The moderator noted the time taken by
test participants to complete each sub-task and comments
made while performing it. The completion of each task was
followed by a short questionnaire capturing the real-time
experience of the participants after each task.
Finally, during the debrieﬁng phase, the test participants
were asked to ﬁll in a post-questionnaire aimed at gathering
general experience and impressions about the user interface.
The post-questionnaire consisted of objective type questions
gathering feedback using a ﬁve-point Likert scale, ranging
from “strongly agree” to “strongly disagree”, in addition to
open-ended questions. Example claims included: “The trust
decision expert tool is easy to use.” “I think the trust decision
expert tool presents all the information needed for decision
making.” “I think the trust decision expert tool presents the
information in formats co-related with the task of decision
making.” Example open ended questions included: “In the
trust decision expert tool I liked...” and “In the trust decision
expert tool, I think the following information is missing...”
The user evaluations have been made with ﬁve test par-
ticipants, which has provided us with useful feedback on
further developing the tool. In order to draw any broader
conclusions about the usability of the trust decision expert
tool, a larger user experiment is necessary. However, as the
tool development work is ongoing, the smaller experiment
supports particularly the discovery of any glaring issues that
should be addressed in the next version of the prototype.
We have planned and worked on related decision elements
as separate projects that are yet to be bundled together to
a coherent set of user interfaces; this bundled whole would
then form a natural target for larger-scale testing in future
work.
The ﬁrst point of view evaluated the sufﬁciency of the
information presented to the human users for trust decision
making. As previously mentioned, the user interface presents
risk, reputation, context, collaboration progress status, goals
and credibility information for trust decision making. Ta-
ble III shows the user rating of the user interface in terms
of the sufﬁciency of the presented information. Based on the
analysis of the debrieﬁng phase and participant comments
while performing the tasks, we believe the probable reason
for disagreement might be the absence of some relevant
information, such as the value of the contract in terms of
possible monetary proﬁts to the enterprise. Another sugges-
tion for enhancing the available information concerned a
more detailed representation of the collaboration progress,
relating it to the underlying business process model instead
of simple milestones.
The second point of view of usability evaluated how
easy the user interface was to use, in terms of ease of
ﬁnding the presented information, clarity and existence of
correlation between the information presentation formats and
tasks to be performed. Missing or unclear information were
again a likely cause for critique here. For example, the
test participants were unclear about the ontological meaning
of the assets. Furthermore, some users suggested that a
summarized and concise view of the information already
presented should be added, including, for example, small
textual sentences such as “you have 63% probability of
gaining monetary beneﬁts”.
The third point of view of the user performance evaluated
the user interface in terms of the success rate of task comple-
tion, number of errors committed while performing the tasks,
and time taken for task performance. The evaluation results

548
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Table III SUMMARY OF THE USERS’ OVERALL EVALUATIONS.
Statement
Str. Agr.
Agree
Neutral
Disagree
Str. Dis.
Sufﬁciency of information
-
3
-
2
-
Ease of ﬁnding information
-
3
2
-
-
Clarity fo presentation
-
4
-
1
-
Correlation between information
2
1
2
-
-
presentation and tasks
Ease of use
-
3
2
-
-
Conﬁdence of using
-
3
2
-
-
Willingness to use in future
-
4
-
1
-
Feel safe to use
-
-
4
1
-
reveal that the task completion rate is 100% irrespective of
accuracy. However, when considering the factor of accuracy,
the successful task completion rate is 100% for only two of
the participants. It is 93% for two other users, and 78% for
one participant. In other words, the error rate is 7%. We
suspect the lack of attentive focus while reading the tasks
to be the main reason for the existing error rate, because
we found the same participants giving correct answers to
other similar tasks. Regarding task completion timing, we
found that three of the test participants are able to perform
71% of the tasks within seconds, whereas the remaining
participants perform respectively 79% and 93% of the tasks
in seconds. The times taken here varied from less than
10 seconds seconds to almost a minute depending on the
task presented. In contrast, the most laborous of the tasks
required up to two and a half minutes (with a mean of 1:28)
for the users to ﬁnd the required information. The time taken
is reasonably agreeable considering the novelty of the tool,
as none of the participants have ever used any kind of trust
decision expert tool before. It does reﬂect the difﬁculty of
using an expert tool to make manual decisions in complex
situations, however: as the available information becomes
more intricate, the need to help the user through an intuitive
user interface and controlled automation increases.
The fourth point of view of quality aims to evaluate the
user satisfaction of using the user interface in terms of
ease of use, conﬁdence, willingness to use and perception
about security. The evaluations are summarized on the last
four lines of Table III. As mentioned previously, insufﬁcient
presented information seems to be a likely reason for dis-
agreements or neutral opinions.
In general, we learned that the test participants found the
information presentation formats to be easy to read and un-
derstand. They also stated they found the user interface to be
intuitive, although obviously there is room for improvement.
The user evaluations also resulted in identifying some
suggestions in terms of missing information for further im-
provement of the existing version of the trust decision expert
tool. Table IV presents the suggestions or recommendations
together with the participant concerns and their priority. The
participant concern provides the justiﬁcation for introducing
the proposed change. Priority has been decided based on
three factors: effect of the change on the workings of the
trust decision expert tool, support provided by the Pilarcos
trust management system, and number of participants sup-
porting it. For example, presenting the summarised view of
the presented information will affect trust decision making
positively and can be supported by Pilarcos. Furthermore,
a majority of the test participants expressed their desire of
having this kind of information for trust decision making.
V. CONCLUSION AND FUTURE WORK
Inter-enterprise collaborations and social networking have
become part of our normal life. To support dynamically
evolving open service ecosystems, we need infrastructure
to handle interoperability management, collaboration coor-
dination, breach recovery and trust management. Organiza-
tional and individual users’ decision-making processes and
the conceptual basis required by them are not sufﬁciently
supported by automation tools yet. Particularly, the concepts,
processes and interfaces for enabling user involvement are
missing in many current collaboration management systems.
Furthermore, consumers of collaboratively provided services
or networked services in general are not sufﬁciently aware
of the trust related threats in this new environment. As a
result, they act too trustingly or base their trust decisions
on unreliable, or unsuited information. Both in the service
provision environments and in the service consumption side
it is still early days when it comes to understanding how
the complex networks and partners cause threats in trust-
requiring activities.
It is essential that research is done on trust management
for inter-enterprise collaborations where there is no joint
source for information on who to trust. We need to ﬁnd out
how the human or organizational decision-making processes
work and what kind of information humans can perceive and
judge situations with. We need to ﬁnd out how trust decisions
can be supported with automation, and how that automation
or trust decision interfacing can be kept secure. Furthermore,
trust decisions often take place side by side with strategical

549
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Table IV SUGGESTIONS, PARTICIPANT CONCERN AND PRIORITY REGARDING RECOMMENDATIONS FOR TRUST DECISION EXPERT TOOL.
Suggestion
Participant Concern
Priority
Summary/Analysis of the presented infor-
mation
Test participants are concerned about analyzing the presented
information. The summary can give them more conﬁdence
and enhance clarity.
High
Information about other collaboration alter-
natives
Test participants are anxious to know other collaboration pos-
sibilities. In the case of Pilarcos, this need will be addressed
by a collaboration negotiation expert tool in planning.
Low
Previous decision history
Test participants are concerned about the previous decisions
made automatically or manually on behalf of the enterprise.
This will enhance clarity and conﬁdence in decision making.
Medium
Ontological explanation of presented factors
Test participants are particularly concerned about the exact
meaning of the presented information. This will enhance
conﬁdence, clarity and perceptions about security.
High
Simulating effects of different policies
Test participants desire to analyze the effects of simulating
different policies on presented value. Pilarcos supports only
one simulation at the time, however. Availability will enhance
conﬁdence, clarity and perception about safety.
Medium
Proper business process representation
Test participants are concerned about current used format for
presenting progress information. Good information formats
will promote clarity, conﬁdence and safety perception.
High
choices and privacy checks, as in the case of Pilarcos. Thus
the larger problem is how to design a human-perceivable
process to interact with all these facilities.
In this paper, we have analyzed some of the inter-
enterprise collaboration management systems with their trust
management approaches. Interfacing with human and organ-
isational users on the collaboration and service aspects is
not simply a technical user interface problem, but requires
that the systems in their entirety have been built in a way
that respects the human and organisational concepts, and the
processes of perceiving and making decisions. In contrast
to the other approaches, we are studying reputation systems
based on contract fulﬁlment, as subjective experience reports
based on pure opinion are problematic from the point of
view of reputation system robustness. If there is no way to
punish unfair experience reports, the incentives to misuse
reputation systems threatens to leave them unusable in prac-
tice. Contractually regulated experience reporting improves
the quality of the input information to the trust management
system.
The contribution of this paper lies in the study and ap-
plication of the human processes meeting the trust decision
support systems. First, the literature study gave us insight
on the human perspectives on decision making. Second, we
focused on understanding the user interface role and criteria.
The systems must approach users as autonomous decision-
makers that need both automated support for routine tasks in
routine situations, and intervention possibilities in less clear
circumstances. Furthermore, an individual may be acting on
behalf of an organisation, or at least bound by a hierarchy of
regulations in his or her use case context. Third, we applied
the gained knowledge to a ﬁrst-cut user interface design. The
small study on the usability of that indicates that our plans on
a larger interface that captures decision aspects on privacy,
business network model and enterprise strategies as well are
justiﬁed, and the connectivity of those aspects is indeed
expected by the users. The focal points to be presented
include i) clear summaries that can be expanded into more
detailed information as needed, ii) communication of the
ontological meaning of presented decision factors, and iii)
access to information about the proposed or existing collab-
oration as a whole, such as the progress of the collaborative
business process. It is also particularly beneﬁcial to represent
and simulate the effects of conﬁguring and reconﬁguring a
collaboration, such as partner changes and different business
network model selection.
Our future work include research and development of
interfacing processes and user interfaces for collaboration
contracts, agents managing collaborations in organisations,
and for ecosystems within which the inter-enterprise col-
laborations are governed. In addition, developing metrics
for observing service behaviour would beneﬁt both the
reputation-based trust decisions and the re-engineering of
collaborations and service portfolios of enterprises.
In larger scale, the future development should include
education on trust issues for awareness rising in consumers
to require proper management facilities for trust and privacy
aspects of the networked services they use in daily life.
In addition, standards for distributing trust and reputation
related information should be developed with sufﬁciently
wide scope of system models in mind, in order to cover
not only client-to-system trust, or client-to-server trust, but
true collaborative networks too.
ACKNOWLEDGMENT
We would like to thank our anonymous reviewers for their
helpful comments. The research leading to this publication

550
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
was conducted as a part of the CINCO group at the Uni-
versity of Helsinki, Department of Computer Science. It has
been funded by the Academy of Finland through the Trusted
Business Transactions (TBT) project.
REFERENCES
[1] P. Kaur, S. Ruohomaa, and L. Kutvonen, “User interface
for trust decision making in inter-enterprise collaborations,”
in Proceedings of the Fifth International Conference on
Advances in Computer-Human Interactions (ACHI 2012).
Valencia, Spain: IARIA, Jan. 2012, pp. 122–127, Best
paper award. [Online]. Available: http://www.thinkmind.org/
download.php?articleid=achi 2012 5 30 20133
[2] S. Ruohomaa and L. Kutvonen, “Trust and distrust in
adaptive inter-enterprise collaboration management,” Journal
of Theoretical and Applied Electronic Commerce Research,
Special Issue on Trust and Trust Management, vol. 5,
no.
2,
pp.
118–136,
Aug.
2010.
[Online].
Available:
http://www.jtaer.com/aug2010/ruohomaa kutvonen p7.pdf
[3] L. Kutvonen, T. Ruokolainen, S. Ruohomaa, and J. Metso,
“Service-oriented middleware for managing inter-enterprise
collaborations,” in Global Implications of Modern Enterprise
Information Systems: Technologies and Applications, ser.
Advances in Enterprise Information Systems (AEIS).
IGI
Global,
Dec.
2008,
pp.
209–241.
[Online].
Available:
http://www.igi-global.com/reference/details.asp?id=9648
[4] S. Ruohomaa, A. Hankalahti, and L. Kutvonen, “Detecting
and reacting to changes in reputation ﬂows,” in Trust
Management
V,
ser.
IFIP
Advances
in
Information
and Communication Technology, vol. 358, Copenhagen,
Denmark,
Jun.
2011,
pp.
19–34.
[Online].
Available:
http://dx.doi.org/10.1007/978-3-642-22200-9 5
[5] P.
Kaur
and
S.
Ruohomaa,
“Human
intervention
on
trust
decisions
for
inter-enterprise
collaboration,”
in
Post-Proceedings
of
the
EDOC2011
PhD
symposium,
ser.
Department
of
Computer
Science
Series
of
Publications B, vol. B-2011-1.
University of Helsinki,
Department of Computer Science, Aug. 2011. [Online].
Available: http://www.cs.helsinki.ﬁ/group/cinco/publications/
public pdfs/kaur11human.pdf
[6] S. S. Msanijla, H. Afsarmanesh, J. Hodik, M. Reh`ak,
and
L.
M.
Camarinha-Matos,
“ECOLEAD
deliverable
D21.4b:
Creating
and
supporting
trust
culture
in
VBEs,” EC Information Society, Tech. Rep., Mar. 2006.
[Online].
Available:
http://www.ve-forum.org/projects/284/
Deliverables/D21.4b Final.pdf
[7] H. van der Heijden, T. Verhagen, and M. Creemers,
“Understanding online purchase intentions: contributions
from technology and trust perspectives,” Eur. J. Inf. Syst.,
vol. 12, no. 1, pp. 41–48, March 2003. [Online]. Available:
http://portal.acm.org/citation.cfm?id=965200.965205
[8] Y.
Yao,
S.
Ruohomaa,
and
F.
Xu,
“Addressing
common vulnerabilities of reputation systems for electronic
commerce,” Journal of Theoretical and Applied Electronic
Commerce Research, vol. 7, no. 1, pp. 1–15, Apr. 2012.
[Online]. Available: http://www.jtaer.com/statistics/download/
download.php?co id=JTA20120101
[9] A. Jøsang and R. Ismail, “The Beta reputation system,” in
Proceedings of the 15h Bled Electronic Commerce Confer-
ence, Bled, Slovenia, Jun. 2002, pp. 324–337. [Online]. Avail-
able: http://ecom.fov.uni-mb.si/proceedings.nsf/Proceedings/
D9E48B66F32A7DFFC1256E9F00355B37/$File/josang.pdf
[10] A. Jøsang and J. Haller, “Dirichlet reputation systems,”
in Proceedings of the Second International Conference on
Availability, Reliability and Security (ARES 2007).
Vienna,
Austria: IEEE Computer Society, Apr. 2007, pp. 112–119.
[Online]. Available: http://dx.doi.org/10.1109/ARES.2007.71
[11] Y. Wang, C.-W. Hang, and M. P. Singh, “A probabilistic
approach for maintaining trust based on evidence,” Journal of
Artiﬁcial Intelligence Research, vol. 40, no. 1, pp. 221–267,
2011. [Online]. Available: http://www.jair.org/media/3108/
live-3108-5411-jair.pdf
[12] T. D. Huynh, N. R. Jennings, and N. R. Shadbolt, “An
integrated trust and reputation model for open multi-agent
systems,” Journal of Autonomous Agents and Multi-Agent
Systems, vol. 13, no. 2, pp. 119–154, 2006. [Online].
Available: http://eprints.ecs.soton.ac.uk/12593/
[13] S.
Ruohomaa,
“The
effect
of
reputation
on
trust
decisions
in
inter-enterprise
collaborations,”
Ph.D.
dissertation,
University
of
Helsinki,
Department
of
Computer
Science,
May
2012.
[Online].
Available:
http://urn.ﬁ/URN:ISBN:978-952-10-7912-2
[14] S. Ruohomaa, L. Kutvonen, and E. Koutrouli, “Reputation
management survey,” in Proceedings of the 2nd International
Conference on Availability, Reliability and Security (ARES
2007).
Vienna, Austria: IEEE Computer Society, Apr. 2007,
pp. 103–111. [Online]. Available: http://dx.doi.org/10.1109/
ARES.2007.123
[15] A.
Jøsang,
R.
Ismail,
and
C.
Boyd,
“A
survey
of
trust and reputation systems for online service provision,”
Decision Support Systems: Emerging Issues in Collaborative
Commerce, vol. 43, no. 2, pp. 618–644, Mar. 2007. [Online].
Available: http://dx.doi.org/10.1016/j.dss.2005.05.019
[16] R.
Kerr
and
R.
Cohen,
“Smart
cheaters
do
prosper:
Defeating trust and reputation systems,” in Proceedings of
the 8th International Conference on Autonomous Agents
and Multiagent Systems (AAMAS 2009), vol. 2.
Budapest,
Hungary:
ACM,
May
2009,
pp.
993–1000.
[Online].
Available: http://dl.acm.org/citation.cfm?id=1558151
[17] V. Cahill et al., “Using trust for secure collaboration
in uncertain environments,” Pervasive Computing, vol. 2,
no. 3, pp. 52–61, Aug. 2003. [Online]. Available: http:
//ieeexplore.ieee.org/iel5/7756/27556/01228527.pdf
[18] “The eBay online marketplace website,” 2012, (Accessed
17.12.2012.). [Online]. Available: http://www.ebay.com/
[19] P. Resnick and R. Zeckhauser, “Trust among strangers in
internet transactions: Empirical analysis of eBay’s reputation
system,” in The Economics of the Internet and E-Commerce,
ser. Advances in Applied Microeconomics, vol. 11.
Elsevier
Science, Amsterdam, 2002, pp. 127–157. [Online]. Available:
http://dx.doi.org/10.1016/S0278-0984(02)11030-3

551
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[20] S. Marsh, A. Basu, and N. Dwyer, “Rendering unto Caesar
the things that are Caesar’s: Complex trust models and
human understanding,” in IFIPTM 2012, ser. IFIP AICT, no.
374, NIT Surat, India, May 2012, pp. 191–200. [Online].
Available: http://dx.doi.org/10.1007/978-3-642-29852-3 13
[21] S. Ries, “Trust in ubiquitous computing,” Ph.D. dissertation,
TU
Darmstadt,
Oct.
2009.
[Online].
Available:
http:
//tuprints.ulb.tu-darmstadt.de/1948/
[22] B. Fogg, C. Soohoo, D. Danielson, L. Marable, J. Stanford,
and E. R. Tauber, “How do people evaluate a web site’s credi-
bility?” Stanford Persuasive Technology Lab, Tech. Rep., Oct.
2002. [Online]. Available: http://www.consumerwebwatch.
org/dynamic/web-credibility-reports-evaluate-abstract.cfm
[23] K. Karvonen, T. Kilinkaridis, and O. Immonen, “Widsets:
A usability study of widget sharing,” in Human-Computer
Interaction - INTERACT 2009, ser. LNCS, vol. 5727,
no. II, Uppsala, Sweden, Aug. 2009, pp. 461–464. [Online].
Available: http://dx.doi.org/10.1007/978-3-642-03658-3 50
[24] M. Wilson, D. Chadwick, T. Dimitrakos, J. Doser, A. Arenas,
P. Giambiagi et al., “The TrustCoM Framework V0.5,” in 6th
IFIP Working Conference on Virtual Enterprises (PRO-VE
2005), Valencia, Spain, Sep. 2005.
[25] M.
Wilson,
A.
Arenas,
D.
Chadwick,
T.
Dimitrakos,
J. Doser, P. Giambiagi, D. Golby, C. Geuer-Pollman,
J. Haller, K. Stølen et al., “The TrustCoM approach to
enforcing agreements between interoperating enterprises,” in
Interoperability for Enterprise Software and Applications
Conference
(I-ESA’06),
Bordeaux,
France,
Mar.
2006.
[Online].
Available:
http://epubs.cclrc.ac.uk/bitstream/898/
Trustcom Interoperability France.pdf
[26] R. Ratti, M. del Mar Rodrigo Castro, C. A. Ferrandiz,
S. Mores, R. Rabelo, R. J. T. Junior, and P. Gibert, “TrustCoM
project ﬁnal report,” European Commission, Tech. Rep., Apr.
2007.
[27] R. J. Rabelo, S. Gusmeroli, C. Arana, and T. Nagellen,
“The
ECOLEAD
ICT
infrastructure
for
collaborative
networked organizations,” in Network-Centric Collaboration
and Supporting Frameworks. IFIP TC 5 WG 5.5, Seventh
IFIP Working Conference on Virtual Enterprises, vol. 224.
Helsinki, Finland: Springer, Sep. 2006, pp. 451–460. [Online].
Available: http://dx.doi.org/10.1007/978-0-387-38269-2 47
[28] S. S. Msanjila and H. Afsarmanesh, “HICI: An approach
for identifying trust elements — the case of technological
trust perspective in VBEs,” in Proceedings of the Second
International Conference on Availability, Reliability and
Security (ARES 2007).
Vienna, Austria: IEEE Computer
Society,
Apr.
2007,
pp.
757–764.
[Online].
Available:
http://dx.doi.org/10.1109/ARES.2007.94
[29] S. Ruohomaa and L. Kutvonen, “Making multi-dimensional
trust decisions on inter-enterprise collaborations,” in Proceed-
ings of the Third International Conference on Availability,
Security and Reliability (ARES 2008).
Barcelona, Spain:
IEEE Computer Society, Mar. 2008, pp. 873–880. [Online].
Available: http://dx.doi.org/10.1109/ARES.2007.123
[30] X. Zhang and Q. Zhang, “Online trust forming mechanism:
approaches and an integrated model,” in Proceedings of
the 7th international conference on Electronic commerce,
ser. ICEC ’05.
Xi’an, China: ACM, Aug. 2005, pp.
201–209.
[Online].
Available:
http://doi.acm.org/10.1145/
1089551.1089591
[31] R. Fung and M. Lee, “EC-Trust (Trust in electronic
commerce): Exploring the antecedent factors,” in Americas
Conference on Information Systems (AMCIS) Proceedings,
Milwaukee,
Wisconsin,
USA,
Aug.
1999,
paper
179.
[Online]. Available: http://aisel.aisnet.org/amcis1999/179
[32] T. Deelmann and P. Loos, “Trust economy: Aspects of repu-
tation and trust building for SMEs in e-business,” in Americas
Conference on Information Systems (AMCIS) Proceedings,
Dallas, Texas, USA, Aug. 2002, paper 302.
[33] D.
L.
Shapiro,
B.
H.
Sheppard,
and
L.
Cheraskin,
“Business on a handshake,” Negotiation Journal, vol. 8,
no.
4,
pp.
365–377,
Oct.
1992.
[Online].
Available:
http://dx.doi.org/10.1111/j.1571-9979.1992.tb00679.x
[34] S. Ba, “Establishing online trust through a community
responsibility system,” Decision Support Systems, vol. 31,
no. 3, pp. 323 – 336, 2001. [Online]. Available: http://www.
sciencedirect.com/science/article/pii/S0167923600001445
[35] E. Kim and S. Tadisina, “Customers’ initial trust in e-
businesses: How to measure customers’ initial trust,” in
Americas Conference on Information Systems (AMCIS) Pro-
ceedings, Tampa, Florida, USA, Aug. 2003, paper 5.
[36] D. H. Mcknight, V. Choudhury, and C. Kacmar, “Trust in
e-commerce vendors: a two-stage model,” in International
Conference on Information Systems (ICIS’00), Brisbane,
Queensland, Australia, Dec. 2000, pp. 532–536. [Online].
Available: http://dl.acm.org/citation.cfm?id=359640.359807
[37] J. Salo and H. Karjaluoto, “A conceptual model of trust in
the online environment,” Online Information Review, vol. 31,
no. 5, pp. 604–621, 2007.
[38] R. C. Mayer, J. H. Davis, and F. D. Schoorman, “An
integrative model of organizational trust,” The Academy of
Management Review, vol. 20, no. 3, pp. 709–734, July 1995.
[39] L. L. Cummings, D. H. McKnight, and N. L. Chervany,
“Initial trust formation in new organizational relationships,”
The Academy of Management Review, vol. 23, no. 3, pp. 473–
490, July 1998.
[40] J. R. Dunn and M. E. Schweitzer, “Feeling and believing:
The inﬂuence of emotion on trust,” Journal of Personality
and Social Psychology, vol. 88, no. 5, pp. 736–748, May
2005. [Online]. Available: http://psycnet.apa.org/doi/10.1037/
0022-3514.88.5.736
[41] F. D. Schoorman, R. C. Mayer, and J. H. Davis, “An integra-
tive model of organizational trust: Past, present, and future,”
Academy of Management Review, vol. 32, no. 2, pp. 344–354,
2007.
[42] D. H. McKnight and N. L. Chervany, “The meanings
of trust,” University of Minnesota, MIS Research Center,
Tech. Rep., 1996. [Online]. Available: http://misrc.umn.edu/
workingpapers/fullPapers/1996/9604 040100.pdf

552
International Journal on Advances in Intelligent Systems, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/intelligent_systems/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[43] P. A. Pavlou, “Consumer acceptance of electronic commerce:
Integrating trust and risk with the technology acceptance
model,” International Journal of Electronic Commerce,
vol. 7, no. 3, pp. 101–134, Apr. 2003. [Online]. Available:
http://dl.acm.org/citation.cfm?id=1288216.1288221
[44] J. Nielsen, Usability Engineering.
Boston: M.A. Academic
Press, 1993.
[45] G. H¨aubl and V. Trifts, “Consumer decision making in
online shopping environments: The effects of interactive
decision aids,” Marketing Science, vol. 19, no. 1, pp. 4–21,
2000. [Online]. Available: http://dx.doi.org/10.1287/mksc.19.
1.4.15178
[46] J. M. Weber, D. Malhotra, and J. K. Murnighan, “Normal
acts of irrational trust: Motivated attributions and the trust
development process,” Research in Organizational Behavior,
vol. 26, pp. 75–101, 2004, an Annual Series of Analytical
Essays and Critical Reviews. [Online]. Available: http://www.
sciencedirect.com/science/article/pii/S0191308504260038
[47] L. Kutvonen, T. Ruokolainen, and J. Metso, “Interoperability
middleware for federated business services in web-Pilarcos,”
International Journal of Enterprise Information Systems,
Special issue on Interoperability of Enterprise Systems and
Applications, vol. 3, no. 1, pp. 1–21, Jan. 2007. [Online].
Available: http://www.cs.helsinki.ﬁ/group/cinco/publications/
public pdfs/kutvonen06interop.pdf
[48] P.
Kaur,
“Users’
trust
decisions
on
inter-enterprise
collaborations,” Master’s thesis, Aalto University, Computer
Science and Engineering; Tech. Rep, University of Helsinki
Department of Computer Science, Sep. 2011. [Online].
Available: http://www.cs.helsinki.ﬁ/group/cinco/publications/
public pdfs/kaur11msthesis.pdf
[49] L.
Kutvonen,
J.
Metso,
and
S.
Ruohomaa,
“From
trading
to
eCommunity
management:
Responding
to
social and contractual challenges,” Information Systems
Frontiers (ISF) - Special Issue on Enterprise Services
Computing:
Evolution
and
Challenges,
vol.
9,
no.
2–3,
pp.
181–194,
Jul.
2007.
[Online].
Available:
http://dx.doi.org/10.1007/s10796-007-9031-x
[50] L. Kutvonen, S. Ruohomaa, and J. Metso, “Automating
decisions for inter-enterprise collaboration management,”
in Pervasive Collaborative Networks. IFIP TC 5 WG
5.5
Ninth
Working
Conference
on
Virtual
Enterprises,
September 8–10, 2008, Poznan, Poland, ser. IFIP, no. 283.
Poznan, Poland: Springer, Sep. 2008, pp. 127–134. [Online].
Available: http://www.cs.helsinki.ﬁ/group/cinco/publications/
public pdfs/kutvonen08automating.pdf
[51] S. Crompton, M. Wilson, A. Arenas, L. Schubert, D. I.
Cojocarasu,
J.
Hu,
and
P.
Robinson,
“The
TrustCoM
general
virtual
organization
agreement
component,”
in
UK e-Science All Hands Meeting, UK Natl e-Science
Centre, Nottingham, UK, Sep. 2007. [Online]. Available:
http://www.allhands.org.uk/2007/proceedings/papers/771.pdf
[52] R. Ratti, M. del Mar Rodrigo Castro, C. A. Ferrandiz,
S. Mores, R. Rabelo, R. J. Tramontin Junior, and P. Gibert,
“Deliverable D61.1c ICT-I Reference Framework (version
3),” European Commission, Tech. Rep., Apr. 2007.
[53] T. Ruokolainen, S. Ruohomaa, and L. Kutvonen, “Solving
service ecosystem governance,” in Proceedings of the 15th
IEEE International EDOC Conference Workshops. Helsinki,
Finland: IEEE Computer Society, Aug. 2011, pp. 18–25.
[Online]. Available: http://dx.doi.org/10.1109/EDOCW.2011.
43
[54] K. Karvonen, L. Cardholm, and S. Karlsson, “Designing
trust for a universal audience: A multicultural study on the
formation of trust in the Internet in the Nordic countries,”
in Proceedings of the First International Conference on
Universal Access in HCI (UAHCI’2001), New Orleans, LA,
USA, Aug. 2001. [Online]. Available: http://www.tml.hut.ﬁ/
Research/TeSSA/Papers/Karvonen/designing-trust.pdf
[55] Y. Shen, P. Nurmi, S. Ruohomaa, and M. Lehtim¨aki,
“D6.3.2.8: Understanding widget downloading preferences,”
TIVIT, ICT SHOK Future Internet Programme, Tech. Rep.,
Mar. 2011. [Online]. Available: http://www.futureinternet.ﬁ/
publications/Deliverable D6.3.2.8.pdf
[56] I. Vessey and D. Galletta, “Cognitive ﬁt: An empirical study
of information acquisition,” Information Systems Research,
vol.
2,
no.
1,
pp.
63–84,
1991.
[Online].
Available:
http://isr.journal.informs.org/cgi/content/abstract/2/1/63
[57] L. Oshlyansky, P. Cairns, and H. Thimbleby, “Validating the
uniﬁed theory of acceptance and use of technology (UTAUT)
tool cross-culturally,” in Proceedings of the 21st British
HCI Group Annual Conference on People and Computers:
HCI...but not as we know it - Volume 2, ser. BCS-HCI ’07.
Swinton, UK: British Computer Society, Sep. 2007, pp. 83–
86.
[58] J. Sweller, “Cognitive load during problem solving: Effects
on learning,” Cognitive Science, vol. 12, no. 2, pp. 257
– 285, 1988. [Online]. Available: http://www.sciencedirect.
com/science/article/pii/0364021388900237

