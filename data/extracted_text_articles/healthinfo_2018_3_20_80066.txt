Evaluating Real-Time Hand Gesture Recognition for Automotive Applications in 
Elderly Population: Cognitive Load, User Experience and Usability Degree 
 
 
Diana Trojaniello, Alessia Cristiano, Alberto Sanna 
Center for Advanced Technology and Wellbeing 
Ospedale San Raffaele 
Milan, Italy 
E-mail: trojaniello.diana@hsr.it, cristiano.alessia@hsr.it, 
sanna.alberto@hsr.it   
 
 
 
 
 
 
Stela Musteata 
Division of Medical Sciences 
University of Victoria 
Victoria, Canada 
E-mail: stella.musteata@gmail.com 
  
 
 
Abstract— Driving a car represents a crucial aspect to keep 
independence, social life and wellbeing for elderly people. Due 
to the age-related cognitive decline, solutions aimed to help 
older adults to interact easily with the vehicle and to control 
the car sub-systems are required. Thanks to the technology 
advancement, a number of interaction modalities are available, 
including touch, voice and, most recently, gesture control. 
Systems based on gesture control allow the subjects to interact 
with the vehicle sub-systems (i.e., vehicle navigation tool) 
through easy gestures, thus avoiding the subjects to be 
distracted while driving. This represents an interesting feature 
for elderly people who often show limitations in attention. On 
the other hand, learning the use of new technologies, such as a 
new interaction modality, as for the gesture control based 
systems, could represent a critical issue, in particular for 
elderly people who often suffer of memory problems.  The 
current study aims to investigate the usability, user experience 
and mental workload associated with the first usage of a new 
developed prototype of an in-vehicle system, based on gesture 
control, for elderly people. Results showed that a low usability 
degree, as well as a quite high mental workload, is associated to 
the usage of the proposed prototype. The inclusion of other 
interaction modalities, such as voice and touch controls, as well 
as the improvement in the gesture control system, i.e., by 
reducing the number of gestures needed, is required in future 
releases of the developed prototype.  
Keywords- Ageing; Elderly; Mobility; HMI; Human 
Machine Interaction; Gesture control; Usability; User experience 
I. 
 INTRODUCTION 
The European population estimated in 2017 is about 
511.8 million people, and 19% are older adults aged 65 and 
over (Eurostat). The life expectancy increase has brought 
great revolutions in the social and cultural spheres, and new 
challenges in relation to the health and well-being of older 
population.  
Cognitive decline and brain aging is one of the older 
adult’s challenges. Some seniors maintain excellent 
cognitive functions up to 70 or 80 years, others show signs of 
cognitive decline already in their 60s. Attention, processing 
speed [1] and episodic memory [2] represent the mostly 
aging 
affected 
cognitive 
functions 
with 
dramatic 
consequences on the daily tasks performances, such as 
driving [3]–[5]. A prerequisite for driving is the integration 
of high-level cognitive functions with perception and motor 
functions. The cognitive functions involved in driving are 
divided attention, processing speed, visual perception, short-
term memory, working memory and episodic, semantic and 
procedural memory  [6]–[8]. The age-related decline of these 
abilities in older drivers leads to difficulties of handling 
trafficked intersections and high speed roads, noticing the 
nearby upstream signals, negotiating wide multi-lane 
carriageways, etc. [7]. For example, due to the age-related 
decline of cognitive abilities, many of European seniors 
consider driving a car a stressful task. Furthermore, the UK 
Department for Transport research suggests that drivers aged 
between 60 to 69 had in average 18.8 crashes casualties per 
billion miles driven [9]. This number significantly increases 
to 56.7 casualties for drivers older than 70 years. 
Reaching the grocery shops, the neighborhood facilities, 
or participating in community social events constitute 
essential needs for an older adult; therefore, the main 
challenge of nowadays society is to preserve the driving 
ability of older population. Maintaining a good mobility is 
vital and highlights the importance of developing innovative 
solutions that will help the ageing population to feel 
confident in driving safely. In this context, the design of 
future in-vehicle interfaces should take into account older 
drivers' needs and capabilities by increasing the safety and 
the comfort of elderly people. Intelligent Transport Systems, 
including in-vehicle navigation systems (i.e., tools that use 
geographical information to give feedback and support to 
drivers) can provide older drivers with increased confidence, 
and potentially deter them from taking risky behaviors [10]. 
In addition, new human-machine interfaces should be more 
accessible without requiring long periods of learning and 
adaptation. They should also provide more natural human-
machine interaction avoiding overloading the mental abilities 
of older drivers. 
As described in Myron Krueger’s book Artificial Reality 
(1993), “natural interaction” means voice and gesture [11]. 
The voice control of in-vehicle systems is seen as an 
extremely desirable feature and potentially safe application 
for older adults, allowing to drive without requiring visual 
attention [12]. Similarly, in the last years, hand gesture 
control has gained popularity due to the potential reduction 
36
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-675-0
HEALTHINFO 2018 : The Third International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

of the visual load and visual distractions associated to its 
usage while driving. In fact, systems based on gesture 
control are able to distinguish hand movements while giving 
correspondent reaction and vocal feedback (i.e., answer the 
phone, send messages, listen the desired music) without 
diverting the attention from driving. Furthermore, gesture 
control does not limit the autonomy and safety of the driver, 
while reducing the errors in driving.  
An innovative prototype of Human Machine Interface 
(HMI) system based on gesture control has been realized 
within the H2020 European project “SILVERSTREAM”. It 
has been specifically designed to help elderly people while 
driving, avoiding unambiguous and problematic interactions.  
The objective of the present study was to investigate 
various aspects of the proposed HMI system by assessing its 
suitability for the elderly people through an evaluation of 
user expectation, user experience and usability, as well as an 
assessment of the mental workload associated with its usage. 
The paper is organized as follows. An overview of the 
system, including the hand tracking device, as well as the 
sample population and acquisition protocol description are 
reported in section II. While section III provides the 
experimental results, the discussion has been provided in 
section IV. Finally, the conclusion and possible future works 
are reported in section V. 
II. 
MATERIALS AND METHODS 
In the following sections an overview of the system as well 
as of the sample population and experimental activities 
along with the data analysis plan has been provided.    
A. System 
The 
tested 
system 
consisted 
of 
the 
following 
components: 
 
Hand tracking device (Leap motion controller, Leap 
Motion, Inc., USA): a small USB peripheral device 
which use two monochromatic IR cameras and three 
infrared LEDs to track the hand gestures and recognize 
the fingers movements (Figure 1a); 
 
Laptop 
(Notebook 
F302LJ, 
ASUS) 
where 
the 
developed software for vehicle management (i.e., home, 
settings, radio, car navigation, etc.) has been installed 
(Figure 1b); 
 
Monitor (FA1013/S 10.1 inches, Lilliput) (Figure 1c); 
 
3D mouse (Space Mouse Compact, 3Dconnexion, 
Germany), which includes an internal 6 degrees of 
freedom sensor allowing to zoom and rotate in an 
intuitive manner thanks to simple movements. (Figure 
1d). 
The above-mentioned components have been hardware 
connected and represent the tested “HMI system”. 
 
B. Hand tracking device  
The hand tracking device (Leap motion sensor) 
represents the core of the tested system since it allows the 
software remote control by tracking the hands and fingers 
movements (i.e., “gestures”). The device consists of two IR 
cameras and three infrared LEDs directed along the y-axis 
with a field of view of about 150 degrees (Figure 2). 
 
 
 
 
(a) 
(b) 
 
 
(c) 
(d) 
Figure 1. System components 
 
 
Figure 2. Leap motion sensor coordinate system 
The effective range covered is from approximately 25 to 
600 millimetres above the device. Position of hands and 
fingers is provided thanks to a model of human hand 
included in the linked proprietary software. The software 
recognises certain movement patterns (i.e., gestures), which 
indicate the user’s intention or command. The recognized 
gestures could be clustered in the following subclasses: 
 
Circle Gesture (Figure 3a) 
 
Swipe Gesture (Figure 3b) 
 
Back Gesture (Figure 3c) 
 
Grab Gesture (Figure 3d) 
 
Hand Key Tap Gesture (Figure 3e) 
 
 
 
(a) 
(b) 
(c) 
 
 
 
(d) 
(e) 
 
Figure 3. Recognized gestures 
C. Sample Population 
A sample of thirty subjects aged over 65 years old took 
part to the study. Subjects were recruited from a previous 
clinical study (“Epidemiological study on a sample of elderly 
subjects with subjective complaints of memory”) approved 
37
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-675-0
HEALTHINFO 2018 : The Third International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

by the Ethics Committee of San Raffaele Hospital (HSR), in 
Milan. All participants provided informed written consent, 
edited in accordance to the Declaration of Helsinki [13].   
D. Experimental Setup 
Subjects have been invited at the HSR facilities to take 
part to the experiment. A room, suitably furnished with the 
HMI system, has been chosen as scenario for the 
experiments. A large digital screen has been used during the 
experiments to show the gestures to the participants and the 
requested tasks (Figure 4).  
       
       
Figure 4. Experimental setup 
Two researchers, i.e., testers (a neuropsychologist and a 
bioengineer) were involved in the experiments. 
E. Acquisition protocol 
Before starting the experiment, participants have been 
interviewed through “Preliminary Interview” by the 
neuropsychologist regarding their level of confidence in 
using technological devices, in both general and automotive 
context. Then, the following experimental protocol (lasting 
about 1h and half) has been carried out for each participant:  
 
Cognitive assessment through the Mini Mental State 
Examination (MMSE); 
 
Demonstrative video illustrating the main features of 
the HMI system (i.e., setting, gestures, etc.);  
 
Subjective expectations assessment through the user 
experience evaluation questionnaire (SUXESi) [14], to 
assess the user expectation about the proposed system;  
 
Familiarization period in which participant was 
invited to freely use the HMI system; 
 
Usability test where the participant was asked to carry 
out a number of tasks commonly performed in a vehicle 
(e.g. selection of an audio track through the HMI 
system or regulating the temperature) through the 
gestures shown in the  demonstrative video and 
reported in Figure 3;  
 
Subjective usability assessment through the System 
Usability Scale (SUS) questionnaire [15], [16], to 
evaluate the post-test perceived usability of the system; 
 
Subjective 
experience 
assessment 
through 
the 
SUXESf questionnaire, to assess the user experience 
after the system usage. 
 
Mental workload assessment through the NASA [17] 
Task Load Index (TLX) questionnaire. 
Finally, the neuropsychologist interviewed the participant 
by means of “Final Interview” to collect his/her impressions 
about the tested system focusing in particular on: ease of 
use, workload associated and main difficulties found. 
F. Methods 
All the above-mentioned surveys have been already 
validated and published in literature and represent gold 
standard methodologies for assessing the following aspects 
of interest: cognitive functions (MMSE), users’ expectations 
and users experience (SUXES), the system usability (SUS) 
and mental workload (NASA) associated to the HMI system 
use.  
The usability test has been performed according to the 
standard guidelines [18], which requires the participant to 
perform a number of task using the tested system. During 
the test, the tester observed the participant without formulate 
any question while collecting some quantitative variables 
(i.e., required time for the tasks, number of attempts and 
number of errors). These variables were useful for the 
objective evaluation of usability of the HMI system. 
G. Data analysis 
1) Preliminary Interview 
The general knowledge of the technology along with the 
confidence in the usage of the three more common 
interaction modalities in automotive context (voice, touch 
and gesture) have been investigated for each subject. A 
frequency analysis has been performed considering the 
answers obtained.  
2) Cognitive assessment 
Each participant’s MMSE outcome score was corrected 
for age and education and compared with the pathological 
cut-off of 23.60/30.  
3) User expectation and user experience 
According to [14], for each subject, two different scores 
associated to the user expectations (the “desired” and the 
“accepted” level) have been identified through the SUXESi. 
Instead, a further score associated to the user experience 
(the “perceived” level) has been computed through the 
SUXESf. Based on such scores, two different measures have 
been computed: 
 
Measure of Service Superiority (MSS): difference 
between the perceived level and the desired level; 
 
Measure of Service Adequacy (MSA): difference 
between the perceived level and the accepted level. 
Those measures allowed the estimation of the gap between 
expectation and experience. If the experience is in the range 
of expectation, MSS value is negative and MSA is positive. 
4) Usability of the system  
According to the level of agreement selected for each 
statement of the SUS questionnaire, a SUS score has been 
computed for each participant. According to [15], [16] 
38
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-675-0
HEALTHINFO 2018 : The Third International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

depending on whether the reported SUS score was greater or 
smaller than 68, the system was defined usable or not.  
In 
addition, 
in 
order 
to 
evaluate 
the 
subjects 
performances in using the gesture control, quantitative 
scores (i.e., objective scores) collected during the usability 
test (number of errors) have been analyzed for each gesture.   
5) Mental workload 
An overall score of workload in a 100-point scale based 
on weighted average of six sub-scales (Mental Request, 
Physical Request, Temporal Request, Performance, Effort 
and Frustration) has been obtained for each subject.  
III. 
RESULTS 
In the following, the main results of the study have been 
provided. 
A. Sample Population 
Subjects’ characteristics (age and schooling) are reported 
in Table I. 
TABLE I.  
PARTICIPANTS’ AGE AND SCHOOLING 
Gender 
# 
Participants’ characteristics 
Age [years] 
Schooling [years] 
Female 
17 
70±4 
12±3 
Male 
13 
73±3 
14±3 
 
B. Preliminary Interview 
Subjects’ knowledge of the technology (clustered in 
three main categories: poor, medium and high according to 
the self-reporting score) has been shown in Table II.  
TABLE II.  
KNOWLEDGE OF TECHNOLOGY  
Knowledge of 
technology 
High 
Medium 
Poor 
40% 
33% 
27% 
 
Subjects’ knowledge of the interaction modalities 
(touch, voice and gesture control) has been reported in 
Figure 5. 
 
 
Figure 5. Knowledge of interaction modalities 
Only one subject reported the knowledge of gesture 
control, while none of them had ever had the chance to try 
it.  
C. Cognitive assessment 
All the subjects reported no cognitive impairment 
(MMSE<23.60). The subjects reported the following scores: 
MMSE=26 (n=1); MMSE=27 (n=3); MMSE=28 (n=7); 
MMSE=29 (n=7); MMSE=30 (n=12). 
D. User expectation and user experience 
The values of MSS and MSA computed for each subject 
are reported in Figure 6. 
 
Figure 6. Measure of service superiority (MSS) and Measure of 
service adequacy (MSA) 
As shown in the figure, for all the subjects, except two, 
the perceived level was lower than the desired one (MSS<0) 
but, for ten of them, higher than the accepted one (MSA>0). 
The experiences resulted to be in the range of expectations 
(MSS values negative and MSA values positive) for eight 
subjects. 
E. Usability of the HMI system  
The SUS scores are shown in Table III. 
TABLE III.  
SUS SCORES 
SUS score 
Participants 
> 68  
27 % 
≤ 68  
73 % 
 
According to the table, only 27% of subjects reported a 
SUS score >68 meaning that the system was judged usable. 
The Acceptability level has been reported in Table IV. 
TABLE IV.  
LEVEL OF ACCEPTABILITY ACCORDING TO THE SUS SCORE 
Acceptability 
Range 
#Subjects 
Not acceptable 
0-50 
11 
Marginal-low 
50-62 
9 
Marginal-high 
62-70 
2 
Acceptable 
70-100 
7 
 
39
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-675-0
HEALTHINFO 2018 : The Third International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

The usability of the system has been also analyzed 
considering the number of errors reported for each gesture 
during the usability test, as reported in Table V.  
TABLE V.  
NUMBER OF ERRORS DURING THE USABILITY TEST 
Gesture 
Requested 
repetitions (#) 
Errors (#) 
mean 
std 
Circle Gesture  
60 
3 
± 9 
Swipe  
600 
4 
± 5 
 Back 
180 
8 
± 10 
Grab  
60 
1 
± 2 
Hand Key Tap  
390 
4 
± 5 
 
The higher number of repetitions for some of the 
gestures (Swipe, Hand Key Tap and Back) are related to the 
tasks flow (i.e., made a phone call, select one music track, 
etc.).  
F. Mental workload 
The overall workload has been computed for each 
subject and reported in Figure 7 together with a box and 
whisker to graphically summarize the data. 
 
 
Figure 7.  NASA TLX score 
The workload experienced by participants for each 
dimension investigated by NASA TLX questionnaire has 
been shown in Figure 8.  
 
 
Figure 8. NASA TLX raw scores 
The NASA dimension characterized by a higher 
workload resulted to be the mental one. 
G. Final Interview 
Subjects’ impressions about the ease of use of the HMI 
system, the associated workload and the difficulties found 
during its use have been reported in Table VI. 
TABLE VI.  
PARTICIPANTS’ FEEDBACK 
 
Ease 
of 
use 
Workload 
Difficulty 
 
Easy 
Physical 
Cognitive 
Memory 
Association 
Yes 
13 % 
23 % 
63 % 
23 % 
20 % 
No 
87 % 
77 % 
37 % 
77 % 
80 % 
 
Subjects reported a low perceived ease of use (87%) and 
cognitive effort has been noticed (63%). Instead, only few 
subjects reported high physical workload (23%) and 
memory  (23%) or association (20%) difficulties.  
IV. 
DISCUSSIONS 
The purpose of this work was to verify the 
appropriateness in terms of user experience and usability of 
the proposed HMI system to the elderly specific needs.  
All subjects reported good cognitive performances on 
MMSE test. Most of them (73%) considered the HMI 
system not usable and their experience was below the range 
of expectations while the 63% of participants complained 
the cognitive workload needed to accomplish the tasks 
required during the test. Moreover, most participants (87%) 
reported that the HMI system was very difficult to learn 
even if only a small part of them declared, at the end of the 
test, to have experienced memory (23%) and association 
problems (20%). It is clear that such problems can lead to a 
lower accuracy of gestures execution, which consequently 
appears in negative emotions, as irritation and frustration, 
during the interaction with the system.  
The advantage of using a gesture control-based system 
in automotive context does not seem to be confirmed by 
participants: indeed, the gestures have not been so 
assimilated to allow their execution without looking at the 
screen. A proper learning appears therefore fundamental to 
ensure a better experience with the proposed system and it 
can be done simplifying the most critical gestures as the 
back one, as resulted from the usability testing and, at the 
same time, providing more time to make the elderly more 
familiar with this new kind of technology.  
 
V. 
CONCLUSIONS 
The results obtained in the present study suggested that 
the proposed HMI system, based on gesture control, is 
difficult and not well perceived by older population. In 
addition, long time to ensure a correct and complete 
learning for properly using the system resulted to be needed. 
However, it is important to highlight that the present 
generation of elderly has not so much familiarity with the 
technology contrary to the future one. Therefore, the 
40
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-675-0
HEALTHINFO 2018 : The Third International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

integration with the best-known touch and voice controls, as 
well as an accomplished learning leading to an automatic 
execution of gestures should be provided to make the tested 
HMI system a useful tool for the forthcoming generations of 
elderly.  
ACKNOWLEDGMENT 
The research leading to these results has received funding 
from the European Union’s Horizon 2020 research and 
innovation programme under grant agreement No 653861 – 
SILVERSTREAM.  
REFERENCES 
[1] 
T. a Salthouse, “Aging associations: influence of speed on 
adult age differences in associative learning.,” J. Exp. 
Psychol. Learn. Mem. Cogn., vol. 20, no. 2, pp. 1486–
1503, 1994. 
[2] 
X. Y. Li et al., “Age- and brain region-specific changes of 
glucose metabolic disorder, learning, and memory 
dysfunction in early alzheimer’s disease assessed in 
APP/PS1 transgenic mice using18F-FDG-PET,” Int. J. 
Mol. Sci., vol. 17, no. 10, 2016. 
[3] 
C. Bottari, C. Dassa, C. Rainville, and É. Dutil, “The 
criterion-related validity of the IADL Profile with 
measures of executive functions, indices of trauma 
severity and sociodemographic characteristics,” Brain 
Inj., vol. 23, no. 4, pp. 322–335, 2009. 
[4] 
L. C. McGuire, E. S. Ford, and U. A. Ajani, “The impact 
of cognitive functioning on mortality and the development 
of functional disability in older adults with diabetes: The 
second longitudinal study on aging,” BMC Geriatr., vol. 
6, pp. 1–7, 2006. 
[5] 
P. Missotten et al., “Relationship between quality of life 
and cognitive decline in dementia,” Dement. Geriatr. 
Cogn. Disord., vol. 25, no. 6, pp. 564–572, 2008. 
[6] 
S. Bao and L. N. Boyle, “Age-related differences in visual 
scanning at median-divided highway intersections in rural 
areas,” Accid. Anal. Prev., vol. 41, no. 1, pp. 146–152, 
2009. 
[7] 
D. R. Mayhew, H. M. Simpson, and S. A. Ferguson, 
“Collisions involving senior drivers: High-risk conditions 
and locations,” Traffic Inj. Prev., vol. 7, no. 2, pp. 117–
124, 2006. 
[8] 
J. S. R. Leversen, B. Hopkins, and H. Sigmundsson, 
“Ageing and driving: Examining the effects of visual 
processing demands,” Transp. Res. Part F Traffic 
Psychol. Behav., vol. 17, pp. 1–4, 2013. 
[9] 
N. Korner-Bitensky, A. Kua, C. von Zweck, and K. Van 
Benthem, “Older driver retraining: An updated systematic 
review of evidence of effectiveness,” J. Safety Res., vol. 
40, no. 2, pp. 105–111, 2009. 
[10] 
C. Emmerson, W. Guo, P. Blethe, A. Namdeo, and S. 
Edwards, “Fork in the road: In-vehicle navigation systems 
and older drivers,” Transp. Res. Part F Traffic Psychol. 
Behav., vol. 21, pp. 173–180, 2013. 
[11] 
M. W. Krueger, “An Easy Entry Artificial Reality,” 1993. 
[12] 
J. E. Alvarez, I., López-De-Ipiña, M. K., & Gilbert, “The 
voice user help, a smart vehicle assistant for the elderly,” 
Lect. Notes Comput. Sci. (including Subser. Lect. Notes 
Artif. Intell. Lect. Notes Bioinformatics)., 2012. 
[13] 
World Medical Association, “World Medical Association 
Declaration of Helsinki,” Bull. world Heal. Organ., vol. 
79, no. 4, pp. 373–374, 2001. 
[14] 
M. Turunen, J. Hakulinen,  a Melto, T. Heimonen, T. 
Laivo, and J. S. Hella, “- User Experience Evaluation 
Method for Spoken and Multimodal Interaction,” Proc., 
no. January 2016, 2009. 
[15] 
A. Bangor, P. Kortum, and J. Miller, “Determining what 
individual SUS scores mean: Adding an adjective rating 
scale,” J. usability Stud., vol. 4, no. 3, pp. 114–123, 2009. 
[16] 
J. Brooke, “SUS-A Quick and Dirty Usability Scale.” 
[17] 
Nasa, “NASA Task Load Index,” Hum. Ment. Workload, 
vol. 1, no. 6, pp. 21–21, 2006. 
[18] 
J. Nielsen and T. K. Landauer, “A mathematical model of 
the finding of usability problems,” Proc. SIGCHI Conf. 
Hum. factors Comput. Syst. - CHI ’93, pp. 206–213, 1993. 
 
 
 
41
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-675-0
HEALTHINFO 2018 : The Third International Conference on Informatics and Assistive Technologies for Health-Care, Medical Support and Wellbeing

