Hyponym Extraction from the Web
based on Property Inheritance of Text and Image Features
Shun Hattori
College of Information and Systems
Muroran Institute of Technology
27-1 Mizumoto-cho, Muroran, Hokkaido 050-8585, Japan
Email: hattori@csse.muroran-it.ac.jp
Abstract—Concept hierarchy knowledge, such as hyponymy
and meronymy, is very important for various Natural Language
Processing systems. While WordNet and Wikipedia are being
manually constructed and maintained as lexical ontologies,
many researchers have tackled how to extract concept hier-
archies from very large corpora of text documents, such as the
Web, not manually, but automatically. However, their methods
are mostly based on lexico-syntactic patterns as not necessary
but sufﬁcient conditions of hyponymy and meronymy, so they
can achieve high precision but low recall when using stricter
patterns or they can achieve high recall but low precision
when using looser patterns. Therefore, we need necessary
conditions of hyponymy and meronymy to achieve high recall
and not low precision. The previous papers have assumed
“Property Inheritance” from a target concept to its hyponyms
and/or “Property Aggregation” from its hyponyms to the target
concept to be necessary and sufﬁcient conditions of hyponymy,
and proposed several methods to extract hyponymy relations
from the Web, based on property inheritance and/or property
aggregation of text features such as meronyms and behavior.
This paper proposes a method to acquire hyponymy relations
from the Web, based on property inheritance of not only text
features, but also image features for each conceptual word.
Keywords-hyponymy; meronymy; concept hierarchy; Web min-
ing; image analysis; property inheritance; typical image.
I. INTRODUCTION
Concept
hierarchies,
such
as
hyponymy
(is-a)
and
meronymy (has-a) relations, are very fundamental for vari-
ous Natural Language Processing (NLP) systems. For exam-
ple, query expansion in information retrieval [1–4] or image
retrieval [5], question answering [6], machine translation,
object information extraction by text mining [7], Sense-
based Object-name Search (SOS) [8], etc. Our appearance
information extraction [7] is based on the heuristics that
an appearance description about a target object-name (e.g,
“kingﬁsher”) often has a pair of an appearance descriptor
and its hypernym (e.g., “blue bird” and “beautiful bird”) or
its meronym (e.g., “blue wings” and “long beak”).
While WordNet [9] and Wikipedia [10] are being man-
ually constructed and maintained as lexical ontologies at
the cost of much time and effort, many researchers have
tackled how to extract concept hierarchies from very large
corpora of text documents, such as the Web, not manu-
ally, but automatically [11–14]. However, their methods are
mostly based on lexico-syntactic patterns as sufﬁcient but
not necessary conditions of concept hierarchies. Therefore,
they can achieve high precision but low recall when using
stricter patterns (e.g., “x such as y” and “y is a kind of x”)
or they can achieve high recall but low precision when using
looser patterns (e.g., “y is a/an x”).
To achieve high recall and not low precision, our previous
works [15–18] have assumed “Property Inheritance” from a
target concept to its hyponyms (i.e., subordinate concepts
for the target concept) and/or “Property Aggregation” from
its hyponyms to the target concept to be necessary and
sufﬁcient conditions of hyponymy, and proposed several
methods to extract hyponymy relations from the Web by
text mining techniques, based on property inheritance and/or
property aggregation of text features such as meronyms and
behavior-words. The former assumption is to utilize the other
semantic relations surrounding the subordinate (hyponymy)
relation between a target concept and its hyponym candidate,
i.e., superordinate relationships (hypernymy) and coordinate
relationships (including synonymy and antonymy), and to
improve a weighting of hyponymy extraction by using mul-
tiple property inheritances not only from the target concept
to its hyponym candidate, but also between the other pairs
of concepts (e.g., from a hypernym of the target concept
to its hyponym candidate and/or from the target concept to
a coordinate concept of its hyponym candidate). The latter
assumption is to improve a weighting of property extraction
by using property aggregation to each target concept from
its typical hyponyms.
To make our previous method more robust, this paper
utilizes not only Web text, but also Web images, and
proposes a method to acquire hyponymy relations from the
Web, based on property inheritance of not only text features,
but also image features for each conceptual word.
The remainder of the paper is organized as follows.
Section II proposes a method to extract hyponymy relations
from the Web, based on property inheritance of not only
text features, but also image features. Section III shows
some experimental results to validate the proposed method.
Finally, we conclude this paper in Section IV.
109
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-240-0
SEMAPRO 2012 : The Sixth International Conference on Advances in Semantic Processing

II. METHOD
This section introduces our previously published basic
method [15] to extract hyponymy relations from the Web by
using not only lexico-syntactic patterns with a target word
and its hyponym candidate as sufﬁcient but not necessary
conditions of hyponymy, but also “Property Inheritance” (of
text features such as meronyms and behavior-words) from
the target word to its hyponym candidate as their necessary
and sufﬁcient conditions. To make the basic method more
robust, this section proposes a method to acquire hyponymy
relations from the Web, based on property inheritance of not
only text features, but also typical image features for each
concept by using not only Web text, but also Web images.
Our methods for automatic hyponym extraction from the
Web are based on the following basic assumption of “Prop-
erty Inheritance”. Let C be the universal set of concepts
(conceptual words). This paper assumes that if and only
if a concept x ∈ C is a hypernym (superordinate) of a
concept y ∈ C, in other words, the concept y is a hyponym
(subordinate) of the concept x, then the set of properties
that the concept y has, P(y), completely includes the set of
properties that the concept x has, P(x), and the concept y
is not equal (equivalent) to the concept x.
isa(y, x) = 1 ⇔ P(y) ⊇ P(x) and y ̸= x,
P(c) = {p ∈ P | has(p, c) = 1},
where P stands for the universal set of properties and
has(p, c) ∈ {0, 1} indicates whether or not a concept c ∈ C
has a property p ∈ P,
has(p, c) =
{ 1
if a concept c has a property p,
0
otherwise.
In other words, if and only if a concept y is a hyponym of
a concept x, then the number of properties that both concepts
x and y share is equal to the number of properties that the
superordinate concept x has (and is less than the number of
properties that the subordinate concept y has).
isa(y, x) =







1 if
∑
p∈P
has(p, y) · has(p, x) =
∑
p∈P
has(p, x),
0 if
∑
p∈P
has(p, y) · has(p, x) <
∑
p∈P
has(p, x).
It is essential for automatic hyponym extraction from the
Web based on the above basic assumption to calculate the
binary value has(p, c) ∈ {0, 1} for any pair of a property
p ∈ P and a concept c ∈ C accurately. However, it is
not easy, and we can calculate only the continuous value
has∗(p, c) ∈ [0, 1] by using Web text and/or Web images
in this paper. Therefore, we suppose that the ratio of the
number of properties that a concept y ∈ C inherits from a
target concept x ∈ C to the number of properties that the
y
x
P(x)
P(y)
x: target concept            
y: hyponym candidate 
P(c): property vector
ß inherit ?
isa (y,x) = ?
. . .
. . .
Figure 1.
Hyponym Extraction based on Property Inheritance.
target concept x has,
∑
p∈P
has∗(p, y) · has∗(p, x)
∑
p∈P
has∗(p, x) · has∗(p, x)
,
can measure how suitable the concept y is for a hyponym
of the target concept x, isa∗(y, x), as an approximation
of whether or not the concept y is a hyponym of the
target concept x, isa(y, x). Then, the concept y would be
considered to be a hyponym of the target concept x when
the ratio is enough near to one (or greater than a threshold
value), while the concept y would be considered to be not a
hyponym of the target concept x when the ratio is not near
to one (or less than a threshold value).
When a target concept x ∈ C is given, our proposed
method based on property inheritance executes the following
four steps to extract its hyponyms from the Web. First, a
set of candidates for its hyponyms of the target concept x,
C(x) is collected from the Web as exhaustively as possible.
Second, the continuous value has-txt∗(p, c) or has-img∗(p, c)
for each pair of a property (text or image feature) p ∈ P
and a concept c ∈ C (the target concept x or its hyponym
candidate y ∈ C(x)) is calculated by analyzing not only
Web text, but also Web images. Last, the continuous value
isa-PI∗
n(y, x) for each pair of the target concept x and
its hyponym candidate y ∈ C(x) is calculated based on
property inheritance of the top n typical properties of the
target concept x to its hyponym candidate y, and then a set
of its top k hyponym candidates ordered by their weight
would be outputted to the users.
Step 1. Hyponym Candidate Collection
A set of hyponym candidates of the target concept x,
C(x) needs to be collected from the Web as exhaustively
as possible and enough precisely. If C(x) should be set to
110
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-240-0
SEMAPRO 2012 : The Sixth International Conference on Advances in Semantic Processing

the universal set of concepts, C, its recall could equal to 1.0
(the highest) but its precision would nearly equal to 0.0 (too
low). Meanwhile, if y ∈ C(x) is collected from some sort of
corpus of text documents by using too strict lexico-syntactic
pattern (e.g., “y is a kind of x”), its precision is enough high
but its recall is too low in most cases. Therefore, this paper
uses not too strict but enough strict lexico-syntactic pattern
of hyponymy to collect the set from the Web as exhaustively
as possible and enough precisely. Any noun phrase y whose
lexico-syntactic pattern “y is a/an x” exists at least once in
the title and/or summary text of the top 1000 search results
by submitting a phrase “is a/an x” as a query to Yahoo!
Web Search API [19] is inserted into C(x) as a hyponym
candidate of the target concept x.
Step 2. Text Property Extraction
In our previous papers [15–18], typical properties p such
as meronyms and behavior-words of each concept (the target
concept x or its hyponym candidate y ∈ C(x)) are extracted
from only Web text as precisely as possible by using an
enough strict lexico-syntactic pattern “c’s p” as a sufﬁcient
condition of meronymy. The continuous value has-txt∗(p, c)
of a text property p for each concept c is deﬁned as follows:
has-txt∗(p, c) := if(["c’s p"])
if(["c’s"])
∈ [0, 1],
where if([q]) stands for the number (frequency) of Web
images that meet a query condition q in such a corpus as
the Web. This paper calculates it by submitting each query
to Yahoo! Image Search API [20]. Note that has-txt∗(p, c)
is not a binary value {0, 1} but a continuous value [0, 1], so
it cannot indicate whether or not a concept c has a property
p but how typical the property p is of the concept c.
Step 3. Image Property Extraction
This paper considers not only Web text, but also Web
images, and extracts not only text features such as meronyms
and behavior-words, but also image features of typical
images as typical properties for each concept c. The top
100 search results by submitting a phrase “c” as a query to
Yahoo! Image Search API are reranked based on the Visu-
alRanking algorithm [21] to acquire more typical images of
the target concept c. The continuous value has-img∗(p, c) of
an image feature p for each concept c is deﬁned as follows
by using the top k (= 10) reranked images Ik(c):
has-img∗(p, c) :=
∑
i∈Ik(c)
prop(p, i)
k
∈ [0, 1],
where prop(p, i) stands for the proportion of a HSV or SIFT
[22] color-feature p in a Web image i.
Step 4. Candidate Weighting by Property Inheritance
To ﬁlter out noisy hyponym candidates of the target
concept x, each hyponym candidate y ∈ C(x) is assigned
the weight isa-PI∗
n(y, x), based on not only the inheritance
inherit-txt∗
n(y, x) of the top n typical text features, but also
the inheritance inherit-img∗
n(y, x) of the top n typical image
features from the target concept x:
isa-PI∗
n(y, x)
:=
(1 − α) · inherit-txt∗
n(y, x)
+ α · inherit-img∗
n(y, x),
inherit-txt∗
n(y, x) :=
∑
p∈P tn(x)
has-txt∗(p, y) · has-txt∗(p, x)
∑
p∈P tn(x)
has-txt∗(p, x) · has-txt∗(p, x)
,
inherit-img∗
n(y, x) :=
∑
p∈P i
n(x)
has-img∗(p, y) · has-img∗(p, x)
∑
p∈P in(x)
has-img∗(p, x) · has-img∗(p, x)
,
where α ∈ [0, 1] stands for a certain combination parameter.
III. EXPERIMENT
This section shows some experimental results to validate
the proposed method to extract hyponymy relations from the
Web, based on “Property Inheritance” of not only typical text
features, but also typical image features for each concept,
compared with a traditional lexico-syntactic pattern based
hyponym extraction.
Figure 2 compares the average Precison-Recall curves by
the proposed hybrid hyponym extraction (α = 0.5, n = 10)
by using not only Web text, but also Web images, the
previous hyponym extraction (α = 0, n = 10) by using
only Web text, and a lexico-syntactic pattern based hyponym
extraction for several kinds of target conceptual words such
as “bird” and “ﬂower”. The MAP (Mean Average Precision)
of the proposed hybrid hyponym extraction is the best.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Precision
Recall
Lexico-Syntactic Pattern
Property Inheritance (Text)
Property Inheritance (Text+Image)
Figure 2.
Precison-Recall of Hyponym Extraction based on Property
Inheritance of Text and/or Image Features.
111
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-240-0
SEMAPRO 2012 : The Sixth International Conference on Advances in Semantic Processing

Table I
TOP 18 HYPONYMS EXTRACTED FROM THE WEB FOR “PENGUIN”.
1: photostream
2: iceberg
3: revenge
4: beak
5: poems
6: head
7: feet
8: nest
9: lair
10: eye
1: ■■■■■
2: ■■■■■
3: ■■■■■
4: ■■■■■
5: ■■■■■
6: ■■■■■
7: ■■■■■
8: ■■■■■
9: ■■■■■
10: ■■■■■
penguin
(——)
Top 10 Typical
Text Features
1
2
3
4
5
6
7
8
9
10
(——)
Top 10 Typical
Color Features
1
2
3
4
5
6
7
8
9
10
(——)
Rank
Syntactic Pattern
Text (α = 0.0)
Image (α = 1.0)
Text+Image (α = 0.5)
1
animal
(196)
gentoo penguin
(16.1158)
gentoo penguin
(1.02559)
gentoo penguin
(8.57070)
1
2
3
4
5
6
7
8
9
10
(16.1158)
1
2
3
4
5
6
7
8
9
10
(1.02559)
2
favorite animal
(128)
yellow-eyed penguin
(11.0503)
emperor penguin
(1.02353)
yellow-eyed penguin
(5.72191)
1
2
3
4
5
6
7
8
9
10
(11.0503)
1
2
3
4
5
6
7
8
9
10
(0.39347)
3
tux
(86)
little blue penguin
(7.66437)
baby penguin
(0.94967)
little blue penguin
(4.10788)
1
2
3
4
5
6
7
8
9
10
(7.66437)
1
2
3
4
5
6
7
8
9
10
(0.55138)
4
book
(50)
king penguin
(6.78528)
chinstrap penguin
(0.89687)
king penguin
(3.63577)
1
2
3
4
5
6
7
8
9
10
(6.78528)
1
2
3
4
5
6
7
8
9
10
(0.48626)
5
character
(48)
magellanic penguin
(6.53255)
pc
(0.86006)
magellanic penguin
(3.61665)
1
2
3
4
5
6
7
8
9
10
(6.53255)
1
2
3
4
5
6
7
8
9
10
(0.70074)
6
hoiho
(43)
emperor penguin
(4.74698)
african penguin
(0.85294)
emperor penguin
(2.88526)
(4.74698)
(1.02353)
7
pablo
(43)
baby penguin
(3.65535)
sutter
(0.78754)
baby penguin
(2.30251)
(3.65535)
(0.94967)
8
friend
(37)
chinstrap penguin
(2.67442)
inch serving platter
(0.784431)
chinstrap penguin
(1.78565)
(2.67442)
(0.89687)
9
spheniscus mendiculus
(28)
mr. ﬂibble
(2.37420)
google
(0.77023)
mr. ﬂibble
(1.31628)
(2.37420)
(0.25837)
10
avatar
(27)
macaroni penguin
(2.08840)
adelie penguin
(0.76570)
macaroni penguin
(1.24987)
(2.08840)
(0.41134)
11
hot dog
(24)
favorite animal
(1.25312)
political activist banksy
(0.75514)
royal penguin
(0.91535)
(1.17650)
(0.65420)
12
uguin
(22)
royal penguin
(1.17650)
ty avalanche
(0.75316)
favorite animal
(0.86913)
(1.25312)
(0.48515)
13
galapagos penguin
(18)
little penguin
(0.93420)
video
(0.73873))
adelie penguin
(0.84118)
(0.91665)
(0.76570)
14
god
(18)
adelie penguin
(0.91665)
tux
(0.73620)
little penguin
(0.74092)
(0.93420)
(0.54764)
15
snares islands penguin
(17)
vigilance
(0.86808)
antarctic penguin
(0.73326)
tux
(0.66230)
(0.58840)
(0.73620)
16
heart
(15)
misaki
(0.79266)
linux mascot tux
(0.71541)
african penguin
(0.65259)
(0.45224)
(0.85294)
17
poet
(10)
wentworth miller
(0.78618)
free pablo
(0.70746)
vigilance
(0.63249)
(0.86808)
(0.39691)
18
gentoo penguin
(9)
enemies
(0.64338)
abbath
(0.70085)
misaki
(0.61684)
(0.79266)
(0.44102)
112
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-240-0
SEMAPRO 2012 : The Sixth International Conference on Advances in Semantic Processing

Table II
TOP 18 HYPONYMS EXTRACTED FROM THE WEB FOR “SUNFLOWER”.
1: love
2: garden
3: ﬁeld
4: seeds
5: life
6: smile
7: seed
8: head
9: leaves
10: spiral
1: ■■■■■
2: ■■■■■
3: ■■■■■
4: ■■■■■
5: ■■■■■
6: ■■■■■
7: ■■■■■
8: ■■■■■
9: ■■■■■
10: ■■■■■
sunﬂower
(——)
Top 10 Typical
Text Features
1
2
3
4
5
6
7
8
9
10
(——)
Top 10 Typical
Color Features
1
2
3
4
5
6
7
8
9
10
(——)
Rank
Syntactic Pattern
Text (α = 0.0)
Image (α = 1.0)
Text+Image (α = 0.5)
1
seed
(208)
jill jack
(480.541)
yellow
(1.22165)
jill jack
(240.390)
1
2
3
4
5
6
7
8
9
10
(480.541)
1
2
3
4
5
6
7
8
9
10
(0.23893)
2
favorite ﬂower
(52)
tall sunﬂower
(213.538)
girasol
(1.05447)
tall sunﬂower
(106.943)
1
2
3
4
5
6
7
8
9
10
(213.538)
1
2
3
4
5
6
7
8
9
10
(0.34733)
3
district
(42)
present invention
(211.163)
marigold
(0.86360)
present invention
(105.940)
1
2
3
4
5
6
7
8
9
10
(211.163)
1
2
3
4
5
6
7
8
9
10
(0.71685)
4
navy blue ﬁeld
(23)
independent person
(75.6619)
second parent sunﬂower plant
(0.85420)
independent person
(37.9542)
1
2
3
4
5
6
7
8
9
10
(75.6619)
1
2
3
4
5
6
7
8
9
10
(0.24643)
5
favorite thing
(22)
mirasol
(48.8920)
pairwise disjoint sets
(0.83355)
mirasol
(24.5911)
1
2
3
4
5
6
7
8
9
10
(48.8920)
1
2
3
4
5
6
7
8
9
10
(0.29011)
6
logo
(21)
larva
(42.6859)
sol
(0.81621)
larva
(21.4258)
(42.6859)
(0.16564)
7
yellow
(12)
common sunﬂower
(40.2172)
known prior art
(0.75949)
common sunﬂower
(20.4846)
(40.2172)
(0.75199)
8
hell
(11)
favorite ﬂower
(35.4822)
common sunﬂower
(0.75199)
favorite ﬂower
(17.8299)
(35.4822)
(0.17753)
9
sunbutter
(11)
lead singer
(19.1564)
inﬂorescence
(0.73851)
lead singer
(9.71413)
(19.1564)
(0.27188)
10
seal
(10)
species
(15.7655)
present invention
(0.71685)
species
(8.03862)
(15.7655)
(0.31178)
11
happiness
(9)
aliya
(13.6240)
imidazolinone herbicide
(0.66606)
aliya
(6.97572)
(13.6240)
(0.32740)
12
ﬂower variation
(8)
g-dragon
(11.7593)
silver necklace
(0.61189)
g-dragon
(6.00615)
(11.7593)
(0.25297)
13
friend
(7)
jerusalem artichoke
(11.6205)
maximilian’s sunﬂower
(0.60568)
jerusalem artichoke
(5.93293)
(11.6205)
(0.24531)
14
colour
(6)
happiness
(10.4684)
sunbutter
(0.60099)
happiness
(5.39702)
(10.4684)
(0.32564)
15
disjoint sets
(6)
arapahoe
(9.35538)
helianthus annuus
(0.59916)
arapahoe
(4.89790)
(9.35538)
(0.44043)
16
jerusalem artichoke
(6)
mommy
(6.20476)
size
(0.59646)
mommy
(3.25753)
(6.20476)
(0.31031)
17
pervenets
(6)
fabric
(5.60841)
disjoint sets
(0.55639)
fabric
(2.94874)
(5.60841)
(0.28907)
18
g-dragon
(4)
larry
(3.25074)
crepe back satin
(0.55406)
larry
(1.82185)
(3.25074)
(0.39296)
113
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-240-0
SEMAPRO 2012 : The Sixth International Conference on Advances in Semantic Processing

IV. CONCLUSION
To achieve high recall and not low precision in automatic
hyponym extraction from the Web, our previous work has
assumed “Property Inheritance” from a target concept to
its hyponyms and/or “Property Aggregation” from its hy-
ponyms to the target concept to be necessary and sufﬁcient
conditions of hyponymy, and proposed several methods to
extract hyponymy relations from the Web, based on property
inheritance and/or property aggregation of text features such
as meronyms and behavior-words. To make our previous
method more robust, this paper has utilized not only Web
text, but also Web images, proposed a method to acquire
hyponymy relations from the Web, based on property inher-
itance of not only text features, but also image features for
each conceptual word, and validated the proposed method
by showing some experimental results.
ACKNOWLEDGMENT
This work was supported in part by JSPS Grant-in-Aid for
Young Scientists (B) “A research on Web Sensors to extract
spatio-temporal data from the Web” (#23700129, Project
Leader: Shun Hattori, 2011-2012).
REFERENCES
[1] Mandala, R., Tokunaga, T., and Tanaka, H.: “The Use
of WordNet in Information Retrieval,” Proceedings of the
COLING ACL Workshop on Usage of WordNet in Natural
Language Processing, pp. 31–37 (1998).
[2] Hattori, S., Tezuka, T., and Tanaka, K.: “Activity-based Query
Reﬁnement for Context-aware Information Retrieval,” Pro-
ceedings. of the 9th International Conference on Asian Digital
Libraries (ICADL’06), LNCS vol. 4312, pp. 474–477 (2006).
[3] Hattori, S., Tezuka, T., Hiroaki, O., Oyama, S., Kawamoto,
J., Tajima, K., and Tanaka, K.: “ReCQ: Real-world Context-
aware Querying,” Proceedings of the 6th International and
Interdisciplinary Conference on Modeling and Using Context
(CONTEXT’07), LNAI vol. 4635, pp. 248–262 (2007).
[4] Hattori, S.: “Alternative Query Discovery from the Web for
Daily Mobile Decision Support,” Proceedings of the 5th
IADIS International Conference on Wireless Applications and
Computing (WAC’11), pp. 67–74 (2011).
[5] Hattori, S.: “Hyponymy-Based Peculiar Image Retrieval,”
Int’l Journal of Computer Information Systems and Industrial
Management (IJCISIM), MIR Labs, vol. 5, pp. 79–88 (2012).
[6] Fleischman, M., Hovy, E. and Echihabi, A.: “Ofﬂine Strate-
gies for Online Question Answering: Answering Questions
Before They Are Asked,” Proc. 41st Annual Meeting of the
Association for Computational Linguistics, pp. 1–7 (2003).
[7] Hattori, S., Tezuka, T., and Tanaka, K.: “Mining the Web
for Appearance Description,” Proceedings of the 18th Inter-
national Conference on Database and Expert Systems Appli-
cations (DEXA’07), LNCS vol. 4653, pp. 790–800 (2007).
[8] Hattori, S. and Tanaka, K.: “Object-Name Search by Visual
Appearance and Spatio-Temporal Descriptions,” Proc. of the
3rd Int’l Conference on Ubiquitous Information Management
and Communication (ICUIMC’09), pp. 63–70 (2009).
[9] Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D., and
Miller, K. J.: “Introduction to WordNet: An On-line Lexical
Database,” International Journal of Lexicography, vol. 3, no.
4, pp. 235–312 (1993).
[10] V¨olkel, M., Kr¨otzsch, M., Vrandecic, D., Haller, H., and
Studer, R.: “Semantic Wikipedia,” Proc. 15th Int’l Conference
on World Wide Web (WWW’06), pp. 585–594 (2006).
[11] Hearst, M. A.: “Automatic Acquisition of Hyponyms from
Large Text Corpora,” Proc. 14th Int’l Conference on Com-
putational Linguistics (COLING’92), vol. 2, pp. 539–545
(1992).
[12] Morin, E. and Jacquemin, C.: “Automatic Acquisition and Ex-
pansion of Hypernym Links,” Computers and the Humanities,
vol. 38, no. 4, pp. 363–396 (2004).
[13] Kim, H., Kim, H., Choi, I., and Kim, M.: “Finding Relations
from a Large Corpus using Generalized Patterns,” Interna-
tional Journal of Information Technology, vol. 12, no. 7, pp.
22–29 (2006).
[14] Ruiz-Casado, M., Alfonseca, E., and Castells, P.: “Automa-
tising the Learning of Lexical Patterns: An Application to the
Enrichment of WordNet by Extracting Semantic Relationships
from Wikipedia,” Data & Knowledge Engineering, vol. 61,
no. 3, pp. 484–499 (2007).
[15] Hattori, S., Ohshima, H., Oyama, S., and Tanaka, K.: “Mining
the Web for Hyponymy Relations based on Property Inheri-
tance,” Proceedings of the 10th Asia-Paciﬁc Web Conference
(APWeb’08), LNCS vol. 4976, pp. 99–110 (2008).
[16] Hattori, S. and Tanaka, K.: “Extracting Concept Hierarchy
Knowledge from the Web based on Property Inheritance and
Aggregation,” Proc. of the 7th IEEE/WIC/ACM Int’l Confer-
ence on Web Intelligence (WI’08), pp. 432–437 (2008).
[17] Hattori, S. and Tanaka, K.: “Extracting Concept Hierarchy
Knowledge from the Web by Property Inheritance and Re-
cursive Use of Term Relationships,” IPSJ Transactions on
Databases (TOD40), vol. 1, no. 3, pp. 60–81 (2008).
[18] Hattori, S.: “Object-oriented Semantic and Sensory Knowl-
edge Extraction from the Web,” Web Intelligence and Intel-
ligent Agents, In-Tech, pp. 365–390 (2010).
[19] Yahoo!
Web
Search
API,
http://search.yahooapis.jp/
PremiumWebSearchService/V1/webSearch (2012).
[20] Yahoo!
Image
Search
API,
http://search.yahooapis.jp/
PremiumImageSearchService/V1/imageSearch (2012).
[21] Jing, Y. and Baluja, S.: “VisualRank: Applying PageRank
to Large-Scale Image Search,” IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 30, no. 11, pp. 1877–
1890 (2008).
[22] Lowe, D. G.: “Distinctive Image Features from Scale-
Invariant Keypoints,” International Journal of Computer Vi-
sion, vol. 60, no. 2, pp. 91–110 (2004).
114
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-240-0
SEMAPRO 2012 : The Sixth International Conference on Advances in Semantic Processing

