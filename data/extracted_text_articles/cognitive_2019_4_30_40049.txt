Cognitive Products: System Architecture and Operational Principles
Dari Trendaﬁlov∗‡, Kashif Zia†∗, Alois Ferscha∗‡, Ali Abbas∗‡,
Behrooz Azadi‡, Johannes Selymes‡, Michael Haslgr¨ubler∗‡
∗Institute of Pervasive Computing
Johannes Kepler University
Linz, Austria
†Faculty of Computing and Information Technology
Sohar University
Sohar, Oman
‡Pro2Future GmBH
Linz, Austria
Abstract—Future commercial products and product assemblies
could greatly beneﬁt from recent developments in machine learn-
ing, providing the foundation of cognitive products equipped with
sensors and actuators and embedded into tangible objects oper-
ating in the real world. This paper identiﬁes key challenges in the
related ﬁelds and provides motivation for further advancements
particularly in the domain of resource-constrained distributed
and embedded Artiﬁcial Intelligence. Enabling cognitive capabil-
ities, such as perception, reasoning, learning and planning, could
result in higher reliability, adaptivity and improved performance,
however it would require an increased involvement of non-
technical disciplines like cognitive neuroscience. We propose a
generic top-level cognitive architecture providing a reference
to various research areas involved in this multifaceted ﬁeld.
Conceptual prototypes of two cognitive products, targeting real-
world industrial environments, are presented and discussed.
Keywords–cognitive systems; ambient intelligence; embedded sys-
tems; distributed intelligence; cognitive components.
I.
INTRODUCTION
Humans have developed skills to survive in a complex world
by evolving adequate information processing mechanisms well
suited to deal with ill-structured problems involving a high
degree of uncertainty. The human brain, however, cannot com-
pete with machines on tasks requiring massive computational
resources. Machines are faster, more accurate and stronger
than humans. However, humans outperform machines in many
tasks, which require ﬂexible, reliable and adaptive control.
Since these abilities are currently beyond the reach of state-of-
the-art Artiﬁcial Intelligence (AI), much of the inspiration for
implementing future intelligent machines needs to be taken
from cognitive sciences that study computational models of
human perception, attention and motor control. The ultimate
goal is to turn machines into ones that can reason using
substantial amount of appropriately represented knowledge,
learn from its past experiences in order to continuously im-
prove performance, be aware of its own capabilities, reﬂect
on its own behavior and respond robustly to surprise [1].
Such a high level intelligence should be complemented by
low level cognitive abilities provided by reactive models. This
would enable a major leap in the quality of interaction and
cooperation with humans.
Therefore, the aim of ongoing research in this ﬁeld is
to develop efﬁcient computational mechanisms for artiﬁcial
cognitive systems, which consolidate and beneﬁt from ﬁndings
about the structure and functional organization of natural cog-
nitive systems, while taking into consideration the differences
in their characteristics. For example, sensorimotor loops of
humans and machines differ signiﬁcantly in sensing accuracy,
actuation precision and internal processing latency, implying
different cognitive abilities. Therefore, while following the
basic principles of human cognition, certain deviations in the
realization of Artiﬁcial Intelligence systems can be expected.
Cognitive products are created from a combination of
mechatronic systems equipped with artiﬁcial sensors and
actuators and advanced software algorithms. They integrate
cognitive functionality, such as perceiving the environment,
learning and reasoning from knowledge models. This ﬁeld is
still in its infancy, however the time is ripe for laying down the
foundations of basic system architecture and operational prin-
ciples, which are key challenges for the research community
towards developing future cognitive products.
The main contribution of this paper is the introduction of
a generic system architecture and the description of the key
operational principles of future products with cognitive capa-
bilities. For illustrative purposes, we provide two conceptual
examples of tools incorporating generic cognitive components
and building on the notion of embedded AI. Furthermore, we
raise key open research questions, which need to be addressed
in order to enable the integration of advanced AI into a broad
range of future commercial products.
Integrating cognitive capabilities such as perception, learn-
ing, reasoning, planning and action into future robots, man-
ufacturing systems, autonomous vehicles, etc. requires the
orchestrated effort of various scientiﬁc ﬁelds, i.e., Cognitive
and Neuroscience, Control and Information Theory, Artiﬁ-
cial Intelligence and Engineering. In recent years, disciplines
concerned with cognitive systems have cross-pollinated each
other in various ways. The interdisciplinary research in this
area includes two major subﬁelds, Cognitive Science, which
develops ‘human-like’ computational models of cognition, per-
ception and action, inspired by recent advances in neuroscience
and sensorimotor control, and AI, which explores algorithms
62
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

realizing cognitive capabilities building on advanced methods
of machine learning and Bayesian reasoning.
In Section 2, we brieﬂy review the related scientiﬁc ﬁelds.
Section 3 introduces the concept of cognitive products and
identiﬁes the key challenges to be addressed by the AI com-
munity in order to enable human-like cognitive functions in
machines. Section 4 presents a top-level generic architecture
for cognitive products and describes its key elements. In
Section 5, we introduce two concept devices, building on a set
of generic cognitive features. Section 6 sums up key aspects
of cognitive products and production systems of the future.
II.
BACKGROUND
Cognitive neuroscience and Artiﬁcial Intelligence have a
long relationship, dating back to McCulloch’s, Turing’s, Neu-
mann’s and Hebbian era [2][3], when the theoretical foun-
dations of computing and AI were laid by deﬁning basic
principles interwoven with neuroscience and psychology. Since
then both ﬁelds grew tremendously and evolved into full-
ﬂedged disciplines, having some collaboration at the periphery,
but not mainstream. However, it is a prime time to intensify the
interaction within this relationship again [4][5]. Furthermore,
the growing empirical evidence of Bayesian decision pro-
cesses in human sensorimotor control, reasoning and learning
mechanisms [6] has triggered an enormous research effort
in cognitive psychology. Neuroscientists investigate cogni-
tive control of multi-sensory perception-action couplings in
dynamic and rapidly changing environments, which provide
important insights for neurocognitive models used in technical
system implementations [7]. Research on perception provides
mechanisms allowing to capture information, which is relevant,
by attention focus and context understanding.
Better understanding biological brains could play a vital
role in building intelligent machines. Recent advances in AI
have been inspired by studies of neural computation in humans
and other animals. Neuroscience could provide a rich source
of inspiration for new types of algorithms and architectures,
independent of and complementary to the mathematical and
logic-based methods and ideas that have largely dominated
traditional approaches to AI [4]. Recent studies attempt to dis-
cover mechanisms by which the brain implements algorithms
with the functionality of backpropagation. Such developments
illustrate the potential for synergistic interactions between AI
and neuroscience. Leveraging insights gained in neuroscience
research could expedite progress in the ﬁeld of AI. Earlier
research in cognitive science followed the approach to rea-
soning, which uses behavioral rules based on rewards and
punishments and is inspired by Behaviorism [8], and have
recently refocused onto the Connectionist approach [9][10].
Data science continually makes rapid advances particularly
on the frontiers of deep learning, which provide opportunities
for a variety of applications [11–13] stretching deep into sec-
tors of economy that have stayed on the sidelines thus far. The
volume of available data is growing exponentially, more so-
phisticated algorithms are being developed and computational
power and storage are steadily increasing. The convergence of
these trends is fueling rapid technology advances and business
disruptions. However, modern AI generally provides solutions
ﬁne-tuned to crunch large complex data sets enabling only
rudimentary context awareness.
Artiﬁcial Neural Networks (ANN) [14] have become very
popular recently due to advancements in computing power,
availability of big data and developments in deep learning
techniques. The great success of Deep Neural Networks (DNN)
built largely on the power of GPUs for massive parallel com-
puting. Deep learning derives its power from computational
models composed of multiple processing layers able to learn
representations of data with multiple levels of abstraction
[15][16]. This makes it naturally ﬁt for pattern recognition
problems where learning is about discovering features that
have high value states in common [10]. More recent advances
in deep learning are moving beyond object recognition and to-
wards scene understanding [17][18]. Yet, current deep learning
methods excel in recognition [19] rather than understanding
tasks, and furthermore are not able to draw causal relationships
between objects. Complex scene understanding requires core
knowledge about physics [20], compositions and relationships
of objects and causality between them [10]. To understand
causal relationships between interacting agents in a scene, their
intentions and goals, we need core knowledge from social
psychology. The mechanism of learning and thinking needs
to be local and incremental, based on a generic approach,
which starts from a clean slate and evolves over time. A more
principled approach to cognition builds models to understand
the world [10], as the key to human intelligence is its capability
to explain nature, rather than classify or recognize phenomena.
Several concepts for cognitive architectures have been pro-
posed in the past, namely ACT-R [21], Soar [22], ADAPT
[23], PSI [24], however the common shortcoming of all is the
lack of general design methodology. These approaches lack
modeling of cognitive information processing from the ground
up. Examples of basic information processing functions are
acquisition, processing and transferring, while more abstract
and complex ones are analyzing and classiﬁcation [25]. Other
cognitive functions, such as observe, recognize, encode, store,
remember, think, problem solving, motor control and language
show that beyond formalizing they also combine new informa-
tion with existing internalized knowledge representation [26].
III.
COGNITIVE PRODUCTS
Cognition implies the ability to understand the underly-
ing nature of things, not only at present but also in the
past and in the foreseeable future, and to take this into
consideration in decision-making. For this purpose, humans
require sufﬁcient, usually not too extensive information, ex-
perience, and profound knowledge on the matter as well
as an estimation of the consequences of alternative actions.
Transferring these capabilities to digital systems could enable
new levels of innovative functionality depending on the scale
of particular applications, with systems ranging from local
man-machine interaction to shop-ﬂoor or factory-wide man-
to-machine (M2M) communication to management of inter-
organizational production processes. This requires the creation
of tangible, durable objects consisting of a physical carrier
63
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

system with embodied mechanics, electronics, microprocessors
and software, and equipping them with cognitive capabilities
enabled by ﬂexible control loops and cognitive algorithms [27].
In contrast to products operating with deterministic control
methods, cognitive products do not only act autonomously,
but they do so in an increasingly intelligent human-like man-
ner [27]. Cognitive products could maintain multiple goals,
perform context-sensitive reasoning and make appropriate de-
cisions based on complex and uncertain information, which
makes them more robust in their adaptation to dynamic en-
vironments than other products. Coping with such intelligent,
ﬂexible and robust behavior would emphasize the importance
of the human factor in smart factories and at the same
time could put the human operator into a better position
when adapting to highly customized dynamically changing
manufacturing processes as compared to fully automated mass
production systems. On one hand, the increasing specialization
of products and processes requires guidance in task execution,
while on the other hand industry requires a continuous, detailed
assessment of data in order to optimize product speciﬁcations
and production processes.
A. Can a machine think?
While the notion of Artiﬁcial Intelligence has been around
for decades, recent advances in algorithms and processing
power combined with the exponential growth in available data
are enabling the creation of machines with unprecedented
capabilities. While these technologies might not redeﬁne what
it means to ‘think’ they are starting to perform activities
long thought to be the sole purview of humans – sometimes
at higher levels of performance than people can achieve.
Although in some tasks AI outperforms human counterparts
[28] machines are still far from general human-level intelli-
gence, which relates to qualitative cognitive aspects of human
learning and thinking, such as intuition, inference, imagination,
imitation, learning to learn, prediction and planning.
As opposed to narrow (weak) AI, typically developed for
a speciﬁc application such as object or speech recognition
(e.g., IBM’s Deep Blue and Watson, Google’s AlphaGO [29]),
general (strong) AI possesses an understanding of the world
and has human-like cognitive abilities. When a general AI
is confronted with a new problem it can ﬁnd a solution
based on experience with similar problems by applying, e.g.,
transfer learning [30][31] or abstract association or based on
its understanding of the world independent of the particular
task. Knowledge about the world may be simply related
to objects size, location, co-occurrences, properties, but also
more abstract insights like physical laws, social behavior, and
causality. An ‘ultimate’ test for assessing general intelligent
behavior of an AI based on its distinction from a human when
inquired by a human observer was proposed already in [32].
Technologies like Cyber-Physical Systems (CPS), Internet
of Things (IoT), Industry 4.0 and autonomous vehicles operate
in self-contained, distributed and localized manner utilizing
resource-constrained devices, which creates scalability issues
for deep learning techniques. Therefore, besides ﬂexibility
and adaptivity, efﬁciency becomes a key criterion for future
systems. We need a computational cognitive foundation for
things that think. For a truly human-like thinking and learn-
ing the system should possess causal model of the world
describing the structure and the causal relationships between
the agents and their environment, rather than merely solving
pattern recognition problems. Cognitive systems should be
able to perform ground learning starting from a clean slate
and evolving on top of born-with theories of core knowledge,
e.g., intuitive physics [33] and psychology [34]. They should
harness the compositionality, i.e., the construction of new
knowledge based on primitive elements, and learning-to-learn
in order to rapidly acquire and generalize knowledge to novel
situations and processes. These features are necessary for
achieving a general-purpose AI ﬂexible enough to adapt to
previously unseen scenarios and interactions.
B. Beyond state-of-the-art
We are witnessing an era in which the convergence of
algorithmic advances, data proliferation, and tremendous in-
crease in computing power and storage have propelled AI from
hype to reality. However, in order to develop truly human-like
learning and thinking machines there are open key challenges
for AI research, i.e., (i) machine learning requires massive
resources (computing power and training data), (ii) models do
not generalize well, (iii) processes of training and inference
most likely differ from human learning and reasoning.
Within the Smart Movement [35][36] products have been in-
creasingly equipped with electronics, enabling the assessment
of isolated environmental data and the interpretation of basic
contextual information (e.g., wearable activity trackers, smart-
phones and watches, etc.). However, these products typically
have deterministic and predeﬁned behavior and lack the ca-
pabilities required for sustainable and autonomous human-like
cognitive functions, such as perception, awareness, learning,
reasoning and decision-making. Cognitive products are capa-
ble of achieving self-awareness, understand their immediate
environment including human collaborators, activities and pro-
cesses, and can perform goal-oriented complex tasks such as
human assistance and guidance, as well as integrate higher-
level work-ﬂow information related to environmental states
into object models.
Cognitive systems exhibit behavior through perception, ac-
tion, individual or social interaction with the environment,
and depend on standardized networks and interfaces for com-
munication and access to information from distributed and
embedded systems. The next generation of products and man-
ufacturing machinery suited for batch and continuous process
industries with embedded cognitive functions will enable the
following capabilities in an autonomous self-organized fashion
•
assistive man-machine collaboration enabling appropri-
ate worker support and guidance in complex processes;
•
adaptive control of dynamic M2M networks enabling
self-adaptation to work situations, material, human re-
sources and environmental conditions;
•
embedded data analytics enabling autonomous sensor-
based data collection, data mining and real-time predic-
tive and pro-active planning and decision-making;
64
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

•
embodiment appropriately related to workers and other
cognitive systems in the immediate environment;
•
synergistic machine-to-machine organization of produc-
tion systems.
Further advances of cognitive products could include seman-
tic work-ﬂows and tool description models for (i) work-ﬂow
alignment, (ii) quality control, (iii) tolerance range assessment,
and (iv) skill, task and overall evaluation. This would require
the identiﬁcation of a formal model for an opportunistic
multimodal feedback framework based on the optimization of
user, tool, material and environmental parameters. Building on
a knowledge database of previously applied strategies a reason-
ing engine could provide guidance even in previously unseen
work-ﬂow situations using context and activity recognition.
C. Embedded AI
Rapid developments in hardware, software and communica-
tion technologies have facilitated the emergence of Internet-
connected sensory devices that provide ubiquitous observa-
tions and data measurements from the physical world. The
technology of Internet-connected devices, referred to as In-
ternet of Things (IoT) [37], extends the current Internet by
providing connectivity and interactions between physical and
cyber worlds. IoT continuously generate data with a variety
of modalities and data quality and the intelligent processing
and analysis of such data is the key to developing smart appli-
cations. As the number of commercial and industrial devices
proliferates, connecting them in dynamic networks comprised
of intelligent individual components is a key challenge for IoT
to realize its full potential [38].
An industrial facility might have thousands of sensors
monitoring the status of machines and processes, which how-
ever often reside in silos that do not communicate. Some
AI solutions are centralized on cloud service architectures,
where sensor data needs to be collected, correlated with
historical performance data and analyzed to provide actionable
information for real-time decision-making. However, in many
industrial locations sufﬁcient bandwidth or connectivity cannot
be relied upon. Therefore, in order to obtain reliable continuous
time-critical decisions we need to embed intelligence at the
source of sensing. This requires building smart devices on
top of edge computing architectures and equipping them with
Artiﬁcial Intelligence. To this end, some chip companies work
on incorporating conventional AI software in their chips, while
others are building advanced cognitive AI solutions that can
be embedded in off-the-shelf inexpensive chips. Embedding
cognitive capabilities such as perception, awareness, reasoning,
learning and decision making into products requires addressing
constraints in terms of size and weights, real-time computation,
limited processing resources (memory footprint and computing
power), low power consumption and low cost. Scarcity of
resources hinders autonomous real-time execution of conven-
tional deep learning algorithms on embedded devices due to
massive computational requirements. We envision that deep
learning will have a pivotal role in realizing a ﬂexible and ef-
ﬁcient learning platform for embedded AI. However, industrial
design and software need to be optimized to simultaneously
meet all of the above constraints, while current machine learn-
ing methods still require massive computing power, training
data and memory footprint. The next generation of machine
learning algorithms need to provide ﬂexible, efﬁcient and
incremental learning techniques for resource-constrained envi-
ronments in order to enable future self-organized autonomous
systems. Recent advances in deep learning are already moving
beyond object recognition and towards scene understanding,
which requires core knowledge about physics, compositions,
relationships and causality between objects [39]. If the scene
includes agents and humans interacting, percepting and acting,
then we also need core knowledge of social psychology
for understanding their intentions and goals. For realizing a
dynamically evolving low foot-print learning framework, deep
learning has to respond to these challenges and answer key
research questions such as:
1)
Can deep neural networks ﬁt cognitive processes of
human brain?
2)
How can insights in human perception be applied to AI
systems?
3)
Can DNN transfer knowledge learned in one task to
another?
D. Ensembles of cognitive components
Modern smart factories require the integration of ﬂexible
cognitive components enabling implicit supply chain manage-
ment via vertical integration and quality management via step-
wise traceability. Building on the approach of opportunistic
sensing cognitive components could advertise their capabilities
with respect to both sensing and actuation. Upon localizing
each other they could form collective ensembles in self-
organized manner and exchange structured data. Furthermore,
they could jointly sense their shared contextual state and
adapt accordingly by preemptively suggesting usage strategies
or best practices to users, or by reactively setting operation
parameters to suit particular circumstances. Such ensembles
could learn from use and/or misuse of individual tools and
take proactive steps to avoid hazardous situations and increase
their own life-span. Component and production history aware-
ness could enable the ﬁne-grained modeling, organization and
optimization of complex production processes. The ultimate
goal is to enable the creation of joint cognitive systems [40],
consisting of distributed networks of intelligent devices and
human operators.
E. Dependability
The accurate operation of cognitive production tools is of
utmost importance even in very harsh production environments
as tool downtime or malfunction may lead to reduced pro-
ductivity, waste products or may harm the worker in safety-
critical applications. Certain capabilities related to sensing,
localization and communication are particularly vulnerable in
harsh environmental conditions such as for example strong
electromagnetic ﬁelds generated by arc welding. Therefore,
highly dependable uniﬁed solutions need to be devised, inte-
grated and tested in cognitive tools.
65
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

Machines equipped with cognitive abilities could provide
higher degree of robustness and dependability by learning
to perform complex tasks reliably and accurately in various
extreme conditions. In order to achieve that they must take
into consideration all available sensory channels and utilize
the most appropriate ones. Embedded context and activity
recognition based on multi-sensor fusion (RGBD video, mo-
tion, orientation and pressure sensors, eye-tracking, GSR, HRV,
RFID, indoor localization, etc.) could enable advanced context
understanding including presence, activities, needs and skills of
workers, work-ﬂows, etc. However, current industrial solutions
are limited to recording basic information about speciﬁc envi-
ronmental aspects (e.g., temperature, humidity sensing, etc.).
True cognitive products need to advance this state-of-the-art by
building on adaptive and robust multimodal sensor networks
and distributed data processing algorithms.
IV.
COGNITIVE ARCHITECTURE
Enabling an advanced level of self-organization, which
allows machines to accomplish complex tasks in changing
and uncertain environments, maintain multiple goals simul-
taneously, resolve conﬂicts between interfering goals and act
appropriately in unexpected and previously unseen situations,
requires a sophisticated design methodology and appropriate
cognitive architecture.
For ensuring robust and reliable behavior of cognitive
products we need advanced virtual methods for engineering,
tools and models providing fully functional simulation environ-
ments. Every cognitive product device generates data, which
is fed back into engineering and maintenance systems for
continuous product improvement and condition monitoring and
therefore requires an individual virtual representation reﬂecting
its context of use. In parallel to virtual methods, modeling and
controlling single instances and ensembles of cognitive com-
ponents require a user-centric product development approach,
which takes into account ergonomic aspects and human factors.
In order to capture the synergistic interdependence between
humans and cognitive products in the context of social inter-
action and collaboration we need to take into account affective,
cognitive and social aspects in interaction design, informed by
relevant sociological, psychological, socio-cultural, ethical and
legal studies.
Decision making
Cognitive models
Perception
Machine learning
Action
Figure 1.
Diagram reﬂecting the relationships between elements of the
Cognitive System Architecture.
A state-of-the-art cognitive system architecture requires a
probabilistic approach in order to provide means for integrating
perception, learning, reasoning and action in the face of un-
certainty. Such an architecture would include a comprehensive
repertoire of diverse learning methods capable of generalizing
from a very few samples. The acquisition of new skills and
activities from little prior experience and a limited number of
observations would be facilitated by knowledge representation,
learning infrastructure and computational models tailored par-
ticularly for low-power sensor-equipped embedded platforms
operating in resource-constrained environments.
Cognitive system architectures usually decompose cognition
functionally into modules operating in a tightly interconnected
mode [41]. The elements describing the conceptual represen-
tation of the hierarchical ‘human-like’ perception–action loop
required for realizing cognitive products are shown in Table I.
Creating technical devices that interact with a Human always
requires the consideration of the human factor, since the inter-
action involves two systems that are different by nature, i.e.,
Biological on one side and Cyber-Physical on the other [42].
Furthermore, enabling a more natural relationship with the
user necessitates the integration of sophisticated human-like
cognitive functions, such as emotion and intention recognition.
Formal concepts and models of primitive cognitive rules for
multi-sensor computational perception, learning and reasoning
are inspired by neural processes underlying human cognition
and are based on core knowledge theories of intuitive physics
and psychology (see Figure 1). They provide a foundation
supporting primitives of ﬂexible and efﬁcient learning: descrip-
tive causal model of the world, compositionality and rapid
learning-to-learn capability. The aim is to achieve compact
representations and optimize inference for execution on em-
bedded devices in real time. Another key criterion is the radical
decrease in resource requirements compared to cloud-server
based solutions. This requires efﬁcient hierarchical data rep-
resentations emulating human perception with digital sensors
and a new generation of deep learning algorithms and artiﬁcial
neural networks reﬂecting the hierarchies of human cognition,
distributed and incrementally evolving in nature. Independent
cognitive devices would form a network within which they
could interact autonomously with each other, providing the
basis for the emergence of an even higher intelligent entity.
TABLE I.
ELEMENTS OF THE COGNITIVE SYSTEM ARCHITECTURE.
Element
Description
Perception
acquisition of information about the environment and the body
of an actor, typically considered in AI an estimation process
providing symbolic representation of the world state
Action
process of generating actual behavior in machines in the form
of executable control programs derived from precise dynamical
system models
Learning
process of acquiring, structuring and reorganizing information
that results in new knowledge and leads to behavioral changes,
which are measurable and persistent in time
Decision
making
process of making inferences and generating representations of
conceptual future behavior based on evidence and basic principles
using various mechanisms (causal, temporal, spatial, etc.)
Cognitive
models
formal models and ingredients of human intelligence reﬂecting
aspects of core knowledge necessary for general-purpose capa-
bilities
66
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

V.
CONCEPT DEVICES
In this section we describe a set of speciﬁc, yet generic,
cognitive features, in the context of two conceptually different
prototypes of intelligent production tools. The realisation of
these prototypes is ongoing work and therefore their evaluation
is not included in this paper. However, with these examples we
demonstrate how knowledge transfer could be achieved across
a range of cognitive products, ensuring device interoperability
and minimizing development costs.
A. Power tool
Let us take the power tool (see Figure 2) as an example
of a potential future product with cognitive capabilities. The
cognitive power tool is a ubiquitous computing, sensing and
actuation device in which sensors are connected in a network,
where data analysis is performed in real-time on embedded
computing device providing autonomous decision making in
a distributed architecture. The cognitive capabilities of the
network include state estimation from sensor data, context
inference, continuous acquisition, update and use of activity
models. The cognitive sensor network has to recognize and
understand human actions with respect to tasks and goals, and
furthermore estimate and predict user state and future behavior.
Certain activities can be performed concurrently and need to be
decomposed into primitive actions for classiﬁcation purposes.
Recent innovations in linear motion and assembly technol-
ogy enable high-precision measuring systems based on intelli-
gent engineering solutions, opening a variety of opportunities
for Industry 4.0 applications. This includes the integration of
high-precision digital sensors for torque and angle of rotation
acquisition, which provide excellent accuracy, repeatability,
durability and process documentation. Both power and control
technologies can be fully integrated into the power tool and
no external sensors or controls are required during operation.
The power tool combines wireless capabilities with state-of-
the-art tightening technology, a combination which has the
potential to improve efﬁciency, cycle-times and data collection
during the manufacturing process. During each work step
Figure 2.
Cognitive components of a conceptual intelligent power tool.
the integrated controller monitors the tightening of variable-
speed pump drives and transmits the results over wireless
channel to a receiving station. Its decentralized intelligence
is integrated in the tool and can utilize product variables such
as serial numbers to determine the tightening process recipe
for execution. Integrating the control of the tightening process
ensures the highest level of reliability even in wireless dead
zones. Power tool ensembles interconnected in networks could
share tightening data and thus optimize production processes
and product quality.
The capabilities of our conceptual cognitive power tool are
described in Table II.
B. Head gear
Recent advances in mobile computing, Augmented Reality
(AR) and wearable sensors have had a profound impact on
assistive technology supporting daily routines of industrial
employees. A great effort is dedicated to exploring the beneﬁts
of AR, however more advanced developments are typically
restricted to the research community and are not commercially
available due to various shortcomings. AR solutions have
been developed predominantly on hand-held devices, which
constrains user movement and ability to interact with the
physical world using hands-free operation. More advanced
Head-Mounted Displays (HMD) overcome these obstacles by
allowing users to follow instructions in hands-free manner
while performing an assembly operation.
Google Glass, arguably the most popular HMD, has been
utilized in a variety of settings including agriculture, health-
care, sports, information retrieval and teleconferencing, to
name a few. Smart head-wear devices have also been deployed
in industrial environments. However, while large scale develop-
ments are under way in this ﬁeld, the potential and the beneﬁts
of the evolving HMD technology in real industrial settings are
not completely clear yet.
Recent smart head-wear technologies have targeted a num-
ber of areas, including
•
aviation – helmet-mounted and cockpit-projected solu-
tions primarily used for military purposes with limited
commercialization;
TABLE II.
FEATURES OF A COGNITIVE POWER TOOL.
Feature
Description
Pressure detection
piezo element for contact pressure
Smart chuck
tool surveillance (e.g., temperature) for minimal
work-ﬂow interruption
Torque adaptation
based on task and work-piece requirements
Visual feedback
visual guidance on pico projector
Optical sensor
high resolution target localization, context and task
recognition
Antennas
communication infrastructure (e.g., RFID, Zigbee,
WiFi, BT)
Indoor
positioning
localization in industrial environmental settings
(e.g., WPS, BT, ToA)
Acoustic
feedback
advanced guidance in real-time operation
Haptic feedback
vibro-tactile actuators for work-ﬂow management
Inertial sensing
orientation, position and movement tracking
Cognitive unit
context-awareness,
intelligent
reasoning
and
decision-making
Control unit
execution of work-ﬂow management
67
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

•
consumer – home entertainment and daily activity en-
hancement (Google, Samsung);
•
manufacturing – enhancement of process engineering,
logistics and ﬁeld services (e.g., hands-free maintenance
instructions, barcode scanning, warehouse navigation);
•
medical/Healthcare – telemedicine and hands-free pa-
tient information;
•
military – reconnaissance with multi-spectral cameras
and thermal night vision;
•
sports – display salient information such as track trajec-
tory, temperature, altitude and speed in cycling, sailing
and motor sports;
•
ﬁreﬁghting – object recognition and ﬂow path tracking
using thermal vision and edge detection;
•
publishing – instant translation.
The ﬁeld of HMD is still fragmented with respect to the
utilized technology. Commercial products use various connec-
tivity methods, a range of operating systems and a number of
primary and secondary input/output devices. No single stan-
dard solution exists, which could provide all essential features
a factory worker might beneﬁt from in a complex industrial en-
vironment in order to increase production efﬁciency. Existing
HMD devices lack comprehensive solutions providing a step-
by-step guide to assist workers in the completion of a complex
assembly task, instead they usually support a prerecorded video
playback or a video teleconference access to relevant experts.
Typical features of existing industrial HMD solutions include
•
presentation of work instructions related to a particular
task, which are overlaid on the real-world scene with
spatial and temporal relevance;
•
superposition of thermal contour of real-world objects
frame-overlaid onto a portable display;
•
remote asset access and data visualization;
•
connected expertise;
•
hands-free interaction using voice control.
Reusing many of the cognitive components of the power tool
(see Table II), we could imagine a head-wear device equipped
with a smart-phone for localized computation and mirrored
visual feedback, as shown in Figure 3. Additional components
include a world-view camera for monitoring the environment
and gesture control, as well as eye-tracking cameras for atten-
Figure 3.
Cognitive components of a conceptual intelligent head gear.
tion detection, and multi-directional vibro-tactile feedback.
Modern smart-phones are equipped with a variety of unob-
trusive embedded sensors (e.g., inertial, infrared, light, proxim-
ity, ﬁngerprint, temperature, noise, speech, GPS, etc.), which
are widely used for human activity recognition purposes. Data
analysis is performed either online in real-time or ofﬂine
depending on the application and the context. Furthermore,
the ubiquity and the signiﬁcant computational power combined
with large built-in memory and low manufacturing cost make
smart-phones a very good potential candidate for a head-
mounted mini computer, providing a convenient high reso-
lution visual display mirrored in the helmet besides portable
sensing and computing resources. Established standards, open
source platforms and a variety of connectivity methods make
the integration of smart-phones in industrial IT networks easy.
A head-wear with augmented cognitive capabilities could
infer the skill or attention level of workers and provide the
necessary assistance and appropriate guidance pro-actively. It
could anticipate safety critical events and predict human behav-
ior in unstructured and dynamically changing environments,
continuously re-training itself also from partial and uncertain
information. It could store relevant data locally or remotely and
could recall the appropriate piece of information in a timely
manner in order to support workers efﬁciently.
VI.
DISCUSSION
In this paper, we have described the basic operational prin-
ciples of potential future cognitive products, emerging at the
intersection of AI, Cognitive and Neuroscience, Control and
Information theory, Engineering and Human Factors. Recent
developments in AI open up the possibility to advance beyond
current standards towards ‘Things that think’, ‘Cyber-Physical
Systems’ and ‘Industry 4.0’, which have emerged as keywords
for intelligent systems. In this context, we have identiﬁed
various areas where AI technology could advance the state-of-
the-art in cognitive systems. This requires the development of
computationally efﬁcient AI algorithms, which could perform
real-time inference on resource-constrained embedded devices.
We have pointed out a number of research areas, which could
provide breakthroughs in this direction such as
•
efﬁcient learning from sparse data (‘one-shot’) [43],
•
real-time embedded inference,
•
advanced perception and scene understanding.
The integration of cognitive functions could enable future
products to interact independently with their environment. This
would allow self-organized and self-optimized behavior and
would increase signiﬁcantly their adaptivity and robustness.
However, achieving such a high level of autonomous intel-
ligence would require a considerable involvement of non-
technical disciplines like cognitive science and neurobiology.
Considering the multifaceted nature of this area it is necessary
that researchers from different ﬁelds collaborate more closely
in the design and development of future cognitive products.
The ultimate goal is to enable human-like cognitive ca-
pabilities in products by supporting multi-sensor perception
of complex environments, storing and recalling information,
transferring knowledge in the form of reasoning models to
68
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

previously unseen situations, human-like decision-making and
continuous learning. This would provide autonomous decision-
making, ﬂexible adaptation to new tasks in changing environ-
ments and workload capacities. Systems that think, reason,
make ﬂexible human-like decisions and sense/adapt to the
environment will enable seamless interaction with humans
resembling smooth and efﬁcient human-human interaction.
Empowering production systems and products to adapt, learn,
develop and react human-like would enhance production pro-
cesses and reduce user frustration. This would facilitate the
development of human–machine joint cognitive systems in
which humans could teach machines to perform speciﬁc tasks.
To support human operators in complex work-ﬂows cogni-
tive devices could beneﬁt from their awareness of
•
contextual information offered by other devices and via
local sensing,
•
state of other tools involved in the production process,
•
experience and skill level and work-ﬂow complexity,
•
cognitive load and level of attention of human operators.
We envision cognitive industrial systems based on manufac-
turing machinery connected to world-wide online platforms
where machines and tools are added and removed in real-
time in plug-and-use or plug-and-produce fashion. In a decen-
tralized system architecture systems, processes and services
communicate and interact autonomously and solve problems
jointly. Industrial utilization typically triggers the enhancement
of production tools with cognitive capabilities driven by their
application in particular production environments. However, in
speciﬁc cases such concept devices can be directly transferred
to commercial home appliances as well. Cognitive production
tools could bring a competitive advantage for industrial players
by providing key beneﬁts such as
•
learning from past experience to avoid repetition of
errors and continuously improve quality and cost,
•
worker guidance and support,
•
automated tool conﬁguration and adaptation to current
work-ﬂows,
•
data collection for detailed modeling and documentation
of production front- and back-end processes,
•
production task awareness to enable ﬂexible adaptation
to variations within a single and across different tasks,
•
worker skill awareness to enable compensation for lack
of skill or attention,
•
collaboration between cognitive tools to provide a reso-
lution for deviations in earlier production steps.
New business models and services could make use of the
continuous data streams captured in product utilization and
production control, paving the way towards a fully automated
product-production ecosystems.
VII.
CONCLUSION
We have proposed a generic cognitive architecture, which
could provide the foundation for creating future intelligent
products and production systems realizing human-like capa-
bilities such as appreciate, learn and plan. The paper sheds
light on the important role AI could play in the design and de-
velopment of cognitive products, and identiﬁes key challenges
to be addressed by the AI community in order to fulﬁl these
high expectations. At the same time, cognitive systems could
serve as a suitable environment for leveraging advances in AI
research and validating their relevance. The paper presents a
motivation for integrated future research, and highlights recent
progress opening up the possibility for building the cognitive
products of tomorrow. In this context, we have identiﬁed a
number of research areas where major breakthroughs could
advance signiﬁcantly this ﬁeld. The aim of this paper is to
raise the awareness of relevant scientiﬁc ﬁelds of such joint
opportunities in order to foster a highly interactive broader
research community.
ACKNOWLEDGMENT
The authors would like to acknowledge support by FFG
funded Pro2Future under contract No. 6112792.
REFERENCES
[1] R. J. Brachman, “Systems that know what they’re doing,” Intelligent
Systems, vol. 17, no. 6, 2002, pp. 67–71.
[2] W. S. McCulloch and W. Pitts, “A logical calculus of the ideas immanent
in nervous activity,” The bulletin of mathematical biophysics, vol. 5,
no. 4, 1943, pp. 115–133.
[3] J. J. Hopﬁeld, “Neural networks and physical systems with emergent
collective computational abilities,” Proceedings of the national academy
of sciences, vol. 79, no. 8, 1982, pp. 2554–2558.
[4] D.
Hassabis,
D.
Kumaran,
C.
Summerﬁeld,
and
M.
Botvinick,
“Neuroscience-inspired artiﬁcial intelligence,” Neuron, vol. 95, no. 2,
2017, pp. 245–258.
[5] D. L. Yamins and J. J. DiCarlo, “Using goal-driven deep learning models
to understand sensory cortex,” Nature neuroscience, vol. 19, no. 3, 2016,
p. 356.
[6] K. P. K¨ording and D. Wolpert, “Bayesian decision theory in sensorimotor
control,” Trends in Cognitive Sciences, vol. 10, 2006, pp. 319–326.
[7] V. Mnih et al., “Human-level control through deep reinforcement learn-
ing,” Nature, vol. 518, no. 7540, 2015, p. 529.
[8] B. F. Skinner, Science and human behavior.
Simon and Schuster, 1953,
no. 92904.
[9] J. A. Fodor and Z. W. Pylyshyn, “Connectionism and cognitive archi-
tecture: A critical analysis,” Cognition, vol. 28, no. 1-2, 1988, pp. 3–71.
[10] B. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman,
“Building machines that learn and think like people,” Behavioral and
Brain Sciences, vol. 40, 2017, p. e253.
[11] B. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum, “Human-level
concept learning through probabilistic program induction,” Science, vol.
350, no. 6266, 2015, pp. 1332–1338.
[12] A. Van Den Oord et al., “Wavenet: A generative model for raw audio.”
in SSW, 2016, p. 125.
[13] L. A. Gatys, A. S. Ecker, and M. Bethge, “A neural algorithm of artistic
style,” arXiv preprint arXiv:1508.06576, 2015.
[14] F. Rosenblatt, “The perceptron: a probabilistic model for information
storage and organization in the brain.” Psychological review, vol. 65,
no. 6, 1958, p. 386.
[15] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,
no. 7553, 2015, p. 436.
[16] J. Schmidhuber, “Deep learning in neural networks: An overview,”
Neural networks, vol. 61, 2015, pp. 85–117.
69
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

[17] A. Karpathy and L. Fei-Fei, “Deep visual-semantic alignments for
generating image descriptions,” in Proceedings of the IEEE conference
on computer vision and pattern recognition, 2015, pp. 3128–3137.
[18] S. A. Eslami et al., “Attend, infer, repeat: Fast scene understanding
with generative models,” in Advances in Neural Information Processing
Systems, 2016, pp. 3225–3233.
[19] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Advances in neural infor-
mation processing systems, 2012, pp. 1097–1105.
[20] P. Battaglia, R. Pascanu, M. Lai, D. J. Rezende et al., “Interaction
networks for learning about objects, relations and physics,” in Advances
in neural information processing systems, 2016, pp. 4502–4510.
[21] J. Anderson et al., “An integrated theory of the mind,” Psychol. Rev.,
vol. 111, no. 4, 2004, pp. 1036–1060.
[22] A. Newell, Uniﬁed theories of cognition.
Harvard University Press,
Cambridge, 1990.
[23] C. Burghart et al., “A cognitive architecture for a humanoid robot – a
ﬁrst approach,” in In: Proceedings of IEEE-RAS international conference
on humanoid robots (Humanoids2005), 2005, pp. 357–362.
[24] D. D¨orner, H. Schaub, and F. Detje, “About the interplay of cognition,
emotion and motivation - or: A simple theory for complicated behaviors,”
In: Sozionikaktuell, no. 2, 2001.
[25] T. Metzler and K. Shea, “Taxonomy of cognitive functions,” in In:
Proceedings of 18th International Conference on Engineering Design
(ICED11), 2011.
[26] G. Strube, Dictionary of cognitive science.
Klett-Cotta, Stuttgart, 1996.
[27] T. Metzler and K. Shea, “Cognitive products: Deﬁnition and framework,”
in In: Proceedings of International Design Conference (DESIGN2010).
Berlin, Springer, 2010, pp. 865–874.
[28] K. He, X. Zhang, S. Ren, and J. Sun, “Delving deep into rectiﬁers:
Surpassing human-level performance on imagenet classiﬁcation,” in
Proceedings of the IEEE international conference on computer vision,
2015, pp. 1026–1034.
[29] D. Silver et al., “Mastering the game of go with deep neural networks
and tree search,” nature, vol. 529, no. 7587, 2016, p. 484.
[30] A. A. Rusu et al., “Progressive neural networks,” arXiv preprint
arXiv:1606.04671, 2016.
[31] A. Rusu et al., “Sim-to-real robot learning from pixels with progressive
nets,” arXiv preprint arXiv:1610.04286, 2016.
[32] A. Turing, “Mind,” Mind, vol. 59, no. 236, 1950, pp. 433–460.
[33] D. Buckingham and T. R. Shultz, “The developmental course of distance,
time, and velocity concepts: A generative connectionist model,” Journal
of Cognition and Development, vol. 1, no. 3, 2000, pp. 305–345.
[34] E. S. Spelke, “What makes us smart? core knowledge and natural
language,” Language in mind: Advances in the study of language and
thought, 2003, pp. 277–311.
[35] S. Das., I. R. S. Cook, D., A. Ananda, M. C. Chan, and W. Ooi,
“Designing smart environments: A paradigm based on learning and
prediction,” in Mobile, Wireless, and Sensor Networks, Technology,
Applications, and Future Directions.
Wiley, 2006, pp. 337–358.
[36] E.
Aitenbichler,
F.
Lyardet,
G.
Austaller,
J.
Kangasharju,
and
M. M¨uhlh¨auser, “Engineering intuitive and self-explanatory smart prod-
ucts,” in Proc. 22nd Annual ACM Symp. Applied Computing.
ACM
Press, New York, NY, 2007, pp. 1632–1637.
[37] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of things
(iot): A vision, architectural elements, and future directions,” Future
generation computer systems, vol. 29, no. 7, 2013, pp. 1645–1660.
[38] J. Dean et al., “Large scale distributed deep networks,” in Advances in
neural information processing systems, 2012, pp. 1223–1231.
[39] E. S. Spelke and K. D. Kinzler, “Core knowledge,” Developmental
science, vol. 10, no. 1, 2007, pp. 89–96.
[40] E. Hollnagel and D. Woods, Joint Cognitive Systems: Foundations of
Cognitive Systems Engineering.
Taylor & Francis, 2005.
[41] M. Beetz, M. Buss, and D. Wollherr, “Cognitive technical systems – what
is the role of artiﬁcial inteligence?” in Advances in Artiﬁcial Intelligence,
vol. 4667.
Berlin, Springer, 2007, pp. 19–42.
[42] D. Fass and F. Gechter, “Virtual environments integrative design – from
human-in-the-loop to bio-cyber-physical systems,” in 8th International
Conference on Applied Human Factors and Ergonomics, Advances in
Intelligent Systems and Computing, 7 2018, pp. 168–176.
[43] A. Santoro, S. Bartunov, M. Botvinick, D. Wierstra, and T. Lillicrap,
“One-shot learning with memory-augmented neural networks,” arXiv
preprint arXiv:1605.06065, 2016.
70
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

