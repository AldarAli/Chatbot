Adaptive Online Compressing Schemes Using Flow Information
on Advanced Relay Nodes
Mei Yoshino, Hiroyuki Koga
Graduate School of
Environmental Engineering
University of Kitakyushu, Japan
Email: moeu@net.is.env.kitakyu-u.ac.jp
h.koga@kitakyu-u.ac.jp
Masayoshi Shimamura
Global Scientiﬁc Information
and Computing Center
Tokyo Institute of Technology, Japan
Email: shimamura@netsys.ce.titech.ac.jp
Takeshi Ikenaga
Graduate School of Engineering
Kyushu Institute of Technology, Japan
Email: ike@ecs.kyutech.ac.jp
Abstract—As the number of users and applications continues
to grow, Internet trafﬁc is growing explosively. Excessive trafﬁc
causes network congestion, though, and signiﬁcantly degrades
communication performance. In this paper, we propose adap-
tive online compressing schemes that use ﬂow information on
advanced relay nodes to efﬁciently reduce the amount of trafﬁc
by utilizing network and computational resources. The proposed
schemes compress multiple packets forwarded in the same direc-
tion by utilizing the waiting time. Furthermore, we evaluate the
proposed schemes compared to an adaptive packet compression
scheme previously proposed.
Keywords-adaptive online compression; advanced relay node;
network resource; computational resource
I.
INTRODUCTION
Continual growth in the number of users and the frequent
data exchange of content such as videos and music are causing
Internet trafﬁc to increase explosively. According to [1], mobile
data trafﬁc will grow at a compound annual growth rate of 66
percent from 2012 to 2017, reaching 11.2 exabytes per month
by 2017. When trafﬁc becomes excessive it causes network
congestion, which in turn signiﬁcantly degrades communica-
tion performance. Since network resources are limited, they
must be used efﬁciently to alleviate this problem.
To enable efﬁcient use of network resources, an adap-
tive packet compression scheme has been proposed [2]. This
scheme assumes that advanced relay nodes are located inside
networks and that these nodes possess not only network
resources (i.e., forwarding functions) but also computational
resources (i.e., processing functions) [3]. This scheme com-
presses an incoming packet at the advanced relay nodes while
the packet is waiting in an output queue to transfer when
congestion occurs. The authors showed numerical results in
terms of compression ratio using a data set from an actual
network and conﬁrmed the effectiveness of the adaptive packet
compression scheme [2], [3]. Even though the adaptive packet
compression scheme could reduce the data size by only 5%
(i.e., a compression ratio of 0.95), it improved the packet
discard ratio and delay time.
In this paper, we suggest adaptive online compressing
schemes that use ﬂow information on advanced relay nodes
to improve communication performance by reducing the com-
pressed data size more effectively. A key idea is that the
proposed schemes compress a block generated from multiple
packets forwarded in the same direction (e.g., towards the same
destination host or the same subnet) in an output queue at
advanced relay nodes. For the block compression, we used a
previously reported approach. In [4], to shrink the data size
of archival trafﬁc dump data, the authors focus on correlations
between header ﬁelds among multiple packets. They then show
that the compression ratio can be improved by rearranging
header ﬁelds so as to store similar ﬁelds into a single block.
In our case, since we compress a block of multiple packets
going in the same direction, these packets have similar header
ﬁelds (e.g., the destination IP address). Therefore, we expect
the compression ratio to be improved. However, if the proposed
schemes attempt to compress a large block generated from
many packets, the compression opportunity can be lost. This is
because the proposed schemes cannot gather the packets before
the packets are transmitted from an output queue. To efﬁciently
compress a block, we propose two compression schemes: (1)
a ﬂow compression scheme which compresses packets having
the same 5-tuple header information, and (2) an edge compres-
sion scheme which compresses packets passing through the
same egress edge of advanced relay nodes. Furthermore, we
investigate the effect of the number of compression packets and
the compression time when the proposed schemes are used.
Through simulations, we show the potential and effectiveness
of the proposed schemes.
The remainder of this paper is organized as follows.
In Section 2, we describe related studies in terms of data
compression. In Section 3, we explain the proposed schemes.
We describe the simulation environment in Section 4 and the
simulation results in Section 5. We conclude in Section 6.
II.
RELATED WORK
As stated in Section 1, several data compression schemes
have been proposed. In this section, we ﬁrst describe the
adaptive packet compression scheme, which is the basis of our
proposed schemes. We then describe IPzip from a perspective
of efﬁcient multiple packet compression.
98
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

a
c
a
b
b
b
b
b
a
c
c
a
b
b
b
a
c
a
b
b
a
c
c
a
a
c
a
c
Wai ng  me
a
c
a
b’
b’
b’
Transmi"ed 
packets
Wai ng  me
Compressed 
packets
Figure 1.
Behavior of the proposed schemes
A. Adaptive packet compression scheme
The adaptive packet compression scheme [2] aims to
improve communication performance by efﬁciently using both
network and computational resources. When an advanced relay
node receives a packet, the node calculates the waiting time
of the packet inside its output queue, and then it decides
to compress the packets if the waiting time is sufﬁciently
large. Since it compresses packets by exploiting the waiting
time, the processing time of compression becomes nearly zero.
Therefore, the adaptive packet compression scheme achieves
better online packet compression at advanced relay nodes.
Through data analysis using an actual data set, the authors
found that packets can be classiﬁed into compressible and
incompressible packets. They showed that the average com-
pression ratio of all the packets was 0.945 and that of the
compressible packets was 0.929. These results showed that
actual trafﬁc volume could be reduced by packet compression
even if the compression ratio was high (i.e., less than a 10%
reduction of data size).
In [2], the authors also showed the effectiveness of the
adaptive packet compression scheme through simulation eval-
uation. In this evaluation, the compression ratio was set to
0.95. Simulation results showed that the adaptive packet com-
pression scheme improved the packet discard ratio and delay
time even though it could reduce the data size by only 5%.
B. IPzip
IPzip [4] compresses a block created from multiple packets
and is used to reduce the data size of stored trafﬁc dump data.
The authors focus on similarities among these packets. For ex-
ample, if packets are transferred to the same destination, these
packets have the same destination IP address in their header
ﬁelds. IPzip rearranges header ﬁelds inside stored dump data
so as to collect the same or similar information inside header
ﬁelds, and then it compresses all the data that has rearranged
header ﬁelds. IPzip can achieve better compression with a
low compression ratio through this sophisticated compression
approach.
III.
ADAPTIVE ONLINE COMPRESSING SCHEMES
In this section, we describe adaptive online compressing
schemes. We ﬁrst describe an overview of our idea and then
propose two kinds of compression scheme.
A. Overview
Unlike the adaptive packet compression scheme [2], our
proposed schemes gather multiple packets adaptively in an
output queue at advanced relay nodes and compress them
by utilizing the waiting time. Various criteria can be used
to create blocks: (1) ﬂow (i.e., same source and destination
IP addresses, source and destination port numbers, and proto-
col number), (2) service (i.e., same destination address and
port number, and protocol number), (3) host-by-host (i.e.,
same source and destination addresses), and (4) destination
group (i.e., same network address). The proposed schemes
compress multiple packets forwarded in the same direction
using ﬂow and destination group information (i.e., 5-tuple
header information or information of passing through the same
egress edge of advanced relay nodes). Fig. 1 illustrates an
example of the proposed schemes’ behavior. In this ﬁgure,
multiple packets forwarded in the same direction (packets b)
are grouped and compressed while they are waiting in the
output queue. To compress a block generated from multiple
packets, our proposed schemes need more processing time
than is needed for a packet compression scheme. We deﬁne
the time needed to compress a block as the “compression
time”. Moreover, we deﬁne the number of packets to be
compressed as the “number of compression packets”. Let n be
the compression time and m be the number of compression
packets. The proposed schemes compress m packets forwarded
in the same direction when the queue length is more than n+m
packets. Note that we normalize the compression time using
the packet transmission time, so that we represent the number
of packets as the compression time.
B. Compression schemes
To efﬁciently compress a block, we propose two types of
block compression: a ﬂow compression scheme and an edge
compression scheme. Both generate a block from multiple
packets having the same information in a part of the header
ﬁeld. However, the two schemes generate a block differently.
Flow compression scheme
The ﬂow compression scheme generates a block by using
information related to end nodes. This scheme gathers multiple
packets having the same 5-tuple header information (i.e.,
source and destination IP addresses, source and destination
port numbers, and protocol number) in the output queue, and
generates a block from these.
Edge compression scheme
The edge compression scheme gathers multiple packets
passing through the same egress edge of an advanced relay
node in the output queue, and generates a block from these.
Therefore, this scheme compresses a block containing different
transport ﬂows.
IV.
SIMULATION ENVIRONMENT
In this section, we evaluate the proposed schemes in
comparison with the adaptive packet compression scheme
through simulations. First, we describe the simulation model
and evaluation indices. We use network simulator ver. 2.35 [5]
after implementing the proposed schemes.
A. Simulation model
Fig. 2 shows the network topology. In this simulation
model, congestion can occur at links between an ingress edge
99
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

TABLE I.
SIMULATION PARAMETERS
Buffer size on each node
50 [packet]
Transport layer protocol
TCP with SACK option
Packet size
1500 [Byte]
Number of compression packets
1–20
Compression time
5–30 [packet]
of advanced relay nodes and a core router. A TCP sender node
Si,j sends packets toward a TCP receiver node Ri,j connected
to an egress edge node Ei, where i represents the number of
ingress and egress edge nodes and j represents the number of
end nodes connected to a single edge node. The links between
each ingress or egress edge node and core routers have a
bandwidth of 100 Mb/s and a delay time of 3 ms, while the
bottleneck link between core routers has a bandwidth of 200
Mb/s and a delay time of 5 ms. All other access links between
each sender or receiver node and the ingress edge or egress
edge nodes have a bandwidth of 100 Mb/s and a delay time of
1 ms. The proposed schemes compress packets at ingress edge
nodes and expand them at egress edge nodes. If the compressed
packets are lost, ingress edge nodes retransmit them.
As the simulation parameters, we set the compression
ratio of the adaptive packet compression scheme to 0.95
in accordance with [2]. To determine the compression ratio
of the proposed schemes, we preliminarily investigated the
compression ratio of multiple packets (from 1 to 100) using the
Lempel-Ziv-Oberhumer (LZO) compression algorithm with a
data set from an actual network (4.7 GB, approximately 50
million packets). Through this investigation, we found that
the compression ratio varied approximately from 0.25 to 0.95.
In this simulation, using the mean values of the preliminary
results, we set the compression ratio of the proposed schemes
to 0.6 or 0.5 when the number of compression packets is 5 or
10, respectively. Other simulation parameters are summarized
in Table I.
We investigate the effect of the number of compression
packets on communication performance. In this scenario, the
number of end nodes pairs varies from 9 to 300 (multiplies of
three) and a single TCP ﬂow will ﬂow between each pair of
end nodes, so there are 9 to 300 TCP ﬂows.
B. Evaluation indices
To evaluate the effectiveness of the proposed schemes, we
focus on the total throughput performance as an evaluation
index. The total throughput is calculated by summing the
throughput of all TCP ﬂows from 10 to 30 seconds after the
simulation starts to avoid the inﬂuence of a transient period and
it is averaged over 10 simulation runs with different random
seeds. To analyze the results, we also investigate the number
of compression processings.
V.
SIMULATION RESULTS
In this section, we show evaluation results of the proposed
schemes compared with the performance of the adaptive packet
compression scheme. First, we investigate the throughput per-
formance of each scheme. We then examine the effect of each
parameter on throughput performance.
S11
S12
S13
…
S1N
I1
…
E1
…
I2
…
I3
…
E2
…
E3
100 Mb/s
1 ms
100 Mb/s
3 ms
200 Mb/s
5 ms
100 Mb/s
3 ms
100 Mb/s
1 ms
S: Sender   R: Receiver
I: Ingress    E: Egress
S21
S22
S23
S2N
S31
S32
S33
S3N
R11
R21
R31
R3N-2
R12
R22
R32
R3N-1
R13
R23
R33
R3N
Figure 2.
Simulation topology
A. Throughput characteristics of each scheme
We ﬁrst evaluate the throughput performance of each
scheme. Fig. 3 shows the total throughput of the proposed
schemes, the adaptive packet compression scheme, and a
no-compression scheme (simply relaying all packets without
packet compression) when the number of TCP ﬂows varies
from 9 to 300. In this ﬁgure, “Edge” denotes the edge
compression scheme, “Flow” denotes the ﬂow compression
scheme, “Packet” denotes the adaptive packet compression
scheme, and “Nocomp” denotes the no-compression scheme.
The number of compression packets for the proposed schemes
is set to 5 (the compression ratio is 0.6) or 10 (the compression
ratio is 0.5), while the compression ratio of the adaptive packet
compression scheme is set to 0.95, as described in the previous
section. The compression time is set to the time needed to
forward 5 packets.
Figs. 3(a) and 3(b) show that the total throughput of the
edge and ﬂow compression schemes is higher than that of
the other schemes regardless of the number of compression
packets. The throughput of the proposed schemes exceeds the
bottleneck link bandwidth by effectively compressing multiple
packets, while that of the adaptive packet compression and
no-compression schemes is limited by the bandwidth. In the
case of a small number of compression packets, the ﬂow
compression scheme attains higher throughput than the edge
compression scheme over a wide range of the number of
TCP ﬂows. However, the throughput of the ﬂow compression
scheme decreases as the number of TCP ﬂows increases when
the number of compression packets is large.
Let’s investigate the reason for the above phenomenon.
Figs. 4(a) and 4(b) respectively show the number of compres-
sion processings for each scheme when the number of TCP
ﬂows varies from 9 to 300 and when the number of compres-
sion packets of the proposed schemes is set to 5 or 10. The
number of compression processings is approximately the same
for the ﬂow and edge compression schemes when the number
100
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

 160
 180
 200
 220
 240
 260
 280
 300
 320
9 27 45 63 81 99
198
300
Total throughput [Mb/s]
Number of TCP flows 
Edge
Flow
Packet
Nocomp
(a) Number of compression packets: 5
 160
 180
 200
 220
 240
 260
 280
 300
 320
9 27 45 63 81 99
198
300
Total throughput [Mb/s]
Number of TCP flows 
Edge
Flow
Packet
Nocomp
(b) Number of compression packets: 10
Figure 3.
Throughput performance
of TCP ﬂows is less than 63. On the other hand, the number
of compression processings of the ﬂow compression scheme
falls as the number of TCP ﬂows increases, especially in the
case of a large number of compression packets, while that of
the edge compression scheme increases as the number of TCP
ﬂows increases. This is because the ﬂow compression scheme
has difﬁculty gathering multiple packets having the same ﬂow
information due to the limited buffer size. Compared to the
ﬂow compression scheme, the edge compression scheme can
compress packets much more often because each of the ingress
edge nodes needs to handle only three types of packet going
toward the egress edge nodes. Therefore, the edge compression
scheme can better maintain throughput performance than can
the ﬂow compression scheme in the case of a large number of
compression packets.
The above results demonstrate that the proposed schemes
can improve throughput performance compared with the other
schemes. In the following subsection, we discuss the effect
of each parameter of the proposed schemes on the throughput
performance.
B. Effect of each parameter
To analyze the performance between the ﬂow and edge
compression schemes in detail, we investigate the effect of
 0
 20000
 40000
 60000
 80000
 100000
9 27 45 63 81 99
198
300
Number of compression 
 processings
Number of TCP flows 
Edge
Flow
Packet
(a) Number of compression packets: 5
 0
 20000
 40000
 60000
 80000
 100000
9 27 45 63 81 99
198
300
Number of compression 
 processings
Number of TCP flows 
Edge
Flow
Packet
(b) Number of compression packets: 10
Figure 4.
Number of compression processings
each parameter on the throughput performance. The perfor-
mance of the proposed schemes depends on how many packets
are successfully compressed. Namely, the main factors deter-
mining performance are the number of compression packets
and the compression time. In this subsection, we examine the
effect of these parameters on the throughput performance and
the number of compression processings.
First, we focus on the effect of the number of compression
packets on the throughput performance. Figs. 5(a) and 5(b)
show the total throughput and the number of compression
processings of each scheme when the number of compression
packets varies from 1 to 20, respectively. The number of TCP
ﬂows is set to 198, where the number of compression packets
has a signiﬁcant impact on the throughput performance of the
ﬂow and edge compression schemes as shown in Fig. 3. The
compression ratio is set to the average value of 0.6 regardless
of the number of compression packets in order to focus on the
opportunity of compression in the ﬂow and edge compression
schemes. The compression time is set to 5 packets.
As shown in Fig. 5(a), the ﬂow compression scheme
enables excellent throughput when the number of compres-
sion packets is small, especially in the case of 5. However,
the throughput of the ﬂow compression scheme drastically
decreases as the number of compression packets increases. On
101
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

the other hand, the throughput of the edge compression scheme
increases as the number of compression packets increases.
Consequently, the edge compression scheme maintains high
throughput over a wide range of the number of compression
packets.
In order to understand the reason for this, let’s consider
the number of compression processings shown in Fig. 5(b).
The number of compression processings in the ﬂow compres-
sion scheme drastically decreases as the number of compres-
sion packets increases. This is because the ﬂow compression
scheme has difﬁculty gathering multiple packets having the
same ﬂow information due to the limited buffer size as
discussed in the previous subsection. On the other hand,
although the number of compression processings in the edge
compression scheme decreases as the number of compression
packets increases, it remains higher than that in the ﬂow
compression scheme when the number of compression packets
is large. That is, compared to the ﬂow compression scheme, the
edge compression scheme can compress packets much more
often because each of the ingress edge nodes has to handle only
three types of packet going toward the egress edge nodes.
These results demonstrate that the ﬂow compression
scheme enables higher throughput than the edge compression
scheme with a small number of compression packets, while
the edge compression scheme maintains high throughput with
a large number of compression packets. The ﬂow compression
scheme gathers multiple packets having the same 5-tuple
header information; i.e., that belong to a ﬂow. In contrast,
the edge compression scheme gathers multiple packets passing
through the same egress edge nodes; i.e., that belong to
multiple ﬂows. With a small number of compression packets,
since the opportunity of compression between the ﬂow and
edge compression schemes is almost the same, the ﬂow
compression scheme can rapidly increase the throughput of
the ﬂow, while the edge compression scheme can increase the
throughput of the multiple ﬂows only gradually. Therefore,
the ﬂow compression scheme can maintain a large number of
compression processings as well as excellent throughput. On
the other hand, with a large number of compression packets,
the compression opportunity in the ﬂow compression scheme
is much smaller than that in the edge compression scheme.
As a result, the edge compression scheme can obtain higher
throughput than that of the ﬂow compression scheme.
Next, we focus on the effect of compression time on the
throughput performance. Figs. 6(a) and 6(b) respectively show
the total throughput of each scheme when the compression
time varies from 5 to 30 packets and when the number
of compression packets of the proposed schemes is set to
5 (compression ratio: 0.6) or 10 (compression ratio: 0.5).
The number of TCP ﬂows is set to 198. The throughput
of the ﬂow and edge compression schemes increases as the
compression time decreases. That is, the proposed schemes
improve the performance as the processing speed on the edge
nodes will have been higher. Similar to the results above, the
ﬂow compression scheme enables higher throughput than the
other schemes with a small number of compression packets.
However, the throughput of the ﬂow compression scheme de-
creases as the compression time increases and is appropriately
equal to that of the edge compression scheme with a large
compression time. On the other hand, with a large number
 180
 200
 220
 240
 260
 280
 300
 320
 5
 10
 15
 20
Total throughput [Mb/s]
Number of compression packets
Edge
Flow
Packet
(a) Throughput
 0
 20000
 40000
 60000
 80000
 100000
 5
 10
 15
 20
Number of compression 
 processings
Number of compression packets
Edge
Flow
Packet
(b) Number of compressing processings
Figure 5.
Effect of the number of compression packets
of compression packets, the edge compression scheme attains
higher throughput than the other schemes over a wide range
of compression time.
Figs. 7(a) and 7(b) respectively show the number of com-
pression processings when the compression time varies from
5 to 30 packets and when the number of compression packets
of the proposed schemes is set to 5 (compression ratio: 0.6)
or 10 (compression ratio: 0.5). The number of TCP ﬂows is
set to 198. The number of compression processings of each
scheme decreases as the compression time increases because
a large compression time reduces the buffer capacity available
to gather multiple packets having the same information as well
as the compression opportunity. With a small number of com-
pression packets, the ﬂow compression scheme attains a larger
number of compression processings than the edge compression
scheme when the compression time is small. However, with a
large compression time, there are no differences between the
number of compression processings of each scheme. On the
other hand, with a large number of compression packets, the
number of compression processings of the edge compression
scheme exceeds that of the ﬂow compression scheme and is as
large as that of the adaptive packet compression scheme with
a large compression time.
These results demonstrate that the proposed schemes can
102
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

 175
 200
 225
 250
 275
 5
 10
 15
 20
 25
 30
Total throughput [Mb/s] 
Compression time [packet]
Edge
Flow
Packet
(a) Number of compression packets: 5
 175
 200
 225
 250
 275
 5
 10
 15
 20
 25
 30
Total throughput [Mb/s] 
Compression time [packet]
Edge
Flow
Packet
(b) Number of compression packets: 10
Figure 6.
Effect of compression time: Throughput
improve the throughput by adaptively compressing multiple
packets gathered in an output queue at edge nodes through
utilization of the waiting time. The ﬂow compression scheme
enables high throughput with a small number of compression
packets and a small compression time. Otherwise, the edge
compression scheme enables higher throughput.
VI.
CONCLUSION
To improve communication performance by efﬁciently
decreasing Internet trafﬁc, we have proposed adaptive online
compression schemes that use ﬂow information in advanced
relay nodes. The proposed schemes gather adaptively multiple
packets forwarded in the same direction in an output queue
at advanced relay nodes and compress them by utilizing the
waiting time. Through evaluations by simulation, we have
shown that the proposed schemes enable high communica-
tion performance by compressing multiple packets. The ﬂow
compression scheme enables high throughput with a small
number of compression packets and a small compression
time. Otherwise, the edge compression scheme enables higher
throughput. In our future work, we will design dynamic online
compression algorithms that can adapt compression methods to
network conditions and evaluate the proposed schemes using
 0
 10000
 20000
 30000
 40000
 50000
 60000
 70000
 80000
 90000
 5
 10
 15
 20
 25
 30
Number of compression 
processings
Compression time [packet]
Edge
Flow
Packet
(a) Number of compression packets: 5
 0
 10000
 20000
 30000
 40000
 50000
 60000
 70000
 80000
 90000
 5
 10
 15
 20
 25
 30
Number of compression 
processings
Compression time [packet]
Edge
Flow
Packet
(b) Number of compression packets: 10
Figure 7.
Effect of compression time: Number of compression processings
a prototype implementation from a viewpoint of the computa-
tional resources (processing time, memory usage, etc.).
ACKNOWLEDGMENT
This work was supported in part by the Japan Society for
the Promotion of Science, Grant-in-Aid for Young Scientists
(B) (No. 25730063).
REFERENCES
[1]
Cisco Systems, Inc., “Cisco visual networking index: Global mobile data
trafﬁc forecast update, 2012–2017,” Feb. 2013. Information available
at
http://www.cisco.com/en/US/solutions/collateral/ns341/ns525/ns537/
ns705/ns827/white paper c11-520862.pdf. [Retrieved: Dec. 2013]
[2]
M. Shimamura, H. Koga, T. Ikenaga, and M. Tsuru, “Compressing pack-
ets adaptively inside networks,” IEICE Transactions on Communications,
vol. E93-B, no. 3, Mar. 2010, pp. 501–515.
[3]
M. Shimamura, T. Ikenaga, and M. Tsuru, “A design and prototyping
of in-network processing platform to enable adapting network service,”
IEICE Transactions on Information and Systems, vol. E96-D, no. 2,
Feb. 2013, pp. 238–248.
[4]
S. Chen, S. Ranjan, and A Nucci, “IPzip: A stream-aware IP compres-
sion algorithm,” Proc. IEEE Data Compression Conference (DCC’08),
Mar. 2008, pp. 182–191.
[5]
The
Network
Simulator,
http://www.isi.edu/nsnam/ns.
[Retrieved:
Dec. 2013]
103
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-318-6
ICN 2014 : The Thirteenth International Conference on Networks

