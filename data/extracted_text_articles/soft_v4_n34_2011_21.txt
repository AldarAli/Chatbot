489
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
An Augmented Reality Platform for the Enhancement  
of Surgical Decisions in Pediatric Laparoscopy 
Lucio Tommaso De Paolis, Giovanni Aloisio 
Department of Innovation Engineering 
University of Salento 
Lecce, Italy 
lucio.depaolis@unisalento.it 
giovanni.aloisio@unisalento.it 
 
 
Abstract— The practice of Minimally Invasive Surgery is 
becoming more and more widespread and adopted as an 
alternative to the classical procedure. This technique presents 
many advantages for the patients, but also some limitations for 
the surgeons. In particular, the lack of depth in perception and 
the difficulty in estimating the distance of the specific 
structures in laparoscopic surgery can impose limits on 
delicate dissection or suturing. The presence of new systems for 
the pre-operative planning can be of great help to the surgeon. 
The use of the Augmented Reality technology shows a way 
forward in bringing the direct advantage of the visualization of 
the open surgery back to minimally invasive surgery and can 
increase for the physician the view of the organs with 
information obtained from the image processing of the patient. 
The developed application allows the surgeon to get 
information about the patient and her/his pathology, 
visualizing and interacting with the 3D models of the organs 
built from the patient’s medical images, measuring the 
dimensions of the organs and deciding the best insertion points 
of the trocars in the patient’s body. This choice can be 
visualized on the real patient using the Augmented Reality 
technology. 
Keywords - Augmented Reality; medical image processing;  
user interface; minimally invasive surgery; preoperative surgical 
planning 
I. 
 INTRODUCTION 
One trend in surgery is the transition from open 
procedures 
to 
minimally 
invasive 
laparoscopic 
interventions, where visual feedback to the surgeon is only 
possible through the laparoscope camera and direct 
palpation of organs is not possible. 
Minimally Invasive Surgery (MIS), such as laparoscopy 
or endoscopy, has become very important and the research 
in this field is more and more widely accepted. These 
techniques offer the possibility to surgeons of reaching the 
patient’s internal anatomy in a less invasive way and 
causing only a minimal trauma to patients.  
The diseased area is reached by means of small incisions 
in the body, called ports. Specific instruments and a camera 
are inserted through these ports; during the operation a 
monitor shows what is going on inside the body. The 
surgeon does not have a direct vision of the organs and thus 
he is guided by camera images; this is very different from 
what happens in open surgery because there is no possibility 
to touch the organs. 
The laparoscopic access is an alternative to the open entry 
techniques because it aims to prevent visceral and vascular 
injury due to division of abdominal wall layers. The reasons 
of a limited use of the open-access method is due to the time 
needed for the performance, the difficulty in maintaining the 
pneumoperitoneum because of the gas leakage and the lack 
of a particular evidence for the prevention of intra-
abdominal injury using this method. 
 The vascular injury during the first laparoscopic access is 
the first cause of death in laparoscopy, second only to 
anesthesia and bowel injury, with a reported mortality rate 
of 15%.  
Unlike most of vascular injuries, where the occurrence 
and presentation are immediate, many bowel injuries are not 
recognized at the time of the procedure because of the 
suboptimal visualization.  
To overpass the several complications in the laparoscopic 
access, optically guided trocars are designed to decrease the 
risk of injury to intra-abdominal structures allowing the 
surgeon to visualize abdominal wall layers during the 
placement. 
As a promising technique, the practice of MIS is 
becoming more and more widespread and is being adopted 
as an alternative to classical procedures. 
Shorter hospitalizations, faster bowel function return, 
fewer wound-related complications and a more rapid return 
to normal activities have contributed to accept these surgical 
procedures. 
The advantages of this surgical method are evident on the 
patients, but these techniques involve some limitations to 
surgeons; due to the limited field of view, the position and 
the orientation of the camera require frequently adjustments 
and significant hand-eye coordination is necessary because 
the instrument movements visualized on the screen not 
match the surgeon’s hand movements. 
In addition, the imagery is in 2D and the surgeon can 

490
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
estimate the distance of anatomical structures only by 
moving the camera. In laparoscopic surgery, the lack of 
depth perception and the difficulty in estimating the distance 
from the anatomical structures can impose limitations on 
delicate dissection or suturing. 
Motivated by the benefits that MIS can bring to patients, 
many research groups are now focusing on the development 
of systems in order to assist the surgeons during the surgical 
procedures and to carry out their tasks in both faster and 
safer ways. Other research groups have developed solutions 
to support the preoperative surgical planning and the intra-
operative surgical procedure. 
Even though the interpretation of the computed 
tomography (CT) or the magnetic resonance images (MRI) 
remains a difficult task, the latest developments in medical 
imaging processing make possible the reconstruction of 3D 
models of the organs providing anatomical information 
barely detectable by CT and MRI slices or ultrasound scan 
and an accurate knowledge of patient’s anatomy and 
pathologies as well.  
A suitable use of these models could lead to an 
improvement in patient care by guiding the instruments 
through the body without the direct sight of the physician; in 
addition, these models can be the bases to build the realistic 
virtual environment used in Virtual Reality and Augmented 
Reality applications. 
This paper presents an advanced platform for the 
visualization and the interaction with the 3D patient models 
of the organs built from CT images [1].  
The presence of a system for the pre-operative planning 
can help the surgeon very much and this support is more and 
more important in pediatric laparoscopic surgery where you 
have to understand the exact conditions of the patient’s 
organs and the precise location of the operational site. 
The developed application allows the surgeon to choose 
the points for the insertion of the trocars on the virtual 
model and to overlap them, before starting the real surgical 
procedure, on the real patient body using the Augmented 
Reality technology. 
II. 
THE AUGMENTED REALITY IN SURGERY 
Appropriate visualization tools and techniques play an 
important role in providing detailed information about 
human organs, pathologies and realistic 3D models of the 
organs of the specific patient. The utilization of visual 
information together with the operation techniques help the 
surgeon during the surgical procedure and provide a 
possible solution to the problems that minimally invasive 
surgery can present. 
In addition, the integration with the Virtual Reality 
technology can change surgical preparation and the 
surgeons can practice and perform a surgical procedure 
before the patient arrives in the operating room; this 
involves not only a reduction of complications, but also 
individual components of the surgery can be honed to 
precision. 
The use of the Augmented Reality technology shows a 
way forward in bringing the direct advantage of the 
visualization of the open surgery back to minimally invasive 
surgery and can increase for the physician the view of the 
organs with information obtained from the image processing 
of the patient [2]. 
Augmented Reality can avoid some drawbacks of MIS 
and can lead to new medical treatments. 
The Augmented Reality research aims to allow the real-
time fusion between the computer-generated digital content 
and the real world. Thanks to Augmented Reality, it is 
possible to see hidden objects and therefore to enhance the 
users' perception and to improve the interaction with the real 
world. The virtual objects, displaying what the users cannot 
detect directly with their own senses, help them to perform 
real-world tasks better. 
In opposition to Virtual Reality technology that gets into 
a synthetic environment but doesn’t make possible the 
vision of the real world, Augmented Reality technology 
allows to see 3-dimensional virtual objects superimposed 
upon the real world. 
Therefore, AR supplements reality rather than completely 
replace it. The user has a feeling that the virtual and real 
objects coexist in the same space. 
Azuma [3] presents a survey of AR and describes the 
characteristics of AR systems, registration and sensing 
errors together with the efforts to overcome them. Using 
Azuma’s definition, an AR system has to fulfil the 
following three characteristics: 
• Real and virtual objects are united in a real 
environment, they appear to coexist in the same 
space; 
• The system is interactive and it performs in real-
time; 
• The virtual objects are registered with the real world. 
Milgram and Kishino [4] defined the Mixed Reality as an 
environment “in which real world and virtual world objects 
are presented together within a single display, that is, 
anywhere between the extrema of the virtuality continuum”  
The Virtuality Continuum extends from the completely 
real through to the completely virtual environment with 
Augmented Reality and Augmented Virtuality ranging 
between. 
Thus Augmented Reality is a mixture of reality and 
virtual reality. It includes both virtual objects and real-world 
elements, but the surrounding environment is real.  
Fig. 1 shows the Milgram’s reality-virtuality continuum. 
In order to have a true AR application, the computer-
generated organs must be accurately positioned on the real 
ones. For this reason it is necessary to carry out an accurate 

491
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
registration phase, which provides, as result, the correct 
overlapping of the 3D model of the virtual organs on the 
real patient [5], [6], [7]. 
In medical applications of the Augmented Reality 
technology, the right detection and the overlapping of the 
fiducial points are very important because even a very slight 
mistake could have very serious consequences on the 
patient. 
 
 
Figure 1.  Milgram’s reality–virtuality continuum 
The integration of the registration algorithm into the 
surgical workflow requires a trade-off of complexity, 
accuracy and invasiveness. The process of registration can 
be obtained using the optical (infrared) tracking systems that 
are the best choice at the moment; these devices are already 
in use in the modern operating rooms. 
For the registration of patient data with the AR system it 
is possible to have a point-based registration approach 
where specific fiducials can be used and fixed on the of the 
patient. These fiducials are touched with a tracked pointer 
and their positions have to match the correspondent 
positions of fiducials placed during the patient scanning and 
segmented in the 3D model. Point-based registration is 
known to be a reliable solution if the set of fiducials is 
carefully chosen. The accuracy depends on the number of 
fiducials, the quality of measurement and the spatial fiducial 
arrangement [8]. 
The simple augmentation of the real scene is not realistic 
enough because, although the organ positions are computed 
correctly, the relative position in depth of real and virtual 
images may not be perceived. 
Indeed, in AR applications, although virtual objects have 
been correctly positioned in the scene, they are visually 
overlapped with all real objects, creating a situation that is 
not sufficiently realistic.  
In particular, this effect is not acceptable for surgical AR 
applications and it is necessary, in addition to a proper 
positioning of the organs in the virtual scene, in order to 
ensure a correct visualization. 
Some solutions have been proposed, but the issue of 
correct depth visualization remains partially unsolved. 
Augmented Reality provides an intuitive human-
computer interface. In surgery this technology makes it 
possible to overlay virtual medical images on the patient, 
allowing surgeons to have a sort of “X-ray vision” of the 
body and providing a view of the patient’s anatomy. 
Augmented Reality technology offers the same visual 
advantages as open surgery in minimally invasive surgery 
and increases the physician’s visual knowledge with 
information gathered from patients’ medical images. 
The patient becomes transparent and this virtual 
transparency makes it possible to find tumours or vessels 
not using the touch, but simply visualizing them thanks to 
augmented reality. 
The virtual information can be displayed directly on the 
patient’s body or visualized on an AR surgical interface, 
showing where the operation must be performed. 
For instance, a physician might also be able to see the 
exact location of a lesion on a patient's liver or the right 
place where to drill a hole on the skull in brain surgery or 
where to perform a needle biopsy of a tiny tumour. 
In general, AR technology may be used in minimally 
invasive surgery for: 
• Training purposes; 
• Preoperative planning; 
• Advanced visualization during the real procedure. 
AR technology in minimally invasive surgery may be 
used for training purposes, pre-operative planning and 
advanced visualization during the real procedure. Several 
research groups are exploring the use of AR in surgery and 
are developing many image-guided surgery systems. 
Devernay et al. [9] propose the use of an endoscopic AR 
system for robotically assisted minimally invasive cardiac 
surgery. One of the problems closely linked to endoscopic 
surgery is that, because of the narrow field of view, 
sometimes it is quite difficult to locate the objects seen 
through the endoscope. The information coming from the 
3D anatomical model of the patient’s organs (built from 
MRI or CT-scan) and the position of the endoscope are not 
sufficient because some organs are displaced by the inflated 
gas. They propose a methodology to achieve coronary 
localization by Augmented Reality on a robotized 
stereoscopic endoscope adding “cartographic” information 
on the endoscopic view and by indicating the position of the 
coronaries with respect to the field of view. 
Bichlmeier et al. [10], [11] focus on the problem of 
misleading perception of depth and spatial layout in medical 
AR and present a new method for medical in-situ 
visualization that allows for improved perception of 3D 
medical imaging data and navigated surgical instruments 
relative to the patient’s anatomy.  They describe a technique 
to modify the transparency of video images recorded by the 
colour cameras of a video see-through HMD. The presented 
method allows for an intuitive view on the deep-seated 
anatomy of the patient providing visual cues to perceive 
correctly absolute and relative distances of objects within an 
AR scene. The results can be applied for designing medical 
AR training and educational applications. Fig. 8 shows an 
application of the developed method. The medical AR scene 

492
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
is presented to the observer using an “AR window” [20]. 
Samset et al. [12] present tools based on novel concepts 
in visualization, robotics and haptics providing tailored 
solutions for a range of clinical applications. Examples from 
radio-frequency ablation of liver-tumours, laparoscopic liver 
surgery and minimally invasive cardiac surgery will be 
presented. 
Navab et al. [13], [14] introduce the concept of a 
laparoscopic virtual mirror: a virtual reflection plane within 
the live laparoscopic video that is able to visualize a 
reflected side view of the organ and its interior. The 
Laparoscopic Virtual Mirror is able to reflect virtually the 
3D volume as well as the laparoscope or any other modelled 
and tracked instruments. Combining this visualization 
paradigm with a registration-free augmentation system for 
laparoscopic surgery, it is possible to get a powerful medical 
augmented reality system that could make minimally 
invasive surgeries easier and safer to perform. 
Kalkofen et al. [15] overlay carefully synthetic data on 
top of the real world imagery by taking into account the 
information that is about to be occluded by augmentations 
as well as the visual complexity of the computer-generated 
augmentations added to the view. They solve the problem of 
augmentations occluding useful real imagery with edges 
extracted from the real video stream.  
De Paolis et al. [16] present an Augmented Reality 
system that can guide the surgeon in the operating phase in 
order to prevent erroneous disruption of some organs during 
surgical procedures. Since the simple augmentation of the 
real scene cannot provide information on the depth, a sliding 
window is provided in order to allow the occlusion of part 
of the organs and to obtain a more realistic impression that 
the virtual organs are inside the patient’s body. In addition, 
distance information is provided to the surgeon and an 
informative box is shown in the screen in order to visualize 
the distance between the surgical instrument and the organ 
concerned. When the distance between the surgical 
instrument and some specified organs is under a safety 
threshold, a video feedback as well as an audio feedback in 
the form of an impulse are provided. The frequency of this 
impulse increases when the distance between the surgical 
instrument and the organ concerned decreases. 
Soler et al. [17] present the results of their research into 
the application of AR technology in laparoscopic and 
NOTES (Natural Orifice Transluminal Endoscopic Surgery) 
procedures. They have developed two kinds of AR software 
tools (Interactive Augmented Reality and Fully Automatic 
Augmented Reality) taking into account a predictive 
deformation of organs and tissues during the breathing cycle 
of the patient. A preclinical validation has been performed 
on pigs and results are very encouraging and represent the 
first phase for surgical gesture automation that will make it 
possible to reduce surgical mistakes. 
The collaboration between the MIT Artificial Intelligence 
Lab and the Surgical Planning Laboratory of Brigham [18] 
has led to the development of solutions that support the 
preoperative surgical planning and the intraoperative 
surgical guidance. 
Papademetris et al. [19] describe the integration of image 
analysis 
methods 
with 
a 
commercial 
image-guided 
navigation system for neurosurgery (the BrainLAB 
VectorVision Cranial System). 
III. 
THE INFORMED CONSENT 
In the current climate of increasing awareness, patients 
are demanding more knowledge of the operative process. 
The term "informed consent" explains the process by which, 
before treatment, comprehensive and impartial information 
regarding a planned operative procedure is provided to a 
patient so that he can understand the implications of the 
procedure before consenting. 
Informed consent is a process of communication between 
patient and physician that results in the patient's 
authorization or agreement to undergo a specific medical 
intervention.  
In the communications process the physician discusses 
with the patient about the patient's diagnosis (if known), the 
nature and purpose of a proposed treatment or procedure, 
the risks and benefits of a proposed treatment or procedure, 
the risks and benefits of an alternative treatment or 
procedure and the risks and benefits of not receiving or 
undergoing a treatment or procedure. 
Bollschweiler et al. [20] present the results of the study of 
a new method of consenting improved using a multimedia-
based 
information 
program 
(MM-IP). 
80 
patients 
undergoing laparoscopic cholecystectomy went through the 
standard informed consent process and a group of patients 
were also given access to a MM-IP. Questionnaires were 
used to evaluate the effectiveness of the MM-IP for 
improving the consent process and were completed before 
surgery in order to evaluate how patients perceived their 
own understanding of important aspects of their illness. 
Patients positively evaluated the use of the MM-IP.  
Eggers et al. [21] present a multimedia program aimed at 
obtaining informed consent from obese patients before 
gastric banding. The result emphasizes that the multimedia 
program clearly benefits both surgeons and patients, but the 
personal contact with the surgeon remains essential because 
the information presented in multimedia format do not 
alleviate patient anxiety. 
Wilhelm et al. [22] evaluate the impact of an extended 
education on patients undergoing cholecystectomy. For 
extended patient information, a professionally built DVD 
was used and the quality of education was evaluated using a 
purpose-built questionnaire. They prove the positive impact 
of 
an 
information 
DVD 
on 
patients 
knowledge; 

493
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
nevertheless, they assert that the multimedia tools cannot 
replace personal interaction and should only be used to 
support daily work. 
IV. 
THE 3D MODELS OF PATIENT’S ORGANS 
In MIS, the use of images registered to the patient is a 
prerequisite for both the planning and the guidance of this 
kind of operations. From the medical image of the patient 
(MRI or CT) it is possible to obtain an efficient 3D 
reconstruction of his anatomy and improve the standard 
slice view by means of the visualization of the 3D models of 
the organs.  
The 3D models of the patient’s anatomy are built from 
the medical images (MRI or CT) of a patient by means of 
the 
application 
of 
segmentation 
and 
classification 
algorithms. The grey levels in the medical images are 
replaced by colours and associated to the different organs. 
Several research teams deal with the task of segmentation 
and developed techniques that allow extracting the patient’s 
organs from CT-scan or MRI automatically or interactively. 
Nowadays there are different software used in medicine 
for the visualization and the analysis of scientific images 
and the 3D modelling of human organs; Mimics [23], 3D 
Slicer [24], ParaView [25] OsiriX [26] and ITK-SNAP [27] 
play an important role among these tools. 
In our case studies, the 3D models of the patient’s organs 
have 
been 
reconstructed 
using 
segmentation 
and 
classification algorithms provided by ITK-SNAP and by 3D 
Slicer.  
ITK-SNAP provides semi-automatic segmentation using 
active contour methods as well as manual delineation and 
image navigation; it also fills a specific set of biomedical 
research needs. 
 
 
Figure 2.  An example of the image processing using ITK-SNAP. 
3D Slicer is a multi-platform, free and open-source 
software package for visualization and medical image 
computing. The platform provides functionality for 
segmentation, 
registration 
and 
three-dimensional 
visualization of multi-modal image data. 
Fig. 2 shows the result of the image processing using 
ITK-SNAP; the skin and the muscles of the abdominal 
region are displayed in total transparency and the tumour is 
shown in magenta. 
V. 
THE CASE STUDIES 
We processed two different case studies: the first case 
study, shown in Fig. 3, concerns a two-year-old child with a 
benign tumour of the right kidney; the second case study, 
shown in Fig. 4, concerns a twelve-year-old child with a 
tumour of the peripheral nervous system (ganglioneuroma). 
 
 
Figure 3.  3D model of a child with a tumour at the kidney. 
The slice thickness equal to 3 mm has caused some 
aliasing effects on the reconstructed 3D models that could 
lead to inaccuracies. Therefore we have paid special 
attention to the smoothing of the reconstructed models in 
order to maintain a good correspondence with the real 
organs. 
In our application, the mesh editing has been carried out 
using the open-source MeshLab software application [28]. 
A radiologist has validated the obtained 3D models. 
VI. 
THE USED TECHNOLOGIES 
In the application, it is necessary to use an optical tracker 
in order to detect without delay the right position and 
orientation of the surgical tool used by the surgeon. The 
tracking system is also used in order to permit the 
overlapping of the virtual organs on the real ones in the 

494
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
augmented visualization of the scene during the real surgical 
procedure. 
Among the different tracking systems based on 
mechanical, optical or visual technologies, we chose an 
optical tracker (the Polaris Vicra of the NDI Inc.) in order to 
avoid the problems typical of the mechanical systems 
associated to the use of metal devices. 
 
 
Figure 4.  Virtual model of a child with a ganglioneuroma. 
The Polaris Vicra optical system [29] tracks both active 
and passive markers and provides precise, real-time spatial 
measurements of the location and orientation of an object or 
tool within a defined coordinate system. 
The system uses a position sensor to detect infrared-
emitting or retro-reflective markers affixed to a tool or 
object; using the information received from the markers, the 
sensor is able to know position and orientation of the tools 
within a specific measurement volume. The system consists 
of 2 IR cameras and some tools with reflective beads placed 
on known geometry frames. The system can calculate the 
real position of the tool in the space with an accuracy of 0.2 
mm and 0.1 of a degree. 
The tracking technology is usually used in the modern 
operating rooms and provides an important help to enhance 
the performance during the real surgical procedures. 
VII. THE USER INTERFACE 
The developed application is supplied with a specific user 
interface that allows the user to take advantage of the 
feature offered by the software. The application is provided 
of 4 sections with the aim to provide support to the surgeons 
in the different steps of the surgical procedure such as the 
study of the case, the diagnosis, the pre-operative planning, 
the choice of the trocar entry points and the simulation of 
the surgical instruments interaction. 
Starting from the models of the patient’s organs, the 
surgeon can note some data about the patient, collect 
information about the pathology and the diagnosis, choose 
the most appropriate positions for the trocar insertion and 
overlap these points on the patient’s body using the 
Augmented Reality technology.  
By means of the user interface it is possible to display all 
the organs of the abdominal region or just some of these 
using the show/hide functionality; it is also possible to 
change the transparency of each organ. 
It is possible to use this platform in order to describe the 
pathology, the surgical procedure and the consequent risks 
to the child’s parents, with the aim of obtaining informed 
consent for the surgical procedure. 
VIII. THE DEVELOPED APPLICATION 
In the developed application, as shown in Fig. 5, all the 
patient’s information (personal details, diseases, specific 
pathologies, diagnosis, medical images, 3D models of the 
organs, notes of the surgeon, etc.) are structured in a XML 
file associated to each patient. 
 
 
Figure 5.  Patient’s data collected in an XML file. 
A specific section for the pre-operative planning includes 
the visualization of the virtual organs. The physician can get 
some measurements of organ or pathology sizes and some 
distances.  
For the computation of the distance between a pair of 
points we have used the PQP library (Proximity Query 
Package) [30]. This section is shown in Fig. 6.  
By means of a detailed view of the 3D model, the surgeon 
can choose the trocar entry points and check if, with this 
choice, the organs involved in the surgical procedure can be 
reached and the procedure can be carried out in the best 
way. 

495
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Fig. 7 shows the specific section of the user interface for 
the interaction with the 3D models of the patient’s organs. 
By means of a detailed view of the 3D model, the surgeon 
can choose the trocar entry points and check if, with this 
choice, the organs involved in the surgical procedure can be 
reached and if the choice allows carrying out the procedure 
in the best way [31]. 
 
 
Figure 6.  Example of a measurement of organs. 
Complications associated with starting first abdominal 
entry are the first concern for laparoscopic surgeons. In 
order to minimize first access-related complications in 
laparoscopy, several techniques and technologies have been 
introduced in the last years.  
The problem of blind access is that it may imply vascular 
injuries caused by the blind entry of instruments in the 
abdominal cavity. This problem can be solved with the 
direct visualization of under-layer viscera and vessels. 
 
 
Figure 7.  Section for the interaction with the organs. 
Sometimes, using the standard insertion points for the 
surgical tools, also a simple surgical procedure can be very 
difficult because of the specific anatomy of the different 
patients. The surgeon can find it difficult to reach the 
specific organ or to interact with the surgical tools. In this 
case he has to choose another insertion point in order to be 
able to carry out the surgical procedure in the most suitable 
way. 
Our aim is to avoid the occurrence of this situation during 
the real surgical procedure using the visual information 
provided by means of the 3D models of the patient’s 
anatomy. 
In the developed application, in order to verify if the 
chosen insertion points allow reaching properly the specific 
organ interested to the surgical operation and permitting to 
carry out the procedure in a correct way, it is also possible 
to simulate the interaction of the surgical instruments.  
 
 
Figure 8.  Section for the choice of the trocar insertion.  
Our application, by means of an Augmented Reality 
module, supports the placement of the trocars on the real 
patient during the surgery procedure and simulates the 
insertion of the trocars in the patient body in order to verify 
the correctness of the chosen insertion sites.  
The Augmented Reality surgery guidance aims to 
combine a real view of the patient on the operating table 
with virtual renderings of structures that are not visible to 
the surgeon. In this application we use the AR technology in 
order to visualize on the patient’s body the precise location 
of selected points on the virtual model of the patient. 
For the augmented visualization, in order to have a 
correct and accurate overlapping of the virtual organs on the 
real ones, a registration phase is carried out; this phase is 
based on fiducial points and on the use of an optical tracker.  
Fig. 8 shows the section for the accurate choice of the 
trocar insertion points. 
Using the augmented visualization, the chosen entry 
points for the trocars can be visualized on the patient’s body 
through the Augmented Reality technique in order to 
support the physician in the real trocar insertion phase.  
Fig. 9 shows the specific section for the simulation of the 

496
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
surgical tools interaction with the possibility to move the 
trocar entry points using the arrows. 
 
 
Figure 9.  Simulation of the surgical tools interaction. 
Fig. 10 shows the augmented visualization of the chosen 
trocar entry points overlapped on the patient's body (a 
dummy). The yellow points are the fiducials used for the 
registration phase and the red ones are the trocar insertion 
points. 
 
 
Figure 10.  The augmented visualization. 
IX. 
USABILITY TESTS 
In order to evaluate the validity and the usability of the 
developed application and to receive possible suggestions 
from the users, some tests have been carried out. The test 
phase has been realized in order to allow the users to check 
all the functionalities of the application. 
After a short period of training (5 minutes), the users 
have tried to carry out different procedures and, 
subsequently, they have reported the impressions on a 
specific questionnaire. 15 subjects have been testing the 
application for an average time of 7 minutes and 43 seconds. 
The obtained results can be considered satisfactory and 
some annotations to improve the user interface and the 
usability of the application have been considered. In 
particular, the users have suggested: 
• To improve the session for the choice of trocar entry 
points by means of a more accurate explication about 
the use of the arrows in the interface; 
• To provide a more simple way to store the 
measurements of the organs. 
Fig. 11 shows a graph with the test answers about the 
usability of the different sessions of the application. 
 
 
Figure 11.  Test answers about the usability of the application sessions. 
X. 
CONCLUTIONS AND FUTURE WORK 
The developed platform offers a tool to visualize the 3D 
reconstructions of the patient’s organs, obtained by the 
segmentation of a CT scan.  
The system allows interacting with the models in order to 
choose the more appropriate insertion pints of the trocars 
and to simulate the placement of these in order to verify the 
validation of this choice. The Augmented Reality module 
supports the placement of the trocars on the real patient’s 
body during the surgery procedure.  
An accurate integration of the virtual organs in the real 
scene is obtained by means of an appropriate registration 
phase based on fiducial points fixed onto the patient. In 
addition, a complete user interface allows a simple and 
efficient utilization of the developed application. 
Furthermore the platform permits to store the patient and 
the pathology information that the surgeon can note during 
the use. 
The platform can support the physician in the diagnosis 
step and in the preoperative planning when a laparoscopic 
approach will be followed. In addition, this support could 
lead to a better communication between physicians and 
patient’s parents in order to obtain their informed consent. 
The building of a complete Augmented Reality system 

497
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
that could help the surgeon during the other phases of the 
surgical procedure has been planned as future work; the 
acquisition in real time of a patient’s video and the 
dynamically overlapping of the virtual organs to the real 
patient’s body will be developed taking into account the 
surgeon point of view and the location of medical 
instrument. 
An accurate AR visualization modality will be developed 
in order to provide a realistic depth sensation of the virtual 
organs in the real body. 
Accuracy and usability tests will be also carried out. 
 
ACKNOWLEDGEMENT 
This work is part of the ARPED Project (Augmented 
Reality Application in Pediatric Minimally Invasive 
Surgery) funded by the Fondazione Cassa di Risparmio di 
Puglia. The aim of the ARPED Project is the design and the 
development of an Augmented Reality system that can 
support the pediatric surgeon through the visualization of 
anatomical structures of interest during the pre-operative 
planning and the laparoscopic surgical procedure. 
 
REFERENCES 
[1] L. T. De Paolis, M. Pulimeno, and G. Aloisio, “An 
Augmented Reality Application for the Enhancement of 
Surgical Decisions”, The 4th International Conference on 
Advances in Computer-Human Interactions (ACHI 2011), 
February 23-28, 2011, Gosier, Guadeloupe, France, pp. 192-
196. 
[2] L. T. De Paolis and G. Aloisio, “Augmented Reality in 
Minimally Invasive Surgery”, Advances in Biomedical 
Sensing, Measurements, Instrumentation and Systems, 
Lecture 
Notes 
in 
Electrical 
Engineering, 
Vol. 
55, 
Mukhopadhyay S.C. & Lay-Ekuakille A. (Eds.), Springer 
Publisher, December 2009, ISBN 978-3-642-05166-1; 
[3] R. Azuma, “A Survey of Augmented Reality. Presence: Tele-
operators and Virtual Environments”, 4(6), pp. 355-385, 
1997. 
[4] P. Milgram and F. Kishino, “A Taxonomy of Mixed Reality 
Visual Displays”, IEICE Transactions on Information 
Systems, E77-D(12), 1994, pp. 1321-1329. 
[5] J. B. A. Maintz and M. A. Viergever, “A survey of medical 
image registration”, Medical Image Analysis, vol. 2, 1998, pp. 
1-36. 
[6] F. Sauer, “Image Registration: Enabling Technology for 
Image Guided Surgery and Therapy”, 2005 IEEE Engineering 
in Medicine and Biology, Shanghai, China, 2005. 
[7] M. Feuerstein, S. M. Wildhirt, R. Bauernschmitt, and N. 
Navab, “Automatic Patient Registration for Port Placement in 
Minimally Invasive Endoscopic Surgery”, Medical Image 
Computing and Computer-Assisted Intervention (MICCAI 
2005). Lecture Notes in Computer Science 3750, Springer-
Verlag, Palm Springs, CA, USA, 2005, pp. 287-294. 
[8] T. Sielhorst, M. Feuerstein, and N. Navab, “Advanced 
Medical Displays: A Literature Review of Augmented 
Reality”, IEEE/OSA Journal of Display Technology, Special 
Issue on Medical Displays, 4(4), 2008, pp. 451-467. 
[9] F. Devernay, F. Mourgues, and E. Coste-Manière, “Towards 
Endoscopic Augmented Reality for Robotically Assisted 
Minimally Invasive Cardiac Surgery”, IEEE International 
Workshop on Medical Imaging and Augmented Reality, 
2006, pp. 16-20. 
[10] C. Bichlmeier and N. Navab, “Virtual Window for Improved 
Depth Perception in Medical AR”, International Workshop on 
Augmented Reality environments for Medical Imaging and 
Computer-aided 
Surgery 
(AMI-ARCS), 
Copenhagen, 
Denmark, 2006. 
[11] C. Bichlmeier, F. Wimmer, H. S. Michael, and N. Nassir, 
“Contextual Anatomic Mimesis: Hybrid In-Situ Visualization 
Method for Improving Multi-Sensory Depth Perception in 
Medical Augmented Reality”, Sixth IEEE and ACM 
International Symposium on Mixed and Augmented Reality 
(ISMAR '07), 2007, pp. 129-138. 
[12] E. Samset, D. Schmalstieg, J. Vander Sloten, A. Freudenthal, 
J. Declerck, S. Casciaro, Ø. Rideng, and B. Gersak, 
“Augmented Reality in Surgical Procedures”, SPIE Human 
Vision and Electronic Imaging XIII, (6806):68060K.1-
68060K.12, 2008. 
[13] N. Navab, M. Feuerstein, and C. Bichlmeier, “Laparoscopic 
Virtual Mirror - New Interaction Paradigm for Monitor Based 
Augmented Reality”, IEEE Virtual Reality Conference 2007 
(VR 2007), Charlotte, North Carolina, USA, 2007, pp. 10-14. 
[14] C. Bichlmeier, S. M. Heining, M. Rustaee, and N. Navab, 
“Laparoscopic Virtual Mirror for Understanding Vessel 
Structure: Evaluation Study by Twelve Surgeons”, 6th IEEE 
International Symposium on Mixed and Augmented Reality 
(ISMAR'07), Nara, Japan, 2007. 
[15] D. Kalkofen, E. Mendez, and D. Schmalstieg,” Interactive 
Focus and Context Visualization in Augmented Reality”, 6th 
IEEE International Symposium on Mixed and Augmented 
Reality (ISMAR'07), Nara, Japan, 2007, pp. 191-200. 
[16] L. T. De Paolis, M. Pulimeno, M. Lapresa, A. Perrone, and G. 
Aloisio, “Advanced Visualization System Based on Distance 
Measurement for an Accurate Laparoscopy Surgery”, Joint 
Virtual Reality Conference of EGVE - ICAT - EuroVR, 
Lyon, France, 2009. 
[17] L. Soler, S. Nicolau, J.-B. Fasquel, V. Agnus, A. Charnoz, A. 
Hostettler, J. Moreau, C. Forest, D. Mutter, and J. Marescaux, 
“Virtual Reality and Augmented Reality Applied to 
Laparoscopic 
and 
NOTES 
Procedures”, 
IEEE 
5th 
International Symposium on Biomedical Imaging: from Nano 
to Macro, 2008, pp. 1399-1402. 
[18] W. E. L. Grimson, T. Lozano-Perez, W. M. Wells, G. J. 
Ettinger, S. J. White, and R. Kikinis, "An Automatic 
Registration Method for Frameless Stereotaxy, Image Guided 
Surgery, and Enhanced Reality Visualization", Transactions 
on Medical Imaging, 1996. 
[19] X. Papademetris, K. P. Vives, M. Di Stasio, L. H. Staib, 
M. Neff, S. Flossman, N. Frielinghaus, H. Zaveri, E. J. 
Novotny, 
H. Blumenfeld, 
R. 
T. 
Constable, 
H. 
P. 
Hetherington, R. B. Duckrow, S. S. Spencer, D.D . Spencer, J. 
and S. Duncan, “Development of a research interface for 
image guided intervention: Initial application to epilepsy 
neurosurgery”, International Symposium on Biomedical 
Imaging ISBI, 2006, pp. 490-493. 
[20] E. Bollschweiler, J. Apitzsch, R. Obliers, A. Koerfer, S. P. 
Mönig, R. Metzger, and A. H. Hölscher, “Improving informed 
consent of surgical patients using a multimedia-based 
program? Results of a prospective randomized multicenter 
study of patients before cholecystectomy”, Annals of Surgery, 
August 2008, 248(2), pp. 205-11. 
[21] C. Eggers, R. Obliers, A. Koerfer, W. Thomas, K. Koehle, A. 
H. Hölscher, and E. Bollschweiler, “A multimedia tool for the 
informed consent of patients prior to gastric banding obesity”, 
Silver Spring, November 2007, 15(11), pp. 2866-2873. 
[22] D. Wilhelm, S. Gillen, H. Wirnhier, M. Kranzfelder, A. 
Schneider, A. Schmidt, H. Friess, and H. Feussner, “Extended 

498
International Journal on Advances in Software, vol 4 no 3 & 4, year 2011, http://www.iariajournals.org/software/
2011, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
preoperative patient education using a multimedia DVD-
impact on patients receiving a laparoscopic cholecystectomy: 
a randomised controlled trial”, Langenbeck’s Arch ives of 
Surgery, March 2009, 394(2), pp. 227-33. 
[23] Mimics Medical Imaging Software, Materialise Group. 
Available: http://www.materialise.com/mimics 
[24] 3D Slicer. Available:  http://www.slicer.org 
[25] J. Ahrens, B. Geveci, and C. Law, “ ParaView: an End-User 
Tool for Large Data Visualization”, Visualization Handbook, 
Edited by C.D. Hansen and C.R. Johnson, Elsevier, 2005. 
[26] O. Faha, “Osirix: an Open Source Platform for Advanced 
Multimodality 
Medical 
Imaging”, 
4th 
International 
Conference on Information & Communications Technology, 
Cairo, Egypt, 2006, pp. 1-2. 
[27] P. A. Yushkevich, J. Piven, H. Cody, S. Ho, J. C. Gee, and G. 
Gerig, “User-Guided Level Set Segmentation of Anatomical 
Structures with ITK-SNAP”, Insight Journal, Special Issue on 
ISC/NA-MIC/MICCAI Workshop on Open-Source Software, 
Nov 2005. 
[28] P. Cignoni, M. Callieri, M. Corsini, M. Dellepiane, F. 
Ganovelli, and G. Ranzuglia, “MeshLab: an Open-Source 
Mesh Processing Tool,” in Proc. Sixth Eurographics Italian 
Chapter Conference, 2008, Salerno, Italy, pp. 129-136. 
[29] NDI Polaris Vicra. Available: http://www.ndigital.com 
[30] E. Larsen, S. Gottschalk, C. L. Ming, and D. Manocha, “Fast 
Proximity Queries with Swept Sphere Volumes”, Technical 
Report TR99-018, Dept. of Computer Science, University of 
North Carolina, 1999. 
[31] A. Tinelli, A. Malvasi, G. Hudelist, O. Istre, and J. Keckstein,  
“Abdominal Access in Gynaecological Laparoscopy: a 
Comparation between Direct Optical and Open Access” 
Journal of Laparoendosc & Advanced Surgical Techniques, 
19(4), 2009, pp. 529-33. 
 
 

