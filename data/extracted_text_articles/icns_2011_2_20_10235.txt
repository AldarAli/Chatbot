IEEE 802.11n MAC Mechanisms for High Throughput: a Performance Evaluation  
Miguel A. García, M. Ángeles Santos and Jose Villalón, 
Albacete Research Institute of Informatics. Universidad de Castilla – La Mancha.  
Campus Universitario, 02071. Albacete, SPAIN. 
{Mangel.Garcia, MariaAngeles.Santos, JoseMiguel.Villalon}@uclm.es 
 
 
Abstract— Nowadays IEEE 802.11 standard is the most widely 
used one in wireless LAN (WLAN) technology. One of the key 
reasons is the continuous amendments presented by the IEEE 
802.11 working group. One of these amendments (IEEE 
802.11n) was approved to enhance 802.11 for higher 
throughput operation. IEEE 802.11n is an ongoing next-
generation wireless LAN standard that supports a very high 
speed connection with more than 100 Mb/s data throughput 
measured at the medium access control layer. In this paper we 
examine the major improvements introduced by IEEE 802.11n 
MAC: aggregation, block acknowledgement, and reverse 
direction. We show the impact of each parameter in the 
network performance.  
Keywords-component; IEEE 802.11n; aggregation; block 
ACK;  reverse direction1 
I. 
 INTRODUCTION 
These days, the wireless LAN (WLAN) technology is 
usually deployed using the IEEE 802.11 standard.  One of 
the main factors for the popularity of the IEEE 802.11 is the 
continuous amendments. The IEEE 802.11 working group 
has always strived to improve this wireless technology 
through creating new amendments to the base 802.11 
standard. The amendments try to solve the low efficiency of 
its medium access control (MAC) and physical (PHY) layer 
protocols, which restrict its applications to support high data 
rate multimedia services. Current WLAN systems endure 
difficulties due to the increasing expectations of end users 
and volatile bandwidth Delay-boundary demands from new 
higher data rate services, such as high-definition television 
(HDTV), video teleconferencing, multimedia streaming, 
voice over IP (VoIP), file transfer, and online gaming. 
In 2002, the IEEE 802.11 standard working group 
established the high-throughput study group (HTSG) with 
the aim to achieve higher data rate solutions by means of 
existing PHY and MAC mechanisms [2, 3]. Its first interest 
was to achieve a MAC data throughput over 100 Mb/s using 
the 802.11a standard. However, the objective proved to be 
infeasible. So, in September 2003, the HTSG set off the 
IEEE 802.11n (“n” represents next-generation) resolution to 
compose a high-throughput (HT) extension of the current 
WLAN standard would increase the transmission rate and 
                                                           
1This work was supported by the Spanish MEC and MICINN, as well as 
European Comission FEDER funds, under Grants CSD2006-00046 and 
TIN2009-14475-C04. It was also partly supported by the Council of 
Science and Technology of Castilla-La Mancha under Grants PEII09-0037-
2328 and PII2I09-0045-9916. 
would reduce the unavoidable overhead. The main goal of 
the IEEE 802.11n task group (TGn) was to define an 
amendment that had a maximum data throughput of at least 
100 Mb/s (measured at the MAC layer) and at the same time, 
to allow coexistence with legacy devices. To achieve high 
throughput in 802.11 wireless networks, the most commonly 
used method is to increase the raw data rate in the PHY 
layer. For this propose IEEE 802.11n [4] include multiple 
input multiple output (MIMO) antennas with orthogonal 
frequency division multiplexing (OFDM) and various 
channel binding schemes. Moreover, IEEE 802.11n expands 
the channel bandwidth to 40MHz to increase the channel 
capacity.  
However, higher PHY rates do not necessarily translate 
into corresponding increases in MAC layer throughput. 
Indeed, it is well known that the MAC efficiency of 802.11 
typically decreases with increasing PHY rate [5], [6]. To 
solve this limitation, IEEE 802.11n defines new mechanisms 
to increase the network performance. 
The main contribution of this work is to provide an 
understanding of the three IEEE 802.11n MAC layer major 
enhanced 
mechanisms: 
aggregation, 
block 
acknowledgement, and reverse direction. Most previous 
works on IEEE 802.11n performance evaluation only 
explored aggregation mechanism [7, 8]. In [9] the authors 
evaluate both physical and MAC enhanced.   
The rest of this paper is structured as follows: in Section 
2 we describe a brief outline of the current IEEE 802.11 
standard, followed by a discussion of its maximal throughput 
limitations. We describe the IEEE 802.11n in Section 3. We 
carry out a performance evaluation in Section 4 by means of 
extensive simulation. Section 5 concludes this paper. 
II. 
IEEE 802.11 
A. Overview of IEEE 802.11 PHY 
The IEEE 802.11 PHY layer specification concentrates 
mainly on wireless transmission. The original specification 
was first approved in 1997 [1] and includes a primitive MAC 
architecture and three basic over-the-air communication 
techniques with maximal raw data rates of 1 and 2 Mb/s. 
Because of their fairly low data bandwidths, further 
amendments have been proposed throughout the years: IEEE 
802.11a [10], 802.11b [11], and 802.11g [12]. Both 802.11a 
and 802.11b were finalized in 1999 and support raw data 
rates up to 11 Mb/s and 54 Mb/s, respectively. In June 2003, 
a third PHY specification (802.11g) was introduced, with 
similar maximum raw data rate as 802.11a but operating in 
separate frequency bands. For this period, there were many 
32
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

amendments and countless research works for improved 
PHY specifications that mostly aim to provide reliable 
connections and higher data rates. This is mainly because 
there is a continuous rapid increase in user demand for faster 
connections. In spite of establishing novel techniques that 
theoretically can be used for higher data transmission rates, 
the throughput outcomes at the MAC data are surprisingly 
low and in most cases, half of what the underlying PHY rates 
can offer. 
B. IEEE 802.11 MAC 
The MAC architecture is based on the logical 
coordination functions, which determine who accesses to the 
wireless medium at each time. In the legacy IEEE 802.11 
standard, there are two types of access schemes: the 
mandatory distributed coordination function (DCF), which is 
based on the carrier sense multiple access with collision 
avoidance (CSMA/CA) mechanism; and the optional point 
coordination function (PCF), which is based on a poll-and-
response mechanism. These MAC schemes are inadequate to 
resolve differentiation and prioritization between frames and 
multimedia applications such as VoIP and audio/video 
conferencing with strict performance constraints. Due to 
these applications have become widely popular, a new 
extension was vital. In late 2005, IEEE 802.11 TG approved 
the IEEE 802.11e amendment [13] to provide an acceptable 
level of quality of service (QoS) for multimedia applications. 
The 802.11e proposes the hybrid coordination function 
(HCF), which uses a contention-based channel access 
method, known as enhanced DCF channel access (EDCA). 
EDCA has the ability to operate simultaneously with a 
polling-based HCF controlled channel access (HCCA). In 
addition to the differentiation and prioritization that IEEE 
802.11e offers, the transmission opportunity (TXOP) was 
introduced in order to improve MAC efficiency. A TXOP is 
an interval of time in which multiple data frames can be 
transferred from one station to another (also known as 
bursting). During a TXOP period the station can transmit 
multiple data frames without entering the backoff procedure, 
reducing the overhead due to contention and backoff period. 
Along with frame bursting, another type of acknowledgment 
(ACK), known as block ACK, was established. Receivers 
can acknowledge multiple received data frames efficiently 
by using just a single extended ACK frame.  
C. Throughput Limitations 
To understand the inefficiency of IEEE 802.11 over 
higher data rates, we must briefly describe the legacy DCF. 
A successful packet transmission in DCF is illustrated in Fig. 
1. When a station has a data frame (MAC service data unit, 
MSDU) to transmit, MAC headers are added to form 
MPDUs. A station may start to transmit after having 
determined that the channel is idle during an interval of 
time longer than the distributed interframe space (DIFS). 
Otherwise, once the transmission in course finishes and in 
order to avoid a potential collision with other active 
stations, if the channel is busy, the station will wait a 
random interval of time (the backoff_time) before start to 
transmit. The station will be able to begin transmission as 
soon as the backoff counter reaches zero. In order to know 
if a transmission has been successful, the destination 
station should respond to the source station with an ACK 
in an interval of time equal to the short interframe space 
(SIFS). 
ACK
Payload
Header
Backoff
DIFS
SIFS
STA
AP
busy
Payload time
Overhead
Overhead
busy
 
Figure 1. Legacy IEEE 802.11 operation. 
By looking into the procedure of a packet transmission, 
we note that the channel is inefficiently used by the DCF. 
During the transmission procedure, transmission time is 
divided into a DIFS, a Contention Window backoff time, the 
PPDU transmission time, a SIFS, and the ACK frame 
transmission time. The PPDU transmission time can be 
further divided into two parts: 802.11 header and data 
payload transmission time. Other than the payload 
transmission portion is the overhead. The overhead of the 
DCF mechanism results in the inefficiency of the channel 
utilization, and thus limits the data throughput. When the 
payload is small, the overhead is relatively large and is less 
efficient. The percentage of the overhead among all usable 
airtime increases as the physical transmission rate increases. 
This fact causes that he overhead limits the achievable data 
throughput. In a higher data rate scenario, although the frame 
transmission time is reduced, the part of the overhead is 
unchanged due to the backward compatibility issue. As a 
result, to achieve higher throughput in 802.11 reducing the 
percentage of overhead is critical. 
 
III. 
IEEE 802.11N 
Although 802.11e adds the support of QoS, TXOP and 
block ACK, the inefficiency of channel utilization in legacy 
802.11 MAC is not fully solved. To satisfy the current need 
of the high-speed wireless network access, the major target 
of IEEE 802.11n, is to provide a high throughput mechanism 
based on state of art design while allowing the coexistence of 
legacy 802.11 devices. To meet the requirements of “high 
throughput”, two possible methods can be applied. The first 
one is to increase the data rate in the PHY layer, and the 
second one is to increase the efficiency in the MAC layer. 
Based on the foundation of 802.11a/b/g/e, many new 
features in PHY and MAC layers are introduced to enhance 
the throughput of IEEE 802.11 WLAN. 
A. MIMO-OFDM physical layer 
To achieve high throughput in 802.11 wireless networks, 
the most commonly used method is to increase the raw data 
rate in the PHY layer. IEEE 802.11 uses two mechanisms to 
increase this data rate: MIMO technology and a channel 
bandwidth that is twice as size (from 20 MHz to 40 MHz). 
IEEE 802.11n expands the channel bandwidth to 40MHz in 
33
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

order to increase the channel capacity. However, IEEE 
802.11n operates in OFDM scheme with MIMO technique 
[6]. MIMO can effectively enhance spectral efficiency with 
simultaneously multiple data stream transmissions. In theory, 
channel capacity gain could be up to the number of 
transmitting antennas without additional bandwidth or 
power. The power of the MIMO system relies on using 
space-time coding and the channel information for intelligent 
transmission. Multiple antennas could help to transmit and 
receive from multiple spatial channels simultaneously. 
Multipath 
wireless 
fading 
channel 
results 
in 
poor 
performance in legacy 802.11 PHY scheme. Hence, 802.11n 
PHY applies MIMO technique to improve performance over 
multipath environment. With this enhancement in the PHY 
layer, the peak PHY rate can be boosted up to 600 Mbps to 
meet the IEEE 802.11n high throughput requirement. 
B. Aggregation 
Increasing the data rate of PHY layer alone is not enough 
to achieve the desired MAC layer throughput of more than 
100 Mbps due to rate independent overheads. We have 
described the overhead in legacy IEEE 802.11 MAC, which 
has been partly solved by the TXOP technique introduced by 
the 802.11e amendment. Aggregation may further enhance 
efficiency 
and 
channel 
utilization. 
The 
aggregation 
mechanism combines multiple data packets from the upper 
layer into one larger aggregated data frame for transmission. 
Overhead in multiple frame transmissions is reduced since 
the header overhead and interframe time is saved. 
In IEEE 802.11n MAC, the aggregation mechanism is 
designed as two-level aggregation scheme, and hence two 
types of aggregation frames are defined: aggregate MAC 
protocol service unit (A-MSDU) and aggregate MAC 
protocol data unit (A-MPDU). The aggregation mechanism 
is able to function with A-MPDU, A-MSDU, or using both 
of them to form two-level aggregation. A-MSDU is 
composed of multiple MSDUs and is created when MSDUs 
are received by the MAC layer. To ease the de-aggregation 
process, the size of a MSDU, including its own subframe 
header and padding, must be multiple of 4 bytes. Two 
parameters are used to form an A-MSDUs: the maximum 
length of an A-MSDU (3839 or 7935 bytes by default), and 
the maximum waiting time before creating an A-MSDU. 
Aggregated MSDUs must belong to the same traffic flow 
(same TID) and have the same destination and source. 
Broadcasting and multicasting packets are excluded. 
In the second level, multiple MPDUs are aggregated into 
an A-MPDU, which is created before sending the MSDU (or 
A-MSDU) to the PHY layer for its transmission. Unlike the 
A-MSDU, the MAC layer does not wait for additional time 
before the A-MPDU aggregation. It only uses the available 
MPDUs in the queue to create A-MPDUs. The TID of each 
MPDU in the same A-MPDU might be different. The 
maximum size limit of A-MPDU is 65535 bytes. In an A-
MPDU, each MPDU has an MPDU delimiter at the 
beginning and padding bytes at the end. These bytes ensure 
that the size of each MPDU is multiple of 4 bytes. Delimiter 
is used to separate the MPDUs in an A-MPDU. The de- 
aggregation process first checks the CRC integrity. If the 
CRC check is passed, the MPDU will be de aggregated and 
sent to upper layer. 
 
padding
MSDU
Subframe 
Header
padding
MAC header
FCS
…
First level
MPDU 
delimiter
PHY 
Header
…
Second level
MSDU subframe
MSDU subframe
MSDU subframe
MPDU
MSDU subframe
A-MSDU
A-MSDU
 
Figure 2. Aggregation in IEEE 802.11n. 
The two-level aggregation mechanism is shown in Fig. 2. 
In the first level, MSDUs received by the MAC layer from 
the upper layer are buffered for a short time until A-MSDUs 
are formed according to their TID, destination, source, and 
the maximum size of A-MSDU. Then, the complete A-
MSDUs and other non-aggregate MSDUs are sent to the 
second level to form an A-MPDU. Due to compatibility 
reasons, every MPDU in A-MPDU should not exceed 4095 
bytes. It must be taken into account that 802.11n aggregation 
does not support frame fragmentation. Only complete A-
MSDUs or MSDUs, not the fragments of A-MSDUs or 
MSDUs, could be contained in an A-MPDU. The whole 
aggregation mechanism completes when A-MPDU is 
created. 
C. Block ACK 
Originally, the block ACK operation incorporates the 
TXOP mechanism, as previously described in the 802.11e 
MAC design. The block ACK mechanism is further 
enhanced in 802.11n to be applied with the aggregation 
feature. Although a larger aggregation frame may 
significantly reduce the overhead in a transmission, the 
frame error rate is higher as the size of the frame increases. 
Large frames in a high bit-error-rate (BER) wireless 
environment have a higher error probability and may need 
more retransmissions. The network performance might be 
degraded. To overcome this drawback of the aggregation, the 
block ACK mechanism is modified in 802.11n to support 
multiple MPDUs in an A-MPDU. Fig. 3 shows the block 
ACK mechanism. When an A-MPDU from one station is 
received and errors are found in some of the aggregated 
MPDUs, the receiving node sends a block ACK which only 
acknowledges the correct MPDUs. The sender only must 
retransmit those non-acknowledged MPDUs. Block ACK 
mechanism resolves the drawback of large aggregation in the 
error-prone wireless environment and further enhances the 
performance of 802.11n MAC (Fig. 3). 
Block ACK mechanism only applies to AMPDU, but not 
A-MSDU. That is, when an MSDU is found to be incorrect, 
the whole A-MSDU needs to be transmitted for error 
recovery. The maximum number of MPDUs in an A-MPDU 
is limited to 64 as one block ACK bitmap can only 
34
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

acknowledge at most 64. The original block ACK message 
in IEEE 802.11e contains a Block ACK bitmap field with 64 
× 2 bytes. These two bytes record the fragment number of 
the MSDUs to be acknowledged. However, fragmentation of 
MSDU is not allowed in 802.11n A-MPDU. Thus, those 2 
bytes can be reduced to 1 byte, and the block ACK bitmap is 
compressed to 64 bytes. This is known as compressed block 
ACK. Compared with 802.11e, the overhead of block ACK 
bitmap in 802.11n is reduced. Moreover, IEEE 802.11n 
introduces the use of implicit block ACK. With this 
mechanism is not necessary to request the sending of ACK 
block, reducing overhead. 
 
PHY HEADER
MPDU 1
MPDU 2
MPDU 3
STA
PHY HEADER
MPDU 1
MPDU 2
MPDU 3
PHY HEADER
ACK 1= 1 ACK 2= 0 ACK 3= 0
PHY HEADER
ACK 1= 1 ACK 2= 0 ACK 3= 0
PHY HEADER
MPDU 2
MPDU 3
PHY HEADER
MPDU 2
MPDU 3
PHY HEADER
ACK 2= 1 ACK 3= 1
PHY HEADER
ACK 2= 1 ACK 3= 1
AP
MPDU 4
MPDU 5
MPDU 6
MPDU 4
MPDU 5
MPDU 6
ACK 4= 1 ACK 5= 0 ACK 6= 1
ACK 4= 1 ACK 5= 0 ACK 6= 1
MPDU 5
MPDU 5
ACK 5= 1
ACK 5= 1
 
Figure 3. Block ACK with aggregation. 
D. Reverse Direction 
Reverse direction mechanism is a novel breakthrough to 
enhance the efficiency of TXOP. In conventional TXOP 
operation, the transmission is uni-directional from the station 
holding the TXOP, which is not applicable in some network 
services 
with 
bi-directional 
traffic 
like 
VoIP, 
videoconference and on-line gaming. The conventional 
TXOP 
operation only 
helps 
the 
forward 
direction 
transmission but not the reverse direction transmission. For 
application with bi-directional traffic, their performance is 
degraded by the random backoff and contention of the 
TXOP. Reverse direction mechanism allows the holder of a 
TXOP to allocate the unused TXOP time to its receivers and 
hence, enhancing the channel utilization and performance of 
reverse direction traffic flows. 
PHY HEADER RDG=1
MPDUs 1
SIFS
RD initiator
RD responder
Remaining
TXOP (2)
Remaining TXOP (1)
PHY HEADER RDG=1
Block ACK 1
SIFS
PHY HEADER RDG=0
MPDUs 2
PHY HEADER
Block ACK 2
PHY HEADER RDG=0
MPDUs 3
PHY HEADER
Block ACK 3
 
Figure 4. Reverse direction. 
The reverse direction operation is illustrated in Fig. 4. In 
reverse direction operation, two types of stations are defined: 
RD initiator and RD responder. RD initiator is the station 
which holds the TXOP and has the right to send reverse 
direction grant (RDG) to the RD responder. RDG is marked 
in the 802.11n header and is sent with the data frame to the 
RD responder. When the RD responder receives the data 
frame with RDG, it responds with RDG acknowledgement if 
it has data to be sent, or without RDG if there is no data to be 
sent to the RD initiator. If the acknowledgement is marked 
with RDG, the RD initiator will wait for the transmission 
from the RD responder, which will start after a SIFS or a 
reduced inter-frame space (RIFS) once the RDG ACK is 
sent. RIFS can be used in the scheme when no packet is 
expected to be received after the transmission, which is the 
case here. If there is still data to be sent from the RD 
responder, it can mark RDG (which represents MORE 
DATA) in the data frame header to notify the initiator. The 
RD initiator still has the right to accept the request. To 
allocate the remaining TXOP, the initiator will mark the 
RDG in the acknowledge message or the next data frame. To 
reject the new RDG request, the initiator just ignores it.  
The major enhancement of the reverse direction 
mechanism is the delay reduction in reverse link traffic. 
These reverse direction data packets do not need to wait in 
queue until the station holds a TXOP but can be transmitted 
immediately when the RD responder is allocated for the 
remaining TXOP. This feature can benefit a delay-sensitive 
service like VoIP. We will show a performance enhancement 
in the simulation section. 
IV. 
PERFORMANCE EVALUATIONS 
In this section, we carry out a performance analysis on 
the effectiveness of the IEEE 802.11n standard. We examine 
the major improvements introduced by IEEE 802.11n MAC: 
aggregation, block acknowledgement, and reverse direction. 
We show the impact of each parameter in the network 
performance.  
A. Scenario 
In our simulations, we model an IEEE 802.11n wireless 
LAN using OPNET Modeler tool 10.0 [14]. We use a 
wireless LAN consisting of several wireless stations and an 
access point connected to a wired node, which serves as sink 
for the flows from the wireless domain. All the stations are 
located within a basic service Set (BSS), i.e., every station is 
able to detect a transmission from any other station. The 
parameters of the wired link have been chosen to ensure that 
the bandwidth bottleneck of the system is within the wireless 
LAN. Each wireless station operates at 300 Mbit/s IEEE 
802.11n mode and we assume the use of an ideal channel. 
All the stations use a MIMO configuration with 2x2 
antennas. 
For all the scenarios, we have assumed a bi-directional 
and constant bit-rate application. This application has an 
average rate of 8 Mbps and a packet size equal to 1000 bytes. 
We start by simulating a WLAN consisting of two wireless 
stations. We then gradually increase the network load by 
adding the number of stations each time. We increase the 
35
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

number of stations 2 by 2 starting from 2 and up to 20. In 
this way, the offered load is increased from 32 Mbps (16 
Mbps in the AP and 16 Mbps in the stations) up to 320Mbps. 
The traffic sources are randomly activated within of the 
interval [1,1.5] seconds from the start of the simulation. 
Throughout our study, we have simulated two minutes of 
operation of each particular scenario. Our measurements start 
after a warm-up period allowing us to collect the statistics 
under steady-state conditions. Each point in our plots is an 
average over thirty simulation runs, and the error bars 
indicate the 95% confidence interval.  
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Maximum Size of Aggregation
64
60
40
20
 
(a) Stations 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Maximum Size of Aggregation
64
60
40
20
 
(b) AP 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Maximum Size of Aggregation
64
60
40
20
 
(c) Global Throughput 
Figure 5. Performance evaluation for different sizes of aggregation. 
For the purpose of our performance study we are selected 
the normalized throughput. The normalized throughput is 
calculated as the percentage of the offered load actually 
delivered to destination. 
B. Results 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Implicit BlockACK
No Implicit
Implicit
 
(a) Stations 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Implicit BlockACK
No Implicit
Implicit
 
(b) AP 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Implicit BlockACK
No Implicit
Implicit
 
(c) Global Throughput 
Figure 6. Performance evaluations with implicit block ACK.. 
Figure 5 shows the normalized throughput with different 
maximum size of aggregation. In this simulations we have 
fixed the first level of aggregation (A-MSDU) changing the 
second level of aggregation (A-MPDU). We evaluate several 
maximum sizes for the aggregated frames (20, 40, 60 and 64 
packets). The figure shows that the larger the aggregation, 
higher performance is achieved. This improved performance 
is higher in the AP (see Figure 5.b). This is because the AP 
has more packets to transmit that the stations so the AP will 
36
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

use the higher size of aggregation. This result is expected 
since a higher aggregation size leads to a lower overhead. 
Figure 6 shows the effect of using the implicit block 
ACK. In these simulations, the maximum size of aggregation 
is fixed to 60. The figure shows that the normalized 
throughput increases when an implicit ACK block is used. 
This is due to the reduction in overhead. When the implicit 
block ACK is used, the station does not request 
confirmations. 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Maximum Size of Reverse
Without Reverse
20
40
60
 
(a) Stations 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Maximum Size of Reverse
Without Reverse
20
40
60
 
(b) AP 
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 5
 10
 15
 20
Normalized Throughput
Number of Stations
Maximum Size of Reverse
Without Reverse
20
40
60
 
(c) Global Throughput 
Figure 7. Performance evaluations for different sizes of reverse direction.. 
Finally, the impact of use the reverse direction is shown 
in Figure 7. This figure shows that the use of reverse 
direction improves network performance. This result also 
was expected because if bidirectional applications are 
transmitted, the destination station takes advantage of the 
TXOP that belongs to the sending station. However, the size 
of the reverse should not be too large, because it gives too 
much traffic to the destination station 
V. 
CONCLUSIONS 
We have investigated the performance of IEEE 802.11n 
MAC protocol. The three enhanced 802.11n MAC 
mechanisms: aggregation, block acknowledgement and 
reverse direction have been discussed. We have implemented 
an 802.11n module in Opnet Modeler. We designed several 
simulation scenarios in order to evaluate the influence of the 
different enhanced mechanisms. The simulation results have 
shown that the aggregations, implicit block ACK and reverse 
direction mechanisms reduce the overhead allowing an 
increase of the network performance. 
REFERENCES 
 
[1] IEEE Std. 802.11 WG, “Part 11: Wireless LAN Medium Access 
Control (MAC) and Physical Layer (PHY) Specifications,”. 1999. 
[2] V. Jones, R. DeVegt, and T. Jerry, “Interest for Higher Data Rates 
(HDR) Extension to 802.11a,” IEEE 802.11n working doc. 802.11-
02-081r0, Jan. 20023. 
[3] J. Rosdahl, “Draft Project Authorization Request (PAR) for High 
Throughput Study Group,” IEEE 802.11n working doc. 802.11-
02/798r2, Mar. 2003. 
[4] IEEE P802.11n, “Part 11: Wireless LAN Medium Access Control 
(MAC) and Physical Layer (PHY) Specifications: Enhancements for 
Higher Throughput,”  2009. 
[5] Magis Networks White Paper, ”IEEE 802.11 e/a Throughput 
Analysis”, 2004, www.magisnetworks.com. 
[6] Y. Xiao and J. Rosdahl, “Performance analysis and enhancement for 
the current and future IEEE 802.11 MAC protocols”, ACM 
SIGMOBILE Mobile Computing and Communications Review 
(MC2R), special issue on Wireless Home Networks, Vol. 7, No. 2, 
Apr. 2003, pp. 6-19. 
[7] Lin Y, Wong VWS (2006) WSN01-1: frame aggregation and optimal 
frame size adaptation for IEEE 802.11n WLANs. IEEE Global 
Telecommunications Conference, San Francisco, December. 
[8] Xiao Y (2005) IEEE 802.11n: enhancements for higher throughput in 
wireless LANs. IEEE Wirel Commun 12(6):82–91: 
[9] Chih-Yu Wang  and Hung-YuWei, “IEEE 802.11n MAC 
Enhancement and Performance Evaluation”. Mobile Netw Appl, 
Vol. 14, No. 6, pp. 760-771. 
[10] IEEE Std. 802.11 WG Std 802.11a, “Part 11: Wireless LAN Medium 
Access Control (MAC) and Physical Layer (PHY) Specifications: 
High-speed Physical Layer in the 5 GHz Band”, 1999 
[11] IEEE Std. 802.11 WG Std 802.11b, “Part 11: Wireless LAN Medium 
Access Control (MAC) and Physical Layer (PHY) Specifications: 
Further Higher-Speed Physical Layer Extension in the 2.4 GHz 
Band”, 1999. 
[12] IEEE Std. 802.11 WG Std 802.11g, “Part 11: Wireless LAN Medium 
Access Control (MAC) and Physical Layer (PHY) Specifications: 
Further Higher-Speed Physical Layer Extension in the 2.4 GHz 
Band”, 2003. 
[13] IEEE Std. 802.11 WG Std 802.11e: “Wireless LAN Medium Access 
Control (MAC) and Physical Layer (PHY) Specifications: Medium 
Access Control (MAC) Quality of Service Enhancements", 2005 
[14] OPNET Technologies Inc., http://www.opnet. 
 
37
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

