Virtualization as a Driver for the Evolution of the Internet of Things: Remaining 
Challenges and Opportunities Towards Smart Cities 
 
Andreas Merentitis1, Vangelis Gazis1, Eleni Patouni2, Florian Zeiger1, Marco Huber1, Nick Frangiadakis1, and Kostas Mathioudakis1  
1AGT International, Darmstadt, Germany 
2 Department of Informatics & Telecommunications, University of Athens, Athens, Greece 
{amerentitis, vgazis, fzeiger, mhuber,  nfrangiadakis, kmathioudakis}@agtinternational.com 
{elenip}@di.uoa.gr 
 
 
Abstract— Fueled by advances in microelectronics, wireless 
communications and the availability of affordable mobile 
connectivity, the last decade has seen an unprecedented 
proliferation in the number of interconnected devices. This 
evolution is part of the transition to the Internet of Things 
(IoT), which envisions connecting anything at any time and 
place. While it can be argued we are already living in the IoT 
era, the next paradigm shift is already emerging on the 
horizon, targeting yet another order of magnitude increase in 
the number of interconnected devices and promising to bring 
people and processes in the equation. This is particularly 
important towards the vision of Smart Cities, where physical 
infrastructure is complemented by the availability of 
intellectual and social capital, increasing both urban 
competitiveness and quality of life. However, before such a 
paradigm shift can be realized, significant challenges with 
respect to scalability, cooperative communications, energy 
consumption, as well as convergence of sensor and analytics 
trends have to be resolved. In this paper we elaborate on the 
different trends, as well as the remaining open problems and 
we show how Sensor Virtualization Technology, capturing 
both the Virtual Sensors and Virtual Sensors Networks 
aspects, promises to alleviate or resolve these challenges, and 
pave the way towards the evolution of the Internet of Things.  
Keywords- Sensor Networks, Sensor Virtualization; Machine 
to Machine Communications; Internet of Things; Future 
Internet. 
I. 
 INTRODUCTION  
Technological advances in the fields of sensor 
technology, low power microelectronics, and low energy 
wireless communications paved the way for the emergence 
of Wireless Sensor Networks (WSNs). These networks are 
currently used in a wide range of industrial, civilian and 
military applications, including healthcare applications, 
home automation, earthquake warning, traffic control and 
industrial process monitoring. A WSN is a system 
composed of small, wireless nodes that cooperate on a 
common distributed application under strict energy, cost, 
noise and maintenance constraints [1], [2]. Although many 
interesting applications have been implemented/developed 
for WSNs, further work is required for realizing their full 
potential as “the next big thing” that will revolutionize the 
way we interact with our environment. 
Such promises are particularly important when viewed 
in the context of the global urbanization trend and the 
challenges that accompany it. With 60% of the world 
population projected to live in urban cities by 2025, the 
efficient use of resources becomes a topic of paramount 
importance. Such efficiency calls for situational awareness 
of the Smart City across multiple domains in an 
unprecedented level. 
As a promising step in this direction, during the last 
decade there has been a growing research interest in the 
Internet of Things (IoT), ranked as a disruptive technology, 
according to the US National Intelligence Council [3]. An 
early definition for the IoT envisioned a world where 
computers would relieve humans of the Sisyphean burden of 
data entry, by automatically recording, storing and 
processing all the information relevant to the things 
involved in human activities, while also providing “anytime, 
anyplace [...] connectivity for anything” [4]. 
Beyond offering pervasive connectivity, the IoT 
ecosystem is composed of smart things, objects, and 
applications. This notion of smartness is taking different 
forms in the literature. For example, the user experience of a 
mediated context-aware mobile system which is enabled by 
modern 
smart 
phones 
and is 
focusing 
on 
urban 
environments is presented in [5]. Approaches that support 
the exploitation of semantic technologies in context aware 
smart space applications are described in [6]. The presented 
technologies enable the creation of pervasive computing 
systems. A new flow-based programming paradigm for 
smart objects and the IoT is introduced in [7]. New 
workflow models suitable for embedded devices have been 
proposed, as well as orchestration techniques for the ad-hoc 
combination of smart objects. Smart spaces are discussed in 
[8] as a way to meet challenges such as interoperability, 
information processing, security and privacy towards the 
deployment of IoT.  
Combining the notions of pervasive connectivity and 
smartness, different understandings and definitions have 
been reported in the literature [9]-[11] regarding what the 
Internet of Things is about. However, while it is possible to 
argue that the IoT is already here [12], the next (r)evolutions 
are already on the horizon, ranging from the open effort to 
the Future Internet and the rapidly spawning Smart City 
projects around the world up to industry driven initiatives. 
The latter include efforts such as the National Instruments 
Data Acquisition Technology Outlook [13], the General 
Electric concept of “Industrial Internet” [14], and the 
86
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

CISCO initiated “Internet of Everything” [12], [15]. Such 
initiatives have differences in flavor and focus; yet, it is 
possible to distil the general trends and enablers that need to 
be in place for successfully realizing the shift to the next 
networking paradigm, whichever form it might take.  
In this paper, we argue that, among these enablers, 
Sensor Network Virtualization is a technology that has the 
potential to augment and unlock advances in several other 
fronts (e.g., scalability, cooperation, low energy solutions 
and convergence of Sensor Network and Data Analytics 
trends) that will pave the way towards this paradigm shift. 
Smart Cities are going to be at the forefront of this paradigm 
shift, therefore a lot of the examples and use cases discussed 
in following Sections are coming from the domain of Smart 
Cities.   
The rest of the paper is organized as follows: Section II 
highlights the main challenges of Smart Cities and the costs 
associated to the lack of data integration across multiple 
verticals. The lack of such data integration capability can be 
seen as a driver for some of the key networking trends that 
are commonly captured in several independent views for the 
next networking paradigm evolution. It finishes with a 
selection of four core areas where significant challenges 
remain unresolved. Section III introduces the Virtualization 
layers and the main functionality that each layer is 
responsible for. It gives also a broad overview of which 
virtualization types promise to address each of the core areas. 
The selected areas and the nature of the challenges in each of 
them are then discussed in more detail in Sections IV-VII. 
Section VIII elaborates on the different aspects of sensor 
infrastructure virtualization. Their advantages are captured 
and the potential of using different virtualization flavors to 
address the challenges described earlier is explained. Finally, 
Section IX concludes the paper. 
II. 
TOWARDS SMART CITIES: IDENTIFICATION OF 
RELEVANT NETWORKING TRENDS  
Amassing large numbers of people, urban environments 
have long exhibited high population densities and now 
account for more than 50% of the world’s population [16]. 
With 60% of the world population projected to live in urban 
cities by 2025, the number of megacities (i.e., cities with at 
least 10 million people in population) is expected to increase 
also. It is estimated that, by 2023, there will be 30 
megacities globally. Considering that cities currently occupy 
2% of global land area, consume 75% of global energy 
resources and produce 80% of global carbon emissions, the 
benefit of even marginally better efficiency in their 
operation will be substantial [16]. For instance, the 
Confederation of British Industries (CBI) estimates that the 
cost of road congestion in the UK is GBP 20 billion (i.e., 
USD 38 billion) annually. In London alone, introduction of 
an integrated ICT solution for traffic management resulted 
in a 20% reduction of street traffic, 150 thousand tons of 
CO2 less emissions per year and a 37% acceleration in 
traffic flow [17]. 
Being unprecedentedly dense venues for the interactions 
(economic, social and of other kind) between people, goods 
and services, megacities also entail significant challenges. 
These relate to the efficient use of resources across multiple 
domains (e.g., energy supply and demand, building and site 
management, public and private transportation, healthcare, 
safety and security, etc.). To address these challenges, a 
more intelligent approach in managing assets and 
coordinating the use of resources is envisioned, based on the 
embodiment of sensor and actuator technologies throughout 
the city fabric in a pervasive manner. This ubiquitous fabric 
will be supported by flexible communication networks and 
the ample processing capacity of data centers. 
By aggregating data feeds and applying data processing 
algorithms to reveal the main relationships in the data, the 
situational awareness of the Smart City across multiple 
domains (e.g., transportation, safety, health, energy, etc.) at 
the executive level is greatly facilitated. For instance, by 
leveraging its open data initiative, the city of London 
provides a dashboard application demonstrating the kind of 
high-level overview and insight achievable by cross-silo 
data integration and innovative analytic applications [18]. 
However, this vision entails significant challenges on the 
design of the sensory fabric and the application model 
through which sensory data are discovered, accessed and 
consumed. It is currently understood that an intermediary 
layer of abstraction between the actual sensors and the 
applications utilizing them will be necessary [19].  
The role of such a layer is to abstract the peculiarities of 
the sensor hardware from the applications, thus facilitating 
interoperability; to provide opportunities for forming shared 
resource pools, therefore increasing the efficiency and 
scalability of the system; and to allow creation of sandboxed 
islands that enforce the least privilege principle, thus 
enabling privacy protection (e.g., particularly important for 
a lot of healthcare applications in Smart Cities). Related 
activities towards such goals have been in the scope of 
various 
initiatives, 
focusing 
both 
on 
the 
scalable 
interconnection part, as well as on efficiency and privacy 
topics. All of these objectives have to be supported in a 
transparent way through well-established and standardized 
discovery and negotiation protocols, so that the devices can 
autonomously perform them with only minimal or no 
human intervention. 
In parallel with the efforts towards efficiently and 
transparently interconnecting a myriad of smart devices 
according to the IoT vision, the Future Internet stands as a 
general term for research activities and communication 
paradigms towards a more up to date and efficient Internet 
architecture. Approaches towards the “Future Internet” 
cover the full range from small, incremental evolutionary 
steps up to complete redesigns (clean slate) of the core 
architecture and the underlying mechanisms, where the 
applied technologies are not to be limited by existing 
standards or paradigms (e.g., the client server networking 
model might evolve into co-operative peer structures). In 
87
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

general, most of the work in this area is summarized by the 
Future Internet Assembly (FIA) [20], where it is underlined 
that whatever form the Future Internet may take, a set of 
core principles need to be preserved: 
• 
Heterogeneity support principle, refers to supporting a 
plethora of devices and nodes, scheduling algorithms 
and queue management mechanisms, routing protocols, 
levels of multiplexing, protocol versions, underlying 
link layers or even administrative domains and pricing 
structures. 
• 
Scalability and Amplification principle, describing the 
ability of a computational system to continue operating 
under well specified bounds when its input is increased 
in size or volume. 
• 
Robustness principle, ensuring that each protocol 
implementation must transparently interoperate with 
other implementations. 
• 
Loose Coupling principle, describing a method of 
interconnecting architectural components of a system so 
that those components depend on each other to the least 
extent practicable. 
• 
Locality principle, which in the computer science 
domain focuses on the design of thrashing-proof, self-
regulating, and robust logical systems. 
However, apart from these principles that should only 
undergo small incremental changes (if any) a list of 
additional 
principles that 
need to be significantly 
adapted/relaxed or augmented is also provided. Here, we 
focus on a subset of this list that is related or overlapping to 
the IoT evolution: 
• 
Keep it simple, but not “stupid” principle [20], which 
refers to the fact that in current Internet design, the 
complexity belongs always at the edges, while in a 
more 
flexible 
architecture 
inherently 
supporting 
heterogeneous “Things” this might not always be the 
case. 
• 
Polymorphism principle, which refers to the ability to 
manipulate objects of various classes, and invoke 
methods on an object without knowing that object’s 
type. The idea is to extend this principle to allow the 
same 
abstract 
components 
exhibiting 
different 
functional and non-functional behavior in case of 
changing environments or circumstances [20]. 
• 
Unambiguous naming and addressing principle, 
establishing that protocols are independent of the 
hardware medium and hardware addressing scheme. 
The proposal of the FIA initiative is to extend this 
principle in order to also capture the data and services. 
Even more recently than the FIA initiative, CISCO has 
evangelized the Internet of Everything (IoE) as the next 
wave in the evolution of the networking paradigms [12]. 
With a clear all-IP focus, building on the same principles as 
Machine to Machine Communications (M2M) and the 
Internet of Things but extending them, the IoE envisions to 
increase the number of connections by yet another order of 
magnitude (from ~10 billion currently connected “Things”). 
However, arguably the biggest innovation is that it targets to 
include processes and people in the loop, facilitating and 
enabling communications that are more relevant in order to 
offer new capabilities, richer experiences and unprecedented 
economic opportunities.  
In all the previous activities, as well as in various 
independent research efforts, it has already being identified 
that in future large-scale heterogeneous networks, the 
adoption of mechanisms achieving scalable, predictable and 
self-adaptive network behavior (“more relevant” in CISCO 
IoE terminology, “pushing the boundaries” in the GE 
Industrial Internet notion) will be a key enabler [12], [14], 
[15], [21], [22]. At the same time, with systems becoming 
continuously more complex in terms of scale and 
functionality, reliability and interoperability are getting 
increasingly important. Therefore, techniques for achieving 
dependable system operation under cost and energy 
constraints will be an important evolutionary step [2], [21], 
[22].  
In the majority of cases, wireless network development 
is guided by horizontal mass-markets (“one size fits all”). 
On the other hand, typically different verticals and niche 
markets require dedicated applications [22]. Consequently, 
the deployment or evolution of a wireless network in these 
areas 
often 
demands 
for 
expensive 
infrastructure 
replacement. Moreover, extending system and network 
capabilities, switching services or adopting the purpose of 
an operational network consisting of heterogeneous 
“Things” usually calls for costly (manual) reconfigurations 
and upgrades, while it often results in temporary 
unavailability of system services. Both of these properties 
are not attractive in a Smart City environment, while the 
second one is strictly unacceptable for a large number of 
relative vertical areas that form the backbone of the city 
infrastructure, such as water and electricity supply networks, 
Intelligent Transportation Systems, etc.  
On the other hand, dynamic changes during operation 
typically allow for only a limited subset or scope of updates, 
which may not be sufficient for example if the goals of the 
network have to be radically changed in order to support a 
mega-event or provide emergency services in case of a 
catastrophic event such as an earthquake or flood. Even in 
normal operation, the ability to evolve significantly the 
objectives of the networking infrastructure over a period of 
time might provide opportunities for cutting costs, making it 
easier to integrate new systems as they become available or 
change the scope of a network to a secondary objective, 
while still being able to provide backup capacity to the new 
primary network in case it is required. Solutions for such 
problems require capabilities for spontaneous ad-hoc 
cooperation 
between 
objects, 
self-adaptive 
behavior, 
exploitation of dynamic information, predictability of non-
functional properties (e.g., energy consumption), and on-
the-fly reconfiguration [21], [22], [23]. 
88
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Summarizing, first and foremost, scalability is the key 
enabler for facilitating the (r)evolution of the Future Internet 
as the number of interconnected devices is expected to rise 
by yet another order of magnitude. The vast majority of 
these devices will be smart sensors with relatively limited 
computation resources. Thus, key challenges lie in efficient 
cooperation of heterogeneous network elements in order to 
realize advanced capabilities and services. Furthermore, 
innovations to low energy solutions create an attractive 
business case by offering benefits in terms of operational 
cost, long-term product reliability and increased lifetime of 
wireless and mobile elements (especially relevant for a 
significant portion of the myriad of electronic “Things” that 
will be battery powered in the Smart City environment). 
Last but not least, as the number of interconnected devices 
will increase a convergence of the Sensor Network and 
Data Analytics trends is required for effectively bringing 
processes and people into the equation. Following a short 
description of the different virtualization levels, an overview 
of the respective trends and key open issues is provided in 
the sequel of this section. 
III. 
VIRTUALISATION LEVELS  
The challenges identified in Section II for the evolution 
of Internet of Things require solutions for the scalability, 
data isolation and generation of relevant information at the 
end-user side. The latter will inevitably trigger changes at 
the network level, to handle performance issues as well as 
network/resource management technical challenges related 
to the vast number of interconnected devices and huge 
amount of generated data. Thus, this analysis addresses the 
benefits 
of 
virtualization 
at 
the 
end-user 
level, 
complemented by related requirements at the network side.  
Several types of virtualization can be distinguished at 
both the network and the end user side, including Virtual 
Machines and OS Virtualization, Sensor Virtualization, and 
Sensor Network Virtualization [24]. While the first two types 
have found their way into mainstream applications and are 
arguably the driving forces behind the cloud computing 
paradigm, the other two types are still in their infancy. In this 
work, we investigate sensor virtualization from the 
perspective of extracting relevant information from a large 
network of heterogeneous sensors, in a secure, efficient, and 
device-agnostic way. 
The end-user side addresses the interconnection of the 
different user hardware appliances/things (e.g., sensor or 
embedded devices) and is closely related to the evolution of 
the Internet of Things. However, the biggest breakthrough 
envisioned in this part is to include processes and people in 
the loop, enabling communications that are more relevant in 
order to offer new capabilities, richer experiences and 
unprecedented economic opportunities. To pave the way for 
this vision, sensor virtualization will play an important role 
towards: (1) addressing scalability challenges in the 
interconnection, control and management of a plethora of 
heterogeneous smart things, (2) promoting cooperation 
between the different elements in an energy efficient way, 
and (3) providing a basis over which the data analytics and 
sensor network trends can evolve and converge, independent 
of manufacturer-specific hardware or software perks [1].  
At the network side, virtualisation implements the 
abstraction of network elements and transport resources, as 
well as their combination into a common pool, possibly 
distributed among different network locations. When a static 
network location is considered, the physical resources of a 
single network element are partitioned to form virtual 
resources. The distributed case is realised through the 
relocation of specific network functions to standard hardware 
servers that can be placed anywhere in the network; in 
addition, the separation between physical resources and 
logical services of network elements is possible [25].  
In order to realize this separation, the Network 
Infrastructure 
Virtualization 
layer 
supports 
resource 
reusability and flexible resource pooling at the PHY and 
MAC layers. Its main purpose is to facilitate efficient usage 
of the network resources and not to abstract and aggregate 
their management from a central point. Thus, it facilitates 
the virtualization at the end-user side. 
In the end-user side we introduce the Thin Software 
Virtualization layer, to support dynamic formulation, 
merging and splitting of sensor network subsets that serve 
different applications and are possibly administered by 
different entities. This software is embedded in the end-user 
devices. It caters for (1) interoperability of heterogeneous 
sensors from different vendors, (2) exposure of the sensor 
basic functionality to the data consumer and sensor 
assignment to tasks, (3) data isolation and enforcement of 
the least privilege properties, and (4) collaboration with 
other sensors and/or consideration of analytic models that 
connect the underlying phenomena so that the sensed data 
can be transformed to relevant information, produced and 
transmitted on demand.  
 
Figure 1: Virtualization layers and supporting functions 
In addition, we propose the introduction of the following 
functionality within the layers (Figure 1): a) the Energy 
Management function, which spans across both the end-user 
and the network side - at the end-user side, an example of 
89
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

such functionality are the various LEACH variants or similar 
protocols that can be part of the node operating system; b) 
the Resource Management function, which realizes the fair 
dynamic resources allocation to the end-user devices; c) the 
Data Analytics  function, which is responsible for making 
sense of the collected information and extracting value from 
it, and d) the Self-Organization Function, residing at the 
network side to support the dynamic sensor collaboration. 
IV. 
SCALABILITY OF COMMUNICATION AND 
MANAGEMENT 
In order to realize the vision of ~50 billion devices 
connected to the Internet by 2020 [12], several scalability 
enablers need to be in place. One can argue that some of 
them are already here and they have driven the evolution 
towards the estimated ~10 billion interconnected devices 
that we have currently reached [12], [15]. Hardware node 
miniaturization, node capability enrichment and cost 
reduction, all fueled by Moore’s law, are a good example of 
such enablers. Processing and storage availability are also 
improving thanks to the cloud computing paradigm. On the 
network protocol naming and addressing part, the transition 
to IPv6 has to take place sooner than later in order to 
facilitate the next jump in number of interconnected devices.    
However, apart from the hardware node and protocol/ 
communication part, efficient management of this huge 
number of heterogeneous devices is also a big challenge. 
The concept of network management traditionally captures 
the methods and tools that are related to the operation, 
administration, maintenance, and provisioning of networked 
systems. In this context, operation is related to keeping the 
network 
working 
according 
to 
the 
specifications; 
administration is dealing with resource tracking and 
utilization; maintenance is concerned with changes and 
upgrades to the network infrastructure; and finally 
provisioning addresses dynamic, service-based resource 
allocation. However, catering for heterogeneous sensors and 
actuators deployed in Smart Cities, each with different 
requirements and operational properties calls for a paradigm 
shift; higher layers need to efficiently capture the changing 
dynamics of the systems and the lower layers need to 
transform this information into appropriate action, in an 
autonomous and scalable fashion. 
In recent years, several extensions have been proposed 
to the traditional definition of network management that are 
specifically designed to address the topic of ever increasing 
network management complexity. The Self-Organizing 
Network (SON) notion was introduced by the 3rd 
Generation Partnership Project (3GPP) and targets to 
constitute future radio access networks easier to plan, 
configure, manage, optimize and heal compared to current 
state of the art. In similar direction, Autonomic Networking, 
inspired by the IBM initiated vision for Autonomic 
Computing [26], has been proposed as a means to create 
self-managing networks able to address the rapidly growing 
complexity of modern large scale networks and to enable 
their further growth, far beyond the size of today. The four 
main 
pillars 
of 
Autonomic 
Networking 
are 
self-
configuration, self-healing, self-optimization, and self-
protection, known also as self-CHOP features. However, the 
related technologies have so far found their way mostly in 
cellular networks or in smaller scale ah-hoc sensor 
networks. Frameworks for configurable and, to some extent, 
reusable deployment of SON functionality would be an 
important evolutionary step in the direction of scalable 
network management and lower maintenance cost.  
V. 
COOPERATIVE COMMUNICATIONS AND NETWORKING  
Close cooperation between network elements is 
increasingly seen as an important driver for further 
evolution. In the FIA recommendations, it is referenced, for 
example, that the traditional client-server model will at least 
partially evolve into co-operative structures between peer 
entities.  Cooperation frameworks cover the full range from 
information exchange, actions coordination and decision 
making. Moreover, such aspects are expected to be utilized 
in different context, thus spanning different communication 
layers and capabilities. A taxonomy of cooperative and 
collaborative frameworks was presented in [21]. 
In order to achieve cooperation between networks in 
multi-stakeholder 
networking 
environments, 
proper 
incentives need to be in place. Such incentives formulate the 
expected networking benefits that a single network can 
derive from its cooperation with another. Networks are only 
motivated to cooperate with other networks when this 
cooperation improves their performance according to such 
incentives [21]. However, in order to be effective and 
support 
generalization 
in 
a 
large 
scale 
dynamic 
environment, the incentives should not express low-level 
performance metrics, but instead indicate high level 
functional and network requirements. An incentive 
formulates a reason for cooperation between networks (i.e., 
if cooperation with another network can improve this high 
level objective, cooperation might be viable). Example 
incentives are (i) increasing coverage (to reach more 
clients), (ii) reduce energy consumption (to increase battery 
life), and (iii) increasing QoS guarantees (higher throughput, 
higher reliability, lower delay, etc.), among others [21]. 
Deciding, however, on the most beneficial cooperation 
settings requires mechanisms such as negotiation [21], [27]. 
During negotiations, independent devices or complete 
networks with the required capabilities are identified and the 
utility of the cooperation is derived also as part of the 
cooperation incentive [28], [29], [30]. While significant 
research efforts have been invested in this area, large scale 
commercial application is still limited. Variations in the 
realization of the cooperation mechanisms and compatibility 
problems between the early products of different vendors 
are among the more important inhibitors; therefore ways to 
alleviate them will be particularly beneficial.  
90
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

VI. 
LOW ENERGY SOLUTIONS 
Energy efficiency is commonly perceived as one of the 
most important design and performance factors of a 
Wireless Sensor Network (WSN). This fact is only expected 
to increase in relevance as a myriad of additional mobile 
and portable devices will be connected to the Future 
Internet. The desired low energy behavior can be achieved 
by optimizing the sensor node as well as the communication 
protocol [31]. The goal is to reduce energy consumption 
and, consequently, increase the lifetime of the system.  
At the level of the independent nodes, the fundamental 
limit of the energy requirements is calculated by taking into 
account the energy consumption of every hardware (HW) 
component on a WSN node like sensors and conditioning 
electronic circuitry, processing and storage, radio, etc. The 
components selected in the final node architecture will have 
a significant impact on the nodes’ capabilities and lifetime. 
Thus, a holistic low-power system design should be pursued 
from the very beginning, creating the correct HW 
infrastructure base for further network, protocol, software 
and algorithmic energy efficiency optimization.  
This holistic low-power system approach can further 
incorporate methods for energy harvesting from the 
environment in order to utilize ambient energy sources (e.g., 
mechanical, thermal, radiant and chemical) that will allow 
extending lifetime and minimizing or possibly removing the 
need for battery replacement. Such a scenario would enable 
the development of autonomous wireless sensor networks 
with theoretically unlimited lifetime. Still focused on the 
sensor node level, but on the algorithmic part, ongoing 
efforts are targeting to design the sensor nodes in an 
inherent power-aware approach. The goal is to develop an 
adaptable system that is able to prioritize either system 
lifetime or output quality at the user’s request.  
Optimizations for low energy are a relatively mature 
field that has been (in different forms) around for a long 
time. For example, the radio communication and network 
protocol part is a major source of energy consumption that 
is often targeted for optimization. However, most of the 
available solutions are not directly transferable across 
different verticals and application domains.  
Optimizing the network protocol is typically done with 
respect to a specific application domain, usually to favor 
bursts of transmission followed by cycles of low or no 
activity. As the range of transmission is also a very 
important parameter, low energy operation of a specific 
protocol version is often achieved only for a selected range, 
whereas other protocols are more efficient beyond that 
range. Thus, a certain low energy protocol is typically 
“optimal” only with respect to a specific communication 
range and bandwidth, while other solutions might be 
preferable outside of this area. This implies that making the 
best selection usually requires a thorough understanding of 
the specific requirements and peculiarities of the targeted 
application domain and environment, so that the energy 
optimization can be appropriately tailored to these 
parameters. Therefore, a more transparent on-the-fly 
mechanism for node reconfigurations between different 
Pareto-optimal states is required to enhance sensor node 
reusability in the context of different vertical applications.  
VII. CONVERGENCE OF THE SENSOR NETWORK AND DATA 
ANALYTICS TRENDS 
In order to efficiently bring together “Things” with 
processes and people as envisioned by the Internet of 
Everything, connected “Things” will need to share higher-
level information with distributed peer entities, as well as 
with centralized processing units or people for further 
evaluation and decision making. This transformation from 
data sharing to information sharing is considered as 
particularly important in the IoE notion because it will 
facilitate faster, more intelligent decisions, as well as more 
effective control of our environment [12]. Similarly, in the 
field of industrial automation, there is clear movement 
towards keeping the pace with the rapidly increasing data 
footprint by a paradigm shift in data acquisition and 
processing [13].  
In parallel with these activities, a significant evolution is 
taking place in the data analytics domain. In this case, the 
trend is to evolve from “descriptive analytics” that capture 
what is happening to “predictive analytics” that describe 
what is likely to happen. Similarly, a little further down the 
road is the progress from “diagnostic analytics” that 
describe why something is happening to “prescriptive 
analytics” that describe what should happen, i.e., what is the 
optimal response. Fusion of “hard” data coming from 
sensors with “soft” data from, e.g., social networks (often 
called also soft fusion or social fusion) is another important 
trend in this domain, which is already going in the direction 
of bringing humans into the equation. “Pervasive analytics” 
(in some cases even referenced as “butler analytics”) are 
envisioning to bring the power of analytics in an ever 
increasing range of day-to-day applications and make them 
available to non-experts. The relation between sensor and 
analytic trends is depicted in Figure 2. 
 
Figure 2: Convergence between sensor and analytic trends 
At the same time, as the amount of data generated by 
this ever increasing number of sensors (augmented also by 
91
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the social fusion trend) reaches new heights, the defining 
3Vs of Big Data (Volume, Variety and Velocity) require 
revisiting in order to cope with the new requirements. In this 
direction, IBM has added Veracity as a fourth dimension 
that captures the uncertainty of the data. And while Volume 
and Velocity are to some extent infrastructure planning 
issues, a fundamental paradigm shift might be needed in 
order to address Variety and Veracity in a generic 
framework that is able to handle the requirements of all the 
data types without the need to develop from scratch 
algorithms for each of them. Deep Learning is a novel idea 
in machine learning that promises to do exactly that, 
extracting the relevant information (features) from different 
types of raw data, without the need for (expensive and time 
consuming) manual feature engineering by human experts 
[32]. 
Although data sharing and access to sensor information 
enables a number of new and innovative applications 
beneficial for users, a major effort is needed to ensure that 
data protection and privacy policies are met. In order to 
leverage the full potential of IoT, work needs to be done 
beyond identity and access management – trust and 
reputation systems need to be introduced which can serve 
the needs of widely distributed and highly scalable mobile 
networks, while offering mechanisms to preserve privacy 
for the users.  
Whenever users are accessing Smart City services in the 
IoT enabled world, identity related data must be handled 
according to existing regulations and principles. In order for 
the system to work efficiently at full capacity, sensitive data 
need to be exchanged between multiple devices. The 
challenges in the future IoE environment are even more 
complex as protecting privacy is evolving to a continuous 
effort. For example, privacy protection cannot stop with the 
end of the users’ session as the focus is not only on 
protecting the identity on short term. Location of users, 
content of queries, as well as the footprint everybody is 
creating by using services in IoT is of interest [33]. Unless 
proper precautions are taken, aspects such as people 
location, previously considered very hard to trace, will 
become traceable. At the same time, an adversary 
employing an IoT enabled attack will have a vast capacity 
for data collection and thus a large attack surface. The 
research community is faced with new challenges that have 
yet to be fully addressed [34].   
A nice example of a future Smart City / IoT service is 
participatory sensing enabled environmental monitoring. In 
this scenario people are encouraged to provide data on 
pollution throughout the city using measurements from 
personal mobile sensors. Even this simple example shows 
how easy the users’ location together with a measurement 
timestamp can give more information than originally 
intended. The success of numerous Internet of things 
applications of similar nature will depend on the ability of 
contributors to preserve their privacy while maintaining 
accountability [35]. Despite the numerous challenges, some 
important steps in the required direction have already been 
made. 
New 
techniques 
combining 
anonymization, 
pseudonyms, and statistical disclosure control, will allow 
users to keep track of their privacy footprint [36], including 
also the information they are disclosing indirectly.  
Having processed the IoT generated information by 
some advanced data analytics algorithm, one scenario is that 
certain actions are then automatically realized without 
human intervention. However, there are cases that the final 
decision process might still be desirable to be done by a 
human expert, especially in the context of Smart Cities in 
the IoE vision where people are also an important part of the 
equation. In the latter case, Visual Analytics are coming into 
play in order to make the information perceptible to 
humans. Visual Analytics are a combination of machine 
learning tools and advanced information visualization 
methods with the goal of facilitating analytical reasoning. 
Such techniques might be for example of particular interest 
in the detection of trends and their possible causes inside an 
ocean of unstructured sensor data, so that informed 
decisions that combine human judgment and relevant data 
evidence can be made.  
Nevertheless, in order to apply all these advanced Data 
and Visual Analytics algorithms major impediments such as 
the limitations in bandwidth and storage (for example when 
dealing with devices generating a large data footprint, such 
as video camera streams) have to be tackled.  To overcome 
these limitations arising from the current systems for M2M 
applications, novel approaches have been proposed which 
are based on the following principle: storing and processing 
the data as close as possible, both in space and time, to 
where they are generated and consumed, hence enabling the 
so-called analytics at the edge [37].  
It is worth mentioning that developments in pervasive 
analytics and analytics at the edge go hand in hand, as both 
are aiming for migrating analytics capability to the 
“Things”, i.e., towards the edge of the network. An 
indicative realization of those proposals will be defined by a 
content-centric platform distributed over a local cloud, 
hosted by the gateways or advanced edge devices with 
process and storage capabilities.  This approach will not 
only alleviate the big-data problem as data is processed 
where it is created, but also will reduce network traffic and 
communication costs and can facilitate faster reactions when 
an event or an alarm is generated. 
The desired destination in the convergence of IoT and 
Data Analytics is a framework of abundant sensor 
information taping at the “anytime, anyplace […] 
connectivity for anything” notion of the IoT combined with 
advanced analytic models that can provide real insight (in 
the 
form 
of 
human-consumable 
prediction 
and 
recommendation) for any situation and usable by everyone.  
However, significant steps need to be taken before this 
vision is realized. “Analytics” is a very broad and varying 
field, and while wrapping them in a user friendly package is 
easy, using them in an irresponsive way without knowledge 
92
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

or respect for possible limitations or model constraints, can 
be the recipe for disaster [38]. Frameworks that can provide 
different tradeoffs of accuracy, execution time and easiness 
to interpret, enforce privacy policies, and at least make the 
users aware of model limitations and constraints would be 
an important driver towards approaching this vision.      
VIII. SENSOR INFRASTRUCTURE VIRTUALIZATION AS A 
DRIVER TOWARDS THE FUTURE INTERNET 
Achieving a significant progress in the four open 
challenges identified in the previous sections calls for 
frameworks that either facilitate innovation or minimize the 
cost/risk for each of the four pillars identified previously 
(scalability, 
cooperation, 
low 
energy 
solutions 
and 
convergence of Sensor Network and Data Analytics trends). 
It is also important to underline that these pillars are not 
completely autonomous, but are mutually dependent. For 
example, one of the objectives of cooperation might be low 
energy operation, while the cooperation process by itself has 
to be scalable. Therefore, an important constraint is that 
possible solutions for each challenge are as transparent as 
possible to the other topics, to avoid setbacks in other fronts. 
A promising paradigm for addressing challenges in terms of 
decreasing the cost/risk as well as facilitating innovation in 
some of the topics identified previously is virtualization, as 
discussed in the Virtualization Levels Section.  
Virtual Sensor Networks (VSNs) are emerging as a 
novel form of collaborative wireless sensor networks [39] 
that can establish the basis over which the evolution from 
connecting “Things” to the efficient interaction of the 
“Things” with processes and people can be realized [1]. A 
VSN can be formed by supporting logical connectivity 
among collaborative sensors [24], [39], [40]. Nodes are 
grouped into different VSNs based on the phenomenon they 
track (e.g., number of cars vs. NO2 concentration) or the 
task they perform (e.g., environmental monitoring vs. traffic 
control). VSNs are expected to provide the protocol support 
for formation, usage, adaptation, and maintenance of the 
subset of sensors collaborating on a specific task(s).  
Even 
nodes 
that 
do 
not 
sense 
the 
particular 
event/phenomenon (directly or indirectly by the notion of 
Virtual Sensor - VS) could be part of a VSN if they permit 
sensing nodes to communicate through them. Thus, VSNs 
can utilize intermediate nodes, networks, or other VSNs to 
deliver messages across VSN members. The same physical 
infrastructure can be reused for multiple applications, 
promoting scalability and resource efficiency. In addition, 
VSN at the end user side allows for devices sharing among 
several 
virtual 
networks 
serving 
different 
purposes/applications. This concept builds upon the Service 
Oriented Architecture (SOA) paradigm, which provides a 
flexible infrastructure and processing environment for 
service-based software design. SOA lays its foundation in 
service provision to end-user applications/other services 
distributed in a network and comprises functionality for 
describing, publishing and discovering services as well as 
service composition and management [41], [42]. Using 
SOA, each end-user device may use one or more of the 
available services independent of the other devices. In a 
similar manner, respective functionality will be supported 
by the VSN at the end user side for the mapping of the 
devices to the virtual networks, the aggregation of the 
application based on the functions available in each node 
and the over VSN management. All of these architectural 
considerations are relevant for creating a unified situational 
awareness picture of the Smart City, as discussed in Section 
II. 
The VSNs may also evolve into a dynamically varying 
subset of sensor nodes (e.g., when a phenomenon develops 
in the spatial domain, the sensors that can detect it change 
over time). Similarly, the subset of the users or processes 
having access rights to different subsets of the VSN can 
vary (e.g., the people that have access to the network change 
with time or specific operations on a sensor network subset 
are only available to specific groups of people based on 
their role, etc.). This node grouping, merging and splitting 
property makes it easier to define, apply, and update policies 
(e.g., least privilege access) based on conceptual models 
rather than by configuring each of the myriad nodes 
independently. 
Having alleviated part of the scalability and information 
protection/privacy requirements through the VSN concept is 
a good starting point for progressing on an even more 
ambitious front: going from data exchange between sensors 
to the sharing of relevant information, produced on the spot 
as and when required, so that it can be consumed on demand 
by processes and people. This paradigm is also promising to 
address the transmission and processing challenges that 
traditional large scale sensor installations face. The latter 
include various Big Data scalability issues with respect to 
the centralized gathering, logging and processing of the 
sensor data. The Virtual Sensor notion is instrumental in this 
effort.  
In this paper, we use the term Virtual Sensor (VS) to 
refer to a software entity that can serve as an aggregation 
point for multiple sensors, using physical sensor entities and 
a computational model to combine their measurements [1]. 
The VS can be a thin layer of virtualization software that is 
executed on physical sensors (often referred as embedded 
hypervisor) or it can be a mathematical model for 
aggregating information residing in a sensor management 
platform similar to [41].  
These different realizations of the VS notion face 
different types of challenges. For example, centralized or 
hybrid semi-centralized solutions based on analytic engines 
have to address the challenges of data fusion from 
heterogeneous sources, both functional (different credibility 
levels of the sensors, co-dependent sensor observations, 
difficulty to link human information needs to sensor control, 
etc.) and non-functional (scalability and performance 
problems, security and privacy requirements, etc.). It should 
be noted at this point that the non-functional requirements 
93
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

such as scalability and privacy can prove critical in a Smart 
City context were a multitude of private and public devices 
need to interoperate and exchange potentially sensitive 
information.  
At the same time, the embedded hypervisors have to 
cope with the integrated nature of embedded systems, and 
the related need for isolated functional blocks within the 
system 
to 
communicate 
rapidly, 
to 
achieve 
real-
time/deterministic performance, and to meet a wide range of 
security and reliability requirements [2], [44]. In this 
context, bringing more processing capacity and intelligence 
in the end devices is both inevitable and necessary in order 
to cope with scalability challenges [21]. The related 
analytics at the edge effort (see Section VII) is focusing on 
realizing this transition from centralized to (semi)distributed 
analytics. 
However, despite the different types of challenges, both 
embedded hypervisors and analytically/computationally 
realized virtual sensors share a number of key properties. 
First and foremost, the VS is doing more than interpolating 
values of physical sensors measuring the same phenomenon, 
as translation between different types of physical sensors is 
a far more interesting topic when models for the relations 
between 
the 
underlying 
phenomena 
are 
available. 
Furthermore, such models can even be learned by data over 
time in a (partially) unsupervised manner, according to the 
Deep Learning paradigm [32] as indicated in Section VII. 
An interesting use case for this translation process in an 
urban setting is the estimation of car pollution based on a 
model that combines car counting (e.g., by induction loops 
or cameras) and weather conditions, while possibly utilizing 
also the information from the few available pollution 
sensors [1]. In this case, the VS can be configured to report 
periodically the estimated pollution value and give a 
warning if the pollution is above certain regulations 
(relevant information), instead of continuously reporting all 
the data. 
Another example that is applicable in smart grid 
scenarios is the calculation of electric grid parameters (e.g., 
the load on given points in the transmission network, or the 
sag of transmission lines). Such information can be deduced 
by the Virtual Sensor indirectly from correlated values and a 
model of the related phenomena, even with a sparse network 
of different sensors (e.g., voltage and temperature sensors 
for the sag case, coupled with measurements of wind speed 
from a nearby weather station). Again the VS can issue 
warnings or alerts when some dynamic threshold values are 
exceeded instead of producing and transmitting all the 
information continuously. It is important to note that both 
the 
embedded 
hypervisor 
and 
the 
platform-based 
realizations of Virtual Sensors can employ state of the art 
signal processing techniques such as compressive sensing 
(for efficiently reconstructing a signal from relatively few 
measurements taking advantage of sparseness properties) or 
robust statistics (for copying with outliers, impulsive 
interference, etc.). 
  
 
Figure 3: Sensor Infrastructure Virtulization depicted over the various dimensions of cooperative decision making and control.  
94
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
At their core, VSNs and VS are building on and/or 
extending existing collaborative networking paradigms, 
therefore classifying them with respect to the ways that 
cooperation is realized in more conventional cooperative 
communication schemes is of great value. Taking into 
consideration the properties of Virtual Sensors and VSNs 
discussed previously, an updated model of the 3D 
cooperative methods taxonomy introduced in [21] that also 
captures the different sensor-level virtualization aspects is 
provided below. Figure 3 depicts the scope of the 
cooperation as planes in a 3D space. Specifically, the 3 axis 
are: 1) information exchange, with the extreme values being 
independent sensing and full context exchange, 2) decision 
and configuration control with the extreme values being 
independent actions and fully coordinated actions, and 3) 
layer mechanisms, with the extreme values being upper layer 
and lower layer mechanisms.  
Each of these dimensions is being associated to a set of 
enablers and technical areas [1]. For example, cross-layer 
coordination spans the range of medium and low layer 
mechanisms, it requires a high information exchange level, 
and the level of coordination varies from medium/high to 
very high. Similarly, Virtual Sensors are depicted in the 
representation as a 3D cloud that spans medium to upper 
layer mechanisms. This cloud covers low/medium to high 
information exchange (because a VS can be either realized 
on the nodes as thin virtualization software or implemented 
as an aggregation software component running in a 
centralized platform). Finally, the cloud is mostly touching 
the area around medium action coordination since the state 
of the art efforts are mainly focusing more on the sensing 
rather than the actuation. The cloud that represents a VS can 
therefore expand to cover more of the axis that represents 
actions, in case virtualized actuation becomes more relevant 
in the future. 
IX. 
CONCLUSION 
The rapid proliferation in the number of devices 
connected to the Internet that occurred during the last 
decade is expected to continue, targeting yet another order 
of magnitude increase and promising to bring people and 
processes in the equation. However, in order to realize this 
paradigm shift, important challenges with respect to 
scalability, 
cooperative 
communications, 
energy 
consumption, as well convergence of sensor and analytics 
trends need to be addressed. In this paper, we have 
elaborated on the different flavors of Sensor Infrastructure 
Virtualization as a powerful enabler that can pave the way 
towards the next evolution of the IoT. The latter is expected 
to trigger disruptive innovation across different domains, 
laying the foundation for the Smart Cities of the future. 
ACKNOWLEDGMENT  
Part of this work has been performed under the research 
project FutureNET. The research project is implemented 
within 
the 
framework 
of 
the 
Action 
"Supporting 
Postdoctoral Researchers" of the Operational Program 
"Education and Lifelong Learning" (Action’s Beneficiary: 
General Secretariat for Research and Technology), and is 
co-financed by the European Social Fund (ESF) and the 
Greek State. 
REFERENCES 
[1] A. Merentitis, et al., “WSN Trends: sensor infrastructure 
virtualization as a driver towards the evolution of the Internet of 
Things,” International Conference on Mobile Ubiquitous Computing, 
Systems, Services and Technologies (UBICOMM), pp. 113-118, 
September 29 - October 3, 2013, Porto, Portugal. 
[2] A. Merentitis, N. Kranitis, A. Paschalis, and D. Gizopoulos, “Low 
energy on-line self-test of embedded processors in dependable WSN 
nodes,” IEEE Transactions on Dependable and Secure Computing, 
2011, vol. 9,  issue 1, pp. 86-100. 
[3] National Intelligence Council, “Disruptive civil technologies: six 
technologies with potential impacts on US Interests out to 2025,” 
Apr. 2008. [Online]. http://www.fas.org/irp/nic/disruptive.pdf, last 
access: May 2014. 
[4] International Telecommunication Union “The Internet of Things” 
2005. 
[5] J. Kjeldskov, M. Skov, G. Nielsen, S. Thorup, and M. Vestergaard, 
“Digital urban ambience: mediating context on mobile devices in a 
city,” Pervasive and Mobile Computing, vol. 9, issue 5, 2013, pp. 
738–749. 
[6] J. Kiljander, A. Ylisaukko-oja, J. Takalo-Mattila, M. Eteläperä, and 
J.-P. Soininen, “Enabling semantic technology empowered smart 
spaces,” Journal of Computer Networks and Communications, vol. 
2012, 2012, pp. 14. 
[7] G. Kortuem, F. Kawsar, V. Sundramoorthy, and D. Fitton, “Smart 
objects as building blocks for the internet of things,” IEEE Internet 
Computing, vol. 14, no. 1, pp. 44–51, Jan. 2010. 
[8] D. Korzun, S. Balandin, A. Gurtov, “Deployment of Smart Spaces in 
Internet of Things: Overview of the Design Challenges, Internet of 
Things, Smart Spaces, and Next Generation Networking, 13th 
International Conference,”  NEW2AN 2013, and 5th Conference, 
ruSMART 2013, Springer, Lecture Notes in Computer Science, vol. 
8121, 2013, pp 48-59. 
[9] L. Atzori, A. Iera, and G. Morabito, “The Internet of Things: a 
survey,” Computer Networks, vol. 54, no. 15, 2010, pp. 2787–2805. 
[Online]. 
http://www.sciencedirect.com/science/article/pii/S138912861000156
8, last access: May 2014. 
[10] D. Miorandi, S. Sicari, F. D. Pellegrini, and I. Chlamtac, “Internet of 
Things: vision, applications and research challenges,” Ad Hoc 
Networks, vol. 10, no. 7, 2012, pp. 1497–1516. [Online]. 
http://www.sciencedirect.com/science/article/pii/S157087051200067
4, last access: May 2014. 
[11] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of 
Things (IoT): A vision, architectural elements, and future directions,” 
Future Generation Computer Systems, 2013, vol. 29, issue 7, pp. 
1645-1660 
[Online]. 
http://www.sciencedirect.com/science/article/pii/S0167739X1300024
1, last access: May 2014. 
[12] D. Evans, “The Internet of Everything: how more relevant and 
valuable connections will change the world”, CISCO White Paper 
[Online]. http://www.cisco.com/web/about/ac79/docs/innov/IoE.pdf, 
last access: May 2014. 
[13] National Instrumnets, Data Acquisition Technology Outlook 2013, 
[Online]. http://www.ni.com/daq-trends/, last access: May 2014. 
[14] P. C. Evans and M. Annunziata, “Industrial Internet: pushing the 
boundaries of minds and machines,” GE White Paper, Nov. 26, 2012, 
[Online]. 
http://www.ge.com/docs/chapters/Industrial_Internet.pdf, 
last access: July 2013. 
95
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[15] J. Bradley, J. Barbier, and D. Handler, CISCO White Paper, 
“Embracing the Internet of Everything to capture your share of $14.4 
trillion,” 
[Online].http://www.cisco.com/web/about/ac79/docs/innov/IoE_Econ
omy.pdf, last access: May 2014. 
[16] United Nations, “World urbanization prospects 2011 revision,” 
[Online] http://esa.un.org/unup/, last access May 2014. 
[17] The 
Economist, 
“Running 
out 
of 
road”, 
[Online] 
http://www.economist.com/node/8355114, last access May 2014. 
[18] The London Dahsboard, [Online] http://data.london.gov.uk/london-
dashboard, last access: May 2014. 
[19] ETSI 
technical 
report, 
“Machine-to-Machine 
communications 
(M2M); study on semantic support for M2M data,” ETSI TR 101 
584, 
http://www.etsi.org/deliver/etsi_tr/101500_101599/101584/02.01.01_
60/tr_101584v020101p.pdf, last access: May 2014. 
[20] Future Internet Architecture (FIArch) Group, “Future Internet design 
principles,” 
January 
2012, 
[Online]. 
http://www.future-
internet.eu/uploads/media/FIArch_Design_Principles_V1.0.pdf, 
last 
access: May 2014.  
[21] G. Koudouridis, et al., “Enablers for energy-aware cooperative 
decision and control in wireless networks,” Vehicular Technology 
Conference C2POWER Workshop, May 2011, pp.1-5, Budapest, 
Hungary. 
[22] N. Alonistioti, et al., “Towards self-adaptable, scalable, dependable 
and 
energy 
efficient 
networks: 
the 
self-growing 
concept,” 
UBICOMM, 25-30 October 2010, pp. 324-327, Florence, Italy. 
[23] E. Patouni, A. Lilis, A. Merentitis, N. Alonistioti, C. Beaujean, D. 
Bourse, and E. Nicollet, “Protocol reconfiguration schemes for 
policy-based 
equipment 
management,” 
Vehicular 
Technology 
Conference (VTC), September 2006, pp.1-5, Montréal, Canada. 
[24] H. M. N. D. Bandara, A. P. Jayasumana, and T. H. Illangasekare, 
“Cluster tree based self organization of virtual sensor networks,” 
GLOBECOM Workshops Nov. 2008, pp.c 1-6, New Orleans USA.  
[25] NGMN Technical Document, “Suggestions on potentil solutions to 
C-RAN by NGMN alliance,” January 2013, version 4.0. 
[26] B. Jacob, R. Lanyon-Hogg, D.K. Nadgir, and A.F. Yassin, 
“A practical guide to the IBM autonomic computing toolkit,” 
IBM, International Technical Support Organization, 2004. 
[27] P. Magdalinos, et al., “A proof of concept architecture for self-
configuring 
autonomic 
systems,” ICT 
Mobile 
and Wireless 
Communications Summit, June 2008, Stockholm, Sweden. 
[28] K. 
Chatzikokolakis, 
R. 
Arapoglou, A. 
Merentitis, and 
N. 
Alonistioti, “Fair power control in cooperative systems based on 
evolutionary techniques,” UBICOMM, September 2012, pp. 111-116 
Barcelona, Spain. 
[29] A. Merentitis and D. Triantafyllopoulou, “Transmission power 
regulation 
in 
cooperative 
cognitive 
radio 
systems 
under 
uncertainties,” International Symposium on Wireless Pervasive 
Computing, (ISWPC), pp. 537-568, 5-7 May 2010, Modena, Italy. 
[30] E. Patouni, B. Fuentes, and N. Alonistioti, “A network and service 
governance framework: case study for efficient load balancing,” in 
the Proceedings of the IEEE 17th International Workshop on 
Computer Aided Modeling and Design of Communication Links and 
Networks 2012 (CAMAD 2012), 17-19 September, Barcelona, Spain. 
[31] G. Anastasi, M. Conti, M. D. Francesco, and A. Passarella, “Energy 
Conservation in Wireless Sensor Networks: a Survey,” Journal of Ad 
Hoc Networks, vol. 7, issue 3, May, 2009, pp. 537-568. 
[32] G. E. Hinton, “Learning multiple layers ofrepresentation,” Elsevier 
Trends in Cognitive Sciences, 2007, vol. 11, no. 10.  
[33] J. Braun, J. Buchmann, C. Mullan, and A. Wiesmaier, “Long term 
confidentiality: a survey,” Designs, Codes and Cryptography, pp. 1–
20, September 2012. 
[34] I. Barreira, T. Gustavsson, A. Wiesmaier, C. Galan, and S. Gorniak, 
“ENISA Guidelines for trust services providers,” ENISA Guidelines, 
December 2013. 
[35] F. Zeiger and C. Gorecki, “Method and system for preserving privacy 
and accountability,” Application for patent at the European Patent 
Office, EP2592805 . 
[36] R. Steele and A. Clarke, “The Internet of Things and Next-generation 
Public Health Information Systems,” Communications and Network, 
vol. 5 No. 3B, August 2013, doi=10.4236/cn.2013.53B1002. 
[37] Distributed Data Mining and Big Data, Intel White Paper [Online]. 
http://www.intel.com/content/dam/www/public/us/en/documents/whit
e-papers/distributed-data-mining-paper.pdf, last access: July 2013. 
[38] N.N. Taleb, “The Black Swan: the impact of the highly improbable,” 
Random House Digital, Inc., 2010, ISBN 978-1400063512, 
doi=10.1007/s00362-009-0226-8.  
[39] L. Sarakis, T. Zahariadis, H. Leligou, and M. Dohler, “A framework 
for service provisioning in virtual sensor networks,” EURASIP 
Journal on Wireless Communications and Networking 2012, pp. 1-19. 
[40] N. M. M. K. Chowdhury and R. Boutaba, “A survey of network 
virtualization,” Computer Networks, vol. 54, no 5, Apr. 2010, pp. 
862–876. 
[41] R. Berbner, T. Grollius, N. Repp, J. Eckert, O. Heckmann, E. Ortner 
and R. Steinmetz R, “An approach for the Management of Service-
oriented Architecture (SoA)-based Application Systems,” In: 
Proceedings of the Workshop Enter-prise Modelling and Information 
Systems Architectures, EMISA 2005, pp 208-221.  
[42] M.P. Papazoglou, and W-J van den Heuvel. “Service-Oriented 
Computing: State-of-the-Art and Open Research Issues,” IEEE 
Computer. v40 i11 (2003). 
[43] V. Gazis, K. Sasloglou, N. Frangiadakis, P. Kikiras, A. Merentitis, K. 
Mathioudakis, and G. Mazarakis, “Architectural Blueprints of a 
Unified Sensing Platform for the Internet of Things,” International 
Conference on Computer Communications and Networks (ICCCN), 
30 July – 2 August, 2013, Nassau, Bahamas. 
[44] A. Merentitis, G. Theodorou, M. Georgaras, and N. Kranitis, 
“Directed Random SBST Generation for On-Line Testing of 
Pipelined Processors,” International On-Line Testing Symposium 
(IOLTS), 6-9 July 2008, Rhodes, Greece. 
 
 
 
96
International Journal on Advances in Internet Technology, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/internet_technology/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

