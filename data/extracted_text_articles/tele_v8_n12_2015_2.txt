9
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Musing: A Mobile Client and Web Server Augmented Reality Application for 
Museum Visitors and Curators  
K. Whiteside1, G. Atkinson1, M. Stump2, G. Lawrence2, D. E. Tamir1 
 
1Department of Computer Science 
2School of Art and Design 
Texas State University 
San Marcos, TX, USA 
{kjw52, gma23,mr14,gl16,dt19}@txstatet.edu 
 
Abstract‚ÄîTextual didactics, used in museums and galleries 
provide access to historical, socio-political, technical, and 
biographic information about the artworks and artists. These 
types of didactics are considered to be cost-effective. However, 
they do not enable the use of audio, video, and Web interface 
that allows for multiple forms of usage for the museum 
visitors. We have developed a smartphone application, called 
Musing, for interaction of museum visitors with informational 
content and enhancement of their museum experience. Musing 
is an augmented reality (AR) application that enables the 
visitor to capture an artwork with a smartphone camera. Using 
image processing, the application recognizes the artwork and 
places graphical user interface objects in the form of Points of 
Interest (POIs) onto the image of the artwork displayed on-
screen. These POIs provide the visitor with additional didactic 
information in the form of text overlays, audio, video, and Web 
sites. The Musing application and administrator Web site, 
described in this paper, is designed with several performance 
and efficiency goals, including high reliability and recognition 
rate, high usability, and significant flexibility. The application 
is designed to be adaptable to a variety of museums and 
galleries without requiring special hardware or software. 
Furthermore, the administrative interface enables museum 
staff to provide content for the didactics without requiring 
software development skills.  
 
Keywords‚Äîinteractive didactic; museum didactic; virtual 
museum; image recognition;  augmented reality 
I. 
 INTRODUCTION 
Museums have historically been tasked with providing 
access to, and educating visitors about artworks. Museum 
didactics attempt to clarify artworks‚Äô meanings by 
addressing concepts of art, history, politics, construction 
techniques, as well as the lives of artists. For many visitors, 
however, museum and gallery exhibitions may lack the 
proper context to allow access points for exhibited works and 
can leave the ‚Äúuninitiated viewer‚Äù intimidated, ‚Äúparticularly 
when it comes to interpretation‚Äù [1][2]. 
In many ways, mobile technologies, such as responsive 
Web sites and AR, present an ideal opportunity to make 
those personal connections with the visitor, as well as help 
the visitor make connections to the exhibited objects and/or 
works of art. As such, the context for the artwork is 
broadened via interviews, videos, Web sites, source material, 
art historical influences, and other artworks with shared 
conceptual frameworks, all of which can be integrated into a 
mobile application for the museum. Such a personalization 
of experience through narrative is a highly effective way to 
expand the context for the work and deepen viewers‚Äô 
connections as they process and integrate the information 
into their existing world-view [3]. 
Nevertheless, under the current paradigm, in order to add 
audio and video to exhibits, museums must rely on 
proprietary hardware and software. The hardware must be 
provided by the institution at significant cost both in capital 
investment and in maintenance. The software used on these 
devices is often proprietary for the exhibition, reliant on 
external hardware installed in the gallery, and must be 
reprogrammed for new exhibitions. While large museums 
have the resources to purchase and maintain these systems, 
small community-based museums often do not. 
Pedagogical 
shifts 
away 
from 
passive 
museum 
participation to active participation are occurring in higher 
education, as well as in museological practices, and reflect 
the changing needs of the visitor [4].  An enriched learning 
environment requires incorporating diverse learning styles, 
which 
include 
visual/print, 
visual/picture, 
auditory, 
kinesthetic, and verbal/kinesthetic modalities [4]. 
A. Problem Statement 
In order for museums and galleries to fully meet the 
needs of their visitors, they must incorporate didactic 
information that embraces diverse learning styles and present 
multiple types of didactic information.  
An interactive didactic system should be designed to 
reach the highest number of museums and their visitors, 
which does not rely on proprietary hardware, the installation 
of external devices in the gallery, or the need to reprogram 
the system when exhibits are modified or added. 
In order to create a system that does not require 
proprietary hardware, the system should be developed on 
mobile hardware that many of the museum visitors already 
possess. 
This 
hardware 
would 
include 
classes 
of 
smartphones and tablets running on iOS or Android 
operating systems.  
To minimize the technical burden on institutions, the 
system should not rely on extra hardware such as Bluetooth 
or Near Field Communication (NFC) devices.  
An administrator panel should be designed to facilitate 
ease of editing‚Äîaddition and deletion of content in such a 
way as to give museologists these abilities without the 
requirement of software development skills. 

10
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Finally, image processing and image recognition 
algorithms should be used in order to provide the opportunity 
for the viewers to deepen their connections to artworks by 
scanning artworks directly, removing the need for external 
tokens such as Quick Response codes (QR) or number codes 
to be entered by users. 
B. Hypothesis 
By using a combination of off-the-shelf image 
recognition algorithms and unmodified consumer-level 
hardware, the research team will be able to create a client 
application that is fast and accurate enough to be usable in a 
museum, without the need for proprietary hardware, or 
external tokens. In addition, retrieving exhibition data via a 
database will allow for a client program that is sufficiently 
flexible and does not require reprogramming when 
exhibitions are added or modified.  
The proposed interactive didactic system will be 
designed with a client-server architecture. A database, 
administered by a Web site, will provide the client 
application with access to didactic information without the 
need to permanently store that information on the device. 
The client application will be programmed for current 
popular hardware such as a smartphone or a tablet, either 
owned by the museum visitor or provided in the form of 
loaners. 
Providing museologists with an efficient and usable 
software tool that facilitates generating new AR exhibitions 
and editing / modifying existing AR exhibitions (i.e., editing 
the Musing server) without requiring software development 
skills will enable widespread usage of the client part of 
Musing.     
In order to test the relative success of the application and 
its acceptance by museum visitors, Musing will be deployed 
in three exhibitions at The University Galleries at Texas 
State University, a three thousand square foot, university-
based, contemporary art exhibition venue. Benchmark 
testing of the application will be conducted in order to 
determine recognition accuracy rate and speed. Post-exhibit, 
exit questionnaires will be given to visitors in order to 
determine their acceptance of the client application and 
perceptions of system performance and usability. 
C. Proposed Solution 
The research team has developed Musing, a mobile, 
image recognition and AR application that runs on 
consumer-based iOS systems, requires no external tokens or 
hardware, and does not require reprogramming between 
exhibits.  The application has passed the Apple approval 
process and is available at [5]. 
The main contributions of this research is the design, 
development, and deployment of an end-to-end reliable, 
usable, and effective AR system that provides a museum 
visitor with virtual information and provides museum staff 
with adaptable, cost effective, and easy to maintain virtual 
museum utility. To date and to the best of our knowledge, 
this is the only fully functional system that integrates 
custom-hardware agnostic and custom-software agnostic 
virtual museum content delivery and administrative support, 
which does not require hardware to be installed in the 
exhibition space, and is freely available to consumers. 
This paper, which is an expanded version of [1], is 
organized in the following way: Section II provides 
background in the form of relevant past research performed 
by this team, with Section III containing a Literature review. 
The application deployment of the Musing client application, 
as well as its associated administration back-end is outlined 
in Section IV, followed by deployment results showcased in 
Section V. Section VI explains the evaluation of results from 
both benchmark testing and exit questionnaires given to the 
museum visitors. Lastly, Section VII outlines the conclusions 
and future research objectives for Musing. 
II. 
BACKGROUND 
A. Previous Research 
In 2012, the research team developed a series of 
responsive Web pages triggered by QR codes used in an 
exhibition at The University Galleries at the Texas State 
University [6].  
In this pilot program, QR codes were included in the 
tombstone wall labels placed next to artworks in the gallery. 
These codes, when scanned with reader software on the 
user‚Äôs smartphone, presented the visitor with a custom-built 
Web responsive page for each artwork (Figure 1). These 
pages provided supplemental didactic information via news 
articles that pertained to the artwork‚Äôs subject matter, full 
artist biographies, video interviews with the artist, photos of 
the artist‚Äôs workspace, and links to external Web sites. 
 
 
Figure 1. Example QR-triggered Web page with artist interview 
(http://www.txstgalleries.org/michael-henderson) 
 
During the pilot exhibition, the gallery Web site recorded 
23 unique visitors per day with an average time on-page of 3 
minutes and 37 seconds. The Web pages that were only 
accessible by the QR codes were responsible for 16 of the 23 
unique daily visitors (69%) and the majority of the time on-
page (3 minutes and 33 seconds). For comparison, exhibits 
installed after the pilot test did not include QR codes. The 
subsequent exhibit showed a decline in both the number of 
online visitors (-26%) and the amount of time visitors spent 
on the gallery Web site (-42.5%). This data indicates that 
when QR codes and their associated didactic information are 

11
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
included with the artworks in the gallery, there is an increase 
in online interaction with the visitor. 
The experiment with QR codes in the gallery indicated 
that visitors would use interactive technologies in the gallery 
and that they would spend the time necessary to consume the 
extra content. However, a major drawback of the QR codes 
was the inability for the museum professional to contextually 
place information within an artwork‚Äôs representation. The 
newer AR technology would allow the administrator to place 
content exactly where it would be most pertinent to the 
visitor‚Äôs view of the artwork. For example, a POI could be 
placed over a specific person or place in an artwork to 
provide 
information 
about 
the 
historical 
or 
social 
significance. Lastly, QR code reader software is not created 
specifically for the needs of museums and galleries, as they 
are designed to work for a wide variety of applications, from 
advertising to stock keeping. 
Following the positive response to the QR code project, it 
was decided that the next step in the research should be to 
create an AR system allowing for information placement 
within an artwork, and which could be designed specifically 
for the needs of museums and galleries.  
Several aspects of the Musing system, such as the 
pedagogical and art design characteristics are covered in 
[7][8]. The current paper, as well as [1], concentrate on the 
user experience and the technological innovation which 
enables this experience. 
III. 
LITERATURE REVIEW 
The literature review is addressing two areas of interest: 
1) The relevance and potential for a positive influence of 
technology in an exhibition setting on the visitor experience, 
and 2) current use and applications of AR and mobile 
applications within an exhibition setting.  
In his article, ‚ÄúDesigning Mobile Digital Experiences,‚Äù 
Tallon talks about the ‚Äúpotential of digital technology‚Äù as it 
surpasses its own hype to become a source of enrichment 
for visitors‚Äô learning [9]. This positions the visitor as a 
collaborator in the process of making meaning by gathering 
information and connecting them through their personal 
frame of reference. 
Stephen Weil, author of Making Museums Matter, 
advocates for museums to ‚Äúbe more than merely a 
communicator or a stimulant‚Äù [10].  Moving from the 
traditional (and outmoded) linear model of communication 
that provides didactic information in an institutional voice 
via wall labels and gallery talks, to a circular model that 
promotes‚Äîby incorporating technology into the exhibition 
materials‚Äîan enriched environment in which the visitors 
can partner in the making of meaning by aggregating a 
variety of information types as well as voices within the 
information dissemination. Learning environments that 
qualify as enriched are reflective of a variety of learning 
modalities: visual, auditory, and kinesthetic [11], which are 
comprised of seeing, hearing, and interaction. This is 
imperative if museums visitors are to move toward relating 
to art in a non-linear manner. 
Another influential theory can be found in John Falk‚Äôs 
book, ‚ÄúIdentity and the Museum Visitor Experience‚Äù [12], 
wherein Falk identifies five key types of visitors who attend 
museums while also defining visitor motivation. These five 
key user types fall within the definitions of human need, 
rather than that of demographics and are characterized in the 
following ways relative to basic human needs. They are:  1) 
Explorers‚Äìmotivated by personal curiosity (i.e., browsers); 
2) Facilitators‚Äìmotivated by other people and their needs 
(i.e., a parent bringing a child); 3) Experience-Seekers‚Äì
motivated by the desire to see and experience a place (i.e., 
tourists); 4) Professional/Hobbyists‚Äìmotivated by specific 
knowledge-related goals (i.e., a scholar researching a 
specific topic); 5) Rechargers‚Äìmotivated by a desire for a 
contemplative or restorative experience. 
It is through this research and literature review that the 
research team gained a clearer picture as to the need for, as 
well as potential ways to make connections and meaning, in 
assessing audiences based on their desired experience rather 
than outmoded demographic considerations. As such, 
learning typologies, alongside Falk‚Äôs research on the five 
types of user experiences seen in museums, provides an 
emerging picture of the important role that technology can 
play in facilitating a variety of learning styles, as well as, the 
diversity of user types are found in exhibition settings.  
Addressing the second area of interest, a review of 
existing literature showed a number of teams researching 
the possibility of using AR to augment the information 
provided by museum didactics. In most of the cases, 
however, these didactics rely on proprietary hardware, 
require reprogramming between exhibitions, or installation 
of external tokens (e.g., Bluetooth, RFID, and QR) within 
the museum space. Some work has been done with respect 
to the challenges of image recognition, but little attention 
has been paid with regard to integrating custom-
hardware/software agnostic image based picture recognition 
with content delivery. 
Bimber et al. have developed a mobile system, named, 
PhoneGuide allowing museum visitors to use mobile 
phones to detect artworks in a physical museum space [13]. 
Their method includes image recognition, using the phone‚Äôs 
camera, as well as pervasive tracking techniques using a 
grid of Bluetooth emitters distributed in the space [13]. The 
reliance on external tokens (e.g., Bluetooth) to assist in the 
object recognition would require the museum to install new 
hardware and provide for updates in each gallery space.  
Hatala et al. describe a prototype system, called Ec(h)o, 
developed to provide ‚Äúspatialized soundscapes‚Äù for museum 
visitors [14]. That is, specialized audio is played for the 
listeners depending on their position within the museum. 
The supplied audio is meant to augment the overall 
experience of the exhibit rather than providing information 
about artwork. 
Jing et al. have developed a mobile augmented reality 
prototype system which uses image recognition running on 
specialized hardware to provide additional information on 

12
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
physical images displayed in museums for Personal 
Museum Tour Guide Applications [15]. The system uses the 
SIFT recognition algorithm that employs ‚Äúcoarse to fine‚Äù 
recognition to improve the speed of the process [16]. 
Nevertheless, some users complained of slow processing 
speed.  
Blockner et al. developed a prototype system which 
allows users to create virtual museum tours on a mobile app. 
The mobile device uses NFC to transmit these tours to 
projectors positioned within the gallery which display the 
desired information [17]. 
Miyashitat et al. have developed an interactive device at 
the Dai Nippon Printing (DNP) Museum Lab at the Louvre 
Museum (Paris) for use with an exhibition on Islamic Art. 
This device used a neural network based system to map 
content of exhibits and was able to recognize three 
dimensional objects from a single viewpoint, but also relies 
on purpose specific hardware which is not available outside 
the Louvre and requires that Bluetooth enabled hardware be 
installed in the gallery [18]. 
Klopfer et al. proposed a ‚Äúlocation aware field guide‚Äù 
which operated in a manner similar to Musing but it was not 
adapted to use in a museum [19].  
Lee et al. used an ultra-mobile PC, inertia tracker and 
camera for object recognition [20]. This system did not rely 
on external devices; instead, it relied on template matching. 
In this case, a translucent image of the next artwork is 
placed on the screen, guiding the user to the next artwork to 
be matched and used to locate the user within the museum 
space, attempting to estimate the user‚Äôs location by the last 
artwork scanned. However, this approach does not provide 
for an accurate location estimate. Furthermore, this project 
relied on proprietary hardware supplied by the institution. 
Another system that used specialized hardware to 
provide an augmented reality experience is described in 
[21]. The system overlays the picture of a physical image 
displayed on a custom hardware with pertinent information 
in real-time. The detection of the artwork is accomplished 
using ultrasound sensors and gyros for pose tracking. The 
information is then matched to the image using an edge-
detection algorithm. 
Explora-Museum-EXMU ([22]) is a tablet application 
that shares several features with Musing. It has a similar 
look and feel and similar client/server design approach1. 
Nevertheless, two key features distinguish the EXMU app 
from Musing. First, the app is currently available only on 
tablets. Second, and more important, the app requires 
special hardware in the form of blue tooth transmitters.  
This might impose limitations on the flexibility of 
placement of artwork and rearrangement of the app upon 
changes in gallery / museum content. 
                                                           
1 The application has been recently announced and there is no much 
information about it except for the information available in [22]. 
In addition to the previously discussed systems, there are 
a number of consumer-level museum applications that do 
not require proprietary hardware.  
The Smithsonian Institution and Arcade Sunshine Media 
have developed The Peacock Room Comes to America app. 
The iOS application was built specifically to explore artist 
James 
McNeill 
Whistler‚Äôs 
Peacock 
Room 
in 
the 
Smithsonian Freer Gallery [23]. The application allows for a 
virtual exploration of the space by presenting a scrolling 
image of the room with tapable artworks in the scene. When 
tapped, these artworks offer expanded textual and audio 
information. Peacock Room does not require the visitor to 
be physically located within the museum to view content, 
meaning that it does not actively drive visitors to the 
exhibit. The entirety of information (text, audio, and video) 
is locally stored on the user‚Äôs device. As such, the 
application must be reprogrammed and downloaded again 
by the user, if information is edited or new information is 
created, which may result in the user missing updates and/or 
corrections/additions. Musing includes a setting referred to 
as the ‚ÄúPermanent Exhibition,‚Äù which allows museums to 
create sampler exhibits to advertise new exhibitions. 
However, in addition to this option, Musing‚Äôs ‚ÄúAR‚Äù optio 
enables augmented reality and real-time/on-location user 
interaction with the artworks on exhibition within the 
galleries.  
The Museum of Modern Art (MoMA) in New York has 
developed the MoMA application, containing a large amount 
of information about the museum, including a calendar, 
ability to purchase tickets, and the ability to browse the 
MoMA‚Äôs extensive collections, either by physically visiting 
the museum or browsing at home [24]. MoMA‚Äôs primary 
interface involves typing-in reference numbers (located next 
to artworks in the gallery) to allow visitors to listen to audio 
descriptions of artworks and view large photos. Much of the 
information is not locally stored on the device and is 
downloaded from an online database. Although there are 
reference numbers posted next to artworks in the physical 
gallery, the visitor is not required to visit the museum in 
order to consume the information. Additionally, content is 
not relayed contextually within the picture-plane which does 
not allow for direct connections to be made.   
Reality Check, created by the McNay Museum of San 
Antonio, allows visitors to use their own device‚Äôs 
(smartphone, tablet, etc.) camera (or that of a loaner device) 
to scan artworks in the physical gallery to initiate image 
recognition [25]. The application is designed to be game-
like, allowing the visitor to recognize an artwork by first 
selecting a ‚Äúclue.‚Äù These clues are unique shapes of objects 
present in the artwork. Once the chosen shape is recognized 
in the artwork by the device‚Äôs camera, the visitor is 
presented with supplemental textual, audio, and video 
information. Reality Check stores all of the information 
locally on the hardware, thus, a new build of the application 
is required as information is edited or created. 

13
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
While the aforementioned systems show promise, they 
suffer from a variety of potentially problematic issues. Of 
the systems that require proprietary hardware, museums 
must use financial resources to purchase and maintain 
loaner devices. Systems that rely on external devices, such 
as Bluetooth emitters, increase workload of museum staff 
who must install them within the space. Most importantly, 
the majority of these systems require reprogramming when 
content is created and edited. 
IV. 
APPLICATION DEVELOPMENT AND DEPLOYMENT 
Musing was developed by an interdisciplinary team that 
included 
researchers 
within 
computer 
science, 
communication 
design, 
and 
museology. 
The 
client 
application, built on iOS, was initially deployed from 
October 8th, 2013 through November 14th, 2013, in The 
University Galleries at Texas State University, for the 
exhibition, Eric Zimmerman: West of the Hudson (Figure 2) 
(additional example images, scanable by Musing, are 
available in [26]). During the 38-day run of the exhibit, 242 
visitors downloaded Musing. In addition, 11 visitors 
checked-out iPod Touch devices provided by the galleries, 
indicating a high number of visitors used their personal 
devices. Gallery guest book logs showed that a minimum of 
962 visitors attended the exhibit, denoting that about 25% of 
visitors had chosen to use Musing. This indicates a relatively 
strong initial acceptance rate of the concept. However, these 
figures do not account for repeat visitors, visitors who did 
not sign-in at the front desk, or visitors who shared devices. 
 
Figure 2. Head of State by Eric Zimmerman, 2013. Example artwork 
from exhibit, West of the Hudson 
 
The first deployment of the Musing client indicated 
promising results. However, data for the exhibit was 
manually input into the database by developers. In order to 
fully test a system that could be deployed in a functioning 
museum, the Web-based administrator panel would need to 
be tested as well.  
A second deployment was designed to test the entire 
system, including the museum professional‚Äôs ability to add, 
edit, and delete exhibit content with the Web-based Musing 
Administrator Panel (MAP). In addition, new artworks were 
chosen, which created unique challenges for the image 
recognition algorithm and were used in order to test its 
robustness.  
In order to test for a greater variety of artwork media, the 
second trial utilized two concurrent exhibitions, which ran in 
two separate rooms of the gallery from March 17 through 
April 11, 2014. The first was an exhibition of photographs 
by artist, Lauren E. Simonutti titled, The Devil‚Äôs Alphabet. 
The second was an exhibition of paintings by artist Richard 
Martinez titled, ¬°PAINTINGSFORNOW!, This exhibit was 
chosen explicitly because of the artworks‚Äô strong silhouettes, 
large areas of solid color, and limited visible surface detail.  
Before exhibition installation and during content 
development, the museologist was able to input data into the 
database via the MAP for both exhibitions. This allowed the 
user to add, edit, and delete information, which included the 
uploading of reference photos, adding and rearranging POIs, 
populating content for the added POIs, and adding artists‚Äô 
biographical information. Additionally, this trial allowed the 
development team to discover any programmatic issues and 
resolve them during the data entry process.  
Testing in the gallery indicated that the imagery in The 
Devil‚Äôs Alphabet was satisfactorily recognizable by Musing 
(Figure 3). As these artworks were photographic prints 
behind glass, there were some adjustments needed for 
lighting within the exhibition space in order to minimize 
environmental reflections, which circumstantially interfered 
with image recognition.  
 
Figure 3. The Devil's Alphabet: A by Lauren E. Simonutti, 2007. Example 
artwork from exhibit, The Devil‚Äôs Alphabet 
 

14
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Musing‚Äôs 
recognition 
rate 
of 
artworks 
in  
¬°PAINTINGSFORNOW! was not satisfactory. As the 
paintings in this exhibit displayed strong silhouettes, but very 
little surface variation in tone or texture, it is theorized that 
the flat color and limited amount of detail in the artworks 
were the cause of the recognition failure (Figure 4). As an 
alternative, this exhibit was offered as a ‚ÄúPermanent Exhibit‚Äù 
within the Musing library so that the visitor could still access 
and 
view 
the 
information 
without 
utilizing 
image 
recognition. This points to a need to improve the image 
recognition capabilities of Musing for artworks of this kind. 
During the second trial, additional 58 users downloaded 
Musing.  This number is influenced by the fact that the 
second trial took place during the same exhibition schedule 
as well as the same exhibition venue. Visitor attendance logs 
establish the fact that because the venue is within an 
academic setting, many of the visitors are the same for each 
exhibition. As a result, it is thought that the majority of users 
may have already downloaded Musing for the prior usage. 
 
Figure 4. BEALDARC by Richard Martinez, 2012. From exhibit, 
¬°PAINTINGSFORNOW! 
A. Pedagogical Design 
Making 
associations 
is 
essential 
to 
deepening 
understanding and the pedagogical shifts that are occurring 
within museology reflect the changing needs of the museum 
visitor. In addition, art museums may have difficulties in 
identifying effective ways to provide the proper context for 
the art they exhibit, something that may result in a lack of 
connection to their visitors. As such, the use of Musing can 
result in an enriched aesthetic and educational experience 
for the visitor and provide a large context for exhibited 
artwork to encourage and deepen personal connections to 
the exhibition objects and expand the visitors‚Äô knowledge 
and understanding of the artwork, itself. These connections 
can be made by broadening the context for the novice 
viewer while adding to the experience of the initiated 
viewer.  Further results can be a bridging of gallery 
programming within the daily life of the visitor via their in-
gallery experience and connections. The use of Musing 
within an exhibition setting can provide an interpretive 
framework, which allows access to supplemental didactic 
information about the exhibitions while offering opportunity 
for interactivity.  
At the heart of the concept of the ideal 21st century 
museum/gallery experience is what educator and innovator 
John Dewey referred to over a century ago when he spoke 
of the importance of interactivity to provide for an enriched 
learning environment [4]. Such interactivity, and the 
resulting enrichment, requires providing for diverse learning 
styles by including visual/print, visual/picture, auditory, and 
verbal/kinesthetic modalities, as well as a variety of user 
types [12]. These enriched learning environments are 
comprised of seeing, hearing, and interaction by moving 
beyond the traditional linear model of communication that 
provides didactic information via textual labels and gallery 
talks, to a non-linear model of communication through the 
provision of individual POIs, associated with each scanned 
artwork. Through the visitor‚Äôs ability to access the POIs, 
which reflect a variety of types of didactic content contained 
within Musing, the application provides for an enriched 
environment in which the visitors can participate in creating 
a large context for the works exhibited. The provision of 
additional information about each work via POIs positions 
the visitor as a collaborator in the process of making 
meaning and serves to engage the visitor with the provided 
information which solidifies the content knowledge [4]. 
Meaning is made by the viewer in a variety of ways, which 
can begin by looking at art through several different filters. 
The individual POI provides an opportunity to show the 
viewer the works within an art historical, biographical, 
conceptual, or technical framework. As museums and 
galleries continue to seek ways in which the visitor‚Äôs 
experience can be augmented, these POIs are an effective 
way to provide access for visitors to contextual information 
for the exhibited works, broadening the exhibitions‚Äô theses 
for the novice viewer as well as augmenting the meaning for 
the initiated viewer. This extends the application‚Äôs ability to 
meet the needs of a variety of visitors who learn in different 
ways and access works on a multitude of levels, as well as 
John Falk‚Äôs five types of user experiences [12]. As such, the 
broadening of the exhibited works‚Äô context via interviews, 
videos, Web sites, source material, art historical influences, 
and other art with shared conceptual frameworks allows for 
a personalization for the visitor through the implied 
narratives. This is thought to be the most effective way to 
expand the context for the work and deepen viewers‚Äô 
connections through the exercise and action of gathering the 
information [2]. The resulting associations within the 
gallery setting, moving into the viewers‚Äô world, are essential 
to deepening the understanding of subject matter‚Äîa result 
of the user transferring what he or she already knows and 
reflecting upon it [4]. 
For the novice viewer, whose frame of reference may 
be lacking in depth to fully make these associations, the POI 
format is ideal to expand reference points. As these 
associations and connections deepen, the experience begins 
to look familiar, something that can also make looking at art 
more comfortable. As Marjorie Schwarzer writes, ‚ÄúToday, 
when the meaning of art is more contested than ever, 

15
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
[technologies] offer visitors the possibility of diverse 
interpretations‚Äù [27]. Schwarzer adds, ‚ÄúThe branches of 
information available on these devices are close in spirit to 
the multiple ways in which we engage art‚Äù [27]. The ability 
to allow for different levels and a wide range of information, 
as well as a seemingly endless number of interpretive 
applications, reflects the diversity of the museum audience, 
itself [27].  
Marjorie Schwarzer also notes, ‚ÄúAs society is 
bombarded with rapidly changing multimedia messages, our 
ways of deciphering and understanding information have 
changed. We increasingly rely on a combination of sound, 
moving image, and text. Like it or not, new technologies 
outside of a museum‚Äôs four walls alter the way that people 
process information inside the museum‚Äù [27]. Musing‚Äôs 
effectiveness comes from the immediacy with which the 
user can access the POI content and making information 
available on demand allows for visitors to move freely 
within the space, not having to rely upon the preconceived 
schedule of their guide or any predetermined path.   
Within 
the 
preferred 
postmodern 
approach 
to  
museology, the ability of the visitor to gain information and 
knowledge in an interactive capacity reflects several of the 
key tenets of the New Museology‚Äîvalue, meaning, and 
access‚Äîwhile allowing for greater meaning and relevance 
of the content in contemporary society [28]. An undesirable 
level of institutional authority can be implied or inferred 
through exhibitions that are authoritative in their approach 
to didactic display and interpretation, seen in limited 
interpretive labels and language wherein the curator‚Äôs voice 
is solely represented. Without the constructed intellectual 
space needed to create meaning, the visitor may fail to foster 
an individual relationship with exhibition objects [28].  
This, in turn, can determine whether the visitor‚Äôs experience 
is enriched, aggregated, and circular in nature‚Äîcomprised 
of many small connections formed between objects and the 
visitor‚Äôs personal connections‚Äîor an isolated, linear-
oriented experience‚Äîformed from objects considered in 
isolation via limited interactivity. As such, the visitor‚Äôs 
relationship and connections to exhibition objects depends 
heavily on subjective and experiential aspects such as 
interactivity and consumption of information with which 
they make their own meaning [29]. We can see the ways in 
which visitors‚Äô relationships to objects are defined by how 
active/passive they are allowed to be; the more restrained 
the institutional authority associated with the experience is, 
the closer the relationship may be that the visitor can 
develop with the object [28][29].   
The effects of this enriched experience build on each 
other.  Providing a large narrative context for the exhibition 
objects allows the visitor to make greater connections with 
the individual works of art within an exhibition and make 
connections between the works contained within the 
exhibition and a large relationship between exhibitions 
offered through Musing. In this way, the artworks 
themselves become an interpretive tool, which allows for a 
familiar relationship on the part of the visitor and a greater 
connection to them. This focus on communication of 
content and provision of context for the object is what 
Stephen Weil refers to as ‚ÄúThe Poetics and Politics of 
Representation‚Äù [28].  In so doing, the visitor looks at the 
featured works and sees, understands, and connects through 
them.  
B. 
Client User Interface Design 
Musing was designed to employ a client-server 
architecture that allows museum administrators to upload, 
remove, and alter content, post-deployment. This is 
accomplished through an administrative Web interface 
(MAP) which feeds the shared database. The application 
retrieves this content as requested by the user. This 
approach allows the material provided to the user to be as 
current as possible. Hence, the application is flexible and 
not limited to ‚Äúon board‚Äù data, allowing any museum to 
closely serve the needs of its visitors. The application relies 
on an open source library called OpenCV for the processing 
and recognition of images which have been captured by the 
user.  
The User Interface was designed in such a way as to 
adhere to the Apple Human Interface Guidelines for a tab-
bar navigation style application: Consisting of the 
Exhibitions Screen, Scan Artwork Screen, Artwork View 
Screen, and Favorites Screen. 
C. The Exhibitions Screen and the Artwork View Screen 
The Exhibitions Screen, depicted in Figure 5a, consists of 
a list-view of exhibits that a visitor can visit, organized by 
‚ÄúPermanent Exhibits‚Äù and ‚ÄúAugmented Reality Exhibits‚Äù. 
Permanent Exhibits are previews of the experience that 
visitors can expect when using the application in-gallery. 
These exhibits contain artworks that can be viewed outside 
of the gallery setting (e.g., residence, dorm, etc.). This type 
of exhibit is included to advertise the application‚Äôs features, 
to familiarize the user with the way that the application 
works, and encourage users to attend a live exhibition. The 
AR exhibition section includes exhibits that must be attended 
in person to view the didactic information for the artworks. 
This view provides information such as the name of the 
exhibit, in which museum the exhibit is located (provided 
more than one organization uses Musing), and a 
representative image to advertise the exhibition. Figure 5b 
shows a portion of the ‚ÄúArt View‚Äù screen: a captured and 
identified image along with the overlaid POIs. 
POIs‚Äîtapable buttons that represent the types of content 
available to the user‚Äîare able to provide the user with a 
variety of didactic information. The individual POIs are as 
follows: 1) Factoids: Small pieces of text that can be attached 
to a feature in an artwork (Figure 6a); 2) Web site: Links 
provide information about the artist, or historically pertinent 
information (Figure 6b); 3) Video: Takes the user to an 
established internet video site such as YouTube and Vimeo 
or a locally hosted video within the application (Figure 7a).  

16
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
These individual POIs can be tied directly to the 
aforementioned learning types (visual, auditory, and 
kinesthetic) written about by Pashleret et al. [11].  Through 
the diversity of information dissemination methods such as  
 
 
 
 
 
Figure 5. (a-top) Exhibitions Screen, including exhibition selection, and 
primary navigation; (b-bottom) A captured and identified image along with 
the overlaid POIs. 
 
 
 
video, web based content, and text, as well as image based 
content,  the visual learner‚Äôs needs are met, while the 
auditory learner is stimulated as well by video and audio files 
and the kinesthetic learner enjoys the interactivity with the 
technology, itself.  Through the exploration of the elements 
that comprise the experience provided by Musing, each of 
the learning types can be stimulated in ways that allow for 
their access to the content. 
 
 
 
Figure 6. (a-top) Factoid POI; (b-bottom) External Web site 
D. The Favorites Screen 
Many museum visitors wish to retain information in 
order to consume or refer to at a later date. Musing allows 
the visitor, to favorite any of the artworks they scanned while 
visiting the museum. These favorites are saved in the 
Favorites Screen in a list view for later retrieval (Figure 7b).   

17
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
 
Figure 7. (a-top) YouTube video, created and uploaded by the musing 
professional; (b-bottom) Favourites Screen with list-view of saved artworks 
E. 
Server User Interface Design 
In order for Musing to be used in a wide variety of 
museums and galleries, the MAP Web site was created to 
provide museologists with the ability to easily create, 
retrieve, update and delete content in the system.  As all 
consumable content for the client application is provided 
from a database, without MAP, the Musing system would 
require expensive upkeep by software developers.  
MAP includes four pages for data entry: Exhibits, 
Artworks, Edit POIs, and Artists. 
The Exhibits page allows the user to create/add 
exhibits, edit, and delete existing exhibits (Figure 8). From 
this page, the user is able to select existing exhibits for 
editing as well as create new ones. 
 
 
Figure 8. Exhibits page, showing existing exhibits 
When a new exhibition is created, MAP initiates the 
Edit Exhibition page (Figure 9). This interface allows the 
user to browse their local machine for an exhibition image 
(automatically resized by the system), choose a beginning 
and end date for the exhibit, enter the museum or gallery 
name, and set the exhibit type to Permanent or Augmented 
Reality. This information is displayed in the client on 
Musing‚Äôs Home Screen (Figure 5a). 
 
Figure 9. Adding a new exhibit (detail) 
After a new exhibit is created, the user is taken to the 
Artworks page. This page allows the user to add new 
artwork images to the exhibition, delete artworks, or edit 
artworks within the exhibition (Figure 10). 
When adding a new artwork to an exhibition, the 
artwork editing page allows the user to upload and crop a 
reference photo of the artwork (used for image recognition 
by the client application) and enter information about the 
artwork. This information includes the artwork‚Äôs title, 
dimensions, materials, year created, and artist (maintained 
separately by the Artist page). The entirety of this 
information is displayed in the Musing client after image 
recognition has taken place (Figures 5b and 6a).  
 From the selected artwork‚Äôs page, the user is able to 
edit the POIs (Figure 11). The user has the ability to add 
new POIs, placing them by clicking and dragging. 
Additionally, the user is able to assign content to each POI, 

18
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
and assign a category: History, Technique, Information, 
Web, or Video. The POIs are assigned (ùë•, ùë¶) coordinates 
and appear in the Musing client in the same locations on the 
artworks (Figures 5b and 6a). 
 
Figure 10. Managing artworks within an exhibit 
Artist information is kept separate from the exhibits and 
the individual artworks to avoid duplication of data entry. 
The Artist section of MAP allows the user to add new artists 
or edit existing ones (Figure 12). 
 
 
Figure 11. Editing POIs on the artwork (detail) 
The Edit artist page allows the user to upload and crop 
a photo of the artist, input names, birth/death dates, and 
links to artist biographies, as well as bibliographic 
references. This biographic information is displayed in the 
Musing client at the bottom of the View Artworks Screen 
(Figure 5b). 
 
Figure 12. Editing Artist information (detail) 
 
After selecting an exhibit, the authenticated user is 
presented with a thumbnail for all of the artworks currently 
associated with that exhibit. In addition, the user is given the 
option of adding a new artwork to the exhibit. When a new 
work is added, the user selects an image of the art from local 
storage on their machine. The image is expected to be 
cropped such that only the artwork itself and its frame are 
shown. This greatly improves the recognition performance 
of Musing and creates a better experience for users of the 
application. 
When an image has been selected for a new artwork, the 
user is directed to a page where information regarding the 
particular artwork can be entered or edited. This same 
screen is reached when an existing work of art is selected 
from the exhibit listing. The user is able to enter the 
artwork‚Äôs title, size, year of creation, medium, and the 
artist‚Äôs name. Artists are stored and catalogued in the 
database and information such as year of birth, year of death 
if applicable, and a link to a biography, can be entered and 
stored as a unique entry to the artwork in the database to 
avoid duplication of entries. 
Next, the administrative support utility enables the 
administrator to define and edit POIs for an artwork. This is 
done using a graphical interface designed with JQuery. The 
user selects a position on a displayed image of the artwork, 
chooses the media type that the POIs references‚Äîalong 
with its associated icon‚Äîand the text or URL as 
appropriate. In addition, users can alter the position of 
existing POIs by dragging and dropping them. The user can 
add and modify exhibits, as well as artists in a manner 
similar to that described for artworks. 
 
F. Hardware/Software Architecture 
The Musing server, or MAP, UI is constructed with 
HTML and CSS, reading from and writing to a MySQL 
database hosted on a Linux Web server. Currently, the 
Musing client runs on iOS based hardware, such as iPhone, 
iPod Touch, and iPad.  An Android version is under design.  
 
1) Back-end Processing 
The back-end (server) application provides two main 
functionalities. First, it supplies information in the form of 
reference images and relevant didactics to the user, enabling 
its operation inside the gallery or with a permanent 
exhibition. Second, the back-end is designed to provide an 
administrator (e.g., a museum staff member) with the 
capability to edit the contents of an exhibition within the 
system.  The server, which is shared by the application and 
the administrative support back-end utility, is used by the 
gallery administrators to load content into Musing. 
The back-end, administered by MAP, is written in PHP 
and uses standard web-technologies (including HTML, CSS, 
JavaScript, AJAX, jQuery, and several Open-Source 
JavaScript libraries) to deliver a user-centric experience. It is 
designed to allow users unfamiliar with database systems to 
create, read, update, and delete entries for exhibits from a 
database stored within the web application‚Äôs framework. The 
entries include artworks contained within a chosen exhibit, 
the associated artists, and curated POIs.  
The primary vehicle for data entry into MAP is via Web 
forms depicted in Figures 8-12. These forms, when 
submitted, write data into the appropriate fields in the 
database. The database for the entire system is comprised of 
eight tables. One table is responsible for user authentication, 

19
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
along with another which records failed login attempts. Two 
tables are responsible for tracking permissions of the exhibits 
and the artists. These tables separate exhibits and artists by 
user, so that administrators may only view their own 
information. The remainder of the tables are responsible for 
holding 
artworks, 
exhibits 
(Figures 
9-10), 
POI 
placement/content (Figure 11) and data for artists (Figure 
12).  
When a new image is uploaded via a Web form, either 
for an artist headshot or an artwork reference image, the 
image is saved into a folder on the server and a pointer is 
saved to the appropriate database table for later retrieval.  
JQuery and JavaScript are used to facilitate the 
placement of POIs (Figure 11), by allowing the museologist 
to drag and drop POIs wherever they wish in the picture 
plane. The (ùë•, ùë¶) coordinates of the POIs are saved to the 
database in the POI table, along with the Artwork‚Äôs ID, icon 
type, media type (e.g., text, video, audio) and URL for that 
content. 
Musing was developed with the intention of packaging 
within the application as little data as possible. When the 
user activates Musing, it requests an XML document 
containing a list of available exhibits from the back-end data 
server. The application parses the XML document and 
extracts the information into an Exhibit object within the 
application. Along with the XML document, which contains 
the names of the exhibits, locations, and id values which the 
application can use to retrieve data about specific exhibits, 
the application retrieves a ‚Äúbanner image‚Äù for each exhibit, 
which is displayed in a list for the user to browse. 
When the user selects an exhibit from the list on Musing‚Äôs 
Home screen (Figure 5a), the application passes its id value 
to a PHP script hosted on the data server. This process is 
referred to as ‚Äòsynching‚Äô.  During synching, the server 
compiles the pertinent information and returns information 
in the form of XML file and a set of JPEG images of the 
gallery artworks to the app. The XML document contains 
information about each artwork, along with the set of POIs 
related to the information. The user can tap on POIs to 
display additional information about the artwork or artist. 
The images retrieved along with this document are used 
both for displaying POIs on the Artwork View screen and as 
references by the image recognition. 
As in the case of the exhibit list, the XML document 
provided by the data server when the application is synched 
to a particular exhibit is parsed. The extracted information is 
used to populate painting and POIs within the application 
for each painting and POIs listed in the database. The 
images are also incorporated into these objects. Testing has 
shown that this process of synchronization typically takes 
approximately 20 seconds, during which time the user is 
shown a modal progress graphic. 
 
2) Front-end Processing 
Musing supports two types of exhibits‚Äî permanent and 
AR. The synching process is the same for both. If the 
database indicates that an exhibit is permanent, the user is 
shown a list of artworks available in an exhibit and each may 
be selected by tapping. This displays the artwork‚Äôs image 
with the proper set of overlaid POIs. The second type of 
exhibit is the AR variety. In this case, the user is given an 
image detection view rather than a list, which displays a real-
time feed from the devices camera over which is laid a 
graphic of an empty painting frame, along with a button 
which the user can use to capture a photograph. 
During image detection, the users are instructed to 
position themselves so that a Musing enabled artwork fully 
fills the frame displayed (this is not mandatory, yet it can 
improve the recognition rate) on the device‚Äôs screen and to 
take a picture of the artwork. When this is done and an image 
is captured, the application compares the captured image to 
each reference image currently synchronized for the exhibit. 
If a match can be made, the application proceeds to the 
Artwork View screen, exactly as it does when the user 
selects an image in a permanent exhibit. Otherwise, an error 
message is displayed in a modal dialog. To save in storage 
space, the captured image is discarded after being matched or 
rejected. 
From the Artwork View screen, the user has the option of 
capturing the artwork and its information by making the 
artwork one of their ‚ÄúFavorites.‚Äù This is the only condition 
under which Musing locally stores the artwork and its 
information. This is done by passing the image, POIs data, 
and artist information to a Favorites Database object that 
incorporates those values into an array of artwork objects. 
The data is then written into Musing‚Äôs internal database. The 
information stored in the favorites array is accessible by the 
user regardless of whether or not the device is connected to 
the internet. 
 
3) Image Processing and Recognition 
Musing relies on the Oriented FAST and Rotated 
BRIEF (ORB) image detection algorithm [30]. The ORB 
procedure combines the ‚ÄúFAST‚Äù key-point detection and 
‚ÄúBRIEF‚Äù determination of descriptors. Key-points are 
clusters of pixels within an image which are unusual enough 
to stand out and to help distinguish a particular image from 
other images. After identifying a set of key-points within an 
image, a set of descriptors is calculated for each key-point 
using BRIEF [30]. This functionality is provided by the 
OpenCV open source computer vision library which is 
available for use in iOS and Android devices. 
Key-point 
detectors 
frequently 
rely 
on 
finding 
‚Äúcorners‚Äù and ‚Äúedges‚Äù within images since image 
boundaries often create distinguishable pairings of shade 
and color [30]. ORB is translation invariant. Additional 
operations are performed to compensate for rotation and 
scaling [30]. 
In the training stage, 
BRIEF employs binary 
comparisons between pixels in a smoothed image [30]. This 
algorithm takes a relatively large set of key-points‚Äîoften as 
many as 500‚Äîand builds a classification tree for the set. 
The tree serves as an image ‚Äúsignature‚Äù used to measure 
similarities between images. Alternatively, under the 

20
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
approach used in this research, one can employ the results of 
the BRIEF stage using the ùëò nearest neighbors (kNN) and 
one-to-one and onto mapping (bijection) test approach. 
Following the synching process, users can point their 
device camera at an artwork in the gallery and capture its 
image. This image is processed using ORB and then 
compared to each of the reference images which were 
downloaded at sync time. Each reference image is processed 
to determine its key-points / descriptors at the time of 
comparison and this information is recalculated for each 
comparison. Musing employs the kNN and bijection 
approach to the key-points. Each key-point in a captured 
image is compared to each other in the reference image. A 
small set of matching key-points in the reference image is 
found for each key-point in the captured image. The goal is 
to find a maximal, high reliability, bijection between a 
subset of the key-points in a reference image and a subset of 
the key-points in the captured image. Hence, if any key-
point in the reference image matches more than one key-
point in the captured image with equal reliability, then 
Musing dismisses that match. The literature has suggested 
0.65 as a reliability threshold and as the best threshold ratio 
for selecting one match as superior to the other [31]. Musing 
image recognition procedure uses this (0.65) threshold. The 
kNN is done twice, creating a set of directional matches that 
compares the reference image to the photograph taken and 
vice-versa. Then both sets are compared, dismissing any 
match that is not bidirectional. If a significant number of 
bidirectional matches is identified, the images are 
considered a match. Musing currently uses a threshold of 4 
bidirectional matches as the minimum subset size. 
When Musing has determined that a captured image 
matches a reference image, the reference image is displayed 
on screen along with an overlay of POIs. 
The following is a description of the applied image 
recognition algorithm, starting with the captured image and 
the first reference image. 
Step One: Captured Image Key-point Calculation - Find 
the key-points for the captured image using the FAST 
method [30]. This method checks a ring around each pixel 
and compares their intensities. It returns the point as a key-
point if the gray level of a number of pixels within the ring 
is sufficiently higher or lower than the nucleus pixel itself. 
Step Two: Captured Image Descriptor Calculation - 
BRIEF is used to take a patch of pixels surrounding a key-
point and uses binary intensity thresholds to create a 256-bit 
binary vector describing the area around the key-point [30]. 
Steps Three & Four: Reference Key-points and 
Descriptors - Steps one and two are repeated for the 
reference image. 
Step 
Five-A: 
Descriptor Matching (Captured 
to 
Reference) - A kNN matching of the Hamming Distances 
of each descriptor in the captured image to its K nearest 
neighbors in the reference image is performed. The two best 
matches for each key-point are retained.  
Step Five-B: Descriptor Matching (Reference to 
Captured) - Step Five-A is applied with the roles of the 
captured and reference image reversed. 
Step Six-A: Ratio-Test (Captured to Reference) - This 
step discards every match identified for the captured image 
where the best match and second-best match have similar 
Hamming distances. This produces a one-to-one match.  
Step Six-B: Ratio-Test (Reference to Captured) -
Weeding, using the same criteria as in step Six-A is 
performed on any match from the set of matches identified 
in the reference image. 
Step Seven: Symmetry Cross-Check Test - The 
Symmetry cross-check test returns only the pairs of matches 
that are found from the captured image to the reference 
image and from reference image to the captured image. This 
process enables keeping only the strongest symmetric 
correspondences and maintaining a bijection.   
 
Figure 13 illustrates the process performed in steps 5 to 7. 
 
 
 
 
 
 
Figure 13. (A) and (B) kNN matching (ùëò = 2); (C) and (D) Descriptor matching  - the process discards matches with similar quality (Hamming distance) 
and retains the best match for distinctive matches; (E) Symmetry cross checking ‚Äì only bidirectional matches are retained. 
 
 

21
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
Step Eight: Output if Found - If four or more matches 
remain after the weeding performed by the ratio tests and 
symmetry test, the procedure retains the identity of the 
reference image and returns to step three for the next 
reference image (if such an image is available). The 
procedure keeps track of the identity of the image that 
produced the largest number of matches and outputs its id.  
If all reference images have been tested and no match has 
been found, then a message ‚ÄúImage Not Found‚Äù along with 
instructions to the user on ways for improving the 
possibility of match are displayed. 
G. Design of Testing Instruments 
Although this project seeks to augment the viewers‚Äô 
experience, while traditional didactics and tours remain in 
place, it is not simply an ‚Äúadd-on‚Äù to the material that the 
galleries already provide. It is a model for directional 
movement in museum practices, so to assure its success, 
proper analysis must be done. Utilizing Scott Sayre‚Äôs model 
of evaluation‚ÄîPre-production Surveys, Formative Testing, 
Summative Evaluation, Audience Focus Groups, and 
Computer-collected data ‚Äì we can get a thorough evaluation 
before, during, and after production that provides a myriad 
of benefits relative to the assurance of effectiveness [2].  
Testing instruments consisted of quantitative benchmark 
testing and a qualitative user perception exit questionnaire. 
As a part of the quantitative testing, each reference and 
captured image has been processed to generate 500 
identifying key-points in each of 60 total images. The 60 
images consist of: ten reference images (ùëÖ1 ‚àí ùëÖ10) and ten 
images that served as captured images(ùëÉ1 ‚àí ùëÉ10). Each of 
the captured images was captured four additional times for a 
total of five capturing per image. The first one used 
maximum alignment to the reference images the rest of the 
four were taken with increasing rotation translation and 
scaling (due to different distance). The maximal rotation was 
40 degrees.   
The procedure described above was applied to the ten 
reference images and fifty captured images. A threshold of 
0.3% over the percent of matching key-points, which was 
empirically identified as the most suitable threshold was used 
by the program and applied to the matching results.  
For the qualitative testing we have used a 23-question 
exit questionnaire designed to capture feedback from in-
gallery users. The questions were written to determine the 
user‚Äôs acceptance of the application, their perceptions of 
application performance, enjoyment of the application, as 
well as pedagogical concerns. 
V. 
DEPLOYMENT RESULTS 
A. Technical Results (Internal Testing) 
Figure 14 shows a heat-map of the results of this 
experiment in the form of a confusion matrix.  The figure 
shows a recognition rate of 96.4% with 0% error of type-1 
(false positive) and 3.3% error of type-2 (false negative) 
obtained with ùëÉ(1,4) and ùëÉ(1,5). We have found however, that 
with rotation of more than 45 degrees there were numerous 
false negatives; but, still 0% of false positive error. 
The testing has shown that Musing recognizes images 
with near perfect reliability under ideal conditions, that is, 
when a user is directly in front of the artwork, has positioned 
the artwork correctly within the image capture frame, and is 
not holding the device at an angle. Nevertheless, excessive 
rotation of the camera while capturing an image diminishes 
reliability. Our testing indicates that Musing recognizes 
images at a 45 degree rotation with 90% reliability and a 90 
degree rotation with 84% reliability. The application 
performance degrades when the user stands off of the center 
line when photographing a piece of art, producing a skewed 
image. A slight deviation from the center (approximately 15 
degrees) produced no noticeable change in testing but at 
greater values (approximately 45 degrees) the system 
produces 40% true positives and 60% false negatives. As far 
as can be determined, in the field-deployment testing, the 
system did not generate false positive results. Furthermore, 
the user surveys have not indicated that the application has 
produced a false positive error in use. Additionally, if the 
user stands too far from the artwork to properly fill the 
capture frame the reliability has suffered as well, with the 
reliability rate dropping to 48% at approximately twice the 
recommended distance.  
Testing indicated that the image recognition algorithm 
failed when artworks were behind glass, causing heavy 
reflections, as well as those artworks with little tonal 
variation or surface detail. Artworks behind glass can often 
create reflections of the user as they are standing in front of 
the artwork. These reflections interfere with the image 
recognition by creating an image that falls outside the 
tolerance range of the algorithm. Artworks that exhibited 
little tonal variation (i.e., large patches of solid color) or little 
surface detail also created challenges for the image 
recognition algorithm, as there were not enough unique 
identifier points for the algorithm to affect recognition. 
Testing performed to evaluate the processing time 
revealed that with 10 reference images, the application was 
able to compare and either display or reject an image in 
approximately 3.3 seconds on a stock iPod Touch-5. Again, 
user surveys indicate that this was sufficient to produce a 
positive experience for most users. 
Finally, User surveys conducted during the trials indicate 
that the application‚Äôs reliability was sufficient to produce a 
positive experience for most users. 
B. Exit Questionnaire Results with Live Users 
Of the pertinent questions, 83.6% responded that Musing 
was able to recognize the artwork ‚Äúevery time‚Äù or ‚Äúmost of 
the time.‚Äù 77.5% considered Musing to be quick and 
responsive.  87.7% considered Musing enjoyable to use and 
93.8% wishing to see Musing in a future exhibit. 
VI. 
RESULTS EVALUATION 
The deployment results show high recognition accuracy 
and relatively short synching/recognition delay time, 
therefore the functionality of the entire system has been 

22
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
verified. The application has passed the Apple approval 
process and is available for download [5].  
Formal user feedback obtained via questionnaire was 
consistent with our evaluation of the system and with 
informal feedback. The visitors that have responded to the 
survey have found the application as informative and usable. 
Their perception of precision and timing was favorable and 
overall they have commended the system and expressed 
interest in its further use. Informal feedback from users, 
including several staff members of other galleries, was 
overwhelmingly positive. 
VII. CONCLUSIONS AND FUTURE RESEARCH 
We have designed, implemented, and deployed a usable 
mobile application that facilitates an enriched museum 
visitor experience via AR using interactive didactics. Per 
our assessment, the application has achieved its stated goals 
and has shown that the research hypothesis is valid. 
Although tried and true wall labels, pamphlets, and 
gallery talks are sufficient for conveying information and 
serve to extend interpretive opportunities [32], they carry 
with them constraints that do not adapt in the ways that 
mobile media can.  Mobile media technology provides the 
ability to allow for different levels and a wide range of 
information, as well as a seemingly endless number of 
interpretive applications and these interpretive strategies can 
reflect the diversity of the museum audience, itself [27]. 
These diverse and changing multimedia messages are 
reflected in the ways that Musing can be used.  
Ultimately, the knowledge and deepened understanding 
that Musing can facilitate is filtered through the learning and 
innovation skills of the 21st Century ‚Äì that of creativity and 
innovation, communication and collaboration, and cross-
disciplinary thinking [32]. 
The field testing via the exhibition shows that Musing 
can be used on non-proprietary smartphone hardware and 
provide visitors with didactic information, without the need 
for external tokens and reprogramming for information 
changes. This enables reduced reliance on loaner hardware. 
In addition, the implementation of MAP allowed for the 
museologist to curate an exhibition within a simple to use 
Web application, without the need for software development 
abilities. This ability allows musing to be deployed in 
external museums and galleries as a complete, turn-key 
solution. 
A.  Future Research 
Future enhancements to the Musing smartphone 
application (client) will include abilities for users to share 
images and didactics via social media such as Facebook and 
Twitter, as well as the ability to comment on artworks 
within the application so users can ‚Äújoin in the 
conversation.‚Äù Additionally, there are plans to complete a 
port of the current iOS-based implementation to the Android 
environment. 
It was determined that number of user downloads did not 
provide sufficient information about the way that users were 
interacting with the client. The addition of data analytics 
within the client, including collecting the number of times a 
user accessed the client, the number of times that an 
artworks scanned, the number of POIs accessed, and 
additional information could provide insight into the relative 
success of the client. 
Future research with regard to MAP includes a 
redesigned GUI and improved user experience, as well as 
user testing with multiple users in order to provide the 
research team with a plan for feature enhancements. 
Other plans for future activities include expanding the 
image processing capabilities by further improving 
recognition accuracy, resilience, and time performance. We 
plan to investigate the integration of algorithms for 
recognition of 3-D objects using the smartphone/tablet 
camera. 
Lastly, in the Fall of 2014 and Spring of 2015 the 
research team has tested the Musing system (client and 
server) in external galleries, not directly attached to this 
project. The Bluestar Gallery in San Antonio, Texas and the 
Wittliff Collection Gallery in the Texas State University has 
tested an exhibit with Musing. Both galleries provided 
important positive feedback concerning the experience of 
visitors that used the app and the ease of use for gallery 
stuff. Additionally, the feedback provided helped improving 
some of Musing features. We plan to continue testing 
Musing in external galleries. It is hoped that more 
information can be gleaned from implementing Musing 
from these exhibits and in a large variety of gallery spaces.  
 
ACKNOWLEDGEMENT 
The research team would like to thank Texas State 
University‚Äôs Research Enhancement Grant program for 
providing the initial funding for this research. In addition, 
continued project funding was provided by the office of the 
Vice President of Research (Dr. Michael Blanda), Dr. 
Timmothy Mottet, Dean of the College of Fine Arts and 
Communication, Dr. Stephen Seidman, Dean of the College 
of Science and Engineering, Mr. Michael Niblett, Director of 
the School of Art and Design, and Dr. Hongchi Shi, Chair of 
the Department of Computer Science of Texas State 
University. 
 
 

23
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 14. A heat-map of the results of the image matching experiment.   
REFERENCES 
[1] G. Atkinson, K. Whiteside, D. E. Tamir, G. Lawrence, and 
M. M. Stump, ‚ÄúMusing: Interactive Didactics for Art 
Museums and Galleries via Image Processing and 
Augmented Reality - Providing Contextual Information for 
Artworks 
via 
Consumer-Level 
Mobile 
Devices,‚Äù 
proceedings of the 6th International Conference on Creative 
Content Technology, Content 2014, Venice, Italy, May, 
2014. 
[2] S. Sayre, ‚ÄúAssuring the Successful Integration of 
Multimedia Technology in an Art Museum Environment,‚Äù 
in S. Thomas and A. Mintz (Eds.), the Virtual and the Real:  
Media in the Museum, Washington, D.C., 1998, pp. 1-10. 
[3] K. Morrissey and D. Worts, ‚ÄúA Place for the Muses? 
Negotiating the Role of Technology in Museums,‚Äù in S. 
Thomas and A. Mintz (Eds.), the Virtual and the Real:  
Media in the Museum, Washington, D.C., 1998, pp. 147-
171. 
[4] T. C. Clapper, ‚ÄúThe Enriched Environment: Making 
Multiple Connections‚Äù in the Academic Leadership 
Journal, 8(4), 2010, pp. 1-2.  
[5] Musing, a photo recognition application that allows users to 
scan artwork at participating museums and art galleries to 
learn 
more 
about 
the 
work, 
Apple 
Store, 
https://itunes.apple.com/us/app/musing/id694382407?ls=1
&mt=8, [retrieved August 2014].  
[6] G. Lawrence and M. Stump, ‚ÄúConnecting Physical and 
Digital Worlds. A Case Study of Quick Response Codes 
and Social Media in a Gallery Setting,‚Äù The International 
Journal of Design in Society, 6(3), 2013, pp. 79-95. 
[7] G. Atkinson, K. Whiteside, G. Lawrence, M. M. Stump, 
and D. E. Tamir, ‚ÄúMusing: Enhancing Educational 
Experience through an Augmented Reality/Virtual Museum 
Application,‚Äù in proceedings of the, 8th International 
Technology, Education and Development Conference, 
Seville, Spain, March, 2014. 
[8] K. Whiteside, G. Atkinson, M. M. Stump, G. Lawrence, D. 
E. Tamir, ‚ÄúMusing: Adaptable Mobile Augmented Reality 
Application 
for 
Museums 
and 
Art 
Galleries,‚Äù 
in 
proceedings of the Electronic Visualization and the Arts, 
EVA 2014, London, UK, July, 2014 
[9] L. Tallon, ‚ÄúIntroduction: mobile digital and person‚Äù In L. 
Tallon and K. Walker (Eds.), Digital Technologies and the 
Museum Experience: Handheld Guides and Other Media, 
Lanham, MD; AltaMira Press, 2008, pp. xiii-xxv. 

24
International Journal on Advances in Telecommunications, vol 8 no 1 & 2, year 2015, http://www.iariajournals.org/telecommunications/
2015, ¬© Copyright by authors, Published under agreement with IARIA - www.iaria.org
[10] S.E. Weil, ‚ÄúMaking Museums Matter‚Äù Smithsonian 
Institution, Washington, D.C., USA, 2002. 
[11] H. Pashler, M. McDaniel, D. Rohrer, and R. Bjork, 
Learning styles: Concepts and evidence. Psychological 
Science in the Public Interest 9, 2009, pp. 105‚Äì119. 
[12] J. Falk, Identity and the Museum Experience. Walnut 
Creek, California: Left Coast Press, 2009. 
[13] O. Bimber, and E. Bruns, ‚ÄúPhoneGuide: Adaptive Image 
Classification for Mobile Museum Guidance,‚Äù IEEE 
International Symposium on Ubiquitous Virtual Reality, 
Jeju, South Korea, 2011, pp.1-4. 
[14] M. Hatala, L. Kalantari, R. Wakkary, and K. Newby, 
‚ÄúOntology And Rule Based Retrieval Of Sound Objects In 
Augmented Audio Reality System For Museum Visitors,‚Äù 
ACM symposium on Applied computing, New York,  NY, 
2004, pp. 1045-1050. 
[15] C. Jing, G. Junwei, and W. Yongtian, ‚ÄúMobile Augmented 
REality System For Personal Museum Tour Guide 
Applications‚Äù, IET Wireless and Mobile Computing, 
Shanghai, China, 2011, pp. 262 ‚Äì 265. 
[16] E. Rublee, V. Rabaud, K. Konolige, and G. Bradski, ‚ÄúORB: 
an EfÔ¨Åcient Alternative to SIFT or SURF‚Äù IEEE 
International Conference on Computer Vision, Barcelona, 
Spain, 2011, pp. 2564-2571.  
[17] M. Bl√∂ckner, S. Danti, J. Forrai, G. Broll, and A. De Luca, 
‚ÄúPlease Touch the Exhibits!: Using NFC-based Interaction 
for Exploring a Museum,‚Äù International Conference on 
Human-Computer Interaction with Mobile Devices and 
Services, New York,  2011, Article 71. 
[18] T. Miyashitat, et al., ‚ÄúAn Augmented REality Museum 
Guide, in IEEE International Symposium on Mixed and 
Augmented Reality, Cambridge, 2008, pp. 103 ‚Äì 106. 
[19] E. Klopfer and K. Squire, ‚ÄúEnvironmental Detectives‚ÄîThe 
Development of an Augmented Reality Platform for 
Environmental Simulations,‚Äù in Educational Technology 
Research and Development, 56(2), 2008, pp.203-228. 
[20] D. Lee, and J. Park, ‚ÄúAugmented Reality based Museum 
Guidance System for Selective Viewings,‚Äù IEEE Workshop 
on Digital Media and its Application in Museum & 
Heritage, 2007, Chongign, China, pp. 379-382. 
[21] J. Oh et al., ‚ÄúEfficient Mobile Museum Guidance System 
Using Augmented Reality,‚Äù IEEE International Symposium 
on Consumer Electronics, Vilamoura, Portugal, 2008, 
pp.1,4, 14-16. 
[22] Transform your museum visit into an incredible exploration 
http://www.explora-museum.com/ 
[retrieved, March, 2015] 
[23] Peacock Room Comes to America iPhone and iPad 
application.  
https://itunes.apple.com/us/app/peacock-room-comes-to-
america/id671150763?mt=8  
[retrieved, March, 2015]. 
[24] MoMA iPhone application.  
https://itunes.apple.com/us/app/moma/id383990455?mt=8 
[retrieved, March, 2015]. 
[25] Reality Check iPhone application.  
https://itunes.apple.com/us/app/themcnay-reality-
check/id615135643?mt=8  
[retrieved, March, 2015]. 
[26] Eric Zimmerman: West of the Hudson, example images, 
scanable by Musing,  
http://www.musingapp.com/test_images/,  
[retrieved, March, 2014].  
[27] M. Schwarzer, ‚ÄúArt & Gadgetry: The Future of the 
Museum Visit‚Äù, Museum News.  
http://www.aamus.org/pubs/mn/MN_JA01_ArtGadgetry.cf
m,  
[retrieved, March, 2015]. 
[28] D.C. Stam, ‚ÄúThe informed muse: The implications of ‚ÄòThe 
New Museology‚Äô for museum practice,‚Äù In G. Corsane 
(Ed.), Heritage, Museums and Galleries. London and New 
York: Routledge, 2005. 
[29] A. McClellan, ‚ÄúIdeals and Mission,‚Äù The Art Museum from 
Boullee to Bilbao, University of California Press, pp. 13-
54, 2008. 
[30] M. Calonder et al., ‚ÄúBRIEF: Computing a Local Binary 
Descriptor Very Fast,‚Äù IEEE Transactions on Pattern 
Analysis and Machine Intelligence, 34(7), 2012, pp. 1281-
1298. 
[31] E. Rosten, R. Porter and T. Drummond, ‚ÄúFaster and Better: 
A Machine Learning Approach to Corner Detection,‚Äù IEEE 
Transactions on Pattern Analysis and Machine Intelligence, 
32(1), 2010, pp. 105-119. 
[32] Museums & Society 2034: Trends and Potential Futures, 
Center for the Future of Museums, American Association 
of Museums, Washington, DC  
http://resource.aaslh.org/view/museums-and-society-2034-
trends-and-potential-futures-report/  
[retrieved, March, 2015]. 
 

