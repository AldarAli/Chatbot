Variable-Regularized Low-Complexity RLS
Adaptive Algorithms for Bilinear Forms
Ionut¸-Dorinel Fˆıciu, Camelia Elisei-Iliescu, Cristian-Lucian Stanciu, and Constantin Paleologu
University Politehnica of Bucharest, Romania
Email: {cristian, pale}@comm.pub.ro
Abstract—This work in progress targets the identiﬁcation of
bilinear forms using fast converging adaptive algorithms. In
this framework, the bilinear term is deﬁned with respect to
the impulse responses of a spatiotemporal model. Recently, the
recursive least-squares algorithm tailored for bilinear forms
(RLS-BF) was introduced in this context, together with its low-
complexity version based on dichotomous coordinate descent
(DCD) iterations, namely RLS-DCD-BF. Aiming to improve the
robustness of the RLS-DCD-BF algorithm in noisy conditions, a
variable-regularized version is presented in this paper. Simulation
results indicate the appealing performance of this solution and
motivate our future works on multilinear forms.
Index Terms—adaptive ﬁlter; bilinear forms; recursive least-
squares; variable regularization; dichotomous coordinate descent
I. INTRODUCTION
The recursive least-squares (RLS) is the algorithm of choice
in many system identiﬁcation scenarios [1]. The main reason
behind this popularity is its fast converging feature, while
the drawback consists of a high computational complexity.
However, there are several efﬁcient solutions to reduce the
computational amount of the RLS algorithm, like the dichoto-
mous coordinate descent (DCD) method [2].
Nevertheless, the system identiﬁcation problems become
challenging in case of a larger parameter space [3]. Such
approaches can be formulated in terms of the identiﬁcation
of multilinear forms, while the solutions are based on multi-
dimensional adaptive algorithms. Currently, we focus on the
identiﬁcation of bilinear forms, where the bilinear term is
deﬁned with respect to the impulse responses of a spatiotem-
poral model [4]. Recently, the RLS algorithm tailored for
the identiﬁcation of bilinear forms (RLS-BF) was developed,
together with its DCD-based version (RLS-DCD-BF) [5].
This work in progress is focused on two main directions.
First, in order to improve the robustness in noisy environments,
we present a variable-regularized (VR) version of the RLS-BF
algorithm (namely VR-RLS-BF), where the time-dependent
regularization parameters are adjusted so that the algorithm
can perform well in noisy environments. Second, we develop
low-complexity versions of the VR-RLS-BF algorithm based
on the DCD method. Simulation results show the good behav-
ior of the VR-based algorithms and open the path toward the
generalization of these solutions for multilinear forms.
The paper is organized as follows. Section II introduces
the system model and brieﬂy presents the RLS-DCD-BF al-
gorithm [5]. Section III is dedicated to the variable regularized
versions of this algorithm. Simulation results are provided in
Section IV, while Section V concludes the paper.
II. RLS-DCD-BF ALGORITHM
In the framework of a real-valued bilinear model [4], the
reference signal (at discrete-time index n) is deﬁned as
d(n) = hT X(n)g + w(n) = y(n) + w(n),
(1)
where
h
and
g
are
the
two
impulse
responses
of
the
system
(of
lengths
L
and
M,
respectively),
X(n)
=
[ x1(n)
x2(n)
· · ·
xM(n) ]
is the zero-
mean
multiple-input
signal
matrix
of
size
L × M,
xm(n) =
[ xm(n)
xm(n − 1)
· · ·
xm(n − L + 1) ]T
is a vector containing the L most recent time samples of the
mth (m = 1, 2, . . . , M) input signal, w(n) is the zero-mean
additive noise [which is uncorrelated with X(n)], and the
superscript T denotes the transpose operator. From (1), we
can deﬁne the signal-to-noise ratio (SNR) as SNR = σ2
y/σ2
w,
where σ2
y
=
E
[
y2(n)
]
and σ2
w
=
E
[
w2(n)
]
are the
variances of y(n) and w(n), respectively, with E[·] denoting
mathematical expectation. The goal is to identify the two
impulse responses of the bilinear system (i.e., h and g) with
two adaptive ﬁlters, denoted by bh(n) and bg(n).
Following this approach, the estimated signal results in
by(n) = bhT (n − 1)X(n)bg(n − 1), while the error signal is
e(n) = d(n) − by(n) = d(n) − bhT (n − 1)X(n)bg(n − 1)
= d(n) − bhT (n − 1)exbg(n) = d(n) − bgT (n − 1)exbh(n), (2)
with the notation exbg(n)
=
[bg(n − 1) ⊗ IL]T ex(n) and
exbh(n) =
[
IM ⊗ bh(n − 1)
]T
ex(n), where ⊗ is the Kro-
necker product, IL and IM are the identity matrices of
sizes L × L and M × M, respectively, and ex(n)
=
[
xT
1 (n)
xT
2 (n)
· · ·
xT
M(n)
]T .
Following
the
least-
squares (LS) error criterion, the normal equations are [4]
Rbg(n)bh(n) = pbg(n),
(3)
Rbh(n)bg(n) = pbh(n),
(4)
where the terms from (3)–(4) can be recursively updated as
Rbg(n) = λbhRbg(n − 1) + exbg(n)exT
bg (n),
(5)
pbg(n) = λbhpbg(n − 1) + exbg(n)d(n),
(6)
Rbh(n) = λbgRbh(n − 1) + exbh(n)exT
bh(n),
(7)
pbh(n) = λbgpbh(n − 1) + exbh(n)d(n),
(8)
9
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Table I. RLS-DCD-BF algorithm.
Initialization:
bh(0) =
[ 1
0
· · ·
0 ]T , bg(0) = 1
M
[ 1
1
· · ·
1 ]T
Rbg(0) = δIL, Rbh(0) = δIM, rbh(0) = 0L×1, rbg(0) = 0M×1
For n = 1, 2, . . .
Step 1:
Rbg(n) = λbhRbg(n − 1) + exbg(n)exT
bg (n)
Rbh(n) = λbgRbh(n − 1) + exbh(n)exT
bh (n)
Step 2:
e(n) = d(n) − exT
bg (n)bh(n − 1) = d(n) − exT
bh (n)bg(n − 1)
Step 3:
epbg(n) = λbhrbh(n − 1) + exbg(n)e(n)
epbh(n) = λbgrbg(n − 1) + exbh(n)e(n)
Step 4:
Rbg(n)△bh(n) = epbg(n)
DCD
==⇒ △bh(n), rbh(n)
Rbh(n)△bg(n) = epbh(n)
DCD
==⇒ △bg(n), rbg(n)
Step 5:
bh(n) = bh(n − 1) + △bh(n)
bg(n) = bg(n − 1) + △bg(n)
with λbh (0 ≪ λbh < 1) and λbg (0 ≪ λbg < 1) denoting the
forgetting factors. Using the matrix inversion lemma [1] to
update R−1
bg (n) and R−1
bh (n), the RLS algorithm for bilinear
forms (RLS-BF) was developed in [5]. This algorithm has a
computational complexity proportional to O(L2 + M 2).
In order to reduce the computational amount of the RLS-BF
algorithm, an efﬁcient approach is based on transforming the
sequences of the normal equations (3)–(4) into a sequence of
auxiliary normal equations. These auxiliary normal equations
can be solved by using an efﬁcient iterative technique, like
the DCD algorithm [2]. The resulting RLS-DCD algorithm
for bilinear forms (RLS-DCD-BF) is resumed in Table I.
The evaluation of the correlation matrices [i.e., Rbg(n) and
Rbh(n) in step 1] represents a computationally expensive step
of the RLS-DCD-BF algorithm. Exploiting the structure of
these matrices, two approximate versions of the RLS-DCD-BF
algorithm were proposed in [5]. The ﬁrst one, namely RLS-
DCD-BF-v1, takes into account that exbg(n) owns (to some
extent) the time-shift property, especially in the steady-state,
when bg(n) ≈ bg(n−1). Consequently, since the matrix Rbg(n)
is symmetric, only its ﬁrst column could be computed, i.e.,
R(1)
bg (n) = λbhR(1)
bg (n − 1) + exbg(n)ex(1)
bg (n),
(9)
where ex(1)
bg (n) denotes the ﬁrst element of the vector exbg(n).
Moreover, the lower-right (L−1)×(L−1) block of Rbg(n) can
be approximated by the (L − 1) × (L − 1) upper-left block of
the matrix Rbg(n − 1). Thus, the computational complexity of
the RLS-DCD-BF-v1 algorithm is proportional to O(L+M 2).
Similarly, under some strong assumptions [i.e., i) the co-
variance matrices of the inputs are close to a diagonal one
and ii) the input signals are independent and have the same
power], we can also assume that Rbh(n) tends to a diagonal
matrix, so that it could be efﬁciently updated similar to (9).
Hence, a second version of RLS-DCD-BF algorithm results
(namely RLS-DCD-BF-v2), with a computational complexity
proportional to O(L + M).
III. VARIABLE REGULARIZED RLS-BF ALGORITHMS
The regularization process is essential in practice, taking
into account the presence of additive noise [6]. Here, we
consider the regularized RLS-BF algorithm, with the updates:
bh(n) = bh(n − 1) +
[
Rbg(n) + δbhIL
]−1 exbg(n)e(n),
(10)
bg(n) = bg(n − 1) +
[
Rbh(n) + δbgIM
]−1 exbh(n)e(n),
(11)
where δbh and δbg are the regularization terms. Alternatively,
bh(n) = Pbg(n)bh(n − 1) + eh(n),
(12)
bg(n) = Pbh(n)bg(n − 1) + eg(n),
(13)
where Pbg(n)
=
IL −
[
Rbg(n) + δbhIL
]−1 exbg(n)exT
bg (n),
Pbh(n) = IM −
[
Rbh(n) + δbgIM
]−1 exbh(n)exT
bh(n), and
eh(n) =
[
Rbg(n) + δbhIL
]−1 exbg(n)d(n),
(14)
eg(n) =
[
Rbh(n) + δbgIM
]−1 exbh(n)d(n).
(15)
The vectors eh(n) and eg(n) are the correction components of
the algorithm, due to the dependency on d(n). Let us deﬁne
eebg(n) = d(n) − ehT (n)exbg(n),
(16)
eebh(n) = d(n) − egT (n)exbh(n),
(17)
the error signals between the desired signal and the estimated
signals obtained from the ﬁlters optimized in (14)–(15). In
the context of system identiﬁcation, the purpose is to recover
the noise signal from the error of the adaptive ﬁlter [6]. As a
consequence, we could ﬁnd δbh and δbg in such a way that
E
[
ee2
bg(n)
]
= E
[
ee2
bh(n)
]
= σ2
w.
(18)
At this point, let us assume that the covariance matrices of the
inputs are close to a diagonal one, i.e., E
[
xm(n)xT
m(n)
]
≈
σ2
xmIL, m = 1, 2, . . . , M; also, let us consider that the input
signals are independent and have the same power, i.e., σ2
xm ≈
σ2
x, m = 1, 2, . . . , M. In this context, we can show that
exT
bh(n)exbh(n) ≈ Mσ2
x
bh(n − 1)

2
, where ∥·∥ denotes the Eu-
clidean norm. Also, E
[
exbh(n)exT
bh(n)
]
≈ σ2
x
bh(n − 1)

2
IM.
Similarly, we obtain exT
bg (n)exbg(n) ≈ Lσ2
x ∥bg(n − 1)∥2 and
E
[
exbg(n)exT
bg (n)
]
≈ σ2
x ∥bg(n − 1)∥2 IL. Therefore, for λbh ≈
1 − 1/L and λbg ≈ 1 − 1/M, we obtain (for n large enough):
Rbg(n) + δbhIL ≈
[
Lσ2
x ∥bg(n − 1)∥2 + δbh
]
IL,
(19)
Rbh(n) + δbgIM ≈
[
Mσ2
x
bh(n − 1)

2
+ δbg
]
IM.
(20)
10
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Next, squaring and taking the expectations on both sides of
(16)–(17), then developing (18) based on (19)–(20), we obtain
two quadratic equations with the following solutions:
δbh =
LE
[
∥bg(n − 1)∥2] (
1 +
√
1 + SNR
)
SNR
σ2
x,
(21)
δbg =
ME
[bh(n − 1)

2] (
1 +
√
1 + SNR
)
SNR
σ2
x.
(22)
The most problematic term in (21)–(22) is the SNR, taking
into account that the additive noise could be nonstationary
in real-world applications. However, in (1), the output signal
y(n) can be considered uncorrelated with the noise w(n).
Therefore, (1) can be expressed in terms of power estimates
as σ2
d = σ2
y + σ2
w, where σ2
d = E
[
d2(n)
]
is the variance
of the reference signal. Consequently, σ2
w = σ2
d − σ2
y. At this
point, let us assume that the adaptive ﬁlters have converged to a
certain degree, so that we can use the approximation σ2
y ≈ σ2
by,
where σ2
by = E
[
by2(n)
]
is the variance of the estimated signal
by(n). Using this approximation, it results that σ2
w ≈ σ2
d − σ2
by.
The power estimates can be recursively estimated as bσ2
d(n) =
γbσ2
d(n − 1) + (1 − γ)d2(n) and bσ2
by(n) = γbσ2
by(n − 1) +
(1 − γ)by2(n), where 0 ≪ γ < 1. Therefore, an estimate of
the SNR results in [
SNR(n) = bσ2
by(n)/|bσ2
d(n) − bσ2
by(n)|. Next,
since bh(n − 1) and bg(n − 1) are available at time index n,
the expectation operator can be omitted in (21)–(22). Thus,
using the notation s(n) =
[
1 +
√
1 + [
SNR(n)
]
/[
SNR(n),
the regularization terms from (21)–(22) result in
δbh(n) = L ∥bg(n − 1)∥2 s(n)σ2
x,
(23)
δbg(n) = M
bh(n − 1)

2
s(n)σ2
x.
(24)
Consequently, we obtain a variable-regularized RLS-BF (VR-
RLS-BF) algorithm, with the updates similar to (10)–(11), but
using the variable regularization parameters from (23)–(24).
Furthermore, the problem can be interpreted in terms of
solving the normal equations [1]:
Rbg(n)bh(n) = pbg(n),
(25)
Rbh(n)bg(n) = pbh(n),
(26)
where Rbg(n) =
bRbg(n) + δbh(n)IL, Rbh(n) =
bRbh(n) +
δbg(n)IM, and pbg(n) and pbh(n) are given in (6) and (8),
respectively. The normal equations (25)–(26) can also be recur-
sively solved using the DCD method [2]. Therefore, following
a similar approach (as presented in Section II), it results a low-
complexity version of the VR-RLS-BF algorithm based on the
DCD iterations, namely VR-RLS-DCD-BF; this algorithm is
summarized in Table II. Also, the computational complexity
in step 1 of the VR-RLS-DCD-BF algorithm can be reduced
based on (9). Similarly, two versions of the VR-RLS-DCD-BF
algorithm can be obtained, which are also indexed as v1 and
v2. The ﬁrst one uses (7) and (9) in step 1 [i.e., an amount of
O(L+M 2) operations], while the second one further reduces
the computational amount up to O(L + M), similar to the
RLS-DCD-BF-v2 algorithm.
Table II. VR-RLS-DCD-BF algorithm.
Initialization:
bh(0) =
[ 1
0
· · ·
0 ]T , bg(0) = 1
M
[ 1
1
· · ·
1 ]T
Rbg(0) = 0L×L, Rbh(0) = 0M×M
rbh(0) = 0L×1, rbg(0) = 0M×1
For n = 1, 2, . . .
Step 1:
Rbg(n) = λbhRbg(n − 1) + exbg(n)exT
bg (n)
Rbh(n) = λbgRbh(n − 1) + exbh(n)exT
bh (n)
Step 2:
Compute δbh(n) and δbg(n) using (23)–(24)
Step 3:
Rbg(n) = Rbg(n) + δbh(n)IL
Rbh(n) = Rbh(n) + δbg(n)IM
Step 4:
e(n) = d(n) − exT
bg (n)bh(n − 1) = d(n) − exT
bh (n)bg(n − 1)
Step 5:
epbg(n) = λbhrbh(n − 1) + exbg(n)e(n)
epbh(n) = λbgrbg(n − 1) + exbh(n)e(n)
Step 6:
Rbg(n)△bh(n) = epbg(n)
DCD
==⇒ △bh(n), rbh(n)
Rbh(n)△bg(n) = epbh(n)
DCD
==⇒ △bg(n), rbg(n)
Step 7:
bh(n) = bh(n − 1) + △bh(n)
bg(n) = bg(n − 1) + △bg(n)
IV. SIMULATION RESULTS
Simulations are performed in the framework of the bilinear
model described in Section II, in the context of a system
identiﬁcation scenario. The two impulse responses of the
spatiotemporal system (h and g) are randomly generated, with
Gaussian distribution; the lengths are set to L = 64 and
M = 8. An abrupt change of the system is simulated in the
ﬁrst two experiments, by generating two new random impulse
responses in the middle of simulations, in order to evaluate the
tracking capabilities of the algorithms. In the experiments, we
compare the performance of the RLS-DCD-BF, VR-RLS-BF,
and VR-RLS-DCD-BF algorithms. The same values of the
forgetting factors are used for all the algorithms, by setting
λbh = λbg = 1 − 1/(2ML). As a performance measure,
the normalized projection misalignment (NPM) [7] is used to
evaluate the identiﬁcation of the individual impulse responses.
In the ﬁrst experiment (Figure 1), we compare the perfor-
mance of the VR-based algorithms in moderate SNR con-
ditions, using SNR = 10 dB. The input signals are AR(1)
processes, where each one of them is generated by ﬁltering
a white Gaussian noise through a ﬁrst-order system with
the transfer function 1/
(
1 − 0.8z−1)
. All the DCD-based
algorithms use only one “successful” DCD iteration [2], which
is a signiﬁcant gain in terms of computational complexity. As
we can notice in Figure 1(a), both VR-RLS-DCD versions (v1
and v2) perform very similar to the VR-RLS-BF algorithm.
However, it can be noticed a slower tracking reaction of the
VR-RLS-DCD-v2 [Figure 1(b)], due to the approximation
related to the matrix Rbh(n), which is related to the spatial
ﬁlter bg(n). On the other hand, since the temporal ﬁlter bh(n)
11
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

Time (seconds)
0
1
2
3
4
5
6
7
8
9
10
NPM[g, bg(n)] (dB)
-50
-40
-30
-20
-10
0
(b)
VR-RLS-BF
VR-RLS-DCD-BF-v1
VR-RLS-DCD-BF-v2
Time (seconds)
0
1
2
3
4
5
6
7
8
9
10
NPM
h
h, bh(n)
i
(dB)
-30
-20
-10
0
(a)
VR-RLS-BF
VR-RLS-DCD-BF-v1
VR-RLS-DCD-BF-v2
Figure 1.
Comparison of the VR-based algorithms in terms of (a)
NPM
[
h, bh(n)
]
and (b) NPM [g, bg(n)]. The system changes after 5 sec-
onds. The input signals are AR(1) processes and SNR = 10 dB.
Time (seconds)
0
5
10
15
20
25
30
NPM[g, bg(n)] (dB)
-30
-20
-10
0
(b)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Time (seconds)
0
5
10
15
20
25
30
NPM
h
h, bh(n)
i
(dB)
-20
-15
-10
-5
0
(a)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Figure 2.
Comparison of the VR-based algorithms in terms of (a)
NPM
[
h, bh(n)
]
and (b) NPM [g, bg(n)]. The system changes after 15
seconds. The input signals are speech sequences and SNR = 0 dB.
is not directly inﬂuence by this approximation, it behaves well
in case of the VR-RLS-DCD-BF-v2 algorithm [Figure 1(a)].
In the following, we focus on the performance of the VR-
RLS-DCD-BF algorithm, which is compared to the RLS-
DCD-BF algorithm (i.e., the “non-regularized” version). The
input signals are speech sequences. Thus, we do not include
in comparisons the v2 versions, since the assumption related
to the matrix Rbh(n) is biased for nonstationary inputs.
In Figure 2, we consider low SNR conditions, by setting
SNR = 0 dB. It can be noticed that the VR-based algo-
rithms perform very similar. Nevertheless, the RLS-DCD-BF-
v1 algorithm achieves a slightly better tracking reaction, while
reaching a higher misalignment level.
Finally, in Figure 3, we assess the performance of the
algorithms in case of SNR variations. In the ﬁrst 12 seconds,
we set SNR = 0 dB; then, the SNR drops to −25 dB for
the next 6 seconds. Nevertheless, the VR-based algorithms
are very robust in this case. Also, the VR-RLS-BF and VR-
RLS-DCD-BF-v1 perform very similar. As expected, the RLS-
Time (seconds)
0
5
10
15
20
25
30
NPM[g, bg(n)] (dB)
-30
-20
-10
0
(b)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Time (seconds)
0
5
10
15
20
25
30
NPM
h
h, bh(n)
i
(dB)
-20
-15
-10
-5
0
(a)
VR-RLS-BF
VR-RLS-DCD-BF-v1
RLS-DCD-BF-v1
Figure 3. Comparison of the VR-RLS-BF, VR-RLS-DCD-BF-v1, and RLS-
DCD-v1 algorithms in terms of (a) NPM
[
h, bh(n)
]
and (b) NPM [g, bg(n)].
The SNR decreases from 0 dB to −25 dB between times 12 and 18 seconds.
DCD-BF-v1 algorithm is affected by the noise variation.
V. CONCLUSIONS AND FUTURE WORKS
In this work in progress, we have focused on the regular-
ization terms of the RLS algorithm for bilinear forms. First,
a method for ﬁnding the optimal regularization parameters
(depending on the SNR) was presented. Second, using a proper
evaluation of the SNR, a variable-regularized algorithm was
developed, together with two low-complexity versions based
on the DCD method. Simulations have shown that the VR-
based algorithms outperform their non-regularized counterpart,
mainly in terms of robustness against SNR variations.
Future works will focus on the extension of these solutions
in case of multilinear forms, by exploiting tensor-based adap-
tive algorithms. In this context, the decomposition methods
can be combined with low-rank approximations, aiming the
identiﬁcation of more general forms of impulse responses.
ACKNOWLEDGEMENT
This work was supported by a grant of the Romanian Ministry of Education
and Research, CNCS – UEFISCDI, project number: PN-III-P1-1.1-TE-2019-
0529, within PNCDI III.
REFERENCES
[1] A. H. Sayed, Adaptive Filters. New York, NY: Wiley, 2008.
[2] Y. V. Zakharov, G. P. White, and J. Liu, “Low-complexity RLS algo-
rithms using dichotomous coordinate descent iterations,” IEEE Trans.
Signal Processing, vol. 56, pp. 3150–3161, July 2008.
[3] M. Rupp and S. Schwarz, “A tensor LMS algorithm,” in Proc. IEEE
International Conference on Acoustics, Speech, and Signal Processing
(ICASSP), 2015, pp. 3347–3351.
[4] C. Paleologu, J. Benesty, and S. Ciochin˘a, “Adaptive ﬁltering for the
identiﬁcation of bilinear forms,” Digital Signal Processing, vol. 75, pp.
153–167, Apr. 2018.
[5] C. Elisei-Iliescu et al., “Efﬁcient recursive least-squares algorithms for
the identiﬁcation of bilinear forms,” Digital Signal Processing, vol. 83,
pp. 280–296, Dec. 2018.
[6] J. Benesty, C. Paleologu, and S. Ciochin˘a, “Regularization of the RLS
algorithm,” IEICE Trans. Fundamentals, vol. E94-A, pp. 1628–1629,
Aug. 2011.
[7] D. R. Morgan, J. Benesty, and M. M. Sondhi, “On the evaluation of
estimated impulse responses,” IEEE Signal Processing Lett., vol. 5, pp.
174–176, July 1998.
12
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-848-8
ADAPTIVE 2021 : The Thirteenth International Conference on Adaptive and Self-Adaptive Systems and Applications

