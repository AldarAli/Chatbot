 
 
NEMO Converter 3D: Reconstruction of 3D Objects  
from Photo and Video Footage for Ambient Learning Spaces
David Bouck-Standen, Alexander Ohlei, Viktor Daibert, Thomas Winkler and Michael Herczeg 
Institute for Multimedia and Interactive Systems 
University of Luebeck 
Luebeck, Germany 
email: [bouck-standen, winkler, ohlei, daibert, herczeg]@imis.uni-luebeck.de 
 
 
Abstract— In ambient and mobile learning contexts, 3D 
renderings create higher states of immersion compared to still 
images or video. To cope with the considerable effort to create 
3D objects from images, with the NEMO Converter 3D 
(NOC3D) this paper presents a technical approach to 
automatically reconstruct 3D objects from semantically 
annotated media, such as photos and more importantly video 
footage, in a background process. By using the Mobile 
Learning Exploration System (MoLES) with a smartphone, 
the user creates and collects media in mobile context, which 
are automatically uploaded into the NEMO-Framework 
(Network Environment for Multimedia Objects) together 
with semantic annotations for contextualized access and 
retrieval. 
NEMO 
provides 
an 
extendable web-based 
framework to store media like photos, videos and 3D objects 
together with semantic annotations. The framework has been 
developed for Ambient Learning Spaces (ALS) in a research 
project. With InfoGrid, a mobile augmented reality 
application connected to NEMO, the user experiences the 
previously generated 3D object placed and aligned into real 
world scenes. 3D objects automatically reconstructed from 
photo and video footage by NOC3D are stored in NEMO and 
thus provided to all applications accessing the NEMO API. 
Related to the pedagogical background of our research 
project, this paper focuses on the technical realization and 
validation of NOC3D with reference to a realistic scenario for 
the usage of NOC3D in ambient and mobile contexts. In 
Section 2, we regard related work. In Section 3, we present a 
practical scenario for using NOC3D. In Sections 4, we 
describe the technical environment for NOC3D and our 
research project. In Section 5, we outline the realization of 
NOC3D in the ambient context of our scenario. In Section 6, 
we present our findings and conclude with a summary and 
outlook in Section 7. 
Keywords — Mobile media; Mobile learning; Ambient 
Learning Spaces; Multimedia Storage; 3D Conversion 
I. 
INTRODUCTION 
Today, in our interconnected society people live in close 
relationship with their digitally enriched environments. 
Together with ambient and mobile technology, this 
individual interconnection between physical and digital 
worlds plays an important role. Contemporary pedagogical 
approaches follow the assumption that humans learn 
individually and during all of their life. Since the learning 
process also takes place by being and acting in the physical 
world, one important goal is to offer ubiquitous learning 
environments; we called them Ambient Learning Spaces 
(ALS), as described by Winkler et al. [1]. In ALS, working 
with media in general, and especially mobile media supports 
the following learning objective: the learner creates 
contextualized and personalized media, which is stored as 
digital data and simultaneously enriched with a dynamic set 
of semantic annotations. This so-called enriched media is 
managed by the Network Environment for Multimedia 
Objects (NEMO) we now use in its latest implementation, 
based on the original concepts of Lob et al. [2]. NEMO 
stores text, still images, video, 3D objects, animations, and 
audio, which are extended by digital properties represented 
by semantic annotations. Through a digital overlay for 
physical objects, the NEMO framework provides web-
based access to enriched media within ALS. The relatedness 
of body and space supports the individuality of the learning 
process. Together with the loss of spatial distance and the 
exponentially growing quantity of information, this induces 
new technical requirements, as a single individual is no 
longer capable of consuming and structuring the globally 
and permanently available information in its entireness [3]-
[5]. ALS enables learners to structure information 
themselves using ambient technology in web-based 
applications in mobile contexts on their smartphones. This 
seems to be fostering the construction of sustainable and 
mindful knowledge. In this setting, enriched media become 
the carrier of information utilized in various contexts [6] 
within ALS, where 3D renderings empower imagination, 
creativity and learning compared to still images or video [7]. 
In ALS, enriched media is managed via the ALS Portal 
[6], a web-based platform that features modularized media 
management, ALS applications, such as mentioned below, 
and settings stored in NEMO for any ALS applications. For 
each learning application, a special area within the ALS-
Portal allows teachers and learners to manage information, 
primarily enriched media, depending on their access rights 
and permissions. 
With the help of the Mobile Learning Exploration 
System (MoLES), a mobile ALS application running on 
smartphones originally introduced by Winkler et al. [8], 
students create enriched media in a mobile context to 
answer given questions for a specific task assigned by their 
teacher whilst conducting an exploration outside of school. 
For example, they take photos and video footage from 
objects they encounter and add digital notes within MoLES 
by annotating the media. This enriched media is transferred 
to NEMO for storage. After finishing a field trip, the 
students use the enriched media they created to reflect and 
present their findings to their fellow students. 
For mobile context in ALS, we have developed the 
augmented reality application InfoGrid that recognizes 
visual markers or detects Bluetooth beacons both triggering 
the display of images and video, the playback of audio or 
the augmented reality presentation and alignment of 3D 
models provided by NEMO. 
6
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

 
 
In its semantic repository, the NEMO framework stores 
media from all the students as outlined. Images or video 
footage of the same physical objects often occur many 
times, but differ with regard to the angle, lightning or 
framing. With the NEMO Converter 3D (NOC3D), this 
paper presents a solution to make use of such footage 
collectively created by the students in order to enhance the 
learner’s experience in an ambient learning context. 
II.  
RELATED WORK 
Semantic media comprises the integration of data, 
information and knowledge. This relates to the Semantic 
Web [9] and aims at allowing computer systems as well as 
humans to make sense of data found on the web. This 
research field is of core interest for our work since it yields 
structured 
data 
in 
a 
well-defined, 
reusable, 
and 
contextualized manner. 
The field of metadata-driven digital media repositories 
is related to this work [10] as well. Apart from the goals of, 
e.g., delivering improved search results with the help of 
meta information or even a semantic schemata, the NEMO 
framework distinguishes itself from a mere repository by 
containing and using repositories as internal components, 
delivering more complex features through the NEMO logic 
described below. 
NEMO facilitates collecting, consuming and structuring 
information by interacting device-independently with 
enriched media, whereas the linked data research targets 
sharing and connecting data, information and knowledge on 
the Web [11]. 
Various implementations exist in order to reconstruct 
3D 
objects 
from 
photographic 
images, 
but 
the 
implementation examined in our work have in common not 
being integrated into a fully automated web-based 
framework making use of semantically annotated data in 
mobile contexts providing background services for ambient 
learning environments. 
In the research field of e-learning, other work 
connecting semantic structures with learning can be found 
[12]-[14]. In contrast, our work focuses on linking 
educational 
contents 
with 
the 
living 
environment 
(Lebenswelt) and thus engaging learners in communicative 
processes through contextualized and personalized enriched 
media. For this purpose, NEMO provides means of 
connecting formal and non-formal learning, e.g., in schools, 
as well as non-formal and informal learning outside of 
schools, like in museums. However, NEMO is not used to 
examine the learner’s performance, provide standard 
learning materials or collect homework, such as Moodle 
[15]. 
III.  A PRACTICAL SCENARIO 
Michelle, a fourteen year-old student, joins a field trip 
through the Hanseatic City of Luebeck at school. Prior to 
the field trip, with the help of the ALS-Portal, Michelle’s 
teacher prepared some questions for the students to be 
answered using MoLES, for example “Who are famous 
composers who left their tracks in Luebeck?” While 
exploring their city, Michelle answers this question with the 
MoLES application running on her smartphone. Michelle 
uses MoLES and takes photos and tapes videos of what she 
thinks is related to the question at hand. In this case, for 
instance, she discovers the statue of composer Johannes 
Brahms on the riverside of the Trave River. Using MoLES, 
she takes a few photos and records a video. For every 
medium she creates, Michelle notes a few keywords and 
sentences to remember better later on. MoLES uploads this 
enriched media automatically into NEMO over a secure 
connection. 
Back in school, Michelle prepares a short presentation 
of her findings from the field trip. Meanwhile, she knows 
that composer Johannes Brahms never lived in Luebeck 
himself. Michelle also learns that during the Imperial Era 
some ‘moneybags’ from Luebeck were fond of Brahms and 
centuries later, during the 1990s, the local Music Academy 
founded the Brahms Institute. She logs on to the ALS-Portal 
and, among her media, she discovers that the statue of 
Johannes Brahms is now available as a 3D model, which she 
incorporates into her presentation. With the help of the 
mobile application InfoGrid, during the presentation, her 
classmates, who are surprised that they did not notice the 
statue themselves before, are now able to take a closer look 
at it and are astonished to hear from Michelle’s presentation, 
that Brahms is also linked to the Hanseatic City of Luebeck. 
IV. NEMO AT A GLANCE 
NEMO is a web-based framework for ALS. As shown 
in Figure 1, the framework primarily consists of three main 
levels: (1) the NEMO Application Programming Interface 
(API) level giving ALS applications access to NEMO, (2) 
the NEMO Logic level and (3) the NEMO Core level. 
NEMO as well as NOC3D have been implemented in C# 
running on Windows Server and Microsoft .NET 
architecture, 
also 
making 
use 
of 
the 
Windows 
Communication Foundation (WCF) framework. 
The NEMO API (cf. Figure 1) provides access for 
applications, such as MoLES, interacting through Web 
Services in an authenticated context over a secure 
connection. Each application accesses a specific Web 
Service to achieve a higher level of transparency and 
Figure 1: The NEMO framework. The NEMO Logic computes, e.g., 
coherences, semantic models, and data mapping and a modularised 
interface for feature extendibility. 
7
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

 
 
maintainability. With the NEMO API Client Model, we 
created a model for a well-defined data interchange between 
NEMO and any application in ALS through the Web, 
following the idea of knowledge representation in a formal 
and explicit way. From experience, we expect any 
information entered by a learner to be incomplete, as he or 
she is still engaged in a process of gathering, structuring, 
and memorizing, thus NEMO is able to handle incomplete 
and uncertain information [16] in the NEMO Logic and 
Core levels. Therefore, the model for any client application 
is independent of any internal model used by the NEMO 
framework. In addition, this minimizes the learning curve 
for ALS application development, as no detailed knowledge 
of semantic modeling is required when developing an 
application accessing NEMO. NEMO also provides cross-
platform capabilities [17]. 
In the NEMO Logic, we implemented the NEMO 
Model, which abstracts ALS as a semantic model. Here, the 
computational logic resides, which initiates and controls 
like semantic searches and context analysis in the NEMO 
Core. In the NEMO Logic, mappings are conducted 
between the NEMO Model and the NEMO API Client 
Model through a modified Semantic Object Relational 
Mapping (SORM). For any Web Service, the NEMO Logic 
holds the specific application logic and thus interconnecting 
the applications 
accessing 
the 
NEMO 
framework 
semantically through an extendable modular structure with 
loose coupling. We have already developed extensions for 
NEMO, e.g., the NEMO Converter (cf. Figure 1), which 
delivers media in device-specific formats and resolution as 
requested. For research purposes, another extension tracks 
all requests, actions, as well the corresponding application 
state of the NEMO framework. NOC3D also extends 
NEMO Logic. All data collected is stored anonymously, 
due to the sensitivity of the data and legal regulations for 
public organizations like schools and museums. In a defined 
context of an evaluation, personal information may be 
collected synonymously. As we develop NEMO with 
scalability and diversity in mind, NEMO also runs in 
multiple interconnected instances. 
The NEMO framework is based on the NEMO Core 
where enriched media is stored (cf. Figure 1). A semantic 
database provides internal storage for any digital entity in 
the form of semantic annotations. Through the Semantic 
Web Connector, (cf. Figure 1) any semantic database can be 
used as internal data store, thus developing applications 
accessing NEMO requires no knowledge of the respective 
database query language. Any query result of the internal or 
any external semantic database is mapped into the NEMO 
Model. In the NEMO Logic, this data will be processed as 
described above. Binary media is stored in the Binary 
Storage (cf. Figure 1), which is linked to the internal 
semantic database in order to retrieve the stored object as 
enriched media again and also serves as cache in order to 
reduce on-the-fly conversion time of the NEMO Converter. 
An authentication module provides an interface to connect 
to different authoritative systems in order to check 
application or media-specific permission settings and user 
access rights. 
V. THE NEMO CONVERTER 3D 
NOC3D is developed as a component for the NEMO 
Logic under the following assumptions, which are partly 
derived from the scenario described above: 
 NOC3D runs in an autonomous mode as a 
background service without any user interaction 
required. 
 Images and videos are taken with different camera 
models, mostly with smartphones, from various 
angles and may contain only sections of the object. 
Therefore, an input for NOC3D can most certainly 
not be described as “ideal” or “complete”. The 
cameras are not calibrated. 
 No additional markers are used in the process of 
media creation, only steady surroundings around the 
object are required. Every photo or video has to 
contain 
surroundings 
around 
the 
object 
of 
reconstruction. 
 An object for reconstruction has to be sized between 
5cm and 5m in height. 
 Images and videos may not contain multiple objects 
and only one object will be reconstructed per run. 
A. 3D Reconstruction 
In general, the algorithms used in each step and data they 
require or provide as input and output determine the 
sequence of steps of 3D reconstruction. For our scenario in 
an ambient context, we have enhanced their combination 
and derived parameters from the tests we conducted. At 
first, from automatically generated and manually entered 
semantic annotations, GPS coordinates, date and time and 
with regard to different calendrical seasons, for each 
possible 3D object, NEMO compiles a selection of images 
and videos, which possibly show the same object. All media 
is transferred to NOC3D, as shown in Figure 2. As NOC3D 
provides a web-based API, NOC3D may be set up on a 
dedicated server. An identifier passed additionally allows 
NEMO to link the original media with the 3D object after 
the asynchronous task of NOC3D finishes.  
Operating on the media selection passed on by NEMO, 
NOC3D at first calculates camera parameters, which will be 
used for the process of reconstruction later on. 3D object 
reconstruction starts by calculating match points of all 
images and grouping them using VisualSFM [18]. This is 
necessary in order to find the object for 3D reconstruction 
in the images automatically. Every two images with at least 
40 match points are grouped. To receive a high quality result 
from later steps, all images with a resolution below 
1200x1200px are discarded at this point, if a group has a 
minimum of 10 images with a resolution above 
1200x1200px. A group with less than 10 images is 
discarded, because these will not be of any use for further 
processing. We found these parameter values through 
experimental 
testing 
during 
development. 
Running 
VisualSFM on the group of images, until no other image of 
the selection can be grouped repeating all steps outputs a 
group of images containing the object for 3D reconstruction.  
In the next step, depicted in Figure 2, the Center for 
Machine Perception Multi-view Reconstruction Software 
(CMPMVS) [19] calculates the cloud of points using the 
camera parameters from the first step [20][21]. CMPMVS 
transforms the point cloud into a mesh model and separately 
calculates a preliminary texture. 
8
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

 
 
The textured model is handed over to MeshLab [22]. At 
first, small artifacts are removed and, for web-based and 
browser compatibility, the number of polygons is reduced 
to 30.000. In addition, MeshLab is used to close polygon 
gaps in the reconstructed model, remove devious edges and 
smooth the entire model. After conversion into a NEMO-
compatible file format, NOC3D hands over the completed 
3D object to NEMO. NEMO stores the 3D object together 
with the semantic annotations of the images used to 
reconstruct the model, omitting those annotations from the 
enriched media that do not match. Afterwards, the 3D object 
is available in NEMO. 
B. 3D Reconstruction from Video Footage 
In general, in the process of 3D reconstruction more 
images from different angles lead to qualitatively better 
results. During the development of NOC3D through 
qualitative evaluation with university students, we found 
out that taking hundreds of images of the same object does 
not integrate well with our usage scenario. In case of an 
entire class of 20 or more students, who take at least five 
images of the same object, NOC3D produces acceptable 
results. However, the challenge of acquiring sufficient 
footage remains. 
The process of acquiring footage used for 3D 
reconstruction is simplified by supporting videos as input 
format. As a video generally consists of at least 24 frames 
per second, just moving around the object taping a video 
will produce enough material. Before starting the process of 
reconstruction, videos have to be pre-processed, as 
illustrated in Figure 2. The video frames are extracted 
frame-by-frame into images using FFmpeg and stored 
temporarily. This leads to duplicate or similar images, e.g., 
when the camera movement around the object is slow. All 
duplicates are removed during pre-processing using the 
imaging library ImageMagick, as they do not contribute 
usable data in the object reconstruction process. In addition, 
unusable images like from overexposed or black frames will 
be removed. After pre-processing, all images extracted from 
the video footage are joined with other images for 
reconstruction. Our tests indicate, that at least one image 
(e.g. photo) not taken from a video is required in order to 
produce acceptable results. This is due to camera 
parameters, which are not separately stored with each video 
frame, but are required for the process of 3D reconstruction. 
As for our scenario, smartphones used to take photos and 
tape videos available today produce video footage in similar 
quality to images, which are sufficient for NOC3D, as 
illustrated in Figure 3. 
C. Running Time Issues 
With regard to 3D reconstruction, running time of the 
module is critical. Preparing the media for processing is 
performed with linear effort, including extracting usable 
still images from video as shown in Figure 2. All further 
steps require significantly more effort, depending on the 
number of images, the objects complexity and the image 
resolution. Through experiments, we found that this process 
is speeded-up without losing quality by reducing the image 
resolution of all images with a resolution above 
1200x1200px in half. Additionally, running time improves 
significantly, whenever images are omitted that do not 
contain the object, which is reconstructed.  
During development, we found that integrating NOC3D 
directly on the same server with NEMO is unpractical, as 
3D reconstruction in general results in high processor 
(CPU) utilization. Besides, 3D reconstruction performs up 
to 75% faster on Graphics Processing Units (GPU) than on 
CPUs. The solution we implemented is to run NOC3D on a 
dedicated server. Therefore, we extended NOC3D to 
connect with NEMO through over Web Services. As a 
  
Figure 2. Sequence of the NOC3D algorithm, as more detailed described 
in section V.A. Media selection as well as storing the 3D object is 
performed externally from NOC3D by NEMO. 
 
Figure 3. Screenshot of a 3D object reconstructed with NOC3D from 
225 images automatically extracted from semantically annotated videos. 
The blue background is rendered by the 3D object viewer. 
9
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

 
 
result, NEMO transfers all footage to NOC3D, which stores 
all data temporarily on that server. The process of 3D 
reconstruction is started after all footage has been 
transferred and NOC3D signals NEMO the completion of a 
conversion process via callback. Because we are using a 
dedicated server, we are now able to choose CMPMVS as 
cloud of points algorithm, which only runs on CUDA-
enabled (Compute Unified Device Architecture) GPUs.  
VI. 
FINDINGS 
In summary, NOC3D produces 3D objects (cf. Figure 3) 
with an acceptable quality given the mobile and ambient 
context of our scenario in the open standard OBJ-file-
format. Due to the automatic process, it is inevitable that 3D 
objects may contain some surroundings, like, e.g., the grass 
and path around the statue shown in Figure 3.  
In order to integrate NOC3D in a timely manner as 
outlined in our scenario, most importantly a multi-GPU 
system consisting of multiple CUDA-compatible graphic 
boards is recommended. In addition, free RAM capacity of 
at least the size of the footage used for conversion as well as 
hard disk storage of at least ten times the size of the footage 
for temporary storage is advisable. For evaluation purposes, 
we have tested our implementation with series of photos 
taken with different smartphones (e.g. Samsung SM-
G531F, Nokia Lumia 650 and 930, Motorola Moto G4 and 
X Play). With regard to the quality of the resulting 3D 
objects, we also used photos from digital cameras (e.g. 
Olympus D595Z, Nikon D7000). We have taken footage 
from 20 different statues across the Hanseatic City of 
Luebeck, Germany, and compiled them into different 
selections according to semantic annotations using NEMO. 
The footage taken cannot be described as ‘ideal’, as we 
cared to take mostly snapshots, e.g., only showing parts of 
the objects or without optimal lightning that would be used 
when reconstructing 3D models in, for instance, a 
laboratory with a special 3D scanner. Thus, our tests reflect 
media expected to be created by students on a field trip, 
matching our scenario. 
Our evaluation shows that, in our scenario, an average 
minimum of 110 images is required in order to be able to 
recognize the resulting 3D object as such, as illustrated in 
Figure 4. The maximum of images is only limited by 
hardware resources, but keeping in mind the time-
consuming process of 3D reconstruction should be limited 
to a maximum of 450 images. This value is derived from 
our experiments in context with our scenario and is 
depending on the objects complexity, desired quality, 
hardware capabilities, as described below, and the usage 
scenario. In addition, our tests indicate that using images 
with the same resolution enhances performance, but our 
research does not focus on optimizing the algorithms 
employed for 3D reconstruction within NOC3D. Hence, we 
recommend setting up NOC3D on a dedicated GPU render 
server. 
Using footage from symmetric objects especially in 
front of symmetric or repeating backgrounds leads to 
unusable 3D objects, as the example in Figure 5 shows. 
Using more photos does not enhance the output. Generally 
and as expected, higher resolution of footage as well as 
using more images results in more detailed 3D objects. 
Nevertheless, using MoLES in context with our scenario 
limits students to the use of smartphones, which is why or 
primary focus lies on generating acceptable 3D models from 
smartphone-generated footage. 
During our tests, we found that in some cases NOC3D 
aborted due to a memory overflow. This occurs due to 
limited hardware resources, exhausted by huge amounts of 
input data. Apart from upgrading the hardware, our solution 
is to catch the exception and remove images with the highest 
and lowest resolution gradually, restarting the process. With 
this strategy we try to keep as much information on the 
object and as much high quality footage as possible. This 
strategy may be optimized with the help of future 
experience.  
In total, NOC3D generates all sample models without 
any unexpected result or malfunctioning. Processing the 
sample models on our dedicated system using an NVidia 
GeForce GTX 560 takes between four and eight hours each, 
depending on model complexity and the amount of data to 
process.  
VII. 
SUMMARY AND OUTLOOK 
NOC3D is a module for NEMO that serves fully 
automated reconstruction of 3D objects from images and 
most importantly from video footage created in ambient and 
mobile context and is used for learning scenarios in 
Ambient Learning Spaces (ALS). Through NOC3D, 
enriched media collectively created by students using their 
smartphones in mobile context is converted into 3D objects. 
Using Web technology, we integrate 3D models seamlessly 
with applications from ALS which are used in mobile 
contexts and in context of learning with media.  
It is our hypothesis that learning in a formal and non-
formal learning space [6][23], which is digitally enriched 
through ambient media, fosters cognitive skills and 
intelligent knowledge in a communicative environment 
[24][25]. We are going to evaluate this in the near future.  
With regard to 3D objects, we plan to evaluate their 
values in a digitally enriched learning environment. In the 
setting of our ongoing research, InfoGrid will be deployed 
 
 
Figure 5. On the left: Statue “Panther” in a botanic garden in the 
Hanseatic City of Luebeck. On the Right: The output from 175 photos is 
hardly recognizable as a panther.  
 
Figure 4. Statue called “Dorothea” by the people of the Hanseatic City 
of Luebeck. Number of images used for 3D reconstruction, from left to 
right: 62, 110, 233, 327. 
10
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

 
 
in two museums in the Hanseatic City of Luebeck, which 
are our ALS project partners, later this year and we are 
currently developing scenarios for integrating 3D objects in 
museum context. Thus, 3D objects play a vital role in our 
research project. Later this year, we plan to integrate 3D 
objects from NOC3D in our ALS Portal in order to provide 
specific features to allow post processing the automatically 
generated 3D objects from NOC3D. With the help of these 
features, the user, e.g., may remove unwanted surroundings 
around 3D objects.  
For any ALS application of the research project, among 
other features, NEMO provides persistent semantic storage 
of enriched media. Together with our project partners, two 
schools and two museums located in the Hanseatic City of 
Luebeck, the use of these applications together with NEMO 
in context of mobile and ambient learning is currently being 
evaluated. NEMO is running in multiple instances on-site. 
The ALS applications are featuring the creation, 
presentation, use and interaction with enriched media. The 
applications are developed for various platforms, in 
desktop, stationary and mobile contexts. Thus, NEMO is 
technically connecting the learner’s knowledge into an 
ambient context, bridging the learning environment and 
lived-in world (Lebenswelt) to foster sustainable learning 
and meaningful knowledge. 
ACKNOWLEDGMENT 
We develop NEMO in the research project “Ambient 
Learning Spaces” supported by the German Research 
Foundation (Deutsche Forschungsgemeinschaft, DFG).  
REFERENCES 
[1]  T. Winkler, F. Scharf, C. Hahn, and M. Herczeg, "Ambient 
Learning Spaces," in Education in a Technological World: 
Communicating Current and Emerging Research and 
Technological Efforts, pp. 56-67, 2011.  
[2]  S. Lob, J. Cassens, M. Herczeg, and J. Stoddart, "NEMO - 
The Network Environment for Multimedia Objects," ACM 
(Proceedings of the First International Conference on 
Intelligent Interactive Technologies and Multimedia, 
Allahabad, India), pp. 245-249, 2010.  
[3]  A. Lugmayr, T. Risse, B. Stockleben, K. Laurila, and J. 
Kaario, "Semantic ambient media - an introduction," 
Multimedia Tools and Applications, vol. 44, no. 3, pp. 337-
359, 2009.  
[4]  M. McLuhan, "Understanding Media: The Extensions of 
Man," McGraw-Hill, New York, 1964. 
[5]  A. Whitmore, A. Agarwal, and L. Da Xu, "The Internet of 
Things - A survey of topics and trends," Information Systems 
Frontiers, vol. 17, no. 2, pp. 261-274, 2015.  
[6]  T. Winkler, D. Bouck-Standen, M. Ide, A. Ohlei, and M. 
Herczeg, InteractiveWall 3.1 - Formal and Non-Formal 
Learning at School with Web-3.0-based Technology in Front 
of Large Multi-touch Screens (In Press), Washington DC, 
USA: AACE, 2017.  
[7]  K. Persefoni, and A. Tsinakos, "Use of Augmented Reality 
in terms of creativity in School learning," in Make2Learn 
workshop (ICEC’15), Trondheim, Norway, pp. 45-53, 2015. 
[8]  T. Winkler, S. Günther, and M. Herczeg, "Moles: Mobile 
Learning Exploration System," in Society for Information 
Technology & Teacher Education International Conference 
(SITE), Charleston, SC, USA, pp. 348-351, 2009.  
[9]  T. Berners-Lee, J. Hendler, and O. Lassila, "The Semantic 
Web," Scientific American, pp. 30-37, 2001.  
[10] F. Nack, "The future in digital media computing is meta," 
IEEE MultiMedia, vol. 11, no. 2, pp. 10-13, 2004.  
[11] C. Bizer, T. Heath, and T. Berners-Lee, "Linked Data - The 
Story So Far," International Journal of Semantic Web 
Information Systems, vol. 5, no. 3, pp. 1-22, 2009.  
[12] S. S. Kusumawardani, L. E. Nugroho, A. Susanto, A. 
Kumara, H. S. Wasisto, and U. Cortés, "Ontology 
Development of Semantic E-Learning for Final Project 
Course," Advanced Science Letters, vol. 21, no. 1, pp. 46-51, 
2015.  
[13] M. Masud, "Collaborative e-learning systems using semantic 
data interoperability," Computers in Human Behavior, vol. 
61, pp. 127-135, 2016.  
[14] P. Bouquet and A. Molinari, "A New Approach to the Use 
of Semantic Technologies in E-Learning Platforms," 
International Journal of Advanced Corporate Learning, vol. 
9, no. 2, pp. 5-12, 2016.  
[15] M. Dougiamas, and P. Taylor, "Moodle: Using Learning 
Communities to Create an Open Source Course Management 
System," World Conference on Educational Multimedia, 
Hypermedia and Telecommunications (EDMEDIA), pp. 
171-178, 2003.  
[16] P. Oliveira, and P. Gomes, "Instance-based Probabilistic 
Reasoning in the Semantic Web," in Proceedings of the 18th 
International Conference on World Wide Web. ACM, New 
York, pp. 1067-1068, 2009.  
[17] D. Bouck-Standen, M. Schwandt, T. Winkler, and M. 
Herczeg, "ELBlocks - An Interactive Semantic Learning 
Platform for Tangibles," Mensch und Computer 2016 -
Workshopband, Regensburg, 2016.  
[18] C. Wu, "VisualSFM : A Visual Structure from Motion 
System," 2011. [Online]. Available: http://ccwu.me/vsfm/. 
[Accessed 20 May 2017]. 
[19]Center for Machine Perception Multi-view Reconstruction 
Software (CMPMVS). [Online]. [Accessed 20 May 2017].
Available: http://cmp.felk.cvut.cz/ 
[20] M. Jancosek, and T. Pajdla, Multi-View Reconstruction 
Preserving Weakly-Supported Surfaces, CVPR 2011, IEEE 
Conference on Computer Vision and Pattern Recognition 
2011, pp. 3121-3128, 2011.  
[21] Y. Furukawa, and J. Ponce, "Accurate, Dense, and Robust 
Multi-View Stereopsis," IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 32, no. 8, pp. 1362-
1376, 2010.  
[22]P. Cignoni, M. Callieri, M. Corsini, M. Dellepiane, F. 
Ganovelli, and G. Ranzuglia, "MeshLab: an Open-Source 
Mesh Processing Tool", Eurographics Italian Chapter 
Conference, pp. 129-136, 2008. 
[23] T. Winkler, and M. Herczeg, "The Mobile Learning 
Exploration System (MoLES) in Semantically Modeled 
Ambient Learning Spaces," IDC ’13 Proceedings of the 12th 
International Conference on Interaction Design and 
Children, pp. 348-351, 2013.  
[24] C.-C. Huang, T.-K. Yeh, T.-Y. Li, and C.-Y. Chang, "The 
Idea Storming Cube: Evaluating the Effects of Using Game 
and Computer Agent to Support Divergent Thinking," 
Educational Technology & Society, vol. 13, no. 4, pp. 180-
191, 2010.  
[25] M. D. Dickey, Engaging by design: How engagement 
strategies in popular computer and video games can inform 
instructional design, vol. 53, Kluwer Academic Publishers, 
2005, pp. 67-83. 
11
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-601-9
AMBIENT 2017 : The Seventh International Conference on Ambient Computing, Applications, Services and Technologies

