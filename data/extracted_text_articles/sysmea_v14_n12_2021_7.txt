69
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
An Interactive AR-Based Virtual Try-on System Using Personalized Avatars: 
Augmented Walking and Social Fitme 
 
Yuhan Liu1, Yuzhao Liu1, Shihui Xu1, Kelvin Cheng2, Soh Masuko2 and Jiro Tanaka1 
1
Waseda University, Kitakyushu, Japan 
2 Rakuten Institute of Technology, Rakuten, Inc., Tokyo, Japan 
e-mail: liuyuhan-op@akane.waseda.jp, liuyuzhao131@akane.waseda.jp, shxu@toki.waseda.jp,  
kelvin.cheng@rakuten.com, so.masuko@rakuten.com, jiro@aoni.waseda.jp 
 
 
Abstract — E-commerce websites offer the convenience to 
consumers to purchase clothes online. However, they have 
difficulties imagining how they will look like. To address this 
problem, we propose a holographic 3D virtual try-on system 
that provides users a novel experience where they can view 
garments fitted onto their own personalized virtual body. The 
garment models are generated from garment images obtained 
from online shopping websites. Users can animate their dressed 
virtual body in a real-life scene in augmented reality. We also 
propose Social Fitme, which provides multiple users an intuitive 
sharing experience with others. Users can try on clothes with 
their friends and communicate with each other, thereby giving 
them the opportunity to make more confident decisions. We 
conducted a user study to compare our proposed system with an 
image-only shopping system and validate its effectiveness. We 
found that Social Fitme can greatly improve the shopping 
pleasure of users and provide them a more engaging and 
effective shopping experience. Interactions between users can 
help them explore new styles, enhance their relationships, and 
strengthen their social connections. 
 
Keywords — augmented reality; virtual try-on; personalized 
avatar; virtual fitting; garment modeling; 
social interaction; 
shared experience; augmented walking.  
I.  INTRODUCTION 
With the continuous development of the e-commerce 
technology, the number of consumers purchasing clothes 
online is increasing. Consumers usually desire to try on 
garments to assess if the clothes are suitable before 
purchasing. However, when shopping online, they cannot 
try them on. Consequently, they may worry how well the 
clothes will fit on their own body. Furthermore, it is difficult 
for them to imagine how they will look like with various 
postures (e.g., standing, walking and posing) or in different 
settings. 
To address these problems, we have proposed a 3D virtual 
try-on (VTO) system using personalized models [1] (Figure 
1). 
(a) We generate virtual models of users based on their own 
body and face information. 
(b) We gather some garment information and achieve 3D 
garment visualization using Cloth-Weaver [2].  
Figure 1. Our system allows users to view virtual garment fitted onto personalized body models and animate them in real-life scene 
 
 

70
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
(c) We customize the garment model for each user and 
match it to their personalized virtual models.  
(d) We enable users to view their own personalized body 
model fitted with virtual garment.  
(e) We enable these models be visualized in a real-life scene 
together with animated motions.  
 
To determine the user’s acceptability, we conducted a 
user study to evaluate the value and convenience of our system. 
We also propose Social Fitme, which allows multiple users to 
virtually fit garments together (Figure 2). Our system reduces 
the gap between offline shopping and online shopping. It 
enhances the social experience of online shopping by allowing 
users to experience the pleasure of physical shopping with 
friends, choose clothes for each other, and get quick feedback 
in real-time. The aim of the system is to improve the user 
experience of online shopping by enabling social interaction 
between users while engaging with a more personalized VTO 
system. 
We introduce two advanced features of online shopping in 
our proposed VTO system as the main contributions of this 
study: 
1) 
A fully personalized VTO system that enables users 
to view virtual garments interactively and immersively in 
360° as well as check their garment on a personalized virtual 
body augmented with human-like motion in the real-world. 
Users can try on clothes directly and quickly view the 
appearance of their dressed body. 
2) 
A socially interactive VTO system that supports an 
intuitive sharing experience for users. Users can experience 
social interactions during the VTO process, such as sharing 
their dynamic dressed virtual body with each other. Social 
Fitme strengthens the social connections between users when 
shopping online. Interactions between users can help them 
make more confident decisions and explore new clothing 
styles. 
The rest of the paper is organized as follows. In Section Ⅱ, 
a brief review of previous research on VTO, garment 
modeling and virtual avatar is presented. In Section Ⅲ, we 
describe the system design, including human model 
personalization, garment model generation and 3D VTO 
system. In Section Ⅳ, Social Fitme, which is a socially 
interactive VTO system is described. In Section Ⅴ , we 
present our evaluation result. In Section Ⅵ, conclusion and 
future works are described. 
 
II. 
RELATED WORK 
In this section, we will describe the related work. Related 
work on VTO, Garment modeling, Virtual avatar, 
Personalization of VTOs, and Virtual avatar in social 
augmentation is described in this order. 
A. VTO 
Earlier works on VTO are mostly conducted in 
computer graphics [3][4][5]. Previous works focused on 
two types of VTO: 2D overlay VTO and 3D VTO. 
 
2D overlay VTO: 
Hilsmann et al. [6] retextured garment overlay for real-
time visualization of garments in a virtual mirror 
environment. Yamada et al. [7] proposed a method of 
reshaping the garment image based on human body shapes 
to make fitting more realistic. However, similar to many 
other retexturing approaches, it operates only in 2D without 
using 3D information in any way, which does not allow 
users to view their virtual self from arbitrary viewpoints. 
 
3D VTO:  
3D garment models perform precise garment simulation 
rather than just 2D overlays. Protopsaltou et al. [8] created 
a virtual dressing room, where customers can view garments 
fitted onto their virtual body. Li et al. [9] proposed a multi-
part 3D garment model reconstruction method to generate 
virtual garments for virtual fitting on virtual avatars. 
Recently, VTO has been combined with augmented 
reality (AR) or virtual reality (VR) technologies to provide 
consumers a more realistic try-on experience. Consumers 
can get a better sense of how they will look like when 
wearing the products. Several fashion firms, including Uniqlo 
Figure 2. Social Fitme, an AR-based try-on system for multiple users to share their fitting experience together. Users can virtually try- on 
clothes using a mobile device and view their personalized virtual avatar in motion in the real world. They can speak to each other and give 
fashion advice in real-time when using the system 
 

71
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
and Gap, have utilized the AR technology in the form of a 
mobile applications [10]. 
Using the VR technology, 
consumers can feel like they are physically in a virtual fitting 
room. Several fashion retailers have provided this kind of 
shopping experience, such as Alibaba and Dior. 
 
B. Garment modeling 
Unlike 2D images, a 3D garment model can be used to 
perform precise garment simulation. Most garment modeling 
research focuses on 3D garments for a virtual character. Some 
garment-retargeting methods transform garment designs from 
one character to another. For example, Pons-Moll et al. 
introduced a system using a multi-part 3D model of clothed 
bodies for clothing extraction and retargeting the clothing to 
new body shapes [11]. Pattern-based methods simulate the 
garment creation process in real life, while garment modeling 
tools, such as Marvelous Designer [12], offer 
garment 
modeling and editing of pattern design. Pattern-based 
methods require professional knowledge of garment design 
and are difficult for non-experts. To address the problem of 
digitizing garments, Zhou et al. created virtual garments 
from a single image [13]. Chen et al. captured real garments 
using a depth camera and built a coarse shape from its raw 
RGBD sequence using the RGB color information and depth 
information [14]. 
 
C. Virtual avatar 
Most VTO systems provide a virtual fitting experience 
on a default virtual avatar, rather than one generated from 
users’ own body [15]. The default virtual avatar can be 
modified by users based on individual preferences and can 
be personalized by uploading their facial images [16][17]. 
This type of virtual avatar cannot reflect the true body shape 
of consumers. 
The absence of “true fit” may disappoint customers when 
shopping online. For our proposed system, we create virtual a 
personalized model for each user, which can reflect their body 
shape and facial appearance. This will make their try-on 
experience more accurate and engaging, thus increasing their 
confidence when making purchasing decisions on garments 
online. 
D. Personalization of VTOs 
Depending on the avatar's level of personalization, the 
avatar representing the user may or may not provide a real 
sense of self. According to the avatar's similarity to the user, 
virtual try-on systems can be divided into two levels [18]:  
 
1) Non-personalized VTO:  
Some VTO experiences are based on a default virtual 
avatar, not generated from the user’s own body [19][20]. The 
lack of precision in describing users and products reduces 
VTO experience of users.  
2) Personalized VTO: 
Personalized VTO enables a more realistic user 
experience where the virtual avatars can mirror their actual 
looks and fit the clothes on the virtual self [21][22][23]. The 
virtual avatar is customized with personal features (face, 
height, weight, and body shape). Kim et al. researched the 
perceived usefulness, enjoyment, and ease of use of the 
personalized VTO [20]; Merle et al. argued that the 
personalized VTO can lead to more positive consumer 
perceptions than the non-personalized VTO and provide a 
higher self-congruity with the virtual model [18]. 
 
E. Virtual avatar in social augmentation 
 Early research has shown that a virtual avatar represented 
by a graphical persona in a virtual social environment can 
create an illusion for users that they are in the environment 
and co-present with their companions [24][25][26]. Roth et al. 
found that virtual avatars that can perform daily social 
interactions can increase social presence in a multi-user 
environment and enhance user experience [27]. For co-
located social experience, Lankes et al. investigated the 
effects of avatars and verbal communication on co-presence 
in a cooperative game [28]. 
 
In summary, we found that there is a lack of research 
exploring the dynamic VTO experience with personalized 
motions. In addition, the social feature is an important factor 
of dress fitting that has been ignored in previous VTO systems. 
Our proposed AR-based try-on system provides multiple users 
an intuitive sharing experience, allowing them to view their 
dressed body with personalized human-like motions 
augmented in the real world and share their outfits with others. 
 
III. 3D VTO 
Our 3D VTO system involves human model personalization, 
garment model generation, and 3D VTO. 
Figure 3 presents an overview of our proposed system. This 
system uses three elements as input: a single face image 
with a full-frontal face, a short video of the user’s full body, 
and a 2D garment image from online shopping websites. The 
procedure can be described as follows: 
 
 
Figure 3. System Overview 

72
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
(a) Mapping the 2D garment image into the 3D garment 
model templates and generating the 3D garment model 
based on online images.  
(b) Generating the 3D human model based on the face 
image and recorded video. 
(c) Matching the 3D garment model to the human model.  
(d) Users choose different clothes to try on. Users can 
change the pose in VR fitting room. They can also see their 
augmented walking in AR environment.  
 
A. Human model personalization 
Owing to the lack of physical fitting in online shopping, a 
gap between the actual and perceived body size can exist, 
which may make it difficult for consumers to examine the true 
fit on their own body and influence their purchase selection 
while shopping online. Therefore, the virtual human body 
should have an appropriate 3D representation corresponding to 
the real user’s human body shape and facial features. 
This will give a better representation of the user and allows 
for a more accurate clothes fitting, as well as for virtual human 
body animation. We create human body models based on 
Alldieck’s study [29] and generate face models based on 
Deng’s method [30]. Moreover, a hair model library is 
prepared, and the most similar hair model is matched to the 
face model we generated. 
 
B. Garment model generation 
To 
provide 
users 
with 
better 
garment 
product 
visualization, we allow users to view garments from various 
angles and directions when users are shopping online. Our 
approach uses garment image information from existing 
shopping websites (e.g., H&M [31] and Zara [32]) to create 
a virtual garment library. Textures are extracted from the 
garment image and mapped onto the 3D garment model. The 
final 3D garment is shown in Figure 4. We mainly focus on 
these two parts: garment model templates used in our system 
and 3D modeling and texturing approaches. 
 
3D garment model templates 
Garments are created using the traditional 2D pattern 
approach. We build several 3D templates of virtual garment 
models for the personalized human model using Cloth 
Weaver, which is a Blender template library. It allows 
simulating the methods of traditional garment designs. The 
2D pattern is discretized into a triangular mesh. Next, we 
design and modify the 2D pattern, and then use the reference 
line to automatically fit the flat pattern to the corresponding 
part of the body (Figure 5). These are used as the basis for 
creating a variety of garment models (Figure 6). We 
simulated several types of clothing for female and male 
bodies. For females, we prepared them with long sleeves, T-
shirt, long pants, dress and skirt for fitting. For males, we 
prepared them with T-shirts, long sleeves and half pants for 
fitting. 
 
Texture mapping 
We collected garment images from existing shopping 
websites (H&M, ZARA, etc.) and mapped these clothes 
images to generated 3D garment model templates (Figure 7). 
We segmented different parts of the garment from a single 
garment image. The segmented clothes can be divided into 
three main parts: left sleeves, right sleeves, and the front of 
clothes. The 3D mesh of a generated garment template can be 
extended into a 2D reference mesh in 3ds Max [33]. To map 
the web garment image into a 3D virtual garment template, we 
Figure 4. Generate 3D garment model based on the information from 
shopping website 
Figure 5. 2D patterns creation and positioning around generic body 
  
 
Figure 6. Some 3D garment templates provided for users 
 
 
Figure 7. Mapping Web garment image to generated 3D garment 
templates 

73
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
map the different segmentation parts from the garment 
image to its corresponding parts on the garment template. 
 In this way, we can generate a  3D garment model 
with texture. The garment can be customized in various ways 
to match the desired design. The most obvious change is the 
customization of appearance and color, which is achieved by 
modifying the texture of the cloth. Therefore, we collected 
garment images from online shopping websites as textures 
and created a garment model library for users (Figure 8). 
 
C.  3D VTO 
We gathered various garment information from online 
websites to enhance the online shopping experience of 
users. Our system was developed using Unity3D [34] on 
Windows 10 and we deployed our system on Android 
smartphones. The 3D VTO system consists of two parts: 
virtual fitting and augmented walking. 
 
Virtual fitting 
Virtual reality relies on an entirely digital environment 
that can provide an immersive and interactive shopping 
experience for users. We prepared a variety of fitting scenes 
for users, such as on the street, in the office and at the 
supermarket. Users can view the virtual garment based on the 
different virtual scenes, giving them an idea of how they will 
look like for various occasions or purposes (Figure 9).  
 
Augmented walking 
Normally, when users shop at physical (offline) stores, 
they often check the attributes of clothes through various 
motions, such as twisting the body or raising the arm to help 
confirm the suitability of the clothes. However, when 
shopping online, users cannot visualize the details of the 
garment. Compared to the offline try-on experience, the 
traditional online shopping purchasing environment lacks the 
capability for users to try-on garments on their own body and 
check whether the clothes fit on them under various postures. 
Therefore, we propose a dynamically interactive method that 
allows users to animate their dressed human body in 360°and 
enables them to view their virtual body walking in the real-life 
scene.  
The implementation of the augmented walking framework 
aims to animate the personalized avatar of users in the real 
world. Figure 10 depicts the workflow of animating the 
personalized virtual avatar in the real world, which can be 
described as follows. 
 
1) 
Personalized virtual avatar. We integrate the virtual 
human model and clothes model in 3ds Max and export 
the virtual avatar as .fbx file. 
2) 
Skeleton binding and Skinning. We upload the 
personalized virtual avatar to Mixamo [35], which is a 
web-based service for creating 3D animation of human 
models. We bind the skeleton to the virtual avatar and 
skin it using Mixamo. 
3) 
Animate virtual avatar. To attach the animation to a 
personalized avatar, we use the animator controller in 
Unity [36] to control the virtual avatar and perform 
various animation. 
4) 
Augmented walking in the real world. We realize the 
augmented walking using Vuforia Augmented Reality 
SDK [37]. 
 
We fitted our generated human model with garment 
models and created walking and posing animations, as 
illustrated in Figure 11. Using Mixamo, the motions we 
generated are very lifelike actions, such as waving/shaking 
hands, walking, sitting, and turning around. 
 
Figure 9. Fitting scenes 
Figure 8. Garment model library for female and male 
 
Figure 10. Implementation of augmented walking 
 
Figure 11. Postures of personalized human model 
 

74
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
IV. SOCIAL FITME: SHARED VTO EXPERIENCE 
AR applications can enable social interactions among 
users. They can interact with the virtual content while 
engaging in normal communication in the real world. So far, 
there is a lack of research on applying AR for VTO. 
Social Fitme is an AR mobile application that supports 
interactive social sharing of VTO experience for multiple 
online shopping users (Figure 12). Based on online shopping 
websites, 3D garments are generated, which provide users a 
more realistic try-on. 
 Users can first create a fitting room by scanning the 
ground (a, b), and animate their virtual avatars in the real 
environment (c). Other co-located users can join in the same 
fitting room and can be represented as virtual avatars located 
in the same position and orientation in the same physical 
environment (d). Users can interact with the virtual avatar, 
virtually try garments on, communicate with each other and 
give fashion advice (e). 
To provide users a more engaging VTO experience, Social 
Fitme allows users to socially share their intuitive VTO 
experience with others, enabling them to get quick feedback 
as well. Users can both try on clothes on their own body or on 
other user’s body. They can also help each other make 
decisions and find the best match for each other (Figure 13). 
Our system was developed using Unity3D on Windows 
10 
and 
deployed 
on 
Android 
smartphones. 
The 
implementation of our system consists of the following three 
parts: 
 
 
Human 
model 
personalization. 
We 
personalized 
theappearance of users based on their face image and full- 
body images. The 3D face model was generated using 3D 
avatar SDK [38], whereas the body model was built by 
3DLook [39]. They were then combined into a 3D human 
model. 
 
Motion capture. To gather individual movements of users, 
we used Microsoft Kinect V2 depth sensor [40] to record 
postures and user movements and create their own animation 
library for our system. To convert the captured motion 
captured data into animation, we used a Unity plugin, 
Cinema-Mocap [41], which is a marker-less motion capture 
solution for Unity to create customized animations for users. 
As the movement captured by Kinect V2 depth sensor is 
somewhat jittery, we edited and smoothed the animation 
frame-by-frame using Maya software [42], which is a 3D 
computer animation, modeling, simulation, and rendering 
program. 
 
Shared VTO experience. To share the VTO experience with 
co-located users, we used ARCloud Anchors API from Google. 
ARCore [43] connects to its ARCore cloud anchor service to 
host and resolve anchors. The hosting and resolution of an 
anchor can be deployed on multiple devices through an 
effective network connection. 
 
 
 
 
 
Figure 13. Our system provides an intuitive sharing virtual try-on experience for users 
 
Figure 12. The workflow of Social Fitme 
 
 

75
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
TABLE I. QUSTIONNAIRE AND MEASRUEMENT ITEMS 
Items 
Statements 
Enjoyment 
a. Using the system, shopping experience was 
enjoyable for me. 
Convenience 
b. I can get a sense of how the outfit might look for 
the various occasions. 
c. I can get a sense of how I look wearing these 
clothes. 
Augmented 
Walking 
d. Seeing a model of me walking in the real-world 
enhanced my shopping experience. 
e. Having a model walking in a real environment 
helps me understand more about the appearance of 
the clothes. 
User Behavior 
f. I want to use this system when I buy some 
clothes online in the future. 
 
 
V. 
EVALUATION 
We carried out two user studies. i.e., user study 1 and user 
study 2, to evaluate our system. The objective of user study 1 
is to assess whether our 3D VTO system can enhance the 
online shopping experience of users. The objective of user 
study 2 is to evaluate the effectiveness of the system and 
interactions designed to support the sharing 
of VTO 
experience in AR. 
 
A. User study 1 
 
1) Participants 
A total of 10 college students participated in both 
condition 1 (VTO condition) and condition 2 (image-only 
condition). College students aged 18–30 years are usually 
targeted by AR/VR applications, as they are more likely to 
try new technologies and they are proactive in online 
shopping for fashion products. Hence, we invited N=10 
participants (7 males and 3 females) with an average age of 
22.5 years to complete our evaluation. 
 
2) Evaluation design 
We conducted an initial experiment to evaluate our 
system. The objective was to assess whether our 3D VTO 
system could enhance the online shopping experience of 
users, thereby helping them make better purchasing decisions. 
To investigate the users’ attitudes toward the typical online 
shopping and 3D VTO with augmented walking, we 
conducted an experimental study with the following two 
conditions.  
 
a) VTO condition: simulation of shopping experience using 
our 3D VTO system. 
b) Image-only condition: simulation of typical online 
shopping experience using only images of garments online. 
 
We hypothesized that the former condition would lead to a 
higher rating than the latter. 
 
We personalized the human model of each participant 
based on their 2D face image and 360° body videos. Each 
participant simulated the shopping experience with two 
different conditions. The order of the conditions was 
randomized. After each task, the participants were asked to 
rate their experience (from 1 “strongly disagree” to 7 “strongly 
agree”) in our questionnaire, indicated on a 7-point Likert 
scale. At the end of the experiment, we interviewed the 
participants to gather their preferences and open-ended 
feedback. 
We measured enjoyment, convenience, and user behavior 
for the two conditions. We also analyzed whether the 
augmented motion in the real-life scene enhances the users’ 
shopping experience. The questionnaire and measurement 
items are presented in Table I.  
 
3) Results 
We separated the result into two sections: analysis of the 
rating from questionnaires and thematic analysis of the 
participants’ comments. 
We analyzed the result in terms of user enjoyment, 
convenience, augmented walking, and user behavior. 
 
Enjoyment. As Figure 14 shows, we found a significant 
effect on the participants’ shopping enjoyment. A repeated 
measures t-test revealed a statistically significant difference 
between the various conditions (p<0.01). The participants 
rated the enjoyment significantly higher in the VTO 
condition. 
Convenience. We analyzed the user convenience through the 
two statements below:  
A. “I can get a sense of how the outfit may look for various 
occasions.” We found that the participants rated the VTO 
(p<0.01) significantly higher than the other condition (Figure 
15).  
B. “I can get a sense of how I look wearing the clothes.” We 
also found that participants rated the virtual try-on condition 
(p<0.01) significantly higher, meaning that it gave users a 
better feeling for how these clothes might look like on their 
body (Figure 16). 
 
 
 
 
Figure 14. Participants rated their Experiences more 
enjoyable in the virtual try-on condition 

76
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
 
Augmented walking. To understand whether the 3D VTO 
system within the AR scene enhances the user experience, we 
prepared two statements: 
 
a. 
“Seeing a model of myself walking in the real-world 
enhanced my shopping experience.” Figure 17 
summarizes the of participants’ opinions of VTO 
condition. 
 
b. “Having a model walking in a real environment helps me 
understand more about the appearance of the clothes.” 
Figure 18 summarizes the participants’ opinions of the 
VTO condition. 
 
In summary, all participants have the same opinion that 
augmented walking can enhance their shopping experience. 
Of the 10 participants, 9 rated that the virtual model walking 
in the real environment helps them understand more about the 
appearance of the clothes. One of the main reasons given is 
that the real environment is very realistic, which helps them to 
view the appearance of the garment model. Moreover, the 
virtual models walking in the real-life scene are very 
interesting and can improve the participants’ enjoyment of the 
online shopping process. At the same time, augmented 
walking can also provide a better 3D visualization for users.  
The dynamic fitting display can show the shape of the 
clothes when they are in motion and increases the number of 
clothes attributes that can be observed. 
 
User behavior. All participants preferred the VTO condition 
for both enjoyment and convenience. We also analyzed the 
user preference on whether they want to use the VTO system 
in the future or not. The results indicated that 9 out of 10 
participants wanted to use this system in the future (Figure 
19). 
 
4) Qualitative results 
At the end of the experiment, open-ended feedback was 
sought from the participants, and a thematic analysis was 
performed on their responses and their impression of using 
our 3D VTO system. 
Most participants thought that the virtual avatar with 
augmented walking in the real world offers them a sense of 
wearing clothes on their own body, which can provide them 
with a better understanding of the detail of the clothes. 
Moreover, augmented walking allows them to visualize their 
personalized model in the real world, increasing their 
shopping enjoyment. P6 mentioned that the augmented 
walking makes them feel like they are looking into a mirror. 
P7 said that augmented walking in the real world can help 
Figure 17. All participants agree that seeing own model in the real-
world enhanced their shopping experience. 9 out of 10 participants 
strongly agree with it 
 
Figure 16. Participants rated that virtual try-on condition gave users 
a better feel for how these clothes look like on their body 
Figure 19. Most participants want to use this system when they buy 
some clothes online in future 
 
Figure 15. Participants rated their Experiences more 
enjoyable in the virtual try-on condition 
Figure 18. Most participants agree that the model walking in the real 
environment helps them understand more about the appearance of the 
clothes 

77
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
them observe more details of clothes. 
Most participants thought that our system is interesting. 
Our system can enhance their experience and narrow their 
selections when shopping online. For instance, P1 mentioned, 
"Shopping online is difficult because the model’s body shape 
is pretty, while people in real life don’t have such a perfect 
body. This system shows how the clothes look like on my 
body in the real world, which gives me confidence when 
buying clothes.” Similar comments were received from P3 
and P4. 
Furthermore, the 3D VTO system provides users outfit 
ideas and more clothing information to users. P3 thinks that 
the 3D virtual system provides various virtual scenes to help 
users in selecting clothes, especially for special occasions. P6 
mentioned that the 3D garment model allows him to see 
himself wearing clothes in 360 °  and obtain additional 
clothing information than just looking in a mirror. P7 said that 
the virtual model walking in the real world may help them in 
checking how they will look like in the real wearing 
conditions. 
We also received comments about future improvement. 
P3 suggested that the material of clothes could be improved to 
look more like a real fabric, and P9 thought that it would be 
better to use motion capture to simulate real movements of 
users moving in the real world. The free comments from 
participants are summarized in Table Ⅱ. 
 
B. User study 2 
 
1) Participants 
We recruited 12 participants (6 females and 6 males) aged 
between 20–25 years old. We selected participants from this 
demographic because they are usually the target users of 
AR/VR applications, since they are more likely to try new 
technologies and are proactive in online shopping for 
fashion products. We gathered their relationship with their 
partner by the inclusion of community in self-scale (IOS) [44]. 
TABLE Ⅱ. SUMMARY OF FREE COMMENT 
Keyword 
Conclusion and Comments 
Augmented 
walking 
Judging of fitting: Wearing clothes doing some 
activities in the real world provides users with better 
understanding of the detail of clothes, which allows 
to better judge of fitting. 
Humanoid motion: Using motion capture 
technology to capture user’s movement may offer 
users a better sense of “real me”. 
Garment 
model 
Information visualization: The 3D virtual try-on 
system gives users outfit ideas and provides more 
clothing information to users (muti-direction and 
muti-angle). 
Realistic garment: Garment material can be more 
like real fabric. 
Shopping 
experience 
The 3D virtual try-on system can narrow users’ 
selections of clothes and increase their purchase 
confidence. 
Increases the enjoyment of shopping experience. 
 
 
2) Evaluation design 
Our study used a within-subject design in which two 
participants used the VTO system with two different modes of 
independent and co-located AR-based VTO in random order. 
The two conditions are as follows (Figure 20): 
1. Independent AR-based VTO. Participants place their 
virtual avatar separately in their own physical environment 
and view their own personalized virtual body with garment 
models and posing or walking in the real world. 
2. Co-located AR-based VTO. Participants can share their 
VTO experience with their partners at the same time and  
in the same place. They can communicate verbally and 
visually and give advice on each other’s fitting effects. 
 
We separated the participants into six pairs, where people 
of the same sex are in the same group. We asked each pair of 
participants to virtually try the clothes on and simulate the 
shopping experience using the independent AR-based try-on 
condition and the co-located AR-based try-on condition. 
Afterward, the participants were asked to complete a 7- Likert 
scale questionnaire to rate their shopping experience. At the 
end of the experiment, we interviewed the participants and 
gathered some open-ended feedback. 
 
3) Results 
We analyzed the result in terms of body similarity, 
enjoyment, usefulness, closeness, and user behavior. Paired t-
test was performed using SPSS [45] to assess whether there 
were statistically significant differences between the means of 
the two conditions (Figure 21). 
 
Body similarity. We analyzed the user body similarity 
through the statement, “I feel that the virtual body I saw was 
my own body.” Although there is no significant difference 
found in body similarity (p = 0.59) between the two conditions, 
we found that their friends’ evaluations of their virtual bodies 
often affected their perception of their own virtual avatar. 
Several participants mentioned that when they heard positive 
feedback from friends, for example, “This virtual avatar really 
looks like you,” they felt that the virtual body became more 
similar to themselves. On the other hand, when participants 
heard negative comments from friends, they reduced the 
ratings of their virtual avatar. 
 
Enjoyment. We analyzed user enjoyment through the 
statement, “This VTO system was enjoyable to use.” We 
found that the participants rated the co-located AR condition 
(p < 0.05) significantly higher, meaning that it can provide 
users with a more enjoyable experience. The participants 
tended to spend more time and were more engaged in 
Figure 20. The experiment conditions 
 

78
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
shopping together with their partners in the co-located AR-
based try-on condition. Compared with the independent VTO, 
they paid more attention to help friends choose clothes and 
give their personal opinions. P11 mentioned, “It’s fun to try 
on clothes for my partner. I feel more engaged when we can 
talk to each other and try-on together; it is just like we are 
shopping together.” 
 
Effectiveness. We analyzed the system’s effectiveness 
through the statement, “Using this VTO system would 
enhance my effectiveness in shopping.” We found a 
significant effect on users’ shopping effectiveness (p < 0.05). 
Most participants mentioned that using the co-located AR 
system allows them to receive recommendations from others. 
For example, P2 commented, “When I shared my VTO 
experience to my partner, I could get more helpful advice from 
my partner.” 
Several participants thought that comments from others can 
help them explore a completely new clothing style. P6 
mentioned, “When I shop online alone, the styles of clothes 
that I choose are very similar to what I already have. When 
using this system, friends will often give me suggestions, 
encouraging me to try on new styles.” 
Many participants said that our system offers an intuitive 
try-on effect, which can help save time when shopping. For 
instance, P10 stated, “Friends can quickly help us eliminate 
clothes that are not suitable, which is a great way to save time 
on shopping.”  
Compared to just sharing links or outfit photos with friends, 
sharing an intuitive fitting experience with others can obtain a 
more accurate recommendation. P2 remarked, “When I shop 
online, I can only share links and images of clothes, and my 
friends can only give advice based on their imagination. It is 
not helpful for me.” 
 
User behavior. We analyzed the users’ attitude toward our 
shopping technology through the statement, “I want to use this 
system when I buy some clothes online in the future.” We 
found that the participants rated the co-located AR condition 
(p < 0.01) significantly higher than the independent AR 
condition. We also asked the participants’ preferences for 
each condition at the end of the study. Consequently, 11 
participants preferred the co-located AR-based try-on 
condition. Only one participant favored the AR-based 
independent try-on because he was worried that sharing his 
body with others would reveal his privacy. 
 
Happiness and closeness with others. We analyzed the users’ 
happiness when using the co-located AR system through the 
statement, “I feel happy when I am shopping with my partner.” 
The participants strongly agreed that they feel happy (M = 
6.58, SD = 0.64) when shopping with their partners. Most 
participants reported feeling happy and closer with their 
partners after using our system. P1 mentioned, “It allows me 
to experience the pleasure of shopping with friends.” 
Furthermore, P12 noted, “Seeing our avatars doing real-life 
motions in the real world, similar to this kind of game-like try-
on experience, makes me very happy.” 
We analyzed the closeness between participants by the 
inclusion of community in self-scale (IOS). The results 
showed that closeness with their partners increased from an 
average IOS score of 4.66 (SD = 1.15) to 5.08 (SD = 1.24) 
after the experiment (p < 0.05). Some participants thought that 
using our system can enhance their relationship and strengthen 
their social connections. P2 stated, “It’s fun to try on clothes 
in the same space with my friend’s avatars. We can talk to 
each other, see each other’s avatars, and then interact with 
each other. I think our relationship has become closer.”  
 
We summarized the main results and presented 
explanatory analysis based on our observation during the 
study as well as findings from the interviews. The results 
indicated that Social Fitme can greatly improve the shopping 
pleasure of users and provide them a more engaging and 
effective shopping experience. Our system provides users an 
intuitive sharing VTO experience. Comments from others can 
not only help users make confident decisions, but also allows 
them to explore a completely new clothing style. Users can 
enhance their relationship and strengthen their social 
connection by using our system. We summarized the results 
in Table Ⅲ. 
 
 
 
Figure 21. Perceived levels of body similarity, enjoyment, usefulness, confidence in fit problem, attitude toward shopping technology, and 
closeness. Note: *p < 0.05, **p < 0.01 
 
 

79
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
 
TABLE Ⅲ. SUMMARY OF RESULT 
Theme 
Conclusion 
Effectiveness 
Helpful comments: comments from others 
can help users make a more confident 
decision.  
Diversified styles:users can explore a 
completely new style based on advice given 
by others.  
Intuitive sharing experience: 
personalized avatars in AR provide a more 
intuitive way to share their outfits with 
others when online shopping, which can 
offer users a better judge of fit. 
Filter mismatched selection: users can 
eliminate the unsuitable selections quickly. 
Detailed garment visualization: users can 
view garments from multiple angles and in 
more details. 
Happiness 
Closeness with 
others 
Enhance relationship: using Social Fitme 
strengthen social connection and make 
users feel closer together. 
Game-like shopping experience: users feel 
happier when simulate try-on experience 
with others. 
Enjoyment 
 
More engaged: users are more enjoyable and 
engaged in sharing outfits with others, they 
tend to ask for ot he r’s recomme ndat io n s and 
make a more confident choice. 
 
Ⅵ CONCLUSION AND FUTURE WORK 
In this paper, we presented a 3D VTO system to help 
consumers obtain a better sense of how they will look when 
purchasing clothes online. To allow users to assess how well 
the displayed products match their actual body, we 
personalized users’ own virtual avatars corresponding to real 
users’ human body shape and face features. Based on online 
garment images, we generated 3D virtual garments to 
personalize the human body. Users can fit their 3D user 
models with a selection of virtual garments, and view the 
animated body in the real-life scene, as well as various virtual 
scenes, to get a better sense of the dynamic effects of the 
clothes. An initial evaluation reveals that the VTO system is 
more enjoyable and convenient than that of using images only.  
Augmented walking provides an interactive dynamic VTO 
experience for users, which gives them better understanding 
of the details of clothes. The virtual avatar wearing clothes in 
the real world can provide a better sense of “true fit,” which 
helps users judge their fitting more effectively. Furthermore, 
most of the participants prefer using this system for online 
shopping in the future. They think that this system can 
increase their purchase confidence and solve the fit problem 
when shopping online. 
However, our system still has certain limitations that can be 
improved. In the future, we plan to enhance our clothing 
animations and cloth simulation methods to provide users with 
a more realistic VTO effect. Motion capture can also be used 
to better simulate user’s walking motion, to provide a more 
realistic and interactive fitting experience. 
We also presented Social Fitme, a platform and concept for 
co-located social try-on system that supports personalized 
interactions through smartphones. The system implements 
interactive technology combined with AR and cloud 
technologies and provides users with a novel shopping 
experience. We conducted a user study to explore the 
effectiveness of our system and interactions designed to 
support the sharing of VTO experience in AR. We found some 
possibilities and advantages of multi-user online social 
shopping: 
•Try clothes on users’ friends directly. Rather than just 
imagine how the clothes look like on their friend’s body, users 
can try clothes on the personalized avatar of their friend 
directly and view the effect on the dressed virtual body in the 
real-life scene quickly. 
•Explore a completely new style of clothing. Our system 
allows users to experience the pleasure of physical shopping 
with friends, allowing them to choose clothes for each other, 
or even explore a completely new style of clothing that they 
would otherwise not try on by themselves. 
•More confident decisions. The sharing VTO experience 
in AR can provide users with a more effective shopping 
experience. Sharing the intuitive dressed body allows users to 
obtain more accurate comments from others, thereby helping 
them make more confident purchase decisions. 
•Strengthen social connection. The rating of IOS showed 
that the shared VTO system can strengthen social relationship 
between friends and make users feel closer to each other. 
In the future, we will improve our work from these two 
perspectives: 
 
1) Improve sense of personalization with facial expression. 
 Our personalization research result in VTO shows that the 
level of personalization can be improved to a certain extent, 
such that the realism and interactivity of VTO may be 
increased (e.g., facial expression of virtual avatar). Several 
participants mentioned that they hope that our system will add 
real facial expressions to make the virtual avatar more 
natural/humanlike and share the emotional attitude toward 
virtual clothes with others. Thus, future work may explore 
expression design of the personalized avatars to provide a 
more natural and interactive sharing VTO experience for users. 
 
2) Enrich social interactions with VTO.  
Our system allows users to share their virtual avatar with 
others from a social interaction perspective. We presented a 
new way for multiple users to experience a VTO experience 
in the local space. In the future, we hope to apply the shared 
AR-based try-on system to remote users, allowing multiple 
users to cross distance barriers and share fittings through 
natural communication. 
 
 
 
 
 

80
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
REFERENCES 
 
[1] Y. Liu, Y. Liu, S. Xu, J. Yuan, X. Sun, K. Cheng, et al., “3D 
Virtual Try-On System Using Personalized Avatars: Augmented 
Walking in the Real World,” in Proceedings of the Thirteenth 
International Conference on Advances in Computer-Human 
Interactions (ACHI 2020), pp. 391-398, 2020. 
[2] Cloth-Weaver. https://clothweaver.com/.  
[retrieved: Nov. 2021] 
[3] X. Han, Z. Wu, Z. Wu, R. Yu, and L. S. Davis. “Viton: An image-
based virtual try-on network,” in 
Proceedings of 2018 
IEEE/CVF Conference on Computer Vision and Pattern 
Recognition, pp. 7543-7552, 2018. 
DOI: https://doi.org/10.1109/CVPR.2018.00787 
[4] M. Sekine, K. Sugita, F. Perbet2, B. Stenger, and M. 
Nishiyama, “Virtual fitting by single-shot body shape 
estimation,” In Proceedings of International Conference on 
3D Body Scanning Technologies. pp. 406-413, 2014. 
[5] P. Decaudin, D. Julius, J. Wither, L. Boissieux, A. 
Sheffer, and M.-P. Cani, “Virtual garments: A fully 
geometric 
approach for clothing design,” In Computer 
Graphics Forum, pp. 625-634, 2006. 
DOI: https://doi.org/10.1111/j.1467-8659.2006.00982.x 
[6] A. Hilsmann and P. Eisert, “Tracking and Retexturing Cloth 
for Real-Time Virtual Clothing Applications,” in Proceedings 
of 
the 
4th 
International 
Conference 
on 
Computer 
Vision/Computer Graphics Collaboration Techniques Springer-
Verlag, Berlin, Heidelberg, pp. 94–105, 2009. 
DOI: https://doi.org/10.1007/978-3-642-01811-4_9 
[7] H. Yamada, M. Hirose, Y. Kanamori, J. Mitani, and Y. 
Fukui, “Image-based virtual fitting system with garment 
image reshaping,” in Proceedings of 2014 International 
Conference on Cyberworlds," IEEE, pp. 47-54, 2014. 
DOI: https://doi.org/ 10.1109/CW.2014.15 
[8] D. Protopsaltou, C. Luible, M. Arevalo, and N. Magnenat-
Thalmann, “A body and garment creation method for an Internet 
based virtual fitting room,” in Advances in modelling, animation 
and rendering, pp. 105-122, 2002. 
DOI: https://doi.org/10.1007/978-1-4471-0103-1_7 
[9] D. Li, Y. Zhong, G. Wu, and P. Hu, “Automatic three-
dimensional-scanned garment fitting based on virtual tailoring 
and geometric sewing,” Journal of Engineered Fibers and Fabrics, 
vol. 14, 16 pages, 2019.  
DOI: Https://Doi.Org/10.1177/1558925018825319 
[10] H. Lee and K. Leonas, “Consumer experiences, the key to 
survive in an omni-channel environment: use of virtual 
technology,” Journal of Textile and Apparel, Technology and 
Management, vol. 10, pp. 1-23, 2018. 
[11] G. Pons-moll, S. Pujades, S. Hu, and Michael J. Black, 
“ClothCap: seamless 4D clothing capture 
and retargeting,” 
ACM Transactions on Graphics, vol. 36, 15pages, 2017. 
DOI: https://dl.acm.org/doi/10.1145/3072959.3073711 
[12] Marvelous Designer, https://www.marvelousdesigner.com/. 
[retrieved: Nov. 2021] 
[13] B. Zhou, X. Chen, Q. Fu, K. Guo, and P. Tan, “Garment 
modeling from a single image,” in Computer graphics forum, pp. 
85-91, 2013. 
DOI: https://doi.org/10.1111/cgf.12215 
[14] X. Chen, B. Zhou, F. Lu, L. Wang, L. Bi and P. Tan, “Garment 
modeling with a depth camera,” ACM Transactions on 
Graphics vol. 34, 12 pages. 2015. 
DOI: https://doi.org/10.1145/2816795.2818059 
[15] Warehouse, https://www.warehouselondon.com/.  
[retrieved: Nov. 2021] 
[16] M. Yuan, I. R. Khan, F. Farbiz, S. Yao, A. Niswar and M. H. 
Foo, “A mixed reality virtual clothes try-on system,” IEEE 
Transactions on Multimedia, vol. 15, pp. 1958-1968, 2013. 
DOI: https://doi.org/10.1109/TMM.2013.2280560 
[17] N. Magnenat-Thalmann, B. Kevelham, P. Volino, M. Kasap, 
and E. Lyard, “3d web-based virtual try on of physically 
simulated clothes,” Computer-Aided Design and Applications, 
vol. 8, pp. 163-174, 2011. 
DOI: https://doi.org/10.3722/cadaps.2011.163-174 
[18] A. Merle, S. Senecal, and A. St-Onge, “Whether and how virtual 
try-on influences consumer responses to an apparel web site,” 
International Journal of Electronic Commerce, vol.16, no.3, pp. 
41-64. 2012.  
DOI: https://doi.org/10.2753/JEC1086-4415160302 
[19] A. M. Fiore, J. Kim, and H. Lee, “Effect of image interactivity 
technology on consumer responses toward the online retailer,” 
Journal of Interactive Marketing, vol.19, no.3, pp. 38-53, 2005. 
DOI: https://doi.org/10.1002/dir.20042 
[20] A. M. Fiore, H. J. Jin, and J. Kim, “For fun and profit: Hedonic 
value from image interactivity and responses toward an online 
store,” Psychology & Marketing vol.22, no.8, pp. 669-694, 2005. 
DOI: https://doi.org/10.1002/mar.20079 
[21] J. Kim and S. Forsythe, “Sensory enabling technology 
acceptance model (SE-TAM): A multiple-group structural model 
comparison,” Psychology and Marketing 25, 9, 901-922, 2008. 
DOI: https://doi.org/10.1002/mar.20245 
[22] C. Li and F. Cohen, “In-home application (App) for 3D virtual 
garment fitting dressing room,” Multimedia Tools and 
Applications, vol.80, pp. 5203–5224 (2021). 
DOI: https://doi.org/10.1007/s11042-020-09989-x 
[23] K. W. Lau and P. Y. Lee, “The Role of Stereoscopic 3D Virtual 
Reality in Fashion Advertising and Consumer Learning,” 
Advances in Advertising Research (Vol. VI), pp. 75-83, 2016. 
DOI: https://doi.org/10.1007/978-3-658-10558-7_7 
[24] K. L. Nowak and F. Biocca, “The Effect of the Agency and 
Anthropomorphism on Users' Sense of Telepresence, Copresence, 
and Social Presence,” in Virtual Environments. Presence: 
Teleoperators and Virtual Environments vol.12, no.5, pp.481-494, 
2003. DOI: https://doi.org/10.1162/105474603322761289 
[25] M. E. Latoschik, F. Kern, J. Stauffert, A. Bartl, M. Botsch, and 
J. Lugrin, “Not Alone Here?! Scalability and User Experience of 
Embodied Ambient Crowds in Distributed Social Virtual Reality,” 
IEEE transactions on visualization and computer graphics,  
vol 25, no. 5, pp. 2134–2144, 2019. 
DOI: https://doi.org/10.1109/TVCG.2019.2899250 
[26] M. E. Latoschik, D. Roth, D. Gall, J.Achenbach, T. Waltemate, 
and M. Botsch,” The Effect of Avatar Realism in Immersive 
Social Virtual Realities,” in Proceedings of the 23rd ACM 
Symposium on Virtual Reality Software and Technology 
(VRST ’17), no.39, pp. 1-10, 2017. 
DOI: https://doi.org/10.1145/3139131.3139156 
[27] D. Roth, C. Klelnbeck, T. Feigl, C. Mutschler, and M. E. 
Latoschik, “Beyond Replication: Augmenting Social Behaviors 
in Multi-User Virtual Realities,” in Proceedings of 2018 IEEE 
Conference on Virtual Reality and 3D User Interfaces (VR), 215-
222, 2018.  
DOI: https://doi.org/10.1109/VR.2018.8447550 
[28] M. Lankes, J. Hagler, G. Kostov, and J. Diephuis, “Invisible 
Walls: Co-Presence in a Co-located Augmented Virtuality 
Installation,” in Proceedings of the Annual Symposium on 
Computer-Human Interaction in Play (CHI PLAY '17). 
Association for Computing Machinery, New York, NY, USA, pp. 
553–560, 2017. DOI: https://doi.org/10.1145/3116595.3116609 
[29] T. Alldieck, M. Magnor, W. Xu, C. Theobalt, and G. 
Pons-Moll, "Video based reconstruction of 3d people 
models," in Proceedings of 2018 IEEE/CVF Conference on 
Computer Vision and Pattern Recognition, pp. 8387-8397, 2018. 
DOI: https://doi.org/10.1109/CVPR.2018.00875 
[30] Y. Deng, J. Yang, S. Xu, D. Chen, Y. Jia, and X.Tong, 
“Accurate 3D Face Reconstruction with Weakly-Supervised 
Learning: From Single Image to Image Set,” in Proceedings 

81
International Journal on Advances in Systems and Measurements, vol 14 no 1 & 2, year 2021, http://www.iariajournals.org/systems_and_measurements/
2021, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
of the IEEE Conference on Computer Vision and Pattern 
Recognition Workshops, 11pages, 2019. 
Retrieved from https://arxiv.org/abs/1903.08527 
[31] H&M. https://www.hm.com/. [retrieved: Nov. 2021] 
[32] ZARA. https://www.zara.com/. [retrieved: Nov. 2021]  
[33] 3ds Max.  
https://www.autodesk.co.jp/products/3ds-max/overview/. 
[retrieved: Nov. 2021] 
[34] Unity3D. https://unity.com/. [retrieved: Nov. 2021] 
[35] Maximo. https://www.mixamo.com/. [retrieved: Nov. 2021] 
[36] Animator Controller. https://docs.unity3d.com/Manual/class-
AnimatorController.html. [retrieved: Nov. 2021] 
[37] Vuforia Engine. https://developer.vuforia.com/. 
[retrieved: Nov. 2021] 
[38] AI-powered 3D Avatars, Avatar SDK. https://avatarsdk.com/.  
[39] Body Data Platform, 3D LOOK.  
https://3dlook.me. [retrieved: Nov. 2021] 
[40] Kinect. https://en.wikipedia.org/wiki/Kinect.  
[retrieved: Nov. 2021]  
[41] CinemaMocap. 
https://assetstore.unity.com/packages/tools/animation/cinema- 
mocap2-markerless-motion-capture-56576.  
[retrieved: Nov. 2021]  
[42] Maya. https://www.autodesk.co.jp/products/maya/overview. 
[retrieved: Nov. 2021]  
[43] ARCore. https://developers.google.com/ar.  
[retrieved: Nov. 2021]  
[44] D. Mashek, L. W. Cannaday, and J. P. Tangney. “Inclusion of 
community in self scale: A single-item pictorial measure of 
community connectedness,” Journal of Community Psychology, 
35, 257–275, 2007. 
DOI: https://doi.org/10.1002/jcop.20146 
[45] SPSS. https://www.ibm.com/analytics/spss-statistics-software. 
[retrieved: Nov. 2021] 
 

