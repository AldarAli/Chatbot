Comparative Assessment of Mobile Navigation Applications using 2D Maps and
Augmented Reality Interfaces
Mustafa Eseng¨un, G¨okhan ˙Ince
Computer Engineering Department Istanbul Technical University
Istanbul, Turkey
Email: {esengun, gokhan.ince}@itu.edu.tr
Abstract—So far, 2D map-based navigation applications on mobile
platforms have been dominating the market. However, with the
rise of augmented reality technology, a new type of interface is
introduced to the navigation applications. To this end, two mobile
navigation applications having different interaction styles were
developed for a task of navigation in Istanbul Technical University
campus. The ﬁrst application offers navigation within a 2D digital
map view and the second application is an augmented reality
browser, which provides navigation by displaying waypoints onto
the phone’s camera view. The aim of this study is to investigate
how efﬁcient these two different interfaces are in the tasks of
navigation and exploring the campus area. In line with this
purpose, a user experience test was conducted in the ﬁeld and the
results show that both interfaces have their own pros and cons,
but they both accomplish their navigation duties with success.
Keywords–user experience; augmented reality browser; mobile
navigation.
I.
INTRODUCTION
Mobile navigation applications are essential for people
to ﬁgure out how to get from one point to another in any
environment without getting lost. Teevan et al. [1] stated that
the most common reason for performing a local search was
to get directions to their target location (52%), followed by
the desire to go somewhere (43%), to get a phone number
of a place (28%) and to choose a speciﬁc place to visit
(21%). Therefore, the main focus should not only be given to
show the right path with as much clear directions as possible
but also to take the elements of exploration and discovery
into account. Another important factor in the development
process is the type of user interaction with the application.
Different interaction types may create different effects on the
degree of exploration of the environment and user’s satisfaction
while using the application, both of which are needs to be
investigated constituting the main aim of this study.
We chose to implement two different interfaces, each of
which has different interaction style. The proof-of-concept
system is proposed as a campus guide application to be used
within the vicinity of Istanbul Technical University (ITU) [2].
The ﬁrst application offers navigation functionality and fea-
tures to explore the area, whose interface design was inspired
from the existing Google Maps [3] application. The second
application is an Augmented Reality (AR) browser application,
which displays the buildings in the campus onto the live
camera view of the smartphone as Points Of Interests (POI)
and provides navigation by displaying arrows as waypoints
directing the user to any destination. By conducting user
experience tests, as well as the travel duration, the usability
of these two interfaces and efﬁciency of these two guidance
approaches were investigated.
The structure of the paper is as follows: In Section II,
related researches and their differences with this study are pre-
sented. In Section III, the design and implementation details of
the algorithms and applications are introduced. In Section IV,
setup of the user experiments is presented, and the results
are discussed. Lastly, in Section V the paper is concluded by
presenting the main outcome of this study and the future work
ideas.
II.
LITERATURE REVIEW
The navigation applications allow people to ﬁnd their
route and explore their surroundings easily and quickly in
the places they have not visited before without losing too
much time [4]. Especially universities with huge campuses
welcomes thousands of new students and visitors every year,
and to help people ﬁnd their route without getting lost, most of
the universities have guidance signs located at different points
around the campus. However, this kind of guidance causes
extra burden for the people because they ﬁrst have to spend
time and energy to ﬁnd those signs. To overcome this issue,
different mobile solutions were developed, which are easier
for the people to get access [5][6][7].
In order to get more help and beneﬁt from the navigation
applications, the interaction styles of applications plays an
important role. By using advantages of recent technologies,
navigation applications can provide rich contents to the users.
Most of the existing mobile navigation applications use 2D
map interface, which presents interactive items overlayed onto
the map to provide information. This kind of interface allows
user to see their surroundings from a bird’s-eye view [7].
On the other hand, AR browsers offer a different kind of
interactivity. The technology of AR carries the experience with
the real world to a higher level by allowing to see more than
what actually exists by combining the real world with the
virtual data provided. AR combines the real physical world
view with various media contents such as images, 3D models,
animations and sounds in order to enhance the perception of
the user among the environment or the objects. The media
content related with real world locations and displayed onto
the camera view of the phones make the users feel as if
the objects really exist on those locations, which provides
opportunity for the people to enhance their perception and get
to know better about surroundings [8][9][10]. Another reason
of usage of augmented reality in navigation applications is that
AR provides a location-aware interface [9]. Since the study of
Feiner et. al. [11], mobile AR applications have been one of
the attractive research topics in academia and they showed that
AR technology can guide the people to explore an area or a
city which are not familiar to them.
423
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

In AR browser applications, as location-based AR appli-
cations, POIs are displayed onto the camera view by using
information balloons or any other media content [4]. These
applications use phone’s camera, GPS, compass and other
sensors to relate the digital content with the real world
objects in order to provide much detailed information about
that location[12][13]. There are couple of commercial AR
applications available, such as, Wikitude [14], Layar [15] and
Junaio [16], each of which enables displaying POIs on the
camera view.
Comparison of user experience in using AR browser and
2D digital map applications has been discussed in some
studies. Lee [13] proposed to use a 2D digital map, an AR
browser and panoramic photographs interfaces to inform the
tourists about the original view of the buildings which were
damaged by an earthquake in Chirstchurch city. The user
experience tests conducted in this study showed that 2D digital
map interface was commonly used for browsing and ﬁnding the
point of interests. Another application developed by Mulloni
et. al. [18] provided a 2D digital map interface together
with an AR browser interface within an application having
a switching mode between them to offer navigation service.
The results of user experience test of this study showed that
AR browser interface was mostly used at crossings of the
route where users tried to decide, which direction they need to
turn, whereas they used 2D digital map interface mostly when
they walked straight. In a similar study [17], three different
applications, one with a 2D map interface developed using
Google Maps Application Program Interface (API), another
one with an AR browser interface and the last one with the
combination of these two interfaces, were compared in terms
of user experience for a navigation task. Results of this study
showed that when AR browser interface was used, arriving
at the destination took longer because of the obstacles on the
route. The drawback of this system was that the route planning
options in this interface was limited. Another outcome of this
study was that using the AR browser interface user found
shorter routes between two locations compared to that when
using the 2D map because in the map those routes were either
covered by trees or not included in the satellite images.
What distinguishes our study from the ones in the literature
is the way of providing navigation service. To be more speciﬁc,
AR interfaces in the literature borrowed either the 2D digital
map interfaces for navigation purpose or only showed points
of interests and expected the users to walk towards them.
However, in our study, AR browser interface not only shows
the point of interests but also it displays arrows as waypoints
to guide the users their destination.
III.
PROPOSED NAVIGATION APPLICATIONS
The shortest path between a selected source and target lo-
cation is displayed to the users in both applications. Moreover,
to help users to explore the campus, a search functionality is
also implemented together with displaying buildings as groups,
such as academic buildings, sport facilities, etc.
A. Finding the Shortest Path for Navigation
In both applications, the shortest path offered to the user
is calculated by using Dijkstra’s shortest path algorithm. For
the implementation of this algorithm Liang’s [19] method is
used as a reference. The algorithm uses a weighted graph
which includes nodes, edges and weights of each edges. The
graph was created using Google Earth [20] software. To deﬁne
nodes of the graph, pins are put onto the campus image for
every building in the campus, and walkable areas between
the buildings. Afterwards, the edges are speciﬁed and distance
between each nodes are deﬁned as the weights of the edges.
A small part of the graph is shown in Figure 1, where the red
lines show edges and the walkable paths for the users.
Figure 1. Representation of nodes and edges in the graph created in Google
Earth program
The nodes are stored in an array with their descriptions
and the edges are stored using an integer array, which has
the index of the source node, followed by the index of the
target node and the distance between the nodes as weights
of the edges. The nodes created in Google Earth were ex-
ported and then parsed to extract and store the name, lati-
tude and longitude information of each node to be used to
construct these arrays. By using the coordinates of nodes,
distance between two nodes are calculated using Haversine
Formula [21] and then stored as weight of the edges. Haversine
formula as deﬁned in (1a)-(1f) gives us the distance between
two coordinates pos1(lat1, long1) and pos2(lat2, long2). It
presumes a spherical Earth with radius 6376.5 (1a). In order
to convert lat1, long1 and lat2, long2 from degrees, minutes,
and seconds to radians, each value is multiplied by π/180. It
calculates the changes in latitude and longitude as in (1b) and
(1c) respectively. Next, it uses (1d), (1e), (1f) to calculate the
great-circle distance between two points, that is, the shortest
distance over the earth’s surface.
R = earth′sradius = 6376.5,
(1a)
∆lat = lat2.π/180 − lat1.π/180,
(1b)
∆long = long2.π/180 − long1.π/180,
(1c)
a = sin2(∆lat/2) + cos(lat1).
(1d)
. cos(lat2). sin2(∆long/2),
c = 2. arcsin(√a),
(1e)
d = R.c
(1f)
where,
424
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

•
lat : Latitude
•
long : Longitude
•
∆lat : change in latitude
•
∆long: change in longitude
•
a : the square of the half of the straight line distance
between two points
•
c : the great circle distance in radians
•
d : distance
All the edges in this graph are bidirectional. Therefore,
when an edge is deﬁned as from A to B, another edge is also
needed to be deﬁned as from B to A. When the user wants to
get to a target from his/her current position, ﬁnding the source
node requires an extra calculation because user’s position is
deﬁned with the corresponding GPS data and it may not be
the same with any of the nodes in the graph. Therefore, when
the user wants to walk or drive from his/her current position
to a target destination, the source node in the algorithm is
chosen by ﬁnding the closest node to the user’s position. In
order to ﬁnd the closest node to the user’s position, distance
between user’s position and all the nodes are again calculated
using Haversine Formula.
After constructing the graph and specifying the node that is
closest to the user, Dijkstra’s algorithm [19] was implemented
to ﬁnd the shortest path from a source node to a target node.
The shortest path between two nodes is deﬁned as the path
with the minimum total weights. The algorithm is known as
a single-source shortest path algorithm because it ﬁnds the
shortest path from the source node to all the other nodes. The
pseudo code of the Dijkstra’s Shortest Path Algorithm is shown
in Figure 2.
function SHORTESTPATH(source)
Let V denote the set of vertices in the graph and v
denotes any of the vertices in V;
Let T be a set that contains the vertices whose paths
to source are known;
Initially T contains source vertex with cost[source] =
0;
while sizeof T ≤ n do
ﬁnd v in V - T with the smallest cost[u] + w(u,v)
value among all u in T;
add v to T and set cost[v] = cost[u] + w(u,v);
end while
end function
Figure 2. The pseudo code of the Dijkstra’s Shortest Path Algorithm.
The algorithm returns the nodes of the path from source to
destination node that were used to display route information
in the applications [19]. The intermediate nodes are used to
show waypoints in AR browser application and used to draw
the path in the 2D digital map application.
B. Navigation Application with a 2D Digital Map Interface
This application was developed as an effort to provide
navigation service and also other informative features to help
the new visitors easily adapt themselves to the ITU campus.
Users can search a building and get detailed information
about it (Figure 3a). The 2D map interface shows the user
location with a blue dot, which is updated on the map as the
user moves. Moreover, on this blue dot a small arrow shows
which direction the user is currently looking at. Users can
also view the buildings in groups, such as academic buildings,
sports facilities, dormitories etc. (Figure 3b). User can choose
source and destination locations (Figure 4a) and follow the
highlighted path to the destination (Figure 4b). Zoom and map
orientation controls are also available in the interface.
(a) Search places function
(b) Displaying buildings in groups
Figure 3. 2D map interface
(a) Navigation menu
(b) Route information
Figure 4. Shortest route to a destination
C. Navigation Application with an AR Browser Interface
POIs are presented to the user by blue boxes overlayed
onto the phone’s camera. POIs were deﬁned as the buildings
in the campus. The distance information between the user
and the buildings are also presented. Users can also perceive
their orientation to the buildings by using the radar component
(Figure 5a). The features of displaying buildings in groups and
425
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

searching a building from a dropdown list is also available in
this application (Figure 5b). Moreover, users are free to deﬁne
a range parameters to see the POIs that are located only within
that range. This feature is useful if the user prefers to see
only the buildings that are close to current location. A user
can select any POI to see the detailed information about the
building as in Figure 6a.
(a) POIs representation
(b) Searh menu
Figure 5. AR browser application interface
(a) Detailed builging information
(b) Target and waypoint
representation
Figure 6. AR browser navigation interface
Since this interface uses the camera of the phone, the route
information is provided using a ﬁrst-person view. The route is
displayed to the user as a series of waypoints represented by
red arrows (Figure 6b). Once the user gets close enough to
the ﬁrst waypoint, the next one appears and user is directed to
the second, and so on. If the new visible waypoint is not in
the ﬁeld of vision of the user, s/he gets directed with a small
green arrow to the new waypoint (Figure 7).
Figure 7. Arrow directing to the new waypoint
IV.
EXPERIMENTS AND RESULTS
A. Hardware and Software Settings
Both applications were developed for Android smartphones
and tested with a Nexus 5 mobile device. The application
with 2D digital map interface was developed using Google
Maps API [22]. By using this API, Google’s map is integrated
into the application and GPS sensor data was fetched. For
the application with AR browser interface Wikitude Software
Development Kit (SDK) [23]was used. By using this SDK,
any type of information can be easily augmented onto the
camera view of the smarthphones. Coordinates, names and
descriptions of POIs were arranged and uploaded to a web
service. The application only requests this data when it is ﬁrst
started and parses the data to overlay the POI’s information
onto the camera view as shown in (Figure 5a).
B. Experimental Conditions
The user experience tests were conducted with two groups
of participants consisting of 5 people each (3 female, 7 male)
from ages 23 to 37. They were asked to follow predeﬁned
routes unfamiliar to them. Two successive routes were deﬁned.
First group of the participants were asked to follow the ﬁrst
route (699 meters) with the 2D map interface and the second
route (307 meters) with the AR browser interface. Conversely,
second group of the participants were asked to follow the ﬁrst
route with the AR browser interface and the second route with
the 2D map interface. By doing this, the potential effect of
task familiarity on the results was intended to be eliminated.
The participants were instructed to think aloud during the tests.
After each route was completed, the participants were asked
to ﬁll out two questionnaires about the interface they used.
The ﬁrst questionnaire was called NASA TLX [24] form,
which consisted of six questions with a Likert scale of 1
to 21 (1: the lowest, 21: the highest). It is applied to the
participants to obtain information about how much mental,
physical, temporal and psychological work load they felt for
the given task. The second questionnaire was the Post Study
System Usability Questionnaire (PSSUQ) [25], which had 19
questions and measured the overall user satisfaction with the
applications, usefulness of the applications, information quality
and interface quality of the applications.
426
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

C. Results
According to the demographic information about the users,
none of them used an AR application before, whereas all of
them used a 2D digital map application. Overall time spent
by the two groups with the two interfaces are summarized in
Table I. It is apparent that no matter which route was used, 2D
digital map interface took less time to arrive to the destination
than the AR browser interface.
TABLE I. MEAN ROUTE COMPLETION TIMES.
Group #
Route 1 (699 m.)
Route 2 (307 m.)
Group 1
with AR 13 min.
with 2D map 7.4 min.
Group 2
with 2D map 7.4 min.
with AR 8.2 min.
The results of NASA TLX questionnaire in Figure 8
showed that the application with the 2D map interface de-
manded less mental workload than the AR application. The
probable reason for a difference of 2.3 points was that the
participants used their intuition more with the AR interface
to ﬁnd the target. The application with the 2D map interface
demanded less physical workload (4.8/21) than the application
with the AR browser interface (12.6/21) since they needed
to hold the phone always at the eye level to see the arrow
and other information. Moreover, it was found out that AR
browser interface caused negative feelings such as 12.9% more
stress, irritation etc. because of the low stabilization of the
arrow caused by hand movements and frequent GPS signal
ﬂuctuations. In terms of temporal worload, which was about
how much time pressure the users felt due to the given tasks
and whether the interfaces put the users in rush or not, the 2D
map interface was evaluated higher by 2.2 points since some
of the participants missed the route updates and then rushed
to get on the previous route in order to not extend the distance
towards the target. The results also show that the participants
spent less effort to achieve the tasks with the 2D digital map
interface (7/21) compared to the AR browser interface (9.5/21)
since with the 2D application some of the participants looked
the route only couple of times especially when they got close
to the turning points, but with the AR application participants
were always in the interaction with the application. Lastly,
participants evaluated themselves more successful with the 2D
digital map interface, since they arrived to the target location
easier using the 2D digital map interface compared to their
performance with the AR browser interface.
The results of PSSUQ is presented in Figure 9. In terms
of user satisfaction, PSSUQ results showed that the 2D digital
map interface (71.1% of user satisfaction) is better than AR
browser interface (56.2% of user satisfaction). The reason that
the users were less satisﬁed with the AR browser interface
was due to the longer task completion times and the amount
of the frustration they felt with the interface. In terms of
interface quality, 2D digital map interface was considered
simpler than the AR browser interface, which resulted in the
8.6% difference in the interface quality scores of the two
interfaces. Moreover, 2D digital map interface was scored as
71% in terms of usefulness while AR browser interface was
scored as 56% because the 2D digital map interface was easier
to learn because it looked more familiar and usual than the AR
browser interface, and also it was considered as more effective
in the navigation tasks the participants fulﬁlled. Considering
the information quality scores, because of the color choices
(for some participants) and the low stabilization of the arrows
the participants experienced with the AR browser interface,
the 2D digital map interface was preferred. However, the radar
feature of the AR browser interface was found useful by the
participants since it helped them to stay on the right path
during the navigation and also to get back on the right path
when they got lost.
Mental
Physical
Temporal
Performance
Effort
Frustration
1
2
3
4
5
6
7
8
9
10
11
12
13
Scores
AR browser interface
2D digital map interface
Figure 8. NASA TLX questionnaire results.
User
satisfaction(%)
Usefulness(%) Information
quality(%)
Interface
quality(%)
10
20
30
40
50
60
70
80
Scores
AR browser interface
2D digital map interface
Figure 9. PSSUQ results.
Seven participants stated that they would prefer 2D digital
map interface, whereas, three participants stated that the AR
browser interface would be their choice. Moreover, four of
the participants suggested that the combination of these two
interfaces would be more useful. A seven degree scale (1: the
highest, 7: the lowest) was provided to the participants to eval-
uate the degree of exploration they felt with the two interfaces.
The answers showed that the 2D digital map interface helped
427
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

them more to explore the area while walking and the average
degree of exploration score given to 2D digital map interface
was 4.3, whereas, average degree of exploration score of AR
browser interface was 5.4 since using the AR application, users
were regularly focusing on the arrow and keeping their eyes
on the screen almost all the time. Moreover, the search places
feature was mentioned as more useful in the AR browser
interface especially when the POIs was overlapping.
Besides these questionnaires the thoughts of the partici-
pants stated during the experiments were also examined. At
the beginning of the navigation task, each participant tried to
orient him/herself to the map according to the direction that
they are facing to. Some of the participants mentioned that
radar component in the AR browser interface was helpful for
ﬁnding the initial orientation. They also stated that the arrow,
which shows the orientation of the user in the 2D digital
map interface appeared and disappeared too much, which
caused confusion about the direction to be followed. Moreover,
participants stated that they had to look at the arrow all the
time, which was tiring and might pose danger while walking.
The blue boxes showing the target POI were mentioned as
useful especially when they had difﬁculty to decide towards
which direction they needed to walk. Most of the participants
found the 2D digital map interface more helpful to get to know
the environment and the route. However, when the GPS signal
shows the user’s location wrongly even for a moment, some of
the participants got confused and felt anxious. In conclusion,
all of the participants stated that the combination of these two
interfaces would be more effective for a navigation task.
V.
CONCLUSION AND FUTURE WORK
In this study, two different mobile navigation interfaces
were compared in terms of user experience by conducting
an experiment using a navigation scenario. The results of
the experiment revealed the advantages and disadvantages
of both interfaces. Speciﬁcally, using 2D digital map inter-
face participants spent less time to arrive to target locations.
Moreover, in terms of physical and mental workload, the 2D
digital map interface was less demanding. User satisfaction
was found to be higher with the 2D digital map interface since
the participants found it simple and functional for the given
tasks. The radar component in the AR browser interface was
considered useful for orientation and locating the target point.
As a future work, the combination of these two interfaces
will be implemented, which was actually suggested by some of
the participants. With this new interface, displaying the point of
interests according to users’ preference will be also provided.
It is also thought to be a useful research that an AR application
similar to the one in this study can be implemented in optical
head-mounted displays, such as, Google Glass or Samsung
Gear VR, and tested with the users in order to observe people’s
behaviour and usability of these type of devices in navigation
tasks.
REFERENCES
[1]
J. Teevan, A. Karlson, S. Amini, A. Brush, and J. Krumm, “Understand-
ing the Importance of Location, Time, and People in Mobile Local Search
Behavior”, in Proceedings of the 13th International Conference on Mo-
bileHCI 2011, Stockholm, Sweden. ACM, 2011, pp. 77-80 ISBN: 978-
1-4503-0541-9, URL: http://dl.acm.org/citation.cfm?id=2037386 [ac-
cessed: 2015-11-27].
[2]
“ITU Webpage”, 2016, URL: http://www.itu.edu.tr [accessed: 2016-01-
02].
[3]
“Google Maps”, 2015, URL: http://www.maps.google.com [accessed:
2015-09-05].
[4]
G. Cherchi, F. Sorrentino, and R. Scateni, “AR Turn-By-Turn Navigation
in Small Urban Areas and Information Browsing”, in STAG - Eurograph-
ics Italian Chapter Conference 2014, Italy. The Eurographics Association,
2014, pp. 37-40, ISBN: 978-3-905674-72-9, URL: http://diglib.eg.org/
[accessed: 2015-11-20].
[5]
T. J. Mehigan and I. Pitt, Harnessing Wireless Technologies for Campus
Navigation by Blind Students and Visitors, Springer Berlin Heidelberg,
Berlin, Heidelberg, 2012, pp. 67-74, in ICCHP 2012, Linz, Austria, July
11-13, 2012, Proceedings, Part II, ISBN: 978-3-642-31534-3.
[6]
I. M. Rufﬁn, A. Murphy, V. Larkin, and J. E. Gilbert, “CAMPNAV: A
Campus Navigation System For the Visually Impaired”, Proceedings of
E-Learn: World Conference on E-Learning in Corporate, Government,
Healthcare, and Higher Education 2006, pp. 2944-2951. AACE, Hon-
olulu, Hawaii, USA, 2006.
[7]
T. S. Wang, D. Tjondronegoro, M. Docherty, W. Song, and J. Fuglsang,
“A Recommendation for Designing Mobile Pedestrian Navigation System
in University Campuses”, In Proceedings of the 25th OzCHI ’13, 2013,
Adelaide, Australia. ACM, 2013, pp. 3-12, ISBN: 978-1-4503-2525-7,
URL: http://dl.acm.org/ [accessed: 2015-11-27].
[8]
J. R. Vallino, “Interactive Augmented Reality”, Technical Report, Uni-
versity of Rochester, 1998.
[9]
R. Azuma, “A Survey of Augmented Reality”, Presence: Teleoperators
and Virtual Environments, Vol. 6, no. 4, 1997, pp. 355-385.
[10]
D. W. F. van Krevelen and R. Poelman, “A Survey of Augmented
Reality Technologies, Applications and Limitations”, The International
Journal of Virtual Reality, Vol. 9, No. 2, 2010, pp. 1-20.
[11]
S. Feiner, B. MacIntyre, T. Hollerer, and A. Webster, “A touring
machine: prototyping 3D mobile augmented reality systems for exploring
the urban environment”, Personal Technologies, vol. 1, no. 4, 1997, pp.
208-217, ISSN: 1617-4917.
[12]
T. Langlotz, J. Grubert, and R. Grasset, “Augmented Reality Browsers:
Essential Products or Only Gadgets?”, Communications of the ACM,
vol. 56, no. 11, 2013, pp. 34-36, ISSN: 0001-0782.
[13]
G. A. Lee, A. D¨unser, S. Kim, and M. Billinghurst, “CityViewAR:
A
Mobile
Outdoor
AR
Application
for
City
Visualization”,
IEEE
ISMAR-AMH
Proceedings,
Nov.
2012,
pp.
57-64,
URL:
http://ieeexplore.ieee.org/ [accessed: 2015-11-22].
[14]
“Wikitude”, 2015, URL: http://www.wikitude.com [accessed: 2015-10-
03].
[15]
“Layar”, 2015, URL: http://www.layar.com [accessed: 2015-10-10].
[16]
“Junaio”, 2015, URL: http://www.junaio.com [accessed: 2015-10-17].
[17]
A. D¨unser, M. Billinghurst, J. Wen, V. Lehtinen, and A. Nurminen,
“Exploring the use of handheld AR for outdoor navigation”, Computers
& Graphics, vol. 36, Issue 8, 2012, pp. 1084-1095, ISSN: 0097-8493.
[18]
A. Mulloni, H. Seichter, and D. Schmalstieg, “User Experiences with
Augmented Reality Aided Navigation on Phones”, in ISMAR, Oct. 2011,
pp.229-230, URL: http://ieeexplore.ieee.org/ [accessed: 2015-11-22].
[19]
Y. Liang, Weighted Graphs and Applications. Pearson Education, 2011,
chapter 31, pp. 1094-1127, in Introduction to Java programming: Com-
prehensive version (8th ed., International ed.).
[20]
“Google Earth”, 2015, URL: http://www.earth.google.com [accessed:
2015-08-30].
[21]
R. W. Sinnott, “Virtues of the Haversine”, Sky and telescope 11/1984;
68(2, article 159):158.
[22]
“Google Maps API”, 2015, URL: http://developers.google.com/maps/
[accessed: 2015-09-06].
[23]
“Wikitude SDK”, 2015, URL: http://www.wikitude.com/products/wikitude-
sdk/ [accessed: 2015-10-19].
[24]
S. G. Hart, “NASA-Task Load Index (NASA-TLX); 20 Years Later”,
Proceedings of the HFES 50th Annual Meeting, vol. 50, no. 9, 2006, pp.
904-908.
[25]
JR. Lewis, “Psychometric Evaluation of the Post-Study System Us-
ability Questionnaire: The PSSUQ”, Proceedings of the HFES Annual
Meeting, vol. 36, no. 16, 1992, pp. 1259-1260.
428
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

