Fundamental Study to Consider for Advanced Interface in Grasping Movement 
Shunji Shimizu / Tokyo University of Science, Suwa 
Department of Electric Systems Engineering 
Chino-city, Japan 
shun@rs.suwa.tus.ac.jp 
Hiroaki Inoue/ Tokyo University of Science, Suwa 
Research course of Engineering/Management  
Chino-city, Japan 
jgh12701@ed.suwa.tus.ac.jp
 
Noboru Takahashi/ Tokyo University of Science, Suwa 
Research course of Engineering/Management 
Chino-city, Japan 
srl@rs.suwa.tus.ac.jp 
 
Abstract— the analysis of human grasping movement is 
important in developing methodologies for controlling robots 
or understanding human motion programs. In analyzing 
human grasping movement, it is advantageous to classify 
movements. In previous papers, classifications of grasping 
patterns were proposed according to the posture. Among these 
classifications of grasping patterns, no unified view has been 
reached as yet. The measured quantities in grasping have 
included only the posture of the hand, force and its distribution. 
Few have pertained to classifications based on grasping force 
and its distribution. This paper first tries to analyze the effect 
of visual information on grasping movements, and then 
attempts to classify grasping movements broadly according to 
their purpose. For the elements of the purposes of grasping 
movements, movements that were decided upon were those 
which require attention, snapping or the adjustment of the 
wrist or movements which do not require any special action to 
achieve their purpose. Secondly, we focus on the tactile 
information to predict with a limitation of movement. Finally, 
we attempted to discuss the relation between human brain 
activity and grasping movement on cognitive tasks. 
Keywords-human hand; grasping force; grasping pattern; 
brain activity;NIRS. 
I. 
 INTRODUCTION 
Human hands are so dexterously controlled that they can 
manipulate almost anything freely. Observations obtained 
from analyzing the grasping patterns of human hands will be 
useful in the control of robot hands. For example, it may be 
possible for industrial robots to deal flexibly with and solve 
unexpected problems which may occur. In the construction 
of more sophisticated interface systems the analysis of the 
grasping patterns of human hands is also suggested as an 
important subject for controlling robot hands by remotely. 
  To analyze grasping patterns, many researchers, including 
Schlesinger [1] have proposed and reported methods to 
classify 
grasping 
patterns 
[2][3]. 
However, 
these 
classifications of grasping modes depend largely on the 
researcher’s personal definitions, and no unified view has 
been reached at present. 
The measured quantities in grasping include the posture 
of the hands, and force and its distribution. However, most 
classifications have been based on the posture of the hands, 
and little has been reported on classification based on 
grasping force and its distribution. 
  From the point of the view of the grasping task, Napier 
broadly divided grasping patters into “power grip” and 
“precision grip” [4]. In addition, Cutkosky classified more 
grasping patterns by incorporating details of the objects and 
the precision of the task in Napier’s concept [5]. Meanwhile, 
Kamakura et al. presented a classification cased on the 
contact pattern between the grasped object and grasping 
hand [6]. Kang et al. proposed the technique of the “contact 
web” which estimated information and classified grasping 
based on the resulting contact pattern [7]. For the theory of 
multi-fingered hands Yokokawa is proposing the dynamic 
multi-fingered manipulability measurement under the 
concept of the dynamic manipulability [8]. Another new 
approach to control the robots is the Programming by 
Demonstration done (PbD). A late report is proposed by K. 
Bernard in et al [9]. Shimizu et al. described the Sensor 
Glove MKIII which is useful in analyzing grasping patterns 
and shows the potential of measuring grasping force 
distribution for classification [10].  
 Many reserch works exist on the classification of grasping 
movements. However, there are only a few areas using these 
classifications, such as the industry, indicating a need for a 
more useful grasping classification to be used in engineering. 
We thus considered using new elements to broadly classify 
grasping movements. We set grasping movement purposes 
for the new elements, elements which are movements that 
require attention, snapping or adjustment of wrist or do not 
require any special action to achieve their  purpose. 
Therefore, it was necessary to find a place in which position 
and direction had little effect when measuring grasping 
movements. We subsequently deliberated the possibility of 
broadly classifying grasping patterns according to the 
purpose of the grasping movement. A report about the 
importance of grasping task is proposed by Shiraishi, et al.  
[11], too. 
This paper first tries to analyze the effect of visual 
information on grasping movements and then considers the 
potential for using the elements described above in 
classification. Lastly, we focus on the tactile information to 
predict with a limitation of movement. 
342
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

II. 
EXPERIMENT FOR MEASURING GRASPING MOVEMENT 
WITH CONSIDERING EFFECT OF WRIST DIRECTION 
A. Experimantal Method 1 
To measure grasping movement with minimal effect 
from the position and object’s direction for classification, it 
is necessary to ascertain the proper position and direction 
from which to do so. The next step is to discover the role 
visual information plays in grasping patterns. In this 
experiment, USB cameras from three directions measured 
grasping patterns. The cameras used had a resolution of over 
0.3 megapixels.  
B. Range of Movement 
To find the area which would not need to be considered 
in regard to its effect on grasping shape; subjects were made 
to grasp a pointer directed toward them. Then the area in 
which they could move without changing the direction was 
measured. Fig. 1 shows the range of movement. Subjects 
were four healthy, right-handed men aged 22 to 24. 
 
Figure 1.  Range of movement (object: pointer) 
 
The range of movement seems to depend on their 
flexibility and grasping patterns. As can be seen in Fig. 1, a 
15 cm margin has been set, and the objects have been placed 
to check their effect on grasping. Fig. 2 shows the position in 
which the objects were placed. Grasping patterns differed 
little according to position; here, Position C was used for 
classification. However, if the object is placed in direction 
(4), the grasping patterns change for right-handed people. 
The next step was to look at the relationship between 
direction and grasping 
 
 
 
Figure 2.  object’s position and direction 
 
C. Effect of Direction on Grasping 
To analyze the relationship between direction and 
grasping pattern, the angle of the underarm and the angles in 
Fig. 3 were measured by changing the object's direction. The 
directions of (1) to (3) were measured by changing the angle 
30 degrees. Subjects were told to grasp the object and put it 
onto another table. The subjects were five right-handed 
healthy men aged 22 – 24. 
Increases in the angle of the wrist and the angle of the 
finger baseline are seen to be related to the angle of the 
object. The angle of the underarm decreased as the angle of 
the object increased. However, as the angle of the underarm 
is influenced by reaching, the displacement is not uniform. 
Fig. 4 exemplifies the difference between grasping patterns 
and the object’s directions. 
 
 
Figure 3.  angle measured, θand φ 
343
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
 
 
 
 
 
 
Figure 4.  grasping patterns for each object 
(Top: pointer, Middle: pincher, Bottom: hammer) 
III. 
EXPERIMENT OF CLASSIFICATION OF GRASPING 
MOVEMENTS 
A. Experimental Method 2 
We compared the difference of grasping movement 
based on “purpose of grasping movement”. We set elements 
which are movements that require attention, snapping or 
adjustment of wrist or do not require any special action to 
achieve their purpose. We considered the potential for using 
the elements described above in classification [12]. 
B. Experiment for the Classification of Grasping 
Movements 
To classify grasping movements, the purpose of grasping 
was used as an element that is determined at a certain point, 
i.e., before or after grasping. In this experiment, five kinds of 
tasks were used to consider the relation between grasping 
patterns and their purpose. The tasks are to move the object 
to another place (Task 1), to put the object onto a small box 
(Task 2), to throw the object (Task 3), to make the object 
pass through a small hole (Task 4), to use the object as you 
usually do (Task 5) after grasping. These tasks were created 
to measure a simple grasping movement (Task 1), a 
movement requiring attention (Task 2), the movement which 
requires snapping (Task 3), a movement which requires 
attention and adjustment of wrist (Task 4), a movement that 
is imagined to be associated with the object (Task 5). And 
checked that the grasping movements would change with 
there tasks. 
  The purpose of the first experiment was to measure 
grasping shapes according to their purpose. The next step 
was to measure grasps without a prescribed purpose. The 
purpose was given only after the subject first grasped the 
object. The subjects were six right-handed healthy men aged 
22 – 24.  
C. Result of Classfication Experiment 
The results showed two movements involved in grasping 
and taking action when checking the difference between the 
first grasping shape and the next grasping shape. One is a 
change in grasping shapes before picking up. The other one 
is a change in the grasping shapes after picking up.  Fig 6 
shows the first movement; the grasping shape changes 
according to its purpose. T shows the second movement; the 
grasping shape changes according to its purpose. Such cases 
might be difficult to classify only by force distribution. Such 
movements were not seen in the case of every object. 
Therefore we attempted to discover out the difference 
between them and use it with the force distribution to 
classify grasping movements. 
This experiment showed that one seems to make space 
between the palms and object or change the grasping shape 
into a more flexible form when they try to do something 
sensitive like Task 4. Probably, such a tendency has some 
relation to degree of freedom in movement. 
 
 
 
 
344
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

 
 
Figure 5.  changing the shape when grasping 
(Top: Task 1, Middle: Task 3, Bottom: Task 4) 
 
 
Figure 6.  changing the shape after grasping 
(left:task4, right:task5) 
IV. 
TACTILE INFORMATION 
Looking into the tactile information and degree of 
freedom in hand movement, we first tried to check how 
correctly we could imagine the shape only from tactile 
information. Therefore, the relation of such information to 
the degree of freedom in movement was considered in 
conducting this experiment [13]. 
A. Experiment Method for Tactile Information 
Three limitations were made to analyze the effect. One 
was wearing an eye mask to shut out the visual information. 
Another one was a pinching movement to control the tactile 
information. The last one aluminum fingertip cover to reduce 
the tactile information and to make the surface like robot 
hand because we are thinking to use the results for robot’s 
hands. The fingertip cover used in this experiment was 
enclosed in aluminum sheeting and the finger cushion’s side 
was flattened. Limitations in pinching movement are shown 
in Fig 7. 
The test was to guess the object with eyes masked and 
fingertip limitations. After that, same tests were conducted 
without using the fingertips. Fig 7, 8 and 9 shows the objects 
used. Objects in Fig. 8 were stuck to board. The objects in 
Fig. 8 (lower right) can be spun using the stick that is 
standing on the small plate. The objects in Fig. 9 can be 
pinched freely. 
TABLE I.  
LIMITATION OF PINCH 
freedom 
degree 
number 
Limitation 
1 
Not allowed to pinch again 
1' 
allowed to grasp again just a little 
2 
allowed to move up and down 
3 
allowed to go over lateral side 
4 
allowed to grasp freely 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7.  object for tactile information test 
 
 
 
 
 
 
 
 
 
 
   
Figure 8.  Object for tactile information test 
 
 
 
 
 
 
 
 
 
 
 
Figure 9.  Object for tactile information test 
345
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

B. Result of the Experiment in Tactile Information 
Fig. 10 shows the result of this test. The answers were 
checked by a majority decision of three observers. The 
subjects for this experiment were six men and two women, 
all healthy, right-handed and aged 20 – 60. 
In Fig. 10, the accuracy rate was higher when the 
fingertip covers were not used, and the accuracy rate 
basically increased with the degree of freedom, but it 
increased only slightly when the fingertip covers were not 
used, or when there was a high degree of freedom. From the 
aspect of object identification only with tactile information, 
the difference in fingertip cover suggests the importance of 
the ridges in the fingers’ skin and the plasticity of the finger 
surface, probably because they are enhancing the signals. 
Furthermore, Degree of Freedom 4 was lower than that of 1 
when they tried without the fingertip cover. This seems to 
have occurred when they lost track of direction when they 
moved their hands. This suggests that the relation between 
accuracy rate and freedom digger is not a simple 
proportional relation. 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1
2
3
4
freedom degree
accuracy rate [%]
with fingertip
no fingertip
 
Figure 10.  degree of freedom and accuracy rate 
 
V. 
GRASPING MOTION AND HUMAN BRAIN ACTIVITY 
We are trying to process experimental measuring and 
discuss human brain activity on grasping movement and 
cognitive task. So, we measured brain activity from the 
viewpoint of blood flow changes when subject performed 
grasping movement including reaching. Six subjects were 
healthy males who were right handed. They were asked to 
read and sign an informed consent regarding the experiment. 
In 
measurement, 
f-NIRS(Functional 
Near 
Infrared 
Spectroscopy ) made by SHIMADZE Co. Ltd. were used. 
A. Experimental Method 
Subjects were asked to grasp the piece of wood, pointer, 
column-shaped metallic bar and hammer based on 
instructions from operator (Fig. 11). Brain activity was 
measured under four conditions. Subjects grasped objects 
actively with their eyes open (1) or close (2), and passively 
with their eyes open (3) or close (4). In addition, subjects 
were told to perform simple grasping motion or do it with 
imaging motion for using object. 
Subjects took a rest during 10 seconds at least with their 
eye close before starting task and the time design was rest (5 
seconds) – task (10 seconds) – rest (5 seconds). Finally, 
subject closed their eyes for 10 seconds again after task. 
Then, the brain activity was recorded from the first eyes-
closed rest to the last eyes. The part of measurement was the 
frontal lobe. 
B. Experimental Results 
Fig. 12 shows one subject’s measuring result. At the first, 
Hb-oxy was increased in overall frontal lobe after start of 
grasping task. This tendency was common among subjects. 
After that, Hb-oxy was increased and decreased in 
synchronization with task and rest. Also, there was 
remarkble tendency like this during task with imageing and 
their eyes open. 
Analysis was performed one-sample t-test and sample 
was variation in brain activity during about four seconds 
after starting tasks. 
As a result, there was not significant differences at frontal 
lobe. However, it was shown as common tendency among 
subjects that there was adifference in variation of oxy-Hb 
density due to presence or absence of existence or non-
existence imaging motion and eyesight. It was thought that 
this result was derived from planning for grasping and 
visuals timulation. 
 
 
 
Figure 11.  Grasping object 
 
 
Figure 12.  Measuring Result of grasping steering wheel 
346
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

VI. 
CONCLUSION AND FUTURE WORK 
In this study, we performed three experiments. The 
analysis of human grasping movement is important in 
developing methodologies 
for 
controlling robots 
or 
understanding human motion programs. In analyzing human 
grasping movement, it is advantageous to classify 
movements. 
This paper first studies that the grasping angle changes. 
From the results, it was determined that basically the wrist 
angle and finger baseline angle are proportionally related. In 
this report we attempted to classify the grasping patterns 
based on “purpose of grasping movement”. In the results 
described in Section III.B, we found two movements related 
to the “purpose of grasping movement”. Some grasping 
movements change when you give them a purpose before 
grasping, but some grasping movements do not change until 
the object is lifted and the action accomplished. These results 
suggest the possibility of the classification of grasping 
movements according to “purpose of grasping movement”. 
Furthermore, it would be useful to classify the grasping 
movements that have similar grasping forms or distributions, 
but have different actions after grasping.  At a later stage, we 
would like to classify grasping movements according to the 
"purpose of grasping movement" and use the results of the 
distribution in grasping patterns to create more useful 
classifications for grasping movements in engineering. 
The results in Section IV.B are important, in using the 
classification. The relation between accuracy rates basically 
increases with the degree of freedom, but if the degree of 
freedom increases with no useful feedback, the results would 
differ from expectation. Therefore, the challenge which lies 
ahead is to find effective ways to use the tactile information.  
In terms of measuring brain activity, we plan to examine 
change of brain activity due to shape of hand and object as 
well as a review of experimental design. 
REFERENCES 
[1] G Schlesinger: “Der Mechanische Aufbauder kunstlischen 
Glieder [The mechanical structure of artificial limbs]”, In 
M.Borchardt et al. (Eds.),Ersatzklieder und Arbeishilefen fuk 
Kriegsbeschadigte und Unfallverlezte, pp. 21-600, Berline: 
Springer, 1919. 
[2] CL.Mackenzie 
and 
T.Iberall:“The 
Grasping 
hand,”G.e.Stelmach, 
P.A.Vroon(Eds.), 
Advances 
in 
psychology, no.104, pp. 15-46, Amsterdam, 1994. 
[3] M.A. Arbib, T.Iberall, and D.M.Lyons: "Coordinatecontrol 
programs for movements of the hand,"  In A.W.Goodwin & 
I.Darian-Smith (Eds.), Hand function and the neocotex, pp. 
111-129 
[4] J.R.Napier: ”The prehensile movement of the human hand,” 
The journal of bone and joint surgery, vol.38 B, no.4, pp. 902-
913, 1956. 
[5] M.R. Cutkosky: “On grasping choice, grasping models, and 
the design of hands for manufactureing task, ”IEE Trans. 
Robotics and Automation, vol.5, no.3 , pp. 269-279,1819. 
[6] N.Kamakura, M.Matsuo, H.Ishii, F.Mitsuboshi, and Y.Miura: 
“Patten of static prehension in normal hands,” The American 
journal of occupational therapy, vol.34, no. 7, pp. 437-445, 
1980 
[7] S.B.Kang and K.Ikeuchi: “Towed automatic robot instruction 
from perception – recognizing a grasping from observation,” 
IEEE Trans. Robotics and Automation, vol.9, No.4, pp. 432-
443, 1993. 
[8] M.Fujiwa, Y.Yokokohji, and T.Yoshikawa: “Dynamic Multi-
Fingered Manipulability for Articulated Hands and its 
Extension to a Design Index for Master-Slave Hands,” 
Journal of the Robotics Society of Japan, vol.22, No.2, pp. 
264-272, 2004 
[9] K.Bernardin, K.Ogawara, K.Ikeuchi, and R.Dillmann; “A 
Sensor Fusion Approach for Recognizing Continuous Human 
Grasping Sequences Using Hidden Markov Models” IEEE 
Trans. Robotics, 21(1):pp. 47-57,2005. 
[10] S.Shimizu, M.Shimojo, S.Sto, Y.Seki, A.Takahashi, Y.Inukai, 
and M.Yoshioka; “The Relationship between Hunam Griip 
Types ans Force Distribution Pattern in Grasping,” 8th 
International onferrence on Advanced Robotics, pp. 299-304, 
1997 
[11] K.Shiraishi, T.Kondo, and K.Ito; “Analysis on the Task 
Dependency of Human Grasp Movements and Application to 
Robot 
Control” 
SICE 
Symposium 
on 
Systems 
and 
Information,pp. 283-286,2002 
[12] S. Matsuzawa, S. Shimizu, S. kikuchi, E. Watanabe, H. Kina, 
H. Hurata, N.  Takahashi, and T. Ehara,“Proposal for a New 
Classification Method for Grasping Movement,” The 13th 
International Conference on Advanced Robotics, 2007, Jeju 
Island, Kores. 
[13] N. Takahashi, S. Shimizu, Y. Hirata, H. Nara, H. Inoue, N. 
Hirai, S.  Kikuchi, E. Watanabe, and S. Kato,“Basic study of 
Analysis of Human Brain Activities during Car Driving,” the 
14th 
International 
Conferrence 
on 
Human-Computer 
Interaction, 2011, Orlando, Florida, USA. 
[14] S. Matsuzawa, S. Shimizu, S. kikuchi, E. Watanabe, H. Kina, 
H. Hurata, N.  Takahashi, and T. Ehara,“A Basic Study of 
Grasping Motion for Advanced Interface,” the 12th 
International Conferrence on Human-Computer Interaction, 
2007, Beijing, China. 
347
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

