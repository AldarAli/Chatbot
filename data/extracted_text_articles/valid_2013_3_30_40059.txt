An Evaluation of Client-Side Dependencies of Search Engines 
by Load Testing 
Emine Sefer, Sinem Aykanat 
TUBITAK BILGEM YTKDM 
Kocaeli, Turkey 
emine.sefer@tubitak.gov.tr 
sinem.aykanat@tubitak.gov.tr 
 
 
Abstract— Nowadays, web based large-scale systems, such as 
search engines, are widely used. The popularity of search 
engines created a new environment in which the applications 
need to be highly scalable due to the data tsunami generated by 
a huge load of requests. In this context, the main problem is to 
validate how far the web applications especially search engines 
can deal with the load generated by the clients. Load testing, in 
general, refers to the practice of accessing the system behavior 
under load. In this paper, we study on search engine 
performances’ dependencies related to network bandwidth and 
Internet browsers in aspect of load testing. We observed that 
search engines’ speed is dependent on Internet browsers and 
network bandwidth. 
Keywords-search engine; load testing; Internet browser; 
network bandwidth. 
I. 
 INTRODUCTION 
Web-based applications are widely used nowadays 
because of their advantages, such as cross-platform without 
distribution and installation of software on thousands of 
clients, easy to be used and managed, etc. Therefore, web-
based applications need to scale to thousands of concurrent 
users. To assure the quality of these systems, load testing is a 
required testing procedure in addition to conventional 
functional testing procedures, such as unit and integration 
testing [1]. 
Load testing, in general, refers to the practice of accessing 
the system behavior under load [1]. The load testing aims to 
identify and isolate system bottlenecks, tune application 
components, predict system scalability, and make judgments 
on system architecture or design, while performance models 
are used in analyzing the performance and scalability 
characteristics of the system under study [2]. 
In the literature, there are various load testing studies for 
web-based applications, using different technologies. One of 
these studies is conducted by A. Habul and E. Kurtovic. 
Their study presents a methodology for load testing an Ajax 
application [3]. Another study is about performance 
comparison between different web-based application 
architectures which are .NET and Java EE [4]. One of them 
is for peer-to-peer applications [5]. 
In this paper, we aim to present basic load testing 
approach for web applications with high intensity of use. 
Search engine applications are at the top of these 
applications.  
From a user perspective, the client-side performance is 
more important than server performance. So, the client-side 
performance is considered for load testing in this study. 
Seeking client-side performance, response time, error rate, 
CPU usage and memory consumption are taken into 
consideration. These metrics are interpreted for two 
criterion, including bandwidth and browser for search 
engines by HP LoadRunner, which is a performance and 
load testing tool. 
The paper starts by giving information on load testing 
and 
load 
testing 
metrics, 
then 
introduces 
testing 
environment. In fourth section, load testing results are 
given. Finally, the results obtained in this research are 
discussed. 
II. 
LOAD TESTING 
A. Load Testing 
The analyze of the performance of the web-based system 
can be achieved using load testing and/or performance 
modeling approaches. Load testing is carried out to 
determine a system’s behavior under both normal and 
expected peak load conditions. It helps to identify the 
maximum operating capacity of an application such as any 
bottlenecks and determine which element is causing 
degradation. 
B. Load Testing Metrics 
1) Response Time: Response time is a time defined by 
interval between client request and response from server. 
Response time is the key software performance metric for 
server-client applications. 
 
2) Error Rate: Error Rate is the mathematical 
calculation that produces a ratio of unanswered requests to 
all requests. The percentage reflects how many responses 
are HTTP status codes indicating an error on the server, as 
well as any request that never gets a response. Error Rate is 
a significant metric because it measures “performance 
failure” in the application. It tells how many failed requests 
61
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-307-0
VALID 2013 : The Fifth International Conference on Advances in System Testing and Validation Lifecycle

are occurring at a particular point in time of your load test 
[7]. 
 
3) Client-side Resource Utilization (CPU Usage and 
Memory Consumption) 
CPU usage is the amount of CPU time used by the Web 
Service while processing the requests and memory 
consumption is the amount of memory used by the Web 
Service while processing the requests.  
III. 
TEST ENVIRONMENT  
To measure dependencies of the search engine according 
to the intended use, a simple scenario was chosen. Scenario 
steps are provided below: 
 
Open browser 
 
Enter search engine address 
 
Type “wikipedia” query string 
 
Click search button 
 
Click “http://www.wikipedia.org/” address 
The scenario contains three transactions that are opening 
search engine, searching and redirection to Wikipedia. It has 
been run for 1000 concurrent users for all cases. Concurrent 
users mean that all of users send their requests to the server 
at the same time. 
This scenario was run for three search engines that are 
Google, Yandex and Bing according to two criteria, which 
are network bandwidth and Internet browsers. These 
Internet browsers are Google Chrome, Internet Explorer, 
Mozilla Firefox versions of which are supported HP 
LoadRunner. For the other case, two different network 
bandwidth values were selected: 1.5 Mbps (Asymmetric 
Digital Subscriber Line-ADSL) and 10 Mbps. Windows 
Performance Monitor application is used to measure CPU 
and RAM usage ratios. 
Testing environment consists of a PC hardware that runs 
LoadRunner 11.5 testing tool. The technical characteristics 
of this PC are: 
 
Intel i5 CPU @3.2 GHz 
 
4 GB RAM 
 
64-bit operating system 
 
Windows 7 Professional 
IV. 
EXPERIMENTAL RESULTS 
In this study, in order to compare dependencies of search 
engines, load test scenario was run on two different cases. 
These are Internet browser and network bandwidth. 
A. Internet Browser 
The reason for choosing the browser is to understand 
whether speed of search engines depends on Internet 
browser or not. 
Load test results of selected search engines are given in 
Table I, Table II and Table III for different browsers.  
LoadRunner computed average response times of each 
transaction and we computed average response time that are 
given in Tables I-III as linear average of three transactions 
for each Internet browser. 
TABLE I.  
BING PERFORMANCE COMPARISON  
Bing 
Search Engines 
Google Chrome 
IE 
Mozilla Firefox 
CPU 
15% 
13% 
11% 
RAM 
38% 
36% 
40% 
Average 
Response 
Time (s) 
2,547 
1,946 
2,359 
Error Rate 
0,122 
0,002 
0,007 
a. 
At 10 Mbps network bandwidth 
TABLE II.  
YANDEX PERFORMANCE COMPARISON 
Yandex 
Search Engines 
Google Chrome 
IE 
Mozilla Firefox 
CPU 
23% 
15% 
12% 
RAM 
38% 
33% 
33% 
Average 
Response 
Time (s) 
2,102 
2,101 
1,979 
Error Rate 
0,0003 
0 
0,0003 
a. At 10 Mbps network bandwidth 
TABLE III.  
GOOGLE PERFORMANCE COMPARISON 
Google 
Search Engines 
Google Chrome 
IE 
Mozilla Firefox 
CPU 
22% 
22% 
20% 
RAM 
39% 
39% 
40% 
Average 
Response 
Time (s) 
3,368 
3,417 
3,143 
Error Rate 
0 
0 
0 
a. At 10 Mbps network bandwidth 
In Table I, load test results for Bing are shown. 
According to Table I: 
 
In terms of the use of PC resources, it is observed that 
Bing used CPU at least on Mozilla Firefox. 
 
In terms of the use of average response time, it is been 
observed that Bing was the fastest search engine 
running on IE. 
 
It is observed that errors in Bing are arised respectively 
due to the server and timeout period (LoadRunner 
timeout period: 120 s.). 
In Table II, load test results for Yandex are shown. 
According to Table II: 
 
In terms of the use of PC resources, it is observed that 
Yandex used the least CPU on Mozilla Firefox. 
62
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-307-0
VALID 2013 : The Fifth International Conference on Advances in System Testing and Validation Lifecycle

 
In terms of the use of average response time, it is 
observed that Yandex was the fastest search engine 
running on Mozilla Firefox. 
In Table III, load test results of Google are shown. 
According to Table III: 
 
In terms of the use of average response time, it is 
observed that Google was the fastest search engine 
running on Mozilla Firefox. 
As a result, with regard to above statements, it can be 
considered that search engines’ performance depend on 
Internet browser. 
B. Network Bandwitdh 
Network bandwidth used by the Internet user determines 
the speed of download and upload and is a parameter 
considered in the load test. 
At first, widely used by the Internet users for network 
bandwidth ADSL (1.5 Mbps) is selected. Secondly, for 
putting forward dependence of search engines to network 
bandwidth, 10 Mbps, nearly ten times ADSL is selected.  
The comparisons of 10 Mbps and ADSL for search 
engines are shown in the following tables. 
We computed average response time that are given in 
Tables IV-VI as linear average of three transactions’ 
average response times by LoadRunner for each Internet 
browser. 
 
TABLE IV.  
BING PERFORMANCE COMPARISON 
Bing 
Internet Browsers 
Chrome 
IE 
Firefox 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
CPU 
14% 
15% 
14% 
13% 
14% 
11% 
RAM 
39% 
38% 
36% 
36% 
39% 
40% 
Average 
Response 
Time (s) 
3,117 
2,547 
2,921 
1,946 
3,04 
2,359 
TABLE V.  
YANDEX PERFORMANCE COMPARISON  
Yandex 
Internet Browsers 
Chrome 
IE 
Firefox 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
CPU 
25% 
23% 
28% 
15% 
26% 
12% 
RAM 
38% 
38% 
44% 
33% 
36% 
33% 
Average 
Response 
Time (s) 
2,405 
2,102 
2,416 
2,101 
2,35 
1,979 
TABLE VI.  
GOOGLE PERFORMANCE COMPARISON  
Google 
Internet Browsers 
Chrome 
IE 
Firefox 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
CPU 
22% 
22% 
21% 
22% 
22% 
20% 
Google 
Internet Browsers 
Chrome 
IE 
Firefox 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
ADSL 
10 
Mbps 
RAM 
40% 
39% 
30% 
29% 
40% 
40% 
Average 
Response 
Time (s) 
3,7 
3,368 
3,466 
3,417 
3,731 
3,143 
 
In Table IV, it is observed that the decrease in network 
bandwidth only caused an increase in response time. In 
other words, we could say that Bing is slowed down when 
bandwidth is reduced. 
In Table V, it is shown that when network bandwidth is 
reduced, CPU utilization of Yandex increased in IE and 
Firefox browsers. Also, it is observed that an increase in 
network bandwidth caused lower RAM usage by Yandex in 
IE and lower response times in all browsers. 
In Table VI, it is observed that the decrease in network 
bandwidth only caused an increase in response times. 
As a result, in terms of PC resource usage and speed, 
Yandex depends on network bandwidth. In terms of speed, 
Google and Bing browsers can be considered to be 
depended on network bandwidth. 
C. Comparing Search Engines in Point of Transactions 
The scenario contains three transactions that are opening 
search engine, searching and redirection to Wikipedia. The 
comparison of the transactions is given in Table VII.  
We computed average response time that are given in 
Table VII as linear average of three Internet browsers’ 
average 
response 
times 
by 
LoadRunner 
for 
each 
transactions. 
 The curves of variation of transactions’ response time 
due to elapsed time for Google, Yandex and Bing are given 
in Fig. 1, Fig. 2, and Fig. 3, respectively. 
TABLE VII.  
TRANSACTION PERFORMANCE COMPARISON  
Average 
Response 
Time (s) 
Transactions 
 
Opening Search 
Engine 
 
Searching 
 
Redirecting 
Bing  
4,058 
0,682 
2,11 
Yandex 
2,995 
1,467 
1,720 
Google 
1,036 
0,794 
8,412 
a. 
At 10 Mbps network bandwidth 
According to opening search engine transaction, Google 
can be considered the fastest search engine. For searching 
transaction, it is observed that Bing and Google are faster 
than Yandex. By redirecting transaction, Google is said to 
be the slowest search engine. The reason for Google’s slow 
redirecting is when user clicks the link, Google firstly send 
user their own servers to get information for their ranking 
algorithms and then provide the connection to selected link. 
63
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-307-0
VALID 2013 : The Fifth International Conference on Advances in System Testing and Validation Lifecycle

V. 
CONCLUSION AND FUTURE WORK 
In this paper, we aimed at presenting search engine 
performances’ dependencies on network bandwidth and 
Internet browsers. We evaluated client-side performance of 
search engines for load testing. 
As a result of load testing, it is observed that search 
engines’ performance depend on Internet browser and 
Google is the least dependent on Internet browsers.   
As network bandwidth increases, the utilization of PC 
resources by search engines decreases and speed of search 
engines increases as expected. However, usage of PC 
resources by Yandex increases. In this instance, Yandex is 
the most dependent on network bandwidth.  
In future study, in addition to client-side load testing, it is 
planned to evaluate the behavior of the server during load 
testing. 
ACKNOWLEDGMENT 
The authors would like to thank Software Testing and 
Quality Evaluation Center (YTKDM in Turkish) of 
Scientific and Technological Research Council of Turkey 
(TUBITAK in Turkish) for funding this study. 
 
 
 
REFERENCES 
[1] J. A. Meira, E. C. d. Almeida, Y. L. Traon, and G. Sunye, 
"Peer-to-peer Load Testing," Proc. IEEE Fifth International 
Conference on Software Testing, Verification and Validation 
(ICST), 
April 
2012, 
pp. 
642 
– 
647, 
doi: 
10.1109/ICST.2012.153. 
[2] O. Hamed and N. Kafri, "Performance Testing for Web Based 
Application Architectures (.NET vs. Java EE)," Proc. First 
International Conference on Networked Digital Technologies 
(NDT), 
July 
2009, 
pp. 
218 
– 
224 
doi: 
10.1109/NDT.2009.5272178 . 
[3] A. Habul and E. Kurtovic, "Load Testing an AJAX 
Applications," Proc. 30th International Conferenece on 
Information Technology Interfaces (ITI 2008), June 2008, pp. 
729-732, doi: 10.1109/ITI.2008.4588501. 
[4] B. Beizer, Software System Testing and Quality Assurance, 
2nd ed., Van Nostrand Reinhold, 1894, pp. 218-250. 
[5] Z. M. Jiang, A. E. Hassan, G. Hamann, and P. Flora, 
"Automatic Identification of Load Testing Problems," Proc.  
IEEE International Conference on Software Maintenance 
(ICSM 
2008), 
Sept.-Oct. 
2008, 
pp. 
307-316, 
doi: 
10.1109/ICSM.2008.4658079. 
[6] P. Yunming and X. Mingna, “Load Testing for Web  
Applications,” Proc. 1st IEEE International Conference on 
Information Science and Engineeering (ICISE), Dec. 2009, 
pp. 2954-2957, doi: 10.1109/ICISE.2009.720. 
[7] http://loadstorm.com/load-testing-metrics/, 2013. 
 
 
 
 
 
 
 
 
Figure 1.  Opening search engine transaction response time. 
64
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-307-0
VALID 2013 : The Fifth International Conference on Advances in System Testing and Validation Lifecycle

 
Figure 2.  Searching transaction response time. 
 
Figure 3.  Redirection to Wikipedia transaction response time. 
 
65
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-307-0
VALID 2013 : The Fifth International Conference on Advances in System Testing and Validation Lifecycle

