Project Management for Online Course Quality Management 
Brayden Milam, Julie R. Newell, Stephen Bartlett, Tamara Powell, Kaylee Polk, Elly Sloman, Aiden Reichner, Lesley Gabel 
Norman J. Radow College of Humanities and Social Sciences, Office of Digital Education 
Kennesaw State University, Kennesaw, Georgia, USA 
Email: bmilam3@kennesaw.edu, jnewell2@kennesaw.edu, sbartlet@kennesaw.edu, tpowel25@kennesaw.edu, 
kpolk7@students.kennesaw.edu, esloman@students.kennesaw.edu, areichne@students.kennesaw.edu, lgabel@kennesaw.edu 
 
Abstract— Post-pandemic, a requirement that online courses 
be certified for accessibility and meet federal guidelines for 
instructional equivalency created a backlog of courses that 
needed to be processed quickly and efficiently. This situation 
was particularly acute in the Radow College of Humanities 
and Social Sciences, the largest College at Kennesaw State 
University, and its 11 component schools and departments. 
Without the availability of increased staff or funding, 
efficient workflow management systems needed to be 
established quickly and using software already available at 
the institution. Team members developed the “Bucket 
System” based on multiple components of Microsoft 365 to 
map and track workflows across multiple criteria and 
multiple reviewers. This paper builds on a previous 
presentation by exploring existing project management 
methodologies and expanding on how the team built their 
framework, software system, and supplementary tools to 
meet needs specific to higher education institutions.  
Keywords-course review; online course quality; project 
management methodology (PMM); monitoring and evaluation 
(M&E) framework; Microsoft 365. 
I. 
INTRODUCTION 
This project, first presented at eLmL 2022: The 
Fourteenth International Conference of Mobile, Hybrid, 
and On-line Learning [1], originally detailed a year-long, 
large-scale course quality review endeavor conducted by 
the Office of Digital Education (ODE) in the Radow 
College of Humanities and Social Sciences (RCHSS) at 
Kennesaw State University (KSU), a public university in 
metro-Atlanta, Georgia. In summer 2022, shortly after the 
conference we presented our findings at, college and 
university leadership decided to reassign the course review 
process to the university-level equivalent of the ODE. 
While no further data was collected, this paper explores 
the existing project management methodologies consulted 
during our initial conversations and expands on how our 
team built the framework, software system, and 
supplementary tools we used to support the process we 
developed.  
In 2018, KSU President Pamela Whitten chose to 
discontinue the requirement of Quality Matters (QM) 
Certification for all online classes. Colleges within the 
university could still require quality control, but it was left 
to college leadership to decide if and how to implement 
this control. RCHSS continued to offer training and 
certification options for those departments requesting 
support. Training and certification were also built into 
compensation contracts offered by the college. Despite 
these continued options, the college decided to allow the 
requirement for instructor and course certification to lapse.  
Instead of following QM, which cost money and 
received opposition from faculty resistant to the latest 
version update, digital education experts in what was then 
the Distance Learning Center partnered with faculty to 
develop a set of standards that fit the university’s needs 
and aligned with best practices. This process ultimately 
resulted in the KSU Course Quality Checklist (KSU CQC) 
and was approved through various shared governance 
bodies. While some colleges chose to remain with QM 
(after memberships were provided through the University 
System) and others developed their own rubrics, the KSU 
CQC was adopted across multiple colleges at the 
university and has become the standard quality measure in 
RCHSS in instances when course review is required.  
When the pandemic hit in March 2020, the focus 
across KSU shifted from offering high quality courses to 
simply offering courses. Suddenly, everyone needed to be 
online. Professional development shifted with the needs of 
faculty and training facilitators as they struggled alike to 
adapt to the relatively new modality of synchronous online 
education. The nearly four-month period of online-only 
education at the start of the pandemic allowed 
misconceptions about online teaching and learning to 
spread as digital learning experts scrambled to teach basics 
to faculty with little-to-no online experience. Then, in Fall 
2020, as the return to campus began, faculty were expected 
to teach in various rotational and hybrid formats with 
many having had little-to-no training in these new 
modalities. This trend continued into Spring 2021, with a 
complete return to campus planned for Fall 2021. By this 
point, the combined effects of eliminating required 
instructor and course certification for online offerings and 
unsound pedagogical approaches created by pandemic 
pandemonium were beginning to manifest in student 
complaints about the quality of online education. Studies 
[2][3][4] show “(1) stress and negative emotions 
increased, (2) positive emotions, enjoyment with class, 
satisfaction with class decreased, (3) engagement 
decreased, and (4) extroverts and those who prefer on 
campus classes were impacted the most by the conversion 
to online [2].” 
The authors first present a description of the context 
and magnitude of the challenge to be addressed. The paper 
then details the project management system developed to 
facilitate the workflow of the overall process and the 
ancillaries intended to help faculty master the skills 
necessary to have all courses certified by the university’s 
deadlines. 
14
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

II. 
OVERVIEW AND RATIONALE 
After a change in leadership in July 2021, KSU’s 
Office of the President charged the Division of Curriculum 
and Academic Innovation (CAI) with ensuring that all 
digital course content met recently updated federal 
guidelines and the University System of Georgia Board of 
Regents policy on accessibility standards and sustained 
instructor interaction. Each college, in turn, was asked to 
submit a review procedure for all online and hybrid 
courses. While many colleges already possessed the 
requested review procedure, the lack of required review 
since 2018 meant RCHSS was faced with creating and 
implementing a new review process in a limited window 
of time.  
A. The RCHSS Proposal 
The RCHSS ODE solicited input from faculty and 
college administrators and created three plans for 
reviewing asynchronous online, synchronous or hybrid 
online, and template courses (defined as courses created in 
entirety by faculty designers but taught by other course 
facilitators). These processes were then vetted through the 
appropriate college faculty governance channels. The CAI 
charged each college with developing and implementing 
their plans by the start of Spring 2022, which gave the 
ODE team roughly five and a half months to solicit 
feedback, adapt the KSU CQC for hybrid and template 
courses, update faculty certification trainings, and develop 
all 
tools 
(including 
communication 
and 
project 
management tools) needed to implement the initial two-
year review cycle. No new resources were provided at the 
university or college level to support this initiative.  
B. A Larger College, a Larger Problem 
The five-month implementation timeline and two-year 
review timeline were reasonable for most other colleges at 
KSU. However, RCHSS is, by far, the largest college on 
campus, with 425 faculty and 8,500 students enrolled in 
majors within the College. Additionally, RCHSS is 
responsible for eight of the fourteen general education 
standards required for institutional accreditation. As shown 
in Figure 1, of those eight standards, the college offers 50 
different courses that can be completed to fulfill the 
requirements, compared to 22 courses offered by a mix of 
the Coles College of Business, the College of Science and 
Mathematics (CSM), and the College of the Arts (COTA) 
across the remaining six standards. In Fall 2021, RCHSS 
offered 35% of undergraduate course sections and 41% of 
graduate course sections, totaling 750 sections, in the 
online modality (Figure 1). 
Of the eleven departments and schools in RCHSS, two 
have completely rejected the idea of template courses 
outside of use for emergency hires, and two regularly use 
template courses. The remaining seven departments 
reserve template courses for adjunct and emergency use 
only. This practice contrasts with other colleges at the 
university. For the most part, other colleges only utilize 
template courses or are so limited in size as to require one 
or two course builds to meet class section needs. Because 
RCHSS is focused on disciplines in the humanities and 
social sciences, RCHSS has dozens of sections of one 
course, all with unique designs, to allow faculty to teach to 
their strengths and provide their expertise to students. For 
example, many faculty teach American literature online, 
and yet each professor has a different specialization; one 
professor might be an expert on African American 
literature in the 19th century and build his/her/their course 
around those authors, while another might focus on Gothic 
authors in the American South, which could produce a 
thematically similar course with content drastically 
different from his/her/their colleague. When each faculty 
member creates his/her/their course according to best 
practices and capitalizes on his/her/their area of expertise, 
students get the best instruction and experience. This, of 
course, contrasts to programs taught in other colleges that 
are built around state/national/international accreditation 
standards, which often utilize a specific curriculum across 
all course sections. Additionally, bespoke course designs 
allow for continued variety in perspective and approach, 
avoiding some of the pitfalls of intellectual and cultural 
homogenization.  
The ODE team had little time to prepare for this 
project and had no formal structures or tools in place to 
accommodate a project this large. The structures and tools 
previously used to review courses on a training basis 
needed to be adapted to accommodate a higher volume of 
course designs reviewed in a shorter amount of time.  
 
It takes an average of three to five hours to review each 
course, contingent on the course content and approach. 
Based upon pre-pandemic numbers, the team had 
anticipated reviewing a total of approximately 750 courses 
over a two-year period. In spring 2022, we expected 135 
courses to be submitted for review. 192 courses have been 
submitted. Projected forward, we are now anticipating 
reviewing around 1000 courses over the next two years 
using a team of two instructional designers, three faculty, 
and four student assistants.  
The most comparable project underta”en b’ the team 
was a review of 115 partial courses across a seven-month 
period, which was tracked in an Excel spreadsheet. At the 
time, our team consisted of one instructional designer, two 
faculty, and two senior student assistants, and all were able 
to assist in the review process.  
III. 
PROJECT MANAGEMENT SOFTWARE 
A. Possible Paths Forward 
Knowing the scope of the project, we began to look at 
how we would manage our end of the course review 
process:  
1. Conducting the initial course review,  
2. Sharing the feedback written during each 
review with the faculty designer so they could 
make changes, 
15
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

3. Assisting the faculty designer with any 
technology issues they ran into during their 
changes,  
4. Re-reviewing the course after appropriate 
changes had been completed, 
5. Submitting the course to the institutional 
database managed by CAI. 
 
RC
COLES
CSM
KSU Undergraduate Co
 
Curriculum Offerings
  
Hybrid
RCHSS Undergraduate Co
 
Sections By Modality 
 
Figure 1. Three charts showing the division of courses across KSU and 
within the college.  
We had three factors to consider when developing our 
workflow [5]. First, we needed to abide by the processes 
put forth by the departments in our college. Because our 
college is so large, the RCHSS Digital Education Council 
requested that each department be allowed to submit their 
own process to us. The outcomes from this request were 
varied: seven departments decided to defer to the ODE and 
have us carry out all reviews; one department decided to 
do the same but added additional faculty support by way 
of a mentoring committee to assist faculty designers with 
updating their courses to meet the reviews put forth by the 
ODE team; and three departments decided to conduct all 
parts of the review, with minimal support from the ODE.  
Second, our undergraduate student assistants are only 
able to conduct the accessibility portion of the review, not 
to make decisions concerning content and pedagogy. One 
section of the KSU CQC is dedicated to digital 
accessibility. The review process for this section is very 
clinical, so it can be completed by students without years 
of instructional design experience.  
Third, the sheer number of courses was overwhelming 
to a team with only five people qualified to evaluate entire 
courses. Department schedulers indicated a slow return to 
pre-pandemic scheduling practices, so we estimated that 
we would need to review 135 courses across the Spring 
2022 semester. We were wary of more “traditional” 
project management methodologies (PMM) that required 
adherence to strict procedures, given the ever-changing 
nature of our institution and the natural progression of 
shared governance proceedings that might affect RCHSS’s 
course review policy. At the same time, we knew that the 
CAI was planning for this process to be a multi-year 
undertaking, scaffolded by course level (e.g., 1000-level 
courses were reviewed in Spring 2022, 2000- and 3000-
level courses would be reviewed in Fall 2022, 4000- and 
5000-level courses would be reviewed in Spring 2023, and 
so on through upper-level undergraduate and then graduate 
courses). This would require us to reevaluate at the end of 
each semester with the little downtime that classes were 
not in session, 9-month faculty were not on contract, but 
that the University was still open.  
 
 
Figure 2. Screenshot of the "Bucket System" dashboard. 
 
As previously stated, our most comparable undertaking 
was tracked in a spreadsheet and was conducted when our 
team was half the current size. Initial research about 
implementing PMM revealed some of our own 
hesitations: fear about unforeseen changes in policies that 
our office would have to coordinate; implementing a 
structured process in a naturally flexible and collaborative 
office; and an unfamiliarity with how to manage every 
document and piece of data we needed to track [6]. 
Further, reviews [7] indicated that they were “more 
adequate to be implemented in larger and more complex 
projects… [while] agile methodologies… are more 
suitable… for some smaller and less complex projects We 
looked more closely at agile methodology and found 
better matches for our needs with the SCRUM approach, 
16
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

which emphasizes teamwork and accountability and 
meshes flexibility with repetitive process [8]. The only 
problem was that length of our “sprints” would follow a 
semesterly pattern—nearly triple the length recommended 
by experts [8].  Essentially, we would be able to utilize 
most aspects of a SCRUM framework, but we would need 
to expand our timeline and build in some added 
flexibility.   
 
 
Figure 3. A screenshot of the tagging system the ODE utilizes within the 
bucket system. 
 
We decided that the reevaluation/sprint process would 
instead follow a monitoring and evaluation (M&E) 
framework [9], which is typically implemented to track 
large-scale resources and goods for government agencies 
and non-governmental organizations (NGOs). In our case, 
neither the university nor the college could commit any 
additional resources, and the ODE had very little 
resources of our own. Instead of having the typical 
outputs, outcomes, and impacts of resource development, 
our outputs would be course reviews, outcomes would 
focus on bringing courses up to meet the course quality 
standards set by the federal government and the 
University, and the impact would be approved courses 
(ideally leading to improved retention and graduation 
rates, though these would not be tracked by the ODE).  
After reading and watching project management 
software (PMS) reviews and testimonies from other higher 
education teams [10][11], the team met and compiled a list 
of the features we would need.  
• 
Access for at least 10 people 
• 
Reporting functions  
• 
Ability to connect files to a task 
• 
Ability to assign tasks 
• 
Ability to create subtasks 
• 
A visual marker for where the course was in 
the review workflow.  
 
Our team also decided that we preferred a more visual 
interface, as opposed to a simple task list. A 
comprehensive literature shows [12] that “creative 
discovery processes are almost never structured and 
require lots of interaction with the data.” Because this 
process was new and we knew that we would need a 
comprehensive understanding of our workflow to both 
increase efficiency and advise College and University 
leadership, we wanted to ensure that we had a holistic 
view at the ready.  
Most importantly, all of this needed to be located in a 
no-cost or extremely low-cost tool. PMS like Slack [13], 
Trello [14], and ClickUp [15] had been utilized by the 
team before but required monthly subscriptions for large 
projects. Open-source PMS like OpenProject [16] and 
Focalboard [17] all had the key features the ODE team 
needed but also had annual hosting costs, usually upwards 
of $150USD. Products offered by ServiceNow [18], BMC 
[19], and IBM [20] were much more robust than needed 
for this one project, so they were not considered.  
B. “The Bucket System” 
After developing our list of wants and needs, we 
developed an original system we have christened as the 
“Bucket System.” Our system was devised to be hosted in 
existing PMS and as an easy way to physically move items 
along in a workflow, while also providing more flexibility 
than an Excel spreadsheet. The team devised a plan to 
build something similar to other tools by utilizing various 
Microsoft applications, as the University had recently 
moved to Microsoft 365 [21]. This project management 
tool would be modeled after existing tools [22] but would 
be customized to our specific needs.   
 
 
Figure 4. Screenshot showing how tasks become invisible once marked 
"complete." 
 
Microsoft Planner had the tools we would need at a 
task-management level (file connection, task assignment, 
reporting functions, and subtasks) and had several layout 
options. It was also integrated with Microsoft Teams—
which would create a localized “dashboard”—and Power 
Automate, Microsoft’s backend automation and workflow 
application, which would be crucial in populating the 
system. Microsoft Lists had similar functions—and the 
bonus of custom metadata fields—but lacked the visual 
layout we wanted. Ultimately, the goal was to produce a 
Kanban-like system of workflow visualizations, as we 
unfortunately did not have the luxury of limiting work in 
progress (WIP) that was required in a true Kanban system 
[23]. Microsoft Planner utilizes columns called “buckets” 
and projects called “cards” (Figure 2). Each bucket 
represents a step in the workflow, and each card within a 
bucket represents an individual course. Additionally, we 
could 
follow 
a 
loose 
interpretation 
of 
SCRUM 
methodology with built in data visualization, which 
17
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

allowed us to catch up on what had been completed, by 
whom, and what obstacles people were facing. 
 
 
Figure 5. A course review card showing the light green “in D2L tag,” a 
completed checklist, attached documents, and comment trail. 
 
Within the cards, we initially utilized the tag feature to 
indicate whether ODE directors had access to the course in 
the LMS (and, thus, had the ability to add reviewers) and 
whether the course was undergoing a “recheck” or re-
review. We ultimately added a tag to mark course reviews 
as finished because we initially lost courses that had been 
dismissed as “complete” (Figures 3 and 4). 
We also use the comment section to create a 
documentation trail regarding when communication had 
been sent to faculty. The team found that using the “start 
date” feature did little to help prioritize courses, as 
Planner does not offer a “start date” option under the 
sorting tool. We instead pivoted to using the “due date” 
feature, which had the bonus of posting the date on the 
card. This all creates an easily accessible history of what 
courses have been reviewed, where they are in the 
process, and who has completed what (Figure 5). 
After building the process in planner, the decision was 
made to integrate the structure with Microsoft Forms, 
which would allow faculty to submit “review requests.” 
We reviewed the Certified Course Build SmartSheet 
developed by the CAI, which was designed to track 
courses certified according to quality standards and 
included key questions on our Form (Figure 6). 
Originally, we created one Form for all of RCHSS. As we 
tested the process, we discovered we needed individual 
Forms for all eleven departments and schools. This 
decision was made to minimize confusion, as we initially 
offered too many review-customization options on a 
single form, and to streamline the automation process. 
The automation process is as follows: a faculty member 
fills out a form, Power Automate pulls information from 
the Form to generate a Planner card in the correct bucket 
and then sends a personalized confirmation email to the 
faculty member (Figure 7).  
 
Figure 6. The first page of the Review Request Form for the Department 
of Psychological Science. 
After the faculty member has added the ODE directors to 
their course shell, the formal review process begins. At 
the beginning of each week, the ODE Associate Director 
assigns courses to ODE reviewers (instructional designers 
and faculty) and student assistants depending on the 
courses available for review. Instructional designers and 
faculty prioritize courses taught by departments with their 
18
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

own review process, while student assistants complete 
accessibility reviews for courses that are reviewed by the 
ODE in full. The instructional designers and faculty then 
complete sections A and B of the review for the courses 
assigned to them, which require greater familiarity with 
digital accessibility standards and state and federal 
mandates, respectively. They then pass the course along 
to the department liaison/representative so the department 
can finish the rest of the review. Alternately, students 
complete section A of the review, which only requires 
familiarity with standards of digital accessibility, for the 
courses assigned to them. After the accessibility review 
has been completed, students pass their reviews on to the 
ODE instructional designers and faculty, who complete 
the rest of the review.  
 
 
Figure 7. The automated process behind the Psychological Science 
Request Form, built with Power Automate. 
 
Following the completion of the initial review, the 
review documents are sent to the faculty designer. The 
faculty designer then works to make the appropriate 
changes and consults with ODE team members (or their 
department liaisons) if they need assistance. After the 
appropriate changes have been made, the course 
undergoes a secondary review. If the course passes this 
review, the review documents will then be sent to the 
department chair for approval. If the course does not pass 
the review, the revision process begins again. This 
revision process may be completed up to two times before 
the course is removed from the queue. If it is removed 
from the queue, the chair must request reactivation and 
the faculty designer must resubmit the course to be 
reviewed without priority.  
Once a course is approved by the department chair, the 
ODE Director submits the course to the CAI’s Certified 
Course Design SmartSheet and notifies the program 
coordinator, who updates the public-facing spreadsheet 
maintained by the ODE. As of Spring 2022, this process 
is set to repeat on a five-year cycle. The initial review 
cycle is based on course level, so all existing courses will 
have completed the review process by December 2023 
and been scheduled for their next re-review.  
C. Supplemental Tools for the Team 
The most refined and evaluated portion of our review process involved 
managing individual workloads. To contend with the sheer number of 
courses, we developed clinical language guides for our accessibility 
reviewers and fillable documents for our content equivalency reviewers. 
 
Figure 8. An Accessibility Check Template, with verbiage available to 
copy and paste into communications with faculty members.  
 
 
The language guides were developed first, as the first 
step of our end of the review process. Our student 
assistants were trained in reviewing digital materials for 
accessibility (e.g., ensuring videos had intelligible 
captions, documents contained heading structures, color 
contrast was appropriate, etc.). Ms. Milam, the staff 
expert on accessibility and a former ODE student 
assistant, worked with Sam Lee to develop a template in 
January 2021. By the time the reviews were well 
underway, she and Kaylee Polk worked to adapt the 
language in the template into a guide (Figure 8), so that 
students could copy and paste language to help faculty 
address the issues at hand. Each software supported by 
KSU (all Microsoft Office products, D2L, Adobe 
Acrobat, and Kaltura MediaSpace) had a section with 
professional, courteous language instructing the faculty 
designer of the issue and providing resources on how to 
solve it. The language was then pasted into the final 
review document with information about where the issue 
was 
located 
(the 
weekly 
or 
unit 
folder—called 
“modules”—along with the document name).  
19
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

After developing the language guides, the content 
equivalency 
reviewers 
began 
developing 
fillable 
documents (Figure 9) for their own use. Three of these 
documents were created: one for asynchronous online 
courses, one for hybrid and synchronous online courses, 
and one for on-site/face-to-face courses. Each document 
utilized MS Word’s checkbox, content controls, and 
grouped text features to create a mix of “locked” content 
and “fillable” content. This was to ensure that faculty 
received an accessible, standardized document with direct 
yet courteous language to assist them through the review 
process. 
 
Figure 9. The KSU Course Quality Checklist converted into a fillable 
document in MS Word, created with Content Controls. 
IV. 
TOOLS FOR SHAREHOLDER INVOLVEMENT 
Our most important shareholders in this process were 
faculty. To initiate a review, faculty must submit their 
courses for review, request new course shells for each 
course review needed, and add the ODE directors to the 
new course shells. We wanted to streamline the process as 
much as possible to make it as simple as possible for 
faculty, so as not to induce confusion or increase their 
workloads. The simple form and automated email 
accomplished most of these goals. We kept the forms as 
simple as possible, included tutorials on how to request, 
copy, and add the ODE directors to the course shells in 
Brightspace D2L, our learning management system; 
eliminated an additional step of communication by 
requesting faculty utilize the enrollment notification option 
in D2L; and added a layer of familiarity with 
personalization tools [24]. Ultimately, we have received 
positive, anecdotal feedback from faculty about how easy 
the process is. 
A. The Course Review Dashboard  
The ODE decided to anticipate the needs of faculty and 
create resources to aid them in the course review process. 
The 
primary 
resource 
was 
the 
“Course 
Review 
Dashboard,” which functions as a one-stop-shop for all  
 
After consulting with the RCHSS Digital Education 
Council, the ODE found that the new emphasis on 
accessibility requirements made syllabi templates more 
desired by faculty. Again, lockability remained the greatest 
difficulty, as faculty would frequently mistakenly render 
ADA compliant syllabi inaccessible by altering certain 
document features. After many hours of research, the team 
was able to use Microsoft Word to develop a “lockable” 
template, much like the fillable document mentioned 
earlier, that met accreditation and accessibility standards 
but remained customizable enough to allow for academic 
freedom. The team also worked with the First-Year 
Composition (FYC) program to develop two syllabi 
specifically for use in ENGL 1101: Composition I and 
ENGL 1102: Composition II, two courses all students are 
required to complete prior to graduation. These templates 
were created with a variety of Developer Tools, including 
content controls and “lockable” groups, and general 
accessibility tools, like Styles and list/table structures.  
V. 
CONCLUSION 
With varying requirements across the eleven schools 
and colleges that comprise the Radow College, the 
unexpectedly high number of course submissions, and the 
need to validate review practices and feedback information 
across reviewers, much fine-tuning of the Bucket System 
is still in progress. The overall system, however, is proving 
to be robust and flexible while providing consistent 
tracking and information capture. things related to course 
reviews, including tutorials, policies and checklist criteria, 
review request forms, and contacts. This project was 
designed to be far-reaching and creative. We knew the 
website needed to be easy to navigate and user friendly, 
but we also knew how expansive the topics and resources 
needed to be. We ultimately built eight pages hosted on the 
site and built an additional site specifically for course 
reviewers within the departments. We also completely 
redesigned our tutorial library, which hosted 115 simple 
technology and software tutorials, for a cleaner interface 
with a more visual navigation structure (Figure 9).  
A. Syllabus Templates  
With a great deal of the accessibility and quality 
checklist requirements focused on course syllabi, a 
significant need for an accessible syllabus template arose. 
The need to include an ever-increasing number of policies 
and links to student success tools had placed syllabi 
templates at the forefront of academic concerns of the 
university for well over a decade. The updated federal 
guidelines and University System of Georgia Board of 
Regents policy only increased the urgency in addressing 
this need. The greatest difficulty was in “locking” the 
template so that required items could not be altered or 
deleted while keeping the remainder of the document open 
for editing by the instructor. An early attempt at an 
electronic solution to the syllabus template issue ended in 
a costly failed attempt to partner with a professional 
technical company. Further attempts at a lockable form 
were abandoned.  
20
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Because the Bucket System is built on components of 
Microsoft 365 and accessed through familiar interfaces, 
the time required to learn to use the system effectively is 
far shorter than would be the case using other software 
tools to manage the same project. Bringing new reviewers 
or content specialists online is also simplified, with no 
need to obtain additional software licenses or install 
additional software. It also bridges seamlessly across units 
within the College and across the University as needed.  
 
 
 
Figure 10. Two screenshots showing the Tutorial and Course Review 
Dashboard websites. 
 
The Bucket System has been adapted across multiple 
course review efforts and departmental processes. Each 
department with their own review process has a system 
customized to their needs, including one built for the 
university-level equivalent of ODE. For example, the 
faculty member designated as the Hybrid Specialist in the 
ODE is piloting an adaptation of the Bucket System to 
track and manage a grant-funded Open Educational 
Resource (OER) project. Currently, this version of the 
Bucket System functions more as a task board but will be 
adapted at the conclusion of the OER’s pilot semester 
(Spring 2023) into a ticketing system for instructors to 
provide feedback and request support from the original 
grant team on any issues that may present. Using the 
Bucket System in this way will allow for data collection, 
as the team plans to build in survey software and track 
open feedback and support tickets. Additionally, the 
Bucket System is being used as an event management tool 
by RCHSS’s Office of the Dean. This version of the 
Bucket System more closely mirrors the original version. 
Each event hosted by the College has a dashboard, is used 
for knowledge management, task completion, budget 
tracking, contact tracking, and collects data that feeds into 
a more comprehensive data visualization page. The Office 
of the Dean plans to duplicate the system at the end of the 
fiscal year to use for future years.  
REFERENCES 
[1] B. Milam, T. Powell, J. R. Newell, S. Bartlett, L. Gabel, K. 
Polk, E. Sloman, A. Reichner, “Using the Tools at Hand: 
Creative Online Course Quality Management,” In The 
Fifteenth International Conference on Mobile, Hybrid, and 
On-Line Learning (June 2022): 42-47. 
[2] A. Whiting, W. Ritz, and J. S. Hain, “Exploring the Effects 
of Students from Converting On-Campus Classes to Online 
due to the COVID-19 Pandemic,” Journal for Advancement 
of Marketing Education 29, no. 1 (2021): 13-24. 
[3] T. H. Reisenwitz and J. G. Fowler, “Transitioning from 
Face-To-Face to Online Classes During a Pandemic: 
Factors That May Affect Student Satisfaction of the 
Administration and Instructors,” Marketing Education 
Review 31, no. 3 (2021): 199-208.  
[4] G. Bulman and R. W. Fairlie, “The Impact of COVID-19 
on Community College Enrollment and Student Success: 
Evidence from California Administrative Data,” National 
Bureau of Economic Research Working Paper Series 
(2022).  
[5] Project Management Institute,  A Guide to the Project 
Management Body of Knowledge (PMBOK(R) Guide–Sixth 
Edition, Project Management Institute, 2017.   
[6] E. Ozmen, Project management methodology (PMM): how 
can PMM serve organisations today?, PMI® Global 
Congress 2013—EMEA, Istanbul, Turkey. Newtown 
Square, PA: Project Management Institute, 2013. 
[7] P. Jovanović and I. Berić, “Analysis of the Available 
Project 
Management 
Methodologies,” 
Management: 
Journal of Sustainable Business and Management Solutions 
in Emerging Economies 23, no. 3 (2018): 3-13.  
[8] M. Sliger, “Agile project management with Scrum,” PMI® 
Global Congress 2011—Dallas, TX (2011).  
[9] Handbook on Planning, Monitoring and Evaluating for 
Development 
Results, 
United 
Nations 
Development 
Programme, 2009. 
[10] J. D. Frame, Managing Projects in Organizations: How to 
Make the Best Use of Time, Techniques, and People (3rd 
Edition), Jossey-Bass, 2003. 
[11] R. Michalak and M. D. T. Rysavy, “Managing Remote 
Projects Effectively with an Action Dashboard,” Journal of 
Library Administration, 60(7), pp. 800–811, 2020.  
[12] V. González and A. Kobsa, “Benefits of information 
visualization systems for administrative data analysts,” In 
21
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Proceedings on Seventh International Conference on 
Information Visualization IV (2003): 331-336. 
[13] Slack, https://slack.com.  Date accessed: 01 June 2023. 
[14] Trello, https://trello.com/en-US. Date accessed: 01 June 
2023. 
[15] ClickUp, https://clickup.com. Date accessed: 01 June 2023. 
[16] OpenProject, https://www.openprojec.org. Date accessed: 
01 June 2023. 
[17] Focalboard, https://www.focalboard.com. Date accessed: 
01 June 2023. 
[18] ServiceNow, 
https://www.servicenow.com/products/project-portfolio-
management.html. Date accessed: 01 June 2023. 
[19] BMC, https://www3.bmcgroup.com/solutions/virtual-data-
room/difference/project-management/. Date accessed: 01 
June 2023. 
[20] IBM, 
https://www-
50.ibm.com/partnerworld/gsd/solutiondetails.do?&solution
s=50480. Date accessed: 01 June 2023. 
[21] Microsoft 
365, 
https://www.microsoft.com/en-
us/microsoft-365. Date accessed: 01 June 2023. 
[22] S. L. Catto, & E. A Maccari, “Innovation Projects 
Management: A Systematic Literature Review.” Brazilian 
Journal of Management / Revista de Administração Da 
UFSM, 14 (4), pp. 848–863, 2021. 
[23] N. Damij and T. Damij, “An Approach to Optimizing 
Kanban Board Workflow and Shortening the Project 
Management Plan,” IEEE Transactions on Engineering 
Management, 
forthcoming, 
doi: 
10.1109/TEM.2021.3120984, 2021. 
[24] R. V. Waters & S. A. Ahmed, “Beyond the Spreadsheets: 
Quality 
Project 
Management,” Performance 
Improvement, 59 (10), pp. 16–29, 2020. 
22
International Journal on Advances in Systems and Measurements, vol 16 no 1 & 2, year 2023, http://www.iariajournals.org/systems_and_measurements/
2023, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

