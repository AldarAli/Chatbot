Methodology of Training and Support for Urban Search and Rescue With Robots 
 
Janusz Bedkowski, Karol Majek, Igor Ostrowski, 
Paweł Musialik, Andrzej Masłowski 
Institute of Mathematical Machines IMM 
Warsaw, Poland 
e-mail: januszbedkowski@gmail.com, 
karolmajek@gmail.com, iostrowski@wp.pl, 
pawelmus@op.pl, a.maslowski@imm.org.pl 
Artur Adamek 
Department of Geodesy and Cartography 
Warsaw University of Technology 
Warsaw, Poland 
e-mail:  a.adamek@gik.pw.edu.pl 
Antonio Coelho 
FEUP 
INESC TEC 
Porto, Portugal 
e-mail: acoelho@fe.up.pt 
 
 
Geert De Cubber  
Department of Mechanics MECA 
Royal Military Academy 
Brussels, Belgium 
e-mail: geert.de.cubber@rma.ac.be
 
 
 
 
Abstract— A primordial task of the fire-fighting and rescue 
services in the event of a large crisis is the search for human 
survivors on the incident site. This task, being complex and 
dangerous, often leads to loss of lives. Unmanned search and 
rescue devices can provide a valuable tool for saving human 
lives and speeding up the search and rescue operations. Urban 
Search and Rescue (USAR) community agrees with the fact 
that the operator skill is the main factor for successfully using 
unmanned robotic platforms. The key training concept is  
“train as you fight” mentality. Intervention troops focalize on 
“real training”, as a crisis is  difficult to simulate.  For this 
reason, in this paper a methodology of training and support for 
USAR with unmanned vehicles is proposed. The methodology 
integrates the Qualitative Spatio-Temporal Representation and 
Reasoning (QSTRR) framework with USAR tools to decrease 
the cognitive load on human operators working with 
sophisticated robotic platforms. Tools for simplifying and 
improving virtual training environment generation from life 
data are shown. 
Keywords – USAR; robot; training and support; qualitative 
reasoning 
I. 
 INTRODUCTION AND RELATED WORK 
The major factor of training determining the acceptance 
of the USAR community is for the learning process of 
different tools to conclude within one week, which is the 
duration of a typical Search and Rescue (SAR) training 
course. For this reason, it can be difficult to adopt a new 
training technology if the training requires more than this 
duration. Training and support is related with effective tasks 
the robots would be able to do.  
In this context, CRASAR, the Centre for Robot-Assisted 
Search and Rescue from the Texas A&M University, 
compiled a list of distinct activities for rescue robots [1][2]. 
The activities and tasks relevant to USAR with unmanned 
vehicles are: Area reduction, in the early stages of a disaster, 
there is generally a large area which must be labeled as 
“possibly affected”. To deploy the USAR teams correctly it 
is required to assess as soon as possible which areas are more 
affected and which areas are less affected. Sectorization, the 
disaster area must be subdivided into sectors. Search, robotic 
tools could speed up the search for victims. Reconnaissance 
and mapping, robotic tools can help to increase the common 
operation picture and situational awareness of the deployed 
teams by mapping the terrain. Rubble removal, robots can 
remove heavy rubble faster than humans. Debris estimation, 
after a major crisis, there is in general a lot of debris lying 
around, impeding the proper deployment of rescue operators 
and goods. Robots could help with a quicker and better 
assessment of the most affected zones. Structural inspection 
and shoring, USAR teams need to assess the structural 
integrity of a building and may help to stabilize it before 
entering. On site medical assessment and intervention, robots 
can provide medical personnel means to inspect a victim 
remotely via video or audio and to provide the victim life 
support. Evacuation of casualties, robots may act as carriers 
to evacuate victims from the disaster area. Acting as mobile 
beacon or repeater, Robots can help with extending the 
mobile communication range, by acting as a repeater. Over 
the horizon applications, Often, SAR teams want to know the 
damage in a nearby village/suburb/town. It would be highly 
convenient to be able to send a light Unmanned Aerial 
System (UAS).  
Within the context of mentioned tasks relevant to USAR 
with unmanned vehicles it is observed that most of these 
activities can be modeled using a QSTRR [3]. QSTRR 
proposes the interaction with the environment through a 
spatial design task. The problem of providing intelligent 
spatial decision-making capabilities is related to the 
77
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-257-8
ICAS 2013 : The Ninth International Conference on Autonomic and Autonomous Systems

 
 
framework of Multi-Modal Data Access for Spatial 
Assistance Systems [4]. This framework shows a key 
concept of spatial assistance systems by focusing on multi-
perspective 
semantics, 
qualitative 
and 
artefactual 
abstractions, industrial conformance and interoperability. 
Authors also provide examples of use for distinct application 
domains, which was an important input for the developed 
methodology of training and support. A core concept of 
artefactual 
abstractions 
is 
to 
provide 
qualitative 
categorization into functional, operational and range 
spaces [5]. Functional space is a region of space within 
which a person must be located in, in order to interact with 
the object or to employ the object for its intended function. 
Operational space is a region of space that an object requires 
to perform its intended function. Range space is a region of 
space where the object operates as a result of performing its 
intended function. These spaces can model robotic activities 
in disaster zones.  
Another important aspect used in the proposed 
methodology of training and support is related to geo-
referencing of terrestrial laser-scanner data for applications 
in architectural modeling [6]. Using a 3D laser we can obtain 
accurate 3D models of the disaster zone, which is the key 
concept in the proposed USAR-training and support 
application. From the USAR community point of view, the 
use of laser scanning can provide frequently updated, 
accurate and reliable data. In [7] Kurt3D, data from KINECT 
sensor and Riegl VZ-400 3D scanner are shown, which gives 
an impression that the State of the Art (SoA) offers efficient 
mobile platforms equipped with advanced sensors for 
obtaining accurate maps, that could be used in USAR. Some 
of these maps are used for semantic objects identification [8]. 
Using semantic information extracted from 3D laser data is a 
relatively recent research topic in mobile robotics.  In [8] a 
semantic map for a mobile robot was described as a map that 
contains, in addition to spatial information about the 
environment, assignments of mapped features to entities of 
known classes.  In [9] a model of an indoor scene is 
implemented as a semantic net. This approach is used in [10] 
where a robot extracts the semantic information from 3D 
models built from a laser scanner.  
The proposed methodology of training and support is 
adopting procedural modeling tools [11][12] that can be used 
for the generation of virtual urban environments, reducing 
both the amount of interaction needed as well as modeling 
effort. These techniques can be enhanced to generate 
accurate models that incorporate the semantic data existing 
in Geographic Information System (GIS) [13][14]. On the 
other hand, municipalities often store several semantic data 
regarding the urban features populating the territory in a GIS. 
Procedural modeling of urban environments originates from 
the use of L-Systems [15]. The limitations of this 
mathematical tool led to the development of the CGA Shape 
[16], a shape grammar capable of producing extensive 
architectural models with high detail. The implementation of 
the CGA Shape is integrated in the CityEngine framework. 
The same limitation led to the development of Geospatial L-
Systems [17], an extension of parametric L-Systems which 
incorporates spatial awareness. This approach combines the 
ability of data amplification provided by the L-Systems with 
the geospatial awareness of GIS. Approach proposed in this 
paper combines procedural modeling tools, Qualitative 
Spatio-Temporal Representation and Reasoning framework 
and modern laser scanning to provide methodology for 
training and support for robotic USAR application. 
The paper is organized as follows: Section II describes 
the use of QSTRR framework for purpose of semantic 
modeling, Section III concentrates on procedural modeling 
of urban environments, Section IV, V and VI describe data 
processing and conceptualization, experiments conducted 
are described in Section VII, finally Section VIII contains 
conclusion and future work description. 
 
II. 
SEMANTIC MODEL OF USAR OPERATION 
To model an USAR operation, the QSTRR is proposed. 
The main element is an ontology. As a representation 
vocabulary 
it 
is 
specialized 
to 
the 
domain 
of 
physical/functional entities in real structured environment. It 
allows to build a model of an environment using qualitative 
spatio-temporal or quantitative (depends on the need) 
representation. An ontology (O) is composed of several 
entities:  a set of concepts (C), a set of relations (R),a set of 
axioms (A) (e.g., transitivity, reflexivity, symmetry of 
relations), a concepts' hierarchy (CH), a relations' hierarchy 
(RH), a set of spatio-temporal events (Est), what can be 
formulated as following definition: 
 
Ο = <C;R;A;CH;RH;Est>  
(1) 
A concept is defined as a primitive spatial entity described 
by a shape (S) composed of polygons in 3D space 
associated 
with 
a 
semantic 
label 
(SL). 
Ontology 
distinguishes two different types of attributes that can be 
assigned to a concept, quantitative (Aqn) and qualitative 
(Aql). Four values of qualitative attribute (entity function) 
are listed: real physical object, functional space, operational 
space, range space. Functional, operational and range spaces 
are related with spatial artifacts that describe the USAR 
environment and robotic devices such as sensors and 
actuators. Quantitative attributes are related with physical 
properties of spatial entities and are as follows: location, 
mass, center of mass, moment of inertia (how much 
resistance there is to change the orientation about an axis), 
material (friction, restitution). Therefore, the definition of 
the concept (C) is formulated as: 
 
 
C = <S;Aqn;Aql; SL> 
 (2) 
The set of relations (R) is composed of quantitative and 
qualitative spatial relations. For topological spatial relations  
78
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-257-8
ICAS 2013 : The Ninth International Conference on Autonomic and Autonomous Systems

 
 
 
Figure 1.  The relations of RCC-8 calculus (conceptual neighborhood). 
 (qualitative) the Region Connected Calculus (RCC) is 
proposed. RCC is a formalism for spatial reasoning that 
takes regions of space (shapes) instead of points of classical 
geometry as primitives. One particular prominent reasoning  
system is a system of topological relations called RCC8(the 
relations of RCC-8 calculus and conceptual neighborhood is 
shown in Figure 1, therefore the ontology includes eight 
different topological relations between two regions (in our 
case shapes): disconnected (DC), externally connected (EC), 
partial overlap (PO), equal (EQ), tangential proper part 
(TPP) and its inverse (TPPi), non-tangential proper part 
(NTPP) and its inverse (NTPPi). 
Quantitative spatial relations are a way to constrain the 
way entities move relative to each other.  The ontology 
defines the following constraints: origins locked, orientations 
locked; origins locked, orientations free; free rotation around 
one axis; sliding. Ontology provides a mechanism for 
building world models that assume spatio-temporal relations 
in different time intervals (in other words: world models that 
can capture changes) for the representation of spatio-
temporal knowledge used for spatiotemporal reasoning. 
Chosen temporal representation takes temporal intervals as a 
primitive, therefore ontology defines qualitative spatio-
temporal events (Est) related with topological spatial 
relations RCC-8:  
onEnter (DC->EC->PO),  
onLeave(PO->EC->DC),  
onStartInside(PO->TPP->NTPP),  
onStopInside(NTPP->TPP->PO).  
These four qualitative spatio-temporal events can be used 
to express most important spatio-temporal relations that can 
be held between two concepts in different intervals of time. 
To store the instances of ontology-based elements (defined 
on the conceptual level) an instance base (IBO) is defined: 
 
IBO = <IO
C ; IO
R ; IO
Esτ> 
 (3) 
where: IO
C contains instances of concepts C, IO
R contains 
instances of relations R, IO
Est contains instances of spatio-
temporal events. Semantic model is defined as a pair: 
 
SM =<O; IBO> 
 (4) 
where: O is an ontology and IBO is an instance base related 
to ontology O. Ontology is known a-priori but instance base 
is being updated during USAR operation. Semantic model is  
 
Figure 2.  City model generated from municipal GIS 
a core concept for support system. The projection of the 
semantic model onto 3D space is defined as 3D semantic  
map, and the projection of the semantic model onto 2D 
space is defined as 2D semantic map. Semantic maps are 
useful visualization tools for increasing the awareness of 
search teams concerning the global operational picture of 
the USAR scenario. 
 
III. 
PROCEDURAL MODELING TOOLS FOR THE 
GENERATION OF VIRTUAL URBAN ENVIRONMENTS 
Procedural methods require that the user, capturing the 
knowledge about the modeling process, introduces some 
guidelines and rules. This is time consuming and can be 
difficult to develop in a crisis situation.  By taking advantage 
of the semantic model for USAR operation this approach 
uses generic production rules to amplify available data from 
existing shapes or general information.  
In this sense, some methods have already been 
conceived, but as far as control is concerned, procedural 
ways still lack powerful picking and manipulation facilities 
to 
apply 
geometric 
operations. This motivates the 
development of more advanced methodologies for such 
control.  
Based on PGCAD API [12], a solution for geometric 
manipulation in procedural modeling tools that incorporates 
spatial awareness and semantic control, it is possible to 
achieve more powerful control over geometric entities based 
on their properties and sequential application of modeling 
operations, therefore allowing a greater, faster and more 
intuitive approach for geometry generation. This is achieved 
through its intuitive topological structure, which features a 
set of properties, such as scope, spatial awareness and 
semantic information. The modeling processes can be 
massively applied to sets of shapes, yet act according to each 
individual shape’s properties. This allows a more customized 
control, as well as successive tracking, which induce a 
greater, faster and more intuitive approach for geometry 
generation. 
 
79
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-257-8
ICAS 2013 : The Ninth International Conference on Autonomic and Autonomous Systems

 
 
IV. 
REAL TIME 3D DATA PROCESSING 
The goal of support system is to increase the awareness of 
rescue team concerning a disaster sector. For this reason, a 
data filtering and registration tool is developed [18]. Figures 
3 and 4 demonstrate the computation of 3D clouds obtained 
with a modern 3D laser scanner (each cloud contains 1,5 
million 
of 
data 
points). 
  
Figure 3.  The filtering of 2D cloud of points. 
 
Figure 4.  The registration of 3D cloud of points. 
 
The computation time of filtering is on average 1,2 second, 
the registration takes in average 2 minutes assuming 
computational help of the ICP (Iterative Closest Point) 
algorithm. It is important to emphasize that  the proposed 
approach can register up to 65million of points within 30 
minutes. 
 
V. 
MANUAL CONCEPTUALISATION 
The proposed support system provides the functionality 
of manual conceptualization based on the registered 3D 
cloud of points (Figure 5). Rescue team members will have 
the possibility to assign semantic labels to the observed 
objects.   
 
 
 
Figure 5.  The view of HMI for manual conceptualisation. 
These labels correspond to the spatial regions in the 3D 
scene will generate additional semantic concept in the 
semantic model of global operational picture that is 
distributed over USAR system. 
VI. 
AUTOMATIC CONCEPTUALISATION 
To decrease the cognitive load on rescue team members, 
the proposed support and training system provides a 
mechanism for automatic conceptualisation based on 
artificial intelligence techniques. In its current form, the 
system classifies each point into one of four classes:  ground, 
building, vegetation, unclassified. The assignment is made 
by analysing normal vectors of points. The first step 
concentrates on finding the post populous horizontal plane, 
below the origin point of the scan. To achieve this, a 
RANdom SAmple Consensus (RANSAC) [19] method is 
used. After that, each point whose distance to the found plain 
is lower then R is classified as ground. Those points are then 
filtered out from the data 3D point cloud. Remaining points 
are grouped into cells of 2x2 meters, in the horizontal plane. 
They main assumption, on which classification between 
vegetation and buildings is made is that buildings are mostly 
regular plains, whereas trees and bushes are mostly irregular 
group of points. Therefore, a cell that holds vegetation points 
should have a roughly uniform distribution of directions of 
normal vectors, and cell that holds building walls should 
have most normal vectors pointing in one direction. Based 
on that reasoning the cells are classified in two groups: 
potential building or potential vegetation. The cell is 
considered potential building if normal vectors of at least 
half of the points in the cell point in roughly the same 
direction. In such cell RANSAC algorithm is used to see if 
such a plane can be found that at least half of the points in 
the cell is in N-distance of it. If this condition is met, the cell 
is classified as a building. Every cell that does not meet this 
condition is added to the group of potential vegetation. The 
vegetation hypothesis is checked by counting the dominant 
direction of normal vectors of each point in the cell. If the 
distribution of normal vectors directions is roughly uniform, 
the cell is considered vegetation. The cells that do not meet 
this condition are classified as unclassified. After initial 
classification, every cell is checked, by comparing it with it’s 
neighbors. 
80
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-257-8
ICAS 2013 : The Ninth International Conference on Autonomic and Autonomous Systems

 
 
 
Figure 6.   The view of HMI for the visualisation of automatic 
conceptualisation. 
The results of the algorithm are shown in Figure 6. 
Classes of points are shown by color: green-ground, red-
building, blue-vegetation, gray-unclassified. Computation 
time for 15 million points cloud for this particular 
experiment is 50s. 
VII. EXPERIMENT 
To proof the concept of qualitative reasoning used in 
USAR with robots, we validate the methodology in the 
environment shown in Figure 7. Each cell corresponds to a 
10x10 meter rectangle. Therefore, the global operational 
picture covers region of 200x200 meters. The semantic 
model contains 3D shapes of the scanned real objects, robot 
goals (starting point, middle goal, and destination goal), 
robot path – rectangular prisms – 3D shapes between goals, 
robot shape and artificial cameras (Figure 8). The projections 
of the semantic model onto 3D and 2D spaces are shown in 
Figures 9 and 10. These projections are defined as semantic 
maps, which are to be visualized for rescue team members to 
increase their awareness of global operational picture. The 
qualitative reasoning capabilities for the given example can 
be demonstrated using the following request-respond pairs. 
Request: where is the robot? 
Qualitative respond: robot is inside the path. 
Quantitative respond: robot’s GPS(Global Positioning 
System) coordinates. 
When human operator will try to omit the path support 
system will respond: 
Qualitative respond: robot is going out of the path. 
Quantitative respond: robot’s GPS coordinates. 
 
 
Figure 7.  Testing environment - the registetred 3D cloud of points. 
 
 
Figure 8.  Visualisation of the semantic model. 
 
Figure 9.  2D semantic map of semantic model from Figure 7. 
 
81
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-257-8
ICAS 2013 : The Ninth International Conference on Autonomic and Autonomous Systems

 
 
 
Figure 10.  3D semantic map of semantic model from Figure 7. The view 
point - range space of artificial camera.  
Based on these simple examples it can be observed that 
qualitative reasoning capabilities are very useful for rescue 
team members because of its simple form. It is important to 
simplify the use of advanced technologies which can help to 
introduce new modules into the USAR community. 
VIII. CONCLUSION 
In this paper, a methodology for training and support for 
Urban Search and Rescue with robots is shown. The 
methodology integrates the QSTRR framework with USAR 
tools for decreasing the cognitive load on human operators 
working with sophisticated robotic platforms. The goal was 
to develop software component for filtering and registering 
3D data acquired with modern 3D laser scanner (providing 
millions of points in a single 3D scan). Registered data is 
manually or automatically conceptualized, providing a 
semantic model associated with a global operational picture. 
Through the modification of this semantic map, we can 
model complex USAR scenarios, assuming the usage of the 
robotic platforms. 
ACKNOWLEDGMENT 
The research leading to these results has received funding 
from the European Community's Seventh Framework 
Programme 
(FP7/2007-2013) 
under 
grant 
agreement 
n°285417. 
REFERENCES 
[1] J. Burke, R. Murphy, E. Rogers, V. Lumelsky, and J. Scholtz , 
“Final report for the RARPA/NSF interdisciplinary study on 
Human-Robot Interaction” IEEE Transactions on Systems, 
Man, and Cybernetics - Part C: Applications and Reviews, 
Vol.34, No. 2, 2004, pp. 103-112. 
[2] J. Carlson, R. Murphy, and A. Nelson, “Follow-Up analysis 
of mobile robot failures,” CRASAR Technical Report - 
TR2004-10, 2004. 
[3] J. Będkowski, “Intelligent mobile assistant for spatial design 
support,” Journal of Automation in Construction, 2012, doi: 
http://dx.doi.org/10.1016/j.autcon.2012.09.009 
[4] C. Schultz and M. Bhatt, “A multi-modal data access 
framework for spatial assistance systems: use-cases with the 
building information model (bim/ifc),” ISA, Proc. 2nd ACM 
SIGSPATIAL International Workshop on Indoor Spatial 
Awareness, 2010, pp. 39-46. 
[5] M. Bhatt, F. Dylla, and J. Hois, “Spatio-Terminological 
interference for the design of ambient environments,” in 
Conference on Spatial Information Theory(COSIT’09), K. S. 
Hornsby, C. Claramunt, M. Denis, and G. Ligozat, pp. 371-
391, Springer-Verlagm, 2009.  
[6] S. Schuhmacher and J. Bohm, “Georeferencing of terrestrial 
laserscanner data for applications in architectural modeling,” 
3D-ARCH 2005: Virtual reconstruction and visualization of 
complex architectures, Mestre-Venice, Italy, 22-24 August, 
2005, Univesitat Stuttgart, 2005, URL: http://elib.uni-
stuttgart.de/opus/volltexte/2007/3256 
[7] J. Elseberg, D. Borrmann, and A. Nuchter, “Efficient 
processing of large 3d point clouds,” Proc. XXIII 
International Symposium on Information, Comunication and 
Automation Technologies(ICAT11), Srajevo, Bosnia, 2011, 
pp. 1-7 
[8] A. Nuchter and J. Hertzberg, “Towards semantic maps for 
mobile robots,” Robot. Auton. Syst., vol. 56, no. 11, 2008, pp. 
915-926, 
doi: 
10.1016/j.robot.2008.08.001. 
URL: 
http://dl.acm.org/citation.cfm?id=1453261.1453481 
[9] O. Grau, “A scene analysis system for the generation of 3-d 
models,” NRC ’97, Proc. International Conference on Recent 
Advances in 3-D Digital Imaging and Modeling, IEEE 
Computer Society, Washington, DC, USA, 1997, p. 221-228. 
[10] A. Nuchter, H. Surmann, K. Lingemann, and J. Hertzberg, 
“Semantic 
scene 
analysis 
of 
scanned 
3d 
indoor 
environments,” Proc. Eighth International Fall Workshop on 
Vision, Modeling, and visualization (VMV 03), 2003, pp. 
665-673. 
[11] P. B. Silva, A. Coelho, R. Rodrigues, and A. A. de Sousa, “A 
procedural geometry modeling API,” Proc. GRAPP & IVAPP 
2012, Italy, SciTePress 2012, 24-26 February, 2012, pp. 129-
134. 
[12] P. B. Silva and A. Coelho, “Procedural modeling for realistic 
virtual worlds development,” Journal of Virtual Worlds 
Research, vol. 4 , no. 1, 2011 , doi:10.4101/jvwr.v4i1.2109 
[13] D. Jesus, A. Coelho, C. Rebelo, A. Cardoso, and A. A. Sousa, 
“A pipeline for procedural modelling from geospatial data.” 
Proc. Eurographics 2012, pp. 9-10, 2012. 
[14] T. Martins, P. B. Silva, A. Coelho, and A. A Sousa, “An 
urban ontology to generate collaborative virtual environments 
for municipal planning and management,” Proc. GRAPP 2012 
-7th International Conference in Computer Graphics Theory 
and Applications, pp. 507-510, 2012. 
[15] Y. I. H. Parish and P. Müller, “Procedural modeling of cities.” 
Proc. 28th annual conference on Computer graphics and 
interactive techniques(SIGGRAPH ’01), ACM, New York, 
USA, 2001, pp. 301-308. 
[16] P. Müller, P. Wonka, S. Haegler, A. Ulmer, and L. van Gool, 
“Procedural modeling of buildings” ACM Trans Graph., 
vol. 25, July 2006, pp. 614-623. 
[17] A. Coelho, M. Bessa, A. A. Sousa, and F. N. Ferreira, 
“Expeditious modeling of virtual urban environments with 
geospatial l-systems,” Computer Graphics Forum, vol. 26, 
no. 4, 2007, pp. 762-782. 
[18] J. Będkowski, A. Masłowski, and G. De Cubber, “Real time 
3D localization and mapping for USAR robotic application,” 
Industrial Robot: An International Journal, vol. 39, no. 5, 
2012, pp. 464-474. 
[19] M. A. Fischler and R. C. Bolles,"Random Sample Consensus: 
A paradigm for model fitting with applications to image 
analysis and automated cartography," Comm. of the ACM, 
vol. 
24, 
no. 
6, 
june 
1981, 
pp. 
381–395, 
doi 
:10.1145/358669.358692 . 
82
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-257-8
ICAS 2013 : The Ninth International Conference on Autonomic and Autonomous Systems

