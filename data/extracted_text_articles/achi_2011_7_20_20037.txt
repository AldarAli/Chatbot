Virtual Reality Technologies: a Way to Verify Dismantling Operations 
First application case in a highly radioactive cell 
 
Caroline Chabal, Alexandre Proietti, Jean-François Mante, Jean-Marc Idasiak 
CEA, DEN, SDTC 
Bagnols-sur-Cèze, France 
caroline.chabal@cea.fr, alexandre.proietti@gmail.com, jean-francois.mante@cea.fr, jean-marc.idasiak@cea.fr 
 
 
Abstract—Dismantling is a major challenge for nuclear 
companies, which are faced with the clean-up of former 
nuclear sites. In order to increase efficiency, optimize costs and 
planning, intervention designers must verify scenario key 
points, take into account unexpected situations and provide 
technical answers. Simulation is a good means of visualizing 
and therefore understanding constraints, of testing different 
alternatives, and a way to train workers prior to interventions. 
This paper describes an application of such a technology: 
dismantling a chemical cell in the APM (Marcoule Pilot 
Workshop) facility at Marcoule (France). This highly 
radioactive cell will be dismantled by a remote handling system 
using the Maestro slave arm. An immersive room has been 
used to design the dismantling scenarios.  For these, the 
Maestro slave arm has been coupled with a haptic interface 
and, thanks to force feedback and visual immersion, 
accessibility, operational trajectories and maintainability on 
the carrier have been verified. If problems are found, updates 
of the carrier design are carried out before its final 
construction to guarantee the system will work properly. We 
describe the processes of building the 3D model and verifying 
scenarios. Finally, we present the first results, which are 
encouraging, and the perspectives for the project. 
Keywords-virtual reality; dismantling operation; haptic 
interface; accessibility study; remote handling; collision 
detection; interactivity; real-time 
I. 
 INTRODUCTION 
The CEA (French Atomic and Alternative Energies 
Commission) dismantling division runs an R&D program to 
provide innovative simulation tools for decommissioning 
projects. The various software and hardware tools are based 
on Virtual Reality (VR) technologies, and enable a user to 
interact with a computer-simulated environment, whether 
that environment is a simulation of the real world or of an 
imaginary world. VR environments, mostly based on visual 
immersion and displayed either on a computer screen or 
through stereoscopic displays, can also include additional 
sensory information, such as sound or touch [1]. 
This paper describes how VR technologies, adapted to 
the nuclear decommissioning context, can provide useful 
support to engineers in charge of scenario design. Before 
beginning the actual operations, such a set of tools is also 
well adapted to communicating and sharing information 
during project reviews, or to training workers and ensuring 
they are aware of the risks they could be exposed to. It is the 
first time in the world that such technology has been used to 
define 
decommissioning 
scenarios. 
VR 
showed 
its 
advantages in other industrial or medical fields, like 
automotive conception or surgical training [2]. 
First, the chosen VR technologies will be presented. 
Secondly, the first application case will be presented and 
explained as well as the nuclear environment and the remote 
handling system used for dismantling. Then, we will 
describe the simulator developed to validate scenarios. 
In the last section, we will describe our first results and 
the perspectives. 
II. 
THE MARCOULE IMMERSIVE ROOM 
The CEA created the Marcoule immersive room at the 
end of 2008 in order to validate maintenance or dismantling 
operations. It is a resource shared by all the CEA 
decommissioning projects (about ten), and can be used for 
project reviews, for accessibility, ergonomics or scenario 
feasibility studies, and for training workers [3]. 
The team works on new plant design as well as 
dismantling projects. 
A. The hardware equipment 
1) Stereoscopy 
The room is equipped with a very large screen, 3.7m by 
2.3m. After examining the options available, we have chosen 
the Infitec (INterference FIlter TEChnology) passive 
stereoscopic technology and use two projectors from the 
constructor Projection Design to display the images by back 
projection. The largest resolution is 1920x1200. Special 
interference filters (dichromatic filters) in the glasses and in 
the projector form the main item of technology and have 
given it this name. The filters divide the visible color 
spectrum into six narrow bands - two in the red region, two 
in the green region, and two in the blue region (called R1, 
R2, G1, G2, B1 and B2 for the purposes of this description). 
The R1, G1 and B1 bands are used for one eye image, and 
R2, G2, B2 for the other eye. The human eye is largely 
insensitive to such fine spectral differences, so this technique 
is able to generate full-color 3D images with only slight 
colour differences between the two eyes [4]. 
The main advantages of this technology are the very light 
weight of the glasses and it allows the user to turn his head 
with keeping a good stereoscopy. The size of the screen is 
very comfortable to work on life-size simulations.   
153
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

2) Motion capture 
A motion capture system based on four IR cameras 
manufactured by AR-Tracking is used to track the position 
of the specially-equipped glasses in real-time. As a result, 
when the user moves his head, the point of view of the 
simulation changes as if a genuine movement had taken 
place within the VR surroundings. 
3) Haptic device 
The room is also equipped with a haptic interface, the 
Virtuose 6D35-45 (Fig. 1), which enables the manipulation 
of virtual objects and force feedback to simulate the contacts. 
This device is developed by Haption, a spin-off of the CEA 
and it is the only product on the market today, which offers 
force feedback on all six degrees of freedom (DOF) together 
with a large workspace and high torques [5]. 
 
 
Figure 1.  Virtuose 6D35-45. 
B. The software tools 
We use TechViz XL [6] developed by TechViz, a French 
company in order to catch the OpenGL flow of an 
application, generate stereoscopic images and send it to both 
projectors. TechViz XL notably works with 3DSMax, 
SolidWorks or Virtools. 
Virtools produced by Dassault Systèmes is used to 
manage a simulation. It offers a development environment to 
create 3D real-time applications and thanks to its Software 
Development 
Kit 
(SDK), 
we 
can 
add 
our 
own 
functionalities. 
III. 
FIRST APPLICATION: CELL 414 
A. Presentation of the project 
The APM facility is the Marcoule Pilot Workshop. It was 
a prototype plant for reprocessing spent fuel, first 
commissioned in 1962, with production activities shut down 
in 1997. The plant is currently undergoing clean-up and 
dismantling. 
Cell 414 (Fig. 2) is a part of the APM and was a chemical 
unit used to process liquids from irradiated fuel dissolution 
operations. It is a particularly large cell: 20m long, 4m wide 
and 6m high. There is approximately 5km of pipes. The 
present high level of radioactivity rules out direct manual 
dismantling, so the choice of a remote handling system 
called Maestro has been made.  
The first step of decommissioning is to remove high level 
radioactivity (hot spots). Data was gathered from an initial 
inventory: hot spots were identified with a gamma camera. 
These hot spots like the centrifuges or some parts of the 
pipes have to be removed first in order to reduce cell 
radioactivity. 
Figure 2.  Cell interior seen from a porthole. 
B. The remote handling system 
1) The Maestro system 
The Maestro system is the result of 10 years of 
collaboration between the CEA and Cybernetix in charge of 
its manufacturing [7]. This advanced remote manipulator is 
used when human intervention is not possible as if to operate 
in nuclear or offshore hostile environments. Maestro is 
dedicated to many tasks like inspection, maintenance, 
dismantling, cleaning…etc. Dexterity, accuracy and strength 
are its main advantages. It can be used in either robotic mode 
(automatic sequence) or in manual remote control mode with 
or without force feedback management. 
This system is made up with two parts: the master arm 
and the slave arm. The master arm is a device allowing the 
control of slave arm end-effecter in Cartesian mode with a 
complete force feedback. This device is a Virtuose 6D40-40 
from Haption. The slave arm is a hydraulic robot with six 
degrees of freedom (Fig. 3). 
The cell 414 dismantling project will be the first working 
site where Maestro will be used to dismantle a whole cell. 
 
 
 
 
 
 
 
 
 
 
Figure 3.  The Maestro kinematics 
2) The carrier 
The carrier was especially designed for Cell 414 
dismantling, and will enable the Maestro system to reach all 
parts of the cell.  
Axis 2 
Axis 1 
 
Axis 3 
 
Axis 4 
 
Axis 5 
 
Axis 6 
 
154
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

It works on three axes, using existing rails to move along 
the cell (20m), with vertical (3m) and rotating movements. A 
crane-type handling bracket is also set up on the carrier to 
hold parts during dismantling and for other handling 
operations. This carrier is currently undergoing tests. 
The carrier-crane combination also has six degrees of 
freedom (Fig. 4), with four translation axes and two rotation 
axes. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 4.  The carrier kinematics 
IV. 
FROM REAL TO VIRTUAL : THE STEPS TO BUILD THE 
SIMULATION 
In order to verify accessibility and maintainability on the 
carrier and to validate technical choices, it was decided to 
design the dismantling scenarios using a simulator and the 
VR technologies available in Marcoule.   
A. Step one: build the 3D models 
1) The cell 414 and the APM facility 
First, 3D models of the environment had to be built. As 
the 2D drawings of facility inside were not sufficiently up-
to-date 
to 
design 
a 
precise 
digital 
mock-up, 
a 
photogrammetric technique was used. A remote controlled 
camera was brought in the cell to take a set of pictures from 
different points of view. Then the 3D model was built using 
a semi-automatic process, to produce a model compatible 
with CAD or modeling software. About 200 pictures were 
necessary for the 3D reconstruction and only the internal 
parts were modeling in this way. This step was made by an 
external company.  
Secondly, the modeling of the building containing the 
cell 414 was made with the plan of construction.  
Finally, we merged these two parts to get a whole model 
into the 3DSMax software. The images below enable the 
comparison between a real photo and a VR view of the same 
scene. We can see that the 3D simulation is very close to 
reality (Fig. 5). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5.  A real photo (left) and 3D view (right) 
2) The robots 
Dealing with the robots previously presented, we 
obtained the CAD model by the manufacturer of the real 
robots: Cybernetix. The modeling is in SolidWorks format 
and we did the necessary conversions to use it into 3DSMax. 
B. Step two: develop the simulator 
1) The Virtools environment 
Our simulator is based on Virtools 5.0. It uses a specific 
script language and functions called Building Block (BB), in 
order to provide the interaction between the different objects, 
create menu, play sound, etc. 
To import 3D models into Virtools, they must be in a 
specific format. That is why we use 3DSMax because it 
provides an exporter from .MAX format to .NMO format 
used by Virtools.  
Virtools owns a basic physics engine but we use a third 
party physics engine because it is more precise and adapted 
to the force feedback. It will be presented in the following 
paragraph.  
2) Physics engine: IPSI 
IPSI [8] is a physics engine provided by Haption. It 
enables the testing of intersections between volumetric 
solids, in order to calculate trajectories and impact points. 
The real-time collision detection disables penetration 
between objects. Volumetric existence is given to geometric 
objects by taking the external skin of each 3D object. 
IPSI allows the creation of the kinematics of a robot: 
hierarchy between the different segments of a robot, the kind 
of degrees of freedom and its values, etc. 
Finally, IPSI can attach a virtual object to the Virtuose 
device and calculate the force feedback in case of collisions.  
3) The simulator 
Thanks to the Virtools SDK and the IPSI API, we can 
use Virtools for the graphical part and IPSI for the physical 
part. We created a Dynamic Link Library (DLL) for Virtools 
to add the abilities of using the functionalities of IPSI.  
In the initialization of the simulation, all the 3D objects 
we want to add to the physical simulation are sent to IPSI as 
well as the information about robots (hierarchies, degrees of 
freedom, etc). So we create kinematics of the Maestro arm 
155
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

and the carrier. As a matter of fact, we can consider both 
objects as robots and describe very precisely their motion. It 
consists in giving properties, by defining rotation or 
translation axis and end stops given by Cybernetix. Virtual 
robots can then be manipulated with their constraints as in 
real. 
The graphical representation of the objects is updated in 
Virtools by IPSI which calculates the new position in real-
time. During the simulation life, we use a callback function 
to match graphical and physical objects.  
C. Step three: control the simulation 
To control the robots, two gaming joysticks are used to 
pilot the carrier and the crane. The first one controls the three 
DOF of the carrier and the second one those of the crane. 
These controls are very similar to the interface which will be 
used for the final dismantling system.  
The Maestro arm has been coupled to the Virtuose 6D 
35-45 haptic interface. The Virtuose enables manipulation of 
the Maestro end-effecter, and thus control of the Maestro 
extremity while respecting the kinematics chain and all the 
end-stops. 
The entire robot can be maneuvered in real-time with 
these devices. 
D. Step four: add interactive functionalities  
 An interactive real-time simulator was developed where 
the whole cell, the Maestro slave arm and the carrier are 
loaded. The Maestro arm and its carrier can be maneuvered 
using the joysticks and Virtuose. Any of the nine available 
tools like drill or angle grinder can be connected to the 
Maestro arm or changed, as necessary.  
The points of view of the six cameras (two available in 
the cell and four embedded on the carrier) are also displayed 
in the simulator. It has been checked that every part of the 
cell is visible. Indeed, the operator will not perceive the cell 
directly during the dismantling. He will be in a room with six 
monitors to view the pictures being transmitted from the six 
cameras. There will be also a microphone in the cell, so the 
operator will can hear the sound of collisions in the 
monitoring room. Therefore we associated a sound with 
collision in the simulator, to enhance the information sent to 
the user.  
Lastly, automatic scenarios, such as the carrier entry in 
the cell, are programmed. 
V. 
FIRST RESULTS 
Tests carried out on the system had two objectives : first, 
to check that the carrier design was suitable for the Cell 414 
environment, and second, to verify the whole dismantling 
operation design [9]. 
Two 
interface 
problems 
preventing 
the 
forward 
movement of the carrier were quickly identified: while the 
first obstacle could be avoided by raising the Maestro base, 
the second will have to be dismantled by existing in-cell 
equipment, before the carrier enters the cell. 
We have then verified the detailed dismantling scenario 
from the carrier entry to the cutting of centrifuges. We found 
a lot of technical key points which need to be clarified 
because the feasibility of the task is not easy. For example, 
the tool grasping seems to be a problem because the Maestro 
slave arm is in a limit configuration and the carrier has to be 
in a specific position (Fig. 6). It disables the grasping in 
some parts of the cell. This kind of problems was not yet 
identified and the manufacturer has to take into account these 
issues. 
The last work we have done focuses on the centrifuges 
dismantling. We proved that the planed scenario was not 
feasible. With the simulation we brought alternative 
solutions.   
Thus, from the first simulation runs, the project has 
already brought vital information to implement in its 
dismantling scenarios. The chosen VR technologies have 
proved their worth, and the various capabilities of the 
Maestro system and carrier will continue to be tested as the 
dismantling project enters its next phase. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6.  The tool grasping 
VI. 
LIMITS AND PERSPECTIVES 
A. Current limits 
First, the mismatch of information relevant to reality can 
affect safety and performance. For instance, if the modeling 
accuracy of the robot or the cell is not enough, we cannot be 
sure that the scenarios that have to be tested with the 
simulator are reproducible in practice. The robot model 
directly comes from the CAD model of the manufacturer, so 
it can be considered as identical as the real one. The 
modeling incertitude is brought by 3D reconstruction. As a 
matter of fact, photogrammetry is accurate with 5cm 
precision. The most difficult task is to obtain a right model of 
the cell. The actual model created by photogrammetry is 
accurate enough for the first steps of scenario study but 
because of the layout of the cell, the complete model of the 
pipes could not be rebuilt with this technique. Only the first 
row of pipes were modeled so we have to update the cell 
modeling after the first steps of dismantling if we want to fit 
to the reality.      
156
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Secondly, we are limited by the physics engine. In deed, 
it is directly dependent on the computing power. With the 
current hardware, we cannot physicalize the robots and the 
whole cell with a high precision for the collision detection 
and get a real-time simulation. That is why we only 
physicalize the robots and some interesting parts of the cell. 
These parts depend on the tested scenario. Collision 
detection precision has to be inferior or equal to 10mm so 
that the accessibility studies could be realistic.  
B. Add the radioactivity dose rate information 
The CEA in collaboration with Euriware, a French 
company, developed an application called NARVEOS [10] 
capable of calculating the radioactivity dose rate. It is 
specifically 
used 
to 
simulate 
scenarios 
in 
nuclear 
environments. In NARVEOS, we can import a 3D model of 
a nuclear facility, specify the kinds of materials (steel, lead, 
concrete …) and add radioactive sources, protection screens, 
and measurement points in the 3D model. The software is 
able to calculate the radioactivity level in these points in real- 
time. For instance, we can measure the radioactivity dose 
rate on an operator moving in the facility.   
In a near future, we want to assembly the functionalities 
of NARVEOS with our simulator. In this way, we will be 
able to follow in real-time the decrease of radioactivity level 
during decommissioning and calculate the new levels after 
the removal of hot spots. 
C. Train the operators 
From the beginning of this project, the idea of training 
operators was predominant. The models are very closed to 
the reality and we can work with a life-size simulation. 
Currently, the control of the robots with the joysticks plus 
the Virtuose device, allow testing the real robot motion in the 
cell. For instance, we can find the most fitted carrier 
positions to work at best with the Maestro slave arm. We can 
also use the simulation to increase the operators’ awareness 
of the risks they could be exposed to, like collisions between 
carrier and equipments or robot damage.  
Moreover, the main purpose of the training is to avoid 
nuclear incidents like workers’ irradiation. That is why we 
want to use the radioactivity dose rate simulation to train 
operators and inform them where the radioactive areas are 
located.  
Another advantage of the training is to show operators 
that there is no direct vision, so they will get used to working 
with only video and sound monitoring from the cell. 
VII. CONCLUSION 
This project shows that VR technologies can contribute 
to improve knowledge regarding project preparation and 
validate technical choices. The simulator involved is generic 
and can load any 3D model of a building. It is already 
functional and useful for the operator’s training. The CEA 
has also compiled a comprehensive robotics library and can 
therefore run VR versions of scenarios with any of these 
systems in order to test alternative solutions. 
Given the first results, the CEA proved VR tools open up 
new perspectives for studies, for decommissioning cost and 
deadline management, as well as for communication 
between project teams, contractors and Nuclear Safety 
Authority.  
REFERENCES 
[1] F. Gosselin, J. Martin, C. Andriot, and J. Savall, “Large workspace 
haptic 
devices 
for 
human 
scale 
interaction”, 
LIST/Réalité 
Virtuelle/UE-SKILLS, 2008. 
[2] F. Yaacoub, “Development of virtual reality tools for arthroscopic 
surgery training”, Université Paris-Est, Phd thesis in computer 
science, Paris, France, 2008. 
[3] G. Rindahl, T. Johnsen, and Y. Iguchi, “Virtual reality technology 
and 
nuclear 
decommissioning”, 
Int. 
conference 
on 
safe 
decommissioning for nuclear activities, Berlin, Germany, 2002. 
[4] H. Jorke and M. Fritz, “INFITEC- a new stereoscopic visualisation 
tool by wavelength multiplex imaging”,  Journal of Three 
Dimensional Images, vol.19, pp. 50-56, Japan, 2005. 
[5] P. Garrec, J-P. Friconneau, and F. Louveau, “Virtuose 6D: a new 
force-control master arm using innovative ball-screw actuators”, ISR, 
Paris, France, 2004. 
[6] C. Limousin, J. Sebot, A. Vartanian, and N. Drach, “Architecture 
optimization for multimedia application exploiting data and thread-
level parallelism”, Journal of Systems Architecture, vol. 51, issue 1, 
pp. 15-27, January 2005. 
[7] O. David, Y. Measson, C. Rotinat, F-X. Russotto, and C. Bidard, 
“Maestro 
: 
a hydraulic 
manipulator 
for 
maintenance and 
decommissioning application”, ENC, Bruxelles, Belgium, 2007. 
[8] Haption, 
IPSI 
datasheet. 
Available 
from  
http://www.haption.com/site/eng/images/pdf_download/Datasheet_IP
SI.pdf. 
[9] C. Chabal, A. Proietti, and E. Rigaux, “Virtual Reality, a way to 
optimize decommissioning scenarios”, Poster, ENC, Barcelona, 
Spain, 2010.  
[10] J-B. Thevenon, L. Lopez, C. Chabal, and J-M. Idasiak, “Using 
simulation for intervention design in radiating environment: first 
evaluation of NARVEOS”, GLOBAL, Paris, France, 2009. 
157
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

