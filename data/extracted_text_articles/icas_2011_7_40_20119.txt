An Autonomic Security Mechanism
Based on Novelty Detection and Concept Drift
Gesiel Rios Lopes, Andr´e L. V. Coelho, Raimir Holanda Filho
Master’s Course in Applied Computer Sciences
University of Fortaleza - UNIFOR
Fortaleza - CE - Brazil
Email: gesielrios@edu.unifor.br, {acoelho,raimir}@unifor.br
Abstract—The growth in the number of elements and services
in current computer networks and the integration of several
technologies, in order to provide connectivity and services
everytime
and
everywhere,
have
renderede
the
computing
infrastructure complex and susceptible to malicious activities.
In this sense, the use of autonomic computing principles arises
as an alternative to face these challenges, in special to deal with
the development of security mechanisms capable of infering
malicious activities with the purpose of self-protecting the
infrastructure against attacks.This paper presents and evaluates
a novel model of an autonomic element which is based on the
notions of novelty detection and concept drift. The element
is able to infer malicious activities that may compromise
the proper functioning of the network. Experimental results,
extracted from real samples network trafﬁc, indicate that the
element autonomic element infact is very useful.
Keywords—Autonomic
network,
autonomic
element,
novelty
detection, concept drift.
I. INTRODUCTION
In recent decades the industry has increasingly produced
new technologies, products and services, thus satisfying the
demands for computer systems with large storage capacity
and fast communication. These advances, although they bring
important beneﬁts, they have produced highly complex and
heterogeneous systems. As a result, ensure security, fault
tolerance, design capabilities, integration and management are
becomming critical factors [1]. Therefore, solving the pro-
blems and difﬁculties generated by this scenario is a big cha-
llenge, which will only be achieved when computer systems be
designed and built to adjust to changing situations, treating and
managing of their resources efﬁciently. These factors are the
main motivations for developing a new management system,
delegating such tasks to machines, thus enabling the removal
of administrative staff from the cycle and putting it only in
a supervisory position. This view has been referenced in the
academic community as autonomic computing [2].
This paper addresses the challenge of implementing an
autonomic element, with the following combination of proper-
ties: continuous unsupervised learning of new concepts, an
approach based on statistical properties extracted from the
initial packet payload of the TCP ﬂows and the use of a
sorting algorithm of low computational power, the clustering
algorithm k-means [3]. Moreover, our work is not limited to
submitting a proposal, because it evaluates an implementation
of an autonomic element using real traces. It is expected that
the autonomic element proposed in this work will enable self-
protection, self-conﬁguration and able to learn new concepts
over time, based on ﬂows generated by the trafﬁc.
The paper is organised as follows: Section II presents
the concepts of novelty detection, the continuous learning
OLINDDA (OnLIne Novelty and Drift Detection Algorithm)
algorithm used by the autonomic element proposed in this pa-
per and the k-means clustering algorithm. Section III presents
our proposed autonomic element. Section IV describes the
procedure for collecting and labeling the data used in the
validation of the autonomic element. Section V presents our
results and analysis, and ﬁnally, on Section VI our paper is
concluded with some remarks and future works.
II. NOVELTY DETECTION
The mining of data streams brings several challenges to
machine learning techniques. Its importance increases with
the need for real-time analysis of a large amount of data.
In this scenario, the ability to identify emerging concepts is
an important attribute, and the Novelty Detection technique
can contribute toward that goal. In Machine Learning, novelty
detection can be deﬁned as the identiﬁcation of patterns that
differ somehow from those normally expected, keeping a
certain similarity with the concept of outliers [4]. In the context
of this work, we consider a novelty as a new concept, i.e.,
an abstraction of instances or examples that share a set of
characteristics that differ from those previously identiﬁed.
If the characteristics of a new concept are similar to a
concept learned initially we use the term concept drift. Within
this paper, was used the OLINDDA, a cluster-based algorithm
which considers the problem of detecting concepts from
Internet Trafﬁc and operates over a continuous ﬂow of data
[4].
A. The OLINDDA algorithm
In
this subsection,
we
present the
functions of
the
OLINDDA. In terms of the learning paradigm, it may be
divided in two phases: a supervised learning phase, where a
normal model is built from a set of examples that describe
the data domain, and an unsupervised learning phase, where
unlabeled examples arriving from a data stream are analized
158
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

and novel concepts are continuously learned [4]. The im-
plementation of OLINDDA used in the proposed autonomic
element made use of the k-means clustering algorithm [5].
1) The k-means algorithm: Cluster analysis aims to divide
the elements of one sample, or population, in clusters so that
the elements belonging to the same group are similar to each
other based on variables (features) used for measuring them,
and the elements in different clusters are heterogeneous with
respect to these same characteristics.
Let x ∈ Rn be a vector of features with a known pro-
bability density p. We want to compute a partition of Rn,
{R1, R2, . . . , Rn}, representing each class by a vector ˆxi ∈ Ri
that is called centroid. The choice of centroids and the partition
is made to minimize the average distance of each vector to its
centroid:
D = E {d (x, r (x))}
(1)
The solution adopted in practice is to alternately estimate
the centroid and the partition of space. The algorithm of Lloyd-
Max is summarized in the following table [5]:
1) Initialization: Choose a static number of classes and
initialize the centroids of each class according to some
criterion.
2) Classiﬁcation:
Determine
a
partition
of
X,

X1, X2, . . . , Xc	
, associating each training sample to
the class whose centroid is closest:
x ∈ Xk : k = arg min
i
d(x, ˆxi)
(2)
3) Update centroids: Calculate new centroids for each class
by the equations
X
x∈Xp
∂
∂ˆxp
d(x, ˆxp) = 0,
p = 1, . . . , c,
(3)
where Xp means the data set assigned to the p-th class.
If d(x, y) = ∥x − y∥2,
ˆxp = 1
Np
X
x∈Xp
x,
p = 1, . . . , c
(4)
where Np = |Xp|
4) Back to step 2 until there is a stop condition.
In the second step, each pattern is classiﬁed in the class of
the closest centroid. During the third step, the centroids are
recalculated, starting to occupy the midpoint of the standards
in its class.
B. Distinction between normal and unknown
For construction of the normal concept, OLINDDA initially
considers a set of examples that are used to represent the
normal concept. The initial data are grouped into k clusters
by the k-means clustering algorithm. For each cluster, we
calculate the distance between the centroid and the farthest
example. This allows us to establish a decision boundary for
each cluster. The union of the boundaries of all clusters is
the global decision boundary which deﬁnes the model. A
new unseen example that falls inside this global boundary is
consistent with the model and therefore considered normal;
otherwise, it is labeled unknown. Otherwise, the example is
marked as a member of an unknown proﬁle and moved to a
short-term memory for further analysis. That memory works
like a FIFO queue to avoid its uncontrolled growth, eliminating
old samples to permit the inserting of new samples [4].
C. Identiﬁcation of novelty and concept drift
To monitor the formation of clusters in the short-term
memory of unknown data, we use k-means to generate k
candidate clusters. For a candidate cluster to be considered
valid, which might indicate a concept in our approach, it must
fulﬁll the following requirement. We use the in implementation
of the proposed autonomic element, the sum of the squares of
the distances between examples and the centroid divided by
the number of examples as a validation criterion of the degree
of cohesion, deﬁned by:
d(xj, ˆxi) =
P
xj∈ci
(xj − ˆxi)2
Ni
(5)
where ci represents the candidate cluster, ˆxi their respective
centroids and Ni the number of examples of their respective
centroids belonging in ci.
Then, we compare this value to the mean distance between
the centroid and examples of the candidate cluster. If the
value for the candidate cluster is lesser than or equal to
the one obtained for the model, the candidate cluster is
considered valid. This restriction aims at selecting clusters
whose density is not lower than that of the model. Once a
candidate cluster has been validated: it may either represent
a novel concept (novelty) or be an evidence that the normal
concept is undergoing a change (concept drift).
To establish the limit between conceptual change and no-
velty, we calculate the global position of a centroid for the
Normal template and then calculates the distance between
this centroid and the overall centroid farther away, resulting
in a decision boundary. If the centroid of the new cluster is
beyond this boundary, the new cluster is considered a new
and separate for further analysis. Otherwise, it is attributed to
this new cluster a change of concept, and this information is
used to update the standard model itself. An overview of the
OLINDDA is shown in Figure 1.
III. OUR PROPOSED AUTONOMIC ELEMENT
In this section, we present our proposed autonomic element
(Figure 2), which aims to identify, by monitoring the network
trafﬁc, malicious activity resulting from deviations and possi-
ble changes in the normal concept.
Our autonomic element uses the general format of auto-
nomic element, proposed by [2] and based on trafﬁc sub-
ﬂows [6], which can be deﬁned as a stream of packet being
transmitted between a pair of hosts. Only TCP trafﬁc was
analyzed during this research, generating a set of 52 statistical
variables candidates for discriminant, calculated based only on
information obtained from the packet headers (for example:
159
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

Fig. 1.
Overview of the OLINDDA [4].
TABLE I
EXAMPLES OF CANDIDATE VARIABLES TO DISCRIMINANT
Candidate Variable
Total of packet (Client to Server)
Minimum Windows Size (Server to Client)
Mean of Inter-Packet Length Variation(Client to Server)
Maximum of Bytes in Ethernet Packet (Client to Server)
packet size and TCP ﬂags), without the use of inspection of
payload and port numbers. The variables are calculated for
each direction of a bidirectional ﬂow (client to server and
server to client). Table I shows some of these variables.
Fig. 2.
Proposed Autonomic Element.
The implementation of the proposed autonomic element
occurs in two phases: the ﬁrst is called supervised phase and
the second phase called unsupervised. In the ﬁrst phase, the
autonomic element determines the statistical variables that best
discriminate the trafﬁc considered normal(attack free) from a
trace previously classiﬁed. At this stage the autonomic element
use the mechanisms proposed to select the set of statistical
candidates variables that best characterizes the normal trafﬁc.
Once you have determined the set of variables, the autonomic
element builds the initial model, which will be used to identify
potential malicious activities on the network and veriﬁes the
accuracy of the chosen variables. In the unsupervised phase,
the proposed element performs the implementation of the
autonomic cycle, as described below:
Monitor: The autonomic element (Figure 2(a)), works on
the network trafﬁc in promiscuous mode and reconstructs the
TCP ﬂows, extracts sub-ﬂows, and calculates the statistical
variables selected during the supervised phase, passing them
to the analysis phase.
Analyze: Our autonomic element (Figure 2(b)), veriﬁes if
each sub-ﬂow generated in the previous phase can be explained
by the normal concept built during supervised phase. All sub-
ﬂows explained by the normal concept are labeled as normal
to the next phase. The sub-ﬂows not explained are temporarily
stored in the short-term memory of unknown data. When the
amount sub-ﬂows stored in the short-term memory reaches
a certain threshold, new clusters are generated, which will
be labeled as a change of concept or novelty in accordance
with the criteria used by OLINDDA and forwarded to the next
stage.
Plan: Our autonomic element (Figure 2(c)), identiﬁes the
ﬂows which were explained by the normal concept. These
follow without any analysis in the next phase. The clusters
labeled as concept drift or novelty are built into the normal
concept. The information of the of remaining packets of sub-
ﬂows the clusters labeled as a novelty are stored, so they are
discarded at the execute phase.
Execute: Our autonomic element (Figure 2(d)), in this phase
execute the action plan established in the plan phase, i.e.,
all remaining packets of each sub-ﬂows that were considered
normal concept following without any changes and all the re-
maining sub-ﬂows identiﬁed as novelty are discarded, because
in our approach these packages represent some malicious
activity.
Knowledge: stores the informations found by the autonomic
element in all phases, such as the statistical variables, limits,
the normal model, error rates, among other items.
Figure 3 describes temporally the stages of implementation
of the proposed functioning of the autonomic element during
the unsupervised phase. Initially, at time t0, the autonomic ele-
ment has only the model for normal trafﬁc. In between times
t0 and t1, the proposed autonomic element is performed in the
presence of normal ﬂows and classes of attacks. During this
period abnormal sub-ﬂows are stored in short-term memory of
unkown. At time t1, temporary memory is ﬁlled and moves
the analysis of sub-ﬂows into candidate clusters, validating
and classifying them into innovations and changes in concept.
From the time t1, the autonomic element has proposed the
concept of related clusetrs and normal clusters validated and
classiﬁed as concept drift and novelty.
160
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

Fig. 3.
Incorporation of novelty.
IV. DATA AND MEASUREMENTS
Considering the difﬁculties to obtain actual samples of mali-
cious trafﬁc properly identiﬁed, we used artiﬁcially generated
attacks and inserted into traces that are supposedly free of
attacks to validate our experimental autonomic element. Thus,
it is possible to verify whether the attacks can be correctly
detected by our autonomic element.
To represent the normal trafﬁc were used samples collected
from a network gateway at the University of Fortaleza, during
the period April 26-28, 2010. The captured packets were
temporarily stored and the ﬂows were reconstructed. Each ﬂow
was labeled with an application class. The process of labeling
each ﬂow was performed in a semiautomated manner through
the use of the payload inspection tool OpenDPI [7]. Aiming to
ensure that normal trafﬁc really was free of malicious trafﬁc,
was also applied to each ﬂows the tool Snort NIDS [8], with
rules dated from November, 2010.
Our autonomic element was trained and validated through
the use of 3 trafﬁc datasetsts (referred as T1, T2 and T3).
Each dataset was collected during periods of 1 hour (morning,
afternoon and evening) and they contain the network trafﬁc
of the following classes: HTTP(browsers) and Snort Alerts
(Alerts of possible ﬂows of malicious activities identiﬁed by
Snort [8]). Also were added to each dataset, 1250 attacks
ﬂows: Denial of Service and Brute Force, artiﬁcially generated.
The process of generating of the attack trafﬁc, was con-
ducted in a controlled manner in the laboratory. Figure 4 shows
the topology used to generate the attack trafﬁc.
In this scenario, we used three computers: the attacker, the
victim and sniffer. The attacker has the role of sending trafﬁc
from attacks against services like FTP, SMTP and HTTP, to a
victim. To generation the Denial of Service Attack and Brute
Force Attack, were used the tools Heyenae [9] and Brutus
[10], respectively.
Table II describes the classes, applications and total ﬂows
found within each dataset.
Fig. 4.
Network topology used in the generation of artiﬁcial attacks.
V. RESULTS AND DISCUSSION
In this section, we present the experimental results obtained
with the implementation of our autonomic element using
TABLE II
SUMMARY OF DATASETS.
Class
Number of Flows
T1
T2
T3
HTTP
6835
5284
2588
Snort Alerts
1845
1296
697
Denial of Service
1250
1250
1250
Brute Force
1250
1250
1250
the process of cross-validation with 10 partitions [11]. To
measure the accuracy of our autonomic element, we use the
average rate of false-positive error eF P os, which measures
the average error committed when examples of sub-ﬂows of
attacks are considered as normal and average of false-negative
error eF Neg, which measures the average error committed
when normal trafﬁc ﬂows are labeled as attacks. These metrics
are given below:
eF P os = Total of false-positive sub-ﬂows
Total of normal sub-ﬂows
(6)
eF Neg = Total of false-negative sub-ﬂows
Total of attacks sub-ﬂows
(7)
In the supervised phase in order to determine the set of
statistical variables that best characterizes the trafﬁc to be
considered normal, we used 50% of HTTP ﬂows and 50%
of Snort Alert ﬂows of T1, T2 and T3. The remaining HTTP
ﬂows and Snort Alert, along with attack ﬂows of T1, T2 and
T3, were used in the unsupervised phase, to verify the learning
ability of the our autonomic element.
A. Supervised phase
When considering the use of discriminating variables, it is
essential to have measured in the sample elements, variables
that can really distinguish the population, otherwise the quality
of the classiﬁcation will be compromised. A very common
mistake is to think that increasing the number of discrimi-
nators, a better solution is reached. The Java implementation
of the Wrapper [12] evaluator found in Weka [13] was used
for selection of features that better characterize the ﬂows
associated to normal concept. Wrapper evaluates features using
precision estimations produced by the learning algorithm that
will be used on the classiﬁcation. In this case, the Na¨ıve Bayes
and Best First were selected as search method for the Wrapper
evaluator.
Figures 5 and 6 show, respectively, the results of the rates
of eF P os and the HTTP ﬂows considered unknown in datasets
T1, T2 and T3 for the set features selected by Wrapper for N
initial packets.
As we can observe on Figures 5 and 6, the initial 11 packets
utilization of each ﬂow, was the result with lower average
rates of eF P os unknown HTTP ﬂows considered by normal
concept generated and so used by the autonomic element in
the unsupervised phase.
161
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

Fig. 5.
Rate of false-positive error.
Fig. 6.
HTTP ﬂows considered unknown by the normal concept.
B. Unsupervised phase
The tabulated data below represent the results found by
applying our autonomic element over 50% remainder set of
HTTP ﬂows 50% of Snort Alert ﬂows and Denial of Service
and Brute Force ﬂows.
TABLE III
PERCENTAGE OF FLOWS CONSIDERED NORMAL.
Class
Dataset
HTTP
Snort
Denial of
Brute
Alert
Service
Force
T1
66,11%
4,03%
0%
0%
T2
69,11%
3,12%
0%
0%
T3
67,51%
3,87%
0%
0%
Table III presents the percentage of ﬂows considered nor-
mal by the autonomic element. We can see that on average
67.59% of HTTP trafﬁc was correctly classiﬁed as normal, ie,
were explained by the model correctly formed during normal
supervision. We also had an average of 3.67% of false positive,
ﬂows of Snort Alert class that were classiﬁed as normal traﬁc.
No Denial of Service and Brute Force attack, were classiﬁed
as normal trafﬁc ﬂows.
TABLE IV
PERCENTAGE OF FLOWS CONSIDERED AS UNKNOWN.
Class
Dataset
HTTP
Snort
Denial of
Brute
Alert
Service
Force
T1
33,89%
95,97%
100%
100%
T2
30,86%
96,88%
100%
100%
T3
32,49%
96,13%
100%
100%
Table IV presents the percentage of ﬂows considered as
unknown by the autonomic element. We can see that on
average 32.15% of HTTP ﬂows were classiﬁed as unknown.
It is noteworthy that the initial error rate may indicate a slight
concept drift of such ﬂows. We also see that our autonomic
element, obtained an average accuracy of 96.33% of Snort
Alert ﬂows and 100% in classes of attacks, which implies a
high degree of discriminantion of the model generated during
the supervised phase.
Tables V and VI show the Concept Drift and Novelty
percentage of candidates clusters generated by autonomic
element after analysis on the short-term memory.
TABLE V
CONCEPT DRIFT PERCENTAGE OF CANDIDATES CLUSTERS.
Class
Dataset
HTTP
Snort
Denial of
Brute
Alert
Service
Force
T1
100%
0,83%
0%
0%
T2
100%
0,78%
0%
0%
T3
100%
0,81%
0%
0%
Table V presents the percentage of candidates clusters en-
dorsed by our autonomic element of the type concept drift. We
can observe that from the ﬂows HTTP classiﬁed as unknown,
100% of there are classied concept drift, which indicates
a slight concept drift of these ﬂows relative to the normal
concept determined during supervised phase. We also see that
we had an average rate of 0.81% of Snort Alert ﬂows regarded
as the type concept drift, which may explain the rate of 3.67%
of false positive found by our autonomic element. Table V also
shows that none of the ﬂows of the classes of attacks Denial of
Service and Brute Force, generates clusters of the type concept
drift.
TABLE VI
NOVELTY PERCENTAGE OF CANDIDATES CLUSTERS.
Class
Dataset
HTTP
Snort
Denial of
Brute
Alert
Service
Force
T1
0%
99,17%
100%
100%
T2
0%
99,22%
100%
100%
T3
0%
99,19%
100%
100%
Table VI presents the percentage of candidates clusters
endorsed by our autonomic element considered novelty. We
can observe that none of the HTTP ﬂows generated candi-
date clusters like novelty, which indicates a high degree of
discriminator the of chosen variables and the normal model,
both made during supervised phase. We can also observe that
our autonomic element found a rate of 99.19% of candidates
clusters of the Snort Alert class as type Novelty and 100%
accuracy in the classes of attack artiﬁcially generated, show-
ing once again the high discriminat degree of the variables
chosen and the quality of the model generated during normal
supervision.
From the results presented, we can observe a high capacity
of the our autonomic element to identify the trafﬁc considered
normal, with an average accuracy of 98.77%. It noteworthy
also that all normal sub-ﬂows considered unknown, generated
concept drift clusters and all sub-ﬂows of the classes of attacks,
were correctly classiﬁed as unknown and generated novelty
clusters.
162
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

VI. CONCLUSIONS AND FUTURE WORKS
In this paper, we presented an autonomic element to provide
self-protection and self-conﬁguration in a computer network,
that makes use of OLINDDA, a novelty and concept drift
algorithm in data streams. The OLINDDA uses a cluster-based
approach, which considers the problem of detecting concepts
from an one-class classiﬁcation perspective.
The implementation of the proposed autonomic element
occurs in two phases: the ﬁrst is called supervised phase and
the second phase called unsupervised. In the ﬁrst phase, the
autonomic element determines the statistical variables that best
discriminate the trafﬁc considered normal(attack free) from
a trace previously classiﬁed. In the unsupervised phase, our
autonomic element implementation executes the autonomic
cycle, using the set of variables and the normal concept is
determined during the supervised phase.
From the results presented, we can observe that the im-
plementation of our autonomic element showed an average
accuracy of 98.77% of all ﬂows classiﬁed as malicious, which
indicates a high degree of accuracy in the classiﬁcation of
ﬂows and a strong learning ability of our autonomic element.
Despite our autonomic element has been applied in a small
set of attacks, it can be perfectly applicable to other types
of attacks. We intend in future work, add new attacks and
simulate more realistic scenarios.
REFERENCES
[1] T. R. M. Braga, F. A. Silva, L. B. Ruiz, and H. P. Assunc¸˜ao, “Redes
autonˆomicas. anais dos minicursos do 26 simp´osio brasileiro de redes
de computadores,” SBC, pp. 159–208, 2006.
[2] J. O. Kephart and D. M. Chess, “The vision of autonomic computing,”
in IEEE Computer Society.
36(1): 41-50, 2003.
[3] S. A. Mingoti, An´alise de Dados Atrav´es de M´etodos de Estat´ıstica
Multivariada: Uma Abordagem Aplicada.
Editora UFMG, 2007.
[4] E. J. Spinosa, A. P. de Leon F. de Carvalho, and a. Gama, Jo “Olindda:
a cluster-based approach for detecting novelty and concept drift in data
streams,” in SAC ’07: Proceedings of the 2007 ACM symposium on
Applied computing.
New York, NY, USA: ACM, 2007, pp. 448–452.
[5] S. P. Lloyd, “Least squares quantization in pcm,” IEEE Transactions on
Information Theory, vol. 28, pp. 129–137, 1982.
[6] T. Nguyen and G. Armitage, “Training on multiple sub-ﬂows to optimise
the use of machine learning classiﬁers in real-world ip networks,” Local
Computer Networks, Annual IEEE Conference on, vol. 0, pp. 369–376,
2006.
[7] “Ipoque’s dpi software’s open source version.”
http://www.opendpi.org
(as of November, 2010), 2010.
[8] “Snort is an open source network intrusion prevention and detection
system (ids/ips).”
http://www.snort.org (as of November, 2010), 2009.
[9] Hyenae, “Hyenae project (hyenae).”
http://hyenae.sourceforge.net (as
of November, 2010), 2010.
[10] Brutus,
“Brutus
-
the
remote
password
cracker.”
http://www.hoobie.net/brutus (as of November, 2010), 2001.
[11] S. J. Russell and P. Norvig, Artiﬁcial Intelligence: A Modern Approach,
2nd ed.
Pearson Education, 2003.
[12] M. A. Hall, “Correlation-based feature selection for discrete and numeric
class machine learning,” in Proceedings of the Seventeenth International
Conference on Machine Learning, ser. ICML ’00.
San Francisco, CA,
USA: Morgan Kaufmann Publishers Inc., 2000, pp. 359–366. [Online].
Available: http://portal.acm.org/citation.cfm?id=645529.657793
[13] E. F. Ian H. Witten, Data Mining: Practical Machine Learning Tools
and Techniques.
Morgan Kaufmann, 2005.
163
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

