100
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Increase of Robustness of Production Plans using a Hybrid Optimization and 
Simulation Approach 
 
Christoph Laroque 
Heinz Nixdorf Institute 
University of Paderborn 
Paderborn, Germany 
laro@hni.uni-paderborn.de 
Robin Delius 
Heinz Nixdorf Institute 
University of Paderborn 
Paderborn, Germany  
robin.delius@hni.upb.de 
Jan-Hendrik Fischer 
 
University of Paderborn 
Paderborn, Germany  
jhfischer@gmail.com 
Dennis Horstkemper 
 
University of Paderborn 
Paderborn, Germany  
dhorstkemper@gmail.com  
 
Abstract — We propose the use of the material flow simulation 
to evaluate the robustness of a production plan, which was 
created and optimized with no respect to unforeseen 
derivations. The necessary probabilities for machine failures 
and similar operational events on the floor can easily be 
integrated in the simulation model, in order to analyze, how 
initial plan performs in these situations. The influence of 
unforeseen events in daily production cannot be modeled 
within mathematical optimization without consuming either 
large amounts of computation time or requiring domain 
specific 
techniques, 
which 
increasingly 
decrease 
the 
maintainability of a model. We show a possible way to use 
simulation to evaluate and enhance a production plan. We 
illustrate the developed process using a real-world use-case of 
medium complexity and can show, that simulation is able to 
evaluate the robustness of a given pre-optimized production 
plan. 
Keywords - material flow simulation; robustness; production 
planning; mathematical optimization 
I. 
 MOTIVATION 
Even after overcoming the global economic crisis 
tremendous requirements exist within the daily operation of 
a production facility and its supply chain. Fluctuating 
demands are leading to less adequate forecast data and the 
need to lower capital commitment is leading to the 
necessarily of designing robust production planning models 
[1], [5], [6]. Major objective is always to be able to serve all 
demands in due time while causing minimal costs. 
Several uncertainties exist within the production 
planning process. On the one hand, many unforeseen events 
can take place: machine failures, missing materials, changed 
sales demands or ill employees are only a small subset of 
possible examples. On the other hand, it is simply 
impossible to include all factors that might occur into the 
planning process in the first place. Therefore, planning 
methods are always based on different models of a 
production structure, which are an abstraction of reality 
themselves.  It is the responsibility of the production planner 
to decide, which factors he wants to take into the account 
when creating the models. He always has to find a 
compromise between the detail level of the model (and 
therefore its significance) and the solvability of the 
optimization problem, which is created on its basis. The lot 
sizing and scheduling problems that are used within 
production planning are usually already np-complete even in 
their simplest form [15]. Therefore, one cannot guarantee to 
be able to find acceptable solutions in a timely manner 
while using modern operation research techniques. We 
show that the applying uncertain information to a simple 
stochastic optimization model yields either unacceptable 
solutions or unacceptable solution times. Thus, we have to 
find a way to include the aforementioned uncertainties 
within the production planning process without limiting its 
solvability 
significantly. 
Using 
advanced 
stochastic 
optimization techniques is out of the question: Special 
techniques, like the Benders Decomposition [22], are based 
upon the specific structure of certain optimization model. As 
production systems underlie a constant change however, the 
model needs to be able to be adapted constantly. 
Additionally efforts made in applying such a model for a 
certain production system cannot be reused, as two 
production systems and therefore the corresponding 
optimization models are seldom identical or even similar 
[23]. To create an approach, which allows for easy 
maintainability, 
sufficient 
solution 
quality 
including 
uncertain events and practical solution times we connect 
mathematical optimization models with a down streamed 
material flow simulation. While we always assume optimal 
conditions within the mathematical optimization model, we 
are including the uncertainties in the simulation process. 
This allows us to analyze whether a production plan is able 
to perform well creating an acceptable monetary solution 
under these changed conditions or not. We can improve 
upon scheduling decisions using rule-based machine 
controls within the simulation, reacting to changes in the 
production systems environment. In addition, we are able to 
create automatic or manual modifications of the plan and 
can evaluate these as well using additional simulations. It is 
easily possible to develop a more robust production plan 
with this toolset. 
Simulations usually are used to verify the solutions of an 
optimization problem. However, the aim of our research is to 
replace parts of the optimization process with simulation 
methods to receive solutions with an acceptable quality on a 
timely manner. First, we solve a mathematical optimization 
problem with standard solver software like IBM ILOG 
CPLEX [17]. The solution generated by the optimization is 

101
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
represented by a mst-file, will then be converted into a 
machine readable production plan, which is used as an input 
for the simulation environment d³fact. Within this 
environment we can evaluate the performance of a plan 
against environmental influences. Additionally, we can 
create production plans, which are optimized for a certain 
scenario, meaning a distinct combination of different 
influences, and use several of these plans to create a new 
production plan within a post-processing software. This plan 
shows an increased performance in any scenario, which we 
can proof by simulating and evaluating it again. Figure 1 
shows this general optimization and simulation process.  
After regarding the necessary State-of-the-Art in Section 
II, we describe the production model and the corresponding 
optimization models in Section III. It is possible to include 
uncertainties in the planning phase within the mathematical 
optimization process. We discuss these methods in Section 
IV and analyze the corresponding solution quality and 
solution times. To generate a more robust production plan 
based upon a given near optimal plan we propose a 
procedure, which generates and evaluates a number of 
scenarios with the help of offline simulations to create a 
new plan. We explain the transfer of the optimization 
solutions into the simulation process in Section V. To cover 
a broad spectrum of stochastically possible scenarios; 
several replications of the stochastic simulation based upon 
the production structure are performed. This way we are 
able to cover a wide field of possible scenarios for machine 
failures and other events. 
The production schedules are logged and afterwards 
evaluated on the base of costs and robustness. A rule-based 
machine control is used to reduce possible production losses 
when intermediate products were not assembled in due time. 
An additional post-processing can be used to maintain 
further robustness increasing actions. The effect of these 
actions can be evaluated using further simulations. We 
present these processes in Section VI. We finally evaluate 
the outcome of our work using a case study. Additionally, 
we give a conclusion (Section VII) and an outlook towards 
further possibilities and improvements for this approach.  
 
CPLEX
MST-File
Converter
Production 
Plan
d³FACT
Production 
Plan including 
uncertainties 
Evaluation
DB
Evaluated Production 
Plans
Postprocessing
 
Figure 1. General Structure of presented concept 
 
II. 
STATE OF THE ART 
An ideal environment, free from external influences as 
used in most scheduling approaches is normally not given 
when processing a production plan. Production settings are 
subject to influences from human and machine failures. 
Additional resources and materials might not be available in 
due time and new demands often have to be taken into 
account on a short-term notice. A comprehensive overview 
about the execution of production plans under uncertainties 
is given by Aytug et al. [2]. They develop taxonomy to 
classify uncertainties, to be able to classify numerous facets 
of disturbances within operational procedures. These are 
characterized by four dimensions: 
• 
Cause (e.g., machine failure) 
• 
Context (e.g., materials have not been delivered) 
• 
Effect (postponed starting times) 
• 
Inclusion (reaction upon interruptions, either  
predictive or reactive) [2] 
These 
aspects 
illustrate 
uncertainties 
within 
the 
production planning process. The effect of disturbances and 
interruptions depends upon the robustness of the scheduling. 
Schneeweiß [15] gives a basic definition of a robust plan: a 
plan is robust, when it is insensitive against random 
environmental influences. Based on this expression one 
cannot find any quantitative measurements however. Scholl 
[16] expanded upon this definition. We mainly consider two 
of the criteria he developed: if a plan is always valid, no 
matter what environmental influences may effect it, it is 
called “total validity robust”. One cannot assume to reach 
this level in practical applications though. Therefore, one is 
able to analyze the validity robustness in greater detail 
instead of using a binary value.  One could analyze the 
amount of broken model restrictions or also weight them 
after their importance. Within production planning, it is 
especially important to stay within the machine capacities 
and to adhere to given deadlines. We can consider the 
objective function of the planning models as the result of a 
production planning process. Therefore, one can define the 
criteria of result robustness: a plan is result robust, when its 
result only differs in a minimal way from the original plan 
when random environmental influences occur. However, a 
good result for one scenario may often lead towards a bad 
result for another scenario. Additionally result and validity 
robustness conflict with each other: a higher validity often 
causes higher costs. 
Simulations can fulfill two roles within robust 
production planning: on the one hand, one can use a 

102
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
simulation to simply assess and evaluate the robustness of a 
plan to confirm the validity of other approaches to create 
robust production plans. On the other hand they can be used 
to create robust production plans to include uncertainties. 
Aytug et al [2] identified three main approaches in prior 
literature to create robust production plans: completely 
reactive procedures, robust scheduling and predictive-
reactive scheduling. Completely reactive procedures only 
take action when disturbances in the production process 
already occurred. They sort and filter all jobs given to the 
current machine and continue with the job that appears to be 
the best based on this evaluation. 
Robust scheduling approaches instead are creating plans, 
which minimize the effects of disturbances within the 
production procedure. Therefore, a plan for a worst-case 
scenario is created. Such a plan aims to be able to be 
processed in many different scenarios without greater 
difficulties. Both of these approaches share the issue, that 
available capacities will not be used to their full extend. 
A large amount of research happens within the area of 
predictive-reactive scheduling. First, a plan for the whole 
planning horizon is created. This plan will be adapted later 
on. This can happen in a periodic fashion, on the occurrence 
of new events or in combination of both methods. In 
practice, these hybrid approaches are mostly used [12], [7]. 
Simulations are a standard tool to evaluate the 
robustness of production plans. This can be done based 
upon different target measures. Honkomp et al. [10] 
compare a basic deterministic simulation with multiple 
stochastic replications. To measure the robustness they use 
metrics that either compute the relation between the average 
objective function of the stochastic simulations and the 
deterministic objective function or calculate the standard 
deviation of the stochastic simulations towards the best 
deterministic objective function. Apart from cost analysis, 
Pfeiffer et al. [13] also consider the plan efficiency and 
stability. This is also done in the overview about 
rescheduling approaches. Usually one obtains simple 
efficiency measurements (e.g., delays, backlogging amounts 
and production times). One can also evaluate these values 
visually [8]. Plan changes caused by stochastic events are 
processed to optimize the efficiency values. However, 
effects of changes within the scheduling are not taken into 
account within these approaches. Instead of optimizing the 
efficiency values one might also aim to create plans that 
only differ minimal from the original plan. A framework to 
evaluate different techniques to generate robust production 
plans has been developed by Rasconi et al. [14]. 
Our work is based on well known optimization models. 
Typically, two different optimization models are used to 
create a production plan. Initially we calculate the lot sizes 
using 
a 
Multilevel 
Capacitated 
Lotsizing 
Problems 
(MLCLSP) based upon macro periods. Subsequently one 
creates a plan based upon micro periods using a Discrete 
Lot-Sizing and Scheduling Problem (DLSP) to determine 
exact production timings. As a result, the order is decided, 
in which the machines process their corresponding lots. We 
use a MLCLSP based on the formulation of Tempelmeier 
and Helber [9] and a DLSP based on the formulation of 
Drexel and Kimms [24]. These models can be combined in a 
hierarchical manner, relying on the formal description of 
hierarchical problems of Schneeweiß [35]. Several efforts 
have been made to include uncertain events into the 
formulation of these models. Additionally, special solution 
methods have been applied to these formulations. For 
example Gupta and Maranas as well as Bakir and Byrne 
propose a two staged model to include demand uncertainties 
[25][26]. Demand uncertainties are also analyzed by Chen 
and Chu [27]. They do however propose an adapted 
Lagrangian Relaxation approach to solve this problem. 
While demand uncertainty is a problem mostly approached 
in operative planning processes, more uncertainties 
obviously arise in tactical and strategic planning problems, 
which are spread about considerably longer timeframes. 
Three main classes of uncertainty, which were analyzed in 
scientific literature, are classified by Tajbakhsh et al. [28]: 
stochastic lead times, as they were discussed by Dolgui et 
al. [29] or Gurnaki and Gerchak [30], uncertainties in supply 
quality as considered by Radhoui et. al. [31] and 
uncertainties in purchasing prices. Our work however is 
only considering uncertainties in the operational production 
execution level.  
All aforementioned stochastic optimization approaches 
to include uncertainties do not take the model life cycle, as 
described by Forgione [32], into account. Literature and 
research typically do focus on creating and implementing 
better and more sophistic solution methods to find better 
solutions to increasingly complex optimization models in a 
shorter timeframe. However, they do not consider the 
maintainability of such models, which is a key part of a 
models life cycle and by far exceeds its deployment time if 
economically used [33]. Other researchers, like Sundaram 
and Wolf also note, that businesses demand optimization 
models to be adaptable for changes within their companies. 
This led to the introduction of Enterprise Model 
management Software, which however has not been used to 
include uncertain planning processes as of now [34]. 
Nevertheless, this demand lets us to conclude, that special 
complex solution methods for advanced stochastic models 
will not receive a broad acceptance in businesses and 
therefore are not applicable for real world problems.  
III. 
PRODUCTION MODEL 
To receive meaningful results we base our work on a 
close to reality production model with a corresponding 
complexity. Leaned upon a company in the supply industry 
of average size the model contains 21 machines with a 
general production structure, meaning that converging, 
diverging and linear substructures appear. Some of the 44 
products can be produced on several machines in a parallel 
matter. This may possibly lead to different production and 
setup times as well as costs. 11 products with external 

103
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
consumer demands exist in total. We can classify the model 
into 13 different levels, which could be used to decompose 
the problem. Based on this assumption, a high degree of 
freedom exists, when a concrete production plan shall be 
created. Figure 2 shows the overall machine plan and 
material flow of the production model. We create a lot-
sizing and scheduling by the combined usage of the Models 
MLCLSP and DLSP. 
 
Figure 2. Machine Plan 
A. Deterministic Lotsizing Problem  
To determine the production amounts for each given period 
we use a MLCLSP in this paper. The basic version of the 
MLCLSP, as described by Tempelmeier and Helber [9] 
develops a cost optimal multi-period production plan based 
on given demands, production costs, setup costs, inventory 
costs and machine capacities. For this purpose the 
optimization problem tries to take advantage of possible 
synergy effects that occur when production lots for several 
demands are combined, creating less need for setup 
processes. In contrast, this might create capital commitment 
and inventory costs when products are created in an earlier 
period. Therefore, a compromise between these factors has 
to be found. The model considers machine capacities in 
particular. Each machine can only be operated for a limited 
amount of time per period, for example for one or several 
working shifts. This does force an inventory increase. 
 
The MLCLSP is a model based on macro periods, 
meaning multiple actions can be done within one time 
period. Therefore it only determines which amounts of, 
which products are produced on, which machine in every 
given period. The model explicitly does not determine a lot 
scheduling. To reproduce dependencies between different 
products lead times are used. If a product needs another 
product from an earlier production level as an input, it has to 
be produced in an earlier period. A production of 
intermediate products is triggered whenever a final product 
is created. A bill of materials is used to determine the 
needed amounts.  
The 
MLCLSP 
we 
are 
using 
contains 
several 
enhancements over the basic models used in most literature. 
Several additional constraints are used to comply with the 
complexity of real production planning. Additionally to the 
standard model, we allow backlogging for products that 
have a direct external demand. Backlogged demands do 
however create extraordinarily high penalty costs, as the 
consequences of unsatisfied demands can be as severe as the 
loss of a customer. Products can be manufactured on several 
machines in a parallel matter. We include transport lots, 
forcing the production of certain parts in given batch sizes, 
and the machine capacities are determined upon a flexible 
work shift model. Late and Night shifts cause additional 
personal costs. Also, productions on Saturdays and Sundays 
lead to increasing costs. We do this to reflect the increased 
worker salaries at this time.  

104
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The mathematical formulation of the used model is as 
follows: 
Model MLCLSP: 
 
Minimize O = ∑
∑
∑
                  
 
   
 
   
 
   
                                
 
Under the Constraints: 
                ∑
             
 
                          
    ,   
  
(4.1.1) 
 ∑
                      
        
      
    ,     
(4.1.2) 
               
    ,   
  
(4.1.3) 
                
    ,    
  
(4.1.4) 
               
    ,    
 ,      
(4.1.5) 
        
     
     
       
    ,    
 ,      
(4.1.6) 
                
    ,    
 ,      
(4.1.7) 
             
    ,    
  
(4.1.8) 
    = 0 +    
          
      
    
       
    ,     
(4.1.9) 
   
      
      
    
    ,     
(4.1.10) 
∑
        
    
    ,     
(4.1.11) 
                
    ,    
 ,      
(4.1.12) 
 
Variables and constants meanings: 
 
    
Direct demand coefficient of products k and i 
    
Available capacity of resource j in period t 
    
Primary demand for product k in period t 
     
Personal costs for resource j in period t 
   
Stock expense ratio for product k 
   
Penalty costs for backlogging of product k 
J 
Amount of Resources (j= 1,2,…,J) 
   
Index set of operations performed by resource j 
M 
Big number 
   
Index set of followers of product k 
    
production costs of product k in period t 
     
Production amount of product k on resource j in 
period t 
     
Amount of containers of product k processed by 
resource j in period t  
      
Container size/Transport lot size for product k 
    
Setup costs for product k on resource j 
T 
Length of planning horizon measured in periods 
(t=1,2,…,T) 
     
Production time for product k on resource j 
     
Setup time for product k on resource j 
    
Stock for product k at the end of period t 
     
Binary setup variable for product k on resource j in 
period t 
     
Backlog variable for product k in period t 
       
Maximal backlog amount for product k (always 0 for 
intermediate products) 
   
     
     
  
Binary variables used to calculate the amount of used 
working shifts 
 
In the objective function the sum of setup-, stock-, 
production-, backlog penalty and personal costs are 
minimized. The following constraints enforce the creation 
of a valid production plan, which fulfills external demands 
in due time whenever possible. 
Constraint 4.1.1 creates a balance between external 
demands on one side and production- stock and backlog 
amounts as well as secondary demands on the other side. 
Thus, it is enforced, that demands can be either satisfied by 
production and inventory amounts, or that appropriate 
backlog penalty costs are applied. To be sure that 
intermediate products are assembled before the final product 
is created, products must be created a day before the 
secondary demand takes place. This day of lead time is 
needed, as the MLCLSP does not create an exact 
scheduling. Machine capacities are taken into account in 
constraint 4.1.2. It is only possible to perform a limited 
amount of production and setup activities within a single 
period. Constraint 4.1.3 ensures that one can only produce a 
product on a machine when a machine was set up for that 
product beforehand. 
Additionally, constraint 4.1.5 ensures that machines can 
only produce products that they can be set up for. Constraint 
4.1.7 expresses that production lots always have to be a 
multiple of transport lots. Within constraint 4.1.8, maximum 
backlog amounts for each product are defined. This way we 
can ensure that demands for intermediate products cannot be 
backlogged. The constraint 4.1.9 and 4.1.10 determine the 
amount of working shifts used for a machine in a certain 
period.  Constraints 4.1.11 and 4.1.12 are used to allow for a 
setup carry-over between different periods. This way, a 
machine only needs to be set up once, when a product is 
produced in several consecutive periods. The other 
constraints are used to design meaningful bounds to the 
variables, for example, stock amounts always have to have a 
positive value. 
 

105
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
B. Deterministic Scheduling Problem 
Using a DLSP one can assess a plan based upon micro 
periods to determine exact production timings. The 
solutions of the MLCLSP can be used as parameters for the 
DLSP. This way one can create a complete machine 
scheduling plan. A basic version of the DLSP can be found 
at Fleischmann [11] or Drexel and Kimms [24]. The 
production amounts within a period that have been 
determined using the MLCLSP can be used as external 
demands for the DLSP. Periods within the DLSP are chosen 
as the smallest meaningful unit, for example the smallest 
common denominator of setup- and production times. The 
MLCLSP includes lead times; therefore, it is not needed to 
take dependencies between production levels into account. 
Hence, we can solve the DLSP for each machine 
individually. This means that the solution times are rather 
short. We adapted the basic DLSP formulation to use a 
similar notation as our MLCLSP model. We did not include 
additional enhancements into our DLSP, as most major 
decisions were already done at the level of the MLCLSP. 
The mathematical formulation of the DLSP is as follows: 
 
Model DLSP: 
Minimize O = ∑
∑
      
 
   
         
 
   
 
 
Under the Constraints: 
                      
    ,     
(4.2.1) 
                  
          
    ,     
(4.2.2) 
                  
    ,     
(4.2.3) 
∑
   
 
   
    
     
(4.2.4) 
       
    ,    
(4.2.5) 
       
    ,    
(4.2.6) 
               
    ,    
(4.2.7) 
 
Variables and constants meanings: 
 
   
Available capacity in period t 
    
Primary demand for product k in period t 
   
Stock expense ratio for product k 
    
Production amount of product k in period t 
    
Setup costs for product k 
  
Length of planning horizon measured in periods 
(t=1,2,…,T) 
    
Production time for product k 
     
Setup time for product k  
    
Stock for product k at the end of period t 
    
Binary setup variable for a setup process of product k in 
period t 
    
Binary setup variable for a setup state of product k in period 
t 
 
The objective function is used to minimize the sum of 
setup and inventory costs. We use the DLSP to solely define 
a scheduling and not a lot-sizing. Therefore, it is not needed 
to include production and personal costs within this model. 
Constraint 4.2.1 is the inventory equation, expressing 
that demands have to be fulfilled by production and 
inventory amounts. As the DLSP is solved on a per machine 
basis, we do not take secondary demands into account. 
Additionally, backlog amounts are not represented, as we do 
not allow backlogging within the scheduling problem. 
Constraint 4.2.2 ensures that a bucket is either filled by a 
production process or by a setup process. As the DLSP is 
following a “All or nothing” principle for micro periods, a 
period capacity either gets completely used by a process, or 
is not used at all. In conclusion, a setup-carryover must be 
possible. Constraint 4.2.3 is included for this purpose. To 
ensure that only one setup state can occur at any given 
moment, Constraint 4.2.4 exists. The other constraints are 
used to design meaningful bounds to the variables. For 
example, production and inventory amounts always have to 
be positive. 
C. Combined Lotsizing and Scheduling 
To create a complete production plan including lot-
sizing and scheduling decisions, we use the models 
MLCLSP and DLSP combined in a hierarchical planning 
compound.  This combination can be based on the common 
schema for hierarchical planning problems, which was 
described by Schneeweiß [35]. He considers two different 
planning problems as shown in Figure 3: on the top level, a 
planning problem is making decisions, which have to be 
considered by the bottom level problem. Therefore, the 
decisions by the top level model create a decreased room for 
maneuvers for the bottom level model. The models 
MLCLSP and DLSP can clearly be used as a top level and 
bottom level problem in this fashion.  
 
 
Figure 3.  Hierarchical Planning Schema 
The Top level tries to anticipate the decision made by 
the bottom level. Typically a reduced set of information 
about the bottom level decision problem is used. This 

106
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
amount of information is called “Feed forward”. If all 
information was used and an exact anticipation of decisions 
of the bottom level was done, one would solve the complete 
bottom level problem within the top level problem. A 
distinction of the planning models would thus be pointless. 
Decisions of the top level problem can form “Instruction”, 
which are given to the bottom level problem and have to be 
considered by it. This does however mean that the top level 
problem can make decisions that lead to situations within 
the bottom-level problem that cannot be solved sufficiently. 
In this case a manual or automatic Feedback process has to 
take effect, which causes a new planning process at the top 
level under an adapted anticipation of the bottom level 
models decisions.  
Applied to our mathematical models, this means that the 
MLCLSP determines, which products shall be produced at 
what date. The production and setup times used by the 
MLCLSP are identical to the times used by the DLSP. 
Therefore the capacity usage can be exactly anticipated.  
Both models also only allow for the usage of one setup state 
at the same moment. Theoretically a lot determined by the 
MLCLSP could be produced in the form of two different 
lots. However, setup costs would occur twice in this case – 
therefore the model DLSP avoids this situation and the 
amount of setup processes is also correctly anticipated by 
the MLCLSP. Variable bounds and setup carryover 
constraints are also identical in function in both models. The 
MLCLSP therefore anticipates all decisions by the DLSP 
correctly, and the “Feedback” functionality is not needed 
when combining these models. The “Instruction” process is 
needed however. The variable outputs for production 
amounts in the MLCLSP are transferred to the input demand 
Parameter for the DLSP. The values can be transferred one 
by one, but the periods need to be adjusted, as the models 
operate on different time models. We assume that the 
demand applies at the last micro period within the DLSP 
that belongs to the according macro period within the 
MLCLSP. The amount of micro periods per macro period 
are determined by the amount of work shifts within the 
MLCLSP and therefore forms another “Instruction”. The 
different time models also account for the need to separate 
the models in the first place. Including micro periods within 
the MLCLSP would vastly increase the decision room and 
prolong solution times without increasing the solution 
quality. The correct anticipation of most of the DLSP’s 
decisions however allows us to exclude a lot of the 
information needed within the MLCLSP, leaving us with a 
very simple and fast to solve formulation of the DLSP. 
IV. 
STOCHASTIC OPTIMIZATION APPROACH 
Fuzzy parameters and uncertain information can be 
reproduced using stochastic methods inside the model 
classes we described earlier. Ideally, we already know exact 
probabilities for possible events in advance. Where 
applicable we can use appropriate prognosis methods to 
estimate this probabilities. Otherwise, we can only use a 
normal or similar distribution. 
The stochastic optimization tries to find a solution that is 
the best for all possible combinations of parameters. Finding 
a solution for these models already is a np-hard problem for 
sharp levels of information. Finding a solution for a 
stochastic problem is an extremely time consuming task. 
Fuzzy parameters might even lead to a state explosion, 
meaning that an exponentially rising amounts of possible 
parameter combinations exist. The overwhelming amount of 
combinations cannot be used to create a valid solution. This 
situation gets even more complicated, as we use a multi-
period, multilevel production structure. A problem in early 
periods or on a low level can lead to even more problems in 
later periods or levels. In many situations, one cannot find a 
solution that is applicable for all possible situations. 
Therefore, one cannot assume that that it is practical to 
include uncertainties in the planning process using 
stochastic optimization methods. Even when such a solution 
exists, it is unlikely that it can be found within a reasonable 
amount of time.  
A. Stochastic Optimization Techniques 
In literature and research, several approaches to include 
uncertainties into an optimization model exist. The simplest 
version is to create a deterministic substitute value model 
[36] [37]. The stochastic influences will be replaced by a 
deterministic value, for example by calculating the mean of 
the value throughout a finite set of scenarios. The 
expressiveness of such a model is rather limited, because 
edge cases with tremendous influences will not be handled 
at all [20]. This model class still is applicable in practice 
though, as it can be used to calculate minimum needed 
buffer times. 
A more complex version of stochastic optimization 
models are fat solution models [38]. In this model, class one 
tries to find a solution that is applicable to a number of finite 
scenarios, and creates a solution that is ideal within this 
constraints [39]. The occurrence of edge cases, for example 
an extremely prolonged set-up time, can cause huge issues: 
solutions must always adhere to the worst case scenarios. 
Therefore, it is hard to find a valid solution for this model 
type. Finding good solutions is almost impossible within 
most mid to large size problem classes using this modeling 
technique. 
Most sophisticated stochastic optimization approaches 
are based on three different methods. Multilevel stochastic 
models with compensation are based upon Dantzig [6]. 
Decisions on one level are made at an early point of time 
and fixed for all following levels. We consider a huge 
amount of possible events; therefore, we would have to 
model a corresponding amount of model levels. Stochastic 
programs with probabilistic constraints date back to Charles 
and Cooper [4]. Within these models, the breach of 
constraints is permitted for certain parameter combinations. 
One can only find proper solutions for this type of models 
when it is possible to transform the models into an equal 
deterministic model. Additionally, the expressive value of 
the model can be reduced due to the loosened constraints. 

107
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Bellman [3] introduced stochastic dynamic programming. 
Based upon a decision tree a backward chaining is used to 
conclude the ideal choice at the decision situation. All this 
approaches share the issue that they can only be solved 
efficiently, if the amount of possible scenarios can be 
reduced to a certain amount. However, when looking at a 
real production problem a seemingly infinite amount of 
decisions is possible.  
B. Setup Of Test Cases 
To test our assumption, that stochastic optimization 
models cannot be used to generate good solutions in a timely 
manner when including uncertainties, we created several 
simple stochastic optimization models. The production 
schedule execution is typically affected by unforeseen 
interruptions und disturbances. In our test models, cycle, 
and setup times are considered stochastically influenced, 
due to their high influence on the overall flow shop 
production process and their deterministic usage in the 
production-planning model. Material shortages, which arise 
from supplier unreliableness, are not taken in account and 
all materials are assumed of as supplied in time. However, 
scrap parts can also occur during the in-house production. 
We also include this possibility of uncertain behavior. When 
scrap parts are produced, the appropriate lot sizes must be 
expanded to compensate. 
The stochastic influences are modeled with two 
parameters. On the one, hand the likeliness of an increased 
process time or an occurrence of scrap part production and 
on the other hand the amount of the deviation. The 
probability that the planned process time varies, is modeled 
with a uniform distribution, whereas for the duration a 
normal distribution is used. Ideally, one is able to use 
historical data to determine the probabilities for each 
machine individually; however, this is not possible in a 
hypothetical model. 
First, we created a deterministic substitute value model. 
The variable amounts are derived from different test sets, 
and a ceiling modeling is used to keep the integrity of the 
integer inventory restriction. As expected, the resulting 
solution times differ only slightly from a purely 
deterministic optimization model. In comparison to the 
original plan, slightly more parts where produced in all lots 
and slightly more working shifts were applied. 
Secondly, we created a Fat Solution model. We use this 
model class within our MLCLSP similarly as before: for 
each scenario, the setup times, production times and 
production amounts are altered via stochastic factors. We 
are unable to find any solutions using this approach. The 
inventory balance equation cannot be fulfilled, as the 
production amounts are different in each scenario. 
Therefore, the inventory and backlog amounts cannot be 
equal throughout the scenarios. 
Lastly, we created a two staged stochastic optimization 
model with simple compensation. Inequalities of the model 
are accepted in some edge cases, but penalty costs apply to 
keep these occurrences low. Indirectly, we already include 
such penalties in our model, as we allow backlogging. To 
formulate a two staged model with simple compensation, we 
must simply allow different inventory and backlog amounts 
per scenario. Backlogging of a demand is an opportune 
business decision: sometimes demands simply cannot be 
fulfilled with the given production capacities. When a 
demand is backlogged until the end of the planning horizon, 
one even might consider ordering those parts externally 
through an alternative supplier or subcontractor. We can 
make the problem solvable by making the inventory and 
backlog variables scenario specific. A similar compensation 
cannot be done for capacity constraints though: while 
backlogging is an opportune business decision one cannot 
prolong a working day beyond the 24 hour mark. Therefore, 
we kept the capacity constraints in the fat solution format. 
We ran the optimization process with 10 and 100 
scenarios 
and 
for 
the 
different 
amount 
of 
machines/production levels to determine the problem sizes 
we can solve using this method. We cancelled the 
optimization runs if we either found a solution with a gap 
below 10% or weren’t able to find such a solution within 3 
hours. Tables 1 and 2 show the results of our test runs. 
Obviously, we are unable to find good solutions in 
medium or big problem sizes, as they appear in practice. 
Additionally, the high penalty costs for identified solutions 
make it appear, that these solutions do not suffice for the 
creation of a sensible plan. Considering this solutions and 
our argument that we are not able to use much further 
advanced stochastic optimization methods, because we 
cannot guarantee their maintainability, leads us to conclude 
that a different approach is needed to tackle this problem. 
Therefore, 
we 
propose 
an 
approach 
combining 
a 
deterministic 
optimization 
with 
a 
down-streamed 
simulation. 
 
 
 

108
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
TABLE 1. 
SOLUTIONS FOR 10 SCENARIOS 
Model-
type 
Mean Value 
Two Stage with Compensation 
# of Levels 
Solution Time 
(m:s) 
Solution Value 
(€) 
GAP 
(%) 
Solution Time 
(m:s) 
Solution Value 
(€) 
GAP 
(%) 
1 
00:01 
809,644 
1.76 
00:06 
850,455 
3.97 
2 
02:01 
3,923,725 
1.52 
03:20 
4,847,523 
1.05 
3 
00:43 
3,983,490 
2.62 
04:44 
4,910,212 
1.31 
4 
04:11 
3,958,611 
1.04 
06:56 
5,528,856 
9.93 
5 
105:09 
5,085,347 
9.34 
180:00* 
156,516,563 
17.3 
6 
166:28 
5,969,908 
9.32 
180:00* 
143,278,724 
87.3 
7 
180:00* 
6,417,375 
13.5 
180:00* 
246,840,729 
21.5 
8 
180:00* 
14,445,652 
58.7 
180:00* 
172,457,779 
85.7 
9 
180:00* 
14,323,895 
25.0 
180:00* 
196,765,403 
81.5 
10 
180:00* 
14,378,925 
24.53 
180:00* 
190,311,820 
76.6 
11 
180:00* 
76,451,461 
84.8 
180:00* 
171,081,633 
72.4 
12 
180:00* 
113,678,019 
89.50 
180:00* 
119,017,009 
54.9 
13 
180:00* 
842,996,612 
85.6 
180:00* 
195,472,374 
71.3 
TABLE 2. 
SOLUTIONS FOR 100 SCENARIOS 
Model 
type 
Mean Value 
Two Stage with Compensation 
# of Levels 
Solution Time 
(m:s) 
Solution Value 
(€) 
GAP 
(%) 
Solution Time 
(m:s) 
Solution Value 
(€) 
GAP 
(%) 
1 
00:01 
843,109 
5.65 
02:17 
866,438 
5.75 
2 
00:22 
3,910,988 
1.25 
180:00* 
1,768,362,646 
99.72 
3 
00:37 
3,986,675 
0.72 
180:00* 
1,768,362,646 
100 
4 
02:59 
3,945,480 
2.71 
180:00* 
1,768,311,953 
100 
5 
04:11 
5,085,347 
10 
180:00* 
1,768,235,686 
97.6 
6 
180:00* 
6,414,774 
14.5 
180:00* 
1,768,366,685 
97.3 
7 
180:00* 
6,307,645 
11.0 
180:00* 
1,768,312,876 
97.3 
8 
180:00* 
7,134,935 
15.8 
180:00* 
1,768,313,128 
96.9 
9 
180:00* 
15,696,427 
28.4 
180:00* 
1,768,367,156 
95.9 
10 
180:00* 
30,413,920 
62.3 
180:00* 
1,768,367,156 
95.9 
11 
180:00* 
49,768,107 
75.4 
180:00* 
1,768,367,632 
95.4 
12 
180:00* 
273,806,941 
95.4 
180:00* 
1,768,261,632 
95.2 
13 
180:00* 
158,961,462 
91.9 
180:00* 
1,768,262,192 
95.7 
 
 
*: No Solution with <10% GAP could be found within a 180 minute timeframe 
 
 

109
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
V. 
HYBRID APPROACH 
To be able to simulate the results of an optimization, the 
solution data has to be preprocessed in order to prepare the 
data for the simulation model. CPLEX can export a XML-
based file-format, which contains the mathematical 
programming solution for all variables of the problem. The 
Converter module reads the file line by line, whereas each 
line represents a variable. We mainly need two decision 
variables to be able to simulate the plan: the production 
variable      determines the products that are produced on a 
certain machine in a given time period. Additional data like 
production- and setup times as well as costs can be read 
from the database based on this production lots. Because a 
work shift model has been included in the mathematical 
optimization, every machine can have a different capacity in 
each period. Therefore, we also have to take the variable 
    into account, which describes these capacities. We sort 
the lots generated by the MLCLSP in order of the results of 
the DLSP model to create our initial scheduling. This can be 
done by analyzing the occurrence of setup process variables 
   . The real scheduling and date safeguarding will be done 
within the simulation process. Based upon the given data we 
are able to calculate all needed information in a 
deterministic fashion. For example, we are able to calculate 
the stock or backlog amounts via a difference of production 
amounts, demands and secondary demands. Thus, we have 
all information needed to control the simulation procedure. 
These calculations are also needed to evaluate the 
simulation results. Therefore, it is a sensible approach to 
calculate these values for the original plan instead of 
importing every information from the mathematical model. 
A. Simulation 
The simulation model is implemented using the discrete 
event simulator d³FACT developed by our workgroup, 
Business Computing, esp. CIM. The extensible Java API 
provides a high-performance, petri-net-based material flow 
component [1]. 
The production plan information is first transferred 
towards the simulation logic. During the initialization of the 
simulation model, all machines are loading their fixed 
schedules for the complete planning period. It holds for each 
machine, which products in what amount have to be 
produced in each period. Furthermore, it holds the planned 
durations for the maintenance, production and setup 
processes. The lot release order is fixed and stays so, even in 
the case of blocked lots due, to late secondary demands. All 
released lots are stored in a FIFO-Queue, to be processed in 
their incoming order. At the beginning of each new period, 
all planned lots are enqueued and the production cycle 
starts. Prior to nearly any lot, a setup is intended for rigging 
the machine. If planned, a routine maintenance of the unit is 
performed after a given amount of work pieces. 
If multiple products or machines demand the same 
intermediate product, a fork is needed to control the material 
flow. It stores and routes the tokens as needed towards the 
point of consumption. The built-in buffer stores the tokens 
until a machine starts a job and signals its demand. The fork 
uses a FIFO-Queue to handle the incoming requests and to 
minimize the mean waiting time for supply. The machine 
uses a strict FIFO-Queue for lots to dispatch. In this naive 
version, even a blocked lot with unfulfilled secondary 
demands waits until its demands are met. If all lots for a 
period are finished, the shift ends and the next jobs are 
dispatched in the next period. 
Under certain circumstances, it is possible that in case of 
unmet secondary demands and fully loaded periods, lots are 
pushed into the following period. In this case, the moved 
lots are scheduled prior to the regular lots to dispatch the 
longer waiting jobs first. Because the planning methods 
calculates with one day lead-time it is easily possible that 
delayed lots are blocking further following demands. 
B. Uncertainties in the production planning process 
We include the same kind of uncertainties in our 
simulation as before. These are the failure of machines in 
the form of prolonged cycle and setup times and the 
production of scrap parts. 
The cycle and setup times that are incorporated in the 
formulation of the production-planning problem, are 
forming the lower bound for the process execution and are 
modeled in the simulation. 
The stochastic influences are also using the same two 
parameters as before. They determine the number of 
uncertainties that occur, and the strength of their effects. 
C. Rule-based machine control 
To be able to improve the production plan within the 
simulation we are using a rule-based machine control. We 
are allowing a machine to change its own scheduling plan. 
As a day of lead-time is included in our planning process, 
this should not have a negative effect on later production 
levels.  One possible rule that we also implemented appears, 
when a machine is unable to produce a lot because the 
secondary demands cannot be met. In this case, the machine 
logic tries to find other lots for this period, which do not 
need the missing intermediate products. When such a lot 
exists, it is processed first while the original planned lot will 
be processed later. This way, we are able to ensure an even 
utilization of the given machine capacities. Additionally we 
reduce the danger of possible backlog amounts. This way 
we increase the validity robustness of the production plan. 
Another possible decision rule concerns setup carryovers. If 
production lots of the same product exist in successive 
periods, it is sensible to change the scheduling in a way, 
which allows this product to be produced in the end of the 
first period and in the beginning of the second period. 
Therefore, the need to setup the machines for both 
production lots is not applicable anymore. If one introduces 
a setup, carryover into the mathematical optimization highly 
increased solution times may occur. The discussed rule-
based mechanisms however only lead towards a small 
increase in processing time within the simulation process. 
Additional rules can always be applied in a model specific 
fashion. 

110
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
D. Evaluation 
The evaluation calculates performance figures for the 
validity and result robustness. For measuring the validity 
robustness, we compare the objective value of the simulated 
plans with the objective value of the original plan from the 
mathematical optimization. A comparison of single cost 
values is also possible, like evaluating the influence of 
capital commitment costs. A plan is considered validity 
robust, when it does not violate any of the optimization 
models restrictions. The model we use does allow 
backlogging however. Backlogging always incurs penalty 
costs, which also influence the result robustness. However, 
one cannot assess the influence of delivery dates that could 
not be met, as it might lead to the loss of a customer in the 
extreme cases. Therefore, it is sensible to protocol every 
appearance of backlog amounts. 
Important information considers the machine load 
factors. It can happen that the planned or even the maximum 
capacity of a machine is not sufficient to produce all lots 
allocated to it. These events are protocolled and evaluated 
separately as well. This allows for the search of admissible 
alternatives.  
E. Post-Processing 
Within the post-processing component, we are able to 
use additional simulation external methods to generate an 
improved production plan with an increased robustness 
based upon the simulated production plan. An increase of 
validity however usually creates increased costs. Therefore, 
we cannot assume that increased validity robustness also 
correlates with high result robustness. 
The simplest way to increase the robustness of a plan is 
to extend the given capacities where possible. Our model is 
based on a possible three-shift production. Generally, one 
tries to avoid using all three shifts to avoid high personal 
costs during nighttime. By courtesy of the simulation we 
can however estimate the increase of robustness when 
considering the introduction of additional shifts. This allows 
the production planner to decide whether the additional 
costs are justified or not. One possible way to do this 
automatically is to calculate the average of the production 
timings after a higher number of simulations. Afterwards we 
can determine the average machine load factor and decide 
upon the amount of needed work shifts.  
Another possible way to increase the robustness of the 
production plan is to move several lots into an earlier 
period, when this period contains larger capacity reserves. 
This process is considerably more complicated, as 
secondary demands also have to be fulfilled in due time.  
Therefor one cannot simply review available capacities for 
the final product. One also has to check whether available 
capacities for the production of all needed intermediate 
products exist, which often is not the case when the overall 
machine load factor is constantly high. Additionally an 
earlier production causes further inventory and capital 
commitment costs. Thus, this way often is not an opportune 
choice. In general, it lies in the responsibility of the 
production planner to decide, which amounts of cost 
increases he accepts to increase the validity robustness of 
his production plans. All production plans that are created 
within the post-processing can be simulated and evaluated 
again. The production planer consequently can access all 
information he needs to come to a corresponding decision. 
VI. 
RESULTS 
We executed several simulation runs based upon the 
production plan created by the deterministic mathematical 
optimization, including all 13 planning levels (c.f. figure 2) 
and using a planning horizon of 56 periods with a dynamic 
demand structure. We assumed a failure rate of 10% for 
each machine. The corresponding processes were prolonged 
by a standard deviation of 15% and 30%. Table 3 shows 
several performance indicators in a comparison of 
simulations with a naïve and rule-based machine control, in 
particular focusing delays for final products. We calculated 
the average values of 100 simulation runs, which took less 
than an hour of time, enabling us to handle real world 
problem sizes within a timeframe, which is applicable in 
practice. The rule-based machine controls objective function 
costs are considerably lower than the costs caused by the 
naïve machine control. It is noticeable that less final parts get 
delayed when using the rule-based machine control. 
Therefore, the ability to supply is increased and lower delay 
penalty costs occur. These also explain the lower objective 
cost values. 
TABLE 3. 
 COMPARISON BETWEEN DETERMINISTIC (D), RULE-
BASED (RB) AND NAIVE (N)MACHINE CONTROL 
 
 
However, a deterministic simulation of the production 
plan without stochastic influences shows that no penalty 
costs occur. The deterministic objective function value is 
correspondingly low. The rule-based machine control causes 
an improvement in result robustness as well as validity 
robustness. Table 4 shows the corresponding evaluation 
metrics by Honkomp et al. [10].  
 
TABLE 4. 
METRICS BY HONKOMP 
Standard 
Deviation Sim-Type 
          
  
̅̅̅̅      
15% 
Rule-Based 
40,00% 
1,42 
Naive 
40,09% 
1,52 
30% 
Rule-Based 
42,90% 
1,57 
Naive 
44,40% 
1,69 
 
Standard 
Deviation
Sim-
Type
Objective 
Function
Delayed Final 
Products 
(Absolute)
Delayed Final 
Products 
(Relative)
Delay Penalty 
Costs
Stock Costs
D
2.769.282,95 € 2.769.282,95 € 2.769.282,95 € 2.769.282,95 € 2.769.282,95 €
RB
3.944.976,12 € 3.944.976,12 € 3.944.976,12 € 3.944.976,12 € 3.944.976,12 €
N
4.211.949,84 € 4.211.949,84 € 4.211.949,84 € 4.211.949,84 € 4.211.949,84 €
RB
4.355.206,90 € 4.355.206,90 € 4.355.206,90 € 4.355.206,90 € 4.355.206,90 €
N
4.670.432,31 € 4.670.432,31 € 4.670.432,31 € 4.670.432,31 € 4.670.432,31 €
15%
30%

111
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The first column represents the relations between the 
standard deviation of all objective function values of all 
stochastic simulation runs and the objective function value 
of the deterministic simulation. A lower value indicates that 
disturbances and environmental influences have less impact 
on the ability to supply. The second column represents the 
relations between the objective function values of stochastic 
and deterministic simulations. The value shows the cost 
increase caused by the disturbances and directly shows the 
result robustness. Normally, a higher robustness is gained 
by increased costs. However, the inclusion of penalty costs 
into the objective function value causes lower cost for the 
more robust plan.  
Another reason for increased costs is personal costs. 
The simulation showed that more working shifts have to be 
introduced to be able to satisfy customer demands. The 
original plan was using working shift per day. The resulting 
plans when using either simulation method mostly used two 
or three shifts. The rule-based machine control delays 13% 
less products beyond the planned capacity restrictions, 
therefore needing less working shifts and causing less 
personal costs as well. When analyzing the problems within 
the production process one needs to find out where a 
possible bottleneck occurs. During the simulation we 
protocol all occurrences of backlog amounts and the 
connected machines, products and periods. For further 
analysis we can determine, which products are delayed most 
as shown in figure 4. 
 
 
Figure 4.  Delayed Final Parts according to products 
Surprisingly, most delays are caused by one final part. 
This is an obvious sign that the production capacity for this 
part might not be sufficient. Alternatively, production 
capacities for needed intermediate products might be 
insufficient. This can be found out by analyzing internal 
delays for the intermediate products. Table 5 shows the 
absolute and relative internal delays for both simulation 
types averaged over 100 simulations. We define internal 
delays as the amount of intermediate products that couldn’t 
be produced in the planned period. 
The usage of the rule-based machine control also shows 
an improvement when considering the internal demands. 
Despite not leading to direct revenue losses due to unmet 
demands, internal delays can cause costs when changes in 
the production plan have to be made. These costs aren’t 
implicitly included into our production model, but it is in the 
interest of the production planner to reduce these costs as 
well. When considering the internal delays per product we 
are able to find out that product 10 and product 11 are based 
on the same intermediate product. This product possesses 
several internal delays, which influence the production of 
the final products. We were able to find the bottleneck in 
our production model and can take action to reduce the 
impact of this issue. 
TABLE 5. 
ANALYSIS: ACCUMULATION OF INTERNAL DELAYS 
Standard 
Deviatio
n 
Sim-Type 
Internal 
Delays 
(Absolute) 
Internal 
Delays 
(Relative) 
15% 
Rule-Based 
10194,38 
1,81% 
Naive 
11172,92 
1,99% 
30% 
Rule-Based 
16172,68 
2,88% 
Naive 
17266,10 
3,07% 
VII. 
CONCLUSIONS 
We have shown in this paper that a material flow 
simulation can be used to analyze a production plan created 
in a mathematical optimization and to evaluate its 
robustness. It is easily possible to read the results of an 
optimization process, to transfer this data into our 
simulation framework. We are able to simulate the plan 
including probabilities for unforeseen events and fuzzy 
information. The results of the simulations can be used to 
find possible weak spots in the given plan. In several cases, 
we might be able to fix these weak spots through automatic 
post-processing or with manual changes. The effect of these 
changes can also be evaluated using additional simulation 
runs. Therefore, a production planner can decide whether he 
wants to implement these changes or not. Performing a large 
number of simulations is substantially faster than running 
another instance of the optimization problem. This 
especially holds true, if we compare runtime of our hybrid 
approach to the runtime of stochastic optimization methods. 
We were unable to find applicable solutions in real world 
sized problems in an acceptable timeframe using stochastic 
optimization methods and argued that advanced methods of 
decomposition for increased problem-solving efficiency are 
not accepted in practice due to their low maintainability. In 
the end, we recommend the hybrid optimization and 
simulation approach for practical and economic usage and 
expect further improvements to be made. 
REFERENCES 
[1] C. Laroque, R. Delius, J.-H. Fischer, and D. Horstkemper, “Increase 
of Robustness on Pre-optimized Production Plans Through 
Simulation-based Analysis and Evaluation”, Proceedings of The 
Third International Conference on Advances in System Simulation, 
IARIA Xpert Publishing Services, 2011, pp. 13-20. 
[2] C. Almeder, M. Preusser, and F.R. Hartl, “Simulation and 
optimization of supply chains: alternative or complementary 
approaches?”, OR Spectrum 31, Springer Verlag, 2009, pp.95–119. 
[3] M. Aufenanger, W. Dangelmaier, C. Laroque, and N. Rügener, 
“Knowledge-based Event Control For Flow-Shops Using Simulation 
and Rules”, Proceedings of the 2008 Winter Simulation Conference, 
1,66% 
98,34% 
Product 10
Product 11

112
International Journal on Advances in Systems and Measurements, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/systems_and_measurements/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Edited by S. J. Mason, R. R. Hill, O. Rose, T. Jefferson, J. W. Fowler, 
p 1952-1958, 2008. 
[4] H. Aytug, M.A. Lawley, K. McKay, S. Mohan, and R.Uzsoy, 
“Executing production schedules in the face of uncertainties: A 
review and some future directions” European Journal of Operational 
Research 161, 2005, pp 68-110. 
[5] R. Bellman, “Dynamic Programming”, Princeton University Press, 
Princeton, New Jersey, 1957. 
[6] R. Bihlmaier, A. Koberstein, and R. Obst, “Modeling and optimizing 
of strategic and tactical production planning in the automotive 
industry under uncertainty”, OR Spectrum 31, Springer Verlag, 2009, 
pp. 311-336. 
[7] S. Biswas and Y. Narahari “Object oriented modeling and decision 
support for supply chains”, Eur J Oper, Res 153, 2004, pp.704–726. 
[8] A. Charnes and W.W. Cooper, “Chance-constrained programming”, 
Management Science 5, 1959, pp. 73-79. 
[9] C. S. Chong, A. I. Sivakumar, and R. Gay, “Simulation-based 
scheduling for dynamic discrete manufacturing.”, Proceedings of the 
2003 Winter Simulation Conference, Edited by S. Chick, P.J. 
Sánchez, D. Ferrin and D. J. Morrice, 2003. 
[10] G. 
B. 
Dantzig, 
“Linear 
Programming 
under 
uncertainty”, 
Management Science 1, 1955, pp. 197-206. 
[11] M. Frantzén, A. H. C. Ng, and P. Moore, “Asimulation-based 
scheduling system for real-time optimization and decision making 
support”, Robotics and Computer-Integrated Manufacturing, 2011. 
[12] F. Ghezail, F. Pierreval, and S. Hajri-Gabouj, “Analysis of robustness 
in proactive scheduling: A graphical approach”, Computers & 
Industrial Engineering 58, 2010, pp. 193-198. 
[13] S. Helber and H. Tempelmeier, “A heuristic for dynamic multi-item 
multi-level capacitated lotsizing for general product structures”, 
European Journal of Operational Research 75, North-Holland,1994, 
pp. 296-311. 
[14] S. Honkomp, J. L. Mockus, and G. V. Reklaitis, “A framework for 
schedule evaluation with processing uncertainty“, Computers and 
Chemical Engineering 23, 1999, pp. 595-609. 
[15] B. Fleischmann, “The discrete lot-sizing and scheduling problem”, 
European Journal of Operational Research 44, North-Holland, 1990, 
pp. 337-348. 
[16] J. Maes, and L. Van Wassenhove, “Multi-Item Single-Level 
Capacitated Dynamic Lot-Sizing Heuristics - A General Review”, 
The Journal of the Operational Research Society, Vol. 39, No. 11 
(1988), pp. 991-1004. 
[17] A. Peiffer, B. Kádár, L. Monostori, and D. Karnok, “Simulation as 
one of the core technologies for digital enterprises: assessment of 
hybrid rescheduling methods”, International Journal of Computer 
Integrated Manufacturing, 21:2, 2007, pp. 206 – 214. 
[18] A. Peiffer, B. Kádár, and L. Monostori, “Stability-oriented evaluation 
of rescheduling strategies, by using simulation“,Computers in 
Industry 58, 2007, pp. 630-643. 
[19] R. Rasconi, A. Cesta, N. Policella, “Validating scheduling approaches 
against executional uncertainty”, Journal of Intelligent Manufacturing 
(2010), 2008, pp. 49-64. 
[20] C. 
Schneeweiß, 
“Planung 
2: 
Konzepte 
der 
Prozeß- 
und 
Modellgestaltung“, Springer, 1992. 
[21] A. Scholl, „Robuste Planung und Optimierung“, Physica-Verlags, 
2004. 
[22] ILOG CPLEX: High-Performance Software for Mathematical 
Programming and Optimization, http://www.ilog.com/products/cplex, 
20.12.2012 
[23] F. You and I. Grossmann, “Multicut benders’ decomposition 
algorithm for supply chain planning under uncertainty”, Annals of 
Operations Research 10479, 2011. 
[24] W. Dangelmaier, D. Brüggemann, B. Klöpper, and T. Rust, „OOPUS 
WEB - Eine flexible Plattform für die Implementierung von PPS-
Tools 
erläutert 
an 
der 
Anbindung 
einer 
CSLP-orientierten 
Belegungsplanung in der Serienfertigung“, Beiträge zu einer Theorie 
der Logistik, Springer, 2008, pp. 323-347. 
[25] A. Drexl and A. Kimms, “Lot sizing and scheduling - Survey and 
extensions”, European Journal of Operations Research, 1999, pp. 
221-235. 
[26] A. Gupta and C. Maranas, “Managing demand uncertainty in supply 
chain planning”, Computers and Chemical Engineering 27, 2003, pp. 
1219–1227. 
[27] M.D. Byrne and M. A. Bakir, “Stochastic linear optimisation of an 
mpmp production planning model”, International Journal of 
Production Economics 55 (1), 1998, pp. 87 – 96. 
[28] H. Chen and C. Chu, “A lagrangian relaxation approach for supply 
chain planning with order/setup costs and capacity constraints”, 
Journal of Systems Science and Systems Engineering, Volume 12, 
Number 1 2003, pp. 98-110. 
[29] M. M. Tajbakhsh, S. Zolfaghari, and C.-G. Lee, “Supply Uncertainty 
and Diversification: A Review”, Trends in Supply Chain Design and 
Management, Springer Series in Advanced Manufacturing, 2007, Part 
II., Part 3, p 345-368. 
[30] A. Dolgui, F. Grimaud and K. Shchamialiova, “Supply Chain 
Management Under Uncertainties: Lot-sizing and Scheduling Rules”, 
Springer Series in Advanced Manufacturing, Springer, 2010, Ch. 7, 
pp. 181–220. 
[31] H. Gurnani and Y. Gerchak, “Coordination in decentralized assembly 
systems with uncertain component yields”, European Journal of 
Operational Research 176 (3) ,2007, pp 1559 – 1576. 
[32] M. Radhoui, N. Rezg, and A. Chelbi, “Integrated model of preventive 
maintenance, quality control and buffer sizing for unreliable and 
imperfect production systems”, International Journal of Production 
Research 47 (2), 2009, pp. 389–402. 
[33] M. Radhoui, N. Rezg, and A. Chelbi, “Integrated model of preventive 
maintenance, quality control and buffer sizing for unreliable and 
imperfect production systems”, International Journal of Production 
Research 47 (2), 2009, pp. 389–402. 
[34] A. Bharadwaj, J. Chooineh, A. Lo, and B. Shetty, “Model 
Management 
Systems: 
A 
Survey”, 
Annuals 
of 
Operations 
Research(38), 1992, pp. 17-67. 
[35] D. Sundaram and E. Wolf, “Enterprise Model Management Systems”, 
Proceedings of EOMAS '09: Proceedings of the International 
Workshop on Enterprises & Organizational Modeling and Simulation, 
New York, 2009. 
[36] C. Schneeweiß, „Elemente einer Theorie hierarchischer Planung“, 
OR-Spektrum 16 (2), 1994, pp. 161-168. 
[37] K. Marti, “Stochastic Optimization Methods”, Springer, 2008. 
[38] J. Birge and F. Louveaix, “Introduction to Stochastic Programming”, 
Springer, 1997. 
[39] A. Madansky, “Methods of solution of linear programs udner 
uncertainty”, Operations Research 10 (4), 1962, pp. 463 – 471. 
[40] J. Mayer, “On the numerical solution of stochastic optimization 
problems”, IFIP International Federation for Information processing 
199 (1), 2006, pp. 193–206. 
 

