Compositing Ground Penetrating Radar Scans of Differing Frequencies for Better 
Depth Perception 
 
Roger Tilley, Hamid R. Sadjadpour, Farid Dowla 
Department of Electrical Engineering 
University of California, Santa Cruz 
Santa Cruz, CA. 95064 
Email: {rtvax, hamid, dowla} @soe.ucsc.edu 
 
 
 
Abstract— Methods developed to reduce interference in a noisy 
environment, be it radar target responses or effective 
communications in the presence of noise for mobile phone 
users, are vital in delivering a clear usable signal.  The methods 
used to render a cleaner signal can also be used to combine 
signals of various frequencies. Ground Penetrating Radar 
(GPR) scans over the same area are no exception.  This paper 
explores using an optimization problem solver, the Expectation 
Maximization (EM) Algorithm, to define the weights to use to 
combine multiple GPR scans at different frequencies over the 
same target area.  This approach exploits the Gaussian 
Mixture Model (GMM) feature of the EM algorithm to 
produce a cleaner image at depth.  Our method demonstrates a 
measured improvement toward producing a cleaner image. 
Keywords-Ground 
Penetrating 
Radar; 
Expectation 
Maximization; Gaussian Mixture Model; Maximum Likelihood 
parameter estimation; Finite Difference Time Domain Method, 
GprMax. 
I.  INTRODUCTION 
Ground Penetrating Radar (GPR) scans are used to 
illuminate objects in various terrain types at different depths.  
The frequency scan that best illuminates an object is 
different at each depth. Higher frequency scans image 
objects closer to the surface in great detail while lower 
frequencies image objects deeper with less fidelity.  
Assuming GPR radar scans at different frequencies over the 
same terrain can be treated like sub-components of a square 
wave, where the summation of sub-components determines a 
crisp square wave; then, adding the scans together should 
form an improved image of the terrain being scanned with 
higher resolution to a lower depth [1]; a byproduct of the 
summation.  Just simply adding each scan together, as 
demonstrated in this paper, has been shown not to be 
sufficient for the GPR case but does suffice for square wave, 
triangle wave, and sawtooth wave cases.  For GPR scans, a 
weighted version of each scan presents the best solution to 
this problem [2].  Employing.an optimization problem solver 
to determine the weight applied to each scan is the first use 
of this method to develop an optimal weighted combination 
of GPR frequency scans.  In the literature, other methods 
have been proposed to solve this problem with varying 
success; all with a very similar approach to each other.  
Methods by Dougherty et al. [3], Booth et al. [4], and 
Bancroft [5] all discussed ways to weight each signal used to 
combine individual frequency traces of GPR scans.  Absent 
from these works are optimization problem solvers such as 
the Expectation Maximization (EM) Algorithm [6].  We 
have chosen to investigate using the data mixture feature of 
the EM Algorithm to develop optimal weights. 
In this paper, we describe the EM algorithm and its data 
mixture feature, as it relates to GPR scans of different 
frequencies, and compare the results with the methods of 
Dougherty et al. [3], Booth et al. [4], and Bancroft [5].  This 
paper is organized as follows. In Section II, we discuss work 
related to the multi-frequency GPR mixture process.  In 
Section III, the EM Algorithm data mixture process is 
described.  In Section IV, the Maximum-Likelihood (ML) 
Estimation process and its relationship to the EM Algorithm 
data mixture process [6][7] is described.  In Section V, we 
present an EM Algorithm Test Case.  Section VI, briefly, 
describes the methods of Dougherty et al. [3]. in developing 
signal weights.  Section VII, the methods examined by Booth 
et al. [4] are discussed.  In Section VIII, the methods 
proposed by Bancroft [5] are discussed.  In Section IX, we 
demonstrate that computer modeling can be used to 
substitute for real data.  In Section X, we present results of 
simulated GPR scan examples using the software GprMax 
[8], comparing EM Algorithm data mixture method with 
methods of Dougherty et al. [3], Booth et al. [4], and 
Bancroft [5].  In Section XI, we draw some conclusions and 
discuss possible future work. 
 
II. RELATED WORK 
A search of the relevant literature uncovered only a few 
publications on compositing of GPR signals.  The earliest 
works found discussed GPR time-slice analysis, GPR 
overlay analysis and GPR isosurface rendering, all similar in 
approach; mostly by archaeologists.  The general approach 
was to illuminate the strongest reflections at a specified time 
or depth with a color or shading.  Assemble the information 
by layers of depth or time and display the completed result. 
[9]. 
Dougherty et al. [3] was the earliest work found, which 
attempted to combine GPR signal traces for site 
characterization and bandwidth enhancement.  Their 
413
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

research involved real data taken from a former lumber mill 
waste site near Boise, Idaho.  Part of the focus was on 
developing a method to simulate the direct arrival pulse to 
ultimately subtract from the traces. An additional paper 
focus was on enhancing the GPR response by summing the 
traces of differing frequencies.  The latter part of the paper, 
focused on establishing proof of bandwidth enhancement 
through summation.  Some success was noted but, equally 
weighting and summing the traces only marginally 
enhanced the results.  Bandwidth enhancement was 
confirmed after trace summation using correlation. 
The results of Dougherty et al. [3] were re-affirmed in 
two publications both authored by Booth et al. [2][4]. They 
successfully repeated the enhancement of the spectral 
bandwidth by compositing; adding to the compositing 
method, shifts to align trace direct arrival peaks and an 
adjustment to trace weights before summing.  The scan 
weights were adjusted to enhance the magnitude of the 
higher frequency scans while de-emphasizing the magnitude 
of lower frequency scans.  Booth et al. [2] used data sets 
from glacial deposits near Guelph, Ontario, Canada for the 
first publication. The second publication [4], focused on 
attempting to find the best method to combine GPR 
frequency scans.  GPR data sets from the Waterloo Moraine 
in Ontario, Canada were analyzed.  Several methods to 
combine multiple frequencies were documented.  Weighting 
factors were developed from trace averaged amplitude 
spectra, as well as time invariant weighting factors output 
from a least-squares analysis, were evaluated.  The time 
invariant weight methods developed, attempted to match the 
compositing results to an idealized amplitude spectrum.  
Improvements over Dougherty et al. [3]. were realized. 
Bancroft [5] continued the work by studying previous 
compositing methods by Dougherty et al. [3]. and Booth et 
al. [4].  Bancroft [5] introduced additional methods to 
compute weights for use in compositing GPR frequencies.  
One introduced method Bancroft [5] named the double ramp 
summation method, where one ramp suppresses a 
frequency’s energy over time while a second ramp 
introduces an adjacent frequency’s energy over time.  The 
ramp length was arbitrarily defined but, based on the 
wavelength of the GPR frequency of interest.  The start time 
for each ramp was a calculated value based on the GPR 
frequency of interest.  Bancroft’s [5] other method was 
called Amplitude Envelope Equalization.   The weights used 
in this ramp summation technique were developed as a ratio 
of the average envelope of GPR frequencies.  Improvements 
over Booth et al. [4] were not dramatic for the cases 
presented. 
The “state of the art” or related work to date has focused 
on mathematically defining the weights for each frequency 
by equal weighting, by the value needed to equalize the 
spectra of GPR frequencies, through ramp summation, or by 
a least-squares process to match an idealized amplitude 
spectrum.  Optimization problem solving methods have yet 
to be explored. Our previous work [1] addresses the 
problem as a clustering mixture model problem, well suited 
for EM methods. 
 
III. EXPECTATION MAXIMIZATION ALGORITHM 
The EM Algorithm is used to solve many types of 
problems.  One type is to group like items contained in 
complex mixtures; another type is to solve incomplete data 
problems by performing Maximum Likelihood (ML) 
parameter estimation.  A third type is to determine the 
membership weights of data points in a cluster within a finite 
Gaussian Mixture Model (GMM) [10][11].  This third 
feature is what will be exploited to combine multiple GPR 
frequency scans into a composite wave.  Other mathematical 
distributions can represent the data set created by GPR scans, 
but we used a Gaussian distribution because it is often used 
when the distribution of the real-valued random variables is 
unknown. 
We can define a finite mixture model f(x;θ) of K 
components as mixtures of a Gaussian function as: 
 
𝑓𝑓൫𝑥𝑥; 𝜃𝜃൯ = ∑
𝛼𝛼𝑘𝑘𝑝𝑝𝑘𝑘(𝑥𝑥| 𝜃𝜃𝑘𝑘)
𝐾𝐾
𝑘𝑘=1
, 
(1) 
 
Where:  
- 
𝑝𝑝𝑘𝑘൫𝑥𝑥ห𝜃𝜃𝑘𝑘൯  are K mixture components with a 
distribution defined over 𝑝𝑝൫𝑥𝑥|𝜃𝜃𝑘𝑘൯ with parameters 
𝜃𝜃𝑘𝑘 = ቄ𝜇𝜇𝑘𝑘, 𝐶𝐶𝑘𝑘ቅ  (mean, covariance) 
- 
𝑝𝑝𝑘𝑘൫𝑥𝑥ห𝜃𝜃𝑘𝑘൯ = 
 
1
(2𝜋𝜋)𝑑𝑑 2
⁄  |𝐶𝐶𝑘𝑘|1 2
⁄ 𝑒𝑒− 1
2ቀ𝑥𝑥−𝜇𝜇𝑘𝑘ቁ
𝑇𝑇
𝐶𝐶𝑘𝑘−1ቀ𝑥𝑥−𝜇𝜇𝑘𝑘ቁ 
(2) 
 
- 
𝛼𝛼𝑘𝑘 are K mixture weights, where  ∑
𝛼𝛼𝑘𝑘
𝐾𝐾
𝑘𝑘=1
= 1. 
- 
൛𝑥𝑥𝑖𝑖, … … … , 𝑥𝑥𝑛𝑛ൟ  Data set for a mixture component 
in d dimensional space. 
 
There are 2 steps in each iteration of the EM Algorithm, 
the Expectation step (E-step) and the Maximization step (M-
step).   The E-Step computes the conditional expectation of 
the group membership weights (𝑤𝑤𝑖𝑖𝑘𝑘′𝑠𝑠)  for 𝑥𝑥𝑖𝑖′𝑠𝑠  , adding 
unobservable data given 𝜃𝜃𝑘𝑘 .  The M-Step computes new 
parameter values ቀ𝛼𝛼𝑘𝑘, 𝜇𝜇𝑘𝑘, 𝐶𝐶𝑘𝑘ቁ to maximize the finite mixture 
model using the membership weights.  The E-Step and M-
Step are repeated until a stopping criterion is reached 
(convergence).  Convergence is indicated by the log-
likelihood of 𝑓𝑓(𝑥𝑥; 𝜃𝜃) not changing substantially from one 
iteration to the next. 
 
 
E-Step – 
𝑤𝑤𝑖𝑖𝑘𝑘 = 
𝑝𝑝𝑘𝑘൫𝑥𝑥𝑖𝑖|𝜃𝜃𝑘𝑘൯∗𝛼𝛼𝑘𝑘
∑
𝑝𝑝𝑚𝑚൫𝑥𝑥𝑖𝑖|𝜃𝜃𝑚𝑚൯∗𝛼𝛼𝑚𝑚
𝐾𝐾
𝑚𝑚=1
  
 
(3) 
 
for  1 ≤ 𝑘𝑘 ≤ 𝐾𝐾,   1 ≤ 𝑖𝑖 ≤ 𝑁𝑁;  
  
 
with constraint ∑
𝑤𝑤𝑖𝑖𝑘𝑘
𝐾𝐾
𝑘𝑘=1
= 1   
 
414
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

M-Step – 
𝑁𝑁𝑘𝑘 = ∑
𝑤𝑤𝑖𝑖𝑘𝑘
𝑁𝑁
𝑖𝑖=1
  
 
(4) 
 
𝛼𝛼𝑘𝑘
𝑛𝑛𝑛𝑛𝑛𝑛 = 
𝑁𝑁𝑘𝑘
𝑁𝑁  , for  1 ≤ 𝑘𝑘 ≤ 𝐾𝐾  
(5) 
 
𝜇𝜇𝑘𝑘
𝑛𝑛𝑛𝑛𝑛𝑛 = ቀ
1
𝑁𝑁𝑘𝑘ቁ ∑
𝑤𝑤𝑖𝑖𝑘𝑘 ∗ 𝑥𝑥𝑖𝑖
𝑁𝑁
𝑖𝑖=1
   
(6) 
 
for  1 ≤ 𝑘𝑘 ≤ 𝐾𝐾  
 
 
 
 
𝐶𝐶𝑘𝑘
𝑛𝑛𝑛𝑛𝑛𝑛 =    
 
ቀ
1
𝑁𝑁𝑘𝑘ቁ ∑
𝑤𝑤𝑖𝑖𝑘𝑘 ∗ ቀ𝑥𝑥𝑖𝑖 − 𝜇𝜇𝑘𝑘
𝑛𝑛𝑛𝑛𝑛𝑛ቁ ቀ𝑥𝑥𝑖𝑖 − 𝜇𝜇𝑘𝑘
𝑛𝑛𝑛𝑛𝑛𝑛ቁ
𝑇𝑇
𝑁𝑁
𝑖𝑖=1
(7) 
 
Convergence (log likelihood of  𝑓𝑓(𝑥𝑥; 𝜃𝜃) ) – 
 
    Log 𝑙𝑙(𝜗𝜗) =  
 
       ∑
log 𝑓𝑓൫𝑥𝑥𝑖𝑖; 𝜃𝜃൯ = 
𝑁𝑁
𝑖𝑖=1
 
 
 
 
 
∑
൫log ∑
𝛼𝛼𝑘𝑘𝑝𝑝𝑘𝑘൫𝑥𝑥𝑖𝑖ห𝜃𝜃𝑘𝑘൯
𝐾𝐾
𝑘𝑘=1
൯
𝑁𝑁
𝑖𝑖=1
         (8) 
 
These equations that make up the EM Algorithm were 
implemented in MATLAB.  The variables ‘k’ and ‘x’ 
represent the different scanning frequencies and GPR trace 
scans, respectively.  Each trace, at a frequency and 
transmitter (Tx)/receiver (Rx) position, are analyzed and 
combined for all frequencies using the EM Algorithm before 
moving on to the next position.  Described below are the EM 
GMM process steps. 
 
Expectation Maximization Gaussian Mixture Model process: 
1. Initialize algorithm parameters; weights (mixture 
and group membership), mean, covariance, for each 
trace. 
2. Expectation step – estimate parameters. 
3. Maximization 
step 
– 
maximize 
estimated 
parameters. 
4. Check for convergence – log likelihood of mixture 
model. 
5. Repeat steps 2 – 4 until change from iteration to 
iteration is below or equal a defined value. 
6. Combine traces with defined mixture weights. 
 
IV. MAXIMUM LIKELIHOOD ESTIMATION PROCESS AND 
THE EM RELATIONSHIP 
Maximum Likelihood Estimation (MLE) can provide a 
good estimate of an unknown parameter, which maximizes 
the probability of getting the data we observed (likelihood).  
A simple example is as follows.  Given a random sample X1, 
X2, …, Xn, independent and identically distributed (i.i.d.) 
with a probability density function 𝑓𝑓(𝑥𝑥𝑖𝑖, 𝜃𝜃), where 𝛳𝛳 is the 
unknown parameter to be estimated; the joint probability 
density function (PDF) can be labeled as L(𝛳𝛳). 
L(𝛳𝛳) = P(X1 = 𝑥𝑥1, X2 = 𝑥𝑥2, …, Xn = 𝑥𝑥𝑛𝑛) =  
 
 𝑓𝑓(𝑥𝑥1; 𝜃𝜃) ∗ 𝑓𝑓(𝑥𝑥2; 𝜃𝜃) … 𝑓𝑓(𝑥𝑥𝑛𝑛; 𝜃𝜃) = ∏
𝑓𝑓(𝑥𝑥𝑖𝑖; 𝜃𝜃)
𝑛𝑛
𝑖𝑖=1
  (9) 
 
Assuming the probability density function is Gaussian 
with known variance 𝜎𝜎2 and unknown mean, µ, then, the 
likelihood equation becomes the following: 
 
L(𝜇𝜇) = ∏
𝑓𝑓(𝑥𝑥𝑖𝑖; 𝜇𝜇, 𝜎𝜎2)
𝑛𝑛
𝑖𝑖=1
=  
 
 
 
𝜎𝜎−𝑛𝑛(2𝜋𝜋)−𝑛𝑛 2
⁄ exp (−
1
2𝜎𝜎2 ∑
(𝑥𝑥𝑖𝑖 − 𝜇𝜇)2
𝑛𝑛
𝑖𝑖=1
)  (10) 
 
To solve for the mean, 𝜇𝜇, we take the partial derivative of 
the log likelihood equation with respect to (w.r.t.) the mean, 
µ, and set the result equal to 0 to solve the resultant equation 
for the variable 𝜇𝜇.  Taking a second partial derivative of the 
log likelihood w.r.t. 𝜇𝜇 and returning a negative value verifies 
that the parameter 𝜇𝜇 does indeed represent the maximum 
value for the likelihood function. 
 
Log (L(𝜇𝜇)) =  −𝑛𝑛 log(𝜎𝜎) − 
𝑛𝑛
2 log(2𝜋𝜋) − ∑
(𝑥𝑥𝑖𝑖 − 𝜇𝜇)2
2𝜎𝜎
𝑛𝑛
𝑖𝑖=1
 (11) 
𝜕𝜕
𝜕𝜕𝜇𝜇 (log (𝐿𝐿(𝑢𝑢))) = −2(−1) ∑
(𝑥𝑥𝑖𝑖− 𝜇𝜇)
2𝜎𝜎2
𝑛𝑛
𝑖𝑖=1
= 0 
(12) 
Solve for 𝜇𝜇;       𝜇𝜇 = 
∑
𝑥𝑥𝑖𝑖
𝑛𝑛
𝑖𝑖=1
𝑛𝑛
 
 
(13) 
 
The process can be repeated for the variance should it not 
be known.  The MLE process becomes hard if there are at 
least two sets of data where only one set is partially observed 
(hidden) or when estimating mixture parameters is 
necessary. 
A mixture distribution has a PDF of the form 𝑓𝑓(𝑥𝑥) =
 ∑
𝛼𝛼𝑘𝑘𝑓𝑓(𝑥𝑥; 𝜃𝜃𝑘𝑘)
𝐾𝐾
𝑘𝑘=1
, where there are K number of components 
in the mixture model and for each k, there is a PDF, 𝑓𝑓(𝑥𝑥; 𝜃𝜃𝑘𝑘) 
as well as a weight 𝛼𝛼𝑘𝑘 and a complete observed data set x.  
Other assumed constraints are ∑ 𝛼𝛼𝑘𝑘 = 1
𝑘𝑘
 and 𝛼𝛼𝑘𝑘  ≥ 0 for all 
k.  The joint PDF takes on the form with n observed data for 
each k: 
 
𝐿𝐿(𝑥𝑥|𝛼𝛼, 𝜃𝜃𝑘𝑘) = ∏
∑
𝛼𝛼𝑘𝑘𝑓𝑓(𝑥𝑥𝑖𝑖; 𝜃𝜃𝑘𝑘)
𝐾𝐾
𝑘𝑘=1
𝑛𝑛
𝑖𝑖=1
 
 
(14) 
 
The log of the likelihood equation yields the following: 
 
Log(൫𝐿𝐿(𝑥𝑥|𝛼𝛼, 𝜃𝜃𝑘𝑘)൯ = ∑
𝑙𝑙𝑙𝑙𝑙𝑙 ∑
𝛼𝛼𝑘𝑘𝑓𝑓(𝑥𝑥𝑖𝑖; 𝜃𝜃𝑘𝑘)
𝐾𝐾
𝑘𝑘=1
𝑛𝑛
𝑖𝑖=1
 
(15) 
 
Solving this weighted MLE equation using MLE is 
challenging because of the log of sums and the challenge to 
determine what value to start with for the weight associated 
with an individual distribution 𝛼𝛼𝑘𝑘.  There may be many local 
maxima that are less than the global maximum that are 
available. Choosing the weight value that arrives at the 
global maximum for the log likelihood is not likely in short 
order.   
The EM algorithm provides a means to estimate the 
weights and guarantee convergence of the likelihood 
equation [6][7] to a non-decreasing local maximum with 
each completion of all steps of the algorithm.  The EM 
algorithm reduces the MLE optimization problem to a 
sequence of simpler optimization sub-problems that are each 
guaranteed to converge. 
415
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Another way to describe the MLE process and the EM 
algorithm relationship is through this example of 2 different 
coins tossed [12].  Two coins each tossed 10 times with the 
result of Heads or Tails recorded as well as, which coin 
produced the recorded values for 5 sets of 10 tosses.  All 
information is known therefore the calculation of the 
probability of Heads (𝛳𝛳A) for coin A and the calculation of 
Heads (𝛳𝛳B) for coin B are straight forward. 
 
𝜃𝜃𝐴𝐴 = 
#𝑜𝑜𝑜𝑜 ℎ𝑛𝑛𝑒𝑒𝑒𝑒𝑒𝑒 𝑢𝑢𝑒𝑒𝑖𝑖𝑛𝑛𝑢𝑢 𝑐𝑐𝑜𝑜𝑖𝑖𝑛𝑛 𝐴𝐴
𝑇𝑇𝑜𝑜𝑇𝑇𝑒𝑒𝑇𝑇 # 𝑜𝑜𝑜𝑜 𝑐𝑐𝑜𝑜𝑖𝑖𝑛𝑛 𝑜𝑜𝑇𝑇𝑖𝑖𝑝𝑝𝑒𝑒 𝑜𝑜𝑜𝑜𝑓𝑓 𝑐𝑐𝑜𝑜𝑖𝑖𝑛𝑛 𝐴𝐴  
(16) 
𝜃𝜃𝐵𝐵 = 
#𝑜𝑜𝑜𝑜 ℎ𝑛𝑛𝑒𝑒𝑒𝑒𝑒𝑒 𝑢𝑢𝑒𝑒𝑖𝑖𝑛𝑛𝑢𝑢 𝑐𝑐𝑜𝑜𝑖𝑖𝑛𝑛 𝐵𝐵
𝑇𝑇𝑜𝑜𝑇𝑇𝑒𝑒𝑇𝑇 # 𝑜𝑜𝑜𝑜 𝑐𝑐𝑜𝑜𝑖𝑖𝑛𝑛 𝑜𝑜𝑇𝑇𝑖𝑖𝑝𝑝𝑒𝑒 𝑜𝑜𝑜𝑜𝑓𝑓 𝑐𝑐𝑜𝑜𝑖𝑖𝑛𝑛 𝐵𝐵  
(17) 
 
Restructuring the problem such that the coin that was used, 
for any of the 5 sets of 10-coin tosses, is unknown.  The 
approach of calculating with hidden data, which coin, 
involves an iterative scheme where a guess is made to 
determine, which coin was used for each of the 5 sets; then, 
calculating the MLE as before; repeating this process until 
convergence.  Many local maxima are found before the 
global maximum is determined. Each local maximum 
reached in the interim is not necessarily larger than the 
previous outcome.  Changing the initial guess can change the 
order of the outcome. 
The EM process for this example is implemented such that 
the probability of start values is calculated using existing 
data (Expectation Step).  The following step is to recalculate 
the model parameters then, calculate the maxima for that set 
of parameters using an MLE process (Maximization Step).  
The EM process is repeated until a global maximum is 
reached.  The EM process creates a simpler optimization 
sub-problem at each iteration that is guaranteed to converge 
and has been shown to have an increasing maximum value 
for each cycle (E-Step, M-Step).  A set of equations as 
shown below represent the EM solution given initial values 
of 𝛳𝛳A and 𝛳𝛳B. 
 
Expectation Step 
𝑝𝑝(𝐴𝐴)𝑖𝑖 = 
𝜃𝜃𝐴𝐴𝑁𝑁𝑁𝑁 (1−𝜃𝜃𝐴𝐴)𝑁𝑁𝑁𝑁
𝜃𝜃𝐴𝐴
𝑁𝑁𝑁𝑁(1−𝜃𝜃𝐴𝐴)𝑁𝑁𝑁𝑁 +  𝜃𝜃𝐵𝐵
𝑁𝑁𝑁𝑁(1−𝜃𝜃𝐵𝐵)𝑁𝑁𝑁𝑁 
(18) 
𝑝𝑝(𝐵𝐵)𝑖𝑖 = 
𝜃𝜃𝐵𝐵𝑁𝑁𝑁𝑁 (1−𝜃𝜃𝐵𝐵)𝑁𝑁𝑁𝑁
𝜃𝜃𝐴𝐴
𝑁𝑁𝑁𝑁(1−𝜃𝜃𝐴𝐴)𝑁𝑁𝑁𝑁 +  𝜃𝜃𝐵𝐵
𝑁𝑁𝑁𝑁(1−𝜃𝜃𝐵𝐵)𝑁𝑁𝑁𝑁 
(19) 
 
where: NH is the number of heads in set i of 5 sets 
of 10 tossed coins, xi;  
p(A)i  – probability of heads for coin A in set i;  
p(B)i  – probability of heads for coin B in set i  
 
Maximization Step 
𝜃𝜃𝐴𝐴 =
∑
𝑝𝑝(𝐴𝐴)𝑖𝑖
5
𝑖𝑖=1
∑
𝑝𝑝(𝐴𝐴)𝑖𝑖 + ∑
𝑝𝑝(𝐵𝐵)𝑖𝑖
5
𝑖𝑖=1
5
𝑖𝑖=1
 
 
(20) 
𝜃𝜃𝐵𝐵 =
∑
𝑝𝑝(𝐵𝐵)𝑖𝑖
5
𝑖𝑖=1
∑
𝑝𝑝(𝐴𝐴)𝑖𝑖 + ∑
𝑝𝑝(𝐵𝐵)𝑖𝑖
5
𝑖𝑖=1
5
𝑖𝑖=1
 
 
(21) 
  
The EM algorithm provides a workable solution to a very 
hard problem when hidden or incomplete data exists.  It 
incorporates the MLE process only after reducing the model 
to a form, which is guaranteed to converge.  Combining GPR  
frequency scans have an aspect that the actual weight values 
for each frequency are unknown or hidden.  The way the EM 
algorithm accomplishes workable solutions to hidden or 
incomplete data sets, distinguishes it from other optimization 
problem solvers, thus making it a featured candidate to 
provide a viable solution for combining multiple GPR 
frequency scans. 
 
V. EXPECTATION MAXIMIZATION TEST CASE 
As an EM GMM test case, we constructed a series of six 
sine waves (50, 150, 250, 350, 450 and 550 Hz) noted in 
Figures 1-3, which when weighted properly, sum to the 
square wave of Figure 4.  Figure 5, demonstrates the result 
determined by the EM GMM as compared to the desired 
result.  The apparent error can be attributed to at least two 
conditions; to machine round off errors of the computer used 
and to the group membership weights, 𝑤𝑤𝑖𝑖𝑘𝑘 and/or mixture 
weights, 𝛼𝛼𝑘𝑘 each constrained to sum to one.  The weights 
normally sum to greater than one depending on the number 
of signals added together.  Even when the weights for sine 
wave to square wave construction are scaled to a maximum 
value of one; they still do not match up to the EM GMM 
generated weights.  Despite this limitation, the mixed success  
 
 
Figure 1. Sine wave frequencies 50-150 Hz.  
 
 
Figure 2. Sine wave frequencies 250, 350Hz. 
 
416
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

of adding arbitrary frequencies together bolsters our idea to 
use the EM GMM method on multiple GPR scans.  The GPR 
frequencies to choose for the analyses are simply the 
frequencies needed to span the depth and detail the GPR user 
wishes to achieve.  As a reminder, low frequencies image 
deep with low resolution where as high frequencies image 
with great detail in a shallow area. 
 
 
Figure 3. Sine wave frequencies, 450-550 Hz. 
 
 
 
Figure 4. Square wave desired signal. 
 
 
 
Figure 5. EM algorithm result with desired signal.  
 
VI. DOUGHERTY ET AL. PROCESS 
Dougherty et al. [3]. collected GPR data from a former 
lumber mill waste site near Boise, Idaho.  He sought to 
enhance the original GPR data through air wave/direct 
arrival wave removal, and bandwidth enhancement.  They 
first aligned each trace by the direct arrival pulse in each  
trace then, removed DC shifts; the low frequency “wow” 
component, followed by scaling each trace by the L2 norm 
of the direct arrival pulse.  The traces were summed and the 
resultant direct arrival estimate was then, subtracted from 
each trace removing the direct arrival signal.  An exponential 
gain recovery function was applied to each trace.  Equal 
weighting was applied to each trace with the direct arrival 
signal removed as each frequency was summed.  Dougherty 
et al. [3] demonstrated some clarity of shallow reflections  
due to direct wave removal.  They achieved resolution and 
continuity of reflection enhancement by summing the 
frequencies.  Spectral bandwidth was increased as well.  
However, the resultant signal was overwhelmed by the 
lower frequencies in the summation. 
 
Dougherty et al. [3] process steps are as follows: 
1. Align each trace by direct arrival. 
2. Remove DC shift. 
3. Remove low frequency (wow). 
4. Scale each trace by L2 norm of direct arrival pulse. 
5. Sum traces to form estimate of direct arrival signal. 
6. Subtract estimate from each trace. 
7. Apply exponential gain recovery function 
8. Apply equal weighting to each trace. 
9. Sum each trace all frequencies. 
 
VII. BOOTH ET AL. PROCESS 
Booth et al. [4], using real data acquired at a site on the 
Waterloo Moraine (an accumulation of glacial debris) in 
Ontario, Canada, examine five methods of achieving an 
increased bandwidth and thus a more approximate delta 
function through evaluating composite synthetic GPR 
wavelets; with a few method variations.  The simple 
summation of [3] was examined, as one method.  A second 
method, examined a scaled summation approach where the 
maximum value of each frequency spectra was determined 
and the spectrums equalized.  The values used to equalize 
the spectra provided the signal weighting prior to 
summation.  A third method, involved shifting traces such 
that the main peaks of the direct arrival pulses were aligned 
with the dominant peak then, the scaled summation of 
method two was applied.  Method three provided the best 
result for increased spectral bandwidth, thus the best delta 
function, and GPR resolution for synthetic wavelets.  Booth 
et al. [4] repeated the above analyses with GPR traces with 
one change.  The time-shifting of traces was changed to 
align the first break of each trace at 0 ns.  Then method two 
was applied, averaging the frequency spectra of each trace 
for one frequency then, determining the frequency weight; 
417
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

repeating for all frequencies.  This process was given the 
name of dominant frequency amplitude equalization 
(DFAE).  As a final discussion, another weighting method 
was examined where the weighting factors were obtained 
from a least squares analysis, Optimal Spectral Whitening 
(OSW) that attempts to match the summed result to a 
defined optimal amplitude spectrum.  The defined optimal 
spectrum determines over what set of frequencies the 
frequency data sets would be enhanced.  A time-varying 
Fourier transformation of each data set must be performed 
prior to implementing the least square analysis.   
The OSW process determined a time window to operate 
on by choosing the longest wavelet period of the GPR 
scanned frequencies. A frequency spectrum was produced 
for each time window of each trace. The spectra for a scan 
frequency were averaged together, and a magnitude was 
determined for each scanned frequency over the time-
window spectra.  The magnitude determined became a row 
in the OSW matrix.  The process continues for each scan 
frequency for that time-window resulting in an over-
determined linear system.  Then solving the over-
determined linear system for the frequency weights using a 
defined desired spectral amplitude.  The desired spectral 
amplitude is usually defined as identical values (constant), 
one for each scan frequency.  The OSW process is complete 
with the combining of traces for that time window with the 
computed weights. 
 
Booth et al. [4] process steps are as follows: 
Method 2 – 
1. Determine frequency spectrum of each wavelet. 
2. Equalize spectra for all frequencies; the magnitude 
needed to equalize spectra determines the weight 
for that frequency. (method 3 variation – average 
the frequency spectra of each trace for one 
frequency then, determining the weight; repeating 
for all frequencies). 
3. Sum each wavelet of all frequencies with 
appropriate weight for that frequency. 
Method 3 –  
1. Shift all traces such that main peaks of Direct 
Arrival Signal are aligned. (variation – align the 
first break of each trace to 0 ns). 
2. Continue by applying the steps of method 2. 
DFAE – method 4 
1. Remove DC shift. 
2. Remove low frequency (wow). 
3. Shift all traces to first break of Direct Arrival. 
4. Remove direct signal (mute-ramping from 0% to 
100% at chosen mute time). 
5. Determine frequency spectrum of each trace. 
6. Average spectrum for ensemble estimate. 
7. Equalize ensemble spectra for all frequencies; the 
magnitude needed to equalize spectra determines 
the weight for that frequency. 
8. Sum each trace of all frequencies with appropriate 
weight for that frequency. 
OSW – method 5 
1. Remove DC shift. 
2. Remove low frequency (wow). 
3. Shift all traces to first break of Direct Arrival. 
4. Remove direct signal (mute- mute-ramping from 
0% to 100% at chosen mute time). 
5. Average traces for each frequency. 
6. Compute spectra of average trace for each 
frequency. 
7. Determine magnitude at scan frequencies for each 
spectra; becomes a row in OSW matrix “A”.  One 
row for each frequency. 
8. Determine idealized frequency spectra vector “S”; 
vector usually set to value of one for each scan 
frequency. 
9. Determine weights by solving matrix equation 
𝑊𝑊 = (𝐴𝐴𝑇𝑇 ∗ 𝐴𝐴)−1 ∗ 𝐴𝐴𝑇𝑇 ∗ 𝑆𝑆.  
10. Combine weighted frequency traces;  𝑠𝑠𝑢𝑢𝑠𝑠 =
𝑡𝑡𝑡𝑡𝑡𝑡𝑡𝑡𝑒𝑒𝑠𝑠 ∗ 𝑊𝑊. 
11. Repeat steps 6 -10 for all analysis time windows 
over the GPR reflection Profile. Time window 
should be greater than the longest wavelet period to 
be sampled. 
 
VIII. BANCROFT PROCESS 
Bancroft [5], using real data from Santa Rosa Island, 
Florida, discusses the findings of Dougherty et al. [3] and 
the methods described by Booth et al. [4], while defining 
other methods to determine the weighting factors.  One 
method uses a ramped summation method where the higher 
frequency data was suppressed by the same amount that the 
lower frequency data was enhanced over the two-way transit 
time of a GPR scan.  Bancroft [5] discussed this double 
ramped summation technique using linear or Butterworth 
function ramps.  To determine the ramp length for each 
frequency, Bancroft [5] multiplied the wavelength period of 
a frequency by an arbitrary number of 15 for 15 wave 
periods.  For the double ramped method two adjacent 
frequencies were used; one frequency that was being 
enhanced and one frequency that was suppressed.  The ramp 
length was determined by the frequency that was being 
suppressed.  The 15th wave period was used as the ramp 
length.  The start time was determined by examining the 
amplitude envelope of a trace.  The amplitude envelope was 
calculated by taking the absolute value of the Hilbert 
transformation of a single trace.  The minimum value of the 
log of the averaged amplitude envelope for all traces of one 
frequency determines the suppression start time for that 
frequency. 
Another method discussed was called the Amplitude 
Envelope 
Equalization 
(AEE) 
technique. 
 
Without 
Automatic Gain Control (AGC) applied to each frequency 
data set, a set of multipliers were calculated as the ratio of 
418
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

the average envelope value of the lowest frequency and the 
average envelope value of the other frequency data sets.  
The weights or multipliers determined this way were 
applied to AGC processed frequency data sets over the 
portion of time that each frequency was to be enhanced.  
Determining the portion of time a ratio is applied was 
calculated by finding the minimum value of the log of the 
amplitude envelope (envelope computed without AGC 
applied); indicating the time where the suppression of that 
particular frequency data begins.  This point was defined as 
data too attenuated to provide useful information.  The 
average amplitude value of one frequency was determined 
by averaging the envelopes of all traces at one frequency.  
The weights established by this averaging method were used 
in conjunction with the double ramped summation method 
described earlier. 
Bancroft [5] also suggests an alternative subjective 
method to determine the weighting through visual 
inspection of each frequency data set; but there was much 
less clarity as to how this was done and how experienced the 
reviewer must be. 
 
Bancroft [5] process steps are as follows:  
1. Clip data prior to first arrival. 
2. Remove low frequency (wow). 
3. Automatic gain control gain. 
4. Bandpass filter. 
5. Determine 
length 
of 
decreasing 
ramp 
in 
nanoseconds beginning with highest frequency. 
6. Determine amplitude envelope of all traces 
(without AGC) of one frequency and average them. 
Repeat for all frequencies. 
7. Determine the suppression start time by finding the 
minimum value of the log of the amplitude 
envelope. 
8. Process traces adding them using the ramp 
summation technique. 
 
Amplitude Envelope Equalization Technique -  
1. Clip data prior to first arrival. 
2. Remove low frequency (wow). 
3. Automatic gain control gain. 
4. Bandpass filter. 
5. Determine 
length 
of 
decreasing 
ramp 
in 
nanoseconds beginning with highest frequency. 
6. Determine amplitude envelope of all traces 
(without AGC) of one frequency and average them. 
Repeat for all frequencies. 
7. Determine the suppression start time by finding the 
minimum value of the log of the amplitude 
envelope. 
8. Determine the AEE multipliers as a ratio of the 
average envelope of the lowest frequency data set 
and the average envelope of the other frequency 
data sets. 
9. Apply the AEE multipliers to the ramped 
summation technique. 
 
IX. COMPUTER MODELING VERIFICATION 
Computer model verification that GprMax delivers 
reasonably accurate simulated GPR scans is presented in 
reference [13].  In the reference, target objects were buried 
on a test site called “The Forest Lodge”, located near 
Greenville, California in the Northern Sierra about 60 miles 
(96.56 kilometers) north of Lake Tahoe.  The objects were 
metal (tin) roofing sheets approximately 1.83 meters (6 feet) 
long by 66 centimeters (26 inches) wide by 1.27 millimeters 
(0.05 inches) in depth.  There were 8 sheets in total buried at 
depths of 0.5 meters (1.64 feet), 1.0 meters (3.28 feet), 1.5 
meters (4.92 feet), 2.0 meters (6.56 feet), 2.75 meters (9.02 
feet), 3.0 meters (9.84 feet), 3.5 meters (11.48 feet) and 4.0 
meters (13.12 feet), roughly 1.83 meters (6 feet) apart.  The 
soil content appeared to be a mixture of clay and sand, 
though a geological survey was not conducted.  Figure 6 
shows the tin sheets before burial. A MALA Imaging Radar 
Array System (MIRA), a multi-static radar by MALA 
GeoScience Corporation, was used to scan the Forest Lodge 
site.  This radar consisted of 9 Tx’s and 8 Rx’s, constructed 
such that each receiver collected a signal from 2 adjacent 
transmitters at different times, constructing 2 channels 
received by one receiver.  This radar’s center frequency was 
set at 200 MHz providing 16 channels of data cutting a 2-
meter swath over targets of interest to create a 3-D image.  
The results shown in Figure 7 depict only 5 of the 8 roofing 
sheets clearly, in a stair step fashion as they were buried.  
For the 3-D model of Figure 8 a dry sand medium was used 
for the analysis.  Figure 9 and Figure 10 show two 2-D 
slices of the results of a 200 MHz analysis using the 
GprMax modeling program.  Actual and model results  
 
 
 
Figure 6. Target GPR imaging objects, tin roofing sheets, were buried 
at various depths.  The experiments provided ground truth GPR data for 
hardware to software comparison. 
 
419
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

compare favorably though the simulation shows all 8 sheets, 
5 of them well.  My argument that software analysis can be 
used successfully to study actual GPR received data is 
strengthened.  Using a mixture of clay and sand as the 
medium in the model we believe would show a better fit; 
target reflections would be attenuated more.  This could be 
achieved by adjusting the permittivity, affecting the velocity 
through the medium, and adjusting the conductivity, 
affecting signal attenuation. This success of actual data 
verses model data comparison, supports the use of computer 
simulation for accurate results and shall be used in the 
remaining analyses within this paper. 
 
 
 
Figure 7. Processed 3-D data scanned by MALA MIRA radar over the 
Forest Lodge test site of buried tin sheets of known depth.  5 of the 8 
roofing sheets are visible in a stair step fashion. 
 
 
 
 
 
Figure 8. GprMax 3-D model of the Forest Lodge site of buried 
objects.  This model was used to study FDTD response experiments 
conducted for this study. 
 
 
Figure 9. 
 
 
Figure 10. 
Figure 9 and Figure 10 FDTD Analysis results at 200 MHz for two 2-D 
slices of the 3-D analysis results.  All 8 of the simulated buried tin sheets 
are shown. 
 
X. GPR SCAN RESULTS 
To determine the capability of the EM GMM problem 
solver, a fictional area was defined using a Finite Difference 
Time Domain (FDTD) [14][15][16] modeling software 
package to produce GPR scans simulating real GPR scans.  
A Proprietary package in development, similar in operation 
to the popular GprMax software program by A. 
Giannopoulos [8] using the Transmission-Line Matrix 
(TLM) methods, as well as the GprMax software package 
were used to model a defined space.  The FDTD method 
provides a solution to Maxwell’s equations expressed in 
differential form.  Whereas the TLM method provides a 
solution by simulating the propagation of electric and 
magnetic fields by voltage and current pulses in 
interconnected transmission lines [17].   Only 2-D analyses 
were performed.  
420
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 11. Defined Space with buried target at 15 meters depth and Tx’s & 
Rx’s 5 meters above ground. 
 
The defined space modeled consisted of a Transmitter 
(Tx) and Receiver (Rx) suspended 5 meters above ground in 
air with a target (perfect electrical conductor) buried 10 
meters below ground in a moist-sand medium with a relative 
permittivity (𝜀𝜀𝑓𝑓 ) of 9.0 and an electrical conductivity of 
0.001 mS/m (Test Case 1 - TC1).  The target is 2 meters in 
length and 0.5 meters in depth. The transmitter and receiver 
were moved along the length of the defined space as shown 
in Figure 11 for a total of 36 scans at 0.25 meters per step.  
The Tx starts at 0.5 meters ending at 9.5 meters, and the Rx 
starts at 0.75 meters ending at 9.75 meters, well within the 
defined space of 10 meters in length by 25 meters in depth.  
Each scan is 425 ns long, capable of receiving a reflected 
signal approximately 24 meters below Tx’s and Rx’s in 
moist-sand and air, with a minimum grid space of 200 points 
in x-direction, (∆x – 0.05 meters), and 500 points in y-
direction, (∆y – 0.05 meters). 
Simulated GPR scans were repeated for 20, 30, 50, 100, 
500 and 900 MHz frequencies.  A 2-D display for each 
frequency result is shown in Figures 12-19.  In each case the 
object is correctly identified at approximately 10 meters 
below ground, approximately 15 meters below Tx’s and Rx’s 
or approximately 240 ns from the direct arrival signal (black 
line on plot); the two-way travel time for the radar signal.   
An individual trace by trace display is shown in Figure 17 
and Figure 19, to better depict the target return signal.  
Arrow 1 in Figure 12 shows the direct arrival signal and 
ground bounce (radar return from the ground).  Arrow 2 in 
Figure 12 denotes the target reflection at depth. In the 
30MHz trace result (Figure 13), the target is indicated by 
arrow 3.  The remaining unlabeled arrows indicate the target 
reflection at depth for the indicated scan frequency.  Of 
interest, is the line length in frequency scans 100 MHz and 
below indicating the target, representing limited if not non-
existent edge detection.  For this analysis, the test area length 
is less than half the depth (25 meters depth by 10 meters 
length), more like a bore hole, contributing to the limited 
target edge detection.  Arrow 4 (Figure 19) exhibits better 
edge detection. 
 
Figure 12. 2-D GPR scans 20MHz. 
 
 
Figure 13. 2-D GPR scan 30MHz. 
 
 
 
Figure 14. 2-D GPR scan 50MHz. 
1 
2 
3 
421
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 15. 2-D GPR scan 100MHz. 
 
Figure 16. GPR scan 500MHz. 
 
Figure 17.  GPR scan 500MHz (individual traces). 
 
Figure 18. GPR scan 900MHz (normal 2 D image display). 
 
 
 
 
Figure. 19. GPR scan 900MHz (individual traces). 
 
 
 
 
In all the simulated GPR scan results, as the frequency is 
increased, the area where the target exists is more 
pronounced.  The opposite occurs as the scan frequency is 
lowered. 
Figure 20 shows the result of adding each of the 
frequencies together having removed the direct arrival signal 
and scaling each signal max value to the same magnitude.  A 
broad area of target reflection is shown from approximately 
240 ns to 320 ns in depth (two-way travel time); a very 
rough indication of target depth.  The direct arrival signal 
was removed by subtracting a GPR scan without a target 
from a scan with a target, for each frequency. 
 
4 
422
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
 
Figure 20. Sum of frequency signals with direct arrival and ground bounce 
signals removed. 
 
 
Figure 21 and Figure 22 show the same signals combined 
using the EM algorithm to determine the weight of each 
signal.  Figure 22 shows the EM processed individual signal 
traces.  The area that is being scanned is more like a bore 
hole, twice as deep as its width.  This accounts for the broad 
reverse “u-shaped” area that begins at target depth.  The 
existence of lower frequencies in the sum broadens the 
output result. 
Figure 23 shows the results of applying the Dougherty et 
al. [3] approach to the same test area.  The target depth is 
correctly identified but the depth indication is slightly less 
crisp than the EM algorithm case.  The EM case depicts a 
thinner line in depth.  It appears the delta depth issue (less 
crisp) is the result of the lower frequencies in the sum. 
 
 
 
Figure 21. EM sum of frequency signals with Direct Arrival and ground 
bounce signals removed. 
 
 
Figure 22. EM processed signal traces with Direct Arrival and ground 
bounce signals removed. 
 
 
However, the Dougherty et al. [3] approach shows better 
edge detection.  The width of the target is better defined 
though still wider than the defined area but less than the EM 
GMM case.  For the Dougherty et al. [3] case, part of the 
Direct Arrival/Ground bounce signal is visible due to the 
method used to remove them from each frequency scan. 
For the same test area, applying the Booth et al. [4] OSW 
approach with one time-window results in the output shown 
in Figure 24.  Again, the target depth is correctly identified 
but like the Dougherty et al. [3] method the depth indication 
is quite broad.  The delta time depth indication is larger than 
the EM and Dougherty et al. [3] methods, (Figure 21 and 
Figure 23).  Similar to the EM method, the width in scan axis 
length is large; edge detection is not well defined.  The 
thickest part of the trace indicates the test target. 
 
 
 
    Figure 23. Dougherty et al. [3] standard response for TC1. 
 
423
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
           
 Figure 24. Booth et al. [4] response for TC1. 
 
Figure 25 demonstrates the AEE method of Bancroft [5].  
The target depth is correctly identified and the depth 
indication is like that of the EM method, sharp but slightly 
broader in depth.  This is about the same as the Dougherty et 
al. [3] method, and smaller than the Booth et al. [4] method.  
Target edge detection is more like Booth et al. [4] where the 
thickest part of the GPR result indicates the test target.  Like 
the EM method the GPR reflection covers a wide area (0 to 9 
meters) in scan axis length.  How much of this response is 
due to the bore hole effect of the target area is unknown at 
this time.  We applied a modified AEE method consisting of 
calculated multipliers only and not the ramped summation 
because the calculated start and end of each ramp conflicted 
with each other, which is not the case for the scan 
frequencies chosen by Bancroft [5]. 
 
 
Figure 25. Output from Amplitude Envelope Equalization 
method of Bancroft [5] for TC1. 
 
For test case 1, the test area definition poses a problem as 
to the effect of the bore hole like definition of the target area, 
on the outcome of the scan response.  Of concern, is whether 
a less than crisp edge detection or the addition of large 
magnitude lower frequencies, are making the depth 
indicators broad.  By exercising a more complicated test area 
with broader scan area we attempted to address these 
concerns. 
The second defined area consists of an area 30 meters in 
length and 25 meters in depth with little or no space above 
ground, (0.15 meters), for the Tx and Rx used (Test Case 2 – 
TC2).  They are swept along the scan axis length starting at 
0.5 meters (Tx) and ending at 24.85 meters with spacing 
between the Tx and Rx the same as before (0.25 meters), as 
shown in Figure 26.  The number of GPR scans is 145.  The 
electrical conductivity of the ground is the same as before 
but the relative permittivity (𝜀𝜀𝑓𝑓)  is 3.0 for dry sand.  Each 
scan is 550 ns long, capable of receiving a reflected signal 
approximately 48 meters below Tx’s and Rx’s in dry sand, 
with a minimum grid space of 150 points in x direction, (∆x 
– 0.2 meters), and 2500 points in the y direction, (∆y - 0.01 
meters).  Simulated burial in the ground at 8 different levels 
(4.565, 6.065, 8.565, 10.065, 12.815, 14.065, 16.565 and 
18.065 meters) are sheets of corrugated aluminum, modeled 
as perfect electrical conductors for ease of computation.  
Each sheet is approximately 2 meters in length and 0.1 
meters in depth.  The GPR scanning frequencies are the same 
as before.  The result for the EM method, shown in Figure 
27, identifies 8 targets at very close to the correct depth 
(approximately 50, 70, 100, 116, 148, 160, 190 and 208 ns 
for two-way travel time at a velocity in the medium of 
0.1732 m/ns for the defined relative permittivity) with edges 
depicted reliably but with less fidelity as one descends in 
depth.  Figure 28 displays the individual GPR traces instead 
of the image response. 
Applying the Dougherty et al. [3] method to this second 
test area produces the GPR response shown in Figure 29.  
Note that not all plates are depicted. Only 5 and barely 6 of 
the 8 are designated.  Where the plates end in width is 
tolerably detectable; edges are noted but not clearly.  The 
result is poorer than the EM processed response of Figure 
27; direct arrival signal removed by subtraction as before. 
 
 
 
 
Figure 26. EM algorithm Test Case, (8) 2 meter long plates, 0.1 meter 
thick. 
 
 
424
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 27. GPR scan result for complex structure. 
 
 
 
Figure 28. EM processed signal traces for complex structure. 
 
 
 
       Figure 29. Dougherty et al. [3] standard response for TC2. 
 
Figure 30 shows the GPR response of the Booth et al. [4] 
OSW method with one time-window applied to this second 
test area. The ground bounce (shown as a straight line at 
approximately 50 ns in Figure 30) is still present in the 
image because the mute feature had to balance between 
removing the direct arrival/ground bounce signal and not 
removing the reflection of the first plate at a depth of 
approximately 50 ns two-way travel time.  Again only a few 
plates are detectable.  Easily shown are the first 4 plates and 
barely plates 5 and 6 of the 8 plates in the test area.  
Comparing the result to the EM method, the Booth et al. [4] 
method falls short at depth.  Edge detection is poorer than the 
EM method but comparable to the Dougherty et al. [3] 
method. 
 
 
        Figure 30. Booth et al. [4] response for TC2. 
 
Figure 31 depicts the result of employing the AEE 
Bancroft [5] method on test area 2.  Like Booth et al. [4] and 
Dougherty et al. [3] before, not all buried plates are 
illuminated.  Of the 8 plates, 4 are depicted with a possibility 
of 3 more.  Added under plates at 50 ns and 75 ns in depth 
are “ghost” plates at 100 ns and 150 ns.  There were no 
targets buried at these two points.  Edge detection is better 
than Booth et al. [4] and Dougherty et al. [3] and on par with 
the EM algorithm.  Again, only the calculated AEE 
multipliers were used due to the same ramp start and end 
conflict issue. 
 
 
          Figure 31. Bancroft [5] response for TC2. 
425
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
For this more complicated test case, the EM algorithm 
has performed the best in terms of revealing the 8 buried 
plates.  Edge detection is still not great but tolerable for the 
EM method for both test cases and the Bancroft method for 
the second test case.  The larger scan area does address the 
bore hole effect question of wider scan axis length reducing 
wide reflection traces.  The dimensions of the scan area does 
affect the width of the scan axis reflections.  The ability to 
achieve crisp edge detection has not changed much however. 
The previous test cases modeled were all in homogenous 
material either moist sand or dry sand. Of interest to be 
modeled were objects placed in a non-homogenous material; 
layered like what could appear in nature. As an additional 
test case (TC3), a model area was created with dry sand, 
clay, concrete, granite, and limestone with relative 
permittivity of material noted in Figure 32.  Sheets of 
corrugated 
aluminum, 
modeled as 
perfect electrical 
conductors were buried as noted in the previous test case.  
The result (Figure 33) for the EM method on this test case 
mirrors that of the previous homogeneous medium case.  
There are a few subtle changes (coloration differences – the 
concrete buried object, plate 6, has a lighter color for 
example), which coincide with material the aluminum sheets 
(perfect electrical conductors) are buried in.  Figure 34 
shows the individual GPR traces. 
 
Figure 32. Test Case Area 3 (8)  2 meter long plates, 0.1 meter in depth. 
 
 
Figure 33. EM Algorithm GPR scan result for TC3 (8) Plates shown 
 
Figure 34. EM Algorithm GPR Scan result showing individual traces 
for TC3. 
 
XI. CONCLUSION AND FUTURE WORK 
In this paper, we have explored using the Expectation 
Maximization Gaussian Mixture Model, an optimization 
problem solver, to define weights to combine multiple GPR 
frequency scans over the same area to improve image 
resolution to a lower depth.  First, we looked at using the EM 
GMM method to combine multiple frequency sine waves to 
form a square wave by defining the best set of weights for 
the square wave frequency harmonics presented.  Though not 
without problems, the process performs reasonably well in 
forming a square wave combining the multiple frequencies.  
The value of the mixture weights summing to one is an issue 
to look at; but they are defined that way in the EM GMM 
algorithm.  Actual multiple sine wave mixture weight values 
are different but similar in magnitude.  Though not ideal, 
there was enough success to pursue using the EM GMM 
technique on GPR scans over the same area at different 
frequencies, the first use of this technique on GPR scans of 
multiple frequencies.  We explored whether the Maximum 
Likelihood Estimation process would be more fitting for our 
analyses.  In exploring this technique, we were reminded that 
the MLE process, though workable, presents problems when 
hidden or incomplete data exists [6][7].  The resultant 
likelihood equation does not have a closed form solution or a 
single global maximum and becomes very hard to solve.  
Whereas the EM Algorithm provides a well-structured 
solution by creating a set of simpler optimization sub-
problems, from the MLE process, that are guaranteed to 
converge and produce local maxima at each iteration that 
increase until a global maximum is reached. 
In considering the EM GMM case for GPR signals we 
encountered several other methods, in the literature, that 
attempted to combine scans of various frequencies over the 
same target area.  Methods by Dougherty et al. [3], Booth et 
al. [4] and Bancroft [5] were compared to our EM GMM 
method [18] as a way to judge how well our method 
performed compared to solutions found in the literature.  
Because we lacked the equipment hardware to perform field 
Dry sand (𝜀𝜀𝑓𝑓 − 3) 
Clay (𝜀𝜀𝑓𝑓 − 5) 
Granite (𝜀𝜀𝑓𝑓 − 4) 
Concrete(𝜀𝜀𝑓𝑓 − 6) 
426
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

experiments, a well-known computer program was used to 
model simulated target areas.  The targets were perfect 
electrical conductors and the media used well-defined 
permittivity values.  The scan results demonstrated the 
effectiveness of the software program GprMax [8].  The 
connection between actual and simulated results were 
detailed in reference [13] and discussed here briefly. The 
GprMax [8] results were determined to be an accurate 
depiction of field experiments.  We found that in comparing 
our EM GMM process with Dougherty et al. [3], Booth et al. 
[4] and Bancroft [5], our process faired the best in 
recognizing images at depths down to 20 meters in moist 
sand and dry sand media.  As a final test, we performed an 
experiment with the same targets positioned this time in 
several media types that varied with depth from the surface.  
In this non-homogenous experiment, we used dry sand first 
then, clay and granite, concrete and finally limestone as the 
final layer.  The result was the same as without such division 
in media types. 
Our results uncovered problem areas in need of future 
study.  The edge detection ability, how to reliably remove the 
direct wave/ground bounce without removing the reflected 
radar response from the target, and how to best align GPR 
trace starting points across frequencies, are a few examples.  
Solving the alignment problem appears to reduce the 
thickness in depth of the GPR scan results.  Of interest in a 
future project would be the result of using the EM GMM 
method in finding tunnels in a realistic clutter environment. 
 
APPENDIX A 
A.1  
GPR BASICS 
Ground Penetrating Radar method provides a way to map 
sub-surface artifacts or structures using radio waves.  GPR 
modes in practice consist of reflection, velocity sounding 
(common mid-point) mode and trans-illumination.  The 
most common mode is the reflection mode where a GPR 
radio wave from a transmitter at or above the ground 
surface, propagates through a medium to a buried target, 
reflecting the radar wave back to a receiving antenna.  The 
velocity sounding or common mid-point mode provides a 
method to determine the velocity of the radio wave in a 
medium by setting a transmitter and receiver at a specified 
distance apart; instituting a scan then, moving both 
transmitter and receiver a distance further apart, repeating 
the process several times.  The result provides a way to 
calculate the velocity through the medium that the radio 
waves have encountered.  Trans-illumination is used for 
Bore holes in two ways; One, a transmitter (Tx) and receiver 
(Rx) are moved in unison from one position to another 
beginning at the surface of a bore hole then, lower on either 
side of the area of interest; scanning is across the area of 
interest.  Two, only one transmitter is used and several 
receivers are placed at various positions in depth.  Figure 1A 
depicts these modes.  Antenna orientation, polarization and 
the available power verses the loss mechanisms determined 
by the radar range equation are of interest but beyond the 
scope of this paper. 
Of interest in the reflection mode method are the signal 
arrival types, the theoretical resolution of a GPR system, 
and what item is the major contributor to the velocity in a 
medium.  The signal arrival types are the direct air wave, 
critically refracted air wave, direct ground wave, and 
reflected wave.  The theoretical resolution is proportional to 
¼ of the velocity in a medium divided by the frequency of 
the radio wave (i.e. the wavelength in a medium divided by 
4;  𝑇𝑇ℎ𝑒𝑒𝑙𝑙𝑡𝑡𝑒𝑒𝑡𝑡𝑖𝑖𝑡𝑡𝑡𝑡𝑙𝑙 𝑡𝑡𝑒𝑒𝑠𝑠𝑙𝑙𝑙𝑙𝑢𝑢𝑡𝑡𝑖𝑖𝑙𝑙𝑛𝑛 = ቀ𝜆𝜆 = 
𝑉𝑉
𝑜𝑜ቁ 4
⁄  ).  The velocity 
in a medium is proportional to the speed of light in a 
vacuum divided by the square root of the relative 
permittivity of the medium making permittivity the major 
influence on the velocity in a medium. 
 
𝑉𝑉𝑒𝑒𝑙𝑙𝑙𝑙𝑡𝑡𝑖𝑖𝑡𝑡𝑉𝑉 = (𝑡𝑡 (√𝜀𝜀𝑓𝑓)
⁄
) ∗ 1𝑒𝑒−9meters/ns      (1A) 
c = speed of light (3e8 meters/sec) 
𝜀𝜀𝑓𝑓 – relative permittivity 
 
Permittivity is defined as a measure of how an electric 
field is affected and affects a dielectric medium.   Figure 2A 
and Figure 3A. depict the signal arrival types, and equations 
governing time, depth and velocity measurements. 
 
 
 
Figure 1A. GPR Scanning Modes [19]. 
 
Typically, short radar pulses are transmitted into the 
medium.  The most common pulses used are the “Ricker 
Pulse” (second derivative of a Gaussian pulse) or the first 
derivative of a Gaussian pulse (a Monocycle) (Figure 4A). 
427
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 2A. GPR Arrival Types [20]. 
 
 
 
Figure 3A. Simple CMP plot w/equations for  
Arrival Types [20]. 
 
 
Most equipment manufacturers do not divulge their transmit 
pulse type; but the “Ricker” Pulse is assumed.  Figures 5A-
8A show plots of typical reflected signals received without a 
buried target at various frequencies.  Each Tx/Rx is 5 meters 
above the ground (dry sand) in air.  Shown are the direct 
arrival signal and the ground bounce.  Note as the frequency 
increases, the direct arrival gets sharper and the ground 
bounce is better defined though the time of the return signal 
occurs is the same. 
 
Figure 4A. Gaussian, 1st derivative (Monocycle), 2nd 
derivative (Ricker)(normally GPR response signals for 
Monocycle and Ricker are inverted) [21]. 
 
 
Figure 5A. Direct arrival and ground bounce, 20MHz. 
 
 
 
Figure 6A. Direct arrival and ground bounce, 50MHz. 
 
 
 
 
Figure 7A. Direct arrival and ground bounce, 100MHz. 
 
Direct Arrival 
Direct Arrival 
Ground Bounce 
Ground Bounce 
Direct Arrival 
Ground Bounce 
428
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
Figure 8A. Direct arrival and ground bounce, 500MHz. 
 
Several methods exist to calculate the velocity of a radio 
wave in a medium.  The two most popular are derived from 
the common mid-point (CMP) mode.  Figure 3A depicts the 
first method, a simple plot of the CMP results with 
equations.  Figure 9A depicts the second method, the (time2 
– Tx/Rx separation2) analysis method named (t2-x2) where 
the slope of the plot is equal to 1/(velocity squared).  With 
simple manipulation of the result, the velocity in a medium 
can be determined. 
 
 
Figure 9A. Shows  𝑡𝑡2 − 𝑥𝑥2 𝐴𝐴𝑛𝑛𝑡𝑡𝑙𝑙𝑉𝑉𝑠𝑠𝑖𝑖𝑠𝑠  (st) [22]. 
 
A.2  
MODELING BASICS 
The top 2 methods used to model GPR analysis are the 
Transmission-Line Matrix (TLM) method and the Finite 
Difference Time Domain (FDTD) method [15].  Both 
methods provide a solution to Maxwell’s equation subject to 
geometry, initial conditions, and boundaries of a problem.  
The TLM method [17] is implemented as an electrical 
network model solution to an electromagnetic field problem.  
Transmission lines are interconnected at regular intervals to 
form TLM nodes.  The propagation of electric and magnetic 
fields are simulated by voltage and current pulses.  The 
model space step defines the distance between TLM 
adjacent nodes.  The time step represents the time, which a 
pulse takes to travel from one TLM node to the next. 
The FDTD method provides a solution to Maxwell’s 
equations expressed in differential form.  The partial 
derivatives in Maxwell equations are discretized using 
central difference techniques resulting in difference 
equations, which are solved by an iterative process.  
Included in the difference equations are the model space 
step and time step. 
 
A.3 
TWO-WAY-TRAVEL-TIME (TWTT) 
Figure 10A and Figure 11A demonstrate the GPR trace of 
the example in Figure 6 at 20 and 50 Mhz.  The target is 10 
meters below the ground and 15 meters from the Tx’s and 
Rx’s.  There are 2 mediums the radar signal travels through, 
free space (Tx/Rx to ground) and moist sand (ground to 
target).  The velocities for the 2 mediums are 0.3 m/ns (free 
space) and 0.1 m/ns (moist sand).  To determine the distance 
to the target from the Tx/Rx from Figure 7A, the mediums 
and the velocity through the mediums alone the following 
occurs. 
 
𝑇𝑇𝑊𝑊𝑇𝑇𝑇𝑇 = 
2∗𝑒𝑒𝑖𝑖𝑒𝑒𝑇𝑇𝑒𝑒𝑛𝑛𝑐𝑐𝑛𝑛 𝑇𝑇𝑥𝑥/𝑅𝑅𝑥𝑥 𝑇𝑇𝑜𝑜 𝑇𝑇𝑒𝑒𝑓𝑓𝑢𝑢𝑛𝑛𝑇𝑇
𝑉𝑉𝑛𝑛𝑇𝑇𝑜𝑜𝑐𝑐𝑖𝑖𝑇𝑇𝑉𝑉 𝑇𝑇ℎ𝑓𝑓𝑜𝑜𝑢𝑢𝑢𝑢ℎ 𝑇𝑇ℎ𝑛𝑛 𝑚𝑚𝑛𝑛𝑒𝑒𝑖𝑖𝑒𝑒      (2A) 
 
TWTT = 280 ns - 40 ns =240 ns, from Figure 7A.  
Medium 1 – free space, velocity 0.3 m/ns, distance to 
ground from Tx/Rx is 5 meters 
 
TWTT (1)=  (2 * 5 meters)/(0.3 m/ns)≈33 ns 
Medium 2 – moist sand, velocity 0.1 m/ns, distance to 
target from ground is: 
d =  (0.1 m/ns * (240 ns - 33 ns))/2  ≈10.35 meters. 
Total calculated distance (d) from Tx/Rx to target is 15.35 
meters (5 meters + 10.35 meters); close to the defined 15-
meter distance, but accurate because true distance from 
Tx/Rx to target is at an angle, which is longer than the 
perpendicular distance. 
 
A.4 
VELOCITY THROUGH A MEDIUM AND PENETRATION 
DEPTH [23] 
The velocity is dependent on a material’s relative 
permittivity. The higher the relative permittivity of a 
medium, the lower the velocity is through the medium.  
When the relative permittivity of a medium is known the 
calculated velocity through the medium can be calculated 
using equation 1A. 
 
Example: free-space has a permittivity (εr) = 1, 
𝑉𝑉𝑒𝑒𝑙𝑙𝑙𝑙𝑡𝑡𝑖𝑖𝑡𝑡𝑉𝑉 = [ 3𝑒𝑒 + 8 𝑆𝑆𝑆𝑆𝑡𝑡𝑡𝑡(1) ∗ 1𝑒𝑒 − 9]
⁄
 m/ns.  
V = 0.3 m/ns. 
Direct Arrival 
Ground Bounce 
429
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

 
 
Figure 10A. GPR trace depicting Two-way-transit-time 
for a target at 20MHz. 
 
 
 
Figure 11A. GPR trace depicting Two-way-transit-time 
for same target of Figure 10A at 50 MHz. 
 
As the electrical conductivity, (units Siemens/meter), 
increases the penetration depth decreases, determining how 
deep an electrical signal will penetrate.  Higher frequencies 
reduce the depth penetration but increase image resolution.  
Table 1 lists a few nominal values for permittivity and 
conductivity. 
TABLE 1 (MEDIUM AND VELOCITY VALUES) 
Medium 
εr 
Velocity 
(m/ns) 
Conductivity 
(mS/m) 
concrete 
6 
0.1225 
0.01 
clay  
5 
0.1342 
2 
dry-sand 
3 
0.1732 
0.01 
granite 
4 
0.1500 
0.01 
limestone 
7 
0.1134 
0.5 
 
ACKNOWLEDGMENT 
This work was performed under the auspices of Sandia 
National Laboratories a multimission laboratory managed 
and operated by National Technology and Engineering 
Solutions of Sandia, LLC, a wholly owned subsidiary of 
Honeywell International, Inc. for the U.S. Department of 
Energy’s National Nuclear Security Administration under 
contract DE-NA-0003525. 
 
 
REFERENCES 
[1] R. Tilley, H. Sadjadpour, and F. Dowla, “Combining Ground 
Penetrating Radar Scans of Differing Frequencies Through 
Signal Processing,” The Ninth International Conference on 
Advanced Geographic Information Systems, Applications, 
and Services, GEOProcessing 2017, Nice, France, Mar 2017, 
pp. 32-38, ISBN:978-1-61208-539-5. 
[2] A. L. Endres, A. Booth, and T. Murray, “Multiple Frequency 
Compositing of Spatially Coincident GPR Data Sets,” 
Proceedings of the Tenth International Conference on Ground 
Penetrating Radar, 2004, Delft, The Netherlands,  June 2004, 
pp. 271-274,  ISBN: 90-9017959-3. 
[3]  M. E. Dougherty, P. Michaels, J. R. Pelton, and L. M. 
Liberty, “Enhancement of Ground Penetrating Radar Data 
Through Signal Processing,” Symposium on the Application 
of Geophysics to Engineering and Environmental Problems 
1994, pp. 1021-1028, Jan 1994, DOI 10.4133/1.2922053. 
[4] A. D. Booth, A. L. Endres, and T. Murray, “Spectral 
Bandwidth Enhancement of GPR Profiling Data Using 
Multiple-Frequency Compositing,” Journal of Applied 
Geophysics, 
vol 
67, 
pp. 
88-97, 
Jan 
2009, 
DOI 
10.1016/j.jappgeo.2008.09.015. 
[5] S. W. Bancroft, “Optimizing the Imaging of Multiple 
Frequency GPR Datasets using composite Radargrams: An 
Example from Santa Rosa Island, Florida,” PhD dissertation, 
University of South Florida, 2010. 
[6] A. P. Dempster, N.M. Laird and D.B. Rubin, “Maximum 
Likelihood from Incomplete Data via the EM Algorithm,” 
Journal 
of 
the 
Royal 
Statistical 
society, 
Series 
B 
(Methodological) 
39(1): 
pp. 
1-38, 
1977, 
JSTOR 
2984875.MR0501537. 
[7] C. R. Shalizi, “Advanced Data Analysis from an Elementary 
Point of View,” Book Draft from Lecture Notes for Course 
36-402 at Carnegie Mellon University, Chapters 19.1-19.2.2, 
January 2017,  
http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV
.pdf, 2017.11.23. 
[8] A. Giannopoulos, “Modelling Ground Penetrating Radar by 
GprMax,” Construction and Building Materials, vol. 19, pp. 
755-762, Dec 2005, DOI 10.1016/j.conbuildmat.2005.06.007. 
[9] J. A. Pena, T. Teixido, “Cover Surfaces as a New Technique 
for 3-D Image Enhancement, Archaelogical Applications,” 
Repositorio Institucional de la Universidad de Granada, 
Spain, 2012,  http://hdl.handle.net/10481/22949, 2017.11.23. 
[10] Padhraic Smyth, “The EM Algorithm for Gaussian Mixtures, 
Probabilistic Learning: Theory and Algorithms, CS274A,” 
University of California, Irvine, Department of Computer 
Science, Lecture Note 4. 
[11] J. J. Verbeek, N. Vlassis, and B. Krӧse, “Efficient Greedy 
Learning of Gaussian Mixtures,” The 13th Belgian-Dutch 
Conference on Artificial Intelligence (BNAIC’01),pp. 251-
258, 2001,  INRIA-00321510. 
TWTT 
430
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

[12] C. Do, S. Batzoglou, “What is the Expectation Maximization 
Algorithm,” Nature Biotechnology vol. 26, Issue 8, pp. 897-
899, 2008, DOI 10.1038/NTBL1406. 
[13] R. Tilley, F. Dowla, F. Nekoogar, and H. Sadjadpour, “GPR 
Imaging for Deeply Buried Objects: A comparative Study 
based on FDTD models and Field Experiments,” Selected 
Papers Presented at MODSIM World 2011 Conference and 
Expo; pp. 45-51, Mar. 2012; (NASA/CP-2012-217326); (SEE 
20130008625) . 
[14] A. P. Annan, “Electromagnetic Principles of Ground 
Penetrating Radar,” in Ground Penetrating Radar Theory and 
Applications, M. J. Harry, Ed., ed Amsterdam: Elsevier, pp. 
1-40, 2009, ISBN: 978-0-444-53348-7. 
[15] A. Tavlove, “Review of the formulation and Applications of 
the Finite-Difference Time-Domain Method for Numerical 
Modeling 
of 
Electromagnetic-Wave 
Interactions 
with 
Arbitrary Structures,” Wave Motion, vol. 10, pp. 547-582, 
Dec 1988, DOI 10.1016/0165-2125(88)90012-1. 
[16] N. Blindow, D. Eisenburger, B. Illich, H. Petzold, and T. 
Richter, “Ground Penetrating Radar,” in Environmental 
Geology, Ed. Springer Berlin Heidelberg, pp. 283-235, 2008, 
DOI 10.1007/978-3-540-74671-3_10. 
[17] C. Christopoulos, “The Transmission-Line Modeling (TLM) 
Method in Electromagnetics,” Synthesis Lectures on 
Computational Electromagnetics, vol. 1, Issue 1, pp. 1-132, 
Morgan 
& 
Claypool 
Publishers, 
2006, 
DOI 
10.2200/S00027ED1V01Y200605CEM1007. 
[18] R. Tilley, H. Sadjadpour, and F. Dowla, “Extending Ground 
Penetrating Radar Imaging Capabilities Through Signal 
Processing,” Proceedings of the 2nd World Congress on Civil, 
Structural, and Environmental Engineering (CSEE’17),  
Barcelona, Spain, April 2017, ISSN 2371-5294, DOI 
10.11159/icgre17.194. 
[19] A. P. Annan, and S.W. Cosway, “Ground Penetrating Radar 
Design,” Proceedings of the Symposium on the Application 
of Geophysics to Engineering and Environmental Problems 
(SAGEEP), 
vol 
2, 
pp. 
329-351, 
1992, 
DOI 
10.4133/1.2921946. 
[20] J. van der Kruk, E. C. Slob, and J. T. Fokkema, “Background 
of ground-penetrating radar measurements,” Journal of 
Geologie en Mijnbouw, vol. 77, Issue 2, pp. 177-188, 1998, 
DOI 10.1023/A:103546619639. 
[21] B. M. ter Haar Romeny, “Front-End Vision and Multi-Scale 
Image Analysis: Multi-Scale Computer Vision Theory and 
Applications written in Mathematica,” Springer Publishers, 
2008, ISBN 978-1-4020-1507-6. 
[22] J. van der Kruk, “Reflection Seismic I,” Lecture Series in WS 
2004/2005, 
Institut 
fȕr 
Geophysik 
ETH 
Zȕrich, 
http://www.wgeosoft.ch/Document/Reflection_ETHZ.pdf, 
2017.11.23. 
[23] H. M. Jol, editor, “Ground Penetrating Radar Theory and 
Applications,” Elsevier Science, 2009, ISBN: 978-0-444-
53348-7. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
431
International Journal on Advances in Software, vol 10 no 3 & 4, year 2017, http://www.iariajournals.org/software/
2017, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

