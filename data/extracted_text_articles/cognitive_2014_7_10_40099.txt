Automatic Classiﬁcation of Cell Patterns for
Triple Negative Breast Cancer Identiﬁcation
Juan Luis Fern´andez-Mart´ınez∗, Ana Cernea∗, Enrique J. deAndr´es-Galiana∗,
Primitiva Men´endez-Rodr´ıguez†,
Jos´e A. Galv´an‡ and Carmen Garc´ıa-Pravia†
∗Mathematics Department, Oviedo University,
Email: jlfm@uniovi.es, cerneadoina@uniovi.es, ej.deandres@gmail.com
†Hospital Universitario Central de Asturias, Oviedo
Email: tiva@hca.es, carmen.garciapravia@gmail.com
‡Institute of Pathology, University of Bern
Email: josegalvan6@hotmail.com
Abstract—This paper is devoted to presenting a methodology in
Artiﬁcial Intelligence and Cognition for the optimization of basal
cell patterns classiﬁcation. Different unsupervised and supervised
learning techniques are applied to the analysis, diagnosis and
prognosis of cell patterns classiﬁcation for Triple Negative Breast
Cancers (TNBC), a group of cancers that, together with basal-like
breast cancers, have a very bad prognosis. For that purpose, dif-
ferent machine learning algorithms are performed on histological
images, and on a list of pathological and immunohistochemical
variables currently used in medical practice. The main objective
is to design a biomedical robot able to assist physicians with
the kind of histological grade of different subgroups of TNBC
samples in order to optimize the treatment protocol. The proposed
methodology is performed on a database of 116 patients. The re-
sults show that pathological and immunohistochemical variables
and histological images provide complementary information to
improve the classiﬁcation of TNBC samples.
Keywords–Artiﬁcial
Intelligence;
Cognition;
Cell
Patterns;
Triple Negative Breast Cancers (TNBC); Machine Learning.
I.
INTRODUCTION
Breast cancer (or neoplasia) is a very heterogeneous
disease. This term encompasses a variety of entities with
distinct morphological features and clinical behaviors. For
a long time, breast tumors have been classiﬁed according
to their morphologic features (histologic type and grade) to
ascertain prognostic outcome in patients. Subsequently, molec-
ular markers (the expression of estrogen and progesterone
receptor and human epidermal growth factor 2 receptor) were
used to provide additional predictive power. Therefore, Triple
Negative Breast Cancers (TNBC) refers to any breast cancer
characterized by the absence of Estrogen Receptors (ER),
Progesterone Receptors (PR) and Human Epidermal Growth
Factor 2 Receptors (HER2). This classiﬁcation is important
from a clinical and therapeutic point of view, since TNBC
are resistant to targeted therapies, because they do not express
these receptors [13]. Statistics showed that TNBC account for
approximately 15%−25% of all breast cancer cases. Recently,
a molecular classiﬁcation based on gene expression proﬁles
classiﬁed tumors into ﬁve groups that were not detected
using traditional histopathologic methods. This classiﬁcation
includes the basal-like tumors group [17]. These tumors are
deﬁned by: (1) the lack of ER, PR, and HER2 expressions;
(2) the expression of one or more high-molecular-weight/basal
cytokeratins (CK5/6, CK14); (3) the lack of expression of ER
and HER2 in conjunction with expression of CK5/6; and (4)
the lack of expression of ER, PR, and HER2 in conjunction
with expression of CK5/6. Also, from a morphological point of
view both basal-like and triple negative breast cancers share a
predominance of high histologic grades. The analysis of gene
expression proﬁles showed that 77% of basal-like tumors were
of TNBC phenotype [17].
The treatment for TNBC is adjuvant chemotherapy and ra-
diotherapy. Unfortunately, response to chemotherapy does not
correlate with overall survival. In addition, most recurrences
are observed in TNBC during the ﬁrst and third years after
therapy, and most deaths take place in the ﬁrst ﬁve years. The
survival decreases after the ﬁrst metastatic event. Therefore,
in this heterogeneous group of tumors, new identiﬁcation and
classiﬁcation techniques are necessary to establish a better
diagnosis and prognosis, and to outline appropriate therapies.
[6].
The main objective of this research is to design a biomedi-
cal robot able to help physicians with the diagnosis of different
subgroups of TNBC in order to optimize their treatment proto-
col. The ﬁrst aim of this research is to analyze the possibility
of performing an automatic histological grade prediction using
different biometric attributes of TNBC images and also a
list of currently-used pathological and immunohistochemical
variables. The methodology used in this paper is inspired by
previous research works [7][8]. The preliminary conclusion
of this study is that the use of both pieces of information
(immunohistochemical markers and histological images) might
improve the accuracy of TNBC histological grades classiﬁca-
tion and survival.
The structure of this paper is as follows: Section II de-
scribes the database of histological images and pathological,
clinical and immunohistochemical variables; Sections III and
IV describe the machine learning methods used in both cases.
Section V presents the histological image attributes, and ﬁ-
nally, Section VI draws the conclusion and future research
work.
151
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

II.
DATABASE DESCRIPTION
A. Histological Images
A cohort of 105 Caucasians women diagnosed in the
Hospital Universitario Central de Asturias (Spain) with TNBC
and ages between 30 and 94 years were enrolled in this study,
which was developed in accordance with the last version of
the Helsinki Declaration of 1975 [21]. Tumor samples were
obtained from surgical resection. They were ﬁxed in 10%
formaldehyde and parafﬁn embedded, then cut 4µm thick,
mounted on treated slides, and stained with H&E stain (Hema-
toxylin and eosin stain). Finally, the sections were studied and
photographed at
two different resolutions (100X and 400X)
using an Olympus light microscope. Most of the cancers in this
cohort were classiﬁed in histological degrees 2 (20 samples)
and 3 (89 samples), and only two samples were in degree
1. Also, a few samples have a histological degree, which is
unknown. This methodology will be used in the future to asses
the histological grade of the TNBC samples, and to analyze
the possibility of predicting the patients survival.
B. Pathological and Clinical Variables
The pathological and clinical variables description is im-
portant to understand the different classiﬁcation problems
involved in this analysis, and the way the histological grade
of the TNBC is established in medical practice. The Notting-
ham Histologic Score system (the Elston-Ellis modiﬁcation of
Scarff-Bloom-Richardson grading system [2], [5]) has been
applied to establish the histological grades of the TNBC
cancers. This system is based on the ability of the tumor
to form structures similar to the ducts where the tumor has
originated, on the similarity between the cancer cells and the
original benign cells and ﬁnally on its proliferative activity. The
histological grade will be used as the class for the different
machine learning classiﬁcation problems presented in this
paper.
In order to assign the grade score, several factors are
taken into account: (1) Tubular structure formation: the
score increases with the percentage of tumor area forming
glandular/tubular structures, as follows: score 1: > 75% of
tumor area forming glandular/tubular structures; score 2: 10%
to 75% of tumor area forming glandular/tubular structures;
score 3: < 10% of tumor area forming glandular/tubular (2)
Nuclear pleomorphism: the score increases with variation
of size and shape of cells, as follows: score 1: Small nuclei
with little increase in size in comparison with normal breast
epithelial cells, regular outlines, uniform nuclear chromatin,
little variation in size; score 2: Cells larger than normal with
open vesicular nuclei, visible nucleoli, and moderate variability
in both size and shape; score 3: Cells with vesicular nuclei,
often with prominent nucleoli, exhibiting marked variation in
size and shape. (3) Mitotic rate: The mitotic count score
depends on the ﬁeld diameter of the microscope used by
the pathologist. The pathologist will count how many mitotic
ﬁgures are seen in 10 high power ﬁelds. Using a high power
ﬁeld diameter of 0.50 mm, the criteria are as follows: score 1:
less than or equal to 7 mitoses per 10 high power ﬁelds; score
2: 8-14 mitoses per 10 high power ﬁelds; score 3: equal to or
greater than 15 mitoses per 10 high power ﬁelds.
The ﬁnal total score is used to determine the histological
grade of a TNBC sample, as follows:
•
Histological grade 1: tumors with a total score be-
tween 3 and 5;
•
Histological grade 2: tumors with a total score be-
tween 6 and 7;
•
Histological grade 3: tumors with a total score be-
tween 8 and 9.
In the present case, most TNBC samples were classiﬁed
with grades 2 (20 samples) and mainly 3 (89 samples). Higher
scores are usually correlated with the worse prognostic.
Other currently used variables include: (1) TNM stage:
The pathologic stage of breast cancer takes into consideration
the tumor size (T) and the presence of any lymph nodes
metastases (N) or distant organ metastases (M). (2) Differ-
entiation: it is a combined measure of the tubular formation
and the pleomorphism. It is a descriptor provided by the
medical experts based on visual inspection of the histological
images. This histological variable is expected to be highly
correlated in medical practice to the histological grade of
the different TNBC samples. (4) Vascular and perineural
invasion: binary variable indicating the presence or absence
of tumor cells inside the vessels and nerves, respectively. (5)
Necrosis: binary variable indicating the presence of death cells.
This variable is correlated with the TNBC aggressiveness. (6)
In situ component: binary variable indicating the absence
of invasion of tumor cells into the surrounding tissue. Most
of these variables are provided by the pathologist by visual
inspection of the TNBC images.
C. Immunohistochemical variables
The following immunohistochemical variables are also
currently monitored: (1) Estrogen receptors (ER), Proges-
terone receptors (PR) and Androgen receptors (AR) nuclear
expression: Hormone receptor status is important because these
variables serve to decide whether the cancer is likely to
respond to hormonal therapy or other treatments. (2) Human
epidermal growth factor receptor 2 (HER-2): HER2 testing
is performed to assess prognosis and to determine suitability
for trastuzumab therapy. (3) Ki67 expression: The percentage
of Ki-67 (< 2%, 2 − 20% and > 20%) can be used to aid
in assessing the proliferative activity of normal and neoplastic
tissue. (4) Bcl-2 expression: Bcl-2 is speciﬁcally considered as
an important anti-apoptotic protein and classiﬁed as an onco-
gene. Bcl-2 expression is associated with a better prognosis [4].
(5) E-cadherin expression: Reduction or loss of E-cadherin
expression is associated with invasive carcinoma and possibly
metastasis in a variety of carcinomas [16]. (6) P53 expression:
is also a maker used in breast cancer, but its signiﬁcance in
predicting clinical outcome remains controversial. (7) CK-5/6
and CK-14 expression: are helpful markers in the identiﬁca-
tion of breast cancer with a basal phenotype. (8) COL11A1:
is a stromal marker of invasion [10].
All these variables but COL11A1 have been described in
the literature as useful for TNBC description.
It is important to note that the histological grade estimation
of the TNBC samples is established in medical practice as it
152
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

has been shown in this section, using the pathological, clinical
and immunohistochemical variables that are measured for each
patient, and also by visual inspection of the histological images
after surgical resection. Therefore, and up to our knowledge,
no biomedical robot exists to automatize these approaches, to
integrate both types of information, and to assist physicians
with the diagnostic. This decision has very important conse-
quences on the prescribed treatment for the patient.
III.
MACHINE LEARNING USING PATHOLOGICAL AND
IMMUNOHISTOCHEMICAL VARIABLES
The aim of this section is to analyze the most discrimi-
natory pathological and immunohistochemical variables of the
histological grade. Data preprocessing includes in this case the
imputation of the clinical variables that have not been mea-
sured for some patients in real practice and the normalization
of these variables in the interval [0, 1] according to their own
empirical cumulative distribution. The imputation algorithm
that is used is based on the nearest neighbor estimator. Its
workﬂow is as follows: (1) Finding the subset Sfi of samples
(patients) that are fully-informed for all the control variables.
(2) For each patient k that is not fully-informed, ﬁnding the
set of variables mk(var1 : varq) that are missed. These
variables are interpolated using the values of the same variables
corresponding to the nearest fully-informed patient fk in Sfi:
m∗
k(var1 : varq) = mfk(var1 : varq).
(1)
In order to measure the similarity between patients we use
the cosine criterion induced by the Euclidean scalar product
deﬁned over the set of fully-informed variables in the current
sample (patient):
cos(mk, mj) =
mk · mj
∥mk∥2∥mj∥2
,
(2)
where mk and mj stand for the vectors of fully-informed
variables in patients k and j. Once the variables are imputed,
the normalization of variable varj is based on the p-percentile
concept: P(varj ≤ cp) = p, by assigning the probability
p to the value cp of the attribute varj. Figure 1 shows the
normalized pathological and immunohistochemical variables.
The samples are arranged by their histological grades (2 to
3) beginning by the top of the image. It can be observed the
high variability of these variables within the different classes
(histological grades).
To perform machine learning, we have ﬁrst used feature
selection methods to ﬁnding the minimum-size list of most
discriminatory variables. For that purpose, we deﬁned the
Generalized Fisher’s ratio of the attribute j, for a binary
classiﬁcation problem, as follows [9]:
FRj = (µj1 − µj2)2
σ2
j1 + σ2
j2
,
(3)
where is µj1 a measure of the center of the distribution of the
attribute j in class i, and σji is a measure of its dispersion
within the class i. The Fisher’s ratio (GFR) can be also
generalized for multiclass classiﬁcation as follows:
GFRj =
Nc
X
i=1
Nc
X
k=i+1
(µji − µjk)2
σ2
ji + σ2
jk
,
(4)
Figure 1.
Normalized pathological and immunohistochemical array. The
samples are ordered by their histological grade (ﬁrst 20 samples with degree
2, followed by 89 samples with histological degree 3.
where Nc is the number of classes, j is the attribute index
and i, k the classes indices. This feature selection method
looks for attributes that are homogenous within each class (low
intra-class dispersion) and show a high separation between the
center of the corresponding distributions (inter-class distance).
Most discriminatory attributes correspond to higher Fisher’s
ratios. The algorithm to ﬁnd the minimum-size list of features
is based on Recursive Feature Elimination, that is:
1)
Attributes are ranked by the decreasing value of their
Fisher’s ratio.
2)
Beginning by the tail of the list we calculate the
accuracy of the different set of attributes, that are
formed by dropping one attribute at each time. The
set with the optimum accuracy and minimum size is
therefore selected.
3)
Finally, the accuracy of this reduced set of the at-
tributes in the class prediction is based on Leave-
One-Out method, using the average distance on the
reduced set of attributes. The class with the minimum
distance is assigned to the sample test. The average
accuracy is calculated by iterating over all the sam-
ples.
The classiﬁcation problem is linearly separable when this
simple algorithm provides high accuracies. In the case where
these accuracies decrease, other nonlinear classiﬁcation algo-
rithms should be used instead. If despite all these modiﬁca-
tions, there is no improvement in the accuracy, this would
mean that the data set (data and class) is noisy.
Table 1 shows the list of attributes selected by the Fisher’s
ratio (FR) analysis using the median and the mean to describe
the centers of the distribution of the corresponding classes.
These attributes are ranked by decreasing discriminatory power
(Fisher’s ratio) in the case of the median. In the case of the
mean, the Ki67 expression should be in the third position.
Five of the eight attributes in these lists are in common:
Mitotic count, Differentiation, AR expression, Ki67 expression
and Tubular Formation. The reduced base of features with
the highest accuracy (96, 4%) is composed by the four ﬁrst
153
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

Table I.
LIST OF MOST DISCRIMINATORY ATTRIBUTES AND THEIR
CORRESPONDING FISHER’S RATIOS USING THE MEDIAN AND THE MEAN.
Attributes
FR median
FR mean
Mitotic count (10HPF)
4.56
2.00
Differentiation
4.55
2.41
AR expression
2.60
0.64
Tubular Formation
2.46
0.56
Insitu
2.06
-
T
2.05
-
N
1.99
-
Ki67 expression
1.78
0.94
pro-CollA1 intensity
-
0.24
Bcl2 expression
-
0.22
pro-Coll1A1 Score
-
0.21
markers (Mitotic count, Differentiation, AR expression, and
Tubular Formation). Only four patients are wrongly predicted
using these attributes. Also, using the mean the two ﬁrst mark-
ers (Differentiation and Mitotic count) provide an accuracy
of 94.4%. Other list of features with high accuracy (93.6%)
includes HER2, PR expression, nipple and/or skin invasion,
ER, AR and Ki67 expressions. Interesting, the main attributes
in these lists coincide with those used by medical experts to
asses the histological grade of TNBC samples, nevertheless,
these lists also show other attributes that are important for
this automatic classiﬁcation and were not directly used by the
pathologists.
We have also analyzed the possibility of predicting the me-
dian survival of the different patients. This analysis has shown
that the best markers to predict survival (with 78% of accuracy)
are: E-cad expression, tumor size, perineural invasion, tubular
formation, differentiation, and TNBC subtype. The accuracy of
this prediction is lower than in the former case (histological
grade), showing that this problem is not very well linearly
separable using these attributes. Other additional variables,
such as the kind of treatment followed by the patient, should
be also used. The use of a nonlinear neural network classiﬁer
(extreme learning machine) [12] improved the accuracy of the
prediction till 84%.
IV.
MACHINE LEARNING USING HISTOLOGICAL IMAGES
The second aim of this research is to analyze the possibility
of performing an automatic histological grade prediction using
different biometric attributes of TNBC images corresponding
to different histological grades taken at two different reso-
lutions. These pattern images have been chosen by expert
pathologists in this ﬁeld. Figure 2 shows different histological
images at two different resolutions for cancers in degrees
1, 2 and 3. It can be observed that the main differences
reside on the histological variables that have been described
in the previous section, that are visually assessed by medical
experts. The question resides in the possibility of capturing
these characteristics using image processing techniques and
machine learning.
A. The automatic image classiﬁcation problem
The automatic image recognition problem consists in as-
signing a class to a new incoming image I /∈ Bd, given a
database of TNBC color training images
Bd =

Ik ∈ S(n,m,3) (N) : k = 1, . . . , N
	
,
(5)
Figure 2.
Basal images at two resolutions (100x and 400x magniﬁcation)
for TNBC with three different histological grades. In the present case the
histological grade 1 is very bad represented (only two samples).
that are characterized by a set of histological grades (labels)
annotated by medical experts
Cd = {ck ∈ {1, 2, ..., Nc} , k = 1, . . . , N} .
(6)
In this deﬁnition, S(n,m,3) is the space of color images of
size m × n, and Nc is the number of classes (3 in this
particular case). To perform the classiﬁcation it is necessary
to construct a learning algorithm C∗ : S(n,m,3) → Cd for the
class prediction:
The classiﬁcation is based on a nearest neighbor algorithm
[15]:
1)
First, ﬁnding the image Ik ∈ Bd such as:
d (I, Ik) = min d (I, Ij) , Ij ∈ Bd,
(7)
where d is a suitable distance (or norm) criterium
deﬁned over S(n,m,3).
2)
Once this image has been found, assigning the class
as follows: C∗
I = CIk = Ck.
The images are represented by a feature vectors calculated
for each individual method of analysis (or attribute). Naming
vk
i ∈ Rsk the feature vector of image Ii according to the
attribute k, the distance between two images Ii and Ij is
deﬁned as follows:
d (Ii, Ij) = ∥vk
i − vk
j ∥p,
(8)
where p is a certain norm deﬁned over the k-attribute space
(Rsk).
The ﬁnal classiﬁcation will be performed by consensus
[14]:
1)
From every individual non-supervised classiﬁer built
using the different attributes, we retain the ﬁrst Nf
images that are closer to I. Based on this classiﬁca-
tion a matrix M ∈ MNf×Na is built, containing the
Nf image candidates for each of the Na attributes and
their corresponding histological grades. The score of
image I according to the attribute j (j = 1, Na) to
belong to the class k (k = 1, Nc) is established as
follows:
sjk = 1
fk
Njk
Nf
,
(9)
154
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

where fk is the sampling frequency of class k in
the training database (examples) and Njk is the
number of images belonging to class k within the
Nf candidates found for attribute j.
2)
The ﬁnal score for a new incoming image I to belong
to class k is calculated as follows:
Sk =
Na
X
j=1
sjkwj = sjk · w, k = 1, Nc
(10)
where sjk is the score assigned by attribute j to class
k and w is a vector of weights corresponding to
the trust factors assigned to any individual classiﬁer
(attribute). After calculating the scores for all the
classes, the ﬁnal classiﬁcation of the test image I is
performed by selecting the class with the major score.
Eventually, the number of candidate images (Nf), the
sampling frequencies (fk), and the trust factors (w),
can be optimized (supervised learning) using global
algorithms, such as PSO.
V.
IMAGE ATTRIBUTES
In this paper, we have used the following list of attributes,
statistical based (histogram and variogram), spectral (discrete
cosine transform), and image segmentation/regional descrip-
tors (edges, texture and Zernike Moments). In this case all
attributes will be calculated as global descriptors since TNBC
image comparison should not be pixel-based.
A. PCA analysis using attributes of the histological images
In this section, we analyze the possibility of discriminating
the different histological grades of the TBNC samples by
means of unsupervised classiﬁcation using the Principal Com-
ponent Analysis (PCA). PCA aims at ﬁnding the orthogonal
basis by diagonalizing the experimental covariance matrix of
training images [18]:
S =
N
X
k=1
(Xk − µ)(Xk − µ)T ,
(11)
where Xk∈ RNpixels transformed into 1 − D column vectors,
µ = 1
N
PN
k=1 Xk is the images sample mean, N is the number
of sample images contained in the learning database, and
Npixels is the number of pixels of each image. The eigenfaces
uk are the eigenvectors of S, corresponding to the largest
eigenvalues. The dimensionality reduction from Npixels to q
parameters, is obtained by retaining the q ﬁrst eigenfaces uk,
spanning most of the database variability. Figure 3 shows the
PCA plot in two dimensions (two ﬁrst PCA coordinates) of
the different TNBC images at 10X resolution. We also show
the TNBC samples that have positive androgen receptors (AR).
This information is important since it implies a different type
of TNBC (apocrine carcinoma). Apocrine carcinoma is a sub-
type of TNBC that expresses androgen receptor (AR), but often
lacks estrogen receptor (ER) and progesterone receptor (PR).
It is possible to observe that TNBC samples with HG = 2
are mainly located on three different clusters, surrounded by
samples with HG = 3. Also, most of the HG2 samples
correspond to apocrine type. Taking this fact into account, it
seems that non-apocrine HG2 samples are only located in very
restricted areas of the PCA diagram. Figure 4 shows the 10
Figure 3.
PCA plot (two ﬁrst PCA coordinates) of the basal images
corresponding to the histological grades 2 (HG2) and 3 (HG3), at 100x
magniﬁcation. We also show the samples with positive androgen receptor
(AR = 1).
Figure 4.
Mean 10 ﬁrst PCA coefﬁcients for HG2 and HG3 images. It
can be observed that the biggest difference occurs for PCA number 4. PCA
with higher indexes correspond to increasing high frequency harmonics in the
images.
ﬁrst mean PCA coefﬁcients for TNBC images with histological
grades 2 and 3. It can be observed that biggest differences
occur high-order harmonics (4th). This attribute is expected to
have a medium discriminatory power on TNBC images.
B. Color Histograms
An image histogram describes the frequency of the bright-
ness in the image. The shape of the histogram provides
information about the nature of the image [20]. For a gray-
scale digital image I the histogram represents the discrete
probability distribution of the gray-levels in the image. For this
purpose the gray-scale space ([0, 255] for an 8-bit image)
is divided into L bins, and the number of pixels in each class
ni, (i = 1, L) is calculated. In this case the attribute vector
has dimension L:
HI = (n1, ..., nL).
(12)
Relative frequencies can be also used by dividing the absolute
frequencies ni by the total number of pixels in the image.
In the case of RGB images, the histogram is calculated for
each color channel IR, IG and IB, and then all the channels
histograms are merged together, as follows:
HI = (H (IR) , H (IG) , H (IB)) .
(13)
155
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

Figure 5 shows the relative histograms of the color channels for
TNBC images with HG2 and HG3. It can be observed that the
major differences occur in the green channel, being its relative
frequency lower than those of the red and blue channels. This
attribute is expected to have a medium discriminatory power
for TNBC images.
Figure 5.
Mean histograms for HG2 and HG3 images. We show a different
histogram for each color channel. The biggest differences between classes
HG2 and HG3 occur in the green color channel.
C. Variogram
The variogram of an image describes the spatial distribution
in each color channel. In spatial statistics the variogram
describes the degree of spatial dependence of a spatial random
ﬁeld or stochastic process, the gray-scale in this case. For a
given value of vector h, deﬁned by a modulus and direction,
the variogram is an index of dissimilarity between all pairs of
values separated by vector h. The omnidirectional variogram
is the mean of the p-absolute difference between the color
values of the N(h) pairs of pixels that are located at the same
distance h:
γi(h) =
1
N(h)
N(h)
X
k=1
|ci(xk) − ci(xk + h)|2.
(14)
To compute the variogram each color channel (matrix)
is transformed into the corresponding color vector ci(x).
Typically N(h) is limited to one third of the total number of
pixels. The number of classes that have been considered in this
case was N(h) = 100. Variograms are usually used to analyze
spatial continuity and anisotropies. The sill of the variogram is
related to the color channel variability, its range to the spatial
continuity, and its nugget (origin value) to the image low scale
variabilities. Figure 6 shows the omnidirectional variograms of
the three color channels for TNBC images with HG2 and HG3.
It can be observed that the major differences occur in all the
channels, being the blue and green the most discriminatory
with respect to this attribute. The green channel also shows
the biggest nugget. This attribute is expected to have a high
discriminatory power for TNBC images.
D. Texture Analysis
Texture analysis of an image consists in analyzing regular
repetitions of a pattern. In this paper, we use the spatial gray
level co-occurrence matrix to describe an image texture. The
gray level co-occurrence matrix (GLCM), or spatial depen-
dence matrix of an image I is an estimate of the second-order
Figure 6. Mean variograms for HG2 and HG3 images. The biggest differences
in the sill occur in the green and blue channels.
joint probability function Pd,θ(i, j) of the intensity values of
two pixels i and j located at a distance d apart (measured
in number of pixels) along a given direction θ. Typically the
GLCM is calculated for different pairs of d and θ. Different
statistical moments can be calculated from the GLCM matrix,
such as contrast, homogeneity, squared energy, correlation and
entropy [1]. In the present case, we have used a lag d = 1
for the directions 0, 45, 90 and 135. Figure 7 shows the
texture moments of the three color channels for TNBC images
with HG2 and HG3. The conclusions are similar than in the
case of variogram. This attribute is expected to have a high
discriminatory power for TNBC images.
Figure 7.
Mean texture coefﬁcients for HG2 and HG3 images. The biggest
differences also occur in the green and blue channels.
E. Edges Detection
Edges are determined by sets of pixels where there is
an abrupt change in intensity. If a pixel’s gray level value
is similar to those around it, there is probably not an edge
at that point. However, if a pixel has neighbors with widely
varying gray levels, it may represent an edge. Thus, an edge
is deﬁned by a discontinuity in the gray-level values. More
precisely, we can consider an edge as a property associated
to a pixel where the image function f(x, y) changes rapidly
in the neighborhood of that pixel. Related to f, an edge is a
vector variable with two components: magnitude and direction.
The edge magnitude is given by the gradient of the pixels
intensities function, and its direction is perpendicular to the
156
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

gradient’s direction:
|∇f(x, y)| =
s
∂f
∂x
2
+ ∂f
∂y
2
,
(15)
θ(x, y) = arctg
∂f
∂y , ∂f
∂x

± π
2 .
(16)
To compute the partial derivatives of f(x, y) we have used
the Canny edge detection operator [3], which is one of the
most commonly used in image processing, due to its property
of detecting edges in a very robust manner in the case of
noisy images. The edge detection algorithm provides an image
of the same size than the original image on which this
analysis is performed. To produce the edge attributes we use a
compression of edge image using the DCT. In the present case
this analysis provides an attribute vector of dimension 48 for
each image. Figure 8 shows the DCT-edges moments of the
three color channels for TNBC images with HG2 and HG3.
The main differences occur for the ﬁrst coefﬁcients in each
color channel. This attribute is expected to have a low/medium
discriminatory power for TNBC images.
Figure 8.
Mean edges vectors (after compression by the DCT) for HG2
and HG3 images. In this case we plot consecutively the ﬁrst 16 DCT-edges
coefﬁcients of each color channel. No big differences are visually observed.
F. Discrete Cosine Transform (DCT)
DCT is a free-covariance model reduction technique that
attempts to decorrelate 2D images by projecting the rows and
columns of the incoming image into cosines of increasing
frequency [11]. DCT is a discrete Fourier transform that
expresses a signal in terms of a sum of sinusoids with different
frequencies and amplitudes. For an image Ik the DCT is
deﬁned as follows:
D(u, v) = c(u)c(v)
s−1
X
i=0
n−1
X
j=0
D(i,j)
(17)
D(i,j) = Ik(i, j) · cos π(2i + 1)u
2s
cos π(2j + 1)v
2n
,
(18)
with u = 0, ..., s − 1, v = 0, ..., n − 1, and
c(α) =
(
1
√
N ,
if
α = 0,
q
2
N ,
if
α ̸= 0.
(19)
N is either the number of rows (s) or columns (n) of the
image. The DCT can be expressed in matrix form as an
orthogonal transformation [7].
DCT = UDCIkV T
DC,
(20)
where matrices UDC and VDC are orthogonal. This transfor-
mation is separable and can be deﬁned in higher dimensions.
The feature vector of an image Ik is constituted by the
q1 − q2 block of DCT , DCT (1 : q1, 1 : q2), where q1, q2
are determined by energy reconstruction considerations using
the Frobenius norm of the image Ik. Figure 9 shows the DCT
coefﬁcients of the three color channels for TNBC images with
HG2 and HG3. As in the previous case the main differences
occur for the ﬁrst coefﬁcients in each color channel. This
attribute is expected to have a low/medium discriminatory
power for TNBC images.
Figure 9.
Mean DCT coefﬁcients for HG2 and HG3 images. In this case we
plot consecutively the ﬁrst 16 DCT coefﬁcients of each color channel. No big
differences are visually observed.
G. Zernike Moments
Zernike polynomials are a sequence of polynomials that
are orthogonal on the unit disk, and are widely used as basis
functions for image analysis. Due to the orthogonality of
Zernike polynomials, Zernike moments are image descriptors
used in many applications due to their properties of orthog-
onality and rotation invariance. In biomedical applications,
Zernike moments have been used as shape descriptors to
classify benign and malignant breast masses [19]. Figure 10
shows the Zernike moments for the TNBC images of degree
2 and 3 for polynomials of order 10. This analysis provided
an attribute of dimension 36x3 for each color image in this
case. Although Zernike moments has been previously applied
as shape descriptors to classify benign and malignant breast
tissues [19], the differences do not seem very important in this
particular case and occur mainly for higher order polynomials
in the green and blue channels. This attribute is expected to
have a medium discriminatory power.
Finally, as a compendium of all these analysis, Figure 11
shows the PCA plots in 2D (similar to ﬁgure 3) of all the
attributes that have been commented. It can be observed that
the HG2 and HG3 samples are located differently in each of
these diagrams. Using the above mentioned image attributes,
the unsupervised machine learning algorithm commented in
section IV-A provided an accuracy of 86.8%, which is slightly
higher than the majority voting algorithm (80%). Future re-
search will be devoted to this important problem.
157
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

Figure 10.
Mean Zernike moments for polynomials of order 10, for HG2 and
HG3 images. The biggest differences occur in the green and blue channels.
Figure 11.
PCA plots (two ﬁrst PCA coordinates) for all the attributes used
in the analysis of the histological images.
VI.
CONCLUSIONS AND FUTURE RESEARCH
In this paper, we have explored the possibility to design
a biomedical robot able to assist physicians on the kind of
histological grade/survival of different subgroups of TNBC
samples in order to optimize their diagnosis/treatment and
prognosis. Very promising preliminary results are shown using
pathological and immunohistochemical variables and histolog-
ical images of a cohort with 105 patients. Future research
will include the possibility of using other supervised learning
techniques and global optimization methods (PSO) to optimize
the machine learning parameters and to improve the accuracy
of the classiﬁcation. Also, it is expected that the use of both
pieces of information (pathological and immunohistochemical
variables and histological images) will provide complementary
information, improving the accuracy in the classiﬁcation of
TNBC samples (histological grade and survival).
ACKNOWLEDGMENT
The authors want to acknowledge the Hospital Central
de Asturias (Oviedo, Spain) for providing all the facilities to
acquire and treat the TBNC samples.
REFERENCES
[1]
M. H. Bharati, J. J. Liu, and J. F. MacGregor, Image texture analysis:
methods and comparisons.
Chemometrics and Intelligent Laboratory
Systems, 72(1), 2004, pp. 57-71.
[2]
H. J. Bloom and W. W. Richardson, Histological grading and prognosis
in breast cancer; a study of 1409 cases of which 359 have been followed
for 15 years, British journal of cancer 11 (3), 1957, pp. 359377.
[3]
J. Canny, A computational approach to edge detection. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence, 8(6), 1986, pp.
679-698.
[4]
S. J. Dawson et al.,
BCL2 in breast cancer: a favourable prognostic
marker across molecular subtypes and independent of adjuvant therapy
received, British Journal of Cancer. 103(5), 2010, pp. 668-75.
[5]
C. W. Elston and I. O. Ellis, Pathological prognostic factors in breast
cancer I. The value of histological grade in breast cancer: experience
from a large study with long-term follow up. In Histopathology, 19,
1991, pp. 403-10.
[6]
O. Fadare and F. A. Tavassoli, Clinical and pathologic aspects of basal-
like breast cancers. In Nat Clin Pract Oncol. 5(3), 2008, pp. 149-59.
[7]
J. L. Fern´andez-Mart´ınez and A. Cernea,
Numerical analysis and
comparison of spectral decomposition methods in biometric applications.
International Journal of Pattern Recognition and Artiﬁcial Intelligence
(IJPRAI), 28(1), 2014, pp.14560-14593.
[8]
J. L. Fern´andez-Mart´ınez, A. Cernea, E. Garc´ıa-Gonzalo, J. Velasco
and B. Ketan Panigrahi,
Aligned PSO for Optimization of Image
Processing Methods Applied to the Face Recognition Problem,
In
Swarm, Evolutionary, and Memetic Computing (SEMCCO), Springer
Berlin Heidelberg, Lecture Notes in Computer Science, 8297, 2013, pp
642-651.
[9]
R. A. Fisher, The use of multiple measurements in taxonomic problems.
Annals Eugen, 7, 1936, pp. 179-188.
[10]
C. Garc´ıa-Pravia et al.,
Overexpression of COL11A1 by cancer-
associated ﬁbroblasts: clinical relevance of a stromal marker in pancreatic
cancer. In PLoS One. 8(10), 2013, e78327.
[11]
Z. M. Hafed and M. D. Levine, Face recognition using the discrete
cosine transform. Int. J. Comput. Vision, 43(3), 2001, pp. 167-188.
[12]
G. B. Huang et al., Extreme learning machine: Theory and applications.
Neurocomputing, 70, 2006, pp. 489501.
[13]
E. A. Rakha et al.,
Breast cancer prognostic classiﬁcation in the
molecular era: the role of histological grade. In Breast Cancer Research,
12(14), 2010, pp. 12-207.
[14]
L. Rokach, Ensemble-based classiﬁers. Artiﬁcial Intelligence Review,
33(1-2), 2010, pp. 1-39.
[15]
G. Shakhnarovich, T. Darrell, and P. Indyk, Nearest-Neighbor Methods
in Learning and Vision: Theory and Practice (Neural Information
Processing), The MIT Press, 2006.
[16]
S. M. Siitonen et al.,
Reduced E-cadherin expression is associated
with invasiveness and unfavorable prognosis in breast cancer. American
Journal of Clinical Pathology, 105, 1996, pp. 394-402.
[17]
T. Sørlie et al., Gene expression patterns of breast carcinomas distin-
guish tumor subclasses with clinical implications. In Proc Natl Acad Sci
USA 98(19), 2001, pp. 10869-10874.
[18]
M. Turk and A. Pentland,
Eigenfaces for recognition.
Journal of
Cognitive Neuroscience, 3(1), 1991, pp. 71-86.
[19]
A. Tahmasbi, F. Saki, H. Aghapanah, and S.B. Shokouhi,
A Novel
Breast Mass Diagnosis System based on Zernike Moments as Shape
and Density Descriptors,
Proceeding of 18th Iranian Conference of
Biomedical Engineering (ICBME) , 2011, pp.100-104.
[20]
S. E. Umbaugh. Computer Vision and Image Processing: A Practical
Approach Using CVIPtools. Number ISBN 0-13-264599-8. Prentice Hall
Professional Technical Reference, 1998.
[21]
World Medical Association, Declaration of Helsinki - Ethical Principles
for Medical Research Involving Human Subjects, The Journal Of the
American Medical Association (JAMA), 2013, Volume 310(20), pp.2191-
2194.
158
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

