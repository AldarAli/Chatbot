Coping with System Hazards in Early Project Life Cycle 
Identification and Prioritization 
 
Mohammad Rajabalinejad 
Faculty of Engineering Technology, University of Twente, Enschede, the Netherlands 
M.Rajabalinejad@utwente.nl 
 
 
Abstract--The rising complexity of product and systems 
demands further attention to potential hazards. While 
researchers explore tools and methods to identify hazards, 
their prioritization remains a challenging task in a multi-
stakeholder environment. A reason for this is that the hazards 
are hardly quantifiable. While the accurate quantification 
remains a challenge, a flexible and pluralistic approach can 
bring the important ones on top of the list. This paper offers a 
methodology for ranking hazards in early phases of design 
with presence of a high level of uncertainty. It uses a 
pluralistic approach for prioritization of hazards. It adapts 
probability theory to embed flexibly in communication with 
stakeholders and process the available information. A 
graphical 
tool 
facilitates 
this 
communication 
and 
probabilistically utilize available information about system 
hazards. It introduces the “degree of consensus” as a metric to 
rank the identified hazards. This metric represents the consent 
of stakeholders on the system of interest (SoI) concerns used 
for example in its architecture, design decisions, or alternative 
evaluation. The paper explains the mathematical formulation 
and presents an application example for this. 
consensus; hazards; uncertainty; prioritization; ranking. 
 
I. 
INTRODUCTION 
A. Hazard Identification  
Hazards are the risk sources, and their proper recognition 
and prioritization leads to a better understanding of risk and 
their management. The rising complexity and cross-
disciplinary nature of systems demands further development 
for identification of hazards [1]. Hazard is the potential 
source of harm [2], and this creates a direct link between 
hazard and risk. If a hazard is not identified, risks remain 
unattended.  
The European norm on risk assessment [3] summaries 
the tools and methods applicable to hazard identification in 
categories of strongly applicable and applicable. The 
strongly applicable methods for risk identifications are 
brainstorming, Delphi, Check-lists, Primary hazard analysis, 
Hazard and operability studies (HAZOP), Environmental 
risk assessment, SWIFT, Scenario analysis (SA), Failure 
mode and effect analysis (FMEA), Cause-and-effect 
analysis, Human reliability analysis (HRA), Reliability 
centered maintenance (RCM),  Consequence/probability 
matrix. The applicable methods for hazard identifications 
are Business impact analysis (BIA), Fault tree analysis 
(FTA), Event tree analysis (ETA), Cause and consequence 
analysis (CCA), Layer protection analysis, Sneak circuit 
analysis, Markov analysis, FN curves, Risk indices, 
cost/benefit analysis, and Multi-criteria decision analysis.  
B. Early life-cycle 
Designers can effectively impact a system in early 
design phases. In this phase, changes are often less costly 
and design decisions can profoundly influence the system of 
interest. In early design phases, proper information reduces 
uncertainties, increases utilities, and creates value for the 
system as shown in Figure 1. This is because proper 
information for a designer leads to better design choices that 
ultimately influence the rest of design including concept, 
detail, services, and etcetera.  
 
Figure 1. The information concern in the design process [4]. 
 
Yet information in the beginning of design can also be 
overwhelming. A design team may be exposed to a lot of 
information that hinders focusing on the key aspects of 
design. In system design with the multi-stakeholder nature 
of systems, divergent expectations of stakeholders can 
prevent a designer to focus on the key drivers for a system 
design.  
In an interdisciplinary system, there are a lot of mono- or 
multi- disciplinary hazards that are hard to quantify or 
prioritize. Quantification of hazards in the form of frequency 
or severity comes after its realization. Furthermore, this 
quantification may be subject to change over time. 
7
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-522-7
PESARO 2016 : The Sixth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

Lack of proper hazard identification or prioritization 
leads to rising complexity in the risk analysis and 
management. Most of the currently applied hazard 
identification methods result in a hazard pool. In such a 
view, a larger system results a larger hazard pool which 
makes the prioritization more complex. The next section 
discusses this in further details. 
C. Hazards, risks and requirements 
A good understanding of hazards and risks helps to 
develop a proper list of requirements. The importance of 
requirements have been discussed in design literatures, see 
e.g. [5-7]. This study adapts a pluralistic approach for 
highlighting system hazards, risks or requirements.  
Literatures have discussed that many engineering design 
methods pay attention to system risks when there is already 
a concept for the system. Yet proper view of main hazards 
helps forming an architecture that fits better to them [8, 9]. 
Recognition of system hazards is indeed a pluralistic 
approach, and the design team/ architecture need to 
approach different system stakeholders and explore their 
concerns about the system risks and hazards. Stakeholder in 
this paper is used as a general term that includes system 
shareholders, users, designers, experts and etcetera, and the 
concern refers to a stakeholder concern including the 
specific hazard.  
Literatures 
confirm 
that 
an 
incomplete 
set 
of 
stakeholders may lead to incomplete results since there are 
problems arising from the scope, understanding and 
validation of needs, concerns or concern [10, 11] in the 
course of communication with stakeholders. Therefore, 
identification of stakeholders and elicitation of information 
are considered as prerequisites for understanding the system 
hazards. Systems often involves a large number of 
stakeholders [12]. Figure 2 presents the functional diagram 
for identifying stakeholders and communicating with them. 
This results in a pool of concerns with a lot of information. 
Ranking of this information helps the designer to keep her 
focus on the key aspects. Recognition of key hazards is 
likely to be seen subjectively as different stakeholders tend 
to focus on their areas of interest and pay more attention to 
the hazards that influence their interest.   
 This study assumes that key hazards are recognized by 
the stakeholders and that those key hazards can be 
determined through a pluralistic approach. It therefore 
focuses to offer a pluralistic approach that communicates 
well with stakeholders, provides freedom for presenting the 
opinions, and embraces doubts or uncertainties in their 
information.  
D. System hazards 
This study builds on the assumption that key hazards in 
design are recognized by the consensus of stakeholders, and 
they can be rated systematically through a ranking process. 
In general, ranking of parameters (hazards) based on their 
importance is well discussed in decision models. The use of 
multi criteria decision models typically involves a 
systematic ranking process as for instance indicated in [13, 
14]. The influence of the ranking process on final decisions 
is for example explained in [15]. A review of subjective 
ranking methods shows that different methods cannot 
guarantee accurate results. This inconsistency in judgment 
explains difficulty of assigning reliable and subjective 
weights to the requirements. A systematic approach for 
ranking is described in [16] that is a generalization of 
Saaty’s pairwise structure [17]. Given the presence of 
subjectivity in the ranking process, sensitivity analysis of the 
design criteria is used to study the influence of variation and 
the ranking process on the decisions made [18]. 
Furthermore, some approaches e.g. the task-oriented 
weighing approach is effectively used. This approach is 
meant to limit the subjectivity of criteria weighting [19]. It 
suggests an algorithm to rank criteria objectively while 
considering the uncertainty in criteria weight [20]. The 
approach is based on introducing fuzzy numbers that 
imposes specified membership functions, which has been 
also used in [21, 22]. 
The methods used to identify the system hazards are 
mentioned earlier in this paper. The outlines of these 
methods are available elsewhere in for example [23]. The 
Figure 2. The process of identification of stakeholders and communication with them. 
Identify 
stakeholders
Integrate collected 
information
Communicate with 
stakeholders
Document 
concerns/ values 
Identify key 
concerns/
values
 more stakeholders identified?
Form the pool 
of concerns/
values
8
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-522-7
PESARO 2016 : The Sixth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

use of these methods results in a bank of information called 
a “pool of hazards”. 
E. Pool of hazards 
The so called pool of hazards integrates the identified 
hazards that threaten the system. This pool includes all the 
system hazards recognized by stakeholders. As the pool can 
become of enormous size, a method is required for listing 
them based on their priorities. Figure 3 schematically shows 
a set of hazards recognized for a system.  
 
 
Figure 3. A schematic view for the pool of hazards. 
 
II. 
COMMUNICATON OF HAZARDS 
There are obstacles in communication with system 
stakeholders 
who 
can 
be 
individuals, 
corporations, 
organizations and authorities, with different fields/ levels of 
knowledge and experience [4]. They all have their interests 
and expectations. This study uses uncertainty to allow a 
human solution in terms of preferred alternatives [24, 25]. 
The uncertainty in importance of design concerns is also of 
human nature which should be reflected in the process [26]. 
The principle of the method is described elsewhere in [7] 
and discussed in further details through this next section. 
A. Presentation  
The method aims at a realistic and intuitive approach that 
can communicate to stakeholders with different fields of 
knowledge and expertise. The method must be transparent, 
easy to implement and readily adaptable by different users. 
For this purpose, graphs are used to effectively communicate 
with different users. The format presented in Figure 4 is 
used to identify and register the importance of a concern 
according to a stakeholder. It shows that the linguistic scale 
may replace the numeric scale for the ease of 
communication, and one can assign a range of possible 
importance to a certain concern. For illustration, Figure 4(b) 
shows that the i-th concern, 
i
C , may have the importance 
somewhere from 0.6 to 0.8 according to one of the 
stakeholders in 0 to 1 grading scale, where 0 indicates no 
importance at all and 1 represents the absolute importance. 
Then, probability distribution function (PDF) is assigned to 
this recorded data. Symmetric opinions are assumed here in 
this paper as described in [27, 28] and the collected data is 
treated as a random variable with a Gaussian distribution. 
 
B. Formulation 
Having m stakeholders, their opinions for the i-th design 
concern 
i
C is presented by stochastic variables 
1
, 2
,...,
m
i
i
i
c
c
c
, 
where 
kiv  presents the k-th stakeholder’s opinion over the 
importance of the i-th concern. The mean and standard 
deviation of these variables are respectively shown as 
1
2
,
,...,
m
i
i
i



and 
1
2
,
,...,
m
i
i
i



. As a result, the overall 
mean and standard deviation of opinions over the i-th 
concern are formulated by Equations (1) and (2), 
respectively. 
1
1
1
k
m
i
k
i
m
k
k
k

 






 
  
 
 
( 1 ) 
2
2
2
2
1
k
m
k
i
i
m
j k
k
k
 













  
 
 
 
( 2 ) 
Where 
k
  represents the assigned weight to the k-th 
stakeholder. If the stakeholders are evenly graded (which is 
not very likely in the context of complex systems), 
Equations (1) and (2) transform to the following.   
1
1
k
m
i
i
m k





   
 
 
 
( 3 ) 
(a)
(b)
Figure 4. An example of a stakeholder’s opinion about 
the importance of the i-th concern
i
C .
9
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-522-7
PESARO 2016 : The Sixth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

2
2
2
1
k
m
i
i
k
m



 
   
 
 
 
( 4 ) 
After normalization, the following equations are 
concluded. 
1
i
i
n
i
i






  
 
 
 
 
( 5 ) 
2
2
1
i
i
n
i
i



















  
 
 
 
( 6 ) 
2
2
2
1
i
i
n
i
i






   
 
 
 
( 7 ) 
Where 
i , 
 i
and 
i  are respectively the weight factor, 
its standard deviation and the relative uncertainty for the i-th 
concern. Relative weight 
i  is often used as the criteria for 
ranking parameters or concerns. Under uncertain situation, 
however,  
i  is not the only parameter to rank data, and its 
uncertainty 
 i
can play an important role in the ranking 
process. High uncertainty can lead to high risk, and one may 
prefer a concern with more certainty but lower
i . On the 
basis of discussion above, we use “the reliability index” as 
an estimated measure of reliability of each concern. 
Therefore, the reliability index of each concern is estimated 
as 
i
i
i



 
  
 
 
 
 
( 8 ) 
The equation above indicates the relative standard error 
(RSE) for the importance of i-th estimated concern, which 
also can be referred to as reliability of the i-th concern [29]. 
It represents the degree of stakeholders’ consensus on the i-
th concern. The algorithm for applying this method is 
described next and an example application of it is presented 
in the next section.  
C. Algorithm 
Here, we describe the steps needed for ranking the 
requirements. A summary of this process is shown in Figure 
5. 
 
List m  stakeholders and n concerns for SoI. 
Determine the weight of stakeholders’ opinions if they 
are not evenly graded. 
 
Draw tables and list concerns 
1
2
(
,
,...,
n )
C C
C
 using 
the numeric or verbal format shown in Figure 4. 
 
Ask the stakeholders to fill the tables. This step 
concludes m series of tables. Use 
kic  format to label 
the collected information for each table, where k is the 
number of stakeholders. 
 
Calculate the expected concern and standard 
deviation (
ki and 
 ki
) for each 
kic . 
 
Calculate the mean and standard deviation for each 
concern (
i and 
i
) for the i-th concern. Use 
Equations (1) and (2). If the stakeholders are evenly 
graded, use Equations (3) and (4). 
 
Use Equations (5) to (7) to calculate the normalized 
weight of each concern, its standard deviation, and 
relative uncertainty. 
 
If new stakeholders or concerns are realized, reiterate 
from the first step. Otherwise use Equation (8) to 
calculate the degree of consensus on each concern and 
rank the concerns. 
 
This process uses the collected information and sorts the 
system concerns based on the stakeholders’ opinion. The 
next section presents an example application for this. 
List  m stakeholders and n 
concerns 
Create evaluation tables for 
concerns   
Have concerns evaluated by 
stakeholders
Calculate mean and standard deviation (µi 
and ƃi ) for  each concern ci
Measure the degree of consensus 
for each concern (βi)
Rank the concerns based on 
degree of consensus
 
Figure 5. The process for ranking concerns.
10
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-522-7
PESARO 2016 : The Sixth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

III. 
EXAMPLE APPLICATION 
To illustrate the application of the proposed method, a 
simple example is presented in this section. In the example, 
there are four concerns (hazards) in the pool of concerns 
(hazards). These concerns have typically been shown by 
different 
geometrical 
shapes 
(see 
Figure 
6). 
Two 
stakeholders have ranked the concerns according to their 
views shown in this figure. The outcome of this ranking is 
presented in TABLE 1. The first column of this table shows a 
list of design concerns which are to be ranked. The rest of 
the columns respectively present the mean, standard 
deviation, relative weight, its uncertainty and relative 
uncertainty for each concern. The last column, which is 
highlighted, shows the degree of stakeholder’s consensus.  
As seen in this table, there could be different results for 
ranking based on “relative weight” or “relative uncertainty”. 
Here the “degree of consensus” plays an important role to 
set the priority of concerns as it acts as a measure of the 
reliability in each concern.  
This example shows how the method is used to 
communicate with stakeholders, register their concerns, 
integrate the collected data and disclose the most important 
aspects. Similar results have been achieved through real-
world case studies to prioritize the stakeholder consensus in 
terms of project requirements. See for example [6, 7]. 
 
IV. 
CONCLUSIONS 
This study highlights the stakeholders’ concerns for 
identification of system hazards. Realization of key concerns 
and their ranking can be a challenging task due to a high 
number of stakeholders and their competing or conflicting 
interest.  
The paper proposes an approach that uses a graphical 
0
20%
40%
60%
80%
100%
 
0
20%
40%
60%
80%
100%  
(a) 
(b)
Figure 6. This figure presents the opinion of two stakeholders over the importance of four concerns shown by 
different figures. The numerical scale is used to present the importance of each concern. 
TABLE 1. THIS TABLE PRESENTS THE REQUIREMENTS AND THEIR WEIGHT FACTORS, STANDARD DEVIATIONS, RELATIVE 
WEIGHTS, UNCERTAINTIES IN RELATIVE WEIGHT, RELATIVE UNCERTAINTIES AND DEGREE OF CONSENSUS.
Concerns 
Expected 
concern     
(
i %) 
Standard 
deviation 
(
i
 %) 
Relative 
weight    
(
i %)
Uncertaint
y in weight 
(
 i
%) 
Relative 
uncertainty      
(
i %)
Degree 
of 
Consensus (
i %)
 
45 
5 
10 
1.1 
11 
9.1 
 
60 
7.5 
14 
1.7 
25 
8.2 
 
80 
5 
18 
1.1 
11 
16.4 
 
82.5 
5 
19 
1.1 
11 
17.3 
11
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-522-7
PESARO 2016 : The Sixth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

tool to communicate with stakeholders, collect the 
information and combine it in order to rank the concerns. 
The “degree of consensus” is used to rank concerns. The 
proposed approach is based on probability theory and 
promotes probabilistic thinking.  
The use of this outcome for triangulation of hazard 
identification is the next step for this research. 
 
REFERENCES 
[1] 
Beck, G. and C. Kropp, Infrastructures of risk: A 
mapping approach towards controversies on risks. 
Journal of risk research, 2011. 14(1): p. 1-16. 
[2] 
ISO(12100:2010), Safety of machinery - general 
principles for design - risk assessment and risk 
reduction. 2010. 
[3] 
EN(31010), Risk management - risk assessment 
techniques. 2010. 
[4] 
Rajabalinejad, M. and C. Spitas, Incorporating 
uncertainty into the design management process. 
Design Management Journal, 2012. 6(1): p. 52-67. 
[5] 
Engel, A. and T.R. Browning, Designing systems 
for adaptability by means of architecture options. 
Systems Engineering, 2008. 11(2): p. 125-146. 
[6] 
Rajabalinejad, 
M. 
and 
G.M. 
Bonnema. 
Determination of stakeholders' consensus over 
values of system of systems. in Proceedings of the 
9th International Conference on System of Systems 
Engineering: The Socio-Technical Perspective, 
SoSE 2014. 2014. 
[7] 
Rajabalinejad, 
M. 
and 
G.M. 
Bonnema, 
Probabilistic thinking to support early evaluation 
of system quality: Through requirement analysis, 
in 5th International Conference on Complex 
Systems Design & Management (CSD&M) 2014, 
Paris, 12-14 November. 2014: Paris. 
[8] 
Leveson, N., Engineering a safer world. 2012, 
Cambridge, Massachusetts, London, England: 
Massachusetts Institute of Technology. 
[9] 
Rajabali 
Nejad, 
M., 
G.M. 
Bonnema, 
and 
F.J.A.M.v. Houten, An integral safety approach 
for design of high risk products and systems, in 
Safety and Reliability of Complex Engineered 
Systems P.e. al., Editor. 2015, Taylor & Francis 
Group: Zurich, Switzerland. 
[10] 
Christel, M.G. and K.C. Kang, Issues in 
requirements elicitation. 1992, DTIC Document. 
[11] 
Heemels, W., L. Somers, P. van den Bosch, Z. 
Yuan, B. van der Wijst, A. van den Brand, and G. 
Muller, The key driver method. Boderc: Model-
Based Design of High-Tech Systems, edited by W. 
Heemels and GJ Muller, 2006: p. 27-42. 
[12] 
Heemels, W., E. vd Waal, and G. Muller, A multi-
disciplinary and model-based design methodology 
for high-tech systems. Proceedings of CSER, 2006. 
[13] 
Pahl, G., W. Beitz, and K. Wallace, Engineering 
design: A systematic approach. 1996: Springer 
Verlag. 
[14] 
Whitten, J.L., V.M. Barlow, and L. Bentley, 
Systems analysis and design methods. 1997: 
McGraw-Hill Professional. 
[15] 
Barron, F.H. and B.E. Barrett, Decision quality 
using ranked attribute weights. Management 
Science, 1996. 42(11): p. 1515-1523. 
[16] 
Takeda, E., K.O. Cogger, and P.L. Yu, Estimating 
criterion 
weights 
using 
eigenvectors: 
A 
comparative 
study. 
European 
Journal 
of 
Operational Research, 1987. 29(3): p. 360-369. 
[17] 
Saaty, T.L. and L.G. Vargas, The logic of 
priorities: Applications in business, energy, health, 
and transportation. 1982: Kluwer-Nijhoff. 
[18] 
Barzilai, J., Deriving weights from pairwise 
comparison matrices. Journal of the Operational 
Research Society, 1997. 48(12): p. 1226-1232. 
[19] 
Yeh, C.-H., R. J. Willis, H. Deng, and H. Pan, 
Task oriented weighting in multi-criteria analysis. 
European Journal of Operational Research, 1999. 
119(1): p. 130-146. 
[20] 
Buckley, J.J., Ranking alternatives using fuzzy 
numbers. Fuzzy Sets and Systems, 1985. 15(1): p. 
21-31. 
[21] 
Tsai, W.C., A fuzzy ranking approach to 
performance eealuation of quality. 2011. Vol. 18. 
2011. 
[22] 
Mitchell, 
H.B., 
Rnking-intuitionistic 
fuzzy 
numbers. International Journal of Uncertainty, 
Fuzziness and Knowledge-Based Systems, 2004. 
12(03): p. 377-386. 
[23] 
ISO(31000:2009), Risk management — principles 
and guidelines. 2009. 
[24] 
Zimmermann, H.J., Fuzzy sets, decision making 
and expert systems. Vol. 10. 1987: Springer. 
[25] 
Rajabalinejad, M. Modelling dependencies and 
couplings in the design space of meshing gear sets. 
2012. 
[26] 
McManus, H. and D. Hastings, A framework for 
understanding uncertainty and its mitigation and 
exploitation in complex systems. IEEE Engineering 
Management Review, 2006. 34(3): p. 81-94. 
[27] 
Choy, S.L., R. O'Leary, and K. Mengersen, 
Elicitation by design in ecology: Using expert 
opinion to inform priors for bayesian statistical 
models. Ecology, 2009. 90(1): p. 265-277. 
[28] 
O'Hagan, A., J. Forster, and M.G. Kendall, 
Bayesian inference. 2004: Arnold London. 
[29] 
Melchers, R.E., Structural reliability analysis and 
prediction. 1999. 
 
12
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-522-7
PESARO 2016 : The Sixth International Conference on Performance, Safety and Robustness in Complex Systems and Applications

