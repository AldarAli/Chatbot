 
 
Medical Image Retrieval Using Visual and Semantic Features 
Supreethi K P 
Department of Computer Science and Engineering.   
College of Engineering, JNTU 
 Hyderabad, India 
e-mail:supreethi.pujari@gmail.com 
Kavitha Pammi,M.Tech(CS)-VI Semester 
Department of Computer Science and Engineering. 
College of Engineering, JNTU 
Hyderabad, India 
e-mail:pammikavitha@gmail.com
 
 
Abstract— Medical images are being digitized and the 
medical databases are rapidly growing. These images 
are used in academics, diagnoses, and hospitals for 
planning treatment. Data mining techniques are applied 
to medical images, for a quick diagnosis. Thus, the 
technique of Content-based Medical Image Retrieval 
(CBMIR) emerges as the times require. For  medical 
image retrieval, current CBMIR is not sufficient to 
capture the semantic content of an image and difficult to 
provide good results according to the predefined 
categories in the medical domain by using less medical 
knowledge. In this paper, the retrieval system is a 
combination of low-level image feature and high-level 
semantics and it includes three main parts: In the first 
part, the low-level fusion visual features are extracted 
based on intensity, texture, and their extended versions. 
Secondly, a set of disjoint semantic tokens with 
appearance in lung CT images is selected to define a 
vocabulary based on medical knowledge representation. 
Finally, a mapping is investigated to associate low-level 
visual image features with their high-level semantics. In 
this paper a mapping modelling of visual feature and 
knowledge representation is presented to approach for 
medical image retrieval. One important contribution of 
this paper is the use of physicians defined linguistic 
variables closely related to known pathologies. This 
framework could be the foundation of building a novel 
and flexible model for diagnostic medical image retrieval 
that uses physician-defined semantics. 
 
Keywords- Medical image retrieval;  low-level features; 
knowledge representation;  semantic Features. 
 
I. 
INTRODUCTION  
 
With the increasing influence of computer techniques on 
the medical industry, the production of digitized medical 
data is also increasing heavily. In recent years, rapid 
advances in software and hardware in the field of 
information technology along with a digital imaging 
revolution in the medical domain facilitate the generation 
and storage of large collections of images by hospitals and 
clinics. Though the size of the medical data repository is 
increasing heavily, it is not being utilized efficiently, apart 
from just being used once for the specific medical case 
diagnosis. In such cases, the time spent on the process of 
analyzing the data is also being utilized for that one case 
only. But, if the time and data were to be utilized in solving 
multiple medical cases then, the medical industry can benefit 
intensively from the medical experts’ time in providing new 
and more effective ways of handling and inventing medical 
solutions for the future. This can be made possible by 
combining two most prominent fields in the field of 
computer science – data mining techniques and image 
processing techniques. 
Medical imaging is the technique used to create images 
of the human body for medical procedures (i.e., to reveal, 
diagnose or examine disease) or for medical science. 
Medical imaging is often perceived to designate the set of 
techniques that noninvasively produce images of the internal 
aspect of the body. Due to increase in efficient medical 
imaging techniques, there is an incredible increase in the 
number of medical images. These images, if archived and 
maintained, would aid the medical industry (doctors and 
radiologists) in ensuring efficient diagnosis. 
The core of the medical data are the digital images, 
obtained after processing the X-ray medical images; these 
should be processed in-order to improve their texture and 
quality using image processing techniques and the data 
mining techniques may be applied in-order to retrieve the 
relevant and significant data from the existing million of tons 
of medical data with the entire manual way to maintain the 
image data, which is inefficient in meeting the needs of 
searching with the huge medical image database and is 
affecting the function of the image used in the diagnoses 
adversely? Thus, the technique of Content-based Medical 
Image Retrieval (CBMIR) is considered to be an effect way 
to tackle the problem.  In specialized fields, namely in the 
medical domain, absolute color or grey level features are 
often of very limited expressive power unless exact reference 
points exist as it is the case for computed tomography 
images [13]. In the medical image system, low-level visual 
features (e.g., color, texture, shape, edge, etc.) are generated 
in a vector form and stored to represent the query and target 
images in the database. Queries by image content require 
that, prior to storage, images are processed, and appropriate 
descriptions of their content are extracted and stored in the 
database [28]. When a user makes a query, medical image 
retrievals are performed based on computing similarity in the 
118
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
feature space and most similar to the query image are 
returned to the user based on similarity values computed. 
A diagnosis by a specialist often requires a visit to a 
radiology department to obtain various images that highlight 
the suspected pathology. Despite the high resolution of the 
acquired images, image-based diagnosis often utilizes a 
considerable amount of qualitative measures. To improve the 
diagnosis and efficiency, the research in medical image 
analysis has focused on the computation of quantitative 
measures by automating some of the error-prone and time-
consuming tasks, such as segmentation of a structure. 
The Bag Of visual Words (BoW) model is commonly 
used in natural language processing and information retrieval 
for text documents [1]. In this model, a document is modeled 
as an instance of a multinomial word distribution and it is 
represented as a frequency of occurrence word histogram. 
The representation as a frequency vector of word 
occurrences does not take grammar rules or word order into 
account. It preserves key information about the content of the 
document. This representation can be used to compare 
documents, and to identify document topics. The BoW 
representation 
is 
successfully 
used 
in 
document 
classification, clustering, and retrieval tasks and is the 
cornerstone of all Internet search engines [1]. 
To represent an image using the BoW model, the image 
must be treated as a document. Unlike the text world, there is 
no natural concept for a word or a dictionary. Thus there is a 
need to find a way to break down the image into a list of 
visual elements (patches), and a way to differentiate the 
visual element space, since the number of possible visual 
elements in an image is very huge. In the visual BoW model, 
the image feature extraction step takes place in a procedure 
involving detection of points-of-interest, feature description, 
and codebook generation. The visual word Model can thus 
take the form of a histogram representation of the image, 
based on a collection of its local features. Each bin in the 
histogram is a codeword index out of a finite vocabulary of 
visual code words, generated in an unsupervised way from 
the data. Images are compared and classified based on this 
discrete and compact histogram representation. 
In recent years, the Bow approach has successfully been 
applied to general scene and object recognition tasks [9] [11] 
[19]. Varma et al.[19], introduced the idea of using the joint 
distribution of intensity values over compact neighborhoods 
for the task of texture classification was introduced. In vector 
quantization of invariant local image, descriptors were used 
to form clusters, referred to as visual “words.” They then 
searched for objects throughout a movie sequence by 
analogy to text retrieval. Natural scene categories were 
learned using visual words in [11]. Local words were either 
grayscale patches or scale-invariant feature transform (SIFT) 
descriptors [26], sampled on a grid, randomly, or at interest 
points. Then, they then learned a generative hierarchical 
model to describe the resulting visual word distribution. 
Spatial pyramids [34] were introduced as a technique of 
partitioning the image into increasingly fine sub regions, and 
computing histograms of local features within each sub 
region. 
In this paper , Section II describes the existing systems 
for medical image retrieval, limitations of the existing 
system thus motivation and advantages of the proposed 
system.  Section III presents the Architecture of the system 
and the methods followed to retrieve the result. Section IV 
depicts the module that is developed to retrieve the result. 
Section 
V 
illustrates 
the 
overall 
work 
done 
for 
implementation and Future work. 
 
II.STATE OF THE ART 
 
In picture archiving and communication system (PACS), 
image information is retrieved by using limited text keyword 
in special fields in the image header (e.g., patient identifier). 
Content-based 
image 
retrieval (CBIR) 
has received 
significant attention in the literature as a promising technique 
to facilitate improved image management in PACS system 
[13][16]. The Image Retrieval for Medical Applications 
(IRMA) project [16][38] aims to provide visually rich image 
management through CBIR techniques applied to medical 
images using intensity distribution and texture measures 
taken globally over the entire image. This approach permits 
queries on a heterogeneous image collection and helps in 
identifying images that are similar with respect to global 
features e.g., all chest x-rays in the AP (Anterior-Posterior) 
view. The IRMA system lacks the ability for finding 
particular pathology that may be localized in particular 
regions within the image. In contrast, the Spine Pathology 
and Image Retrieval System (SPIRS) [39][40][41] provides 
localized 
vertebral 
shape-based 
CBIR 
methods 
for 
pathologically sensitive retrieval of digitized spine x-rays 
and associated person metadata. Image Map [42] is so far, 
the only existing medical image retrieval that considers how 
to handle multiple organs of interest and it is based on spatial 
similarity. Consequently, a problem caused by user 
subjectivity is likely to occur, and therefore, the retrieved 
image will represent an unexpected organ. ASSERT [43] 
(Automatic Search and Selection Engine with Retrieval 
Tools) is a content–based retrieval system focusing on the 
analysis 
of 
textures 
in 
high 
resolution 
Computed 
Tomography (CT) scan of the lung. In WebMIRS [44] 
system, the user manipulates GUI tools to create a query 
such as, “Search for all records for people over the age of 65 
who reported chronic back pain. Return the age, race, sex 
and age at pain onset for these people.” In response, the 
system return values for these four fields of all matching 
records along with a display of the associated x-ray images. 
So there is a need of absolute error free, efficient and 
automatic CBMIR system which can really helpful in 
medical stream. 
Medical images are being digitized and the medical 
databases are rapidly growing. These images are used in 
academics, diagnoses, and hospitals for planning treatment. 
The existing CBMIR [3] systems are capable of retrieving 
medical images. They take input as an image and produce 
results that match the low level features of the image. Visual 
119
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
features such as color, shape and texture are implemented for 
retrieval of images in CBMIR [3]. 
 
Limitations / Disadvantages of the existing System 
 
 
The current CBMIR is not sufficient to capture the 
semantic content of an image [9] because CBMIR is 
a technique for retrieving image on the basis of 
automatically derived features such as color, texture 
and shape to index images with minimal human 
intervention. 
 
Therefore it is difficult to provide good results 
according to the predefined categories in the 
medical domain for less using the medical 
knowledge. 
 
Accordingly, in this paper, a mapping model of visual 
feature and knowledge representation is proposed. 
 
 
The proposed approach is described in the following section 
which takes the advantage of semantic feature retrieval along 
with the visual features of the medical images. 
 
III. PROPOSED SYSTEM 
 
A. System Overview 
 
 
In this paper, we propose to use medical concepts 
based on medical knowledge to represent lung CT image. It 
allows our system to work at a higher semantic level and to 
standardize the semantic index of medical data, facilitating 
the communication between visual and textual indexing and 
Retrieval. Here, a concise presentation of the main theme of 
this paper is given. 
 
As depicted in Fig. 1, the main components in 
Essence are: 1) Semantic domain; 2) Images space; 3) 
Feature extraction algorithms;  4) Feature domain; 5) 
Query system;. Knowledge components are represented in 
rectangles, and knowledge-driven actions, such as search 
and discovery, are represented in oval shapes. 
 
The Semantic domain is organized as a local-as-
view data integration subsystem [35]. This system let users 
build, refine, and further decompose their semantics 
independently, with minimum effort. The Semantic domain 
represents the expert’s knowledge in an XML format. Using 
a similar format, the framework represents the knowledge of 
a specific case, a medical image, in Feature domain. 
Each element in the Feature domain is a signature 
of a medical image in the Image space. The signature is 
computed by executing the Feature extraction algorithms. 
 
The Query system searches the knowledge base, 
selects relevant images, and translates the result into a 
human-readable format. It provides two mechanisms to 
access the knowledge: 1) query by semantics and 2) 
mapping low level features with semantic terms. 
 
 
 
Figure 1. Proposed System Architecture 
 
 
In the first part, the low-level fusion visual features 
are extracted based on intensity, texture, and their extended 
versions. Secondly, a set of disjoint semantic tokens with 
appearance in lung CT images is selected to define a 
vocabulary based on medical knowledge representation. 
Finally, a mapping is investigated to associate low-level 
visual image features with their high-level semantics.  
 
IV. IMPLEMENTATION 
 
This section describes about the implementation of each 
module like Pre-Processing, Feature Extraction, mapping 
algorithm, in which detailed description of each module is 
give below. 
 
A. Pre-Processing 
Pre-processing includes the process of removing 
the unwanted data from the image and improves the quality 
of the images. This process of removing unwanted data (like 
stop-words in the data mining process) can be achieved by 
the techniques such as cropping, image enhancement, etc. In 
this section, a series of effective pre-processing methods 
[31] are adopted to extract the pulmonary parenchyma 
which will improve the quality of feature extraction and 
then increase the retrieval performance in accuracy and 
speed. The process of extraction of pulmonary parenchyma 
is as follow.  
 
 
 
Figure 2. Pre-processing Result 
 
120
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
Step 1: Cutting out the background region 
 
First, pre-processing is applied to the original CT 
scan image. Both lungs and their nearby portions 
are areas of interest and pixel values external to 
this area being insignificant are removed. 
Step 2: Segmentation with optimal threshold and noise     
            Cancellation 
 
The next step is applying threshold to the image to 
achieve two categories of pixels in the image or a 
binary image. Then tested for separation of left and 
right lungs if no threshold value is adjusted. 
Step 3: Elimination of trachea and main bronchus. 
 
During acquisition or digitization process of CT 
scan images a noise could be introduced that needs 
to be reduced. An appropriate filter need to be 
chosen which can enhance the image quality even 
for non uniform noise, like salt and pepper noise, 
and also preserve the important edges. 
 
There may be the presence of noise and other 
components, i.e., airways and bronchi in the image. 
These components are to be eradicated. 
 
It is evident that two major objects in the threshold 
image are both lungs. Connected component 
analysis is applied here.  
 
The connected component labelling algorithm 
assigns distinct labels to all the regions in the 
image so as to manipulate the regions fulfilling the 
specific criteria set for regions. Keeping this in 
view, extract the two largest components. 
Step 4: Adaptive segmentation of left and right lung 
 
A fully automatic method based on adaptive 
thresholding for segmenting the lungs in three-
dimensional (3-D) pulmonary X ray CT images 
consists of eight steps.  
 
In the first step, a threshold is selected to convert a 
CT image into a binary image.  
 
In the second step, the lung objects are removed 
from the ribcage to obtain the external mask.  
 
In the third step, the right and left lung area is 
extracted by applying the external mask.  
 
In the fourth step, the large airways are removed 
utilizing the mean and the deviation of pixel 
intensities. 
 
In the fifth step, a test is made to see if the selected 
threshold is good. If the selected threshold is not 
good, the 
 
Threshold will be adjusted and the algorithm goes 
back to step 1.  
 
In the sixth step, a morphology operation is applied 
to smooth the mediastinum.  
 
In the seventh step, a split curve is derived from the 
gap of the separated left and right lungs.  
 
In the last step, the left and right lungs are 
segmented. 
Step 5: Refinement processing and mask generation 
 
The external mask is adopted to eliminate 
unwanted objects surrounding the lungs, so the 
whole lung region can be extracted precisely. 
 
To obtain the external mask, remove the two lungs 
to form the non-lung mask. And then the non-lung 
mask will be inverted to build the external mask. 
 
Thus, pulmonary parenchyma is useful for the extraction of 
image feature. One of segmentation result is shown in Fig 
.2, various features such as trachea, CTbed will be extracted. 
 
B. Low-Level Feature Extraction  
 
Low-level image feature extraction is the basis of CBIR 
systems. To performance CBIR, image features can be 
extracted from the entire image. 
 
 Gray Level Co-Occurrence Matrix (GLCM) Statistical 
Feature Vector: 
 
 
With the created GLCM [36], various features can 
be computed out. Fourteen parameters were summarized 
before, but with the special characteristics of lung CT 
image, four parameters are chosen to descript the 
texture. These feature description groups along with the 
images are in a database for the retrieval purpose. 
 
• Energy 
 
Measure the number of repeated pairs. The energy 
 
is expected to be high if the occurrence of repeated 
 
pixel pairs is high. 
     ∑
    
   ∑
   [ (   )    )] 
   
|(d,)]2         (1) 
• Entropy 
 
Measure 
the 
randomness 
of 
a 
gray-level 
 
distribution. The entropy is expected to be high if 
 
the gray-levels are distributed randomly throughout 
 
the image. 
     
∑
    
   ∑
   [ (   )    )]    [ (      
   
  )] (2) 
 
• Contrast 
 
Measure the local contrast of an image. The 
 
contrast is expected to be low if the gray levels of 
 
each pixel pair are similar. 
        ∑
    
   ∑
   (   )   (       )
   
|d,)  (3) 
 
• Correlation 
121
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
 
Provide a correlation between the two pixels 
 
in the pixel pair. The correlation is expected  to be 
high if the gray levels of the pixel pairs  
are highly correlated. 
     
∑
    
   ∑
      (       ) 
   
    
    
 
 (4) 
               
            Where  x ,  y,  x , y are mean value and standard 
variance of 
  
 
 
So, the above GLCM parameters are used as retrieval 
feature vector: F GI.CM = {FENG, FENT, FCOR, FLOC}.And d= 1, 
 
 
 
Wavelet Statistical Feature Vector: 
 
 
Wavelet transform [37] has been successfully used 
in 
image 
compression, 
enhancement, 
analysis, 
and 
classification. An image is a 2-D signal, so the 2-D discrete 
wavelet transform (DWT) can be implemented to approach 
to texture analysis. 
  
In this paper, a multi-resolution representation is 
gotten by using 2-D wavelet transform with three-level 
decomposition. The statistical information, which is from the 
texture feature with different multi-resolution, will constitute 
the retrieval feature vector. When the distinct texture 
characteristics appear in certain frequency and direction the 
output of wavelet channel has more energy. So the mean and 
variance of energy distribution in every decomposition level 
can represent the texture feature. And we use the mean and 
variance of this energy as the retrieval feature vector FWAVI. . 
 
  
  
 (5) 
 
C. Knowledge Representation and Semantic Features 
Identification Phase 
 
 
Most of the decisions in the medical domain are 
made by comparing the data in hand against existing domain 
knowledge. During the decision-making process, physicians 
base their diagnoses on a set of heuristics developed from 
different areas as a "multi-dimensional intuition" in which 
tacit knowledge plays a very important role. Several 
perceptual categories are usually used for recognizing 
pathologies in lung CT images by physicians. 
 
In this phase, a set of disjoint semantic tokens with 
appearance in medical images is selected to define a 
vocabulary based on medical knowledge representation. 
Here we use the keywords of diagnosis report from the 
doctor to represent each token in the medical domain. 
 
 
Semantic vocabulary used 
1. 
Reticular Opacities  
2. 
Nodular Opacities 
3. 
High Density Areas 
4. 
Low Density  Areas 
5. 
Cavitary  
6. 
Cystic structure 
7. 
Emphysema  
8. 
Calcification  
9. 
Honeycombing  
10. 
hydrothorax 
 
 
Mapping Algorithm 
 
The main difficulty in image retrieval based on 
semantics is to use image's low-level features to replace 
"word" (semantic) in the text retrieval. 
1. A set of disjoint semantic concepts with visual 
appearance in medical images is first selected to define a 
vocabulary based on medical knowledge representation. 
2. Low-level features are extracted from medical image z to 
represent each vocabulary term. 
3. These low-level features are used as training examples to 
build hierarchical semantic classifiers according to the 
semantic vocabulary. The classifier for the medical semantic 
vocabulary is designed using a hierarchical classification 
scheme based on Support Vector Machine (SVM) 
classifiers.  
4. Hierarchical classification scheme is based on Support 
Vector Machine (SVM) classifiers. A tree, whose leaves are 
the medical semantic vocabulary terms is designed and 
constructed in a top-down manner, guided by the possible 
hierarchy of the associated terms in semantic vocabulary. 
Fig. 3 depicts the tree. The upper levels of the tree consist of 
auxiliary classes that group similar terms with respect to 
their visual appearances.  
 
 
 
Figure 3. Tree Structure for Medical Semantic Vocabulary 
Classifier 
D. Retrieval Phase 
 
For training of SVM, 100 images with physicians labelling are 
selected as training set and rest of the images are utilized to 
test the retrieval approaches. For SVM based image 
classification, recent work shows that the Radial Basis 
kernel Function (RBF) works well when the relation 
between class labels and attributes is nonlinear [33]. 
122
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
Therefore, we use RBF kernel as a reasonable first choice. 
The RBF kernel function is 
 
 (6) 
 
There are two tuneable parameters, while using 
RBF kernels: c and r. We define C =200 and r =0.0002 for 
example. 
 
In this phase, the low level features are used as 
training examples to build a semantic classifier according to 
the above vocabulary. The visual feature and semantic 
feature are mixed as Indexing. 
 
 
 
Figure  4. A Retrieval Result 
 
 
In the experiments, every image from the test DB 
is served as a query image. We design two types of 
experiments to evaluate the retrieval system. 
 I) Retrieval based on low level features only. For every 
medical semantic category, we chose relevant image as 
example to conduct the retrieval.  
2) Retrieval based on semantic description. For every 
medical semantic category 10 tests are conducted and 100 
tests are conducted totally. One of semantic concept with 
hydrothorax retrieval results is shown in Fig. 4. Based on 
the  input image as shown in the left top corner in Fig. 4,  all 
the similar images from the database are retrieved. 
Our system has a small knowledge base, which can 
be further enhanced. Ensemble classifiers can be used in the 
future 
work. Sophisticated knowledge representation 
algorithms may be considered. 
 
E. Evaluation of the Results 
 
Retrieval precision and ranking measures (Average-r) are 
used as parameters in system evaluation. 
(I) The retrieval precision is defined as follows : 
 
Precision = a / a+b                                      (7) 
Where a is the number of similar images and b is the 
number of dissimilar images in the results . 
(2) Suppose the query is q , r1,r2,.... rm are the correct results 
retrieved by the system, rank(rj) is the No. j correct result's 
ranking position, so the average ranking value is calculated 
as follows: 
 
Average-r = 1/m m rank(rj)                                   (8)
 
 
 
 
 
j=1 
This value reflects the average ranking of query in the 
retrieval results. So, the smaller it is, the better. In the 
experiment, we set m=10. The statistic results are shown in 
Table 1. 
TABLE 1. The Experiment Static Result 
 
 
 
 
From the above statistic results , we can see that 
the image with outstanding texture information always get 
better precision and smaller average ranking value. For 
example the images which possess the pathological 
characteristics of nodular opacities and honeycombing get 
the best precision. This is Because the low-level feature 
extraction procedure is mainly used of texture analysis 
algorithm. 
 
In addition, when the visual features are difficult to 
present the method use semantic correlation can put up a 
satisfied result. For above ten kinds of queries, the semantic 
correlation gets an average precision. So we can see the 
method we proposed has a good robustness. 
V  CONCLUSION AND FUTURE WORK  
 
In this paper, visual, semantic features and 
knowledge representation are used for medical image 
retrieval. This framework could be the foundation for 
building flexible model for diagnosis of medical images. 
This framework can use physician-needed semantics. The 
expressions of diseases in medical image are complex and 
various. From the statistical results, the image with 
outstanding texture information always gets better precision 
and smaller average ranking value. The images which 
possess the pathological characteristics of nodular opacities 
and honeycombing get the best precision. In addition, when 
the visual features are difficult to present the method uses 
123
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
semantic correlation, which can put up a satisfied result .Our 
results prove that our proposed system has good robustness.  
 
REFERENCES 
[1]  U.Avni, H. Greenspan, Eli Konen, M.Sharon, and J. Goldberger, "X-
ray Categorization and Retrieval on the Organ and Pathology Level, 
Using Patch-Based Visual Words", IEEE Transactions on Medical 
Imaging , vol 30, no.3, March  2011. 
[2]  U.Avni, J. Goldberger,M. Sharon, E.Konen, and H. Greenspan, 
“Chest X-ray characterization: From the organ identification to the 
pathology categorization,” presented at the 11thACMSIGMM 
International Conference on Multimedia Information Retrieval (MIR-
2010),  Philadelphia, PA,  Mar.2010, pp. 29–31. 
[3] C. B. Akgul, D. L. Rubin, S. Napel, C. F. Beaulieu, H. Greenspan, 
and B. Acar, “Content based image retrieval in radiology: Current 
status and future directions,” J. Digital Imag., Jan. 2010. 
[4] S.Bhadoria and  Dr. C. G. Dether, “Study of Medical Image Retrieval 
System”, International Conference on Data Storage and Data 
Engineering., 2010. 
[5] U. Avni, J. Goldberger, and H. Greenspan, “Dense simple features for 
fast and accurate medical X-ray annotation,” in 10th Workshop of the  
Cross-Language Evaluation Forum (CLEF 2009), LNCS. New York: 
Springer,Lecture Notes in Computer Science, 2010. 
[6] U.Avni, J. Goldberger,M. Sharon, E.Konen, and H. Greenspan, 
“Chest X-ray characterization: From the organ identification to the 
pathology categorization,” presented at the 11thACMSIGMM 
International Conference on Multimedia Information Retrieval (MIR-
2010),  Philadelphia,  PA,  Mar.2010,  pp. 29–31. 
[7] Li Jin, L.Hong, and T.Lianzhi, "A Mapping Modelling of Visual 
Feature and Knowledge Representation Approach for Medical Image 
Retrieval". Proceedings of the 2009  IEEE International Conference 
on Mechatronics and Automation, Changchun, China,August 2009. 
[8] J. Zhang, M. Marszalek, S. Lazebnik, and C. Schmid, “Local features 
and kernels for classification of texture and object categories: A 
comprehensive study,” Int. J. Comput. Vis., vol. 73, no. 2, 2007,pp. 
213–238. 
[9] E. Nowak, F. Jurie, and B. Triggs, “Sampling strategies for bag-of-
features image classification,” in Proc. ECCV,2006, pp. 490–503. 
[10] Liu, J., Hu, Y., Li, M., Ma, and W.-Y., 2006. Medical image 
annotation and retrieval using visual features. In: Working Notes of 
the 2006 CLEF Workshop. 
[11] L. Fei-Fei and P. Perona, “A Bayesian hierarchical model for learning 
natural scene categories,” in Proc. CVPR, 2005, vol. 2, pp. 524–531.  
[12] H. Alto, R. M. Rangayyan, and J. E. L. Desautels, “Content-based 
retrieval and analysis of mammographic masses,”J. Electron. Imag., 
vol. 14, no. 2, 2005. 
[13] H. Müller, N. Michoux, D. Bandon, and A. Geissbühler, “A review of 
content-based image retrieval systems in medical applications—
Clinical benefits and future directions,” I. J. Med. Informat., vol. 73, 
no. 1, 2004, pp. 1–23. 
[14] S. Hong, C.Wencheng, Z.Jiwu and Z.Hong, "Medical image retrieval 
based on low level features and semantic features," Journal of Image 
and Graphic, vol. 9, no. 2, 2004, pp.220-224. 
[15] T. F.Wu, C. J. Lin, R. C. Weng, “Probability Estimates for Multi-
class Classification by Pairwise Coupling.”,Journal ofMachine 
Learning Research, vol. 5,2004, pp. 975–1005. 
[16] T. M. Lehmann et al., “Content-based image retrieval in medical 
applications,” Methods Inf. Medicine, vol. 43, no. 4, Oct. 
2004,pp.354–361,. 
[17] Khanh Vu, Hua K.A and Tavanapong W., “Image Retrieval Based on 
Regions of Interest”, Knowledge and Data Engineering, IEEE 
Transactions on, vol. 15, April 2003,pp.1045-1049. 
[18] E. Chang, G. Kingshy, G. Sychay, and G. Wu. “CBSA:content-based 
soft annotation for multimodal image retrieval using Bayes point 
machines”, IEEE Trans. on CSVT, 13(1), 2003,pp. 26–38. 
[19] M. Varma and A. Zisserman, “Texture classification: Are filter banks 
necessary?,” in Proc. CVPR,  vol. 2,2003, pp. 691–698. 
[20] P. J. Eakins, “Towards Intelligent image retrieval.”, Pattern 
Recognition, vol. 35,2002, pp. 3–14. 
[21] M. R. Naphade, C. Lin, J. R. Smith, B. Tseng, and S.Basu, “Learning 
to Annotate Video Databases,” Proceedings of SPIE, vol. 4676,2002, 
pp. 264–275. 
[22] A. Smeulder, M.Worring, S. Santini, A. Gupta, R. Jain, “Content-
Based Image Retrieval at the End of the Early Years.”, IEEE Trans. 
on Pattern Anal. and Machine Intell., vol.22, 2002, pp. 1349–1380. 
[23] J. C. Bezdek, et al., "Fuzzy Models and Algorithms for Pattern 
Recognition and Image Processing"., Kluwer Academic Publishers, 
Boston, 1999. 
[24] O. Chapelle, P. Haffner, V. Vapnik, “SVMs for histogram-based 
image classification.”, IEEE Trans. on Neural Networks, vol.10(5), 
1999,pp. 1055–1064. 
[25] A. K. Jain, M. N. Murty, and P. J. Flynn, “Data clustering:a review.”, 
ACM Computing Surveys, vol. 31(3),1999, pp.264–323.    
[26] D. G. Lowe, “Object recognition from local scale-invariant features,” 
Proc. ICCV, vol. 2, 1999,pp. 1150–1157.                                                
[27] P. Korn, N. Sidiropoulos, C. Faloutsos, E. Siegel, and Z. Protopapas, 
“Fast and effective retrieval of medical tumor shapes,”IEEE Trans. 
Knowl. Data Eng., vol. 10, no. 6, Nov./Dec. 1998, pp. 889–904. 
[28] E.G.M. Petrakis and C. Faloutsos, “Similarity searching in medical 
image databases,” IEEE Trans. Knowl. Data Eng., vol. 9, no. 3, 
1997,pp. 435–447. 
[29] C. Cortes and V. Vapnik, “Support-vector network”,Machine 
Learning, vol. 20, 1995,pp. 273–297. 
[30] K. 
Fukunaga, 
"Introduction 
to 
Statistical 
Pattern 
Recognition".,second ed., Academic Press, 1990. 
[31] C. Lei, Z. Jie, Y. Xiao-e, et al, "Fast lung segmentation algorithm for 
thoracic 
CT 
based 
on 
automated 
thresholding," 
Computer 
Engineering and Applications, vol. 44,  no.12,  2008, pp.178-181. 
[32] Qing-zhu Wang , Ke Wang "Medical Image Retrieval Based on Low 
Level Feature and High Level Semantic Feature," 2nd International 
124
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

 
 
Conference on Computer Engineering and Technology, vol. 7, no.12, 
2010,pp.430-432. 
[33]   O. Chapelle, P. Haffner and V. Vapnik,  "SVMs   for histogram based           
         Image classification". IEEE Trans. On Neural Networks, vol                                       
 
  10,1999,   pp.1055-1064. 
 [34]  A.Abdullah, Remco C.  Veltkamp and  Marco   A. Wiering, " Spatial    
Pyramids and Two-layer Stacking SVM Classifiers for Image              
categorization: A Comparative Study". 
 [35] I. F. Cruz and A. Rajendran, “Semantic data integration in                                                                                                                                                              
 
hierarchical domains,” IEEE Intell. Syst., vol. 18, no. 2, Mar.– Apr.    
           2003, pp-63-73.s 
  [36] P.Maheshwary, N.Sricastava, "Prototype System for Retrieval of 
Remote Sensing Images on Color Moment and Gray Level Co-
occurrence Matrix," IJCSI International Journal of Computer 
Science Issues, Vol 3, 2009.  
[37]  G. Quellec, M. Lamard, G. Cazuguel, B. Cochener, and C. Roux. 
“Wavelet optimization for content-based image retrieval in medical 
databases.”, Medical Image Analysis, 14(2), 2010, pp.227 - 241. 
[38] C. Thies, M.O. Guld, B Fischer, and T.M. Lehmann, "Content-based 
queries on the CasImage database within the IRMA framework”, 
Lecture Notes in Computer Science, Springer 3491, 2005, pp. 781–
792.  
[39]  S. Antani, L.R. Long, and G.R. Thoma, “Content-based image 
retrieval for large biomedical image Archives”, Proceedings of 11th 
World Congress Medical Informatics,2004,pp.829–833. 
[40]  L.R. Long, S.K. Antani, and G.R. Thoma, “Image informatics at 
national research center”, Computer Medical Imaging   and graphics 
(ELSEVIER), Vol. 29, 2005, pp.171–193. 
[41] G.R. Thoma, L.R. Long, and S.K. Antani, “Biomedical                        
imaging research and development: knowledge from images  in the 
medical enterprise”, Technical Report Lister Hill           National 
Centre for Biomedical Communications, 2006. 
[42]   E.G.M. Petrakis, and C. Faloutsos, “ImageMap: An Image Indexing 
Method Based on Spatial Similarity”, IEEE Transaction on 
Knowledge and Data Engineering, 2002, pp. 979–987. 
[43] Chi-Ren Shyu, Carla E. Brodley, Avinash C. Kak, and Akio 
Kosaka,“ASSERT:A 
Physician-in-the-Loop 
Content-Based 
Retrieval System for HRCT Image Databases”, Computer Vision 
and Image Understanding, Vol. 75, No. 1, 1999, pp. 111–132.  
[44]   L.R. Long, S.R. Pillemer, R.C. Lawrence, GH Goh, L. Neve, and 
G.R. Thoma, “WebMIRS:Web-based Medical Information Retrieval 
System” , Proceedings of SPIE Storage and Retrieval for Image and 
Video Databases VI,SPIE ,Vol. 3312, 1998, pp. 392-403.
  
125
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-354-4
ADVCOMP 2014 : The Eighth International Conference on Advanced Engineering Computing and Applications in Sciences

