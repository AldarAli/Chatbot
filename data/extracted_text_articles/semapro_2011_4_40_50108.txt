A Multi-Layer Approach to the Derivation of  
Schema Components of Ontologies from German Text 
Mihaela Vela and Thierry Declerck 
Language Technology Lab 
DFKI Saarbrücken 
Saarbrücken, Germany 
Mihaela.Vela@dfki.de Thierry.Declerck@dfki.de
 
 
Abstract—We describe an on-going work on the semi-
automatic derivation of ontological structures from text. 
Hereby, we first apply on plain text pattern-based linguistic 
heuristics, for identifying relevant segments out of which 
candidate ontology classes and relations can be derived. The 
second step proposes a consolidation of those candidates on the 
basis of a partial linguistic and semantic analysis of the textual 
context of the segments. The last step is dealing with the 
extension of the derived ontology structures. We use for this a 
constituency and dependency analysis of the textual segments 
selected in steps 1 and 2. We show how these three steps 
support in different but related ways the derivation of ontology 
components from text.  
Keywords – knowledge acquisition; text-based knowledge 
I. 
INTRODUCTION 
We describe a semi-automatic incremental multi-layer 
rule-based methodology for the derivation of ontology 
schema components from a corpus consisting of the 1992 
edition of the German newspaper "Wirtschaftswoche". We 
use this somehow older corpus, since it has been manually 
annotated with various types of information. The corpus 
comprises 200107 words, 11583 sentences and 121331 
phrases. By Derivation of Ontology Schema Components we 
mean the acquisition from text of possible concepts and 
relations between these concepts for the semi-automatic 
ontology building. By Ontology Schema we mean a construct 
similar to the T-Box of an ontology [23]. Our work is 
addressing the intensional part of ontologies and can be 
considered as contributing to the ontology learning field at 
large. Ontology learning is the process of semi-automatic 
support in ontology development (see [1]). 
We are dealing in our work primarily with German text. 
In this concrete case, we consider compound nouns and their 
paraphrases in the corpus as the basic segments in text that 
can serve for the detection of candidate ontology classes and 
relations. Compounding is a very rich word formation 
process in German (and other related Germanic languages), 
also 
with 
well-established 
construction 
patterns 
corresponding to semantic types, which makes them good 
candidates 
for 
the 
derivation 
of 
ontology 
schema 
components. We use paraphrases of nominal compounds in 
the corpus for fixing their status as candidates for classes and 
for specifying the relations existing between those classes. 
Paraphrases of compounds are defined as a text segment 
containing the elements of the compound nouns separated by 
a limited number of other word forms. 
In a second step, we apply morphological, Part-of-Speech 
(PoS) and lexical-semantic analysis to the text segments 
described in step1. This helps further filtering out and further 
specifying the previously derived candidates, avoiding 
redundancies in the derivation of classes (limiting the names 
of class labels to lemmas, and joining labels that are 
synonyms, etc.) 
In the last step, we extend the extracted classes and 
relations on the basis of deeper linguistic processing, more 
precisely analyzing the constituency and dependency 
structures of the context of the detected textual segments. 
Our approach results in a set of generic patterns (in machine 
learning language we would call them seeds) for deriving a 
stable structure of conceptual relations from the combined 
shallow and linguistic analysis of specific textual segments. 
The paper is structured as follows. Section 2 gives an 
overview on related work. Section 3 describes the pattern-
based processing of text for detecting segments containing 
candidates for ontology derivation. Section 4 presents the 
ontology derivation potential from the textual context of the 
segments, annotated with PoS, morphology, and lexical 
semantics. Section 5 deals with the refinement of the 
ontology derived so far, using constituency and dependency 
information. Section 6 describes some evaluation work and 
Section 7 concludes and names some issues for further work. 
II. 
RELATED WORK 
There are purely linguistic approaches to Ontology 
Learning ([3][4][5]), linguistic approaches making use of 
machine learning for generalization ([6]) and machine 
learning approaches that use linguistic information ([2][7]). 
Those approaches have in common that they concentrate on 
discovering new relations, although some approaches are 
dealing with the discovery of new concepts ([2][6][8]) too. 
The purely linguistic approaches ([3][4][5]) perform 
ontology learning on the basis of deep linguistic analysis, by 
activating a graphical interface controlled by the user for 
entering the extracted knowledge into the ontology. 
The method proposed in this paper is based on linguistic 
patterns, combining shallow and deep linguistic analysis, in 
an unsupervised way, and thus not involving authoring tools. 
91
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

Our work resembles most the one presented by [6], but our 
combination from shallow and deep linguistic analysis 
allows covering a wider range of phenomena for the 
derivation of schema components of ontologies. 
III. 
PATTERN-BASED TEXT ANALYSIS 
Although pattern-based linguistic heuristics alone is not 
enough to acquire extended and complex ontological 
knowledge, a pre-processing of the plain text is very 
important when it comes to define an anchor (text segment) 
from which to start the computationally more expensive 
process of ontology learning.  
A. Detection of Candidate Concepts and Relations 
A first intuition guiding our investigation is the fact that 
German nominal compounds are good indicators for the 
expression of relations between concepts expressed by the 
elements of the compounds. According to [9], the German 
determinative compounds (determinative compounds are 
those in which one element is subordinated to the other 
element of the other, more precisely, one element 
determines/specifies the other element [10]) consist mostly 
of two elements, whereas the first one usually specifies the 
second. From this observation one can heuristically derive a 
hyponymy relation between the whole compound and its 
second element: Konzernchef (chief of corporation) is a 
specific type of a Chef (chief). 
Although German uses also copulative compounds, we 
do not expand on those in the actual paper, in which we 
concentrate on binary determinative noun-noun compounds 
(copulative compounds are compounds were the elements 
are considered semantically coequal and which do not have a 
main element which specifies or determines the other 
element in the compound. This type of compounding is more 
seldom in German [11]). We implemented a quite 
straightforward pattern-based algorithm for the detection of 
this type of compounds: we first search for nouns in the 
corpus (for German, a string starting with a capital letter 
between blanks or between a blank and a punctuation sign). 
If, in a second search round, we can detect that such a noun 
item appears as sub-string in a larger noun, then we 
considered that we have found a compound. While this 
approach works quite well for finding the nouns acting as the 
prefix of a compound (since it starts with a capital letter), we 
need to access a lexicon for deciding if the suffix of the 
compound is also a noun (we use for this the lexicon listed in 
[24].) 
We include in our patterns the German joint elements 
(Fugeelement) which may appear in compounds (such as “s“ 
in Wohnungsbau (house building),  in order to get the right 
string, when the word is used in isolation. But with our very 
simple approach we do miss the nouns that undergo 
morphology changes when they are used in a compound.  
We consider the two elements of a nominal compound as 
acting as potential ontology classes, and the remaining task is 
then to specify the possible relations between these two 
nouns, or candidate ontology classes. 
B. Deriving Candidate Ontology Classes and Relations 
from Nominal Compounds 
On the basis of the detection of compounds, and 
assuming that elements of compounds act as possible 
ontology classes, we suggest two rules for deriving potential 
elements for the schema of an ontology: the structural type 
represented by the subClassOf relation (rendering the 
relation between the whole compound and its second 
element) and a relation denoting an objectProperty 
(rendering the relation between the two elements of the 
compound). We are using here the OWL-DL terminology for 
the property name. 
The first rule states that between a compound as a whole 
and its second noun there is a subClassOf relation. This 
decision is motivated by the definition of the determinative 
compounds which introduces hyponymy between the 
compound and its second noun. 
For example, from the compound Bankenvertreter we 
derive the relation: subClassOf(Bankenvertreter, Vertreter), 
which translated into English means that a representative of 
a bank is a subClassOf a  representative. 
Our intuition - sustained by the already existing analyses 
of the German compound ([11][12][13]) - was that there 
exists also an additional relationship between the elements of 
a compound, which we consider of being of type  
objectProperty. Applying the corresponding rule to the 
already mentioned compound Bankvertreter we derive a 
objectProperty(Bank, Vertreter) relation between the class 
Bank (bank) and the class Vetreter (representative). 
Obviously, the (naïve) processing strategy presented 
above is very general and the very generic objectProperty 
relation we can derive is not really satisfying. In order to 
improve this state, we try to find expressions in the text that 
are containing paraphrases of the compounds, expecting to 
find more semantic information for allowing the further 
specification of the (generic) object property relation we 
established between the elements of a compound. 
C. Patterns for the Recognition of Paraphrases of 
Compounds 
After splitting the compound back into noun1 + noun2 
we automatically search for paraphrases (in our context a 
paraphrase consists of a test window that contains the 
elements of a compound separately) of all found compounds 
in our corpus. Our decision to look for the paraphrases of 
compounds is motivated by the fact, that while we assume 
that the elements of a compound are semantically related to 
each other, analyzing the paraphrases will allow specifying 
more precisely this relation [9]. Compounds without a 
paraphrase are no longer considered for ontology derivation. 
For now the search space for detecting paraphrases is our 
corpus, but this will be extended to other corpora. 
Our assumption is also sustained by [11] and [13]. 
Although they have two different methods for approaching 
this issue, the main idea is the same: the elements of a 
compound are semantically related to each other and this 
relation becomes visible in the paraphrase.   
We find in the corpus two kinds of paraphrases, in which 
the elements of the original compounds are linguistically 
92
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

related: either by a genitive article as Vertreter der Bank 
(representative of the bank) or by a preposition as Chef im 
Konzern (chief of corporation). The finding of a paraphrase 
for a compound validates the subClassOf relation, whereas 
the use of lexical semantics on the elements of a paraphrase 
allows specifying the objectProperty. 
IV. 
SHALLOW LINGUISTIC ANALYSIS 
The addition of PoS and morphology annotation to the 
paraphrases helps in solving the redundancy problem of the 
ontology classes: by using lemmas for generating names of 
classes we avoid generating as many classes as this lemma 
has morphological variations in the text. Lexical semantics 
allows reducing the number of classes by grouping lemmas 
to more general “words” (like the synsets of GermaNet 
(GN) [14]) and at the same time specifying the derived 
generic relation objectProperty according to the semantics 
(therefore we use GN’s semantic fields for nouns: artifact, 
attribute, shape, feeling, body, cognition, communication, 
motive, food, object, phenomenon, plant, substance, time, 
animal, state, act, process, person, group, possession, 
relation, attribute, event, quantity, location) of these lemmas 
and of other word forms present in the paraphrase.  
  
A. Specifying Relations with Lexical Semantics 
Analyzing the paraphrases annotated with GN’s semantic 
information we discovered the following six relations 
between the already detected classes:   
• 
hasPosition,  
• 
disposesOver,  
• 
hasDimension,  
• 
hasAttribute,  
• 
hasEvent,  
• 
hasLocation. 
For example, for the compound Aktiengesellschaft (stock 
company) 
we 
found 
the 
reformulation 
Aktien 
der 
Gesellschaft (shares of the company), where Aktien was 
semantically classified as belonging to GN's semantic class 
possession and Gesellschaft has been classified as belonging 
to GN's semantic class group enabling the structural 
integration of the discovered classes and relations into a 
more sophisticated ontology structure. The heuristics for the 
derivation of the relation between the two concepts Aktien 
(shares) 
and 
Gesellschaft 
(company) 
proposes 
the 
verbalization of the more generic class to which the first 
noun in the paraphrase belongs. This way the verbalized 
possession was transformed into disposesOver generating 
disposesOver(Gesellschaft, Aktien). 
Applying morphology and lexical semantics to the 
second type of paraphrase patterns, those involving 
prepositions, we notice that the generic objectProperty can 
be further specialized depending on the lexical semantics of 
the used prepositions.  
Prepositions are semantically ambiguous, but the 
ambiguity can be reduced on the base of the lexical 
semantics of the associated nouns. Analyzing this type of 
paraphrases we discovered, based on the same heuristics as 
for genitive phrases, a set of six rules for the derivation of 
ontological relations. From this six relations, five were 
already discovered during the analysis of genitive phrases: 
disposesOver, hasDimension, hasAttribute, hasEvent,  and 
hasLocation. Only one relation is new: the hasAffiliation 
relation. 
B. Analyzing Modification Phenomena 
In the process of detecting paraphrases we observed that 
many of the paraphrases contain modifiers. In order to 
determine the type of ontological relation that can be 
extracted from the structure modifier(s)-nominal head (such 
as multinationale Gesellschaft (multinational corporation)), 
some components of the structure had to be viewed from a 
lexical semantic point of view. We concentrate here on 
adjectives and adverbs, and apply to them various language 
specific classification schemes. 
For adjectives we used the classification by [15] and for 
adverbs the classification by [16] (we use for modifiers this 
semantic classification because they are more fine-grained 
than GermaNet's classification and we can easily add new 
adjectives and adverbs to it). As for nouns, the semantic 
classes to which the adjectives and adverbs belong are 
introduced as ontology classes. 
Based on this classification we introduce new relations 
between the modifiers and the noun they modify. Having for 
example the paraphrase Aktien der deutschen Gesellschaft 
(shares of the German corporation), the derivation rule will 
return the following relation: hasNationality(Gesellschaft, 
Nationality). Here hasNationality is a subproperty of 
hasAffiliation. 
Many of the nouns appearing in paraphrases are modified 
by just one modifier. But there are cases in the corpus in 
which a noun is preceded by more than one modifier.  For 
multiple premodifiers which are not separated by any 
punctuation sign or conjunction to each other, we speak of an 
aggregation of adjectives. For example for großen deutschen 
Konzern (large German concern), linguistically the first 
premodifier in the token chain modifies the remaining phrase 
[17]. From this kind of linguistic constructions we extract 
hasNationality(Konzern, Nationality) and hasDimension( 
Konzern, Dimension). 
A different linguistic principle applies for modifiers 
connected by punctuation signs or/and conjunctions: each 
pre-modifier introduces a relation between itself and the 
noun it modifies [17]. From kleinen, krisengeplagten Firmen 
(small 
firms, 
affected 
by 
the 
crisis) 
we 
extract 
hasDimension(Firma, Dimension) and hasMode(Firma, 
Mode). As one can see, we cannot model directly the two 
different ways plural modification is linguistically working 
in the ontology. 
A more specific case is represented by the modification 
of adjectives by adverbs such in sehr großes Gehalt (very big 
salary). In this case the adverb sehr modifies the adjective 
großes and not the whole phrase [10] großes Gehalt. We 
extract then the relations: hasAspect(Dimension, Aspect) and 
hasDimension(Gehalt, Dimension). 
 Since modification is a very powerful linguistic 
phenomenon with a high coverage in the corpus, the three 
93
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

extraction rules discussed above cover 26 relations, 
depending on the semantic class of the modifier. 
V. 
PHRASE STRUCTURE AND SYNTACTIC INFORMATION  
Although, many extraction rules were generated with the 
shallow linguistic analysis, we are aware that the sentential 
level is an additional resource for the extraction of 
ontological information. We decided to first analyze 
predicate-argument structures in all sentences containing a 
paraphrase, since those contain in our sense already enough 
hints for possible ontology classes and relations. The 
analysis of the extracted sentences has shown that there is 
potential 
for 
extracting 
additional 
ontology 
schema 
components. In this case we also have to take into account 
additional PoS tags and morphological information (for 
example for the verbs). As a lexical-semantic resource for 
the verb, we use both the classification by [18] and GN.  
A. Extraction of Ontology Schema Components from 
Grammatical Functions 
With the help of grammatical functions (for example the 
subject-object relation in a sentence) we developed a set of 
rules for extracting the arguments of specific verbs in the 
corpus. This allows extracting relations such as  
• 
earn,  
• 
appliesFor, 
• 
estimate,  
• 
hasPossession,  
• 
partOf, 
• 
subClassOf, 
• 
etc. 
Let 
us 
consider 
the 
following 
sentence: 
Die 
Papierherstellung ist zu einer extrem kapitalintensiven 
Branche geworden (Paper production evolved to a very 
capital-intensive branch). In this example, the verb sein (be) 
connects the subject Papierherstellung (paper production) 
and the kapitalintensiven Branche (capital-intensive branch) 
of the sentence. 
In fact, the rule states that only the nominal heads of the 
phrases identified as subject and object enter the ontology 
and therefore we extract subClassOf(Papierherstellung, 
Branche). Additionally, for each of the two nouns we use 
GN's information about synonyms, antonyms, hyponyms and 
meronyms. In a next step, we include then also the 
information 
that 
Branche 
can 
have 
the 
property 
kapitalintensiv.  
VI. 
EVALUATION  
The evaluation of the method for extracting ontology 
schema components was performed on a manually annotated 
test suite. The test suite consists of 200 randomly selected 
sentences (out of over 11000) which were annotated by a 
student of business informatics. We plan to ask another 
person to annotate the same corpus. This was till now not 
possible for time reasons. 
We applied our method and the corresponding tools on 
this test corpus. The quantitative evaluation was performed 
in two stages, and after each stage we measured the 
performance of our method. We compared the results of our 
method with the manual annotation by calculating the F-
measure. 
 
TABLE 1. PRECISION AND RECALL SCORES 
 
Phenomenon 
Prec. 
Recall 
1st run 
2nd run 
Compound 
(subClassOf) 
1 
1 
1 
1 
Modification 
1 
0,52 
0,68 
1 
(Para)phrase 
1 
0,23 
0,37 
0,76 
Gramm Funct. 
0.5 
0,30 
0,38 
0,80 
 
From the results in Table 1 we notice that we have the 
best results when it comes to extract the subClassOf relation, 
which is extracted mainly from compounds. It seems that our 
compound filtering process is really helping in getting a high 
number of correct answers. But it seems also that the 200 
manually annotated sentences contain only determinative 
compounds, and we would have to test our method on 
copulative compounds too. 
The subClassOf relation is extracted not only from 
compounds but is introduced into the ontology from GN 
(using the more abstract “words” in the synsets). In this case 
the left-hand side argument of the subClassOf relation differs 
from the one chosen by the manual annotator. 
We consider still our method to be valid, since we found 
it totally normal that a human being annotates semantically 
different than GN (the student didn't have GN as a resource 
to consult for his annotation). Both assignments by GN and 
by the student are correct, but we notice that the manual 
annotator has chosen a more specific class than the one our 
method uses. 
    The results from the modification phenomena show that 
we have a very good precision. This means that we either 
find a true relation or we do not find it at all. This 
corresponds to the methodology applied: if a modifier is in 
our modifier lexicon it produces a true relation, if not it does 
not produce anything and these we can read from the recall 
score. 
   For the relations extracted from phrases we achieve the 
lowest scores concerning the recall. This low score is due to 
three factors: there is no rule for extracting a relation, the 
implemented rule does not work properly and the rule exists 
but it does not fire because of lack of semantic information. 
We can influence on the first two factors by writing new 
rules or improving the implementation of the existing rules. 
     In fact the GN lookup fails because certain nouns in our 
analysis do not have a stem and the GN lookup is based on 
stems. This is an issue that we can solve in a next stage of 
our work.  
The scores for ontology extraction from grammatical 
functions show one characteristic common to all other 
phenomena: the relation is either not found but if it is found 
than it is correct. The precision and recall (and consequently 
the F-measure) scores are influenced not necessary by our 
94
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

rules, but by the assignment of grammatical functions by the 
parser. Because we cannot influence the ambiguity of the 
grammatical function assignment, in the second evaluation 
round we manually corrected the ambiguities provided by 
the parser. 
In the second evaluation round we concentrated also on 
relations from phrases and modification. We improved the 
scripts implementing the rules for ontology extraction from 
phrases and enlarged our lexicons for ontology extraction 
from modification phenomena. We also have to notice here, 
that the disambiguation of the grammatical function 
assignment provided a considerably improvement of the 
measured scores. 
Also part  of the evaluation, in a broader sense, is the 
integration of the ontological knowledge extracted here into 
a bigger ontology. We suggest for this purpose The 
Suggested Upper Merged Ontology (SUMO) [25]. SUMO is 
in a large freely available ontology. Another  important 
characteristic of SUMO is the fact that it has been mapped to 
the whole lexicon of WordNet. From this perspective, 
SUMO is the ontology which fits our approach, when it 
comes to integrate our work into a broader ontology. It is 
true, that there is no direct mapping between GN and 
SUMO. This situation can besolved by first mapping from 
GN to WordNet and then to SUMO. The direct mapping 
between GN and WordNet is possible since both have the 
same general structure concerning the semantic tree. 
 
VII. CONCLUSION AND FURTHER WORK 
Our aim was to present a multi-layer, rule-based 
approach for the extraction of ontology schema components 
and to show that a significant amount of ontological 
knowledge can be derived without using exclusively deeper 
linguistic information. 
While applying our method on German language, we saw 
that this approach can be extended to all Germanic languages 
making use of compounding. Swedish is a good example, 
and [22], for example discusses the potential of compound 
for building a FrameNet resource for Swedish.  
 We also experimented with other language families, 
more specifically French. Different from the German 
compounds, the French compounds are not always conflated 
to a single word. The cumulated form of compounds such as 
sociolinguistique (sociolinguistic) is in French the exception. 
The majority of compounds in French consist either of two 
components connected by a hyphen such as timbre-poste 
(stamp) or are just two or more words which appear in a 
lexical chain such as dessin animé (animated cartoon) or 
séance  marathon (marathon session). The most productive 
of the latter compounds are the compounds constructed with 
prepositions such as mesure de sécurité (safety measure). 
Noun-noun compounds are in French less frequent than in 
German or English [21]. We applied our method on 
compounds consisting of nouns, of an adjective and a noun 
and prepositional compounds. Assuming the appropriate 
linguistic tools, our method can be applied to French text. 
It seems thus that only the first step of our work would 
need a complete re-implementation when applying our 
strategy to other language (families).  
The phenomena which we consider in this work are 
compounding, 
nominalization, 
premodification, 
postmodification, phrase-structure combined with lexical 
semantics. From the purely linguistic point of view we do 
not take into consideration the peculiarities of relative 
clauses. We also do not cope now with the semantic and 
linguistic properties of the negation particle or with 
coreference. These phenomena are not treated here because 
of a more pragmatical and practical reason: the linguistic 
tools we have at hand do not annotate these kinds of 
phenomena. Experiments on the instantiation were also 
performed, achieving promising results. To integrate these 
phenomena into the approach presented here remains an 
issue for future work. 
Beside these points, we are now working on modeling 
our findings about the relations between natural language 
expressions and ontology schema components in an 
appropriate way. This is done within the context of a running 
European R&D project, the Monnet project [26]. In this 
project, a model, called “lemon” [27], for representing 
lexicons in ontologies, has been implemented. While this 
model has been primarily designed for the ontological 
representation of natural language expressions used in labels 
of ontologies, we see a big opportunity for using this model 
for the representation of language data we have been dealing 
with in the context of knowledge acquisition from text. First 
steps are dealing with abstracting over the lexical material 
we found in text, and confining ourselves with the use of 
linguistic categories, that are related to specific ontology 
schema components. The work is thus going toward a 
declarative description of linguistic patterns that should be 
used in ontology engineering. 
 
VIII. ACKNOWLEDGEMENTS 
The work presented in this paper was supported (in part) 
by the European project MONNET No. (FP7/2007-2013) 
248458.  
REFERENCES 
[1] P. Buitelaar, P. Cimiano, and B. Magnini, “Ontology learning from 
text: An overview,” in Ontology Learning from Text: Methods, 
Evaluation and Applications. Frontiers in Artificial Intelligence and 
Applications, IOS Press, vol. 123, pp. 3-12, 2005. 
[2] M. A. Hearst, “Automatic acquisition of hyponyms from large text 
corpora,” in Proceedings of 14th International Conference on 
Computational Linguistics (COLING-92), pp. 539-545, Nantes, 
France, 2002. 
[3] P. Cimiano, A. Hotho, and S. Staab, “Learning concept hierarchies 
from text corpora using formal concept analysis,” Journal of Artificial 
Intelligence Research, vol. 24, pp. 462-471, 2005. 
[4] G. Aguado de Cea, A. Gomez-Perez, E. Montiel-Ponsoda, and M. del 
Carmen Su´arez-Figueroa, “Natural language-based  approach for 
helping in the reuse of ontology design patterns,” Proceedings of the 
EKAW Conference, pp. 32-47, 2008.  
[5] N. Aussenac-Gilles and M.-P. Jacques, “Designing and evaluating 
patterns for relation acquisition from texts with caméléon,” 
Terminology, vol. 5, nr. 1, pp. 450-473, 2008. 
95
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

[6] M. Ciaramita, A. Gangemi, E. Ratsch, J. Saric, and I. Rojas, 
“Unsupervised learning of semantic relations for molecular biology 
ontologies,” in Ontology Learning and Population: Bridging the Gap 
between Text and Knowledge, IOS Press, pp. 91-107, 2008. 
[7] P. Gamallo, M. Gonzalez, A. Agustini, G. Lopes, and V. S. de Lime, 
“Mapping syntactic dependencies onto semantic relations,” in 
Proceedings of the ECAI Workshop on Machine Learning and 
Natural Language Processing for Ontology Engineering, pp. 15-22, 
2002. 
[8] E.de la Clergerie, “Spécifications du service d’extraction supervisée 
d’ontologies,” SCRIBO Project, Tech. Rep., 2009. 
[9] J. Erben, “Einführung in die deutsche Wortbildungslehre”, 3rd ed. 
Berlin: Erich Schmidt Verlag GmbH and Co., 1993. 
[10] Duden, “Grammatik der deutschen Gegenwartssprache”, 4th ed 
Mannheim/Wien/Zürich, Dudenverlag, 2006. 
[11] M. Lohde, “Wortbildung des modernen Deutschen”, Tübingen: 
Francke, 2006. 
[12] W. 
Fleischer 
and 
I. 
Barz, 
“Wortbildung 
der 
deutschen 
Gegenwartssprache”,  2nd ed. Tuebingen, Niemeyer, 1995. 
[13] W. Motsch, “Deutsche Wortbildung in Grundzügen”, 2nd ed. Berlin, 
de Gruyter, 2006. 
[14]  C. Kunze and L. Lemnitzer, “GermaNet – representation, 
visualization, application,” in Proceedings of the LREC, pp.1485-
1491, 2002. 
[15] S.-M. Lee, “Untersuchungen zur Valenz des Adjektivs in der 
deutschen Gegenwartssprache”, Frankfurt am Main, Germany: Lang, 
1994. 
[16] A. Lobeck, “Discovering Grammar: An Introduction to English 
Sentence Structure”, Oxford University Press, 2000. 
[17] G. Zifonun, L. Hoffmann, and B. Strecke, “Grammatik der deutschen 
Sprache”, Berlin/New York, de Gruyter, 1997, vol. 3. 
[18] H. Schumacher, Verben in Feldern, 1st ed. Berlin: de Gruyter, 1986. 
[19] M. Vela and T. Declerck,“A Methodology for Ontology Learning: 
Deriving Ontology Schema Components from Unstructured Text”, 
Proceedings of the Workshop on Semantic Authoring, Annotation 
and Knowledge Markup, Redondo Beach, California, United States, 
pp. 22-26,2009. 
[20] M. Vela and T. Declerck, “Concept and Relation Extraction in the 
Finance 
Domain”, Proceedings of the Eighth 
International 
Conference on Computational Semantics (IWCS-8), Tilburg, 
Netherlands, Tilburg University, pp. 346-351, 1/2009. 
[21] H. Geckelerand and W. Dietrich, “Einführung in die französische 
Sprachwissenschaft”, Erich Schmidt Verlag, 2007. 
[22] L. Borin, D. Dannélls, M. Forsberg, M. Toporowska Gronostaj, and 
D. Kokkinakis, “The Past Meets the Present in the Swedish 
FrameNet++” , 14th EURALEX International Congress, pp. 269-281, 
2010. 
[23] http://wiki.dbpedia.org/Ontology, retrieved October, 2011. 
[24]  http://wortschatz.uni-leipzig.de, retrieved October, 2011. 
[25] http://www.ontologyportal.org/, retrieved October, 2011. 
[26] www.monnet-project.eu/, retrieved October, 2011. 
[27] J. McCrae, G. Aguado-de-Cea, P. Buitelaar, P. Cimiano, T. Declerck, 
A. Gomez-Perez, J. Gracia, L. Hollink, E. Montiel-Ponsoda, and D. 
Spohr, “Interchanging lexical resources on the Semantic Web. Journal 
for Language Resources and Evaluation”, in press. 
 
 
 
 
96
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-175-5
SEMAPRO 2011 : The Fifth International Conference on Advances in Semantic Processing

