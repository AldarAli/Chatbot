Reachability Games Revisited
Imran Khaliq
Media Design School
Auckland, New Zealand
email:imran.khaliq@mediadesignschool.com
Gulshad Imran
Dept. of Mathematics, University of Auckland
Auckland, New Zealand
email: ggul005@aucklanduni.ac.nz
Abstract— In this paper, we provide a reﬁned analysis of the
classical algorithm for solving reachability games. We provide a
new algorithm that remembers information about fewer nodes
than the classical algorithm does by computing the number of
efforts made by the player to win the game.
Keywords – reachability games; effort based strategies; mem-
oryless determinacy
I. INTRODUCTION
In system Veriﬁcation and Testing, the reachability ques-
tion asking if a system can attain some speciﬁed state
from a given state is well studied and well motivated. The
reachability question was studied in the context of games by
many [1] – [7]. Reachability games are played between two
players Players 0 and Player 1, over a ﬁnite directed graph.
The nodes of the graph are the states of the system it models
and edges of the graph represent transitions of the system.
An inﬁnite sequence of states of the system can now be
viewed as an inﬁnite path through the graph. The question
of reachability in veriﬁcation can now be solved in terms
of constructing winning strategies for the corresponding
reachability game. In reachability games, Player 0 wins a
play if the play visits some speciﬁed set, called a target set,
at least once. A reachability game is solved in linear time
on the size of the underlying graph [2].
The problem of solving a reachability game is mainly
about constructing the attractor set for the winner. The
concept of attractor set is also useful for the solution of
inﬁnite games with Safety [6], Buchi [8], McNaughton [9],
and, Parity [10] winning conditions. The classical algorithm
(see for instance [2]) for solving reachability games suggests
a winning strategy that remembers ranks of all the nodes in
the winning region of Player 0. Roughly, a rank of a node
v is i if Player 0 can reach the target set (starting from
v) within i moves made by the players. In this paper, we
carefully analyse the attractor set of the target set. We call
the attractor set (for Player 0) of the target set the winning
region for Player 0. We observed that the winning region may
contain Player 0 nodes such that all its outgoing edges lead to
the winning region of Player 0. We call a set containing such
nodes the effortless region of Player 0. The ranks of the nodes
in effortless region need not to be remembered. Therefore,
our winning strategy for Player 0 takes into account such
nodes and hence improves upon memory efﬁciency. We call
such strategies, effort-based strategies. We call a strategy that
is dependent only on the current node of the play, memoryless
strategy. Thus memoryless strategies do not depend on the
history, where history is a ﬁnite preﬁx of a play. We will
prove that effort-based strategies are memoryless strategies.
Such strategies recall fewer ranks than the classical approach.
The summary of the paper is as follows. In Section II,
we will provide basic deﬁnitions about games in general.
In Section III, we will describe reachability games. In
Section IV, we will provide our own procedure for solving
reachability games. Finally, the conclusion is presented in
Section V.
II. BASIC DEFINITIONS
Our games are played between two players. We call them
Player 0 and Player 1. The underlying graph of a game is
called arena. Our deﬁnition of arena is the following:
Deﬁnition 2.1 (Arena): An arena is a tuple (V0 ∪ V1, E),
where V0 and V1 are pairwise disjoint sets of nodes and
E ⊆ V0×V1∪V1×V0 is the set of edges. We set V = V0∪V1.
We also postulate that for every u ∈ V there always exists
v ∈ V such that (u, v) ∈ E. We always assume that the
set V of nodes is ﬁnite. The set of successors of u ∈ V is
deﬁned by uE = {v ∈ V | (u, v) ∈ E}.
Thus, arenas are just ﬁnite bipartite graphs. The nodes of
the set V0 will be called Player 0’s nodes and nodes of V1
will be called Player 1’s nodes.
Let G = (V0 ∪V1, E) be an arena. A play between Player
0 and Player 1 is described as follows. The play begins at
any node v0 ∈ V . Say the node is in V0. In this case, Player
0 selects an edge e = (v0, v1), moves along the edge, and
passes control to the opponent. Then, Player 1 selects an edge
e = (v1, v2), moves along the edge and passes control to the
opponent. This goes on turn by turn. The deﬁnition of arena
implies that at any given moment of the play, the players
are able to make moves and continue the play. Formally, we
deﬁne a play as follows.
Deﬁnition 2.2 (Play): A play in the arena G = (V0 ∪
V1, E) is an inﬁnite sequence v0, v1, v2, v3 . . . such that
(v0, v1), (v1, v2), (v2, v3), . . . are all edges of the graph.
Unless the arena is trivial, there are inﬁnitely many inﬁnite
plays. Clearly, every play is an element of V ω, where V ω is
the set containing all sequences over V .
Let G = (V0 ∪V1, E) be an arena. Let ρ = v0, v1, v2, . . . ,
be an inﬁnite play played between Player 0 and Player 1.
We would like to deﬁne what it means that Player 0 wins
the play ρ. The winner is determined through the following
deﬁnition.
129
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-458-9
SOFTENG 2016 : The Second International Conference on Advances and Trends in Software Engineering

Deﬁnition 2.3: A winning set for Player 0 is a subset
W ⊆ V ω. We say that Player 0 wins the play ρ if ρ ∈ W.
Otherwise, Player 1 wins the play.
Now, we are ready to formally deﬁne a game.
Deﬁnition 2.4 (Game): A game between Player 0 and
Player 1 is a tuple (V0 ∪V1, E, W), where G = (V0 ∪V1, E)
is an arena and W is a winning set for Player 0. We typically
denote games by Γ.
Note that, arenas are ﬁnite objects while winning sets W are
not necessarily objects that are deﬁned by ﬁnite means.
A. Strategies
In this section, given a game, we deﬁne the winner of
the game and explain what it means to solve the game. The
notation σ ∈ {0, 1} will represent one of the two players
Player 0 and Player 1, his opponent will be represented by
1 − σ.
Let Γ = (V0 ∪ V1, E, W) be a game. We deﬁne histories of
the game as follows.
Deﬁnition 2.5: A history is a ﬁnite preﬁx of a play. We
deﬁne set of histories for Player σ as follows: H(σ) = {h | h
is a history and the last letter of h is in Vσ}.
Clearly, H(σ) ∩ H(1 − σ) = ∅ and every history is either
in H(σ) or in H(1 − σ). Informally, a strategy for Player
σ, is a rule that tells the player which edge to select given
a history of a play in H(σ). Formally, we deﬁne a strategy
for a player as follows.
Deﬁnition 2.6: A strategy for Player σ is a function fσ :
H(σ) → V such that for every h = v0, v1, . . . , vn ∈ H(σ)
we have (vn, fσ(h)) ∈ E.
Now, given a node v ∈ V and strategy fσ for Player σ, one
can consider all the plays starting at v and consistent with
the strategy fσ. Here, we say that a play ρ = v0, v1, v2, . . .
is consistent with fσ if v0 = v and for all histories h =
v0, v1, . . . vi ∈ H(σ) of this play we have (vi, fσ(h)) ∈ E
and vi+1 = fσ(h).
Deﬁnition 2.7: Let Γ = (V0 ∪ V1, E, W) be a game. Let
v ∈ V be a node.
• We say Player σ wins from a node v if Player σ has
a winning strategy fσ such that all the plays that begin
from v and consistent with fσ are winning for the
player.
• We say Player σ wins from a set or has a winning
strategy from a set A ⊆ V if Player σ has a winning
strategy from each node in A.
• We say that v is a winning node for Player σ if the
player wins the game from the node v.
From this deﬁnition, it follows that, if v is a winning node
for a player, then v can not be a winning node for the
opponent. One of the fundamental concepts in game theory
is the following deﬁnition.
Deﬁnition 2.8: A game Γ is determined if every node of
the game is winning for either Player 0 or Player 1.
There are examples of games that are not determined,
see [11]. Determinacy is one of the important topics in
descriptive set theory. One of the important theorems is the
following theorem of Martin [12].
Theorem 2.9 (Martin’s determinacy theorem): Every
Borel game, that is the game at which W is a Borel set, is
determined.
Reachability games are Borel and hence determined. The
deﬁnition below is meant when we say a game is solved.
Deﬁnition 2.10: Let Γ be a game. We say Γ is solved if
there exists an algorithm that given the Γ, outputs the sets W0
and W1, where W0 is the set of all nodes in Γ from which
Player 0 wins the game and W1 is the set of all nodes in Γ
from which Player 1 wins the game. The set Wσ, σ ∈ {0, 1}
is called winning region for Player σ.
III. REACHABILITY GAMES
In this section, we discuss reachability games in detail.
The algorithm and deﬁnitions discussed here are borrowed
from [2]. In reachability games, Player 0 wins a play if the
play visits a speciﬁed set of nodes at least once. Formally,
we deﬁne reachability games as follows.
Deﬁnition 3.1 (Reachability Games): A
reachability
game Γ consists of:
1) The arena G = (V0 ∪ V1, E).
2) The target set T of nodes T ⊆ V0 ∪ V1.
We say that Player 0 wins a play v0, v1, v2, v3 . . . if there
exists an i such that vi ∈ T. Otherwise, Player 1 wins the
play.
From the deﬁnition, it is clear that Player 0 wins a play ρ
from a node u if
• ρ begins from the node u;
• there is a ﬁnite preﬁx η of ρ such that the last node in
η belongs to the target set.
Deﬁnition 3.2: A memoryless strategy for Player σ is a
function fσ : Vσ → V such that (u, fσ(u)) ∈ E. A game
enjoys memoryless determinacy if for every node one of the
players wins the game with memoryless strategy.
It turns out that winners in reachability games have
memoryless winning strategies. We prove this in the next
theorem. Before we proceed, we deﬁne some notations. Let
Γ be a reachability game. Assume X ⊆ V . Deﬁne,
reachσ(X) = {u ∈ Vσ | ∃ v ∈ uE ∩ X}∪
{u ∈ V1−σ | uE ⊆ X}.
When the player is clear, then sometimes we denote the
above set by reach(X).
Theorem 3.3 (Memoryless Determinacy [2] pp. 34):
Reachability games enjoy memoryless determinacy.
Proof:
The winning region for Player 0 is deﬁned
inductively. We set, X0 = T, and for i ∈ ω, Xi+1 =
reach0(Xi) ∪ Xi. Since the set of nodes V is ﬁnite there
is an s such that Xs = Xs+1, where s is the smallest such
number.
130
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-458-9
SOFTENG 2016 : The Second International Conference on Advances and Trends in Software Engineering

Claim 3.4: The set Xs is the winning region for Player
0, that is W0 = Xs.
For the proof, we use the concept of rank. We say a node u
has rank r, r ≥ 0, if u ∈ Xr \ Xr−1. A node u has inﬁnite
rank if u /∈ Xr for all r.
To deﬁne a memoryless strategy f0 for Player 0 we linearly
order < the set V1 that is, v1 < v2 < v3 < · · · < vl where
l = |V1|. We deﬁne f0 as follows:
Let v ∈ Xs∩V0. Let r be the rank of v. Then f0(v)
is minimal with respect to < such that (v, f0(v)) ∈
E and rank of f0(v) is r − 1.
For v /∈ Xs, we set f0(v) be the minimal with
respect to the order < such that (v, f0(v)) ∈ E.
We show that f0 is winning strategy from the set Xs. Let
v be a node in Xs. From the above deﬁnition of reach(Y )
it implies that v has some ﬁnite rank r say. If v is Player
0’s node then by the strategy f0 Player 0 chooses f0(v) of
rank r − 1. If v is Player 1’s node then Player 0 waits for
Player 1’s move. Since vE ⊆ Xr−1, any choice of Player
1 selects a node in vE of rank strictly less than r. Each
player’s move select a node of lesser rank every time. Since
r is ﬁnite, every play that begins from v ultimately ends at
a target node. Hence Xs ⊆ W0.
Now, we show that Player 0 cannot win from a node in
V \ Xs. Let M = V \ Xs. To deﬁne a memoryless strategy
f1 for Player 1 we linearly order the set V0 that is v′
1 < v′
2 <
v′
3 < · · · < v′
m where m = |V0|.
If v ∈ M∩V1 then f1(v) is minimal with respect to
the order such that f1(v) ∈ M and (v, f1(v)) ∈ E.
If v ∈ Xs then f1(v) is the minimal with respect
to the order such that (v, f1(v)) ∈ E.
Let v belong to M. If v is Player 0’s node then Player 1 does
nothing but just waits for the Player 0’s move. Any choice
of Player 0 selects a node in M. This is because vE ⊆ M
as otherwise v would be in W0.
If v is Player 1’s node then there exists a node v′ ∈ M
such that (v, v′) ∈ E otherwise v would belong to W0. By
strategy f1 Player 1 chooses minimal f1(v) with respect to
the order < such that f1(v) ∈ M and (v, f1(v)) ∈ E. Player
0 cannot win any play which begins from a node belongs
to M if Player 1 follows the strategy f1. This is because
M ∩ T = ∅. Hence, W0 = Xs and W1 = M.
Corollary 3.5: There exists an algorithm that solves
reachability games in O(|V | + |E|) time, where V is the
set of nodes and E is the set of edges in the arena.
Proof:
We construct the winning region for Player
0 inductively. Initially, we set X0 = T. Suppose Xi is
constructed. To construct Xi+1, ﬁrst we copy elements of
Xi to Xi+1. Second, we add a node u in Xi+1 if:
• u ∈ V0 and if there exists a node v ∈ Xi such that
(u, v) ∈ E, then we add to Xi+1.
• u ∈ V1 and if uE ⊆ Xi, then we add to Xi+1.
To implement the procedure for constructing the winning
region in O(|V | + |E|) time, we assign a counter c(u) to
a node u /∈ T. Initially, we set
c(u) = 1 if u ∈ V0 and
c(u) = |uE| if u ∈ V1.
Whenever, we add a node v to Xi+1, where v
/∈ Xi,
we subtract 1 from the counter of each node u such that
(u, v) ∈ E; From this point on the edge (u, v) will never be
used again. When a counter becomes zero then the node is
also added to Xi+1. This shows that the running time of the
algorithm is in O(|V | + |E|).
Corollary 3.6: Let Γ be a reachability game. The function
φσ : 2V → 2V deﬁned by φσ(A) = A ∪ reachσ(A), is
monotone function with respect to set inclusion, where A ⊆
V and 2V is the set containing all subsets of V . That is,
φσ(A) ⊆ φσ(B) whenever A ⊆ B.
Deﬁnition 3.7: We denote the winning region of Player 0
in a reachability game by Attr0(T) and call it the 0-attractor
of the set T. A memoryless winning strategy f0 as described
in the proof of Theorem 3.3 is called T-attractor strategy for
Player 0. When the target set T is clear, then we simply say
attractor strategy for Player 0.
Note that, in reachability games, we can change the roles
of the players. In this case, Player 1 tries to reach a given
set T while the opponent tries to avoid it. As shown above,
one can build the 1-attractor of the set T. Hence, we can
talk about σ-attractor sets for the players when a target set
is speciﬁed.
Deﬁnition 3.8: A σ-trap (or trap for σ) is a subset X ⊆ V
such that vE ⊆ X for every v ∈ X ∩Vσ and vE∩X ̸= ∅ for
every v ∈ X ∩ V1−σ. A memoryless strategy which assigns
for v ∈ X ∩V1−σ a node f(v) ∈ vE ∩X is called a trapping
strategy for Player 1 − σ.
Corollary 3.9: The complement of σ-attractor of a target
set T is σ-trap.
IV. REACHABILITY GAMES AND EFFORT MOVES
In this section, We give a reﬁned analysis of the set
Attr0(T) for a given reachability game Γ. The idea here
is to compute the number of efforts made by Player 0 to
win the game from Attr0(T). Let X ⊆ V be a set. Deﬁne
ℑ(X) = {v ∈ V | vE ⊆ X}. We deﬁne the sequence
ℑ0, ℑ1, ℑ2, ℑ3, . . . as follows:
ℑ0 = X,
ℑi+1 = ℑ(ℑi) ∪ ℑi.
Since the arena is ﬁnite, there exists a minimal k such that
ℑk+1 = ℑk. We call this ℑk, the effortless region for X and
denote it by eﬀ(X).
Lemma 4.1: Player 0 has a winning strategy from eﬀ(T)
to visit T.
Proof:
Let u ∈ eﬀ(T). This implies that u ∈ ℑi for
some i. Since uEi ⊆ ℑi−1, any play starting at u will
eventually visit ℑ0 = T. Thus, a winning strategy for Player
0 is simply to choose any node v such that (u, v) ∈ E.
In order to construct the winning region for Player 0, we
deﬁne the sequence eﬀ0, eﬀ1, eﬀ2, eﬀ3, . . . as follows:
eﬀ0 = eﬀ(T)
131
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-458-9
SOFTENG 2016 : The Second International Conference on Advances and Trends in Software Engineering

eﬀi+1 = eﬀ(eﬀi ∪ reach(eﬀi)).
Let us recall reach(Y ) = {u ∈ V0 | ∃v ∈ uE ∩ Y } ∪ {u ∈
V1 | uE ⊆ Y }, where Y ⊆ V . Here, the second part is
empty. Since, the arena is ﬁnite, it implies that there exists
a minimal t such that eﬀt+1 = eﬀt.
Deﬁnition 4.2: The Player 0’s move from a node u to a
node v in a reachability game is called an effort move if
u ∈ reach0(eﬀi) \ eﬀi and v ∈ eﬀi for some i.
Lemma 4.3: Player 0 has a strategy from eﬀi+1 \ eﬀi to
visit T after i + 1 effort moves have been made.
Proof:
We prove the lemma by induction on i. For
i = 0, let x ∈ eﬀ1 \ eﬀ0. This implies that any play
from x will eventually visit reach0(eﬀ(T)). For every u ∈
reach0(eﬀ(T)), there exists a v ∈ eﬀ(T) such that (u, v) ∈
E otherwise u /∈ reach0(eﬀ(T)). We set f(u) = v. Player 0
now moves to this v.
Let the lemma be true for i = k.
Let x ∈ eﬀk+1 \ eﬀk.
Any play from x will eventually visit reach(eﬀk). For every
u ∈ reach0(eﬀk) there exists a v ∈ eﬀk such that (u, v) ∈ E,
otherwise u /∈ reach0(eﬀk). We set f(u) = v. If Player 0
follows this strategy f, then Player 0 can visit eﬀk after one
effort has been made if a game begins from the node x. By
induction hypothesis Player 0 can visit T after k + 1 effort
moves.
Theorem 4.4: Let Γ be a reachability game. Consider the
sequence deﬁned as follows:
eﬀ0 = eﬀ(T)
eﬀi+1 = eﬀ(eﬀi ∪ reach0(eﬀi)).
If t is the minimal number such that eﬀt+1 = eﬀt then eﬀt
is the winning region for Player 0 and V \eﬀt is the winning
region for Player 1.
Proof: Let u ∈ eﬀt. By the above two lemmas Player
0 has a strategy to visit T after t effort moves. Hence eﬀt ⊆
W0. This strategy can be written explicitly as follows. For
any given u ∈ V0 set:
If u ∈ reach0(eﬀi) \ eﬀi for some i then select
v such that (u, v) ∈ E and v ∈ eﬀi. Otherwise,
select any w such that (u, w) ∈ E.
To prove W0 = eﬀt, we show that Player 1 has a winning
strategy from V \ eﬀt. We set W ′ = V \ eﬀt. Let a play
begins from a node u in W ′. If u is Player 0’s node then
Player 1 does nothing but just waits for the Player 0’s move
at u. Any choice of Player 0 selects a node in W ′. This is
because uE ⊆ W ′ as otherwise u would be in reach0(eﬀt).
If u ∈ V1 ∩ W ′, then there exists a node v ∈ W ′ such that
(u, v) ∈ E otherwise u would belong to eﬀt. We deﬁne
g(u) = v. Any play which begins from a node in W ′ and
consistent with this strategy g always stays inside W ′. Hence
g is a winning strategy for Player 1 from W ′ because W ′ ∩
T = ∅. Thus, W0 = eﬀt and V \ eﬀt = W1.
Note that the winning strategy f, for Player 0, extracted
from the classical algorithm that solves a reachability game,
remembers ranks of all the nodes in Attr0(T). That is, for
all u ∈ Attr0(T), f(u) = v, where v ∈ uE and rank of v is
strictly less than u. For all z ∈ V0\Attr0(T), f(z) is such that
(z, f(z)) ∈ E. Our new procedure for solving reachability
games suggests a winning strategy g that remembers only
nodes in
T ∪ reach0(eﬀ0) ∪ reach0(eﬀ1) ∪ reach0(eﬀ2) ∪ . . . .
We deﬁne g as follows. For all u ∈ X, g(u) = f(u), where
X = T ∪ reach0(eﬀ0) ∪ reach0(eﬀ1) ∪ reach0(eﬀ2) ∪ . . ..
For all z ∈ V0 \ X, f(z) is such that (z, f(z)) ∈ E. We
call this strategy, effort-based strategy . Thus, we obtain the
following theorem.
Theorem 4.5: Given a reachability game, there exists a
linear time algorithm that extracts an effort-based memory-
less winning strategy for the winner.
V. CONCLUSION
To win a reachability game, the classical algorithm remem-
bers ranks of all nodes of the arena. The winning region for
a player may contain nodes such that all their outgoing edges
lead to the winning region of the player and hence no effort is
involved by the player at such nodes. The region that contains
such nodes we called it effortless region. Our algorithm takes
effortless region into account and hence improved memory
efﬁciency. Moreover, the algorithm is memoryless and it
takes linear time on the number of nodes and edges of the
arena.
REFERENCES
[1] W. Thomas, ”Inﬁnite games and veriﬁcation,” Proc. Computer Aided
Veriﬁcation, LNCS 2404, Springer 2002, pp. 58–64.
[2] E. Gr¨adel, W. Thomas, and T. Wilke, ”Automata, logics, and inﬁnite
games: A guide to current research”, LNCS 2500, Springer, Heidel-
berg, 2002.
[3] L. Roditty, and U. Zwick, ”A fully dynamic reachability algorithm for
directed graphs with an almost linear update time”, Proc. 36th ACM
Symposium on Theory of Computing, 2004, pp. 184-191.
[4] B. Khoussainov, J. Liu, and I. Khaliq, ”A dynamic algorithm for reach-
ability games played on trees”, Proc. 24th International Symposium
of Mathematical Foundations of Computer Science, LNCS, vol. 5734,
2009, pp. 518-529.
[5] P. Hunter, ”Reachability in succinct one-counter games”, Proc. 9th
International Workshop on Reachability Problems, LNCS 9328, 2015,
pp. 37- 49.
[6] K, Chatterjee, L. Alfaro, and T. A. Henzinger, ”Strategy improvement
for concurrent reachability and turn-based stochastic safety games”,
Jouranl of Computer and System Sciences, vol. 79, issue 5, 2013, pp.
640 - 657.
[7] S. Dziembowski, M. Jurdzinski, and I. Walukiewicz, ”How much
memory is needed to win inﬁnite games”, Proc. 12th Annual IEEE
Symposium on Logic in Computer Science, Warsaw Poland, 1997 pp.
99 - 110.
[8] K. Chatterjee, T. Henzinger, and N. Piterman, ”Algorithms for buchi
games”, Proc. 3rd Workshop of Games in Design and Veriﬁcation,
2006.
[9] R. McNaughton, ”Inﬁnite games played on ﬁnite graphs”, Annals of
Pure and Applied Logic, vol. 65, pp. 149184, 1993.
[10] M. Huth, J. H. Kuo, and N. Piterman, ”Fatal attractors in Parity
games”, Proc. FoSSaCS, pp. 34 - 49, 2013.
[11] D. Gale, and F. Stewart, ”Inﬁnite games with perfect information.
Annals of Mathematical Studies (Contributions to the Theory of
Games II)”. vol. 28, 1953, pp. 245-266.
[12] D. Martin, ”Borel determinacy. Annals of Mathematics”, vol. 102,
1975, pp. 363-375.
132
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-458-9
SOFTENG 2016 : The Second International Conference on Advances and Trends in Software Engineering

