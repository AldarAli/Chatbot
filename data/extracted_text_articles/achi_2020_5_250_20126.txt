An Approach for the Visualization of Crafts and Machine Usage in Virtual 
Environments 
 
Evropi Stefanidi, Nikolaos Partarakis, Xenophon 
Zabulis 
Institute of Computer Science, Foundation for Research and 
Technology – Hellas (FORTH)  
Heraklion, Greece  
email: {evropi, partarak, zabulis}@ics.forth.gr 
 
George Papagiannakis 
Institute of Computer Science, Foundation for Research and 
Technology – Hellas (FORTH) & 
Department of Computer Science, University of Crete 
Heraklion, Greece  
email: papagian@ics.forth.gr
Abstract—Despite 
the 
cultural, 
societal, 
economic 
and 
traditional significance and value of Heritage Crafts and 
Intangible Cultural Heritage, efforts towards their digital 
representation and presentation, and subsequently their 
preservation, are scattered. To that end, this paper proposes an 
approach for their visualization in Virtual Environments, 
within which the practitioner is represented by a Virtual 
Human, their actions through animations resulting from 
Motion Capture recordings, and objects through their 3D 
reconstructions. Our novel approach is based on a conceptual, 
twofold decomposition of craft processes into actions, and of 
the machines used into components. Thus, in the context of this 
paper, we have developed a pipeline that delivers a Virtual 
Environment, through which a wide range of users, from 
museum curators and exhibitors, to everyday users interested 
by a craft, can experience craft usage scenarios. Via our 
visualization pipeline, we claim that we deliver an efficient way 
of visualizing craft processes within Virtual Environments, 
thus increasing the usability and educational value of craft 
representation, and opening the way to a variety of new 
applications for craft presentation, education and thematic 
tourism. In the scope of this paper, we focus on the Heritage 
Craft of loom weaving; however, our approach is generic, for 
representing any craft, after its decomposition according to 
our technique. 
Keywords-Machine Usage Visualization; Heritage Crafts; 
Cultural Heritage; Motion Capture; Virtual Humans. 
I. 
 INTRODUCTION 
Heritage Crafts (HCs) involve tangible craft artifacts, 
materials and tools, and encompass traditional craftsmanship 
as a form of Intangible Cultural Heritage (ICH). Intangible 
HC dimensions include dexterity, know-how, and skilled use 
of tools, as well as identity and traditions of the communities 
in which craftsmanship is, or was, practiced [1].   
Regarding their digitization, the advances in the 3D 
digitization of the shape and appearance of physical objects 
(3D reconstruction) have enabled the digital representation 
of tangible CH elements. The selection of a digitization 
modality and approach is central for accurate digitization, 
and is facilitated by guidelines focused on the Cultural 
Heritage domain [2]. In order to digitize not only the tangible 
elements of craft, but also the actions of the practitioner, the 
representation of the craft needs to include intangible 
dimensions.  
As a step towards digitizing and representing HCs, we 
propose a novel approach for their visualization in Virtual 
Environments (VEs), within which the practitioner is 
represented by a Virtual Human (VH), and objects through 
their 3D reconstructions. Practitioner actions are reproduced 
by animating the VH based on Motion Capture (MoCap) 
recordings. The appropriate simulation of VHs is an 
important aspect, since crafts are practiced by humans and 
machines are designed for use by them. At the center of the 
proposed approach is a conceptual, twofold decomposition 
of craft processes into actions, and of machines into 
components, which include their physical interface. This is 
essential in the systematic transfer of craft practice from the 
physical to the virtual domain, while retaining realism. In 
more detail, this decomposition must be meaningful to allow 
the semantic representation of craft processes. 
Using this approach, we claim that we could model a 
multitude of craft instances and machines, by decomposing 
crafts to simple motion driven operations, and machines to 
fundamental machine components. Thus, our contribution 
lies in a novel method for the presentation, representation 
and preservation of HCs, from which a multitude of user 
groups can benefit: (i) craftsmen whose work will be 
preserved and represented, (ii) local communities in which 
the craft is practiced, (iii) museum curators and exhibitors for 
the presentation of various traditional crafts and (iv) people 
without a specialization regarding Heritage Crafts, who are 
however interested in a HC and wish to learn more about it 
(e.g., tourists, teachers, school groups). 
 In the context of this paper, we focus on the craft of 
loom weaving, and describe the application of our pipeline 
and decomposition methodology on this craft. Nevertheless, 
our approach could be used for the representation of a variety 
of crafts, after their segmentation according to our technique. 
The rest of this paper is organized as follows. Section II 
presents a discussion of related work. Section III describes 
how we designed the transition of loom weaving from the 
physical to virtual world. Section IV addresses the details of 
the design and implementation of our approach, while 
Section V presents our conclusions and future work. The 
acknowledgement and references close the article. 
II. 
RELATED WORK 
To the best of our knowledge, there is no similar work 
regarding the digital representation of Heritage Crafts – or 
271
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

crafts in general - via the utilization of Virtual Humans, 
MoCap and 3D reconstruction; nor did we find other work 
that proposes the conceptual decomposition of crafts and 
machines used. Our approach is an extension of the work we 
conducted in [3], which presented a pipeline for the 
demonstration of tool usage for handicrafts and hand-held 
tools, to the world of HCs. In this paper, we take our 
research a step further, by focusing on HCs, and including all 
the steps that are needed, including interaction with 
craftsmen, in order to deliver a successful result for accurate 
representation of a HC. Therefore, in this section we present 
the related work we found regarding: (i) Virtual Humans and 
their use and importance in 3D applications, and (ii) tools for 
tool usage demonstration. 
With respect to VHs, they constitute an important aspect 
of 3D applications, since humans can familiarize themselves 
with human-like characters. They mainly play the role of 
narrators [4] and virtual audiences [5]. In the context of VEs, 
they have already been used for explaining physical and 
procedural human tasks [6], simulating dangerous situations 
[7], group and crowd behavior [8], and assisting users during 
navigation, by pointing relevant locations and positions and 
providing users with additional information [9]. They can 
also play the role of a tutor, acting as an embodied teacher, 
enabling an individualized instruction for a massive number 
of learners. In our approach, they are used to represent HC 
practitioners, by demonstrating craft processes. 
Regarding tool usage demonstration, M.A.G.E.S ™ [10] 
is a platform facilitating just that, by introducing an SDK for 
VR surgical training. It also includes a plugin for 
manipulation of tools in VR environments, which allows 
developers to transform any 3D model of a tool (pliers, 
hammer, scalpel, drills, etc.) into a fully functional and 
interactive asset, ready to use in VR applications. After the 
tool generation, users can interact with it in the VE and use it 
to complete specific tasks following recorded directions. 
Another tool is ExProtoVAR [11], which allows non-
technical users to generate interactive experiences in AR. 
With respect to the related work, we propose a novel 
approach that utilizes the concepts of Virtual Humans and 
demonstration of tools in VEs, but in the context of 
presenting and representing Heritage Crafts, so as to aid in 
their representation and preservation. To that end, we utilize 
3D reconstruction to digitize the machines and tools used for 
each craft, and MoCap recordings for the actions of the 
craftsmen. Moreover, we induce the motion of the tools and 
machines from the human motion, by applying mathematical 
formulas for the simulation of the tool motion, and for the 
correct attachment of the tools to the corresponding body 
parts which should use them. Our contribution also entails 
the segmentation of the craft process into its essential parts, 
and the decomposition of the machines used into basic parts 
which we call Fundamental Machine Components.   
III. 
DESIGNING THE TRANSITION OF LOOM WEAVING 
FROM THE PHYSICAL TO THE VIRTUAL WORLD 
The proposed design process for the representation of 
machines entails the conceptual decomposition of craft 
processes into actions and machine components. To facilitate 
presentation, the use case of loom weaving is considered.  
It is essential that craftspersons are centrally involved in 
the conceptual decomposition, to provide functional insight 
and emic understanding of the represented process. In this 
case study, we collaborated with the practitioner community 
of the Association of Friends of Haus der Seidenkultur 
(HdS), Krefeld, Germany [12] (Figure 1), within the context 
of the Mingei EU H2020 Innovation action [13]. HdS 
provided descriptions and testimonies and allowed us to 
record functional demonstrations (MoCap, Video) of the 
practitioners, so as to perform careful observation and 
analysis of the craft. At the same time, collaborative sessions 
enabled craft understanding and provided insight from the 
perspective of the practitioner, towards a meaningful 
decomposition. Context definitions for our use case were 
then created, which are provided below, and are visible in 
Figure 2. 
 
Figure 1.  Co-design session at HdS. 
 
Figure 2.  Loom components. 
Yarn is a continuous length of interlocked fibers, 
produced by spinning fibers into long strands. Warp and 
Weft are the horizontal and vertical threads of a fabric. 
Weaving is the process of yarn transformation to fabric; 
vertical warp threads (warps) are held in tension on a loom, 
while weft is perpendicularly interlaced, fastened in-between 
elevated (upper) and lowered (lower) warps. A loom is a 
piece 
of 
machinery 
that 
facilitates 
weaving. 
The 
configuration of upper and lower warps (or the weave of the 
fabric), determines the structure of the woven fabric. Shed is 
the space due to the temporary separation of upper and lower 
272
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

warps. A treadle is a loom lever that mechanizes shed 
creation. A shuttle is a device used to interlace weft through 
upper and lower warps. Finally, a beater is a tool used to 
fasten the weft to the warp. 
 
 
Figure 3.  Storyboard of the three stages of weaving and the machine parts 
involved. 
Central to the process is the loom machine, which retains 
warps at tension, to facilitate the thread-by-thread 
interlacement of weft through them. There are several types 
of looms. In the conventional loom, weft is introduced using 
a shuttle. Each thread of weft is fastened by a beat of the 
beater [14]. 
Regarding our approach, the weaving process was 
decomposed into 3 actions, repeated for each thread of weft 
[14]: (i) Shedding: warp threads are separated to form a shed, 
(ii) Picking: weft is passed across the shed using the shuttle, 
and (iii) Beating: weft is pushed against the fabric using the 
beater. The decomposed loom interface components are the 
shuttle, treadle and beater, depicted on the left side of Figure 
2. Initially, textual descriptions were created collaboratively 
for each action, which also identified the machine interface 
components and human body parts used to operate them. 
We thus developed an analytical way to visually and 
textually represent a process comprised of actions performed 
on objects and machine interface components. In this 
collaborative process, the need for a representation that is 
intuitive to the practitioner and analytical enough for a 
semantic representation of the process was identified. To that 
end, storyboards were selected as a methodological approach 
to address this need. The weaving process was encoded as a 
sequence of actions and reviewed by the community of 
practitioners, finally producing the storyboard visible in 
Figure 3. 
This decomposition of the weaving process contains the 
interplay between human motion and components of the 
physical interface of the machine. To meaningfully represent 
the machine interface, we decompose it in elementary 
components, called Fundamental Machine Components 
(FMCs). These FMCs are rigged 3D models enhanced with 
functionality that simulates their motion, as described in 
Table I. 
IV. 
DESIGN AND IMPLEMENTATION OF OUR APPROACH 
The proposed approach is generic towards the transfer of 
knowledge on machine usage to Virtual Environments. To 
that end, we segment the recordings of practitioners during 
machine usage into actions and categorize them by 
introducing them as items in a Motion Vocabulary (MV). At 
the same time, we decompose elements of the physical 
interface of Machines into FMCs. Thus, we call a Motion 
Vocabulary Item (MVI) an entity that represents an action, or 
part of an action, and contains a motion recording and 
possibly a reference to an FMC.  
The steps of the pipeline for the proposed approach are 
the following: 
 
Involvement of craftspersons in the conceptual 
decomposition, to provide functional insight and 
emic 
understanding 
of 
the 
process 
to 
be 
represented. 
 
Decomposition of machine interface components. 
 
Acquisition of machine 3D model.  
 
MoCap of operators using the machine. 
 
Implementation of a VH. 
 
Segmentation of MoCap recording into a MV. 
 
Retargeting of recorded motion to the VH operating 
a 3D model of the machine. While human motion is 
recorded in MoCap files, we do not have MoCaps 
for the FMCs, because it is simpler and more cost-
efficient to induce the machine motion by 
combining the mechanics of the FMC and the 
human motion from the MoCap. Moreover, in this 
way, we avoid the intervention and instrumentation 
of machines, which could alter their usage. 
 
Visualization of modeled process. 
 
The following sections present the implementation of the 
proposed approach for the case study of loom weaving. 
A. MoCap 
The motion of practitioners was recorded in MoCap 
animation files, using a NANSENSE R2 [15] motion capture 
suit, during MoCap sessions. 
B. Loom Model Acquisition 
Often the machine is extremely difficult to reconstruct, 
due to its placement in the constrained environments of 
workshops and museums. As this was the case with the 
looms we had at hand, we used a basic loom model found at 
[16] to demonstrate our approach. Of course, any 3D model 
of the machine could be used. 
C. Virtual Humans 
The VHs that reproduce the recorded actions are 3D 
Avatars. In this case study, the VH was created in Poser Pro 
11, and then imported to our development platform 
(Unity3D). 
273
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

TABLE I.  
DECOMPOSITION OF LOOM WEAVING INTO STEPS 
Steps 
Action 
Result 
Design of the FMCa 
Shedding 
Treadle is pressed by foot. 
Warp threads are separated, by the press 
of the treadle. 
 
Picking 
The shuttle is passed from one side to the other 
by hand. 
A row of weft is created by a pass of the 
shuttle. 
 
Battening 
The beater is dragged with force on the new 
warp. 
Weft row completed using the beater.  
 
a. In the figures, dashed lines plot the feasible induced motion trajectories. 
D. Motion Vocabulary 
The next step entails the decomposition of the process of 
loom weaving into actions. Thus, we edited the MoCap 
animation files, to correlate the motion segments (MVIs) to 
the conceptually decomposed actions. These segments are 
considered building blocks of the weaving MV, which is the 
basis of sequences, or “sentences”, encoding weaving 
processes. 
E. Loom Machine Abstraction 
We then proceeded with defining the elements of the 
physical interface of the loom as FMCs. Each one is 
comprised of (i) a 3D model of a machine part, and (ii) 
motion rules that represent the feasible, induced motion of 
the FMC during its operation. 
F. Association of Virtual Humans and FMCs 
Machine interface components, represented as FMCs, are 
associated with the VH body part(s) that are used for their 
operation (e.g., treadle with foot, shuttle with hand, beater 
with both hands). We first establish a pairing between the 
FMC and a point on the Avatar. Subsequently, the preferred 
grip posture is defined. For this purpose, we employ the 
following entities: 
 
Avatar A, with skeleton S, is comprised of joints 
and skin T. Skin T is a, possibly textured, 
deformable 3D surface, represented by a mesh of 
triangles. When A is animated, T deforms according 
to the motion of S. 
 
Two grip points, gL, gR on T encode the grip center 
for the left and right hand respectively. These points 
are selected with respect to the FMC, as objects 
may not always be held in the same way. 
 
Each hand has a reference frame based on 
orthogonal unit vectors. These are 
, 
,
, for the 
left and 
, 
,
 for the right. The center of the 
frame is selected at an anatomically meaningful 
location. 
 
An FMC has a reference frame based on 
, 
,
, 
which are orthogonal unit vectors for the FMC. 
Each FMC is centered at its centroid. 
 
The FMC has a preferred usage position (e.g., grip, 
foot position). This position may not be unique. 
 
A posture p is comprised of (i) a configuration of 
the joints of A, (ii) a preferred location and (iii) 
orientation of A’s body members, for FMC usage. 
 
An animation is a transition from a posture to 
another, represented by a sequence of states of the 
A’s joints.  
A preemptive posture is the preferred for A posture at the 
first moment of the FMC usage. A preemptive animation is 
an animation that brings A to the preemptive posture. 
For our case study, we define the following concepts: 
 
Loom L is represented by a mesh of triangles, 
encoded by its vertices, lv, and its triangles, lt. 
 
TRE, BEA, SHU are FMCs for the treadle, beater 
and shuttle, respectively. 
 
Points bL and bR on the BEA, denote the grip 
locations of the left and right hands. 
 
Animations pL and pR, for preemptive usage 
postures for the BEA, for the left and right hand.  
 
Preemptive usage animations fL and fR for the 
placement of the left and right feet on TRE.  
 
Point da on TRE at the center of the area that the 
foot is pressing on the treadle. Preemptive usage 
postures sL, and sR encode shuttle grip by the left 
and right hand. 
 
Point us on SHU (shuttle centroid).  
 
MV for Loom Weaving MVLW contains MVITRE, 
MVIBEA and MVISHU which are the treadle, beater 
and shuttle animations (encoding human motion but 
not machine motion): 
o 
MVITRE: treadle pushed down and released.  
o 
MVISHU: shuttle pushed from left to the 
right and vice versa. 
o 
MVIBEA: beater pulled towards the operator 
for a beat, then pushed away. 
274
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

 
Animation function AN(A/FMC, Posture) which 
animates either the A or FMC according to a MVI. 
A scene is the VE where the A, FMCs and objects are 
instantiated, and the FMCs, L, and A are brought to the 
reference frame of the scene. This is achieved by appropriate 
rotation R (encoded as a 3x3 rotation matrix), a translation t 
(encoded as a 3x1 matrix) and a scaling s transformation for 
each component, once and prior to their import in the VE. 
Each 3D point, let q, of the object’s 3D model undergoes 
transformation R* sq + t, where * denotes matrix 
multiplication. The transformations are individual for each of 
the FMCs, loom and A, and are denoted as RT, sT, tT for the 
treadle, RS, sS, tS for the shuttle etc. 
G. Induced Machine Motion 
Induced machine motion was simulated as follows: 
1) Principle of induced motion.  
Let avatar A at the preemptive usage posture of an FMC. We 
consider the execution of a MVI by A, during a time interval. 
The motion of the FMC due to the MVI is called Induced 
Motion of the FMC. We propose a synchronization method 
of the FMC’s motion with that of the VH for each MVI, 
based on the feasible induced motion trajectory of the FMC. 
 
 
Figure 4.  Visualization of the foot pressing the treadle. 
2) Treadle Motion. 
Treadle motion is performed by execution of MVITRE and 
denoted as AN(A, MVITRE). The treadle is moved when the 
bounding box of the TRE collides with the foot of the 
Avatar. The virtual motion is achieved through a function 
TRE’=AN(TRE, MVITRE’), where MVITRE’ contains the 
projections of MVITRE to the motion trajectory of TRE 
(Figure 4). 
 
Figure 5.  Attaching the hands on the beater. 
3) Beater Motion. 
The preferred posture of A’s hands is reached by 
animating A using a preemptive animation, so that 
A’=AN(A,pL), A’=AN(A,pR). Hand motion is performed by 
MVIBEA’ through function A’=AN(A, MVIBEA’) and loom 
motion through L’=AN(L, MVIBEA’), where MVIBEA’ contains 
the projections of the grip points to the motion trajectory of 
BEA (Figure 5). 
4) Shuttle Motion. 
Shuttle motion MVISHU is simulated through function 
A’=AN(A, MVISHU), while the attachment of the shuttle to 
each of the hands of the Avatar is performed by A’=AN(A’, 
sL) and A’=AN(A’, sR) for the left and right hands 
respectively (shuttle is exchanged between the hands) 
(Figure 6). The motion of the shuttle is represented as 
L’=AN(L, MVISHU’), where MVISHU’ is modeled as a constant 
linear motion, between the starting point of the SHU feasible 
induced motion trajectory and its ending point, and vice 
versa. 
 
  
Figure 6.  Attaching the hands on the shuttle. 
 
Figure 7.  Visualization of the result: the VH is operating the loom. 
V. 
CONCLUSION  
This work presented a novel approach for the 
representation of machine usage by Virtual Humans in 
Virtual Environments and described its implementation for 
the case of loom weaving. Resulting from our pipeline, the 
visualization of an Avatar using the loom are visible in 
Figures 7 and 8, with Figure 8 focusing on the treadle 
operation. The proposed approach allows for further 
configurations to facilitate the representation of other crafts 
including machine usage. 
The application of our approach on the craft of loom 
weaving allowed us to have an initial validation of our 
pipeline, in the context of the described experiment; 
however, it is imperative, and part of our immediate future 
plans, to conduct an evaluation with craft experts, to have 
their verification. Subsequently, and after any necessary 
changes stemming from their feedback, we will evaluate our 
system with users from various target user groups, such as 
275
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

museum curators, exhibitors and non-craftspeople, such as 
tourists. Finally, we aim to further generalize our approach, 
by including new Fundamental Machine Components in our 
framework and studying new crafts and techniques.  
The genericity of the approach stems from the reusability 
of the main components of the proposed pipeline. Motion 
Capture technologies can be used to record any human 
operation involving the usage of tools and/or machines. 
Furthermore, our approach of decomposing a machine in 
Fundamental Machine Components allows us to define 
different components used in different operations to achieve 
different results. The binding of such components with 
process-specific knowledge adds to the novelty and 
reusability of our approach. 
 
 
Figure 8.  Detail of the foot of the VH operating the treadle while loom 
weaving. 
As a second use case where the proposed approach is 
being applied, efforts are already being put towards 
representing the hand-based craft of mastic cultivation, 
practiced in the island of Chios, Greece, utilizing the pipeline 
described in this paper. Namely, after having performed 
Motion Capture of the mastic cultivators’ movements, we are 
now in the process of segmenting the actions in their 
elementary parts, as well as digitizing the tools used with 
their corresponding motions. The overarching goal is the 
capability to represent and present a plethora of crafts, thus 
contributing to Heritage Craft presentation, representation 
and valorization. At the same time, our proposed pipeline 
presents opportunities for use cases that go beyond the field 
of Cultural Heritage, as it could be used to model various 
handicraft actions, e.g., using garden tools or assembling 
furniture, by decomposing them into their fundamental 
actions and components, according to our methodology. 
 
ACKNOWLEDGMENT 
This work has been supported by the EU Horizon 2020 
Innovation Action under grant agreement No. 822336 
(Mingei); the authors are grateful to project partner 
ARMINES for the acquisition of MoCap data and the 
practitioner community of the Association of Friends of 
Haus der Seidenkultur (HdS), Krefeld, Germany for their 
collaboration and support on understanding the craft of loom 
weaving. 
REFERENCES 
 
[1]  UNESCO, “Text of the Convention for the Safeguarding of the 
Intangible Cultural Heritage,” UNESCO Paris, 17 October 2003, 
2003. 
[2] 
“3D-ICONS, ‘Guidelines & Case Studies,’”. 3D-ICONS is a project 
funded under the European Commission’s ICT Policy Support 
Programme, project no. 297194. 2014. 
[3] 
E. Stefanidi et al., “TooltY: An approach for the combination of 
motion capture and 3D reconstruction to present tool usage in 3D 
environments,” in Intelligent Scene Modelling and Human Computer 
Interaction, N. M. Thalmann, J. Zhang, and J. Zheng, Eds. Springer, 
in press. 
[4] 
P. Zikas et al., “Mixed reality serious games and gamification for 
smart education,” in European Conference on Games Based 
Learning, 2016, p. 805. 
[5] 
M. Chollet, N. Chandrashekhar, A. Shapiro, L.-P. Morency, and S. 
Scherer, “Manipulating the perception of virtual audiences using 
crowdsourced behaviors,” in International Conference on Intelligent 
Virtual Agents, 2016, pp. 164–174. 
[6] 
J. Rickel and W. L. Johnson, “Animated agents for procedural 
training in virtual reality: Perception, cognition, and motor control,” 
Applied artificial intelligence, vol. 13, no. 4–5, pp. 343–382, 1999. 
[7] 
D. Traum and J. Rickel, “Embodied agents for multi-party dialogue in 
immersive virtual worlds,” in Proceedings of the first international 
joint conference on Autonomous agents and multiagent systems: part 
2, 2002, pp. 766–773. 
[8] 
Z. Paul, P. Margarita, M. Vasilis, and P. George, “Life-sized Group 
and Crowd simulation in Mobile AR,” in Proceedings of the 29th 
International Conference on Computer Animation and Social Agents, 
2016, pp. 79–82. 
[9] 
L. Chittaro, R. Ranon, and L. Ieronutti, “Guiding visitors of Web3D 
worlds through automatically generated tours,” in Proceedings of the 
eighth international conference on 3D Web technology, 2003, pp. 27–
38. 
[10] G. Papagiannakis, N. Lydatakis, S. Kateros, S. Georgiou, and P. 
Zikas, “Transforming medical education and training with VR using 
MAGES,” in SIGGRAPH Asia 2018 Posters, 2018, p. 83. 
[11] N. Pfeiffer-Leßmann and T. Pfeiffer, “ExProtoVAR: A Lightweight 
Tool for Experience-Focused Prototyping of Augmented Reality 
Applications Using Virtual Reality,” in International Conference on 
Human-Computer Interaction, 2018, pp. 311–318. 
[12] “Welcome to the ‘Haus der Seidenkultur’, Krefeld.” [Online]. 
Available: https://seidenkultur.de/. [Retrieved: Jan, 2020]. 
[13] “The Mingei project.” [Online]. Available: http://www.mingei-
project.eu/. [Retrieved: Jan, 2020]. 
[14] A. Albers and N. F. Weber, On Weaving: New Expanded Edition. 
Princeton University Press, 2017. 
[15] “Nansense - Professional Inertial Motion Capture Systems.” [Online]. 
Available: https://www.nansense.com/. [Retrieved: Jan, 2020]. 
[16] B. 
L, 
“Counterbalance 
Loom.” 
[Online]. 
Available: 
https://3dwarehouse.sketchup.com/model/a4d5115a90e3f5534cf6cee
9a1fdf035/Counterbalance-Loom. [Retrieved: Jan, 2020]. 
 
276
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

