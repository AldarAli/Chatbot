Projection-Based Inter-Agent Collision Avoidance in Dual Agent
Systems
Vinod P. Gehlot and Mark J. Balas
Mechanical Engineering Department
Texas A&M University, College Station, Texas 77843, USA
email: {vinodgehlot, mbalas}@tamu.edu
Saptarshi Bandyopadhyay, Marco B. Quadrelli, and David S. Bayard
Jet Propulsion Laboratory
California Institute of Technology, Pasadena, California 91125, USA
email: {saptarshi.bandyopadhyay, marco.b.quadrelli, david.s.bayard}@jpl.nasa.gov
Abstract— Inter-agent
collisions
can
occur
in
otherwise
dynamically-stable (i.e., Lyapunov stable) dual-agent leader-
follower systems. These inter-agent collisions between the leader
and the follower happen during the transient phase of the
system’s evolution, although the steady-state behavior of the
system is asymptotically/exponentially stable. Therefore, to
avoid such inter-agent collisions, it is essential to control the
relative error trajectory between the leader and the follower
during the transient phase of the system’s evolution. In this
paper, we introduce a novel projection operator based model-
reference control architecture that can mitigate impending
inter-agent collisions by modifying the transient dynamics of
relative trajectories. This controller augments the follower’s
baseline controller and consists of two essential components: a
collision-free reference model based on the projection operator
and a model reference tracking controller to guide the follower
to follow the reference-model. This paper deﬁnes the concept
of transient-instability in leader-follower systems, introduces
collision mitigation controller architecture, and presents an
illustrative example demonstrating its effectiveness.
Keywords— Inter-agent collision avoidance; Collision mitiga-
tion; Multi-agent systems; Swarms; Interconnected systems;
Motion planning; Projection operator.
I. INTRODUCTION
In a dual agent leader-follower system, the leader is an
independent entity; and the follower, as the name suggests,
follows the leader at a speciﬁed separation distance. Relative
position vectors and their associated dynamics are fundamen-
tal to the leader-follower formation maintenance. Therefore,
the dynamic stability of the relative error dynamics is of
paramount importance. We begin our discussion by intro-
ducing the mathematical preliminaries of dual agent leader-
follower systems.
In the ﬁgure below, there are two identical agents — linear
time-invariant (LTI) systems — identiﬁed by their indices
1, and 2, and their corresponding state vectors x1, and x2,
respectively. They are in a leader-follower arrangement, with
agent 1 as the leader, and agent 2 as the follower.
The trajectories of the agents evolve according to the
dynamics deﬁned in (1). Here, i ∈ I = {1, 2}, is the index
of the two agents, xi is the state vector of the agents that
1
2
Fig. 1.
Two Agent Leader-Follower Formation
evolves in the n−dimensional state space X ⊆ Rn, ui ∈
U ⊆ Rm, and yi ∈ Y ⊆ Rp are the m−dimensional input
and p−dimensional output vectors of the agents, respectively.
The tuple (A, B, C) are the set of appropriately sized matri-
ces that model the system dynamics.
˙xi = Axi + Bui
(1a)
yi = Cxi
(1b)
Although not necessary, assume that in (1), the matrix A
has at least a one-dimensional null space. This assumption
allows for the arbitrary assignment of constraints on a partial
set of an agent’s state vector; without the use of a constant
control effort.
In this formation, agent 1 is an independent entity, and
agent 2, the follower, does not affect its dynamics. Agent 2
merely tracks agent 1 and maintains a spatial separation of
d2 ∈ X using the control law
u2 = G (y1 − y2 − Cd2) = GCξ2.
(2)
Here, ξ2 ≡ x1 − x2 − d2 ∈ Rn is the relative error as
measured from agent 2, and G ∈ Rm×p is a stable closed
loop gain matrix that drives the relative error trajectory
ξ2(t) → 0 as t → ∞. Note that d2 is a vector quantity, and it
resides in the null space of the system matrix A (d ∈ ker(A)),
therefore, it can include many more constraints besides
distance. Equation (3) is the relative error dynamics of the
two agent formation, and a suitable value of the gain matrix
G will render the closed loop matrix AC ≡ (A − BGC)
Hurwitz, thereby meeting the formation control objective.
We say that agent 2 is “looking” at agent 1 when it takes
control actions based on its sensor observation of agent 1 —
like in (2).
˙ξ2 = (A − BGC)ξ2 + Bu1
(3)
72
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

The two agent formation discussed thus far is quite
common in many applications, and it sets the stage for
discussion on transient stability in this paper. Examples of
the formation just described include adaptive cruise control
in vehicles, autonomous convoy or platooning, autonomous
mid-air refueling, and formation ﬂying spacecraft among
others. Whatever the application may be, it is important to
ensure that the dynamics in (3) are dynamically stable (i.e.
Lyapunov stable). In our previous work [1]–[3], we explored
the stability and adaptive control of several general formation
geometries with large number of agents and arbitrary net-
work topologies. In this paper, we use the two-agent leader-
follower formation from Figure 1 to introduce the concept of
transient instability in leader-follower systems, and a novel
control architecture that mitigates transient stabilities. We
deﬁne transient instability for the leader-follower formation
as follows:
Deﬁnition 1.1 (Transient Stability): The dynamics of a
two agent leader-follower formation is transient-stable if the
relative error trajectory ξ2(t) → 0 as t → ∞, and
∥ξ2(t)∥ ≤ ξmax
2
≡ (1 − α)∥d2∥,
(4)
for all t ∈ R+. The scalar α ∈ [0, 1) describes a safety
perimeter around agent 2.
In other words, we say that the two agent system is
transient-stable if 1) the relative error trajectory is asymp-
totically stable, and 2) the agent trajectories evolve collision
free. The problem of collision avoidance in formation and
swarms is a thoroughly studied subject in the control and
robotics literature, but many questions, particularly that of
transient stability, still remain unanswered.
When it comes to collision avoidance algorithms in au-
tonomous systems, the paper by Ames et. al [4] is notewor-
thy. They present a control barrier function based Quadratic
Programming (QP) algorithm, that the follower continu-
ously executes to generate collision free trajectories, all the
while meeting asymptotic stability of the relative trajecto-
ries. And, since the control inputs are generated optimally,
we know that the trajectories will be unique. The recent
survey by Rossi et. al [5] offers comprehensive outlook
on the current state-of-the-art multi-agent coordination and
control algorithms. Based on this survey, the vast array of
coordination and control algorithms can be classiﬁed into
two broad categories: predictive and reactive algorithms.
In predictive algorithms, optimization based path planning
algorithms determine collision free trajectories for the agents
to follow. Well known predictive algorithms include Optimal
Reciprocal Collision Avoidance (ORCA), and Model Pre-
dictive Control and Sequential Convex Programming (MPC-
SCP). Reactive algorithms, on the other hand, accomplish
collision avoidance on an ad-hoc basis; when a safety-
perimeter violation occurs, imminent collision is avoided by
recomputing the motion planning algorithm. Voronoi-based
[6], and Artiﬁcial Potential Functions (APF) [7] are two
examples of reactive algorithms. With regards to stability,
predictive algorithms, in general, can guarantee asymptotic
stability but not collision avoidance, and reactive algorithms,
Fig. 2.
Projection Operator in Action
can guarantee collision avoidance, but not asymptotic stabil-
ity. It is worth mentioning that no algorithm mentioned in
[5] can guarantee transient-stability.
Unlike the methods thus described, in this paper, we
introduce a smooth, Lipschitz continuous method for col-
lision avoidance that does not require the controller to solve
optimization problems continuously in realtime. Moreover,
this approach can satisfy dynamic stability and collision
avoidance simultaneously. In the proposed method, we in-
troduce a novel reference model for the follower that uses
the projection operator to modify the drift vector ﬁeld (A −
BGC)ξ2 + Bu1 in (3) of the relative error vector ξ2(t) to
generate transient-stable relative trajectories. Since directly
differentiating ξ2(t) can induce unwanted noise into the
feedback loop, we instead propose a Luenberger estimator
of the form
˙ˆξ2 = (A − BGC)ˆξ2 + L(ˆy2 − y2)
(5a)
ˆy2 = C ˆξ2
(5b)
to generate an estimate of the drift vector ﬁeld in (3).
This estimator is embedded within the projection operator
to form the reference model, thereby generating relative
error trajectories that satisfy the constraint (4). Finally, we
augment the baseline control law in (2) with a type-1 track-
ing control law that tracks the transient stable trajectories
generated by the reference model. It is the combination of
the reference model, the reference model tracking controller,
and the baseline relative error regulator that ensures transient
stability in Deﬁnition 1.1. Figure 3 shows the proposed
control methodology. We present our results in three sections.
In Section II, we introduce the fundamentals of the projec-
tion operator and a few essential results without proof. In
Section III, we introduce the transient instability mitigation
architecture and discuss its various components, and present
the main theoretical results. Finally, in Section IV, we use an
illustrative example to demonstrate the effectiveness of the
collision mitigation strategy presented in this paper.
II. THE PROJECTION OPERATOR
The projection operator is among several methods in the
convex analysis that can solve constrained convex optimiza-
tion problems. In gradient descent iterations, the projection
operator projects the gradient of the cost function onto the
constraint manifold, limiting the solution to the convex set
deﬁned by the constraints. According to [8], Kreisselmeier
and Narendra [9] were the ﬁrst to use the projection operator
to bound time-varying gains in adaptive control systems. And
since then, it has been hugely popular in several adaptive
73
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

control algorithms [10] [8] [11]. Let θ ∈ Rn be a state
vector that evolves according to
˙θ(t) = g(θ),
(6)
and suppose that we want the trajectory θ(t) to stay within a
convex set with the boundary f(θ) = c. We can accomplish
this by constraining the dynamics in (6) with the projection
operator dynamics
˙θ(t) = Proj(θ, g(θ))
=
(
I − ∇f(∇f)T
∥∇f∥2 f(θ)

g(θ)
if f > 0 and θT ∇f > 0
g(θ)
otherwise.
(7)
The modiﬁcation of the dynamics in (6) by (7) guarantees
that θ(t)’s trajectory will stay within the convex set
Θ = {θ ∈ Rn : f(θ) ≤ 0}.
(8)
The projection operator achieves this by subtracting from the
drift vector ﬁeld g(θ), the component of g(θ) that is parallel
to the gradient vector ∇f(θ) (see Figure 2). Therefore, drift
vector Proj(θ, g(θ)) lies on the tangent plane TθM, where
M = {θ : f(θ) = c} is the constraint manifold. The
following is a signiﬁcant lemma that is useful in stability
proofs involving the projection operator.
Lemma 2.1 (Projection Inequality): Let θ∗ be point in the
interior of the convex set Θ, and let Γ > 0 be some positive
deﬁnite and symmetric matrix, then for any other θ(t) ∈ Θ,
(θ − θ∗)T 
transient stability criterion in Deﬁnition 1.1. ε > 0 is a scalar
that creates a smooth boundary by deﬁning two concentric
convex sets
Ω0 ≡ {ˆξ2 ∈ Rn : ∥ˆξ2∥ ≤ ∥ξmax
2
∥
√1 + ε}, and
(14a)
Ω1 ≡ {ˆξ2 ∈ Rn : ∥ˆξ2∥ ≤ ∥ˆξmax
2
∥}.
(14b)
From Lemma 11.4 in [8], for any trajectory ˆξ2(ti) = ˆξti ∈
Ω0, the projection operator guarantees that for all t > ti,
ˆξ2(t) ∈ Ω1. Hence, the estimated state vector ˆξ2(t) satisﬁes
the transient characteristics and generates CF trajectories.
Moreover, in the following result, we show that even though
the estimator dynamics are enclosed within the projection
dynamics, the estimated state ˆξ2(t) exponentially converges
to the actual state vector ξ2(t).
Theorem 3.1 (Collision Free Estimator Stability): The
error trajectory e(t) ≡ ˆξ2 − ξ2, of the estimator dynamics
˙ˆξ2 = Γ−1Proj(ˆξ2, Γh(ˆξ2, y2, ua2))
ˆy2 = C ˆξ2,
(15)
with h(ˆξ2, ua2, y2) ≡ Ac ˆξ2 −Bua2 +L(ˆy2 −y), is exponen-
tially stable.
Proof: For notational convinence, let z ≡ (ˆξ2, y2, ua2).
Taking the time derivative of e(t), we have
˙e(t) = ˙ˆξ2(t) − ˙ξ2(t)
= Γ−1Proj(ˆξ2, Γh(z)) − h(z) + (Ac + LC)e.
Let V (e) be the positive deﬁnite and decresent Lyapunov
function associated with the estimator error trajectory e(t),
and deﬁned by
λmin(Γ)∥e∥2 ≤ V (e) ≡ 1
2eT Γe ≤ λmax(Γ)∥e∥2.
By taking the time derivative of V (e) and using Lemma 2.1,
we obtain
˙V (e) = eT Γ˙e
= eT Γ

Γ−1Proj(ˆξ2, Γh(z)) − h(z)

|
{z
}
≤0
+ eT Γ(Ac + LC)e
≤ eT Γ(Ac + LC)e.
The closed-loop estimator matrix Ac + LC is Hurwitz,
therefore, for a given Q > 0, there exists a matrix Γ > 0
that solves the Lyapunov matrix equation
Γ(Ac + LC) + (Ac + LC)T Γ = −Q.
Therefore,
˙V (e) ≤ −1
2eT Qe ≤ −1
2λmin(Q)∥e∥2 ≤ − λmin(Q)
2λmax(Γ)
|
{z
}
=µ
V (e)
⇒ ˙V (e) + µV (e) ≤ 0.
Using the integrating factor eµt, we have
Z τ
0
eµt( ˙V + µV ) ≤
Z τ
0
eµt 0 ⇒ V (e(τ)) ≤ e−µτV (0)
Further,
V (0) ≤ λmax(Γ)∥e(0)∥2, and
p
λmin(Q) ∥e(τ)∥ ≤ V
1
2 (e(τ)) ≤ e−(µ/2)τ V
1
2 (0).
Therefore,
∥e(τ)∥ ≤
s
λmax(Γ)
λmin(Γ)
|
{z
}
=K0
e−(µ/2)τ ∥e(0)∥ = K0e−(µ/2)τ∥e(0)∥
The CF tracker subsystem generates the input vector ua2
so that the follower can track the transient stable relative error
trajectories produced by the CF estimator. Fundamentally,
the CF tracker is a servomechanism problem, and there are
several options for its structure. A PID/LQR controller based
type-1 tracker is a perfectly reasonable option. With a view
on applying the CF tracker/estimator to more extensive and
complex swarms, we opt for an output-feedback model-
reference based tracking architecture. A model-reference
based approach can readily accept time-varying adaptive
gains, which allows for the automation of gain determination
in complex formation structures.
Assumption: The output state vector ˆξ2(t) of the CF
estimator can be expressed as a linear combination of basis
vectors φi(t) with some coefﬁcient matrix L.
With this assumption, we can write the CF estimator
output in the command generator form
ˆξ2(t) = Lφ(t)
ˆy2 = C ˆξ2(t)
(16)
where, φ(t) = (φ1(t), . . . , φp(t))T , is a column vector of
tracking signal basis functions. According to [13], (16) is
equivalent to the dynamical system
˙η(t) = Fη(t)
ˆy2 = Cη(t).
(17)
The following result is the stability proof of the CF tracker
subsystem based on the output-feedback model-reference
tracking controller.
Theorem 3.2 (Reference Model Tracking): The
follower
LTI system
˙x2 = Ax2 + Bu2
(18a)
y2 = C(x1 − x2 − d2) = Cξ2,
(18b)
with the tracking control law
ua2 = Ge(y2 − ˆy2) + S2ˆy2,
(19)
75
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

for appropriately sized gain matrices Ge, and S2, will track
the command generator reference (CGR) system
ˆξ2(t) = Lφ(t)
(20a)
ˆy2 = C ˆξ2(t),
(20b)
such that, both the output relative error vector ey(t) ≡
ˆy2(t)−y2(t), and the error between the relative error vectors
e(t) ≡ ˆξ2(t) − ξ2(t), are driven to the origin exponentially.
Provided, the transmission zeros and the poles of the relative
error dynamics ξ2(t) are distinct.
Proof: Let ξ∗
2, u∗
2, and y∗
2, be the ideal trajectory, ideal
inputs, and ideal output, respectively. The ideal trajectory,
and its associated vectors evolve according to the dynamics
˙ξ∗
2 = Acξ∗
2 + Bu∗
2
(21a)
y∗
2 = Cξ∗
2 = ˆy2.
(21b)
That is, the ideal trajectory ξ∗
2 evolves so that it tracks the
CGR system output exactly. Let S be a matrix that relates
the ideal trajectories to the CGR system, deﬁned by
ξ∗
2
u∗
i

= S
ˆy2
0

=
S11
S12
S21
S22
 ˆy2
0

.
(22)
The CGR system can also be expressed in the form of an
equivalent LTI system
˙η(t) = Fη(t)
(23a)
ˆy2 = Cη(t)
(23b)
Using (21), and (23), and taking the time derivative of (22),
we have matrix equations
(AcS11 − BS21)C = S11CF
(24a)
CS11 = I,
(24b)
which are the matching conditions for the tracking problem.
The implementation of the tracking control law requires the
solution to the matrices S11 and S21. According to [14], the
solution to the matrices S11 and S21 exists, provided the
transmission zeros of the reference model, and the poles of
the plant are distinct, which by assumption is true. We now
deﬁne the tracking error ∆ξ2 ≡ ξ∗
2 − ξ2. Taking its time
derivative, we have
∆ ˙ξ2 = Ac∆ξ2 − B∆ua2
(25a)
∆y2 = C(ξ∗
2 − ξ2) = y∗
2 − y2 = ˆy2 − y2,
(25b)
where, ∆ua2 = u∗
a2 − ua2. Let ∆ua2 = Ge∆y, so that, the
closed-loop tracking error system
∆ ˙ξ2 = (Ac − BGeC)∆ξ2 = ˜Ac∆ξ2
(26a)
∆y2 = C∆ξ2
(26b)
is exponentially stable. Therefore, ∆ξ2 → 0 as t → ∞,
which implies ξ2(t) → ˆξ2(t) as t → ∞. Also, since
∆ua2 = Ge∆y
⇒ u∗
a2 − ua2 = Ge(ˆy2 − y2)
⇒ ua2 = Ge(y2 − ˆy2) + S21ˆy2
The proposed CF tracking controller tracks the collision-free
trajectory generated by the CF estimator. But, only if the
follower dynamics are deterministic. In practice, an adaptive
control law would determine the gain matrices Ge and S21,
which would result in robust tracking performance similar or
better to that of integral action in type-1 servomechanisms.
IV. SIMULATION RESULT
We use the two simulation runs: Run 1 with CF tracker
disabled, and Run 2 with CF tracker enabled, to demonstrate
the functioning, and also highlight a few limitations of the
CF estimator and tracker subsystem. For the two simulation
runs, the leader and follower are double integrator agents
with the model ¨x = u. The leader and the follower initially
rest at their speciﬁed separation of 5 meters. After a speciﬁed
time of about 20 seconds, a position and velocity disturbance
is applied to the leader using the input vector ud, as shown in
Figure 5. ˙x1 = Ax1+Bu1+ud is the structure of the leader’s
dynamics with the disturbance vector input ud. In Figures 6
and 7, the solid horizontal lines named Relative Error Upper
limit, and Relative Error Lower limit, reﬂect the relative error
bounds in (3). The dashed lines represent the beginning of the
soft constraint boundary for the projection operator; the esti-
mates from the projection operator are allowed to exceed the
soft boundary temporarily. Figure 4 shows timed sequence
of the leader and follower positions for the two simulation
runs. Stiffness in the Ordinary Differential Equations (ODEs)
can arise from the projection-based dynamics in the follower
reference model, and it can lead to slow convergence when
using popular explicit ODE solvers such as the Dormand-
Prince RK5(4) [15]; usually, an implicit solver is a better
solution. For the simulation runs in this paper, we used the
LSODA solver (which is roughly equivalent to ode15s in
MATLAB) from SciPy [16], which is a scientiﬁc library for
Python, and it can automatically switch between implicit and
explicit methods to handle stiff ODEs.
Figure 6 shows the results for the simulation run with the
CF tracker turned off. There are two important outcomes.
First, as expected, the relative error trajectory violates the
upper and lower limits for collision avoidance. Second, the
CF estimator generated trajectory saturates and never exceeds
the transient stability bounds. However, when the actual
relative error is within the bounds, the estimator perfectly
tracks the actual trajectory. The outcomes of this simulation
demonstrate the predictions of Theorem 3.1.
Figure 7 shows the results for the simulation run with
the CF tracker turned on. Right away, we see that both
the true and the estimated relative trajectories never exceed
the transient instability bound; therefore, no collisions occur.
Since the CF estimator on the follower does not have access
to the leader’s input information, whenever the vector ud is
non-zero, a near constant bias/DC component exists between
the actual and estimated relative trajectories. The magnitude
of the disturbance vector components is deliberately limited
to 2 [m] or [m/s]. If the magnitude of the disturbance is any
higher, the bias between the actual and estimated trajectories
76
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

increases and degrades the tracking performance, which can
result in inter-agent collisions. It can be shown that the
sharing of control information (i.e., u1(t)) from the leader
to the follower will resolve the aforementioned issues.
-20
-10
0
x-position [m]
0
5
10
15
20
25
30
Time [s]
Collision Tracking
Off
-20
-10
0
x-position [m]
Collision Tracking
On
Collision
Occurs 
Projection
Estimator
+Tracking 
Thwarts
Collision
Fig. 4.
Sequences of Leader-Follower Motion from Simulation Runs
0
20
40
60
80
100
Time [s]
-2
0
2
position and velocity
dist. [m] or [m/s]
position (u
d
p)
velocity (u
d
v )
Fig. 5.
Leader Disturbance Vector
0
20
40
60
80
100
Time [s]
-10
0
10
Relative Position Error
[m], 
2 = x 1 - x 2 - d
Relative Error Upper Limit
Relative Error Lower Limit
True
Estimated
Fig. 6.
Follower Trajectory with Tracking Off
0
20
40
60
80
100
Time [s]
-10
0
10
Relative Position Error
[m], 
2 = x 1 - x 2 - d
Relative Error Upper Limit
Relative Error Lower Limit
True
Estimated
Fig. 7.
Follower Trajectory with Tracking On
V. CONCLUSION
We have developed a novel controller architecture that
addresses the problem of transient instabilities in dual-agent
formations. We also presented the preliminary theoretical
results on the stability of the collision-free estimator and the
tracker subsystems. The proposed controller is particularly
attractive due to its simplicity and its ability to guarantee
both dynamic and transient stability. Future work will focus
on 1) developing a comprehensive analytical framework that
will investigate robustness to external noise and disturbances.
And 2) on generalizing the architecture to larger and more
complex formation structures.
ACKNOWLEDGMENT
Part of this research was carried out at the Jet Propulsion
Laboratory, California Institute of Technology, under a con-
tract with the National Aeronautics and Space Administra-
tion. ©2020 California Institute of Technology. Government
sponsorship acknowledged.
REFERENCES
[1] V. P. Gehlot and M. J. Balas, “An evolving systems approach to the
stable operation of dynamic formations and swarms of autonomous
vehicles in a disruptive environment,” in 2018 AIAA SPACE and
Astronautics Forum and Exposition, AIAA SPACE Forum.
American
Institute of Aeronautics and Astronautics, 2018.
[2] ——, “A theoretical framework for the stable operation of autonomous
spacecraft formations in the hill-clohessy-wiltshire frame,” in IEEE
Southeast Conference.
IEEE, 2019.
[3] V. P. Gehlot, M. J. Balas, and S. Bandyopadhyay, “Dynamic stability
and adaptive control of networked evolving formations with weak
nonlinearities,” in AIAA Scitech Forum.
AIAA, 2020.
[4] A. D. Ames, J. W. Grizzle, and P. Tabuada, “Control barrier function
based quadratic programs with application to adaptive cruise control,”
in 53rd IEEE Conference on Decision and Control, 12 2014, pp. 6271–
6278.
[5] F. Rossi, S. Bandyopadhyay, M. Wolf, and M. Pavone, “Review of
multi-agent algorithms for collective behavior: a structural taxonomy,”
IFAC-PapersOnLine, vol. 51, no. 12, pp. 112 – 117, 2018, iFAC Work-
shop on Networked & Autonomous Air & Space Systems NAASS
2018.
[6] D. Zhou, Z. Wang, S. Bandyopadhyay, and M. Schwager, “Fast, on-
line collision avoidance for dynamic vehicles using buffered voronoi
cells,” IEEE Robotics and Automation Letters, vol. 2, no. 2, pp. 1047–
1054, 2017.
[7] O. Khatib, “Real-time obstacle avoidance for manipulators and mobile
robots,” in Proceedings. 1985 IEEE International Conference on
Robotics and Automation, vol. 2, 1985, pp. 500–505.
[8] E. Lavretsky and K. Wise, Robust and Adaptive Control: With
Aerospace Applications, ser. Advanced Textbooks in Control and
Signal Processing.
Springer London, 2012.
[9] G. Kreisselmeier and K. Narendra, “Stable model reference adaptive
control in the presence of bounded disturbances,” IEEE Transactions
on Automatic Control, vol. 27, no. 6, pp. 1169–1175, 1982.
[10] N. Hovakimyan and C. Cao, L1 Adaptive Control Theory: Guaranteed
Robustness with Fast Adaptation, ser. Advances in Design and Control.
Society for Industrial and Applied Mathematics, 2010.
[11] P. A. Ioannou and J. Sun, Robust Adaptive Control.
Mineola, New
York: Dover Publication, Inc., 2012, p. 586.
[12] P. Ioannou and B. Fidan, Adaptive Control Tutorial, ser. Advances in
Design and Control. Society for Industrial and Applied Mathematics,
2006.
[13] C. D. Johnson, “Disturbance-accommodating control; an overview,” in
1986 American Control Conference, 1986, pp. 526–536.
[14] M.
J.
Balas
and
S.
A.
Frost,
“Adaptive
Tracking
Control
for Linear Inﬁnite Dimensional Systems,” ser. Smart Materials,
Adaptive
Structures
and
Intelligent
Systems,
vol.
Volume
2:
Modeling, Simulation and Control; Bio-Inspired Smart Materials
and Systems; Energy Harvesting, 09 2016. [Online]. Available:
https://doi.org/10.1115/SMASIS2016-9098
[15] J. Dormand and P. Prince, “A family of embedded runge-kutta for-
mulae,” Journal of Computational and Applied Mathematics, vol. 6,
no. 1, pp. 19 – 26, 1980.
[16] P. Virtanen et al., “SciPy 1.0: Fundamental Algorithms for Scientiﬁc
Computing in Python,” Nature Methods, vol. 17, pp. 261–272, 2020.
77
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-787-0
ICAS 2020 : The Sixteenth International Conference on Autonomic and Autonomous Systems

