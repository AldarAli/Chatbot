Face Recognition Using 1DLBP Texture Analysis 
 
Amir Benzaoui and Abdelhani Boukrouche  
Laboratory of Inverses Problems, Modeling, Information and Systems (PI:MIS) 
Department of Electronics and Telecommunication 
University of 08 Mai 1945 
P.O box 401, Guelma, Algeria 
amirbenzaoui@gmail.com           abdelhanib@yahoo.fr 
 
 
Abstract— A new algorithm for face recognition is proposed in 
this work; this algorithm is mainly based on Local Binary 
Pattern texture analysis in one dimensional space and Principal 
Component Analysis as a technique for dimensionalities 
reduction. The extraction of the face’s features is inspired from 
the principal that the human visual system combines between 
local and global features to differentiate between people. Starting 
from this assumption, the facial image is decomposed into several 
blocks with different resolutions, and each decomposed block is 
projected in one dimensional space. Next, the proposed 
descriptor is applied for each projected block. Then, the resulting 
vectors will be concatenated in one global vector. Finally, 
Principal 
Component 
Analysis 
is 
used 
to 
reduce 
the 
dimensionalities of the global vectors and to keep only the 
pertinent information for each person. The experimental results 
have shown that the proposed descriptor Local Binary Pattern in 
one Dimensional Space combined with Principal Component 
Analysis have given a very significant improvement at the 
recognition rate and the false alarm rate compared with other 
methods of face recognition, and a good effectiveness against 
different external factors as: illumination, rotations, and noise. 
Keywords— face recognition;  local binary pattern (LBP); local 
binary pattern in one dimensional space (1DLBP); texture 
description; 
dimesionalitiy 
reduction; 
Principal 
Compenent 
Analysis (PCA). 
I. 
 INTRODUCTION 
The automatic analysis of the human face has become 
recently an active research area in the artificial vision and 
patterns recognition domains, due to its important use in 
several applications such as electronic election, biometrics and 
video surveillance [1, 2, 3]. Face analysis includes face 
detection and tracking, face recognition, age and gender 
recognition, and emotion recognition. Human face is dynamic 
entity, which changes under the influence of several factors as 
pose, size, occlusion, background complexity, lighting and the 
presence of some components such as mustaches, beard, and 
glasses. So, the essential key for any face analysis problem is 
on how to find an efficient descriptor to represent and to 
model the face in a real context? 
 
The crucial step in any problem of face analysis is the 
phase of features extraction. In this phase, there are two major 
approaches, local and global approaches. Global approaches 
are based on pixel information; all pixels of the facial image 
are treated as a single vector; the vector size is the total 
number of the image pixels [4]. Most of the methods of this 
approach use another space of representation (subspace) to 
reduce the number of pixels and to eliminate the redundancies. 
Principal Component Analysis (PCA) [5] and Linear 
Discernment Analysis (LDA) [6] are the most popular 
methods used to reduce the dimensions and to select the useful 
information. However, these approaches are not effective in 
the unconstrained cases, i.e., situation where occlusion, 
lighting, pose, and size of the face are uncontrolled.  
 
Recently, the scientists concentrate on local approaches, 
which are considered as a robust approaches in the 
unconstrained cases compared with global approaches; in this 
case, the face analysis is given by the individual description of 
its parts and their relationships, this model corresponds to the 
manner of perception by the visual human system. The 
methods of this approach are based on the extraction of 
features from the facial image and the definition of an 
adequate model to represent the face [7]. Several methods and 
strategies have been proposed to model and classify faces 
essentially based on the texture, normalized distances, angles 
and relations between eyes, mouth, nose and edge of the face. 
Local Binary Pattern (LBP) [8], Local Gabor Binary Pattern 
(LGBP) [9] and Oriented Edge Magnitudes (POEM) [10] are 
the recent methods in this approach.   
 
Psychological and neuroscience studies have showed that 
the human visual system combines between local and global 
features to differentiate between people [11]. LBP is the best 
descriptor for capturing the local features, but it is not 
performed in the description of the global features [8]. From 
these assumptions, we propose in this work a new feature 
extraction method based on a descriptor proposed in our 
laboratory in [12, 13, 14], called 1DLBP (Local Binary Pattern 
in One Dimensional Space), inspired from classical LBP. The 
proposed method, which is applied on face recognition, is 
characterized by the combination of the local and global 
features for modeling faces. The algorithm of extraction is 
decomposed into five principal stages; first, the input image is 
decomposed into several blocks with different resolutions. A 
vertical projection in one dimensional space is applied for 
each decomposed block. Next, the proposed descriptor is 
applied on each projected block. Then, the resulting vectors 
from each block are concatenated in one global vector. 
Finally, Principal Component Analysis is needed to regroup 
14
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-272-1
FUTURE COMPUTING 2013 : The Fifth International Conference on Future Computational Technologies and Applications

the global vectors, to reduce the dimensionalities and to keep 
only the useful information for each individual. 
 
This paper is organized as follows: in the next section, we 
describe the classical LBP and histogram feature. In Section 3, 
the proposed algorithm of feature extraction for face 
recognition is presented. For this purpose, chi-square distance 
is required to measure similarities between face templates. In 
Section 4, we present our experimental results by applying the 
proposed algorithm on ORL and AR databases. Finally, a 
conclusion related to this work is given in Section 5. 
 
II. 
LOCAL BINARY PATTERN (LBP) 
 
The original LBP operator introduced by Ojala et al. [15], 
which has been used for texture discrimination, has shown a 
powerful and effective results against to the variations in 
rotation and illumination. The operator labels the pixels of an 
image by thresholding the 3×3 neighborhood of each pixel 
with the central value and considering the result as a binary 
code. Next, the histogram of the labels can be used as a texture 
descriptor (see Figure 1); for a given pixel  gc(xc,yc) from gray 
image, its texture LBP is calculated by comparing gc with its 
neighbors pixels P on a circle of radius R (see Figure 2 for 
more details on circular neighborhood). The value of LBP(gc) 
is obtained as: 
 
LBPP,R(xc, yc) = ∑Pi=1 S(giP ,R - gc) 2i-1                               (1) 
 
S(x) is defined as:  S(x) = 1         if x  0;
0     otherwise;                  (2) 
 
    The major disadvantage of the original LBP operator 
resides in the size of the descriptor, a mask of 3×3 pixels 
cannot capture the structures of large scale which can 
considered as a dominants structures in the image. Recently, 
the size of the operator has been extended by using a mask 
with different large sizes. Figures 2.a, 2.b, 2.c show three 
examples of the extended LBP. 
 
 
 
Figure 1.  LBP calculation performed into 3×3 neighborhood. 
       
 
                      (a)                                    (b)                                     (c) 
Figure 2.  Neighborhood set for different (P,R). (a) The basic LBP operator 
(P,R) = (8,1) (b) LBP with circular neighborhood (8,2). (c) LBP with circular 
neighborhood (8,3).  
 
 
      
      
                   
Figure 3.  ELBP samples with different extention [16]. 
 
 
Original image      LBP (8,1)         LBP (8,2)       ELBP (8,3,2)    ELBP (8,3,4)         
Figure 4.  Results of LBPs application with differentd masks . 
    Another type of the extended operators of LBP called: 
Elliptical Local Binary Patterns (ELBP) [16]. In ELBP, at 
each pixel gc(xc,yc), we consider its surrounding pixels that lie 
on an  ellipse (see Figure 3) with (xc,yc ) is the center. ELBP of 
(xc, yc) with P neighboring pixels at (R1, R2) distances is 
computed as: 
 
ELBPP,R1,R2  (xc, yc) = ∑Pi=1 S(giP ,R1,R2 - gc) 2i-1               (3) 
 
S(x) function is defined as (2). 
 
In details, the coordinates of the i th neighboring pixel of 
(xc,yc) are calculated using the formulas: 
 
      angle-step = 2 * π / P                                                            (4) 
 
      xi = xc + R1 * cos (( i – 1) * angle-step)                           (5) 
 
      yi = yc + R2 * sin (( i – 1) * angle-step)                           (6) 
 
However, the extend versions of LBP operators and the 
Elliptical LBPs present a good results by capturing the local 
and global patterns but they are not performed for capturing 
the micro characteristics (fine details) of the human face. 
Figure 4 shows the rsults of LBP and ELBP applications using 
different masks.  
III. 
PROPOSED APPROACH 
The proposed algorithm used to extract information for 
face recognition is described in the following recapitulation; 
next, we present each step in details. We consider that we have 
a gallery θ of biometric samples with P persons, S biometric 
sample (image) per person, N training images for each person 
15
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-272-1
FUTURE COMPUTING 2013 : The Fifth International Conference on Future Computational Technologies and Applications

Pi and M testing images (example θ=400,  P=40, S=10, N=5, 
M=5, with ORL database, θ=2600, P=100, S=26, N=13, 
M=13 with AR database). The process of features extraction is 
composed of six principal stages for each person: 
 
• 
Preprocessing of the N images. 
• 
Decomposition of each image Ni into several blocks 
with different resolution.   
• 
Projection of each block decomposed in one 
dimensional space. 
• 
Application of the proposed descriptor 1DLBP for 
each projected block. 
• 
Concatenation of the resulting vectors of an image Ni 
in one global vector Vi. 
• 
Dimensionalities reduction of the V grouped global 
vectors using PCA. 
A. Preprocessing 
 
The objective of the preprocessing is the modification of 
the source’s image representation to facilitate the task of the 
following steps and to improve the rate of recognition. First, 
the facial image is converted into grayscale image. Next, every 
grayscale image is filtered by median filter to suppress noise. 
Lastly, the noise suppression image is then adjusted to 
improve the contrast of the image. 
B. Image decomposition  
 
Most LBP operators characterize the face texture 
distribution of each pixel with its neighborhood only. But, the 
differences between two faces can be demonstrated not only 
by the texture distribution of each pixel with its neighborhood, 
but also by the relative connection with other pixels. With this 
intention, we have decomposed the original image into several 
sub-images (see Figure 5) to characterize better the details and 
the relationships between all the image pixels. Next, the 
extracted histograms will be concatenated in one global vector 
in the next stages. With this technique, we can obtain the fine 
details and the relative connections between all pixels.  
C. 1D vertical projection 
 
The 1D projection of rows or columns of each level 
provides an effective mean to describe better the local and 
global patterns. Figure 6 presents an example of vertical 
projection. The objective of the projection is to validate the 
descriptor LBP in one dimensional space to find another mean 
for describing and analyzing better the human face’s texture. 
 
 
 
 
 
 
 
 
 
 
Figure 5.  Image decomposition in differents blocks. 
D. 1DLBP application 
 
    The concept of the 1DLBP method consists in a binary code 
describing the local agitation of a segment in 1D signal. It is 
calculated by thresholding of the neighborhood values with 
the central value. All neighbors get the value 1 if they are 
greater or equal to the current element and 0 otherwise. Then, 
each element of the resulting vector is multiplied by a weight 
according to its position (see Figure 6.c). Finally, the current 
element is replaced by the sum of the resulting vector. This 
can be recapitulated as follows: 
    
1DLBP = ∑n=0N-1 S(gn – g0).2n                                           (7) 
 
S(x) function is defined as (2). 
 
    g0 and gn are respectively the values of the central element 
and its 1D neighbors. The index n increases from the left to 
the right in the 1D string as shown in Figure 6.c. The 1DLBP 
descriptor is defined by the histogram of the 1D patterns. 
 
 
 
 
 
 
 
                                      (a) Vertical Projection 
 
 
 
 
 
 
130 
115 
64 
120 
110 
105 
130 
40 
32 
                                   (b) Threshold 
 
1 
1 
0 
1 
 
0 
1 
0 
0 
                                                  (c) Multiplication 
 
128 
64 
32 
16 
 
8 
4 
2 
1 
                                                   (d) Multiplication Result 
 
128 
64 
0 
16 
 
0 
4 
0 
0 
                             (e) 1DLBP 
 
 
 
 
 
212 
 
 
 
 
 
Figure 6.  Example of vertical projection in 1D space + 1DLBP application. 
 
16
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-272-1
FUTURE COMPUTING 2013 : The Fifth International Conference on Future Computational Technologies and Applications

E. Concatenation of the resulting vectors 
 
The proposed descriptor 1DLBP is applied on all blocks of 
the decomposed image with the different resolution presented 
in Figure 5. The extracted histograms from each block are 
concatenated in one global histogram (vector) representing 
one face image Vi. A problem of information redundancies is 
appeared due to the important size of each global vector. To 
resolve this problem, we have used the Principal Component 
Analysis (PCA) as a technique of dimensionalities reduction, 
to regroup all the global vectors of each person Xi in one 
global matrix and to select the useful information needed to 
modeling each person. 
 
F. Dimensionalities reduction with PCA 
 
The principal idea of PCA is to represent a group of 
images (vectors) of a same person X in another space of lower 
dimension; this space is constructed from a set of training 
images. PCA begins with a set of 1D training vectors of the 
same class; each vector Γi represents a training image Ii (I = 
1...N), and construct Oi = Γi - Ѓ where Ѓ represents the mean 
vector of all Γi vectors. Then, determinate the eigenvectors µi 
of the covariance matrix C= ∑i Oi × Oi
T. The first K “Principal 
axis” corresponds to the K largest eigenvalues (the value of K 
is chosen in the same that the sum of the first axis K provides 
a large proportion of the total eigenvalues sum). 
  
Now, given a new image ξ considered as a test example. 
First, we built its 1D representation using the extraction 
method proposed in this work (stages: 1-5), and we subtract 
the average face as follows: θ = ξ1D – Ѓ. Next, we project the 
image in the principal axis elaborated as: θp= ∑i=1,K µi
T (θ -µi). 
Finlay, we calculate the chi-Square distance to classify the 
image ξ in the nearest class corresponding to a degree of 
similarities that exceeds a fixed threshold. 
 
Distchi-square (X, Y) = ∑
(89:;9)<
89=;9
>
9?@
                                         (8) 
IV. 
EXPERIMENTAL RESULTS 
    To evaluate the performances of the proposed algorithm, we 
have carried out several tests on ORL and AR databases; we 
randomly selected half of samples for training set and the 
remaining samples for testing set. In all our experiments, we 
considered the average recognition rates of several random 
permutations (50 permutation with ORL database and 100 
permutations with AR database), and we compared the 
obtained results (identification and false alarm rates) with 
other methods using the same testing protocols. Our 
experiments are implemented with Matlab 2010a, Windows 7, 
HP Core 2 Duo, 3 Ghz CPU with 2 Gb Ram. 
 
A. ORL database 
 
The ORL database contains 400 frontal images in different 
facial expression, conditions of illumination, hairstyles with or 
without beard, moustaches and glasses for 40 persons, 10 
images for each person. Each sample is a 92×112 gray image, 
with tolerance for some tilting and rotation of up to 20° (see 
Figure 7).  
B. AR database 
 
The AR database was collected at the Computer Vision 
Center in Barcelona, Spain in 1998 [17]. It contains images of 
116 individuals (63 men and 53 women). The imaging and 
recording conditions (camera parameters, illumination setting, 
and camera distance) were carefully controlled and constantly 
recalibrated to ensure that settings are identical across 
subjects. The resulting RGB color images are 768×576 pixels 
in size. The subjects were recorded twice at a 2–week interval. 
During each session 13 conditions with varying facial 
expressions, illumination and occlusion were captured (see 
Figure 8).  
 
    First, we applied the methods inspired from the LBP texture 
analysis in the two databases (classical LBP, extended LBP, 
Elliptical LBP, and the one dimensional projected LBP). The 
performances of these methods are shown in Table 1. 
 
 
 
       
 
Figure 7.  Some images from ORL database. 
 
 
Figure 8.  Some images from AR database [17]. 
TABLE I.  
COMPARATIVE RECOGNITION RESULTS OF THE ISPIRED LBP 
METHODS ON ORL AND AR DATABASES 
RR: Recognition Rate %. 
FAR: False Alarm Rate %. 
  
 
ORL 
 
RR % 
AR 
 
RR % 
Average 
 
RR % 
Average 
 
FAR % 
LBP (8,1) 
85,2 
87,5 
86,4 
3,62 
LBP (8,1)  
PCA 
91,4 
93 
92,2 
1,92 
LBP (8,2) 
86 
89,4 
87,7 
3,1 
ELBP 
(8,3,2) 
84,3 
88,1 
86,2 
2,97 
ELBP 
(8,3,4) 
83,8 
86,9 
85,4 
3,03 
1DLBP 
92 
92,6 
92,3 
2.36 
1DLBP  
PCA 
95,8 
97,9 
96,9 
1.44 
     
17
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-272-1
FUTURE COMPUTING 2013 : The Fifth International Conference on Future Computational Technologies and Applications

TABLE II.  
COMPARAISON WITH OTHER STATE OF THE ART APPROACHS 
 
 
ORL 
 
RR % 
AR 
 
RR % 
Average 
 
RR % 
Average 
 
FAR % 
LBP (8,1)  PCA 
91,4 
93 
92,2 
1,92 
1DLBP  PCA 
95,8 
97,9 
96,9 
1.44 
Local Gabor Binary 
Pattern (LGBP) 
94,1 
96,2 
95,2 
1,87 
POEM 
90,9 
89,4 
90,2 
2,6 
PCA 
85 
81,2 
83,1 
5,12 
LDA 
82,4 
84,7 
83,6 
5,36 
           
    The results of the experiments clearly showed that the 
projected Local Binary Pattern with dimensionalities reduction 
using PCA enhances the recognition performance in all 
configurations and presents a very good improvement and 
significant results in recognition rate, false alarm rate against 
other variants of LBP. 
 
    We also conducted tests comparing our method against 
recent and classical state-of-the-art approaches using the 
similar protocols under more challenges and scenarios. The 
results, shown in Table 2, indicate clearly the effectiveness of 
our approach which outperforms all other methods.  
 
    The facial images are taken with ORL database which is 
considered as a stable database in the unconstrained cases, and 
the AR database which presents a very good variation, in 
lighting, occlusion and facial expression, to measure the 
performances of the approach in the difficult situations. The 
comparison results presented in Table 2 shows that our 
proposed approach presents very good results with AR 
database which indicates that this approach has an important 
effectiveness against to the variations in different factors like: 
occlusion, lighting, rotation, and noise.  
 
    Another conclusion we can make from Table 1 and Table 2 
is that 1DLBP + PCA is much better than 1DLBP only; the 
association of the PCA as a robust technique in the 
dimensionalities reduction is very interesting to improve the 
performances of the proposed approach. 
V. 
CONCLUSION AND FUTURE WORK 
Facial image can be considered as a composition of local 
and global features. Starting from this assumption, we have 
successfully developed a new algorithm for texture face 
discrimination, this algorithm is primary based on Local 
Binary Patterns but projected in one dimensional space; it 
combines between local and global features, capable of 
recognizing faces in different situations. Each facial image is 
decomposed on multi blocks with different resolution and 
each decomposed block will be vertically projected in one 
dimensional space. Next, the proposed descriptor is applied on 
each projected block. Then, the extracted vectors from each 
block will be concatenated in one global vector. Finally, 
Principal Component Analysis is applied on the regrouped 
vectors to reduce the dimensionalities of the concatenated 
vectors and to extract the useful information. The 
experimental results applied on ORL and AR database have 
showed that the proposed approach has given a very 
significant improvement at the recognition rate, false alarm 
rate and a good effectiveness against different external factors 
as: occlusion, illumination, rotations, and noise. 
 
As a prospect of this work, we hope to apply the proposed 
descriptor in other application of face analysis, like age, or 
gender recognition, to apply the same descriptor with other 
modalities of biometric system, like the use of the human ear 
in identity recognition.   
REFERENCES 
[1] M. Khasawneh, M. Malkawi, O. Al-Jarrah, T.S. Hayajneh, and M.S. 
Ebaid, “A Biometric-Secure e-Voting System for Election Processes,” 
Proc. IEEE Sym. on Mechatronics and its Applications (ISMA 8), 
Amman, 
Jordan, 
May 
2008, 
pp. 
371-376. 
doi: 
10.1109/ISMA.2008.4648818 
[2] A. Hadid, J.L. Dugelay, and M. Pietikainen, “On the use of Dynamic 
Features in Face Biometrics: Recent Advances and Challenges,” Signal, 
Image and Video Processing  (Springer), vol. 5, no. 4, Nov 2011, pp. 
495-506. doi: 10.1007/s11760-011-0247-3  
[3] L. Ding and A.M. Martinez, “Features versus Context: An approach for 
precise and detailed detection and delineation of faces and facial 
features,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 
32, no. 11, Nov 2010, pp. 2022-2038. doi: 10.1109/TPAMI.2010.28 
[4] R.S. Kathavarayan and M. Karuppasamy, “Identification of Untrained 
Facial Image in Combined Global and Local Preserving Feature Space,” 
International Journal of Biometrics and Bioinformatics (IJBB), vol. 4, 
no. 1, Mar 2010, pp. 1-12. 
[5] M.A. Turk and M.P. Pentland, “Eigenfaces for recognition,” Journal of 
Cognitive Neuroscience, vol. 3, no. 1, 1991, pp. 71-86. doi: 
10.1162/jocn.1991.3.1.71 
[6] N. Belhumeur, J.P Hespanha, and D.J. Kriegman, “Eigenfaces vs 
Fisherfaces: Recognition using class specific linear projection,” IEEE 
Trans. Pattern Analysis and Machine Intelligence, vol. 19, no. 7, Jul 
1997, pp. 711-720. doi: 10.1109/34.598228.  
[7] T. Cootes, C. Taylor, H. Kang, and V. Petrovié, “Handbook of Face 
Recognition”. Chapter.3: “Modeling Facial Shape and Appearance”. 
Springer, 1st Edition, 2005, pp. 40. doi: 10.1007/b138828 
[8] T. Ahonen, A. Hadid, and M. Pietikainen, “Face Recognition with Local 
Binary Pattern,” Proc. Springer. European Conference on Computer 
Vision (ECCV 8), Prague, Czech, May 2004, pp. 469-481. doi: 
10.1007/978-3-540-24670-1_36 
[9] N. Nguyen, L. Bai, and L. Shen, “Local Gabor Binary Pattern whitened 
PCA: A novel approach for face recognition from single image per 
person,” Proc. IEEE / Springer Conf. On Biometrics (ICB 3), Alghero, 
Italy, Jun 2009, pp. 269-278. doi: 10.1007/978-3-642-01793-3_28. 
[10] N.S. Vu and A. Caplier, “Face recognition with patterns of oriented edge 
magnitudes,” Proc. Springer. European Conference on Computer Vision. 
(ECCV 11), Heraklion Crete, Greece, Sep 2010, pp. 313-326. doi: 
10.1007/978-3-642-15549-9_23. 
[11] A.J O'Toole, D.A Roark, and H. Abdi, “Recognizing moving faces: A 
psychological and neural synthesis,” Trends in Cognitive Science, vol. 6, 
no. 6, Mar 2010, pp. 261-266. 
[12] L. Houam, A. Hafiane, R. Jennane, A. Boukrouche, and E. Lespessailes, 
“Trabecular Bone Anisotropy Characterisation Using 1D Local Binary 
Patterns,” Proc. Springer Conf. Advanced Concepts for Intelligent 
Vision Systems (ACIVS 12), Sydney, Australia, Dec 2010, pp. 105-113, 
doi: 10.1007/978-3-642-17688-3_11 
18
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-272-1
FUTURE COMPUTING 2013 : The Fifth International Conference on Future Computational Technologies and Applications

[13] L. Houam, A. Hafiane, R. Jennane, A. Boukrouche, and E. Lespessailes. 
“Trabecular Bone Texture Classification Using 1D LBP and Wavelets 
Coefficients in High-pass Bands,” Proc. Conf. Signal, Image, Vision and 
their Application (SIVA), Guelma, Algeria, Nov 2011, pp. 116-121. 
[14] L. Houam, A. Hafiane, R. Jennane, A. Boukrouche, and E. Lespessailes, 
“Texture characterization using Local Binary Pattern and Wavelets. 
Application to Bone Radiograph,” Proc. IEEE Conf. Image Processing, 
Theory, Tools and Applications (IPTA 3), Istanbul, Turkey, Oct 2012, 
pp. 371-376. doi: 10.1109/IPTA.2012.6469546  
[15] T. Ojala, M. Pietikainen, and D. Harwood, “A comparative study of 
texture measures with classification based on featured distribution,” 
Pattern Recognition, vol. 29, no. 6, 1996, pp. 51-59. doi: 10.1016/0031-
3203(95)00067-4 
[16] H.T. Nguyen, N.S. Vu, and A. Caplier, “How far we can improve micro 
features based face recognition systems?,” Proc. IEEE Conf. Image 
Processing, Theory, Tools and Applications (IPTA 3), Istanbul, Turkey, 
Oct 2012, pp. 350-353. doi: 10.1109/IPTA.2012.6469533  
[17] A.M. Martinez and R. Benavente, “The AR face database”, CVC 
Technical Report, 24, 1998. 
 
19
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-272-1
FUTURE COMPUTING 2013 : The Fifth International Conference on Future Computational Technologies and Applications

