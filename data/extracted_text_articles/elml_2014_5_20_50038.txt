Practice and Effects of Programming Education in Blended Quiz Production 
 
Junko Shinkai, Yoshikazu Hayase 
Department of Electronics and Computer Engineering 
Toyama National College of Technology 
Toyama, Japan 
{shinkai, hayase}@nc-toyama.ac.jp 
Isao Miyaji 
Department of Information Science 
Okayama University of Science 
Okayama, Japan 
 miyaji@mis.ous.ac.jp 
 
 
Abstract—Blended classes are conducted for the purpose of 
improving the practices and effects of programming education. 
Using an environment in which students make quizzes 
collaboratively or independently, as well as an e-learning 
system and mutual assessment activity among students, 
students compose quizzes and evaluate one another in classes. 
This paper describes differences of consciousness in different 
performance groups based on the results of a questionnaire 
administered to students, preferred items for making quizzes, 
and a comparison of test scores obtained during the first year 
and second year of Technical College. 
Keywords–programming education; collaborative learning; 
quiz-making; Moodle 
I.  INTRODUCTION 
Aiming at improving the effects of programming 
education, each unit was conducted based on blended 
learning combined with teacher-centered class, individual 
learning using e-learning and collaborative learning by 
students’ mutual assessment [3]. The results of a 
questionnaire after finishing all the units and tests revealed 
that quiz-tests were effective in developing students’ 
knowledge of programming.  However, it was found that 
there were cases when students happened to get correct 
answers of quiz-tests by guessing.  
Therefore, the purpose of this study is to develop an 
accurate knowledge of students and verify the effect of 
blended learning after practicing activities of students’ 
making quizzes, which was presumed to be more effective 
in developing students’ understanding of programming than 
their solving given questions. 
Section II explains the collaborative quiz-making 
environment based on Moodle (Modular object-oriented 
dynamic learning environment). Section III describes a 
practical example conducted for unit learning and feedback   
after practicing each unit. The conclusion of this study and 
future considerations are expressed in Section IV.   
II. COLLABORATIVE QUIZ-MAKING ENVIRONMENT  BASED ON 
MOODLE 
The collaborative quiz-making environment module 
was developed to make multiple-choice questions that can be 
leveraged with the quiz module as a standard module of the 
Moodle [3]. The development environment is Moodle 1.9 on 
Linux server with PHP (Hypertext Preprocessor) 5 script 
language, MySQL 5 database management system, and 
Apache 2 hypertext transfer protocol sever [4]. Figure 1 is a 
use case diagram by UML(Unified Modeling Language) of  
collaborative quiz-making environment. The collaborative  
quiz-making environment has the following three functions: 
(1) Students’ quiz-making function 
Students can make multiple-choice questions without 
being aware of the tags needed to make quizzes with Moodle. 
 (2) Mutual evaluation among students function 
Through the evaluation items produced by teachers, 
students can evaluate quizzes made by other students. 
(3) Teachers’ quiz-registering function 
Teachers can use the quizzes made by students in quiz 
modules by registering quizzes made by students into 
Moodle’s standard quiz bank. 
 
Figure 1.  A use case diagram of collaborative quiz-making environment. 
III. PRACTICE AND EVALUATION OF CLASSES 
Programming education was conducted with a 
collaborative quiz-making environment for 39 students of the 
second year of the Electronic Information Department of  
Technical College. Immediately after one unit of the 
programming education classes was completed, quiz-making 
and evaluation activities were conducted. Students were 
asked to do the activities 3 times in substitution, operation, 
and input–output, in selection, and in recursion. The quiz to 
be made included multiple-choice questions for programs of 
C language grammar. Each student composed a single 
question and conducted a mutual evaluation for the questions 
108
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-328-5
eLmL 2014 : The Sixth International Conference on Mobile, Hybrid, and On-line Learning

with peer students having the same last digit of their student 
number. 
The outline of programming education in blended 
making quizzes is presented in Figure 2. For each unit, 
blended classes which consist of individual learning with e-
learning quizzes and collaborative learning with the 
collaborative quiz-making environment were conducted. 
 
 
Figure 2.  Component of blended classes. 
A. Differences in students’ consciousness by performance 
score group 
After the 30th class, a questionnaire with 45 items related 
to quiz-making, evaluation, and the collaborative quiz-
making environment shown in Table I was administered to 
39 students. The questionnaire was administered with the 
five-level rating evaluation from “5: I think so.” to “1: I do 
not think so”. According to the score x of four manuscript 
tests conducted in 2012, the students were divided into an 
ascendant group (x≥m+SD/2, 17 students), a median group 
(m-SD/2≤x<m+SD/2, 12 students), and a descendant group 
(x<m-SD/2, 10 students), where m and SD respectively 
denote the average score and standard deviation. For the 
students answering “3: yes and no” in each group, a 
significance test was conducted to ascertain whether the 
average score deviated to the positive side or negative side or 
did not deviated at all. The result is presented in Table I. The 
signs of m, SD, t, p, and F in Table I represent the mean, 
standard deviation, t value, significant probability, and the F 
value, respectively. 
The significance test, conducted for all 45 items, found 
that each group deviated to the positive side with a 
significance level of 1%. Additionally, the significance test 
on each item revealed that the quantities of items which 
significantly deviated to the positive side in the ascendant 
group, the median group, and the descendant group were 26, 
21, and 29, respectively. 
Next, analysis of variance was conducted for each item. 
The result shown in Table I demonstrates that only the 24th 
item (The quizzes made by others are difficult.) was 
significant. As a result of performing multiple comparisons 
using the LSD (Least Significant Difference) method on the 
24th item, a significant difference was found between the 
ascendant group and the descendant group, suggesting that 
the students in the descendant group felt that problems made 
by others were more difficult than those in the ascendant 
group. The LSD is a method for multiple comparisons after 
the analysis of variance. 
The items that deviated significantly to the positive side 
suggested the following: 
(1) Items that deviated significantly to the positive side 
irrespective of the score group 
The first item and the 20th item showed that students 
thought it was difficult for them to make quizzes and give 
advice related to choices (wrong answers). The largest t 
value in the descendant group was the first item, “making 
quizzes is difficult,” which deviated significantly to the 
positive side. 
The second and fourth items and the 25th and 27th items 
suggested that students thought that they were able to 
improve the level of understanding of what they had learned 
and were able to gain complete control over their knowledge 
by making quizzes and solving the quizzes made by others. 
Moreover, the 40th and 41st items revealed that students 
were able to accept criticism and advice from others 
gratefully, which helped them modify their quizzes. 
(2) Items that significantly deviated to the positive side 
were only those of the ascendant group 
Only the fifth item deviated significantly to the positive 
side in the ascendant group, which showed that the students 
in the ascendant group thought it was more effective to make 
quizzes than to solve them. For the students in the ascendant 
group, quiz-making activities might improve the level of 
understanding of what they have learned. 
(3) Items that significantly deviated to the positive side 
only in the descendant group 
The 18th and 19th items showed that the students in the 
descendant group thought that they were able to improve 
their motivation for learning and obtain knowledge 
completely by thinking about alternative choices (wrong 
answers) for multiple-choice questions. Furthermore, the 
23rd item showed that they thought that they could obtain 
knowledge completely by thinking about advice for wrong 
answers. Additionally, the 33rd item found that they thought 
that their use of evaluation activities had improved the level 
of understanding of what they had learned. 
Consequently, although students felt it was difficult to 
make quizzes, they thought that the activities of thinking 
about wrong answers and advice and those of evaluation can 
engender improvement of the level of understanding of what 
they had learned. 
B. Opinions about making quizzes 
The students were asked to write freely the reasons why 
they felt it was difficult to make quizzes. The main reasons 
are shown below: 
(1) Benefits of making quizzes 
・Making quizzes helps me review what I have learned. 
・Making quizzes can improve my understanding of 
programming. 
(2) Shortcomings of making quizzes 
・ Making quizzes was difficult, so I could not get 
motivated by myself. 
・It took much time to do it. 
109
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-328-5
eLmL 2014 : The Sixth International Conference on Mobile, Hybrid, and On-line Learning

(3) Benefits of evaluation activities 
・It serves as a review. 
・Thanks to this activity, I was able to understand what 
is important in programming. 
(4) Shortcomings of evaluation activities 
・I did not know whether I made correct evaluations. 
・When I did not understand them, I was unable to make 
evaluations. 
The results of free description suggested that students 
thought that quiz-making and evaluation activities were able 
to help them improve their understanding as a review. 
However, for the students who felt it was difficult to make 
quizzes alone, they turned out to be demotivating. In addition, 
some students turned out to feel concerned about making 
evaluations. 
C. Preferential items of making quizzes 
Asking students to assign the order of priority (1–6) of 
items on which they placed importance in making quizzes 
(Table II), a cross table of the result of each item was 
conducted.  
 
TABLE II.  CROSS TABLE OF QUIZ-MAKING PREFERENTIAL 
ITEMS AND TESULTS OF χ2 TESTS 
Priority order
 Item
1
2
3
4
5
6
Total
1
2
3
4
5
6
Total
Difficulty level of question
4
9
11
7
7
1
39
6.5
6.5
6.5
6.5
6.5
6.5
39
Option of question (Wrong answer)
1
6
11
12
7
2
39
6.5
6.5
6.5
6.5
6.5
6.5
39
Advisory statement for wrong answe
0
0
0
6
15
18
39
6.5
6.5
6.5
6.5
6.5
6.5
39
Learning contents of question
22
9
3
5
0
0
39
6.5
6.5
6.5
6.5
6.5
6.5
39
Originality of question
3
3
5
4
9
15
39
6.5
6.5
6.5
6.5
6.5
6.5
39
Helpful for learners
9
12
9
5
1
3
39
6.5
6.5
6.5
6.5
6.5
6.5
39
Total
39
39
39
39
39
39
234
39
39
39
39
39
39
234
Difficulty level of question
-1.0
1.0
1.8
0.2
0.2 -2.2
*
Option of question (Wrong answer)
-2.2 -0.2
1.8
2.2
0.2 -1.8
*
**
Advisory statement for wrong answe -2.5 -2.5 -2.5 -0.2
3.3
4.5
**
**
Learning contents of question
6.1
1.0 -1.4 -0.6 -2.5 -2.5
**
Originality of question
-1.4 -1.4 -0.6 -1.0
1.0
3.3
**
Helpful for learners
1.0
2.2
1.0 -0.6 -2.2 -1.4
**
**: p  < .01 ,  *: p  < .05
Actual frequency
Expected frequency
Adjusted residual
Significance test
 
 
A χ2 test was conducted in the 6 × 6 contingency table. 
Results show that the frequency deviation was significant 
(χ2(25) = 160.15, p<.01). Then, among the cells in which 
significant difference was found by residual analysis, the 
cells with positive residual error were marked with *. 
According to the results of residual analysis shown in 
Table II, students assigned priority to what they learned, and 
to what was helpful to other students in making quizzes. 
They did not regard the originality of advice for wrong 
answers and quizzes as important.  
D. Comparison of test performance between the presence 
or absence of quiz-making activity 
A regular examination with the same 13 problems was 
conducted during the 2011 school year, when students did 
not experience a quiz-making activity, and during the 2012 
school year, when they experienced it. The problems are 
presented in Table III. The problems consist of the multiple-
choice questions to test the knowledge of C language, in 
addition to questions to test the programming ability to make 
an algorithm and represent it in a C program. In each school 
year, students solved e-learning quizzes. Each question’s 
average score was analyzed using a significance test. The 
results are shown in Table IV.  
Significant differences were found among the average 
scores of all 13 questions, showing that the result of the 2012 
school year, with quiz-making activity, was higher. 
Additionally, the SD in 2012 was smaller, so the variation of 
scores was smaller. 
 
TABLE IV.   COMPARISION OF TWO YEARS’ TEST SCORES 
ｍ
SD
ｍ
SD
ｔ
p
Q.1
16.0
12.5
4.0
11.4
6.2
0.9
Q.2
20.0
15.9
5.6
16.6
5.0
0.6
Q.3
16.0
11.3
4.4
12.7
4.1
1.5
Q.4
12.0
10.0
3.2
10.4
2.5
0.7
Q.5
16.0
12.9
4.5
14.7
3.6
2.1 *
Q.6
12.0
9.6
3.5
10.7
3.0
1.5
Average
15.3
12.0
2.8
12.8
2.8
1.2
Q.7
20.0
16.6
5.5
16.5
5.9
0.1
Q.8
15.0
8.0
6.4
9.9
6.4
1.4
Q.9
14.0
11.1
4.7
12.1
3.8
1.1
Q.10
15.0
13.3
4.0
14.1
2.6
1.1
Q.11
12.0
7.6
4.6
9.8
3.2
2.6 *
Q.12
10.0
7.3
4.3
8.9
2.9
1.9
Q.13
12.0
10.2
3.7
11.1
1.8
1.5
Average
14.0
10.6
3.5
11.8
2.3
1.8
11.3
3.2
12.3
2.6
2.1 *
*：　 p  < .05
Questions to test
C language
knowledge
Questions to test
programming
ability
Average score of the whole questions
Category
Question Perfect
Score
2011
2012
Significance Test
 
With each question’s average score, only question 5 to 
test knowledge (to solve values of variables and pointer 
variables when programming is conducted) and question 11 
to test programming ability (to create a program for a 
function which assigns an argument value to a 2D array) 
showed significant difference. The results of the tests 
suggest that blending quiz-making activities was effective, 
although only slightly so, for improving programming 
learning. 
IV. CONCLUSION AND FUTURE PROBLEMS 
Aiming at improving programming education, class 
practice was conducted with a blended quiz-making activity 
using the collaborative quiz-making environment. According 
to the questionnaire administered after class practice, 
students, irrespective of performing score groups, reported 
that 
quiz-making 
activities 
were 
helpful 
for 
their 
understanding of what they had learned and for making their 
knowledge complete. At the same time, they thought it was 
difficult to make quizzes. 
The students in the ascendant group thought that making 
quizzes was more effective than solving them. In contrast, 
the students in the descendant group thought that thinking 
about alternative choices led to improved understanding and 
secured knowledge and that evaluating quizzes made by 
others improved their own understanding. In making quizzes, 
students assigned primary importance to what they had 
learned. They gave secondary emphasis to what was helpful 
to them. Comparison of the test results obtained during two 
years revealed that quiz-making activities were helpful, but 
only slightly, to improve what students had learned and to 
reinforce their knowledge. 
In future studies, several ways to examine should be 
striven to make students feel it is less difficult to make 
quizzes, for example by seeking points at issue in their 
textbook and by reviewing points before quiz-making 
activities. 
110
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-328-5
eLmL 2014 : The Sixth International Conference on Mobile, Hybrid, and On-line Learning

ACKNOWLEDGMENT 
Part of this study was conducted with support by a Grant-
in-Aid for Scientific Research (C) (No. 25350371). 
REFERENCES 
[1] Y. Fu-Yun, L. Yu-Hsin, and C. Tak-Wai, “A Web-based 
Learning System for Question-posing and Peer Assessment,” 
Innovation in Education and Teaching International, vol.42, 
no.4,  Nov. 2005, pp.337–348. 
[2] A. Nakano, T. Hirashima, and A. Takeuchi, “An Intelligent 
Learning Environment for Learning by Learning by Problem 
Posing,” IEICE Trans D-I, vol.J83-D-I, no.6, Jun. 2000, pp. 
539–549 (in Japanese). 
[3] J. Shinkai and I. Miyaji, “Effects of Blended Instruction on C 
Programming Education,” Transactions of Japanese Society 
for Information and Systems in Education, vol.28, no.2, Apr.  
2011, pp.151–162 (in Japanese). 
[4] J. Shinkai, Y. Hayase, and I. Miyaji, “Conducting 
Programming Education Using Collaborative Question-posing 
Environments,” Proceedings of Society for Information 
Technology & Teacher Education International Conference, 
Mar. 2013, pp.4742-4747. 
 
TABLE I. COMPARISION OF TWO YEARS’ TEST SCORES 
ｍ
SD
ｔ
ｐ
ｍ
SD
ｔ
ｐ
ｍ
SD
ｔ
ｐ
(1)
vs.
(2)
(2)
vs.
(3)
(3)
vs.
(1)
1 Making quizzes is difficult.
3.9
0.8
4.7 **
4.3
1.2
4.0 **
4.4
0.5
8.6 **
1.2
2 Making quizzes improves understanding of learning contents.
4.0
0.6
6.7 **
4.2
0.9
4.3 **
4.0
0.8
3.9 **
0.2
3 Making quizzes improves learning motivation.
3.1
0.9
0.5  
3.0
1.2
0.0  
3.4
0.8
1.5  
0.5
4 Making quizzes makes learning contents complete.
3.9
0.6
6.1 **
4.1
0.8
4.7 **
4.0
0.7
4.7 **
0.3
5 Making quizzes is more effective for solving quizzes.
3.5
0.7
2.7 *
2.8
1.2
0.5  
3.4
1.0
1.3  
1.7
6 Making quizzes is helpful to reviewing learning contents.
3.8
0.9
3.8 **
4.0
0.9
4.1 **
3.8
0.8
3.2 *
0.2
7 Making quizzes improves program-making ability.
3.9
0.8
4.7 **
4.2
0.9
4.3 **
3.7
1.1
2.1 +
0.7
8 Making quizzes improves knowledge of programming language grammar.
3.6
0.9
2.9 *
4.2
0.9
4.3 **
4.0
0.9
3.4 **
1.2
9 Making quizzes improves program knowledge.
3.7
0.8
3.4 **
4.2
0.7
5.6 **
3.9
0.7
3.9 **
1.2
10 You made quizzes expecting that they would be helpful to other learners.
3.6
1.2
2.0 +
3.6
1.2
1.6  
3.4
0.7
1.8  
0.1
11 You made quizzes being aware of what was important in learning.
3.7
0.9
3.2 **
3.5
0.9
1.9 +
3.8
0.9
2.8 *
0.3
12 You made quizzes being aware of intention of giving quizzes.
3.4
1.0
1.5  
3.6
0.9
2.2 *
3.6
0.7
2.7 *
0.3
13 You can not make quizzes from matters that I do not understand.
4.2
1.0
5.3 **
4.7
0.7
8.9 **
4.1
1.4
2.5 *
1.0
14 You studied in advance to make quizzes.
2.8
1.1
0.8  
3.5
1.2
1.4  
3.2
0.9
0.7  
1.6
15 You had a talk with other learners to make question.s
3.4
1.2
1.2  
3.2
1.0
0.6  
3.3
1.1
0.9  
0.1
16 Thinking about choices (wrong answers) is difficult.
3.6
1.0
2.4 *
3.3
1.4
0.8  
4.0
0.8
3.9 **
1.0
17 Thinking about choices (wrong answers) improves understanding of learning contents.
3.5
1.1
2.0 +
3.6
1.1
1.9 +
3.4
0.7
1.8  
0.9
18 Thinking about choices (wrong answers) improves learners’ motivation.
2.9
0.9
0.3  
2.9
1.3
0.2  
3.5
0.5
3.0 *
1.3
19 Thinking about choices (wrong answers) makes the knowledge of learning content secure.
3.3
1.2
1.0  
3.1
1.2
0.2  
3.6
0.7
2.7 *
0.6
20 Thinking of advice for choices (wrong answers) is difficult.
4.1
0.9
4.9 **
4.3
0.9
5.0 **
4.1
0.7
4.7 **
0.2
21 Thinking of advice for choices (wrong answers) improves understanding of learning content.
3.8
0.9
3.8 **
3.6
1.0
2.0 +
3.5
0.7
2.2 +
0.5
22 Thinking of advice for choices (wrong answers) improves learners’ motivation.
2.9
0.9
0.5  
2.7
1.4
0.8  
3.1
0.6
0.6  
0.5
23 Thinking of advice for choices (wrong answers) makes the knowledge of learning contents secure.
3.5
1.1
1.7  
3.5
1.4
1.3  
3.6
0.7
2.7 *
0.0
24 Quizzes made by others are difficult.
3.1
0.7
0.4  
3.7
0.9
2.6 *
3.9
0.6
5.0 **
5.0 *
*
25 Solving quizzes produced by others improves understanding of learning content.
3.9
0.8
4.7 **
4.6
0.5
10.7 **
4.1
0.7
4.7 **
2.9
26 Solving quizzes made by others improves learners’ motivation.
3.4
1.0
1.7  
3.8
1.1
2.3 *
3.9
0.9
3.3 **
0.8
27 Solving quizzes made by others makes the knowledge of learning contents secure.
3.8
0.8
4.2 **
4.2
0.8
4.8 **
4.2
0.8
4.8 **
1.4
28 Quizzes made by others make you aware of what is important in learning.
3.5
0.9
2.5 *
4.0
0.6
5.7 **
3.8
0.6
4.0 **
1.5
29 Blanks in quizzes made by others are appropriate.
3.6
0.8
3.0 **
3.9
0.7
4.7 **
3.8
0.6
4.0 **
0.8
30 Wrong answers made by others are appropriate.
3.6
0.8
3.4 **
3.7
0.9
2.6 *
4.0
0.8
3.9 **
0.7
31 Advice for wrong answers made by others is appropriate.
3.5
0.7
3.0 **
3.5
0.9
1.9 +
3.6
0.5
3.7 **
0.1
32 Evaluating quizzes made by others is difficult.
4.2
0.8
6.0 **
3.6
1.0
2.0 +
3.8
0.4
6.0 **
2.0
33 Evaluating quizzes made by others improves understanding learning contents.
3.2
1.3
0.6  
3.3
1.2
1.0  
3.9
0.7
3.9 **
1.3
34 Evaluating quizzes made by others improves learners’ motivation.
2.7
1.0
1.2  
3.4
1.1
1.3  
3.6
1.2
1.6  
2.7
35 Evaluating quizzes made by others is helpful to review learning contents.
3.6
0.8
3.0 **
3.6
1.1
1.9 +
3.8
0.8
3.2 *
0.2
36 Evaluating quizzes made by others improves program-making ability.
3.0
0.9
0.0  
3.2
1.2
0.5  
3.4
0.8
1.5  
0.5
37 Evaluating quizzes made by others improves the knowledge program language’s grammar.
3.4
0.8
1.9 +
3.5
1.1
1.6  
3.6
1.1
1.8  
0.2
38 Evaluating quizzes made by others improves program knowledge.
3.4
0.8
2.1 *
3.8
0.8
3.5 **
3.7
1.1
2.1 +
0.9
39 Evaluations made by others are appropriate.
3.8
0.7
4.7 **
3.8
0.9
3.0 *
3.6
0.7
2.7 *
0.3
40 You can accept evaluations made by others gratefully.
3.8
1.0
3.3 **
4.1
0.7
5.6 **
3.9
0.7
3.9 **
0.3
41 Evaluations made by others help you to modify your questions.
4.0
0.9
4.8 **
4.3
0.6
7.0 **
4.2
0.6
6.0 **
0.5
42 Evaluations made by others help you to modify your questions.
3.6
0.9
2.8 *
3.4
0.9
1.6  
4.0
0.7
4.7 **
1.4
43 The system’s quiz-making function is easy to use.
2.8
1.0
0.9  
3.1
1.0
0.3  
3.4
1.2
1.1  
1.2
44 The system’s evaluation function is easy to use.
3.0
1.0
0.0  
3.3
0.9
1.3  
3.6
0.8
2.3 +
1.4
45 The system’s evaluation browsing function is easy to use.
3.1
1.2
0.2  
3.3
1.1
0.8  
3.4
0.7
1.8  
0.3
3.5
0.5
4.3 **
3.7
0.5
4.8 **
3.7
0.5
4.9 **
0.7
 
**：　p  < .01　，　*：　 p < .05　，　+：　p < .1
Eevaluation Items
(1) Ascendant
(2) Median
(3) Descendant
Distribution
of
score groups
Ｎｏ．
F
Average
Multiple comparison
by
LSD method
 
TABLE III.  EXAM QUESTIONS 
Q.1 Fill in the blanks of algorithm to obtain product power of odds from one to n.
Q.2 Input integer number data and fill in the blanks of the program to obtain absolute figure abs of the value.
Q.3 Input n unknowns of data with the keyboard and store them into array a[]. Then fill in the blanks the program to obtain the maximum value amax of the data.
Q.4 Fill in the blanks of the algorithm to obtain nth multinominal using Horner’s method.
Q.5 Write the value when the following program is conducted (pointer variable).
Q.6 Fill in the blanks of the program of function DelBlk (), which stores the sequence of blanks in the array s[] as a single blank into the array t[].
Q.7 Make a program to obtain greatest common division gcd of two natural numbers a and b using the Euclidean algorithm.
Q.8 Make a program that presents when it is prime number and when it is not when a positive integer n (n>1) is input.
Q.9 Make a program of function sum () to obtain the sum of integer n to m. Then, n and m are arguments.
Q.10 Make a program of the function abs_fun() to obtain absolute values of integer data x of arguments.
Q.11 Make a program of the function fun() to input integer data z in all factors of the nth row and the mth column in integer type 2D array x[N][M] .
Q.12 Make a program using the function strleng() to the length of the array of arguments.
Q.13 Make a program using the function swap to interchange the values of integer a and b.
Questions to test
 C language
knowledge
Questions to test
programming
ability
 
111
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-328-5
eLmL 2014 : The Sixth International Conference on Mobile, Hybrid, and On-line Learning

