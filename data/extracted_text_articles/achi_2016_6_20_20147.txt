A Training-assistance System using Mobile Augmented Reality 
 for Outdoor-facility Inspection 
 
Yoshiki Yumbe 
Global Center for Social Innovation – Tokyo,  
Research & Development Group, Hitachi, Ltd. 
Tokyo, Japan 
e-mail: yoshiki.yumbe.bc@hitachi.com 
Osamu Segawa and Makoto Yamakita 
Chubu Electric Power, Co., Inc. 
Nagoya, Japan 
e-mail: Segawa.Osamu@chuden.co.jp
 
 
Abstract— 
A 
training-assistance 
system 
using 
mobile 
augmented reality (AR) for outdoor-facility inspection was 
designed, developed, and evaluated. In inspection training for 
pole-mounted communication facilities for electric power 
supply operation, the realization of efficient, effective, and 
autonomous learning is desired. In light of these, three AR 
functions supporting inspection training, namely, pole 
navigation, visualization for facility attributes, and facility-
defect search, were proposed. To realize these functions, a 
hybrid tracking method for accurate AR overlaying was 
proposed. Moreover, a prototype system was developed and 
evaluated at a real training site. The evaluation results show 
that the proposed system supports efficient, effective, and 
autonomous learning. In other words, AR technology can be 
applied to training in outdoor-facility inspection. 
Keywords-augmented reality; facility inspection; training 
assistance. 
I. 
INTRODUCTION  
Recently, demand for using smart devices has been 
growing, such as smartphones and tablets, to access various 
types of information during field work. Furthermore, with 
improving performance of such smart devices, “augmented 
reality” (AR) has been increasingly becoming a strong tool 
for supporting field work in various industrial segments [1]-
[6]. In the electric power industry, improving efficiency of 
facility maintenance while retaining reliability has become a 
significant issue. Conventionally, high reliability of pole-
mounted facilities for electric-power supply operation is 
ensured by periodic inspection. Recently, succession of 
inspection skills and maintaining inspection quality have 
become more important. Therefore, to nurture experienced 
inspectors, a supporting framework for efficient, effective, 
and autonomous learning is desired. As for the inspection 
training, a training assistance system using AR technology 
may become an useful solution.  
In this work, a training-assistance system using mobile 
AR technology for inspection training of outdoor facilities 
was proposed. The organization of the paper is as follows. In 
section II, the workflow of typical inspection training was 
surveyed. On the basis of survey results, required AR 
functions for supporting the training were established in 
section III. After the requirements were defined, an AR-
based training-assistance system and an effective user 
interface were designed, and several technical methods for 
the system were proposed in section IV.  In section V, a 
prototype system was developed. In section VI, the 
availability and practicability of the prototype was evaluated 
by active workers and trainers at a real training site. On the 
basis of the evaluation results, the applicability of mobile AR 
technology to training in outdoor-facility inspection was 
examined. In section VII, some related works are introduced 
and compared with our work. Finally, the conclusion and 
future works are described in section VIII. 
II. 
ISSUES CONCERNING INSPECTION TRAINING AND 
RESEARCH OBJECTIVE 
Electric-power companies manage their communication 
facilities for electric-power supply operation. The inspection-
target facilities (e.g., communication lines and ancillary 
equipment such as hangers and closures) are mounted on 
utility poles. Conventionally, communication facilities are 
maintained by periodic inspection. During the inspection of a 
facility, inspectors visually check the condition of the 
facilities (e.g., cracks, rust, distortion, various separation 
distances, and botanical collision). To check a facility 
comprehensively, an inspector has to learn the accurate 
knowledge about the target facilities, namely, the type, 
specification, normal and abnormal conditions. Recently, 
succession of inspection skills and maintaining inspection 
quality have become more important. Therefore, to nurture 
experienced inspectors, an effective training framework is 
desired. The objectives of the inspection training are 
described as follows. 
 
(1) Ensure trainees understand types, specifications, and 
structures of the facilities. 
(2)  Ensure trainees understand how to inspect the facilities. 
That is, trainees are taught to concretely judge whether 
conditions of each facility are normal or abnormal and 
find defects comprehensively. 
 
In the inspection training, the trainer gives several 
trainees specific guidance on inspection know-how. 
Improving efficiency of the training 
and trainees’ 
understanding are crucial issues.  
116
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

In consideration of these issues, AR technology was 
applied to facility-inspection training with the aim of 
realizing efficient, effective, and autonomous learning. 
Furthermore, a prototype training-assistance system using 
mobile AR technology was designed and developed, and its 
availability and practicability were evaluated at a real 
training site. 
III. 
FUNCTIONAL REQUIREMENTS 
First, in this section, a conventional training workflow is 
defined. Second, functional requirements to support the 
workflow and the system concepts are proposed. 
A. Training Workflow 
The inspection training is performed in a training site 
containing 
mock 
utility 
poles 
and 
pole-mounted 
communication facilities. Certain types of  defects were 
preliminarily set in the mock facilities. The conventional 
training workflow is explained as follows. First, the trainees 
confirm the inspection target on a (paper) facility map. They 
move to the target and identify it while confirming it on the 
map. They confirm the target facility and its details (type, 
specification, structure, and so on) using paper-based 
manuals. After confirming the facility details, they check the 
condition of the target against a checklist. In other words, the 
trainees search for the preliminarily set facility defects. 
When they find a defect, they write an inspection report. 
These steps are performed at all facilities. Finally, the 
trainees receive feedback from their trainer. 
B. Functional Requirements and System Concept 
Functional requirements for the training-assistance 
system using mobile AR are described as follows. The 
system is “paper-less” and implemented on a general-
purpose tablet. In view of applicability to the inspection 
training, the conventional training workflow should also be 
supported by the system. To realize efficient, effective, and 
autonomous learning, the three main AR functions required 
are summarized as follows. 
 
(1) Pole navigation 
Trainees confirm their location and surrounding facilities 
on a digital facility map and AR. The system assists in 
identifying the target facility. 
(2) Visualization of facility attributes 
      Trainees acquire facility information (type, specification, 
structure, and so on) by AR, which enables the user to 
link the real facility to that information. 
(3) Facility-defect search 
The system not only provides defect information to 
trainees but also assists autonomous defect search 
utilizing AR. 
IV. 
SYSTEM OVERVIEW 
This section describes technical detail of the proposed 
system and the concrete methods to satisfy the three above-
listed AR functional requirements. 
A. Pole Navigation 
Conventionally, trainees move to a target facility while 
confirming the target location on a map. Therefore, a 
facility-navigation function for identifying the target was 
devised. The function informs the trainees of their relative 
locations in regard to surrounding facilities. The proposed 
pole-navigation method and user interface are shown 
schematically in Figure 1. The location (latitude and 
longitude) of each utility pole is stored in a database. A 
rough user location is obtained from the GPS (global 
positioning system). User heading is obtained from 
acceleration and geomagnetic sensors mounted on the tablet. 
First, surrounding facility’s data is retrieved from the 
database on the basis of GPS location of the user. Location 
and heading of the facility in relation to the user are 
calculated. On the basis of the calculation results, AR tags 
are mapped onto the tablet’s screen as shown in Figure 1. 
The center of the screen represents user location. Each AR 
tag shows the relative distance and heading of surrounding 
poles. Relative distance from each pole to the user is 
represented by the tag’s color and size. These AR tags are 
rendered every time the GPS location and user heading are 
changed. 
 
Pole ID: 001
(lat001, lng001)
Pole ID: 002
(lat002, lng002)
Pole ID: 003
(lat003, lng003)
GPS location
User heading
Camera preview
Pole tag
Camera heading
pole ID:001
distance: 15m
pole ID:002
distance: 10m
pole ID:002
distance: 30m
GPS location
 
Figure 1.  Pole-navigation function and user interface. 
Pole ID: XXX
Assembling 
pattern (X)
Assembling 
pattern (X)
Closure ID: XX
Com line A
Com line A
Detailed Info
(picked up from conventional 
training manuals)
Camera preview
AR tag -> tap
 
Figure 2.  Visualization of facility attributes and user interface. 
B. Visualization of facility attributes 
This 
function 
enables 
visualization 
of 
facility 
information (hereafter, attributes) using AR. The function 
and user-interface design are summarized in Figure 2. The 
AR contents are defined for each type of facility. Detailed 
information is not suitable for visualization by AR because 
117
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

it is “floating” in accord with the live camera motion of the 
tablet. Therefore, AR is only used to point out the position 
of the target. Facility ID or type is displayed using AR. If 
the user taps an AR “balloon,” detailed information appears 
on the right side of the screen. In this way, the user can link 
the real facility to related information. 
 
To realize the function explained above, an accurate AR 
method is needed. In general, AR technologies are classified 
as vision-based or location-based methods [7][8]. Vision-
based methods identify target objects by using features 
obtained from images. Moreover, they can be categorized as 
either of two approaches: marker-based [9] or marker-less 
[4]. In case of marker-based approaches, the target objects 
are identified by recognizing artificial markers. Applying 
marker-based approaches to pole-mounted facilities seems a 
distant prospect because an enormous number of markers 
are required. Location-based methods, on the other hand, 
identify target objects on the basis of GPS location, heading, 
and geographical locations of target objects [10][11]. While 
such approaches have a merit of low computational cost, 
their identification accuracy is low because of measurement 
errors. The location-based method seems to be suitable for 
this case because geographical locations (latitude, longitude, 
and ground height) of the facilities are already stored in the 
database.  
Therefore, in our previous study, a robust identification 
algorithm was proposed [12]. The algorithm is an advanced 
approach for conventional location-based methods. It uses 
GPS data as well as data from acceleration and geomagnetic 
sensors. Concretely, the facilities are identified on the basis 
of not only a tablet’s current location and heading obtained 
from these sensors but also object distance (i.e., the distance 
between the user and the object being inspected) by a 
triangulation method using acceleration and geomagnetic 
sensors. The facilities can be identified robustly without 
being influenced by measurement errors of the sensors. 
A target facility is initially registered and AR objects are 
overlaid accurately by a robust identification method. After 
the target is identified, it should be continually tracked so 
that the AR contents can be overlaid accurately. Therefore, a 
hybrid tracking method is proposed. The proposed method 
realizes accurate tracking using a combination of tablet’s 
attitude angles and line-detection results from camera 
images (see Figure 3). First, the overlaid AR objects after 
the robust identification keep tracking the target facility by 
using the tablet’s attitude angles (yaw, pitch, and roll) as 
shown in Figure 3(a). Simultaneously, line objects are 
detected by using a probabilistic Hough transform and line-
segment clustering (Figure 3(b)). The objectives of line 
detection are horizontal lines corresponding to the 
communication lines and vertical lines corresponding to the 
utility pole. In an outdoor situation, it is difficult to detect 
these lines only because captured images contain various 
background noises. Detected line objects are therefore 
narrowed down (Figure 3(c)). Concretely, detected line 
objects located near the sensor-based AR objects (Figure 
3(a)) are extracted. The amount of horizontal correction is 
calculated by using the AR object for the pole and a couple 
of vertical lines (Figure 3(d)). The amount of vertical 
correction is calculated by using the AR object for the 
communication lines and the same number of horizontal 
lines (In Figure 3(e), the number of lines is two). The 
overlaid positions of the AR objects are translated by using 
these correction amounts. These steps are launched after the 
identification process is finished and repeated. In the 
training operation, the AR rectangles and lines shown in 
Figure 3(a) are hidden, and this procedure is performed in 
the background. The accurate tracking by the proposed 
hybrid tracking method realizes our training assistance 
functions. 
(a) Sensor-based tracking
(b) Line-detection results (c) Narrowing down of line objects 
(d) Horizontal correction using vertical lines
(e) Vertical correction using horizontal lines
Pole object
(sensor-based)
communication
line object
(sensor-based)
Line objects
(detected from
image)
Pole
Extracted 
horizontal 
line objects
Extracted 
vertical 
line objects
Located near the 
sensor-based AR objects
Amount of horizontal
correction
Amount of vertical
correction
 
Figure 3.  Summary of hybrid tracking method. 
C. Search for facility defects 
As mentioned before, the training facilities have some 
preliminarily set defects. The trainees learn how to inspect a 
facility by searching for these defects. The training-
assistance system should not only provide defect information 
to the trainees but also assist autonomous defect search using 
AR. Therefore, a function for searching for autonomous 
defects is proposed. A summary of the proposed function is 
described in Figure 4. The defect locations (latitude, 
longitude, and ground height) are also stored in the database. 
AR objects for the defects are overlaid as transparent objects. 
The correction amounts obtained from the hybrid tracking 
method are used to overlay the AR objects for defects, too. 
First, the user searches for a facility defect. If the user finds a 
defect, they capture an image containing the defect  the 
inside of the blue box shown in Figure 4(b). After capturing 
the image, the user selects a corresponding defect type from 
a check list. Once a defect type is selected, the captured 
118
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

image and selected defect type are linked and recorded. After 
the defect search is finished, the recorded results (i.e., defect 
type and position) are evaluated. That is, captured-image 
position and selected-defect type are checked by comparing 
them with actual defect data, and the user is informed 
whether or not their recorded data is correct. Finally, a 
hidden AR object is displayed to inform the user of the 
correct data.  
The proposed function assists the trainees to search for 
facility defects autonomously while actually thinking for 
themselves. Moreover, learning how to inspect facilities 
becomes more enjoyable for the user in a similar manner to a 
treasure hunt. 
Pole
User
Communication line
Defect
Screen
Defect
Pole
Pole
Communication line
Tablet
 
(a) Example of defect search. 
Camera preview
Transparent 
AR object
No.
Check items
1
Vegetation
2
Separation distance
3
…
4
…
Add
Add
Add
Add
No.
Check items
○/×
1
Separation distance
○
2
3
…
Results
Done
Pole
Pole ID: XXX
(i) Search defect
-> capture image
(ii) Select defect type
from check list
-> found defect is recorded
(iii) After done button is pushed, 
recorded data are evaluated.
(iv) Correct defect
is displayed
 
(b) Design of user interface.  
Figure 4.  Summary of searching for facility defects. 
V. 
SYSTEM IMPLEMENTATION 
Based on the technical methods described above, the 
prototype system was implemented on an Android tablet. 
Operation examples of each function are shown in Figures 5, 
6, and 7. In Figure 5, an example of pole navigation is shown. 
On the left side of the screen, relative distance of each pole 
from the user is represented by the tag’s color and size. A red 
tag means near the pole. On the right side of the screen, a 
facility map and the user’s location are displayed.  
Examples of the function for visualizing facility 
attributes are shown in Figure 6. AR is only used to point out 
the target position. Facility ID or type is overlaid using an 
AR balloon. In Figure 6(a), a pole ID is overlaid on a live 
camera view. If the user taps the AR balloon, detailed 
information about the pole is displayed on the right side of 
the screen. In Figure 6(b), two assembly patterns, one closure, 
and two communication lines are pointed out by the AR 
balloons. As shown in Figure 6, the AR objects are overlaid 
accurately by the robust identification and the hybrid 
tracking methods. An example of the hybrid tracking is 
shown in Figure 7. In normal operation, the hybrid tracking 
is performed in the background. Therefore, the AR 
rectangles and detected lines are hidden. In Figure 7, the blue 
rectangle and the green -lines were overlaid by sensor-based 
tracking. The red lines were obtained by line detection. The 
amounts of horizontal and vertical corrections (expressed in 
pixels) obtained by the hybrid tracking are displayed on the 
upper side of screen. 
 
 
Figure 5.  Pole navigation. 
 
(a) Utility pole. 
 
(b) Attachments (left) and communication lines (right). 
Figure 6.  Visualization of facility attributes. 
119
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

An example of the facility-defect search function is 
shown in Figure 8. In this example, one facility defect was 
preliminarily set. The defect type is insufficient separation 
between two communication lines. In Figure 8(a), the user 
searches for the defect and captures an image containing the 
detected defect point inside the blue box. After capturing the 
image, the user selects a corresponding defect type from the 
check list on the right side of the screen. In Figure 8(b), the 
recorded data (position and type) are evaluated, and the user 
is informed of the evaluation result. After that, the hidden 
AR object is displayed to inform the user of the correct data. 
As explained above, the correct operation of proposed 
AR functions were confirmed by prototyping. 
 
 
Figure 7.  Hybrid tracking. 
 
(a) Search for defect . 
 
(b) Evaluate recorded data and inform user 
Figure 8.  Search for facility defect. 
VI. 
EVALUATION 
The developed AR system was evaluated as follows. On 
the basis of the evaluation results, the applicability of the 
proposed system to outdoor-facility-inspection training was 
examined. 
A. Evaluation Approach 
The proposed AR system was evaluated in the field (at a 
training center). In the evaluation, seven users were selected 
from active workers and trainers belonging to the power 
distribution department, and the communication facility 
department of Chubu Electric Power Co., Inc. They 
evaluated the system by comparing it with that used in 
conventional inspection training (because they already have 
knowledge of the training). While using the proposed 
system in the evaluation trial, they experience the training 
workflow. After finishing the trial, each user evaluated the 
system by questionnaire, which was based on the web-
usability scale (WUS) [13], the technology-acceptance 
model (TAM) [14], and the AR acceptance model [15]. The 
questionnaire consists of 20 statements on a five-point scale 
(1 (disagree) to 5 (agree)) and a free-comment field. The 
statements were categorized into five categories: usability, 
autonomy, efficiency, understanding, and applicability. 
Autonomy, efficiency, understanding are defined in 
accordance with our research objective. Besides, usability is 
an important factor because insufficient usability may 
hinder the evaluation of the proposed AR functions. The 
statements are listed as follows. 
 
Usability: 
 
The system was easy to use. 
 
It responded quickly to my commands. 
 
It was easy to understand. 
 
It was easy to make substantial use of the system. 
Autonomy: 
 
The support of a trainer was unnecessary.  
 
Learnt to use the system was anxiety-free.  
 
Learning by using the system was enjoyable.  
Efficiency:  
 
Facility information could be acquired when needed.  
 
Information necessary for training could be acquired.  
 
Learning was smooth.  
 
The system is more useful than paper-based manuals.  
Understanding:  
 
It was easy to find where a facility.  
 
I could determine facility attributes easily.  
 
I could quickly learn how to inspect a facility.  
 
The AR contents in the left side of screen are useful.  
 
The detailed information appearing on the right side of 
screen is useful.  
Applicability: 
 
The system is applicable to inspection work.  
 
The system matches the objective and workflow of 
inspection training.  
 
The system is promising for inspection training.  
120
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

 
I will recommend the system to new employees. 
B. Evaluation Results 
The evaluation results are summarized and discussed. In 
Figure 9, the average scores for each category were 
expressed as a radar chart. Average score and standard 
deviation for each statement are listed in Table 1. According 
to the figure, the average score for each category was more 
than 3.0, which shows the proposed AR system was given 
positive feedback. The category “efficiency” received the 
highest score among the five categories. Especially, the 
statements “Facility information could be acquired when 
needed.” and “Information necessary for training could be 
acquired.” received high scores over 4.0. For “autonomy”, 
the statement “Learning by using the system was 
enjoyable.” also received a high score over 4.0. The 
evaluation results show that the proposed AR functions and 
system are useful for the inspection training. As explained 
above, whereas the users give positive feedbacks regarding 
the proposed AR functions and system, the category 
“applicability” gets a lower score than those for the other 
categories. It consists of several statements for evaluating 
the user’s intention to apply the AR system in inspection 
training. The low score for applicability infers that the users 
have some reservations in regard to applying the AR system 
in inspection training. To determine the reason for the 
slightly lower score for applicability, the free comments 
written by the users are reviewed as follows. Some 
examples of the comments are listed below. 
 
 
This system might miss facility defects that should be 
found.  
 
When the user moves in the wrong direction or 
chooses the wrong target, assist functions to correct 
these errors are required. 
 
The system is useful because it assists with an 
autonomous defect search. However, the training 
contents are insufficient. For example, the user should 
be taught not only how to identify each defect but also 
why it is defect and the safety risk is poses. 
 
These comments suggest two future tasks in regard to 
improving the proposed AR system. First, assist functions to 
correct wrong operation by the user are required. It is 
assumed that these comments may influence the score for 
the statement “Learning to use the system was anxiety-free.” 
Second, more training materials should be prepared. The 
AR system should cover the same training contents as those 
taught in the inspection training course. Moreover, the 
proposed AR system will be more effective if additional 
training materials are displayed using AR. 
As described above, the evaluation results show that the 
proposed AR functions and system support efficient, 
effective, and autonomous learning. If the two above-
described tasks are accomplished, the AR system will be 
truly applicable to training in outdoor-facility inspection. 
3.7 
3.7 
3.8 
3.8 
3.4 
1.0 
2.0 
3.0 
4.0 
5.0 
Usability
Autonomy
Efficiency
Understanding
Applicability
 
Figure 9.  Summary of evaluation result. 
TABLE I.  
AVERAGE SCORE AND STANDARD DEVIATION FOR EACH 
STATEMENT. 
Categories
Statements
Average
scores
Standard 
deviations
Usability
The system was easy to use.
3.6 
0.7
It responded quickly to my commands.
3.1 
1.0
It was easy to understand.
3.9 
1.0
It was easy to make substantial use of the system.
4.1 
1.0
Autonomy
The support of a trainer was unnecessary.
3.6 
0.9
Learnt to use the system was anxiety-free.
3.0 
1.1
Learning by using the system was enjoyable.
4.4 
0.5
Efficiency
Facility information could be acquired when needed.
4.3 
1.0
Information necessary for training could be acquired.
4.1 
0.8
Learning was smooth.
2.9 
1.0
The system is more useful than paper-based manuals.
4.0 
1.1
Understanding
It was easy to find where a facility.
3.6 
0.9
I could determine facility attributes easily.
3.7 
1.0
I could quickly learn how to inspect a facility.
3.3 
1.2
The AR contents in the left side of screen are useful.
3.9 
0.8
The detailed information appearing on the right side of screen is useful.
4.4 
0.5
Applicability
The system is applicable to inspection training.
3.1 
1.1
The system matches the objective and workflow of inspection training.
3.7 
1.0
The system is promising for inspection training.
3.4 
1.3
I will recommend the system to new employees.
3.1 
1.0
 
VII. RELATED WORKS 
In industrial segments, several researchers have discussed 
applying AR technology to industrial education and training. 
For example, an AR-based educational system for 
automotive engineering has been proposed [1][2]. Moreover, 
support systems for aircraft maintenance, namely, a marker-
based registration method and a marker-less camera-pose 
estimation method, respectively, have been proposed [3][4]. 
An interactive AR application prototype for industrial 
education and training applications has also been proposed 
[5]. In [5], their system was applied to a simple virtual 
demonstration of assembling/disassembling procedures. In 
these works, the target facilities onto which AR information 
is overlaid are used indoors or located locally. Moreover, the 
above-described systems only present maintenance or 
assembly procedures by AR. From the perspective of 
training, these systems may not support autonomous learning 
sufficiently. In industrial education and training, trainees 
should be taught not only “how” they should work but also 
“why” they should work in accordance with the procedures 
in the manual. As described above, AR-based autonomous 
training systems that teach the ability to think for oneself  
have not been studied so much. 
121
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

On the contrary, a mobile AR application for visualizing 
maintenance data about power-distribution facilities was 
proposed [6]. It was developed for facility-inspection work, 
not for inspection training. In detail, a conventional location-
based approach was applied. However, the measurement 
errors of sensors mounted on a tablet were not considered. In 
the fields of industrial education and training area, applying 
AR technology to outdoor widely-scattered facilities has not 
been studied so much.  
VIII. CONCLUSION 
A 
training-assistance 
system 
for 
outdoor-facility 
inspection using mobile augmented reality was developed 
and evaluated. In early phase of the research, conventional 
inspection 
training 
for 
pole-mounted 
communication 
facilities was surveyed. On the basis of the survey results, 
three AR functions to realize efficient, effective, and 
autonomous learning, namely, a pole-navigation function, a 
visualization function for facility attributes, and a facility-
defect search function, were proposed. A hybrid tracking 
method was also proposed to realize accurate AR overlaying. 
Moreover, the prototype system was evaluated by active 
workers and trainers using questionnaire at a real training 
site. The evaluation results show that the proposed system 
supports efficient, effective, and autonomous learning. In 
other words, AR technology can be applied to training in 
outdoor-facility inspection. 
In future work, the proposed AR system will be 
improved on the basis of the feedback obtained from the 
evaluation. Furthermore, the effects of using the proposed 
system on training will be evaluated by further field 
evaluations by more test subjects.  
After applying the proposed system to the facility 
inspection training, some technologies for supporting 
inspection work will be developed and evaluated (e. g., 
facility defect detection using image recognition). 
ACKNOWLEDGMENT 
The authors thank the staffs at Chubu Electric Power, Co., 
Inc., who gave us the opportunity to evaluate the prototype 
system and shared their knowledge of facility-inspection 
training. 
REFERENCES 
[1] I. Farkhatdinov and J.-H. Ryu., “Development of Educational 
System for Automotive Engineering Based on Augmented 
Reality”, In International Conference on Engineering 
Education and Research, 2009. 
[2] H. Regenbrecht, G. Baratoff, and W. Wilke., “Augmented 
Reality Project in Automotive and Aerospace Industry”, IEEE 
Computer Graphics and Applications, Vol. 25, 6, pp. 48-56, 
2005. 
[3] T. Haritos and N.D. Macchiarella, “A Mobile Application of 
Augmented Reality for Aerospace Maintenance Training”, In 
Proc. DASC 2005, Vol. 1, pp.5.B.3 - 5.1-9, 2005. 
[4] F. De Crescenzio, M. Fantini, F. Persiani, L. Di Stefano, P. 
Azzari, and S. Salti., “Augmented Reality for Aircraft 
Mintenance Training and Operations Support”, IEEE 
Computer Graphics and Applications, volume 31, pp. 96–101, 
2011. 
[5] B. Besbes, S.N. Collette, M. Tamaazousti, S. Bourgeois, and 
V. Gay-Bellile., “An Interactive Augmented Reality System a 
Prototype for Industrial Maintenance Training Applications”, 
In Proc. IEEE/ACM International Symposium on Mixed and 
Augmented Reality, pp.  269-270, 2012. 
[6] A. W. McMorran, S. E. Rudd, John J. Simmins, N. 
McCollough, and C. M. Shand., “Field Force Data 
Visualization: Developing an Open Mobile Platform for 
Integrated Data Access”, In Proc. IEEE Power and Energy 
Society General Meeting, pp. 1-5, 2012. 
[7] R. Azuma, Y. Baillot, R. Behringer, S. Feiner, S. Julier, and B. 
MacIntyre., “Recent advances in augmented reality”, In IEEE 
Computer Graphics and Applications, volume 21, issue 6, pp. 
34-47, 2001. 
[8] D.W.F. van Krevelen and R. Poelman., “A survey of 
augmented reality technologies, applications and limitation”, 
In International Journal of Virtual Reality, volume 9, number 
2, pp. 1-20, 2010. 
[9] M. Billinghurst, M. Hakkarainen, and C. Woodward., 
“Augmented assembly using a mobile phone”, In Proc. 7th 
International 
Conference 
on 
Mobile 
and 
Ubiquitous 
Multimedia, pp. 84–87, 2008. 
[10] W. Piekarski, B. Gunther, and B. Thomas., “Integrating 
virtual and augmented realities in an outdoor application”, In 
Proc. 2nd IEEE and ACM International Workshop on 
Augmented Reality, pp. 45-54, 1999. 
[11] T. Höllerer, S. Feiner, and J. Pavlik.. “Situated documentaries 
embedding multimedia presentations in the real world”, In 
Proc. 3rd International Symposium on Wearable Computers, 
pp. 79-86, 1999. 
[12] Y. Yumbe, and N. Furulawa, “A Robust Location-based 
Augmented-reality System for Supporting Inspection of 
Power-distribution Facilities”, In Proc. The 76th National 
Convention of Information Processing Society of Japan, pp. 
9-10, 2014. 
[13] K. Nakagawa, T. Suda, H. Zempo, and K. Matsumoto, “The 
Development of Questionnaire for Evaluating Web Usability”, 
Human Interface Society 10th Symposium, pp.421-424, 2001.  
[14] F. D. Davis, R. P. Bagozzi, and P. R. Warshaw, “User 
acceptance of computer technology: A comparison of two 
theoretical models”, Management Science 35: pp. 982–1003, 
1989. 
[15] M. Leue, D. tom-Dieck., and T. Jung, “A Theoretical Model 
of Augmented Reality Acceptance”, e-Review of Tourism 
Research, pp.1-21, 2014.  
 
122
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-468-8
ACHI 2016 : The Ninth International Conference on Advances in Computer-Human Interactions

