A Model for Experience-Based Agent Specific Trust 
 
Mats Neovius 
Faculty of Natural Sciences and Technology 
Åbo Akademi University 
Turku, Finland 
Email: mneovius@abo.fi 
 
 
Abstract — Contemporary computerized tasks increasingly 
depend on inherently inaccurate information provided by 
autonomous agents. Reasons for the information inaccuracy 
are many, including the uncertainty in measurement 
(calibration 
errors), 
the 
process 
inherent 
inaccuracy 
(rounding), changing level of quality and, when humans are 
involved, differences in preferences (bias), (un)intentional 
violation of expectation to mention a few. Parameterization of 
this inaccuracy is demanded for prompt and justified adaption. 
Frequently, this parameterization is overlooked when models 
for reasoning on the inaccuracies are presented. In this paper, 
we address the parameterization of inaccuracy by an 
experience-based model. The model is based on Dempster-
Shafer theory of evidence that relies on a history of experiences 
of subjective satisfaction on some provided data. From this 
history, the model derives the warranted belief and certainty 
that may justifiably be placed on the acquired data. The model 
facilitates decay and abstraction of a subset of history to a 
versatile score. This paper’s contribution is in showing the 
experience-based model’s generality and versatility by 
mapping it to EigenTrust, Subjective Logic and probabilistic 
trust management models.   
Keywords- Experience-based trust; multi-agent; evicence 
theory; adaptive systems. 
I. 
 INTRODUCTION 
Collective 
intelligence, 
collaborative 
intelligence, 
participatory sensing and many related concepts share the 
idea of a set of decentralised autonomous agents interacting 
for a cause. This cause, whatever it may be, is realised as a 
resource that the provider(s) possess(es) and the consumer 
desires. Realistic examples of such resources include a 
measurement of a sensor, information an agent is willing to 
share. In such a setting, the level of trust the consuming 
agent may justifiably place on an acquired resource is 
inherently incomplete. This is due to the continuously 
changing context in which the resource was established, i.e., 
deviation in calibration, changes in temperature, mood, bias, 
time etc. Thus, though the provider would willingly and 
rightfully (untampered) share a resource, it may still be 
perceived by an agent as an unreliable provider in context. 
These 
inherent 
inaccuracies 
are 
acknowledged 
in 
participatory sensing [1] and as the parameters of quality of 
context by Buchholz et al. [2] as: precision (accuracy), 
probability of correctness (unintentional errors, e.g., bugs), 
trustworthiness, resolution (granularity, rounding) and up-to-
dateness (age of measurement). They define trustworthiness 
as “how likely it is that the provided information is correct” 
[2] and as a parameter that the consumer evaluates on the 
provider. For the consumer (hereafter trustor) to evaluate the 
level of trust in a context on the provider (hereafter trustee), 
the history of experiences may be utilised.  
An experience, as considered in this paper, is a first-hand 
posterior (subjective) evaluation by the trustor on a resource 
provided by the trustee in a proposition. The set of first-hand 
experiences is an agent’s experience history. When 
combining several agents’ experiences, the level of trust 
becomes reputation-based; a concept originally coined by 
Barber [3]. In reputation-based trust, referral experiences are 
used as witnesses to augment the first-hand experiences. 
Thus, reputation-based trust calls for trust transitivity and a 
means to discount the referrals’ experiences. Further, 
combining the history of experiences on a system’s global 
level provides a reputation of “what is generally said or 
believed” [4] about the trustee. This global view assumes a 
ground truth to exist that all trustees agree on. Thus, we 
model an experience as a posterior subjective evaluation by 
the trustor on the trustee at a datum in a proposition by a 
score. This four tuple view excluding the datum is shared by 
the FIdes REputation (FIRE) model [5]. Characterising for 
agent specific trust relying on experiences is that initially, in 
the absence of experiences, the level of trust should be 
vacuous. A vacuous level is the level of full uncertainty. The 
level of uncertainty is sometimes called the level of 
confidence [6]. We consider all experiences to increase 
certainty (decrease uncertainty); research not agreeing on 
this view exists [7].  
In this paper we parametrize inaccuracy in a 
computationally light experience-based general trust model. 
The model features learning to trust and means to build and 
maintain a level of trust within group of agents (agent 
societies) [8]. It was originally developed for deriving the 
level of momentary trust on continuously changing, 
subjective and inherently inaccurate data with varying 
quality [9]. The view is sketched in Figure 1, which is 
inspired by the sentient object model by Fitzpatrick et al. 
[10]. In Figure 1, an agent may consume resources of other 
agents or inquire agents as referrals. The acquired resources 
may be weighted by the momentary discounted level of trust 
the trustor has in the trustee and the level the trustee claims 
in the resource. If triggering an actuator, the posterior trust 
level forms the basis for an experience. If providing the level 
of trust in a trustee further to another agent, this agent acted 
as a referral. On this view, this paper outlines the model for 
10
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-463-3
ADAPTIVE 2016 : The Eighth International Conference on Adaptive and Self-Adaptive Systems and Applications

storing, inquiring, delegating, decaying and abstracting the 
referrals provided experiences preserving a sense of privacy. 
The contribution of this paper is that we show the mapping 
of the general model to well-known trust management 
models from the autonomous agent systems point of view.  
 
Figure 1. The sentient agent model. 
The outline of this paper is as follows: in Section II we 
provide the motivating background and present related work. 
Following this, Section III introduces the foundation for the 
general experience-based trust model from a multi-agent 
perspective. Section III also defines the general model, of 
which a variant has successfully been implemented on in-
house temperature data [9]. Section IV provides the 
contribution of this paper in the form of motivating the 
generality and versatility by mapping it to other 
computational models. Finally, Section V imposes a critical 
discussion on the findings and concludes the paper. 
II. 
BACKGROUND AND RELATED WORK 
Traditionally, trust in the context of computers related to 
authorisation of agents by security policies to access 
resources. This is an example of policy-based trust, a 
concept originally introduced by Blaze et al. [11] as a variant 
for specifying such security policies of a resource in terms of 
credentials and relationships for authorisation, also known as 
resource access trust [12] and credential based trust [13]. 
Fundamental for this is that these policies are effectively 
Boolean predicates and can be modelled mathematically 
within frameworks [13] [14] [15] providing an absolute level 
of trust in a proposition. For example, with respect to file-
access rights, an agent may be trusted on a partially ordered 
discrete scale of none ≤ read ≤ read/write to the extent of 
read stating absolutely that this agent may not write the file 
under any circumstances. Implementations of policy-based 
trust include access control and firewall rules. However, as 
this paper considers agent specific trust for setting the level 
of reliance on a resource by experience, rather than access to 
it by policies, this paper will not consider policy-based trust 
as such. Interested readers are directed elsewhere [16].  
Autonomous agents may in contemporary open systems 
be either software agents or human agents. Examples of such 
systems include Multi-Agent Systems and the "things" in the 
Internet of Things initiative. Regardless of the type of the 
agent, the benefits are in agent collaboration. This 
collaboration implies a sense of mutual trust between the 
interacting agents. However, in the set of agents providing a 
resource, the consuming agents need to “know which 
interaction partners to trust and how to select them” [17]. 
Moreover, as the preferences of the trustor may be 
subjective, or the behaviour of the trustee may change, the 
computational trust management system needs to be adaptive 
in providing the momentary level of trust. For this, 
experience-based trust models relying on authentication of 
the agent and its behavioural history recorded as experiences 
may be used. Related work on similar means only 
considering the first-hand experiences and the global 
reputation include TRAVOS (Trust and Reputation model 
for Agent-based Virtual OrganisationS) [6].  
Implementations of experience-based trust models may 
be centralised or distributed. In a centralised environment 
dedicated agents gather all experiences making the level of 
experience-based trust representing the collective ‘belief’, 
‘doubt’, ‘evidence’ or ‘support’ that the trustee will perform 
in accordance with the collective’s shared expectations. 
Examples include online auction sites such as Ebay, product 
review sites such as Epinions, and discussion forums 
(Slashdot’s karma), to mention a few. In centralised systems, 
the score type is typically uniform, e.g., in Ebay {-1, 0, 1}, 
and the proposition the "item to be as described". For such, 
research on forgiveness and regret in social online settings 
evaluating, among others, the EVENT with respect to the 
agent’s reputation have been researched elsewhere [18]. 
In a distributed system, where each agent stores its own 
possibly subjective experiences, there is no global objective 
level of trustworthiness. For the agents to acquire second-
hand trust levels (using referrals), the trust score level needs 
to be uniform. They are frequently partially ordered and 
often totally ordered [19]. Existing representations include 
{0, 1}, {-1, 0, 1} with -1 ≤ 0 ≤ 1, any real in [0, 1], {low, 
med, high} with low ≤ med ≤ high. Related work often 
overlooks the merger of a set of such scored experiences or 
provides a level with semantics such as "the greater the 
better" or a probability [20]. Such models work well when 
assuming that each agent has an objective level of trust and 
the model's task is to figure this out [21], e.g., determining if 
a dice is biased by repeated testing that is a stochastic 
processes for which statistical and probabilistic model 
checkers have been developed. 
In an open system assuming biased agents with non-
uniform preferences, varied aspiration levels and possible 
performance changes in the producers, stochastic processes 
do not suffice. In such settings, a momentary and agent 
specific level of trust is reasonably sought. On this, related 
literature has applied logical reasoning on (i) binary and 
discrete values, (ii) fuzzy on continuous values, (iii) 
transitivity and (iv) probabilistic reasoning on a value range. 
Existing implementations of these include (i) summation 
[22] [23], (ii) Regret system [24], (iii) PageRank [25], and 
(iv) Βpdf [26] [27] [28], EigenTrust [29] respectively. Thus, 
open systems demand an agent specific versatile model 
considering the subjectivity, means to store and share levels 
of trust while preserving the referral’s privacy. Moreover, as 
of the limited evidence, the trustor’s level of (un)certainty 
need to be parameterized; with the initial level of ‘no 
certainty’. This level of trust is dynamic, emergent, 
incomplete, relative, subjective and decentralised making the 
experience based trust systems very hard (if not impossible) 
to define formally [13].  
Computational models for such a level “aims at 
supporting a decision making by computational agents in the 
11
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-463-3
ADAPTIVE 2016 : The Eighth International Conference on Adaptive and Self-Adaptive Systems and Applications

presence of unknown, uncontrollable and possibly harmful 
entities and in contexts where the lack of reliable information 
makes classical techniques useless” [11]. Common to such 
models are the demand of good quality inputs. To the best of 
our knowledge, general models capturing the fundamentals 
of trust calculations have been considered by Krukow et al. 
[13] [30]. TRAVOS [6] model considered a very similar 
view, however, omitting decay or discounting of second-
hand trust levels that they correctly note to be truth tellning. 
III. 
EXPERIENCE-BASED TRUST 
Experience-based trust is frequently defined in line with 
Gambetta [31] as a subjective probability between two 
individuals, also called ‘reliability trust’ [4] describing the 
probability an agent A expects agent B to deliver. However, 
we consider experience-based trust as a parameter supporting 
a decision with a sense of relative security. For example, 
having an infinite resource of single coloured balls ball ∈ 
{red, green, blue}, the posterior reliability trust indicate the 
reliance that the next picked ball is of a specific colour. From 
this, assuming even distribution, a utility function defining 
the rationality of the decision can be defined.  
To capture this, we use the broader definition of trust, 
called ‘decision trust’ [4] similar to that of McKnight and 
Chervaney [32] with the extension that the trustee is any 
identifiable matter [33], def. 1: Trust: “The extent to which a 
trustor is willing to depend on a trustee in a given situation 
with a feeling of relative security, even though negative 
consequences are possible”. This definition implies that trust 
is relevant only when something can go wrong, that trust is 
proposition specific and that it is a metric describing the 
relation of warranted reliance a trustor places on the trustee. 
Let this relation be denoted by T. Moreover, consider the 
definition’s situation as the proposition  that defines the 
exclusive and exhaustive outcomes of a frame of 
discernment, i.e., a trust relation with a level ω in a 
proposition   between A and B is denoted AζTωB. The 
definition also underlines the need of uncertainty as opposed 
to certainty, where uncertainty for “do not know” must not be 
confused with distrust of “do not trust” [14]. Thus, the 
definition calls for a metric where increased uncertainty in an 
experience indicate a decrease in the weight of the evidence. 
This view enables a decay of experiences without subverting 
the foundational meaning of the experience, e.g., by time as a 
function of forgiveness or regret [34]. 
A. General properties of a trust relation 
The most important property of a trust relation is the 
unique identification of the counterpart. The arity have been 
defined as a one-to-one, one-to-many, many-to-many or 
many-to-one [12] where many is an identifiable set of 
trustees. Other properties outline that a trust relation is 1) 
subjective, 2) asymmetric, 3) incomplete, 4) evolves over 
time, 5) proposition specific and 6) transitive (with 
restrictions). Below we briefly discuss 6), directing 
interested readers elsewhere [35]. 
The trust relation’s transitivity is frequently disputed, i.e., 
if AζTωB and BζTωC does this imply that AζTωC? Related 
literature examines this problem in greater detail [12] [36] 
[37]. For this paper we consider trust relations transitive over 
a chain of ‘positive’ decision trust propositions, i.e., if ω 
indicates a level for an affirmative decision, then AζTω1B ∧ 
BζTω2C ⇒ AζTω3C. For ω indicating distrust, this is 
considered not to hold as it would require deciding whether 
or not your enemy’s enemy is your friend [38]. Hence, trust 
is in this paper considered transitive, but distrust is not [39].  
B. The Experience(s) 
For representing an experience and the history of such, 
we follow Krukow’s [13] and Teacy et al. [6] general 
models. We consider an experience a four tuple and utilise 
Dempster-Shafer theory view of subjective probabilities. An 
element of this tuple is the score that should be accurate 
enough to have semantics, and at the same time general 
enough to map to computational methods. As the score type 
is subject to the used computational method and this paper is 
about a general model, we present a score type only as proof 
of concept when the model is mapped to other methods. 
Moreover, to meet with the property of incompleteness and 
that trust evolves; a means for decay per experience is 
introduced. We stress that this decay must not subvert the 
experience, merely degrade its weigh. 
An experience Exp is the manifestation of an agent’s 
(trustor) posterior subjective evaluation score  ∈ {<score>} 
of an observation on a trustee  ∈ {<  >} at datum  
in a proposition  ⊆ {<  >} . We represent this 
as a four tuple (, , , ), e.g., an experience by trustor P ∈ 
{<agents>} at datum  ≤   where   is the momentary 
datum in proposition  with score  is denoted  !() =
(, , , ) . The history of an agent P’s experiences 
 !(#) for i = 1, …, n is a set of such four tuples, i.e., 
{(, #, , )}. Thus, adding a new experience (, , , ) to 
the history {(, #, , )}  is straight forward  !$%& =
(, , , ) ∪ {(, #, , )} where j = 1, ..., n, . The datum 
may be virtually any continuous matter or composition of 
such, but often considered time. Projections on this four 
tuple is possible. That is,  ((), ) defines the projection 
on agent A’s experiences on (), ) and similarly for other 
projections, 
i.e., 
 ((), )
 = 
{(), , , )}
 and 
 ($), *,  & = {(#, )} for  ⊆  and # ≤ * for i = 0, 
1, … p. Thus, for a specific datum # the projection returns a 
singleton assuming that an agent cannot interact in several 
matters simultaneously. In addition, we note the deliberate 
loose definition of , that with this notation may be a group 
of agents, supporting the trust relation's arity. 
C. Type of Score 
The general model’s score type must be versatile. For 
this, we propose the score type of a tuple (sat, unsat) as for 
satisfactory and unsatisfactory where sat, unsat ∈ [0, 1] and 
sat + unsat ≤ 1. Subadditivity is fundamental for expressing 
uncertainty and decay without subverting the semantics of 
the experience, i.e., the level of certainty is sat + unsat 
where theoretical full certainty is sat + unsat = 1. Moreover, 
coarsening a multinomial proposition || ≥ 3 to a binomial 
|| = 2, this binomial score type is applicable on any || ≥ 2, 
12
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-463-3
ADAPTIVE 2016 : The Eighth International Conference on Adaptive and Self-Adaptive Systems and Applications

e.g., let ball ∈ {r, g, b}, deriving {r, b} is {r} + {b} + {r, b} 
where '+' denote sum of sat and unsat respectively. 
With score η, an experience is (′, #, , (, ,)). 
Related work considering a similar score type include 
Noorian et al. [40] and methods using Beta probability 
density functions. The type’s semantics incorporate that of 
Dempster-Shafer theory, i.e., experience certainty is 
captured by the combined weight and distribution by 
relative weigh. A vacuous experience may thus be expressed 
as (0, 0), a dogmatic experience (the probabilistic view) is 
when sat + unsat = 1, and absolute experiences (binary or 
Boolean view) when (sat, unsat) = (0, 1) or (sat, unsat) = (1, 
0). Thus, a score sat = 0.3 and unsat = 0.5 is valid indicating 
a certainty of 0.8. From this, uncertainty u is easily derived, 
, = 1 −  − , as is the dogmatic expectation value 
of satisfyability as sat / (sat + unsat). 
D. Decay of Experience 
Decay of an experience relates to forgetting or 
forgiveness. When the datum is time, it is natural to weigh 
recent experiences over older. Let the decay factor be λ 
where 0 ≤ λ ≤ 1. This factor relies on a continuous datum ϵ 
by which it decays. We write /01 for the general decay 
function d at datum 2 on an experience  3(#) where # 
≤ 2 as:  
/01 4 3(#)5 = (′, #, , 601708 ∗ )  
(1) 
Dually, this decay may be applied on the history of 
experiences where : = 1, …, m and : ≤ 2: 
/01 4 3(:)5 = {(′, :, , 60170; ∗ )} 
(2) 
Here each experience is decayed by λ, defining the speed of 
‘forgiveness’. The closer λ is to 1, the slower the speed with 
λ = 1 indicating no decay motivated when consistency is 
assumed. Dually, λ = 0 indicate complete decay, motivated 
when the experiences are random. Hence, the effect of decay 
is that an experience score  is reduced by factor λ with 
respect to the datum, i.e.,  at 2 is less or equal to  at : 
when n ≤ m and λ ≤ 1. Realistically, ϵ  may be time.   
E. Abstracting Experiences 
To calculate with a set of experiences, a composition 
to an abstract experience, denoted Abs is necessary. 
This abstraction is done by some datum, say 2, hence 
=>01. The composition of decayed experiences outlines a 
momentary decayed score, the abstracted score absscore. 
We define this for : = 1, …, m and : ≤ 2: 
=>01 4 3(2)5 = (′, 2, , ∑
@A1BC*D(3E,0;,F) )
 (3) 
Thus, =>01 4 3(′, 2, )5 = (>G) . We define 
absscore as a tuple (abssat, absunsat) where abssat, 
absunsat ∈ ℝ+. The semantics of this is linear: “the greater 
the more certain“. Updating the absscore is recursive [41] 
whenever λ is universal, continuous and applied on all 
experiences locally.  
=>01I 4 3(#)5 = E, 2I, , 4 3(E, 2I, , ) +
 =>01 4 3(′, 2, )5 ∗ 65 
(4) 
Here  3(E, 2I, , ) is the new experience. In case no 
new experience was recorded at 2E,  3(E, 2I, , ) = 
(<vacuous>), i.e., (0, 0). Thus, abstraction is irreversible and 
provides a sense of privacy that decay enhances on.  
IV. 
THE GENERAL MODEL MAPPED TO EXISTING 
COMPUTATIONAL METHODS 
In the subsequent sections, we will show how the general 
model may be mapped to a probabilistic view. 
A. Probabilistic views 
Semantically a purely probabilistic view is very rich. 
From the absscore expectation value this is directly derived 
by abssat / (abssat + absunsat). However, the probabilistic 
view abstracts (assumes) certainty, i.e., the expectation value 
outcome is equivalent for Beta (4, 2) and Beta (12, 6) where 
obviously, the latter should indicate higher certainty. Hence, 
for the probabilistic view to be reasonable, certainty is 
complete, i.e., it is a dogmatic view. We can see this as a 
valid approach only for statistical modelling. In addition, the 
presented general model also captures consistent behaviour, 
e.g., assume there to be an event of 0.7 probability of 
success, then by setting λ = 1, absscore will approach the 0.7 
relation between abssat and absunsat. On such an event, the 
model holds as decay does not subvert the expectation value. 
Thus, we conclude that the probabilistic view can be 
expressed by the general model. 
B. Discrete views 
A discrete view is one where the level of trust is 
expressed in a countable space. This space is a set that is 
typically totally ordered, e.g., none ≤ small ≤ large. Thus, as 
probabilistic views are possible, this less expressive discrete 
view on a totally ordered set is possible to express by the 
general model as well.  
C. EigenTrust 
EigenTrust [29] is an algorithm originally targeted for 
Peer-to-Peer systems that computes a global trust value for 
an agent. The algorithm requires each experience to be rated 
either satisfactory or unsatisfactory, making the score binary 
η ∈ {0, 1}. Such experiences may be modelled by the general 
model, and merged to the absscore. Thus, EigenTrust 
function on the abstracted score G33E of agent  on ′ as 
G33E  = >33E  - >,33E . A score G33E  is 
normalized with respect to G33EE where ′′ ∈ {<agents>} \ 
 , i.e., with respect to agents   have recorded direct 
interaction with whenever G33EE ≥ 0, otherwise G33EE = 0. 
These normalized values is the G33EE  vector that when 
organized as a global I-by-J matrix M denoting on one row 
the level of trust an agent perceives in the other agents. 
When M is transposed MT, a row denotes the level of trust 
others’ have in an agent. Hence, multiplying MT by itself is 
as if asking friends, i.e., (MT)2. Obviously, this assumes 
transitivity, and as the score is positive, only positive 
13
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-463-3
ADAPTIVE 2016 : The Eighth International Conference on Adaptive and Self-Adaptive Systems and Applications

transitivity. For (MT)n where n is sufficiently large, the 
matrix rows will converge within some tolerance providing 
an unweighted the global objective trustworthiness vector. 
Thus, the general model maps to EigenTrust. 
D. Subjective Logic 
Subjective Logic (SL) is a probabilistic logic providing a 
means for transitivity and derives a level of subjective belief 
in an entity in a proposition developed primarily by Jøsang 
[27] [38]. It is related to Dempster-Shafer theory and 
consists of a set of well-defined logical operators on its 
basic type opinion ω being a four tuple (b, d, u, a) as for 
belief, disbelief, uncertainty and base rate. This opinion 
represents a binomial view, i.e., one where the exclusive and 
exhaustive frame of discernment polarity is 2, for and 
against. SL on dogmatic opinions (no uncertainty) falls back 
on traditional probabilistic logic and functions as Boolean 
logic when the opinions are absolute. 
For the opinion to capture the general model’s absscore 
overlooking the level of (un)certainty, a non-informative 
prior weigh parameter W is introduced. The assignment of 
W is delicate depending on the frequency of new 
experiences with respect to the datum and level of decay 
making it application specific. With this, the expectation 
value is defined abssat / (abssat + absunsat + W) implying 
that W guarantees incompleteness in form of non-additivity. 
A mapping function from absscore including W to the 
opinion type basing on the abstracted history of experiences 
have been presented by Jøsang [27] [41]:  
 K
⎩
⎪
⎨
⎪
⎧> = 
PQRRPS
PQRRPSTPQRU:RPSTV
/ = 
PQRU:RPS
PQRRPSTPQRU:RPSTV
, = 
V
PQRRPSTPQRU:RPSTV
 = > 
 
 ⇔
> =
VQ
U
>, =
V@
U
 
 
 
 = >  ⎭
⎪⎪
⎬
⎪⎪
⎫
 .   (5) 
The SL is also related to a Βeta probability density 
function (Βpdf) [28] as absscore maps to the Βpdf input 
tuple (α, β). Hence, visualising the SL as a Βpdf is possible. 
For a vacuous initial view i = 0 of =>01 4 3(#)5 = (0, 
0) to be a horizontal Βpdf, the non-informative prior weigh 
W need to be 2 and the base rate 0.5. Thus, we conclude that 
the general model maps to opinions of SL. 
V. 
DISCUSSION AND CONCLUSION 
To capture the uncertainty of ‘do not know’ for 
something unanticipated, we have presented a general 
model for experience based trustworthiness relying on 
Dempster-Shafer theory of evidence. More pragmatic 
studies on the application of this are found elsewhere [9] 
[42]. As |{(, , , )}|  is finite, |absscore| < ∞ holds 
whereas the evidence on any binomial view is 
incomplete voiding the traditional probabilistic views of 
Markov chains or Monte Carlo simulations. In addition, 
the well-known shortcoming of Dempster’s rule of 
combination producing counter-intuitive results in case of 
strong conflict has been resolved [43]. This is also in line 
with Pearl [44] stating that “belief theory is a theory on the 
probability of provability as opposed to probabilities of 
truth“. In addition, fuzzy logic operating on crisp measures 
about linguistically vague and fuzzy propositions is different 
from the presented model operating on uncertain but on 
crisp propositions [38] [45]. 
This general model of trust presented in this paper 
parameterises the level of reliability placed on a trustee in a 
proposition by disjoint experiences. The model has been 
implemented on real data in related work [9]. This paper 
shows how to abstract these experiences to a composite 
score and how this score may be mapped to well-known 
methods. Thus, the contribution of this paper is in 
motivating the generality and versatility of the experience-
based trust model and the specific score type. Further 
facilitating the use of an experience-based model alike is its 
computational lightness featuring decay by some datum.  
ACKNOWLEDGMENT 
This research is funded by the Academy of Finland 
project “Merge: Merging digital hydraulic Systems and 
Supercomputing: New possibilities to improve productivity, 
reliability and service for hydraulic machines” (Grant nr. 
286094). 
REFERENCES 
[1]  S. Kanhere, “Participatory Sensing: Crowdsourcing Data from 
Mobile Smartphones in Urban Spaces,” in 12th IEEE Int. 
Conf. on Mobile Data Management, pp.3-6, 2011.  
[2]  T. Buchholz, A. Küpper and M. Schiffers, “Quality of 
Context Information: What it is and why we need it,” in proc. 
of the 10th HPOVUA workshop, 2003.  
[3]  B. Barber, The Logic and Limits of Trust, Rutgers University 
Press, 1983.  
[4]  A. Jøsang, R. Ismail and C. Boyd, “A survey of trust and 
reputation systems for online service provision,” Decis. 
Support Syst., vol. 43, no. 2, pp. 618-644, 2007.  
[5]  T. Huynh, N. Jennings and N. Shadbolt, “An integrated trust 
and reputation model for open multi-agent systems,” 
Autonomous Agents and Multi-Agent Systems, vol. 13, no. 2, 
pp. 119-154, 2006.  
[6]  W. Teacy, J. Patel, N. Jennings and M. Luck, “TRAVOS: 
Trust and Reputation in the Context of Inaccurate Information 
Sources,” Autonomous Agents and Multi-Agent Systems, vol. 
12, no. 2, pp. 183-198. , 2006.  
[7]  Y. Wang and M. Singh, “Evidence-based trust: A 
mathematical model geared for multiagent systems,” ACM 
Trans. Auton. Adapt. Syst., vol. 5, no. 4, p. 28 pages, 2010.  
[8]  S. Sen, “A comprehensive approach to trust management,” in 
Proc. of the Int. Conf. on Autonomous Agents and Multi-
Agent Systems, pp. 797-800, 2013.  
[9]  M. Neovius, “Adaptive Experience-Based Composition of 
Continuously Changing Quality of Context,” in Int. Conf. on 
Adaptive and Self-Adaptive Systems and Applications, 2015.  
[10] A. Fitzpatrick, G. Biegel, S. Clarke and V. Cahill, “Towards a 
14
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-463-3
ADAPTIVE 2016 : The Eighth International Conference on Adaptive and Self-Adaptive Systems and Applications

Sentient Object Model,” in Workshop on Engineering 
Context-Aware Object Oriented Systems and Environments, 
2002.  
[11] M. Blaze, J. Feigenbaum and J. Lacy, “Decentralized Trust 
Management,” in Proc. of the IEEE Symposium on Security 
and Privacy, 1996.  
[12] T. Grandison and M. Sloman, “A Survey of Trust in Internet 
Applications,” IEEE Communications Surveys and Tutorials, 
vol. 3, no. 4, pp. 2-16, 2000.  
[13] K. Krukow, “Towards a theory of trust for the global 
ubiquitous computer,” PhD thesis, University of Aarhus, 
Denmark., 2006. 
[14] M. Carbone, M. Nielsen and V. Sassone, “A Formal Model 
for Trust in Dynamic Networks,” in Proc. of Int. Conf. on 
Software Engineering and Formal Methods, 2003.  
[15] S. Weeks, “Understanding Trust Management Systems,” in 
Proc. of the IEEE Symposium on Security and Privacy, 2001.  
[16] D. Artz and Y. Gil, “A survey of trust in computer science 
and the Semantic Web,” Web Semantics, vol. 5, no. 2, pp. 58-
71, 2007.  
[17] S. Keung and N. Griffiths, “Trust and reputation,” in Agent-
Based Service-Oriented Computing (Chap. 8), pp 189–224, 
Springer, 2010.  
[18] A. Vasalou, A. Hopfensitz and J. Pitt, “In praise of 
forgiveness: Ways for repairing trust breakdowns in one-off 
online interactions,” International Journal of Human-
Computer Studies, vol. 66, no. 6, pp. 466-480, 2008.  
[19] M. Neovius, “Trustworthy Context Dependency in Ubiquitous 
Systems,” TUCS dissertations nr. 151. PhD thesis, Turku, 
Finland, 2012. 
[20] S. Ruohomaa, L. Kutvonen and E. Koutrouli, “Reputation 
Management Survey,” in Int. Conf. on Availability, 
Reliability and Security, pp. 103-111, 2007.  
[21] P. Massa and P. Avesani, “Trust Metrics on Controversial 
Users: Balancing Between Tyranny of the Majority and Echo 
Chambers,” Int. J. on Semantic Web and INformation 
Systems, vol. 3, no. 1, 2007.  
[22] A. Abdul-Rahman and S. Hailes, “Supporting Trust in Virtual 
Communities,” in Proc. of the 33rd Hawaii Int. Conf. on 
System Sciences, 2000.  
[23] J. Schneider, G. Kortuem, J. Jager, S. Fickas and Z. Segall, 
“Disseminating 
Trust 
Information 
in 
Wearable 
Communities,” Personal Ubiquitous Computing, vol. 4, no. 4, 
pp. 245-248, 2000.  
[24] J. Sabater and C. Sierra, “Social ReGreT, a reputation model 
based on social relations,” SIGecom Exch., vol. 3, no. 1, pp. 
44-56, 2001.  
[25] L. Page, S. Brin, R. Motwani and T. Winograd, “The 
PageRank Citation Ranking: Bringing Order to the Web,” 
Technical Report. Stanford InfoLab, 1999. 
[26] S. Buchegger and J.-Y. Le Boudec, “A Robust Reputation 
System for Peer-to-Peer and Mobile Ad-hoc Networks,” in 
P2PEcon, 2004.  
[27] A. Jøsang, “Artificial Reasoning with Subjective Logic,” in 
Second Australian Workshop on Commonsense Reasoning, 
1997.  
[28] L. 
Mui, 
M. 
Mohtashemi 
and 
A. 
Halberstadt, 
“A 
Computational Model of Trust and Reputation for E-
businesses,” in Proc. of the 35th Annual Hawaii Int. Conf. on 
System Sciences, 2002.  
[29] S. Kamvar, M. Schlosser and H. Garcia-Molina, “The 
Eigentrust algorithm for reputation management in P2P 
networks,” in Proc. of the 12th Int. Conf. on World Wide 
Web, 2003.  
[30] K. Krukow, N. M. and V. Sassone, “Trust models in 
ubiquitous computing,” Philos Transact A Math Phys Eng 
Sci., no. 366, pp. 3781-3793, 2008.  
[31] D. Gambetta, “Can We Trust Trust?,” in Trust: Making and 
Breaking Cooperative Relations, Chapter 13, Department of 
Sociology, University of Oxford, 2000, pp. 213-237. 
[32] H. McKnight and N. Chervaney, “The Meanings of Trust,” 
Technical Report 96-04, 1996. 
[33] C. Castelfranchi and R. Falcone, “Principles of Trust for 
MAS: 
Cognitive 
Anatomy, 
Social 
Importance, 
and 
Quantification,” in Proc. Int. Conf. on Multi Agent Systems., 
1998.  
[34] S. Marsh and P. Briggs, “Examining Trust, Forgiveness and 
Regret as Computational Concepts,” in Computing with social 
trust, Chapter 2, Springer, 2009, pp. 9 - 43. 
[35] Z. Yan and S. Holtmanns, “Trust Modeling and Management: 
from Social Trust to Digital Trust,” in Computer Security, 
Privacy and Politics: Current Issues, Challenges and 
Solutions, IGI Global, 2007.  
[36] B. Christianson and W. Harbison, “Why isn't trust 
transitive?,” in Proc. of the Security Protocols Int. Workshop, 
1996.  
[37] A. Jøsang and S. Pope, “Semantic constraints for trust 
transitivity,” in Proc. of the 2nd Asia-Pacific conf. on 
Conceptual modelling, 2005.  
[38] A. 
Jøsang, 
Subjective 
Logic, 
http://folk.uio.no/josang/papers/subjective_logic.pdf, 
visited 
24.11.2015.  
[39] T. DuBois, J. Golbeck and S. A., “Predicting Trust and 
Distrust in Social Networks,” in IEEE Third Int.l Conf. on 
Privacy, Security, Risk and Trust, 2011.  
[40] Z. Noorian, S. Marsh and M. Fleming, “Multi-layer cognitive 
filtering by behavioral modeling,” in Int. Conf. on 
Autonomous Agents and Multiagent Systems, 2011.  
[41] A. Jøsang and R. Ismail, “The beta reputation system,” in 
Proc. of the 15th Bled Conference on Electronic Commerce, 
2002.  
[42] M. Neovius, M. Stocker, M. Rönkkö and L. Petre, 
“Trustworthiness Modelling on Continuous Environmental 
Measurement,” in Proc. of the 7th Int. Cong. on 
Environmental Modelling and Software, 2014.  
[43] A. Jøsang and S. Pope, “Dempster's Rule as Seen by Little 
Colored Balls,” Computational Intelligence, vol. 4, no. 28, pp. 
pp. 453-474, 2012.  
[44] J. Pearl, “Reasoning with Belief Functions: An Analysis of 
Compatibility,” Int. J. of Approximate Reasoning, vol. 4, no. 
5/6, pp. 363-389, 1990.  
[45] A. Jøsang, “A logic for uncertain probabilities,” Int. J. 
Uncertain. Fuzziness Knowl.-Based Syst., vol. 3, no. 9, pp. 
279-311, 2001.  
15
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-463-3
ADAPTIVE 2016 : The Eighth International Conference on Adaptive and Self-Adaptive Systems and Applications

