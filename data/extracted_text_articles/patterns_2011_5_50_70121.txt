A Quality Control System using Texture Analysis in Metallurgy
Jonathan M. Blackledge
School of Electrical Engineering Systems
Dublin Institute of Technology
Dublin, Ireland
Email: jonathan.blackledge@dit.ie
Dmitriy A. Dubovitskiy
Radiation and Environmental Science Centre
Dublin Institute of Technology
Dublin, Ireland
dmitriy.dubovitskiy@dit.ie
Abstract—Object detection, recognition and texture classiﬁ-
cation is an important aspect of many industrial quality control
systems. In this paper, we report on a system designed for
the inspection of surfaces which has a range of applications
in the area of metallurgy. The approach considered is based
on the application of Fractal Geometry and Fuzzy Logic
for texture classiﬁcation and, in this paper, focuses on the
manufacture of rolled steel. The manufacture of high quality
metals requires automatic surface inspection for the assessment
of quality control. Quality control systems are required for
several tasks such as screening defected products, monitoring
the manufactures process, sorting information for different
applications and product certiﬁcation and grading for end
customers. The system discussed in this paper was developed
for the Novolipetck Iron and Still Corporation in Russia and
tested with images captured at a rolling mill with metal sheets
moving at speed of up to six meters per second and inspected
for several defect classes. The classiﬁcation method used is
based on the application of a set of features which include frac-
tal parameters such as the Lacunarity and Fractal Dimension
thereby incorporating the characterisation of surface surfaces
in terms of their texture. The principal issues associated with
texture recognition are presented which includes fast segmen-
tation algorithms. The self-learning procedure for designing
a decision making engine using fuzzy logic and membership
function theory is also presented and a new technique for the
creation and extraction of information from a membership
function considered. The methods discussed, and the system
developed, have a range of applications in ‘machine vision’ and
automatic inspection. However, in this publication, we focus on
the development and implementation of a surface inspection
system that can be used in a iron and steel manufacture by
non-experts to the automatic recognition system operators.
Keywords-Computer vision; patterns analysis; segmentation;
object recognition; self-learning; fuzzy logic; image morphology.
I. INTRODUCTION
Pattern recognition is a part of image analysis, which
involves the use of image processing methods that are often
designed in an attempt to provide a machine interpretation
of an image, ideally, in a form that allows some decision
criterion to be applied [1], [2]. Pattern recognition uses
a range of different approaches that are not necessarily
based on any one particular theme or uniﬁed theoretical
approach. This is because there is no complete and unique
theoretical model available for explaining and simulating
the processes of visual image comprehension by humans.
Hence, machine vision remains a rather elusive subject area
in which automatic inspection systems are advanced without
having a fully operational theoretical framework as a guide.
Nevertheless, numerous algorithms for understanding two-
and three-dimensional objects in a digital image have and
continue to be researched in order to design systems that
can provide reliable automatic object detection, recognition
and classiﬁcation in an independent environment, [9], [10],
[11] and [13].
Machine Vision can be thought of as the process of linking
parts of the visual object’s ﬁeld with stored information or
‘templates’ with regard to a pre-determined signiﬁcance for
the observer. There are a number of questions concerning
vision such as: (i) what are the goals and constraints? (ii)
what type of algorithm or set of algorithms is required to
effect vision? (iii) what are the implications for the process,
given the types of hardware that might be available? (iv)
what are the levels of representation required to achieve
vision? The levels of representation are dependent on what
type of segmentation and edge detection can and/or should
be applied to an image. For example, we may be able to
produce primal sketches from an image via some measure
of the intensity changes in a scene. These are recorded as
place tokens and stored in a database. Regions of pixels
with similar intensity values or sets of lines are obtained
by isolating the edges of an image scene and computed by
locating regions where there is a signiﬁcant difference in the
intensity. Such sets are subject to inherent ambiguities when
computed from a given input image and associated with
those from which an existing data base has been constructed.
These ambiguities can only be overcome by the application
of high-level rules, based on how humans interpret images,
but the nature of this interpretation is not deﬁed. Parts of
an image will tend to have an association if they share size,
colour, ﬁgural similarity, continuity, shading and texture. For
this purpose, one needs to consider how best to segment an
image and what form this segmentation should take.
The identiﬁcation of the edges of features on metal
surfaces (as given in Figure 1, for example) is an important
component for developing quality control system in metal-
lurgy. This identiﬁcation provides information on the basic
topology of a feature from which an interpretative match can
122
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

be achieved. Some edges can be detected only in terms of a
representative view a whole image and have no connection
with local pixels. Nevertheless, the segmentation of an image
into a complex of edges is a useful pre-requisite for object
identiﬁcation and the solution may require analysis of the
whole scene. Although many low-level processing methods
can be applied for this purpose, the problem is to decide
which object boundary each pixel in an image falls within
and which high-level constraints are necessary. In many
cases, a principal question is, which comes ﬁrst, recognition
or segmentation?
Figure 1.
Example of a metal surface with edge-based features.
Compared to image processing, computer vision (which
incorporates machine vision) is more than automated image
processing. It results in a conclusion, based on a machine
performing an inspection of its own. The machine must
be programmed to be sensitive to the same aspects of
the visual ﬁeld as humans ﬁnd meaningful. Segmentation
is concerned with the process of dividing an image into
meaningful regions or segments. It is used in image analysis
to separate features or regions of a pre-determined type
from the background; it is the ﬁrst step in automatic image
analysis and pattern recognition. Segmentation is broadly
based on one of two properties in an image: (i) similarity;
(ii) discontinuity. The ﬁrst property is used to segment an
image into regions which have grey or colour levels within
a predetermined range. The second property segments the
image into regions of discontinuity where there is a more or
less abrupt change in the values of the grey or colour levels.
In this paper, we consider an approach to object detection
in an image scene that is based on a new segmentation edge
recognition or edge tracing or edge following algorithm.
The segmented object is then analysed in terms of met-
rics derived from both a Euclidean and Fractal geometric
perspective, the output ﬁelds being used to train a fuzzy
inference engine with a supervised leaning technique, the
recognition structure being based on some of the tech-
nologies for image processing, analysis and machine vision
reported in [12]. The approach considered is generic in that it
can, in principle, be applied to any type of imaging modality.
The system developed includes features that are based on the
textural properties of an image which is an important theme
is patterns analysis.
II. PATTERN RECOGNITION
Pattern recognition can be considered to be a form of
machine understanding based on assigning a particular class
to an object. The tasks of construction and application of
formal operations for numerical or character representation
of objects of a real or ideal world is the basis of pattern
recognition. This depends on establishing equivalence re-
lations that express a ﬁt of evaluated objects to any class
with independent semantic units. The recognition classes
of equivalence can be set by the user in the construction
of an algorithm, which uses own pithy representations or
external padding information on a likeness and difference
of objects in the context of a solved task; the basis for
phrase ‘recognition with the teacher’. For a typical object
recognition system, the determination of the class is only
one of the aspects of the overall task. In general, pattern
recognition systems receive data in the form of ‘raw’ mea-
surements which collectively form a stimuli of ‘feature’
vector [3], [4]. Uncovering relevant attributes in the elements
present within the feature vector is an essential part of such
systems. An ordered collection of such relevant attributes
which more clearly represent the underlying features of
the object is assembled into the feature vector. In this
context, learning amounts to the determination of rules of
associations between the features and attributes of a pattern.
Practical image recognition systems generally contain
several stages in addition to the recognition engine itself. The
recognition represents information processing that is realised
by some converter of the information (by an intellectual
information channel), having an input and output. On input,
such a system establishes information on the properties of
an object. On output, the information shows which class
or feature of an object is assigned. When a computerised
123
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

system decides on the task of classiﬁcation without engaging
external learning information, it is called automatic classiﬁ-
cation - ‘recognition without the teacher’. The majority of
algorithms for pattern recognition require the engagement
of a number of considerable computational capabilities,
which can be provided only with high-performance com-
puter equipment [5].
There are two principal methods for object recognition so-
lutions with a parametric and non-parametric approach. Sta-
tistical voting and alphabetic propositions has been reviewed
in [7][8][12]. The main disadvantage with this approach is
that classes have to be clearly deﬁned so that no overlapping
is allowed. Methods based on a principal of separation and
potential functions can be found in [6] and [11]. A large
amount of training data or preliminary information about
system is required which makes the recognition process
less ﬂexible. In general, there is no system which considers
objects from the point of view of a superposition of global
scenery. This leads to the following problem: how can we
evaluate an object in terms of it being part of the ‘bigger
picture’ without losing speciﬁc details on its particular
texture for precise recognition? This paper attempts to solve
this problem by merging concepts from Fractal Geometry
[21] [22] [23] [24] [25] and Fuzzy Logic [15] [16] [17]. We
start by considering the problem of object location.
III. OBJECT LOCATION
Recognition is the process of comparing individual fea-
tures against some pre-established template subject to a set
of conditions and tolerances. This task can be reduced to
the construction of some function determining a degree of
proximity of the object to a sample - a ‘template’ of the
object. The process of recognition commonly takes place in
four deﬁnable stages: (i) image acquisition and ﬁltering; (ii)
object location (with edge detection); (iii) measurement of
object parameters; (iv) object class estimation and decision
making.
Suppose we have an image which is given by a function
f(x, y) and contains some object described by a set of
features S = {s1, s2, ..., sn}. We consider the case when it
is necessary to deﬁne a sample, which is somewhat ‘close’ to
this object in terms of a matching set. The system discussed
in this paper is based on an object detection technique
that includes a novel segmentation method and must be
adjusted and ‘ﬁne tuned’ for each area of application. This
includes those features associated with an object for which
fractal models are well suited [1], [2], [21]. A conventional
method consists of calculating some function of a pointwise
coincidence between the map of the object and the image
together with a search for the maximum of this function.
In terms of a ‘similarity function’, this method can be
represented in terms of metrics that include the sum of
square deviations, the sum of the modulus of deviations or
as a pair of sum of multiplications of values of brightness
(function of the greatest transparency), for example. The
ﬁrst two similarity functions compute the ‘smallness’ of a
functional pair; instead of searching for a maximum it is
necessary to search for a minimum.
Not all fragments of an object are equally important for
recognition and hence, a broadly distributed functional eval-
uation matched with weighted coefﬁcients can be undertaken
on separate parts. Appropriate similarity functions can be
used as a sum of the weighted squares of deviations, a
sum of the weighted modules of deviations and the sum of
the weighted multiplication of pairs of brightness values.
The correct selection of weight coefﬁcients is important
in the ﬁeld of identiﬁcation and can be calculated from a
given set of samples. The common application for weighted
comparisons occurs in the ﬁeld of artiﬁcial neural networks.
The advantage of usage of neural networks lies in the
capability of introducing a ﬂexible set of weights during op-
eration (system training). This property becomes especially
important if a set is based on a non-stationary model which
varies in time while it is extended and updated.
The system described in this paper provides a decision
using a knowledge database by subscribing different objects.
The ‘expert data’ in the application ﬁeld creates a knowledge
database by using a supervised training system with a
number of model objects [15]. At this stage, the learning
technique uses positive feedback for the second step of
object location and ﬁltering. We consider an image of a
metal surface as given Figure 1.
Figure 1 represents the result after applying a conventional
ﬁltering and edge detection procedure. The conventional
method does not provide continuous edges in order to locate
a feature. We have therefore designed a new object location
procedure that considers the image in its entirety without
detailing smaller features. This is based on a measure
of weight coefﬁcients to provide information about object
connectivity. The result of this procedure can be given in
Figure 2.
The calculation of weight coefﬁcients for each pixel is
deﬁned as kx,y:
fm,n = f(x, y)kx,y
where
kx,y =


1
f(x, y)


kx−1,y+1
kx,y+1
kx+1,y+1
kx−1,y
px,y
kx+1,y
kx−1,y−1
kx,y−1
kx+1,y−1



 ∗ pobj(x,y)
There is local dependency between the current pixel fm,n
and the object pixels. The global evaluation is determined
by pobj(x,y) which is the probability that the pixel could be
a part of an object. This probability is calculated from a
fuzzy logic membership function which has a loop-back to
the current object location. The function pobj(x,y) is a two
124
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

Figure 2.
Metal surface with approximate object locations.
dimensional matrix and recalculates local values dynami-
cally using the object table location fm,n. The construction
of this matrix is based on the following: The intensity level
of the objects is computed. This level uses only those pixels
which have not been recognised as a part of an object. To
start with, the object level denoted by Lobj is higher than the
background level Lbgr as the recognition process continues.
As long as Lobj == Lbgr, all objects are recognised as
having been indexed according to the equation [19], [20]
Lbgr = mean[f(x, y) − f(m, n)]
In order to obtain Lobj, a probabilistic min-max equation,
which has been experimentally tested for different surfaces,
is used given by [19]:
Lobj =
(
Lx,
Lx ≥ Ly;
Ly,
otherwise.
where
Lx = 1
2

min
y

The overall accuracy depends on the level of conﬁdence of
an expert. In some cases, an expert is unable to make clear
decisions about which class belongs to an object. In such
cases, it must be 50/50 in order for the system to consider
this case as overlapping, but not to delete it and use extra
data from the KDB to make a decision.
Consider a sample belonging to one of three groups:
Scale, Cleavage crack or Cusping. We then undertake the
same operations as those during the training session. The
system then ﬁnds the object, computes its fractal dimension
which, in this case study, is 2.58, for example, and the
convexity factor (0.69). The degree of conﬁdence determined
by all the parameters functions is displayed in Figure 3.
Figure 3.
Precision deﬁnitions
We compute the degree of conﬁdence for each class as:
(Scale)=0.27+0.87=1.14
(Cusping)=0.46+0.42=0.88
(Clevage crack)=0+0=0
The maximum of these values characterizes that class
to which the given image corresponds. In the example
given, the output is Scale. For industrial systems with many
reference classes, it is possible to utilise scaling factors
for each of the computed parameters in conformity with
a measure of inﬂuence (weight coefﬁcient) on a parame-
ter for a class deﬁnition. The weight coefﬁcients will be
automatically readjusted with the next teaching input. Once
the expert decides to correct some class performance, then
the corresponding input parameters will be reconsidered for
chosen class only.
The computation time depends on the image resolution,
normally varying from 2 to 10 seconds in the MatLab
environment. For a metal surface moving at 6m/sec, the
algorithm described above would need to be implemented
by means of a ﬁeld-programmable gate array (FPGA), which
will lead to the computation ﬁtting within frames.
V. CONCLUSION AND FUTURE WORKS
This paper has been concerned with the task of developing
a methodology and applications that are concerned with two
Figure 4.
Result of surface inspection.
key tasks: (i) the partial analysis of an image in terms of its
fractal structure and the fractal properties that characterize
that structure; (ii) the use of a fuzzy logic engine to classify
an object based on both its Euclidean and fractal geometric
properties. The combination of these two aspects has been
used to deﬁne a processing and image analysis engine that
is unique in its modus operandi but entirely generic in terms
of the applications to which it can be applied.
The work reported in this paper is part of a wider
investigation into the numerous applications of pattern
recognition using fractal geometry as a central processing
kernel. This has led to the design of a new library of
pattern recognition algorithms including the computation of
parameters in addition to those that have been reported here
such as the information dimension, correlation dimension
and multi-fractals [21]. The inclusion or otherwise of such
parameters in terms of improving vision systems such as the
one considered here remains to be understood. However,
from the work undertaken to date, it is clear that texture
based analysis alone is not sufﬁcient in order to design a
recognition and classiﬁcation system. Both Euclidean and
fractal parameters need to be combined into a feature vector
in order to develop an operational vision system, which
includes objects that have textural properties such as those
associated with medical imaging.
The creation of logic and general purpose hardware for
artiﬁcial intelligence is a basic theme for any future de-
velopment based on the results reported in this paper for
the applications developed and beyond. The results of the
126
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

current system can be utilized in a number of different areas
although medical imaging would appear to be one of the
most natural ﬁelds of interest because of the nature of the
images available, their complex structures and the difﬁculty
of obtaining accurate diagnostic results which are efﬁcient
and time effective. A further extension of our approach is
to consider the effect of replacing the fuzzy logic engine
used to date with an appropriate Artiﬁcial Neural Network.
It is not clear as to whether the application of an ANN could
provide a more effective system and whether it could provide
greater ﬂexibility with regard to the type of images used and
the classiﬁcations that may be required.
ACKNOWLEDGMENT
The authors are grateful for the advice and help of Dr P.P.
Chernov (Novolipetsk Iron and Steel Corporation), Professor
V. Deviatkov and Professor A. Chernikov (Bauman Moscow
State Technical University).
REFERENCES
[1] J. M. Blackledge, Digital Signal Processing, 2nd Edition,
Horwood Publishing, 2006.
[2] J. M. Blackledge, Digital Image Processing, Horwood Pub-
lishing, 2005.
[3] W. E. L. Grimson, Object Recognition by Computers: The
Role of Geometric Constraints, MIT Press, 1990.
[4] B. D. Ripley, Pattern Recognition and Neural Networks,
Academic Press, Oxford, 1996.
[5] R. B. Macy Abhijit and
S.Pandya, Pattern Recognition
with Neural Networks in C++, IEEE Press, Florida Atlantic
University, 1995.
[6] C. T. Leondes, Image Processing and Pattern Recognition,
Academic press, London, 1998.
[7] E. L. Hall, Computer Image Processing and Recognition,
Academic press, London, 1979.
[8] T. Pavlidis, Algorithms for Graphics and Image Processing,
Computer Science Press, USA, 1982.
[9] E. R. Davies, Machine Vision: Theory, Algorithms, Practical-
ities, Academic press, London, 1997.
[10] H. Freeman, Machine Vision. Algorithms, Architectures, and
Systems, Academic press, London, 1988.
[11] J. Louis and J. Galbiati, Machine Vision and Digital Image
Processing Fundamentals, State University of New York,
New-York, 1990.
[12] R. Boyle, M. Sonka and V. Hlavac, Image Processing, Anal-
ysis and Machine Vision, PWS, USA, 1999.
[13] W. E. Snyder and H. Qi, Machine Vision, Cambridge Univer-
sity Press, England, 2004.
[14] V. S. Nalwa and T. O. Binford, On Detecting Edges IEEE
Trans. Pattern Analysis and Machine Intelligence, (PAMI-8),
699-714, 1986.
[15] L. A. Zadeh, Fuzzy Sets and their Applications to Cognitive
and Decision Processes, Academic Press, New York, 1975.
[16] E. H. Mamdani, Advances in Linguistic Synthesis of Fuzzy
Controllers, J. Man. Mach., 8, 669-678, 1976.
[17] E. Sanchez, Resolution of Composite Fuzzy Relation Equa-
tions, Int. Control, 30, 38-48, 1976.
[18] N. Vadiee, Fuzzy Rule Based Expert Systems-I, Prentice Hall,
Englewood, 1993.
[19] J. M. Blackledge and D. Dubovitsky, A Surface Inspection
Machine Vision System that Includes Fractal Analysis, ISAST
Transactions on Electronics and Signal Processing Vol. 3, No
2, 76-89, 2008.
[20] J. M. Blackledge and D. Dubovitsky, Object Detection and
Classiﬁcation with Applications to Skin Cancer Screening,
ISAST Transactions on Intelligent Systems, Vol. 1, No 1, 34-
45, 2008
[21] M. J. Turner, J. M. Blackledge and P. R. Andrews, Fractal
Geometry in Digital Imaging, Academic Press, London, 1998.
[22] B.
B.
Mandelbrot,
The
Fractal
Geometry
of
Nature,
W.H.Freeman, New York, 1983.
[23] K. Falconer, Fractal Geometry, Wiley, 1990.
[24] N. Sarkar, B. Chaudhuri and P. Kundu, Improved Fractal
Geometry Based Texture Segmentation Technique, IEEE Pro-
ceedings Vol.140 , number 5, pages 233-241, 1993.
[25] J. Keller and S. Chen, Texture Description and Segmentation
through Fractal Geometry, Computer Vision Graphics and
Image Processing, number 45, pages 150-166, 1989.
[26] Cancer research uk, accessed 12.09.2011
http://cancerhelp.cancerresearchuk.org/type/melanoma/
[27] J. S. Lim, Two-Dimensional Signal and Image Processing,
Prentice-Hall, 1990.
[28] J. M. Blackledge and D. Dubovitsky, Morphological Analysis
from Images of Hyphal Growth using a Fractional Dynamic
Model, Theory and Practice of Computer Graphics, University
of Warwick, 2011, p17-24, 2011.
[29] J. M. Blackledge and D. Dubovitsky, Moletest: A Web-
based Skin Cancer Screening System, The Third International
Conference on Resource Intensive Applications and Services,
INTENSIVE 2011, May 22-27, Venice, Italy, 22-29, 2011.
[30] J. M. Blackledge and D. Dubovitsky, Pattern Recognition
in Cytopathology for Papanicolaou Screening, Theory and
Practice of Computer Graphics, Shefﬁeld 6-8 September, Vol.
25, No. 1, 2010.
127
PATTERNS 2011 : The Third International Conferences on Pervasive Patterns and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-158-8

