Measuring the Impact of eGovernment Services 
 
Lasse Berntzen 
Department of Business and Management 
Buskerud and Vestfold University College 
Drammen, Norway 
e-mail: lasse.berntzen@hbv.no 
 
 
Abstract – Impact of eGovernment services is about 
measurable effects as experienced by stakeholders. Automatic 
or 
semi-automatic 
data 
collection 
can 
make 
impact 
assessments more effective, and periodical assessments become 
more feasible.  The paper reviews earlier research on 
eGovernment impact, discusses the problem of impact as a 
function of time, and proposes an indicator set suitable for 
automatic or semi-automatic data collection. 
Keywords – impact; egovernment assessment; indicators; 
indicator sets; measurements; eGovMon. 
I. 
 INTRODUCTION 
The Oxford Dictionary of English [1] defines impact as  
“a marked effect or influence”.  
For e-government services, the definition of impact 
needs to be refined further. eGovMoNet, an EU-funded 
thematic network addressing measurement of eGovernment 
services proposed the following definition [2]: “The 
measurable effect of service initiatives that make a 
difference to its users, providers, or society”. A key concept 
here is a measurable effect. 
The eGovMon project (2008-2012) [3], a research 
project funded by the Research Council of Norway, worked 
with municipalities and government agencies to develop 
methodologies 
and 
tools 
to 
measure 
accessibility, 
transparency, efficiency and impact of eGovernment 
services. 
According to the eGovMon project proposal, impact 
was described as “a measurable positive effect of a service 
on a web site, e.g. number of visitors, user surveys 
explaining level of satisfaction with the service.” 
Another definition by Millard and Shanin [4] links 
impacts to general objectives of eGovernment: “These are 
the overall goals of a policy and are expressed in terms of 
its ultimate impacts. These will not normally be expressed 
as eGovernment objectives, but rather as societal objectives 
to which successful eGovernment development should 
contribute, such as economic growth, jobs, democracy, 
inclusion, quality of life, etc.” 
 
Measuring impact is not easy for two reasons: 
• 
Impact is multi-dimensional and potentially very 
complex. An easy way out is to focus on a very limited 
set of indicators, but simultaneously running the risk of 
loosing key aspects that makes a difference to the 
stakeholders (citizens/users, service providers, society). 
• 
Impact is also a function of time. A measurement will 
never be more than a snapshot of something happening 
over time. 
 
Note that impact can be positive or negative, based on 
what kind of difference it makes to its stakeholders. If the 
impact is positive or negative needs to be addressed from 
the perspective of the respective stakeholder. 
This paper aims at providing a short overview of research 
on impact of e-government, discuss some of the 
complexities involved, and finally, propose how impact data 
can be collected and used for automated or semi-automated 
measurements. 
II. 
RELATED WORK 
There has been limited research on the measurement of 
eGovernment impact. Except from a few academic papers 
from around 2004-2005 (described below), most recent 
search results refer to eGovMoNet thematic network and the 
eGovMon project (described above). 
In one of the first papers discussing impact in the context 
of e-government [5],  Peters, Janssen and van Engers 
observed: “Our analyzes shows a messy picture on the 
measurement 
of 
e-government. 
Many 
measurement 
instruments take a too simplistic view and focus on 
measuring what is easy to measure. Many of the instruments 
focus on measuring the visible front of eGovernment and 
ignore the performance of the cross-agency business 
processes. None of the instruments focus on measuring 
multi-service organizations. The instruments focus on one 
(type of) agency and do not provide an overall picture. “ 
Their conclusion was: “A good theoretical framework for 
measuring the impact of eGovernment and the use of 
resources is still lacking”. 
54
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-324-7
ICDS 2014 : The Eighth International Conference on Digital Society

Aichholzer [6] analyzed the impacts of e-Government in 
Austria. He based his analysis on case studies and found the 
following impacts: 
• 
Reduced process time 
• 
Improved service 
• 
Reduced administrative burden 
• 
Increased efficiency 
• 
Adaption problems and reorganization 
• 
Cost reductions and enhanced revenues 
 
He stated that his analysis was “still largely in its infancy”, 
and that “comprehensive and methodologically sound 
assessment frameworks for measuring e-government effects 
are not yet at hand”. 
 
Amberg et al. [7] used a stakeholder approach to find 
different impacts of eGovernment. The stakeholder analysis 
revealed the following stakeholder groups, and relevant 
impacts for each group: 
 
Citizens (individual and collective) 
• Improved information (quantity and quality) 
• Increased quality of service offerings 
• Increased citizen- friendliness and comfort of application 
flows and services 
• Availability of online service offerings 24 hours a day 
• Time savings (*) 
• Financial savings (*) 
• Increased (perceived) transparency of application flow 
• Improved communication with rural and remote 
communities 
• Increased involvement and participation in decision 
processes at communal level (e-democracy) 
Private sector and non-profit organizations 
• Improved information (quantity and quality) 
• Time savings (*) 
• Financial savings (*) 
• Increased information and service delivery transparency 
• Increased quality of service offerings 
• Improved communication possibilities for organizations 
in rural and remote communities 
Employees 
• Increased motivation 
• Job enrichment and new forms of functions 
• Personnel development (*) 
• Reduced work load 
• Improved working conditions 
Internal organization 
• Reduced costs (*) 
• Increased revenues (*) 
• Increased process efficiency (*) 
• Modernization of IT/communication infrastructure 
(capacity) (*) 
• Improved organizational image as a result of better 
location marketing 
• Increased financial aids and donations (*)  
Central government politics 
• Improved intercommunal communication and 
collaboration 
• Reduced costs (*) 
• Improved efficiency (*) 
• Improved location marketing and image 
• Acceleration of decision processes in public 
administration (*) 
The authors proposed methods to evaluate each effect, 
for most of them qualitative surveys and personal interviews 
and for some (*) measurements of operating figures. Such 
data would typically be accessible from other computer-
based systems (e.g. ERP-system) through a protocol or an 
interface. 
The authors ended up with a proposal for a scoring 
template (Figure 1) for “measuring the total impact of e-
government”. 
The scoring template uses a scale from 0 (insignificant) 
to 10 (significant) to evaluate the effects on each single 
stakeholder. Each single effect is assigned a weight. Each 
stakeholder group is also assigned a weight. The score for 
each effect is multiplied with the weight and the weighted 
scores are added together to give the total impact score. 
 
 
 
Effects on: 
Evaluation 
Weight 
each effect 
Weight 
stakeholders 
(0-10) (E) 
(W) 
(E x W) 
Citizens 
 
 
40% 
effect C1 
--x-------- 
20% 
8% 
effect C2 
-------x--- 
80% 
32% 
Private sector 
 
 
20% 
effect P1 
-----x----- 
50% 
10% 
effect P2 
---x------- 
50% 
10% 
Employees 
 
 
15% 
effect E1 
----x------ 
80% 
12% 
effect E2 
--------x-- 
20% 
3% 
Organization 
 
 
15% 
effect O1 
---x------- 
60% 
9% 
effect O2 
x---------- 
40% 
6% 
Central 
government 
 
 
10% 
effect G1 
----------x 
50% 
5% 
effect G2 
-----x----- 
50% 
5% 
Figure 1. Template for measuring total impact of eGovernment [7] 
In parallel with these efforts, other researchers have 
found easier ways to assess e-government [8]: 
• Counting the number of eGovernment services or making 
a checklist of “most important” eGovernment services. 
55
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-324-7
ICDS 2014 : The Eighth International Conference on Digital Society

• Measuring the maturity of e-services based on their 
complexity or level of integration. 
• Measuring the accessibility or usability aspects of 
eGovernment services. 
The common approach is to address the supply-side. 
What electronic services do the government provide? How 
many and how good are the services? 
Only a small ratio of papers and reports address 
eGovernment services from the citizen or user perspective 
(e.g., Norris [9]). What is the uptake of a service? How 
satisfied are the users?  
Impact is about mixing both perspectives (supply side 
and demand side) with even more dimensions, e.g. uptake 
and satisfaction, to understand the total effect of 
eGovernment services. 
The problem is to find indicators that are relevant and 
preferably possible to collect through automated procedures. 
Heeks [10] investigated the measurement of impact. He 
found the following samples of measure: citizen benefit, 
financial benefit, back-office changes. Samples of indicators 
were; time saved, financial savings perceived by officials, 
nature of changes to government processes, and changes in 
process time. The data gathering methods used were: 
interview, internal self-assessment, questionnaire, popup 
survey. 
He ended up with the following recommendation: 
“Output/Impact Measurement 
Measures beyond adoption in the eGovernment value 
chain are needed to judge the value of eGovernment. 
Most of the impact examples given in Table 3 (of 
Heek`s paper) were measured by self assessment; a 
method with distinct drawbacks, as noted below. As 
also discussed later, there may be emerging 
opportunities to use web metrics/crawlers to assess 
some outputs/impacts but only in certain situations. In 
general, then, output and impact measurements 
require some form of survey. Surveys have been used 
for this but survey data to date seems to have 
concentrated mainly on adoption and use, so there is 
obvious potential for change.” 
Millard and Shahin [4] also links impacts and general 
objectives: “Outcomes are converted to impacts (defined as 
the general objectives) by the ICT-enabled policy 
achievement intervention logic. Impacts are at the societal 
level, and encompass what eGovernment outcomes should 
contribute to. This could include: 
• economic productivity 
• economic growth 
• jobs 
• competitiveness 
• local and regional development 
• environmental improvement and sustainable development 
• inclusion 
• democracy, participation and citizenship 
• quality of life / happiness 
• increased justice and security 
• universal human rights and peace 
The consulting companies Deloitte Consulting and 
Indigo [11], working on behalf of the European 
Commission, published a study on the measurement of 
eGovernment user satisfaction and impact. 
The introduction says:  
“The European Commission Information Society and 
Media study on measurement of user satisfaction and 
impact has developed a multilayer user-satisfaction 
and impact measurement toolkit aimed at providing 
both policy makers and public agencies with the 
necessary information and tools for the analysis of 
public sector service provision. This standardized 
survey framework provides a hands-on approach to a 
set of customizable survey tools”. 
But, when discussing measurement of user impact, the 
report focuses on effectiveness, giving the following 
examples: 
• reduced administrative burden – examples: % change in 
time and costs saved by citizens and businesses, or in 
number of users reporting e-service saved time over 
traditional methods for a standard bundle of services; 
• increased users’ value and satisfaction – examples: % 
change in waiting times for a standard bundle of services, 
or in number of users reporting eGovernment services to 
be useful; 
• more inclusive public services – examples: % increase of 
eGovernment use by socially disadvantaged groups, or of 
number of SMEs bidding for public tenders 
electronically. 
This short literature review shows the complexity as 
well as the almost endless possibilities that exist for making 
indicators. 
III. 
A MODEL TO UNDERSTAND IMPACT 
Stragier, Verdegen, and Verleye developed the model 
shown in Figure 2, to describe the relationship between 
input, output, outcome and impact [2,12]. The eGovMoNet 
thematic network used this model.  
The model shows the following four types of outcomes 
from 
eGovernment: 
benefits, 
barriers, 
uptake 
and 
satisfaction, which again makes impact on different 
stakeholders/stakeholder groups. 
By collecting information on benefits (e.g. improved 
efficiency, transparency and/or quality), barriers (e.g., 
accessibility barriers), uptake (ratio or number of users) and 
satisfaction (through e.g., user satisfaction surveys), it 
would be possible to compute an impact score for each 
stakeholder/stakeholder group. 
 
56
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-324-7
ICDS 2014 : The Eighth International Conference on Digital Society

 
 
Figure 2. Framework for measuring impact [2,12]. 
IV. 
ONE PROBLEM: IMPACT AND TIME 
Impact can have several dimensions and be seen as a 
function of time. Therefore a measurement can show one 
dominant type of impact at time t1 and another type of 
impact at time t2. Ideally, impact is measured relative to 
time t0, before the service is made available. 
 
One illustrative example: A municipality introduces an 
eGovernment 
service 
to 
handle 
application 
for 
kindergartens. The use of this service is mandatory. Parents 
experiencing problems are advised to visit the municipal 
service center for help and instruction. Most parents 
experience no problems with the service, but a few feel they 
lack the necessary competence to use the service. The 
employees working at the service center get some 
complaining visitors (“everything was better before”), but 
spend time showing them how to use the system. 
The short-term impact is that most users adopted the 
electronic service, but the introduction also created a high 
level 
of 
noise. 
The 
administrative 
gains 
for 
the 
administration were not very high. 
However, the following year, due to efforts put in the 
first year, things went more smoothly, with almost no 
complaints and increased efficiency. 
This shows that impact is something fluid that changes 
over time. It is only possible to take snapshots of impact. 
V. 
HOW TO MEASURE IMPACT 
For the eGovMon project it was necessary to balance an 
almost unlimited number of possible dimensions of impact 
with the need for an effective data collection regime. 
Therefore, eGovMon did not address long term impact of 
eGovernment services, but more the short-term effects as 
seen by citizens/users and administration. It was also 
necessary to select indicators that could be collected 
automatically or with limited effort. 
The indicators were developed and discussed during 
workshops with eGovMon partners (municipalities and 
public agencies). 
 
Two stakeholder groups were identified: 
• Citizens/users 
• Administration 
For the first stakeholder group, the following outcomes 
were identified: 
• Benefits 
• Barriers 
• Uptake 
• Satisfaction 
For the second stakeholder group, one outcome was 
identified: 
• Benefits 
Even if it would be possible to identify barriers, uptake 
and satisfaction from the administration side, these 
outcomes are less relevant since eGovMon targets existing 
services. Therefore, potential barriers have already been 
removed; the uptake is in place (the administration 
processes the results of the service), and at this stage, should 
the administration not be satisfied with the service, it is their 
own problem. 
This gives the following set of five indicators: 
• Benefits for the citizen/user 
• Barriers experienced by the citizen/user 
• Uptake by citizens/users 
• The satisfaction reported by the citizen/user 
• Benefits for the administration 
A. Benefits for the citizen/user 
One of the benefits addressed already is the efficiency 
gain for the user. Other benefits may be faster response, 
access from everywhere at any time, and better quality. As a 
starting point, the efficiency gain for citizens/users is 
selected as indicator, with the possibility to incorporate 
other aspects at future times. 
B. Barriers experienced by the citizen/user 
Barriers include access to technology, accessibility and 
appropriate training. Since access to technology is not seen 
as a problem in Norway (the digital divide is almost non-
existent), the accessibility score can be used as an indicator. 
Since services often are provided through forms, it may also 
be beneficial to address certain specific issues e.g. 
• Prefilled content 
• Validation of fields where appropriate 
• Help information available 
• Meaningful error messages (in user’s own language) 
57
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-324-7
ICDS 2014 : The Eighth International Conference on Digital Society

• For multi-page forms – possibility to move back and 
forth 
• Possibility to provide user feedback (feedback button) 
• The possibility to complete a form after a break (no 
timeout) 
C. Uptake by citizens/users 
Uptake would typically be the ratio between users of 
the electronic service and the total number of (potential) 
users.  
D. The satisfaction reported by the citizen/user 
Satisfaction can be reported through electronic surveys, 
or even better, a small survey upon exit. “Please rate your 
overall satisfaction with this electronic service”. 
E. Benefits for the administration 
The efficiency gain for the administration has been 
addressed earlier. Other benefits may include quality 
improvement of data submitted due to built in validation of 
forms. 
The scores of each of the five indicators can be 
normalized (e.g., on a scale from 0 to 20) and then be added 
to produce an impact score (e.g., 0 to 100).  
VI. 
CONCLUSION AND DISCUSSION 
In this paper, we have given an overview of some 
previous attempts to measure eGovernment impact, and also 
proposed a new set of indicators. Following Heeks [8], self-
assessments have been avoided, and focus has been put on 
data collection by web metrics/crawlers and surveys. Data 
collection can then be made automatic or semi-automatic. 
The proposed indicator set tries to balance ease of use with 
the complexity of impact analysis. The indicator set uses 
five indicators to measure impact both from the citizen/user 
side and from the administrative side, and can be used for 
longitudinal studies of impact. 
ACKNOWLEDGMENT 
The eGovMon project was co-funded by the Research 
Council of Norway under the VERDIKT program. Project 
no.: VERDIKT 183392/S10. 
The author wants to thank the eGovMon core team for 
valuable input and discussions. 
REFERENCES 
[1] 
Oxford English Dictionary, Oxford University Press, 2006 
[2] 
Verleye, G., Karamagioli, E., Verdegem, P., Jenner, S. and Lorenzo, 
E. Measure Paper 3; Impact measurement. 
https://www.academia.edu/1020911/Measure_paper_3_Impact_meas
urement [Retrieved Feb 2014] 
[3] 
eGovMon Project Folder 
http://archive.tingtun.no/eGovMon/folder_egovmon_org.pdf 
[Retrieved Feb 2014] 
[4] 
Millard, J., Leitner, C. and Shahin, J. Towards the eGovernment 
vision for EU in 2010: research policy challenges. Institute for 
Prospective 
Technological 
Studies. 
2006. 
http://ftp.jrc.es/EURdoc/eur22635en.pdf 
[5] 
Peters, Rob M., Janssen, Marijn and van Engers, Tom M. Measuring 
eGovernment 
Impact: 
Existing 
practices 
and 
shortcomings. 
Proceedings of the 6th international conference on Electronic 
Commerce, ACM, New York, 2004, pp. 480-489. 
[6] 
Aichholzer, G., Service Take-Up and Impacts of E-Government in 
Austria. In Wimmer, M. et al. (eds.). Electronic Government, 
Proceedings 4th International Conference EGOV 2005. Lecture Notes 
in Computer Science 3591, Springer. 2005, pp. 93-104. 
[7] 
Amberg, M., R. I. Markov, et al. A Framework for Valuing the 
Economic Profitability of e-Government. Proceedings of the 1st 
International Conference on e-Government ICEG 2005, Academic 
Conferences, 2005, pp. 45-55. 
[8] 
Berntzen, L, & Olsen, M.G., "Benchmarking e-Government - A 
Comparative Review of Three International Benchmarking Studies," 
Proceedings, Third International Conference on Digital Society 
(ICDS), 2009 pp.77-82 
[9] 
Norris, D. F. e-Government Impacts at the American Grassroots: An 
Initial Assessment. Electronic Government. Proceedings of the 3rd 
Internatinal Conference EGOV 2004, Lecture Notes in Computer 
Science 3183, Springer, 2004, pp. 371-376. 
[10] Heeks, R. Understanding and measuring eGovernment: International 
benchmarking studies, United Nations 
http://unpan1.un.org/intradoc/groups/public/documents/un/unpan0236
86.pdf, 2006 [Retrieved Feb 2014] 
[11] Deloitte Consulting and Indigov (2008) Study on the Measurement of 
eGovernment User Satisfaction and Impact. European Commission 
http://www.epractice.eu/files/EU%20UserSat_Final%20Report.pdf 
[Retrieved Feb 2014] 
[12] Stragier, J., Verdegen, P., and Verleye, G. (2010) “How is e-
Government Progressing? A Data Driven Approach to e-Government 
Monitoring”, Journal of Universal Computer Science, vol. 16, no. 8, 
2010, pp. 1075-1088.
 
58
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-324-7
ICDS 2014 : The Eighth International Conference on Digital Society

