Smartphone-Based 3D Navigation Technique for Use in a Museum Exhibit  
 
L.-P. Bergé1, G. Perelman1, M. Raynal1, C. Sanza1, M. Serrano1, M. Houry-Panchetti1, R. Cabanac2, E. Dubois1
1 IRIT, Université Paul Sabatier 
University of Toulouse 
Toulouse, France 
{Louis-Pierre.Berge, Emmanuel.Dubois}@irit.fr 
2 Télescope Bernard Lyot, Observatoire Midi-Pyrénées 
University of Toulouse 
Tarbes, France 
remi.cabanac@obs-mip.fr 
 
 
Abstract—3D Virtual Environment (3DVE) comes up as a good 
solution for transmitting knowledge in a museum exhibit. 
However, interaction techniques involved in such settings are 
mostly based on traditional devices such as keyboard and 
mouse. Recently, the popular use of smartphone as a personal 
handled computer lets us envision the use of mobile device as 
an interaction support with these 3DVE. In this paper, we 
focus on the navigation task inside a 3DVE and we propose to 
use the smartphone as a tangible object. Physical actions on the 
smartphone trigger translations and rotations in the 3DVE. In 
order to prove the interest in the use of the smartphone, we 
compare our solution with available solutions: keyboard-
mouse and 3D mouse. User experiments confirmed our 
hypothesis and particularly emphasizes that visitors find our 
solution more attractive and stimulating. 
Keywords-interaction with smarpthone, 3D navigation, 
museum exhibit, experiment. 
I. 
INTRODUCTION 
With the evolution of technology, computing capabilities 
and 
rendering techniques, the use of 3D Virtual 
Environments (3DVE) is becoming a standard. They are no 
longer restricted to industrial use and they are now available 
to the mass-market in various situations: for leisure in video 
games, to explore a city in Google Earth or in public displays 
[1], to design a kitchen on a store website or to observe rare 
or fragile objects in a museum. However, in these mass 
market contexts, the visitor’s attention must be focused on 
the content of the message and not distracted by any 
difficulties caused by the use of a complex interaction 
technique. This is especially true in a museum where the 
maximization of the knowledge transfer is the primary goal 
of an interactive 3D experience. Common devices, such as 
keyboard and mouse [2] or joystick [3] are therefore widely 
used in museums. To increase the immersion of the user, 
solutions combining multiple screens or cave-like devices [4] 
also exist. However, these solutions are cumbersome, 
expensive and not widespread. 
Alternatively the use of smartphone, as a personal 
handheld computer, is commonly and largely accepted. 
Smartphones provide a rich set of features and sensors that 
can be useful to interact, especially with 3DVE and with 
remote, shared and large displays. Smartphones also create 
the opportunity for the simultaneous presence of a private 
space of interaction and a private space of viewing coupled 
with a public viewing on another screen. Furthermore, many 
researches have already been performed with smartphone to 
study their use for interacting with a computer. They explore 
multiple aspects such as technological capabilities [5], tactile 
interaction techniques [6], near or around interaction 
techniques [7]. Given the potential in terms of interaction 
support and the availability of smartphones in anyone's 
pocket, we explore in this paper benefits and limitations of 
the use of a smartphone for interacting with a 3DVE 
displayed in a museum context.  
This paper is focusing on one task: the navigation inside 
a 3DVE. This is the most predominant task a user will have 
to perform in order to discover and understand the virtual 
space. Concretely our technique translates motions of the 
smartphone into motions of the point of view in the 3DVE. 
We thus propose 1) to consider a smartphone as a tangible 
object, in order to smoothly integrate it in a museum 
environment and because it has been proven to be easier to 
apprehend by newcomers [8], 2) to display feedback and/or 
personalized information on the smartphone display, 3) to 
deport the display of the 3DVE on a large screen, in order to 
provide a display space visible by multiple users as required 
in museum contexts. As a result, our technique combines the 
use of a popular and personal portable device, the physical 
space surrounding the device and the user gestures and input 
for navigating inside a 3DVE. 
We compared our designed solution to the use of more 
common and available technologies: the keyboard-mouse 
device and a 3D mouse device. We proposed a controlled 
evaluation focused on the interaction techniques: out of a 
specific museum context, the user will not be distracted by 
pedagogical content. We measure usability and attractiveness 
in conjunction with performance considerations. The results 
confirm the interest of considering the use of personal 
mobile devices for navigating inside a 3DVE: results are 
particularly significant in terms of user attractivity.  
In the following sections, we first detail our interaction 
technique. Next, we present the settings of the user 
experiment. We finally discuss the results, the place of our 
solution in the related work and we conclude with 
perspectives for improving the technique. 
II. 
OUR INTERACTION TECHNIQUE 
As described above, our interaction technique is based on 
the manipulation and use of a smartphone, a familiar and 
personal object for most of the users. Three major 
characteristics define our interaction technique: tangible 
manipulation of the smartphone, personalized data displayed 
on the smartphone and 3DVE displayed on a remote screen. 
252
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

We restricted the degrees of freedom of the navigation 
task in order to be close to human behavior and existing 
solutions in video game with standard device: two degrees of 
freedom (DOF) are used for translations (front/back and 
left/right) and two for rotations (up/down and left/right). We 
did not include the y-axis translation and the z-axis rotation 
since they are not commonly used for the navigation task. To 
identify how to map the tangible use of the smartphone to 
these DOF, we first performed a guessability study. 
A. Guessability study 
14 participants have been involved and they were all 
handling their own smartphone in the right hand. To 
facilitate the understanding, the guessability study dealt with 
only one translation and one rotation. A picture of a 3DVE 
was presented to participants on a vertical support. It 
included a door on the left of the 3D scene and participants 
were asked to perform any actions they wished with their 
smartphone in order to be able to look through the door. A 
second picture was then displayed: now facing the door, 
participants were instructed to pass through the door.  
In this second question, 11 participants performed hand 
translations to translate the point of view. Interestingly none 
suggested using the tactile modality. Results are more 
contrasted with the first question, requiring a rotation: 5 par-
ticipants used a heading rotation of the handled smartphone; 
1 only used the roll technique; 3 proposed to touch the target 
with their smartphone; 5 participants placed the smartphone 
vertically (either in landscape or portrait orientation) and 
then rotated the smartphone according to the vertical axis 
(roll) thus preventing the view on the smartphone screen.  
B. Design solution 
From the guessability study, we retain that physical 
translations of the smartphone seem to be the most direct 
way to perform translations of the point of view in the 
3DVE. It has been implemented in our technique as follow. 
Bringing the smartphone to the left / right / front or back of 
its initial position triggers a corresponding shifting 
movement of the point of view in the 3DVE (Figure 1-a). 
The position of the point of view is thus controlled through a 
rate control approach; the rate applied is always the same and 
constant. In addition, feedback is provided on the 
smartphone. A large circle represents the initial position of 
the smartphone and the physical area in which no action will 
be triggered: the neutral zone. A small circle represents the 
current position of the smartphone and arrows express the 
action triggered in the 3DVE. As long as the small circle is 
inside the large circle, the navigation in the 3DVE is not 
activated. In addition it is possible to combine front / back 
translation with right / left translation. The feedback 
provided during each of four possible motions is illustrated 
in Figure 1-b. Finally, the smartphone vibrates every time 
that the navigation action is changed. 
Regarding rotations, we retain from the guessability 
study the most usable solution: rotations of the hand-wrist 
handling the smartphone are mapped to orientations of the 
point of view in the 3DVE. In our implementation, 
horizontal wrist rotations to the left/right of the arm are map- 
 
Figure 1: Our smartphone based interaction. (a) Physical action for 
translation. (b) Feedback of the translation: front, left, front and right, back 
translation. (c) Physical action for rotation. (d) Feedback of the rotation. 
ped to left/right rotations of the viewpoint (heading axis, rY) 
and wrist rotations above/below the arm are mapped to 
up/down rotations of the viewpoint (pitch axis, rX) (Figure 
1-c). A position control approach has been adopted here that 
establishes a direct coupling of the wrist angle with the point 
of view orientation. A constant gain has been set for the wrist 
rotations: the limited range of 10° to left and right [9] can be 
used to cover the range of the rotation angle inside the 3DVE 
(180°). This solution does not support a U-turn: this was not 
required in the experiment but could be solved by 
transforming the position control into a rate control when the 
wrist reaches a certain angle. In addition, two "spirit levels" 
feedback are displayed on the smartphone to provide an 
estimation of the current orientations of the smartphone 
(Figure 1-d) with respect to the initial orientations used as a 
reference. 
To avoid unintended motions of the virtual camera in the 
3DVE, translations and rotations of the smartphone are 
applied to the 3DVE only when the user is pressing a button 
“navigate” displayed on the smartphone. 
The smartphone also displays a “calibrate” button. This 
allows the user to recalibrate the smartphone at will, i.e., to 
reset the center of the neutral zone to the current position of 
the smartphone and the reference orientations.  
III. 
EXPERIMENT 
We 
conducted 
an 
experiment 
to 
compare 
our 
smartphone-based interaction technique with two other 
techniques using devices available in museums: a keyboard-
mouse combination and a 3D mouse. In the museum context, 
the temporal performances are not predominant. In fact our 
goal was to assess and compare the usability and 
attractiveness of these three techniques. Our protocol does 
not include museum information in order to keep the 
participant focused on the interaction task.  
A. Task 
The task consisted in navigating inside a 3D tunnel com-
posed by linear segments ending in a door (Figure 2-b). The 
task is similar to the one presented in [10] and sufficiently 
generic to correctly evaluate the interaction techniques. 
Participants had to go through the segments and go across 
the doors but could not get out of the tunnel. Black arrows on 
the wall allow finding easily the direction of the next door. 
The segments between the doors formed the tunnel, whose 
orientation was randomly generated in order to include all 25 
possible directions to the next door. The center of each door 
is placed 0, 20 or 40 pixels to the left or right and to the top 
a)
b)
c)
d)
rY
rX
rY
rX
253
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

 
Figure 2. (a) Representation of one segment of the 3D tunnel. 
(b) Screenshots of the 3D environment of the experiment. 
 
Figure 3. (a) The keyboard-mouse, (b) The 3D mouse and (c) the 
smartphone configuration. (d) The Polhemus sensor. 
or bottom of the center of the previous door (Figure 2-a). The 
movement of the user is not subject to gravity. When the user 
looks up and starts a front translation movement, the result-
ing motion is a translation in the direction of point targeted. 
B. Interaction techniques 
We compared three techniques: keyboard-mouse, 3D 
mouse and our technique based on a smartphone. In 
keyboard-mouse, movements of the mouse control the 2 
DOF point of view of the virtual camera (orientation). The 
four directional arrow of the keyboard control the 2 DOF of 
the translation of the virtual camera. In 3D mouse, the 
participant applies lateral forces onto the device to control 
translation (right/left, front/back), and rotational forces to 
control orientations of the virtual camera. The use of our 
technique, the smartphone, has been described in section II. 
For the three techniques, it appears that left/right translations 
are particularly useful when collision with doors occurs. 
For each technique we determined the speed gain of the 
translation and rotation tasks through a pre-experiment with 
six subjects. We asked participants to navigate inside our 3D 
virtual environment with each technique and to freely adjust 
the gains to feel comfortable performing the task. We 
stopped the experiment and recorded the settings when the 
participant successfully went through 5 consecutive doors. 
Finally, for each technique, we averaged the values of gain 
between participants. We noticed that the gain of the 
translation of keyboard-mouse was higher than the 3D 
mouse or smartphone. This is probably due to the habit of 
subjects to manipulate this technique.  
C. Apparatus 
The experiment was done in full-screen mode on a 24″ 
monitor with a resolution of 1920 by 1080 pixels. We 
developed the environment with a 3D open source engine, 
Irrlicht, in C++. For the keyboard and mouse device, we used 
a conventional optical mouse and a standard keyboard with 
180 keys (Figure 3-a). For the 3D mouse we used the Space-
Navigator [11] (Figure 3-b), a commercial device with 6 
DOF. For the smartphone, we implemented the technique on 
a Samsung Galaxy S2 running Android 4.1.2 (Figure 3-c). 
To avoid an overload of the smartphone computing 
capabilities with the processing of the internal sensors 
(accelerometers, gyroscope) we used an external 6D tracker: 
the Polhemus Patriot Wireless (Figure 3-d). We attached a 
sensor on the rear face of the smartphone. Via a driver 
written in C++, the marker returns the position and the 
orientation of the smart-phone. We filtered the data noise 
with the 1€ filter [12]. 
D. Participants and procedure 
We recruited a group of 24 subjects (6 female), of 29.3 
(SD=9) years old on average. All subjects were familiar with 
the keyboard and mouse, 17 of them had a smartphone and 
only 1 has used the 3D mouse.  
Every 
participant 
performed 
the 
3 
techniques 
(smartphone, keyboard-mouse and 3D mouse). They started 
with the keyboard-mouse technique in order to be used as a 
reference. The order of smartphone and 3D mouse 
techniques was counterbalanced to limit the effect of 
learning, fatigue and concentration. For each technique, the 
subject navigated inside 6 different itineraries. We 
counterbalanced the itineraries associated with each 
technique across participants so that each technique was used 
repeatedly with each group of users. 
Participants were sited during the experiment and were 
instructed to optimize the path, i.e., the distance travelled. 
They could train themselves on each technique through one 
itinerary. When the user passed through a door, a positive 
beep was played. When the user collided with an edge of the 
tunnel, a negative beep was played. 
After having completed the six trials for one technique, 
the subject filled the SUS [13] and AttrakDiff [14] 
questionnaires and indicated three positive and negative 
aspects of the technique. The procedure is repeated for the 
two remaining technique. The experiment ended with a short 
interview to collect oral feedback. The overall duration of the 
experiment was about 1 hour and 30 minutes per participant. 
E. Collected data 
In addition to the SUS and AttrakDiff questionnaires 
filled after each technique to measure usability and 
attractiveness, we also asked for a ranking of the three 
interaction techniques in terms of preferences. From a 
quantitative point of view we measured the traveled distance 
and the number of collisions.  
IV. 
RESULTS 
We present in the following section quantitative and 
qualitative results obtained. 
A. Quantitative results 
First a Kruskal-Wallis test confirmed that none of the 18 
randomly chosen itineraries had an influence on the collected 
results. On average we observed that the travelled distance is 
the smallest with the keyboard-mouse (2766px, SD = 79), 
followed by the 3D mouse (2881px, SD = 125) and the 
smartphone (2996px, SD = 225). According to a Wilcoxon 
test these differences are significant. The same conclusions 
254
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

 
 
 
Figure 4: Evolution of the travelled distance and the amount 
of collisions according to 6 trials of the subjects 
Figure 5: Portfolio generated 
on the AttrakDiff website 
Figure 6: Average values for the four dimensions of 
the AttrakDiff questionnaire 
can be drawn with regard to the amount of collisions 
(keyboard-mouse: 5.08, SD = 5.68; 3D mouse: 16.11, SD = 
15.86; smartphone: 33.35, SD = 24.64).  
Given the high dispersion of the distance and collision 
measures, we refined this analysis in distinguishing the 
results obtained for each of the six trials performed by the 24 
participants (Figure 4). This refined analysis reveals a 
significant learning effect with the smartphone technique: 
between the first and sixth trial, the distance is 7.3% shorter 
(Wilcoxon test,         ) and collision are reduced of 
43.3% (Wilcoxon test,         ). A significant learning 
effect is also observed with the 3D mouse, but only in terms 
of distance and with a smaller improvement (1.6% shorter, 
Wilcoxon test,        ).  
The learning effect with the smartphone is so important 
that, at the last trial, the travelled distance for the smartphone 
(2893px) and the 3D mouse (2873px) is comparable (no 
significant difference, Wilcoxon test,       ). 
B. Qualitative results  
Three aspects have been considered in the qualitative 
evaluation: usability, attractiveness and user’s preference.  
Usability evaluation: the SUS questionnaire [13] gives 
an average score of 82.60 (SD=12.90) for the keyboard-
mouse, 54.79 (SD=22.47) for the smartphone based 
interaction and 53.54 (SD=27.97) for the 3D mouse. A 
Wilcoxon test shows that the SUS difference is statistically 
significant between the keyboard-mouse and each of the two 
other techniques (3D mouse, smartphone). However, the 
SUS difference is not statically significant between the 3D 
mouse and the smartphone. Research conducted on the 
interpretation of the SUS score [15] permits to classify the 
usability of the keyboard-mouse as “excellent”. According to 
this same interpretation scale, the usability of the smartphone 
and the 3D mouse is identified as “ok”. 
We also note a wide dispersion of the SUS score. We 
thus performed a more detailed analysis of the SUS score. 
First, according to [15] a system with a “good” usability 
must obtain a score above 70. In our experiment, 33% of 
participants scored the 3D mouse above 70 while 37% of 
participants scored the smartphone above 70. Second, 3D 
mouse and smartphone were two techniques unfamiliar to 
the participants. Results of the SUS questionnaire shows that 
when the smartphone is used after the 3D mouse, the average 
score for the smartphone is 65.62 whereas in the other order 
the average score is 43.96. The perceived usability of the two 
unfamiliar techniques is therefore lower than the perceived 
usability of the keyboard-mouse. However, once the 
participants 
have 
manipulated 
these 
two 
unfamiliar 
techniques, the perceived usability of the smartphone 
increases drastically.  
Attractiveness: Data collected using AttrakDiff [16] 
give an idea of the attractiveness of the technique and how it 
is experienced. Attrakdiff supports the evaluation of a system 
according to four distinct dimensions: the pragmatic quality 
(PQ: product usability, indicates if the users could achieve 
their goals using it); the hedonic quality – stimulation (HQ-
S: determine to which extent the product can support the 
need in terms of novel, interesting and stimulating functions, 
contents and interaction); the hedonic quality – identity (HQ-
I: indicates to what extend the product allows the user to 
identity with it); the attractiveness (ATT: global values of the 
product based on the quality perception).  
Figure 5 shows a portfolio of average value of the PQ 
and the HQ (HQ-S+HQ-I) for the three interaction 
techniques assessed in our user experiment.  
The keyboard-mouse was rated as “fairly practice-
oriented”, i.e., one of the first levels in the category “task-
oriented”. According to the website report [16], the average 
value of PQ (above 1) indicates that there is definite room of 
improvement in terms of usability. The average value of HQ 
obtained (approx. -1) expresses that there is clearly room for 
improvement in terms of user’s stimulation. The 3D mouse 
was rated as “fairly self-oriented”, i.e., one of the first levels 
in the category “self- oriented”. The average value of PQ 
(approx. 0) expresses that there is room for improvement in 
terms of usability. The average value of HQ obtained 
(approx. 1) expresses that room for improvement also exists 
in terms of user’s stimulation. The smartphone was rated as 
“self-oriented”. The average value of PQ (approx. 0) 
expresses that there is room for improvement in terms of 
usability. The average value of HQ obtained (above 1) 
expresses that the user identifies with the product and is 
motivated and stimulated by it. 
Figure 6 summarizes the average values for the four 
AttrakDiff dimensions of the three interaction techniques. 
With regards to the four dimensions the smartphone is rated 
higher than the 3D mouse and the differences are statistically 
significant (T-test, p<0.05). For the PQ value the keyboard-
mouse is better than the smartphone (statistically significant, 
p<0.05). For HQ-I and HQ-S values the smartphone is better 
than the keyboard-mouse (statistically significant, p<0.05). 
255
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

In terms of ATT, smartphone is again rated higher than 
keyboard-mouse but the difference is however not 
statistically significant (p>0.05). Compared to the keyboard-
mouse, the smartphone is considered as novel, innovative, 
inventive, stylish and creative. Improvements in term of 
simplicity, straightforwardness or predictability could 
increase the average value of PQ and probably increase even 
more the ATT value of the smartphone. 
 User preference: at the end of the experiment a short 
semi-guided interview was performed. Participants were first 
asked to rank the three techniques from 1 (best) to 3 (worst). 
Results are in line with the SUS scores: the keyboard-mouse 
technique is largely preferred and the 3D mouse is by far the 
least appreciated technique: only 2 participants out of 24 
ranked it as the best, and 14 ranked it as the worst. The 
smartphone based-interaction is ranked uniformly in the 
three places (7, 9, 8). 
Finally, three positive points and three negative points 
were asked for each technique. The most frequently 
mentioned positive points are “quick”, “easy” and “accurate” 
for the keyboard-mouse technique, “intuitive”, “novel” and 
“usable with on hand” for the 3D mouse and “immersive”, 
“funny”, and “accessible to everybody” for the smartphone. 
Participants are thus appreciating the conditions of use 
created by the smartphone while they particularly pinpoint 
the effectiveness of the mouse and provide general 
comments about the 3D mouse. 
The most frequently mentioned negative aspects is a 
practical aspect for the keyboard-mouse (“requires the use of 
both hands”). They are related to the effectiveness of use of 
the 3D mouse (“difficulty to combine translation and rotation 
at the same time”, “lack of precision” and “high need for 
concentration”) and for the smartphone it focuses on one 
specific feature (“difficulty to translate to the left or right”) 
and the overall context of use (“the apparent time of 
learning” and “the fatigue caused in the arm”).  
Technical issues for the 3D mouse and effectiveness of 
the keyboard-mouse are thus highlighted while benefits and 
limits related to the interactive experience are mentioned for 
the smartphone. This clear shift of interest between the three 
techniques reveals that the disappointing performances of the 
smartphone highlighted in the previous section are not totally 
overruling the interest of the participants for the smartphone-
based technique. It is therefore a very interesting proof of 
interest for further exploring the use of smartphone in 3DVE. 
V. 
DISCUSSION 
Among the existing attempts for exploring the navigation 
of 3DVE with a smartphone, two different settings exist. A 
first set of solutions, as opposed to our setting, propose to 
display the 3DVE directly on the smartphone. Different 
techniques are explored to change the point of view inside 
the 3D scene: tactile screen like Navidget [17], integrated 
sensor [18], smartphone motions in the space around a 
reference, as Chameleon technique [19] and T(ether) [20] 
and manipulation of physical objects around the smartphone 
[21]. The second set of solutions avoids issues related to 
occlusion of the 3DVE with fingers by displaying the 3DVE 
on a distant screen. These solutions involved integrated 
sensor [22] to detect user’s motions, tactile screen [23] or a 
combination of both [24]. Although our technique is clearly 
in line with this second set of solutions, our use of the 
smartphone presents three major originalities. Firstly, the 
smartphone is not limited to a remote controller: it is also 
used to provide the user with feedback or personalized 
information. Secondly, using tactile interaction to support the 
navigation would occlude part of the screen and prevent its 
use for visualizing data, selecting objects or clicking on 
additional features. Instead, physical gesture are applied to 
the smartphone to control rotations like in [25] or [24] but 
also to control translations of the point of view in the 3DVE. 
Thirdly, the choice of the gestures to apply has been guided 
by the results of a guessability study that highlight the most 
probable gesture users would perform with a smartphone. 
We used this approach rather than a pre-experiment or 
results of existing experiment [24] because when getting 
familiar with the manipulation of smartphone, universal 
gestures will be adopted, and not necessarily those known as 
the most efficient. User’s prime intuition of use looked more 
important to us. 
Beyond the interaction technique designed, the contribu-
tion includes a set of evaluation results. The user experiment 
revealed a significant learning effect with the smartphone. 
This is a very encouraging result because no learning effect 
was observed with keyboard-mouse and 3D mouse although 
the participants were unfamiliar with 3D mouse and 
smartphone: the use of smartphone thus significantly 
improves over the time. Results also revealed that the use of 
our smartphone based technique to navigate inside a 3DVE 
is more attractive and stimulating than more usual technique 
such as the keyboard-mouse and the 3D mouse. In terms of 
usability, user's preferences (interaction technique ranking) 
and quantitatively (travelled distance and amount of 
collisions) our smartphone technique appears to be weaker 
than the keyboard-mouse technique but similar to the 3D 
mouse. This tradeoff between attractivity and usability 
/performance emphasizes that compared to two manufac-
tured devices, our technique is better accepted but weaker in 
performance and usability. This is particularly encouraging 
because technological improvements of our technique, such 
as mixing the use of integrated sensor with image processing 
to compute more robust and accurate smartphone position 
and orientation, will also increase the user's performance. In 
addition the use of smartphone is already widely spread and 
we believe that their use as an interaction support with 
remote application will develop as well and become a usual 
interaction form. Altogether this user experiment establishes 
that the use of smartphone to interact with 3DVE is very 
promising and need to be further explored.  
Finally, to validate the interest of the approach in an 
operational context, the presented smartphone technique is 
currently running in an animated 3DVE representing a large 
telescope. The interactive installation (Figure 7) is used in a 
museum to explain the different parts of the telescope and 
how the telescope is operated. Visitors virtually navigate in 
the dome of the telescope to observe the different elements 
and perform complementary actions such as selecting a star 
or controlling the telescope. A large and varied audience,  
256
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

 
Figure 7: Interactive installation with our smartphone based interaction 
ranging from scholar to retired persons, are using this 
interactive installation. An in-situ evaluation of the use of the 
technique in comparison to other will soon be performed. 
VI. 
CONCLUSION 
In this paper, we explored the feasibility of using a 
smartphone to navigate inside a 3DVE displayed in the 
context of a museum exhibit. Smartphones present the 
advantage to provide a private space for viewing and to 
constitute a personal device for navigating or controlling a 
3D cultural or pedagogical content. Generalizing its use 
throughout a museum is also completely imaginable. With a 
QR code the visitor can easily download the mobile app in 
front of the exhibit and interact with the 3DVE. The 
originality of our technique relies on the fact that the 
smartphone is used as a tangible object. Physical actions on 
the smartphone trigger translation and rotation in the 3DVE. 
Very promising results have been highlighted in a user 
experiment comparing our solution to a keyboard-mouse 
technique and a 3D mouse, the most common devices found 
in museum nowadays. We measured that after a short learn-
ing time, the smartphone technique leads to performance 
results that are comparable to the 3D mouse. Through 
technical optimization we are also confident that it might 
become comparable to the keyboard-mouse technique. But 
more notably, we clearly established that visitors find such a 
solution more attractive and stimulating.  
In this study, we have therefore established that the use 
of a smartphone as a tangible object for navigating inside a 
3DVE is a good alternative to the keyboard-mouse and 3D 
mouse. A part from the technical improvements already 
mentioned we plan to investigate the causes and length of the 
learning effect. To complete our study, it could be interesting 
to measure the impact of the use of a smartphone on the 
museum visit and on the quality of the educational transfer. 
Finally, using a hand free interaction with the smartphone for 
navigating inside a 3DVE opens up perspectives for 
controlling additional features in the 3DVE with the 
smartphone that we will integrate. 
REFERENCE 
[1] D. S. Tan, D. Gergle, P. Scupelli, and R. Pausch, “Physically 
large displays improve performance on spatial tasks,” ACM 
Trans. Comput. Interact., vol. 13, Mar. 2006, pp. 71–99. 
[2] L. Pecchioli, M. Carrozzino, F. Mohamed, M. Bergamasco, 
and T. H. Kolbe, “ISEE: Information access through the 
navigation of a 3D interactive environment,” J. Cult. Herit., 
vol. 12, no. 3, Jul. 2011, pp. 287–294. 
[3] T. Wischgoll and J. Meyer, “An explorational exhibit of a 
pig’s heart,” in ACM SIGGRAPH 2005, 2005, p. 138. 
[4] C. Christou, C. Angus, C. Loscos, A. Dettori, and M. Rous-
sou, “A versatile large-scale multimodal VR system for cul-
tural heritage visualization,” in VRST’06, 2006, pp. 133–140. 
[5] H. Graf and K. Jung, “The smartphone as a 3D input device,” 
in 2012 IEEE Second International Conference on Consumer 
Electronics - Berlin (ICCE-Berlin), 2012, pp. 254–257. 
[6] H.-N. Liang, J. Trenchard, M. Semegen, and P. Irani, “An ex-
ploration of interaction styles in mobile devices for navigating 
3d environments,” in APCHI’12, 2012, pp. 309–313. 
[7] D. Avrahami, J. O. Wobbrock, and S. Izadi, “Portico: tangible 
interaction on and around a tablet,” in UIST'11, 2011, pp. 
347–356. 
[8] O. Shaer and E. Hornecker, “Tangible User Interfaces: Past, 
Present, and Future Directions,” Found. Trends® Human–
Computer Interact., vol. 3, no. 1–2, Jan. 2009, pp. 1–137. 
[9] T. Tsandilas, E. Dubois, and M. Raynal, “Modeless Pointing 
with Low-Precision Wrist Movements,” in INTERACT 2013, 
2013, vol. 8119, pp. 494–511. 
[10] G. Casiez, and C. Chaillou, “Effects of DOF Separation on 
Elastic Devices for the Navigation in 3D Virtual 
Environments with Force Feedback,” in IEEE World Haptics 
2005, 2005, pp. 483-486. 
[11] “3Dconnexion.” [Online]. http://www.3dconnexion.fr/ 
products/spacenavigator. [Accessed: 27-Jan-2014]. 
[12] G. Casiez, N. Roussel, and D. Vogel, “1 € filter: a simple 
speed-based low-pass filter for noisy input in interactive 
systems,” in CHI’12, 2012, pp. 2527–2530. 
[13] J. Brooke, “SUS: A quick and dirty usability scale,” Usability 
Eval. Ind., 1996, pp. 189–194. 
[14] M. Hassenzahl, “The Interplay of Beauty, Goodness, and 
Usability in Interactive Products,” Human-Computer 
Interact., vol. 19, no. 4, Dec. 2004, pp. 319–349. 
[15] A. Bangor, P. T. Kortum, and J. T. Miller, “An Empirical 
Evaluation of the System Usability Scale,” Int. J. Hum. 
Comput. Interact., vol. 24, no. 6, Jul. 2008, pp. 574–594. 
[16] “AttrakDiff.” [Online]. http://attrakdiff.de/index-en.html. 
[Accessed: 27-Jan-2014]. 
[17] M. Hachet, F. Decle, S. Knodel, and P. Guitton, “Navidget for 
3D interaction: Camera positioning and further uses,” Int. J. 
Hum. Comput. Stud., vol. 67, no. 3, 2009, pp. 225–236. 
[18] W. Hürst and M. Helder, “Mobile 3D graphics and virtual 
reality interaction,” in ACE’11, 2011, pp. 28–36. 
[19] B. Buxton and G. W. Fitzmaurice, “HMDs, Caves & 
Chameleon: A Human-Centric Analysis of Interaction in 
Virtual Space,” SIGGRAPH, vol. 32, no. 4, 1998, pp. 64–68. 
[20]  “Tangible Media Group.” [Online]. http://tangible.media.mit. 
edu/project/tether/. [Accessed: 27-Jan-2014]. 
[21] M. Hachet, J. Pouderoux, and P. Guitton, “3D Elastic Control 
for Mobile Devices,” IEEE Comput. Graph. Appl., vol. 28, 
no. 4, Jul. 2008., pp. 58–62. 
[22] S. Boring, M. Jurmu, and A. Butz, “Scroll, tilt or move it: 
using mobile phones to continuously control pointers on large 
public displays,” in OZCHI’09, 2009, pp. 161–168. 
[23] D. Gracanin, K. Matkovic, and F. Quek, “iPhone/iPod Touch 
as Input Devices for Navigation in Immersive Virtual 
Environments,” in IEEE Virtual Reality Conference, 2009, 
pp. 261–262. 
[24] A. Benzina, A. Dey, M. Toennis, and G. Klinker, “Empirical 
evaluation of mapping functions for navigation in virtual 
reality using phones with integrated sensors,” in APCHI’12, 
2012, pp. 149–158. 
[25] F. Daiber, L. Li, and A. Krüger, “Designing gestures for 
mobile 3D gaming,” in MUM’12, 2012, pp. 3–8.  
257
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

