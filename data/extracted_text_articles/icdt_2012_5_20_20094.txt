Estimation of Perceived Quality in Convergent Services 
 
Pedro de la Cruz Ramos1, Mario Cao Cueto1, Raquel Pérez Leal2, Francisco González Vidal1  
 
1Depto. de Ingeniería Telemática 
Universidad Politécnica de Madrid 
Madrid, Spain 
{pcruzr, mcao, vidal}@dit.upm.es 
2Depto. de Teoría de la Señal y Comunicaciones 
Universidad Carlos III de Madrid 
Madrid, Spain 
rpleal@tsc.uc3m.es
 
 
Abstract— Triple-Play (3P) and Quadruple-Play (4P) services 
are being widely offered by telecommunication services 
providers. Such services must be able to offer equal or higher 
quality levels than those obtained with traditional systems, 
especially for the most demanding services such as broadcast 
IPTV. This paper presents a matrix-based model, defined in 
terms of service components, user perceptions, agent 
capabilities, performance indicators and evaluation functions, 
which allows to estimate the overall quality of a set of 
convergent services, as perceived by the users, from a set of 
performance and/or Quality of Service (QoS) parameters of 
the convergent IP transport network. 
Keywords- Quality of Experience, Perceived Quality, Quality 
of Service, etwork Performance, Quality Models. 
 
I. 
INTRODUCTION 
Customers 
of 
convergent 
Triple-Play 
(3P) 
and 
Quadruple-Play (4P) services expect a Quality of Experience 
(QoE) comparable to that obtained with traditional broadcast 
systems. Consequently, it is of utmost importance for 3P and 
4P service providers to be able to measure, estimate and/or 
monitor user perceived quality in near real time, especially 
for the most demanding services such as broadcast IPTV. 
User QoE in 3P/4P services depends on many factors, 
among other: 
1) Perceived quality of each of the individual services, 
which in turn depends on: 
a) Perceived quality of each of the service 
components. 
b) Relationships, interactions and/or dependencies 
between the components. 
2) Service availability and reliability. 
3) System responsiveness, user-friendliness, etc. 
4) Customer service. 
For instance, 3P QoE depends on the perceived quality of 
the IPTV service, which in turn depends on audiovisual 
quality, which depends on audio quality, video quality and 
audio-video synchronization (lip sync), and so on. 
This paper focuses on those elements of perceived 
quality that can be estimated, directly or indirectly, from 
performance or Quality of Service (QoS) parameters of the 
convergent IP transport network, i.e., parameters which can 
be measured at easily accessible reference points  [1] or 
obtained from the Network Management System (NMS). 
These parameters include: 
1) IP Packet Error Ratio (PER) and Packet Loss Ratio 
(PLR). 
2) End-to-end IP packet delay. 
3) Delay variation (jitter). 
For instance, MPEG Video Quality can be estimated 
from QoS parameters such as PLR [2][3]. 
In order to estimate user perceived quality we propose 
the use of a matrix-based model, which allows to estimate 
the overall quality of a set of convergent services, as 
perceived by one or more types of users, from a set of 
performance and/or Quality of Service (QoS) parameters of 
the convergent IP transport network. 
In the following sections the model is presented; its 
application to convergent services is described; the quality 
evaluation process is detailed; the main conclusions are 
summarized; and some future work is outlined. 
II. 
PRESENTATION OF THE MODEL 
The model is schematically depicted in Figure 1. Its 
elements are succinctly described in the following sections. 
It is thoroughly described in  [4][5][6], where its application 
to a 3P (data + voice + video) service offering is also 
explained. The video service (VoD), however, is considered 
of little importance and thus dropped. In the case of domestic 
users, the voice service (VoIP) is also dropped, so that the 
global service reduces to a data service (Internet access + 
On-Line Gaming). 
In this paper, instead, a full Triple-Play service offering, 
including data, voice and video services, is covered. 
For the purposes of this paper, a “user” is anyone who 
“consumes” some service included in a 3P/4P service 
offering. Typically, they are unaware of the internal 
mechanisms used to provide the service, and of its 
composing elements. They are only interested in the 
“experience” delivered to them by these services, and judge 
the quality of this experience (QoE) by means of their 
subjective perceptions, and not by technical criteria. 
Usually, we will not be interested in the individual QoE 
of specific users, but in the “average QoE” of a community 
or category of users with similar characteristics, i.e., of a 
“user type”. Sometimes, we will even consider the average 
QoE of a wide sample of customers whith quite dissimilar 
characteristics, i.e., that of the “average user”. 
88
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

A. Services and User Perceptions 
In Figure 1, the upper side of the matrix corresponds to 
the services and how the users experience those services as 
sets of user perceptions. 
Services. For the purposes of this paper, a service is 
defined as a set of functionalities whose purpose is to satisfy 
certain needs and which are perceived as a whole by the 
users. We will distinguish between: 
1) Overall or Global Services: they are offered by 
providers as a whole, but composed of more 
elementary services. An example is the 3P Service 
offered by a provider as a whole. 
2) Final Services: components of Global Services. 
They are not offered independently by providers, 
but are perceived as independent services by users. 
Examples: Internet Access, IPTV, VoIP, etc. 
3) Elementary or Basic Services: components of Final 
Services. They are not offered independently by 
providers. Users perceive them as separate, but not 
independent, services. Examples: Web Browsing, 
Electronic Mail, File Transfer, etc. 
4) Support Services: they support the Final and/or 
Basic Services. They are not offered independently, 
and users are often unaware of their existence. 
Examples: ADSL access, DNS, DHCP, etc. 
In this paper, “Service” will mean “Final Service” unless 
otherwise stated. 
User Perceptions. A user perception is a factor that 
influences the evaluation of the service quality as perceived 
by users, i.e., the Quality of Experience (QoE). 
It may be quantified by means of a valuation, similar to 
that obtained by subjective methods such as MOS, DSCQM, 
SSCQE, etc.  [7] [8]. In this paper, user perceptions will be 
quantified 
using 
the 
Standard 
MOS 
Scale 
(from 
1=unacceptable to 5=excellent) [9]. 
For each user perception, Global Valuation Factors 
(GVF) should be defined as objective, quantifiable 
parameters which determine (or at least influence) the 
subjective perception of quality. They are the result of the 
performance achieved by providers and obtained by the users 
of the service. They provide a clean separation between 
technical 
performance 
parameters 
and 
user 
quality 
evaluations. For example a GVF for the perception of 
“Download Speed” may be the “Page Download Time”. 
B. Agents and Agent Capabilities 
In the left side of Figure 1, the agents and their 
capabilities are depicted. 
Agents. An agent is any component of a system which 
has individual, separate existence and provides an 
identifiable set of functionalities with the purpose of 
providing some service to the users. Examples: Content 
providers, Carriers, Access providers. 
Agent 
Capabilities. 
These 
are 
the 
different 
functionalities provided by the agents, contributing to the 
provision of a service to the users. Examples: Connectivity, 
processing, data storage, data transfer. 
For each agent there are (Internal) Performance 
Parameters, which are internal elements or factors that an 
agent may control or manage and that contribute to the 
performance of a capability. Typically, they are magnitudes 
related to the internal infrastructure or operation of the agent. 
Some typical examples are: throughput, bit error rate, 
MTBF. 
C. Matching Points and Performance Indicators 
As previously mentioned, the matrix-oriented quality 
estimation model tries to identify the dependencies between 
services and the performance and/or quality parameters 
related to the agents and their capabilities. 
Matching Points. They represent the relationships or 
dependencies 
between 
user 
perceptions 
and 
agent 
capabilities, such that the capability affects or influences the 
perception. For instance, the data transfer capability of the 
transport network influences the loading speed perception in 
the web browsing service.  
Performance 
Indicators. 
These 
are 
measurable 
magnitudes, associated to matching points, whose values 
determine or affect the user valuation of the corresponding 
perception. We will distinguish between: 
1) Elementary Performance Indicators, which model 
the contribution of a single capability of an agent to 
a perception. 
2) Local Performace Indicators, which model the 
contribution of all capabilities of an agent to a 
perception. 
3) Global Performance Indicators, which model the 
contribution of all agents to a perception. 
Some examples are: bandwith, delay, jitter. 
D. Quality Evaluation Process 
The Quality Evaluation Process comprises a set of sub-
processes and functions. Figure 2 shows the information 
flow of these evaluation functions and processes, where the 
output of each step is the input to the next one. We will 
distinguish the following evaluation functions: 
 
: 
⋅ ⋅ ⋅ 
Services 
Perceptions 
Agents 
Capabilities 
S1 
Sm 
SM 
P11 
P1T1 
⋅ ⋅ ⋅ 
P21 
P2T2 
PM1 ⋅ ⋅ ⋅ 
PMTM 
⋅ ⋅ ⋅ 
⋅ ⋅ ⋅ 
A1 
An 
AN 
C11 
C1S1 
: 
Cn1 
CnSn 
: 
CN1 
CNSN 
I11
11 
In1
11 
IN1
11 
In1
1T1 
IN1
1T1 
I11
21 
InSn
2T2 
I11
M1 
I NSN
M1 
InSn
MTM 
Matching Points 
Indicators 
I1S1
11 
InSn
1T1 
I1S1
2T2 
In1
MTM 
 
Figure 1.  Matrix-oriented quality estimation model. 
89
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

1) Performance Functions: compute the Elementary 
Performance 
Indicators 
from 
the 
Internal 
Performance Parameters. 
2) Local Weighting Processes: compute the Local 
Performance Indicators from the Elementary 
Performance Indicators. 
3) Global Aggregation Process: computes the Global 
Performance Indicators from the Local Performance 
Indicators. 
4) Parameterization Functions: compute the Global 
Valuation Factors from the Global Performance 
Indicators. 
5) Valuation Functions: compute the valuations of 
perceptions from the Global Valuation Factors. 
6) Global 
Evaluation 
Process: 
computes 
the 
evaluations of the perceived quality of each Final 
Service and the overall evaluation of the Global 
Service, for each User Type and/or for the Average 
User. For this purpose, the Analytic Hierarchy 
Process (AHP) method  [10] is used. 
III. 
APPLICATION OF THE MODEL TO CONVERGENT (3P) 
SERVICES 
We will follow the application methodology described in 
 [4]. We will try to estimate the average QoE of so-called 
“Residential Users”, i.e., domestic (home), non-enterprise 
users, whose interests are mainly the leisure and pastime 
opportunities given by broadcast IPTV, and the information 
access possibilities offered by Internet Access, and 
specifically, Web Browsing. These users also seek cost 
saving opportunities offered by VoIP. 
For broadcast IPTV, these customers expect a QoE 
comparable to that of traditional broadcast systems (i.e., 
terrestrial or satellite TV). For VoIP, they will also expect a 
quality similar to that of POTS, but will very likely accept a 
quality similar to that of mobile telephony, if the cost savings 
are substantial. 
Non-residential users, i.e., enterprise and SOHO (Small 
Office/Home Office), are usually not interested in TV 
services, and so in 3P services, and are thus not considered in 
this model. 
A. Identification of Components 
Following the model presentation described above, this 
section aims to identify the model components and define its 
corresponding parameters. 
For the purposes of this paper, we will consider a 3P 
Global Service offering composed of the following Final 
Services: 
1) Internet 
Access, 
including 
Web 
Browsing, 
Electronic Mail, File Transfer and File Sharing 
(P2P). 
2) IP Telephony: Voice Call. 
3) IPTV: Digital Video Broadcast (DVB). 
As we are specifically interested in the estimation of user 
perceived quality from performance and/or QoS parameters 
of the underlying convergent IP transport network, we will 
deliberately ignore the Customer Service, Pricing and 
Marketing aspects of these services, as they cannot be 
estimated from network parameters, and will concentrate 
only in the technical quality aspects. 
The User Perceptions that we consider relevant for each 
service are shown in Table I. Some perceptions are common 
to all services. The Global Valuation Factors for each user 
perception are also shown in Table I. 
The Global Performance Indicators (GPI) for each user 
perception of a representative service (Digital Video 
Performance Functions
Local Weighting Process
Global Aggregation Process
Parameterization Process
Valuation Functions
Global Evaluation Process (AHP)
Agents
Internal Performance Parameters
Elementary Performance Indicators
Local Performance Indicators
Global Performance Indicators
Global Valuation Factors
Perception Valuations
Service Quality 
Evaluations
 
Figure 2.  Matrix-oriented quality estimation model. 
TABLE I.     USER PERCEPTIONS AND GLOBAL VALUATION FACTORS 
Service 
Perception 
GVF 
Web 
Browsing 
Download Speed 
Page Download Time 
Electronic 
Mail 
Response Speed 
Response Time 
Download Speed 
Download Rate 
File Transfer 
Upload Speed 
Upload Rate 
File Sharing 
Download Speed 
Download Rate 
Voice Quality 
R-Factor 
Codec Parameters 
Response Speed 
Response Delay 
Voice Call 
Call Setup Speed 
Call Setup Delay 
Video Quality 
Video Quality Metric 
Audio Quality 
PEAQ Metric 
Lip Sync 
Audio-Video Delay 
Digital 
Video 
Broadcast 
Channel Change 
Speed 
Channel Change Time 
Availability 
Successful Connection 
Percentage 
All Services 
Reliability 
Interrupted Connection 
Percentage 
 
90
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

Broadcast) are shown in Table II. The detailed relationships 
between indicators and GVFs (parameterization functions), 
and the process for deriving Global Performance Indicators 
(GPI) from Local and Elementary Performance Indicators 
(LPI/EPI) (i.e., the Local/Global Weighting Processes) will 
be given in Section IV. 
For the identification of Agents we will use the network 
model and reference points recommended in  [1]. The main 
agents are: 
1) Content Provider(s), which are the ultimate 
responsibles of the delivery of the final services. 
2) Service Provider(s), that we further subdivide into: 
a) Internet Service Provider (ISP), which provides 
Internet Access Services to end users. It may 
also integrate some additional services. 
b) Network Services Provider (NSP), which 
provides some of the Support Services (such as 
DNS, DHCP, etc.). 
c) Service Centers, which host the Final Services 
and provide connectivity between the ISPs and 
the Content Providers. 
3) Network Provider(s), that we further subdivide into: 
a) Access Network Provider, which transports the 
information between the end-user and the ISP. 
b) Core (Transport) Network Provider (Carrier), 
which includes all those elements which 
connect the ISP that hosts the final service to 
other ISPs, e.g., neutral points, international 
accesses, inter-ISP accesses, etc. 
4) End-User, including the User Plattform and 
Customer Premises Equipment (CPE). 
The most relevant capabilities for each agent are shown 
in Table III. 
B. Definition of Matching Points. 
The relationships (Matching Points) between User 
Perceptions and Agent Capabilities depend on the precise 
information flows. We may distinguish four cases, 
depending on whether the content server is internal or 
external to the ISP, and whether or not the content is 
“cached” (stored) in the ISP or in the user platform. 
For the purposes of this paper, we will consider the case 
where the content server is external to the ISP and there is no 
content caching outside the content provider. The resulting 
matching points between capabilities and perceptions are 
shown in Table III. 
IV. 
QUALITY EVALUATION PROCESS 
In this section, we will describe in detail: 
1) The local and global weighting and/or aggregation 
processes (including weighting matrixes and/or 
metrics), valuation functions and quality models for 
each service. 
2) The process for computing the Global Perceived 
Quality from the valuations of the perceptions for 
each service. 
TABLE III.     PERCEPTION-CAPABILITY MATCHING POINTS. 
 
Services 
Web Browsing 
Electronic Mail 
File Transfer 
File Sharing 
Voice Call 
Digital Video 
Broadcast 
All Services 
 
Perceptions 
Download Speed 
Response Speed 
Download Speed 
Upload Speed 
Download Speed 
Voice Quality 
Video Quality 
Audio Quality 
Lip Sync 
Channel Change Speed 
Availability 
Reliability 
Agents 
Capabilities 
Matching Points 
Processing 
X X X X X X X X X X X X 
User 
Platform 
Transfer 
X X X X X X X X X X X X 
Processing 
X X X X X X X X X X X X 
CPE 
Transfer 
X X X X X X X X X X X X 
Upstream C. 
 
X 
 
X 
 
X 
 
 
 
X X X 
Access 
Network 
Downstr. C. X X X 
 
X X X X X X X X 
Upstream C. 
 
X 
 
X 
 
X 
 
 
 
X X X 
Transport 
Network 
Downstr. C. X X X 
 
X X X X X X X X 
Internal C. 
X X X X X X X X X X X X 
ISP 
External C. 
X X X X X X X X X X X X 
Connectivity X X X X X 
 
 
 
 
X X X 
NSP 
Processing 
X X X X X 
 
 
 
 
X X X 
Upstream C. 
 
X 
 
X 
 
X 
 
 
 
X X X 
Downstr. C. X X X 
 
X X X X X X X X 
Service 
Centers 
Processing 
X X X X X X X X X X X X 
Upstream C. 
 
X 
 
X 
 
X 
 
 
 
X X X 
Downstr. C. X X X 
 
X X X X X X X X 
Content 
Provider 
Processing 
X X X X X X X X X X X X 
 
TABLE II. GLOBAL PERFORMANCE INDICATORS (GPI) FOR A 
REPRESENTATIVE SERVICE (DIGITAL VIDEO BROADCAST) 
Perception 
Indicators 
Video Quality 
Packet Loss Ratio 
Video Coding Rate 
Image Size (Resolution) 
Image Rate 
Codec Parameters 
Audio Quality 
Packet Loss Ratio 
Audio Coding Rate 
Codec Parameters 
Lip Sync 
Audio-Video Delay 
Channel Change 
Speed 
IGMP Leave Time 
IGMP Join Time 
Key Acquisition Time 
Program Decoding Time 
Key-Frame Acquisition Time 
Frame Reordering Time 
Error Correction Time 
Processing Time 
Buffering Delay 
 
91
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

A. Performance Functions 
The Performance Indicators corresponding to the 
capabilities of each agent will be measured directly (or 
obtained from the Network Management System). Thus 
Performance Functions are not required in this case. 
In the most general case, where Performance Indicators 
cannot be measured directly, they should be derived from 
Internal Performance Parameters measured for each agent (or 
obtained from the NMS) by means of suitable Performance 
Functions. 
B. Local Weighting Process 
As we are considering the case of a single type of flow 
(see Section III.B), there is no need for a local weighting 
process: the contributions of the relevant capabilities of each 
agent are used directly in the global weighting process. 
In the most general case, when several types of flows are 
considered, the contribution of each capability of each agent 
should be weighted depending on its participation in each 
flow and the importance or contribution of each flow to the 
total information flow. 
C. Global Aggregation Process 
For the Global Aggregation Process, simple metrics will 
be used as far as possible. They are summarized in Table IV. 
D. Valuation and Parameterization Functions 
As mentioned before, the valuation and parameterization 
functions relate the perceptions for each service to Global 
Valuation Factors and Global Performance Indicators. 
In the next subsections, we provide models for the 
estimation of perceived quality for the main Basic Service of 
each Final Service. 
1) IPTV: Digital Video Broadcast 
We have developed our own model for estimating the 
video quality in IPTV. An early version of the model is 
described in [2], and a more advanced version in [3]. 
{ 5 - 4⋅VQM 
        VQM ≤ 1 
MOS = { 
 
 
 
      (1) 
{ 1 
 
        VQM > 1 
 
VQM  =  VQMC  +  VQML  
 
      (2) 
 
VQMC  =  VQMREF · (VCR/VCRREF)−KC 
      (3) 
 
VQML  =  (1−VQMC) · (PLR/PLR1) KL 
      (4) 
where 
VQM 
is the Video Quality Metric as specified in [11] 
VQMC 
is the contribution of coding to VQM 
VQML 
is the contribution of packet losses to VQM 
VCRREF is a reference VCR (e.g., 1Mbps) 
VQMREF is the value of VQM at the reference VCR 
PLR1 
is the value of PLR for which VQM = 1 
 
VQMREF, KC, PLR1 and KL depend on the codec, the 
coding parameters, and the characteristics of the video 
sequence (type, format, spatial and temporal complexity, 
information contents, etc.). 
PLR1 and KL also depend on VCR. We have found that 
their variation with VCR fits very well to a function of the 
form: 
 
F(VCR) = A + B⋅VCR⋅(1+C⋅e−(VCR/D)^K) 
      (5) 
In order to estimate the Audiovisual Quality for 
synchronized audio and video streams, we use the model 
described in [12][13]: 
QAV = K0 + KA⋅QA + KV⋅QV + KAV⋅QA⋅QV 
      (6) 
where 
 
QAV 
is the Audiovisual Quality Factor 
 
QA 
is the Audio Quality Factor 
 
QV 
is the Video Quality Factor 
 
QAV must be converted to the standard MOS scale using 
the E-Model conversion function specified in [14]: 
{ 1 
 
 
 
QAV < 0 
MOS={ 1+0,035·QAV+QAV·(QAV-60)·(100-QAV)·7·10-6 
{  
 
 
 
0≤QAV≤100 (7) 
{ 4,5 
 
 
 
QAV > 100 
 QV is derived from the MOS value given by (1) using the 
E-Model inverse function specified in ITU-T G.107 [14]. 
There are other factors that contribute to the global 
quality perception of the IPTV service, such as audio quality, 
audio-video synchronization (lip sync), channel change time, 
etc. In order to compute the global quality perception all 
these factors must be taken into account. 
The Perceived Global Quality of the IPTV service will be 
computed using a nonlinear model: 
QIPTV = KIPTV+KAV⋅QAV+KTav⋅QTav+KTcc⋅QTcc 
+ KAVTav⋅QAV⋅QTav+KAVTcc⋅QAV⋅QTcc+KTavTcc⋅QTav⋅QTcc (8) 
where 
QIPTV 
is the Global Quality of the IPTV service 
QAV 
is the Audiovisual Quality given by (7) 
QTav 
is the Perceived Quality due to audio-
video desynchronization (lip sync) 
QTcc 
is the Perceived Quality due to Channel 
Change Time (CCT) 
Qi⋅Qj 
are the interaction terms 
 
The coefficients Ki will be computed using the AHP 
method. 
TABLE IV.     METRICS FOR THE GLOBAL AGGREGATION PROCESS 
Indicator 
Metric 
Delay 
Additive 
Delay Variance 
Additive 
Jitter 
Rooted Sum of Squares (RSS) 
Bandwidth 
Concave 
Packet Passthrough Ratio 
Multiplicative 
Packet Loss Ratio 
Additive 
 
92
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

2) IP Telephony: Voice Call 
In order to estimate the voice quality perception in IP 
Telephony, the adaptation of the E-Model [14] for VoIP 
given in [15] [16] will be used: 
 
R = Ro – Is – Id – Ie + A  
 
 (9) 
 
{ 0.024·d 
 
d < 177.3 
Id = { 
 
 
 
 
(10) 
 
{ 0.134·d – 19.503 
d ≥ 177.3 
Ie = a·ln(1+b·ρ)+c 
 
 
(11) 
where 
R 
is the R-Factor of the E-Model 
Ro = 93.2 is the signal/noise ratio for 0dBr 
Is 
is the degradation of the voice signal 
Id 
is the degradation caused by delay and 
delay variation (jitter) 
Ie 
is the degradation caused by the 
equipment (coding and packet loss) 
A 
is the User Expectation Factor 
d 
is the end-to-end delay in miliseconds 
ρ 
is the end-to-end packet loss ratio 
a,b,c 
are coefficients that depend on the codec 
 
The R-Factor will be converted to the standard MOS 
scale using the E-Model conversion function  [14]: 
{ 1 
R<0 
  MOS = { 1+0,035·R+R·(R-60)·(100-R)·7·10-6 0≤R≤100 (12) 
{ 4,5 
R>100 
There are other factors that contribute to the global 
quality perception of the service, such as dial tone delay, call 
setup time, etc. In order to compute the global quality 
perception all these factors must be taken into account. 
The Perceived Global Quality of the IP Telephony 
service will be computed using a nonlinear model similar to 
that used for the IPTV service (8). 
3) Internet Access: Web Browsing 
In order to estimate the preceived quality for Web 
Browsing in the Internet Access service, we will use the 
model proposed in [4], which in turn is based on that 
proposed in [17]: 
{ 5 
T < 2 seg 
MOS = { 5 - log2 T/2 
2 seg ≤ T ≤ 30 seg (13) 
{ 1 
T > 30 seg 
T = TDNS + 2⋅RTD + TMAIN + N⋅S/B  
(14) 
where 
T 
is the average page download time 
TDNS 
is the time needed for name resolution 
RTD 
is the Round Trip Delay 
TMAIN 
is the main page download time 
N 
is the average number of objects in a page 
S 
is the average object size 
B 
is the effective bandwith 
 
The Perceived Global Quality of the Internet Access 
service will be computed by combining the Perceived 
Quality evaluations for each Basic Service using a linear 
model as proposed in [4]: 
QIA = KWB⋅QWB + KEM⋅QEM + KFT⋅QFT + KFS⋅QFS (15) 
where 
QIA 
is the Perceived Quality of the  
 
 
Internet Access Service 
 
QWB 
Web Browsing Service 
 
QEM 
Electronic Mail Service 
 
QFT 
File Transfer (FTP) Service 
 
QFS 
File Sharing (P2P) Service 
 
The coefficients Ki will be computed using the AHP 
method [10]. 
E. Global Evaluation Process 
In this section, the contributions of the different elements 
of the model are weighted and combined in order to produce 
a global evaluation of the perceived quality of the 3P service. 
The AHP method  [10] will be used when the weights cannot 
be determined in a more specific way. 
1) Evaluation of Perceptions 
Once the different perceptions related to a service have 
been derived (valuation and parameterization functions), 
they must be combined in order to obtain the global 
evaluation of the service. For each service, an AHP matrix 
[10] should be used to define the relative importance of the 
different perceptions.  
For all services, we have considered that service 
availability has extreme importance, and service reliability 
strong importance for the users, relatively to other 
perceptions. For other perceptions, we have considered the 
primary perceptions (other than service availability and 
reliability) as moderately more important than the secondary 
perceptions. These ratings will be refined once we had more 
evidence of the relative importance of these perceptions for 
domestic users. 
2) Evaluation of Services 
In  [4], all services are evaluated in a single step. Instead, 
we have decomposed the Service Evaluation process in two 
steps: first, the relative importance of the Final Services is 
rated; then, the relative importance of the Elementary 
Services of each Final Service is rated. This method scales 
better to a situation with many Final Services, each in turn 
composed of many Elementary Services. 
The relative weights for the Final Services are shown in 
Table V. They are derived from service usage data [18]. 
TABLE V. IMPORTANCE WEIGHTS FOR FINAL SERVICES. 
Service 
Internet 
Access 
IP 
Telephony 
IPTV 
Home percent 
63,9 
80,6 
99,6 
Weight 
0,2618 
0,3302 
0,4080 
 
93
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

As an example, the relative importance (AHP Matrix) for 
the Elementary Services of the Internet Access Service is 
shown in Table VI. The value (rating) in each cell represents 
the importance of the service in the row relative to the 
service in the column. The precise meaning of each rating is 
described in [10], but intuitively a higher rating means that 
the row is more important relative to the column. 
The importance ratings are derived from those in  [4] after 
removing the unused services and including the new ones. 
We have given File Sharing the same importance as File 
Transfer, and kept the relative importance of other services. 
The Consistency Ratio (CR) of this matrix is 
2.25%<10%, so the relative importance factors are 
acceptably consistent. The corresponding weights are shown 
in Table VII. 
V. 
CONCLUSION 
A model for the estimation of quality as perceived by the 
users (i.e., the user Quality of Experience, QoE) in Triple-
Play (3P) and Quadruple-Play (4P) services has been 
presented. The model is based on a matrix framework 
defined in terms of user types, service components, and user 
perceptions on the user side, and agents, agent capabilities, 
and performance indicators on the network side. A Global 
Quality Evaluation process, based on several layers of 
evaluation functions, has been described, that allows to 
estimate the overall quality of a set of convergent services, as 
perceived by the users, from a set of performance and/or 
Quality of Service (QoS) parameters of the convergent IP 
transport network. The model has been refined for the 
particular case of residential (domestic) users with a specific 
information flow where the content server is external to the 
ISP and there is no content caching outside the content 
provider. The full sets of services, user perceptions, 
valuation factors, agents and agent capabilities have been 
provided, as well as the full matrix of matching points 
between 
agent 
capabilities 
and 
user 
perceptions. 
Performance 
indicators, 
as 
well 
as 
valuation 
and 
parameterization functions for some representative services 
(Digital Video Broadcast in IPTV, Voice Call in IP 
Telephony, and Web Browsing in Internet Access) have been 
provided. For Global Service Quality evaluation, weights for 
the Final Services, derived from service usage statistics, have 
been provided, as well as an example of the use of the AHP 
method for deriving the weights of the Elementary Services 
of a Final Service (Internet Access). In summary, the paper 
shows the applicability of the proposed model to the 
estimation of perceived quality (Quality of Experience) in 
convergent 3P/4P services. 
ACKNOWLEDGMENT 
This research was partially supported by the Spanish 
Ministry of Science and Innovation grant TEC2008-06539 
(ARCO Project). 
REFERENCES 
[1] ITU-T G.1081, “Performance monitoring points for IPTV,” 
International Telecommunication Union, October 2008. 
[2] P. de la Cruz Ramos, F. González Vidal, and R. Pérez Leal, 
“Perceived video quality estimation from spatial and temporal 
information contents and network performance parameters in 
IPTV,” Proc. of the Fifth IARIA International Conference on 
Digital Telecommunications (ICDT 2010), pp. 128-131, 
Athens, Greece, June 2010. 
[3] P. de la Cruz, R. Pérez Leal, and F. González Vidal, “A model 
for perceived video quality estimation from coding and QoS 
parameters in IPTV,” December 2011. Submitted to IEEE 
Communications 
Magazine: 
Special 
Issue 
on 
QoE 
Management in Emerging Multimedia Services. 
[4] F. Liberal Malaína, “Proposal of a model and a methodology 
for quality management in telecommunication services,” PhD. 
Thesis, University of the Basque Country, Spain, September 
2005. 
[5] F. Liberal Malaína, A. Ferro, and J. O. Fajardo, “PQoS based 
model for assessing significance of providers statistically,” 
Proceedings of HETNET’05 Conference, 2005. 
[6] F. Liberal Malaína, H. Koumaras, L. Sun, A. Ferro, A. 
Kourtis, and E. C. Ifeachor, “QoE in multi-service multi-agent 
networks,” International Journal of Communication Networks 
and Distributed Systems, 2006. 
[7] ITU-R 
BT.500-12, 
“Methodology 
for 
the 
subjective 
assessment of the quality of television pictures,” International 
Telecommunication Union, September 2009. 
[8] ITU-T P.911, “Subjective audiovisual quality assessment 
methods 
for 
multimedia 
applications,” 
International 
Telecommunication Union, December 1998. 
[9] ITU-T P.800, “Methods for subjective determination of 
transmisión quality,” International Telecommunication Union, 
1997. 
[10] T. Saaty, “The Analytic Hierarchy Process,” McGraw Hill, 
New York, USA, 1990. 
[11] ITU-T 
J.144, 
“Objective 
perceptual 
video 
quality 
measurement techniques for digital cable television in the 
presence 
of 
a 
full 
reference,” 
International 
Telecommunication Union, March 2004. 
[12] M. N. Garcia and A. Raake, “Impairment-factor-based audio-
visual quality model for IPTV,” International Workshop on 
Quality of Multimedia Experience (QoMEx) 2009, San 
Diego, California, USA, July 29-31, 2009. 
[13] M. N. Garcia, R. Schleicher, and A. Raake, “Impairment-
factor-based audiovisual quality model for IPTV: Influence of 
video resolution, degradation type, and content type,” 
EURASIP Journal on Image and Video Processing, Volume 
2011, Article ID 629284, 2011. 
[14] ITU-T G.107, “The E-Model, a computational model for use 
in transmission planning,” International Telecommunication 
Union, April 2009. 
TABLE VI.     AHP MATRIX FOR THE INTERNET ACCESS SERVICE 
(DOMESTIC USERS) 
 
Web 
Browsing 
E-Mail 
File 
Transfer 
File 
Sharing 
Web 
Browsing 
1 
4 
6 
6 
E-Mail 
1/4 
1 
3 
3 
File 
Transfer 
1/6 
1/3 
1 
1 
File 
Sharing 
1/6 
1/3 
1 
1 
TABLE VII.     AHP WEIGHTS FOR THE INTERNET ACCESS SERVICE 
(DOMESTIC USERS) 
Web 
Browsing 
E-Mail 
File 
Transfer 
File 
Sharing 
0.6121 
0.2164 
0.0858 
0.0858 
 
94
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

[15] L. Sun, “Speech quality prediction for voice over Internet 
Protocol networks,” PhD. Thesis, University of Plymouth, 
U.K., 2004. 
[16] L. Sun and E. Ifeachor, “New models for perceived voice 
quality prediction and their applications in playout buffer 
optimization for VoIP networks,” Proceedings of IEEE 
International Conference on Communications (IEEE ICC 
2004), Paris, France, pp. 1478-1483, 2004. 
[17] R. D. van der Mei, “Performance analysis of communication 
networks,” Faculty of Science, Vrije Universiteit, 2004. 
[18] INE, “Encuesta sobre equipamiento y uso de tecnologías de la 
información y comunicación en los hogares 2011,” Instituto 
Nacional de Estadística, Ministerio de Economía y Hacienda, 
Gobierno de España, October 2011. 
95
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-193-9
ICDT 2012 : The Seventh International Conference on Digital Telecommunications

