A Self-diagnosis Algorithm Based on Causal Graphs
Jingxian Lu
Orange Labs
2, Avenue Pierre Marzin
22300 Lannion Cedex, France
jingxian.lu@orange-ftgroup.com
Christophe Dousson
Orange Labs
2, Avenue Pierre Marzin
22300 Lannion Cedex, France
christophe.dousson@orange-ftgroup.com
Francine Krief
LaBRI - University Bordeaux 1
351, Cours de La Liberation
33405 Talence Cedex, France
francine.krief@labri.fr
Abstract—The concept of autonomic networking has
been introduced to facilitate network management that
is increasingly complex. It uses a closed control loop
proposed by the autonomic computing. Obviously, this
approach relies on a distributed architecture. This
implies that the diagnosis algorithms have to be dis-
tributed in order to satisfy autonomic architecture re-
quirements. In this paper we describe novel algorithms
regarding the use of causal graph model to perform
diagnosis distribution in telecommunication networks.
Keywords—diagnosis algorithm; causal graph; distri-
bution; self-diagnosis.
I. Introduction
With the growth of network complexity and hetero-
geneity, the need for managing and controlling the net-
work eﬀectively by reducing human intervention seems
essential. An autonomic system can monitor itself and
adjust to the changing environment. It manages itself
and becomes autonomic without human interventions
[1]. The four distinct purposes of an autonomic system
are: Self-conﬁguring, Self-healing, Self-optimizing and Self-
protecting. To achieve those purposes, autonomic systems
have a detailed knowledge of their internal state as well
as their environment through a continuous monitoring
of eventual changes that could aﬀect their components.
Detecting changes helps the autonomic system adjust its
resources and by monitoring, it continues to determine if
the new measures satisfy the desired performance. This is
an overview of the closed control loop (Figure 1) of self-
management systems.
Manageable resource
Sensor
Effector
Autonomic manager
Plan
Analyze
Execute
Monitor
Knowlegde
Manageability
Interface
Data
Action
Fig. 1.
The closed control loop for Autonomic computing
ANA [2] has deﬁned the organization of the autonomic
network with the possibility for an autonomic element
to exchange information with diﬀerent neighbor elements.
The project FOCALE [3] has deﬁned the ability of an
operator to manage an autonomic network with business
objective. A new control loop is used to manage the closed
control loop of each network element. Because operators
don’t accept the black box (i.e., closed control loop)
solution, an autonomic control loop must be validated
by Service/Network Provider before integration in the
network.
Self-healing means the system ability to examine, ﬁnd,
diagnose and repair system malfunctions [4]. With the
development of autonomic network, the concept of self-
healing is becoming more and more important for oper-
ators in order to satisfy customers needs. The need for
dependable autonomic network has motivated researchers
over the recent decades to investigate self-diagnosis. Self-
diagnosis is an important part of self-healing. It is required
that network could detect faults, handle alarms, execute
related test by itself. The purpose of our studies is to intro-
duce self-diagnosis in Self-healing function by autonomic
networking.
This paper describes a novel algorithm regarding the
use of causal graph model for performing self-diagnosis
in telecommunication networks. We have presented the
causal graph model in the paper [5]. The causal graph
based diagnosis is a kind of model-based approach relied
on a graph which represents causal propagation between
causes and eﬀects [6]. It could represent a process at a
high level of abstraction and could be reﬁned in a very
detailed way if necessary. It allows to split the model into
small parts and so to have an incremental way of modeling.
By the way, it allows a very ﬂexible way to model the
knowledge. By deﬁnition, the causal graph is an acyclic
graph. And it is composed of two parts: nodes representing
partial states of the system and arcs representing causal
relations. The causal graph structure is based on ﬁve types
of nodes and one type of arcs (shown in Figure 2):
Primary cause is also called default or failure, and has
no predecessor in the graph.
Intermediate cause represents partial states of the sys-
tem. Intermediate and initial causes can’t be directly
observed.
Observation is the observable eﬀect of failures and cor-
responds to alarms. In the graph, these nodes are leaves
146
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

Should cause
Primary cause
Intermediate cause
Repairing 
action
Observation
Test
Fig. 2.
The components of causal graph
and have no successors.
Test is used to verify a state or a hypothesis. From the
view of causality, they are exactly as observations, the only
diﬀerence is that they are not automatically notiﬁed, but
need to be explicitly requested. (This node type could be
also used to request a database.)
Repairing action is a special node, because it is not a
partial state, and it doesnot take part in the causal relation
between causes and eﬀects. We can consider it as a label, it
only serves when the diagnosis has been completed. These
actions are considered as an additional treatment to repair.
Should cause means that the cause systematically leads
to the eﬀect (or the eﬀect is a systematical eﬀect of the
cause). For example, “disconnected Livebox” should cause
“disconnected IP”.
Alarm 
unknown 
IMPU in SLF
IMPU unknown 
in SLF
SLF no 
synchronizaton
IMPU barring 
in SLF
Unknown 
client in 
SLF(No 
account)
Resynchroni-
zation SLF
Unknown client in 
HSS (No account)
Test of 
unknown
client
Client barring 
in SLF
Fig. 3.
An example of a causal graph
Figure 3 gives an example of causal graph in IMS envi-
ronment. In this example, the alarm indicates that user’s
IP Multimedia Public Identity (IMPU) cannot be found in
Subscriber Locator Function (SLF). And “Barring” means
that a client account exists but has expired. The provi-
sioning of the diﬀerent databases is not simple because
SLF and HSS are duplicated and they need to be updated
at the same time with no failure. A non-synchronization
failure or an update failure could happen. We refer the
reader to [5] for more details. In fact, compared with [5],
we have updated, here, some deﬁnitions and rules in order
to improve and establish the algorithms.
The diagnosis process consists in collecting all the cur-
rent observations, and then, determining all the primary
causes which could explain these observations. Some tests
could be launched during diagnosis in order to discriminate
remaining ambiguities. Finally, the repairing action nodes
connect to identify causes which determine the action to
execute for repairing. To achieve the process, each node
has some associated states:
Guilty: for a symptom node (test or observation), it
means that the symptom was observed and should be
explained by, at least, one of its predecessors. For an
intermediate node, it means that the corresponding patho-
logical state is asserted and, for a primary cause, it means
that this cause is responsible for the current problem.
Innocent: for a symptom node, it means that the symp-
tom is not observed (i.e., an alarm is not present or a test
returns a negative result), for a cause primary or not, it
means that it is not involved in the causal path and the
cause should be searched elsewhere.
The diagnosis algorithms relies on a hypothesis set and
are step-by-step procedures. The purpose is to build all the
diagnosis by exploring hypothesis.The hypothesis is based
on summation of state of causal graph nodes. Meanwhile,
the hypothesis must strictly respect the following rules in
order to be consistent.
R1: if a node is guilty, then all its successors are guilty.
R1’: if a node is guilty, at least one of its predecessors
should be guilty (except if the node is a primary cause).
R2: if a node is innocent, then all its predecessors should
be innocent.
R2’: if all the predecessors of a node are innocent, this
node should be innocent.
R3: for a test node, its state will be Guilty or Innocent
according to its result of execution (in other words, the
execution of a test enables to add the observations in
process).
Repairing actions connected to a guilty node of consis-
tent hypothesis are candidates to repair diagnosed prob-
lem.
In next section, we will present the deﬁnitions needed in
order to establish the base of algorithm theories and the
formalized diagnosis algorithm.
II. Definitions and Notations
This section will present required deﬁnitions. The model
is formally deﬁned as follows.
Deﬁnition 1 (Causal graph): A causal graph G is an
acyclic graph and consists in couple (N, S), where:
• N is a set of nodes from the causal graph;
• S is the causal relationship between these nodes.
Deﬁnition 2: For a causal graph G = (N, S), and for
each node n ∈ N, we denote:
• S(n): the subset of successors of node n;
• bS(n): the subset of N containing all the descendants
of n (transitive closure of S)
• S−1(n): the subset of nodes whose successor is n;
• bS−1(n): the subset of all the ascendants of n.
147
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

As an extension, if N ⊂ N, we note bS(N) the set of all
the descendants of nodes N:
bS(N) =
[
n∈N
bS(p)
and
bS−1(N) =
[
n∈N
bS−1(p)
The hypothesis of acyclic graph is then translated by the
following property:
Proposition 1 (Acyclic Graph): The causal graph G =
(N, S) is an acyclic graph, if and only if
∀n ∈ N, n /∈ bS(n)
Deﬁnition 3 (Primary causes and Observations): For a
given causal graph G = (N, S), we deﬁne the set of failures
P and the set of observations O as follows:
• P = {n ∈ N|S−1(n) = ∅}
• O = {n ∈ N|S(n) = ∅}
Note that O contains the nodes corresponding to alarms
as well as tests.
Deﬁnition 4 (Symptom of a failure): An observation a
(a ∈ O) is an symptom (e.g., an alarm) of the failure p ∈ P,
iﬀ there is a causal path from p to a (i.e., a ∈ bS(p)). The
symptoms set of a failure p is thus deﬁned by bS(p) ∩ O.
Deﬁnition 5 (Independance of failures): If two failures
p1 and p2 are independent, then all the eﬀects (observable
symptoms and intermediate causes) of co-occurrence of
these two failures is the union of eﬀects of each failure.
In other words:
bS({p1, p2}) = bS(p1) ∪ bS(p2)
Deﬁnition 6 (Diagnosis): Let a causal graph G = (N, S)
and a set A ⊂ O of alarms (observations), a diagnosis D
is a subset of P which can explain the set of observations.
In other words:
D is a diagnosis for A iﬀ :
A ⊆ bS(D) =
[
p∈D
bS(p)
Note that if D is a diagnosis for A, then ∀p ∈ P, if there
is no interaction between the failures (hypothesis of the
independent failures), D ∪ {p} is a diagnosis for A.
Proof: If D is a diagnosis for A, then we have A ⊆
bS(D). Under the hypotheses of independent failures, we
have bS(D ∪ {p}) = bS(D) ∪ bS(p). If A ⊆ bS(D ∪ {p}), then
D ∪ {p} is a diagnosis for A.
For the same set of symptoms A, you can order the
corresponding diagnosis using the relation ⊆. We will
rather ﬁnd the minimal diagnosis than the direct diagnosis.
Deﬁnition 7 (Minimal Diagnosis): Given
a
causal
graph G = (N, S)) and a set A ⊂ O of the alarms
(observations), a diagnosis D is minimal diagnosis for
A, if and only if, there is no diagnosis D′ for A when
D′ ⊊ D. In other words, if D and D′ are two minimal
diagnosis for A and D′ ⊂ D, then D = D′.
The objective of diagnosis will be to ﬁnd all the minimal
diagnosis.
Deﬁnition 8 (Hypothesis of diagnosis): A hypothesis H
of diagnosis is deﬁned by:
1) a set G(H) ⊆ N of “guilty” nodes;
2) a set I(H) ⊆ N of “innocent” nodes;
3) a set X(H) ⊆ G(H) containing all unexplained nodes
(i.e., without guilty predecessor).
A hypothesis is closed when it explains all its symptoms
and remains consistent, that is to say when:
X(H) = ∅
and
I(H) ∩ G(H) = ∅
Deﬁnition 9 (Fusion of hypotheses): Consider two diag-
nosis hypotheses H and H′, let us deﬁne the fusion of these
two hypotheses H ⊗ H′ as follows:
G(H ⊗ H′) = G(H) ∪ G(H′)
I(H ⊗ H′) = I(H) ∪ I(H′)
X(H⊗H′) = (X(H)\G(H′))∪(X(H′)\G(H))∪(X(H)∩
X(H′))
III. Diagnosis Algorithms
In this section we propose the base of the implemented
diagnosis algorithm and the various proposed extensions
to take into account the tests during the current diagnosis.
We ﬁrst introduce a centralized algorithm in this section,
and then develop the distributed algorithm in the next
section.
A. Diagnosis Search
The algorithm of calculation D relies on a set of hy-
pothesis H and ends when there is no node to explain
in the hypotheses (i.e., all hypotheses are closed). During
initialization of the algorithm, we start from the initial
hypothesis H0 which will be based on A as all the set of
alarms to explain.
Algorithm 1 Calculation of the set D of diagnosis
Require: H
=
{H0} with H0 deﬁned by G(H0)
=
X(H0) = A and I(H0) = O \ A
1: while H ̸= ∅ do
2:
Choose H in H (and delete it from H)
3:
if
X(H) = ∅ (the hypothesis H is closed) then
4:
The diagnosis D is deﬁned by D = G(H) ∩ P
5:
D ← D ∪ {D}
6:
else
7:
Algorithm 2: Develop H
8:
end if
9: end while
We can modify the policy of diagnosis progress by
changing the procedure of choice H in H of the diagnosis
hypothesis to develop (line 3 of the algorithm 1).
Algorithm 3 Propagate m in H′
1: if bS(m) ∩ I(H′) ̸= ∅ then
2:
return H′ is inconsistent
3: else
4:
G(H′) ← G(H′) ∪ bS(m)
5:
return H′ is consistent
6: end if
148
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

Algorithm 2 Develop H of minimal diagnosis
1: Choose n ∈ X(H) (and delete it from X(H))
2: if S−1(n) = ∅ or S−1(n) ∩ G(H) ̸= ∅ then
3:
H ← H ∪ {H} (n is already explained, H remains
valid)
4: else
5:
for all m ∈ S−1(n) do
6:
Create H′ (a duplicate of diagnosis hypothesis H)
7:
G(H′) ← G(H′) ∪ {m}
8:
X(H′) ← X(H′) ∪ {m}
9:
execute Algorithm 3: Propagate m in H′
10:
if H’ is consistent then
11:
H ← H ∪ {H′}
12:
end if
13:
I(H) ← I(H) ∪ {m}
14:
end for
15: end if
Algorithm 2 avoids exploring redundant number of hy-
pothesis and can lead to minimal diagnosis.
B. Extension of absent alarms or lost alarms
An absent or a lost alarm corresponds to an absence of
information, we don’t know if the symptom is present or
not.
By default, algorithm 1 supposes that if an alarm is
unobserved, it is not active (i.e., I(H0) = O \ A). If a
subset A′ ⊂ (O\A) of alarms are absent, then the previous
algorithm is initialized with I(H0) = O \ (A ∪ A′) and the
algorithm remains the same.
The obtained diagnosis assumes that some of these
alarms could be active but lost. For a given diagnosis
D, the set of active alarms is: S
p∈D bS(p) ∩ O. And so,
the alarms assumed as lost by this same diagnosis are:
 S
p∈D bS(p) ∩ O

\ A.
C. Extension of tests
We want to handle the case where certain observations
don’t show spontaneously but correspond to tests to be
executed. In this case, one of certain observations O are
labeled as tests (belongs to T).
The algorithm 4 is the main body of the algorithm, and
it will rely on the following procedures: Algorithm 5 and
Algorithm 6. Note that, for a test node, the algorithm 6
will replace the algorithm 3 to execute.
In the algorithms, T ∗ means the test before the exe-
cution or the test waiting for the execution. T + and T −
are the results after test execution, here T − stands for
a positive result (Innocent) and T + for a negative one
(Guilty).
The test choice policy (line 1 of the algorithm 5) could
be based on the cost induced by the test (in terms of delay,
of computer resource, etc. ).
The development of an algorithm can go through the
selection of executed tests.
Algorithm 4 Calculation of the set D of diagnosis
Require: A ∪ A′ = ∅
1: T ∗ = T + = T − = ∅
2: H = {H0} with H0 deﬁned by G(H0) = X(H0) = A
and I(H0) = A′
3: while H ̸= ∅ do
4:
Choose H in H (and delete it from H)
5:
if G(H) ∩ T − ̸= ∅ ou I(H) ∩ T + ̸= ∅ then
6:
H is consistent (and abandoned as in contradic-
tion with tests executed in other hypothesis)
7:
else
8:
if
X(H) = ∅ then
9:
if T ∗ ∩ G(H) = ∅ then
10:
(the hypothesis H is terminated and without
waiting)
11:
The diagnosis D is deﬁned by D = G(H) ∩ P
12:
D ← D ∪ {D}
13:
else
14:
execute Algorithm 5: Launch a test for H
15:
end if
16:
end if
17:
else
18:
if
T ∗ ∩ G(H) = ∅ (No tests for H) then
19:
execute Algorithm 2: Develop H
20:
else if We choose to launch a test for H then
21:
execute Algorithm 5: Launch a test for H
22:
else
23:
execute Algorithm 2: Develop H
24:
end if
25:
end if
26: end while
Algorithm 5 Launch a test for H
1: Choose and execute a test t ∈ T ∗ ∩ G(H)
2: if The result of t is a “detected problem” then
3:
T + ← T + ∪ {t}
4:
H ← H ∪ {H} (H is consistent)
5: else
6:
T − ← T − ∪ {t}
7:
(we abandon H which is in contradiction with the
result of test)
8: end if
IV. Distribution of the algorithm
A distributed system is a set of components that in-
teract by exchanging messages through a communication
network. When detecting an anomaly, components emit
alarms for monitoring the system.
For a distributed architecture: each local diagnosis sys-
tem ﬁrst calculates a diagnosis using only local informa-
tion, then a global diagnosis is determined by communica-
tion between each local diagnoser. This approach has the
advantage of a complete distribution of the diagnosis task.
It seems also interesting to make the diagnosis as close as
149
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

Algorithm 6 Propagate m in H′
1: if bS(m) ∩

In these 3 algorithms, we have not yet add the test and
repairing actions in order to simplify the algorithms.
Termination of algorithm
For a distribution of algorithm, the termination of di-
agnosis should be considered. When H = ∅, hypothesis of
diagnosis is closed (i.e., diagnosis is complete). Then, all
the results of diagnosis will be sent to operator to ﬁnally
validate and execute the repairing actions.
Let us deﬁne a special message okEID as the response
of askEID to notice the agreement of “complete diagnosis”
between the neighbor diagnosers and a message cancelEID
as a notice of deleting the ﬁnished diagnosis.
Algorithm 10 Reception askEID from Gj
1: if H ̸= ∅ then
2:
sends H to neighbor diagnosers
3:
delete H from Gi
4: else if EID ∈ E then
5:
sends okEID to Gj
6: else
7:
E ← E ∪ {EID}
8:
W(EID) ← {all the IDs of neighbor diagnosers
except Gj}
9:
S(EID) ← Gj
10:
sends okEID to all W(EID)
11: end if
Algorithm 11 Reception okEID from Gj
1: W(EID) ← W(EID) \ {Gj}
2: if W(EID) = ∅ then
3:
sends okEID to S(EID)
4: end if
Algorithm 12 Reception cancelEID from Gj
1: sends cancelEID to all W(EID)
2: W(EID) ← ∅
In the algorithm 10, E is the set of ID of all the
neighbors which send askEID. W(EID) is the set of all
the neighbors which have sent askEID and wait for the
response okEID. And S(EID) is the source of diagnosis.
V. Conclusion and Future Work
We have introduced a novel algorithm regarding the use
of causal graph model for performing self-diagnosis. To do
so, we ﬁrst introduced the notion of causal graph modeling.
Mathematically, it’s possible to derive diagnosis algorithm
based on causal graph: local diagnosis are executed by
local diagnosers and take the form of message passing
algorithms. The keystone of the algorithms is to achieve a
self-diagnosis in a global environment.
Future work will focus on the implementation of the self-
diagnosis algorithm in an IMS platform to verify diagnosis
performance, and then, according to the results of diagno-
sis, we will try to reﬁne the policies of the algorithms and
to improve it.
References
[1] IBM, Autonomic Computing: IBM’s perspective on the state of
information technology, Technical report, 2001.
[2] ANA:
Autonomic
Network
Architecture,
http://www.ana-
project.org
[3] J. C. Strassner, N. Agoulmine, and E. Lehtihet, FOCALE - A
novel autonomic networking architecture. pp.64-79, 2007.
[4] D. Tosi, Research Perspectives in Self-healing Systems, Technical
Report of the University of Milano-Bicocca.
July, 2004.
[5] J. Lu, C. Dousson, B.
Radier, and F. Krief, Towards an au-
tonomic network architecture for self-healing in telecommunica-
tions networks, in Proceedings of 4th International Conference
on AIMS.
Zurich, Switzerland, 2010.
[6] L. Console, D.T. Dupre, and P. Torasso, A theory of diagnosis for
incomplete causal models, in Proceedings of IJCAI. USA, 1989.
[7] R. K. Boel and J.H. van Schuppen, Decentralized Failure Di-
agnosis for Discrete Event Systems with Costly Communication
between Diagnosers, in proc. 6th Int. Workshop on Discrete Event
Systems.
WODES’ 02, pp.175-181, 2002.
[8] R. Debouk, S. Lafortune, and D. Teneketzis, Coordinated decen-
tralized protocols for failure diagnosis of discrete event systems,
Discrete Event Dynamic Systems : theory and applications,
vol.
10(1/2), pp. 33-86, 2000.
[9] T. Yoo and S. Lafortune, A General Architecture for Decen-
tralized Supervisory Control of Discrete-Event Systems, Discrete
Event Dynamic Systems: Theory and Applications.
vol. 12(3),
pp. 335-377, July, 2002.
[10] R. Su, W.M. Wonham, J. Kurien, and X. Koutsoukos, Dis-
tributed Diagnosis for Qualitative Systems, in proc. 6th Int.
Workshop on Discrete Event Systems,
WODES’02, pp. 169-
174, 2002.
[11] Y. Pencole, M. Cordier, and L. Roze, A decentralized model-
based diagnostic tool for complex systems, Int. J. on Artif. Intel.
Tools.
World Scientiﬁc Publishing Comp., vol. 11(3), pp. 327-
346, 2002.
[12] S. Genc and S. Lafortune, Distributed Diagnosis Of Discrete-
Event Systems Using Petri Nets, in proc. 24th Int. Conf. on
Applications and Theory of Petri Nets.
LNCS 2679, pp. 316-
336, June, 2003.
[13] R. K. Boel and G. Jiroveanu, Distributed Contextual Diagnosis
for very Large Systems, in Proceedings of WODES’04,
pp. 343-
348, 2004.
[14] E. Fabre, A. Benveniste, S. Haar, and C. Jard, Distributed
Monitoring of Concurrent and Asynchronous Systems, Journal
of Discrete Event Systems,
2005.
151
ICAS 2011 : The Seventh International Conference on Autonomic and Autonomous Systems
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-134-2

