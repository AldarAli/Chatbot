When Teachers and Machines Achieve the Best Combination: A National
Comparative Study of Face-to-face and Blended Teaching and Learning
Cecilia Marconi
Data Analytics Section
Plan Ceibal
Av. Italia 6201 - CP 11500
Montevideo, Uruguay
Email: cmarconi@ceibal.edu.uy
Juan Jos´e Goyeneche
Instituto de Estad´ıstica
Fac. de C. Econ. y de Adm.
Universidad de la Rep´ublica
Eduardo Acevedo 1139 - CP 11200
Montevideo, Uruguay
Email: jjgoye@iesta.edu.uy
Crist´obal Cobo
Center for Research
Ceibal Foundation
Av. Italia 6201 - CP 11500
Montevideo, Uruguay
Email: ccobo@fundacionceibal.edu.uy
Abstract—This paper analyzes a national technology and
education program in Uruguay known as Plan Ceibal. This work
studies a sample of over 105,000 students from 4th, 5th, and
6th grade of public primary education in that country. This
work aims to assess the impact of technology on teaching and
learning of English. The method adopted is based on log-ﬁle
data to compare two different modalities of English teaching (a
face-to-face and a blended model). Additionally, we explored the
correlation between a common measure of online engagement
when using the Learning Management System (LMS) and an
adaptive English assessment. We examined the impact of the
teaching modalities on the students engagement and to what
extent the engagement can contribute to enhance the student
learning of English. This work documents the steps followed
to elaborate the common measure of engagement to ensure
transparency and its replicability (or improvement). A strength of
this work, in comparison with previous studies, is the number of
cases analyzed as well as the age of the target population (primary
school students). The results indicate that engagement is affected
by at least three key factors: socio-cultural context, teaching
modality, and the role that teachers play. In fact, the higher
the engagement level, the larger the proportion of students who
achieve a better learning outcome in the assessment. This study
shows that the use of LMS enhanced the learning experience
when this tool is integrated within the ecosystem of the teaching
and learning process. The ﬁndings of this study are consistent
with previous works in the ﬁeld, for instance: the relevance of the
context as well as the role of teaching. Although the measurement
of engagement can help to understand students performance
noteworthy that as a stand-alone dimension it is a poor predictor
of performance. To consider additional factors associated with
learning is still necessary.
Keywords—Plan Ceibal; Online learning; LMS Engagement;
Learning Analytics; Adaptive test
I. INTRODUCTION
This study analyzes a national technology and education
program in Uruguay known as Plan Ceibal. In particular, this
work aims to assess the impact of technology on teaching
and learning of English in public primary schools. Previous
research works have shown that the deployment of educational
technology as such, can not necessarily be translated into
better learning outcomes [1]. So, it is critical to consider
associated factors such as the context, the teachers training,
the pedagogical strategies among other factors which can play
a relevant role during learning [2].
Since the Plan Ceibal works at a national level, it must
manage and analyze large-scale platforms and datasets gath-
ered from the whole public educational system. This wealth
of data becomes a unique opportunity for conducting data
analytics exploration. For instance, it opens the opportunity
for combining and analyzing dimensions such as: access to
technology, type of use of the devices in different modalities
of teaching, frequency of use, among others [3] [4]. All
these dimensions are relevant, but, as previous research shows,
in order to play a meaningful role during the educational
process, it is critical that students are engaged in the use of
the technology during their learning experience. That is why
our work aims to analyze students engagement during their
learning experience [5]. It is relevant for our work to build a
common measure of online engagement. This measure can be
particularly useful to analyze from a comparative perspective
how the different teaching modalities of English (a face-to-face
and a blended one) have an impact on students engagement
and to what extent this measure of engagement when using
the LMS can contribute to enhance the student learning of
English. This analysis focuses on the online interactions with
the LMS platform, which includes over 13.7 million records,
of 4th, 5th, and 6th grade students in two teaching modalities
of English from the public educational system of Uruguay
during 2015.
The study is structured as follows. Sections II describes the
two different modalities of teaching English and the national
evaluation. Sections III presents the methodological aspects of
this work. Section IV includes the results and a discussion
of the results obtained. Finally, Section V summarizes the
conclusions and and suggests further work.
II. EDUCATIONAL CONTEXT
In Uruguay, the teaching of English in primary schools is
conducted under two different modalities. We are comparing
34
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

two EFL (English as a Foreign Language) programs. One is
delivered entirely face-to-face and the other uses a blended
modality.
A. Face-to-Face modality
The Second Language Program runs a face to face teaching
program. This modality consists of 3 hours per week for 4th,
5th and 6th graders. The pedagogical activities of the class
are deﬁned by each teacher. In this modality, there is no
prescriptive deﬁnition regarding the use of technology (face-
to-face classes can be enhanced by the use of LMS or other
platforms).
B. Blended modality
”Ceibal en Ingl´es” is a program conducted since 2012
in partnership between Plan Ceibal and British Council to
overcome the shortage of qualiﬁed EFL teachers in Uruguay.
It offers a blended approach integrating remote teaching via
video conference, LMS and traditional face-to-face instruction.
It was designed for primary school learners in 4th, 5th and
6th grades, who have English lessons three times a week [6].
This blended model enabled to conduct multidimensional data
analysis, offering useful information for both the academic
community and the policy makers.
C. National evaluation of both modalities
Since 2014, the National Educational System (ANEP, by its
Spanish acronym), Plan Ceibal and the British Council imple-
mented an annual EFL adaptive test applied to children in both
teaching modalities (face-to-face and blended). Performance
levels were designed in accordance with the standards deﬁned
by the The Common European Framework of Reference for
Languages: Learning, Teaching, Assessment (CEFR) for the
teaching and learning of Foreign Languages [7]. The students’
EFL learning is assessed through an adaptive online test,
including the following domains: Vocabulary, Reading, Gram-
mar (VRG), Listening and Writing. The assessment adapts
to the level of knowledge of the test taker. Depending on
the accuracy of the student answers to previous questions,
the assessment displays either a more difﬁcult or an easier
question as subsequent test items.
The scores patterns indicate that the best results are obtained
by students from higher socio-cultural contexts, as deﬁned by
ANEP. In addition, the higher the student grade level, the better
the results [8]. A subset of the sample of 21.989 students who
completed both 2014 and 2015 tests was analyzed. The results
showed signiﬁcant improvements from 2014 to 2015, across
all three grades, regardless of students socio-cultural contexts.
However, the learning outcomes gap between students from
high and low socio-cultural context remain throughout these
years.
III. METHODOLOGICAL ASPECTS
In this section, we present the objectives of this study, a
summary of the state of the art and the different method-
ological steps implemented to reach our goals. Particularly,
we present our proposal of an engagement index and the
characteristics of our dataset.
A. Key questions
The main question of this study is: what is the effect
of the teaching modality (blended vs face-to-face) on the
level of LMS engagement. We also considered a subsidiary
question: to what extent the use of this technology contributes
to enhance the learning outcomes of learners?
B. Previous research
Using LMS data is often at the heart of learning analytics
studies. It is also one of the most popular research orienta-
tions due to its ubiquity in many educational institutions [9].
Although the expectation is that students’ use of the LMS fea-
tures have a positive effect on student performance, previous
research works show mixed results: basic LMS data does not
predict student academic performance [10]. LMS usage is at
best a poor proxy for actual user-behaviour of students. The
challenge is to build a more comprehensive understanding of
online practices. Previous works indicate that a combination
of LMS data with data from assessments can be a better
predictor for students learning outcome or engagement [11]
[12]. More and more studies of online education have begun
to focus on student engagement, noting that engagement is also
inﬂuenced by the learning context and by the instructor who
plays a signiﬁcant inﬂuence in online (or blended) education
[13] [14] [15] [16]. Student engagement can be represented
by the time and effort students devote to their learning
experience, but also based on the activities conducted online
[17] [18]. When analyzing student engagement in the online
learning environment, it is necessary to select the indicators
to measure online engagement [19] [20]. As previous studies
have explored [21], the integration of LMS into an English
language course can offer a ﬂexible and convenient space for
learning, also called a “third space” for education. Likewise,
recent works have examined different styles on the engagement
patterns [22]. As Wintrup et al. report, previous studies have
analyzed how learners engagement online varies according
to their learning experience [23]. Previous works present an
alternative methodology based on latent class models instead
of computing a single index score [5] [24]. Having revised
and analyzed the existing literature in the ﬁeld [5] [6] [7]
[8], this article develops a methodological approach grounded
on data mining strategies using log-ﬁle data. One of the key
contributions found in the literature is the measurement of
students engagement using log data which is both minimally
disruptive and highly scalable [8].
C. Data sources, sample and index computation
In order to answer our key questions, we used data from
different sources. Our main dataset was the data from the logs
of the LMS platform, 13.7 million records of events of the
students activity during 2015. Administrative information was
collected and merged from Ceibal (grade, school, classroom
and the socio-cultural context of the school). In addition, for
35
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

each student, we added the achieved score from the annual
EFL adaptive online test. The test was applied to 4th, 5th and
6th grade students from primary education who attended either
one of the two modalities of English teaching (blended and
face-to-face). The assessment was not universal, although it
reached 62% (65,699 students) of the total number of students
[8]. This subset included members of all the socio-cultural
contexts and grade levels. The proportion of students in each
grade and in each socio-cultural level in this subsample were
similar to the values of the total population.
The universe considered in this study are students from
4th, 5th and 6th grade of public primary education (105,715
students: 76,752 blended students, and 28,963 face-to-face
students) from all (942) urban schools. Despite the large
number of students and events registered, we managed the
volume of the data with the standard libraries in R (base, stats)
[25]. The original data was read using the library RODBC [26]
to connect to Structured Query Language (SQL) Server.
The second step was to generate an index in order to
systematize the students performance in the LMS, the En-
gagement Index (IEG, in Spanish). This index provided a
combined indicator of key activities: students access, type of
usage in the LMS and intensity of use. This index is used to
establish a common measure to compare both English teaching
modalities.
The properties considered during the elaboration of the
index were (a) it should be increasing with higher level of
engagement, (b) it must be bounded, preferably between 0
and 1, and (c) it should be on a logarithmic or relative scale.
In order to summarize the students activity on the platform,
a subset of 13 variables were selected from the dataset. These
variables computed the number of times that a certain task
was done (logging in, uploading ﬁles, etc.) and the number
of different days when those tasks were done. Since some of
these variables were highly correlate, we selected those that
showed less correlation (less than 0.8) in order to represent the
various aspects of the multivariate analysis. The variables used
in the index were: x1 = number of assignments submitted,
x2 = number of ﬁles uploaded, x3 = number of comments,
x4 = number of comments on submissions, x5 = number of
days in which comments on submissions are made, and x6 =
number of days in which some activity took place.
The computation of the IEG includes two steps: aggregation
of the six variables involved, and re- scaling and smoothing of
the result. First, we computed π = Q6
i=1(1+xi), which takes
a minimum value of 1 when all variables are zero. Then, we
transform the product of the six functions of the variables:
IEG = (δ + 1)/δ × [(π/(δ + π) − 1/(δ + 1)],
where δ is a smoothing parameter (after some calibration we
set δ = 90 for the IEG). It can be seen that IEG = 0 if π = 1
and IEG → 1 as π → ∞. After having obtained the index,
the following step was to analyze the behavior of the IEG at
different levels of analysis (student-level vs classroom-level)
according to the English teaching modalities.
Finally, in order to answer the second research question,
we explored the correlation between IEG and the adaptive
English test scores. From the total number of students (65,699)
who completed the computerized adaptive test, 46,776 were
blended students enrolled in the LMS, so our correlational
analysis focused particularly on this subset.
IV. RESULTS AND DISCUSSION
The ﬁndings of this study are structured in two sections, in
order to answer the questions, followed by a discussion. First,
we conduct a comparative analysis to explore to what extent
the teaching modality (blended vs face-to-face) deﬁnes the
level of engagement in the use of the LMS. Second, we present
to what extent the use of the LMS enhances the learning
outcomes of learners. Finally, we discuss the results.
A. Relation between engagement and teaching modalities
Based on a comparative analysis of the coverage rate for
access to the platforms done by learners according to the
modality of English teaching, it was observed that blended
students registered the highest student coverage rates (82%
blended versus 52% face-to-face). We interpret that these
results, in addition to the proportion of blended students
(76,752) in the total number (105,715), indicate that the access
to the LMS can be explained mostly by the role the platform
plays in the remote teaching of English. It was also observed
that the coverage rate increases with the student grade level:
65.7%, 67.5% and 73.3% for 4th, 5th and 6th, respectively.
The differences identiﬁed in the coverage rate according
to the modality of English teaching can be also observed
in terms of the intensity of use of the platform. Figure 1
shows the engagement index obtained per student for the two
teaching modalities. The engagement index reﬂects a higher
participation and interaction of blended students, with an av-
erage of 0.5 and a median of 0.5, whereas for the face-to-face
students the average is 0,3 and the median is 0. Furthermore,
as seen in other studies [27], we found a positive correlation
between students engagement and the socio-cultural context.
The medians for the IEG for each one of the socio-cultural
quintiles are: Q1 = 0.11, Q2 = 0.22, Q3 = 0.41, Q4 = 0.57,
and Q5 = 0.85, where Q1 is the most critical and Q5 is the
least critical context.
Figure 1 shows that for approximately 30% of the blended
students the interaction with the LMS is zero or very low.
These low values at the beginning of the curve are notably
extended in the graphic corresponding to face-to-face students;
more than half of them have zero or very low levels of
IEG. It can be seen that the proportion of students with
higher engagement is more relevant in the case of the blended
students. Finally, the index illustrates that, in the case of
the blended students, the distribution between the students
with high and low engagement is very similar, while in the
case of the face-to-face students the largest proportion of the
students register a very low engagement index. For illustrative
purposes, a student with a IEG greater than 0.985 is a student
who does at least 12 comments in 3 differents days, has 24
36
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

assignments submitted, 12 ﬁles uploaded, 4.2 comments on
submissions and the standard activity frequency is 32 days
per year when some activity took place.
Figure 1. Blended (a) and Face-to-face (b): IEG distribution by modality of
English teaching.
In the ﬁeld of education, the data from schools have
typically been considered as well-deﬁned units with students
“nested” or grouped within schools. The same happens at
the classroom-level. The analysis at the classroom level con-
tributes to examine what role do the teachers play in the
engagement of their students.
For each student, an indicator was computed showing if
they submitted any assignments. The new indicator, y1 = 1 if
x1 > 0 and y1 = 0 otherwise, was aggregated at the classroom
level by computing its average for all the students in each
classroom. A classroom with an average of 0.50 would mean
that half of the students submitted at least one assignment and
the rest of the students did not submit any. Figure 2 shows for
each classroom the percentage of students with at least one
assignment submitted. It can be seen that in both histograms,
for the students in blended classrooms and for the ones in
face-to-face classrooms, a U-shaped graph appears. The U-
shaped graph shows that the average of y1 for the classrooms
do concentrate either near 0% or 100% suggesting the teachers
effect on the level of students engagement. There are some
teachers who do use the LMS, and therefore almost all of
their students use it, and there are some teachers who do not
use the LMS and neither do their students.
The engagement on the LMS is inﬂuenced by the modality
of English teaching: more groups from blended than face-to-
face registered a higher engagement (IEG). This indicates that
the students’ activity is not only determined by the teaching
modality but also by the role played by the classroom teacher.
B.
Relationship between engagement and performance levels
The correlation was computed between IEG and the adap-
tive online EFL test score. Performance levels of the test
are designed in accordance to those of CEFR. The analysis
was done with 46,776 blended students.We found a moderate
correlations, namely, the Pearson correlation was 0.24 for all
students. We compared the distribution of the levels reached
by the students in the English assessment according to their
level of IEG (see Table I). The analysis shows that the higher
the IEG level, the larger the proportion of students that reach
the highest levels of the test results. Only 32% of the blended
students who have no activity in the LMS (IEG = 0) achieve
the A2 level in the EFL test, whereas this percentage increases
to 62% when we consider the students with a high level of
engagement (IEG greater than 0.985).
The results obtained are observed in the comparison of the
different estimated density functions of the obtained score
for each IEG level. Figure 3 represents the blended students
grouped based on their engagement performance. As men-
tioned before, the higher the IEG the higher their VRG score.
The range of the score of the adaptive test is from 0 to
1500. The score was standardized with an average of 500 and
a standard deviation of 100. After that, cut-off points were
established to determine the levels in accordance to the CEFR.
Figure 3 shows a shift to the right of the curves that represent
a higher level of IEG.
TABLE I. ADAPTIVE EFL TEST (VRG) LEVELS OBTAINED BY LEVELS OF
IEG.
A0
A1-
A1+
A2-
A2+
Total
IEG = 0
1%
32%
35%
31%
1%
100%
0 < IEG ≤ 0.3
1%
26%
32%
41%
1%
100%
0.3 < IEG ≤ 0.8
0%
19%
28%
50%
2%
100%
0.8 < IEG ≤ 0.985
0%
16%
27%
54%
3%
100%
IEG ≥ 0.985
0%
10%
23%
62%
5%
100%
In order to compare the distribution of the VRG scores
according to their level of IEG, we run Kolmogorov-Smirnov
37
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

Figure 2. Blended (a) and Face-to-face (b): Percentage of students within a
classroom with at least one submission by modality of English teaching.
tests in R for each pair of densities. The ﬁve distributions are
signiﬁcantly different (all of the p-values are less than 10−13).
V. DISCUSSION
The modality of teaching plays a relevant role during the
learning of English. The results are consistent with previous
works which suggest that online engagement is enabled or
inﬂuenced by the role played by teachers or tutors [28] [29].
In other words, it is not only the deployment or access to the
educational technology but the human factor which enables
students participation or engagement. This study illustrates the
advantages of an appropriate integration between the use of
Figure 3. Blended students: estimated VRG score density by levels of IEG.
educational technology and face-to-face practices in primary
level education. The majority of research works we reviewed
address higher levels of education. However, in this case the
analysis focused on K-12 students and the results showed
to be consistent with the results of more advanced levels
of education. Additionally, previous works have indicated
that only small, positive relationship was identiﬁed between
engagement and performance at the student’s level [30]. In
our work, we tested these results but aimed for a larger
sample (national scale outside of the context of Massive Open
Online Course) in order to explore the replicability of this
trend. We identiﬁed low to moderate correlation between the
use of the LMS (based on the engagement index) and the
students performance on the adaptive test. This is aligned with
what Gaˇsevi´c et al. (2016) [10] suggest that under speciﬁc
circumstances engagement can be correlated with student
performance, when measuring the use of LMS. However,
engagement can not be understood as a unequivocal predictor
of performance. In that sense, it is important to state that our
results do not indicate causality on student performance but
they suggest the usefulness of the LMS during the learning
experience.
This study follows guidelines of previous works which
have focused on engagement as a critical dimension to study
students learning and/or participation [5] [23] [24] . One
contribution of this study has been to document the elaboration
of the engagement index. The input that our work provides is
to document the steps followed during the selection of different
variables as well as the weight that these values have in the
elaboration of the IEG. This was done with two major purposes
in mind: to ensure the transparency of the indexs elaboration,
and to simplify the replicability (or improvement) of the IEG
in future works.
VI. CONCLUSION AND FURTHER WORK
This study aimed to analyze a large sample of 4th, 5th, and
6th grade primary students in Uruguay.We elaborated an En-
gagement Index to compare two different teaching modalities
38
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

for learning English. One of them, more traditional based on
face-to-face interaction where the teachers deliver the lessons
in dialogue with learners. The other is conducted under a
blended model, combining remote video conference, the use
of a LMS and face-to-face interaction.
One of the ﬁndings that arises from the comparative analysis
is that socio-cultural context and teaching modality are corre-
lated with engagement. Students from higher socio-cultural
contexts present higher levels of engagement. We identiﬁed
that engagement increases with student grade level. In other
words, the higher the students grade, the higher their LMS
participation. Blended students registered a higher index of
engagement in comparison to the face-to-face students. This
could indicate that, when technological resources are well
embedded in the design of the program, students engagement
increases. The contribution of technology was registered even
when the English proﬁciency of teachers was not high.
Regarding the learning outcome (test results) and the En-
gagement Index, we identiﬁed a consistent correlation in all
groups analyzed, between frequency of use of the LMS and
the English learning outcome. Although this result does not
indicate causality, it suggests the usefulness of the platform.
Engagement can help to understand students performance;
however, as a stand-alone dimension, it is a poor predictor of
performance. It is still necessary to consider additional factors
associated with learning.
As shown in the analysis, IEG tries to capture the effect
of the teaching modality (face-to face vs blended) in the
integration of the LMS during the teaching practices. The
results indicate that the use of LMS by 4th, 5th, and 6th grade
students enhanced the learning experience when this tool is
integrated within the ecosystem of the teaching and learning
process.
Based on the ﬁndings, we present some reﬂections regard-
ing the introduction of technology in educational practices
with students in primary education. Although this study is
exploratory based on data analysis, it is important to emphasize
the role of teachers in relation to the use of the platforms
at the primary level. Academic work exploring the impact
of technology in education has usually studied large scale
interventions in secondary and tertiary education, e.g., Massive
Open Online Courses. It is expected that this study can
contribute to future research in the ﬁeld when exploring the
role of technology with students in primary level.
One limitation of this research is that we can not claim
that the sample is representative of the population. Although
this study included a high number of students, the participants
were self-selected (the ones assessed in the national adaptive
test).
Future research can also revise the analysis of log data
(optimizing the engagement index) in order to improve student
outcomes. Additional studies could explore if it is possible to
optimize the IEG measurement by capturing non-structured
data, e.g., contents of the comments, quality of assignments
from the LMS as well as using social network analysis. Further
research can investigate the possibility to replicate the analysis
using the 2016 log-data in order to verify the consistency of
the patterns found. Finally, it would be interesting to identify
the critical variables which explain and/or predict learning
performance.
ACKNOWLEDGMENT
We would like to thank Hern´an Silva and Sof´ıa Doccetti
who are part of the technical team. They would also like to
thank Plan Ceibal, Ceibal en Ingle´es and the Departamento
de Segundas Lenguas for their support, and Claudia Brovetto,
Gabriela Kaplan and Cecilia Aguerrebere for their valuable
contributions.
REFERENCES
[1] F. Avvisati, “Students, Computers and Learning: Making the Connec-
tion,” OECD Publishing, 2015.
[2] J. S. Brown and P. Duguid, “The Social Life of Information: Updated,
with a New Preface,” Harvard Business Review Press, 2017.
[3] M. Bail´on, M. Carballo, C. Cobo, S. Magnone, C. Marconi, M. Mateu,
and H. Susunday, “How can Plan Ceibal Land into the Age of Big
Data?” DATA ANALYTICS 2015, The Fourth International Conference
on Data Analytics, pp. 126–129, 2015.
[4] C. Cobo, M. Mateu, M. Gomez, and C. Aguerreberre, “Strategies for
Data and Learning Analytics Informed National Education Policies:
the Case of Uruguay,” 7th Learning Analytics and Knowledge (LAK)
conference organized by the Society for Learning Analytics Research
(SOLAR) and the Simon Fraser University, 2017.
[5] C. R. Henrie, “Measuring Student Engagement in Technology-Mediated
Learning Environments,” All Theses and Dissertations, vol. Paper 5949,
2016.
[6] C. Brovetto, “Ceibal en Ingl´es: Ense˜nanza de Ingl´es por videoconferen-
cia en Educaci´on Primaria. Aprendizaje Abierto y Aprendizaje Flexible.
M´as all´a de formatos y espacios tradicionales,” Plan Ceibal, pp. 210–
229, 2013.
[7] “Common
European
Framework
of
Reference
for
Languages:
learning,
teaching,assessment,
Language
Policy,”
2001,
URL:
https://www.coe.int/t/dg4/linguistic/Source/Framework EN.pdf.
[8] C. Marconi and M. Luzardo, “Adaptive English evaluation in the
Uruguayan educational system, 2015,” Plan Ceibal, CODICEN, British
Council and CEIP, (S. Rovegno, Trans.), 2016.
[9] Y. Park and I. H. Jo, “ Development of the Learning Analytics Dashboard
to Support Students’ Learning Performance,” J. UCS, pp. 110–133, 2015.
[10] D. Gaˇsevi´c, S. Dawson, T. Rogers, and D. Gaˇsevi´c, “Learning analytics
should not promote one size ﬁts all: The effects of instructional
conditions in predicting academic success,” The Internet and Higher
Education, vol. 28, pp. 68–84, 2016.
[11] A. Wolff, Z. Zdrahal, A. Nikolov, and M. Pantucek, “Improving reten-
tion: Predicting at-risk students by analysing clicking behaviour in a
virtual learning environment,” In Paper presented at the proceedings of
the third international conference on learning analytics and knowledge,
2013.
[12] D. T. Tempelaar, B. Rienties, and B. Giesbers, “ In search for the most
informative data for feedback generation: Learning Analytics in a data-
rich context,” Computers in Human Behavior, vol. 47, pp. 157–167,
2015.
[13] J. Ma, X. Han, J. Yang, and J. Cheng, “Examining the necessary
condition for engagement in an online learning environment based on
learning analytics approach: The role of the instructor,” The Internet and
Higher Education, vol. 24, pp. 26–34, 2015.
[14] M. L. Hung and C. Chou, “Students’ perceptions of instructors’ roles
in blended and online learning environments: A comparative study,”
Computers and Education, vol. 81, pp. 315–325, 2015.
[15] B. J. Calder, E. C. Malthouse, and U. Schaedel, “An experimental
study of the relationship between online engagement and advertising
effectiveness,” Journal of Interactive Marketing, vol. 23(4), pp. 321–
331, 2009.
[16] I. P. Cvijikj and F. Michahelles, “Online engagement factors on Face-
book brand pages,” Social Network Analysis and Mining, vol. 3(4), pp.
843–861, 2013.
39
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

[17] J. M. Jennings and T. E. Angelo, “Student engagement: Measuring and
enhancing engagement with learning,” [Proceedings of a symposium],
New Zealand Universities Academic Audit Unit, 2006.
[18] G. D. Kuh, “What we’re learning about student engagement from NSSE:
Benchmarks for effective educational practices,” Change: The Magazine
of Higher Learning, vol. 35(2), pp. 24–32, 2003.
[19] S. Kinash, M. Judd, V. Naidu, E. Santhanam, J. Fleming, M. Tulloch,
B. Tucker, and S. Nair, “Measuring and improving student course
engagement and learning success through online student evaluation
systems,” Learning and Teaching papers, vol. Paper 113, 2015.
[20] J.
D.
Gobert,
R.
S.
Baker,
and
M.
B.
Wixon,
“Operational-
izing
and
detecting
disengagement
within
online
science
mi-
croworlds,” Educational Psychologist, vol. 50, pp. 43–57, 2015,
doi:10.1080/00461520.2014.999919.
[21] N. Sanprasert, “The application of a course management system to
enhance autonomy in learning English as a foreign language,” System,
vol. 38, pp. 109–123, 2010, iSSN 0346-251X.
[22] S. Bhat, P. Chinprutthiwong, and M. Perry, “Seeing the Instructor in
Two Video Styles: Preferences and Patterns,” International Educational
Data Mining Society, 2015.
[23] J. Wintrup, K. Wakeﬁeld, and H. C. Davis, “Engaged learning in
MOOCs: a study using the UK Engagement Survey,” 2015.
[24] A. Voight and J. Torney-Purta, “A typology of youth civic engagement
in urban middle schools,” Applied Developmental Science, vol. 17(4),
pp. 198–212, 2013.
[25] R Core Team, R: A Language and Environment for Statistical
Computing, R Foundation for Statistical Computing, Vienna, Austria,
2017. [Online]. Available: https://www.R-project.org/
[26] B.
Ripley
and
M.
Lapsley,
RODBC:
ODBC
Database
Access,
2017, r package version 1.3-15. [Online]. Available: https://CRAN.R-
project.org/package=RODBC
[27] J. Kormos and T. Kiddle, “The role of socio-economic factors in
motivation to learn English as a foreign language: The case of Chile,”
System, vol. 41(2), pp. 399–412, 2013.
[28] D. Gedera, J. Williams, and N. Wright, “Identifying factors inﬂuenc-
ing students motivation and engagement in online courses,” Springer,
Singapore, pp. 13–23, 2015.
[29] K. Larkin, “Course redesign to improve pre-service teacher engagement
and conﬁdence to teach mathematics: A case study in three parts,”
International Journal for Mathematics Teaching and Learning, vol.
17(1), 2016.
[30] M. Wells, A. Wollenschlaeger, D. Lefevre, G. D. Magoulas, and
A. Poulovassilis, “Analysing engagement in an online management
programme and implications for course design,” In Proceedings of the
Sixth International Conference on Learning Analytics and Knowledge,
pp. 236–240, 2016.
40
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

