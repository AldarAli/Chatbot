239
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Information Content of Very High Resolution SAR 
Images: Study of Dependency of SAR Image 
Structure Descriptors with Incidence Angle 
 
Corneliu Octavian Dumitru 
Remote Sensing Technology Institute (IMF) 
German Aerospace Center (DLR) 
Oberpfaffenhofen – Wessling, Germany 
corneliu.dumitru@dlr.de 
Mihai Datcu 
Remote Sensing Technology Institute (IMF) 
German Aerospace Center (DLR) 
Oberpfaffenhofen – Wessling, Germany 
mihai.datcu@dlr.de
 
 
Abstract—This paper provide systematic results of the 
influence of the Synthetic Aperture Radar image structure 
descriptors with incidence angle and orbit direction. The 
evaluation is done on TerraSAR-X data and the interpretation 
is done semi-automatically. In the first part, we study and 
assess the behavior of the primitive feature extracted methods 
for images of the same scene with 2 look angles covering the 
min-max range of the sensor. After that the influence of the 
orbit looking is shortly discuss. The tests are done on 
TerraSAR-X products High Resolution Spotlight mode at 3 m 
resolution and two sites covering the Berlin and Ottawa area 
are found to be suitable for this investigation. To identify the 
best features and appropriate incidence angle for them the 
Support Vector Machine and as a measure of the classification 
accuracy the precision–recall were considered. The recall 
shows that the optimal value of the incidence angle in order to 
have a higher classification is obtained for a value of the 
incidence angle closer to upper bound of the sensor range. In 
the second part of the paper a list of queries that can be asked 
by Earth Observation users are presented and proposed to be 
implemented 
in 
the 
next 
generation 
of 
our 
system.                  
The first contribution of this paper is the evaluation of four 
primitive features that are very known (gray level co-
occurrence matrix, Gabor filter, quadrature mirror filter, and 
non-linear short time Fourier transform) but not used and 
compared for SAR images. After the best primitive feature is 
identified the second contribution of this paper lies in the fact 
that the parameters of the data namely, incidence angle and 
orbit direction are systematically investigated in order to find 
the dependency between these parameters and the accuracy of 
the retrieved classes.  
Keywords-classes; features; inicdence angle; orbit direction; 
query; SAR iamges 
I. 
 INTRODUCTION  
The specific information in High Resolution (HR) 
Synthetic Aperture Radar (SAR) images acquired in single 
polarization is mainly in the "structure", e.g. textures, 
objects, or scattering signatures. The "spatial context" 
becomes very important rather than the "pixel based" 
descriptors, which are less informational. The adopted 
solution is to analyze image patches corresponding to ground 
areas of ca. 200 x 200m. Experiments and tests carried 
recently confirmed the usefulness of the concept, however 
further analysis is needed to assess the behavior of the 
method for the indexing of very large SAR data sets as the 
case in Image Information Mining (IIM) [1]. 
There are few publications available [2] ÷ [6] where the 
images are tiled into patches and generating a large number 
of classes. In [2], the patch size is 256 x 256m in order to 
ensure that the extracted information capture the local 
characteristics within a patch rather the global features across 
the entire image. 
In [3], the TerraSAR-X high resolution Spotlight 
products (resolution of ~1 m) were tiled into patches of 
200 x 200m in order to characterize the large and relatively 
small structures available in the urban scene. The images 
covered different region: Las Vegas, Venice, Gizah, and 
Gauting. From 7,000 extracted patches a set of 30 classes 
were generated.  
In [4], the original images are tiled into patches of 
16 x 16 pixels or 128 x 128 pixels. Three classes were 
extracted (city, forest, and sea) and the results of the 
classification shows better performances when the image 
was tiled in patches of 128 x 128 pixels. The same authors 
propose in [5] a patch contextual approach for high 
resolution satellite images (resolution of 0.6 m) where the 
patch size is 200 x 200 pixels. The number of classes was 18. 
In our previous work [6], a pyramid with different 
resolutions (1m, 2m, 2.9m, 4m, and 8m) was considered for 
TerraSAR-X high resolution Spotlight where each image 
was tiled into patches at different size in order to have the 
same area covered on the ground. The patch sizes vary from 
400 x 400m (for 1m resolution) to 25 x 25m (for 8m 
resolution). The two scenes (Venice and Toulouse) were 
considered for this investigation and 30 classes were 
identified. 
In this paper, we propose to study and experimentally 
asses the most relevant PF behavior for indexing the content 
of SAR images as TerraSAR-X. The envisaged algorithms 

240
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
are very well known but not very used for SAR data. After 
finding the best primitive feature algorithm considering the 
optimal size of the patch for high resolution Spotlight mode 
radiometrically enhanced product equal to 220 x 220 pixels 
the second step was to determine the dependency of the SAR 
imaging with the incidence angle. In the end of the paper a 
series of queries that can implemented starting from the 
TerraSAR-X metadata (available in the XML file attached to 
the product), TerraSAR-X image, patches, semantic 
annotation (ontology) of the patches, and primitive features 
extracted from each patch were presented. 
The paper structure is the following. Section II presents 
the TerraSAR-X products used for tests and based on this a 
test dataset is built. Section III explains the actual state-of-
the-art of the feature extraction methods and shortly 
describes the applied methods. Section IV describes the 
methodology used in the next Section. Section V provides 
the details about the experiments, while Section VI gives 
some examples of queries that can be implemented in EO 
systems. Section VII points the conclusion and references 
given at the end of the paper. 
II. 
TERRASAR-X PRODUCTS 
In this section, we discuss the basic TerraSAR-X 
products that are intend to be used and the test dataset that 
was built for this evaluation. 
TerraSAR-X is the German radar satellite and it operates 
in the X-band with a side-looking SAR based on active 
phased array antenna technology [7]. It does supply high 
quality radar data for purposes of scientific observation of 
the Earth. 
The basic products [7] are available in a huge diversity of 
modes (Stripmap, Spotlight, ScanSAR), types (complex, 
detected, geocoded), and configurations (Spatially Enhanced 
Products or Radiometrically Enhanced Products). 
In Figure 1, examples of the basic products are presented 
in order to understand the diversity of TerraSAR-X satellite 
and the difference between these products. Note that, in the 
examples shown in Figure 1, the ScanSAR mode and SSC 
type are missing because was not possible to find in the 
archive these products covering the same area of interest.  
The size of the sub-images tiled from the original image 
and presented in Figure 1 is the same but the coverage on the 
ground is different because the resolution and/or pixel 
spacing of this is different. 
From this huge diversity of products we selected based 
on our previous results [6], [34], and [37] the following 
configuration: 
 
the high resolution Spotlight (HS) mode as one of 
the most popular mode used for research,  
 
the detected product GEC (Geo-coded Elipsoid 
Corrected) products because is geo-referenced 
product and the localisation of the pixels can be 
realised with a higher accuracy than for other 
products. In some applications this is very 
important.  
 
the radiometrically enhanced (RE) configuration 
where the range and azimuth resolution are 
decreased in order to reduce the speackle. 
Our test dataset is created in order to answer to the 
following question: “Which is the optimal incidence angle 
for a better classification?”. 
The characteristics of the test dataset (configuration of 
the product presented before) that we identified in the 
TerraSAR-X archive [34] and selected for this evaluation 
(Berlin – Germany and Ottawa – Canada) are the following: 
 
the ground range resolution is about 2.9 meters, 
 
the single polarisation HH, 
 
Figure 1. Comparative examples of TerraSAR-X products that covers the diversity of: (a) types, (b) geometric resolution configurations, and (c) modes. 
        Spatially  
              Radiometrically 
         Enhanced  
      enhanced 
 
 
 
 
 
  
enhanced   
    High resolution  
   StripMap mode 
     Spotlight mode 
(a) 
(b) 
(c) 
      Multi-look Ground             Geo-coded Elipsoid          Enhanced Ellipsoid 
   range Detected (MGD)           Corrected (GEC)            Corrected (EEC) 

241
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
the orbit looking is ascending for Berlin and 
descending for Ottawa, 
 
the incidence angle is 30° and 42° for Berlin and 
27° and 41° for Ottawa, 
 
the number of looks depends by the incidence angle 
and varies from 5 for an incidence angle of 20° to 9 
for an incidence angle of 55°, 
 
the size of the images is 5549 x 3368 pixels in case 
of Berlin and 4783 x 3381 pixels in case of Ottawa. 
From the image a rectangle is selected in order to 
not have the black letter box effect on the 
processing of the features (see Figure 10). 
In order to understand the difference between different 
values of the incidence angle in Figure 2-a two examples are 
presented. The first one corresponds to central station in 
Berlin and the acquisition of the data was different in order 
to cover the range of the incidence angle. The second one 
corresponds to high builds in the financial district of Ottawa 
and also here the incidence angle was different in order to 
capture the sensibility of the data with the incidence angle.  
Similar examples are presented in Figure 2-b but this 
time we are interested in the orbit direction and for this 
reason we selected two area in Berlin having the orbit 
direction ascending and descending. 
For high resolution SAR images the diversity of the 
classes that can be retrieved from the image is higher than in 
the case of lower resolution images. In Figure 3 the diversity 
of the classes identified in our test dataset is shown. 
 
Figure 2-a. Different patches tiled from the images having the incidence 
angle close to lower and upper bound of the sensor range for Berlin (left 
side of the image) and Ottawa (right side of the image). The characteristics 
of the entire image from where the patches were tiled are: TerraSAR-X HS 
mode with RE configuration at about 2.9 meters resolution with ascending 
looking for Berlin and descending looking for Ottawa. 
 
Figure 2-b. Examples of patches covering the same area on ground but with 
a different orbit direction and incidence angle for the area of Berlin. The 
characteristics of the image from where the patches were tiled are: 
TerraSAR-X HS mode with RE configuration at 6.5 meters resolution. 
 
Figure 3. A set of classes that can be extracted from the two investigate 
sites that are available in our test dataset. 
III. 
FEATURES EXTRACTION METHODS  
In this section, we select four feature extraction methods 
that have been proposed in the past several decades by 
different authors and we compare these for SAR images. 
On a conceptual level we decide which features can be 
extracted in general and on a practical level, we apply the: 
gray level co-occurrence feature extraction [13] for texture 
analysis, Gabor filtering [18] to extract any geometrical or 
neighborhood relationships, quadrature mirror filters [30] for 
texture analysis, and non-linear short time Fourier transform 
[32] for spectral characteristics of the image. 
We can divide the features in two categories: statistical 
and spectral [27], [28]. 
A. Statistical 
1) Gray level co-occurrence matrix 
a) State of the art 
The gray level co-occurrence matrix (GLCM) is a second 
order statics of how often different combinations of pixel 
brightness values (gray levels) occur in an image [13]. 
Haralick et al. [8] compute gray level co-occurrence 
matrix for a distance of one with four directions (0°, 45°, 
90°, and 135°). For a seven-class classification problem, they 
obtained approximately 80% classification accuracy using 
texture features in remote sensing images application. 
Rignot and Kwok [9] have analyzed SAR images using 
texture features computed from GLCM. However, they 
supplement these features with knowledge about the 
properties of SAR images. For example, image restoration 
algorithms were used to eliminate the specular noise present 
in SAR images in order to improve classification results.  
Schistad and Jain [10] compare different methods for 
texture computation in ERS SAR imagery. One of the used 
and computed methods was GLCM with four directions like 
in [8]. The angular second moment, contrast, entropy, 
cluster shade, inertia, and inverse difference moment [13] 
were computed as texture features from the GLCM. A five 
class classification problem was considered and 29% (an 
average) classification error using GLCM was obtained. 
Randen and Husoy [11] consider GLCM as a reference 
method and they compared this with other filtering methods 
(like: QMF, Gabor, discrete cosine transform, etc.) for 
texture extraction. The size of the gray levels in the image is 
8 x 8 (also chosen by Ohanian and Dubes [12]). On the one 
hand, if the value is large, the number of pixel pairs 
contributing to each element in image will be low, and the 
statistical significance poor. On the other hand, if the gray 
levels are low, much of the texture information may be lost 
in the image quantization. The angular second moment, 
contrast, correlation, and entropy were computed as texture 
features for each orientation. The average of the 
classification error was 32%. 
b) Appplied method 
The GLCM is created from a gray scale image by 
selecting either horizontal (0°), vertical (90°), or diagonal 
(45° or 135°) orientation. 
The size of GLCM depends on the number of gray values 
available in the image. For example, in [29], they obtain for 
         ascending  
 
     descending 
                  29°                                                   37°                            
 
  Berlin  
 
                       Ottawa     
  30°                            42°                 27°                              41° 
Berlin 
Ottawa 

242
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
an input image of 8 bits, i.e., 256 values, a GLCM of 
256x256 elements.  
In our case, we scale the radiometric range of the input 
images to 16 steps and obtain a GLCM size of 16x16 
elements.  
The texture parameters [13] computed from the GLCM 
are: mean, variance, entropy, contrast, energy, correlation, 
homogeneity, autocorrelation, dissimilarity, cluster shade, 
cluster prominence, and maximum probability. 
B. Spectral 
1) Gabor filters 
a) State of the art 
A Gabor filter is a linear filter used in image processing 
that is included as a descriptor in MPEG 7 [38]. 
Randen and Husoy [11] review the major filtering 
approaches to texture feature extraction and performed a 
comparative study by comparing with two classical non-
filtering approaches (GLCM which is a statistical method 
and autoregressive which is model based method). The 
dyadic Gabor filter bank (i.e. Gaussian shaped band-pass 
filters, with dyadic coverage of the radial spatial frequency 
range and multiple orientations) proposed by Jain and 
Farrokhnia [14] was considered for the experiments in [11]. 
Five radial frequency were used (proposed by [14] for 
images of size 256 x 256 pixels) and four orientations (0°, 
45°, 90°, and 135°). The average error on the classification 
was 31%. 
Du [15] used texture features derived from Gabor filters 
to segment SAR images. He successfully segmented the 
SAR images into classes of water, new forming ice, older 
ice, and multi-year ice. Lee and Philpot [16] also used 
spectral texture features to segment SAR images. 
Shu et al. [17] extract the information at four directions 
(0°, 45°, 90°, and 135°) by using Gabor filters and then 
computing the mutual information of each corresponding 
image pair. The experiments show that the method can work 
very well even if the SAR image is not filtered; this indicates 
that the method is robust to speckle noise. 
In Manjunath and Ma [18], a Gabor wavelet based 
texture analysis method is proposed and its application to 
image databases is demonstrated on Brodatz texture database 
but also considering the current work related to the idea of 
browsing large satellite images database. The experiments 
results demonstrate that these Gabor features are robust. 
Rotation and scale invariance are important in many 
applications and the preliminary results obtained by [18] 
using Gabor features are very promising. 
In [19] ÷ [22], the Gabor filters are applied to Brodatz 
texture database with very good results. 
b) Appplied method 
Frequency and orientation representations of a Gabor 
filter are similar to those of the human visual system, and it 
has been found to be particularly appropriate for texture 
representation and discrimination. In the spatial domain, a 
2D Gabor filter is a Gaussian kernel function modulated by a 
sinusoidal plane wave [18]. The Gabor filters are self-similar 
- all filters can be generated from one mother wavelet by 
dilation and rotation. 
We have chosen the Gabor filters designed by Manjunath 
B.S. and Ma W.Y. at Vision Research Lab, University of 
California. 
The texture parameter results computed from the Gabor 
filter are mean and variance for different scales and 
orientations. 
2) Quadrature mirror filters 
a) State of the art 
Quadrature Mirror Filter (QMF) banks are multirate (i.e. 
with variable sampling rate throughout the system) digital 
filter banks, introduced by Croisier, [23], Esteban and 
Galand [24]. During the last two decades since the inception 
of QMF banks, they have been extensively used in speech 
signal 
processing, 
image 
processing 
and 
digital 
transmultiplexers [25]. QMF banks are used to split a 
discrete-time signal into a number of bands in the frequency 
domain to process each sub-band in independent manner. 
QMF was used for texture analysis by Randen and Husoy 
[11] as extended classes of filters which include among 
others Gabor filters, discrete cosine transform, etc. This is a 
large class of filters which incorporate both infinite impulse 
response (IIR) and finite impulse response (FIR) filters. In 
their experiments the average of the classification error was 
between 26% and 33%. 
b) Appplied method 
As proposed in [30], statistical features obtained from the 
filtered images using QMF banks in synergy with some other 
features can be used for image (satellite image) indexing. 
The number of features which can be obtained from the 
presented algorithm depends upon the level selected for the 
QMF sub-band decomposition like a wavelet. Features are 
nothing but the mean and variance of the four filtered and 
sub-sampled images in the QMF sub-band pyramid.  
There are many techniques available to design QMF 
banks. We have chosen the QMF banks designed by 
Simoncelli E.P.and Adelson E.H. at the Vision Science 
Group, The Media Laboratory, Massachusetts Institute of 
Technology. 
The parameters computed from the QMF banks (QMFS) 
are mean and variance of the low pass sub-band, horizontal 
sub-band, vertical sub-band, and diagonal sub-band. 
3) Non-linear short time Fourier transform 
a) State of the at 
Much work on extraction of features based on short time 
Fourier transform is done in speech and audio processing. 
The method proposed in [26] was investigated by Li and 
Ogihara [32] for music information retrieval. They are using 
short time Fourier transform feature extraction method to 
extract the timbral texture witch is not capture by the popular 
method in speech and music processing, the Mel-frequency 
cepstral coefficients. The derived features computed from 
STFT are: spectral centroid, spectral Rolloff, spectral flux, 
low energy, and zero crossings. 
The goal of Popescu et al. paper [26] is to define an 
analysis model for High Resolution Spotlight SAR imagery, 
which is able to integrate the radiometric, as well as 

243
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
geometric and texture properties of the SAR data, in order to 
facilitate large data-base queries by informational content 
indexing of the images. The proposed model use the 
information contained in the spectra of the SAR signal.  
The Short Time Fourier Transform (STFT) was 
considered in order to extract the features necessary for the 
Bayesian Support Vector Machine classifier. The features 
are: spectral centroid, spectral flux, cepstral coefficients, and 
first and second statistic measures. Using this method a 
number of 30 classes were recognized from the 9,000 
patches of SAR images acquired with TerraSAR-X satellite. 
b) Appplied method 
This method of SAR image feature extraction and 
complex image information retrieval was first proposed in 
[31]. This non-parametric analysis is a form of time 
frequency analysis where the cutting of a spectrum allows 
the study of the phase responses of scatterers seen from 
different viewing angles.  
The STFT extracts six non-linear features: the first two 
features are based on statistical properties of the spectrum 
and the next four features are timbre features used for music 
genre classification [32]. 
Non-linear STFT (NLFT) features were initially 
proposed mainly for feature extraction from complex-valued 
SAR images, but experiments showed that they give very 
encouraging results also for real-valued images.  
Our proposed algorithm is an implementation of the non-
linear STFT feature extraction. The features parameters 
computed from the STFT are: mean of the STFT 
coefficients, variance of the STFT coefficients, spectral 
centroid in range, spectral centroid in azimuth, spectral flux 
in range, and spectral flux in azimuth. 
IV. 
METHODOLOGY  
In this section is presented the methodology used in order 
to identify the best primitive feature (PF) and the incidence 
angle /orbit direction that has a good classification accuracy 
of the TerraSAR-X.  
The general approach adopted here is to divide the 
TerraSAR-X image into a number of sub-images (by tiling 
the image into patches) [6] and to compute the feature 
extraction associated to these patches. 
For our investigation two sites were considered covering 
the area of Berlin (Germany) and Ottawa (Canada).  
First step is the evaluation of the best primitive features 
(GLCM, GAFS, QMFS, and NLFT); features extracted using 
as a test data the Berlin image. The second step of our 
evaluation is to try to identify the incidence angle and orbit 
direction that gives a better accuracy of the classification 
using the best primitive feature identified during the previous 
step. The evaluation of the second step is done on both sites 
available in the test dataset, Berlin and Ottawa. 
To answer to the two questions regarding the best PF and 
incidence angle / orbit direction of the TerraSAR-X a tool 
based on Support Vector Machine with relevance feedback 
(SVM – RF) was built [6]. 
The SVM – RF tool supports users to search patches of 
interest in a large database. The Graphical User Interface of 
this tool allows Human-Machine Interaction to rank the 
automatically suggested patches which are expected to be 
grouped in classes. Visual supported ranking allows 
enhancing the quality of search results by giving positive and 
negative examples. 
The TerraSAR-X product-image is tiled into patches with 
the size of 220 x 220 meters, and after that are sub-sampled 
to 110 x 110 meters for better performances (see reference 
[39] where comparative results are presented in order to find 
the optimal patch size). 
The feature vector for GLCM has a fix number of 
parameters for each orientation equal to 12, but in order to 
capture the information of the object orientation all four 
orientations (from 1 to 4) of GLCM are taking into account 
(48 components denoted by GLCM_1_2_3_4). In the case of 
Gabor filters, 4 scales and 6 orientations (48 features denoted 
by GAFS 4_6) were considered. For QMFS, the number of 
levels of wavelet decomposition was set equal to 1 this 
means a vector of 8 features was obtained (denoted by 
QMFS 1). The last feature vector is represented by NLFT 
and the number of features was fixed to 6.  
All the features are normalised before being used in the 
SVM-RF tool. The Z-score normalisation method was 
selected and used from the methods available in [33]. 
We define a number of semantic classes and group the 
patches accordingly, using the SVM-RF tool (see the 
flowchart in Figure 4) and the human expertise (using as a 
ground truth the Google Earth. We considered that a patch 
belong to only one class based on the dominant content of 
the patch. 
 
Figure 4. The proposed methodology is the following: (1) the input SAR images are tiled into patches at different size (depending by the resolution and pixel 
spacing of the image) and the primitive features (GLCM_1_2_3_4, GAFS 4_6, QMFS 1, and NLFT) are computed for each patch; (2) the features are 
grouped in classes using the Support Vector Machine classifier; (3) the Google Earth is used as a ground truth in order to define the semantic of the 
generated classes and for visual inspection of these classes. For the evaluation of the best PF the precision-recall metric is computed and after that the PF 
algorithm having the highest recall is used for the evaluation of the incidence angle and orbit direction following the same procedure. 
Patches 
 
Classes 
Primitive 
Feature (PF) 
algorithms 
Classification 
SVM  
Ground truth 
TerraSAR-X images 

244
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 5. Typical classes that can be extracted from: the Berlin image (the top part of the figure) and the Ottawa image (the bottom part of the figure). 
During the evaluation, the number of classes retrieved for 
Berlin area is equal to 11 and for Ottawa area equal to 6. In 
Figure 5 the semantic classes are presented with their 
corresponding number of patches in each class. 
For each step (feature extraction method or incidence 
angle/orbit direction), we tried to detect the classes among 
the number of identified patches of our test dataset. For each 
class, we give 20% of the patches of each class for the 
training as positive examples and one patch from the rest of 
the classes as a negative example and we try to detect the 
similar patches during 7-10 training iterations. The 
evaluations stop when the classified patches which are 
displayed by the Search Engine (SVM - RF tool) remain in a 
stable result (no new patches are longer found from iteration 
to another). The procedure is repeated two times for the same 
class, giving the same positive and negative examples. 
For the quantitative assessment, we compared the 
classification results with the annotated database. We 
propose as evaluation metric the precision-recall that will be 
computed for each class, feature, and incidence angle.  
The precision is defined as the fraction of the retrieved 
images which are relevant, while the recall is defined as the 
fraction of relevant images which have been retrieved.  
V. 
PERFORMANCE EVALUATION 
This section is dedicated to the evaluation of the best 
features that are intended to be used for the evaluation of the 
incidence angles. In Figure 6 is displayed (for Berlin site 
with the incidence angle of 30°) the precision-recall for each 
class separately and for all four investigated features. 
The average of the precision–recall is presented in 
Table I for these features computed over all the classes.  
After the investigation and comparison between the 
features is finished the following conclusion arise that: the 
Gabor filters perform better than the other features especially 
when the precision is computed; regarding the recall, the 
best performance is obtained for quadrature mirror filters. 
The quadrature mirror filters has the advantage of being 
faster (in required run time for feature computation) than the 
Gabor filters. 
TABLE I.  
THE AVERAGE OF THE PRECISION- RECALL  
Features 
Precision 
Recall 
GAFS 4_6 
90.11% 
49.19% 
QMFS 1 
78.59% 
58.77% 
GLCM 1_2_3_4 
84.26% 
50.70% 
NLFT 
71.86% 
55.28% 
 
The discussion reached a point when we have to decide 
what is need the precision that means accuracy of the 
relevant patches from the total number of retrieved patches 
or more relevant patches to be retrieved (recall). Because our 
goal is to find similar patches that exist in our test dataset the 
recall as a metric is considered and as a consequence of this 
decision the QMFS is selected from the four features 
investigated. The precision will be presented only 
informative in the second step where the incidence angle will 
be evaluate. 
From the TerraSAR-X archive [34], we selected two sites 
that correspond to our requirements in order to have the 
incidence angle close to lower and upper bound of the 
TerraSAR-X and different orbit lookings. The range of the 
satellite for high resolution Spotlight mode is between 20° 
and 55°. These two sites are Berlin with incidence angle of 
30° and 42° with ascending looking and Ottawa with 
incidence angle of 27° and 41° with descending looking. 
In the next figures, Figure 7 and Figure 8, for these two 
scenes/sites the metric was computed and the results are 
displayed.  
 
  Water  
    Channel 
  Building reflection 
Urban type 1 
    Urban type 2  
Field 
   31   
 
          32  
 
  64 
 
      111  
             16 
 
   42 
  Forest  
   Forest with  
          Channel 
          Railway tracks 
    Urban type 1      Railway tracks 
                               other objects 
 
 
 
    type 1  
 
 
 
type 2 
    14   
 
          66  
 
  37 
 
      12 
 
             30 
 
  10 
Building reflection     Urban type 2         Streets plus buildings   Urban type 3 
          Sport fields  
         72   
 
 34 
 
      48 
                       28 
 
   9 
 
B
e
r
l
i
n 
O
t
t
a
w
a 

245
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 6. The results of the precision-recall for Berlin. A comparison between all primitive features (GEC-RE product, HS mode, patch size 110x110 pixels). 
 
The best incidence angle in recall was obtained for 
both sites in the case of higher value of the incidence 
angle; this means a value of the incidence angle close to 
the upper bound of the sensor range. 
This value is 42° for Berlin and 41° for Ottawa where 
both orbit directions ascending and descending were 
considered. 
Evaluating the accuracy of the classification separately 
class by class s (the recall metric higher than 65%) the 
following observation can be noticed:  
 
in the case of Berlin better results are obtained for 
“forest”, “forest plus other objects”, and 
“building reflection” class. 
 
in the case of Ottawa better results are obtained 
for “water”, “building reflection”, “urban”, and 
“field”.  
Another study that is presented in this section 
regarding the incidence angle is the influence of this 
parameter when both incidence angles are putted together.  
There are two experiments conducted for this study: 
for the first one, the training was done with examples only 
from one case (only one incidence angle) in order to have 
a reference result and second time with examples from 
both cases (both incidence angles).  
For this investigation the Berlin site is taking into 
account and the results are shown in Figure 9. 
The average of the recall (marked with green color in 
Table II) over all the classes in both cases is: 
 
32.96% when the training was done using one 
incidence angle (e.g. 30°), 
 
38.30% when the training was done combining 
examples from both incidence angles. 
In Table II, the accuracy of the classification 
presented as precision-recall metric is displayed. In the 
right side of the table, the recall for both cases is presented 
for each class separately. For eight from eleven classes the 
recall (marked with red color) is better when the training 
is done with data coming from both incidence angles 
(incidence angles that are covering the min-max range of 
the TerraSAR-X sensor). For the rest of the classes higher 
value in recall (marked with pink color) is obtained when 
the training is done only with data having the incidence 
angle equal to 30°.  
What is interesting here for these three classes 
(classes: streets with some objects and different types of 
railway tracks) is that each of these contains objects that 
have a certain pattern. All these classes can be included in 
a more general class, namely transportation. 
In both cases the class with higher recall (metric 
higher than 65%) is “forest”. 
 

246
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 7. The results of the precision-recall for the center of Berlin. A comparison between the results obtained for both incidence angle 30° and 42°. 
 
Figure 8. The results of the precision-recall for the center of Ottawa. A comparison between the results obtained for both incidence angle 27° and 41°. 

247
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 9. The results of the precision-recall in the case of Berlin. A comparison between the results when the training was done with both incidence angles 
(30° and 42°) and when the training was done with only one value of the incidence angle (30°). 
 
TABLE II.  
A COMAPRISON OF THE PRECISION- RECALL REALISED: WHEN THE TRAINING WAS DONE WITH BOTH INCIDENCE ANGLES AND WHEN THE 
TRAINING WAS DONE WITH ONLY ONE INCIDENCE ANGLE IN THE CASE OF BERLIN AREA. THE FEATURES EXTRACTED ARE QMFS WITH LEVEL OF 
DECOMPOSITION 1. 
Semantic classes 
No. of 
patches 
Precision 
No. of 
patches 
Recall 
Incidence angle  
30° and 42° 
Incidence angle 
30° 
Incidence angle 
30° and 42°° 
Incidence angle  
30° 
Forest 
28 
100.00% 
100.00% 
14 
71.43% 
71.13% 
Forest + other objects 
132 
88.24% 
84.38% 
66 
56.82% 
40.94% 
Channel 
74 
78.57% 
82.14% 
37 
44.59% 
31.08% 
Railway tracks type 1 
24 
100.00% 
100.00% 
12 
29.00% 
29.17% 
Urban type 1 
60 
100.00% 
100.00% 
30 
30.00% 
15.00% 
Railway tracks type 2 
20 
100.00% 
90.91% 
10 
40.00% 
50.00% 
Building reflection 
144 
60.00% 
77.14% 
72 
31.25% 
18.75% 
Urban type 2 
68 
79.31% 
78.26% 
34 
33.82% 
26.47% 
Streets plus buildings 
96 
93.75% 
93.94% 
48 
31.25% 
32.29% 
Urban type 3 
56 
100.00% 
100.00% 
28 
19.64% 
19.00% 
Sport fields 
18 
100.00% 
100.00% 
9 
33.34% 
27.78% 
Total for QMFS and all the 
classes 
90.90% 
91.52% 
 
38.30% 
32.96% 
 

248
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
VI. 
TYPES OF QUERIES 
The purpose of this section is to shows how to improve 
the state of the art of the indexing and querying systems 
available for Earth Observation [7], [35].  
We start this section by presenting a series of query that 
can be asked by EO users. These queries are intended to be 
implemented in the next generation of our system [36]: 
 
1) Query for a product and its metadata: This type of 
query is based on the metadata normally stored in 
the XML file of the TerraSAR-X [6]. 
“Find all GEC products, high resolution Spotlight mode with 
HH polarization that has the latitude equal to 52.49826 N 
and longitude equal to 13.3484534 E”. The results of the 
query are presented in Table III; these parameters are 
extracted from the metadata of each TerraSAR-X product. 
 
2) Query for an image and its metadata: This type of 
query is based on the image and its attached 
metadata (e.g., geographic latitude/longitude). This 
can be useful for a fast query of a location knowing 
the coordinates of the area [7]. 
“Find the images with the center of latitude equal to 
45.42349 N and longitude equal to -75.69793 E and with an 
extension of 0.05“. The result of the query gives us a list 
with 12 images that correspond to specified query (this type 
of search can be done also on the TerraSAR-X archive [7]).  
 
3) Query for images of products that contain patches 
that have certain properties. This type of query can 
be divided in other sub-categories: 
 
a) Query by the land cover/use class of a certain 
patch: This type of query is based on the metadata 
annotated to the patches. 
“Find all patches that correspond to sport fields.” The result 
of this type of query is presented in Figure 10 (all the patches 
marked with green, red, and magenta color). 
 
b) Query by the land cover/use class of a patch 
and the qualitative or quantitative spatial 
properties of a patch: This type of query allows 
us to query for patches with some land cover/use 
class that are spatially related to other patches or 
to a user defined area.  
“Find all patches containing sport fields limited in the west 
by the channel.” The results of this type of query correspond 
to only one patch marked with green color in Figure 10. 
 
c) Query by correlating the land cover/use class 
of more than one patch that has various 
qualitative or quantitative spatial relations 
between them: This type of query extends the 
previous query by allowing the correlation based 
on land cover/use class of multiple patches with 
various spatial relations between them. 
“Find all patches that correspond to a sport field and within a 
distance of patches that correspond to urban area 
(buildings).” There are three such patches (one marked with 
green color and two with red color in Figure 10) that 
correspond to the specific query. 
Another example is: “Find all patches that correspond to 
forest (or trees) that have in middle a sport field.” The results 
are the patches marked with magenta color in Figure 10. 
 
d) Query that involves features of a patch but also 
other properties like the land cover/use class and 
spatial relations: This type of query is based on 
the 
parameters 
of 
the 
feature 
extraction 
algorithms.  
“Find the mean and variance of the low pass sub-band filter 
(the first and second value of the quadrature mirror filters 
vector) for a patch that corresponds to a railway tracks.” This 
query can be useful to understand why sometimes some 
patches may not be grouped tougher even are containing the 
same object (e.g. railway tracks). Such example is found for 
Berlin site (Figure 5) where two classes containing railway 
tracks are spitted in two different classes. 
In Figure 11 is presented an example showing the 
difference between the quadrature mirror filter (QMF) 
features extracted from two patches classified as bridge 
having the incidence angle equal to 27° and 41°.  
 
TABLE III.  
THE RESULTS OF THE QUERY – TYPE 1. 
No. 
Product 
Time UTC 
Incidence angle 
Orbit direction 
1 
GEC, SE., High Resolution Spotlight, HH 
2008-10-11    05:25:17 
36.08518° 
Descending 
2 
GEC, SE., High Resolution Spotlight, HH 
2008-09-30    05:25:17 
35.73137° 
Descending 
3 
GEC, SE., High Resolution Spotlight, HH 
2008-09-19    05:25:16 
35.73308° 
Descending 
4 
GEC, RE, High Resolution Spotlight, HH 
2009-03-23    16:43:52 
30.01653° 
Ascending 
5 
GEC, RE, High Resolution Spotlight, HH 
2009-11-03    16:52:35 
41.90324° 
Ascending 

249
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 10. Results of the proposed queries (query type 3 case a), b), and c)) are marked with different color on the quick-look of the image (city of Berlin).
 
Figure 11. Representation of the QMFS features extracted from the same patch (‘bridge’) having the incidence angle equal to 27° and 41° in the case of 
Ottawa area. 
VII. CONCLUSION 
Based on the results obtained in previous sections a 
general conclusion regarding the incidence angle can be 
drawn manely, the value of the incidence angle closer to the 
lower bound of the sensor range is optimal if the precision 
metric is considered or value of the incidence angle closer to 
the upper bound of the sensor range is optimal if the recall 
metric is computed. However, our goal is to retrieve similar 
patches in a large database and recall is the metric that gives 
as a good measure for this.  
Regarding the orbit direction in both cases (Berlin and 
Ottawa) the classification accuracy obtained for the 
incidence angle was the same even the orbit looking was 

250
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
different (ascending looking for Berlin and descending 
looking for Ottawa). This leads to the idea that the orbit 
direction can be disregarded because the influence of this is 
not so major (maybe for some classes can be important). The 
classification accuracy is given by the incidence angle, the 
parameters of the data (patch size, pixel spacing, and 
resolution), and the primitive features used.  
As a general remark, the SAR signature depends on the 
incidence angle of the data and the accuracy of the 
classification may decrease for different values of the 
incidence angle. 
Examining the types of queries presented in section VI, 
we noticed that the existing EO portals offer partial or full 
support for asking queries of type 1 and 2, but cannot be 
used to answer any of the queries of type 3 and its sub-
categories. These queries can only be asked and answered if 
the knowledge discovery technologies are applied to 
TerraSAR-X images and the relevant knowledge are 
extracted and captured by the semantic annotations. In other 
words the list of queries presented above is intended to be 
implemented in the next generation of the system [36]. 
A real use case and/or application that we identified for 
this type of queries (e.g., type 3) is for example “finding 
areas (e.g., sport terrain or field) where refugee camp or 
hospitals can be placed after an earthquake” like the one in 
Haiti in January 12, 2010 that ZKI [37] has faced recently.  
ACKNOWLEDGMENT 
This work has been partially funded by ESA (European 
Satellite Agency) under the KLAUS project (contract 
no. 22823/09/I-AM). 
REFERENCES 
[1] C.O. Dumitru and M. Datcu, “Dependency of SAR Image 
Structure Descriptors with Incidence Angle“, in Proc. of 
SPACOMM, Chamonix, May 2012, pp. 92-97. 
[2] C.-R. Shyu, M. Klaric, G. Scott, A. Barb, C. Davis, and K. 
Palaniappan, “GeoIRIS: Geospatial Information Retrieval and 
Indexing System – Content Mining, Semantics Modeling, and 
Complex Queries”, IEEE Trans. Geoscience and Remote 
Sensing, vol. 45, Issue 4, pp. 839-852, 2007. 
[3] A. Popescu, I. Gavat, and M. Datcu, “Contextual Descriptors 
for Scene Classes in Very High Resolution SAR Images”, 
IEEE Geoscience and Remote Sensing Letters, 2012, vol. 9, 
Issue 1, 2012, pp. 80-84.. 
[4] P. Birjandi and M., Datcu, “ICA based visual words for 
describing under meter high resolution satellite images”, Proc. 
of. IGARSS 2009, Cape Town, 2009. 
[5] P. Birjandi and M. Datcu, “Topographic independent 
component analysis model for under meter high resolution 
satellite images characterization”, Proc. of ESA-EUSC-
JRC_2009, Torrejon-Spanien, 2009. 
[6] C.O. Dumitru, J. Singh, and M. Datcu, “Selection of relevant 
features and TerraSAR-X products for classification of high 
resolution SAR images“, EUSAR 2012, Nuremberg-
Germany, 24-26 April 2012, pp. 243-246. 
[7] TerraSAR-X: “Basic Products Specification Document”, 
Issue: 1.6 (TX-GS-DD-3302), 2009. 
[8] R. M. Haralick, K. Shanmugam, and I. Dinstein, “Textural 
features for image classification”, IEEE Trans. Systems, Man, 
and Cybernetics, SMC-3, pp. 610-621, 1973. 
[9] E. Rignot and R. Kwok, “Extraction of Textural Features in 
SAR Images: Statistical Model and Sensitivity”, Proc. 
International Geoscience and Remote Sensing Symposium, 
Washington, DC, pp. 1979-1982, 1990. 
[10] A.S. Solberg and A. Jain, “Texture Fusion and Feature 
Selection Applied to SAR Imagery”, IEEE Trans. Geoscience 
and Remote Sensing, vol. 35, no. 2, pp. 475-478, 1990. 
[11] T. Randen and J.H. Husoy, “Filtering for Texture 
Classification: A Comparative Study”, IEEE Trans.Pattern 
Analysis and Machine Intelligence, vol. 21 no.4, pp. 291-310, 
1990. 
[12] P.P. Ohanian and R.C. Dubes, "Performance Evaluation for 
Four Classes of Textural Features", Pattern Recognition, vol. 
25, no. 8, pp. 819-833, 1992. 
[13] GLCM, 
2012, 
Available: 
http://www.fp.ucalgary.ca/mhallbey/orderliness_group.htm 
[14] A.K. Jain and F. Farrokhnia, “Unsupervised Texture 
Segmentation Using Gabor Filters”, Pattern Recognition, vol. 
24, no. 12, pp. 1167-1186, 1991. 
[15] L. J. Du, “Texture Segmentation of SAR Images Using 
Localized Spatial Filtering”, Proc. International Geoscience 
and Remote Sensing Symposium, Washington, pp.1983-1986, 
1990. 
[16] J. H. Lee and W. D. Philpot, “A Spectral-Textural Classifier 
for Digital Imagery”, Proc. International Geoscience and 
Remote Sensing Symposium, Washington, pp. 2005-2008, 
1990. 
[17] L. Shu, T. Tan, M. Tang, and C. Pan, “A Novel Registration 
Method for SAR and SPOT Images”, Proc. IEEE 
International Conference on Image, pp. II.213-II.216, 2005. 
[18] B. S. Manjunath and W. Y. Ma, “Texture Features for 
Browsing and Retrieval of Image Data”. IEEE Trans. Pattern 
Analysis and Machine Intelligence, vol.18, pp.837–842, 1996. 
[19] P. Porter and N. Canagarajah, “Robust Rotation-Invariant 
Texture Classification: Wavelet, Gabor filter and GMRF 
based Schemes”, Proc. Visual Image Processing, vol. 144, 
no. 3, pp. 180-188, 1997. 
[20] S.E. Grigorescu, N. Petkov, and P. Kruizinga, “Comparison 
of Texture Features based on Gabor Filters”, IEEE Trans. 
Image Processing, vol. 10, no. 11, pp. 1160-1167, 2002. 
[21] D. Zhang, A. Wong, M. Indrawan, and G. Lu, “Content-based 
Image Retrieval Using Gabor Texture Features”, IEEE Trans. 
Pattern Analysis and Machine Intelligence, pp. 13-15, 2000. 
[22] M. Torres-Torriti and A. Jouan, “Gabor vs. GMRF Features 
for SAR Imagery Classification”, Proc. Int. Conference on 
Image Processing, Thessaloniki, vol. 3, pp. 1043 – 1046, 
2001. 
[23] A. Croisier, D. Esteban, and C. Galand, “Perfect Channel 
Splitting 
by 
use 
of 
Interpolation/Decimation/Tree 
Decomposition Techniques”, Proc. International Conference 
on Information Science and Systems, Patras Greece, 1976. 
[24] D. Esteban and C. Galand, “Application of quadrature mirror 
filters to split-band voice coding schemes”, Proc. IEEE Int. 
Conf. ASSP, Hartford, Connecticut, pp. 191-195, 1977.  
[25] P. Vaidyanathan, “Quadrature Mirror Filter Banks, M-band 
Extensions and Perfect-Reconstruction Techniques”, IEEE 
ASSP Magazine, vol. 4, no. 3, pp. 4-20, 1987. 
[26] A. Popescu, C. Patrascu, I. Gavat, J. Singh, and M. Datcu, 
“Spotlight TerraSAR-X Data Modeling using Spectral Space-
Variant Measures, for scene Targets and Structure Indexing”, 
Proc. The 8th European Conference on Synthetic Aperture 
Radar, Aachen, Germany, 2010. 
[27] T. Zou, W. Yang, D. Dai, and H. Sun, “Polarimetric SAR 
Image Classification Using Multifeatures Combination and 
Extremely Randomized Clustering Forests”, EURASIP 

251
International Journal on Advances in Telecommunications, vol 5 no 3 & 4, year 2012, http://www.iariajournals.org/telecommunications/
2012, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Journal on Advances in Signal Processing vol. 2010, 
ID 465612, 9 pages, 2010. 
[28] M. Fauvel, J. Chanussot, J.A. Benediktsson, and J.R. 
Sveinsson, 
“Spectral 
and 
Spatial 
Classification 
of 
Hyperspectral Data using SVMs and Morphological Profiles”, 
IEEE 
International 
Geoscience 
and 
Remote 
Sensing 
Symposium, Barcelona, Spain, pp. 4834-4837, 2002.  
[29] R. Haralick, K. Shanmugam, and I. Dinstein, "Textural 
Features for Image Classification", IEEE Trans. Systems, 
Man, and Cybernetics, vol. 3, no. 6, pp. 610–621, 1973. 
[30] M. Campedel, E. Moulines, and M. Datcu, “Feature Selection 
for 
Satellite 
Image 
Indexing”, 
ESA-EUSC: 
Image 
Information Mining – Theory and Application to EO, 2005. 
[31] A. Popescu, I. Gavat, and M. Datcu, M., "Complex SAR 
image characterization using space variant spectral analysis", 
Proc. IEEE Radar Conference, pp. 1-4, 2008. 
[32] Z. Li and M. Ogihara, “Towards Intelligent Music 
Information Retrieval”, IEEE Trans. Multimedia, vol. 8, 
no. 3, pp. 564-574, 2006. 
[33] N. Karthikeyani Visalakshi and K. Thangavel, “Impact of 
Normalization in Distributed K-Means Clustering”. Int. 
Journal of Soft Computing, vol. 4, no. 4, pp. 168-172, 2009. 
[34] EOWEB 
portal: 
https://centaurus.caf.dlr.de:8443/eoweb-
ng/template/default/welcome/entryPage.vm 
[35] M. Wolfmueller, D. Dietrich, E. Sireteanu, S. Kiemle, E. 
Mikusch, M. Boettcher, “Data Flow and Workflow 
Organization - The Data Management for the TerraSAR-X 
Payload Ground Segment”, IEEE Trans. Geoscience and 
Remote Sensing, vol. 47, no.1-1,pp. 44–50, 2009.  
[36] TELEIOS project: Deliverable D6.2.1: Ontologies for the VO 
for TerraSAR-X data, 2012.  
http://www.earthobservatory.eu/deliverables/FP7-257662-
TELEIOS-D6.2.1.pdf. 
[37] Center for Satellite Based Crisis Information – ZKI, 2012. 
Available: http://www.zki.dlr.de/article/1262. 
[38] MPEG 7, 2012. Available: 
http://mpeg.chiariglione.org/standards/mpeg-7/mpeg-7.htm 
[39] C.O Dumitru and M. Datcu, “Study and Assessment of 
Selected Primitive Features Behaviour for SAR Image 
Description“, in Proc. of IGARSS, Munich-Germany, July 
2012, pp. 3596-3599, 2012. 
 

