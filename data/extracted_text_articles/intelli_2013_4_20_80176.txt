Classification of Three Negative Emotions based on Physiological Signals 
- Classification of fear, surprise and stress 
Eun-Hye Jang, Byoun-Jun Park, Sang-Hyeob Kim, 
Myoung-Ae Chung 
IT Convergence Technology Research Laboratory & IT 
Convergence Services Future Technology Research Dept. 
Electronics and Telecommunications Research Institute 
Daejeon, Republic of Korea 
{cleta4u, bj_park, shk1028, machung}@etri.re.kr 
Mi-Sook Park, Jin-Hun Sohn 
Department of Psychology & Brain Research Institute 
Chungnam National University 
Daejeon, Republic of Korea 
{peaceful1026, jhsohn}@cnu.ac.kr 
 
 
Abstract—Physiological signal is one of the most commonly 
used emotional cues. In recent emotion classification research, 
the one of main topics is to recognize human’s feeling or 
emotion using multi-channel physiological signals. In this study, 
we discuss the comparative results of emotion detection using 
several classification algorithms, which classify negative 
emotions (fear, surprise and stress) based on physiological 
features. Physiological signals, such as skin temperature (SKT), 
electrodermal activity (EDA), electrocardiogram (ECG), and 
photoplethysmography 
(PPG) 
were 
recorded 
while 
participants were exposed to emotional stimuli. Twenty-eight 
features were extracted from these signals. For classification of 
negative emotions, four machine learning algorithms, namely, 
Linear Discriminant Analysis (LDA), Classification And 
Regression Tree (CART), Self Organizing Map (SOMs), and 
Naïve Bayes were used. The 70% of the whole datasets were 
selected randomly for training and the remaining patterns are 
used for testing purposes. Testing accuracy by using the 30% 
datasets ranged from 32.4% to 46.9% and, consequently the 
selected physiological features didn't contribute to classify the 
three negative emotions. In the further work, we intend to 
improve emotion recognition accuracy by applying the selected 
significant features, such as NSCR, SCR, SKT, and FFTap_HF. 
Keywords-emotion classigication; physiological signals; 
negative emotions; machine learning algorithm 
I. 
 INTRODUCTION 
Emotion detection is one of the core factors for 
implementing emotional intelligence in human computer 
interaction research [1]. In particular, it is important to 
recognize negative emotions (e.g., anger, fear, etc.) because 
they have direct or indirectly effects gradual deviance or 
interruption of our normal thinking process, they are 
essential for our natural (unforced) survival or struggle for 
existence. Emotion recognition has been done using by facial 
expression, gesture, voice, and physiological signals. In 
particular, physiological signals have advantages; they are 
less affected by social and cultural difference as well as 
signal acquisition by non-invasive sensors is relatively 
simple and is possible to observe user’s state in real time. 
They aren’t robust to social masking or factitious emotion 
expression and are related to emotional state [2]. Recently, 
emotion recognition based on physiological signals has been 
performed by using various machine learning algorithms, 
e.g., Fisher Projection (FP), k-Nearest Neighbor algorithm 
(kNN), and Support Vector Machine (SVM). Previous 
results that have showed the over 80% accuracy on average 
seems to be applicable in real world settings [3-8]. We have 
already reported the recognition accuracy on the three 
emotions, i.e., fear, surprise, and stress, derived from only 
training data [9]. As a follow-up work, we performed 
supplementary 
analysis 
by 
using 
machine 
learning 
algorithms for these emotions based on physiological signals. 
We performed each classifier by 10 fold cross-validation for 
solution of the overfitting problem and divided the dataset 
into 70% training and 30% testing subsets for testing 
purposes. The results were compared with the previous result 
that used the only training dataset. To classify three negative 
emotions, four well-known machine learning algorithms, i.e., 
were Linear Discriminant Analysis (LDA), Classification 
And Regression Tree (CART), Self Organizing Map (SOMs), 
and Naïve Bayes, were used. For dataset of physiological 
signals, 
twenty-eight 
features 
were 
extracted 
from 
physiological 
signals, 
i.e., 
skin 
temperature 
(SKT), 
electrocardiogram (ECG), electrodermal activity (EDA), and 
photoplethysmography (PPG). 
II. 
PHYSIOLOGICAL SIGNALS OF EMOTIONS 
Twelve male and female college students (mean age: 
21±1.48 yrs) participated in this study. They reported that 
they had not any medical illness or psychotropic medication 
and any kind of medication due to heart disease, respiration 
disorder, or central nervous system disorder. They 
participated in an experimental session for 10 weeks on a 
weekly basis over 10 times. A written consent was obtained 
prior to the study from the participants and they were paid 
$20 USD per session to compensate for their participation.  
Thirty emotional stimuli (3 emotions x 10 sessions), 
which are the 2-4 min long audio-visual film clips captured 
originally from movies, documentary, and TV shows, were 
used to successfully induce emotions (fear, surprise, and 
stress) in this study (Figure 1). Audio-visual film clips have 
widely used because they have a relatively high degree of 
ecological validity as well as they have the desirable 
properties of being readily standardized and being dynamic 
rather than static [10-13]. 
 
75
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

 
(a) fear 
 
(b) surprise 
(c) stress 
Figure 1.  Examples of emotional stimuli 
The appropriateness and effectiveness of the stimuli were 
examined through a preliminary study. The appropriateness 
of emotional stimlus means the consistency between emotion 
intended by experimenter and participanats’ experienced 
emotion (e.g., scared, surprise, and annoying). The 
effectiveness was determined by the intensity of emotions 
reported and rated by the participants on a 1 to 11 point 
Likert-type scale (e.g., 1 being “least surprising” or “not 
surprising” and 11 being “most surprising”). The result 
showed that emotional stimuli had the appropriateness of 
92% and the effectiveness of 9.4 points on average. The 
appropriateness and effectiveness of each emotional stimuli 
were as follows; appropriateness and effectiveness of fear 
were 89.0% and 9.6 points, 89% appropriateness and 9.5 
points 
effectiveness 
in 
surprise. 
Stress 
had 
the 
appropriateness of 98% and the effectiveness of 9.1 points. 
Prior to the experiment, participants were introduced 
detailed experiment procedure. They had an adaptation time 
to feel comfortable in the laboratory’s environment and then, 
an experimenter attached electrodes on the participants’ wrist, 
finger, and ankle for the measurement of physiological 
signals. Physiological signals were measured for 60 sec as 
baseline prior to the presentation of emotional stimulus and 
for 2 to 4 min as emotional state during the presentation of 
the stimulus, then for 60 sec as recovery term after 
presentation of the stimulus. Participants reported the 
emotion that they had experienced during the presentation of 
the film clips and the intensities of experienced emotions on 
the emotion assessment scale. This procedure was repeated 3 
times in three different emotion conditions. 
 
 
 
Figure 2.  Analysis of physiological signals 
The dataset of physiological signals were collected using 
by MP150 (Biopac system Inc., USA). SKT electrode was 
attached on the first joint ring finger of non-dominant hand 
and EDA was measured with the use of 8 mm AgCl 
electrodes placed on the volar surface of the distal phalanges 
of the index and middle fingers of the non-dominant hand. 
Electrodes were filled with a 0.05 molar isotonic NaCl paste 
to provide a continuous connection between the electrodes 
and the skin. ECG electrodes were placed on both wrists and 
one left ankle with two kinds of electrodes, sputtered and 
AgCl ones. The left-ankle electrode was used as a reference.  
PPG electrode was attached on the first joint of the thumb of 
the non-dominant hand. To extract features, the obtained 
signals for 30 seconds from the baseline and the each 
emotional state are analyzed by AcqKnowledge (Ver. 3.8.1) 
software (USA) as shown in Fig. 2. Twenty-eight features 
were firstly extracted from the physiological signals, which 
have been used for emotion recognition in the study   (shown 
in Table I). 
TABLE I.  
FEATURES EXTRACTED FROM PHYSIOLOGICAL SIGNALS  
Signals 
Features 
EDA 
SCL, NSCR, meanSCR 
SKT 
meanSKT, maxSKT 
PPG 
meanPPG 
ECG 
Time 
domain 
Statistical 
parameter 
meanRRI, stdRRI, meanHR, 
RMSSD, NN50, pNN50 
Geometric 
parameter 
SD1, SD2, CSI, CVI, RRtri, TINN 
Frequency 
domain 
FFT 
FFT_apLF, FFT_apHF, FFT_nLF, 
FFT_nHF, FFT_LF/HF ratio 
AR 
AR_apLF, AR_apHF, AR_nLF, 
AR_nHF, AR_LF/HF ratio 
Two hundred-seventy physiological signal data (3 
emotions x 10 sessions x 9 cases) were used for emotion 
classification except for data having severe artifacts by 
movements, noises, etc. To classify three negative emotions 
by the twenty-eight physiological features, four machine 
learning algorithms, namely, LDA, which is one of the oldest 
classification 
systems, 
CART, 
which 
is 
a 
robust 
classification and regression tree, unsupervised SOM, and 
Naïve Bayes classifier based on density were used in data 
analysis.  
III. 
CLASSIFICATION OF EMOTIONS 
In this study, we have used LDA, which is one of the 
oldest mechanical classification systems and linear models, 
CART which is a robust classification and regression tree, 
unsupervised SOM, and Naïve Bayes classifier based on 
density for three emotion classifications. LDA is a method 
used in statistics, pattern recognition and machine learning to 
find a linear combination of features, which characterizes or 
separates two or more classes of objects or events. It is a 
technique for dimensionality reduction that projects the data 
onto a subspace that satisfies the requirement of maximizing 
the between-class variance (SB) and minimizing the within-
class variance (SW). It then offers a linear transformation of 
76
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

the predictor variables, which provides a more accurate 
discrimination. In LDA, the measurement space is 
transformed allowing the separability between the emotional 
states to be maximized. The separability between the 
emotional states can be expressed through several criteria 
[14]. SW is proportional to the sample covariance matrix for 
the pooled d-dimensional data. It is symmetric and positive 
semidefinite, and it is usually nonsigular if n>d. Likewise, 
SB is also symmetric and positive semidefinite, but because 
it is the outer product of two vector, its rank is at most one. 
In terms of SB and SW, the criterion function J is written as 

J(w) = (wT SB w)/(wT SW w)

This expression is well known in mathematical physics 
and the generalized Rayleigh quotient. It is easy to show that 
a vector w that maximizes J must satisfy 

SB w =  SW w,

for some constant , which is a generalized eigenvalue 
problem.  
CART [14-15] is a non-parametric decision tree 
technique that produces either classification or regression 
trees, depending on whether the dependent variable is 
categorical or numeric, respectively. Given the data 
represented at a node, either declare that node to be a leaf 
(and state what category to assign to it), or find another 
property to use to split the data into subsets. In the generic 
tree-growing methodology known as CART, the basic 
principle underlying a tree creation is simplicity. We prefer 
decisions that lead to a simple, compact tree with few nodes. 
In formalizing this notion, the most popular measure is the 
entropy impurity (or occasionally, information impurity) 
 
(3) 
where, P(j) is the fraction of patterns at node N that are in 
class j. By the well-known properties of entropy, if all the 
patterns are of the same category, the impurity is 0; 
otherwise it is positive, with the greatest value occurring 
when the different classes are equally likely.  
SOMs called Kohonen map, is a type of artificial neural 
networks in the unsupervised learning category and generally 
present a simplified, relational view of a highly complex data 
set [14, 16]. This is called a topology-preserving map 
because there is a topological structure imposed on the nodes 
in the network. A topological map is simply a mapping that 
preserves neighborhood relations. The goal of training is that 
the “winning” unit in the target space is adjusted so that it is 
more like the particular pattern. Others in the neighborhood 
of output are also adjusted so that their weights more nearly 
match that of the input pattern. In this way, neighboring 
points in the input space lead to neighboring points being 
active. Given the winning unit i, the weight update is  
                     wi(new) = wi + hci (x–wi)                       (4) 
                    hci = h0 exp(- ||ri - rc||2/2)                        (5) 
where, hci is called the neighborhood function that has value 
1 for i=c and smaller for large value of the distance between 
units i and c in the output array. h0 and  are suitable 
decreasing functions of time. Units close to the winner as 
well as the winner itself, have their weights updated 
appreciably. Weights associated with far away output nodes 
do not change significantly. It is here that the topological 
information is supplied.  
The Naïve Bayes algorithm is a classification algorithm 
based on Bayes rule and particularly suited when the 
dimensionality of the inputs is high [14]. When the 
dependency relationships among the features used by a 
classifier are unknown, we generally proceed by taking the 
simplest 
assumption, 
namely, 
that 
the 
feature 
are 
conditionally independent given the category, that is, 
 
(6) 
This so-called naïve Bayes rule often works quite well in 
practice, and it can be expressed by a very simple belief net.  
The machine learning algorithms were evaluated by only 
training and the repeated random subsampling validation. 
The former uses the whole emotional patterns in order to 
build a classifier model using machine learning algorithms 
and measure the classification accuracy of those. The 
repeated random subsampling validation is used to consider 
overffiting problem for only trained model. This builds and 
evaluates a classification model using training and testing 
datasets, respectively. The 70% of the whole emotional 
patterns are selected randomly for training and the remaining 
patterns are used for testing purposes. It was repeated 10 
times in this study.  
Table II summarizes the classification results for the only 
training dataset and the repeated random subsampling 
validation (RRSV). The results of RRSV denote the average 
± standard deviation for 10 times. The results of emotion 
classification by only training dataset had range of 43.1% to 
87.2% when all emotions are recognized and in similar 
results, 70% training dataset had range of 43.0% to 87.4%. 
However, in recognition using 30% of datasets for testing, 
accuracy of all emotions had only 32.4% to 46.9% and 
according to orders of Naive Bayes (Kernel Density), LDA, 
CART, and supervised SOMs, recognition rates were 
obtained 46.9%, 44.0%, 42.9% and 35.5%. 
TABLE II.  
CLASSIFICATION RESULTS BY ONLY TRAINING DATASET 
AND THE REPEATED RANDOM SUBSAMPLING VALIDATION (RRSV)  
Methods 
Only TR 
Acc 
RRSV 
TR Acc  
TE Acc 
LDA 
57.3 
58.9±1.7 
44.0±3.7 
CART 
87.2 
87.4±1.9 
42.9±4.2 
SOMs 
Supervised 
43.1 
43.0±1.8 
35.5±4.5 
Unsupervised 
59.5 
60.5±1.6 
32.4±5.5 
Naive 
Bayes 
General 
51.0 
53.7±2.8 
43.7±6.7 
Kernel Density 
80.9 
81.9±2.9 
46.9±4.8 
TR : Training, TE : Testing, Acc : Accuracy (%) 
77
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

TABLE III.  
THE RESULT ON REPEATED ONE-WAY ANOVA TOWARD 
EACH FEATURES 
ANOVA 
SS 
df 
MS 
F 
dNSCR 
100.398 
2 
50.199 
20.886*** 
dmeanSCR 
7.363 
2 
3.681 
6.242** 
dmeanSKT 
94.884 
2 
47.442 
5.827** 
dmaxSKT 
91.563 
2 
45.781 
5.744*** 
FFTap_HF 
2,322.00 
2 
1,161.00 
3.833* 
 p < .05, ** p < .01, *** p < .001 
 
 
 
 
 
Figure 3.  
The results of LSD post-hoc test (*p<.05, **p<.01, **p<.001) 
IV. 
 CONCLUSION 
The aim of this study was to classify three negative 
emotions, fear, surprise, and stress from physiological signals. 
We performed each classifier by 10 fold cross-validation for 
solution of the overfitting problem and divided the dataset 
into 70% training and 30% testing subsets for testing 
purposes. We compared this result with the previous result by 
the only training dataset and our results found no significant 
differences between the accuracies by the training datasets. 
However, recognition results by 30% of datasets for testing 
were lower than that of training dataset and had range of 
32.4% to 46.9%. This means that consequently the selected 
physiological features didn't contribute to classify the three 
negative emotions. Also, these findings suggest that the given 
dataset by physiological signals has high nonlinear 
characteristic and reflects the individual variability of 
physiological property in emotions. The more or less unique 
and person-independent physiological response among these 
emotions may fall off the recognition rate with the number of 
emotion categories [17].  
The values of testing performance are good indicators of 
the generalization capabilities of the constructed models. As 
selecting a model, if the approximation capability of a trained 
model is considered only, the selected model has great 
recognition 
accuracy; 
however, 
it 
has 
deteriorated 
generalization (prediction) capability and cannot apply to a 
real system. Especially, this is conspicuous in nonlinear 
problem. This important question arises, too, as to the 
selection of the proper structure of the emotion recognition in 
this study. To overcome these limitation, additional works for 
the verification of our dataset’s statistical distribution and for 
performance of features’ normalization those might be able to 
reduce large variability should be conducted. Also, for 
improvement of emotion classification, we have already 
selected the meaningful features, such as NSCR, SCR, and 
SKT, which are significantly different among emotions by 
statistical analysis shown in the Table III and Figure 3 [9]. In 
the follow-up work, we intend to improve recognition 
accuracy by applying these features in our classifiers. 
ACKNOWLEDGMENT 
This research was supported by the Converging Research 
Center Program funded by the Ministry of Education, Science 
and Technology (No. 2012K001330 & 2012K001339). 
REFERENCES 
[1] 
J. Wagner, J. Kim, and E. Andre, “From physiological signals to 
emotions: Implementing and comparing selected methods for feature 
extraction and classification,” IEEE International Conference on 
Multimedia and Expo., vol. 7,  2005,  pp. 940-943. 
[2] 
P. D. Drummond, and S.-H. Quah, “The effect of expressing anger on 
cardiovascular reactivity and facial blood flow in Chinese and 
Caucasians,” Psychophysiology, vol. 38. 2001, pp.190-196. 
[3] 
R. W. Picard, E. Vyzas, and J. Healey, “Toward machine emotional 
intelligence: Analysis of affective physiological state,” IEEE Transaction on 
Pattern Analysis and Machine Intelligence, vol. 23, 2001, pp. 1175-1191. 
[4] 
R. Cowie, E. Douglas-Cowie, N.  Tsapatsoulis, G. Votsis, S. Kollias, W. 
Fellenz, J. G. Taylor, “Emotion recognition in human computer 
interaction,” IEEE Signal Processing Magazine, vol. 18, 2001, pp. 32-80. 
[5] 
A. Haag, S. Goronzy, P. Schaich, J. Williams, “Emotion recognition using 
bio-sensors: First steps towards an automatic system,” Affective Dialogue 
Systems, vol. 3068, 2004, pp. 36-48. 
[6] 
J. A. Healey, Wearable and automotive systems for affect recognition 
from physiology, Doctor of Philosophy, Massachusetts Institute of 
Technology, Cambridge, MA., 2000. 
[7] 
F. Nasoz, K. Alvarez, C. L. Lisetti, N. Finkelstein, “Emotion recognition 
from physiological signals for user modelling of affect,” International 
Journal of Cognition, Technology and Work-Special Issue on Presence, 
vol. 6, 2003, pp. 1-8. 
[8] 
R. Calvo, I. Brown, S. Scheding, “Effect of experimental factors on the 
recognition of affective mental states through physiological measures,” AI 
2009: Advances in Artificial Intelligence, vol. 5866, 2009, pp. 62-70. 
[9] 
E.H. Jang, B.J. Park, S.H. Kim, C. Huh, Y. Eum, J.H. Sohn, “Emotion 
Recognition Through ANS Responses Evoked by Negative Emotions,” 
ACHI 2012 : The Fifth International Conference on Advances in 
Computer-Human Interactions, 2012, pp. 218-223. 
[10] J.J. Gross, and R.W. Levenson, “Emotion elicitation using films,” 
Cognition and Emotion, vol. 9, 1995, pp. 87-108. 
[11] R.S. Lazarus, J.C. Speisman, A.M. Mordkoff, and L.A. Davidson, “A 
Laboratory study of psychological stress produced by an emotion picture 
film,” Psychological Monographs, vol. 76, 1962, pp. 553. 
[12] M.H. Davis, J.G. Hull, R.D. Young, and G.G. Warren, “Emotional 
reactions to dramatic film stimuli: the influence of cognitive and 
emotional empathy,” Journal of personality and social psychology, vol. 52, 
1987, pp. 126-133. 
[13] D. Palomba, M. Sarlo, A. Angrilli, A. Mini, and L. Stegagno, “Cardiac 
responses associated with affective processing of unpleasant film stimuli,” 
International Journal of Psychophysiology, vol. 36, 2000, pp. 45-57. 
[14] R. O. Duda, P. E. Hart, and D. G.  Stork, Pattern Classification, 2nd edn. 
2000. 
[15] L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone, Classification 
and Regression Trees,  Monterey, Calif., U.S.A.: Wadsworth, Inc., 1984. 
[16] T. Kohonen, Self-Organizing Maps, Springer Series in Information 
Sciences, Vol. 30, Springer, Berlin, Heidelberg, New York, Third 
Extended Edition, 2001. 
[17] K. H. Kim, S. W. Bang, S. R. Kim, “Emotion recognition system using 
short-term monitoring of physiological signals,” Medical & Biological 
Engineering & Computing, vol. 42, 2004, pp.419-427. 
78
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-269-1
INTELLI 2013 : The Second International Conference on Intelligent Systems and Applications

