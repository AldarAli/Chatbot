Selecting Adequate Aerial Perceptual Functions with Fuzzy Logic 
 
Christian Hellert and Peter Stütz 
Institute of Flight Systems 
University of the Bundeswehr Munich 
Neubiberg, Germany 
e-mail: [christian.hellert,peter.stuetz]@unibw.de 
 
Abstract—The increasing interest in higher automation of 
unmanned aerial vehicles (UAV) rises the challenge of 
implementing sophisticated perception functions. Since 
such functions, whether being used for navigational (e.g., 
sense & avoid) or surveillance purposes (e.g., object 
detection & tracking), are heavily influenced by 
environmental conditions. Hence, a careful selection and 
parametrization of the perception functions during flight 
is required to maintain perceptual efficiency on-board 
the UAV. This paper introduces a method to predict the 
performance of perception functions, allowing a ranking 
for algorithm selection. The proposed method uses 
expert knowledge to model the influence of the 
environment on the perception functions using fuzzy 
logic. An evaluation of the proposed method is 
performed with an aerial vehicle detection algorithm on 
an imagery dataset, generated from virtual simulation, 
taking into account fog density and cloud cover. The 
results show that the method can predict the algorithms 
performance in general and has the advantage of 
expressive modelling of the expert knowledge. 
Keywords-Perception functions; fuzzy logic; algorithm 
selection; algorithm ranking; expert knowledge. 
I. 
 INTRODUCTION 
The automation of unmanned aerial vehicle (UAV) 
navigation and guidance is an active research area. Further, 
the on-board analysis of mission sensor data is needed for 
environmental 
awareness 
and 
reconnaissance 
and 
surveillance missions. The anticipated benefit of higher 
levels of automation of UAVs is seen by reducing costs, 
being able to control multiple UAVs by a single operator, 
and deploying UAVs in areas where no infrastructure for 
communication and navigation is available. 
Mature data processing algorithms for UAV mission 
sensors are designed for specific use cases, for example often 
in the domain of object detection and tracking. Therefore, the 
algorithms regularly produce reliable results only under 
certain constraints. However, during UAV missions, the 
environment can change considerable for example in terms 
of ground surfaces, field of view, lighting conditions and 
atmospheric effects, influencing the sensor data quality, as 
well as the performance of data processing algorithms.  
Hence, a management of sensors and sensor data processing 
algorithms is advisable to assure the quality of the automated 
sensor data evaluation in the aforementioned application 
domains. 
For this purpose, a respective system concept was 
introduced in [1], namely the Sensor & Perception 
Management System (SPMS). Thereby, the SPMS selects 
appropriate sensor types, e.g., electro-optical (EO), infrared 
(IR), and light detection and ranging (LIDAR), and applies 
adequate sensor data processing algorithms to accomplish 
certain perception tasks, such as object detection, tracking, 
and obstacle recognition. Selecting and parametrizing 
perceptual 
capabilities 
according 
to 
the 
current 
environmental situation eventually results in maintaining 
algorithm performance. 
We developed a method to predict the quality or 
performance of such perceptual capabilities of the SPMS, 
allowing the ranking and selection of the best suited 
algorithms. In Section II, the related work is briefly shown 
and Section III presents an algorithm selection method using 
a weighting function based on fuzzy logic and compares its 
performance prediction for a selected vehicle detection 
algorithm with ground-truth obtained from an evaluation 
dataset. The results of our method are presented and 
discussed in Section IV. Section V closes the paper with a 
conclusion and future work. 
II. 
RELATED WORK 
Rice [2] formulated a general concept for the problem of 
selecting an algorithm from a set of algorithms. Using a case 
base, which contains cases from learning or observing 
successful executed tasks with their solution, is as a general 
methodology for algorithm selection and was proposed by 
[3]. A similarity measurement [4] compares the new task 
with the case base using the tasks problem description to 
select the appropriate solution. 
Hochgeschwender et al. [5] addressed the problem of 
selecting marker detection algorithms, based on image 
interest point detection, under different illuminations in an 
indoor scenario to maximize detection performance. During 
a training phase, the performance of the algorithms is 
evaluated and image histograms, as well as respective 
algorithm parameters, are stored whenever the performance 
seems reasonable. The selection algorithm uses the 
Kullback-Leibler divergence as measurement to compare the 
current image histogram with the saved ones to rank the 
algorithms. 
8
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-520-3
VISUAL 2016 : The First International Conference on Applications and Systems of Visual Paradigms

An automatic selection approach for color constancy 
algorithms is proposed in [6]. They extract simple features 
from images and using a Mamdani-type fuzzy inference 
system to reason about the appropriate algorithm. Thereby, 
the fuzzy rules and sets are learned from example. 
In [7], an approach for selecting sensor processing 
algorithms with Bayesian networks is proposed. Here, the 
environmental and sensor requirements of the algorithms, as 
well as their implementation quality, is modelled to estimate 
the performance of the algorithms.  
A meta-learning approach is used by [8][9] for ranking 
the algorithms with a relative score, in respect of the 
algorithm with the highest score. They extract meta-features 
(e.g., mean illumination or noise-signal ratio of an imagery 
dataset) and evaluate the performance of the algorithms from 
the learning datasets. Afterwards, a meta-learner uses the 
performance and meta-features to derive a model, enabling 
the computing of relative performances of the algorithms on 
a new dataset. This method allows the automatic learning of 
an algorithm selection mechanism without the need for 
explicit expert knowledge as required in the here presented 
method. However, a sophisticated learning dataset must be 
provided to achieve reliable results. 
Other approaches [10]–[12] also model the algorithms 
constraints with expert knowledge and apply machine 
inferencing about the availability of the algorithms [13]. Our 
approach now uses the idea of modelling the environmental 
impact with probabilities [7], since they can be considered as 
not completely observable. It is realized with fuzzy logic 
where expert knowledge is mapped to fuzzy rules. The 
notation and concept introduced by [2] is used in this paper. 
III. 
METHOD 
The selection of an algorithm requires a ranking metric. 
In the proposed method, a weighting function predicts the 
performance of the algorithm with respect to a given 
perceptive task (e.g., vehicle detection), in dependency of a 
feature vector describing the actual environment state. The 
weighting function returns a normalized value, describing 
how successful a certain algorithm can be applied. Fig. 1 
shows an overview of the proposed algorithm selection 
method. The selection function takes the algorithm set and 
the environment state vector to choose an algorithm with a 
parameter set, in dependency of the calculated performance. 
Expert knowledge declare the impact of the environment 
state vector on the algorithms performance. 
The algorithm selection s  requires features 
xf
 to 
compute the performance of the algorithms in a set A, where 
each algorithm 
ai ∈ A
 has parameter sets 
i
j
p ∈a
. The 
following formula expresses the algorithm selection 
function:  
 
(
)
(
A)
s f
p
a
x
j
i
,
=
 
(1) 
with x  denoting a candidate from the problem space and 
{
1}
0
,
,
−
=
K
x
x
x
f

 the extracted features. K  is the number 
of feature elements. The weighting function w  computes the 
Expert Knowledge
Algorithm Set
A
Environment
Algorithm Selection
s(fx , A)
fx
A
ai(pj)
 
Figure 1.  Algorithm selection method using expert knowledge to predict 
the algorithms performance. 
predicted performance for one specific algorithm within one 
specific parameter set. The maximum performance of an 
algorithm 
ia considering its parameter sets results from 
 
(
) (
)
(
i p )
i p
x
p a
q a
a
f
w
i
,
, ,
max
⋅
∈
 
(2) 
where the variable q  states the quality, or general 
usability, of the algorithm for a given parameter set. For 
example, the quality of an object detection algorithm can be 
measured by its average precision. 
In [1][14] the concept for sensor and perception 
management (SPM) was introduced, presenting the idea of 
having a set of dedicated perception chains, each being a 
combination of several algorithms 
ia  to fulfill a specific 
perception task. An example perception chain could consist 
of a segmentation stage, followed by interest point detection 
and eventually a classification algorithm. This work is part 
of such SPM concept and therefore the equation (2) extends 
to 
 
(
) (
)
(
) N
q a
a
w f
i p
i p
x
p a
c
a
i
m
i
1
,
,
,
max








⋅
∈
∈∑
 
(3) 
where 
cm ∈C
 is a perception chain containing 
algorithms 
ia  from A . 
{
M }
m
o
c
c
c
C
,
,
,
,


=
 comprises 
all perception chains designed for a perception task and N is 
the number of algorithms in 
cm
. The selection function 
calculates the perception chain performance, using equation 
(3), and returns the perception chain with the highest 
performance, including the related parameter sets. 
The computation of the algorithms performance within the 
weighting function requires a method to compute the impact 
of the feature vector 
xf
 on the algorithm’s 
p
ia ,  
performance. A classical assessment of the impact of the 
feature vector from examples would require a large dataset 
with aerial imagery, however existing ones [15]–[17] are 
lacking the necessary environmental variations. As an 
alternative approach, here, experts assess the impact of  
9
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-520-3
VISUAL 2016 : The First International Conference on Applications and Systems of Visual Paradigms

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2.  Example images from the dataset: In the first row, the cloud cover increases from the left to right. The illumination decrease slightly and the 
shadows are more blurred while the cloud cover increases. In the second row, the fog density increases from left to right and the contrast declines.
0
0.2
0.4
0.6
0.8
1
input variable "cloud cover" x
0  in %
0
0.5
1
µ(x 0 ) in %
barely
partly
heavy
0
0.2
0.4
0.6
0.8
1
output variable "performance" p in %
0
0.5
1
µ(p) in %
very low
low
average
high
very high
 
Figure 3.  Fuzzy membership functions of cloud cover and performance 
variable: The y-axis denotes the degree of membership. Note that cloud 
cover and fog density are modelled equally. 
environmental 
features 
from 
their 
experience 
and 
knowledge. Here, the notation of if-then fuzzy logic rules 
were chosen, because it is human understandable and 
machine-processible. In addition, since the environment is 
not completely observable, the if-then fuzzy logic rule 
notation is capable of modelling vague knowledge. Such 
fuzzy inference system requires the fuzzification of the input 
values from the feature vector by membership functions. 
In a given toy problem, two input variables were selected 
for describing ambient environmental features, the cloud 
cover 
xf
x ∈
0
 and the fog density 
xf
x ∈
1
, since they affect 
illumination, shadow intensity and significance of gradients 
in images. For illustration, Fig. 2 shows the cloud cover 
input and the performance output value with their 
membership functions. 
The fuzzy rules activate the related membership function, 
whereby the input value of 
x0
, e.g., the cloud cover 
measurement, determines the membership degree 
(
µ x0 )
. 
For example, the rule “if cloud cover is heavy then 
performance is average” activates the cloud cover 
membership function “heavy”, for 
8.0
x0 =
 resulting  in 
(
)
5.0
µ x0 =
. 
Afterwards, 
the 
membership 
function 
“average” of the output variable performance receives the 
same degree of membership. A deffuzification step computes 
the center of the area under the “average” curve, cut off by 
the degree of membership line. For multiple input values, the 
center of the union of the areas is calculated to obtain the 
performance value. This work uses the Mamdani-type fuzzy 
inference [18], because of its expressional power which 
allows a clean modelling of expert knowledge as examined 
by [19]. 
IV. 
EVALUATION AND DISCUSSION 
On the basis of an aerial vehicle detection algorithm, 
developed by [20], an evaluation of the proposed method is 
performed. The vehicle detection algorithm uses weak 
classifiers in a cascade to detect vehicles with Haar-like 
image features and local binary pattern features. The 
variables describing the environment are the cloud cover and 
fog density of the scene as mentioned above. First, the 
average performance of the algorithm is determined with a 
ground-truth 
evaluation 
dataset 
obtained 
in 
virtual 
simulation, using Virtual Battlespace 3 (VBS3) [21]. The 
average performance is then compared with the output of the 
modelled fuzzy inference system to evaluate the precision of 
the weighting function. 
The dataset includes 22 scenarios from one VBS3 map 
with fixed cloud cover and fog density values from zero to 
one, where zero defines clear sky or no fog and one defines 
full cloud cover or dense fog. Fig. 3 shows some example 
images form the dataset. Each scenario consists of 7500 
images in 1920x1080 resolution with annotations of the 
vehicle locations. The parameters for the image generation 
are 50 meter distance from camera to the center of the image 
and an elevation of -45 degrees. These parameters where 
selected from the evaluation of the algorithm in [20], where 
the average performance has the highest score. The image 
generation process scans the scenarios in a grid with 
randomly selected azimuth angles and each vehicle from 
azimuth angles ranging from zero to 360 degrees. The 
vehicles, 50 per scenario, are randomly placed on the map. 
The vehicle detection algorithm is tested on each scenario to 
calculate a receiver operating characteristic (ROC) curve to 
determine 
the 
algorithm’s 
average 
performance, 
in 
dependency of the cloud cover and fog density value 
separately. 
10
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-520-3
VISUAL 2016 : The First International Conference on Applications and Systems of Visual Paradigms

The resulting ROC curves from the scenarios are shown 
in Fig. 4, where the area under the curve is the measurement 
for the average performance of the vehicle detection 
algorithm on the related scenario, and the circles mark the 
optimal operation point for the classifier. The upper plot in 
Fig. 4 shows the ROC curves for cloud cover and the one 
below for influences of the fog density. The scenarios to 
evaluate the cloud cover impact have zero fog density and 
the scenarios for evaluating the fog density impact have 50 
percent cloud cover. 
The fuzzy inference system calculates the prediction of 
the algorithm performance using as input the cloud cover and 
fog density and as output the performance. In Fig. 2 the 
0
0.2
0.4
0.6
0.8
1
False positive rate
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
True positive rate
cloud cover:0.0
cloud cover:0.1
cloud cover:0.2
cloud cover:0.3
cloud cover:0.4
cloud cover:0.5
cloud cover:0.6
cloud cover:0.7
cloud cover:0.8
cloud cover:0.9
cloud cover:1.0
 
0
0.2
0.4
0.6
0.8
1
False positive rate
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
True positive rate
fog density:0.0
fog density:0.1
fog density:0.2
fog density:0.3
fog density:0.4
fog density:0.5
fog density:0.6
fog density:0.7
fog density:0.8
fog density:0.9
fog density:1.0
 
Figure 4.  ROC curves of the vehicle detection algorithm for each 
scenario. 
membership functions for the fuzzy variables are shown. The 
fuzzy rules can be read as follows: 
• 
If fog density is hardly and cloud cover is barely 
then performance is high 
• 
If fog density is hardly and cloud cover is partly then 
performance is high 
• 
If fog density is hardly and cloud cover is heavy then 
performance is very high 
• 
If fog density is moderate and cloud cover is barely 
then performance is high 
• 
If fog density is dense and cloud cover is barely then 
performance is average 
With increasing cloud cover, the average performance of 
the algorithm increases from 62 to 71 percent as depicted in 
the upper graph of Fig. 5. While the cloud cover increases, 
the appearance of shadows and the illumination decreases. 
Therefore, the algorithm is obviously robust against 
illumination changes and shadows. The error between the 
calculated performance and the predicted performance is 7.6 
percent. In the upper graph of Fig. 5 the error is the 
highlighted area between performance and prediction curve. 
0
0.2
0.4
0.6
0.8
1
input value cloud cover in %
0.5
0.6
0.7
0.8
0.9
1
performance in %
performance
prediciton
error
 
0
0.2
0.4
0.6
0.8
1
input value fog density in %
0.5
0.6
0.7
0.8
0.9
1
performance in %
performance
prediciton
error
 
Figure 5.  Comparison between evaluated (solid line) and predicted 
(dashed line) algorithm performance for cloud cover and fog density. 
In general, with increasing fog density the average 
performance decreases, while the image is blurred, reducing 
the significance of the edges in the image. First, the average 
performance increases from 62 to 74 percent and then drops 
11
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-520-3
VISUAL 2016 : The First International Conference on Applications and Systems of Visual Paradigms

to 59 percent. Comparing the calculated performance with 
the predicted performance results in an error of 0.3 percent 
(see lower graph of Fig. 5). 
It can be observed, that the proposed method can in 
general describe the trend of environmental impact on the 
algorithm and is therefore useful for predicting the 
performance of the algorithm. The advantage of the proposed 
method is the clear description of the environmental 
influence, with fuzzy rules from expert knowledge, but the 
disadvantage is the lack in accuracy between the calculated 
and predicted performance. The introduction of a greater set 
of membership functions for the fuzzy variables can increase 
the accuracy, but it also increases the modelling effort and 
therefore, detailed expert knowledge is required, but it is 
unlikely that such detailed knowledge is available. Thus, we 
recommend a clear set of membership functions. 
V. 
CONCLUSION 
The management of perceptual capabilities requires the 
estimation of the performance of the underlying algorithms 
in dependency of the environmental state. In this paper, such 
performance prediction was demonstrated using a fuzzy 
logic approach. The results show, that it is possible to model 
the general influence of the environment state at the 
algorithm performance. 
In [6] image features where used to select the best 
algorithm via learning of an fuzzy inference system. In 
contrast to our approach, the image data must be available to 
select the algorithm, while our method can predict the 
algorithm performance without image data. Tenorth and 
Beetz [11] use expert knowledge to reason about the 
appropriate vision algorithm for a personal robot. Unlike our 
approach, 
they 
require 
detailed 
expert 
knowledge. 
Comparing our method with [5], the modelling of the 
environmental influences takes less effort, but the 
performance prediction accuracy is lower. In addition, when 
expert knowledge is not available, our method cannot be 
used. Therefore, in a next step, the missing expert knowledge 
shall be obtained by machine learning approaches to shape 
the membership function and generate fuzzy rules to enhance 
the performance prediction accuracy. For future evaluation, a 
larger scaled dataset will be generated to test learning 
approaches as well as suitable methods to determine the 
environmental state vector. 
REFERENCES 
 
[1] 
M. Russ and P. Stütz, “Airborne sensor and perception 
management: A conceptual approach for surveillance UAS,” 
in Proceedings of the 15th International Conference on 
Information Fusion (FUSION2012), pp. 2444–2451, 2012. 
[2] 
J. R. Rice, “The Algorithm Selection Problem,” Adv. 
Comput., vol. 15, no. C, pp. 65–118, 1976. 
[3] 
A. 
Aamodt 
and 
E. 
Plaza, 
“Case-based 
reasoning: 
Foundational issues, methodological variations, and system 
approaches,” AI Commun., vol. 7, no. 1, pp. 39–59, 1994. 
[4] 
P. Cunningham, “A Taxonomy of Similarity Mechanisms for 
Case-Based Reasoning,” IEEE Trans. Knowl. Data Eng., 
vol. 21, no. 11, pp. 1532–1543, Nov. 2009. 
[5] 
N. Hochgeschwender, M. A. Olivares-Mendez, H. Voos, and 
G. K. Kraetzschmar, “Context-based selection and execution 
of robot perception graphs,” IEEE Int. Conf. Emerg. Technol. 
Fact. Autom. ETFA, pp. 1–4, 2015. 
[6] 
J. Cepeda-Negrete and R. E. Sanchez-Yanez, “Automatic 
selection of color constancy algorithms for dark image 
enhancement by fuzzy rule-based reasoning,” Appl. Soft 
Comput. J., vol. 28, pp. 1–10, 2015. 
[7] 
M. Russ and P. Stuetz, “Application of a probabilistic 
market-based approach in UAV sensor & perception 
management,” in Information Fusion (FUSION), 2013 16th 
International Conference on, pp. 676–683, 2013. 
[8] 
Q. Sun and B. Pfahringer, “Pairwise meta-rules for better 
meta-learning-based algorithm ranking,” Mach. Learn., vol. 
93, no. 1, pp. 141–161, 2013. 
[9] 
K. A. Smith-Miles, “Cross-disciplinary perspectives on 
meta-learning for algorithm selection,” ACM Comput. Surv., 
vol. 41, no. 1, pp. 1–25, 2008. 
[10] G. H. Lim, S. Member, I. H. Suh, S. Member, and H. Suh, 
“Ontology-Based Unified Robot Knowledge for Service 
Robots in Indoor Environments,” Syst. Man Cybern. Part A 
Syst. Humans, IEEE Trans., vol. 41, no. 3, pp. 492–509, 
2011. 
[11] M. Tenorth and M. Beetz, “KnowRob: A knowledge 
processing infrastructure for cognition-enabled robots,” Int. 
J. Rob. Res., vol. 32, no. 5, pp. 566–590, 2013. 
[12] M. 
Tenorth 
and 
M. 
Beetz, 
“KnowRob—knowledge 
processing for autonomous personal robots,” IEEE/RSJ Int. 
Conf. Intell. Robot. Syst. 2009 (IROS 2009), pp. 4261–4266, 
2009. 
[13] M. Gomez et al., “An ontology-centric approach to sensor-
mission assignment,” Knowl. Eng. Pract. Patterns, pp. 347–
363, 2008. 
[14] C. Hellert, D. Smirnov, M. Russ, and P. Stuetz, “A High 
Level Active Perception Concept For UAV Mission 
Scenarios,” in Deutscher Luft- und Raumfahrtkongress 2012, 
2012. 
[15] S. Razakarivony and F. Jurie, “Vehicle detection in aerial 
imagery : A small target detection benchmark,” J. Vis. 
Commun. Image Represent., vol. 34, pp. 187–203, 2016. 
[16] R. Collins, X. Zhou, and S. K. Teh, “An open source 
tracking testbed and evaluation web site,” IEEE Int. Work. 
Perform. Eval. Track. Surveill., pp. 17–24, 2005. 
[17] F. Tanner et al., “Overhead imagery research data set - An 
annotated data library & tools to aid in the development of 
computer vision algorithms,” Appl. Imag. Pattern Recognit. 
Work. (AIPRW), IEEE, pp. 1–8, 2009. 
[18] E. H. Mamdani and S. Assilian, “An experiment in linguistic 
synthesis with a fuzzy logic controller,” Int. J. Man. Mach. 
Stud., vol. 7, no. 1, pp. 1–13, 1975. 
[19] A. Hamam and N. D. Georganas, “A comparison of 
mamdani and sugeno fuzzy inference systems for evaluating 
the quality of experience of hapto-audio-visual applications,” 
HAVE 2008 - IEEE Int. Work. Haptic Audio Vis. Environ. 
Games Proc., no. October, pp. 87–92, 2008. 
[20] G. Hummel, D. Smirnov, A. Kronenberg, and P. Stütz, 
“Prototyping and training of computer vision algorithms in a 
synthetic UAV mission test bed,” in AIAA SciTech 2014, pp. 
1–10, 2014. 
[21] P. Morrison, “White Paper: VBS2 Release Version 2.0,” 
Nelson Bay, Australia, 2012. 
 
12
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-520-3
VISUAL 2016 : The First International Conference on Applications and Systems of Visual Paradigms

