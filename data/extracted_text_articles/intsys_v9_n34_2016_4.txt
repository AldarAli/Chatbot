265
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
An Approach to Analyzing the Retirement Satisfaction among Men and 
Women Based on Artificial Neural Networks and Decision Trees 
 
Ehsan Ardjmand 
Department of Management, College of Business 
Frostburg State University, Frostburg, USA 
Email: eardjmand@frostburg.edu 
 
Gary R. Weckman, Diana Schwerha 
Department of Industrial and Systems Engineering 
Ohio University 
Athens, Ohio USA 
Email: weckmang@ohio.edu, schwerha@ohio.edu 
Andrew P. Snow 
School of Information and Telecommunication Systems 
Ohio University 
Athens, Ohio USA 
Email: snowa@ohio.edu 
 
 
 
 
 
Abstract— In this article, we will analyze the effect of different 
retirement satisfaction predictors on each other and the 
retirement satisfaction level among men and women. The 
following factors will be used as predicators of retirement 
satisfaction: health; wealth; smoking and drinking habits; 
education; faith; income; impact of health on activities of daily 
living; frequency of activities; and the number of people in a 
household. A set of 858 retired men and 1179 retired women 
from a 2012 Health and Retirement Study database have been 
chosen and analyzed. A neural network was trained for each 
gender in order to predict retirement satisfaction; it also 
generated a decision tree that symbolizes the retirement 
satisfaction and its predictors. The results demonstrate that 
health, age, smoking habits, income, and wealth are the most 
significant predictors for both genders, while for men, 
education also plays an important role in retirement 
satisfaction. 
Keywords- 
Retirement 
Satisfaction; 
Artificial 
Neural 
Networks; Multi-Layer Perceptron; Decision Tree 
I. 
 INTRODUCTION 
This paper investigates the impact that various factors 
collected from a retirement survey and their predictive 
capability on retirement satisfaction through artificial neural 
networks and decision trees. This analysis was first reported 
in [1], and this paper expands on and extends some of those 
preliminary findings. 
As the population of retired people is growing, retirement 
satisfaction has become a significant issue in aging and 
retirement research. It is predicted that around 24 percent of 
the United States' work force in 2018 will be at least 55 years 
old [2]. In addition to positive changes in lifestyle, 
retirement—as a major alteration in life for the elderly—can 
be the source of many negative experiences, such as 
loneliness, anxiety, and sometimes even psychological 
disorders [3].  
There is a large body of research on factors which may 
have an effect on retirement satisfaction—among which 
health and wealth, as the two most important predictors, have 
been shown to have a positive correlation with this kind of 
satisfaction [4-9]. A positive psychological condition is also 
shown to have a positive correlation with retirement 
satisfaction [7].  
Sexuality is also another analyzed factor in literature. 
Although there are many studies focusing only on men or 
women in terms of retirement satisfaction, the studies show 
that there is no significant difference among men and women 
in retirement satisfaction [7, 10-16]. 
Voluntary retirement, engagement in social activities, 
higher educational level, and having a spousal partner also 
can have a positive effect on retirement satisfaction [9, 13, 
16-22].   
Although the retirement satisfaction factors have been 
analyzed extensively in literature, the inter-relational effect 
of these factors remains an unchallenged problem. For 
example, we know that wealth and health have a positive 
correlation with retirement satisfaction [6], but how will a 
high level of wealth and a low level of health affect 
retirement satisfaction simultaneously? Additionally, what 
level of each factor is the threshold at which retirement 
satisfaction may be altered? 
In this paper, using the data of 858 retired men and 1179 
retired women from the 2012 Health and Retirement Study 
database, we predict the retirement satisfaction level as a 
dependent variable and the health, wealth, smoking and 
drinking habits, education, faith, income, impact of health on 
instrumental and regular activities of daily living (ADL)s, 
frequency of activities, and number of people in a household 
as independent variables by using a multi-layer perceptron 
neural network. We then try to illustrate the effect of 
different levels of independent variables on retirement 
satisfaction simultaneously by using a decision tree for both 
men and women.      
In Section II, we explain the method and data we use for 
analysis. In Section III, a discussion on decision trees 
including the TREPAN Software. Section IV continues with 
the retirement satisfaction model followed with Section V 
containing the sensitivity analysis. Sections VI discuss the 
results of analyzing retirement satisfaction as an outcome of 

266
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
predictor variables are presented for both men and women. 
In Section VIi, the overall conclusion is stated. 
II. 
DATA AND METHODOLOGY 
The data for this research came from the 2012 Health 
and Retirement Study (HRS), which was launched in 1992. 
A. Health and Retirement Study 
The data for this research came from the 2012 Health and 
Retirement Study (HRS), which was launched in 1992. The 
total number of randomly considered retired people chosen 
from HRS for this study was 2037, which consisted of 858 
men and 1179 women. Notice that only the respondents with 
no missing values in both dependent and independent 
variables were considered in this study. 
The dependent variable is considered to be retirement 
satisfaction. If a person is reported to be retired in 2012 
he/she is asked the G136 question, “All in all, would you say 
that your retirement has turned out to be very satisfying, 
moderately satisfying, or not at all satisfying?" The answer 
to this question is supposed to capture the retirement 
satisfaction level for retirees. 
The independent variables in this research are the age (in 
months); years of education; belief in a higher power; self-
report of health (based on a 5-point scale in which 1 shows 
excellent health and 5 shows very poor health); a binary 
variable which shows if the health limits the ability to work 
or not; level of difficulty in pursuing the ADLs (based on a 
6-point scale in which 0 shows no difficulty and 5 shows 
someone is unable to perform ADL); mental health (based on 
a 9-point scale in which 0 is excellent and 8 is very poor); a 
set of binary variables that show if the person has blood 
pressure, diabetes, cancer, lung disease, heart problem and/or 
arthritis; frequency of vigorous, moderate, and light activity; 
a binary variable that shows if the person smokes or not; the 
number of alcoholic drinks consumed per week; wealth; 
income; and the number of people living in a household. 
B. Methodology 
In this research for modeling retirement satisfaction and 
other independent variables, we use a multi-layer feed 
forward neural network. For illustrating this relationship in a 
symbolic structure, we will use a decision tree technique 
proposed by Craven [23]. 
1) Artificial Neural Networks (ANN) 
ANNs are mathematical models that mimic the human 
brain. Besides being considered a “black-box” model, ANNs 
also have the limitation of requiring a large amount of 
training and cross-validation data, i.e., typically three times 
more training samples than network weights [24]. Since their 
resurgence in the 1980s, ANNs have been applied to a 
variety of problem domains such as speech recognition [25] 
and generation [26], symbolic learning [27], robotic design 
[28], medical diagnostics [29], game playing [30], healthcare 
systems [31], stock market [32] and ecological modeling [33, 
34]. Theoretically, it is possible to prove that a three-layered 
NN can estimate the value of a function with desirable 
accuracy [35, 36]. Since the relationship of retirement 
satisfaction and other independent variables is not 
necessarily linear and can be considered highly complex, 
feed forward neural networks can be a useful tool for 
predicting the value of retirement satisfaction.  
There are many types of ANN topologies that have been 
comprehensively documented [37], and they range in their 
use and complexity.  One of the most widely used ANNs is 
the feed forward neural network (FNN) [38]. For example, 
Figure 1 shows the general structure of a FNN. The network 
shown is fully connected, since each layer is connected via 
previous layers. The first hidden layer’s neurons are 
connected to the second hidden layer’s, and the second 
hidden layer’s neurons are connected with all of the output 
layer’s neurons. 
There are two main paradigms of ANN training--
supervised 
and 
unsupervised 
learning. The primary 
difference between the two learning schemes is that in 
supervised learning, known outputs, or--“targets”--are used 
to adjust the network’s weights. In unsupervised learning, 
there is not a known output, and the method functions as a 
clustering algorithm. 
 
 
Figure 1. Feed Forward Neural Network. 
 
III. 
 DECISION TREES AND TREPAN 
One of the main drawbacks of neural networks is the lack 
of explanation capability [39]. In order to represent the 
knowledge about retirement satisfaction learned by a neural 
network, we use decision trees. Decision trees classify data 
through recursive partitioning of the dataset into mutually 
exclusive subsets, which best explain the variation in the 
dependent variable under observation [40, 41]. A decision 
tree model consists of logical tests, which result in possible 
classifying consequences. Decision trees have been used to 
aid decision makers in many real-world problems [42, 43].  
TREPAN is a novel rule-extraction algorithm that utilizes 
the behavior of a trained ANN [44]. Given a trained ANN, 
TREPAN extracts decision trees that provide a close 
approximation to the function represented by the network 
when there are issues of accurately calculating tree 
partitions, which are caused by limited sample sizes.  
TREPAN uses a concept of recursive partitioning similar 
to other decision tree algorithms; however, in contrast to the 
depth-first growth used by other decision tree algorithms, 

267
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
TREPAN expands using the “best first” principle. For 
conventional induction algorithms, the amount of training 
data decreases as a decision tree grows. Thus, there is less 
data at the bottom of the tree able to determine class labels 
accurately (see Figure 2).  
 
 
Figure 2. Determination of class labels as decision tree grows 
 
In contrast, TREPAN uses an “oracle” to answer queries 
that determine decision tree splits better when sample 
instances are limited as shown in Figure 3. One important 
aspect of this feature is the user-determined parameter called 
minimum sample. TREPAN ensures that splits are 
determined with a minimum number of sample instances. If 
the number of instances at a particular node, m, is less than 
the minimum sample allowed, TREPAN will make 
membership queries equal to the minimum sample from the 
ANN oracle in order to artificially create sample instances to 
meet the minimum sample requirement.  
 
 
Figure 3. TREPAN Oracle 
 
TREPAN uses an entropy-based criterion called 
“information gain” to determine the best position in which to 
partition the dataset. TREPAN uses M-of-N expressions as it 
splits upon the dataset. In this case, N rules are created. The 
algorithm also determines a value for M, which represents 
the minimum conditions that must be met, which in turn 
dictates the preceding node or final classification. This 
approach allows multiple features to be present in one node. 
To prevent testing of all the possible M-of-N combinations, 
TREPAN makes use of the heuristic “beam search” process. 
This process begins by selecting the best binary split at a 
given node based upon information gain. Additional splitting 
conditions are determined based on the initial rule’s 
“complement” [48]. 
When sample instances are sparse, TREPAN interacts 
with an ANN oracle by means of membership queries. The 
goal of a membership query is to determine a new instance 
among a group of instances. To create appropriate sample 
instances, distributions of attribute values are created that 
conform to the decision tree constraints [45]. Once the 
ranges are determined, random pulls are made from the 
attributes’ distribution in order for the oracle to accurately 
estimate the classification output label. 
Stopping criteria TREPAN uses a ‘local stopping criteria’ 
while the tree is being grown. A node’s ‘impurity’ is 
calculated based off the training samples available. Based on 
the characteristic of a node being evaluated, the local 
stopping criteria will determine if a node is acceptable to 
grow further, or if it should be terminated. TREPAN also 
uses a ‘global stopping criteria’. Unlike the local criterion 
that evaluates terminal nodes during induction, the global 
stopping criterion considers the entire tree’s size. Before 
induction, users determine a maximum tree size, which 
enables users to make trade-offs between the size and 
comprehensibility. Thus, if the maximum tree size is 
reached, the tree forming induction algorithm is finalized.  
Pruning After the decision tree is fully grown, a ‘naïve 
pruning’ process is implemented. This process aims to detect 
sub-trees that have similar predicting accuracies for class-
instances found in terminal nodes. The pruning process is 
performed using a recursive, post-order traversal of the tree, 
to simplify the final tree. The changes made to the tree 
during this process do not affect the predictive power of the 
decision tree because nodes or sub trees that do not 
contribute to the overall efficiency are removed or reduced. 
Thus, the goal of this operation is to reduce the size of the 
tree by replacing portions of the tree’s splits with a single 
terminal node that is able to obtain the same level of 
accuracy of the full tree. 
In addition to TREPAN algorithm Craven has also 
developed two of its important variations which are 
investigated further in this article. The single test TREPAN 
algorithm is similar to TREPAN in all respects except that as 
its name suggests it uses single feature tests at the internal 
nodes. Disjunctive TREPAN uses disjunctive “OR” tests at 
the internal nodes of the tree instead of the m-of-n tests.  A 
more detailed explanation of the TREPAN algorithm can be 
found in Craven’s dissertation [23]. 
Classification performance metrics assessing classifier 
performance is a very important aspect of comparing 
different classifiers. The classification accuracy or error rate 
is the percentage of correct predictions made by the model, 
which can be represented as a confusion matrix as shown in 
Table I. A confusion matrix is a matrix plot of predicted 
versus actual classes with all correct classifications depicted 
along the diagonal of the matrix. It gives the number of 
correctly classified instances, incorrectly classified instances, 
and overall classification accuracy. Consider a two-class 
(i.e., binary) classification problem where four possible 

268
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
outcomes are obtainable. In this case, true positives (TP), 
true negatives (TN), false positives (FP) and false negatives 
(FN) are all obtainable classifications. Based on these 
possible states, the overall classification accuracy is derived 
from equation (1). 
 

Accuracy (%) = (TP+TN) / (TP+FN+FP+TN) x 100 
 
Table I:  Example of confusion matrix 
Class 
Predicted 
Class 
(Yes) 
Predicted 
Class 
(No) 
Actual class 
(Yes)  
TP 
FN 
Actual class 
(No) 
FP 
TN 
 
IV. 
RETIREMENT SATISFACTION MODEL 
For this study, we train a feed forward neural network 
with two hidden layers. There are 15 processing units in the 
first layer and 10 processing units in the second hidden layer, 
as well as tangent hyperbolic and linear transfer functions for 
the hidden and output layers, respectively, that use back 
propagation algorithms in NeuroSolutions 6.20 software. 
The output of the network, i.e., retirement satisfaction – is a 
continuous number. In order to convert the output of the 
network into the categorical scale of retirement satisfaction, 
we divide the output into three categories of (-∞,1.66], 
(1.66,2.33], and (2.33,+∞], which are equivalent to not 
satisfying, moderately satisfying, and very satisfying. Notice 
that in the data we use the numbers 1, 2, and 3 to represent 
satisfying, moderately satisfying, and very satisfying, 
respectively. 
V. 
SENSITIVITY ANALYSIS 
Another approach used in extracting knowledge from 
ANNs is Sensitivity Analysis, which attempts to model the 
interaction of various input factors [46]. Sensitivity analysis 
is a method used to extract cause and affect relationships 
between input and output variables. A given input is 
increased or decreased in small increments, typically by 
one, two, or three standard deviations, with all other 
variables fixed at their mean values, permitting the 
individual contributions of each variable to be assessed. The 
user can then identify interrelationships between input and 
output variables with this information. 
Sensitivity analysis also provides feedback as to which 
input variables are the most significant relative to other 
input variables. Based on this analysis, insignificant 
variables could be removed from the ANN, which would 
reduce the size, complexity, and training times. However, 
this would remove the impact and relationships that the 
input variable has to the output and other input variables.  
 
VI. 
RESULTS 
The final artificial feed forward neural network models 
had the following performance measurements for both Men 
(see Table II) and Women (see Table III).  The table 
illustrates the model’s ability for the train, cross-validation 
and testing datasets. The various measurements listed are 
root mean square error (RMSE), normalized root mean 
square error (NRMSE), mean absolute error (MAE), min and 
max absolute error (Min Abs Error and Max Abs Error) 
along with the final coefficient of correlation (r).  
 
Table II:  Model for Men Retirement Satisfaction Dataset 
Performance 
Training 
Cross-validation 
Test 
RMSE 
0.5878 
0.6040 
0.3455 
NRMSE 
0.2939 
0.3020 
0.5579 
MAE 
0.4833 
0.4863 
0.4833 
Min Abs Error 
0.0008 
0.0024 
0.0008 
Max Abs Error 
1.9318 
1.7192 
1.9318 
r 
0.6675 
0.5556 
0.6675 
 
Table III:  Model for Women Retirement Satisfaction Dataset 
Performance 
Training 
Cross-validation 
Test 
RMSE 
0.6424 
0.6646 
0.6993 
NRMSE 
0.3212 
0.3323 
0.3497 
MAE 
0.5352 
0.5332 
0.5855 
Min Abs Error 
0.0005 
0.0028 
0.0007 
Max Abs Error 
1.7948 
1.8924 
1.7753 
r 
0.6462 
0.5990 
0.5287 
 
The numerical output from the neural network was 
converted into the categorical scale of retirement satisfaction, 
as mentioned earlier.  The resulting confusion matrices were 
calculated along with their respective overall accuracies for 
the training and test datasets.  Tables IV-VII demonstrates 
the ability of the TREPAN model to predict Retirement 
Satisfaction levels for both Men and Women using the single 
test algorithm. 
 
Table IV:  Men training set output based on single test algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
57 
24 
7 
88 
 
2 
57 
123 
60 
240 
 
3 
10 
34 
142 
186 
 
Total 
124 
181 
209 
514 
*Training Set Correctness: 322/514 = 0.626 
 
Table V:  Men test set output based on single test algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
14 
5 
1 
20 
 
2 
23 
37 
24 
84 
 
3 
5 
11 
52 
68 
 
Total 
42 
53 
77 
172 
*Test Set Correctness: 103/172 = 0.599 

269
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Table VI:  Women training set output based on single test 
algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
153 
32 
20 
205 
 
2 
63 
84 
73 
220 
 
3 
16 
89 
176 
281 
 
Total 
232 
205 
269 
706 
*Training Set Correctness: 413/706 = 0.585 
 
Table VII:  Women test set output based on single test algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
49 
26 
11 
86 
 
2 
30 
36 
39 
105 
 
3 
7 
35 
62 
104 
 
Total 
86 
97 
112 
295 
*Test Set Correctness: 147/295 = 0.498 
 
The decision tree model which created the logical tests 
resulting into the classifications shown in the tables above, 
where displayed as decision tree branches. Figure 4 and 
Figure 5 show the decision tree obtained for men and women 
regarding the relationships of the independent variables and 
retirement satisfaction. Notice that every rectangular shape in 
the decision tree shows a condition that, if met, the right 
branch should be followed. The left branch is for the case in 
which the condition is rejected. The oval shapes show the 
consecutive retirement satisfaction level in each branch. 
As it is depicted in Figures 4 and 5, not all of the 
variables are involved in predicting retirement satisfaction. 
The reason is partially because of the low correlation of 
some independent variables and retirement satisfaction, as 
well as the overwhelming impact of these important 
variables on the latter that makes the other factors neutral. 
Another reason is the structure of the decision tree itself. By 
generating a decision tree, we are trying to extract the 
knowledge of the neural network, and the generated tree is 
formed in a way to represent the most possible knowledge in 
the form of rules according to the neural network, which can 
cause us to ignore some of the inputs. 
In addition, more complex decision trees were created 
using the TREPAN and Disjunctive algorithms in order to 
see if the accuracy could be improved.  Tables VIII-XI and 
Figures 6 and 7 display the capability and results of 
modeling created only for the Men’s retirement satisfaction. 
Notice that the overall accuracies of the various 
algorithms are similar but the Disjunctive algorithm has the 
highest overall test results. However, the disjunctive decision 
tree is a little harder to interpret the results as compared to 
the single test output. 
 
Table VIII:  Men training set output based on TREPAN algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
52 
28 
7 
87 
 
2 
61 
108 
40 
209 
 
3 
11 
45 
162 
218 
 
Total 
124 
181 
209 
514 
*Training Set Correctness: 322/514 = 0.626 
 
Table IX:  Men test set output based on TREPAN algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
18 
6 
3 
27 
 
2 
19 
29 
22 
70 
 
3 
5 
18 
52 
75 
 
Total 
42 
53 
77 
172 
*Test Set Correctness: 99/172 = 0.576 
 
Table X:  Men training set output based on Disjunctive algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
55 
28 
8 
91 
 
2 
61 
116 
53 
230 
 
3 
8 
37 
148 
193 
 
Total 
124 
181 
209 
514 
*Training Set Correctness: 319/514 = 0.621 
 
Table XI:  Men test set output based on Disjunctive algorithm 
 
Target 
1 
2 
3 
Total 
Predicted 
1 
13 
6 
2 
21 
 
2 
25 
34 
13 
72 
 
3 
4 
13 
62 
79 
 
Total 
42 
53 
77 
172 
*Test Set Correctness: 109/172 = 0.634 
 
In addition to the decision trees, sensitivity of the mean 
was performed on both the Men’s and Women’s neural 
network models (see Figure 8 and 9).  The top 4 most 
sensitive variables for Men, as shown in Figure 8, is Mental 
health, Age, Wealth and Years of education.  Whereas, for 
Women, the top 4 most sensitive variables, as shown in 
Figure 9, is Mental health, Self report of health, Age and 
Years of education. 
The sensitivity of a single predictive variable can also be 
displayed as compared to Retirement Satisfaction.  Figure 10 
illustrates the behavior of the predictive variable ‘Mental 
health’ over the range of input values.  Notice that in this 
case, for Men, as their mental health degrades (scale implies 
0 is excellent and 8 is very poor) that the overall Retirement 
Satisfaction will typically drop from an average of 2.5 to 1.5. 
 
 
 
 
Figure 10. Mental health impact on retirement satisfaction for Men  
 
Another illustration of how a predictive variable can impact 
retirement satisfaction is the ‘Age’ of the individual.  Figure 
11 displays the relationship, for Men, between ‘Age’ 

270
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
(months) and ‘Retirement Satisfaction’.  Notice that as the 
age of an individual increases so does retirement satisfaction. 
 
 
 
Figure 11. Age (months) impact on retirement satisfaction for Men 
 
A. Comparison with Literature 
All of the extracted rules in decision trees are consistent 
with the results in literature. Age has a positive correlation 
with retirement satisfaction [3]. This effect can be seen by 
following branches that point to older ages and comparing 
them to the other branches in Figures 4 and 5. High levels of 
mental and physical health correspond to higher retirement 
satisfaction [3, 4, 6-8]. Higher levels of wealth and income 
also correspond to higher retirement satisfaction [3, 5-7]. 
Years of education have a positive correlation with 
retirement satisfaction [20]. 
B. New Findings 
In addition to the result comparisons to previous 
literature, some new patterns can be deduced from the 
decision tree. Compared to women, the years spent in 
education for men is an important factor. In Figure 4, one of 
the parameters that affect the retirement satisfaction in men 
is education level. However, in Figure 5 the education level 
is not a condition in defining the retirement satisfaction, 
which shows that for women, it is not an important 
parameter. 
Since for men the wealth appears in higher levels of the 
decision tree, it follows that, compared to women, wealth for 
men is a more important factor. Following the same logic, 
we can see that compared to men, mental health is a stronger 
predictor for women. In addition, for women with poor 
health, wealth is not a predictor at all. Despite this, for men 
with poor overall health, age cannot predict the retirement 
satisfaction.  
Among all the health conditions analyzed, only diabetes 
plays a significant role in explaining retirement satisfaction. 
In both decision trees, i.e., men’s and women’s – having 
diabetes can cause lower retirement satisfaction, except 
where the income level is rather high. Although poor 
conditions of physical and mental health for both men and 
women can cause low retirement satisfaction, a high amount 
of wealth and income can ameliorate this situation.  
VII. CONCLUSION 
In this paper, using the 2012 data of the Health and 
Retirement Study for 858 retired men and 1179 retired 
women, we trained a feed forward neural network to predict 
the retirement satisfaction, considering health, wealth, 
smoking and drinking habits, education, faith, income, 
impact of health on ADLs, frequency of activities, and the 
number of people in a household as independent variables. 
The knowledge of neural networks was represented in the 
form of a decision tree. 
The results show a very high consistency with previous 
findings in literature. Additionally, some new knowledge 
regarding retirement satisfaction was also revealed in the 
form of rules in the decision tree. It was shown that, 
compared to women, years of education is more important to 
men in regards to retirement satisfaction. Under the 
condition of poor health, age is an important predictor of 
retirement satisfaction for women. Among all the health-
related diseases, diabetes plays the most important role in 
terms of predicting retirement satisfaction. Additionally, a 
poor health condition can be negated by higher income or 
wealth. 
To the best of our knowledge, the use of decision trees in 
retirement satisfaction is introduced for the very first time in 
this article. The results show that this technique can be a very 
powerful method for revealing hidden relationships between 
the various predictors of retirement satisfaction. 
REFERENCES 
[1] 
E. Ardjmand, G. R. Weckman, D. Schwerha, and A. P. 
Snow, "Analyzing the Retirement Satisfaction Predictors 
among Men and Women Using a Multi-Layer Feed 
Forward Neural Network and Decision Trees," ALLDATA 
2016, p. 111, 2016. 
[2] 
D. Schwerha, C. Ritter, S. Robinson, R. W. Griffeth, and D. 
Fried, "Integrating ergonomic factors into the decision to 
retire," Human Resource Management Review, vol. 21, pp. 
220-227, 2011. 
[3] 
F. J. Floyd, S. N. Haynes, E. R. Doll, D. Winemiller, C. 
Lemsky, T. M. Burgy, et al., "Assessing retirement 
satisfaction and perceptions of retirement experiences," 
Psychology and aging, vol. 7, p. 609, 1992. 
[4] 
K. A. Bender, "An analysis of well-being in retirement: 
The role of pensions, health, and ‘voluntariness’ of 
retirement," The Journal of Socio-Economics, vol. 41, pp. 
424-433, 2012. 
[5] 
L. T. Dorfman, "Health conditions and perceived quality of 
life in retirement," Health & Social Work, vol. 20, pp. 192-
199, 1995. 
[6] 
C. W. Panis, "Annuities and retirement well-being," 
Pension design and structure: New lessons from behavioral 
finance, pp. 259-74, 2004. 
[7] 
C. A. Price and S. Balaswamy, "Beyond health and wealth: 
Predictors of women's retirement satisfaction," The 
International Journal of Aging and Human Development, 
vol. 68, pp. 195-214, 2009. 
[8] 
M. Reis and D. P. Gold, "Retirement, personality, and life 
satisfaction: A review and two models," Journal of applied 
Gerontology, vol. 12, pp. 261-282, 1993. 
[9] 
N. Schmitt, J. K. White, B. W. Coyle, and J. 
Rauschenberger, 
"Retirement 
and 
life 
satisfaction," 
Academy of Management Journal, vol. 22, pp. 282-291, 
1979. 

271
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
[10] 
T. M. Calasanti, "Gender and life satisfaction in retirement: 
An assessment of the male model," The Journals of 
Gerontology Series B: Psychological Sciences and Social 
Sciences, vol. 51, pp. S18-S29, 1996. 
[11] 
E. Fouquereau, A. Fernandez, and E. Mullet, "Evaluation 
of determinants of retirement satisfaction among workers 
and retired people," Social Behavior and Personality: an 
international journal, vol. 29, pp. 777-785, 2001. 
[12] 
K. Hanson and S. Wapner, "Transition to retirement: 
Gender differences," The International Journal of Aging 
and Human Development, vol. 39, pp. 189-208, 1994. 
[13] 
C. A. Price and E. Joo, "Exploring the relationship between 
marital status and women's retirement satisfaction," The 
International Journal of Aging and Human Development, 
vol. 61, pp. 37-55, 2005. 
[14] 
K. Seccombe and G. R. Lee, "Gender differences in 
retirement satisfaction and its antecedents," Research on 
Aging, vol. 8, pp. 426-440, 1986. 
[15] 
K. F. Slevin and C. Wingrove, "Women in retirement: A 
review and critique of empirical research since 1976," 
Sociological Inquiry, vol. 65, pp. 1-21, 1995. 
[16] 
M. Szinovacz, "Preferred retirement timing and retirement 
satisfaction in women," The International Journal of Aging 
and Human Development, vol. 24, pp. 301-317, 1987. 
[17] 
E. Bonsang and T. J. Klein, "Retirement and subjective 
well-being," 
Journal 
of 
Economic 
Behavior 
& 
Organization, vol. 83, pp. 311-329, 2012. 
[18] 
B. A. Butrica and S. G. Schaner, "Satisfaction and 
engagement in retirement," 2005. 
[19] 
L. T. Dorfman and M. M. Moffett, "Retirement satisfaction 
in married and widowed rural women," The Gerontologist, 
vol. 27, pp. 215-221, 1987. 
[20] 
E. Fouquereau, A. Fernandez, A. M. Fonseca, M. C. Paul, 
and V. Uotinen, "Perceptions of and satisfaction with 
retirement: a comparison of six European union countries," 
Psychology and Aging, vol. 20, p. 524, 2005. 
[21] 
Y. Kremer, "Predictors of retirement satisfaction: A path 
model," The International Journal of aging and Human 
Development, vol. 20, pp. 113-121, 1985. 
[22] 
C. Kupperbusch, R. W. Levenson, and R. Ebling, 
"Predicting husbands' and wives' retirement satisfaction 
from the emotional qualities of marital interaction," 
Journal of Social and Personal Relationships, vol. 20, pp. 
335-354, 2003. 
[23] 
M. W. Craven, "Extracting comprehensible models from 
trained neural networks," University of Wisconsin–
Madison, 1996. 
[24] 
M. M. Nelson and W. T. Illingworth, A practical guide to 
neural nets vol. 1: Addison-Wesley Reading, MA, 1991. 
[25] 
A. Waibel, "Modular construction of time-delay neural 
networks for speech recognition," Neural computation, vol. 
1, pp. 39-46, 1989. 
[26] 
T. J. Sejnowski and C. R. Rosenberg, NETtalk: A parallel 
network that learns to read aloud: MIT Press, 1988. 
[27] 
J. W. Shavlik, R. J. Mooney, and G. G. Towell, "Symbolic 
and 
neural 
learning 
algorithms: 
An 
experimental 
comparison," Machine learning, vol. 6, pp. 111-143, 1991. 
[28] 
G.-T. Hsu and R. Simmons, "Learning footfall evaluation 
for a walking robot," in Proceedings of the Eigth 
International Workshop on Machine Learning, 2014, pp. 
303-307. 
[29] 
M. Jabri, S. Pickard, P. Leong, Z. Chi, B. Flower, and Y. 
Xie, "ANN based classification for heart defibrillators," 
Advances in neural information processing systems, pp. 
637-637, 1993. 
[30] 
G. Tesauro, "Practical issues in temporal difference 
learning," in Reinforcement Learning, ed: Springer, 1992, 
pp. 33-53. 
[31] 
G. G. Towell and J. W. Shavlik, "Extracting refined rules 
from 
knowledge-based 
neural 
networks," 
Machine 
learning, vol. 13, pp. 71-101, 1993. 
[32] 
G. R. Weckman, R. W. Dravenstott, W. A. Young II, E. 
Ardjmand, D. F. Millie, and A. P. Snow, "A Prescriptive 
Stock Market Investment Strategy for the Restaurant 
Industry using an Artificial Neural Network Methodology," 
International Journal of Business Analytics (IJBAN), vol. 3, 
pp. 1-21, 2016. 
[33] 
D. F. Millie, G. R. Weckman, W. A. Young, J. E. Ivey, D. 
P. Fries, E. Ardjmand, et al., "Coastal ‘Big Data’and 
nature-inspired 
computation: 
Prediction 
potentials, 
uncertainties, and knowledge derivation of neural networks 
for an algal metric," Estuarine, Coastal and Shelf Science, 
vol. 125, pp. 57-67, 2013. 
[34] 
D. F. Millie, G. R. Weckman, G. L. Fahnenstiel, H. J. 
Carrick, E. Ardjmand, W. A. Young, et al., "Using artificial 
intelligence for CyanoHAB niche modeling: discovery and 
visualization of Microcystis–environmental associations 
within western Lake Erie," Canadian Journal of Fisheries 
and Aquatic Sciences, vol. 71, pp. 1642-1654, 2014. 
[35] 
K.-I. Funahashi, "On the approximate realization of 
continuous mappings by neural networks," Neural 
networks, vol. 2, pp. 183-192, 1989. 
[36] 
K. Hornik, M. Stinchcombe, and H. White, "Multilayer 
feedforward networks are universal approximators," Neural 
networks, vol. 2, pp. 359-366, 1989. 
[37] 
S. S. Haykin, Neural Networks: A Comprehensive 
Foundation: Prentice Hall, 1999. 
[38] 
M. Amin-Naseri, E. Ardjmand, and G. Weckman, 
"Training 
the 
feedforward 
neural 
network 
using 
Unconscious search," in Neural Networks (IJCNN), The 
2013 International Joint Conference on, 2013, pp. 1-7. 
[39] 
E. Ardjmand, D. F. Millie, I. Ghalehkhondabi, W. A. 
Young II, and G. R. Weckman, "A State-Based Sensitivity 
Analysis for Distinguishing the Global Importance of 
Predictor Variables in Artificial Neural Networks," 
Advances in Artificial Neural Systems, vol. 2016, 2016. 
[40] 
G. Liepins, R. Goeltz, and R. Rush, "Machine learning 
techniques 
for 
natural-resource 
data-analysis," 
Ai 
Applications in Natural Resource Management, vol. 4, pp. 
9-18, 1990. 
[41] 
D. Biggs, B. De Ville, and E. Suen, "A method of choosing 
multiway partitions for classification and decision trees," 
Journal of Applied Statistics, vol. 18, pp. 49-62, 1991. 
[42] 
W. Leech, "A rule-based process control method with 
feedback," ISA transactions, vol. 26, pp. 73-78, 1986. 
[43] 
P. Langley and H. A. Simon, "Applications of machine 
learning and rule induction," Communications of the ACM, 
vol. 38, pp. 54-64, 1995. 
[44] 
M. Craven and J. W. Shavlik, "Using sampling and queries 
to extract rules from trained neural networks," in ICML, 
1994, pp. 37-45. 
[45] 
K. Krawiec, R. Słowiński, and I. Szcześniak, "Pedagogical 
Method for Extraction of Symbolic Knowledge," in 

272
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
International Conference on Rough Sets and current 
Trends in Computing, 1998, pp. 436-443. 
[46] 
A. Saltelli, S. Tarantola, F. Campolongo, and M. Ratto, 
Sensitivity analysis in practice: a guide to assessing 
scientific models: John Wiley & Sons, 2004. 
 
 
 
 
 
 
 
 
Mental 
Health <= 2
Wealth <= 
129899
Yes
Age <= 966
Health <= 3
High
Med
Low
Smokes?
Med
Income <= 
48554
Med
Age <= 872
Health = 0
Years of Edu. 
<= 13
Med
High
Med
Health <= 3
High
Years of Edu. 
<= 15
Med
High
Wealth <= 
412400
No
Mental 
Health <= 5
Have 
Diabetes?
Med
Wealth <= -
4957
Low
Med
Low
Have 
Diabetes?
Med
Years of Edu. 
<= 16
Med
High
 
 
Figure 4. Decision Tree of Retirement Satisfaction for Men. 
 
 
Health <=3
Mental 
Health <= 2
Yes
Health <=2
High
Age <= 946
Income <= 
32966
Med
Does Health 
Limit Work?
Med
High
Wealth 
<=150073
Smokes?
Med
High
High
Mental 
Health <= 4
Med
Wealth 
<=205500
Mental 
Health <= 6
Med
Low
Med
Mental 
Health <= 3
No
Age <= 958
Health <= 4
Mental 
Health <= 1
Med
Low
Low
Have 
Diabetes?
Mental 
Health <= 1
Income <= 
31523
Med
High
Med
Med
Low
 
 
Figure 5. Decision Tree of Retirement Satisfaction for Women. 

273
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
2 of {Age <= 965.5, 
Wealth <= 129899, 
Mental health > 2.5}
Mental health <= 5.5
Yes
 4 of {Frequency of vigorous activity <= 4.5, 
Difficulty inactivities of daily living <= 1.5, 
Years of education > 12.5, Diabetes (no), 
Smokes now (no), Self report of health <= 3.5}
High
Med
Med
High
3 of {Total household income <= 
37380, Does health limit work (yes), 
Years of education <= 14.5, Self report 
of health > 3.5}
No
3 of {Arthritis (no), Smoked before (yes), 
Psychological problem (yes), No. of people in 
household > 1.5, Diabetes (yes)}
Med
Does health limit work (no)
2 of {Diabetes (no), Frequency of moderate 
activity > 3.5 Frequency of light activity <= 
3.5}
Med
High
Age <= 826.5
Self report of health <= 4.5
1 of {Frequency of moderate activity 
<= 3.5, Faith <= 0.5}
Mental health <= 3.5
2 of {Frequency of light activity <= 3.5, Frequency 
of light activity > 4.5, Does health limit work <= 0.5, 
Total household income > 47788}
3 of {Difficulty in instrumental activities of daily living > 
2.5, Difficulty in instrumental activities of daily living <= 
0.5, Frequency of moderate activity > 3.5, Frequency of 
moderate activity <= 4.5, Cancer <= 0.5}
Low
Low
Med
Med
Low
Med
Low
Med
Med
Age <= 855
Smokes now ?
Age <= 878
Wealth <= 609448.5
High
Med
 
Figure 6. Decision Tree of Retirement Satisfaction for Men (Trepan) 
 
 
1 of {Wealth <= 129899.5, Smokes 
now (yes), Mental health > 2.5}
Mental health <= 5.5
Yes
Age <= 964
Med
1 of {Self report of health <= 2.5, 
Age > 955}
No
1 of {Self report of health > 3.5, 
Diabetes (yes)}
1 of {Frequency of vigorous activity > 3.5, Lung disease (yes)}
1 of {Self report of health > 2.5, 
Frequency of light activity > 4.5}
Low
Low
Med
Med
Low
Med
Does health limit work (no)
Wealth <= 465001
Med
Smokes now (no)
1 of {Does health limit work (no), Faith (no)}
Mental health <= 4.5
1 of {Total household income <= 
38319.7, Years of education <= 11}
Total household income <= 37517.9
Age <= 766
Med
Low
Diabetes (no)
Med
Low
Med
Med
Mental health <= 0.5
High
High
High
High
 
Figure 7. Decision Tree of Retirement Satisfaction for Men (disjunctive) 

274
International Journal on Advances in Intelligent Systems, vol 9 no 3 & 4, year 2016, http://www.iariajournals.org/intelligent_systems/
2016, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
 
 
Figure 8. Sensitivity of input predictors on the Retirement Satisfaction for Men (sorted) 
 
 
 
 
Figure 9. Sensitivity of input predictors on the Retirement Satisfaction for Women (sorted) 

