Weight Difference Propagation for
Stochastic Gradient Descent Learning
Shahrzad Mahboubi,
Hiroshi Ninomiya
Graduate School of Electrical and Information Engineering,
Shonan Institute of Technology
Fujisawa, Kanagawa, Japan
Email : mahboubi.shaa@gmail.com,
ninomiya@info.shonan-it.ac.jp
Abstractâ€”This paper proposes a new stochastic (mini-batch)
training algorithm to reduce the computational and hardware
implementation costs of the error Back Propagation (BP) method.
In recent years, with the rapid development of IoT, there has been
an increasing necessity to use microcomputers, especially edge
computers that implement neural networks capable of training
large-scale data. Since the neural network training is based
on the BP method, the error propagation architecture from
the output to the input layers is required for each training
sample to calculate the gradient. As a result, the hardware
and computational costs are increased. This paper attempts to
improve the BP method by using the inner product of the weights
and their updated amounts (differences) for training reducing
the hardware and computational costs. This method eliminates
the requirement of the BP architecture for each training sample
in mini-batch and calculates the amounts of the weight update
with only one weight difference propagation. This means that
the proposed method can reduce the computational complexity
in the backward calculations of the training to 1/ğ‘ (ğ‘ is the mini-
batch size) compared to BP. Computer simulations demonstrate
the effectiveness of the proposed method.
Index Termsâ€”neural network, gradient-based training algo-
rithm, stochastic gradient descent method, error back propaga-
tion, weight difference propagation
I. INTRODUCTION
With the development of information and communication
technology, various devices have been converted to IoT, mak-
ing it possible to acquire and store diverse and vast amounts
of data. The complexity (nonlinearity) of data and its volume
increase day by day. Developing technologies can process
large-scale nonlinear data with high accuracy and speed. In
recent years, Artiï¬cial Intelligence (AI) has attracted attention
as one of the technologies that make this possible and has been
applied in various ï¬elds, including mechanical engineering,
statistics, physics, economics, cognitive science, and brain
science. The core technology in the rapid development of AI is
neural networks (NNs) [1] [2]. NNs are generally trained using
gradient algorithms based on the error Back Propagation (BP)
method. BP training is an efï¬cient and practical algorithm,
and various improvement methods have been proposed. One
of the improved methods is the Stochastic Gradient Descent
(SGD) method for big data learning [1].
Recently, several training algorithms have been proposed
considering biological plausibility [3]â€“[6]. These researches
began with questions such as, â€œDoes the biological brain per-
form complex and accurate backward calculations like BP?â€
[3] [6] or â€œIs it necessary to calculate the exact gradient used
in training?â€ [4] [5]. Furthermore, a gradient-based training al-
gorithm that does not require the backpropagation of errors has
been proposed [7]â€“[9]. This algorithm can potentially reduce
computational and hardware burdens even when processed
by microcontrollers installed in IoT devices. However, these
algorithms are unsuitable for asynchronous parallel learning or
training large datasets and still need improvement. In addition,
there are preliminary simulation experiments of the proposed
algorithms, and the learning accuracy for recent nonlinear data
is not guaranteed.
In this paper, focusing on the algorithm of [7]â€“[9], a novel
algorithm is proposed to simplify the calculation of the gradi-
ent. The proposed method is referred to as Stochastic Weight
Difference Propagation (SWDP) to improve the disadvantages
of SGD. SWDP differs from the conventional SGD in that the
weights can be updated by only the inner product of the post-
synaptic weights and their differences. This enables parallel
training of each neuron in each layer. Therefore, the backward
process for each training sample in mini-batch (stochastic)
training is unnecessary, and the hardware and computational
cost can be reduced. This means that the proposed method
can reduce the computational complexity in the backward
calculations of the training to 1/ğ‘ (ğ‘ is the mini-batch size)
compared to BP. The proposed method, compared with the
conventional SGD method on two benchmark problems and
simulations, demonstrates its effectiveness.
The paper is organized as follows: Section 2 describes
the training of SGD. In Section 3, the proposed SWDP is
derived and explained. In Section 4, the computational cost
of SGD and SWDP is discussed. Sections 5 and 6 present
computational simulations and conclusions, respectively.
II. STOCHASTIC GRADIENT DESCENT METHOD
This paper considers the multi-layer feed-forward NN train-
ing, which is an unconstrained optimization problem to min-
imize the error function ğ¸(w) concerning the weight vector
w âˆˆ Rğ‘›.
min
wâˆˆRğ‘›
ğ¸(w).
(1)
There are two training methods for error Back Propagation
(BP): batch and stochastic (mini-batch) strategies. All training
samples in a dataset ğ‘‡ğ‘Ÿ are used in an epoch to calculate
12
Copyright (c) IARIA, 2023.     ISBN:  ISBNFILL
ICCGI 2023 : The Eighteenth International Multi-Conference on Computing in the Global Information Technology

Fig. 1. Structural diagram of SGD.
gradients in the batch strategy. The error function ğ¸(w) is
deï¬ned as
ğ¸(w) =
1
|ğ‘‡ğ‘Ÿ |
âˆ‘
ğ‘âˆˆğ‘‡ğ‘Ÿ
ğ¸ ğ‘(w),
(2)
where, |ğ‘‡ğ‘Ÿ | denotes the number of samples, and ğ¸ ğ‘(w) is the
error of the ğ‘th sample. On the other hand, the stochastic
training strategy in BP, so-call Stochastic Gradient Descent
(SGD), uses ğ‘‹ âŠ† ğ‘‡ğ‘Ÿ dataset randomly selected from ğ‘‡ğ‘Ÿ in an
iteration to calculate the gradient. The error function ğ¸ğ‘(w)
of SGD is deï¬ned as
ğ¸ğ‘(w) = 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ¸ ğ‘(w),
(3)
where ğ‘ = |ğ‘‹| is the mini-batch size and if ğ‘‹ = ğ‘‡ğ‘Ÿ and ğ‘ = |ğ‘‡ğ‘Ÿ |
then mini-batch training shifts to the batch mode.
Let xğ‘ and oğ‘ be the ğ‘th input and output vectors, respec-
tively. The relation between the inputs and outputs of the NN
is deï¬ned as
oğ‘ = xout
ğ‘ = fğ‘ ğ‘ (w, xğ‘).
(4)
Moreover, let ğ‘¥ğ‘ 
ğ‘–,ğ‘(1 â‰¤ ğ‘  â‰¤ ğ‘œğ‘¢ğ‘¡) be the output of the ğ‘–th neuron
in the ğ‘  layer for the ğ‘th sample, and ğ‘¤ğ‘ 
ğ‘– ğ‘— be the weight from
the ğ‘—th neuron of the ğ‘  âˆ’ 1 layer to the ğ‘–th neuron of the ğ‘ 
layer, the input-output relationship of the neuron is given by
(5) and (6). Note that ğ‘  = out denotes the output layer.
ğ‘¥ğ‘ 
ğ‘–,ğ‘ = ğ‘“ (ğ‘§ğ‘ 
ğ‘–,ğ‘),
(5)
ğ‘§ğ‘ 
ğ‘–,ğ‘ =
âˆ‘
ğ‘—
ğ‘¤ğ‘ 
ğ‘– ğ‘— Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ ,
(6)
where ğ‘“ (ğ‘§ğ‘ 
ğ‘–,ğ‘) and ğ‘¤ğ‘ 
ğ‘– ğ‘— denote the activation function and a
component of the weight vector w, respectively. The update
formula of SGD is deï¬ned as (7) using learning rate ğœ‚.
ğ‘¤ğ‘ 
ğ‘– ğ‘— (ğ‘¡ + 1) = ğ‘¤ğ‘ 
ğ‘– ğ‘— (ğ‘¡) âˆ’ ğœ‚ ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
.
(7)
where ğ‘¡ denotes the iteration number and
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
,
(8)
is the stochastic gradient, which is expansion by chain rule as
(9).
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â·
ğœ•ğ‘¥ğ‘ 
ğ‘–,ğ‘
ğœ•ğ‘§ğ‘ 
ğ‘–,ğ‘
Â·
ğœ•ğ‘§ğ‘ 
ğ‘–,ğ‘
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ ,
(9)
where ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) is the derivative of the activation function and
the partial differentiation of ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— varies depending
on whether the ğ‘  is the output (ğ‘  = ğ‘œğ‘¢ğ‘¡) or the hidden layers.
â€¢ ğ‘  is the output layer (ğ‘  = ğ‘œğ‘¢ğ‘¡):
If ğ‘  is the output layer, the partial differentiation of
ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— is directly derived from the error function. Here,
the two types of error functions, that is, the mean squared error
(MSE) and the cross entropy (CE) are considered.
<MSE >
The error function is deï¬ned as
ğ¸ğ‘(w) = 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ¿
âˆ‘
ğ‘–=1
1
2
(
ğ‘‘ğ‘–,ğ‘ âˆ’ ğ‘¥ğ‘œğ‘¢ğ‘¡
ğ‘–,ğ‘
)2
,
(10)
where ğ¿ is the number of the output units and ğ‘‘ğ‘–,ğ‘ denote ğ‘–th
unit of the output layer for the ğ‘th desired vector. Therefore,
the partial differentiation of ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— is given by
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
= âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
(ğ‘‘ğ‘–,ğ‘ âˆ’ ğ‘¥ğ‘œğ‘¢ğ‘¡
ğ‘–,ğ‘ ) Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ .
(11)
13
Copyright (c) IARIA, 2023.     ISBN:  ISBNFILL
ICCGI 2023 : The Eighteenth International Multi-Conference on Computing in the Global Information Technology

<CE >
The error function and the activation function are deï¬ned
as (12) and the softmax function of (13), respectively.
ğ¸ğ‘(w) = âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ¿
âˆ‘
ğ‘–=1
ğ‘‘ğ‘–,ğ‘ log(ğ‘¥ğ‘œğ‘¢ğ‘¡
ğ‘–,ğ‘ ),
(12)
ğ‘¥ğ‘œğ‘¢ğ‘¡
ğ‘–,ğ‘ = ğ‘“ (ğ‘§s
ğ‘–,ğ‘) =
ğ‘’ğ‘¥ğ‘(ğ‘§ğ‘ 
ğ‘–,ğ‘)
âˆ‘ğ¿
ğ‘–=1 ğ‘’ğ‘¥ğ‘(ğ‘§ğ‘ 
ğ‘–,ğ‘)
.
(13)
where ğ¿ is the classiï¬cation class. The gradient is given by
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
= âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
(ğ‘‘ğ‘–,ğ‘ âˆ’ ğ‘¥ğ‘œğ‘¢ğ‘¡
ğ‘–,ğ‘ ) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ .
(14)
â€¢ ğ‘  is a hidden layer:
If ğ‘  is the hidden layer, the partial differentiation of
ğœ•ğ¸ ğ‘(w)/ğœ•ğ‘¥ğ‘ 
ğ‘–,ğ‘ in (9) is given by
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥s
ğ‘–,ğ‘
=
âˆ‘
ğ‘˜
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥s+1
ğ‘˜,ğ‘
Â·
ğœ•ğ‘¥s+1
ğ‘˜,ğ‘
ğœ•ğ‘§s+1
ğ‘˜,ğ‘
Â·
ğœ•ğ‘§s+1
ğ‘˜,ğ‘
ğœ•ğ‘¥s
ğ‘–,ğ‘
(15)
=
âˆ‘
ğ‘˜
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ +1
ğ‘˜,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) Â· ğ‘¤ğ‘ +1
ğ‘˜ğ‘– .
(16)
Substituting (16) into (9), the gradient of ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— can
be obtained as (17).
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
âˆ‘
ğ‘˜
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ +1
ğ‘˜,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) Â·ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â·ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ .
(17)
(17) shows that the inner product of the back propagation
components ğœ•ğ¸ ğ‘(w)/ğœ•ğ‘¥s+1
ğ‘˜,ğ‘ Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) and the weights ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
is necessary for the all samples in a mini-batch ğ‘. This means
that the derivation of the gradient requires ğ‘ times backward
processes. The structural diagram of SGD is shown in Fig. 1.
This ï¬gure also shows that SGD requires an error propagation
architecture from the output layer to the input layer for each
training sample in order to calculate the gradient.
III. STOCHASTIC WEIGHT DIFFERENCE PROPAGATION
LEARNING
In this paper, to reduce the computational cost of training
in SGD, Stochastic Weight Difference Propagation (SWDP)
is proposed. The proposed SWDP focuses on the backprop-
agation stream of each training sample in SGD training and
eliminates the BP architecture requirement for each training
sample in a mini-batch. As a result, SWDP can calculate the
amounts of weight updates with only one weight difference
propagation. This means that the proposed method can reduce
the computational complexity in the backward calculations of
the training to 1/ğ‘ compared to SGD.
Since the training of SWDP is based on SGD, and the
computation process differs depending on whether ğ‘  is the
output or hidden layers.
â€¢ ğ‘  is the output layer (ğ‘  = ğ‘œğ‘¢ğ‘¡):
If ğ‘  is the output layer, ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— is same as SGD given
by (11) or (14).
â€¢ ğ‘  is the hidden layer:
If ğ‘  is the hidden layer, a variant of (17) is considered. In
the proposed SWDP, the gradient of ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— given by
(17) is transformed as follows:
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
âˆ‘
ğ‘˜
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ +1
ğ‘˜,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) Â· ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
(17)
=
âˆ‘
ğ‘˜
ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ +1
ğ‘˜,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) Â· ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘) Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ . (18)
Here, (18) is transformed to (19) by assuming that the output
of ğ‘–th neuron in ğ‘  layer ğ‘¥ğ‘ 
ğ‘–,ğ‘ â‰  0.
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
=
âˆ‘
ğ‘˜
ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ +1
ğ‘˜,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) Â· ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â·
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ .
(19)
From (9),
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
= ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¥ğ‘ +1
ğ‘˜,ğ‘
Â· ğ‘“ â€²(ğ‘§ğ‘ +1
ğ‘˜,ğ‘) Â· ğ‘¥ğ‘ 
ğ‘–,ğ‘.
(20)
Therefore, (21) can obtained by substituting (20) into (19).
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
=
âˆ‘
ğ‘˜
ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
Â·
ğ‘“ â€²(ğ‘§s
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ . (21)
Here, (21) is transformed as follows: The second sum in
(21) for the sample ğ‘ is divided into two parts, that is,
ğœ•ğ¸ ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— and ğ‘“ â€²(ğ‘§s
ğ‘–,ğ‘)/ğ‘¥ğ‘ 
ğ‘–,ğ‘ Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ . Then (21) is rewritten
as (22),
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
=
âˆ‘
ğ‘˜
ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
{
1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
Â· 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
+ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
((
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
)
Â·
( ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
))}
.
(22)
That is, the ï¬rst term denotes the product of the averages of
ğœ•ğ¸ ğ‘(w)/ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
and ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)/ğ‘¥ğ‘ 
ğ‘–,ğ‘ Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ . The second term is
the covariance of these parts. In (22), if ğœ•ğ¸ ğ‘(w)/ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
and
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)/ğ‘¥ğ‘ 
ğ‘–,ğ‘ Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ are independent variables, (23) holds.
(
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
)
Â·
( ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘ âˆ’ 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
)
= 0
(23)
14
Copyright (c) IARIA, 2023.     ISBN:  ISBNFILL
ICCGI 2023 : The Eighteenth International Multi-Conference on Computing in the Global Information Technology

Fig. 2. Structural diagram of SWDP.
However, these terms are clearly not independent because
these parts are derived from the sample ğ‘. It is also estimated
that as the number of samples in the mini-batch increases, the
value of (23) becomes larger. On the other hand, it is clear that
learning of NN can be performed even if there is some error
in gradients [3]â€“[6]. Therefore, the proposed SWDP assumes
that (23) holds and then obtains (24).
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
â‰ƒ
âˆ‘
ğ‘˜
ğ‘¤s+1
ğ‘˜ğ‘–
(
1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğœ•ğ¸ ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
Â· 1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
)
=
âˆ‘
ğ‘˜
(
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
Â· ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
)
Â·
(
1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥sâˆ’1
ğ‘—,ğ‘
)
.
(24)
In this study, the gradient ğœ•ğ¸ğ‘(w)/ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘— of (24) is used for
learning. Consider the update formula for ğ‘¤ğ‘ +1
ğ‘˜ğ‘– in SGD of (25).
ğ‘¤ğ‘ 
ğ‘˜ğ‘–(ğ‘¡ + 1) = ğ‘¤ğ‘ 
ğ‘˜ğ‘–(ğ‘¡) âˆ’ ğœ‚ ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘˜ğ‘–
.
(25)
Here, the update formula of (25) can be transformed into an
expression for the amount of update (difference) Î”ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
as
Î”ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
= ğ‘¤ğ‘ +1
ğ‘˜ğ‘– (ğ‘¡ + 1) âˆ’ ğ‘¤ğ‘ +1
ğ‘˜ğ‘– (ğ‘¡) = âˆ’ğœ‚ ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
,
(26)
and then
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
= âˆ’1
ğœ‚Î”ğ‘¤ğ‘ +1
ğ‘˜ğ‘– .
(27)
By substituting (27) into (24),
ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
=
âˆ‘
ğ‘˜
(
âˆ’1
ğœ‚Î”ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
)
Â·
(
1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
)
.
(28)
Furthermore, by substituting (28) into the SGD update formula
(7), the proposed SWDP update formula can be obtained as
(29).
ğ‘¤ğ‘ 
ğ‘– ğ‘— (ğ‘¡ + 1) = ğ‘¤ğ‘ 
ğ‘– ğ‘— (ğ‘¡) âˆ’ ğœ‚ ğœ•ğ¸ğ‘(w)
ğœ•ğ‘¤ğ‘ 
ğ‘– ğ‘—
= ğ‘¤ğ‘ 
ğ‘– ğ‘— (ğ‘¡) +
âˆ‘
ğ‘˜
(
Î”ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
)
Â·
(
1
ğ‘
âˆ‘
ğ‘âˆˆğ‘‹
ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)
ğ‘¥ğ‘ 
ğ‘–,ğ‘
Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
)
.
(29)
In (29),
(
1/ğ‘ âˆ‘
ğ‘ ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)/ğ‘¥ğ‘ 
ğ‘–,ğ‘ Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
)
can be calculated in
the forward operation in the mini-batch. Therefore, the back-
ward operation for the learning of NN is one calculation
of âˆ‘
ğ‘˜
(
Î”ğ‘¤ğ‘ +1
ğ‘˜ğ‘– Â· ğ‘¤ğ‘ +1
ğ‘˜ğ‘–
)
in the stochastic learning. This means
that the learning architecture is simple, and the computational
cost decreases compared to SGD. However, it is estimated
that the error of the gradients affects the learning from the
assumption of (23) holds. In Section V, the effect on learning
is investigated through computer experiments. The structural
diagram of SWDP is shown in Fig. 2. This ï¬gure shows
that SWDP eliminates the requirement of the BP architecture
for each training sample in mini-batch and calculates the
amounts of the weight update with only one weight difference
propagation.
IV. COMPUTATIONAL COST
This section discusses the computational costs of the pro-
posed SWDP and SGD for updating a weight of ğ‘¤ğ‘ 
ğ‘– ğ‘—. Since
the forward calculations of SWDP and SGD are the same,
the calculation costs of the backward processes for both
SWDP and SGD are compared. The summary of the backward
computational cost is illustrated in TABLE I. To estimate the
costs of backward processes, (17) and (28) are considered
for SGD and SWDP, respectively. In SGD, the computational
cost is ğ‘(2ğ‘˜ + 2), which denotes the inner product of the
propagated error components and weights in the ğ‘  + 1 layer
for all samples in the mini-batch ğ‘. In SWDP, the cost ğ‘˜
indicates the inner product of weights and their differences
in the ğ‘  + 1 layer. Therefore, it can be seen from TABLE
15
Copyright (c) IARIA, 2023.     ISBN:  ISBNFILL
ICCGI 2023 : The Eighteenth International Multi-Conference on Computing in the Global Information Technology

I that the proposed SWDP can reduce the computational
complexity in the backward calculations of the training to
1/ğ‘ compared to SGD. Here, the computational cost of
(
1/ğ‘ âˆ‘
ğ‘âˆˆğ‘‹ ğ‘“ â€²(ğ‘§ğ‘ 
ğ‘–,ğ‘)/ğ‘¥ğ‘ 
ğ‘–,ğ‘ Â· ğ‘¥ğ‘ âˆ’1
ğ‘—,ğ‘
)
in (28) is 2ğ‘+1, but this term
can be calculated in forward process. Therefore, this cost is
ignored in the backward process of SWDP.
TABLE I
SUMMARY OF THE COMPUTATIONAL COST.
Algorithm
Computational Cost
of Backward
SGD
b(2k + 2) + 1
SWDP
k + 1
V. SIMULATION RESULTS
To investigate the performance of the proposed method,
SWDP is compared with SGD on two classiï¬cation bench-
mark problems. For all problems, the learning rate is set to
ğœ‚ = 0.1 for both algorithms. The mini-batch sizes are set to
ğ‘ = 1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, and 32 for the problems.
The termination condition were set to ğ¸(w) < 10âˆ’3 and the
maximum iteration counts ğ‘¡ğ‘šğ‘ğ‘¥ = 500, 000.
A. 8 Ã— 8 MNIST
The ï¬rst problem is the classiï¬cation problem of MNIST
handwritten digits dataset [10] with 8 Ã— 8 pixels as shown in
Fig. 3. The 8Ã—8 MNIST problem classiï¬es a handwritten digit
image of |ğ‘‡| = 1, 797 training data samples into ten classes
from 0 to 9. In this experiment, the dataset was randomly
divided to 75% (1,347) as the training data ğ‘‡ğ‘Ÿ and 25% (450)
as the test data ğ‘‡ğ‘ . The network structure is 64-10-10, which
denotes inputs, the number of neurons in a hidden layer, and
the outputs. In this problem, the activation functions for the
hidden and the output layers were set to the sigmoid and the
softmax of (13) functions, respectively. The error function is
cross-entropy of (12). The experimental results are shown in
Fig. 4 and TABLE II. In the ï¬rst, Fig. 4 shows the training
and test accuracies for each mini-batch size, where the ğ‘¥-axis
is the mini-batch size, and the ğ‘¦-axis is the accuracy. This
ï¬gure shows that the training accuracies of SGD and SWDP
are almost the same. In terms of test accuracy, both algorithms
maintain almost the same accuracy too. That is, SWDP was
Fig. 3. Examples of 8 Ã— 8 MNIST handwritten digits dataset.
Fig. 4. Accuracy .vs. mini-batches for 8 Ã— 8 MNIST.
up to 3% less accurate than SGD. Therefore, it concluded
that training with almost the same accuracy is possible even
if simpliï¬ed backward calculation. The table summarizes the
epoch, iteration, time, and time per iteration required for the
convergence of SGD and SWDP. The table shows that SWDP
requires more epoch, iteration, and time as the mini-batch size
increases. It can be attributed to (23) becoming stronger as the
mini-batch size increases. However, the computation time per
iteration of the proposed SWDP is shorter than SGD because
the backward computation is simpliï¬ed. Therefore, it can be
concluded that the proposed SWDP method is practical for
this problem.
B. 3-Spiral
The next problem is another nonlinear problem called the
3-Spiral problem [11]. 3-Spiral is a problem of classifying
training data samples ğ‘‡ğ‘Ÿ = 1, 050 into three classes, as shown
in Fig. 5, where each class has 350 data samples. The input
data is the coordinates of each point, and the NN structure is 2-
10-3, which denotes inputs, hidden layer neurons, and outputs
numbers, respectively. The activation and error functions were
the same as the previous problem. The experimental results
are shown in Fig. 6. Fig. 6 shows the training accuracy for
each mini-batch size, where the x-axis is the mini-batch size,
and the y-axis is the training accuracy. This ï¬gure shows that
the proposed method and SGD have similar accuracy when
the mini-batch size ğ‘ = 1 and 2. However, as the mini-
batch size increases, the accuracy of the proposed SWDP
method decreases from 3% to a maximum of 22% (ğ‘ = 10).
Therefore, in training this problem, the training of SWDP
strongly depends on the mini-batch size and the initial values.
VI. CONCLUSION
In this research, a novel training algorithm was proposed.
The proposed method was referred to as Stochastic Weight
Difference Propagation (SWDP) to simplify the gradient calcu-
lation (backward processes) in SGD. SGD, based on the error
propagation architecture from the output to the input layers, is
required for each training sample to calculate the gradient and
16
Copyright (c) IARIA, 2023.     ISBN:  ISBNFILL
ICCGI 2023 : The Eighteenth International Multi-Conference on Computing in the Global Information Technology

TABLE II
THE RESULTS SUMMARY OF 8 Ã— 8 MNIST.
Algorithm
Mini-batch
Epoch
Iteration
Time
per Iteration
Size
(sec)
Time(msec)
SGD
1
28
39,062
0.364
0.9318 Ã—10âˆ’2
2
26
18,170
0.32
0.1761 Ã—10âˆ’1
4
26
9,071
0.284
0.3130 Ã—10âˆ’1
6
26
6,047
0.284
0.4696 Ã—10âˆ’1
8
26
4,535
0.268
0.5909 Ã—10âˆ’1
10
27
3,751
0.276
0.7358 Ã—10âˆ’1
12
26
3,023
0.262
0.8666 Ã—10âˆ’1
14
26
2,591
0.277
0.1069
16
26
2,267
0.268
0.1182
18
26
1,997
0.27
0.1352
20
26
1,808
0.263
0.1454
32
27
1,175
0.274
0.2331
SWDP
1
28
39,062
0.366
0.9369 Ã—10âˆ’2
2
92
62,588
0.947
0.1513 Ã—10âˆ’1
4
192
64,847
1.826
0.2815 Ã—10âˆ’1
6
625
140,223
5.614
0.4003 Ã—10âˆ’1
8
860
144,647
7.691
0.5317 Ã—10âˆ’1
10
1,233
165,355
10.943
0.6617 Ã—10âˆ’1
12
2,254
252,559
19.474
0.7710 Ã—10âˆ’1
14
3,312
318,047
28.558
0.8979 Ã—10âˆ’1
16
4,922
413,499
41.972
0.1015
18
5,006
370,517
42.398
0.1144
20
5,898
395,232
50.48
0.1277
32
11,905
500,000
99.671
0.1993
Fig. 5. Layout of the 3-Spirals dataset.
causes an increase in hardware and computational costs. The
proposed SWDP was focused on the disadvantage of SGD
and reduced the computational complexity in the backward
calculations of the training compared to SGD. The proposed
SWDP simpliï¬es the backward process of SGD using only the
inner product of the weights and their differences in training.
The computational costs of the backward processes during
SWDP training are reduced to 1/ğ‘ (ğ‘ is the mini-batch size)
compared to SGD. Experimental results showed that SWDP
could learn accurately close to SGD even when the backward
processes were simpliï¬ed. However, the number of epochs
Fig. 6. Training accuracy for mini-batches for 3-Spirals.
required for learning SWDP increased as the mini-batch size
increased. This is caused by the fact that SWDP ignored the
covariance term required for the SGD backward processes.
In future works, the proposed method SWDP will be
improved to achieve more robust learning similar to SGD re-
gardless of the mini-batch size, initial values, and nonlinearity
of the problem. In addition to investigating the effectiveness
of the proposed method on edge computing, we plan to
implement SWDP on hardware such as FPGA to verify its
effectiveness.
ACKNOWLEDGMENT
The authors gratefully acknowledge the Honjo International
Scholarship Foundation for supporting this work. The Japan
Society supported this work for the Promotion of Science
(JSPS), KAKENHI (20K11979).
REFERENCES
[1] I. Goodfellow, Y. Bengio and A. Courville, â€œDeep Learningâ€, MIT Press,
2016.
[2] S. Haykin: â€œNeural Networks and Learning Machinesâ€, Pearson, 2009.
[3] D. H. Lee, S. Zhang, A. Fischer and Y. Bengio, â€Difference target
propagation,â€ Proc. ECML/PKDD, Springer, Cham, pp. 498â€“515, 2015.
[4] T. P. Lillicrap, D. Cownden, D. B. Tweed and C. J. Akerman, â€Ran-
dom synaptic feedback weights support error backpropagation for deep
learning,â€ Nature Communications, 2016.
[5] A. NÃ¸kland, â€Direct feedback alignment provides learning in deep neural
networks,â€ Proc. NeurIPS, vol. 29, 2016.
[6] T. Miyato, D. Okanohara, S. I. Maeda and M. Koyama, â€Synthetic gradi-
ent methods with virtual forward-backward networks,â€ Proc. Workshop
trac - ICLR, 2017.
[7] R. D. Brandt and F. Lin, â€Supervised Learning in neural networks with-
out explicit error backpropagation,â€ Proc. Annual Allerton Conference
on Communication Control and Computing, pp. 294â€“303, 1994.
[8] R. D. Brandt and F. Lin, â€Can supervised learning be achieved without
explicit error backpropagation?â€, Proc. IEEE ICNN, pp. 300â€“305, 1996.
[9] H. Ninomiya and N. Kinoshita, â€A new learning algorithm without
explicit error backpropagation,â€ Proc. IJCNNâ€™99, vol.2, No.99CH36339,
pp. 1389â€“1392, 1999.
[10] E. Alpaydin and C. Kaynak, â€œOptical recognition of handwritten digits
data setâ€, UCI Machine Learning Repository, 1998.
[11] J. Bassey, X. Li and L. Qian, â€œAn Experimental Study of Multi-Layer
Multi-Valued Neural Networkâ€, Proc. IEEE ICDIS, pp. 233â€“236, 2019.
17
Copyright (c) IARIA, 2023.     ISBN:  ISBNFILL
ICCGI 2023 : The Eighteenth International Multi-Conference on Computing in the Global Information Technology

