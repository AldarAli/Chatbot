Emotion-Aware Design Image Recommendation
using Color Image Scale
Dongwann Kang
Faculty of Science and Technology
Bournemouth University
Poole, Dorset, BH12 5BB, United Kingdom
Email: dkang@bournemouth.ac.uk
Kyunghyun Yoon
School of Computer Science and Engineering
Chung-Ang University
Seoul, 06974, Korea
Email: khyoon@cau.ac.kr
Abstract—Color is one of the visual elements that psychologically
affect people’s emotion. Although there are slight differences
based on culture, several studies in color psychology have found
that most single colors generally have meaning or emotion.
Therefore, most professional designers use colors in their works
to express the emotion. In this paper, we present a novel method
that recommends design images using a color combination based
on the relation between color and emotion. To achieve this, we
estimate emotion based on the color image scale, which is a
famous color theory in the ﬁeld of design, and recommend design
images according to the emotion.
Keywords–color image scale; emotion; design image; color
combination.
I.
INTRODUCTION
Color is a visual element that psychologically affects
people’s emotion. Generally, it is known that single colors have
their own meaning or emotion [1]. In addition, the combination
of colors also signiﬁcantly affects emotion [2]. Many people
apply these principles knowingly or unknowingly in their daily
life, for example, to coordinate clothes, select furniture color,
etc.
The color image scale [3] [4] is a theory studied by
Shigenobu Kobayashi at Nippon Color & Design Research
Institute. In their psychophysical research, they presented over
1000 color combinations to express any emotion, taste, or
lifestyle that belongs to 174 semantic keywords on the emotion
perceived from color. They labeled each combination of three
colors with one of 174 keywords. In addition, they devised a
two-dimensional emotion space, the color image scale, which
consists of two axes that correspond to the scales cool-warm
and soft-hard. On the color image scale, they located every
keyword according to its two scales measured by several
studies. Figure 1(a) presents the concept that illustrates sev-
eral examples of three-color combinations, along with their
keywords, plotted in the color image scale [4]. In this scale,
they also deﬁned 15 categories such that each keyword belongs
to one of the categories.
Most professional designers also reﬂect these principles
in their works. To convey intended emotion, they intuitively
employ the color combination in their design. At this time,
color combinations which are used for an emotion can be
different to each other, because it is known that there are lots of
available combinations for an arbitrary emotion. Consequently,
the colors used in the works depend on designers’ knowledge
(a) Three-color combinations
(b) The emotion keywords
Figure 1. Three-color combinations and emotion keywords on color image.
and experiences, so that it is not an easy task for non-experts
and beginners to use colors appropriately according to their
emotion.
In this paper, we present a novel method that recommends
design images using the emotion estimated from images based
on the color images scale theory. We establish an emotion
prediction model using a machine learning technique. For
this, we ﬁnd the relationship between the emotion and the
properties of the color combination in the color image scale.
Then, we extract the main colors from the image. Finally, we
estimate the emotion of the image via the properties of the
main colors extracted. Once the prediction model is ready,
any other knowledge is not required in our method, and design
images are recommended according to input emotion.
The remainder of this paper is organized as follows. In
Section II, we explain our approach for establishing emo-
tion prediction model from color combinations. Then, we
present our method for estimating emotion by extracting color
combinations from image in Section III. In Section IV, we
demonstrate the results of our proposed method and discuss
the algorithm used and its limitations. Finally, we conclude this
paper in Section V with a summary of our ideas and outline
of future work.
II.
ESTABLISHING EMOTION PREDICTION MODEL FROM
THREE-COLOR COMBINATIONS
To estimate an emotion from an image, we use the three-
color combinations surveyed by Kobayashi [4]. His research
provides such combinations tagged as the name of the emotion,
and thus we can estimate emotion from an image by extracting
7
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-627-9
MMEDIA 2018 : The Tenth International Conference on Advances in Multimedia

(a)
(b)
(c)
Figure 2. Extracting three-color combinations from input image. (a) Input
image, (b) normalized image, and (c) top three colors frequently used.
a color combination from the image. Kobayashi’s research also
provides the name of each color combination and the emotion
position in the color image scale. Because the positions of the
emotion keywords are graphically represented in the work [4],
we estimate the position by acquiring the centre position of the
text in the graph (Figure 1(b)). Consequently, we obtain three-
color combinations that include the name of three colors and
of the emotion tagged on the combinations, and the emotion
position in the color image scale.
Kobayashi’s work [4] did not cover all possible three-
color combinations. Thus, estimating an emotion from random
color combination is important to ﬁnd the relationship between
each color in his three-color combination. To estimate such
relationship, we employ a machine learning technique. First,
we extract features from the colors in the combination, such
as the hue/saturation/luminance difference between two colors,
and the average hue/saturation/luminance value of three colors.
Consequently, we obtain a 12-dimensional feature for each
three-color combination. Next, we generate data pairs with the
features and two-dimensional position of the emotion tagged
on the data, three-color combination. Finally, we acquire a
prediction function that estimates the emotion coordinates from
the random three-color combination using linear regression [5].
For our experiment, we used 936 three-color combinations
and 174 emotions. To ignore the order of the colors in the
combination, we generated all possible combinations from the
given 936 three-color combinations, such that six combinations
are generated from each three- color combination. The range
of both coordinates in the color image scale is [−3 : +3]. In
our experiment, the prediction error magnitude was recorded at
0.64. In our analysis, the signiﬁcant factors seem to be average
(avg.) hue, hue difference, avg. saturation, and intensity.
III.
ESTIMATING EMOTION BY EXTRACTING COLOR
COMBINATIONS FROM IMAGE
Once the model for predicting emotion from color com-
binations is established, it is enabled to estimate the emotion
of image by using the color combination of image. In this
study, we assume that the three colors used predominantly in
an image affect human emotion similarly to three-color com-
binations. Therefore, we use the three colors most frequently
used in an image to estimate emotion.
In general, digital color images have 24-bit depth color.
There are too many discrete colors in an image, and thus
ﬁnding the most frequently used colors is not meaningful. For
this reason, we normalize an image by enforcing a limited
number of colors. Kobayashi used Hue & Tone 130 system in
(a) Kobayashi’s ground truth [4]
(b) Our results
Figure 3. Ground truth color image scale of 16 images used by Kobayashi
and our results.
[3] to construct the image scale of three-color combinations,
and thus we normalize image colors using the same color
system (Figure 2).
After normalizing the colors, we estimate the emotion
coordinates in the color image scale of an image using
the prediction function described in Section II. Kobayashi
showed the coordinates of 16 famous painting images in [4]
(Figure 3(a)). Similarly to the emotion names, we acquire
the image coordinates by calculating the centre position of
each image. For 16 images with ground truth emotion, we
estimate emotion as the coordinates in the color image scale
(Figure 3(b)). In our experiment, the mean error magnitude
was recorded at 2.08.
We then recommend several images of which emotion
estimated by our method is closer to the input emotion on
the color image scale.
IV.
EXPERIMENTAL RESULTS
For machine learning methodology, we used linear regres-
sion by using Weka library [5]. We evaluated our prediction
performance by using 10-fold cross validation. Figure 4 shows
recommended images of given emotion keywords on proposed
method.
To evaluate our emotion estimation as described in Sec-
tion III, we gathered ground truth data of experimental images
8
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-627-9
MMEDIA 2018 : The Tenth International Conference on Advances in Multimedia

(a) ‘provincial’
(b) ‘simple and elegant’
(c) ‘mysterious’
Figure 4. Recommended images of given emotion keywords.
using a Crowdsourced user study, Amazon mTurk [6]. The
ground truth annotations of 47 design images were generated
by aggregating the study participants’ labels over each image.
Figure 5 shows a sample question for labeling the color image
scale of a given image. For each image, we asked over 50
participants to select a degree of the two factors, warm-cool
and soft-hard, considering color and tone only.
After obtaining the ground truth color image scale of
47 images, we evaluated the performance of our emotion
estimation algorithm. In our experiment, the mean errors for
warm-cool and soft-hard were measured by calculating the
distance between the ground truth and estimated emotion
coordinates, and the corresponding values are 0.13 and 0.21.
In our experiment, the performance of emotion estimation
from an image is worse than that of the emotion estimation
from the three-color combination. In general, digital image
colors for the same image differ slightly from each other
according to image format and compression rate. Therefore,
the prediction performance depends mainly on the color of
the image.
V.
CONCLUSION
In this paper, we proposed a novel method that recommends
images based on the emotion estimated from the image. For
this, we established emotion prediction model by using the
Figure 5. Sample question for labeling color image scale of given image.
color image scale, a well-known theory in design ﬁelds, and
estimated the emotion of image using top three colors and
the model. Then we recommended images of which estimated
emotion was closer to input emotion on color image scale. In
addition, we conducted crowdsourced user study to evaluate
our results.
Our experiment mainly depended on Kobayashi’s research.
Moreover, we obtained the three-color combination from im-
ages by na¨ıvely extracting top three colors frequently used;
therefore, there is no guarantee that the extracted three-color
combination successfully represents the image. Also, it is
known that human emotions affected by color can be altered
based on era and culture. Consequently, a more robust ap-
proach for estimating human emotion is required in our future
work.
In this paper, we consider only color. However, the factor
that affects the emotion of images is not only color. In our
future work, we will study other factors that can affect the
emotion of images, such as composition and texture, and
improve our emotion estimation by employing these factors.
ACKNOWLEDGMENT
This work was supported by the National Research Foun-
dation of Korea(NRF) grant funded by the Korea govern-
ment(MSIP) (No. NRF-2017R1A2B4007481).
REFERENCES
[1]
B. Wright and L. Rainwater, “The meanings of color,” The Journal of
General Psychology, vol. 67, no. 1, 1962, pp. 89–99, pMID: 14008415.
[2]
L. Sivik, “Research on the meanings of color combinations,” in Pro-
ceedings of the Congress of the Association Internationale de la Coleur
(AIC), 1989, pp. 130–132.
[3]
S. Kobayashi, “The aim and method of the color image scale,” Color
Research & Application, vol. 6, no. 2, 1981, pp. 93–107. [Online].
Available: http://dx.doi.org/10.1002/col.5080060210
[4]
——, Color Image Scale.
Kosdansha International, 1991.
[5]
M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H.
Witten, “The weka data mining software: An update,” SIGKDD Explor.
Newsl., vol. 11, no. 1, Nov. 2009, pp. 10–18.
[6]
P. G. Ipeirotis, “Analyzing the amazon mechanical turk marketplace,”
XRDS, vol. 17, no. 2, Dec. 2010, pp. 16–21. [Online]. Available:
http://doi.acm.org/10.1145/1869086.1869094
9
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-627-9
MMEDIA 2018 : The Tenth International Conference on Advances in Multimedia

