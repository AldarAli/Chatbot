Involving Users in the Development of AI-Supported CAM Systems 
by Co-Creation Methods 
 
Nina Rußkamp, Lorena Niebuhr, and Eva-Maria Jakobs 
Human-Computer Interaction Center / Text Linguistics and Technical Communication 
RWTH Aachen University 
Aachen, Germany 
email: {n.russkamp, l.niebuhr, e.m.jakobs}@tk.rwth-aachen.de 
 
 
Abstract—In many German key industries, the process 
planning for manufacturing workpieces is carried out with 
Computer-Aided Manufacturing (CAM) systems. Shorter 
innovation cycles and greater product customization in the 
industry 4.0 era are rapidly increasing the complexity of 
products and CAM systems, making it even for experienced 
CAM planners challenging to carry out their work on time. 
This is also because CAM systems are still difficult to use 
and learn. The research and development project CAM2030 
aims to partially automate parameter optimization in the 
CAM-planning 
process 
with 
the 
help 
of 
artificial 
intelligence, cloud computing, and evolutionary algorithms. 
The aim is to save time, get closer to the perfect process 
planning, and relieve the user. An interdisciplinary team of 
experts from industry and academia is developing 
approaches for a new generation of CAM systems. This 
paper focuses on how co-creation facilitates the involvement 
of software users in developing new software generations 
that 
integrate 
new 
technologies, 
such 
as 
artificial 
intelligence. A methodological co-creation framework was 
developed to continuously incorporate the actors involved in 
the innovation process. The framework was applied to the 
project case study to investigate (i) the potential of the co-
creation framework for eliciting user expectations relevant 
to acceptance and usability, and (ii) what retraining needs 
the integration of artificial intelligence requires and how 
users could be supported when switching to the new system. 
The co-creation approach shows a high potential to integrate 
the user’s (CAM planner’s) perspective in interdisciplinary 
innovation processes. It facilitated the identification of 
general 
and 
selective 
relearning 
needs 
induced 
by 
redesigning CAM-planning processes, the system (interface), 
and the integration of novel technologies. Applying this 
knowledge to the design and implementation of new software 
generations benefits the users and companies; it makes the 
system introduction easier, faster, and less prone to 
disruptions. Future research should provide guidance for 
introducing new generations of CAM software and 
accompanying the transformation process. 
Keywords- user perspective; co-creation; computer-aided-
manufacturing; artificial intelligence; software training. 
I. 
 INTRODUCTION 
In the manufacturing industry, transformation towards 
shorter 
innovation 
cycles 
and 
greater 
product 
customization increases the complexity of Computer-
Aided Manufacturing (CAM) tasks and systems. CAM 
planners face the challenge of meeting rising quality 
requirements under time pressure. CAM planners usually 
achieve a process planning quality close to the optimum 
within a few hours (80 % solution). Most of their working 
time is spent on parameter adjustments to identify and 
eliminate minor but technically relevant errors. A basic 
assumption is that enriching software systems with novel 
technologies, especially Artificial Intelligence (AI), can 
reduce the users’ workload [1]. 
In the research and development project CAM2030, an 
interdisciplinary team of experts from industry and 
academia is developing approaches for a new generation 
of CAM systems that integrate technologies, such as 
artificial intelligence, cloud computing, and evolutionary 
algorithms. The innovation process focuses on partially 
automating CAM-planning processes, especially CAM 
parameterization. The automation requires a modification 
of the parameterization process which will also lead to 
changes in the working processes of CAM planners. Thus, 
AI integration raises the challenges of finding out where 
CAM planners need to rethink and relearn working 
routines, 
which 
solutions 
are 
acceptable 
and 
comprehensible to users, and what support they need to 
adapt to changing workflows as efficiently as possible.  
An essential prerequisite for achieving the project goal 
is to bring actor-specific perspectives together, close 
knowledge gaps, and integrate user perspectives [1]. This 
paper focuses on the involvement of CAM users in the 
innovation process. Therefore, a methodological co-
creation framework was developed that systematically 
incorporates the actors involved in the innovation process 
[2][3]. The co-creation framework is intended to support 
the development process in and across different innovation 
stages. Selected co-creation methods were adapted and 
combined for collaboration in online workshops under 
remote conditions. The approach was tested and evaluated 
guided by the following research questions (RQ): 
RQ1: Does the co-creation approach provide early 
indications of acceptance-relevant user expectations and 
requirements for the new system generation (criterion: 
acceptance and usability)? 
RQ2: Does the co-creation approach enable early 
indications of potential support needs and suitable 
measures to cover them? Where do users need support and 
140
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

explanations when switching to the new system (e.g., in 
the interface design or by training)? How should new 
routines, interfaces, and knowledge requirements be 
introduced? How high is the retraining requirement? 
Section II presents related work on developing AI-
supported systems for the manufacturing industry. The 
methodological approach of this study, developing and 
implementing the co-creation framework, is described in 
Section III. The results of the study are presented in 
Section IV. Section V concludes the findings and provides 
an outlook for future research. Finally, the limitations of 
the study are outlined in Section VI. 
II. 
RELATED WORK 
In this section, the state of the art is shortly 
summarized with respect to two foci: requirements for AI-
supported systems and their use in the manufacturing 
industry (Subsection A) and co-creation approaches for 
product and process innovation (Subsection B). 
A. Requirements for AI-Supported Systems and Their 
Use in the Manufacturing Industry 
When AI technologies are introduced in the context of 
the manufacturing industry, they face a unique set of 
challenges compared to their general use [4]. Introducing 
technologies into production environments involves 
considering existing facilities, IT systems, and the 
employees 
who 
run 
that 
production. 
Therefore, 
requirements for integrating AI technologies can be 
derived from general requirements but must be adapted to 
the area of application [4]. Few publications address 
requirements for AI technologies in a production 
environment [4][5].  
Hoffmann et al. [4] introduce 16 requirements divided 
into five categories: Adaptation, Engineering, Embedding, 
Security, and Trust, that need to be considered when 
introducing AI technologies in a production environment. 
Adaption: When introducing AI technologies, they 
should be adapted to the existing production environment. 
The introduction should be gradual, firstly keeping the 
human employee in control of all decisions, serving as a 
decision support system. In addition, the availability of the 
data needed by the AI has to be considered, and potential 
conflicts in terms of legal, cultural, technical, and security 
issues have to be clarified. 
Engineering: Keeping the AI system as simple as 
possible is a primary goal when designing the AI system. 
The complexity of the system should be hidden. The user 
of the AI-based system most likely doesn't have a 
background in computer science. The simplicity of the 
design contributes to the robustness of the system. The AI 
system should be able to physically and virtually learn and 
incrementally adapt to the production environment [4].  
Embedding: When embedding AI technologies, a trust 
space and boundary need to be defined, such as a 
checkpoint for the human employee to prove the 
plausibility of the AI’s decisions.  AI knowledge should be 
distributed to other AIs via higher-level systems or 
communication networks. However, the AI should not 
base its conclusions on data created by another AI [4]. 
Safety: The safety and security of AI technologies are a 
very broad area for research and requirements engineering. 
It is important to ensure that production systems are safe in 
accordance with applicable laws and regulations and do 
not pose a risk to human employees, even in the case of 
self-improvement. The risk for failure should be 
transparent. Industrial AI must be robust against random 
and deliberate adversary input [4].  
Trust: Trust contributes to security and performance; it 
is an important factor for acceptance [5]. To support trust, 
the AI system’s decisions should be as transparent and 
understandable as possible. The system should be able to 
explain its decision, e.g., through visualizations [6]. Any 
errors in the AI's assumptions should be detectable and 
correctable. Levels of trust or levels of quality should be 
used to express the probability of failure [4]. The AI’s 
capabilities should be provable in a test run or a virtual 
environment. AI systems in the manufacturing industry 
need to be free of bias in treating all vendors’ equipment 
equally. A measure of confidence should be made when 
giving action recommendations. AI systems are expected 
to have a 100 % solution rate, which cannot be achieved 
by a technical system [4]. The level of uncertainty should 
therefore be communicated to the user [5]. 
Both the system and the user require an effective 
learning process. While the system needs time to learn the 
user’s behavioral patterns, intentions, and operational 
status, users need adequate training with the system [5]. 
A critical challenge is establishing a skilled workforce 
for the future manufacturing industry [7]. However, it is 
rarely discussed how to cover CAM users’ relearning 
needs resulting from the integration of AI-based features. 
Jiao et al. [7] postulate to meet digitalization-related 
challenges by fostering nontechnical skills, such as 
continuous learning, communication, critical thinking, and 
making decisions using incomplete knowledge. To our 
knowledge, guidelines for the design of AI-sensitive 
training formats are still missing. 
B. User Integration: Co-Creation Approaches for 
Product and Process Innovation  
To date, software engineering methods tailored to 
developing AI-based systems are scarce [8]. Existing 
approaches focus more on identifying system-immanent 
challenges than user needs [2]. One approach to actively 
involve users throughout the whole innovation process is 
co-creation. Despite its high potential, the use of co-
creation methods for the user-centered innovation of 
complex software systems for the manufacturing industry 
is hardly discussed (but, e.g., [7][8]). 
The key element of co-creation is the collaboration 
between software production- and application-related 
actors as part of “an active, creative and social process” 
[11]. The process facilitates reducing uncertainties by 
providing access to two types of information: customer 
and market needs, e.g., users’ motives and preferences for 
141
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
Figure 1. Innovation stages for developing AI-supported CAM systems 
using co-creation. 
 
new products and services (need information) and 
possibilities for their (technological) implementation 
(solution information). The co-creation typology proposed 
by [11] classifies co-creation methods based on three 
dimensions:  
The stage in the innovation process: It refers to the 
point in time when the method is applied to the innovation 
process. Front-end co-creation at the early stages of the 
innovation process mainly focuses on conceptual tasks, 
i.e., idea generation and selection. In contrast, back-end 
co-creation deals with the design and testing of a product 
at later innovation stages.    
The degree of collaboration: It is determined by the 
number of collaborating partners and the company-to-
customer ratio (developer-to-user ratio), e.g., 1:n or n:m. 
The degrees of freedom: They determine the 
customer’s autonomy in the innovation process resulting 
from the type of task (open vs. predefined task). 
Due to the Covid-19 pandemic, research on virtual co-
creation methods has increased (e.g., [12]). 
III. 
METHODOLOGY 
The methodology comprises three subsections: a 
description of the innovation process segmented into five 
innovation stages the co-creation framework is based on 
(Subsection A), development of the framework and the 
methodological design of the single stages in general 
(Subsection B), and detailed insights into the procedure of 
selected stages (Subsection C). 
A. Overview of the Co-Creation-Based Framework 
The co-creation-based framework was abstracted from 
the innovation process in the project CAM2030 between 
2020 and 2023. It covers five innovation stages, from 
eliciting the as-is condition of the CAM-planning process 
to introducing next-generation CAM systems (see Fig. 1). 
Stage i aimed at creating a shared understanding of the 
status quo and, based on this, at deriving requirements for 
its partial automation. The first step was to elicit, model, 
and visualize the CAM-planning process and its 
embedment in the higher-level production process as 
currently conducted in the manufacturing industry. In the 
second step, the resulting process models were used to 
identify weak points and automation potential of CAM-
planning processes and their implications for the design of 
next-generation CAM systems. The results comprised 
improved and enriched process models [13], a ranked list 
of role-related, topically clustered no-go measurements, 
and, inverted and complemented, a structured catalog of 
requirements for the design of CAM systems.  
Based on stage i, stage ii served the prioritization, 
specification, and complement of requirements, mainly 
focusing on the user interface redesign for optimizing 
CAM parameter settings. The outcome was a prioritized 
and categorized list of requirements for CAM systems in 
general and the user interface in particular. 
Stage iii marked the transition from conceptualization 
to implementation. The focus was on consolidating 
knowledge about system design requirements and 
developing a typical user path, a mockup for the future 
CAM-planning process, and an interactive prototype for 
the user interface.  
Stage iv was iteratively conducted with prototypes of 
different maturity levels. The prototypes were evaluated 
with regard to weaknesses and potential for optimization. 
In addition to guidelines for improving the prototype, user 
feedback regarding integrated help functions and training 
was gathered.   
Stage v (not yet fully implemented) is supposed to 
yield a requirements profile for introducing next-
generation CAM systems and further training of CAM 
planners. The profile should consider different categories, 
such as the content and format of training and the 
planner’s expertise. 
B. Stage-Wise Development of the Framework 
For each stage, a methodological approach was 
developed, implemented, and evaluated, inter alia [14]. 
The approaches were mainly based on co-creation, partly 
complemented by other formats, e.g., online surveys.  Co-
creation was applied in online workshops involving 
developers, CAM users, human-centered work design 
experts, and technical communication experts. The 
workshops were moderated by a team of workshop leaders 
who accompanied the participants to work together on 
system development tasks. The CAM planners were asked 
to provide input and/or evaluate possible solutions in all 
innovation stages. Each workshop ended with an 
evaluation of the methods used in the workshop. The co-
creation workshop tasks varied in several aspects: 
• 
the group size (single-work tasks vs.  group tasks 
in separated teams or the plenum) 
• 
the group composition (role-related teams vs. 
interdisciplinary teams),  
• 
the methods used (front-end vs. back-end co-
creation, integration of co-creation and process 
modeling based on the C3 notation [15] [16]) 
• 
the tools used (selection of Zoom, Google Docs, 
Google Forms, Mural, Figma, and Microsoft 
Office). Google Docs was also used, among other 
things, to share organizational information, such 
as the workshop agenda and the list of 
participants. It served as a guide for the workshop 
procedure.  
142
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
Figure 3. Co-creation workshop (stage ii). 
 
Figure 4. Structure of the prototype testing (stage iv). 
 
Figure 2. Co-creation workshop (stage i). 
• 
the synchrony of user involvement (preparatory 
tasks prior to the workshop vs. collaboration tasks 
during the workshop vs. inter-workshop tasks vs. 
evaluation tasks after the workshop). 
The workshops were digitally recorded. The recording 
included video and audio data as well as written 
documents 
and 
visualizations 
created 
during 
the 
workshop, e.g., notes in shared text documents and online 
whiteboards. The audio was transcribed. The transcripts 
were supplemented with notes and evaluated qualitatively 
(content analysis). Surveys were analyzed qualitatively 
and quantitatively (descriptive statistics). The results were 
made available to all project partners. They were a 
prerequisite and input for the next innovation step. 
C. Methodological Design of Stages i, ii, and iv 
As this paper mainly refers to results yielded from 
stages i, ii, and iv, the methodological approaches of these 
stages are described in more detail: 
The key design element of stage i was the combination 
of co-creation and process modeling methods [14]. The 
purpose of integrating process modeling was tripartite: (i) 
to equalize differences in knowledge about the CAM-
planning process, (ii) to identify and merge role-specific 
perspectives (e.g., general mechanical engineering vs. 
aircraft manufacturing), and (iii) to facilitate getting in the 
requirements elicitation. The elicitation, modeling, and 
visualization of CAM-related processes, as they are 
typically conducted in the manufacturing industry, took 
place before the co-creation workshop pictured in Fig. 2.  
The workshop applied front-end co-creation (e.g., 
warm-up challenge as an idea generation task with high 
degrees of freedom). Group sizes and compositions were 
varied task-by-task while a shared text document was 
accessible for all participants throughout the workshop 
serving as results log. 
For the co-creation workshop in stage ii, the digital 
whiteboard tool Mural was used to enable the workshop 
participants to capture all workshop results – topically 
clustered requirements and their prioritization – at once. 
Dot voting was used to prioritize requirements and identify 
the need for requirements specification (see Fig. 3). 
Stage iv was divided into three parts: (i) a preliminary 
survey with CAM users, (ii) a co-creation test workshop, 
and (iii) a complementary prototype evaluation (see Fig. 
4). To get multiple feedback, especially from CAM 
planners, the approach alternates synchronous (part ii) and 
asynchronous (parts i and iii) formats. This enabled the 
discussion of the pre-survey results during the workshop 
and the prototype evaluation to take place either during or 
after the workshop. Different tools, e.g., Figma and 
Google Forms, were combined for the prototype 
evaluation. Figma allowed self-experience with the 
interactive prototype; the questionnaire was created in 
Google Forms. 
IV. 
RESULTS AND DISCUSSION 
The approach shows a high potential to support all 
stakeholders in creating a shared understanding of the 
innovation process and the resulting CAM system. The co-
creation workshops helped to identify and reconcile 
diverging perspectives (Subsection A). The user input was 
very productive: It provided the need for the redesign of 
the overall system and the user interface and, as a result, 
the need for relearning working routines (Subsection B). 
Additionally, it gave valuable hints for the design of 
integrated help functions and software training (Subsection 
C). 
A. Role-Specific Perspectives on AI Integration 
From the perspective of manufacturing companies, one 
risk is that workers will perceive automation as 
unnecessary, arguing that it is too complex and offers too 
little benefit compared to the current process. High 
training requirements and costs associated with the lack of 
intuitive operation of partially automated CAM systems 
are rejected. AI-based CAM systems must be practical and 
143
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
Figure 5. Ratings of the usefulness of KPI descriptions in the user 
interface. 
 
appropriate for the application domain. 
Developers, especially artificial intelligence experts, 
consider intransparency, i.e., lacking traceability of 
automated decisions made, as one of the three most 
significant inhibitors to the acceptance by CAM planners 
(see also [4]). A related issue is the unpredictability of the 
system’s 
runtime 
for 
automated 
tasks 
and 
the 
automatically generated results’ quality. The developers 
believe that making the system more transparent and 
giving the user continuous feedback on the system’s 
current state will increase acceptance among CAM 
planners (see also [5]). Another barrier to acceptance, 
which can be exacerbated by the factors mentioned above, 
is the disenfranchisement of the CAM planner.  
CAM planners see the risk that automation will reduce 
their freedom of action. They emphasize the need to 
balance simplifying the CAM-planning process against 
limiting the user's flexibility. This is coupled with the 
requirement for the system to adapt to the user's expertise. 
In addition, the lack of trustworthiness of the CAM system 
is considered a no-go characteristic.  
Overall, the workshop participants’ perspectives on 
tipping points for the acceptability and comprehensibility 
of automated CAM features gradually differ. The 
participants agree that the decision-making authority of the 
user is a prerequisite for acceptance. They emphasize the 
need for automation on demand. 
B. Redesign and Relearning Needs 
Stage iv has shown that automating the CAM 
parameterization has multiple consequences. It affects the 
workflow, the significance of Key Performance Indicators 
(KPIs) for the workflow, the system interface design, and 
the requirements for the user. The new workflow 
comprises three steps: (i) configuration of the CAM 
parameterization request (user task), (ii) execution of the 
optimization resulting in a set of high-quality parameter 
settings (automatically generated by the system), and (iii) 
evaluation, selection, and refinement of parameter settings 
(user task). The interface must be adapted to the new 
sequence of actions, e.g., by extending the interface to 
include 
input 
screens 
for 
selecting 
optimization 
preferences. Changes in the workflow and the interface 
force CAM planners working with present CAM systems 
to partly rethink and acquire specific knowledge. Setting 
evaluation and target values during step (i) requires 
knowledge of KPIs concerning production time, quality, 
and costs. The CAM planners need to develop an 
understanding of which KPIs are important and what 
effects they have. Partly, AI is seen as a black box that 
users cannot fully understand. To accept the system, users 
should have access to AI-specific knowledge so that they 
can trust the system, interpret AI-generated results, and 
customize AI-enhanced CAM features.  
C. Implications for the Design of Integrated Help 
Functions, Introduction, and Training 
In the workshops, the CAM planners gave valuable 
hints for the design of user support, which information 
users want to access in the CAM system (explanations and 
help functions as part of the user interface), and what 
should be taught in introductory and advanced training. A 
critical issue is introducing and representing KPIs for the 
automated CAM parameter optimization. The training 
should provide a basic understanding of the KPIs and 
CAM parameters, while the CAM system should provide 
help functions for further information. 
The training should give users a basic understanding of 
the CAM system and its AI-enhanced features. CAM 
planners need to be sensitized to CAM-planning steps that 
require new knowledge or rethinking previous user paths 
and actions. A demonstration of the new optimization 
workflow and user interface should be part of the training. 
The introductory training should also explain how the 
CAM system technically processes an optimization request 
to increase the user’s understanding of what data the 
system needs to be able to carry out an optimization task. 
The introduction of KPIs and CAM parameters should be 
restricted to explaining which target values can be 
optimized and how they relate to the KPIs time, quality, 
and costs. CAM parameters should be introduced as 
threshold values that limit the solution space of the AI-
based optimization.   
Regarding integrated help functions, there is a high 
demand for KPI descriptions explaining the KPIs time, 
quality, and costs. For each KPI, providing explanations in 
the user interface was rated as “very useful,” “useful,” or 
“rather useful” across all user groups (see Fig. 5). 
Descriptions of the KPI costs are perceived as most 
important independently of the user’s expertise. The KPI 
time should be explained for all user groups, particularly 
novices. The KPI quality is useful for all user groups; 
experts are particularly predestined to handle quality-
related information. 
There is a broad consensus on how to integrate KPI 
descriptions into the user interface. Depending on the type 
of the KPI, the preferred format varies: Time- and cost-
related information should be displayed as graphics. For 
quality, the combination of video and graphics is most 
suitable. Occasionally, texts (for time) or a combination of 
text and graphics (for quality and costs) are requested. 
Integrated help functions should give the CAM 
planners indications of what effect the single KPIs have:  
144
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

Time: CAM planners should be able to calculate the 
processing time of their CAM plans and identify and take 
advantage of the potential for time reduction.  
Quality: CAM planners must be able to evaluate in 
advance if the requested component quality can be ensured 
during production. Thus, they need quality estimations of, 
e.g., the CAM path and tools.     
Costs: CAM planners need an overview of the 
different types of costs, e.g., machining costs, tooling 
costs, and personnel costs. It should be clear how changes 
in CAM planning affect expenses and how much the 
execution of the final CAM process planning costs the 
company. 
V. 
CONCLUSION AND FUTURE WORK 
The user’s role in developing innovative software 
systems is often underestimated. Co-creation-based 
approaches are suitable means to integrate the user’s 
perspective in interdisciplinary innovation processes. 
Users' involvement allows for identifying general and 
selective relearning needs induced by the redesign of 
working processes and the system. Applying this 
knowledge to the design and implementation of new 
software generations benefits the users and companies; it 
makes the system introduction easier, faster, and less 
prone to disruptions. Future research should further 
investigate how to introduce new generations of CAM 
software and accompany the transformation process. 
VI. 
LIMITATIONS 
Limitations arise from the end users’ reluctance to 
advance research at the expense of the daily business. 
Other limiting factors concern the restriction of automation 
to 
one 
selected 
CAM-planning 
step 
(the 
CAM 
parameterization) in one specific CAM system and the 
application context (well-educated CAM planners in 
German SMEs).  
ACKNOWLEDGMENT 
This research and development project is funded by the 
German Federal Ministry of Education and Research 
(BMBF) within the “Innovations for Tomorrow’s 
Production, Services, and Work” Program (funding 
number: 02J19B081) and implemented by the Project 
Management Agency Karlsruhe (PTKA). The authors are 
responsible for the content of this publication. 
REFERENCES 
[1] A. Csiszar, P. Hein, M. Wächter, A. Verl, and A. Bullinger, 
“Towards a user-centered development process of machine 
learning applications for manufacturing domain experts,” 
Third International Conference on Artificial Intelligence for 
Industries (AI4I), Irvine, CA, USA, 2020, pp. 36-39, doi: 
10.1109/AI4I49448.2020.00015. 
[2] N. Rußkamp, C. Digmayer, and E.-M. Jakobs, “Co-
creation-based Framework for the agile Development of 
AI-supported 
CAM 
Systems,” 
14th 
International 
Conference on Applied Human Factors and Ergonomics 
(AHFE 2023), unpublished. 
[3] H. Belani, M. Vuković, and Ž. Car, “Requirements 
Engineering Challenges in Building AI-Based Complex 
Systems,” 2019 IEEE 27th International Requirements 
Engineering Conference Workshops (REW), 2019, pp. 
252-255, doi: 10.1109/REW.2019.00051. 
[4] M. Hoffmann, R. Drath, and C. Ganz “Proposal for 
requirements on industrial AI solutions,” in Machine 
Learning for Cyber Physical Systems: Selected papers from 
the International Conference ML4CPS 2020, J. Beyerer, A. 
Maier, and O. Niggemann, Eds. Berlin: Springer Vieweg, 
pp. 63-72, 2021, doi: 10.1007/978-3-662-62746-4. 
[5] S. Pütz et al., “An Interdisciplinary View on Humane 
Interfaces for Digital Shadows in the Internet of 
Production,” 15th International Conference on Human 
System 
Interaction 
(HSI), 
 
2022, 
pp. 
1-8, 
doi: 
10.1109/HSI55341.2022.9869467. 
[6] L. Tonejca, G. Mauthner, T. Trautner, V. König, and W. 
Liemberger, “AI-Based Surface Roughness Prediction 
Model for Automated CAM-Planning Optimization,” 2022 
IEEE 
27th 
International 
Conference 
on 
Emerging 
Technologies and Factory Automation (ETFA), 2022, pp. 
1-4, doi: 10.1109/ETFA52439.2022.9921281. 
[7] R. Jiao et al., “Design Engineering in the Age of Industry 
4.0,” Journal of Mechanical Design, vol. 143, 070801, July 
2021, doi: 10.1115/1.4051041. 
[8] S. Martínez-Fernández et al., “Software Engineering for 
AI-Based Systems: A Survey,” ACM Transactions on 
Software Engineering and Methodology, vol. 31, pp. 1-59, 
2022, doi:10.1145/3487043. 
[9] M. Tandi and E.-M. Jakobs “Two Heads are Better than 
One: Co-Creation as a Resource for User Interface Design 
of CAx Systems,” 2019 IEEE International Professional 
Communication Conference (ProComm), 2019,  pp. 71-78, 
doi: 10.1109/ProComm.2019.00019. 
[10] M. Oliveira, A. Bettoni, E. Coscia, and H. Torvatn 
“Applying 
Co-creation 
Principles 
to 
Requirement 
Elicitation in Manufacturing,” in: HCI International 2019 – 
Late Breaking Papers, HCII 2019, Lecture Notes in 
Computer Science, vol 11786, C. Stephanidis, Ed. Cham: 
Springer, pp. 54-61, 2019, doi: 10.1007/978-3-030-30033-
3_5. 
[11] F. T. Piller, C. Ihl, and A. Vossen, “A typology of customer 
co-creation in the innovation process,” SSRN Electronic 
Journal, vol. 4, Dec. 2010, doi: 10.2139/ssrn.1732127. 
[12] T. Benson et al. “Virtual Co-Creation: A Guide to 
Conducting Online Co-Creation Workshops,” International 
Journal of Qualitative Methods, vol. 20, 2021, doi: 
10.1177/16094069211053097. 
[13] F. Burgert, M. Schirmer, M. Harlacher, V. Nitsch, and S. 
Mütze-Niewöhner, Participative elicitation and modeling of 
a CAM planning process for the manufacturing of complex 
components using the K3 notation. Aachen: Institute of 
Industrial 
Engineering 
and 
Ergonomics, 
2022, 
doi:10.18154/RWTH-2022-01188. 
[14] N. Rußkamp et al., “New ways to design next-generation 
CAM systems. An integrated approach of co-creation and 
process modeling,“ in: Human Aspects of Advanced 
Manufacturing. AHFE (2022) International Conference. 
AHFE Open Access, vol 66, W. Karwowski and S. 
Trzcielinski, Eds. USA: AHFE International, 2022, pp. 1-
12, doi: 10.54941/ahfe1002682. 
[15] S. Killich et al., “Task modeling for cooperative work,” 
Behaviour & Information Technology, vol. 18, pp. 325-
338, 1999, doi: 10.1080/014492999118913. 
[16] A. 
Nielen, 
Systematik 
für 
die 
leistungs- 
und 
zuverlässigkeitsorientierte 
Modellierung 
von 
Arbeits-
prozessen mit kontrollflussorientierten Notationssystemen. 
Aachen: Shaker, 2014. 
145
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

