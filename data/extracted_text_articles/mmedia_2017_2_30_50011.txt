Improving Feature Extraction Accuracy for Skin Analysis 
 
Woogeol Kim, Hyungjoon Kim, Eenjun Hwang 
School of Electrical Engineering 
Korea University 
Anam-Dong, Seongbuk-Gu, Seoul, Republic of Korea 
E-mail: {woogulzzang, hyungjun89, ehwang04}@korea.ac.kr 
 
 
Abstract‚Äî In this paper, we revise our skin feature extraction 
method based on cell segmentation to improve the accuracy and 
efficiency of skin feature analysis. Accurate skin feature 
extraction is critical for the evaluation of skin conditions. In 
order to improve the accuracy of analyzing skin features, we use 
the contrast limited adaptive histogram equalization (CLAHE) 
method for contrast enhancement. Also, we use the extended-
minima transform in order to enhance the depth of wrinkles on 
the skin. After conducting watershed transform for cell 
segmentation, we utilize the labeled information of skin cells to 
extract skin features. We consider two types of skin features that 
are important for estimating the skin age of users. They are cell 
features and wrinkle features. To evaluate the performance of 
our revised method, we collected diverse images using two types 
of microscopy cameras and estimated the skin age based on their 
skin features. Through various experiments, we show that our 
revised method achieves 11% increase in analysis accuracy and 
53% decrease in feature extraction time compared to our 
previous work. 
Keywords- Skin analysis; Feature extraction; Wrinkle feature; 
Contrast stretching; Microscopy image. 
 
I. 
INTRODUCTION 
Various factors, such as exposure to sunlight or pollution, 
smoking and excessive drinking are known to accelerate the 
normal skin aging process and eventually lead to premature 
skin aging. Usually, the degree of skin aging has been 
evaluated by dermatologists based on their personal 
experience or knowledge. This is because there is no standard 
method for quantitative and objective evaluation. If such 
method was available, then users would get consistent and 
quantitative information about their skin condition, and hence 
perform suitable treatment for their skin more effectively and 
conveniently. 
In our previous work, we proposed a scheme for skin 
texture aging trend analysis based on diverse skin texture 
features. To extract such features, we cropped microscopy 
skin image, carried out histogram equalization, removed noise 
and then binarized the image using the Otsu threshold. After 
that, we segmented the skin texture into cells by using the 
watershed algorithm and calculated their features [1][2]. 
In this paper, we modify some of the preprocessing steps 
and segmentation method in the previous work to improve 
feature extraction accuracy and reduce processing time. 
Figure 1 shows the overall steps to do that, which consist of 
preprocessing, cell segmentation and feature extraction. In the 
preprocessing, the original image is cropped to reduce the 
effect of vignetting. Then, contrast stretching is applied in 
order to enhance the intensity between skin and wrinkle. 
Denoising filters are applied to the image. In the cell 
segmentation, extended-minima transform and watershed 
algorithm are used for cell-based segmentation. Each cell 
cluster is labeled, and the labeled information is utilized for 
calculating skin features. We extract five features from the 
skin image to analyze the skin condition. In Figure 1, modified 
modules are represented by double line rectangles.   
The remainder of this paper is organized as follows. In 
Section 2, we introduce several related works for skin analysis. 
Detailed techniques for skin segmentation method are 
described in Section 3 and skin feature extraction method is 
described in Section 4. We explain our experiment and 
conclude this paper in Section 5. 
 
 
Figure 1.  Overall scheme of skin feature extraction 
 
II. 
RELATED WORKS 
So far, medical analysis and diagnosis based on biometric 
images have been performed in the various domains. Skin 
analysis is one of the most popular and interesting tasks, since 
skin is the outermost part of the human body. Various methods 
have been proposed 
for 
evaluating 
skin 
condition 
quantitatively using skin images.  
As an effort to detect skin wrinkles, H. Tanaka et al. 
applied a cross-binarization method to digital skin image to 
26
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-548-7
MMEDIA 2017 : The Ninth International Conferences on Advances in Multimedia

get its binary image, and then, the short straight line matching 
method to detect wrinkles from the binary image and measure 
their length [3]. More specifically, for each base line in the 
cross-binarized image, if more than 70% of its pixels are 
marked black, then the line is considered a wrinkle. After that, 
they continue from the end of current base line to create a new 
base line. This repeats until the end of the wrinkle or the end 
of the image is reached. J. Ute et al. measured the topography 
of skin surface using an optical 3D device and showed that 
there is a significant dependency between skin surface 
topography and the age [4]. On the other hand, G. O. Cula et 
al. developed the automatic facial wrinkles detection 
algorithm based on estimating the orientation and frequency 
of the elongated spatial feature, captured via digital image 
filtering [5]. Recently Yow. Ai Ping et al. proposed the 
ASHIMA system framework and showed how to process HD-
OCT (High-Definition Optical Coherence Tomography) skin 
images automatically to measure the epidermal thickness and 
skin surface topography [6]. 
 
III. 
SKIN SEGMENTATION METHOD 
A. Preprocessing 
Direct image processing on microscope image or captured 
image might face several problems if the image is in RGB 
(Red-Green-Blue) form. Usually, dealing with RGB image 
shows less accuracy than dealing with gray image. Other 
typical factors to decrease the accuracy are vignetting effect 
and noises. To avoid these problems, original images need to 
be converted into binary images through preprocessing. In this 
work, pre-processing consists of three steps. First, the original 
image is cropped to reduce the effect of vignetting. Second, 
contrast stretching [7] is applied to make brightness difference 
between skin and wrinkle bigger. Then, adaptive histogram 
equalization is applied to the image. 
 
1) Cropping 
Due to the limitations of the camera and the interference 
of the light source, captured images may have noise and 
vignetting. Vignetting is a phenomenon where the outer edges 
of the images are dark due to the reduction of light at the 
periphery of camera lens, and hence causing the captured 
images to have different color histogram distributions. In 
order to avoid the problem, we cropped 300 by 300 pixels in 
the center of the image, which has the concentrated luminous 
source of the image. 
 
2) Contrast stretching 
Correct detection of skin wrinkles is critical in the skin 
analysis and its accuracy can be improved by clearly 
separating skin and wrinkle pixels in the image. However, 
original images often lack sufficient contrast due to diverse 
variations in the environment such as light source and 
shooting area. Insufficient contrast could make certain areas 
in the image have similar contrast even though they must be 
distinguished. This problem can be moderated by contrast 
stretching. Contrast stretching expands the dynamic range of 
the intensity levels so that it spans the color distance between 
skin and wrinkle. Figure 2 illustrates the effect of contrast 
stretching. 
 
 
 
(a) Original image 
(b) After contrast stretching 
Figure 2.  Example of contrast stretching 
 
 In the figure, we can see that the intensity of the scalp 
pixels is reduced and the color distinction between skin and 
winkle becomes more prominent. 
 
3) Contrast limited adaptive histogram equalization  
Skin wrinkles can be detected using the watershed 
algorithm [8]. However, we observed that some of the 
wrinkles were missing during the detection due to the lack of 
contrast. Hence, before we use the watershed algorithm to the 
skin image, we apply the contrast limited adaptive histogram 
equalization (CLAHE) method to the image to enhance the 
intensity of winkles [9]. Histogram equalization is a gray scale 
transformation used for contrast enhancement. The aim is to 
get an image with uniformly distributed intensity levels over 
the whole intensity scale. The result of histogram equalization 
might be worse compared to the original image since the 
histogram of the resulting image becomes approximately flat. 
For instance, when high peaks in the histogram are caused by 
an uninteresting area, histogram equalization results in 
enhanced visibility of unwanted image area. This means that 
the local contrast requirement is not satisfied, and as a result, 
minor contrast differences are entirely ignored when the 
number of pixels falling in a particular gray range is relatively 
small. 
An adaptive method to avoid this drawback is block-based 
processing of histogram equalization [10]. In this method, an 
image is divided into sub-images or blocks, and histogram 
equalization is performed on each sub-images or blocks. Then, 
blocking artifacts among neighboring blocks are minimized 
by filtering or bilinear interpolation. 
The CLAHE method uses a clip limit to overcome the 
noise problem. That is, the amplification is limited by clipping 
the histogram at a predefined value before computing the 
Cumulative Distribution Function (CDF). The value at which 
the histogram is clipped, the so-called clip limit, depends on 
the normalization of the histogram and thereby on the size of 
the neighborhood region. The redistribution will push some 
bins over the clip limit again, resulting in an effective clip 
limit that is larger than the prescribed limit and the exact value 
of which depends on the image. 
In our work, we need to remove hairs from the gray image. 
Hairs can be mistaken for wrinkles and hence they are the 
27
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-548-7
MMEDIA 2017 : The Ninth International Conferences on Advances in Multimedia

most critical noise in the wrinkle detection. Skin hairs are 
easily removed by a simple threshold filter. 
 
 
 
(a) After hair removal 
(b) After CLAHE 
Figure 3.  Example of CLAHE 
 
 Figures 3 (a) and (b) show images after hair removal and 
after CLAHE method, respectively.  
 
B. Segmentation processing 
In this section, we describe how to segment a skin image 
into wrinkle cells using the extended-minima transform [11] 
and watershed transform. Watershed transform is one of the 
most widely used image segmentation techniques in image 
processing and we use it for segmentation into wrinkle cells. 
Especially, we perform the extended-minima transform before 
the watershed transform in order to increase the accuracy of 
finding wrinkle cells. 
 
1) Extended-minima transform 
Even though watershed transform is widely used for image 
segmentation, it often suffers from the over-segmentation 
problem since regional minima or ultimate eroded points are 
employed for segmenting cells directly. One of the main 
factors that determines the accuracy of segmenting skin image 
by wrinkle cells is how much the minima points are extended. 
In this paper, we revise the extended-minima transform, 
which is the regional minima of the H-minima transform. 
Regional minima are connected components of pixels with a 
constant intensity value, and whose external boundary pixels 
have higher value.  
 
 
 
(a) Extended-minima extraction 
(b) Imposed minima image 
Figure 4.  Example of extended-minima transform 
  
In other words, the result of h-minimum operator is linked 
to the depth of the minima. In a skin image, wrinkle cells 
consist of some minima and maxima. Minima correspond to 
parts of low depth points and maxima correspond to high 
depth points. Therefore, using the extended-minima transform, 
we can increase the depth between wrinkle cell clusters. It can 
help the watershed transform to cluster the wrinkle cells.  
Figure 4 shows an example of the extended-minima transform. 
First, we extract minima from an image and extend the depth 
of the points. The extended minima are shown in Figure 4 (a). 
Figure 4 (b) shows the result after imposing the extended 
minima to original gray scale image.  
 
2) Watershed segmentation 
Image segmentation is a computer analysis of image 
objects to decide which pixel of the image belongs to which 
object. Basically, this is the process of separating objects from 
background, as well as from each other. Watershed transform 
is a powerful and well-known tool for performing image 
segmentation.  
 
 
(a) Overlapping objects 
(b) Distances 
(c) Separated objects 
Figure 5.  Segmentation using watershed transform 
 
Figure 5 shows how to segment two overlapping circles 
using the watershed transform. To segment them, an image 
distance to the background is computed. The maxima of the 
distance (i.e., the minima of the opposite of the distance) are 
chosen as markers, and the flooding of basins from such 
markers separates the two circles along a watershed line. We 
adapt these steps to our skin image, so that pixels of each 
wrinkle cell are clustered. 
 
3) Cell labelling 
Wrinkle cell labelling can be easily done by applying the 
watershed transform to the skin image.  
 
 
 
(a) Labeled image 
(b) Filtered image with valid cells 
Figure 6.  Labelling process 
 
28
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-548-7
MMEDIA 2017 : The Ninth International Conferences on Advances in Multimedia

From the result of watershed transform, we can get a set 
of wrinkle cells. Each cell contains the positions of pixels in 
the cell which belong to same cluster. Sometimes, the 
segmentation result contains unexpected cells with very small 
size, which are usually noise or moles. Since they are not the 
regular wrinkle cell, they should be removed. In Figure 6 (a), 
we can see an example of labelling wrinkle cells. Each cell is 
labeled using a different color.  Figure 6 (b) shows the noise 
cells that have to be removed. The brown cells need to be 
removed by merging into a neighboring cell. Currently, we 
decide the size of noise cells empirically. 
 
IV. 
SKIN FEATURE EXTRACTION 
A. Defining skin features 
We have developed algorithms for extracting various 
features from microscopy images. Our feature extraction 
method is based on the labeled image described previously. 
Before defining these features, we made the assumptions 
presented in Table 1 based on common knowledge of skin [1]. 
 
TABLE 1.    ASSUMPTIONS BASED ON COMMON KNOWLEDGE OF SKIN 
1. Total wrinkle length decreases with age. 
2. Wrinkle width increases with age. 
3. Wrinkle depth increases with age. 
4. Wrinkle cell area increases with age. 
5. The number of cells decreases with age. 
6. Diameter ratio of inscribed circle and circumscribed circle of 
a cell decreases with age. 
7. Total length of lines connecting cross points of a cell 
increases with age. 
 
In this paper, we define five features which are critical in 
the evaluation of aging skin. The five features are cell count, 
average cell area, average cell gradient, total wrinkle length, 
and average wrinkle width. Cell count indicates how many 
cell clusters are in the skin image. Average cell area indicates 
the average area of cell clusters in the skin image. Every 
wrinkle cell has its own shape, and the distortion of the shape 
is relevant to the degree of skin aging. So, it is useful to know 
how much a skin cell is distorted for skin aging estimation. 
For this purpose, we consider the slope of principal horizontal 
axis as distortion of a cell.  
The wrinkle itself is also very important clue for 
estimating the degree of skin aging. We use two wrinkle 
features in this work; the total wrinkle length and the average 
wrinkle width. 
 
B. Calculating skin features 
In this section, we describe how to calculate those five 
features. We first estimate the number of cells by counting the 
number of labeled cells while excluding cells with a size under 
some threshold. 
The average cell area is quite simple to calculate. We can 
get this feature by just dividing the total number of pixels in 
the labeled cells by the number of cells which we just 
described. 
Total wrinkle length can be calculated using the line 
sieving method. This method first counts the pixels on the 
horizontal and vertical texture lines. It then counts the pixels 
along the diagonal line, and estimates the actual wrinkle 
length considering its slope. In the case of single pixel islands 
on the image, we simply count these islands and add the 
number to the total length. 
We can get wrinkle width using Principal Component 
Analysis (PCA) analysis [12]. PCA algorithm is a method of 
calculating Eigen value and Eigen vector by using all data‚Äôs 
covariance and average. The result of segmented line 
(extracted skeleton) is a set of 1ÔÇ¥1 points. These pixels have 
specific direction, thus we can calculate each point‚Äôs direction. 
In order to calculate the direction, we used PCA algorithm. 
When all of points on the skeleton‚Äôs direction are calculated, 
we can get a perpendicular line for each point. Figure 7 shows 
how to calculate average wrinkle thickness. In the figure, each 
white ‚ÄòÔÇ¥‚Äô is skeleton point, and the line passing the skeleton 
point is a normal line. The red circles indicate the intersection 
of line and wrinkle contour. The length between these two 
intersection points is the wrinkle thickness at that point. 
 
 
Figure 7.  Calculating wrinkle width 
 
Cell gradient is calculated for estimating how irregular a 
cell is due to skin aging. In order to measure the cell gradient, 
we used the regionprops function [13] which calculates a set 
of features for each labeled region. One of the major features 
in the result of regionprops is a scalar angle value for each 
labeled region.  
 
 
Figure 8.  Example of calculating angle 
 
29
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-548-7
MMEDIA 2017 : The Ninth International Conferences on Advances in Multimedia

It can be obtained by calculating the angle between the x-
axis and the major axis of the ellipse that has the same second-
moment as the region. Figure 8 illustrates how to calculate the 
angle. 
 
V. 
EXPERIMENTS 
In order to evaluate the performance of our revised scheme, 
we performed several experiments based on the Matlab 
R2016a. The test images were prepared using microscopy 
cameras compatible with smartphone. We constructed a 
dataset of skin images using two cameras shown in Figure 9. 
 
 
 
(a) Camera A 
(b) Camera B 
Figure 9.  Microscopy cameras compatible with smartphone 
 
 One camera has a scale of 50X to 500X, and the other 
camera has a scale of 25X to 400X. We got approximately 300 
skin images from face and 50 skin images from hand using the 
two cameras. 
 
1) Detection accuracy 
Figure 10 depicts the segmentation result after watershed 
transform. The pixels on the segmented lines are matched to 
the pixels on the wrinkles in the binarized image. The 
binarized image can be obtained using the Otsu‚Äôs method [14]. 
A skin image is composed of multiple wrinkle cells with 
different shape and size.  
 
 
Figure 10.  Comparison of cell segmentation and binarized image 
 
We can compute the accuracy of wrinkle cell detection by 
the matching rate of segmented pixels as shown in Eq. (1). 
Basically, the equation counts how many matched pixels exist 
on both images, and then they are divided by the total number 
of pixels on the cell contour lines in Figure 10. 
 
ùê¥ùëêùëêùë¢ùëüùëéùëêùë¶ = 
ùê∂ùëíùëôùëô_ùëêùëúùëõùë°ùëúùë¢ùëü_ùëùùëñùë•ùëíùëôùë† ‚à© ùëäùëüùëñùëõùëòùëôùëí_ùëùùëñùë•ùëíùëôùë†
ùê∂ùëíùëôùëô_ùëêùëúùëõùë°ùëúùë¢ùëü_ùëùùëñùë•ùëíùëôùë†
 √ó 100       (1) 
 
 
Figure 11.  Comparison of detection accuracy 
 
Figure 11 depicts the result. Accuracies of the previous 
method are under 90 percent. On the other hand, we can see 
that accuracies of our revised method are over 95 percent. 
Overall, our revised method achieved about 10 percent 
improvement over the previous method for each dataset.  
 
B. Execution time 
Next, we compared the execution time of our previous 
method and revised method for cell detection. Here, the 
execution time includes all the steps for the preprocessing and 
segmentation. In the case of feature extraction, both methods 
show little difference.  
 
 
Figure 12.  Comparison of excution time 
 
Figure 12 compares the execution time of previous method 
and revised method taken for analyzing one skin image. As 
shown in the figure, the execution time of our revised method 
was about half that of the previous method.  
 
30
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-548-7
MMEDIA 2017 : The Ninth International Conferences on Advances in Multimedia

VI. 
CONCLUSION 
In this paper, we revised our previous scheme for skin 
feature extraction to improve accuracy and reduce cell 
detection time. To improve the accuracy of skin cell detection, 
we used the contrast stretching and CLAHE filter for contrast 
enhancement, and the extend-minima transform to the skin 
image for cell segmentation. We performed several 
experiments to evaluate the accuracy and execution time of 
our revised method. 
Consequently, our revised method improves the accuracy 
of cell detection by about 10 percent for all the image data set. 
Also, the total execution time for cell detection was reduced 
by half compared to our previous work.  
 
ACKNOWLEDGEMENT 
This work was supported by Institute for Information & 
communications Technology Promotion (IITP) grant funded 
by the Korea government (MSIP) (No. R0190-16-2012, High 
Performance Big Data Analytics Platform Performance 
Acceleration Technologies Development). 
 
REFERENCES 
[1] Y. H. Choi, D. Kim, E. Hwang, and B. Kim, "Skin texture 
aging trend analysis using dermoscopy images," Skin Research 
and Technology, vol. 20, no. 4, pp. 486-497, 2014.  
[2] Y.-H. Choi, Y.-S. Tak, S. Rho, and E. Hwang, "Skin feature 
extraction and processing model for statistical skin age 
estimation," Multimedia tools and applications, vol. 64, no. 2, 
pp. 227-247, 2013. 
[3] H. Tanaka et al., "Quantitative evaluation of elderly skin based 
on digital image analysis," Skin research and technology, vol. 
14, no. 2, pp. 192-200, 2008. 
[4] U. Jacobi et al., "In vivo determination of skin surface 
topography using an optical 3D device," Skin Research and 
Technology, vol. 10, no. 4, pp. 207-214, 2004. 
[5] G. O. Cula, P. R. Bargo, A. Nkengne, and N. Kollias, 
"Assessing 
facial 
wrinkles: 
automatic 
detection 
and 
quantification," Skin Research and Technology, vol. 19, no. 1, 
pp. e243-e251, 2013. 
[6] A. P. Yow et al., "Automated in vivo 3D high-definition optical 
coherence tomography skin analysis system," in Engineering 
in Medicine and Biology Society (EMBC), 2016 IEEE 38th 
Annual International Conference of the, pp. 3895-3898, 2016 
[7]  R. C. Gonzalez and R. E. Woods, ‚ÄúDigital Image Processing,‚Äù 
Addison-Wesley, Third edition, 2008. 
[8] L. J. Belaid and W. Mourou, "Image segmentation: a watershed 
transformation algorithm," Image Analysis & Stereology, vol. 
28, no. 2, pp. 93-102, 2011. 
[9] S. M. Pizer, R. E. Johnston, J. P. Ericksen, B. C. Yankaskas, 
and K. E. Muller, "Contrast-limited adaptive histogram 
equalization: speed and effectiveness," in Visualization in 
Biomedical Computing, 1990., Proceedings of the First 
Conference on, pp. 337-345, 1990. 
[10] Y. C. Hum, K. W. Lai, and M. I. Mohamad Salim, 
"Multiobjectives bihistogram equalization for image contrast 
enhancement," Complexity, vol. 20, no. 2, pp. 22-36, 2014. 
[11] P. Soille, Morphological image analysis: principles and 
applications. Springer Science & Business Media, 2013. 
[12] S. Wold, K. Esbensen, and P. Geladi, "Principal component 
analysis," Chemometrics and intelligent laboratory systems, 
vol. 2, no. 1-3, pp. 37-52, 1987.  
[13] A. Othmani, N. Lomenie, A. Piboule, C. Stolz, and L. F. C. L. 
Y. Voon, "Region-based segmentation on depth images from a 
3D reference surface for tree species recognition," pp. 3399-
3402, 2013. 
[14] N. Otsu, "A threshold selection method from gray-level 
histograms," Automatica, vol. 11, no. 285-296, pp. 23-27, 1975. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
31
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-548-7
MMEDIA 2017 : The Ninth International Conferences on Advances in Multimedia

