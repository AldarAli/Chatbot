Blind People’s Navigation Improvements Using Crowdsourcing  
 
Darius Plikynas  
Department of Business Technologies and 
Entrepreneurship 
Vilnius Gediminas Technical University 
Vilnius, Lithuania 
email: darius.plikynas@vgtu.lt 
Audrius Indriulionis 
Department of Business Technologies and 
Entrepreneurship 
Vilnius Gediminas Technical University 
Vilnius, Lithuania 
email: audrius.indriulionis@vgtu.lt
 
 
Abstract-The literature review and survey of the Blind and 
Severely Visually Impaired (BSVI) people showed that BSVI 
are using the same general-purpose or specialized social 
networking means for communication, learning, remote 
working, leisure, navigation as other people. BSVI oriented 
text (and image) to voice, tactile feedback, and other 
specialized mobile apps or software and hardware solutions 
help in this matter. This paper studies how crowdsourcing 
(participatory social networking) can improve navigation and 
orientation capabilities outdoors and indoors, using the 
computer vision-based Electronic Traveling Aid (ETA) 
approach. This study gives insights into the high potential of 
crowdsourcing usage to improve BSVI people’s ETA 
performance. In this regard, this paper delivers a short 
overview, BSVI survey results, and a description of the 
prototype, which we are developing to meet BSVI expectations. 
Provided insights can help researchers and developers to 
exploit social Web and crowdsourcing opportunities for BSVI 
computer vision-based ETA navigation improvements. 
Keywords-social networking; electronic travelling aids; computer 
vision; blind and severely visually impaired; navigation indoors. 
I. 
 INTRODUCTION 
Admittedly, a wide range of general-purpose social 
networks, web 2.0 media apps, and other smart ICT 
(information and communication technology) tools are 
developed to improve people’s daily tasks, including 
navigation and orientation. Although they are not destined to 
meet specialized requirements of BSVI people, but some 
adds make them useful. For instance, text (and image) to 
voice, tactile feedback, and other additional enabling 
software and hardware solutions are helpful for this matter. 
However, complexity and abundance of features pose a 
significant challenge for BSVI persons. According to Raufi 
et al. [1], the volumes of information together with data from 
social networks confuse BSVI users. In this way, web 2.0 
social networks do not guarantee specialized digital content 
accessibility for BSVI users [2]. Some more focused 
approaches are in demand. 
In general, BSVI users are actively involved in social 
networks [3]-[5]. More than 90 % of BSVI persons actively 
use one or more general-purpose social networking sites, 
such as Facebook, Twitter, LinkedIn, Instagram, and 
Snapchat [3][4], and [6]-[8]. However, only a few social 
networking platforms are specifically oriented for BSVI 
users. For instance, BSVI surveys reveal that social 
networking apps are among five most popular mobile apps 
[11]. The majority of BSVI people - who use social media - 
choose Facebook social networks [4][9], and [10]. The usage 
of Twitter was also unusually high, assuming that its simple, 
text-based interface is more accessible to the screen readers 
[4]. 
Next to the general-purpose social networks, BSVI 
people frequently use apps specifically designed for them to 
accomplish daily activities. However, N. Griffin-Shirley et 
al. emphasizes that persons with visual impairments would 
like to see both improvements in existing apps and new apps 
[11]. Below, we give an example of some of the most 
popular navigation apps used for path planning, navigation, 
and obstacle avoidance [12][13], and [3]. 
For instance, Walky Talkie helps blind people in 
navigation, providing real-time haptic feedback [14]. 
However, the accuracy based on the in-built GPS is low. The 
vOICe for Android application maps live camera views to 
soundscapes, 
providing 
the 
visually 
impaired 
with 
augmented reality-based navigation support (see The vOICe 
for Android - Apps on Google Play).  Ariadne GPS works where 
Google Maps are available (see www.ariadnegps.eu/en). In 
addition to navigation functions, it also enables users to 
navigate in large buildings by pre-programming locations. 
BlindSquare provides information to visually impaired users 
about their surroundings. From a social networking 
perspective, BlindSquare is closely linked to FourSquare as 
it collects information about the user’s environment from 
FourSquare [14].  
The above mentioned cases and some other navigation 
apps are mostly based on the pre-developed navigational 
information, but do not provide a real-life support, user 
experience-centric approaches, and participatory Web 2.0 
social networking. On the contrary, there are other real-life 
social apps such as Be my eyes, which enable access to a 
network of sighted volunteers and company representatives 
who are ready to provide real-time visual assistance for the 
orientation, navigation and other tasks at hand [15]. 
In Section 2, we briefly provide a glimpse of BSVI 
people’s survey results concerning their navigation and 
social networking needs and expectations. In Section 3, we 
share some insights concerning navigation and orientation 
for ETA enhancements using participatory Web 2.0 
advantages. Conclusions are provided in Section 4. 
25
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-872-3
eTELEMED 2021 : The Thirteenth International Conference on eHealth, Telemedicine, and Social Medicine

II. 
BSVI PEOPLE’S SURVEY: SOCIAL NETWORKING AND 
NAVIGATION NEEDS 
To define more precisely BSVI persons’ social 
networking needs and expectations concerning navigation 
help, we conducted a survey and semi-structured interview 
of blind people of various ages. In total, 78 EU located BSVI 
persons’ responses were analyzed, of which 25 were 
identified as blind experts (10+ years of experience or active 
interest in using ETAs for the blind). In the survey, some 
questions (out of 40 questions in total) concerned ETA 
navigation functionalities, and others dealt with social 
networking approaches. 
For instance, the question “Are you using the assistance 
of volunteers over electronic means?” (see Figure 1) revealed 
that only 12 % of all 78 respondents use such assistance. It 
indicates that the electronic assistance level is currently 
deficient, bearing in mind the high potential of social 
networks, web 2.0 media apps, smartphones, and other ICT 
(information and communication technology) tools. In other 
words, it points to the lack of enabling real-time, user-
friendly, experience–centric, and participatory Web 2.0 
technologies. 
 
 
 
Figure 1. Survey responses from 78 BSVI persons. The order of the 
questions is piled up from the bottom to the top. 
 
BSVI experts also provided their answers, see Figure 2. 
They were interviewed concerning the usage of smartphone 
apps and Web portals. For instance, the questions, such as 
“What smartphone apps, web portals, and social networks do 
you know, and which of them do you use to communicate 
with sighted people?” or “What smartphone apps, web 
portals and social networks, specifically designed for the 
blind, do you know?” revealed that most popular apps and 
social networks used by BSVI people are Facebook, Twitter, 
LinkedIn, and Snapchat. Besides, BSVI people use 
Telegram, Youtube, Facetime, Google hangouts, Whatsapp, 
Skype, 
Viber, 
Messenger, 
Zello, 
MySpace, 
Tinder, 
TeamTalk, Eskimi apps. Only 5 out of 25 BSVI experts 
mentioned apps or websites specifically designed for the 
blind: Bee my eyes, Telelight – an accessible telegram client, 
Voreil, Talking Communities, FourSquare/BlindSquare, 
Playroom, Applevis.com, Elvis, blindhelp.net, Blindbargens, 
ACB network, RNIB. It indicates wide variety of 
smartphone apps and Web portals often used for everyday 
tasks. 
 
 
Figure 2. Survey responses from 25 BSVI experts. 
 
Next, we turned our attention to the more specific 
questions regarding social networking tools used for 
navigation. For instance, “Are you familiar with social 
networking tools that support sharing of navigation 
information (directions) between the blind and/or sighted 
volunteers?”. Surprisingly, most of the BSVI respondents do 
not know such tools and only a few mentioned What’s app, 
Be my eyes, and Google Groups “Eyes-free group”. Thus, 
social networking tools used for navigation are not very 
popular. During additional interviews, we figured out a few 
more details. For instance, social networking tools are (i) in 
26
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-872-3
eTELEMED 2021 : The Thirteenth International Conference on eHealth, Telemedicine, and Social Medicine

English mostly; do not operate in other national languages, 
(ii) casual voluntaries are not accustomed to deal well with 
the specific BSVI problems, and (iii) applied technology is 
not specialized enough to tailor real-time and high-quality 
help. 
In another question, “Would you be willing to pay for the 
functionality of an electronic travel aid listed below? How 
much?” we identified value-added and monetary estimation 
of each ETA functionality (however, we present here not the 
price itself but relative estimates). About 80 % of the first 
ranked ETA needs included navigation and orientation 
functionalities, such as recognition of stairs, elevators, doors, 
navigation directions, assistance to return to a specific 
location, and so on. Out of the whole price for all twenty 
chosen ETA functionalities, BSVI were willing to pay 18.3% 
for outdoor navigation; 12.9% for indoor navigation; 12.5% 
for recognition of textual and numerical information’ 8.4% 
for recognition of stairs, lifts/elevators, doors, passages and 
pavements/sidewalks; 6% for information about products 
with BAR and QR codes; 5.8% for assistance of remote 
volunteers to interpret sophisticated surroundings in the 
mother tongue;  3.1% for ability (through social networking) 
to record, store and reuse outdoor navigation information;  
2.7% for ability (through social networking) to record, store 
and reuse indoor navigation information; 1.9% for ability to 
share and exchange outdoor navigation directions through a 
specially designed social network; 1.8% for ability to share 
and exchange indoor navigation directions through a 
specially designed social network, and so on. In sum, around 
32% out of the total price, BSVI were willing to pay for ETA 
functionalities, which can be substantially enhanced using 
participatory Web 2.0 social networking. 
These were just a few exemplary questions. However, 
based on the entire survey analysis, we find out some 
perspective niche of research and development in the field of 
navigational ETA solutions. Based on these insights, we 
made some inferences regarding a combination of modern 
enabling technologies, which can be successfully employed. 
In the next section, we give an exemplary case. 
 
III. 
MACHINE VISION-BASED NAVIGATION 
ENHANCEMENTS USING PARTICIPATORY SOCIAL 
NETWORKING 
In this section, we will share a few participatory Web 2.0 
social networking ideas, which could enhance BSVI 
navigation capabilities for traveling, shopping, and other 
everyday mobility tasks. For instance, in the case of real-
time assistance and guidance' for traveling routes, the 
primary objective of the specialized mobile app's with 
wearable services is to assist a visually impaired or blind 
user in navigating from the chosen point A to point B using 
reliable directions given from an online community. In this 
case, a phone with wearable service would be able to (i) 
stream live video to a crowd server (Social Navigation 
Networking Services) of sighted users through internet/WiFi, 
(ii) receive real-time feedback through assistance and 
guidance instructions. For instance, SoNavNet is designed 
for connected users of the social network to share navigation 
information with the intent of providing more personalized 
navigation methods, routes based on member experience 
rather than the shortest distance [16]. SoNavNet is based on 
the experience-based approach - through communication 
(using online social media) and collaboration (sharing and 
exchanging experiences), BSVIs can find suitable routes 
both n outdoors and indoors that can meet their specific 
needs and preferences. SoNavNet, as an online social 
navigation network system, facilitate sharing and exchanging 
experiences on Points Of Interest (POIs), Routes Of Interest 
(ROIs), and Areas Of Interest (AOIs) [16]. 
The authors in [17] designed a Tales4Us platform to 
promote creativity, collaboration, and learning process, for a 
BVSI and other communities to share their shopping stories 
through a specialized social network. The application has 
such major functionalities: (i) the user can play other users’ 
shopping stories, (ii) users can record new stories and share 
it with the community.  
In the case of “Seeing-eye person” proposed in [18], a 
crowdsourcing approach enables multimedia data sharing 
and services for the BSVI navigation.  The goal of this work 
is to provide user-accessible crowd services (uniquely 
tailored for visually impaired), flexible (with friendly HCI 
and APIs for the ease of plugging in new apps to motivate 
online volunteers for their services), and efficient (near real-
time response, and a balanced workload between mobile 
phone, the back end system, and the different types of users). 
The authors in [19] dedicate their general-purpose social 
navigation approach for any users, including BSVI people 
with impaired mobility. The system allows sharing 
knowledge between them, reviewing an existent place freely, 
or uploading new ones to the global database, improving the 
application 
content. 
The 
ParticipAct 
infrastructure, 
implementing calls to different external API services, as 
geocoding, localization, routing calculation, and POI entities 
download, enabling a new set of functionalities. However, 
the system does not include data quality support in the sense 
of automatic filtering-out of erroneous inputs, as (possibly) 
fake entities. 
In our ETA research, we also use the onboard sensors of 
a smartphone (iPhone or Android Phone), such as a camera, 
compass, GPS, and accelerometer, to assist the navigation of 
a blind user, see Figure 3. The primary function of mobile 
computing is to stream the video and other sensory 
information to the crowd server so that volunteers can use 
the information to provide service. We plan further to tailor 
these techniques in order to address the unique challenges in 
crowd-assisted navigation, such as the smoothness and 
reliability of visual labeling of routes recorded by volunteers, 
and the contextual information of video frames. 
We infer that some of the navigational instructions might 
also be adapted from the machine vision algorithms that 
provide direction information [20]. It lays the potential to 
aggregate all the available instructions into a single one that 
will be returned to the blind user. We need to consider the 
expertise, reliability, and reputation (low reputation might 
indicate noisily, or even malicious volunteer, which we want 
to filter) in the data aggregation process. Besides, we also 
need to consider the synchronicity of data coming from 
27
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-872-3
eTELEMED 2021 : The Thirteenth International Conference on eHealth, Telemedicine, and Social Medicine

different volunteers and the frequency of instructional 
updates. 
 
 
Figure 3. Social navigation network services enabled by mobile device for 
BSVI 
 
The seamless integration of AI-based vision algorithms 
in the crowdsourced social networking solutions can provide 
additional feedback. Vision-based algorithms can be tested 
for accuracy against live information from human 
volunteers. Along with the on-line process and data 
aggregation, an offline analysis will in turn help better tailor 
context-aware human-computer interfaces and further 
improve the online analysis tasks. 
Based on the survey results and above mentioned 
considerations, we are reporting an interim result - a 
prototype of a wearable system configured to help as an 
offline and online web-crowd assisted decision support 
system for BSVI people when orientating and navigating in 
indoor environments (for instance, public institutions, 
schools, hospitals, airports, stores, and other buildings). 
Admittedly, there is a lack of feasible indoor navigational 
solutions that would work well without GPS signal and 
prearranged infrastructural indoor installations (such as WI-
FI routers, beamers, RFID tags). Our survey of blind experts 
has shown that after outdoor navigation, the second most 
demanded and not satisfied need concerns ETA solutions for 
indoor navigation and orientation [12] and [13]. We figured 
out that BSVI persons need ETA for orientation and 
navigation in unfamiliar indoor environments to detect and 
recognize desired indoor destinations such as rooms, WC, 
staircases, elevators, avoiding obstacles on their way. In 
Figure 4, we depicted key guidelines for the ETA system’s 
interface with the BSVI person indoors.  
 
 
 
 
Figure 4. Web crowd (volunteers) assisted method for indoor routing enhancement and optimization, using ETA system functionality 
 
The presented system is a compound technology of 
innovatively adapted hardware devices like the 3D ToF IR 
camera, RGB camera, specially designed tactile display with 
EMG sensors, bone-conducting earphones, controller, and 
28
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-872-3
eTELEMED 2021 : The Thirteenth International Conference on eHealth, Telemedicine, and Social Medicine

IMU, GPS, light detector, compass sensors. GSM 
communication can be implemented as a stand-alone device 
or smartphone that can work as an intermediate processing 
device. Passive sensors passively collect environmental data, 
whereas, active sensor like 3D ToF IR camera emits IR light 
to estimate distances to the objects. Multi-sensory data is 
used to (i) find needed objects, (ii) locate obstacles, and (iii) 
infer users' location in an indoor environment in order to 
help navigate. The devices and sensors observe the 
environment in real-time and send data via the controller to 
the machine learning processing, where features' extraction, 
object recognition, and data storage occur in the web cloud 
database server, see Figure 4. The prototype integrates 
devices and interfaces using modern technologies and 
methods from machine learning and computational vision 
domain.  
From the point of view of the end-user, this prototype 
distinguishes 
among 
other 
related 
wearable 
indoor 
navigational ETA novelties in the sense of a) intelligent user 
interface integrity based on unique tactile display and audio 
instructions, b) hands-free intuitive control interface using 
EMG (electromyography), c) comfortable user-orientated 
headband design, d) machine learning-based real-time 
guidance, e) web-crowd assistance while mapping indoor 
navigational routes and solving problematic situations on the 
way.   
For efficient indoor navigational performance, the 
presented ETA system is used in three consequently 
interconnected modalities: (i) Web crowd assistance when 
volunteers go through buildings and gather step-by-step 
indoor routes' information that is processed in the web cloud 
server and stored in the online DB; (ii) BSVI usage of web 
cloud DB indoor routes when they need guided navigational 
assistance; (iii) in complex indoor situations (such as getting 
lost, encountering unexpected obstacles and situations), the 
BSVI ETA system’s multisensory data stream can be used in 
real-time to get voice-guided help from volunteers familiar 
with the particular route or building. 
 
IV. CONCLUSIONS 
This paper studied how crowdsourcing (participatory 
social networking) can improve navigation and orientation 
capabilities outdoors and indoors, using the computer 
vision-based ETA (electronic traveling aid) approach. This 
study gave insights into the high potential of crowdsourcing 
usage to improve BSVI people’s ETA performance. In this 
regard, this paper delivered a short overview, BSVI survey 
results, and a description of the prototype, which we are 
developing to meet BSVI expectations. Provided insights 
can help researchers and developers to exploit social Web 
and crowdsourcing opportunities for BSVI computer vision-
based ETA navigation improvements. More specifically, 
semi-structured survey revealed a clear lack of participatory 
Web 2.0 social networking usage for the navigation and 
orientation outdoors and indoors. From one side, it is related 
with the lack of BSVI people’s trust and confidence in the 
corresponding ETA technological solutions. From another 
side, it is related with the lack of enabling real-time, user-
friendly, user experience–centric, and participatory Web 2.0 
social networking technologies. 
We found that current research in the area of online 
social navigation network systems, facilitate sharing and 
exchanging experiences on POIs, ROIs, and AOIs. We 
inferred that some of the navigational instructions might 
also be adapted from the machine vision algorithms that 
provide direction information [20]. The seamless integration 
of AI-based vision algorithms in the crowdsourced social 
networking solutions can provide additional feedback. 
Vision-based algorithms can be tested for accuracy against 
live information from human volunteers. 
In summary, participatory Web 2.0 social networking 
systems can enable the integration of smart algorithms 
together with BSVI and sighted people’s best experiences 
while traveling, navigating, and orientating in outdoor and 
indoor environments. It helps to build and continuously 
update real-time metrics of reachable and unreachable POIs 
to the effect that routes could be averaged, erroneous routes 
eliminated, and user experience-based optimal solutions 
found using various optimization approaches (like min-max 
entropy calculation) [21]-[23]. In this way, crowdsourced 
navigation social platforms with real-time video streaming 
and analysis get advantages that none stand-alone 
navigation systems could ever achieve [9]. It is appealing; 
even there are still several unresolved tasks like data 
reliability, 
integrity, 
synchronicity, 
cross-platform 
compatibility [10] and [24].  
The presented ETA system uses crowdsourcing when 
volunteers go through buildings and gather step-by-step 
indoor routes' visual and other sensory information that is 
processed, using machine learning algorithms, in the web 
cloud server and stored for the BSVI usage in the web cloud 
DB. 
In the presented paper, we provided some framework 
and concepts of ETA enhancement for indoor guided 
navigation, using outsourcing of routes mapping. Next, we 
are step by step developing a wearable ETA device 
supplemented with the social networking interface, wherein 
sighted users take an active part in mapping indoor routes 
and helping BSVI persons in complex situations. 
In time, a participatory web 2.0 social networking 
platform – something like a worldwide “Visiopedia - with 
big, labeled, crowdsourced, almost real-time updated, and 
publicly available outdoor and indoor navigational database 
for BSVI could emerge. It would enable much more 
efficient and reliable use of AI-based learning algorithms 
[12] and [13]. 
 
ACKNOWLEDGMENT 
This project has received funding from European 
Regional Development Fund (project No 01.2.2-LMT-K-
718-01-0060) under grant agreement with the Research 
Council of Lithuania (LMTLT). 
29
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-872-3
eTELEMED 2021 : The Thirteenth International Conference on eHealth, Telemedicine, and Social Medicine

 
REFERENCES 
 
[1] B. Raufi, M. Ferati, X. Zenuni, J. Ajdari, I. F. Ismaili, 
“Methods and techniques of adaptive web accessibility for the 
blind and visually impaired,” Procedia - Social and 
Behavioral Sciences, vol. 195(2015), pp. 1999 – 2007, 2015. 
[2] M. Ferati, B. Raufi, A. Kurti, B. Vogel, “Accessibility 
requirements for blind and visually impaired in a regional 
context: An exploratory study. 2nd International Workshop on 
Usability 
and 
Accessibility 
Focused,” 
Requirements 
Engineering, UsARE 2014, pp. 13-16, 2014. 
[3] M. Elbes, A. Al-Fuqaha, “Design of a social collaboration and 
precise localization services for the blind and visually 
impaired,” Procedia Computer Science, vol. 21(2013), pp. 
282 – 291, 2013. 
[4] E.Brady, Y. Zhong, M. R. Morris, J. P. Bigham, 
“Investigating the appropriateness of social network question 
asking as a resource for blind users,” Proceedings of the 2013 
conference on Computer supported cooperative work, San 
Antonio, Texas, USA, pp. 1225-1236, February 23–27, 2013. 
[5] J. Brinkley, N. Tabrizi, “A Desktop Usability Evaluation of 
the Facebook Mobile Interface using the JAWS Screen 
Reader with Blind Users,” Proceedings of the Human Factors 
and Ergonomics Society 2017 Annual Meeting, pp. 828 – 
832, 2017. 
[6] Sh. Wu, L. Adamic, “Visually impaired users on an online 
social network,” Proceedings of the SIGCHI Conference on 
Human Factors in Computing Systems, pp. 3133-3142, 2014. 
[7] V. Voykinska, Sh. Azenkot, Sh. Wu, G. Leshed, “How blind 
people interact with visual content on social networking 
services,” Proceedings of the 2016 conference on Computer 
supported cooperative work, San Francisco, CA, USA, pp. 
1584–1595, February 27-March 02, 2016. 
[8] S. Qiu, J. Hu, G. W. M. Rauterberg, “Mobile social media for 
the blind: Preliminary observations,” Proceedings of the 
International Conference on Enabling Access for Persons with 
Visual Impairment (ICEAPVI), Athens, Greece, pp. 152-156, 
12-14 February 2015. 
[9] B. Della Líbera, C. Jurberg, “Teenagers with visual 
impairment and new media: A world without barriers,” 
British Journal of Visual Impairment, vol. 35(3), pp. 247–256, 
2017. 
[10] I. Tjostheim, I. Solheim, K. S. Fuglerud, “The importance of 
peers for visually impaired users of social media,” 
Proceedings of the 6th IASTED International Conference on 
Human-Computer Interaction, pp. 23–30, 2011. 
[11] N. Griffin-Shirley, D. R. Banda, P. M. Ajuwon, J. Cheon, J. 
Lee, H. R. Park, S. N. Lyngdoh, “A survey on the use of 
mobile applications for people who are visually impaired,” 
Journal of Visual Impairment & Blindness, vol. 111(4), pp. 
307-323, 2017. 
[12] D. Plikynas, A. Žvironas, A. Budrionis, A., M. Gudauskis, 
“Indoor Navigation Systems for Visually Impaired Persons: 
Mapping the Features of Existing Technologies to User 
Needs”. Sensors, 20(3), 636, 2020. 
[13] D. Plikynas, A. Žvironas, M. Gudauskis, A. Budrionis, 
“Research Advances of Indoor Navigation for the Blind 
People: A Brief Review of Technological Instrumentation.” 
IEEE Instrumentation & Measurement Magazine, vol. 23(4), 
pp. 22-32, 2020.  
[14] Á. Csapó, G. Wersényi, H. Nagy, T. Stockman, “A survey of 
assistive technologies and applications for blind users on 
mobile platforms: A review and foundation for research,” 
Journal on Multimodal User Interfaces, vol. 9 (4), pp. 275-
286, 2015. 
[15] A. Mauro, K. Wolf, A. Brock, and N. Henze. "Remote 
assistance for blind users in daily life: A survey about be my 
eyes." In Proceedings of the 9th ACM International 
Conference on PErvasive Technologies Related to Assistive 
Environments, pp. 1-2. 2016. 
[16] E. Sheepy, S. Salenikovich. “Technological Support for 
Mobility and Orientation Training: Development of a 
smartphone 
Navigation 
Aid.” 
Proceedings 
of 
World 
Conference on E-Learning in Corporate, Government, 
Healthcare, and Higher Education 2013 (pp. 975-980). T. 
Bastiaens & G. Marks (Eds.), 2013. 
[17] N. Karlsson, E. Di Bernardo, J. Ostrowski, L. Goncalves, P. 
Pirjanian, M.E. Munich, "The vSLAM Algorithm for Robust 
Localization and Mapping," Proceedings of the 2005 IEEE 
International Conference on Robotics and Automation (ICRA 
2005), 2005. pp. 24-29. doi: 10.1109/ROBOT.2005.1570091 
[18] B. 
Zimmerman, 
A. 
Ozcelik, 
D. 
Roongpiboonsopit, 
“SoNavNet: A Framework for Social Navigation Networks”. 
In International Workshop on Location Based Social 
Networks (LBSN’09). Seattle, WA, November 3-6, 2009.  
[19] S. Vitek, M. Klima, L. Husnik, D. Spirk, "New possibilities 
for blind people navigation". In proceedings of 2011 
International Conference on Applied Electronics (AE): 1-4, 
2011. 
[20] G. Olmschenk, C. Yang, Z. Zhu, H. Tong and W. H. Seiple, 
"Mobile Crowd Assisted Navigation for the Visually 
Impaired," 2015 IEEE 12th Intl Conf on Ubiquitous 
Intelligence and Computing (UIC-ATC-ScalCom), Beijing, 
pp. 324-327, 2015. 
[21] B. K. Kanan, N. Kothari, C. Gnegy, H. Gedaway, M. F. Dias, 
M. B. Dias, “Localization, Route Planning, and Smartphone 
Interface for Indoor Navigation". In Cooperative Robots and 
Sensor Networks, pp. 39-59. Springer Berlin Heidelberg, 
2014. 
[22] H. K. Gedawy, “Designing an Interface and Path Translator 
for a Smart Phone-Based Indoor Navigation System for 
Visually Impaired Users”. Masters Thesis, Carnegie Mellon 
University, 2011. 
[23] K. Nisarg, B. Kannan, E. D. Glasgwow, M. B. Dias, “Robust 
indoor localization on a commercial smart phone”. Procedia 
Computer Science 10: 1114-1120, 2012. 
[24] E. Pissaloux, R. Velazquez (Eds.), “Mobility of Visually 
Impaired 
People: 
Fundamentals 
and 
ICT 
Assistive 
Technologies”. Springer, 2018. 
 
 
 
 
 
30
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-872-3
eTELEMED 2021 : The Thirteenth International Conference on eHealth, Telemedicine, and Social Medicine

