Real-Time Gesture Classification for Monitoring Elderly Physical Activity Using a 
Wireless Wearable Device 
Alexandre Calado1, Pedro Leite1, Filomena Soares1, 
Paulo Novais1 and Pedro Arezes1 
1Algoritmi Centre, University of Minho 
Guimarães, Portugal 
e-mail: alexandreluiscalado@gmail.com, 
a66161@alunos.uminho.pt, fsoares@dei.uminho.pt, 
pjon@di.uminho.pt, parezes@dps.uminho.pt 
Filipe Sousa2 and Joana Silva2 
2Fraunhofer Portugal Research Centre, 
Porto, Portugal 
e-mail: filipe.sousa@fraunhofer.pt, 
joana.silva@fraunhofer.pt 
 
 
Abstract—Gestures are part of communication between 
humans, however, they can also have an important role to play 
for improving human-machine interaction. Moreover, gesture 
recognition can have relevant applications for activity 
monitoring in older adults. This paper proposes the use of the 
Pandlet (a wearable wireless device that features a 3-axis 
accelerometer, 
gyroscope 
and 
magnetometer) 
for 
the 
recognition of two distinct throwing movements performed in 
the Boccia game. The results from this paper will be inserted 
into the iBoccia framework, created with the aim of monitoring 
and promoting physical activity on the elderly by playing the 
game of Boccia. The recognition of throwing gestures shall 
allow a caregiver to follow the performance of the elder 
throughout the game and the force associated with each throw, 
which can be important for identifying muscular diseases. 
Furthermore, it can be used for the elders to interact with a 
user interface that displays the current game score. To achieve 
the goal proposed by this paper, a Support Vector Machine 
(SVM) was trained with data extracted from eight subjects 
regarding two types of throws used in the Boccia game and 
movements performed when the player is not playing. The 
trained model was afterwards implemented for real-time 
classification and tested on four subjects. Overall, the average 
test accuracy was of 75±8%. These results show that the model 
is able to successfully recognize different throwing gestures 
and encourages its use on the iBoccia framework. 
Keywords-Gesture Recognition; Activity Monitoring; SVM; 
Boccia 
I. 
 INTRODUCTION 
Gestures are an essential part of general human 
interaction. Whether it involves physical movements of the 
fingers, hands, arms, head or any other part of the body, 
gestures are usually performed with the intent of conveying 
important information to the interlocutor or interacting with 
the surrounding environment [1].  
Gesture recognition can also be used for further 
improving human-machine interaction. The current trend of 
applications based on virtual reality demands a more suitable 
type of interaction that traditional devices, such as mouse 
and keyboard, cannot cope with [2]. Moreover, it can have 
an important role to play in a wide range of applications, 
such as sign language recognition [3], improve airport 
security [4] and various health applications, such as physical 
rehabilitation in individuals with motor disabilities [5] or the 
diagnosis of neurological disorders [6]. However, the focus 
of this paper will fall on elderly activity monitoring. 
The work described by this paper is based on the 
exploitation of machine learning algorithms for detecting, in 
real-time, different types of ball-throwing movements 
performed by elders during a Boccia game. This is intended 
to be the follow up of previous work [7] and the obtained 
algorithm will be posteriorly annexed to the iBoccia 
framework [8][9]. This framework was created with the 
purpose of monitoring the bio-signals of the elders while 
they play Boccia, simultaneously motivating them to practice 
physical activity by enhancing the overall game experience. 
It comprehends an User Interface (UI) that displays, to the 
elders, the score of the game in real-time through the use of a 
computer vision algorithm [10][11] and an UI designed for 
the caregivers. In the latter, it is possible to keep track of 
information related with the heartbeat, stress levels and game 
performance from each of the players throughout several 
games. The data necessary is acquired using various sensors 
non-wearable and wearable sensors, including the Pandlet 
[12], a wireless wearable device developed by Fraunhofer.  
In the present paper, this device was used to extract 
inertial data from various subjects and train a multiclass 
Support Vector Machine (SVM) model. The trained model 
was afterwards used for classifying data obtained from the 
Pandlet in real-time. For this task, three distinct classes were 
considered: underarm throw, overarm throw and a class 
dedicated to all the movements performed by the player 
different from the latter. 
Considering the aforementioned remarks, recognizing the 
players’ throwing movements would make possible for the 
caregiver to identify what type of throws the elder executed 
throughout the game, along with the force applied in each 
throw, which is easily computed from the accelerometer 
data. Most importantly, posterior analysis of this data could 
allow the caregiver to observe the evolution of the throwing 
force over time, which could help identifying potential 
muscular diseases that often occur at an old age. 
This paper is structured as follows. Section II presents a 
brief literature review regarding gesture recognition and 
activity monitoring in old adults. Section III describes the 
used methodology for training and testing the SVM model 
164
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

and section IV displays the attained results. Finally, Section 
V addresses the final remarks and future work.  
II. 
LITERATURE REVIEW 
Currently there are three main approaches for gesture 
recognition: vision based without markers [13][14], using 
coloured markers [15][16] and using wireless devices 
integrating inertial sensors, such as the Pandlet. Considering 
the latter, Hidden Markov Models (HMM) have been 
frequently used in various works related with gesture 
recognition. Positive outcomes have been obtained using this 
model. For instance, Schlömer et al. [17] employed a Wii-
controller for the recognition of five gestures. The average 
accuracy was of 90%. On the other hand, Wilson et al. [18], 
compared HMM with Linear Time Warping (LTW) and 
Dynamic Time Warping methods (DTW), by means of 
accuracy, for evaluating the classification of seven gestures 
using a wireless device with inertial sensors. The results 
showed that HMM proved to be the best approach, achieving 
an accuracy of 90.43%. Despite HMM’s popularity in this 
type of applications, various other approaches have been 
explored regarding classification strategies including the use 
of Artificial Neural Networks (ANN) [19] and SVM [20], 
which also produced accurate results. Previous work [7] 
included the use of the latter with a DTW kernel for the 
offline classification of the overarm and underarm Boccia 
throwing movements. The accuracies obtained with the data 
extracted from the Pandlet were, however, shadowed by the 
accuracies obtained using the Kinect (66.7% and 80%, 
respectively).  
There are five main groups of activity monitoring 
technology in the elderly [21]: passive infrared sensors, 
body-worn sensors, video monitoring, sound recognition and 
multicomponent approaches. Regarding body-worn sensors, 
the works found in the literature mainly focus on recognizing 
daily activities performed by the elderly in order to assess 
their health status [22], based on the premise that mobility is 
a good health indicator. Najafi et al. [23] used a kinematic 
sensor attached to the chest to detect sitting, standing and 
lying body positions, along with periods of walking and 
postural transitions. 
Due to the decline of muscular strength, which is 
characteristic of old age, it is also essential to detect falls, 
which can be also found abundantly in the literature [24], 
[25]. For instance, Kang et al. [26] used a single 3-axis 
accelerometer placed on the subject’s waist to recognize, 
besides daily activities as seen in Najafi et al., an emergency 
state such as a falling situation. This system was tested on 
five healthy young subjects and the attained detection rate 
was of 96%.  
To the best of the authors’ knowledge, no other works 
regarding the use of gesture recognition applied to Boccia 
were found in the literature. However, some studies were 
performed regarding the kinematic analysis of the throwing 
movement in individuals with cerebral palsy [27][28]. 
III. 
METHODS 
This section addresses the used methodology for 
acquiring data with the Pandlet, along with a brief 
description about this device. This is followed by the 
strategies used for feature selection and training of an SVM. 
Finally, the used approach for testing the model is described.  
A. The Pandlet 
As stated in Section 1 of this paper, the Pandlet is a 
wireless wearable device developed by Fraunhofer. It can be 
placed on the individual’s wrist as an armbrace and 
embodies 
a 
3-axis 
accelerometer, 
gyroscope 
and 
magnetometer, enabling the tracking of the user’s 
movements. It also features an Application Programming 
Interface (API), which allows the communication via 
Bluetooth with Windows, Linux and Android platforms. 
For the purpose of this paper, a 50 Hz sampling was 
enabled. Furthermore, a total of sixteen attributes were 
extracted in each acquisition: the orientation, in Euler angles 
(pitch, yaw and roll) and quaternions, along with the values 
from the accelerometer, gyroscope and magnetometer for 
each axis. 
B. Data Acquisition 
Two throwing gestures were considered, the overarm 
throw and the underarm throw, which are both depicted in 
Fig. 1. During a game of Boccia, these gestures are typically 
used by the player with the intention of hitting the target ball, 
which is called the jack [29].  
 
 
 
Figure 1.  On the left: the overarm throw; On the right: the underarm 
throw 
Eight subjects with 24±1 years of age were selected for 
the task at hand. Since the elders from the nursing home 
where the final system will be tested play while sitting, the 
subjects were asked to sit in a chair. The Pandlet was 
afterwards placed in the subject’s right wrist. 
A ball, used to act as the jack, was placed about 8 meters 
away from the sitting subject. The subject was then asked to 
throw the ball using the underarm throw fifty times and 
using the overhand throw another fifty times, always with 
the intent of hitting the jack and using the right arm. Every 
throwing 
movement 
was 
recorded 
for 
2 
seconds, 
immediately after the subject was given a signal to start. 
Thus, fifty recordings of each movement were obtained for 
each of the subjects. Moreover, in between the execution of 
the throws, the natural movements of the player would be 
recorded. Much like the other classes, fifty recordings of 2 
165
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

seconds were performed. This was done so that the algorithm 
could recognize when the user is not currently playing. 
Overall, a total of 1200 recordings were performed. 
C. Training the Model 
Regarding the training of the model, ten of the attributes 
were considered: the orientation in quaternions, plus the 
acceleration and angular speed for each axis. The 1200 data 
windows with 2 seconds of length were afterwards used to 
train, without any further feature extraction, a multi-class 
SVM with a linear Kernel and Sequential Minimal 
Optimization (SMO) learning. The decision of using an 
SVM was based on previous work [7]. Besides, according to 
the literature, good results have been obtained using an SVM 
for gesture recognition with wireless devices [30][31][32]. 
The training of the SVM and its subsequent real-time 
implementation were performed by using the Accord.NET 
framework [33]. This framework offers multiple applications 
for scientific computing in .NET, such as statistical data 
processing, machine learning and pattern recognition. 
Moreover, it features a wide selection of classifiers, kernel 
functions, performance measuring techniques and hypothesis 
tests.  
D. Testing the Model 
The training of the model was followed by its real-time 
implementation. For classification purposes, windows with 2 
seconds of length were used with no overlapping. 
Testing protocol was similar to what was described in 
subsection B. In total, four subjects with 24.5±1.0 years of 
age participated in the test. The subjects selected for testing 
were different from the ones selected for data acquisition. 
This was done to test the system’s robustness and avoid 
influence from overfitting. 
The subject was invited to sit on a chair and the Pandlet 
was placed on his/her right wrist. Afterwards he/she was told 
to execute all throwing movements with the right arm. 
Twenty balls were given to the subject and the jack was 
placed about 8 meters in front of him/her. The subject was 
then asked to throw ten of the twenty balls using the overarm 
throw movement and the remaining ten using the underarm 
throw movement, always with intent of hitting the jack. The 
obtained results are presented in the following section. 
IV. 
RESULTS 
Table I presents the average recognition accuracy 
confusion matrix, considering the computed results from all 
the subjects during testing. Class A refers to the underarm 
throw, B to the overarm throw and C to any movement that 
differs from a throw. All percentages refer to accuracy. 
TABLE I.  
AVERAGE RECOGNITION ACCURACY CONFUSION MATRIX 
 
Predicted Classes 
A 
B 
C 
Actual 
Classes 
A 
80% 
- 
20% 
B 
- 
70% 
30% 
 
For evaluation purposes, the classifier’s output was only 
considered when throwing movements were executed by the 
subject. Thus, each time the subject performed a throw, the 
output label was noted. 
As it can be observed in Table I, during testing, the 
model did not mislabel any underarm throw as an overarm 
throw or vice-versa. Instead, when a throwing movement 
was mislabelled, it was always classified as class C (non-
throwing movement). 
The obtained average accuracies for each subject can also 
be observed in Table II. 
TABLE II.  
AVERAGE ACCURACIES OF EACH SUCBJECT 
Subject 
Accuracy (%) 
1 
65 
2 
75 
3 
85 
4 
75 
 
Overall, the total average accuracy for throwing gestures 
recognition was of 75±8%. 
V. 
FINAL REMARKS 
The work described in this paper focused on the training 
of a linear SVM and subsequent implementation for real-
time classification. The model, trained with data acquired 
from eight subjects, was used for the recognition of two 
throwing movements used in the game of Boccia: the 
overarm and the underarm throw. Furthermore, it was also 
used to recognize when the player is idle, i.e., any movement 
performed by the used that differs from a throw. Thus, this 
classification problem comprised three classes which, in this 
paper, were identified as classes A, B or C. 
The results from the real-time testing phase showed that 
classification achieved an average accuracy of 75±8%, 
showing that the system successfully recognizes and 
differentiates between the two throwing gestures and other 
movements performed by the player while “idle”. 
The system recognized the underarm throw more 
efficiently, obtaining an 80% accuracy, comparing to the 
70% obtained for the overarm throw. This difference could 
be justified by the fact that, during data acquisition for 
training, subjects performed the underarm throw more 
similarly amongst themselves, oppositely to the overarm 
movement, in which the execution varied from subject to 
subject.  
Another positive aspect is that the classifier did not 
misclassify class A as class B and vice-versa, which appears 
to mean that the data from both throws differs sufficiently for 
the algorithm to not misclassify one for another. 
However, the accuracy considerably varies between some 
of the subjects, which is one of the downsides of the 
proposed system. This shows that each subject has a different 
method of throwing, which might differ substantially from 
the recorded gestures contained in the data set used for 
training. This might be a constraint for testing the system 
during a real Boccia game situation, due to the probability of 
the elders having very different throwing techniques amongst 
166
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

themselves, therefore, it is imperative to have a robust 
model. Having this into account, the usage of other 
classification techniques should be used for further 
improving of the results, such as feature extraction, enable 
overlapped windows for real-time classification or even 
using other kernels and classifiers. Furthermore, more data 
should be acquired from different subjects in order to have a 
more extensive and variable training set, thus increasing the 
model’s robustness. 
Regarding future work, it is intended to implement this 
system in the iBoccia framework for gesture recognition. As 
stated in Section I from this paper, this framework comprises 
two UIs, one for the caregiver to monitor the elder’s physical 
activity and another which displays the game score, in real-
time, for the elders. The implemented algorithm for gesture 
recognition will allow the caregiver to keep track of the 
different throwing movements performed in each game by 
the elders. Thanks to the accelerometer data and knowledge 
of the approximate weight of a Boccia ball (0.275 kg) it is 
also possible to compute the approximate force applied by 
the player during the throw and plot this data for later 
consultation, thus allowing the caregiver to detect decreases 
in the elder’s strength and identify muscular diseases 
characteristic of old age. 
On the other hand, the results from the work described in 
this paper will be also useful for the elders to interact 
indirectly with the UI that displays the current game score. 
By using gesture recognition, it can be possible for the 
system to automatically detect when a player’s turn is over 
and notify the next player that his/her turn has started by 
showing the respective elder’s photo and name on the screen. 
This can further motivate the elders to play Boccia by 
enhancing the game experience. 
In addition, the proposed system is predicted to be tested 
during a Boccia match played in a nursing home. Bearing 
this in mind, it is pertinent to use data acquired from the 
elders during the match for adding to the data set used to 
train the model. The results, as seen in this paper, will be 
evaluated using accuracy as performance metric. 
Overall, the results obtained with the proposed system 
are encouraging and allow the further development of 
innovative solutions for monitoring and motivating elder 
physical activity. 
ACKNOWLEDGMENTS 
This article is a result of the project Deus Ex Machina: 
NORTE-01-0145-FEDER-000026, 
supported 
by 
Norte 
Portugal Regional Operational Program (NORTE 2020), 
under the PORTUGAL 2020 Partnership Agreement, 
through the European Regional Development Fund (ERDF). 
REFERENCES 
[1] 
S. Mitra and T. Acharya, “Gesture recognition: A survey,” 
IEEE Trans. Syst. Man Cybern. Part C Appl. Rev., vol. 37, 
no. 3, pp. 311–324, 2007. 
[2] 
R. Hassanpour, S. Wong, and A. Shahbahrami, “Vision ­ 
Based Hand Gesture Recognition for Human Computer 
Interaction : A Review,” IADIS Int. Conf. Interfaces Hum. 
Comput. Interact., pp. 25--27, 2008. 
[3] 
R.-H. L. R.-H. Liang and M. O. M. Ouhyoung, “A real-time 
continuous gesture recognition system for sign language,” 
Proc. Third IEEE Int. Conf. Autom. Face Gesture Recognit., 
pp. 558–567, 1998. 
[4] 
G. Saggio, F. Cavrini, and F. Di Paolo, “Inedited SVM 
application to automatically tracking and recognizing arm-
and-hand visual signals to aircraft,” IJCCI 2015 - Proc. 7th 
Int. Jt. Conf. Comput. Intell., vol. 3, no. Ijcci, pp. 157–162, 
2015. 
[5] 
Y. J. Chang, S. F. Chen, and J. Da Huang, “A Kinect-based 
system for physical rehabilitation: A pilot study for young 
adults with motor disabilities,” Res. Dev. Disabil., vol. 32, 
no. 6, pp. 2566–2570, 2011. 
[6] 
A. Kupryjanow, B. Kunka, and B. Kostek, “UPDRS tests for 
diagnosis of Parkinson’s disease employing virtual-
touchpad,” Proc. - 21st Int. Work. Database Expert Syst. 
Appl. DEXA 2010, pp. 132–136, 2010. 
[7] 
V. Silva et al., “A wearable and non-wearable approach for 
gesture recognition – Initial results,” 9Th Int. Congr. Ultra 
Mod. Telecommun. Control Syst., pp. 185–190, 2017. 
[8] 
V. Silva et al., “iBoccia: A Framework to Monitor the 
Boccia Gameplay in Elderly,” Lect. Notes Comput. Vis. 
Biomech., vol. 27, pp. 437-446, 2018. 
[9] 
C. Figueira et al., “iBoccia: Monitoring elderly while playing 
Boccia gameplay,” ICINCO 2017 - Proc. 14th Int. Conf. 
Informatics Control. Autom. Robot., vol. 1, no. Icinco, pp. 
670–675, 2017. 
[10] P. Leite, A. Calado, and F. Soares, “Boccia Court Analisys 
for Real-Time Scoring,” In Press, 2018. 
[11] A. Calado, P. Leite, F. Soares, P. Novais, and P. Are-, 
“Boccia Court Analysis for Promoting Elderly Physical 
Activity,” Innov. Eng. Entrep. HELIX 2018. Lect. Notes 
Electr. Eng., vol. 505, pp. 158-164, 2018. 
[12] Fraunhofer Portugal AICOS, “Pandlets – Personal Area 
Dots: Letting Everything Sense,” Innov. Eng. Entrep. HELIX 
2018. Lect. Notes Electr. Eng., vol. 505, no. 1, 2018. 
[13] S. Bhattacharya, B. Czejdo, and N. Perez, “Gesture 
classification with machine learning using Kinect sensor 
data,” 2012 Third Int. Conf. Emerg. Appl. Inf. Technol., pp. 
348–351, 2012. 
[14] Q. Chen, N. D. Georganas, and E. M. Petriu, “Real-time 
Vision-based Hand Gesture Recognition Using Haar-like 
Features,” IEEE Conf IMTC, pp. 1–6, 2007. 
[15] H. Hienz, K. Grobel, and G. Offner , “Real-Time Hand-Arm 
Motion Analysis using a single Video Camera,” Proc. 
Second Int. Conf. Autom. Face Gesture Recognition, Kill., 
pp. 165–168, 1996. 
[16] C. Joslin, A. El-Sawah, Qing Chen, and N. Georganas, 
“Dynamic 
Gesture 
Recognition,” 
2005 
IEEE 
Instrumentationand Meas. Technol. Conf. Proc., vol. 3, no. 
May, pp. 1706–1711, 2005. 
[17] T. Schlömer, B. Poppinga, N. Henze, and S. Boll, “Gesture 
recognition with a Wii controller,” Proc. 2nd Int. Conf. 
Tangible Embed. Interact.  - TEI ’08, p. 11, 2008. 
[18] D. Wilson and A. Wilson, “Gesture recognition using the 
XWand,” 2004. 
[19] R. Xie and J. Cao, “Accelerometer-Based Hand Gesture 
Recognition by Neural Network and Similarity Matching,” 
IEEE Sens. J., vol. 16, no. 11, pp. 4537–4545, 2016. 
[20] Z. He and L. Jin, “Activity recognition from acceleration 
data based on discrete consine transform and SVM,” Conf. 
Proc. - IEEE Int. Conf. Syst. Man Cybern., no. October, pp. 
167
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

5041–5044, 2009. 
[21] K. K. B. Peetoom, M. A. S. Lexis, M. Joore, C. D. Dirksen, 
and L. P. De Witte, “Literature review on monitoring 
technologies and their outcomes in independently living 
elderly people,” Disabil. Rehabil. Assist. Technol., vol. 10, 
no. 4, pp. 271–294, 2015. 
[22] A. M. Khan, Y. K. Lee, S. Lee, and T. S. Kim, 
“Accelerometer’s position independent physical activity 
recognition system for long-term activity monitoring in the 
elderly,” Med. Biol. Eng. Comput., vol. 48, no. 12, pp. 1271–
1279, 2010. 
[23] B. Najafi, K. Aminian, A. Paraschiv-Ionescu, F. Loew, C. J. 
Büla, and P. Robert, “Ambulatory system for human motion 
analysis using a kinematic sensor: Monitoring of daily 
physical activity in the elderly,” IEEE Trans. Biomed. Eng., 
vol. 50, no. 6, pp. 711–723, 2003. 
[24] M. Luštrek and B. Kaluža, “Fall Detection and Activity 
Recognition with Machine Learning,” Informatica, vol. 33, 
pp. 205–212, 2008. 
[25] G. Perolle et al., “Automatic Fall Detection and Activity 
Monitoring for Elderly,” Proc. MEDETEL, vol. 41, no. 2, pp. 
33–41, 2006. 
[26] D. W. Kang, J. S. Choi, J. W. Lee, S. C. Chung, S. J. Park, 
and G. R. Tack, “Real-time elderly activity monitoring 
system based on a tri-axial accelerometer,” Disabil. Rehabil. 
Assist. Technol., vol. 5, no. 4, pp. 247–253, 2010. 
[27] P. C. Huang, P. J. Pan, Y. C. Ou, Y. C. Yu, and Y. S. Tsai, 
“Motion analysis of throwing Boccia balls in children with 
cerebral palsy,” Res. Dev. Disabil., vol. 35, no. 2, pp. 393–
399, 2014. 
[28] R. D. de Arroxellas, R. G. Romano, R. Cymrot, and S. M. 
Blascovi‐Assis, “Bocha adaptada: análise cinemática do 
arremesso e sua relação com a realidade virtual,” Rev. Bras. 
Ciencias do Esporte, vol. 39, no. 2, pp. 160–167, 2017. 
[29] BISFed, “BISFed International Boccia Rules (v.2),” 2017. 
[30] A. Moschetti, L. Fiorini, D. Esposito, P. Dario, and F. 
Cavallo, “Recognition of daily gestures with wearable 
inertial rings and bracelets,” Sensors (Switzerland), vol. 16, 
no. 8, 2016. 
[31] J. Wu, G. Pan, D. Zhang, and G. Qi, “Gesture recognition 
with a 3-d accelerometer,” Proc. 6th Int. Conf. Ubiquitous 
Intell. Comput., vol. 5585, pp. 25–38, 2009. 
[32] Z. He, “Accelerometer based gesture recognition using 
fusion features and SVM,” J. Softw., vol. 6, no. 6, pp. 1042–
1049, 2011. 
[33] C. R. Souza, “The Accord.NET Framework.” [Online]. 
Available: http://accord-framework.net. [Accessed: 26-Jul-
2018].
 
 
168
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-660-6
SENSORDEVICES 2018 : The Ninth International Conference on Sensor Device Technologies and Applications

