Diagonalization and the Complexity of Programs
Emanuele Covino and Giovanni Pani
Dipartimento di Informatica
Università di Bari, Italy
Email: emanuele.covino@uniba.it, giovanni.pani@uniba.it
Abstract—Starting from the deﬁnitions of predicative re-
cursion and constructive diagonalization, we recall our spe-
cialized programming language that provides a resource-free
characterization of register machines computing their output
within polynomial time O(nk), and exponential time O(nnk),
for each ﬁnite k. We discuss the possibility of extending this
characterization to a transﬁnite hierarchy of programs that
captures the Grzegorczyk hierarchy of functions at elementary
level. This is done by means of predicative operators, contrasting
to previous results. We discuss the feasibility and the complexity
of our diagonalization operator.
Index Terms—Hierarchies of complexity classes; Predicative
recursion; Constructive diagonalization.
I. INTRODUCTION AND POSITION OF THE PROBLEM
In [1], the Grzegorczyk’s classes of functions En (n =
0, 1, . . .), have been introduced, with the property that
∪
n<ω En is the class of primitive recursive functions. In
order to deﬁne these classes, the hierarchy functions En have
to be introduced. They are essentially repeated iterations of
the successor function, i.e., E0(x, y) = x + y, E1(x) =
x2 + 2, En+2(0) = 2, En+2(x + 1) = En+1(En+2(x)).
Grzegorczyk’s classes can be deﬁned as follows. E0 is the
class whose initial functions are the zero, successor and the
projection functions, and is closed under composition and
limited recursion. En+1 is deﬁned similarly, except that the
function En is added to the list of the initial functions. En
is called the n-th Grzegorczyk class. Other sequences of
hierarchy functions have been used in literature, for instance
the Ackermann function. The reader can ﬁnd properties and
theorems in [2]; we recall that the class E3 is the class of
the elementary functions E′ (that is, the class of functions
containing the successor, projections, zero, addition, multipli-
cation, subtraction functions, and closed under composition
and bounded sum and product.)
Harmonizations of signiﬁcant complexity classes with the
Grzegorczyk classes have been obtained by Leivant [3], Niggl
[4], and Bellantoni and Niggl [5]. In these papers, the class
of polynomial-time computable functions is characterized
by means of different deﬁnitions of predicative recursion
[6] or ramiﬁed recurrence [7], and starting from a set of
initial functions. Note that a predicative deﬁnition of a
recursive function is based on the idea that functions have
two kind of variables: those whose values are known entirely
(and which can be recursed upon, for instance), and those
whose values are still being computed (and are accessible
in a more restricted way, on the least signiﬁcant digits, for
instance); these two types of variables are called safe and
normal in [6] (dormant and normal in [8]); roughly speaking,
normal variables are used only for recursive calls, while safe
variables are used only for substitution. This allows to discard
explicitly bounded schemes (like the limited recursion) to
characterize classes of functions.
In [5], the classes En are captured by closure under
composition of functions, and by counting the number of
infringements to the predicative principle made into the
recursive deﬁnitions. This is an alternative approach to look at
ramiﬁcation: rather than controlling the type of the variables,
and how they are used in the deﬁnition of a recursive
function, ﬁrst a deﬁnition of a function is given, and then
one examines it in order to see, or to count, how many levels
of impredicative deﬁnitions are used. Even if this approach
represents a detailed analysis of the effects of nesting re-
cursive deﬁnitions, we believe that counting the number of
violations to the predicative principle is as impredicative as
using limited recursion, or as adding a hierarchy function to
the list of initial functions.
In a previous paper [9], we introduced our version of pred-
icative recursion, together with a constructive diagonalization
operator; they allow us to deﬁne a hierarchy of programs
Tk (k = 0, 1, . . .), such that each program deﬁned in Tk
is computable by a register machine within time bounded
by a polynomial nk; and to extend this hierarchy up to the
programs computable within exponential-time bound. In this
contribution we claim that our approach can be extended
further, and that our hierarchy reaches the level 3 of the
Grzegorczyk hierarchy. We address questions raised about
the complexity and feasibility of the diagonalization, and we
compare it to a recent different approach [10].
In Section II, we recall the deﬁnition of our programming
language, and the results holding on the ﬁnite levels of
our hierarchy of programs. In Section III, we introduce the
deﬁnition of diagonalization, we discuss its feasibility, and
we recall the result on programs with exponential-time com-
plexity. In Section IV, we extend the hierarchy of programs
up to the elementary level of the Grzegorczyk hierarchy.
In Section V, we compare our approach to Marion’s [10].
Conclusions and further work are in Section VI.
1
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

II. BASIC INSTRUCTIONS, COMPOSITION OF PROGRAMS
AND RECURSION
In this section, we recall the basic instructions of our
programming language, together with the deﬁnition schemes
of composition and recursion over programs we introduced
in [9]. We then recall the deﬁnition of our ﬁnite hierarchy of
programs, which captures the polynomial-time computable
functions.
The language is built over lists of binary words, with
the symbol © acting as a separator between each word. B
denotes the alphabet {0, 1}, and a, b, a1, . . . denote elements
of B; U, V, . . . , Y denote words over B. r, s, . . . stand for
lists in the form Y1©Y2© . . . ©Yn. ϵ is the empty word. The
i-th component (s)i of a list s = Y1©Y2© . . . ©Yn is Yi.
|s| is the length of the list s, that is the overall number of
symbols occurring in s.
We write x, y, z for the variables used in a program, and
we write u for one among x, y, z. Programs are denoted with
letters f, g, h, and we write f(x, y, z) for the application of
the program f to variables x, y, z, where some among them
may be absent. In what follows, the length lh(f) of a program
f is the number of basic instructions and deﬁning schemes
occurring in its deﬁnition.
The basic instructions allow us to manipulate lists of
words, adding digits to (or erasing parts of) each component;
the so-called simple schemes allow us to change the name of
some among the variables and to select between programs,
according to the value of the variables. The basic instructions
are:
1) the identity I(u) that returns the value s assigned to u;
2) the constructors Ca
i (s) that add the digit a at the right
of the last digit of (s)i, with a = 0, 1 and i ≥ 1;
3) the destructors Di(s) that erase the rightmost digit of
(s)i, with i ≥ 1.
Constructors Ca
i (s) and destructors Di(s) leave the input s
unchanged if it has less than i components. For instance, for
s = 01©11©©00, we have that |s| = 9, and (s)2 = 11; we
also have C1
1(01©11) = 011©11, D2(0©0©) = 0©©, and
D2(0©©) = 0©©.
Given the programs g and h, f is deﬁned by simple
schemes if it is obtained by:
1) renaming of x as y in g, that is, f is the result of the
substitution of the value of y to all occurrences of x
into g. Notation: f =RNMx/y(g);
2) renaming of z as y in g, that is, f is the result of the
substitution of the value of y to all occurrences of z
into g. Notation: f =RNMz/y(g);
3) selection in g and h, when for all s, t, r we have
f(s, t, r) =



g(s, t, r)
if the rightmost digit
of (s)i is b
h(s, t, r)
otherwise,
with i ≥ 1 and b = 0, 1. Notation: f =SELb
i(g, h).
Simple schemes are denoted with SIMPLE. For instance, if
f is deﬁned by RNMx/y(g) we have that f(t, r) = g(t, t, r).
Similarly, f deﬁned by RNMz/y(g) implies that f(s, t) =
g(s, t, t). For s = 00©1010, and f =SEL0
2(g, h), we have
that f(s, t, r) = g(s, t, r), since the rightmost digit of (s)2
is 0.
Given the programs g and h, the program f is deﬁned
by safe composition of h and g in the variable u if it is
obtained by the substitution of h to u in g, if u = x or
u = y; the variable x must be absent in h, if u = z. Notation:
f =SCMPu(h, g). The rationale behind this deﬁnition will be
clear as soon as we will deﬁne the safe recursion scheme.
A modiﬁer is obtained by the safe composition of a
sequence of constructors and a sequence of destructors, and
the class T0 is deﬁned by closure of modiﬁers under selection
and safe composition. Notation: T0=(modifier; SCMP, SEL).
All programs in T0 modify their inputs according to the result
of some test performed over a ﬁxed number of digits.
Given the programs g(x, y) and h(x, y, z), the program
f(x, y, z) is deﬁned by safe recursion in the basis g and in
the step h if for all s, t, r we have
{ f(s, t, a)
=
g(s, t)
f(s, t, ra)
=
h(f(s, t, r), t, ra),
with a ∈ B. Notation: f =SREC(g, h).
In particular, f(x, z) is deﬁned by iteration of h(x) if for all
s, r we have
{ f(s, a)
=
s
f(s, ra)
=
h(f(s, r)).
with a ∈ B. Notation: f =ITER(h). We write h|r|(s) for
ITER(h)(s, r) (i.e., the |r|-th iteration of h on s).
We recall that x, y and z are the auxiliary variable, the
parameter, and the principal variable of a program obtained
by means of the previous recursion scheme, respectively.
Note also that, according to the previous deﬁnitions, the
renaming of z as x is not allowed, and if the step program of
a recursion is deﬁned itself by safe composition of programs
p and q, no variable x (i.e., no potential recursive calls)
can occur in the function p, when p is substituted into the
principal variable z of q. These two restrictions imply that
the step program of a recursive deﬁnition never assigns the
recursive call to the principal variable. This is the key to the
polynomial-time complexity bound intrinsic to our programs,
and fulﬁlls the predicative criteria.
Given the previous basic instructions and deﬁnition
schemes, we are able to deﬁne the hierarchy of classes of
programs Tk, with k < ω, as follows:
1) ITER(T0) denotes the class of programs obtained by
one application of iteration to programs in T0;
2) T1 is the class of programs obtained by closure under
safe composition and simple schemes of programs in
T0 and programs in ITER(T0);
Notation: T1=(T0, ITER(T0); SCMP, SIMPLE);
2
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

3) Tk+1 is the class of programs obtained by closure under
safe composition and simple schemes of programs in
Tk and programs in SREC(Tk), with k ≥ 1;
Notation: Tk+1=(Tk, SREC(Tk); SCMP, SIMPLE).
In [11] and [9] we proved the following two theorems
using as a model of computation the register machines
introduced by Leivant [7] . We have that
1) each program f(s, t, r) deﬁned in Tk can be computed
by a register machine within time bounded by the
polynomial |s| + lh(f)(|t| + |r|)k, with k ≥ 1;
2) a register machine which computes its output within
time O(nk) can be simulated by a program f in Tk,
with k ≥ 1.
The previous result allowed us to prove the following
Theorem 2.1: A program f belongs to Tk if and only if f
is computable by a register machine within time O(nk), with
k ≥ 1.
We recall that register machines are polytime reducible to
Turing machines; thus, the sequence of classes Tk captures
PTIMEF (see [6] and [7] for similar characterizations of this
complexity class).
III. DIAGONALIZATION AND EXPONENTIAL-TIME
COMPUTABLE PROGRAMS
We recall the deﬁnition of structured ordinals and of hier-
archies of slow growing functions, as reported in [12]. Then,
we give the deﬁnition of diagonalization at a given limit
ordinal λ, based on the sequence of classes Tλ1, . . . , Tλn, . . .
associated with the fundamental sequence of λ. A similar
operator can be found in [13], and we will discuss later
the relation between our diagonalization and its analogue in
[10]. Using safe recursion and diagonalization, we are able to
deﬁne a transﬁnite hierarchy of programs characterizing the
classes of register machines computing their output within
time between O(nk) and O(nnk) (with k ≥ 1 and n the
length of the input), that is, the computations with time
complexity between polynomial- and exponential-time.
Following [12], we denote limit ordinals with greek small
letters α, β, λ, . . ., and we denote with λi the i-th element
of the fundamental sequence assigned to λ. For example,
ω is the limit ordinal of the fundamental sequence 1, 2, . . .;
and ω2 is the limit ordinal of the fundamental sequence
ω, ω2, ω3, . . ., with (ω2)k = ωk.
The slow-growing functions Gα : N → N are deﬁned by
the recursion 


G0(n)
=
0
Gα+1(n)
=
Gα(n) + 1
Gλ(n)
=
Gλn(n).
We slightly change the previous deﬁnition, and we deﬁne
the slow-growing functions Bα : N → N by the recursion



B0(n)
=
1
Bα+1(n)
=
nBα(n)
Bλ(n)
=
Bλn(n).
Note that Bk(n) = nk, Bω(n) = nn, Bω+k(n) = nn+k,
Bωk(n) = nn·k, Bωk(n) = nnk, and Bωω(n) = nnn;
moreover, we have that Bα+β(n) = Bα(n) · Bβ(n), and
that Gωα(n) = nGα(n) = Bα(n).
The ﬁnite hierarchy T0, T1, T2, . . . , Tk, . . ., captures the
register machines that compute their output with time
in O(1), O(n), O(n2), . . . , O(nk), . . ., respectively. Jumping
out of the hierarchy requires something more than safe
recursion. We already discussed in the Introduction the
approach presented in [5], that is, to deﬁne a ranking function
that counts the number of nested recursions infringing the
predicative deﬁnition of a program; a class of time-bounded
register machines can be associated to each level of the
ranking. On the other hand, given a limit ordinal λ, we
proposed in [9] a new operator that diagonalizes at level λ
over the classes Tλi, that is, that selects and iterates programs
in a previously deﬁned class Tλi according to the length of
the input. There is no circularity in a program deﬁned by
diagonalization, and we believe that this program isn’t less
predicative than a program deﬁned by safe recursion. For
instance, at level ω, we select (and iterate i times) programs
in the classes Ti, where i is the length of the input; thus, the
ﬁrst level of diagonalization captures the class of all register
machines whose computation is bounded by a polynomial.
By extending this approach to the next levels of structured
ordinals, we were able to reach the machines computing their
output within exponential time nnk.
Given a limit ordinal λ with the fundamental sequence
λ0, . . . , λk, . . ., and given an enumerator program q such that
q(λi) = fλi, for each i, the program f(x, y) is deﬁned by
diagonalization at λ if for all s, t
f(s, t) =ITER|t|(q(λ|t|))(s, t)
where{
ITER1(p)(s, t)
=
ITER(p)(s, t)
ITERk+1(p)(s, t)
=
ITER(ITERk(p))(s, t).
and fλi belongs to a previously deﬁned class Cλi, for each
i. Notation: f =DIAG(λ). Note that the previous deﬁnition
requires that fλi ∈ Cλi, but there aren’t other requirements on
how the C’s classes are built. In what follows, we introduce
our transﬁnite hierarchy of programs, with an important
restriction on the deﬁnition of the C’s.
Given λ < ωω, Tλ is the class of programs obtained by
1) closure under safe composition and simple schemes of
programs in Tα and programs in SREC(Tα), if λ =
α+1; Notation: Tα+1=(Tα, SREC(Tα); SCMP, SIMPLE).
2) closure under simple schemes of programs obtained by
one application of diagonalization at λ, if λ is a limit
ordinal, with fλi ∈ Tλi, for each λi in the fundamental
sequence of λ. Notation: Tλ=(DIAG(λ); SIMPLE);
In [9] we proved that
1) each program f(s, t, r) deﬁned in Tλ (λ < ωω) can be
computed by a register machine within time Bλ(n);
3
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

2) a register machine which computes its output within
time O(Bλ(n)) can be simulated by a program f in
Tλ.
We then have that
Theorem 3.1: A program f belongs to Tα if and only if f
is computable by a register machine within time O(Bα(n)),
with α < ωω.
Two intertwined questions (not addressed in [9]) could
be raised about the enumerator q(λi). First, to which class
does the enumerator belongs? And what are its results?
For complexity reasons, it appears clear that the enumerator
should be deﬁned into the same hierarchy of classes that
we are using to diagonalize; in particular, it can be deﬁned
into the ﬁrst class Tλ1 of every sequence Tλ1, . . . , Tλn, . . .,
because it only has to write sequences of SREC’s and DIAG’s
according to the deﬁnition on the ordinal λi, in order to write
down the deﬁnition of fλi ∈ Tλi. This leads us to the second
question: the results of any program in our language are lists
of binary words, and they aren’t other programs. This means
that the enumerator must return the code of a program in Tλi,
and not the program itself. Deﬁning a code for every element
of our language is straightforward, but we must underline
that every time we diagonalize over a sequence of classes, we
should see the fλi’s as codes of programs; this implies that an
interpreter is concealed in the deﬁnition of diagonalization.
IV. EXTENDING THE HIERARCHY TO THE ELEMENTARY
FUNCTIONS
In [9], the classes Tλ have been deﬁned between level
1 and ωω, reaching the programs computable within ex-
ponential time. This hierarchy can be extended up to the
ordinal ϵ0, with ϵ0 = ωωω...
= sup{ω, ωω, ωωω, . . .}; in
particular, Tϵ0 is the class of programs computable within
time O(Bϵ0(n)) = O(nnn...
). Given that a function f(n) is
elementary if and only if it is computable in time bounded
by nnn...
(see [14]), we have that Tϵ0 characterizes the class
of the elementary functions. The proof of this result is an
extension of the proof introduced in [9]; given λ < ϵ0, we
can prove that
1) each program f(s, t, r) in Tλ can be computed by a
register machine within time in O(Bλ(n));
2) every register machine computing its output within
time O(Bλ(n)) can be simulated by a program f in
Tλ.
Lemma (1) is proved by structural induction on the ordinal
λ, that can be a ﬁnite number, an ordinal β + 1, or a
limit ordinal: in each case we build the register machine
that computes the program f at level λ using the machines
provided by the inductive hypothesis, and we compute the
overall time consumption, showing that it respects the bound
Bλ(n). Lemma (2) is proved for each time-bounded register
machines showing that, given a program nxtM ∈ T0 that
simulates the transition between the machine’s conﬁgura-
tions, a program in the appropriate class Tλ can be built
as the iteration of nxtM, in order to simulate the overall
computation performed by the register machine itself. By (1)
and (2) we have that
Theorem 4.1: A program f belongs to Tα if and only if f
is computable by a register machine within time O(Bα(n)),
with α < ϵ0.
Our operators of predicative recursion and constructive
diagonalization can be used to provide a ﬁne hierarchy of
classes between PTIME and E3. As far as we know, this is
the only characterization of these classes built "from below",
by means of constructive operators. Other characterizations,
like Oitavem [15], and Arai and Eguchi [16], capture the
elementary functions alone, and not in a hierarchy of classes,
using various forms of predicative recursion. Leivant [17],
captures E3 using an extension to higher types of ramiﬁed
recurrence.
V. MARION’S DIAGONALIZATION OPERATOR
In [10], the classes of functions Ik (k = 0, 1, . . .) are
deﬁned on the cartesian product of natural numbers. The class
I0 is deﬁned starting from a ﬁnite set of linear functions
and closing it by composition and ﬂat recursion, deﬁned as
follows:
{ f(0, t)
=
g(t)
f(s + 1, t)
=
h(s, t)
The class Ik+1 contains all the functions deﬁned in Ik and
is closed by ﬂat recursion and by (a version of) predicative
recursion and composition. It is proved that each class Ik
is the class of the functions computable within polynomial-
time bound nk; thus, ∪
k<ω Ik is the class of polynomial
time computable functions. The proof works by induction:
if a function g belongs to I0, then a function Fk computing
gnk can be deﬁned as follows:



F0(0, x, y)
=
g(y)
Fk+1(0, x, y)
=
y
Fk+1(s + 1, x, y)
=
Fk(x, x, Fk+1(s, x, y))
Fk belongs to Ik, for all k. Note how the variable x is
used in order to jump from each class Ik to class Ik+1. In
the last line of the deﬁnition, the number of computations of
the function Fk+1 is set by using the ﬁrst occurrence of x,
and the information about how many times all the remaining
functions Fk, . . . , F0 have to be computed is given by the
second occurrence of x itself. Now the small jump operator
is deﬁned, in order to jump from every class to the next one:
{ ∆[Fk](0, x, y)
=
y
∆[Fk](r + 1, x, y)
=
Fk(x, x, ∆[Fk](r, x, y))
It is proved in [10] that ∆[Fk](r, x, y) = Fk+1(r, x, y). If the
parameter k assumes the role of a variable, ∆ω is deﬁned as
follows:
4
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking








∆ω[g](0, n, x, y)
=
g(y)
∆ω[g](r + 1, 0, x, y)
=
y
∆ω[g](r + 1, n + 1, x, y)
=
= ∆ω[g](r, x, x, ∆ω[g](r + 1, n, x, y))
The operator ∆ω, which is not a polynomial function,
computes all the polynomial-time computable functions.
Contrasting with our approach, no enumerating functions
are used; starting from a function in I0, the small jump
operator deﬁnes a chaining of "growing" functions (w.r.t. the
time complexity) and this chaining is used to jump out of
polynomial class. The problem of how to deﬁne functions
with higher time-complexity is not addressed.
VI. CONCLUSIONS AND FURTHER WORK
In our previous work, we have used a version of safe recur-
sion and constructive diagonalization to deﬁne a hierarchy of
classes of programs Tλ, with 0 ≤ λ < ωω. Each ﬁnite level of
the hierarchy characterizes the register machines computing
their output within time O(nk); using the natural deﬁnition of
structured ordinals, and combining it with the diagonalization
operator, the transﬁnite levels of the hierarchy characterize
the classes of register machine computing their output within
time bounded by the slow-growing function Bλ(n), up to the
machines with exponential-time complexity. In this paper, we
have given a hint of how to extend our hierarchy further,
reaching the class E3 at level ϵ0.
While predicative recursion has been studied thoroughly,
we feel that the diagonalization operator as presented in this
work deserves a more accurate analysis. In particular, we
believe that it is as predicative as the recursion, and that it
could be used to stretch the hierarchy of programs in order
to capture the low Grzegorczyk classes above the elementary
level.
REFERENCES
[1] A. Grzegorczyk, Some classes of recursive functions. Rozprawy
Matematyczne, vol. IV, 1953.
[2] H. E. Rose, Subrecursion: functions and hierarchies. Clarendon press,
Oxford, 1984.
[3] D. Leivant, “Stratiﬁed functional programs and computational com-
plexity,” in Proceedings of the 20th Annual ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages, (POPL’93),
Charleston, 1993, pp. 325–333.
[4] K.-H. Niggl, “The µ-measure as a tool for classifying computational
complexity,” Archive for Mathematical Logic, vol. 39, no. 7, 2000, pp.
515–539.
[5] S. Bellantoni and K.-H. Niggl, “Ranking primitive recursion: the low
Grzegorczyk classes revisited,” SIAM Journal on Computing, vol. 29,
no. 2, 1999, pp. 401–4015.
[6] S. Bellantoni and S. Cook, “A New Recursion-Theoretic Characteriza-
tion Of The Polytime Functions,” Computational Complexity, vol. 2,
1992, pp. 97–110.
[7] D. Leivant, Predicative recurrence and computational complexity I:
word recurrence and polytime, in Feasible Mathematics II, P.Clote and
J.Remmel (eds).
Birkauser, 1994, pp. 320–343.
[8] H. Simmons, “The realm of primitive recursion,” Arch.Math. Logic,
vol. 27, no. 2, 1988, pp. 177–188.
[9] E. Covino and G. Pani, A Slow-growing Hierarchy of Time-bounded
Programs, in Advances in Intelligent Systems: Reviews’ Book Series,
Vol. 1.
IFSA Publishing, Barcelona, Spain, 2017, pp. 151–171.
[10] J. Marion, “On tiered small jump operators,” Logical Methods in
Computer Science, vol. 5, no. 1, 2009.
[11] E. Covino and G. Pani, “A Specialized Recursive Language for
Capturing Time-Space Complexity Classes,” in The Sixth International
Conference on Computational Logics, Algebras, Programming, Tools,
and Benchmarking, (COMPUTATION TOOLS 2015), Nice, France,
2015, pp. 8–13.
[12] M. Fairtlough and S. Weiner, Hierarchies of provably recursive func-
tions, in Handbook of Proof theory, B. Samuel (ed), Studies in logic
and the foundations of mathematics, vol. 137.
Elsevier, Amsterdam,
1998, chapter 3, pp. 149–207.
[13] S. Caporaso, G. Pani, and E. Covino, “A predicative approach to the
classiﬁcation problem,” Journal of Functional Programming, vol. 11,
no. 1, 2001, pp. 95–116.
[14] N. Cutland, Computability: an introduction to recursive function the-
ory.
Cambridge university press, Cambridge, 1980.
[15] I. Oitavem, “New recursive characterization of the elementary func-
tions and the functions computable in polynomial space,” Revista
Matematica de la Univaersidad Complutense de Madrid, vol. 10, no. 1,
1997, pp. 109–125.
[16] T. Arai and N. Eguchi, “A new function algebra of EXPTIME functions
by safe nested recursion,” ACM Transactions on Computational Logic,
vol. 10, no. 4, 2009, pp. 1–19.
[17] D. Leivant, “Ramiﬁed recurrence and computational complexity III:
higher type recurrence and elementary complexity,” Annals of Pure
and Applied Logic, vol. 96, no. 1–3, 1999, pp. 209–229.
5
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-613-2
COMPUTATION TOOLS 2018 : The Ninth International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

