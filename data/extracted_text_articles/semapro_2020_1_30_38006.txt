Towards Using Logical Reasoning for Assessing
the Structure and State of a Human Debate
Helmut Horacek
German Research Center for Artiﬁcial Intelligence
Language Technology Division
Saarbruecken, Germany
Email: helmut.horacek@dfki.de
Abstract—Supporting a human debate by logical reasoning fa-
cilities is a long-term research goal. Support comprises evidence
about argumentative accuracy, detection of inconsistencies, and
exposition of acceptable policy positions. This paper elaborates
the role and embedding of argumentative utterances, through
the use of linguistic tools, which address various aspects of the
semantics of natural language. In addition, long-term issues, such
as uncovering parts of the semantic content of arguments and its
use for reasoning purposes are discussed.
Keywords–Discourse parser; logical entailment; argumentation
graph; argumentation framework.
I.
INTRODUCTION
A major goal in the ﬁeld of computational models for
natural argument is to make logical reasoning capabilities
accessible for discussions, ultimately in the course of incre-
mentally developing human debates. This issue appears to
be notoriously difﬁcult, which is also reﬂected by some sort
of a partition of the research area between natural language
approaches and logical models of argumentation, based on
non-monotonic reasoning [2], with extremely few connections.
An exception is the approach by Wyner and his colleagues
[15], who attempt to interpret a human debate in terms of
arguments in favor or disfavor of the issue at stake or some
intermediate argument. This way, contributions to the debate
can be converted into an Argumentation Graph, which is
the basic logical structure for computing the state of sets of
arguments. The functionality provided by logical reasoning can
be exploited — prominently by exposing sets of acceptable,
consistent arguments that represent reasonable policy positions
of some party — this is an extremely valuable documentation
of the state of a debate. Nevertheless, the mapping from
natural language statements onto logical assertions is made
on a rather superﬁcial level: the proper natural language text
is not analyzed below the level of arguments, and the method
also relies on the assessment of the contributors to the debate
— they have to state which previous argument their new one
relates to, and whether it attacks or supports it. We examine
a number of methods to expand and strengthen this approach,
as an extension to our elaborations in [4].
This paper is organized as follows. In section 2, we
analyze shortcomings of human assignments of arguments and
resulting deﬁcits. In section 3, we discuss potential examina-
tions addressing these deﬁcit, supported by linguistic tools.
In section 4, we address the long-term issue of transferring
portions of contents in the debate to the logical level. In section
5, we discuss future developments.
II.
SOURCES FOR SUPPORT BY LOGICAL REASONING
The method by [15] relies on rather accurate assessments of
participants in a debate with regard to the role of arguments
raised and their relation to the embedding debate. However,
when a human debate evolves in a typical manner, people
sometimes raise their arguments in a sloppy fashion. This is
not surprising, since the majority of them are far from being
well-trained attorneys. In contrast to the human perspective
of communication, percolating the inaccuracy of arguments to
the logical level is likely to limit the usefulness of a logical
support system, which itself exhibits strong rigor. Hence, it
is quite advisable to perceive arguments in the most accurate
form. As already observed and discussed in [4], arguments
may be inaccurate in at least the following ways:
1)
A contribution to the debate may be not a proper
argument, in the sense that this statement does not
attack or support an argument raised before, but it
may be associated with such an argument in another
way, typically by expanding its description.
2)
An argument may be indicated by a debater as
attacker or supporter of some other argument, but
this relation may be better conceived as an indirect
one, since the argument directly attacks resp. supports
another argument related to the one indicated.
3)
Arguments may have logical ﬂaws of various kind,
ranging from logical inconsistencies (typically in the
embedding context) to subtle domain-speciﬁc ones.
The ﬁrst deﬁcit may lead to multiple representations of
what is essentially the same argument — this may lead to tem-
porary inconsistencies and repeated attacks in the subsequent
debate. A similar overhead in reasoning may result from the
second deﬁcit. Issues associated with the third deﬁcit may be
various. Therefore, it is important to obtain a representation of
the debate as accurate as possible, to exploit the functionality
of logical tools attached. To envision this goal, we aim at
computing the role and relations of arguments automatically,
which a participant in a debate can accept or overrule.
III.
USE OF LINGUISTIC TOOLS TO SUPPORT ASSESSING
THE STRUCTURE AND STATE OF A HUMAN DEBATE
In order to address potential deﬁcits of human assessment
regarding position and role of an argument we envision a lin-
guistic analysis of the arguments raised, resulting in evidence
on the level of discourse. Two things are of interest:
1)
the attachment point for a newly raised argument
18
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-813-6
SEMAPRO 2020 : The Fourteenth International Conference on Advances in Semantic Processing

1)
Every householder should pay tax for the garbage
which the householder throws away.
2)
No householder should pay tax for the garbage which
the householder throws away.
3)
Paying tax for garbage increases recycling.
4)
Recycling more is good.
5)
Paying tax for garbage is unfair.
6)
Every householder should be charged equally.
7)
Every householder who takes beneﬁts does not recy-
cle.
8)
Every householder who does not take beneﬁts pays
for every householder who does take beneﬁts.
9)
Professor Resicke says that recycling reduces the
need for new garbage dumps.
10)
A reduction of the need for new garbage dumps is
good.
11)
Professor Resicke is not objective.
12)
Professor Resicke owns a recycling company.
13)
A person who owns a recycling company earns
money from recycling.
14)
Supermarkets create garbage.
15)
Supermarkets should pay tax.
16)
Supermarkets pass the taxes for the garbage to the
consumer.
Figure 1. Human debate as used by Wyner and his colleagues [15].
2)
its argumentative role, attack or support, the funda-
mental links in an Argumentation Framework, or a
further description of a previously raised argument.
Two linguistic tools can contribute to this purpose: (1) a
discourse parser and (2) a textual entailment component. In
both of these, analysis of semantics of natural language is
incorporated to achieve the intended functionality.
A discourse parser can check for the rhetorical role of
arguments and the relations between them, essentially op-
erationalizing Rhetorical Structure Theory [5]. Thereby, the
richness of the rhetorical relations in ordinary texts is not
of primary interest for our purposes, in view of the limited
set of argumentative relations, since only a few rhetorical
relations give highly relevant indications. For instance, some
semantically strong relations, such as contrast and explanation,
typically cooccur with attack and support, respectively.
A textual entailment component can check for consistency
or possible inconsistency. In particular, a high degree of con-
sistency — assuming the component yields results associated
with probabilities - is hardly compatible with an attack relation.
The reverse direction — inferring textual entailment on the
basis of argumentative relations — is possible in some cases.
An attack relation implies contradiction, but only speciﬁc
instances of a support relation constitute entailment. All these
inferences, however, are defeasible on principled grounds: an
argumentative relation may be challenged by an undercutting
defeater [9], which attacks the argumentative relation itself
rather than the argument attacking or supporting another one.
At the present state of the art, unfortunately, neither dis-
course parsers nor textual entailment components are very
strong assistants, they give some indications only. Discourse
parsers are generally reasonable on structural issues — stating
direct or indirect relations between assertions, but they are less
accurate on ontological grounds, that is, inferring rhetorical
relations. This is mainly because statements raised in the
course of a debate, unlike continuous text, are poor in terms
of the use of discourse markers. Consequently, most relations
are hypothesized as elaborations, while the stronger relations
that in fact hold between the arguments are not recognized.
For analyzing the following examples, we refer to the web
versions of the discourse parser developed at Nanyang Techno-
logical University [11] and of AllenNLP’s textual entailment
tool [12]. We refer to the running example Wyner and his
colleagues often have used (see Figure 1).
The ultimate goal is to incrementally build an Argumenta-
tion Graph, starting from the point of debate — “Every house-
holder should pay tax for the garbage which the householder
throws away.” and its opposite — 1) and 2) in Figure 1. We
do not have a systematic procedure for this purpose yet; in
particular, there are too many options for attachment points
when the number of arguments grows. Instead, we illustrate
contributions of the linguistic tools to the analysis of a few
examples, including some controversial interpretations that
have been discussed in previous work.
Recognizing the conﬂation of two statements — one elabo-
rating the other — into a single argument can be supported by
checking their rhetorical relation and the degree of entailment
holding between them. For example, “Recycling more is good”
4) in Figure 1), indicated as a support for “Paying tax for
garbage increases recycling” 3) is assessed as an elaboration
by the discourse parser. Moreover, the textual entailment tool
gives 66 percent entailment for this pair of statements, and
only 1 percent contradiction, which are quite strong values.
Looking at another example, an explanation relation is
predicted by the discourse parser, stating that “Every house-
holder who takes beneﬁts does not recycle” (7) in Figure 1)
explains “Every householder who does not take beneﬁts pays
for every householder who does take beneﬁts” 8); this is a
strong indication that these arguments should be nested rather
than in parallel, as assessed by the human in the debate [16].
Textual entailment gives a weak though rather consistent
evidence about the polarity of an argument, whether it is an
attack or a support — this may be helpful in case a user slips in
the use of the interface. For example, according to the textual
entailment tool, “Paying tax for garbage increases recycling.”
3) (Figure 1) is entailed by “Every householder should pay tax
for the garbage which the householder throws away” 1), at a
53 percent level, but it is assessed to be a contradiction at a 76
percent level to “No householder should pay tax ...” 2). By
the way, the weaker assertion “Not every householder should
pay tax for the garbage which the householder throws away”
is rather undecided, it yields a contradiction at a 36 percent
level, and entailment at a 26 percent level.
IV.
MAKING NATURAL LANGUAGE CONTENT
ACCESSIBLE TO LOGICAL REASONING
The proper natural language content of arguments is not
transferred to the logical level, since arguments in an Argumen-
tation Graph appear as atomic units. This abstraction prohibits
reasoning about portions of natural language statements raised
as an argument, within individual arguments, and across sev-
eral ones. A more detailed logical model would enable testing
whether a natural language statement is consistent in itself,
19
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-813-6
SEMAPRO 2020 : The Fourteenth International Conference on Advances in Semantic Processing

and whether stating an attack or a support relation between
two arguments is acceptable, that is, this does not imply a
contradiction. A richer representation of arguments can also
make more advanced versions of Argumentation Frameworks
accessible — the basic version only deals with attacks — these
may include structured arguments [8] and priorities [10] or
different strengths [1] associated with arguments.
In order to make at least portions of natural language con-
tent accessible to logical reasoning, proper linguistic analysis
has to be carried out, so that semantic issues have to be dealt
with explicitly and not only within the scope of the discourse
parser and the textual entailment tool. In [16] this task has
elaborated for restricted English, but the results are not used
for logical reasoning purposes.
In order to go beyond restricted English, the semantic
representation needs to undergo some sort of a normative
process, to cater for paraphrases and varieties of linguistic
forms. An appropriate strategy appears to be breaking down
representations into atomic relations, and mapping these rela-
tions onto the repertoire stored in a knowledge representation
repository with a preferably large set of ontological deﬁnitions,
the biggest one being OpenCyc [6], used as in [7]. Deﬁning
this uniformity-emphasizing mapping process constitutes a
challenge involving semantic issues. In dependency of the
argumentative statements in a speciﬁc debate, not all of them
need to be broken down into atomic relations; some composite
ones often reoccurring may be maintained.
A case for such composite relations can be made when
recognition of Argumentation Schemes [13][14] within a de-
bate is attempted, Appeal to Expert Opinion being such as a
scheme. The arguments 11) to 13) in Figure 1 instantiate a
part of this scheme, in terms of a critical question (“Professor
Resicke is not objective.”) 11), followed by the associated
justiﬁcation (“Professor Resicke owns a recycling company.”
12) and “A person who owns a recycling company earns money
from recycling.” 13)). Treating “Owning a recycling company”
as a single predicate is enough abstraction to recognize the
presence of the Argumentation Scheme.
V.
CONCLUSION AND FUTURE WORK
In this paper, we have discussed methods for assessing
the structure and state of a human debate. This is done by
consulting linguistic tools to make structure and content of
natural language arguments represented better and thus more
accurately accessible to logical reasoning facilities.
First steps towards operationalizing the concepts exposed
in the paper are installation of the tools we have referred to
via their demo versions, in the hope of getting more accurate
results - later versions are likely to better capture the semantics
of rhetorical relations, by incorporating results of research,
such as [3]. In addition, categorization of statements (such as,
“...is good/bad”) in combination of selected uses of linguistic
tools can be deﬁned to check/improve the argumentation
structure incrementally built. Most importantly, a systematic
procedure for building an Argumentation Graph needs to be
developed. Thereby, focusing on suitable attachment points is
important (a statement about supermarkets is likely to expand
a previously raised argument about supermarkets), as well
as a metric assessing the contextually obtained results of
linguistic tools. Moreover, analyzing focused portions of the
argumentative discourse may be suitable, taking into account
the difference between a multi-party debate and a monological
presentation, which is what discourse parsers expect.
A long term perspective lies in examining the natural
language content of arguments, complementing the atomic
perspective of logical reasoning about acceptability state of
sets of arguments by internal structures that enable checking
consistency - a ﬁrst step towards addressing plausibility.
Limitations even in advanced versions of this approach will
be reasoning functionality which requires world knowledge
more detailed than what has been made accessible to logical
reasoning, which virtually includes all background knowledge;
limited elaborations for speciﬁc domains may be an exception.
Moreover, irony is unlikely to be treated automatically in a
useful manner; it has not been addressed in the argumentation
context so far.
REFERENCES
[1]
T. J. M. Bench-Capon, “Persuasion in practical argument using value-
based argumentation frameworks,” Journal of Logic and Computation,
vol. 13, no. 3, 2003, pp. 429—448, ISSN: 0955-792X.
[2]
P. M. Dung, “On the acceptability of arguments and its fundamental role
in nonmonotonic reasoning, logic programming and n-person games,”
Artiﬁcial Intelligence, vol. 77, 1995, pp. 321—358, ISSN: 0004-3702.
[3]
N. Green and J. Crotts, “Towards automatic detection of antithesis,”
in Proceedings of the 20th Workshop on Computational Models of
Natural Argument co-located with the 8th International Conference on
Computational Models of Argument (COMMA 2020), Perugia, Italy,
2020, pp. 69—73.
[4]
H. Horacek. “Towards bridging between natural language and logic-based
representations of natural arguments,” in CMNA 12, the 12th workshop
on Computational Models of Natural Argument, Montpellier, France,
2012, pp. 21–25.
[5]
B. Mann and S. Thompson, “Rhetorical Structure Theory: Toward a
functional theory of text organization,” Text, vol. 8, 1988, pp. 243—281,
ISSN: 1327-9556.
[6]
“OpenCyc,” URL: https://github.com/asanchez75/opencyc/
[accessed:
2020-09-01].
[7]
“OpenCyc,”
URL:
https://www.qrg.northwestern.edu/OpenCyc/index opencyc.html
[accessed: 2020-09-01].
[8]
H. Prakken, “An abstract framework for argumentation with structured
arguments,” Argument and Computation, vol. 1, no. 2, 2010, pp. 93—
124, ISSN: 1946-2166.
[9]
J. Pollock, “Defeasible reasoning,” Cognitive Science, vol. 11, 1987, pp.
481—518, ISSN: 1551-6709.
[10]
H. Prakken and G. Sartor, “Argument-based extended logic program-
ming with defeasible priorities,” Journal of Applied Non-Classical Log-
ics, vol. 7, no. 1, 1997, pp. 25—75, ISSN: 1166-3081.
[11]
“Rhetorical-Analysis-Demo,”
URL:
http://alt.qcri.org/demos/Discourse Parser Demo/
[accessed:
2020-09-01].
[12]
“Textual-Entailment-Demo,”
URL: https://demo.allennlp.org/textual-entailment/MjI2ODQ0OQ== [ac-
cessed: 2020-09-01]
[13]
D. Walton. “Argumentation schemes for presumptive reasoning,” Erl-
baum, Mahwah, N.J., 1996, ISBN: 9780805820713.
[14]
D. Walton. “Argumentation schemes,” Cambridge University Press,
2008, ISBN: 978-0521723749.
[15]
A. Wyner, T. van Engers, and K. Bahreini. “From policy-making
statements to ﬁrst-order logic,” in EGOVIS, K. Normann Andersen,
E. Francesconi, A. Gronlund, and T. M. van Engers (eds.), Springer
Lecture Notes in Computer Science 6267, Springer Berlin Heidelberg
New York, 2010, pp. 47—61, ISBN: 978-3-642-15171-2.
[16]
A. Wyner, T. van Engers, and A. Hunter. “Working on the argu-
ment pipeline: Through ﬂow issues between natural language argument,
instantiated arguments, and argumentation frameworks,” Argument &
Computation, vol. 7, no. 1, 2016, pp. 69—89, ISSN: 1946-2166.
20
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-813-6
SEMAPRO 2020 : The Fourteenth International Conference on Advances in Semantic Processing

