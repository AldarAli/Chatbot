A Data-driven Workﬂow Based on Structured
Tokens Petri Net
Nahla HADDAR
MIRACL/FSEGS laboratory :Computer Department
FSEGS, Airport avenue Km 4, BP 1013 Sfax 3018, Tunisia
Email :nhaddar@ymail.com
Mohamed TMAR, Faiez Gargouri
MIRACL/ISIMS laboratory :Computer Department
ISIMS, B.P. Technology Center:
242 Sfax 3021, Tunisia
Emails :mohamed.tmar@isimsf.rnu.tn, faiez.gargouri@gmail.com
Abstract—Business
processes
design
and
implementation
within a company are mainly based on the speciﬁcation of
actors and their different tasks. Data and general information
are transmitted in a very speciﬁc organization among actors,
applications and the information system, which constitute a
workﬂow. In this paper, we present an approach for workﬂow
process modeling. The model is in charge of representing both
control ﬂow and shared data in the workﬂow process, and it can
be analysed to verify its correctness before implementation. This
workﬂow modeling approach has been implemented into Opus
system that provides a set of graphical interfaces to model and
execute the business process tasks. The system also provides a
workﬂow engine that grants automatic workﬂow processing by
interpreting the workﬂow process.
Keywords—Workﬂow modeling; Workﬂow management sys-
tem; Petri Nets; Data-driven approach; Structured token.
I. INTRODUCTION
At the beginning of this century, workﬂow management
concentrated on the design and documentation of business
process [1]. Therefore, it focused on the dependencies be-
tween tasks and their sequencing, while data and resources
played a very minor role. Many new approaches have been
introduced, e.g, Petri Nets [2], Business Process Modeling
Notation (BPMN) [3], Business Process Execution Language
(BPEL) [4], etc.; but only a few of them are of ongoing interest
in modeling the exchanged data ﬂow in the business process.
Moreover, the importance of data in business processes has
increased progressively in recent years with the appearance of
the data-driven approaches.
As execution and expressiveness have got more attention,
also validation of the workﬂow model has needed to get
attention. One big standard in this attribute is Petri Nets.
Petri Nets are currently among the best known techniques for
workﬂows speciﬁcation [5].
In this paper, we present a formal approach inspired from
the data-driven approach and the Petri Net formalism to model
workﬂow processes. The resulting model can be analyzed for
validation and automatically generated by the workﬂow engine
for process execution.
The rest of the paper is organized as follows :we illustrate
the related work in Section II and then, we elucidate our
approach for workﬂow modeling in Section III. We illustrate
in Section IV the possible information ﬂows routing. Then, we
demonstrate our approach by an example of workﬂow model
in Section V. In Section VI, we explain how our workﬂow
model can be analyzed and veriﬁed and we present our work-
ﬂow management system Opus in Section VII. Section VIII
concludes the paper.
II. RELATED WORK
Many new approaches have emerged, which shifted their
focus to combination of data ﬂow and control ﬂow. An emerg-
ing approach uses artifacts, that combine data and process by
using atrifacts and Petri Nets model, is the Business Artifacts
(BA) [6].
The BA approach focuses on solving decision problems,
related to reachability, avoiding dead-ends and redundancy,
but it does not provide a graphical notation for process
modeling. Despite it was formally deﬁned, the BA does not
provide a formal mechanism for process veriﬁcation. Process
veriﬁcation has been widely studied in workﬂow research,
with states machines in Petri Nets [7], [8], graphs [9], data
dependencies [10], etc.
Another formal approach based on Petri Nets model is the
CorePro Framework [1]. The CorePro enables to model the
data-driven speciﬁcation and then, to create automatically the
process structures based on given data structures in the model
level. As well, CorePro provides some simple rules to verify
the soundness properties of the data-driven process structures.
However, it has skipped to retain the object states which have
already been activated before the execution.
Many extensions of Petri nets in which tokens carry data
have been deﬁned in the literature, in order to improve
expressiveness of workﬂow models. Data Nets (DN) [11] are
an extension of Petri nets in which tokens are taken from a
linearly ordered and dense domain, and transitions can perform
whole place operations like transfers, resets or broadcasts.
Although, a data net can be viewed as a constrained mul-
tiset rewriting systems (CMRS) enriched with whole-place
operations. And, according to researches developped in [12],
whole-place operations augment the expressive power of Petri
nets only in the case of black indistinguishable tokens, but
not for models in which tokens carry data taken from an
ordered domain. Weakness refers here to the fact that the
CMRS encoding simulates a lossy version of data nets, e.g.,
data nets in which tokens may get lost.
All the approaches mentioned above focus on the data
154
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

routing and data managed by the process, but they consider
activities as black-boxes in which application data is managed
by invoked application components. Some of them, like DN,
can apply transitions that read from or write to some data
element, but with limited power to manage all the handled data
element. This is why processes have to be modeled at a higher-
level of abstraction to reﬂect the preferred work practice.
III. WORKFLOW MODELING USING STRUCTURAL PETRI
NET TOKENS
We have inspired from Petri Nets to propose a new workﬂow
modeling approach leading to a workﬂow process model. To
manage all the data handled by the work procedures, we use
the notion of data-driven process structures.
So, we describe the process by respective data structures,
and we deﬁne a data structure as a pair s = (C, D), where C
is a list of attributes and D is a list of tuples, each tuple is an
ordered set of attribute values. Formally, ∀n, m ∈ N :
C = (c1,c2 ...cn)
D = {(d11,d12 ...d1n),(d21,d22 ...d2n)...(dm1,dm2 ...
dmn)}
Each attribute ci is an ordered pair of attribute name ni and
type name ti, such as :
∀i,ti ∈ {SmallInt, Int, BigInt, Float, Double, Real,
Decimal, Char, V archar, Text, Date, Y ear, Boolean}
∀i,j, dij ≡ tj :an attribute value is a speciﬁc valid value
for the type of the attribute.
The workﬂow process is deﬁned as a Petri Net representing
the work, where a place corresponds to a data structure that
contains structured tokens (tuples) and a transition corre-
sponds to a task. A workﬂow is then a quadruplet WF =
(S, T, Pre, Post) where :
● S is a ﬁnite set of data structures,
● T is a ﬁnite set of tasks,
● Pre ∶ S × T → N is the pre-incidence matrix,
● Post ∶ T × S → N is the post-incidence matrix.
A workﬂow process is deﬁned by an oriented net with
two node types representing data structures and tasks
manipulating the tuples of these structures. A task consumes
data structure tuples to produce others, which can then be
consumed by other tasks.
A task t is said to be enabled if each input data structure
s ∈ S is marked with at least xi tuples (refers to Pre(s, t),
which deﬁnes the weight of the edge from s to t). A ﬁring
of an enabled task t consumes xi tuples from each input data
structure s, and produces xj tuples (refers to Post(t, s)) to
each output data structure of t. Post(t, s) is the weight of
the edge from t to s.
We have to clarify that in our case we cannot be limited
to a simple post-incidence matrix. In fact, each transition
consumes an undeﬁned number of tuples and produces a
number belonging to a well determined range, depending on
its processing (See Table I, in Appendix). For example, if a
transition is a tuples union operation of two data structure
s1 and s2 containing respectively x1 and x2 number of
tuples, it will produce a number of tuples belonging to
the interval :max(x1, x2) and x1 + x2 (because the union
operation eliminates the duplicated tuples).
So, we deﬁne two post-incidence matrices :PostMin and
PostMax, as a values interval which limits all possible
post-incidence matrices. Formally :
∀t ∈ T and s ∈ S, PostMin(t, s) :is the edge going from
transition t to place s minimal weight.
∀t ∈ T and s ∈ S, PostMax(t, s) :is the edge going from
transition t to place s maximal weight.
∀t
∈
T
and
s
∈
S,
Post(t,
s)
∈
[PostMin(t, s), PostMax(t, s)].
We explain this idea in details through the example in
Figure 1.
Figure 1.
Example of workﬂow model
The example illustrated by Figure 1 contains eight places
(s1, s2 ...s8) and ﬁve transitions (ta, tb ...te). Each edge is
associated with a weight (xi > 0).
We deﬁne its Pre matrix by :
Pre =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜
⎝
ta
tb
tc
td
te
s1
x1
0
0
0
0
s2
x2
x2
0
0
0
s3
0
x3
0
0
0
s4
0
0
x6
0
0
s5
0
0
x7
x7
0
s6
0
0
0
0
0
s7
0
0
0
0
x10
s8
0
0
0
0
0
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟
⎠
Following
the
example
illustrated
in
Figure
1,
and
the deﬁnition of its transitions in Table I, we can determine
the values range of output tokens for each ﬁred transition as
follows :
● x4 ∈ [0, min(x1,x2)]
● x5 ∈ [max(x2,x3),x2 + x3]
● x8 = x6 × x7 ∈ [x6 × x7, x6 × x7]
● x9 = x7 ∈ [x7, x7]
● x11 = x10 ∈ [x10, x10]
So, we can deduce the matrices :
PostMin :
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜
⎝
ta
tb
tc
td
te
s1
0
0
0
0
0
s2
0
0
0
0
0
s3
0
0
0
0
0
s4
0
0
0
0
0
s5
0
max(x2, x3)
0
0
0
s6
0
0
x6 × x7
0
0
s7
0
0
0
x7
0
s8
0
0
0
0
x10
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟
⎠
155
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

PostMax :
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜
⎝
ta
tb
tc
td
te
s1
0
0
0
0
0
s2
0
0
0
0
0
s3
0
0
0
0
0
s4
min(x1, x2)
0
0
0
0
s5
0
x2 + x3
0
0
0
s6
0
0
x6 × x7
0
0
s7
0
0
0
x7
0
s8
0
0
0
0
x10
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟
⎠
Using these three matrices (Pre, PostMin and PostMax)
we can derive several properties of the designed workﬂow
model to be veriﬁed. We detail this idea in Section VI.
To reach the lowest level of abstraction, we need algebra
over data structures. So, we have inspired from the relational
algebra to deﬁne the tasks needed to produce data structures
from others. As illustrated in Table I, we redeﬁne the
relational algebra operations in a formal way in order to
suit the Petri Net formality. To keep equivalence between
the attributes of data structures assigned to operations as
Union, Difference, Intersection, and Division, we deﬁne the
Permutation and Substitution operations.
Furthermore,we suggest an Extension operation to add
attributes in a structure scheme, where its values are
generated through applying a function. And ﬁnally, to insert
data structure tuples in a data structure, we deﬁne the
Alimentation operation.
As for example, we explain the Projection operation
illustrated in Table I by the following example :
Whether the structure Products = (Cj, Dj), where :
Cj = (Id, designation, price, Stock),
Dj = {(1, aa, 20.5, 1000), (2, ab, 25.0, 2500), (3, ac,
22.75, 1500).
Prod
=
(Ci,
Di)
=
(Products,
b)
such
as
b = (1, 0, 0, 1).
So, q is deﬁned as following :
q =
5
∑
k=1
bk = 2
⇒ Ci = (cjj′
1 , cjj′
2 )
j′
1 =
min
l = {1,2...5}
l
∑
p=1bp = 1
l
= 1
⇒ ci1 = cj1 = Id
j′
2 =
min
l = {1,2...5}
l
∑
p=1bp = 2
l
= 4
⇒ ci2 = cj4 = Stock
⇒ Prod = ((Id, Stock),{(1, 1000),(2, 2500),(3,
1500)})
IV. INFORMATION FLOWS ROUTING
Our workﬂow model can express sequential, conditional and
parallel routing ﬂow.
Sequential routing is used to deal with causal relationships
between tasks [8]. Figure 2 shows that sequential routing can
be modeled by our operations graph.
Figure 2.
Sequential routing
Parallel routing is used where two tasks B and C have
to be executed at the same time. To model parallel routing,
two building blocks are identiﬁed :The AND-Split and the
AND-Join [8]. Figure 3 shows that both building blocks can
be modeled by our operations graph.
Figure 3.
Parallel routing
Conditional routing is used when there is a mutual ex-
ecution between two tasks according to a condition. We can
express conditional routing by a simple network using control
operations.
Indeed, the control operation decides to continue, or not,
the information ﬂows routing according to the controlled data
structure content. Whether si is the controlled data structure,
sj is the data structure expected by the next transition if the
condition is veriﬁed, so, si will be controlled by one of the
control operations which are deﬁned as follows :
Control operation 1, noted ± :
si ± sj = { si if sj = φ
φ otherwise
Control operation 2, noted ∓ :
si ∓ sj = { si if sj ≠ φ
φ otherwise
An example of control ﬂow is illustrated in Figure 5 in
Appendix, where the structure s6, which contains all the
unpaid bills of the current customer, is used by task t5 to
decide the customer solvency. So, if s6 contains one or more
tokens, t5 will decide that the customer is not solvent, and it
will ﬁnish the order management process. Otherwise, t5 will
reproduce s2 tokens in s7 in order to be sent to Inventory
Check Role.
V. EXAMPLE MODELED USING OUR APPROACH
Consider an ofﬁce procedure for order processing within
a company. When a customer sends his order by email, the
job is sent to the customer solvency check, and then to the
inventory check. After the evaluation, either a rejection mail
is sent to the customer, or the order is sent to shipping and
billing. In this paper, we restrict our example to the solvency
check and the inventory check processes.
To simplify the representation of the model, we group the
tasks related to the same function in the company according
to roles. So, each role work is presented by a sub-process
belonging to the whole workﬂow process deﬁnition.
As shown in Figure 5, when a customer mail arrives, the
156
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

workﬂow will launch. S1 tokens (present customers data) are
to be consumed by t1 in order to select the current customer
(CC) information by his ﬁrst name and his last name (the
selection condition is to be seized by the Solvency Check Role
(SCRole) during the execution of the workﬂow).
The resulted structure s2 token (s2 contains only one token
presenting the CC information), and the s3 tokens (present
bills data of customers) are to be used by t2 to produce
a single data structure containing bills data, and the CC
information. Resulted structure s4 tokens are to be used by
t3 to create an inner join between bills data and the CC,
in order to select only the CC bills. So, s5 tokens present
the CC history on bill payment. To check customer solvency,
t4 selects only s5 tokens which have a paid attribute value
equals to false. The resulted structure s6 is to be then used to
decide the customer solvency. Task t5 is a control operation,
which veriﬁes s6 content. If s6 contains one or more tokens,
t5 will decide that the customer is not solvent (because he has
unpaid bills), and it will ﬁnish the order management process.
Otherwise, t5 will reproduce s2 tokens in s7 in order to be
sent to Inventory Check Role (ICRole).
To select the ordered products, t6 extends s8 (contains all
products data) by the ord qtity attribute (accepts only integer
values), in order to allow the ICRole to seize the ordered
quantities relatively to the ordered products. Then, t7 selects
from the resulted structure s10 only tokens having an ordered
quantity value higher than zero and lower than the stocked
product quantity. The resulted tokens are stocked in s11.
In parallel, t8 applies a projection operation on s7, to get
the structure s9 having as a token, the CC identiﬁer. If there
are available ordered products, the ICRole has to create a new
order. To verify availability, we deﬁne the control operation in
t9. If s11 contains one or more tokens (there is, at least, one
available product), t9 will reproduce s9 token in s12, then, t10
will add a new order in s13. It remains to create the new order
lines. So, the ICRole has to seize the new order identiﬁer, t13
will save his seizure in s17. Then, t14 will create the new order
lines by applying a simple inner product between s17 token
and s15 tokens (present identiﬁers of the ordered products and
their relative ordered quantities).
VI. THE WORKFLOW VERIFICATION
We provide techniques based on Pre and Post matrices,
to ensure that WF satisﬁes the minimum requirements for
correctness.
First of all, we verify that each data structure is the result
of at most a single transition. Formally, consider n places and
m transitions in the workﬂow model :∀ i ∈ {1, 2 ...n},
∀ i ∈ {1, 2 ...n}, ∣j ∈ {1, 2 ...m}, Pre(si, tj) ≠ 0∣ ≤ 1.
(1)
To explain Equation 1, we resume the example in Figure 1,
and we verify s4. So, for i = 4 :
∣j ∈ {a...e}, Pre(s4, tj) ≠ 0∣ = ∣x6∣ = 1
⇒
s4 veriﬁes
the condition.
In the rest of this section we focus on the veriﬁcation of
liveness property of the model. For us, to verify this property,
we have to begin with deﬁning the initial and the ﬁnal marking
of WF.
Formally, the initial marking i is deﬁned as : i =
⎛
⎜⎜⎜
⎝
i1
i2
...
in
⎞
⎟⎟⎟
⎠
,
such as :∀j ∈ {1, 2,...n}
ij =
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩
max
k∈{1, 2,...m}Pre(sj, tk),
if ∀l ∈ {1, 2,...m}PostMax(sj, tl) = 0.
0, otherwise.
(2)
We explain Equation 2 using the example in Figure 1 :
∀j
∈
{1...8},
the
condition
∀l
∈
{a...e}PostMax(sj,
tl)
=
0 return true only for
j = 1, j = 2 and j = 3. So, ∀j ∈ {4...8}, ij = 0.
For j = 1 : max
k∈{a...e}Pre(s1, tk) return Pre(s1, ta) = x1.
⇒ i1 = x1
For j = 2 : max
k∈{a...e}Pre(s2, tk) return Pre(s2, ta) = x2
(or Pre(s2, tb) = x2).
⇒ i2 = x2
For j = 3 : max
k∈{a...e}Pre(s3, tk) return Pre(s3, tb) = x3.
⇒ i3 = x3
As
we
deﬁne
an
interval
for
Post
matrices,
we
deﬁne an interval for ﬁnal possible markings. Formally,
∀j ∈ {1, 2,...n} :
A minimal ﬁnal marking o− is deﬁned
as :o− =
⎛
⎜⎜⎜
⎝
o−
1
o−
2
...
o−
n
⎞
⎟⎟⎟
⎠
, where :
o−
j =
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩
max
k∈{1, 2,...m}PostMin(sj, tk),
if ∀l ∈ {1, 2,...m}Pre(sj, tl) = 0.
0, otherwise.
(3)
Let us calculate o− of the model in Figure 1 :∀j ∈ {1...8},
the condition ∀l ∈ {a...e}Pre(j,l) = 0 return true only for
j = 6, j = 8. So, ∀j ∈ {1...8}/{6,8}, o−
j = 0.
For j = 6 :
max
k∈{a...e}PostMin(s6, tk) return PostMin(s6, tc) = x6×x7.
⇒ o−
6 = x6 × x7
For j = 8 :
max
k∈{a...e}PostMin(s8, tk) return PostMin(s8, te) = x10.
⇒ o−
8 = x10
The maximal ﬁnal marking o+ is deﬁned as o− but with
using the PostMax matrix instead of the PostMin :
o+ =
⎛
⎜⎜⎜
⎝
o+
1
o+
2
...
o+
n
⎞
⎟⎟⎟
⎠
, such as :
o+
j =
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩
max
k∈{1, 2,...m}PostMax(sj, tk),
if∀l ∈ {1, 2,...m}Pre(sj, tl) = 0.
0, otherwise.
(4)
157
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

Assuming i as the initial state, o as the ﬁnal state of a
process, the workﬂow model is live if and only if :
● For every state M reachable from state i, there exists a
ﬁring sequence leading from state M to state o [8]. We
adopt this rule to WF by applying the following rule :
Whether R+ (resp. R−) is the net presenting the maximal
(resp. minimal) output function, such as :
R+ = (S, T, Pre, PostMax),
R− = (S, T, Pre, PostMin),
∀M(i
∗→ R+(M)) ⇒ (R+(M)
∗→ o+),
(i
∗→ R−(M)) ⇒ (R−(M)
∗→ o−).
(5)
● There are no dead transition in the workﬂow model [8].
We also adopt this rule to WF by applying the following
rule :
∀t∈T ∃M,M ′,(i
∗→ R+(M)
t→ M ′).
(6)
We deﬁne the simple algorithm below to ensure the veriﬁ-
cation of Equations 5.
Algorithm 1 Veriﬁcation
/* t is a task to verify */
Procedure VeriﬁcationT(t)
VeriﬁcationT(t)=
⋀
i ∈ {1, 2...n}
Pre(si,t) ≠ 0
VeriﬁcationS(si);
Procedure VeriﬁcationS(s)
/* s is a root node */
if ∀j ∈ {1, 2...m}, PostMax(s, tj) = 0 then
VeriﬁcationS(s)=true;
else
/* ti is the task which has PostMax(s, ti) ≠ 0 */
VeriﬁcationS(s)=VeriﬁcationT(ti)
where
PostMax(s, ti) ≠ 0 ;
end if
We apply Algorithm 1 on the example illustrated in
Figure 1, and we choose to verify task te since its output
data structure is a ﬁnal state in the model; so, its veriﬁcation
generates the veriﬁcation of all ﬁring sequences leading from
a state M to this ﬁnal state.
VeriﬁcationT(te)=
⋀
i ∈ {1, 2...8}
Pre(si,te) ≠ 0
VeriﬁcationS(si)
= VeriﬁcationS(s7) = VeriﬁcationT(td)
= VeriﬁcationS(s5) = VeriﬁcationT(tb)
= VeriﬁcationS(s2) ∧ VeriﬁcationS(s3)
= true ∧ true = true.
To verify Equation 6, we have to verify that the model
is without structural conﬂicts. we assume that WF has a
structural conﬂict if it contains at least two tasks ti and tj
having the same input data structure s. As the case in Figure 1,
the model has a structural conﬂict caused by tb and tc which
share s2. To avoid these cases, we extend the model by adding
extra tasks T ∗ = {tcopy1,tcopy2 ...tcopyk} such as k is the
number of data structures which cause conﬂicts, and tcopy is
a Copy operation (See Table I), which allow to create copies
from a shared data structure to satisfy the need of tasks in a
conﬂict.
The extended model WF+ = (S+, T+, Pre+, Post+) is
deﬁned as follows :S+ = S, T+ = T ∪ T ∗, Pre+ = S × T+
and Post+ = T+ × S.
Figure 4.
Removing the conﬂict
So, to resume, Algorithm 1 can verify that WF+ is live.
VII. IMPLEMENTATION OF THE WORKFLOW
MANAGEMENT SYSTEM Opus
The Opus workﬂow system consists of a number of com-
ponents including a workﬂow engine and a Petri Net editor.
Workﬂow speciﬁcations can be designed using the Opus editor
and deployed in the Opus engine for execution.
The Opus engine follows the workﬂow model deﬁnition
and interprets automatically the code executing the workﬂow.
Then it invites each role to perform its tasks according to
its feasibility and urgency. The veriﬁcation of the conceived
model is automatically ensured as follows in Algorithm 1
and Equation 1. To integrate workﬂows with the Information
System (IS), we developed some tools, e.g., the Import tool
(it imports a table tuples to a deﬁnite data structure belonging
to the workﬂow process), the ImportId tool (it imports the
tuple identiﬁer of the last tuple inserted in a deﬁnite table),
the Insert tool (it inserts data structure tuples in a deﬁnite
IS table) and the Update tool (it updates a table in the IS
with a data structure tuples). To perform these operations, and
operations which requires two identical data structure schemes,
Opus system is equipped with a matching tool, which uses the
Substitution and the Permutation operations.
VIII. CONCLUSION AND FUTURE WORK
The proposed approach is modular in a sense that the work-
ﬂow process is to be decomposed on sub-processes which fa-
cilitates any eventual updates on the workﬂow process model.
In fact, the changes related to the evolution in the role work,
causes the change of its sub-process without damaging other
sub-processes. In particular, the detailed formal deﬁnition of
tasks and data structures is useful for the Opus engine, to
extract all the process speciﬁcations. However, this approach
must be completed by many functionalities. In fact, we plan
to provide techniques to verify others Petri Nets property,
like boundness, soundness, etc. We also plan to implement
a simulation tool to decision-makers, in order to improve
the business process, and a module for documents generation
(invoice, purchase order, etc.) :the system can manage the
content but not the container.
158
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

REFERENCES
[1] D. M¨uller, M. Reichert, and J. Herbst, “Data-driven modeling and
coordination of large process structures,” in OTM Conferences (1), 2007,
pp. 131–149.
[2] C. Petri, “Communications with automata,” Ph.D. dissertation, Institut
f¨ur instrumentelle Mathematik, Bonn, 1962.
[3] Object Management Group (OMG), “Business process model and
notation (bpmn)(version 2.0),” Tech. Rep., 2011. [Online]. Available:
http://www.omg.org/spec/BPMN/2.0/
[4] OASIS
WSBPEL
Technical
Committee,
“Web
services
business
process execution language version 2.0,” 2007. [Online]. Available:
http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.html
[5] W.V.D. Aalst, J.M. Colom, F. Kordon, G. Kotsis, and D. Moldt, Petri
Net Approaches for Modelling and Validation, ser. Lincom Studies in
Computer Science, 2003, vol. 1.
[6] A. Nigam and N.S. Caswell, “Business artifacts: An approach to
operational speciﬁcation,” IBM Syst. J., vol. 42, no. 3, pp. 428–445,
July 2003.
[7] W.V.D Aalst, “Veriﬁcation of workﬂow nets,” in Application and Theory
of Petri Nets 1997, P. Az´ema and G. Balbo, Eds., vol. 1248, 1997, pp.
407–426.
[8] W.V.D Aalst, “The application of petri nets to workﬂow management,”
Journal of Circuits, Systems, and Computers, vol. 8, no. 1, pp. 21–66,
1998.
[9] W. Sadiq and M.E. Orlowska, “Analyzing process models using graph
reduction techniques,” Information Systems, vol. 25, pp. 117–134, 2000.
[10] S.X. Sun, J.L. Zhao, J.F. Nunamaker, and O.R.L. Sheng, “Formulating
the data-ﬂow perspective for business process management,” Information
Systems Research, vol. 17, no. 4, pp. 374–391, 2006.
[11] R. Lazic, T.C. Newcomb, J. Ouaknine, A.W. Roscoe, and J. Worrell,
“Nets with tokens which carry data,” Fund. Informaticae, vol. 88, no. 3,
pp. 251–274, 2008.
[12] P.A. Abdulla, G. Delzanno, and L. Van Begin, “A language-based
comparison of extensions of petri nets with and without whole-place
operations,” in Proceedings of the 3rd International Conference on
Language and Automata Theory and Applications, ser. LATA ’09.
Springer-Verlag, 2009, pp. 71–82.
APPENDIX
Table I
OPERATIONS DEFINITION
Operation
Formal deﬁnition
Named :Inner Product
Description :Performs the
combination of all struc-
ture tuples with those of
another structure.
Noted:×
∀ sj = (Cj, Dj), sk = (Ck, Dk)
Cj = (cj1, cj2 . . . cjnj ),
Ck = (ck1, ck2 . . . cknk )
si = sj × sk
⇒ si = ((cj1 . . . cjnj , ck1 . . . cknk ), Di)
Where :
Di =
⋃
l ∈ {1 . . . nj}
p ∈ {1 . . . nk}
{(djl1 . . . djl
nj ,
dkp1 . . . dkpnk )}
Resulted tokens number :xi = xj × xk
Named :Selection
Description :Selects only
the structure tuples that
meet the desired criteria.
Noted :σ
Whether P is the selection property,
∀ sj = (Cj, Dj), si = σP sj
⇔ si = (Cj,
⋃
e ∈ Dj
P (e)
{e})
Resulted tokens number :xi ∈ [0, xj]
Named :Difference
Description :Subtracts
the tuples of a data struc-
ture from another one.
Noted :−
∀ sj = (C, Dj), sk = (C, Dk)
⇒ sj − sk = (C, Dj − Dk)
Resulted tokens number :
xi ∈ [xj − xk, xj]
Named :Projection
Description :Selects only
the structure columns
(attributes) that we are
interested in.
Noted :
sj = (Cj, Dj), ∀(b1 . . . bn) ∈ {0, 1}n
si = (Ci, Di) = (b1...bn)sj
Where ci is a selected (resp. not selec-
ted) attribute, if bi = 1 (resp bi = 0).
⇔
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
Ci = (cjj′
1
, cjj′
2
. . . cjj′q )
Di = {(dj1j′
1
, dj1j′
2
. . . dj1j′q
),
(dj2j′
1
, dj2j′
2
. . . dj2j′q
) . . . (djmj j′
1
,
djmj j′
2
. . . djmj j′q
)}
Such as :
q = ∑n
k=1 bk :is the number of attributes
in the structure result. And :
j′
k = min l = {1, 2 . . . n}
∑l
p=1 bp = k
l :refers to
the projection attributes indices.
Resulted tokens number :
{ xi = 0, if xj = 0
xi ∈ [1, xj], otherwise
Named :Union
Description :Groups the
tuples of two structures
into a single one.
Noted :∪
∀ sj = (C, Dj), sk = (C, Dk)
⇒ sj ∪ sk = (C, Dj ∪ Dk)
Resulted tokens number :
xi ∈ [Max(xj, xk), xj + xk]
Named :Intersection
Description :Retrieves the
common tuples of two
structures.
Noted :∩
∀sj = (C, Dj), sk = (C, Dk)
sj ∩ sk = (C, Dj ∩ Dk)
Resulted tokens number :
xi ∈ [0, Min(xj, xk)]
Named :Division
Description :Allows to
get a data structure tuples
that are associated with
all tuples of another
structure.
Noted :÷
∀sj = (Cj, Dj), sk = (Ck, Dk)
Where :Cj = (c1 . . . cnj ),
Ck = (c1, . . . cmj )
If nj > mj then :
⎧⎪⎪⎪⎨⎪⎪⎪⎩
si = sj ÷ sk = (Ci, Di)
Ci = (cmj +1, cmj +2 . . . cnj )
∀ q ∈ Di, Dk × q ∈ Dj
Resulted tokens number :
xi ∈ [0, E(xj/xk)]
Named :Substitution
Description :Changes a
structure attribute name.
Noted :⧄
∀sj = (Cj, Dj), si = ⧄(cjk , c, sj)
⇔ si = ((cj1 . . . cjk−1, c, cjk+1
. . . cjn), Dj)
Resulted tokens number :xi = xj
Named :Permutation
Description :Allows
to permute two columns
in a data structure.
Noted : ↷
º
∀si = (Ci, Di), sj =
↷
º (si, k, l)
⇔
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
k, l ∈ {1, 2 . . . n}
k < l
Cj = (ci1 . . . cik−1, cil, cik+1
. . . cil−1, cik , cil+1 . . . cin)
Dj = {(d1i1 . . . d1ik−1, d1il,
d1ik+1 . . . d1il−1, d1ik , d1il+1
. . . d1in), (dmi1 . . . dmik−1,
dmil, dmik+1 . . . dmil−1, dmik ,
dmil+1 . . . dmin)}
Resulted tokens number :xi = xj
Named :Extension
Description :Extends a
structure scheme by ad-
ding a attribute c =(n,t)
and applying a function f.
Noted :
∀sj = (Cj, Dj), si = (sj, c, f)
⇔ si = ((cj1, cj2 . . . cjn, c), {(dj11 ,
dj12 . . . dj1n , f(dj11 , dj12 . . . dj1n ,
Dj)) . . . (djm1 , djm2 . . . djmn , f(djm1 ,
djm2 . . . djmn , Dj))})
Resulted tokens number :xi = xj
Named :Add Tuple
Description :Add a tuple
of data d in a data
structure.
Noted :+
∀sj = (Cj, Dj), Dk = (dk1, dk2 . . . dkn),
si = +(sj, Dk)
⇔ si = ((cj1 . . . cjn), {(dj11 , dj12 . . .
dj1n ) . . . (djm1 , djm2 . . . djmn ), (dk1,
dk2 . . . dkn)})
Resulted tokens number :xi = xj + 1
Named :Copy
Description :Makes n
copies of a data structure.
Noted :tcopy
∀si = (Cj, Dj),
tcopy(si, n) = {Sj1, Sj2 . . . Sjk },
where k ∈ {1, 2 . . . n} and sj = si.
Resulted tokens number :xj = xi
159
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

Figure 5.
Orders management workﬂow
160
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-230-1
ICSEA 2012 : The Seventh International Conference on Software Engineering Advances

