Comparative Evaluation of Database Read and Write Performance
in an Internet of Things Context
Denis Arnst∗,
University of Passau, Passau, Germany
Email: ∗arnst@ﬁm.uni-passau.de
Thomas Herpich†, Valentin Plenk‡, Adrian W¨oltche§
Institute of Information Systems at Hof University, Hof, Germany
Email: †thomas.herpich@hof-university.de, ‡valentin.plenk@iisys.de, §adrian.woeltche@iisys.de
Abstract—In the context of the Internet of Things (IoT), there
is the need to manage huge amounts of time series sensor data,
if high frequency device monitoring and predictive analytics are
targeted for improving the overall process quality in production
or supervision of quality management. The key challenge here
is to be able to collect, transport, store and retrieve such high
frequency data from multiple sensors with minimum resource
usage, as this allows to scale such systems with low costs. For
evaluating the performance impact of such an IoT scenario,
we produce 1000 datasets per second for ﬁve sensors. We send
them to three different types of popular database management
systems (i.e., MariaDB, MongoDB and InﬂuxDB) and measure
the resource impacts of the writing and reading operations
over the whole processing pipeline. These measurements are
CPU usage, network usage, disk performance and usage, and
memory usage results plus a comparison of the difﬁculty for the
developers to engineer such a processing pipeline. In the end, we
have a recommendation depending on the needs, which database
management system is best suited for processing high frequency
sensor data in an IoT context.
Keywords–performance;
benchmark;
nosql;
relational;
database; industry 4.0; mariadb; mongodb; inﬂuxdb; internet of
things; high frequency data acquisition; time series.
I.
INTRODUCTION
Internet of Things (IoT), Industry 4.0 (I4.0), ...these
current buzzwords and many more refer to data-based man-
agement strategies, i.e., a new way of processing big and
smart data. While many papers propose data-mining algorithms
to extract commercial value from a database or a data lake
(e.g. [2]–[4]), less address the computing requirements of
such algorithms in combination with the systems writing or
reading the data. The need for such an evaluation arises,
because of the urge to become more and more precise in
the technological advancement, the quality management has
to keep up for being able to minimize defective products.
We call this the industrial data analytics process. Without
proper systems for managing high frequency data of dozens
or hundreds of different sensors, it is for example nearly
impossible to detect electrical distortions in the power supply
of precision tools for producing highest quality engine parts.
Having possible candidates of systems for managing such
data without having to pay enormous sums of money, allows
to incorporate a new level of quality management and even
predictive analytics in new ﬁelds of technological systems, e.g.,
in production, surveillance, smart home, security business or
economics that would otherwise be too expensive or too slow.
In this paper, we therefore evaluate the computing re-
quirements on all parts of an IoT and I4.0 sensor system in
a benchmark scenario for being able to recommend one or
more systems depending on the needs of the industrial data
analytics process [5]. The benchmark scenario is based on one
of our research projects, where we collect and store ≈ 4 GB
day
of sensor data. This does not sound much, but within a year
of measurement, this can grow to ≈ 1.5 TB
year, which is a lot for
a traditional database system. This is why we need to focus
on a small impact of resource usage for being able at all to
accomplish the goal of high frequency data management.
In our scenario, for simulating this big picture, we ﬁrst
store generated time series sensor data to a database, which
simulates the acquisition, and then we retrieve parts of the data
for simulating the analytics part. We think that typical sensor
acquisition computing resources have only low performance
when sitting nearby the sensor (i.e., integrated circuits only
made for reading and sending the sensor data). For the data
to reach the database server, we believe that there might be
cases where no cable connection is set up but wireless data
transportation could be installed. Although the server itself is
normally well suited concerning its computational capacity,
the low resource impact on writing is an important goal. With
reading the data, we think most work is still on the database
server, which has to ﬁnd and accumulate the needed data
points. The client that reads the data might be a normal desktop
computer or laptop, but also could be a smartphone or tablet,
so the performance impact on the reading client side also is
not to be left out. As the database server is the primary key
in performance here, since all the writing and reading work
is done there, our benchmark mainly focuses on the different
database system servers.
Of course, the typical database servers can be tuned to-
wards high performance reading or writing of data, but often
not towards both at once. This is especially the case, when a
fast retrieval is more important than a fast storage, for example
with time series data in predictive analytics. When comparing
different sensor readings at different points in time, relational
databases rely on B-tree indexes that allow a fast search for
data. These indexes are a huge performance bottleneck if
frequent updates are made. This stems from B-trees being
optimized for random ﬁlls and not for updates only coming
from one side of the tree. [6] propose structures like the
B(x)-tree to overcome this problem. Nevertheless, standard
databases do not implement specialized index structures in
most cases. Instead, specialized ”time-series” databases for this
use case exist (e.g. [7]–[10]).
To verify whether these databases are more suitable for
our application, we use the benchmark scenario presented in
37
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Section II that generates a standard load on all subsystems
of the setup, to compare relational, NoSQL and specialized
time-series databases. Section III presents our test candidates.
Moreover, our experience is that companies rely on systems
they already know and that have been proven to work stably.
Additionally, the developers often have a long experience in
standard database systems such as relational databases but
not in specialized databases like the mentioned time-series
databases. We believe that there are many installations of
traditional databases that are considered for the industrial
data analytics process instead of choosing a specialized tool,
because of the risk that comes with a software that has not been
tested and validated by the company yet. Therefore, we also
consider the implementation difﬁculty of specialized databases
in comparison to traditional systems, and we also develop
”sophisticated” algorithms for getting more performance out
of these systems, which would not be available with rather
”naive” implementations.
In Section IV, we describe different implementations we
developed for writing to the databases and reading from them.
We evaluated several ideas from [11], such as time series
grouping, which is such a more sophisticated approach.
To evaluate the database performance, we measure the load
on the involved infrastructural components, i.e., CPU, memory,
network and hard disk, and perform the benchmarking, as
described in Section V. We believe that the infrastructural
impact is most important for deciding which database is best
suited for a speciﬁc IoT or I4.0 scenario. Section VI discusses
and explains the ﬁndings. Section VII summarizes the paper
and gives recommendations for different needs in an industrial
data analytics process.
Figure 1. Simulated Test Data: Machine Angle (top) and four Data channels
II.
BENCHMARK APPLICATION
One of our current research projects is using predictive
maintenance for analyzing data stemming from a complex
tool operating within an industrial machine tool. The tool
is equipped with 13 analog and 37 digital sensors recording
mechanical parameters during operation. The machine opens
and closes the individual tool components ≈ 3 times per
second, i.e., 3 working cycles per second.
Our data-gathering application records ≈ 300 samples per
cycle from the sensors and stores them in a database for
later analysis. Basically, it stores 1000 samples
sec
. This keeps
the software structure simple and universal and requires few
computing resources on the system writing the data.
For our analysis on the client side we need to retrieve all
samples in one cycle. This does not correspond to the structure
of the database. Our client software maps the time-series data
to machine cycles by using one of the analog input channels
as abscissa. This channel, shown as top channel in Figure 1,
represents the rotatory angle of the machine tool’s main drive.
One rotation corresponds to one machine cycle. The time-
series data of this channel is a sawtooth wave. The period
of this wave is equal to the cycle time.
We use this scenario of writing and reading sensor data
as a base idea for this paper to benchmark the industrial data
analytics process. For the tests in this paper, we substitute
the actual instrumentation and signal conversion with a small
program that creates the sawtooth wave and four sine waves.
For more realistic data, we add some random noise. This
simulates the uncertainty of the sensor readings due to the
sensor resolution and electrical distortion. This prevents the
optimazation of the algorithm by hard-coding a machine cycle
duration, which would be possible if the data was completely
deterministic. Our reading algorithm, which searches for the
measured machine cycle by comparing the noisy abscissa data,
can be seen as very realistically usable this way.
Figure 1 shows the simulated data. In total, we simulate 5
analog channels with a resolution of 12 bit (represented using
2 bytes) and a sample rate of 1000 samples
sec
. This corresponds
to a data rate of 10000 bytes
sec
of simulated data at the sensor.
Later, we add timestamps for each sample with millisecond
resolution, which increases the amount of data sent to the
database server.
Figure 2 shows the ﬂow of the data through our setup. The
reason for this data ﬂow is that we think this exactly matches
a typical industrial environment, where sensors gather mea-
surements (Data-Source), a piece of small software transmits
this information to a database server (Database Writer), and a
monitoring service reads the data from the database (Database
Reader).
In our setup, the Banana Pi single board computer is
running two separate applications: the ﬁrst simulates sensor
data for replacement of real sensors. The second receives
the data and writes it to the database on our server. These
applications are linked via a Linux message queue. If the
second application is not reading fast enough to keep the
buffered data in the queue below ≈ 16 kByte, data is lost.
This is similar to reading a real sensor which does not cache
the data or waits for another application to read the data before
it overwrites its internal memory with new measurements.
Figure 2 then shows the database speciﬁc applications
with gray background. These writer and reader applications
are implemented each for InﬂuxDB, MariaDB and MongoDB,
because every database has it’s own application programming
interface. They use high-level libraries as far as possible to
access the database.
38
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Client
Server
Banana Pi
Database 
Reader
Data-Source 
(Simulation)
Database
Database Writer
IPC-
Queue
TCP or UDP 
over 
fast Ethernet
HTTP or TCP
over 
fast Ethernet
Figure 2. Block Diagram of the Test setup
For the transmission of the data, in the case of InﬂuxDB,
the writing application uses a very fast and easy to access UDP
interface. The advantage of this interface is that it is sufﬁcient
to send a simple concatenated string that is then interpreted by
the InﬂuxDB server system for commitment of the data. For
reading InﬂuxDB, we use the HTTP interface with an high-
level library, which is based on TCP packets. This is because
the UDP interface is solely for writing and the HTTP interface
is the recommended way of querying data from InﬂuxDB.
MariaDB and MongoDB both use speciﬁc TCP connections
for the writing and reading of the data.
Concerning the hardware used in our setup, the single
board-computer is a Banana Pi M3. This system uses an ARM
Cortex A7 (8 x 1.8 GHz) with 2 GB DDR3-RAM and has
Gigabit Ethernet on board.
The three databases are run on a dedicated server with an
Intel Core i5-4670 CPU (4 x 3.4 GHz), 16 GB DDR3-RAM
(4 x 4 GB) and a 256 GB SSD on SATA 3.1 (6.0 Gb/s), also
with Gigabit Ethernet. This server is different from the server
used for the measurements in [1], because, unfortunately, the
old hardware broke.
The database reader is run on a dedicated desktop computer
with an Intel Core i7-4785T (4 x 2.2 GHz with SMT), 16 GB
DDR3-RAM (4 x 4 GB) and Gigabit Ethernet.
Concerning the software, the simulation application as well
as the InﬂuxDB and MariaDB writing and reading applications
are written in C, the MongoDB writing and reading applica-
tions are written in C++. We decided to use C-based languages
for performance reasons, so that the application benchmark can
be run with native platform speed.
All systems are running a Linux CentOS 7 without X.org
server and with the same level of system updates. They are
linked via a Gigabit Ethernet switch for non-blocking network
IO.
III.
CHOICE OF DATABASES
Various publications like [8] or [12] list a huge number of
different databases. They distinguish three categories relevant
for us: Relational Database Management Systems (RDBMS),
NoSQL Database Management Systems (DBMS), and the
more specialized Time Series Databases (TSDB). For our
benchmark, we chose one system for each category. For the
selection we focused on mature (stable releases available for at
least three years) and free software with options for enterprise
support. We mainly consulted the database ranking website
[12] as a basis for selecting databases for our comparison.
As a representative RDBMS we selected the open source
database MariaDB [13]. It is a fork of the popular MySQL
database and widely used in web applications and relational
scenarios. [14] lists MySQL and its more recent fork MariaDB
combined as top RDBMS.
We selected MongoDB [15] as a DBMS advertised ex-
pressly for its usefulness in an IoT context with a lot of sensor
data. It is also the most promising document store [16].
As TSDB we chose InﬂuxDB [17], which claims to be
highly specialized in sensor data. This claim is conﬁrmed by
the score in [18].
We believe that our choice stands for all major and cur-
rently important and well-known types of database systems in
the IoT and I4.0 industrial data analytics process.
IV.
THE DIFFERENT IMPLEMENTATIONS
As seen in Figure 2 the database writers commit the sensor
data to the databases (see Section IV-A). The database readers
(see Section IV-B) read the written sensor data and then
calculate a sum for one machine cycle of sensor data, thus
simulating light analytical processing.
Each writer and reader is written for each database system,
so that we have at least three writing and three reading
applications for comparison purposes. Moreover, because of
the architecture of a database server (NoSQL vs. RDBMS vs.
TSDB), we also had to implement different ways of storing
the data. Additionally, during early development and because
of recommendations at MongoDB, we decided to write an
additional two variants in data storage and transport for both
MariaDB and MongoDB to optimize a degradation behavior
that occurs with what we call a ”naive” implementation. This
sums up to ﬁve different writing and ﬁve different reading
applications for our benchmark. Later, we will introduce a
sixth and seventh reading variant of the InﬂuxDB application
for being able to compare the reading better to the two variants
of the other database systems.
The difference is that in theoretical database lecture, we
are taught to normalize data for being able to freely ﬁlter and
combine without having redundant entries. This typical (or
”naive”) way of implementing database architectures in our
case leads to a performance degradation because of the high
frequency of values. The trouble lies in the frequent updates
of index structures and ﬁles on the hard disk. As a typical
hard disk drive (HDD) is able to perform ≈ 100 input or
output operations per second (IOPS), a traditional, normalized
approach would not be able to handle such high frequency
inserts of 1000 sensor reads per second. For still being able
to measure and compare this traditional approach, we had to
use solid state drives (SSD), which can reach about ≈ 100K
of IOPS today, which in our scenario is enough for not being
the bottleneck.
39
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Nevertheless, by using what we call ”advanced” imple-
mentation strategies, optimized towards this special problem
of high frequency inserts of data, we can reduce the number
of necessary IOPS of the database server and improve the per-
formance for having more capacity left to address increasing
workloads.
The ”advanced” approach caches all the sensor data of one
second (in our case, which could be more in reality, if needed)
and then only writes our 5 ∗ 1000 data points in one operation
to MariaDB and MongoDB. Interestingly, InﬂuxDB does the
same on the server side and caches the data until a larger block
is ﬁlled, before it writes the data down to the disk. Because
InﬂuxDB does this itself (as it is specialized for time series
data), we only had to write one version for this database server.
The aggregation of the sensor data in case of MariaDB
und MongoDB, which theoretically should be a lot faster than
the single insertion of data, unfortunately, has one big ﬂaw
that has to be considered before following this approach: As
the data has to be cached in the writing application, it is not
available on the reading side, because it is not stored in the
database, yet. So when the monitoring application needs live
view of data, an additional pipeline from the sensor read to
the live monitoring system has to be established. As we write
the data to a database ﬁrst, which allows advanced database
querying techniques not available in client software without
additional libraries, but does not allow live monitoring, we
decided that this ﬂaw has no impact in our case. Moreover,
as our reading algorithm needs complete machine cycles for
analysis, our scenario is not in the need of having live access
to the sensor data. As we also believe that many analytical
applications have no advantage of live data and still work ﬁne
when the data is available only one or more seconds later, this
ﬂaw is not further discussed in this paper.
Each implementation itself is optimized concerning run-
time complexity for reduced inﬂuence on the benchmarks by
using memory usage techniques (i.e., stack memory alloca-
tion), database speciﬁc techniques (i.e., prepared statements),
and general algorithmic design principles. This way, we are
able to achieve optimal database performance results. This
is also a reason for the usage of C and C++ as underlying
languages, because this allowed us to tune our algorithms
towards optimal performance, which would not have been
possible, for example, with a language that has no pointer
arithmetic or that uses a garbage collector. It could, of course,
also be possible, to compare the optimized implementations
in C and C++ against implementations without optimizations
like prepared statements, and others, but as this paper is about
different database processing pipelines and wants to max out
the performance, not lay out all possible code optimization
techniques, this is not covered here.
A. Database Writer and Database Structure
Now, every millisecond, the simulator (i.e., sensor) writes
a new measurement value into its local memory, overriding the
previous measurement. The sensor uses an internal clock for
this, which wakes up every millisecond. Our simulator uses the
clock_nanosleep function for simulating this behavior of
updating a measurement each millisecond, like a real sensor
could do.
The database writer application running on the single-
board computer now reads that new measurement from the
simulator (i.e., sensor) over the IPC queue, ﬁve values per
millisecond, so that we have received 1000 measurements per
second with ﬁve sensor measurements each, at the end of a
second. As the database writer is running on a computer that
has a system clock being synchronized to the real time (via
network time protocol), compared to a real sensor that might
not have a synchronized system time or no time at all, the
timestamp for the datapoint is added by the database writer.
Listing 1 shows the structure of the datapoint that is then sent
to the database: It contains the added timestamp and the set of
the ﬁve digital values read from the sensor (i.e., simulator).
The timestamp added has a resolution of one nanosecond
(for further adjustments to even higher frequencies than 1000
values per second) and uses 8 + 4 = 12 bytes of memory for
representing the second as long and the relative nanosecond
part of the corresponding second as int. The digital values
are represented as 16-bit (2 byte) integers. Thus one datapoint
uses 12 + 5 ∗ 2 = 22 bytes of memory in sum.
Listing 1. One datapoint
1 struct data_point
2 {
3
int64_t s;
4
int32_t ns;
5
uint16_t measurements[5];
6 };
1) MariaDB – Individual datapoints: This is a straightfor-
ward implementation of the data structure (we called it ”naive”
earlier). We sequentially store each datapoint as ﬁve rows in the
database table, so we have a normalized table structure (i.e.,
each measurement gets its own row). This results in a high
rate of operations on the database (1000 writes
second). The impact
could be even higher, if we had written each measurement
in a single commit, but we aggregated each sensor readout
(with ﬁve values each) in one commit, so that ﬁve rows are
inserted per commit. This means that we have 5000
rows
second of
sensor data. Moreover, it means that the index also is updated
1000 times
second and the disk probably has a four to ﬁve times
higher load, because it has to write the database log, the data
itself, the index update, ﬁle system table updates and maybe
also ﬁle access and or modiﬁcation times. For this reason, this
normalized approach is not suited for a traditional hard disk
drive.
Table I shows the structure of the data, which is based on
the data_point structure. A compound index is set on sec-
ond and nanosecond for later retrieval of single measurements
in our reading benchmark. number describes the index of the
sensor, so in our test, a value from 0 to 4 for the ﬁve different
sensor values, measurement is the corresponding sensor value.
TABLE I. MariaDB - Table structure of individual datapoints
Field
Type
second
bigint(20)
nanosecond
int(11)
number
smallint(5) unsigned
measurement
smallint(5) unsigned
Our
C
implementation
of
the
algorithm
based
on
libmariadb uses prepared statements, struct data binding
and a single commit for ﬁve rows per sensor read for higher
40
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

performance. These performance optimizations, the explicit
transaction preparation and commitment and the manual cre-
ation of tables necessary for a relational database (not needed
in the other database systems) make the MariaDB code the
largest and most complicated of all our implementations.
2) MariaDB – Bulk Datapoints: As mentioned in Sec-
tion IV and in the preceding paragraph, this implementation
collects all datapoints for one second in memory (i.e., same
int64_t s value), creates one JSON document per second
and writes this document out as one row per second. Thus,
we can store the data in bigger units, which reduces the load
dramatically. Instead of 1000 writes
second with 5000 rows per second,
we now only have 1 write
second with 1 row per second and only 1
index update per second.
For the storage of the JSON document, the table structure
is a little bit different. In MariaDB, the JSON ﬁeld is an alias
for longtext ﬁeld. Yet, the specialized JSON query commands
in MariaDB work for such ﬁelds, which could allow to later
query within the JSON data directly, though we did not use
this approach in our reading benchmark, because of other
reasons discussed later. Table II shows the used structure
with this approach. second has an index, again for faster
retrieval of the data later in our reading, size contains the
length of the text in the JSON ﬁeld, and measurements is the
mentioned JSON document, built in linear time according to
the example in Listing 2. The JSON document now contains
the nanoseconds with the related measurements according to
the data_point structure. We did not save the amount of
measurements (ﬁve) within the JSON document, because we
have a deﬁned data_point.measurements size of ﬁve.
This means that we can save this space in our scenario, as
we will never have fewer or more than ﬁve measurements per
sensor read per millisecond in our datapoints.
TABLE II. MariaDB - Table structure of datapoints in bulk
Field
Type
second
bigint(20)
size
int(10) unsigned
measurements
json
Listing 2. MariaDB - JSON Documents
1
{
2
"measurements": [
3
{"ns":346851124,"m":[389,792,602,315,552]},
4
{"ns":346933204,"m":[516,794,634,317,559]}
5
...
6
]}
The difﬁculty of this adaption is similar to the original,
individual approach, but in one detail is quite complicated:
As it is theoretically impossible to know how many mea-
surements one cycle will have (most of the time the stated
5000 measurements per second in our case, but this is not
guaranteed in a real-world scenario), we needed to implement
a dynamically growing character ﬁeld for the JSON data. We
also needed to change the struct binding in the transaction
commitment for honoring the dynamical length of the JSON
data. As dynamic arrays copy their memory contents multiple
times while growing, this theoretically reduces performance.
But as we use a global string variable and as the length of the
datapoints as string is always very similar, the dynamic string
normally only grows during the ﬁrst iteration and then is not
reallocated anymore in subsequent calls. This is why we can
state that the JSON document is built in linear time during the
benchmark.
3) MongoDB – Individual Datapoints: As a document-
orientated database, MongoDB allows for ﬂexible schemata,
which allows us to leave out any schema creation. Data
is internally organized in BSON (Binary JSON) documents,
which are in turn grouped into collections.
Saving the individual datapoints according to Listing 1,
each measurement would be a document with the time of
measurement and the values organized as a JSON-array. This
is like a mixture of the individual MariaDB and the bulk
MariaDB approach, just with a JSON document per sensor
read, so with 1000 JSON documents per second.
The database supports setting an index on a ﬁeld of a
document, so to support further searching of measurements,
we set an index on time as we have in MariaDB. With such a
structure, similar to the individual MariaDB approach, numer-
ous documents are created per second. After each document
has been added, the index also needs to be updated, which
results in a similarly high computational effort as with the
individual MariaDB approach.
The software for the MongoDB database writer is written in
C++ and uses mongocxx in conjunction with the bsoncxx
library. The document orientated approach of MongoDB makes
designing data structures very ﬂexible. However, the freedom
leads to more work on the initial programming approach, as
there is no schema for clear orientation. Also the need to link
two libraries creates additional effort.
4) MongoDB – Bulk Datapoints: As already stated in
Section IV-A2, we can store a collection of datapoints at once.
In MongoDB, we can implement this with the structure shown
in Listing 3.
Listing 3. Datapoints in bulk
1
{
2
"time" : ISODate("2018-02-12T19:56:49Z"),
3
"measurements" : [
4
{ "time" : ISODate("2018-02-12T19:56:49.13
5Z"), "sensors" : [ 0, 0, 0, 9, 347 ] }
,
5
{ "time" : ISODate("2018-02-12T19:56:49.13
6Z"), "sensors" : [ 0, 2, 4, 10, 351 ]
},
6
...
7
]
8
}
The time value of the top-level document has again a
precision of one second. This document holds all datapoints
sampled during this second in an array, similar to the bulk
MariaDB variant. Every nested document contains the exact
time of its measurement and the actual sensor-values. This
is similar to the MariaDB JSON document, though the time
has no extra ﬁeld and the nanoseconds have a deﬁned format
(ISODate) that bloats the document. Of course, we thought
about using the nanosecond solely, like with MariaDB, but
MongoDB recommended the general use of ISODate, so we
followed this recommendation.
41
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

With this approach, similar to MariaDB, the index has to
be updated only once per second resulting in optimized write
performance. Nevertheless, it must be considered that in this
case only a whole second but no parts of it can be retrieved
efﬁciently. Although MongoDB can retrieve values directly
within a JSON document, similar to MariaDB, the document
ﬁrst has to be loaded and parsed, before the database server can
ﬁnd the queried value. However, because of the high increase
in write throughput, we accept this drawback.
Similar to the MariaDB approach, the application creates
a document for a whole second and ﬁlls it until the second
has passed. Then it sends the document to the database server
once per second.
The documentation for MongoDB provides examples for
the use of streams and basic builders consisting of function
calls. We followed these examples as well as possible with
our implementation. Yet the use of nested structures and the
nature of C++-streams is poorly documented in the doxygen-
based manuals, increasing the implementation effort.
5) InﬂuxDB: As a time-series database InﬂuxDB has a
strict schema design we have to follow. Every series of data
consists of points. Each point has a timestamp, the name of
the measurement, an optional tag, and one or more key-value
pairs called ﬁelds. Timestamps have an accuracy of up to
one nanosecond and are indexed by default. The name of the
measurement should describe the data stored. The optional
tags are also indexed and used for grouping data. Data is
retrieved with InﬂuxQL, a SQL-like query language. Data is
written using the InﬂuxDB Line Protocol (Listing 4). This
is how the protocol is built up: The ﬁrst string is the name
of the measurement, here simply measurement. Subsequently
follow the key-value pairs with ﬁve measurements and ﬁnally
a timestamp in nanosecond precision.
Listing 4. InﬂuxDB Line-Protocol example
1
measurement m0=0, m1=0, m2=0, m3=9, m4=347
1518465409001000000
The database writer for InﬂuxDB is written in C. The de-
fault API for InﬂuxDB is HTTP. For our high-frequency write
access however, we chose the UDP protocol, which is also
supported. We believe that the overhead is smaller when using
the UDP protocol, because HTTP is a very verbose protocol,
especially when sending small requests very frequently like in
our case. So in this case, the data is composed into the Line
Protocol with simple C-String functions and sent with the Unix
function sendto. Since no external code is required and a
custom design of the data structure is not possible, using the
database is straightforward and fast to implement.
Additionally, InﬂuxDB also offers built-in functions to
process data statistically and a client library is not necessary,
which is a beneﬁt for software developers using it, when small
overhead is desired.
Of course, the choice of UDP has the probability of data
loss, which is acceptable in our use case, because we have
very high frequency data and the loss of single measurements
could be compensated, for example by interpolation, or just
be ignored, when reading. For enabling the UDP service of
InﬂuxDB, the OS was conﬁgured corresponding to the infor-
mation provided by InﬂuxData [19]. Because we use dedicated
computers linked together with a nonblocking switch, we had
no measurable UDP loss in our tests. When using a wireless
link between database writer and database server, maybe the
HTTP protocol should be preferred despite the large overhead.
With InﬂuxDB, additional implementation variants were
not needed, because the scheme is ﬁxed and InﬂuxDB itself
caches, accumulates in bigger units and even compresses the
data, before it is written to disk. This is why InﬂuxDB is
the only database system that works out of the box for time
series data without additional effort in optimizing the datapoint
storage.
B. Database Reader
In our reading part of the benchmark, we want to simulate
an interactive monitoring application. We use the database
reader application variants to retrieve the data for three ran-
domly selected machine cycles per second. The rate of 3 reads
sec
is quite high for an interactive application, where a user
selects individual machine cycles for further analysis, but we
assume the user clicks very fast and often. A non-interactive
application, e.g., condition monitoring for predictive analytics,
will process the consecutive cycles at the end of the data
set, not randomly selected cycles. As the most recent data
might still be cached inside the database or page cache of the
operating system, and could also be selected by just jumping
to the end of the data set minus a selected range, our random
selection is an adequate usage scenario between worst and best
case. As we select by time and always have set indexes on the
time, the selection should not trigger sequential scans of the
data but make usage of our selected database structures.
t
t1
t2
t4
t3
t3
t5
t5
t (s)
0
0.334
1.334
1.667
value
0
1024
2048
3072
4096
Figure 3. Strategy to ﬁnd start and end time for a machine cycle
Figure 3 explains our implementation of the reading al-
gorithm. We start at t, which is randomly selected in our
benchmark. From there we search forward to t1, the ﬁrst point
after t where the data of the abscissa-track is bigger than half
the amplitude. This value is ﬁxed, as we know the range of the
abscissa amplitude. From t1 we search backward to t2, the ﬁrst
point before t1 where the data of the abscissa-track is smaller
than an eighth of the amplitude. From t2 we search backward
to t3, the ﬁrst point before t2 where the data of the abscissa-
track is (again) bigger than half the amplitude. The start point
of our cycle is at t4 the minimum value of the abscissa-track
in the range t3 ≤ t4 ≤ t2. The end point of the cycle is at
t5. We ﬁnd t5 by searching forward from t1 for the ﬁrst point
where the data of the abscissa-track is (again) smaller than an
eighth of the amplitude.
This strategy can be implemented by issuing several
SELECT statements to the databases. In the following we refer
to this strategy as ”individual”.
Alternatively we can simply retrieve data for a longer time
span around the time t in question, e.g, ⌊t − 1 sec . . . ⌊t for
42
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

t − ⌊t < 0.5 and ⌊t . . . ⌊t + 1 sec for t − ⌊t ≥ 0.5, and
then perform the same search operation on the retrieved data
in memory. This alternative way is necessary for the write
strategies in sections IV-A2 and IV-A4 where the database
structure does not allow to retrieve individual samples with
high performance. We said that the database allows individual
selection with JSON query commands, but as the data has to
be loaded and parsed in either way, we could just send it to
the client application and work with the aggregated second
on the reading side, again, just as when we aggregated on the
writing side. This leads to the ﬁve (or seven with the InﬂuxDB
alternatives) different reading applications, so that we have a
direct comparison to the ﬁve writing applications. Moreover,
we believe that the direct queries are slower, for example in
MariaDB (see Section IV-A2), because for the selection of
several time points in one document, the data has to be loaded
several times in sequence for each select statement. When we
copy the whole JSON block to the client side, parse it in linear
time O(n) and search solely in-memory, we can guarantee a
single read on the database side and reduce the possible load
on the server, as well as guarantee the linear searching time
on the client side. In the following we refer to this strategy as
”bulk”.
For InﬂuxDB, while we can retrieve individual datapoints,
we also had a bulk variant that read the whole block with
all measurements as with the MariaDB und MongoDB bulk
variants, and we implemented a ”bulk-1” variant of this strat-
egy, which reads only the data in the column corresponding
to the abscissa track, i.e, the machine angle, as a block, and
reads the data for the other four columns in a second read
operation spanning t1 . . . t5. The reason for this is that a
machine cycle in our benchmark is ≈ 0.33 sec and when we
read a block of a whole second, many measurements (of ≈ 3
machine cycles) are transmitted, though only around one third
of the data (one machine cycle) is really needed. With our
MariaDB and MongoDB bulk variants, we had to transmit
the whole block to prevent the database from parsing the
data multiple times, but InﬂuxDB has the ﬂexibility to load
blocks of different datapoints. We were able to investigate
the transmission bandwidth with this behavior, at least for
InﬂuxDB, too. This is why we have seven reading applications.
V.
TESTING
Most applications in our context face limitations in terms
of computing power and network bandwidth. For example, IoT
sensor devices in the ﬁeld of smart home are often battery pow-
ered and wirelessly connected. In I4.0 context, sensors have
no computing power for analytical data processing and they
often are connected via proprietary protocols and interfaces.
Although servers are often better equipped, the client systems
like tablets, smartphones or notebooks have limited computing
capacity in comparison. Consequently, when writing data from
the sensor to the server, in our scenario, we measure the
load on the single board computer, the load on the server,
and the network load. When reading data, we measure the
load on the server, the load on the client, and the network
load as well. With these measurement parameters, we have a
good overview of all critical components of the industrial data
analytics process.
For the concrete measurement process, we deﬁned the
following: The system load on the computers is measured
in terms of CPU and memory usage. For this, we created a
script, which runs the speciﬁed application for 15 minutes,
after a warm-up phase of 5 minutes for ﬁltering out cold-
start phenomenona like caching data in the operating system
page cache, or CPU clock changes due to heat or power usage
(especially on the single board computer, which reduces its
CPU clock under heavy load).
Before the test run stops the application, it uses two Linux-
System commands to gather the following parameters: LCP U
indicates the processor usage. We obtain this value with the
Linux command ps -p <pid>
-o %cpu, which returns a
measure for the percentage of time the process <pid> spent
running over the measurement time.
The maximum value for one core is always 100%. There-
fore, on our 8-core single-board computer, the absolute max-
imum value would be LCP U = 800%. On the server with
4 cores, the absolute maximum value is 400%. The client has
simultaneous multithreading enabled, so its 4 cores are doubled
to 8 threads in the operating system, for an absolute maximum
value of 800% instead of 400%.
Lmem indicates the memory usage in kByte. We use
the amount of memory used by the process <pid> as
the sum of active and paged memory as returned by
the command ps aux -y | awk ’{if ($2 == <pid>
) print $6}’. It outputs the resident set size (RSS) mem-
ory, the actual memory used, which is held in RAM.
Ldisk shows the the amount of disk used by a database
server. To determine this parameter, we ﬁrst empty the respec-
tive database completely by removing its data folder. Then we
start the database and measure the disk space of the folder
before we test. After the test we measure again the used disk
space. Ldisk is then calculated as the difference between the
folder size after the test and the folder size before the test with
an empty database folder. du -sh <path> is used to get the
disk consumption of the respective data folder.
To put the results in perspective: Our benchmark applica-
tion gathers and transmits ≈ 26.4 MByte of raw data during
the 20 minutes of our test. This is calculated as the following:
We have 5∗2 bytes of sensor data plus 12 bytes of timestamp
data per sensor read. We read each sensor 1000 times per
second. This sums up to (5∗2+12)∗1000 = 22000 bytes per
second, or 22 kBytes per second. We measure 20 minutes (of
which 15 minutes are used for the CPU, memory and network
measurement). So we have 22 kBytes∗60 s∗20 min/1000 =
26.4 MBytes, if no sensor value is omitted (which can happen
in the UDP InﬂuxDB writing test).
LIO then shows the average disk input-/output in kBytes
s
caused by the database writing operation being measured using
the pidstat command. As we use a SSD on the server, we
have raised the hardware limit of the IOPS a lot, compared to
a traditional HDD.
Lnet ﬁnally shows the average bandwidth used on the
network. We obtain that value with the command nload.
We run our test in the university network and therefore have
additional external network load (for example DHCP packets,
ARP requests, discovery services, ...). However before each
test, we observe the additional network load for some time,
and as it was always smaller than 1 kBytes
sec , we neglect it.
To put LIO and Lnet in perspective: In our benchmark we
transfer 22 kBytes
sec
from the simulator to the database writers,
43
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

but as the raw data has to be packed into UDP or TCP
packets, which itself are packed into ethernet frames, the
network load has to be larger than the raw data. Especially
in case of the RDBMS and NoSQL database, we have an
additional communication protocol overhead (like SQL in
case of MariaDB), which adds more data to transmit than,
for example, the InﬂuxDB Line Protocol does. Our network
bandwidth results show the data plus the overhead for being
able to see what the individual applications really need as
underlying network throughput.
As our network connection between the tested systems is
always 1 Gbit
sec , our hardware network limit is high enough for
our benchmark. Nevertheless, when using slower or weaker
connections (i.e., wireless network), the network bandwidth,
that may also differ in time, has to be considered as a hard
limit.
Before each test, we reboot the operating systems used in
the test. In case of a write test, we then erase the database
folder before starting the database. Then we turn on the
simulator of the sensor data (in case of a write test), the
database server (always), log in to the single-board computer
(in case of a write test) or the client (in case of a read test) and
start the database writer or reader software for the currently
active database. The actual benchmark begins with restarting
the database reader or writer after the warm up phase. The
database folder of course is not deleted after the warm up
phase and is measured over the whole 20 minutes, because
this could interfere with the other measurement parameters
like CPU, memory and disk IOPS. The reason for this is that
index structures like B-trees are never completely ﬁlled, but
at least 50%. This is for faster insertion in consecutive insert
operations, as the tree does not have to be updated for each
insert operation. When the database is empty though, the tree
is small and has to expand fast during the ﬁrst minutes, as
there are, in absolute numbers, not enough empty buckets
for holding all the high frequency values. After the warm-
up phase, we believe that the index tree is big enough (as
1
4 of the data is already written and the tree has enough
space left for approximately another fourth, when it is ﬁlled
between 50% to 75%), so that tree rebalancings do not occur
often, and have no noticeable impact on the other measurement
parameters anymore. Of course, this example calculation of the
tree structure is not exactly precise, but explains very well why
we do not clear the database folder again after the warm-up
phase.
So in the end, we let the system gather the CPU, network,
memory, and disk IOPS data only for the 15 minutes phase
and the results from the 5 minutes warm-up phase are thrown
away, except for the disk usage, as stated. The performance
data detailed in Section VI is gathered by two scripts running
on the computers used for the test, which start and stop the
applications and measure the resource usages. We test each
database server and each writing-reading application bundles
sequentially, as testing everything in parallel would interfere
with each other’s measurements.
VI.
RESULTS
Tables IV and V show our results for writing, respectively
reading. Figures 4 and 5 then visualize the data in relation to
the maximum values for each criterion.
To directly compare all our candidates, we calculate a
combined score by weighing the parameters. We think that
there are parameters that are more important in an IoT and I4.0
context, than others. We distinguish between critical (weight
of 3), important (weight of 2) and normal (weight of 1).
Since we ﬁnd that the CPU is the most critical and limiting
parameter, we give it a weight of 3 on the server. On the client
it might even be more limiting due to the Banana Pi’s low
power design, which also justiﬁes a weight of 3.
In absolute terms, the RAM usage on server and client was
very small compared to the available RAM, and therefore we
give it a normal weight (with 1).
As already stated, we used an SSD for our benchmarks,
which would not be a limiting factor in our tests. Nevertheless,
as it is possible to have a server with an HDD, which in that
case would be critical, we value the LIO parameter with a
mixture of both scenarios as important (so 2).
As the disk usage already correlates with LIO (i.e., both
disk parameters), we weight it with 1, so that the impact of
the disk results is in a decent relation to the other component’s
results. Additionally, the disk usage is not critical, as disk space
is easy to expand, but for example a high-performance CPU
can not easily be doubled to increase processing power for
non-parallel algorithms.
In wide areas, network-bandwidth could be a limiting
factor, especially when we have wireless connections, for
example in smart home scenarios. As in our main context of
IoT and I4.0, where we believe it is easier to connect the
machines with cables (as they need a large power supply,
too), we give the network an important weight (of 2). Wireless
scenarios would require an even bigger weight.
Finally, we take the subjective difﬁculty of our implemen-
tations into account. We grade on a scale from 5 (i.e., most
difﬁcult), to 1 (i.e., easy), and weight this parameter with a
normal weight. The individual rating is determined by the
experience with the client implementation described in Section
IV. We know that this parameter is not objective, but as we
explained in Section I, the developer experience is an important
argument in deciding which database is selected. Nevertheless,
because we do not want to give a subjective parameter an
important weight, we only weight it with 1, as stated.
Based on the gathered result data, we calculate a score
according to the following formula, where
i = {net, CPU, mem, IO, . . .} and
imp = {MongoDBindividual, MongoDBbulk, . . .}:
Scoreimp =

1 −
P
i

Li
maxi(Li) · weighti

P
i weighti

 · 100%
In this formula, we ﬁrst normalize the resource usage to the
maximum value for each column in Tables IV and V. Then we
sum up the weighted normalized values, and normalize again
to the sum of all weights. Lastly we ”invert” the value by
subtracting it from 1. Thus, the best score is 100%.
Table III shows the aggregated scores for writing and
reading. The total score is the average between write- and
read-score. For writing, we only have one InﬂuxDB appli-
cation, which is the reason for the same score in all three
InﬂuxDB-Writing cells. The ranking and data differs from our
44
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE III. Scored Ranking
Writing
Reading
Total
Implementation
Score
Rank
Score
Rank
Score
Rank
MariaDB Individual
15%
7
71%
5
43%
6
MariaDB Bulk
59%
1
83%
2
71%
1
MongoDB Individual
35%
6
50%
7
43%
7
MongoDB Bulk
54%
2
60%
6
57%
5
InﬂuxDB Individual
39%
3
93%
1
66%
2
InﬂuxDB Bulk
39%
3
80%
4
60%
4
InﬂuxDB Bulk-1
39%
3
82%
3
61%
3
previous benchmark in [1], as we repeated all benchmarks in a
completely new environment, due to the fact that the previous
setup and hardware was not available anymore. In the previous
paper, we also used analog circuitry and a signal-generator for
generating our sensor data, but as this device was no longer
available, for this benchmark, we use a simulator to generate
our data. Moreover, we adapt the weights to be more objective,
which also has an impact on the ranking. Nevertheless, the
order of the ranks is the same as last time, so we think our
new setup is quite comparable.
A. Write Benchmark Results
In the write benchmarks, all ﬁve implementations show
little CPU usage with LCP UServer ≤ 5% on the server and
with LCP UClient ≤ 14% a signiﬁcant but not critical CPU
usage on the Banana Pi. MongoDB individual, MongoDB bulk
and MariaDB bulk are the least demanding implementations
with respect to the server’s CPU. MariaDB bulk also is least
demanding on the client’s CPU. We can see that the server
CPU usage is in all cases far from critical, with the client CPU
usage being much higher.In cases of InﬂuxDB and MariaDB
Individual, as the CPU usage is a lot higher, this can limit
the amount of sensor information or the frequency, that the
database is able to process, earlier, than in the other scenarios.
The parameters LmemServer and LmemClient are fairly
uniform and non critical. We can see that the server’s mem-
ory usage is a lot higher in all scenarios, compared to the
client’s memory usage. This is because of the database servers
being complex software products, requiring some memory to
operate. Nevertheless, with typical servers having often more
than 16 GBytes of memory nowadays, the memory usage is
always uncritical. As the client’s memory usage in the write
benchmarks is only a few megabytes per test run, we can
say that this also has no real impact. It is interesting that the
InﬂuxDB UDP Line Protocol writing application uses by far
the least amount of memory on the client. This does make
sense, because we had no additional libraries involved in this
writing application.
Lnet is also similar for all systems. With Lnet
≈
400 kBit/s MariaDB bulk needs less network bandwidth.
We think, this is because the data that is sent to MariaDB
in the bulk variant, is transferred as binary data (i.e., bulk
data binding) attached to the insert SQL statement. All other
variants have either more individual transport operations, or
transport the data with more describing variables. For example,
InﬂuxDB always sends the full measurement name and the
timestamp as full timestamp with nanosecond precision, while
MariaDB bulk splits the timestamp into the second (transmitted
once) and the nanoseconds since the last full second. Mon-
goDB also is more verbose because of the JSON-format with
the ISODate. We believe that this explains, why MariaDB bulk
has the least network demand in writing.
In terms of disk usage, the compressing databases (i.e.,
InﬂuxDB) have a clear advantage. With Ldisk = 5 MByte
InﬂuxDB is the best in the test. Nevertheless, the bulk variants
also need signiﬁcantly less disk space than the individual
variants. This is easy to explain, because in the individual data
point rows, informations like the second are redundantly stored
for each row. Moreover, the index structures are larger, as they
have to reference more rows than in the bulk variants.
Concerning the implementation difﬁculty, InﬂuxDB was
the easiest, needed the fewest lines of code, no additional
libraries, and no schema to deﬁne. MongoDB Individual and
bulk was much more difﬁcult, because it needed two additional
libraries (with BSON instead of JSON not being a well known
data structure) and more effort in creating a schema for the
document storage. MariaDB was most difﬁcult in both cases,
as in the individual case, the schema and index structure was
more complicated (i.e., combined index, which needs attention
in the deﬁnition because it is sensitive to the order of the
deﬁnition of the columns), while in the bulk case, the schema
and index were easier to deﬁne, but additional effort was
needed for the buffering of the data up to one second, before
the commit. Both MariaDB variants needed the most lines of
code and had advanced techniques like prepared statements
and bulk data binding applied for optimal performance, which
increased the difﬁculty for the developer.
The way we wrote our data was relatively simple concern-
ing its structure and insertion since we made no preprocessing
for our analytical reading algorithm. Especially for InﬂuxDB
this made the implementation very easy and straightforward
because we could used the given schema. This led to a more
difﬁcult implementation on the reading side.
With our weighting, however, MariaDB bulk is the best
ranked database. It needed the least resources concerning the
critical CPU usage and the important network usage. Its disk
usage was average, though the disk IOPS were worse than
MongoDB and InﬂuxDB. Although its implementation was
more difﬁcult, it scored a little bit higher than MongoDB
bulk, especially because of the much higher CPU usage of
MongoDB. The InﬂuxDB writer only performed third, because
it needed a lot more CPU resources on the server side, due to
its buffering and compression mechanism.
B. Read Benchmark Results
In the read benchmarks, MongoDB individual could not
keep up with 3 reads per second, as we deﬁned in our scenario.
This means that MongoDB individual has a noticeable latency
in the interactive application use case. With LCP UServer ≈
87% (single thread, so maximum is 100% here) it almost
blocked our database server, which would further delay parallel
queries from other reading clients.
MongoDB bulk was better concerning the CPU usage on
the server side, but caused a high load on the client with
LCP UClient ≈ 16%. We attribute this to the JSON-formatted
entries that the client had to parse. As we used a library for
parsing, we could not optimize the parsing process towards
this special JSON format, like we could do in MariaDB bulk.
This is why MariaDB bulk has the least CPU impact, as
it only refers to loading blocks of data and sending them
45
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

over without further processing, because the client application
parses the JSON data. This might have been different if we had
used the server side JSON query mechanisms that we wanted
to avoid because of the impact on the CPU usage. MariaDB
Individual obviously causes a higher CPU load as it has to
look up more individual table entries, and InﬂuxDB also uses
more CPU power than MariaDB, as it has to decompress the
data it previously compressed while saving.
For all approaches but MariaDB Individual, LIOServer is
below the data rate of 22 kByte/s that is theoretically required
for reading 3 machine cycles per second (with each being
≈ 0.33 sec), i.e., the same data rate as in the write benchmarks.
We attribute this to the databases or operating system caching
data in memory and the relatively small amount of data stored
during our test ( ≈ 26.4 MBytes). With several hundred
gigabytes or even terabytes of data, we might have overcome
this problem when randomly selecting machine cycles. In
a real-world scenario, where sensor information for several
hundreds of sensors is logged over many years, we believe the
outcome for the disk IOPS in reading will be different to our
benchmark.
The memory footprint LmemServer is comparable to the
writing benchmark, which is obvious in case of MariaDB
and MongoDB being complex database systems. Interestingly,
InﬂuxDB had much lower memory usage, which we believe
lies in the fact that when writing, InﬂuxDB buffered and
compressed the incoming data, while when reading, does
not have to buffer anything and uses decompression methods
normally being less memory intensive, as no code book has to
be built up and held in memory.
Concerning the client memory, InﬂuxDB individual and
bulk loading with all data were best in the memory usage.What
surprised us was the memory footprint of InﬂuxDB, when bulk
loading only the data of the abscissa track and then loading the
machine-cycle in a second run (bulk-1) was tested. Although
the CPU usage was lower, as less data had to be processed
on the client side, the memory usage was clearly higher than
in the other scenario. Unfortunately, we detected a memory
leak in the code that was used for this benchmark, after the
testing environment was already shut down and disassembled.
We believe that the memory footprint should have been similar
to the other two InﬂuxDB reading benchmarks.
The network bandwidth was much higher when reading
than while writing. We think that this lies in the fact that in case
of the individual queries, we sent six queries to the databases
that each had to run three times per second over the network,
and in case of the bulk queries, we always had to load two
seconds of data (six machine cycles) three times per second for
being able to select one machine cycle in the client application
then. InﬂuxDB performed best in its individual case, having
less impact than when writing, which does make sense, as the
protocol needed to transmit only the ﬁltered data.
The difﬁculty rating is that MongoDB was the easiest
in this part, because the deﬁned scheme used on writing
as well as the ability of MongoDB to help us with the
JSON (or BSON) parsing by its libraries, made it adequately
difﬁcult to implement. InﬂuxDB in its individual variant also
was comparably easy to implement due to the given scheme
and simple InﬂuxQL language. The bulk variants were more
difﬁcult in InﬂuxDB, because InﬂuxDB itself did not bulk-
store the data, so we had to manually select more data, though
InﬂuxDB could have ﬁltered it for us server-side. We wanted
to compare the resource impact of bulk variant reading in
InﬂuxDB, but to sum up, this is not advisable, as the beneﬁt
compared to individual loading is small in the resource usage,
but the implementation is a lot more difﬁcult. MariaDB was
by far the most difﬁcult part, because even sending out the
individual queries needed prepared statements and data binding
mechanisms, which bloated the code a lot. The MariaDB bulk
variant was the most difﬁcult to implement, because we had
to write a complete JSON parser ourselves (to be fair, only a
highly optimized JSON parser for the underlying data structure
was built, no general use parser) for guaranteeing linear parsing
time for six in-memory queries, because we believe the that
the database itself would have parsed the data multiple times.
With our weighting, InﬂuxDB individual is the best
database for reading. This is because even though the overall
CPU usage was higher than in case of MariaDB bulk, the
other resource usages (like memory, disk IOPS and network
bandwidth) were all lower. Moreover, it was relatively easy to
implement, compared to the other variants.
We cannot recommend MongoDB individual, but Mon-
goDB itself already recommends to bulk-write and -load
the data. So at least, we can conﬁrm this recommendation.
MongoDB bulk, however, was still not very fast. We believe
that this lies in the high CPU usage on the client, which
is caused by the BSON library we used, which parses the
document data in a more general and thus not optimized for
this speciﬁc use case way.
MariaDB Individual on the hand end is normalized, like
theory says is a good practice, but for this speciﬁc use case,
the memory, CPU and disk usage on the server are quite high
in comparison. MariaDB bulk is deﬁnitely the recommended
way, despite its difﬁcult implementation, as it causes nearly
no load on the server and client, especially because we also
implemented a highly optimized JSON parser for our own
document structure.
C. Summary
In total we ﬁnd MariaDB Bulk as the best implementa-
tions altogether with a score of 75%. However, the MariaDB
implementations are quite complex and in our case, they
were written by an experienced developer, who knew how
to optimize the workload. This means that RDBMS are still
capable of working with the types of data we investigated.
With 66% the InﬂuxDB individual implementations are not
far behind, while being much easier to implement. We believe
that if the developer is willing to learn a new database system
for this use case of time series data management in the context
of IoT and I4.0, InﬂuxDB might be the right choice.
VII.
CONCLUSION
We introduced a complete benchmark set that was inspired
by real world scenarios from IoT and I4.0 scenarios and
benchmarked a set of three different types of database systems
with one or more variants of writing and reading applications
to simulate the behavior of high frequency monitoring and pre-
dictive analytics in the context of the industrial data analytics
process.
While we presented MongoDB as a good candidate in
[1], we had to observe a lack of performance in the read
46
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

benchmarks. This might be caused by our high-frequency, low
data volume read application. MongoDB obviously is better for
larger documents with different schemata than for relational
structured time series data.
MariaDB bulk scored best in the write benchmarks with a
low resource requirement, and it performed well in the read
benchmarks, especially because we were able to optimize a
lot, like custom JSON parsing. This demonstrates that ’classic’
RDBMS are able to keep up with more modern architectures
like the one we benchmarked, although they put some strain
on LIO, Ldisk and the developer.
The TSDB InﬂuxDB individual showed reasonably good
write and read performance while requiring the least amount of
database know-how. The naive read and write implementations
scored quite well, but we think that in very large installations,
the compression and server-side buffering mechanisms can
lead to an earlier exhaust of resources than when using a
RDBMS. If the server is more than capable enough and if
the developer wants an easier implementation, then InﬂuxDB
can be recommended.
With our results, individual developers and companies have
a base for deciding which database system, and how much
effort and resources are needed to implement high frequency
monitoring and analytical processing techniques for improving
their overall product.
ACKNOWLEDGMENT
This work was supported by the European Union from
the European Regional Development Fund (ERDF) and the
German state of Bavaria.
TABLE IV. Test Results: Write Benchmarks
Server
Banana Pi
Infrastructure
Difﬁculty
LCP UServer
LmemServer
LIOServer
LCP UClient
LmemClient
Lnet
Ldisk
MariaDB Individual
5%
170.835 kByte
1840 kByte/sec
9,4%
2.096 kByte
715 kBit/s
88 MByte
5
MariaDB Bulk
1%
160.834 kByte
417 kByte/sec
6,5%
2.232 kByte
395 kBit/s
32 MByte
5
MongoDB Individual
1%
257.166 kByte
71 kByte/sec
13,9%
3.561 kByte
710 kBit/s
58 MByte
4
MongoDB Bulk
1%
137.701 kByte
56 kByte/sec
8,9%
3.607 kByte
617 kBit/s
15 MByte
4
InﬂuxDB
5%
147.444 kByte
37 kByte/sec
11,7%
284 kByte
785 kBit/s
5 MByte
1
Weight
3
1
2
3
1
2
1
1
TABLE V. Test Results: Read Benchmarks
Server
Client
Infrastructure
Difﬁculty
LCP UServer
LmemServer
LIOServer
LCP UClient
LmemClient
Lnet
MariaDB Individual
7%
208.896 kByte
46,9 kByte/s
0,4%
4.427 kByte
1025 kBit/s
4
MariaDB Bulk
0%
154.544 kByte
5,2 kByte/s
0,6%
3.979 kByte
3520 kBit/s
5
MongoDB Individual
87%
188.737 kByte
3,5 kByte/s
1,4%
5.487 kByte
6750 kBit/s
3
MongoDB Bulk
11%
121.252 kByte
1,6 kByte/s
15,9%
2.564 kByte
3520 kBit/s
3
InﬂuxDB Individual
8%
40.605 kByte
0,9 kByte/s
1,3%
1.533 kByte
530 kBit/s
3
InﬂuxDB Bulk
12%
37.272 kByte
1,1 kByte/s
7,0%
1.556 kByte
1898 kBit/s
4
InﬂuxDB Bulk-1
7%
26.970 kByte
1,2 kByte/s
3,4%
28.979 kByte
1025 kBit/s
4
Weight
3
1
2
3
1
2
1
47
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

0,0% 
10,0% 
20,0% 
30,0% 
40,0% 
50,0% 
60,0% 
70,0% 
80,0% 
90,0% 
100,0% 
$L_{CPU_{Server}}$
$L_{mem_{Server}}$
$L_{IO_{Server}}$
$L_{CPU_{Client}}$
$L_{mem_{Client}}$
$L_{net}$
$L_{disk}$
Server
Banana Pi
Infrastructure
Write
MariaDB Individual
MariaDB Bulk
MongoDB Individual
MongoDB Bulk
InfluxDB
dto. Since no external code is required and
the data structure is not possible, using the
forward and fast to implement.
ﬂuxDB also offers built-in functions to
cally and a client library is not absolutely
a beneﬁt for software developers using it.
DP has the probability of data loss, which
r use case. For enabling the UDP service
OS was conﬁgured correspondingly to the
d by InﬂuxData.4
V.
TEST CRITERIA
ns in our context face limitations in terms
r and network bandwidth. Consequently we
n the single board computer, the load on
network load.
on both computers is measured in terms
ry usage. We created a script, which runs
cation for one hour. Before it ends the
two Linux-System commands to gather the
rs.
the processor usage. We obtain this value
mmand ps -p <pid>
-o %cpu which
ure for the percentage of time the process
ng over the measurement time.
value for one core is always 100%. On
ard computer the absolute maximum value
800%. On the server the absolute maximum
s
memory
usage
in
kByte.
We
use
emory used by the process <pid> as
e and paged memory as returned by
aux -y | awk ’{if ($2 == <pid>
t outputs the resident set size (RSS) mem-
mory used which is held in RAM.
the amount of disk used by a database. To
meter we ﬁrst empty the respective database
oving its data folder. Also we start the
ure the disk space of the folder before we
we measure the used disk space again and
s result. du -sh <foldername> is used to
mption of the respective data folder. To put
ective: Our benchmark application gathers
MByte of raw data during the one hour of
average bandwidth used. We obtain that
mmand nload. To put that number in
benchmark we transfer 10 000 bytes from
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
impact of the disk results is in a decent relation to the other
component results. On difﬁcult places, network-bandwidth
could be limited, potentially a data logging application could
be connected wirelessly so we weight it with 1 5
Unix function sendto. Since no external code is required and
custom design of the data structure is not possible, using the
database is straight-forward and fast to implement.
Additionally, InﬂuxDB also offers built-in functions to
rocess data statistically and a client library is not absolutely
ecessary, which is a beneﬁt for software developers using it.
The choice of UDP has the probability of data loss, which
s acceptable in our use case. For enabling the UDP service
f InﬂuxDB, the OS was conﬁgured correspondingly to the
nformation provided by InﬂuxData.4
V.
TEST CRITERIA
Most applications in our context face limitations in terms
f computing power and network bandwidth. Consequently we
measure the load on the single board computer, the load on
he server and the network load.
The CPU load on both computers is measured in terms
f CPU and memory usage. We created a script, which runs
he speciﬁed application for one hour. Before it ends the
pplication, it uses two Linux-System commands to gather the
ollowing parameters.
LCP U indicates the processor usage. We obtain this value
with the Linux command ps -p <pid>
-o %cpu which
will return a measure for the percentage of time the process
<pid> spent running over the measurement time.
The maximum value for one core is always 100%. On
ur 8 core single-board computer the absolute maximum value
would be LCP U = 800%. On the server the absolute maximum
alue is 600%.
Lmem
indicates
memory
usage
in
kByte.
We
use
he amount of memory used by the process <pid> as
he sum of active and paged memory as returned by
he command ps aux -y | awk ’{if ($2 == <pid>
print $6}’. It outputs the resident set size (RSS) mem-
ry, the actual memory used which is held in RAM.
Ldisk shows the the amount of disk used by a database. To
determine this parameter we ﬁrst empty the respective database
ompletely by removing its data folder. Also we start the
database and measure the disk space of the folder before we
est. After the test we measure the used disk space again and
se the difference as result. du -sh <foldername> is used to
et the disk consumption of the respective data folder. To put
he results in perspective: Our benchmark application gathers
nd transmits ⇡ 53MByte of raw data during the one hour of
ur test.
LIO shows ...
Lnet shows the average bandwidth used. We obtain that
alue with the command nload. To put that number in
erspective: In our benchmark we transfer 10.000 bytes
sec
from
he microcontroller to the single-board computer.
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
impact of the disk results is in a decent relation to the other
component results. On difﬁcult places, network-bandwidth
could be limited, potentially a data logging application could
be connected wirelessly, so we weight it with 1.5.
Lastly we take the subjective difﬁculty of our implementa
and
the
to
ely
it.
ich
ice
the
ms
we
on
ms
uns
the
the
lue
ich
ess
On
lue
um
use
as
by
d>
m-
To
ase
the
we
and
to
put
ers
of
hat
in
om
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
impact of the disk results is in a decent relation to the other
component results. On difﬁcult places, network-bandwidth
could be limited, potentially a data logging application could
be connected wirelessly so we weight it with 1 5
code is required and
ot possible, using the
mplement.
built-in functions to
ary is not absolutely
e developers using it.
y of data loss, which
ing the UDP service
rrespondingly to the
A
limitations in terms
dth. Consequently we
omputer, the load on
s measured in terms
a script, which runs
Before it ends the
mmands to gather the
We obtain this value
>
-o %cpu which
of time the process
ent time.
s always 100%. On
olute maximum value
he absolute maximum
n
kByte.
We
use
process <pid> as
ory as returned by
if ($2 == <pid>
set size (RSS) mem-
ld in RAM.
sed by a database. To
e respective database
r. Also we start the
the folder before we
disk space again and
ldername> is used to
ve data folder. To put
k application gathers
uring the one hour of
used. We obtain that
put that number in
er 10.000 bytes
sec
from
omputer.
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
impact of the disk results is in a decent relation to the other
component results. On difﬁcult places, network-bandwidth
could be limited, potentially a data logging application could
be connected wirelessly, so we weight it with 1.5.
Lastly we take the subjective difﬁculty of our implementa-
Unix function sendto. Since no external code is required and
a custom design of the data structure is not possible, using the
database is straight-forward and fast to implement.
Additionally, InﬂuxDB also offers built-in functions to
process data statistically and a client library is not absolutely
necessary, which is a beneﬁt for software developers using it.
The choice of UDP has the probability of data loss, which
is acceptable in our use case. For enabling the UDP service
of InﬂuxDB, the OS was conﬁgured correspondingly to the
information provided by InﬂuxData.4
V.
TEST CRITERIA
Most applications in our context face limitations in terms
of computing power and network bandwidth. Consequently we
measure the load on the single board computer, the load on
the server and the network load.
The CPU load on both computers is measured in terms
of CPU and memory usage. We created a script, which runs
the speciﬁed application for one hour. Before it ends the
application, it uses two Linux-System commands to gather the
following parameters.
LCP U indicates the processor usage. We obtain this value
with the Linux command ps -p <pid>
-o %cpu which
will return a measure for the percentage of time the process
<pid> spent running over the measurement time.
The maximum value for one core is always 100%. On
our 8 core single-board computer the absolute maximum value
would be LCP U = 800%. On the server the absolute maximum
value is 600%.
Lmem
indicates
memory
usage
in
kByte.
We
use
the amount of memory used by the process <pid> as
the sum of active and paged memory as returned by
the command ps aux -y | awk ’{if ($2 == <pid>
) print $6}’. It outputs the resident set size (RSS) mem-
ory, the actual memory used which is held in RAM.
Ldisk shows the the amount of disk used by a database. To
determine this parameter we ﬁrst empty the respective database
completely by removing its data folder. Also we start the
database and measure the disk space of the folder before we
test. After the test we measure the used disk space again and
use the difference as result. du -sh <foldername> is used to
get the disk consumption of the respective data folder. To put
the results in perspective: Our benchmark application gathers
and transmits ⇡ 53MByte of raw data during the one hour of
our test.
LIO shows ...
TODO
Plenk:
Beschreiben
Lnet shows the average bandwidth used. We obtain that
value with the command nload. To put that number in
perspective: In our benchmark we transfer 10.000 bytes
sec
from
the microcontroller to the single-board computer.
We run our test in the university network and therefore
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
impact of the disk results is in a decent relation to the other
component results. On difﬁcult places, network-bandwidth
could be limited, potentially a data logging application could
be connected wirelessly, so we weight it with 1.5.
Lastly we take the subjective difﬁculty of our implementa-
tions into account. We grade on a scale from 5, most difﬁcult
required and
le, using the
t.
functions to
ot absolutely
pers using it.
loss, which
UDP service
ingly to the
ons in terms
equently we
the load on
ed in terms
which runs
it ends the
to gather the
in this value
%cpu which
the process
s 100%. On
ximum value
te maximum
e.
We
use
<pid> as
returned by
== <pid>
(RSS) mem-
M.
database. To
ive database
we start the
er before we
ce again and
> is used to
older. To put
ation gathers
one hour of
obtain that
number in
0 bytes
sec
from
nd therefore
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
impact of the disk results is in a decent relation to the other
component results. On difﬁcult places, network-bandwidth
could be limited, potentially a data logging application could
be connected wirelessly, so we weight it with 1.5.
Lastly we take the subjective difﬁculty of our implementa-
tions into account. We grade on a scale from 5, most difﬁcult
Unix function sendto. Since no external code is required and
a custom design of the data structure is not possible, using the
database is straight-forward and fast to implement.
Additionally, InﬂuxDB also offers built-in functions to
process data statistically and a client library is not absolutely
necessary, which is a beneﬁt for software developers using it.
The choice of UDP has the probability of data loss, which
is acceptable in our use case. For enabling the UDP service
of InﬂuxDB, the OS was conﬁgured correspondingly to the
information provided by InﬂuxData.4
V.
TEST CRITERIA
Most applications in our context face limitations in terms
of computing power and network bandwidth. Consequently we
measure the load on the single board computer, the load on
the server and the network load.
The CPU load on both computers is measured in terms
of CPU and memory usage. We created a script, which runs
the speciﬁed application for one hour. Before it ends the
application, it uses two Linux-System commands to gather the
following parameters.
LCP U indicates the processor usage. We obtain this value
with the Linux command ps -p <pid>
-o %cpu which
will return a measure for the percentage of time the process
<pid> spent running over the measurement time.
The maximum value for one core is always 100%. On
our 8 core single-board computer the absolute maximum value
would be LCP U = 800%. On the server the absolute maximum
value is 600%.
Lmem
indicates
memory
usage
in
kByte.
We
use
the amount of memory used by the process <pid> as
the sum of active and paged memory as returned by
the command ps aux -y | awk ’{if ($2 == <pid>
) print $6}’. It outputs the resident set size (RSS) mem-
ory, the actual memory used which is held in RAM.
Ldisk shows the the amount of disk used by a database. To
determine this parameter we ﬁrst empty the respective database
completely by removing its data folder. Also we start the
database and measure the disk space of the folder before we
test. After the test we measure the used disk space again and
use the difference as result. du -sh <foldername> is used to
get the disk consumption of the respective data folder. To put
the results in perspective: Our benchmark application gathers
and transmits ⇡ 53MByte of raw data during the one hour of
our test.
LIO shows ...
TODO
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
VII.
RESULTS
Table IV shows our results. Figure 3 visualizes the data in
relation to the maximum values in respective to each criteria.
The Bulk implementations of MariaDB and MongoDB
are able to surpass all other databases in regard to server
processor usage. InﬂuxDB required the least CPU usage when
only regarding individual implementations. All implementa-
tions could handle the high data rate, however the rate of the
MariaDB individual implementation was ﬂuctuating in tests.
The RAM usage of the InﬂuxDB components were the lowest.
Nonetheless, even the utilization of MariaDB - the database
with the highest memory usage - was absolutely seen so low
that it may not be relevant. The usage and activity of the
disk was signiﬁcantly higher when using MariaDB compared
to the others. The InﬂuxDB and the bulk implementation of
MongoDB got by with the least amount of disk usage.
To directly compare all our candidates we calculate a
combined score by weighing the parameters. In a ﬁrst step
we set the values of each column in Table IV in relation
to the columns maximum, so that we compare the relative
performance. In the next step before we add them up we assign
each parameter a weighting.
Since we ﬁnd that the CPU is the most important parameter,
we give it a weight of 2 on server and as resources on
client are limited it is weighted with 2.5 there. In absolute
terms, the RAM usage on server and client was very little
and therefore we weight it with 0.25. For IO we used a SSD,
when using a HDD, IO usage could pose a larger problem
and therefore it is weighted with 2.5. As the disk usage is
already correlating with IO, we weight it with 0.5 so that the
i
t
f th
di k
lt i i
d
t
l ti
t
th
th
Figure 4. Overview of all Write Benchmark Values (normalized to respective Maximum)
0,0% 
10,0% 
20,0% 
30,0% 
40,0% 
50,0% 
60,0% 
70,0% 
80,0% 
90,0% 
100,0% 
$L_{CPU_{Server}}$
$L_{mem_{Server}}$
$L_{IO_{Server}}$
$L_{CPU_{Client}}$
$L_{mem_{Client}}$
$L_{net}$
Server
Client
Infrastructure
Read
Maria-DB Individual
Maria-DB Bulk
Mongo-DB Individual
Mongo-DB Bulk
Influx-DB Individual
Influx-DB Bulk
Influx-DB Bulk-1
0,0% 
10,0% 
20,0% 
30,0% 
40,0% 
50,0% 
60,0% 
70,0% 
80,0% 
90,0% 
100,0% 
$L_{CPU_{Server}}$
$L_{mem_{Server}}$
$L_{IO_{Server}}$
$L_{CPU_{Client}}$
$L_{mem_{Client}}$
$L_{net}$
Server
Client
Infrastructure
Read
MariaDB Individual
MariaDB Bulk
MongoDB Individual
MongoDB Bulk
InfluxDB Individual
InfluxDB Bulk
InfluxDB Bulk-1
ired and
using the
tions to
bsolutely
using it.
s, which
P service
y to the
in terms
ently we
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
f
60
i
Th
f
d
d
il d i
S
i
V i
external code is required and
ure is not possible, using the
fast to implement.
offers built-in functions to
ient library is not absolutely
software developers using it.
obability of data loss, which
or enabling the UDP service
ured correspondingly to the
ata.4
RITERIA
ext face limitations in terms
bandwidth. Consequently we
board computer, the load on
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
Unix function sendto. Since no external code is required and
a custom design of the data structure is not possible, using the
database is straight-forward and fast to implement.
Additionally, InﬂuxDB also offers built-in functions to
process data statistically and a client library is not absolutely
necessary, which is a beneﬁt for software developers using it.
The choice of UDP has the probability of data loss, which
is acceptable in our use case. For enabling the UDP service
of InﬂuxDB, the OS was conﬁgured correspondingly to the
information provided by InﬂuxData.4
V.
TEST CRITERIA
Most applications in our context face limitations in terms
of computing power and network bandwidth. Consequently we
measure the load on the single board computer, the load on
the server and the network load.
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
al code is required and
not possible, using the
implement.
built-in functions to
brary is not absolutely
re developers using it.
ity of data loss, which
bling the UDP service
orrespondingly to the
A
ce limitations in terms
idth. Consequently we
computer, the load on
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single-board computer
and the server during the test.
function sendto. Since no external code is required and
tom design of the data structure is not possible, using the
ase is straight-forward and fast to implement.
dditionally, InﬂuxDB also offers built-in functions to
ss data statistically and a client library is not absolutely
sary, which is a beneﬁt for software developers using it.
he choice of UDP has the probability of data loss, which
ceptable in our use case. For enabling the UDP service
ﬂuxDB, the OS was conﬁgured correspondingly to the
mation provided by InﬂuxData.4
V.
TEST CRITERIA
ost applications in our context face limitations in terms
mputing power and network bandwidth. Consequently we
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
f
60
i
Th
f
d
d
il d i
S
i
V i
Unix function sendto. Since no external code is required and
a custom design of the data structure is not possible, using the
database is straight-forward and fast to implement.
Additionally, InﬂuxDB also offers built-in functions to
process data statistically and a client library is not absolutely
necessary, which is a beneﬁt for software developers using it.
The choice of UDP has the probability of data loss, which
is acceptable in our use case. For enabling the UDP service
of InﬂuxDB, the OS was conﬁgured correspondingly to the
information provided by InﬂuxData.4
V.
TEST CRITERIA
Most applications in our context face limitations in terms
of computing power and network bandwidth. Consequently we
measure the load on the single board computer, the load on
LCP UServer
LCP UClient
(1)
LmemServer
LmemClient
(2)
Lnet
Ldisk
LIO
(3)
(4)
VI.
TESTING
Before each test, we restart both the Banana Pi and the
server. We then erase the database folder on the server and give
both systems ⇡ 5min to settle. Then we turn on the function
generators, log in to the single-board computer and start the
Database Writer software for the currently active database. The
actual benchmark begins with starting the Receiver Software.
We let the system gather data from the function generators
for 60 minutes. The performance data detailed in Section V is
gathered by two scripts running on the single board computer
Figure 5. Overview of all Read Benchmark Values (normalized to respective Maximum)
48
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

REFERENCES
[1]
D. Arnst, V. Plenk, and A. W¨oltche, “Comparative Evaluation of
Database Performance in an Internet of Things Context,” in Proceedings
of ICSNC 2018 : The Thirteenth International Conference on Systems
and Networks Communications, Nizza, October 2018, pp. 45 – 50.
[2]
D. Wang, J. Liu, and R. Srinivasan, “Data-driven soft sensor approach
for quality prediction in a reﬁning process,” IEEE Transactions on
Industrial Informatics, vol. 6, no. 1, Feb 2010, pp. 11–17, URL:
https://dx.doi.org/10.1109/TII.2009.2025124 [retrieved: 2018-08-14].
[3]
G. K¨oksal, ˙I. Batmaz, and M. C. Testik, “A review of data mining appli-
cations for quality improvement in manufacturing industry,” Expert Sys-
tems with Applications, vol. 38, no. 10, 2011, pp. 13 448 – 13 467, URL:
http://www.sciencedirect.com/science/article/pii/S0957417411005793
[retrieved: 2018-08-14].
[4]
F. Chen, P. Deng, J. Wan, D. Zhang, A. V. Vasilakos, and X. Rong, “Data
mining for the internet of things: Literature review and challenges,”
International Journal of Distributed Sensor Networks, vol. 11, no. 8,
2015, p. 431047, URL: https://doi.org/10.1155/2015/431047 [retrieved:
2018-08-14].
[5]
J. Lee, H. D. Ardakani, S. Yang, and B. Bagheri, “Industrial big
data analytics and cyber-physical systems for future maintenance &
service innovation,” Procedia CIRP, vol. 38, 2015, pp. 3 – 7, URL:
http://www.sciencedirect.com/science/article/pii/S2212827115008744
[retrieved: 2018-08-14].
[6]
C. S. Jensen, D. Lin, and B. C. Ooi, “Query and update efﬁ-
cient b+-tree based indexing of moving objects,” in Proceedings of
the Thirtieth International Conference on Very Large Data Bases
- Volume 30, ser. VLDB ’04.
VLDB Endowment, 2004, pp.
768–779, URL: http://dl.acm.org/citation.cfm?id=1316689.1316756 [re-
trieved: 2018-08-14].
[7]
S.
Acreman,
“Top
10
time
series
databases,”
URL:
https://blog.outlyer.com/top10-open-source-time-series-databases
[retrieved: 2018-08-14].
[8]
A. Bader, O. Kopp, and M. Falkenthal, “Survey and Comparison of
Open Source Time Series Databases,” Datenbanksysteme f¨ur Busi-
ness, Technologie und Web - Workshopband, 2017, pp. 249 – 268,
URL: http://btw2017.informatik.uni-stuttgart.de/slidesandpapers/E4-14-
109/paper web.pdf [retrieved: 2018-08-14].
[9]
D. Namiot, “Time series databases,” in DAMDID/RCDL, 2015,
URL:
https://www.semanticscholar.org/paper/Time-Series-Databases-
Namiot/bf265b6ee45d814b3acb29fb52b57fd8dbf94ab6
[retrieved:
2018-08-14].
[10]
S. Y. Syeda Noor Zehra Naqvi, “Time series databases and in-
ﬂuxdb,” Studienarbeit, Universit´e Libre de Bruxelles, 2017, URL:
http://cs.ulb.ac.be/public/ media/teaching/inﬂuxdb 2017.pdf [retrieved:
2018-08-14].
[11]
A. M. Castillejos, “Management of time series data,” Dissertation,
School
of
Information
Sciences
and
Engineering,
2006,
URL:
http://www.canberra.edu.au/researchrepository/ﬁle/82315cf7-7446-fcf2-
6115-b94fbd7599c6/1/full text.pdf [retrieved: 2018-08-14].
[12]
solidIT consulting & software development gmbh, “DB-Engines Rank-
ing,” URL: https://db-engines.com/en/ranking [retrieved: 2018-08-14].
[13]
“MariaDB homepage,” URL: https://mariadb.org/ [retrieved: 2018-08-
14].
[14]
solidIT
consulting
&
software
development
gmbh,
“DB-
Engines
Ranking
of
Relational
DBMS,”
URL:
https://db-
engines.com/en/ranking/relational+dbms [retrieved: 2018-08-14].
[15]
“MongoDB
homepage,”
URL:
https://www.mongodb.com/what-is-
mongodb [retrieved: 2018-08-14].
[16]
solidIT
consulting
&
software
development
gmbh,
“DB-
Engines
Ranking
of
Document
Stores,”
URL:
https://db-
engines.com/en/ranking/document+store [retrieved: 2018-08-14].
[17]
“InﬂuxDB homepage,” URL: https://www.inﬂuxdata.com/time-series-
platform/inﬂuxdb/ [retrieved: 2018-08-14].
[18]
solidIT
consulting
&
software
development
gmbh,
“DB-
Engines
Ranking
of
Time
Series
DBMS,”
URL:
https://db-
engines.com/en/ranking/time+series+dbms [retrieved: 2018-08-14].
[19]
“UDP
Conﬁguration
of
InﬂuxDB,”
URL:
https://github.com/inﬂuxdata/inﬂuxdb/tree/master/services/udp
[retrieved: 2018-08-14].
49
International Journal on Advances in Internet Technology, vol 12 no 1 & 2, year 2019, http://www.iariajournals.org/internet_technology/
2019, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

