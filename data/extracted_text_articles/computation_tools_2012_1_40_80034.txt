Multiplicative Complexity and Solving Generalized
Brent Equations With SAT Solvers
Nicolas T. Courtois
University College London,
Gower Street, London, UK
Email: n.courtois@ucl.ac.uk
Daniel Hulme
University College London,
Gower Street, London, UK
Email: d.hulme@cs.ucl.ac.uk
Theodosis Mourouzis
University College London,
Gower Street, London, UK
Email: theodosis.mourouzis.09@ucl.ac.uk
Abstract—In this paper we look at the general problem of
Multiplicative Complexity (MC) as an essential tool for opti-
mizing potentially arbitrary algebraic computations over ﬁelds
and rings in the general non-commutative setting. Our goal is to
ﬁnd optimizations in a fully automated way via algebraic formal
coding and conversion to a SAT problem [1].
We focus on the basic problems of minimizing the number
of multiplications in Matrix Multiplication, complex number
multiplication and also quaternion multiplication. Minimizing
the number of multiplications in the Matrix Multiplication
problem alone (and this for problems of ﬁxed size some of
which we were able to optimize [4]) is known to be able to
lead to immediate improvements in countless other algorithms
on formal languages, graphs, arbitrary ﬁnite groups, various
real/complex/algebraic rings and ﬁelds of practical importance.
Thus we may hope to translate our efforts to improve many
high-proﬁle applications in computer graphics, signal processing,
cryptography, computational physics and chemistry, weather
prediction, ﬁnancial computing, Google page ranking, etc.
The classical tool to solve the Matrix Multiplication problem
are the Brent Equations [3]. We have developed a methodology
for solving these equations over small ﬁelds such as GF(2) with
a conversion to a SAT problem and progressive lifting to larger
ﬁelds and rings. We generalize the Brent Equations [3] and extend
our method to similar algebraic optimizations and to tri-linear
problems.
We have been able to obtain new results to decrease the MC of
several well known operations in algebra, which to the best of our
knowledge are new. For example we have obtained a new general
3×3 matrix multiplication method with 23 multiplications [4]. We
also present new formulas for complex number multiplications
and quaternion multiplications. Additionally, using our method-
ology we are able to produce highly optimized implementations
of small circuits. We obtained exact lower bounds with respect
to MC of two very well known block ciphers, such as PRESENT
and GOST, known for their exceptionally low implementation
cost. Our method is efﬁcient for any sufﬁciently small circuit [5].
Index Terms—Linear Algebra, Fast Matrix Multiplication,
Complex Numbers, quaternions, Strassen’s algorithm, Multi-
plicative Complexity
I. INTRODUCTION
The optimization of certain arbitrary algebraic computations
over ﬁelds and rings in the general non-commutative setting is
considered as one of the most important topics in theoretical
computer science and mathematics. In this paper we study
how the Multiplicative Complexity (MC) of certain arbitrary
algebraic computations such as the Matrix Multiplication
(MM), multiplication of complex numbers, multiplication of
quaternions and of a general Boolean circuit can be reduced
over small ﬁelds such as GF(2), the ﬁeld of two elements,
and then be progressively lifted to larger rings.
MC is the minimum number of AND gates that are needed
if we allow an unlimited number of NOT and XOR gates.
Informally, we are interested in reducing the number of
multiplications involved in an arbitrary algebraic computation
allowing unlimited number of additions.
Our method consists of three basic steps. In the ﬁrst step we
formally encode the problem by writing a system of equations
which describe the problem and then we consider the problem
over the ﬁnite ﬁeld of two elements GF(2). In case of the
MM problem and the complex or the quaternion multiplication
problem we use the Brent Equations [3] in the encoding
step while for circuit minimization we encode the problem
formally as a straight-line representation problem, described
by a quantiﬁed set of multivariate relations [5]. Then we
proceed by converting the reduced modulo 2 problem to a
SAT problem using the Courtois-Bard-Jefferson method [2]
and then we progressively lift the solution to larger ﬁelds and
rings using different heuristic techniques and other constraint
satisfaction algorithms.
A. Motivation for Low MC
Matrix Multiplication:
One of the most famous problems in computer algebra is the
problem of MM of square and non-square matrices, where the
aim is to reduce the number of 2-input multiplications needed
in order to compute the product of two matrices. A speed-up
in MM will automatically result in a speed improvement of
many other algorithms and techniques such as:
• Gauss Elimination algorithm for solving a system of
linear polynomial equations
• Algorithms for solving of non-linear polynomial equa-
tions
• Recognizing if a word of length n belongs to a context-
free language
• Transitive closure of a graph or a relation on a ﬁnite set
• Cryptanalysis
Circuit Complexity:
22
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-222-6
COMPUTATION TOOLS 2012 : The Third International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

We refer to some reasons why circuits of low MC are very
important especially for industrial reasons and for cryptogra-
phy. For more analytic explanations, see [5].
• Lower the hardware implementation cost of a cipher in
silicon
• Develop certain so called Bitslice parallel-SIMD software
implementations of block ciphers such as in [16]
• In symbolic computing and numerical algebra, this kind
of optimization can be applied recursively to produce
asymptotically fast algorithms to solve very famous and
important practical problems such as Gaussian reduction
and MM
• Prevent Side Channel Attacks (SCA) on smart cards such
as Differential Power Analysis (DPA) [15].
II. METHODOLOGY
We have fully automated the process as follows:
1) Form the Brent Equations (or write a quantiﬁed set of
multivariate relations that describes the problem)
2) Consider only solutions in 0,1=integers modulo 2
3) Convert to SAT with Courtois-Bard-Jefferson method [2]
4) Lift the solution from GF(2) to the general bigger ﬁelds
by another constraint satisfaction algorithm
A. Brent Equations
We use Brent Equations as a sort of “formal algebraic”
method for encoding problems that optimize certain arbitrary
algebraic computations. Our main idea is to encode such
problems into a “language” which can be converted to a SAT
problem and then we attempt to solve this hard problem using
our portfolio of 500 SAT solvers.
Suppose we want to multiply a M×N matrix A by a N×P
matrix B using T 2-input multiplications.
We solve the above problem by solving the following system
of (MNP)2 equations in T(MN + NP + MP) unknowns,
see [3]:
{∀i∀j∀k∀L∀m∀n, ∑T
p=1 αijpβkLpγmnp = δniδjkδLm}(1)
A solution to this set of equations implies that the coefﬁcient
entries cij of the product matrix C = AB can be written as
cnm = ΣT
p=1γmnpqp (2) where the products q1, q2, ..., qT are
given by qp = (Σαijpaij)(ΣβKLpbKL) (3).
Thus, our aim is to form Brent-like equations for other
problems such as complex multiplication and quaternion mul-
tiplication and then convert it to a SAT problem where we can
apply our portfolio of SAT solvers to get the solution.
B. SAT Solvers
Satisﬁability (SAT) is the problem of determining if the
variables of a given Boolean formula can be assigned in a
way as to make the formula evaluate to TRUE [13]. SAT
was the ﬁrst known example of an NP-complete problem. A
wide range of other decision and optimization problems can
be transformed into instances of SAT and a class of algorithms
called SAT solvers can efﬁciently solve a large enough subset
of SAT instances such as MiniSAT solver [23]. Our aim is to
transform problems like MM into SAT problems.
C. Solving Brent Equations Modulo 2 and Lifting
In the ﬁrst step we form the Brent Equations for our problem
and we consider them over the ﬁeld GF(2). We are interested
only in simple solutions that work over small ﬁnite rings and
ﬁelds. Then using the Courtois-Bard-Jefferson converter we
convert this system of equations over GF(2) to a SAT problem
and attempt to solve it. After obtaining the solution modulo
2 we begin again and try to lift the solution to a modulo 4
solution using very similar formal encoding.
D. Solving and Conversion
The system of equations is encoded algebraically and then
converted to a SAT problem. We have implemented a method
to convert this very hard problem to a SAT problem, and we
have attempted to solve it, with our portfolio of some 500 SAT
solvers and their variants.
III. MATRIX MULTIPLICATION
Many attempts to solve the general MM problem in the
literature work by solving ﬁxed-size problems and applying
the solution recursively. This leads to pure combinatorial
optimization problems with ﬁxed size. For square matrices
the naive algorithm is cubic and the best known theoretical
exponent is 2.376, due to Coppersmith and Winograd [14].
This exponent is quite low and it is conjectured that one should
be able to do MM in so called “soft quadratic time”, with
possibly some poly-logarithmic overheads, which could even
be sub-exponential in the logarithm. This in fact would be
nearly linear in the size of the input.
In 2005 a team of scientists from Microsoft Research and
two US universities established a new method for ﬁnding such
algorithms based on group theory, and their best method so
far gives an exponents of 2.41 [17], close to Coppersmith-
Winograd result and subject to further improvement.
All attempts to solve the MM problem in the literature
rely on solving certain ﬁxed size problems, which can be the
recursively applied to produce asymptotically fast algorithms
that can be used for more general cases. In 1969 Victor
Strassen established a ﬁrst asymptotic improvement to the
complexity of MM algorithm, by proving that two matrices
2 × 2 can be multiplied by using seven instead of eight
multiplications [22]. Later in 1975 Laderman published a
solution for multiplying 3×3 matrices with 23 multiplications
[9]. Since then this topic generated very considerable interest
and yet to this day it is not clear if Laderman’s solution in
case of 3 × 3 multiplication can be further improved.
As in many previous attempts to solve the problem
we proceed by solving the so called Brent equations [3].
This approach has been tried many times before, see
[[3],[8],[10],[12],[13],[11]].
We write the coefﬁcients of each product as three 3 × 3-
matrices for each multiplication A(i), B(i) and C(i), 1 ≤ i ≤
r, with r = 23 where A will be the left hand side of each
product, B the right hand size, and C says to which coefﬁcient
of the result this product contributes.
The Brent equations are as follows:
23
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-222-6
COMPUTATION TOOLS 2012 : The Third International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

∀i∀j∀k∀l∀m∀n ∑r
i=1 A(i)
ij B(i)
kl C(i)
mn = δniδjkδlm (4)
For 3×3 matrices we get exactly 729 cubic equations. Then
using our methodology we obtained the following solution for
the case of 3 × 3 matrices. Our solution in non-isomorphic to
any of the existing solutions:
P01 := (a23) ∗ (−b12 + b13 − b32 + b33);
P02 := (−a11 + a13 + a31 + a32) ∗ (b21 + b22);
P03 := (a13 + a23 − a33) ∗ (b31 + b32 − b33);
P04 := (−a11 + a13) ∗ (−b21 − b22 + b31);
P05 := (a11 − a13 + a33) ∗ (b31);
P06 := (−a21 + a23 + a31) ∗ (b12 − b13);
P07 := (−a31 − a32) ∗ (b22);
P08 := (a31) ∗ (b11 − b21);
P09 := (−a21 − a22 + a23) ∗ (b33);
P10 := (a11 + a21 − a31) ∗ (b11 + b12 + b33);
P11 := (−a12 − a22 + a32) ∗ (−b22 + b23);
P12 := (a33) ∗ (b32);
P13 := (a22) ∗ (b13 − b23);
P14 := (a21 + a22) ∗ (b13 + b33);
P15 := (a11) ∗ (−b11 + b21 − b31);
P16 := (a31) ∗ (b12 − b22);
P17 := (a12) ∗ (−b22 + b23 − b33);
P18 := (−a11 + a12 + a13 + a22 + a31) ∗ (b21 + b22 + b33);
P19 := (−a11 + a22 + a31) ∗ (b13 + b21 + b33);
P20 := (−a12 + a21 + a22 − a23 − a33) ∗ (−b33);
P21 := (−a22 − a31) ∗ (b13 − b22);
P22 := (−a11 − a12 + a31 + a32) ∗ (b21);
P23 := (a11 + a23) ∗ (b12 − b13 − b31);
c11 = P02 + P04 + P07 − P15 − P22;
c12 = P01 − P02 + P03 + P05 − P07 + P09 + P12
+P18 − P19 − P20 − P21 + P22 + P23;
c13 = −P02 − P07 + P17 + P18 − P19 − P21 + P22;
c21 = P06 + P08 + P10 − P14 + P15 + P19 − P23;
c22 = −P01 − P06 + P09 + P14 + P16 + P21;
c23 = P09 − P13 + P14;
c31 = P02 + P04 + P05 + P07 + P08;
c32 = −P07 + P12 + P16;
c33 = −P07 − P09 + P11 − P13 + P17 + P20 − P21;
Lemma 1: : Our new solution is neither equivalent to the
Ladermans solution [9] nor equivalent to any of the solutions
given in [1].
Proof:
Following
[1],
the
Ladermans
solution
has
exactly
6
matrices
of
rank
3
(which
occur
in
products
P01, P03, P06, P10, P11, P14).
At
the
same
time
in
all new solutions presented in [1], at most 1 matrix will have
rank 3. In our solution we have exactly 2 matrices of rank
3 (which occur in products P18 and P20, there are 2 and
not more such matrices, both being on the left hand size
namely A(18), in A(20)). This proves that all these solutions
are distinct.
Remark: This result demonstrates that the space of so-
lutions to Ladermans problem is larger than expected, and
therefore it becomes now more plausible that a solution with
22 multiplications exists. If it exists, we might be able to ﬁnd
it soon just by running our algorithms longer, or due to further
improvements in the SAT algorithms.
IV. COMPLEX NUMBER MULTIPLICATION
In order to compute the product (a + bi) ∗ (c + di) = (ac −
bd) + (ad + bc)i (5) we need 4 multiplications using the naive
algorithm. Gauss was the ﬁrst to prove that the multiplication
of two complex numbers (a+bi)∗(c+di) can be done using 3
multiplications instead of 4. We obtained the same result using
our methodology. We can translate this complex multiplication
problem to a MM problem using the isomorphism between
the set of complex numbers {a + bi : a, b ∈ R} and the 2
dimensional sub-algebra of {
(a
b
c
d
)
: a, b, c, d ∈ R}, given
by:
{
(a
−b
b
a
)
: a, b ∈ R}.
In the ﬁrst step we form the 3-dimensional Brent Equations
for multiplying two 2x2 matrices A and B and then using SAT
solvers and lifting techniques we obtain the seven following
Strassen-like products, which can be used to compute the
entries {c11, c12, c21, c22} of the matrix C = AB.
P1 = (a12 + a22) ∗ (b12 + b22);
P2 = (a11) ∗ (b11);
P3 = (a21) ∗ (b11 + b12 + b21 + b22);
P4 = (a12) ∗ (−b21);
P5 = (−a11 + a12 − a21 + a22) ∗ (b12);
P6 = (−a21 + a22) ∗ (b21 + b22);
P7 = (−a12 + a21 − a22) ∗ (b12 + b21 + b22);
c11 = P2 − P4;
c12 = P4 − P5 − P6 − P7;
c21 = P3 + P4 − P1 − P7;
c22 = P1 + P6 + P7 − P4;
Now
if
we
consider
these
products
over
the
2-
dimensional sub-algebra of matrices deﬁned before we get
that Span{P1, .., P7}
=
Span{P1, .., P4} since we have
P5 = 2P4, P7 = P3 − P2 (6) and P6 = 2P2 − P3 − P1 (7).
This suggests that four products are enough to compute the
product of two complex numbers as the naive multiplication.
However, if we also consider the set of entries {c11, c21} over
the new set of products we have that c11 = P2 − P4 (8) and
c21 = P2 + P4 − P1 (9). As we see, our method gives three
multiplications in total as proposed by Gauss.
A. Multiplication of three complex numbers
We provide an exceptionally good solution which exists
over GF(2) in the non-homogenous case for the problem of
multiplying three complex numbers. Multiplication of three
complex numbers is a trilinear problem as we aim to minimize
the number of multiplications needed to represent the map
f : (V, V, V ) → V .
Using our method we show that multiplication of three
complex numbers (a+bi)∗(c+di)∗(e+fi) can be achieved
using ﬁve multiplications at most.
24
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-222-6
COMPUTATION TOOLS 2012 : The Third International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

Lemma 2: : MC((a + bi) ∗ (c + di) ∗ (e + fi)) ≤ 5 over
GF(2).
Proof:
In GF(2) we can do 5 multiplications total!
P1 := (a + b + e + f) ∗ (c + d + e + f);
P2 := (a + e) ∗ (d + e);
P3 := (c + f) ∗ (b + f);
Im := P4 := (P1 + P2 + P3 + a + d + e) ∗ (P1 + e + f);
Re := P5 := (P1+e+f)∗(P1+P4+a+b+c+d+1);
V. QUATERNION ALGEBRA
Quaternions are a number system that extends the complex
multiplication that were introduced by the Irish Mathematician
Sir William Rowan Hamilton, who deﬁned a quaternion as the
quotient of two directed lines in a three-dimensional space or
equivalently as the quotient of two vectors [7]. It can also be
seen as the sum of a scalar and a vector. They are widely
used in both theoretical and applied mathematics, especially
for calculations involving three-dimensional rotations such as
three-dimensional computer graphics and computer vision and
in real-time symmetric cryptography [6].
As a set, the quaternions are equal to R4 and every element
can be represented as:
a1+ bi + cj + dk, where i, j, k satisfy the following relations;
i2 = j2 = k2 = ijk = −1, ij = k, ji = −k, jk = i, kj = −i
and ki = j, ik = −j (10).
The Hamilton product of two quaternions:
a1 + b1i + c1j + d1k, a2 + b2i + c2j + d2k is given by
(a1a2 −b1b2 −c1c2 −d1d2)+(a1b2 +b1a2 +c1d2 −d1c2)i
+(a1c2+b1d2+c1a2+d1b2)j+(a1d2+b1c2−c1b2+d1a2)k
(11).
Our aim is to compute the minimum number of 2-input
multiplications needed to compute the product of two quater-
nions. Using the naive multiplication method we need 16
multiplications but this number of multiplication can be re-
duced using the Gauss method to 12. Using our software
we obtain the 12 products that are needed to compute the
product of two quaternions over the general non-commutative
setting. Additionally, we further investigate the number of 2-
input multiplication needed over GF(2) and we surprisingly
get eight. Below we provide the encoding of quaternion
multiplication problem into Brent Equations and the next
Lemmas provide the result obtained by our software.
Encoding q1 ∗ q2 into Brent Equations:
Suppose
{a1, a2, a3, a4},
{b1, b2, b3, b4}
are
non-
commutative
variables
and
σijk
is
a
given
three-
dimensional array of numbers from the set {−1, 0, 1} ,
and we want to compute the 4 sums of 2-input products:
a1b1 − a2b2 − a3b3 − a4b4, a1b2 + a2b1 + a3b4 − a4b3, a1b3 +
a2b4 + a3b1 + a4b2, a1b4 + a2b3 − a3b2 + a4b1.
Then our aim is to ﬁnd the least possible T and scalars
αit, βjt, γkt such that from the T products of the form
pt = (∑
i αitai).(∑
j βjtbj) (12) for 1 ≤ t ≤ T, we can
form the qk as linear combinations of the pt as
qk = ∑T
t=1 γktpt (13) for 1 ≤ k ≤ K.
Combining these two results we formulate the problem of
ﬁnding the minimum number of 2-input multiplications for
multiplying two quaternions a1 + a2i + a3j + a4k, b1 + b2i +
b3j + b4k as follows:
Quaternion
multiplication
problem:
Find
constants
αit, βjt, γkt and least T (where T
≤ 12) such that the
following system of 64 equations in 12 ∗ T unknowns hold:
∑T
t=1 αitβjtγkt = σijk (14),
for 1 ≤ i ≤ 4, 1 ≤ j ≤ 4, 1 ≤ k ≤ 4
,where σijk: σ111 = 1, σ122 = 1, σ133 = 1, σ144 = 1,
σ212 = 1, σ221 = −1, σ234 = 1, σ243 = 1, σ313 = 1, σ324 =
−1, σ331 = −1, σ342 = 1, σ414 = 1, σ423 = 1, σ432 = −1,
σ441 = −1 and zero elsewhere.
Lemma 3: MC(q1 ∗ q2 : qi ∈ H) ≤ 12
Proof: Using the complex representation of q1 and q2 we
need to compute four entries of the form:
1) (q1 ∗ q2)11 = (a + bi) ∗ (e + fi) + (c + di) ∗ (−g + hi)
2) (q1 ∗ q2)12 = (a + bi) ∗ (g + hi) + (c + di) ∗ (e − fi)
3) (q1 ∗ q2)21 = (−c + di) ∗ (e + fi) + (a − bi) ∗ (−g + hi)
4) (q1 ∗ q2)22 = (−c + di) ∗ (g + hi) + (a − bi) ∗ (e − fi)
Using Gauss formulaes we can obtain the ﬁrst two entries
{(q1 ∗ q2)11, (q1 ∗ q2)12} using 12 multiplications. Using this
methodology we have obtained the following terms ae −
bf, be+af, ce+fd, ed−fc, ag−bh, bg+ah, −cg−hd, ch−dg.
However the other entries {(q1 ∗ q2)21, (q1 ∗ q2)22} can be
computed using these terms multiplied by −1. Using our
software we obtained the following formulas for the quaternion
multiplication using 12 multiplications which can be also
directly veriﬁed using MAPLE computer algebra software:
P01 := (a4) ∗ (b2);
P02 := (a1) ∗ (b1 + b2 + b4);
P03 := (a1) ∗ (b3);
P04 := (−a1 + a2) ∗ (b1);
P05 := (−a2) ∗ (b1 − b2);
P06 := (a2) ∗ (b3);
P07 := (a2) ∗ (b4);
P08 := (a3) ∗ (b1);
P09 := (a1 + a3 − a4) ∗ (b1 + b2);
P10 := (a3 + a4) ∗ (−b3);
P11 := (a1 − a3 + a4) ∗ (b4);
P12 := (−a4) ∗ (−b3 + b4);
expand(−P04 − P05 + P10 + P12 − a1 ∗ b1 + a2 ∗ b2 +
a3 ∗ b3 + a4 ∗ b4);
expand(P02 + P04 − P11 − P12 − a1 ∗ b2 − a2 ∗ b1 − a3 ∗
b4 + a4 ∗ b3);
expand(P01 + P03 + P07 + P08 − a1 ∗ b3 − a2 ∗ b4 − a3 ∗
b1 − a4 ∗ b2);
expand(−P01 + P02 + P06 + P08 − P09 − a1 ∗ b4 − a2 ∗
b3 + a3 ∗ b2 − a4 ∗ b1);
Additionally, we obtain a result over the ﬁeld GF(2) and
our results are summarized in the next lemma. Obtaining
25
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-222-6
COMPUTATION TOOLS 2012 : The Third International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

results over the ﬁeld of two elements is very useful as binary
encoding is employed in many areas such as cipher design in
cryptography and circuit design for either software or hardware
implementations.
Lemma 4: MC(q1 ∗ q2 : qi ∈ H) ≤ 8 over GF(2).
Proof: Using our automated software we obtained the
following solution which can be directly veriﬁed with MAPLE
computer algebra software:
P01 := (a2 + a3) ∗ (b1 + b2 + b4);
P02 := (a1 + a2 + a3) ∗ (b1 + b2 + b3 + b4);
P03 := (a1 + a2) ∗ (b2 + b3 + b4);
P04 := (a1 + a3) ∗ (b1 + b2 + b3);
P05 := (a3 + a4) ∗ (b1);
P06 := (a1 + a2 + a3 + a4) ∗ (b2);
P07 := (a2 + a4) ∗ (b4);
P08 := (a1 + a4) ∗ (b3);
expand(P01 + P02 + P03 + P07 − a1 ∗ b1 + a2 ∗ b2 + a3 ∗
b3 + a4 ∗ b4)mod2;
expand(P02 + P03 + P04 + P08 − a1 ∗ b2 − a2 ∗ b1 − a3 ∗
b4 + a4 ∗ b3)mod2;
expand(P01 + P02 + P03 + P04 + P06 − a1 ∗ b3 − a2 ∗
b4 − a3 ∗ b1 − a4 ∗ b2)mod2;
expand(P01 + P02 + P04 + P05 − a1 ∗ b4 − a2 ∗ b3 + a3 ∗
b2 − a4 ∗ b1)mod2;
VI. EXACT CIRCUIT COMPLEXITY OPTIMIZATION
In case of circuit complexity we employed the heuristic
proposed by Boyar and Peralta [18] based on the notion of
MC and consists of the following steps:
1. (Step 1) First compute the MC.
2. (Step 2) Then optimize the number of XORs separately,
see [[19],[21] ].
3. Optional Step 3: At the end do additional optimizations
to decrease the circuit depth, and possibly additional software
optimizations, see [[18],[20] ].
We encode the problem formally as a straight-line represen-
tation problem, described by a quantiﬁed set of multivariate
relations and we convert it to SAT with the Courtois-Bard-
Jefferson tool [2]. Our method on how we compute the MC
of the circuit is found in [5].
As a proof of concept we consider the following S-box with
3 inputs and 3 outputs, which have been generated at random
for the CTC2 cipher [5] and is deﬁned as 7, 6, 0, 4, 2, 5, 1 .
We have tried to optimize this S-box with the well known
software Logic Friday (based on Espresso min-term optimiza-
tion developed at Berkeley) and obtained 13 gates. With our
software and in a few seconds we obtained several interesting
results, each coming with a proof that it is an optimal result
(cannot be improved anymore). We get:
Lemma 5: The Multiplicative Complexity (MC) is exactly
3 (we allow 3 AND gates and an unlimited number of XOR
gates).
The Bitslice Gate Complexity (BGC) is exactly 8 (allowed
are XOR,OR,AND,NOT).
The
Gate
Complexity
(GC)
is
exactly
6
(allowing
NAND,NOR,NXOR).
The NAND Complexity (NC) is exactly 12 (only NAND
gates and constants).
Fig. 1.
Our provably optimal implementation of CTC2 S-box with 6 gates.
Proof: Unlike the great majority of circuit optimizations,
needed each time a given cipher is implemented in hardware,
our results are exact. They are obtained by solving the problem
at a given gate count k, the SAT solver outputs SAT and a
solution, and if for k-1 gates the SAT solver is good enough
and fast enough, it will output UNSAT and we obtain a proven
lower bound, a rare thing in complexity, see [5].
VII. CONCLUSION
In this paper we study the notion of Multiplicative Com-
plexity (MC) which minimizes the number of elementary non-
linear operations (AND gates) at the cost of linear operations.
We used MC as an essential tool for optimizing potentially
arbitrary algebraic computations over ﬁelds and rings in the
general non-commutative setting.
We employed an automated method for obtaining new
formulas for Matrix Multiplication (MM), complex number
and quaternion multiplication based on SAT solvers. We
extensively used the notion of Brent Equations [3] as a formal
encoding of these problems and then we consider solutions of
the corresponding system of equations over the ﬁeld of two
elements. After we algebraically encode the problem we con-
vert it into a SAT problem using the Courtois-Bard-Jefferson
[2] and then using our portfolio of 500 SAT solvers we try to
solve the problem over GF(2). Starting from scratch we try
to lift the solutions modulo 2 to solutions modulo 4 and also
to bigger ﬁelds. We lift the solutions using another constraint
satisfaction algorithm and some heuristics discovered during
our simulations that reduces the complexity of our lifting
technique even more.
We have been able to obtain new results in decreasing the
MC of several well known operations in algebra, which to the
best of our knowledge are new. For example we have obtained
a new general 3 × 3 MM method with 23 multiplications [4].
We also derived new formulaes regarding the multiplication
of three complex numbers using 5 multiplications over GF(2)
and for multiplying two quaternions using 8 multiplications
over GF(2). We also derived efﬁcient implementations regard-
ing the MC of some ciphers such as PRESENT, GOST and
CTC2 [5].
So far our method works efﬁciently for obtaining compact
representations of algebraic computations or circuits over the
26
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-222-6
COMPUTATION TOOLS 2012 : The Third International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

ﬁeld of two elements. In some cases we are able to lift our
solutions from GF(2) to the general non-commutative setting.
However, our lifting technique sometimes is not efﬁcient and
is not able to lift the solutions. As future work we will
improve our lifting techniques so that we will be able to obtain
similar compact representations which hold over arbitrary non-
commutative rings.
ACKNOWLEDGMENT
We would like to thank the anonymous referees of this paper
who helped us a lot to improve it.
REFERENCES
[1] R.W. Johnson and A.M. McLoughlin, Noncommutative Bilinear Algo-
rithms for 3 x 3 Matrix Multiplication
In SIAM J. Comput., vol. 15 (2),
pp.595-603, 1986.
[2] G.V. Bard, N.T. Courtois and C. Jefferson, Efﬁcient Methods for Conver-
sion and Solution of Sparse Systems of Low-Degree Multivariate Poly-
nomials over GF(2) via SAT-Solvers
Presented at ECRYPT workshop
Tools for Cryptanalysis, 2007.
[3] R. Brent, Algorithms for matrix multiplication
Tech. Report Report TR-
CS-70-157,Department of Computer Science, Stanford, 52 pages, 1970.
[4] N.T. Courtois, G.V. Bard2, and D. Hulme, A New General-Purpose
Method to Multiply 3x3 Matrices Using Only 23 Multiplications
At
http://arxiv.org/abs/1108.2830, 2011.
[5] N.T. Courtois, D. Hulme, and T. Mourouzis, Solving Circuit Optimisation
Problems in Cryptography and Cryptanalysis
Appears in electronic
proceedings of 2nd IMA Conference Mathematics in Defence, UK,
Swindon, 2011.
[6] R. Anand, G. Bajpai and V. Bhaskar, Real-Time Symmetric Cryptography
using Quaternion Julia Set
IJCSNS International Journal of Computer
Science and Network Security, VOL.9 No.3, 2009
[7] W.R. Hamilton, On quaternions, or on a new system of imaginaries in
algebra
Philosophical Magazine. Vol. 25, n 3. p. 489495, 1844
[8] G. Bard, New Practical Approximate Matrix Multiplication Algorithms
found via Solving a System of Cubic Equations
A draft paper submitted
to a journal, can be found at: http://www-users.math.umd.edu/ bardg/
[9] J.D. Laderman,
A Non-Commutative Algorithm for Multiplying 3x3
Matrices Using 23 Multiplications
ull. Amer. Math. Soc. Volume 82,
Number 1, 1976
[10] W. Smith, Fast Matrix Algorithms And Multiplication Formulae
Avail-
able at:https://math.cst.temple.edu/ wds/matgrant.ps.
[11] N. Burr, An investigation into fast matrix multiplication
done under
supervision of Nicolas T. Courtois, and submitted as a part of BSc Degree
in Computer Science at Univesity College London, 2010
[12] G. Bard, New Practical Approximate Matrix Multiplication Algorithms
found via Solving a System of Cubic Equations
A draft paper submitted
to a journal, can be found at: http://www-users.math.umd.edu/ bardg/
[13] G. Bard, Algorithms for Solving Linear and Polynomial Systems of Equa-
tions over Finite Fields with Applications to Cryptanalysis
Submitted
in Partial Fulﬁllment for the degree of Doctor of Philosophy of Applied
Mathematics and Scientiﬁc Computation, 2007
[14] D. Coppersmith and S.Winograd On the asymptotic complexity of matrix
multiplication
SIAM Journal Comp., 11, pp 472-492 , 1980
[15] E. Prouff, C. Giraud, and S. Aumonier Provably Secure S-Box Imple-
mentation Based on Fourier Transform
In CHES 2006, Springer LNCS
4249, pp: 216-230, 2006
[16] M. Albrecht, N.T. Courtois, D. Hulme.
and G. Song Bit-Slice Imple-
mentation of PRESENT in pure standard C
, 2011
[17] H. Cohn, R. Kleinberg, B. Szegedyz and C. Umans Grouptheoretic
Algorithms for Matrix Multiplication
In FOCS05, 46th Annual IEEE
Symposium on Foundations of Computer Science, pp. 379, 2005
[18] J. Boyar and R. Peralta A New Combinational Logic Minimization
Technique with Applications to Cryptology In SEA 2010: 178-189, 2009
[19] J. Boyar, P. Matthews and R. Penalta, On the Shortest Linear Straight-
Line Program for Computing Linear Forms
In MFCS, 2008
[20] J. Boyar and R.Peralta
A depth-16 circuit for the AES S-box
http://eprint.iacr.org/2011/332
[21] C. Fuhs and P. Schneider-Kamp Synthesizing Shortest Linear Straight-
Line Programs over GF(2) Using SAT
In SAT 2010, Theory and
Applications of Satisﬁability Testing, Springer LNCS 6175, pp. 71-84,
2010
Volker Strassen, ,
[22] V. Strassen Gaussian elimination is not optimal
Numerische Mathe-
matik 13 pp. 354-356, 1969
[23] N. Sorensson and N. Een Minisat v1. 13-a sat solver with conﬂict-clause
minimization
SAT journal pp. 53, 2005
27
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-222-6
COMPUTATION TOOLS 2012 : The Third International Conference on Computational Logics, Algebras, Programming, Tools, and Benchmarking

