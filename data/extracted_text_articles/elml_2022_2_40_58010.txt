Developing Instructor Training for Diverse & Scaled Contexts: A Learning 
Engineering Challenge 
 
Rachel Van Campenhout 
Research and Development 
VitalSource  
Pittsburgh, PA, USA  
e-mail: rachel.vancampenhout@vitalsource.com 
Aaron Kessler 
Residential Education, MIT Open Learning 
Massachusetts Institution of Technology 
Cambridge, MA, USA 
e-mail: kesslera@mit.edu 
 
 
Abstract— Learning engineering provides both a practice and 
process for solving educational challenges. While the 
circumstances of each challenge require a unique application 
of learning engineering, the learning engineering process was 
designed in such a way to provide guidance across a broad 
range of contexts. In this paper, the learning engineering 
process is articulated from the perspective of the developers of 
online courseware used in higher education. Within this use-
case, we exemplify how an initial learning engineering process 
for the creation of the courseware provided a starting point for 
iteration, and in this instance, the beginning of an entirely new 
process on instructor enactment of that courseware. Whereas 
the initial challenge was to develop the courseware 
environment, this emergent challenge now focuses on 
understanding and addressing contextual factors that affect 
the successful instructor application of the courseware learning 
environment at scale. 
Keywords-learning 
engineering; 
learning 
engineering 
process, instructor training; teaching and learning; learning 
technology; courseware. 
I. 
 INTRODUCTION  
Learning engineering is defined by the IEEE IC Industry 
Consortium of Learning Engineering (ICICLE) [4] as “a 
process and practice that applies the learning sciences using 
human-centered engineering design methodologies and data-
informed decision making to support learners and their 
development.” Learning engineering is an interdisciplinary 
practice that incorporates the learning sciences, data science, 
curriculum research, game design, and more, providing an 
infrastructure for design research, analytics, and iterative 
improvement [2]. A learning engineering process model was 
first developed through initial work in the ICICLE design 
special interest group [6] with later iterations discussed 
herein [7]. The learning engineering process model is 
cyclical in form to reflect the concurrence of work required 
and the constant iterations that occur in trying to solve any 
educational challenge. This learning engineering process 
itself is broadly described as the applications for its use are 
equally varied. There are many types of educational 
challenges to be solved and as many groups working to solve 
them. The learning engineering process provides an 
organizational workflow that any person or team can apply 
to their challenge. As shown in Fig. 1, the challenge to 
improve learning or learning environments is at the center of 
the model. Investigation, creation, and implementation are all 
connected in the process of designing and enacting the 
solution to this challenge. Yet each of these phases of the 
cycle can also inform the challenge and solution in their own 
iterative cycles. Lastly, the context, learners, and team all 
contribute to variations in how challenge solutions can be 
scaled or not depending on the almost limitless varied 
settings such solutions might be deployed.  
 
Figure 1.  The learning engineering process (CC by Aaron Kessler). 
This process can be broadly illustrated through the 
example of courseware development at Acrobatiq (Fig. 2). 
The challenge at the center of the learning engineering 
process was to create courseware that applied established 
learning science research to provide an effective digital 
learning environment for students. The context for this 
challenge was shaped by Acrobatiq’s origins from Carnegie 
Mellon University’s Open Learning Initiative and the 
research in online learning established there (e.g., [8][9]. The 
goal was to apply that research to a courseware environment 
that could be used by students across higher education 
institutions at large. The team consisted of learning  
29
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-985-0
eLmL 2022 : The Fourteenth International Conference on Mobile, Hybrid, and On-line Learning

 
Figure 2.  The learning engineering process with the central challenge of 
creating online courseware. 
engineers, software engineers, subject matter experts, project 
managers, and data scientists. This team collectively 
contributed to the creation phase of the process. During this 
phase, the courseware platform and content were created—
which consisted of many iterative cycles of design, 
development, and data instrumentation.  
Once ready, the process moved on to the implementation 
phase wherein the courseware learning environment was 
used by instructors teaching at community colleges and four-
year institutions. Data were collected by the platform as 
students engaged with the courseware, and these data were 
then analyzed during the investigation phase. The data 
analysis of this investigation stage provided examples of 
effective learning methods such as adaptivity [16] and 
replication of findings of previous research on the learn by 
doing method [17]. The investigation phase also uncovered 
areas in need of improvement, which created additional 
iterations of the learning engineering process. For example, 
data analysis showed low student use of the adaptive 
activities across course subjects and educational institutions. 
Identifying this issue initiated an iterative improvement cycle 
wherein a change was made in the location and delivery 
design of the activity. This change was then re-implemented 
with students, and further data analysis showed this solved 
the challenge, and completed that iteration of the original 
learning engineering process [15]. It should be noted that 
these analyses and iterations did not occur one at a time, but 
rather as concurrent processes. 
Yet other investigations of the courseware usage 
identified a new challenge altogether. An analysis of the 
same Probability and Statistics courseware used across a 
state system of community colleges and universities 
identified that different instructor implementation policies 
and practices affected student engagement with the 
courseware [18]. This analysis revealed the need for a new 
learning engineering process where the challenge was no 
longer 
developing 
effective 
courseware, 
but 
rather 
facilitating the instructor’s application of the courseware 
across a large scale of unique learning contexts, as seen in 
Fig. 3.  
When we consider the challenge that no two educational 
settings are the same, it becomes clear that the instructor’s 
application of any learning resource, technology, or 
intervention could result in varied outcomes across settings. 
Successful practices in one specific learning situation may 
not be successful in a different environment. This work seeks 
to accomplish two goals. The first is to show how multiple 
learning engineering challenges and processes can evolve 
from a single original challenge. The second is to focus on 
the contextual factors that contribute to how instructors enact 
any learning technology, resource, or treatment and how the 
learning engineering process can be applied to solve this 
challenge. The courseware example highlights the learning 
engineering process used to design a solution to better train 
instructors in a scalable way, with the goal of supporting 
effective implementation of the courseware in diverse and 
distributed environments. Situating this case in cycles of the 
iterative learning engineering process exemplifies how one 
cycle of work can result in clear points of identifying and/or 
redefining the central challenge addressed through the 
learning engineering process. 
II. 
THE LEARNING ENGINEERING CHALLENGE: 
CONTEXT-SPECIFIC TRAINING AT SCALE 
Every opportunity a student has to learn is one in which a 
learning experience—including an instructional plan—was 
purposefully designed and implemented. Whether this occurs 
in a traditional classroom between a teacher and students, an 
after-school program, or an online training for lifelong 
learners, each learning interaction is an implementation of a 
designed learning experience. The implementation of an 
instructional plan has the potential to drastically impact how 
students engage with the learning resource and develop the 
knowledge at the core of the learning experience. Beyond 
that, it can also impact the way in which students are able to 
demonstrate their understanding through assessments and 
activities. Recent examples of research on digital learning 
resources showcase the crucial role of the educator for the 
implementation of technology in the classroom. A study 
investigating the teachers’ role implementing a cognitive 
tutor for math education for fifth to eighth graders identified 
different 
patterns 
of 
teacher/student/cognitive 
tutor 
interactions that could impact student performance in 
computer-directed learning environments [5]. Research on an 
instructor’s implementation practices of adaptive courseware 
in higher education showcased how specific changes 
to course policies and teaching practice strongly impacted 
student engagement and exam scores [3].  
 
 
30
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-985-0
eLmL 2022 : The Fourteenth International Conference on Mobile, Hybrid, and On-line Learning

 
Figure 3.  The original challenge of creating courseware leads to a new challenge—supporting instructor enactment of courseware across diverse 
environments.
The discussion of implementation is not new, with efforts 
to define and describe its importance in educational research 
going back decades [1]. Implementation—and the level of 
fidelity to the intended implementation plan—is a rigorously 
applied practice in the healthcare field where adherence to a 
implementation of a treatment is highly relevant to 
outcomes, yet historically has been less frequently applied in 
education to evaluate the efficacy or effectiveness of an 
educational treatment [11]. This concept of implementation 
is relevant at its most basic level to the use of courseware as 
a learning resource in the classroom: in order to help students 
achieve the benefits of the courseware (i.e., learn by doing or 
adaptivity), they must actually use those features. However, 
unlike the example of controlled lab experiments in the 
healthcare field discussed by [11], all educational natural 
learning contexts will have variability that cannot fit a single 
prescribed implementation plan. The learning engineering 
process can help to address this challenge by unpacking the 
contextual factors surrounding the implementation of 
courseware at scale. 
Before continuing the unpacking of this learning 
engineering challenge, an issue of language must be 
addressed. 
As 
described 
in 
the 
literature 
above, 
implementation as a term is commonly used to refer to the 
application of a plan or treatment either in a controlled 
experiment or natural learning settings. However, this same 
term is used as the label for the stage of the learning 
engineering process in which the solution is deployed. In this 
work, the challenge of the learning engineering process (the 
implementation of the courseware across varied educational 
settings) and the implementation stage (in which the solution 
to this challenge is implemented) will become easily 
confused. Therefore, in this work, implementation will refer 
to the learning engineering stage, and the central challenge 
will be referred to as the instructor’s application or 
enactment of the courseware.  
A. Challenge Context: Variation in Instructor Setting 
 In the original learning engineering process discussed 
above, the central challenge was to develop courseware that 
could serve students and instructors in a wide variety of 
educational settings. Yet the variation in the implementation 
phase of the learning engineering process—wherein 
instructors utilized the courseware in their teaching practice 
in widely different ways—resulted in significant differences 
in student engagement and outcomes. This realized 
variability presents the opportunity for establishing a second 
challenge, not about the development of the courseware 
31
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-985-0
eLmL 2022 : The Fourteenth International Conference on Mobile, Hybrid, and On-line Learning

itself, but rather the application of it in the classroom. Given 
that the courseware was designed to be agnostic to setting, it 
cannot be differentiated for each use-case. Therefore, a 
potential set of solutions to this challenge required 
exploration outside of the technology itself and as such 
involve a new learning engineering process described in 
greater detail below.  
Part of the learning engineering process is the basic 
principle that learning itself is situated within specific 
contexts. Consider first the complexities educators are faced 
with for teaching and learning. The courseware as a learning 
resource may be a new environment for instructors compared 
to traditional textbooks, or even etexts. In addition to the 
courseware, 
instructors 
likely 
also 
use 
a 
learning 
management system and other teaching and learning tools 
that make up the learning ecosystem for a course. Teaching 
models (such as traditional, blended, flipped-blended) vary 
by instructor and interact with teaching modality, which has 
expanded from face-to-face to include hybrid and fully 
online learning modes with increasing frequency. These 
options for teaching models and resources are further 
complicated once considering their interaction with the 
specific group of learners being instructed. The number of 
students as well as their characteristics all contribute to the 
unique context in which an instructor applies their 
instructional plan. The instructor’s use of courseware 
(designed to be context agnostic) within varied and 
unknowable settings is the context for the second learning 
engineering challenge (Fig. 3). 
B. Designing a Solution 
As seen in Fig. 1, the design phase of the learning 
engineering process encompasses several tasks necessary for 
the development of the solution. The relevant research from 
the learning sciences should be consulted for the design and 
development of the solution, with data instrumentation 
incorporated into both of those tasks. Finally, plans for the 
implementation of the solution are created [13].  
1) Design 
One designed solution to the challenge of effectively 
utilizing courseware across many diverse settings is 
instructor training and support. While there could be any 
number of other solutions, the influence of instructor choices 
on student participation and outcomes is an established 
relationship that can be leveraged toward optimum 
courseware usage, and the instructor is also able to adjust 
enactment plans to account for their specific setting of 
teaching and learning. Before beginning to design and 
develop this instructor training and support solution, the 
existing research and knowledge base on instructor policies 
and practices that are beneficial engagement and outcomes 
should be consulted. Research can surface a set of practices 
to consider recommending for instructors—and sometimes a 
set of practices to avoid. For example, the teaching model 
(traditional, blended, flipped-blended, etc.) is known to 
influence student outcomes [10], and therefore is a factor to 
consider for the application of courseware as the learning 
resource for a class. Simply using the courseware and 
completing the formative practice garners benefits for 
students, so assigning completion points as part of the overall 
course grade could become a recommended practice [3]. 
Another strategy to recommend could be to use the data from 
the instructor dashboards to facilitate interventions between 
instructors and students or help tailor additional instruction 
around content students struggled with. A community 
college case study of instructors using courseware identified 
that the data dashboards helped identify at-risk students and 
facilitated a flipped-blended model for in-person and remote 
learning [14]. Research on successful practices for teaching 
and learning with digital resources can provide a starting 
point for the design and development of a solution [13][7].  
2) Instrumentation 
Instrumentation in the learning engineering process is 
when 
data collection 
is 
designed, 
developed, and 
implemented. This instrumentation step is part of the 
creation phase because preparing for what data will be 
needed for analysis and how that data will be collected must 
happen concurrently with the design and development of the 
solution. While the courseware collects data as students are 
learning, this does not help address the challenge of assisting 
instructors’ use of courseware within their specific teaching 
and learning setting. Therefore, gathering data to explore and 
understand their situated learning environment should 
become part of the solution. The focus on instructors and 
their needs for teaching when instrumenting a solution is 
aligned with the human-centered approach of learning 
engineering. “Human-centered engineering design means 
designing from the perspective of humans who will be 
interacting with implemented designs” [12, p. 83]. 
Identifying core variations in teaching and learning that 
instructors have to navigate in order to instrument and 
implement the solution maintains the instructors at the heart 
of the solution. 
Instructors will need to identify factors that contribute to 
how they might enact this learning resource. This could 
include identifying the teaching model, modality, number of 
students, student characteristics, course category (major/non-
major, elective, required, etc.), and graded components of the 
course. One avenue for standardized data collection would 
be surveys for the instructor to complete prior to receiving 
their training materials (the solution in development). These 
factors all contribute to how the courseware could be most 
successfully utilized and, therefore, are necessary for 
instrumentation as inputs for tailoring training for 
instructors.  
Instrumentation should also include gathering success 
criteria and the subsequent data necessary to determine if 
those success criteria were met. This type of instrumentation 
can be easy to overlook but is key to maintaining a cohesive 
vision for the goals of using courseware as a learning 
resource across all stakeholders involved. This also means 
that this instrumentation will need to consider several distinct 
groups of stakeholders. To design for instrumentation at 
different levels, the first step is identifying the relevant 
groups. Students are the primary users of the courseware, as 
it is their learning resource, and therefore defining what 
success looks like to them is key. Depending on the situation, 
this could range from simply engaging with the courseware 
32
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-985-0
eLmL 2022 : The Fourteenth International Conference on Mobile, Hybrid, and On-line Learning

to increased learning outcomes on assessments. Also 
consider the difference between what students would identify 
as their successful use of the courseware versus what the 
instructor would define as student success. The instructor’s 
goals likely would include success criteria for students—
such as improved grades—but may also include goals for 
themself such as shifting the teaching model, identifying and 
intervening with at-risk students, or tailoring instruction 
based on data. There may also be additional stakeholders 
further removed from the active use of the courseware who 
have a vested interest in its use and therefore additional 
success criteria, such as administrators. Their goals may be 
more broadly related to success and retention metrics. 
Identifying each group of stakeholders for the courseware 
and their goals allows for the instrumentation of data 
collection to determine how those goals are being met. 
Without 
this 
instrumentation 
planning, 
design, 
and 
development, there could be a lack of clarity as to whether 
the courseware was successfully applied in a specific context 
to meet specific goals and, furthermore, what iterative 
improvements may be needed to meet those goals in the 
future. 
3) Plan for Implementation 
 With the research base established and instrumentation 
stakeholders understood, the design and development work 
can move out of initial stages and continue concurrently. The 
challenge of how to train and support instructors to 
implement courseware effectively in incredibly varied 
settings requires a solution that can address these situational 
factors (as many as feasible) in a scalable way. As 
courseware is designed as a learning resource for students, 
training must be designed as a learning resource for 
instructors. Each major contextual factor identified could be 
addressed as a topic with successful practices established in 
educational research combined with case study successes to 
address common variability in each topic. Preparing for 
known variations in teaching environments can provide a 
stand-alone resource, but planning for unanticipated cases 
should also be part of the solution design. Direct instructor 
training would be beneficial not only for identifying these 
special cases, but also to execute the instrumentation plan 
described for collecting data on context and stakeholder 
goals. Furthermore, just as instructors need to tailor their use 
of courseware depending on whether they have 20 or 200 
students, so too would the instructor implementation training 
and support plan need to adapt depending on the number of 
instructors. Designing different training implementation 
plans depending on the number of instructors and modality 
of training is another component of the creation phase. 
C. Implementation and Investigation 
Once the instructor training solution has been designed, 
instrumented, and developed, it is time to implement it with 
instructors. The implementation of this solution may begin 
with a few instructors as a pilot or with a large number of 
instructors if delivery at scale is possible. No matter the 
scale, data collected from instructors on their unique 
teaching factors will begin to inform the investigation of the 
solution. For example, an instructor teaching a traditional 
face-to-face semester course and an instructor teaching an 
asynchronous online course will both experience the training 
solution and use it to attempt to optimize their application of 
the courseware in their unique setting. Combining the data 
collected from their teaching context with the student 
engagement and outcome data collected from the courseware 
will begin to inform how successful the training solution was 
in supporting instructors. Additionally, the contextual factors 
provided by instructors would inform new content or 
changes to the training solution to incrementally increase the 
factors covered, iteratively improving the solution. Feedback 
from instructors on success metrics would also surface 
information in the investigation phase of the learning 
engineering process that could lead to new instructor 
enactment suggestions in the training. Ideally, each 
implementation of the training would provide data to inform 
further improvements to the solution, which would hopefully 
continuously improve instructor use of courseware in their 
educational context for the benefit of student learning. 
III. 
CONCLUSION 
Learning engineering as a process is used in many 
different contexts to solve many different educational 
challenges. However, it is unlikely a challenge would be 
perfectly solved after one single cycle of the learning 
engineering process. Instead, the process is designed and 
intended to support many iterations of the process to 
continuously improve the solution, while also being aware 
that sub-cycles or entirely new but related learning 
engineering challenges may arise. Clearly identifying each 
educational challenge at the center of each learning 
engineering process and how multiple separate or sub-cycles 
relate will benefit the entire learning engineering team tasked 
with solving the challenge(s) most effectively. 
The example of how multiple related learning 
engineering challenges can develop expressed here was 
chosen to highlight a related challenge often overlooked: the 
highly varied educational settings within which educational 
technology and interventions are used. In this example, the 
development of educational technology was the primary 
learning engineering challenge accomplished through the 
learning engineering process, but how to help instructors 
teaching in such varied circumstances became an entirely 
new educational challenge to be solved. The need to support 
instructors to enact learning technology or educational 
interventions in a meaningful way within their unique 
teaching and learning circumstances is a nearly universal 
challenge. Even with educational technology that conforms 
to the latest research in the learning sciences, the enactment 
of that resource in a specific educational setting will strongly 
inform student engagement and outcomes with that resource. 
This challenge is one that all creators and developers of 
educational solutions should consider carefully and attempt 
to solve using the iterations of the learning engineering 
process.  
 
 
 
33
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-985-0
eLmL 2022 : The Fourteenth International Conference on Mobile, Hybrid, and On-line Learning

REFERENCES 
[1] M. Fullan and A. Pomfret. Research on curriculum instruction 
implementation. Review of Educational Research, 47, 1977, 
pp. 335–397. 
[2] J. Goodell, and K.-P Thai. A Learning Engineering Model for 
Learner-Centered Adaptive Systems. In: Stephanidis, C., et al. 
(eds.) HCII 2020. LNCS, vol. 12425, 2020, pp. 557–573. 
Springer, Cham. https://doi.org/10.1007/978-3-030-60128-7 
[3] M. Hubertz  and R. Van Campenhout. Teaching and Iterative 
Improvement: The Impact of Instructor Implementation of 
Courseware on Student Outcomes. The IAFOR International 
Conference on Education – Hawaii 2022 Official Conference 
Proceedings. 
ISSN: 
2189-1036, 
2022, 
pp. 
201–210. 
Honolulu, 
Hawaii. 
https://doi.org/10.22492/issn.2189-
1036.2022.19 
[4] ICICLE. What is Learning Engineering? 2020. Retrieved 
from: https://sagroups.ieee.org/icicle/  
[5] A. Kessler, M. Boston, and M. K. Stein. Exploring how 
teachers support students’ mathematical learning in computer-
directed learning environments. Information and Learning 
Science, 
121(1–2), 
2019, 
pp. 
52–78. 
https://doi.org/10.1108/ILS-07-2019-0075 
[6] A. Kessler and Design SIG Colleagues. Learning Engineering 
Process 
Strong 
Person. 
2020. 
https://sagroups.ieee.org/icicle/learning-engineering-process/.  
[7] A. Kessler, S. Craig, J. Goodell, D. Kurzweil, and S. 
Greenwald. Learning Engineering is a Process. In J. Goodell 
& J. Kolodner (Ed.). Learning Engineering Toolkit: Evidence-
Based Practices from the Learning Sciences, Instructional 
Design, and Beyond. 2022. New York: Routledge.  
[8] K. R. Koedinger, E. A. McLaughlin, J. Z. Jia, and N. L. Bier. 
Is the doer effect a causal relationship? How can we tell and 
why it's important. Proceedings of the Sixth International 
Conference on Learning Analytics & Knowledge. 2016,pp. 
388-397. 
Edinburgh, 
United 
Kingdom. 
http://dx.doi.org/10.1145/2883851.2883957  
[9] M. Lovett, O. Meyer, and C. Thille. The Open Learning 
Initiative: Measuring the effectiveness of the OLI statistics 
course in accelerating student learning. Journal of Interactive 
Media 
in 
Education, 
(1), 
2008, 
pp. 
1-16. 
http://doi.org/10.5334/2008-14  
[10] L. E. Margulieux, W. M. McCracken, and R. Catrambone,. 
Mixing in-class and online learning: Content meta-analysis of 
outcomes for hybrid, blended, and flipped courses. Computer-
Supported Collaborative Learning Conference, CSCL, 1, 
2015, pp. 220–227. 
[11] C. L. O’Donnell. Defining, Conceptualizing, and Measuring 
Fidelity of Implementation and Its Relationship to Outcomes 
in K-12 Curriculum Intervention. (2008). Review of 
Educational 
Research. 
78(1). 
2008, 
pp. 
33–84. 
https://doi.org/10.3102/0034654307313793 
[12] K.-P. Thai, S. D. Craig, J. Goodell, J. Lis, J. R. Schoenherr, 
and 
J. 
Kolodner. 
Learning 
Engineering 
is 
Human-
Centered.  In J. Goodell & J. Kolodner (Ed.). Learning 
Engineering Toolkit: Evidence-Based Practices from the 
Learning Sciences, Instructional Design, and Beyond. 2022. 
New York: Routledge.  
[13] L. Totino and A. M. Kessler. Designing and Implementing a 
Lightboard Learning Experience for Instructors Through the 
Learning 
Engineering 
Process. 
2022. 
https://doi.org/10.31219/osf.io/y3cfb 
[14] M. L. Townsend and R. Van Campenhout. Initial findings 
moving from hybrid to online learning: How Wor-Wic 
Community College adjusted to COVID-19 with Acrobatiq 
courseware. Poster presented at Seventh ACM Conference on 
Learning@Scale. 
2022. 
https://learningatscale.acm.org/las2020/programme/ 
[15] R. Van Campenhout. Learning Engineering as an Ethical 
Framework. In: Sottilare R.A., Schwarz J. (eds) Adaptive 
Instructional Systems. Design and Evaluation. HCII 2021. 
Lecture Notes in Computer Science, vol 12792, 2022, pp. 
105–119. Springer, Cham. https://doi.org/10.1007/978-3-030-
77857-6_7 
[16] R. Van Campenhout, B. Jerome, and B. G. Johnson. The 
impact of adaptive activities in Acrobatiq courseware: 
Investigating the efficacy of formative adaptive activities on 
learning estimates and summative assessment scores. In: 
Sottilare R., Schwarz J. (eds.) Adaptive Instructional Systems. 
HCII 2020. LNCS, vol 12214. Springer. 2020, pp. 543–554. 
https://doi.org/10.1007/978-3-030-50788-6_40 
[17] R. Van Campenhout, B. G. Johnson, and J. A. Olsen. The 
doer effect: replicating findings that doing causes learning. 
Proceedings of eLmL 2021: The Thirteenth International 
Conference on Mobile, Hybrid, and On-line Learning. ISSN 
2308-4367, 
 
2021, 
pp. 
1–6. 
https://www.thinkmind.org/index.php?view=article&articleid
=elml_2021_1_10_58001 
[18] R. Van Campenhout and M. Kimball. At the intersection of 
technology and teaching: The critical role of educators in 
implementing technology solutions. IICE 2021: The 6th 
IAFOR International Conference on Education – Hawaii 
2021 Official Conference Proceedings. ISSN 2189-1036, 
2021, 
pp. 
151–161. 
https://doi.org/10.22492/issn.2189-
1036.2021.11  
 
 
34
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-985-0
eLmL 2022 : The Fourteenth International Conference on Mobile, Hybrid, and On-line Learning

