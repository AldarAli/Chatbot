A 3D Convolutional Neural Network for Anomalous Propagation Identiﬁcation
Hansoo Lee, Jonggeun Kim, and Sungshin Kim
Department of Electrical and
Computer Engineering
Pusan National University
Busan, South Korea
Email: {hansoo, wisekim, sskim}@pusan.ac.kr
Abstract—Radar is one of the most popular and widely used
weather observation devices because of its better performance
compared to other remote sensing devices. However, the ob-
servation results of the radar unavoidably contain unwanted
signals, called non-precipitation echoes, which include anomalous
propagation. These represent a negative inﬂuence, especially in
the quantitative precipitation estimation. Therefore, it is essential
to remove the anomalous propagation in the radar data for
accurate weather forecasting. In this paper, we implemented a
three-dimensional convolutional neural network for classifying
the anomalous propagation in the radar data. Without consid-
ering feature engineering, which is difﬁcult and mostly hand-
crafted, we were able to obtain improved performance in the
classiﬁcation with actual occurrence cases of the echo.
Keywords–Pattern recognition; Deep learning; 3D convolutional
neural network; Anomalous propagation; Radar data analysis.
I.
INTRODUCTION
Machine learning, which allows solving real-world prob-
lems by utilizing given data, applies to lots of practical ﬁelds
including medicine [1], ﬁnance [2], genetics and genomics
[3], etc. Additionally, deep learning [4], a sub-class of the
machine learning, signiﬁcantly inﬂuences many aspects of
modern society by achieving outstanding improvements espe-
cially in large-scale image processing and speech recognition.
One of the compelling advantages of deep learning is that it
can derive remarkably successful results without considering
feature selection [5] and extraction [6]. Therefore, there are a
lot of ongoing active studies that aim to lower the expensive
computational costs.
These research works inﬂuence many academic and prac-
tical ﬁelds including weather prediction because the weather
prediction is intimately connected with modern society [7]. For
example, it is possible to protect lives and properties by fore-
casting storms and local torrential rainfalls. Also, these works
help minimize economic damages from agﬂation caused by
abnormal climate changes. Deep learning related studies have
been gradually growing to respond to an increased demand for
accurately analyzed results from observation devices such as
radar and satellite.
Currently published researches related to weather predic-
tion are mainly focused on precipitation nowcasting [8][9]
and storm identiﬁcation [10][11] based on accurately ana-
lyzed results of radar observations. The radar is the most
popular weather observation device because it can generate
spatiotemporal observation results with high resolution, and
is able to provide three-dimensional precipitation information
in a more direct way than other sensing devices. However, the
radar observes all objects in the atmosphere without exception.
In other words, the observation results inevitably contain
unwanted signals, called non-precipitation echoes.
Non-precipitation echoes have many different causes. The
typical non-precipitation echoes are as follows. First, inter-
ference [12] occurs by strong wireless impulse signals which
have similar bandwidth to radars. Second, biological echo can
appear [13] by a ﬂock of birds or insects. Third, ground echo
[14] and sea clutter [15] can be present in the radar image
by artiﬁcial or natural objects on the surface of the earth and
the sea. Fourth, chaff echo [16] occurs by scattered lightweight
materials from an aircraft or battleship to avoid radar detection.
Fifth, anomalous propagation [17] appears by refracted radar
beam due to rapid changes in temperature or humidity. Among
them, the anomalous propagation causes signiﬁcant errors in
radar rainfall estimation because it is less predictable and has
changeable intensity of reﬂectivity or extension of areas.
In early days, a manual quality control process based on
experts knowledge was used to eliminate anomalous propaga-
tion. After that, statistical-based [18] and machine learning-
based [19] methods were complementary used. However, ear-
lier studies applied conventional machine learning methods
which included feature engineering. Considering that feature
engineering negatively inﬂuences performance, many difﬁcul-
ties followed, unavoidably. In this paper, we implement a
non-precipitation echo detection method based on a three-
dimensional convolutional neural network. By using our deep
learning architecture, it is unnecessary to go through additional
feature selection and extraction.
This paper is organized as follows. In Section 2, we brieﬂy
present a background knowledge of radar operating principles
and anomalous propagation. Section 3 explains convolutional
neural network and introduces our 3D architecture. In Section
4, our experimental framework and results are described.
Section 5 provides the conclusion and future works.
II.
BACKGROUND
This section explains the operating principle of radar and
occurrence properties of the anomalous propagation echo for
providing background knowledge.
A. Weather Radar
The primary operating principles of radar are radiating
intense electromagnetic energy and gathering backscattered
signals from ﬂoating objects in the observation hemisphere. In
1
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-646-0
INTELLI 2018 : The Seventh International Conference on Intelligent Systems and Applications

other words, by using electromagnetic energy as its measur-
ing tools, radar computes valuable information for analyzing
properties of the reﬂected signals including distance, power
density, radial velocity, etc. [20].
The operating principle makes the radar one of the most
popular measurement devices for weather forecasting because
the electromagnetic waves travel their pre-set route from the
transmitter of radar regardless of weather condition. In other
words, radar can operate 24 hours a day, seven days a week
in all weather conditions including severely low visibility
conditions including fog, rain, snow, and hail.
There are two main types of scans: Range Height Indi-
cator (RHI) and Plan Position Indicator (PPI). The RHI scan
provides the image from the side. Lots of studies utilize the
RHI scan when an improved vertical resolution is required.
On the other hands, the PPI scan produces the image as seen
from above [21]. The PPI scan is generally utilized in weather
forecasting process because it facilitates to understand time
series changes of radar echoes.
B. Anomalous Propagation
The electromagnetic waves follow the quasi-optical laws
because they behave similarly to light beams in a uniform
and constant medium. But the precondition is rarely satisﬁed
in the earth’s atmosphere in practice. In other words, the
refraction of the emitted electromagnetic waves is a common
phenomenon because of several factors including pressure,
temperature, and vapor pressure. Considering that the primary
operating principle of the radar is based on the condition
that the emitted electromagnetic waves travel in an ideal
atmospheric environment, measurement results are inevitably
wrong. Therefore, standard refraction based on these factors is
commonly used in actual observation instead of no refraction
condition.
From a different point of view, the radiated electromagnetic
waves from the radar can travel in various directions due
to refraction when the speciﬁc conditions are satisﬁed. For
instance, the rapid changes of a temperature gradient, pressure
or water vapor content can bend the waves or even trap them in
a speciﬁc layer in the air. As a result, when the rapid changes
of the atmospheric condition refract the radar beam, there is
a chance that the radar cannot perceive the difference which
can derive signiﬁcant wrong results in weather forecasting.
There are two typical different cases of the refracted
pathways: the radar shows nothing when raining, and the
radar shows precipitation echoes without raining. The former
situation occurs when the radar beams are refracted toward
the opposite direction of the surface, which is called sub-
refraction. And the latter situation occurs when the radar
beams are refracted toward the surface, which is called super-
refraction. In this case, the radar misrecognizes the objects
on the earth or sea surface as precipitation echoes. The
misrecognized echo is called anomalous propagation.
Notably, the anomalous propagation causes signiﬁcant er-
rors in radar rainfall estimation because it is less predictable
and it has the changeable intensity of reﬂectivity or extension
of areas. Therefore, the anomalous propagation should be
removed from the radar observation result for accurate weather
forecasting. Figure 1 and Figure 2 show individual cases
of precipitation and anomalous propagation, respectively. As
0
0
0
100
100
10
200
200
x position
y position
20
300
300
Precipitation
altitude
400
400
30
40
Figure 1. Precipitation case
Figure 2. Anomalous propagation case
shown in the ﬁgures, it is difﬁcult to distinguish which one
is precipitation and which is anomalous propagation without a
quality control process.
III.
METHODS
This section provides brief elucidations about a conven-
tional artiﬁcial neural network, a convolutional neural network
that is one of the outstanding deep learning models, and de-
tailed explanations about our implemented three-dimensional
convolutional neural network.
A. Artiﬁcial Neural Network
The artiﬁcial neural network is a mathematical algorithm
for high-level data processing which is inspired by biological
nerve systems. It is conﬁrmed that the biological nerve system
is a source of the artiﬁcial neural network because the op-
erating principles of their basic components are considerably
similar. Many practical applications frequently use the arti-
ﬁcial neural network for solving their problems because the
2
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-646-0
INTELLI 2018 : The Seventh International Conference on Intelligent Systems and Applications


	

	

	

		
	

	
Figure 3. Simpliﬁed convolutional neural network
model has good performance in classiﬁcation, regression, and
clustering [22].
Layers are typical organizations of the artiﬁcial neural
network. Nodes, which contain an activation function, are
components of the layers. The artiﬁcial neural network can
solve difﬁcult problems by using highly interconnected and
weighted nodes. There are three types of layers: input, hidden,
and output. When the artiﬁcial neural network gets a mul-
tidimensional vector as an input, the input layer distributes
the input to the hidden layer. And the hidden layer determines
whether the outputs of the previous layer are helpful or harmful
to the ﬁnal result and distributes its output by using weighted
sum and activation function. The output layer ﬁnalizes outputs
of the previous layer. In summary, it is possible to describe
the operating principle of the artiﬁcial neural network in (1).
y = fh
 n
X
i=1
ωixi − b
!
(1)
where f(·) is an activation function, n is the number of
variables xi from the previous layer, ω is weights, and b is
biases.
However, despite the outstanding performances of the con-
ventional artiﬁcial neural network in various practical ﬁelds,
the requirement of signiﬁcant computational complexity is the
most substantial limitation of the model when it needs to
deal with image processing. For example, the conventional
model requires 12, 228 weights in the ﬁrst hidden layer for
analyzing a 64 × 64 color image. Additionally, considering
that the network structure should be a lot larger than the input
image, the conventional neural network seems not manageable
for the given problem. In other words, there are two main
reasons why the conventional neural network is not suitable
for image processing. First, it is necessary to provide unlimited
computational power and time for training the huge model.
Second, it might cause over-ﬁtting problem.
B. Convolutional Neural Network
For solving the two problems of the conventional model, a
convolutional neural network is suggested [23]. The convolu-
tional neural network has similar components to the conven-
tional artiﬁcial neural network. Namely, they have identical
structures, components, and backpropagation based on the
self-optimisation process. But a noticeable difference exists
between the conventional neural network and the convolutional
neural network in that the latter has three salient types of lay-
ers: convolutional, pooling and fully-connected layers. Figure
3 illustrates the simpliﬁed example of the convolutional neural
network.

	










	












(a) Conventional machine learning
	

	
	


		






	

(b) Deep learning
Figure 4. Comparison of model learning process
When the input layer distributes the pixels of the image
as inputs, the convolution layer convolves each ﬁlter across
the data to produce a two-dimensional activation map. By
using a zero-padding process, it is possible to keep the size
of each convolved data as given inputs. The pooling layer
reduces the data from the convolution layer with activation
function for curtailing the number of parameters and the
computational complexity of the model. The fully-connected
layer performs the same roles as the conventional neural
network and attempts to derive scores from the activation
functions. Finally, the convolutional neural network uses the
derived scores for classiﬁcation.
Furthermore, there is another advantage to notice in the
convolutional neural network that the convolution layers in
the model can extract features from given input data. In the
majority of conventional machine learning algorithms, they
should include feature engineering in a training phase. The
principal point is that most of the features are hand-crafted,
which is difﬁcult, time-consuming and requiring domain ex-
pertise. Also, if the extracted features could not describe the
given data well, it is possible to degenerate performances
of the model. Figure 4a shows the learning and prediction
phases of the conventional machine learning methods, which
include the feature extraction in the process. On the other
hand, it is unnecessary to put the time and effort into feature
engineering when the convolutional neural network is applied.
Figure 4b illustrates the learning and prediction phases of the
deep learning including the convolutional neural network. It is
easily noticeable in Figure 4 that the feature extraction process
is not necessary for the deep learning implementation.
C. 3D Convolutional Neural Network
In this paper, we implemented a three-dimensional convo-
lutional neural network for practical utilization in radar data
analysis. The architecture of the model is shown in Figure
5, which contains four hidden convolution layers and a fully-
connected layer. The convolution layers contain convolution
ﬁlter, ReLu activation function (f(x) = max(x, 0)), and
max-pooling. Additionally, dropout is applied for preventing
overﬁtting.
3
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-646-0
INTELLI 2018 : The Seventh International Conference on Intelligent Systems and Applications




	




	




	




	





	





	





	





	





	





	


	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	









	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	













	
	












	














Figure 5. 3D Convolutional neural network structure
The implemented three-dimensional convolutional neural
network is similar to the architecture of two-dimensional
convolutional neural networks. But, unlike the bidimensional
convolutional neural network structure, the implemented model
utilizes tridimensional convolutional ﬁlters, activation func-
tions, and max-poolings. We chose a 3×3×3 size structure for
convolutional ﬁlters by conducting empirical experimentations.
Also, we designed the convolution layers so that the shape of
input and output is identical by using a zero-padding process.
In case of max-pooling, we chose a 2×2×2 shape. This kind
of max-pooling structure allows reducing the computational
complexity of the convolutional network for both two- and
three-dimensional structure. Similarity and dissimilarity of the
convolutional neural network structures are easily found in (2)
and (3).
vxyz
ij
= f
 X
m
Pi−1
X
p=0
Qi−1
X
q=0
ωpq
ijmv(x+p)(y+q)
(i−1)m
+ bij
!
(2)
vxyz
ij
= f
 X
m
Pi−1
X
p=0
Qi−1
X
q=0
Ri−1
X
r=0
ωpqr
ijmv(x+p)(y+q)(z+r)
(i−1)m
+ bij
!
(3)
where (x, y, z) is a coordinate of feature map and volume,
(p, q, r) is a spatial dimension index of kernel, i indicates
convolution layer, bij means bias, and f(·) is an activation
function.
Also, for applying the rule [24], we tried to add more
layers in the architecture. As a result, we implemented another
convolutional neural network, which additionally contains a
fully-connected layers, as shown in Figure 6. As for the same
structure described in Figure 5, the convolution layers contain
a convolution ﬁlter, ReLu activation function, max-pooling and
dropout. The difference between the two models is illustrated
in Table I for readibility.
IV.
EXPERIMENTS
Currently, the implemented network is designed as a binary
classiﬁcation as shown in Figure 5 because it is hard to
obtain the sufﬁcient number of individual recurrence case of
each non-precipitation echo. Also, the simultaneous occurrence
cases of the non-precipitation echoes are more frequent than
the standalone occurrence cases. Therefore, we utilised learn-
ing of the implemented model by using two days of anomalous
propagation and two days of precipitation. And we applied the
other data for testing which contains both precipitation and
anomalous propagation separately. In summary, we used 508
numbers of tridimensional radar images as training data and
144 number of radar images as test data. Also, we trained the
implemented models with the Adam optimizer at a learning
rate of 0.001.
The testbed environment conﬁguration was as follows:
•
CPU: Intel i7-7700K @ 4.20GHz × 8
•
RAM: 16GB DDR4
•
GPU: NVIDIA GeForce GTX1080/PCIe/SSE2
•
Framework: TensorFlow 1.4.1, Python 3.5.2
•
OS: Ubuntu 16.04 LTS
For evaluating the implemented three-dimensional con-
volutional neural network, we conducted evaluations using
accuracy as shown in (4).
Accuracy =
TP + TN
TP + TN + FP + FN
(4)
where TP indicates true positive, TN indicates true negative,
FP indicates false positive, and FN indicates false negative.
Also, we utilised the terms that true indicates the anomalous
propagation echo, and that false indicates the non-anomalous
propagation echo, respectively.
We derived the results from the implemented models in
Figure 5 and Figure 6. By using the model in Figure 5, it
showed classiﬁcation accuracy as 68.75% on average. On the
4
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-646-0
INTELLI 2018 : The Seventh International Conference on Intelligent Systems and Applications




	




	




	




	





	





	





	





	





	





	


	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	









	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	

	



	













	
	












	
















Figure 6. Extended 3D Convolutional neural network structure
TABLE I. THREE-DIMENSIONAL CONVOLUTIONAL NEURAL NETWORKS FOR EXPERIMENTATION
Conﬁguration
3DCNN
input
16@conv3d
maxpool
32@conv3d
maxpool
64@conv3d
maxpool
128@conv3d
maxpool
FC-512
softmax
3DCNN Extended
input
16@conv3d
maxpool
32@conv3d
maxpool
64@conv3d
maxpool
128@conv3d
maxpool
FC-512
FC-512
softmax
other hands, by using the model in Figure 6, it showed better
average accuracy as 72.22%. From the experimental results, we
can conclude that the three-dimensional convolutional neural
network as shown in Figure 6 shows better results because the
two sequentially connected fully-connected layers operate as
the conventional neural network.
V.
CONCLUSION AND FUTURE WORKS
In this paper, we implemented a three-dimensional convo-
lutional neural network for classifying the anomalous propaga-
tion in the radar data as a feasibility study. The implemented
model was able to learn volumetric features in tridimensional
radar data without information loss. As a result, the three-
dimensional convolutional neural network was able to identify
the anomalous propagation by using actual occurrence cases
of the anomalous propagation.
In future works, we will try to implement multi-class
classiﬁcation method by using the proposed method as a
prototype. Currently, the implemented network is designed as a
binary classiﬁcation to classify the whether the given tridimen-
sional is an anomalous propagation or not. The convolutional
neural network is easy to expand from binary to multi-class
classiﬁcation by expanding the number of layer elements of
the output layer. Additionally, the multi-class classiﬁcation
based approach is a more beneﬁcial way to utilize in practical
ﬁelds because it is more prone to occur different types of non-
precipitation echoes simultaneously.
ACKNOWLEDGMENT
This work was supported by BK21PLUS, Creative Human
Resource Development Program for IT Convergence.
REFERENCES
[1]
R. C. Deo, “Machine learning in medicine,” Circulation, vol. 132,
no. 20, 2015, pp. 1920–1930.
[2]
W.-Y. Lin, Y.-H. Hu, and C.-F. Tsai, “Machine learning in ﬁnancial
crisis prediction: a survey,” IEEE Transactions on Systems, Man, and
Cybernetics, Part C (Applications and Reviews), vol. 42, no. 4, 2012,
pp. 421–436.
[3]
M. W. Libbrecht and W. S. Noble, “Machine learning applications in
genetics and genomics,” Nature Reviews Genetics, vol. 16, no. 6, 2015,
p. 321.
[4]
Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521,
no. 7553, 2015, p. 436.
[5]
G. Chandrashekar and F. Sahin, “A survey on feature selection meth-
ods,” Computers & Electrical Engineering, vol. 40, no. 1, 2014, pp.
16–28.
[6]
J. Tang, S. Alelyani, and H. Liu, “Feature selection for classiﬁcation: A
review,” Data Classiﬁcation: Algorithms and Applications, 2014, p. 37.
[7]
X. Shi et al., “Deep learning for precipitation nowcasting: A benchmark
and a new model,” in Advances in Neural Information Processing
Systems, 2017, pp. 5622–5632.
[8]
S. Xingjian et al., “Convolutional lstm network: A machine learning ap-
proach for precipitation nowcasting,” in Advances in neural information
processing systems, 2015, pp. 802–810.
[9]
S. Kim, S. Hong, M. Joh, and S.-K. Song, “Deeprain: Convlstm
network for precipitation prediction using multichannel radar data,”
arXiv preprint arXiv:1711.02316, 2017.
[10]
W. Zhang, L. Han, J. Sun, H. Guo, and J. Dai, “Application of multi-
channel 3d-cube successive convolution network for convective storm
nowcasting,” arXiv preprint arXiv:1702.04517, 2017.
[11]
Y. Liu et al., “Application of deep convolutional neural networks
for detecting extreme weather in climate datasets,” arXiv preprint
arXiv:1605.01156, 2016.
[12]
E. Saltikoff et al., “The threat to weather radars by wireless technology,”
Bulletin of the American Meteorological Society, vol. 97, no. 7, 2016,
pp. 1159–1167.
[13]
V. Lakshmanan, J. Zhang, and K. Howard, “A technique to censor
biological echoes in radar reﬂectivity data,” Journal of Applied Me-
teorology and Climatology, vol. 49, no. 3, 2010, pp. 453–462.
[14]
S. M. Bachmann and M. Tracy, “Data driven adaptive identiﬁcation and
suppression of ground clutter for weather radar,” in 25th Conference on
IIPS for Meteorology, Oceanography, and Hydrology, Nashville, TN,
USA, vol. 11, 2009, p. B3.
5
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-646-0
INTELLI 2018 : The Seventh International Conference on Intelligent Systems and Applications

[15]
P. Gerstoft, W. S. Hodgkiss, L. T. Rogers, and M. Jablecki, “Probability
distribution of low-altitude propagation loss from radar sea clutter data,”
Radio Science, vol. 39, no. 6, 2004, pp. 1–9.
[16]
Y. H. Kim, S. Kim, H.-Y. Han, B.-H. Heo, and C.-H. You, “Real-time
detection and ﬁltering of chaff clutter from single-polarization doppler
radar data,” Journal of Atmospheric and Oceanic Technology, vol. 30,
no. 5, 2013, pp. 873–895.
[17]
M. Grecu and W. F. Krajewski, “An efﬁcient methodology for detection
of anomalous propagation echoes in radar reﬂectivity data using neural
networks,” Journal of Atmospheric and Oceanic Technology, vol. 17,
no. 2, 2000, pp. 121–129.
[18]
S. Moszkowicz, G. J. Ciach, and W. F. Krajewski, “Statistical detection
of anomalous propagation in radar reﬂectivity patterns,” Journal of
Atmospheric and Oceanic Technology, vol. 11, no. 4, 1994, pp. 1026–
1034.
[19]
M. A. Rico-Ramirez and I. D. Cluckie, “Classiﬁcation of ground clutter
and anomalous propagation using dual-polarization weather radar,”
IEEE Transactions on Geoscience and Remote Sensing, vol. 46, no. 7,
2008, pp. 1892–1904.
[20]
M. I. Skolnik, “Introduction to radar,” Radar Handbook, vol. 2, 1962.
[21]
F. Fabry, Radar meteorology: principles and practice.
Cambridge
University Press, 2015.
[22]
S. Haykin and N. Network, “A comprehensive foundation,” Neural
Networks, vol. 2, no. 2004, 2004, p. 41.
[23]
Y. LeCun and Y. Bengio, “Convolutional networks for images, speech,
and time series,” The handbook of brain theory and neural networks,
vol. 3361, no. 10, 1995, p. 1995.
[24]
Y. Bengio, “Practical recommendations for gradient-based training of
deep architectures,” in Neural networks: Tricks of the trade.
Springer,
2012, pp. 437–478.
6
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-646-0
INTELLI 2018 : The Seventh International Conference on Intelligent Systems and Applications

