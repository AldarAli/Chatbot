Towards Demystifying Transformations of Tchaikovsky’s Children’s Album with
Support of Computational Models: Problem Conceptualization
Evgeny Pyshkin
University of Aizu
Tsuruga, Ikki-Machi, Aizu-Wakamatsu, Fukushima, 965-8580, Japan
Email: pyshe@u-aizu.ac.jp
Abstract—Though the studies of rich metaphors hidden in the
musical compositions lay mostly in scope of art and musicology,
there is still large space for formal methods based on mathe-
matical models and computer technology that can be helpful in
discovering complementary insights to how the composition is
structured, what are its relationships to the precursors’ works,
and how it affects the later works of the same or other authors.
Our idea is to investigate how computational models can enhance
musicology research on music style identiﬁcation and comparative
analysis using the case study of Tchaikovsky’s Children’s Album.
Keywords–Musicology; music information retrieval; human-
centric computing; similarity; music modeling.
I.
INTRODUCTION
In my recent talk on Jan 6th, 2021, in the University of
Aizu “Tchaikovsky. Children’s (?) Album: Time, Metaphors,
Rediscoveries” [1], I discussed the phenomenon of Piotr
Tchaikovsky’s “Children’s Album” for piano solo (Op. 39) [2].
This masterpiece was composed and published as far as in
1878, but today it still remains one of constant topics of interest
for researchers [3][4]. Though the study of rich metaphors
hidden in the pieces thought to be for children rather lies
in the scope of art and musicology, there is still a large
research space for formal methods based on mathematical
and computational models, which may give additional insights
into our understanding of the structure and organization of
the whole work, its relationships to precursors (such as “43
Clavierst¨ucke f¨ur die Jugend” by Robert Schumann [5]), as
well as the reasons for signiﬁcant differences between the
original manuscript and the ﬁrst published edition. Surpris-
ingly, in musicology literature, one of the ﬁrst careful studies
of transformations between the manuscript and the published
edition can be found in the early 1990s only; thus, more than
100 years after the whole work was completed [6][7]. These
studies mostly remain in scope of music and art theory, with
almost no involvement of machine learning approaches. Today,
it is commonly not disputed that computer science and artiﬁcial
intelligence may contribute to musicology research on music
style identiﬁcation and comparative analysis. In this study, we
try to discover appropriate formal models that would enhance
the analysis and understanding of Tchaikovsky’s “Children’s
Album”, which can be considered as a very good example
of applied human-centric computing research in the frame of
art and humanities, where solutions cannot be designed within
a certain context only, but require intensive cross-disciplinary
efforts so as to bridge the communities working in different
contexts and using different vocabularies [8].
The remaining text is organized as follows. Section II
provides a brief review of state-of-the-art research on linking
musicology and computerized analysis of music compositions
with a particular attention to the case study of Tchaikovsky’s
“Children’s Album”. Section III sketches a number of promis-
ing models that may contribute to music stylistic similarity
recognition and evaluation aimed at bridging the gaps between
musicology studies and computer models.
II.
RELATED WORK
According to Nattiez, music is a symbolic fact charac-
terized by the complex conﬁguration of interpretants [9]. In
music, we use various connected but independent models
including letter-based notations, such as Helmholz or scientiﬁc
pitch notation (that can be considered as simple syntax based
language constructions), complex symbolic notations in the
form of graphic note scores ranging from hardly formalizable
ancient models, such as Znamenny chant, at one pole, or
relatively strict Mensural notation, at another pole, up to
modern sheet music (based on many rules but giving some
freedom to support the individual styles of composers), piano
roll notation, tablature, MIDI representations, as well as audio
signals and even spectral models, such as acoustic ﬁngerprints.
The great variety of models used for music representation is
one of reasons why music provides an interesting and complex
use case for experimenting with information retrieval, object
recognition and classiﬁcation algorithms. Music representation
complexity can be explained by the presence of two arrays of
elements and relationships, where the ﬁrst one corresponds to
the elements that can be treated mathematically (pitch, rhythm,
or harmony), while the second one includes non-mathematical
elements such as tension, expectancy, and emotion [10].
A. Bridging the gap between pure musicology and applied
human-centric computer technology
Current approaches to music similarity evaluation (in-
cluding our own work on melody extraction and similarity
estimation using Earth Mover’s Distance algorithms [11])
mostly target the searching and retrieval systems including
well-known apps, such as Shazam [12], without a perfect ﬁt
to the problems of stylistic similarity evaluation. From this
point of view, models of functional representation of music
harmony and harmonic similarity estimation [13] seem to be
more adequate to the problem of style identiﬁcation. Indeed,
usually, listeners can recognize similarity of compositions
because of their harmonic similarity (see Figure 1). However,
it does not immediately lead us to clearly conclude about the
composition’s stylistic resemblances or dependencies. Even
6
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-887-7
ADVCOMP 2021 : The Fifteenth International Conference on Advanced Engineering Computing and Applications in Sciences

harmonic equivalence may not be enough to recognize the
melody, as demonstrated in [14] and later analyzed in [15]
in the experiments with melodies distorted by substituting the
note octave by randomly selected ones within three octaves:
every note in the sequence keeps its position on the scale,
but the tune varies over a three-octave range (similarly to an
example of such distortion shown in Figure 2).
Figure 1. Harmony resemblance between Beethoven’s Moonlight Sonata and
its variation
Figure 2. Distorted note sequence of Beethoven’s Moonlight Sonata with
keeping harmonic equivalence
Harmonic functions were core elements of SPEAC music
representation system developed by Cope [16][17], which is an
implementation of augmented transition network, a ﬁnite-state
automaton with recursive succession rules between music sub-
phrases allowing for logical syntax substitutions [18]. Cope’s
SPEAC system is based on a hierarchical representation of the
structure of music composition in nested contexts beginning
from notes and chords up to chapters and parts (see Figure 3
(a)). Five identiﬁers contributing to SPEAC acronym stand
for statement S, preparation P, extension E, antecedent A,
and consequent C, all of which are kinds of abstractions
assigned to groups of notes “depending on levels of tension
between intervals, metrical placement, and agogic emphasis,
measured both in the preceding and following groups” [18].
Succession rules deﬁned by Cope limit possible transitions
between the SPEAC states (see Figure 3 (b)). Therefore,
SPEAC progressions are like genome sequences using SPEAC
identiﬁers as bases enforced by harmonic tension weights
and hierarchical relationships between progressions at different
levels. Modeling music structure using SPEAC-analysis can
be a promising approach to recognize music style similarity
through SPEAC progression similarity as well as with the help
of comparison between the corresponding graphs, speciﬁcally
with respect to recent SPEAC-analysis implementations avail-
able as libraries in universal languages, such as Python [19].
Figure 3. Progression bases in SPEAC system by David Cope.
Due to a large number of applications of using deep neural
networks for object recognition and classiﬁcation (especially
for image recognition, including such subjective trait as image
aesthetics), machine learning approaches and recurrent neural
networks may be promising for music style identiﬁcation,
classiﬁcation and analysis. Though, in contrast to a variety of
works on computer music generation, we argue that the main
challenge is not to teach AI to create art objects, but to be able
to help us in perceiving objects created by humans [20].
B. Renditions and Implications of “Children’s Album”
Since both Tchaikovsky and Schumann belong to the ro-
mantic tradition rooted in part of leitmotif music by Beethoven
and Wagner, on the one hand, and in the new music language of
Glinka, Chopin and Liszt, on the other hand, certain harmony
and music development similarity surely exists in their works.
According to the network of inﬂuences on classical composers
originally described by Smith and Georges et al. in the original
Classical Music Navigator [21], Schumann is one of composers
who greatly inﬂuenced Tchaikovsky (along with Balakirev,
Beethoven, Chopin, Delibes and others) as shown in Figure 4.
However, admitting Schumann’s inﬂuence to Tchaikovsky
does not lead us to automatically judge the “Children’s Album”
as an imitation of Schumann’s pieces for the young (also with
long history of editions but rather few scholarly studies [23])
even though Tchaikovsky claimed it explicitly in the subtitle
for the published edition “24 simple pieces for children like
Schumann” (but not in the manuscript! [24]). What if this
subtle (?) subtitle is a kind of hint that Tchaikovsky gave
us? Like saying: “Well, it is deﬁnitely not “like Schumann”!
Should you then believe in the appropriateness of all made
transformations?” These transformations (see Figure 5) destroy
the structure of the album as an indissociable whole, and
deform the micro-cycles existing in the manuscripts (where the
Doll cycle is the clearest case), as well as evident harmonic
links, for instance, between the ﬁrst and the last pieces in the
manuscript, “Morning prayer” and “The hurdy-gurdy man is
singing”, respectively.
An idea that changes in the order of compositions between
the manuscript and ﬁrst published edition were mistakenly in-
troduced by the publisher could not be accepted as convincing
enough: indeed, Tchaikovsky approved this version. Nekhaeva
suggested that these transformations can be considered as a
“gesture of the composer, a natural desire to overcome the
temporary barrier and directly appeal to future generations of
musicians” [4]. This opinion supports an existing hypothesis
7
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-887-7
ADVCOMP 2021 : The Fifteenth International Conference on Advanced Engineering Computing and Applications in Sciences

Figure 4. “Inﬂuenced-by” relationships for Tchaikovsky (as in Classical Music Navigator [22]
claiming that Tchaikovsky probably preferred to hide some
metaphors so that they are not so explicitly exposed as in the
manuscript. From the perspective of musicology, we could not
expect to ﬁnd a ﬁnal answer (and perhaps it is not needed).
Instead, a possibility to incorporate formal computational
approaches into informal art discourse can, produce a number
of important additional insights for better understanding of
genesis of one of Tchaikovsky’s masterpieces in piano music.
C. Dataset Issues
In the process of study, we need to investigate, what are the
suitable computational approaches that may contribute to style
identiﬁcation. Because of the subjectivity of style attribution
and style dependency analysis, a possibility to construct and
assess different computational models should be considered.
It may be that particular models can contribute to particular
characteristics of music style recognition.
We also need to deﬁne a dataset with the selection of
compositions including the following components:
•
24 piano compositions from the “Children’s Album”;
•
Selection of characteristic piano compositions by
Schumann, including those from Op. 68;
•
Selection of compositions with expected high degree
of style similarity, which were attributed by their
authors as imitations, such as piano works of Liszt,
Chopin, Schumann (referential dataset);
•
Selection of other characteristic compositions (e.g.,
by Tchaikovsky), where style similarity was reported
by musicology experts (referential dataset). The stud-
ies [25][26] can provide information for selection of
relevant referential datasets.
III.
PROMISING APPROACHES FOR FURTHER STUDIES
There is a number of works contributing to music analysis
based on audio signal processing. Detection music ﬁle similar-
ity based on tonality, tempo and chord progression similarity
(that can be extracted from sound ﬁles using signal processing
algorithms as demonstrated in [27]) is very helpful to improve
8
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-887-7
ADVCOMP 2021 : The Fifteenth International Conference on Advanced Engineering Computing and Applications in Sciences

Figure 5. “Children’s Album”: Original structure is destroyed in the published version.
algorithms of music retrieval, but may not be enough to judge
about stylistic and harmonic similarity or about the presence
of transformed citations where the key, tempo and melody
can be signiﬁcantly modiﬁed compared to the original but
keeping almost intangible traits of similarity, still perceptible
by an experienced ear.Great opportunities provided by signal
processing algorithms enforced by hierarchical semi-Markov
models of music enable automatic music transcription for given
audio signals [28]. Though these works are naturally closely
related to music similarity analysis, the ﬁndings could not be
directly applicable to the problem of developing computational
models of style similarity, which remains challenging even if
the note score is available.
Similarity detection based on note sequences (e.g., in [29])
can give interesting insights into the genesis of music styles,
but does not help much in solving speciﬁc problems of inﬂu-
ence assessment, where study of exact or slightly transformed
note sequences may be insufﬁcient. However, the idea of
grouping compositions based on weaker traits of similarity in
their themes and sub-themes [30] can be promising.
With respect to studies on analysis of acoustic spectral ﬁn-
gerprints for unique identiﬁcation of the music fragments (e.g.,
according to the algorithms described in [31][32]), comparison
between such ﬁngerprints can give one component for similar-
ity analysis. Figure 6 displays an example of piano composition
spectral representation constructed using the online tool [33].
Among other interesting works relevant to this study, there
are studies on approaches using deep neural networks for
object recognition applied to the case of music for a variety of
adjacent problems, including music genre classiﬁcation [34],
content-based music recommendation [35], music style model-
ing [36], deep leaning-based music generation [37], and style-
Figure 6. Sample spectrogram of “A New Doll” (Op. 39, orig. No. 6): ﬁrst
30 measures recorded by Evgeny Pyshkin at Yamaha YDP-144
speciﬁc based music composition [38]. In addition, considering
music as a semi-chaotic natural process with recurrencies and
irregular cyclicities analyzed and visualized with the help of
recurrence plots [39] (similar to spoken pitch as we did in our
prosody visualization research [40]).
IV.
CONCLUSION
In this study, the problem of music style identiﬁcation is
sketched via a brief analysis of computational models and
technical solutions that may be helpful to musicologists in
their research on genesis and implications of musical com-
positions with an example of exploring the links between
Tchaikovsky’s “Children Album” and Schumann’s “Album
f¨ur die Jugend”. With the help of computer technology we
can discover more ﬁndings to support meaningful hypotheses
about the possible reasons explaining signiﬁcant discrepancies
between Tchaikovsky’s manuscript and the following editions
of “Children’s Album”.
Naturally, the outcomes from such compact joint musi-
cology and computer science studies can naturally address
the broader scope of research on music style understanding,
modeling, and recognition for the beneﬁt of both computer
technology and humanities so as to provide interesting use
9
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-887-7
ADVCOMP 2021 : The Fifteenth International Conference on Advanced Engineering Computing and Applications in Sciences

cases for AI applications as well as “a further strand of
evidence for systematic musicology to exploit” as nicely
formulated by Collins in [41].
ACKNOWLEDGEMENT
Many thanks to Natalia Bogach, John Blake, and Andrey
Kuznetsov for their helpful suggestions during our discussions
of this study. The work is supported by the University of Aizu
Research Funding.
REFERENCES
[1]
“International talk: Piano concert talk “Tchaikovsky” was held!” 2021,
retrieved: Aug, 2021. [Online]. Available: https://www.u-aizu.ac.jp/
osip/en/information/post-206.html
[2]
P. Tchaikovsky, Children’s Album. Op 39.
Yurgenson, 1878.
[3]
A. Lazanchina, “Fenomen detstva v fortepiannykh tsiklakh R. Shumana
i P. Tchaikovskogo (The phenomenon of childhood in piano cycles by
R. Schumann and P. Tchaikovsky),” Transactions of Russian Academy
of Science Samara Research Center, 2015, pp. 1224–1227, (In Russian).
[4]
I. Nekhaeva, “The modern measurement of Tchaikovsky (Deﬁnition
experience of the “modernity” concept on example of the “Children’s
Album” by PI Tchaikovsky),” Tomsk State University Journal of
Cultural Studies and Art History, vol. 30, 2018, pp. 146–147,
retrieved: Aug, 2021. [Online]. Available: http://case.asu.ru/ﬁles/form
312-31545.pdf#page=146
[5]
R. Schumann, 43 Piano Pieces for the Youth. Op 68 (Orig. Title in
German: 43 Clavierst¨ucke f¨ur die Jugend).
Schuberth and Co., 1848.
[6]
A. Kandinskiy-Rybnikov and M. Mesropova, “Vremena goda i Det-
skiy albom Tchaikovskogo: Tsyklichnost i problemy ispolneniya
(Tchaikovsky’s The Seasons and Children’s Album: Cyclicity and
performing problems),” in Tchaikovsky: Voprosy istorii, teorii i ispol-
nitelstva (Tchaikovsky. Questions on history, theory, and performing).
Moscow Conservatory, 1990, pp. 120–137, (In Russian).
[7]
——, “O ne opublikovannoy P.I. Tchaikovskim pervoy redaktsii “Det-
skogo alboma” (On an unpublished ﬁrst edition of the “Children’s
album” by P.I. Tchaikovsky),” in Voprosy muzykalnoy pedagogiki
(Issues of Musical Pedagogy).
Muzyka, 1997, pp. 138–161, (In
Russian).
[8]
E. Pyshkin and J. Blake, “A metaphoric bridge: Understanding software
engineering education through literature and ﬁne arts, society,” Society.
Communication. Education, vol. 11, no. 3, 2020, pp. 59–77.
[9]
J.-J. Nattiez, Music and discourse: Toward a semiology of music.
Princeton University Press, 1990.
[10]
R. B. Dannenberg, “Music representation issues, techniques, and sys-
tems,” Computer Music Journal, vol. 17, no. 3, 1993, pp. 20–30.
[11]
A. Kuznetsov and E. Pyshkin, “Searching for music: from melodies
in mind to the resources on the web,” in proceedings of the 13th
international conference on humans and computers, 2010, pp. 152–158.
[12]
A. Wang, “The Shazam music recognition service,” Communications
of the ACM, vol. 49, no. 8, 2006, pp. 44–48.
[13]
J. P. Magalhaes and W. B. de Haas, “Functional modelling of musical
harmony: an experience report,” ACM SIGPLAN Notices, vol. 46, no. 9,
2011, pp. 156–162.
[14]
D. Deutsch, “Octave generalization and tune recognition,” Perception
& Psychophysics, vol. 11, no. 6, 1972, pp. 411–412.
[15]
W. R. Thurlow and W. P. Erchul, “Judged similarity in pitch of octave
multiples,” Perception & Psychophysics, vol. 22, no. 2, 1977, pp. 177–
182.
[16]
D. Cope, “Experiments in musical intelligence (EMI): Non-linear
linguistic-based composition,” Journal of New Music Research, vol. 18,
no. 1-2, 1989, pp. 117–139.
[17]
——, Computer models of musical creativity.
Mit Press Cambridge,
2005.
[18]
P. da Silva, “David Cope and experiments in musical intelligence,” 2003.
[19]
N. Golzitsky, “SPEAC-analysis Python library,” 2021, retrieved:
Jun, 2021. [Online]. Available: https://github.com/GolzitskyNikolay/
SPEAC-analysis
[20]
A. Kuznetsov and E. Pyshkin, “Function-based and circuit-based sym-
bolic music representation, or back to Beethoven,” in Proceedings of
the 2012 Joint International Conference on Human-Centered Computer
Environments, 2012, pp. 171–177.
[21]
C. H. Smith and P. Georges, “Composer similarities through “The Clas-
sical Music Navigator”: Similarity inference from composer inﬂuences,”
Empirical Studies of the Arts, vol. 32, no. 2, 2014, pp. 205–229.
[22]
C. H. S. Smith, “Classical music navigator,” 2014, retrieved: Jun,
2021. [Online]. Available: http://dbtune.org/cmn/
[23]
B. R. Appel, Actually, taken directly from family life: Robert
Schumann’s Album f¨ur die Jugend.
Princeton University Press,
2014,
pp.
171–202.
[Online].
Available:
https://doi.org/10.1515/
9781400863860.171
[24]
“Tchaikovsky: Otkrytyi mir. Detskiy albom (Tchaikovsky: Open
world. Children’s Album,” 2015, retrieved: Aug, 2021 (In Russian).
[Online]. Available: https://www.culture.ru/catalog/tchaikovsky/ru/item/
archiv/detskiy-albom-24-legkih-pesy
[25]
P. Georges, “Western classical music development: a statistical analysis
of composers similarity, differentiation and evolution,” Scientometrics,
vol. 112, no. 1, 2017, pp. 21–53.
[26]
P. Georges and N. Nguyen, “Visualizing music similarity: clustering
and mapping 500 classical music composers,” Scientometrics, vol. 120,
no. 3, 2019, pp. 975–1003.
[27]
M. Thomas, M. Jothish, N. Thomas, S. G. Koolagudi, and Y. S. Murthy,
“Detection of similarity in music ﬁles using signal level analysis,” in
2016 IEEE Region 10 Conference (TENCON). IEEE, 2016, pp. 1650–
1654.
[28]
R. Nishikimi, E. Nakamura, M. Goto, K. Itoyama, and K. Yoshii,
“Bayesian singing transcription based on a hierarchical generative
model of keys, musical notes, and f0 trajectories,” IEEE/ACM Trans-
actions on Audio, Speech, and Language Processing, vol. 28, 2020, pp.
1678–1691.
[29]
S. Cunningham, V. Grout, and H. Bergen, “Mozart to Metallica: A
comparison of musical sequences and similarities.” in CAINE, 2005,
pp. 332–339.
[30]
B. Laskowska and M. Kamola, “Grouping compositions based on
similarity of music themes,” PloS one, vol. 15, no. 10, 2020, p.
e0240443.
[31]
W. Hatch, “A quick review of audio ﬁngerprinting,” 2003, retrieved:
Jun, 2021. [Online]. Available: http://www.music.mcgill.ca/wes/docs/
ﬁnger2.pdf
[32]
P. Cano, E. Batle, T. Kalker, and J. Haitsma, “A review of algorithms for
audio ﬁngerprinting,” in 2002 IEEE Workshop on Multimedia Signal
Processing.
IEEE, 2002, pp. 169–173.
[33]
“Spectrum
analyzer,”
retrieved:
Aug,
2021.
[Online].
Available:
https://academo.org/demos/spectrum-analyzer/
[34]
Y. M. Costa, L. S. Oliveira, and C. N. Silla Jr, “An evaluation of convo-
lutional neural networks for music classiﬁcation using spectrograms,”
Applied soft computing, vol. 52, 2017, pp. 28–38.
[35]
A. Van Den Oord, S. Dieleman, and B. Schrauwen, “Deep content-based
music recommendation,” in Neural Information Processing Systems
Conference (NIPS 2013), vol. 26.
Neural Information Processing
Systems Foundation (NIPS), 2013, pp. 1–9.
[36]
S. Dai, Z. Zhang, and G. G. Xia, “Music style transfer: A position
paper,” arXiv preprint arXiv:1803.06841, 2018.
[37]
J.-P. Briot, G. Hadjeres, and F.-D. Pachet, “Deep learning techniques
for music generation–a survey,” arXiv preprint arXiv:1709.01620, 2017.
[38]
C. Jin, Y. Tie, Y. Bai, X. Lv, and S. Liu, “A style-speciﬁc music
composition neural network,” Neural Processing Letters, vol. 52, 2020,
pp. 1893–1912.
[39]
J.-P. Eckmann, S. O. Kamphorst, and D. Ruelle, “Recurrence plots
of dynamical systems,” World Scientiﬁc Series on Nonlinear Science
Series A, vol. 16, 1995, pp. 441–446.
[40]
N. Bogach et al., “Speech processing for language learning: A practical
approach to computer-assisted pronunciation teaching,” Electronics,
vol. 10, no. 3, 2021, p. 235.
[41]
N. Collins, “Computational analysis of musical inﬂuence: A musico-
logical case study using MIR tools.” in ISMIR, 2010, pp. 177–182.
10
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-887-7
ADVCOMP 2021 : The Fifteenth International Conference on Advanced Engineering Computing and Applications in Sciences

