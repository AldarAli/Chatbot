OOPS ! and Competency Questions for Evaluating the Intelligent Business Process 
Management Ontology 
Sarra MEJRI  
Laboratory RIADI-GDL, ENSI, Manouba 2010, University 
of Manouba, Tunisia 
Higher Institute of Computer Science and Communication 
Techniques of Hammam Sousse, University of Sousse, 
Tunisia 
 e-mail: sarra.mejri.fsm@gmail.com 
Sonia  AYACHI GHANNOUCHIN 
Laboratory RIADI-GDL, ENSI, Manouba 2010, University 
of Manouba, Tunisia 
Higher Institute of Management of Sousse, University of 
Sousse, Tunisia 
e-mail:  sonia.ayachi.ghannouchi@gmail.com
 
 
Abstract— The Intelligent Business Process Management 
Ontology (IBPMO) models the most important concepts in 
the context of both Business Process Management (BPM) 
and Industry 4.0. It ensures the selection of the most suitable 
technologies 4.0 for Business Processes (BPs). Ontologies 
have great promise for improving BPM and realizing the 
Industry 4.0 vision. Ontology Development 101 is the 
method of ontology modeling. A framework would be 
helpful to allow the involved actors benefiting from the built 
ontology and using it for selecting appropriate technologies 
4.0 to be integrated in BPs. In this paper, an evaluation 
framework is proposed to evaluate our IBPM ontology for 
which existing evaluation methods have been combined into 
a single framework, dividing the methods used into two 
phases: verification and validation. The verification of the 
ontology is concerned with validating whether an ontology 
was correctly built. It evaluates the structure, functionality 
and representation of the ontology. It specifically focuses on 
the validation activity using OntOlogy Pitfall Scanner! 
(OOPS !) tools. Different metrics and common pitfalls are 
used to detect errors. The OOPS! tool adopts specific metrics 
for detecting most anomalies found in the ontology and 
suggests improvements. Ontology validation is achieved by 
using Competency Questions (CQs) and expert interviews. 
This evaluation, which relied on a technology-based 
approach, using OOPS! tool, and a prototype development, 
proved the validity of our IBPMO ontology. 
Keywords—ontology; Industry 4.0; Intelligent BPM; 
ontology evaluation; Competency Questions; OOPS!. 
I. INTRODUCTION 
We have proposed IBPMO, in a previous work [1], an 
ontology developed for intelligent BPM, divided into two 
modules: BPM and Industry 4.0. The use of IBPMO 
ensures the selection of the most suitable technologies 4.0 
for BPs. 
This paper aims to assess the quality and the content of 
the IBPM Ontology (IBPMO) to ensure that it is well 
built, structured and contains all important concepts and 
relationships for sufficient reasoning.  
Ontologies consist in a formal conceptualization of the 
knowledge representation and provide the definitions of 
the concepts and relations capturing the knowledge of a 
domain in an interoperable way [2]. In recent years, 
ontology tools have been widely used for representation 
and reasoning in IBPM, which consists of adding smart 
technologies and business intelligence to BPM[2] [3].  
Semantic Web technologies, especially ontologies, can 
be connected with logical inferences to enable a common 
perception of a particular specific domain. Thus, they 
could facilitate alignment and integration of information 
entities for Industry 4.0 processes, connecting people, 
organization of work, and application systems [4]. 
Ontologies are promising means to improve BPM and to 
realize the Industry 4.0 vision [5]. Besides, the evaluation 
of the modeling is an important step in the process of 
ontology development. This step ensures the adequacy of 
the ontology and reduces maintenance costs. In fact, 
ontology evaluation is needed to decide on the quality and 
content of the ontology by judging it against a reference 
framework and identifying what the ontology defines 
correctly, incorrectly or not at all. It is essential for the 
adoption and improvement of the ontology.  
Ontology evaluation is a key ontology engineering 
activity that can be performed following a variety of 
approaches and using various tools [6]. It consists of two 
parts : ontology validation process and verification activity 
[7]. Ontology validation process checks the correctness of 
the built ontology and especially investigates the structure, 
functionality and representation of the ontology with the 
help of different metrics and quality criteria. Whereas, 
ontology verification activity checks if the right ontology 
is built given the suggested application of the ontology [8]. 
In ontology development 101 (OD 101) method [9], 
evaluation involves four types of references, which are 
CQs, application-based, modeling guidelines and expert 
domain. The first, third and fourth types of references are 
used during ontology modeling, while the second is used 
with the application. The Ontology Development 101 (OD 
101) is used to model and evaluate ontologies effortlessly 
and with more flexibility. To the best of our knowledge, 
the existing research works for example [10] and [11] 
concentrate on the consideration of OD 101 for evaluating 
their ontologies. Thereby, in this paper, we considered the 
ontology evaluation during ontology modeling, which are 
CQs, application-based evaluation, modeling guidelines.  
CQs are used as reference for verification activity. CQs 
play a crucial role in the ontology development lifecycle, 
as they represent the ontology requirements [12].  
41
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

OOPS ! is used as a tool for validation activity. 
OOPS ! represents a tool for diagnosing (semi-) 
automatically in OWL ontologies and targeted at 
newcomers 
and 
domain 
experts 
unfamiliar 
with 
description logics and ontology implementation languages. 
This tool operates independently of any ontology 
development platform and is available online [13].  
The contribution of this work is to propose an 
evaluation framework to evaluate the IBPMO; and thereby 
refine the IBPMO. The IBPMO has been evaluated using 
CQs. Then, IBPMO has been verified for its structure 
using the OOPS ! tool, which was chosen due to its ability 
to perform both ontology diagnosis and repair activity. The 
ontology is refined based on the results of this tool. The 
IBPMO has been validated semantically using various 
CQs to determine its applicability. The IBPMO has then 
been put to the said application and the task based 
evaluation has been carried out. It is found that IBPMO is 
able to serve its intended purpose after tuning it based on 
the results of evaluation. After evaluating the IBPMO, we 
could ensure that the procedure of selecting the most 
suitable technologies for BPs within the IBPMO is 
successfully carried out.   
The goal in this paper is mainly to adopt an evaluation 
process in order to improve the IBPMO. For this purpose, 
it is worth noting that considering CQs, the OOPS ! tool 
and the application-based evaluation can help us to 
successfully evaluate our IBPMO.  
The rest of this paper is structured as follows: Section 
2 presents related work on ontologies evaluation. 
Regarding the third section, it deals with our research 
methodology. 
Section 
4 
briefly 
explains 
the 
implementation of the evaluation process in IBPMO. 
Section 5 concludes the findings. 
II. RELATED WORK ON ONTOLOGIES EVALUATION 
Many researchers have worked on ontology evaluation. 
Jain et al. [14] proposed an evaluation framework to 
evaluate the Emergency Situation Ontology (ESO), in 
which existing evaluation methods have been combined 
into a single framework, dividing the methods used into 
two phases: verification and validation. Richard, et al. [15] 
proposed the LOVMI(Ontologies Validated by Interactive 
Method) method in order to validate ontologies and in 
particular their developed ontology ONTOPSYCHIA, 
which is an ontology for psychiatry in three modules: 
social and environmental factors of mental disorders, and 
treatments. LOVMI validation is performed in six steps: 
validation (1) of consistency, (2) of other structural 
aspects, (3) of labels, (4) of choices of label and (5) of 
semantic with experts and (6) of semantic in an 
application. On the other hand, Kalita, et al. [16] presented 
an evaluation of the developed ontology on traditional 
dances (OTD), which divides the evaluation methods into 
two critical steps : First, the syntactic correctness and 
internal consistency of the ontology were checked via the 
HermiT reasoner and the OOPS! tool, and, in the second 
step, the ontology has undergone a competency check via 
the CQs scenarios. In their work, Chansanam, et al. [10] 
presented an evaluation of The COviD-19 Ontology for 
Cases and Patient information (CODO) focused explicitly 
on the validation operation using OOPS! tools. Moreover, 
Yusof, et al. [11] discussed the manual approach, i.e., 
modeling guidelines and automatic approach, i.e., OOPS! 
for validating the Malaysian food composition ontology 
(MyFCO). In addition, Bezerra, et al. [12] proposed a 
mechanism to support evaluating whether the ontology 
follows their correspondent CQs.  Pizzuti, et al. [17] 
validated and interrogated the MEat Supply Chain 
Ontology (MESCO), that is an ontology developed for 
supporting the management of meat traceability along the 
whole supply chain, through the formulation of several 
queries expressed in Description Logic (DL), executed 
using the Pellet reasoner, to deal with different scenarios 
and problems of traceability.  
We can conclude that to the best of our knowledge rare 
are the approaches that have used the different types of 
references of the OD 101 during ontology evaluation. In 
our research work, we focus on CQs, application-based 
evaluation, modeling guidelines. 
III. PRESENTATION OF OUR IBPMO ONTOLOGY 
Semantic Web technologies, especially ontologies, are 
promising means to improve BPM and to realize the 
Industry 4.0 vision. In this scope, we presented the IBPM 
ontology that we have created with Protégé 5.5.0. Every 
IBPM ontology element is inserted as a class; the full 
hierarchy is shown in Figure 1 (75 classes). The IBPM 
ontology is an important part of our BPIGuide approach, 
which ensures the selection of the most suitable 
technologies 4.0 for BPs.   
Regarding the first step, the scope of our ontology is to 
develop an ontology for IBPM. Basically, a number of 
methodologies have been used for developing ontologies, 
such as the methodology defined in [18], [19], [20] and 
[21], [22], [23]. In our research work, we have selected 
the methodology Ontology Development 101 defined by 
Noy and McGuinness’s in [21] because we have exploited 
an existing ontology. 
Concerning the second step, we have selected the 
existing BPM ontology presented in (von Rosing, Laurier 
and Polovina, 2015a), which is an empiric ontology, 
meaning that its roots lie in practice, as it was developed 
by practitioners documenting their practical knowledge of 
the field rather than having originated from theory and 
academics specialized in a restricted area of business. The 
selected BPM Ontology offers a set of principles, views, 
artefacts, and templates that have detailed metaobject 
relations and rules that apply to them, such as how and 
where can the process objects be related (and where not) 
(von Rosing, Laurier and Polovina, 2015a). 
In order to consider the Industry 4.0 main concepts, we 
have been inspired from [24]. New classes were added to 
present the industry 4.0 concepts such as Sensor, Location, 
Machine, Workstation, Line, Technology4.0. The Machine 
has been defined with the device that performs a task by 
itself or by human intervention. The Workstation refers to 
42
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

small integrated physical groupings of machines. The Cell 
is a set of combined workstations for a particular complex 
task; and the Line is a group of cells. Consequently, new 
relations were added. A sensor is located in a location. A 
process happens in a location. A workstation contains a 
Machine. A machine can be an assembling machine, a 
testing machine and a processing machine. A business 
process adopts a technology 4.0.  
3D printing, Augmented reality/simulation, Big data, 
Biomedical/digital sensor, Blockchain, Cloud computing, 
Collaborative robots, IoT, Machine/deep learning, Remote 
control or monitoring and SOA are introduced as sub-
classes of Technology 4.0. A business process can be 
linked to a business resource through the transforms 
property. Besides, the hasSensor property is used to affirm 
that sensors are attached to a business resource. In 
addition, the happensIn property is used to stand for the 
location where a business process takes place. Moreover, 
the measuredBy property is used to associate a business 
process to the process measurement. The business process 
can be linked to the technology 4.0 through the adopts 
property. 
IV. RESEARCH METHODOLOGY 
This section briefly explains the activities that were 
carried out for ontology evaluation process. The evaluation 
framework is proposed to evaluate our IBPM ontology for 
which existing evaluation methods have been combined 
into a single framework, dividing the methods used into 
two phases: verification and validation [25].  
The verification of the ontology is concerned with 
building an ontology correctly. It evaluates the structure, 
functionality and representation of the ontology. It 
specifically focused on the validation activity using 
OOPS ! tools. Different metrics and common pitfalls are 
used to detect errors. The validation of the ontology 
ensures that the right ontology for the given application is 
built. This is achieved by CQs and expert interviews. In 
particular, we focus (1) on verifying whether the 
developed IBPMO is correct according to three evaluation 
metrics [26], namely completeness, conciseness and 
consistency, and (2) on checking how effective the 
ontology is in the context of different applications. In this 
regard, the IBPMO is evaluated by using three approaches: 
CQs, technology-based, and application-based evaluations. 
Figure 2 shows the evaluation process of the IBPMO. 
 
 
Figure 2. The proposed Evaluation Process 
 
 
 
 
 
Figure 1. Class hierarchy of the IBPMO 
V. EVALUATION OF OUR IBPMO 
In this section, we represent the evaluation of our 
IBPMO, which focuses on the CQs, the technology-based 
evaluation and the application-based evaluation. 
A. Competency Questions evaluation  
For the present evaluation, CQs as a qualitative 
measure is the most effective and reliable way to check if 
all important information are included in the ontology 
[27]. The CQs pertain to various aspects, including class 
hierarchy, individuals, disjoint classes, intersections and 
unions of classes, equivalent classes, universal and 
existential quantification, as well as restrictions related to 
has-value and cardinality [12]. Thus, this evaluation 
focuses on reformulating CQs as queries to retrieve data 
from the ontology and to verify whether the CQs are 
answered or not. In this sense, queries are written in 
Description Logic (DL) and SPARQL language, which is 
43
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

a semantic query language used for describing and even 
worse checking the fulfillment of OWL CQs [12].  
1) Consistency check via CQ-based DL: For syntactic 
correctness and consistency check of our IBPMO, we rely 
on “consistency checkers”. For this task, we have used the 
Hermi reasoner, implemented in Protege as an external 
plug-in. The goal is to verify the ability of the ontology 
and check its consistency. The reasoner is known as a 
classifier and used for consistency checking as well as to 
compute the inferred class hierarchy (Natschläger, 2011). 
HermiT 1.4.3 is an OWL 2 reasoner compatible with Java. 
HermiT 1.4.3 provides functionalities to verify the 
validation, check consistency of the ontology and answer a 
subset of several queries expressed in DL. The evaluation 
process has been executed considering the monitoring of 
chronic disease BP, the food selection and guidance for 
diabetic and hypertensive patients BP and the monitoring 
of COVID 19 patients BP. We have considered these 
different BPs to elaborate our validation, but only the 
individuals of COVID BP will be detailed next. The 
monitoring of chronic disease BP concerns the continuous 
monitoring of patients with chronic disease to effectively 
manage disease. The food selection and guidance for 
diabetic and hypertensive patients BP concerns the 
Classification of Food according to patients’ health. The 
monitoring of COVID 19 patients BP concerns the 
monitoring of COVID-19 patients or persons under 
investigation in the COVID-19 crisis unit at CHU Farhat 
Hached Sousse. The BP and the elaborated ontology were 
elaborated using various surveys and investigation. It 
consists of BPCOVID; Covid19CrisisCell; Physician; 
HealingTime; 
Home; 
IoTTech; 
Oximeter; 
Patient; 
QualityOfService; 
SensorOxygenSaturation; 
SensorTemprature; Thermometer; beurer HealthManager; 
MeasuringSpO2; 
RecoveringPatients; 
RegainingAnAcceptableTemperature; 
Treatment_Cost; 
WorkDoneByPhysician; 
CheckHealthStatus; 
CovidTreatmentProcesses; 
CrisisComityPerformanceIndicator; 
InfectiousDiseaseDepartment 
which 
are 
defined 
to 
represent different individuals. SensorTemperature and 
SensorOxygenSaturation represents the individuals of the 
same class Sensor. Thermometer and Oximeter are 
individuals of the same class ProcessingMachine. Patient 
and Physician are 
instances 
of 
the 
same 
class 
BusinessRole. BPCOVID is an instance of the class 
HumanOperation. HomeMonitoring is an individual of the 
class Sit-Monitoring. Covid19CrisisCell is an instance of 
the class ProcessOwner. We have also defined the 
individuals for both the monitoring of chronic disease BP 
and the food selection and guidance for diabetic and 
hypertensive patients BP. The query formulated for the 
identification of the BPs that have adopted the IoT 
Technology is showed in Fig. 2. It was applied for all the 
individuals of the three considered BPs. 
Two examples of CQs, which cover the IBPMO, are 
provided along with their corresponding DL queries and 
results. The fact that the obtained results are conform to 
the expected results contributes to proving the validity of 
our ontology. 
 
CQ1 : What are the BPs that have adopted the IoT 
Technology ? The results of this DL query, that 
corresponds to this CQ1, show that it is possible to 
easily access to most important information 
related to the monitoring of chronic disease BP, 
the food selection and guidance for diabetic and 
hypertensive patients BP and the monitoring of 
COVID 19 patients BP in a short time, as shown 
in Figure 3. 
 
 
Figure 3. Query for the identification of the BPs that have 
adopted the IoT Technology 
 
 
CQ2: What are the BPs that have adopted the Big 
data Technology ? The result of this DL query, 
that corresponds to this CQ2, shows the instance 
of the BusinessProcess concept that have adopted 
the Big data Technology, as shown in Figure 4. 
 
 
Figure 4. Query for the identification of the BPs that have 
adopted the Big data Technology 
The phase of the internal consistence check ensures 
that our IBPMO does not contain any contradictory facts. 
In fact, The internal consistency check in ontology is 
performed by automated reasoners, which use formal 
language representation and axiomatic definitions to detect 
contradictions within the ontology [28]. 
Besides by this phase, we have checked that the model 
is a correct rendering of the idea we wanted to express.  
44
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

2) CQ-based SPARQL: In this paper, each question is 
translated into SPARQL queries and implemented in 
Protégé using the SPARQL QUERY plugin.  
Four examples of CQs, which cover the IBPMO, are 
provided along with their corresponding SPARQL queries 
and results.  
 
CQ1: What are the Business Processes contained 
in the ontology? The SPARQL query, that 
corresponds to this CQ1 to retrieve all instances 
of the BusinessProcess concept, is presented in 
Fig. 4. The result of this query, as illustrated in 
the Figure 5, contains the BPs modeled in the 
IBPM Ontology.   
 
Figure 5. SPARQL query results for CQ1 
 
CQ2: What are the concepts represented in the 
ontology that model a Business Process? Figure 6 
displays the formal representation of this CQ 
using SPARQL query. The query asks for the 
subclasses 
of 
the 
class 
BusinessProcess. 
Consequently, the result of this query as shown in 
the Figure 6 contains all instances of the 
BusinessProcess. 
 
Figure 6. SPARQL query results for CQ2 
 
CQ3: What are the concepts modeled in the 
ontology that can be used to be applied to 
Business Processes? Fig. 6 presents the SPARQL 
query formalizing CQ3 to retrieve the subclasses 
of the class BusinessProcess that are linked to the 
BusinessResource/Actor class via the object 
property appliesTo. The result of this query, as 
shown in the Figure 7, contains the business 
resource/actor for each business process modeled 
in the IBPMO.   
 
Figure 7. SPARQL query results for CQ3 
 
CQ4 : What are the concepts modeled in the 
ontology that can be used to be applied to 
Business Processes in a specific (particuler) 
domain? Figure 8 presents the SPARQL query 
formalizing CQ3 to retrieve the subclasses of the 
class BusinessProcess that are linked to the 
BusinessResource/Actor class via the object 
property appliesTo. The result of this query, as 
shown in the Figure 8, contains the business 
resource/actor and the domain for each business 
process modeled in the IBPMO.   
By providing a set of CQs for the validation purpose, 
the completeness of the ontology is evaluated. Each query 
is run on the IBPMO to test if all requirements can be met 
and the correct answers can be inferred. For those queries 
that fail to run, the missing concepts or relations are added 
in the IBPMO. Nonetheless, one of the main problems that 
hamper the proper use of CQs lies on the completeness of 
the ontology that can never be proved and constant 
enhancement of the IBPMO needed. 
 
 
Figure 8. SPARQL query results for CQ4 
B. Technology-based evaluation 
The present evaluation is concerned with the structural 
characteristics of an ontology. It investigates the syntax, 
consistency and formal semantics and thereby aims to 
ensure the correctness and usability of the ontology. 
Different tools have been developed to support the 
technology-based evaluation. In this study, our IBPMO is 
evaluated through the OOPS ! tool, which is a web-based 
evaluation tool used for the detection of common pitfalls 
or anomalies in ontologies according to a pitfall catalogue 
currently containing 41 errors. This tool helps developers 
to improve ontology quality by automatically detecting 
potential errors [13].  
45
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

Figure 9. The OOPS!  Validation results. 
After executing the online tool reliably OOPS ! with 
the IBPMO, a summary of the pitfalls encountered is 
generated as shown in Figure 9. The diagnosis results 
obtained from OOPS! were manually revised. In fact, the 
OOPS! tool detects most anomalies found in the ontology 
and suggests improvements. Nonetheless the modifications 
of the ontology needs to be done manually. OOPS ! 
classified the results for each pitfall into three levels: 
critical, important, and minor levels. Priority was given for 
the critical level first. The minor level was not mandatory 
since it was not counted as a problem; however, by doing 
so, it will improve the IBPMO performance. Fig.8  shows 
the validation results for our IBPMO. It achieved two 
important and three minor pitfalls. It attains zero critical 
pitfalls. The three minor pitfalls resulted from missing 
annotations (P08), Inverse relationships not explicitly 
declared (P13) and using different naming conventions in 
the ontology (P22). The two important pitfalls in the 
opposite are caused by missing domain or range in 
properties (P11) and the absence of a declared license 
(P41). The pitfalls detected by OOPS ! can also be 
classified 
by 
the 
following 
evaluation 
criteria : 
consistency, completeness, and conciseness. The obtained 
results show that no consistency nor conciseness pitfalls 
are detected. Nevertheless, other pitfalls are detected (P08, 
P22,P41) and two of them (P11, P13) are related to the 
ontology completeness. Table 1 presents the five pitfalls 
encountered.  
TABLE I.  
IBPMO PITFALLS DETECTED BY OOPS 
Criteria 
Pitfall 
Description 
Importance 
level 
Cases 
Consistency 
No 
detected 
pitfalls 
that 
correspond to 
consistency 
_ 
0 
Completeness 
P11 : 
Missing 
domain 
or 
range 
in 
Important 
 
 
 
 
18  
 
 
 
properties 
P13 : 
Inverse 
relationships 
not 
explicitly 
declared 
 
 
     Minor 
 
  
11 
Conciseness 
No 
detected 
pitfalls 
that 
correspond to 
conciseness 
_ 
0 
 
 
Other Pitfalls 
P08 : 
Missing 
annotations  
P22 : 
Using 
different 
naming 
conventions in 
the ontology 
P41 : 
No 
license 
declared 
 
 
Minor 
 
 
 
 
 
Minor 
 
 
 
 
 
 
 
 
 
Important 
 
 
45 
 
 
 
 
 
The 
pitfall 
applies to the 
ontology 
in 
general 
 
 
 
 
 
 
The 
pitfall 
applies to the 
ontology 
in 
general 
 
 
Figure 10 shows an excerpt of the first important pitfall 
(P11: Missing domain or range in properties). It shows a 
missing  domain and range for some properties. But this 
pitfall was reported for the properties which were already 
mentioned as inverse properties in the IBPMO. Eighteen 
cases were detected for this pitfall as they represented 18 
object properties without domain and range. The OD101 
provided the guidelines regarding this property’s facet. 
The effect of range and domain constraints as axioms is 
the most common problem in OWL [29] [30]. In IBPMO, 
the domain and range of properties are not assigned to 
avoid the above problems. Thus, no ontology repair action 
was carried out for this pitfall. 
 
46
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

 
Figure 10.  An excerpt from the first important pitfall. 
 
Figure 11 shows the second and the last important 
pitfall in IBPMO (P41: No license declared ). It reports 
about uses of no license agreement in the IBPMO. The 
pitfall concerns the ontology metadata aspect, which does 
not have any guidelines in OD 101. The repair 
recommendation by OOPS! was to include a statement 
containing the license information using any of the 
following 
properties: 
dc:rights, 
dcterms:rights, 
dcterms:license, cc:license or xhv:license. 
 
 
Figure 11. Second important pitfall. 
 
In Protégé, the metadata annotations are under the 
ontology header view. Figure 12 shows the interface of 
metadata annotations where the license of the IBPMO is 
declared. The predicate for the license declaration of the 
IBPMO was taken from the dcterms:license and assigned 
to the CC-BY license [31], which is the most popular open 
Creative Commons Attribution License.  
 
 
Figure 12. License declaration. 
 
The IBPMO has three minor pitfalls. Figure 13 shows 
the first minor pitfall (P08: Missing annotations). The 
description of this pitfall was in creating an ontology 
element, human readable annotations have failed to be 
attached to it. The label annotation properties (rdfs:label) 
and the description annotation properties (rdfs:comment) 
were considered to define annotations of the IBPMO 
elements. These are the two most commonly used 
annotation properties, besides owl:versionInfo [32]. This 
pitfall will be repaired for further reuse. 
 
Figure 13. First minor pitfall. 
 
The second minor pitfall is P13 : Inverse relationships 
not explicitly declared. It suggested some object properties 
which can be declared as inverse. The description of this 
pitfall was when any relationship (except for those that 
were 
defined 
as 
symmetric 
properties 
using 
owl:SymmetricProperty) 
did 
not 
have 
an 
inverse 
relationship (owl:inverseOf) defined within the ontology. 
OOPS! listed all of the object properties in IBPMO, which 
did not have the inverse relationship (see Figure 14). OD 
101 
provided 
the 
guidelines 
regarding 
inverse 
relationships. Poveda-Villalón et al. [33] stated that the 
specification of the inverse properties is needed for 
completeness.  
 
 
Figure 14. Second minor pitfall. 
 
The final minor pitfall is P22: Using different naming 
conventions in the ontology (see Figure 15). It detected 
uses of different naming conventions in the IBPMO. This 
was reported because for some long class names the 
symbol “-” (dash) was used, but for short class names, it 
was not used. A modification was not necessary. OD 101 
provided guidelines on naming conventions. It emphasized 
consistency with the chosen naming conventions. The 
benefits from the consistency help to avoid modeling 
mistakes, improve readability, and ease the understanding 
of the ontology.  
 
 
Figure 15. Third minor pitfall. 
 
After correcting the observed errors, the pitfall scanner 
is run again to ensure all errors are corrected and no new 
ones are detected. OOPS! plays a significant role in 
ensuring the ontology is free from the common pitfall by 
47
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

double checking the modeling guidelines provided by the 
Ontology Development 101. For example, it supports the 
latest common modeling errors that are not listed in the 
Ontology Development 101, such as the annotation issue. 
The 
main 
advantage 
of 
OOPS! 
is 
the 
repair 
recommendation made by it. It shows how the ontology 
element can be repaired to improve the ontology technical 
quality. In the IBPMO, the evaluation results from OOPS! 
have improved the inferencing, understanding, clarity and 
metadata aspects. Nevertheless, OOPS! has a limitation. It 
still needs to be revised manually in some cases of the 
pitfall. 
C. Application-based evaluation 
The last step of the evaluation process consists of using 
the ontology in a dedicated application. In the present 
evaluation approach, the IBPMO is evaluated by providing 
an application-based approach to assess the ability of the 
IBPMO to serve as a knowledge base for a computer 
system. The effectiveness of the IBPMO has been assessed 
by putting it to the real application. It was designed to 
work for as a knowledge base. The IBPMO is validated by 
providing the following applications. 
 
IBPMO database and interface: A standalone 
application, which enables the visualization of 
knowledge modeled in the IBPMO, was 
developed. The interfaces provided by the 
application are designed to configure user needs 
on selection criteria. In order to provide an easy 
means to configure each criterion, three User 
Interface (UI) components can be used, which 
allow modifying a criteria’s configuration. The 
UI components concern the performance criteria, 
the BP languages and the application fields. Such 
interfaces display the selection criteria. Figure 
16-18 
show 
interface 
examples 
of 
the 
application : interface for performance criteria 
(Figure 16), interface for BP languages (Figure 
17) and interface for application fields (Figure 
18). 
 
BPIGuide tool: The IBPMO is used in 
conjunction with the BPIGuide tool decribed in 
previous works. The BPIGuide enables the 
decision rules represented in the IBPMO to be 
automatically infered. Since, using the ontology-
based engine, the result of the execution of these 
rules are the rank of the recommended 
technologies 4.0 which will be presented to users 
and could be used to redesign and implement 
optimized BPs 4.0. Besides, our validated 
ontology was used in the context of patient care 
in the healthcare field. We applied the different 
rules that we extracted from IBPMO in the 
surgical monitoring business process. 
 
Figure 16. Interface for performance criteria 
 
 
Figure 17. Interface for BP languages 
 
 
Figure 18. Interface for application fields 
 
VI. DISCUSSION 
The evaluation of the IBPMO indicates that the 
ontology is well-designed and suitable for its application. 
Only minor changes and adaptations regarding the lexical 
and structural layer are made. The conducted evaluation 
revealed that the developed IBPMO is : correct since it 
meets the completeness, conciseness, and consistency 
standards, and effectiveness since it can be used concretely 
in a variety of applications. Nevertheless, evaluating the 
IBPMO demonstrated that most probable no automatic 
method will ever be enough to perform a complete 
ontology evaluation. The evaluator has to decide on the 
criteria relevant for the evaluation, has to evolve the CQs 
and has to make decisions based on the evaluation results 
over each metric. But as good science should exclude 
subjectivity, it is advisable that more than one person 
performs the evaluation. Experts should be included for a 
satisfactory result in the evaluation. 
VII. CONCLUSION AND FUTURE WORK 
Ontology evaluation is a main task in the process of 
ontology development that takes a lot of effort and 
thought-process as each ontology needs an individual 
approach for evaluation adapted to the intended 
48
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

application of the ontology. The ontology evaluated in this 
study, IBPMO, has been developed to select the most 
suitable technologies 4.0 for BPs. We mainly focused on 
the end-to-end evaluation methodology. First, the IBPMO 
is evaluated against CQs. This first phase focuses on 
reformulating CQs as queries, which are expressed in DL 
and SPARQL language to retrieve data from the ontology 
and to verify whether the CQs are answered or not. During 
the second phase, a technology-based evaluation approach 
is addressed to specify quality criteria in order to ensure 
that the IBPMO is rid from pitfalls. At last, the ontology is 
evaluated using an application-based approach to assess 
the effectiveness of the IBPMO. For future work, the 
IBPMO will be upgraded with linked open data to enable 
domain knowledge sharing and reuse. 
REFERENCES 
[1] S. Mejri and S. Ghannouchi. "Towards a New Approach 
for Intelligent BPM Based on Technologies 4.0". New 
Trends in Intelligent Software Methodologies, Tools and 
Techniques: 
Proceedings of 
the 
20th 
International 
Conference on New Trends in Intelligent Software 
Methodologies, Tools and Techniques (SoMeT_21). vol. 
337, 
pp. 
313-326, 
September 
2021. 
https://doi.org/10.3233/FAIA210030. 
[2] V. R. Sampath Kumar, et al. “Ontologies for Industry 4.0”. 
The Knowledge Engineering Review. vol. 34, pp. e1-e17, 
November 
2019. 
https://doi.org/10.1017/S0269888919000109. 
[3]  
S. Jaskó, A. Skrop, T. Holczinger, T. Chován, and J. 
Abonyi. 
“Development 
of 
manufacturing 
execution 
systems in accordance with Industry 4.0 requirements: A 
review of standard-and ontology-based methodologies and 
tools”. Computers in Industry. Vol. 123, pp. 1-18, 
December 2020. 
[4] C. Kaar, J. Frysak, C. Stary, U. Kannengiesser, and H. 
Müller. “Resilient Ontology Support Facilitating Multi-
Perspective 
Process 
Integration 
in 
Industry 
4.0”. 
Proceedings of the 10th International Conference on 
Subject-Oriented Business Process Management. pp. 1–10, 
April 2018. 
[5] A. Annane, N. Aussenac-Gilles, and M. Kamel. “BBO: 
BPMN 2.0 Based Ontology for Business Process 
Representation.” 20th European Conference on Knowledge 
Management (ECKM 2019). pp. 49–59, September 2019. 
[6] M. Poveda-Villalón, MC. Suárez-Figueroa, and A. Gómez-
Pérez. “Validating ontologies with oops!” Knowledge 
Engineering 
and 
Knowledge 
Management: 
18th 
International Conference, EKAW 2012. Galway City, 
Ireland, pp. 267–81, October 2012. 
[7] A. A. Alsanad, A. Chikh, and A. Mirza. “A Domain 
Ontology for Software Requirements Change Management 
in Global Software Development Environment”. IEEE 
Access. 
vol. 
7, 
pp. 
49352-49361, 
January 
2019. 
https://ieeexplore.ieee.org/abstract/document/8684236/ 
(accessed January 30, 2023). 
[8] A. Abdelghany, N. Darwish, and H. Hefni. “An Agile 
Methodology for Ontology Development”. IJIES 2019. 
Vol. 
12, 
pp. 
170–181, 
April 
2019. 
https://doi.org/10.22266/ijies2019.0430.17. 
[9] N. Noy and DL. McGuinness. “Ontology development 
101”. Knowledge Systems Laboratory, Stanford University 
2001. vol. 2001, pp. 1-18, January 2001.  
[10] W. Chansanam, K. Suttipapa, and A.R. Ahmad. "COVID-
19 
ontology 
evaluation". 
International 
Journal 
of 
Management. vol. 11, pp. 47-57, October 2020. 
[11] N. M. Yusof and S. A. M. Noah. "Malaysian food 
composition ontology evaluation". International Journal of 
Machine Learning and Computing. vol. 9, pp. 700–705, 
October 2019. 
[12] C. Bezerra, F. Freitas, F. Santana da Silva. “Evaluating 
Ontologies with Competency Questions”. pp. 284-285, 
November 2013. https://doi.org/10.1109/WI-IAT.2013.199. 
[13] M. Poveda-Villalón, A. Gómez-Pérez, and MC. Suárez-
Figueroa. “Oops!(ontology pitfall scanner!): An on-line 
tool for ontology evaluation”. International Journal on 
Semantic Web and Information Systems (IJSWIS). vol. 10, 
pp. 7–34, April 2014. 
[14] S. Jain, V. Meyer. “Evaluation and refinement of 
emergency situation ontology”. Int J Inform Educ Technol. 
vol. 8, pp. 713–719, July 2018.  
[15] M. Richard, X. Aimé, M.C. Jaulent, M.O. Krebs, and J. 
Charlet. “From Patient Discharge Summaries to an 
Ontology for Psychiatry”. MEDINFO 2017: Precision 
Healthcare through Informatics, IOS Press. pp. 930–934, 
June 2017. 
[16] D. Kalita, and D. Deka. “Ontology for preserving the 
knowledge base of traditional dances (OTD)”. The 
Electronic Library. vol. 38, pp. 785–803, October 2020. 
[17] T. Pizzuti, G. Mirabelli, Grasso G, and G. Paldino. 
“MESCO (MEat Supply Chain Ontology): An ontology for 
supporting traceability in the meat supply chain”. Food 
Control. vol. 72, pp. 123–133, Février 2017. 
[18] M. Uschold and M. King. “Towards a methodology for 
building ontologies”. Citeseer. pp. 1-13, July 1995. 
[19] M. Gruninger. “Methodology for the design and evaluation 
of ontologies”. Proc. IJCAI’95, Workshop on Basic 
Ontological Issues in Knowledge Sharing. April 1995.  
[20] M. Fernández-López, A. Gómez-Pérez, and N. Juristo. 
“Methontology: from ontological art towards ontological 
engineering”. pp. 33-40, March 1997. 
[21] N. F. Noy, and D. L. McGuinness. “Ontology development 
101: A guide to creating your first ontology”. Stanford 
knowledge systems laboratory technical report KSL-01-05. 
pp. 1-25, March 2001.  
[22] H. S. Pinto, S. Staab, and C. Tempich. "DILIGENT: 
Towards a fine-grained methodology for DIstributed, 
Loosely-controlled 
and 
evolvInG 
Engineering 
of 
oNTologies”. ECAI. vol. 16, pp. 1-393, January 2004. 
[23] M. C. Suárez-Figueroa, A. Gómez-Pérez, and M. 
Fernández-López. “The NeOn methodology for ontology 
engineering. Ontology engineering in a networked world”. 
pp. 9–34, Springer; December 2011.  
[24] F. Giustozzi, J. Saunier, C. Zanni-Merk. “Context modeling 
for industry 4.0: An ontology-based proposal”. Procedia 
Computer Science. vol. 126, pp. 675–684, January 2018. 
[25] H. Hlomani and D. Stacey. “Approaches, methods, metrics, 
measures, and subjectivity in ontology evaluation: A 
survey”. pp. 1-11, August 2014. 
49
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

[26] Z. C. Khan.” Evaluation metrics in ontology modules”. pp. 
1-13, April 2016. 
[27] Kurukshetra, S. Jain S, and V. Meyer. “Evaluation and 
Refinement of Emergency Situation Ontology”. IJIET. vol. 
8, 
pp. 
713–719, 
January 
2018. 
https://doi.org/10.18178/ijiet.2018.8.10.1127. 
[28] J. D. Warrender and P. Lord . "How, What and Why to test 
an ontology". pp. 1-4, Mai 2015. 
[29] A. Rector, et al. “OWL pizzas: Practical experience of 
teaching OWL-DL: Common errors & common patterns”. 
Engineering Knowledge in the Age of the Semantic Web: 
14th International Conference, EKAW. Whittlebury Hall, 
UK, pp. 63–81, October 2004. Proceedings 14, Springer. 
[30] D. Allemang and J. Hendler. “Semantic web for the 
working ontologist: effective modeling in RDFS and 
OWL”. pp. 1-510, May 2011. 
[31] M. Poblet, et al. “Assigning Creative Commons Licenses to 
Research Metadata: Issues and Cases”. In: Pagallo U, 
Palmirani M, Casanovas P, Sartor G, Villata S, editors. AI 
Approaches to the Complexity of Legal Systems, vol. 
10791, 
pp. 
245–256, 
October 
2018. 
https://doi.org/10.1007/978-3-030-00178-0_16. 
[32] M. Horridge, et al. “A practical guide to building owl 
ontologies using protégé 4 and co-ode tools edition1”. vol. 
2. pp. 1-107, March 2011. 
[33] A. Gangemi, C. Catenacci, M. Ciaramita, and J. Lehmann. 
“Modelling ontology evaluation and validation”. The 
Semantic Web: Research and Applications: 3rd European 
Semantic Web Conference, ESWC. Budva, Montene, pp. 
140–154, June 2006. 
 
50
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-098-8
ICSEA 2023 : The Eighteenth International Conference on Software Engineering Advances

