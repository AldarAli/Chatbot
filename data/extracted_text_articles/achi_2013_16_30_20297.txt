Adaptive Simulation of Monitoring Behavior:
The Adaptive Information Expectancy Model
Bertram Wortelen, Andreas L¨udtke
Human Centered Design Group
OFFIS - Institute for Information Technology
Escherweg 2, 26121 Oldenburg, Germany
Email: {wortelen|luedtke}@ofﬁs.de
Abstract—Human attention is a fundamental but limited
resource. Especially when performing safety critical tasks a
suitable distribution of attention is essential for safe operation.
E.g., changes in task relevant information have to be recognized
in time in order to react adequately. This paper presents the
Adaptive Information Expectancy (AIE) model, which simu-
lates the scheduling of attention within cognitive architectures.
It can be used for model-based evaluations of interactive
human-machine systems. Results of a ﬁrst evaluation study
are shown based on a simple laboratory monitoring task. An
overview on the AIE model is given and it is shown how it
was integrated in the Cognitive Architecture for Safety Critical
Task Simulation (CASCaS). A formal model for the laboratory
task was developed and then simulated using CASCaS. Several
aspects of the AIE model are evaluated on the basis of the
simulations of this agent in two main steps. The ﬁrst step of
the evaluation compares the agent behavior with results from
the studies conducted by Senders. In this step two alternative
AIE model variants are compared to participants’ behavior.
The second evaluation step explores parameter sensitivity and
the convergence behavior of the model.
Keywords-Event expectancy; cognitive model; attention allo-
cation; monitoring behavior;
I. INTRODUCTION
Detailed knowledge about human attention allocation is
vital for designers of human-machine interaction, e.g., in
cars or aircrafts. It has been acknowledged by many re-
searchers that executable cognitive models have the potential
to capture such knowledge and to make it readily available to
designers (e.g., [1][2][3]). This paper presents the Adaptive
Information Expectancy (AIE) model which is an extension
of the seminal SEEV model introduced by Wickens et al. [4].
How humans distribute their attention depends on several
factors. The SEEV model is a predictive model of attention
distribution that relates the amount of attention allocated
to a speciﬁc information source to four inﬂuencing factors.
The abbreviations of these factors form the acronym SEEV:
Saliency of information events, Effort required to perceive
the information, Expectancy of new information events and
Value of the task, that requires the information. The SEEV
model can easily be applied to estimate percentage dwell
times (PDTs) – the percentage of time a human operator
spends looking at an information source, e.g., of a human-
computer interface.
The AIE model is based on the two knowledge driven
factors Expectancy and Value. Although it does not consider
Saliency and Effort, it extends the SEEV model in two
ways. (1) It relates the attention distribution to an executable
task model, which can be simulated, e.g., in a cognitive
architecture. Based on the simulation further measures like
gaze frequencies or link values can be estimated, besides the
mere prediction of PDTs as provided by the SEEV model.
(2) The second extension is related to the operationalization
of Expectancy. The SEEV model requires a system designer
or Human Factors Expert (HFE) who applies the model
to give an estimate of each of the inﬂuencing factors for
all considered information sources. For this, Wickens et
al. [4] propose a lowest ordinal algorithm as an easy to
use method, that orders the inﬂuencing factors by small
integers according to their rank. Although this method has
been proven simple and effective, it is only a very rough
operationalization that is dependent on the subjective rating
of the HFE. The AIE model strives to replace this by de-
riving the expectancy factor dynamically from a simulation
of the task model in a dynamic environment. It is thus
able to adapt its attention distribution automatically to the
current situation, which is an enhancement over the SEEV
model. It furthermore provides a much more detailed view
because it integrates the simulation of task performance and
the simulation of attention control in a tightly coupled way.
The long term goal of this research is to use the AIE model
to predict the allocation of attention dependent on design
characteristics of human-machine interfaces and associated
tasks in complex and safety critical environments.
The following shows results of a preparatory study that
was used to evaluate the AIE model on the basis of a labora-
tory monitoring task, which was developed by John Senders
in the 1960s [5]. The paper starts with an overview on the
AIE model and its integration in the Cognitive Architecture
for Safety Critical Task Simulation (CASCaS) [6][7]. Then
an overview on Senders’ task and the derived task formal-
ization is given in Section III and IV. Section V is dedicated
to the detailed evaluation of the AIE model.
413
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

II. ADAPTIVE INFORMATION EXPECTANCY MODEL
The AIE model and its integration into CASCaS will be
described here brieﬂy on an abstract level to provide a basic
understanding. For a more elaborated description see [7].
Cognitive architectures can be understood as engines that
are intended to execute formal models of tasks in a psycho-
logical plausible way. CASCaS is a modular architecture
consisting of components for perceptual, memory, knowl-
edge processing and motor processes. The AIE model is a
general model of attention allocation and thus is integrated
in CASCaS as part of a general model of human cognition.
In contrast, task models describe task speciﬁc aspects of
human behavior. The interpretation of a task model by
the cognitive architecture eventually simulates human-like
behavior. In the following the term (cognitive) agent refers
to the combination of task model and cognitive architecture.
A. Control of Attention
While the SEEV model is typically used to predict the
visual attention allocation to multiple information sources,
the AIE model intends to predict to which task an agent
mentally attends. However there is typically a very strong
relationship between visual and mental attention, which
Just and Carpenter [8] named the eye-mind-assumptions.
This assumption was adopted for the AIE model evaluation
presented in Section V, where the gaze behavior of the
participants in Senders’ study is compared with the gaze
behavior of the cognitive agent.
An assumption of the AIE model is, that human behavior
is goal oriented and every task serves to achieve one speciﬁc
goal. The AIE model is applicable to situations where
multiple tasks have to be performed in parallel in a time-
shared fashion, like e.g., a pilot that has to monitor a set of
displays, while controlling the aircraft and communicating
with the pilot non ﬂying. Attention is a limited resource and
often only one of the tasks can be processed consciously.
Although in real situations it is often possible to execute
some parts of tasks really in parallel, this aspect will not be
discussed in this paper.
To instantiate a cognitive agent CASCaS loads a hierar-
chical task model. Each task seek to achieve a goal and
is modeled by a set of rules. These rules represent the
knowledge of the human operator about the task. For a driver
model, for example, they describe how the driver interacts
with the car and the surrounding trafﬁc. The rule language
is based on the well-known GOMS notation [9]. All rules
consist of a left-hand side (IF) and a right-hand side (THEN).
The left-hand side names the goal to be achieved and a
Boolean condition that deﬁnes in which situations the rule
shall be applied. The right-hand side deﬁnes the actions that
are executed when applying the rule.
Multitasking situations in the task model have been han-
dled in the past by a very simple mechanism that treats
every task as equal and repetitively executes every task for
a certain but short amount of time in a ﬁxed sequence. This
mechanism is now replaced by the AIE model. The AIE
model assigns a weight to each goal gi of all active tasks:
w(gi) = U ·
ugi
P
gj∈G
ugj
+ V ·
vgi
P
gj∈G
vgj
(1)
In the above equation G is the set of goals for all active
tasks, ugi is the expectancy coefﬁcient that describes how
much the agent expects new information for the task of goal
gi and vgi is the value or importance of goal gi. Thus the
weight w(gi) depends on the relative importance of a task
compared to the importance of all tasks and the relative
information expectancy of a task compared to all tasks. The
factors U and V are used to adjust the overall inﬂuence of
task importance and information expectancy.
CASCaS now selects the next goal to be executed in a
probabilistic way. The probability of selecting goal gi is
deﬁned by the relation of all weights:
P(gi) =
w(gi)
P
gj∈G
w(gj)
(2)
In Equation 1 the value and expectancy factors are linked
by addition. However in applications of the SEEV model ad-
ditive combinations (e.g., [10]) as well as multiplicative ones
(e.g., [11]) can be found. Arguments can be found for both
variants. This was discussed by Wickens et al. [12]. They
achieved a better model ﬁt with the additive formulation. But
still there is no consensus about this issue. To shed further
light on this matter, the AIE model was implemented in both
variants. To explicitly distinguish between both variants the
symbol AIE+ is used for the additive formulation and AIE∗
for the multiplicative formulation.
B. Event functions
To use the AIE model the coefﬁcients in equation 1 have
to be deﬁned for each task. For the value coefﬁcients vgi it
is suggested to employ the lowest ordinal algorithm that is
typically used for the coefﬁcients of the SEEV model [4].
But for the expectancy coefﬁcients ugi an automatic opera-
tionalization is proposed.
Wickens et al. describe the expectancy factor as an
”information-related measure of event expectancy (e.g.,
bandwidth, event rate; [...])” [4, p.3]. This view is adopted
by the AIE model. The expectancy coefﬁcients are opera-
tionalized on the basis of information events. An event is
deﬁned as follows:
If at time t information, which is relevant for a goal g is
used to achieve g, then e = (g, t) is called an event at time
t for goal g. Let E be the set of all events that occurred
during a simulation, then Eg ⊆ E is denoted to be the set
of all events for goal g. Events can be ordered and indexed
by their time of arrival. With eg,i the i-th event in Eg is
denoted.
414
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

The identiﬁcation of events in CASCaS is straight for-
ward. CASCaS processes tasks using a rule engine similar
to other rule based architectures like e.g., ACT-R. It pro-
vides four different rule types: regular, percept, waiting and
reactive rules. When a task gets actively processed by a rule
engine the process is typically as follows. If the task needs
some information appropriate percept rules are executed that
instruct CASCaS to direct its gaze to an information source,
which provides the information. After the information has
been perceived, it can be used by regular rules to achieve the
task goal. If the perceived information is of no use for the
agent, a waiting rule is ﬁred, which signalizes, that another
task should be executed. Hence the execution of a regular
rule corresponds to the recognition of an information event
for the goal, which is supported by that rule.
During the simulation of the task model CASCaS records
the events of all goals and develops for each a cumulative
frequency distribution function Hg of the distances between
consecutive events eg,i and eg,i+1. The value Hg(∆t) can
answer the question, how often an event occurred not later
than ∆t time units after the previous event. This is used
to describe whether the agent can expect new events for a
speciﬁc goal and thus the expectancy coefﬁcients are deﬁned
by ug = Hg(t − tg,n)/dg, with t being the current time,
n being the index of the last event for g and dg being the
amount of time that the agent was working on g. Thus ug is a
time dependent function which is called the event function of
g. One effect of this operationalization is that the expectancy
of new events continuously increases since the last event was
observed.
Another effect is that the behavior of the agent changes
over time. At the beginning of the simulation it has no
knowledge about event distance. But the more events the
agent detects the more stable the event functions get. Thus
the behavior should change less the more time passes.
The learning speed of the agent should correspond to the
convergence speed of the event functions. According to the
Berry-Esseen theorem [13] the pointwise convergence speed
should be bounded by O(n− 1
2 ), with n being the number of
events which are recorded in Hg. If the distribution of event
distances does not change over time, having a ﬁxed average
event rate, this can be expressed in a time-dependent way by
O(t− 1
2 ). Unfortunately the assumption that the distributions
do not change over time is false, because there is always
a feedback within the cognitive agent when using the AIE
model: The event functions inﬂuence the selection of goals;
the selection of goals determine, where the model looks
at; where the model looks at inﬂuences the perception of
events distances; ﬁnally, the perception of event distances
inﬂuence the event functions. But assuming, that the effect
of this feedback loop is small, at least a similar learning
speed should be obtained. This was considered during model
evaluation and will be addressed in Section V.
Table I
BANDWIDTHS OF THE GAUGES FOR THE THREE EXPERIMENT
CONFIGURATIONS.
Conﬁguration
Partici-
Signal bandwidths per gauge (Hz.)
pants
1
2
3
4
5
6
C1
5
0.08
0.16
0.32
0.64
-
-
C2
3
0.03
0.05
0.12
0.20
0.32
0.48
C3
2
0.02
0.04
0.08
0.16
0.32
0.64
III. SENDERS’ MONITORING TASK
For a ﬁrst evaluation of the AIE model a simple laboratory
task was selected. It is the monitoring task developed by
Senders [5]. A cognitive agent was developed that relies on
the AIE model and is able to interact with this task. The
model is evaluated in section V against data that Senders
obtained in his studies on this task. In this section a short
overview on the task and the setup he used in his studies is
given. For more details see the original work [5].
In the Senders Task participants had to observe a set
of gauges that displayed dynamic values of currents for
ﬁctitious devices. Every time one of the displayed signals
fell below -45 µA or above 45 µA participants had to push a
button. Senders investigated how bandwidths of the signals
inﬂuence the gaze distribution of the participants. He used
ﬁve different tasks conﬁgurations. Three of these are used
for the evaluation and are denoted by C1, C2 and C3.
The signal bandwidths of each conﬁguration are listed in
Table I. It must be said, that the conﬁguration C1 belongs
to a different study than conﬁgurations C2 and C3. It was
conducted before the study involving C2 and C3.
C1 investigates the gaze behavior while monitoring four
gauges. Five participants executed this task for 1 h per day
over 30 days . Gaze behavior of the last three minutes of
each day have been analyzed.
C2 was similar to C1, but six instead of four gauges were
used. Participants executed the task for 1 h per day over 10
days. Gaze behavior of the last 11 minutes of the last day
have been analyzed. This conﬁguration is shown in Figure 1,
which shows the geometrical layout of the six gauges (left
side) and the viewing distance of the observer (right side).
C3 was similar to C2, but signal generation was changed,
which resulted in a different set of signal bandwidths.
b
-50
-40
-30
-20-10 0
10 20
30
40
50
µAmpere
b
-50
-40
-30
-20-10 0
10 20
30
40
50
µAmpere
b
-50
-40
-30
-20-10 0
10 20
30
40
50
µAmpere
b
-50
-40
-30
-20-10 0
10 20
30
40
50
µAmpere
b
-50
-40
-30
-20-10 0
10 20
30
40
50
µAmpere
b
-50
-40
-30
-20-10 0
10 20
30
40
50
µAmpere
158 mm
158 mm
76 mm
76 mm
76 mm
76 mm
158 mm
76 mm
23 ◦
6◦
Front view
Side view
Display
Figure 1.
Task conﬁguration with six gauges (reconstructed from [5]).
415
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

Look at
Gauge 1
Press
button
|x| ≥ 45 µA
|x| < 45 µA
done
observe gauge 1
Look at
Gauge 3
Press
button
|x| ≥ 45 µA
|x| < 45 µA
done
observe gauge 3
Look at
Gauge 2
Press
button
|x| ≥ 45 µA
|x| < 45 µA
done
observe gauge 2
Look at
Gauge 4
Press
button
|x| ≥ 45 µA
|x| < 45 µA
done
observe gauge 4
Look at
Gauge 5
Press
button
|x| ≥ 45 µA
|x| < 45 µA
done
observe gauge 5
Look at
Gauge 6
Press
button
|x| ≥ 45 µA
|x| < 45 µA
done
observe gauge 6
D
Figure 2.
State diagram of the cognitive agent’s task model. The states
observe gauge 5 and observe gauge 6 are only active for C2 and C3.
IV. COGNITIVE AGENT
Senders Task was modeled using the rule based language
of CASCaS. Figure 2 shows the semantics of these rules
in the form of a state chart. The overall goal is to observe
all gauges. This is decomposed into one subgoal for the
observation of each gauge. This results in four subgoals for
C1 and six subgoals for C2 and C3. These subgoals are
represented in Figure 2 by the top-level states. The task that
is executed to achieve each goal is depicted within the top-
level states by the process steps that have been mentioned
in Section II-B. At the beginning of the task processing the
agent executes a percept rule, which instructs CASCaS to
look at the information source that provides information for
the task. This is in this case the gauge for the speciﬁc task. If
the perceived information demands a reaction of the agent a
regular rule is ﬁred. For Senders’ task it happens when the
signal is in the alarm region (|x| ≥ 45 µA). The response
button is pressed as reaction by the execution of a regular
rule. If the signal is not in the alarm region no reaction is
required, the agent ﬁres a waiting rule and the task is ﬁnished
at least for the moment. In the condition that the signal is in
the alarm region, the agent uses the perceived information
to trigger an action by executing a regular rule. Thus these
situations are the events for this task.
The AIE model comes into play at the decision point
marked with a D in the ﬁgure. Here the agent selects which
subgoal it will process next. According to the AIE model the
agent will select to observe a gauge, where it highly expects
an alarm, in order to detect as much alarms as possible.
The expectancy coefﬁcients ui will be derived during the
simulation. The task values vi have to be assigned by the
model developer. Because all tasks have the same priority,
these coefﬁcients have been selected to be 1 for each task.
Expectancy and Value factors are weighted equally (U =
V = 1).
Figure 3.
Glance frequencies of participants and AIE+ agent for each
gauge in each conﬁguration.
V. EVALUATION
To evaluate the AIE model CASCaS was connected to a
simulation of the three conﬁgurations of Senders Task. The
cognitive agent described in the last section was instantiated
in CASCaS. CASCaS itself was connected to a simulation
of the three conﬁgurations of Senders Task.
A. Additive Variant: AIE+
The evaluation starts with an analysis about the model
ﬁt of the AIE+ model to Senders’ data. The agent was
simulated 10 times for 3 h of simulation time in each of the
three conﬁgurations. To avoid that the results are affected by
learning effects, only the last 1 h from every 3 h simulation
run was analyzed.
In [5] Senders presented the glance frequencies of the
participants to each gauge. In Figure 3 this data is shown
together with the glance frequencies that have been observed
in the simulation of the AIE+ agent. The ﬁgure shows, that
the agent’s behavior well matches the experimental data for
C2 and C3 with very high trend correlation of R2 = 0.996
for C2 and R2 = 0.984 for C3. Also the absolute deviations
measured by the root-mean-square error (RMSE) are small
with RMSE = 0.04 Hz for C2 and RMSE = 0.09 Hz for C3.
The situation is different for C1. Although the agent shows
the general trend (R2 = 0.851), the absolute deviation is quite
high (RMSE = 1.1 Hz). Especially the overall frequency for
C1 is with 3.1 Hz considerably greater than for C2 (2.0 Hz)
and C3 (2.1 Hz). The cognitive agent is not able to reach
the high glance frequencies in C1, because the model that
is part of CASCaS and calculates the duration of saccades
and ﬁxations does not permit such small gaze durations,
which are required to simulate these high gaze frequencies.
For details on this model see [14]. The reason for the high
frequencies in C1 compared to C2 and C3 are not known.
It might be due to the additional 20 days of practice that
participants had for C1, or just due to differences in the eye
data processing, which was done by a frame-by-frame rating
for videos of participants’ eye movements.
However, Senders also calculated link values for C1.
The link value probability according to ISO 15007-1:2002
describes for two information sources the relative frequency
of gaze transitions between these information sources com-
pared to all observed gaze transitions. The link values
416
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

Figure 4.
Correlation of link value probabilities for conﬁguration C1. A
data point i↔j represents the link value probability between gauge i and
gauge j.
obtained during the simulation of the AIE+ agent correlate
well with the ones observed by Senders for C1 (R2 = 0.87)
as can be seen in Figure 4.
B. Sensitivity Analysis
In equation 1 it can be seen, that there are quite a lot
of coefﬁcients that have to be determined before using the
model. Compared to the SEEV model the AIE model already
eliminates the need to deﬁne the expectancy coefﬁcients ui
by expert knowledge.
But still the value coefﬁcients vi and the general weights
U and V
remain. A high number of parameters bears
the danger that it allows, in principal, to ﬁt the model
predictions to any kind of data. Wickens addresses this issue
by proposing the lowest ordinal algorithms to restrict the
choice of coefﬁcient for the application of the SEEV model.
This approach is also proposed for the value coefﬁcients of
the AIE model. However, for the monitoring task discussed
in this paper this is meaningless, because Senders did not
instruct the participants to prioritize any of the gauges.
Therefore the value coefﬁcients are all equal and thus are
not free parameters at least for this agent.
In applications of the SEEV model the issue of weighting
the inﬂuence factors Expectancy and Value differently is
typically not addressed and the factors are weighted equally.
The same was done for the weights of the AIE+ agent
presented in the previous section (U = V = 1), which led to
very good results for C2 and C3. Nevertheless these are
free parameters, which have only the weak restriction that
usually they are chosen equally. Although it seems that U
and V are two parameters, it is effectively one parameter.
Inserting equation 1 into equation 2 leads to:
P(gi) =
U
V ·
ugi
P
gj ∈G
ugj +
vgi
P
gj ∈G
vgj
U
V + 1
(3)
Note that this conversion is only valid for V ̸= 0. As can be
seen now U and V only occur as U/V and thus this is only
Figure 5.
RMSE and R2 values obtained from simulating the AIE+ agent
with different values of U/V .
one free parameter. A sensitivity analysis was conducted to
estimate the effect of the relation U/V on the model ﬁt. A
set of selected relations were analyzed:
0/1, 1/5, 1/4, 1/3, 1/2, 2/3, 3/4, 4/5, 1/1, 5/4, 4/3, 3/2, 2/1, 3/1, 4/1, 5/1, ∞
For each relation 10 simulations with a duration of 3 h
have been executed like described in Section V-A. The
obtained RMSE and R2 values are displayed in Figure 5.
The highest correlation values have been obtained in the
range from 0.2 to 2.0 with R2 > 0.98, while the lowest
absolute deviations have been found in the range between
1.0 and 1.5 with a RMSE < 0.04 Hz. So the popular choice
of U = V = 1 was obviously also for this task an adequate
one, although a slightly better ﬁt has been observed with
a slightly higher value of U. This is a satisfactory result.
According to Pitt et al. [15] a model should be stable around
a reasonable region of parameters. As an equal weighting
of expectancy and value is a usual assumption, this property
seems to be well met by the cognitive agent.
It should be noted that the considerations made in this
section are only valid for the presented task model. For
a more general view on the AIE model this work has to
be repeated for a set of different task models in different
application domains.
C. Multiplicative Variant: AIE∗
In Section II it was mentioned, that there is no consensus
about how expectancy and value are linked. In the following
the simulation results are shown using the AIE∗ agent. In
the multiplicative variant of equation 1 the weighting factors
U an V are eliminated when the fraction in equation 2
is reduced. Thus there is no free parameter. Executing the
simulation again in the way described in Section V-A using
the AIE∗ formulation produces the glance frequencies shown
in Figure 6.
It can be seen, that the model ﬁt is worse than for
the AIE+ agent. The differences are clearly visible for C2
and C3 for which the AIE+ agent showed a very good
model ﬁt. Here the AIE∗ agent especially underestimates
the frequencies to the gauges with low signal bandwidths.
417
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

Figure 6.
Glance frequencies of participants and AIE∗ agent for each
gauge in each conﬁguration.
Giving the data a closer look reveals that the obtained
frequencies are almost identical to the frequencies of the
AIE+ agent using weights U = 1 and V = 0. And both
models are in fact identical. The value coefﬁcients of the
AIE∗ model disappear when reducing equation 2, because
they are all equal. This is equivalent to disabling the value
factors in the AIE+ model (V = 0).
D. Learning Convergence
In Section II-B it was assumed that the learning speed
should be bound by O(t− 1
2 ) if feedback effects can be
neglected. To investigate this the same agent as in Sec-
tion V-A was used. But now 20 simulation for C2, each
with a duration of 9 h were made. Every 5 minutes the event
functions of all 20 simulations were pairwise compared
using the difference measure V from Kuiper’s test, which
describes the similarity of two frequency distributions u1
and u2. The symbol V k is used to avoid a mix-up with
the weight of the value factors. According to [16] V k is
calculated by:
V k = max
0<∆t<∞(u1(∆t) − u2(∆t))
+
max
0<∆t<∞(u2(∆t) − u1(∆t))
(4)
This resulted in 190 comparisons every 5 minutes. It was
expected that the event functions are getting more and more
similar over time and thus the average V k should converge
Figure 7.
Convergence of event functions. Differences between event
functions of different simulation runs measured by V k are displayed on a
log-log plot and asymptotically approach 0.
Gauge
a
c
1
-0.082
0.216
2
-0.072
0.233
3
-0.035
0.292
4
0.006
0.354
5
0.058
0.429
6
0.081
0.475
b
0.682
Figure 8.
Learning effect on glance frequencies. Frequencies over time
are ﬁtted to functions of the form a · tb + c. Fitted parameters are listed
on the right side.
towards 0. The average V k values are plotted on a log-
log graph in Figure 7. It can be seen, that these values
form straight lines for the event functions of each task. This
strongly supports the initial assumption, that the learning
speed can be expressed by a function of the form a · tb. It
also supports the assumption that the event functions always
converge against the same function.
In the same way the consequences of the learning process
on the glance frequencies of the cognitive agent were
analyzed. It turned out, that these reﬂect the learning process.
They develop according to functions of the form a · tb + c.
This knowledge now allows to ﬁt the simulation data to
such functions, and to estimate their asymptotical value.
In Figure 8 this can be seen for C2. In the left graph the
average glance frequencies are plotted over time by dotted
lines. With solid lines functions of the form a · tb + c are
plotted that were ﬁtted to the data using the method of least
squares. In the table on the right side the ﬁtted coefﬁcient are
listed. The c-coefﬁcient is the estimation of the asymptotical
glance frequency value. This graph helps to identify how
much simulation time should be dedicated to learning the
event distance distributions. For the AIE+ agent a learning
phase of at least 30-50 minutes should be used. After this
time there is only little change in the glance frequencies.
The same analysis was conducted for the AIE∗ agent. It
required a much longer learning time. The parameter b that
determines the learning speed for the glance frequencies is
for the AIE∗ agent only at b = 0.432.
VI. CONCLUSION AND FUTURE WORK
The AIE model supports the simulation of task models
within the cognitive architecture CASCaS, by providing a
model of attention control. It was shown how the AIE model
automatically derives expectancy for information events and
uses this to guide its attention. A good model ﬁt was
achieved between the agents glance frequencies and results
taken from studies conducted by Senders [5]. The issue of
418
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

combining the Expectancy and Value factors additively or
multiplicatively was addressed by evaluating both variants.
The additive variant provided a better model ﬁt. A sensitivity
analysis for the free parameter revealed that the agents
behavior is stable within a reasonable parameter region. It
was analyzed how fast the agent is able to recognize the
distribution of events. The hypothesized speed function a·tb
was successfully ﬁtted against the observed simulation data.
The AIE model is strongly related to the SEEV model
and extends it in some ways. However, it is more an
alternative for the SEEV model than a replacement. The
SEEV model provides a simple and fast way to estimate the
distribution of attention. But its static way of application
does not provide a detailed insight in the situation under
investigation. This is provided by the AIE model, as it is
integrated in a cognitive architecture as basic simulation
framework. The AIE model additionally beneﬁts from the
simulation, because it dynamically derives expectancy values
during simulation, which in contrast has to be done by
human factors experts for the SEEV model. Thus from an
application point of view the AIE model trades off simplicity
for richness of detail.
It should although be noted, that the results presented in
this paper are only valid for the investigated monitoring
task and the transferability as well as scalability remains
to be investigated. There are some aspects that reduce the
representativeness of the study. Senders did not manipulate
the information value for the gauges. Thus changes in the
value coefﬁcients are not addressed. However the expectancy
coefﬁcients are the main focus of the AIE model. In addition,
the participants did not inﬂuence the displayed signals,
which is unrealistic for most human-machine systems. This
application served as a ﬁrst evaluation step for the model.
More and richer applications are required to ground the
ﬁndings of this study. A subsequent step to this study is
the application of the AIE model to a cognitive car driver
model. In the long term, this work shall lead to a general
evaluation method for human machine interaction that is
based on virtual human-in-the-loop simulation.
ACKNOWLEDGMENT
Parts of this research has been conducted within the
European project D3CoS and is funded by ARTEMIS-JU
and national authorities under grant agreement no. 269336.
REFERENCES
[1] B. E. John, S. M. Starr, and B. S. Utesch, “Experiences
with collaborative, distributed predictive human performance
modeling,” in CHI ’12 Extended Abstracts on Human Factors
in Computing Systems.
New York, NY, USA: ACM, 2012,
pp. 437–452.
[2] J. A. B. D. Dzaack, “Analyse kognitiver benutzermodelle fr
die evaluation von mensch-maschine-systemen,” Ph.D. disser-
tation, Technische Universitt Berlin, Fakultt fr Verkehrs- und
Maschinensysteme, 2008.
[3] F. E. Ritter, G. D. Baxter, G. Jones, and R. M. Young,
“User interface evaluation: How cognitive models can help,”
in Human-computer interaction in the new millennium, J. M.
Carroll, Ed.
Addison-Wesley, 2001, pp. 125–147.
[4] C. D. Wickens, J. Helleberg, J. Goh, X. Xu, and W. J. Horrey,
“Pilot task management: Testing an attentional expected value
model of visual scanning,” University of Illinois, Aviation
Research Lab, Savoy, IL, Tech. Rep. ARL-01-14/NASA-01-
7, November 2001.
[5] J. W. Senders, “Visual scanning processes,” Ph.D. disser-
tation, University of Tilburg, Netherlands, 1983, lawrence
Erlbaum Assoc., Hillsdale, NJ,1984.
[6] A. L¨udtke, J.-P. Osterloh, L. Weber, and B. Wortelen, “Mod-
eling pilot and driver behavior for human error simulation,”
in Digital Human Modeling, ser. Lecture Notes in Computer
Science, V. G. Duffy, Ed.
Springer, Berlin, 2009, vol.
5620/2009, pp. 403–412.
[7] B. Wortelen, M. Baumann, and A. L¨udtke, “Dynamic sim-
ulation and prediction of drivers’ attention distribution,” un-
published.
[8] M. A. Just and P. A. Carpenter, “A theory of reading: From
eye ﬁxations to comprehension,” Psychol. Rev., vol. 87, no. 4,
pp. 329–354, July 1980.
[9] S. K. Card, T. P. Moran, and A. Newell, The Psychology of
Human-Computer Interaction.
Hillsdale: Erlbaum, 1983.
[10] B. F. Gore, B. L. Hooey, C. D. Wickens, and S. Scott-Nash,
“A computational implementation of a human attention guid-
ing mechanism in MIDAS v5,” in Digital Human Modeling,
ser. Lecture Notes in Computer Science, V. G. Duffy, Ed.
Springer, Berlin, 2009, vol. 5620/2009, pp. 237–246.
[11] W. J. Horrey, C. D. Wickens, and K. P. Consalus, “Modeling
drivers visual attention allocation while interacting with in-
vehicle technologies,” J. Exp. Psychol.-Appl., vol. 12, no. 2,
pp. 67–78, 2006.
[12] C. D. Wickens, J. S. McCarley, A. L. Alexander, L. C.
Thomas, M. Ambinder, and S. Zheng, “Attention-situation
awareness (A-SA) model of pilot error,” in Human perfor-
mance modeling in aviation, D. C. Foyle and B. L. Hooey,
Eds.
New York: CRC Press/Taylor & Francis Group, 2008,
pp. 213–239.
[13] W. Feller, An Introduction to Probability Theory and its
Applications.
John Wiley & Sons, 1966, vol. 2, ch. 16.
[14] J.-P. Osterloh and A. L¨udtke, “Analyzing the ergonomics of
aircraft cockpits using cognitive models,” in Proceedings of
the 2nd International Conference on Applied Human Factors
and Ergonomics (AHFE), W. Karwowski and G. Salvendy,
Eds., Las Vegas, Nevada, USA, July 2008.
[15] M. A. Pitt, W. Kim, D. J. Navarro, and J. I. Myung, “Global
model analysis by parameter space partitioning,” Psycholog-
ical Review, vol. 13, no. 1, pp. 57–83, 2006.
[16] W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P.
Flannery, Numerical Recipes in C: The Art of Scientiﬁc
Computing.
Cambridge University Press, 1992.
419
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

