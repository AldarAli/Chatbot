Does Collarette of Iris Work for Recognizing Persons?
Ren-He Jeng, Wen-Shiung Chen
VIP-CCLab., Dept. of Electrical Engineering
National Chi Nan University
Puli, Nantou, Taiwan
s98323907@mail1.ncnu.edu.tw, wschen@ncnu.edu.tw
Lili Hsieh
Dept. of Information management
Hsiuping University of Science and Technology
Taichung, Taiwan
lily@mail.hust.edu.tw
Abstract—In recent years, iris has been extensively discussed
in the ﬁeld of biometrics. An iris recognition system has three
main stages such as image preprocessing, feature extraction
and template matching. Since eyelid and eyelashes act as a
kind of armour that protect the eye from harm, it makes
iris localization inaccurate in image pre-processing step. A
novel method is proposed to locate iris radius based on
collarette of iris muscle. The collarette is the thickest region
of the iris, separating the pupillary portion from the ciliary
portion. Some researches suggest that the parameters of iris
normalization algorithm adopts collarette to replace iris outer
radius. However, reducing the normalization radius of iris
will deform normalized iris image and result in lose of iris
feature information. In this paper, we present our experiments
by adopting different iris radii and different normalization
algorithms in iris recognition system. We also propose an
iris localization method and a collarette localization method.
In feature extraction, we adopt the Gabor wavelet ﬁlter to
extract local texture features from iris images. All experiments
are tested on UBIRIS Sessao.1 and CASIA.v1 databases. The
experimental results show that the proposed approach has
achieved a high accuracy of 96%.
Keywords-Biometrics; Iris Recognition; Iris Localization; Iris
Normalization; Collarette;
I. INTRODUCTION
In biometric-based automatic identity authentication tech-
niques, iris recognition is one of the most reliable and trusted
methods. Human iris is a thin circular organ which lies
between the cornea and the sclera of a human eye. Literature
show that, among all the biometric traits, iris has most rich
texture information and very high uniqueness, which has
been proved in the ﬁrst automated iris recognition system
developed by Daugman in [1]. In his system, a human iris is
localized by using the integro-differential operators and then
the cropped iris region is linearly normalized to rectangular
image. Following the preprocessing step, 2D Gabor wavelets
are used to extract iris codes based on the sign of the phase
angle, and the iris codes are matched by using Hamming
distance.
Another well-known iris recognition system was proposed
by Wildes et al. [2], in which the Hough transform is applied
to locate iris and the Laplacian pyramid is used to extract
four band-pass components from one iris image as their
feature presentation. Typically, the framework of iris recog-
nition systems includes three steps: image preprocessing,
feature extraction, and classiﬁcation/recognition. In fact, the
key step is to detect the range of interesting in the image
preprocessing part. This key step is sometimes called the
normalization step and it effects the system recognition per-
formance drastically. The general normalization algorithm
was proposed by Daugman [1]. This algorithm is the most
popular and has been widely used in many systems, in which
irises are assumed in a homogenous ”rubber-sheet” model.
In Daugman’s approach, the annular iris region is linearly
mapped or transformed into a ﬁx-sized rectangular block via
the following formulas:
 x (r, θ) = (1 − r) xp (θ) + rxi (θ)
y (r, θ) = (1 − r) yp (θ) + ryi (θ)
(1)
where (xp(θ), yp(θ)) and (xi(θ), yi(θ)) are the polar co-
ordinates of the inner and outer boundary points in the
direction θ in the original image, (x, y) are the Cartesian
coordinates. In 2000, H. J. Wyatt’s [3] proposed a mesh-
work of ’skeleton’ that can minimize ’wear-and-tear’ of
iris as pupil size varies. By following, Yuan and Shi [4]
adopted the idea in [3] as a basic model and simpliﬁed
it, and developed a non-linear iris normalization model
algorithm. The modiﬁed approach was applied to overcome
the non-linear deformation on the iris texture caused by pupil
variations. It has been shown that this modiﬁed approach
achieves a relatively good performance. However, the model
needs to solve two simultaneous equations, it is complicated
to get the sampling points and the time complexity is
high. Moreover, the model is not entirely accurate since
it assumes the stretch of iris tissue in radial direction is
linear as the pupil size changes. Changing the size of pupil
is controlled by iris with sphincter muscle and radial muscle
from different expanded level of direction. Therefore, to
develop a non-linear normalization method for resolving iris
texture deformation is necessary.
Though the eyelid and eyelash protect the iris of a human
eye, the blocking from them actually affects the processing
of image preprocessing step such that almost all systems
are not capable of precisely locating the radius of an iris.
Accordingly, some research works focus on how to locate
the iris precisely. One of the works is to localize the so-called
89
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

”collarette” [5] [6], which is a clear division line between
sphincter muscle and radial muscle, as illustrated in Fig. 1.
Some researchers believe that the colleratte may replace
iris outer radius potentially and improve the performance of
iris recognition systems. In 2004, Sung et al. [5] proposed
a framework of iris recognition with collarette detection
algorithm for locating boundary using statistical information,
and the success rate increases 1.0%. This system was
tested in two ﬁelds, one is between inner boundary and
outer boundary and another is between inner boundary and
collarette boundary.
Figure 1.
The structure of a human iris.
II. OUR METHOD
A. Iris Localization
The framework of our recognition system is shown in
Fig. 2. In the image preprocessing part, there are three
processes such as initial iris localization, collarette detection,
and normalization. Our proposed collarette detection method
has a limited condition for initial iris localization radius
due to collarette zone, which is the region between iris
outer radius and iris inner radius. Accordingly, the initial iris
radius could wrap collarette. If initial iris radius could not
provide enough normalization radius, it does not illustrate
collarette in unwrapping image.
Figure 2.
The framework of the iris recognition.
1) Initial Radius Localization: Initial radius localization
consists of four operations in the following: segmentation,
k-means computation, boundary points detection and radius
localization, as shown in Fig. 3. First, we must assume a
center point, radius and segmentation range for segmenting
assumed iris zone, as shown in Fig. 4 (a)(c). Besides, we
used pixel intensity of slices to decide initial boundary, as
Si = max |Pi − ui|, where Si is boundary, Pi is pixel
intensity, and ui is the mean value of each slice. A slice
means a serial of pixels. Then the initial radius initial is
deﬁned to be the mean value of Si. Following, in the second
part, we used k-means algorithm to cluster color features,
as illustrated in Fig. 4 (b)(d). Moreover, we ﬁnd the closest
different value with value on index initial of slice, which
are radius points rp, as illustrated in Fig. 4 (e). Finally, the
rp points are mapped onto original eye image, and then the
mean values of axis-x and axis-y are the coordinates of the
initial radius center point, due to the instinctive symmetry
in the shape of irises. In fact, the radius is the mean of
distances between center points and rp.
Figure 3.
The ﬂow diagram of initial radius localization.
2) Collarette Localization: In the beginning, we refer to
”pushing and pulling” model [7] to develop our proposed
initial radius localization. After unwrapping iris by eq. 1
with initial radius, we observe pixel intensity of the slices,
as shown in Fig. 5(a), it is an example curve about pixel
intensity in three angles. Since the trend of curves are
upwards, our goal is to ﬁnd the points where the intensity
changes from ﬂat into upwards in every curves. Figure 5(a)
that the curves are not smooth so that it might be located at
local parts. Accordingly, we construct a curve in polynomial
curve ﬁtting [8], as illustrated in Fig. 5(b), that has the best
ﬁt to a series of data points, possibly subject to constraints.
When computing the mean value ui in i-th curve (Li), we
ﬁnd the closest point in the curves Pi = min |Li − ui|, as
illustrated in Fig. 6, and the real-line is the simulated col-
larette line. And then computing the mean of Pi, we obtain
the position index of the collarette in iris unwrapping image.
Finally, by re-mapping the pseudo collarette to original iris,
the real collarette radius is then detected.
B. Iris Normalization
Since the location of the iris is known, our experiments
are tested on UBIRIS.v1 series 1 and CASIA.v1 with
linear normalization and non-linear normalization algorithm,
respectively. The linear normalization was proposed by
Daugman [1], and in this paper we will introduce a non-
linear normalization algorithm in the following subsection.
90
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

(a)
(b)
Figure 5.
The pixel value samples of an iris.
1) Fast Algorithm of Non-Linear Normalization: Accord-
ing to the method in the non-linear normalization model [3],
[4] mentioned above, we know that the ﬁnal goal is to ﬁnd
out the Cartesian coordinates Ax and Ay of the sampled
point A, indirectly by ﬁrst knowing the coordinates of the
virtual point A’. If we know the length of OA between the
point A and the pupil center O, and the angle θr(i) between
OA′ and y-axis, the coordinates of the point A may be
determined. It is observed from Fig. 7 that the two points
A′ and A are collinear,so OA and OA′ have the same angle
θr(i). Obviously, the three points, the point A′, the pupil
center O and the center o1 of arc(P′I′), form a triangle
△A′Oo1, as shown in Fig. 7. Since the lengths of three sides
of the triangle are known, the angle θr(i) can be determined
according to the law of cosine.
Similarly, the three points, the point A, the pupil center
O and the center o2 of arc(PI′), also from another triangle
△AOo2, as shown in Fig. 7. In this triangle only OA is
unknown. According to the law of cosine, the length of
OA may be determined from θr(i) which might be obtained
from △A′Oo1. Trivially, the coordinates, Ax and Ay, of the
sampled point A are computed by the following equations:
 Ax = ∆1 (i) sin (θr (i))
Ay = ∆1 (i) cos (θr (i))
(2)
where
θr (i) = cos−1
"
y2
2 + (rref + ∆2 (i))2 − r2
2
2y2 (rref + ∆2 (i))
#
(3)
and
∆1 (i) =

(a)
(b)
(c)
(d)
(e)
Figure 4.
The example result of radius localization.
Figure 6.
The simulated collarette line.
Figure 7.
Fast non-linear normalization model.
measure the Hamming distance [1] between two iris codes
and then set threshold to recognize them.
III. EXPERIMENTS AND ANALYSIS
A. Iris Database Description
Our experiments for identiﬁcation will be tested on
UBIRIS.v1 Sessao 1 and CASIA.v1 database, respectively.
The UBIRIS.v1 Sessao 1 [9] has 241 people for a total
1214 images and at least 5 photos in each class of size
800 × 600, and taken at a moderate distance under visible
wavelength light and the primary objective is to reduce the
need for cooperation, which means the users would not
feel constrained during the process of image acquisition.
It is developed by the SOCIA lab (Soft Computing and
Image Analysis Group) of the University of Beira Interior.
In the CASIA.v1 database [10], there are 756 images for 108
people and least 7 photos in each class of size 320 × 280,
and captured by near infra-red camera automatically in
room.
B. Comparison of the Sampling Distances with Different Iris
Radius Sets
In this paper, we tested iris recognition system with differ-
ent normalization algorithms, linear normalization algorithm
and non-normalization algorithm, and different radius. For
the unwrapping part, we tested three ﬁelds. The ﬁrst ﬁeld is
between inner boundary and outer boundary, the second one
is between collarette and outer boundary, and the third one
is the ﬁeld between inner boundary and collarette boundary.
92
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

As iris radius and collarette were detected, we computed
the difference value between the coordinates of i-th and
(i+1)-th sample points, as shown in Fig. 8. Since the image
size of eye in CASIA is smaller than UBIRIS.v1 Sessao 1,
the sampling distance curves are beating lightly in Fig. 8
(c)(d).
C. Experimental Results
In our experiments, we deﬁne three iris radii: iris inner
(ir), iris outer (IR) and collarette (cr). In fact, all experiments
are tested in three wrapping ﬁelds with ir-IR, ir-cr and cr-IR.
As mentioned in previous section, we extract iris features by
using 2D-Gabor wavelet ﬁlter, store a small number of bits
for each iris code, and compare them by using Hamming
distance. Observing Table 1 and Table 2, that experimental
results obtained on UBIRIS.v1 Sessao 1 shows that cr-IR
is better than ir-cr, no matter what linear normalization
algorithm or non-linear normalization algorithm are used.
Besides, the results for CASIA.v1 normalized in cr-IR is
better than in ir-cr with linear normalization algorithm.
However, the results for CASIA.v1 with non-linear normal-
ization are just in reverse, as listed in Table 1. Comparing
eye images in two different databases, we found that the
UBIRIS.v1 Sessao 1 has much complex furrows besides the
collarette, and the texture under collarette is straight muscle.
After unwrapping it, the divergence of texture of iris images
in UBIRIS.v1 Sessao 1. presents lightly. Moreover, the iris
furrows are complex near pupil in CASIA.v1, so the feature
representation in ir-cr is better than in ir-IR.
Table I
EXPERIMENTAL RESULTS WITH LINE NORMALIZATION ALGORITHM
(%)
ir-IR
ir-cr
cr-IR
CASIA.v1
6.9
9.3
4.3
UBIRIS.v1 Sessao
3.5
4.5
3.7
Table II
EXPERIMENTAL RESULTS WITH NON-LINE NORMALIZATION
ALGORITHM (%)
ir-IR
ir-cr
cr-IR
CASIA.v1
3.5
4.3
9.6
UBIRIS.v1 Sessao 1
3.5
3.3
3.2
IV. CONCLUSION
In this paper, we propose a collarette detection method
based on pixel intensity variation by using polynomial curve
ﬁtting, unlike existing variants of collarette by using a strong
classiﬁer. We only extract features with 2D-Gabor wavelet
ﬁlter and store a small number of bits for each iris code,
then compare them by using hamming distance, and set
a threshold to classify them. Therefore, the experimental
results show the effectiveness of our radius and collarette
localization algorithms as well as iris normalization algo-
rithm.
REFERENCES
[1] J. G. Daugman. High conﬁdence visual recognition of persons
by a test of statistical independence.
IEEE Transactions
on Pattern Analysis and Machine Intelligence, 15(11):1148–
1161, 1993.
[2] R. P. Wildes. Iris recognition: An emerging biometric tech-
nology. Proceedings of the IEEE, 85(9):1348–1363, 1997.
[3] H. J. Wyatt. A ‘minimum-wear-and-tear’ meshwork for the
iris. Vision Research, 40(16):2167–2176, 2000.
[4] X. Yuan and P. Shi. Iris recognition using collarette boundary
localization.
In Proceedings of International Workshop on
Biometric Recognition Systems on Advances in Biometric
Person Authentication (IWBRS 2005), volume 4, pages 135–
141, 2005.
[5] H Sung, J. Lim, J. H. Park, and Y. Lee.
Iris recognition
using collarette boundary localization. In Proceedings of the
17th International Conference on Pattern Recognition (ICPR
2004), volume 4, pages 857–860, 2004.
[6] K. Roy and P. Bhattacharya. Collarette area localization and
asymmetrical support vector machines for efﬁcient iris recog-
nition. In Proceedings of the 14th International Conference
on Image Analysis and Processing (ICIAP 2007), pages 3–8,
2007.
[7] Z. F He, T. N. Tan, Z. A. Sun, and X. C. Qiu.
Toward
accurate and fast iris segmentation for iris biometrics. IEEE
Transactions on Pattern Analysis and Machine Intelligence,
31(9):1670–1684, 2009.
[8] C. M. Bishop. Pattern Recognition and Machine Learning.
Springer, 1 edition, 2007.
[9] H. Proena and L. A. Alexandre. UBIRIS: A noisy iris image
database. In Proceedings of the 13th International Conference
on Image Analysis and Processing (ICIAP 2005), volume
LNCS 3617, pages 970–977, 2005.
[10] P. J Phillips, K. W Bowyer, and P. J Flynn. Comments on the
CASIA version 1.0 iris data set. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 29(10):1869–1870, 2007.
93
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

(a)
(b)
(c)
(d)
Figure 8.
The experimental performance in UBIRIS.v1 Sessao and CASIA.v1 with different iris localization methods and normalization algorithms. (a)(b)
UBIRIS.v1 Sessao 1, (c)(d)CASIA.v1
94
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

