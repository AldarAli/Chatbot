 
Understanding Map Operations in Location-based Surveys 
G. Batinov, M. Rusch, T. Meng,  
K. Whitney, T. Patanasakpinyo, and L. Miller 
Department of Computer Science 
Iowa State University 
 Ames, IA 50011   
e-mail: lmiller@iastate.edu 
Sarah Nusser 
Department of Statistics 
Iowa State University 
Ames, IA 50011   
 
Abstract—Location-based surveys have been moving to 
handheld computing devices as the availability of such devices 
has become more common.  The more limited screen size of the 
handheld devices has made the maps more difficult to use.  The 
present work looks at the map operations of users to determine 
if they are having problems.   Two studies have been analyzed 
to get an understanding of the types of patterns that might be 
used to identify users that are having trouble.  The choice of 
the two studies was to find two studies that were quite different 
and use one of the studies to find patterns of map operations 
that would indicate that a user was having problems.  The 
second study could then be used to test the relevance of the 
patterns in a different implementation of the same task.  We 
have identified patterns of interest using the data from the first 
study and found that the same patterns were relevant in the 
second study. 
 
Keywords—location-based surveys, map operations. 
 
I. 
INTRODUCTION 
As computing devices have become common place, we 
are seeing more location-based surveys use handheld 
devices in the field.  On many of these handheld devices 
screen space continues to be limited.  As a result, maps in 
these surveys can be difficult to work with. 
 
The present work focuses on understanding the types of 
difficulties that field staff have with map operations (e.g., 
zoom and pan) in such survey instruments.  Ultimately, we 
are interested in whether it is feasible to identify map 
operation patterns that suggest that a map user is in trouble.  
To look at this question, we have evaluated the results of 
two studies that use the same survey task (address 
verification), but different implementations. 
 
We couldn’t find existing research results that directly 
apply to this problem.  The closest work looked at map 
errors in the context of the sequence of map operations that 
were used to create a new map.  Examples are Lodwick et 
al. [3] and Haining et al. [2].  More recently, work on map 
operations have used previous users’ work to inform other 
users.  For example, Wong et al. [7] looked at the impact of 
seeing previous users’ map operation footprint in crowd  
 
Shneiderman [6] looks at the notion of the Visual 
Information Seeking Mantra.  The concept is related to the 
work discussed here in that Shneiderman’s approach 
provides a framework for designing geographic software 
applications. 
 
Roth [4] provides an overview of map-based primitives 
that provide the underpinnings of the map operations used 
in our studies. 
 
The main contribution of this paper is that we were able 
to identify patterns in the data from Study 1 that suggested 
that the user was in trouble when he/she was using the map 
operations (zoom and pan) and verify that the same patterns 
could be used in the second study in spite of the differences 
in the way that the software was implemented.  We also 
looked at the different treatments used in the two studies to 
extent this result over multiple variations of the software 
implementations.  The fact that the two studies used 
different devices and were conducted in very different 
environments enhances the second study as a means of 
validating the patterns.  Our tests show that the patterns 
could be found early enough in sequences of map operations 
that intervention has the potential to result in significant 
savings in terms of the number of map operations the user 
ultimately performed.   
 
The remainder of the paper is divided as follows: Section 
II briefly reviews the two user studies used in the analysis.  
The results are presented in Section III.  Section IV provides 
a discussion of the results.  Finally, we look at conclusions 
and future work in Section V.  
 
II. METHODS 
A. Overview 
The experimental task (address verification) involves 
comparing a housing unit configuration on the ground with 
the corresponding information in the map.  Possible 
outcomes are: 1) the ground situation is correctly reflected 
in the map requiring no further action; 2) the map has an 
error of commission that requires a map spot to be removed; 
3) the map has an error of omission that requires a map spot 
to be inserted; and 4) the map has an error in the housing 
unit location that requires the map spot to be relocated.  
The term scenario is used to indicate the process of 
completing the verification of one address.  The scenario 
144
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

 
type was not significant as one would expect since the bulk 
of the map operations are used to get to the point that the 
user is able to view the addresses on the map in the target 
area. 
The next two sub-sections briefly overview the relevant 
details of the two studies.  The maps are based on the US 
Bureau of Census’s Tigerline maps.  The map spots on the 
maps are used as identifiers of the location of housing units.  
For example, the spot labeled 507 in Fig. 2 indicates the 
current map location of the target address – 507 Astaire Ct.  
Beyond having the same survey task the implementations 
used in the two studies are different. Even within the two 
studies there are different treatments to be considered. 
 
 
Figure 1: The computer set up used in the Study 1. 
B.  Study 1 
Thirty-five participants were recruited from the 
community to perform 10 address verification scenarios.  
The map used in the software instrument covered a city of 
slightly over 40,000. 
The experiment was designed to impose a rigid protocol 
on the participants.  To successfully perform the task for 
each address, the following steps need to be executed in 
sequence: 1) find the address on the ground (i.e., in the 
photos presented to the subject ), 2) locate the address on 
the software map, 3) answer a question posed by the 
software as to whether or not the address was on the map, 4) 
if so, answer a question posed by the software as to whether 
or not the address was in the correct location on the map, 
and 5) fix the map if an error was identified.   
To focus the participants on the software instrument, 
the participants were seated at a table with two monitors 
showing the two sides of the street (Fig. 1).  The application 
recorded the time it took participants to perform each step in 
the procedure, the number of attempts to match each 
address, the number of attempts to fix the map, the accuracy 
in fixing the map, and the number of times specific buttons 
or other software tools were used.   
Two treatments were used in the experiment – guided 
(17 participants) and unguided (18 participants).  The screen 
shown in Fig. 2 illustrates the guided treatment.  The guided 
statements were general statements to indicate the next step 
in the protocol.   
In addition to the rigid protocol another important 
property of Study 1 is that the map was reset after each 
completion of a scenario. 
 
       
 
         Figure 2. The guided interfaces of Study 1.   
A more detailed look at the original user study can be 
found in Rusch, et al. [5].   
C. Study 2 
Thirty-one 
participants 
performed 
the 
address 
verification task for 6 addresses in the second study.  
The second study required to physically navigate the 
address space.  The map of the address space covered a 3X4 
block neighborhood of Ames, Iowa. The participants in the 
study were divided into two treatments (field and virtual 
reality (VR)).  The field group went into an Ames, Iowa 
neighborhood and had to navigate as well as perform the 
address verification on the software.  The VR group 
performed the same task, with the exception that the 
navigation took place within Iowa State University’s C6 (a 
fully immersive virtual reality environment).   
 
A key difference between the two studies is that in Study 
2, the participants could choose the scenario they wanted to 
work on in any order.  They could also revisit any scenario 
145
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

 
at any point in their work.  Fig. 3 shows a screen shot of the 
software showing the scenario menu.  Another important 
difference is that completing a scenario in Study 2 did not 
automatically reset the map.  Rather the map view remained 
the same until the participant performed another map 
operation. 
 
A more detailed look at the original user study can be 
found in Batinov, et al. [1]. 
 
IV. RESULTS 
A. Overview 
Each operation performed by a participant in both 
studies was logged and time stamped.  To look at the map 
operations, the log files have been parsed to generate the 
string of map operations.  Examples of the parsed results for 
the two studies are given in Figs. 5 and 6, respectively.  The 
legend for the map operations common to both studies is 
given in Fig. 4. 
 
     
 
    Figure 3. Edit screen with address list extended. 
 
Before looking at the results of our investigation, we 
need to introduce some terminology that is important to the 
remainder of the paper.  A count pattern, denoted n(list of 
unique map operations) is detected if the map operations in 
the list appears n times in the scenario sequence.  For 
example, the count pattern 3(A) means that we are looking 
for the appearance of 3 up pans (A) that appear in the 
sequence.  Note they do not have to be consecutive 
operations.  Looking at line two in Fig. 5, we see that the 
line contains the count pattern 3(A).  Note that it also 
contains 1(A), 2(A) and 4(A). 
 
A reversal count pattern is a count pattern where the 
map operations in the list represent a reversal.  For example, 
n(+-), n(AV) and n(<>) are reversal count patterns.  Since 
they are only counts, n(AV)=n(VA) for each of the 
reversals.   
 
The next sub-section looks at results for the first study.   
 
+ - zoom in by clicking + icon 
B - one level zoom in using the scroll bar 
C - two level zoom in using the scroll bar 
b - one level zoom out using the scroll bar 
c - two level zoom out using the scroll bar 
-  - zoom out by clicking – icon 
x - center zoom click 
> - pan right 
< - pan left 
A - pan up 
V - pan down 
R - reset map 
*  - attempted to pan beyond the map borders  
 
Figure 4. Map operation symbols common to the two data sets. 
 
B. Study 1 Results 
 
Fig. 5 shows the map operations for one of the 35 
participants.  Each line in the data represents the map 
operations for one scenario.   
 
+x>+xV-R>++><> 
+x+xV>-+xA>VAAVV+AVR++><<<VV<<--+>R<>+<+x 
<+>VVV-R+xAAVVVVVVAAA+A 
+<<R+xVAAAAAR<<<<<>>>>+xA+xA><> 
+x+x><-+>-+x>><<-+xVV 
+xV+x-+VA 
+x+xAA>V<R+x+x> 
+xV+xVA 
+x+x 
+x+x-+VA 
Figure 5. Sample map operation data showing one line for each scenario for 
Study 1. 
 
One obvious type of count pattern that tends to generate 
extraneous operations is a reversal.  Table I shows the 
number of scenarios (out of 170) that contained at least two 
or three (n=2 and n=3) reversal count patterns for the guided 
treatment.  Table II provides similar results for count 
patterns for the individual pan operations with n=2 and n=3. 
 
TABLE I. Number of scenarios in the guided data set that contain the 
reversal count patterns. 
Reversals 
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(z+)n(z-) 
19 
0.112 
10 
0.059 
n(>)n(<) 
36 
0.212 
20 
0.118 
n(A) n(V) 
55 
0.324 
36 
0.212 
146
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

 
TABLE II. Number of scenarios in the guided data set that contain pan 
count patterns of n= 2 and n=3. 
Pan 
Count 
Patterns  
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(>) 
52 
0.306 
30 
0.176 
n(<) 
52 
0.306 
31 
0.182 
n(A) 
72 
0.424 
45 
0.265 
n(V) 
65 
0.382 
49 
0.288 
 
Table III shows the number of map operations that 
participants used after one of the reversal count patterns was 
encountered  at either the n=2 or n=3 levels in the guided 
treatment.  Table IV shows the same results for the pan 
operators. 
 
TABLE III. Number of the 17 participants in the guided data set that used 
the reversal count patterns. 
Reversals 
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(z+)n(z-) 
13 
0.765 
9 
0.529 
n(>)n(<) 
15 
0.882 
9 
0.529 
n(A) n(V) 
17 
1.000 
13 
0.765 
 
TABLE IV. Number of the 17 participants in the guided data set that 
contain pan count patterns of n= 2 and n=3. 
Pan 
Count 
Patterns 
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(>) 
17 
1.000 
13 
0.765 
n(<) 
15 
0.882 
13 
0.765 
n(A) 
17 
1.000 
14 
0.824 
n(V) 
17 
1.000 
15 
0.882 
 
Table V shows the number of map operations that 
participants used after one of the pan or reversal count 
patterns were encountered at either n=2 or n=3 levels.  The 
second value is the number of scenarios that contain one or 
more of the count patterns. 
 
TABLE V. Number of map operations/impacted scenarios after 
encountering a reversal or a pan count pattern of size n in the guided data 
set. 
n 
pans 
reversals 
both 
2 
1130/104 
815/72 
1194/108 
3 
886/75 
578/46 
911/78 
 
Tables VI-X show the same results for the unguided 
treatment (180 scenarios). Table XI shows the same results 
for the full data set (35 participants) after the optimal set of 
map operations have been removed from each scenario. The 
optimal set of map operations was determined by examining 
each scenario. 
 
TABLE VI. Number of scenarios in the unguided data set that contain the 
reversal count patterns. 
 
Reversals 
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(z+)n(z-) 
33 
0.183 
19 
0.106 
n(>)n(<) 
53 
0.294 
33 
0.183 
n(A) n(V) 
58 
0.322 
44 
0.244 
 
TABLE VII. Number of scenarios in the unguided data set that contain pan 
count patterns of n= 2 and n=3. 
Pan 
Count 
Patterns  
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(>) 
66 
0.367 
45 
0.250 
n(<) 
70 
0.389 
48 
0.267 
n(A) 
82 
0.456 
56 
0.311 
n(V) 
68 
0.378 
51 
0.283 
 
TABLE VIII. Number of the 18 participants in the unguided data set that 
used the reversal count patterns. 
Reversals 
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(z+)n(z-) 
13 
0.722 
10 
0.556 
n(>)n(<) 
16 
0.889 
12 
0.667 
n(A) n(V) 
16 
0.889 
14 
0.778 
 
TABLE IX. Number of the 18 participants in the unguided data set that 
contain pan count patterns of n= 2 and n=3. 
Pan 
Count 
Patterns  
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(>) 
17 
0.994 
17 
0.994 
n(<) 
17 
0.994 
14 
0.778 
n(A) 
16 
0.889 
14 
0.778 
n(V) 
17 
0.994 
16 
0.889 
 
TABLE X. Number of map operations/impacted scenarios after 
encountering reversals or a pan count pattern of size n in the unguided data 
set. 
n 
pans 
reversals 
both 
2 
1537/111 
1167/84 
1568/112 
3 
1239/82 
863/59 
1261/84 
 
C. Study 2 
 
Fig. 6 shows the map operations for one of the 31 
participants in Study 2.  The map operations use the same 
symbols as were shown in Fig. 4.  The other new symbols 
JZ, KZ, LZ, MZ, NZ and PZ indicate the selection of one of 
the six scenarios used in this study.  As can be seen from 
Fig. 6, participants can open and work on a scenario at any 
time.   
 
TABLE XI. Number of map operations/impacted scenarios after the 
optimal set of map operations have been removed.   
n 
pans 
reversals 
both 
2 
2560/199 
1838/151 
2634/205 
3 
2034/148 
1352/101 
2072/153 
 
JZ--A<V><AVV><>Ax 
PZ<V<AAVV>cBxBV<V<>AA><><BV><<>V<> 
MZ 
PZ 
MZV<>V<>A<<VA>b>--++>>><<-+V** 
NZ<>>><<<<>>><A<<V>>>>*<><A<<V+- 
KZ>>><<><>><<<A 
NZ<>>-->-++-++--++<V--- 
LZxA<<>>V 
NZ<<A 
LZ<>-->>AA<<VVxAVA 
JZ>V>>V 
 
Figure 6. Map operations showing one line for each open scenario for 
Study 2 for one participant. 
147
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

 
 
From Fig. 6, it is clear that the notion of a scenario is not 
as consistent as it was in Study 1.  Moreover, since it is not 
clear that operations at the end of a line are consistent with 
the open scenario, combining map operations from multiple 
lines for the same scenario is not meaningful.  As a result, 
we use each line as a representation of a unit task.  Table 
XII shows the number of lines containing reversal and  
 
Table XII. Line counts for reversal and pan count patterns for n=2 and n=3. 
Operations 
Count 
n=2 
Average 
n=2 
Count 
n=3 
Average 
n=3 
n(z+)n(z-) 
59 
0.2063 
40 
0.1399 
n(>)n(<) 
93 
0.3252 
63 
0.2203 
n(A) n(V) 
53 
0.1853 
28 
0.0979 
n(>) 
116 
0.4056 
74 
0.2587 
n(<) 
116 
0.4056 
83 
0.2902 
n(A) 
62 
0.2168 
36 
0.1259 
n(V) 
72 
0.2517 
45 
0.1573 
 
pan count patterns for the full Study 2 dataset (both VR and 
field).  Tables XIII-XV show the number of the number of 
map operations that exist beyond the count patterns for the 
full Study 2 dataset, the VR treatment and the field 
treatment, respectively. The full dataset contains 286 lines 
of map operations, while the two treatments (VR and field) 
consist of 157 and 158 lines, respectively. 
 
TABLE XIII. Number of map operations/impacted lines after encountering 
a reversal or a pan count pattern for the complete dataset and n= 2 and n=3. 
n 
pans 
reversals 
both 
2 
1607/153 
1350/124 
1703/164 
3 
1135/103 
857/87 
1242/113 
 
TABLE XIV. Number of map operations/impacted lines after encountering 
a reversal or a pan count pattern for the VR treatment dataset and n= 2 and 
n=3. 
n 
pans 
reversals 
both 
2 
997/88 
834/67 
1039/91 
3 
730/58 
559/51 
782/62 
 
TABLE XV. Number of map operations/impacted lines after encountering 
a reversal or a pan count pattern for the field treatment dataset and n= 2 and 
n=3. 
n 
pans 
reversals 
both 
2 
610/65 
516/57 
664/73 
3 
405/45 
298/36 
460/51 
 
D. Comparing Results 
 
To compare the results from the two studies, we used the 
unpaired t-test with the null hypothesis that the two 
populations differ.  The data drawn from the two studies for 
this test was the number of map operations that appeared 
after one of the count patterns was detected. Table XVI 
shows the values for the count patterns for n=2 and n=3.  
The value of p in both cases is not significant.  As a result, 
we see the potential map operations saved from two very 
different implementations as being statistically equivalent. 
 
 
Table XVI. T-test values comparing the potential savings from the two  
studies. 
 
 
 
 
We found very similar results when we compared the 
treatments (guided vs unguided and field vs VR) using the 
same approach. 
V. DISCUSSION 
 
The goal of this study was to use Study 1 to identify 
interesting count patterns and use the Study 2 data to see 
whether the same patterns are valid there as well.  We have 
chosen to work with the raw data to provide a view of 
potential savings that intervening might bring to users of a 
survey instrument.  Note that we are only looking at the 
potential savings, while realizing that the participant would 
still have to complete the task.   
 
The expectation is that intervening would give them the 
opportunity to more efficiently complete the task.  Pans in 
both studies have the side effect of causing some 
participants to wander.  Also note that we are not looking to 
statistically compare results across studies or treatments.  
Rather we simply are looking to identify potential count 
patterns that exist in different implementations.  The fact 
that the implementations of the software, the study 
environments, and the devices used are very different makes 
our approach of using the Study 2 data to validate our 
results more interesting. 
 
A. Study 1  
The Study 1 data has been evaluated across the two 
treatments as well as the complete dataset.  From Tables I, 
II, VI, and VII, we find that the reversal and pan count 
patterns show up in both treatments.  Table V illustrates that 
for all of the scenarios that contain a count pattern at either 
n=2 or n=3, there are more than 10.8 map operations per 
impacted scenario that could potentially be saved for the 
guided treatment.   From Table X we see that there are even 
more map operations after the count patterns for the 
unguided treatment (at least 13.2 map operations per 
scenario impacted).  Recognizing the count patterns and 
intervening gives the potential to significantly reduce the 
user frustration in map based surveys.  This is especially 
useful in the handheld environment, where small screen size 
tends to complicate the use of maps. 
 
Tables III, IV, VIII, and IX look at the number of 
participants that incur at least one of the count patterns.  
Here we see that over half of the participants in the guided 
treatment (0.529) and unguided treatment (0.556) have used 
at least one count pattern.  The number of participants for 
most count patterns is closer to 1.0.  Table XI shows the 
same results for the complete Study 1 dataset after the 
Study 1 vs Study 2 
t 
dff 
p 
n=2 
1.5459 
382 
0.1230 
n=3 
1.3928 
273 
0.1648 
148
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

 
optimal query has been removed from each scenario string.  
The idea behind this data was to only consider the 
extraneous map operations in each line of map operations.  
Again, we find that the average number of additional map 
operations in the line to be over 12.1 per scenario. 
 
From these results, we believe that the reversal and pan 
count patterns for n=2 and n=3 are reasonable choices for 
determining that a user is having difficulties using the map 
operations.  In the next subsection we look at the impact of 
these count patterns on the Study 2 dataset. 
 
B. Study 2 
As noted earlier, the software implementation for Study 
2 provided a more flexible protocol.  Two important 
differences are that the participants could work on any 
scenario at any time and that the map was not reset at the 
completion of a scenario as it was in the first study.   The 
first difference resulted in a breakdown in the way that 
scenario could be used.  In the first study, a scenario was 
essentially the same as a line of data.  In the second study a 
scenario was typically opened on more than one line.  Since 
there is no way to relate operations on an open scenario to 
the scenario (the participant could be positioning the map 
for another scenario), the task unit was interpreted as a line 
of map operations.   
 
The second difference is somewhat more important in 
the context of this study.  Since the map was not reset after 
the completion of a scenario, most participants in the second 
study tended to use pans to move on to the next address 
location on the map.  This provides an interesting point, as 
the optimal approach was to reset the map after completion 
of a scenario rather than use pans.  A third difference is the 
size of the underlying map.  The smaller map for Study 2 
should mean less pans, but the pan count pattern numbers 
are still quite large.  In addition to these three differences 
the two studies differed in the type of device used as well as 
the environment used for the study. 
 
The result has been that we see the count patterns from 
Study 1 being useful in Study 2.  Looking at Fig. 6, it is 
easy to see how this one participant tended to wander on the 
map when he/she was using pan operations.  More 
important, the results in Tables XIII and XV show that the 
count patterns have been found early enough in the lines of 
map operations to potentially save participants from using 
extra pan operations and reversals.   
 
VI. CONCLUSION AND FUTURE WORK 
 
We were able to find an interesting set of map operation 
count patterns based on pans and reversals in two different 
implementations of the address verification task.  Our next 
step is to use the count patterns in a new user study where 
we can intervene and study the actual impact on 
participants.  Ultimately, our goal is to use the map 
operation count patterns found in this work to provide an 
adaptive approach to help users struggling with using maps 
on the mobile devices that agencies like the Bureau of 
Census are starting to use in the field for large tasks like 
address verification. 
 
REFERENCES 
 
[1] Batinov, Georgi, Kofi Whitney, Les Miller, Sarah 
Nusser and Bryan Stanfill. “Evaluating The Impact Of 
Spatial Ability In Virtual And Real World Environments,” 
The Sixth International Conference on Advances in 
Computer-Human Interactions. Nice, France. February 24-
March 1, 2013. pp. 274-279. 
 
[2] Haining, Robert and Giuseppe Arbia. “Error Propagation 
Through Map Operations.” Technometrics, Vol. 35, No. 3 
(Aug., 1993), pp. 293-305. 
 
[3] Lodwick, Weldon, William Monson & Larry Svoboda.  
“Attribute error and sensitivity analysis of map operations in 
geographical information systems: suitability analysis,” 
International Journal of Geographical Information Systems. 
Volume 4, Issue 4, 1990. pages 413-428. 
 
[4]Roth, Robert. "Cartographic Interaction Primitives: 
Framework and Synthesis," Cartographic Journal.  Volume 
49, Issue 4 (November 2012), pp. 376-395. 
 
[5] Rusch, M. L., S. M. Nusser, L. L. Miller, G. I. Batinov, 
and K. C. Whitney. “Spatial Ability and Map-Based 
Software Applications,” The Fifth International Conference 
on Advances in Computer-Human Interactions. Valencia, 
Spain. January 30-February 4, 2012, pp. 35-40. 
 
[6] Shneiderman, B. "The eyes have it: a task by data type 
taxonomy for information visualizations". IEEE Symposium 
on Visual Languages. 1996. pp.336-343. 
 
[7] Wong, Yuet Ling, Jieqiong Zhao & Niklas Elmqvist. 
“Evaluating Social Navigation Visualization in Online 
Geographic Maps,” Human Computer Interaction. 2014.     
 
149
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

