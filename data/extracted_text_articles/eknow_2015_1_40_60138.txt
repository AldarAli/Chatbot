 A Usability Evaluation Methodology of Digital Library 
 
Luz A. Sánchez-Gálvez1, 2 
1Facultad de Ciencias de la Computación,  
Benemérita Universidad Autónoma de Puebla,  
72570, Puebla, México 
sanchez.galvez@correo.buap.mx 
luzsg@correo.ugr.es 
Juan M. Fernández-Luna 
2Departamento de Ciencias de la Computación e I.A., E.T.S. 
de Ingenieria Informatica, CITIC-UGR 
Universidad de Granada,  
18071 Granada, Spain 
jmfluna@decsai.ugr.es 
 
 
Abstract— Digital Libraries are information systems that allow 
managing and preserving digital resources, as well as 
providing access to them. The designing of these kinds of 
systems should always be completed having in mind the users. 
Accordingly, it is of outmost importance that the user interface 
presents a high level of usability. In this paper, a usability 
evaluation methodology of Digital Libraries is proposed; 
specifically for the Web site of Academic Digital Libraries. The 
methodology offers a evaluation instrument that collects the 
users' perceptions through four dimensions (effectiveness, 
efficiency, satisfaction and learnability). In addition, the gap 
theory of quality service is employed and a fuzzy linguistic 
approach using aggregation operators, which operate directly 
with words (linguistic information) is applied. Therefore, the 
methodology shows to be a significant, innovative contribution 
to the research area on usability evaluation of digital libraries. 
It can be useful for both an academic library Web site and an 
operational digital library. A case study is presented in order 
to demonstrate the usage of usability evaluation methodology 
of digital library. 
Keywords-digital libraries; usability evaluation methodology; 
usability 
dimensions; 
evaluation 
instrument; 
aggregation 
operators. 
I. 
 INTRODUCTION  
There are many definitions of usability in the literature, 
which provide different and complementary points of view, 
and show the evolution of the term itself along the evolution 
of knowledge. Usability is the broad discipline of applying 
sound scientific observation, measurement, and design 
principles to the creation and maintenance of Web sites in 
order to bring about the greatest ease of use [1]. According to 
Nielsen [2], usability focuses mainly on the use of a Web site 
or an interface and how people use it to carry out their tasks. 
If a Web site or interface is not able to satisfy the needs of 
their users, they will not be successful in the long term. 
Usability has several international standard definitions. It  
is a quality attribute that assesses how simple it is to utilize 
user interfaces. The concept of usability, is also related to 
methods to improve the easiness of its use throughout the 
design process.  
Digital Libraries (DLs) are information systems that 
allow to manage and preserve digital resources, and to 
provide access to them. The design of these systems must be 
always accomplished bearing in mind the user, so, it is 
vitally important that the user interface has a high degree of 
usability. In this paper, a usability evaluation methodology 
for the DLs —specifically for the academic DL Web site— 
such as a case study of  the usability evaluation of the DL 
Web site in the University of Puebla is presented. The 
methodology proposes an evaluation instrument, that collects 
the users’ perceptions by four dimensions (effectiveness, 
efficiency, satisfaction and learnability). In addition, the gap 
theory of service quality and a fuzzy linguistic model using 
aggregation operators of linguistic information —which 
operate directly with words— are used. Therefore, the 
methodology proves to be a significant and innovative 
contribution to the area of usability evaluation research of  
DLs. The same can be applied to a Web site of an academic 
DL as an operational DL. 
The rest of this paper is organized as follows: Section II 
describes some related works in evaluating DLs. Section III 
explains the  LibQUAL+ methodology. Section IV presents 
a brief introduction to the linguistic approach. Section V 
details a usability evaluation methodology. Section VI 
outlines the conclusions and future work. 
II. 
RELATED WORK 
According to the literature, most evaluations have 
focused on library service quality and its collections. Among 
the contributions of research on usability evaluation of Web 
sites, there are those of Hammill [3], who evaluated the 
usability of the Florida International University libraries’ 
Web site by means of formal usability test and questionnaire, 
for determining whether its design and organization allow 
users to easily locate information based on the navigation, 
the clarity of vocabulary, and the visibility of the different 
sections. Oulanov and Pajarillo [4] described the results of a 
usability evaluation study of the Web-based graphical user 
interface version of the Web bibliographic database of the 
City University of New York, using questionnaire that 
determined the affect, efficiency, control, helpfulness, and 
adaptability as usability attributes. Lee [5] evaluated the 
usability of a Research Center library Web site in Korea by 
using a mixture of observation methods, and some formal 
usability tests; including heuristic evaluation, laboratory 
usability testing, and remote usability testing. Jeng’s 
usability model [6], which is one of the most cited works on 
usability evaluation of DL Web sites, carried out usability 
tests based on tasks, comprising four usability dimensions; 
effectiveness, efficiency, satisfaction, and learnability, as 
23
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-386-5
eKNOW 2015 : The Seventh International Conference on Information, Process, and Knowledge Management

well as, some sub-attributes of usability. She also suggested 
some specific measures for each dimension, although it must 
be considered that those could vary according to the user’s 
particular skills. Joo, Lin, and Lu [7] proposed a usability 
evaluation model by means a questionnaire, to survey the 
three usability criteria: effectiveness, efficiency, and 
learnability, in academic library Web sites. Alasem [8] used 
a questionnaire based usability test as a method for 
evaluating the usability of Saudi Digital Library’s interface. 
In his usability evaluation, he suggested criteria such as 
efficiency, 
effectiveness, 
aesthetic 
appearance 
and 
learnability.  
The usability study as in [9] is among the few studies 
comparing users’ performance in multiple operational DLs: 
ACM, IEEE CS, NCSTRL, and NDLTD. This study used 
questionnaire and formal usability test, their objective was to 
identify specific characteristics that aid in the effectiveness 
(ease of use), likability, learnability and usefulness of DLs. 
The user’s performance was measured by its ease of use, the 
amount of searching time, and the number of errors made. In  
[10] explored usability issues (perceived ease of search, 
satisfaction and perceived ease of browsing) on the design 
and the interaction in the browse and search function of 
ACM, IEEE CS, and IEEE Xplore.  
 LibQUAL+ methodology [11] was developed in the 
evaluating of the digital library services, provides a useful 
framework for usability evaluation of digital library. 
LibQUAL+ uses the gap theory of service quality, as well as 
other assessment frameworks based on SERVQUAL model 
[12]. Nowadays, The DigiQUAL project, being an extension 
of LibQUAL+, developed a service quality model reflecting 
digital environments [13]. 
 Specialized assessment’s works for academic libraries 
have been limited to assessing the quality service, but the 
evaluation of the Web site usability of academic libraries has 
received relatively little attention. Furthermore, these studies 
use neither the service quality gap nor the linguistic 
aggregation operators (LOWA and LWA). Regarding works 
that employ linguistic aggregation operators; these are 
strictly oriented to the quality of service [14] and they do not 
utilize the four usability attributes proposed hereby. 
This paper provides a methodology that combines 
methods and principles —dimensions, questionnaire and 
measurement scale— of usability evaluation and fuzzy logic 
techniques, focusing on usability evaluation of digital 
libraries, which can either be academic or operational. 
III. 
LIBQUAL+ METHODOLOGY 
The Association of Research Libraries (ARL) in 
conjunction with the University of Texas A&M, started a 
project to obtain a standardized measure of the quality 
library service. The LibQUAL+ methodology is the result of 
such a project, which allows determining the quality of 
library services from the users’ perception. LibQUAL+ is 
based on the theory of quality service —assessment applied 
in the environment of enterprises and organizations— 
particularly on the SERVQUAL evaluation methodology.  
SERVQUAL is the most accepted and extended 
measurement of quality service.  It is based on the principle 
that "only customers judge quality; all other judgments are 
essentially irrelevant" [15]. Thus, customer satisfaction is the 
key element in SERVQUAL. Service quality is related to 
diminishing 
the 
distance 
between 
the 
customers’ 
expectations and his final perception.  
According to SERVQUAL, customers will evaluate, 
positively or negatively, the quality of a service where their 
prior perceptions were either higher or lower than expected. 
Hence, companies or organizations that provide services, 
where one of the objectives is being observed differently by 
means of a quality service, must show special interest on 
exceeding their customers' expectations.  
LibQUAL+ looks forward to evaluating the quality of 
service of a library, considering three dimensions: the 
affective value provided by the staff, the value of the library 
space, and the value represented by the information control. 
Hence, service quality is evaluated through a survey of 22 
questions; Minimum required level of service; Expected 
level of service; and the level perceived by the user. The 
Expected level and the Minimum required level establish the 
boundaries of a zone of tolerance within which the perceived 
scores should desirably float. Based on the users’ feedback, 
it is possible to define two variables for detecting the 
strengths and weaknesses of a library i.e. Adequacy of 
Service (the difference between the perceived value and the 
minimum value) indicating the areas where the library 
service is below the level expected by the user, and Service 
Excellence (the difference between the perceived value and 
the expected value) that identifies areas where the library 
provides a better service than that expected by the user. 
IV. 
LINGUISTIC APPROACH  
The information cannot always be evaluated in a 
quantitative manner, sometimes it is necessary to do it 
qualitatively. The existence of qualitative variables inherent 
to human behavior, or external environment elements,  
which are difficult to quantify objectively lead individuals to  
express their opinions better, by using linguistic terms 
instead of precise numerical values. A linguistic variable 
differs from a numerical one in that its values are not 
numbers, but words or sentences in a natural  or artificial 
language [16].  
When a linguistic model is used, the existence of a 
suitable set of terms or labels according to the problem 
domain is assumed, then, the individuals can express their 
perceptions. The ordinal fuzzy linguistic model [17] is very 
useful as it simplifies the computing by eliminating the 
complexity of having to define a grammar. 
An ordinal fuzzy linguistic modeling [16] is used in this 
paper to represent the users’ perceptions with words, based 
on the linguistic aggregation operators LOWA and LWA 
[14] , in order to evaluate the academic digital libraries Web 
sites usability.  
The Linguistic Ordered Weighted Averaging (LOWA) is 
an operator used to aggregate non-weighted ordinal linguistic 
information, i.e., linguistic information values with equal 
importance. The Linguistic Weighted Averaging (LWA) is 
an 
operator 
used 
to 
aggregate 
weighted 
linguistic 
information, i.e., linguistic information values has  different 
24
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-386-5
eKNOW 2015 : The Seventh International Conference on Information, Process, and Knowledge Management

importance. In order to calculate both operators, this paper 
follow the definitions established on [18].  
V. 
A USABILITY EVALUATION METHODOLOGY 
In this work, a usability evaluation methodology has been 
developed for the academic DL Web sites based on literature 
review. Therefore, this methodology takes an approach that 
requires the establishment of dimensions, as a way to 
measure usability, based on standards such as ISO 9241-11 
[18] and Nielsen´s definition [2]. Consequently, it considers 
four dimensions: effectiveness, efficiency, satisfaction, and 
learnability represented in twenty items to capture the users' 
perceptions to assess the usability degree of academic DL 
Web sites. Furthermore, the methodology uses a fuzzy 
linguistic model by means of aggregation operators with 
linguistic information, which handle words directly. They are 
important to allow sorting and classifying all data from an 
aggregation process, without any loss of linguistic 
information. In addition, the model LibQUAL+, which 
attempts to measure the overall service quality in academic 
DL is utilized. LibQUAL+ emerged from the SERVQUAL 
methodology; an instrument based on the gap theory of 
service quality, which was used to assess private sector 
institutions. 
Deficiencies on usability of DL Web sites could be 
identified through LibQUAL+. Therefore, the proposed 
methodology of usability evaluation in this paper, could offer 
commendations 
for 
prioritizing 
improvements 
and 
guaranteeing a proper interface design of DL, based on 
users’ preferences within an institution. 
The usability evaluation methodology, consists of 
different 
steps; 
the 
development, 
production, 
implementation, 
evaluation 
and 
reliability 
of 
the 
questionnaire, as well as the results analysis, from where a 
series of recommendations to improve the usability of DLs 
Web sites can be provided. The steps for implementing  this 
methodology are:  
A. The identification of dimensions.  
B. The preparation of the questionnaire.  
C. The usability evaluation by aggregating  operators.  
D. The presentation of evaluation results.  
E. The commendation of the DL Web site. 
A. Dimmensions of Usability 
The usability is a multidimensional concept. In this paper 
four dimensions of usability —effectiveness, efficiency, 
satisfaction and learnability— are proposed to assess the 
usability of academic digital libraries' Web sites (see Table 
1). 
In order to define the usability dimensions, the models of 
Nielsen [19], ISO 9241-11 [18], Shackel [20] Tsakonas [21], 
Jeng [6], and Xie [22] were revised. Finally, the chosen 
dimensions were based on the standard definition of ISO 
9241-11 [18] and the Nielsen model [19]. Nielsen’s model, 
which is one of the most cited in the area of usability 
engineering, 
postulates 
five 
attributes: 
learnability; 
efficiency; memorization; low error rate (easy error 
recovery); and subjective satisfaction. 
 
TABLE I.  
DIMENSIONS OF METHODOLOGY 
Dimension 
Sub criteria 
Definition 
Effectiveness 
  
It refers to completion of tasks where  
users achieve specific goals. 
Efficiency 
  
It refers to the resources used for 
performing a task. 
Learnability 
  
The system should be easy to learn and 
to understand; it should be easy for the 
user to achieve a task by using the 
system. 
Satisfaction 
Ease of use 
It refers to the user's perception about 
the use of the system. 
Information 
Organization 
It is to assess whether the structure, 
design, and organization of the system 
reach the users' goals. 
Clear 
Labeling 
It refers to the clear labeling of the DL 
Web site from the users’ point of view, 
and whether  the terminology used is 
easy to understand.  
Visual 
Aspect  
It evaluates the site design concerning 
its visual appealing. 
Error 
Recovery 
It has to do with the easy to  recover 
from errors made by the users. 
Navigability It refers to the easiness that users may 
have to go from one site to another . 
 
B. Questionnaire 
An important part of the usability research has been the 
designing of a questionnaire. The items for measuring the 
usability of a DL Web site, were based on the literature on 
usability evaluation studies. First, it was necessary to 
establish the dimensions. To be able to generate 
measurement 
items; 
usability 
frameworks, 
usability 
guidelines, and usability testing were reviewed [6][11][19]. 
All measurement items chosen, were modified to reflect the 
unique features of academic libraries Web sites. Thus, 
twenty items establish the questionnaire (see Table 2) to 
capture the users' perceptions on the rate of usability of 
academic DL Web sites, based on the proposed usability 
dimensions. Users must answer the questions about their 
personal experience when interacting with the DL Web site. 
C. Evaluation 
Before evaluating the usability of the DL Web site of the 
University of Puebla —which is the case study—,  the 
participants were asked to fill out a pre-questionnaire 
concerning demographic data —level of education, age, and 
gender, use frequency of the DL Web site and level of 
computer skills. The filling of the pre-questionnaire and 
usability questionnaire, were accomplished by accessing 
http://encuiti.netai.net/. In this case, it is a tool designed and 
implemented especially for this evaluation study; that allows 
the capture and analysis of data, by using the aggregation 
operators  for data processing  through LOWA and LWA.  
A total of 54 users participated in the usability evaluation 
of the DL Web site of the University of Puebla —including 
students and teachers, both undergraduate and masters.  
The pre-questionnaire was analyzed using frequency 
charts to determine the type of user, who responded to the 
survey based on their age, sex, level of education, computer 
25
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-386-5
eKNOW 2015 : The Seventh International Conference on Information, Process, and Knowledge Management

skills, and Web site usage. The usability evaluation 
questionnaire was examined bearing in mind the following 
steps: 
TABLE II.  
QUESTIONNAIRE 
Dimension 
Item 
Effectiveness 
Can you usually complete a search task by  using the DL 
Web site? 
Can  you successfully  find digital resources through the 
DL Web site? 
Do the digital resources of the DL Web site satisfy your 
needs of information? 
In general, is the DL Web site useful to help you find the 
information you are looking for? 
Efficiency 
Can you complete a task quickly by using the resources of 
the DL Web site? 
Do you obtain results quickly by using  the DL Web site? 
Does  the user interface gives you expeditious access to 
DL resources? 
Is the access to information services (databases, catalogs, 
etc.)  quick and easy to use? 
Learnability 
Was learning to use the DL Web site easy? 
Are the terms used on the DL Web site easily 
understandable? 
Is the DL Web site help well organized? 
Are new users able to utilize the services without 
considerable effort? 
Satisfaction 
What is your main fulfillment when using the DL Web 
site? 
What is the rate of navigability of the DL Web site? 
Is the organization and distribution of information on the 
DL Web site clear? 
 Is the language used on the Web site, appropriate and  
classified by tags clearly enough? 
Iis the Web site visually appealing? 
Does the Web site allow an easy error recovery? 
Are he services offered by the DL Web site satisfactory? 
Total 
Usability  
What is the general usability of the the DL Web site? 
1. The users expressed their judgment by completing the 
questionnaires (see Table 1).  
The scale for this model is S={VL=Very Low, L=Low, 
M=Medium, 
H=High, 
VH=Very 
High}.  
As a result for each one of the users uj  
(u1, 
u2,...un) 
and for each questionnaire item ik  
(i1, i2,...im),  m is 
the total number of questions; 
there is a tuple 
(mvjk,pvjk,evjk) of the minimum value —mv—, perceived 
value —pv— and the expected value —ev—, for each 
user uj  and for each question ik. 
2. To  compute the  global  users’  opinion  concerning  
each  item ik of the tuple (mv,jk, pvjk, evjk), the following 
aggregation operators are used:  
2.1 LOWA [14] is used if all users are considered to 
bear the same importance.  
mvk = Q(mv1k,…,mvnk)  
       
pvk = Q(pv1k,…,pvnk) 
evk = Q(ev1k,…,evnk) 
2.2 LWA [14] is used when each user is considered to 
bear a different level of importance. 
mvk = Q((UI(u1,i k),mv1k),…, (UI(un,i k),mvnk))       
pvk = Q((UI(u1,i k),pv1k),…, (UI(un,i k),pvnk)) 
evk = Q((UI(u1,i k),ev1k),…, (UI(un,i k),evnk)) 
Where UI(uj,i k)  S is the level of relative linguistic 
importance assigned to a user uj for the item  ik. 
3. The overall review of all questions of the tuple (mv,pv,ev)  
is calculated similarly to the previous step, by using 
aggregation operators: 
LOWA [14] is used when all the items are considered to 
bear the same importance. 
mvk = Q(mv1,…,mvm) 
    
     
pvk = Q(pv1,…,pvm) 
evk = Q(ev1,…,evm) 
LWA [14] is used when each item is considered to carry 
a different level of importance. 
mv = Q((II(i1),mv1),…, (II(im),mvm)) 
 
pv = Q((II(i1),pv1),…, (UI(im),pvm)) 
ev = Q((II(i1),ev1),…, (UI(im),evm)) 
Where II(ik) S is the level of relative linguistic 
importance assigned to item ik. 
4. The gap theory of service quality is applied to each item. 
The tolerance zone is located between the minimum and 
the expected values. The difference between the 
perceived and the minimum values, is called Service 
Adequacy —SA— and the Service Superiority —SS— is   
the difference between the expected values and the 
perceived ones. Therefore, for each item ik , SAk and SSk 
are computed  as follows [9]: 
SAk = D(pvk, mvk) 
                
SSk = D(evk, evk) 
 On the other hand, when utilizing questionnaires for 
evaluating the usability of a Web site, it is important to 
verify the reliability of the evaluation instrument it is 
advisable to use the Cronbach's alpha. 
Cronbach’s alpha allows to quantify the level of 
reliability of a evaluation scale, built from k variables 
observed. Assuming that the variables are related to the 
qualitative interest data; the k variables should achieve 
stable, consistent measurements with a high level of 
correlation among themselves. A questionnaire is considered  
reliable when Cronbach's alpha is greater than 0.80. The 
formula for Cronbach's alpha is: 
 
 
 
Where 
 is the item variance i; 
      
 is the item variance of all observed values; 
       K in the item number of the questionnaire; 
D. Results of the Questionaries  
Both a quantitative and a qualitative analysis are 
accomplished in the usability evaluation of the DL Web site. 
The qualitative analysis focuses on calculating the 
aggregation operators LOWA and LWA; It is based on 
proposed linguistic labels on the scale. 
The LOWA operator requires to obtain the combination 
of the users’ perception for each item. Thus, Table 3 
summarizes the result of the combined aggregation of the 
users’ perception for the three assessed values: minimum, 
26
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-386-5
eKNOW 2015 : The Seventh International Conference on Information, Process, and Knowledge Management

perceived, and expected values, regarding the DL Web site 
as well as their corresponding gap. On the other hand, Figure 
1 shows a radar chart that summarizes the user responses to 
the questionnaire items on the minimum, perceived and 
expected levels. This type of chart was used to display the 
results obtained with the LOWA operator. As shown therein, 
the usability of the minimum value is reflected on the chart 
with a medium value (orange color), by most users the 
perceived one (green color) and the expected one (blue 
color) show a tendency towards a higher level of usability in 
the DL Web site. 
The LWA operator allows perceiving  the opinion of all 
users on items with a different level of importance; which is 
suitable to evaluate the usability on this paper, because it 
contemplates four dimensions: efficiency, effectiveness, 
learnability, and satisfaction. So, the level of importance  
will vary according to the dimension being assessed. In case 
of measuring effectiveness, items 1, 2, 3, and 4 would have a 
Very High (VH)  level of importance, while the remaining 
items present a Very Low (VL) level of importance as shown 
in Table 4. 
TABLE III.  
RESULTS OF THE LOWA OPERATOR 
Item 
Minimum 
Perceived 
Expected 
Usability 
Adequacy 
Usability 
Excellence 
1 
M 
H 
H 
L 
VL 
2 
M 
H 
H 
L 
VL 
3 
M 
H 
H 
L 
VL 
4 
M 
H 
H 
L 
VL 
5 
M 
H 
H 
L 
VL 
6 
M 
H 
H 
L 
VL 
7 
M 
H 
H 
L 
VL 
8 
M 
H 
H 
L 
VL 
9 
M 
H 
H 
L 
VL 
10 
L 
H 
H 
M 
VL 
11 
L 
H 
H 
M 
VL 
12 
L 
H 
M 
M 
L+ 
13 
L 
H 
M 
M 
L+ 
14 
L 
H 
M 
M 
L+ 
15 
M 
H 
H 
B 
VL 
16 
M 
H 
H 
B 
VL 
17 
L 
H 
H 
M 
VL 
18 
L 
H 
H 
M 
VL 
19 
M 
H 
H 
L 
VL 
20 
M 
H 
H 
L 
VL 
 
 
 
Figure 1.  Radial chart of the LOWA operator. 
TABLE IV.  
LWA OPERATOR FOR THE EFFECTIVENESS DIMENSION 
LWA: Effectiveness  
Minimum 
Perceived 
Expected 
M 
H 
H 
On the other hand, concerning the quantitative analysis, 
item 20 has been planted to measure the satisfaction of  the 
user’s overall usability of the DL Web site. Figure 2. 
displays that 21 out of the 54 respondents have a High (H) 
overall satisfaction when evaluating the DL Web site 
usability; while 12 of them show a VH level; 16  show a 
Medium (M) value, and the other 5 present a Low (L) value. 
As mentioned above, the evaluation questionnaire 
reliability, was calculated using Cronbach's alpha, obtaining 
a value equal to 0.91 for the minimum value; 0.91 for 
perceived value; and 0.92 for the expected value, which 
means such a reliability is fairly acceptable.  
 
Figure 2.  Chart of the Total Usability (20 items). 
E. Commendations  
On the whole, the usability evaluation results of the   DL 
Web site in the University of Puebla, have been satisfactory. 
However, the adequacy gap indicates that the improvement 
should focus primarily on two-dimensions; learnability and 
satisfaction. 
In the former, the adjustments should be directed to 
improve the functions of help. So, it is advisable to follow 
the guidelines provided by ISO, IBM and Microsoft, in order 
to meet the standards of the interface design. Thus, 
improving, incorporating, and maintaining the support 
functions visible (in addition to video tutorials) for guiding 
users —especially the novices—. 
While in the latter, the changes should be oriented to 
improve the navigability, the interface and the error 
recovery. Consequently, including icons or links that allow 
return to a previous state of the system or even the main 
menu of the library is recommended as well as messages, 
which clearly inform and orient about the task of search 
being performed. As for the interface, three commendations 
are made: To modify its organization to simplify and 
improve its navigability; to focus on the services offered by 
the library, eliminating or reducing those that are strange to 
it, and using a clear terminology that would improve the 
appearance of the Web site. These interface adjustments help 
to simplify the management system errors. All the 
27
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-386-5
eKNOW 2015 : The Seventh International Conference on Information, Process, and Knowledge Management

aforementioned would facilitate the usability of the DL Web 
site in the University of Puebla, as a result, an excellent 
service can be provided. 
VI. 
CONCLUSIONS AND FUTURE WORK 
In this work, an innovative methodology for evaluating 
the usability of digital libraries has been developed. In 
developing the methodology, the basic principles of usability 
(establishing four dimensions, the questionnaire and the 
measurement scale) have been combined with models of 
service quality (the gap theory of service quality) and fuzzy 
logic models (LOWA and LWA linguistic operators) 
specifically applied in evaluating the usability of DLs.  
This methodology could be used to evaluate any Web 
sites. However, some particular questions (such as 
responsive design and real time responses) should be 
analyzed, which are out of reach on this analysis. 
In this research a measuring instrument (questionnaire) 
with 20 questions that collects user perceptions based on the 
four dimensions proposed to evaluate the usability of DL is 
intended. Moreover, the use of aggregation operators of 
linguistic information with a measurement scale was raised 
five linguistic labels. The gap in quality service has set the 
pace to suggest a number of commendations for improving 
the BUAP DL Web site. 
Cronbach's alpha was used for verifying the reliability of 
the measurement instrument, resulting in a value close to 1, 
indicating a rather acceptable measurement instrument. A 
qualitative study was also carried out using descriptive 
statistics to compare the results with those obtained with the 
aggregation operators, which showed that the use of these 
operators is appropriate for the methodology. 
     Future work will focus on applying the survey again after 
a trial using the DL Web site in order to accomplish a 
comparative analysis, improving the survey tool used in such 
a manner that allows diverse linguistic quantifiers be used to 
calculate the weights of aggregation operators. 
ACKNOWLEDGMENT 
This paper has been supported by the Spanish 
“Ministerio de Ciencia e Innovación” under projects 
TIN2011-28538-C02-02 and TIN2013-42741-P. 
REFERENCES 
[1] M. Pearrow, Web site usability handbook. Rockland, MA: 
Charles River Media. 2000. 
[2] J. 
Nielsen, 
Usability 
engineering. 
Cambridge, 
Mass: 
Academic Pr. 1993. 
[3] S. Hammill, “Usability testing at Florida International 
University Libraries: what we learned,” Electronic Journal of 
Academic and Special Librarianship, vol. 4(1). 2003. 
[4] A. Oulanov and E.F.Y. Pajarillo, “CUNY+ Web: usability 
study of the Web-based GUI version of the bibliographic 
database of the City University of New York (CUNY),” The 
Electronic Library, vol. 20 (6), pp.481-487, 2002. 
[5] K. P. Lee, A study on the improvement plan by analyzing user 
interaction pattern with the RISS. Technical Report KR2004-
17, KERIS, Seoul 2004. 
[6] J. Jeng, “Usability assessment of academic digital libraries: 
Effectiveness, efficiency, satisfaction, and learnability,” 
International Journal of Libraries and Information Services, 
vol. 55, pp. 96–121. 2005. 
[7] S. Joo, S. Lin, and K. Lu, “A Usability Evaluation Model for 
Academic Library Websites: Efficiency, Effectiveness and 
Learnability,” Journal of Library and Information Studies vol. 
9 (2), pp.11-26, 2011. 
[8] A. Alasem, “Evaluating the Usability of Saudi Digital 
Library's Interface (SDL),” In Proceedings of the World 
Congress on Engineering and Computer Science 2013 Vol I 
WCECS 2013, San Francisco, USA, pp. 23-25, October 2013,  
[9] R. Kengeri, D. Seals, H. Reddy, H. Harley, and E. Fox, 
“Usability study of digital libraries: ACM, IEEE-CS, 
NCSTRL, NDLTD,” International Journal on Digital 
Libraries Vol. 2, pp. 157–69, 1999. 
[10] X. Zhang, J. Liu, Y. Li, and Y. Zhang “How usable are 
operational digital libraries – A usability evaluation of system 
interactions. Proceedings of the ACM SIGCHI Symposium on 
Engineering Interactive Computing Systems, Pittsburgh, pp. 
177-186, July 2009. 
[11] C. Cook, F. Heath, and B. Thompson, Score norms for 
improving library service quality: A LibQUAL+ study. 
Portal: Libraries and the Academy, vol. 2 (1), pp. 13–26, 
2002. 
[12] A. 
Parasuraman, 
V.A. 
Zeithaml, 
and 
L.L. 
Berry, 
“SERVQUAL: A Multiple-Item Scale for Measuring 
Customer Perceptions of Service Quality,” Journal of 
Retailing, vol. 64, pp.12-40, 1988. 
[13] M. Kyrillidou and S. Giersch, “Developing the DigiQUAL 
protocol for digital library evaluation,” In M. Marlino, T. 
Summer, & F. Shipman (Eds.), Proceedings of the Fifth 
ACM/IEEE-CS Joint Conference on Digital Libraries, pp. 
172-173. New York: ACM Press. 2005. 
[14] R. Heradio, F.J. Cabrerizo, D. Fernández-Amorós, M. 
Herrera, and E. Herrera-Viedma, “A  fuzzy  linguistic  model  
to  evaluate  the  quality  of  Library 2.0  functionalities,” 
International Journal of Information Management, vol. 33, pp. 
642– 654, 2013. 
[15] V.A. Zeithaml, L.L. Berry, and A. Parasuraman, Delivering 
Quality Services - Balancing Customer Perceptions and 
Expectations. The Free Press, New York, 1990. 
[16] L.A. Zadeh, “The concept of a linguistic variable and its 
applications to approximate reasoning. Part III,” Information 
Sciences, vol. 9 (1), pp. 43–80, 1975. 
[17] F. Herrera, E. Herrera-Viedma, and J.L. Verdegay, “Direct 
approach processes in group decision making using linguistic 
OWA operators,” Fuzzy Sets and Systems, vol. 79, pp. 175–
190, 1996. 
[18] International Organization for Standardization, Technical 
Committee of Ergonomics, 1998. Ergonomic requirements for 
office work with visual display terminals (VDTs): Part 11: 
Guidance on usability (ISO No. 9241-11). 
[19] J. Nielsen and R.L. Mack, Usability inspection methods, eds. 
1994. New York: Wiley. 
[20] B. Shackel, Usability - context, framework, definition, design 
and evaluation. In B. Shackel & S. Richardson (Eds.), Human 
factors for informatrics usability, pp.21-37. Cambridge: 
Cambridge University Press. 1991. 
[21] G. 
Tsakonas, 
S. 
Kapidakis, 
and 
C. Papatheodorou, 
“Evaluation of user interaction in digital libraries,” Notes of 
the DELOS WP7 Workshop on the Evaluation of Digital 
Libraries. pp. 45–60, 2004. 
[22] H. Xie, “Users’ evaluation of digital libraries (DLs): their 
uses, their criteria, and their assessment,” Information 
Processing and Management. Vol. 44(3), pp. 1346–1373. 
2008. 
28
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-386-5
eKNOW 2015 : The Seventh International Conference on Information, Process, and Knowledge Management

