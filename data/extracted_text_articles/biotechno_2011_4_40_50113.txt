Computational Modeling of
Robust Figure/Ground Separation
Marc Ebner
Eberhard Karls Universit¨at T¨ubingen
Wilhelm-Schickard-Institut f¨ur Informatik
Cognitive Systems, Sand 1
72076 T¨ubingen, Germany
marc.ebner@wsii.uni-tuebingen.de
Stuart Hameroff
Departments of Anesthesiology and Psychology
and Center for Consciousness Studies
The University of Arizona
Tucson, Arizona 85724, USA
hameroff@u.arizona.edu
Abstract—It is unknown which computational method the
brain uses to perceive a visual scene. Given current advance-
ments, it is now possible to model perceptual processes of the
brain using spiking neural network models. We have developed
a computational model for robust ﬁgure/ground separation. The
model is based on a laterally connected sheet of spiking neurons.
The sheet of neurons receives its visual input from a virtual
retina. It is assumed to be located inside V1 or a higher visual
area. The neurons are assumed to be laterally connected to
their nearest neighbors through gap-junctions. These lateral
connections allow the neurons to exchange information and
therefore allow for robust ﬁgure/ground separation. Even though
we only show results for visual signals, the method is quite general
and may be used in various areas of the brain. A result of
the lateral coupling is that the neurons synchronize their ﬁring
behavior resulting in the so called gamma-synchrony which is
also a result of our computational model.
Index Terms—visual perception; spiking neurons; lateral-
coupling; gap-junctions; gamma-oscillations
I. INTRODUCTION
In computational neuroscience, one tries to understand how
the brain actually processes information at the neural level.
The goal is to seek an algorithmic description. Once this
description is obtained it may be used to simulate the same
behavior in another medium, i.e. on a computer. We are still
a long way from being able to fully understand how human
visual processing works. However, we have been able to show
how the brain can process visual information using a sheet of
spiking neurons. Our sheet of neurons is laterally connected to
neighboring neurons. The connections (assumed to be due to
gap junctions) allow the neurons to exchange data with their
neighbors and therefore tune their ﬁring behavior such that the
relevant neurons collectively respond to a certain stimulus.
Our contribution is to extend the spiking neuron model to
include lateral connections. We provide a complete algorithmic
description of our theoretical model which can be used for
comparison with real data or for predictions. We show how
the sheet of neurons automatically adapts its behavior so as to
robustly extract a ﬁgure from ground.
In our simulations, we model a single sheet of neurons. The
input to this sheet of neurons is assumed to come from a virtual
retina, i.e. from neural cells responding to visual stimuli.
Hence, the sheet of neurons perceives and represents a visual
scene. Even though we only show results for visual stimuli, the
method is quite general and may be used to process arbitrary
signals. It could also be used to process haptic or auditory
information. Our model assumes that cells performing a related
function are connected through gap junctions while no lateral
connection exists between cells tuned to process different
kinds of information. Since a gap-junction can be modeled as
a resistive connection, the entire set of interconnected neurons
form a resistive grid. This resistive grid causes the neurons
to laterally exchange part of their activation level with nearby
neurons provided that the connected gap junction is in an open
state. The resistive grid is also used to temporally and spatially
average the incoming spikes. This enables the network to tune
their behavior and to perform robust ﬁgure/ground separation.
The temporally and spatially averaged signal is used as an
adjustive signal for the neuron. Depending on this signal,
the gap junctions open or close. When the temporal average
of the neuron’s dendritic input is above the spatial average
of the neuron’s dendritic input, then the gap junction opens
it’s connection. If the temporal average is below the spatial
average, then the gap junction closes. Once, the gap junction
between two neurons is open, then these two neurons exchange
part of their activation, thereby synchronizing their ﬁring
behavior. Eventually, other nearby neurons will also open their
gap junctions, thereby forming an extended zone of laterally
connected neurons with synchronized ﬁring behavior. All of
the neurons whose receptive ﬁeld shows part of the ﬁgure will
ﬁre in synchrony. Neurons for which the ﬁgure is outside the
receptive ﬁeld will ﬁre out of sync and at a much lower rate.
II. SPIKING NEURAL NETWORKS
Sensory perception, motor control and learning are due to
the neural processing which occurs inside the brain. The brain
itself is usually modeled as a set of spiking neurons [2]. In
this standard model, each neuron independently integrates the
electrical inputs which it receives from other neurons. This
happens until the activation of the neuron rises above a certain
level or threshold. Once this happens, the neuron is said to ﬁre.
The neuron then sends an electrical impulse or signal along
the axon. This signal may then be integrated by other neurons
which eventually will also ﬁre.
67
BIOTECHNO 2011 :  The Third International Conference on Bioinformatics, Biocomputational Systems and Biotechnologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-137-3

It is standard practice to only model the spiking behavior
of neurons as this is thought to be the most relevant aspect
of neural information processing. It is assumed that the entire
function of the neuron can be replicated by only modeling the
spiking behavior of the neuron. Low level interactions between
neurons, i.e. at the level of neuro transmitters and ion channels,
are thought not to be relevant to replicate neural processing.
Hence, these aspects are usually omitted in computational
modeling. By abstracting and given powerful computational
resources, it is possible to even model thalamocortical systems
[1].
In the standard so called integrate and ﬁre model, each
neuron is viewed as a functional unit. The neuron integrates the
input received through the dendrites. Once a given threshold is
reached, then the neuron is said to ﬁre. The input of a neuron is
due to electrical signals received via axons from other neurons.
Whenever a neuron ﬁres, then a voltage spike is sent along
its axon. This electrical signal is received by other neurons
through their dendrites (and also via their cell bodies). Each
neuron integrates its input over time resulting in a buildup of
the activation potential. If the activation potential of a cell is
high enough, then the neuron will again send a spike down its
axon. This signal will be integrated by other neurons and the
process continues.
Let Vi be the activation potential of neuron i of a larger
network. The change of the activation potential Vi can be
modeled by the following equation (modiﬁed from [3]):
C dVi
dt = gi(Ei − Vi) + Itonic + Ii +
N
X
j=1
wijKj
(1)
Here, C is the capacitance of the neuron. The factor gi is
the leakage conductance. This factor will determine the speed
with which the cell will eventually reach the resting potential
Ei if no input is received. A tonic current can be modeled
through the term Itonic. An input current to neuron i from
an external source can be provided through the term Ii. Let
Kj be the input received from neuron j. Each input will be
weighted with factors wij describing the connection strength
between neurons i and j. The connection strengths can be
tuned through neural learning. The input of a neuron is the
weighted sum over all its inputs received from other neurons.
In this standard neural model, an important ingredient is
missing. Lateral connections between neurons are not consid-
ered. We ﬁnd such lateral connections between neurons to be
highly useful for signal processing. The lateral connections
allow the neurons to exchange data with their immediate
neighbors and thereby to collectively tune the response to a
given stimulus.
III. LATERAL CONNECTIONS
Our model neuron extends the standard model by also
including lateral connections between neurons. Similar to the
standard model, the neuron temporally integrates the incoming
spikes. This leads to a rise of the activation voltage until a
particular threshold is reached. Once this happens, the neuron
dendrites
neuron (gap junction)
connection to neighboring
spatial averaging of
input (conditional)
input (unconditional)
spatial averaging of
spike generation
axon
can be open or
closed
thresholding
gap junction
temporal averaging
of input
temporal averaging of input for
conditional opening of gap junctions
Fig. 1.
Artiﬁcial neuron. Each neuron is laterally connected via gap junctions
to several other neurons (only 4 gap junctions are shown).
sends a spike along its axon, i.e. it ﬁres. In contrast to the
integrate and ﬁre model, our neuron includes lateral connec-
tions which as assumed to be due to gap junctions between
neurons. Only neurons which perform a similar function are
assumed to be laterally connected. During development, lateral
connections may just occur completely at random. In the
course of time, some neighboring neurons will ﬁre together by
chance. This may lead to gap junctions between these neurons.
The laterally connected neurons will form a sub-network. A
gap junction can be modeled as a resistive connection between
neurons [4], [5]. Hence, the connected neurons form a resistive
grid. Since the gap-junctions are always there, the gap-junction
connections form an unconditional resistive grid. This resistive
grid is used to adaptively tune the neuron to a given stimulus.
A gap junction may be in one of two states. It can be open
or closed. The state that is chosen is voltage dependent. A
voltage dependent conductance of gap junctions was also used
by Traub et al. [6]. In our model, a channel is opened for each
open gap junction allowing the connected set of neurons to
exchange part of their activation. This leakage current causes
the conditionally connected neurons to synchronize their ﬁring
behavior. In computational modeling, an open gap junction
is modeled as a resistor. The synchronization of laterally
connected neurons occurs in the same way that chaotic or non-
linear electrical circuits synchronize their behavior if they are
resistively connected, i.e. a signal is exchanged between the
two circuits [7]–[9].
The input spikes passing next to each gap-junction are
temporally integrated and, through the resistive grid, also
spatially averaged. The spatially averaged input results in an
adjustive signal for the neuron. Gap junctions open and close
depending on this signal. In our model, we call this signal the
sync-threshold. Gap junctions open if the temporal average of
a neuron’s input is above the spatial average. Otherwise, the
gap junctions close.
An illustration of our neuron including lateral connections is
shown in Figure 1. The lateral connections are shown extrud-
ing from the body of the neuron in order to make clear that this
68
BIOTECHNO 2011 :  The Third International Conference on Bioinformatics, Biocomputational Systems and Biotechnologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-137-3

is a connection to other neurons on the same level. In reality,
the gap-junctions are located on the dendrites which are shown
on the left part of Figure 1 leading up to the neuron body. The
neuron receives its input through the dendrites. This input is
temporally integrated as is illustrated by the center box labeled
“
R
dt”. The same input is also temporally integrated (although
with a different factor) and also spatially averaged at each gap-
junction as illustrated by the boxes “
R
dt and “
R
dx”. Figure
1 shows 8 dendritic connections but only 4 gap-junctions in
order not to overload the ﬁgure. In an actual neuron, the
connections are not necessarily uniformly distributed. For each
gap-junction, two connections are shown. One dark connection
and one light connection. The lighter connection illustrates the
resistive grid that is formed because the gap-junction exists.
The darker connection illustrates the conditional connection
between neighboring neurons as the gap junctions open or
close (sphere on the dark lateral connection). If the temporal
average of the incoming signal is clearly above the spatial
average, then the gap junctions open. If the temporal average
is below the spatial average, then the gap junctions close.
The dendritic input to the neuron is integrated by the second
box labeled “
R
dx”. Note that this input passes through the
ﬁrst box labeled “R dx” which is the integration due to the
unconditional resistive grid. If the gap junction is open, part
of the activation will be exchanged between the connected
neurons. The current will ﬂow from the neuron having a higher
activation to the neuron having a lower activation. This causes
the connected neurons to synchronize their ﬁring behavior. If
the activation of the neuron rises above a threshold (illustrated
by the “Threshold”-box), then the neuron will ﬁre. In this case,
an electrical impulse is sent along the axon. This is illustrated
by the box with the spike.
A connected network of such neurons is able to extract
an arbitrary signal which is above the average. The same
function could also be achieved with multiple interconnected
neurons. It could be that the above behavior illustrated within
a single neuron is actually spread over multiple neurons inside
a cortical column. See Mountcastle [10] for a review of
columnar organization of the neocortex.
IV. ROBUST FIGURE/GROUND SEPARATION
In order to evaluate our model, we ﬁrst start off using
virtual stimuli. A sheet of 1000 laterally connected neurons
is simulated. This sheet of neurons processes input from a
virtual retina. The 1000 neurons are randomly placed inside a
100×100×2 area. It would sufﬁce to model a two-dimensional
sheet of neurons. However, we have used a three-dimensional
sheet in order to include the fact that actual neurons are
not perfectly positioned inside a two-dimensional plane. Let
(xi, yi, zi) be the position of the i-th neuron inside the three-
dimensional area. Each neuron is laterally connected to its
6 nearest neighbors the sheet. Input to neuron i is provided
by a virtual retina. The receptive ﬁeld of neuron i is mapped
topographically from its position inside the sheet to the retinal
neurons. Let xi, yi, and zI be the normalized coordinates with
range [0, 1], then neuron i receives its input from position
(wxi + xr, hyi + yr) where w is the width of the retina and
h is the height of the retina and (xr, yr) is a random offset
selected from −1, 0, 1.
Our sheet of neurons could theoretically be located inside
V1, however, it is more likely to be located in some higher
visual area. It could be used wherever a signal has to be sepa-
rated from ground. Below, we will show how the network can
be used to separate a lighter signal from a darker background.
The same network, however, can also be used to separate
more complicated signals which depend on motion or texture.
Neurons processing these features would be located in V3 or
V5 or inside higher areas [11], [12].
The human visual system uses two different types of recep-
tors: rods and cones. The cones are used for color vision. Three
different cones can be distinguished. Their peak response
lies either in the red, green or blue parts of the spectrum
[13]. The retinal receptors measure the light falling onto
the retina. The information is then passed on to the lateral
geniculate nucleus and ﬁnally reaches V1. By the time, the
visual information has reached the visual cortex, it has been
transformed from a red-green-blue coordinate system to a
rotated coordinate system. This rotation is caused by color
opponent and double-opponent cells. The axes of the rotated
coordinate system are: bright-dark, red-green and yellow-
blue [14]. For our experiments, we will be using only the
bright-dark channel (also called lightness). We process data
which is stored as computer images. The transformation from
red, green, and blue non-linear pixel intensities (R, G, B)
is given by L = 0.299R + 0.587G + 0.114B [15]. Each
neuron i of our sheet receives lightness L from 3 different
positions of the virtual retina. The mapping from neurons to
their input is deﬁned as described above. Thus, we have for
the output oi of the retinal neuron i: oi = L(x′
i, y′
i) with
(x′
i, y′
i) = (wxi + xr, hyi + yr).
Each neuron is fully described by the following state
variables: ai activation, ti ﬁre-threshold, oi output voltage,
˜ai, temporal average of incoming spikes, ¯ai spatial average of
temporal average. The variable ˜ai is actually associated with
every gap-junction. However, we have used one variable per
neuron to speed up the simulation. The algorithm which is run
by each neuron i is shown in Figure 2. Due to the leakage fac-
tors, the state variables can be initialized with random values at
the start of the algorithm. For our experiments, we have used
the following parameters: αa = 0.9995 decay of activation
potential, αo = 0.5 decay of output voltage, αt = 0.001
temporal averaging factor of gap-junction, αs = 0.0001 spatial
averaging factor of gap-junction input, ǫ = 0.0001 leakage to
adjacent neurons upon ﬁring, γ = 0.0005 reduction of ﬁre-
threshold, ω = 1.999 factor for over-relaxation, ∆tr = 10
refractory period of neuron, wij = 1 weight between neurons
i and j. We have used only positive unit weights because the
input image is directly processed by the neural sheet. In the
brain, the weights can be found using neural learning, e.g.,
Hebbian learning [16]. Of couse, it is also possible to include
negative weights. Negative weights would represent inhibitory
signals. The type of weights that have to be used, are of course
69
BIOTECHNO 2011 :  The Third International Conference on Bioinformatics, Biocomputational Systems and Biotechnologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-137-3

(01)
oi = (1 − αo)oi // decay of output
(02)
ai = (1 − αa)ai // decay of activation
(03)
ai = ai + αa
P
j wijoj // integrate input
(04)
˜ai = (1 − αt)˜ai + αt
P
j wijoj // temporal average
(05)
¯a′′ = ¯ai // save previous result
(06)
¯a′ =
1
1+|N|
P
j∈N ¯ai // compute spatial average
(07)
¯ai = (1 − αs)¯a′ + αs˜ai // add temp. average
(08)
¯ai = (1 − ω)¯a′′ + ω¯ai // use over-relaxation
(09)
if (˜ai > ¯ai) open gap junctions
(10)
else close gap junctions
(11)
if Neuron i ﬁred within ∆tr return
(12)
N = {j|Neuron j is laterally connected to
(13)
neuron i via open gap junction }
(14)
a′ = ai; n = 1 // initialize spatial averaging
(15)
for all j ∈ N do : if Neuron j did not ﬁre within ∆tr
(16)
{ a′ = a′ + aj; n = n + 1 }
(17)
ai = a′/n // spatial averaging completed
(18)
// distribute sp. avg to neighboring neurons
(19)
for all j ∈ N do : if Neuron j did not ﬁre within ∆tr
(20)
{ aj = ai; }
(21)
ti = max[0, 1 − γ · Ns] // comp. ﬁre-threshold
(22)
if (ai > ti) {// does the neuron ﬁre?
(23)
ai = 0 // reset activation
(24)
oi = 1 − ǫ|N| // output rises to 1
(25)
for all j ∈ N do : aj = aj + ǫ // distribute leakage
(26)
}
Fig. 2.
Algorithm of neuron i
dependent on the problem that has to be solved. For our task,
unit weights sufﬁce. The parameter Ns denotes the number of
neurons in the sub-network.
In the following, we will refer to the line numbers of Figure
2 in order to explain what the neuron does. First, the output
voltage (01) as well as the activation (02) decays. Each neuron
integrates the input (03). The gap junctions are controlled
depending on whether the temporal average of the input is
above the spatial average (09-10). The temporal average of the
input is computed in (04). The spatial average of the temporal
average is computed using over-relaxation in (05-08). This
spatial average is basically an adaptive threshold which allows
for adaptive ﬁgure/ground separation.
Note that in an earlier model [17], we have used the
ﬁring signal of the neuron as a feedback signal to control
all of the gap-junctions at the same time. It is probably more
accurate, that each gap-junction is controlled independently
by the temporal average of the signal passing through the
dendrite where the gap-junction is located. Thus, according to
our theory, each gap-junction opens or closed independently
of the other gap-junctions depending on the signal that passes
through its dendrite. The algorithm that we use for our
simulation, nevertheless takes the signal running through all of
the dendrites as a single input and controls all gap-junctions
of a neuron at the same time. This allows for faster simulation
of the entire sheet of neurons.
Condition (09) ensures that the brightest stimulus is ex-
tracted. Parts of the image with high lightness correspond to
the ﬁgure whereas other parts with low lightness correspond
to the background. Processing continues if the neuron is no
(d)
 0
 0.005
 0.01
 0.015
 0.02
 0.025
 0.03
 0
 0.2
 0.4
 0.6
 0.8
 1
frequency in percent
lightness
sync-threshold
 0
 0.005
 0.01
 0.015
 0.02
 0.025
 0.03
 0
 0.2
 0.4
 0.6
 0.8
 1
frequency in percent
lightness
sync-threshold
 0
 0.005
 0.01
 0.015
 0.02
 0.025
 0.03
 0
 0.2
 0.4
 0.6
 0.8
 1
frequency in percent
lightness
sync-threshold
histogram
(a)
(b)
input image
sheet of neurons
(c)
 0
 0.005
 0.01
 0.015
 0.02
 0.025
 0.03
 0
 0.2
 0.4
 0.6
 0.8
 1
frequency in percent
lightness
sync-threshold
Fig. 3.
Experimental results for different noisy input images (zero mean,
standard deviation 0.05). The relationship between background lightness
Lb and ﬁgure lightness Lf is (a) Lb/Lf =0.1/0.3 (b) Lb/Lf =0.3/0.5 (c)
Lb/Lf =0.5/0.7 (d) Lb/Lf =0.7/0.9
longer in its refractory period (11). Lines (12-20) distribute
part of the activation across open gap junctions. The acti-
vation ﬂows from the neuron having a higher activation to
neighboring neurons having a lower activation. This causes
adjacent neurons with open gap-junctions to synchronize their
ﬁring behavior. The ﬁre-threshold is set depending on the
size of the connected sub-network (21). If the connected sub-
network is large, then the threshold is lowered, whereas if the
connected sub-network is small, then the threshold is higher.
This causes neurons belonging to a larger object to ﬁre with
a higher frequency. Once the neuron ﬁres (22-26), most of
the activation is sent along the axon. However, part of the
activation is also distributed to neighboring neurons.
A single neuron could also perform a bright/dark classi-
ﬁcation with a proper choice of parameters. However, such
a neuron will not be adaptive to the image content. Figure
3 shows the results for different input images with static
noise. The input received by the retinal neurons is shown
on the left hand side. The sheet of neurons is shown in the
middle. Each neuron is marked by a dot. Open gap junctions
between neurons are drawn with colored lines. The right
hand side shows the distribution of the lightness of the input
image. In Figure 3(a) both background and the foreground
square (ﬁgure) are quite dark. Subsequently, in cases (b-d),
the lightness is increased. We can see that for input image (a),
a lightness of 0.3 is classiﬁed as ﬁgure because the background
has a lower lightness, e.g., 0.1. However, for case (d), a
lightness of as high as 0.7 is classiﬁed as background because
70
BIOTECHNO 2011 :  The Third International Conference on Bioinformatics, Biocomputational Systems and Biotechnologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-137-3

Vs
Vs
4
Vs
5
1
1
(a)
2
(b)
2
3
3
Vs
4
Vs
5
Vs
6
6
Fig. 4.
(a) input stimulus (b) behavior of six different neurons (marked).
Neurons 1-3 are located on the ﬁgure and show synchronous ﬁring behavior
whereas neurons 4-6 are located on the background and ﬁre out of sync.
Vs
Vs
4
Vs
5
1
1
(a)
2
(b)
2
3
3
Vs
4
Vs
5
Vs
6
6
Fig. 5.
(a) input stimulus (b) behavior of six different neurons (marked).
Neurons 1-3 are located on the ﬁgure and show synchronous ﬁring behavior
whereas neurons 4-6 are located on the background and ﬁre out of sync.
the ﬁgure has a higher lightness of 0.9. Thus, we see that our
network is able to adapt to the image content and extract the
correct ﬁgure. It is also robust in that it is able to cope with
noisy input stimuli.
By using other types of input with appropriate weights in
(03) and (04), arbitrary stimuli can be extracted. For instance,
one could envisage a sheet of neurons processing input from
V4 (color) or V5 (motion). Such a sheet could be tuned to
extract a moving color stimulus.
Figure 4 shows that the neurons that have their receptive
ﬁeld on the ﬁgure ﬁre in synchrony while other neurons ﬁre
out of sync. Figure 4(a) shows the neural sheet overlaid on
the input image. The output of six different neurons is shown
in Figure 4(b). Figure 5 shows what happens for a stimulus of
larger size. In this case, the neurons increase their ﬁring rate.
This effect is due to the adaptive threshold that is computed
in Figure 2(21). Higher visual areas can discern objects of
different sizes based on their ﬁring rate.
Figure 6 shows how the network behaves for real input
images moving across the virtual retina. As the object or
ﬁgure moves across the retina, different neurons are activated
in the course of time. Neurons of a connected sub-network
synchronize their ﬁring rates. Different objects will have
different ﬁring rates. This allows for visual servoing techniques
[18], [19] which can be used by higher visual areas to track
an object.
V. DISCUSSION AND BASIS OF OUR MODEL
The sheet of neurons segments the scene into ﬁgure and
ground. Related work for scene segmentation includes the
work of Zhao and Breve [20]. They have used Wilson-Cowan
(f)
(a)
(b)
(d)
(e)
(c)
Fig. 6.
(a-c) Moving stimulus. (d-f) A connected sub-network tracks the
ﬁgure.
neural oscillators [21] and segmented static input. Quiles et
al. [22] have developed a visual selection mechanism and
show how their integrate and ﬁre network responds to different
static images. Their model includes short range excitatory
connections and long-range inhibitory connections. Eckhorn
et al. [23] simulated results from the visual cortex of the cat.
They simulated two one-dimensional layers of neurons and
used a moving stimulus as input. In contrast to our model, they
have used long range feeding connections connecting neurons
of the same layer. Our computational model is quite simple,
yet it shows how synchronized zones of activity can arise and
move around in the brain. These zones of activity are assumed
to correlate with conscious perception and control.
Our model of laterally connected neurons show a syn-
chronous ﬁring behavior of neurons responding to the main
stimulus (ﬁgure) whereas the remaining neurons ﬁre out of
sync. Indeed, the electroencephalogram (EEG) shows the syn-
chronized ﬁring behavior of neurons inside the frequency band
from 40 to 80Hz [24], [25] This is called gamma synchrony
EEG. A review on how gamma synchrony correlates with
perception and motor control is given by Singer [26]. The
gamma synchrony is due to inter-dendritic gap junctions [27],
[28]. Hameroff [29] has put forward the “conscious pilot”
model. According to this model, gap junctions open and
close, thereby creating synchronized zones of activity. These
zones move through the brain and convert non-conscious
cognition, i.e. cognition on auto-pilot, to conscious cognition.
A review of several different theories of conciousness is given
by Kouider [30]. Several theories of consciousness assume
re-entrant, i.e. recurrent, processing of information, e.g., the
re-entrant dynamic core hypothesis by Tononi and Edelman
[31], or the local recurrence theory by Lamme [32]. Crick
and Koch [33] have noted that humans appear not to be
aware of processing which occurs inside V1. Thus, conscious
processing probably starts somewhere above V1. According
to Zeki [34], multiple consciousnesses are distributed across
different processing sites giving rise to microconsciousness.
Attributes such as color, form and motion are bound which
then gives rise to macroconsciousness. And ﬁnally, there is a
global form of conciousness or uniﬁed consciousness which
involves linguistic and communication skills. Our model is
71
BIOTECHNO 2011 :  The Third International Conference on Bioinformatics, Biocomputational Systems and Biotechnologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-137-3

based on recurrent information processing. Hence, it is in line
with theories of Tononi and Edelman as well as the theory
of Lamme. In Zeki’s terms, our model would be a case of
microconsciousness.
Synchronized ﬁring can be achieved through either local
or global connections. Our model only uses local connections
between neurons. No global connections are required. Never-
theless, global connections could be used to pass information
on to higher areas or to provide feedback to lower areas. Wang
[35] as well as K¨onig and Schillen [36] have used global
connections to establish synchronous ﬁring. They use long
range excitatory delay connections to achieve desynchroniza-
tion across different regions. Terman and Wang [37] use a
global inhibitor to achieve desynchronization. In our model,
neurons responding to the same object will synchronize their
ﬁring behavior because they are laterally connected through
gap-junctions. Two neurons, each responding to a different
object will not be synchronized because of the dependence
of the ﬁring threshold on the size of the connected zone of
neurons.
VI. CONCLUSION
The standard integrate and ﬁre model does not take lateral
connections between neurons into account. The lateral con-
nections are assumed to occur through gap junctions which
behave like resistors. A gap junction may be either in an
open state or in a closed state. The gap-junctions form two
resistive networks. An unconditional network and a conditional
network. The unconditional network is used by our model
to tune the network to the correct input level. It computes a
spatial average of the temporally smoothed input. This spatial
average is used to set the sync-threshold by comparing it to
the temporal average of the overall input to the neuron. If
the overall input is above the spatial average, then the gap
junctions open. This causes the neuron to synchronize its ﬁring
behavior such that neurons which have their receptive ﬁeld
above the stimulus ﬁre in synchrony. We have shown that
our model allows for robust ﬁgure/ground separation both on
artiﬁcial stimuli as well as with real stimuli.
REFERENCES
[1] E. M. Izhikevich and G. M. Edelman, “Large-scale model of mammalian
thalamocortical systems,” Proceedings of the National Academy of
Sciences USA, vol. 105, no. 9, pp. 3593–3598, 2008.
[2] W. Gerstner and W. Kistler, Spiking Neuron Models.
Cambridge, UK:
Cambridge University Press, 2002.
[3] J.-P. Thivierge and P. Cisek, “Nonperiodic synchronization in hetero-
geneous networks of spiking neurons,” The Journal of Neuroscience,
vol. 28, no. 32, pp. 7968–7978, Aug. 2008.
[4] J. Herault, “A model of colour processing in the retina of vertebrates:
From photoreceptors to colour opposition and colour constancy phe-
nomena,” Neurocomputing, vol. 12, pp. 113–129, 1996.
[5] M. L. Veruki and E. Hartveit, “All (rod) amacrine cells form a network
of electrically coupled interneurons in the mammalian retina,” Neuron,
vol. 33, pp. 935–946, Mar. 2002.
[6] R. D. Traub, N. Kopell, A. Bibbig, E. H. Buhl, F. E. N. LeBeau, and
M. A. Whittington, “Gap junctions between interneuron dendrites can
enhance synchrony of gamma oscillations in distributed networks,” The
Journal of Neuroscience, vol. 21, no. 23, pp. 9478–9486, Mar. 2001.
[7] T. L. Carroll and L. M. Pecora, “Synchronizing chaotic circuits,” IEEE
Trans. on Circuits and Systems, vol. 38, no. 4, pp. 453–456, Apr. 1991.
[8] L. M. Pecora and T. L. Carroll, “Synchronization in chaotic systems,”
Physical Review Letters, vol. 64, no. 8, pp. 821–824, Feb. 1990.
[9] C. K. Volos, I. M. Kyprianidis, and I. N. Stouboulos, “Experimental syn-
chronization of two resistively coupled Dufﬁng-type circuits,” Nonlinear
Phenomena in Complex Systems, vol. 11, no. 2, pp. 187–192, 2008.
[10] V. B. Mountcastle, “The columnar organization of the neocortex,” Brain,
vol. 120, pp. 701–722, 1997.
[11] S. M. Zeki, “Review article: Functional specialisation in the visual cortex
of the rhesus monkey,” Nature, vol. 274, pp. 423–428, Aug. 1978.
[12] S. Zeki, A Vision of the Brain.
Oxford: Blackwell Science, 1993.
[13] H. J. A. Dartnall, J. K. Bowmaker, and J. D. Mollon, “Human visual pig-
ments: microspectrophotometric results from the eyes of seven persons,”
Proc. R. Soc. Lond. B, vol. 220, pp. 115–130, 1983.
[14] M. J. Tov´ee, An introduction to the visual system.
Cambridge:
Cambridge University Press, 1996.
[15] C. Poynton, Digital Video and HDTV. Algorithms and Interfaces.
San
Francisco, CA: Morgan Kaufmann Publishers, 2003.
[16] D. O. Hebb, The Organization of Behavior.
New York: Wiley, 1949.
[17] M. Ebner and S. Hameroff, “A computational model for conscious visual
perception and ﬁgure/ground separation,” in Proc. Int. Conf. on Bio-
Inspired Systems and Signal Processing, Rome, Italy,
Portugal: Science
and Technology Publications, 2011, pp. 112–118.
[18] F. Chaumette and S. Hutchinson, “Visual servo control part I: Basic
approaches,” IEEE Robotics & Automation Magazine, vol. 13, no. 4,
pp. 82–90, Dec. 2006.
[19] ——, “Visual servo control part II: Advanced approaches,” IEEE
Robotics & Automation Magazine, vol. 14, no. 1, pp. 109–118, 2007.
[20] L. Zhao and F. A. Breve, “Chaotic synchronization in 2D lattice for
scene segmentation,” Neurocomputing, vol. 71, pp. 2761–2771, 2008.
[21] H. R. Wilson and J. D. Cowan, “Excitatory and inhibitory interactions in
localized populations of model neurons,” Biophysical Journal, vol. 12,
pp. 1–24, 1972.
[22] M. G. Quiles, L. Zhao, F. A. Breve, and R. A. F. Romero, “A network of
integrate and ﬁre neurons for visual selection,” Neurocomputing, vol. 72,
pp. 2198–2208, 2009.
[23] R. Eckhorn, H. J. Reitboeck, M. Arndt, and P. Dicke, “Feature linking
via synchronization among distributed assemblies: Simulations of results
from cat visual cortex,” Neural Computation, vol. 2, pp. 293–307, 1990.
[24] C. M. Gray and W. Singer, “Stimulus-speciﬁc neuronal oscillations in
orientation columns of cat visual cortex,” Proceedings of the National
Academy of Sciences USA, vol. 86, pp. 1698–1702, Mar. 1989.
[25] U. Ribary, A. A. Ioannides, K. D. Singh, R. Hasson, J. P. R. Bolton,
F. Lado, A. Mogilner, and R. Llin´as, “Magnetic ﬁeld tomography of
coherent thalamocortical 40-hz oscillations in humans,” Proc. of the
National Acad. of Sciences USA, vol. 88, pp. 11 037–11 041, Dec. 1991.
[26] W. Singer, “Neuronal synchrony: A versatile code for the deﬁnition of
relations?” Neuron, vol. 24, pp. 49–65, 1999.
[27] R. Dermietzel, “Gap junction wiring: a ‘new’ principle in cell-to-
cell communication in the nervous system?” Brain Research Reviews,
vol. 26, pp. 176–183, 1998.
[28] A. Draguhn, R. D. Traub, D. Schmitz, and J. G. R. Jefferys, “Electrical
coupling underlies high-frequency oscillations in the hippocampus in
vitro,” Nature, vol. 394, pp. 198–192, Jul. 1998.
[29] S. Hameroff, “The “conscious pilot” – dendritic synchrony moves
through the brain to mediate consciousness,” Journal of Biological
Physics, vol. 36, pp. 71–93, 2010.
[30] S. Kouider, “Neurobiological theories of consciousness,” in Encyclope-
dia of Consciousness, W. P. Banks, Ed.
Elsevier, 2009, pp. 87–100.
[31] G. Tononi and G. M. Edelman, “Consciousness and complexity,” Sci-
ence, vol. 282, pp. 1846–1851, Dec. 1998.
[32] V. A. F. Lamme, “Towards a true neural stance on consciousness,” Trends
in Cognitive Sciences, vol. 10, no. 11, pp. 494–501, 2006.
[33] F. Crick and C. Koch, “Are we aware of neural activity in primary visual
cortex?” Nature, vol. 375, pp. 121–123, May 1995.
[34] S. Zeki, “A theory of micro-consciousness,” in The Blackwell companion
to consciousness, M. Velmans and S. Schneider, Eds.
Malden, MA:
Blackwell Publishing, 2007, pp. 580–588.
[35] D. Wang, “Emergent synchrony in locally coupled neural oscillators,”
IEEE Trans. on Neural Networks, vol. 6, no. 4, pp. 941–948, Jul. 1995.
[36] P. K¨onig and T. B. Schillen, “Stimulus-dependent assembly formation of
oscillatory responses: I. synchronization,” Neural Computation, vol. 3,
pp. 155–166, 1991.
[37] D. Terman and D. Wang, “Global competition and local cooperation in
a network of neural oscillators,” Physica D, vol. 81, pp. 148–176, 1995.
72
BIOTECHNO 2011 :  The Third International Conference on Bioinformatics, Biocomputational Systems and Biotechnologies
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-137-3

