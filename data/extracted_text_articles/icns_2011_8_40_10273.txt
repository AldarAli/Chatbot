User to User adaptive routing based on QoE
Hai Anh TRAN, Abdelhamid MELLOUK, Said HOCEINI,
University of Paris-Est Creteil Val de Marne (UPEC)
Image, Signal and Intelligent Systems Lab-LiSSi Lab
Transport Infrastructure and Network Control Group - TINC
122 rue Paul Armangot, 94400 Vitry sur Seine, France
{hai-anh.tran, mellouk, hoceini}@u-pec.fr
Abstract—Service quality can be deﬁned as “the collective
effect of service performances which determine the degree of
satisfaction of a user of the service” [1]. In other words, quality
is the customer’s perception of a delivered service. As larger
varieties of services are offered to customers, the impact of
network performance on the quality of service will be more
complex. It is vital that service engineers identify network-
performance issues that impact customer service. They also must
quantify revenue lost due to service degradation. The Quality of
Experience (QoE) becomes recently the most important tendency
to guarantee the quality of network services. QoE represents
the subjective perception of end-users using network services
with network functions such as admission control, resource
management, routing, trafﬁc control, etc. In this paper, our
main focus is routing mechanism driven by QoE end-users.
With the purpose of avoiding the NP-complete problem and
reducing the complexity problem for the future Internet, we
propose two protocols based on user QoE measurement in routing
paradigm to construct an adaptive and evolutionary system. Our
ﬁrst approach is a routing driven by terminal QoE basing on
a least squares reinforcement learning technique called Least
Squares Policy Iteration. The second approach, namely QQAR
(QoE Q-learning based Adaptive Routing), is a improvement of
the ﬁrst one. QQAR basing on Q-Learning, a Reinforcement
Learning algorithm, uses Pseudo Subjective Quality Assessment
(PSQA), a real-time QoE assessment tool based on Random
Neural Network, to evaluate QoE. Experimental results showed
a signiﬁcant performance against over other traditional routing
protocols.
Index Terms—Quality of Service (QoS), Quality of Experience
(QoE), Network Services, Routing System, Autonomous System,
Pseudo Subjective Quality Assessment (PSQA), Reinforcement
Learning.
I. INTRODUCTION
In order to reach new opportunities and improve market
competitiveness, network service providers are offering new
value-added services, such as video on demand (VoD), IPTV,
voice over IP (VoIP), etc. Consequently, improving the quality
of the services as perceived by the users, commonly referred
to as the quality of experience (QoE), has a great effect as
well as a signiﬁcant challenge to the service providers with
a goal to minimize the customer churn yet maintaining their
competitive edge. Based on this kind of quality competition,
the new term of QoE has been introduced, combining user
perception, experience and expectations without technical
parameters such as QoS parameters. In fact, the network
provider’s aim is to provide a good user experience at
minimal network resource usage. It is important from the
network operator to be aware of the degree of inﬂuence of
each network’s factor on the user perception. For users, also
for operators and Internet service providers, the end-to-end
quality is one of the major factors to be achieved. QoE takes
into account the needs and the desires of the subscribers
when using network services, while the concept of QoS
just attempts to objectively measure the service delivered.
Furthermore, e2e QoS with more than two non correlated
criteria is NP-complete (proved in [2]). With the evolution of
the Internet, both technologies and needs continue to develop,
so complexity and cost become limiting factors in the future
evolution of networks. In order to reduce this complexity
problem, one has integrated QoE in network systems. Firstly,
as an important measure of the end-to-end performance at
the service level from the user’s perspective, the QoE is an
important metric for the design of systems and engineering
processes. Secondly, with QoE paradigm, we can reach a
better solution and prevent the NP-complete problem because
our goal is just maintaining QoE criteria instead of optimizing
multiple QoS criteria.
Routing mechanism is key to the success of large-scale,
distributed communication and heterogeneous networks. In
this section, a review of some related works reveals that
various approaches have been proposed to take account of
QoS requirements. However the goal of every traditional
algorithm is to maximize many QoS criteria simultaneously.
So they meet the NP-complet problem as we mentioned
before.
The idea of applying reinforcement learning to routing in
networks was ﬁrstly introduced by [3]. Authors described
the Q-routing algorithm for packet routing. Reinforcement
learning module is embedded into each node of a switching
network. In [3], each node to keep accurate statistics on
which routing decisions lead to minimal delivery times uses
only local communication. However, this proposal focus on
optimizing only one basis QoS metric (delivery times). So
user perception (QoE) is not yet considered in this approach.
[4] proposed an application of gradient ascent algorithm
for RL to a complex domain of packet routing in network
communication. This approach updates the local policies
while avoiding the necessity for centralized control or
global knowledge of the networks structure. The only global
170
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

information required by the learning algorithm is the network
utility expressed as a reward signal distributed once in an
epoch and dependent on the average routing time. In [5],
K-Optimal path Q-Routing Algorithm (KOQRA) is presented
as a QoS based routing algorithm based on a multi-path
routing approach combined with the Q-routing algorithm.
The global learning algorithm ﬁnds K best paths in terms
of cumulative link cost and optimizes the average delivery
time on these paths. The technique used to estimate the
end-to-end delay is based on the Q-Learning algorithm to
take into account dynamic changes in networks. In [6] AV-
BW Delay Q-Routing algorithm uses an inductive approach
based on trial/error paradigm combined with swarm adaptive
approaches to optimize three QoS different criteria: static
cumulative cost path, dynamic residual bandwidth and end-to
end delay. Based on KOQRA, the approach presented here
adds a new module to this algorithm dealing with a third QoS
criterion which takes into account the end-to-end residual
bandwidth. In [7], authors use heuristics to determine a
source-to-destination path that satisﬁes two or more additive
constraints based on edge weights. [8] presented a polynomial
time approximation algorithm for k multi-constrained path
using a shortest path algorithm such as Dijkstra algorithm.
In [9], authors proposed a randomized heuristic that employs
two phases: 1) a shortest path is computed for each of the k
QoS constraints as well as for a linear combination of all k
constraints; 2) a randomized breadth-ﬁrst search is performed
for a k multi-constrained problem.
We can see that all of these approaches above do not take into
account the perception and satisfaction of end-users. In other
words, QoE concept is ignored. That poses the problem of
choosing the best QoS metric that is often complex. However
QoE comes directly from the use and represents the true
criteria to optimize. In taking into account this lack, other
proposals are presented in [10].
In [11], authors presented an overlay network for end-to-end
QoE management. The purpose is QoE optimization by
routing around failures in the IP network and optimizing the
bandwidth usage on the last mile to the client. Components of
overlay network are located both in the core and at the edge
of the network. In [12], authors propose an extended version
of the Optimized Link State Routing(OLSR) protocol. It uses
fuzzy logic to build a fuzzy system that aims to optimize
networks resources, solve the problem of using multiple
metrics for routing and try to improve the user perception.
However, these proposals do not use any adaptive mechanism.
Furthermore, they do not consider QoE as a user feedback.
[13] presented a new adaptive mechanism to maximize the
overall video quality at the client. Overlay path selection is
dynamically done based on available bandwidth estimation,
while the QoE is measured using PSQA tool, the same
measurement tool we have used. After receiving a client
demand, the video server chooses an initial strategy and an
initial scheme to start the video streaming. Then, client uses
PSQA to evaluate the QoE of the received video in real
time and sends this feedback to server. After examining this
feedback, the video server will decide to keep or to change
its strategies. This approach has well considered end-users
perception. However the adaptive mechanism is quite simple
because it is not based on the learning method. Furthermore,
the problem of this approach is the fact that authors use
source routing.
Instead of trying to optimizing many QoS criteria like
approaches above, our algorithm just based on user perception
(QoE).
In the recent years, there are many researches, proposals that
are made in order to measure, evaluate, and improve QoE in
networks. Our work aimed to construct an adaptive routing
method that can retrieve environment information and adapt
to the environment changes. This adaptive routing mechanism
maintaining the required QoE of end-users is very necessary
for network systems that have great dynamics (i.e. unreliable
communication) and multiple user proﬁles where the required
QoE levels are different. For better user’s perception, it is
preferable that a routing protocol adapts itself to these QoE
levels.
Our two proposals are routing systems driven by terminal
QoE based on Reinforcement Learning (RL) concept [14]
[15]. They aimed to maintain user satisfaction using QoE
feedback of end-users. The ﬁrst algorithm is based on Least
Squares Policy Iteration (LSPI) [16], a RL technique that
combines least squares function approximation with policy
iteration. The second algorithm, an improvement of the ﬁrst
one, is based on Q-Learning [15] which is one of the RL
algorithms. However, native Q-Learning taking into account
rewards at all nodes in the system is inadequate to our target
problem because the QoE reward is available only at the last
node (QoE is evaluated at end-users). In order to improve the
ﬁrst algorithm, we evaluate the QoE at any node in the whole
system. The QoE measurement is realized by using a hybrid
between subjective and objective evaluation method called
Pseudo Subjective Quality Assessment (PSQA) tool [17].
The paper is structured as follows: Section II describes
the QoE measurement method we have used. We present our
approaches in section III. The experimental results are shown
in section IV. Paper is ended with conclusion and some future
works in section V.
II. QOE MEASUREMENT METHOD
It is not easy to evaluate the perceived quality of a multime-
dia stream. The best way to assess it is to have real people do
the assessment because quality is a very subjective concept.
There are standard methods for organizing subjective quality
assessments, such as the ITU-P.800 [18] recommendation for
telephony, or the ITU-R BT.500-10 [19] for video. However,
subjective evaluations are very expensive and cannot be a part
of an automatic process. As subjective assessment is useless
for real time evaluations, a signiﬁcant research effort has been
done to obtain similar evaluations by objective methods. The
most commonly used objective measures for speech / audio
are Signal-to-Noise Ratio (SNR), Segmental SNR (SNRseg),
171
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

Perceptual Speech Quality Measure (PSQM) [20], Measur-
ing Normalizing Blocks (MNB) [21], ITU E–model [22],
Enhanced Modiﬁed Bark Spectral Distortion (EMBSD) [23]
and Perceptual Analysis Measurement System (PAMS) [24].
For video, some examples are the ITS’ Video Quality Metric
(VQM) [25], Color Moving Picture Quality Metric (CMPQM)
[26], and Normalization Video Fidelity Metric (NVFM) [27].
These quality metrics often provide assessments that do not
correlate well with human perception, and thus their use as a
replacement of subjective tests is limited.
So we decide to use PSQA tool, a hybrid between subjective
and objective evaluation. PSQA tool measures QoE in an
automatic and efﬁcient way, such that it can be done in real
time. It consists of training a Random Neural Network (RNN)
to behave as a human observer and to deliver a numerical
evaluation of quality, which must be close to the average
value that a set of real human observers would give to the
received streams. PSQA method includes the following steps:
a) Identifying a set of parameters having an important impact
on the perceived quality, b) Building a platform allowing to
send a video sequence through an IP connection, c) Performing
a subjective testing experiment, d) Training the RNN.
PSQA used RNN for the learning phase. Sequences are input
data of RNN that will give a real function as output. So
for any conﬁguration, the function returns a number close to
the associated MOS (Mean Opinion Score)1 value [28]. Our
testbed using PSQA tool is described in detail in section IV.
Using PSQA method gives us a function f expressed as:
f : R3 → R
(1)
This function f takes a combination of three parameter values
as mentioned above (delay time, loss rate and conditional loss
rate) to obtain a single output equivalent to the appropriate
MOS score. So from now onwards the expression of ”applying
PSQA tool” means using function f in Equation 1 with three
parameters as input to obtain the MOS score.
III. USER PERCEPTION BASED ROUTING SYSTEM
Our idea to take into account end-to-end QoE consists to
develop adaptive mechanisms that can retrieve the information
from their environment (QoE) and adapt to initiate actions.
The action choice should be executed in response to end-users
feedback, in other words the QoE feedback. Concretely, the
system integrates the QoE measurement in an evolutionary
routing system in order to improve the user perception based
on Q-Learning algorithm to choose the “best optimal QoE
paths” (Fig. 1). So in that way, the routing process is build
according to maintaining the best user perception.
In this section, we present our two approaches: our routing
system driven by terminal QoE and his improvement, QQAR
algorithm.
1Mean Opinion Score (MOS) gives a numerical indication of the perceived
quality of the media received after being transmitted. MOS is expressed in a
number, from 1 to 5, 1 being the worst and 5 the best. The MOS is generated
by averaging the results of a set of standard, subjective tests where a number
of users rate the service quality
Fig. 1: Integration of QoE measurement in routing system
A. Routing system driven by terminal QoE
In order to integrate RL notion into our routing system, we
have mapped RL model to our routing model in the context
of learning routing strategy (Fig. 2). We consider each router
in the system as a state. The states are arranged along the
routing path. Furthermore, we consider each link emerging
from a router as an action to choose. The system routing
mechanism corresponds to the policy π. After data reach end-
Fig. 2: Routing system based on reinforcement learning
users, QoE evaluation is realized to give a QoE feedback to
the system. We consider this feedback as environment reward
and our purpose is to improve the policy π using this QoE
feedback. Concretely, the policy π is chosen so that it is equal
to argmax of action value function Q in policy π:
πt+1(st) = argmaxQπt(st, a)
(2)
Least-Squares Policy Iteration (LSPI) [16] is a recently in-
troduced reinforcement learning method. Our choice is based
on the fact that this technique learns the weights of the
linear functions, thus can update the Q-values based on the
most updated information regarding the features. It does not
need carefully tuning initial parameters (e.g., learning rate).
Furthermore, LSPI converges faster with less samples than
basic Q-learning.
In this technique, instead to calculate directly action-value
function Q, this latter is approximated with a parametric
function approximation. In other words, the value function is
172
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

approximated as a linear weighted combination:
ˆQπ(s, a, ω) =
k
X
i=1
φi(s, a)ωi = φ(s, a)T ω
(3)
where φ(s, a) is the basis features vector and ω is weight
vector in the linear equation. The k basis functions represent
characteristics of each state-action pair.
We have to update the weight vector ω to improve system
policy.
Bellman equation and Eq 3 can be transformed to Φω ≈ R +
γP πΦω, where Φ represent the basis features for all state-
action pairs. This equation is reformulated as:
ΦT (Φ − γP πΦ)ωπ = ΦT R
(4)
Basing on equation 4, the weight ω of the linear functions in
equation 3 is extracted:
ω = (ΦT (Φ − γP πΦ))−1 × ΦT R
(5)
For a router s and forwarding action a, s′ is the corresponding
neighbor router with P(s′|s, a) = 1. Our learning procedure
is realized as follows: when a packet is forwarded from node
s to s′ by action a, which has been chosen by current Q-
values φ(s, a)T ω, a record < s, a, s′, φ(s, a) > is inserted to
the packet. The gathering process (Fig. 3) is realized until
the packet arrives at the destination (end-users). Thus with
Fig. 3: Learning procedure
this way, one can trace the information of the whole routing
path. At the end-users, a QoE evaluation process is realized to
give a QoE score that is the value of R vector in equation 5.
Furthermore, with the gathered information, the new value of
ω is determined using equation 5. Then this new weight value
ω′ is sent back to the system along the routing path in order to
improve policy procedure in each router on the routing path.
With the new weights ω′, policy improvement is realized in
each router on the routing path by selecting the action a with
the highest Q-value:
π(s|ω′) = argmaxaφ(s, a)T ω′
(6)
The next subsection presents the improvement of this algo-
rithm in using QoE measurement tool at all nodes of the
routing system.
B. QQAR algorithm
In order to evaluate QoE in entire system, we have applied
PSQA tool into all nodes (routers) including the last one
representing end-user station (Fig. 4). In fact, measuring
QoE anywhere in the system facilitates applying Q-Learning
into our model with the reward at any node. That is the
improvement factor of our ﬁrst approach.
The proposed routing mechanism can be formulated as fol-
lows:
• First step - Data packet ﬂow: the provider sends data
packet to end-user. After receiving this data packet, each
node in the routing path forwards the packet to the
next node with a selection process presented in detail in
subsection 2. It simultaneously evaluates QoE by using
PSQA tool and saves this result.
• Second step - At end-user side: After data reach end-user,
QoE evaluation is realized by using PSQA tool to give a
QoE feedback as ACK message to the routing path that
this data ﬂow just passes through.
• Third step - ACK message ﬂow: Each time a node receives
a ACK message, it updates the Q-value of the link
that this ACK message just passes through. The update
process is introduced ci-below (subsection 1). It then
attaches the QoE measurement result that it saved above
into the ACK message and forwards it to the previous
neighbor.
Fig. 4: QQAR routing system
With regard to a selection process in each node after receiving
a data packet, we have to consider the tradeoff between explo-
ration and exploitation. This tradeoff is one of the challenges
that arises in RL and not in other kinds of learning. To obtain
a lot of reward, a RL agent (router) must prefer actions that
it has tried in the past and found to be effective in producing
reward. But to discover such actions, it has to try actions that
it has not selected before. The agent has to exploit what it
already knows, but it also has to explore in order to make better
action selection in the future. There are some mathematical
issues to balance exploration and exploitation. In our approach,
we choose softmax method as selection process that will be
presented in the subsection 2.
1) Learning process: In our model, each router has a rout-
ing table that indicates the Q-values of links emerging from
this router. For example in Fig. 5, node y has a routing table
containing Q values: Qyz1, Qyz2, Qyz3...Qyzn corresponding
to n links from y to zi with i = 1..n. Based on this routing
table, the optimal routing path can be trivially constructed by
a sequence of table look-up operations.
173
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

As mentioned above, after receiving a data packet, the last
Fig. 5: Learning process
node representing end-user evaluates the QoE, it then sends
back feedback as ACK message to the routing path. Each
router x in this routing path receives this message containing
information: the PSQA result of the previous router (qy) and
the maximum value of Q-values (max Qyz) in the routing table
of node y (Fig. 5). Router x then updates the Q-value of the
link connecting to y. Our update function based on the native
Q-Learning (Eq ??) is deﬁned in Equation 7:
Qxy
|{z}
new value
= Qxy
|{z}
old value
+α

β (qy − qx) + γ max
i
Qyzi
|
{z
}
new estimation
− Qxy
|{z}
old value

(7)
Where Qxy and Qyzi are Q-values of links xy and yzi. qx
and qy are results obtained (MOS score) by using PSQA tool
at node x and y. α is the learning rate, which models the rate
updating Q-value. The two discount factors β and γ balance
the value between future reward and immediate reward.
2) Selection process: As mentioned above, our selection
process must balance between the exploration and exploitation
phase. It cannot always exploit the link that has the maximum
Q-value because each link must be tried many times to reliably
estimate its expected reward. Therefore, we have chosen
softmax method using Boltzmann distribution [15]. So with
this softmax action selection rules, after receiving a packet,
node x chooses its neighbor yk among its n neighbors yi
(i = 1..n) with probability presented in Equation 8:
pxyk =
e
Qxyk
τ
Pn
i=1 e
Qxyi
τ
(0 ≤ k ≤ 1)
(8)
Where Qxyi represents Q-value of link xyi and τ represents
a temperature parameter of Boltzmann distribution. High tem-
perature causes the link selection to be all equi-probable.
Low temperatures generates a greater difference in selection
probability for links that differ in their Q-values. In other
words, more we reduce the temperature τ, the more we exploit
the system. In that way, we reduce the temperature τ after each
time of forwarding packet as shown in Equation 9:
τ = φ × τ
(0 < φ < 1)
(9)
where φ is the weight parameter.
So in that way, we initially balance exploration and exploita-
tion. After that system is quite converged, we then increasingly
exploit the system.
IV. EXPERIMENT
In order to validate our proposed approach, this section
presents ﬁrstly our testbed for collecting dataset to PSQA
tool. We then describe our simulation results using OPNET
simulator.
A. Testbed for PSQA
Training RNN for PSQA tool needs a real dataset of the
impact of the network on the perceived video quality. To
construct this dataset, we conducted an experiment consist
of selecting a number of human and asked him to score
the perceived quality of video using the MOS score. The
testbed (Fig. 6) is composed by client-server architecture and a
network emulator. The client is VLC video client [29] and the
server is VLC video streaming server [29]. The trafﬁc between
client and server is forwarded by the network emulator NetEm
[30]. NetEm provides the way to reproduce a real network in
a lab environment.
The current version of NetEm can emulate variable delay,
Fig. 6: Testbed for PSQA tool
loss, duplication and re-ordering.
The experimental setup consists on forwarding video trafﬁc
between server and client. Then, we introduce artiﬁcial ﬁxed
delay, variable delay and loss on the link to disturb the video
signal.
According to ITU-R [31], the length of the video should be at
least 5sec. We choose the sintel video trailer [32]. This video
is of 52 seconds duration, 1280 x 720 dimensions and 24
frames per second cadence and uses H.264 codec. This video
was chosen because it alternates high and slow movements.
Experiments were conducted with ﬁxed delay values of [25,
50, 75, and 100ms], variable delays of [0, 2, 4, 6, 8, 16,
174
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

32ms], loss rate values of [0, 2, 4, 6, 10, 15, 20, 25, 30%]
and successive loss probability of [0, 30, 60, 90%]. These
values were chosen to cover the maximum of QoE range.
To collect data, we chooses viewers with a strong cinematic
experience.
Nowadays, as a major part of monitors are LCD, we used the
same ones. The particular screen used is a 19” size screen
“LG ﬂatron L194wt–SF“ which has 1440x900 resolution.
The obtained dataset of this testbes is used for learning process
of PSQA tool. We then obtain the function f in Equation 1
and apply the latter to our system as QoE measurement tool
(PSQA).
B. Routing system simulation results
We have used Opnet simulator version 14.0 to implement
our approach in an autonomous system. Regarding network
topology, we have implemented an irregular network with 3
separated areas including 38 routers, each area is connected
to each other by one link, all links are similar (Fig. 7). The
network system is dynamically changed with an average period
of 200 seconds.
Fig. 7: Simulation network topology
To validate our results, we compare our approach with three
kinds of algorithm:
• Those based on Distance-Vector (DV) algorithm. In this
algorithm, routers can maintain the optimal route by
storing the address of the next router in the routing table
so that the number of hops to reach the destination is
minimal. The roads are updated every 30 seconds.
• Those based on Link-State algorithm: SPF (Short Path
First). In this algorithm, each router establishes relations
with its neighbors by sending hello messages. Each router
then forwards the list of networks it is directly connected
by messages (LSA-Link State Advertisements) to spread
gradually to all routers in the network. The set of LSAs
forms the database links Link-State Database (LSDB),
which is identical for all participating routers. Each router
then uses Dijkstra’s algorithm to determine the shortest
route to each network known in the LSDB.
• Those based on Standard Optimal QoS Multi-Path Rout-
ing (SOMR) algorithm where routing is based on ﬁnding
K Best Optimal Paths and used a composite function to
optimize delay and link cost criteria simultaneously.
(a) User perception in low load trafﬁc network
(b) User perception in different load trafﬁc levels of network
Fig. 8: User perception
Fig. 8 illustrates the result of average MOS score of four
algorithms (non-charged network in 8a and different charge
levels in 8b). In the charged system case, we have generated
a trafﬁc that stress the network. The charge level represents
the rate of number of charged link and number of total link:
level = ns
N
(10)
where ns is number of charged links and N is number of total
links in the system.
In observing Fig. 8a, we can see that results of all four
algorithms ﬂuctuate very much in the ﬁrst 1500 seconds. That
is explained by the execution of initialization process. In other
words, these four algorithms do not have any information
about the system in this ﬁrst period, they try to explore it.
In these ﬁrst 1500 seconds, the MOS score of QQAR varies
between 2.5 and 4, SOMR between 2.4 and 4.1, SPF between
1.7 and 3.6, DV between 1.4 and 3.5. After the ﬁrst 1500
seconds, protocols gradually become stable. QQAR varies
between 3.4 and 3.7. DV and SPF are quite stable with average
results respectively 1.4 and 1.9. SOMR varies much more but
the maximum value (obtained in period from 2100th to 2300th
second) is still lower than QQAR.
Fig. 8b gives us the average of these four algorithms in
different charge levels formulated in (10): from 10% to 90%.
We can see that more the system is charged, the higher
the average score decreases. However, at any charge level,
the average MOS score of QQAR is better than three other
algorithms. With a charge level lower than 10%, the MOS
175
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

score of QQAR is higher than 3 (in MOS score range, 3
represents a fair quality). Regarding the three other protocols,
the maximum value obtained by SOMR is just 2.4 with charge
level 10%.
QQAR gives a better e2e QoE perception in both cases than
three other algorithms in the same delay. So with our approach,
despite network environment changes, we can maintain a
better QoE without any other e2e delay or any other QoS
metric. Thus, QQAR is able to adapt its decisions rapidly in
response to changes in the network dynamics.
Our experiment works consist also the survey of overheads
met by these protocols. The type of overhead we observe
is control overhead that is determined by the proportion of
control packet number to the number of all packets emitted.
To monitor this overhead value, we have varied node number
in adding routers to network system. So the observed node
numbers are [38, 50, 60, 70, 80]. The obtained result is
showed in Fig. 9. We can see that the control overhead of
Fig. 9: Control overhead
our approach is constant (50%). That is explained by the
equal of control packet number and data packet number in
QQAR. Each generated data packet leads to an acknowledge
packet generated by destination node. The control packet rates
of DV, SPF and SOMR are respectively 0.03, 0.4 and 0.1
(packet/second). This order explains the control overhead order
in Fig. 9. Whereas the SPF algorithm has the highest value
because of the highest control packet rate (0.4 packet/second)
with multiple type of packet such as Hello packet, Link State
(LS) Acknowledgement packet, LS Update packet, LS State
request packet, etc. , DV algorithm has the smallest overhead
value with a control packet rate value of 0.03. We can see also
that the higher the number of node, the higher the overhead
is. So with a stable overhead, our approach is more scalable
than these three others.
V. CONCLUSION
We present in this paper two approaches for routing systems
driven by terminal QoE. We have integrated QoE measurement
to routing paradigm for an adaptive and evolutionary system.
Our second approach based on Q-Learning algorithm uses
PSQA tool, a hybrid of subjective and objective method,
for QoE evaluation. The simulations obtained demonstrates
that our proposed approach yields signiﬁcant QoE evaluation
improvements over traditional approaches.
Finally, extensions to the framework for using these techniques
across hybrid networks to achieve end-to-end QoE needs to
be further investigated. Also, some future works includes
applying our protocol to large scalable real testbed to verify
its feasibility.
REFERENCES
[1] “ITU-T recommendation E.800. Quality of telecommunication services:
concepts, models, objectives and dependability planning. Terms and def-
initions related to the quality of telecommunication services,” September
2008.
[2] Z. Wang and J. Crowcroft, “Quality of service routing for supporting
multimedia applications,” IEEE Journal on selected areas in communi-
cations, vol. 14, no. 7, pp. 1228–1234, 1996.
[3] J. A. Boyan and M. L. Littman, “Packet routing in dynamically changing
networks: A reinforcement learning approach,” Advances in Neural
Information Processing Systems, p. 671, 1994.
[4] L. Peshkin and V. Savova, “Reinforcement learning for adaptive routing,”
in Neural Networks, 2002. IJCNN’02. Proceedings of the 2002 Interna-
tional Joint Conference on Neural Networks, vol. 2.
IEEE, 2002, pp.
1825–1830.
[5] A. Mellouk, S. Hoceini, and S. Zeadally, “Design and performance anal-
ysis of an inductive qos routing algorithm,” Computer Communications,
vol. 32, no. 1371-1376, 2009.
[6] S. Hoceini, A. Mellouk, and B. Smail, “Average-Bandwidth Delay Q-
Routing Adaptive Algorithm,” in ICC’08. IEEE International Confer-
ence on Communications.
IEEE, 2008, pp. 1840–1844.
[7] J. Jaffe, “Algorithms for ﬁnding paths with multiple constraints,” Net-
works, vol. 14, no. 1, pp. 95–116, 1984.
[8] S. Sahni, Data Structures, Algorithms and applications in C++.
Uni-
versities Press, 2005.
[9] B. Quoitin and S. Uhlig, “Modeling the routing of an autonomous system
with C-BGP,” Network, IEEE, vol. 19, no. 6, pp. 12–19, 2005.
[10] H. A. Tran and A. Mellouk, “Qoe model driven for network services,”
Wired/Wireless Internet Communications, pp. 264–277, 2010.
[11] B. D. Vleeschauwer, F. D. Turck, B. Dhoedt, P. Demeester, M. Wijnants,
and W. Lamotte, “End-to-end qoe optimization through overlay network
deployment,” International Conference on Information Networking,
2008.
[12] R. Gomes, W. Junior, E. Cerqueira, and A. Abelem, “A QoE Fuzzy
Routing Protocol for Wireless Mesh Networks,” Future Multimedia
Networking, pp. 1–12, 2010.
[13] G. Majd, V. Cesar, and K. Adlen, “An adaptive mechanism for multipath
video streaming over video distribution network (vdn),” First Interna-
tional Conference on Advances in Multimedia, 2009.
[14] L. P. Kaelbling, M. L. Littman, and A. W. Moore, “Reinforcement
learning: A survey,” Journal of AI Research, vol. 4, pp. 237–285, 1996.
[15] R. S. Sutton and A. G. Barto, “Reinforcement learning: An introduction,”
IEEE transactions on neural networks, vol. 9, 1998.
[16] M. G. Lagoudakis and R. Parr, “Least-squares policy iteration,” Journal
of Machine Learning Research, vol. 4, p. 1149, 2003.
[17] G. Rubino, “Quantifying the quality of audio and video transmissions
over the internet: The psqa approach,” Design and operations of com-
munication networks: a review of wired and wireless modeling and
management challenges. Imperial College Press, London, 2005.
[18] “ITU-T P.800. Methods for subjective determination of transmission
quality - Series P: telephone transmission quality; methods for objective
and subjective assessment of quality,” August 1996.
[19] Methodology for the Subjective Assessment of the Quality of Television
Pictures, Recommendation ITU-R BT.500-10, ITU Telecom. Standard-
ization Sector of ITU, August 2000.
[20] J. Beerends and J. Stemerdink, “A perceptual audio quality measure
based on a psychoacoustic sound representation,” JOURNAL-AUDIO
ENGINEERING SOCIETY, vol. 40, pp. 963–963, 1992.
[21] S. Voran, “Estimation of perceived speech quality using measuring
normalizing blocks,” in Speech Coding For Telecommunications Pro-
ceeding, 1997, 1997 IEEE Workshop on.
IEEE, 2002, pp. 83–84.
[22] ITU-T Recommendation G.107: The E-model, a computation model for
use in transmission planning, International Telecommunication Union,
August 2008.
176
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

[23] W. Yang, “Enhanced modiﬁed bark spectral distortion (EMBSD): An
objective speech quality measure based on audible distortion and cog-
nition model,” Ph.D. dissertation, Temple University, 1999.
[24] A. Rix, “Advances in objective quality assessment of speech over
analogue and packet based networks,” in Data Compression: Methods
and Implementations (Ref. No. 1999/150), IEE Colloquium on.
IET,
2002, p. 10.
[25] S. Voran, “The development of objective video quality measures that
emulate human perception,” in Global Telecommunications Conference,
1991. GLOBECOM’91.’Countdown to the New Millennium. Featuring a
Mini-Theme on: Personal Communications Services.
IEEE, 2002, pp.
1776–1781.
[26] C. van den Branden Lambrecht, “Color moving pictures quality metric,”
in Image Processing, 1996. Proceedings., International Conference on,
vol. 1.
IEEE, 2002, pp. 885–888.
[27] C. van den Lambrecht, “Perceptual models and architectures for video
coding applications,” Ph.D. dissertation, Ph. D. dissertation, EPFL,
Switzerland, 1996.
[28] “Recommendation p.801: Mean opinion score (mos) terminology,” ITU-
T Rec P.801, 2006.
[29] Videolan. [Online]. Available: http://www.videolan.org/
[30] S. Hemminger, “Network emulation with netem,” in Linux Conf Au,
April 2005.
[31] “Recommendation 500-10: Methodology for the subjective assessment
of the quality of television pictures,” ITU-R Rec. BT.500, 2000.
[32] Sintel video trailer. [Online]. Available: http://www.sintel.org/
177
ICNS 2011 : The Seventh International Conference on Networking and Services
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-133-5

