The Effects of Extended Estimation on Affective Attitudes in an Interactional Series of
Tasks
Yoshimasa Ohmoto∗, Soshi Horii∗ and Toyoaki Nishida∗
∗Department of Intelligence Science
and Technology
Graduate School of Informatics
Kyoto University
Kyoto, Japan
Email: ohmoto@i.kyoto-u.ac.jp, horii@ii.ist.i.kyoto-u.ac.jp, nishida@i.kyoto-u.ac.jp
Abstract—When engaged in long-term human-human interac-
tions, we mutually estimate and construct a model of behavior. To
achieve long-term, sustained human-agent interaction, the agent
induces an active attitude within the human to demonstrate and
share their common ground. This study aimed to investigate the
effects of the agent’s estimation of a human’s preferences on the
human’s affective impressions to induce an active attitude within
a series of interactions. We conducted an experiment to evaluate
the effect of the proposed method using two agents. The results
showed that the proposed method could reduce the number of
interactions in the decision-making process and improved some
of the affective impressions related to the agent’s character. In
addition, we found that the rate of participants’ acceptance of
the proposals by the agent, which was implemented our proposed
method, was signiﬁcantly low. This was possible because the
agent provided a consistent estimation of emphasizing points for
each participant. The participants’ attitude indicates that they
regarded the agent as being communicative.
Keywords–Multi-modal interaction; human-agent interaction;
affective attitudes.
I.
INTRODUCTION
In recent years, the development of conversational agents,
such as robots and virtual agents, has rapidly expanded.
However, many of these agents are regarded as multimodal
interfaces that provide useful information rather than as social
partners [1]. There are many issues to contend with in the
production of a social partner agent. In this paper, we fo-
cus on methods for maintaining continuous interaction with
such agents during long-term activities. During short-term
interactions such as those occurring at front desks, shopping
counters, and information ofﬁces, the quality of the interaction
is “mechanical,” even between humans. Our aim is to develop
an agent that could be regarded as a communicative social
partner like human.
It is important that the mental state of people when
they interact with the agents is the same as that when they
interact with humans. The mental states that humans can be
in with respect to an agent can be deﬁned as physical stance,
design stance and intentional stance [2]. When we take the
physical stance, we pay attention to physical features such as
the power of the motor, the spec of the display and so on. When
we take the design stance, we expect that the agent works
mechanically according to predeﬁned rules. When we take the
intentional stance, we consider that the agent has subjective
thoughts and intentions. When a human interacts with another
human, they usually take the intentional stance. In this case,
they and their communication partner respect each other. When
a human interacts with a machine, they usually take the design
stance. In this case, they usually interact with the machine
from a self-centered perspective because they do not consider
that the machine has its own intentions. To establish social
relationships between a human and an artiﬁcial agent, the agent
has to induce the intentional stance.
When engaged in long-term human-human interactions, we
actively demonstrate and share our own preferences, mental
attitudes, and inner states to facilitate smooth interaction.
Through our interactions with each other, we mutually estimate
and construct a model of behavior. However, in many human-
agent interactions, it is difﬁcult for the human to estimate
the agent’s behavior model, because the agent and the human
do not actively demonstrate and share a common ground.
Consequently, the human is unable to apply a general human
behavior model to the agent. To resolve this problem, previous
researchers have attempted to approximate an agent’s behavior
model to a generalized human behavior model. However, in
the course of a long-term interaction, we expect that the
behavior model will be personalized along with the interac-
tion. Therefore, this approach is not considered suitable for
developing an agent that can be regarded as a communicative
social partner. To achieve long-term, sustained human-agent
interaction, the agent induces an active attitude within the
human to demonstrate and share their common ground..
To develop our social partner agent, we propose methods for
dynamically estimating emphasizing points (DEEP) based on
verbal reactions, body movements, and physiological indices.
These methods aim to support interactive decision-making
[3][4] and to induce an intentional stance for active interaction
between a human and an agent [5]. However, these previous
studies have demonstrated that it is not sufﬁcient to investigate
the effects of a model’s constructed inner state model on
a human’s attitude toward the interaction within a series of
such interactions. This study aimed to investigate the effects
of the agent’s estimation of a human’s preferences on the
human’s affective impressions within a series of interactions.
We expected the provision of consistent estimation, using
accumulated data on interactions, to induce a positive human
attitude toward the agent and the interaction.
The paper is organized as follows. Section 2 brieﬂy
introduces previous works. Section 3 explains the outline of the
proposed method which is partly described in previous works.
Section 4 describes an experiment for comparing two types
62
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

of methods and then presents the results. Section 5 discusses
the achievements and future work. We give our conclusion in
Section 6.
II.
RELATED WORK
Agents that collaboratively perform various tasks-such as
subordinate support agents, when people perform tasks using
their own initiative, and automated attentive agents, which
automatically perform tasks in line with a human’s wishes,
have been proposed previously. In addition, some researchers
have developed systems that can provide proposals to satisfy a
user’s demands. These systems gradually estimate user demand
throughout the interaction.
Aydogan et al. [6] proposed an architecture in which
both consumers and producers use a shared ontology to ne-
gotiate services. Through repetitive interactions, the provider
accurately learns consumer needs to provide better-targeted
offers. The system learns consumer needs through long-term
interactions; however, it did not consider that user demands
and needs could change during the process of the interaction.
Azaria et al. [7] considered a two-player game in which an
agent repeatedly supplies advice to a human user followed by
an action taken by the user that inﬂuences both the agent’s
and the user’s costs. That study consisted of a repeated setting
that is analogous to choice-selection processes, in which a
person is asked to choose a route to work from a set of
possible candidates. In their study, they proposed an agent
that models human behavior by combining principles from
behavioral science with machine-learning techniques. In these
studies, the researchers considered the effectiveness of task
performance; however, they did not consider the inﬂuences on
the affective attitude of the users. If a user could effectively
perform a task but had poor affective impressions, the user
would be hesitant to use the system or the agent. Papangelis
et al. [8] argued that rapport, which is an affective attitude,
had been identiﬁed as an important factor in human task.
Some studies have investigated how an agent’s advice is
accepted by users. Goetz et al. [9] reported that an appropriate
match between a robot’s social cues and its task improves peo-
ple’s acceptance of and cooperation with the robot. Appearance
is a factor that induces affective impressions. De Melo et al.
[10] explored the interpersonal effect of emotions expressed
by embodied agents on human decision-making. Their results
show that participants are sensitive to differences in facial
displays and cooperate signiﬁcantly more with a cooperative
agent. These results indicate that affective impressions inﬂu-
ence human decision-making.
III.
OVERVIEW OF FACILITATIVE DYNAMIC ESTIMATION
OF EMPHASIZING POINTS WITH EXTENDED ESTIMATION
In an earlier study [3], we proposed DEEP method, based
on verbal reactions, body movements, and physiological in-
dices from an interaction. In Ohmoto et al. [4], we combined
divergent and convergent processes with the DEEP method. We
call this “facilitative DEEP” (fDEEP). In these studies, we tried
to estimate “emphasizing points.” The emphasizing points are
factors that we consider and emphasize to reach an appropriate
decision. There are many factors which inﬂuence decision-
making. We implicitly focus on some of the factors and make
a decision based on the focused factors. We brieﬂy explain
the method and additionally propose “extended estimation,”
which is needed for maintaining emphasizing points in an
interactional series of tasks.
A. Estimation of emphasizing points
The degree of emphasis is rated on a scale from zero to
ﬁve. The rating is changed based on the following three factors
in interaction between human and a system with DEEP. The
system capture the factors by using cameras, microphones, mo-
tion capture systems and a measuring system for physiological
indices.
1) Verbal reactions: Either of the following two reactions
occurs.
•
Listed words appear in answers or demands.
•
The participant provides backchanneling phrases,
which express acknowledgement, surprise, or under-
standing, such as “ah,” “oh,” “aha,” “I see,” and “I
understand.”
2) Body movements: The participant repeatedly nods three
times or more.
3) Physiological indices: Either of the following two re-
sponses occurs. (refer to [11], [12], [13]).
•
Skin conductance response (SCR) increases more than
10% compared with resting levels.
•
Low-frequency/high-frequency (LF/HF) value (elec-
trocardiograph measurement) is more than 5.0.
Verbal reactions, body movements, and physiological in-
dices, are used as criteria for determining when a new factor
is discovered and should be emphasized, and for determining
when a user’s degree of emphasis of a particular factor
increases or decreases.
4) Rules for changing estimated emphasizing points during
interaction: A DEEP system explains the proposals and the
estimated emphasizing points change depending on the partic-
ipant’s responses.
5) Discovery of a new factor to be emphasized: Verbal
reactions, body movements, and physiological indices are the
criteria for determining when a new factor is discovered and
should be emphasized. When any one of the three criteria
appears during interaction, the system decides that the factor
should be slightly emphasized, and increases the degree of
emphasis from zero to two. When any two or all three criteria
are present, the system increases the emphasis from zero to
three.
6) Increasing or decreasing degree of emphasis: Verbal
reactions, body movements, and physiological indices are used
as criteria for determining when a user’s degree of emphasis
of a particular factor increases or decreases. When any one
of the three criteria appears, the system decides that the factor
should be emphasized, and increases the emphasis of the factor
by one.
When there are physiological reactions, but no verbal
reactions and body movements, the system decides that the
factor should be emphasized less, and decreases the emphasis
of the factor by one.
7) Rules for changing estimated emphasizing points from
active demands: The system asks whether or not a user has
any demands. From the user’s response, the system determines
what the user’s demands are and what changes there are to
the emphasizing points. The system accepts keywords which
are expected words in advance to express emphasizing points,
63
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

demands, and basic words necessary to capture demands in the
user’s responses. Words that are not expected to be included
in answers are ignored.
8) Discovery of new factors to be emphasized: When the
emphasis degree of the discovered factor is zero, the system
increases the degree of emphasis from zero to three.
9) Increasing or decreasing degree of emphasis: When the
emphasis of the discovered factor is greater than zero and the
system decides that the factor should be increased, the system
increases the degree by one. When the system decides that the
emphasis of the factor should be decreased and the degree is
greater than zero, the system decreases the degree by one.
B. Selecting the next step based on DEEP results
According to the criteria mentioned above, changes to a
user’s emphasizing points are estimated after the proposals
are given and data are collected from the user’s reactions and
responses. After the estimation, the next two proposals are
selected based on the estimation results.
The next proposals are selected using a table of orthogonal
arrays prepared in advance. Orthogonal arrays are a special
set of Latin squares, which can be used to estimate main
effects using only a few experimental runs. Each proposal in
the table has parameters of emphasizing points. From the table,
the proposal that most satisﬁes the user’s emphasizing points
is selected. When many proposals in the table can satisfy a
user’s emphasizing points, a proposal is selected according to
predeﬁned rules. The rules are designed by hand. For example,
the system selects a nearest proposal in convergent process
because the system knows which factor is important for the
user. The distances of the proposals are calculated by cosine
similarity.
C. Method to control divergent and convergent processes in
an interaction
The agent which supports the user’s decision-making dur-
ing the interaction needs to use social signals for active listen-
ing and teaming to control divergent and convergent processes
based on the estimated emphasizing points in the interaction.
For the facilitative interaction, we combined divergent and
convergent processes with the DEEP method (fDEEP). The
used signals are the frequency of providing a new proposal,
recommendation from the agent, mimicry of nodding motions,
and utterances.
1) The agent’s behavior in the divergent process: The agent
provides a small nod once in reaction to the user’s utterance.
The frequency of providing a new proposal is low. The
agent provides a new proposal after the agent explains three
emphasizing points. The furthest proposal from the previous
one is selected as a new proposal. The degree of emphasis
decreases if the emphasizing point is not explained in the
previous proposal.
2) The agent’s behavior in the convergent process: The
agent provides two large nods in reaction to the user’s utter-
ance. The frequency of providing a new proposal is high. The
agent provides a new proposal after the agent explains one
emphasizing point, which is a recommendation. The nearest
proposal to the previous one is selected as a new proposal.
The degree of emphasis decreases only when the emphasizing
point is clearly refused in the previous proposal.
3) The rules to switch between the divergent process and
convergent process: The agent starts the interaction with a
divergent process. The agent switches from the divergent
process to a convergent process when the agent detects the
following situations:
•
There are more than three emphasizing points, with a
degree of emphasis of more than one, and the degree
of emphasis does not change during the interaction.
•
The user offers a convergent opinion such as “I want
to see like this one” and “I want to determine.”
4) The emphasizing points of the agent: The agent has
the same set of emphasizing points for the decision making.
The emphasizing points and the degree of emphasis are the
subjective opinions of the agent. The emphasizing points are
set to the values of the recent proposal at the time when the
agent switches from the divergent process to the convergent
process. This means that the agent searches the neighbor of
the last proposal of the divergent process during the convergent
process. The degree of emphasis decreases when the empha-
sizing point is clearly refused by the user.
D. Extended estimation through maintenance of emphasizing
points within a series of interactions
In this study, we used historical estimated emphasizing
points within a series of tasks to estimate emphasizing points
within a new but similar task. We have termed this “extended
estimation,” which is similar to near transfer. There are some
previous studies about knowledge transfer [14][15]; however,
we cannot apply the theory directly to our actual agent system.
Figure 1 illustrates the concept of extended estimation. In
this example, a person is coordinating their new living space.
The person ﬁrst selects furniture and electronics for the living
space and then plans where to place them within this space.
When selecting these items, their qualities are a primary
consideration. During the planning phase, the person considers
the relationship between the furniture and electronic items.
Thus, while selection and planning are different tasks, they
are correlated. Often, an adviser who helps plan the living
space estimates emphasizing points during the planning phase
based on the history of those involved in the selection. This
individual then offers advice based on the extended estimation.
One purpose of the extended estimation is to adjust the degree
of each emphasizing point in the history of the previous tasks
that is to be applied in the estimation of the emphasizing points
of the next task. This adjustment is based on relationships
that exist between these sequential tasks and it plays a role in
converting the meaning of each emphasizing point within the
previous and the next tasks.
To implement the extended estimation, we have added
two components to DEEP. The ﬁrst is for maintaining the
history of the estimated emphasizing points within a series of
interactions related to sequential tasks. The second adjusts the
degree of each emphasizing point to a new task. We termed this
enhanced version “facilitative DEEP with extended estimation”
(feeDEEP). When applied to a new task, feeDEEP converts
the degree of estimated emphasizing points in previous tasks
to those in the new task using predeﬁned rules, such as a
predesigned relational network. For this study, we constructed
predeﬁned rules from the observations performed during pre-
liminary experiments. In the preliminary experiment, we listed
candidates of emphasizing points and the relationships among
them. We interviewed the participants to select and determine
64
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

Figure 1. Example of extended estimation.
the emphasizing points and the weight of the relationships after
the preliminary experiment. In addition, when the extended
estimation achieved a degree entailing a sufﬁcient number
of emphasizing points, an agent implemented feeDEEP by
initiating the interaction through a convergent process.
We expected that feeDEEP can estimate the degree
of emphasizing points effectively because their initial values
could be set based on user preference. The agent implementing
feeDEEP could also provide affective impressions that con-
veyed an impression of the agent’s consistent individuality
to the user. These affective impressions are important for
motivating users to engage in continuous interaction with the
agent.
IV.
EXPERIMENT
The purpose of our experiment was to investigate how
feeDEEP affects the efﬁciency of the decision-making process
and impressions related to agent behavior in an interactional
series of tasks. We expected that the extended estimation
will reduce cognitive load on decision-making by effective
support; thus, participants would notice agent proposals that
were personalized for them. We used two types of agents
to evaluate the effects of the proposed method. One was an
agent that implemented feeDEEP and the other was an agent
that implemented fDEEP. The feeDEEP agent maintained the
participant’s emphasizing points; however, the fDEEP agent
did not. The inputs for the agents were captured automatically,
with the exception of data related to verbal meanings, such
as the varbal negative feedback and the questions by the
participants, because we could not robustly determine them
automatically in real time, such as whether a user’s utterance
was positive or negative and whether the user’s utterance was
a question. We refer to the agent control method using manual
inputs as a Wizard of Oz (WOZ) method. After the experi-
ment, we analyzed the interaction behavior of participants and
questionnaire responses.
A. Task
The participants were asked to coordinate a new living
space. The primary task included three tasks, i.e., furniture
selection, electronics selection, and living space planning.
They ﬁrst selected furniture and electronic items for the living
space, and then planned where to place these items within
the space. The participants interacted with the agent about the
selection of items and the planning. We identiﬁed 16 factors of
emphasizing points, such as relaxing, natural, for work, clean,
Figure 2. The experimental setting.
leisure, high spec and so on, that the participants considered
when they performed each task. The factors in each task
were partially the same; however, some differed. In addition,
between the selection tasks and the planning task, the meanings
of the same factors differed.
B. Experimental setup
The experimental setting is shown in Figure 2. A partic-
ipant sat in front of a 60-inch monitor displaying the agent
and the proposal. The experimenter sat out of view of the
participant and entered the stimuli via a WOZ interface. Two
video cameras recorded participant behavior, i.e., one was
placed on the monitor to record the participant’s behavior
and another was placed behind the participant to record the
agent’s behavior. The participant’s voice was recorded using
microphones placed under the monitor. Polymate was used
to measure SCR and an electrocardiogram. The experimenter
instructed the participants to keep their left arm on an armrest.
C. Procedure
After brief instruction about the experimental procedures,
the experimenter showed a video of typical interaction with
the agent in a preliminary experiment in which participants
performed a different task. Then, electrodes were attached to
the participant to measure SCR and LF/HF values. After a 2-
min relaxation period, the experimenter began the ﬁrst task.
The participant repeatedly asked questions about the proposal
and considered the proposals provided by the agent until one of
the proposals satisﬁed the participant. The participants rested
between each task. At the conclusion of the experiment, the
participants completed a questionnaire.
The participants in this experiment were 21 Japanese college
students (16 males and 5 females) aged between 19 and 31
years (average age was 22.9). Eleven participants (8 males
and 3 females) interacted with the feeDEEP agent (feeDEEP
group) and the rest interacted with the fDEEP agent (fDEEP
group).
D. Results of the analysis of the number of proposals
To investigate whether the extended estimation contributed
to effective decision-making, we counted the number of pro-
posals from the agent in the second selection task and the
65
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

Figure 3. The number of proposals in the second selection task and in the
planning task.
Figure 4. Questionnaire results.
planning task. We performed a paired t-test on the data of
each group to compare the interaction efﬁciency in the tasks.
Figure 3 shows a signiﬁcant difference in the feeDEEP group
(p = 0.00034); however, there was no signiﬁcant difference
in the fDEEP group (p = 0.26). In addition, we performed
an unpaired t-test on the data in the planning task between
each task. As a result, the value for the feeDEEP group was
signiﬁcantly less than that for the fDEEP group (p = 0.0078).
These results indicate that the feeDEEP agent achieved more
effective decision-making support in the planning task than the
fDEEP agent.
E. Results of questionnaire analysis
The purpose of this analysis was to investigate how the
extended estimation inﬂuenced the participants’ subjective
impressions relative to the agent’s behavior. The participants
answered six questions using a seven-point scale. The scale
was presented as seven ticks on a black line without numbers
(scored from 1 to 7). The results are shown in Figure 4.
We performed a Mann-Whitney U test on the data from the
questionnaire.
1) How satisﬁed are you with the ﬁnal products?: There
was no signiﬁcant difference between the groups (p = 0.53).
The average scores were higher than the midpoint of the scale;
thus, the participants accepted the ﬁnal products provided by
the agents. This indicates that the algorithms that controlled
the human-agent interaction and provided candidates were
accepted by the participants.
2) How human-like do you feel that the agent’s behavior
was?: The participants in the feeDEEP group felt that the
agent was signiﬁcantly more human-like than the participants
in the fDEEP group (p = 0.035). We believe that one reason
for this is that the feeDEEP agent was consistent in terms
of suggestions and candidates. Consistency by the extended
estimation affected the participants’ impressions of a human-
like agent.
3) How natural do you feel that the agent’s interaction
was?: There was no signiﬁcant difference between the groups
(p = 0.57). The average scores were higher than the midpoint
of the scale; thus, the agents achieved natural interaction to
some degree. However, the extended estimation did not affect
the participants’ impressions.
4) How satisﬁed are you with the interaction process?:
There was no signiﬁcant difference between the groups (p =
0.54). The average scores were higher than the midpoint of
the scale; thus, the participants felt relatively good about the
agents’ estimations. However, the extended estimation did not
affect the participants’ impressions.
5) How would you rate the agent’s level of effort?:
This question was asked because we want to know whether
the participants regarded the agent as an independent-minded
partner. The participants felt that the feeDEEP agent tried
harder than the fDEEP agent (p = 0.087, marginally signiﬁcant
difference). Only one participant in the feeDEEP group scored
lower than the midpoint of the scale, and this participant
indicated that the agent’s voice did not express hard work. This
reason did not relate to the agent’s interaction behavior. On the
other hand, four participants in the fDEEP group scored higher
than the midpoint of the scale. We suggest that the extended
estimation affected the participants’ impressions of the agent’s
character.
6) How frequently did you accept the agent’s proposals?:
The participants in the feeDEEP group accepted signiﬁcantly
fewer proposals than the participants in the fDEEP group
(p = 0.013). In the interviews, most participants from the
feeDEEP group said that they could express their opinions.
In contrast, most of the participants in the fDEEP group said
that they compromised due to the agent’s ability. The ability
of the agents was the same, with the exception of the extended
estimation of the feeDEEP agent; therefore, we suggest that
extended estimation can induce participant opinions.
V.
DISCUSSION
We conducted an experiment to investigate whether ex-
tended estimation inﬂuences the efﬁciency of decision making
and the affective impressions of the implementing agent. The
experimental results indicate that extended estimation reduced
the number of interactions in the decision-making process.
This reduction was not attributed to the tediousness of the
interaction with the agent because the extended estimation
also provided positive affective impressions related to the
agent’s character. In addition, we did not obtain high scores for
impressions related to the interaction process (naturalness and
conﬁdence). One of the reasons for this was that the agent only
provided proposals for the decision-making task. Naturalness
and reliability are important for motivating sustained interac-
tion; therefore, we will consider how to gain user conﬁdence
in future research.
A particularly important ﬁnding emerged from our analysis
of the data obtained from the questionnaire used in the exper-
iment, i.e., the rate of participant acceptance of the feeDEEP
agent’s proposals within these interactions was signiﬁcantly
66
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

low despite a decrease in the number of interactions. Intu-
itively, one of the reasons why the number of interactions
may have decreased was that the agent was able to provide
proposals that matched participant preference, thereby leading
to quick acceptance of a proposal. However, this contradicts
the results of the previous questionnaire. In addition, there
was no signiﬁcant difference in the number of interactions
during the selection sessions. However, participants chose
their top three emphasizing points out of a total of 15 at
the end of the experiment. The average number of matched
emphasizing points was 1.67, and all of the participants’
emphasizing points had at least one match. This indicates that
the agents were, to some extent, able to estimate participants’
preferences accurately. Based on these results, we suggest
that the feeDEEP agent induced an active attitude toward the
decision-making interaction, which reﬂected the participants’
desires due to the extended estimation. However, participants
who interacted with the fDEEP agent demonstrated a passive
attitude by selecting an agent’s proposal that relatively matched
their preferences. We further suggest that the reason for an
active attitude among participants was that they were able
to construct an estimation behavior model for the agent.
This was possible because the agent provided a consistent
estimation of emphasizing points for each participant. The
participants’ attitudes indicate that they regarded the agent as
communicative. To create a system that is user-centric, it is
necessary for the user to maintain an active attitude toward
the decision-making interaction in order to accomplish their
goals. This study has demonstrated one method that can be
applied to induce an active attitude.
In our previous work [16][17], we analyzed physiological
indices (SCR and LF/HF values) that were obtained experi-
mentally. However, we could not include an analysis of these
indices in this paper. In the near future, we will analyze these
data in detail to investigate the underlying reasons for these
experimental results.
VI.
CONCLUSIONS
In this study, we investigated the effects of the consistent
estimation of a human’s preferences on the human’s affective
impressions within a series of human-agent interactions. For
this purpose, we proposed the estimation model with extended
estimation based on DEEP. We conducted an experiment to
evaluate the effect of the method using two agents; a feeDEEP
agent, which was proposed in this study, and a fDEEP agent,
which was proposed in our previous work. The results showed
that feeDEEP agent could reduce the number of interactions
in the decision-making process and improved some of the
affective impressions related to the agent’s character. In addi-
tion, we found that the rate of participants’ acceptance of the
feeDEEP agent’s proposals was signiﬁcantly low. This was
possible because the agent provided a consistent estimation
of emphasizing points for each participant. The participants’
attitude indicates that they regarded the agent as being com-
municative.
In this study, we constructed predeﬁned rules from
observations, which is one of the most important point of
extended estimation. We will develop the automated construc-
tion method of the rules based on the obtained data of actual
interaction in future.
ACKNOWLEDGMENT
This research is supported by Grant-in-Aid for Young
Scientists (B) (KAKENHI No. 25870353), Grant-in-Aid for
Scientiﬁc Research (A) (KAKENHI No. 24240023) and Grant-
in-Aid for Scientiﬁc Research on Innovative Areas (KAKENHI
No. 26118002) from the Ministry of Education, Culture,
Sports, Science and Technology of Japan.
REFERENCES
[1]
B. Shneiderman and P. Maes, “Direct manipulation vs. interface agents,”
interactions, vol. 4, no. 6, 1997, pp. 42–61.
[2]
D. C. Dennett, The intentional stance.
MIT press, 1989.
[3]
Y. Ohmoto, T. Miyake, and T. Nishida, “Dynamic estimation of empha-
sizing points for user satisfaction evaluations,” in Proc. the 34th Annual
Conference of the Cognitive Science Society, 2012, pp. 2115–2120.
[4]
Y. Ohmoto, M. Kataoka, and T. Nishida, “The effect of convergent
interaction using subjective opinions in the decision-making process,”
in Proc. the 36th Annual Conference of the Cognitive Science Society,
2014, pp. 2711–2716.
[5]
Y. Ohmoto, J. Furutani, and T. Nishida, “Induction of intentional
stance in human-agent interaction by presenting agent behavior of
goal-oriented process using multi-modal information,” in COGNITIVE
2015: The Seventh International Conference on Advanced Cognitive
Technologies and Applications.
IARIA, 2015, pp. 90–95.
[6]
R. Aydogan and P. Yolum, “Learning consumer preferences using se-
manticsimilarity,” in AAMAS ’07: Proceedings of the 6th international
joint conference on Autonomous agents and multiagent systems.
New
York, NY, USA: ACM, 2007, pp. 1–8.
[7]
A. Azaria, Y. Gal, S. Kraus, and C. V. Goldman, “Strategic advice
provision in repeated human-agent interactions,” Autonomous Agents
and Multi-Agent Systems, 2015, pp. 1–26.
[8]
A. Papangelis, R. Zhao, and J. Cassell, “Towards a computational
architecture of dyadic rapport management for virtual agents,” in
Intelligent Virtual Agents.
Springer, 2014, pp. 320–324.
[9]
J. Goetz, S. Kiesler, and A. Powers, “Matching robot appearance and
behavior to tasks to improve human-robot cooperation,” in Robot and
Human Interactive Communication, 2003. Proceedings. ROMAN 2003.
The 12th IEEE International Workshop on.
IEEE, 2003, pp. 55–60.
[10]
C. M. De Melo, P. Carnevale, and J. Gratch, “The inﬂuence of emotions
in embodied agents on human decision-making,” in Intelligent virtual
agents.
Springer, 2010, pp. 357–370.
[11]
T. Lin, M. Omata, W. Hu, and A. Imamiya, “Do physiological data
relate to traditional usability indexes?” in Proceedings of the 17th
Australia conference on Computer-Human Interaction, 2005, pp. 1–10.
[12]
U. M. Nater, R. La Marca, L. Florin, A. Moses, W. Langhans, and
et. al., “Stress-induced changes in human salivary alpha-amylase activ-
ity?associations with adrenergic activity,” Psychoneuroendocrinology,
vol. 31, no. 1, 2006, pp. 49–58.
[13]
K. Nakazono, T. Hada, E. Ataka, H. Tanaka, and Y. Nagashima,
“Workload evaluation of gaming task by physiological indices and
psychological indices,” Technical report of IEICE. HIP, Tech. Rep.,
2008.
[14]
M. Wilkesmann and U. Wilkesmann, “Knowledge transfer as interaction
between experts and novices supported by technology,” Vine, vol. 41,
no. 2, 2011, pp. 96–112.
[15]
S. S. Gunasekaran, S. A. Mostafa, and M. S. Ahmad, “Knowledge trans-
fer model in collective intelligence theory,” in Advances in Intelligent
Informatics.
Springer, 2015, pp. 481–491.
[16]
Y. Ohmoto, A. Matsumoto, and T. Nishida, “The effect of alternating
propagation of local objective and global purpose by a network-
connected two-layer model of emphasizing factors,” in 2015 EuroAsian-
Paciﬁc Joint Conference on Cognitive Science, 2015, p. (in press).
[17]
Y. Ohmoto, S. Takeda, and T. Nishida, “Distinction of intrinsic and
extrinsic stress in an exercise game by combining multiple physiological
indices,” in 2015 7th International Conference on Games and Virtual
Worlds for Serious Applications (VS-GAMES), 2015, p. (in press).
67
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

