 
 
Modelling Spatial Understanding: 
 Using Knowledge Representation to Enable Spatial Awareness  
in a Robotics Platform 
Martin Lochner, Charlotte Sennersten, Ahsan Morshed, and Craig Lindley 
CSIRO Computational Informatics (CCI) Autonomous Systems (AS)  
Commonwealth Scientific and Industrial Research Organization (CSIRO)  
Hobart, Tasmania, Australia 
Contact: martin.lochner@csiro.au, charlotte.sennersten@csiro.au,  
ahsan.morshed@csiro.au, craig.lindley@csiro.au 
 
 
Abstract—Robotics in the 21st century will progress from 
scripted interactions with the physical world, where human 
programming input is the bottleneck in the robot’s ability to 
sense, think and act, to a point where the robotic system is able 
to autonomously generate adaptive representations of its 
surroundings, and further, to implement decisions regarding 
this environment.  A key factor in this development will be the 
ability of the robotic platform to understand its physical space.  
In this paper, we describe a rationale and framework for 
developing spatial understanding in a robotics platform, using 
knowledge representation in the form of a hybrid spatial-
ontological model of the physical world.  While such a system 
may be implemented with classical ontologies, we discuss the 
advantages 
of 
non-hierarchical 
modes 
of 
knowledge 
representation, 
including 
a 
conceptual 
link 
between 
information processing ontologies and contemporary cognitive 
models.  
Keywords-Human Robot Interaction; Autonomous Navigation; 
Knowledge Representation; Spatial Ontology   
 
I. INTRODUCTION 
 
The process of transitioning away from hard-coded 
robotics applications, which carry out highly pre-determined 
actions such as the traditional manufacturing robot, is 
already well underway.  With notions such as cloud robotics 
[1] entering the zeitgeist, and highly publicized events such 
as the DARPA Robotics Challenge (Dec 19-21 2013, Miami 
FL) bringing public attention to these advances, it is 
foreseeable that robots will be entering the mainstream 
realm of human activity – more than in fringe applications 
(robotic vacuum cleaner; children’s toys), but in key areas 
such as caring for the aged [2], operating vehicles [3], 
disaster management [4], and undertaking autonomous 
scientific investigation [5]. 
The hurdles that must be overcome in reaching these 
goals, however, are neither few nor small.  This can be 
plainly seen, for example in the aforementioned 2013 
Robotics Challenge, in which simple spatial tasks that are 
routine for a human being (open a door, climb a ladder) are 
still critically difficult for even the most advanced and 
highly funded robotics projects.  While the state-of-the-art is 
impressive, it is evident that physical robotics hardware is 
far in advance of the control systems that are in place to 
guide the robot.  The challenge is, thus, to develop systems 
whereby a robot can perceive a physical space and 
understand its position in that space, the components that 
exist within the space, and how it can or should interact with 
these components in order to achieve implicit or explicit 
goals.  This is furthermore impacted by the requirement that 
robotic systems be able operate in outdoor environments 
where distributed connections may not be available; 
however, describing the development of long-range data 
networks for robotic communication is beyond the scope of 
this paper.  
While there are a number of ways that the problem of 
providing a robot with a spatial understanding can be 
approached (e.g., neuro-fuzzy reasoning [6], dynamic 
spatial relations via natural language [7]) it is our 
proposition that leveraging the current advancements in 
knowledge 
representation 
via 
ontologies 
[8][9], 
in 
combination with an understanding of human spatial-
cognitive processing [10][11], and enabled by real-time 
scene modeling [12]  will provide a powerful and accessible 
methodology for enabling spatial understanding and 
interaction in a mobile robotics platform. As argued by  
Sennersten et al. [13], the advantage of using cloud-based 
repositories of perceptual data annotated with ontology and 
metadata information is to take advantage of humanly-
tagged examples of sense data (e.g., images) to overcome 
the symbol grounding problem. Symbol grounding refers to 
the need for symbolic structures to have valid associations 
with the things in the world that they refer to. Achieving 
symbol grounding is an ongoing challenge for robotics and 
other intelligent systems (see, for example, Brooks, 1999 
[14]). Using cloud-based annotations attached to sensory 
exemplars takes advantage of the human ability to ground 
symbols, obviating the need for robots to achieve this 
independently of human symbolic expressions. 
This paper provides a conceptual overview of how 
spatial understanding can be developed in a robotics 
platform.  We discuss traditional knowledge representation 
(classical information processing ontologies), describe the 
development and use of “cognitive” ontologies, and how 
this may be transitioned into the development of a physical-
spatial 
ontology, 
including 
a 
possible 
system 
of 
26
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

 
 
comprehension for spatial position. Finally, we discuss the 
notion that truly non-hierarchical systems such as complex 
chemical structure, and such as the human cortex, may 
require the development of systems of knowledge 
representation that transcend the structural limits of today’s 
systems.   
 
II. KNOWLEDGE REPRESENTATION 
 
The development of specific nomological hierarchies for 
concept representation is currently taking place across many 
fields of academic endeavor (e.g., genetics, medicine, 
neuroscience, biology, chemistry, physics).  Under the guise 
of the philosophical concept of an Ontology, such 
applications seek to outline the knowledge which exists 
within a domain at three levels of representation: Classes, 
Properties, 
and 
Relationships. 
These 
nomological 
hierarchies provide a way of describing the precise 
relationship that terms in a given domain have to one 
another. As an information processing construct, the 
definition of an ontology is refined as an “explicit formal 
specification of the terms in the domain and relations among 
them”, 
or 
more 
concisely, 
“a 
specification 
of 
a 
conceptualization” [15]. 
A 
system 
that 
operates 
with 
such 
knowledge 
representation within its core functionality may be 
considered to be ‘knowledge-based’. A knowledge-based 
system is a computer program that stores knowledge about a 
given domain (also known as an “expert system”, when the 
knowledge is considered to be from a highly specialized 
domain). However, an ontology does not intrinsically 
represent the kinds of truth-functional mappings or 
procedures captured by rules in more complete knowledge 
bases. Hence, an ontology provides classifications and the 
ability 
to 
infer 
associations 
via 
subclass/superclass 
relationships. More complex forms of reasoning required for 
most forms of useful cognitive task performance require 
task-oriented rules.  As such, the domain knowledge in a 
knowledge base includes ontology representations, while 
most task-oriented reasoning is achieved by the use of rules 
that refer to ontological constructs in the form of domains 
within rule tuples. 
The system attempts to mimic the reasoning of a human 
specialist by conducting reasoning across rules and in 
reference to a database of atomic facts. Matching sense data 
against metadata/ontology-annotated sense data on the web 
can provide a method of automatically mapping a current 
sensed situation to the annotations of past situations stored 
in the cloud.  This allows the system to retrieve 
representations of the situation in an atomic form, as 
statements formulated using the symbolic forms of 
annotations which are retrieved by matching against 
associated sense data. Ontologies hold the potential, 
therefore, to provide the constructs for symbolic atomic fact 
expressions that rule-sets can then process for automated 
cognitive task performance. 
A. Cognitive Ontologies 
 
An increasing number of ontologies are available on-line 
that can potentially support this symbolic structure 
generation 
process. 
Knowledge 
representation 
via 
ontological structure has been applied to the field of 
cognitive science, both in relation to terminology used 
within the domain (e.g., DOLCE - Descriptive Ontology for 
Linguistic and Cognitive Engineering [16][17]) and for 
concepts relevant to empirical testing paradigms (e.g., 
CogPo [18]).  Indeed, several cognitive ontologies have 
been developed in the recent years, including DOLCE, 
WordNet [19], CYC [20], and CogPo. 
WordNet is an online lexical knowledgebase system, 
whose design is inspired by current psycholinguistic 
theories of human lexical memory, where each cognitive 
artifact can be semantically classified into English nouns, 
verbs, and adjectives, with different meanings and 
relationships in real-world scenarios.  DOLCE is developed 
by Nicola Guarino and his associates at the Laboratory for 
Applied Ontology (LOA) [21].  It captures the ontological 
categories underlying natural language and human common 
sense. DOLCE, however, does not commit to a particularly 
abstract level of concepts that relate to the world (like 
imaginary thoughts); rather, the categories it introduces are 
thought of as cognitive artifacts, which are ultimately 
dependent on human perception, cultural imprints and social 
conventions. 
The Cyc project goal is to build a larger common-sense 
background knowledgebase which is intended to support 
unforseen future knowledge representation and reasoning 
tasks. The Cyc knowledgebase contains 2.2 million 
assertions (fact and rules) describing more than 250,000 
terms, including nearly 15,000 predicates.   
Finally, the Cognitive Paradigm Ontology (CogPo) is 
developed based on two well-known databases, namely, the 
Functional Imaging Biomedical Informatics Research 
Network (FBIRN) Human Imaging Data base [22] and the 
BrainMap database [23]. The CogPo Ontology has 
categorized each paradigm in terms of (1) the stimulus 
presented to the subjects, (2) the requested instructions, and 
(3) the returned response. All paradigms are essentially 
comprised of these three orthogonal components, and 
formalizing an ontology around them is a clear and direct 
approach to describing paradigms. This well-formed 
standard 
ontology 
guides 
cognitive 
experiments 
in 
formalizing the cognitive knowledge.  
While these ontologies are of great value to the 
community of researchers, and while the knowledge-based 
mapping of concepts within particular domains may enable 
robotic systems to rapidly access the linguistic identity of 
physical objects and their relations within the domain, they 
do not provide a means whereby the robot may become 
spatially aware.  To achieve this goal, we will need to 
provide the robot with the ability to identify the spatial 
characteristics particular to an identified object, and the 
27
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

 
 
physical relations between these objects and the surrounding 
environment.  A robot requires an internal representation of 
three-dimensional space. It could access two dimensional 
images on the web, by content-matching those images with 
contents of its own visual system. The matching process, 
and especially the ongoing three dimensional interpretation 
of 
the 
images, 
could 
be 
greatly 
aided 
if 
the 
ontology/metadata 
associated 
with 
images 
includes 
representation of the three dimensional context of image 
capture. 
The 
“ontological” 
schema 
of 
knowledge 
representation for images may provide this means if it is 
extended to include three dimensional spatial annotations.  
 
III. REPRESENTING RELATIONSHIPS IN THREE 
DIMENSIONS:  SPATIAL ONTOLOGIES 
 
We propose here that this same methodology for 
specifying semantic relationships between concepts (the 
ontological structure of knowledge representation, i.e., 
Classes, Properties, and Relationships) may also be useful in 
specifying spatial relationships between physical objects.  
While a traditional ontology will hierarchically represent a 
concept and its relation to other concepts in a domain, a 
spatial ontology (e.g., Figure 1) will represent an object, 
(class), its spatial properties including a detailed 3d 
representation in a language such as the X3D XML-based 
file format, and its positional relation (x,y,z) to other objects 
existing within the scene by using the datatype properties.  
   
 
 
Figure 1. Example of a simple spatial ontology 
(Note that the relations between objects are represented via “Data 
Properties” here.) 
 
An entity (the “individual”) in a prototypical ontology is 
comparable to an entity in a spatial ontology, being an 
object in the physical world.  Class indicates the category 
into which the individual falls, for example “person”, or 
“boat”.  Attributes traditionally describe the individual – 
features, properties, or characteristics of the object: a person 
has arms; a boat has a hull.  In a spatial ontology this 
information will be appended with configural information 
regarding the object, for example the parent-child node 
relationship of a human body, including torso, appendages, 
etc.  The relation between individuals is where the power of 
the traditional ontology arises, by specifying the precise 
ways in which different individuals relate to one another 
(e.g., “a catamaran is a subclass of boat”).  Once again, in a 
spatial ontology the relation will be a precise indicator (a 
reference, or an ‘object index’) of the relative positionality 
of items in the physical space, as described in the following 
section.  By thus, leveraging the existing functionality of 
ontological representation, augmented with relevant and 
necessary spatial referencing information, we may develop a 
knowledge-based system that enables a level of spatial 
awareness in a robotic platform. 
 
A. A system of comprehension for spatial position 
Following the above discussion about relationships in 
3D space, we look into how coordinate systems can be 
synchronized. The physical scale requirement that a robot 
needs to have can be measured by the accuracy the robot 
needs to operate in via its navigation system. An 
autonomous robot must be able to determine its position in 
order to be able to navigate and interact with its 
environment correctly (e.g., Dixon and Henlich, 1997 [25]). 
When the Class of “robot” navigates from A to B it is a 
basic motion, which is similar to the movement of an in-
game character via a default keyboard set-up where the key 
“W” moves the character forward, turning left using key 
“A”, turning right using key “D” and go backwards using 
key “Z”. The 3D digital world uses the X, Y, Z coordinate 
system called the Cartesian Coordinate Method (CCM) and 
is expressed in meters (m). To measure distance between 
two spherical points; X¹, Y¹, Z¹ and X², Y², Z² we take the 
Euclidean distance using a Cartesian version of Pythagoras’ 
Theorem (1). The distance is the sum of their individual 
point differences in square. 
 
 
(1) 
 
To determine a position in the physical world and 
navigate the robot in map-referenced terms to a desired 
destination point from A to B, Dixon and Henlich use what 
they call 1) Global Navigation. The positioning accuracy 
with a standard consumer Geographical Positioning System 
(GPS) is accurate within a range of 8 feet which is 
approximately 284 centimeters.  This does not give high 
fidelity position accuracy.  As such, when the robot has to 
operate in a typical indoor manufacturing environment, it 
needs detailed position support in order to create 3D 
reference points within the space. What Dixon and Henlich 
call 2) Local Navigation, is to determine one’s own position 
relative to the objects (stationary or moving) in the 
environment, and to interact with them correctly. If we think 
28
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

 
 
of Human Robot Interaction (HRI) and the robot arm and its 
gripper(s) (hand/s), the gripper(s) must via eye(s) be able to 
recognize the object it will manipulate and how it shall be 
manipulated. The spatial centre points for individual objects 
are of importance, as well as group of objects and the 
robot’s own centre point in relation to actual manipulation 
centre point for gripper.  From a spatial ontology point of 
view, the centre points have to be able to change 
dynamically depending on interaction purpose. 
For example, the Puma robot arm series has three 
different arms with slightly different sophistication and 
these are Puma 200, Puma 500, and the Puma 700 Series. 
These robot arms execute 3) Personal Navigation [D&H] 
which make the arm aware of the positioning of the various 
parts, its own positioning, and also in relation to each other 
and in handling objects. The Puma 200 Series has been used 
for absolute positioning accuracy for CT guided stereotactic 
brain surgery [26]. The Puma 200 robot has a relative 
accuracy of 0.05 mm. There are already 3D Spatial Vision 
Systems for robots out on the market which are driven via 
several cameras. This creates a local world solution for 3D 
vision robot guidance where the software first make the user 
calibrate the cameras and the robot and then loading 
standard CAD files of parts the system shall track. 
 
IV.  BEYOND ONTOLOGIES – COMPLEX 
RELATIONSHIPS, AND ALTERNATIVES TO 
HEIRARCHICAL DATA REPRESENTATION 
 
As we move from relatively canonical data sets for 
which the information processing ontology was designed 
(i.e., semantic relations within a particular knowledge base) 
to more complex relationships (such as ad-hoc physical 
relations) in which the hierarchical order is not nearly so 
explicit, or potentially non-existent, will the classical 
ontology suffice?  Or alternately, will something more 
adaptive need to take its place?  Because relationships in the 
physical world are multifaceted and multidirectional, it is 
useful to have a schema which can represent this 
interconnectedness.  The key strength of an ontology is that 
it provides a concrete nomological environment from which 
to operate within the chosen domain.  Table 1 summarizes 
the traditional information processing ontology. 
 
 
TABLE 1: TRADITIONAL ONTOLOGY CHARACTERISTICS 
 
- allows a common understanding of the structure of information 
- enables reuse of domain knowledge 
- makes domain assumptions explicit 
- separates domain knowledge from operational knowledge 
- defines a common vocabulary for researchers 
- provides machine readable definitions of basic concepts and the 
relationships among them 
 
However, there are instances (albeit few as of this 
writing) in which it is being recognized that the intrinsic 
limitations of the “ontology” such it is commonly 
understood in 2014, (e.g., OWL-based [Web Ontology 
Language]) are sufficient as to demand a modification 
whereby 
the 
innate 
complexities 
of 
a 
real-world 
phenomenon may be modeled.  That is: complex, potentially 
non-hierarchical relationships. 
For example, it has been noted in the field of chemical 
molecular informatics that while ontologies are able to 
represent tree-like structures, they are unable to represent 
cyclical or polycyclical structures [27].  Similarly, the 
difficulty in building classifications of nano-particles has led 
some researchers to begin to look into taxonomies based on 
“physical / chemical / clinical / toxic / spatial” 
characteristics of an object, supplemented by structural 
information, in order to account for shapes, forms and 
volumes [28].  Other examples of representing complex 
structural relations which stretch the boundaries of 
ontological representation include using Description Graph 
Logic Programs (DGLP) to represent objects with arbitrarily 
connected parts [29], and a hybrid formalism whereby the 
authors propose a “combination of monadic second order 
logic and ordinary OWL”, where the two representations are 
bridged 
using 
a 
“heterogeneous 
logical 
connection 
framework” [30]. 
It is evident that the potential applications of a 
formalism such as the ontological method of information 
representation far outreach the initial conceptualizations of 
the language. While it may be possible to model 3 
dimensional spatial information within the constraints of a 
hierarchical ontology, it is also to be considered that this 
notion, as well as applications such as those described 
above, may require the development of progressive, flexible 
alternatives, which capture the strengths of the ontology 
(i.e., the points from Table 1), while managing to represent 
arbitrary or non-hierarchical relationships. 
 
A. Cognitive Models and Ontologies 
One information system where a non-hierarchical 
organization may be necessary, when attempting to map the 
internal structural relations, is the human brain.  For more 
than half a century, researchers across many fields (e.g., 
Cognitive Psychology, Neuroscience, Cognitive Science) 
have been using models to posit and test hypothetical 
interpretations of how the human brain is structured.  These 
range from the very simple (e.g., Baddely’s working 
memory model, [31]) to complex neurological models (e.g., 
[32]), though no current model has even begun to approach 
the actual complexity of the human brain.  On a neuronal 
level, and certainly even on a functional level such as 
between brain regions, this is a non-hierarchical system. 
It is remarkable that at a superficial level, the 
development of ontologies draws a strong parallel with 
some theoretical interpretations of how the human cognitive 
system might be structured (see Table 2).  This relation is 
further discussed in Sennersten et al. [13]. 
 
29
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

 
 
TABLE 2:  COMPARISON OF CLASSIC  
ONTOLOGY, OAR, AND ACT-R MODELS 
 
 
 
 
 
 
 
In OAR (Object, Attribute, Relation) Wong [10] 
develops a model which most certainly shares conceptual 
roots with ontological knowledge representation.  Likewise, 
parallels may be drawn with Anderson’s ACT-R model [11] 
and Trafton’s “embodied” version [32] ACT-R/E.  In each 
model, Objects in the real world possess characteristics (i.e., 
attributes, or properties) and also relations with one 
another.  If we can augment these heretofore largely 
semantic components with a functional representation of 
three dimensional space (e.g., at the 3 levels Global, Local, 
and Personal), we may have the fundaments of a system of 
Spatial Understanding for a robotic platform.   
 
V. SUMMARY 
 
One of the few certainties regarding the immediate 
future is that robotic control technology will advance from 
systems which are coded for specific applications, to 
systems which are designed with an innate adaptability to 
unexpected environmental situations.  This will require new 
methods of providing on-the-fly relational information to 
the robot, in order for it to gain an understanding of both its 
spatial position, and the position of other objects in the 
vicinity, their characteristics, and the ways in which it can 
relate to them.  A reworking of the traditional OWL-based 
ontology, with an eye for 3-dimensional spatial relations on 
1) Global, 2) Local, and 3) Personal levels of specificity 
may be sufficient to this end. 
It is also noted that as data sets become more complex, 
and especially as we begin to consider that most complex of 
biological control systems, the human cognitive system, it 
may very well become necessary to develop hybrid 
ontological-type systems of knowledge representation which 
1) encompass the full realm of advantages provided by the 
use of specific nomologial hierarchies, and 2) enable the 
encoding of arbitrary or non-hierarchical relationships. The 
development knowledge-based systems that can account for 
abstract, 
non-hierarchical 
relations 
could 
potentially 
facilitate the next generation of spatially aware robotics 
applications. 
 
  
 
 
 
 
 
 
 REFERENCES 
 
[1] 
J. Kuffner, “Cloud Enabled Robots,”  Presentation, IEEE 
Humanoids conference, Nashville, Tenn. 2010.  
http://www.scribd.com/doc/47486324/Cloud-Enabled-
Robots [retrieved: March, 2014] 
 [2] R. Khosla, M. Chu, R. Kachouie, K. Yamada, and T. 
Yamaguchi. “Embodying Care in Matilda: An Affective 
Communication Robot for the Elderly in Australia.” In 
Proceedings of the 2nd ACM SIGHIT International Health 
Informatics Symposium, pp. 295–304, 2012.  
http://dl.acm.org/citation.cfm?id=2110398. [retrieved: 
March, 2014] 
[3] 
J. M. Lutin, A. L Kornhauser, and E. Lerner-Lam. “The 
Revolutionary Development of Self-Driving Vehicles and 
Implications for the Transportation Engineering Profession.”  
Institute of Transportation Engineers, ITE Journal, vol. 
83(7), July 2013, pp. 28. 
[4] 
L. M. Hiatt, S. S. Khemlani, and J. G. Trafton, “An 
Explanatory Reasoning Framework for Embodied Agents,” 
Biologically Inspired Cognitive Architectures, vol. 1, July 
2012, pp. 23–31, doi:10.1016/j.bica.2012.03.001. 
[5] 
A. Elfes, J. L. Hall, E. A. Kulczycki, D. S. Clouse, A. C. 
Morfopoulos, J. F. Montgomery, J. M. Cameron, A. Ansar, 
and R. J. Machuzak, “An Autonomy Architecture for 
Aerobot Exploration of the Saturnian Moon Titan,” IEEE 
Aerospace and Electronic Systems Magazine, vol. 23(7), 
July 2008,  pp. 1-9. 
[6] 
K. K. Tahboub and S. N. Al-Din Munaf, “A Neuro-Fuzzy 
Reasoning System for Mobile Robot Navigation,” JJMIE 
vol. 3(1), March 2009, pp. 77-88.  
http://pdf.aminer.org/000/361/105/a_neuro_fuzzy_approach_
to_autonomous_navigation_for_mobile_robots.pdf. 
[retrieved: March, 2014] 
[7] 
J. Fasola and M. Matarić, “Using Spatial Language to Guide 
and Instruct Robots in Household Environments,” Refereed 
Workshop, AAAI Fall Symposium: Robots Learning 
Interactively from Human Teachers, Arlington, VA, Nov 
2012. 
http://www.aaai.org/ocs/index.php/FSS/FSS12/paper/viewFil
e/5582/5880. [retrieved: March, 2014] 
[8] 
C. Hudelot, J. Atif, and I. Bloch, “Fuzzy Spatial Relation 
Ontology for Image Interpretation,” Fuzzy Sets and Systems, 
vol. 159(15), August 2008, pp. 1929–1951. 
doi:10.1016/j.fss.2008.02.011. 
[9] 
G. Fu, C. B. Jones, and A. I. Abdelmoty, “Ontology-Based 
Spatial Query Expansion in Information Retrieval,” On the 
Move to Meaningful Internet Systems 2005: CoopIS, DOA, 
and ODBASE, Springer, 2005, pp. 1466–1482. 
http://link.springer.com/chapter/10.1007/11575801_33. 
[retrieved: March, 2014] 
OAR 
Model 
Ontology 
Components 
ACT-R 
ACT-R/E 
 
Object(s) 
Attribute(s) 
Relation(s) 
 
Class 
Properties 
Relationship(s) 
 
ChunkType  
Chunk Slot(s) 
Function(s) 
 
 
30
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

 
 
[10] Y. Wang, “The OAR model for knowledge representation,” 
Proc. The 2006 IEEE Canadian Conference on Electrical and 
Computer Engineering (CCECE’06), Ottawa, Canada, May 
2006, pp. 1692-1699.  
[11] J. R. Anderson, “ACT,” American Psychological 
Association, vol. 51(4), 1995, pp. 355-365.  
[12] M. Bosse, R. Zlot, and P. Flick, “Zebedee: Design of a 
Spring-Mounted 3-D Range Sensor with Application to 
Mobile Mapping,” IEEE Transactions on Robotics, vol. 
28(5), October 2012, pp. 1104–1119. 
doi:10.1109/TRO.2012.2200990. 
[13] C. Sennersten, A. Morshed, M. Lochner, and C. Lindley, 
“Towards a cloud-based architecture for 3D object 
comprehension in cognitive robotics”, The 6th International 
Conference on Advanced Cognitive Technologies and 
Applications, 25-29th of May 2014, Venice, Italy 
(Submitted).  
[14] R. A. Brooks, “Cambrian Intelligence.” Massachusetts, MIT 
Press, 1999. 
[15] T. R. Gruber, “A Translation Approach to Portable Ontology 
Specifications,” Knowledge Acquisition, vol. 5(2), 1993, pp. 
199–220. 
[16] C. Masolo, S. Borgo, A. Gangemi, N. Guarino, A. Oltramari, 
and Schneider, L, “Dolce: a descriptive ontology for 
linguistic and cognitive engineering, “ WonderWeb Project, 
Deliverable D17, vol. 2(1), 2003. 
[17] C. Masolo, S. Borgo, A. Stefano, A. Gangemi, N. Guarino, 
A. Oltramari and L. Schneider. “The WonderWeb Library of 
Foundational Ontologies.” IST Project 2001 - 33052 
WonderWeb: Intermediate Report, May 2003. 
 [18] J. A. Turner and A. R. Laird, The cognitive paradigm 
ontology: design and application. Neuroinformatics, vol. 
10(1), 2012, pp. 57-66. 
[19] G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross, and K. J. 
Miller, “Introduction to wordnet: An on-line lexical 
database”. International journal of lexicography, vol. 3(4), 
1990, pp. 235-244. 
[20] C. Matuszek, J. Cabral, M. J. Witbrock, and J. DeOliveira, 
“An Introduction to the Syntax and Content of Cyc,” AAAI 
Spring Symposium: Formalizing and Compiling Background 
Knowledge and Its Applications to Knowledge 
Representation and Question Answering, March 2006, pp. 
44-49. 
[21] Laboratory for Applied Ontology (LOA) (ISTC-CNR) 
http://www.loa.istc.cnr.it/  [retrieved: March, 2014]. 
[22] D. B. Keator, J. S. Grethe, D. Marcus, B. Ozyurt, S. Gadde, 
S. Murphy, and P. Papadopoulos , “A national human 
neuroimaging collaboratory enabled by the Biomedical 
Informatics Research Network (BIRN)”, Information 
Technology in Biomedicine, IEEE Transactions on, vol. 
12(2), 2008, pp. 162-172. 
[23] A. R. Laird, J. J. Lancaster, and P. T. Fox, “Brainmap,” 
Neuroinformatics, vol. 3(1), 2005, pp. 65-77. 
[24] Y. Kwoh, J. Huo, E. Jonckheere, and S. Hayati, “A Robot 
with Improved Absolute Positioning Accuracy for CT 
Guided Stereotactic Brain Surgery”, IEEE Transactions on 
Biomedical Engineering, Feb 1988, vol. 35(2), pp. 153-160. 
[25] J. Dixon and O. Henlich, “Mobile Robot Navigation”, Final 
Report, Information Systems Engineering, Imperial College, 
UK, 1997. 
[26] D. Martin, C. Fowlkes, D. Tal, and J. Malik, “A database of 
human segmented natural images and its application to 
evaluating segmentation algorithms and measuring 
ecological statistics,” Computer Vision 2001 (ICCV 2001), 
Proceedings, Eighth IEEE International Conference on, vol. 
2, pp. 416-423, 2001. 
[27] J. Hastings, C. Batchelor, and M. Okada, “Shape Perception 
in Chemistry,” Proceedings of the Second Interdisciplinary 
Workshop The Shape of Things (SHAPES 2013), Rio de 
Janeiro, Brazil, April 3-4, 2013, pp. 83-94.  http://ceur-
ws.org/Vol-1007/paper6.pdf.  [retrieved: March, 2014]. 
[28] V. Maojo, M. Fritts, F. Martin-Sanchez, D. De la Iglesia, R. 
E. Cachau, M. Garcia-Remesal, and J. Crespo. 
“Nanoinformatics: Developing New Computing Applications 
for Nanomedicine.” Computing, vol. 94(6), March 7, 2012, 
pp. 521–539, doi:10.1007/s00607-012-0191-2. 
[29] D. Magka, B. Motik, and I. Horrocks, “Modelling structured 
domains using description graphs and logic programming,” 
Lecture Notes in Computer Science, vol. 7295, 2012, pp. 
330-344, Department of Computer Science, University of 
Oxford, 2011. 
[30] O. Kutz, J. Hastings, and T. Mossakowski.  “Modelling 
Highly Symmetrical Molecules: Linking Ontologies and 
Graphs Artificial Intelligence: Methodology, Systems, and 
Applications,” Lecture Notes in Computer Science, vol. 
7557, chap. 11, pp. 103–111, Springer Berlin / Heidelberg, 
Berlin, Heidelberg, 2012. 
[31] A. D. Baddeley and G. Hitch, “Working memory,” In The 
psychology of learning and motivation: Advances in research 
and theory, vol. 8, G.H. Bower, Ed. New York: Academic 
Press, 1974, pp. 47–89. 
[32] M. Riesenhuber and T. Poggio, “Hierarchical models of 
object recognition in cortex,” Nature Neuroscience, vol. 
2(11), November 1999, pp. 1019–1025. 
[33] G. Trafton, L. Hiatt, A. Harrison, F. Tanborello, S. 
Khemlani, and A. Schultz, “ACT-R/E: An Embodied 
Cognitive Architecture for Human-Robot Interaction,” 
Journal of Human-Robot Interaction, vol. 2(1), March 2013, 
pp. 30–55. doi:10.5898/JHRI.2.1.Trafton. 
31
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-340-7
COGNITIVE 2014 : The Sixth International Conference on Advanced Cognitive Technologies and Applications

