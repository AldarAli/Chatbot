 
 
A Tool for Generating Ambiguous Objects in Two Viewing Directions 
Ken Nakaguchi, Koichi Matsuda and Oky Dicky Ardiansyah Prima 
Graduate School of Software and Information Science 
Iwate Prefectural University 
152-52, Sugo, Takizawa, Iwate, Japan 
e-mail: g236s003@s.iwate-pu.ac.jp, {matsuda, prima}@iwate-pu.ac.jp 
 
 
Abstractâ€”Ambiguous objects provide visual shape information 
that can be interpreted differently depending on the viewing 
direction. Generating effective ambiguity objects is difficult and 
therefore requires easy-to-use computational modelling. In this 
paper, we propose a Three-Dimensional (3D) modelling tool to 
generate an object that can be perceived differently from two 
different viewing directions. The tool uses solid models of 
cylindrical surfaces parallel to each of the viewing directions. 
These models are intersected at the central axis and rotated 
according to the viewing direction, using the intersection as the 
origin. Finally, by transforming each Two-Dimensional (2D) 
figure drawn by the user in each viewing direction into a 
cylindrical surface, a 3D ambiguous object can be generated. 
These 2D figures can be drawn using mouse click events. The 
generated ambiguous objects can be fabricated on a 3D printer 
to demonstrate the usability of the proposed tool. Our 
experiments show that ambiguous objects consisting of simple 
and complex shapes were successfully generated.  
Keywords-3D-Illusion; ambiguous object; ambiguous cylinder; 
3D modelling; visual perception. 
I.  INTRODUCTION 
An optical illusion is a phenomenon in which our 
perception of an object differs from its physical reality. This 
illusion is important in the study of human visual processing. 
The study of optical illusions began with Two-Dimensional 
(2D) images but has now been extended to Three-
Dimensional (3D) objects. The former are ambiguous figures 
that represent a single figure but have multiple interpretable 
meanings, such as Edgar Rubin's â€œFace-Vase illusionâ€ [1]. 
These figures are most often represented in binary images, 
where the white areas are foreground figures and the black 
areas are the intangible background, or vice versa. The 
boundaries shared by these areas play an important role in the 
figure assignment process. The latter are ambiguous objects, 
the shape of which can appear to be different depending on 
the direction in which they are viewed. Such objects can be 
generated in three ways: by making a discontinuous structure 
appear continuous from certain viewing directions [2], by the 
use of curved surfaces instead of planes [3], or by the use of 
angles other than 90 degrees to create a rectangular 
appearance [4]. Sugihara (2012) classified ambiguous objects 
into seven generations and showed that all objects are 
accompanied by illusions [5]. 
Computer-aided tools are available to assist in the 
generation of ambiguous figures and objects. The ambiguous 
figure generation tool finds partial matches by performing 
shape matching and deformation of the two figures and then 
stitching them together to produce the resulting image [6]. 
However, generating ambiguous objects is more complex. 
The tools used need to be built on a 3D modelling framework, 
with geometric modifications to the shapes also being 
performed in 3D [7]. Furthermore, unlike ambiguous figures, 
the generated ambiguous objects are viewing direction 
dependent, requiring the viewpoint to be determined prior to 
modelling. 
In this study, we focused on the following two aspects 
when developing a tool to facilitate generating ambiguous 
objects. Firstly, the tool is implemented on top of a 3D 
modelling framework, but the shape of the individual objects 
is determined by drawing in 2D. Secondly, the shape of the 
generated ambiguous objects changes adaptively according to 
the viewing direction. This implementation allows users 
unfamiliar with 3D modelling to create ambiguous objects. 
The rest of this paper is organized as follows. Section II 
describes related works on ambiguous object generation. 
Section III describes our proposed tool for generating the 
ambiguous objects in two viewing directions. Section IV 
summarizes our results. Finally, Section V concludes our 
study and discusses future work. 
 
II. RELATED WORKS 
The methods used to generate ambiguous figures and 
objects can be divided into three categories, as described 
below. 
The first method generates ambiguous figures by 
manipulating the relationship between edges or faces. 
Shinohara et al. constructed a system that can portray 
impossible figures realistically using ray tracing [8]. Their 
system provides predefined basic parts, where the user can 
interactively manipulate the rendering depth of each surface 
with respect to the parts. Owada et al. proposed a system for 
generating ambiguous figures by taking a 3D object as input 
and interactively editing the edges of its 2D plane from a given 
viewing direction [9]. These operations can be performed 
using mouse events. Both systems facilitate the generation of 
ambiguous figures, but there is no continuity of edges and 
faces in the resulting 3D objects. 
The second is Fukuda's method of generating ambiguous 
objects in two viewing directions [10]. These works were 
published in the book "One solid with two shapesâ€ but are 
difficult to reproduce because the parameters and optimization 
methods required for their generation were not disclosed. 
45
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
 
The third is the method of generating ambiguous objects 
by solving linear equations. Sugihara experimented with 
generating an ambiguous object using 2D planar shapes such 
as flowers and stars as input. However, the results showed that 
the solution of the linear equations could not be obtained 
depending on the viewing direction and the given input 
geometry. 
Although it does not fit into the above categories, a simple 
tool for generating ambiguous objects without the need to edit 
the object's shape has been proposed [11]. This tool generates 
ambiguous objects by adjusting the position and inclination of 
several square pillars placed in 3D space. However, due to the 
requirement of using square pillars, this tool cannot generate 
objects of arbitrary shape. 
All of the above studies focused on modelling the shape 
of the ambiguous object in its generation but did not consider 
modelling the shape independent of the viewing direction. The 
automatic modification of the shape by changing the 
viewpoint would facilitate the generation of ambiguous 
objects. 
 
III. OUR PROPOSED TOOL  
The proposed tool uses an approach that allows the 
generation of 3D objects seen from each viewing direction, 
based on 2D figures. The generation of an ambiguous object 
involves the drawing of 2D figures and the integration of two 
solid 3D models. 
A. The drawing of 2D figures 
The tool provides two canvases for drawing each figure, 
where the user can draw a 2D figure by drawing a single stroke 
on each canvas. Note that the line segments composing each 
figure are not supposed to self-intersect. Figure 1 shows a 
circle Pï¡  and a triangle Pï¢  drawn on the canvases, respectively.  
The figures on the canvas are stored as polygons. However, 
their shapes need to be optimized to make them equal in size 
and to remove unnecessary vertices caused by hand tremors 
during the drawing process. The proposed tool optimizes the 
figures drawn by the user through the following pre-
processing. 
a. Normalization 
To make the two figures in an ambiguous object more 
visible, it is necessary to scale both figures equally. Therefore, 
the center coordinate 
ğ¶(ğ‘ğ‘¥, ğ‘ğ‘¦) = (1
ğ‘› âˆ‘ ğ‘ƒğ‘–
ğ‘¥
ğ‘›
ğ‘–=1
, 1
ğ‘› âˆ‘ ğ‘ƒğ‘–
ğ‘¦
ğ‘›
ğ‘–=1
) 
(1) 
of each figure is taken as the origin, and the vertices Pi that 
makes up the figure is then normalized by 
ğ‘ƒâ€²
ğ‘– =
ğ‘¤
max(ğ‘ƒğ‘¥,ğ‘ƒğ‘¦)âˆ’minâ¡(ğ‘ƒğ‘¥,ğ‘ƒğ‘¦)(ğ‘ƒğ‘–
ğ‘¥, ğ‘ƒğ‘–
ğ‘¦), 
(2) 
where w is a user-defined scale of the figure, while ğ‘ƒğ‘¥ and ğ‘ƒğ‘¦ 
represent the coordinates of the vertices. 
b. Smoothing 
The following smoothing process is applied to each 
vertex to reduce the distortion of the figure caused by hand 
tremors during drawing.  
ğ‘ƒâ€²â€²ğ‘– = ğ‘ ğ‘šğ‘œğ‘œğ‘¡â„(ğ‘ƒâ€²ğ‘–) = 1
3(ğ‘ƒâ€²ğ‘–âˆ’1 + ğ‘ƒâ€²ğ‘– + ğ‘ƒâ€²ğ‘–+1).â¡ 
(3) 
This process effectively reduces noise in the vertices caused 
by subtle hand tremors. 
c. Vertices pruning 
To make the density of the vertices that make up the figure 
uniform, the distance between vertices  
 
 
Figure 1. Two 2D figures created to be perceived from two 
viewing directions. 
Figure 2. Two 2D figures integrated into a solid 3D object that can 
be perceived from two viewing directions. 
 
 
 
Figure 3. Two cylindrical surfaces for this study. 
 
 
ï¿½ â€²
ï¿½ â€²
h
h
Central axis
Central axis
46
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
 
ğ·ğ‘– = âˆš(ğ‘ƒâ€²â€²ğ‘–
ğ‘¥ âˆ’ ğ‘ƒâ€²â€²ğ‘–+1
ğ‘¥ )2 + (ğ‘ƒâ€²â€²ğ‘–
ğ‘¦ âˆ’ ğ‘ƒâ€²â€²ğ‘–+1
ğ‘¦ )
2 
(4) 
that are less than a threshold is removed. 
B. The integration of two solid 3D models 
The integration of the two figures, as shown in Figure 1 
into a single solid object must be done in a unique way. Figure 
2 shows a possible integration in which the shape of Pï¡ and Pï¢ 
can be perceived from the viewpoint of Eï¡ and Eï¢, respectively. 
This integration can be seen as the creation of an ambiguous 
3D object representing the two figures. The shape of Pï¡ is 
represented by an ellipsoid plane, while Pï¢ is by a spherical 
triangle. 
In this study, two cylindrical surfaces are used for the 
integration of the two figures. The integration takes the 
following steps. 
Step 1: Generate a cylindrical surface for each figure. Figure 
3 shows cylindrical surfaces ğ´â€² and ğµâ€² for Pï¡  and Pï¢. 
The height of the cylindrical surface (h) should be 
high enough with respect to the viewing direction, as 
will be described later. 
Step 2: Intersect the central axes (dashed lines) of the 
cylindrical surfaces ğ´â€² and ğµâ€² , and rotate each 
cylindrical surface around the intersection point (I) to 
face the viewing points Eï¡ and Eï¢, as shown in Figure 
4. 
Step 3: Perform a Boolean intersection to create a new solid 
from the intersection of the volumes of ğ´â€² and ğµâ€². 
Figure 5 shows the resulting ambiguous object and its 
projected image plane as seen from Eï¡ and Eï¢, 
respectively. 
 
IV. EXPERIMENTAL RESULTS 
Ambiguous objects consisting of simple and complex 
shapes were created using the proposed tool. Figure 6 shows  
 
 
Figure 4. Two cylindrical surfaces ğ´â€² and ğµâ€² that intersect with respect to 
their viewing directions. 
Figure 5. A solid object resulted from the Boolean intersection. 
 
 
Shape 
Figure #1 
Figure #2 
 
 
 
 
 
 
Figure 6. Figures for the construction of a simple 
and a complex ambiguous object. 
 
 
Simple
Complex
 
(a) Simple cylindrical surfaces 
 
(b) Complex cylindrical surfaces 
Figure 7. Cylindrical surfaces used to construct the 
ambiguous objects. 
 
 
47
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
 
  
 
  
(a) Viewing directions. 
 
(b) The image plane viewed from Eï¡. 
 
(c) The image plane viewed from E1. 
 
 
(d) The image plane viewed from E2. 
 
 
(e) The image plane viewed from E3. 
  
(f) The image plane viewed from Eï¢. 
Figure 8. The resulting ambiguous objects constructed by using simple figures. 
 
 
(a) Viewing directions. 
 
(b) The image plane viewed from Eï¡. 
 
(c) The image plane viewed from E1. 
 
(d) The image plane viewed from E2. 
 
(e) The image plane viewed from E3. 
 
(f) The image plane viewed from Eï¢. 
Figure 9. The resulting ambiguous objects constructed by using complex figures. 
 
 
 
48
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

 
 
the 2D figures used to construct the ambiguous objects. The 
silhouettes of a turtle and a rabbit were used as simple figures. 
The figures are drawn almost entirely in outline, with no 
hollow areas. On the other hand, Japanese kanji characters 
were used as complex figures but were designed to be drawn 
with a single stroke. 
Cylindrical surfaces associated to the simple and the 
complex figures were intersected to build ambiguous objects, 
as shown in Figure 7. Here, w=2.5 was used to rescale each 
figure to be 1m wide. The pre-processing shows that the 
cylindrical surfaces that intersect each other can be made to 
be of the same height. As both cylindrical surfaces are 
integrated by the Boolean interception, any change in viewing 
direction can generate a new ambiguous object. Unlike 
previous studies, the shape of the ambiguous object does not 
need to be edited each time the viewing direction is changed. 
To show the difference between the correct and incorrect 
viewing directions of the generated ambiguous objects, the 
appearance of the objects in different viewing directions was 
captured, as shown in Figures 8 and 9. Let Eï¡ and Eï¢ be the 
correct viewing points and Ei the arbitrary viewing points 
(i=1,...,3), the original figures appear in its form when viewed 
from Eï¡ and Eï¢.  
 
V. CONCLUSION AND FUTURE WORK 
In this paper, we propose a 3D modeling tool for 
generating ambiguous objects. These objects can be perceived 
differently from two different viewing directions. Users can 
easily generate ambiguous objects by simply drawing two 2D 
figures with this tool. Once the user defines the viewing 
direction of these figures, the ambiguous object is 
automatically generated. This approach differs significantly 
from those proposed in previous studies because the original 
2D figures do not need to be modified by changes in viewing 
direction. Currently, there are several limitations in the 
proposed tool. First, if the angle between the two viewpoint 
directions is extremely small, the thickness of the generated 
ambiguous object becomes extremely thin, making it difficult 
to fabricate it with a 3D printer. Second, the appearance of the 
ambiguous object differs from the intended appearance even 
when it is viewed with only a slight viewpoint misalignment, 
because there is no tolerance process for viewpoint 
misalignment. Future work will include performing subjective 
evaluation experiments to evaluate the robustness of viewing 
the ambiguous objects generated by our tool. 
 
 
REFERENCES 
[1] E. Rubin, â€œFigure and Ground,â€ Readings in Perception, pp. 
194â€“203, 1958. 
[2] A. I. Seckel, â€œMaster of Deception,â€ Sterling Publishing Co., 
Inc., 2004. 
[3] G. Elber, â€œModeling (Seemingly) Impossible Models,â€ 
Computer and Graphics, vol. 35, no. 3, pp. 632â€“638, 2011. 
[4] K. Sugihara, â€œThree-Dimensional Realization of Anomalous 
Pictures: An Application of Picture Interpretation Theory to Toy 
Design,â€ Pattern Recognition, vol. 30, no. 7, pp. 1061â€“1067, 
1997. 
[5] K. Sugihara, â€œEvolution of Impossible Objects,â€ 9th 
International Conference on Fun with Algorithms, vol. 2, pp. 
2:1â€“2:8, 2012. 
[6] Y. -M. Kuo, H. -K. Chu, M. -T. Chi, R. -R. Lee, and T. -Y. Lee, 
â€œGenerating Ambiguous Figure-Ground Images,â€ in IEEE 
Transactions on Visualization and Computer Graphics, vol. 23, 
no. 5, pp. 1534-1545, 2017. 
[7] G. Sera and G. Elber, "Generation of View dependent Models 
Using Free Form Deformation," The Visual Computer, vol. 23, 
pp. 219-229, 2007. 
[8] Y. Shinohara and Y. Miyashita, "Proposal of a Realistic 
Representation Method for Impossible Three-Dimensional 
Objects," Information Processing Society of Japan, HCI 2009-
HCI-132, pp. 95-102, 2009. 
[9] S. Owada and J. Fujiki, â€œInteractive Stereopsis of Impossible 
Objects as Artistic Expression,â€ Technical Report of the 
Institute of Image Information and Television Engineers, vol. 32, 
no. 14, pp. 43-46, 2008. 
[10] S. Fukuda, â€œShigeo Fukuda's Three-Dimensional Modeling,â€ 
Kawade Shobo Shinsha, 1977. 
[11] K. Sugihara, â€œAmbiguous Pillars: a New Class of Impossible 
Objects,â€ Computer Aided Drafting, Design and Manufacturing, 
vol. 25, no. 4,  pp. 19-25, 2015. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
49
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-078-0
ACHI 2023 : The Sixteenth International Conference on Advances in Computer-Human Interactions

