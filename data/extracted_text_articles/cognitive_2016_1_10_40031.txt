Interface for Communication Between Robotic and Cognitive Systems
Through the Use of a Cognitive Ontology
Helio Azevedo(1,2)
Roseli Aparecida Francelin Romero (1)
(1) ICMC-USP / University of S˜ao Paulo
(2) Center for Information Technology Renato Archer (CTI)
S˜ao Paulo , Brazil
Email: hazevedo@usp.br , rafrance@icmc.usp.br
Abstract—The demand for socially interactive robots has in-
creased annually. In particular, service robots have invaded homes
and worked directly with humans who, in general, are not
familiar with such devices. Their acceptance is conditioned to
the evolution of research in the area of human-robot interaction.
This paper contributes towards this acceptance process presenting
an ontology that accelerates the implementation of cognitive
systems in robots and enables the reproduction of experiments
associated with cognitive models and comparison among different
implementations. The speciﬁc objective is the deﬁnition of an
ontology that provides a protocol for communication between
cognitive and robot part systems.
Keywords–cognitive model; robot; ontology.
I.
INTRODUCTION
The growing use of robots in the modern society is a
reality [1]. Only a few decades have passed from a beginning
restricted to production environments to the use of service
robots in homes. Inside a residence, robots must use similar
interaction processes to interact directly with humans.
Such dissemination of robots requires a growth in research
on Human-Robot Interactions (HRI), particularly in the sub-
area deﬁned by Fong [2] as Socially Interactive Robots (SIR).
Therefore, the evolution of research into cognitive systems
is one of the basic conditions for the consolidation of SIR.
However, such research is hindered by the existence of multiple
robot platforms, of which many are proprietary, a fact that
minimizes the exchange of knowledge and skills among re-
searchers. Moreover several programming frameworks exhibit
different architectures and interfaces, which cause the subtrac-
tion of resources and delay in the achievement of results.
SIR applications demand more ﬂexible solutions than those
offered by hierarchical, reactive and hybrid classical robotic
architectures [3]. On the other hand, cognitive architectures
have emerged for modeling the cognitive aspects present in
processing systems required by the society. They offer an
interesting approach. However, there is a question concerning
the facilitation of communication between the systems present
in these two ”worlds“: robotic and cognitive.
Before delving into such a question, let us recall some
deﬁnitions. A robot is an agent that acts in the physical world
to accomplish one or more tasks. In this work, we assume
the robot processing system is organized into two hierarchical
systems. The ﬁrst, named ”cognitive system“, models the
cognitive architecture [4], whereas the second, named ”robot
part system“, controls the devices attached to the robot [5].
Our hypothesis is there is a gap of communication between
the cognitive model and the system that controls the sensors
and actuators of robots. As an approach to reduce this gap, we
propose deﬁning a set of formally related terms that enables
this communication. The strategy for the achievement of such
a formalization is the deﬁnition of a cognitive ontology, named
”OntCog“, whose beneﬁts involve:
•
establishment of a standardized interface between the
”cognitive system“ and the ”robot part system“,
•
facilitation of the development of cognitive robotic
simulators,
•
minimization of laboratory costs for research on cog-
nitive science applied to robotics, and
•
facilitation of the construction of reference environ-
ments for the development, evaluation and comparison
of the performance of cognitive applications.
Few studies have prioritized the development of a protocol
for the modeling of cognitive aspects. Novikova et al. [6]
designed a platform, named SIGVerse, for the modeling of
a robot agent in a 3D environment that interacts with a human
avatar controlled by Wii, Kinect and Oculus Rift interfaces.
Wii controls the walking movements, Kinect controls the trunk
that enables the avatar to pick up objects and perform gestures,
and Oculus Rift increases the effect of interaction with the
3D environment. The cognitive aspect is achieved through the
recognition of two emotions in interaction, namely surprise
and happiness.
On the other hand, some studies have attempted to sim-
ulate cognition in humans instead of robots. Faber et al. [7]
performed a planning of assembly tasks in a manufacturing
system considering the knowledge of human operators. This
knowledge is initially absorbed by the analysis of the strategies
used by operators during the assembly of mechanical compo-
nents and then employed in the construction of a knowledge
base (production rules) used in the manufacturing planning.
This paper is organized as follows: Section II presents
the cognitive ontology proposed and highlights questions that
are research subjects; Section III describes the strategies for
the validation and veriﬁcation process of the ontology; ﬁnally,
Section IV summarizes the conclusions.
1
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-462-6
COGNITIVE 2016 : The Eighth International Conference on Advanced Cognitive Technologies and Applications

II.
COGNITIVE ONTOLOGY
This study aims at a protocol for the transfer of information
at a higher cognition level. Below are questions that naturally
arose in the proposal:
•
What is the desired cognition level?: The spectrum
of cognitive information is wide and ranges from
sensations to memory, emotions and creativity. Our
initial hypothesis states that the protocol is used as an
interface between the cognitive and robot part systems.
In this scenario, our interest is on the senses, i.e.,
sight, hearing, touch, taste and smell. We assume the
other abstration levels of cognition are generated by
the cognitive system, therefore, the representation of
such information in the protocol is not required.
•
How can this information be represented?: Data
stream should not be used in the representation of
senses obtained directly from sensors, but rather, a
more high-level must be considered. Regarding the
”hearing sense“, the information would be words,
sirens, birds, music, etc. A point for discussion con-
cerns the way ”attention focus“ information should be
aggregated to the message.
The natural way of describing this protocol is by using
ontologies. An ontology formally describes objects and their
relationships in a knowledge domain and its main advantages
include [8]:
•
offer of a formally deﬁned vocabulary,
•
implementation as a semantic data model,
•
possibility of data integration and exchange of infor-
mation among agents, and
•
supply of consistency check tools.
Over the past few years, several ontologies have been pro-
posed for robotic applications, however, according to Prestes
[9], they are not generic enough to fully meet the needs of
robotics and automation areas. The IEEE offered the 1872-
2015 - IEEE Standard Ontologies for Robotics and Automation
[5] in 2015 and deﬁned four ontologies, namely CORA, a
core ontology targeted to robotics and automation, Corax,
which presents common concepts in robotics and automation,
RPARTS, which deﬁnes concepts that represent parts of the
robot, and POS, which deﬁnes general notions of position and
orientation.
We are particularly interested in CORA, as it represents the
highest level of abstraction under which other groups develop
speciﬁc ontologies. The ontology proposed in this paper is
adherent to CORA, as adherence to international standards
minimizes the development efforts and provides better results.
A. Senses Axioms
Our perception of the environment is generated from infor-
mation gathered by the senses. Sense Axioms (Figure 1) deﬁne
the objects, properties and relations present in robot sensory
information.
The ﬁrst open question on this topic regards the type of in-
formation, i.e., whether it is symbolic or numeric. Concerning
the taste sense, the robot sensory information can be classiﬁed
as sweet, bitter, sour and salty (symbolic types) or ph level
(numerical type). Another question is related to the cognitive
information composition that must travel on the established
interface. As an example, rather than notifying the taste and
smell perception, we could use ﬂavor.
The treatment to be given to information present only
in robots, but not in humans, as magnetism, radioactivity,
infrared, etc, must also be taken into account. The ontology
modeling can range from a super class deﬁnition, named
Generic, to the inclusion of a class for each sensor type or
distribution of information between basic senses. For example,
the infrared might be bonded with sight.
Figure 1. Senses Subclasses.
B. Act Axioms
Another group of information deﬁned in the protocol
represents messages from a cognitive system to a robot part
system (Figure 2). In this group the central question is at what
level of detail should the action be described?. For example,
the action of picking up an object in the robot visual ﬁeld can
be broken down into the following steps: determination of the
object position, size analysis, calculation of mass, identiﬁcation
of the motion sequence of the actuator arm, veriﬁcation of
obstacles in the path of each junction, execution of movements
and capture of the object. Another possibility would be the
simple sending of a message with the following content: ”Get
object X in position Y“.
III.
VERIFICATION AND VALIDATION
After the ontology deﬁnition, the results must be ver-
iﬁed and validated. The veriﬁcation (Are we building the
product correctly?) is based on the OntoClean methodology
[10], which provides a formal basis for the validation of the
ontological adequacy of taxonomic relationships. The strategy
is to aggregate a set of meta information (Rigidity , Identity,
Unity, and Dependence) to the ontology classes and iteratively
reﬁne the original taxonomic structure.
Validation (Are we building the right product?) is carried
out through the testing of the ontology in a controlled en-
vironment, i.e., given a usage scenario, ”OntCog” must offer
2
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-462-6
COGNITIVE 2016 : The Eighth International Conference on Advanced Cognitive Technologies and Applications

Figure 2. Actuator Subclasses.
resources for the representation of the exchange of information
between the cognitive and robot part systems.
Robotics report V.O. [11] proposes the creation of an
environment called ”Robot City Environment“, where robots
would be inserted and validated through interactions with
human actors. The use of validation environments is the basis
for a system testing, however, ”Robot City Environment“
incurs a high implementation cost.
We propose an alternative approach based on a simulator
rather than emulated cities. Figure 3 shows the architecture for
the simulator called Cognitive Model Development Environ-
ment (CMDE), which represents an environment for the eval-
uation of cognitive models. CMDE consists of two processing
nodes, of which the ﬁrst implements a ”cognitive system”
to be tested in CMDE environment and the second, called
Robot City Simulator (RCS), is a cognitive model simulator.
RCS includes the ”robot part system“ and the programming
interfaces used in the parameterization of the environment
required during a simulation.
Figure 3. Cognitive Model Development Environment.
IV.
CONCLUSION
This paper has addressed the hypothesis there exists a
gap of communication between cognitive and robot part sys-
tems that directly impacts on the complexity increase in the
cognitive systems development and difﬁculty of reproducing
experiments. The strategy proposed for its minimization is the
deﬁnition of an ontology that enables the design of a cognitive-
level protocol for the development of socially interactive
robots.
The expected results are more ﬂexibility to the process
of elaboration and validation of robotic cognitive systems by
decreasing the researcher efforts and allowing the development
of cognitive research in smaller laboratories and with fewer
resources through simulators adherent to ”OntCog“ ontology.
ACKNOWLEDGMENT
The authors acknowledge FAPESP (2013/26453-1) for the
ﬁnancial support. This study is part of a PhD thesis and all
criticisms or contributions are welcome.
REFERENCES
[1]
IFR, “World Robotics Survey: Service Robots are Conquering the
World,” International Federation of Robotics (IFR), Alemanha, Frank-
furt, 2015, URL: http://www.worldrobotics.org/ [accessed: 2016-01-23].
[2]
T. Fong, I. Nourbakhsh, and K. Dautenhahn, “A survey of socially
interactive robots,” Robotics and Autonomous Systems, vol. 42, no.
3-4, 2003, pp. 143–166.
[3]
R. R. Murphy, Introduction to AI Robotics.
MIT press, 2000, ISBN:
978-02-62-13-38-38.
[4]
P. Langley, J. E. Laird, and S. Rogers, “Cognitive architectures: Re-
search issues and challenges,” Cognitive Systems Research, vol. 10,
no. 2, 2009, pp. 141–160.
[5]
“1872-2015 IEEE Standard Otologies for Robotics and Automation,”
IEEE, New York, NY, 2015.
[6]
J. Novikova, L. Watts, and T. Inamura, “Modeling Human-Robot
Collaboration in a Simulated Environment,” in Proceedings of the
Tenth Annual ACM/IEEE International Conference on Human-Robot
Interaction Extended Abstracts - HRI’15 Extended Abstracts.
New
York, New York, USA: ACM Press, 2015, pp. 181–182, ISBN: 978-
14-50-33-31-84.
[7]
M. Faber, S. Kuz, M. P. Mayer, and C. M. Schlick, “Design and
Implementation of a Cognitive Simulation Model for Robotic Assembly
Cells,” in Lecture Notes in Computer Science, Don Harris, Ed. Springer
Berlin Heidelberg, 2013, ch. 24, pp. 205–214.
[8]
V. A. Jorge, V. F. Rey, R. Maffei, S. R. Fiorini, J. L. Carbonera,
F. Branchi, J. P. Meireles, G. S. Franco, F. Farina, T. S. da Silva,
M. Kolberg, M. Abel, and E. Prestes, “Exploring the IEEE ontology for
robotics and automation for heterogeneous agent interaction,” Robotics
and Computer-Integrated Manufacturing, vol. 33, jun 2015, pp. 12–20.
[9]
E. Prestes, J. L. Carbonera, S. R. Fiorini, V. A. M. Jorge, M. Abel,
R. Madhavan, A. Locoro, P. Goncalves, M. E. Barreto, M. Habib,
A. Chibani, S. Gerard, Y. Amirat, and C.Schlenoff, “Towards a core
ontology for robotics and automation,” Robotics and Autonomous
Systems, vol. 161, 2013, pp. 1193–1204.
[10]
C. W. N. Guarino, “An overview of ontoclean,” Handbook on On-
tologies, International Handbooks on Information Systems, 2009, p.
201220.
[11]
V. O. Robotics, “A Roadmap for U.S. Robotics: From Internet to
Robotics,” Robotics Virtual Organization, 2013, URL: https://robotics-
vo.us/sites/default/ﬁles/2013%20Robotics%20Roadmap-rs.pdf
[accessed: 2016-01-23].
3
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-462-6
COGNITIVE 2016 : The Eighth International Conference on Advanced Cognitive Technologies and Applications

