Using Brain-Computer Interface and Internet of Things to Improve Healthcare for
Wheelchair Users
Ariel Teles∗, Maur´ıcio Cagy†, Francisco Silva‡, Markus Endler§, Victor Bastos¶ and Silmar Teixeira¶
∗Federal Institute of Maranh˜ao, Brazil, Email: ariel.teles@ifma.edu.br
†Federal University of Rio de Janeiro, Brazil, Email: mcagy@peb.ufrj.br
‡Federal University of Maranh˜ao, Brazil, Email: fssilva@lsdi.ufma.br
§Pontiﬁcal Catholic University of Rio de Janeiro, Brazil, Email: endler@inf.puc-rio.br
¶Federal University of Piau´ı, Brazil, Email: {victorhugobastos, silmarteixeira}@ufpi.edu.br
Abstract—Brain-to-Thing Communication (BTC) is a type of
ubiquitous system that aims to allow the communication from the
human brain to smart objects in the Internet of Things (IoT).
In this way, brain commands can be used to remotely control
sensing and actuation of IoT devices. In this paper, we propose a
BTC system for healthcare and show the viability to develop
it. We present our BTC system architecture for wheelchair
users, an illustrative application example, research challenges in
this domain, and we show our current development status and
perspectives.
Keywords–Brain-to-Thing Communication; Internet of Things;
Brain-computer Interface.
I.
INTRODUCTION
The Internet of Things (IoT) paradigm proposes the expan-
sion of the current Internet infrastructure towards a network
with smart objects connected to each other, which not only
obtain environmental information, but also interact with the
physical world using existing Internet patterns to provide
information transparency services, analysis, applications and
communications [1]. In this sense, IoT is not related only to
interconnection of devices to the Internet, but also with (i)
the knowledge acquisition from each smart object and from
the physical word around it (i.e., sensing), and (ii) performing
actions on the smart object (i.e., actuation).
On the other hand, the Brain-Computer Interface (BCI)
technology has been proposed, which is a “communication
system that does not depend on the brain’s normal output
pathways of peripheral nerves and muscles” [2]. A BCI system
enables a human to interact with the surrounding environment
through brain-generated signals (i.e., brain activity) obtained
via ElectroEncephaloGraphy (EEG). BCI systems have nor-
mally been proposed to provide communication for people
with some type of physical paralysis. Some BCI system
examples are neural prostheses, robotic wheelchair [3], and
robots in general.
From the union of IoT and BCI systems, we propose a
Brain-to-Thing Communication (BTC) system for healthcare.
The main idea is to enable a communication from the brain
to smart objects (i.e., the “things”) for wheelchair users. This
will allow actuation and sensing to be performed on smart
objects via commands sent by people from their controlled
brain activity. In this way, the BTC system can contribute
to improve quality of life and reduce intensive care costs for
people with some physical or motor problem and who need
to use a wheelchair (e.g., paraplegics, patients with severe
diseases, such as Amyotrophic Lateral Sclerosis, or people who
have suffered from a stroke), providing a mean to enable them
to become more independent.
The rest of this paper is organized as follows. Section II
presents the initial architecture of our proposed BTC system.
Next, Section III exhibits a real illustrative example to show the
usage of our proposed system. Section IV gives an overview
of the challenges faced by this research. Finally, in Section V,
we drive our conclusions.
II.
SYSTEM ARCHITECTURE
Figure 1 illustrates the architecture of our proposed BTC
system. Initially, signals are obtained in real-time via EEG
and sent to the Recognizer component, which analyses and
recognizes pre-deﬁned patterns. These brain activity patterns
represent mental states of the user (e.g., left hand or right
hand imagined movements) and are recognized by signal-
processing techniques [4]. A non-invasive EEG is a method to
register brain activities with electrodes externally distributed
along the head of the user. In cases in which it is required to
identify only speciﬁc patterns (e.g., wink/blink, mouth bite,
and muscle artefacts in general, such as hands movements
and swallowing), only a few of electrodes are necessary to
register signals, such as have been used by commercial and
opened wearable devices (e.g., headsets, glasses, and caps as
OpenBCI [5]). In this sense, that type of hardware is expected
to be used for BTC systems, even if it is required to be adapted
or embedded in a wheelchair.
Figure 1. BTC System Architecture.
Recognized brain activity patterns are forwarded to the
user’s mobile device (e.g., smartphone, tablet) and used as
input to an IoT mobile application, which can remotely com-
municate via Internet protocols with online smart objects,
which are connected to the Internet via WiFi. By means of this
92
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

communication, a brain activity pattern that is recognized by
the Recognizer component can be used by the user to control
smart objects. Therefore, BTC systems provide an alternative
communication channel to perform actions and sensing in
smart objects via commands sent by users from their controlled
brain activities.
BTC Communication differs from IoT systems in general
by providing a new communication channel for users, the
brain. It differs from traditional BCI systems by proposing
the following features:
•
Smart environments: smart objects should be spread
in the environment with embedded systems running
sensing and actuation services (e.g., Raspberry PI [6],
Arduino [7], and so on), providing smartness to the
place where the wheelchair user lives (i.e., places
where the user goes during his/her daily routine);
•
Mobility: a wheelchair mobile user can continuously
use the system anywhere and anytime, not only where
he/she lives, but also during all his/her daily routine
activities, remotely sending brain commands via a
mobile application to smart objects;
•
Transparency for the system: IoT and mobile appli-
cations do not know that user inputs are generated
by recognized brain activities, because there is a
component to recognize brain-generated commands;
•
User-aware conﬁrmations: brain commands sent to the
mobile device must trigger visual, audio, or vibratory
conﬁrmations in the application to allow wheelchair
users to know the brain activity patterns recognized
by the system. This is specially important because, in
some cases, the user may also have some communi-
cation problem (e.g., a blind, deaf, or mute person),
requiring the user to know if the system correctly
identiﬁed the command to be sent to a smart object;
•
User-aware interfaces: mobile application interfaces
should be adapted to allow an appropriate navigation.
For example, the mobile application should have a
few button options, limited to the number of brain
activity patterns that can be recognized, providing a
full mapping from all patterns to navigation options.
III.
AN ILLUSTRATIVE EXAMPLE
Consider a person called Bob, a patient who lives most
of the time in a wheelchair. At the same time, he would like
to have a mechanism to control home appliances, because his
wife works and thus he lives most of the day alone. By using a
BTC system, Bob can turn on/off a lamp, an air conditioner, a
television, a hot shower, or a residential security system in his
smart home. Moreover, as the brain-to-thing communication is
made through a home area network, if Bob is not physically
located at his bedroom, he can also send brain commands to
remotely control smart objects located there. For example, Bob
can obtain the current state of the lamp located in his bedroom,
use the mobile application to visualize this information, and
act over the lamp, turning it on/off. Therefore, a BTC system
is designed to provide resources for people with physical
disabilities, mainly wheelchair users, and help them become
more independent.
IV.
CHALLENGES
Some recent works in literature are going towards BTC
systems by proposing initial solutions that show the technical
viability to connect the brain with smart objects, such as
[8] and [9]. Other recent proposals, such as [10] and [11],
develop BTC applications for smart homes combining user
inputs from the EEG with other devices (e.g., glass, mouse,
keyboard). However, our solution mainly differs from all of
them because it is focused on supporting wheelchair users,
which have several limitations. This lies the novelty of our
idea. In this sense, in addition to using real-time mobile
network protocols to avoid delays in the communication among
system components, our solution aims to address some non-
trivial challenges in this domain:
•
Real-time EEG signal processing: EEG signals should
be processed and brain activity patterns recognized in
real-rime by the Recognizer component;
•
Good accuracy in recognizing brain activities: the
Recognizer component should have a high success rate
in identifying EEG signal patterns, in order to avoid
mistakes. Of course, it is required that wheelchair
users have knowledge about the system usage. For
this, an initial training phase is needed. This phase
is also required to calibrate the system;
•
User-oriented mobile application: as previously ex-
plained in Section II, mobile application interfaces
and conﬁrmations should be developed considering
the special needs of wheelchair users (e.g., physical
movement and communication restrictions), which is
a big challenge from the human-computer interface
point of view.
V.
CONCLUSION
We are currently developing the Recognizer component in
Java. We decided to use this platform because of its rich devel-
opment framework and wide acceptance. This implementation
is integrating a commercial EEG in Brazil with Android mobile
devices. The current version of the Recognizer component is
identifying left and right hand imagined movements. We are
also developing the mobile and IoT applications for Android
OS and using a pub/sub communication middleware, the
Scalable Data Distribution Layer (SDDL) [12]. In a second
step, we intend to provide our solution regarding the ability
of communicating with other people via a chat application.
We will evaluate our solution considering as metric the accu-
racy in recognizing brain activities and also Human-computer
interaction aspects, given that users may have different types
of limitations. As future research efforts, we plan to develop a
EEG wearable device in a cap format with additional resources,
such as Global Positioning System and other embedded sen-
sors.
ACKNOWLEDGMENTS
The authors would like to thank the Fundac¸˜ao de Amparo
`a Pesquisa e ao Desenvolvimento Cient´ıﬁco e Tecnol´ogico do
Maranh˜ao (FAPEMA) for the ﬁnancial support.
REFERENCES
[1]
J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of things
(iot): A vision, architectural elements, and future directions,” Future
Generation Computer Systems, vol. 29, no. 7, Sep. 2013, pp. 1645–
1660.
93
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

[2]
Jonathan R. Wolpaw et al., “Brain-computer interface technology:
a review of the ﬁrst international meeting,” IEEE Transactions on
Rehabilitation Engineering, vol. 8, no. 2, Jun 2000, pp. 164–173.
[3]
T. Kaufmann, A. Herweg, and A. K¨ubler, “Toward brain-computer
interface based wheelchair control utilizing tactually-evoked event-
related potentials,” Journal of NeuroEngineering and Rehabilitation,
vol. 11, no. 1, Jan 2014, p. 17.
[4]
F. Lotte, A Tutorial on EEG Signal-processing Techniques for Mental-
state Recognition in Brain–Computer Interfaces.
Springer London,
2014, pp. 133–161.
[5]
Openbci. [Online]. Available: http://openbci.com/ [retrieved: November,
2017]
[6]
Raspberry
pi.
[Online].
Available:
https://www.raspberrypi.org/
[retrieved: November, 2017]
[7]
Arduino.
[Online].
Available:
https://www.arduino.cc/
[retrieved:
November, 2017]
[8]
E. Mathe and E. Spyrou, “Connecting a consumer brain-computer
interface to an internet-of-things ecosystem,” in Proceedings of the 9th
ACM International Conference on PErvasive Technologies Related to
Assistive Environments, ser. PETRA ’16, 2016, pp. 90:1–90:2.
[9]
K. Sadeghi, A. Banerjee, J. Sohankar, and S. K. S. Gupta, “Optimization
of brain mobile interface applications using iot,” in 2016 IEEE 23rd
International Conference on High Performance Computing (HiPC), Dec
2016, pp. 32–41.
[10]
C. P. Brennan, P. J. McCullagh, L. Galway, and G. Lightbody, “Promot-
ing autonomy in a smart home environment with a smarter interface,” in
Annual International Conference of the IEEE Engineering in Medicine
and Biology Society, 2015.
[11]
E. D. Buyser, E. D. Coninck, B. Dhoedt, and P. Simoens, “Exploring
the potential of combining smart glasses and consumer-grade eeg/emg
headsets for controlling iot appliances in the smart home,” in IET
International Conference on Technologies for Active and Assisted
Living, 2016, pp. 1–6.
[12]
L. David, R. Vasconcelos, L. Alves, R. Andr´e, and M. Endler, “A dds-
based middleware for scalable tracking, communication and collabora-
tion of mobile nodes,” Journal of Internet Services and Applications,
vol. 4, no. 1, 2013.
94
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-598-2
UBICOMM 2017 : The Eleventh International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

