Bandwidth on Demand over Carrier Grade Ethernet Equipment 
 
Christos Bouras1,2, Theoni-Katerina Spuropoulou2 and Kostas Stamos1,2,3 
1 Computer Technology Institute and Press “Diophantus”, N. Kazantzaki Str, University Campus 26504, Rio Greece 
2Computer Engineering and Informatics Dept., University of Patras 
3Technological Educational Institute of Patra, Greece  
bouras@cti.gr, spuropoulo@ceid.upatras.gr, stamos@cti.gr 
 
 
Abstract—This paper presents the prototype implementation of 
a Bandwidth on Demand (BoD) service over equipment using 
Carrier Grade Ethernet. The BoD multi-domain service is 
based on AutoBAHN (Automated Bandwidth Allocation across 
Heterogeneous Networks) software. The paper describes the 
steps that have taken place for designing and implementing a 
prototype technology proxy that is able to match the Carrier 
Grade Ethernet equipment with AutoBAHN, based on the 
implementations of the relevant standards and technologies by 
Extreme Networks. The equipment in particular is comprised 
of BlackDiamond 12804 switches, running ExtremeXOS 
version 12. The paper demonstrates how a suitable testbed can 
be created and utilized and how a new technology at the data 
plane can be supported by a Bandwidth on Demand tool. 
Keywords-Carrier Grade Ethernet; BlackDiamond switches; 
Bandwidth on Demand; AutoBAHN 
I. 
INTRODUCTION 
The GN3 European project [1] is a research project 
funded by the European Union and Europe's National 
Research and Education Networks (NRENs). It is a 
continuation of the previous GN2 project and aims at 
building and supporting the next generation of the pan-
European research and education network, which connects 
universities, institutions and other research and educational 
organizations around Europe and interconnects them to the 
rest of the Internet using high-speed backbone connections. 
In the context of this project, a BoD service is being 
developed and the service is supported by the AutoBAHN 
tool. 
The AutoBAHN system [2] is capable of provisioning 
circuits in heterogeneous, multi-domain environments that 
constitute the European academic and research space and 
allows for both immediate and advanced circuit reservations. 
The overall architecture of the AutoBAHN system, its goal 
and the network mechanisms it employs are thoroughly 
presented in [3]. 
This paper presents the prototype implementation of a 
Technology Proxy (TP) for Carrier Grade Ethernet (CGE) 
equipment. AutoBAHN may support multiple underlying 
technologies, and Carrier Grade Ethernet features a 
promising set of characteristics for network carriers. This is 
one of the first attempts at using a CGE network within a 
multi-domain Bandwidth on Demand service, and the 
conclusions of this work are therefore useful in order to 
determine the effectiveness and required effort of using CGE 
as the underlying technology for such purposes. It also 
enables us to compare the degree to which CGE 
implementations lend themselves to participation in a multi-
domain automated reservation service. 
The rest of the paper is structured as follows: 
Section II presents the Carrier Grade Ethernet technology 
and related standards, while Section III introduces the 
general architecture of the AutoBAHN system with an 
emphasis on its lower levels that interact with the underlying 
equipment. Section IV describes the TP framework that has 
been used for handling the creation of the interface towards 
the underlying network technology. Section V focuses on the 
implementation that took place including the testing to verify 
our work. Finally, Section VI concludes the paper and 
presents future fields of related study. 
II. CARRIER GRADE ETHERNET 
Carrier Grade Ethernet (CGE) in general refers to the 
enhancements to Ethernet standards in order to be suitable as 
a carrier-grade and transport technology [4]. 
 
Carrier Ethernet Transport
Multi-technology
DSL
RPR
SONET/
SDH
MPLS
PB / PBB
PBB-TE
Application Services
 
Figure 1. Carrier Ethernet technologies 
 
This section presents briefly the main standards and how 
these relate to the Carrier Grade Ethernet concepts. There are 
several aspects of Ethernet that need to be modified or 
enhanced in order for a technology that was initially 
designed for local area networks to be suitable for carrier 
grade 
deployments 
([5][6][7]). 
In 
general, 
several 
technologies can be considered Carrier Ethernet, including 
204
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

solutions based on carrying Ethernet over Resilient Packet 
Ring (RPR), SDH or DSL technologies, or over MPLS. All 
these approaches can be used to carry applications over 
Ethernet backhaul. However we are focused on so-called 
pure Ethernet centric solutions (Figure 1). Below we give a 
brief overview of the main related protocols that comprise a 
CGE deployment based on pure Ethernet centric solutions. 
The Link Layer Discovery Protocol (LLDP) is a vendor-
neutral Link Layer protocol used by network devices for 
advertising their identity, capabilities, and neighbours on an 
IEEE 802 local area network. The protocol is formally 
referred to by the IEEE as Station and Media Access Control 
Connectivity Discovery specified in standards document 
IEEE 802.1AB [8]. There are several proprietary protocols 
that perform functions similar to LLDP, such as Cisco 
Discovery Protocol, Extreme Discovery Protocol, Nortel 
Discovery Protocol (also known as SONMP), and 
Microsoft's Link Layer Topology Discovery (LLTD). 
IEEE 802.1ad (Provider Bridges) [9] is an amendment to 
IEEE standard IEEE 802.1Q-1998 (aka QinQ or Stacked 
VLANs) [10], intended to develop an architecture and bridge 
protocols to provide separate instances of the MAC services 
to multiple independent users of a Bridged Local Area 
Network, in a manner that does not require cooperation 
among the users, and requires a minimum of cooperation 
between the users and the provider of the MAC service. The 
idea is to provide, for example, the possibility for customers 
to run their own VLANs inside service provider's provided 
VLAN. This way the service provider can just configure one 
VLAN for the customer and customer can then treat that 
VLAN as if it was a trunk. 
Provider Backbone Bridges (PBB) or IEEE 802.1ah-
2008 is a set of architecture and protocols for routing of a 
customer network over a provider's network allowing 
interconnection of multiple Provider Bridge Networks 
without losing each customer's individually defined VLANs. 
It was initially created as a proprietary extension by Nortel 
before being submitted to the IEEE 802.1 committee for 
standardization. The final standard was approved by the 
IEEE in June 2008. [11] 
Provider Backbone Bridge Traffic Engineering (PBB-
TE) is an approved networking standard, IEEE 802.1Qay-
2009 [12]. PBB-TE adapts Ethernet technology to carrier 
class transport networks. It is based on the layered VLAN 
tags and MAC-in-MAC encapsulation defined in IEEE 
802.1ah (Provider Backbone Bridges (PBB), but it differs 
from PBB in eliminating flooding, dynamically created 
forwarding tables, and spanning tree protocols. Compared to 
PBB and its predecessors, PBB-TE behaves more 
predictably and its behavior can be more easily controlled by 
the network operator, at the expense of requiring up-front 
connection configuration at each bridge along a forwarding 
path. PBB-TE operational administration and maintenance 
(OAM) is usually based on IEEE 802.1ag. It was initially 
based on Nortel's Provider Backbone Transport (PBT). 
PBB-TE's connection-oriented features and behaviors, as 
well as its OAM approach, are inspired by SDH/SONET. 
PBB-TE can also provide path protection levels similar to 
the UPSR (Unidirectional Path Switched Ring) protection in 
SDH/SONET networks. 
IEEE 802.1ag IEEE Standard for Local and Metropolitan 
Area Networks Virtual Bridged Local Area Networks 
Amendment 5: Connectivity Fault Management [13] is a 
standard defined by IEEE. It defines protocols and practices 
for OAM (Operations, Administration, and Maintenance) for 
paths through 802.1 bridges and local area networks (LANs). 
It is an amendment to IEEE 802.1Q-2005 and was approved 
in 2007. IEEE 802.1ag is largely identical with ITU-T 
Recommendation Y.1731, which additionally addresses 
performance management. 
 
III. ARCHITECTURE DESCRIPTION 
The aim of the BoD service, as defined in GEANT, is to 
provide dedicated channels for data transport, which are 
necessary for demanding applications and research fields 
with strict demands for the provisioning of guaranteed and 
dedicated capacity and high security level in the sense that 
the carried traffic is isolated from other traffic. This service 
is offered collaboratively by GÉANT and a set of adjacent 
domains (NRENs or external partners) that adhere to its 
requirements. These joint networks form a multi-domain 
area where the service is provided between two end points, 
which may belong to the same or different domains. 
The AutoBAHN system operates in a multi-domain 
environment and consists of several modules that take over 
the resource negotiation, pathfinding, topology abstraction 
and exchange, admission control and other necessary 
operations in order for a multi-domain circuit reservation to 
be processed. At the final stage of processing, a circuit has to 
be realized by sending the appropriate configuration 
commands to the network devices. The AutoBAHN software 
stack is shown in Figure 2 and it is repeated at each domain 
that participates in the BoD service. Domain instances 
communicate with each other via the Inter-Domain Manager 
(IDM) module. 
 
Figure 2. AutoBAHN architecture [2] 
205
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

Network device configuration may take place via a 
Network Management System (NMS) or with direct 
application of configuration commands on devices. In both 
cases, the AutoBAHN module that is responsible for 
bridging the generic AutoBAHN software stack with the 
technology-specific NMS or network devices is called 
Technology Proxy (TP). The TP translates the reservation 
requests, received from the DM, to the appropriate 
commands to be sent (usually via SSH) to a network or an 
NMS. Each domain participating in the BoD service, 
depending on the underlying technology, uses a customized 
version of the TP module. 
IV. TP FRAMEWORK 
Developing a customized Technology Proxy module for 
each domain participating in the BoD service is time-
consuming and may be difficult to accomplish as the 
necessary development manpower may not be available. 
Therefore, AutoBAHN provides the TP framework [2], 
which enables the creation of a customized TP without the 
need to develop software. Instead, all that has to be done is to 
edit the TP configuration with the appropriate network 
configuration commands for setting up and tearing down 
circuits. The TP framework then takes care of generating a 
TP that is capable of bridging the AutoBAHN software with 
the underlying data plane equipment. The TP framework 
configuration is based on XML, and allows the definition of 
several communications methods (such as Telnet or SSH), 
which can also be customized or extended. It can also 
accommodate various vendors, equipment models and 
Operating System versions, using an extensible loader 
architecture. Furthermore, it provides scripting functionality 
for more complicated command structures. Finally, the TP 
framework provides detailed logging so that the network 
administrator may troubleshoot erroneous behavior or failed 
requests. 
V. IMPLEMENTATION 
The Carrier Grade Ethernet TP was prototyped for the 
case of a network implemented with ExtremeNetworks 
equipment and especially with BlackDiamond 12804 
switches. The BlackDiamond 12800 switches allow a single 
Ethernet network to deliver both residential and business 
services. They are chassis-based, Ethernet service core 
switches designed for core applications. Their features 
include hot-swappable I/O modules, Management Switch 
Fabric Modules (MSMs) that provide the active switching 
fabric and CPU control subsystem, auto-negotiation for half-
duplex or full-duplex operation on 10/100/1000 Mbps ports 
and load sharing on multiple ports. They are running 
ExtremeXOS operating system, which supports PBB and 
PBB-TE. 
The PBB-TE technology in particular is the one chosen 
for implementing the dynamic circuit service. PBB-TE 
allows the creation of a traffic engineered service instance 
path that behaves much like a dedicated service line and 
operates over an Ethernet network. A PBB-TE path is a static 
path through a Provider Backbone Bridge Network (PBBN), 
which is a 2 network that supports 802.1ad frames (also 
called Q-in-Q or vMAN in Exterme Networks terminology). 
If a vMAN connects to a PBB-TE path, vMAN frames 
always follow the same path to the egress PBB. If a vMAN 
connects to a PBB, vMAN frames are switched based on the 
configuration of the PBBN switches. PBB-TE changes the 
existing forwarding behavior as defined in 802.1Q to a new 
forwarding behavior by introducing a new port state: 
forwarding with address learning disabled. On a PBB-TE 
link, all broadcast, multicast, and unicast packets with an 
unknown destination MAC address are discarded. PBB-TE 
relies on Ethernet OAM (CFM) for fault detection and 
restoration of provisioned paths. CFM actively monitors all 
provisioned (working and protection) paths. A protection 
path is selected by mapping a Service VLAN (SVLAN) to a 
different BVLAN, which defines all the switch ports that 
link the tunnel endpoints. 
Each switch offers a command line interface which can 
be used by the CGE TP to independently configure each 
switch in the network. This means that the CGE TP needs to 
have knowledge of the underlying network and make 
complicated decisions. Access to the command line interface 
is provided via Telnet, from a strict set of machines within 
the internal testbed network (Figure 3). The testbed, as 
shown on figure 2, consists of three Extreme BlackDiamond 
12804 Carrier Grade Ethernet switches and virtual machines 
as traffic source and destination. MAC addresses of all 
switches and of the virtual machine are either already known 
or discovered through the LLDP protocol supported in the 
switches. Connectivity to the outside world is provided over 
JANET, the research and education network of the UK. 
The Domain Manager (DM) of AutoBAHN submits its 
requests for reservation or deletions of reservations and the 
CGE TP sends its responses using a pre-defined Web 
Services (WS) interface for the DM-TP communication. The 
reservation request as sent by the DM fully describes the 
desired route and request parameters (such as required 
VLAN, capacity, start and end times), leaving to the TP only 
the configuration of the relevant switches. 
 
 
Figure 3. The testbed network, provided by University of Essex 
206
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

For the purpose of the PBB-TE tunnel function, we 
initially defined two BVLANs, creating them statically on 
the interface, so that the TP does not have to recreate them 
every time it processes a reservation request from 
AutoBAHN. The first BVLAN consists of edge switches 4A 
and 4B, while the second includes core switch 5A. Edge 
switches receive customer VLAN traffic from virtual 
machines and transform it into SVLAN traffic, to be inserted 
into the PBBN. By disabling address learning on the 
switches, we gain complete control over the PBBN path, 
since each path is a static route. On a PBB-TE link, all 
broadcast, multicast, and unicast packets with an unknown 
destination MAC address are discarded. The PBB-TE trade-
off is that it takes away the Ethernet self-configure and self-
healing mechanisms. We rely on AutoBAHN for the 
selection of the desired route. By disabling flooding we 
ensure that all path traffic is limited to the configured path. 
Finally, by configuring FDB entries on the egress port of 
each switch along the route, we define the possible paths. 
The implementation described above was tested using a 
simplified client application that provided the TP with 
incoming requests. The TP was able to successfully 
configure the testbed switches as described in the relevant 
sections, setting up a PBB-TE tunnel and enabling layer 2 
connectivity 
between 
the 
desired 
end 
points. 
The 
implemented architecture allows the network administrator 
to define pre-determined paths (using the BVLAN 
configuration described above), which leads to predictable 
traffic management and load balancing. AutoBAHN is then 
used for the creation of the circuits on-demand, making 
dynamic use of the pre-determined paths. It is also possible 
for the administrator to devote a subset of the available 
capacity for the Bandwidth on Demand service, reserving the 
rest for manual configuration or other purposes. 
VI. CONCLUSION AND FUTURE WORK 
Our work focused on integrating a testbed network based 
on equipment supporting Carrier Grade Ethernet standards 
with a multi-domain BoD service. The outcome of our work 
demonstrates that Carrier Grade Ethernet is a viable 
technology for such purposes, even in cases where the 
equipment does not provide a proprietary network 
management solution. Furthermore, we verified that the TP 
framework component that has been developed within the 
GN3 project greatly eases the necessary work for developing 
a bandwidth on demand module for a novel technology. This 
means that different technologies or different vendor 
implementations can be accommodated faster and with fewer 
resources because emphasis needs only to be put on properly 
aligning the technology with the service requirements rather 
than on low level programming tasks.  
Our future work will focus on further testing and 
performance evaluation of Carrier Grade Ethernet operation 
in a broader Bandwidth on Demand context. There are a 
number of possible technology stitching requirements that 
may arise from the interoperation of Carrier Grade Ethernet 
with other technologies supporting Bandwidth on Demand in 
a multi-domain environment, and we plan to investigate 
them in both testbed and production settings. Another aspect 
that we were unable to cover was the one of bandwidth 
limiting or shaping techniques, since VLAN tag was the only 
information available to identify and separate network 
traffic, but BlackDiamond 12804 series switches did not 
support VLAN based traffic groups. We intend to investigate 
solutions to this issue in the future either with the equipment 
under consideration or different equipment. 
ACKNOWLEDGMENTS 
The authors would like to acknowledge the contribution 
of their GN3 partners and especially Ramanujam Jayakumar 
and Mayur Channegowda from University of Essex who 
provided access and support for usage of the CGE 
equipment. 
REFERENCES 
[1] “GN3 
European 
Project,” 
[Online]. 
Available: 
http://www.geant.net/pages/home.aspx. 
[2] AutoBAHN, [Online]. Available: autobahn,geant.net 
(Accessed September 2012) 
[3] M. Campanella, R. Krzywania, V. Reijs, A. Sevasti, K. 
Stamos, C. Tziouvaras, and D. Wilson, “Bandwidth on 
Demand Services for European Research and Education 
Networks”, 1st IEEE International Workshop on Bandwidth 
on Demand, 27 Nov 2006, San Francisco (USA). 
[4] R. Sanchez, L. Raptis, and K. Vaxevanakis, “Ethernet as a 
carrier grade technology: developments and innovations”, 
Communications Magazine, IEEE, Vol. 46, Issue 9, pp. 88-
94, September 2008 
[5] Marwan Batayneh, Dominic A. Schupke, Marco Hoffmann, 
Andreas Kirstaedter, Biswanath Mukherjee, and Biswanath 
Mukherjee, “Lightpath-Level Protection versus Connection-
Level Protection for Carrier-Grade Ethernet in a Mixed-Line-
Rate Telecom Network”, GLOBECOM 2009, pp. 2178-2182 
[6] K. Ogaki, and T. Otani, “GMPLS Ethernet and PBB-TE (A 
carrier's view)”, Conference on Optical Fiber Communication 
(OFC) 2009, pp. 1-4 
[7] Wonkyoung Lee, Chang-Ho Choi, Taesik Cheung, Sun-Me 
Kim, and Ho-Young Song, “Implementation of hierarchical 
QoS mechanism on PBB-TE system”, 9th International 
Conference on Optical Internet (COIN), 2010, pp. 1-3 
[8] The Institute of Electrical and Electronics Engineers, 
“802.1ab: Station and Media Access Control Connectivity 
Discovery” IEEE Standard for Local and metropolitan area 
networks, 6 May 2005, IEEE 
[9] The Institute of Electrical and Electronics Engineers, 
“802.1ad: 
Virtual 
Bridged 
Local 
Area 
Networks 
- 
Amendment 4: Provider Bridges” IEEE Standard for Local 
and metropolitan area networks, 26 May 2006, IEEE 
[10] The Institute of Electrical and Electronics Engineers, 
“802.1Q: Virtual Bridged Local Area Networks” IEEE 
Standard for Local and metropolitan area networks, 19 May 
2006, IEEE 
[11] The Institute of Electrical and Electronics Engineers, 
“802.1ah: 
Virtual 
Bridged 
Local 
Area 
Networks 
- 
Amendment 7: Provider Backbone Bridges” IEEE Standard 
for Local and metropolitan area networks, 14 August 2008, 
IEEE 
[12] The Institute of Electrical and Electronics Engineers, 
“802.1Qay: Virtual Bridged Local Area Networks - 
Amendment 
10: 
Provider 
Backbone 
Bridge 
Traffic 
Engineering” IEEE Standard for Local and metropolitan area 
networks, 5 August 2009, IEEE 
207
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

[13] The Institute of Electrical and Electronics Engineers, 
“802.1ag: 
Virtual 
Bridged 
Local 
Area 
Networks 
- 
Amendment 5: Connectivity Fault Management” IEEE 
Standard for Local and metropolitan area networks, 17 
December 2007, IEEE 
208
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-245-5
ICN 2013 : The Twelfth International Conference on Networks

