 
Spatial Ability and Map-Based Software Applications 
 
M. L. Ruscha, S. M. Nusserb, L. L. Millerc, G. I. Batinovc, K. C. Whitneyc 
aDepartment of Neurology and Department of Mechanical and Industrial  
Engineering, University of Iowa, Iowa City, IA  52242 
bDepartment of Statistics, Iowa State University, Ames, IA  50011-1210 
cDepartment of Computer Science, Iowa State University, Ames, IA  50011-1041 
 
ABSTRACT 
Location-based 
applications 
are 
growing 
in 
importance as agencies are placing more and more 
computing into their field applications.  The 
development of software for these applications needs 
to consider the wide range of user skills.  The present 
work looks at the impact of spatial ability on a typical 
Census Bureau application (address verification).  A 
study of a text guided software system for address 
verification was conducted. The participants were 
tested 
to 
determine 
their 
logical 
reasoning, 
visualization, and perspective taking abilities.  The 
participants performed a set of address verification 
tasks using a tablet in a stationary environment.  The 
study and results are presented and discussed.    
 
Keywords: usability, spatial ability. 
 
I. INTRODUCTION 
Human 
computer 
interaction 
(HCI) 
researchers have recognized the importance of 
individual differences in cognitive abilities for 
designing effective software applications.  Zhang and 
Norman [15] argue that a cognitive task is never 
solely dependent upon the internal mindset of the 
users nor is it solely related to effectiveness of 
software design.  Both individual differences and 
system design have the potential to influence 
computer performance.  Among these differences, 
spatial ability has been found to be one of the 
strongest predictors of human computer performance 
[2,3,4,12].  Lohman [8] defined spatial ability as “the 
ability to generate, retain, retrieve, and transform 
well-structured visual images” (p. 98).   
Spatial ability has several dimensions.  Two 
important 
components 
are 
visualization 
and 
orientation.  Spatial visualization has been defined as 
the “ability to manipulate or transform the image of 
spatial patterns into other arrangements” [5, p. 173].  
Spatial orientation has been defined as the “ability to 
perceive spatial patterns or to maintain orientation 
with respect to objects in space” [5, p. 149]. 
Visualization and orientation have been shown to be 
distinct from one another [6] yet most research on 
computer performance examines either one or the 
other [9]. The importance of spatial ability in 
software user performance suggests that it may be 
advantageous to the user if software systems were 
able to accommodate individual differences in spatial 
ability.  Sein, Olfman, Bostrom, and Davis [10] 
investigated visualization ability in relationship to the 
usage of three applications (email, modeling 
software, and operating systems).  They found that 
persons with high visualization skills learned fastest 
on all of the applications.   
Another area related to interface design that 
we found support for in the literature is guided 
systems.  Berger et al. [1] found that student’s 
performance in discovery systems was dependent on 
the level of their cognitive abilities.  Sein et al. [10] 
showed that low spatial users’ performance could be 
improved by reducing the need for discovery.  
Meanwhile, Zhang [14] showed that externalization 
of help aids and extra navigation information can 
offset the costs of using them.  Vicente et al. [11] 
suggest the use of a task list and instructions for users 
as a possible accommodating strategy for users of a 
spatial user interface. 
35
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
To investigate these ideas, we developed an address 
verification software system.  In this task, Census 
Bureau field staff evaluate whether the location of an 
address on the ground is properly represented on the 
map.  If a map error is detected, the location of the 
housing unit on the map is modified to correct the 
error.  This task can be cognitively demanding.  In 
the field, the user makes a comparison between the 
location of a housing unit as represented on the map 
and on the ground.   
 
 
Figure 1: The computer set up used in the 
experiment. 
Our goal was to investigate whether spatial 
ability (especially visualization and perspective 
taking) plays a role in this task and whether the use of 
task lists and relevant instructions would help bridge 
performance gaps between persons with low and high 
spatial ability by reducing the need for discovery.  
We tested whether using a guided system would 
reduce the need for discovery for participants with 
lower spatial ability.  We hypothesized that spatial 
ability would impact the map operations (e.g., zoom 
and pan) as well as the overall performance (i.e., time 
and accuracy). 
II. METHOD 
A. Overview 
We conducted a user study to evaluate 
whether spatial ability affected user performance for 
an address verification task using software interfaces 
with or without textual protocol and software 
guidance.  We recruited 24 subjects from the 
community to perform 10 address verification 
scenarios.  Subjects were grouped by gender and age.  
Within each group, each subject was randomly 
assigned to the guided or unguided interface 
treatment.  Unlike our paper map study [13], the 
present experiment was designed to impose a rigid 
protocol on the participants.  The application 
recorded the time it took participants to perform each 
step in the procedure, the number of attempts to 
match each address, the number of attempts to fix the 
map, the accuracy in fixing the map, and the number 
of times specific buttons or other software tools were 
used.   
 
        
 
a) Guided User Interface. 
        
 
b) Unguided User Interface. 
       Figure 2. The guided and unguided interfaces.   
36
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
B. Participants 
The twenty-four subjects were recruited 
through fliers posted on the Iowa State University 
campus, local grocery stores, coffee shops, the public 
library, and word of mouth.  This method was used 
because it mimicked recruiting strategies used by the 
Census Bureau to recruit address listing staff.  The 
twenty-four participants were equally split by age 
(<=30, >30) and by gender (female, male). 
C.  Experimental Task and Computing 
Environment 
The experimental task involved comparing a 
housing unit configuration on the ground (simulated 
with photographs of the two sides of the street – 
Figure 1) with the corresponding information in the 
map.  Possible outcomes from comparing ground and 
map locations are: 1) the ground situation is correctly 
reflected in the map requiring no further action; 2) 
the map has an error of commission that requires a 
map spot to be removed; 3) the map has an error of 
omission that requires a map spot to be inserted; and 
4) the map has an error in the housing unit location 
that requires the map spot to be relocated.  
To successfully perform the task, the 
following steps need to be executed: 1) find the 
address on the ground (i.e., in the photos presented to 
the subject), 2) locate the address on the software 
map, 3) answer a question posed by the software as to 
whether or not the address was on the map, 4) if so, 
answer a question posed by the software as to 
whether or not the address was in the correct location 
on the map, and 5) fix the map if an error was 
identified.   Software was developed to instantiate the 
experimental task.  The software generated displays 
of photographic images of the ground setting on two 
monitors, one for each side of the street (Figure 1).  
In addition, the software presented a map-based 
interface on a tablet PC.  The two monitors used in 
the second session to display the street photographs 
were Dell UltraSharp 2000FP 20-inch Flat Panel 
Monitors (16 inches in width and 12 inches in 
height).  The physical dimensions of the map 
software on the tablet PC were reduced to emulate 
the size of a handheld.  The specific measurements 
were 2 1/4 inches in width by 3 inches in height for 
the active interface area and 2 1/16 inches in width 
and 1 7/8 inches in height for the map display area.  
The computer used to display the interface was a 
Gateway Tablet PC M1300.  This tablet had a 12.1-
inch active matrix LCD color screen and was 
configured in a landscape display for the experiment 
(9 3/4 in x 7 1/4 in) (Figure 1).  The interface 
mimicked the size of a handheld computer that might 
be used in the field.  The guided version of the 
software displayed an interface that included 
guidance on what the user should be doing. The 
unguided version of the software had the same 
functionality and layout, but provided no guidance 
(Figure 2).   
The guided version included a yellow box at 
the top of the screen that provided real-time feedback 
on the step to be executed by the subject.  To the left 
was a list of steps that the subject had to accomplish 
to complete each scenario.  As the user progressed 
through each step, the current step was highlighted 
within the list.  To the right was an instruction box 
that provided information about what actions needed 
to be accomplished on each screen to complete the 
step.  For example, if the user was on a screen in 
which they were required to fix the map, the screen 
would tell them one of the specific fixes that needed 
to be accomplished, such as “Tap delete button”.  
Map-related functions were the same on both 
interfaces, and included zoom, pan, reset map, add 
map spot, and delete map spot.  Both interfaces also 
included an address bar that presented the target 
address for each of the 10 different scenarios.  The 
software recorded each user action and generated a 
summary of performance measures for analysis.  
Specific variables included time spent on each 
screen, number of attempts to answer each address 
matching question, positional accuracy in fixing 
maps, and number of times each map tool was used. 
For the photographic images, we used 
manipulated photos of streetscapes.  The original 
photos were taken in areas of Story County that were 
not highly trafficked so that subjects would not 
recognize street configurations.  The experiment used 
maps that were compiled based on Iowa data from 
Black Hawk County and the Department of 
Transportation (DOT).  These maps were similar to 
TIGER/Line shape files that are used by the Census 
Bureau.   The manipulation created settings that 
challenged the users in ways that were consistent 
with the objectives of the study.  For example, we 
removed a structure from a photo to create a vacant 
lot on the ground where the map included an existing 
map spot.  In developing the scenarios, we created 
variation in relation to six factors.  These factors 
included photo, street name, road configuration (e.g., 
four-way intersection, three-way intersection, etc.), 
rotation (e.g., north up, south up, etc.), map, and 
corrective action required.   
D.  Experimental Procedure 
The experiment involved two sessions with 
subjects.  The first session was used to test the 
subjects and the subjects performed the map task in 
37
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
the second session.  During the first session, each 
subject was presented with an informed consent 
form.  After having read this form and signed it, 
cognitive tests were administered to the subjects.  A 
test script was used to ensure consistency.  Three 
cognitive tests were administered to each subject.  
These tests included Ekstrom et al. (1976) paper-
based assessments on visualization (VZ-2) and 
logical reasoning (Ekstrom et al. 1976) and the 
Kozhevnikov et al. (2006) computerized perspective 
taking assessment on orientation.  The Inference Test 
on reasoning was administered first and the Paper-
folding Test on spatial visualization was administered 
second.  After the paper-based tests were completed, 
the subjects were taken to a computer lab where they 
completed the background questionnaire.  Next they 
were trained on the Perspective Taking software (PT) 
and then they proceeded to complete the test.  The PT 
results were compiled by a research team member 
who was not involved in working with subjects and 
used to randomize subjects to guided and unguided 
treatments 
within 
age-gender 
groups. 
 
The 
randomization procedure ensured balance in spatial 
ability across treatments within these groups.   
The second sessions took place throughout 
the two weeks that followed the first session and 
lasted approximately one hour each.  When a subject 
returned, s/he was informed that s/he would perform 
a task that comparing the location of a target housing 
unit on the ground with its representation on the map.  
Subjects were trained on the task procedure using an 
example scenario that was based on two color paper 
printouts.  One color printout included two street 
photos and the other included a zoomed-in map that 
emulated the map that would be displayed on the 
software interface.  The tablet touch screen 
calibration was performed by each subject to ensure 
that the tablet was sensitive to the user’s handedness 
and the way in which s/he used the stylus.  Finally, 
the user was trained to use the software to accomplish 
the experimental task and allowed to practice with 
two computerized practice scenarios.  After training, 
the subject proceeded to complete each of 10 test 
scenarios.  After completing the experiment, the 
subject received a $30 gift card.     
E. Analysis Methods  
The impact of interface treatment (i.e., 
guided 
or 
unguided) 
and 
associations 
with 
demographic and cognitive ability covariates on the 
subjects’ behavioral and performance measures were 
evaluated using regression procedures.  Response 
variables included the time required to perform each 
scenario, the accuracy of locations for addresses that 
required adding or moving map spots, the number of 
times the pan button was used, and the number of 
times the zoom button was used.  Accuracy of a 
newly placed housing unit map spot was derived by 
computing the distance (in meters) between the 
centroid of the parcel in which the housing unit was 
located and the location of the housing unit inserted 
by the subject.  Because preliminary analyses 
indicated that the location accuracy variable required 
a transformation to 
meet regression analysis 
assumptions, a log transformation was applied to this 
variable prior to fitting the regression model.  The 
interface treatment variable was expressed as an 
indicator variable indicating whether the subject was 
assigned 
to 
the 
guided 
treatment 
or 
not.  
Demographic variables (expressed as classification 
variables) included in the model were age category 
(18-29 years of age, 30-39 years of age, 40-59 years 
of age, or 60 years and older) and gender.  For the 
cognitive tests, we standardized for visualization, 
perspective taking, and logical reasoning.  To avoid 
problems with collinearity among spatial ability 
measures, we ran 3 sets of analyses: a) we used only 
VZ, b) both VZ and the spatial difference (VZ-PT) 
were used, c) average (VZ+PT)/2 and the spatial 
difference were used.  Regression models were fit 
using an ordinary least squares (PROC GLM in SAS, 
citation).  We examined residuals for departures from 
assumptions of homogenous variance and linearity.  
Tests of whether regression parameters were equal to 
zero were conducted to identify which covariates 
were associated with each response variable. 
III. RESULTS 
Table 1 presents the test results from the 
analysis for time, log accuracy, zoom button usage, 
pan button usage, and map reset button usage.  
Guidance was not related to any performance 
measure, after accounting for the other explanatory 
variables, except gender.  In analysis c) we found a 
significant negative association between average of 
visualization and perspective taking and time to 
perform the task.  The estimated regression 
coefficient was -320 (SE=145) indicating that as the 
average of the visualization and perspective taking 
standardized test scores increased by one unit, the 
average time spent on completing the full exercise 
was reduced by an estimated 320 seconds (holding 
other variables constant).  Analyses a) -327 (SE=189) 
and b) -245 (SE=74) found similar results for 
association between VZ and the time required.  
There was a significant negative association 
in analysis c) between error in housing unit location 
(log meters) and spatial difference.  The estimated  
 
38
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
 
Table 2. P-values for ANOVA F-tests for each interesting performance variable. 
 
Source 
Time 
(sec) 
 
 
Accuracy 
(log m) 
 
 
Zoom      
(# zoom 
actions) 
 
User Map       Pan 
   Resets        (# pan 
   (# reset       actions) 
   actions) 
Age 
 
 
0.02 b 
     
Gender 
    
0.02 c 
0.009 b 
 
Gender * Interface 
 
 
0.01 b 
 
VZ  
 0.001 b 
 
  0.03 b 
      0.03a           0.03 a 
 
 
 
 
 
Spatial Difference (VZ-PT) 
 0.006 b 
0.02 c 
 
                      0.02 c 
 
 
 
 
 
Spatial Average 
0.05 c 
 
 
 
a) Analysis only with VZ. 
b) Analysis with both VZ and Spatial Difference. 
c) Analysis with both the average and Spatial Difference. 
   
regression coefficient was -.69 (SE=.26), indicating 
that for every unit increase in the difference between 
visualization and perspective taking standardized test 
scores, the user-determined housing unit locations 
was an estimated .69 log meters closer to the target 
location.  There was also a significant association 
between gender and accuracy in analysis c).  The 
estimated regression coefficient   was 1.25 (SE=.48) 
which indicated that females tended to be 1.25 log 
meters less accurate than males.  
Analysis c) found significant negative 
association between age and the use of the zoom.  
The estimated regression coefficient was -5.18 
(SE=2.15), which meant that older subjects tended to 
make less use of the zoom tool.  Analysis b) saw a 
negative association -5.56 (SE=2.36) between VZ 
and zoom.  A positive association 19.82 (SE=6.83) 
also showed up between guided females and the use 
of zoom in analysis b). A significant negative 
association of the differences between visualization 
and perspective taking scores and use of the pan 
buttons was found in analysis c).  The estimated 
regression coefficient was -52.13 (SE=19.94) which 
meant that subjects with high visualization relative to 
perspective taking scores tended to make less use of 
the pan tool.  Finally, a negative association was 
found in analysis a) for the use of the reset map 
button (-1.93 (SE=0.82)). 
 
IV. DISCUSSION 
An important goal of this research was to 
investigate the relationship of spatial ability and user 
software performance for a map-related task in 
relation to two specific sub-factors of spatial 
visualization and orientation (i.e., perspective taking) 
abilities.  It is clear from the analyses that the results 
were sensitive to the relationship between the two 
spatial parameters used.  To get a complete 
understanding, we used the three combinations of 
parameters (a,b,c) shown in the legend of Table 1. 
Our results indicate the maps were more sensitive to 
VZ than the average of the two spatial parameters. 
We found that higher visualization scores tended to 
be correlated with faster performance times and 
fewer map operations (zooms, pans, and map resets).  
The association between spatial ability and user 
performance is consistent with findings from a large 
body of literature in software use (Dahlbäck et al., 
1996; Egan, 1988; Vicente, Hayes, & Williges, 1987; 
Egan & Gomez, 1985).  In addition, our results 
extend this finding to map-based interfaces. 
We also saw that for this set of data that 
there were differential effects of spatial ability sub-
factors corresponding to visualization and perspective 
taking.  Subjects with higher spatial differences were 
able to more accurately record the location of 
addresses that were missing from the map.      
Pan usage was also lower for subjects with 
higher spatial differences, which is a likely result of 
pan usages being lower for subjects with higher VZ 
scores. Older subjects tended to use the zoom tool 
less frequently.  Based on their successful completion 
of the tasks, there isn’t any indication that this 
impacted their overall performance. 
Spatial ability has also been found to vary 
by gender, and when this factor is significant, results 
39
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

 
indicate that spatial ability tends to be higher for men 
relative to women (Linn & Peterson, 1985).  We 
found that on average, male subjects most accurately 
placed housing units on the map when the ground 
situation showed a housing unit that was not initially 
present on the map.  In addition females relied to 
some degree on the guided interface. 
The logical reasoning abilities of the 
participants were not significant for any of the 
performance parameters. 
The lack of a relationship between the 
availability of the software layout (i.e., guided 
treatment) 
and 
spatial 
ability 
was 
somewhat 
surprising.  Based on the connection between 
discovery of the software structure and visualization 
scores in the literature, one would have expected 
more value from the guided interface.  The question 
of interest is whether the fact that our software broke 
the task into a series of rather simple self-contained 
subtasks (Figure 2) reduced the participants’ need for 
discovery in the sense detailed by Sein et al. (1993).  
There are two directions we will be able to go to 
better understand why we didn’t see a relationship.  
One issue is the complexity of the task.  We are 
currently conducting two studies to provide more 
information on what participant skills are being used 
in the address verification task.  Future experiments 
will be designed to look at other forms of guidance to 
help us determine whether our guidance structure 
and/or content was inadequate. 
ACKNOWLEDGEMENTS 
We gratefully acknowledge the scientific 
guidance of Elizabeth Murphy and Kathleen 
Ashenfelter of the U.S. Census Bureau.  This 
research was funded in part by a professional services 
agreement with the U.S. Census Bureau and by the 
National Science Foundation grant No. 0092696.   
REFERENCES 
[1] Berger, C.F., Lu, C.R., Belzer, S.J., & Voss, B.E. 
(1994). Research on the use of technology in science 
education. In Gabel, D. L. (Ed.), Handbook of 
Research on Science Teaching and Learning, Simon 
and Schuster, New York, pp. 466–490. 
[2] Dahlbäck, N., Höök, K., & Sjölinder, M. (1996). 
Spatial Cognition in the Mind and in the World: The 
case of hypermedia navigation. The Eighteenth 
Annual Meeting of the Cognitive Science Society, 
CogSci’96, University of California, San Diego, July. 
[3]Egan, D. (1988). Individual differences in human-
computer interaction. In: M. Helander (ed.), 
Handbook of Human-Computer Interaction, (pp. 543-
568). Amsterdam: Elsevier Science Publishers.  
[4]Egan, D.E., & Gomez, L.M. (1985). Assaying, 
isolating and accommodating individual differences 
in learning a complex skill. In R. Dillon (Ed.), 
Individual differences in cognition. New York: 
Academic Press. 
[5] Ekstrom, R.B., French, J.W., Harman, H.H., & 
Dermen, D. (1976). Manual for Kit of Factor-
Referenced Cognitive Tests. Princeton, NJ: 
Educational Testing Service. 
[6] Kozhevnikov, M., & Hegarty, M., (2001). A 
dissociation between object manipulation spatial 
ability and spatial orientation ability. Memory and 
Cognition, 29, 745-756. 
[7] Linn, M. C., & Petersen, A. C. (1985). Emergence 
and characterization of sex differences in spatial 
ability: A meta-analysis. Child Development, 56, 
1479-1498. 
[8] Lohman, D.F. (1996). Spatial ability and g. In I. 
Dennis & P. Tapsfield (Eds.), Human abilities: Their 
nature and measurement (pp. 97-116). Mahwah, NJ: 
Lawrence Erlbaum Associates. 
[9] Pak, R., Rogers, W. A., & Fisk, A. D. (2006). 
Spatial ability subfactors and their influences on a 
computer-based information search task. Human 
Factors, 48, 154-165. 
[10] Sein, M., Olfmann, L., Bostrom, R., & Davis, S. 
(1993). Visualization ability as a predictor of user 
learning success. International Journal of Man – 
Machine Studies, 39, 599 – 620. 
[11] Vicente, K.J., and Williges, R.C., (1988). 
Accommodating individual differences in searching a 
hierarchical file system, International Journal of man 
Machine Studies, 29, 647 – 668. 
[12] Vicente, K., Hayes, B.C., & Williges, R.C. 
(1987). Assaying and isolating individual differences 
in searching a hierarchical file system. Human 
Factors, 29, 349-359. 
[13] Whitney, K.C., G.J. Batinov, L.L. Miller, S.M. 
Nusser, and K.T. Ashenfelter. (2011). Exploring a 
Map Survey Task’s Sensitivity to Cognitive Ability. 
The Fourth International Conference on Advances in 
Computer-Human Interactions. Gosier, Guadeloupe, 
France. 63-68. 
[14] Zhang, J. (1997). The nature of external 
representations in problem solving. Cognitive 
Science, 21, 2, 179-217. 
[15] Zhang, J., & Norman, D.A. (1994). 
Representations in distributed cognitive tasks. 
Cognitive Science, 18, 87-122
 
40
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

