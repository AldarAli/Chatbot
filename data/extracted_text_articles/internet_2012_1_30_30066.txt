On Tuning TCP for Superior Performance on High
Speed Path Scenarios
Kazumi Kumazoe, Hirofumi Ishizaki, Takeshi Ikenaga, Dirceu Cavendish, Masato Tsuru, Yuji Oie
Department of Computer Science and Electronics
Kyushu Institute of Technology
Fukuoka, Japan 810-0004
Email: {zaki,ike}@ecs.kyutech.ac.jp, {kuma,cavendish,tsuru,oie}@ndrc.kyutech.ac.jp
Abstract—Transmission control protocol performance varies
considerably, depending on network and path conditions. In this
paper, we discuss path conditions that affect TCP performance,
from round trip delays to path capacity and buffering. We
characterize throughput performance of popular TCP congestion
avoidance mechanism as well as recently proposed TCP variants
via open source based network experiments. We show that
superior TCP performance may be achieved via careful selection
of congestion avoidance mechanism, as well as parameter tuning.
Keywords—high speed networks; TCP congestion avoidance;
Packet retransmissions; Path capacity and buffering;
I. INTRODUCTION
Transmission control protocol (TCP) is the dominant trans-
port protocol of the Internet, providing reliable data transmis-
sion for the large majority of applications. User experience
depends heavily on TCP performance. In the last decade, many
TCP variants have been proposed, mainly motivated by per-
formance reasons. As TCP performance depends on network
characteristics, and the Internet keeps evolving, TCP variants
are likely to continue being proposed. Most of the proposals
deal with congestion window size adjustment mechanism, the
so called congestion avoidance phase of TCP.
In prior works, we have introduced a delay based TCP
window ﬂow control mechanism that uses path capacity and
storage estimation [6], [7]. The idea is to estimate bot-
tleneck capacity and path storage space, and regulate the
congestion window size using a control theoretical approach.
Two versions of this mechanism were proposed: one using
a proportional controlling equation [6], and another using a
proportional plus derivative controller [7].
In this work, we study TCP performance of most popular
TCP variants - Reno [3], Cubic (Linux) [11], Compound
TCP (Windows) [12] - as well as our most recently proposed
TCP variants: Capacity and Congestion Probing (CCP) [6],
and Capacity Congestion Plus Derivative (CCPD) [7], under
various path conditions. Our contributions are as follows. We
show that most used TCP variants of today perform differently
over various network scenarios. In addition, for our TCP
variants, we tune their performance according to network
scenarios for superior performance. Our results show that there
is no single TCP variant that is able to best perform under
all network scenarios. For our protocols, we investigate best
protocol parameters to deliver superior performance. For other
protocols, our results can be seen as a call for protocol tuning.
The material is organized as follows. Related work discussion
is provided on Section II. Section III introduces the TCP
variants addressed in this paper, their features and differences.
Section IV addresses their performance evaluation. Section VI
addresses directions we are pursuing as follow up to this work.
II. RELATED WORK
Research studies of TCP performance on various network
environments abound. Many of these studies, have focused on
mobile wireless networks [5], [9], [13], as loss based conges-
tion avoidance has the issue of not being able to differentiate
between random packet loss and buffer overﬂow packet loss
[4]. [5] studies throughput performance of TCP variants for
various Packet Error Rates (PERs) on a mobile network via
simulations. [9] also studies TCP variants performance under
various PERs, but it also investigates the impact of routing
protocols on TCP performance. Wireless network scenarios
typically involve a low speed bottleneck link capacity, which
limits the size of the congestion window to small values,
masking the buffer overﬂow problem on routers.
On wired high speed networks, [8] has conducted a study of
the impact of buffer size, packet error rate, and network delay
on throughput performance of NewReno, BIC, Cubic, High-
speed, and Compound TCP variants under large bandwidth
delay product and high capacity bottlenecks, via simulations.
Although our work has similarities with theirs, we evaluate
unique aspects of TCP such as throughput recovery upon cross
trafﬁc via open source experiments rather than simulations.
III. TRANSMISSION CONTROL PROTOCOL FRAMEWORK
TCP protocols fall into two categories, delay and loss based.
Advanced loss based TCP protocols use packet loss as primary
congestion indication signal, performing window regulation as
cwndk = f(cwndk−1), being ack reception paced. Most f
functions follow an Additive Increase Multiplicative Decrease
strategy, with various increase and decrease parameters. TCP
NewReno and Cubic are examples of AIMD strategies. In
contrast, delay based TCP protocols use queue delay informa-
tion as the congestion indication signal, increasing/decreasing
the window if the delay is small/large, respectively. CCP and
CCPD are examples of delay based protocols.
11
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-204-2
INTERNET 2012 : The Fourth International Conference on Evolving Internet

Most TCP variants follow a framework composed of few
phases: slow start, congestion avoidance, fast retransmit, and
fast recovery.
• Slow Start(SS) : This is the initial phase of a TCP
session, where no information about the session path
is assumed. In this phase, for each acknowledgement
received, two more packets are allowed into the network.
Hence, congestion window cwnd is roughly doubled at
each round trip time. Notice that the cwnd size can only
increase in this phase. In this paper, all TCP variants make
use of the same slow start except Cubic [11].
• Congestion Avoidance(CA) : This phase is entered when
the TCP sender detects a packet loss, or the cwnd
size reaches a target upper size called ssthresh (slow
start threshold). The sender understands that the cwnd
size needs to be controlled to avoid path congestion.
Each TCP variant has a different method of cwnd size
adjustment.
• Fast Retransmit and fast recovery(FR) : The purpose
of this phase is to freeze all cwnd size adjustments in
order to take care of retransmissions of lost packets.
Figure 1 illustrates various phases of a TCP session. A
comprehensive tutorial of the evolution of TCP features can
be found in [2].
pkt loss
pkt loss
pkt loss
ssthresh
SS
FR
CA
CA
t
cwnd size
Fig. 1: TCP Congestion Window Dynamics
A. Reno TCP
Reno is a loss based TCP, and may be considered the
oldest implementation of TCP to achieve widespread usage.
Its congestion avoidance scheme relies on increasing the cwnd
by 1/cwnd increments, and cutting it in half on packet loss
detection, as per equation 1.
AckRec :
cwndk+1
= cwndk +
1
cwndk
PktLoss :
cwndk+1
= cwndk
2
(1)
Notice that for large cwnd values, the increment becomes
small. So, for large bandwidth delay product paths, Reno cwnd
ramps up very slowly. A new version of Reno, TCP NewReno
introduces an optimization of the Fast Recovery mechanism,
but its congestion avoidance scheme remains the same.
B. Cubic TCP
TCP Cubic is a loss based TCP that has achieved
widespread usage due to being the default TCP of the Linux
operating system. Its congestion window adjustment scheme
is:
AckRec :
cwndk+1
= C(t − K)3 + Wmax
K
= (Wmax β
C )1/3
(2)
PktLoss :
cwndk+1
= βcwndk
Wmax
= cwndk
where C is a scaling factor, Wmax is the cwnd value at
time of packet loss detection, and t is the elapsed time since
the last packet loss detection (cwnd reduction). Although
the equations look complicated, the rational is simple. Cubic
remembers the cwnd value at time of packet loss detection
- Wmax, when a sharp cwnd reduction is enacted, tuned by
parameter β. After that, cwnd is increased according to a cubic
function, whose speed of increase is dictated by two factors: i)
how long it has been since the previous packet loss detection,
the longer the faster ramp up; ii) how large the cwnd size was
at time of packet loss detection, the smaller the faster ramp
up. The shape of Cubic cwnd dynamics is typically distinctive,
clearly showing its cubic nature. Notice that upon random loss,
Cubic strives to return cwnd to the value it had prior to loss
detection quickly, for small cwnd sizes.
C. Compound TCP
Compound TCP is the TCP of choice for most Windows
machines. It implements a hybrid loss/delay based congestion
avoidance scheme, by adding a delay congestion window
dwnd to the congestion window of NewReno [12]. Compound
TCP cwnd adjustment is as per Equation 3:
AckRec :
cwndk+1
= cwndk +
1
cwndk + dwndk
(3)
PktLoss :
cwndk+1
= cwndk +
1
cwndk
where the delay component is computed as:
AckRec : dwndk+1 = dwndk + αdwndK
k − 1, if diff < γ
dwndk − ηdiff,
if diff ≥ γ
PktLoss : dwndk+1= dwndk(1 − β) − cwndk
2
(4)
where α, β, η and K parameters are chosen as a tradeoff
between responsiveness, smoothness, and scalability. diff is
deﬁned as the difference between an expected throughput and
the actual throughput, as diff = cwnd/minRtt−cwnd/srtt,
minRtt is the minimum rtt experienced by the TCP session,
and srtt is a smooth round trip delay computation.
D. Capacity and Congestion Probing TCP
TCP CCP is our ﬁrst attempt to design a delay based
congestion avoidance scheme based on solid control theo-
retical approach. The cwnd size is adjusted according to
a proportional controller control law. The cwnd adjustment
scheme is called at every acknowledgement reception, and
may result in either window increase and decrease. In addition,
packet loss does not trigger any special cwnd adjustment. CCP
cwnd adjustment scheme is as per Equation 5:
12
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-204-2
INTERNET 2012 : The Fourth International Conference on Evolving Internet

cwndk = [Kp(B − xk) − in flight segsk]
2
0 ≤ Kp
(5)
where Kp is a proportional gain, B is an estimated storage
capacity of the TCP session path, or virtual buffer size, xk is
the level of occupancy of the virtual buffer, or estimated packet
backlog, and in flight segs is the number of segments
in ﬂight (unacknowledged). Typically, CCP cwnd dynamics
exhibit a dampened oscillation towards a given cwnd size,
upon cross trafﬁc activity. Notice that cwndk does not depend
on previous cwnd sizes, as with the other TCP variants.
E. Capacity and Congestion Plus Derivative TCP
TCP CCPD is our second attempt to design a delay based
congestion avoidance scheme based on solid control theoret-
ical approach, being a variant of CCP. The scheme cwnd
adjustment follows the same strategy of CCP. The difference
is that it uses a proportional plus derivative controller as its
control equation, as per Equation 6:
cwndk = Kp[B − xk − in flight segsk] +
Kd
tk − tk−1
[xk−1 + in flight segsk−1 +
−xk − in flight segsk]
(6)
where Kp is a proportional gain, Kd is a derivative gain, tk
and tk−1 are two consecutive ack reception epochs, and the
other parameters are deﬁned as per CCP congestion avoidance
scheme. Typically, CCPD cwnd dynamics present similar
dampened oscillatory behavior as CCP, with a much faster
period, due to its reaction to the derivative or variation of the
number of packets backlogged.
IV. TCP VARIANTS PERFORMANCE CHARACTERIZATION
It is well known that TCP throughput performance is
affected by the round trip time of the TCP session. This is
a direct consequence of the congestion window mechanism
of TCP, where only up to a cwnd worth of bytes can be
delivered without acknowledgements. Hence, for a ﬁxed cwnd
size, from the sending of the ﬁrst packet until the ﬁrst
acknowledgement arrives, a TCP session throughput is capped
at cwnd/rtt.
As mentioned earlier, for all TCP variants, the size of the
congestion window is computed by a speciﬁc algorithm at
time of packet acknowledgement reception by the TCP source.
In this section, we characterize TCP performance regarding
data throughput in various network scenarios. For CCP, and
CCPD protocols, we shall use CCP(Kp) notation for CCP
using proportional parameter Kp, whereas CCPD(Kp, Kd)
for CCPD using proportional and derivative parameters, Kp
and Kd, respectively.
We evaluate the throughput performance of TCP variants
in the presence of controlled cross trafﬁc. Fig. 2 depicts the
network scenario used for evaluating TCP protocols against
interfering UDP and TCP types of cross trafﬁc. One TCP
session shares a 1Gbps access link with UDP cross traf-
ﬁc of 200Mbps intensity to a dumb-bell topology emulator
highspeed network, depicted in Fig. 2 a). The PacketStorm
4XG IP Network Emulator [10] is used to vary the end-
to-end round trip time of the TCP sessions. Two Alaxala
switches [1] were used, AX-3630-24T2X and AX-2430-48T-
B. As endpoints, Dell PowerEdge2950 Xeon 1.6GHz machines
were used, running Linux 2.6.26.
Fig. 2 b) describes the timeline of the TCP and UDP
sessions, with the TCP session lasting for 150 secs, and the
UDP trafﬁc starting 50 seconds after the TCP session start, and
ﬁnishing 50 secs prior to the end of the TCP session. Figure
2 c) describes the timeline of a TCP and TCP two session
scenario, where two TCP sessions compete for bottleneck link
bandwidth.


0
100
200
300
400
500
600
700
800
900
1000
ccp(4)
ccp(2)
ccp(1)
ccpd(4,8000)
ccpd(4,4000)
ccpd(4,2000)
ccpd(2,4000)
ccpd(2,1000)
ccpd(1,1000)
cubic
compound
reno
0-50
50-100
100-150
Fig. 3: TCP/UDP throughput - short rtt(20msecs)




































































































































































Fig. 4: TCP/UDP throughput - large rtt(200msecs)
are CCP(4), CCPD(2,2000) and CCPD(4,2000). The worst
performers are Reno and Compound TCP.
3) Very large round trip time paths: Figure 6 reports
TCP throughput performance over a very large rtt, typically
incurred in satellite paths. In this case, traditional TCP variants
have the worst performance across all TCP variants inves-
tigated. Best performers are CCPD(2,4000), CCPD(4,4000)
and CCP(1). For very large rtt paths, CCPD(2,4000) and
CCPD(4,4000) seem to be the top TCP variants performers.
B. Coexisting TCP/TCP sessions
In this subsection, we investigate the throughput perfor-
mance of two TCP ﬂows sharing a single bottleneck. Two
cases can be distinguished: homogeneous case, where the two
TCP sessions belong to the same TCP variant; heterogeneous
case, where the two TCP sessions belong to different TCP
variants.
1) Small round trip time paths: Figure 7 reports throughput
performance of two TCP sessions, staggered in time, over
a short rtt path. For the initial period, with only a single
session, all TCP variants perform similarly. During the period
of the two sessions sharing a bottleneck, CCP with large
alpha parameter delivers best performance. During “recovering
period”, where the ﬁrst session leaves the system, Reno and
Compound TCP present best throughput ramp up performance,
followed by CCPD(4,4000) and Cubic as second best.
Figures
8
and
9
report
throughput
performance
of
CCPD(4,2000) competing with Reno, Cubic, and Compound
TCP variants over a short rtt path. Figure 8 reports perfor-
mance when the ﬁrst ﬂow is CCPD(4,2000), whereas Figure
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
ccp(4)
ccp(2)
ccp(1)
ccpd(4,8000)
ccpd(4,4000)
ccpd(4,2000)
ccpd(2,4000)
ccpd(2,2000)
ccpd(2,1000)
ccpd(1,1000)
cubic
compound
reno
100-150 / 0-50
Fig. 5: TCP/UDP throughput recovery - large rtt(200msecs)
0
100
200
300
400
500
600
ccp(4)
ccp(2)
ccp(1)
ccpd(4,8000)
ccpd(4,4000)
ccpd(2,4000)
ccpd(2,1000)
cubic
compound
reno
0-50
50-100
100-150
Fig. 6: TCP/UDP throughput - very large rtt(600msecs)
9 reports the reverse scenario, when the second ﬂow is
CCPD(4,2000). In general, Flow 1 and ﬂow 2 path band-
width resource is shared unevenly. Comparing the two cases,
throughput ramp up of ﬂow 2 after ﬂow 1 departs is best
achieved by CCPD(4,2000), except when Compound TCP is
used by ﬂow 2, in this short rtt scenario.
Figures 10 and 11 report throughput performance of
CCPD(4,4000) competing with Reno, Cubic, and Compound
TCP variants over a short rtt path. In general, ﬂow 1 and ﬂow
2 path bandwidth resource is shared very unevenly. Comparing
Figure 10 and 11, the following observations can be made. i)
Throughput performance of all TCP variants are similar when
there is no cross trafﬁc; ii) CCPD(4,4000) is able to ramp up
throughput to higher levels once cross trafﬁc vanishes, except
against Compound TCP ramp up performance, which again
is better for this short rtt scenario. When compared with
CCPD(4,2000) performance, it is clear that CCPD(4,4000)
retains more throughput under TCP cross trafﬁc for short rtt
scenario.
2) Large round trip time paths: Figure 12 reports through-
put performance of two TCP sessions, staggered in time, over
a long rtt path. For the initial period, with only a single
session, Compound TCP and Cubic deliver best throughput
performance. During the period of the two sessions sharing a
bottleneck, Cubic, Compound TCP and Reno present the best
aggregate performance. Notice, however, that this is because
the ﬁrst ﬂow retains most of its throughput prior to the
sharing of bandwidth with the second ﬂow. During “recovering
period”, where the ﬁrst session leaves the system, Cubic and
CCPD(4,2000) deliver best throughput.
14
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-204-2
INTERNET 2012 : The Fourth International Conference on Evolving Internet





 


¡


¢


£


¤


¥


¦


§






¨
¨
©
ª
«
¬
¨
¨
©
ª
­
¬
¨
¨
©
ª
®
¬
¨
¨
©
¯
ª
«
°
±
²
²
²
¬
¨
¨
©
¯
ª
«
°
«
²
²
²
¬
¨
¨
©
¯
ª
«
°
­
²
²
²
¬
¨
¨
©
¯
ª
­
°
«
²
²
²
¬
¨
¨
©
¯
ª
­
°
­
²
²
²
¬
¨
¨
©
¯
ª
­
°
®
²
²
²
¬
¨
¨
©
¯
ª
®
°
®
²
²
²
¬
¨
³
´
µ
¨
¨
¶
·
©
¶
³
¸
¯
¹
º
¸
¶
» ¼
½
¾


¿
 
£
» ¼½
¾

 
£
¿



» ¼½
¾
 
 
£
¿



» ¼½
¾
 



¿

 
£
Fig. 7: TCP/TCP throughput - small rtt(20msecs)
À
Á
À
À
Â
À
À
Ã
À
À
Ä
À
À
Å
À
À
Æ
À
À
Ç
À
À
È
À
À
É
À
À
Á
À
À
À
Ê
Ë
Ì
Í
Î
Ê
Ë
Ì
Í
Î
Ï
Ê
Ë
Ì
Í
Ð
Ê
Ë
Ì
Í
Ð
Ê
Ë
Ì
Í
Î
Ê
Ë
Ì
Í
Î
Ï
Ê
Ë
Ì
Í
Ð
Ê
Ë
Ì
Í
Ð
Ê
Ë
Ì
Í
Î
Ê
Ë
Ì
Í
Î
Ï
Ê
Ë
Ì
Í
Ð
Ê
Ë
Ì
Í
Ð
Ñ
Ñ
Ò
Ó
Ô
Ä
Õ
Â
À
À
À
Ö ×
Ø
Ù
Ú
Û
Ñ
Ñ
Ò
ÓÔ
Ä
Õ
Â
À
À
À
Ö ×
Ñ
Ü
Ý
Þ
Ñ
Ñ
Ñ
Ò
Ó
Ô
Ä
Õ
Â
À
À
À
Ö ×
Ñ
Û ß
Ò
Û
Ü
Ú
Ó
àá
Û
â
Â
Á
À
À
×
Á
Â
Å
àá
Û
â
Â
Â
Å
×Á
À
À
àá
Û
â
Á
Â
Å
×Á
À
À
àá
Û
â
Á
À
×
Â
Å
Fig. 8: CCPD(4,2000)/TCP throughput - small rtt(20msecs)
Figures 13 and 14 report throughput performance of
CCPD(4,2000) competing with Reno, Cubic, and Compound
TCP variants over a large rtt path. Figure 13 shows that
Reno, Cubic, and Compound TCP variants deliver poor ﬂow 2
throughput ramp up performance when both ﬂows share path
resources. In contrast, Figure 14 shows a much better ﬂow 2
ramp up performance of CCPD(4,2000) for large rtt scenario.
Moreover, CCPD(4,2000) is able to further ramp up ﬂow 2
throughput to a highest level among all TCP variants.
Figures 15 and 16 report throughput performance of
CCPD(4,4000) competing with Reno, Cubic, and Compound
TCP variants over a large rtt path. TCP ﬂow 2 throughput
is low, as compared with CCPD(4,4000) ﬂow 1, when both
ﬂows share path resources. Fig. 15 shows that Cubic TCP
recovers ﬂow 2 throughput the most, whereas Reno ﬂow 2
has negligible throughput. Fig. 16 shows that CCPD(4,4000)
ﬂow 2 recovers the most throughput after cross trafﬁc ends.
V. DISCUSSIONS
Round trip time is used in the calculation of Retransmission
Time Out (RTO). In addition, round trip time estimate may
be used as an indication of path congestion in various TCP
variants, such as TCP Vegas, and TCP CCP and CCPD.
In these schemes, a TCP session minimum rtt, rttmin, is
computed, and current rtt measurement deviation from this
minimum is taken as an indication of path congestion. Some
TCP schemes also use an estimate of maximum rtt seen, or
rttmax. Care must be taken by these schemes so as to ensure
robustness to path condition changes.
ã
ä
ã
ã
å
ã
ã
æ
ã
ã
ç
ã
ã
è
ã
ã
é
ã
ã
ê
ã
ã
ë
ã
ã
ì
ã
ã
ä
ã
ã
ã
í
î
ï
ð
ñ
í
î
ï
ð
ñ
ò
í
î
ï
ð
ó
í
î
ï
ð
ó
í
î
ï
ð
ñ
í
î
ï
ð
ñ
ò
í
î
ï
ð
ó
í
î
ï
ð
ó
í
î
ï
ð
ñ
í
î
ï
ð
ñ
ò
í
î
ï
ð
ó
í
î
ï
ð
ó
ô
õ
ö
÷
ø
ù
ù
ú
û
ü ç
ý
å
ã
ã
ã
þ
ÿ 

*
+
*
*
,
*
*
-
*
*
.
*
*
/
*
*
0
*
*
1
*
*
2
*
*
3
*
*
+*
*
*
4
5
6
7
8
4
5
6
7
8
9
4
5
6
7
:
4
5
6
7
:
4
5
6
7
8
4
5
6
7
8
9
4
5
6
7
:
4
5
6
7
:
4
5
6
7
8
4
5
6
7
8
9
4
5
6
7
:
4
5
6
7
:
;
<
=
>
?
@
@
A
B
C
.
D
.
*
*
*
E
F
G
H
I
@
?
@
@AB
C
.
D
.
*
*
*
E
F
>
J A
>
G
=
B
?
@
@
A
B
C
.
D
.
*
*
*
E
K L
>
M
,
+*
*
?
+
,
/
K L
>
M
,
,
/
?
+
*
*
K L
>
M
+
,
/
?
+
*
*
K L
>
M
+
*
?
,
/
Fig. 11: TCP/CCPD(4,4000) throughput - small rtt(20msecs)
0
100
200
300
400
500
600
700
800
900
ccp(4)
ccp(2)
ccp(1)
ccpd(4,8000)
ccpd(4,4000)
ccpd(4,2000)
ccpd(2,4000)
ccpd(2,2000)
ccpd(2,1000)
ccpd(1,1000)
cubic
compound
reno
flow1 0-25
flow1 25-100
flow2 25-100
flow2 100-125
Fig. 12: TCP/TCP throughput - large rtt(200msecs)
REFERENCES
[1] Alaxala Networks Corporation, “High Performance Layer 3 Switches”
http://www.alaxala.com/en/products/index.html, accessed Apr. 16, 2012.
[2] A. Afanasyev, N. Tilley, P. Reiher, and L. Kleinrock, “Host-to-Host Con-
gestion Control for TCP, ” IEEE Communications Surveys & Tutorials,
Vol. 12, No. 3, pp. 304-342, Third Quarter 2010.
[3] M. Allman, V. Paxson, and W. Stevens, “TCP Congestion Control,” IETF
RFC 2581, April 1999.
[4] M. Alnuem, J. Mellor, and R. Fretwell, “New Algorithm to Control
TCP Behavior over Lossy Links, ” IEEE Int. Conference on Advanced
Computer Control, pp. 236-240, Jan 2009.
[5] A. Ahmed, S.M.H. Zaidi, and N. Ahmed, “Performance evaluation of
Transmission Control Protocol in mobile ad hoc networks, ” IEEE Int.
Networking and Communication Conference, pp. 13-18, June 2004.
[6] D. Cavendish, K. Kumazoe, M. Tsuru, Y. Oie, and M. Gerla, “Capacity
and Congestion Probing: TCP Congestion Avoidance via Path Capacity
and Storage Estimation,” Second Int. Conference on Evolving Internet,
September 2010.
[7] D. Cavendish, Hiraku Kuwahara, K. Kumazoe, M. Tsuru, and Y.
Oie, “TCP Congestion Avoidance using Proportional plus Derivative
Control,” Third Int. Conference on Evolving Internet, June 2011.
[8] J. Chicco, D. Collange, and A. Blanc, “Simulation Study of TCP
Variants,” IEEE Int. Symposium on Computers and Communication, pp.
50-55, June 2010.
[9] S. Henna,“A Throughput Analysis of TCP Variants in Mobile Wireless
Networks,” Third Int. Conference on Next Generation Mobile Applica-
tions, Services and Technologies - NGMAST, pp.279-284, Sept. 2009.
[10] PacketStorm Communications, Inc., “PacketStorm 4XG Network Em-
ulator” http://www.packetstorm.com/psc/psc.nsf/site/4XG-software, ac-
cessed April 16, 2012.
[11] I. Rhee, L. Xu, and S. Ha, “CUBIC for Fast Long-Distance Networks,”
Internet Draft, draft-rhee-tcpm-ctcp-02, August 20088.
[12] M. Sridharan, K. Tan, D. Bansal, and D. Thaler, “Compound TCP: A
New Congestion Control for High-Speed and Long Distance Networks,”
Internet Draft, draft-sridharan-tcpm-ctcp-02, November 20088.
[13] S. Waghmare, A. Parab, P. Nikose, and S.J. Bhosale, “Comparative
analysis of different TCP variants in a wireless environment,” IEEE 3rd
Int. Conference on Electronics Computer Technology, Vol.4, p.158-162,
April 2011.
N
O
N
N
P
N
N
Q
N
N
R
N
N
S
N
N
T
N
N
U
V
W
X
Y
U
V
W
X
Y
Z
U
V
W
X
[
U
V
W
X
[
U
V
W
X
Y
U
V
W
X
Y
Z
U
V
W
X
[
U
V
W
X
[
U
V
W
X
Y
U
V
W
X
Y
Z
U
V
W
X
[
U
V
W
X
[
\
\
]
^
_ R
`
P
N
N
N
a b
c
d
e
f
\
\
]
^_R
`
P
N
N
N
a b
\
g
h
i \
\
\
]
^
_ R
`
P
N
N
N
a b
\
f
j
]
f
g
e
^
k l f
m
P
O
N
N
b
O
P
S
k l f
m
P
P
S
b
O
N
N
k l f
m
O
P
S
b
O
N
N
k l f
m
O
N
b
P
S
Fig. 13: CCPD(4,2000)/TCP throughput - large rtt(200msecs)
n
o
n
n
p
n
n
q
n
n
r
n
n
s
n
n
t
n
n
u
n
n
v
n
n
w
n
n
x
y
z
{
|
x
y
z
{
|
}
x
y
z
{
~
x
y
z
{
~
x
y
z
{
|
x
y
z
{
|
}
x
y
z
{
~
x
y
z
{
~
x
y
z
{
|
x
y
z
{
|
}
x
y
z
{
~
x
y
z
{
~










r

p
n
n
n

 








 r

p
n
n
n

 


 







r

p
n
n
n


 
p
o
n
n

o
p
s

 
p
p
s

o
n
n

 
o
p
s

o
n
n

 
o
n

p
s
Fig. 14: TCP/CCPD(4,2000) throughput - large rtt(200msecs)





































 




 















 




 















 




 
¡
¡
¢
£
¤

¥




¦ §
¨
©
ª
«
¡
¡
¢
£
¤

¥




¦
§
¡
¬
­
®
¡
¡
¡
¢
£
¤

¥




¦ §
¡
«
¯
¢
« ¬
ª
£
° ±
«
²




§



° ±
«
²



§



° ±
«
²



§



° ±
«
²


§


Fig. 15: CCPD(4,4000)/TCP throughput - large rtt(200msecs)
³
´
³
³
µ
³
³
¶
³
³
·
³
³
¸
³
³
¹
³
³
º
³
³
»
³
³
¼
³
³
½
¾
¿
À
Á
½
¾
¿
À
Á
Â
½
¾
¿
À
Ã
½
¾
¿
À
Ã
½
¾
¿
À
Á
½
¾
¿
À
Á
Â
½
¾
¿
À
Ã
½
¾
¿
À
Ã
½
¾
¿
À
Á
½
¾
¿
À
Á
Â
½
¾
¿
À
Ã
½
¾
¿
À
Ã
Ä
Å
Æ
Ç
È
É
É
Ê
Ë
Ì·
Í
·
³
³
³
Î
Ï
Ð
Ñ
Ò
É
È
É
É
Ê
ËÌ
·
Í
·
³
³
³
Î
Ï
Ç
Ó
Ê
Ç
Ð
Æ
Ë
È
É
É
Ê
Ë
Ì·
Í
·
³
³
³
Î
Ô Õ
Ç
Ö
µ
´
³
³
È
´
µ
¸
Ô Õ
Ç
Ö
µ
µ
¸
È
´
³
³
Ô Õ
Ç
Ö
´
µ
¸
È
´
³
³
Ô Õ
Ç
Ö
´
³
È
µ
¸
Fig. 16: TCP/CCPD(4,4000) throughput - large rtt(200msecs)
16
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-204-2
INTERNET 2012 : The Fourth International Conference on Evolving Internet

