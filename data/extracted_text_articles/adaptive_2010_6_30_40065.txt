Quantifying Adaptability 
Ken Krechmer 
Lecturer, University of Colorado 
Palo Alto, CA 94303-3024 USA 
krechmer@csrstds.com 
 
Abstract––Until adaptability can be calculated and measured, 
it is difficult to understand or promote.  This paper defines 
adaptability and offers a way to measure it based on 
communications theory.  Adaptability is a complex process 
which requires a number of supporting processes and 
definitions.  The concept of state-pairs is developed and used to 
describe communicating entities, interfaces, comparison, 
measured information, communications, flexibility and, finally, 
adaptability.  Interfaces are delineated by their  percent of 
adaptability; different means are identified to add the benefits 
of adaptability to existing and future systems.  
Keywords-adaptability; interface; communications structure; 
measured information; etiquette  
I. 
 INTRODUCTION 
This paper defines adaptability as the process of 
automatically negotiating possible parameters, as it makes a 
system more adaptable.  Some assumptions in this definition 
include: a negotiation occurs between at least two entities, 
and a negotiation requires communications.  With the 
recognition that communications is a requirement before 
adaptability can be realized, adaptability is defined based on 
communications 
theory. 
 
First 
the 
structure 
of 
a 
communications system used to transfer a message between 
transmitter and receiver entities is developed.  From this 
structure an interface is derived.  Defining an interface 
allows an understanding of how to adapt and measure an 
interface.  Quantifying adaptability also adds to the 
understanding of how to implement adaptable systems. 
II. 
A COMMUNICATIONS STRUCTURE 
Adaptability requires communications.  Fig. 1 models 
communications for the purpose of understanding its 
structure rather than its performance.  Fig. 1 is similar to the 
Shannon model of a communications system except that the 
communications channel is replaced by an interface and the 
probability of the output message being the same as the input 
message is fixed to one [1, page 34].  The transmitter (T) and 
receiver (R) are communicating entities connected via an 
interface.  This model allows an analysis of the structure of 
the relationship between T and R.   
From communications theory, T and R support all the 
state-pairs ti - ri, where i includes the set of all t or r states 1 
to n in Fig. 1.  A state-pair includes a specific input part (tx) 
associated with T, which is related to the output part (rx) 
associated with R.   
The relationship between tx and rx is described as one-
one.  "A relation is said to be one-one when, if t has the 
relation in question to r, no other term t' has the same relation 
to r, and t does not have the same relation to any other term r' 
other than r" [2].  All the state-pairs associated with T and R 
form the interface between T and R.  A single set of ti or ri 
states is termed a parameter of the transmitter or receiver.  
Communications between T and R (information transfer) is 
possible only when multiple state-pairs form an interface.  
Most interfaces include multiple parameters.  An interface is 
a concept that does not exist independently, it is only formed 
by the common parameters of the related  entities. 
A state-pair is in some ways a relationship between equal 
elements.  As example in Fig. 1, state tx may be considered 
as the equal of state rx.  However, it is not possible to define 
such equality exactly without specifying other sets of state-
pairs.  For state tx to be equal to rx for example, the boundary 
conditions of each state (defined by other state-pairs) must 
be equal.  To avoid this complexity, this paper considers a 
state-pair to be one-one, not necessarily equals.   
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1.  Communications structure. 
Transmitter (T)  
output 
 
Receiver (R)  
 
r1 
r2 
r3 
. 
rn 
 
t1 
t2 
t3 
. 
tn 
 
Interface) 
signal path 
 
input 
 
146
ADAPTIVE 2010 : The Second International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-109-0

 
 
 
The concept of state-pairs may be applied to any 
interface, even a physical interface.  Examine a perfectly 
compatible (zero tolerance) physical plug and socket.  The 
outside diameter of the plug and the inside diameter of the 
socket are the same.  The length of the plug and the socket 
are the same.  The interface between the plug and socket 
consists of all the points on the same diameters along the 
same length of the socket and plug.  These common points 
are the state-pairs which form a physically compatible 
interface.  In a real physical interface, multiple layers of sets 
of state-pairs are needed to completely define the interface 
including: the physical dimension system used and the 
tolerances applied. 
III. 
COMMUNICATIONS PROCESS 
The communications structure in Fig. 1 allows a detailed 
view of a communications process across the interface.  This 
is necessary to see the how state-pairs create an interface and 
eventually to use the number of state-pairs to quantify 
adaptability.   
The ability to pass information across each state-pair 
requires two comparisons.  Each comparison is associated 
with a part of a state-pair. The fundamental nature of these 
comparisons is suggested by I. Kant who states that a 
comparison is necessary for understanding [3]. 
 
TABLE I.  
COMMUNICATIONS PROCESS 
 
The simplest communications process may consist of six 
operations, three in the transmitter and three in the receiver 
(Table 1).  What is critical to this analysis is that the 
communications process consists of symmetric transmit and 
receive processes, each of which includes a comparison. The 
symmetry about the interface first appears in the concept of 
one-one and also appears in Fig. 3 (below). Operations 2 and 
5 in Table 1 demonstrate how a state-pair relates to the 
communications process. 
Consider a binary amplitude-modulated communications 
system with two state-pairs (t1 - r1 and t2 - r2) and without 
time domain or tolerance effects.  The input message to T is 
compared with the decision boundary between t1 and t2 
determining which state causes a T signal output in volts 
(V).  T encodes +V signals for t1 and -V signals for t2 which 
are received as signals in R. The received signal is compared 
with the decision boundary between r1 and r2 determining 
which state causes a R output message.  R decodes +V 
signals to r1 and -V signals to r2.  The decision boundaries, 
both threshold and maximum, are lower level parameters 
(formed by other parameters created in the implementation 
of T and R). These boundaries implement the relationship 
between each part of the t1 - r1 and t2 - r2 state-pairs and  
determine the operational characteristics of the signal path.  
A more complex communications system has more sets of 
transmitter and receiver state-pairs (parameters) and more 
complex boundaries.  
Example: In the course of reading, a word appears of 
unknown meaning.  The reader refers to a dictionary.  A 
dictionary relates words (states) to their meanings (message). 
The author and reader select words from similar dictionaries 
(first and second comparisons). The author's and reader's 
dictionaries together are the state-pairs of equal words with a 
common meaning in each dictionary.   
The state-pairs in a communications system may be 
created by chemical bonds (A-C, G-T in DNA), pre-existing 
written or spoken alphabets, pre-existing dictionaries or 
syntax, the specifications or standards defining a transmitter, 
receiver or protocol (electronic communications) or a 
physical implementation of a transmitter, transmission link, 
or receiver.  Different functionalities of state-pairs are 
divided into layers in the Open System Interconnect model 
(OSI) where each reference layer provides the interface(s) 
used by the next layer.  Layer one includes physical aspects 
of the interface and higher layers include successively more 
abstract functionality. 
IV. 
MEASUREMENT PROCESS 
With a model of a communications structure and 
communications process, a measurement can be defined in 
mathematical terms.  When a measurement is understood, 
communication entities and their interface may be defined. 
Then adaptability can be measured based on the interface 
between the communicating entities.  
A measurement is a quantified selection from an entity or 
process (E/P) being measured.  Making a quantified 
selection is similar to the communications process shown in 
Table 1.  In a measurement process there is a receiver with a 
set of states used for comparison with the signal from an E/P 
to be measured.  The signal from the E/P may be generated 
by the E/P or applied externally to the E/P to generate a 
reflected signal.  This signal from the E/P may be seen as 
from a transmitter.  The receiver must have one-one states 
with the signals received for a practical measurement.  The 
similarity of a measurement and a communications process 
supports the use of communication theory to analyze the 
measurement process.   
N. Campbell defines a measurement (the concept) as "the 
assignment of numerals to represent properties" [4].  A 
measurement process assigns the numerals by utilizing one 
or more comparisons between the signal received and the 
states of the receiver.  Each of the states of the receiver, and 
its associated boundary conditions, acts to quantify the 
measurement.  Any parameter (property) of an E/P which 
may be quantified, e.g., weight, length, color, hardness, 
texture, transfer rate, capacity, spin, etc. may be a measured 
parameter.   
The choice of the receiver, its range of states and 
boundary conditions actually selects and quantifies the 
parameter of the E/P to be measured.  That is, if a length 
scale is used, distance is measured; if a weight scale is used, 
weight is measured; if a voltmeter is used, voltage is 
measured, etc.  A measurement is not absolute; it is always 
For the transmitter (T): 
1 
Select an input message 
2 
Compare this input and determine state (ti) 
3 
Output a signal 
For the receiver (R): 
4 
Select the signal received 
5 
Compare this signal and determine related state (ri) 
6 
Output message 
147
ADAPTIVE 2010 : The Second International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-109-0

 
relative to the parameter measured by the receiver, the states 
of that parameter in the receiver and the boundary conditions 
between states.  This requires that the states of the receiver 
be represented in a definition of measured information.   
V. 
DEFINING MEASURED INFORMATION 
The following paragraphs develop the mathematical 
basis for the information contained in the measurement of a 
parameter (T) of an E/P.  When the quantity of measured 
information transmitted across an interface is known then the 
adaptability of that interface may be quantified.   
 
 
 
Equation (1) is Shannon's equation for entropy [1, page 
50]. p describes the probability of (x).  Dt (2) is defined in T. 
Cover and J. Thomas as the entropy relative to log n [5, page 
27].  This following paragraphs develop a proof that Dt 
represents the information contained in the measurement of a 
parameter (T) of an E/P.1  A receiver (for ti) with n discrete 
states is assumed in (2).  The n discrete states are represented 
by the first term (log n) in (2).  The entropy distribution 
(H(T)) of the measurement process is calculated by the 
second term.  The first term is the reference applied to 
quantify the second term.  The output from the measurement 
process is one or more specific states tx, ty, tz.  The measured 
information is equal to Dt.  
As example, when a voltmeter (used to measure volts) 
with a 3 volt full scale (parameter of the voltmeter) and the 
minimum measurable increment (tolerance) of 0.1 V, has 30 
(= n) possible states of vi and produces a single output 
measurement vx, then Dv = log 30.   The greater the number 
of states n, the greater the information from the measurement 
process.  The narrower the distribution of the entropy term 
(H(T)), the greater the information.  A perfect measurement 
(zero H(T)) produces the maximum information, log n.  The 
first term of (2) effectively includes the concept of tolerance 
(minimum 
measurable 
increment) 
in 
the 
measured 
information calculation.  
Fig. 2 expresses (2) as a Venn diagram.  Fig. 2 shows 
how the limit of the entropy distribution (log n) is related to 
the entropy distribution (H(T)).  Equation (3) is Cover and 
Thomas' equation for Mutual Information (MI), the relative 
entropy between related entropy distributions.  Replacing 
H(R) in (3) [5, page 19] with log n calculates the mutual 
information of H(T) and log n (4).   
 
 
MI = I(T;R) = H(R)–H(R|T)  
(3) 
 
Expand H(R|T)=H(R)–H(T), then replace H(R) with log n 
 
 
MI = log n - (log n – H(T)) 
(4) 
 
                                                             
1 This definition of measured information has been proposed before.  The 
first time may be in 1957 [6].  To the author's knowledge this paper offers 
the first proof of this definition. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2.  Venn diagram of H(T) and its limit. 
 
 
MI  = H(T)= I (T; log n) 
(5) 
 
Equation (5) shows that H(T) when referenced to its limit 
is equal to the mutual information as the log n terms in (4) 
cancel each other.  Using Dt (2) provides a rigorous 
description of measured information without changing 
mutual information (MI). 
In support of using H(R|T) = H(R)–H(T) above, a related 
result to (5) substitutes H(T) for H(R) in (3) and is noted as 
self-information [5, page 20].  Equation (5) and self-
information indicate that the reference may be either log n or 
H(T) itself.  If the reference is not log n or H(T) itself, then 
there are additional parameters (not T).  A single parameter 
entropy distribution should be referenced to its limit (i.e., log 
n), as applying H(T) to reference H(T) is self-referential. The 
measured information related to a single parameter entropy 
distribution only exists in relation to a reference and the only 
logical reference is the limit of the entropy distribution.  This 
provides a proof of Dt (2) as the definition of measured 
information.   
Consider a measurement of the length of an entity using a 
meter scale.  The meter scale is divided into 1000 
increments.  The entity is the same number of increments 
long (x) every time it is measured, i.e., the entropy 
distribution of this measurement is zero (log 1 = 0).  The 
measured length is x (the data).  Then the information 
contained in the measurement is log 1000.  The quantity of 
measured information is the same for any accurate 
measurement using the same meter scale (reference).   
VI. 
COMMUNICATIONS 
Communications across an interface makes adaptability 
possible.  This requires the six operations from Table 1 
(above).  These six operations occur across the interface 
formed by the state-pairs.   
A communications system is modeled by using two 
overlapping Venn diagrams from Fig. 2 as shown in Fig. 3.  
The second Venn diagram in Fig. 3 models H(R) and log nr  
and their relationship Dr.  Fig. 3 is derived from Shannon's 
model of a communications system, where the receiver 
output is related to the transmitter input by a probability less 
than one.  Fig. 3 models equation (3) with the addition of the 
limits of H(T) and H(R) and their associated intersection.   
In Fig. 3 log nt is the bound of H(T) and log nr is the 
bound of H(R).  The intersection of log nt and log nr  is 
log n 
H(T) 
Dt = log n - H(T) 
148
ADAPTIVE 2010 : The Second International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-109-0

 
shown as a dotted lens shape.  This intersection represents 
the interface (I) made up of all the possible state-pairs of T 
and R.  I limits the MI (intersection of the solid circles, solid 
lens shape) possible between T and R.  MI represents the 
entropy distribution transferred from T to R.  I is the limit of 
MI in the same manner that log n is the limit of H(T) as 
shown in Fig. 2.  Similarly, the intersection of Dt and Dr (not 
delineated in Fig. 3) represents the measurement of the 
information that is communicated, in the same manner that 
Dt (2) represents the information in a measurement.  When I 
(the state-pairs available for communications) is changeable, 
adaptability is possible.   
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3.  Venn diagram of a communication system. 
By expanding on the previous example of the 
measurement of the length of an entity with a meter scale, a 
rudimentary communications process may seen.  After the 
first measurement (with first comparison), the data (x) is 
transferred (communicated) to a second entity by applying 
the meter scale to a second entity and identifying where x 
appears (second comparison).  The two meter scales (or one 
used 
twice) 
form 
the 
set 
of 
state-pairs 
in 
this 
communications process which pass the data (x) from the 
first entity to the second entity.  This example shows that a 
measurement transfer system transfers data by comparing the 
initial entity to its reference and comparing the referenced 
data to the second entity.   
Fig. 3 offers a similar view to the simple measurement 
transfer example above, where the transmitter entropy 
distribution (a measure of the transmitted data distribution) is 
compared to the common state-pairs (interface) formed by 
the limits of the transmitter and receiver entropy 
distributions.  This creates the MI which, with unpaired 
states of the receiver, provides the received entropy 
distribution (a measure of the received data distribution).  
This view explains how communications occurs, not by an 
H(T) to H(R) interaction, but via the existence of a state-pairs 
interface.   
VII. ADAPTABILITY 
In a communications system, the parameters are defined 
by sets of state-pairs which form the interface (I) between 
two compatible E/P.  The interface (I) allows comparisons 
which can support communications.  Changing I is what 
allows adaptability.  Using this model it is now possible to 
define and quantify adaptability. 
A. Unpaired States 
Each parameter presented across an interface consists of 
a number of state-pairs (n).  However, the number of states 
in T may not be the same as the number of states in R for 
some parameters. This situation was not considered in 
Shannon's work, perhaps because it was seen as a design 
error.  However, in complex communication systems such 
unpaired states occur when parameters, by virtue of options, 
special features, differing revisions or just non-selection in 
the transmitter or receiver, are not available or not used.  For 
instance, telephone modems may support up to six different 
modulations ranging from 300 bit/s to near 56 kbit/s.  Using 
a standardized protocol (V.8), the telephone modems 
identify which modulations are available at each end and 
select the modulation which supports the highest common 
data rate; the remaining modulations are unused.  
Fig. 3 shows unpaired states within each dotted circle 
areas (log nt and log nr) and outside I.  The communications 
structure would be more efficient if unpaired states didn't 
exist.  Older communications systems, which tended to be 
single provider (e.g., telegraph and telephony), tried to avoid 
unpaired states to be more efficient.  But the need for 
tolerance in older analog receivers always required the 
receiver states (e.g., bandwidth) be greater than the 
transmitter states.   
Newer communications systems tend to have more and 
more unpaired states as communications becomes more 
complex and multi-vendor.  This may also be seen as a 
greater desire for peer-to-peer systems (which will have 
unpaired states).  Interconnected systems have become 
larger, multi-vendor, and include many revision levels and 
multiple technologies.  Since memory and programming 
costs are very low and continue to decline, the trend towards 
less efficient systems (with more unpaired states) appears to 
be continuing. 
At least two approaches have been used to avoid the 
effects of unpaired states: 1) the selection of other 
capabilities has been treated as vendor-specific and not 
defined (e.g., the 3G cellular IMT-2000 standards);  2) a 
protocol is defined to determine which of the available 
capabilities in the T or R should be employed in a specific 
situation.  As example, telephone modems prior to V.32 
(circa 1984) selected the modulation used based on 
convention and vendor-specific decision boundaries.  After 
V.32, the identification, negotiation and selection of a 
specific modulation was defined by an independent protocol, 
V.8.   
B. Defining Adaptability 
Adaptability in communications systems is the process of 
automatically negotiating possible parameters, as it makes a 
system more adaptable.  As defined here, adaptability 
requires three specific functions: identification of the 
capabilities available at each end, negotiation to determine 
the desired state-pairs (the interface), and selection of the 
desired state-pairs (which may require accessing software 
from elsewhere).  These three functions are more complex 
versions of the three basic operations (Table 1) required for 
any communications: select input, compare input to 
reference (with adaptability mechanisms each end is 
 H(R) 
 
H(T) 
MI 
log nt 
log nr 
I 
149
ADAPTIVE 2010 : The Second International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-109-0

 
compared to the other), and create output (select state-pairs).  
After these adaptable processes are completed, then 
communications of information or control can begin via the 
negotiated interface.  
Interfaces have three major variations: fixed (state-pairs 
are unchangeable), flexible (state-pairs may be changed) and 
adaptable (state-pairs are negotiated).  A mechanical plug 
and socket is an example of a fixed interface.  Examples of 
flexible interfaces include: an Edison light bulb socket which 
supports many different types of lamps.  While the 
mechanical aspects of the light bulb and socket are fixed, the 
load can be changed.  A human user manually identifies and 
selects the specific lamp and the Edison light bulb 
plug/socket (the physical interface) makes this flexibility 
possible.  A protocol example of a fixed interface that 
supports flexibility is the use of the Internet protocols 
TCP/IP as the interface with which each lower physical 
network or higher layer protocol is designed to interoperate.  
Some programmable processes also provide flexible 
interfaces.  As example, XML (eXtensible Markup 
Language) provides identification and selection without 
negotiation.  
Flexible interfaces using XML are the current state-of-
the-art.  Universal Plug and Play (UPnP) utilizes XML to 
identify and select resources between a local personal 
computer and peripheral devices.  In this system the personal 
computer is "in charge" and negotiation is not necessary.  
Application layer negotiation to purchase music, books or 
programs is also widely used (e.g., Apple Store).  But the 
negotiation of lower layer communications services (e.g., 
bandwidth, compression, security) where there may be a 
charge involved requires that the communications system 
itself be adaptable.  As example, the compression of audio 
and video may be quite complex and many implementations 
are patented.  The ability to select which form of audio or 
video compression is desired depends on the bandwidth 
available, the users' needs for audio or video quality and the 
users' willingness to pay.  This requires a negotiation only 
possible with an adaptable communications system.  Since 
the concept of adaptability is not widely understood, there 
are few examples of lower layer communications systems 
that support negotiation for the purpose of economic 
transactions.  Yet the difficulty of equitably providing 
additional Internet bandwidth is well known and the even the 
subject of US Federal Communications Commission 
hearings. 
A negotiation process is required to equitably support 
charging for lower layer communications services on the 
Internet.  If one or more parameters are identified as 
proprietary (e.g., identified by a trademark), the use of such 
parameters would legally require the trademark owner's 
approval.  All the other parameters used in the interface 
remain in the public domain.  Such approval might require 
some form of payment to the trademark owner.  If the 
proprietary service is valuable, implementers or users will 
have reason to pay the trademark owner for the use of their 
proprietary technology or service.  Many different 
procedures are possible to compensate the trademark owner: 
charge for downloads, per implementation fees, usage fees, 
periodic maintenance/support fees, or simply the sales 
advantages of proprietary implementations or services 
offering improved operation over public sections of the 
standard.   
Adaptability, which includes the means to negotiate 
state-pairs, is necessary to support true peer-to-peer 
communications. Without negotiation, one E/P must depend 
on the other to determine state-pairs, when unpaired states 
are possible.  By definition, a dependent relationship cannot 
be peer-to-peer.  Only when the two communicating E/P can 
change independently can they be considered peers.   
C. Measuring Adaptability 
Communications interfaces are layered.  Adaptability or 
flexibility may be employed at each layer of the OSI model 
or partially in one or more layers.  A complex interface may 
consists of a mix of fixed, flexible and adaptable parameters.  
Understanding state-pairs and the significance of the number 
of state-pairs allows the interface's adaptability to be 
measured.  The adaptability of an interface may be 
quantified by counting the total number of state-pairs 
available across the interface and relating it to the total 
number of flexible (e.g., weighted 0.5) and adaptable (e.g., 
weighted 1.0) state-pairs.  Arbitrarily weighting flexibility as 
one-half adaptability allows both approaches to changing 
state-pairs to be evaluated.  The choice of the weighting of 
flexibility and adaptability as well as the weighting of 
specific parameters (e.g., is physical layer adaptability more 
or less important than higher layer adaptability) is closely 
related to the intended use.  Equation (6) models the example 
of a very simple interface with three parameters b, c and d 
where b has n state-pairs (all fixed), c has m state-pairs (all 
flexible) and d has p state-pairs (all adaptable); the 
percentage of adaptability (A) is shown in (7). 
 
 
a = ( .5m+1p)/(n+m+p)  
(6) 
 
 
a x 100 = A in percent  
(7) 
 
Consider the example of the meter scale (n = 1000mm) 
used to transfer a measurement from one entity to another. 
When a meter scale is used on one side of a measurement 
stick and an extended yard scale (n = 16 x 39.37 inches = 
629.92) is used on the other side, flexibility is introduced.  
Then each scale of the measuring stick is a set of fixed state 
pairs and the two scales are two flexible state-pairs (m=2):  
1. measuring both entities with the meter scale. 
2. measuring both entities with the yard scale.   
The measurement of adaptability for this example is 
shown in (8), (9) and (10), where m=2, p=0, n1=1000 and 
n2=629.92: 
 
 
a = ( .5x2+1x0)/(1000 + 629.92+2+0)  
(8) 
 
 
a = ( 1)/(1631.92)  
(9) 
 
 
a x 100 = .06% A 
(10) 
 
150
ADAPTIVE 2010 : The Second International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-109-0

 
D. Implementing Adaptability 
At least two means to implement adaptability are known.  
Adaptability may be created by a software program (often 
termed agent software) that can identify, negotiate and select 
the state-pairs across an interface.  Or an independent 
communications protocol may be used for the purposes of 
identification, negotiation and selection.  When such a 
protocol is used only for these purposes, it is termed an 
etiquette [7].  It seems likely that other approaches to 
implement adaptability will be identified.  
Etiquettes are already used in some communications 
systems, e.g., ITU V.8 for telephone modems, ITU T.30 for 
G3 fax,  ITU G.994.1 for digital subscriber line transceivers, 
and IETF Session Initiation Protocol (SIP); their properties 
have been explored previously [7].  In the long term 
evolution (LTE) architecture, an etiquette would allow the 
service provider to negotiate the protocol that optimizes 
system loading or maximizes geographic coverage, or allow 
a user to select the protocol (and related service provider) 
that offers the best economic performance for that user. An 
etiquette 
also 
better 
supports 
troubleshooting 
of 
incompatibilities as each end can identify the available 
parameter sets of the other end.  The use of adaptability 
mechanisms is a system architecture choice which 
significantly enhances the long term performance of 
programmable heterogeneous communications systems. 
When systems are programmable, adaptability is 
possible.  An etiquette transmitter presents the range of 
possible compatible parameters to an etiquette receiver.  The 
etiquette receiver responds with its range of possible 
compatible parameters.  Using heuristics local to the 
transmitter and receiver (e.g., largest parameter is best [pels, 
bits, colors, data rate, etc.]) or remote heuristics accessed by 
both the transmitter and the receiver (e.g., using a remote 
data base to determine which common parameters are to be 
utilized), the etiquette transmitter and receiver negotiate and 
select the desired interface for compatibility and follow-on 
communications.  
Adaptability could be useful in software defined radios.  
A software defined radio which includes the physical layer, 
perhaps others, is not defined as adaptable but has the 
properties ─ programmable and a radio interface (non-
mechanical) ─ that allow it to be adaptable.   
Compatible systems have state-pairs.  If there are 
transmitter states (at any OSI layer) that do not have related 
receiver states, such inconsistencies can cause "bugs."  
Adaptability mechanisms offer a means to negotiate and 
select a specific interface and reduce such bugs.   
For the negotiation process of an etiquette to operate 
consistently, any addition to an etiquette must be a proper 
super-set of the previous version.  As long as the etiquette is 
a logical single tree structure, where each branch refers to a 
single parameter set, no deletions are allowed and the 
etiquette receiver ignores anything it doesn't recognize, a 
correctly modified etiquette will always be backward 
compatible.   
Following this model, an etiquette may be expanded 
whenever desired, independently in the transmitter and the 
receiver.  This allows new capabilities, and the parameters in 
the etiquette that identify them, to be added to a 
communications system at any time.  If both ends can 
support the new parameters they can be employed.  If one 
end supports a parameter and the other end does not, it may 
be practical for the deficient end to download the needed 
software from a known Internet web site.  
VIII. CONCLUSIONS 
Adaptability makes it possible to automatically negotiate 
the rising complexity of communications, introduce new 
technology into communications channels at will, simplify 
communications troubleshooting, better support multi-mode 
operation, avoid identified communications channel bugs 
and support incentives to developers and implementers 
without forcing all users of public interfaces to pay private 
fees.  The advantages of adaptability are significant.  Using 
the approach outlined, the adaptability of current and future 
programmable communications systems may be measured so 
that users, service providers and developers may easily 
recognize and utilize this important functionality.  
REFERENCES 
[1] C. E. Shannon and W. Weaver, The Mathematical Theory of 
Communications, Fig. 1 p. 34. Urbana and Chicago IL, USA: 
University of Illinois Press, 1963. 
[2] B. Russell, Introduction to Mathematical Philosophy, page 
15. New York: Simon and Schuster, 1971.  
[3] I. Kant, Logic (General Doctrine of Elements, Para. 6, Logical 
Acts of Comparison, Reflection and Abstraction), Library of 
Liberal Arts, trans. R.S. Hartman and W. Schwarz.  
Indianapolis and New York: The Bobbs-Merrill Company, 
Inc., 1974. 
[4] N. Campbell, Foundations of Science, p. 267, Dover 
Publications, New York, NY, 1957. 
[5] T. M. Cover and J. A. Thomas, Elements of Information 
Theory, New York: John Wiley & Sons, Inc., 1991. 
[6] H. Everett, III, Theory of the Universal Wave Function, page 
25, 1957, published in The Many-Worlds Interpretation of 
Quantum Mechanics, edited by Bryce S. DeWitt and Neil 
Graham, Princeton Series in Physics, 1980. 
[7] K. Krechmer, "Fundamental nature of standards: technical 
perspective," IEEE Communications Magazine, 38(6), p. 70, 
June, 2000.  Also at http://www.csrstds.com/fundtec.html    
 
151
ADAPTIVE 2010 : The Second International Conference on Adaptive and Self-Adaptive Systems and Applications
Copyright (c) IARIA, 2010               ISBN: 978-1-61208-109-0

