A Collaborative Responsive and Fully Customizable System for Image Quality 
Assessment Based on Subjective Visual Perception 
 
Maria Grazia Albanesi 
Dept. of Electrical, Computer and Biomedical Engineering 
 University of Pavia 
Pavia, Italy 
Email: mariagrazia.albanesi@unipv.it 
 
 
Abstract— This paper describes a new system for image 
quality assessment related to subjective visual perception. The 
novelties of the contribution consist in the realization of a Web-
based collaborative platform, which (a) allows a set of human 
observers to cooperate to the process of Mean Opinion Score 
generation in a complete asynchronous and distance-online 
participation, and (b) is fully responsive, thus the images can 
be tested on different devices, not only monitors or television 
sets, but also smartphones. A new method for the analysis of 
the results is also proposed; it is based on visual tables, which 
arrange the semantic of the experimental data in colored 
patterns, useful for understanding the properties of both 
images and observers. A set of target images has been 
identified and included in a Web based prototype to which 
testers can freely connect. The system is fully customizable 
because the code is freely available for download; in this way 
the programmer may easily change all the main parameters 
(images, number of impairments levels, type of impairment, 
and so on). Experimental results are reported and commented, 
with considerations on the possible applications of the system 
in different contexts. 
Keywords - subjective image quality assessment; visual 
analisys, collaborative Web-based process. 
I. 
 INTRODUCTION 
Image quality assessment is an important task in modern 
multimedia processing, since the perceived quality can 
greatly influence the use of image information and the 
quality of experience [1-2]; moreover, the subjective 
evaluation of the perceived quality of a digital image is 
considered the most reliable method, since it can faithfully 
reflect 
the judgment of 
the human 
observer [3]. 
Unfortunately, 
organizing 
subjective 
image 
quality 
assessment experiments is very time consuming and requires 
a high economic effort and commitment. In this paper, a new 
system for subjective image quality assessment is proposed. 
The system was developed at the Department of Electrical, 
Computer and Biomedical Engineering (University of Pavia, 
Italy) and it has the main purpose of supporting scientists in 
the realization of experiments for subjective assessment of 
the quality of digital images. The most used approach (in the 
following, the traditional approach) in literature is to carry 
out the evaluation of the perceived quality experimentally 
using a set of human observers, which are asked to rate the 
perceived quality in different situations. In this process, there 
are several issues that matter: 
• 
The choice of human observers is particularly 
critical, since they must be sufficiently educated on 
the standardized protocol to be used in the 
experimental evaluation and must also have peculiar 
characteristics, e.g., normal or corrected to normal 
visual acuity, a good sensitivity to colors, a good 
ability to maintain high attention and concentration 
as the experiments can also last several minutes. 
• 
The realization of the experiments for perceptive 
evaluation of image quality in the laboratory are 
often too expensive and time consuming. The setup 
of the necessary hardware can involve the use of a 
high volume of resources and efforts. 
• 
The choice of the set of images to be evaluated can 
also greatly influence the results of the experiments. 
Generally, the choice is made according to the type 
of impairment to consider. There are many datasets 
of digital images freely downloadable to be used in 
the experiments, for example the very well-known 
databases by the Laboratory for Image & Video 
Engineering (LIVE) [4]. 
For many years, the subjective assessments of image 
quality have been realized following the traditional approach, 
which has been particularly relevant in some applications, 
e.g., in television broadcasting [5]. Since 2009, some 
innovative proposals began to appear [6-8], with the intent to 
replace or to be alternative to the traditional method. They 
were based on a crowdsourcing approach, namely the 
possibility of recruiting observers on the Web and the 
realizations of the experiments using a Web-interface. This 
approach has several advantages and disadvantages, which 
must be properly balanced. The crowdsourcing approach 
reduces costs, as it is not necessary to set up an effective 
evaluation environment in the laboratory (hardware set up 
and staff commitment). Furthermore, the recruitment phase 
of the observers can also be delegated to another subject (e. 
g., an external company, as in [8]) or using collaborative 
platforms, i.e., social networks. The main disadvantage of 
this approach is that you lose the control over the choice of 
observers and the standardization of the method. For this 
reason, it is very important to provide observers with a 
precise and detailed protocol with all the instructions they 
must follow, including those relating to the implementation 
1
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-978-2
VISUAL 2022 : The Seventh International Conference on Applications and Systems of Visual Paradigms

of the experiment, for example the distance from the 
monitor, lighting, or other details. However, there is no 
guarantee that the observer follows the protocol correctly as 
the process of expressing the opinion on the perceived 
quality is not supervised. Although the last aspect seems 
particularly critical, the results in the literature have been 
encouraging in identifying the crowdsourcing approach as 
very similar if not equivalent to the traditional approach, by 
comparing the Mean Opinion Score (MOS) in both the 
approaches on the same target dataset, with a high 
correlation coefficients and confidence interval [8]. 
The main goals of the project here reported try to 
overcome some of the problems of both the traditional and 
the crowdsourcing approaches, by proposing a hybrid 
system. Moreover, an innovative tool for analyzing human 
observer reliability is described, to fill the gap in literature on 
the critical issue of the selection of subjects involved in the 
experiments. 
The rest of the paper is organized as follows: Section II 
describes the goals addressed and the method implemented 
in the system. Section III describes the experiment design 
and analysis. Section IV provides some further ideas for 
using 
the 
system 
in 
different 
applications. 
The 
acknowledgement and conclusions close the article. 
II. 
GOALS AND METHODS OF  SYSTEM IMPLEMENTATION 
The proposed system is a hybrid between the traditional 
approach and the crowdsourcing approach. It was called 
Subjective Image Quality Assessment (SIQA) project [9] and 
it is based on a Web interface for experimental evaluation of 
the perceived quality. However, the possibility of 
downloading the entire project and installing a stand-alone 
configuration (still maintaining the web interface) allows to 
use it also for the traditional approach. We called it a hybrid 
system because it clearly can be exploited while retaining the 
positive aspects of both solutions, e.g., the traditional and the 
crowdsourcing approach. In fact, there are two methods for 
using the SIQA system: 
 
• 
Offline method: the open-source code [10], was 
developed in Phyton, under Massachusetts Institute 
of Technology (MIT) License; it can be freely 
downloaded and used as it is or modified to adapt 
the experiments to your commitments. This is like 
the traditional approach, but for the user interface (a 
web browser) and the image dataset (freely 
downloadable o replicable). This method can also 
guarantee the important aspect of customization (see 
Section II.A, Innovations of the System). 
• 
Live method: by taking the “Live Test” on the SIQA 
website [9]. This is performed on a subset of images 
and, clearly, it follows a pure crowdsourcing 
approach. However, it can be used for the important 
phases of the traditional approach of training the 
observers and their warming-up at the beginning of 
the subjective quality assessment experiments [3]. 
Therefore, the system is useful regardless of which 
approach (traditional or crowdsourcing) you use and 
can be adapted to different experimental contexts. 
The two operating methods also guarantee some 
innovative aspects, with respects to the current state-of-the-
art, which are detailed in the next paragraph. 
A. Innovations of the System 
Using the SIQA system in one or both the methods 
before described, you can have some interesting and 
innovative advantages: 
• 
You can decide to have full control over the choice 
of observers, as in the traditional approach, or to 
relax it (crowdsourcing approach). 
• 
You can choose one of the approach or both 
according to your needs: for example, you could 
choose the crowdsourcing approach for a test phase 
or for the selection of observers and then choose a 
more 
traditional 
approach 
to 
improve 
the 
standardization of the process and obtain the real 
experimental data. 
• 
The SIQA Web site is fully responsive, so it can be 
used to test human observer perception on different 
kind of devices, including smartphones. Evaluating 
user experience on smartphone has become more 
and more important over the years [11]. 
• 
The possibility of completely downloading all the 
code and being able to modify it allows the scientist 
to easily replace the image datasets (taking it form 
the many available in literature [4] or a personalized 
dataset) and modify their characteristics, for example 
the number of levels and type of impairment, the 
type of images (gray-level or color images, 
resolution, format, or compression standards). 
• 
The possibility of changing the quality impairment is 
very important: it can be not only noise, 
compression, or other engineering parameters, but 
also coming from other disciplines, to extend the 
concept of image quality to other fields, for example 
psychology, which is interesting in communication 
and advertisement (see Section IV, Examples of 
Application of the System). 
Besides the SIQA system, in the paper an innovative tool, 
called Visual MOS Table, for analyzing the experimental 
data is proposed and described. It is a visual tool: by 
arranging the MOS values in a bidimensional table and with 
a simple but effective use of colors, it is very simple to 
analyze which images in the dataset can be considered 
“outliers” in the perceptual process. Moreover, the Visual 
MOS Table can be used also to identify which human 
observers are too strict, or too permissive, in assessing 
quality.  
B. Impression or quality?  
At first glance, SIQA project may seem very similar to 
systems used for user impression evaluation, such as the so 
popular solutions of photo sharing on Web. However, there 
are some substantial differences: first, in a subjective quality 
assessment task (as in SIQA project), opinion score is 
statistically evaluated not only for what concern the average, 
but also the standard deviation, which gives relevant 
information about the homogeneity of the evaluation task. 
2
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-978-2
VISUAL 2022 : The Seventh International Conference on Applications and Systems of Visual Paradigms

Moreover, in a real subjective evaluation experiment, the 
user does not choose the image to rank, and the set of 
assessed images is the same for all the subjects. These 
constraints do not apply to standard photo impression 
evaluation. For this reason, SIQA project evaluate the 
subjective quality (as defined in literature), rather than a 
simple user impression on the Web. 
III. 
EXPERIMENT DESIGN AND ANALISYS 
The system is fully compatible with the method 
recognized in the literature among the best ones for 
subjective evaluation, i.e., the single stimulus Absolutely 
Category Rating (ACR) test [5]; in fact, in literature, there is 
no evidence that a double stimulus method is more accurate 
than a single stimulus [12]. Moreover, the single ACR 
stimulus is one of the best in optimizing time effort of the 
experiments, especially if we need to put a temporal limit to 
each experimental session (in general no more than 30 
minutes).  The single stimulus ACR method ask the 
observers their opinion about the perceived quality of only 
one image at time, by expressing a rank according to five 
scores, from 1 to 5, according to a well-known equivalence, 
shown in Table I. The values of the scores are collected on a 
pool of images and for a set on human observer, and the 
standard results of MOS and its Standard Deviation (SDOS) 
are provided. 
The SIQA system has been tested first in a set of closed 
experiments (i.e., inside the laboratory) on different kinds of 
images (color, grey levels) and different visual impairments 
(lossy compression, noise addition, blurring) of increasing 
severity. On the SIQA Web site [9] the results of these 
preliminary tests are available by clicking on the second 
button (i.e., “Download presentations”) in the section 
Download (see Figure 1). 
 
 
Figure 1.  The Donwload Section (on the top) and the Live Test Section 
(on the bottom) of the SIQA Website (https://siqa.pythonanywhere.com).  
TABLE I.  
THE FIVE SCORES OF THE ACR METHOD 
Score 
Perceived 
Quality 
Perceived 
Impairment 
Colors in Visual 
MOS Tablesa 
5 
Excellent 
Imperceptible 
Green 
4 
Good 
Just Perceptible but 
not annoying 
Light Green 
3 
Fair 
Perceptible and 
slightly annoying 
Yellow 
2 
Poor 
Annoying 
Light Red 
1 
Bad 
Very annoying 
Red 
a. 
The meaning of this field is explained in Section III.A 
 
As explained in the previous paragraph on innovations, 
there are two design methods: Live (online) Test and Offline 
test. The first correspond to the crowdsourcing approach, the 
second to the traditional one. In the Live Test is available by 
connecting to the SIQA Website and by clicking on the 
button “Take the test”. The test is performed using a pre-
defined set of three different versions of ten color images: 
“original”, “impairment1” and “impairment2”. The ten 
original images are depicted in Figure 2. The impaired 
versions are obtained from the ten original ones, by applying 
the standard Joint Photographic Experts Group (JPEG) 
compression algorithm, with different quality levels. 
Degradation on impairment1 images should be less visually 
noticeable than the one on the impairment2 images. 
Figure 3 shows a moment of the score expression in the 
interface of SIQA. The score is requested by a simple mouse 
click; other interfaces, for example in [13], store the score 
using a visual stimulus recording, by an eye tracker. 
However, we have decided the simplest mouse-driven 
interface because we want to assure the possibility to use the 
Live Test also on other devices, e.g., smartphone (where 
mouse click is substituted by a simple touch). 
The entire test on the thirty images takes approximately ten 
minutes. We have chosen this duration because it can be 
easily used to select the observers in trial test or for the 
reheat phase in traditional experiments. The strictly 
controlled conditions of traditional test are replaced with 
simple instructions to the observer: 
• 
Observe all the images under similar conditions: 
(viewing distance, brightness, artificial lighting, 
screen contrast). 
• 
Give an evaluation for each image in a maximum 
time of 15 seconds. 
• 
Wear contact lenses or prescription glasses, if any. 
• 
Take the test only once. 
After the test, the scores expressed by the online observer 
are added to the set of previously stored scores in the system, 
and MOS and SDOS are updated. They plots are available by 
clicking on the button “See Results”. For brevity, only the 
MOS experimental data are reported and analyzed in the 
paper (SDOS values are available online). 
At the time of writing this paper, the values of MOS for 
each image and each level of impairment are the ones shown 
in Figure 4: on the x-axis there are the ten images of Figure 
2. The three MOS plots refer to the different levels of JPEG 
quality (Original, Impairment1 and Impairment2). The trend 
3
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-978-2
VISUAL 2022 : The Seventh International Conference on Applications and Systems of Visual Paradigms

of MOS is perfectly consistent with the levels of impairment 
(“original MOS” is always over the impairment1, which is 
always over impairment2). Only for one image (i.e., image 
“tree”, showing section of a tree trunk, see Figure 2g) the 
three values are very closed: 3.79, 3.66, and 3.37, for, 
respectively, the original, impairment1, and impairment2 
image. A possible explanation of this fact is that probably the 
radial symmetry of the texture of image “tree” does not allow 
users to clearly perceive the block distortion, which is typical 
for JPEG compression. 
 
 
Figure 2.  The ten images for the Live Test: (a) Water (b) Books (c) Hand (d) Dogs (e) Tiger (f) Mountains (g) Tree (h) London (j) Poppies (k) Bear. 
 
Figure 3.  Example of the opinion expression for image “Mountains” in the Live Test. 
 
Figure 4.  The MOS computed in the Live Test for the ten images of Figure 2. 
4
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-978-2
VISUAL 2022 : The Seventh International Conference on Applications and Systems of Visual Paradigms

The second design method is the Offline test. On the 
SIQA Web site [9] a set of 135 preloaded images (45 
original and 90 impaired versions) are available by clicking 
on the first button (i.e., “Download image repository”) in the 
section Download. In the following paragraph, a discussion 
of the analysis of the MOS experimental data are discussed 
to show the application of the visual tool called Visual MOS 
Table. 
A. A new tool for experiment analysis: the Visual MOS 
Table 
The image repository for Offline method refers to gray-
level images; Figure 5 shows the first ten (original) images. 
We have used them in an experiment of subjective image 
quality assessment to show the utility of Visual MOS tables. 
The experiments consider three levels of quality, i.e., 
Unimpaired (e.g., Original), Slightly impaired (JPEG lossy 
compression, quality factor 25) and Highly impaired (JPEG 
lossy compression, quality factor 12).  The MOS has been 
measured for 13 expert observers (Evaluator 1-13) and 8 
non-expert observers (Evaluator 14-21). Figure 6 shows the 
Visual MOS Table, created on the MOS data collected in the 
experiments. The table cells are colored to reflect the MOS 
values: green and light green for MOS 5 and 4, yellow for 
MOS 3, light red and red for MOS 2 and 1. Data are 
arranged in two dimensions: the first refers to the columns, 
and columns containing data of the same level of quality 
define an Area of quality level. In Figure 6, the Area of 
quality level “Unimpaired” is highlighted with a blue box. 
By analyzing an Area of quality level across the columns, it 
is very fast and easy to identify images which are outliers in 
the process of subjective quality assessment. For example, in 
the Area of quality level “Unimpaired” yellow and red (light 
and dark red) cells refer to outlier images, i.e., images that 
have achieved a different score than one would expect. In 
Figure 6, for expert observers, image “Wuhan”, “Baby” and 
“Building” have collected five and four outliers (over 13 
observers). This suggest that they are the most difficult 
images to rank correctly.  
The Visual MOS Table can be analyzed also in the other 
dimension, by row. In this case the Area refer to 
homogeneous experimental constraints (Area of constraint). 
In the example, we distinguish between expert vs. non-expert 
observers and in Figure 6 the Area of constraint “non-
expert” is identified by a purple horizontal box. In this case, 
it is possible to identify human observers who are not well 
suited to effectively carry out perceptual judgment. 
Therefore, the system is useful not only to assess image 
quality, but also “tester (human observer) quality”. For 
example, among the non-expert area, the Evaluator n. 16 has 
judged almost every image with very high opinion score (all 
the cells are green, independently on the real quality!). By 
analyzing the Visual MOS Table, we also discover that 
among experts, the Evaluator n. 12 was unable to distinguish 
between images at the highest quality level (Unimpaired) 
and that of intermediate quality (Slightly Impaired), since all 
the cells in the line “Evaluator n. 12” are green in the two 
Areas of quality.  Therefore, Evaluator 12 and 16 could be 
considered outliers and could be discarded by the pool of 
observer in a next experiment. We suggest using the Visual 
MOS Table also to assess the “quality” of the human 
observers. The choice of observers is a very crucial point for 
the success of the subjective evaluation of perceived quality 
experiments and the Visual MOS Table can be a valid help to 
assist this task. 
IV. 
EXAMPLES OF APPLICATIONS OF THE SYSTEM 
The system can be customized by downloading the code 
and modifying the parameters, for example the number of 
impairment levels or the constraint conditions. These 
customizations reflect on the Visual MOS Table by adding 
further Areas of quality or Areas of constraints. For example, 
instead of using the two constraints expert vs. non-expert 
observers, constraints may be changed in “observing on the 
monitor” and “observing on the smartphones”, if the goal of 
the experiment is to investigate the impact on perceived 
quality on different screen. 
Another interesting application is to the definition of a 
more extensive concept of quality; if only one Area of 
quality is used, observers could be asked to evaluate not so 
much the perceived quality at the increasing levels, but the 
effectiveness in the transmission of a semantic message. 
Suppose for example to have five images and that the task is 
to evaluate how they are perceived by the humans for what 
concerns the efficacy in an advertisement message. By 
analyzing the Visual MOS Tables you can easily find which 
is the best image which obtained the highest score (i.e., the 
highest number of “green” or light green cells), possibly 
studying 
different 
viewing 
hardware 
(television 
or 
smartphones). 
V. CONCLUSION AND FUTURE WORK  
The paper describes a hybrid system for both traditional 
and crowdsourcing subjective assessment of image quality 
using a classical single stimulus ACR method. An innovative 
visual tool has been also described for the analysis of MOS 
experimental data, both for finding outliers in the image set 
or in the human observers. Future work will try to adapt the 
SIQA system to: (a) evaluation of video quality and (b) to 
rehabilitation of patients with cognitive deficits. In the latter 
case, instead of measuring the perceived quality, the human 
observer would be asked to express a judgment on the 
semantic of image, to check the ability of the patient to 
recognize different targets (faces, situations, environments). 
ACKNOWLEDGMENT 
The author would like to thank very much the following 
computer engineers of the staff of the Digital Content Retrieval Lab 
(University of Pavia) for the collection of the images and the 
deployment on the Web of the system and of the downloadable 
code: A. Al Masoud, F. Amato, A. S. Blindu, M. Bottini, D. P. 
Lotito, F. Marinelli, D. Murer, R. Petri, and F. Tagliani. 
 
REFERENCES 
[1] H. R. Sheikh and A. C. Bovik, “Image information and visual 
quality,” IEEE Trans. Image Process., vol. 15, no. 2, pp. 430–
444, Jan. 2006. 
5
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-978-2
VISUAL 2022 : The Seventh International Conference on Applications and Systems of Visual Paradigms

[2] Z. Bovik, Modern Image Quality Assessment, Morgan & 
Claypool Publisher, 2006. 
[3] H. R. Hu and K. R. Rao, Digital Video Image Quality and 
Perceptual, Taylor and Francis, 2006. 
[4] Laboratory for Image and Video Engineering, University of 
Texas, USA (LIVE) Subjective Image Quality Database. 
[retrieved: April 2022]: https://live.ece.utexas.edu/research/ 
quality/subjective.htm 
[5] “Methodology for the subjective assessment of the quality of 
television pictures,” ITU-R Recommendation BT.500-12, 
Sept. 2009. 
[6] K. T. Chen, C. C. Wu, Y. C. Chang, and C. L. Lei, “A 
crowdsourceable QoE evaluation framework for multimedia 
content,” in Proc. ACM Multimedia 2009. ACM, pp. 491–
500, 2009. 
[7] Z. Wang, D. Tao, and P. Liu, “Development and Challenges 
of Crowdsourcing Quality of Experience Evaluation for 
Multimedia”, Wang Y., Xiong H., Argamon S., Li X., Li J. 
(eds) Big Data Computing and Communications. Lecture 
Notes in Computer Science, vol 9196. Springer, 2015: doi: 
https://doi.org/10.1007/978-3-319-22047-5_36 
[8] F. Ribeiro, D. Florencio, and V. Nascimento, “Crowdsourcing 
subjective image quality evaluation,” Proc. of 18th IEEE 
International Conference on Image Processing, IEEE Press, 
Sept. 2011, pp. 3158-3161. 
[9] University of Pavia. Subjective Image Quality Assessment. 
[retrieved: April 2022]: https://siqa.pythonanywhere.com/ 
[10] University of Pavia. SIQA Software. [retrieved: April 2022]: 
https://github.com/aiman-al-masoud/image_quality_ 
assessment 
[11] Perceived Image Quality on Mobile Phones with Different 
Screen Resolution, doi:  https://doi.org/10.1155/2016/96219 
25 
[12] R. K. Mantiuk1, A. Tomaszewska. and R. Mantiuk, 
“Comparison of four subjective methods for image quality 
assessment”, COMPUTER GRAPHICS Forum, Vol. 31, 
number 
8, 
pp. 
2478–2491, 
2012: 
doi:  
https://doi.org/10.1111/j.1467-8659.2012.03188.x 
[13] O. Le Meur, A. Ninassi, P. Le Callet, and D. Barba, “Overt 
Visual Attention for Free-viewing and Quality Assessment 
Tasks: Impact of the Regions of Interest on a Video Quality 
Metric”, Signal Processing: Image Communication, Vol. 25, 
Issue 7, pp. 547-558, Aug. 2010, ISSN 0923-5965, doi: 
https://doi.org/10.1016/j.image.2010.05.006. 
 
Figure 5.  The first ten images of the downloadable dataset; in figure, only the original unimpaired version are shown. 
 
Figure 6.  The Visual MOS Table for the experiments of subjective quality assessment on the first ten images of the downloadable set (see Figure 5). The 
blue and purple rectangles define the Area of quality level and the Area of constraint of the table, respectively. 
6
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-978-2
VISUAL 2022 : The Seventh International Conference on Applications and Systems of Visual Paradigms

