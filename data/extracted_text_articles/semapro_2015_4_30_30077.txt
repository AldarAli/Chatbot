Mobile Queries using Semantic Processing into Augmented Reality 
 
Itzel Coral, Miguel Martínez, Félix Mata 
Computing Mobile Laboratory 
IPN-UPIITA 
Mexico City, Mexico 
{email: olivoscastillo@gmail.com, 
mrosales81@gmail.com, mmatar@ipn.mx} 
Roberto Zagal, Consuelo García,  
Systems Department 
IPN-ESCOM 
Mexico City, Mexico 
{email: rzagalf@ipn.mx,  
varinia400@hotmail.com}
 
 
Abstract— This article presents a mobile system to answer 
structured queries into a research-academic domain using a 
spatial Ontology. The answers to queries are displayed on an 
Augmented Reality (AR) interface. The structure of query is a 
triplet formed by: interrogative adverb, verb and direct object. 
The case study is in a university campus. Queries are solved 
using semantic processing, for example, {Who can advise on 
vector calculus?}. Then, possible answers (researchers or 
professors candidates) are obtained applying semantic 
similarity on attributes defined into Ontology (e.g., level of 
expertise, research line to which it belongs, topic, etc.). 
Additionally, spatial parameters are included into the answer, 
such as:  where researcher is located, schedules, colleagues, etc.  
The functionalities of system are: search persons based on 
qualitative and spatio-temporal attributes. The combination of 
a semantic approach with an augmented reality interface 
provides new possibilities to express queries; not only in text or 
based on location, but using AR with interactions. It is useful 
to locate persons in outdoor environments. 
Keywords-Spatial Semantics; Augmented Reality; Mobile 
queries. 
I.  INTRODUCTION 
Very often, in an academic environment, students are 
looking for professors, researchers or specialists with 
knowledge on different topics; even a thesis advisor. Then, 
when non-local students visit the facilities of a university, 
they look for professors to answer a particular question or 
doubt (expressed as a query from smartphone). They do not 
know researchers' names; in other words, information is 
imprecise. The only data they have is the specialty that a 
professor should belong to. Then, they need to ask 
more  information about professors or researchers from 
other students or people on campus. Therefore, it would be 
useful to have a system to help find which professors are the 
experts on particular issues. We have to consider that the 
professors can be located based on schedule of work. In 
addition, when the search for a professor includes several 
criteria, such as level of experience, international 
recognition, among others, the task becomes a challenge. 
This can be solved using a semantic processing approach 
combined with advantages of navigation using AR. In 
addition, once students have identified the professors that 
can support or advise them on a particular topic, it is useful 
to have a comprehensive tool in order to find out the 
schedule and specific geographical location within the 
campus where to find the professor or researcher in 
question. This functionality is enhanced when is displayed 
using AR. 
 
This paper introduces a semantic mobile system using 
augmented reality with the following capabilities: 1) search 
of professor or researcher by criteria: topic, level expertise 
among others, 2) schedules and places where the researchers 
can be found and 3) an interface of navigation and AR. The 
case study is focused on a campus of IPN (Instituto 
Politécnico Nacional) in Mexico, in order to assist students 
with questions regarding to topics of thesis or other subject-
matter. 
 
The rest of the paper is organized as follows: Section II 
shows the related work; Section III explains the 
methodology used; Section IV describes the obtained 
results, and finally, the conclusion and future work are 
outlined in Section V. 
II.  RELATED WORK 
AR technology augments the sense of reality by 
superimposing virtual objects and cues upon the real world 
in real-time [1] and indoor environments. AR has been the 
object of increasing development in outdoor and indoor 
environments [2][3][4][14].  In [11], an indoor technique is 
used for AR positioning system for indoor construction 
application by tracking the coordinates and its angles of 
vision. In order to, achieve indoor positioning in three 
dimensions. Nevertheless, no ontologies or semantic 
processing were used. AR was used in several ways but 
navigation is not provided by a semantic processing, such as 
in [12], where AR is used in a self-guided tour; the user can 
see environment information, sites or buildings, listen to 
audio touring narratives, or get directions.   
86
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-420-6
SEMAPRO 2015 : The Ninth International Conference on Advances in Semantic Processing

Ontology is also employed as a method for identifying 
categories, concepts, relations, and rules [5][6][7]. When 
combined with query languages, domain ontologies favor the 
design and development of domain-based search engines and 
their application to different areas [8]. In contrast, similar 
semantic approaches have been proposed; for example, 
GeoSpatial ontologies are applied in emergency systems for 
indoor disasters, for campus of University of Melbourne 
[13]. The semantic approach gets a spatial analysis; it is used 
for emergency management capabilities indoor and outdoors 
components. But, AR is not assisted using ontologies. Zhang 
et al. [9] proposed a technique that uses common sense 
geographic knowledge and qualitative spatial reasoning for 
the generation of a geographic Ontology. The tools for 
processing Ontology Web Languages (OWL) are numerous; 
One of the most popular is Pellet [10], we decided to use it in 
this research.  
III    METHODOLOGY FOR QUERYING AND SEMANTIC 
PROCESSING  
In order to solve the queries submitted, a four stages 
methodology is defined: a) query contextualization, b) 
displayed results on AR, c) parsing, semantic and spatio-
temporal 
processing, 
information 
retrieval, 
and 
d) 
visualization on AR interface. In Figure 1, general 
architecture of the system is shown. 
 
 
Figure 1.  General architecture of the system. 
In Figure 1, the labels a) and b) represents the stage of query 
contextualization, it means, the attributes required to build a 
query (e..g, “Who knows Electronics?”). This query is sent 
to stage c) where the query is analized sintactically and 
semantically; elements of query are associated with 
concepts in domains of space and time, in order to infer 
answer(s) to query. These answers, are attributes on time 
(e.g., hour) and location (e.g., a classroom) that will be sent 
to modules in stage b) in order to transform them in 
elements that can be displayed on AR interface, finally the 
stage d) shows the AR interface with the obtained results.  
In the case of semantic processing stage, it involves three 
steps: Ontology design, rules’ definition and reasoner’s 
implementation. They are described in the next section. 
A. Ontology Model Design 
     The ontological model was designed to represent the 
knowledge of researchers, professors and their respective 
field of expertise and workplace. Ontology will be explored 
in order to answer queries. Ontology is built based on 
relationships from custom university academic domain. The 
model was built with the OWL language and using Protegé 
editor 4.3.0 [16]. The semantic consistency was checked 
using Pellet reasoner [15] that was coupled as a plug-in in 
the editor. In Figure 2, the basic hierarchical structure of 
Ontology is shown; it describes the context of spatial 
location of the professors at a university. In Ontology, the 
geographical entity class is the parent concept that defines 
the set of laboratory classes, classrooms, auditoriums, 
offices, buildings, etc. Each class, with its identifier, has 
three aspects: subclass, equivalents and the elements of 
which are disjoint. 
The Ontology was implemented in Spanish; the concepts 
are related to geographical objects (classroom, level, office, 
building) events (exposition, conference) and classification 
of personnel (Academic, administrative, etc). In similar 
way, Ontology was complemented to spatial objects, 
temporal aspects and subjects. Figure 2 shows an Ontology 
fragment  (in Spanish) of geographical objects. 
 
Figure 2.  Spatio-Temporal Ontology. 
The Ontology is explored in order to contextualize queries 
(find a matching concept between query and class or 
87
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-420-6
SEMAPRO 2015 : The Ninth International Conference on Advances in Semantic Processing

instance of Ontology); the Ontology is used to make 
inferences, too.    
B. Semantic Processing 
     The Ontology describes academic knowledge and 
associated spatio-temporal attributes (e.g., specialist in 
mathematics, located in basic sciences office, available 
schedule 13:00 to 17:00). The reasoner Pellet is used to 
extract information that is not explicitly represented by the 
data (some inferences). In Table I, object's properties 
(denoted as Pn where n is the property identifier) are 
categorized for each type of relationship: spatial  (e.g., P1-
withInThe), temporal (P13-ocurredIn) and academic (P5-
knows). For example, “isLocatedIn” (P16) is a spatial 
relationship to link people with their specialty and identify 
their specific positions, i.e., one can infer the following 
knowledge: if the teacher Luis Flores (instance of the class 
“Academic”) 
“isLocatedIn” 
department 
of 
advanced 
technologies (it is an instance of "Office" class) and its 
location says that this office is withInThe academic 
department (then it follows that the teacher Luis isLocatedIn 
the 
entity 
called 
“Academic 
department”). 
Several 
inferences are made in order to solve imprecise queries 
(e.g., looking for physics researcher with works in modern 
physics) in opposite way with a precise query (e.g., looking 
for researcher Pedro). In Table 1, a sample of different 
properties of spatio-temporal Ontology’s classes (from 
Figure 2) is shown.  
TABLE I.  
AXIOMS OF FIGURE 2 
 
Property 
Meaning 
P1 
houses  
Related offices with staff who 
reside there 
P2 
limitShares 
Related Contiguous entities 
P3 
withCharge 
Relates 
to 
administrative 
staff 
position held 
P5 
knows  
Personnel related to their area of 
knowledge (academy) 
P8 
withIn 
Relating 
a 
larger 
entity 
that 
contains 
P16 isLocatedIn 
Reverse Property Shelter_to 
P17 over 
Reverse Property below 
    The properties link entities, and in turn with entities’ 
domain and their values are used as axioms in reasoning and 
detecting inconsistencies. This is useful for scalability of 
Ontology design. The properties defined in the Ontology are 
type transitive, i.e., the reasoner is able to conclude that if an 
object O1 is related to another object O2 by property P1 and 
this in turn is related by the same property with O3 object, 
then individuals O3 and O1 share the property P1. 
    The domain of P16 isLocatedIn relationship is the staff of 
the institution, its range are different entities (offices, 
laboratories and staff rooms); where a teacher can be 
located. Figure 3 shows some of the 162 entities of courses 
offered by the university. The professors were characterized 
by defining their equivalents, the academy and career to 
which they belong. There are 256 people including 
information, such as names, titles and locations, academic 
and administrative staff of the institution (see Figure 3).  
 
Figure 3.  Entities, Relationships and Axioms for Academy Concept. 
    This fragment of Ontology is used to solve queries related 
to personnel search by their specialty; an example of 
modeled knowledge is as follows: Personnel is located in an 
entity, therefore an entity contains elements of Personnel 
class. Personnel (professors or researchers) know some 
element of academy class (e.g., Mathematics) then is of 
academic type. For example: person HHEAIRX0 (Pablo 
Hernandez) knows AcCB (basic sciences academy). The 
element MCTed (differential equations) is of type subject 
(topic) and belongs to Basic sciences academy, hence 
professor Pablo Hernandez knows differential equations. 
C. Querying and Semantic Processing  
    The system uses two types of processing queries: precise 
and imprecise; an example of the former {Q1 = Who knows 
Electronics?} to solve, the Ontology is explored to retrieve 
the name (find a semantic matching) of academy teachers 
belong to electronics subject; as it is to assume that all 
teachers know subjects of the academy they belong to. 
88
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-420-6
SEMAPRO 2015 : The Ninth International Conference on Advances in Semantic Processing

    In the case of the latter type of queries, i.e. working with 
imprecise questions, let us consider the query such as  Q2 = 
Where is the office 122? To answer it, one use DESCRIBE 
relation to retrieve or infer facts about the concept "office 
122" for example, what class are held here, if it has cubicles 
teachers, how spatial concepts share limit, on which floor 
and in which the building it is located, etc. 
    The overall set of steps to process queries is: 1) SPARQL 
[17] translation, 2) detection of the object of interest, 3) 
identification of keywords exploring the Ontology using 
words of query, which detects the interrogative adverb and 
verb, and 4) related to the query retrieves information from 
the Ontology. For example, the query Q3: Who can help me 
with an issue in Electronics? is translated into SPARQL 
query format as follows: 
PREFIX bibo: 
http://www.semanticweb.org/itz/ontologies/2014/7/BIBO_v1# 
SELECT ?personnelName ?AcademyName 
WHERE {?subject bibo:withName?subjectName 
FILTER (str(?nameSubject) = “Electronics”) 
{?subject bibo;belongsTo 
?Academy.?academy bibo:withName?AcademyName. 
?Personnel bibo:KnowsAbout?academy. 
?Personnel bibo:withName? PersonnelName} 
    The query Q3, retrieves teachers from academy where 
Electronics course is taught. The original query should be 
analyzed in order to identify the direct object (interest 
object), and then the terms of original query are compared 
with the elements of Ontology (using similarity). This way, 
we determined if the object of interest is referring to a 
subject, academy, and event or is an unknown concept for 
the Ontology. To determine how similar a text string is to 
another, the elements of the Ontology and the phrase are 
mapped to a vector space that allows the use of the dot 
product as a measure of similarity: In the first instance, it is 
required to extract the "universe" of words contained in the 
collection of items of Ontology and determine the frequency 
in which they appear.  
Below is built a N×M matrix, where N is the number of 
elements and M to the number of terms (words without 
repeating) in the "universe". The vector representing the 
user's phrase, is constructed and the dot product between it 
and the rows of the matrix is calculated. Accordingly, the 
pair of vectors whose dot product is the largest will be the 
most similar to the phrase. Therefore; the system identifies 
it as the object of interest the user refers to. In the following 
section the results are discussed. 
IV. 
TEST AND RESULTS 
Testing was done using several queries; the first test was 
to evaluate the answer of the system when a query asks for 
data not stored in the Ontology. Hence, in order to answer, 
the processing should use similarity, and, then, the results 
obtained are shown. 
 
Let us consider the query Q4={who can help me with issues 
of vector calculus} 
 
2015/02/9 21:04 Monday 
Matches: 2 
multivariable calculus ... 0.6544891121378675 
Answer: There are two teachers who may like 
help: 
Francisco Perez 
Mario Contreras 
RA: false 
Time: 168 milliseconds 
 
For example, in the query Q4, user asked for vector 
calculus (but no data or concept of calculus vector is present 
into the Ontology). The system answers by relating Vector 
calculus with an entity of class named "multivariate 
calculus", although it has similarity just above of 60%, but 
not best candidates were found. This relation was made 
because both subjects-matter (vector and multivariable 
calculus) are in the area of Basic Sciences according to the 
hierarchy of Ontology. The next test is a query spatio-
temporal, when a user requires to know when and where a 
subject matter is taught.  
 
Let us consider the query Q5 ={Schedule of network 
security subject?}  
    
2015/02/11 11:56  
Matches: 6 
network security ... 1.0 
Task: I'm looking for the schedule network security 
Answer: network security in 3TM3 group: 
* Monday at 10:00 Telematics Laboratory II 
* Tuesday at 10:00 in classroom 122 
network security in 3TV3 group: 
* Monday at 16:00 in classroom 102 
* Wednesday at 16:00 laboratory telematics II 
RA: false 
    Time: 181 milliseconds 
      
In query Q5, a query element has a matching of 100% 
with 
the 
event 
of 
Ontology: 
“network 
security”. 
Nevertheless, when is an event occurred in two groups and 
the query not specified which one is required, then the 
reasoner retrieves both schedules. 
The next test is based on spatial queries using current 
user’s location and spatial relations (next, in front of, etc). 
These queries ask for information such as:  
 
Q6={available professors in building “A”?},  
 
Q7={researchers located next to telematics academy?},  
 
Q8={events occurred around to my current position?}. 
 
89
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-420-6
SEMAPRO 2015 : The Ninth International Conference on Advances in Semantic Processing

In Figure 4, the user’s position is represented using a 
user icon. The points marked by the user symbol and the 
orientation indicated by the sight lines from A to H. The 
GPS have a 5 meters error (in optimal conditions) that 
facilitates the deployment of virtual objects on screen 
(augmented reality) with equivalent margin of error. 
 
 
Figure 4.  Several User’s Position and Sight Line Directions. 
    The events are retrieved under sight line A, using user’s 
position from GPS, and the neighborhood using spatial 
relations. The sight line is processed based on the actual 
position. Then, we calculated that line cross building “A” is 
located to 11.252 meters from user. The result obtained is as 
follows: 
 
Data received: (19.511537 -99.126536) at 0 ° 
Fri 2015/02/20 10:45:00 
Sight Line: LINESTRING (-99.126536 19.511537, -99.126431 
19.517536) 
Against: Building A 
Central Crossing: POINT (-99.1265322955 19.5117492255) to 
11,252 meters 
Estimated Height: 6.97 meters 
Information: * Classroom 423 
Class: Distributed Systems 
Group: 2TM5 
Title: José  Rodriguez  
Floor: P2 
Address: Left 
Distance: 1555 meters 
* Laboratory of Complex Systems 
Entity no events registered 
Floor: P1 
Address: Left 
Distance: 1828 meters 
* Nanophotonics and laboratory techniques 
Entity no events registered 
Floor: PB 
Address: Left 
Distance: 1975 meters 
* Classroom 422 
entity unoccupied 
Floor: P2 
Address: Right 
Distance: 7786 meters 
* Classroom 412 
Entity no events registered 
Floor: P1 
Address: Right 
Distance: 7366 meters 
Time: 4089 milliseconds 
    These results are displayed using AR; to achieve that, the 
building height is computed to determine the vertical 
position of virtual objects to be displayed on screen 
(according to corresponding level of building).  
Each virtual object can be touched and relevant 
information of this object or event will be displayed. Hence, 
the following information is retrieved:  event, level, address 
and distance regarding to cross point between view line and 
polygon. Figure 5 shows this result. 
 
 
Figure 5.  Augmented Reality Navigation for Query Types Q6, Q7 and Q8. 
    In Figure 5, the app notifies the user that s/he is in front 
of building A. Then, the interface allows to  navigate using 
AR, when the mobile device points to a different direction, 
less or equal to 30° degrees regarding to original line of 
sight (located in top of Figure 4).  While, in Figure 6, 
information is retrieved, when virtual objects are touched. 
This data corresponds to events belong to time interval 
(defined by start and finish hour) and the temporal context. 
 
 
Figure 6.  Retrieved Information in AR Interface Q8. 
In this case, the AR tests were conducted in portrait 
mode (vertical position); to display the position of the 
virtual objects the building height is dividing by three 
(floors of building). Converting meters to pixels is essential 
90
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-420-6
SEMAPRO 2015 : The Ninth International Conference on Advances in Semantic Processing

in order for the building to be displayed on screen from 
foundation to roof, in order to display all the elements on 
screen (see Figure 7). 
 
Figure 7.  Information retrieval displayed on the AR interface. 
    In Figure 7, we note that the response to the sight line B 
presents a significant error (the square icons are displayed 
out of building). This is because although the system does 
not expect the user to visualize the entities full front, the 
algorithm that calculates the position of virtual objects does 
not consider the perspective introduced by lateral views. To 
remedy this deficiency, it was decided to deploy graphic 
elements only on the sub entities that lie within the range 
formed by an angle of 30° right or left regarding to user’s 
line of sight.   
V. CONCLUSION AND FUTURE WORK 
The use of semantic processing to find a knowledge 
profile represents a useful field for tasks of semantic 
similarity. The resolution of queries over Ontology 
exploration about spatial and temporal attributes can solve 
complex queries. 
 
Displaying results in augmented scenarios provide a 
practical way to locate people. The combination of 
ontologies and AR for mobile phones represents a field of 
opportunity for various tasks and scopes. GPS and compass 
sensor require developing algorithms in order to compensate 
the error margin or use external devices with great precision, 
in order to offer a precise augmented navigation. Future 
work considers including speech recognition and AR using 
sensors instead of pattern recognition. 
ACKNOWLEDGMENT 
The authors of this paper wish to thank the Mobile 
Computing 
Laboratory-UPIITA, 
Instituto 
Politécnico 
Nacional in Mexico, IPN-UPIITA, IPN-ESCOM, COFAA-
IPN, IPN-SIP and CONACYT. 
REFERENCES 
[1] 
J. Carmigniani, B. Furht, M. Anisetti, P. Ceravolo, E. Damiani, and 
M. 
Ivkovic, 
Augmented 
reality 
technologies, 
systems 
and 
applications. Multimedia Tools and Applications, 2011, vol. 51, no. 1, 
pp. 341-377. 
[2] 
H. M. Park, S.H. Lee, and J.S. Choi, 2008. Wearable augmented 
reality system using gaze interaction. In Proceedings of the 7th 
IEEE/ACM International Symposium on Mixed and Augmented 
Reality (ISMAR '08). IEEE Computer Society, Washington, DC, 
USA, 
175-176. 
DOI=10.1109/ISMAR.2008.4637353 
http://dx.doi.org/10.1109/ISMAR.2008.4637353 
[3] 
T.N Arvanitis., A. Petrou, Knight J.F., Savas S., Sotiriou S., M. 
Gargalakos, E. Gialouri, Human factors and qualitative pedagogical 
evaluation of a mobile augmented reality system for science 
education used by learners with physical disabilities. 2009, Personal 
and Ubiquitous Computing 13(3):243–250.  
[4] 
F. Zhou, H. B. L. Duh,  and M. Billinghurst, Trends in augmented 
reality tracking, interaction and display: A review of ten years of 
ISMAR. In Proceedings of the 7th IEEE/ACM International 
Symposium on Mixed and Augmented Reality. 2008, pp. 193-202. 
IEEE Computer Society.  
[5] 
B. Smith, and D. Mark, Geographical categories: an ontological 
investigation. International Journal of Geographical Information 
Science, 2001, 15 (7), 591–612.  
[6] 
M. Sorrows and S. Hirtle, The nature of landmarks for real and 
electronic spaces. Lecture Notes in Computer Science, 1999, 1661, 
37–50. 
[7] 
B. Tversky and K. Hemenway, Objects, parts, and categories. Journal 
of Experimental Psychology: General, 1984, 113 (2), 169–193. 
[8] 
B. Huang, C. Claramunt, Spatiotemporal data model and query 
language for tracking land use change. 2005, Transportation Research 
Record, 107-113. 
[9] 
Y. Zhang, Y. Gao, L. Xue, S. Shen, K. Chen, A common sense 
geographic knowledge base for GIR, Science in China Series E: 
Technological Sciences, 2008, 51 (1) , pp. 26–37. 
[10] E. Sirin, B. Parsia, B. C. Grau, A. Kalyanpur, & Y. Katz, Pellet: A 
practical owl-dl reasoner. Web Semantics: science, services and 
agents on the World Wide Web, 2007, 5(2), 51-53. 
[11] C. Kuoa, T. Jengb and I. Yangc, An invisible head marker tracking 
system for indoor mobile augmented reality. Automation in 
Construction, an International Research Journal. Volume 33, August 
2013, Pages 104–115. 
[12] T. L. Chou and L. J. ChanLin, Augmented reality smartphone 
environment orientation application: a case study of the Fu-Jen 
University mobile campus touring system. Procedia-Social and 
Behavioral Sciences. 2012, 46, 410-416. 
[13] H. Tashakkori, A. Rajabifard, M. Kalantar, A new 3D indoor/outdoor 
spatial model for indoor emergency response facilitation. Building 
and Environment. 2015, 89, 170-182. 
[14] P.Daponte, L. De Vito, F. Picariello and M. Riccio, State of the art 
and 
future 
developments 
of 
measurement 
applications 
on 
smartphones. 
Journal 
of 
the 
International 
Measurement 
Confederation, volume 46, Issue 9, November 2013, Pages 3291–
3307. 
[15] Pellet Reasoner, http://pellet.owldl.com/, [retrieved: February, 2015]. 
[16] Protégé Editor, http://protege.stanford.edu/, [retrieved: February, 
2015]. 
[17] SPARQL, 
http://www.w3.org/TR/rdf-sparql-query/, 
[retrieved: 
February, 2015]. 
 
 
 
91
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-420-6
SEMAPRO 2015 : The Ninth International Conference on Advances in Semantic Processing

