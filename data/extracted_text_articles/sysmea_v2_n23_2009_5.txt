178
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
Improving the Quality of Control of Periodic Tasks Scheduled by FP with an
Asynchronous Approach
P. Meumeu Yomsi, L. George, Y. Sorel, D. de Rauglaudre
AOSTE Project-team
INRIA Paris-Rocquencourt
Le Chesnay, France
{patrick.meumeu, laurent.george, yves.sorel, daniel.de rauglaudre}@inria.fr
Abstract
The aim of this paper is to address the problem
of correctly dimensioning real-time embedded systems
scheduled with Fixed Priority (FP) scheduling. It is well
known that computers which control systems are greatly
affected by delays and jitter occurring in the control loop.
In the literature, a deadline reduction approach has been
considered as one solution to reducing the jitter affecting a
task, thereby obtaining better loop stability in the control
loop. Here, in order to improve the sensitivity of the
deadlines, we propose another solution for reducing the
worst case response time of the tasks, hence reducing the
jitter, when all the tasks are scheduled with the Deadline
Monotonic Algorithm. This is performed for a speciﬁc
asynchronous scenario for harmonic periodic tasks. We
compare the results to those for the synchronous scenario
in terms of minimum deadline reduction factor preserving
the schedulability of tasks set in both cases.
Keywords: Real-time systems, Fixed-priority scheduling
algorithms, Sensitivity analysis, Robust control.
1. Introduction
In this paper we consider the problem of correctly dimen-
sioning real-time embedded systems ([1], [2], [3], [4]). The
correct dimensioning of a real-time system strongly depends
on the determination of the tasks’ Worst-Case Execution
Times (WCETs). Based on the WCETs, Feasibility Condi-
tions (FCs) ([5], [6], [7]) can be established to ensure that the
timeliness constraints of all the tasks are always met when
tasks are scheduled by a ﬁxed or a dynamic priority driven
scheduling algorithm. We consider an application composed
of a periodic task set Γn = {τ1, · · · , τn} of n periodic tasks,
scheduled with Fixed Priority (FP) preemptive scheduling.
The classical deﬁnition of a periodic task τi, is:
• Ci: the Worst Case Execution Time (WCET) of τi.
• Ti: the period of τi.
• Di: the relative deadline of τi (a task requested at time
t must be terminated by its absolute deadline t + Di),
where Di ≤ Ti.
A recent research area called sensitivity analysis aims at
providing interesting information on the validity of feasi-
bility conditions by considering possible deviations of task
WCETs ([2]), task periods ([2]), or task deadlines ([3]).
This makes it possible, for example, to ﬁnd a feasible task
set, if the current one is not feasible, by modifying the
task parameters or determining the impact of a change in
architecture on the feasibility of a task set. A task set is
declared feasible if for any task in the synchronous scenario,
its worst case response time is less than or equal to its
deadline. We are interested in the sensitivity of deadlines.
Computer controlling systems are very much affected by
delays and jitter occurring in the control loop. A deadline
reduction has been considered by ([8]) as one solution to
reducing the jitter affecting a task and therefore obtaining
better loop stability in the control loop. The jitter of a task
depends on the minimum and on the worst case response
times. Reducing the deadline of a task can be a way to
reduce the worst case response time of a task and thus can
reduce the jitter of the task. However, this deadline reduction
should be performed in such a way that it does not cause any
task to fail at run-time. This supposes a scheduling driven
by deadlines.
This paper proposes a solution to reduce as much as possible
the worst case response time of each task when tasks
are scheduled with ﬁxed priorities, according to Deadline
Monotonic Algorithm, by using a speciﬁc asynchronous
ﬁrst release times scenario. We show the beneﬁts of our
asynchronous scenario by comparing the minimum deadline
reduction factor applied preserving the schedulability of
the tasks in the synchronous and in the our asynchronous
scenario.
With Deadline Monotonic Algorithm, tasks are scheduled
according to their relative deadlines. The smaller the relative
deadline, the higher the priority. Starting from a schedulable
task set, we want to characterize the minimum deadline
reduction factor 0 < α ≤ 1 such that any task τi, i =
1, . . . , n having a deadline Di = α×Ti is schedulable. α is
such that any smaller reduction factor would lead to a non
schedulable task set. We compare the value of α obtained in

179
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
the worst case synchronous scenario (all the tasks are ﬁrst
released at the same time) to that obtained with a particular
asynchronous scenario that we propose, and which has some
interesting properties. We show that the minimum reduction
factor obtained in our asynchronous scenario is always less
than or equal to the minimum reduction factor obtained in
the synchronous scenario.
Reducing the deadline of a task makes it possible to reduce
the jitter resulting from the execution of a task. In this paper
we show that the maximum deadline reduction is minimized
for the synchronous scenario where all the tasks are ﬁrst
released at the same time.
We then propose a particular asynchronous ﬁrst release times
scenario that allows us to obtain better feasibility conditions
and a better deadline reduction factor than the one obtained
with the synchronous scenario, thus reducing the jitter of the
tasks for a better control.
The feasibility problem of asynchronous task sets is known
to be more complex than for synchronous task sets. We
introduce a new formalism to compute the worst case
response time of a task for asynchronous task sets. We apply
this approach to the case where the periods of the tasks are
harmonic. We then show that in this case, the worst case
response time is always obtained for the second instance of a
task, which represents a signiﬁcant reduction in complexity.
The rest of the paper is organized as follows. In section
2, we give a state of the art regarding sensitivity analysis
of deadlines considering dynamic and ﬁxed priority driven
schedulings. We then focus on asynchronous task sets and
recall existing feasibility conditions. In section 3, we in-
troduce the concepts and notations and establish important
properties for the particular asynchronous scenario that we
have chosen. We consider harmonic periods. We show that,
using this particular scenario, the worst case response time
of every task is obtained for its second instance1. In section
4, we introduce a new scheduling representation which is
more compact than the classical linear representation / Gantt
Chart for a schedule. In section 5, we introduce the concept
of Mesoid which is used to compute the worst case response
time of an asynchronous task set. In section 6, we give an
algorithm for the computation of the worst case response
time of any task in our asynchronous scenario, then we show
how to compute the minimum deadline reduction factor. An
example is given in order to compare the deadline reduction
factor obtained with our asynchronous scenario to that in
the synchronous scenario. We provide experimental results
in section 7 based on extensive simulations comparing the
deadline reduction factor for several load conﬁgurations in
both the synchronous case and in our asynchronous scenario.
Finally, we conclude in section 8.
1. Throughout the paper all subscripts refer to tasks whereas all super-
scripts refer to instances.
2. State of the art
Sensitivity analysis for deadlines has been considered for
Earliest Deadline First (EDF) scheduling algorithm by ([3])
showing how to compute the minimum feasible deadlines
such that the deadline of any task τi equals αDi, where
α is reduction factor 0 < α ≤ 1. In ([8]), the space of
feasible deadlines (D-space), a space of n dimensions has
been considered. Any task set having deadlines in the D-
space is considered to be schedulable. To the knowledge of
the authors, no work has been done on the sensitivity of
deadlines for ﬁxed priority scheduling algorithms.
Few results have been proposed to deal with the deadline
assignment problem. As far as the authors are aware, no
results are available for Fixed Priority (FP) scheduling.
Baruah & al., in [9] propose modifying the deadlines of
a task set to minimize the output, seen as a secondary
criteria. In Cervin & al. ([10]), the deadlines are modiﬁed to
guarantee close-loop stability of a real-time control system.
Marinca & al. ([11]) focus on the deadline assignment
problem in the distributed case for multimedia ﬂows. The
deadline assignment problem is formalized in terms of a
linear programming problem. The scheduling considered on
every node is non-preemptive EDF or FIFO, with a jitter
cancellation applied on every node. A performance evalua-
tion of several deadline assignment schemes is proposed.
A recent paper proposed by Balvastre & al. ([3]) proposes
an optimal deadline assignment for periodic tasks scheduled
with preemptive EDF in the case of deadlines less than or
equal to periods. The goal is to ﬁnd the minimum deadline
reduction factor preserving all the deadlines of the tasks.
They ﬁrst focus on the case of a single task deadline
reduction and show how to compute Dmin
i
, the minimum
deadline of task τi such that any deadline smaller than Dmin
i
for task τi will lead to a non-feasible task set.
They also show in [3] that when considering the reduction of
a single task τi, Dmin
i
is the worst case response time of task
τi for EDF scheduling. The maximum deadline reduction
factor αi for task τi is then: αi = 1 − Dmin
i
Di .
In the case of a deadline reduction applied to n tasks, the
goal is to minimize all tasks’ deadlines assuming the same
reduction factor for all the tasks (with no preference re-
garding which task requires the greatest deadline reduction).
Balbastre & al. in [3] show how to compute the maximum
deadline reduction factor α applied to all the deadlines
using an iterative algorithm. The principle is to compute the
minimum slack t−h(t) for any time t ∈ [0, L) to determine
the deadline reduction factor applied to all the tasks, where
h(t) = Pn
i=1 max(0, 1 + ⌊ t−Di
Ti ⌋)Ci and L is the length of
the ﬁrst synchronous busy period, solution of the equation
t =
n
X
i=1
 t
Ti

Ci.

180
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
τ = {τ1, . . . , τn} : task set;
L ← compute-L(τ) : integer; α ← 1 : real
slack = mint∈[0,L)(t − h(t)) : real;
While (slack ̸= 0) do
α = mini=1...n(1 − slack
Di );
For (i = 1;i < n;i + +) do
Di = αDi;
end For
slack = mint∈[0,L)(t − h(t));
done
Return α;
Algorithm 1: Computation of α for EDF scheduling
For Fixed Priority (FP) scheduling, necessary and sufﬁcient
FCs have been proposed in the case of non-concrete tasks
where the ﬁrst release times of the tasks can be arbitrary.
A classical approach is based on the computation of the
tasks’ worst-case response times ([12], [6]). The worst-case
response time, deﬁned as the worst case time between the
request time of a task and its latest completion time, is
obtained in the worst case synchronous scenario where all
the tasks are ﬁrst released at the same time, and is computed
by successive iterations. This worst case response time
provides a bound on the response time valid for any other
task ﬁrst release times. It can be shown that considering only
non-concrete tasks can lead to a pessimistic dimensioning
[13].
The complexity of this approach depends on the worst
case response time computation complexity. In the case of
deadlines less than or equal to periods for all tasks, the
worst-case response time Ri of a task τi is obtained in the
synchronous scenario for the ﬁrst release of τi at time 0
and is the solution of the equation ([12]) Ri = Wi(Ri),
where Wi(t) = Ci + P
τj∈hp(i)
l
t
Tj
m
Ci and hp(i) denotes
the set of tasks with a priority higher than or equal to that
of τi except τi itself. The value of Ri is computed by
successive iterations and the number of iterations is bounded
by 1+P
τj∈hp(i)
j
Di
Tj
k
. A necessary and sufﬁcient feasibility
condition for a task set is: ∃t ∈ S, such that Wi(t)/t ≤ 1,
where S = ∪τj∈hp(i){kTj, k ∈ N}∩[0, Di]. For any task τi,
the checking instants correspond to the arrival times of the
tasks with a higher priority than τi within the interval [0, Di].
This feasibility has been improved by ([14]), where the
authors show how to reduce the time instants of S. For any
task τi, they show how to signiﬁcantly reduce the number
of checking instants during the interval [0, Di] to at most
2i−1 times rather than 1+P
τj∈hp(i)
j
Di
Tj
k
. When deadlines
and periods are independent, ([6]) shows that the worst-
case response times of a sporadic task τi are not necessarily
obtained for the ﬁrst activation request of τi at time 0. The
number of activations to consider is 1 +
j
Li
Ti
k
, where Li
is the length of the worst-case level-τi busy period deﬁned
in ([15]) as the longest period of processor activity running
tasks of priority higher than or equal to τi in the synchronous
scenario. It can be shown that Li = P
τj∈hp(i)∪τi
l
Li
Tj
m
Cj.
From its deﬁnition, Li is bounded by:
Min











X
τj∈hp(i)∪τi
Cj
1 −
X
τj∈hp(i)∪τi
Cj
Tj
,
X
τj∈hp(i)∪τi
Cj
Tj
· P











([7]).
where P
=
LCM(T1, . . . , Tn) is the least common
multiple (LCM) of the periods of all tasks and it leads to
a pseudo-polynomial time complexity for the feasibility
conditions.
This is an interesting approach as it provides a pseudo-
polynomial time complexity but it may lead to a pessimistic
dimensioning as the synchronous scenario might not be
likely to occur.
In order to improve the schedulability of the systems, offset
strategies on the ﬁrst release times of the tasks have been
considered. A system where offsets are imposed is called
an asynchronous system. ([13]) shows signiﬁcant feasibility
improvements considering offsets. Simulations show that
the number of feasible schedulable systems with offsets
(while unfeasible in the synchronous case) increases with the
number of tasks for a processor load of 0.8 and ranges from
40.5% to 97% for different offset assignment strategies. This
percentage strongly decreases when the load is high (tends
to 1).
With asynchronous tasks, ([16]) shows that for a given offset
assignment, the schedulability of the tasks must be checked
in the interval [0, maxi=1...n(Oi)+2P) where P is the least
common multiple of the tasks and Oi is the offset of task τi,
leading to an exponential time complexity. To provide less
pessimistic FCs, it is furthermore mandatory to prove that
the offsets will not result later in a synchronous scenario.
This problem is referred to as the K-simultaneous congru-
ence problem in the state of the art ([16]). This feasibility
result has been signiﬁcantly improved by ([17]) showing that
the interval to check the feasibility of a periodic task set with
offsets can be reduced to [0, maxi=1...n(Oi) + P).
Furthermore, ([16]) proves the non optimality of Deadline
Monotonic scheduling algorithm for asynchronous systems
when task deadlines are less than or equal to periods. An
optimal priority assignment can be obtained in O(n2) using
the Audsley procedure ([18]).
A particular case denoted offset free systems corresponds
to the case where offsets can be chosen arbitrarily. An
optimal offset assignment is given in ([19]). An offset
assignment is optimal if it can ﬁnd a schedulable offset
whenever a feasible assignment exists. The complexity of

181
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
the offset assignment algorithm is exponential and is in
O((max2≤j≤nTj)n−1). The offset of task τ1 is set to 0.
Different offset strategies / heuristics have been considered
in the literature. Among them, we can cite the dissimilar
offset assignment proposed by ([19]) that consists in shifting
(computing a distance between the offsets) the offset of
the tasks to be as far as possible from the synchronous
scenario. The algorithm sorts the couple of tasks (τi, τj)
by decreasing values of gcd{Ti, Tj} such that the distance
belongs to [0, gcd{Ti, Tj}). The dissimilar offset assignment
signiﬁcantly reduces the number of offsets to consider, lead-
ing to a complexity in O(n2.(log(maxi∈[1,n]Ti)+log(n2))).
Other offset assignment strategies have been considered
by ([13]) using the Audsley procedure to determine the
subset of tasks of τ that can be feasibly scheduled in the
synchronous scenario (setting their offset to 0). The offsets
are only computed for the subset of tasks that are unfeasible
with the Audsley procedure in the synchronous case. The
authors consider different criteria to assign the offsets, based
on the criteria used to sort the couple of tasks (τi, τj).
The complexity is the same as that of the dissimilar offset
assignment.
In this paper we consider a particular asynchronous
harmonic concrete task set where ∀2 ≤ i ≤ n, Ti−1 | Ti
(i.e. there exists k ∈ Z such that Ti = kTi−1) with
particular offsets. In the case of non-concrete harmonic
tasks, when tasks are scheduled with Rate Monotonic
Algorithm (the shorter the period, the higher the priority)
and in the case where deadlines are equal to periods, a
necessary and sufﬁcient condition for the feasibility of such
a system is given by U = P
i=1...n
Ci
Ti ≤ 1 (see [20]). This
potentially proves the beneﬁts of considering harmonic
tasks in order to get better feasibility conditions. This
property does not hold when deadlines can be shorter than
periods. In this case we show how to determine in O(n)
the offset of the tasks to obtain a pseudo-polynomial time
feasibility condition instead of an exponential one. In the
case of asynchronous tasks, the worst case response time
cannot be computed with a recursive equation as for the
synchronous tasks. This is due to the fact that with offsets,
there is not necessarily a continuous busy period from time
0 to the release time of a task. In this paper we investigate
a new approach to compute the worst case response time
of a task based on the Mesoid approach. This approach
was ﬁrst introduced by ([4]) in the context of real-time
scheduling with preemption cost. This approach does not
require a continuous busy period to compute the worst case
response times of the tasks. We propose a particular offset
assignment, such that the worst case response time of any
task is obtained for its second request time, providing an
exponential time improvement in the complexity of the FCs.
More recently, for control systems, [21] has proposed to
include the control delay resulting from the response time of
a task as a cost function for the controllers. They show how
to solve the optimal period assignment problem analytically.
3. Properties of the asynchronous harmonic
task set
3.1. Concepts and notations
We recall classical results in the uniprocessor context for
real-time scheduling.
• Time is assumed to be discrete (task arrivals occur
and task executions begin and terminate at clock ticks;
the parameters used are expressed as multiples of
the clock tick); in [22], it is shown that there is no
loss of generality with respect to feasibility results by
restricting the schedules to be discrete, once the task
parameters are assumed to be integers (multiples of the
clock tick) i.e. a discrete schedule exists, if and only if
a continuous schedule exists.
• A task set is said to be valid with a given scheduling
policy if and only if no task occurrence ever misses its
absolute deadline with this scheduling policy.
• U
=
Pn
i=1
Ci
Ti
is commonly called the processor
utilization factor associated to the task set Γn, i.e., the
fraction of processor time spent in the execution of the
task set ([23]). If U > 1, then no scheduling algorithm
can meet the tasks’ deadlines.
• The synchronous scenario corresponds to the scenario
where all the tasks are released at the same time (at
time 0).
The model depicted in ﬁgure 1 is Liu & Layland’s
pioneering model [23] for systems executed on a single
processor.
Figure 1. Model
Throughout the paper, we assume that all timing characteris-
tics are non-negative integers, i.e. they are multiples of some
elementary time interval (for example the “CPU tick”, the
smallest indivisible CPU time unit):
We introduce several notations for a periodic task τi =
(Ci, Di, Ti) used to compute the worst case response time
of a task:
• τ k
i : The kth instance of τi

182
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
• r1
i : Release time of the ﬁrst instance of τi
• rk
i = r1
i + (k − 1)Ti: Release time of τ k
i
• Rk
i : Response time of τ k
i released at time rk
i
• Ri: Worst-case response time of τi
3.2. The speciﬁc asynchronous scenario
Here we give some interesting properties which are satis-
ﬁed by the speciﬁc asynchronous scenario we propose and
which lead to the conclusion that the worst case response
time of a task in our asynchronous scenario is obtained for
any task for its second release.
In this section we assume that the relative deadline for
each task equals its period, i.e. Di = Ti. This assumption
will be weakened in section 6.
We ﬁrst show in lemma 1 that with harmonic asyn-
chronous tasks, two instances belonging to any two tasks
can never be released at the same time if their release times
are not equal modulo their periods.
Lemma 1: Let Γn = {τ1, τ2, · · · , τn} be a system of n
independent harmonic (i.e. Ti | Ti+1, ∀i ∈ {1, · · · , n − 1})
preemptive tasks ordered by decreasing priorities (Ti ≤
Ti+1, ∀i ∈ {1, · · · , n − 1}).
If there exist two tasks τi, τj ∈ Γn, (i < j) such that
r1
j ̸= r1
i mod[Ti] 2, then ̸ ∃k, l ≥ 0 such that rk
j = rl
i.
Proof: (by contradiction)
Let us assume that there exist two tasks τi, τj ∈ Γn, (i <
j) such that r1
j ̸= r1
i mod[Ti], and ∃k, l ≥ 0 such that rk
j =
rl
i.
rk
j = rl
i
⇐
r1
j + (k − 1)Tj = r1
i + (l − 1)Ti
⇐
r1
j = r1
i + (l − 1)Ti − (k − 1)Tj
⇐
r1
j = r1
i mod[Ti] as Ti | Tj.
Contradicts the hypothesis and thus, ends the proof.
We now show in theorem 1 that from the point of view
of any task in the system, the schedule repeats identically
from the second instance.
Theorem 1: (inspired by theorem 2.48 in [24])
Let Γn
= {τ1, τ2, · · · , τn} be a system of n asyn-
chronous independent periodic preemptive tasks ordered by
decreasing priorities (Ti ≤ Ti+1, ∀i ∈ {1, · · · , n − 1}). Let
r1
1, r1
2, · · · , r1
n be respectively the release time of their ﬁrst
instances. Let (si)1≤i≤n be the sequence inductively deﬁned
by



s1 = r1
1
si = r1
i +
(si−1 − r1
i )+
Ti

· Ti
∀i ∈ {2, · · · , n}
(1)
Then,
if Γn
is schedulable up to sn + Hn, with Hn
=
2. Given a, b, c ∈ Z : a = b mod[c] means that there exists d ∈ Z such
that a = b + c ˙d.
LCM(T1, T2, · · · , Tn) and x+ = max{x, 0}, then Γn is
schedulable and periodic from sn with period Hn.
Proof: (By induction on the number of tasks n)
The property is straightforward for the simple case where
n = 1: indeed, the schedule for task τ1 is periodic of
period T1 from its ﬁrst release (s1 = r1
1) since C1 ≤ T1,
otherwise the deadline of the ﬁrst instance is missed. Let
us now assume that the property is true up to n = i − 1
and Γi = {τ1, τ2, · · · , τi} is schedulable up to si + Hi,
with Hi = LCM(T1, T2, · · · , Ti). Notice that si is the
ﬁrst release time of task τi after (or at) si−1. We have
si + Hi ≥ si−1 + Hi−1 and by induction hypothesis,
the subset Γi−1 = {τ1, τ2, · · · , τi−1} is schedulable and
periodic from si−1 of period Hi−1. As tasks are ordered
by priority, the instances of the ﬁrst ones are not changed
by the requests of task τi and the schedule repeats at time
si + LCM(Hi−1, Ti) = si + Hi. Consequently, Γi =
{τ1, τ2, · · · , τi} is schedulable and its schedule repeats from
si with period Hi.
We now characterize the asynchronous scenario we con-
sider in this paper in corollary 1. This leads to providing
a simple method for computing the worst response time of
each task in section 5 by using corollary 2, and then a pseudo
polynomial FC detailed in section 6.1.
Corollary 1: From the point of view of any task τi of
a schedulable system Γn = {τ1, τ2, · · · , τn} ordered by
decreasing priorities (Ti ≤ Ti+1, ∀i ∈ {1, · · · , n − 1}) such
that Ti | Ti+1 and r1
i+1 = r1
i −Ci+1, the schedule is periodic
from the second instance with period Hi = Ti.
Proof: (By induction on the index i of the task)
Let us consider a task τi of a schedulable system Γn =
{τ1, τ2, · · · , τn}, we assume that Ti | Ti+1 and r1
i+1 =
r1
i − Ci+1,
∀i ≥ 1. Thanks to the previous theorem, it
is sufﬁcient to prove that si − r1
i = Ti,
∀i ≥ 2. This is
done by induction on i.
The property is straightforward for the simple case where
i = 2: indeed, as C2 ≤ T2 and H2 = LCM(T1, T2) = T2,
the schedule for task τ2 is periodic of period T2 from its
second release since s2 = r1
2 +
(s1 − r1
2)+
T2

· T2 = r1
2 +
C2
T2

·T2 = r1
2 +T2 is the ﬁrst release time of task τ2 after
(or at) s1 = r1
1. Let us now assume that the property is true
up to index i − 1 and Γi = {τ1, τ2, · · · , τi} is schedulable.
Thanks to the previous theorem, we have
si = r1
i +
(si−1 − r1
i )+
Ti

·Ti = r1
i +
(Ti−1 + r1
i−1 − r1
i )+
Ti

·Ti
by induction hypothesis.
Thus, si = r1
i +
(Ti−1 + Ci)+
Ti

· Ti since r1
i−1 = r1
i + Ci.
Now, as 0 < Ti−1 + Ci < Ti due to the scenario imposed

183
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
to the ﬁrst instance of each task and the fact that Ti−1 | Ti,
then we obtain si = r1
i + Ti.
Corollary 2: The worst response time Ri of each task τi
is obtained in the second instance and is equal to that in all
instances greater than 2.
Proof:
Immediately follows from corollary 1 and the fact that
R1
i = Ci by construction, Rk
i ≥ Ci
∀k ≥ 1, and we
consider harmonic tasks.
4. A new scheduling representation
A direct consequence of corollary 2 leads us to the
conclusion that in the case of a valid schedule, i.e. when all
deadlines are met for all tasks, the schedule obtained at level
i (the resulting schedule of the i tasks with the highest prior-
ity) is periodic with the period Ti = LCM{Tj|j = 1, · · · , i}
from the second instance. As such, from the point of view
of each task, the interval preceeding the second instance
necessarily contains the transient phase, corresponding to
the initial part of the schedule at level i, and the interval
starting at date r2
i with the length Ti is isomorphic to the
permanent phase of the schedule at level i, corresponding
to the periodic part of the schedule. The transient phase is
always ﬁnite due to the existence of the permanent phase
and the permanent phase repeats indeﬁnitely.
For a system of n periodic harmonic tasks for which there
exists a valid schedule, since the permanent phase repeats
indeﬁnitely, we introduce a new scheduling representation.
This scheduling representation is obtained by graphically us-
ing an oriented circular disk called Dameid with a reference
time instant t0 = 0 corresponding to the time reference in the
classical linear representation or Gantt Chart. The positive
direction in Dameid is the trigonometrical one, i.e. opposite
to that of the hands of a watch. The circumference of Dameid
at level n corresponds to Hn = LCM{Ti | i = 1, · · · , n}
where Ti means the period of the ith task and n denotes
the number of tasks in the system. In Dameid, the different
release times for each task are unambiguously determined
by the value of their ﬁrst release time relatively to that of
other tasks with respect to the reference date t0 = 0, and
the ratio Hn
Ti
for task τi. As an example, ﬁgure 2 illustrates
the release times of each task for a system consisting of 4
periodic harmonic tasks. In this ﬁgure, the ﬁrst release time
of task t1 is −2, while that of task t3 is 0.
Figure 3 clariﬁes our idea for the construction of Dameid
for a given set of harmonic periodic tasks. This ﬁgure
illustrates, for the same system with 4 tasks (see Figure 2),
the correspondence of the release times of each periodic
task in Dameid relative to the reference date t0 = 0. The
main intuition behind this new representation is to reduce
Figure 2. Release times of each task in the classical
linear representation or Gantt Chart
the interval of analysis for a system harmonic periodic tasks
whatever their ﬁrst release times are.
Figure 3. Release times of each task in Dameid
Now, in addition to the release times of each task, let
us add the WCETs and explain how Dameid can represent
schedules.
During the scheduling process from the highest priority
task to the lowest priority task, some of the available time
units at a given level i, i.e. those which are not executed
after the schedule of the ﬁrst i − 1 highest priority tasks,
are executed by time units corresponding to the WCET Ci
of the current task τi. This is done in order to obtain the
next result for the scheduling analysis of the next task τi+1
with respect to the priorities. As the considered scheduling
policy (DM) determines the total order in which to perform
the scheduling analysis, it follows that the circular repre-
sentation, i.e. Dameid, of circumference corresponding to
the LCM of periods of all tasks that we have introduced
allows us to build directly the permanent phase of the system
if it is schedulable. Indeed, Dameid can be constructed
completely independently from the linear representation. In
this representation, the WCETs of the tasks correspond to
angular sectors, where the angular unit is given by
1
Hn
and

184
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
Hn = LCM{T1, T2, · · · , Tn}.
Figure 6 shows an example of the Dameid for the system
of which the schedule and the curve of response time as
a function of time for each task are illustrated in ﬁgure
4 and ﬁgure 5. For this system, whose characteristics are
summarized in table 1, we assume that task t1 has a higher
priority than task t2, i.e. tasks are scheduled by using DM. In
ﬁgure 4, the permanent phase is illustrated by the highlighted
zone (blue zone). The curve of the response time of each
task according to time (see ﬁgure 5) shows that from the
time t = 15, the response time of each task is constant.
We ﬁnd this result by constructing the Dameid. Indeed, the
LCM of the periods of both tasks t1 and t2 is given by
H2 = LCM(5, 15) = 15. The release times of task t1
in Dameid with respect to its ﬁrst release time are given
by r1
1 = 4, r2
1 = 9 and r3
1 = 14. For task t2, we have
a single release time equal to r1
2 = 0 because its period
T2 = H2 = 15. Since task t1 has a higher priority than
task t2, then at each release time of t1, i.e. at the dates
r1
1, r2
1 and r3
1, a sector corresponding to its worst case
execution time (C1 = 2 time units) is executed. As task
t2 has a lower priority than task t1, the ﬁlling of the sectors
of circumference corresponding to its worst case execution
time (C2 = 4 time units) can only be done between the time
instants 1 and 4, then time instants 6 and 7. Dameid builds
the permanent phase of the system directly: in ﬁgure 4, task
t2 has two distinct response times, 4 time units for the ﬁrst
activation and 7 time units afterwards, while in the circular
representation through Dameid, it has a single response time,
7 time units, which corresponds to its response time in the
permanent phase.
Tche
r1
i
Ci
Di
Ti
t1
4
2
5
5
t2
0
4
15
15
Table 1. Characteristics of the tasks
Figure 4.
Linear representation / Gantt Chart of the
schedule.
This new representation of the schedule is more interest-
ing than the linear representation / Gantt Chart because it is
more compact and puts greater emphasis on the available
time units in the resulting schedule. In his thesis ([24]), Joel
Goossens suggested that the permanent phase is sufﬁcient to
guaranteeing the schedulability of a given periodic task set
Figure 5. Response time of each task as a function of
time.
Figure 6.
Circular representation of the schedule by
using Dameid.
when the cost of preemption is neglected and this permanent
phase is directly built by using Dameid. We now suppose the
asynchronous task set deﬁned in corollary 1 and present the
Mesoid approach used to compute the worst case response
time of each periodic task.
5. Worst case response time: the Mesoid ap-
proach
In this section we provide the method for computing
the worst response time of each task in order to check
its schedulability. Actually, three classical methods may be
used to do so: the utilisation factor of the processor ([25]),
the worst response time of each task, or the processor

185
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
demand ([26]). In this paper we have chosen to use the
second approach as it provides a schedulability condition
for each task individually. The main idea behind the Mesoid
approach is to ﬁll some available time units left by the
schedule of higher priority tasks with executed time units
corresponding to the execution time of the current task.
Since the worst response time is obtained in the second
instance w.r.t. corollary 2, we will achieve this goal by
applying the method described in [4] to a system where the
tasks are not all released simultaneously and where the cost
of a preemption is assumed to be zero. This method, unlike
those proposed in ([27], [7], [28]), is of lesser complexity
since it is not necessary to determine the releases of every
task w.r.t. those of higher priority tasks.
As we are in a ﬁxed priority context, the proposed method
checks for the schedulability of each task by computing its
worst response time, from the task with the highest priority
to that with the lowest priority. Hence, from the point of view
of any task τi of a system Γn = {τ1, τ2, · · · , τn} ordered by
decreasing priorities (Ti−1 ≤ Ti, ∀i ∈ {2, · · · , n}) such that
Ti−1|Ti and r1
i = r1
i−1 − Ci, the elapsed duration between
the release of the second instance and the ﬁrst release r1
i−1
of task τi−1 is given by Ti − Ci. Before providing the
computation method of the worst case response time, we
provide some necessary deﬁnitions below.
5.1. Deﬁnitions
All the deﬁnitions and terminologies used in this section
are directly inspired by ([4]) and are applied here to the case
of a model where the cost of preemption is assumed to be
zero. From the point of view of any task τi, the hyperperiod
at level i, Hi, is given by Hi = LCM{Tj}τj∈sp(τi) = Ti
as Ti−1|Ti for every i ∈ {2, · · · , n} , and sp(τi) is the
set of tasks with a period shorter than that of task τi.
Without any loss of generality we assume that the ﬁrst task
τ1 starts its execution at time t = 0 and that all tasks have
different periods. Since at each level the schedule repeats
indeﬁnitely from the second instance thanks to corollary 1, it
is sufﬁcient to perform the scheduling analysis in the interval
[r1
i + Ti, r1
i + 2Ti] for task τi as its response time in its ﬁrst
instance equals its WCET.
We proceed the schedule from the task with the shortest
period towards the task with the longest period. Thus, at each
level in the scheduling process the goal is to ﬁll available
time units in the previous schedule, obtained up to now, with
slices of the WCET of the current task, and hence we obtain
the next current schedule. Consequently, we represent the
previous schedule of every instance τ k
i of the current task
τi = (Ci, Ti) by an ordered set of Ti time units where some
have already been executed because of the execution of tasks
with shorter periods, and the others are still available for the
execution of task τi in that instance. We call this ordered set
which describes the state of each instance τ k
i the Mk
i Ti-
mesoid. More details on the deﬁnition of a Ti-mesoid are
given in [4]. For the current task τi = (Ci, Ti), there are as
many Ti-mesoids as instances. We call Mb,2
i
the Ti-mesoid
corresponding to the second instance of task τi before being
scheduled in the current schedule. The process used to build
Mb,2
i
for task τi will be detailed later in this subsection. Still,
from the point of view of task τi, we deﬁne for the mesoid
Mb,2
i
the corresponding universe X2
i to be the ordered set,
compatible with that of the mesoid, which consists of all
the availabilities of Mb,2
i
– that is to say, all the possible
values that Ci can take in Mb,2
i . Task τi will be said to be
potentially schedulable if and only if
Ci ∈ X2
i
∀ i ∈ {1, · · · , n}
(2)
This equation veriﬁes that Ci belongs to the universe
at level i. If it does not, then the system is clearly not
schedulable. When equation (2) holds for a given task τi,
we call Ma,2
i
the Ti-mesoids corresponding to the second
instance of task τi after τi has been scheduled. Ma,2
i
is a
function of Mb,2
i
which itself is a function of Ma,2
i−1, both
detailed as follows.
Let f be the function such that Mb,2
i
= f(Ma,2
i−1)
which transforms the Ti−1-mesoid after task τi−1 has been
scheduled at level i − 1 into the Ti-mesoid before task τi is
scheduled at level i.
As mentioned in [4], a mesoid consists only of time units
already executed denoted by “e” and time units still available
denoted by “a”. Moreover, the cardinal of a mesoid is equal
to the period of the task under consideration whatever the
level is. As such, the function f transforms a time unit al-
ready executed (resp. still available) in Ma,2
i−1 into a time unit
already executed (resp. still available) in Mb,2
i
by following
an index ψ which enumerates, according to naturals, the time
units (already executed or still available) in Ma,2
i−1 of task
τi−1 after τi−1 has been scheduled. As the elapsed duration
between the release of the second instance of task τi and
the release of the ﬁrst instance of τi−1 is Ti − Ci, then ψ
starts from the time unit right after γi = Ti − Ci mod [Ti−1]
time units in the mesoid Ma,2
i−1 towards the last time unit,
and then circles around to the beginning of the mesoid
Ma,2
i−1 again, until we get the Ti-mesoid Mb,2
i . This Ti-
mesoid is obtained when ψ = Ti. Indeed, the previous
schedule at level i (the schedule obtained at level i − 1)
consists of Hi−1 = Ti−1 time units whereas the schedule
of the current task τi is computed upon Hi = Ti time
units. Thus, that amounts to extending the previous schedule
from Ti−1 to Ti time units by identically repeating the
previous schedule as often as necessary to obtain Hi time
units. Due to the particular releases of the ﬁrst instance of
each task, i.e. r1
i+1 = r1
i − Ci+1 ∀ i ∈ {1, · · · , n − 1},
notice that index ψ in contrast to index ζ used in [4]
which started from the ﬁrst time unit, starts from the time
unit right after γi = Ti − Ci mod [Ti−1] time units in
the mesoid Ma,2
i−1. Since τ1 is the task with the shortest

186
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
period, then sp(τ1) = {τ1}. Because τ1 is never preempted,
we have Mb,2
1
= {1, 2, · · · , T1} and therefore we obtain
Ma,2
1
= {(C1), 1, 2, · · · , T1 − C1}.
Let g be the function such that Ma,2
i
= g(Mb,2
i ) which
transforms the Ti-mesoid Mb,2
i
before task τi has been
scheduled at level i into the Ti-mesoid Ma,2
i
after task τi
has been scheduled at level i.
5.2. Worst case response time with a Mesoid
For the Ti-mesoid Mb,2
i , we will compute the response
time R2
i of task τi in the second instance by adding to the
WCET Ci all the consumptions appearing in that Ti-mesoid
before the availability corresponding to Ci [4]. This yields
the worst-case response time Ri of task τi since at each level
the schedule becomes periodic from the second instance, that
is to say Rk
i = R2
i ∀ k ≥ 2, and R1
i = Ci ∀ i ≥ 1.
Now we can build Ma,2
i
= g(Mb,2
i ): function g trans-
forms a time unit already executed in Mb,2
i
into a time unit
already executed in Ma,2
i
, and transforms a time unit still
available into either a time unit still available or a time unit
already executed w.r.t. the following condition. We use an
index which enumerates according to numerals the time units
in Mb,2
i
from the ﬁrst to the last one, at each step in the
incremental process, if the current value of the index is less
than or equal to R2
i , function g transforms the time unit
still available into a time unit already executed due to the
execution of instance τ 2
i , otherwise g transforms it into a
time unit still available. Indeed, function g ﬁlls available
time units in the current schedule with slices of the WCET
in each Ti-mesoid, leading to the previous schedule for the
next task at level i + 1 w.r.t. priorities. To summarize, for
every task τi, we have
τi :



Mb,2
i
: Ti-mesoid before τi is scheduled at level i
Ma,2
i
: Ti-mesoid after τi is scheduled at level i.
6. Deadline reduction factor
6.1. Worst case response time computation
The approach proposed here leads to a new schedulability
condition
for
harmonic
hard
real-time
systems.
This
condition is new in the sense that in addition to providing
a necessary and sufﬁcient schedulability condition, it
also reduces the feasibility interval for a given harmonic
asynchronous system.
In the scheduling process, at each level i, the basic idea
consists in ﬁlling availabilities in the mesoid Mb,2
i
before
task τi is scheduled, with slices of its WCET. This is why it
is fundamental to calculate the corresponding response time.
This yields the worst case response time and allows us to
conclude on the schedulability of task τi w.r.t. priorities. In
the case where τi is schedulable, we build Ma,2
i
, after τi has
been scheduled, in order to check the schedulability of the
next task, and so on, otherwise the system is not schedulable.
Thanks to everything we have presented up to now, τ1 is
scheduled ﬁrst and r1
1 = 0. The latter statement implies
that before τ1 is scheduled, its WCET can potentially take
any value from 1 up to the value of its period T1. Since
task τ1 is never preempted, then Mb,2
1
= {1, 2, · · · , T1} and
X2
1 = {1, 2, · · · , T1}. Moreover, its response time is also
equal to C1. Consequently, the corresponding T1-mesoids
associated to task τ1 are given by
τ1 :



Mb,2
1
= {1, 2, · · · , T1}
Ma,2
1
= {(C1), 1, 2, · · · , T1 − C1}
We assume that the ﬁrst i − 1 tasks with 2 ≤ i ≤ n have
already been scheduled, i.e. the Ti−1-mesoid Ma,2
i−1 of task
τi−1 is known, and that we are about to schedule task τi.
As explained in the previous section, the Ti-mesoid
Mb,2
i
= f(Ma,2
i−1) of task τi is built thanks to index ψ on
Ma,2
i−1 of task τi−1 without forgetting to start from the time
unit right after γi = Ti−Cimod[Ti−1] time units rather than
the ﬁrst time unit as in [4]. Again this is due to the particular
release of the ﬁrst instances of tasks: r1
i = r1
i−1−Ci. We can
therefore determine the universe X2
i when the Ti−1-mesoid
Ma,2
i−1 is known. Unless the system is not schedulable, i.e.
Ci ̸∈ X2
i , we assume that task τi is potentially schedulable,
i.e. Ci ∈ X2
i . The response time R2
i of task τi in its kth
instance (with k ≥ 2), i.e. in the kth Ti-mesoid will be
obtained by summing Ci with all consumptions prior to Ci
in the corresponding mesoid. The worst-case response time
Ri of task τi will then be given by
Ri = R2
i
This equation leads us to say that task τi is schedulable
if and only if
Ri ≤ Ti
(3)
If for task τi expression (3) holds, then Ma,2
i
= g(Mb,2
i )
will be deduced as explained in the previous section. For
the sake of clarity, whenever there are two consecutive con-
sumptions in a mesoid, this amounts to considering only one
consumption which is the sum of the previous consumptions.
That is to say that after determining the response time of task
τi in its kth mesoid, if Ma,k
i
= {(c1), (c2), 1, 2, · · · }, then
this is equivalent to Ma,k
i
= {(c1 + c2), 1, 2, · · · }.
Below, we present our scheduling algorithm which, for
a given task, on the one hand ﬁrst determines the value
of γi = Ti − Ci mod [Ti−1] relative to priorities, then, on
the other hand the schedulability condition. Recall that the
elapsed duration between the release of the second instance
and the ﬁrst release is Ti − Ci. The scheduling algorithm
has the following nine steps. Since the task with the shortest

187
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
period, namely task τ1, is never preempted, the loop starts
from the index of the task with the second shortest period,
namely task τ2 as the schedule proceeds towards tasks with
longer periods.
1: for i = 2 to n do
2:
Determine the release time of the ﬁrst instance of task
τi:
r1
i = r1
i−1 − Ci
and compute γi = Ti − Ci mod [Ti−1] of the second
instance of τi w.r.t. τi−1.
3:
Build the Ti-mesoid Mb,2
i
= f(Ma,2
i−1) of task τi
before it is scheduled. This construction is based on a
modulo Ti arithmetic using index ψ on Ma,2
i−1 without
forgetting to start from the time unit right after γi =
Ti−Cimod[Ti−1] time units rather than the ﬁrst time
unit as in [4]. This is due to the particular release of
tasks.
4:
For the Ti-mesoid Mb,2
i
resulting from the previous
step, build the corresponding universe X2
i
which
consists of the ordered set of all availabilities of
Mb,2
i . Notice that this set corresponds to the set of
all possible values that the WCET Ci of task τi can
take in Mb,2
i .
5:
Since τi is potentially schedulable, i.e. its WCET
Ci ∈ X2
i , we must verify that it is actually schedula-
ble. Clearly, if Ci ̸∈ X2
i , then task τi is not schedu-
lable because the deadline of the task is exceeded.
6:
Determine the response time Rk
i of task τi in its kth
instance, i.e. in the kth Ti-mesoid. This is obtained
by summing Ci with all the consumptions prior to Ci
in the corresponding mesoid. Deduce the worst-case
response time Ri of task τi.
Ri = R2
i
It is worth noticing that task τi is schedulable if and
only if
Ri ≤ Di.
7:
If Ri ≤ Di, then build Ma,2
i
= g(Mb,2
i ), increment
i, and go back to step 2 as long as there remain
potentially schedulable tasks in the system.
8:
If Ri > Di, then the system {τi = (Ci, Ti)}1≤i≤n is
not schedulable.
9: end for
Thanks to the above algorithm, a system of n tasks
{τi = (Ci, Ti)}1≤i≤n, with harmonic periods and ﬁrst
released such that r1
i = r1
i−1 − Ci, is schedulable if and
only if
Ri = R2
2 ≤ Di
∀i ∈ {1, 2, · · · , n}
(4)
6.2. Computation of α
The value of α is given by: α = max1≤i≤n
Ri
Ti

.
This value of α guarantees that no task fails at run-time.
We recall that for the synchronous scenario, the worst case
response time of task τi is given by:
Ri = Ci +
X
j∈hp(i)
Ri
Tj

Cj
Example
Let us consider {τ1, τ2, τ3, τ4} to be a system of four
tasks with harmonic periods and ﬁrst released such that r1
i =
r1
i−1 − Ci. The characteristics are deﬁned in table 2.
Table 2. Characteristics of the tasks
Ci
Ti
τ1
2
5
τ2
4
15
τ3
5
30
τ4
7
60
The shorter the period of a task is, the higher its level is.
Thus, as depicted in table 2, τ1 has the highest level and task
τ4 the lowest level. Thanks to our scheduling algorithm,
for task τ1 whose ﬁrst release time is r1
1 = 0, we have
τ1 :



Mb,2
1
= {1, 2, 3, 4, 5}
R1 = 2
Ma,2
1
= {(2), 1, 2, 3}
γ2 = T2 − C2 mod [T1] = 15 − 4 mod [5] = 1, thus for task
τ2 whose ﬁrst release time is r1
2 = r1
1 − C2 = −4, we have
τ2 :



Mb,2
2
= {(1), 1, 2, 3, (2), 4, 5, 6, (2), 7, 8, 9, (1)}
R2 = 4 + 2 + 1 = 7
Ma,2
2
= {(7), 1, 2, (2), 3, 4, 5, (1)}
γ3 = T3 −C3 mod[T2] = 30−5mod[15] = 10, thus for task
τ3 whose ﬁrst release time is r1
3 = r1
2 −C3 = −4−5 = −9,
we have
τ3 :



Mb,2
3
= {(1), 1, 2, 3, (8), 4, 5, (2), 6, 7, 8, (8), 9, 10, (1)}
R3 = 5 + 8 + 1 = 14
Ma,2
3
= {(16), 1, 2, 3, (8), 4, 5, (1)}
γ4 = T4 −C4 mod[T3] = 60−7mod[30] = 23, thus for task
τ4 whose ﬁrst release time is r1
4 = r1
3−C4 = −9−7 = −16,
we have
τ4 :



Mb,2
4
= {(4), 1, 2, (17), 3, 4, 5, (8), 6, 7, (17), 8, 9, 10, (4)}
R4 = 7 + 8 + 17 + 4 = 36
Ma,2
4
= {(53), 1, 2, 3, (4)}
Consequently, the set of tasks {τ1, τ2, τ3, τ4} with har-
monic periods and ﬁrst released such that r1
i = r1
i−1 − Ci
is schedulable. The schedule with the above characteristics

188
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
Figure 7. Execution of a set of harmonic tasks with r1
i =
r1
i−1 − Ci, ∀ i ∈ {2, · · · , 4}
Figure 8. Circular representation of the schedule for a
set of harmonic tasks with r1
i = r1
i−1−Ci, ∀i ∈ {2, · · · , 4}
is depicted in ﬁgure 7 and the circular representation of the
schedule by using Dameid is depicted in ﬁgure 8.
The schedule of the same set of tasks released simultane-
ously is depicted in ﬁgure 9 and the circular representation
of the schedule by using Dameid is depicted in ﬁgure 10.
Figure 9. Execution of a set of harmonic tasks with r1
i =
0 ∀ i ∈ {1, · · · , 4}
It is worth noticing here the large variation between the
two scenarios in terms of the tasks’ response times. In fact,
the worst case response time of task τ4 in ﬁgure 7 and ﬁgure
Figure 10. Circular representation of the schedule for a
set of harmonic tasks with r1
i = 0 ∀ i ∈ {1, · · · , 4}
8 is 36 time units whereas it is 55 time units in ﬁgure
9 and ﬁgure 10. This phenomenon is even more apparent
in the next section with the experimental results where we
gradually and uniformly decrease the value of the relative
deadlines for all tasks by the same factor to highlight the
advantage of our approach.
Tasks
Rsynchronous
i
Rasynchronous
i
τ1
2
2
τ2
8
7
τ3
15
14
τ4
55
36
This
leads
us
to
obtain
αsynchrnous
=
max(2/5, 8/15, 15/30, 55/60)
=
0.91
whereas
αasynchrnous = max(2/5, 7/15, 14/30, 36/60) = 0.60,
which means the improvement performed in this case is of
34.54%
7. Experimental results
In this section we present some experimental results found
by using the approach we have developed above. To achieve
these experimental results, we proceed in two steps. First, we
compare the minimum deadline reduction factor α obtained
in the synchronous scenario with that obtained in our speciﬁc
asynchronous scenario. Second, we extend this comparison
concerning the value α to the value of α obtained for an
arbitrarily generated scenario of the ﬁrst release times for all
tasks. This extension is performed by using more extensive
experiments in order to get more accurate conclusions with

189
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
regard to the contributions of the proposed approach. As in
([1]), we consider a set of harmonic tasks scheduled with
the Deadline Monotonic algorithm.
The ﬁrst step in our process of comparing the value of
α for given scenarii of ﬁrst release for all tasks consists
in performing 10000 experiments for each graph, where
every task set consists of n = 10 harmonic tasks. The
total utilization factor of the processor is randomly chosen
between 0.7 and 1 for each task set. Hence, we can evaluate
the gain of our speciﬁc asynchronous scenario deﬁned in
corollary 1 in section 3, compared to the synchronous one.
We set α = Di
Ti , and we gradually and uniformly decrease
the value of the relative deadlines Di by the same factor
for all tasks in each set. In both the synchronous and the
asynchronous scenario, we plot the curves corresponding to
the smallest value of α, as a function of the total utilization
factor of the processor, for the task set to remain schedulable.
The resulting graphic is displayed in ﬁgure 11. If the value
of α is denoted αsynchronous in the synchronous scenario
and αasynchronous in our asynchronous scenario, the gain
can be computed as follows:
gain = αsynchronous − αasynchronous
αsynchronous
× 100
Figure 11. Value of α with our asynchronous scenario
and with the synchronous scenario
In ﬁgure 11, the solid curve represents the result obtained
for α in our speciﬁc asynchronous case whereas the dotted
curve represents the result obtained in the synchronous case.
In both cases, we start with a schedulable task set ∀τi, Di =
Ti. From [20], U ≤ 1 is a necessary and sufﬁcient condition
for the schedulability of a harmonic task set as tasks are
scheduled with DM, equivalent to RM when ∀τi, Di = Ti.
We can see that for a small load, we obtain almost the same
α both in the synchronous and in the speciﬁc asynchronous
cases.
Concerning the second step in our process of comparing
the value of α for given scenarii of ﬁrst release times for
all tasks, we perform twice as many experiments than for
the ﬁrst step. That is to say, we perform 20000 experiments
for each graph, and every task set still consists of n = 10
harmonic tasks. Again, the total utilization factor of the
processor is randomly chosen between 0.7 and 1 for each
task set. As such, we can evaluate the gain of α obtained
in our speciﬁc asynchronous scenario, compared to that
obtained in the synchronous scenario on the one hand, and
to the mean value obtained for a set of arbitrarily generated
scenarii on the other hand. As for the ﬁrst step, we set
α =
Di
Ti , and we gradually and uniformly decrease the
value of the relative deadlines Di by the same factor for all
tasks in each set. For the synchronous, and the asynchronous
scenarii, we plot the curves corresponding to the smallest
value of α. For the set of arbitrarily generated scenarii, we
plot the curves corresponding to the mean value of α. This is
performed in each case as a function of the total utilization
factor of the processor, for the task set to remain schedulable.
The curves obtained are displayed in ﬁgure 12.
0.70
0.75
0.80
0.85
0.90
0.95
1.00
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
load
alpha
Figure 12. Value of α with our asynchronous scenario,
then with the synchronous scenario and the mean of a
set of arbitrarily generated scenarii
In ﬁgure 12, the curve in red represents the result obtained
for α by using our speciﬁc asynchronous scenario. The curve
in green represents the result obtained for the synchronous
case and the curve in blue represents the mean value
obtained for a set of arbitrarily generated scenarii. In all the
cases, we start with a schedulable task set ∀τi, Di = Ti and
U ≤ 1 remains a necessary and sufﬁcient condition for the
schedulability of a harmonic task set as tasks are scheduled

190
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
with DM. It is worth noticing that DM is equivalent to RM
when ∀τi, Di = Ti.
We can see that we always obtain almost the same value
for α both in the synchronous case and for the mean value
obtained for a set of arbitrarily generated scenarii.
For a small load, the value of α varies very slightly
whatever the scenario of ﬁrst release for all tasks is. In both
steps, this is due to the fact that with a small load the worst
case response times of the tasks are less inﬂuenced by the
ﬁrst release times of other tasks. When the load increases,
the gain also increases, reaches and remains at a maximum
of 14.3% for U = 0.95. Over the load U = 0.95, the
gain steadily decreases when U tends to 1 and α tends to
1. At high loads, the worst case response time of a task
tends to its period and thus α tends to 1. In this latter case,
the improvement obtained with our spaciﬁc asynchronous
scenario becomes less signiﬁcant.
8. Conclusion
In this paper we have proposed a new approach for a
better control of periodic tasks scheduled with Deadline
Monotonic scheduling algorithm. We have considered a spe-
ciﬁc asynchronous task set and harmonic tasks that enables
us to signiﬁcantly reduce the worst case response time of
each task thus reducing the jitter of each task for a better
control. The asynchronous scenario we considered makes it
possible to signiﬁcantly reduce the complexity of the worst
case response time computation. We have then considered
the Mesoid approach to compute the worst case response
time of a task in an asynchronous scenario. We have used
the Mesoid approach to compute the minimum deadline
reduction factor characterizing the beneﬁt in terms of worst
case response time reduction. We have proved by extensive
simulations that the gain in terms of deadline reduction
can reach 14.3% with our particular asynchronous scenario
compared to the synchronous scenario and to an arbitrarily
generated scenario. This makes it possible to better control
the jitter of the tasks when considering control loops. Future
work will compare the deadline reduction factor obtained
with EDF with the one we have obtained with our speciﬁc
asynchronous scenario.
References
[1] P. Meumeu Yomsi, L. George, Y. Sorel, and D. De Rauglau-
dre. Improving the Sensitivity of Deadlines with a Speciﬁc
Asynchronous Scenario for Harmonic Periodic Tasks sched-
uled by FP. The Fourth International Conference on Systems
(ICONS’09), Cancun, Mexico, March 1 - 6 2009.
[2] Giorgio Buttazzo Enrico Bini, Marco Di Natale. Sensitivity
Analysis for Fixed-Priority Real-Time Systems. Proceedings
of the 18th Euromicro Conference on Real-Time Systems
(ECRTS’06), Dresden, Germany July 5-7, 2006.
[3] Ismael Ripoll Patricia Balbastre and Alfons Crespo. Optimal
deadline assignment for periodic real-time tasks in dynamic
priority systems. Proceedings of the 18th Euromicro Confer-
ence on Real-Time Systems (ECRTS’06), Dresden, Germany
July 5-7, 2006.
[4] P. Meumeu Yomsi and Sorel Y. Extending Rate Monotonic
Analysis with Exact Cost of Preemptions for Hard Real-Time
Systems. Proceedings of 19th Euromicro Conference on Real-
Time Systems, ECRTS’07, Pisa, Italy, Jul. 2007.
[5] S. Baruah, R. Howell, and L. Rosier.
Algorithms and
complexity concerning the preemptive scheduling of periodic
real-time tasks on one processor. Real-Time Systems, Vol. 2,
pp. 301-324, 1990.
[6] K. Tindell, A. Burns, and A. J. Wellings. Analysis of hard
real-time communications.
Real-Time Systems, Vol. 9, pp.
147-171, 1995.
[7] L. George, N. Rivierre, and M. Spuri.
Preemptive and
non-preemptive scheduling real-time uniprocessor scheduling.
INRIA Research Report, No. 2966, September 1996.
[8] E. Bini and G. Buttazzo.
The Space of EDF Feasible
Deadlines. Proceedings of the 19th Euromicro Conference on
Real-Time Systems (ECRTS’07), Pisa, Italy, July 4-6 2007.
[9] S. Baruah, G. Buttazo, S. Gorinsky, and G. Lipari. Scheduling
periodic task systems to minimize output jitter. In 6th Con-
ference on Real-Time Computing Systems and Applications,
pp. 62-69, 1999.
[10] A. Cervin, B. Lincoln, J. Eker, K. Arzen, and Buttazzo
G.
The jitter margin and its application in the design
of real-time control systems.
In proceedings of the IEEE
Conference on Real-Time and Embedded Computing Systems
and Applications, 2004.
[11] D. Marinca, P. Minet, and L. George. Analysis of deadline as-
signment methods in distributed real-time systems. Computer
Communications, Elsevier, To appear, 2004.
[12] M. Joseph and P. Pandya. Finding response times in a real-
time system. BCS Comp. Jour., 29(5), pp. 390-395,, 1986.
[13] M. Grenier, J. Goossens, and N. Navet. Near-optimal ﬁxed
priority preemptive scheduling of offset free systems. Proc.
of the 14th International Conference on Network and Systems
(RTNS’2006), Poitiers, France, May 30-31, 2006 2006.
[14] Giorgio Buttazzo Enrico Bini.
Schedulability Analysis of
Periodic Fixed Priority Systems.
IEEE Transactions On
Computers, Vol. 53, No. 11, Nov.2004.
[15] J.P. Lehoczky. Fixed priority scheduling of periodic task sets
with arbitrary deadlines. Proceedings 11th IEEE Real-Time
Systems Symposium, pp 201-209, Dec. Lake Buena Vista, FL,
USA, 1990.
[16] J. Y. T. Leung and M.L. Merril. A note on premptive schedul-
ing of periodic, Real Time Tasks.
Information Processing
Letters, Vol 11, num 3, Nov. 19980.

191
International Journal on Advances in Systems and Measurements, vol 2 no 2&3, year 2009, http://www.iariajournals.org/systems_and_measurements/
[17] Annie Choquet-Geniet and Emmanuel Grolleau.
Minimal
schedulability interval for real-time systems of periodic tasks
with offsets. Theor. Comput. Sci., 310(1-3):117–134, 2004.
[18] N. C. Audsley. Optimal priority assignment and feasibility of
static priority tasks with arbitrary start times. Dept. Comp.
Science Report YCS 164, University of York, 1991.
[19] J. Goossens. Scheduling of offset free systems. Real-Time
Systems, 24(2):239-258, March 2003.
[20] G. C. Buttazzo. Rate Monotonic vs. EDF: Judgment Day.
Real-Time Systems, 29, 5-26, 2005.
[21] E. Bini and A. Cervin. Delay-Aware Period Assignment in
Control Systems. Proceedings of the 26th IEEE International
Real-Time Systems Symposium (RTSS’08), Barcelona, Spain,
Nov. 30 to Dec. 3 2008.
[22] S. Baruah, A. K. Mok, and L. Rosier. Preemptively scheduling
hard real-time sporadic tasks on one processor. Proceedings
of the 11th Real-Time Systems Symposium, pp. 182-190, 1990.
[23] L. C. Liu and W. Layland. Scheduling algorithms for multi-
programming in a hard real time environment.
Journal of
ACM, Vol. 20, No 1, pp. 46-61, January 1973.
[24] J. Goossens. Scheduling of Hard Real-Time Periodic Systems
with Various Kinds of Deadline and Offset Constraints. PhD
thesis, Universit´e Libre de Bruxelles, 1998.
[25] C.L. Liu and J.W. Layland.
Scheduling algorithms for
multiprogramming in a hard-real-time environment. Journal
of the ACM, 1973.
[26] A.K. Mok S.K. Baruah and L.E. Rosier.
Preemptively
scheduling hard realtime sporadic tasks on one processor. In
proc. 11th IEEE Real-Time Systems Symposium, 1990.
[27] Joseph Y.-T. Leung and M. L. Merrill. A note on preemptive
scheduling of periodic, real-time tasks. Information Process-
ing Letters, 1980.
[28] J. Leung and Whitehead J.
On the complexity of ﬁxed-
priority scheduling of periodic real-time tasks. Performance
Evaluation(4), 1982.

