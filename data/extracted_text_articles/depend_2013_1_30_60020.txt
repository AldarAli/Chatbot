Reliable and Secure Memories Based on Algebraic Manipulation
Detection Codes and Robust Error Correction
Shizun Ge
ECE, Boston University
Boston, MA, USA
Email: shizunge@gmail.com
Zhen Wang
Mediatek Wireless, Inc
Boston, MA, USA
Email: wang.zhen.mtk@gmail.com
Mark Karpovsky
ECE, Boston University
Boston, MA, USA
Email: markkar@bu.edu
Pei Luo
ECE, Boston University
Boston, MA, USA
Email: luopei@bu.edu
Abstract—The reliability and security of memories are crucial consider-
ations in the modern digital system design. Traditional codes concentrate
on detecting and correcting errors of certain types, e.g., errors with small
multiplicities or byte errors, and cannot detect or correct unanticipated
errors. Thereby, they may not be sufﬁcient to protect memories against
malicious attackers with strong fault injection capabilities and cannot cor-
rect unexpected errors with high multiplicities. The contribution of this
paper is that we construct a new reliable and secure memory architecture
based on robust Algebraic Manipulation Correction (AMC) codes. These
codes can be used for correction of random errors and for detection
of fault injection attacks. These codes can provide a guaranteed error
detection probability for all errors even if both the user deﬁned messages
(data stored in the memory) and the error patterns are controllable by
an attacker. The presented code can correct all single-bit errors in the
information bits of the code. Moreover, these codes can be used to correct
double-bit errors with high probabilities. The construction and the error
correction procedures for the code will be described. The probability that
an error can be successfully detected and/or corrected and the hardware
overheads for the proposed memory architecture will be estimated. The
presented approach is efﬁcient for protecting security/reliability critical
memories used to store the important information on the chip (e.g., a
secret key in a cryptographic device).
Keywords-Algebraic Manipulation Detection Code, Error Correction,
Fault Injection Attack, Hardware Security
I. INTRODUCTION
Memories are critical elements in today’s digital systems. Various
types of memories are widely used in many different reliable and
secure applications and appear in nearly all digital devices. SRAMs,
for example, are often used as caches and internal memories in em-
bedded systems. Non-volatile memories like EEPROM and Flashes
are often used in cryptographic devices to store secret informations
such as the encryption keys and passwords.
The reliability of memory is a crucial consideration for today’s
digital devices. For some designs as much as 70% of the chip area
is taken by the embedded memory [1], [2]. This large area of the
chip is especially vulnerable to single-event-upsets (SEUs) caused
by single, energetic particles like high-energy neutrons and alpha
particles. SEU temporarily alters the state of the devices and results
in soft errors. These errors are nondestructive and appear as unwanted
bit ﬂips in memory cells and registers. Continuing scaling of device
features and performance increases the likelihood of errors, which
makes the error models more unpredictable. As the speed of the
devices becomes higher the relative size of the clock transition timing
window increases and this makes devices more sensitive to SEU [3].
Similarly, decreased voltage levels for modern technologies make bit
inversions more likely to occur [4].
The dangers of possible errors in memories resulting from SEUs
are often mitigated with the use of linear single-error-correcting,
double-error-detecting codes (SEC-DED). These codes have mini-
mum Hamming distance four and are able to correct all single bit
errors and detect all double bit errors. In the presence of multi-bit
errors, however, the reliability of systems utilizing error protection
architectures based on these codes may be questionable. For any
linear SEC-DED codes with k information bits, the number of
undetectable multi-bit errors is 2k. In addition to this, a huge number
of multi-bit errors will be miscorrected. In the case where SEU results
in multi-bit distortions with high probability, these codes may not be
sufﬁcient to provide a high reliability. Anomalies of systems caused
by multi-bit upsets (MBU) have already been reported [5], [6].
The increase of the MBU rate in deep submicron technologies
deteriorates the situation even further. In 65nm triple-well SRAMs
with a thin cell architecture, the rate of multi-bit errors caused by
neutron induced SEU increases by a factor of ten compared to that
in 90 nm technologies nearly 55% of the errors due to neutron
radiation were multi-bit errors [7]. Although there are mechanisms
like bit interleaving [8] that can be used to minimize the error rate
contribution of multi-bit errors, whether it is enough under such
high MBU rate is still unknown. Moreover, the advantage of bit
interleaving comes at a price of more layout constraints, which may
result in larger power consumptions and longer access times. Thereby,
memory protection architectures which can provide better protection
against multi-bit errors than that based on classical linear codes are
in demand.
Memories used in secure cryptographic devices not only suffer
from random errors but are also vulnerable to errors injected by
malicious fault injection attacks. It has been shown that the attacker
can derive the secret key of the cryptographic devices thus break the
security of the whole systems by injecting faults during encryption or
decryption operations to force the devices working abnormally [9],
[10].
Most of the existing reliable and secure memory architectures are
based on linear codes, which concentrate their error detection and
correction capabilities against certain types of errors, e.g., errors with
small multiplicities [11], [12], [13]. The reliability and security of
systems protected by linear codes largely depend on the accuracy
of the expected error model. For memories used in cryptographic
devices, the error model and the number of distorted bits introduced
by the faults injected by the attacker are generally unpredictable
due to the adaptive nature and the advanced fault injection methods
available to an attacker. Thereby, the security of memories protected
by linear codes cannot be guaranteed assuming the strongest attacker
model.
As an alternative to linear codes, robust codes and their variants
based on nonlinear encoding functions were proposed in [14],
[15]. Different from linear codes, robust codes can provide nearly
equal protection against all error patterns and are more suitable for
applications where multi-bit errors are more probable or the error
model is hard to predict. One limitation of robust codes is that
these codes assume the information bits of messages or outputs
of the device-to-be-protected are uniformly distributed and are not
controllable by external forces, e.g., by an attacker during error
16
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

injection attacks on devices. The reliability and the security of the
communication or computation channels protected by robust codes
will be largely compromised if both information bits of the messages
and the non-zero error patterns can be controlled by the attacker.
Intuitively, the limitation of robust code described above can be
efﬁciently eliminated by introducing randomness into the encoding
procedure of the code. Due to the fact that the random data are
independent of the user information y, they can always be uniformly
distributed. As a result, the assumption for robust codes that y is
uniformly distributed is no longer required. Moreover, since the user
has zero knowledge and no control of the random bits generated for
each encoding operation, no matter how the attacker selects y and e,
the probability that e is masked will be upper bounded by a number
determined by the size of the set of possible random numbers. A
coding technique based on adding to k information bits m random
bits and r redundant bits, which overcomes the limitation of robust
codes, is called strongly secure algebraic manipulation detection
(AMD) code [16].
However, the constructions presented in [16] usually generate
codes with a Hamming distance of 1, which cannot be used for
error correction. While the resulting AMD codes are suitable for
protecting the secure devices against fault injection attacks, in certain
circumstances they may not be able to provide enough resistance
against random transient errors introduced by the mother nature.
The contribution of this paper is as following. In this paper, we
propose new constructions of Algebraic Manipulation Correction
(AMC) codes and efﬁcient algorithms foe decoding for these codes.
Comparing with our previous works [17], [18], [16], this code have a
Hamming distance 4 and can correct all single-bit errors. Moreover,
we describe a new error correction algorithm for the code which
can also correct all double-bit errors with high probabilities. The
proposed codes can provide a guaranteed level of security as well
as a high level of reliability to the protected device, although the
proposed scheme will require more redundancy, area and power. The
problem of separating between single bit random errors and attacks
for AMC codes is discussed in [17].
The rest part of the paper is organized as follows. The deﬁnitions
of AMD codes and AMC codes are shown in Section II. In Section
III-A, we describe the construction of the proposed AMC code
and present the error correction algorithm for correcting random
single and double errors. The hardware design and the analysis and
comparison of overheads for the proposed codes are shown in Section
IV.
II. DEFINITIONS
AMD codes are designed to provide a guaranteed level of security
even if the attacker can control both the error patterns and the input
(thus the fault-free output) of a device. Different from regular error
control codes, a codeword of an AMD code contains three parts: k-bit
user deﬁned information y, m-bit random data x and r-bit redundancy
f(y, x).
Throughout the paper we denote by ⊕ the addition in GF(q), q =
2r. All the results presented in the paper can be easily generalized
to the case where q = pr (p is a prime). An AMD code V with
codewords (y, x, f(y, x)), where y ∈ GF(2k), x ∈ GF(2m) and
f(y, x) ∈ GF(2r), will be referred to as a (k, m, r) code.
Deﬁnition 2.1: (Security Kernel) [16] For any (k, m, r) error
detecting code V with the encoding function f(y, x), where y ∈
GF(2k), x ∈ GF(2m) and f(y, x) ∈ GF(2r), the security kernel
KS is the set of errors e = (ey, ex, ef), ey ∈ GF(2k), ex ∈
GF(2m), ef ∈ GF(2r), for which there exists y such that f(y ⊕
ey, x ⊕ ex) ⊕ f(y, x) = ef is satisﬁed for all x.
KS = {e|∃y, f(y ⊕ ey, x ⊕ ex) ⊕ f(y, x) ⊕ ef = 0, ∀x}.
(1)
For cryptographic devices and secure applications, non-zero errors
e in the security kernel can be used by an advanced attacker to bypass
the protection based on the error detecting code V . For any error e∗ =
(e∗
y, e∗
x, e∗
f) ∈ KS, e∗ ̸= 0, where 0 is all zero vector, there exists
y∗ (the protected information at the output of the device) such that
for this y∗ the error e∗ is not detected for any choice of the random
variable x (the probability of not detecting e∗ for the information y∗
is equal to 1). Thus to conduct a successful attack, it is sufﬁcient for
the attacker to inject e∗ ∈ KS when the expected output is in the
format of (y∗, x, f(y∗, x)). An AMD code should have no errors in
the security kernel except for the all zero vector in GF(2n), where
n = k + m + r.
Deﬁnition 2.2: [19] A (k, m, r) error detecting code is called
Algebraic Manipulation Detection (AMD) code iff KS = {0}, where
0 is the all zero vector in GF(2n), n = k + m + r.
There are no undetectable errors (errors that are undetected with
a probability of 1) for AMD codes. For any y and any e, the error
masking probability for an AMD code V can be computed as
QV (y, e)
=
2−m|{x (y, x, f(y, x)) ∈ V,
(y ⊕ ey, x ⊕ ex, f(y, x) ⊕ ef) ∈ V }|,
(2)
which is the fraction of random m-bit vectors x that will mask a
ﬁxed error e for a given y. The security level of the system protected
by AMD code can be characterized by the worst case error masking
probability QV = maxy maxe̸=0 QV (y, e).
The general architecture of a computational channel (device)
protected by a (k, m, r) AMD code is shown in Figure 1, where
RNG is a random number generator (either in software or hardware)
and EDN is the error detection network.
Fig. 1.
Computation channel protected by a systematic (k, m, r) AMD code
(original device and the predictor may be under attack).
The deﬁnition of AMD code can be found in [20], [16]. The
existing AMD codes [20], [16] are designed for error detection and
have Hamming distances less than 3. In this paper, we will construct
Algebraic Manipulation Correction (AMC) codes that can be used
not only for error detection but also for error correction. These codes
can be used for design of reliable and secure memories where error
correction is indispensable for restoring data distorted by natural
effects such as soft errors. The formal deﬁnition of AMC codes is as
follows.
Deﬁnition 2.3: An AMD code with Hamming distance at least 3
is called an Algebraic Manipulation Correction (AMC) code.
17
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

III. PROPOSED SINGLE-ERROR-CORRECTING AMC CODES
A. Construction of the proposed single-error-correcting AMC codes
In this Section, we will present the general construction of AMC
codes and two error correction algorithms. The ﬁrst algorithm can
correct all single-bit errors and detect all double-bit errors. The
second algorithm can correct not only single-bit errors but can also
correct double-bit errors with high probabilities at the cost of higher
hardware overhead.
Theorem 3.1: Suppose
1) (x, xP) is a codeword of (m + rH, m, 3) binary linear
Hamming code VH with rH redundant bits and distance 3,
where x ∈ GF(2m), xP ∈ GF(2rH ), P is a rH ×m encoding
matrix, and
2) f(y, x) ∈ GF(2m) is a nonlinear encoding function f(y, x) =
y1x⊕y2x2⊕y3x3⊕· · ·⊕ybxb⊕xb+2 (b is odd, b+2 < 2m−1).
where y = (y1, y2, . . . , yb); yi ∈ GF(2m), (i = 1, 2, . . . , b);
x ∈ GF(2m); f(y, x) ∈ GF(2m) and all the operations are
in GF(2m); 2m − 1 is a prime number;
3) πy = y1 ⊕ y2 ⊕ y3 ⊕ · · · ⊕ yb ∈ GF(2m) is the byte-wise
parity of y;
Then the code VAMC = {(y, πy ⊕ x, xP, f(y, x))} is a (k, m, m +
rH) SEC Algebraic Manipulation Correction (AMC) code, with k =
bm information bits, m random bits, m + rH redundant bits.
This code has secure kernel KVAMC = {0} with the maximum
error masking probability QVAMC = (b + 1)(2m − 2)−1 and Ham-
ming distance 3.
We note that the proposed AMC code is a combination of
(y, x, f(y, x)) AMD code which provides for secure kernel {0}
and (x, Px) Hamming code which provides for distance 3. This
construction is similar to Vasil’ev nonlinear perfect code [21].
Remark 3.1: We may use any AMD encoding functions f(y, x)
described in [20], [16]. In general case, y ∈ GF(2k), where k = sr,
and x ∈ GF(2m), where m = tr. In this case, x = (x1, x2, . . . , xt)
and f(y, x) is a polynomial of t variables x1, . . . , xt. Thus, y will
be divided into s/t parts, each of which contains tr bits, and then
πy ∈ GF(2tr) is the byte-wise parity. The padding zeros may be
applied to y, when s is not dividable by t.
Example 3.1: Let m = 7, which is the number of random bits.
Also let the encoding function be f(y, x) = y1x ⊕ y2x2 ⊕ y3x3 ⊕
y4x4 ⊕ y5x5 ⊕ x7, where y = (y1, y2, . . . , y5) ∈ GF(235) is the
information part, yi ∈ GF(27) for i = 1, 2, . . . , 5, x ∈ GF(27) is
the random number.
Let {(x, xP)} be the (11, 7, 3) Hamming code, where P is the
encoding matrix for the Hamming code. Since 27 − 1 is a prime
number, the code VAMC deﬁned by Theorem 3.1 is an AMC code
with d = 3 and QVAMC =
6
27−2 =
1
21.
Comparing to the AMD Code with k = br = 35, m = r = 7 and
nonlinear encoding function f(y, x) = y1x ⊕ y2x2 ⊕ y3x3 ⊕ y4x4 ⊕
y5x5 ⊕ x7, the codeword of VAMC contains 4 more redundant bits.
Remark 3.2: In a normal base Galois ﬁeld [20], square operation
can be achieved by the cyclic shift. As a result, f(y, x) in Theorem
3.1 can be slightly modiﬁed to reduce its hardware complexity of
computing f(y, x) using the following encoding equation
f(y, x) = y1x ⊕ y2x2 ⊕ y3x4 ⊕ · · · ⊕ ybx2(b−1) ⊕ x2b+1,
where y = (y1, y2, y3, . . . , yb) and yi ∈ GF(2m) (i = 1, 2, 3, . . . b);
x ∈ GF(2m); x ̸= 0, 1, where 1 is all 1 vector; f(y, x) ∈ GF(2m);
and 2m − 1 is a prime number and b < m.
This code reduces the computational complexity of decoding at
the cost of higher error masking probability, which is going up to
QVAMC = 2b(2m − 2)−1.
B. Algorithm for Single Error Correction and Estimation of Proba-
bilities of Miscorrection for the Proposed Codes
A direct approach is to add codewords to an existing AMD
code some additional redundant bits to provide for error correction,
(y, x, f(y, x), P) as an example. We will present another approach
which can detect and correct the errors in the codewords but will
requires less redundant bits.
1) Error correction algorithm for the proposed SEC-DED AMC
code: There are four parts in every codeword of the AMC code
constructed as in Theorem 3.1, namely y, πy ⊕ x, xP, and f(y, x).
For a codeword v = (v1, v2, v3, v4) of the AMC code VAMC
constructed in Theorem 3.1, there are
v1 = y = (y1, y2, y3, . . . , yb); yi ∈ GF(2m), i = 1, 2, 3, . . . , b;
v2 = πy ⊕ x; πy, x, v2 ∈ GF(2m);
v3 = xP; xP ∈ GF(2rH );
v4 = f(y, x); v4 ∈ GF(2m);
(x, xP) is a codeword of a linear Hamming code with distance 3
and the check matrix is H = [P T |I], where P T is the transposed
matrix of P and I is an identity matrix.
Denote the error vector by e = (e1, e2, e3, e4) and the received
message by ˜v = ( ˜v1, ˜v2, ˜v3, ˜v4), where ˜vi = vi ⊕ ei, i = 1, 2, 3, 4
and e1, ˜v1 ∈ GF(2bm); e2, ˜v2 ∈ GF(2m); e3, ˜v3 ∈ GF(2rH );
e4, ˜v4 ∈ GF(2m). We assume that we only need to correct the
errors in the information part v1 = y. The decoding procedure can
be divided into the following steps.
1) Calculate (˜u, ˜v3), where ˜u = π ˜v1 ⊕ ˜v2
2) Calculate SH = H(˜u, ˜v3)T , the syndrome for the Hamming
code.
Use SH as the input to the Hamming decoder, then obtain the
error locator ε, where ε ∈ GF(2m). Since ε is the output of
the Hamming decoder, there should be only one bit in ε which
is equal to one, and all other bits are zeros.
Let u = ˜u ⊕ ε = π ˜v1 ⊕ ˜v2 ⊕ ε, where u ∈ GF(2m). If
uncorrectable multi-bit errors are detected by the Hamming
decoder, then no further steps need to be performed. Otherwise,
go to the step 3.
3) Calculate SAMD as follows
SAMD = f(˜y, u) ⊕ ˜v4
= f(y ⊕ e1, x ⊕ πe1 ⊕ e2 ⊕ ε) ⊕ f(y, x) ⊕ e4. (3)
If both SH = 0 and SAMD = 0, then there are no errors.
If only SAMD = 0, there are multiple errors. Therefore, as
long as SAMD = 0, the correction procedure is completed.
Otherwise go to the next step.
4) Compare SAMD with εuj, for all j = 1, 2, 3, . . . , b.
a) If SAMD = εuj for some j ∈ {1, 2, 3, . . . , b}, then the
jth part yj ∈ GF(2m) of information ˜v1 ∈ GF(2bm)
of the codeword is distorted and the error in that part is
ε ∈ GF(2m), which means ˆyj = ˜yj ⊕ ε, where ˆyj ∈
GF(2m) is the corrected message.
b) Otherwise, there are multiple errors or the error is not
in the information part v1. No error correction will be
attempted.
The decision table for the proposed single error correction algo-
rithm is summarized in Table I
Example 3.2: (Single Error Correction)
Consider a proposed AMC code with b = 2, m = 3. VH is a (6, 3, 3)
18
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

TABLE I
CORRECTION ALGORITHM DECISION TABLE FOR SEC-DED AMC
SH
SAMD
Decision
SH = 0
SAMD = 0
No Error
SAMD ̸= 0
Double/Multiple Errors
SH ̸= 0 and
∀SAMD
Double/Multiple Errors
SH ̸= hi
I(∀i)
SH = hi
SAMD ̸= εuj
Single Error in v2, v3, or v4
or SAMD = 0
Or Double/Multiple Errors
SAMD = εuj
Single Error in v1
SAMD ̸= 0
(Correction)
I hi (1 ≤ i ≤ m) is the ith column of the parity check matrix
H of the Hamming code. This row is only valid for non-perfect
Hamming code.
Hamming code with P =


1
1
0
1
0
1
0
1
1

.
The encoding function is f(y, x) = y1x⊕y2x2⊕x5. The codeword
is in the format of v = ((y1, y2), πy ⊕ x, xP, f(y, x)), where
y1, y2, x, xP, f(y, x) ∈ GF(23). We select z3 ⊕ z ⊕ 1 as the
generating polynomial for GF(23), with the rightmost bit being the
least signiﬁcant bit.
Suppose y1 = (001), y2 = (001), x = (010). Then we have
πy ⊕ x = (001) ⊕ (001) ⊕ (010) = (010), (xP)T = (101), and
f(y, x) = (001)(010) ⊕ (001)(010)2 ⊕ (010)5 = (010) ⊕ (100) ⊕
(111) = (001). Thus, the original codeword is v = (v1, v2, v3, v4) =
(001001, 010, 101, 001).
Suppose there is a single error e = (000010, 000, 000, 000)
in the received message. Therefore, the distorted message is ˜v =
(001011, 010, 101, 001). We have (˜u, ˜v3) = (π ˜v1 ⊕ ˜v2, ˜v3) =
(000, 101).
SH = H(˜u, ˜v3)T = [P T |I](˜u, ˜v3)T = (101). After decoding
(˜u, ˜v3) using the Hamming decoder, we have ε = (010). And
u = π ˜v1 ⊕ ˜u ⊕ ε = (000) ⊕ (000) ⊕ (010) = (010). Then
syndrome SAMD = (001)(010) ⊕ (011)(010)2 ⊕ (010)5 = (011).
Since SAMD = εu2 = (010)(010)2 = 011, the error ε = (010) is
located at second bit of ˜y2.
The error is successfully corrected.
2) Estimations on a probability for the miscorrection: Suppose
v = (v1, v2, v3, v4), where v1 = y, v2 = πy ⊕ x, v3 = xP,
v4 = f(y, x) is a codeword for an AMC code VAMC described
in Theorem 3.1. Let e = (e1, e2, e3, e4) be the error vector and
˜v = { ˜v1, ˜v2, ˜v3, ˜v4} be the received (distorted) message, where
˜vi = vi ⊕ ei, i = 1, 2, 3, 4. Let e1 = (e11, e12, . . . , e1b), where
e1i ∈ GF(2m) for i ∈ {1, 2, . . . , b}. Denote the message after
correction, i.e., the output of the decoder by ˆv = ( ˆv1, ˆv2, ˆv3, ˆv4),
where e1, ˜v1, ˆv1 ∈ GF(2bm), e2,
˜v2,
ˆv2 ∈ GF(2m); e3,
˜v3,
ˆv3 ∈ GF(2rH ); e4, ˜v4, ˆv4 ∈ GF(2m).
We say that the error is miscorrected if c1 ̸= ˆc1. The miscorrection
probability can be deﬁned as
Qmc(y, e) = |{x|v1 ̸= ˆv1, e ̸= 0}|2−m,
(4)
where 2m is the number of possible values of x.
Theorem 3.2: Miscorrection Probability.
For the AMC code constructed by Theorem 3.1, the algorithm in
Section III-B1 has a miscorrection probability Qmc(y, e), at most
b(b + 1)(2m − 2)−1, maxy;e̸=0 Qmc(y, e) ≤ b(b + 1)(2m − 2)−1.
The proof of this theorem is based on the analysis of the algorithm
presented in Section III-B for the case SH ̸= 0, SH ̸= hi for each i
(see Table I).
The AMC code for Theorem 3.1 can be extended to be a code with
Hamming distance 4 by adding one more overall parity bit after which
the code can correct single error and at the same time detect all double
errors without miscorrection of double errors. The error detection
and correction capabilities for the extended SEC-DED AMC code is
summarized in Table II.
TABLE II
ERROR DETECTION AND CORRECTION CAPABILITIES FOR SEC-DED
AMC CODE
Number
Error
Errors
Errors in
Errors
of errors
in parity
in v1
v2 and/or v3
in v4
I
Single
Detected
Corrected
DetectedII
Detected
Double
Detected. No miscorrection.
Multiple
Detected with a probability 1 − QVAMC.III
even
No miscorrection.
Multiple
Detected with a probability 1 − Qmc.IV
odd
Miscorrected with a probability Qmc.
I If errors are located only in the v4, no errors in the other parts
of codeword c, these errors will always be detected.
II Here if we assume there is only a single error, then when the
error is not in v1, it is in v2 or v3 and can be corrected.
III QVAMC
is
the
maximum
error
masking
probability.
QVAMC = (b + 1)2−m
IV Qmc is the error miscorrection probability.
Qmc ≤ b(b + 1)2−m
Remark 3.3: We note that the straightforward concatenation ap-
proach for construction of AMC codes with distance 3 based on
adding redundant bits to AMD code requires more redundancy than
codes constructed by Theorem 3.1.
For the straightforward concatenation approach (y, x, f(y, x), P),
the redundant parts are x, f(y, x) and P, in which P is the Hamming
redundant part for (y, x, f(y, x)) as the information part. Which
means the redundant bits are 2m + ⌜log2(mb + 2m + 1)⌝ for the
straightforward concatenation approach. For the proposed architec-
ture, the redundant parts are π⊕x, xP and f(y, x), the redundant bits
number is 2m+⌜log2(m+1)⌝. For large b, the proposed architecture
will save much more area than the straightforward concatenation
approach.
C. Double Error Correction Algorithm and Estimations on the Prob-
ability of Miscorrection
1) Error correction algorithm: We note that the proposed AMC
codes with overall linear parity bit can be used to correct double
errors with a multiple-iteration algorithm. In this case the syndrome
SH for a Hamming code with distance 3 could be the sum of two
columns hi1 and hi2 of the check matrix H, where i1 and i2 indicate
the location of two errors.
For the proposed code, besides the syndrome for the Hamming
code, we may use the syndrome for the AMD code to verify the
location of the double error. After computing the syndrome, we can
try all pairs (i1, i2) such that hi1 +hi2 = SH and if for one of them
the corresponding AMD syndrome SAMD = 0, it indicates that the
double error is at the position i1 and i2.
We need to try all pairs of hi1 and hi2 with the same sum SH =
hi1 + hi2. To achieve smaller number of iterations, we would like
to make the number of pairs as small as possible. For a non-prefect
Hamming code, we would like to select the check matrix H, such
19
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

that
min
H max
SH |{(i1, i2)|SH = hi1 ⊕ hi2}|,
(5)
where maxSH |{(i1, i2)|SH = hi1 ⊕ hi2}| indicates the maximum
possible number of iterations.
We are able to pre-compute a lookup table for a ﬁxed H for a
Hamming code to simplify the locating of double errors for a given
SH.
Example 3.3: For a (11,7,3) shortened Hamming code with check
matrix
H =


1
0
1
0
1
0
1
0
1
0
1
1
1
0
0
1
1
0
0
1
1
0
0
0
0
0
1
1
1
1
0
0
0
1
1
1
1
0
0
0
0
0
0
0

.
we have maxSH |{(i1, i2)|SH = hi1 ⊕ hi2}| = 3.
For another (11,7,3) shortened Hamming code with check matrix
H =


0
1
0
1
0
1
0
0
1
0
1
0
1
1
0
0
1
1
0
1
1
0
1
0
0
0
0
1
1
1
0
0
0
1
1
1
1
1
0
0
0
0
0
0

.
we have maxSH |{(i1, i2)|SH = hi1 ⊕ hi2}| = 2
Clearly, the second check matrix results in a smaller number of
iterations to ﬁnd the corrected error vector.
There are ﬁve parts (with the overall linear parity bit) in every
codeword of the AMC code constructed as in Theorem 3.1, namely
y, πy ⊕ x, xP, f(y, x) and the overall parity. For a codeword v =
(v1, v2, v3, v4, v5) of the extended AMC code VAMC constructed in
Theorem 3.1, there are
v1 = y = (y1, y2, y3, . . . , yb); yi ∈ GF(2m), i = 1, 2, 3, . . . , b;
v2 = πy ⊕ x; πy, x, c2 ∈ GF(2m);
v3 = xP; xP ∈ GF(2rH );
v4 = f(y, x); v4 ∈ GF(2m);
v5 = Π(v1, v2, v3, v4)
(x, xP) is a codeword of a linear Hamming code with distance 3
and the check matrix is H = [P T |I], where P T is the transposed
matrix of P and I is an identity matrix. v5 is the overall linear parity
bit.
Denote the error vector by e = (e1, e2, e3, e4, e5) and received
message by ˜v = ( ˜v1, ˜v2, ˜v3, ˜v4, ˜v5), where ˜vi = vi ⊕ ei, i =
1, 2, 3, 4, 5 and e1, ˜v1 ∈ GF(2bm); e2, ˜v2 ∈ GF(2m); e3, ˜v3 ∈
GF(2rH ); e4, ˜v4 ∈ GF(2m); e5, ˜v5 ∈ GF(2). We assume that we
only need to correct the errors in the information part c1 = y. The
decoding procedure can be divided into the following steps.
1) if the the overall parity indicates that there are errors with even
multiplicities, go to step 2, otherwise it may be a single error.
2) calculate (˜u, ˜v3), where ˜u = π ˜v1 ⊕ ˜v2
3) calculate SH = H(˜u, ˜v3)T , the syndrome for the Hamming
code.
4) use SH as the input to a lookup table, then we can obtain some
pairs of error locators εi1, and εi2where εi1, εi2 ∈ GF(2m),
for some i1 and i2, such that SH = hi1 ⊕ hi2, where hi1 and
hi2 are the ith
1
and ith
2
column respectively of the Hamming
check matrix H.
εi1 (as well as εi2) is an m-bit vector with 1 in the only ith
1
(or ith
2 ) bit and 0 in all other bits.
Let u = ˜u ⊕ εi1 ⊕ εi2 = π ˜v1 ⊕ ˜v2 ⊕ εi1 ⊕ εi2, where u ∈
GF(2m).
If there are no such pairs in the look-up table, then no further
steps need to be performed. The error is not correctable by this
algorithm. Otherwise, go to the step 5.
5) calculate SAMD as follows
SAMD = f(˜y, u) ⊕ ˜v4
= f(y ⊕ e1, x ⊕ πe1 ⊕ e2 ⊕ εi1 ⊕ εi2) ⊕ f(y, x) ⊕ e4.
(6)
If both SH = 0 and SAMD = 0, then there are no errors.
Therefore, as long as SAMD = 0, the correction procedure is
completed. Otherwise go to the next step.
6) Compare SAMD with εi1uj1 ⊕ εi2uj2, for all j1, j2
∈
{1, 2, 3, . . . , b}. If
SAMD = εi1ui1 ⊕ εi2uj2
(7)
for some j1, j2 ∈ {1, 2, 3, . . . , b}, then the yj1, yj2 ∈ GF(2m)
of information ˜v1 ∈ GF(2bm) of the codeword are distorted
and the error in those parts are εi1, εi2 ∈ GF(2m) respectively.
That means ˆyj1 = ˜yj1 ⊕ εi1, and ˆyj2 = ˜yj2 ⊕ εi2,where
ˆyj1, ˆyj2 ∈ GF(2m) are the corrected messages.
7) If no j1, j2 are found, go back to step 4, try another pair εi1, εi2
for the same SH.
8) If no εi1, εi2 satisfy (7), then the errors are not correctable for
this algorithm.
Example 3.4: Consider
an
extended
proposed
AMC
code
with b = 2, m = 7. VH is a (11, 7, 3) Hamming code with
H =


0
1
0
1
1
0
1
1
0
0
0
0
1
1
0
1
1
1
0
1
0
0
1
0
0
0
1
1
0
0
0
1
0
1
1
1
1
0
0
0
0
0
0
1

.
The encoding function is f(y, x) = y1x⊕y2x2⊕x5. The codeword
is in the format of v = ((y1, y2), πy ⊕x, xP, f(y, x), πv), where y1,
y2, x, f(y, x) ∈ GF(27), xP ∈ GF(24) and πv is the overall parity.
We select z7 ⊕z3 ⊕1 as the generating polynomial for GF(27), with
the rightmost bit being the least signiﬁcant bit.
Suppose y1 = (0000110), y2 = (0000011), x = (0000010).
Then we have πy ⊕ x = (0000110) ⊕ (0000011) ⊕ (0000010) =
(0000111), xP = (0110), and f(y, x) = (0000110)(0000010) ⊕
(0000011)(0000010)2 ⊕ (0000010)5 = (0100000).
Thus, the original codeword is v
=
(v1, v2, v3, v4, v5)
=
((0000110, 0000011), 0000111, 0110, 0100000, 1). Suppose there is
a double error e = ((0000001, 0001000), 0000000, 0000, 0000000)
in the received message. Therefore, the distorted message is
˜v = ((0000111, 0001011), 0000111, 0110, 0100000, 1). We have
(˜u, ˜v3) = (π ˜v1 ⊕ ˜v2, ˜v3) = (0001011, 0110). SH = H(˜u, ˜v3)T =
[P T |I](˜u, ˜v3)T = (0101)T . The overall pairty shows that there is an
error with a number of erroneous bits being even.
Since the rightmost bit is the least signiﬁcant bit, we have the
following lookup table for error locations.
SH
i1
i2
0101
1
4
2
7
Then let i1 = 1 and i2 = 4, then εi1 = (0000001) and εi2 =
(0001000). We have u = ˜u⊕εi1 ⊕εi2 = (0000010), and SAMD =
˜v4 ⊕ f( ˜v1, u) = (0100010). Let j1 = 1 and j2 = 2, we have
εi1uj1 ⊕ εi2uj2 = (0000001)(0000010) ⊕ (0001000)(0000100) =
(0100010).
Therefore we know that the error εi1 locates at y1 and εi2 locates
at y2. Actually, since u = (0000010), if i1 = 1 and i2 = 4, then
SAMD = (0100010) = εi1uj1 + εi1uj1 only if j1 = 1 and j2 =
2. If i1 = 2, i2 = 7, then εi1uj1 + εi1uj1 = ε2uj1 + ε7uj2 ̸=
20
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

SAMD = (0100010) for any j1, j2. The corrected message is ˆv =
((0000110, 0000011), 0000111, 0110, 0100000, 1).
In this example, we need at least 7 clock cycles to ﬁnd the double
error for the best case. Correspondingly, we will need 2+17∗(14+
3) = 291 cycles to locate the double error for the worst case.
2) Estimations on the probability of miscorrection: In this section
we estimate the upper bound for the probability that any error is
miscorrected into a double error in the information part.
Theorem 3.3: For the algorithm of double error correction pre-
sented in Section III-C, the miscorrection probability Qmc for any
given pair e and y will be Qmc ≤ (2m − 2)−1max(b2np(b +
1), 0.5b(b − 1)m(b + 1)).
The estimated Qmc gives the upper bound for the miscorrection
probability. Note that, a double error in the information part may be
also miscorrected into another double error in the information part
with the same miscorrection probability.
Example 3.5: (Miscorrection Probability) For an extended pro-
posed AMC code with b = 2, m = 7, the check matrix for
the (11, 7, 3) Hamming code is the same as in Example 3.4. The
encoding function is f(y, x) = y1x ⊕ y2x2 ⊕ x5, we have np = 2.
Since b2np(b+2) = 32 > 0.5b(b−1)m(b+2) = 28, the maximum
miscorrection probability is Qmc = (b2np(b+2))(2m −2)−1 =
32
126
for a given error e and a given information part y.
We conducted simulation experiments to estimate the probabilities
of miscorrecting one double error into another one for m = 2, b = 2
and H as deﬁned above with np = 3. All possible combinations of
y and e are tested to see the number of random numbers x such that
the errors are miscorrected.
The real miscorrection probability is Qmc =
10
126 ≈ 0.08, which is
smaller than the estimated miscorrection probability is Qmc =
32
126.
Example 3.6: For an extended proposed AMC code with b = 4,
m = 17, the check matrix for the (22, 17, 3) Hamming code H =
[22, 21, · · · , 2, 1], and encoding function f(y, x) = y1x⊕y2x2⊕x5,
we have np = 6.
Since b2np(b + 2) = 576 ≤ 0.5b(b − 1)m(b + 2) = 612, the
maximum miscorrection probability is Qmc = (0.5b(b − 1)m(b +
2))(2m − 2)−1 =
612
217−2 for a given error e and a given information
part y.
A simulation was conducted to test the real miscorrection prob-
ability for a double error in the information part is miscorrected
into another double error in the information part. 10, 000 random
combinations of y and e have been tested to see the number of random
numbers x such that the errors are miscorrected.
The evaluated miscorrection probability is Qmc =
131
217−2 ≈ 0.001,
which is again much smaller than the estimated miscorrection proba-
bility Qmc =
612
217−2. We also note this miscorrection probability for
double errors is small and converges to 0 very fast as the number
of random bits m grows, thus the proposed code may be used for
double-error-correction.
We
note
that
compared
with
the
direct
construction
(y, x, f(y, x), P),
the
proposed
architecture
can
protect
the
f(y, x) at the same time while requires less redundant bits.
IV. HARDWARE DESIGN OF RELIABLE AND SECURE MEMORIES
BASED ON THE PROPOSED AMC CODES
A. Hardware implementation
Figure 2 presents the architecture for memories protected by the
proposed code in Theorem 3.1. In cryptographic applications, the m
random digits can be generated by a random number generator (RNG)
which is already integrated in most of the modern cryptographic de-
vices. During a WRITE operation, the encoder loads the information
bits and the random bits, then generates the redundant bits which are
saved in the redundant memory block. The redundant bits are split
into two parts, the linear part (πy ⊕ x, xP) which contains m + rH
bits and the nonlinear part f(y, x) which contains m bits. During
a READ operation, the Error Correcting Network block computes
the syndrome of the retrieved data and executes the error correction
algorithm. If uncorrectable errors occur, ERR will be asserted and no
correction will be attempted.
Fig. 2.
Memory protected by the proposed code (the memory, redundant
memory and the encoder may be under attack).
The encoder for the proposed code is presented in Figure 3. The
Πv is the overall parity check of the system. The inputs to the encoder
are the information bits y and the random number x. The encoder
for the proposed AMC code contains the Hamming encoder and the
AMD encoder to calculate f(y, x). The AMD encoder requires b
Galois ﬁeld multipliers for GF(2m) to calculate the products of y
and xi and additional circuits to generate xi.
The proposed code with distance 4 is a SEC-DED code, and only
single error in the information part will be corrected. So if there
are multiple errors or the single-bit error is not in the information
part, the decoder sends the uncorrected messages to the output ports,
and set the error ﬂag (ERR). (ERR should be asserted iff there are
uncorrectable errors.) The error ﬂag signal will be used for the error
handling, which is discussed in previous part of this paper. If there are
even number errors, i.e., the overall parity bit c5 is zero, no correction
will be attempted.
To calculate the products between yi and xi in f(y, x), for i ∈
{1, 2, . . . , b}, b multipliers in GF(2m) are required. The computation
of εui requires another b multipliers. We note that multipliers can be
reused to reduce the area complexity at the cost of a larger decoding
latency as more clock cycles are required. However, due to the reused
hardware, a ﬁnite state machine should be introduced. If we do not
reuse the multipliers, the architecture could be pipelined.
21
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

Fig. 3.
Encoder without overall parity check bit for the proposed code
B. Comparison of the secure SEC-DED memories based on proposed
codes with memories based on the known codes
In this section we compare the security levels in terms of the
numbers of undetectable errors, sizes of security kernels and mis-
correction probabilities, for the proposed codes VAMC of distance
4 with additional overall check parity to the known nonlinear SEC-
DED robust codes (extended Vasil’ev and extended Phelps) presented
in [22]. The hardware overheads in terms of area, power and latency
for encoders and decoders of different codes are also compared in
this section. Transmission rates are also compared. All codes have
distance 4. All the robust codes compared are (39, 32, 4) codes [22].
For the proposed code, the number of information bits k = bm =
35, the number of random bits is m = 7, the degree of f(y, x) is
b = 5, the Hamming code used is a (11, 7, 3) Hamming code. Overall
parity is added to achieve Hamming distance four.
There are 35+7+7 = 49 bits for the AMD part of the codes. The
Hamming code used for error correction part is a (55, 49, 3) code.
Overall parity is also added to achieve Hamming distance four.
TABLE III
SIZES OF DETECTION KERNELS AND SECURITY KERNELS AND
MISCORRECTION PROBABILITIES FOR DIFFERENT CODES
Codes
|KD|I
|KV |II
Qmc
III
Extended Hamming IV
232
32(232 − 1)
1
Extended Vasil’ev IV
26
≈ 12(232 − 1)
0.5
Extended Phelps IV
227
32(227 − 1)
1/16
Proposed code
0
0
30/126
I |KD| is the number of undetectable errors (size of detec-
tion kernel)
II |KV | is the size of security kernel
III Qmc is the miscorrection probability
IV Data are obtained from [22]
Table III compares the sizes of detection kernels, i.e., the number of
undetected errors, the sizes of security kernels and the miscorrection
probability for the Hamming code, robust codes from [22], and the
extended proposed code VAMC with above parameters. It follows
from the table that the proposed code is the best one providing good
security for the strong attack model, as the code has zero size of
the security kernel. The miscorrection probability for the proposed
code is slightly worse than for the extended Phelps code, but it is
still better than for the extended Vasil’ev code [22] and the Hamming
code. Moreover, our code has no errors which are always undetected
or miscorrected.
The encoder and the decoder for the proposed codes have been
modelled in Verilog and synthesized in Cadence Encounter RTL
Compiler with the Nangate 45nm Opencell library version v2009 07.
The designs were placed and routed using Cadence Encounter. The
latencies, the area overhead and the power consumptions of the
encoders and the decoders were estimated using Concurrent Current
Source (CCS) model under typical operation condition assuming a
supply voltage of 1.1V and a temperature of 25 Celsius degree. The
synthesis results for the encoder and decoder are shown in Table IV
and Table V respectively. Those results were all obtained based on
same simulation condition.
TABLE IV
SYNTHESIS RESULTS FOR ENCODERS
Architectures
Latency
Area
Power
(ns)
(um2)
(mW)
Extended Hamming I
0.290
282.2
0.2898
Extended Vasil’ev I
0.367
296.1
0.2916
Extended Phelps I
0.429
383.0
0.4728
Proposed code
1.000
2246.6
3.444
(smaller latency)
Proposed code
1.860
1573.9
1.044
(lower power)
I Data for the robust codes and the extended Ham-
ming code are obtained from [22]
From Table IV, we can see that comparing to the extended Phelps
code, the extended AMC code with distance four requires at least
161% increase in the latency. When optimizing the area and power,
the latency increases to 433% of Extended Phelps Code encoder.
The encoder of the extended proposed code also requires at least
310% more area and 121% more power than the encoder of the
Extended Phelps code. This is the cost required to provide for the
strong security.
We implemented the decoders for the proposed SEC-DED AMC
codes with three proﬁles. One emphasizes the overall latency, another
forces on the clock speed, and the third one requires the smallest area
as well as power. To achieve the fastest clock speed, the decoder is
pipelined. From Table V, we see that the smallest clock cycle of
the decoder of our code is 1.096 ns, which is 64% more than the
extended Phelps code, while 130% more area and 370% more power
are used. On the other hand, sacriﬁcing the clock speed, the decoder
requires only 58% more area and 30% more power than the extended
Phelps code. With 80% more area and 120% more power, we note
that we can achieve the smallest overall latency, which is 1.971 ns.
From the results presented in this section one can see that the
proposed AMC codes provide for better security (see Table III) but
require larger overhead in latency, area and power (see Table III and
Table II) than the known SEC codes (Hamming, Vasil’ev and Phelps).
C. Case studies for the proposed code
Figure 4 shows the transmission rate for different numbers of
information bits for the extended Hamming code which is the same
as the extended robust codes from [22] and the proposed SEC-DED
22
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

TABLE V
SYNTHESIS RESULTS FOR DECODERS
Architectures
Latency
Area
Power
(ns)
(um2)
(mW)
Extended Hamming I
0.538
620.3
0.7119
Extended Vasil’ev I
0.652
763.2
0.8340
Extended Phelps I
0.670
1799.8
1.774
Proposed code
1.971
3272.9
4.056
(smaller latency)
Proposed code
1.096×2II
4215.6
8.49
(faster clock)
Proposed code
2.000×2II
2846.7
2.312
(lower power)
Double error correction
0.917
11669.7
4.402
for Proposed Code
I Data for the robust codes and the extended Hamming code
are obtained from [22]
II ”×2” means there are two pipeline stages and the number
in front indicates the clock speed.
AMC codes with distance 4 with three different parameter sets. One
code uses m = 7 random bits, and (11,7,3) Hamming code. For
another proposed code, we use m = 17 random bits and (22,17,3)
Hamming code. The third proposed code use m = 19 random bits
and (24,19,3) Hamming code. (We need that 2m−1 will be a prime.)
The degree b of nonlinear function of the proposed codes varies with
the number of information bits.
Fig. 4.
Memory Overhead
The proposed codes require more redundant bits than the extended
Hamming code, however as the number of information bits increases,
the transmission rate of the proposed codes dramatically increases,
since the number of redundant bits for the proposed codes depends
on only m and does not depend on the number of information bits
k = bm as b increases. As k goes to inﬁnity, the transmission rate
of the proposed codes approaches one.
In order to decrease the probability for the missing, we can increase
the number of random bits m. Moreover, in order to obtain a reason-
able transmission rate, the degree b of the nonlinear function f(y, x)
should also be increased. Since QVAMC = (b + 1)(2m − 2)−1, the
denominator increases exponentially with m, while the numerator
increase linearly with b.
In the remainder of this section we consider the problem of the
optimal selection of parameters m and b for a given number k of
information bits for the proposed codes.
With the same m, as b increases, additional multipliers are required
for f(y, x) and the complexity for the encoder and the decoder
are increasing. Additionally, an increase in the length k of the
information part will result in an increase of the probability of
multiple-bit random errors, which diminishes utility of SEC-DED
codes. Therefore when choosing the parameters of the code, we
should balance the transmission rate and the encoder and decoder’s
hardware complexities, security and reliability demands.
We propose the codes balancing these secure and reliable demands,
with parameters listed in Table VI.
TABLE VI
PARAMETERS FOR THE PROPOSED CODES
k
m
m + rH
b
QVAMC
Qmc
68
17
22
4
6(217 − 2)−1
30(217 − 2)−1
136
17
22
8
10(217 − 2)−1
90(217 − 2)−1
204
17
22
12
14(217 − 2)−1
182(217 − 2)−1
272
17
22
16
18(217 − 2)−1
306(217 − 2)−1
76
19
24
4
6(219 − 2)−1
30(219 − 2)−1
133
19
24
7
8(219 − 2)−1
56(219 − 2)−1
209
19
24
11
12(219 − 2)−1
132(219 − 2)−1
266
19
24
14
16(219 − 2)−1
240(219 − 2)−1
The hardware overhead for the encoders and the decoders for those
SEC-DED codes are shown in Table VII and Table VIII respectively,
under the same simulation condition as in Section IV-B. Note that the
architectures here are not pipelined. (The pipelined version may use
faster clock.) And we do not use the Horner scheme to implement
the AMD encoding functions in order to achieve a smaller overall
latency. We may also sacriﬁce the area and power to achieve a smaller
latency.
TABLE VII
ENCODER OVERHEAD FOR THE PROPOSED CODES
Parameters of the codes
Latency
Area
Power
(ns)
(um2)
(mW)
m=17, b=4
2.623
5495
1.509
m=17, b=8
4.375
11375.2
3.968
m=17, b=12
4.403
16709.6
7.145
m=17, b=16
4.799
23578.8
11.23
m=19, b=4
3.181
7013.6
2.522
m=19, b=7
4.914
13788.1
6.052
m=19, b=11
4.945
20253.5
10.898
m=19, b=14
5.419
28587.9
17.128
Additionally, we note that the data output from the memory can
be directly forwarded to other parts of the system, before the decoder
generates its outputs. When errors are detected or corrected by the
decoder, the processor can be stalled and the data can be re-fetched
from the decoder. In this case, when no errors occur, the decoder
does not affect the performance of the system in term of the latency.
We may take advantage of this when our code is used for a memory,
when the random access is frequently required.
V. CONCLUSIONS
In this paper, we show a reliable and secure memory architecture
based on robust algebraic manipulation correction (AMC) codes.
We describe the constructions of robust AMC codes, estimate their
parameters (error detection and/or correction probabilities, etc) and
23
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

TABLE VIII
DECODER OVERHEAD FOR THE PROPOSED CODES
Parameters of the codes
Latency
Area
Power
(ns)
(um2)
(mW)
m=17, b=4
5.421
9040
1.761
m=17, b=8
7.455
17376
4.411
m=17, b=12
7.594
26389
7.487
m=17, b=16
8.127
35446
11.25
m=19, b=4
6.051
10500
2.372
m=19, b=7
6.666
19609
5.072
m=19, b=11
7.565
30568
9.68
m=19, b=14
8.886
38363
12.18
present the robust error correction algorithm for these codes. For
the presented codes any error for any user deﬁned message can be
detected with a probability exponentially converging to one. Any
repeating error (error with a high laziness) can be corrected with
a probability converging to one as PR or the number of redundant
bits r grows. The area, power consumption and the latency for
the encoder and the syndrome computation circuit are studied. The
described architecture is suitable for the protection of the most
security/reliability critical part (which is usually a small portion of
the system) of the memory in many applications, where the error
model is unpredictable (e.g., memories in cryptographic devices that
may suffer from fault injection attacks) or the multi-bit error rate is
high or difﬁcult to estimate (e.g., nano-scale memories).
ACKNOWLEDGEMENT
The work of the third author is sponsored by the NSF grant CNS
1012910.
REFERENCES
[1] T.R.Halfhil, “Z-ram shrinks embedded memory,” Microproces-
sor Report, Tech. Rep., Oct 2005.
[2] S.K.Moore, “Masters of memory,” IEEE Spectrum, vol. 44,
no. 1, pp. 45–49, Jan 2007.
[3] A. H. Johnston, “Scaling and technology issues for soft error
rates,” ser. 4th Annual Research Conference on Reliability,
2000.
[4] A. Eto, M. Hidaka, Y. Okuyama, K. Kimura, and M. Hosono,
“Impact of neutron ﬂux on soft errors in mos memories,” in
Electron Devices Meeting, 1998.
[5] S. Satoh, Y. Tosaka, and S. A. Wender, “Geometric effect of
multiple-bit soft errors induced by cosmic ray neutrons on
drams,” June 2000.
[6] G. M. Swift, “In-ﬂight observations of multiple-bit upset in
drams,” IEEE Trans. Nuclear Science, vol. 47, 2001.
[7] G. Georgakos, P. Huber, M. Ostermayr, E. Amirante, and
F. Ruckerbauer, “Investigation of increased multi-bit failure rate
due to neutron induced seu in advanced embedded srams,” in
Symposium on VLSI Circuits Digest of Technical Paper, 2007.
[8] J. Maiz, S. Hareland, K. Zhang, and P. Armstrong, “Characteri-
zation of multi-bit soft error events in advanced srams,” in IEEE
Int’l Electronic Device Meeting, December 2003, pp. 519–522.
[9] H. Bar-El, H. Choukri, D. Naccache, M. Tunstall, and C. Whe-
lan, “The sorcerers apprentice guide to fault attacks,” 2002.
[10] S. Skorobogatov, “Optical fault masking attacks,” Workshop on
Fault Diagnosis and Tolerance in Cryptography, pp. 23–29,
2010.
[11] Y. Emre and C. Chakrabarti, “Memory error compensation
techniques for jpeg2000,” in Signal Processing Systems (SIPS),
2010 IEEE Workshop on, 2010, pp. 36–41.
[12] R. T. Chien, “Memory error control: beyond parity,” Spectrum,
IEEE, vol. 10, no. 7, pp. 18–23, 1973.
[13] Y. Bentoutou, “Efﬁcient memory error coding for space com-
puter applications,” in Information and Communication Tech-
nologies, 2006. ICTTA ’06. 2nd, vol. 2, 2006, pp. 2347–2352.
[14] M. G. Karpovsky and A. Taubin, “New class of nonlinear
systematic error detecting codes,” IEEE Transactions on Infor-
mation Theory, vol. 50, no. 8, pp. 1818–1820, 2004.
[15] Z. Wang, M. Karpovsky, and A. Joshi, “Reliable MLC NAND
ﬂash memories based on nonlinear t-error-correcting codes,”
in Dependable Systems and Networks, IEEE/IFIP International
Conference on, 2010.
[16] Z. Wang and M. Karpovsky, “Algebraic manipulation detection
codes and their applications for design of secure cryptographic
devices,” in On-Line Testing Symposium (IOLTS), 2011 IEEE
17th International, july 2011, pp. 234 –239.
[17] G. Shizun, W. Zhen, L. Pei, and K. Mark, “Secure memories
resistant to both random errors and fault injection attacks
using nonlinear error correction codes,” in Proc. Workshop on
Hardware and Architectural Support for Security and Privacy,
HASP 2013, 2013.
[18] W. Zhen and M. Karpovsky, “Reliable and secure memories
based on algebraic manipulation correction codes,” in On-Line
Testing Symposium (IOLTS), 2012 IEEE 18th International,
2012, pp. 146–149.
[19] R. Cramer, Y. Dodis, S. Fehr, C. Padr, and D. Wichs, “Detection
of algebraic manipulation with applications to robust secret
sharing and fuzzy extractors,” in Advances in Cryptology C
EUROCRYPT 2008, ser. Lecture Notes in Computer Science,
N. Smart, Ed.
Springer Berlin / Heidelberg, 2008, vol. 4965,
pp. 471–488.
[20] Z. Wang and M. Karpovsky, “Algebraic manipulation detection
codes and their applications for design of secure cryptographic
devices,” in IEEE 17th International On-Line Testing Sympo-
sium (IOLTS), 2011, pp. 234–239.
[21] J.
L.
Vasil’ev,
“On
nongroup
close-packed
codes,”
in
Probl.Kibernet., vol. 8, 1962, pp. 375–378.
[22] Z. Wang, M. Karpovsky, and K. Kulikowski, “Design of memo-
ries with concurrent error detection and correction by nonlinear
SEC-DED codes,” Journal of Electronic Testing, pp. 1–22, 2010.
24
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-301-8
DEPEND 2013 : The Sixth International Conference on Dependability

