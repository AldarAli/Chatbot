Can We Monitor Crew Situational Awareness During Flight? 
 
Exploring the use of behavioural markers 
 
Tanja J. J. Bos 
Training, simulation and operator performance 
National Aerospace Laboratory NLR 
Amsterdam, The Netherlands 
e-mail: Tanja.Bos@nlr.nl 
Antoine J. C. de Reus 
Training, simulation and operator performance 
National Aerospace Laboratory NLR 
Amsterdam, The Netherlands 
e-mail: Antoine.de.Reus@nlr.nl 
 
 
Abstract— Is it possible to automatically and non-intrusively 
observe flight crew behaviour in the cockpit in order to 
monitor 
their 
Situational 
Awareness 
during 
flight? 
This work in progress investigates the possibility to 
automatically monitor flight crew Situational Awareness (SA). 
The monitoring tool is to automatically analyse the Situational 
Awareness of both pilots on the basis of their visual scanning, 
their interaction with cockpit systems and their speech. Visual 
scanning is an indicator for the first level of Situational 
Awareness (perception), which is a necessary basis for higher 
levels 
of 
Situational 
Awareness 
(comprehension 
and 
projection). The timing of pilot interactions with cockpit 
systems as well as speech could be indicators of these higher 
levels of Situational Awareness. The question we would like to 
answer in our work is: can we establish a common behavioural 
pattern within a flight crew that indicates optimal SA and can 
we use this as a reference to identify reduced SA? And, if this 
proves to be impossible, is an individual reference pattern 
possible and is that a suitable alternative? 
 
Keywords- 
crew 
monitoring; 
Situational 
Awareness; 
modelling. 
I. 
 INTRODUCTION 
Continuous combined efforts by the aviation community 
have resulted in the achievement of a safety record in air 
transport that is unequalled by other modes of transport. In 
recent years, although these efforts continue unabated, the 
accident rate seems to have reached a stable rate of about 2 
accidents per ten million flights [1]. With air transport 
foreseen to grow in the coming decades (4.7% to 5.0% per 
year), this accident rate, while very low, will translate to 
several major incidents and accidents per week. 
A fundamental pillar in aviation safety is the 
requirement that no single failure should result in a 
catastrophic accident, i.e., the write-off of an aircraft and 
multiple fatalities. During aircraft type certification the 
manufacturer must prove to the aviation authorities that the 
probability of a system failure is below a threshold that is 
inversely related to the severity of the consequences. For 
example, potentially catastrophic failures must have a 
probability of less than one occurrence in every 100.000.000 
flight hours. 
Aircraft systems have become so reliable, that human 
error has become more prominent in statistical analyses of 
factors contributing to accidents. Thus, a large percentage of 
recent accidents can be linked somehow to a human factors 
issue, such as poor perception of the environment, 
inadequate 
crew 
coordination, 
excessive 
workload, 
misunderstanding of an evolving situation and inappropriate 
training. 
Even in case of two well-trained pilots, complex and 
high workload conditions are not uncommon today. 
Especially in these conditions, optimum crew action 
depends on an adequate understanding of the situation at 
hand and the corrective actions that are needed. Monitoring 
crew status in flight is therefore considered one of the 
enablers for enhancing overall safety. When suboptimal 
crew status is indicated, the crew could be assisted. In this 
work, we particularly look at crew Situational Awareness 
(SA). 
The overall objective of the work is to automatically 
monitor the pilots’ state in a non-intrusive way. This 
includes constructs such as flight crew’s presence in their 
seats, physical state, drowsiness, workload, distraction, etc. 
Situational Awareness is one of these constructs. So far, it is 
not possible to directly measure Situational Awareness in a 
non-intrusive way. Thus, Situational Awareness is usually 
assessed using ratings by an observer or using self-ratings 
and questionnaires, such as Situation Awareness Rating 
Technique (SART) and Crew Awareness Rating Scale 
(CARS). These measurements are neither automatic nor 
non-intrusive and not suitable for day to day use in an 
airline cockpit. In this operational environment, Situational 
Awareness should be inferred from automatic behavioural 
analysis of non-intrusive measurements. 
This paper describes the work in progress. The sections 
included describe: the concept of SA (2), the operational 
context (3), the potential observables for SA (4), the 
implementation of the tool in the operational context (5),  
the method used (6) and the last section the status at the 
time of writing.  
68
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

II. 
SITUATIONAL AWARENESS 
One of the most widely accepted definitions of 
Situational Awareness is that of Endsley [2]: “the 
perception of the elements in the environment within a 
volume of time and space, the comprehension of their 
meaning, and the projection of their status in the near 
future”. 
 
This definition includes three levels of SA: 
 
Level 1, Perception – This is the basic information 
that is required for Situational Awareness, being 
able to notice events, people, objects in the external 
environment. This level simply represents the 
collection of basic data. 
 
Level 2, Comprehension – Once an event, or 
object, has been perceived, it is necessary to 
understand the meaning of that object in the 
situation. This represents the interpretation of the 
basic data that is collected through perception.  
 
Level 3, Projection – The third level of Situational 
Awareness represents the ability to project the 
interpretation of the current situation into the 
future. This level of Situational Awareness is 
required to be able to predict the effect of the 
information that is currently available onto the 
future situation. 
 
Situational Awareness of pilots has been assessed during 
many flight simulation experiments, but monitoring it 
automatically and non-intrusively in an operational 
environment is the challenge of this work in progress. 
 
III. 
THE PROCEDURAL CHARACTER OF FLYING 
The tasks of a pilot consist of actions necessary to fly the 
aircraft, to navigate, to communicate and to manage 
systems. Crew behaviour in the cockpit is largely driven by 
procedures. These procedures are dependent on the flight 
phase and are influenced by the environment (e.g., weather, 
terrain), external events (e.g., ATC commands) and the 
aircraft state (e.g., speed, fuel, systems status). 
Crew behaviour is also driven by crew resource 
management. One pilot is responsible for flying the aircraft 
and the other for other tasks such as the communication 
(with the cabin and outside world), and managing systems. 
The pilots in their roles have complementary tasks, but both 
need to assure themselves that primary flight parameters are 
within the acceptable range. Together they are responsible 
for a safe flight execution. 
Descents, approaches and landings are the more busy 
flight phases, which consist of a relatively predictable 
number of actions and the use of checklists. Depending on 
the type of technology available on the airport and other 
conditions such as visibility, the type of landing, the level of 
automation is selected. The different landings may require 
different procedures but it is expected that roughly the 
visual information acquisition behaviour is similar.  
 
IV. 
OBSERVABLES 
Much of the information that is available in the cockpit 
is of the visual modality. Hence, the crew’s scanning pattern 
and visual focus points are an important method of 
observing the crew’s attention. The crew’s scanning pattern 
can be recorded with an eye-tracker. The crew’s interaction 
with cockpit systems and speech can also be recorded 
directly. How suitable are these three types of behavioural 
measurements for automatic recording and interpretation on 
the flightdeck in actual flight?  
A. Eye gaze 
Eye gaze is highly selective in the sense that it provides 
direct insight in the information that is being used by pilots 
[3][4] for performing their tasks. Eye gaze is also highly 
generalizable, i.e., all pilots must visually scan cockpit 
instruments and the outside world in order to retrieve most 
of the required information. Eye gaze is highly responsive 
too: a single eye fixation related to information intake can 
be in the order of 70 ms. Finally, with state-of-the-art 
algorithms, eye gaze data can be reliably filtered and 
interpreted. Note that some displays in the cockpit can 
present different pages with information. Consequently, the 
active page should be taken into account when interpreting 
the data. 
B. Interaction 
Interaction with cockpit systems is highly selective in 
the sense that it provides direct insight in the tasks pilots are 
performing. Besides, every crew has to perform the same 
interactions to obtain the same results, so measures of 
interactions are also high generalizable. They are highly 
responsive too: every interaction is directly and instantly 
related to a pilot task. For this reason, complex filtering is 
not needed and automatic interpretation is straightforward. 
Note however, that in less busy flight phases the crew has 
some freedom in the order of performing their tasks. 
C. Speech 
Speech recognition can provide insight in the topics the 
pilots are discussing; however, it is more difficult to reliably 
infer the precise meaning of the vocalizations in relation to 
task performance. Note that this may change in the near 
future since speech recognition technology is developing 
rapidly (consider the “digital assistants” on smartphones, 
that rely heavily on understanding natural speech). Also 
note that interpretation of intonation can also give clues 
regarding crew state and this has been shown to work. 
However, it provides little concrete information regarding 
task occupation. 
All in all, recordings of eye gaze and interaction with 
cockpit systems are currently the most suitable behavioural 
69
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

measures for our purpose. Finally, note that these measures 
primarily relate to SA Level 1 and 2. 
 
V. 
METHOD 
As a first step in our work, the SA assessment module is 
scoped around one flight phase, for which the required 
behaviour is particularly procedural and therefore relatively 
predictable: the full descent under nominal conditions. 
The input for the SA module will be the visual acquisition 
on the basis of eye-tracker information, the altitude in 
relation to the runway, the information that is displayed on 
the cockpit systems and the communication with Air Traffic 
Control.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1 The cockpit and distinguished areas of interest  
 
The methodology consists of two phases: a development 
phase to create the reference model and a validation [4][5] 
phase to validate the SA module that compares actual 
behaviour to the reference behaviour in real time. 
A. Development phase 
For the development of the reference model, pilots made 
descents in NLR’s Airbus A320 lookalike cockpit mock-up 
using an eye-tracker system to register their information 
acquisition. 
Scenarios were prepared with full descents to Schiphol 
airport, Amsterdam. The scenarios started a few minutes 
before top of descent to allow the pilots to prepare the 
descent and to build their SA as they would in a normal 
operation. Approach and landing checklists were part of the 
procedure. Each pilot, after a familiarisation session, flew 
three scenarios. One scenario concerned nominal conditions 
including heading instructions around a weather cell. In the 
other two scenarios the conditions were less optimal. In one 
scenario, the fuel on board was low and the landing 
condition as proposed by Air Traffic Control was less 
optimal. In the third scenarios a flap malfunction forced the 
pilot to divert to a different destination airport. It was 
observed if the pilot perceived the condition, if he 
understood it and took appropriate action timely.  
Participants’ behaviour was observed and after each 
scenario the pilots were interviewed to assess how they 
experienced the scenario and how they rated their SA in the 
course of the run. These observations and ratings are used in 
the development phase to tune the system. 
The eye-tracker system delivers visual information 
acquisition in terms of dwells: the uninterrupted amount of 
time spent on an Area of Interest. The relevant Areas of 
interest are visualized in Figure 1. The data was analysed 
post experiment, in relation to the altitude above the landing 
runway and compared to the SA ratings and observations. 
The analysis allowed defining a reference model that 
represents adequate SA and thresholds for degraded SA. 
This common reference model was then integrated into the 
SA module to real-time monitor SA. 
B. Validation phase 
A group of pilots will participate to a validation 
exercise. In this exercise the SA module will provide 
indications of the pilot’s SA in real time. This will also take 
place in a simulator that resembles an A320 cockpit.  
 
VI. 
CONCLUSION AND FUTURE WORK 
In attempts to further increase flight safety, tools are 
being developed to monitor pilots’ status in flight. This 
work-in-progress aims to develop a module that can monitor 
the pilots’ Situational Awareness in a non-intrusive way. 
For this, the pilots’ visual acquisition and communication 
with Air Traffic Control are the observables used. A model 
was developed of minimal desired division of attention on 
sub-tasks: Aviate, Navigate, Communicate and Manage 
Systems during descent and landing. The model was 
incorporated into a module able to monitor the pilots’ 
division of attention, and indicating degraded SA. 
At the time of finalising this work-in-progress paper, the 
module is being evaluated in a validation exercise. This will 
allow further improvement of the model. 
 
ACKNOWLEDGMENT 
This work is part of the EU 7th framework project 
ACROSS (Advanced Cockpit for Reduction of Stress and 
Workload). 
REFERENCES 
  
[1] Airbus S.A.S., Quality and Safety First, Commercial Aviation 
Accidents, 
A 
Statistical 
Analysis, 
May 
2015. 
http://www.airbus.com/company/aircraft-
manufacture/quality-and-safety-first/ 
Last 
retrieved 
September 2015.  
[2] M. Endsley, “Toward a theory of Situational Awareness in 
dynamic systems”, Human Factors 37, pp. 32–64. 1995. 
[3] H. van Dijk, G. K. van de Merwe, and G. D. R. Zon, 
Situational Awareness Assessment in Flight Simulator 
Experiment. Proceedings ISAP 2009. 
 
70
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

[4] G. D. R. Zon, H. van Dijk, A Selection of Human Factors 
Tools: Measuring HCI Aspects of Flight Deck Technologies. 
Proceedings HCI International 2009. 
[5] G. D. R. Zon, and M. I. Roerdink, HCI Testing in Flight 
Simulator: Set Up and Crew Briefing Procedures - Unique 
Design and Test Cycle. Proceedings HCI International 2007
 
71
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-440-4
CENTRIC 2015 : The Eighth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

