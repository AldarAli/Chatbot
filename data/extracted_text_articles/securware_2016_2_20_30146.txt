The Principle of 3D Sensors
Miroslav Marcaník, Michal Šustek, Pavel Tomášek
Tomas Bata University in Zlín
Faculty of Applied Informatics
Nad Stráněmi 4511, 760 05, Zlín 
{marcanik, sustek, tomasek}@fai.utb.cz
Jiří Dvořák 
Brno University of Technology,
Faculty of Mechanical Engineering
Antonínská 548/1, 601 90, Brno
dvorak@fme.vutbr.cz
Abstract - Gradual development of modern trends with
more
emphasis
on
visualization
and
measurement
accuracy have resulted in the continuous improvement
of measuring instruments, which are very closely linked
to Personal Computers and/or Programmable Logic
Controllers to the displaying unit and leads to greater
utilization of 3D technology. 3D technology is used in
security, biometrics, and in many other fields. This
contribution is focused on understanding the issues of
scanning and its advantages and disadvantages. It serves
as a complete overview of the structure of the 3D
sensors.
Keywords – 3D sensors; sensors; CCD; CMOS.
I.
INTRODUCTION
The greater emphasis on accuracy, versatility, speed, and
price
is
the
result
of the
continual
development
of
production, automation, and research of 3-dimensional
measurements of objects. These 3D technologies became
more
important
with
the
development
of
integrated
computer technologies.
The binary system is a numbering system which is used
to express a value using only characters 0 and 1. The binary
system belongs to a group of positional number systems
with base 2, which is a specific number as expressed by the
power of 2. The numbers registered in the binary system are
called binary numbers. Record of numbers in the binary
system is complemented by a 'B' or 'b', which is used as a
subscript on the last digit or acronym BIN. [1]
Thus, the control input/output information becomes only
the values “YES” or “NO” because that specifies whether
the previous cycle is performed correctly, satisfies the
specified tolerances, but it does not describe the influences,
facts and events that preceded the input. Since the control
input/output is mainly done visually, it is necessary to adapt
the technique using geometry [2]. This path is very
appealing, but it may happen that our elected sensing
principle is imperfect and must subsequently find a new
algorithm for image processing. The main representative of
3D shooting is CCD (Charge-Coupled Device) [3] and/or
CMOS (Complementary Metal–Oxide–Semiconductor) [3]
camera. The separation of signals may be difficult in
practice, because there are plenty of influencing factors.
Quality can be affected by the most essential settings, such
as
the
arrangement
of
cameras,
illuminators
and
environment. This setting is applied in film and art
photography as well. A big part is affected by lighting or
suitable arrangement of illuminators - object - cameras. If
we have neglected these factors, we put programmers in a
position where they spend most of their time creating and
optimizing algorithms for finding the proper results in the
image. Some problems and disruptive factors can be
eliminated by polarization and absorption filters, semi-
permeable mirrors, light reflectors and diffusers [4].
Photometric systems can be difficult to connect with the
PCs and their operation systems but, generally, they use
simple methods of image processing. Scanning is performed
using surface or line CCD camera with a greater emphasis
on minimization of measurement errors [2].
The rest of the paper is structured as follows. Section II
serves as an introduction to optical radiation and the
principle
of
its
operation.
Section
III
describes
two
construction types for scanning device and their advantages
and disadvantages. The last section describes the types of
methods used for 3D scanning.
II.
OPTICAL RADIATION
A 3D sensor utilizes electromagnetic waves radiated by
the scanned object to obtain information on shape, position
and object properties. The object may be an active source of
optical radiation, or passive, which only reflects or modifies
the incident radiation from another source. The most
significant
properties
are
light
rays,
straight
lines,
independence of each other and no interaction with each
other. The law of reflection and refraction is applied.
Optical
radiation
has
the
same
properties
as
the
electromagnetic wave [2].
For the velocity (in m·s-1) we have the relation:
 
εµ
1
v =
 
(1) 
Permittivity (ε) is a physical quantity describing the
relationship between the vectors of the electric field
intensity and electric induction in a material or vacuum.
Permeability (µ) expresses the influence of the material or
environment on a magnetic field [5].
27
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-493-0
SECURWARE 2016 : The Tenth International Conference on Emerging Security Information, Systems and Technologies

Since it is a very small probability that the scanning
takes place in vacuum, we extend this pattern for the
environment where the scanning is performed. The relation
to calculate the diverse environment is given below:
 
r
c
v
ε
=
 
(2) 
where c = 2,998·108 m·s-1 is the speed of light in
vacuum and εr the relative permittivity environment.
The speed of light is also affected by refractive index.
Maxwell
explains
the
relation
between
the
absolute
refractive index n0 and the dielectric constant εr:
 
2
εr = n0
 
(3) 
Radiation can also be characterized by wavelength (λ),
which is always smaller than in vacuum. The relation
between λ and n is expressed by:
 
0
0
n
n
λ
λ =
 
(4) 
III.
PRINCIPLE OF VIDEO CAMERA
The principle of the video camera is the same as the
digital camera. Reflected electromagnetic waves (visible
light) from the object pass through the objective and fall
onto the photosensitive sensor. Consequently, the input
image is converted to an electronical signal by the sensor
and then it is saved using the internal electronics.
A.
Objective
The camera uses the lens optical system for imaging.
Lenses are divided into two basic groups: lens (refractors)
and mirrors (reflectors). Reflectors create an image of
direct, apparent and the same as the subject. Two types of
mirrors are used - concave and convex. Concave mirrors
create a mirror image that is direct, apparent and reduced.
Convex are dependent on the distance from the focus and
the mirror. If we show the object positioned between the
focal point and highlight of mirrors, it creates a picture of
the direct and virtual object located further from the focus.
On the other hand, it appears as an image inverted and real.
The size of the result image can be dependent on the
position of the lenses as well as reduction or enlargement.
The main advantages include the absence of reflectors
chromatic aberration and it is easier to manufacture large
mirrors. Figure 1 shows the main representatives of mirror
telescopes which are Cassegrain [6] and Newtonian [6]
telescopes.
Figure 1. Principle of the reflector (1 - Newton's principle 2 - Cassegrain
principle) [6]
Refractors use an optically isotropic medium which is
bounded by two spheres (or one spherical and one plane). It
is called the lens (spherical lens). Lenses limited by non-
spherical surfaces (e.g. part of the cylinder, ellipsoid, etc.)
are called aspherical lenses. The lens has a different
refractive index than its surroundings. The emerging picture
when viewing the lens depends on the type of lens
(converging, diverging) and the position of the object
against the lens. A diffusing lens creates an image directly.
The size of the resulting image may be larger or smaller
against to original image [6].
Figure 2. Principle refractor [6]
B.
CCD vs CMOS
Nowadays, technologies are dominated by two data
recorders.
CCD is the most frequently used imaging chip in
compact cameras. Its manufacture is relatively simple, but
costly. The output information from the CCD chip is not a
digital, but an analog, and must be digitized. The utilization
of the Analog / Digital converter (A/D) means higher power
consumption and slowing down the flow of data. Light-
sensitive cells on CCD have a square shape and the output
from the CCD is via bus. The individual rows or columns of
photosensitive cells are connected to the bus. Data is sent to
the bus row by row. Simpler embodiments but slower data
read. That arrangement of the CCD chip is called progressive
CCD chip. In contrast, the chip known as an interlaced CCD
chip
is
easier
to
manufacture.
The principle is very simple. First to third column is on its
own register (subtraction for mini sort memory), fourth to
sixth also have their own pair. They are deducted gradually
in these values of individual registers, which leads to higher
28
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-493-0
SECURWARE 2016 : The Tenth International Conference on Emerging Security Information, Systems and Technologies

speed retrieval of data from the chip (in this case, it would be
2-3 times).
Figure 3. Principle CCD [4]
CMOS chip is predominantly used in digital cameras
and gradually expands into digital compacts. CMOS chip is
structurally a very complex matter, but it is cheaper to
produce because it is produced in the same way as computer
processors. Circuits that digitize an image at the CCD for all
pixels gradually are directly part of the CMOS chip - each
photoreceptor cell has these circuits directly at each other.
Digitalization of the image is thus, performed in each
photosensitive cell at the same time. This reduces the time
required for reading the image of the CMOS chip and
reduces power consumption. On the other hand, the area
sensitive to light is only a tiny part of the overall chip
because the other areas are digitizing circuitry. This is
solved by color filters. These filters use Red – Green – Blue
– additive color model (RGB) or Cyan – Magenta – Yellow
– Key (CMYK). Filter miniature lens which focuses the rays
illuminating the surface of photoreceptor cell only to place,
which is the light-sensitive. The number of cells per
micrometer rises up to tens of million. Another advantage is
the data output from the CMOS chip goes suddenly as
matrix. This increases the speed of a collection of data from
the CMOS chip. In particular, this property is desirable for
high speed filming. Older and cheaper CMOS chips cause
undesired spreading to nearby hubs light-sensitive cells.
Overall, this phenomenon manifested itself as lighter or
darker bands on the scene known as the effect of striped
shirt - a man in a one color shirt looks like he is wearing
striped one. This undesirable phenomenon of "leakage" of
electrons can sometimes be observed on the CCD chip as
well. A new generation of CMOS does not suffer from this
defect anymore [4].
Figure 4. Principle CMOS [4]
IV.
PRINCIPLES 3D SCANNING
3D sensors are coming to the forefront and are more and
more commonly used in all possible sectors because of the
development of technology and the increasing demand and
popularity
of
virtual
reality.
Some
examples
include
construction, architecture, industrial machinery, navigation,
etc. Perhaps in all applications, it is necessary to have
coordinates in a 3D space. The scanning is dependent on the
position of the object, its speed, color, shape, and angle of
rotation. The advent of modern technology and optics,
which is still used for 2D scanning, expanded to methods
for measuring the third dimension. Today, there are mainly
two methods of measuring. The first one is a triangulation
and
the
second
is a light interference. The gradual
development of technologies brings about the third method.
This method is called Time of Light (TOF) and uses the
knowledge of the speed of light.
A.
Triangulation
Triangulation is very often used as a method which
requires a very complicated structure of the measuring
sensor. It is divided into two categories: active triangulation
and passive triangulation.
The
principle
of the
active
triangulation
involves
photogrammetric reconstruction of the scanned object. The
surface of scanned object is illuminated by the light source
and simultaneously scanned by the CCD sensor [7].
The
principle
of
passive
triangulation
involves
photogrammetric reconstruction of the scanned object on the
basis of its projection on the sensor surface device. One
dimension is lost during projection and it is needed to renew
on the basis of a common information from multiple sources
[7].
The principle can be seen in Figure 5. The light signal is
transmitted from the laser source to the object. The object
reflects the light ray to the camera. The angle of the
29
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-493-0
SECURWARE 2016 : The Tenth International Conference on Emerging Security Information, Systems and Technologies

transmitted ray from the source is constant, but the CCD
sensor depending on the spend ray of the dimmed sensor.
The connector between the light source and the CCD sensor
is called triangulation base (baseline). Thanks to the
knowledge of two angles and the length of the triangular
base, we can calculate the distance of a point, and then save
the coordinates for later calculations and rendering [8].
Figure 5. Principle triangulation [5]
To mark the surface, the following are used:
•
the light beam (1D triangulation),
•
light (2D triangulation),
•
Structured light beam (3D triangulation).
Disadvantages:
•
higher purchase price and better facilities,
•
time demands when evaluating the Record,
•
the limiting factor may be the memory size and
especially the quality of the recording,
•
more necessary knowledge of issues,
•
treatment of subjects.
B.
Interferometry
Interferometry is a method suitable for very precise
measurements over a short distance. The principle is based
on
light
interference.
The
principle
can
be
seen
in
Figure 6. The light source - the laser - is transmitted through
the polarization splitter - a part on the measured object. The
reflected signal is combined with polarization ray splitter
reference called carrier wave and they may interfere
together. The resulting wave interference is given by
equation (5) [8]:
(
)
(
)
(
)
(
) (
)
(
)
(
)
(
j xy j x )y
I xy I xy
I xy
I xy
I xy
,
, cos ,
,
2
,
,
,
2
1
2
1
2
2
2
1
−
+
+
=
 
(5) 
Disadvantages:
•
Technologically intensive production;
•
Demanding quantitative interpretation of results;
•
Susceptibility to interference.
Figure 6. Principle Interferometry [8]
C.
TOF
This is a method that uses the knowledge of the speed of
modulated light signal that is emitted from the transmitter
and subsequently reflected towards the receiver. The use of
this method requires very precise time value. The principle
can be seen in Figure 7. The distance of sensing object can
be computed from formula 6, where “t” is the total time
from sending a signal to the one more acceptation and “c” is
the speed of light (c = 2.998 * 108 m / s) [8].
Figure 7. Principle TOF [8]
2
s = c*t
 
(6) 
Disadvantages:
•
High-accuracy time measurement required
•
Measurement of light pulse return is inexact, due to
light scattering
•
Difficulty to generate short light pulses with fast
rise and fall times
30
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-493-0
SECURWARE 2016 : The Tenth International Conference on Emerging Security Information, Systems and Technologies

•
Usable
light
sources
(e.g.
lasers)
suffer
low
repetition rates for pulses
V.
CONCLUSION
We can find a lot of potential in utilization of 3D sensors
in all sectors from an overall perspective. A big boom was
registered mainly in the improvement of cartography,
digitization, security etc. The main objective of this article
was to suggest the basic concepts, definitions, types and
principles of various kinds of sensors. The summary of the
information in this article suggests that the expansion of 3D
scanners and 3D technologies and their general application
over time will be more necessary than previously thought.
The main advantage of 3D sensors is the utilization of three-
dimensional space, which has been in seclusion so far and
was not the main goal. The authors believe that 2D sensor
will be partially or completely replaced by 3D sensors in a
few years. Although we area ware that 3D sensors are more
expensive because it is necessary to place greater emphasis
on accuracy and designing of 3D scanners, they do provide
an improved visualization.
ACKNOWLEDGMENT
This work was supported by Internal Grant Agency of
Tomas
Bata
University
under
the
project
No.
IGA/FAI/2016/25.
REFERENCES
[1]
Binary System. PLC Automatization [online]. [cit. 2016-07-18].
Available
from:
http://plc-
automatizace.cz/knihovna/data/soustava/dvojkova-binarni-
soustava.htm
[2]
Kreidl M. and R. Šmíd. Technical diagnosis: sensors, methods,
signal analysis. 1st ed. Praha: BEN - technical literature, 2006.
Sensors non-electrical quantities. ISBN 80-7300-158-6.
[3]
Šnajdárek, Ladislav. Methods 3d Laser Scanning Workpieces In
Process Plan. Brno, 2008. Bachelor's Thesis. Brno University Of
Technology. Supervision: Ing. Miroslav Opl.
[4]
Digimanie. Mobile phones with cameras: CMOS sensor chips vs
CCD [online]. Web, 2009 [cit. 03/31/2016]. Available from:
http://www.digimanie.cz/fotomobily-snimaci-cipy-cmos-vs-
ccd/2885
[5]
Zheng, D., Liu, T., Zhou, L., Xu, Y., Electromagnetic absorbing
property of the flaky carbonyl iron particles by chemical corrosion
process (2016), Journal of Magnetism and Magnetic Materials, 419,
pp. 119-124. DOI: 10.1016/j.jmmm.2016.06.008
[6]
The section for children and young Czech Astronomical Society.
Section for children and young Czech Astronomical Society
[online]. Web: Web, 2006 [cit. 03/31/2016]. Available from:
www.mladez.astro.cz
[7]
Islam, S.C., Herrmann, M., Beigang, R., A THz triangulation and
imaging system and its applications, (2007) IRMMW-THz2007 -
Conference Digest of the Joint 32nd International Conference on
Infrared and Millimetre Waves, and 15th International Conference
on Terahertz Electronics, art. no. 4516600, pp. 498-499. Cited 2
times.
[8]
Marcaník M. and J. Dvorak. Use of 3D sensors for the protection of
critical infrastructure elements and soft targets. Zlín: Tomas Bata
University in Zlín, 2015. ISBN 978-80-7454-559-7.
[9]
A. Zatočilová. Straightness measurement and evaluation of rotary 
axes forged using photogrammetry and image analysis [online].
Brno,
2014
[cit.
03/31/2016].
Available
from:
http://dl.uk.fme.vutbr.cz/zobraz_soubor.php?id=2310.
PhD.
Technical University Brno. Supervisor Doc. Ing. Jan Brandeis, PhD.
[10]
Hubálek, J. microsensors and microelectromechanical systems.
Institute of Microelectronics, Faculty of Electrical Engineering and
Communication [online]. Brno © 2004-2015, 10. 11. 2015 [cit.
11/11/2015].
Available
from:
http://www.umel.feec.vutbr.cz/bmms/prednasky/BMMS-01.pdf.
[11]
Mechatronics
|
Introduction:
Sensors
[online].
2010
[cit.
11/10/2015].
Available
from:
http://mechmes.websnadno.cz/dokumenty/pri-mn-s-
10_senzory_uvod.pdf
[12]
Skoupý, P. 3D optical measurement and scanning systems for
engineering. Brno: Brno University of Technology, Faculty of
Mechanical Engineering, 2007. [cit. 11/11/2015]
[13]
Brunet, F. Contributions to Parametric Image Registration and 3D
Surface Reconstruction. Clermont-Ferrand, 2010. [cit. 2015-11-11].
Available from: http://www.brnt.eu/publications/brunet2010phd.pdf.
Universite d’Auvergne.
[14]
Schroeder, K. Martin, and B. Lorensen, Visualization Toolkit: An
Object-Oriented Approach to 3D Graphics, 4th Edition. Kitware,
December 2006 [cit. 2015-11-11]
[15]
Janková, M.; Dvořák, J. The ICT possibilities in the virtual 
universities cyberspace. In Mathematics, Information Technologies
and Applied Sciences 2014 (post-conference proceedings of selected
papers
extended
versions). Brno:
MITAV
2014,
2014. s.
59-
65. ISBN: 978-80-7231-978- 7.
31
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-493-0
SECURWARE 2016 : The Tenth International Conference on Emerging Security Information, Systems and Technologies

