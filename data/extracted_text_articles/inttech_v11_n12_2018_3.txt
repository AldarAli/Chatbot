An Investigation of Users’ Actions
Expressed in Tweets Submitted by Using Music Player Applications
Yasuhiko Watanabe, Kenji Yasuda, Ryo Nishimura, and Yoshihiro Okada
Ryukoku University
Seta, Otsu, Shiga, Japan
Email: watanabe@rins.ryukoku.ac.jp, t130522@mail.ryukoku.ac.jp,
r nishimura@afc.ryukoku.ac.jp, okada@rins.ryukoku.ac.jp
Abstract—What users are doing at a certain point in time is
important for designing various services and applications in social
media, such as targeted advertisement, news recommendation,
and real-world analysis. As a result, in this study, we investigated
tweets which users submitted when they were listening to music
by using music player applications. We collected 2,000 tweets
including hashtags generated by music player applications and
investigated what users described in these tweets. We found 10
% of them were tweets where actions while listening to music
were described. We applied machine learning techniques to detect
tweets where two kinds of actions while listening to music, moving
to somewhere or going to bed, were described. Furthermore,
we examined whether we can detect tweets where two kinds of
action phases, start and middle, were described. In both cases,
we obtained the high accuracy and precision. The experimental
result shows that our method is useful for providing behavior
based services and applications in social media.
Keywords–music player application; music content; behavior
based service; Twitter; social media.
I.
INTRODUCTION
Social media, such as Twitter and Facebook, generate large
quantities of data about where users are and what they are
thinking or doing at a certain point in time. Take tweets on
Twitter, (exp 1) and (exp 2), for example. We can understand
the submitters of these two tweets were listening to music. This
is because #nowplaying in (exp 1) and (exp 2) show that these
tweets were submitted by using music player applications.
Users who are using music player applications are thought
to be listening to music.
(exp 1) #nowplaying: ”soundscape” from ”soundscape -
Single” by TRUE (saisei kaisuu: 35) #songsinfo
(#nowplaying: ”soundscape” from ”soundscape -
Single” by TRUE (plays: 35) #songsinfo)
(exp 2) #nowplaying kagerou by ONE OK ROCK on
#onkyo #hfplayer
#nowplaying is a hashtag generated by various music player
applications. Furthermore, #songsinfo in (exp 1) is a hashtag
generated by a music player application, SongsInfo. Also,
#onkyo and #hfplayer in (exp 2) are hashtags generated by
a music player application, HF Player. These hashtags and
the other words in (exp 1) and (exp 2) were all generated
and embedded into these tweets automatically by music player
applications when users submitted these tweets by using them.
As a result, these hashtags enable us to understand that these
users were listening to music when they submitted these tweets
by using music player applications. As mentioned, (exp 1)
and (exp 2) consist of words and hashtags all of which were
generated by music player applications. On the other hand,
(exp 3), (exp 4), and (exp 5) include words generated not only
by music player applications but by users.
(exp 3) #nowplaying: ”Grow Slowly” from ”Hafa Adai”
by iguchi yuka (saisei kaisuu: 3) #songsinfo suki
desu motto kiiteiru
(#nowplaying: ”Grow Slowly” from ”Hafa Adai”
by Iguchi Yuka (plays: 3) #songsinfo I like and
listen to it so many times)
(exp 4) basu wo nogashita node aruki masu !!#now-
playing: ”walk on Believer ♪” from ”walk on
Believer ♪” by toyosaki aki (saisei kaisuu: 96)
#songsinfo
(I will walk because I missed the bus !! #nowplay-
ing: ”walk on Believer ♪” from ”walk on Believer
♪” by toyosaki aki (plays: 96) #songsinfo)
(exp 5) tenshon age te yakin ikuzo #nowplaying NIGHT
FLIGHT by Perfume on #onkyo #hfplayer
(I cheer myself up and go to night shift #now-
playing NIGHT FLIGHT by Perfume on #onkyo
#hfplayer)
Speciﬁcally, the following words in (exp 3), (exp 4), and (exp
5) were generated not by music player applications but by
users.
•
suki desu motto kiiteiru (I like and listen to it so many
times) in (exp 3),
•
basu wo nogashita node aruki masu !! (I will walk
because I missed the bus !!) in (exp 4), and
•
tenshon age te yakin ikuzo (I cheer myself up and go
to night shift) in (exp 5)
In this study, we describe user generated words in tweets
submitted by using music player applications as comments.
We will explain comments in tweets submitted by using music
player applications in Section III. The comments in (exp 3),
(exp 4), and (exp 5) express user’s impression, action, and
reason, respectively.
We can know that the submitters of (exp 3), (exp 4), and
(exp 5) were listening to music when they submitted these
tweets into Twitter. Furthermore, comments in these tweets
enable us to understand what they were thinking and doing
while listening to music. What users are thinking and doing
at a certain point in time is important for designing various
services and applications on social media, such as targeted
advertisement, news recommendation, and real-world analysis.
As a result, we investigated tweets submitted by using music
21
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

player applications and show what Twitter users are thinking
and doing while listening to music [1]. In this paper, we
conduct a detailed investigation on tweets submitted by using
music player applications and discuss whether they can be
classiﬁed by using machine learning techniques.
The rest of this paper is organized as follows: In Section
II, we survey the related works. In Section III, we investigate
tweets submitted by music player applications and show what
users are thinking and doing while listening to music. In
Section IV, we apply machine learning techniques to classify
tweets submitted by music player applications and discuss
whether we can detect what users are doing and what action
phases they are in while listening to music. Finally, in Section
V, we present our conclusions.
II.
RELATED WORKS
Twitter enables us to easily submit short messages in
real time from anywhere with internet access. As a result,
Twitter data is a valuable resource for predicting various
trends and events. Taking this in consideration, there are
many studies that have treated Twitter as a social sensor [2].
Aramaki et al. reported that Twitter messages reﬂect the real
world and inﬂuenza related tweets can be extracted by using
Twitter API and NLP techniques [3]. Also, Culotta showed
that inﬂuenza-related Twitter messages can be identiﬁed by
using a document classiﬁcation method and a small number
of ﬂu-related keywords can forecast future inﬂuenza rates [4].
Sakaki et al. investigated the real-time nature of Twitter and
proposed an event notiﬁcation system that monitors tweets and
delivers notiﬁcation promptly [5]. Jansen et al. reported that
microblogging is an online tool for customer word of mouth
communications and potentially rich for companies to explore
as part of their overall branding strategy [6]. Furthermore,
Twitter data was used for inferring on-line Internet service
availability [7], measuring public interest and concern about
health-related events [8], observing information diffusion in
social media [9], and examining situational features during
emergency events [10].
Timestamps and geotags embedded into tweets are useful
for treating Twitter as a social sensor. Some researchers con-
ducted studies for event detection using geotags embedded into
tweets. Lee and Sumiya proposed a method for detecting local
events by applying a k-means clustering method to geotagged
Twitter documents [11]. Kamath et al. studied the spatio-
temporal dynamics of Twitter hashtags by using a sample
of 2 billion geo-tagged tweets [12]. However, Watanabe et
al. reported that less than one percent of Twitter posts are
associated with a geolocation [13]. This is because Twitter
users have been slow to adopt geospatial features and only
a small amount of tweets comes with location information
[14]. As a result, recent work has focused on geoinference
for predicting the locations of posts. Yamaguchi et al. pointed
out that most existing methods can be categorized into two
kinds of approaches: a content-based approach or a graph-
based approach [15].
First, we discuss studies based on the content-based ap-
proach. The content-based approach leverages user-generated
contents in the form of texts. Cheng at al. proposed a method
for estimating a Twitter user’s city-level location based purely
on the content of the user’s tweets [14]. Eisenstein et al.
proposed a method of multi-level generative model that enables
prediction of an author’s geographic location from tweets
[16]. Hecht et al. reported that user’s home country and state
can be reasonably inferred by using simple machine learning
techniques [17]. Han et al. proposed a method of ﬁnding
location indicative words via feature selection and examined
whether the reduced feature set boosts geolocation accuracy
[18]. Schulz et al. proposed a multi-indicator approach for
determining the location where a tweet was created and
the location of the user’s residence [19]. Yamaguchi et al.
proposed an online location inference method that can update
inference results using only newly arriving contents without
using previous contents [15].
Next, we discuss studies based on the graph-based ap-
proach. The graph-based approach is based on the structure
of social graphs where friends are connected. This approach
is based on an idea: users’ social networks are useful for
revealing their locations. For example, Twitter users are more
likely to follow others that are geographically closer to them.
As a result, Rout et al. described this approach as network-
based approach [20]. Wang et al. used communication records
of 6 million mobile phone subscribers and found that the
similarity between individuals’ movements, their social con-
nectedness and the strength of interactions between them are
strongly correlated with each other [21]. Backstrom et al.
pointed out that, by using user-supplied address data and the
network of associations between members of the Facebook
social network, we can directly observe and measure the
relationship between geography and friendship [22]. Rout et
al. proposed an approach to geolocating users of online social
networks, based solely on their friendship connections [20].
Sadilek et al. reported that we can infer people’s ﬁne-grained
location, even when they keep their data private and we can
only access the location of their friends [23].
Kinsella et al. pointed out that understanding where users
are can enable a variety of services that allow us to present
information, recommend businesses and services, and place
advertisements that are relevant to where they are [24]. We
also may say that understanding what users are thinking and
doing can enable a variety of services that are relevant to
what they are thinking and doing. However, few studies have
been made on predicting what users are thinking and doing
while many studies have been made on predicting where
users are. As a result, in this paper, we investigate tweets
submitted by using music player applications and show what
Twitter users are thinking and doing while listening to music.
Furthermore, we discuss whether tweets submitted by using
music player applications can be classiﬁed by using machine
learning techniques.
III.
INVESTIGATION OF TWEETS SUBMITTED BY USING
MUSIC PLAYER APPLICATIONS
In this section, we investigate tweets submitted by music
player applications and show what the users are thinking and
doing while listening to music.
A. The investigation object
Tweets can be classiﬁed into three types [25]:
•
reply
A reply is submitted to a particular person. It contains
“@username” in the body of the tweet. For example,
(exp 6) is a reply to @eitaso.
22
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

(exp 6) @eitaso ore to nagoya de seigi no uta wo
utawanaika ? (ˆLˆ) #nowplaying futten
toppa ☆ LOVE IS POWER ☆ / chikyu
bouei bu
(@eitaso Let’s sing a song of justice
in Nagoya? (ˆLˆ) #nowplaying futten
toppa ☆ LOVE IS POWER ☆ / chikyu
bouei bu)
•
retweet
A retweet is a reply to a tweet that includes the original
tweet.
•
normal tweet
A normal tweet is neither reply nor retweet. For
example, (exp 3), (exp 4), and (exp 5) are normal
tweets. Normal tweets are generally submitted to
general public.
In order to investigate tweets submitted by music player
applications and what the users are thinking and doing while
listening to music, we collected the following 2000 tweets:
•
1,000 Japanese normal tweets including hashtag [26]
◦
#nowplaying
◦
#songsinfo
obtained from 13 October 2016 to 11 December 2016.
These 1,000 tweets were submitted by 244 users.
•
1,000 Japanese normal tweets including hashtag
◦
#nowplaying
◦
#onkyo
◦
#hfplayer
obtained from 13 October 2016 to 1 December 2016.
These 1,000 tweets were submitted by 345 users.
We did not collect the following tweets even if they include
the hashtags above: replies, retweets, and tweets that include
no comments generated by users. As a result, (exp 1), (exp 2),
and (exp 6) were not included in the collected 2000 tweets.
Then, we extracted user generated comments from them by
eliminating the following words.
•
Uniform Resource Locators (URL),
•
hashtags, and
•
words generated automatically by music player appli-
cations.
As a result, we extracted suki desu motto kiiteiru (I like and
listen to it so many times) from (exp 3) as a user generated
comment. Also, we extracted basu wo nogashita node aruki
masu !! (I will walk because I missed the bus !!) and tenshon
age te yakin ikuzo (I cheer myself up and go to night shift)
from (exp 4) and (exp 5), respectively.
B. Tweets which users submit when they use music player
applications
We classiﬁed comments in tweets submitted by using music
player applications into the following four types:
impressions
comments expressing users’ impressions
and evaluations of contents which they played by
using music player applications,
reasons comments expressing reasons why users played
contents by using music player applications,
Figure 1. The classiﬁcation result of the 2,000 tweets which users submit
when they use music player applications (by human experts).
actions
comments expressing actions which users carried
out when they used music player applications, and
others
comments that cannot be classiﬁed into the three
types above.
Figure 1 shows the classiﬁcation result of the obtained 2,000
Japanese tweets. We should notice that some comments can be
classiﬁed into two types. For example, yoi kyoku da! (Good
music!) in (exp 7) is classiﬁed into impressions. On the other
hand, ekurea katte kaero! (Let’s buy an eclair and go home!)
is classiﬁed into actions.
(exp 7) yoi kyoku da! ekurea katte kaero!
(Good music! Let’s buy an eclair and go home!)
We shall discuss the following kinds of comments in detail.
•
comments expressing impressions,
•
comments expressing reasons, and
•
comments expressing actions.
1) Comments expressing impressions:
We found many
comments expressing users’ impressions and evaluations of
contents which they played by using music player applications.
Figure 1 shows that more than half of the obtained 2000 tweets
were classiﬁed into ones expressing users’ impressions, such
as (exp 8) and (exp 9).
(exp 8) yoi. suki.
(Good. I like it.)
(exp 9) natsukashi sugi te naki sou
(I was close to tears)
In addition, we found that many comments expressing users’
impressions were related to time, such as (exp 10) and (exp
11).
(exp 10) kono jikantai ni kiku jazz ha, honto ni kimochi ga
ii.
(It’s fun listening to jazz in this time period.)
(exp 11) shinya no Neptunus ha kakubetsu.
(It is wonderful to listen to Neptunus very late at
night.)
Especially, most of them were related to time periods when
users played music by using music player applications.
23
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

Figure 2. The classiﬁcation result of the 215 tweets expressing users’ actions
(by human experts).
2) Comments expressing actions: Psychology research has
shown that people can attend only one task at a time [27].
Hyman et al. reported that people talking on their cell phones
while walking they ran into people more often, and did not
notice what was around them [28]. However, listening to music
is an exception. We often do something while listening to
music. Actually, we found many tweets where users described
their actions while using music player applications. (exp 12),
(exp 13), (exp 14), and (exp 15) are examples of comments
expressing users’ actions.
(exp 12) tsuukin chu.. sawayakana hare.
(On my way to work.. It’s a crisp day.)
(exp 13) oyasumi nasai
(Good night)
(exp 14) desaki deno gyomu shuryo. kiro he. yokohama live
no set list.
(I have ﬁnished my business out of the ofﬁce. On
my way home. The set list of the Yokohama live.)
(exp 15) italo pop kiki nagara kare- shikomu yo
(I will make curry with listening to Italo pop)
In our investigation, three kinds of most commonly actions
described in tweets submitted by using music player appli-
cations are move, sleep, and work. For example, (exp 12)
shows that the submitter was going to work with listening
to music. (exp 13) shows that the submitter was going to
sleep, and (exp 14) shows that the submitter had ﬁnished the
job. As shown in Figure 1, we found 215 tweets expressing
users’ actions in the obtained 2,000 tweets which users submit
when they use music player applications. We classiﬁed these
215 tweets expressing actions into four types: move, sleep,
work, and others. Figure 2 shows the classiﬁcation result of
the tweets expressing users’ actions. We found some tweets
expressing users’ actions can be classiﬁed into two types.
For example, (exp 14) was classiﬁed into work and move. In
particular, user’s action expressed in desaki deno gyomu shuryo
(I have ﬁnished my business out of the ofﬁce) of (exp 14) was
classiﬁed into work. On the other hand, user’s action expressed
in kiro he (On my way home) of (exp 14) was classiﬁed
into move. Furthermore, some tweets expressing users’ actions
were classiﬁed into others. This is because they were classiﬁed
into neither move, sleep, nor work. For example, (exp 15)
was classiﬁed into others. As shown in Figure 2, many tweets
expressing users’ actions were classiﬁed into move and sleep.
Hamamura and Iwamiya conducted the survey on the use of
Figure 3. The classiﬁcation result of the stages of users’ actions in the 215
tweets expressing users’ actions (by human experts).
Figure 4. The classiﬁcation result of the stages of users’ actions: move,
sleep, work, and others (by human experts).
portable music player [29]. The survey was conducted on 72
college students. The result of their survey had partially in
common with ours. In their investigation result, 65 students and
39 students of them used portable music players while moving
and working, respectively. This investigation result is in good
agreement with ours. On the other hand, in their investigation
result, there were no students who used portable music players
while sleeping. The result is not in good agreement with
ours. Furthermore, Hamamura and Iwamiya reported that 19
students used portable music players while shopping. On the
other hand, we found only one comment, (exp 16), submitted
by a user who were shopping while listening to music.
(exp 16) osanpo & okaimono !
(walk & shopping !)
Many tweets expressing users’ actions showed the phases
of their actions. For example, (exp 13) showed that the tweet
was submitted just before the user started his/her action. On
the other hand, (exp 12) showed that the tweet was submitted
when user’s action was ongoing. As a result, we classiﬁed
the 215 tweets expressing users’ actions in Figure 1 into
four types: start, middle, end, and others. Figure 3 shows the
classiﬁcation result of the tweets expressing users’ actions. As
shown in Figure 3, many tweets were classiﬁed into user’s
phase (start) and phase (middle). Some tweets expressing
users’ actions can be classiﬁed into two types. For example,
(exp 14) was classiﬁed into user’s phase (end) and phase (start).
24
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

In particular, user’s action expressed in desaki deno gyomu
shuryo (I have ﬁnished my business out of the ofﬁce) of (exp
14) was classiﬁed into user’s phase (end). On the other hand,
user’s action expressed in kiro he (On my way home) of (exp
14) was classiﬁed into user’s phase (start). Furthermore, Figure
4 shows the classiﬁcation result of the phases of user’s actions
expressed in 215 tweets (Figure 2), move, sleep, work, and
others. Figure 4 shows that
•
there were many tweets expressing users’ action
(sleep) in the tweets classiﬁed into user’s phase (start),
•
there were many tweets expressing users’ action
(move) in the tweets classiﬁed into user’s phase (mid-
dle), and
•
there were many tweets expressing users’ action
(work) in the tweets classiﬁed into user’s phase (end).
Both (exp 17) and (exp 18) were classiﬁed into user’s action
(move) in Figure 2. On the other hand, (exp 17) and (exp 18)
were classiﬁed into user’s phase (middle) and phase (start) in
Figure 4, respectively. The number of tweets expressing the
phase (middle) of user’s action (move), such as (exp 17), was
more than twice the number of those expressing the phase
(start) of user’s action (move), such as (exp 18).
(exp 17) kiki nagara doraibu now –
(I am driving a car now while listening to music
–)
(exp 18) yakin! chikusho- itte kuru!
(Night shift! Damn it. Let’s go!)
As shown in Figure 4, most of tweets expressing users’ action
(sleep) were classiﬁed into user’s phase (start). However, there
was a small number of tweets classiﬁed into user’s phase
(middle), such as (exp 19).
(exp 19) nere masen
(I can’t sleep.)
Many of tweets expressing user’s action (work) were classiﬁed
into user’s phase (end). However, we found some tweets
classiﬁed into user’s phase (middle), such as (exp 20) and (exp
21).
(exp 20) shigoto tiu nano yo ne
(Working now.)
(exp 21) kore wo kiki tutu tabunya no eigo no kyokasho wo
hitasura yakushite iru
(I have been listening to this song and translated
English textbooks in other areas entirely.)
We found some tweets which expressed users’ actions, how-
ever, did not show the phases of them. For example, (exp 22)
did not show the phase of user’s action.
(exp 22) asa undou
(morning exercise)
3) Comments expressing reasons: We found many com-
ments expressing users’ reasons why they were listening to
music by using music player applications.
(exp 23) kibun teki ni kikitaku natta
(I have a craving for music)
(exp 24) katte shimatta
(I ﬁnally bought it!)
Figure 5. The classiﬁcation result of users’ results in the 312 tweets
expressing users’ reasons (by human experts).
(exp 23) and (exp 24) shows the reasons why the submitters
of them were listening to music by using music player appli-
cations, feeling and acquisition, respectively. The submitter of
(exp 23) felt an impulse and listened to music. On the other
hand, the submitter of (exp 24) bought music contents and
listened to it.
As shown in Figure 1, we found 312 tweets expressing
users’ reasons in the obtained 2,000 tweets which users submit
when they use music player applications. We classiﬁed these
312 tweets expressing users’ reasons why they were listening
to music by using music player applications into ten types:
(1) feeling, (2) acquisition, (3) relaxation, (4) favorite, (5)
season/weather, (6) event, (7) natural ﬂow, (8) day/time, (9)
random play, and (10) others.
Figure 5 shows the classiﬁcation result of the tweets
expressing users’ reasons why they were listening to music
by using music player applications.
We classiﬁed (exp 23) into user’s reason (feeling). This
is because we thought the submitter of (exp 23) felt like
listening to music. Also, we classiﬁed (exp 25) into user’s
reason (feeling). This is because we thought the submitter of
(exp 25) did not listen to the song for a long time, and so,
he/she felt like doing it.
(exp 25) sugoku hisashiburi ni kiku.
(I listen to this song after a long interval.)
We classiﬁed (exp 24) into user’s reason (acquisition) because
the submitter of (exp 24) bought and obtained the music
content. Also, we classiﬁed (exp 26) into user’s reason (ac-
quisition) because the submitter of (exp 24) could not ﬁnd the
CD for a long time and found it.
(exp 26) I found CD
We classiﬁed (exp 27) and (exp 28) into user’s reason (re-
laxation). In these tweets, the submitters played musics for
relaxation.
(exp 27) kibun tenkan ♪
(relaxation ♪)
(exp 28) toriaezu tenshon age
(Let’s get going)
(exp 29) and (exp 30) are examples of tweets classiﬁed into
user’s reason (favorite). This is because both the submitters of
(exp 29) and (exp 30) addicted to the songs that they played.
25
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

(exp 29) kinou kara do hamari shite iru
(I have been addicted to the song since yesterday)
(exp 30) 1 nichi 1 kai ha kikanaito ikite ikenai karada ni
(I will die if I do not play this song at least once
a day)
(exp 31) and (exp 32) are examples of tweets classiﬁed into
user’s reason (season/weather). We thought both the submitter
of (exp 31) and (exp 32) felt like listening to the song and
submitting the tweets because they felt the sense of the season.
As shown in Figure 5, 18 tweets were classiﬁed into this type.
Seven of these tweets, including (exp 32), were submitted on
November/24/2016, the ﬁrst snow day of the winter. All these
seven tweets touched the snow.
(exp 31) kono kisetsu ha kore yana
(This music suits the mood of the season)
(exp 32) yuki to ieba kojinteki niha kore
(I listen to the song when it snows)
We classiﬁed (exp 33) and (exp 34) into user’s reason (event).
The reasons why the submitter of (exp 33) and (exp 34) play
the songs were the birthday of his/her friend and Halloween,
respectively.
(exp 33) Mikakoshi Happy Birthday !!!
(My Mikako, Happy Birthday !!!)
(exp 34) happi- harouin
(Happy Halloween)
In both of (exp 35) and (exp 36), the submitters described that
they selected and played the songs naturally. Take (exp 35)
for example. kotti mo (this song) in (exp 35) meant implicitly
that the submitter just before listened to the other song that
had some kind of connection to this song. The connection let
him/her select and play it. As a result, we classiﬁed (exp 35)
and (exp 36) into user’s reason (natural ﬂow).
(exp 35) kotti mo kika naku cha
(I have to listen to this song)
(exp 36) touzen no nagare
(natural course)
We classiﬁed (exp 37) and (exp 38) into user’s reason
(day/time). The submitters of (exp 37) and (exp 38) listened
to the songs because it was Sunday morning and night,
respectively.
(exp 37) nichiyoubi no asa ha, sawayaka ni heavy metal!!
(((o(* ° ▽ ° *)o)))
(let’s play heavy metal music refreshingly in Sun-
day morning!! (((o(* ° ▽ ° *)o))) )
(exp 38) ichiou mada yonaka nano de kiku
(I listen to this song because it is still night time)
We classiﬁed (exp 39) and (exp 40) into user’s reason (random
play). Both (exp 39) and (exp 40) were touched the songs that
were selected randomly by music player applications.
(exp 39) kyou no 1 kyoku me (random kettei)
(Today’s ﬁrst song (random selection))
(exp 40) soshite randam saisei de nagarete kita noga kore
to iu
(Then, random play and this song comes)
As shown in Figure 5, we found many tweets the comments
of which were classiﬁed into user’s reason (feeling) and
(acquisition). This investigation result is not in good agreement
TABLE I. THE FEATURES USED IN MACHINE LEARNING METHODS FOR
DATA TRAINING AND CLASSIFYING TWEETS EXPRESSING USERS’ ACTIONS
WHILE LISTENING TO MUSIC
s1
word unigrams of the comment
s2
word bigrams of the comment
s3
the number of words in the comment
s4
word unigrams of the ﬁrst sentence of the comment
s5
word bigrams of the ﬁrst sentence of the comment
s6
the number of words in the ﬁrst sentence of the comment
s7
the last word of the ﬁrst sentence of the comment
s8
character unigrams of the comment
s9
character bigrams of the comment
s10
character 3-grams of the comment
s11
the length of the comment
s12
character unigrams of the ﬁrst sentence of the comment
s13
character bigrams of the ﬁrst sentence of the comment
s14
character 3-grams of the ﬁrst sentence of the comment
s15
the length of the ﬁrst sentence of the comment
with the survey on the use of portable music player conducted
by Hamamura and Iwamiya [29]. They conducted the survey
on 72 college students and reported that the reasons why
the students used portable music players were relaxation (56
students), to kill time (51 students), to intercept environmental
sound (27 students), to sharpen concentration (18 students),
to improve operational efﬁciency (14 students), to avoid being
talked to (13 students). The common reason of this survey
and our investigation is only relaxation. This is because we
investigated each tweets and the reason why the submitter
listened to the song. On the other hand, Hamamura and
Iwamiya did not survey every single use of portable music
player. They surveyed the reasons why the college students
used portable music players in their daily lives.
IV.
DETECTION OF TWEETS EXPRESSING USERS’
ACTIONS
What users are doing at a certain point in time is important
to design various services and applications in social media that
are relevant to what they are doing. If we detect users’ actions
while listening to music automatically, we can design behavior
based services and applications in social media more precisely.
For example, users may have free time to use services and
applications when they are listening to music and going to
somewhere. On the other hand, users may not want to be
disturbed when they are lying down on their beds and listening
to music. As a result, in this section, we discuss whether
we can detect tweets including comments expressing users’
actions, especially, move and sleep, from those including hash-
tags generated by music player applications by using machine
learning techniques. Furthermore, we discuss whether we can
detect tweets including comments expressing the phases of
users’ actions.
In this study, we used the 2,000 tweets investigated in
Section III for the experimental data. The experimental data
include 216 comments expressing users’ actions. In this ex-
periment, we used the support vector machine (SVM) and
maximum entropy method (ME) for data training and clas-
sifying. Table I shows feature s1 to s15 used in machine
learning on experimental data. s1 to s7 were obtained by
using the results of morphological analysis on experimental
26
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE II. THE CLASSIFICATION RESULT OF USERS’ ACTIONS IN THE
2,000 TWEETS INCLUDING HASHTAGS GENERATED BY MUSIC PLAYER
APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
users’ comments
action
others
recall
action
127
88
0.59
others
9
1776
0.99
precision
0.93
0.95
(b) ME classiﬁcation result
ME results
users’ comments
action
others
recall
action
123
92
0.57
others
7
1778
1.00
precision
0.95
0.95
data. In the experiments, we used a Japanese morphological
analyzer, JUMAN, for word segmentation of tweets [30]. s8
to s10 and s12 to s14 were obtained by extracting character
N-gram from experimental data. Odaka et al. reported that
character 3-gram is good for Japanese processing [31]. s4 to
s7 and s12 to s15 were obtained from ﬁrst sentences of tweets.
This is because, we thought, clue expressions of users’ actions
are often found at ﬁrst sentences of tweets. We conducted this
experiment using TinySVM [32] and maxent [33]. Table II
shows the SVM and ME classiﬁcation results of users’ actions
in the 2,000 tweets. The experimental result was obtained with
10-fold cross-validation. As shown in Table II, we obtained
95% accuracy each when we applied SVM and ME machine
learning techniques to detect tweets including comments ex-
pressing user’s actions. The SVM and ME precision of tweets
including comments expressing user’s actions were 93% and
95%, respectively. On the other hand, the SVM and ME
recall of tweets including comments expressing user’s actions
were 59% and 57%, respectively. The experimental results
show that our method failed to detect many tweets expressing
users’ actions. However, the precisions of our method show
that our method is useful to collect tweets expressing users’
actions precisely. In order to discuss the experimental result,
we examined whether we can detect tweets including com-
ments expressing users’ actions, move and sleep, from those
including hashtags generated by music player applications by
using machine learning techniques.
The experimental data include
•
99 comments expressing users’ action (move) and
•
62 comments expressing users’ action (sleep).
Table III and Table IV show the classiﬁcation result of users’
action (move) and users’ action (sleep) in the 2,000 tweets,
respectively. As shown in Table III, we obtained 97% accuracy
each when we applied SVM and ME machine learning tech-
niques to detect tweets including comments expressing user’s
action (move). Also, as shown in Table IV, we obtained 99%
accuracy each when we applied SVM and ME machine learn-
ing techniques to detect tweets including comments expressing
user’s action (sleep). Furthermore, the SVM and ME precision
TABLE III. THE CLASSIFICATION RESULT OF USERS’ ACTION (MOVE) IN
THE 2,000 TWEETS INCLUDING HASHTAGS GENERATED BY MUSIC PLAYER
APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
users’ actions
move
others
recall
move
48
51
0.48
others
5
1896
1.00
precision
0.91
0.97
(b) ME classiﬁcation result
ME results
users’ actions
move
others
recall
move
41
58
0.41
others
2
1899
1.00
precision
0.95
0.97
TABLE IV. THE CLASSIFICATION RESULT OF USERS’ ACTION (SLEEP) IN
THE 2,000 TWEETS INCLUDING HASHTAGS GENERATED BY MUSIC PLAYER
APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
users’ actions
sleep
others
recall
sleep
49
13
0.79
others
0
1938
1.00
precision
1.00
0.99
(b) ME classiﬁcation result
ME results
users’ actions
sleep
others
recall
sleep
45
17
0.73
others
0
1938
1.00
precision
1.00
0.99
of tweets including comments expressing user’s action (move)
were 91% and 95%, respectively. Also, the SVM and ME
precision of tweets including comments expressing user’s
action (sleep) were 100% each. On the other hand, the SVM
and ME recall of tweets including comments expressing user’s
action (move) were 48% and 41%, respectively. However, the
SVM and ME recall of tweets including comments expressing
user’s action (sleep) were 79% and 73%, respectively. The
reason why the recall of tweets including comments expressing
user’s action (sleep) was better than user’s action (move) was
that typical expressions, such as “oyasuminasai (good night)”,
were often used in comments expressing user’s action (sleep).
The experimental result shows that our method is useful to
detect and collect tweets including comments expressing user’s
action (sleep). On the other hand, the recall of tweets including
comments expressing user’s action (move) shows that our
method failed to detect many of them. However, the precision
of them shows that our method is useful to collect them
precisely.
Next, we discuss whether we can detect tweets including
comments expressing the phases of users’ actions, start, mid-
27
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE V. THE CLASSIFICATION RESULT OF THE PHASE (START) OF
USERS’ ACTIONS IN THE 2,000 TWEETS INCLUDING HASHTAGS
GENERATED BY MUSIC PLAYER APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
action stages
start
others
recall
start
62
41
0.60
others
2
1895
1.00
precision
0.97
0.98
(b) ME classiﬁcation result
ME results
action stages
start
others
recall
start
59
44
0.57
others
1
1896
1.00
precision
0.98
0.98
TABLE VI. THE CLASSIFICATION RESULT OF THE PHASE (MIDDLE) OF
USERS’ ACTIONS IN THE 2,000 TWEETS INCLUDING HASHTAGS
GENERATED BY MUSIC PLAYER APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
action stages
middle
others
recall
middle
33
44
0.43
others
3
1920
1.00
precision
0.92
0.98
(b) ME classiﬁcation result
ME results
action stages
middle
others
recall
middle
29
48
0.38
others
1
1923
1.00
precision
1.00
0.98
dle, and end. This is because the phases of users’ actions enable
us to provide more precise services and applications relevant
to users’ actions. The experimental data include
•
103 comments expressing the phase (start) of users’
actions and
•
77 comments expressing the phase (middle) of users’
actions.
Table V shows the classiﬁcation results of the phase (start)
of users’ actions in the 2,000 tweets. Table VI shows the
classiﬁcation results of the phase (middle) of users’ actions
in the 2,000 tweets. As shown in Table V and Table VI, both
of the precision of tweets including comments expressing the
phase (start) and phase (middle) of users’ actions were good.
On the other hand, the recall of tweets including comments
expressing the phase (start) was better than that of tweets
including comments expressing the phase (middle). In order
to discuss the experimental result, we examined whether we
can detect tweets including comments expressing the phases
of speciﬁc actions, move and sleep. The experimental data
TABLE VII. THE CLASSIFICATION RESULT OF THE PHASE (START) OF
USERS’ ACTION (SLEEP) IN THE 2,000 TWEETS INCLUDING HASHTAGS
GENERATED BY MUSIC PLAYER APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
action (sleep)
start
others
recall
start
50
9
0.85
others
0
1941
1.00
precision
1.00
1.00
(b) ME classiﬁcation result
ME results
action (sleep)
start
others
recall
start
45
14
0.76
others
0
1941
1.00
precision
1.00
0.99
TABLE VIII. THE CLASSIFICATION RESULT OF THE PHASE (MIDDLE) OF
USERS’ ACTION (MOVE) IN THE 2,000 TWEETS INCLUDING HASHTAGS
GENERATED BY MUSIC PLAYER APPLICATIONS.
(a) SVM classiﬁcation result
SVM results
action (move)
middle
others
recall
middle
27
27
0.50
others
4
1942
1.00
precision
0.87
0.99
(b) ME classiﬁcation result
ME results
action (move)
middle
others
recall
middle
25
29
0.46
others
1
1945
1.00
precision
0.96
0.99
include
•
59 comments expressing the start of users’ sleep
•
54 comments expressing the middle of users’ move
Especially, users who are in the middle of move are good tar-
gets for social media services, such as targeted advertisement
and news recommendation. Table VII shows the classiﬁcation
results of the phase (start) of user’s action (sleep) in the 2,000
tweets. Also, Table VIII shows the classiﬁcation results of the
phase (middle) of user’s action (move) in the 2,000 tweets.
In both cases, we obtained the high accuracy and precision.
However, the recall of tweets including comments expressing
the phase (start) of user’s action (sleep) was good while that of
the phase (middle) of user’s action (move) was not good. This
is because Twitter users often submit short messages including
typical expressions, such as “oyasuminasai (good night)”, in
order to inform they cannot read any messages while they
are sleeping. Nakao reported that there are many Japanese
young SNS users who feel regret when they cannot reply to
SNS messages rapidly [34]. As a result, many Twitter users
submit messages including these typical expressions, such as
28
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

“oyasuminasai (good night)”, before they are sleeping.
The experimental results show that our method could not
detect many tweets expressing users’ actions. However, the
precisions of our method show that our method is useful to
collect tweets expressing users’ actions precisely. In other
words, tweets detected by our method are useful to understand
what users were doing and what phases users were in. As a
result, our method is useful to provide social media services,
such as targeted advertisement, news recommendation, and
real-world analysis.
V.
CONCLUSION
Social media such as Twitter generate large quantities of
data about what users are thinking and doing at a certain
point in time. In this respect it is important to design various
services and applications in social media, such as targeted
advertisement, news recommendation, and real-world analysis.
As a result, in this study, we investigate tweets submitted by
music player applications and show what the users are thinking
and doing while listening to music. Furthermore, we apply ma-
chine learning techniques to detect tweets submitted by music
player applications and discuss whether we can detect tweets
expressing what the users are doing and what action phases
they are in while listening to music. In both cases, we obtained
the high accuracy and precision, however, the low recall. The
low recall shows that our method often failed to detect tweets
expressing users’ actions. However, the high accuracy and
precision show that most of detected tweets were classiﬁed
correctly. In other words, tweets detected by our method are
useful to understand what users were doing and what action
phases they are in. As a result, our method is useful to provide
social media services, such as targeted advertisement, news
recommendation, and real-world analysis. We intend to use
the results of this study for further investigation of tweets
expressing users’ emotions and sentiments. This is because
more than half of the investigated tweets were classiﬁed into
ones expressing users’ impressions.
REFERENCES
[1]
Y.
Watanabe,
K.
Yasuda,
R.
Nishimura,
and
Y.
Okada,
“An
investigation of tweets submited by using music player applications,”
in Proceedings of the Ninth International Conference on Evolving
Internet (INTERNET 2017), Jul 2017, pp. 24–29. [Online]. Available:
https://www.thinkmind.org/index.php?view=article&articleid=internet
2017 2 30 40029 [accessed: 2018-5-25]
[2]
T. Sakaki and Y. Matsuo, “Twitter as a social sensor : Can social sensors
exceed physical sensors?” Journal of Japanese Society for Artiﬁcial
Intelligence, vol. 27, no. 1, jan 2012, pp. 67–74.
[3]
E. Aramaki, S. Maskawa, and M. Morita, “Twitter catches the
ﬂu: Detecting inﬂuenza epidemics using twitter,” in Proceedings
of the Conference on Empirical Methods in Natural Language
Processing, ser. EMNLP ’11.
Stroudsburg, PA, USA: Association for
Computational Linguistics, 2011, pp. 1568–1576. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2145432.2145600 [accessed: 2018-5-
25]
[4]
A. Culotta, “Towards detecting inﬂuenza epidemics by analyzing twitter
messages,” in Proceedings of the First Workshop on Social Media
Analytics, ser. SOMA ’10. New York, NY, USA: ACM, 2010, pp. 115–
122. [Online]. Available: http://doi.acm.org/10.1145/1964858.1964874
[accessed: 2018-5-25]
[5]
T. Sakaki, M. Okazaki, and Y. Matsuo, “Earthquake shakes twitter
users: Real-time event detection by social sensors,” in Proceedings of
the 19th International Conference on World Wide Web, ser. WWW ’10.
New York, NY, USA: ACM, 2010, pp. 851–860. [Online]. Available:
http://doi.acm.org/10.1145/1772690.1772777 [accessed: 2018-5-25]
[6]
B. J. Jansen, M. Zhang, K. Sobel, and A. Chowdury, “Twitter power:
Tweets as electronic word of mouth,” J. Am. Soc. Inf. Sci. Technol.,
vol. 60, no. 11, Nov. 2009, pp. 2169–2188. [Online]. Available:
http://dx.doi.org/10.1002/asi.v60:11 [accessed: 2018-5-25]
[7]
M.
Motoyama,
B.
Meeder,
K.
Levchenko,
G.
M.
Voelker,
and
S.
Savage,
“Measuring
online
service
availability
using
twitter,”
in
Proceedings
of
the
3rd
Workshop
on
Online
Social
Networks,
ser.
WOSN’10.
Berkeley,
CA,
USA:
USENIX
Association,
2010,
pp.
13–13.
[Online].
Available:
https://cseweb.ucsd.edu/˜savage/papers/WOSN10.pdf [accessed: 2018-
5-25]
[8]
A.
Signorini,
A.
M.
Segre,
and
P.
M.
Polgreen,
“The
Use
of
Twitter
to
Track
Levels
of
Disease
Activity
and
Public
Concern
in
the
U.S.
during
the
Inﬂuenza
A
H1N1
Pandemic,” PLoS One, vol. 6, no. 5, May 2011. [Online]. Available:
http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0019467
[accessed: 2018-5-25]
[9]
J. Leskovec, L. Backstrom, and J. Kleinberg, “Meme-tracking and
the dynamics of the news cycle,” in Proceedings of the 15th ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining, ser. KDD ’09.
New York, NY, USA: ACM, 2009, pp. 497–
506. [Online]. Available: http://doi.acm.org/10.1145/1557019.1557077
[accessed: 2018-5-25]
[10]
S. Vieweg, A. L. Hughes, K. Starbird, and L. Palen, “Microblogging
during two natural hazards events: What twitter may contribute to
situational awareness,” in Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems, ser. CHI ’10.
New
York, NY, USA: ACM, 2010, pp. 1079–1088. [Online]. Available:
http://doi.acm.org/10.1145/1753326.1753486 [accessed: 2018-5-25]
[11]
R. Lee and K. Sumiya, “Measuring geographical regularities of
crowd behaviors for twitter-based geo-social event detection,” in
Proceedings of the 2Nd ACM SIGSPATIAL International Workshop
on
Location
Based
Social
Networks,
ser.
LBSN
’10.
New
York,
NY,
USA:
ACM,
2010,
pp.
1–10.
[Online].
Available:
http://doi.acm.org/10.1145/1867699.1867701 [accessed: 2018-5-25]
[12]
K. Y. Kamath, J. Caverlee, K. Lee, and Z. Cheng, “Spatio-temporal
dynamics of online memes: A study of geo-tagged tweets,” in
Proceedings of the 22Nd International Conference on World Wide
Web, ser. WWW ’13.
New York, NY, USA: ACM, 2013, pp. 667–
678. [Online]. Available: http://doi.acm.org/10.1145/2488388.2488447
[accessed: 2018-5-25]
[13]
K. Watanabe, M. Ochi, M. Okabe, and R. Onai, “Jasmine: A real-
time local-event detection system based on geolocation information
propagated
to
microblogs,”
in
Proceedings
of
the
20th
ACM
International Conference on Information and Knowledge Management,
ser. CIKM ’11.
New York, NY, USA: ACM, 2011, pp. 2541–
2544. [Online]. Available: http://doi.acm.org/10.1145/2063576.2064014
[accessed: 2018-5-25]
[14]
Z.
Cheng,
J.
Caverlee,
and
K.
Lee,
“You
are
where
you
tweet: A content-based approach to geo-locating twitter users,”
in
Proceedings
of
the
19th
ACM
International
Conference
on
Information and Knowledge Management, ser. CIKM ’10.
New
York, NY, USA: ACM, 2010, pp. 759–768. [Online]. Available:
http://doi.acm.org/10.1145/1871437.1871535 [accessed: 2018-5-25]
[15]
Y. Yamaguchi, T. Amagasa, H. Kitagawa, and Y. Ikawa, “Online
user location inference exploiting spatiotemporal correlations in social
streams,” in Proceedings of the 23rd ACM International Conference
on Conference on Information and Knowledge Management, ser.
CIKM
’14.
New
York,
NY,
USA:
ACM,
2014,
pp.
1139–
1148. [Online]. Available: http://doi.acm.org/10.1145/2661829.2662039
[accessed: 2018-5-25]
[16]
J. Eisenstein, B. O’Connor, N. A. Smith, and E. P. Xing, “A latent
variable model for geographic lexical variation,” in Proceedings of
the 2010 Conference on Empirical Methods in Natural Language
Processing, ser. EMNLP ’10.
Stroudsburg, PA, USA: Association for
Computational Linguistics, 2010, pp. 1277–1287. [Online]. Available:
http://dl.acm.org/citation.cfm?id=1870658.1870782 [accessed: 2018-5-
25]
[17]
B.
Hecht,
L.
Hong,
B.
Suh,
and
E.
H.
Chi,
“Tweets
from
justin
bieber’s
heart:
The
dynamics
of
the
location
ﬁeld
in
user
proﬁles,”
in
Proceedings
of
the
SIGCHI
Conference
on
Human
Factors
in
Computing
Systems,
ser.
CHI
’11.
New
29
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

York, NY, USA: ACM, 2011, pp. 237–246. [Online]. Available:
http://doi.acm.org/10.1145/1978942.1978976 [accessed: 2018-5-25]
[18]
B. Han, P. Cook, and T. Baldwin, “Geolocation prediction in
social media data by ﬁnding location indicative words,” in COLING
2012, 24th International Conference on Computational Linguistics,
Proceedings of the Conference: Technical Papers, 8-15 December
2012, Mumbai, India, M. Kay and C. Boitet, Eds.
Indian Institute
of Technology Bombay, 2012, pp. 1045–1062. [Online]. Available:
http://aclweb.org/anthology/C/C12/C12-1064.pdf [accessed: 2018-5-25]
[19]
A. Schulz, A. Hadjakos, H. Paulheim, J. Nachtwey, and M. M¨uhlh¨auser,
“A multi-indicator approach for geolocalization of tweets.” in ICWSM,
E. Kiciman, N. B. Ellison, B. Hogan, P. Resnick, and I. Soboroff, Eds.
The AAAI Press, 2013.
[20]
D. Rout, K. Bontcheva, D. Preot¸iuc-Pietro, and T. Cohn, “Where’s
@wally?:
A
classiﬁcation
approach
to
geolocating
users
based
on
their
social
ties,”
in
Proceedings
of
the
24th
ACM
Conference on Hypertext and Social Media, ser. HT ’13.
New
York,
NY,
USA:
ACM,
2013,
pp.
11–20.
[Online].
Available:
http://doi.acm.org/10.1145/2481492.2481494 [accessed: 2018-5-25]
[21]
D.
Wang,
D.
Pedreschi,
C.
Song,
F.
Giannotti,
and
A.-L.
Barabasi, “Human mobility, social ties, and link prediction,” in
Proceedings of the 17th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, ser. KDD ’11.
New
York, NY, USA: ACM, 2011, pp. 1100–1108. [Online]. Available:
http://doi.acm.org/10.1145/2020408.2020581 [accessed: 2018-5-25]
[22]
L. Backstrom, E. Sun, and C. Marlow, “Find me if you can:
Improving geographical prediction with social and spatial proximity,”
in Proceedings of the 19th International Conference on World Wide
Web, ser. WWW ’10.
New York, NY, USA: ACM, 2010, pp. 61–
70. [Online]. Available: http://doi.acm.org/10.1145/1772690.1772698
[accessed: 2018-5-25]
[23]
A. Sadilek, H. Kautz, and J. P. Bigham, “Finding your friends
and following them to where you are,” in Proceedings of the Fifth
ACM International Conference on Web Search and Data Mining,
ser. WSDM ’12.
New York, NY, USA: ACM, 2012, pp. 723–
732. [Online]. Available: http://doi.acm.org/10.1145/2124295.2124380
[accessed: 2018-5-25]
[24]
S. Kinsella, V. Murdock, and N. O’Hare, “”i’m eating a sandwich
in glasgow”: Modeling locations with tweets,” in Proceedings of the
3rd International Workshop on Search and Mining User-generated
Contents, ser. SMUC ’11.
New York, NY, USA: ACM, 2011, pp. 61–
68. [Online]. Available: http://doi.acm.org/10.1145/2065023.2065039
[accessed: 2018-5-25]
[25]
Y.
Watanabe,
K.
Nakajima,
H.
Morimoto,
R.
Nishimura,
and
Y. Okada, “An investigation of a factor that affects the usage of
unsounded code strings at the end of japanese and english tweets,”
in Proceedings of the Seventh International Conference on Evolving
Internet (INTERNET 2015), Oct 2015, pp. 50–55. [Online]. Available:
https://www.thinkmind.org/index.php?view=article&articleid=internet
2015 2 40 40038 [accessed: 2018-5-25]
[26]
Twitter,
“How
to
use
hashtags,”
https://help.twitter.com/en/using-
twitter/how-to-use-hashtags [accessed: 2018-5-25].
[27]
S. Weinschenk, 100 Things Every Designer Needs to Know About
People, 1st ed.
Thousand Oaks, CA, USA: New Riders Publishing,
2011.
[28]
I. E. Hyman, S. M. Boss, B. M. Wise, K. E. McKenzie, and J. M.
Caggiano, “Did you see the unicycling clown? inattentional blindness
while walking and talking on a cell phone,” Applied Cognitive
Psychology, vol. 24, no. 5, 2010, pp. 597–607. [Online]. Available:
http://dx.doi.org/10.1002/acp.1638 [accessed: 2018-5-25]
[29]
M. Hamamura and S. Iwamiya, “Survey on the use of portable audio
devices by university students,” The Journal of the Acoustical Society
of Japan, vol. 69, no. 7, jul 2013, pp. 331–339.
[30]
S. Kurohashi and D. Kawahara, JUMAN Manual version 5.1 (in
Japanese).
Kyoto University, 2005.
[31]
T. Odaka et al., “A proposal on student report scoring system
using
n-gram
text
analysis
method,”
The
transactions
of
the
Institute of Electronics, Information and Communication Engineers.
D-I, vol. 86, no. 9, sep 2003, pp. 702–705. [Online]. Available:
http://ci.nii.ac.jp/naid/110003171273/en/ [accessed: 2018-5-25]
[32]
Taku Kudoh. TinySVM: Support Vector Machines. [Online]. Available:
http://chasen.org/˜taku/software/TinySVM/index.html [accessed: 2018-
5-25]
[33]
M.
Utiyama,
“Maximum
entropy
modeling
packages,”
http://mastarpj.nict.go.jp/˜mutiyama/software/maxent
[accessed:
2010-7-27], 2008.
[34]
M. Nakao, “Social media and children : Report from the world summit
on media for children (wsmc),” The NHK monthly report on broadcast
research, vol. 65, no. 3, mar 2015, pp. 76–80. [Online]. Available:
https://ci.nii.ac.jp/naid/110009890194/en/ [accessed: 2018-5-25]
30
International Journal on Advances in Internet Technology, vol 11 no 1 & 2, year 2018, http://www.iariajournals.org/internet_technology/
2018, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

