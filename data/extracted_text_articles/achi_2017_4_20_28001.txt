Changes in Small Eye Movements in Response to
Impressions of Emotion-Evoking Pictures
Tetsuya Furuta
Control and System Engineering
Tokyo Institute of Technology
Ookayama, Meguro-ku, Tokyo, Japan
Minoru Nakayama
Information and Communications Engineering
Tokyo Institute of Technology
Ookayama, Meguro-ku, Tokyo, Japan
email: nakayama@ict.e.titech.ac.jp
Abstract—The possibility of evaluating the emotional impressions
of pictures was examined using the cross power spectrum density
(CPSD) of small eye movements. Pictures were employed as
a set of normative emotional stimuli and were presented to 7
male subjects in order to evoke emotional impressions. The eye
movements resulting from each stimulus were measured using a
video based eye tracker while the viewer’s subjective impression
for each picture was rated. The stimuli were then grouped as
“Pleasant” or “Unpleasant”. In comparing the CPSDs of eye
movements between two groups, the powers of the CPSDs for
the “Unpleasant” group were signiﬁcantly higher, at 3.75-7.5Hz
during the 400-1033.3ms after stimulus onset. This result conﬁrms
that eye movements reﬂect viewer’s emotional impression.
Keywords–eye movements; emotional assessment; subjective as-
sessment; cross power spectrum
I.
INTRODUCTION
Emotional impressions require the highest level of infor-
mation processing, and emotions are an essential facet of
human behavior. Therefore, this activity has been studied
psychologically and clinically, and has often been referred
to in the study of applied sciences, such as marketing. The
emotional state which is created in some patients is often
measured using eye oscillations such as small eye movements
[1]–[3]. As the eye oscillations also reﬂect the mental workload
in a speciﬁc task [4], a more detailed analysis is required.
However, as the deﬁnition of an emotional state remains
ambiguous, facial expressions were used to evoke viewer’s re-
sponses. During the experiment, the frequency power of small
eye movements can indicate the degree of “Unpleasant” im-
pressions of facial expressions [5]. Whether the phenomenon is
maintained when various images are used should be conﬁrmed.
In addition to this, the observation procedure has not yet been
established.
This paper conﬁrmed the possibility of using a set of
normative emotional stimuli of photos and a typical video
based eye tracker to detect viewer’s emotional responses using
the responses of their eye movements. Also, a procedure
for evaluating eye movement was established. This paper is
organized as follows. Section II gives a brief description of
previous works, and Section III presents the experimental
method. In Section IV, the results of the experiment are shown,
and the discussion is summarized in Section V. Section VI
concludes the overall results.
II.
PREVIOUS WORK
The relationships between facial expressions and the ob-
server’s eye movements has been studied previously [6].
An observer’s emotional impressions are stimulated by the
viewing of facial expressions, due to a kind of emotional
synchronization [7]. The responses of both eye movements
and event related potentials (ERPs), such as the observation of
brain activity, were analyzed after pictures of facial emotions
that had been prepared as the Japanese and Caucasian Facial
Expression of Emotion (JACFEE) collection [8] were shown
to participants. The individual impressions of the facial expres-
sions in the pictures were evaluated using a scale called the
“Affect Grid” [9]. The results of viewer’s rating patterns were
extracted using cluster analysis, and assigned to two clusters
labeled “Pleasant” and “Unpleasant” [10]. Also, there were
some signiﬁcant differences in the waveforms of ERPs be-
tween the two clusters [10]. All of the differences suggest that
the degree of two dimensional eye oscillation for “Unpleasant”
facial images is signiﬁcantly higher than for “Pleasant” images.
To extract perceptual differences between the two groups
of emotional face images, ERP potentials were compared at
three typical positions on the scalp, such as the Frontal (Fz),
Central (Cz) and Occipital areas, according to the international
10-20 system. Signiﬁcant differences in frontal electrode Fz
from 142.5ms to 192.5 ms and central electrode Cz from
132.5ms to 195.0 ms were observed [10]. The difference was
not detected in waveforms at the Oz (Occipital) electrode.
Emotional recognition is a thought process at the highest level,
and the differences appear on potentials at an early stage, from
between 130 to 195 milliseconds after the introduction of the
stimulus at the mid and frontal areas [10].
In regard to these results, as ERP responses to facial
expressions occur earlier than the reactions to eye movements
[11] [12], some speciﬁc area of brain activation may trigger
these eye movements. As there are some latencies in eye
movement after stimulus onset [13], eye movement may follow
a rapid physiological response such as an ERP. In order to
examine the phenomenon, the relationships between the two
indices were analyzed for every 160msec. time interval. The
results provide evidence that the activity of an electrode at the
central area of the scalp affects eye movement between 220
and 540ms when “Unpleasant” images of facial expressions
are displayed. This phenomenon is more highly emphasized
during the viewing of “Unpleasant” facial expression images
than it is during the viewing of “Pleasant” images [5].
88
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

During the experiment, eye movement was measured using
electro-oculograms (EOGs) at a sampling rate of 400Hz. Eye
oscillation activity was calculated as a cross power spectrum
density (CPSD) using the two dimensional positions of eye
movement. The EOG observation requires four electrodes
which are placed directly around the eyes of the subjects, so
that viewing activities are restricted. In addition to this, the
measuring technique did not focus on the frequency powers of
lower frequency ranges where eye oscillations during ﬁxation
increase the power of CPSDs. While most eye trackers are
designed for use during unrestricted viewing, observations
were measured at a sampling rate of 60Hz. Therefore, the
sampling rate and the period of observation used to detect
eye oscillation should be considered carefully.
In order to determine the feasibility of observing eye
oscillations at a lower sampling rate, the EOG data was re-
sampled at 60Hz and analyzed using CPSD measurements
and an observation interval set at 640 ms (256 data points).
Frequency power can be calculated every 1.5625Hz. The
frequency powers of the CPSDs of the two groups of emotions
were compared across several periods of time. As a result,
signiﬁcant difference (p < 0.05) in two of the groups was
detected at a frequency range between 3.125 and 6.25Hz in
650–1440ms. The result is a reasonable range of frequency
and duration for eye oscillation.
The possibility of evaluating eye oscillations at lower
frequency which would be comparable to the 60Hz rate was
examined, and a procedure was developed [14].
III.
EXPERIMENTAL METHOD
The stimulus and experimental design are organized as
follows.
A. Stimulus
To evoke viewer’s emotions, a set of pictures from the
International Affective Picture System (IAPS) was employed
[15]. According to the license, the images are not allowed to be
presented in any format. This data set consists of scene images
which produce speciﬁc impressions and is well known as a
set of normative emotional stimuli for use in the experimental
investigation of emotions. The contents of the photographs are
completely different from the photographs of facial emotions
mentioned above in Section II. Sixty seven pictures were
selected that would produce the anticipated responses within
a range of emotional impressions. Since the photos consisted
of natural expressions, the level of brightness varied widely.
The color range also varied widely. This is known as saliency,
when the features of images presented affect a viewer’s eye
movement [16]. To reduce the effects of color, all pictures
were converted into grayscale images. However, the brightness
levels were not adjusted for presentation in this experiment.
B. Experimental design
The photos were displayed on a 19 inch LCD which was
60cm away from subjects. The eye tracker unit (nac:EMR-
ACTUS) was set under the LCD monitor, and the observer
did not wear any equipment. A presentation diagram is shown
in Figure 1. Each photo was displayed for 3 seconds, followed
by a blank image used to produce eye ﬁxation. The stimulus
3 ~ 4s
3 ~ 4s
3 ~ 4s
3s
3s
Figure 1. Diagram of stimuli shown.
0
50
100
150
Frequency
1
2
3
4
5
6
8
7
9
Pleasant
Unpleasant
Unpleasant
group
Pleasant
group
Figure 2. Results of viewer’s ratings of photos using an “Unpleasant” –
“Pleasant” scale.
presentation was controlled using the software of the eye
tracker. Subjects were not asked to produce any responses
before an image had been viewed. The eye movements of both
eyes in response to every photo were recorded at 60Hz, and
the data of the left eye was used in the analysis which follows.
Three trials were conducted during which the same set of
images was shown to each subject, followed by a short break.
All photos were evaluated by each participant following each
of the sessions, using a 9 point scale which ranged between
“Pleasant” and “Unpleasant”. The numerical rating was used
as one of the two dimensions of an Affect grid [9].
The subjects, who possessed sufﬁcient visual acuity, were
7 male university students aged between 21 and 24 years old.
The contents of the experiment were explained to all partici-
pants in advance, and informed consent was then obtained.
IV.
RESULTS
The rating responses for stimuli and the analyses of eye
movements are summarized as follows.
A. Subjective evaluation
All photographs were rated by each subject using a 9-point
scale. The overall frequencies of the scale are summarized
in Figure 2. The frequency is the cumulative value of the
responses of all participants to each photograph, since indi-
vidual ratings are different and independent. The responses
89
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
833.3-1366.6msec
Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
166.6-700msec
Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
1000-1533.3msec
Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
333.3-866.6msec
Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
500-1033.3msec
Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
666.6-1200msec
Frequency[Hz]
0
5
10
15
CPSD[dB]
-40
-20
0
20
40
0-533.3msec
Pleasant
Unpleasant
Pleasant
Unpleasant
Figure 3. Comparison of cross power spectrum densities for every 533.3ms between 0 and 1533.3ms.
were widely distributed as was intended by the experimental
design. The result suggests that some pictures are rated as
the most “Pleasant” ones while others were rated as the most
“Unpleasant”. The most common responses to pictures were in
the neutral category “5”. Therefore, the photographs have been
divided into two groups using the rating scale. The responses
between two groups were compared, in order to rate them
according to the factor of their emotional impressions. In
the following analysis, ratings less than 5 are classiﬁed as
“Unpleasant” (Nu = 187) and the remainder of the ratings are
classiﬁed as “Pleasant” (Np =282). As the responses consist
of individual impressions of each photo, the grouping patterns
between individuals are different.
B. Cross power spectra of eye movements
To detect evoked eye movements during picture obser-
vation, frequency analysis was conducted using the two di-
mensions of eye movement. Cross power spectrum densities
(CPSDs) were calculated for every 533.3ms (32 data points
at a 60Hz sampling rate). As the frequency power of the
CPSD is generated every 1.875Hz, it is comparable to the
calculations used for the condition mentioned above in Section
II. When eye blinks occurred during observations, the trials
were omitted. Since the eye tracker measures pupil diameters
simultaneously, eye blinks can be used to detect the sudden
drop in the diameter of the eye.
To examine the emotional difference factor of the pic-
tures, frequency powers of CPSDs of eye movements were
calculated for 7 periods: 0–533.3ms, 166.6-700ms, 333.3-
866.6ms, 500-1033.3ms, 666.6-1200ms, 833.3-1366.6ms, and
1000-1533.3ms. The duration was shifted every 166.6ms. The
power spectra of CPSDs of eye movements are summarized
in Figure 3. In the ﬁgures, the blue line indicates the powers
of the “Pleasant” group, and the red line indicates the powers
of the “Unpleasant” group. The powers are at almost the same
levels at 0–533.3ms and 166.6–700ms. For the periods 333.3-
866.6ms, 500-1033.3ms and 666.6-1200ms, the powers of the
“Unpleasant” group gradually become greater than the ones for
the “Pleasant” group, and the frequency range of the difference
becomes lower.
In examining the signiﬁcant differences in frequency pow-
ers between the two emotional groups, some signiﬁcant dif-
ferences exist. The results are summarized as a 3D graph in
Figure 4. The horizontal axes represents the frequencies and
duration analyzed, and the vertical axis represents the levels
of signiﬁcance. A cuboid indicates that there is a signiﬁcant
difference between the two groups. As the ﬁgure shows,
signiﬁcant differences appear, depending on frequency and
duration. At an early stage, a signiﬁcant difference between
333.3 and 866.6ms at 5.625Hz was observed. Some additional
differences which were signiﬁcant followed at an early stage.
In addition, the possibility of detecting the differences occurred
between 400 and 1033.3ms at 3.75–7.5Hz. The duration of
90
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

3
2
1
0
100-633.3
150-683.3
200-733.3
250-783.3
300-833.3
350-883.3
400-933.3
450-983.3
500-1033.3
550-1083.3
600-1133.3
650-1183.3
700-1233.3
750-1283.3
800-1333.3
Duration (msec.)
t-value
p<0.05
p<0.10
7.50Hz
5.625Hz
3.75Hz
Figure 4. Results of t-tests which conﬁrm signiﬁcant differences in cross
power spectrum densities of eye movements between two emotional groups.
6
5
4
3
DC component (x 104)
1
2
3
4
5
6
7
8
9
Unpleasant
Pleasant
Figure 5. Relationship between viewer’s rates and the brightness of
photographs presented (Error bars indicate STD Errors)
observation time is shown as red cuboids in Figure 4. When
this condition was analyzed, it was conﬁrmed that the differ-
ence in the frequency power of eye movement CPSDs for the
“Unpleasant” group is signiﬁcantly higher than the CPSDs for
the “Pleasant” group across all periods of time.
V.
DISCUSSION
The activation of eye oscillation in response to “Unpleas-
ant” images was conﬁrmed when photographs of emotional
expressions were introduced in addition to the facial images
which were presented. The frequency ranges and duration were
also conﬁrmed during this experiment.
The brightness level of the pictures was not considered
during the design of this experiment, though several features
and especially brightness affect the saliency of the visual
attention of the viewers. In a previous study, the inﬂuence of
the level of brightness was ignored, as all visual stimuli were
similar photos of facial expressions. To conﬁrm the factor of
brightness in the experiment, the relationships between picture
brightness and viewer’s subjective evaluations are summarized
in Figure 5. The horizontal axis indicates the rating values,
and the vertical axis indicates the values for DC components
of photographic data, using DCT analysis. The error bars show
the standard errors of DC components as a level of brightness.
In regards to the relationships between picture brightness
and viewer’s subjective evaluations, a small correlation was
observed. The effectiveness of viewer’s ratings of the deviation
of DC components is not signiﬁcant however, according to the
results of one-way ANOVA (F(8, 460) = 1.69, p = 0.10).
Therefore, the degree of contribution of picture brightness
should be considered carefully in the feature studies.
Another question is the mechanism which causes eye
oscillation when “Unpleasant” images are displayed. The phe-
nomenon was observed when both facial images and normal
pictures were viewed. The latencies in appearance of the dif-
ferences in CPSD powers and chronological analysis suggest
that the oscillations may be caused by image recognition and
the activation of some area of the brain. The details of the
information processing process are unclear. In regards to our
daily experience, as we may be reluctant to view unpleasant
images, the detailed of this phenomenon should be examined
in greater detail.
As the phenomenon may be a stable one, responses can be
used to evaluate the viewer’s emotional impressions of images
such as those used in HCI design or psychological analysis.
To examine the validity of using this technique, the inﬂuence
of various factors such as brightness or the color of stimuli
should be conﬁrmed. The study of these factors will be the
subject of our further study.
VI.
CONCLUSION
The possibility to evaluating viewer’s emotional condition
when evoked by their viewing photographs was examined
using frequency analysis of eye movements. As the previous
studies suggested, at lower frequencies some cross power
spectrum densities of eye movements were generated by the
invoked emotional conditions created using the facial images
which were shown to subjects. To create the stimulus using
images, a set of normative emotional stimuli photographs
was introduced, and a typical video based eye tracker was
employed to measure eye movement.
In regard to the chronological analysis of the cross power
spectrum densities (CPSDs) of eye movement, a signiﬁcant
difference was conﬁrmed at 400–1033.3ms after stimulus onset
in the frequency range of 3.75-7.5Hz. From the differences that
were extracted from the durations and frequency ranges, the
powers of CPSDs for “Unpleasant” images were signiﬁcantly
higher than were the ones for “Pleasant” images. Also, as the
differences began between 333.3 and 866.6ms, it suggests that
an early response has occurred.
ACKNOWLEDGMENT
This research was partially supported by the Japan Society
for the Promotion of Science (JSPS), Grant-in-Aid for Scien-
tiﬁc Research (KAKEN, B-26282046: 2014-2016).
REFERENCES
[1]
P. Tseng et al., “High-throughput classiﬁcation of clinical populations
from natural viewing eye movements,” Journal of Neurology, vol. 260,
Jan 2013, pp. 275–284.
[2]
M. Watanabe, Y. Matso, L. Zha, D. P. Munoz, and Y. Kobayashi,
“Fixational saccades reﬂect volitional action preparation,” Journal of
Neurophisiology, vol. 110, 2013, pp. 522–535.
91
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

[3]
Y. Matsuo et al., “Gap effect abnormalities during a visually guided pro-
saccade task in children with attention deﬁcit hyperactivity disorder,”
PLoS ONE, vol. 10, no. 5, 2015, p. e0125573.
[4]
M. Nakayama and M. Katsukura, “Development of a system usability
assessment procedure using oculo-motors for input operation,” Univer-
sal Access in Information Society, vol. 10, no. 1, 2011, pp. 51–68.
[5]
M. Nakayama and M. Yasuda, “Relationships between eegs and eye
movements in response to facial expressions,” in Proceedings of
ACM Symposium on Eye Tracking Research & Applications 2016
(ETRA2016), 2016, pp. 291–294.
[6]
G. J. Walker-Smith, A. G. Gale, and J. M. Findlay, “Eye movement
strategies involved in face perception,” Perception, vol. 6, 1977, pp.
313–326.
[7]
A. Suzuki, “Facial expression recognition and embodied simulation,”
Japanese Psychological Review, vol. 57, no. 1, 2014, pp. 5–23.
[8]
D. Matsumoto and P. Ekman, “Japanese and Caucasian facial expres-
sion of emotion (JACFEE) and neutral faces (JACNeuF),” 1988, san
Fransisco State University, San Francisco, CA, USA.
[9]
J. A. Russell, A. Weiss, and G. A. Mendelsohn, “Affect grid: A single-
item scale of pleasure and arousal,” Journal of Personality and Social
Psychology, vol. 57, no. 3, 1989, pp. 493–502.
[10]
M. Yasuda, Z. Dou, and M. Nakayama, “Features of event-related
potentials used to recognize clusters of facial expressions,” in Proceed-
ings of International Conference on Bio-inspired Systems and Signal
Processing (BIOSIGNAL 2015), 2015, pp. 165–171.
[11]
M. G. Calvo and L. Nummenamaa, “Eye-movement assessment of
the time course in facial expression recognition: Neurophysiological
implications,” Cognitive, Affective, & Behavioral Neuroscience, vol. 9,
no. 4, 2009, pp. 398–411.
[12]
M. Eimer and A. Holmes, “Event-related brain potential correlates of
emotional face processing,” Neuropsychologia, vol. 45, 2008, pp. 15–
31.
[13]
S. Palmer, Vision Science –Photons to Phenomenology.
Cambridge,
MA, USA: The MIT Press, 2000.
[14]
T. Furuta and M. Nakayama, “The relation between eye movements and
subjective evaluation of emotional pictures,” IEICE Technical report,
Tech. Rep. HCS2016-05, 2016.
[15]
P. Lang, M. Bradley, and B. Cuthbert, “International affective pi-
cuture system (IAPS): Affective ratings of pictures and instruction
manual,” University of Florida, Tech. Rep. Technical Report A-8, 2008,
http://csea.phhp.ufl.edu/media.html, Last accessed at
22nd Feb. 2017.
[16]
L. Itti, “Quantifying the contribution of low-level saliency to human
eye movements in dynamic scenes,” Visual Cognition, vol. 12, no. 6,
2005, pp. 1093–1123.
92
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

