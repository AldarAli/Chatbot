Efﬁciently Detecting Disguised Web Spambots (with Mismatches) in a Temporally
Annotated Sequence
Hayam Alamro
Department of Informatics
King’s College London, UK
Department of Information Systems
Princess Nourah bint Abdulrahman University
Riyadh, KSA
email: hayam.alamro@kcl.ac.uk
Costas S. Iliopoulos
Department of Informatics
King’s College London, UK
email: costas.iliopoulos
@kcl.ac.uk
Abstract—Web spambots are becoming more advanced, utilizing
techniques that can defeat existing spam detection algorithms.
These techniques include performing a series of malicious actions
with variable time delays, repeating the same series of malicious
actions multiple times, and interleaving legitimate (decoy) and
malicious actions. Existing methods that are based on string
pattern matching are not able to detect spambots that use these
techniques. In response, we deﬁne a new problem to detect
spambots utilizing the aforementioned techniques and propose an
efﬁcient algorithm to solve it. Given a dictionary of temporally
annotated sequences S modeling spambot actions, each associated
with a time window, a long, temporally annotated sequence T
modeling a user action log, and parameters f and k, our problem
seeks to detect each degenerate sequence ˜S with c indeterminate
action(s) in S that occurs in T at least f times within its associated
time window, and with at most k mismatches. Our algorithm
solves the problem exactly, it requires linear time and space,
and it employs advanced data structures, bit masking and the
Kangaroo method, to deal with the problem efﬁciently.
Keywords–Web spambot; Indeterminate ; Disguised; Actions log.
I.
INTRODUCTION
A spambot is a computer program designed to do repetitive
actions on websites, servers or social media communities.
These actions might be harmful, such as carrying out certain
attacks on websites/ servers or may be used to deceive users
such as involving irrelevant links to increase a website ranking
in search engine results. Spambots can take different forms that
are designed according to a spammer desire such as using web
crawlers for planting unsolicited material or to collect email
addresses from different sources like websites, discussion
groups or newsgroups with the intent of building mailing lists
for sending unsolicited or phishing emails. Usually, Spammers
create fake accounts to target speciﬁc websites or domain
speciﬁc users and start sending predeﬁned designed actions
which are known as predeﬁned scripts. Therefore, websites
administrators are looking for automated tools to curtail the
actions of web spambots. Although there are attempts to
prevent spamming using anti-spambots tools, the spammers try
to adopt new forms of spambots by manipulating spambots’
actions behaviour to appear as it were coming from a legitimate
user to bypass the existing spam-ﬁlter tools. One of the main
popular techniques used in web spambots is content-based
which inject repetitive keywords in meta tags to promote a
website in search engines, as well as link-based techniques
that add links to a web page to increase its ranking score in
search engines. There are several works for preventing the use
of content-based or link-based techniques by web spambots
[1]–[6]. However, they focus on identifying the content or links
added by spambots, rather than detecting the spambot based on
their actions. There are also techniques that analyze spambot
behavior [5] [7]. These techniques utilize supervised machine
learning to identify the source of spambot, rather than detecting
the spambot. More relevant to our work are string pattern
matching-based techniques that detect spambots based on their
actions (i.e., based on how they interact with the website
these spambots attack) [8] [9]. These techniques model the
user log as a large string (sequence of elements corresponding
to actions of users or spambots) and common/previous web
spambot actions as a dictionary of strings. Then, they perform
pattern matching of the strings from the dictionary to the large
string. If a match is found, then they state that a web spambot
has been detected. For example, the work by Hayati et.al
[8] proposes a rule-based, on-the-ﬂy web spambot detection
technique, which identiﬁes web spambots by performing string
matching efﬁciently using tries. The work of [9] improves
upon [8] by considering spambots that utilize decoy actions
(i.e., injecting legitimate actions, typically performed by users,
within their spam actions, to make spam detection difﬁcult)
and using approximate pattern matching based on the FPT
algorithm to detect such spambots. However, both [8] and [9]
are limited in that they consider consecutive spambot actions.
This makes them inapplicable in real settings where a spambot
needs to be detected from a log representing actions of both
users and spambots, as well as settings where a spambot
injects legitimate actions in some random fashion within a
time window. The reason that the works of [8] and [9] are
inapplicable in these settings is that they do not take into
account temporal information of neither the sequence (i.e., the
user log) nor the pattern (i.e., the spambot actions). Recently,
Artiﬁcial Intelligence (AI) has been employed in security
purposes to recognize cyber crimes and to reduce the time
and money needed for manual tasks and threats monitoring at
businesses. In our paper, we use one of the main approaches
for AI-based threats detection which is based on monitoring
behavior of a stream of data in a log ﬁle and try to detect
the places of spambots. To the best of our knowledge, our
50
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

contribution is novel as no other work takes into account the
temporal information of a sequence of actions in a user log,
nor the estimated time window of a pattern of actions in a
dictionary. These challenges made ﬁnding an effective solution
to our problem a new challenge as there is no other work
addressing the issue of time (the spambot can pause and speed
up) or errors (deceptive or unimportant actions). It is worth
mentioning that our methods are not comparable to others
as they address different issues. The other challenge that we
faced was when conducting our laboratory experiments for our
algorithm as there was no publicly available data set modeling
the real temporal annotated sequence of a user log. The only
available is the public data sets (WEBSPAM-UK2006/7) which
are a collection of assessments and set of host names and based
on the spamicity measure to decide whether a web page is a
spam, non-spam or undecided.
In this work, we focus on time annotated sequences, where
each action is associated with a time stamp. Our goal is to
detect one or more spambots, by ﬁnding frequent occurrences
of indeterminate spambot actions within a time window that
can also occur with mismatches. Our work makes the following
speciﬁc contributions:
1. We introduce an efﬁcient algorithm that can detect one or
more sequences of indeterminate (non solid) actions in text T
in linear time. We ignore the temporal factor in describing this
algorithm to facilitate the process of clariﬁcation and focus
on detecting disguised web spambots efﬁciently. It is worth
mentioning that our algorithm can compute all occurrences of
a sequence ˜S in text T in O(m + logn + occ), where m is the
length of the degenerate sequence ˜S, n is the length of the text
T and occ is the number of the occurrences of the sequence
˜S in text T.
2. We propose an efﬁcient algorithm for solving (f, c, k, W)-
Disguised Spambots Detection with indeterminate actions and
mismatches. Our algorithm takes into account temporal in-
formation, because it considers time-annotated sequences and
because it requires a match to occur within a time window.
The latter requirement models the fact that spambots generally
perform a series of disguised actions in a relatively short period
of time. Our algorithm is a generalization of the previous
problem and based on constructing a generalized enhanced
sufﬁx array, bit masking with help of Kangaroo method which
help in locating indeterminate spambots with mismatches
fast. Our proposed algorithm (f, c, k, W)-Disguised Spambots
Detection with indeterminate actions can ﬁnd all occurrences
of each ˜Si in S, such that ˜Si occurs in T at least f times
within the window Wi of ˜Si and with at most k mismatches
according to Hamming distance.
The rest of the paper as follows. In Section II, detailed
literature review, In section III we introduce notations and
background concepts. In Section IV, we formally deﬁne the
problems we address. In Section V, we formally detail our
solutions and present our algorithms. In Section VI, we present
experimental results. In Section VII, we conclude.
II.
LITERATURE REVIEW
Web spam usually refers to the techniques that the spam-
mers used to manipulate search engine ranking results to
promote their sites either for advertising purposes, ﬁnancial
beneﬁts or for misleading the user to a malicious content trap
or to install malware on victim’s machine. For these purposes,
spammers can use different techniques such as content-based
which is the most popular type of web spam, where the
spammer tries to increase term frequencies on the target page
to increase the score of the page. Another popular technique is
through using link-based, where the spammer tries to add lots
of links on the target page to manipulate the search engine
results [10] [11]. Ghiam et al. in [11] classiﬁed spamming
techniques to link-based, hiding, and content-based, and they
discussed the methods used for web spam detection for each
classiﬁed technique. Roul et al. in [10] proposed a method
to detect web spam by using either content-based, link-based
techniques or a combination of both. Gyongyi et al. in [12]
proposed techniques to semi-automatically differ the good
from spam page with the assistance of human expert whose his
role is examining small seed set of pages to tell the algorithm
which are ’good pages’ and ’bad pages’ roughly based on their
connectivity to the seed ones. Also, Gyongyi et al. in [13]
introduced the concept of spam mass and proposed a method
for identifying pages that beneﬁt from link spamming. Egele et
al. [14] developed a classiﬁer to distinguish spam sites from
legitimate ones by inferring the main web page features as
essential results, and based on those results, the classiﬁer can
remove spam links from search engine results. Furthermore,
Ahmed et al. [15] presented a statistical approach to detect
spam proﬁles on online social networks (OSNs). The work in
[15] presented a generic statistical approach to identify spam
proﬁles on online social networks. For that, they identiﬁed 14
generic statistical features that are common to both Facebook
and Twitter and used three classiﬁcation algorithms (naive
Bayes, Jrip and J48) to evaluate features on both individual and
combined data sets crawled from Facebook and Twitter net-
works. Prieto et al. [16] proposed a new spam detection system
called Spam Analyzer And Detector (SAAD) after analyzing a
set of existing web spam detection heuristics and limitations to
come up with new heuristics. Prieto et al. in [16] tested their
techniques using Webb Spam Corpus(2011) and WEBSPAM-
UK2006/7, and they claimed that the performance of their
proposed techniques is better than others system presented in
their literature. On the other side, other contributions try to
detect web spambot using supervised machining learning. In
this regard, Dai et al. [17] used supervised learning techniques
to combine historical features from archival copies of the web
and use them to train classiﬁers with features extracted from
current page content to improve spam classiﬁcation. Araujo
et al. [18] presented a classiﬁer to detect web spam based on
qualiﬁed link (QL) analysis and language model (ML) features.
The classiﬁer in [18] is evaluated using the public WEBSPAM-
UK 2006 and 2007 data sets. The baseline of their experiments
was using the precomputed content and link features in a
combined way to detect web spam pages, then they combined
the baseline with QL and ML based features which contributed
to improving the detecting performance. Algur et al. [19]
proposed a system which gives spamicity score of a web page
based on mixed features of content and link-based. The pro-
posed system in [19] adopts an unsupervised approach, unlike
traditional supervised classiﬁers, and a threshold is determined
by empirical analysis to act as an indicator for a web page to
be spam or non-spam. Luckner et al. [20] created a web spam
detector using features based on lexical items. For that, they
created three web spam detectors and proposed new lexical-
based features that are trained and tested using WEBSPAM-
51
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

UK data sets of 2006 and 2007 separately, then they trained
the classiﬁers using WEBSPAM-UK 2006 data set but they
use WEBSPAM-UK 2007 for testing. In the end, the authors
based on the results of the ﬁrst and second detectors as a
reference for the third detector where they showed that the data
from WEBSPAM-UK 2006 can be used to create classiﬁers
that work stably both on the WEBSPAM-UK 2006 and 2007
data sets. Moreover, Goh et al. [21] exploited web weight
properties to enhance the web spam detection performance
on a web spam data set WEBSPAM-UK 2007. The overall
performance in [21] outperformed the benchmark algorithms
up to 30.5% improvement at the host level and 6 − 11%
improvement at the page level. At the level of online social
networks (OSNs), the use of social media can be exploited
negatively as the impact of OSNs has increased recently and
has a major impact on public opinion. For example, one of the
common ways to achieve media blackout is to employ large
groups of automated accounts (bots) to inﬂuence the results
of the political elections campaigns or spamming other users’
accounts. Cresci et al. [22] proposed an online user behavior
model represents a sequence of string characters corresponding
to the user’s online actions on Twitter. The authors in [22]
adapt biological DNA techniques to online user behavioral
actions which are represented using digital DNA to distinguish
between genuine and spambot accounts. They make use of
the assumption of the digital DNA ﬁngerprinting techniques
to detect social spambots by mining similar sequences, and
for each account, they extract a DNA string that encodes its
behavioral information from created data set of spambots and
genuine accounts. After that, Cresci et al. [23] investigate the
major characteristics among group of users in OSNs. The study
in [23] is an analysis of the results obtained in DNA-inspired
online behavioral modeling in [22] to measure the level of
similarities between the real behavioral sequences of Twitter
user accounts and synthetic accounts. The results in [23] show
that the heterogeneity among legitimate behaviors is high and
not random. Later, Cresci et al. in [24] envisage a change in the
spambot detection approach from reaction to proaction to grasp
the characteristics of the evolved spambots in OSNs using the
logical DNA behavioral modeling technique, and they make
use of digital DNA representation as a sequence of characters.
The proactive scheme begins with modeling known spambot
accounts with digital DNA, applying genetic algorithms to
extract new generation of synthetic accounts, comparing the
current state-of-art detection techniques to the new spambots,
then design novel detection techniques.
III.
BACKGROUND AND MAIN TERMINOLOGIES
Let T = a0a2 . . . an−1 be a string of length |T| = n over
an alphabet Σ of size |Σ| = σ. The empty string ε is the string
of length 0. For 1 ≤ i ≤ j ≤ n, T[i] denotes the ith symbol
of T, and T[i, j] the contiguous sequence of symbols (called
factor or substring) T[i]T[i+1] . . . T[j]. A substring T[i, j] is
a sufﬁx of T if j = n and it is a preﬁx of T if i = 1. A string
p is a repeat of T iff p has at least two occurrences in T. In
addition p is said to be right-maximal in T iff there exist two
positions i < j such that T[i, i+|p|−1] = T[j, j+|p|−1] = p
and either j + |p| = n + 1 or T[i, i + |p|] ̸= T[j, j + |p|]. A
degenerate or indeterminate string , is deﬁned as a sequence
˜X = ˜x0 ˜x1 . . .
˜
xn−1, where ˜xi ⊆ Σ for all 0 ≤ i ≤ n − 1 and
the alphabet Σ is a non-empty ﬁnite set of symbols of size
|Σ|. A degenerate symbol ˜x over an alphabet Σ is a non-empty
subset of Σ, i.e. ˜x ⊆ Σ and ˜x ̸= ∅. |˜x| denotes the size of ˜x
and we have 1 ≤ ˜x ≤ |Σ|. A degenerate string is built over
the potential 2|Σ|−1 non-empty subsets of letters belonging to
Σ. If |˜x| = 1, that is |˜x| repeats a single symbol of Σ, we say
that ˜xi is a solid symbol and i is a solid position. Otherwise,
˜xi and i are said to be a non-solid symbol and non-solid
position respectively. For example, ˜X = ab[ac]a[bcd]bac is a
degenerate string of length 8 over the alphabet Σ = {a, b, c, d}.
A string containing only solid symbols will be called a solid
string. A conservative degenerate string is a degenerate string
where its number of non-solid symbols is upper-bounded by a
ﬁxed position constant c [25], [26]. The previous example is
a conservative degenerate string with c = 2.
A sufﬁx array of T is the lexicographical sorted array
of the sufﬁxes of a string T i.e., the sufﬁx array of T is
an array SA[1 . . . n] in which SA[i] is the ith sufﬁx of T
in ascending order [27]–[29]. The major advantages of sufﬁx
arrays over sufﬁx trees is the space as the space needed
using sufﬁx trees becomes larger with larger alphabets such as
Japanese characters, and it is useful in computing the frequency
and location of a substring in a long sequence (corpus) [28].
LCP(T1, T2) is the length of the longest common preﬁx
between strings T1 and T2 and it is usually used with SA
such that LCP[i] = lcp(TSA[i], TSA[i−1]) For all i ∈ [1..n]
[27] [30].
IV.
PROBLEMS DEFINITIONS
The two main problems that the paper will address can be
deﬁned as follows.
Problem A: Disguised (Indeterminate) Actions
Some spambots might attempt to disguise their actions
by varying certain actions. For example, a spambot takes
the actions ABCDEF, then ACCDEF, then ABDDEF
etc. This can be described as A[BC][CD]DEF. They try to
deceive by changing the second and third action. The action
[BC] and [CD] are variations of the same sequence. We will
call the symbols A, C, D, E, F solid, the symbols [BC] [CD]
indeterminate or non-solid and the string A[BC][CD]DEF
degenerate string which is denoted by ˜S. In fact, they can
disguise any of the actions. In this case, we are not concern
which actions will be disguised but we assume that the
numbers of attempts to disguise is limited. Let us assume that
the number of disguised actions is bounded by a constant c.
For the moment, we will ignore the temporal factor of the
disguises at this problem to facilitate the clariﬁcation of the
discovery of the spambot actions, and we will consider the
temporal factor in describing problem B as it is a generalization
of problem A. Actually, we combine both temporal and fake
actions discovery by apply both algorithms simultaneously. For
now, let us consider the series of actions taking place on the
server.
Deﬁnition IV.1. Given a sequence T = a1 . . . an, ﬁnd all
occurrences of ˜S = s1s2 . . . sm in T, where si might be solid
or indeterminate.
Problem B: Disguised Actions (with k Mismatches)
It is a generalization of Problem A with k errors such that
the sequence of spambot actions ˜S is degenerate actions with
errors, and the number of errors is bounded by a constant
k. Our aim is to detect new suspicious spambots which are
52
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

resulting from changing other disguised actions by spammers
such that using few mismatches in its spambot actions ˜S to
appear like actions issued by a genuine user.
Deﬁnition IV.2. Given a sequence T = a1 . . . an and an
action sequence ˜S = s1s2 . . . sm, ﬁnd all occurrences of ˜S
in T where si might be solid or indeterminate with hamming
distance between ˜S and T is no more than k mismatches.
V.
ALGORITHMS
In the following, we discuss our algorithms for the two
aforementioned problems which they include (preprocessing)
as preliminary stage.
A. Preprocessing
Our algorithms require as input sequences temporally an-
notated actions. These temporally annotated sequences are
produced from user logs consisting of a collection of http
requests. Speciﬁcally, each request in a user log is mapped
to a predeﬁned index key in the sequence and the date-time
stamp for the request in the user log is mapped to a time point
in the sequence.
B. Problem A: Disguised (indeterminate) actions
In order to design an efﬁcient algorithm for this problem,
we need to use the following steps that will make the algorithm
fast.
Step 1: For each non-solid sj occurring in degenerate
pattern ˜P = s1 . . . sm, we substitute each sj with ’#’ symbol,
where ’#’ is not in Σ. Let ˆP be the resulting pattern from
substitution process and will be considered as a solid pattern,
see (Figure 1 Step1) and (Table I).
TABLE I. CONVERTING ˜P TO ˆP
˜
P
A
B
[GX]
C
[AD]
F
ˆ
P
A
B
#1
C
#2
F
Step 2: Compute the sufﬁx array for the sequence of
actions T. Since the sufﬁx array is sorted array of all sufﬁxes
of a given string, we can apply binary search algorithm with
the sufﬁx array to ﬁnd a pattern of spambot actions in a text
of actions in O(mlogn) time complexity, where m is the
the length of the pattern P and n is the length of the text
T. Our algorithm uses Manber and Myers algorithm which
is described in [31], which uses a sufﬁx array for on-line
string searches and can answer a query of type "Is P a
substring in T?" in time O(m + logn). The algorithm in [31],
uses a sorted sufﬁx array, binary search against the sufﬁx
array of T and auxiliary data structures Llcp, Rlcp which
they are precomputed arrays and hold information about the
longest common preﬁxes (lcps) for two subranges (L . . . M)
and (M . . . R) of binary search. Subsequently, the algorithm
speeds up the comparison and permits no more than one
comparison for each character in P to be compared with the
text T. The method is generalised to O(m+logn+occ) to ﬁnd
all occurrences of P by continuing on the adjacent sufﬁxes to
the ﬁrst occurrence of P in sufﬁx array, see (Figure 1 Step2).
Step 3: At this stage, we consider each non-solid position
sj in ˆP which is represented by ’#’ as an allowed mismatch
with the corresponding action ai in T as ’#’ is not in Σ. To
query whether that ai belongs to the set of actions in ’#’, the
algorithm uses a bit masking operation. For example, suppose
we want to see whether the action ’X’ in text T belongs to
one of the set actions [GX] in ˆP which is represented by
’#1’, see Table I, we assume that each action in degenerate
symbol represents bit ’1’ among other possible actions, and ’0’
otherwise. Furthermore, The current compared action ai in T
is always represented by bit ’1’. Thereafter, the algorithm uses
And bit wise operation between the two sets [GX] and [X]
such that [11] V[01] = [01] which means that [X] ∈ [GX]. To
do that, the algorithm uses the sufﬁx array and binary search
to ﬁnd the pattern match, and for each ’#’ in the sequence is
encountered, the algorithm consider it as an allowed mismatch
and get into the veriﬁcation process to check whether the action
ai in T is one of the actions in ’#’. However, each non-solid
position sj in ˆP is numbered sequentially starting from 1 up
to the number of indeterminate symbols c. Consequently, we
refer to that position for each pattern of spambots actions with
the number of the pattern ˆPr and the number of #l, where
1 ≤ r ≤ Σ ˆP and 1 ≤ l ≤ Σ# ∈ ˆPr, see (Figure 1 Step3).
Input: Action sequence T , spambots dictionary S where each spambot ˜
P ∈ S
Output: all matching ˜
P found in T
1: procedure LOCATE ALL LOCATIONS OF ˜
P WITH INDETERMINATE ACTIONS IN T
2: ▷ Step1: (Substitution)
3:
for each ˜
Pr ∈ S do
4:
ˆ
Pr ← ˜
Pr
5:
m ← | ˆ
Pr|
6:
l ← 1
7:
for (j = 0 to m − 1) do
8:
if (
ˆ
Pr[j] is non solid) then
9:
ˆ
Pr[j] ← #l
10:
l ← l + 1
11:
end if
12:
end for
13:
end for
14: ▷ Step2: (actions matching)
15:
Build the sufﬁx array SA for the text of actions T
16:
for each ˆ
Pr ∈ S do
17:
Apply the binary search with LCPs arrays of Manber and Myer in [31]
18:
For each current action ai in SA compared to non solid symbol represented
by ’#l’ in ˆ
Pr ▷ go to: step 3
19:
end for
20: ▷ Step3: (veriﬁcation process)
21:
mask = 1 V hashMatchT able[ ˆ
Pr#l][ascii[ai]]
22:
if mask = 1 then
23:
continue
24:
else
▷ not match
25:
exit matching
26:
end if
27: end procedure
Figure 1: Problem A: Locate spambots with indeterminate
actions
Veriﬁcation process: At this stage, the algorithm does a
bit level masking operation using the logical operator ’And’
between the current compared action ai in T and the cor-
responding non-solid position in ˆP which is represented by
’#l’. As we mentioned before, the algorithm assumes each
current compared action ai in T is represented by a bit ’1’, and
each ’#l’ of each pattern reveals its original set of actions by
setting bit ’1’ at each action belongs to its set and ’0’ otherwise
using a match table called hashMatchTable, see Table II. To
access the corresponding column in hashMatchTable directly,
the columns are indexed by the (ascii code) of each character
53
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

belongs to the actions alphabets in Σ and ordered from 65
to 90 which are the ascii code of capital letters (or 97 to
122 for small letters). Thus, the algorithm can apply the
following formula (1 V hashMatchTable[ ˆPr#l][ascii[ai]]) to
ﬁnd whether that current comparing action ai in T has a match
with one of the actions in ’#l’ where ’1’ is the corresponding
bit of ai, see (Figure 1 Step3) and (Table II).
TABLE II. HASHMATCHTABLE OF THE PATTERN
˜P1 = AB[GX]C[AD]F WHERE ITS COVERSION IS
ˆP1 = AB#1C#2F
asscii(ai)
65
66
67
68
..
71
...
88
89
90
ai
A
B
C
D
..
G
...
X
Y
Z
ˆ
P1#1
0
0
0
0
1
...
1
0
0
ˆ
P1#2
1
0
0
1
0
...
0
0
0
. . .
.. .
. . .
...
...
...
...
...
. . .
. . .
ˆ
Pr#l
.. .
. . .
...
...
...
...
...
. . .
. . .
Theorem 1. Algorithm (Figure 1) computes the occurrence of
the pattern ˆP in text T in O(mlogn) time using sufﬁx array
with binary search.
Theorem 2. Algorithm (Figure 1) can compute all occurrences
of the pattern ˆP in text T in O(m + logn + occ) time using
an enhanced sufﬁx array with auxiliary data structure LCP,
binary search and bit masking.
C. Problem B: Disguised Actions (with k Mismatches)
The problem we solve is referred to as (f, c, k, W)-
Disguised Spambots Detection which is a generalization of
problem A and deﬁned as follows:
Problem. (f, c, k, W)-Disguised Spambots Detection with in-
determinate actions. Given a temporally annotated action se-
quence T (aj, tj), a dictionary S containing sequences ˆSi each
has a c non-solid symbol (represented by #), associated with
a time window Wi, a minimum frequency threshold f, and a
maximum Hamming distance threshold k, ﬁnd all occurrences
of each ˆSi ∈ S in T, such that each ˆSi occurs: (I) at least f
times within its associated time window Wi, and (II) with at
most k mismatches according to Hamming distance.
The problem we introduce in our work considers spam-
bots that perform indeterminate sequence of malicious actions
multiple times. Thus, we require an indeterminate sequence
which has c non-solid symbol(s) to appear at least f times
and within a time window Wi, to attribute it to a spambot.
In addition, we consider spambots that perform decoy actions,
typically performed by real users. To take this into account,
we consider mismatches. We assume that the dictionary and
parameters are speciﬁed based on domain knowledge (e.g.,
from external sources or past experience).
1) Our algorithm for solving (f, c, k, W)-Disguised Spam-
bots Detection: The algorithm is based on constructing a
generalized enhanced sufﬁx array data structure, bit masking
with help of Kangaroo method [32], to ﬁnd the longest
common subsequence LCS between a sequence of actions in
T and an action sequence ˆSi with at most k mismatches in
linear time.
Deﬁnition V.1. The Enhanced sufﬁx array (ESA) is a data
structure consisting of a sufﬁx array and additional tables
which can be constructed in linear time and considered as
an alternative way to construct a sufﬁx tree which can solve
pattern matching problems in optimal time and space [33],
[34].
Deﬁnition V.2. The Generalized enhanced sufﬁx array (GESA)
is simply an enhanced sufﬁx array for a set of strings, each one
ending with a special character and usually is built to ﬁnd the
longest common sequence LCS of two strings or more. GESA
is indexed as a pair of identiﬁers (i1, i2), one identifying the
string number, and the other is the lexicographical order of the
string sufﬁx in the original concatenation strings [35].
To do so, we start with algorithm (Figure 2). First, our
algorithm extracts the actions of the temporally annotated
action sequence T into a sequence Ta such that it contains
only the actions a0 . . . an from T (step 2).
Then, we gen-
Input: Temporally annotated action sequence T , spambot dictionary S, k, f
Output: All occurrences for each spambot ˆ
Si in dictionary S
1: procedure DISGUISED SPAMBOTS DETECTION WITH K MISMATCHES
2:
Ta ← all extracted action sequences with same their order from T
3:
n ← |Ta|
4:
// Create GESA, where each index consists of a pair (i1, i2)
5:
GESA(Ta, S ˆ
Si) ← Ta!0 ˆ
S1!1 ˆ
S2!2 . . . ˆ
Sr!r
6:
Create GESAR from GESA
7:
Initialize hashMatchT able[no.of#][26]
8:
for each spambot sequence ˆ
Si ∈ S do
▷ Start matching
9:
occ ← 0, occur[] ← empty, sus_spam ← empty
10:
// Calculate LCS between ˆ
Si and Ta
11:
m ← GESAR[i], (m1, m2) ← GESA[m].(i1, i2)
12:
// Find the closest Ta sequence sufﬁx j which is identiﬁed by i1
=
0 and
closest to m either before or after m
13:
j ← m − 1
▷ (j ← m + 1) in case closest j is after m
14: Find_Occ:
15:
while j ≥ 0 and i1 ̸= 0 do ▷ (j < n) & (i1 ̸= 0) in case closest j is
after m
16:
j ← j − 1
▷ j ← j + 1 in case closest j is after m
17:
end while
18:
if j ≥ 0 and i1 = 0 then ▷ ((j < n) & (i1 = 0)) in case closest j is
after m
19:
(j1, j2) ← GESA[j].(i1, i2)
20:
Find_LCS(Ta,
ˆ
Si,
j2,
m2,
n,
k,
occ,
occur[], S,
sus_spam, hashMatchT able)
21:
j ← j − 1
▷ j ← j + 1 in case closest j is after m
22:
if j ≥ 0 then
▷ j < n in case closest j is after m
23:
// Find other occurrences of suspicious spambot from ˆ
Si
24:
go to Find_Occ
25:
else
26:
Output sus_spam,occur[]
27:
end if
28:
end if
29:
end for
30: end procedure
Figure 2: Problem B: Disguised spambots detection with k
mismatches
eralize the enhanced sufﬁx array to a collection of texts
Ta and set of action sequences S ˆ
Si separated by a special
delimiter at the end of each sequence (step 5) as follows:
GESA(Ta, S ˆ
Si) = Ta!0 ˆS1!1 ˆS2!2 . . . ˆSr!r
Such that, ˆS1 . . . ˆSr are set of spambots sequences that be-
long to dictionary S ˆ
Si, and !0, . . . , !r are special symbols
not in Σ and smaller than any alphabetical letter in Ta and
smaller than ’#’ with respect to an alphabetical order. We
will refer to a collection of tables (GESA, GESAR, LCS,
T, S ˆ
Si) to ﬁnd disguised spambots within a time window t
such that given a temporally annotated action sequence T =
(a0, t0), (a1, t1) . . . (an, tn), an action sequence ˆS = s1 . . . sm
54
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

and an integer t, we will compute j1, j2, . . . , jm such that
aji = si, 1 ≤ i ≤ m
and
Pm
i=1 tji < t or tjm − tj1 < t
with Hamming distance between Ta and ˆS no more than
k mismatches. For example, suppose we have the following
sequence actions:
Ta = ABBABGCDFCBACAFAABGDFF and an in-
determinate spambot sequence:
ˆS
=
B#1C#2F, where
#1 = [GX] and #2 = [AD] in the original sequence ˜S.
Hence, the GESA(Ta, ˆS) = Ta!0 ˆS!1, where all sequences are
concatenated in one string separated with a unique delimiter
! and the reference indexing of the GESA will consist of 29
index as shown in Figure 3. Our algorithm includes initializa-
A
B
B
A
B
G
C
D
F
C
B
A
C
A
F
A
A
B
G
D
F
F
!0
B
#1
C
#2
F
!1
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
1
Figure 3: Concatenation strings of Ta!0 ˆS!1
tion for hashMatchTable to do bit masking (see Figure 2, step
7). For each spambot sequence ˆSi in the spambots dictionary
S ˆ
Si, the algorithm calculates the longest common sequence
LCS between ˆSi and Ta starting at position 0 in sequence
ˆSi and position j in sequence Ta such that the common
substring starting at these positions is maximal (see Figure
2, steps 8-24). Since the sufﬁxes of these two sequences are
represented in the lexicographical order at GESA(Ta, S ˆ
Si),
we need to look up the closest sufﬁx j (which belongs
to the other sequence in Ta) to the sequence ˆSi. This can
be achieved by using GESAR table which retains all the
lexicographical ranks of the sufﬁxes of the GESA (see Figure
2, step 6). After locating the sufﬁx index of the pattern ˆSi,
(see Figure 5, rank 10 in GESAR(i) column as an example),
then, the closest sufﬁx j will be the closest neighbour to that
sufﬁx and belongs to the sequence Ta (which is identiﬁed
by an integer number i1 and equal to 0). More precisely, the
length of the longest common sequence at position GESA(i)
and matching substring of GESA(j) is given as follows:
LCS( ˆSi, Ta) = max(LCP(GESA(i1, i2), GESA(j1, j2)) = l0
Where l0 is the maximum length of the longest com-
mon preﬁx matching characters between GESA(i1, i2) and
GESA(j1, j2) until the ﬁrst mismatch occur (or one of the
sequences terminates). Next, the second step in our algorithm
involves ﬁnding the length of the longest common subsequence
starting at the previous mismatch position l0 which can be
achieved using Kangaroo method (see Figure 4) as follows:
max(LCP(GESA(i1, i2 + l0 + 1), GESA(j1, j2 + l0 + 1)) = l1
Where l1 is the maximum length of the longest common
preﬁx matching characters between GESA(i1, i2 +l0 +1) and
GESA(j1, j2+l0+1) until the second mismatch occur (or one
of the sequences terminates). Once our algorithm encounters
’#’ at the pattern, it will get into the veriﬁcation process (see
Figure 4, steps 27-32) that we described in problem A (using
bit masking and hashMatchTable). Our algorithm will continue
in using Kangaroo method to ﬁnd other k mismatches until
the number of mismatches is greater than k or one of the
sequences terminates. Subsequently, to ﬁnd other occurrences
of the spambot ˆSi in Ta, Figure 2 continues ﬁnding the second
closest sufﬁx j that belongs to the sequence Ta simply from
GESA, see Figure 5.
1: function FIND_LCS(Ta,
ˆ
Si, j2, m2, n,k, occ, ref
: occur[], S, ref
:
sus_spam, hashMatchT able[][26])
▷ ref: to return parameter’s value to
algorithm Figure 3
2:
l ← 0; k_mis ← 0
3:
while k_mis < k and l < n and l < | ˆ
Si| do
4:
while Ta[j2 + l] = ˆ
Si[0 + l] do
5:
sus_spam ← sus_spam + Ta[j2 + l]
6:
l ← l + 1
7:
end while
8:
if ˆ
Si[0 + l] =′ #′ then
9:
go to Veriﬁcation process
10:
if match then
11:
sus_spam ← sus_spam + Ta[j2 + l]
12:
l ← l + 1
13:
else
14:
k_mis ← k_mis + 1
15:
end if
16:
end if
17:
end while
18:
if |sus_spam| = | ˆ
Si| then
19:
a_time ← 0
20:
for pos = j2 to | ˆ
Si| do
21:
a_time ← a_time + T [tpos]
22:
end for
23:
if a_time ≤ Wi then
24:
occ ← occ + 1; occur[occ] ← j2
25:
end if
26:
end if
27: ▷ Veriﬁcation process:
28:
if hashMatchT able[ ˆ
Si[0 + l]][ascii[Ta[j2 + l]]] = 1 then
29:
match ← true
30:
else
31:
match ← false
32:
end if
33: end function
Figure 4: Problem B: LCS with Kangaroo method
i
GESA[i]
Sufﬁx
GESAR[i]
0
(1,28)
!1
5
1
(0,22)
!0b#1c#2f!0
13
2
(1,24)
#1c#2f!1
11
3
(1,26)
#2f!1
6
4
(0,15)
aabgdff!0b#1c#2f!1
14
5
(0,0)
abbabgcdfcbacafaabgdff!0b#1c#2f!1
27
6
(0,3)
abgcdfcbacafaabgdff!0b#1c#2f!1
19
7
(0,16)
abgdff!0b#1c#2f!1
20
8
(0,11)
acafaabgdff!0b#1c#2f!1
25
9
(0,13)
afaabgdff!0b#1c#2f!1
18
10
(1,23)
b#1c#2f!1
12
11
(0,2)
babgcdfcbacafaabgdff!0b#1c#2f!1
8
12
(0,10)
bacafaabgdff!0b#1c#2f!1
17
13
(0,1)
bbabgcdfcbacafaabgdff!0b#1c#2f!1
9
14
(0,4)
bgcdfcbacafaabgdff!0b#1c#2f!1
24
15
(0,17)
bgdff!0b#1c#2f!1
4
16
(1,25)
c#2f!1
7
17
(0,12)
caf aabgdff!0b#1c#2f!1
15
18
(0,9)
cbacafaabgdff!0b#1c#2f!1
28
19
(0,6)
cdfcbacafaabgdff!0b#1c#2f!1
21
20
(0,7)
dfcbacafaabgdff!0b#1c#2f!1
26
21
(0,19)
dff!0b#1c#2f!1
23
22
(1,27)
f!1
1
23
(0,21)
f !0b#1c#2f!1
10
24
(0,14)
faabgdff!0b#1c#2f!1
2
25
(0,8)
fcbacafaabgdff!0b#1c#2f!1
16
26
(0,20)
f f!0b#1c#2f!1
3
27
(0,5)
gcdfcbacafaabgdff!0b#1c#2f!1
22
28
(0,18)
gdff!0b#1c#2f!1
0
Figure 5: GESA for the sequences Ta, ˆS and illustration of
occurrences of ˆS in Ta at i = 12, 14 and 15 and k = 2, where
#1 = [GX] and #2 = [AD]
As we can see from Figure 5, there are three occurrences
for spambot ˆS in Ta with up to k = 2 mismatches. The ﬁrst
occurrence is illustrated using blue color at i = 12 with one
mismatch (k = 1). The second occurrence is illustrated using
violet color at i = 14 with zero mismatch (k = 0) and the last
55
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

occurrence is illustrated using green color at i = 15 with two
mismatches (k = 2). All curved arrows represent the Kangaroo
jumps, and the underlines represent mismatches places. Finally,
at each occurrence of ˆSi in the sequence Ta, algorithm (Figure
4) checks its time window using the dictionary S and T such
that it sums up each time ti associated with its action ai in T
starting at the position j2 in GESA(j1, j2) until the length of
the spambot | ˆSi| and compares it to its time window Wi. If the
resultant time is less than or equal to Wi, algorithm (Figure 4)
considers that the pattern sequence corresponds to a spambot
and terminates (see Figure 4, steps 18-26), so that the control
returns to algorithm (Figure 2). Once the frequency number
hits a predeﬁned threshold f, the sequence and its occurrences
will be output by algorithm Figure 2.
VI.
EXPERIMENTAL EVALUATION
We implemented our algorithm in C++ and ran it on an
Intel i7 at 3.6 GHz. Our algorithm uses linear time and space.
It constructs the sufﬁx array by almost pure Induced-Sorting
[36], to build our GESA for the concatenated sequences (Ta
and data dictionary S), and then it applies the bit masking
and Kangaroo method to detect all uncertain actions. We use
synthetic data to test our method, because we are not aware
of publicly available datasets of real spambot behavior and
modeling the real temporal annotated sequence of a user log.
TABLE III. RESULTS FOR THE NUMBER OF DETECTED
DESGUISED SPAMBOTS AND RUNTIME. DICTIONARY SIZE
|S| = 100, 200 AND 500 (INCLUDE 20, 50 AND 100
DISGUISED SEQUENCES RESPECTIVELY) WITH f = 2, AND
HAMMING DISTANCE THRESHOLD k = 0, 1 AND 2.
|S| : |#|
|T |
|Tinj|
Disguised actions
Time (min)
k = 0 k = 1 k = 2 k = 0 k = 1 k = 2
100 : 20
10,000
13,004
85
142
376
0.036
0.038
0.043
25,000
28,100
97
152
302
0.223
0.225
0.237
50,000
52,924
93
154
542
0.890
0.894
0.974
100,000 103,028
90
161
758
3.705
3.751
3.795
200 : 50
10,000
16,060
206
313
976
0.137
0.148
0.160
25,000
30,876
306
422
1726
0.555
0.582
0.586
50,000
55,856
202
258
946
1.976
1.957
2.094
100,000 105,878
203
337
1512
7.422
7.781
7.966
500 : 100
10,000
25,088
630
856
2141
2.294
2.255
2.367
25,000
39,736
602
811
2488
2.440
2.575
2.582
50,000
64,666
582
791
2854
6.621
6.779
6.929
100,000 114,812
640
902
4110
21.515 21.744 22.207
However, the use of synthetic data does not affect our
ﬁndings, because our method is guaranteed to detect all
speciﬁed patterns in any temporally annotated sequence. Also
note that we do not compare with existing works because
no existing method can solve this problem. We used a
random string generator to generate: (I) temporally anno-
tated sequences with 26 distinct characters and sizes in
{10000, 25000, 50000, 100000}, and (II) dictionaries with size
in {100, 200, 500}. In every generated temporally annotated
sequence T, we injected each sequence in S to random
locations f ∈ {2, 5, 10} times, to obtain the web-spambots user
log Tinj. We also changed some sequences in S, to simulate
disguised and mismatch actions. Speciﬁcally, we replaced 20%
of actions of selected sequences in S by ’#’ symbol which
represents an indeterminate symbol that corresponds to one or
more action in Tinj, to simulate disguised actions. Also, we
changed one random element in 25% of randomly selected
sequences, to simulate a mismatch, and two random elements
in another 25% of randomly selected sequences, to simulate
two mismatches. The window length (Wi) for each sequence
in S was selected randomly in [5, 125]. Table III shows the
impact of the dictionary size |S| on the disguised spambot
actions (with mismatches) and runtime. From this table we
observe the following:
• For the same (|S| : |#|) and |T| and varying k, the
number of detected actions increases, as our algorithm
by construction detects all actions with at most k mis-
matches (so the actions for a larger k include those for
all smaller k’s). Interestingly, the sequences which have
disguised actions (represented by ’#’ symbol) are detected
as the normal sequences due to the use of bit masking
operation and hashMatchTable. Also, it is noticeable that
the runtime is hardly affected by k, due to the use of the
Kangaroo method, which effectively speeds up the ﬁnding
of occurrences of spambots. For example, the time for
the disguised spambots detection at k = 1 and k = 2,
when (|S| : |#| = 500 : 100) and (|T| = 25, 000)
is relatively the same, despite the big difference in the
number detected spambots.
• For the same (|S| : |#|) and k and varying |T|, the
number of detected actions does not directly depend on
|T|; it depends on the size of the injected actions to T,
which generally increases with (|S| : |#|). The runtime
increases with |T|, since our algorithm always detects all
actions in T.
• For the same |T| and k and varying (|S| : |#|), the
number of detected actions increase with (|S| : |#|) as
our algorithm always detects all actions in the dictionary,
and the runtime also increases with the dictionary size.
Table IV shows the impact of the frequency f on the disguised
spambot actions and runtime. For this table, we observe the
following:
TABLE IV. RESULTS FOR THE NUMBER OF DETECTED
DISGUISED SPAMBOTS AND RUNTIME. DICTIONARY SIZE
(|S| : |#| = 100 : 20) WITH f = 2, 5 AND 10, AND
HAMMING DISTANCE THRESHOLD k = 0, 1 AND 2.
f
|T |
|Tinj|
Disguised actions
Time (min)
k = 0 k = 1 k = 2 k = 0 k = 1 k = 2
2
10,000
13,004
85
142
376
0.036
0.038
0.043
25,000
28,100
97
152
302
0.223
0.225
0.237
50,000
52,924
93
154
542
0.890
0.894
0.974
100,000 103,028
90
161
758
3.705
3.751
3.795
5
10,000
17,510
209
345
715
0.085
0.088
0.092
25,000
32,750
243
376
497
0.345
0.353
0.357
50,000
57,310
234
379
894
1.073
1.091
1.144
100,000 107,570
224
382
1075
4.184
4.147
4.247
10
10,000
25,020
417
681
1264
0.179
0.191
0.203
25,000
40,500
488
751
1149
0.514
0.532
0.539
50,000
64,620
466
751
1475
0.528
1.494
1.456
100,000 115,140
451
755
1609
4.713
4.948
5.045
• For the same f and |T| and varying k, the detected actions
for any k include all actions with at most k mismatches.
Also, the runtime is hardly affected by k and disguised
actions, due to the use of the Kangaroo method and bit
masking operation.
• For the same f and k and varying |T|, the number of
detected actions does not increase with |T|, as it depends
on the size of injected actions which generally depends
on (|S| : |#|), as explained above. The runtime increases
because our algorithm always detects all actions in T.
56
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

• For the same |T| and k and varying f, the number of
detected actions increases as our algorithm always detects
all injected actions. Interestingly though the algorithm
scales well with f, especially when |T| is large. This
is due to the use of the Generalized enhanced sufﬁx
array (GESA) which ﬁnds all subsequent occurrences of
a detected action occurrence directly from the adjacent
sufﬁxes to the ﬁrst occurrence sufﬁx.
VII.
CONCLUSION
We have introduced two efﬁcient algorithms that can detect
spambots of malicious actions with variable time delays. One
can detect one or more indeterminate sequences in a web user
log using Manber and Myers algorithm and bit masking oper-
ation. The second proposed a generalized solution for solving
(f, c, k, W)-Disguised Spambots Detection with indeterminate
actions and mismatches. Our algorithm takes into account
temporal information, because it considers time-annotated se-
quences and because it requires a match to occur within a time
window. The problem seeks to ﬁnd all occurrences of each
conservative degenerate sequence corresponding to a spambot
that occurs at least f times within a time window and with
up to k mismatches. For this problem, we designed a linear
time and space inexact matching algorithm, which employs the
generalized enhanced sufﬁx array data structure, bit masking
and Kangaroo method to solve the problem efﬁciently.
REFERENCES
[1]
J. Yan and A. S. El Ahmad, “A low-cost attack on a microsoft captcha,”
in CCS.
ACM, 2008, pp. 543–554.
[2]
A. Zinman and J. S. Donath, “Is britney spears spam?” in CEAS, 2007.
[3]
S. Webb, J. Caverlee, and C. Pu, “Social honeypots: Making friends
with a spammer near you.” in CEAS, 2008, pp. 1–10.
[4]
P. Heymann, G. Koutrika, and H. Garcia-Molina, “Fighting spam on
social web sites: A survey of approaches and future challenges,” IEEE
Internet Computing, vol. 11, no. 6, 2007, pp. 36–45.
[5]
P. Hayati, K. Chai, V. Potdar, and A. Talevski, “Behaviour-based web
spambot detection by utilising action time and action frequency,” in In-
ternational Conference on Computational Science and Its Applications,
2010, pp. 351–360.
[6]
F. Benevenuto, T. Rodrigues, V. Almeida, J. Almeida, C. Zhang, and
K. Ross, “Identifying video spammers in online social networks,” in
International workshop on Adversarial information retrieval on the web.
ACM, 2008, pp. 45–52.
[7]
A. H. Wang, “Detecting spam bots in online social networking sites: a
machine learning approach,” in CODASPY, 2010, pp. 335–342.
[8]
P. Hayati, V. Potdar, A. Talevski, and W. Smyth, “Rule-based on-the-ﬂy
web spambot detection using action strings,” in CEAS, 2010.
[9]
V. Ghanaei, C. S. Iliopoulos, and S. P. Pissis, “Detection of web spambot
in the presence of decoy actions,” in IEEE International Conference on
Big Data and Cloud Computing, 2014, pp. 277–279.
[10]
R. K. Roul, S. R. Asthana, M. Shah, and D. Parikh, “Detecting spam
web pages using content and link-based techniques,” Sadhana, vol. 41,
no. 2, 2016, pp. 193–202.
[11]
S. Ghiam and A. N. Pour, “A survey on web spam detection methods:
taxonomy,” arXiv preprint arXiv:1210.3131, 2012.
[12]
Z. Gyongyi, H. Garcia-Molina, and J. Pedersen, “Combating web spam
with trustrank,” in Proceedings of the 30th international conference on
very large data bases (VLDB), 2004.
[13]
Z. Gyongyi, P. Berkhin, H. Garcia-Molina, and J. Pedersen, “Link
spam detection based on mass estimation,” in Proceedings of the 32nd
international conference on Very large data bases. VLDB Endowment,
2006, pp. 439–450.
[14]
M. Egele, C. Kolbitsch, and C. Platzer, “Removing web spam links
from search engine results,” Journal in Computer Virology, vol. 7, no. 1,
2011, pp. 51–62.
[15]
F. Ahmed and M. Abulaish, “A generic statistical approach for spam de-
tection in online social networks,” Computer Communications, vol. 36,
no. 10-11, 2013, pp. 1120–1129.
[16]
V. M. Prieto, M. Álvarez, and F. Cacheda, “Saad, a content based web
spam analyzer and detector,” Journal of Systems and Software, vol. 86,
no. 11, 2013, pp. 2906–2918.
[17]
N. Dai, B. D. Davison, and X. Qi, “Looking into the past to better
classify web spam,” in Proceedings of the 5th international workshop
on adversarial information retrieval on the web, 2009, pp. 1–8.
[18]
L. Araujo and J. Martinez-Romo, “Web spam detection: new classiﬁ-
cation features based on qualiﬁed link analysis and language models,”
IEEE Transactions on Information Forensics and Security, vol. 5, no. 3,
2010, pp. 581–590.
[19]
S. P. Algur and N. T. Pendari, “Hybrid spamicity score approach to web
spam detection,” in International Conference on Pattern Recognition,
Informatics and Medical Engineering (PRIME-2012).
IEEE, 2012,
pp. 36–40.
[20]
M. Luckner, M. Gad, and P. Sobkowiak, “Stable web spam detection
using features based on lexical items,” Computers & Security, vol. 46,
2014, pp. 79–93.
[21]
K. L. Goh, R. K. Patchmuthu, and A. K. Singh, “Link-based web spam
detection using weight properties,” Journal of Intelligent Information
Systems, vol. 43, no. 1, 2014, pp. 129–145.
[22]
S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, and M. Tesconi,
“Dna-inspired online behavioral modeling and its application to spam-
bot detection,” IEEE Intelligent Systems, vol. 31, no. 5, 2016, pp. 58–
64.
[23]
——, “Exploiting digital dna for the analysis of similarities in twitter
behaviours,” in 2017 IEEE International Conference on Data Science
and Advanced Analytics (DSAA).
IEEE, 2017, pp. 686–695.
[24]
S. Cresci, M. Petrocchi, A. Spognardi, and S. Tognazzi, “From reaction
to proaction: Unexplored ways to the detection of evolving spambots,”
in Companion Proceedings of the The Web Conference 2018, 2018, pp.
1469–1470.
[25]
C. Iliopoulos, R. Kundu, and S. Pissis, “Efﬁcient pattern matching in
elastic-degenerate strings,” arXiv preprint arXiv:1610.08111, 2016.
[26]
M. Crochemore, C. S. Iliopoulos, R. Kundu, M. Mohamed, and
F. Vayani, “Linear algorithm for conservative degenerate pattern match-
ing,” Engineering Applications of Artiﬁcial Intelligence, vol. 51, 2016,
pp. 109–114.
[27]
S. J. Puglisi, W. F. Smyth, and A. H. Turpin, “A taxonomy of sufﬁx array
construction algorithms,” acm Computing Surveys (CSUR), vol. 39,
no. 2, 2007, pp. 4–es.
[28]
M. Yamamoto and K. W. Church, “Using sufﬁx arrays to compute
term frequency and document frequency for all substrings in a corpus,”
Comput. Linguist., vol. 27, no. 1, Mar. 2001, pp. 1–30.
[29]
J. Kärkkäinen, P. Sanders, and S. Burkhardt, “Linear work sufﬁx array
construction,” JACM, vol. 53, no. 6, 2006, pp. 918–936.
[30]
T. Kasai, G. Lee, H. Arimura, S. Arikawa, and K. Park, “Linear-
time longest-common-preﬁx computation in sufﬁx arrays and its ap-
plications,” in Annual Symposium on Combinatorial Pattern Matching.
Springer, 2001, pp. 181–192.
[31]
U. Manber and G. Myers, “Sufﬁx arrays: a new method for on-line
string searches,” siam Journal on Computing, vol. 22, no. 5, 1993, pp.
935–948.
[32]
M. Nicolae and S. Rajasekaran, “On pattern matching with k mis-
matches and few don’t cares,” IPL, vol. 118, 2017, pp. 78–82.
[33]
M. I. Abouelhoda, S. Kurtz, and E. Ohlebusch, “Replacing sufﬁx trees
with enhanced sufﬁx arrays,” J. Discrete Algorithms, vol. 2, 2004, pp.
53–86.
[34]
M. Abouelhoda, S. Kurtz, and E. Ohlebusch, Enhanced Sufﬁx Arrays
and Applications, 12 2005, pp. 7–1.
[35]
F. A. Louza, G. P. Telles, S. Hoffmann, and C. D. Ciferri, “Generalized
enhanced sufﬁx array construction in external memory,” AMB, vol. 12,
no. 1, 2017, p. 26.
[36]
G. Nong, S. Zhang, and W. H. Chan, “Linear sufﬁx array construction
by almost pure induced-sorting,” in DCC, 2009, pp. 193–202.
57
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-783-2
PATTERNS 2020 : The Twelfth International Conference on Pervasive Patterns and Applications

