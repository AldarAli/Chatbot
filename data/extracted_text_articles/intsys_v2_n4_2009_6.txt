457
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
Automated Dependability Planning in Virtualised Information System
Marco D. Aime
m.aime@polito.it
Paolo Carlo Pomi
paolo.pomi@polito.it
Marco Vallini
marco.vallini@polito.it
Politecnico di Torino
Dipartimento di Automatica e Informatica
Corso Duca degli Abruzzi 24, 10149 Torino, Italy
Abstract
Virtualisation technologies widely affect information de-
pendability practices, and suggest novel approaches for de-
pendable system conﬁguration. We analyse how to exploit
these peculiarities within a tool for semi-automated con-
ﬁguration of virtual information systems. We present the
general architecture of the tool, which is the product of
previous work focused on traditional information systems,
and discuss how to update its conﬁguration strategies when
moving to virtual environments. We present the stepwise
process that, starting from the model of the target service,
computes a set of conﬁguration plans that determine which
virtual machines should be deployed, their internal conﬁg-
uration, and their intended interactions. Our tool also gen-
erates re-conﬁguration templates to switch between differ-
ent conﬁguration plans in case of dependability problems
or changed requirements. Actually, reaction plans are heav-
ily affected by virtualisation technologies, which permit fast
re-allocation and reconﬁguration of virtual machines. We
ﬁnally discuss the integration of our process with virtual
machine management systems, in order to perform conﬁgu-
ration and re-conﬁguration in fully automated way.
Keywords: automatic system conﬁguration; depend-
ability ontology; virtualization.
1
Introduction
Virtualisation technologies are changing traditional ar-
chitecture in data center environments [8, 17, 26]. They
widely affect the trade-off between costs and beneﬁts of
standard dependability mechanisms and suggest the intro-
duction of novel approaches. In previous work [6] we ad-
dressed the policy-driven, automatic conﬁguration of infor-
mation systems, taking care of dependability requirements
at the business service level. [6] describes process, algo-
rithms, and tools for semi-automatic generation of depend-
ability conﬁgurations for information systems not relying
on modern virtualisation technologies. In [7], we have ﬁrst
analysed how to adapt our approach to virtualised informa-
tion systems. In this paper, we investigate how virtualisa-
tion changes the best practices of dependability planning,
and how we have updated our conﬁguration framework ac-
cordingly. In particular, after a quick reference to virtualisa-
tion concepts, we summarise the relevant background from
previous works in Sec. 2, discuss virtualisation-based de-
pendability conﬁguration strategies in Sec. 3, describe the
conﬁguration generation algorithms implemented by our
tool in Sec. 4, and give guidelines to integrate with virtual
machine management systems in Sec. 5.
The heart of modern virtualisation technologies is the
Virtual Machine Monitor, or hypervisor, that allows mul-
tiple operating system instances to run on the same physical
host. The ﬁrst technology class is full virtualisation, like
VMware[28], which introduces a layer that traps and emu-
lates all privileged instructions. On the other hand, para vir-
tualisation [9] uses a modiﬁed operating system to let vir-
tual machines directly use hardware resources. This tech-
nique introduces lower overhead and best ﬁts data centres.
Hypervisor offers isolation among hosted virtual ma-
chines: if a service running on a guest machine is tampered,
security threats are conﬁned and do not affect the other vir-
tual machines. Virtual machines (VMs) are connected to-
gether by virtual connections, managed by the hypervisor,
with advantages in terms of performance and security [16].
Actually, process and connection isolation assumes the hy-
pervisor as trusted. The set of techniques to achieve trusted
hypervisors, e.g. Trusted Computing [25], are out of the ob-
jectives of this paper.
Hypervisor can also freeze and restore VMs, but the mi-
gration of a VM requires taking a snapshot of all its re-
sources at a given time, sending this snapshot to the destina-
tion hosting device, and rebuilding there the VM from the
snapshot. Although migration is extremely promising for
dependability, migration functions, as currently provided by
1

458
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
the hypervisor, make hard assumptions: source and destina-
tion hosts must share the same hardware architecture; the
source and destination hosts must share the same network
segment; the VM image and virtual storage must be already
available at the destination host. Moreover, management
of failures in the migration process is generally incomplete
[19]. Therefore, safe VM migration requires in practice a
complex process to be carefully planned.
Our process and tools allow minimising the risks of vir-
tual systems by planning hot/cold standbys for critical VMs,
conﬁguring distributed storage, and protecting data transfer
across the system. Starting from service-level models of the
target dependability requirements, our tools generate mul-
tiple conﬁgurations featuring different dependability solu-
tions. Conﬁgurations may be further selected according to
other constraints (e.g. performance, cost, energy). We in-
stead exploit these alternative conﬁgurations to construct
re-conﬁguration templates, intended in terms of switching
between different conﬁgurations to react to dependability
problems or changed requirements.
2
Planning Framework
Our framework implements a model-based approach to
progressive policy reﬁnement and conﬁguration generation.
We developed a tool, able to generate set of alternative con-
ﬁgurations for complex ICT systems, considering the de-
pendability requirements at business level.
Approaches for automatic conﬁguration were proposed
by [23], using policy reﬁnement techniques widely adopted
also in our work.
The author focused his attention on
conﬁguration of devices, but did not consider in detail the
chance to have different deployment plans. Another inter-
esting work on policy reﬁnement is [10] but it is mainly
focused on authentication and authorisation rules.
In [11] authors present an approach very similar to
ours, but limited to J2EE based applications, whereas ours
presents a technology independent solution, in fact, in this
paper we study its application at virtualized environments.
Furthermore, they do not present a clear methodology for
modelling information system nor a classiﬁcation of the
system components from the dependability point of view.
[22] shows a promising model-driven approach to achieve
security requirements, but it does not consider dependabil-
ity problems. Another interesting project is [12], but is more
concerned on software development rather than on conﬁgu-
ration and management of an existing system.
This tool generates an allocation plan, for alternative
hosting of service components, then for every plan gener-
ates the conﬁguration for the devices involved in the host-
ing, in the communication enabling and protection, and the
protection of hosts.
Our approach is based on a system of rules that act on
the ontology representing the system. Add the beginning
the ontology is separated in service and requirements on
one side, and on the other side the hardware and software
able to host and protect the service. Every rule reads the
information from the ontology and adds some information,
reducing the gap among the two side of the ontology. The
rules executed after can use all the information already gen-
erated, since some rules can add the connection between
the two sides. Such approach permits to fully track the au-
tomatic generation process, and insert other rules to exploit
different scenarios or dependability solutions.
More details of the framework are presented in [6]:
we resume here its building blocks as long as this work
is layered upon them. Three steps compose the process:
model construction, conﬁguration generation and conﬁgu-
ration ranking. During model construction, we describe the
information system, composed by business services, virtual
machines, physical resources, and dependability require-
ments. We model business services using a proﬁle of W3C’s
Web Service Choreography Description Language [2]. We
consider services as a set of interactions between different
service components, from a choreographic point of view.
This approach handles every business service component
as a black box, and focuses on the role inside the global
business process. To model the virtual infrastructure, we
use the System Description Language [3] based on DMTF’s
CIM[24]. This model is based on a multi-layered graph of
physical and software elements in the network (nodes), and
their structural and logical dependencies (edges). All our
models have an XML serialisation. These models are then
represented as ontology, to be read by the generation pro-
cess.
The conﬁguration generation process produces a set of
alternative virtual network topologies (composed by vir-
tual machines and virtual networks) driven by templates
plus corresponding per-device abstract conﬁgurations. Ev-
ery conﬁguration provides the business services with vary-
ing degrees of compliance with the given dependability con-
straints. We perform two main reﬁnement steps in cascade:
(1) generate the virtual machines to host and protect the
business service components, considering the required ca-
pabilities; (2) permit and protect interactions among service
components, generating an abstract conﬁguration for every
involved network node (e.g. ﬁrewalls, load balancers). The
tool is designed as an ontology-based model transformation
engine. Transformation rules are written using XSL and ex-
ecuted by a standard XSL engine. This technological choice
has been taken because XSL allows writing rules using set
operation discouraging the usage of internal models: since
its support to procedural programming approach is minimal.
In this manner, rules are naturally forced to be simple and
have to exploit ontology models as intermediate data repos-
itory, by adding artifacts instance to be used by the rule ex-
2

459
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
ecuted after. Finally, the integration that we did within an
XML database permits a distributed approach with few ef-
forts. The engine retrieves the model processed by the pre-
vious steps from the XML database and executes the set of
transformations for the current level extending the internal
model. In this paper, we analyse the main changes required
to make the conﬁguration rules virtualisation aware.
3
Dependability Techniques in virtualisation
environment
3.1
Service provisioning
This section describes how virtualisation technology im-
pacts the dependability techniques used for conﬁguring
servers and technical services to maintain business service
continuity.
Our tool originally computed allocation of services on
physical machines. When migrating to the virtualisation
world, we calculate the allocation of virtual machines while
considering the security requirements determined by the
hosted services. In other words, the maximum of the hosted
service for every dependability requirements is considered,
in order to guarantee the correct level of support for all
them. This choice must consider that, for example, inter-
nal resources are scarce (few machines available) and less
efﬁcient (provider is supposed to have a better connection
to the Internet), but grant higher trust levels. Outsourcing
VMs instead of services implies that the conﬁguration of
VMs’ internals is not delegated to the hosting provider. Our
tool computes such conﬁgurations, allowing stronger con-
trol on the system.
Depending on the service allocated, we classify VMs
in two classes: working machines, performing operations
on external data (e.g. application servers), and storing ma-
chines, saving data on their own disk images e.g. DBMS. In
accordance to this classiﬁcation, the conﬁgurations also de-
scribe whether each VM should be spawned in ’persistent’
(their disk images are modiﬁed) or ’non-persistent’ mode
(when we shut down and restart the VM all the modiﬁcation
on disk images are lost). As detailed in the next sections,
this approach reduces the impact in case of vulnerability,
and helps in backup strategies.
Service isolation and packaging
The conﬁguration rules
ﬁrst isolate different classes of services to limit fault prop-
agation, including exploitation of vulnerabilities. In tradi-
tional systems, isolation implies different servers, generat-
ing big additional costs. When our tool produces plans for
virtual environment, it enforces isolation more aggressively
due to reduced costs of VMs. Nevertheless, it considers the
different strength between such logical isolation and a tra-
ditional physical isolation.
Splitting a service onto different machines allows min-
imising permissions. Imagine to have two services differen-
tiated either by roles (one for restricted users, one for pub-
lic), permissions (one just reading some contents, the other
modifying them), or resources (one accessing the stock, the
other using customer data). With no alternative allocation,
we must expose both services to each other, delegate isola-
tion to the operating system, and increase risks of violations
of the more restricted service. In similar cases, our tool
spawns two different machines: a machine accessible from
the public, the other implementing session-level access con-
trol (TLS or VPN); a machine accessing read-only data, the
other with read-write access to data. Similarly, imagine al-
locating two web applications on the only available Apache
web server, one requiring a module that presents a well-
known vulnerability. Our tool generates two different VMs,
each one with the proper set of software dependencies.
In traditional systems, our tool considers service isola-
tion costly from the communication performance point of
view, due to the additional network interactions.
When
adopting VMs, the tool decreases this cost, since the in-
teractions between VMs on the same physical device are
generally faster than network communications. Naturally,
to exploit this feature our tool calculates the VM groups, in
order to minimise the communication delay w.r.t the busi-
ness service model. As result, typically, these groups collect
service components belonging to the same business service
[13].
Some services reside on isolated hosts by design (e.g. ,
ﬁrewalls of different brands, front-ends and application
servers).
Our planner seeks server consolidation, imple-
menting them as different VMs on the same physical ma-
chine, to speed up network communications, while preserv-
ing most of the security advantages deriving from isolation.
Virtual machine replication
Replication of resources,
typically with the aid of a central manager (e.g. load bal-
ancer), is a pillar of dependable conﬁguration. Our plan-
ning tool exploits the chance to spawn dynamically virtual
machines to implement countermeasures and mitigations
to problems like vulnerability exploitations, denial of ser-
vice attacks, failures and QoS degradation due to misuse or
spikes in demand.
Menaces deriving from possible vulnerabilities are quite
common in information systems. Typically, there are three
different approaches to such problems: change the soft-
ware implementation with an immune one, apply a security
patch, or take the risk of a possible exploitation. We model
software packages with their dependences and we can tag
whether a software package is vulnerable or not. Thanks to
this model, the planner mitigates the impact of vulnerabil-
ities affecting service availability exploiting “diversity im-
plementation” concepts [18]. In other words, our tools plan
3

460
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
a replication of critical service components, using differ-
ent operating systems, with different software implementa-
tions, and subject to different vulnerabilities. Since in many
cases the vulnerability affects a library imported and not di-
rectly the software package, this approach is effective when
the two implementations do not share any library. Actually,
this approach is most effective when service availability is
crucial, but problematic for conﬁdentiality requirements. In
fact, the chance to get conﬁdential data increases, due to
the possibility that at least one replica has unknown vul-
nerabilities. In this case, the planner considers a solution
based on cold/hot standby as more effective: the spare sys-
tem with the alternative implementation is exposed only in
case the standard one has become vulnerable. In particu-
lar, the tool prescribes the storage of disk images of VMs
with alternative implementations (e.g. a Linux ﬁrewall and
an OpenBSD one, a Linux web server and a Windows one).
Data management
In a standard system, DBMS servers
provide persistent data services to applications. In virtual
environment, our tool determines at conﬁguration time how
many DBMS virtual machines are needed and why. In fact,
since our models manage also the nature of the data of the
applications, our tool plans to spawn different DBMS in-
stances and split data belonging to different applications.
This isolation allows enforcing access control also at net-
work level by selectively authorising service component in-
teractions. For example, we can suppose that applications
X and Y need two different data sets, L and K. Instead of
allowing X and Y to communicate with the same DBMS
(that contains L and K), our tools spawn two different
DBMS, hosting L and K respectively. Our tool will then
compute the network conﬁguration rules allowing interac-
tions X < − > L and Y < − > K (see 3.2). This
’defence in depth’ mechanism can be expensive, but, if cor-
rectly balanced (e.g. right grouping of data applications),
impacts positively on the overall system security.
Unfortunately, virtual machine technologies do not solve
the problem of data loss. On the contrary, due to increased
data splitting, we need to perform more backup operations.
For this problem, our planning tool exploits the same ap-
proach of non-virtual environment. It assumes the use of
separated or external ﬁle systems (e.g. NFS, SAN), stor-
ing data in dependable way (e.g. RAID), and performing
replication/backup services. We classify virtual machines
in working machines (e.g. application servers, web servers)
that offer an execution environment and operate on remote
data, and storage machines that use their disk image as per-
manent storage (e.g. DBMS, ﬁle servers). We spawn only
the storage virtual machines in persistent mode, whereas
working machines are spawned in non persistent mode.
Therefore, the planner applies backup services only for stor-
age virtual machines, spawned in persistent mode. When
critical information is not easily separable from the other, it
is less expensive than a full backup.
3.2
Enabling and protecting communica-
tions
For authorising service interactions in non-virtualised
environment, we base on network topology and equipment
capabilities; e.g. we look for packet ﬁlters placed between
two interacting applications and select appropriate ﬁltering
rules to permit their trafﬁc. Virtualisation adds more ﬂexi-
bility in redesigning network topology (at least internally to
physical hosts), and in spawning capabilities where needed
(e.g. displace a virtual ﬁrewall in front of a service). A ba-
sic security advantage of virtualisation is ameliorating ser-
vice interaction protection in respect of traditional local net-
works. Integrity and conﬁdentiality of internal trafﬁc are of-
ten neglected and, as a result, the local network is exposed
to several security risks: unauthorised network attachment
or host compromise easily lead to jeopardise interactions
(trafﬁc snifﬁng, ARP poisoning, host impersonation, ses-
sion hijacking etc. ) and services (vulnerabilities, poor con-
trols etc. ). If we deploy two interacting services in two
virtual machines on the same host connected by a dedicated
virtual link, their trafﬁc is no more exposed to external at-
tacks. Actually, in virtualised environment, most of the se-
curity guarantees fall if the hypervisor misbehave (e.g. be-
cause of unintended design or tampering). In the following
we basically assume the hypervisor as trustworthy.
Filtering, proxing, balancing
In local area networks, we
conﬁgure Virtual LANs (VLANs) to achieve host/service
separation. This solution has some issues: (1) it requires
VLAN aware switches, not always available in local net-
works (hosts connected to the same VLAN unaware switch
are necessarily part of the same VLANs); (2) it speciﬁes
which hosts are part of the same virtual network but does
not control which services are reachable from whom. Us-
ing local ﬁrewalls, i.e.
ﬁrewalls collocated with server
equipment, has several drawbacks too: (1) decreased per-
formances due to hardware resource sharing with the appli-
cation processes; (2) software dependencies problems and
incompatibility with other installed software; (3) imperfect
security due to application vulnerabilities and their propaga-
tion (if one of provided services is vulnerable, and privilege
escalation is possible, the attacker could easily circumvent
the local ﬁrewall). For virtualised environments, our tool
designs alternative ad-hoc virtual networking to enforce
host isolation. It creates dedicated virtual links for interact-
ing virtual machines, it spawns separate virtual machines
to host ﬁltering and proxy services when needed, and uses
VPNs to protect trafﬁc ﬂowing in/out a physical host (VPN
conﬁguration is discussed in the next section). The sim-
4

461
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
plest conﬁguration template contains two virtual machines
within a physical host: one for the application service and
another for ﬁrewall services. Adding a separate virtual ma-
chine for ﬁrewall services solves problems related to depen-
dencies and vulnerabilities, because application and ﬁrewall
are now isolated.
On the other side, performance prob-
lems do not increase signiﬁcantly thanks to the efﬁciency
of modern virtualisation technologies. The ﬁrewall perfor-
mance depends on hardware capabilities (CPU and mem-
ory), operating system, network stack, and ﬁltering mech-
anism implementation. Several improvements have been
proposed to enhance virtualised networking performances
[16]. The hypervisor analyses each data packet that arrive
on the network interface and transfers it to the proper vir-
tual domain. The packet transfer operation is quite com-
plex and requires several memory operations (data alloca-
tion/deallocation).
The [16] work improves this process
modifying packet transmission and reception path. For high
assurance, a common practice is using two or more ﬁre-
wall devices in cascade: if their platforms and operating
systems are different, it is reasonable to assume that they
have different vulnerabilities. However, this conﬁguration
increases service latency, energy consumption, and costs.
For external network attachment, our tool deploys and con-
ﬁgures two ﬁrewall virtual machines with different OS and
ﬁltering software on the same physical host, reducing en-
ergy consumption and saving costs. However, two physical
hosts are still required for achieving resiliency against hard-
ware failures. More complex virtual networking is needed
when placing several application virtual machines on the
same physical host. Virtual trafﬁc ﬁltering can be enforced
either at the hypervisor or by spawning dedicated ﬁrewall
virtual machines. Hypervisor has privileged access to net-
work trafﬁc, does not depend on virtual network conﬁgura-
tion, and is much more efﬁcient. However, as the hypervi-
sor is the single point of failure it should be kept as simple
as possible: e.g. packet-ﬁltering rules can be enforced, but
extended ﬁrewalling through reverse proxies does not ﬁt.
Our tool adopts the dedicated ﬁrewall virtual machine tech-
nique. First, the tool computes the feasible conﬁgurations
(e.g. single or cascade virtual ﬁrewalls) in respect of secu-
rity requirements. It then performs a trade-off reusing the
same ﬁrewall virtual machines for several service interac-
tions (resources optimization). Finally, ﬁrewall virtual ma-
chines are conﬁgured with a virtual network interface per
each application machine that should be ﬁltered. This ap-
proach requires conﬁguring a speciﬁc IP subnet for each
application virtual machine, but allows deﬁning more spe-
ciﬁc packet ﬁltering policies (per interfaces). The increased
conﬁguration complexity is masked by the planning capa-
bilities of our tool, that computes the virtual interfaces to
adopt, and generates the ﬁltering rules for each of those in-
terfaces. This task is achieved by extending the communi-
cation authorisation module and the reachability algorithm
described in [6] to manage virtualised networks. Practically,
the reachability algorithm ﬁnds the ﬁrewall interfaces inter-
ested by each communication between network nodes by
traversing the network topology graph. Then the communi-
cation authorisation module selects and generates ﬁltering
rules for each virtual interface.
The strategies applied for ﬁrewalling can be extended to
balance load among service replicas. In fact, common load-
balancing techniques use a mix of routing, network address
translation, reverse proxing, and name services. All but the
last one works at the same level and uses mechanisms close
to the ﬁrewall services. In the last case, DNS services are
conﬁgured to use a pool of IP addresses, which correspond
to the replicated services. Name resolutions have a valid-
ity that can be conﬁgured to implement rude load-balancing
mechanisms. With a long validity, clients keep sending re-
quests to the same server and the load-balancing is ineffec-
tive. However, if the validity period is too short, every client
request may hit a different replica making session handling
trickier. To achieve load-balancing via DNS (reverse-proxy)
mechanisms our tool ﬁrst deploys a DNS (reverse-proxy)
virtual machine associated to a set of service replicas vir-
tual machines; then it conﬁgures the virtual interfaces and
virtual machines’ IP addresses, and generates the appropri-
ate DNS address pool (proxy rules). The DNS approach
is also more ﬂexible and scalable when the load-balancing
task should be performed by two or more data centres. The
primary DNS could balance the request addressing the data
centre site and a secondary DNS service, located into se-
lected data centre, could address the request to the available
virtual machine. We are most interested in how balancing
strategies interact with security mechanisms such as TLS
and VPN channels, as discussed in next paragraph.
Channel protection and Virtual Private Networks
A
common solution to protect the conﬁdentiality and integrity
of interactions across trust boundaries is authenticating and
ciphering data using TLS or IPSec technology. Both so-
lutions require more computational resources, increase en-
ergy consumption, and introduce trafﬁc overhead. In virtu-
alised environments, we can allocate services that require
channel protection in distinct virtual machines on the same
physical host: as already explained in the previous para-
graph, trafﬁc isolation can be granted without trafﬁc en-
cryption. However, when one of the endpoints is outside the
administrative domain (e.g. customers, 3rd party services),
or when the endpoints could not be aggregated on a single
host (e.g. for resource consumption), their trafﬁc should be
ciphered. To protect this trafﬁc, our best practice is per-
forming aggressive service isolation and creating a sepa-
rate logical ciphered channel for each interaction. Our tool
proposes a set of alternative conﬁgurations with different
5

462
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
trade-offs between level of isolation and resource optimiza-
tion. Consider a three-tier web application interacting with
two user categories, for example gold and platinum users.
To address availability requirements and cost savings the
presentation and application servers have to be outsourced
to a 3rd hosting service. Instead, to meet stringent secu-
rity requirements, the database should be kept internally to
the company. The most common solution for protecting the
data ﬂow between application and database across the In-
ternet (or Intranet) is to conﬁgure a Virtual Private Network
(VPN). Often, in non-virtualised environments, IPSec is
conﬁgured to tunnel the trafﬁc between two gateways. The
ﬁrst problem is that the trafﬁc between hosts and gateways
is not protected and might be attacked. In addition, IPSec
may be difﬁcult to conﬁgure, especially key exchange ser-
vices that may collide with ﬁrewall and address translation
policies. Another solution is to conﬁgure a TLS based VPN,
e.g. using OpenVPN1, that is more ﬂexible than IPSec and
easier to conﬁgure. However, as for IPSec, the TLS VPN
is often conﬁgured between two concentrators. Following
the rules described in Sec. 3.1, in similar cases, our tool
ﬁrst provides users role isolation by splitting both the appli-
cation and the database in a pair of virtual machines: one
for gold users and another for platinum ones. The tool then
computes two alternative solutions that rely on TLS VPN
concentrator virtual machines. The ﬁrst adds two TLS VPN
concentrator VMs per each application-database pair. This
conﬁguration performs strong interaction separation, allows
conﬁguring a different IP subnet for every TLS VPN, and
provides IP reachability only between interacting endpoints.
In fact, if a VPN is compromised, only its trafﬁc can be at-
tacked, while other interactions are not affected. The sec-
ond solution provides resource optimization by adding only
two VPN concentrator VMs shared by both the application-
database pairs. The VPN machines are always placed on
the same physical host of the VMs originating the trafﬁc to
protect. As already discussed for local ﬁrewalls, isolating
the concentrator in a separate virtual machine, limits attack
propagation. To implement the conﬁguration rules above,
we extended our previous algorithms, originally described
in [6], for the conﬁguration of end-to-end TLS VPNs. In
practice the tool: (1) computes the required VPN concen-
trator VMs; (2) computes the virtual interfaces to adopt; (3)
generates VPN conﬁguration rules for each of those inter-
faces. Finally, we reuse the communication authorisation
module to permit TLS VPN communications generating the
proper ﬁltering rules. Note that, in non-virtualised environ-
ments, the proposed solution and security level would have
unreasonable costs as we need to conﬁgure a host for each
virtual machine and two TLS VPN concentrators for each
interaction. Our tool can also conﬁgure balancing services
for increasing dependability of the VPN concentrators. To
1http://openvpn.net
achieve this, we can conﬁgure DNS to resolve the VPN ser-
vice to the address pool of the available concentrators. In
a more complex conﬁguration, we also add an additional
layer of reverse-proxy services acting as NAT-level load bal-
ancers and forwarding client requests to one of the available
concentrators. In both cases, we assume that the load shar-
ing mechanism is performed rarely: once an endpoint has
joined the VPN, the concentrator does not change. If the
current VPN concentrator fails, the client should rejoin, and
the DNS (and reverse-proxy) resolves to another concentra-
tor. At last, to better secure trafﬁc between the company and
the provider’s data centre (e.g. prevent trafﬁc analysis), our
tool suggests encapsulating the TLS VPNs into an IPSec
tunnel. This step uses the same conﬁguration rules origi-
nally described in [6].
We now focus on how managing secure connections
(e.g. HTTPs) in case of virtual service replicas. As pre-
sented in 3.2, our strategies for placing virtual ﬁrewalls offer
reverse-proxy and balancing capabilities. In fact, the use of
a TLS capable reverse-proxy is the simplest solution. Every
client contacts the reverse proxy that forwards the client re-
quest to one of the application virtual machines conﬁgured
in the pool. Our tool generates a set of alternative conﬁg-
urations using a TLS reverse-proxy virtual machine. One
of the simplest conﬁgurations is to displace, on the same
physical host, the reverse-proxy machine and two or more
application virtual machines. In this case, only the trafﬁc
between the proxy and the external world is ciphered. The
interactions between the proxy and the replicas are conﬁg-
ured as logical links using virtual interfaces as described
for ﬁrewalls. When replicas are allocated to multiple phys-
ical hosts, the trafﬁc between proxy and remote replicas is
ciphered via the VPN techniques described above. Unfortu-
nately, the reverse-proxy solution does not scale to large in-
stallations and multiple systems. We must introduce DNS-
based load sharing mechanisms that requires additional is-
sues to be solved. Even if the DNS resolution validity pe-
riod is correctly conﬁgured, when it expires, a new TLS
negotiation may be required. Most notably, this happens
with HTTPs sessions and the use of TLS session ID. To ef-
ﬁciently solve the TLS balancing problem we must address
two phases: negotiating a new TLS session, and resum-
ing pre-negotiated sessions through the session ID mech-
anism. The straightforward solution is using a backend en-
gine that performs TLS negotiation and/or caches session
data. For example, a relay like [20] allows a server to re-
sume a TLS session negotiated by any other one. A sim-
ilar solution that implements a centralised session cache
is the “distcache project”2, supported for example by the
Apache web server. This tool can be installed directly on
application server replicas (e.g. distcache is supported by
the Apache web server), or on reverse-proxies / TLS relays
2http://distcache.sourceforge.net
6

463
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
to load-balance TLS interactions. We also consider more
distributed solutions like the TLS session tickets speciﬁed
in [21]. They provide a mechanism to store session data on
the client side, in the way web cookies work. Basically, the
server seals the session state into an encrypted ticket and
forwards it to the client, which uses this information to re-
sume the session against any server in the pool. Similarly
to the previous solutions, session tickets are directly sup-
ported by some application servers (e.g. Apache), and can
be exploited at TLS proxies to enable distributed session re-
sumption. When selecting a server-side approach, our tool
allocates replicated virtual machines for DNS services, and
one or more VMs for TLS engine. Instead, for the client-
side approach, the tool conﬁgures the shared keys, to protect
the TLS session ticket, on each virtualised replicas.
Monitoring and logging
Monitoring and logging are rel-
evant tasks to trace system behaviour and to highlight prob-
lems. For security purposes, they are useful to check host
and service availability, to detect network attacks, to ensure
non repudiation. In non-virtualised environments, monitor-
ing tasks often rely on dedicated hosts and networks for bet-
ter performance of application services and better isolation
of monitor ones.
However, to report host/service status,
monitoring systems also install agents on each monitored
host (e.g. Nagios3). To contain costs and management ac-
tivities, every agent or network probe collect and sends a
subset of information to a centralised host, the aggregation
point that analyses the reported data. This approach has
its dependability and scalability limits in the aggregation
point. In virtualised environments, the monitor and logging
tasks can be distributed more accurately to achieve a multi-
level and dependable architecture with reduced costs. Best
practice for securing monitoring and logging tasks is using
stealth components, to hide the presence of agents and net-
work probes and preserve them from security attacks. In
virtualised systems, placing monitoring functions at the hy-
pervisor can hide and protect monitoring services. On the
other side, as already discussed for ﬁrewalls, the trade-off is
the increased complexity of the hypervisor.
Our strategy is to install an agent on every virtual ma-
chine in order to collect information like network reacha-
bility, received network packets, and service status. A set
of virtual machines able to collect reported data, are located
on different physical hosts and conﬁgured in load-balancing
mode to achieve high availability. These virtual machines,
to better address administrator objectives, are conﬁgured to
perform all monitoring/logging tasks or a speciﬁc task: for
example, collecting only network reachability data. We can
deploy another set of virtual machines (in load-balancing
conﬁguration) able to analyse the reported data, in order to
3http://www.nagios.org
build the network model, trace network behaviour, and eval-
uate security risks.
4
Conﬁguration Algorithms
4.1
Conﬁguration and Re-conﬁguration
The conﬁguration generation process is based on the re-
quirements (functional and non-functional) of the service(s)
to be hosted by the information system. It reﬁnes these re-
quirements, exploring the alternatives exploitation of avail-
able resources. These computations originate a Directed
Acyclic Graph (DAG), where every node represents a par-
tially reﬁned conﬁguration. Every step of the process, per-
forms the reﬁnement for every partial conﬁguration, read-
ing all the information generated by previous phases. Some
steps generate directly element to be used for the ﬁnal con-
ﬁguration, whereas others compute artefacts that are use-
ful only for the steps executed after. When all the reﬁne-
ment steps are completed, the ﬁnal leaves of the conﬁgura-
tion DAG represents the ﬁnal conﬁgurations to be enforced
while conﬁguring the information system. Some conﬁgura-
tion will presents different level of residual requirement to
be managed by the actual devices. If the requirements are
high, the system recommends the usage of high availability
devices; ignoring these recommendations causes a conﬁgu-
ration with lower dependability of the system.
In order to react to emergency states, some rules per-
form a linkage between conﬁgurations. In other words, on a
conﬁguration, if occurs an event that could compromise the
achievement of the requirements. Reaction consists in per-
forming a conﬁguration switch to alternative reﬁnements,
where such risky events do not occur or their effects are
negligible or tolerable. In fact, faults or vulnerability ex-
ploitation make affected components unusable. Such links
are named “Reaction” and links the problem in a conﬁgu-
ration to the novel conﬁguration to be adopted. The target
(emergency) conﬁguration is chosen among alternatives as
the one with less differences compared with the current one,
to minimise the reaction time. This retrieval is performed,
searching the conﬁguration that is not excluded by the fault,
with the maximum number of choice of reﬁnements in com-
mon: this operation is simple since the conﬁguration DAG
maintains tracks of every choice.
The class diagram in Fig. 1 represents the data used in
the process. The dashed boxes discriminates the different
supplier of such data.
Administrators supply as input the list of the service
components, “Service” in the diagram, and, for each of
them, the different implementations of the service, “Imple-
mentation”. Every implementation is composed by one or
more software packages, with their dependencies. We re-
fer to functional requirements to indicate the implementa-
7

464
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
tion together with the Service Access Point and the need
to permanently store data or not. Furthermore, administra-
tors assign values to non functional (dependability) require-
ments, classiﬁed on a scale of LOW, MEDIUM and HIGH:
availability (how much is important that a service is avail-
able?), conﬁdentiality (does the service manage classiﬁed
data? How much it is important to preserve their conﬁden-
tiality?) integrity (how much is serious if the service or the
service data are tampered?). Other requirements could be
added, but the extension must supply also additional rules
to the process to reﬁne them. Since the requirements are
assigned to all the elements, we created an abstract class
that is extended by every object subject to requirement. The
adoption of a coarser scale for such requirements is sup-
ported and possible, if the rules are changed to understand
it. Our concern is the beneﬁt of a more detailed scale would
not confuse the network administrator, without an actual
gain in terms of more precise conﬁgurations.
The process exploits also the SoftwareDatabase that con-
tains the data on the dependencies and conﬂicts among soft-
ware packages. It is built on the base of package managers’
repository, like RPM.
Finally, the box Reﬁnements collects the elements gen-
erated during the process, described in the following sec-
tions. During the description of the process the meaning
and the usage of the classes will be clariﬁed. Such ele-
ments are grouped together to create different conﬁguration
(in the diagram we connected only the superclass Compo-
nent for readability purposes). Furthermore, some compo-
nents are subject to event that causes a reconﬁguration tasks
(a change from a conﬁguration to another).
4.1.1
Service provisioning
The purpose of this step consists in deﬁning the compatible
software group, using the implementation of the different
service components. Each of them presents ore or more
implementation whose software requirements are solved by
means of the software database.
First, the algorithm generates different software pack-
ages groups (containing the application software and its de-
pendencies) for every service. If the dependency can be
satisﬁed in different manners, alternative groups are gener-
ated. They derive the software requirements of the services
implementation. Then, additional groups are added merg-
ing such basic groups, if the software packages compos-
ing them, including the dependencies are is compatible, i.e.
there are not packages in conﬂict. Actually, if the conﬁden-
tiality or integrity is HIGH or they have a different value, or
if their availability is HIGH, groups are not merged, other-
wise the group takes the maximum for every dependability
requirement.
Moreover, requirements are inter-related. The tool prop-
agates the requirements of availability to the software im-
plementation (and, of course, its dependencies) into require-
ments of conﬁdentiality and integrity. We propagate the
requirement of integrity as conﬁdentiality, and vice-versa.
Such requirements are propagated with a level lower that the
originating one, for example an availability=HIGH will be-
come a conﬁdentiality=MEDIUM and integrity=MEDIUM,
since they are derived requirements.
Listing 1 presents the implementation of the task that is
composed by three main parts. In group initialisation, a dif-
ferent group for each implementation is created. In depen-
dency retrieval the tool completes the dependency by means
of software database, and in case of different alternatives to
satisfy, it creates different groups, without conﬂicting soft-
ware packages. In merging groups, if compatible originates
additional composed groups.
Listing 1. Allocation computation
//Group initialization
foreach service in Service.getInst()
foreach impl in service.impl()
Group g = new Group(service, impl)
foreach sw in impl.getSw()
g.add(sw);
//Dependency retrieval
foreach g in Group.getInst()
foreach sw in g.getSoftwares()
Impl alternativeDeps = SoftwareDB.getDeps(sw);
foreach alternativeDep in alternativeDeps
// if the software to add do not presents any
conflict ...
SoftwareDB.getConflicts(alternativeDep.getSoftwares()).
intersect(g.getSoftwares)
==null
Group gNew = g.clone();
gNew.addAll(alternativeDep.getSoftwares);
//Merging groups
foreach g1 in Groups.getInstances()
foreach g2 in Groups.getInstances()
if (g1 != g2)
if (g1.isCompatible(g2))
Group g = Group.merge(g1,g2);
The generated groups of software packages are aggre-
gated together to compose different solutions at application
level, with at least one group for every service. If the service
requires MEDIUM or HIGH availability, it is possible get
more groups, with a lower level of availability, implement-
ing a redundant solutions or maintaining only one group that
will be than achieved or with a VM duplication or with HA
devices.
In this phase, also groups with different implementation
or dependencies for the same service are generated, to im-
plement a diversity design strategy. In this case, the prop-
agation from the availability to the other requirements is
computed subtracting two levels, since to deﬁnitely com-
promise the availability of the service, it is needed to ﬁnd a
way to compromise every implementation. On the contrary,
8

465
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
Figure 1. Class Diagram for the reﬁnement algorithms
conﬁdentiality requirement is augmented of one level, since
the violation of single software is sufﬁcient to access to crit-
ical condition.
A more complex analysis is necessary for integrity is-
sues, in fact, a different implementation may help in recog-
nising when integrity is violated (same service returning
different results) but for understand the correct results it
is necessary having at least three implementation, to mas-
querading an integrity violation on one group, as explained
in [14].
Actually, to implement this measure, it neces-
sary having ad-hoc modules to implement a voting system.
Since such modules are not common, integrity requirement
propagation is not modiﬁed by diversity implementation.
Additional conﬁgurations are generated, to be used in
emergency conditions. Our tool generates conﬁgurations
with only the service with availability=HIGH, conﬁgura-
tion with all the service with availability=HIGH and some
or all service with availability=MEDIUM and conﬁguration
with the entire MEDIUM and HIGH availability service and
some low availability. Indeed, when a conﬁguration is cho-
sen, the best choice is the one that offers as more service as
possible, but the reactions could use also others to maintain
at least the critical service available.
Listing 2 brings the results of Listing 1. It performs the
conﬁguration generation, providing every possible combi-
nation of the group, collecting in conf instances.
Listing 2. Conﬁguration generation
// Configurations Initialisation
if (Configuration.getInst()==null)
foreach service in Service.getInst()
foreach impl in service.getImpl()
foreach g in impl.getGroup()
Configuration conf = new Configuration(g)
//Configurations generation
foreach service in Service.getInst()
foreach conf in Configurations.getInst()
foreach impl in service.getImpl()
foreach g in impl.getGroup()
Configuration conf1 = conf.clone()
conf1.add(impl);
//supposes that conf is inserted into the
Configuration register only if no other conf with the
same impls is already
available
9

466
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
4.1.2
React to new vulnerabilities discovered
It is common that new vulnerabilities are discovered when
the system is already online. Typically, such vulnerabilities
are available on vulnerability databases like National Vul-
nerability Database [4]. The tool matches the vulnerability
with the software available in every system and, on the base
of the impact they have, plans reactions. In fact, vulnerabil-
ities entries present also a Common Vulnerability Scoring
System [5] evaluation of the impact in term of conﬁdential-
ity, integrity and availability.
In practice, the conﬁguration generator retrieves all the
vulnerabilities affecting every software package in the sys-
tem and crosses the menaces of exploitation with the de-
pendability requirements. Even if, it is generally a good
practice having as few open vulnerability as possible in
the system, the tool is concentrated to maintain satisﬁed
dependability requirements. In other words, if a software
package presents a vulnerability affecting its integrity, and
the requirements for the group of software packages are for
availability it does not consider vulnerability exploitation
a problem. A natural objection to this method is: “What?
Such requirements are linked. Integrity gives conﬁdential-
ity, integrity and conﬁdentiality gives availability...”. We
agree with this assertion, in fact we consider these issues
in the propagation of the requirements throughout the con-
ﬁguration phases, and, they are already evaluated w.r.t. the
interdependency among them.
Typical reaction to vulnerability consists in switching
(when possible) to an alternative implementation, updat-
ing/patching menaced software packages, or turn off the
dangerous application. If there is an alternative conﬁgu-
ration that is not affected by the vulnerability in object, the
reaction implies a conﬁguration change. Unfortunately, in
many cases, such solution is not feasible and we have not
any alternative implementation. Consequently, the model
of software and software dependencies needs to be updated
with the last version of the products, which hopefully will
be not affected to this. Then, the tool generates additional
conﬁgurations, which are added to the conﬁguration tree.
At this point, we plan a conﬁguration swap to one of the
new conﬁguration generated. In case of none of the previ-
ous solution is possible, it remains or tolerating the situation
(if the availability of the service is crucial) or switching to
a conﬁguration that does not use to software, even if some
service are not available. This last approach is to be con-
sidered transitional, and the update of the software model
is performed regularly, in order to generate a conﬁguration
with all the services available again as soon as possible.
Listing 3 computes the reaction in case of vulnerability
discover. For each requirements associated to a software,
an event of type VULNERABILITY is set. If there is a
different implementation of sw, the reaction performs the
conﬁguration swap to the corresponding conﬁguration; oth-
erwise, it excludes the sw from the usage (again as conﬁg-
uration change) or tolerates the vulnerability on the base of
the availability requirement.
Listing 3. Reaction to vulnerability discover
//Reaction to vulns
foreach conf in Configuration.getInst()
foreach impl in service.getImpl()
foreach g in impl.getGroup()
foreach sw in g.getSoftware()
reqs = sw.getReqs()
foreach req in reqs
if (req.getValue() == HIGH
||req.getValue() == MEDIUM)
Event vt = new Event(sw, VULNERABILITY
,req);
//finds an alternative configuration, with the
service implemented by the sw available, but without the
sw vulnerable
alternativeConfs =
ConfigurationDag.filter(!contains(sw)).filter(!contains(
service)).getCloser(conf
);
if (alternativeConfs!=null)
Reaction r = new Reaction (vt,
alternativeConf);
else
// if the requirement availability is not HIGH,
whereas the others are HIGH or MEDIUM, or the
availability is HIGH, while the
it is we plan to switch off the service
if (reqs.getAvailability().getValue !=
HIGH || (reqs.getAvailability().getValue != MEDIUM &&
req.getValue()== MEDIUM))
//finds an alternative configuration,
but without the sw vulnerable (but this will not have
the service availabel)
alternativeConfs =
Configurations.getInst().filter(!contains(sw).filter()))
;
Reaction r = new Reaction (vt,
alternativeConf);
4.1.3
Virtual machine architecture
VM generation considers the groups of software of every
conﬁguration generated by the previous step, together with
their dependability requirements. First, for every group is
created a separated VM. Second, if a group presents a high
level of availability, more than one VM can be assigned,
with a lower availability requirement. Depending by the
service, it is indicated if the machine needs to store perma-
nently on its own ﬁle system or not, to discriminate between
working machines and storage machines.
The dependability requirements of the VM are used to
eventually choose among different VM templates. If the
availability requirement is high, the performance of the VM
must be coherent. If the conﬁdentiality is high, it will re-
quire VM templates with additional protection, like per-
sonal ﬁrewalls or disk-image encryption. VM integrity will
imply, again, protection from network, like personal ﬁre-
walls, but also digital signature of disk-images. The adop-
tion of trusted computing techniques will be also useful to
10

467
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
satisfy such requirements.
The VM resulting from this computation derives the re-
quirements from the software packages of the correspond-
ing group, which are used to plan the deployment of the
machine on virtualisation environment. Also VM conﬁgu-
rations for emergency conditions are generated, to be linked
by reactions, as we see in the following sections.
For this work, we consider having different templates of
virtual machines, classiﬁed on the base of their capability to
satisfy non-functional requirements. First, the machine can
present a classiﬁcation on the base of their performances,
to answer to availability requirements. Then, they can have
an operating system implementing Mandatory Access Con-
trol (MAC) that beneﬁts conﬁdentiality and integrity. They
can offer the chance to spawn only digitally signed disk im-
ages. They can have one or more personal ﬁltering software
packages (e.g. proxy, ﬁrewall) to limit the access from ex-
ternal. They can offer cryptographic primitives to stores
only ciphered data that increase the conﬁdentiality, but de-
crease the availability. Unfortunately, the match between
these capabilities and the dependability requirements is not
one-to-one, and, furthermore, some mechanisms useful for
requirements are counter-productive for others. For this rea-
son, over dimensioned conﬁgurations are generated, and,
only after considering all mechanisms, the conﬁguration are
chosen.
Actually, the conﬁgurations candidates to be applied are
the ones with the lower requirements remaining. In fact,
machines with higher speciﬁcations cost more. Another im-
portant factor is the number of machines, the lower it is, and
the cheaper is the solution. More expensive, but promising,
conﬁgurations are kept into account to perform reactions in
case of problem.
Listing 4 presents the generation of VM starting from
groups. In this part is crucial the match between the depend-
ability requirements of the groups and the service offered by
the VM. In the ﬁrst part, generation of vm , the availability
is mitigated generating different conﬁgurations with a vary-
ing number of VM assigned. Availability requirements are
coherently adjusted, to consider the redundancy. In the sec-
ond part, mitigation of requirement thought VM capabili-
ties, creates different conﬁguration, for every VM, adopting
a different technical solution. Note that, since this process
is executed more times, also combinations of different solu-
tions are possible. MAC means mandatory access control,
TC trusted computing techniques, CRYPTO cryptographic
primitives, FILTERING a personal ﬁrewall system.
Typically, the best conﬁgurations are the one whose re-
quirements on VMs are lower, since it implies
Listing 4. VM generation
//Generation of vm
foreach conf in Configuration.getInst()
foreach impl in service.getImpl()
foreach g in impl.getGroup()
//Maximum number of machines to be created
if (g.getReqs.getAvailability().getValue == HIGH)
limit
= 4;
else if (g.getReqs.getAvailability().getValue ==
MEDIUM)
limit = 3;
else limit =2;
for (n_machines=1; n_machines++; n_machines<=limit)
conf_new = conf.clone();
for (i=1; i++; i<=n_machines)
//get the correct VM template
vm = new VM (group, conf_new);
vm.setReqs (group.getReqs());
// decreases the availability, one level
every additional virtual machine
vm.decreaseAvailability(n_machines)
//Mitigation of requirement thought VM capabilities
foreach vm in VM.getInstances();
conf = vm.getConf();
if (group.getReqs().getIntegrity = HIGH)
vmt = vm.clone();
vmt.add(MAC);
vmt.getReqs().decrease(INTEGRITY);
if (group.getReqs().getIntegrity = HIGH)
vmt = vm.clone();
vmt = vm.clone();
vmt.add(TC);
vmt.getReqs().decrease(INTEGRITY);
if (group.getReqs().getConfidentiality = HIGH)
vmt = vm.clone();
vmt.add(CRYPTO);
// increases the integrity, since the requirement of
confidentiality is
mitigated if the VM is integer
vmt.getReqs().increase(INTEGRITY);
// increases the availability requirements, since
cryptography decreases
performance
vmt.getReqs().increase(AVAILABILITY);
vmt.getReqs().decrease(CONFIDENTIALITY);
if (group.getReqs().getIntegrity > MEDIUM or group.
getReqs().getConfidentiality
> MEDIUM)
vmt.add(FILTERING);
if (vmt.is(CRYPTO))
avail = vmt.getAvailability ();
if (avail == MEDIUM)
vmt.setAvailability (HIGH);
if (avail == LOW)
vmt.setAvailability (MEDIUM);
4.1.4
React to service performance degradation
When performance for a service is not satisfactory, due to
peaks in workload or a Denial of Service Attack, the re-
action consists in adding computational resources to the
stressed service. Another solution consists in using VM
with higher performance, instead of the original ones.
Alarms derive from sensor put on the VM, and could, for ex-
ample, high CPU or memory consumption. Another alarm
is typically required, to advertise that the solution is over-
sized (for example low CPU load) to react back to normal
11

468
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
usage conditions.
To generate this reaction plan, the tool generated addi-
tional conﬁguration for virtual machines that uses a higher
number of VMs then in normal condition, or VM with more
computational resources, also for the conﬁguration that do
not have all the service active. At this point, depending by
the availability needs of the VM, we generate a reaction
to the proper conﬁguration: if availability needs is set to
HIGH tools prefer a conﬁguration with an additional VM,
also if this implies losing some service (with an availabil-
ity less than high); if availability is MEDIUM it generates a
conﬁguration switch to use an additional VM only if it has
the same available services of the starting one, otherwise
it plans the usage of a more powerful machine; if the avail-
ability is LOW, it plans the usage of a more powerful virtual
machine, if available, otherwise it performs no reactions.
Listing 5 presents the computation of reaction to low per-
formance on a virtual machine. If the availability is HIGH,
we switch to another conﬁguration with a higher number
of machines, also decreasing the number of machines with-
out considering other machines. When the availability is
MEDIUM, it switches only to conﬁguration with the same
number of service available.
Listing 5. reaction to VM performance degra-
dation
// React to performance degradation
foreach vm in VM.getInstances()
g = vm.getGroup();
impl = g.getImpl();
// for each configuration in which the vm is involved
foreach conf in vm.getConfs()
/// in case of performance low, pass to a
configuration
with an higher number of machines
if (vm.getReqs().getAvailability == HIGH)
Event e = new Event(PERFORMANCE_LOW, vm);
alternativeConf =
ConfigurationDag.filter(.getImpl().getGroup().getVM().
count >
.getVM().count()).getCloser(conf);
Reaction r = new Reaction (e, alternativeConf);
if (vm.getReqs().getAvailability == MEDIUM)
Event e = new Event(PERFORMANCE_LOW, vm);
alternativeConf =
ConfigurationDag.filter(conf.getImpl() ==
.getImpl()).filter(.getImpl().getGroup().getVM().count >
.getVM().count()).getCloser(conf);
Reaction r = new Reaction (e, alternativeConf);
4.1.5
React to VM integrity violation
As already said, integrity violation implies more complex
reactions, but virtualisation environment helps.
First, the tool distinguishes in storing and working ma-
chines. For working machines that are spawned in non-
persistent mode, a ﬁrst measure consists in rebooting the
machine.
On the contrary, for storing machines, we can react
swapping to a conﬁguration in which the violated machine
is not longer used. If this violation is caused by vulnerabil-
ity exploitation, and the integrity is high, the system could
also consider switching off the machines affected, until a re-
action for the vulnerability is not put in act. Another option
offered by the tool consists in changing the conﬁguration
to another one with a stronger integrity protection for the
machine.
Listing 6 pseudo-code shows the implementation of this
step. It creates an event of type INTEGRITY VIOLATION
for every VM with an integrity grater or equal to MEDIUM,
and attaches to it a reaction to conﬁguration where the in-
tegrity requirement is lower. In case of lack of proper alter-
natives, if the requirement of availability is lower than the
integrity one it react passing to a conﬁguration that does not
use the tampered machine, otherwise it tolerates the viola-
tion, without any change to conﬁguration.
Listing 6. reaction to VM integrity violation
foreach vm in VM.getInstances()
g = vm.getGroup();
impl = g.getImpl();
foreach conf in vm.getConfs();
if (vm.getReqs().getIntegrity() > MEDIUM)
/// in case of integrity violation, search a vm,
with
the same group but with a lower integrity requirements,
Event e = new Event(INTEGRITY_VIOLATION, vm);
alternativeConf =
ConfigurationDag.filter(vm.getGroup().getVM().
getIntegrity() <
group.getVM().getIntegrity()).getCloser(conf);
if (altenativeConf!=null)
Reaction r = new Reaction (e, alternativeConf);
else if (vm.getIntegrity()>vm.getAvailability)
// if not available and integrity is greater
than availability, switch to a configuration that does
not use the vm (switch
off the vm)
alternativeConf =
ConfigurationDag.filter(!.contains(vm)).getCloser(conf);
4.2
Enforcing security controls
The reﬁnement process, as deﬁned previously, is repre-
sented as a directed acyclic graph. The general workﬂow
to enforce security controls is composed by the following
steps: (1) evaluation of the suitable and available technolo-
gies; (2) reﬁnement of directly and indirectly security con-
trols; (3) generation of alternative conﬁgurations. Each step
reﬁnes the information provided by the previous ones and
populates the graph adding a new level for each step. Each
path between the root and a leaf represents an enforceable
solution. Alternative conﬁgurations are represented as dif-
ferent nodes of the same level.
The ﬁrst step analyses the security requirements to derive
the suitable technologies to protect communication trafﬁc.
12

469
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
Our model associates CIA properties (conﬁdentiality, in-
tegrity and availability), expressed as LOW, MEDIUM or
HIGH to a set of suitable technologies and related modes.
For example, if conﬁdentiality and integrity are set to
MEDIUM the model suggests that the available technolo-
gies are TLS, IPSec and TLS VPN. Otherwise, if conﬁden-
tiality and integrity are set to HIGH, the model suggests
adopting IPSec or TLS VPN. On the contrary, the availabil-
ity property identiﬁes when a service has to be replicated
adopting load-balancing techniques.
The association be-
tween security properties and technologies is deﬁned into
technology templates, expressed using an XML based lan-
guage.
Such templates also contain technology-speciﬁc
modes to support alternative conﬁguration. For example,
the IPSec technology-speciﬁc template contains three dif-
ferent conﬁgurations: tunnel, transport and remote access.
After analysing suitable technologies, the tool analyses
network components capabilities to evaluate which tech-
nologies can be directly or indirectly enforced.
A tech-
nology is directly enforceable if exist a set of services or
devices which support the related capability (e.g. IPSec,
TLS, ﬁltering). Otherwise, if no service or device is able to
support the technology we should enforce it indirectly in-
stalling a new feature or adopting virtualisation techniques.
Our choice consisting providing a virtual machine with the
required features in order to make this process more ﬂex-
ible, secure and feasible. The beneﬁts derived from this
strategy are described in details in the next sections. Our
tool supports ﬁltering and channel protection security con-
trols which can be both directly or indirectly enforceable.
This process is divided into two sub-steps: network com-
ponent analysis and communication policy analysis. The
ﬁrst step takes in input the network description and classi-
ﬁes hosts, routers, ﬁrewalls and services information to dis-
cover network components features and capabilities. The
second step analyses communication components to iden-
tify network components involved in the policy. More pre-
cisely the algorithm transforms the network in a graph, ﬁnds
all paths between policy elements (source and destination)
and identiﬁes the security components (which have secu-
rity capabilities, e.g. ﬁltering, channel protection) involved
in the communication. When ﬁltering or channel protection
capabilities are not available, our tool adopts a set of virtual
machines with conﬁgurable security controls to enforce the
policy. Such VMs have to be added to the output VM archi-
tecture for deployment on virtualised providers.
The adoption of virtual machines allows enforcing a se-
curity control on demand, satisfying policy requirements.
First of all it is necessary understanding which security
controls should be enforced using the virtualisation tech-
nology. For example, considering the objective to enforce
IPSec in tunnel mode for protecting trafﬁc between two
servers.
The tunnel mode requires the adoption of two
IPSec gateways to enforce the tunnel (as deﬁned in the
IPSec technology-speciﬁc template).
Evaluating security
components involved in the policy the algorithm ﬁnd only
one suitable gateway. To enforce the policy two general so-
lutions are available: (a) deploy a virtual machine as IPSec
gateway; (b) deploy two virtual machines, one for each
server. However the problem is quite complex. When an
administrator conﬁgures IPSec in tunnel mode, the trafﬁc
that belongs on untrusted network (e.g. Internet) must be ci-
phered. This simple consideration entails that each gateway
is displaced internally to a trusted network or at its border.
Therefore, the use of a gateway displaced in untrusted net-
work partially invalidates the beneﬁt of ciphered channel.
However, if an IPSec gateway is displaced in untrusted net-
work, a possible solution is to deploy two virtual machines
(in the trusted networks) and not conﬁgure the other gate-
way. The deployment of a virtual machine requires a host
able to support virtualisation. To identify in the network
which are the available hosts we deﬁne the virtualisation
feature as a capability. Therefore, when the algorithm per-
forms network description analysis identify the hosts which
support virtualisation. At previous step the algorithm de-
cides which virtual machines are necessary then it evalu-
ates, using a set of strategies, which hosts are selected to
guest VMs.
This approach requires to analysing allocations ﬁnding
which hosts guest allocated VMs.
To maximize perfor-
mance a physical host supports a limited set of virtual ma-
chines depending on its hardware features. Hence if the host
supports the required VMs to enforce security controls the
algorithm plan to add the new VMs. Otherwise our strategy
is to ﬁnd the nearest suitable host.
Once the tool decides which security controls should be
adopted to protect communication trafﬁc it is necessary to
identify their displacement. Our approach is to group to-
gether services and security controls as indivisible block
using a predeﬁned template. Practically a template con-
tains a set of predeﬁned VMs to perform security controls
which can be enabled or disabled depending on require-
ments (e.g. TLS VPN VM and ﬁrewall VM). In addition
this strategy allows conﬁguring the related virtual network
in more simple way.
4.2.1
Security controls templates
Once the tool derives the required security controls, the re-
lated VMs templates (depicted in Fig. 2) are used to gen-
erate alternative conﬁgurations which should be ﬁnally de-
ployed on virtualisation platforms. The simplest template
is ServiceTemplate that contains three virtual machines:
VM Service, VM FW and VM VPN. The ﬁrst virtual ma-
chine is adopted to host the service and it is mandatory. The
VM VPN instead can be activated on demand to protect ser-
13

470
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
Figure 2. Security controls VMs templates
vice trafﬁc. It can be implemented using IPSec or TLS VPN
technologies as alternative solutions. The VM FW is also
mandatory and it is responsible to ﬁlter trafﬁc among ser-
vice, VPN and external network. As depicted in Fig. 2 this
virtual machine is connected in bridged mode to the exter-
nal network (ExtNet1), the local sub-network of the host,
and to other VMs using two virtualised networks (VNet1
and VNet2). This logical conﬁguration allows separating
and masquerading external and internal (virtualised) net-
works. For example, to allow trafﬁc between the external
network and the service, on the ﬁltering virtual machine we
can add a port forwarding rule, masquerading internal net-
work. In addition, when VM VPN is active, it is possible
to derive a set of rules to: (a) allow only ciphered trafﬁc
between external and VM VPN; (b) allow unprotected traf-
ﬁc only between VM VPN and VM Service. The security
requirements, deﬁned as input are reﬁned using templates.
For example, if the conﬁdentiality requirement of service is
set to HIGH, in the resulting template the VM Service and
VM VPN are set to MEDIUM.
The BalancedServiceTemplate introduces the load-
balancing functionality adopting the VM LB. This, often
implemented as a reverse-proxy, is in charge to dispatch
trafﬁc (protected or not protected) among replicas to en-
hance service availability. The application of this template
is mandatory when in the conﬁguration there are more soft-
ware package groups for one implementation. In that case
the availability requirement on VM LB is set to HIGH. An
interesting extension to ameliorate service availability is
to add another load-balancer VM. This can be placed in
standby and resumed as soon as the ﬁrst load-balancer fails.
In order to decrease the number of virtual machines and
to aggregate functionalities the ﬁltering and reverse-proxy
could be grouped together as a VM PRX-FW. An interest-
ing extension of this template is to introduce load-balancing
feature for VPN trafﬁc. In a simple scenario we can substi-
tute the service replicas with VPN virtual machine replicas
enhancing VPN service availability. In more complex sce-
nario the objective could be to improve availability of ap-
plication and VPN services. In that case, we can modify
the template to insert two different load-balancers: one for
application and another for VPN replicas.
14

471
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
Finally the last template MultipleServiceTemplate is suit-
able to displace different service virtual machines on the
same physical host. In this conﬁguration each service is
directly linked to the VM FW using a virtual sub-network
with speciﬁc network address and the VPN gateway is
shared to different services. However it is possible conﬁg-
ure the virtual machines to belong to the same sub-network.
Grouping together the service VMs allows optimizing their
allocation enhancing general performance introducing a se-
curity drawback. In fact, each service is protected using
the same VPN channel and if the VPN is compromised, all
trafﬁc could be jeopardized. To reduce the related risk the
template could be modiﬁed to support different VPN gate-
ways. Practically we can displace a shared VPN gateway
for non critical service and a speciﬁc VPN VM for each
critical service.
4.2.2
Security controls transformations
Once the tool selects the set of templates to adopt, it per-
forms a set of transformations to reﬁne the provided in-
formation. A transformation T is an operation that takes
as input a set of services, a template and security require-
ments and produces a set of alternative conﬁgurations. A
subset of security controls transformations is depicted in
Fig. 3. A conﬁguration is expressed using an XML based
language and contains: (a) the VM components; (b) the vir-
tualised and physical network description; (c) the policies
to enforce. The VM components and the virtual network
links are derived from the set of services and template, then
the virtual and physical network conﬁguration are computed
consequently. The ﬁrewall virtual machine is directly con-
nected using a bridge to the physical network. The related
external IP should be assigned accordingly to physical host
subnet evaluating network description. The algorithm, after
a network analysis, proposes to the administrator a set of
available IPs. For each virtual links the algorithm computes
the network conﬁguration for each virtual machine. In prac-
tice it selects the addresses range from a table that contains
the allocations for private networks (populated considering
the [1]) and generates other network information (gateway,
DNS). Finally, the tool generates the related policies for the
provided solution. This process is composed by two steps:
(1) generation of channel protection policies; (2) genera-
tion of ﬁltering policies. Considering the selected security
technology and the service description, the algorithm gen-
erates the related properties for each virtual machine related
to a protected communication. For example, if the selected
technology is HTTP over TLS, the TLS properties (e.g. ci-
pher suite, server authentication or mutual authentication,
etc. ) are attached to the service virtual machine component
conﬁguration. In similar manner, when the tool selects TLS
VPN or IPSec, the algorithm attaches the related proper-
ties to the VPN component. Finally the algorithm evaluates
the components security properties and virtual network con-
ﬁguration generates the ﬁltering policies. In practice, the
ﬁrewall VM is conﬁgured to forward trafﬁc between exter-
nal world and internal services according to security prop-
erties. For example, if the internal service is protected using
HTTP over TLS, the ﬁrewall policy forwards only HTTPS
trafﬁc between external and internal networks. To clarify
Listing 7. Network conﬁguration and policies
for (a)
<VM id=’VM_Service’>
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’10.10.10.2’ />
<netmask value=’255.255.255.0’ />
<gateway value=’10.10.10.1’ />
<dns value=’ask to admin’ />
</network-interface>
</VM>
<VM id=’VM_FW’>
//bridged interface
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’ask to admin’ />
<netmask value=’ask to admin’ />
<gateway value=’ask to admin’ />
<dns value=’ask to admin’ />
</network-interface>
//VNet1
<network-interface value=’eth1’>
<addr type=’IPv4’ value=’10.10.10.1’ />
<netmask value=’255.255.255.0’ />
<gateway value=’ask to admin’ />
<dns value=’ask to admin’ />
</network-interface>
<policies>
<filtering-policy id=’1’>
<type=’forwarding’ />
<src ip=’*’ proto=’tcp’ port=’80’ />
<dst ip=’10.10.10.2’ proto=’tcp’ port=’80’ />
<action value=’allow’ />
</filtering-policy>
</policies>
</VM>
the security controls reﬁnement we discuss the transforma-
tions of Fig. 3. The most simple transformation is iden-
tiﬁed by (a) and generates a conﬁguration that contains a
service and a ﬁrewall virtual machines. The tool (1) de-
ﬁnes the properties of the virtual network that links service
to the ﬁrewall; (2) generates a port forwarding policy to al-
low external trafﬁc reaching internal service using speciﬁc
protocol and port. The algorithm analyses the table of pri-
vate addresses and provides the network conﬁgurations for
the virtual machines shown in listing 7. For example, let
us consider that the service is a web server that uses HTTP
protocol on port 80: the ﬁrewall (VM FW) is conﬁgured to
forward trafﬁc from external network to the internal service
as described in listing 7.
The (b) example demonstrates service load-balancing.
In this case the tool generates network conﬁgurations for:
(1) the sub-network VNet2 that contains the load-balancer
15

472
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
s1
External 
Network
T(s1, ServiceTemplate, secReq)
VM_FW
VM_s1
External 
Network
SecReq:
CIA=(LOW, 
LOW, LOW)
s1R1
External 
Network
SecReq:
CIA=(HIGH, 
HIGH, HIGH)
T((s1R1,s2R2), BalancedServiceTemplate, 
secReq)
s1R2
VM_FW
External 
Network
ExtNet1
VM_VPN
s1
External 
Network
SecReq:
CIA=(HIGH, 
HIGH, LOW)
s2
VM_FW
VM_s1
VM_VPN
External 
Network
VM_s2
T((s1, s2), MultipleServiceTemplate, 
secReq)
T((s1, s2), ServiceTemplate, 
secReq)
VM_FWs1
VM_s1
VM_VPNs1
VM_FWs2
VM_s2
VM_VPNs2
External 
Network
(a)
(b)
(c)
VM_s1R1
VM_LB
VM_s1R2
VNet2
VNet1
ExtNet1
VNet1
ExtNet1
VNet1
VNet2
VNet3
ExtNet1
VNet1s1
VNet2s1
VNet1s2
VNet2s2
(c1)
(c2)
Figure 3. Security controls transformations
(VM LB) and the replicas (VM s1R1 and VM s1R2); (2)
the sub-network VNet1 that contains the VPN gateway
(VM VPN). The virtual ﬁrewall (VM FW) policies are: (1)
port forwarding for load-balanced services; (2) port for-
warding for VPN service (if the gateway is based on TLS
VPN technology).
In addition, the tool conﬁgures the
VM LB to balance trafﬁc among replicas and the VM VPN
to protect communications. The load-balancer conﬁgura-
tion depends on mechanism selected to implement its func-
tionality. The VPN gateway, often implemented as TLS
VPN (for ﬂexibility purposes), can be conﬁgured as client
or server. For example, it is often conﬁgured as server on
the service side and in client mode on external clients (any-
to-one interaction model). In other cases, VPN gateways
could be conﬁgured as one-to-one, i.e. to tunnel trafﬁc be-
tween two different services or any-to-any, i.e. to tunnel
16

473
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
Listing 8. VPN and balancer network conﬁgu-
ration and policies for (b)
<VM id=’VM_VPN’>
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’10.10.10.2’ />
<netmask value=’255.255.255.0’ />
<gateway value=’10.10.10.1’ /> <!-- to VM_FW -->
<dns value=’ask to admin’ />
</network-interface>
<vpn-network-conf>
<vpn-pool type=’IPv4’ lowValue=’10.10.10.5’
highValue=’10.10.10.10’/>
<vpn-service-addr type=’IPv4’ value=’10.10.10.2’ />
<vpn-service-interface type=’tap’ value=’tap0’/>
<vpn-service-protocol type=’tcp’ port=’1194’/>
</vpn-network-conf>
</VM>
<VM id=’VM_LB’>
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’10.10.20.2’ />
<netmask value=’255.255.255.0’ />
<gateway value=’10.10.20.1’ /> <!-- to VM_FW -->
<dns value=’ask to admin’ />
</network-interface>
<balancer-conf>
<balancer id=’balancer-VM_LB’>
<addr type=’IPv4’ value=’10.10.20.2’ />
<proto type=’tcp’ port=’80’ />
</balancer>
<replicas>
<replica id=’replica-VM_s1R1’>
<addr type=’IPv4’ value=’10.10.20.3’ />
<proto type=’tcp’ port=’80’ />
</replica>
<replica id=’replica-VM_s1R2’>
<addr type=’IPv4’ value=’10.10.20.4’ />
<proto type=’tcp’ port=’80’ />
</replica>
</replicas>
</balancer-conf>
<balancer-policies>
<balancer-policy id=’1’>
<balancer-fronted value=’balancer-VM_LB’/>
<balancer-replica value=’replica-VM_s1R1’/>
<balancer-replica value=’replica-VM_s1R2’/>
</balancer-policy>
</balancer-policies>
</VM>
<VM id=’VM_s1R1’>
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’10.10.20.3’ />
<netmask value=’255.255.255.0’ />
<gateway value=’10.10.20.1’ />
<dns value=’ask to admin’ />
</network-interface>
</VM>
<VM id=’VM_s1R2’>
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’10.10.20.4’ />
<netmask value=’255.255.255.0’ />
<gateway value=’10.10.20.1’ />
<dns value=’ask to admin’ />
</network-interface>
</VM>
trafﬁc among different services. In listings 8, 9 we propose
a conﬁguration to balance VM s1R1 and VM s1R2 replicas.
In this case, we adopt the TLS VPN approach and the listing
8 contains useful information for VM VPN conﬁguration.
First of all, the deﬁnition of the network addresses which
belong to the VPN and assigned to clients, in that case, the
tool allocates 5 IPs from 10.10.10.5 to 10.10.10.10. In ad-
dition, the tool generates, using the speciﬁc TLS VPN tem-
plate, the virtual interface (tap0) and the protocol and port
of the VPN service (tcp/1194). To allow external clients ac-
cessing the internal services (VM s1R1 and VM s1R2) they
must join to the VPN. For that purpose, the virtualised ﬁre-
wall is conﬁgured to forward ciphered trafﬁc (using TCP
protocol) to the virtual host 10.10.10.2 on port 1194. The
load balancer conﬁguration is quite simple and contains the
description of adopted replicas and a set of policies to bal-
ance trafﬁc. In practice for each replica the tool deﬁnes an
IP address that belongs to the VNet2 and adds VM s1R1 and
VM s1R2 as members of balancing pool.
Listing 9. Firewall network conﬁguration and
policies for (c)
<VM id=’VM_FW’>
//bridged interface
<network-interface value=’eth0’>
<addr type=’IPv4’ value=’ask to admin’ />
<netmask value=’ask to admin’ />
<gateway value=’ask to admin’ />
<dns value=’ask to admin’ />
</network-interface>
//VNet1
<network-interface value=’eth1’>
<addr type=’IPv4’ value=’10.10.10.1’ />
<netmask value=’255.255.255.0’ />
<gateway value=’ask to admin’ />
<dns value=’ask to admin’ />
</network-interface>
//VNet2
<network-interface value=’eth2’>
<addr type=’IPv4’ value=’10.10.20.1’ />
<netmask value=’255.255.255.0’ />
<gateway value=’ask to admin’ />
<dns value=’ask to admin’ />
</network-interface>
<policies>
//allow access to VPN
<filtering-policy id=’1’>
<type=’forwarding’ />
<src ip=’*’ proto=’tcp’ port=’1194’ />
<dst ip=’10.10.10.2’ proto=’tcp’ port=’1194’ />
<action value=’allow’ />
</filtering-policy>
//allow access to balancer
<filtering-policy id=’2’>
<type=’forwarding’ />
<src ip=’10.10.10.*’ proto=’tcp’ port=’80’ />
<dst ip=’10.10.20.2’ proto=’tcp’ port=’80’ />
<action value=’allow’ />
</filtering-policy>
</policies>
</VM>
The last example (Listing 9) describes the alternative so-
lutions (c1 and c2) to conﬁgure a set that aggregates two or
more services. The major difference between the provided
solutions is that in (c1) each service is protected by a ded-
icated ﬁrewall and VPN gateway, on the contrary, the (c2)
adopts shared ﬁrewall and VPN virtual machines. The dif-
ferent approaches have pros and cons. The dedicated ﬁre-
17

474
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
wall and VPN allow protecting the services in more ﬁne
grained way. For example, if a VPN channel is compro-
mised, the other services are not involved. On the contrary,
if we adopt a shared VPN gateway, in case of attacks, each
service could be compromised. However the use of shared
resources enhances the entire system performance. In addi-
tion, the conﬁguration of dedicated ﬁrewall and VPN, often
requires assigning an external IP address for each ﬁrewall
(VM FWs1 and VM FWs2) to correctly perform the port
forwarding. Consider for example that VM s1 and VM s2
are web servers hosting s1 and s2 applications and each
one communicates with external world using tcp protocol
on port 80. In this situation we need to assign an external IP
address for each ﬁrewall to distinguish s1 and s2 requests.
5
Virtual machines generation and manage-
ment
Once the VM conﬁgurations are generated, it is neces-
sary create and conﬁgure the related VMs to implement a
solution. This goal requires the creation of the software en-
vironment that hosts the services, the conﬁguration of net-
works, services, policies and the deployment of the VM to a
physical host. In addition, to react on fault events, it is also
important monitor VM services, manage startup, shutdown
and migration of the virtual machines.
5.1
Building software environment and
speciﬁc conﬁgurations
Several approaches could be followed to build the soft-
ware environment, for example it is possible create manu-
ally a base system template, building a VM from a com-
mon GNU/Linux distribution. Then, the base system tem-
plate could be modiﬁed in automatic way, generating a set
of speciﬁc templates, adding the required software pack-
ages to implement services.
For example, the base sys-
tem could be transformed into a VPN VM template adding
IPSec or OpenVPN software packages. Similarly adding
the Apache Tomcat package we can implement a web server
VM template. The next step requires translating the ser-
vices, network conﬁguration and policies from a technology
speciﬁc and device/service independent language (previous
described models) to the device/service speciﬁc language
(e.g. network conﬁguration for a GNU/Linux system, rules
for a netﬁlter ﬁrewall). This task can be performed using
a set of adapters, one for each device/service category. For
example, an adapter for VPN should be able to translate an
IPSec conﬁguration into the racoon speciﬁc language and a
TLS VPN into the OpenVPN language. Similarly, for ﬁlter-
ing, the adapter should translate the device/service indepen-
dent conﬁguration into a set of netﬁlter or PF (OpenBSD
Packet Filter) rules. The adapter output is a device/service
speciﬁc conﬁguration that must be deployed into the VM.
5.2
Deploying and Managing VMs
Finally, the conﬁgured VMs should be deployed into the
physical machine that will host the services. This task re-
quires to: (1) identify which physical machine are able to
host the VMs; (2) deﬁne a set of mechanisms to transfer
the VMs to physical hosts. Parsing the system description
model allow to identify which physical hosts support vir-
tualisation and which are their performance. This informa-
tion is useful to know how many virtual machines can be
deployed on a particular host. The deployment process, or
in other words the task that transfers the VM to a physi-
cal host, is quite simple but it depends on the virtualisa-
tion technology adopted (e.g. Xen, KVM, VMware, etc. ).
On the contrary the VM managing tasks (startup, shutdown,
migration, network and disk management) are not simple to
address. To handle these tasks and reducing the problem
complexity a possible solution is to adopt a toolkit, like lib-
virt [15], able to deal with different virtualisation technolo-
gies, hiding details. The libvirt toolkit offers a set of API to
interact with the virtualisation capabilities of physical hosts
to deploy and manage VMs.
5.3
Our approach
In this section we describe our approach to generate and
manage the virtual machines accordingly to the previous de-
ﬁned models.
5.3.1
Architecture layers
To perform the tasks described before we introduce in our
architecture three different layers: VM software, VM conﬁg-
uration, VM management. The VM software layer contains
the activities to build a speciﬁc VM template like VM FW,
VM VPN, VM LB and VM for speciﬁc services, for exam-
ple to host Apache Tomcat web application. More prac-
tically we start from a common GNU/Linux distribution,
built manually, to derive automatically a set of predeﬁned
templates, adding the required packages, e.g. OpenVPN for
VM VPN. To perform this process automatically we adopt
a tool (ubuntu-vm-builder [27]) able to add new software
packages to a virtual machine. The predeﬁned templates
could be generated only once, when the tool is run for the
ﬁrst time. On the contrary, a speciﬁc template that hosts
a particular service must be generated when needed. The
build process is performed on a particular physical host,
the builder machine that is also used to deploy and manage
VMs. The VM conﬁguration layer performs the following
tasks: (1) VM internal network conﬁguration; (2) service
18

475
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
conﬁguration; (3) policy conﬁguration; (4) VM conﬁgura-
tion. The VM internal network conﬁguration is generated
accordingly to the security controls transformation, starting
from network conﬁguration and policies model, deﬁned be-
fore. The information is translated using a speciﬁc adapter
that transforms the model to a speciﬁc network conﬁgura-
tion language. For example, considering the listing 7 and
suppose that the VM is implemented using an Ubuntu Linux
operating system, each VM network conﬁguration is trans-
lated into ’/etc/network/interfaces’ language. For bridging
interfaces, the tool asks to admin the IP address that should
be deﬁned accordingly to physical host and external net-
work. The service conﬁguration, for example an Apache
Tomcat web application, is translated using a speciﬁc tem-
plate and a service dependant adapter. The policies, simi-
larly to network conﬁguration are translated from network
conﬁguration and policies model to a speciﬁc security con-
trol language, e.g. netﬁlter, using a speciﬁc adapter. Finally
it is necessary to build the conﬁguration of the virtual ma-
chine as XML model. To perform this step the tool takes as
inputs (a) the VM template generated before (e.g. VM FW);
(b) network conﬁguration and policies model. Considering
the listing 10, the template is used to deﬁne every properties
of the XML model except for the network interface tags,
that are generated using network conﬁguration and policy
model. In addition, this model is used to create the virtual
network properties, as shown for VNet1 in listing 11. The
speciﬁc conﬁgurations, except for virtual network proper-
ties, derived from previous tasks, are deployed into the VM.
More practically, the VM disk is mounted on local ﬁle sys-
tem of the builder machine, and speciﬁc conﬁguration are
copied accordingly. On the contrary the virtual network
properties are used in the next step to conﬁgure the virtu-
alisation environment.
The VM management layer is able to setup the virtuali-
sation environment, deploy, migrate, start and stop a virtual
machine. In order to create and deploy a VM on the physi-
cal host, the ﬁrst activity is setup the virtualisation environ-
ment. In practice, our tool, using the libvirt-java API, cre-
ates the network environment on the remote host, accord-
ingly to the network properties described in listing 11. In
the next step, the tool takes as input the VM conﬁguration
model of 10 and using the API creates the new domain on
remote physical host. Finally, the last step copies the VM
disk on the remote host, and the VM is ready to start.
6
Conclusion
We have analysed how the best practices for service and
network dependability change when exploiting modern vir-
tualisation technologies. Based on the results of this study,
we have updated the process and tools we had developed
for semi-automatic dependability planning of information
Listing 10. libvirt VM conﬁguration model
<domain type=’kvm’>
<name>vm-fw1</name>
<uuid>0cc4736f-2568-241d-c610-2e7ba90002f5</uuid>
<memory>262144</memory>
<currentMemory>262144</currentMemory>
<vcpu>1</vcpu>
<os>
<type arch=’i686’ machine=’pc-0.11’>hvm</type>
<boot dev=’hd’/>
</os>
<features>
<acpi/>
<apic/>
<pae/>
</features>
<clock offset=’utc’/>
<on_poweroff>destroy</on_poweroff>
<on_reboot>restart</on_reboot>
<on_crash>restart</on_crash>
<devices>
<emulator>/usr/bin/kvm</emulator>
<disk type=’file’ device=’disk’>
<source file=’/home/vm-deployment/vm-fw1-disk.img’
/>
<target dev=’hda’ bus=’ide’/>
</disk>
<disk type=’file’ device=’cdrom’>
<target dev=’hdc’ bus=’ide’/>
<readonly/>
</disk>
<interface type=’network’>
<mac address=’54:52:00:60:ef:e5’/>
<source network=’VNet1’/>
</interface>
<interface type=’bridge’>
<mac address=’54:52:00:04:3b:c0’/>
<source bridge=’br0’/>
</interface>
<serial type=’pty’>
<target port=’0’/>
</serial>
<console type=’pty’>
<target port=’0’/>
</console>
<input type=’mouse’ bus=’ps2’/>
<graphics type=’vnc’ port=’-1’ autoport=’yes’ keymap=
’it’/>
<video>
<model type=’cirrus’ vram=’9216’ heads=’1’/>
</video>
</devices>
</domain>
Listing 11. libvirt virtual network properties
for VNet1
<network>
<name>VNet1</name>
<uuid>3e3fce45-4f53-4fa7-bb32-11f34168b82b</uuid>
<bridge name=’virbr1’ stp=’on’ forwardDelay=’0’ />
<ip address="10.10.10.254" netmask="255.255.255.0">
<dhcp>
<range start="10.10.10.100" end="10.10.10.200" />
<host mac="54:52:00:60:ef:e5" name="VM_FW" ip="
10.10.10.1" />
</dhcp>
</ip>
</network>
systems.
19

476
International Journal on Advances in Intelligent Systems, vol 2 no 4, year 2009, http://www.iariajournals.org/intelligent_systems/
In particular, this paper has detailed the algorithms that
our tools exploit to automatically compute allocation and
reaction plans for virtualised information systems. Each al-
gorithm is deﬁned in terms of the relevant modelling on-
tology and the pool of transformation rules working on this
ontology. The actual implementation exploits XML repre-
sentations and transformation languages. We have also de-
veloped prototype integration of our tools with popular vir-
tual machine management software, which is an essential
step towards automatic deployment of the generated plans.
During the selection of the relevant conﬁguration strate-
gies, we have focused on the point of view of the virtual
data center customer: our approach can, and should be, ex-
tended taking in further consideration the point of view of
the hosting provider, which may partially conﬂict with the
customer’s one.
Acknowledgment
This work was developed in the framework of IST-
026600 DESEREC, “Dependability and Security by En-
hanced Reconﬁgurability”, an Integrated Project partially
funded by the E.C. under the Framework Program 6, IST
priority.
References
[1] Network Working Group, Address Allocation for Private In-
ternets. IETF RFC 1918, February 1996.
[2] W3C Consortium, Web Services Choreography Description
Language. http://www.w3.org/TR/ws-cdl-10/,
2005.
[3] POSITIF Consortium, The POSITIF System Description
Language (P-SDL).
http://www.positif.org/,
2007.
[4] National Vulnerability Database.
http://nvd.nist.
gov/, 2008.
[5] Common Vulnerability Scoring System.
http://www.
first.org/cvss/, 2009.
[6] M. D. Aime, P. C. Pomi, and M. Vallini.
Policy-driven
system conﬁguration for dependability. Emerging Security
Information, Systems, and Technologies, The International
Conference on, 0:420–425, 2008.
[7] M. D. Aime, P. C. Pomi, and M. Vallini. Planning depend-
ability of virtualised networks. Dependability, International
Conference on, 0:46–51, 2009.
[8] Amazon. Amazon Elastic Compute Cloud (Amazon EC2).
http://aws.amazon.com/ec2/.
[9] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris,
A. Ho, R. Neugebauer, I. Pratt, and A. Warﬁeld. Xen and
the art of virtualization. In SOSP ’03: Proceedings of the
nineteenth ACM symposium on Operating systems princi-
ples, pages 164–177, 2003.
[10] N. Damianou, N. Dulay, E. C. Lupu, and M. Sloman. Pon-
der: a language for specifying security and management
policies for distributed systems. Imperial College Research
Report DoC 2000/1, 2000.
[11] T. Eilam, M. Kalantar, A. Konstantinou, G. Paciﬁci, J. Per-
shing, and A. Agrawal. Managing the conﬁguration com-
plexity of distributed applications in internet data centers.
Communications Magazine, IEEE, 44(3):166–177, March
2006.
[12] P. Giorgini, F. Massacci, J. Mylopoulos, and N. Zannone.
Requirements engineering meets trust management - model,
methodology, and reasoning. In In Proc. of iTrust ’04, LNCS
2995, pages 176–190. Springer-Verlag, 2004.
[13] M. Israel, J. Borgel, and A. Cotton. Heuristics to perform
molecular decomposition of large mission-critical informa-
tion systems. In SECURWARE ’08: Proceedings of the 2008
Second International Conference on Emerging Security In-
formation, Systems and Technologies, pages 338–343, 2008.
[14] L. Lamport, R. Shostak, and M. Pease. The byzantine gen-
erals problem.
ACM Transactions on Programming Lan-
guages and Systems, 4:382–401, 1982.
[15] libvirt. http://libvirt.org/.
[16] A. Menon, A. L. Cox, and W. Zwaenepoel. Optimizing Net-
work Virtualization in Xen. Proceedings of the USENIX
Annual Technical Conference, 2006.
[17] Microsoft Corporation. Azure Service Platform. http:
//www.microsoft.com/azure/.
[18] D. M. Nicol, W. H. Sanders, and K. S. Trivedi. Model-based
evaluation: From dependability to security.
IEEE Trans-
actions on Dependable and Secure Computing, 1(1):48–65,
2004.
[19] J. Oberheide, E. Cooke, and F. Jahanian. Empirical exploita-
tion of live virtual machine migration. In In Proceedings of
the BlackHat DC convention, 2008.
[20] E. Rescorla, A. Cain, and B. Korver. SSLACC: A Clustered
SSL Accelerator. In Proceedings of the 11th USENIX Secu-
rity Symposium, pages 229–246, Berkeley, CA, USA, 2002.
USENIX Association.
[21] J. Salowey, H. Zhou, P. Eronen, and H. Tschofenig. Trans-
port Layer Security (TLS) Session Resumption without
Server-Side State. IETF RFC 5077, January 2008.
[22] F. Satoh, Y. Nakamura, N. K. Mukhi, M. Tatsubori, and
K. Ono. Methodology and tools for end-to-end soa secu-
rity conﬁgurations. In SERVICES ’08: Proceedings of the
2008 IEEE Congress on Services - Part I, pages 307–314,
Washington, DC, USA, 2008. IEEE Computer Society.
[23] J. Strassner. Policy-Based Network Management: Solutions
for the Next Generation (The Morgan Kaufmann Series in
Networking). Morgan Kaufmann Publishers Inc., San Fran-
cisco, CA, USA, 2003.
[24] The DMTF Technical Committee.
The Common In-
formation Model (CIM).
http://www.dmtf.org/
standards/cim, 2008.
[25] Trusted Computing Group. https://www.trustedcomputing
group.org, 2009.
[26] Ubuntu.
Ubuntu Enterprise Cloud.
http://www.
ubuntu.com/cloud/private.
[27] Ubuntu.
ubuntu-vm-builder.
https://
help.ubuntu.com/8.04/serverguide/C/
ubuntu-vm-builder.html.
[28] VMware. http://www.vmware.com.
20

