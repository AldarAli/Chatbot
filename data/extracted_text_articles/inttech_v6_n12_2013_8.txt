90
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
End-user Facilitated Interoperability in Internet of Things 
Visually-enriched User-assisted Ontology Alignment  
 
Oleksiy Khriyenko, Vagan Terziyan, and Olena Kaikova 
IOG group, MIT Department and Agora Center 
University of Jyväskylä, P.O. Box 35 (Agora) 
FIN-40014 Jyväskylä, Finland 
e-mail: oleksiy.khriyenko@jyu.fi, vagan.terziyan@jyu.fi, olena.o.kaikova@jyu.fi  
 
 
Abstract — Nowadays, we make a separation between the 
real/physical world and the Internet. It is time for these two be 
blended and provide ubiquitous access and interoperability 
online. We are approaching Internet of Things - a forthcoming 
technological revolution that will radically change our 
environment and enable innovative applications and services. 
To make this happen, we have to eliminate the fragmentation 
in used technologies and have to make the devices be used 
across various applications and services. We need to find a way 
to actually carry out the necessary and massive deployment of 
ubiquitous devices. So we need to put more effort into the 
design of tools to automate deployment and configuration of 
devices. This paper tackled a problem of an effective way to 
support interoperability in Internet of Things. We consider 
human as a very powerful asset in the world of ubiquitous 
systems and services that may provide his/her knowledge, 
experience and expertise. At the same time, we see a lack of 
human-oriented systems and infrastructures to support such a 
new role of a human. With a respect to the above statements, 
authors propose visually-enriched approach for user-powered 
ontology alignment to facilitate semantic interoperability in the 
Web of Things.  
Keywords- Mashup supported semantic visual mapping; 
visual ontology alignment, visual semantic human interface, 
semantic interoperability. 
I. 
 INTRODUCTION 
This paper is an extension of the original paper [1] that 
has been presented at the international conference 
UBICOMM-2012. Here, authors extend the paper with more 
details regarding required semantic language extension for 
visually-enriched ontology and resource description, and 
present browser for visually-enriched linked data.   
 Our current Digital World is changing rapidly. We are 
about to enter a new era of ubiquitous computing and 
communication that will radically transform our corporate, 
community, and personal spheres. Tomorrow’s world of 
Ubiquitous Pervasive Computing and Internet of Things is a 
technological revolution that represents the future of 
computing and communications and its development 
depends on technical innovations in a number of important 
fields. In the interconnected world of computers, interactions 
occur, not only between humans and applications, but also 
between applications of various kinds, applications and 
equipment, low-level software units, or any other logical or 
physical 
entities. 
Unlimited 
interoperability 
and 
collaboration are important values for a multitude of areas in 
our daily life.  
With a purpose to better understand a need of proposed 
contribution, and highlight possible requirements and 
characteristics of interoperable systems, let us start with 
some short samples of use case scenarios: 
Scenario 1: Person is traveling by a car. Suddenly, 
something is happened with the car and it needs to be 
repaired. Instead of searching the nearest car service station, 
booking a time and filling a request form describing current 
state of the car; the car itself searches for correspondent 
services in the web, collects necessary data from the 
correspondent modules of the car and books a time for 
maintenance service. During the maintenance, the car gets 
new spare-parts and integrates them to the central diagnostic 
system of the car (regardless of the fact that parts are 
produced by different vendors). In the same manner, car 
might negotiate and book appropriate time for annual 
technical check-up taking into account timetable of the 
owner, been connected to his/her personal organizer. During 
the trip, car might suggest optimized schedule of refueling 
taking into account fuel consumption, location of gasoline 
stations and their prices, discounts and bonuses available for 
the driver and other relevant contextual information.  
Scenario 2: Person has bought “smart-home” system 
from some vendor. Vendor installs smart-home network 
with a set of smart-entities (sensors and actuators) and one 
control unit. So far, all the elements of the network belong 
to the same vendor and interoperate via the same ontology 
and communication protocol. A couple of month later, 
house owner buys a new smart-entity for good price from 
another vendor and connects it to the existing network. 
Later, friend of the house owner suggests some generic 
software application, which could be used as an upgrade of 
the smart-home network control unit and provides new 
useful features in comparison to the functionality of initial 
software of the control unit. This software application is 
produced by totally different vendor, and still can be 
installed to the control unit and communicate with all the 
connected to the smart-home network entities.        

91
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Scenario 3: Person has several measurement units 
(produced by different vendors) that can measure his/her 
heartbeat rate, arterial pressure, distance person walked or 
run, and some other parameters related to his/her health 
condition and physical activities. Person easily connects all 
these devices to a smart-phone to be able to log and observe 
them. Later, from an app. store, person buys application that 
suggests correspondent diet, taking into account all the 
measured personal data. Entering a supermarket and to be 
connected to the local infrastructure of it, application starts 
to navigate person to the correspondent location of the 
suitable products for his/her diet or alert the person when 
he/she puts to the basket a product which consists 
inappropriate ingredients.               
All mentioned above stories are not fantasies. It is our 
tomorrow and, in some cases, even our today. Unfortunately, 
in case of our today, we have integration of systems 
produced 
by 
the 
same 
vendor. 
Supporting 
one 
interoperability model in several products, vendor creates 
integrated environment for various applications and 
interaction scenarios to be run on it. All these applications 
should support correspondent predefined API and data 
model. But, it is not what we expect to be in our tomorrow. 
We need an open environment with possibility to integrate 
various 
systems 
and 
components 
(hardware, 
apps, 
communication channels, etc.) produced by different vendors 
(see Figure 1). With a goal to achieve such requirements, we 
are approaching Internet of Things - a forthcoming 
technological revolution that will radically change our 
environment and enable innovative applications and services.  
Above the personal level, the IoT will also have an 
important impact on enterprises and on society in general. 
IoT will enable a global connectivity between physical 
objects (connecting “things”, not only places or people), will 
bring real-time machine-published information to the Web, 
as well as will enable a better interaction of people with the 
physical environment by combining ubiquitous access with 
ubiquitous intelligence. IoT will consist of a heterogeneous 
set of devices and communication strategies between them. 
Such a heterogeneous system should evolve into a more 
structured set of solutions, where “things” are uniformly 
discoverable, enabled to communicate with other entities, 
and are closely integrated with Internet infrastructure and 
services, regardless of the particular way (RFIDs, sensors, 
embedded devices) in which they are connected to the IoT.  
In this context, one of the challenging bottlenecks is to 
support interoperability between “entities” on a semantic 
level [2][3].  
Taking into account current state of the art in the field of 
innovative research and development, we see lack of human-
oriented systems and services. Now, human becomes very 
dynamic and proactive resource of a large integration 
environment with a huge amount of various heterogeneous 
data and services. As a user, human requires a technology 
and tools for easy and handy information access and 
manipulation. Moving from industrial era to the era of 
ubiquitous services, human is not considered only as a 
user/consumer any more. Human becomes a service 
provider, an expert that provides her/his knowledge and 
expertise to the digital world. Transition from an industrial 
welfare society to sustainable human-centric services society 
requires elaboration of correspondent infrastructure and tools 
to allow people add value to the process. Therefore, in this 
paper we propose an approach towards visually-enriched 
semantics as an infrastructure for user-powered semantic 
technology enhancement. The main contributions of the 
paper are visually enriched ontology and a system that 
visually assist users to execute semantic alignment. 
 
 
Figure 1.  Thing Integration Environment. 

92
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Paper consists of two main sections: Section II and 
Section III. Section II addresses semantic integration 
platform for IoT and a vision of user-powered consumption 
of semantic technologies. Section III presents visually-
enriched approach for user-powered ontology alignment to 
facilitate semantic interoperability in the Web of Things. 
Section IV presents author’s conclusions with respect to the 
proposed contribution and defines future work.   
II. 
THING INTEGRATION ENVIRONMENT 
A. Smart Gateway - semantic integration platform for IoT 
We are already in the middle of era of automated 
machine communication. There is already a lot of machine-
to-machine communication going on out there; parking 
meters are connected, and vending machines automatically 
report when new supplies are needed. Every minute huge 
amount of data are being exchanged between machines for 
various purposes within various sectors. However, there is a 
big challenge in moving beyond application-specific devices 
and establishing an information model that will create re-use 
of the data generated by devices for new applications in 
different domains.  
Finding the right horizontal points in the solutions is a 
key. There are already useful deployments within the 
transport, automotive, building, health and utility sectors, but 
everything is still very sector-specific. We need to create an 
infrastructure that will make information generated from a 
car or a building understandable not only within their own 
specific 
application/system, 
but 
across 
of 
various 
applications and domains. The vision of an open and 
interoperable IoT implicates ability: 
• 
to have a growing environment with possibility to 
install and interconnect all IoT devises and software 
(services and applications) on the fly; 
• 
to interconnect devises produced by different 
vendors;  
• 
for third parties, to elaborate generic applications and 
services for IoT environments in the sense of 
applying them on various IoT device sets (same 
purpose, but different vendors). 
To satisfy such requirements, IoT will require 
interoperability at multiple levels and rely on the benefits of 
the semantic technologies. On the hardware side, such 
problems have to be addressed as handling a capability 
mismatch between traditional Internet hosts and small 
devices, as well as handling widely differing communication 
and processing capabilities in different devices. In the 
interface between the device and network domains, IoT 
gateways will provide a common interface towards many 
heterogeneous devices and networks [4]. We assume that all 
“things” (devices, sensors, actuators, etc.) are connected to 
the web. Digital “things” such as services usually are 
accessible through the web. Applications might be 
downloaded and installed to the integration platform - Smart 
Gateway. Thus, we have correspondent requirements for 
such a platform. Smart Gateway should allow installation of 
applications and further configuration of communication 
model with it, based on accompanied annotation of the 
application. In case of services, Smart Gateway should be 
able to access semantic annotation through service access 
point and configure communication model with it as well. 
Talking about physical world objects (device, sensors, 
etc.), usually they are accessible through the gateway - a 
control unit of a network provided by the same vendor. The 
only requirement - gateway should be presented in the web 
as a service with a set of capabilities provided by “things” 
connected to the gateway (providing data or doing some 
actions). In case we cannot have single “thing” personally 
connected to the web, we should deal with sub-network that 
consists of mentioned “thing” and correspondent gateway. 
Thus, we will have a set of gateways connected to the web 
and ready to become a part of the integration environment. 
Having all the gateways accessible as web-services, all 
connected to them real world “things” become digital entities 
and might be registered to the Smart Gateway. 
Depending on a business model, Smart Gateway might 
be a part of a gateway, provided by certain vendor. In such a 
way, vendor can promote own network solution as an 
extendable open environment that support connectivity and 
interoperability of various entities produced by other 
vendors. Having Smart Gateway as a part of local network of 
connected “things”, services and applications is a reasonable 
model in case of time-limited and highly secured runtime 
systems. At the same time, Smart Gateway might be 
considered as a separate integration solution - services 
located in the Cloud and accessible through the web. Been 
easily accessible, such “thing” integration service might be 
very popular among ordinary people who would like to 
create and manage their own distributed smart spaces, 
integrate various services with ubiquitous “things”. Relevant 
research has been done in “Smart Resource” and 
“UBIWARE” Tekes projects with respect to Global 
Understanding Environment (GUN) [5].           
B. User-powered consumption of semantic technologies 
To achieve the vision of ubiquitous ‘things’, the next 
generation of integration systems will need different methods 
and techniques to provide connectivity, interoperability and  
intelligence of distributed entities, as well as smart and 
intuitive mechanism of communication with a human. 
Among those there are technologies such as Semantic Web 
[6][7], Web Services [8][9], Mashups [10], Linked Data 
[11][12], etc. To integrate ‘things’ seamlessly with the 
existing Web infrastructure and to represent interconnected 
‘things’ uniformly as Web resources, resulting Web of 
Things (WoT) is a good facilitator of interoperability. 
Making devises able to unambiguously exchange the 
meaning of data, Semantic Web technology can be used to 
extend WoT into Semantic Web of Things (SWoT). 
Semantic based technologies are viewed today as key 
technologies to resolve the problems of interoperability and 
integration within the heterogeneous world of ubiquitously 
interconnected objects and systems. Semantic Web is a 
vision with an idea of having data on the Web defined and 
linked in a way that it can be used by machines not just for 
display purposes, but for automation, integration and reuse of 
data across various applications. Semantic Web is considered 

93
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
as 
a 
standardized 
approach 
to 
achieve 
automated 
interoperability 
of 
heterogeneous 
systems/applications. 
Heterogeneity of systems and various data sources become a 
bottleneck for automated service integration, data processing 
and reuse. To make data ready to be consumed and 
processed by external systems, data sources and data should 
pass through the semantic adaptation [5][13] and be 
accessible in common uniform way. Due to the huge amount 
of application areas that Semantic Web technology tried to 
cover, community started to elaborate different standards and 
techniques to solve interoperability problems. As a result, we 
have a big variety of separated islands of information and 
management systems. These information islands internally 
follow the Semantic Web vision, but are heterogeneous from 
the general (global) interoperability point of view. This leads 
to the fact that society and especially its business-oriented 
part has started to doubt that such widely spread activity will 
be so much beneficial for them. Only some applications and 
systems in restricted domains became really useful. Most 
probably, the reason for this is the decentralization of 
uncontrolled activities, which creates new problems on the 
way towards ubiquitous Semantic Web. There are no doubts 
that Semantic Web is a very promising technology, but it 
definitely lacks more smart management or at least an 
environment that plays coordinative and supportive role and 
directs users towards proper technology utilization.  
Services providers, as well as producers of “things”, are 
the end users of the service-oriented technologies. They need 
appropriate controlled support from the infrastructure that 
facilitates interoperability of services/devices, integration of 
heterogeneous data sources, and provides platform for new 
services/application development. Thus, we have to provide 
such a coordinative and supportive environment that will 
facilitate development and growth of service and smart-
entity market. With respect to the current state of the art, we 
cannot expect that community of service providers and 
smart-entity vendors will build one global integration 
infrastructure with common ontology. We cannot expect that 
someone else (alone or in a consortium) will do the same. 
Current achievements in the area of interoperability of 
heterogeneous systems present technologies and tools for 
experts to build and manage adapters between heterogeneous 
systems or their components. Semantic Web is a technology 
for machines to better perform, providing services for human 
in automated or semi-automated way. In a case of 
unavailability of a common data model, we have to deal with 
semi-automated performance of the system when human 
become involved to the process not just as a consumer, but 
as an expert - necessary part in the chain to supervise and 
correct the process performed by machines [14].  
With an increase in the development of ontologies, we 
need tools and techniques for solving heterogeneity problems 
between different ontologies. Therefore, we need ontology 
alignment [15][16][17][18], which helps us to bring different 
knowledge representations into mutual agreement. With 
respect to the scenarios mentioned above, ontology 
definitions of all the smart-entities and applications/services 
should be (semi-)automatically aligned by control unit of the 
network to ensure interoperability of them in a unified way. 
Regarding to the mentioned ontology alignment techniques, 
we may expect automatic alignment for simple and similar 
ontologies, but in all other cases, we will definitely need a 
human be involved into the process. This is largely a human-
mediated process. There are existing tools that can help with 
identifying differences among ontologies [19], but user 
interaction is still essential in order to control, approve, and 
optimize the alignment results.  
Unfortunately, approaching the era of ubiquitous services 
and IoT, we cannot expect availability of huge amount of 
professional experts involved to the daily processes of 
“things” interoperability support. We have to find a solution 
to bring technology closer to the ordinary user and make 
him/her able to not only utilize services, but to setup, 
configure and supervise interoperability process. We expect 
a human to be not only an end-user/consumer of technology 
world, but also to become an integral part of it, providing 
own expertise and capabilities. In all mentioned scenarios, 
person (owner of the smart-network) should be able to help 
the system to perform a proper ontology alignment through 
correspondent human interface of the alignment system. 
Owner of interoperable system does not only consume a 
service delivered by smart machines, but also plays a 
valuable role as a supervisor of interoperability process. 
Therefore, among variety of other adapters between 
heterogeneous entities, bridge to the human (human-to-
machine H2M and machine-to-human M2H interfaces) 
becomes one of the most important tools of next generation 
integration infrastructures. 
Such an adaptation of the human to the technology world 
might be provided by Personal Assistant (PA) - supportive 
agent assigned to every user [14]. From one side, it should 
deal with human personality and adapts to his/her personal 
ontology and personal perception of environment. From 
another side, it should support common semantic standards 
and approach to be interoperable with other surrounding 
digital world entities (applications, services and systems). 
The main features of PA (among others) are:  
• 
Enabling personal user ontology creation and 
ontology driven resource annotation;  
• 
Ability to adjust to the personal user ontology, to the 
way user perceives the environment, information and 
knowledge; 
• 
Ability to build personalized semantic mind-map 
based on user behavior and preferences; 
• 
Enabling personalized natural user-driven way of 
querying, filtering, browsing and presentation of 
information. 
Personalized representation of information very much 
concerns a human supervised ontology alignment process. 
Ontologies very much differ from each other. The more 
specific, detailed and complex ontology we make, the more 
semantic value it has, but, it makes harder to integrate 
ontology with others. Taxonomies of different ontologies are 
not likely to be the same. Even developed by professionals, 
we still have different ontologies for the same problem 
domain. It would seem that experts, involved to the same 
domain, should operate with the same terms, use the same 
vocabulary and knowledge representation model. But, people 

94
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
are different, context and personal perception of surrounding 
world brings problems to interoperability process. As a part 
of the processes, human brings a certain level of uncertainty, 
and only human my help to solve the problem so far. Thus, 
to avoid heterogeneity in the resource annotations and 
simplify ontology alignment for automated interoperability 
between digital elements of the technology world, we may 
admit a necessity of personalized adaptation of every human 
(no matter whether it is an expert (knowledge provider) or 
user/customer) to the common information/data model. 
In the next section we present an approach towards 
visually-facilitated human-assisted ontology alignment for 
automated interoperability among various heterogeneous 
entities of IoT. This approach supports the idea of end-user 
involvement as a powerful intelligent entity if IoT.    
III. 
HUMAN-ASSISTED VISUAL ONTOLOGY ALIGNMENT 
A. Visually-facilitated semantic matching 
Let us consider a scenario of installation of a new floor-
heating regulator to a “smart-home” system. Assuming that 
we have two different vendors (Vendor A - producer of the 
Control Unit for the smart-home system, and Vendor B - 
producer of the regulator for a floor-heating system), we 
have two different ontologies OntologyV
A and OntologyV
B. 
Vendor A logically defines all the floor-heating systems with 
respect to the room the system is associated with. Thus, 
OntologyV
A might contain such concepts as: living room 
floor-heating system, bedroom #1 floor-heating system, 
bedroom #2 floor-heating system, kitchen floor-heating 
system, bathroom floor-heating system, etc. From the 
Vendor A point of view, all these concepts refer to 
absolutely different sub-systems in the “smart-home” 
network. On the other side, association of the floor-heating 
system with particular room/place does not matter for 
Vendor B. Therefore, “floor-heating system” concept in the 
OntologyV
B is a more general and independent entity. 
Moreover, most probably “floor-heating system” concept 
will be named very much different in those two ontologies 
and automated alignment will be absolutely impossible.           
Since the Control Unit of the smart-home is a more 
general device (in comparison to specific Floor-heating 
system) and deals with many other devices and systems in 
the installed network, it utilizes more wide ontology. 
Therefore, to allow interoperability between the Control Unit 
and Floor-heating system, we have to map OntologyV
B to 
wider OntologyV
A. At the same time, we have to pay 
attention to the user’s (“smart-home” owner’s) OntologyH
i. 
In general case, every human has own personal ontology that 
will be supported by his/her PA for interaction with devices, 
services, 
applications 
and 
systems. 
But, 
for 
any 
system/application, to be a mediator between the human and 
some other system with its own ontology, personal human 
ontology itself should be mapped with ontology of mediator-
system in advance. PA will collect correspondent alignments 
of personal human ontology with ontologies of various 
mediating systems that human will be interacted with.  
Assuming that fully automated alignment is not possible, 
we do not consider the cases with very simple and self-
descriptive ontologies, where automated alignment might be 
done based on matching of synonyms of the property manes. 
Correspondent example of the research at this direction is a 
work performed in the Tivit SHOK IoT project (funded by 
Tekes, Finland), where authors are trying to minimize human 
involvement to the process of establishing interoperability 
between heterogeneous systems [4]. They try to retrieve (to 
build) ontologies from examples of massages that systems 
operate in communication process (requests, response, etc.). 
Authors build simple plane ontologies based on names of 
parameters used in the messages. Later, ontologies are 
automatically aligned and correspondent alignments are used 
for automatic interoperability between heterogeneous 
systems in runtime. But, as was mentioned, it might work in 
case of self-descriptive messages, where parameters are 
named by words that make sense, without abbreviations and 
shortenings, and preferably in the same language. In all other 
cases (cases with complex hierarchy of sub-classes, cases of 
different domain description models, cases of multilingual 
and multicultural ontology definitions, etc.), this would not 
work automatically and will require human assistance. Thus, 
in cases of human-assisted alignment of personal human 
ontology or ontologies provided by different vendors, we 
need an innovative suitable for non-expert mechanism and 
correspondent user interface for ontology alignment.  
With respect to the research [20][21][22][23], there are 
some available Ontology Alignment and visualization tools: 
Foam algorithm [24], multiple-view plug-in for Protégé [25] 
- AlViz [26], BLOOMB system [22] and Knowledge 
Modeler[27]. The very good overview of visually supported 
ontology alignment tools is presented in the paper [28]. 
There graphical primitives such as point, line, area, or 
volume are currently utilized to encode information. These 
objects are characterized by position in space, size, 
connections & enclosures, shape, orientation, and visual cues 
like color and texture, with temporal changes, and viewpoint 
transformations. Unfortunately, all these tools were 
elaborated for domain experts who know what ontology is 
and what information models might be used. Such tools 
present a lot of statistical data and analytics that might be 
very useful for the ontology engineer, but not for the 
ordinary user of a service. Information visualization should 
aim at making complex data easy accessible and understood 
for interactive investigation by the user. In case of smart-
home, we expect that user has a basic knowledge about a 
domain and functionality of the system. Like in the scenario 
above, house owner knows already available sub-system of 
his/her smart-home, their purposes and functionality, as well 
as he/she knows a purpose of the new parts that he/she wants 
to be added to the system. Therefore, we have to find more 
suitable approach for user-assisted ontology alignment.  
To be easily recognized by human, concepts and 
properties of different ontologies must be presented in the 
most understood form - in a form of image. An image (or 
other visual form) is the most common information 
representation model for human. It helps to understand the 
meaning and avoid verbal uncertainty presented in textual 
form. Therefore, user interface should be able to present 
semantics through interactive image mash-ups and user-

95
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
friendly 
browsing 
mechanism. 
Talking 
about 
data 
visualization, we would like to admit existence of some 
domain-oriented software applications, which try to visualize 
data in domain specific and suitable for human way 
(graphics software from SmartDraw®, concept-browser 
Conzilla and Human Semantic Web browser Conzilla2, etc.). 
But still, they are developed for specific standalone domain-
oriented applications. And when we face a real need in an 
open unlimited collaboration environment, we have to 
develop much more visualization tools and modules that are 
aimed to visualize various resource properties, contexts, 
situations and associations to provide human flexible and 
handy 
Human-Machine 
interaction 
interface. 
Thus, 
semantic-based 
context-dependent 
multidimensional 
resource visualization approach and 4i (FOR EYE) 
technology [29][30][31] can be a basis for the development 
of such interface. The idea of intelligent resource 
visualization is to simplify the search and browsing 
processes 
via 
associative 
resource 
visualization. 
Multidimensional associative resource visualization means 
visualization of a resource depending on a context, via 
association with various aspects of resource being (relations 
with the other resources, domains, areas of interest, etc.). 
Sometimes, we cannot specify exactly what we are looking 
for, but we feel that it is somehow related to certain stuff, 
certain situation, certain context. Such visualization can give 
us a hint, turn to the right direction, show us related objects 
and provide links to them. In other words, visualization will 
utilize context-based filtering and enrichment of the 
visualized scene with the relevant links. Such approach 
provides an opportunity to create intelligent visual interface 
that presents relevant information in more suitable and 
personalized 
for 
user 
form. 
Context-awareness 
and 
intelligence of such interface brings a new feature that gives 
a possibility for user to get not just raw data, but required 
information based on a specified context. Now it has become 
evident that we cannot separate visual aspects of both data 
representation and graphical interface from interaction 
mechanisms that help user to browse and query a data set 
through its visual representation.    
Figure 2 shows us possible visual interpretations of the 
Vendor A, Vendor B, and user (smart-home owner) 
ontologies with respect to the scenario of adding the living 
room floor heating system to the “smart-home” network. 
Since we are not consider “smart-home” owner as an expert 
in ontologies and complex control systems, we cannot expect 
that it would be possible for him/her to utilize currently 
available solutions for ontology alignment. Only we can 
expect is awareness of the user about purpose, capabilities 
and main functionality of the “smart-home” Control Unit and 
floor-heating system that he/she would like to add to the 
“smart-home” network. Having even such limited expertise 
of the problem domain, user is able to browse visual 
description of the Control Unit (the structure of sub-systems,  
 
 
Figure 2.  Visually-facilitated Ontology Alignment. 

96
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
capabilities, inputs and outputs, properties, etc.) and 
description of the floor-heating system from another vendor 
to provide appropriate matching. User can intuitively map 
concepts and properties presented by images. Applying 
possible results, achieved by integrated modules of 
automated ontology alignment (as a background process), 
Visual Ontology Alignment Tool assists user with 
suggestions and requests next necessary alignments caused 
by alignments made on the previous steps. Additional textual 
descriptions of visual annotations support user to make 
correct mapping. As a result, correspondent parts of 
ontologies OntologyVA and OntologyVB, which are related 
to the communication scenario between “smart-home” 
Control Unit (Vendor A) and floor-heating system (Vendor 
B), will be mapped and correspondent alignment will be 
used in runtime operation of the “smart-home” network. 
B. Visually-enriched ontology and resource description 
To operate with visual representation model in a smart 
way, visualization tool should retrieve correspondent images 
together with ontologies. It means that ontologies should be 
extended with additional layer that contains visual definition 
of the concepts (classes and properties). Later in the text, we 
will call such visually-enriched ontology as Visual Ontology 
(VisOntology). We consider two scenarios of human-assisted 
visual enrichment of data (see Figure 3). In the first case, 
Ontology/Domain 
Expert 
creates 
VisOntology 
using 
Ontology Visual Enrichment Tool that adds correspondent 
image layer to the ontology. Later, Vendor provides 
annotation of the Service/System that was produced by 
Vendor. In the second case, Vendor itself provides visually-
enriched annotation (VisAnnotation) of the produced 
Service/System 
using 
Visually-enriched 
Resource 
Description Tool based on regular domain ontology provided 
by Ontology/Domain Expert. In this case, visually-enriched 
ontology might be automatically created from the visually-
enriched resource description during the annotation process. 
In case when it is difficult to associate any image with some 
of the concepts, tool will create an image with a 
correspondent text (word, character, sign, etc.) retrieved 
from the name of ontology element. One more scenario 
might have a place if we consider possibility for some third 
party to substitute Vendor in the Service/System annotation 
process and provide visual annotation in both previous cases. 
Both tools that were mentioned in the above scenarios have 
the same nature and similar functionality. Thus, let us 
consider them as a single tool for visual semantic 
enrichment. 
The best way to provide visual layer to the ontology is to 
extend existing ontology editors (the most popular - Protégé 
ontology creation and editing tool) with possibility to assign 
appropriate visual element to every entity of ontology (class 
and property). Talking about instance annotation process, 
visually-enriched description might be performed via various 
RDF creation tools. It might be Protégé as well as any other 
more customized RDF creation tool which is more suitable 
for specific application domain. The main purpose of the tool 
is to help user to brows ontology and assign “visSemantics” 
property to every entity of ontology: class, property and 
instance. Taking into account formal aspects of a visual layer 
in ontology definition and resource description, we have to 
extend the RDF Schema (RDFS) [32] and Web Ontology 
Language (OWL) [33]. Figure 4 presents possible extension 
of RDFS or OWL with “visSemantics” property used for 
VisOntology and VisDescription. Talking about resource 
annotation, tool creates an annotation template based on 
assigned ontology and provides possibility to add visual 
description. In such a way, tool extends the concepts of the 
ontology with “visSemantics” property and correspondent 
value in a form of image. Currently we consider the range of 
this property as a literal URL of an image. In more advance 
version of VisOntology and VisDescription of the resource, 
the range might be extended to video, audio or any other 
multimedia content. Such extended range of the property 
might be regulated by rich datatypes that will restrict the type 
(file extension) of the file mentioned as a Literal value of the 
visSemantics property.   
Visual enrichment is individual, as long as a set of 
images, used by VisOntology and VisAnnotation providers, 
is individual. Tools should allow user to make key-word 
based image annotation/tagging for individual content and 
create a personal pool of annotated visual content for further 
reuse. Later, annotated content (used for visual enrichment)  
 
Figure 3.  Human-assisted visual enrichment scenarious. 

97
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
will be easily retrieved based on user search request or 
automatically suggested to a user based on attributes of self- 
descriptive elements of ontology. In case of old-fashioned 
service/system description which is based on ordinary 
ontology, enrichment of the description might be still 
automated on some extend. Based on the names of ontology 
concepts, Visual Enrichment Tool may search among visual 
content (annotated already), and build visual layer 
automatically. Quality of automated enrichment might be 
relatively low in comparison to human assisted enrichment. 
But, even in worst cases, when we do not have any human 
involvement at the stage of resource annotation, it might help 
to retrieve at least some visual content for further visual 
ontology alignment process. Taking into account growing 
trend towards sharing and reuse of content, annotated visual 
content might be shared through various clouds and common 
spaces. Thus, tool can use not only personal visual content of 
the user, but also will allow to manage and extend his/her 
virtual visual content space with external sources. In this 
case, Social Web might be considered as a good platform to 
share visual annotation content and VisOntologies. 
Assuming that it might be not so popular for vendors to 
provide visual description manually, visually-enriched 
ontologies might become popular. Already having visual 
layer imbedded into ontology, resource annotation tool will 
suggest correspondent visual entity with respect to the class 
of annotated instance. Responsible for resource annotation 
expert might just simply accept such proposed visualization 
or provide customized visualization more suitable in 
particular context. Every time when expert select customized 
visualization, correspondent visual entity might be shared 
and will extend ontology with extra visual definition of 
correspondent 
class 
(or 
property). 
Multiple 
visual 
annotations of the classes and properties will enhance semi-
automated resource definition process. Several appropriate 
visualization options will be proposed to annotation expert. 
To avoid redundancy of alternatives, they might be filtered 
based on automatically detected or specified (by annotation 
expert) context. This will require context definition for each 
visualization entity in the ontology (see Figure 4). In this 
example, we may see the definition of the contexts for two 
different images assigned to the HeatingSystem class (class 
of various heating systems). Context definition might be 
perform via reification mechanism and be defined either by 
context definition keyword(s) (via “visContextKeyWords”  
property) or by instance of the context definition class (via 
“visContext”  property). Thus, the domain for both 
mentioned properties in rdf:Statement. In the example, we 
may find two different methods for applying reification 
mechanism. One of them uses abbreviation “{}” supported 
by Notation-3 [34] serialization to define a statement. 
Another method uses standard approach of RDFS via 
definition of an instance of rdf:Statement class. The range of 
the “visContextKeyWords” and “visContext” properties is 
different. Range for the first property is restricted by 
rdfs:Literal class and considered to be referred to keyword 
(key-sentence). At the same time, range of another property 
refers to the class of context definitions. In this paper we do 
not concentrate our attention on the context definition class.  
 
Figure 4.  “visSemantics” ontology extension and visualization context 
definition. 
@prefix :    <http://www.example.org/sample.owl#>. 
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>. 
@prefix rdfs:<http://www.w3.org/2000/01/rdf-schema#>. 
@prefix owl: <http://www.w3.org/2002/07/owl#>. 
 
rdfs:vviissSSeemmaannttiiccss  
  
          rdf:type rdf:Property; 
     rdfs:domain rdfs:Resource; 
     rdfs:range rdfs:Literal. 
 
owl:vviissSSeemmaannttiiccss  
  
          rdf:type owl:DatatypeProperty; 
     rdfs:domain rdfs:Resource; 
     rdfs:range rdfs:Literal. 
 
owl:vviissCCoonntteexxttKKeeyyWWoorrddss    
          a owl:DatatypeProperty; 
     rdfs:domain rdf:Statement; 
     rdfs:range rdfs:Literal. 
 
owl:vviissCCoonntteexxtt  
  
          a owl:ObjectProperty; 
     rdfs:domain rdf:Statement; 
     rdfs:range owl:CCoonntteexxttDDeeffiinniittiioonn. 
 
:HeatingSystem a rdf:Class . 
 
owl:ContextDefinition a rdf:Class . 
 
#---some definition of the context --- 
:carHContext a owl:ContextDefinition . 
 
#------------------------------------- 
 
{:HeatingSystem  rdfs:vviissSSeemmaannttiiccss  
“www.example.org/FloorHSystem.jpeg”} 
 
owl:vviissCCoonntteexxttKKeeyyWWoorrddss 
 
“floor heating” ,  
 
“home heating” , 
“room heating” . 
 
{:HeatingSystem  rdfs:vviissSSeemmaannttiiccss  
“www.example.org/CarHSystem.jpeg”} 
 
owl:vviissCCoonntteexxtt  ::ccaarrHHCCoonntteexxtt  . 
 
:statement_1 a rdf:Statement ; 
rdf:subject :HeatingSystem ; 
rdf:predicate rdfs:vviissSSeemmaannttiiccss  ;;  
rdf:object        
   “www.example.org/CarHSystem.jpeg” . 
 
 
:statement_1 owl:vviissCCoonntteexxttKKeeyyWWoorrddss 
 
“car heating” ,  
 
“vehicle heating” . 
 

98
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
There are several approaches towards context definition, but 
in this paper we are just assuming an existence of some 
context 
definition 
class 
(in 
our 
example 
- 
“ContextDefinition” class).    
Sub-class and sub-property hierarchy of the ontology also 
can help to collect visualization alternatives and automate 
resource annotation process. All the visualization entities that 
describe sub-classes and sub-properties also describe supper-
classes and supper-properties. Even if certain class does not 
have any visual description/representation, the list of 
alternatives to describe an instance of that class will be 
retrieved from the sub-classes and the same context-based 
filtering technique might be applied to find more appropriate 
visualization. Thus, more detailed ontology with deep sub-
class hierarchy might minimize amount of multiple context-
dependent visualization settings. If we reconsider example in 
Figure 4 and define floor heating system and car heating 
system as sub-classes of more general class that defines all 
heating systems, then “HeatingSystem” class might be 
described by some general visualization and additional 
alternatives might be collected form visual descriptions of 
its’ sub-classes.  
C. Browsing of visually-enriched linked data 
Browsing 
of 
visually-enriched 
ontologies 
and 
visualization of visually-enriched resource descriptions 
might be performed by appropriate visualization tools. As 
was mentioned before, it is reasonable to have visualization 
of ontologies imbedded into ontology editors. At the same 
time, visually-enriched resource descriptions must be 
visualized in more intuitive way via smart integration of data 
mashups [29][30]. In this project, we have been used 4i 
(FOR EYE) Browser [31] - smart visual context-sensitive 
resource browser (elaborated in UBIWARE Tekes project) 
and Linked Data Browser (elaborated in this project for 
visualization of visually-enriched resource descriptions) (see 
Figure 5). 4i (FOR EYE) is an ensemble of Intelligent GUI 
Shell (smart middleware for context dependent combination 
of different MetaProviders) and MetaProviders, visualization 
modules that provide integration and context-dependent 
filtered representation of resource data. Context-awareness 
and intelligence of such interface brings a new feature that 
gives a possibility for user to get not just raw data, but 
required integrated information based on a specified context.  
 
Figure 5.  Browsing of visually-enriched linked data. 

99
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
The Figure 5 shows us example of Linked Data browsing 
with respect to the heating systems imbedded into smart-
home described in one of the scenarios in the beginning of 
the paper. Based on the resource description file that contains 
visually-enriched 
resource 
descriptions, 
one 
of 
the 
visualization modules of the 4i Browser has been used to 
present us all the heating systems available in the house. 
Another visualization tool (Linked Data Browser) has been 
used to browse the RDF graph from the same resource 
description source and show us certain smart-home with 
correspondent smart-home heating system that consist of 
four sub-heating systems for living room, bedroom, balcony, 
and bathroom.                 
IV. 
CONCLUSION AND FUTURE WORK 
Approaching the era of people-oriented systems, human 
becomes very dynamic and proactive resource of a large 
integration environment with a huge amount of different 
heterogeneous data. People are great asset to be utilized in 
servicing and services creation. Involving people to the 
process, we allow them be not only a user, but also add value 
to technology evolution.  
With the aim to elaborate an environment that enables 
integration of heterogeneous “things” and intelligent 
distributed systems within the Internet of Things framework, 
authors 
address 
the 
mechanism 
of 
human-assisted 
simplification of semantic matching to allow interoperability 
of entities in the IoT. Assuming unavailability of a sufficient 
amount of professional experts to be involved to the daily 
“things” integration support process, authors proposed the 
way to make user be not just a consumer of thing-based 
services, but also an expert capable to compose and establish 
interoperability among the things. Taking into account 
specifics of the potential user and unsuitability of current 
ontology alignment tools for it, this paper presents a human-
driven approach towards visually-facilitated ontology 
alignment through visually-enriched ontologies and resource 
(thing) descriptions. Authors have presented extension of 
RDFS and OWL ontologies to enable creation of visually-
enriched ontologies and resource descriptions. Current 
implementation of correspondent toolset is concentrated on 
and consists of an interface for the final stage - Visual 
Ontology Alignment Tool that assumes existence of 
VisOntologies 
and 
VisDescriptions 
of 
Things.  
Implementation of the tool for visual enrichment of 
ontologies and resource descriptions is considered as a future 
continuation of presented work.  
ACKNOWLEDGMENT 
This research has been performed as part of IoT Tivit 
SHOK Program in the department of Mathematics and 
Information Technology (MIT, University of Jyvaskyla, 
Finland) funded by TEKES and consortium of industrial 
partners. Authors are grateful to the project team members 
from Industrial Ontologies Group (IOG) and colleagues from 
VTT research team (as well as other industrial partners of the 
project) who have been involved into the correspondent task 
and did provide fruitful cooperation. 
 REFERENCES 
[1] O. Khriyenko, V. Terziyan, and O. Kaikova, “User-assisted 
Semantic Interoperability in Internet of Things: Visually-
facilitated Ontology Alignment through Visually-enriched 
Ontology and Thing Descriptions”, In: Proceedings of the 
Sixth International Conference on Mobile Ubiquitous 
Computing, 
Systems, 
Services 
and 
Technologies 
(UBICOMM 2012), Barcelona, Spain, 23-38 September, 
2012, pp. 104-110. 
[2] D.J. Cook and S.K. Das, “How smart are our environments? 
An updated look at the state of the art”. Pervasive and Mobile 
Computing. 3(2) , 2007, pp. 53-73. 
[3] J. Honkola, H. Laine, R. Brown, and O. Tyrkko, “Smart-M3 
information sharing platform”. Proc. IEEE Symp. Computers 
and Communications (ISCC’10), 2010, pp. 1041-1046. 
[4] K. Kotis and A. Katasonov, "Semantic Interoperability on the 
Web of Things: The Smart Gateway Framework", CISIS 
2012, Palermo, Italy, 2012. 
[5] O. Kaykova, O. Khriyenko, D. Kovtun, A. Naumenko, V. 
Terziyan, and A. Zharko, “Challenges of General Adaptation 
Framework for Industrial Semantic Web”, In: Amit Sheth and 
Miltiadis Lytras (eds.), Semantic Web-Based Information 
Systems: 
State-of-the-Art 
Applications, 
CyberTech 
Publishing, 2007, pp. 61-97. 
[6] Semantic Web, 2001. URL: http://www.w3.org/2001/sw/ 
[7] T. Berners-Lee, J. Hendler, and O. Lassila, “The Semantic 
Web”, Scientific American 284(5), 2001, pp. 34-43.  
[8] A. Ankolekar, M. Burstein, J.R. Hobbs, O. Lassila, D.L. 
Martin, D. McDermott, S.A. McIlraith, S. Narayanan, M. 
Paolucci, T.R. Payne, and K. Sycara, “DAML-S: Web Service 
Description for the Semantic Web”, 2002. URL: http://www-
2.cs.cmu.edu/~terryp/Pubs/ISWC2002-DAMLS.pdf  
[9] M. Paolucci, T. Kawamura,  T.R. Payne, and K. Sycara, 
“Importing 
the 
Semantic 
Web 
in 
UDDI”, 
2002. 
URL:http://www-2.cs.cmu.edu/~softagents/papers/Essw.pdf 
[10] EM. Maximilien, A. Ranabahu, and K. Gomadam, “An 
Online Platform for Web APIs and Service Mashups”. In 
IEEE INTERNET COMPUTING, IEEE Computer Society, 
2008, pp. 32-43. 
[11] T. Berners-Lee, “Linked Data - Design Issues”. 2006. URL: 
http://www.w3.org/DesignIssues/LinkedData.html 
[12] T. Heath and C. Bizer, “Linked Data: Evolving the Web into a 
Global Data Space” (1st edition). Synthesis Lectures on the 
Semantic Web: Theory and Technology, 1:1, 1-136. Morgan 
& Claypool. 2011. 
[13] O. Khriyenko and M. Nagy, “ Semantic Web-driven Agent-
based Ecosystem for Linked Data and Services”, In: 
Proceedings of the Third International Conferences on 
Advanced Service Computing, Rome, Italy, 25-30 September, 
2011, 8 p. 
[14] O. Khriyenko, “Collaborative Service Ecosystem - Step 
Towards the World of Ubiquitous Services”. In: Proceedings 
of the IADIS International Conference Collaborative 
Technologies 2012, Lisbon, Portugal, 19-21 July,  2012.  
[15] V. Spiliopoulos and G. A. Vouros, “Synthesizing Ontology 
Alignment Methods Using the Max-Sum Algorithm”, 
Knowledge and Data Engineering, IEEE Transactions on, 
vol.PP, no.99, pp.1-11.  
[16] K. Kotis, A. Katasonov, and J. Leino, “Aligning Smart and 
Control Entities in the IoT”, In: Proceedings of the 5th 
Conference on Internet of Things and Smart Spaces, St.-
Petersburg, Russia, 27-28 August, 2012.  
[17] K. Kotis, A. Valarakos, and G. Vouros, "AUTOMS: 
Automating Ontology Mapping through Synthesis of 
Methods.", In: Proceedings of the International Semantic Web 

100
International Journal on Advances in Internet Technology, vol 6 no 1 & 2, year 2013, http://www.iariajournals.org/internet_technology/
2013, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Conference (ISWC'06), Ontology Matching International 
Workshop, Atlanta USA, 00/2006.  
[18] A. Valarakos, V. Spiliopoulos, K. Kotis, and G. Vouros, 
"AUTOMS-F: A Java Framework for Synthesizing Ontology 
Mapping Methods", i-Know,07, Graz, Austria, 00/2007. 
[19] P. Shvaiko and J. Euzenat, “Ontology matching: state of the 
art and future challenges”. IEEE Transactions on Knowledge 
and Data Engineering, 2012. 
[20] J.  Pina, E. Cerezo, and F. Seron, “Semantic visualization of 
3D urban environments”. Multimedia Tools and Applications, 
Volume 59, Number 2 (2012), pp. 505-521, DOI: 
10.1007/s11042-011-0776-3. 
[21] M. Lanzenberger and J. Sampson, “Human-Mediated Visual 
Ontology Alignment”. HCI (9) 2007, pp. 394-403. 
[22] P. Jain, P. Hitzler, A.P. Sheth, K. Verma, and P.Z. Yeh, 
“Ontology Alignment for Linked Open Data”. In: Proceedings 
of the 9th International SemanticWeb Conference, ISWC 
2010, Springer-Verlag (2010), Shanghai, China, November 7-
11, 2010, pp. 402–417.  
[23] F. Kboubi, A.H. Chaibi, and M.B. Ahmed, 'Semantic 
Visualization and Navigation in Textual Corpus'. In: CoRR 
abs/1202.1841, 2012 . 
[24] M. Ehrig and Y. Sure, “Ontology mapping - an integrated 
approach. In: Bussler, C., Davis, J., Fensel, D., Studer, R. 
(eds.) Proceedings of the First European Semantic Web 
Symposium, Heraklion, Greece, 10-12 May, 2004. 
[25] Protégé-owl 
(Stanford 
Medical 
Informatics) 
- 
http://protege.stanford.edu/overview/protege-owl.html 
[26] M. Lanzenberger and J. Sampson, “Alviz - a tool for visual 
ontology alignment”. In: Society, I.C.S. (ed.) Proceedings of 
the IV06, 10th International Conference on Information 
Visualization, London, UK, July, 2006. 
[27] A. Sheth and D. Avant, "Semantic Visualization: Interfaces 
for exploring and exploiting ontology, knowledgebase, 
heterogeneous content and complex relationships," NASA 
Virtual Iron Bird Workshop, CA, March 31 and April 2, 2004. 
[28] M. Granitzer, V. Sabol, K. W. Onn, D. Lukose, and K. 
Tochtermann, "Ontology Alignment - A Survey with Focus 
on Visually Supported Semi-Automatic Techniques," Future 
Internet, 2, 2010, pp. 238-258. 
[29] O. Khriyenko, "Context-sensitive Multidimensional Resource 
Visualization", In: Proceedings of the 7th IASTED 
International Conference on Visualization, Imaging, and 
Image Processing (VIIP 2007), Palma de Mallorca, Spain, 29-
31 August 2007.  
[30] O. Khriyenko, "4I (FOR EYE) Technology: Intelligent 
Interface for Integrated Information", In: Proceedings of the 
9th International Conference on Enterprise Information 
Systems (ICEIS-2007), Funchal, Madeira – Portugal, 12-16 
June 2007. 
[31] O. Khriyenko, "Context-sensitive Visual Resource Browser", 
In: Proceedings of the IADIS International Conference on 
Computer 
Graphics 
and 
Visualization 
(CGV-2008), 
Amsterdam, The Netherlands, 24-26 July 2008. 
[32] RDF Vocabulary Description Language 1.0: RDF Schema. 
W3C 
Recommendation 
10 
February 
2004. 
URL: 
http://www.w3.org/TR/rdf-schema/  
[33] OWL Web Ontology Language. W3C Recommendation 10 
February 
2004. 
URL: 
http://www.w3.org/standards/techs/owl#w3c_all  
[34] Notation3 (N3): A readable RDF syntax. W3C Team 
Submission 
28 
March 
2011. 
URL: 
http://www.w3.org/TeamSubmission/n3/ 
 

