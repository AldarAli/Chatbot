Minmax Regret 1-Center on a Path/Cycle/Tree
Binay Bhattacharya, Tsunehiko Kameda, and Zhao Song
School of Computing Science, Simon Fraser University
University Drive, Burnaby, Canada V5A 1S6
Email: {binay, tiko, zhaos}@sfu.ca
Abstract—In a facility location problem in computational
geometry, if the vertex weights are uncertain one may look for
a “robust” solution that minimizes “regret.” The best previously
known algorithm for ﬁnding the minmax regret 1-center in a tree
with positive vertex weights is due to Yu et al., and runs in sub-
quadratic asymptotic time in the number of vertices. Assuming
that the minimum weight of at least one vertex is non-negative,
we present a new, conceptually simpler algorithm for a tree with
the same time complexity, as well as an algorithm that runs in
linear (respectively sub-quadratic) time for a path (respectively
cycle).
Index Terms—facility location; 1-center; minmax regret opti-
mization
I. INTRODUCTION
Deciding where to locate facilities to minimize the com-
munication or transportation costs is known as the facility
location problem. For a recent review of this subject, the
reader is referred to [1]. The cost of a vertex is formulated as
the distance from the nearest facility weighted by the vertex
weight. In the minmax regret version of this problem, there is
uncertainty in the weights of the vertices and/or edge lengths,
and only their ranges are known. Chen and Lin (Theorem 1
in [2]) proved that in solving this problem, the edge lengths
can be set to their maximum values, when the vertex weights
are non-negative. Our model assumes that the edge lengths are
ﬁxed and uncertainty is only in the weights of the vertices.
A particular realization (assignment of a weight to each
vertex) is called a scenario. Intuitively, the minmax regret
1-center problem can be understood as a 2-person game as
follows. The ﬁrst player picks a location x to place a facility.
The opponent’s move is to pick a scenario s. The payoff to
the second player is the cost of x minus the cost of the 1-
center, both under s, and he wants to pick the scenario s that
maximizes his payoff. Our objective (as the ﬁrst player) is to
select x that minimizes this payoff in the worst case (i.e., over
all scenarios).
The rest of the paper is organized as follows. Section II
reviews work relevant to our problem. In Section III, we
deﬁne the terms that are used throughout the paper, and cite or
prove some center-related properties. Section IV ﬁrst discusses
how to compute the centers and their costs under a certain
set of scenarios. We then present a linear time algorithm for
computing the minmax regret 1-center of a path. In Section V,
we present an algorithm for a cycle. Finally, Section VI
presents a simpliﬁed algorithm for a tree, and Section VII
concludes the paper.
II. RELATED WORK AND OUR OBJECTIVES
The problem of ﬁnding the minmax regret 1-center on a net-
work, and a tree in particular, has been attracting great research
interest in recent years. Several researchers have worked on
this problem. The classical p-center problem is discussed by
Kariv and Hakimi in [3]. Megiddo [4] computes the classical
1-center of a tree with non-negative vertex weights in O(n)
time, where n is the number of vertices. Averbakh and Berman
[5] proved some basic results in the minmax regret 1-center
problem. More recently, Yu et al. [6] solved the problem in
O(mn log n) (resp. O(n log2 n)) time for a general network
(resp. tree network) with positive vertex weights, where m is
the number of edges.
Since the known algorithm for a general network is rela-
tively inefﬁcient, we look for more efﬁcient algorithms for spe-
cial families of networks. Yu et al. [6] proposed an O(n log2 n)
time algorithm for a tree with positive vertex weights. Their
algorithm is rather involved, so we want to come up with
a conceptually simpler algorithm, under the more relaxed
assumption that at least one vertex has the maximum weight
that is positive. A cycle is the simplest building block of any
network that is more general than a tree, but to the best of our
knowledge, nothing is known about the complexity of ﬁnding
the minmax regret 1-center on a cycle. We want to design
an efﬁcient algorithm that is speciﬁcally tailored to a cycle
network.
III. PRELIMINARIES
As stated above, we assume that there is at least one vertex
whose minimum weight is non-negative. Then it is clear that
all vertices whose weights are negative can be ignored, because
they cannot inﬂuence the 1-center. Therefore, we assume
without loss of generality that the minimum weights of all
vertices are non-negative.
Let G = (V, E) be a path, cycle or tree network with n
vertices. We also use G to denote the set of all points (vertices
and points on edges) on G. Each vertex v ∈ V is associated
with an interval of integer weights W(v) = [wv, wv], where
0≤wv ≤wv, and each edge e∈E is associated with a positive
length (or distance). We assume that the distances between a
point on an edge and its end vertices are prorated fractions of
the edge length. For any pair of points p, q ∈ G, the shortest
distance between them is denoted by d(p, q). Let S be the
Cartesian product of all W(v), v ∈ V :
S ≜
Y
v∈V
[wv, wv].
108
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-237-0
ADVCOMP 2012 : The Sixth International Conference on Advanced Engineering Computing and Applications in Sciences

The cost of a point x∈G with respect to v∈V under scenario
s is d(v, x)ws
v, where ws
v denotes the weight of v under s, and
the cost of x under s is deﬁned by
F s(x) ≜ max
v∈V d(v, x)ws
v.
(1)
The point x that minimizes F s(x) is called a (classical) 1-
center under s, and is denoted by c(s). Throughout this paper
the term center refers to this weighted 1-center. The difference
Rs(x) ≜ F s(x) − F s(c(s))
(2)
is called the regret of x under s. We ﬁnally deﬁne the maximum
regret of x as
R∗(x) ≜ max
s∈S Rs(x).
(3)
The scenario that maximizes Rs(x) for a given x∈G is called
the worst case scenario for x. Note that R∗(x) is the maximum
payoff with respect to x that we mentioned in the Introduction.
We seek location x∗ ∈G, called the minimum regret 1-center,
that minimizes R∗(x).
Let V = {v1, v2, . . . , vn}. For simplicity, we use wi = wvi
in what follows. The base scenario, s0, is deﬁned by ws0
i =wi
for all i. A vertex v that maximizes (1) is said to be a critical
vertex for x [5]. For i = 1, 2, . . . , n, let us deﬁne the single-
max scenario si by wi = wi and wj = wj for all j ̸= i, and
let S∗ denote the set of all single-max scenarios. Averbakh
and Berman proved the following fundamental theorem for
the trees, but the same proof is valid for the general network.
Theorem 1: [5] For any point x in a network, there is a
worst case scenario si ∈ S∗. Vertex vi is a critical vertex for
x.
Theorem 1 implies
R∗(x) = max
s∈S∗ Rs(x).
(4)
Therefore, we need to consider only the single-max scenarios
in looking for the minmax regret location x∗.
The cost of x∈G with respect to vi is given by
fi(x) ≜ d(x, vi)wi.
(5)
It will turn out that we need to consider either
f i(x)=d(x, vi)wi or f i(x)=d(x, vi)wi,
(6)
which is called the min-weight cost and max-weight cost with
respect to vi, respectively. To evaluate (2) for s=sj, we need
to ﬁnd c(sj) ﬁrst. Most of our effort will be on how to compute
c(sj) efﬁciently.
IV. PATH NETWORK
We start with a path, which is the simplest network.
A. Computing the Upper Envelope of a Set of Line Segments
Assume that the vertices of a path P =(V, E) are laid out
horizontally, in the order v1, v2, . . . , vn from left to right. Let
Li(x) represent an increasing function, such as f i(x), deﬁned
for x to the right of vi. Its value gets larger as x moves
right from vi. To ﬁnd c(sj) efﬁciently, we construct the upper
envelope of {Li(x) | i = 1, 2, . . . , n}, assuming w1 ≥ 0. If
wi ≥ wj for i < j, then we have Li(x) > Lj(x) for all x
(to the right of vj, where Lj(x) is deﬁned), and Lj(x) won’t
be a part of the upper envelope. In this case, we say that
Li(x) dominates Lj(x), and can ignore Lj(x). Therefore, the
following algorithm assumes that wi <wj holds for any i and
j such that i<j.
Algorithm Find-Envelope/Path
1) Push [1 : (v1, 0)] in stack Σ. (Meaning: L1(x), starting
at (v1, 0), is the initial part of the upper envelope.)
2) For k=2, 3, . . . , n, carry out steps 3 to 5.
3) Let [i:(xi, yi)] be the item at the top of Σ. If line Lk(x)
passes above (xi, yi) pop up the top item from Σ and
repeat this step.
4) Compute the intersection (xk, yk) of Lk(x) and Li(x).
If xk is to the left of vn, then push [k:(xk, yk)] into Σ.
Lemma 1: When
Algorithm
Find-Envelope/Path
completes, an entry [i:(xi, yi)] in stack Σ means Li(x) forms
a segment of the upper envelope of {Lj(x) | j = 1, 2, . . . , n},
starting at point (xi, yi). Find-Envelope/Path runs in
O(n) time.
Proof: The ﬁrst part is obviously true of the entry [1 :
(v1, 0)], which is the bottom entry of Σ that is never removed.
Suppose [j :(xj, yj)] (resp. [i:(xi, yi)]) was the entry at the top
(resp. 2nd from the top) of Σ, when line Lk(x) is processed.
See Figure 1. If Lk(x) is like the dotted line, then step 3
vk
Lj
Li
Lk
vj
vi
Fig. 1.
Computing the upper envelope of lines Li(x), Lj(x), and Lk(x).
computes the intersection of Lk(x) and Lj(x) and pushes [k:
(xk, yk)] into Σ, indicating that Lk(x) is the next segment
starting at (xk, yk). If Lk(x) is like the dashed line, then step
4 computes the intersection Lk(x) and an earlier line Li(x),
and pushes [k :(xk, yk)] into Σ, while step 3 discards Lj(x).
In this case [i : (xi, yi)] and [k : (xk, yk)] become adjacent
entries in Σ, indicating that the line segment from (xi, yi) to
(xk, yk) is a part of the upper envelope. It is easy to show that
the algorithm runs in O(n) time.
For the base scenario, s0 (deﬁned in Section III), let
F s0
r (x) denote the upper envelope of the set of functions,
{f r
i (x)|1≤i≤n}, where f r
i (x)=f i(x) for x to the right of
vi, and 0 otherwise. A typical function F s0
r (x) is plotted in
109
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-237-0
ADVCOMP 2012 : The Sixth International Conference on Advanced Engineering Computing and Applications in Sciences

Figure 2. Symmetrically, let F s0
l (x) denote the upper envelope
v i
0
c(s )
c(s )i
v j
c(s )j
F   (x)
    0
s
r
  
F   (      )
  
i c(s )i
s
    i
_
 y=d(x,c(s )) w
i
f (x)
j     
_
    
f (x)
j     
_
j
_
j
= d(x,v )w j
_
j
= d(x,v )w j
_
j
= d(x,v )w j
_
j
f (x)
i     
_
i    
_
    
i
= d(x,v )w
    
    j
_
 y=d(x,c(s )) w
j
l
l
Fig. 2.
Intersection of f
l
i(x) and F s0(x) gives c(si).
of {f l
i(x) | 1 ≤ i ≤ n}, where f l
i(x) = f i(x) for x to the left
of vi, and 0 otherwise. The value of F s0
l (x) gets smaller as x
approaches vi from left. We have
F s0(x) = max{F s0
l (x), F s0
r (x)},
and the 1-center under s0, c(s0), is clearly at the lowest point
of F s0(x), namely at the intersection of F s0
l (x) and F s0
r (x).
From Lemma 1 it follows that
Lemma 2: [4]
The
1-center
under
s0,
c(s0),
and
F s0
l (c(s0))=F s0
r (c(s0)) can be computed in O(n) time.
B. Regret Function
Our next objective is to ﬁnd R∗(x). But to do so, we need
to know some of the centers in {c(si)|i=1, 2, . . . , n}. Center
c(si) can be found by computing the intersection of f i(x)=
d(x, vi)wi and F s0(x). Recall that F s0(x) = F s0
l (x) (resp.
=F s0
r (x)) for x to the left (resp. right) of c(s0). Let c(s0) be
on edge (vm, vm+1). Let f
l
i(x)=f i(x)=d(vi, x)wi for x to
the left of vi, and 0 otherwise. Figure 2 shows the intersection
of f
l
i(x) and F s0
r (x), where m+1 ≤ i ≤ n. If f
l
i(x) passes
below the lowest point of F s0(x) at x=c(s0), then we have
c(si)=c(s0). For 1≤i≤m, we can similarly compute c(si),
as the intersection of f
r
i (x) and F s0
l (x). Again, if f
r
i (x) passes
below the lowest point of F s0(x) at x=c(s0), then we have
c(si)=c(s0).
Function R∗(x) will be convex, and the optimal location x∗
will correspond to its lowest point. By deﬁnition, si is obtained
from s0 by changing wi from wi to wi. From (1), we have
F si(x)
=
max
v∈V d(v, x)wsi
v
=
max{f i(x), F s0(x)}.
(7)
Cf. Lemma 3.5 in [6]. From (2), (4) and (7), we get
R∗(x) =
max
si∈S∗{max{f i(x), F s0(x)}−F si(c(si))}
=
max
si∈S∗{max{d(c(si), x)wi, F s0(x)−F si(c(si))}}
= max{ max
si∈S∗{d(c(si), x)wi}, F s0(x)−F sk(c(sk))},
(8)
where F sk(c(sk)) = minsi∈S∗ F si(c(si)). Therefore, R∗(x)
can be computed as the upper envelope of {d(c(si), x)wi |
si ∈ S∗} and F s0(x)−F sk(c(sk)).
Figure 2 shows F s0
r (x) and two cost functions f
l
i(x) and
f
l
j(x), where i < j and wi > wj. If c(si) lies to the right
of c(sj), then f
l
i(x)−F si(c(si)) = d(c(si), x)wi dominates
f
l
j(x) − F sj(c(sj)) = d(c(si), x)wj, and thus sj can be
discarded. In this case, c(sj) need not even be computed,
saving time.
Algorithm Find-Nondominated
Push point p=(c(s0), F s0
r (c(s0))) into stack ND.
For i=m+1, . . . , n, do the following:
1) Find if f
l
i(x) passes above point p=(xp, yp) at the top
of ND.
2) If it does, compute the intersection of f
l
i(x) and F s0
r (x),
and push it into ND. Otherwise, c(si) is to the left of
xp, and d(c(si), x)wi could not be a part of the upper
envelope. In Figure 2, sj satisﬁes this condition.
Lemma 3: Algorithm
Find-Nondominated
runs
in
O(n) time.
Proof: By Lemma 2, we can compute (c(s0), F s0
r (c(s0)))
in O(n) time. Step 1) of the above algorithm entails evaluating
f
l
i(xp), and takes constant time. In Step 2), we check succes-
sive segments of F s0
r (x) upwards, starting at p=(xp, yp). We
never backtrack along F s0
r (x), so that the total time required
is O(n).
Let us rewrite {d(c(si), x)wi |si ∈S∗} in (8) as follows:
{d(c(si), x)wi |si ∈S∗} = {d(c(si), x)wi |1≤i≤m}
∪{d(c(si), x)wi |m+1≤i≤n}.(9)
In order to ﬁnd the upper envelope of the functions in
{d(c(si), x)wi |m+1≤i≤n} and identify its linear sections,
we use Algorithm Find-Envelope/Path, with left and
right reversed, starting at the right end of the path. This
envelope is a continuous, piecewise linear, decreasing function
of x, if we move x from v1 towards vn. We combine it with
F s0(x)−F sk(c(sk)), according to (8), to ﬁnd the left half
of R∗(x). Analogously, we can ﬁnd the right half of R∗(x),
based on {d(c(si), x)wi | 1 ≤ i ≤ m}, which is a continuous,
piecewise linear, increasing function of x. The lowest point of
R∗(x) can be found in O(n) time.
Theorem 2: The minmax regret 1-center of a path network
can be computed in O(n) time.
V. CYCLE NETWORK
Let C =(V, E) be a cycle with length LC. For p, q ∈C, the
part of C clockwise, from p, to q is denoted by C(p, q), and its
length is denoted by d(p, q). The cost of a point x ∈ C under
s is given by
F s(x) =
X
v∈V
min{d(v, x), d(x, v)}ws
v.
(10)
Suppose that the vertices of C are numbered cw as v1, . . . , vn
from the origin o that lies in the interior of edge (vn, v1). If
d(p, q) = d(q, p), we say that points p and q are antipodal to
each other, and p (resp. q) is the antipode [7] of q (resp. p),
denoted by p=α(q) (resp. q=α(p)).
110
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-237-0
ADVCOMP 2012 : The Sixth International Conference on Advanced Engineering Computing and Applications in Sciences

Recall the base scenario s0 and the set S∗ of single-
max scenarios from Section III. To evaluate (2) for different
scenarios and points, our ﬁrst task is to ﬁnd the centers
{c(si)|si ∈S∗}.
A. Finding Upper Envelope
The cost line of vertex vi under base scenario s0, is f i(x)=
d(x, vi)wi. Figure 3 shows f 2(x), f 3(x), and f 4(x). They
are plotted over two periods of a cycle, so that for any point
p∈C, one of the two occurrences of p in it has the property that
C(α(p), p) and C(p, α(p)) appear continuously in the diagram.
This property becomes useful when we process “queries” later.
Observe that f i(x) takes the minimum (resp. maximum) value
v 4
v3
v 2
v 2
v3
0
c(s )
v 1
v 1
v 4
v 4
0
c(s )
a
c=
b
2
c(s )
2
_
f (x)
Fig. 3.
The upper envelope is shown in thick line segments.
at x = vi (resp. x = α(vi)). The center c(s0) is at the lowest
point of the upper envelope of {f i(x)|i=1, 2, . . . , n}.
The following algorithm constructs the clockwise (cw) upper
envelope, Ecw, of {Li(x) | i = 1, 2, . . . , n}, where Li(x) =
f i(x) for x∈C(vi, α(vi)) and Li(x)=0 for x∈C(α(vi), vi).
It is very similar to Find-Envelope/Path.
Algorithm Find-Envelope/Cycle
1) Put [1:(v1, 0)] in stack Σ. (Meaning: L1(x), starting at
(v1, 0) is the initial part of the upper envelope.)
2) For k=2, 3, . . . , n, carry out steps 3 and 4.
3) Let [i:(xi, yi)] be the item at the top of Σ. If line Lk(x)
passes above (xi, yi) pop up the top item from Σ and
repeat this step.
4) Compute the intersection (xk, yk) of Lk(x) and Li(x).
If the intersection lies within LC/2 clockwise from vi,
then push [k:(xk, yk)] into Σ.
Clearly, there are O(n) linear segments in Ecw. The follow-
ing lemma can be proved similarly to Lemma 1.
Lemma 4: When Find-Envelope/Cycle applied to
a cycle completes, an entry [i
:
(xi, yi)] in stack Σ
means Li(x) forms a segment of the upper envelope of
{Lj(x)
|
j
=
1, 2, . . . , n}, starting at point (xi, yi).
Find-Envelope/Cycle runs in O(n) time.
Similarly, we can compute the counterclockwise (ccw) upper
envelope, Eccw, in O(n) time.
Lemma 5: The 1-center, c(s0), of the base scenario on a
cycle network can be found in O(n) time.
Proof: After computing Ecw and Eccw in O(n) time, we
compute their upper envelope, E, in linear time. The lowest
point of the merged envelope corresponds to c(s0).
For each single-max scenario sj ∈S∗, we consider f j(x) as
its query function. In the example shown in Figure 3, the query
function f 2(x) intersects upper envelope E at two points, a
and b. Point c is the lowest point in C(a, b), so c(s2) is given
by point c. In general, let a (resp. b) be the closest point to vj,
if any, where query line f j(x) intersects E in the one-period
interval C(α(vj), α(vj)). If there is no such intersection point,
set a = α(vj) that lies on the ccw side of vj in the 2-period
diagram of E, and b=α(vj) that lies on the cw side of vj in
the 2-period diagram of E. Then c(sj) is given by the lowest
point on E, clockwise from a to b.
Lemma 6: The centers {c(si)|si ∈S∗} and the costs of the
centers {F si(c(si))|si ∈S∗} can be computed in O(n log n)
time.
Proof: The intersection points a and b mentioned above,
if any, can be determined in O(log n) time, using the query
algorithm in [8] twice. It yields both c(si) and F si(c(si)). We
repeat this for every scenario si ∈S∗.
B. Finding the Optimal Location
Let G be a network, which is a cycle in our current situation.
Averbakh and Berman [9] convert G to its auxiliary network
G′ in such a way that the minmax regret 1-center problem
on G becomes the classical 1-center problem on G′. Assume
that F s(c(s)) for all s ∈ S∗ are available, and let M be a
positive integer that is sufﬁciently large [9]. They append an
edge (vi, v′
i) of length {M −F si(c(si))}/wi to every vertex
vi ∈V , where v′
i is a new vertex of degree 1, called the dummy
vertex corresponding to vi. The vertices of G′ that are present
in G have weights equal to zero. For any vertex v′
i ∈ G′ its
weight is set to wi. Clearly, G′ is a weighted cactus graph.
Averbakh and Berman prove
Theorem 3: [9] The minmax regret 1-center problem on
network G can be solved by computing the classical weighted
1-center problem on G′.
Now that we have computed {F si(c(si)) | si ∈ S∗}
(Lemma 6), we can invoke Theorem 3. It is known that the
classical weighted 1-center problem on a cactus network can
be computed in O(n log n) time [10]. We thus have
Theorem 4: The minmax regret 1-center in a cycle network
can be found in O(n log n) time.
VI. TREE NETWORK
Since our algorithm for a tree network needs a balanced tree,
we ﬁrst review spine decomposition [11], [12] that can convert
any tree into a structure that has properties of a balanced tree.
A. Review of Spine Decomposition
Many efﬁcient tree algorithms preprocess a given tree,
by aggregating information on its subtrees, and storing the
condensed information at their root vertices. In spine decom-
position, the structure that stores the aggregate information is
separated from the given tree, and the height of this structure
is bounded by O(log n), so that it can provide beneﬁts of a
balanced tree.
Given tree T with n vertices, we ﬁrst ﬁnd its 1-center
under the base scenario rT = c(s0), and assume that T is
a binary tree rooted at rT = c(s0). If T is not binary, it can
be transformed into a binary tree by adding no more than
111
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-237-0
ADVCOMP 2012 : The Sixth International Conference on Advanced Engineering Computing and Applications in Sciences

n zero weight vertices and zero length edges [13]. In spine
decomposition, we select a path from rT to a leaf in T such
that the next vertex on this path always follows the child
vertex that leads to the largest number of leaves from it. More
formally, let Nl(v) denote the number of leaves that have v
as an ancestor. If v0(=rT ), v1, . . . , vk are the vertices on the
path, then Nl(vi+1) ≥ Nl(v′
i) always holds, where v′
i is the
other child vertex of vi, if any. We call path ⟨v0, v1, . . . , vk⟩
the top spine, if k≥1. Now, for each i=1, . . . , k, we consider
vi as the root of the subtree containing v′
i, and ﬁnd other spines
recursively. Note that a vertex belongs to at most two spines.
Between these two spines, the one that is closer to the root of
T is considered the parent spine of the other. For the tree T in
Figure 4(a), its spine decomposition is shown in Figure 4(b),
where the vertices of each spine are aligned either horizontally
or vertically.
Root
1
v
2
v
3
v
4
v
5
v
0
v
6
v
v7
8
v
v9
v10
11
v
12
v
13
v
14
v
(a)
v1
v2
v3
v4
v5
0
v
6
v
7
v
8
v
9
v
10
v
11
v
v12
v13
14
v
Root of T
(b)
Fig. 4.
(a) Tree T; (b) Spine decomposition of T.
A spine could be of length O(n). To gather information
efﬁciently from the vertices of spine σ, we build an auxiliary
binary tree, called the spine tree and denoted by τ(σ), on
top of it as follows. For spine σ = ⟨v0, v1, . . . , vk⟩ with
root r(σ) = v0, let N(vi) denote the number of descendant
vertices of vi in T, excluding the vertices on σ, but including
vi itself. Therefore, we have N(v0) = 1. Under the root of
τ(σ), we create two child nodes. (We use the term “nodes”
to distinguish them from the vertices of the original tree T.)
We partition {v0, . . . , vk} into two subsets L = {v1, . . . , vh}
and R = {vh+1, . . . , vk} in such a way that Ph
i=0 N(vi)
and Pk
i=h+1 N(vi) are as close as possible, and associate
L (resp. R) with the left (resp. right) child node. We keep
partitioning until each node is associated with just one vertex,
which becomes a leaf node of τ(σ). We then identify the root
of τ(σ) with r(σ) in the parent spine. In Figure 5(a), for
example, the nodes at the two ends of each arrow are really
just one node. The resulting structure, together with the spine
tree for each spine, is denoted by SD(T).
Lemma 7: [12] SD(T) can be constructed in O(n log n)
time, where n is the number of vertices in the given tree T.
B. Envelope Tree
We remove the edges belonging to the original tree T
from SD(T) as in Figure 5(b), and call the resulting tree
the envelope tree, denoted by E(T). An argument in [12]
(Subsection 2.2) directly implies that
Lemma 8: [12] The height of E(T) is O(log n), where n
is the number of vertices in T.
Root of T
v'
Top spine
1
v
v2
0
v
6
v
7
v
8
v
9
v
1
10
v
11
v
12
v
u
v'
v'
8
7
(a)
1
v
0
v
6
v
v7
8
v
9
v
v10
11
v
u
v2
12
v
(b)
Fig. 5.
(a) Part of SD(T); (b) E(T).
Note that Lemma 8 does not imply that the sum of the heights
of all spine trees is O(log n). For our purpose, we slightly
modify spine decomposition. As the top spine, we choose a
maximal path from the root that contains the center c(s0).
Lemma 8 is still valid with this modiﬁcation.
C. Algorithm
For a path and a cycle, instead of computing the intersection
of f j(x) with f i(x) individually for all i, which is too time-
consuming, we constructed the upper envelope for {f i(x)|vi ∈
V }, and computed the intersection of f j(x) with it. However,
it is difﬁcult to make this approach work for a tree.
For a tree, we ﬁrst compute the upper envelopes for various
subsets of {f i(x) | vi ∈ V } instead. Namely, in Phase 1, we
compute an upper envelope at each node (called an envelope
node) u in E(T). Such an upper envelope is for the cost
functions of all vertices of T that have u as an ancestor in
E(T), based on the vertex weights under s0. For example, at
u in Figure 5(b), we compute and store the upper envelope for
its descendant vertices i.e., v1, v6, v7 and v10. In Phase 2, for
each vertex v∈V , we extract a set of O(log n) upper envelopes
from those computed in Phase 1, compute the intersection of
f j(x) with each of them, and determine the most costly one
among them, which gives c(sj). Here are the details.
1) Phase 1: We assume that envelope tree E(T) has already
been constructed for a given T (Lemma 7). At a leaf node
of E(T), which is a vertex (vi) of T, the upper envelope is
f i(x) = d(x, vi)wi, which is composed of either one line
(if vi is a leaf vertex of T) or two lines (if vi is a non-
leaf vertex of T) forming the shape of letter V. At the 2nd
level from the bottom of E(T), each envelope node has two
end vertices of an edge of T as its descendants. Eventually,
we reach an envelope node that is the root of a spine tree.
Figure 6 illustrates how to propagate the cost contributions
from the vertices of a lowest spine σ1 to its parent spine σ2.
The horizontal line in Figure 6(a) represents σ1. It is connected
to σ2 at its root vertex v=r(σ1). The information concerning
the upper envelope from σ1 that we need to propagate to τ(σ2)
is shown by the thick line segments, labeled “Contribution
to parent spine” in Figure 6(a). It, together with its mirror
image, is stored as envelope Ev(x) at v. This is because the
cost contribution from a vertex on σ1 is the same at any two
points on σ2 that are at equal distance from v, one closer to
r(σ2) and the other away from it. See Figure 6(b).
112
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-237-0
ADVCOMP 2012 : The Sixth International Conference on Advanced Engineering Computing and Applications in Sciences

Root of spine
Contribution to
   parent spine
v
h
(a)
Root of child spine
v
h
v
E  (x)
(b)
v
v'
v'
E   (x)
v
E  (x)
u
E  (x)
(c)
Fig. 6.
(a) Spine σ1 with v = r(σ1); (b) Ev(x) stored at v on spine σ2;
(c) Eu(x) stored at u (parent of v and v′).
Suppose that two vertices on σ2, v and v′, have an envelope
node u as their parent node. We now construct Eu(x) from
Ev(x) and Ev′(x) by computing their upper envelope. In
Figure 6(c), Eu(x) is shown by thick line segments. We can
similarly construct the upper envelopes at higher envelope
nodes in E(T). Since E(T) is of height O(log n) (Lemma
8), the total time required for computing the envelopes at all
the nodes of E(T) is O(n log n).
2) Phase 2: Let π(vj) denote the path from the leaf node
vj (a vertex of T) to the root of E(T). We compute c(sj),
tracing π(vj) upward from vj as follows:
Algorithm Find-Center/Tree
1) At each node u visited, do the following:
(a) If the left (resp. right) child node of u is on π(vj),
let u′ denote u’s right (resp. left) child node.
(b) Find the lowest intersection point, if any, of f j(x)
with Eu′(x), where they have opposite slopes.
2) From among the intersection points computed in step
1(b), ﬁnd the highest point. If this point has a higher
cost than c(s0), then the corresponding location gives
c(sj). Otherwise c(sj)=c(s0).
Since c(s0) is on the top spine, if vj is on spine σ, c(sj) can
lie either on σ or an anscester spine. Thus, the spine trees for
the other spines can be ignored. Suppose, for example, that we
want to compute c(s10) in Figure 5. We ﬁrst visit the parent
node of v10, and check its other child node, where the upper
envelope (i.e., f 7(x)) for v7 is stored as Ev7(x). We now
carry out step 1(b), i.e., compute the intersection of f 10(x)
and f 7(x) , to ﬁnd the ﬁrst candidate for c(s10). We then
trace E(T) upwards to u, and repeat step 1(a)(b). In this case,
it entails computing the intersection of f 10(x) with Eu′(x)
stored at the left child u′ of u, where Eu′(x) is the upper
envelope of f 1(x) and f 6(x).
Theorem 5: The minmax regret 1-center of a tree network
can be found in O(n log2 n) time.
Proof: In executing Find-Center/Tree, the number
of envelope nodes encountered on π(vj) is O(log n) by
Lemma 8. Step 1(b) can be carried out, using binary search,
since Eu′(x) is convex with a number of corner points. Thus
the processing time per vertex (vj) is O(log2 n), and the
total time for all 1-centers {c(sj) | si ∈ S∗} is O(n log2 n).
Once we have computed {c(si) | si ∈ S∗}, we can evaluate
{F si(c(si))|si ∈S∗} easily, and invoke Theorem 3.
VII. CONCLUSION AND FUTURE WORK
We have presented an algorithm for ﬁnding the minmax
regret 1-center of a path (resp. cycle) network that runs
in O(n) (resp. O(n log n)) time. No algorithms speciﬁcally
tailored to these families of networks were previously known.
We also presented a new algorithm for a tree that runs in
O(n log2 n) time. For a tree, an algorithm with the same
complexity was already known [6], but its description takes
up several pages.
Lemma 5 implies that the classical weighted 1-center in a
cycle network can be computed in O(n) time, which is a new
result and is optimal. It is valid for any cycle network that
contains at least one vertex whose weight is non-negative. As
future work, we want to see if the O(n log2 n) time complexity
for a tree can be improved, and also work on a cactus network.
A more challenging problem is ﬁnding the minmax regret p-
center for p≥2.
ACKNOWLEDGMENT
This work was partially supported by Discovery Grants
from the Natural Science and Engineering Research Council
of Canada.
REFERENCES
[1] T. S. Hale and C. R. Moberg, “Location science research: A review,”
Annals of Operations Research, vol. 123, pp. 21–35, 2003.
[2] B. Chen and C.-S. Lin, “Minmax-regret robust 1-median location on a
tree,” Networks, vol. 31, pp. 93–103, 1998.
[3] O. Kariv and S. Hakimi, “An algorithmic approach to network location
problems, part 1: The p-centers,” SIAM J. Appl. Math., vol. 37, pp.
513–538, 1979.
[4] N. Megiddo, “Linear-time algorithms for linear-programming in R3 and
related problems,” SIAM J. Computing, vol. 12, pp. 759–776, 1983.
[5] I. Averbakh and O. Berman, “Algorithms for the robust 1-center problem
on a tree,” European Journal of Operational Research, vol. 123, no. 2,
pp. 292–302, 2000.
[6] H.-I. Yu, T.-C. Lin, and B.-F. Wang, “Improved algorithms for the
minmax-regret 1-center and 1-median problem,” ACM Transactions on
Algorithms, vol. 4, no. 3, pp. 1–1, June 2008.
[7] A. Goldman, “Optimal center location in simple networks,” Transporta-
tion Science, vol. 5, pp. 212–221, 1971.
[8] B. Chazelle and L. J. Guibas, “Fractional cascading: II. Applications,”
Algorithmica, vol. 1, pp. 163–191, 1986.
[9] I. Averbakh and O. Berman, “Minimax regret p-center location on a
network with demand uncertainty,” Location Science, vol. 5, pp. 247–
254, 1997.
[10] B. Ben-Moshe, B. Bhattacharya, Q. Shi, and A. Tamir, “Efﬁcient
algorithms for center problems in cactus networks,” Theoretical Compter
Science, vol. 378, no. 3, 2007.
[11] R. Benkoczi, B. Bhattacharya, M. Chrobak, L. Larmore, and W. Rytter,
“Faster algorithms for k-median problems in trees,” Mathematical
Foundations of Computer Science, Springer Verlag, vol. LNCS 2747,
pp. 218–227, 2003.
[12] R. Benkoczi, “Cardinality constrained facility location problems in
trees,” Ph.D. dissertation, School of Computing Science, Simon Fraser
University, Canada, 2004.
[13] A. Tamir, “An O(pn2) algorithm for the p-median and the related
problems in tree graphs,” Operations Research Letters, vol. 19, pp. 59–
64, 1996.
113
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-237-0
ADVCOMP 2012 : The Sixth International Conference on Advanced Engineering Computing and Applications in Sciences

