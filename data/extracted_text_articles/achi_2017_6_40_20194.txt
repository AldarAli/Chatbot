Identifying Inexpensive Off-the-Shelf Laser Pointers for Multi-User Interaction on
Large Scale Displays
Christopher S. Stuetzle
Dept. of Computer Science
Merrimack College
North Andover, Massachusetts 01845
Email: stuetzlec@merrimack.edu
Barb Cutler
Dept. of Computer Science
Rensselaer Polytechnic Institute
Troy, NY 12180
Email: cutler@cs.rpi.edu
Tyler Sammann
Dept. of Computer Science
Rensselaer Polytechnic Institute
Troy, NY 12180
Email: tylersammann@gmail.com
Abstract—We present a method for identifying inexpensive, off-
the-shelf laser pointers in a multi-user interaction environment
on large-scale displays. We identify a laser pointer’s personality, a
measure of its output in a particular context. Our method requires
a set of inexpensive and unmodiﬁed green lasers, a large screen, a
projector, and a camera with an infrared (IR) ﬁlter. The camera
detects the IR spillover from the green laser beam, while ignoring
color information projected onto the screen. During a calibration
phase, a radial histogram of each laser’s IR spillover are used to
represent the laser’s personality. Our system is able to identify the
spots of a speciﬁc laser, allowing multiple users to simultaneously
interact in the environment. In addition, we present a series of
applications that take advantage of tracked and identiﬁed laser
pointers to demonstrate large-scale, multi-user interactions.
Keywords–Systems, man, and cybernetics; User interfaces;
Human-computer interaction.
I.
INTRODUCTION
Multi-user, large-scale interfaces, in which individual users
are identiﬁed and tracked, present a challenging and worth-
while design problem. Collaborative problem solving is of-
tentimes easier to accomplish when sharing a large projection
surface than when operating on individual screens (such as
with mobile devices), and user interaction and U.I. design
is simpliﬁed if all users operate on the same display. In
applications in which efﬁcient interactivity between users is
important, laser pointer devices are preferable to stationary
pointer devices, such as mice [1]. In most cases, the chal-
lenge of identifying individual users is tackled by physically
modifying laser pointers, an effective yet often-times costly
and time-consuming solution. To circumvent these drawbacks,
we present the idea of describing a laser by its personality, a
measure of the shape and intensity of a laser pointer’s leaked
infrared (IR) light, which allows us to track and identify an off-
the-shelf laser pointer among a group of others for the purpose
of multi-user collaborative applications.
Our contributions are:
•
The laser pointer personality, the signature shape and
intensity of a laser point’s infrared light leakage, and
the laser pointer personality system used to identify
laser pointers by their personalities.
•
Several multi-user applications that demonstrate the
utility of the personality system.
Figure 1. False color renderings of the IR spill from 6 inexpensive green
laser pointers.
The rest of this paper is organized as follows. Section II
describes the laser personality system. Section III discusses
accuracy test results. Section IV discusses various applications
that take advantage of the laser personality system. Section V
closes the article.
A. Related Work
Single laser point detection is accomplished in two main
ways: brightness ﬁltering and IR ﬁltering. Olsen and Nelson
detect a laser spot on a large display screen with a two-pass
system that detects red brightness with an applied convolution
ﬁlter [2]. Oh and Stuerzlinger allow for multiple laser points
by applying a threshold to the brightness ﬁeld of the image
[3]. The same technique is applied by Davis and Chen in their
LumiPoint system [4]. However, depending on the brightness
of the laser spot with respect to the rest of the image, this can
create trouble due to its context sensitivity. Ahlborn et al. [5]
present a system using multiple camera views, in which the
background image is ﬁltered out. IR ﬁltering is employed by
work by Qin et al. [6], Angelini et al. [7], and Cheng et al.
[8].
In addition to laser spotting, one challenge in multi-user
laser pointer systems is pointer identiﬁcation. One method is to
dynamically change the number of lasers present in the system
at any given point in time, and to track an IDed laser spot
across frames with predictive measures, such as the Kalman
ﬁlter [9] [10] [8]. Another method involves the use of time
division multiplexing, or the application of a laser blinking
pattern, to identify a particular laser, as employed by Vogt
150
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

et al. [11] [12], as well as Pavlovych and Stuerzlinger [13].
Francisco de la O Chavez et al., present a system whereby
users can operate the electronic devices and appliances in their
homes with a laser pointer [10]. Qinet al., present a system in
which a special laser pointer is used to project several beams
whose orientations indicate the angle of rotation along the
beam axis of the laser [6]. Biet al. present the uPen, a laser
pointer outﬁtted with right- and left-click buttons, designed to
mimic computer mouse functionality [14]. Shizukiet al. present
a series of gestures used with a laser pointer, and a series of
applications using them [15]. In some applications, single laser
pointer identiﬁcation is all that is necessary, such as that by
Miksiket el al. [16]. Each of these systems involves specialized
hardware, and such additional cost. Our system requires only
an I.R. ﬁltered camera and cheap laser pointers.
II.
LASER POINTER PERSONALITY SYSTEM
To detect the current position of each laser pointer dot, we
use a 1280 x 960 pixel monochrome, 33fps video camera.
An IR pass ﬁlter in front of the camera blocks all visible
light (from the projector), so we can robustly detect the bright
points of IR light from the laser. We speciﬁcally use green
laser pointers because the green light is produced indirectly
from an infrared laser diode, and some of the infrared light
remains for our detection. Most inexpensive green lasers do
not include an IR ﬁlter to block this light.
We begin with a simple calibration step to determine
the pixel to pixel correspondence between our camera and
the 1920 x 1080 projector and projection surface, and to
collect intensity data on all lasers in the system. Our system
has been tested on screens as tall as 18 feet (2.44 meters).
Calibration consists of hovering each laser point on several
known locations on the screen for a period of time. When
tracking multiple lasers simultaneously, we use the Kuhn-
Munkres, a.k.a. Hungarian Algorithm [17] [18] [19] to match
the lasers from frame to frame. This method produces a
pairing that efﬁciently minimizes the sum of the distances
between the positions of each laser across the two frames. We
also considered using a Kalman ﬁlter [9] to track smoothly
moving laser dots, but our early experiments indicated this
was complicated to tune for the accelerations of the laser dots
at corners or tight turns and ultimately not necessary.
In addition to the centroid of the laser spot we also extract
the intensity and size of the detected IR spill to calibrate
laser intensity data for identiﬁcation. Inexpensive lasers exhibit
unique IR spillover, as shown in Fig. 1, and this is fairly
consistent for each device (once the laser has warmed up for
about 15 seconds, and as long as the batteries are reasonably
fresh), allowing us to track and identify the lasers over time.
The pattern of spill from the laser varies most with distance of
the laser to the screen. The top row of images in Fig. 1 were
collected with the laser 15 feet from the screen, the middle
row at 10 feet, and the bottom row at 5 feet.
We call this signature the lasers personality. During the
calibration phase, we capture several frames worth of this
intensity data at each of the calibration points for each laser.
We examine the blob of light and calculate a radial histogram
of the intensity values of the blob. In practice, 20 bins
(representing a radius of 20 pixels) is sufﬁcient to capture the
uniqueness of a laser spots shape. Note that the calibration
can be performed simultaneously for many lasers (with 1
Figure 2. 30 personality measurements for each of 6 lasers from a single
calibration screen location.
person per laser), and takes less than a minute. Sample laser
personality data is presented in Fig. 2.
A. Identifying Laser Spots: Matching Personalities
Once calibration is complete, the system is able to match
any laser spot on the projection surface with one of the
calibrated lasers. When a laser spot is detected, its personality
is calculated, and matched with that of one of the known lasers.
For efﬁciency, we utilize two passes to process the camera
image. In a ﬁrst coarse pass, we examine every nth pixel in
the camera image and all pixels greater than a pre-set intensity
threshold continue to the second pass. In the second pass, a
generous window around each remaining pixel is examined.
We collect all nearby pixels above the threshold and extract the
largest connected component. The centroid of this component
is set as the laser spot position. We then compute the histogram
of pixel intensities shown in Fig. 2, matching the personalities
using the sum of squared differences between the detected and
known personalities.
It is important to note that the apparent laser intensity
varies spatially for each laser due to a number of additional
variables, including: distance from laser to screen, distance
from screen to camera, and camera vignetting. We normalize
for these variations by averaging all of the intensity data
for all of the lasers collected at each of the calibration grid
points, and normalize the input by dividing it by the spatial
average. We use barycentric coordinates and interpolation
to normalize laser points between calibration grid locations.
Camera position normalization is especially crucial when the
camera is placed at an extreme angle to the screen, and thus
experiences signiﬁcant perspective distortion. When multiple
lasers are simultaneously detected on the screen, we leverage
temporal coherence to disambiguate lasers with somewhat
similar histogram personalities. We employ the Kuhn-Munkres
algorithm to assign unique labels to all detected points; that
is, no two lasers will be assigned the same ID, even if they
both select the same ID as their ﬁrst choice.
III.
ACCURACY TESTS
The tests were performed using six lasers (given IDs 1-6)
in the 19 x 23 space. The space was divided into a series of
151
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

TABLE I. RESULTS FROM ACCURACY TESTS.
Laser
a) Single Pos.
b) Arc Mov.
c) Line Mov.
d) Walking Path
e) All Lasers
1
100.00
100.00
96.54
98.27
53.88
74.14
51.13
68.49
99.79
100.00
2
100.00
100.00
100.00
100.00
90.43
95.21
78.65
86.25
99.07
100.00
3
95.85
100.00
70.96
73.48
35.14
48.65
60.50
96.10
83.49
98.75
4
92.79
100.00
77.40
100.00
80.41
100.00
83.02
100.00
99.61
99.78
5
99.67
99.67
100.00
100.00
57.99
92.57
82.95
94.26
99.80
99.92
6
90.33
96.03
93.89
95.91
72.56
79.70
91.81
94.86
84.08
99.90
Min:
521
347
230
645
968
testing locations at discretized 22.5 arcs with radii of 5’, 10’,
and 15’ from the center of the projection surface. The results
are presented in Table ??. Five accuracy tests were run in total,
described below.
•
a) Stationary Test - judge how well lasers could be
matched to the calibrated data while stationary.
•
b) Arc Walking Test - judge how much side-to-
side movement affected the overall accuracy of the
identiﬁcation system.
•
c) Straight Line Walking Test - judge how much
distance from the screen affected the overall accuracy
of the system.
•
d) Path Walking Test - provide an overall averaging
of the previous two tests, and to mimic movement
expected by users in real-world environments.
•
e) All Lasers Simultaneous Test - assess how accu-
rately the laser identiﬁcation system performed when
several lasers were on the screen at once.
For each test and for each laser two percentages are
reported: the percentage of frames in which it was correctly
identiﬁed as its primary ID (left column), and the percentage
of frames in which it was identiﬁed as either the primary or
secondary ID (right column). The minimum number of frames
collected for each test is reported along the bottom row. All
units are percentages of frames.
Overall, our laser identiﬁcation system is most effective
when lasers remain in the general area from which their
calibration data is collected while the system is in use. It is
rare that a laser is mislabeled in this instance. However, when
moving from place to place, the shape of the laser spot can
change dramatically, and so the personality can as well. This
explains the poor performance of lasers in general in tests c)
and d).
These tests bring to light two noteable shortcomings of our
identiﬁcation system that will be tackled in the future. The ﬁrst
is that position is important when comparing a laser spot to a
given set of laser personalities, and a lasers personality changes
over the time of its use due to warming and battery drain.
IV.
APPLICATIONS
We have implemented a series of ﬁve applications that
effectively take advantage of multi-user interfaces for visual-
ization, education, and problem-solving. The common thread
among each of the applications is its use of input from several
different users to achieve a common goal, e.g. exploration
of a data visualization or solving a puzzle. Our applications
are a multi-user painting program, a puzzle solving program,
Figure 3. A visualization of the puzzle application.
a terrain and hydrography data visualization tool, a graph
visualization tool, and an infrastructure map visualization tool.
The ﬁrst application is a standard paint program, which
allows any number of users to paint on the screen using the
laser pointer as a brush, selecting color and size at will. Users
hover over buttons to choose color and brush The puzzle
solving program reads in an image and breaks it into n equally-
sized rectangular textured tiles, randomizes them, and displays
the new order on the screen, seen in Fig. 3. In the ﬁgure, ﬁve
users (each represented by his own color) attempt to solve
a 7x5 piece puzzle. The ﬁve images represent ﬁve points in
time during the solving of the puzzle. Each border between
two tiles that should not be adjacent is greyed out (top left
image), but once a tile is placed next to its proper neighbor,
the border ﬁlls in (middle image). Each laser point creates a
trail of a unique color as it moves across the projection surface,
providing feedback to individual users. The common goal of
152
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

the users of this application is to reassemble the original image
by clicking and dragging the tiles.
In addition, we have implemented a visualization tool for
terrain hydrography. The goal of the application is to allow for
the exploration of terrain hydrography data by multiple users
through a laser pointer interface, utilizing the work of Metz
et al. [20] and OCallaghan and Mark [21]. The application
consists of a data view and a graphical user interface side-by-
side, in which modes are selected in the GUI through dwell-
selection. In addition to selection of modes, the laser pointers
are also used to interact directly with the 3D terrain data and
camera view.
We have also developed a graph visualization tool that
allows users to explore data organized by nodes and edges. Our
application takes as input node and connectivity information.
Laser points which dwell on a node for a period of time grab
the node, indicated by the laser trail turning green, and can
drag the node to a new location. The graph will rearrange itself
based on a mass-spring simulation, minimizing the energy in
the system.
Our ﬁnal application is a visualization, exploration, and
editing tool for infrastructure data. The data are organized as
a spatial graph of interconnected nodes and arcs in several
different infrastructure systems: electric power, telecommuni-
cations, transportation, etc. The tool is used to visualize the
complex network along with vulnerabilities during hurricane
and ﬂooding scenarios (e.g., where are ambulances re-routed
if a local hospital is ﬂooded). Images of all applications and
videos of the system in use are available upon request.
V.
CONCLUSION
Multi-user interaction on large-scale displays is a powerful
collaborative tool with several applications. In this paper, we
have presented a method for identifying off-the-shelf laser
pointers in an inexpensive and simple manner by calibrating
each laser pointers IR spillovers intensity histogram, called
the lasers personality, allowing for closest-neighbor matching
of data points. The system requires only a calibration step to
set up, and once it is complete multiple users can interact with
interfaces in a large-scale environment. Applications tailored
to multi-user collaborate problem solving efforts are presented
in this paper that take advantage of our systems ability to
identify laser points to explore data, manipulate data, and solve
problems in a group environment. Our method is inexpensive,
accurate, simple, and scalable to large screen displays.
While the system works well when users do not change
how far they are from the projection surface (sufﬁcient for
many applications), there are times when this is not enough.
One clear extension to this work is the introduction of con-
tinuous calibration, in which calibration data is updated as
the lasers are used to account for changes in environment,
including the position of the users. Additionally, the next step
of adopting the system for general use is a detailed user study,
which we plan to conduct in the near future. And we will
extend our suite of applications for a broader audience.
REFERENCES
[1]
A. Pavlovych and W. Stuerzlinger, “Laser pointers as interaction devices
for collaborative pervasive computing,” Center for Parallel Computing,
Tech. Rep., 2004.
[2]
D. R. Olsen and T. S. Nielsen, “Laser pointer interaction,” in CHI, 2001,
pp. 17–22.
[3]
J.-Y. Oh and W. Stuerzlinger, “Laser pointers as collaborative pointing
devices,” in Graphics Interface, 2002, pp. 141–150.
[4]
J. Davis and X. Chen, “Lumipoint: Multi-user laser-based interaction
on large tiled displays,” Displays, vol. 23, p. 2002, 2000.
[5]
B. A. Ahlborn, D. Thompson, O. Kreylos, B. Hamann, and O. G. Staadt,
“A practical system for laser pointer interaction on large displays,” in
Proceedings of the ACM symposium on Virtual reality software and
technology, ser. VRST ’05.
New York, NY, USA: ACM, 2005, pp.
106–109.
[6]
Y. Qin, Y. Shi, H. Jiang, and C. Yu, “Structured laser pointer: enabling
wrist-rolling movements as a new interactive dimension,” in Proceed-
ings of the International Conference on Advanced Visual Interfaces, ser.
AVI ’10.
New York, NY, USA: ACM, 2010, pp. 163–166.
[7]
L. Angelini, M. Caon, S. Carrino, O. A. Khaled, and E. Mugellini,
“Multi-user pointing and gesture interaction for large screen using
infrared emitters and accelerometers.” in HCI (2)’11, 2011, pp. 185–
193.
[8]
K. Cheng and K. Pulo, “Direct interaction with large-scale display
systems using infrared laser tracking devices,” in Proceedings of the
Asia-Paciﬁc symposium on Information visualisation - Volume 24, ser.
APVis ’03.
Darlinghurst, Australia, Australia: Australian Computer
Society, Inc., 2003, pp. 67–74.
[9]
R. Kalman, “A new approach to linear ﬁltering and prediction prob-
lems,” Journal of Basic Engineering, vol. 82, no. 1, pp. 35–45, 1960.
[10]
F. de la O Ch´avez, F. Fern´andez de Vega, G. Olague, and J. Llano Mon-
tero, “An independent and non-intrusive laser pointer environment con-
trol device system,” in Proceedings of the 5th international conference
on Pervasive services, ser. ICPS ’08.
New York, NY, USA: ACM,
2008, pp. 37–46.
[11]
F. Vogt, J. Wong, S. Fels, and D. Cavens, “Tracking multiple laser
pointers for large screen interaction,” in Ext. Abstracts UIST, 2003, pp.
95–96.
[12]
F. Vogt, J. Wong, B. A. Po, R. Argue, S. S. Fels, and K. S. Booth,
“Exploring collaboration with group pointer interaction,” in Proceedings
of the Computer Graphics International. Washington, DC, USA: IEEE
Computer Society, 2004, pp. 636–639.
[13]
A. Pavlovych and W. Stuerzlinger, “Effect of screen conﬁguration and
interaction devices in shared display groupware,” in Proceeding of the
3rd ACM international workshop on Human-centered computing, ser.
HCC ’08.
New York, NY, USA: ACM, 2008, pp. 49–56.
[14]
X. Bi, Y. Shi, X. Chen, and P. Xiang, “uPen: laser-based, personal-
ized, multi-user interaction on large displays,” in MULTIMEDIA ’05:
Proceedings of the 13th annual ACM international conference on
Multimedia.
New York, NY, USA: ACM Press, 2005, pp. 1049–1050.
[15]
B. Shizuki, T. Hisamatsu, S. Takahashi, and J. Tanaka, “Laser pointer
interaction techniques using peripheral areas of screens,” in Proceedings
of the working conference on Advanced visual interfaces, ser. AVI ’06.
New York, NY, USA: ACM, 2006, pp. 95–98.
[16]
O. Miksik, V. Vineet, M. Lidegaard, R. Prasaath, M. Niessner,
S. Golodetz, S. L. Hicks, P. Perez, S. Izadi, and P. H. Torr, “The
semantic paintbrush: Interactive 3d mapping and recognition in large
outdoor spaces,” in Proceedings of the 33rd Annual ACM Conference
on Human Factors in Computing Systems, ser. CHI ’15.
New York,
NY, USA: ACM, 2015, pp. 3317–3326.
[17]
H. W. Kuhn, “The Hungarian method for the assignment problem,”
Naval Research Logistics Quarterly, vol. 2, pp. 83–97, 1955.
[18]
J. Munkres, “Algorithms for the assignment and transportation prob-
lems,” Journal of the Society for Industrial and Applied Mathematics,
vol. 5, no. 1, pp. 32–38, March 1957.
[19]
J. Weaver, “Kuhn-Munkres (Hungarian) Algorithm in C++,” 2010.
[20]
M. Metz, H. Mitasova, and R. S. Harmon, “Efﬁcient extraction of
drainage networks from massive, radar-based elevation models with
least cost path search,” Hydrology and Earth System Sciences, vol. 15,
no. 2, pp. 667–678, 2011.
[21]
J. F. O’Callaghan and D. M. Mark, “The extraction of drainage networks
from digital elevation data,” Computer Vision, Graphics, and Image
Processing, vol. 28, no. 3, pp. 323 – 344, 1984.
153
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-538-8
ACHI 2017 : The Tenth International Conference on Advances in Computer-Human Interactions

