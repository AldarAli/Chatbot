Some New Concepts in MCS Ontology for Cognitics; 
Permanence, Change, Speed, Discontinuity, Innate versus Learned Behavior, and More 
 
Jean-Daniel Dessimoz and Pierre-François 
Gauthey  
HEIG-VD, School of Business and Engineering 
HES-SO, Western Switzerland University of Applied 
Sciences 
CH-1400 Yverdon-les-Bains, Switzerland 
e-mail: {jean-daniel.dessimoz, pierre-
francois.gauthey}@heig-vd.ch 
 
Hayato Omori 
Department of Mechanical Engineering 
University of Chuo 
Tokyo, Japan 
 e-mail: h_omori@bio.mech.chuo-u.ac.jp 
 
 
 
Abstract—Paving the way for advanced cognitive technologies 
and applications, an ontology for automated cognition, 
cognitics, has been proposed. Starting in a pragmatic way from 
where we stand, in particular with humans creating robots, 
progressing with distributed axioms, navigating through small 
contexts in direction of selected goals (design of high 
performance machines, of robots cooperating with humans, 
and better understanding of cognition in humans), we adopt an 
incremental, constructivist approach, in conceptual and 
operational frameworks. Discussion is made in the current 
paper of a number of cognitive notions including those of 
reality, time and revisited “speed”, change and discontinuity, 
innate and learned behaviors, as well as the human-inspired 
basics of communication in a group. These newly defined 
notions conveniently complement the existing Model for 
Cognitive Sciences ontology. All these elements confirm the 
rightness of our current approaches in solving concrete 
Artificial Intelligence problems and this is illustrated below by 
some concrete examples taken in domestic context, including 
robots capable of learning. 
Keywords- cognitive robotics; MCS ontology for cognition; 
cognitive 
speed; 
discontinuity; 
reality; 
innate 
behavior;  
communication basics 
I. 
 INTRODUCTION 
In the past century, a major step in evolution has been 
made when information has been formally defined, and 
infrastructure has been provided for communication and 
processing of information in a massive scale. 
In the early days of signal processing, in technical terms, 
information was neatly provided by some transmitters, 
originating from some other electronic devices, control 
panels, microphones or other sensors yet. Machine-based 
sources of information were limited to signal generators, 
such as for sine-waves or pseudo-random sequences. 
Then, however, things have become much more complex 
and cognition is the new domain to domesticate, where 
pertinent information is autonomously created by expert 
agents (e.g. , [1]). It is with this very relevant goal that the 
MCS theory for cognitive sciences has been created (Model 
for Cognitive Sciences [2, 3] and the cognitive pyramid of 
Fig. 1). This has been published and has already brought 
interesting benefits in terms of understanding the core 
cognitive properties, assessing quantitatively their values, 
and allowing for convincing implementation of cognitive 
robots in selected areas [4]. So far, people have developed 
context-dependant expertise indicators (e.g. Elo points for 
chess-players, Association of Tennis Professionals points for 
tennis-players, or IQ scores), but unfortunately no other 
work, in our knowledge, has addressed the formal, 
technically-prone definitions of cognitive entities with 
associated units, beyond the concept of information. 
 
Figure 1.  Main cognitive entities in MCS theory. Important cognitive 
concepts, defined in MCS theory, are colored in green (left).  They are 
based on a few classic entities, including reality and time, which, though 
classic, also need a discussion from a cognitive perspective 
Fig.1 schematically presents the main cognitive entities 
in MCS theory context. Without giving here again the 
equations for their quantitative assessments, let us briefly 
review their definitions.  
The top group is green, referring to MCS essentials. 
Knowledge is, for an agent (human or possibly machine-
based) the property to deliver the right information; fluency, 
the cognition speed; expertise, the property to deliver 
information right and fast, the product of knowledge and 
fluency; learning, the ability to increase expertise levels; 
intelligence, the capability to learn, and quantitatively, the 
ratio of learning to experience; experience, the amount of 
information witnessed in terms of input and output 
associations (“examples”, “experiments”); complexity, the 
amount of information necessary to exhaustively describe an 
object; abstraction, the property of delivering less 
139
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

information than it is incoming; concretization is the inverse 
of abstraction.  
The lower group is white. Even though in principle the 
corresponding concepts are classical, experience shows that 
their limits are not well understood, and this is especially 
disturbing as the new, green concepts are built on them. Thus 
information is very much time-dependant, the delivery of it 
essentially making its repetition useless; information is 
essentially subjective, which means that the same message 
may convey different quantities to different users; memory is 
considered here as a support for the permanence of 
messages, such as an engraved stone, i.e. without the 
typically associated writing and reading processes; the last 3 
quoted concepts, reality, model and time, are further 
discussed in the sequel of this paper.  
In general, commonsense, classical concepts, and 
corresponding MCS concepts are quite synonymous and can 
be described by the same words; nevertheless, there remain 
often subtle differences, and in the sequel of this article, 
when the respective distinctions should be made, the “c-“ 
prefix will be added for the terms defined in MCS Ontology; 
for example c-speed (1/s unit) is not the usual displacement, 
motion speed (m/s unit). 
Today another step is considered, whereby artificial 
cognitive agents should effectively approach human 
cognitive capabilities for three complementary reasons: 
better functional services (including those involving human-
machine cooperation), better understanding of human nature, 
and implementation possibility of theories in order to make 
them operational, and thereby possibly validate them. 
Proceeding should now be done in incremental steps along 
two complementary ways: the understanding of concepts, 
and the operationalized implementation of cognition in 
machines. 
In this endeavors, a first surprise had been to experience 
that the prerequisites, the basis on which the MCS theory 
was built, were not at all as widely understood as expected 
(re. general surveys [5,6] and focused discussions below). A 
complement had been progressively brought, re-discussing 
classical topics, namely those relating to the notions of 
information, models and memory. 
Now, at the moment of addressing in its “generality” the 
cognitive faculty of humans, another necessary pre-condition 
for implementing it in machine-based agents appears. A 
further analysis, of deeper foundations yet on which the 
MCS theory is grounded, cannot be escaped. What is reality? 
What is time? How to cope with the infinite complexity of 
reality? How much innate or wired can be the cognitive 
capability we are considering?  
The paper addresses these questions in successive 
sections: Section II for reality; Section III for time; Section 
IV for ways to cope with the infinite complexity of reality, in 
particular including the innate versus learning paradigms for 
producing new cognitive agents. Finally, the general 
presentation made so far will be illustrated in Section V with 
detailed concrete examples, taken in the field of cooperative 
robotics, addressing both human and machine-based 
cognitive aspects and operations. 
II. 
WHAT IS REALITY? 
In MCS theory, reality is in principle viewed as 
everything, including not only physical objects but also 
immaterial ones, including information repositories, models, 
assumptions, novels and if-worlds. It corresponds to the 
universal definition of Parmenides: What is, is. As illustrated 
in Fig. 2, reality is infinitely complex (re. the definition of 
complexity in  MCS ontology: an infinite amount of bits or 
megabytes of information would be required for the 
exhaustive description of reality), so much so that even any 
tiny part of it, in practical terms, is infinitely complex as 
well. Reality, including self, is also always the ultimate 
reference. All subjects facing reality are bound to adopt a 
constructivist approach [7], relying on means initially self-
provided, as innate or “wired”, and later on, hopefully 
improving those means, in particular by proceeding with 
exploration and learning by experience (Concretely, a human 
starts in particular with DNA; a typical robot of ours is given 
in particular a computer and an executable program; then 
they explore and learn and ultimately successfully achieve 
many new, unforeseen operations). 
This position is similar to the one of Kant [5], for whom 
innate, pre-existing “categories” are initially required, 
allowing cognitive agents to perceive. And simultaneously, 
by careful axiomatic contributions, complex cognitive 
structures including possible collective, shared models 
(culture) can be elaborated. 
In summary, in a first stage where a single individual is 
considered, we do not need to know what is reality, as we 
benefit from the beginning, of an innate (or “wired” in 
machines) capability to cope with it (models). Nevertheless, 
rational processes can also develop in parallel, which, with 
automated cognition, possible exploration tasks, and on the 
basis of acquired experience, should yield various 
improvements. 
At the next stage, where the creation of a new capacity to 
cope with reality is considered, ingenuity is the key, as 
defined in MCS ontology [3]. 
 
Figure 2.  Experience strongly suggests that reality is infinitely complex. 
Models may be simple and validly serve singular goals, but they should 
always be considered as very specific for those goals and infinitely 
lacunary with respect to reality 
III. 
WHAT IS TIME? 
Strangely, time is far from well defined in classical 
terms. The proposal of Kant is interesting with his 
140
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

complementary attitudes, leaning on one hand towards 
intuition, 
whereby 
everyone 
has 
a 
spontaneous 
understanding of the time concept; and leaning on the other 
hand towards rationality (Weltweisheit, philosophy), by 
which a rigorous, “mathematical”, definition could be 
elaborated – with no guarantee but chance however to have 
this latter construct coincide with the former one. Similarly, 
St-Augustine claims to know very well what is time - as long 
as noone asks for a formal definition of it! Even in the 
contemporary time where philosophy and science have both 
well developed, Rosenberg apologizes for simply defining 
time as follows: “time is duration” and “duration is the 
passage of time” [6]. 
 
Figure 3.  Time characterizes permanence, and speed as defined in MCS 
ontology, i.e., “c-speed”, does it for change. 
It is well-known that dictionaries tend to have circular 
definitions. This should be accepted for at least two reasons: 
as clearly stated by Kant, reality and cognitive world are 
disconnected; in this sense, a “first” definition, i.e., relating 
directly to reality is impossible (convenient complements to 
circumvent this obstacle include visits to museums, science 
parks, touring and lab experiments). Now, with circular 
definitions, the cognitive world appears as a maze with 
multiple entry points. In a chain of 10 so-related concepts, 
the reader has ten chances to hop with his/her/its intuition 
from reality to the cognitive world (which includes libraries, 
languages, dictionaries and Wikipedia). 
Time has already been addressed in MCS ontology, as 
well two other closely-related concepts fluency and agility. 
Here, however, things improve: a clearer articulation is made 
between time and change; speed is defined in a universal 
way, 
which 
then 
helps, 
with 
appropriate, 
specific 
complements, better handle changes in a variety of domains. 
Fluency, thus, becomes the speed of expert information 
delivery and agility the speed of action. 
We propose here to define time as a distributed axiom, in 
a cloud of 6 interconnected concepts: time, permanence, 
eternity, change, speed, and discontinuity (re. Fig. 3): 
- Time is a measure of permanence, and is quantified by 
the “second” as a unit. 
- Permanence is the property of things that do not change. 
- A permanence that is persistent for an infinite amount 
of time is eternity. 
- Speed is a measure of change, and is quantified, in 
MCS ontology (“c-speed”), by the inverse of a second 
(notice that this is more general than the usual motion speed, 
assessed in meter per second; it can also apply to all 
dimensions other than linear in distance, e.g. speed of 
rotation, heating, speech, sedimentation, or general cognitive 
operations). 
- Change is the property of things that do not remain 
same, stable, permanent over a certain time.  
- A change that occurs at an infinite speed is a 
discontinuity. 
If any single one of the six previous statements is 
intuitively understood, this evidence can be rationally 
propagated to all the other 5 associated concepts. 
Changes can be of different orders: the speed of change 
may be permanent, constant over a certain time (1st order 
change); or the speed itself may change at constant speed, 
yielding the notion of permanent acceleration (2nd order 
change), etc. (re. “jerk” for 3rd order change). 
IV. 
HOW TO COPE WITH THE INFINITE COMPLEXITY OF 
REALITY? 
Section II has shown that reality should be considered as 
infinitely complex. Yet, it appears that much can often be 
achieved in practice. So, what paradigms allow for such 
positive outcomes? The current section presents 5 of them, 
including the selection of (prioritized) goals, the pragmatic 
exploration of local circumstances, the generation of agents 
with some innate or wired initial capabilities, an iterative 
process improving performance, and the accelerated progress 
resulting from setting multiple, coordinated actions in 
parallel. 
A. Necessity of selecting a goal 
As illustrated in Fig. 2, experience shows that numerous 
goals can be reached while ignoring most aspects of reality. 
Numerous simple ad hoc models prove effective. To the 
point where even bacteria not only survive in our often-
hostile world, but even usually live well and multiply. 
A basic paradigm consists in focusing attention on 
selected contexts, successively considering them with as 
many constraints as possible. A good example of this 
approach is notably the famous “hic et nunc – here and now” 
framework in Jesuits’ case studies. Here, are some other 
typical cases: “under assumption”, “with abstract and holistic 
views”, “with more detailed analytical representations”, etc. 
Critical for success is the proper selection of a goal. A 
goal in practice always has a number of peculiarities that 
open possibilities for effective and simple modeling (re. also 
Fig. 2). In AI, it is often said in substance that experts know 
what to ignore in a given situation. 
For example, we have stated above what is the main goal 
of the research we refer to in this paper: to make possible the 
design of artificial cognitive agents effectively approaching 
141
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

human cognitive capabilities, with further possible positive 
impacts in three areas (see Introduction section). Toward this 
goal, an effective model implies in particular the proposed 
extensions of MCS ontology. 
Some other, more intuitive arguments for selecting a goal 
include the following two:  
- It may be useful to map in cognitive context the well 
established A* algorithm for navigation in space [8]; crucial 
elements are the location of goal-site and the one of current 
position. 
- As reality is infinitely complex, non-oriented efforts 
would get as diluted and ineffective as curry powder in a 
river (re. Thai word recommending humans to focus on 
selected goals).  
B. Pragmatic approach adapted to circumstances 
Then care must be given to current status. In a pragmatic 
way, we propose to start with the world as is, modeled as 
simply as necessary for reaching the considered goals. In 
cognition, backtracking is the rule. From the selected goal, 
specifications are derived, which then lead the cognitive 
process, 
and 
in 
particular 
an 
active 
perception 
(“exploration”) 
faculty 
capable 
of 
acquiring 
useful 
information and the possible experience elements eventually 
allowing for improvements (re. Fig. 4). 
 
Figure 4.  In cognition, backtracking is the rule. From the selected goal, 
specifications are derived, which then lead the cognitive process, and in 
particular an active perception (“exploration”) faculty  capable of acquiring 
the experience necessary for improvements. 
C. Innate goal and capabilities 
A prominent place is initially given to innate and current 
capabilities (re. Fig. 5). 
In practice, it is precious to be aware that even humans 
do not start, individually, from scratch. At birth time, they 
already know for example how to grasp, crawl, find their 
food; these tasks are not necessarily obvious for a robot. 
Some chicken for example have such an elaborate pre-
design that they can be industrially grown without any social 
assistance; they can get out of their egg and develop without 
the help of previous generations. 
It is therefore legitimate also for machine-based agents 
under study to start from some predefined (let us say 
“wired”, or pre-programmed) initial state. And humans have 
created robots. 
D. Improved goal and capabilities 
In the paragraph about reality, care had been taken to 
keep things as simple as possible. Nevertheless, multiple 
cognitive processes, including some innate capabilities, and 
possibly newly acquired experience elements could already 
been mentioned, opening the way for improvements and 
learning. 
 
Figure 5.  Current goals and processes may result from exploration 
performed and/or experience acquired by an agent running a given 
cognitive process in a certain domain of reality. Initial goals and processes 
are innate (or “wired”). 
The next interesting stage occurs when the design and 
creation of a new capacity to cope with reality is considered 
(Fig. 6). For connecting directly to reality, chance (as in 
Darwin’s theory,) or ingenuity (as defined in MCS ontology 
[3]) are the main keys.  
 
Figure 6.  Current goals and processes may lead to improvements in next 
generation system (in particular for humans or machines). 
E. Collective approach; elements of communication, 
credibility, reputation, and trust 
Experience shows that the coordinated forces of multiple 
agents – groups- increase the possibilities of successful 
actions in the world. 
This paradigm can be exploited in a multiplicity of ways. 
Of particular interest for our context, we find groups of 
humans, of robots, and of hybrid resources – robots 
cooperating with humans. 
Groups have already been defined in MCS ontology. In 
this context a critical ingredient has been identified as the 
culture of the group, and, in reference to it, the 
communication channel and some kind of formalism, 
protocol or language. 
Two new elements come now under scrutiny. The first 
one, is, for inspiration, the case of baby communication, a 
case reasonably simple for the purpose of progressive 
142
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

transfer of approach to machine-based systems. The second 
one is the sharing of error probability of a source, among 
humans, which expands at group-level a feature already 
taken into account for individual cognitive agents. 
In their early months of existence, babies appear to have 
at least 4 types of communication capabilities. In some 
circumstances, babies can express strongly (high arousal) 
their emotions [9], their states of happiness and unhappiness 
(positive or negative valence); they cry, or smile, which 
typically leads to corresponding correcting or sustaining 
actions from their parents. They also test the good 
understanding and adequacy of key behaviors and gestures 
by imitating, and mimicking; they also sometimes just 
synchronize with others in their attitudes and actions (they 
join in or trigger yawning, and laughing). 
The MCS theory has introduced a value, in terms of 
probability of error, for cognitive agents delivering 
information. This affects the quantitative estimation of 
knowledge characterizing these sources. Now we can add a 
similar, interesting property at group level, which allows for 
appropriate propagation of the expected error-rate. In this 
framework, agents would take into consideration the 
credibility of sources and in particular of other group 
members; if shared at group level, this credibility could form 
the basis for, collectively, building up a reputation. Thus 
when receiving a message, such agents could associate to it a 
trust value, based on reputation. Improvements would result 
in terms of modulation of risk-taking and in the respective 
weighting of multiple conflicting sources being integrated 
(fused). 
V. 
DETAILED EXAMPLES IN COOPERATIVE ROBOTICS 
Let us consider a typical test task of Robocup@Home  
(RaH) competitions, “Fetch and Carry” (F&C). In substance, 
team members can in particular talk to their robots, giving a 
hint about what to fetch (e.g., “a grey box”), and where it 
stands (e.g., “near the front door”); the robot should by then 
know enough about topology and navigation to be able to 
autonomously reach there, locate the object accurately 
enough to get it in the “hand”, grasp it, lift it up, and 
transport it back to the starting location (re. Fig. 7). 
The results of Sections II and IV, including §A to E in 
the latter case can be illustrated here, both in human and in 
machined contexts.  
A. Illustration in human context 
In a first stage, a group of international experts have 
elaborated a rulebook where the general goal of designing 
systems useful for humans (SII) is focused towards a 
domestic goal (SIV.A), and then backtracked into the 
specification of even more focused subgoals : elementary 
capabilities to be devised. One of them is the task called 
“Fetch and Carry”, addressing a “natural” way for a robot to 
find, grasp and transport an object (SIV.A). This 
intermediary goal is then searched in parallel by multiple 
teams (SIV.E). This task adapts to local infrastructure 
(SIV.B) and is iteratively considered, year after year (SIV.C-
D). 
 
Figure 7.  In the F&C task, our proprietary robot RH-Y uses in particular a 
vocal dialogue, a navigation capability typically using a ranger for 
navigation purpose, a time-of-flight camera for recognising and locating 
objects (center) and position and force controlled arm and gripper (left and 
right). 
B. Illustration in robotic context 
The demonstration system is real and thus very complex. 
An overview of the task can be seen on a video available 
online (e.g., [10]) and multiple aspects are presented 
elsewhere. Here we shall discuss a minimum of aspects for 
purpose of example.  
Consider first as an analogy, the problem for a human to 
jump over a wall. This can be easily achieved, or may remain 
totally impossible, depending on how high is the wall; the 
metric height is critical. Similarly, in the cognitive world, 
properties must be precisely defined and metrically 
quantified in order to allow for meaningful descriptions and 
effective requirement estimation. 
For the F&C test task, referees typically retain about 20 
objects, which may be randomly put in 20 possible locations. 
Robots may more or less be wired with initial expertise, e.g., 
in terms of topologies and functions; a common culture is 
also defined (“names” of standard objects and locations are 
published on a wall one day or more before the test). Let us 
practice a quantitative estimation of requirements in terms of 
cognitive entities (re. concepts of Fig. 1). Ignoring here many 
processes, such as e.g. word perception and recognition, or 
navigation and handling, let us focus on the cognitive task of 
understanding which object is where. The input space would 
consist in about 10 bit of information for each object and 
rough location specified. On this basis, at the most abstract 
level, one out of 20x20=400 possibilities should be resolved 
(i.e. about 9 bit) to know which object is to be fetched, and 
where it is roughly located. In this very minimal form, the 
necessary knowledge for correctly understanding the vocal 
dialogue amounts to approximately K=14 lin. With a 
dialogue lasting for 5 s, the amount of expertise for this 
cognitive task amounts to E=14/5=2.8 lin/s. Learning is 
demonstrated and can be quantitatively estimated on this 
domain:  without dialogue the task cannot be achieved in the 
5 min allotted to the task (roughly,  K=0 lin, and therefore, 
E=0 lin/s), while with a successful dialogue, lasting for, say 
5 s, E increases to about 3 lin/s. The MCS intelligence index 
is thereby of i=3/5=0.6 lin/s2.  
In the specified location (e.g.”near the door”) the object 
is manually moved by referees by +/- 20cm just before the 
test, making it impossible for robots to have it fully (pre-) 
143
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

wired. Therefore exploration as in SIV.B is performed, using 
Time-of-Flight (TOF, distance) perception. Notice that here, 
as in most usual cases, the perception process features (or 
requires) a lot more knowledge and expertise than the above 
cognitive operation: in particular the input space includes 
here 176x144 samples, each with 1cm accuracy in a 500cm 
range, i.e., about 150’000 bit of information; similarly, the 
output stage is relatively large for successful trajectory 
specification (about 10’000 bit of output information), and 
the processing time is short (say, 0.1s). 
Time is a very important feature for success, in many 
contexts of this applications (motor control, parallel agent 
management, sensor-based exploration process, etc.). In our 
proprietary “Piaget” environment [11], agents run in parallel, 
with very short, individually granted, time slots, lasting for 
about 100 nanoseconds each in average. Therefore, at low 
level, Piaget defines its own time basis (“TicksPerSecond”); 
nevertheless, at higher level and for longer time increments 
(>10 ms) time is managed on the basis of the system clock, 
and is thereby compatible with the general culture, common 
to multiple robots and humans, that makes effective 
cooperation possible. 
VI. 
CONCLUSION 
Starting in a pragmatic way from where we stand, in 
particular with humans creating robots, progressing with 
distributed axioms, navigating through small contexts in 
direction of selected goals (the design of high performance 
machines, of robots cooperating with humans, and a better 
understanding of cognition in humans), we adopt a 
constructivist approach in conceptual framework and 
validate them gradually by making them operational in test 
tasks. The paper has first briefly revised MCS, an ontology 
for cognition, both for the case when it is embedded in 
humans, and also for the case when it is machine-based, 
automated (re. « cognitics » in this latter case). Past works 
had taken for granted that reality and time were notions 
evident for everyone. Now, at the moment of attempting a 
practical implementation of those notions in robots, the 
situation is quite different. Early results in the context of 
MCS theory had made it clear that reality is infinitely 
complex, practically out of reach for cognition, under 
condition of exhaustivity. Further research has therefore been 
performed and the current paper could nevertheless sketch 
ways to cope with the infinite complexity of reality. Several 
other cognitive notions could also be newly discussed, 
including those of time and revisited “speed”; change and 
discontinuity; innate and learned behaviors; as well as the 
human-inspired basics of communication in a group. On the 
basis of the proposed MCS ontology, and taking often 
advantage of innate/wired expertise, it can be concluded that 
robots can be effectively deployed in quantitatively bound 
domains, as illustrated in several concrete examples. 
ACKNOWLEDGMENTS 
The authors wish to thank the reviewers for several 
useful suggestions. They also acknowledge the contributions 
of numerous engineers and students, as well as members of 
technical services, at HEIG-VD, who have more or less 
directly contributed to the reported project. In particular, this 
year, the following persons can be mentioned: Sudarat 
"Amy" Tangnimitchok, Promphan "Kim" Ounchanum, and 
So Mi Kang. 
REFERENCES 
[1] Bernard Claverie, “Cognirique - Science et pratique des 
relations à la machine à penser”, Editions L'Harmattan, 2005, 
pp. 141. 
[2] Jean-Daniel Dessimoz, "Cognition Dynamics; Time and 
Change 
Aspects 
in 
Quantitative 
Cognitics", 
Second 
International Conference on 
Intelligent Robotics 
and 
Applications. Singapore, 16 - 18 December, 2009; also in 
Springer Lecture Notes in Computer Science, ISBN 978-3-
642-10816-7, pp. 976-993. 
[3] Jean-Daniel Dessimoz, "Cognitics - Definitions and metrics 
for cognitive sciences and thinking machines", Roboptics 
Editions, Cheseaux-Noréaz, Switzerland, ISBN 978-2-
9700629-1-2, pp. 169, January 2011. 
[4] Wisspeintner, T., T. van der Zant, L. Iocchi, and S. Schiffer, 
"RoboCup@Home: 
Scientific 
Competition 
and 
Benchmarking for Domestic Service Robots", Interaction 
Studies, vol. 10, issue Special Issue: Robots in the Wild, no. 
3: John Benjamin Publishing, pp. 392--426, 2009. 
[5] Frederick Charles Copleston, “A history of philosophy”, 
Volume 6, Continuum International Publishing Group Ltd.; 
Édition : New edition (June 5, 2003), pp. 528. 
[6] Alexander 
Rosenberg, 
“Philosophy 
of 
science: 
a 
contemporary 
introduction”, 
Routledge 
comtemporary 
introductions to philosophy, 2005 
[7] George E. Hein, “Constructivist Learning Theory”, The 
Museum and the Needs of People CECA (International 
Committee of Museum Educators) Conference, Jerusalem 
Israel, 15-22 October 1991, Lesley College. Massachusetts 
USA. 
[8] Hart, P. E.; Nilsson, N. J.; Raphael, B., "A Formal Basis for 
the Heuristic Determination of Minimum Cost Paths", IEEE 
Transactions on Systems Science and Cybernetics SSC4 4 (2), 
pp. 100–107, 1968. 
[9] Julie A. Jacko (Ed.), “Human-Computer Interaction. Novel 
Interaction Methods and Techniques” 13th Internat. Conf., 
HCI Internat. 2009, Proc. Part II, San Diego, CA, USA, 
Springer. 
[10] http://rahe.populus.ch /rub/4 , last downloaded on June 3rd, 
2012. 
[11] Jean-Daniel Dessimoz, Pierre-François Gauthey, and Hayato 
Omori, "Piaget Environment for the Development and 
Intelligent Control of Mobile, Cooperative Agents and 
Industrial Robots", accepted for publication, ISR 2012, 
International Symposium for Robotics, Internat. Federation of 
Robotics, Taipei, Taiwan, Aug.27-30, 2012. 
 
 
144
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-218-9
COGNITIVE 2012 : The Fourth International Conference on Advanced Cognitive Technologies and Applications

