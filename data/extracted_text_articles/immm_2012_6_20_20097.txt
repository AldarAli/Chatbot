An Improved Face Recognition Algorithm Using Adjacent Pixel Intensity Difference 
Quantization Histogram and Markov Stationary Feature 
 
Feifei Lee, Koji Kotani*, Qiu Chen, and Tadahiro Ohmi 
New Industry Creation Hatchery Center, Tohoku University 
* Department of Electronics, Graduate School of Engineering, Tohoku University 
Aza-Aoba 6-6-10, Aramaki, Aoba-ku, Sendai 980-8579, JAPAN 
e-mail: fei@fff.niche.tohoku.ac.jp 
 
 
Abstract—Previously, we have proposed a robust face 
recognition algorithm using adjacent pixel intensity difference 
quantization (APIDQ) histogram combined with Markov 
Stationary Features (MSF), so as to add spatial structure 
information to histogram. We named the new histogram 
feature as MSF-DQ feature. In this paper, we employ multi-
resolution analysis for the facial image to extract more 
powerful personal feature. After a set of multi-resolution 
pyramid images is generated using sub-sampling, MSF-DQ 
features at different resolution levels are extracted from 
corresponding pyramid images. Recognition results are firstly 
obtained using MSF-DQ features at different resolution levels 
separately and then combined by weighted averaging. Publicly 
available AT&T database of 40 subjects with 10 images per 
subject containing variations in lighting, posing, and 
expressions, is used to evaluate the performance of the 
proposed 
algorithm. 
Experimental 
results 
show 
face 
recognition using proposed multi-resolution features is very 
efficient. The highest average recognition rate of 98.57% is 
obtained. 
Keywords-Face 
recognition; 
Adjacent 
pixel 
intensity 
difference quantization (APIDQ); Markov stationary feature 
(MSF); Multiresolution; Histogram feature 
I. 
 INTRODUCTION 
In the last two decades, face recognition has been a hot 
research topic in artificial intelligence and pattern 
recognition area due to its potential applications in many 
fields such as law enforcement applications, security 
applications and video indexing, etc. As a more natural and 
effective person identification method compared with that 
using other biometric features such as voice, fingerprint, iris 
pattern, etc., a lot of face recognition algorithms have been 
proposed [1]-[14]. These algorithms can be roughly divided 
into two main approaches, that is to say, structure-based and 
statistics-based. 
In the structure-based approaches [3][4], recognition is 
based on the relationship between human facial features such 
as eye, mouth, nose, profile silhouettes and face boundary. 
Statistics-based approaches [5][6][7] attempt to capture and 
define the face as a whole. The face is treated as a two 
dimensional pattern of intensity variation. Under this 
approach, the face is matched through finding its underlying 
statistical regularities. Principal component analysis (PCA) is 
a typical statistics-based technique [5]. However, these 
techniques are highly complicated and are computationally 
power hungry, making it difficult to implement them into 
real-time face recognition applications. 
In [18][19], a very simple, yet highly reliable face 
recognition 
method 
called 
Adjacent 
Pixel 
Intensity 
Difference Quantization (APIDQ) Histogram Method is 
proposed, which achieved the real-time face recognition. At 
each pixel location in an input image, a 2-D vector 
(composed of the horizontally adjacent pixel intensity 
difference (dIx) and the vertically adjacent difference (dIy)) 
contains information about the intensity variation angle (θ) 
and its amount (r).  After the intensity variation vectors for 
all the pixels in an image are calculated and plotted in the r-θ 
plane, each vector is quantized in terms of its θ  and r values.  
By counting the number of elements in each quantized area 
in the r-θ  plane, a histogram can be created.  This histogram, 
obtained by APIDQ for facial images, is utilized as a very 
effective personal feature. Experimental results show a 
recognition rate of 95.7 % for 400 images of 40 persons (10 
images per person) from the publicly available AT&T face 
database [20].  
In [17][18], we combine the APIDQ histogram with 
Markov stationary feature (MSF), which was proposed in 
[19], so as to encode spatial structure information within and 
between histogram bins. The MSF extends the APIDQ 
histogram features by characterizing the spatial co-
occurrence of histogram patterns using the Markov chain 
models and improves the distinguishable capability of 
APIDQ features to extra-bin distinguishable level [19]. The 
highest average recognition rate of 97.16% is obtained by 
using the publicly available database of AT&T [20]. It can 
be said that the extended MSF-DQ features is more robust 
for face recognition. 
We can imagine that different MSF-DQ features are 
extracted with different resolutions of the image.  Therefore, 
more comprehensive personal feature information can be 
obtained by combining multiple recognition results using 
multi-resolution analysis. In this paper, we employ multi-
resolution analysis for the facial image to extract more 
powerful personal feature.  
In Section II, we will first introduce Markov stationary 
feature (MSF) as well as the Adjacent Pixel Intensity 
Difference Quantization (APIDQ) histogram feature which 
123
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

had been successfully applied to face recognition previously, 
and then describe proposed face recognition algorithm using 
multi-resolution 
MSF-DQ 
features 
in 
Section 
III. 
Experimental results will be discussed in Section IV. Finally, 
conclusions will be given in Section V. 
II. 
RELATED WORKS 
A. Markov Stationary features (MSF) 
The Markov stationary feature (MSF) [19] extends the 
APIDQ histogram features by characterizing the spatial co-
occurrence of histogram patterns using the Markov chain 
models and improves the distinguishable capability of 
APIDQ features to extra-bin distinguishable level. We will 
briefly introduce the MSF in this section. 
Let 
kp  be a pixel in image I, the spatial co-occurrence 
matrix is defined as 
K K
ijc
C
×
=
)
(
  where 
 
/) 2
|
|
,
#(
2
1
2
1
d
p
p
c
p
c
p
c
j
i
ij
=
−
=
=
=
, 
      (1) 
 
in which d (d=1 in this paper) indicates 
1L  distance 
between two pixels 
1p  and 
2
p , and 
ijc  counts the number 
of spatial co-occurrence for bin 
ic  and 
jc .  
The co-occurrence matrix 
ijc  can be interpreted in a 
statistical view. Markov chain model is adopted to 
characterize the spatial relationship between histogram bins. 
The bins are treated as states in Markov chain models, 
and the co-occurrence is viewed as the transition probability 
between bins. In this way, the MSF can transfer the 
comparison of two histograms to two corresponding 
Markov chains. 
  The elements of the transition matrix P are constructed 
from the spatial co-occurrence C by formula (2). 
 
∑
=
=
K
j
ij
ij
ij
c
c
P
1
/
 
 
 
 
     (2) 
 
The state distribution after n steps is defined as
π (n)
, 
and the initial distribution is
π(0)
, the Markov transition 
matrix obeys following rules [19]. 
 
n P
n
( )
)1
(
π
π
=
+
, 
Pn
n
(0)
( )
π
π
=
;  
     (3) 
n
m
m n
P P
P
=
+
 
 
where 
π(0)
 is defined as  
∑
=
=
K
i
ii
ii
c
c
1
/
π (0)
 
 
 
 
     (4) 
 
According to the formula (3), we can get a distribution 
of π  called a stationary distribution which satisfies 
 
π = πP
 
 
 
 
 
     (5) 
 
The 
stationary 
distribution 
becomes 
the 
final 
representation of MSF. Obtaining the MSF of each image, 
the comparison of two histograms is transferred to the 
comparison of two corresponding Markov chains. 
 
B. Adjacent Pixel Intensity Difference Quantization 
(APIDQ) 
The Adjacent Pixel Intensity Difference Quantization 
(APIDQ) histogram method [15] has been developed for 
face recognition previously. Figure 1 shows the processing 
steps of APIDQ histogram method.  In APIDQ, for each 
pixel of an input image, the intensity difference of the 
horizontally adjacent pixels (dIx) and the intensity 
difference of the vertically adjacent pixels (dIy) are first 
calculated by using simple subtraction operations shown as 
formula (6). 
 
( , )
)1
( ,
, )
(
( , )
)
,1
(
, )
(
I i j
I i j
i j
dIy
I i j
j
I i
i j
dIx
−
+
=
−
+
=
     
 
     (6) 
 
A calculated (dIx, dIy) pair represents a single vector in 
the dIx-dIy plane. By changing the coordinate system from 
orthogonal coordinates to polar coordinates, the angle θ  and 
the distance r represent the direction and the amount of 
intensity variation, respectively. After processing all the 
pixels in an input image, the dots representing the vectors 
are distributed in the dIx-dIy plane. The distribution of dots 
(density and shape) represents the features of the input 
image.  
Low-Pass Filtering (2-D Ave.)
Adjacent Pixel Intensity 
Differentiation (dIx, dIy)
Coordinates Change (r-θ)
Quantization
Histogram Generation
Input Image
APIDQ
 
 
Figure 1.   Processing steps of APIDQ histogram method. 
124
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

Each intensity variation vector is then quantized in the r-
θ  plane. Quantization levels are typically set at 8 in θ -axis 
and 8 in r-axis (totally 50). Since dIx-dIy vectors are 
concentrated in small-r (small-dIx, -dIy) region, non-
uniform quantization steps are applied in r-axis. The number 
of vectors quantized in each quantization region is counted 
and a histogram is generated. In the face recognition 
approach, this histogram becomes the feature vector of the 
human face.  
The essence of the APIDQ histogram method can be 
considered that the operation detects and quantizes the 
direction and the amount of intensity variation in the image 
block. Hence the APIDQ histogram contains very effective 
image feature information.  The MSF extends histogram 
based features with spatial structure information of images, 
and transfer the comparison of two histograms to two 
corresponding Markov chains.  
 
III. 
PROPOSED FACE RECOGNITION ALGORITHM 
A. Multi-resolution analysis 
Because different MSF-DQ features are extracted with 
different resolutions of the image, more comprehensive 
personal feature information can be obtained by combining 
multiple recognition results using multi-resolution analysis. 
In this paper, we employ multi-resolution analysis for the 
facial image to extract more powerful personal features. As 
shown in figure 2, after a set of multi-resolution pyramid 
images is generated using sub-sampling, MSF-DQ features 
at 
different 
resolution 
levels 
are 
extracted 
from 
corresponding pyramid images. Recognition results are first 
obtained using MSF-DQ features at different resolution 
levels separately and then combined by weighted averaging. 
B. Proposed algorithm 
The procedure of proposed face recognition algorithm 
using APIDQ histogram combined with MSF is shown in 
figure 3. Low-pass filtering is first carried out before 
APIDQ using a simple 2-D moving average filter. This low-
pass filtering is essential for reducing the high-frequency 
noise and extracting the most effective low frequency 
component for recognition. After multi-resolution pyramid 
images 
are 
generated 
using 
sub-sampling, 
APIDQ 
operations are implemented on respective images with 
different resolution and quantization region number 
corresponded to each 2x2 image block is calculated. 
Because each 2x2 image block can be regarded as a pixel of 
color
ic , the co-occurrence matrix for APIDQ can be 
computed according to formula (1).  
The Markov transition matrix P is calculated by formula 
(2). Then the stationary distribution can be approximated by 
the average of each row 
ia
→  of
n
A  using formula (7). 
 
∑
=
→
≈
K
i
ia
K
1
1 /
π
, where 
T
k
n
a
a
A
]
,
,
[
1
→
→
⋅⋅⋅
=
, 
     (7) 
 
)
1(
1
2
n
n
P
P
P
I
n
A
+
⋅⋅⋅
+
+
+
+
=
  
     (8) 
 
MSF-DQ 
feature (1)
MSF-DQ 
feature (2)
MSF-DQ 
feature (n)
Multi-resolution 
MSF-DQ features
High
Low
Resolution
 
Figure 2.   Multi-resolution MSF-DQ features. 
Facial Image
APIDQ
Co-occurrence matrix generation
Markov transition matrix generation
Initial and Stationary distribution 
calculation
Multi-resolution MSF-DQ features
Low-Pass Filtering (2-D Ave.)
Database Matching (MD)
Database
Recognition Result
Recognition
Registration
Multi-resolution pyramid images
 
Figure 3.   Proposed face recognition algorithm using multi-
resolution MSF-DQ features. 
125
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

  n =50 is used as same as in [19]. The initial distribution 
π (0)
 can be obtained by formula (4). As shown in formula 
(9), the Markov stationary feature is defined as the 
combination of the initial distribution 
π(0)
 and the 
stationary distribution π after n steps.  
 
T
hMSF DQ
[ (0), ]
π
π
=
−
→
 
 
 
     (9) 
 
We call MSF extension of APIDQ histogram as a MSF-
DQ feature. The MSF-DQ feature made from each pyramid 
image is compared with those from the same resolution 
images in the database by calculating distances (di) between 
them using the same distance calculation formula as in [19]. 
Then the integrated distances (D) are obtained by weighted 
averaging as shown in the following formula (10).   
 
       
∑
∑
=
i
i
i
w
w d
D
      
 
 
 
     (10) 
 
where wi is weighting coefficient of the different resolutions, 
The best match is output as recognition result by searching 
the minimum integrated distance. 
IV. 
EXPERIMENTAL RESULTS AND DISCUSSIONS 
A. Data sets 
The publicly available face database of AT&T 
Laboratories Cambridge [20] is used for the analysis and 
recognition experiments.  Forty people with 10 facial 
images each, (totaling 400 images), with variations in face 
angles, facial expressions, and lighting conditions are 
included in the database.  Each image has a resolution of 
92x112.  Figure 4 shows typical image samples of the 
database of AT&T Laboratories Cambridge.  From the 10 
images for each person, five were selected as probe images 
and the remaining five were registered as album images.  
Recognition experiments were carried out for 252 (10C5) 
probe-album combinations using the rotation method. 
B.  Experimental results 
Comparison of recognition results are shown in Figure 5.  
Recognition success rates are shown as a function of filter 
size.  The filter size represents the size of the averaging 
filter core.  A size of F3, for instance, represents the filter 
using a 3x3 filter core. Figure 5 shows the comparison 
between the recognition results using different resolution 
MSF-DQ features separately and multi-resolution MSF-DQ 
features. Average recognition rate is shown here. “bin 50 
(original DQ)” stands for the case that original APIDQ 
utilizes quantization table containing the number of bins of 
50 in [15][16]. “bin42_s92x112”,  “bin42_s46x56”, 
“bin42_s23x28”, and “bin42_s11x14” stand for the cases 
 
 
Figure 4. Samples of the database of AT&T Laboratories Cambridge.  
 
Figure 5.   Comparison of results. Average recognition rate is shown here. 
126
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

using various resolution MSF-DQ features separately. 
“bin42_Multiresolution” stands for the case using multi-
resolution MSF-DQ features proposed in this paper, which 
weighting coefficient at each resolution level is set as 1. 
The best performance of the average recognition rate 
97.16% [17][18] is obtained at original image size of 
92x112 when using separate single-resolution MSF-DQ 
features. By using multi-resolution MSF-DQ features with 
the weighting coefficient at each resolution level of 1, 
highest recognition rate increases to 98.16%. It can be said 
that multi-resolution MSF-DQ features is more robust than 
single-resolution MSF-DQ features. 
Figure 6 and 7 also show the results of using single-
resolution solely, and those of using some combinations. 
Maximum of the average recognition rate 98.57% is 
achieved at the combination of weighting coefficients of 
2:1:1:0 with the image resolutions of 92x112, 46x56, 23x28, 
11x14, respectively. It can be considered too small image 
resolution give less contribution for feature generation. 
V. 
CONCLUSION  
In this paper, we improved our face recognition using 
MSF-DQ feature by employing multi-resolution analysis for 
the facial image to extract more powerful personal feature. 
Excellent face recognition performance as large as a 98.57% 
recognition rate has been achieved by using the publicly 
available database of AT&T. It can be said that multi-
resolution MSF-DQ features is more robust for face 
recognition. 
ACKNOWLEDGMENT 
This research was partially supported by the Ministry of 
Education, Culture, Sports, Science and Technology of 
Japan, Grant-in-Aid for Scientific Research (C), No. 
24500104, 2012-2015, and also by research grant from 
Support 
Center 
for 
Advanced 
Telecommunications 
Technology Research, Foundation (SCAT). 
 
REFERENCES 
[1] R. Chellappa, C. L. Wilson, and S. Sirohey, “Human and 
machine recognition of faces: a survey,” Proc. IEEE, vol. 83, 
no. 5, 1995, pp. 705-740. 
[2] S. Z. Li and A. K. Jain, “Handbook of Face Recognition,” 
Springer, New York, 2005. 
[3] R. Brunelli and T. Poggio, “Face recognition: features versus 
templates,” IEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 15, no. 10, Oct. 1993, pp. 1042-1052. 
[4] L. Wiskott, J.M. Fellous, N. Kruger, and C. Malsburg, “Face 
recognition by elastic bunch graph matching,” IEEE Trans. 
Pattern Analysis and Machine Intelligence, vol. 19, no. 10, 
1997, pp. 775-780. 
 
Figure 6.   Comparison of results. Average recognition rate is shown here. 
 
 
Figure 7.   Comparison of results. Maximum average 
recognition rate is shown here. 
127
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

[5] M. Turk and A. Pentland, “Eigenfaces for recognition,” 
Journal of Cognitive Neuroscience, vol. 3, no. 1, Mar. 1991, 
pp. 71-86. 
[6] W. Zhao, “Discriminant component analysis for face 
recognition,” Proc. in the Int’l Conf. on Pattern Recognition 
(ICPR’00), Track 2, 2000, pp. 822-825. 
[7] K.M. Lam, H. Yan, “An analytic-to-holistic approach for face 
recognition based on a single frontal view,” IEEE Trans. 
Pattern Analysis and Machine Intelligence, vol. 20, no. 7, 
1998, pp. 673-686. 
[8] M.S. Bartlett, J.R. Movellan, and T.J. Sejnowski, “Face 
recognition by independent component analysis,” IEEE Trans. 
on Neural Networks, vol. 13, no. 6, 2002, pp. 1450-1464. 
[9] P. N. Belhumeur, J. P. Hespanha, and D. J. Kriegman, 
“Eigenface vs. Fisherfaces: Recognition using class specific 
linear projection,” IEEE Trans. Pattern Analysis and Machine 
Intelligence, vol. 19, May 1997, pp. 711-720. 
[10] B. Moghaddam, A. Pentland, “Probabilistic visual learning 
for object representation,” IEEE Trans. Pattern Analysis and 
Machine Intelligence, vol. 19, no. 7, 1997, pp. 696–710. 
[11] S. G. Karungaru, M. Fukumi, N. Akamatsu, “Face recognition 
in colour images using neural networks and genetic 
algorithms,” Int’l Journal of Computational Intelligence and 
Applications, vol. 5, no. 1, 2005, pp. 55-67. 
[12] Z. Liu, C. Liu, “Fusion of color, local spatial and global 
frequency 
information 
for 
face 
recognition,” 
Pattern 
Recognition, vol. 43, Issue 8, Aug. 2010, pp. 2882-2890. 
[13] H. F. Liau, K. P. Seng, L. M. Ang, and S. W. Chin, “New 
Parallel Models for Face Recognition,” Recent Advances in 
Face Recognition, Edited by K. Delac etc., InTech,  2008. 
[14] Q. Chen, K. Kotani, F. F. Lee, and T. Ohmi, “Face 
Recognition Using VQ Histogram in Compressed DCT 
Domain,” Journal of Convergence Information Technology, 
vol. 7, no. 1, 2012, pp. 395-404. 
[15] K. Kotani, F.F. Lee, Q. Chen, and T. Ohmi, “Face recognition 
based on the adjacent pixel intensity difference quantization 
histogram method,” 2003 Int’l Symposium on Intelligent 
Signal Processing and Communication Systems, D7-4, 2003, 
pp. 877-880. 
[16] F. F. Lee, K. Kotani, Q. Chen, T. Ohmi, “Face Recognition 
Using Adjacent Pixel Intensity Difference Quantization 
Histogram,” Int’l Journal of Computer Science & Network 
Security, vol. 9, no. 8, 2009, pp. 147-154. 
[17] F. F. Lee, K. Kotani, Q. Chen, T. Ohmi, “A Robust Face 
Recognition Algorithm Using Markov Stationary Features 
and Adjacent Pixel Intensity Difference Quantization 
Histogram,” Proc. in 7th Int’l Conf. on Signal Image 
Technology & Internet Based Systems (SITIS 2011), France, 
2011, pp. 334-339. 
[18] F. F. Lee, K. Kotani, Q. Chen, T. Ohmi, “Face Recognition 
Using Adjacent Pixel Intensity Difference Quantization 
Histogram Combined with Markov Stationary Features,” Int’l 
Journal of Advancements in Computing Technology, in press. 
[19] J. Li, W. Wu, T. Wang, and Y. Zhang, “One step beyond 
histograms: Image representation using Markov stationary 
features,” Proc. in the IEEE Conference on Computer Vision 
and Pattern Recognition (CVPR’08) , 2008, pp. 1-8. 
[20] AT&T Laboratories Cambridge, The Database of Faces, at 
http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.
html. 
[21] P. J. Phillips, H. Wechsler, J. Huang, & P. Rauss. “The 
FERET database and evaluation procedure for face 
recognition algorithms,” Image and Vision Computing J, vol. 
16, no. 5, 1998, pp. 295-306. 
 
 
 
 
 
128
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

