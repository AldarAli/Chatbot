Developing Evaluation Matrix of Digital Library Interface by Analyzing Bloopers of 
Korean National Digital Library Sites 
 
Miah Kam, Jee Yeon Lee 
Department of Library and Information Science 
Yonsei University 
Seoul, South Korea 
makiyma@hanmail.net, jlee01@yonsei.ac.kr 
 
 
Abstract— The importance of digital libraries is increasing 
with the advancement and proliferation of networked online 
services. This work in progress focuses on developing an 
evaluation model for analyzing the real-world cases. Firstly, 
the web bloopers of the Korean digital libraries were identified, 
then heuristic evaluations were applied to categorize the 
bloopers into five types, which occur in three main components 
of the digital libraries. The resulting evaluation matrix consists 
of one axis for the web blooper types and the other for the 
digital library components. Each matrix cell has different 
weighting derived from the heuristic evaluation of the digital 
libraries in service. Digital library developers, managers, and 
subject matter experts should be able to consult the evaluation 
matrix to improve the usability and accessibility of their 
libraries. Our digital library evaluation matrix, based on the 
heuristic evaluation model, should raise the efficiency of digital 
library user interface evaluation. 
Keywords-Digital Library User Interface; Library Service 
Components; Web Bloopers; Heuristic Evaluation; Evaluation 
Matrix. 
I. 
 INTRODUCTION 
The advancement of information technology enabled 
ordinary people to browse and access online library 
resources with ease. This new mode of access caused 
fundamental changes in library user behavior.  
Users often visited physical libraries to get the 
information they needed, but today, more users with 
information technology exposures, initially access digital 
libraries before visiting physical libraries [1][2][3]. In 
addition to many obvious advantages, the ubiquitous access 
to digital libraries reinforced its use and importance as a de 
facto source of information. 
Previous studies found usability, especially interface 
usability, to be one of most important factors in 
understanding user satisfaction with digital libraries. Xie [4] 
found that ‘interface usability’ was the most important factor 
in assessing digital library user satisfaction. Hernon and 
Calvert [5] also claimed that ‘ease of use’ was one of the 
most significant factors in measuring e-service quality. 
Indeed, many digital library-related studies focused their 
research on the user interface aspect of libraries, such as 
Liew [6]. Hariri and Norouzi [7] classified digital library-
related topics into 3 groups: (1) user interface and digital 
libraries, (2) digital libraries and usability, and (3) other 
studies related to user interface. However, these studies did 
not provide concrete guideline on how to develop or improve 
the digital library interfaces. To fill this gap, our aim is to 
develop a digital library blooper matrix that can be applied 
easily by practitioners to improve the interfaces of their 
digital libraries. 
The term blooper, which refers to a silly mistake, was 
introduced by Jeff Johnson [8] in 2000 to describe his 
finding of problematic user interfaces. He conceptualized the 
Graphical User Interface (GUI) and web bloopers as 
mistakes, that are committed frequently in designing the 
interface and consequently influence usability. Web bloopers 
are often used as a checklist, which guides what not to do in 
detail and helps managers to improve interface efficiently 
and effectively. Web bloopers are closely related to the 
heuristics evaluation method, which was introduced by 
Nielsen and Molich [9]. Both methods use a checklist to 
identify usability problems. The heuristics evaluation method 
is “a method of reviewing the usability of software to find 
potential problems. Reviewers go through the software 
systematically with a list of UI design guidelines in hand, 
noting places where the software’s UI violates the 
guidelines” [8]. Web bloopers show real-world examples of 
what not to do in the interfaces and, thus, it is possible to 
simulate the heuristics evaluation by counting how many 
problematic features exist. 
The concept of web bloopers has not yet been fully 
examined in the academic community, although this concept 
has great research potential. Only some studies mention web 
bloopers [10][11], because this concept is firstly written for 
the practitioner’s community. It is difficult to find digital 
library related studies that use web blooper related ideas to 
either evaluate or implement the interfaces. Thus, our work 
in progress attempts to determine whether the use of web 
bloopers can effectively improve digital library user 
interfaces. 
The Korean digital libraries became more accessible and 
interactive for users with the advancement of the digital 
information technology. Although digital libraries place 
greater concern on the searching and full-text viewing related 
problems than other web services, libraries share many 
common usability requirements with other services. In this 
study, the practical notion of web bloopers was combined 
39
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

with the examination of the digital library specific usability 
issues to evaluate the Korean digital libraries’ interfaces. 
The aims and method of this research are as follows. 
Firstly, we inductively generate web blooper types and 
digital library components by analyzing the operational 
Korean national digital libraries such as ‘Dibrary of the 
National Library of Korea’, ‘The National Assembly Digital 
Library’ and ‘The National Library for Children and Young 
Adults’. Secondly, we develop a digital library blooper 
matrix with the web blooper types and digital library 
components. Finally, we develop a digital library user 
interface evaluation matrix based on the heuristics evaluation. 
In Section II, five cases of the actual web bloopers were 
shown. In Section III, we discovered bloopers and 
components which are divided into two axes. In Section IV, 
we developed an evaluation matrix by using the evaluation 
model and assigning weightings. Finally, in Section V, we 
concluded this work to show contributions, applicable area, 
limitations and potential future works. 
II. 
CASE ANALYSIS  
Three Korean national digital library sites were analyzed 
and over 260 web bloopers were found. The web bloopers 
were categorized into five groups according to their 
characteristics considering simplicity of errors, the amount of 
information and convenience of use. This categorization 
were used to evaluate usability regarding user interface 
design.  
A. Case 1 - User Support and Purpose of Operation 
The blooper shown in Figure 1 was from the Online 
Archiving & Searching Internet Sources (OASIS) [12] site of 
the National Library of Korea. This site behaves differently 
for different web browsers. The ‘Back’ button does not work 
when viewing the site via Internet Explorer (IE): however, it 
works when viewing via Google Chrome. This kind of 
inconsistency is an example of what can go wrong in the 
‘general website’ component of the digital libraries.  
 
 
Figure 1.  A web blooper of ‘User Support and Purpose of Operation’. 
B. Case 2 – System Menu and Navigation 
The blooper shown in Figure 2 was found in the 
Government General Gazette of the Chosun [13] site of the 
National Library of Korea. Selection of one of the search 
results did not always produce the expected outcome. 
Unselected results sometimes showed up or nothing showed 
up at all. This can be regarded as a navigation problem and 
an example of what can go wrong in the full-text viewing 
component of digital libraries.  
 
 
Figure 2.  A web blooper of ‘System Menu and Navigation’. 
C. Case 3 - Motion and Interaction 
This web blooper of Figure 3 occurred in the Dibrary 
[14], which is the digital library for the National Library of 
Korea. There was a problem with the checkboxes, which 
limited the search scope to a specific resource type. The 
checkboxes were under the main search menu. It was not 
possible to uncheck the boxes unless the user selected 
another checkbox. This probably occurred as the checkboxes 
were implemented as radio buttons. This problem occurred 
in the ‘general website’ component. 
 
 
Figure 3.  A web blooper of ‘Motion and Interaction’. 
D. Case 4 - Information Provision 
The case in Figure 4 was also gathered from the Dibrary 
[14] site. In the federated search, which targeted resources on 
other sites, only the top five results were shown for each site. 
To see the lower ranked results, users had to go to the 
corresponding external site. This problem was categorized to 
occur in the ‘searching and search results’ component. 
 
 
Figure 4.  A web blooper of ‘Information Provision’. 
 
 
 
40
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

E. Case 5 - Visual design 
The web blooper shown in Figure 5 was yet another case 
from the Dibrary [14] site. For the subject category search, it 
was difficult to tell which one was selected, as none of the 
icons or the font colors of descriptions’ changed, even when 
the user’s mouse pointer was on a specific subject 
description. This was a visual design problem, and it 
occurred in ‘searching and search results’ component. 
 
 
Figure 5.   A web blooper of ‘Visual design’. 
There are also various other cases of web bloopers on 
Korean national digital library sites. By categorizing these 
bloopers and identifying corresponding digital library 
components where the bloopers were found, an evaluation 
matrix with two axes was developed. 
III. 
DISCOVERING BLOOPERS AND COMPONENTS  
A. Axis  1 – Bloopers Types 
Based on the analysis of the discovered bloopers, the 
bloopers were categorized into five types: 1) User Support 
and Purpose of Operation, 2) System Menu and Navigation, 
3) Motion and Interaction, 4) Information Provision, and 5) 
Visual Design. These types are similar to the ones used by 
Jeff Johnson [15][16]. Each type in turn was further divided 
to reflect the finer understanding of the bloopers. A brief 
description of five blooper types and the further divided sub 
types are as follows: 
1) User Support and Purpose of Operation: supporting 
users, language, customization and browser; 
2) System Menu and Navigation: clearance of navigation, 
structure and location path; 
3) Motion and Interaction: matter of overlapped link, link 
motion, form, loading speed, system feedback; 
4) Information Provision: related to relative link, 
consistency, relevance, recency, and understandability; and 
5) Visual Design: icon, color, image, font and layout. 
B. Axis  2 – Digital Library Components 
By conducting a literature review [15][16] and analyzing 
ten prominent websites of libraries and information centers, 
three digital library components were identified: 1) general 
website, 2) full-text viewer, and 3) searching and search 
results. 
IV. 
DEVELOPING EVALUATION MATRIX  
A. Evaluation Model 
The resulting matrix of Table 1 consists of five blooper 
types (22 subtypes) and three library components. The 
second and third stages of Jakob Nielsen’s Heuristic 
Evaluation [17] were used to develop a weighted evaluation 
table. The five phases of Heuristic Evaluation were: 1) pre-
evaluation 
training: 
give 
evaluators 
needed 
domain 
knowledge and information on the scenario, 2) evaluation: 
individuals evaluate user interface and make a list of 
problems, 3) severity rating: determine how severe each 
problem is, 4) aggregation: group meets and aggregates 
rating, and 5) debriefing: discuss the outcome with the 
design team. 
TABLE I.  
WEIGHTED BLOOPER EVALUATION MATRIX OF DIGITAL 
LIBRARY INTERFACE. 
 
Digital Library 
Components(DLC) 
Blooper 
Type 
Blooper 
 Subtype 
DLC
1)a 
DLC
2)b 
DLC
3)c 
Type 1) 
User Support 
and Purpose 
of Operation 
 
1)-1 : Users 
 
 
 
1)-2: Language 
 
 
 
1)-3: Customizing  
 
 
 
1)-4 : Browser 
 
 
 
Type 2) 
System 
Menu and 
Navigation 
2)-1 : Navigation 
 
 
 
2)-2 : Structure 
 
 
 
2)-3 : Location path 
 
 
 
Type 3) 
Motion and 
Interaction 
3)-1 : Overlapped link 
 
 
 
3)-2 : Link motion 
 
 
 
3)-3 : Form 
 
 
 
3)-4 : Loading speed 
 
 
 
3)-5 : System feedback 
 
 
 
Type 4) 
Information 
Provision 
4)-1 : Relative link 
 
 
 
4)-2 : Consistency 
 
 
 
4)-3 : Relevance 
 
 
 
4)-4 : Recency 
 
 
 
4)-5: Understandabability 
 
 
 
Type 5) 
Visual 
Design 
5)-1 : Icon 
 
 
 
5)-2 : Color 
 
 
 
5)-3 : Image 
 
 
 
5)-4 : Font 
 
 
 
5)-5 : Layout 
 
 
 
a. Digital Library Component 1), General website 
 b. Digital Library Component 2),  Full-text viewer 
c. Digital Library Component 3), Searching and search results 
 
41
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

B. Weights 
Each cell is colored differently to show different weights. 
The weights were assigned not just by counting the 
frequency of specific bloopers but also to reflect the needs of 
digital library sites. This should allow evaluators to refer to 
the matrix easily and efficiently when evaluating the 
interfaces. There are three levels in weighting. The most 
frequently occurring blooper types in a component with high 
importance are dark colored. The problem, which occurs on 
this level, should be fixed as soon as possible. Light gray-
colored cells refer to less serious problems but with higher 
frequency of occurrence than the white-colored cells. The 
white-colored cells refer to general bloopers with lesser 
impact on the interface’s usability than the light gray ones. In 
summary, these weightings was assigned by considering the 
seriousness of each observed example. The resulting matrix 
is as shown in Table 1. 
V. 
CONCLUSTIONS AND FURTHER WORK 
A. Contribution 
The evaluation matrix should be used for assessing the 
usability of the digital library interfaces. As the matrix was 
developed by analyzing the sites in service, it should be also 
applicable to the real-world cases by the developers and 
managers of the digital libraries.  
Most of the existing web bloopers were about general 
web sites and no special attention was paid to the 
particularities of the digital libraries. Thus, our digital 
library-specific evaluation matrix based on the heuristic 
evaluation model should raise the efficiency of digital library 
user interface evaluation. 
B. Applicable area 
The evaluation matrix can also be used as an evaluation 
tool of various general websites. Although the development 
started with the national digital library sites, this matrix 
should be applicable in various areas, because it is composed 
with combinations of essential elements of websites and 
critical web bloopers. This can be used in evaluating web 
sites such as search engines, and educational websites which 
need to be checked continuously to ensure the usability.  
C. Limitations & future work 
Although it was possible to find 260 web bloopers, the 
resulting evaluation matrix was only based on three Korean 
national digital libraries. Thus, it is not possible for us to 
claim strong reliability of the research outcome. Thus, 
additional digital libraries, especially in countries other than 
Korea, will be analyzed to augment the current evaluation 
matrix.  
The resulting evaluation matrix with one axis of five web 
bloopers types and the other of three digital library 
components makes 15 cells and 66 cells when we further 
categorized the blooper types. In the future, each digital 
library component will be re-examined to check the benefit 
of further dividing each component. In addition, examples 
and explanations will be added to each cell to further assist 
the users of the evaluation matrix. 
 
REFERENCES 
[1] S. Joo, J. Lee, “Measuring the usability of academic digital 
libraries: Instrument development and validation,” The 
Electronic Library, vol. 29 issue 4, 2010, pp. 523-537. 
[2] I. Xie, "Users' evaluation of digital libraries (DLs): Their uses, 
their criteria, and their assessment," Information Processing 
and Mangement, vol. 44, 2008, pp. 1346-1373. 
[3] J. Hwang and E. Lee, “Development of service quality 
measurement model and index for digital libraries”, Journal of 
Korean Library and Information Science Society, vol. 41 
issue 1, March. 2010, pp. 121-147. 
[4] I. Xie, "Evaluation of digital libraries", Library & Information 
Science Research, vol. 28, 2006, pp. 433-452. 
[5] P. Hernon and T. Calvert, “E-service quality in libraries: 
Exploring 
its 
features 
and 
dimensions”, 
Library 
& 
Information Science Research, vol. 27 issue 3, 2005, pp. 377–
404. 
[6] C. L. Liew, “Cross-cultural design and usability of a digital 
library supporting access to Maori cultural heritage 
resources,” Victoria University of Wellington: New Zealand, 
2008. 
[7] N. Hariri and Y. Norouzi, “Determining evaluation criteria for 
digital libraries' user interface: a review”, The Electronic 
Library, vol. 29 issue 5, 2011, pp. 698-722. 
[8] J. Johnson, “GUI Bloopers: Don’ts and do’s for software 
developers and web designers,” San Francisco, CA: Morgan 
Kaufmann Publishers, 2000. 
[9] J. Nielsen and R. Molich, “Heuristic evaluation of user 
interfaces,” In Proceedings of ACM CHI’90 Conference on 
Human Factors in Computing Systems, 1990,  pp. 249-256. 
[10] J. Cappel James and Z. Huang, "A usability analysis of 
company websites," Journal of Computer Information 
Systems, vol. 48 issue 1, September. 2007, pp.117-123. 
[11] M. Shelstad, “Content matters: analysis of a website redesign”, 
OCLC Systems & Services, vol. 21 issue 3, 2005, pp. 209-
225. 
[12] OASIS,  <http://www.oasis.go.kr/ctrlu?cmd=main> 
2014.12.28 
[13] Government General Gazette of Chosun, <http://gb.nl.go.kr> 
2014.12.28 
[14] Dibrary, <http://www.dibrary.net> 2014.12.28 
[15] J. Johnson, “Web bloopers: 60 common web design mistakes, 
and how to avoid them,” Morgan Kaufmann; 1 edition, April. 
2003.  
[16] J. Johnson, “GUI Bloopers 2.0, second edition: common user 
interface design don'ts and dos,” San Francisco, CA: Morgan 
Kaufmann Publishers; 2nd edition, September. 2007. 
[17] J. Nielsen, “Heuristic evaluation,” in Nielsen, J. and Mack, R. 
L, Eds. New York: John Wiley and Sons, 1994.
 
42
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-382-7
ACHI 2015 : The Eighth International Conference on Advances in Computer-Human Interactions

