Sensory Evaluation Method to Create Pictograms  
Based on Multiplex Sign Languages  
 
Naotsune Hosono 
Keio University, 
Oki Consulting Solutions 
Tokyo, Japan 
Hosono903@oki.com 
 
Hiromitsu Inoue 
Chiba Prefectural University 
of Health Sciences, 
Chiba, Japan 
Abstract— This paper discusses a method to create pictograms 
based on multiplex local sign languages with applying the 
concept of “Context of Use” on dialogue with applying 
Multivariate Analysis (MVA). Since pictograms are universal 
communication tools, human centred design (HCD) and 
context analysis by Persona model are applied. The 
experiments consist of three steps. The first step is to find out 
the similarity of a selected word among seven different local 
sign languages, which are American, British, French Spanish, 
Japanese, Korean and Chinese by means of MVA. The second 
step is to create a new common pictogram referring to the first 
step result by a pictogram designer. The final step is to validate 
the newly created pictogram by MVA. Under the cycle of HCD, 
the pictogram designer will perform to summarize the 
expression of several local sign languages by this method. The 
acquisition of this experience is to include it as a pictogram 
design guideline for context of universal communications such 
as emergency and traveling situations. Through the proposed 
method, the relationship between selected words and local sign 
languages are initially explained by sensory evaluation of the 
subjects. Currently the outcome of pictograms or icons of this 
experiment are implemented on the modern tablet computers 
with a touch panel display considering computer-human 
interactions. 
Keywords- Context of Use; Human Centred Design; 
Pictogram; Universal Communication; Sensory Evaluation. 
I. 
 INTRODUCTION  
This paper discusses a method to create pictograms or 
icons referring to multiplex local sign languages with the 
concept of context of use on dialogue and Multivariate 
Analysis (MVA) [1]. Since pictograms or icons are universal 
communication tools, Human Centred Design (HCD) [2] and 
context analysis by Persona model by Alan Cooper [3] are 
applied in this research. This research was started in order to 
investigate the context of universal communication through 
local sign languages. 
HCD is based on the context of use which is organized 
by four factors as user, product, task and environment in use 
(Figure 1). The research scope covers not only linguistic 
studies of sign language but also HCD with context of use 
[4]. 
The structure of this paper is that at first section the 
research purpose with deaf people issues in the case of 
emergency is introduced. Then simple and easy to use 
pictograms or icons are to be required as an efficient 
communication tool. In the middle sections to find out such 
pictograms or icons applying sensory evaluation method is 
discussed. The validity of the newly created pictograms or 
icons is discussed in the final section.  
II. 
RESEARCH PURPOSE AND ISSUES  
The purpose of this research is to figure out a method to 
create meaningful pictograms or icons referring to several 
local sign languages [5]. The sign language (SL) is basically 
a communication method from one person to the other for 
hearing impaired persons. The main factors of sign language 
consist of the hand shape, location and movement. There is a 
dilemma that SL is a language with motion whereas 
pictograms or icons are still ones. There was quite a 
discussion among researchers. Then hand shapes and 
locations are drawn by an animation and movements are 
done by arrows referring to a snapshot of the related local 
sign languages. 
III. 
RESEARCH PROCEDURES 
Considering such research purpose and issues, the 
following three steps with seven phase research procedures 
are prepared; 
Step1:  
Phase 1:  Determine a concept 
Phase 2:  Create Persona Model and its Scenario 
Phase 3:  Key words extraction especially on emergency 
and travelling situations 
Phase 4:  Conduct first Sensory Evaluation with seven 
local sign languages to extract similarities. 
Step 2: 
Phase 5:  Design a summarized pictogram referring to the 
result above. 
Step 3:  
Phase 6:  Conduct second Sensory Evaluation with seven 
local sign languages adding a summarized pictogram to 
validate 
Phase 7:  Conclude a method  
 
A. Phase 1: The Context Determination  
Based on the concept described above, two context 
situations of emergency or travelling have initially been 
chosen [6]. Alan Cooper proposed the Persona Model [3] 
related to HCD where several situation representing Personas 
are imaginably created in order to simulate and find how 
they will behave under a certain context. This method is 
highly accepted by the manufacturers in creating new 
13
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

product plans and has been applied to service science [7]. 
B. Phase 2: Persona Model and Scenario Creation  
The first step is to create two Personas with applying the 
Persona Model under HCD [2]. The first Persona is a deaf 
person in a situation where he suffers a sudden illness while 
commuting in the morning, and is carried to the hospital by 
an ambulance (Figure 2). The second one is an office lady 
who lives in Hong Kong and has to visit Tokyo on business 
and then pleasure. 
Diary like scenarios underlying Personas are described 
from discussions with colleagues utilizing the Brain 
Storming Method. These scenarios mainly pay attention to 
the dialogues between the Persona and those people 
surrounding [8]. The first scenario of the deaf person in an 
emergency consists of about 600 words (equivalent to 3000 
Japanese characters) and second with the traveling woman 
about 1700 words (equivalent to 8500 characters). 
C. Phase 3: Key words extraction on situations  
This research is focused upon dialogues with several 
participants and referring to observations from the view 
point of the provider and the receiver under dialogue 
principle [8]. 
The next phase is to extract words that are 
fundamentally essential to the dialogues of the scenarios. 37 
words were selected and categorized by discussions with 
colleagues. 
Looking at the dialogues in the scenarios under the 
selected context, the hardest process is initiating the 
dialogue to a stranger. In modern times, people are worried 
about security. They are extremely cautious when 
approached by an unfamiliar person. Several interjections 
are included to assist the initiation of dialogues. 
D. Phase 4: First Sensory Evaluation with seven local sign 
languages  
The research is initially focused upon creating 
pictograms or icons to make dialogues since the 
fundamentals of sign language are hand shape, location and 
movement. This research references to a collection of 
animation figures consists of seven local sign languages 
whose author is a deaf architect, gave overwhelming support 
to the research by supplying and permitting reference to the 
database. The seven local sign languages are of American, 
British, Chinese, French, Korean, Japanese, and Spanish [9].  
In the experiment, subjects are first shown an expression 
with the collection of animation figures consists of seven 
local sign languages. After then subjects are informed of the 
sign meaning, they are requested to vote with 19 tokens 
which of the seven different local sign language expressions 
(samples) best coincides with the informed image. They are 
asked to put all 19 tokens on the condition that they are 
permitted eventually zero voting on some samples. 
 
 
Figure 2. An example of Persona model 
 
 
Profile
 Communication methods are Sign Langue, Lip Reading. Write Message is used  when 
complicated.
–
Write message is particularly used  in a convenience store, a gas station or a 
coffee shop.
–
Write on the palm without tools of writing.
 Parents will support when emergency.
–
By using mobile mail to the parents with explaining the situation, then ask 
parents to contact to colleagues or insurance company.
–
Telephone can not be used to call an ambulance or police station.
 Write message or gesture are used when consulting with medical doctors.
–
Ask repeatedly by write message when the explanations by the doctor or 
nurse are complicated.
–
Lip reading is not useful since they wear face guard mask.
–
Normally at the first visit to hospital , a sign interpreter will be accompanied.
 Always prepare tools of writing for the accidents or disaster.
 Mobile mile is daily used.
Goal
 Wish to inform current status or wish precisely.
 Wish to understand of the antagonist dialogue.
 Wish to use a simple and easy communication method when emergency.
Personal Profile
 Occupation：SE
 Address：Tokyo, Japan
 Age：24
 Characters：Cheerful, precise and 
friendly
 Symptom： Adult Deafened
Mobile usage situation
 Mobile Phone
‒Daily used
‒Mobile mail and Internet
‒Internet sites are Routing 
or weather forecasting 
 Other used functions
‒Digital Camera
Takuya  Kobayashi
“Try to communicate with all methods”
 Adult Deafened
 Friendly Character
 Identity for deaf
SCOPE
Persona A
Figure 1. Context of use of Guidance on usability 
 
Users
Tasks
Equipment
Environment
Input
Output
Effectiveness
Efficiency
Satisfaction
Foreign People
Impaired People
In use at 
Station, Airport
Ambulance, Hospital
Communication Service
Collaboration Service
Travelling
Emergency
 
S
A
J
F
C
U
K
E
Abbreviations: 
 
A: American Sign 
Language (ASL) 
J: Japanese Sign 
Language (JSL) 
F: French Sign 
Language (FSL) 
C: Chinese Sign 
Language (CSL) 
B: British Sign 
Language (BSL) 
K: Korean Sign 
Language (KSL) 
E: Spanish Sign 
Language (SSL) 
S: Summarized and 
newly designed 
pictogram 
Figure 3. A sample of voting sheet of 
“When ?” 
14
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

This sensory evaluation method can easily make relative 
comparisons between the seven expressions of local sign 
languages and is more applicable than the ordering method 
or pair comparison method. An example of voting sheet of 
“When ?” with local sign languages is shown in Figure 3 
except the pictogram “S”. 
Then the correspondence analysis of Multivariate 
Analysis (MVA) by statistic software; Statistical Package 
for Social Science (SPSS) [10, 11] is applied. The outcome 
is plotted as similar local sign languages are to be plotted 
closely on a plane. In the characteristics of correspondence 
analysis, the subjects who have general and standard ideas 
are positioned in the centre, whereas those who have 
extreme or specialized ideas are positioned away from the 
centre. The center crossing point of the first and second 
Eigenvalues is gravity point or average point.  
The first experiment subjects are 13 people in their 20’s 
including nine science course students, four humanity 
course students. Some have experience living overseas and 
sign language interpreting. After voting by the tokens, all 
the subjects are asked of their confidence level with  
Semantic Differential (SD) method [12]. 
Figure 4 is an example of outcome chart where 
“When ?” is plotted. 
E. Phase 5: Summarized Pictograms Design  
Analyzing a plot chart of “When ?” in Figure 4 with 
seven sign languages, many subjects feel that French, 
American, British and Spanish sign languages are 
representing similarly “When ?” since they are plotted 
closely on the chart.  
Following to the cycle process of HCD, the original 
designer is asked to summarize and design an animation like 
ictogram showing exclusively French, American, British 
and Spanish by referring to the outcome by the sensory 
evaluation mentioned above. Then the newly designed 
pictogram, which is “S” in Figure 3, is added to seven local 
sign languages with American, British, Chinese, French, 
Korean, Japanese, and Spanish. 
F. Phase 6: Second Sensory Evaluation with seven local 
sign languages with summarized pictogram  
The next procedure is the same manner as the first 
experiment of Phase 4. After subjects are informed of the 
sign meaning, this time they are requested to vote with 23 
tokens which of the eight different local sign language 
expressions including newly designed one which is a 
pictogram “S” in Figure 3 will be the best coincides with 
their image. The procedure was the same manner as the first 
sensory evaluation step of phase 4, and the correspondence 
analysis of Multivariate Analysis (MVA) by SPSS is once 
again performed. The outcome including the newly 
designed pictogram is plotted with other seven local sign 
languages in order to prove and measure whether the newly 
created pictogram represents of the cluster.  
The second experiment subjects are 20 engineering 
department students in their 20’s including two female 
students. Almost all except three are different subjects from 
the first experience. After voting by the tokens, all the 
subjects are again asked of their confidence level with 
Semantic Differential (SD) method. 
Figure 5 is an example of outcome chart where 
“When ?” is plotted. Comparing Figure 4 with Figure 5, 
Figure 5 is plotted under uncertainty for factor rotation. The 
newly designed one will represent French, American, 
British and Spanish sign languages since it is plotted close 
Figure 4. A plot of “When ?” with seven sign languages. 
 
Dimension 
2
Dimension 1
 
When?
Dimension 2
Dimension 1
Figure 5. A supplementary treatment plot chart of 
 “When ?” with eight sign languages 
15
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

to those sign languages. Whereas Japanese, Korean, and 
Chinese plotted further down.  
In order to prove the outcome, Supplementary Treatment 
of MVA by SPSS is applied with adding newly designed 
one to the seven sign languages. These deployments of the 
plots are similar in seven and eight sign languages 
experiments. 
G. Phase 7: Conclude the Method  
Through the experience of the first Sensory Evaluation 
with seven local sign languages of 37 words, many sign 
language expressions are identified by representing the 
meaning. Among them the most converged seven words of 
“when?”, “good-by”, “When ?”, “thank you”, “where?”, 
“toilet”, and “expensive” among 37 are selected by means 
of brain storming.  
Comparing two outcomes of Phase 4 (Figure 4) with 
seven local sign languages and of Phase 6 (Figure 5) with 
eight local ones, followings are concluded. 
- 
Selected 
seven 
newly 
designed 
animation 
pictograms are all positioned in the centre of the 
related local sign languages cluster. 
- 
Even though almost of the subjects are different at 
the first and second experiment, the general 
outcome plot patterns hold similar patterns in space. 
- 
In western sign languages of French, American, 
British and Spanish tend to be plotted closely 
together. 
 
IV. 
CONCLUSION AND FUTURE WORK 
This paper discusses a method to extract the summarized 
expression of several local sign languages in order to draw 
pictograms or icons by applying the sensory evaluation with 
MVA. The experiments consist of three steps.  
The first step is to find out a pictogram is a majority 
common expression upon a word among seven local sigh 
languages. Looking at the first step, this method looks valid 
in practice since French and American sign languages are 
similar by historical background, and in fact and they are 
plotted close to each other. The second step is to prove the 
characteristics of the pictogram represent the meaning of the 
word. The final step is to validate the newly created 
pictogram by MVA. Almost all of the newly designed 
pictograms positioned in the centre of the cluster then it is 
representative of the clusters.  
In the example of “When ?” among seven sign languages, 
analyzing by the Supplementary Treatment of MVA, the 
newly designed pictogram will be representing French, 
American, British and Spanish sign languages since it is 
plotted close to those sign languages on the plane. 
Currently the outcome of pictograms or icons of this 
experiment are implemented on the modern tablet computers 
with a touch panel display considering computer-human 
interactions. 
 
V. 
DISCUSSIONS 
Through the proposed method, the relationship between 
selected words and local sign languages are initially 
explained by sensory evaluation by the subjects. Under the 
cycle of HCD, the pictogram designer will perform to 
summarize the expression of several local sign languages by 
this method. The acquisition of user experience is to include 
it as a design guideline for instance of the context of 
emergency and traveling situations.   
The issues are that the quality of the newly designed 
pictogram depends on the designer’s ability to summarize 
several ones. The newly designed pictograms are still biased 
by sign languages in this research in order to become much 
easier communication tool, and require further improvement 
to simplify and easily to understand for everybody.   
Considering the results of the second experienced phase 
to prove the outcome design by Supplementary Treatment of 
SPSS, the proposed method is one of the guidelines to create 
pictograms by referring to several sign languages. 
 
ACKNOWLEDGEMENT 
A collection of local sign language database is supplied 
and permitted for research use by Mr. M. Akatsuka of 
Architectural Association of Japanese DEAF (AAJD) as well 
as Mr. M. Suzuki who is a deaf architect and proposed idea.  
 
REFERENCES 
 
[1] Hosono, N., Inoue, H., Tomita Y.: Sensory analysis method 
applied to develop initial machine specification, Measurement, 
vol. 32, pp. 7-13 (2002). 
[2] International Organization for Standardization: ISO9241-210 
(former 13407:1999), Ergonomics Human-centred design 
processes for interactive systems (2010). 
[3] Cooper A.: About Face 3, Wiley (2007). 
[4] Miki H., Hosono, N.: Universal Design with Information 
Technology (Japanese version), Maruzen (2005). 
[5] Horton W.: The Icon Book, John Wiley & Sons, Inc. (1994). 
[6] International Organization for Standardization: ISO9241-11, 
Ergonomic requirements for office work with visual display 
terminals (VDTs), Guidance on usability (1998). 
[7] Hosono N., Miki H., Suzuki M., Tomita Y., Urgent 
Collaboration Service for Inclusive Use, HCII2009, in CD-
ROM (2009). 
[8] International Organization for Standardization: ISO9241-110, 
Ergonomic requirements for office work with visual display 
terminals (VDTs), Dialogue principles (2006). 
[9] Akatsuka, M.: Seven sign languages for tourists: Useful 
words and expressions, Chinese-Japanese-American Working 
Group (2005). 
[10] Field, A.: Discovering Statistics Using SPSS 3rd edition, Sage 
Publications (2009). 
[11] SPSS: Categories in Statistical Package for Social Science 
ver.18, SPSS (2009). 
[12] Hosono N., Inoue H., Miki H., Suzuki M., Nagashima Y., 
Tomita Y., Yamamoto S., Service Service Method to create 
Pictograms referring to Sign Languages, HCII2011, in CD-
ROM (2011). 
 
16
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-250-9
ACHI 2013 : The Sixth International Conference on Advances in Computer-Human Interactions

