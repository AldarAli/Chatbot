A Walking Aid Integrated in a Semi-Autonomous Robot Shopping Cart
Hermann Kaindl, Bernhard Putz, Dominik Ertl
Vienna University of Technology
Institute of Computer Technology
Vienna, Austria
(kaindl, putz, ertl)@ict.tuwien.ac.at
Helge H¨uttenrauch, Cristian Bogdan
Royal Institute of Technology
School of Computer Science
Stockholm, Sweden
(hehu, cristi)@csc.kth.se
Abstract—Challenged and/or elderly people experiencing
limited mobility impairment may want to get support for
walking. In public, e.g., in a supermarket, they may want to
get this support without it being immediately visible. Therefore,
we integrated walking aid functionality into a robot shopping
cart. It can support a customer to lean on the cart while the
walking pace is controlled to follow a user-determined setting.
More precisely, the user of the cart can get walking assistance
by holding speciﬁcally designed handle bars supporting both
arms. This construction is fully integrated in a prototypical
robot designed as a shopping cart.
Keywords—Walking aid; semi-autonomous robot shopping
cart.
I. INTRODUCTION
Especially in an aging society, more and more (partial)
challenges arise. Primarily elderly people often experience
challenges with walking. As long as they can walk, however,
they typically prefer some kind of walking assistance over
a wheel chair. In public, they may even want to hide
their challenge and to get such support without it being
immediately visible. The latter requirement is hard to fulﬁll
with a dedicated walking aid.
We developed a (prototypical) robot serving as a shopping
cart and, from the very outset, we planned to integrate
a walking aid. When someone would use such a robot
shopping cart, this very robot can serve both the usual
shopping purposes and as a walking aid. Its motor power lets
it drive to desired goods and help move loaded goods, and
at the same time provide walking assistance. In addition to
the mode with the walking aid, the robot cart has a steering
mode, an autonomous mode and semi-autonomous modes
for guiding a user to certain products and for following the
user. Unless the robot is in the walking aid mode, its handle
bars are in a locked position.
This shopping cart is a companion robot designed to
perform services in a complex and cluttered dynamic en-
vironment, a supermarket, shared by humans and other
robots. To share such an environment with humans and to
cooperate with them requires certain communication abilities
from the robot. Even our prototypical implementation for
research purposes can handle multimodal input through a
touch screen, speech input and a barcode reader [3], as
well as output through a graphical user interface and speech
output [2]. It can even reinforce multimodal output through a
motion cue [6]. The primary services that we implemented in
the prototype are management of a shopping list and guiding
a user to the products from the shopping list.
The remainder of this paper is organized in the following
manner. First, we explain the design and implementation of
this walking aid. Then we present an exploratory study with
it. Finally, we discuss related work.
II. WALKING AID DESIGN AND IMPLEMENTATION
We designed the cart to provide walking assistance for
users with special needs. In particular, it provides physical
support for walking, via an add-on ergonomically designed
for such users. Another main goal was to particularly support
those who want to hide their challenge while shopping in a
supermarket.
Taking existing designs for non-robot walking aids into
consideration, the idea was to use a construction supporting
both arms with handle bars positioned at waist-height and
equipped with buttons for user control. However, no adjust-
ments in width and height were intended, in order to keep
the design and the ﬁrst-time usage simple. The buttons can
be pressed easily while holding the handle bars for being
physically supported. Due to safety reasons, two (yellow)
bumper rings enclose the outer cart shape for detecting
collisions. These bumpers limit the leg-moving space, i.e.,
a walking aid add-on inside the bumpers has safety-related
advantages but is ergonomically inapplicable.
Therefore, the handle bars of our walking aid are swivel-
mounted on the cart (see a design sketch in Figure 1 with
body proportions). Figure 2 shows the implemented walking
aid in its locked position. Whenever the walking aid is to be
used, the handle bars can be swiveled out of their vertical
spring-locked position. Figure 5 shows this position of the
implemented walking aid when in use for steering the robot.
The swivel-out event is detected by two micro switches to
enable an automatic mode change of the cart.
Each of the two bars ends is equipped with two pushbut-
tons for controlling speed and orientation of the cart. Two
of these buttons can be seen in Figure 2. The walking aid
control through all four buttons is illustrated in Figure 3.
218
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Figure 1.
Swivel-mounted handle bars for our cart walking aid related to
body proportions.
However, there is no step-less speed control, and compared
to the autonomous modes of the cart, maximum speed and
acceleration are reduced for better controllability.
III. EXPLORATORY STUDY
We have explored how a robotic shopping cart apart from
its main function of carrying goods and guiding to locations
in the store, could have a second function as a walking aid.
In order to conduct a formative evaluation of the walking aid,
we carried out a small user study where we let two users
drive the robot (as shown in Figure 5), who where untrained
on the walking aid. As the prototype is motorized and in an
early stage, we did not involve people with actual walking
impairments as users of the system for safety reasons.
A. Setup and task
The participants were introduced to the notion of a
walking aid. They were also shown how to operate the robot
using the buttons on the handles, both with the illustration
shown in Figure 3 and by letting them try it out on their
own. Using a think-aloud protocol, the participants reported
which one of the functionalities they attempted to use.
After that, they had to perform the tasks depicted in
Figure 4. The ﬁrst task was to drive forward in a slalom
course to a point located in the map (see Point 1). Once at
Point 1, they were instructed to drive backward to Point 2.
This slalom course contains the typical maneuvers one
would perform with such a shopping cart. The grey boxes
shown in the ﬁgure are empty cartons with a dimension of
about 60 × 60 × 60cm. The participants were instructed that
they should not touch the boxes with the robot.
After they had performed these tasks, the participants
received a subjective questionnaire and ﬁlled it out.
B. Results
Both participants managed to learn driving the robot using
the given interface, and they also succeeded with the driving
task. Further studies, however, are necessary to ﬁgure out if
Figure 2.
Implementation of the walking aid — locked position.
this electro-mechanical interface is helpful and easy to learn
for the elderly and (partially) challenged people as well.
Since only two people took part in the study, it makes little
sense to provide quantitative data. There were some open
questions where the participant expressed their opinions:
• “[I] would like the direction button on the other hand”
• “a
bigger
turning
radius
would
be
better
for
handicapped people”
• “The global behavior is easy to understand even if a
few tries are needed to learn the commands”
• “[It’s] easier to learn by using than by reading
instructions.”
The construction was considered stable and pleasant to
grasp, and its handling and use easy to learn. Interestingly,
just trying it out was considered more effective than the
instructions through the illustration in Figure 3. Still, the
placement of buttons should be studied further.
IV. RELATED WORK
Most of the related research activities focus solely on
the walking function. They implemented their support for
walking as a primary, single function, either by assisting
with the driving using the handle as input (see [1], [11])
or by assisting visually impaired users to a location using a
physical interface modeled after the leashes of guide dogs.
The user grabs the handle and follows the robot (see [8],
[9]).
Graf et al. [5] designed and implemented a semi-
autonomous walking aid platform for elderly and handi-
capped people. These authors have people in mind that use
219
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Btn 1-  left
Btn 2 - left 
Btn3 - right
Btn 4 - right
Shift robot left
Shift robot right
Move forward
Move backward
Turn left
Turn right
Backward turn left
Backward turn right
Figure 3.
Walking aid control through the four buttons.
this platform day-by-day, thus getting used to it. While this
walking aid is used mainly at home, we focus on a populated
domain like a supermarket, where people typically do not
have much time to learn a user interface. Moreover, we
focus on slightly impaired users who are, in principle, able
to walk on their own, but might require some help when
maneuvering a shopping cart ﬁlled with a lot of goods, and
would like to hide their walking problems.
Addressing the same problem of keeping the elderly
and handicapped independent, previous research by Lee
et al. [10] and Annicchiarico et al. [1] presents personal
assistive mobility devices for elderly people with walking
Point 
2
Point
1
START
END
Figure 4.
The map showing the task that was used for the pilot study.
impairments. However, their focus is on users requiring a
“pure” walking support. Our work does not ﬁt well for those
that who have more severe problems when using a shopping
cart in a supermarket.
Kanda et al. [7] presented an affective guide robot in
a shopping environment. This robot supports people to
navigate through a shopping mall and provides information
about products via a speech interface for input and output.
Even though our service robot shares the same domain with
this service robot, their work does not have any functionality
to help people with a walking impairment.
Glas et al. [4] introduce a guiding and helping robot called
RoboPal. It is designed to operate in the domain of everyday
life, acting as a guide or helping people with daily errands in
real-world environments. The authors studied nonverbal cues
of RoboPal associated with leading and following behavior
of the robot. However, due to its morphology, RoboPal is
a communication robot only and not intended to physically
support the elderly or disabled in the course of maneuvering
goods in a shopping cart.
V. CONCLUSION
We designed and built a walking aid that is prototypi-
cally integrated in a semi-autonomous robot shopping cart.
Through building it and a small exploratory study, we gained
ﬁrst insights and showed the principal feasibility of such
an approach. After the safety issues will have been solved
satisfactorily, studies and experiments with people having
partial challenges with walking can be a next step for further
development of such an integrated walking aid.
ACKNOWLEDGMENTS
This research has been carried out in the CommRob
project (http://www.commrob.eu), partially funded by the
EU (contract number IST-045441 under the 6th framework
programme). The idea of a walking aid integrated in a robot
shopping cart originally came from Vasilios Spais in the
course of preparing the project proposal. Special thanks
220
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Figure 5.
The walking aid in use.
are due to the Institute of Mechanics and Mechatronics
of the Vienna University of Technology and, in particular,
Peter Unterkreuter for providing help in the manufacture and
assembly of all mechanical walking aid components.
REFERENCES
[1] R. Annicchiarico, C. Barru´e, T. Benedico, F. Campana,
U. Cort´es, and A. Mart´ınez-Velasco.
The i-Walker: An
intelligent pedestrian mobility aid. In Proceedings of the 2008
European Conference on Artiﬁcial Intelligence (ECAI 2008),
pages 708–712. IOS Press: Amsterdam, The Netherlands,
2008.
[2] D. Ertl, J. Falb, and H. Kaindl. Semi-automatically conﬁgured
ﬁssion for multimodal user interfaces. In Proceedings of the
Third International Conference on Advances in Computer-
Human Interactions (ACHI 2010), pages 85–90. IEEE Com-
puter Society Press: Piscataway, NJ, USA, 2010.
[3] D. Ertl, S. Kavaldjian, H. Kaindl, and J. Falb.
Semi-
automatically generated high-level fusion for multimodal user
interfaces. In Proceedings of the 43rd Annual Hawaii Inter-
national Conference on System Sciences (HICSS-43). IEEE
Computer Society Press: Piscataway, NJ, USA, 2010.
[4] D. F. Glas, T. Miyashita, H. Ishiguro, and N. Hagita. RoboPal:
Modeling role transitions in human-robot interaction. In Pro-
ceedings of the IEEE International Conference on Robotics
and Automation (ICRA 2007), pages 2130–2137, April 2007.
[5] B. Graf, M. Hans, and R. D. Schraft.
Care-o-bot ii —
development of a next generation robotic home assistant.
Auton. Robots, 16(2):193–205, 2004.
[6] H. H¨uttenrauch, C. Bogdan, A. Green, K. S. Eklundh, D. Ertl,
J. Falb, H. Kaindl, and M. G¨oller. Evaluation of Robot Body
Movements Supporting Communication.
In Proceedings
of New Frontiers in Human-Robot Interaction Symposium
of the Convention Artiﬁcial Intelligence and Simulation of
Behaviour (AISB), Leicester, UK, 2010.
[7] T. Kanda, M. Shiomi, Z. Miyashita, H. Ishiguro, and
N. Hagita. An affective guide robot in a shopping mall. In
Proceedings of the 4th ACM/IEEE International Conference
on Human-Robot Interaction, pages 173–180. ACM: New
York, NY, USA, 2009.
[8] V. Kulyukin, J. Nicholson, and D. Coster. Shoptalk: Toward
independent shopping by people with visual impairments.
In Proceedings of the 10th International ACM SIGACCESS
Conference on Computers and Accessibility (Assets ’08),
pages 241–242. ACM: New York, NY, USA, 2008.
[9] V. A. Kulyukin and C. Gharpure. Ergonomics-for-one in a
robotic shopping cart for the blind. In HRI ’06: Proceedings
of the 1st ACM SIGCHI/SIGART Conference on Human-
robot Interaction, pages 142–149, New York, NY, USA, 2006.
ACM.
[10] G. Lee, T. Ohnuma, and N. Chong. Design and control of
JAIST active robotic walker.
Intelligent Service Robotics,
3:125–135, 2010. 10.1007/s11370-010-0064-5.
[11] T. R¨ofer, T. Laue, and B. Gersdorf. iWalker — An Intelligent
Walker providing Services for the Elderly. In Proceedings of
the European Conference on Technically Assisted Rehabilita-
tion (TAR ’09), Berlin, Germany, 2009. VDe/VDI.
221
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

