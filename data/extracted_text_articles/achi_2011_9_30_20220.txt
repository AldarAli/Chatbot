A Framework for Computer Based Training  
to In Vitro Fertilization (IVF) Techniques   
A. F. Abate, M. Nappi, S. Ricciardi 
Department of Mathematics and Computer Science  
 University of Salerno 
Fisciano (SA) -Italy 
{abate, mnappi, sricciardi}@unisa.it 
 
  
Abstract - This paper presents a visual-haptic framework for 
the simulated training to some key procedures of the In Vitro 
Fertilization techniques which are become very popular to 
address several infertility conditions. Two of the most crucial 
procedures typically involved in the fertilization process, the 
Intra Cytoplasmic Sperm Injection (ICSI) and the Embryo 
Transfer (ET) are integrated in the system proposed. The aim 
is simulating them both at the visual and kinesthetic level by 
means of a specifically developed virtual environment. This 
environment includes the human egg, the selected sperm and 
the micro needles required during the ICSI as well as the 
catheter, the womb and the embryo involved in ET. The 
proposed approach exploits a two hand-based haptic devices 
mimicking the force feedback of the actual manipulation gear 
and a visual-haptic engine simulating the shape and the 
dynamic behavior of the main components involved in the two 
aforementioned stages of the artificial fertilization process.  
 
Keywords: visual-haptic interface; 3D object manipulation; 
virtual training 
I. INTRODUCTION 
Today, haptic devices providing realistic force feedback 
to the manipulation of virtual objects [1] allow the users of 
virtual simulators not only to practice at a visual level but 
also to develop the haptic-knowledge required to perform 
hand-based tasks [2]. Medical/surgical training applications 
[3] may particularly benefit from a visual-haptic approach, 
since they are inherently dependent on physical interaction 
[4] [5]. In this study the aforementioned interaction 
paradigm is exploited for the simulated training of two key 
techniques commonly required for In-Vitro Fertilization 
(IVF): the (Intra Cytoplasmic Sperm Injection) typically 
known as ICSI and the Embryo Transfer (ET) which are 
briefly explained in the following lines.  
The term ICSI refers to the injection of a sperm directly 
into the cytoplasm of the egg. This procedure by-passes all 
the natural barriers that the sperm has to encounter. The 
ICSI procedure begins by drawing out the previously 
immobilized sperm into a tiny micro-needle, carefully 
maintaining it at its tip. The micro-injection needle is 
manipulated using a micro-manipulator which has 
extremely fine control capabilities. The egg itself is held 
onto another micro-tool by gentle suction to keep it firmly 
positioned. The micro-needle containing the sperm is 
pushed gently up against the outer shell (pellucida zone) 
and carefully injected through the shell, through the outer 
membrane of the egg and directly into the centre of the egg 
itself, i.e., the egg’s cytoplasm (Figure 1a). At the end of 
the injection procedure the micro-injection needle is 
carefully withdrawn and suction on the egg is released. 
After subsequent culture procedures, in case of 
fertilization, the Embryo Transfer (ET) procedure is 
performed by placing the embryos back in the uterus by 
means of a specific flexible catheter (Figure 1b), where 
they will hopefully implant and develop to result in a live 
birth. The ET procedure is a critically important procedure, 
and the physician can ruin everything with a carelessly 
performed embryo transfer. The entire IVF cycle depends 
on delicate placement of the embryos at the proper location 
near the middle of the endometrial cavity with as little 
trauma and manipulation as possible. To our best 
knowledge, this is the first proposal of an integrated 
ICSI/ET virtual training system, while there are only very 
few works addressing the ICSI simulation through 
virtual/augmented reality techniques. Banerjee et alii [6] 
propose a cellular micro-manipulation simulator based on 
the Immersive TouchtTM VR system including a high-
resolution display coupled with a haptic device providing 
force feedback during the simulated cell injection 
procedure, while the main limit reported about this 
approach is the lack of hand-eye coordination. Mizokami et 
al. [7] suggest a system to simulate the ICSI procedure by 
means of a Sensable’s Phantom stylus-based haptic device, 
which is however limited to simulate only the interaction 
with the micro-needle manipulator. According to the 
embryologists involved in this research a useful training 
system should realistically simulate procedures which often 
involves both hands, therefore we decided to implement a 
two-hand based interaction approach to perform the tasks 
required.  
II. SYSTEM’S ARCHITECTURE 
Though the VR-related issues may seem to be 
prevailing in this proposal, the main challenges are 
represented by the two-hand interaction and by the realism 
of the visual-haptic perceptions to be provided during the 
202
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

simulated manipulation procedure. Indeed, for such a 
virtual training system to be effective and useful, the 
perceptual level of the simulation is more important than 
the exact agreement with the underlying physic laws. 
According to objectives mentioned in the introduction, a 
couple of CyberForce® hand-based force-feedback devices 
by Cyberglove Systems have been adopted in order to 
provide the user with haptic sensations while performing 
simulated ICSI and ET. The CyberForce device is made up 
by an articulated exoskeleton anchored to the back of the 
user’s hand which is devoted to the recovery of grounded 
forces to the user’s arm-hand-fingers system within its 
operative volume. The overall architecture of the Virtual-
ICSI simulator is schematically shown in Figure 2, with its 
main components. 
- Human-Machine Interface: receives as input the 
positional/rotational user’s info from the haptic sub-system 
and outputs the user’s activity data to the Physics Engine. 
The HMI enables to explicitly (by vocal commands) or 
implicitly (by hand activity) modify the simulation 
evolution. 
- Visual Rendering Engine: integrates the tracking data 
and the current state of the physical simulation, 
transforming the polygonal geometry according to the 
camera viewpoint and rasterizing the scene in frames to be 
sent to the Head Mounted Display. It also checks for 
collision arising between the interacting objects, outputting 
a vector representation of any collision event, which is 
employed by the Haptic Rendering Engine which simulates 
contact forces. The VE is built on the Quest3D graphics 
programming environment [8] based on the DirectX API. 
- Haptic Rendering Engine: is responsible for 
reproducing the haptic behaviour of all the objects involved 
in the interaction by means of specific haptic models. HRE 
depends on the Visual Rendering Engine and directly 
controls the Haptic Sub-System to exert contact and 
feedback forces. It outputs force-relevant data consisting in 
one force value for each finger plus the three-component 
force vector to be actuated by the hand back force 
transmission arm by applying a non-linear transfer 
function. The penetration of objects into other objects is 
therefore prevented by the combined action of the collision 
detection and the resulting force actuation by the force 
feedback device.  
Contact forces are simulated by measuring them in 
terms of the depth of penetration of the virtual hand model 
into the grasped object. 
  
- Haptic Sub-System: is made by left and right 
exoskeletons and it translates the output of the haptic 
rendering in terms of force feedback, also acting as an 
alternative input interface to select and activate the 
available functions. 
- Tracking System: captures the user’s hands position 
and orientation to enable coherent visualization by the 
visual engine. 
- Physical Engine: simulates the dynamic behaviour of 
any object involved in the virtual simulation and 
represented in the 3D Dataset. The representation complies 
with an approximation of a subset of the physics laws 
appropriate to the simulation, by means of a set of physical 
parameters 
as 
mass, 
static/dynamic 
friction, 
and 
stiffness/elasticity. Rigid body dynamics is accomplished 
by means of the Newton Dynamics API [9] which is based 
on a deterministic solver instead of a more common solver 
based on linear complementary problem (LCP) or iterative 
methods, resulting in a more accurate and stable solutions. 
Soft body dynamics, which is required to realistically 
simulate the effect of the egg-needle and egg-pipette 
interaction, would be very compelling to render in real-
time on a purely physical base, therefore it has been 
approached by pre-calculated 3D morphing. 
- Auxiliary Vocal Interface: allows the user to control 
the system by (context dependent) vocal commands 
together to the haptic sub-system which represents the main 
user interface. This additional interface level is required 
since often during operations the user typically has both 
hands engaged in the manipulation. 
- 3D Dataset: is the source of every virtual content 
which is represented with polygonal geometry, textures, 
shadiness, physical properties and processed by the Visual 
Rendering Engine and the Physical Engine.  
- Head Mounted Display: allows the user to experience 
an immersive simulation from a viewpoint resembling the 
microscope ocular. 
 
                        
 
Figure 1. (a) The micro-needle penetrates the egg’s zone-pellucida and reaches cytoplasm during ICSI. (b) A  pictorial view of the embryo transfer 
procedure. The embryologist carefully insert the catheter through the cervix until the target site is reached and the fertilized embryos are gently released.
203
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

 
Figure 2. Schematic view of the system’s architecture. 
The egg model is based on concentric geodetic 
spheroids replicating the different cell’s membranes, and its 
topology allows an ideal shape deformation when in touch 
with the micro-needle. The flexible catheter controlled by 
the user during the ET is approximated as a cinematic chain 
where each link’s rotational values affect the previous links 
according to the distance in the chain and to a parametric 
decay function. The approach to render the contact between 
the catheter and soft organic tissues, like the cervix or the 
endometrium, exploits deformability/stiffness mapping. By 
means of this technique, texture mapping (typically 
simulating visual properties such as color, transparency, 
roughness, shininess, etc.) can be used to associate local 
deformability data to 3D geometry instead of relying on 
object-level properties.  
 
Figure 3. An example of deformability map representing the local stiffness 
of the simulated endometrium respectively by means of an 8 bit texture. 
The deformability map is associated to mesh vertices 
through mapping coordinates in the form (u, v), previously 
projected onto the surface. The additional info can be 
represented through each pixel’s RGB channels in a color 
texture or even in a grayscale bitmap, according to different 
arrangements offering a great flexibility of use (Figure 3). 
In its simplest form an 8 or 16 bit grayscale image may 
encode the local stiffness parameters required to compute 
the reaction force at a texel level, thus providing a range of 
256 or 65536 stiffness levels with a spatial granularity only 
depending by image’s resolution. A specific pixel shader 
processes the frames to provide a “ultrasound like” 
appearance to the rendered images reproducing the look of 
the diagnostic imagery to enhance the realism of the 
simulated intervention.  
 
Figure 4. A rendering showing the simulated Embryo Transfer 
III.  
FIRST EXPERIENCES WITH THE SYSTEM 
We performed some preliminary experiments on the 
framework described above, to verify the subjective 
response of the expert and trainees embryologists to the 
virtual training. The test bed hardware included a dual 
quad-core Intel Xeon processor based on a Mac Pro 
workstation from Apple Inc., equipped with 8 Gigabytes of 
RAM and an Nvidia Quadro 5600 graphics board with 1,5 
Gigabytes of VRAM. Five embryologists have been 
involved in the experimental sessions after a brief training 
on the usage of the HMD (a Cybermind Visette Pro SXGA) 
and of the haptic devices (Figure. 5). Each operator 
participated to 6 different sessions (3 for ICSI and 3 for 
ET) for a total of 30 sessions. After each session, each 
operator had to fill a questionnaire, assigning a vote in the 
integer range 1-10 (the higher the better) to seven 
subjective aspects of the simulated intervention and 
precisely: A. Realism of Visual Simulation; B. Realism of 
Haptic 
Perceptions; 
C. 
Accuracy 
of 
Simulated 
Manipulation; D. Visual-Haptic Coherence; E. HMD 
Alignment; F. Haptic System Fatigue; G. Simulator 
Usefulness.  
Visual-Haptic Engine 
 
Human  
Machine  
Interface 
Vocal 
Interface  
Haptic  
Sub-System 
Head 
Mounted 
Display  
 
Dynamics 
 
Hapting Rendering 
Visual 
Rendering 
 
User 
6 DOF 
Tracking 
3D 
Dataset 
 
204
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

A.   Measures the overall visual realism of the 
simulation in terms of its training efficacy. This value is 
therefore affected not only by the graphics quality 
delivered by the system (the level of detail in the 3D 
anatomy, the frame rate, etc.) but also by how credible are 
the visual aspects of the dynamic simulation.  
B.  Measures the realism of the haptic sensations 
provided during the virtual experience. This value is 
therefore influenced by the limits of the haptic device in 
terms of force intensity and degree of freedom (for instance 
the Cyberforce cannot convey torque on wrist and arm 
joints) but also by the quality of the haptic-rendering 
algorithms adopted to simulate the contact forces during 
collision between solid and deformable bodies. 
C.  Measures the effectiveness of the visual-haptic 
manipulation, including grasping, releasing and exertion of 
forces on the virtual objects during the manual 
intervention. 
E.  Measures the subjective perception of spatial and 
temporal coherence between visual and haptic stimula 
provided by the system during the simulation. Therefore 
this value measures the quality of the perceptual illusion 
generated during simulation.  
F.  Measures comfort level experienced by users 
wearing the Head Mounted Display. The values reported in 
this experiment are clearly dependent on the particular 
HMD solution adopted, and on the device’s technical 
specs, particularly the field of view, the resolution and the 
display’s 
corner-to-corner 
sharpness, 
so 
they 
may 
considerably change if other devices are chosen. Negative 
issues related to the immersive stereoscopic visualization 
may have an impact on this value as well. 
G.  Measures the accretion of abilities and, 
consequently, the reduction of human stress related to a 
tricky medical scenario.  
While these Figures are subjective and the number of users 
involved in these first trials is small, the overall evaluation 
has been positive so far. 
 
 
Figure 5. Two exoskeletons during a simulated manipulation. 
TABLE 1. Subjective evalutions resulting from the resume form 
Features 
Min 
Avg. 
Max 
(A) Realism of Visual Simulation 
6 
7.1 
9 
(B) Realism of Haptic Perceptions  
5 
6.3 
8 
(C) Accuracy of Sim. Manipulation 
6 
7.2 
8 
(D) Visual-Haptic Coherence  
6 
6.8 
7 
(E) HMD Sickness 
4 
5.4 
7 
(F) Haptic System Fatigue  
4 
5.8 
6 
(G) Simulator Usefulness  
6 
7.3 
8 
IV.  
CONCLUSIONS 
A framework for the visual-haptic simulation of In 
Vitro Fertilization procedures has been presented in this 
paper. The main visual and haptic aspects of the simulated 
procedure have been positively evaluated during our 
preliminary tests, while the main concern is related to the 
overall fatigue involved in wearing the articulated 
exoskeletons and the head mounted display. Anyway our 
work is at an early stage and we are in the process to set up 
and perform more polished and accurate experiments to 
measure the advantages and the limits of this framework 
for IVF practice. 
REFERENCES 
 [1] 
M. A. Srinivasan and C. Basdogan, Haptics in virtual 
environments: 
Taxonomy, 
research 
status, 
and 
challenges, 
Computer and Graphics, Vol 21, Issue 4, , pp. 393-404. 
[2]  
C. Krapichler, M. Haubner, A. Lösch, and K. Englmeier, (1997) 
“Human-Machine Interface for Medical Image Analysis and 
Visualization in Virtual Environments”, IEEE conference on 
Acoustics, Speech and Signal Processing, ICASSP-97. Vol 4, pp. 
21-24. 
[3]  
K. F. Kaltenborn and O.Rienhoff, Virtual Reality in Medicine. 
Methods of information in medicine. Vol. 32, N 5, 1993, pp.407-
417  
[4]  
C. Basdogan, C. Ho, and M. A. Srinivasan, Virtual Environments 
for Medical Training: Graphical and Haptic Simulation of 
Laparoscopic Common Bile Duct Exploration. In IEEE/Asme 
Transactions On Mechatronics, Vol. 6, No. 3, September 2001, pp. 
269-284. 
[5]  
O. Körner and R. Männer, Implementation of a Haptic Interface for 
a Virtual Reality Simulator for Flexible Endoscopy. In Proceedings 
of 11th Symposium on Haptic Interfaces for Virtual Environment 
and Teleoperator Systems (HAPTICS'03), 2003, pp. 278-285. 
[6]  
P. Banerjee, S. Rizzi, and C. Luciano, Virtual Reality and Haptic 
Interface for Cellular Injection Simulation. In Proceedings of 14th 
Medicine Meets Virtual Reality, JD Westwood et al, YOS Press, 
2007, pp. 37-39. 
[7]   N. Abe, R. Mizokami, Y.Kinoshita, and S.He, Artificial Reality and 
Telexistence, 17th IEEE International Conference on, 28-30 Nov. 
2007, pp 143-148. 
[8]  
Quest3D visual development software: http://quest3d.com/  
[9] 
Newton Game Dynamics API, (www.newtondynamics.com). 
205
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

