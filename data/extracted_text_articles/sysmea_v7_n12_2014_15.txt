Generic and Adaptable Online Conﬁguration
Veriﬁcation for Complex Networked Systems
Ludi Akue, Emmanuel Lavinal, Thierry Desprats, and Michelle Sibilla
IRIT, Universit´e de Toulouse
118 route de Narbonne
F31062 Toulouse, France
Email: {akue, lavinal, desprats, sibilla}@irit.fr
Abstract—Dynamic reconﬁguration is viewed as a promising
solution for today’s complex networked systems. However, con-
sidering the critical missions actual systems support, systematic
dynamic reconﬁguration cannot be achieved unless the accuracy
and the safety of reconﬁguration activities are guaranteed. In this
paper, we describe a model-based approach for runtime conﬁgu-
ration veriﬁcation. Our approach uses model-driven engineering
techniques to implement a platform-independent online conﬁgu-
ration veriﬁcation framework that can operate as a lightweight
extension for networked systems management solutions. The
framework includes a ﬂexible and adaptable runtime veriﬁcation
service built upon a high-level language dedicated to the rigorous
speciﬁcation of conﬁguration models and constraints guarding
structural correctness and service behavior conformance. Exper-
imental results with a real-life messaging platform show viable
overhead demonstrating the feasibility of our approach.
Keywords—Network and Service Management; dynamic recon-
ﬁguration; conﬁguration veriﬁcation; online veriﬁcation; model-
based approach.
I.
INTRODUCTION
Complex networked systems and services are a fundamen-
tal basis of today’s life. They increasingly support critical
services and usages, essential both to businesses and the
society at large. The evident example is the Internet with all
its services and usages in a variety of forms, architectures and
media ranging from small mobile devices such as smartphones
to large-scale critical systems such as clusters of servers
and cloud infrastructures. Consequently, it is indispensable to
ensure their proper and continuous operation.
Network and Service Management (NSM) is a research
and technical discipline that deals with models, methods and
techniques to ensure that managed networked systems and
services operate optimally according to a given quality of
service. To cope with the increasing complexity of managed
systems, NSM has evolved into self-management, a vision that
consists in endowing management solutions with a high degree
of autonomy to allow them to dynamically and continuously
reconﬁgure managed systems in order to maintain a desired
state of operation in the face of unstable and unpredictable
operational conditions.
A main obstacle to the diffusion of dynamic reconﬁguration
solutions is the lack of standard methods and means to ensure
the effectiveness of subsequent conﬁguration changes and
prevent erroneous behaviors from compromising the system’s
operation. This issue is particularly signiﬁcant in today’s
mission critical systems management like cloud infrastructures,
avionics, healthcare systems or mobile multimedia networks.
This will also help increase users’ conﬁdence in the automation
of reconﬁguration, thus ease the adoption of ongoing auto-
nomic solutions.
This article extends our recent work [1] on a model-
based approach for online conﬁguration veriﬁcation with a
running prototype architecture. It also provides additional
concepts, methods and tools forming an online conﬁguration
veriﬁcation framework. In particular, we describe how we use
the framework to enrich a management system for a message
oriented middleware platform with online conﬁguration check-
ing capabilities. Following the same process, the veriﬁcation
framework could be integrated with other existing management
solutions.
Our approach to build this framework was ﬁrst to deﬁne
MeCSV (Metamodel for Conﬁguration Speciﬁcation and Va-
lidation), a high-level language, dedicated to the speciﬁcation
and veriﬁcation of conﬁgurations. MeCSV allows operators
to specify at design time, a platform-neutral conﬁguration
schema of their managed system with constraints guarding
the desired service architecture and operation. One novelty
of the metamodel is to include the capability to express
both ofﬂine and online constraints. Ofﬂine constraints are
typically structural integrity rules, that is, rules that govern
a system’s conﬁguration structure. Online constraints concern
service operation, they consist of rules to be enforced with
regards to runtime conditions to avoid committing inconsistent
conﬁgurations. An earlier version of the metamodel has been
presented in [1].
Second, we have designed a runtime veriﬁcation service,
able to manipulate the concepts deﬁned in this language.
This service offers two interfaces, a veriﬁcation interface for
invoking conﬁguration veriﬁcation and an edition interface for
managing speciﬁcations at runtime. The veriﬁcation interface
is ﬂexible as it provides different operations to tailor conﬁgu-
ration veriﬁcations to the usage scenarios, e.g., verifying only
a subset of constraints regarding their severity or importance.
The edition interface enables constraints updates at runtime to
cope with changing management requirements.
These two phases allow our framework to support a ve-
riﬁcation process that starts at design time with a rigorous
speciﬁcation of veriﬁcation models and continues at runtime
through an automatic checking of conﬁgurations based on
these models.
The rest of the paper is organized as follows: Section
168
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

II identiﬁes runtime conﬁguration veriﬁcation requirements
and positions existing works. We give an overview of the
framework in Section III, and through a case study included
in Section IV, elaborate on its building blocks in Section V
and Section VI. We describe the integration of the framework
with a real-life messaging platform in Section VII along with
experimental results, proving the feasibility of the approach.
Section VIII concludes the paper and identiﬁes future work.
II.
BACKGROUND AND RELATED WORK
We begin this section by introducing the terminology used
throughout the paper, then we expose the runtime conﬁguration
veriﬁcation requirements in the current context of autonomous
management approaches like in [2] and [3]. Finally, we present
how those requirements have been addressed in related works.
A. Terminology
This section recalls deﬁnitions of key terms used through-
out the paper.
1) Conﬁguration: A conﬁguration of a system is a col-
lection of speciﬁc functional and non-functional parameters
(also known as conﬁguration parameters or conﬁguration data)
whose values determine the expected functionalities that the
system should deliver.
2) Execution context: The execution context of a system
comprises every element that can inﬂuence the system’s op-
eration. It includes both the system’s technical environments,
i.e., its interactions with other systems, its supported services
and usages and the users’ expectations, i.e., management and
service objectives.
3) Operational state: The operational state of a system
qualiﬁes its observed operation in terms of the current values
of its state parameters (or state data). The operational state is
issued by a monitoring or a supervisory system. It reﬂects the
behavior of the system relevant to the context at hand.
4) Dynamic Reconﬁguration: Reconﬁguration is the mo-
diﬁcation of an existing and already deployed conﬁguration.
Reconﬁgurations can be static, that is conﬁgurations are mod-
iﬁed ofﬂine, when the system is not running. They can also
be dynamic, that is conﬁgurations are modiﬁed online, while
the system is running. We are especially interested in managed
systems that are reconﬁgured dynamically.
5) Conﬁguration veriﬁcation: Conﬁguration veriﬁcation is
the process of examining conﬁguration instances against a
set of deﬁned requirements according to system architecture
and service objectives. Conﬁguration veriﬁcation checks the
correctness of proposed conﬁguration instances, thus detect
misconﬁgurations prior to changing the productive system.
B. Conﬁguration Veriﬁcation Requirements
Veriﬁcation has always been critical to check that a given
conﬁguration meets its functional as well as non-functional
requirements. When considering the lifecycle of a conﬁgurable
system, in contrary to software veriﬁcation that occurs mainly
during the development phase of a system, conﬁguration
veriﬁcation rather occurs in the use phase of a system to
enforce its operation and maintenance (Fig. 1).
Design
Implementation
Tests & 
Validation
Operation & 
Maintenance
Veriﬁcation in the system's life cycle
Conﬁguration veriﬁcation
Development Phase
Use Phase
Fig. 1.
Conﬁguration veriﬁcation in a simpliﬁed system’s lifecycle
Conﬁguration veriﬁcation is traditionally done ofﬂine, ei-
ther at design time, for example in test environments, or
in production environments to enforce static reconﬁgurations.
This veriﬁcation is limited to structural sanity checks, typically
testing the correct structure and composition of conﬁguration
parameters in terms of authorized values, consistent cross-
components dependencies and syntactical correctness. This
type of veriﬁcation involves conﬁguration data only. We have
called it structural integrity veriﬁcation [4].
By deﬁnition, dynamic reconﬁguration implies conﬁgura-
tion veriﬁcations should be carried out automatically at runtime
for checking live conﬁguration changes. Therefore, the veriﬁ-
cation process should take into account running operational
conditions (1). It should also be ﬂexible and adaptable to cope
with the changing execution context in terms of architectural
dynamics and changes of service objectives (2). Besides, it
should accommodate the heterogeneity of management do-
mains, representations and tools (3).
1) Operational Applicability Veriﬁcation:
Conﬁguration
veriﬁcation should go beyond structural checks to assess the
operational applicability of proposed conﬁgurations regarding
runtime conditions at hand.
As systems adapt dynamically, ongoing operational states
can invalidate the suitability of a produced conﬁguration
despite its structural correctness. For instance, one of the most
common causes of a failed live virtual machine migration is not
checking that the current physical resources of the destination
host are sufﬁcient before performing the live migration.
A runtime conﬁguration veriﬁcation should include opera-
tional applicability veriﬁcation, that is, checking if a proposed
conﬁguration fulﬁlls some running conditions [4]. This type of
veriﬁcation requires the knowledge of monitored operational
state data. In other words, a runtime conﬁguration veriﬁcation
should cover both structural integrity veriﬁcation and opera-
tional applicability veriﬁcation.
2) Flexible and Adaptable Veriﬁcation: Conﬁguration ve-
riﬁcation should be ﬂexible and adaptable to cope with the
changing execution context in terms of architectural dynamics
and changes of service objectives.
The execution context of actual complex systems is highly
dynamic in terms of operational conditions variations and
dynamic usages where they are added, removed, migrated
according to changing management and service objectives.
This dynamicity implies conﬁguration changes of different
spatial and temporal scopes, e.g., local changes to system-
wide changes, planned or spontaneous changes, punctual or
life-long changes [5], [6].
A runtime conﬁguration veriﬁcation solution should thus
accommodate these new characteristics by being ﬂexible and
169
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

adaptable in order to be tailored to reconﬁguration needs
and usage scenarios, e.g., adapting the veriﬁcation scope and
perimeter.
3) Platform-independent Veriﬁcation: Conﬁguration veriﬁ-
cation should be platform-neutral to accommodate the hetero-
geneity of management domains, representations and tools.
Management applications domains are highly heterogenous
in terms of the nature and importance of conﬁguration data,
(e.g., conﬁguration data can be functional, non-functional,
static or dynamic), their different representations due to differ-
ent management standards and protocols, as well as the diverse
nature of properties to be checked (e.g., hard constraints,
soft constraint) according to diverse usage scenarios (mobility,
performance, functional, non-functional) [7], [8].
In consequence, a conﬁguration veriﬁcation solution should
be high-level and capable to integrate this heterogeneity.
C. Related Work
This section discusses existing works regarding the identi-
ﬁed conﬁguration veriﬁcation requirements.
The need for conﬁguration representation standards and
conﬁguration automation are growing concerns regarding the
complexity of the conﬁguration management of today’s large-
scale systems [9], [7]. Our work is at the junction of these
two topics as the veriﬁcation framework we provide enables a
platform independent online conﬁguration veriﬁcation that is
a prerequisite for conﬁguration automation as well as dynamic
reconﬁguration.
Existing management standards like the Distributed Mana-
gement Task Force Common Information Model (CIM) [10]
and the YANG data modeling language [11] include constructs
for conﬁguration veriﬁcation, yet their enforcement is left to
implementors and solutions developers. Furthermore, those
standards do not propose any mechanism for ﬂexible and
adaptable conﬁguration veriﬁcation as well as the management
of the resulting veriﬁcation lifecycle.
Beyond management standards, related works can fall into
two groups: constraint checking approaches [12], [13], [14],
[15] and valid conﬁguration generation approaches [16], [17],
[18].
In the ﬁrst group, conﬁguration experts are given a speciﬁ-
cation language to express some constraints that a veriﬁcation
engine checks on proposed conﬁguration instances. In the sec-
ond group, conﬁguration decision is modeled as a Constraint
Satisfaction Problem, adequate SAT solvers generate valid
conﬁgurations or prove insatisﬁability.
Both groups present common limitations, they do not ad-
dress online conﬁguration checking with regards to operational
conditions: they provide only structural integrity veriﬁcation
that relies purely on conﬁguration data or conﬁnes conﬁ-
guration veriﬁcation to design time. They do not support a
ﬂexible and adaptable veriﬁcation (e.g., only check a subset of
constraints, modify and manage constraints during the recon-
ﬁguration life cycle). In addition, they mainly propose domain-
speciﬁc tools with use-case speciﬁc veriﬁcation (networks,
distributed applications, JAVA applications, virtual machines).
Our work in contrast proposes a generic conﬁguration
veriﬁcation approach that targets speciﬁcally online conﬁgura-
tion checking, considering the inﬂuence of ongoing execution
conditions on the veriﬁcation process. It is thus proﬁtable for
complementing existing veriﬁcation approaches.
In particularly, our work shares common foundations with
SANChk [14], a SAN (Software Area Networks) conﬁguration
veriﬁcation tool. They both use formal constraint checking
techniques and enable a ﬂexible and adaptable conﬁguration
veriﬁcation. However, SANChk is speciﬁc to SAN conﬁgura-
tions and does not target online conﬁguration veriﬁcation.
III.
ONLINE CONFIGURATION VERIFICATION
FRAMEWORK
This section presents our veriﬁcation approach and subse-
quent assumptions and concepts.
A. Assumptions
The following assumptions characterize the class of mana-
ged systems that we currently consider:
•
The system is supposed known, observable, it is under
a supervisory control that collects measures about its
operating states and environment.
•
The system is dynamically conﬁgurable, that is to say
its current conﬁguration can be altered at runtime if
needed.
•
The system’s execution context is highly dynamic,
hence is subject to sudden and often unpredictable
variations.
•
Either the supported management goals are clearly
speciﬁed in order to derive properties to validate, or
these properties are already deﬁned.
B. Vision and Design Principles
The veriﬁcation framework aims at offering an online
conﬁguration checking service that can be used by manage-
ment solutions without changing existing tools. It speciﬁcally
targets current autonomous and self-management approaches.
As such, it purposefully addresses the runtime management of
the systems’ dynamics and the rapidly changing service and
architecture requirements. The framework supports these new
requirements through three main design principles according
to the requirements exposed in Section II:
•
Enabling an operational veriﬁcation of conﬁgurations
that takes into account their dependency on running
execution states: in the context of self-adaptation,
conﬁgurations are highly dependent on the operational
conditions that can invalidate the suitability of a
candidate conﬁguration.
•
Allowing modiﬁcation of validity properties at run-
time: management systems are likely to have their
requirements evolve at runtime, and these evolutions
are to be translated at runtime into the creation or
modiﬁcation of properties on conﬁgurations.
170
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

•
Supporting existing management systems in order to
enhance their reliability with a veriﬁcation functional-
ity. This can notably be achieved by integrating exist-
ing management standards such as CIM and YANG.
C. Integration within the Management Control Loop
Self-management is generally performed through a control
loop called the MAPE (Monitor-Analyze-Plan-Execute) loop:
the managed system is monitored (Monitor) to produce metrics
that are analyzed (Analyze) to detect or prevent any undesir-
able behavior. Corrective changes are then planned (Plan) –
either in the form of a new conﬁguration or as a sequence of
actions – then effected on the system (Execute) [2].
Runtime conﬁgurations decision is normally the respon-
sibility of the Plan function. Consequently, a runtime conﬁ-
guration veriﬁcation function that handles the two types of
conﬁguration veriﬁcation is worthy to extend the MAPE loop
to assure the validity of proposed conﬁgurations.
Monitor
Execute
Analyze
Plan
Managed elements
Online 
Conﬁguration 
Veriﬁcation
1
2
3
Fig. 2.
The vision of online conﬁguration checking
Fig. 2 illustrates our vision of a standard online con-
ﬁguration checking. An external and protocol-independent
veriﬁcation solution interacts with a management system (rep-
resented through the MAPE loop) through the Plan block (1),
center of runtime conﬁguration decisions, while relying on the
Monitor block (2) for the retrieval of the required ongoing
execution states, and thus processes an online veriﬁcation of
conﬁgurations (3).
As a result, the veriﬁcation solution we propose, can extend
any self-conﬁgurable system that does not have built-in online
conﬁguration veriﬁcation. The only requirement for the self-
conﬁguring system is to allow access to its conﬁgurations
and monitored data at runtime. Furthermore, this veriﬁcation
solution can be independently tuned and managed giving
ongoing usage needs.
D. Overview of the Framework’s Building Blocks
This section describes the building blocks of our veriﬁ-
cation framework. The framework supports a model-based ap-
proach for runtime conﬁguration veriﬁcation relying on a high-
level speciﬁcation language MeCSV and a veriﬁcation service
able to manipulate the concepts deﬁned in this language.
1) MeCSV language: MeCSV is a metamodel dedicated to
the formal modeling of conﬁguration information for runtime
veriﬁcation. It offers platform-neutral conﬁguration speciﬁ-
cation constructs including innovative features that enable
MeCSV Reference Model
MeCSV Metamodel
(a) Speciﬁcation of a MeCSV reference model
«conforms to»
Conﬁguration 
Veriﬁcation Service
Managed elements
(b) Online conﬁguration veriﬁcation architecture
D
E
S
I
G
N 
T
I
M
E
Human 
Operator
Ofﬂine model edition
Constraints
Constraints
Constraints
Constraints
State 
parameters
Conﬁguration 
structure
Management 
System
Human 
Operator
R
U
N
-
T
I
M
E
Online model edition
«uses»
Fig. 3.
Framework’s approach and architecture
veriﬁcation against runtime execution conditions. Even though
MeCSV allows to model a system’s conﬁguration, it is in-
tended for veriﬁcation purposes only and is not suitable neither
to model exhaustive management information nor to handle
the management of the conﬁguration’s lifecycle (conﬁguration
data stores, conﬁguration deployment etc.).
2) Target Domain Reference Model: The central objective
of MeCSV is to allow the deﬁnition of a Reference Model
that every possible conﬁguration of the target system should
conform to (Fig. 3 (a)). Operators or vendors can thus use
the MeCSV metamodel at design time to deﬁne the reference
model of a given managed application domain (e.g., an ap-
plication server, a messaging middleware). Deﬁned reference
models are instances of the MeCSV metamodel, they are
dedicated to a target application domain but do not rely on
platform-speciﬁc representations. This reference model is to be
deﬁned only once, it will be processed at each reconﬁguration
decision, to dynamically evaluate conﬁguration instances.
3) Veriﬁcation Service: The framework includes a runtime
architecture, Fig. 3 (b), with a veriﬁcation service. This service
needs to be initialized with the deﬁned reference model. A
related management system assuring monitoring and recon-
ﬁguration capabilities can then invoke speciﬁc operations at
runtime to perform online veriﬁcations of decided conﬁgura-
tion instances. This veriﬁcation service also supports online
modiﬁcation of reference models to cope with the evolution
of management and system requirements.
E. General Life Cycle of the Framework
The framework’s building blocks support the following
veriﬁcation process:
1) At design time: A human operator, (e.g., an adminis-
trator or a conﬁguration expert) uses the MeCSV metamodel
to formally specify the MeCSV Reference Model of a given
application domain (cf. Fig. 3 (a)). This reference model is
made of a conﬁguration schema of the domain, a relevant set
171
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

of operational state parameters to monitor and the ofﬂine and
online constraints, necessary to enforce the structural integrity
and operational applicability of conﬁguration instances.
2) At runtime: this reference model will be used by the
Veriﬁcation Service for the automatic evaluation of proposed
conﬁguration instances (cf. Fig. 3 (b)). This online veriﬁcation
can evolve along with management objectives as the deployed
reference model can be updated by human operators.
These two phases will be detailed subsequently in Sections
V and VI, respectively.
IV.
USE CASE
This section illustrates a Message-oriented Middleware
(MOM) case study on which the examples given in the
following sections will be based.
A. Introduction to MOM
A MOM system is a speciﬁc class of middleware that
supports loosely-coupled communications among distributed
applications via asynchronous message passing, as opposed
to a request/response metaphor. They are at the core of a
vast majority of ﬁnancial services. Client applications interact
through a series of servers where messages are forwarded,
ﬁltered and exchanged.
The middleware’s operation involves the proper conﬁgura-
tion of numerous elements such as message servers, message
destinations and directory services. Involved conﬁguration and
reconﬁguration tasks can be classiﬁed into two categories:
ﬁrst, setup operations that include deﬁning the number of
servers, where they will run and the messaging services each
will provide. Second, maintenance operations that use the
platform’s monitoring metrics to adjust initial setups such as
memory resources, message thresholds and users access.
By adding a management interface, an operator can monitor
and tune the system’s performance, reliability and scalability
according to the monitored metrics (e.g., memory resources
and users access) and management objectives.
B. JORAM’s platform
JORAM (Java Open Reliable Asynchronous Messaging)
[19] is an open source MOM implementation in Java. JORAM
provides access to a MOM platform that can be dynamically
managed and adapted, i.e., monitored and conﬁgured for the
purpose of performance, reliability and scalability thanks to
JMX (Java Management eXtensions) management interfaces.
Principal managed elements are message servers that offer
the messaging functionalities such as connection services and
message routing and message destinations that are physical
storages supporting either queue-based (i.e., point-to-point) or
topic-based (i.e., publish/subscribe) communications.
A JORAM platform can be conﬁgured in a centralized
fashion where the platform is made of a single message server
and a distributed fashion, the platform is made of two or more
servers running on given hosts. A JORAM platform can be
dynamically reconﬁgured, message servers can be added and
removed at runtime. A platform conﬁguration is described
by an XML conﬁguration ﬁle according to a provided DTD
(Document Type Deﬁnition).
Fig. 4 shows a centralized conﬁguration example, that
will be further experimented in Section VII (Test Case 1).
This conﬁguration is made of one server, several middleware
services (connection manager, naming service, etc.), two mes-
sage queues and a user’s permissions (note that due to space
limitations, some conﬁguration elements have been discarded).
<?xml version="1.0"?>
<config name="Simple_Config">
 <server id="0" name="S0" hostname="localhost">
  <service class="org.[…].ConnectionManager" args="root root"/>
  <service class="org.[…].TcpProxyService" args="16010"/>
  <service class="fr.[…].JndiServer" args="16400"/>
 </server>
</config>
<JoramAdmin>  
  <InitialContext> […] </InitialContext>
  <ConnectionFactory> […] </ConnectionFactory>
  <Queue name="myQueue" serverId= "0"
         nbMaxMsg="200" dmq="dmqueue">
    <freeReader/> <freeWriter/>
    <jndi name="myQueue"/>
  </Queue>
  <User name="anonymous" password="passwd" serverId="0"/>
  <DMQueue name="dmqueue" serverId = "0">
<freeReader /><freeWriter />
  </DMQueue>
</JoramAdmin>
Fig. 4.
A Joram’s conﬁguration example
C. Veriﬁcation Requirements
The following requirements are considered for the purpose
of the case study, they encompass the manufacturer’s set of
conﬁguration constraints and custom conﬁguration constraints
that guarantee memory performance. A valid conﬁguration of
the platform should provide the necessary messaging features
in order for client applications to communicate efﬁciently.
More precisely,
•
Correct conﬁguration structure: it should respect the
platform’s architecture and the relationships between
the conﬁguration parameters. (Req1)
•
Object discovery and lookup: connection factories and
destinations should be accessible via a naming service,
i.e., the platform should provide an accessible JNDI
service where the reference of the administered objects
should be stored. (Req2)
•
Memory optimization: message queues should not run
low in memory, i.e., queues should not be loaded at
more than 80% of their maximum capacity. (Req3)
V.
MECSV METAMODEL
This section presents the salient features of the metamodel
depicted in Fig. 5. MeCSV is organized in three categories
of constructors: the ﬁrst category is dedicated to conﬁguration
description, the second to operational state data description and
the last for constraint expression.
A. Conﬁguration Data Description
This part of the metamodel, depicted in Fig. 5 - Conﬁgu-
ration, represents concepts to describe conﬁguration data.
172
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

ManagedElement
(depends on 
StateParameter)
StateParameter
Configuration
ConfigurationParameter
ConstrainableElement
ConfigurationMetadata
!!active!:!Boolean
!!level!:!ConstraintLevel
!!language!:!String
!!expression!:!String
Constraint
OfflineConstraint
OnlineConstraint
evaluationContext
ownedConstraint
Conﬁguration
Operational state
Constraint
constrainedElement
ElementConfiguration
ConfigurationComposition
ConfigurationReference
Fig. 5.
Overview of the MeCSV metamodel
Conﬁguration data are generally described in a set of
conﬁguration ﬁles where their structure is speciﬁed through
the setting of some conﬁguration properties with appropriate
values and options.
There are a lot of bindings between the system’s elements
that should be reﬂected in their conﬁguration: for example, the
dependency of a server on its host machine should be speciﬁed
by the coordination of the server’s hostname value with the
machine’s hostname value.
These needs are addressed by the following constructs that
are protocol and tool independent.
1) Conﬁguration Parameter: represents quantiﬁable con-
ﬁguration parameters of managed elements; their expression
deﬁnes the conﬁguration data structure. A message server’s
identiﬁer or hostname information are examples of its conﬁ-
guration parameters.
2) Conﬁguration: allows to coordinate conﬁguration para-
meters and group them in categories. Conﬁguration elements
act as containers for conﬁguration parameters. For example, a
conﬁguration ﬁle can be modeled as a single Conﬁguration,
or for more ﬂexibility, divided into multiple Conﬁgurations.
3) Conﬁguration Dependency: to model bindings between
two conﬁguration elements, a conﬁguration dependency should
be deﬁned between them. It means that a conﬁguration pa-
rameter of some conﬁguration references a whole or a part
of another conﬁguration. Typically, a server’s hostname refer-
ences its host machine’s name information. It is an example
of a conﬁguration dependency between the server and its host.
4) Conﬁguration Composition: this relationship allows to
divide a main conﬁguration into partial conﬁgurations. For
example, a message server’s conﬁguration is logically split
into message services, connection factories and destinations
sub-conﬁgurations. These sub-conﬁgurations are linked to their
parent conﬁguration through a conﬁguration composition.
5) Conﬁguration Metadata: provides a means to specify
metadata for conﬁguration lifecycle management. For instance,
one could want to tag speciﬁc conﬁgurations as default or
initial. Another example is the visited metadata used in the
JORAM platform to mark deployed conﬁgurations.
B. Operational State Data Description
As our work targets a global management environment
where the managed system is both observable and reconﬁgura-
ble, we provide constructs to represent information about ma-
naged elements as well as their monitored state. A knowledge
of the monitored state is required to guide reconﬁgurations
and to assert the operational compliance of proposed conﬁgu-
rations. The following concepts allow to describe operational
state data (Fig. 5 - Operational state).
1) Managed element: represents the notion of managed
element like it is similarly deﬁned in several management
information models. A common pattern is to separate managed
elements representation from conﬁguration modeling; mana-
ged element representations containing monitoring-oriented
information. In the case study, the message server is an
example of managed element.
2) State Parameter: models the traditional operational state
attributes like operational status, statistical data, in sum, any
collected metrics about the system’s operation. The current
queue’s load or the number of active TCP connections, are
examples of state parameters.
In our approach, Managed Element and State Parameter are
the necessary management building blocks for conﬁgurations
and runtime constraints deﬁnition. Their values are supposed
173
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

to be provided by the existing monitoring framework. They
are read-only elements contrary to conﬁguration data.
C. Constraint Speciﬁcation and Management
The following elements allow to deﬁne the constraints that
conﬁguration instances should respect as shown in Fig. 5 -
Constraint.
1) Constraint: represents the restrictions that must be sa-
tisﬁed by a correct speciﬁcation of conﬁgurations according
to the system’s architecture and management strategies. Cons-
traints are boolean expressions in a given executable language.
The Constraint element is subtyped into ofﬂine and online
constraints to support the speciﬁcities of the two types of
conﬁguration validation.
2) Ofﬂine Constraint: represents structural integrity rules
that a correct conﬁguration data structure and composition
of the system should respect. They can be checked either
beforehand at design time or during runtime; they do not
involve any check against operational conditions. For example,
each message destination should have a JNDI name (in order
to be looked up by client applications).
3) Online Constraint: deﬁnes rules for the operational
applicability enforcement. Online constraints use state pa-
rameters values, their evaluation tests the conﬁguration data
against convenient state parameters. For instance, a queue’s
maximum capacity should be kept greater than the current
number of pending messages.
4) Constraint Lifecycle Management:
Constraints also
have additional attributes for their life cycle management:
they have a “constraint level” attribute to modulate their
strictness. In particular, this allows to assign a severity level
to the different constraints (e.g., high, medium, low) and an
“active” attribute to activate or deactivate them depending
on the operational context and management strategies (e.g.,
critical vs non-critical).
MeCSV has been formally speciﬁed as a UML proﬁle [20].
UML constructs have been tailored to the MeCSV concepts
to enable its usage in available UML modelers and to ease
the adoption of the MeCSV language. Indeed, UML is well
supported by many modeling tools and widely accepted as a
standard modeling language.
D. Reference Model Speciﬁcation Process
The speciﬁcation process is a two-step process that occurs
at design time: ﬁrst the representation of the reference model
structural classes, that is the representation of the conﬁguration
data and state data structure, and second, the expression of
ofﬂine and online constraints.
The completion of these two steps provides the MeCSV
reference model of a given management domain that is to
be registered into the veriﬁcation service. It will be used at
runtime to check decided conﬁgurations.
1) Direct Modeling: Direct modeling is the general process
for a MeCSV Reference Model speciﬁcation. Operators install
the MeCSV metamodel into a compliant model editor such
as Eclipse Model Development tool (ECLIPSE MDT) and use
MeCSV constructs to represent each part of the subsequent
reference model.
deﬁne conﬁguration 
classes
deﬁne state classes
express constraints
Reference 
Model
MeCSV
Metamodel
Fig. 6.
Reference model design process: direct modeling
As it is shown in Fig. 6, they ﬁrst describe the conﬁguration
parameters and state parameters organized into classes with
convenient composition and dependency associations, then
they specify the ofﬂine constraints that constrain the pure struc-
ture of conﬁguration information and the online constraints
that help evaluate the compliance of a given conﬁguration
information with the execution context at hand.
2) Model Transformation: This general speciﬁcation pro-
cess slightly differs when a management information model
already exists (Fig. 7).
deﬁne mapping rules
generate structural 
classes
express constraints
Reference Model
Transformation
Rules
Existing 
management 
model
MeCSV
Metamodel
Fig. 7.
Reference model design process: model transformation
Indeed, the ﬁrst step can be automated, mapping rules can
be directly deﬁned between the speciﬁc management model
and MeCSV, thus translating the legacy constructs into the
related MeCSV ones. For example, one could use model-driven
techniques such as model to model transformation or reﬂection
for the implementation of such mapping rules. The second step
of constraints expression remains identical.
174
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

VI.
VERIFICATION SERVICE ARCHITECTURE
This section details the architecture of the runtime veriﬁ-
cation service and the resulting veriﬁcation process.
A. Overview
Fig. 8 gives an overview of the main components of
the veriﬁcation service, a veriﬁcation engine and a model
repository, offering two interfaces, the veriﬁcation and edition
interfaces respectively for the usage of the service and the
online edition of MeCSV reference models. The veriﬁcation
interface is supported by the veriﬁcation engine and the edition
interface enables modiﬁcation of reference models stored in the
model repository.
Reference model  
instances (XMI)
Ref. Model 
Repository
Management 
System
Veriﬁcation  Results
Current
state values
Conﬁg.
instances 
Operator
Reporting Generator
Constraint Checker
Model Processor
Veriﬁcation Engine
Fig. 8.
Online Veriﬁcation Service
1) Veriﬁcation Interface: This interface is to be used by a
management system to request the veriﬁcation of conﬁguration
instances at runtime. It offers several functions, listed in Table
I, that allow to trigger two types of veriﬁcation: i) a complete
veriﬁcation where every existing constraint, in active state, is
veriﬁed or ii) a selective veriﬁcation where a speciﬁc subset
of constraints are veriﬁed according to their type and severity
level (e.g., online constraints with a highest severity level).
The veriﬁcation engine is designed to process model in-
stances conforming to an existing MeCSV reference model
classes. Consequently, every API call must contain conﬁgura-
tion instances and running operational state values described
in a MeCSV-compliant format. Each call returns a veriﬁcation
result object including potential veriﬁcation errors.
2) Edition Interface: This interface allows the registration
of MeCSV reference models to the model repository. It also
supports the online modiﬁcation of registered reference mod-
els. Constraints can thus be added, removed, their status and
severity can also be updated any time (Table I).
Note that the reference model is reloaded each time it
is updated, allowing both the conﬁguration structure and the
set of constraints to be modiﬁed at runtime. This feature is
particularly useful to add or remove constraints according to
the management requirements that may change over time.
3) Reference Model Repository:
The reference model
repository stores MeCSV reference model classes and cons-
traints to be processed during the veriﬁcation. It also supports
the usual creation, update, deletion and querying functions
of a database, to adapt the model to evolving management
requirements.
4) Veriﬁcation Engine: The veriﬁcation engine is the sys-
tem component that checks provided conﬁguration instances
and reports inconsistencies. It provides three capabilities:
•
A model processor, capable of analyzing and parsing
model elements. It handles veriﬁcation requests and
ensures the existence of a related MeCSV reference
model for received conﬁguration instances.
•
A constraint-checker, capable of checking dynamically
received conﬁguration instances against related refe-
rence model classes and available set of constraints.
If a constraint is not satisﬁed, it notiﬁes found errors
to a reporting submodule.
•
A reporting generator, capable of issueing an in-
dication that contains ﬂawed elements and violated
constraints.
The veriﬁcation engine is built-upon the open source
Dresden OCL library [21]. Dresden OCL includes an OCL
parser and interpreter that we have enriched with MeCSV
speciﬁc features such as ofﬂine and online constraints
differentiation and selective constraint checking, and with
new capabilities like runtime modiﬁcation of reference model
constraints.
The Veriﬁcation Service thus allows an existing mana-
gement system to request veriﬁcation of live conﬁguration
changes, It supports a single tenant as well as a multi tenant
usage.
B. Online Veriﬁcation Process
The following sequence diagram (Fig. 9) shows the interac-
tions involved when a management system requests veriﬁcation
of some conﬁguration instances. Two types of interactions
can be identiﬁed: internal interactions between the decision
and the monitoring modules of the management system and
external interactions between the management system and the
veriﬁcation service.
Management System
Veriﬁcation result
Veriﬁcation Service
State parameters values
retrieval
Veriﬁcation request
Monitoring
Decision
MeCSV reference instances creation
(1)
(2)
(3)
(4)
Fig. 9.
Online Veriﬁcation Process
When the decision module elects a conﬁguration to verify,
it ﬁrst interacts with the monitoring module to retrieve current
values of deﬁned state parameters, Fig. 9 - (1), then it trans-
forms those data into MeCSV-compliant instance models, Fig.
9 - (2), and sends them to the veriﬁcation service, Fig. 9 - (3).
The veriﬁcation service checks received conﬁguration in-
stances both structurally and according to retrieved operational
state instances of the step (2) and returns veriﬁcation results,
Fig. 9 - (4). It thus enriches management systems with a
runtime conﬁguration veriﬁcation capability.
175
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

TABLE I.
API CALLS SUPPORTED BY THE VERIFICATION AND THE EDITION INTERFACES
Interface
API call name
Functionality
Veriﬁcation Interface (access to the Veriﬁcation Engine)
validateAll()
Check given conﬁgurations against all existing constraints.
validateByConstraintType()
Check given conﬁgurations against constraints of a certain type, e.g., online only.
validateByConstraintLevel()
Check given conﬁgurations against constraints of a certain severity, e.g., fatal.
validateByConstraintFeatures()
Check given conﬁgurations against constraints of a certain type and severity, e.g., online and fatal.
Edition Interface (access to the Reference Model Repository)
registerReferenceModel()
Register a MeCSV reference model.
updateConstraintStatus()
Edit the status of a given constraint, e.g., deactivate a constraint.
updateConstraintLevel()
Edit the severity level of a given constraint, e.g., decrease the severity.
updateConstraintFeatures()
Edit both the status and the severity level of a given constraint.
VII.
EXPERIMENT
This section describes the application of the veriﬁcation
framework to the JORAM case study presented in Section IV.
Sections VII-A and VII-B describe how we have used the
framework at design time to specify a reference model for the
case study and how this reference model has been exploited
at runtime to execute veriﬁcation. Section VII-C evaluates this
prototype experiment and Section VII-D discusses observa-
tions and results.
A. Design time: Reference Model Speciﬁcation
Following the direct modeling speciﬁcation methodology,
exposed in Section V-D, we installed the MeCSV Eclipse
Plugin in the ECLIPSE MDT model editor.
The different conﬁguration concepts of Joram’s DTD gram-
mar have been modeled as adequate MeCSV-stereotyped UML
classes, attributes and associations forming the conﬁguration
information model of the platform.
Constraints have been manually derived from requirements
1, 2 and 3 (cf. Section IV) and expressed in OCL. The follow-
ing are examples of constraints that have been implemented:
•
Each server should have an unique server id.
•
Each server should provide a message destination and
a connection factory (administered objects).
•
Each administered object should have a JNDI name.
•
A directory service (JNDI) should be available.
•
The JNDI service should be activated and running.
•
A queue should not be loaded at more than 80% of
its maximum capacity.
The last two constraints are online constraints, they can
only be evaluated at runtime, against operational conditions,
thus requiring access to monitored data. This operational data
has been identiﬁed (e.g., servers’ operational status, queues’
pending messages size, current number of client connections)
and modeled as classes and attributes thanks to MeCSV
ManagedElement and StateParameter stereotypes.
Fig. 10 shows an excerpt of the deﬁned MeCSV reference
model. This reference model subset contains the high-level
conﬁguration structure of a message server including a mes-
sage queue, the ofﬂine and online constraints that should be
respected and depending state parameters necessary to enable
the operational applicability veriﬁcation.
«ConfigurationParameter»	  jndiName
«ConfigurationParameter»	  nbMaxMsg
«Configuration»
QueueConfig
«ConfigurationParameter»	  serverId	  
«ConfigurationParameter»	  serverName
«ConfigurationMetadata»	  	  configType
«Configuration»
ServerConfig
«ConfigurationComposition»
«ConfigurationReference»
«StateParameter»	  pendingMessageCount
«StateParameter»	  nbMsgsSentToDMQSinceCreation
«ManagedElement»
Queue
«StateParameter»	  status
«StateParameter»	  engineAverageLoad1
«ManagedElement»
Server
«OnlineConstraint»
OperationalApplicableNbMaxMsg
{
	  	  	  {active	  =	  true}
	  	  	  {level	  =	  ConstraintLevel.ERROR}
	  	  	  {language	  =	  OCL}
	  	  	  {body	  =	  self.nbMaxMsg	  *	  0.8	  >	  
	  	  	  	  	  	  	  	  	  	  	  self.managedElement.pendingMessageCount}
}
«OfflineConstraint»
QueueIntegrity
{
	  	  	  {active	  =	  true}
	  	  	  {level	  =	  ConstraintLevel.FATAL}
	  	  	  {language	  =	  OCL}
	  	  	  {body	  =	  self.jndiName	  <>	  null	  
	  	  	  	  	  	  	  	  	  	  	  AND	  self.nbMaxMsg	  >	  0}
}
«ElementConfiguration»
«ElementConfiguration»
Fig. 10.
Excerpt of the MeCSV reference model for a MOM application
domain
B. Runtime: Online Veriﬁcation Process
1) Dedicated Management System: For the veriﬁcation
process, we have set up a dedicated management system built
upon the JMX management interfaces provided by the JORAM
platform. The JMX interfaces comprise a monitoring interface
allowing to collect metrics of interest about the running
platform and a conﬁguration interface capable of tuning the
platform’s conﬁguration at runtime. Messaging servers, as
well as messaging destinations, can be dynamically added or
removed.
This management system is composed of a monitoring
module and a decision module. The decision module is capable
of choosing a conﬁguration at runtime, requesting running
operational data from the monitoring module and transforming
these data into MeCSV-compliant instance models to be sent
to veriﬁcation.
In the same time, we implemented several client applica-
tions exchanging a high load of ﬁctive messages to act on
the monitored metrics (e.g., servers’ average message ﬂows,
destinations’ number of pending messages).
2) Veriﬁcation Process: The veriﬁcation process starts with
the initialization of the veriﬁcation service with the deﬁned
reference model. As for the management system, the deci-
sion module embeds different pre-deﬁned conﬁgurations. At
runtime, the decision module arbitrarily switches from one
conﬁguration to the other and requests the veriﬁcation of its
choice before deploying them.
Once the target conﬁguration is selected, the management
system follows the process previously illustrated in Fig. 9. It
ﬁrst retrieves running state values from the monitoring module,
176
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

then translates them in instances conforming to the deﬁned
reference model and ﬁnally requests their veriﬁcation.
C. Experimental Setup
The goal of the experiments was both to test the ability
of the MeCSV metamodel to serve as a formal speciﬁcation
notation and to evaluate the effectiveness of the veriﬁcation
service for processing online conﬁguration checking against
the deﬁned reference model. We also measured the execution
time of the veriﬁcation process.
We performed our experiments on three different platform
conﬁgurations varying in size and complexity, namely the
number of system’s elements (messaging servers, available
services, message queues) and dependencies between them.
•
The ﬁrst conﬁguration (Test Case 1) is a centralized
messaging server offering basic message features for
a total of nine conﬁgurable elements.
•
The second (Test Case 2) consists of two messaging
servers (about eighteen conﬁgurable elements).
•
The third (Test Case 3) has three messaging servers
and holds thirty conﬁgurable elements.
•
To test the scalability of the validator, we deﬁned
a fourth conﬁguration (Test Case 4), made of 300
managed elements, that has been programmatically
tested with random state values variations.
Witness veriﬁcation tests on correct conﬁguration instances
have also been conducted for each case.
The summary of test cases data is shown in Table II.
TABLE II.
SUMMARY OF TEST CASES DATA
Nb. servers
Nb. managed
elements
Nb. conﬁguration
parameters
Nb. state
parameters
Test case 1
1
9
57
25
Test case 2
2
18
110
64
Test case 3
3
30
197
103
Test case 4
30
300
1970
103
For each proposed conﬁguration instance, we gradually
ran complete veriﬁcations with ten, ﬁfty and one hundred
OCL constraints with a ratio of 80% ofﬂine constraints for
20% online constraints. For each veriﬁcation request, we took
100 measurements of the execution time in milliseconds and
computed the arithmetic mean.
Furthermore, we test selective veriﬁcations requesting the
evaluation of speciﬁc subsets of constraints ﬁltered according
to their type and severity. We also test the online edition
of constraints, verifying that the veriﬁcation engine considers
their modiﬁcation.
The tests were run on a Intel R
⃝ CoreTM 2 Duo with 2.66
GHz and 4 Gigabytes of main memory.
D. Results and Discussions
1) Feasability: The veriﬁcation service has been success-
fully tested: the received instances were checked against the
stored reference model with both ofﬂine and online constraints
violations detected and notiﬁed, both in the case of complete
as well as selective veriﬁcation requests. This permitted the
decision module not to apply non-valid conﬁgurations.
The detection of online constraints violations, especially in
the case of witness veriﬁcation tests, conﬁrms our thesis about
operational applicability veriﬁcation.
A ﬁrst conclusion that can be drawn from these tests is
the effectiveness of the veriﬁcation service, thus the ability for
MeCSV to be used to specify a real-life system’s conﬁguration
schema and subsequent constraints for online conﬁguration
veriﬁcation.
2) Veriﬁcation Time: Concerning the veriﬁcation time, the
veriﬁcation service has a noticeable but reasonable initial-
ization overhead where the MeCSV reference classes and
constraints are registered, but after this time, it processes
constraint evaluations quickly.
Fig. 11.
Veriﬁcation overhead for the ﬁrst three test cases
The overall checking time for the three deployed scenarios
is under 700 ms, which is very encouraging. It comprises the
time taking to check the received instance conformance to
the reference model, the constraint evaluation time and the
reporting time (negligible).
A very important result lies in the effect of the number of
system elements and the number of OCL constraints on the
veriﬁcation time. As shown in Fig. 11, the execution time is
not proportional neither to the number of system’s elements
nor to the number of constraints. For example, while the size
of elements quintuples from test case 1 (6 managed elements)
to test case 3 (30 managed elements), their average veriﬁcation
time ratio hardly doubles (ratio is 1.73). Similarly, although the
number of constraints increased by ten, the average veriﬁcation
cost is barely multiplied by 1.5. Further analysis of collected
measures showed that constraints were checked in linear time.
We can conclude that in small conﬁgurations, the number
of system’s elements or the number of constraints scarcely
affects the veriﬁcation performance.
Furthermore, we observed that the error rate is not a factor
impacting the veriﬁcation time. An error-free conﬁguration
takes the same time as a highly erroneous conﬁguration.
3) Scalability of the approach: The fourth case offers
particular insights on the performance of the approach on a
177
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

very large conﬁguration (Fig. 12). The worst case veriﬁcation
time of 30 message servers (2000 managements parameters
and 100 constraints) is far below 2 seconds, which is still
an acceptable time for a runtime veriﬁcation program. This
progression conﬁrmed our ﬁrst conclusion that the veriﬁcation
performance is not proportional to the size of conﬁguration
elements. While system’s elements increased by 50 (from 6
managed elements to 300 managed elements), veriﬁcation time
increased by less than 5.
Fig. 12.
Veriﬁcation overhead for the scalability test case (Test Case 4)
The complete veriﬁcation process overhead is very encour-
aging regarding the added capability to detect conﬁguration
errors at runtime. Indeed, even though conﬁguration instances
can be veriﬁed beforehand at design time, the difﬁculty to
predict the varying operating conditions can compromise the
success of runtime conﬁguration changes.
Altogether, these experimental results conﬁrm the impor-
tance of online conﬁguration veriﬁcation and show the feasi-
bility of our veriﬁcation framework to enrich a dynamically re-
conﬁgurable platform with runtime conﬁguration veriﬁcation.
VIII.
CONCLUSION AND FUTURE WORK
Designing lightweight online veriﬁcation approaches is a
critical requirement if we are to build reliable self-adaptive
management systems and ease their adoption. This is funda-
mental as misconﬁgurations can be prejudicial to the proper
operation of the system.
This paper presented a veriﬁcation framework including an
online conﬁguration veriﬁcation service relying on a high-level
speciﬁcation language named MeCSV. The framework aims to
enrich existing management systems with platform-neutral and
ﬂexible conﬁguration veriﬁcation capabilities based not only
on structural checks but also on running operational conditions.
We then described a methodology for using the framework
from design time to runtime. We applied this methodology
on a real-life message-oriented middleware case study where
we successfully modeled the conﬁguration schema, validity
constraints and operational state data in a platform-independent
fashion. This reference model was used by the veriﬁcation ser-
vice to process veriﬁcation requests of conﬁguration instances
in viable time.
A series of veriﬁcation experiments during reconﬁgurations
allowed us to discuss results and observations demonstrating
the feasibility of the approach. In future work, we intend to
further experience the methodology and integrate more legacy
systems so that we can ease the integration process and lower
subsequent costs.
REFERENCES
[1]
L. Akue, E. Lavinal, and M. Sibilla, “A model-based approach to
validate conﬁgurations at runtime,” in 4th International Conference on
Advances in System Testing and Validation Lifecycle (VALID), 2012,
pp. 133–138.
[2]
J. O. Kephart and D. M. Chess, “The Vision of Autonomic Computing,”
Computer, vol. 36, no. 1, pp. 41–50, 2003.
[3]
J. Strassner, N. Agoulmine, and E. Lehtihet, “Focale–a novel autonomic
computing architecture,” in Latin–American Autonomic Computing
Symposium, 2006.
[4]
L. Akue, E. Lavinal, and M. Sibilla, “Towards a Validation Framework
for Dynamic Reconﬁguration,” in IEEE/IFIP International Conference
on Network and Service Management (CNSM), 2010, pp. 314–317.
[5]
M. MacFaden, D. Partain et al., “Conﬁguring networks and devices
with Simple Network Management Protocol (SNMP), RFC 3512,” IETF
Request for Comment,[Online], pp. 1–69, 2003.
[6]
B. H. Cheng, R. De Lemos et al., “Software engineering for self-
adaptive systems: A research roadmap,” in Software engineering for
self-adaptive systems, 2009, pp. 1–26.
[7]
P. Anderson and E. Smith, “Conﬁguration tools: working together,” in
19th conference on Large Installation System Administration (LISA)
Conference, 2005.
[8]
N. Samaan and A. Karmouch, “Towards autonomic network manage-
ment: an analysis of current and future research directions,” Communi-
cations Surveys & Tutorials, IEEE, vol. 11, no. 3, pp. 22–36, 2009.
[9]
D. Oppenheimer, A. Ganapathi, and D. A. Patterson, “Why do internet
services fail, and what can be done about it?” in Proceedings of the
4th conference on USENIX Symposium on Internet Technologies and
Systems, ser. USITS’03, 2003, pp. 1–1.
[10]
“CIM Schema version 2.29.1 - CIM Core,” Distributed Management
Task Force (DMTF), June 2011.
[11]
M. Bjorklund, “YANG - A Data Modeling Language for the Network
Conﬁguration Protocol (NETCONF),” Internet Engineering Task Force
(IETF), RFC 6020, October 2010.
[12]
A. V. Konstantinou, D. Florissi, and Y. Yemini, “Towards Self-
Conﬁguring Networks,” in DARPA Active Networks Conference and
Exposition (DANCE), 2002.
[13]
D. Agrawal, J. Giles et al., “Policy-based validation of san conﬁgura-
tion,” in 5th IEEE International Workshop on Policies for Distributed
Systems and Networks (POLICY) 2004, 2004, pp. 77–86.
[14]
E. Genc¸ay, C. Sinz et al., “SANchk: SQL-based SAN conﬁguration
checking,” IEEE Transactions on Network and Service Management,
vol. 5, no. 2, pp. 91–104, 2008.
[15]
P. Goldsack, J. Guijarro et al., “The SmartFrog Conﬁguration Manage-
ment Framework,” ACM SIGOPS Operating Systems Review, vol. 43,
pp. 16–25, 2009.
[16]
T. Hinrichs, N. Love et al., “Using object-oriented constraint satisfaction
for automated conﬁguration generation,” in DSOM, 2004, pp. 159–170.
[17]
L. Ramshaw, A. Sahai et al., “Cauldron: a policy-based design tool,” in
7th IEEE International Workshop on Policies for Distributed Systems
and Networks, 2006, pp. 113–122.
[18]
T. Delaet and W. Joosen, “PoDIM: A Language for High-Level Conﬁ-
guration Management,” in LISA, 2007, pp. 261–273.
[19]
“JavaTM Open Reliable Asynchronous Messaging (JORAM),” OW2
Consortium, June 2013. [Online]. Available: http://joram.ow2.org/
[20]
“OMG Uniﬁed Modeling Language (OMG UML), Superstructure
V2.1.2,” november 2007.
[21]
“Dresden OCL,” TU Dresden, Software Technology Group, June 2013.
[Online]. Available: http://www.dresden-ocl.org/
178
International Journal on Advances in Systems and Measurements, vol 7 no 1 & 2, year 2014, http://www.iariajournals.org/systems_and_measurements/
2014, © Copyright by authors, Published under agreement with IARIA - www.iaria.org

