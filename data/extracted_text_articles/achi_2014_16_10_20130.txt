BOrEScOPE – Exoskeleton for Active Surgeon Support during Orthopedic Surgery 
P. P. Pott, M. Hessinger, R. Werthschützky,  
H. F. Schlaak 
Institute of Electromechancial Design 
Technische Universität Darmstadt 
Darmstadt, Germany 
p.pott@emk.tu-darmstadt.de 
E. Nordheimer, E. Badreddin,  
A. Wagner 
Institute of Computer Engineering, Automation Lab 
Heidelberg University  
Heidelberg, Germany 
achim.wagner@ziti.uni-heidelberg.de
 
 
Abstract— The use of robots in a medical environment is a 
challenging task not only for system development but also for 
the actual application in this demanding environment. Robots 
are used to enhance surgery quality in terms of precision, 
application of new therapies, or to improve ergonomics - only 
to name a few reasons.  The approach described in this paper 
is to provide a lightweight exoskeleton worn by the orthopedic 
surgeon. It is intended to be used during drilling tasks at the 
spine and to enhance precision as the surgeon is led by optic, 
acoustic, and haptic perception. The parallel flux of forces and 
the inherently mobile robot base allow the surgeon to directly 
maintain responsibility for surgery. Not only the mechanical 
design of the system but also the control is decomposed into 
several levels. To do so, a behavior-based approach is used. 
The system’s design criteria are briefly described and first 
results are presented. The exoskeleton is composed of an 
anthropomorphic arm actuated by twisted-string actuators. 
This leads to a lightweight construction. To provide sufficiently 
fast and precise information about the spatial position and its 
time derivations, optical and inertial tracking is used. A User 
Guidance Opto-Acoustic Display is utilized to provide the 
surgeon with information on position and orientation of the 
tool in six degrees of freedom with respect to the desired 
trajectory. First experimental results derived that the intended 
workspace meets the surgical requirements and the user 
guidance system enables the surgeon to follow the desired 
trajectory by intuitive user guidance. 
Keywords- exoskeleton; orthopedic surgery, human-machine 
interaction; twisted-string actuation; behavior-based system 
decomposition 
I. 
 INTRODUCTION 
Medical robotic systems for the use in the operating room 
(OR) have been under development for more than 20 years. 
Early systems for neurosurgery [1, 2] and orthopedics [3] 
proved usefulness and even made it for commercialization. 
However, their impact was not as high as expected [4]. In the 
last ten years, many new robotic systems have been 
developed and even introduced to the market. The most 
popular is the daVinci Surgical System by Intuitive Surgical, 
Inc., Sunnyvale, CA, USA. Nevertheless, there are hundreds 
of different systems and many reviews to learn more about 
the field of robotics. 
Aim of our work is to develop and to design a robotic 
interaction system for orthopaedic surgery. Here, the surgeon 
has to fulfil delicate tasks like drilling the spine while 
maintaining high precision in the sub-millimeter range. 
Placing a robotic arm next to the OR table [5], the ceiling [6] 
or even on the patient [7] does not seem to be appropriate. 
Earlier work of our group showed the high potential of 
placing the robot in the user’s hand [8, 9] to compensate 
tremor and involuntary movements both from surgeon and 
patient [10]. This robotic system provides precise movement 
and ease-of-use. However, its size and weight is not 
appropriate for longer deployment. Instead of using a passive 
balancing system we decided to develop a new system worn 
at the surgeon’s arm near to his or her centre of gravity to 
improve ergonomic handling. In the following sections, we 
will present and describe the system’s concept, basic 
components, the control strategy, and first results.  
II. 
SYSTEM DESIGN 
In this paper, we provide an overview of the 
BOrEScOPE system. It comprises an external optical high-
speed tracking system for six degrees of freedom (DOF) 
position and orientation measurement fused with data from 
an inertial measurement unit (IMU), the robotic system 
including actuation and sensor systems and the mechanical 
part, the control hard- and software, and finally an opto-
acoustic display unit for communication and user guidance. 
In the following sections, we will address these sub-systems 
and describe the control strategy.  
A. Robotic System 
The robotic system of the BOrEScOPE basically consists 
of an exoskeleton for the (right) arm of the surgeon including 
shoulder and wrist (Figure 1). All together seven degrees of 
freedom (DOF) are realized to provide good compliance 
with the human anatomy and the same dexterity. The range 
of motion of the shoulder (170° abd./add.; 150° flex./ex.; 
180° inw./outw. rotation), elbow (100° flex.), and wrist 
(150° pron./sup.; 20° ulnar flex./ex.; 120° flex./ex.) joints has 
been derived experimentally. Shoulder elevation is not 
considered as the abduction angle is reduced to 80°. The arm 
is attached to a backpack that is carried by shoulder and hip 
harness.  
To achieve a lightweight mechanism, the actuators are 
placed in the backpack and force is transmitted via Bowden 
cables. The actuators are based on the twisted string-concept 
[11],  using a bunch of at least two strings that are drilled 
axially by a DC motor. This causes the string-arrangement to 
shorten and produces a rather high force. Using a lightweight 
17 mm 
DC 
motor 
(1741 024 CXR 
by 
Faulhaber, 
377
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

Schönaich, Germany) with 8 mNm nominal torque and three 
strings, a force of 130 N can be produced. Also, no 
traditional gear reduction is needed leading to very quiet 
operation. As only pulling forces can be produced, an 
antagonistic arrangement is used. Sensors are deployed at the 
string actuator to measure shortening and at the actuated 
joint to provide precise angle information. Doing so, the 
elasticity of the Bowden cable is used to derive a series-
elastic actuator (SEA) [12]. Prior work of our group showed 
good results using SEA in human machine interaction [13]. 
The inherent compliance allows zero-torque control and 
robust reaction to dynamic external forces. This reduced 
stiffness “feels better” than a conventional robotic arm. 
 
 
Figure 1 Overview of the robotic subsystem of the BOrEScOPE. 
The system is designed to carry a 2.5 kg payload and 
compensate the gravity force of the human arm up to a body 
weight of 80 kg. Shoulder and elbow joints can provide 
speeds up to 6 rad/s. The static force to guide the user can be 
up to 10 N at the handle. 
B. Opto-Acoustic Display 
One of the challenges in developing a user-friendly 
Graphical User Interface (GUI) for the Human Machine 
Interaction (HMI) is to facilitate an intuitive operation and 
control of the technical system. The basic requirements are to 
reduce the possible error occurring during user interaction 
with the machine and to navigate the user. Since the tool 
position is influenced by the human tremor (frequency range 
of several Hertz), and since latencies in the feedback-loop 
must be avoided, a dynamical tool tracking is proposed, 
consisting of a combination of optical and inertial motion 
measurements. Based on these data the User Guidance Opto-
Acoustic Display (UGOAD) is realized, which navigates the 
user to the goal pose (position and orientation), displays the 
processing trajectory, and gives a feedback of pose errors. 
Display and measurement latency has to be kept low to 
reduce phase shift in the feedback loop and to provide stable 
overall system behavior. The goal 6D poses as well as the 
processing trajectories are provided from planning data, 
which are defined by the surgeon using 3D patient imaging 
(CT). According to the requirements, a first UGOAD 
functional prototype was realized (see Figure 2).  
 
 
Figure 2 Experimental environment for the first prototype of the opto-
acoustic display deployed in the BOrEScOPE system. 
The experimental handheld drilling tool (Figure 2, on the 
left) was equipped with three active optical LED markers  
and an IMU device (Crista IMU, Cloud Cap Technology, 
Inc.). The monitor (Figure 2, on the right) can provide both 
optical and acoustic information. In the final implementation, 
a miniaturized screen will be attached directly to the tool. 
The optical tracking system (Krypton K600, Nikon 
Metrology, Inc.) (Figure 2, in the background) is used in 
addition to the Crista IMU to collect the motion data of the 
handheld device. Data fusion is accomplished using Kalman-
filter based methods [14]. The resulting filtered variables for 
position, orientation, velocities, angular rates, and linear 
acceleration are utilized for navigation purposes and 
provided to the lower levels. In later development stages the 
complete handheld device can be mounted and aligned to the 
exoskeleton. The 6 DOF user navigation is realized by 2D 
representations of the tool pose on the UGOAD which is 
described below in detail. 
C. Control Structure 
The control system is developed according to Nested 
Recursive Behavior-based Control (RNBC) structure [15]. 
Accordingly, the hardware is realized as a number of 
components (Figure 3) interacting on diverse behavioral 
levels. In contrast to a one-to-one mapping of the behavior 
levels, one single behavior level can be distributed on 
multiple hardware components. Several behavior levels may 
be aggregated in one single hardware device. In the latter 
case, behaviors are realized as software processes. For the 
BOrEScOPE realization, the upper levels, i.e., mission, 
navigation and trajectory control, are realized as software 
378
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

processes integrated into a QNX-based (QNX Software 
Systems Ltd.) real-time PC. The behavior levels for position 
control, collision avoidance, velocity control and force 
control are realized using an embedded PC based on xPC 
Target™ (The Mathworks, Inc.). The xPCTM Target PC is 
interconnected with the QNX PC via a serial link and to the 
motor controllers (type EL7342 by Beckhoff Automation, 
Verl, Germany) via EtherCAT. The motor controllers 
directly control the currents of the actuators. Position 
constraints for link actuation are calculated using the robot 
kinematics in order to avoid internal collisions. Additionally, 
external ultrasonic (US) sensors can help to avoid collisions 
of the robot with its environment. A milling tool can be 
aligned with the patient coordinate frame and a target bone 
can be processed with the preplanned trajectory.  
 
Figure 3 System architecture of the BOrEScOPE system 
To achieve compliance with the behavior of the operator, 
three interaction modalities are realized: The opto-acoustic 
display provides optical (1) and acoustical output (2) while 
the robot provides haptic feedback (3). The control 
algorithm’s input is a virtual static force field generated 
around the main axis of the bore and depending on the actual 
distance, speed and direction of movement of the 
BOrEScOPE’s end effector [16, 17]. When the patient is 
moving, this force field also moves in space. To achieve 
smooth and comfortable movement, the real force acting 
between BOrEScOPE and the wrist are measured. The user 
tries to minimize the forces following the BOrEScOPE 
system. 
Using this algorithm, the 7 DOF redundant robotic 
system can be controlled easily and intuitively while 
maintaining the human’s dexterity. As both, the linear 
displacement at the actuators and the angular displacement in 
the actual joints are measured and controlled, serial-elastic 
actuation is achieved. 
III. 
RESULTS 
The BOrEScOPE system is still under development. The 
two main subsystems opto-acoustic display and robotic 
system show first and promising results that are described in 
the following. 
The measured peak response time of hand movement as a 
result of optical stimuli amounts to around 250 ms. The 
requirement of visually provided information should be 
adapted on this process time. The reaction time of the 
UGOAD as well as the robot must be kept within a limit of 
10-20 ms (10-20-fold faster). Thus, the calculation of 
graphical contents and of the control algorithm should 
terminate within this time. Based on this knowledge the 
sensor data acquisition, the global-control loop, and UGOAD 
were implemented as real-time processes in the QNX 
Neutrino operating system. 
Figure 4 Three operate zones of the UGOAD: a) No displacement, b) 
Translational displacement in x-axis, c) Rotational displacement around x- 
and y-axis, d) Displacement in view axes 
The first display prototype was realized by a 2D 
representation of the 6 DOF pose data. Accordingly, the 
actual and the reference pose of the tool are shown in the x-
y-plane of the display. The z-axis is perpendicular to the 
display plane. In order to intuitively capture the 6 DOF 
contents in the 2D image a two body projection metaphor is 
realized. In this imagination one small colored octagon is 
mounted virtually at the tool tip and one large colored 
octagon at the rear of the tooling machine. Looking from 
above in direction of the drilling tool (z-axis) corresponds to 
looking through the large octagon and through the small 
octagon on the tool tip, which is in the center of both. The 
small black octagon with crosshairs and large black octagon 
are virtually mounted at the target (reference) pose. If the 
tool is aligned (Figure 4a), the small octagons are aligned 
and the large colored octagon has its original size in the 
central position. If the tool is misaligned in the x-axis (Figure 
4b) the large colored octagon is shifted correspondingly in 
the x-direction. The same holds for the y-axis. A 
misalignment in the z-axis is represented by the size of the 
large colored octagon. A deviation in the positive z-direction 
means that the tool is too far away from the user, which is 
shown by the reduced size relatively to the large black 
octagon. Negative deviation means, that the tool is too 
narrow, displayed as increased size. A deviation in the 
orientation is displayed as shift of the small colored octagon. 
379
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

For example, if the tool is turned around the y-axis (Figure 
4c), the tool tip is moved in x-direction, displayed as x-axis-
shift of the small colored octagon. The corresponding 
principle holds for the orientation error around the x-axis. 
Here, a y-shift of the small octagon can be observed. The 
orientation error around the z-axis is directly displayed as a 
rotation of the colored octagons around their centers.   
As additional element, a rectangular border is shown in 
green color, which indicates that the pose is in the desired 
workspace. If the tool approximates the limit positions for at 
least one axis, the color changes firstly from green to orange, 
showing that a user intervention is required.  In critical 
vicinity to the constraints the color changes to red 
(Figure 4d) asking for urgent motion actions.  The color 
change is supported by changing the waveform of the 
acoustic channel. 
IV. 
DISCUSSION AND CONCLUSION 
To set up a robotic system with close human-machine 
interaction in a medical environment is a delicate task. 
However, the project is still in progress and work starting 
from the presented concept to the final realization is still 
ongoing. We managed to define interfaces between the 
robotic system and the human operator not only 
mechanically but also visually and using the audio channel. 
Smooth and comfortable working with the system is strongly 
dependent on low latency, high update rates, and actually 
predictable behavior. Here, our system will have to deal with 
some drawbacks as the force field generation is depending 
on data quality of the optical tracking system which tends to 
jitter and noisy signals. This will be addressed in future by 
using redundant LED markers and by combining data of an 
inertial tacking system. Furthermore, the quality of real-time 
data transfer will be improved. 
First tests with users demonstrate that the 6 DOF can be 
captured by the majority of subjects without further 
explanation. Thus, the usage of the UGOAD as a feedback in 
the human interaction with the machine implicates a massive 
improvement of human performance to achieve the common 
tasks and there is every indication that the developed 
UGOAD insure an intuitive operation and an intuitive 
control. 
Mechanically, the robot will have to cope with force-
depended friction in the Bowden cables. This issue will be 
addressed by a model-based controller with individual 
parameters for each axis.  
ACKNOWLEDGMENT 
The work is funded by the German Federal Ministry of 
Education and Research under grants 16SV5773 and 
16SV5774. 
 
 
 
 
 
 
REFERENCES 
[1] 
Y. Kwoh, et al., "A new computerized tomography-aided robotic 
stereotaxis system," Robotics Age, 1985, pp. 17-22. 
[2] 
J. Doll, W. Schlegel, O. Pastyr, V. Sturm, and W. Maier-Borst, "The 
use of an industrial robot as a stereotactic guidance system.," in CAR 
87, Berlin, 1987. 
[3] 
R. H. Taylor, et al., "An Image-Based Robotic System for Hip 
Replacement Surgery," Journal of the Robotics Society of Japan, 
1990, pp. 111-116. 
[4] 
C. Caetano da Rosa, Operationsroboter in Aktion. Bielefeld, 
Germany: transcript Verlag, 2013. 
[5] 
M. Jakopec, et al., "The First Clinical Application of a "Hands-on" 
Robotic Knee Surgery System," Computer Aided Surgery, vol. 6, 
2001, pp. 329-339. 
[6] 
H. Mayer, I. Nagy, A. Knoll, E. U. Schirmbeck, and R. 
Bauernschmitt, "A robotic system providing force feedback and 
automation for minimally invasive heart surgery," in CARS, Osaka, 
Japan, 2006, pp. 265-267. 
[7] 
M. Shoham, M. Burman, E. Zehavi, and Y. Kunicher, "MARS: 
miniature bone-mounted robot," in ISRACAS'2003, Tel Aviv, Israel, 
2003. 
[8] 
P. P. Pott, et al., "ITD - A handheld manipulator for medical 
applications - Concept and design," in 3rd annual meeting of CAOS, 
Marbella / Spain, 2003, pp. 290-291. 
[9] 
P. P. Pott, A. Wagner, E. Badreddin, P. Weiser, and M. L. R. 
Schwarz, "Inverse Dynamic Model and a Control Application of a 
Novel 6-DOF Hybrid Kinematics Manipulator," Journal of 
Intelligent and Robotic Systems, vol. 63, 2010, pp. 3-23. 
[10] A. El-Shenawy, A. Wagner, P. P. Pott, and E. Badreddin, 
"Disturbance Attenuation of a Handheld Parallel Robot," in IEEE 
ICRA, Karlsruhe, 2013. 
[11] T. Würtz, et al., "The Twisted String Actuation System: Modeling 
and Control," in IEEE/ASME International Conference on Advanced 
Intelligent Mechatronics, Montréal, Canada, 2010, pp. 1215-1220. 
[12] K. Kong , J. Bae, and M. Tomizuka, "Control of Rotary Series 
Elastic Actuator for Ideal Force-Mode Actuation in Human-Robot 
Interaction 
Applications," 
IEEE/ASME 
Transactions 
on 
Mechatronics, vol. 14, 2009, pp. 105-118. 
[13] M. Grün, R. Müller, and U. Konigorski, "Model Based Control of 
Series Elastic Actuators," in IEEE Biomedical Robotics and 
Biomechatronics (BioRob), Rome, Italy, 2012, pp. 538-543. 
[14] N. Sadaghzadeh, L. Zouaghi, A. Wagner, J. Poshtan, and E. 
Badreddin, "Cascaded Error Estimation and Compensation of an 
Inertial Measurement Unit using the Fusion of Optical and Inertial 
Sensors," in COMADEM, Helsinki, 2013. 
[15] E. Badreddin, "Recursive Control Structure for Mobile Robots," in 
International Conf. on Intelligent Autonomous Systems 2 (IAS.2), 
Amsterdam, 1989, pp. 11-14. 
[16] A. Wagner, E. Nordheimer, and E. Badreddin, "Hierarchical 
constraint-based singularity avoidance," in System Theory, Control 
and Computing (ICSTCC), Sinaia, 2012. 
[17] O. Khatib, "Real-time obstacle avoidance for manipulators and 
mobile robots," The International Journal of Robotics Research, vol. 
5, 1986, pp. 90-98. 
 
 
380
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-325-4
ACHI 2014 : The Seventh International Conference on Advances in Computer-Human Interactions

