Hybrid Control and Game Design for BCI-integrated Action FPS Game 
 
Supachai Tengtrakul and Setha Pan-ngum 
Department of Computer Engineering 
Chulalongkorn University 
Bangkok, Thailand 
e-mail: 6170289321@student.chula.ac.th, setha.p@chula.ac.th 
 
 
Abstract— Despite years of research, the fundamental issues of 
Electroencephalography (EEG) remain one of the most 
prominent problems for Brain-Computer Interface (BCI) 
game design, resulting in BCI games that look very lacking 
compared to other games in the market. This paper presents a 
new hybrid game control that is a combination of 4 methods of 
interaction: 
a 
Steady-State 
Visually 
Evoked 
Potential 
(SSVEP)-based 
BCI 
that 
utilizes 
a 
state-of-the-art 
Riemannian-based classifier, a mouse, a keyboard and an eye 
tracker. This paper also presents an action First-Person-
Shooting (FPS) game that works together with the control to 
deliver satisfying BCI game experience. This game features 3 
mechanics that assist the BCI control: slowing down time, 
highlighting an SSVEP stimulus that is being looked at and 
activating an SSVEP command automatically if players fail to 
do so in exchange for not receiving some rewards. From the 
test result from 10 subjects, we found that all subjects can issue 
commands through the eye tracker adequately at first, but the 
performance degraded over time. SSVEP commands had a 
60.5% successful manual activation rate and it took around 
3.569 seconds for each successful manual activation. Despite 
some inconveniences seen from the result, 90% of the subjects 
still found the game enjoyable, and 10% felt neutral toward 
the game. 
Keywords-BCI; EEG; SSVEP; Games; Riemannian-based 
classification. 
I. 
INTRODUCTION 
Brain-Computer Interface (BCI) gives us a mean to 
control a computer without moving by monitoring our brain 
activity. There are several techniques used to monitor the 
brain activity, and one of them is Electroencephalography 
(EEG) [1]. EEG monitors the brain activity through 
electrodes mounted on the scalp, so the procedure is 
completely non-invasive and can be applied repeatedly to 
anyone without risks or limitations [2]. These advantages, 
combined with the ease of setting up offered by dry 
electrodes, make EEG-based BCIs undoubtedly the most 
suitable BCIs for gaming application. 
BCI games have a lot of benefits. They can be used to 
help patients recover from incidents of stroke and traumatic 
brain injuries, treat seizure disorders, help children and 
adolescents who have Attention-Deficit and Hyperactivity 
Disorder (ADHD) [3] or improve the quality of life of people 
with severe disabilities. Even for normal players, BCI games 
can provide Neurofeedback (NF) functionality that can 
modify the game experience to best suit players’ emotional 
state and improve players’ attention and cognitive skill when 
played regularly [4]. However, the gaming industry has 
never adopted BCIs in any full-featured game [5] since it has 
fundamental issues that make it not viable compared to the 
traditional input devices. The first issue is that the number of 
commands available for players can be very limited, 
depending on the approach we choose to process EEG. 
Another issue is high intersubject variability which leads to 
unreliability, the need for calibration and the phenomenon 
called BCI illiteracy, which prevents some people from using 
a BCI effectively [1]. 
Among several EEG-based BCI approaches, one of the 
most reliable ones is Steady-State Visually Evoked Potential 
(SSVEP) [3]. This approach uses visual stimuli that flicker at 
the frequency of 6 Hz or above to evoke brain responses [6]. 
EEG at the same frequency and its harmonics will become 
very dominant and easy to detect once subjects start focusing 
on a stimulus, and it will continue to dominate as long as 
subjects continue focusing. This means that SSVEP can 
support many commands, can support continuous input, has 
high susceptibility to artifacts [5], requires little to no time 
for calibration [7] and has a low chance to find a subject with 
BCI illiteracy [1]. However, this approach comes with a few 
issues. The first issue is that it cannot control in-game 
movement efficiently [5]. The second issue is that the 
accuracy of SSVEP classification has never been perfected 
and will only diminish the more stimulus frequencies are 
being used [8]. The last issue is that each subject’s reaction 
toward the stimuli can be wildly different. Some people, 
especially the elderly, can find them annoying [1] while 
some people can find them tiresome or uncomfortable after 
constantly looking at them [9]. The most extreme case is that 
it can trigger a seizure in people with epilepsy, so every test 
requires a subject’s medical history checking beforehand 
[10]. 
Using an SSVEP-based BCI with other input devices can 
mitigate some of the issues. For example, the study by 
Stawicki et al. [8] shows that a spelling application 
controlled by an SSVEP-based BCI and an eye tracker works 
better than the same application controlled by the BCI alone. 
Unfortunately, this idea has not gained a lot of traction in 
BCI game research community yet [5]. 
For the reasons mentioned above, we developed a new 
hybrid game control that uses an SSVEP-based BCI, a 
mouse, a keyboard and an eye tracker together. We also 
408
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

developed an action First-Person-Shooting (FPS) game that 
features several mechanics to facilitate the BCI control. Both 
work together to bring BCI game experience closer to the 
game experience provided by other games in the market. 
This paper is organized into 6 sections. Section 2 
describes the EEG signal acquisition and the development of 
the signal processor. Section 3 describes the design and 
development of the game. Section 4 describes the procedure 
of the experiment. Section 5 presents the result and 
discussion before Section 6 finally concludes this paper.   
II. 
BCI APPROACH 
A. Signal Acquisition 
EEG signals are acquired through G.SAHARA active dry 
electrode system and G.MOBILAB+ from G.TEC [11]. 
Since SSVEP can be detected strongly in the occipital region 
of the brain [6], the electrodes were mounted at the following 
positions according to the international 10-20 system: Oz, 
O1, O2, POz, PO3, PO4, PO7 and PO8. The electrodes are 
connected to G.MOBILAB+ which is responsible for 
acquiring EEG signal at the sampling rate of 256Hz. 
B. Signal Processing 
According to the report on the progress of BCI games by 
Kerous et al. [5] and our survey, we found that the SSVEP 
classification method usually used in later studies is 
Canonical Correlation Analysis (CCA)-based classification. 
However, in the updated review of classification methods by 
Lotte et al. [12], we found another type of method called 
Riemannian-based classification. This type of classification 
can be applied to several BCI approaches and gives a 
performance that rivals or even surpasses the previous state-
of-the-art method. For SSVEP, the first implementation was 
proposed by Kalunga et al. [13], and the result showed that it 
can outperform 2 CCA-based state-of-the-art methods 
proposed by Lin et al. [14] and Nakanishi et al. [15]. 
This classification method involves mapping a band-
passed signal directly onto a Riemannian manifold and using 
Minimum 
Distance 
to 
Riemannian 
Mean (MDRM) 
algorithm to classify the signal. Essentially, this means 
estimating a covariance matrix from the band-passed signal, 
then finding the distance between the covariance matrix and 
the matrices that represent each class before finally 
classifying 
the 
signal 
into 
the 
closest 
class. The 
representative matrices are derived from all covariance 
matrices in the same class during a training phase. There are 
3 variations of the method presented in the paper. The first 
one does not use the full MDRM algorithm, trading accuracy 
for speed. The second one uses the full algorithm, trading 
some speed for accuracy. The last one uses the full algorithm 
and an outlier signal removal method called Riemannian 
potato for maximum accuracy. We chose the first one to 
make our BCI as responsive as possible and compensate for 
the accuracy by limiting the number of stimulus frequencies 
to only one and utilizing an eye tracker to determine what 
stimulus is being focused on instead. This can mitigate the 
error that can happen during SSVEP classification, which, in 
turn, improves the accuracy and reliability of our BCI 
significantly, as seen in the work of Stawicki et al. [8]. 
We chose to implement this classifier on Matlab [16]. 
The original work by Kalunga was not implemented for real-
time applications as it uses 4 seconds of signal for each 
iteration and requires 5 iterations before it can give a definite 
answer. Since G.MOBILAB+ uses a 256Hz sampling rate, 4 
seconds of signal means 8,192 samples (1,024 x 8 channels) 
which is too much for real-time processing, so we reduce it 
to 2.5 seconds. We do not want to reduce it any further as 
requiring a lot of data might be the characteristic of this 
classifier. Still, 5,120 samples remain a lot for real-time 
processing, so we decided to give Matlab 0.25 seconds to 
complete each iteration. We also remove the voting process 
completely and reassign that task to the game instead. This 
allows the game to dynamically adjust the voting process to 
suit the current context, which can be very beneficial for 
continuous input. 
III. 
GAME APPROACH 
A. Game Design 
To demonstrate that the new hybrid control has more 
capability and imposes less restriction on the game design, 
we design the game with 2 goals in mind. First, the game 
must feature every kind of command that has ever been in an 
FPS game. Second, the game must feature unique mechanics 
to facilitate the BCI control that cannot be implemented with 
non-hybrid BCI control. 
The core gameplay of FPS games is always the same 
since its earlier days, namely, players must progress through 
levels/maps and kill enemies. The innovation for the genre in 
terms of control comes from expanding more on this core 
gameplay. Regarding progressing through levels/maps, the 
most basic things that players need are movement, 
environment interaction and resources. In old games like 
Doom (1993) [17], movement is limited to walking and 
jumping, environment interaction is just pressing the right 
door switch, and resources only come in the form of pickups 
scattered around a level that can be utilized only when 
players walk right through them. However, in modern games 
like Far Cry 5 [18], movement can be sprinting, crouching or 
sliding, environment interaction can be talking to someone to 
receive a side quest, and resources can be items stored in the 
inventory that can be utilized anytime. Regarding killing 
enemies, the most basic things that players need are 
weapons. In Doom (1993) [17], players can only kill enemies 
with guns. However, in newer games like Borderlands [19], 
players can also kill enemies with a melee attack, a 
throwable item like a grenade or the special ability of the 
character that they chose. 
Every command we have mentioned can be categorized 
into 5 types: movement, weapon, environment interaction, 
item and ability. Item and ability can be combined into one 
type since not every item and ability is meant for taking out 
enemies and both of their usages are limited by either 
quantity, cooldown or mana point. The real fifth type comes 
from in-game menu which is mandatory for every game. 
These 5 types are more than enough to serve the core 
409
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

gameplay of progressing through levels/maps and killing 
enemies. Therefore, they are enough for any FPS game.  
Which command can be activated by SSVEP depends on 
whether or not it has at least one Head-Up Display (HUD) 
associated with it. However, as stated in the downsides of 
SSVEP, making every HUD become stimuli can be very 
annoying or tiresome for some players. Therefore, we need 
to do that only for the commands that require continuous 
input or the commands that do not, but should, require some 
degree of focus to activate. For the rest of HUD-associated 
commands, we decided to have players activate them by 
looking at a HUD and pressing a universal command button 
instead. The eye tracker that we use in this study is Tobii Eye 
Tracker 4C [20] which is capable of eye blink detection. This 
allows the game to know where players are looking at when 
they are blinking which can be translated into some 
additional commands as well. 
The commands in movement type usually do not have 
any HUD associated with them. These commands should not 
require a lot of focus from players to activate as each of them 
is usually used in combination while players are focusing on 
more important tasks. Therefore, it is best to let players 
activate them easily through a mouse and a keyboard. 
The second type is weapon which usually comes with a 
HUD: a crosshair for shooting or aiming down sight, an 
ammo count for reloading, a weapon icon for changing 
weapon, etc. We decided that aiming down sight should be 
activated by closing one eye to imitate how we aim a gun in 
real life. The rest of the commands, except shooting, can be 
activated by looking at a HUD and pressing a universal 
command button. Shooting is an exception because it shares 
the same HUD with aiming down sight and it needs both 
single and continuous input for automatic and semi-
automatic weapons. Therefore, our solution is to make the 
command able to be activated by 2 methods: aiming at an 
enemy or focusing on a stimulus. The game also needs to 
slow down time for players when they are trying to focus 
because this command is more likely to be used during a 
hectic situation which can make focusing a lot harder.  
The third type is item/ability, which needs a HUD to 
inform players whether an item/ability is available to use or 
not, meaning that every command in this type can be 
activated by looking at a HUD and pressing a button. 
However, we thought that there needs to be another way to 
activate these commands. Since some items/abilities tend to 
be used more often than others, having players closing one 
eye a little longer than usual to use the most essential 
item/ability immediately without the need to look at any 
specific HUD might improve gameplay significantly. 
The fourth type is environment interaction, which needs a 
HUD to avoid confusion since most objects, or even doors, 
in most games are non-interactable. We decided that there 
should be 2 methods to activate this command: looking at a 
HUD and pressing a button or focusing on a stimulus. The 
latter would be used to depict an object that requires some 
effort to interact with. This also requires the game to slow 
down time for players if the interaction happens during a 
hectic situation. 
The last type is in-game menu, which consists of every 
command related to in-game menus such as a pause menu, 
an inventory, a map, a weapon wheel, etc. We decided that it 
is best to let players control every in-game menu, except the 
weapon wheel, with a mouse and a keyboard since they can 
be wildly different in each game. The weapon wheel is an 
exception because its functionality is always the same; open, 
select an option and close which can be easily translated into 
holding a button, looking at an option before releasing the 
button. 
From what we have described, a mechanic that facilitates 
the BCI control has already been mentioned, slow motion. 
This mechanic can already satisfy our goal since it needs an 
eye tracker, making it unable to be implemented with non-
hybrid BCI control. However, due to the high intersubject 
variability of BCIs [1], we decided to add 2 more mechanics 
to improve the reliability, automatic activation and reward 
for manual activation. The game will activate an SSVEP 
command automatically at the end of the slow motion and 
give players some rewards if they can activate the command 
manually before the slow motion ends. 
 
Figure 1.  The screenshot of our game, Core Defender. 
When combining this mechanic and the activation 
methods we have summarized together, we came up with a 
single-player FPS game called Core Defender, as seen in 
Figure 1. In this game, a player must use everything at 
his/her disposal to fight off 3 waves of enemies that want to 
crash into the core in the middle of the room. There are 2 
weapons available: an assault rifle and a sniper rifle. The 
assault rifle can change between 3 ammo types: red ammo 
that does well against red enemies, yellow ammo that does 
well against yellow enemies and orange ammo that does well 
against both. If the player uses red or yellow ammo against 
the correct enemies, the player will be granted bonus scores. 
The sniper rifle, on the other hand, has only one ammo type 
and grants the player bonus scores all the time. Its shot is so 
powerful that it can destroy any enemy in a single hit. 
Besides the weapons, the player can also use the ability to 
turn on a laser grid around the core and slow down time. 
Turning on the laser grid can help the player destroy every 
enemy near the core, but it is limited to 2 times throughout 
the game.  Slowing down time lasts for 8 seconds and 
players must wait for a cooldown to use it again. This ability 
is essential because it must be activated every time before the 
player can fire the sniper rifle or turn on the laser grid. If the 
 
410
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

player can activate one of those commands before the ability 
ends, the game will reward the player with a faster 
cooldown. Between each wave, the player has a choice to 
repair the core in exchange for some scores or skip to the 
next wave immediately. Regardless of how well the player 
plays, the core’s health will always be reduced at the end of 
each wave to raise the stake for the player who wants the 
highest scores possible. 
From the gameplay we have described, we can list every 
command available and summarize how each of them can be 
activated as follows: 
 
Using a mouse and a keyboard: move, look, 
open/close the assault rifle mode selection menu 
(Figure 2). 
 
Aiming at an enemy: fire the assault rifle. 
 
Pressing a universal command button when looking 
at a specific HUD: change weapon, use/cancel 
slowing down time. 
 
Closing one eye: aiming down sight. 
 
Closing one eye longer than usual: use/cancel 
slowing down time. 
 
Focusing on a stimulus when slowing down time is 
active: fire the sniper rifle, activate the laser grid. 
 
Focusing on a stimulus when slowing down time 
does not have to be active: fix the core, skip the wait 
time between each wave. 
 
Looking: select an option in the assault rifle mode 
selection menu (Figure 2). 
 
Figure 2.  A screenshot showing the assault rifle mode selection menu. 
B. Stimulus Design 
Another thing that is crucial for bringing out the best 
performance of an SSVEP-based BCI is the stimuli. 
According to the report by Zhu et al. [21], using LED or 
fluorescent lights to display the stimuli can evoke stronger 
brain responses from a subject than using a monitor. Using a 
pattern reversal graphic instead of a simple flickering graphic 
can help us get a stronger brain responses as well. However, 
it is one of our goals to make the game as easy to set-up as 
possible and to make the stimuli look consistent with the rest 
of the game in terms of the aesthetic. Therefore, we cannot 
use those options which leaves us with 3 factors that we need 
to consider: frequency, color and visibility.  
The frequencies used in most researches are usually in 
the range of 12-25Hz [21]. We decided to use 15Hz because, 
according to the study by Pastor et al. [22], the brain 
response reaches the greatest amplitude around this 
frequency. 
The report by Zhu et al. [21] also wrote about the impact 
that stimulus color has on the performance of a BCI when 
using red, blue or yellow stimuli. However, none of those 
colors performs exceptionally well at 15Hz and the report 
stated that it required further study, so we chose the color 
that is used most among the studies that use the same type of 
graphic for their stimuli: white. The final design of our 
stimuli can be seen in Figure 3. Both second and third stimuli 
can appear at the same time. 
 
Figure 3.  The SSVEP stimuli that appear in the game. 
Visibility is another factor that may become an issue in 
our study. Since the stimuli are white and displayed on a 
computer screen, they can be barely visible to the player 
when his/her in-game character is in a bright environment or 
looking directly at a light source. To solve this issue, we use 
a mechanic called stimulus highlighting, as seen in Figure 4. 
The game will utilize the eye tracker to darken everything on 
the screen except the stimulus that is being looked at. 
 
Figure 4.  A screenshot showing stimulus highlighting. 
C. Game Development & BCI Integration 
The game was developed on game engine Unity 5 [23] 
for Windows platform and was integrated with 2 other 
components: Tobii Eye Tracker 4C and signal processor.  
The integration with Tobii Eye Tracker 4C was done 
through a low-level Software Development Kit (SDK) called 
Stream Engine SDK [24]. Even though there is Tobii Unity 
SDK [25] available, we cannot use it since it does not 
provide a crucial feature that is eye blinking detection. 
The integration with the signal processor was done 
through a software suite called BCI2000 [26]. BCI2000 
consists of 4 modules: a source module, a signal processing 
module, an application module and an operator module. The 
first 3 modules can be swapped in and out freely while the 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
411
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

last one stays the same to make sure that those 3 modules 
work together properly. For the source and signal processing 
module, we use the modules that come with BCI2000 to 
receive the signal from G.MOBILAB+ and send it to our 
classifier in Matlab. For the application module, however, 
there is currently no module that can communicate with 
Unity directly, so we use a dummy application with the sole 
functionality of sending and receiving User Datagram 
Protocol (UDP) messages instead. These messages can be 
sent across 2 computers or sent to other programs on the 
same computer through the localhost address. Despite the 
performance overhead, we chose remote communication 
because it allows us to test the game anywhere by simply 
installing the game on a target computer. 
IV. EXPERIMENT 
The experiment was performed on 10 male subjects who 
had never been diagnosed with epilepsy. Most subjects’ age 
ranged from 21 to 26, except 1 subject who was 46. The test 
environment was dimly lit to increase the effectiveness of 
SSVEP stimuli and contained as few electrical sources as 
possible to minimize the number of artifacts in the EEG 
signal. 
The experiment consisted of 3 main steps. The first step 
was testing the eye tracker, which involved calibrating the 
eye tracker and testing every eye tracker-related command. 
The test was done by having a subject activate each 
command 10 times and report to us how many attempts it 
took to activate each of them. During this step, any 
commands that were triggered when the subject had no 
intention to use any commands would be recorded as false 
triggering. The second step was testing the BCI which 
involves mounting electrodes, calibrating the BCI and testing 
every BCI command. The test was done by having the 
subject activate each command 10 times before moving on to 
the next one. The time it took to activate each command or 
whether the subject activated it manually or not would be 
recorded by the game. The last step was playing which 
involved playing the game from start to finish at least once. 
The data about SSVEP activation that the game recorded 
would not contribute toward the BCI test result because, after 
a long test, we wanted the subjects to have fun with the game 
so they may not focus on the stimuli as hard when they did 
not feel the need to get faster slow-motion cooldown that 
manual activation provided. All subjects were told about the 
prize that they would receive if they won and got 80% of the 
possible score before the game started. 
After the experiment was completed, every subject must 
do a questionnaire. This questionnaire is adapted from the 
core module of Game Experience Questionnaire developed 
by Poels et al. [27] which aims to assess game experience in 
7 aspects: competence, sensory and immersion, flow, 
tension, challenge, negative affect and positive affect. Every 
question must be answered on a scale of 0 to 4; 0 means 
strongly disagree, 4 means strongly agree. The subject can 
also provide additional feedback if he/she wishes to do so. 
V. 
RESULTS AND DISCUSSIONS 
A. Eye Tracker  
Before the test began, we asked the subjects to close one 
eye to observe how well they can do it. Out of 10 subjects, 
there was only 1 who could keep the other eye open the 
entire time, which was below our expectation. Nonetheless, 
the result shows that the worst average first attempt rate of 
the commands that are activated by closing one eye is 70%, 
meaning that 70% of the time the subject can use the 
commands on the first attempt. The most attempts for a 
single command come from a different subject which is 3 
attempts for aiming down sight. The worst average first 
attempt rate of the commands that do not involve closing one 
eye is 86.667%, and the worst false trigger rate is 7.407%. 
Overall, 10 subjects have an 86.5% average first attempt rate 
for the commands that are activated by closing one eye, a 
96.333% average first attempt rate for the commands that are 
not and a 4.128% average false trigger rate. These data are 
enough to conclude that every subject can use eye tracker-
related commands adequately during the test step. 
TABLE I.  
THE RESULT OF THE BCI TESTING 
 
Shooting the Sniper Rifle 
Activating the Laser Grid 
Skipping 
Fixing the Core 
 
Manual 
Auto 
Delay (sec.) 
Manual 
Auto 
Delay 
Manual 
Auto 
Delay 
<8 sec. 
>=8 sec. 
Fail 
Delay 
Sub. 1 
7 
3 
1.764 
5 
5 
2.41 
4 
6 
2.421 
6 
2 
2 
2.792 
Sub. 2 
9 
1 
4.478 
3 
7 
5.1 
9 
1 
3.095 
2 
4 
4 
1.942 
Sub. 3 
9 
1 
4.042 
7 
3 
2.355 
10 
0 
3.542 
8 
0 
2 
2.265 
Sub. 4 
6 
4 
3.778 
6 
4 
2.383 
8 
2 
2.223 
9 
1 
0 
4.946 
Sub. 5 
5 
5 
3.045 
8 
2 
2.531 
7 
3 
3.684 
8 
2 
0 
3.992 
Sub. 6 
7 
3 
4.736 
3 
7 
3.928 
4 
6 
3.658 
1 
6 
3 
7.85 
Sub. 7 
6 
4 
2.752 
5 
5 
3.703 
8 
2 
2.669 
6 
4 
0 
3.672 
Sub. 8 
8 
2 
4.492 
1 
9 
6.7 
6 
4 
5.078 
4 
3 
3 
5.65 
Sub. 9 
7 
3 
3.088 
2 
8 
1.992 
6 
4 
2.808 
2 
5 
3 
5.567 
Sub. 10 
7 
3 
3.519 
9 
1 
3.031 
6 
4 
3.111 
8 
2 
0 
1.964 
Avg. 
7.1 
2.9 
3.569 
4.9 
5.1 
3.413 
6.8 
3.2 
3.229 
5.4 
2.9 
1.7 
4.064 
412
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

B. BCI  
The differences between the results of each command are 
far above our expectations. As seen in Table I, shooting the 
sniper rifle yields moderately good results with a 71% 
average manual activation rate and 3.569 seconds average 
activation time, while activating the laser grid and fixing the 
core are significantly worse. It is important to note that the 
activation time does not take Auto and >=8 sec. columns into 
account. We think that there are 3 potential causes. The first 
one is that the subjects might feel more pressured when 
trying to activate these commands. Activating the laser grid 
must be used during enemy waves, and the subjects must 
focus while they see enemies approaching from multiple 
angles. Fixing the core is a unique command because it has 
no automatic activation. Compared to other commands that 
have 8 seconds for manual activation, this command can fail 
completely if it is not activated manually within the time 
between enemy waves. The second cause might be the size 
of the stimulus which is noticeably smaller than the stimulus 
of shooting the sniper rifle. One subject also said that the 
position of the stimulus (upper screen) made it a bit harder to 
focus when compared to the stimulus of skipping that looks 
the same but is located in a different area (lower screen). The 
last cause, which we think affects every command in general, 
is the performance of the Riemannian-based SSVEP 
classifier. As mentioned before, this classifier in the original 
work requires 4 seconds of signal for each iteration. 
Applying that directly to our work might result in an average 
activation time that is well above 4 seconds. However, 
modifying the classifier to use only 2.5 seconds as we did 
might affect the accuracy and lower the manual activation 
rate, which is a trade-off that is worth looking into more in 
the future. 
C. Playing Session 
From 10 playing sessions, 453 enemies were destroyed in 
total, and 176 of them were destroyed by the sniper rifle 
which is equal to 38.852%. 60% of the subjects used the 
sniper rifle more than 40% of the time, and 50% of those 
used the sniper rifle more than the assault rifle. These results 
show that most subjects felt confident enough to use SSVEP 
commands during an action whether the BCI worked reliably 
enough or not. 
TABLE II.  
THE RESULT OF THE QUESTIONNAIRE 
 
Avg. Score 
Result (Positive/Negative) 
Competence 
2.8 
Positive 
Sensory & Immersion 
3 
Positive 
Flow 
3 
Positive 
Tension 
2.3 
Negative 
Challenge 
3.2 
Positive 
Negative Affect 
1.42 
Positive 
Positive Affect 
2.9 
Positive 
D. Questionnaire 
We averaged the scores of every question in each 
category across every subject and the result can be seen in 
Table II. The max score of 4 can be either positive or 
negative, depending on the category. As can be seen, the 
subjects generally have positive impressions toward the 
game in every aspect except one, tension. The questions in 
the tension category focus on whether the subjects felt 
annoyed or frustrated by the eye tracker and BCI control or 
not. The average score of the eye tracker control is 2.1, and 
the average score of the BCI control is 2.5. When comparing 
the eye tracker score to the results of the previous test, it 
clearly shows that most subjects experienced facial fatigue 
during the real playing session. Despite all these negative 
results, most subjects still enjoyed the game and felt that they 
could control the game well enough, which are reflected in 
the positive affect and competence score. 
VI. 
CONCLUSION AND FUTURE WORK 
A new hybrid control, which is a combination of SSVEP-
based BCI, an eye tracker, a mouse and a keyboard, has been 
presented. The BCI utilizes the Riemannian-based classifier 
proposed by Kalunga et al. [13] in the hope of making the 
BCI reliable enough to control FPS games. An action FPS 
game that features several mechanics to facilitate the BCI 
control has also been presented. Those mechanics are slow 
motion, automatic SSVEP activation, highlighting stimulus 
and reward for manual activation. 
The performance of the BCI is inconsistent. The results 
were decent for some commands, but far below our 
expectation for others. This might be because we reduced the 
signal window used for each iteration from 4 seconds, as 
originally proposed, to 2.5 seconds. Furthermore, we found 
that most subjects cannot close one eye perfectly and 
experienced facial fatigue during the real playing session, 
which makes eye tracker-related commands more frustrating 
to use. Despite these issues, the mechanics of the game still 
helped the subjects gain enough control of the game to find it 
enjoyable and created enough incentive for the subjects to 
use BCI commands. 
In future studies, we would like to focus on finding the 
optimal signal window that maintains both speed and 
accuracy for the classifier. We will also make activating 
commands by closing one eye not mandatory for aiming 
down sight since it is not related to the BCI and it hurts the 
overall game experience more than enhances it. 
REFERENCES 
[1] B. Allison et al., "BCI Demographics: How Many (and What Kinds 
of) People Can Use an SSVEP BCI?," IEEE Transactions on Neural 
Systems and Rehabilitation Engineering, vol. 18, no. 2, pp. 107-116, 
Apr. 2010, doi: 10.1109/TNSRE.2009.2039495. 
[2] M. Teplan, "Fundamental of EEG Measurement," Measurement 
Science Review, vol. 2, pp. 1-11, Jan. 2002. 
[3] R. Parafita, G. Pires, U. Nunes, and M. Castelo-Branco, "A spacecraft 
game controlled with a brain-computer interface using SSVEP with 
phase tagging," 2013 IEEE 2nd International Conference on Serious 
Games and Applications for Health (SeGAH), Vilamoura, May 2013, 
pp. 1-6, doi: 10.1109/SeGAH.2013.6665309. 
413
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

[4] K. P. Thomas, A. P. Vinod, and C. Guan, "Enhancement of attention 
and cognitive skills using EEG based neurofeedback game," 2013 6th 
International IEEE/EMBS Conference on Neural Engineering (NER), 
San 
Diego, 
CA, 
Nov. 
2013, 
pp. 
21-24, 
doi: 
10.1109/NER.2013.6695861. 
[5] B. Kerous, F. Škola, and F. Liarokapis, "EEG-based BCI and video 
games: a progress report," Virtual Reality, vol. 22, no. 2, pp. 1-17, 
Oct. 2017, doi: 10.1007/s10055-017-0328-x. 
[6] C. Ming, G. Xiaorong, G. Shangkai, and X. Dingfeng, "Design and 
implementation of a brain-computer interface with high transfer 
rates," IEEE Transactions on Biomedical Engineering, vol. 49, no. 10, 
pp. 1181-1186, Oct. 2002, doi: 10.1109/TBME.2002.803536. 
[7] R. Singla, "Comparison of SSVEP Signal Classification Techniques 
Using SVM and ANN Models for BCI Applications," International 
Journal of Information and Electronics Engineering, vol. 4, no. 1, pp. 
6-10, Jan. 2014, doi: 10.7763/IJIEE.2014.V4.398. 
[8] P. Stawicki, F. Gembler, A. Rezeika, and I. Volosyak, "A Novel 
Hybrid Mental Spelling Application Based on Eye Tracking and 
SSVEP-Based BCI," (in eng), Brain Sci, vol. 7, no. 4, pp. 35, Apr. 
2017, doi: 10.3390/brainsci7040035. 
[9] H. Gürkök, A. Nijholt, and M. Poel, "Brain-Computer Interface 
Games: Towards a Framework," Entertainment Computing - ICEC 
2012, Berlin, Heidelberg, Sep. 2012, pp. 373-380. 
[10] G. Harding, A. J. Wilkins, G. Erba, G. L. Barkley, and R. S. Fisher, 
"Photic- and pattern-induced seizures: expert consensus of the 
Epilepsy Foundation of America Working Group," (in eng), 
Epilepsia, vol. 46, no. 9, pp. 1423-1425, Sep. 2005, doi: 
10.1111/j.1528-1167.2005.31305.x. 
[11] G.Tec Medical Engineering. G.Saharasys & G.Mobilab+. Product. 
available: https://www.gtec.at. last accessed: Oct. 2020. 
[12] F. Lotte et al., "A Review of Classification Algorithms for EEG-
based Brain-Computer Interfaces: A 10-year Update," Journal of 
Neural Engineering, vol. 15, no. 3, pp. 31005, Feb. 2018, doi: 
10.1088/1741-2552/aab2f2. 
[13] E. K. Kalunga et al., "Online SSVEP-based BCI using Riemannian 
geometry," Neurocomputing, vol. 191, pp. 55-68, Feb. 2016, doi: 
https://doi.org/10.1016/j.neucom.2016.01.007. 
[14] Z. Lin, C. Zhang, W. Wu, and X. Gao, "Frequency recognition based 
on canonical correlation analysis for SSVEP-based BCIs," IEEE 
Transactions on Biomedical Engineering, vol. 54, no. 6, pp. 1172-
1176, Jul. 2007, doi: 10.1109/TBME.2006.889197. 
[15] M. Nakanishi, Y. Wang, Y. T. Wang, Y. Mitsukura, and T. P. Jung, 
"A high-speed brain speller using steady-state visual evoked 
potentials," (in eng), Int J Neural Syst, vol. 24, no. 6, pp. 1450019, 
Sep. 2014, doi: 10.1142/s0129065714500191. 
[16] Math 
Works. 
Matlab 
R2018b. 
Software. 
available: 
https://www.mathworks.com. last accessed: Oct. 2020. 
[17] Id 
Software. 
Doom 
(1993). 
Video 
game. 
available: 
https://store.steampowered.com. last accessed: Oct. 2020. 
[18] Ubisoft. 
Far 
Cry 
5. 
Video 
game. 
available: 
https://store.steampowered.com. last accessed: Oct. 2020. 
[19] Gearbox 
Software. 
Borderlands. 
Video 
game. 
available: 
https://store.steampowered.com. last accessed: Oct. 2020. 
[20] Tobii Tech. Tobii Eye Tracker 4C. Product. no longer available. 
detail: https://gaming.tobii.com. last accessed: Oct. 2020. 
[21] D. Zhu, J. Bieger, G. Garcia-Molina, and R. Aarts, "A survey of 
stimulation methods used in SSVEP-based BCIs," Computational 
Intelligence and Neuroscience, vol. 2010, pp. 702357, Jan. 2010, doi: 
10.1155/2010/702357. 
[22] M. A. Pastor, J. Artieda, J. Arbizu, M. Valencia, and J. C. Masdeu, 
"Human cerebral activation during steady-state visual-evoked 
responses," (in eng), J Neurosci, vol. 23, no. 37, pp. 11621-11627, 
Dec. 2003, doi: 10.1523/jneurosci.23-37-11621.2003. 
[23] Unity 
Technologies. 
Unity 
5. 
Software. 
available: 
https://unity3d.com. last accessed: Oct. 2020. 
[24] Tobii Tech. Stream Engine SDK. Software development kit. 
available: https://vr.tobii.com/sdk/develop/native/stream-engine. last 
accessed: Oct. 2020. 
[25] Tobii Tech. Tobii Unity SDK for Desktop. Software development kit. 
available: https://developer.tobii.com/tobii-unity-sdk. last accessed: 
Oct. 2020. 
[26] Schalk Lab. BCI2000. Software. available: http://bci2000.org. last 
accessed: Oct. 2020. 
[27] K. Poels, Y. A. W. de Kort, and W. A. Ijsselsteijn, D3.3 : Game 
Experience Questionnaire (development of a self-report measure to 
assess the psychological impact of digital games). Eindhoven: 
Technische Universiteit Eindhoven, 2007. 
 
414
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

