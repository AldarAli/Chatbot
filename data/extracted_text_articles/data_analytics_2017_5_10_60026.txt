Detecting Fake Reviews through Sentiment Analysis Using Machine Learning 
Techniques 
 
 
Elshrif Elmurngi, Abdelouahed Gherbi                                                                            
Department of Software and IT Engineering                                                  
École de Technologie Supérieure                                                      
Montreal, Canada                                                                                                 
Email: elshrif.elmurngi.1@ens.etsmtl.ca, abdelouahed.gherbi@etsmtl.ca  
 
 
Abstract— Recently, Sentiment Analysis (SA) has become one of 
the most interesting topics in text analysis, due to its promising 
commercial benefits. One of the main issues facing SA is how to 
extract emotions inside the opinion, and how to detect fake 
positive reviews and fake negative reviews from opinion 
reviews.  Moreover, the opinion reviews obtained from users 
can be classified into positive or negative reviews, which can be 
used by a consumer to select a product. This paper aims to 
classify movie reviews into groups of positive or negative 
polarity by using machine learning algorithms. In this study, we 
analyse online movie reviews using SA methods in order to 
detect fake reviews. SA and text classification methods are 
applied to a dataset of movie reviews. More specifically, we 
compare five supervised machine learning algorithms: Naïve 
Bayes (NB), Support Vector Machine (SVM), K-Nearest   
Neighbors (KNN-IBK), KStar (K*) and Decision Tree (DT-J48) 
for sentiment classification of reviews using two different 
datasets, including movie review dataset V2.0 and movie reviews 
dataset V1.0. The measured results of our experiments show 
that the SVM algorithm outperforms other algorithms, and that 
it reaches the highest accuracy not only in text classification, but 
also in detecting fake reviews. 
Keywords- Sentiment Analysis; Fake Reviews; Naïve Bayes; 
Support Vector Machine; k-Nearest Neighbor; KStar;  Decision 
Tree -J48. 
I. 
 INTRODUCTION  
Opinion Mining (OM), also known as Sentiment Analysis 
(SA), is the domain of study that analyzes people’s opinions, 
evaluations, sentiments, attitudes, appraisals, and emotions 
towards entities such as services, individuals, issues, topics, 
and their attributes [1]. “The sentiment is usually formulated 
as a two-class classification problem, positive and negative” 
[1]. Sometimes, time is more precious than money, therefore 
instead of spending time in reading and figuring out the 
positivity or negativity of a review, we can use automated 
techniques for Sentiment Analysis. 
     The basis of SA is determining the polarity of a given text 
at the document, sentence or aspect level, whether the 
expressed opinion in a document, a sentence or an entity 
aspect is positive or negative. More specifically, the goals of 
SA are to find opinions from reviews and then classify these 
opinions based upon polarity. According to [2], there are three 
major classifications in SA, namely: document level, sentence 
level, and aspect level. Hence, it is important to distinguish 
between the document level, sentence level, and the aspect 
level of an analysis process that will determine the different 
tasks of SA. The document level considers that a document is 
an opinion on its aspect, and it aims to classify an opinion 
document as a negative or positive opinion. The sentence 
level using SA aims to setup opinion stated in every sentence. 
The aspect level is based on the idea that an opinion consists 
of a sentiment (positive or negative), and its SA aims to 
categorize the sentiment based on specific aspects of entities.     
     The documents used in this work are obtained from a 
dataset of movie reviews that have been collected by [3] and 
[9]. Then, an SA technique is applied to classify the 
documents as real positive and real negative reviews or fake 
positive and fake negative reviews. Fake negative and fake 
positive reviews by fraudsters who try to play their 
competitors existing systems can lead to financial gains for 
them. This, unfortunately, gives strong incentives to write 
fake reviews that attempt to intentionally mislead readers by 
providing unfair reviews to several products for the purpose 
of damaging their reputation. Detecting such fake reviews is a 
significant challenge. For example, fake consumer reviews in 
an e-commerce sector are not only affecting individual 
consumers but also corrupt purchaser’s confidence in online 
shopping [4]. Our work is mainly directed to SA at the 
document level, more specifically, on movie reviews dataset. 
Machine learning techniques and SA methods are expected to 
have a major positive effect, especially for the detection 
processes of fake reviews in movie reviews, e-commerce, 
social commerce environments, and other domains.  
    In machine learning-based techniques, algorithms such as 
SVM, NB, and DT-J48 are applied for the classification 
purposes [5]. SVM is a type of learning algorithm that 
represents supervised machine learning approaches [6], and it 
is an excellent successful prediction approach. The SVM is 
also a robust classification approach [7]. A recent research 
presented in [2] introduces a survey on different applications 
and algorithms for SA, but it is only focused on algorithms 
used in various languages, and the researchers did not focus 
on detecting fake reviews [8]-[12]. This paper presents five 
supervised machine learning approaches to classify the 
sentiment of our dataset which is compared with two different 
datasets. We also detect fake positive reviews and fake 
negative reviews by using these methods. The main goal of 
our study is to classify movie reviews as a real reviews or fake 
reviews using SA algorithms with supervised learning 
techniques.  
65
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

    The conducted experiments have shown the accuracy of 
results through sentiment classification algorithms. In both 
cases (movie reviews dataset V2.0 and movie reviews dataset 
V1.0), we have found that SVM is more accurate than other 
methods such as NB, KNN-IBK, KStar, and DT-J48. 
 
The main contributions of this study are summarized as 
follows: 
 
Using the Weka tool [29], we compare different 
sentiment classification algorithms which are used to 
classify the movie reviews dataset into fake and real 
reviews. 
 
We apply the sentiment classification algorithms using 
two different datasets with stopwords. We realized that 
using the stopwords method is more efficient than 
without stopwords not only in text categorization, but 
also to detection of fake reviews. 
 
We perform several analysis and tests to find the 
learning algorithm in terms of accuracy. 
 
The rest of this paper is organized as follows. Section II 
presents 
the related 
works. 
Section 
III 
shows 
the 
methodology. Section IV explains the experiment results, and 
finally, Section V presents the conclusion and future works. 
 
II. 
RELATED WORKS 
Our study employs statistical methods to evaluate the 
performance of detection mechanism for fake reviews and 
evaluate the accuracy of this detection. Hence, we present our 
literature review on studies that applied statistical methods. 
A. Sentiment analysis issues 
     There are several issues to consider when conducting SA 
[13]. In this section, two major issues are addressed. First, the 
viewpoint (or opinion) observed as negative in a situation 
might be considered positive in another situation. Second, 
people do not always express opinions in the same way. Most 
common text processing techniques employ the fact that 
minor changes between the two text fragments are unlikely to 
change the actual meaning [13].  
B. Textual reviews 
 Most of the available reputation models depend on 
numeric data available in different fields; an example is 
ratings in e-commerce.  Also, most of the reputation models 
focus only on the overall ratings of products without 
considering the reviews which are provided by customers 
[14]. On the other hand, most websites allow consumers to 
add textual reviews to provide a detailed opinion about the 
product [15] [16]. These reviews are available for customers 
to read. Also, customers are increasingly depending on 
reviews rather than on ratings. Reputation models can use SA 
methods to extract users’ opinions and use this data in the 
Reputation system. This information may include consumers’ 
opinions about different features [17] and [18]. 
C. Detecting Fake Reviews Using Machine Learning 
  Filter and identification of fake reviews have substantial 
significance [19]. Moraes et al. [20] proposed a technique for 
categorizing a single topic textual review. A sentiment 
classified document level is applied for stating a negative or 
positive sentiment. Supervised learning methods are 
composed of two phases, namely selection and extraction of 
reviews utilizing learning models such as SVM. 
Extracting the best and most accurate approach and 
simultaneously categorizing the customers written reviews 
text into negative or positive opinions has attracted attention 
as a major research field. Although it is still in an 
introductory phase, there has been a lot of work related to 
several languages [21]-[23]. Our work used several 
supervised learning algorithms such as SVM, NB, KNN-
IBK, K* and DT-J48 for Sentiment Classification of text to 
detect fake reviews. 
D. A Comparative Study of different Classification 
algorithms     
     Table I shows comparative studies on classification 
algorithms to verify the best method for detecting fake 
reviews using different datasets such as News Group  dataset, 
text documents, and movie reviews dataset. It alsoproves that 
NB and distributed keyword vectors (DKV) are accurate 
without detecting fake reviews [11] and [12]. While [10] 
finds that NB is accurate and a better choice, but it is not 
oriented for detecting fake reviews. Using the same datasets, 
[8] finds that SVM is accurate with stopwords method, but it 
does not focus on detecting fake reviews, while [9] finds that 
SVM is only accurate without using stopwords method, and 
also without detecting fake reviews. However, in our 
empirical study, results in both cases with movie reviews 
dataset V2.0 and with movie reviews dataset V1.0 prove that 
SVM is robust and accurate for detecting fake reviews. 
TABLE I.  
A COMPARATIVE STUDY OF DIFFERENT CLASSIFICATION 
ALGORITHMS. 
 
 
66
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

III. 
METHODOLOGY 
 To accomplish our goal, we analyze a dataset of movie 
reviews using the Weka tool for text classification. In the 
proposed methodology, as shown in Figure 1, we follow 
some steps that are involved in SA using the approaches 
described below. 
 
 
 
Figure 1.  Steps and Techniques used in Sentiment Analysis 
 
Step 1: Movie reviews collection 
To provide an exhaustive study of machine learning 
algorithms, the experiment is based on analyzing the 
sentiment value of the standard dataset. We have used the 
original dataset of the movie reviews to test our methods of 
reviews classification. The dataset is available and has been 
used in [12], which is frequently conceded as the standard 
gold dataset for the researchers working in the field of the 
Sentiment Analysis. The first dataset is known as movie 
reviews dataset V2.0 which consists of 2000 movie reviews 
out of which 1000 reviews are positive, and 1000 reviews are 
negative. The second dataset is known as movie reviews 
dataset V1.0, which consists of total 1400 movie reviews, 
700 of which are positive and 700 of which are negative. A 
summary of the two datasets collected is described in Table 
II. 
TABLE II.  
DESCRIPTION OF DATASET 
Dataset 
Content of the Dataset 
Movie 
Reviews 
Dataset 
V2.0 
2000 Movie Reviews (1000+ 
& 1000-) 
Movie 
Reviews 
Dataset 
V1.0 
1400 Movie Reviews (700+ 
& 700-) 
 
Step 2: Data preprocessing 
     The preprocessing phase includes two preliminary 
operations, shown in Figure 1, that help in transforming the 
data before the actual SA task. Data preprocessing plays a 
significant role in many supervised learning algorithms. We 
divided data preprocessing as follows: 
1) StringToWordVector 
      To prepare the dataset for learning involves transforming 
the data by using the StringToWordVector filter, which is the 
main 
tool 
for 
text 
analysis 
in 
Weka. 
The 
StringToWordVector filter makes the attribute value in the 
transformed datasets Positive or Negative for all single-
words, depending on whether the word appears in the 
document or not. This filtration process is used for 
configuring the different steps of the term extraction. The 
filtration process comprises the following two sub-processes: 
• Configure the tokenizer  
   This sub-process makes the provided document classifiable 
by converting the content into a set of features using machine 
learning. 
• Specify a stopwords list 
    The stopwords are the words we want to filter out, 
eliminate, before training the classifier. Some of those words 
are commonly used (e.g., "a," "the," "of," "I," "you," "it," 
"and") but do not give any substantial information to our 
labeling scheme, but instead they introduce confusion to our 
classifier.  In this study, we used a 630 English stopwords list 
with movie reviews dataset V2.0. Stopwords removal helps 
to reduce the memory requirements while classifying the 
reviews. 
2) Attribute Selection 
    Removing 
the 
poorly 
describing 
attributes 
can 
significantly increase the classification accuracy, in order to 
maintain a better classification accuracy, because not all 
attributes are relevant to the classification work, and the 
irrelevant attributes can decrease the performance of the used 
analysis algorithms, an attribute selection scheme was used 
for training the classifier. 
Step 3: Feature Selection 
     Feature selection is an approach which is used to identify 
a subset of features which are mostly related to the target 
model, and the goal of feature selection is to increase the 
level of accuracy. In this study, we implemented five feature 
selection methods widely used for the classification task of 
SA with Stopwords methods. The results differ from one 
method to the other. For example, in our analysis of Movie 
67
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

Review datasets, we found that the use of SVM algorithm is 
proved to be more accurate in the classification task.  
Step 4: Sentiment Classification algorithms 
    In this step, we will use sentiment classification 
algorithms, and they have been applied in many domains 
such as commerce, medicine, media, biology, etc. There are 
many different techniques in classification method like NB, 
DT-J48, SVM, K-NN, Neural Networks, and Genetic 
Algorithm. In this study, we will use five popular supervised 
classifiers: NB, DT-J48, SVM, K-NN, KStar algorithms. 
1) Naïve Bayes(NB) 
     The NB classifier is a basic probabilistic classifier based 
on applying Bayes' theorem. The NB calculates a set of 
probabilities by combinations of values in a given dataset. 
Also, the NB classifier has fast decision-making process. 
2) Support Vector Machine (SVM) 
     SVM in machine learning is a supervised learning model 
with the related learning algorithm, which examines data and 
identifies patterns, which is used for regression and 
classification analysis [24]. Recently, many classification 
algorithms have been proposed, but SVM is still one of the 
most widely and most popular used classifiers. 
3) K-Nearest Neighbor (K-NN) 
     K-NN is a type of lazy learning algorithm and is a non-
parametric approach for categorizing objects based on closest 
training. The K-NN algorithm is a very simple algorithm for 
all machine learning. The performance of the K-NN 
algorithm depends on several different key factors, such as a 
suitable distance measure, a similarity measure for voting, 
and, k parameter [25]- [28]. 
    A set of vectors and class labels which are related to each 
vector constitute each of the training data. In the simplest 
way; it will be either positive or negative class. In this study, 
we are using a single number ‘’k’’ with values of  
k=3. This number decides how many neighbors influence the 
classification. 
4) KStar (K*) 
     K-star (K*) is an instance-based classifier. The class of a 
test instance is established in the class of those training 
instances similar to it, as decided by some similarity function. 
K* algorithm is usually slower to evaluate the result. 
5) Decision Tree (DT-J48) 
    The DT-J48 approach is useful in the classification 
problem. In the testing option, we are using percentage split 
as the preferred method. 
Step 5: Detection Processes 
     After training, the next step is to predict the output of the 
model on the testing dataset, and then a confusion matrix is 
generated which classifies the reviews as positive or 
negative. The results involve the following attributes: 
 
True Positive: Real Positive Reviews in the testing 
data, which are correctly classified by the model as 
Positive (P).  
 
False Positive: Fake Positive Reviews in the testing 
data, which are incorrectly classified by the model 
as Positive (P). 
 
True Negative: Real Negative Reviews in the testing 
data, which are correctly classified by the model as 
Negative (N).   
 
False Negative: Fake Negative Reviews in the 
testing data, which are incorrectly classified by the 
model as Negative (N).   
    True negative (TN) are events which are real and are 
effectively labeled as real, True Positive (TP) are events 
which are fake and are effectively labeled as fake. 
Respectively, False Positives (FP) refer to Real events being 
classified as fakes; False Negatives (FN) are fake events 
incorrectly classified as Real events. The confusion matrix, 
(1)-(6) shows numerical parameters that could be applied 
following measures to evaluate the Detection Process (DP) 
performance. In Table III, the confusion matrix shows the 
counts of real and fake predictions obtained with known data, 
and for each algorithm used in this study there is a different 
performance evaluation and confusion matrix. 
TABLE III.  
THE CONFUSION MATRIX 
 
Real 
Fake 
Real 
True Negative Reviews 
(TN) 
False Positive Reviews 
(FP) 
Fake 
False Negative Reviews 
(FN) 
True Positive Reviews  
(TP) 
 
         Fake Positive Reviews Rate = FP/FP+TN 
(1) 
         Fake Negative Reviews Rate = FN/TP+FN 
(2) 
         Real Positive Reviews Rate = TP/TP+FN 
(3) 
         Real Negative Reviews Rate = TN/TN+FP                
(4) 
         Accuracy = TP+TN/TP+TN+FN+FP                         
(5) 
         Precision = TP/TP+FP 
(6) 
 
    The confusion matrix is a very important part of our study 
because we can classify the reviews from datasets whether 
they are fake or real reviews. The confusion matrix is applied 
to each of the five algorithms discussed in Step 4. 
Step 6: Comparison of results 
     In this step, we compared the different accuracy provided 
by the dataset of movie reviews with various classification 
algorithms and identified the most significant classification 
algorithm for detecting Fake positive and negative Reviews. 
 
IV. 
EXPERIMENTS AND RESULT ANALYSIS 
      In this section, we present experimental results from five 
different supervised machine learning approaches to 
classifying sentiment of our datasets which is compared with 
movie review dataset V2.0 and Movie Review dataset V1.0.  
Also, we have used the same methods at the same time to 
detect fake reviews. 
68
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

A. Experimental result on dataset V2.0 
1) Confusion matrix for all methods 
   The number of real and fake predictions made by the 
classification model compared with the actual results in the 
test data is shown in the confusion matrix.  The confusion 
matrix is obtained after implementing NB, SVM, K-NN, K*, 
DT-J48 algorithms. Table IV displays the results for 
confusion matrix for V2.0 dataset. The columns represent the 
number of predicted classifications made by the model.  
The rows display the number of real classifications in the test 
data. 
TABLE IV.  
CONFUSION MATRIX FOR ALL METHODS 
 
2) Evaluation parameters and accuracy for all methods 
    Five main performance evaluation measures have been 
introduced for Classification algorithms. These include Fake 
Positive Reviews predictive value, Fake Negative Reviews 
predictive value, Real Positive Reviews predictive value, 
Real Negative Reviews predictive value, accuracy and 
Precision. Table V shows the results of evaluation parameters 
for all methods and provides a summary of recordings 
obtained from the experiment. SVM surpasses as the best 
accuracy among the other classification algorithms with 
81.35%. The tabulated observations list the readings as well 
as accuracies obtained for a specific supervised learning 
algorithm on a dataset of a movie review. 
TABLE V.  
EVALUATION PARAMETERS AND ACCURACY FOR 
ALL METHODS. 
Classification 
algorithms 
Fake 
Positive 
Reviews 
% 
Fake 
Negative 
Reviews 
% 
Real 
Positive 
Reviews 
% 
Real 
Negative 
Reviews 
% 
Precision 
% 
Accur
acy % 
NB 
21.9 
18.7 
81.3 
78.1 
78.8 
79.7 
K-NN-IBK 
(K=3) 
19.6 
38.7 
61.3 
80.4 
75.8 
70.85 
K* 
24 
33.7 
66.3 
76 
73.4 
71.15    
SVM 
19.1 
18.2 
81.8 
80.9 
81.1 
81.35 
DT-J48 
23.8 
33 
67 
76.2 
73.8 
71.6 
 
The graph in Figure 2 shows a rate of Fake Positive Reviews, 
Fake Negative Reviews, Real Positive Reviews, Real 
Negative Reviews, Accuracy, and Precision for comparative 
analysis of all different algorithms. 
 
 
Figure 2.    Comparative analysis of all methods 
 
   The comparison in Table VI indicates that the classification 
accuracy of SVM algorithm was better than NB, KNN-IBK, 
K*, and DT-J48 algorithms. 
TABLE VI.  
COMPARISON OF ACCURACY OF CLASSIFIERS 
Classification algorithms 
Accuracy % 
NB 
79.7 
KNN-IBK (K=3) 
70.85 
K* 
71.15    
SVM  
81.35 
DT-J48  
71.6 
 
    The graph in Figure 3 shows accuracy rate of NB, SVM, 
(K-NN, k=3), and DT-J48 algorithms. We obtained a higher 
accuracy in SVM algorithm than in the other algorithms. 
 
 
Figure 3.    Graph showing the accuracy of different algorithms 
 
Table VII shows the time taken by each algorithm to build 
prediction model. As it is evident from the table, K-star takes 
the shortest amount of time of 0 seconds to create a model 
and SVM takes the longest amount of time of 14840 seconds 
to build a model. 
 
 
Classification 
algorithms 
SA 
Real 
Fake 
NB 
Real 
Fake 
 
781 
187 
 
219 
813 
 
KNN-IBK (K=3) 
Real 
Fake 
 
804 
387 
 
196 
613 
 
K* 
Real 
Fake 
 
760 
337 
 
240 
663 
 
SVM  
Real 
Fake 
 
809 
182 
 
191 
818 
 
DT-J48  
Real 
Fake 
 
762 
330 
 
238 
670 
 
69
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

TABLE VII.  
TIME TAKEN TO BUILD MODEL 
Classification algorithms 
Time taken to build model (milliseconds) 
NB 
110 
KNN-IBK (K=3) 
10  
K* 
0  
SVM  
14840 
DT-J48  
340 
 
B.  Experimental results on dataset v1.0 
1. Confusion matrix for all methods 
   The previous section compared different algorithms with 
different datasets. In this section, the algorithms are applied 
to perform a sentiment analysis on another dataset. From the 
results presented in Table VIII, the confusion matrix displays 
results for movie reviews dataset v1.0. 
TABLE VIII.  CONFUSION MATRIX FOR ALL METHODS 
Classification 
algorithms 
SA 
Real 
Fake 
NB 
Real 
Fake 
 
455 
162 
 
245 
538 
 
KNN-IBK (K=3) 
Real 
Fake 
 
480 
193 
 
220 
507 
 
K* 
Real 
Fake 
 
491 
219 
 
209 
481 
 
SVM  
Real 
Fake 
 
516 
152 
 
184 
548 
 
DT-J48 
Real 
Fake 
 
498 
219 
 
202 
481 
 
 
2. Evaluation parameters and accuracy for all 
methods 
   Five main performance evaluation measures have been 
introduced for Classification algorithms. These include Fake 
Positive Reviews predictive value, Fake Negative Reviews 
predictive value, Real Positive Reviews predictive value, 
Real Negative Reviews predictive value, accuracy and 
Precision. Table IX displays the results of evaluation 
parameters for all methods and provides a summary of 
recordings obtained from the experiment. As a result,  SVM 
surpasses for best accuracy among the other classification 
algorithms with 76%.  
TABLE IX.  
EVALUATION PARAMETERS AND ACCURACY FOR 
ALL METHODS 
 
 
 
The graph in Figure 4 displays a rate of Fake Positive 
Reviews, Fake Negative Reviews, Real Positive Reviews, 
Real Negative Reviews, Accuracy, and Precision for 
comparative analysis of all different algorithms. 
 
0
50
100
NB
K-NN-IBK
(K=3)
K*
SVM
DT-J48
Chart of comparative analysis 
Fake Positive Reviews %
Fake negative Reviews %
Real Positive Reviews %
Real negative Reviews %
 Figure 4.   Comparative analysis of all methods 
 
     The comparison in Table X indicates that the 
classification accuracy of SVM algorithm was better than 
NB, KNN-IBK, and DT-J48 algorithms. 
TABLE X.  
COMPARISON OF ACCURACY OF CLASSIFIERS 
Classification algorithms 
Accuracy % 
NB 
70.9 
KNN-IBK (K=3) 
70.5 
K* 
69.4 
SVM  
76 
DT-J48  
69.9 
 
    The graph in Figure 5 displays accuracy rate of NB, SVM, 
(K-NN, k=3), DT-J48 algorithms. We obtained a higher 
accuracy of SVM algorithm than other algorithms. 
 
 
Figure 5.    Accuracy of different algorithms 
 
 
Classification 
algorithms 
Fake 
Positive 
Reviews 
% 
Fake 
Negative 
Reviews 
% 
Real 
Positive 
Reviews 
% 
Real 
Negative 
Reviews 
% 
Precision 
% 
Accur
acy % 
NB 
35 
23.1 
76.9 
65 
68.7 
70.9 
K-NN-IBK 
(K=3) 
31.4 
27.6 
72.4 
68.6 
69.7 
70.5 
K* 
29.9 
31.3 
68.7 
70.1 
69.7 
69.4 
SVM 
26.3 
21.7 
78.3 
73.7 
74.9 
76 
DT-J48 
28.9 
31.3 
68.7 
71.1 
70.4 
69.9 
70
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

TABLE XI.  
TIME TAKEN TO BUILD MODEL 
Classification algorithms 
Time taken to build model 
(milliseconds) 
NB 
90 
KNN-IBK (K=3) 
0  
K* 
10 
SVM  
4240 
DT-J48  
330 
 
   Table XI displays the time taken by each algorithm to build 
prediction model. As it is evident from the table, K-NN takes 
the shortest amount of time of 0 seconds to create a model 
and SVM takes the longest amount of time of 4.24 seconds to 
build a model. 
 
C. Discussion 
     Table XII and Figure 6 present the summary of the 
experiments. Five supervised machine learning algorithms: 
NB, SVM, K-NN, K*, DT-J48 have been applied to the 
online movie reviews. We observed that well-trained 
machine learning algorithms could perform very useful 
classifications on the sentiment polarities of reviews. In terms 
of accuracy, SVM is the best algorithm for all tests since it 
correctly classified 81.35% of the reviews in dataset V2.0 
and 76% of the reviews in dataset V1.0. SVM tends to be 
more accurate than other methods.  
TABLE XII.  
THE BEST RESULT OF OUR EXPERIMENTS 
Experiments 
Fake 
Positive 
Reviews of 
SVM % 
Fake 
Negative 
Reviews of 
SVM % 
Precision 
of SVM 
% 
Accuracy of 
SVM % 
Results on 
dataset V2.0 
19.1 
18.2 
81.1 
81.35 
Results on 
dataset V1.0 
26.3 
21.7 
74.9 
76 
 
Figure 6.   Summary of our experiments 
 
   The presented study emphasizes that the accuracy of SVM 
is higher for Movie Review dataset V2.0. However, the 
detection process of Fake Positive Reviews and Fake 
Negative Reviews offers less promising results for Movie 
Review dataset V2.0 in comparison to Movie Review dataset 
V1.0 as evident from table XII. 
 
V. 
CONCLUSION AND FUTURE WORK 
In this paper, we proposed several methods to analyze a 
dataset of movie reviews. We also presented sentiment 
classification algorithms to apply a supervised learning of the 
movie reviews located in two different datasets. Our 
experimental approaches studied the accuracy of all 
sentiment classification algorithms, and how to determine 
which algorithm is more accurate. Furthermore, we were able 
to detect fake positive reviews and fake negative reviews 
through detection processes.  
Five supervised learning algorithms to classifying 
sentiment of our datasets have been compared in this paper: 
NB, K-NN, K*, SVM, and DT-J48. Using the accuracy 
analysis for these five techniques, we found that SVM 
algorithm is the most accurate for correctly classifying the 
reviews in movie reviews datasets, i.e., V2.0 and V1.0. Also, 
detection processes for fake positive reviews and fake 
negative reviews depend on the best method that is used in 
this study.  
For future work, we would like to extend this study to use 
other datasets such as Amazon dataset or eBay dataset and 
use different feature selection methods. Furthermore, we may 
apply sentiment classification algorithms to detect fake 
reviews using various tools such as Python and R or R studio, 
Statistical Analysis System (SAS), and Stata; then we will 
evaluate the performance of our work with some of these 
tools. 
 
ACKNOWLEDGMENT 
Mr. Elshrif Elmurngi would like to thank the Ministry of 
Education in Libya and Canadian Bureau for International 
Education (CBIE) for their support to his Ph.D. research 
work. 
REFERENCES 
[1] B. Liu, “Sentiment analysis and opinion mining,” Synthesis 
lectures onhuman language technologies, vol. 5, no. 1, 2012, 
pp. 1–167. 
[2] W. Medhat, A. Hassan, and H. Korashy, “Sentiment analysis 
algorithmsand  applications:  A  survey,”  Ain  Shams  
Engineering  Journal,  vol.  5,no. 4, 2014, pp. 1093–1113. 
[3] B.  Pang,  L.  Lee,  and  S.  Vaithyanathan,  “Thumbs  up? 
sentiment  classi-fication using machine learning techniques,” in 
Proceedings of EMNLP,2002, pp. 79–86. [Online]. Available  
:http://www.cs.cornell.edu/People/pabo/movie%2Dreview%2Ddat
a/ 
71
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

[4] J. Malbon, “Taking fake online consumer reviews seriously,” 
Journal ofConsumer Policy, vol. 36, no. 2, 2013, pp. 139–157. 
[5] R. Xia, C. Zong, and S. Li, “Ensemble of feature sets and 
classificationalgorithms for sentiment classification,” Information 
Sciences, vol. 181,no. 6, 2011, pp. 1138–1152. 
[6] T. Barbu, “Svm-based human cell detection technique using 
histogramsof oriented gradients,” cell, vol. 4, 2012, p. 11. 
[7] G. Esposito, LP-type methods for Optimal Transductive 
Support VectorMachines.    Gennaro Esposito, PhD, 2014, vol. 
3. 
[8] P. Kalaivani and K. L. Shunmuganathan, "Sentiment classification of 
movie reviews by supervised machine learning approaches," Indian 
Journal of Computer Science and Engineering, vol. 4, no. 4, pp. 285-
292, 2013. 
[9] B. Pang and L. Lee, “A sentimental education: Sentiment analysis 
usingsubjectivity summarization based on minimum cuts,” in 
Proceedings ofthe 42nd annual meeting on Association for 
Computational 
Linguistics.Association 
for 
Computational 
Linguistics, 
2004, 
p. 
271. 
[Online]. 
Available 
from: 
http://www.cs.cornell.edu/People/pabo/movie%2Dreview%2Ddata
/ 
[10] S. Hassan, M. Rafi, and M. S. Shaikh, “Comparing svm and 
naive bayesclassifiers  for  text  categorization  with  
wikitology  as  knowledge  enrich-ment,” in Multitopic 
Conference (INMIC), 2011 IEEE 14th International.IEEE, 
2011, pp. 31–34.. 
[11] C.-H.  Chu,  C.-A.  Wang,  Y.-C.  Chang,  Y.-W.  Wu,  Y.-L.  
Hsieh,  and  W.-L.  Hsu,  “Sentiment  analysis  on  chinese  
movie  review  with  
distributedkeyword  vector  
representation,”  in  Technologies  and  Applications  
ofArtificial  Intelligence  (TAAI),  2016  Conference  on.IEEE,  
2016,  pp.84–89 
[12] V.  Singh,  R.  Piryani,  A.  Uddin,  and  P.  Waila,  “Sentiment  
analysis  ofmovie  reviews  and  blog  posts,”  in  Advance  
Computing  Conference(IACC), 2013 IEEE 3rd International.    
IEEE, 2013, pp. 893–898. 
[13] G.  Vinodhini  and  R.  Chandrasekaran,  “Sentiment  analysis  
and  opinionmining: a survey,” International Journal, vol. 2, no. 
6, 2012, pp. 282–292. 
[14] G. Xu, Y. Cao, Y. Zhang, G. Zhang, X. Li, and Z. Feng, “Trm: 
Computingreputation score by mining reviews.” in AAAI 
Workshop: Incentives andTrust in Electronic Communities, 
2016. 
[15] N. Tian, Y. Xu, Y. Li, A. Abdel-Hafez, and A. Josang, 
“Generating prod-uct feature hierarchy from product reviews,” 
in International Conferenceon  Web  Information  Systems  and  
Technologies.Springer,  2014,  pp.264–278. 
[16] N. Tian, Y. Xu, Y. Li, A. Abdel-Hafez, and A. Jøsang, 
“Product featuretaxonomy  learning  based  on  user  reviews.”  
in  WEBIST  (2),  2014,  pp.184–192. 
[17] A. Abdel-Hafez and Y. Xu, “A survey of user modelling in 
social mediawebsites,” Computer and Information Science, 
vol. 6, no. 4, 2013, p. 59. 
[18] A.  Abdel-Hafez,  Y.  Xu,  and  D.  Tjondronegoro,  “Product  
reputationmodel:  an  opinion  mining  based  approach,”  in  
SDAD  2012  The  1stInternational  Workshop  on  Sentiment  
Discovery  from  Affective  Data,2012, p. 16. 
[19] N. Jindal and B. Liu, “Opinion spam and analysis,” in 
Proceedings of the2008 International Conference on Web 
Search and Data Mining.   ACM,2008, pp. 219–230. 
[20] R. Moraes, J. F. Valiati, and W. P. G. Neto, “Document-level 
sentimentclassification:  An  empirical  comparison  between  
svm  and  ann,”  ExpertSystems with Applications, vol. 40, no. 
2, 2013, pp. 621–633. 
[21] B.  Liu,  M.  Hu,  and  J.  Cheng,  “Opinion  observer:  
analyzing  and  com-paring  opinions  on  the  web,”  in  
Proceedings  of  the  14th  internationalconference on World 
Wide Web.    ACM, 2005, pp. 342–351. 
[22] A.  Fujii  and  T.  Ishikawa,  “A  system  for  summarizing  and  
visualizingarguments 
in 
subjective 
documents: 
Toward 
supporting decision making,”in Proceedings of the Workshop 
on Sentiment and Subjectivity in Text.Association for 
Computational Linguistics, 2006, pp. 15–22. 
[23] L.-W. Ku, Y.-T. Liang, and H.-H. Chen, “Opinion extraction, 
summariza-tion  and  tracking  in  news  and  blog  corpora,”  
in  Proceedings  of  AAAI,2006, pp. 100–107.  
[24] C. Cortes and V. Vapnik, “Support-Vector Networks,” 
Machine Learning, vol. 20, 1995. 
[25] Y. Song, J. Huang, D. Zhou, H. Zha, and C. L. Giles, “Iknn: 
Informativek-nearest neighbor pattern classification,” in 
PKDD.   Springer, 2007, pp.248–264. 
[26] G.  Bhattacharya,  K.  Ghosh,  and  A.  S.  Chowdhury,  “An  
affinity-basednew  local  distance  function  and  similarity  
measure  for  knn  algorithm,”Pattern Recognition Letters, vol. 
33, no. 3, 2012, pp. 356–363. 
[27] M.  Latourrette,  “Toward  an  explanatory  similarity  measure  
for  nearest-neighbor classification,” Machine Learning: 
ECML 2000, 2000, pp. 238–245. 
[28] S.   Zhang,   “Knn-cf   approach:   Incorporating   certainty   
factor   to   knnclassification.” IEEE Intelligent Informatics 
Bulletin, vol. 11, no. 1, 2010,pp. 24–33. 
[29] M.  Hall,  E.  Frank,  G.  Holmes,  B.  Pfahringer,  P.  
Reutemann,  and  I.  H.Witten,  “The  weka  data  mining  
software:  an  update,”  ACM  SIGKDDexplorations 
newsletter, vol. 11, no. 1, 2009, pp. 10–18. 
 
 
 
 
 
 
 
 
72
Copyright (c) IARIA, 2017.     ISBN:  978-1-61208-603-3
DATA ANALYTICS 2017 : The Sixth International Conference on Data Analytics

