Use of Augmented Reality (AR) and Virtual Reality (VR) to address four of the 
“National Academy of Engineering Grand Challenges for Engineering in the 21st 
Century”  
 
Bibhav Bhattarai  
Computer Science & Software Engineering 
Auburn University 
Auburn, USA 
bzb0079@auburn.edu 
 
 
Abstract— The National Academy of Engineering’s “Fourteen 
Grand Challenges for Engineering in the Twenty-First Century” 
identifies challenges in science and technology that are both 
feasible and sustainable to help people and the planet prosper. 
Four of these challenges are: advance personalized learning, 
enhance virtual reality, make solar energy affordable and 
provide access to clean water. In this work, the authors discuss 
developing of applications using immersive technologies, such as 
Virtual Reality (VR) and Augmented Reality (AR) and their 
significance in addressing four of the challenges. The Drinking 
Water AR mobile application helps users easily locate drinking 
water sources inside Auburn University (AU) campus, thus 
providing easy access to clean water. The Sun Path mobile 
application helps users visualize Sun’s path at any given time 
and location. Students study Sun path in various fields but often 
have a hard time visualizing and conceptualizing it, therefore 
the application can help. Similarly, the application could 
possibly assist the users in efficient solar panel placement. 
Architects often study Sun path to evaluate solar panel 
placement at a particular location. An effective solar panel 
placement helps optimize solar energy cost. The Solar System 
Oculus Quest VR application enables users in viewing all eight 
planets and the Sun in the solar system. Planets are simulated to 
mimic their position, scale, and rotation relative to the Sun. 
Using the Oculus Quest controllers, disguised as human hands 
in the scene, users can teleport within the world view, and can 
get closer to each planet and the Sun to have a better view of the 
objects and the text associated with the objects. In a camp held 
virtually, due to Covid-19, K12 students were introduced to the 
concept and usability of the applications. Likert scales metric 
was used to assess the efficacy of application usage. The data 
shows that participants of this camp benefited from an 
immersive learning experience that allowed for simulation with 
inclusion of VR and AR. 
 
Keywords-Augmented Reality; Engineering Challenges; 
Immersive Technology; Virtual Reality. 
 
I. 
INTRODUCTION 
The National Academy of Engineering’s “Fourteen 
Grand Challenges for Engineering in the Twenty-First 
Century” identifies challenges in science and technology that 
are both feasible and sustainable to help people and the 
planet prosper. The grand challenges of engineering were 
announced in 2008 by a committee of leading technological  
Daniela Marghitu 
Computer Science & Software Engineering 
Auburn University 
Auburn, USA 
marghda@auburn.edu 
 
 
thinkers. These challenges were broadly classified into fourteen 
game-changing goals. Working towards these goals, as per the 
committee, is a way for improving life on the planet [1]. This 
research makes use of immersive technologies to addresses 
four of such challenges: 1. Advance personalized learning, 2. 
Enhance virtual reality, 3. Make solar energy affordable, 
and 4. Provide access to clean water. 
AR and VR are two emerging, immersive technologies in 
recent times. AR creates a composite view by adding digital 
content to a real-world view, often by using the camera of a 
smartphone while VR creates an immersive view where the 
user’s view is often cut off from the real world. In AR, users’ 
world views remain intact and virtual objects simply augment 
the reality, whereas, in VR, users’ world views are totally 
altered, and they can no longer see their actual surroundings. 
In this research, a VR application aims to address the 
first two challenges while two AR applications aim to address 
the last two challenges. The VR application assists users in 
visualizing and understanding our solar system by using a VR 
headset. Users can take an immersive, virtual tour of the solar 
system. This virtual simulation closely parallels the 
movements of the planets, as well as their form, scale, and 
location in relation to the Sun. Thus, this application enables 
users to view our solar system in an immersive environment, 
which could be helpful in visualizing and comprehending a 
system that is not easily observable. The Drinking Water AR 
application 
displays 
information 
on 
drinking 
water 
accessibility and the environmentally sustainable use of water 
bottles rather than plastic cups. The application can be used to 
locate drinking water related information by simply pointing 
the device camera towards a Point of Interest (POI). Also, it 
can be used to file and view water-related complaints. Thus, 
the application helps users to conveniently identify drinking 
water related information inside AU, thus providing easy 
access to clean drinking water. The Sun Path AR application 
helps users visualize Sun’s path at a selected date and 
location. Students study the Sun’s path in several areas, but 
they often fail to visualize and comprehend it. Architects often 
analyze the sun’s path to evaluate the positioning of solar 
panels at a particular location. An effective solar panel 
placement helps optimize solar energy cost. Thus, the 
application could possibly assist the users in efficient solar 
panel placement. 
44
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

Empirical studies on the effectiveness of adding mobile 
game-based augmented reality into basic education suggests 
that AR techniques can boost student learning [2]. Similarly, 
there is an AR application to hydrate dementia-affected older 
adults [3]. The application reminds, inspires, directs, and 
monitors hydration among those adults. Likewise, students 
were readily engulfed in AR and their ability to interact with 
the interface and control virtual objects helped them to 
understand 
more 
advanced 
concepts 
of 
Earth-Sun 
relationships [4]. All the above-mentioned works in the 
literature back up this study's argument that AR can help 
with customized learning, resource access, and visualizing 
abstract concepts. 
In conclusion, the applications serve as a proof of 
concept for use of immersive technology in addressing 
engineering concerns. In addition, K-12 students were 
introduced to the concept and usability of applications at a 
camp held virtually due to Covid-19. Likert scales metric 
was used to assess the efficacy of application usage.  
In section 2, the paper discusses previous work by other 
authors related to this research. The project architecture used 
in the research is then presented in section 3. In section 4, the 
paper depicts the usability study of the research. In section 5, 
the result of the study is reported. Finally, in section 6, the 
authors provide conclusions and future work briefings. 
II. 
RELATED WORK 
 
A. AR/VR Modes and Characteristics 
Virtual reality and augmented reality are two different 
types of immersive technology. Virtual reality (VR) fully 
takes over one's vision, giving users the feeling of being 
transported from the physical world to a virtual one. On the 
other hand, augmented reality (AR) simply overlays virtual 
objects onto the user's view of the real world. Based on the 
underlying implementation scheme, AR is classified into 
three different categories: Marker-less AR, Mark-based AR, 
and Location-based AR. In the same way, VR is classified in 
3 Degrees of Freedom (DoF) and 6DoF based on user's 
degree of freedom. 
Augmented Reality creates a composite view by adding 
virtual components to users’ real view. AR is quite popular 
these days in various fields such as social media, learning, 
shopping and so forth. With the advent of Snapchat filters, 
AR became quite popular in social media. Soon after 
Facebook too integrated filter-based AR functionalities in 
many of its applications. Similarly, Ikea has AR features in 
its shopping application with the help of which customers 
can pick a product and place it at different points in their 
world view to see how the virtual product fits in their world 
view. Likewise, various apps such as Quiver, Blippar and 
Aurasma use AR to help student with learning [5]. There are 
basically 3 types of AR: Marker-based AR, Marker-less AR, 
and Location-based AR. 
Marker-based AR uses pre-defined markers set by the 
developer of the application. When the markers are detected 
in the real world, virtual objects are augmented to the scene. 
Markers may be any form of 2D image, including black- 
and-white and color images. Figure 1 depicts AR content 
overlay over a pre-defined marker. 
 
 
 
 
Figure 1. Marker based AR [6]. 
 
Marker-less AR is not bounded to a particular marker, but 
rather allows users to position objects anywhere they want 
within their real-world view. After placing an object, even if 
the device camera is removed from the line of sight, the 
application still remembers the position of the object using a 
method called Simultaneous Localization and Mapping 
(SLAM), and so when the device is brought back into line of 
sight the object is once again visible [7]. Figure 2 is an AR 
enabled retail application by Ikea. It is a marker-less AR app 
that allows users to place virtual products at desired position 
before buying them, thus assisting users with product selection 
and decision-making. 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. IKEA AR app example [8]. 
Location-based AR enables the ability to place virtual 
objects at various GPS coordinates. Location-based AR, in its 
simplest form, collects data from device components such as 
GPS, accelerometer and digital compass to identify the device 
location and position. The application then compares device 
data to POI information and adds virtual objects to the real 
environment accordingly [9]. An example of one of the most 
popular location-based AR apps is Pokémon Go. Figure 3 
depicts another location- based AR application where different 
points of interest objects are overlaid as per their 
corresponding GPS coordinates. 
 
 
Figure 3. Location based AR app [10]. 
 
45
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

VR is an immersive technology that allows users to 
interact with a virtual environment as if it were the reality. 
In virtual reality, Head-Mounted Displays (HMDs) are 
important for bringing the technology to life. An HMD is 
worn over the head, with the user's world view entirely 
obscured and only the screen displays visible in front of their 
eyes. The display supports a stream of data, images, and 
other such material. Currently, there are several powerful 
3DoF and 6DoF HMDs available on the market. Google 
Cardboard is an example of a 3DoF headset and supports 
3DoF (rotational movement around the x, y, and z axes). 
Similarly, Oculus Quest by Facebook, illustrated in Figure 
4, is an example of a 6DoF headset and supports 6DoF 
(rotational movement around the x, y, and z axes, up, down 
forward, and backward). 
 
 
 
Figure 4. Oculus Quest headset [11]. 
6DoF tracking ensures a higher level of immersion than 
3DoF as the user presence is more authentic. Figure 5 
illustrates 3DoF and 6DoF tracking. 
 
 
 
Figure 5. 3DoF and 6DoF [12]. 
B. Applications in Academic Settings 
A survey study regarding use of augmented reality 
provided a scenario in which enabled mobile devices were 
used for learning and the associated pros and cons of the 
device usage was evaluated [2]. The questionnaire type 
survey is based on one single application – EduPARK – 
which analyzes mobile learning via students’ opinion 
regarding the use of mobile devices for learning. The survey 
considers a total of 244 students at primary Portuguese 
Education System. The study participants consisted of 
students aged 10-16 years old among which 51.6 percent 
were girls and 48.4 percent were boys. The EduPARK 
application is designed for a specific urban park in Portugal. 
The application uses Augmented Reality (AR) to 
provide various biological and historical references of the 
local park. The app was developed in Unity 5 using Vuforia 
framework and makes use of Vuforia’s 2D marker-based 
technology. The marker-based technology allows the app to 
detect images/markers, pre-defined by the app creator, and 
overlay AR contents when the markers are detected by the 
device camera. As per the paper, the markers were manually 
installed in either tiles already existing in the park, or on 
plaques positioned for the purpose of sticking the markers 
onto them. The authors of the paper weigh in on students’ 
perspective with the application usage. The findings of the 
paper suggest that the overall perspective remained positive 
with application usage amongst the students. The study also 
suggests that students believe that mobile devices, in general, 
are beneficial when they want to quickly find up-to- date 
information. However, students had their concerns with some 
of the external aspects of the application usage such as 
unstable, slow access to internet connectivity, restrictions 
forbidding them from carrying mobile devices to the 
classroom and ease of distraction by other applications in 
the mobile device. All in all, this paper suggests that use of 
AR mobile applications in learning can be beneficial. 
A study was done that proposed an AR app that helps 
cognitively impaired elderly people with hydration [3]. Even 
though a significant number of older adults are capable of 
drinking water/fluid by themselves, several cognitive deficits 
such as poor initiation, decreased motivation, amnesia, and 
premature decay of intention may hinder their capability [13]. 
Poor Initiation in older adults is observed when they fail to 
recall, and this deficit is common in elderly people with 
dementia [14]. Due to poor initiation, old adults fail to recall 
where and how to fetch water. Often, older adults have a 
degraded sense of taste and smell due to which drinking water 
might not be as quenching. Thickening of orbitofrontal cortex, 
a part of the brain that pleases and is activated after drinking 
water [14], when medically observed in older adults, results in 
lack of fulfillment and delight that follows water intake [15]. 
Premature decay of intention occurs when a certain activity 
takes longer than anticipated time to fulfil, or when an activity 
is thought of, but execution is hindered by some other 
distraction. Decay in intention is significantly higher in 
elderly people with cognitive defects [16]. The paper claims 
that the AR app proposed has advantages over existing water 
drinking reminder apps when it comes to helping cognitively 
impaired old adults to stay hydrated [3]. The app makes use of 
Vuforia marker- based technology and a game like activity to 
motivate users to meet/increase water intake. Furthermore, it 
also mentions carrying out a feasibility study of two versions 
of the app- basic and advanced - with elderly people (in 
assistance with their caregivers) to find out which of the two 
could be more suitable. It is, therefore, clear from the paper 
that the proposed AR game is beneficial for hydration amongst 
elderly people since it assists them to cope with their cognitive 
disabilities. 
In the application-based paper, the authors use AR 
involving exercises designed to teach spatial concepts of 
rotation/revolution, solstice/equinox, and seasonal variation of 
light and temperature [4]. It utilizes ARToolkit to teach about 
earth-sun relationships to thirty undergraduate geography 
students. Users utilized a lightweight Cy-Visornf DH-440 head 
mounted display (HMD) with a Logitech QuickCam Pro 3000 
video camera attached. The HMD and camera were connected 
46
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

Figure 6. Drinking Water AR application wireframe 
to a laptop running Windows XP and ARToolkit version 
2.52 software. The paper claims that students find it 
challenging to understand spatial concepts and phenomena 
that are complex, and the use of AR based application 
resulted 
in 
a 
significant 
improvement 
in 
student 
understandings along with reduction in misunderstandings. 
Often, teachers use 3d objects or props available in the 
classroom to explain complex concepts but both teacher and 
students struggle since the available objects often fail to 
mimic the actual concept. AR based applications usually 
come in handy at such scenario and eradicate the need for 
props. The research made use of pre- and post-assessment 
worksheets, and the analysis of the assessment resulted in 
some definitive statistics as follows: 
• 
In general, conceptual, and factual understanding 
of the concepts improved in all cases. 
• 
The most significant improvement was seen in 
those with lower pre-assessment scores. 
• 
Most of the students resorted to pictorial 
descriptions to help illustrate their understanding 
on both pre and post assessment which further 
fortified the stance on use of pictures being more 
intuitive when it comes to understanding and 
explaining complex spatial concepts 
The research also made some qualitative analyses and 
drew some definitive conclusions as stated below: 
• 
Ability to interact with the interface and control 
over virtual objects helped students to understand 
more advanced concepts. 
• 
In some cases, the students could no longer 
distinguish the difference between real and 
superimposed virtual objects. In no time, they felt 
like all virtual objects were assimilated in the real 
world. 
The paper, thus, explores AR’s potential to help student 
visualize complex spatial concepts, and puts forth a definitive 
conclusion that AR rightly assists students with their learning 
and understanding. 
III. 
PROJECT ARHITECTURE 
 
A. Approaches to Deployment 
The approach to deployment depends on the wireframes 
of the applications. 
Wireframes for Drinking Water AR Application: 
The welcome activity is a splash screen that shows the logo 
of the application and lets users know that the application is 
starting up. After the splash screen is successfully rendered, 
if it is the first time that the user is using the app then the app 
will ask the user for device camera and GPS permissions. 
When and if the user allows all required permissions, then 
the loading device location dialog is shown while device 
GPS is asynchronously being fetched by a background 
thread. After the location is fetched the app makes use of 
ARCoreLocation to fetch and position the water marker 
overlay on the device camera view. The main activity also 
has a view/file complaint button which can be used by 
general users to file complaint and admin users to view and 
resolve the complaints. The user authentication and data 
storage functionalities are achieved using Google’s Firebase (a 
cloud database). The application wireframes are illustrated in 
Figure 6. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Wireframes for Sun Path AR Application: The 
welcome activity is a splash screen that shows the logo of the 
application and lets the user know that the application is 
starting up. After the splash screen is successfully rendered, if 
it is the first time that the user is using the app then the app 
will ask the user for device camera permission. When and if 
the user allows camera access, the user is taken to the main 
activity of the application. All other functionalities of the 
application is found in the main screen of the app. The 
application wireframes are illustrated in Figure 7. 
 
 
47
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

 
 
 
 
 
 
 
 
 
 
 
 
 
 
Wireframes for Solar System VR Application: The 
main screen is the world space view for the user. The view 
includes all eight planets and the Sun in the solar system. 
All planets are simulated to mimic their position, scale, and 
rotation relative to the Sun. Users can use the Oculus Quest 
controllers to teleport within the world view. To give users a 
more realistic feel, the controllers are disguised as human 
hands in the scene. Users can get closer to each planet and 
the Sun to have a better view of the objects and the text 
associated with the objects. The application wireframe is 
illustrated in Figure 8. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 8. Solar System VR application wireframe 
 
B. Equipment Selection 
Software & hardware requirements stay the same for AR 
applications and differ with the VR application. 
AR applications software requirements: 
• 
Minimum Android version: 7 (API level 24). 
• 
Target Android version: 9 (API level 28) 
AR applications hardware requirements: 
• 
ARCore supported Android mobile devices. 
• 
Target Android version: 9 (API level 28) 
VR application software requirements: 
• 
Quest builds 20.0 release 
VR application hardware requirements: 
• 
Oculus Quest. 
C. Drinking Water AR Application 
The pictorial representation in Figure 9 is the flowchart 
that depicts the runtime flow of the water application. When 
the application is started it first checks to see whether the 
device is supported. If the device is supported, then the 
application seeks user permission to use device camera and 
GPS coordinates since both components are required for the 
application to run. Once the permissions are granted then 
the application initializes ARCore and ARCorelocation 
functionalities asynchronously. After the asynchronous 
methods return Future objects, the application renders the 
location markers. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 9. Solar System VR application wireframe 
 
The water AR application is developed in Android Studio 
using Java programming language, and libraries such as 
Google’s ARCore, Google’s FireBase and ARCoreLocation by 
APPoly. ARCore is Google’s platform for building AR 
experiences. It assists a device to understand its real 
environment so that it can augment it. Two fundamental 
features of ArCore are as follows: 
• 
Motion tracking: allows tracking position of the 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7. Sun Path AR application wireframe 
48
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

mobile device relative to the world. 
• 
Understanding of the real world: Allows 
devices to understand vertical and horizontal 
surfaces and planes [17] 
ARCore API which handles session lifecycle, access to 
device camera and pose is instantiated using ARCore session 
class. While this session is running ARCore holds exclusive 
access to device camera. Since this class consumes a 
significant amount of heap memory of the device, it is 
essential to call close method to release memory while not 
using the session. Failure to close may result in app crashing 
[18]. Similarly, ArSceneView is a SurfaceView which 
integrates with ARCore to render a scene [19]. 
Two of the methods from the ArSceneView class that have 
significant implementation in the application are getArFrame 
method which returns the most recent ARCore Frame, if 
available, and getSession method which returns the ARCore 
Session used by the view. Likewise, Frame class in ARCore 
captures the state and changes to the AR system by making a 
call to session object. It makes use of the getCamera method 
of the class to get the camera object [20]. Once the libraries 
are imported, to place a virtual object in a scene, anchor must 
be defined. Anchor class describes a fixed location and 
orientation in the real world [21]. 
Anchor in the application is obtained from the 
ArCoreLocation library by APPoly. APPoly is a software 
company based in the United Kingdom and contributes to 
the open-source community with various software packages. 
One such software package is ARCoreLocation. Since 
ARCore does not support use of real-world coordinates in its 
AR space [22], this application makes use of the ARCore 
Location library to realize the location-based functionality in 
the app. The location library used to realize location- based 
AR is ARCore-Location: 1.2 [23]. ARCoreLocation allows the 
water app to position AR objects at real-world GPS 
coordinates. The real-world GPS coordinates (longitude and 
latitude) are provided to the application by making use of a 
JSON file. 
The application data related to users and complaints is 
handled using Google’s Firebase – a cloud service that is used 
to authenticate users and store data in Cloud Firestore. Cloud 
Firestore is a NoSQL database that can be used to easily store, 
sync and query data for applications. 
 
D. Sun Path AR Application 
The pictorial representation in Figure 10 is the flowchart 
that depicts the runtime flow of the sun path application. 
When the application is started, it seeks user permission to 
use device camera since the component is required for the 
application to run. Once the permission is granted then it 
initializes the default scene and overlays the sun path on top 
of the device camera view. The user then can select custom 
location, date and time and the application will update the 
scene accordingly. Figure 10 depicts the flowchart for the 
application. 
The Sun path AR application is developed in visual 
studio using JavaScript programming language and React 
Native framework. React Native provides developers with a 
community of open-source modules that can be readily 
incorporated in app development. An overview of components 
is as illustrated in Figure 11. This application is realized into 
three main custom components: 1. Location Component 2. 
Display Component, and 3. Main Component. Each of these 
components make use of core components and community 
components and interact with one another. Location 
Component: This is the component where location-based logic 
and code is written. This component makes use of following 
community components: 
• 
@react-native-community/geolocation 
• 
react-native-google-places-autocomplete 
• 
react-native-maps 
Display Component: This is the main user interface 
component where UI logic and code is written. This 
component mainly comprises of core components such as 
View, Text and ScrollView. The community components used 
are: 
• 
@react-native-community/datetimepicker 
• 
react-native-vector-icons/MaterialCommunityIcons 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 10. Solar System VR application wireframe 
 
 
 
Figure 11. React Native overview [24]. 
 
 
Main Component: Is the engine of the application. All 
custom components are called here along with the following 
community components: 
• 
react-native-WebView 
• 
react-native-camera 
49
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

Amongst various sun position calculation algorithms (such as 
Spencer, Pitmann and Vant-Hull, Walraven, PSA, and 
Michalsky), PSA has superior accuracy and performance 
[25]. Figure 12 illustrates PSA algorithm’s performance in 
terms of accuracy in calculating zenith distance, azimuth, 
and sun vector deviation. User provided GPS coordinates, 
date and time is fed into the PSA algorithm function. The 
function returns Sun spherical coordinates and that is used in 
a projection matrix to visualize the sun path and overlay it on 
top of the world view. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 12. PSA algorithm 
 
 
E. Solar System VR Application 
Figure 13 shows the flowchart of the runtime flow of the 
Solar System VR application, developed in Unity using C# 
programming language. When the application is started, it 
first checks to see if the headset in which the application is 
being run is compatible. The application currently only 
supports Oculus Quest, and so trying to run it on other 
headset will cause the application to crash. After the initial 
validation is successful, the app will then initialize the 
camera component and the world space/scene of the 
application. Immediately after, the application will render all 
GameObjects of the scene and start the planetary rotation 
script (which is used to simulate planet revolution around the 
Sun). While in the world space of the application, the user 
can use controllers to teleport to different areas in the solar 
system and have a closer look at each of the planets. As 
illustrated in Figure 14, a scene in Unity can have objects 
that are called GameObjects. GameObjects serve as 
containers for components. Depending on the type of object 
desired, various combinations of components can be added 
to a GameObject. Developers can either use in-built 
components or create a custom component using Unity 
Scripting API [26]. Transform component, which defines 
position and orientation of the object it is attached to, is the 
only indispensable component in a GameObject. All other 
components either default or custom can be attached or 
detached from a GameObject. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 13. Flowchart of Solar System VR Application 
 
 
 
 
Figure 14. Unity3D GameObject Component Model 
 
IV. 
USABILITY STUDY 
 
A. Virtual Educational K12 Camp 
Research in the Formation of Engineers (RFE) computing 
virtual camp was conducted for K-12 students, in which, 
students from grade 9 to 11 participated. These students were 
instructed on important topics of AR/VR and were also asked 
to use the applications. The following observations were 
gathered from students’ responses: 
• 
All the students were unsure if they had used 
AR/VR applications before, as shown in Figure 
15. 
• 
Many students indicated that the use of AR/VR 
functionalities 
helped 
them 
in 
better 
understanding of subject topics. 
• 
Students equivocally agreed that the apps were 
easier to use and that they were able to 
effortlessly determine drinking water sources 
and sun location. 
Pre-survey and post-survey detail the discrepancies in 
subjects' comprehension before and after using the AR/VR 
applications developed for this research. Students developed a 
greater understanding of the technology by using the 
50
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

applications. According to the post-survey findings, as 
depicted in Figure 16, 50 percent of the students strongly 
agreed, and the other 50 percent agreed that using such 
technologies was interesting. The Drinking Water AR app 
made it easy to find drinking water places, according to 50 
percent who agreed somewhat, 25 percent who agreed, and 
the remaining 25 percent who strongly agreed. Similarly, 50 
percent strongly agreed, 25 percent agreed, and 25 percent 
slightly agreed that determining the sun's location using the 
Sun Path AR app was simpler. 
 
B. Pre-Survey 
 
According to the pre-survey findings, as shown in Figure 
15, 100 percent of the students were unaware of the AR/VR 
technology prior to being introduced in this study. 
 
 
 
 
 
 
 
 
 
 
 
Figure 15. Pre-Survey results 
 
C. Post Survey 
According to the Post Survey findings, as shown in Figure 
16, 100 percent of the students agreed that using AR/VR 
technologies is interesting. 
Figure 16. Post Survey results 
 
V. 
RESULTS 
 
A. Drinking Water AR Application 
 
 The application makes use of location-based AR to overlay 
virtual objects when the device is pointed towards the line of 
sight of POIs. Currently, Haley building and Shelby 
Engineering buildings are the POIs for the application. Figure 
17 shows the overlay when the app is brought to the line of 
sight of one of the coordinates. By pointing their phones 
towards the POIs, users can quickly identify drinking water 
sources and related information. In addition, the app also 
promotes civic engagement. Users can register/sign into the 
program and then file complaints about water supplies. Also, 
the application has provisions to add admin users. Admin users 
can look at the complaints and mark them resolved when 
accomplished. Currently, people on campus can use Google 
Maps to locate buildings but they do not have access to 
building related information. In the future, the application 
could be expanded to provide users with not only water 
information about the buildings, but also information about the 
buildings' internal mappings. 
The application makes use of marker-less AR to overlay 
virtual objects in device’s camera view. The main scene of the 
app displays Sun’s path at a given date, time, and location, as 
illustrated in Figure 18. Sun is the major source of energy to 
our planet, and examining its path is essential for better 
harvesting its energy. Sun path diagrams provide a wealth of 
information on how the sun can affect a site and structure over 
the year. The solar azimuth and altitude for a given position 
can be determined using the diagram. A conventional way of 
examining its path is by manually plotting points/lines in the 
diagram to get solar azimuth and altitude. Accurate and timely 
analysis of Sun’s path plays a significant role in multitude of 
sectors. This app eliminates the need to manually measure 
the position of the sun at a specific date, time, and place.  
 
51
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 17. Drinking Water AR Application prototype 
 
B. Sun Path AR Application 
Users can easily access sun related information such as 
sun position, sunrise time and sunset time. Users can use the 
search functionality in the app to visualize Sun’s path in 
any coordinates searchable in Google Maps API, as 
demonstrated in Figure 18. Practical uses, such as estimating 
solar power and solar water capacity, as well as agricultural 
applications, are possible with this app. 
 
Figure 18. Sun Path AR Application prototype 
C. Solar System VR Application 
The application makes use of VR to simulate our solar 
system. In the main scene, users can see the movements of the 
planets, as wells as their form, scale, and location in relation to 
the Sun. Users can use controllers as their hands to teleport 
within the app and have a better visual of the Sun and planets, 
as illustrated in Figure 19. This can be useful to K-12 
education as it provides an immersive, interactive way to 
visualize and comprehend the solar system. This way of 
teaching using VR could be extended to other subjects. 
Figure 19. Solar System VR Application prototype 
 
VI. 
CONCLUSIONS AND FUTURE WORK 
The Drinking Water AR app served as a prototype to 
resolve the issue of access to safe drinking water while also 
encouraging public participation by enabling users to file 
water-related complaints. By assisting users in visualizing sun 
path at a given time, date, and place, the Sun Path AR 
application served as a prototype to help users learn about sun 
path and its role in making solar energy affordable. It provides 
solar azimuth and altitude information to the user, eliminating 
the need to manually calculate the values using a sun path 
diagram. The Solar System VR app acted as a model for 
enhancing virtual reality by creating an immersive and 
interactive solar system application. The app aided the user in 
visualizing a concept which is not readily apparent. 
The effectiveness of apps was also evaluated among K- 12 
students using a Likert scale-based pre- and post-survey 
metric. The study included twelve students from various 
schools across the United States. Based on the user reviews, it 
is fair to say that the applications were effective in terms of 
interaction, functionality, usability, and user experience. 
However, the implementations and evaluations had some 
limitations that could be addressed in the future. A virtual 
camp, conducted online due to Covid-19, was not quite 
effective to quantitatively evaluate the effectiveness of the 
work. In the future, the authors propose evaluating the 
application in an in-person camp with greater number of 
participants. Besides, following changes to the applications is 
proposed: 
• 
Currently, the water application only supports two of 
52
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

the buildings inside Auburn University, and so 
scaling it to add more buildings is proposed. 
• 
The mock data used for drinking water application 
could be replaced with actual data from the 
university. 
• 
Both the sun path application and the water 
application are developed for android phones only. 
So, equivalent versions of the applications 
compatible to iPhone could be developed. 
• 
Similarly, solar system VR application is only 
runnable in Oculus Quest Headset and could be 
built to support a greater number of headsets. 
 
ACKNOWLEDGMENT 
 
This work is made possible due to an NSF Grant # 1826181. 
 
 
REFERENCES 
 
[1] “Grand Challenges - 14 Grand Challenges for Engineering.” 
http://www.engineeringchallenges.org/challenges.aspx 
(retrieved: Jan. 24, 2021). 
[2] L. Pombo and M. M. Marques, “Improving students’ learning 
with a mobile augmented reality approach – the EduPARK 
game,” ITSE, vol. 16, no. 4, pp. 392–406, Nov. 2019, doi: 
10.1108/ITSE- 06-2019-0032. 
[3] S. Lehman, J. Graves, C. Mcaleer, T. Giovannetti, and C. C. 
Tan, “A Mobile Augmented Reality Game to Encourage 
Hydration in the Elderly,” in Human Interface and the 
Management of Information. Information in Applications and 
Services, vol. 10905, pp. 98–107, 2018. 
[4] S. Yamamoto and H. Mori, Eds. Cham: Springer International 
Publishing, 2018, pp. 98–107. 
[5] B. E. Shelton and N. R. Hedley, “Using augmented reality for 
teaching Earth-Sun relationships to undergraduate geography 
students,” 
in 
The 
First 
IEEE 
International 
Workshop 
Augmented Reality Toolkit, Sep. 2002, p. 8 pp.-, doi: 
10.1109/ART.2002.1106948. 
[6] “6 Exciting AR Apps for Student Learning,” Edutopia. 
https://www.edutopia.org/blog/ar-apps-for-student-learning- 
monica-burns (retrieved: Mar. 10, 2021). 
[7] Y. El Filali and K. Salah-ddine, “Augmented Reality Types And 
Popular Use Cases,” vol. 8, pp. 91–97, Apr. 2019. 
[8] K. Ahir, “What is the difference between Marker based and 
Markerless AR?,” Medium, Sep. 03, 2019. https://kumar- 
ahir.medium.com/what-is-the-difference-between-marker-
based- and-markerless-ar-192fb9fa09c5 (retrieved: Mar. 10, 
2021). 
[9] A. Ayoubi, “IKEA Launches Augmented Reality Application,” 
Architect, 
Sep. 
21, 
2017. 
https://www.architectmagazine.com/technology/ikea-launches- 
augmented-reality-application_o (retrieved: Mar. 10, 2021). 
[10] L. H., “Location-Based AR Apps: Best Examples and Guide on 
How To Build,” Cleveroad Inc. - Web and App development 
company, 
Jul. 
17, 
2018. 
https://www.cleveroad.com/blog/location- 
based-ar-apps-best-
examples-and-guide-on-how-to-build (retrieved: Mar. 10, 2021). 
[11] Locatify, “Location Based Augmented Reality Apps (AR & 
RTLS),” 
Locatify. 
https://locatify.com/blog/location-based- 
augmented-reality-apps-2017-rtls-ar/ (retrieved: Mar. 10, 2021). 
[12] “Oculus Headsets: The Original Quest is Back | Oculus.” 
https://www.oculus.com/quest/ (retrieved: Mar. 10, 2021). 
[13] D. Heaney, “How virtual reality positional tracking works,” 
VentureBeat, May 05, 2019. https://uploadvr.com/how-vr- 
tracking-works/ (retrieved: Mar. 10, 2021). 
[14] J. C. Mentes, “A typology of oral hydration problems exhibited 
by frail nursing home residents,” J Gerontol Nurs, vol. 32, no. 1, 
pp. 13–19; quiz 20–21, Jan. 2006, doi: 10.3928/0098- 9134-
20060101-09. 
[15] I. E. T. de Araujo, M. L. Kringelbach, E. T. Rolls, and F. 
McGlone, “Human cortical responses to water in the mouth, and 
the effects of thirst,” J Neurophysiol, vol. 90, no. 3, pp. 1865– 
1876, Sep. 2003, doi: 10.1152/jn.00297.2003. 
[16] J. Pacheco, J. O. Goh, M. A. Kraut, L. Ferrucci, and S. M. 
Resnick, “Greater cortical thinning in normal older adults predicts 
later cognitive impairment,” Neurobiol Aging, vol. 36, no. 2, pp. 
903–908, Feb. 2015, doi: 10.1016/j.neurobiolaging.2014.08.031. 
[17] G. A. Radvansky, A. K. Tamplin, and S. A. Krawietz, “Walking 
through doorways causes forgetting: Environmental integration,” 
Psychon Bull Rev, vol. 17, no. 6, pp. 900–904, Dec. 2010, doi: 
10.3758/PBR.17.6.900. 
[18] “ARCore,” Google AR & VR. https://arvr.google.com/arcore/ 
(retrieved: Mar. 10, 2021). 
[19] “Session 
| 
ARCore,” 
Google 
Developers. 
https://developers.google.com/ar/reference/java/com/google/ar/co
r e/Session (retrieved: Mar. 10, 2021). 
[20] “ArSceneView | Sceneform (1.15.0),” Google Developers. 
https://developers.google.com/sceneform/reference/com/google/a
r/ sceneform/ArSceneView (retrieved: Mar. 10, 2021). 
[21] “Frame 
| 
ARCore,” 
Google 
Developers. 
https://developers.google.com/ar/reference/java/com/google/ar/co
r e/Frame (retrieved: Mar. 10, 2021). 
[22] “Anchor 
| 
ARCore,” 
Google 
Developers. 
https://developers.google.com/ar/reference/java/com/google/ar/co
r e/Anchor (retrieved: Mar. 10, 2021). 
[23] Appoly, “ARCore Location - Android Studio - Appoly News & 
Opinions,” 
Appoly, 
Mar. 
28, 
2018. 
https://www.appoly.co.uk/2018/03/28/arcore-location/ (retrieved: 
Mar. 10, 2021). 
[24] Appoly, appoly/ARCore-Location. Appoly, 2021. 
[25] “Core Components and Native Components · React Native.” 
https://reactnative.dev/docs/intro-react-native-components 
(retrieved: Mar. 10, 2021). 
[26] M. Blanco-Muriel, D. C. Alarcón-Padilla, T. López-Moratalla, 
and M. Lara-Coira, “Computing the solar vector,” Solar Energy, 
vol. 70, no. 5, pp. 431–441, Jan. 2001, doi: 10.1016/S0038- 
092X(00)00156-0. 
[27] “Unity 
- 
Manual: 
GameObjects.” 
https://docs.unity3d.com/Manual/GameObjects.html 
(retrieved: 
Mar. 
10, 
2021)
 
 
 
 
53
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-878-5
ICWMC 2021 : The Seventeenth International Conference on Wireless and Mobile Communications

