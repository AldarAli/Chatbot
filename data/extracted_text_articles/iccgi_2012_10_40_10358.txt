Software Learnability Evaluation  
An Overview of Definitions and Evaluation Methodologies for GIS Applications 
 
Irfan Rafique, Jingnong Weng, Yunhong Wang, Maissom Qanber Abbasi, Philip Lew  
School of Computer Science and Engineering 
Beijing University of Aeronautics and Astronautics 
Beijing, China 
e-mail: irfan@cse.buaa.edu.cn, wengjn@buaa.edu.cn, yhwang@buaa.edu.cn, maissom@cse.buaa.edu.cn, 
philiplew@buaa.edu.cn 
 
Abstract— Learnability has been regarded as an important 
aspect of usability and considered a fundamental usability 
attribute. Yet, learnability is often overlooked as one of the 
most influential factors for the success of software applications 
especially Geographic Information Systems (GIS) applications. 
GIS Applications have seen a tremendous development during 
the last decades. Becoming more advanced, the amount, 
diversity and high turnover demand fast learning from users. 
Good learnability not only leads to a better productivity 
quickly but also plays a vital role in initial adoption or 
rejection of a technology. There are numerous approaches 
used to define, measure, and evaluate learnability. This paper 
presents some previously researched definitions along with 
methodologies for learnability evaluation with a special focus 
on desktop GIS applications. Our survey of definitions and 
evaluation methodologies leads us to a conclusion that there is 
a need of further research for a sound and widely accepted 
methodology for learnability evaluation of GIS applications. 
Keywords - learnability; GIS applications; learnability 
evaluation; learnability in use; usability. 
I. 
 INTRODUCTION 
 With the pervasiveness of the software in our everyday 
lives, the need for quality software systems becomes 
indispensable. Evaluating and improving quality needs a 
process of continuous assessment. This evaluation should be 
based on various functional as well as nonfunctional 
properties. Non-functional properties as depicted by ISO 
25010 [5] such as efficiency, learnability, security, reliability 
and attractiveness, amongst others, all contribute appreciably 
to the quality of software systems.  
In the last decade, there has been a rapid increase in the 
use of Geographic Information System (GIS) applications, 
especially web-based GIS applications (GISApps), in fields 
like education, transport, criminology, marketing, sociology, 
business and disaster recovery. Today almost all businesses 
and government agencies use GISApps as a tool for decision 
making and problem solving. 
Learnability, by some definitions, characterizes how easy 
is it for users to accomplish basic tasks the first time they 
encounter the software application. In an increasingly 
technological world, software, especially GISApps, are 
becoming more varied and complex. New features are being 
added quite rapidly to new GISApps, which users are 
expected to use immediately. The learnability of modern 
GISApps, especially web-based GISApps, has a distinctive 
importance. With conventional software systems, users must 
make an investment (often substantial) in time and effort to 
install and learn to use an application. However, with web-
based applications, users can very quickly switch from one 
Web application to another with minimal effort.  In 2006, 
Lazar et al. [10] discovered that users reported wasting on 
average, 42-43% of their time on the computer due to 
frustrating experiences. When looking at the specific causes 
of the frustrating experiences that occurred, the study found 
error messages and missing/hard to find/unusable features 
were among top five causes closely related with poor 
usability and more specifically poor learnability. Good 
learnability will lead to reasonable learning times, adequate 
productivity during the learning phase, and thus better 
satisfaction in new users. Improving learnability, thus, has a 
significant impact on the success of software applications 
and especially for GISApps, as GISApps involve a different 
interaction style, three dimensional interface designs and the 
need of grasping spatial concepts, making them more 
difficult to learn. But, improvement first requires identifying 
and understanding learnability issues. Also, learnability 
issues can only be exposed by clearly defining, and then 
evaluating it in systematic and consistent way. 
Although researchers recognize the importance of 
learnability, the consensus among researchers regarding 
defining and evaluating learnability seems lacking, leading to 
the conclusion that software systems still pose learnability 
problems. The main objectives of this research are to: 1. 
Understand learnability in detail with respect to GISApps 
and the special characteristics of GISApps that need 
consideration. 2. Analyze the related research in learnability 
evaluation with reference to GISApps. Although GISApps 
are being widely utilized in different devices like desktops, 
mobile devices and cellular phones, etc., this research is 
focused on learnability related to desktop applications only.  
Following 
this 
introduction, 
Section 
II provides 
background on state of the art research in learnability. 
Section III highlights the importance of learnability for 
GISApps. Section IV provides evaluation schema for 
learnability with respect to GISApps. The subsequent section 
emphasizes quality in use (QinU) aspect of learnability and 
Section VI concludes the paper and outlines future work. 
212
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

TABLE I.  
SUMMARY OF LEARNABILITY DEFINITIONS 
No. 
Source 
Definition 
1.  
Jakob Nielsen 
(1993) [1] 
Novice user's experience on the initial part of 
the learning curve. 
2.  
Dix (1998) [3] 
Ease at which new users can begin effective 
interaction and achieve maximal performance 
3.  
Santos and 
Badre (1995) 
[6] 
Measure of the effort required for a typical 
user to be able to perform a set of tasks using 
an interactive system with a predefined level 
of proficiency. 
4.  
Hart and 
Steveland 
(1988) [8] 
The speed and ease with which users feel that 
they have been able to use the product or as 
the ability to learn how to use new features 
when necessary.  
5.  
Bevan and 
Macleod’s 
(1994) [11] 
A measure of comparison the quality of use 
for users over time. 
6.  
Butler (1985) 
[13] 
Initial user performance based on self 
instruction” and “[allowing] experienced 
users to select an alternate model that 
involved fewer screens or keystrokes.  
7.  
Kirakowski and 
Claridge (1998) 
[4] 
Within the web context is the degree to which 
users feel able to manage the product’s basic 
functions during its first use. 
8.  
ISO 9126-1 
(2001) [16] 
The capability of the software product to 
enable the user to learn its application 
9.  
ISO 25010 
(2011) [5] 
Degree to which a product or system can be 
used by specified users to achieve specified 
goals of learning to use the product or system 
with effectiveness, efficiency, freedom from 
risk and satisfaction in a specified context of 
use 
II. 
CHARACTERIZING LEARNABILITY 
This section of the paper provides background on 
learnability while examining the existing research and 
delineating areas for improvement regarding clarity in its 
definition. 
A. Definiing Learnability 
In order to evaluate learnability, first we have to define 
and understand it clearly. There have been a number of 
different definitions proposed. Table I summarizes some of  
these definitions. The tabulated definitions are among the 
many different definitions used by different researches over 
the last two decades. For the purpose of brevity we have only 
included representative definitions involving some unique 
types of measures in defining learnability. 
Nielsen [1], Holzinger [19], Shneiderman 1995 [20], and 
Chapanis [21] define learnability in terms to time that is 
how quickly users learn to operate the software. Dix et al. 
[3] and Stickel et al. [22] define learnability in terms of ease 
with which new users can begin effective interaction with 
the system. Santos and Badre [6] define learnability in terms 
of measure of effort required to achieve a defined level of 
proficiency. Hart and Steveland [8] and Linja Aho [23] 
define learnability in terms of time and ease with which user 
starts efficient interaction with the product. Rieman [24], 
Butler [13] and MUMMS Questionnaire [25] define 
learnability in terms of user performance without formal 
training. Ziefle [26] and ISO 9126-1 [16] define it in terms 
of software product properties that enable user to learn its 
application. Hart and Steveland [8], Kirakowski and 
Claridge [4] and MUMMS Questionnaire [25] highlight 
subjective aspects of learnability by judging it from user’s 
feelings about learning process. Most of the definitions refer 
to the performance of user relevant to their first interaction 
with the software (initial learnability), but some researchers 
have also taken note of extended learnability, that concerns 
improvement in performance over time ([3][4][11][13]). 
Extended learnability or advanced learnability has been 
characterized by learning of new or advanced features, 
ability to adoption alternate model that involved fewer 
screens or keystrokes, ability to master the software and 
ability to achieve maximal performance. This description 
clearly shows the diversity in the use of measures among 
researchers regarding defining learnability.  
Grossman et al. [27] carried out a survey of 88 research 
papers related to learning in HCI (Human Computer 
Interaction), 45 discussed learnability without a definition, 
and the remainder had conflicting definitions. They classify 
learnability definitions in eight different categories. Instead 
of deciding upon a common definition, they developed 
taxonomy of learnability definitions after highlighting the 
short comings in current definitions. Key features of the 
developed taxonomy include the existence of an optimal 
performance level, the dimension of experience, and the 
timeline of when the learning takes place.  
In general terms “learnability is a characteristic where 
performance improves with experience. As tasks are 
repeated, elements of the task are better remembered, 
prompts are more clearly distinguished, skills are sharpened, 
transitions between successive tasks are smoothed, eye-hand 
coordination is more tightly coupled, and relationships 
between task elements are discovered. The aggregation of 
these effects results in faster performance times, fewer 
errors, less effort, and more satisfied users” [28]. 
B.  Software Quality perspectives of Learnability 
ISO quality models can be used to support specification 
and evaluation of software from different perspectives by 
those 
associated 
with 
acquisition, 
requirements, 
development, use, evaluation, support, maintenance, quality 
assurance and audit of software. The ISO 25010 [5] defines  
1) A quality in use (QinU) model composed of five 
main characteristics (Effectiveness, Efficiency, Satisfaction, 
Freedom from Risk and Context Coverage) that relate to the 
outcome of interaction when a product is used in a particular 
context of use.  
2) A product quality model composed of eight main 
characteristics (including usability) that relate to static 
properties of software and dynamic properties of the 
computer system.  
Many researchers  ([1][2][3]) and standards (IEEE 
standard 610.12 [29], ISO 9126-1 [16] and ISO 25010 [5]) 
have mentioned learnability as an important attribute of 
usability. In ISO 9126 the product centered view of usability 
and learnability was presented but in recent standards both 
products centered and QinU centered views have been 
213
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

presented. According to guidelines of ISO [5], learnability 
can be specified or measured in two different ways. The first 
one is the  “extent to which a product or system can be used 
by specified users to achieve specified goals of learning to 
use the product or system with effectiveness, efficiency, 
freedom from risk and satisfaction in a specified context of 
use”. This corresponds to QinU aspect of learnability. We 
further discuss this aspect in more detail in Section V. The 
second method of specification and measurement of 
learnability is by product properties corresponding to 
suitability for learning as defined in ISO 9241-110 [30]: 
“software product quality is the cause and QinU is the 
effect”. Thus learnability can be seen as the collective effect 
of key product attributes that lead to efficient and effective 
learning of a software product with high end user 
satisfaction levels in a specified context of use. 
III. 
GIS APPLICATIONS AND LEARNABILITY 
This section depicts specific characteristics of GISApps, 
which put greater emphasis on learnability of GISApps. 
Although GISApps work in a graphic user interface, they 
are quite different from general computer applications. The 
special functions required to manipulate spatial aspects make 
the interface complicated and difficult to learn. To make 
matters worse, GISApps employ unique interfaces, and 
therefore users must learn a different interface style with 
each 
application. 
GISApps 
generally 
require 
three 
dimensional (3D) interaction styles. Although we live and 
act in a 3D world, the physical world contains many more 
cues for understanding and constraints and affordances for 
action that cannot currently be represented accurately in a 
computer simulation. It is quite difficult for new users to 
transform traditional WIMP (Windows, Icons, Menus, 
Pointers) interaction styles to three dimensional interaction, 
leading to learning difficulties. 
 A GISApp combines query functions and analysis with 
visualization and geographic features to examine spatial 
problems. Using, managing, and analyzing spatial data, and 
enabling a user to analyze spatial questions is distinctive to 
GISApps, but this leads to usability issues especially in 
understanding and learning the application. For GISApps, 
users have a relatively long learning curve due to the need to 
grasp geographical concepts and different data types. Also, 
the level of user knowledge of geographical concepts, and 
task dependency on geographic concepts are special 
considerations [31]. A report on the Leonardo Pilot Project, 
E-GIS (about learning of GIS applications) notes difficulty in 
learning of GISApps as one of the main causes of student 
drop out during learning course [32]. 
In 
addition 
to 
different 
interaction 
style, 
GIS 
visualization poses several challenges. GIS employ a virtual 
environment (VE) to display and interact with high 
dimensional geospatial structures and phenomena. Way-
finding in such an environment has certain challenges. In the 
real environment, kinesthetic feedback is available to the 
user; movement is restricted by physical boundaries. In VE 
such feedback is not normally given. Navigation in VE is 
generally controlled indirectly with interaction tools such as 
keyboard, mouse, joysticks, etc. Since desktop VEs are 
seldom immersive, navigation in such a VE is even less 
similar to real world navigation because navigation in 
addition to being indirect is typically controlled from the 
"outside" of the environment (like controlling a toy car by 
remote control) [33]. It is therefore common for a novice 
user losing orientation (awareness of the space around, 
including the location of objects and places) during way-
finding process.  
GIS displays wide regions on a small screen and allows 
navigation in large spaces. Unlike the bird’s eye, overall 
view map of an area, the user often deals with only a part of 
a large scale space (not visualized entirely from one 
viewpoint). It is common for the novice users to get ”lost” 
when zoomed into a small area without reference text (e.g., 
place names). 
In current era of GISApps, learnability has new 
challenges as software is mostly released online and online 
help and support are the main customer support mechanisms. 
Therefore, the existing research in software learnability 
needs appropriate considerations specifically for GISApps. 
IV. 
LEARNABILITY EVALUATION 
The previous section discussed some of the particular 
characteristics of GISApps and the importance of requiring a 
new model for learnability evaluation.  This section 
examines some of the existing methods for evaluating 
learnability for GISApps. 
Usability engineering research literature mentions several 
usability evaluation methodologies; however, their suitability 
for evaluating learnability is not well elaborated. Similarly 
the suitability of methodologies used for non GISApps for 
GISApps is also not very obvious. We discuss only those 
methodologies in this section which have been used for 
evaluation of GISApps. 
One of the most common forms of usability testing is the 
“Think-Aloud Protocol”. In this technique respondents are 
asked to give a verbal account of their thinking as they 
answer (concurrent) or immediately after answering 
(retrospective) a draft survey question [25]. Komarkova et al. 
[34] employed Think Aloud Protocol to find usability 
problems in 14 Web based GISApps run by the Czech 
Regional Authorities. They identified learnability related 
issues like complexity of search tools and lack of interface 
understandability. Nivala et al. [35] used this methodology to 
identify the potential usability problems of web mapping 
sites, 
including 
learnability 
issues 
like 
interface 
crowdedness, lack of conformity to user expectations and 
absence of map legends, etc. Think Aloud technique 
provides rich qualitative data and allows first hand insight 
into the thought processes associated with different tasks. 
Think Aloud methodology can be useful for identifying 
learnability issues, but takes place in the unnatural 
environment of a usability lab [3]. Moreover, people can 
only report what they are aware of and can report about the 
components of high level mental processes, like the sequence 
of steps that leads to the solution of a problem. Furthermore, 
it is difficult to identify changes in behavior due to learning 
by this method. 
214
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

TABLE II.  
STATISTICS OF LEARNABILITY RELATED QUESTIONS IN 
FAMOUS QUESTIONNAIRES 
Questionnaire Name 
Number of Questions 
Product 
Perspective 
QinU 
Perspective 
Purdue Usability Testing Questionnaire 
(PUTQ) [2] 
34 
- 
Software Usability Measurement 
Inventory (SUMI) [4] 
4 
6 
Questionnaire for User Interaction 
Satisfaction (QUIS) [7] 
7 
10 
The Post-Study System Usability 
Questionnaire (PSSUQ) [9] 
2 
2 
Practical Heuristics for Usability 
Evaluation (PHUE) [12] 
5 
- 
SUS (System Usability Scale) [14] 
- 
4 
IUI (Isometrics Usability Inventory) [15] 
11 
6 
WAMMI (Website Analysis 
and MeasureMent Inventory) [17] 
- 
2 
Usefulness, Satisfaction, and Ease of use. 
(USE) [18] 
- 
4 
Focus Group [1] is another methodology in which a 
number of users are brought together to discuss new 
concepts and identify issues over a certain period of time. 
Each group is run by a moderator who is responsible for 
maintaining the focus of the group on whatever issues are of 
interest. Fuhrmann and MacEachren [33] employed Focus 
Group for the evaluation of a geovirtual environment and 
discovered 
many 
learnability 
issues 
like 
lack 
of 
predictability, difficult to find features, lack of informative 
feedback from software etc. Harrower et al. [36] employed 
Focus Group to assess an animated and interactive 
geovisualization environment Earth System Visualizer and 
implications of this environment for learning about 
spatiotemporal processes. They deduced that novel interfaces 
may not result in improved performance unless sufficient 
training is provided on how to use them. Focus Groups 
usually provide immediate ideas for the improvement of 
particular products or concepts. This method can be useful 
for identifying learnability issues and proposal of design 
guidelines, but it is rather subjective and expensive 
methodology. Moreover Focus Groups are not efficient in 
covering maximum depth on a particular issue. Additionally 
moderator bias can greatly impact the outcome of a Focus 
Group discussion. 
For the evaluation of MapTime, a software package for 
exploring spatiotemporal data associated with point 
locations, Slocum et al. [37] employed a methodology 
consisting of a combination of individual interviews and 
Focus Groups conducted for three distinct groups of 
participants: novices, geography students, and domain 
experts, and discovered that individual interviews are 
particularly useful in obtaining users' reactions to software 
(as opposed to having them learn the software on their own) 
because the interviewer can steer the interview based on the 
user's responses. 
Observation is a quite frequently employed method for 
learnability evaluation. It involves visiting one or more users 
in their workplaces. Notes must be taken as unobtrusively as 
possible to avoid interfering with their work [19]. Video 
recording has also been a very frequently used method for 
observational data collection. Jones et al. [38] used video 
analysis for an exploratory task-orientated project workshop 
with the four project team members, for usability and 
learnability evaluation of a geographic profiling tool. They 
measured learnability by video analysis of users’ browsing 
interaction. Hossain and Masud  [39] used video evaluation 
to evaluate  “ArcView” GIS software with four participants 
during two hours of interaction. They found 12 learnability 
problems 
using 
this 
method 
including 
interface 
understandability, presence of unfamiliar terms, help and 
error messages inadequacy etc. Video recording is quite 
comprehensive way of data collection, but analysis required 
is quite time taking.  
Another means of electronic observation is Data 
Logging, which involves statistics about the detailed use of a 
system. Meng and  Malczewski [40] used a data logging 
approach to evaluate usability and learnability of a public 
participatory GISApp named ArgooMap. The users’ every 
move on the website was recorded with a logging software 
which made it possible to obtain detailed and useful 
information about the actual usage of the website holding 
ArgooMap. Although this methodology captures data 
automatically, it has not been widely applied for learnability 
evaluation in GISApps. 
Lew et al. [41] used C-INCAMI (Contextual-
Information Need, Concept model, Attribute, Metric and 
Indicator) framework to evaluate learnability as a product 
characteristic of a GISApp named Chinastar. C-INCAMI is 
a framework which relies on an ontological conceptual base; 
on a well-established measurement and evaluation process. 
Using this methodology some learnability issues like lack of 
predictability were identified. This methodology is model 
based and provides quantitative results, but there seems to 
be involvement of subjective judgments while computing 
the metrics for learnability attributes. 
Some researchers employed a combination of several 
methodologies for investigating different aspects of usability 
of GISApps. Nivala et al. [35] for example, conducted a 
series of expert evaluations and user tests. During the expert 
evaluations, eight usability engineers and eight cartographers 
examined the web based GISApps including Google Maps, 
MSN Maps and Directions, MapQuest, and Multimap, by 
paying attention to their features and functionality. 
Additionally, eight user tests were carried out by ordinary 
users in a usability laboratory. User tests used a combination 
of Think Aloud and video recording method. Kristoffersen 
[42] used a “traingularization” of observation, interviews and 
document study to evaluate usability of ArcView used for 
viticulture purposes and concluded that the user consider 
learnability and functionality aspects to be top usability 
issues. 
Many aspects of usability can best be studied by querying 
the users. This is especially true for issues on the subjective 
satisfaction of the users and their possible anxieties, which 
are hard to measure objectively. Use of a subjective 
questionnaire has been a very effective and popular method 
for usability evaluation. Being a sub characteristic of 
215
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

usability, learnability has also been evaluated by using 
subjective questionnaires. Table II lists some famous 
questionnaires along with number of questions relevant to 
product oriented and QinU oriented aspects of learnability. 
It must be kept in mind that the software learnability 
evaluation should provide quantitative or qualitative results 
that are comprehensible, acceptable and repeatable, in order 
to prove a key driver for improvement in learnability and 
consequently 
in 
software 
quality. 
All 
referenced 
methodologies require users to either identify learnability 
problems or evaluate subjective or objective learnability by 
measuring time on task, task correctness, error counts or 
user’s subjective responses. Most approaches are not model 
based and seem to be not easily reproducible. ISO 25010 and 
ISO 9126 both treat learnability as a product characteristic 
that is a characteristic of internal or external quality. 
However, there has been a limited effort regarding 
evaluating learnability from product quality perspective [31].  
Think Aloud Protocol, Focus Group, and interviews are 
all quite direct methodologies for learnability issues 
identification, 
but 
have 
some 
limitations. 
These 
methodologies are prone to high level of subjectivity as well 
as the interplay of a legion of factors, including the 
characteristics of the users, the environment, the sample size 
of the user group, etc., leading to problems in isolating 
individual factors under examination. Similarly data logging 
method has not been found to be widely applied for 
GISApps. C-INCAMI, seems to be a model based scheme 
but has some subjective judgments involved for producing 
quantitative results. Moreover, its applicability in GIS 
domain has been very limited.  
V. 
QULAITY IN USE ASPECT OF LEARNABILITY 
As mentioned in Section II-B, learnability has been 
considered as an attribute of usability. There has been an 
inconsistency even within ISO software quality model 
regarding concept of usability. In earlier drafts of ISO 9126, 
usability was defined primarily in terms of product attributes 
as “A set of attributes of software which bear on the effort 
needed for use and on the individual assessment of such use 
by a stated or implied set of users". In ISO/IEC CD 25010.3 
[43], the product centered view of usability as presented in 
ISO 9126 was deemed narrow at that time and renamed as 
operability but in its final release ISO/IEC 25010:2011 it was 
retained as usability. In ISO/IEC CD 25010.3, usability 
appeared as a characteristic of quality in use. The recent ISO 
25010 standard, regarding usability evaluation states, 
“Usability can either be specified or measured as a product 
quality characteristic in terms of its sub-characteristics, or 
specified or measured directly by measures that are a subset 
of quality in use”. We argue that users achieve their intended 
goals with effectiveness, efficiency, satisfaction and freedom 
from risk (the sub characteristics of QinU) not only because 
of usability, but also due to other product quality 
characteristics like utility (e.g., right functionality or 
functional suitability), reliability and performance efficiency 
etc. The usability attributes of a product are thus only one 
contribution to the quality in use of an overall system. It is, 
therefore worthwhile to model “in use” part of usability on 
QinU model side, rather than considering it as a total “in 
use” aspect of usability. Being a sub characteristic of 
usability, learnability can further be modeled on QinU side 
also. Based on our thorough analysis of literature and 
questionnaires we have noticed several sub characteristics of 
learnability that can be incorporated in QinU model. Lew et 
al. [41] has already mentioned learnability in use concept 
defining it as “the degree to which  specified users can learn 
efficiently and effectively while achieving specified goals in 
a specified context of use”. Most of the learnability 
evaluations mentioned in Section IV measure QinU aspect of 
learnability without defining it specifically as such.  In true 
model based evaluation methodologies both aspects of 
learnability vis-a-vis product centered and QinU oriented 
should be considered. 
VI. 
CONCLUSION AND FUTURE WORK 
Learnability has an increased importance for GISApps 
because of the need of grasping spatial concepts and 
different interaction styles. In learnability research, there has 
been inconsistency in defining learnability and treating it as 
product characteristic or QinU characteristic. There have 
been numerous evaluation methods developed and used by 
researchers during past years, but there seems to be a lack of 
consistency and cross verification between evaluated results. 
Although some researchers have developed methods to 
evaluate learnability in more organized, conceptual and 
model based ways, their applicability in GIS domain is quite 
limited. There is a need to further strengthen the area of 
learnability evaluation in GISApps domain. More research, 
thus, needs to be done for a sound and widely accepted 
learnability evaluation methodology for GISApps.  
In the future, we will develop a comprehensive 
evaluation methodology for modeling and evaluation of 
learnability of GISApps. As a first step we are developing a 
comprehensive concept model that can be employed for 
evaluating evaluate GISApps.  
ACKNOWLEDGEMENT 
Authors gratefully acknowledge support from the lab of 
Digital earth and GIS, School of Computer science and 
engineering, 
Beijing 
University 
of 
Aeronautics 
and 
Astronautics (BUAA), P.R. China. 
REFERENCES 
[1] J. Nielson, Usability Engineering, San Francisco: Morgan 
Kaufmann, 1993, pp. 16-39. 
[2] H.X. Lin, Y.-Y. Choong and G. Salvendy, "A proposed index 
of usability: a method for comparing the relative usability of 
different software systems," Beh. & Infor. Tech. vol. 16, pp. 
267-278, 1997. 
[3] A. Dix, J. Finlay, G. Abowd and R. Beale, Human-computer 
interaction, 2nd ed., Hertfordshide, UK: Prentice Hall 
International, 1998. 
[4] J. Kirakowski, N. Claridge and R. Whitehand, "Human 
Centered Measures of Success in Web Site Design," 4th Conf. 
on Human Factors and the Web, NJ, USA 1998. 
[5] "ISO/IEC 25010:2011: Systems and software engineering – 
Systems and software product Quality Requirements and 
Evaluation– System and software quality models," 2011. 
216
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

[6] P.J. 
Santos 
and 
A.N. 
Badre, 
"Discount 
learnability 
evaluation," GVU Technical Report, Georgia Institute of 
Technology, 1995, pp. 30-38. 
[7] J.P. Chin, V.A. Diehl and K.L. Norman, "Development of an 
instrument measuring user satisfaction of the human-
computer interface," Proc SIGCHI conference on Human 
factors in computing systems, ACM, 1988, pp. 213-218, 
doi:10.1145/57167.57203. 
[8] S.G. Hart and L.E. Staveland, "Development of NASA-TLX 
(Task Load Index): Results of Empirical and Theoretical 
Research," in Advances in Psychology, vol 52, A.H. Peter, M. 
Najmedin (Eds.), North-Holland 1988, pp. 139-183. 
[9] J.R. 
Lewis, 
"IBM 
computer 
usability 
satisfaction 
questionnaires: psychometric evaluation and instructions for 
use," Int. J. Hum.-Comput. Interact. vol. 7, pp. 57-78, 1995. 
[10] J. Lazar, A. Jones and B. Shneiderman, "Workplace User 
Frustration with Computers: An Exploratory Investigation of 
the Causes and Severity.," Beh. and Infor. Tech. vol. 25, pp. 
239-251, 2006. 
[11] N. Bevan and M. Macleod, "Usability measurement in 
context.," Beh. and Infor. Tech. vol. 13, pp. 132–145, 1994. 
[12] G. Perlman, "Practical usability evaluation," Proc CHI '97 
extended abstracts on Human factors in computing systems: 
looking 
to 
the 
future, 
ACM, 
1997, 
pp. 
168-169, 
doi:10.1145/1120212.1120326. 
[13] K.A. Butler, "Connecting Theory and Practice: a case study of 
achieving usability goals.," Proc CHI 85 Proceedings of the 
SIGCHI conference on Human factors in computing systems 
1985, pp. 85-88, doi:10.1145/317456.317472. 
[14] J. Brooke, "SUS: A quick and dirty usability scale," in 
Usability 
evaluation 
in 
industry, 
P.W. 
Jordan, 
B. 
Weerdmeester, A. Thomas, I.L. McLelland (Eds.), Taylor and 
Francis, 1996. 
[15] G. Gediga, K.-C. Hamborg and I. Düntsch, "The IsoMetrics 
usability inventory: An operationalization of ISO 9241-10 
supporting summative and formative evaluation of software 
systems," Beh. and Infor. Tech. vol. 18, pp. 151-164, 1999. 
[16] "ISO 9126-1:2001 Information technology — Software 
product quality — Part 1: Quality model," 2001. 
[17] "WAMMI questionnaire," Human Factors Research Group in 
Cork, Ireland 2011. 
[18] A.M. 
Lund, 
"Measuring 
Usability 
with 
the 
USE 
Questionnaire," Usability and User Experience vol. 8, 2001. 
[19] A. Holzinger, "Usability engineering methods for software 
developers.," Comm. of The ACM vol. 48, pp. 71-74, 2005. 
[20] L. Slaughter, K.L. Norman and B. Shneiderman, "Assessing 
Users' Subjective Satisfaction with the Information System 
for Youth Services (ISYS)," Proc Third Annual Mid-Atlantic 
Human Factors Conference, March 26-28, 1995, pp. 164-170. 
[21] A. Chapanis, "Evaluating usability," in Human factors for 
informatics usability, Camb. Univ. Press 1991, pp. 359-395. 
[22] C. Stickel, J. Fink and A. Holzinger, "Enhancing Universal 
Access – EEG Based Learnability Assessment," in Universal 
Access in Human-Computer Interaction. Applications and 
Services, vol 4556, C. Stephanidis (Ed.), Springer Berlin / 
Heidelberg 2007, pp. 813-822. 
[23] M. Linja-aho, "Creating a framework for improving the 
learnability of a complex system," Human Technology vol. 2, 
pp. 202-224, 2006. 
[24] J. Rieman, "A field study of exploratory learning strategies," 
ACM Transactions on Computer-Human Interaction, vol. 3, 
pp. 189-218, 1996. 
[25] MUMMS, "Questionnaire homepage. Berlin States Museum 
Trial Evaluation Summary," University College Cork , 
Ireland, 2003. 
[26] M. Ziefle and S. Bay, "Mental Models of a Cellular Phone 
Menu. Comparing Older and Younger Novice Users," in 
Mobile Human-Computer Interaction – MobileHCI 2004, vol 
3160, S. Brewster, M. Dunlop (Eds.): Springer Berlin / 
Heidelberg 2004, pp. 571-572. 
[27] T. Grossman, G. Fitzmaurice and R. Attar, "A Survey of 
Software 
Learnability: 
Metrics, 
Methodologies 
and 
Guidelines," Proc 27th international conference on Human 
factors in computing systems, 7th April, 2009, pp. 649-658, 
doi:10.1145/1518701.1518803. 
[28] M.R. Lehto and J.R. Buck, Introduction To human factors and 
ergonomics for engineers, NY: Taylor & Francis, 2008. 
[29] IEEE, "Std 610.12-1990 , IEEE Standard Glossary of 
Software Engineering Terminology ", 1990. 
[30] "ISO 
9241-110:2006: 
Ergonomics 
of 
human-system 
interaction — Part 110: Dialogue principles," 2006. 
[31] P. Lew, L. Zhang and L. Olsina, "Usability and User 
Experience as Key Drivers for Evaluating GIS Application 
Quality," 18th Intl. Conf. on Geoinformatics, Beijing, China, 
2010, doi:10.1109/GEOINFORMATICS.2010.5567803. 
[32] H. Sponberg, E. Ossiannilsson, P. Pilesjö, U. Mårtensson, E. 
Onstein and F. Johansen, "Online GIS-Learning," European 
Assoc. of Distance Teaching Univ., Lisbon, Portugal 2007. 
[33] S. Fuhrmann and A.M. MacEachren, "Navigation in Desktop 
Geovirtual Environments: Usbaility Assessment," Proc 20th  
ICA/ACI International Cartographic Conference, August 06-
10, 2001, pp. 2444-2453. 
[34] J. Komarkova, M. Jedlicka and M. Hub, "Usability user 
testing of selected web-based GIS applications," W. Trans. on 
Comp. vol. 9, pp. 21-30, 2010. 
[35] A.-M. Nivala, S. Brewster and L.T. Sarjakoski, "Usability 
Evaluation of Web Mapping Sites," The Cartographic Journal 
vol. 45, pp. 129–138, 2008. 
[36] M. Harrower, A. MacEachren and A.L. Griffin, "Developing 
a Geographic Visualization Tool to Support Earth Science 
Learning," Cartography and Geographic Information Science, 
vol. 27, pp. 279-293, 2000. 
[37] T. Slocum, R. Sluter, F. Kessler and S. Yoder, "A Qualitative 
Evaluation of MapTime, A Program For Exploring 
Spatiotemporal Point Data," Cartographica: The Intl. J. for 
Geog. Infor. and Geovisualization vol. 39, pp. 43-68, 2004. 
[38] C. Jones, M. Haklay, S. Griffiths and L. Vaughan, "A less-is-
more approach to geovisualization – enhancing knowledge 
construction across multidisciplinary teams," Intl. J. of 
Geographical Infor. Science vol. 23, pp. 1077-1093, 2009. 
[39] M.D. Hossain and M.M. Masud, "Evaluating Software 
Usability of Geographic Information System," Int. J. of 
Software Engineering vol. 2, pp. 64-86, 2009. 
[40] Y. Meng and J. Malczewski, "Usability evaluation for a web-
based public participatory GIS: A case study in Canmore, 
Alberta," J. of Geography, 17th December, 2009. 
[41] P. Lew, L. Olsina, P. Becker and L. Zhang, "An integrated 
strategy to systematically understand and manage quality in 
use for web applications," Requirements Engineering vol., pp. 
1-32, 2011. 
[42] I. Kristoffersen, "Usability Evaluation of GIS used for 
Viticulture Purposes," Department of Informatics, University 
of Oslo, Oslo, 2008, pp. 1-144. 
[43] "ISO/IEC CD 25010.3: Systems and software engineering – 
Software 
product 
Quality 
Requirements 
and 
Evaluation(SQuaRE) – Quality models for software product 
quality and system quality in use," 2009. 
 
 
217
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

