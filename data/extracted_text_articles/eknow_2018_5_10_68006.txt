A Governance Framework for (Semi) Automated Decision-Making
Koen Smit
Digital Smart Services
HU University of Applied Sciences Utrecht
Utrecht, the Netherlands
Koen.smit@hu.nl
Martijn Zoet
Optimizing Knowledge-Intensive Business Processes
Zuyd University of Applied Sciences
Sittard, the Netherlands
Martijn.zoet@zuyd.nl
Abstract—Proper decision-making is one of the most important
capabilities of an organization. Therefore, it is important to
have a clear understanding and overview of the decisions an
organization makes. A means to design and specify decisions is
the Decision Model and Notation (DMN) standard published
by the Object Management Group in 2015. In this standard, it
is possible to specify how a decision should be taken but lacks
elements to specify the actors that fulfill different roles in the
decision-making process. Additionally, DMN does not take into
account the autonomy of machines. In this paper, a framework
is proposed and demonstrated that takes into account different
roles in the decision-making process, and also includes the
extent of the autonomy when machines are involved in the
decision-making processes. Based on the model presented, we
identify several directions for future research, including more
rigorous validation of the proposed model to ensure the model
is applicable in most, if not all, contexts.
Keywords - Decision-Making; DMN; RAPID; Autonomy.
I.
INTRODUCTION
In September 2015, the Object Management Group
(OMG) released a new standard for modelling decisions and
underlying business logic, DMN [1]. In line with the DMN
standard, a decision is defined as: “A conclusion that a
business arrives at through business logic and which the
business is interested in managing.” [2]. Furthermore,
business logic is defined as: “a collection of business rules,
business decision tables, or executable analytic models to
make individual decisions.” [1].
Proper decision-making is one of the most important
capabilities of an organization [3]. In the previous decades,
decision making was a capability only executed by human
actors. However, given the technical developments in
computer hard- and software, the possibilities to automate
decision-making have increased. Examples of techniques
applied during automated decision making are business rules
systems, expert systems, and neural networks [4]. To achieve
proper decision-making, organizations must design and
specify their decisions and decision-making processes. One
aspect that influences the specification of the decision and
the decision-making process is the level of automated
decision-making. Machines can execute decisions only when
the decision and the underlying business logic is specified
formally [5]. Furthermore, when organizations choose to
specify their decisions and decision-making processes, the
level of detail is of importance. This is based, amongst
others, on the type of decision and the actor that executes the
decision. For example, a strategic decision needs to be
specified on a different level of detail compared to an
operational decision and therefore needs a different type of
specification and a different decision-making process.
While DMN is mainly applied to express operational
decisions that will be automated, it can also be used for
manual
decision-making.
However,
the
current
DMN
standard lacks a formal concept to specify a governance
structure for each decision. In this context, a governance
structure is defined to express the roles and responsibilities
relevant to a decision and the underlying decision-making
process. This becomes important when a decision is
executed by instantiating a decision-making process that
features both human and machine actors. Research on
specifying a proper governance structure for decision-
making already concluded that assigning clear roles and
responsibilities are the most important steps in the design
and
specification
of
decisions
and
result
in
better
coordination and quicker response times [3][6].
Another aspect of designing and specifying decisions
and decision-making is the use of machine actors instead of
human actors. Assigning machine actors to parts of the
decision-making process requires organizations to evaluate
the autonomy of the machine. Machine autonomy refers to
the system’s capability to carry out its own tasks and making
decisions [7]. As Parasuraman, Sheridan and Wickens [8]
stated in their work, the question now is: “which system
functions should be automated, and to what extent?” For
example, when possible, do we want to let a machine decide
whether a person should or shouldn’t be admitted to enter a
given country, based on the premise that the machine is more
accurate compared to a human actor in determining the
eligibility of a person.
One reason why it is essential to include proper
governance
structure
when
designing
and
specifying
decisions and decision-making processes is the increasingly
stricter laws and regulations on digital privacy and data
regulation,
i.e.,
the
Health
Insurance
Portability
and
Accountability Act (title II) and the General Data Protection
Regulation [9]. Such laws and regulations can prohibit the
use of machine actors in decision-making, and when it
allows organizations to include them, specifies exactly what
is allowed and what is not allowed. For example, how
exactly personal data is processed, and which roles have
access to it. Thus, to design compliant decisions and
decision-making, an organization must be able to define
83
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-620-0
eKNOW 2018 : The Tenth International Conference on Information, Process, and Knowledge Management

exactly what actors are responsible for, and, when a machine
is made responsible, how autonomously it will operate.
In literature, studies are conducted that resulted in a
model to define, for example, the autonomy of a machine in
decision-making
[8][10][11].
Moreover,
studies
are
conducted that specify the roles that are used to design
decision-making processes between stakeholders [3][12].
However, to the knowledge of the authors, no studies exist
that combine both.
Therefore, in this paper, a model is proposed that
includes the roles and responsibilities aspect, taking into
account human-machine interaction, while also including the
autonomy level of a machine as part of the human-machine
interaction in decision-making. To be able to do so, the
following research question is addressed: “How can a
governance structure be designed to explicate the decision-
making process?”
The remainder of this paper is organized as follows. First,
a literature overview is presented in section two in which the
existing models that define the possible interaction between a
human and a machine are explored and compared. This is
followed by the construction of the model in section three.
Next, in section four, the case to demonstrate and validate
the model is described, which is followed by the actual
demonstration of the model. Lastly, the conclusions are
drawn and we propose directions for future research in
section five.
II.
BACKGROUND AND RELATED WORK
The DMN standard consists of two levels: the Decision
Requirements Level (DRD) and the Decision Logic Level
(DLL). The DRD level consists of four concepts that are
used to capture essential information with regards to
decisions: 1) the decision, 2) business knowledge, which
represents the collection of business logic required to
execute the decision, 3) input data, and 4) a knowledge
source, which enforces how the decision should be taken by
influencing the underlying business logic, see Figure 1. The
contents of the DLL level are represented by the business
knowledge container in the DRD level. In the current
version of DMN, two standard languages are suggested for
expressing business logic, Friendly Enough Expression
Language (FEEL) and Simple Expression Language (S-
FEEL) [1]. However, it also allows the use of other, more
adopted languages like JavaScript, Groovy, and Python [1].
Still, the language selected to represent the decision logic
does not influence the decision requirements level. Analysis
of the DMN standard reveals that no formal elements exist
to specify roles in the decision-making process. To add to
the DMN standard, roles and responsibilities should be
taken into account.
Figure 1. DRD-level elements
A. Roles and responsibilities in decision-making
In the current body of knowledge, frameworks that define
roles and responsibilities in decision-making processes exist.
These studies focus on different perspectives in the decision-
making process. For example, there are studies that focus on
the influences of decision-making roles, i.e., family/collegial
pressure and gender or cultural preferences [13][14].
In
addition, there are also studies that focus on specific
application areas for decision-making, i.e., transportation,
medical, financial and governance [15][16]. For example, in
a patient-doctor context where a treatment has to be decided,
multiple roles are relevant, i.e., the patient, different medical
specialists, the doctor, a nurse, and in some cases family
members of the patient [16].
However, as the scope of this paper lies on the creation
of a framework which can be applied to define the
governance structure of any decision, a more generic set of
roles and responsibilities is required.
The work of Rogers and Blenko [3] features a generic
model named RAPID, which presents five different roles that
are applied during the decision-making process. However,
one limitation in the original study is the focus on decisions
that are only executed by human actors. To ground our
framework construction, a detailed description of the RAPID
framework is provided here.
RAPID focuses on assigning a set of specific roles with
regards to a decision. This framework is characterized by a
simple, yet grounded in practice approach and consists of
five different roles and underlying responsibilities that are
related to a decision. The first role is Recommend, which is
responsible for making a proposal and gathering input for
decision-making. This role communicates with the input role
to
ensure
their
viewpoints
are
embedded
in
the
recommendation. The second role is Agree, which is
responsible for evaluating a proposal provided by the
recommender.
This
role
has
veto
power
over
the
recommendation. When this role declines a recommendation,
a modified proposal has to be made. The third role is Input,
which is responsible for providing input (data) to make the
decision and are typically consulted on the decision. The
opinion of this role is non-binding, but should be taken into
account to ensure the decision does not falter during its
execution. The fourth role is Decide, which is responsible as
the formal decision maker and is accountable for the decision
and its results. This role has the most authority compared to
the other roles as it is able to resolve the decision-making
between the previous roles by making the actual decision. By
doing so, this role has the power to commit an organization
to action based on decision-making. Lastly, the fifth role
stands for Perform, which is responsible for executing the
actual decision in the organization after it is decided by the
previous role.
Based on RAPID, Taylor [12], in a professional article,
adapted the RAPID model but made a distinction between a
human and a machine for decision-making processes in
which he stresses that the action component can be different
between these two. For example, when a decision must be
executed in an organization, human actors perform the actual
84
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-620-0
eKNOW 2018 : The Tenth International Conference on Information, Process, and Knowledge Management

decision and also handle possible exceptions. When a
machine executes decisions, exceptions are filtered out and
send to human actors for further examination. Another
significant difference between a human and a machine actor
is the explicitness of business rules that a machine must be
able to execute, and therefore must be maintained adequately
versus the implicit knowledge for the decision-making
utilized by human actors in the actual decision-making
process.
B. Autonomy level of stakeholders in human-machine
interaction
Machine
autonomy
broadly
refers
to
a
machine’s
capability to carry out its own processes and tasks, along
with the decision-making needed to do so [7].
With regards to machine autonomy, also referred to as
robot autonomy or computer autonomy, many authors added
a framework to the body of knowledge that define autonomy
levels. Both general and context-specific frameworks for
levels of autonomy (LOA) exist, while some define very
detailed levels of autonomy, others utilize autonomy as a
concept without exactly defining the spectrum of autonomy
[17]. In this paper, the focus is on generic LOA frameworks.
Regarding generic LOA frameworks, the work of Sheridan
and Verplanck [18] and later Parasuraman, Sheridan and
Wickers [8] defined ten levels of autonomy for decision-
making with automation (i.e., machines/computers), also
abbreviated to LOADAS. Their classification ranks from full
human decisions and actions (level 1) until full autonomy
without interaction with humans (level 10) and takes into
account several variants with alternatives. For example, veto
voting by human actors and the level of interaction between
a machine and human actor. This LOA framework is, to the
knowledge of the authors, the most popular work as it is
cited numerous times and used in the construction of many
other theoretical and practical constructs. However, the ten
LOA levels described in the work of Parasuraman, Sheridan
and Wickers [8] are too much prone to interpretation, which
can be concluded by how the different authors of subsequent
LOA
frameworks
and
related
work
described
this
framework. For example, the work of Endsley and Kaber
[19] describes that the first of ten levels is not fully manual
as it is handed over to the machine to execute it. This is in
contrast with the interpretation and description by Miller and
Parasuraman [20], which describes that a human actor is
responsible for everything in the decision-making process,
including the execution of the decision. A second example of
an interpretation that is not specific enough with regards to
this framework is the notion of levels one and two in the
work of Beer, Fisk and Rogers [7], which state that these two
levels are exactly the same. This would mean that the model
contains a redundant level.
Endsley and Kaber [10] defined in their work ten
categories of the level of automation along with definitions
for the level of autonomy for each category, based on earlier
work by Endsley [19]. However, the ten levels, which are all
activity focused, are grounded by five levels of autonomy
defined by Endsley [19], which are: 1) manual support, 2)
decision support, 3) consensual AI, 4) monitored AI, and 5)
full automation. This framework’s strength is its simplistic
approach
to
autonomy,
which
is
also
its
drawback.
Compared to the framework of Parasuraman, Sheridan and
Wickers [8], this framework lacks proper detail with regards
to the possibilities a machine nowadays has. For example,
based on the five levels of autonomy it is based on, it is
unclear how recommendations are provided and how the
human actor is informed about executing the actual decision
or the result of the decision after execution by a machine.
A third generic framework is the Autonomy Levels For
Unmanned Systems (ALFUS) [11]. This framework includes
increasingly complex environments in which a machine
makes decisions and executes actions. The LOA levels
included in ALFUS, range from zero (remote control) to ten
(full intelligent autonomy). At the lowest LOA, there is
100% interaction between a human and machine actor, while
at the 10th LOA, almost no interaction between a human and
machine actor is present. While ALFUS describes in more
detail the amount of interaction between human and machine
actors, the composition of this interaction is left implicit as it
requires the ALFUS generic framework to be instantiated
into program specific ALFUS frameworks [11].
The currently available frameworks very accurately
describe what levels of autonomy could be taken into
account and how the interaction is possible between human
and machine actors. However, as pointed out earlier, the
existing frameworks lack the exact separation of tasks and
responsibilities
in
complex
human-machine
interaction
environments. Therefore, in the next section, a model is
proposed that combines both the roles relevant for decision
making with the different levels of autonomy possible for
machines in human-machine interaction to overcome this
gap.
III.
GOVERNANCE FRAMEWORK CONSTRUCTION
For the construction of our framework that fills the gaps
identified in the previous section, two perspectives have to
be merged: detailed decision-making roles and detailed
LOA’s. Regarding the decision-making roles, the RAPID
framework [3] is adopted due to its generic nature, thus is
applicable in all contexts. Then, with regards to autonomy,
the LOADAS framework [8] has been adopted due to the
fact that it is utilized by many newer autonomy frameworks.
However, the low level of detail and different interpretations
of this framework and those that preceded LOADAS were
already
considered
a
drawback
for
the
design
and
specification of decisions and decision-making as discussed
in the previous section. Therefore, these models have been
analyzed to identify Situational Factors (SFs) that need to be
taken into account for the construction of the governance
framework. By doing so, the governance framework adopts
all essential constructs from related work on the subject of
autonomy. Analysis of the models resulted in four SF’s. The
four SFs identified from the literature are: 1) type of actor, 2)
alternatives, 3) veto and 4) inform.
The first SF is the type of actor, see for example “The
computer informs the human only if asked” [8]. Simply
stated, when decision-making is defined, a choice has to be
made whether this should be performed by a human actor
85
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-620-0
eKNOW 2018 : The Tenth International Conference on Information, Process, and Knowledge Management

only (variant one), a combination of a human and a machine
actor (variant two) or solely by a machine (variant three).
The second SF concerns the alternatives and the number of
alternatives that are provided by a machine actor to the
human actor, see for example “The computer narrows the
selection down to a few alternatives” [8]. This SF comprises
three possible variants. The machine actor could provide a
full list of possible alternatives to the human actor, offering
no filtering or selection at all (variant one). In the second
variant, the machine actor could provide a selected set of
alternatives for evaluation by a human actor. This means that
the
machine
actor
already
filtered
out
one or
more
alternatives. The amount of alternatives in this variant
depends on the context of the decision-making, and therefore
is not fixed compared to the first and third variant. Lastly,
the machine actor could provide one alternative to the human
actor, which means that the machine actor performs the
complete selection for the human actor, which only has to
decide whether to execute the provided alternative or not
(variant three). The third SF is veto, which encompasses the
time a human actor is provided by the machine actor to
activate a veto over the decision-making by the machine
actor, see for example “Allows the human a restricted time to
veto…” [8]. The amount of time provided by the machine
actor to veto depends on the context of the decision-making,
which results in two possible variants, decision-making
including a veto possibility regardless of the time specified
to do so (variant one) or decision-making without the
possibility to veto (variant two). The fourth SF comprises the
interaction between the human and machine actor regarding
the output of the decision-making, see for example “Informs
the human only if the computer decides to” [8]. This
interaction could entail four possible variants. The first
variant requires the machine actor to always inform the
human actor with the result of the decision-making by the
machine actor. The second variant requires the human actor
to file a request for information about the decision-making
by
the
machine
actor.
The
third
variant
leaves
the
responsibility to inform the human actor about the decision-
making in the hands of the machine actor, which has to
decide whether it is necessary. For example, this could be
determined by the machine actor based on pre-programmed
or self-learned exceptions. The fourth variant is a fully
autonomous state regarding decision-making by the machine
actor, ignoring the human actor.
Combining the RAPID roles and the four identified SFs a
framework is created that supports the detailed design of a
governance structure, see Figure 3. In the governance
framework, each role involved (five in total) is characterized
by four SFs in the decision-making process and should be
specified accordingly.
Figure 2. Governance structure to complement DMN 1.1
Figure 3. Governance Framework for Decision-making
Based on Figure 3, a governance structure for each
decision can be taken into account. Therefore, an additional
element to enrich the current DMN standard is proposed, see
Figure 2.
IV.
CASE DESCRIPTION & APPLICATION
The
hypothesized
application
of
the
model
is
demonstrated using a scenario with three variants. The first
two variants are based on case study data, while the third
variant is based upon a real-world situation, but is not an
exact real-life organizational interpretation of it (simulation).
First, the scenario is described after which the application of
the model is demonstrated using the scenario.
A. Description of scenario
The scenario used to demonstrate the model embodies a
governmental institution that is responsible for providing
digital services to apply for child benefits, see Figure 4. In
this scenario, civilians need to provide information for the
governmental
institution
to
be
assessed
whether
the
household is eligible to receive child benefits, and when this
is the case, the amount of the child benefits and for what
period the child benefits can be received. In this scenario, a
citizen applies for child benefits.
B. Application of the model
The application of the model is demonstrated using three
variants of the scenario. Each of the variants is characterized
by a different composition of roles and corresponding SFs.
86
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-620-0
eKNOW 2018 : The Tenth International Conference on Information, Process, and Knowledge Management

In the context of this demonstration, three steps are required
before the model can be demonstrated: 1) the decision has to
be modelled in DMN. In this context, this means that the
DRD for this particular decision has to be established (the
decision, its input data, its ruleset and relevant sources), see
Fig 1. 2) The governance structure element has to be added
to the DRD, connected to the appropriate decision, see
Figure 2. Lastly, 3). The roles and SFs need to be specified.
An example template to do so is presented in Table 1.
Figure 4. DRD for determining eligibility for child benefits
To demonstrate the usefulness of this template, the
governance structure for the scenario in this demonstration is
also specified in Table 1. For each variant, the design is
changed and depicted in a new table.
Variant 1: Manual human decision-making
TABLE 1. GOVERNANCE STRUCTURE FOR VARIANT ONE
SF1:
Human/
Machine
SF2:
Alter-
natives
SF3:
Veto
SF4:
Inform
Input
Human
(applicant)
N.A.
N.A.
Always
Recommend
Human
(template)
N.A.
N.A.
Never
Agree
Human
(manager)
N.A.
N.A.
Never
Decide
Human
(employee)
N.A.
N.A.
Always
Perform
Human
(employee)
N.A.
N.A.
Always
In the first variant, the applicant fills in a paper template
and delivers it to the governmental counter (Input). Then,
the
governmental
employee
assesses
the
situation
by
analyzing the information in the template (Recommend) and
decides for which benefits the household is eligible (Decide)
based on a discussion about the case with the manager
(Agree). In practice, it can be the case that one actor fulfills
multiple decision-making roles. When the decision is made,
the governmental employee enters the outcome into the
governmental system (Perform). This allows the applicant
to, on a monthly basis, pick up the appointed benefits at the
governmental counter. Lastly, the applicant is informed by
letter regarding the outcome of the decision and is able to
make an appeal within two weeks.
The template used contains information about the
different benefits available and thus guides the decision-
making for both the input and decide roles.
Variant 2: Machine-supported decision-making
TABLE 2. GOVERNANCE STRUCTURE FOR VARIANT TWO
SF1:
Human/
Machine
SF2:
Alter-
natives
SF3:
Veto
SF4:
Inform
Input
Human
(applicant)
N.A.
None
Always
Recommend
Machine
(system)
One
None
Always
Agree
Human
(manager)
N.A.
N.A.
Always
Decide
Human
(employee)
N.A.
N.A.
Never
Perform
Machine
(system)
N.A.
None
On
request
In this variant, the applicant fills in an application
template and uploads it to the online governmental portal
(Input).
Then,
the
government
employee
receives
a
notification of the system, which also provides a suggestion
(Recommend)
with
regards
to
the
eligibility
of
the
application. The governmental employee decides (Decide)
based on a discussion about the case with the manager
(Agree), taking into account the suggestion of the system.
Next, the system notifies the applicant and transfers the
benefits automatically once a month (Perform).
In this variant, the machine generates a suggestion and is
provided with the result of the decision as it needs to apply
machine-learning to increase and maintain the accuracy of
suggestions.
Variant 3: Autonomous decision-making
TABLE 3. GOVERNANCE STRUCTURE FOR VARIANT THREE
SF1:
Human/
Machine
SF2:
Alter-
natives
SF3:
Veto
SF4:
Inform
Input
Machine
(system)
None
None
Always
Recommend
Machine
(system)
None
None
Never
Agree
Human
(citizen)
None
30d
Always
Decide
Machine
(system)
None
None
On
request
Perform
Machine
(system)
None
None
Always
In this variant, the citizen’s data (all digitally available) is
evaluated on a yearly basis by a machine to determine the
eligibility for benefits (Input). Based on this, the citizen is
informed about the pre-filled applications and is able to veto
the data in the pre-filled applications or veto the eligibility in
general. For this example, the time to veto is one month
(Agree). When no veto is cast by the citizen, the system
decides to process the relevant benefits (Recommend &
87
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-620-0
eKNOW 2018 : The Tenth International Conference on Information, Process, and Knowledge Management

Decide) and the benefits are automatically transferred once a
month (Perform).
In the last variant, the citizen is informed about his/her
pre-filled and analyzed data on top of the actual confirmation
after the benefits are approved after no veto has been cast by
the citizen.
The tree variants described provide an overview of a
decision-making process, the role distribution between
humans and machines, the autonomy of the machine, and
SF’s that have to be taken into account. The framework can
also be applied to guide the creation of a roadmap, as it
shows
how decision-making processes can be further
automated and plan accordingly.
V.
DISCUSSION AND CONCLUSION
Since the DMN standard is getting more commonly
utilized in practice, more decisions are being modelled
explicitly for documentation or automation. However, the
current DMN standard does not take into account roles and
autonomy regarding decisions and the underlying decision-
making process. In this paper, a governance structure
framework is being proposed to complement the design and
specification of decisions in the DMN standard. To do so,
the theoretical constructs of decision-making roles (RAPID)
and autonomy levels together with four SFs (LOADAS) are
combined. The proposed governance structure framework
has been demonstrated using a scenario based on three
variants. For each variant, the roles, responsibilities and SF’s
(human-machine, alternatives, veto and inform) are different.
These variants demonstrate that various choices in decision-
making processes lead to design considerations that should
be taken into account. For example, when machines
autonomously decide on what benefits are relevant, what is
the best method of informing humans in a specific context,
or the appropriate timeframe applicable to veto a decision by
a human, in a specific context?
The
suggested
framework
has
its
limitations. The
framework is a suggested solution derived from the existing
knowledge base in the area of decision management,
decision-making and machine autonomy, and thereby the
result of a ‘generate design alternative’ phase [21]. However,
we believe that the proposed framework reached a level of
maturity such that it can enter a detailed validation phase. In
a planned study, a collection of cases will be used to further
validate the framework and to further demonstrate its
practical usefulness.
REFERENCES
[1]
Object
Management
Group,
“Decision
Model
And
Notation (DMN), Version 1.1,” 2016.
[2]
OMG, “ArchiMate® 3.0 Specification,” 2016.
[3]
P. Rogers and M. Blenko, “Who has the D?,” Harv. Bus.
Rev., vol. 84, no. 1, pp. 52–61, 2006.
[4]
M. Zoet, Methods and Concepts for Business Rules
Management, 1st ed. Utrecht: Hogeschool Utrecht, 2014.
[5]
B. Hnatkowska and J. M. Alvarez-Rodriguez, “Business
Rule Patterns Catalog for Structural Business Rules,” in
Software Engineering: Challenges and Solutions, 1st ed.,
Springer International Publishing, 2017, pp. 3–16.
[6]
M. W. Blenko, M. C. Mankins, and P. Rogers, “The
Decision-Driven Organization,” Harv. Bus. Rev., vol. 88,
no. 6, pp. 54–62, Jun. 2010.
[7]
J. Beer, A. D. Fisk, and W. A. Rogers, “Toward a
framework for levels of robot autonomy in human-robot
interaction,” J. Human-Robot Interact., vol. 3, no. 2, p.
74, 2014.
[8]
R. Parasuraman, T. B. Sheridan, and C. D. Wickens, “A
model for types and levels of human interaction with
automation,” IEEE Trans. Syst. man, Cybern. A Syst.
Humans, vol. 30, no. 3, pp. 286–297, 2000.
[9]
European Commission, “Protection of personal data -
GDPR,”
2017.
[Online].
Available:
http://ec.europa.eu/justice/data-protection/.
[Retrieved:
03-Feb-2018].
[10]
M. R. Endsley and D. B. Kaber, “Level of automation
effects on performance, situation awareness and workload
in a dynamic control task,” Ergonomics, vol. 42, no. 3, pp.
462–492, 1999.
[11]
H. M. Huang, K. Pavek, B. Novak, J. Albus, and E.
Messin, “A framework for autonomy levels for unmanned
systems (ALFUS),” in Proceedings of the AUVSI’s
Unmanned Systems North America, 2005, pp. 849–863.
[12]
J. Taylor, “Who has the ‘D’ when the ‘D’ is automated?,”
2007.
[Online].
Available:
http://www.beyeblogs.com/edmblog/archive/2007/02/who
_has_the_d_w_2.php. [Retrieved: 03-Feb-2018].
[13]
B. W. Husted and D. B. Allen, “Toward a model of cross-
cultural business ethics: The impact of individualism and
collectivism on the ethical decision-making process,” J.
Bus. Ethics, vol. 82, no. 2, pp. 293–305, 2008.
[14]
A. Ho, “Relational autonomy or undue pressure? Family’s
role in medical decision‐making,” Scand. J. Caring Sci.,
vol. 22, no. 1, pp. 128–135, 2008.
[15]
P.
S.
Scherrer,
“Directors’
responsibilities
and
participation in the strategic decision-making process,”
Corp. Gov. Int. J. Bus. Soc., vol. 3, no. 1, pp. 86–90,
2003.
[16]
C. Charles, A. Gafni, and T. Whelan, “Decision-making
in the physician-patient encounter: revisiting the shared
treatment decision-making model,” Soc. Sci. Med., vol.
49, no. 5, pp. 651–661, 1999.
[17]
C. Bartneck and J. Forlizzi, “A design-centred framework
for social human-robot interaction,” in Proceedings of the
13th IEEE International Workshop on Robot and Human
Interactive Communication, 2004, pp. 591–594.
[18]
T. B. Sheridan and W. Verplank, “Human and Computer
Control of Undersea Teleoperators,” Cambridge, MA,
1978.
[19]
M. R. Endsley, “The application of human factors to the
development of expert systems for advanced cockpits.,” in
Proceedings of the Human Factors Society Annual
Meeting, 1987, pp. 1388–1392.
[20]
C. A. Miller and R. Parasuraman, “Designing for flexible
interaction between humans and automation: Delegation
interfaces for supervisory control,” Hum. Factors, vol. 49,
no. 1, pp. 57–75, 2007.
[21]
A. R. Hevner, S. T. March, J. Park, and S. Ram, “Design
Science in Information Systems Research,” MISQ., vol.
28, no. 1, pp. 75–105, 2004.
88
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-620-0
eKNOW 2018 : The Tenth International Conference on Information, Process, and Knowledge Management

