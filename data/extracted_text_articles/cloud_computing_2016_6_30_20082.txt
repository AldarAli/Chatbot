Online Trafﬁc Classiﬁcation Based on Swarm Intelligence
Takumi Sue, Yuichi Ohsita, and Masayuki Murata
Graduate School of Information Science and Technology, Osaka University
Osaka, Japan
{t-sue, y-ohsita, murata}@ist.osaka-u.ac.jp
Abstract—In this paper, we propose a new trafﬁc classiﬁcation
method which constructs hierarchical clusters using the features
of uncompleted ﬂows. By constructing the hierarchical groups,
we can identify the similarity of the groups. If ﬂows of a
new application construct a new group in the lower layer, but
they are classiﬁed in an existing group in the upper layer, the
manager can estimate the characteristic of the new application
from the characteristic of the existing group. In our method,
the hierarchical groups are constructed based on the clustering
method called AntTree; the each ﬂow moves over the tree and ﬁnd
the nodes whose similarity to the nodes exceeds the threshold. By
setting the threshold based on the number of monitored packets
of the ﬂow, we classify the ﬂow if the features of the ﬂow become
sufﬁciently accurate. Otherwise we wait another packets that
improve the accuracy of the features.
Keywords—Trafﬁc
Classiﬁcation;
Hierarchical
Clustering;
Swarm Intelligence
I. INTRODUCTION
As the Internet has become playing an important role in our
society, the number of types of services provided through the
Internet increases. The requirements to the network depend
on the type of the service. The video streaming application
requires enough bandwidth according to the bit rate of the
video. On the other hand, the interactive application such as
online game requires the communication with low latency
instead of the large bandwidth.
The network managers should manage their network so as to
provide sufﬁcient network performance required by each ser-
vice. For example, Miyamura et al. [1] proposed a method that
constructs a virtual network for each service. In this method,
each virtual network is dynamically reconﬁgured so as to
provide a performance required by the service corresponding
to the network. To manage the network based on the types
of the service, we need to classify the trafﬁc based on the
application.
The traditional classiﬁcation of the trafﬁc uses the port
numbers [2]. However, in recent years, a large number of types
of the applications, such as YouTube and network game, have
become provided through HTTP [3]. All of these applications
uses 80 or 443 port. As a result, the trafﬁc classiﬁcation using
the port numbers is no longer applicable in the Internet.
Therefore, the trafﬁc classiﬁcation methods based on the
features of the trafﬁc have been proposed [2], [4]–[6]. The
packet sizes and packet arrival intervals depend on the types of
the application, and the protocol used by the application. The
trafﬁc classiﬁcation methods based on the features monitors
the packet size or packet arrival intervals for each ﬂow. Then,
they classify the ﬂows based on the monitored features by
using the clustering methods, in which the ﬂows are grouped
so that the ﬂows with the similar features belongs to the same
group.
The trafﬁc classiﬁcation should be performed as soon as
possible after the ﬂow arrives. Even if the network manager
sets the rule to relay the ﬂow according to the types of the
application, the rule cannot work before the classiﬁcation of
the ﬂow is completed. The existing method, however, cannot
classify the ﬂow before monitoring the ﬂow is completed. One
approach is to classify the ﬂow after the predeﬁned number
of packets are monitored. By setting the required number of
packets to the small value, we can classify the ﬂow soon after
the ﬂow arrives. However, the features of the ﬂow obtained by
monitoring the small number of packets may be inaccurate,
and some application may be difﬁcult to classify based on
such inaccurate information.
Another problem in the existing trafﬁc classiﬁcation is that
the group constructed by the classiﬁcation methods does not
imply the characteristic of the group. When ﬂows of a new
application comes, the ﬂows are classiﬁed into a new group.
However, the existing classiﬁcation methods do not provide
the information whether the newly constructed group has the
similar characteristic to the existing other groups. As a result, it
is difﬁcult to estimate the characteristic of the new application.
In this paper, we propose a new trafﬁc classiﬁcation method
to solve the above problems. Our method is based on the
hierarchical clustering [7]. In the hierarchical clustering, the
groups of the ﬂows are hierarchically constructed; the ﬂows
are clustered into a small number of groups in the upper
layer, and the ﬂows belonging to the same group in the upper
layers are clustered into several groups in the lower layer.
By constructing the hierarchical groups, we can identify the
similarity of the groups. If ﬂows of a new application construct
a new group in the lower layer, but they are classiﬁed in an
existing group in the upper layer, the manager can estimate the
characteristic of the new application from the characteristic of
the existing group.
In our method, the hierarchical groups are constructed
based on the clustering method called AntTree [8]. AntTree
is inspired by the behavior of ants constructing the tree. In
the AntTree, an ant, which corresponds to an item required
to be classiﬁed, walks on the tree constructed by the other
ants. Then, if the ant ﬁnd the ant whose similarity exceeds the
threshold, the ant is connected to the similar ant. If the nearby
ants do not have the similarity exceeding the threshold, the ant
updates the threshold and goes to another place on the tree.
By continuing this process, the hierarchical tree, where similar
131
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

ants are connected, is constructed.
In our method, we extend AntTree to consider the accuracy
of the features. The features of the ﬂow become accurate as
the number of monitored packets increases. We classify the
ﬂow if the features of the ﬂow become sufﬁciently accurate.
Otherwise we wait another packets that improve the accuracy
of the features. To achieve this, we extend the AntTree by
setting the threshold of the similarity to connect the ants
considering the number of monitored packets. By doing so,
if the quite similar group to the newly arrived ﬂow exists,
the ﬂow is classiﬁed soon after the ﬂow starts. Otherwise, our
method waits another packet to improve the accuracy, and the
ﬂow is classiﬁed after the sufﬁcient packets are monitored.
The rest of this paper is organized as follows. Section II
explains the related work. Section III explains our online
hierarchical trafﬁc classiﬁcation method. In Section IV , we
conduct an experiment with real trafﬁc data. The conclusion
and future work are mentioned in Section V.
II. RELATED WORK
This section explains the related work.
A. Trafﬁc Classiﬁcation
There are several papers proposing a method to classify the
trafﬁc using the features of the monitored trafﬁc.
Roughan et al. proposed a method to classify the trafﬁc
through the supervised machine learning [4]. In this method,
the newly obtained data is classiﬁed as the class of its nearest
neighbor from the training data set. Zhang et al. improved the
accuracy of the nearest neighbor approach when the number of
the training data set is small by incorporating the correlation
information of the ﬂows [9]. Moore et al. also proposed a
method to classify the trafﬁc based on the supervised machine
learning [5]. In this method, the trafﬁc is classiﬁed by using
the Na¨ıve Bayes classiﬁer. Nguyen et al. also used the Na¨ıve
Bayes to classify the trafﬁc [10]. This method uses the features
of a small number of most recent packets to obtain the
features. Then, applying the Na¨ıve Bayes, this method classify
the current ﬂows. Zhang et al. also used the Na¨ıve Bayes
classiﬁer [11]. In this method, ﬂow correlation information
is modeled by bag-of-ﬂow. Then, the features are extracted
for the represent trafﬁc ﬂows. The trafﬁc is classiﬁed by
aggregating the output of the Na¨ıve Bayes classiﬁers using the
extracted features. Li et al. proposed a method to construct the
decision tree from the training data set [12]. Then the trafﬁc
is classiﬁed based on the constructed decision tree. Jin et al.
proposed a trafﬁc classiﬁcation method using multiple simple
linear binary classiﬁers [13]. In this method, each classiﬁer
can be easily trained. Then, combining the multiple classiﬁers,
we can accurately classify the trafﬁc.
The supervised machine learning methods described above
require the training data set. However, as we discussed in
Section I, it is difﬁcult to prepare the training data set including
the suitable labels for the trafﬁc, because the new applications,
which are unknown when the system to classify the trafﬁc
starts, emerge.
The methods to classify the trafﬁc based on the clustering
have also been proposed.
Erman et al. applied the clustering method to the trafﬁc clas-
siﬁcation [14]. They used the K-means method, DBSCAN, and
AutoClass, and demonstrated that these clustering algorithms
can classify the trafﬁc accurately. Bernaille et al. proposed
a method to classify the trafﬁc online using the K-means
method [6]. In this method, the clusters are constructed ofﬂine
by using the training data set. Then, ﬂows are classiﬁed online
by searching the cluster corresponding to the ﬂow. However,
this approach cannot classify the trafﬁc which corresponds to
the application, which was not included in the training data
set. The clustering method can be used to solve this problem.
Zhang et al used the K-means method to detect the unknown
ﬂows [15].
Recently, Wang et al. extended the K-means method to
improve the accuracy of the trafﬁc classiﬁcation [16]. In
this method, the accuracy is improved by considering the
information of the ﬂow inferred from the packet headers as
the constraint on the clustering.
However, the existing trafﬁc classiﬁcation methods based
on the clustering have the following two problems. (1) These
methods do not consider the case that the new applications
emerges. Though the method proposed by Zhang et al [15] can
detect the unknown ﬂows, it cannot estimate the characteristic
of the new ﬂow. (2) These methods assume that the accurate
features of the ﬂow are obtained before classifying the trafﬁc.
However, the accurate features may not be able to be obtained
before the ﬂow is completed.
In this paper, we propose a clustering method which solves
the above problems. Our clustering method can be applicable
to the existing trafﬁc classiﬁcation method based on the
clustering; our clustering method can be run by using any
features of the ﬂows.
B. Clustering
There are many algorithms to construct the clusters.
K-means is one of the most popular clustering algorithms.
In the K-means method, the number of clusters k is given
as a parameter. Then, the k clusters are constructed so as to
minimize the distance from each data point to the center of
the cluster the data point belongs to, which is deﬁned by the
mean of the data points within the cluster. However, the result
of the K-means only indicates the cluster which each data
point belongs to. Thus, we cannot understand the similarity of
the data points belonging to different clusters.
The hierarchical clustering methods can solve the above
problem. In the hierarchical clustering methods, the data points
are clustered into a small number of groups in the upper layer,
and the data points belonging to the same group in the upper
layers are clustered into several groups in the lower layer.
By constructing the hierarchical groups, we can identify the
similarity of the groups.
The ClusTree is one of the hierarchical clustering methods,
which allow to update the clusters online [7]. This method
constructs the tree, including two kinds of nodes, inner node
132
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

and leaf node. The leaf node indicates a ﬁne-grained cluster,
and has the pointer to the feature values of the corresponding
data points. The inner node corresponds to the coarse-grained
cluster, which includes the data points included in its children
nodes. The inner node has the pointer to the aggregated
features of the data points included in its children nodes. In
the ClusTree, the clusters can be updated by (1) searching the
leaf node corresponding to the new data point from the root
node, and (2) updating the features on the path from the root
node to the leaf node.
The ClusTree can be updated online, but does not consider
the case that the features are inaccurate. Therefore, in this
paper, we propose a new clustering method based on the
ClusTree, considering the case that the features are inaccurate.
AntTree [8] is another hierarchical clustering method.
AntTree is a method inspired by the behavior of the ants
constructing a tree. In this process, each data point acts as an
ant; each data point walks around the tree to ﬁnd the node
similar to the ﬂow, and connects it to the found node. In
the AntTree, the nodes in the constructed tree are the data
points. Therefore, it is difﬁcult to interpret the constructed
tree hierarchically; we need to determine the data points
corresponding to the inner nodes when constructing the ﬁne-
grained ﬂow. However, the idea of the AntTree is useful to
handle the inaccuracy of the features. In the AntTree, each
data point has a threshold to determine whether the other data
points are similar to it. Then, each data point walks around
the tree based on the threshold. Though the original AntTree
updates the threshold based on the number of nodes the data
points visited, we can consider the inaccuracy of the features
by setting the threshold based on the accuracy of the features.
Therefore, in this paper, we introduce the method based on
the AntTree to search the cluster each data point belongs to.
III. ONLINE HIERARCHICAL TRAFFIC CLASSIFICATION
METHOD
This section explains our online hierarchical trafﬁc classiﬁ-
cation method.
A. Overview
In this paper, we develop the trafﬁc classiﬁer, which clas-
siﬁes the ﬂow passing the classiﬁer. The ﬂow is deﬁned by
the set of packets between the same IP address pairs using
the same server port. We regard the well-known ports as the
server ports, and the other ports as the client ports. In this
paper, the packets using the same server port is regarded as
the packets belonging to the same ﬂow even if the packets
have the different client port, because some application such
as Web browser uses the multiple TCP connections for the
same transaction.
The trafﬁc classiﬁer monitors the ﬂows. When the trafﬁc
classiﬁer receive a packet, it identiﬁes the ﬂow the packet
belongs to. Then, it stores the information of the packet. The
trafﬁc classiﬁer updates the features of the ﬂow each time a
packet of the ﬂow are monitored.
The trafﬁc classiﬁer classiﬁes the ﬂow based on its features.
To classify the ﬂow, we use the hierarchical clustering meth-
ods. In the hierarchical clustering, the groups of the ﬂows are
hierarchically constructed; the ﬂows are clustered into a small
number of groups in the upper layer, and the ﬂows belonging
to the same group in the upper layers are clustered into several
groups in the lower layer. By constructing the hierarchical
groups, we can identify the similarity of the groups.
Each time the features of the ﬂow is updated, the trafﬁc
classiﬁer runs the clustering method. That is, the clustering is
performed before the ﬂow completed by using the inaccurate
features, which leads to wrong classiﬁcation. Therefore, we
use the clustering method considering the accuracy of the
features. The accuracy of the features of the ﬂow increases
as the number of monitored packets becomes large. Thus, we
classify the ﬂow if the features of the ﬂow become sufﬁciently
accurate. Otherwise we wait another packets that improve the
accuracy of the features.
To achieve this, we extend the AntTree. In the AntTree, an
ant, which corresponds to an item required to be classiﬁed,
walks on the tree constructed by the other ants. Then, if the
ant ﬁnd the ant whose similarity exceeds the threshold, the ant
is connected to the similar ant.
If the nearby ants do not have the similarity exceeding the
threshold, the ant updates the threshold and goes to another
place on the tree. By continuing this process, the hierarchical
tree, where similar ants are connected, is constructed.
In this paper, we set the threshold of the AntTree based on
the number of received packets; the ﬂow with a small number
of monitored packets is connected to the node only if the very
similar node exists. On the other hand, the ﬂow with a large
number of monitored packets is easier to be connected.
B. Data structure
In this paper, we construct the hierarchical cluster based
on ClusTree [7]. Figure 1 shows the data structure of the
constructed cluster.
In this data structure, the feature values of the ﬂows are
stored in a table, and updated each time a packet corresponding
the ﬂow arrives. We denote the feature value of the ﬂow f as
the vector Ff.
This cluster has two kinds of nodes, inner node and leaf
node. The leaf node indicates a ﬁne-grained cluster, and
includes l toL ﬂows. Each leaf node has the pointer to the
feature values of the corresponding ﬂows.
The inner node corresponds to the coarse-grained cluster,
which includes the ﬂows included in its children nodes.
That is, by constructing the tree of inner nodes, we can
hierarchically construct clusters; the inner node near root node
corresponds to the coarser-grained cluster, and the node near
leaf corresponds to the ﬁner grained node.
The inner node construct the tree structure by connecting
it tom to M children. Each inner node has the entries
corresponding to its children. Each entry has the abstracted
clustering features and the pointer to the corresponding child.
133
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

The abstracted clustering features corresponding to the child
node c have the following values.
• The number of ﬂows included in the abstracted features
nc
• The sum of the features Slinear, which is calculated by
Slinear
c
=
∑
f∈Fc
Ff
where Fc is the set of ﬂows included in cluster of the
node c.
In our method, there are ﬂows that have not been classiﬁed
into any clusters. We maintain such ﬂows in a list called
unclassiﬁed ﬂows.
A flow	  feature
Clustering	  feature
Figure 1.
Data structure of the hierarchical cluster
C. Process to update the tree
When the trafﬁc classiﬁer receives a packet, it identiﬁes the
ﬂow of the packet, and stores the packets. Each time a packet
of the ﬂow arrive, the features of the ﬂow are updated. At the
same time, the data structure of the tree is updated.
The process to update the tree depends on whether the ﬂow
is already classiﬁed into one of the clusters or included in the
unclassiﬁed ﬂows.
1) Update the data of the ﬂows that is included in the
unclassiﬁed ﬂows: We denote the ﬂow ﬁnding the cluster by
f new, the location of f new by pf new, the node whose feature
is the most similar to f new among the children of pf new by
cpfnew . T sim
f
and T dissim
f
are the thresholds for the ﬂow f.
Sim(f, c) indicates the similarity between the ﬂow f and the
node c, which is calculated by
Sim(f, c) = 1 − distance(f, c) − distancemin
distancemax − distancemin
(1)
where distance(f, c) is deﬁned by
distance(f, c) =
Ff + Slinear
n
nc
 .
In this paper, the ﬂow f new moves over the tree by per-
forming the following rule once per one arrival packet.
• If pf new is the root node
1) if the root node has no children, make a leaf node
and insert the pointer to f new to the newly added
node
2) Otherwise, go to cpfnew
• If pf new is not the root node
1) If Sim(f new, cpfnew ) ≥ T sim
f new,
a) Go to cpfnew
b) If cpfnew is a leaf node,
i) Insert the pointer to f new to cpfnew
ii) Update the abstracted clustering features of
the ancestors a of cpfnew by adding Ff to
Slinear
a
and 1 to na
iii) If there exists a node whose number of
children exceeds the upper limit (L or M),
add new a node
2) If Sim(f new, cpfnew ) < T sim
f new
a) Sim(f new, cpfnew ) < T dissim
f new , go back to the
parent node of cpfnew
b) Otherwise, stay at cpfnew
In the above steps, T sim
f new and T dissim
f new
is updated by
Tsim(ai) = Tsim(ai) × α1,
(2)
and
Tdissim(ai) = Tdissim(ai) × α2,
(3)
where α1 and α2 are the parameters.
Addition of the new node in the above steps is done by the
following steps. First, we calculate ∑
c∈Ca
Slinear
n
nc
where a is a
node whose number of entries exceeds the upper limit, and Ca
is a set of the children of a. Then, we select the cmax whose
Slinear
n
ncmax is the most different from ∑
c∈Ca
Slinear
n
nc
. Finally, we
remove the entry for cmax from a and add the node including
the entry for cmax. The parent of the newly added node is set
to the parent of a. If the parent of a also has more entries than
the upper limit after the above process, we perform the same
process for the parent again.
IV. EXPERIMENT
In this paper, we used our trafﬁc classiﬁer to classify the
ﬂows from one computer in our laboratory, where 43 ﬂows are
monitored. The computer accessed Web servers, an Exchange
server, and so on through the 80 or 443 port. To classify the
ﬂows, we use the features shown in Table I. In this features, we
deﬁne the downstream packets as the packets from the servers
whose port number is a well-known port, and the upstream
packets as the packets to the servers.
In this experiment, we set the initial values of Tsim(ai)
and Tdissim(ai) to 1.0. We set α1 and α2 to 0.7. We started
the classiﬁcation after 5 packets per ﬂow were received. The
features of each ﬂow were updated until more than 100 packets
of the ﬂow were received. We stopped updating the features
after 100 packets were received, because the features do not
change signiﬁcantly after a sufﬁcient number of packets are
monitored.
Figure 2 shows the tree constructed by our classiﬁcation.
Table II shows the features of the ﬂow grouped by the cluster
in the lowest layer. Tables III and IV show the abstracted
clustering features divided by the number of ﬂows included in
134
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

TABLE I
FEATURES USED IN OUR EXPERIMENT
Name
Description
E(sdown)
Average of the size of the downstream packets
E(sup)
Average of the size of the upstream packets
σ(sdown)
Standard deviation of the size of the downstream packets
σ(sup)
Standard deviation of the size of the upstream packets
E(idown)
Average of the interval of the arrival of the downstream packets
E(iup)
Average of the interval of the arrival of the upstream packets
σ(idown)
Standard deviation of the interval of the arrival
of the downstream packets
σ(idown)
Standard deviation of the interval of the arrival
of the upstream packets
the abstracted clustering features. To illustrate the result of the
clustering, we plot the scatter graph of the clustering features
of each ﬂow. In Figures 3 and 4, we colored the ﬂows based
on the group constructed in the 2nd layer and the 3rd layer of
the tree, respectively.
These ﬁgures show that our clustering method can group
ﬂows into clusters so that the ﬂows with the similar feature are
included in the same cluster, in any layers. That is, our method
can classify the ﬂows even before the ﬂow is completed.
These ﬁgure also indicates that the constructed clusters are
mainly based on the packet sizes, and packet arrival interval
does not have a large impact on the cluster.
Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 
Node 10 
Node 6 Node 7 Node 8 Node 9 
Node 11 Node 12 Node 13 Node 14 Node 15 Node 16 
Depth 4 
Depth 3 
Depth 2 
Depth 1 
Node 3 
Node 1 
Node 2 
Node 4 
Node 0 
Node 5 
Node 6 
Node 0 
Node 1 
Node 2 
Root 
Figure 2.
Tree constructed by our classiﬁcation
V. CONCLUSION
In this paper, we proposed a new trafﬁc classiﬁcation
method that construct hierarchical groups of the similar ﬂows.
Through the experiment, we demonstrated that our classiﬁ-
cation method enables grouping similar ﬂows into the same
clusters. That is, our method can classify the ﬂows even
before the ﬂow is completed. Results also indicates that the
constructed clusters are mainly based on the packet sizes, and
packet arrival interval does not have a large impact on the
cluster.
Our future work includes further veriﬁcation of our method
using larger trafﬁc data and discussion on more appropriate
features calculated from packet information.
REFERENCES
[1] Takashi Miyamura, Yuichi Ohsita, Shin’ichi Arakawa, Yuki Koizumi,
Akeo Masuda, Kohei Shiomoto, and Masayuki Murata, “Network vir-
tualization server for adaptive network control,” in Proceedings of
20th ITC Specialist Seminar on Network Virtualization - Concept and
Performance Aspects, May 2009.
[2] A. Callado, C. Kamienski, G. Szabo, B. P. Gero, J. Kelner, S. Fernandes,
and D. Sadok, “A survey on internet trafﬁc identiﬁcation,” Communica-
tions Surveys & Tutorials, IEEE, vol. 11, pp. 37–52, Aug. 2009.
[3] L. Popa, A. Ghodsi, and I. Stoica, “Http as the narrow waist of the future
internet,” in Proceedings of the 9th ACM SIGCOMM Workshop on Hot
Topics in Networks, Hotnets-IX, (New York, NY, USA), pp. 6:1–6:6,
ACM, 2010.
[4] M. Roughan, S. Sen, O. Spatscheck, and N. Dufﬁeld, “Class-of-service
mapping for QoS: A statistical signature-based approach to IP trafﬁc
classiﬁcation,” in Proceedings of the 4th ACM SIGCOMM Conference
on Internet Measurement, IMC ’04, (New York, NY, USA), pp. 135–
148, ACM, 2004.
[5] A. W. Moore and D. Zuev, “Internet trafﬁc classiﬁcation using bayesian
analysis techniques,” ACM SIGMETRICS Performance Evaluation Re-
view, vol. 33, pp. 50–60, June 2005.
[6] L. Bernaille, R. Teixeira, and K. Salamatian, “Early application iden-
tiﬁcation,” in Proceedings of the 2006 ACM CoNEXT Conference,
CoNEXT ’06, (New York, NY, USA), pp. 6:1–6:12, ACM, 2006.
[7] P. Kranen, I. Assent, C. Baldauf, and T. Seidl, “The ClusTree: indexing
micro-clusters for anytime stream mining,” Knowledge and Information
Systems, vol. 29, no. 2, pp. 249–272, 2011.
[8] H. Azzag, N. Monmarche, M. Slimane, and G. Venturini, “AntTree: a
new model for clustering with artiﬁcial ants,” Evolutionary Computation,
2003. CEC ’03. The 2003 Congress on, vol. 4, pp. 2642–2647, Dec.
2003.
[9] J. Zhang, Y. Xiang, Y. Wang, W. Zhou, Y. Xiang, and Y. Guan,
“Network trafﬁc classiﬁcation using correlation information,” Parallel
and Distributed Systems, IEEE Transactions on, vol. 24, pp. 104–117,
Jan 2013.
[10] T. T. T. Nguyen, G. Armitage, P. Branch, and S. Zander, “Timely
and continuous machine-learning-based classiﬁcation for interactive ip
trafﬁc,” IEEE/ACM Trans. Netw., vol. 20, pp. 1880–1894, Dec. 2012.
[11] J. Zhang, C. Chen, Y. Xiang, W. Zhou, and Y. Xiang, “Internet
trafﬁc classiﬁcation by aggregating correlated naive bayes predictions,”
Information Forensics and Security, IEEE Transactions on, vol. 8, pp. 5–
15, Jan 2013.
[12] W. Li, M. Canini, A. W. Moore, and R. Bolla, “Efﬁcient application
identiﬁcation and the temporal and spatial stability of classiﬁcation
schema,” Comput. Netw., vol. 53, pp. 790–809, Apr. 2009.
[13] Y. Jin, N. Dufﬁeld, J. Erman, P. Haffner, S. Sen, and Z.-L. Zhang, “A
modular machine learning system for ﬂow-level trafﬁc classiﬁcation in
large networks,” ACM Trans. Knowl. Discov. Data, vol. 6, pp. 4:1–4:34,
Mar. 2012.
[14] J. Erman, M. Arlitt, and A. Mahanti, “Trafﬁc classiﬁcation using
clustering algorithms,” in Proceedings of the 2006 SIGCOMM workshop
on Mining network data, pp. 281–286, 2006.
[15] J. Zhang, C. Chen, Y. Xiang, W. Zhou, and A. Vasilakos, “An effective
network trafﬁc classiﬁcation method with unknown ﬂow detection,”
Network and Service Management, IEEE Transactions on, vol. 10,
pp. 133–147, June 2013.
[16] Y. Wang, Y. Xiang, J. Zhang, W. Zhou, G. Wei, and L. Yang, “In-
ternet trafﬁc classiﬁcation using constrained clustering,” Parallel and
Distributed Systems, IEEE Transactions on, vol. 25, pp. 2932–2943,
Nov 2014.
135
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

TABLE II
FEATURES OF THE FLOWS: DEPTH 4
ﬂow number
E(sdown)
E(sup)
σ(sdown)
σ(sup)
E(idown)
E(iup)
σ(idown)
σ(iup)
Node 0
1
0.72084
0.0982946
0.42354
0.114737
1.01073e-005
1.51213e-005
3.37173e-005
3.97892e-005
2
0.627727
0.106697
0.426203
0.126686
5.652e-005
0.000123704
9.43008e-005
0.000106826
3
0.713851
0.0930637
0.381509
0.123607
0.000609879
0.000972389
0.00136518
0.00154726
4
0.804338
0.0884975
0.378517
0.112426
2.81074e-005
6.92139e-005
6.58568e-005
8.45793e-005
5
0.763775
0.116724
0.386436
0.159844
0.0123994
0.0198522
0.0582105
0.072384
Node 1
6
0.546043
0.101218
0.4561
0.115731
5.26767e-005
0.000108162
8.91574e-005
8.57252e-005
7
0.547945
0.104547
0.454592
0.128433
0.000902717
0.00128282
0.00165487
0.00184167
Node 2
8
0.715821
0.144243
0.396433
0.246516
2.88237e-005
3.63364e-005
8.34268e-005
9.56236e-005
Node 3
9
0.427973
0.293015
0.349902
0.284289
3.13866e-005
3.08145e-005
5.17207e-005
4.05901e-005
10
0.541256
0.504292
0.431807
0.441602
0.0011992
0.000964186
0.00186101
0.00159072
Node 4
11
0.361422
0.248002
0.384193
0.309865
0.000404118
0.000285903
0.000602977
0.000354651
12
0.335109
0.277778
0.378048
0.320403
0.000174889
0.000145212
0.000162109
0.000161237
Node 5
13
0.463263
0.20624
0.429613
0.281791
0.00074491
0.000975223
0.00158266
0.0018436
14
0.463263
0.226884
0.429613
0.292398
0.000326853
0.000513898
0.000358468
0.000505234
Node 6
15
0.378691
0.0986175
0.412466
0.0966242
9.41781e-005
7.83116e-005
0.000343073
0.000214059
16
0.384721
0.0927376
0.397592
0.0789838
1.71589e-005
1.75337e-005
5.07459e-005
4.32654e-005
17
0.32715
0.165906
0.398255
0.151882
0.00278449
0.00313977
0.00231127
0.00203568
18
0.406562
0.102182
0.422961
0.0993938
0.000132655
0.000113818
0.000257254
0.000232465
19
0.402588
0.143075
0.437178
0.194868
6.77042e-005
0.00115388
0.00010484
0.0017407
Node 7
20
0.274734
0.109589
0.369642
0.132467
0.000220875
0.000434846
0.000330604
0.00039426
Node 8
21
0.479959
0.10624
0.441488
0.125773
0.0506274
0.0633271
0.101089
0.109396
Node 9
22
0.0570776
0.0593607
0.0114155
0
0.0222335
0.0500198
0.0248326
6.13253e-006
23
0.105784
0.0410959
0
0
0.250259
0.250248
3.545e-006
6.00934e-005
24
0.105784
0.0410959
0
0
0.250257
0.250257
7.90377e-006
0.000219129
25
0.167047
0.328767
0.121385
0
0.323694
0.727734
0.36831
0.121438
Node 10
26
0.0456621
0.0410959
0
0
0.0105705
0.00906027
0.022708
0.0213338
Node 11
27
0.1207
0.0628615
0.0339138
0.0021309
0.00817775
0.00833702
0.00765219
0.00837687
Node 12
28
0.293715
0.10136
0.342828
0.0946878
0.000162252
0.000128599
0.000429047
0.000293705
29
0.3431
0.128742
0.420671
0.191927
0.000136547
0.00013721
0.000158327
8.46613e-005
30
0.256722
0.0967783
0.350721
0.120472
0.00795401
0.00795477
0.00984362
0.0097643
31
0.222
0.107827
0.309717
0.0900621
0.000672249
0.000859237
0.00212733
0.00252721
Node 13
32
0.153349
0.174458
0.190907
0.148768
2.02533e-005
2.86792e-005
5.66575e-005
6.71647e-005
33
0.102055
0.181602
0.0811775
0.176932
9.99759e-005
7.07622e-005
0.000182625
0.000142923
34
0.140665
0.171487
0.131139
0.178177
2.1e-005
1.51033e-005
2.84602e-005
1.38837e-005
35
0.150158
0.132479
0.151779
0.146517
8.32722e-005
8.31819e-005
0.000175796
0.000215069
36
0.100761
0.199391
0.107929
0.277773
0.0292866
0.023471
0.0504462
0.0461822
Node 14
37
0.122273
0.129427
0.0958468
0.102736
0.044121
0.0536464
0.127781
0.138994
Node 15
38
0.226636
0.0888128
0.170655
0.0909378
0.0431425
0.0196648
0.0638903
0.0455347
Node 16
39
0.946356
0.0748792
0.208481
0.156522
3.45042e-005
0.000112505
6.80385e-005
0.000201225
40
0.756059
0.0831219
0.380303
0.112472
0.000272307
0.000536175
0.000593526
0.000963796
41
0.895826
0.0653595
0.278181
0.0857372
7.59293e-005
0.000120305
0.000233297
0.000279578
42
0.862609
0.0769847
0.324408
0.0999886
6.9086e-006
1.35787e-005
1.75598e-005
2.69238e-005
43
0.899784
0.088946
0.292179
0.123184
3.14463e-005
7.06452e-005
5.85814e-005
6.59837e-005
136
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

TABLE III
FEATURES OF THE FLOWS: DEPTH 3
ﬂow number
E(sdown)
E(sup)
σ(sdown)
σ(sup)
E(idown)
E(iup)
σ(idown)
σ(iup)
Node 0
1-5
0.726106
0.100655
0.399241
0.12746
0.0026208
0.00420653
0.0119539
0.0148325
6-7
0.546994
0.102882
0.455346
0.122082
0.000477697
0.00069549
0.000872014
0.000963698
8
0.715821
0.144243
0.396433
0.246516
2.88237e-005
3.63364e-005
8.34268e-005
9.56236e-005
Node 1
9-10
0.484614
0.398653
0.390854
0.362946
0.000615291
0.0004975
0.000956365
0.000815653
11-12
0.348266
0.26289
0.38112
0.315134
0.000289504
0.000215557
0.000382543
0.000257944
13-14
0.463263
0.216562
0.429613
0.287094
0.000535882
0.00074456
0.000970564
0.00117442
Node 2
15-19
0.379942
0.120503
0.41369
0.12435
0.000619237
0.000900662
0.000613436
0.000853234
20
0.274734
0.109589
0.369642
0.132467
0.000220875
0.000434846
0.000330604
0.00039426
21
0.479959
0.10624
0.441488
0.125773
0.0506274
0.0633271
0.101089
0.109396
Node 3
22-25
0.108923
0.11758
0.0332002
0
0.211611
0.319565
0.0982885
0.0304309
26
0.0456621
0.0410959
0
0
0.0105705
0.00906027
0.022708
0.0213338
27
0.1207
0.0628615
0.0339138
0.0021309
0.00817775
0.00833702
0.00765219
0.00837687
Node 4
28-31
0.278884
0.108677
0.355984
0.124287
0.00223127
0.00226995
0.00313958
0.00316747
Node 5
32-36
0.129397
0.171883
0.132586
0.185633
0.00590221
0.00473374
0.0101779
0.00932424
37
0.122273
0.129427
0.0958468
0.102736
0.044121
0.0536464
0.127781
0.138994
38
0.226636
0.0888128
0.170655
0.0909378
0.0431425
0.0196648
0.0638903
0.0455347
Node 6
39-43
0.872127
0.0778583
0.29671
0.115581
8.42191e-005
0.000170642
0.0001942
0.000307501
TABLE IV
FEATURES OF THE FLOWS: DEPTH 2
ﬂow number
E(sdown)
E(sup)
σ(sdown)
σ(sup)
E(idown)
E(iup)
σ(idown)
σ(iup)
Node 0
1-8
0.680042
0.106661
0.412916
0.140997
0.00176102
0.0028075
0.00769962
0.00952319
9-14
0.432048
0.292702
0.400529
0.321725
0.000480226
0.000485873
0.000769824
0.000749338
15-21
0.379201
0.116907
0.411369
0.125713
0.00770635
0.00975218
0.0149268
0.0162938
Node 1
22-27
0.100342
0.0957128
0.0277857
0.00035515
0.144199
0.215943
0.0705857
0.025239
28-31
0.278884
0.108677
0.355984
0.124287
0.00223127
0.00226995
0.00313958
0.00316747
32-38
0.142271
0.153951
0.132776
0.160263
0.0166821
0.0138543
0.0346516
0.0330214
Node 2
39-43
0.872127
0.0778583
0.29671
0.115581
8.42191e-005
0.000170642
0.0001942
0.000307501
137
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up
down
Node 0
Node 1
Node 2
Node 3
Node 4
Node 5
Node 6
(a) E(sup) vs. E(sdown)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up
down
Node 0
Node 1
Node 2
Node 3
Node 4
Node 5
Node 6
(b) σ(sup) vs. σ(sdown)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up 
down 
Node 0
Node 1
Node 2
Node 3
Node 4
Node 5
Node 6
(c) E(iup) vs. E(idown)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up
down
Node 0
Node 1
Node 2
Node 3
Node 4
Node 5
Node 6
(d) σ(iup) vs. σ(idown)
Figure 3.
Features distribution: depth 3
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up 
down 
node 0
node 1
node 2
(a) E(sup) vs. E(sdown)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up
down
Node 0
Node 1
Node 2
(b) σ(sup) vs. σ(sdown)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up
down
Node 0
Node 1
Node 2
(c) E(iup) vs. E(idown)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
up
down
Node 0
Node 1
Node 2
(d) σ(iup) vs. σ(idown)
Figure 4.
Features disribution: depth 2
138
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-460-2
CLOUD COMPUTING 2016 : The Seventh International Conference on Cloud Computing, GRIDs, and Virtualization

