Global Exponential Stability of the Periodic Solution of a Discrete-Time
Complex-Valued Hopﬁeld Neural Network with Delays and Impulses
Val´ery Covachev
Institute of Mathematics and Informatics
Bulgarian Academy of Sciences
Soﬁa, Bulgaria
Email: vcovachev@hotmail.com
Zlatinka Covacheva
Middle East College
Muscat, Sultanate of Oman
Email: zkovacheva@hotmail.com
Abstract—The global stability of the periodic solution of a
discrete-time complex-valued Hopﬁeld neural network is studied.
By introducing an appropriate Lyapunov functional it is proved
that any two solutions of the system exponentially approach each
other with time.
Keywords-complex neural networks; periodic solution; stability.
I. INTRODUCTION
Over the past three decades, neural networks have been
widely studied since they have been successfully applied
to various processing problems such as optimization, image
processing, associative memory and many other ﬁelds (see
[10][12] and references given therein). Different types of
applications depend on the dynamical behaviors of the neural
networks. The existence and stability of equilibrium points and
periodic solutions are of particular interest.
In order to solve problems in the ﬁelds of optimization,
neural control and signal processing, neural networks have
to be designed such that there is only one equilibrium point
and this equilibrium point is globally asymptotically stable so
as to avoid the risk of having spurious equilibria and local
minima. In the case of global stability, there is no need to
be speciﬁc about the initial conditions for the neural circuits
since all trajectories starting from anywhere settle down at the
same unique equilibrium. If the equilibrium is exponentially
asymptotically stable, the convergence is fast for real-time
computations. The unique equilibrium depends on the external
stimulus. When the parameters of the neural network and the
external stimulus are not constants but periodic functions of
time, which is the case in many real-life problems, the role of
the equilibrium point is played by a periodic solution.
Numerical algorithms of Hopﬁeld-type differential equa-
tions lead to discrete-time dynamic systems and such discrete-
time systems should not give rise to any spurious behavior
if either system is to be used for coding equilibrium as
associative memories corresponding to temporally uniform
external stimuli obtained. The discrete-time models serve as
global numerical methods on unbounded intervals for the
continuous-time systems [18].
A. Hirose wrote in the introduction to [13]: “Complex-
valued neural networks (CVNNs) are effective and powerful
in particular to deal with wave phenomena such as electro-
magnetic and sonic waves, as well as to process wave-related
information ...Researchers extend the world of computation to
pattern processing ﬁelds based on a novel use of the structure
of complex-amplitude (phase and amplitude) information.”
Further on, he listed the following major application ﬁelds of
CVNNs: antenna design, estimation of direction of arrival and
beamforming of electromagnetic waves, radar imaging, acous-
tic signal processing and ultrasonic imaging, communications
signal processing, image processing, trafﬁc-lights and electric-
power systems, quantum devices such as superconductive
devices, optical/lightwave information processing including
carrier-frequency multiplexing. CVNNs also ﬁnd applications
in ﬁelds such as speech synthesis, spatiotemporal analysis of
physiological neural devices and systems and artiﬁcial neural
information processing [23]. CVNNs can be considered as an
extension of real-valued neural networks; however, they can
be used to solve problems which cannot be solved using their
real-valued counterparts [20]. The existence, global asymptotic
and exponential stability of equilibrium points of CVNNs have
been actively studied in the recent years [6][14][22]. On the
other hand, there are very few results on the existence, global
asymptotic and exponential stability of periodic solutions of
CVNNs [11][21]. These papers deal with delayed CVNNs,
respectively of neutral type and with impulses. In [23], suf-
ﬁcient conditions are obtained for the existence and global
asymptotic stability of periodic solutions for delayed complex-
valued simpliﬁed Cohen-Grossberg neural networks.
In our previous paper [7], we constructed a discrete-time
counterpart of a complex-valued Hopﬁeld network with time-
varying delays and impulses by using the semi-discretization
method. We found sufﬁcient conditions for the existence of
periodic solutions of the discrete-time system thus obtained by
using the continuation theorem of coincidence degree theory.
The goal of the present paper is to ﬁnd sufﬁcient conditions
for the uniqueness and global exponential stability of the
periodic solution of the aforementioned discrete-time system.
The motivation for our study was the possibility to apply
to CVNNs methods previously applied to real-valued neural
network. The exposition is self-contained: its understanding
does not require reading of [7].
The rest of the paper is organized as follows: Section II
recalls the original continuous-time neural network of [7], its
discrete-time counterpart and representation as a real-valued
discrete-time neural network of double dimension, and the
sufﬁcient conditions for the existence of periodic solutions.
In Section III, under some additional conditions including
1
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-655-2
INFOCOMP 2018 : The Eighth International Conference on Advanced Communications and Computation

time-independence of the delays, we prove the uniqueness and
global exponential stability of the periodic solution by intro-
ducing an appropriate Lyapunov functional. More precisely, it
is shown that any two solutions of the discrete-time system
exponentially approach each other. The proof is more difﬁcult
than in the case of real-valued neural networks because of the
more complicated form of the Lyapunov functional. Finally,
Section IV is Discussion, and Section V is Conclusion and
Further Work.
II. PRELIMINARIES
In [7], we consider the following impulsive neural network
with time-varying delays:
˙zi(t) = −ai(t)zi(t) +
m
X
j=1
bij(t)fj(zj(t))
+
m
X
j=1
cij(t)gj(zj(t − τij(t))) + Ii(t),
t > 0,
t ̸= tk,
(1)
∆zi(tk) = −αikzi(tk) +
m
X
j=1
βijkΦj(zj(tk))
+
m
X
j=1
γijkΓj(zj(tk − τij(tk))) + ζik,
k ∈ {0} ∪ N,
(2)
zi(s) = ϕi(s),
s ∈ [−τ, 0],
i = 1, m, (3)
where zi(t) is the complex-valued state of the i-th neuron
at time t; ai(t) is the rate with which the i-th unit resets
its potential to the equilibrium state when isolated from
the network and external inputs; fj(·), gj(·) denote complex
activation functions, respectively without and with delay; the
functions bij(t), cij(t) represent the weights (or strengths) of
the synaptic connections between the j-th neuron and the i-
th neuron, respectively without and with transmission delay
τij(t); Ii(t) denotes the complex-valued external bias on (input
signal introduced from outside the network to) the i-th unit
at time t; tk (k ∈ {0} ∪ N) are the moments (instants) of
impulse effect satisfying 0 = t0 < t1 < t2 < · · · < tk < · · ·
and
lim
k→∞tk = ∞; ∆zi(tk) := zi(tk + 0) − zi(tk − 0) ≡
zi(tk + 0) − zi(tk) represents the instantaneous change of the
state of the i-th neuron at time tk; Φj(·), Γj(·) : C → C
are some functions; αik, βijk, γijk, ζik are some complex
constants; and τ = max
i,j=1,m sup
t>0
τij(t).
We included a real-life example which is a real-valued
neural network of the form (1)–(3) (see, for instance, [1] and
[16]):
Ci ˙ui(t) = −ui(t)
Ri
+
m
X
j=1
aijfj(uj(t))
+
m
X
j=1
bij(t)gj(uj(t − τij(t))) + Ii,
t > 0, t ̸= tk,
∆ui(tk) = Jjk(ui(tk)),
k ∈ N,
ui(s) = ϕi(s),
s ∈ [−τ, 0],
i = 1, m,
where ui(t) denotes the state (voltage) of the i-th neuron
at time t, the positive constants Ci and Ri are the neuron
ampliﬁer input capacitance and resistance, respectively.
For system (1)–(3) we made the following assumptions:
[H1]
There exists a positive number ω and a positive
integer p such that
ai(t + ω) = ai(t), Ii(t + ω) = Ii(t) for
t ≥ 0 and i = 1, m,
bij(t + ω) = bij(t), cij(t + ω) = cij(t),
τij(t + ω) = τij(t) for t ≥ 0 and i, j = 1, m,
tk+p = tk + ω for k ∈ {0} ∪ N,
αi,k+p = αik, ζi,k+p = ζik for
k ∈ {0} ∪ N and i = 1, m,
βij,k+p = βijk, γij,k+p = γijk for
k ∈ {0} ∪ N and i, j = 1, m.
[H2]
The complex-valued functions ai(t), bij(t), cij(t)
are continuous on [0, ∞]; Re ai(t) > 0 for t ≥ 0
and 0 < Re αik < 1 for k ∈ {0} ∪ N, i = 1, m.
[H3]
There exist positive constants Fj, Gj , Fj, Gj (j =
1, m) such that
max{|Refj(u) − Re fj(v)|, |Im fj(u) − Im fj(v)|}
≤ Fj(|Re u − Re v| + |Im u − Im v|),
max{|Regj(u) − Re gj(v)|, |Im gj(u) − Im gj(v)|}
≤ Gj(|Re u − Re v| + |Im u − Im v|),
max{|ReΦj(u)−Re Φj(v)|, |Im Φj(u)−Im Φj(v)|}
≤ Fj(|Re u − Re v| + |Im u − Im v|),
max{|ReΓj(u) − ReΓj(v)|, |Im Γj(u) − ImΓj(v)|}
≤ Gj(|Re u − Re v| + |Im u − Im v|)
for any u, v ∈ C.
[H4]
The functions τij(t) (i, j = 1, m) are nonnegative
and continuous for t ≥ 0.
[H5]
The functions ϕi(s) (i = 1, m) are piecewise con-
tinuously differentiable on the interval [−τ, 0], with
points of possible discontinuity of the form tk − ω.
To ﬁnd an ω-periodic solution of system (1), (2) means to
determine the initial functions ϕi(s) so that the solution of the
initial-value problem (1)–(3) is ω-periodic.
In their paper [15] T. Insperger and G. St´ep´an presented an
efﬁcient numerical method for the stability analysis of linear
delayed systems. The semi-discretization method is based on
discretization with respect to the past effect only. It was shown
that the semi-discretization method is much more effective
than the full discretization for the stability analysis. The semi-
discretization does not preserve the solutions of the original
system. However, it does preserve their exponential stability
if the semi-discretization is ﬁne enough in some sense.
2
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-655-2
INFOCOMP 2018 : The Eighth International Conference on Advanced Communications and Computation

A modiﬁcation of the semi-discretization method was used
for the stability analysis of neural networks by S. Mohamad
and K. Gopalsamy in [19] and numerous subsequent papers
of the same authors. In particular, it can be applied to not
necessarily linear neural networks if the nonlinearities satisfy
certain conditions.
Similarly to our previous papers [2][3][4], next we derived
a discrete counterpart of system (1)–(3) using a modiﬁcation
of the semi-discretization method and obtained sufﬁcient con-
ditions for the existence of periodic solutions of the latter.
For the sake of deﬁniteness we assumed that τ ≤ ω. For a
positive integer N we chose the discretization step h = ω/N.
For the moment we assume N so large that h < min
k=1,p(tk+1 −
tk). Then each interval [nh, (n + 1)h] contains at most one
instant of impulse effect tk.
For convenience we denoted n = [t/h], the greatest integer
in t/h, nk = [tk/h], and N0 = [τ/h].
Omitting the details, we present the derived discrete-time
counterpart of system (1)–(3):
∆zi(n) = −Ai(n)zi(n) + Ii(n)
+















m
P
j=1
bij(n)fj(zj(n)) +
m
P
j=1
cij(n)gj(zj(n − τij(n))),
n ̸= nk,
m
P
j=1
βijkΦj(zj(nk)) +
m
P
j=1
γijkΓj(zj(nk − τij(nk))),
n = nk,
(4)
n ∈ {0} ∪ N,
zi(s) = ϕi(s) for
s = 0, −1, . . ., −N0,
i = 1, m, (5)
where zi(n) is the complex-valued state of the i-th neuron
at time nh (n ∈ Z, n ≥ −N0; Ai(n) is a complex-valued
function with a positive real part; nk (k ∈ {0} ∪ N) are
integers satisfying 0 = n0 < n1 < n2 < · · · < nk < · · · and
lim
k→∞nk = ∞; ∆zi(n) := zi(n + 1) − zi(n); Φj(·), Γj(·) :
C → C are some functions; αik, βijk, γijk, ζik are some
complex constants; ϕ(s)
=
(ϕ1(s), ϕ2(s), . . . , ϕm(s))T ,
s = 0, −1, . . ., −N0, are given initial vectors, and N0 =
max
i,j=1,m sup
n≥0
τij(n).
From the assumptions H1, H2, H4, it follows that
[H6]
There exist positive integers N and p such that
Ai(n + N) = Ai(n), Ii(n + N) = Ii(n) for
i = 1, m,
n ∈ {0} ∪ N,
τij(n + N) = τij(n) for i, j = 1, m, n ∈ {0} ∪ N,
bij(n + N) = bij(n), cij(n + N) = cij(n) for
i, j = 1, m,
n ∈ N \ {nk}k∈N,
nk+p = nk + N for k ∈ {0} ∪ N,
βij,k+p = βijk, γij,k+p = γijk for
k ∈ {0} ∪ N
and
i, j = 1, m.
[H7]
0 < Re Ai(n) < 1 for i = 1, m, n ∈ IN :=
{0, 1, . . ., N − 1}.
To ﬁnd an N-periodic solution of system (4) means to
determine the initial vectors ϕi(s) so that the solution of the
initial-value problem (4), (5) is N-periodic. For the sake of
deﬁniteness, we assume that N0 ≤ N.
In order to formulate the main result of [7], we introduced
the following notation:
For an N-periodic sequence v(n), we denote ˜v =
N−1
P
n=0
v(n)
(if v(n) is given by a long formula, we write v˜or (v)˜ instead);
bij = max{ sup
n̸=nk
|Re bij(n)|, sup
n̸=nk
|Im bij(n)|},
cij = max{ sup
n̸=nk
|Re cij(n)|, sup
n̸=nk
|Im cij(n)|},
βij = max{max
k=1,p|Reβijk|, max
k=1,p|Im βijk|},
γij = max{max
k=1,p|Reγijk|, max
k=1,p|Im γijk|},
i, j = 1, m;
ρi = (N − p)
m
X
j=1
bij(|Re fj(0)| + |Im fj(0)|)
+ cij(|Re gj(0)| + |Im gj(0)|)]
+p
m
X
j=1

βij(|ReΦj(0)| + |Im Φj(0)|)
+ γij(|Re Γj(0)| + |Im Γj(0)|) ,
i = 1, m;
Bij = 2[(N − p)(bijFj + cijGj) + p(βijFj + γijGj)],
i, j = 1, m.
Next, we introduced the condition
[H8]
min
i=1,m

^
Re Ai − |Im Ai|˜−
m
X
j=1
Bji

 > 0.
We introduce the m × m matrices
˜
AR = diag
 
^
ReAi
1 − ^
Re Ai
1 + ^
Re Ai
, i = 1, m
!
,
˜
AI = diag

∆xi(n) = −Re Ai(n)xi(n) + Im Ai(n)yi(n) + Re Ii(n)
+



























m
P
j=1
[Re bij(n)Re fj(zj(n)) − Im bij(n)Im fj(zj(n))
+ Re cij(n)Re gj(zj(n − τij(n)))
− Im cij(n)Im gj(zj(n − τij(n)))] ,
n ̸= nk;
m
P
j=1
[Re βijkRe Φj(zj(nk)) − Im βijkIm Φj(zj(nk))
+ Re γijkRe Γj(zj(nk − τij(nk)))
− Im γijkIm Γj(zj(nk − τij(nk)))] ,
n = nk,
(6)
∆yi(n) = −Re Ai(n)yi(n) − Im Ai(n)xi(n) + Im Ii(n)
+



























m
P
j=1
[Re bij(n)Im fj(zj(n)) + Im bij(n)Re fj(zj(n))
+ Re cij(n)Im gj(zj(n − τi−m,j(n)))
+ Im cij(n)Re gj(zj(n − τi−m,j(n)))] , n ̸= nk;
m
P
j=1
[Re βijkIm Φj(zj(nk)) + Im βijkRe Φj(zj(nk))
+ Re γijkIm Γj(zj(nk − τi−m,j(nk)))
+ Im γijkRe Γj(zj(nk − τi−m,j(nk)))] , n = nk,
(7)
for i = 1, m.
In the next section, under some additional assumptions,
we prove the global exponential stability of any N-periodic
solution of system (4).
III. MAIN RESULT
Let us denote
Bij = 2 max(bijFj, βijFj),
Cij = 2 max(cijGj, γijGj).
(8)
Next, we introduce the conditions
[H10] The delays τij (0 ≤ τij ≤ N0) are independent of n.
[H11] The inequalities
Re Ai(n) − |Im Ai(n)| −
m
X
j=1
(Bji + Cji) > 0
are satisﬁed for all n ∈ IN and i = 1, m.
It is easy to see that condition H11 implies H8.
Our main result is the following theorem.
Theorem 2: Let conditions H3, H6, H7, H10, H11 hold.
Let z∗(n) = (x∗(n), y∗(n))T be an N-periodic solution of
system (4). Then there exist constants M > 1 and λ > 1 such
that for any λ ∈ (1, λ] and for any other solution z(n) =
(x(n), y(n))T of system (4) deﬁned at least for n ≥ −N0 the
following estimate holds
m
X
i=1
(|xi(n) − x∗
i (n)| + |yi(n) − y∗
i (n)|)
(9)
≤ Mλ−n
m
X
i=1
max
−N0≤s≤0(|xi(s) − x∗
i (s)| + |yi(s) − y∗
i (s)|)
for all n ∈ {0} ∪ N.
In the proof of the theorem, we use the following lemma.
Lemma 1: Let condition H11 hold. Then there exists a
constant λ > 1 such that for any λ ∈ (1, λ]
λ

1 − Re Ai(n) + |Im Ai(n)| +
m
X
j=1
Bji


+
m
X
j=1
Cjiλ1+τji − 1 ≤ 0
for all n ∈ IN and i = 1, m.
Proof: Consider the functions
χi(n, λ) :=λ

1 − Re Ai(n) + |Im Ai(n)| +
m
X
j=1
Bji


+
m
X
j=1
Cjiλ1+τji − 1,
n ∈ IN, i = 1, m.
For each n ∈ IN and i = 1, m, χi(n, λ) is a continuous
function of λ ∈ [1, ∞) such that
χi(n, 1) = −

Re Ai(n) − |Im Ai(n)| −
m
X
j=1
(Bji + Cji)

< 0
by virtue of condition H11, and lim
λ→∞ χi(n, λ) = +∞. Then
there exists λin > 1 such that χi(n, λin) = 0 and χi(n, λ) ≤ 0
for λ ∈ (0, λi,n]. It sufﬁces to choose λ = max{λin| i =
1, m, n ∈ IN}.
Proof of Theorem 2: Let z∗(n) and z(n) be as in the
statement of Theorem 2. Our goal will be to construct a
Lyapunov functional V (n) of the difference z(n) − z∗(n),
which is decreasing with respect to n ∈ {0} ∪ N. First, we
denote
X(n) := x(n) − x∗(n),
Y (n) := y(n) − y∗(n).
Then, from (6) for n ∈ {0} ∪ N, n ̸= nk, we have
Xi(n + 1) = (1 − Re Ai(n))Xi(n) + Im Ai(n)Yi(n)
+
m
X
j=1
Re bij(n)[Refj(zj(n)) − Re fj(z∗
j (n))]
− Im bij(n)[Im fj(zj(n)) − Im fj(z∗
j (n))]
	
+
m
X
j=1

Re cij(n)[Re gj(zj(n − τij)) − Re gj(z∗
j (n − τij))]
− Im cij(n)[Im gj(zj(n − τij)) − Im gj(z∗
j (n − τij))]
	
and, by virtue of H3, we derive
|Xi(n + 1)|
≤ (1 − ReAi(n))|Xi(n)| + |Im Ai(n)| |Yi(n)|
+
m
X
j=1
2bijFj(|Xj(n)| + |Yj(n)|)
+
m
X
j=1
2cijGj(|Xj(n − τij)| + |Yj(n − τij)|).
(10)
4
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-655-2
INFOCOMP 2018 : The Eighth International Conference on Advanced Communications and Computation

In a similar way, we obtain
|Xi(nk + 1)|
≤ (1 − Re Ai(nk))|Xi(nk)| + |Im Ai(nk)| |Yi(nk)|
+
m
X
j=1
2βijFj(|Xj(nk)| + |Yj(nk)|)
+
m
X
j=1
2γijGj(|Xj(nk − τij)| + |Yj(nk − τij)|).
(11)
Using the notation (8), inequalities (10) and (11) can be written
by one formula as
|Xi(n + 1)|
≤ (1 − Re Ai(n))|Xi(n)| + |Im Ai(n)| |Yi(n)|
+
m
X
j=1
Bij(|Xj(n)| + |Yj(n)|)
+
m
X
j=1
Cij(|Xj(n − τij)| + |Yj(n − τij)|)
(12)
for all n ∈ {0} ∪ N.
Similarly, from (7) we derive
|Yi(n + 1)|
≤ (1 − Re Ai(n))|Yi(n)| + |Im Ai(n)| |Xi(n)|
+
m
X
j=1
Bij(|Xj(n)| + |Yj(n)|)
+
m
X
j=1
Cij(|Xj(n − τij)| + |Yj(n − τij)|)
(13)
for all n ∈ {0} ∪ N.
Next, we deﬁne the quantities
Wi(x) = λn|Xi(n)|,
Ψi(n) = λn|Yi(n)|
for λ ∈ (1, λ], n ≥ −N0 and i = 1, m. Then, in view of (12)
and (13), we obtain
Wi(n + 1)
≤ λ(1 − Re Ai(n))Wi(n) + λ|Im Ai(n)|Ψi(n)
+λ
m
X
j=1
Bij(Wj(n) + Ψj(n))
+
m
X
j=1
Cijλ1+τij[Wj(n − τij) + Ψj(n − τij)],
(14)
Ψi(n + 1)
≤λ(1 − Re Ai(n))Ψi(n) + λ|Im Ai(n)|Wi(n)
+λ
m
X
j=1
Bij(Wj(n) + Ψj(n))
+
m
X
j=1
Cijλ1+τij[Wj(n − τij) + Ψj(n − τij)].
(15)
Inequalities (14), (15) suggest us to deﬁne the Lyapunov
functional
V (n) =
m
X
i=1
"
Wj(n) + Ψj(n)
+
m
X
j=1
Cijλ1+τij
n−1
X
s=n−τij
(Wj(s) + Ψj(s))


for all n ∈ {0} ∪ N. Then, we have
V (n + 1) =
m
X
i=1
"
Wj(n + 1) + Ψj(n + 1)
+
m
X
j=1
Cijλ1+τij
n
X
s=n+1−τij
(Wj(s) + Ψj(s))


≤
m
X
i=1
(
λ
"
(1 − Re Ai(n) + |Im Ai(n)|)(Wi(n) + Ψi(n))
+
m
X
j=1
Bij(Wj(n) + Ψj(n))


+
m
X
j=1
Cijλ1+τij
n
X
s=n−τij
(Wj(s) + Ψj(s))



and
∆V (n) ≤
m
X
i=1


λ

1 − Re Ai(n) + |Im Ai(n)| +
m
X
j=1
Bji


+
m
X
j=1
Cjiλ1+τji − 1


(Wi(n) + Ψi(n))
=
m
X
i=1
χi(n, λ)(Wi(n) + Ψi(n)) ≤ 0
in view of Lemma 1. This means that V (n + 1) ≤ V (n) for
all n ∈ {0} ∪ N. In particular,
V (n) ≤ V (0)
for all n ∈ {0} ∪ N and λ ∈ (1, λ].
Taking into account that
V (n) ≥ λn
m
X
i=1
(|xi(n) − x∗
i (n)| + |yi(n) − y∗
i (n)|)
and
V (0) =
m
X
i=1
[|xi(0) − x∗
i (0)| + |yi(0) − y∗
i (0)|
+
m
X
j=1
Cjiλ1+τji
−1
X
s=−τji
(|xi(s) − x∗
i (s)| + |yi(s) − y∗
i (s)|)


≤ max
i=1,m

1 + λ
1+N0
m
X
j=1
Cji


×
m
X
i=1
max
−N0≤s≤0(|xi(s) − x∗
i (s)| + |yi(s) − y∗
i (s)|),
5
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-655-2
INFOCOMP 2018 : The Eighth International Conference on Advanced Communications and Computation

we derive the estimate (9) with
M = max
i=1,m

1 + λ
1+N0
m
X
j=1
Cji

 .
The proof of this estimate did not use the assumption that
the solution z∗(n) is N-periodic. In fact, it shows that system
(4) can have at most one N-periodic solution and such a
solution is globally exponentially stable.
IV. DISCUSSION
Our previous experience with papers devoted to neural
networks has shown us that most of these papers can be
assigned to one of two quite distinct classes — theoretical
and applied (practical).
The papers of the ﬁrst class usually list some real-life appli-
cations in their introductions. These applications are normally
taken from surveys on neural networks or the introductions
of other papers of the same class. Then, the authors study a
mathematical model, which is usually a far-going generaliza-
tion of an application of neural networks to a real-life problem.
The properties of the mathematical model are examined using
methods, often much more complicated than in the present
paper. Finally, a few examples of low-dimensional neural
networks satisfying the conditions obtained may be given, and
some computations may be carried out. However, applications
of the results obtained to real-life problems are very seldom
given.
The papers of the second class are usually devoted to a quite
concrete real-life problem, say, the identiﬁcation of people by
their ﬁngerprints. Experimental data are usually given, but very
little mathematics is used and models to be studied by papers
of the ﬁrst class are seldom given.
The present paper, as well as our previous papers devoted
to neural networks, belong to the ﬁrst class. So it is not easy
to give applications to real-life problems.
To the best of our knowledge, the above mentioned two
classes of papers grow (maybe exponentially) quite indepen-
dently of each other. We hope that a cooperation between
“theoreticians” and “practicians” could prove fruitful for both
trends.
V. CONCLUSION AND FUTURE WORK
In the present paper, we obtained sufﬁcient conditions for
any two solutions of a discrete-time complex-valued Hopﬁeld
neural network with delays and impulses to inﬁnitely approach
each other with time. The proof was accomplished by con-
structing an appropriate Lyapunov functional. The result ob-
tained implies the uniqueness and global exponential stability
of a periodic solution, provided that it exists.
In future, in the theoretical aspect, we can extend our
research to quaternionic neural networks, which are a general-
ization of CVNNs. On the other hand, in case of an available
“practician” as a co-author, we can concentrate on ﬁnding real-
life examples and applications of the CVNNs considered in the
present paper and the results obtained.
REFERENCES
[1] H. Akc¸a, R. Alassar, and V. Covachev, “Stability of neural networks
with time varying delays in the presence of impulses,” Adv. Dyn. Syst.
Appl., vol. 1, no. 1, pp. 1–15, 2006.
[2] H. Akc¸a, R. Alassar, V. Covachev, and Z. Covacheva, “Discrete coun-
terparts of continuous-time additive Hopﬁeld-type neural networks with
impulses,” Dyn. Syst. Appl., vol. 13, no. 1, pp. 77–92, 2004.
[3] H. Akc¸a, E. Al-Zahrani, V. Covachev, and Z. Covacheva, “Existence
of periodic solutions for the discrete-time counterpart of a neutral-type
cellular neural network with time-varying delays and impulses,” Int. J.
Appl. Math. Stat., vol. 57, no. 1, pp. 154–166, 2018.
[4] H. Akc¸a, V. Covachev, Z. Covacheva, and S. Mohamad, “Global expo-
nential periodicity for the discrete analogue of an impulsive Hopﬁeld
neural network with ﬁnite distributed delays,” Funct. Differ. Equ.,
vol. 16, no. 1, pp. 53–72, 2009.
[5] A. Berman and R. J. Plemmons, Nonnegative Matrices in Mathematical
Sciences,
New York: Academic Press, 1979.
[6] M. Bohner, S. H. Rao, and S. Sanyal, “Global stability of complex-
valued neural networks on time scales,” Differ. Equ. Dyn. Syst., vol. 19,
no. 1–2, pp. 3–11, 2011.
[7] V. Covachev and Z. Covacheva, “Existence of periodic solutions for the
discrete-time counterpart of a complex-valued Hopﬁeld neural network
with time-varying delays and impulses,” accepted to IJCNN 2018, Rio
de Janeiro.
[8] M. Fiedler, Special Matrices and Their Applications in Numerical
Mathematics,
Dordrecht: Martinus Nijhoff, 1986.
[9] R. E. Gaines and J. L. Mawhin, Coincidence Degree and Nonlinear
Differential Equations,
Berlin-Heidelberg: Springer-Verlag, 1977.
[10] A. I. Galushkin, Neural Networks Theory,
Berlin-Heidelberg: Springer-
Verlag, 2007.
[11] S. Guo and B. Du, “Global exponential stability of periodic solution for
neutral-type complex-valued recurrent neural networks,” Discrete Dyn.
Nat. Soc., vol. 2016, Article ID 1267954, 10 pp., 2016.
[12] J. Heaton, Introduction to the Math of Neural Networks,
Heaton
Research, ISBN: 9781604390339, 2011.
[13] A. Hirose (Ed.), Complex-Valued Neural Networks: Advances and Ap-
plications,
Wiley-IEEE Press, 2013.
[14] J. Hu and J. Wang, “Global stability of complex-valued recurrent neural
networks with time-delays,” IEEE Trans. Neural Netw. Learn. Syst.,
vol. 23, no. 6, pp. 853–865, 2012.
[15] T. Insperger and G. St´ep´an, “Semi-discretization method for delayed
systems,” Int. J. Numer. Math. Engng., vol. 55, pp. 503–518, 2002.
[16] Y. Li and M. Hua, “The stability analysis for a kind of impulsive
Hopﬁeld cellular neural networks,” 3rd International Conference on
Mechatronics,Robotics and Automation (ICMRA 2015),
Atlantic Press,
4 p., 2015.
[17] Y. Li, L. Zhao, and X. Chen, “Existence of periodic solutions for neural
type cellular neural networks with delays,” Appl. Math. Model., vol. 36,
no. 3, pp. 1173–1183, 2012.
[18] G. Meinardus and G. Nurnberger (Eds.), Delay Equations, Approxima-
tion and Application,
Boston: Birkh¨auser, 1985.
[19] S. Mohamad and K. Gopalsamy, “Dynamics of a class of discrete-time
neural networks and their continuous-time counterparts,” Math. Comput.
Simulation, vol. 53, pp. 1–39, 2000.
[20] T. Nitta, “Solving the XOR problem and the detections of symmetry
using a single complex-valued neuron,” Neural Netw., vol. 16, no. 8,
pp. 1101–1105, 2003.
[21] D. Xie and Y. P. Jiang, “Global exponential stability of periodic
solutions for delayed complex-valued neural networks with impulses,”
Neurocomputing, vol. 207, pp. 528–538, 2016.
[22] Y. Zhang and C. Lin, “Global stability criterion for delayed complex-
valued recurrent neural networks,” IEEE Trans. Neural Netw. Learn.
Syst., vol. 25, no. 9, pp. 1704–1708, 2014.
[23] Z. Zhang and T. Zheng, “Global asymptotic stability of periodic solu-
tions for delayed complex-valued Cohen-Grossberg neural networks by
combining coincidence degree theory with LMI method,” Neurocomput-
ing, vol. 289, pp. 220–230, 2018.
6
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-655-2
INFOCOMP 2018 : The Eighth International Conference on Advanced Communications and Computation

