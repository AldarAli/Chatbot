On Biometric Verification of a User by Means of Eye Movement Data Mining 
 
Youming Zhang and Martti Juhola 
Computer Science, School of Information Sciences 
33014 University of Tampere  
Tampere, Finland 
Youming.Zhang@uta.fi, Martti.Juhola@sis.uta.fi 
 
 
 
Abstract—In biometric verification, a signal, image or other 
dataset is measured from a subject to detect him or her to be 
or not to be an authenticated subject such as the user of a 
computer. So far, biometric verification has mainly been on the 
basis of fingerprints or face images, infrequently other images, 
e.g., iris. We studied the idea to apply fast eye movements 
called saccades to verify an authenticated user from among 
other subjects. We recorded eye movement signals with eye 
movement cameras using a suitable visual stimulation for a 
subject. By means of machine learning methods, we classified a 
subject’s eye movements to verify whether one was an 
authenticated user.  We employed multilayer perceptron 
networks, radial basis function networks, support vector 
machines and logistic discriminant analysis for classification. 
The best accuracy results obtained were approximately 90% 
and showed that it is possible to verify a subject according to 
saccade eye movements. 
Keywords-biometric verification; eye movements; saccades; 
multilayer percetron neural networks; radial basis function 
networks; support vector machines; logistic discriminant analysis 
I. 
 INTRODUCTION 
So far, various biometric data sources have been used to 
verify a subject. Mostly fingerprints [1, 2] and face images [3] 
are applied to this task. Other images measured from subjects 
such as iris images [2, 4] are also studied. In addition to these 
two-dimensional data sources, one-dimensional signals are 
also used, e.g., voice signals [5]. Usually, these datasets 
contain an abundance of data and several variables are 
computed from them to ground the verification procedure on 
variable values of different subjects. Data mining tasks 
needed here may be complicated because of complex data. 
Eye movements are a new potential alternative for 
biometric verification. Eye movements have been researched 
for decades in medicine. During the past 15 years eye 
movements have become an important research objective for 
human-computer interfaces. Along with these applications 
efficient eye movement cameras have been developed. Since 
there is long-term experience in the signal analysis of eye 
movements, for example [6-8], for biomedical and 
physiological applications, it was a direct development to 
attempt to utilize them for biometric verification of a subject 
simulating a computer user. Note that verification 
corresponds to the binary classification between two classes: 
an authenticated user and other subjects. 
There are a few different eye movement types such as 
saccade, nystagmus, smooth pursuit and vestibulo-ocular 
reflex eye movements [7]. Probably the most frequent of all 
are saccades which are made while looking at surroundings 
or reading a text. In addition, they are very fast, in fact the 
fastest movements of man. They are easy to visually 
stimulate and their recording does not require more time than 
a few minutes for our tests. Those other eye movement types 
would require longer recordings or more complicated 
stimulation arrangements [7]. For these reasons, we chose 
saccades to be our data sources here, particularly after 
observing differences between saccades of individuals [7]. 
Up to now, a couple of attempts only have been 
published about this idea to use eye movements for biometric 
verification. In one research [8] they recorded saccade eye 
movement signals to compute cepstrum from these and 
classified signal analysis outcomes by using naïve Bayesian 
method, nearest neighbour searching, decision trees as well 
as support vector machines. In another research [9] they used 
a computational oculomotor model on the parameters of 
which verification was based using nearest neighbour 
searching and decision trees. Our approach differs from 
those since we use physiological variables computed from 
eye movement signals. Most of these variables have been 
employed for long in biomedical investigations [6,7]. 
II. 
EYE MOVEMENT DATA 
We recorded saccade eye movements with a two-camera 
system (Visual Eyes, Micromedical Technologies, UK). Its 
resolution is 320×240 and sampling frequency or frames per 
second 30 Hz. The camera system recognized positions of 
each pupil from successive images of a video stream to 
detect eye movements. The system records horizontal and 
vertical signals, but we used the horizontal direction only. 
We wanted to keep the arrangement as simple as possible for 
stimulation design so that this was simple for a subject in 
order to avoid complex stimulations. Furthermore, using 
simple stimulations means that long recordings are not 
necessary which is important to see this biometric 
verification idea as sensible. On the other hand, the more 
data from each individual, the easier it is perhaps to separate 
him or her from the group of other subjects. The sampling 
frequency of 30 Hz was low compared to other typical ones 
used in eye movement camera systems such as 50 or 60 Hz, 
occasionally even higher like 200 Hz. Nevertheless, it was 
85
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

interesting to see whether this low sampling frequency 
allowed verification. Perhaps using a higher frequency in the 
future could only better results because of more accurate 
variable values to be computed. The system included one 
camera for each eye embedded in the mask attached tightly 
with a headband. The one of lower noise level of two eye 
movement signals was used for verification. Usually, both 
are almost identical. 
We used the same stimulation series for every subject. 
This is, of course, the essential detail for biometric 
verification so that we can assume that every subject has 
followed the same stimulation by his or her gaze and we can 
classify them according to their eye movements. Each 
subject saw a horizontally jumping LED light dot in front of 
him or her. The stimulation component of the eye movement 
recording system included a horizontal LED bar in which 
one LED was switched on for a while, then switched off and 
another switched on immediately, and so on, by varying the 
LED to be next switched on. This way different gaze angles 
were formed. Intervals between light dot jumps were varying 
to make them random for a watching subject. Since intervals 
of 1-3 s were short and varying, the spectator could learn 
neither them nor varying stimulation angles. Varying, 
“random” intervals are important to minimize anticipations 
of a subject while waiting for the next stimulation movement. 
Anticipation would occur if latency or reaction time from the 
beginning of a stimulation movement to the beginning of its 
response, saccade, were shorter than 0.120 s seen as a 
minimum latency in the physiological sense [7].  It takes 
some time for the brain to observe a movement and control 
the response to move the eyes. 
The present stimulation arrangement was used to 
simulate the beginning of a computer session where a user 
would first sit down to start the machine and to wait for its 
initialization. We can imagine that the eye movement 
stimulation would be run immediately after the initialization 
by stimulating a subject with a few dozen stimulation 
movements on the screen of a computer or mobile device. 
Thereafter, the verification procedure would be run. 
We used saccades with the largest stimulation amplitudes 
of around 48º only since saccades of such large amplitudes 
contain greater differences between subjects than those with 
small amplitudes [7]. Great differences between subjects aid 
in verification. Nonetheless, there were smaller stimulation 
angles between large to give a random character between 
stimulations from a spectator’s viewpoint. Consequently, we 
obtained 20 large amplitude saccades from every subject. 
Values of saccade variables depend on saccade amplitudes. 
Thus, we used merely the saccades of the largest stimulation 
amplitude, 
For the sake of the low sampling frequency of 30 Hz, we 
interpolated every signal with a cubic spline method up to 
1000 Hz. The purpose here was to simulate a sampling 
frequency of the newest, expensive high resolution eye 
movement cameras and, most of all, to estimate values of 
eye movement variables more precisely than enabled by the 
original signals sampled at 30 Hz. 
 
 
 
 
 
(a) 
 
 
 
 
 
 
 
 
 
(b)  
 
(c) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1.  (a) The step (broken line) is a stimulation movement produced 
by a horizontally jumping light dot from the left (down in the figure) to the 
right (up). A saccade as a response follows it after a latency. The difference 
between amplitudes determines a negative accuracy, because the saccade 
amplitude is smaller here. A positive accuracy is also possible, but is more 
infrequent than negative. In our tests these values were used as absolute. 
Accuracy, amplitude and latency were three variables used. (b) From the 
saccade signal the first derivative approximation of the velocity curve is 
computed from which (c) the second derivation of the acceleration curve is 
approximated. The maximum velocity, maximum acceleration and 
maximum deceleration were other three useful variables to be computed. 
III. 
SIGNAL ANALYSIS AND DATA PREPROCESSING 
Fig. 1 depicts an ideal saccade and its stimulation as a 
schema. The first signal analysis task is to detect the exact 
beginning and end of every stimulation movement and those 
of the following response eye movement, saccade. 
stimulation 
time [s] 
accuracy 
saccade 
amplitude 
stimulation 
amplitude 
 saccade end 
saccade 
beginning 
amplitude 
[°] 
 
[°] 
latency 
angular 
velocity 
[°/s] 
maximum 
velocity  
angular 
acceleration 
[°/s2] 
maximum 
acceleration 
maximum 
deceleration 
time [s] 
86
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

 
Figure 2.  A smooth  (green) stimulation signal of 64 s sampled at 30 Hz and its (blue) response with saccades.
The former is easy to detect since it is a clear step in a 
signal. The latter may rarely be somewhat corrupted by noise 
or artifacts such as blinks; See Fig. 2, including horizontal 
saccades. 
If a saccade is inaccurate, its amplitude clearly differs 
from that of its stimulation. The brain can rapidly produce a 
corrective saccade with a small amplitude to correct the gaze 
closer to the objective. One cannot sense this correction 
movement, but it is “automatic”. We did not include possible, 
quite infrequent corrective saccades, but determined the 
accuracy of a saccade along with the primary saccade as 
usual. A response to its stimulation movement had to 
resemble a real saccade sufficiently to be accepted for further 
use in signal analysis. In principle a subject might not 
occasionally follow the target with the gaze. This would 
yield no saccade at all. Anticipation as a too early eye 
movement including a latency value less than 0.120 s or even 
a saccade before a stimulation would be rejected as no actual 
responses to stimulations. The quality of signals given by the 
camera system was high with low noise. Thus, rejections of 
eye movements from signals were infrequent, no more than a 
few per cent of all saccades.  
The same stimulation movements (Fig. 2) were run for 
every recording, so that eye movements of subjects were 
comparable with each other. A stimulation series included 
four stimulations with the largest amplitude of 48º. Five 
recordings were run successively from every subject giving 
20 large saccades for a subject. 
The five recordings of each subject formed our data for 
biometric verification tests. The stimulation series also 
contained saccades of smaller amplitudes between those four 
large to make the stimulation series more random-like for a 
subject not able to guess the direction or amplitude of a 
stimulation movement or an interval between two successive 
stimulations. Intervals were 1-3 s within a recording of 64 s.  
After the interpolation of signals, the first derivative and 
second derivative were computed with approximation 
formulas such as two-point central difference differentiation 
[8] from each eye movement signal. A saccade beginning 
was found provided that absolute velocity values rapidly 
increased above a threshold of 50º/s and the corresponding 
saccade end was found when velocity decreased back below 
that threshold. After detecting a saccade and ensuring that it 
was valid according to latency criterion, etc., all its variable 
values were computed and stored: amplitude, accuracy, 
latency and maximum velocity, acceleration and deceleration. 
During recordings, a sitting, alert, relaxed subject was 
asked to follow the stimulation light dot by the gaze. In all, 
we recorded five successive recordings from healthy 132 
subjects from whom 33 were females and 99 males. Mean 
and standard deviation of their ages were 26.2±7.2 years. 
Neither alcohol nor medications were used during 24 h 
before a measurement. We wanted to test mainly young 
subjects in a pretty homogeneous dataset to create a strict 
testing basis. Age, alcohol or medications may have 
influence on values of saccade variables. Means and standard 
deviations were the following: amplitude 48.0±13.4º, 
accuracy 3.2±8.4º, latency 0.269±0.057 s, maximum velocity 
1038±322 º/s, maximum acceleration 47591±23166 º/s2 and 
maximum deceleration 44845±24745 º/s2.  
IV. 
VERIFICATION PROCEDURE 
In biometric or whatever user verification, we have to 
prepare two opposite conditions: a subject attempting to log 
in is either authenticated user or impostor. Thus, we built our 
test procedure to take these two conditions into account. 
87
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

When machine learning algorithms are used, we have to 
construct a training set and its corresponding test set. The 
content of these two sets are varied on the basis of available 
data. In the current case, our eye movement data were quite 
limited. Although there were several subjects, the bottle neck 
for tests was the small number 20 of saccades of the largest 
amplitude. Therefore, we implemented two experimental test 
settings called Alternatives 1 and 2. In the one of them for 
every subject there were either three recordings (12 saccades) 
in a training set and the rest of two recordings (q=8 saccades) 
in the corresponding test set. In the other there were four 
recordings (16 saccades) in a training set and one recording 
(q=4 saccades) in its test set. Since from every subject there 
were five recordings all in all, we obtained c=10 different 
combinations of a training set and a test set from five 
recordings for the former 
Alternative 1 and c=5 
combinations for the latter Alternative 2. These were 
prepared for every of n=132 subjects. Our aim was to test 
our data as broadly as possible as conventional while 
applying data mining methods for classification. 
Our verification task (Fig. 3) comprised two classes. 
Therefore, it was best that the number of saccades of an 
authenticated user and that of other subjects now called 
nonusers were not very imbalanced. We had either m=12 
(Alternative 1) or m=16 (Alternative 2) saccades of an 
authenticated user in a training set. We then took one 
saccade randomly from either 2m=24 or 32 nonusers to test 
Condition 1 (an authenticated user) and, in addition, still one 
saccade to represent an impostor from q=8 or 4 other random 
subjects. Nonusers and impostors were naturally represented 
by different random subjects from among n-1=131 subjects 
(an authenticated user excluded). At first, we implemented 
tests with this approach since we may assume that randomly 
selected subjects represent a more extensive area in the 
variable space than one authenticated. Nonetheless, we 
noticed that better results could be obtained by once copying 
the saccades of an authenticated user to balance the class size 
of an authenticated user’s class and that of nonusers to be 
equal 2m. Copying once m saccades of the former increased 
the density of these saccades in a dataset. 
In the verification procedure, the following symbols are 
also employed. All tests were repeated r=10 times since 
there were random choices of saccades of nonusers and 
impostors and also random initializations, among others, in 
multilayer perceptron networks. To test the remaining q 
saccades were taken to a test set where q was equal to 8 
(Alternative 1) or 4 (Alternative 2). Symbols TP and FN 
equal the numbers of true positive and false negative 
decisions in classifications and FP and TN those of false 
positive and true negative decisions. On the basis of the two 
former, a decision for a subject is made whether a test 
subject 
is 
an 
authenticated 
user 
(Condition 
1). 
Correspondingly, the two latter are used for a decision 
whether a test subject is an impostor (Condition 2). 
 
C11=C21=C12=C22=0; % counters for correct classifications 
of authenticated users and those of impostors 
 
For h=1:r  % iterations of the main loop 
 
For i=1:n % one by one as an authenticated user 
TP2=TN2=FP2=FN2=0 (Alternative 2); 
       For j=1:c % c combinations of recordings 
Take m saccades from 3 (Alternative 1) or 
4 (Alternative 2) recordings of an 
authenticated user to a training set; 
Copy these m saccades in the training set; 
Take randomly 2m nonusers and one 
saccade from each and add these saccades 
to a training set; 
Train a model with 4m saccades of two 
classes: an authenticated user and nonusers; 
TP1=TN1=FP1=FN1=0 (Alternative 1); 
For j=1:q % tests of Condition 1 
Classify a test saccade of an 
authenticated user into either 
correct class 
TP=TP+1 
 or incorrect class 
FN=FN+1; 
End 
For k=1:q % tests of Condition 2 
Classify a test saccade of an 
impostor into either correct class 
TN=TN+1 
or incorrect class 
FP=FP+1; 
 
 
End 
 
 
% Follow majority vote for decision 
 
           If TP1≥FN1 then C11=C11+1 (Alternative 1); 
 
           If TN1>FP1 then C21=C21+1 (Alternative 1); 
 
       End 
 
       % Follow majority vote for decision 
If TP2≥FN2 then C12=C12+1 (Alternative 2); 
If TN2>FP2 then C22=C22+1 (Alternative 2); 
 
End 
End 
(Alternative 1) 
Accuracy of authenticated users=100 % ∙ C11/(r∙n∙c)  
Accuracy of impostors=100 % ∙ C21/(r∙n∙c) 
(Alternative 2) 
Accuracy of authenticated users=100 % ∙ C12/(r∙n) 
Accuracy of impostors=100 % ∙ C22/(r∙n) 
 
Figure 3.  Verification procedure for authenticated users (Condition 1) and 
impostors (Condition 2). Two different test settings are called Alternatives 
1 and 2. 
V. 
CLASSIFICATION RESULTS AND DISCUSSION 
The main data mining task was to classify test saccades 
into two classes: an authenticated user or nonusers. There 
were n=132 subjects and r=10 main iterations in the 
verification 
procedure 
yielding 
13200 
decisions 
in 
Alternative 1 and 1320 decisions in Alternative 2. 
 
 
88
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

TABLE I.  
CLASSIFICATION ACCURACIES OF MLP NETWORKS 
WITHOUT NORMALIZATION: MEANS AND STANDARD DEVIATIONS IN 
PERCENTS (ON EQUALS THE NUMBER OF OUTPUT NODES AND C CONDITIONS 
1 AND 2) 
Accuracies for two test alternatives, output node numbers  ON and 
conditions C 
Alter-
native 
ON 
C 
Number of hidden nodes 
 
 
 
4 
6 
8 
10 
1 
1 
1 
71.8±0.8 
70.8±0.9 
71.0±1.6 
70.4±0.8 
1 
1 
2 
64.9±0.7 
65.2±1.8 
66.5±1.4 
66.4±0.9 
1 
2 
1 
72.1±1.2 
71.8±1.3 
72.2±0.8 
71.7±1.1 
1 
2 
2 
66.8±1.5 
66.8±1.5 
66.8±1.7 
67.0±1.5 
2 
1 
1 
78.5±3.3 
79.6±3.4 
78.9±2.5 
78.5±2.5 
2 
1 
2 
74.2±3.1 
78.0±3.4 
79.8±3.6 
80.8±2.6 
2 
2 
1 
81.9±2.8 
82.6±3.2 
82.2±3.5 
79.8±2.8 
2 
2 
2 
77.8±1.9 
78.6±3.0 
78.6±2.7 
79.2±3.0 
TABLE II.  
CLASSIFICATION ACCURACIES OF MLP NETWORKS WITH 
NORMALIZATION AND ALTERNATIVE 2: MEANS AND STANDARD 
DEVIATIONS IN PERCENTS 
Accuracies for output nodes and conditions 
Output 
nodes 
Condition 
Number of hidden nodes 
 
 
4 
6 
8 
10 
1 
1 
81.1±2.7 
78.4±3.9 
78.9±2.6 
78.4±2.5 
1 
2 
75.8±2.4 
79.5±3.2 
81.1±3.6 
80.5±3.2 
2 
1 
80.5±1.8 
80.1±4.2 
80.0±4.5 
79.6±2.6 
2 
2 
77.3±2.4 
81.7±3.6 
80.2±4.3 
82.7±2.5 
 
We applied multilayer perceptron (MLP) networks [9] 
with 6 input nodes (6 variables), 4, 6, 8 or 10 hidden nodes 
and 1 or 2 output nodes for two classes. A validation error 
was used for MLP networks. It automatically stopped 
training after 9 or 10 epochs to avoid overtraining. Since we 
used the backpropagation algorithm in Matlab (MathWorks 
Inc., USA) also used for all tests of our research, we 
experimented with its training procedure variations including 
the adaptive learning rate, Powell-Beale restarts, batch 
gradient descent with momentum and Levenberg-Marquardt 
algorithm [10]. For actual tests we used the last method that 
yielded slightly better results than those of the other. 
At first, we investigated possible differences between test 
results of Alternatives 1 and 2. Since the number of 5 
recordings (20 saccades) of each subject was small subject to 
build training and test sets in data mining, it was important to 
test more than one alternative. However, the scarcity of the 
data did not allow more alternatives than the aforementioned 
two. We also varied the number of output nodes from 1 to 2. 
On the basis of the best results written in Bold in Tables I 
and II 2 output nodes produced accuracies 1-4% superior to 
those of 1 node. 
TABLE III.  
CLASSIFICATION ACCURACIES OF LOGISTIC DISCRIMINANT 
ANALYSIS AND SVM WITH NORMALIZATION: MEANS AND STANDARD 
DEVIATIONS IN PERCENTS. 
Accuracies for two test alternatives A and conditions C 
A 
C LogDA 
SVM kernels 
 
 
 
Linear 
2nd deg. 
3rd deg. 
Gaussian 
1 
1 78.5±105 
80.0±0.5 
75.6±1.0 
69.6±1.2 
84.9±0.7 
1 
2 65.7±1.7 
62.2±1.3 
63.6±1.7 
61.8±1.7 
73.0±1.3 
2 
1 86.6±1.7 
88.0±2.9 
82.7±2.1 
74.1±2.5 
92.1±1.9 
2 
2 77.4±3.4 
73.9±4.8 
77.1±2.9 
73.3±4.5 
84.8±1.9 
 
The scales of the variables markedly differed from each 
other. We tested MLP networks without and with 
normalization into interval [0,100]. The accuracies obtained 
without or with normalization had virtually no differences on 
an average. The results of the former are showed in Table I. 
Those of the latter are in Table II with Alternative 2 only, 
since Alternative 2 with the larger training set than with 
Alternative 1 indicated to be 7-13% better in Table I. The 
similar observation was gained for all later results. Note that 
while evaluating results we always have to look at both 
conditions at the same time, because they both are equally 
critical objectives. Note also that 50% is seen as a baseline 
result for Conditions 1 and 2. Because there are two classes 
of equal size, a random guess between them would be correct 
with probability 0.5. The number of the hidden nodes from 6, 
8 or 10 yielded the best results for the pairs of Conditions 1 
and 2. 
We ran support vector machines (SVM) with the linear, 
quadratic, third degree polynomial and radial basis function 
(Gaussian) kernels. Table III shows results for SVM kernels 
and logistic discriminant analysis (LogDA). We ran tests for 
all four SVM kernels and logistic discriminant analysis by 
using both Alternatives 1 and 2 with and without 
normalization. Alternative 2 again generated higher results 
than Alternative 1. The use of normalization according to 
Table III did not affect average results seemingly at all 
compared with those not presented without normalization, 
mostly less than ±1%. SVM with the radial basis function 
(Gaussian) kernel was the best choice here, but differences 
were small compared with a few other kernels. 
TABLE IV.  
CLASSIFICATION ACCURACIES OF RBF NETWORKS WITH 
NORMALIZATION: MEANS AND STANDARD DEVIATIONS IN PERCENTS 
Accuracies for two test conditions 
Condition 
Spread and goal 
 
15   0.05 
15  0.08 
20  0.08 
20  0.1 
1 
75.4±4.1 
77.8±0.1 
83.4±2.6 
88.5±1.8 
2 
92.6±1.6 
94.7±1.6 
88.9±3.9 
88.9±1.9 
 
Ultimately, we exploited RBF networks by running 
system parameters of  spread 10, 15, 20, 25, 30, 35, 40, 45 
and 50, and goal 0.005, 0.02, 0.03, 0.05, 0.08 and 0.1. The 
best combinations of these were spread equal to 15 or 20 and 
goal equal to 0.05, 0.08 or 1.0. Final results of RBF networks 
89
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

are presented in Table IV. For the RBF networks, our data 
required normalization, because our tests (not presented here) 
without it favoured Condition 2 and almost entirely failed 
with Condition 1. Thus, the results in Table V were 
computed with normalization and using Alternative 2. 
Since our final objective to develop a biometric 
verification procedure on the basis of eye movements 
included a criterion that computing time should be fast, it is 
important to look at running times of the preceding tests. 
There were 132×10×5=6600 models trained for every test 
type or structure (cell) in the case of Alternative 2. For 
Alternative 1 there were 132×10×10=13200 models trained, 
correspondingly. The training and test time of an MLP 
network was around 0.5 s on an average. For RBFs that time 
of one network was around 4 s and for SVMs and LogDA 
less than 0.05 s. Let us remember that these execution times 
also included training not always necessary to do while 
applying a data mining method in actual applications, except 
when the system is used for the first time and then adaptively, 
say, after a successful login. In any case, even the use of the 
slowest method here was fast enough. Of course, additional 
computation is needed before the data mining phase to 
perform signal analysis. Still, this is also very fast, because 
its time complexity is linear and the length of eye movement 
signals is short, no more than a few thousand samples, say 1-
3 minutes. Consequently, the running time would be minimal 
compared to such a recording time. At the beginning, in the 
course of a recording the eye movement camera system also 
makes image processing, but this is also close to real time. 
The camera system used consisted of only an initial 
calibration when taken into use. Thus, calibration required no 
additional processing time here. 
VI. 
CONCLUSION 
The MLP networks produced their best results with 
Alternative 2, 2 output nodes, 6 hidden nodes in Table I and 
10 hidden nodes in Table II. The use of normalization did not 
improve the results obtained which were around 8% poorer 
than the best of SVMs and RBFs in Tables III-V. The 
Gaussian kernel was the best choice with SVMs. RBFs were 
very sensitive to normalization needed apart from the other 
being very insensitive to normalization. 
The best results obtained were fairly good as 89% of the 
best results in Tables IV and V. We may assess that the best 
realistic accuracies based on various biometric verification 
references are around 95%. Thus, the results of this quite 
novel way to perform a biometric verification task are 
promising although more research has to be made to improve 
verification accuracies. A clear chance here is to collect a 
larger set of recordings from each individual. There were 
only five recordings with four large saccades per a subject. 
Forming a larger training set from each subject than now it is 
quite probable that we are able to improve classification 
results based on data mining methods. To compare with 
other scarce results presented thus far, our results were equal 
or better than various values 50-90% given in [11, 12]. 
The eye movement camera system used included a low 
sampling frequency of 30 Hz (frames per second). Still, 
verification was fairly successive. The low sampling 
frequency was, however, interesting since it was similar to 
that often used in cheap web cameras. We may except that in 
the future eye movement cameras are installed in computers 
or mobile devices to follow a user’s gaze for various human-
computer interface tasks [13]. If their sampling frequencies 
will be higher, e.g., 200 Hz, biometric verification with eye 
movements may well be realistic. 
ACKNOWLEDGEMENT 
The authors thank prof. Ilmari Pyykkö, M.D., from the 
Department of Otorhinolaryngology, Tampere University 
Hospital, Finland, for advice subject to eye movements. The 
first author acknowledges the support given by Tampere 
Doctorial Program in Information Science and Engineering. 
REFERENCES 
 
[1] X. Tan, B. Bhanu, and Y. Lin, “Fingerprint classification 
based on learned features,” IEEE Trans. Syst. Man Cybern, 
Part C: Appl. Rev., vol. 35, no 3, pp. 287–299, August 2005. 
[2] V. Conti, C. Militello, F. Sorbello, and S. Vitabile, “A 
frequency-based approach for features fusion in fingerprint 
and iris multimodal biometric identification systems,” IEEE 
Trans. Syst. Man Cybern, Part C: Appl. Rev., vol. 40, no 4, pp. 
384–395, July 2010. 
[3] K. Venkataramani, S. Qidwai, and B. V. K. Vijayakumar, 
“Face authentication from cell phone camera images with 
illumination and temporal variations,” IEEE Trans. Syst. Man 
Cybern, Part C: Appl. Rev., vol. 35, no 3, pp. 411–418, 
August 2005. 
[4] Z. Sun, Y. Wang, T. Tan, and J. Cui, “Improving iris 
recognition accuracy via cascaded filters,” IEEE Trans. Syst. 
Man Cybern, Part C: Appl. Rev., vol. 35, no 3, pp. 435–441, 
August 2005. 
[5] R.W. Frischholz and U. Dieckmann, “BioID: A multimodal 
biometric identification system,” IEEE Computer, vol. 33, no 
2, pp. 64–69, February 2000. 
[6] M. Juhola, “A syntactic method for analysis of sacadic eye 
movements,” Pattern Recogn., vol 19, pp. 353-359, 1986. 
[7] M. Juhola, H. Aalto, and T. Hirvonen, ”Using results of eye 
movement signals in the neural network recognition of 
otoneurological patients,” Comp. Meth. Progr. Biomed.. vol 
86, pp. 216-226, 2007. 
[8] S. Usui and I. Amidror, “Digital low-pass differentation for 
biological signal processing,” IEEE Trans. Biomed. Eng., vol. 
29, pp. 686-693, 1982. 
[9] S. Haykin, Neural Networks, A Comprehensive Foundation, 
Second Edition, Prentice Hall, 1999. 
[10] H. Demuth, M. Beale and M. Hagan, Neural Network 
ToolboxTM 6 User’s Guide, The MathWorks, 2009. 
[11] P. Kasprowski and J. Ober, “Eye movements in biometrics,” 
Biometric Authentication: Int. Workshop, Springer-Verlag, 
LNCS, vol. 3087, pp. 248-258, 2004. 
[12] O. V. Komogortsev, S. Jayarathna, C. R. Aragon, and M. 
Mahmoud, “Biometric identification via an oculomotor plant 
mathematical model,” Proc. 2010 Symp. Eye Tracking 
Research & Applications, pp. 57-60, 2010. 
[13] A. Holzinger, R. Geierhofer, and G. Searle, “Biometric 
signatures in practice: A challenge for improving human-
computer interaction in clinical workflows,” A. M. Heinecke, 
H. Paul (Eds.), Mensch & Computer, Oldenbourg Verlag, 
München, Germany,  pp. 339-347, 2006. 
90
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-227-1
IMMM 2012 : The Second International Conference on Advances in Information Mining and Management

