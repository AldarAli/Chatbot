A Perspective-Corrected Stylus Pen for 3D Interaction 
Rintaro Takahashi, Katsuyoshi Hotta, Oky Dicky Ardiansyah Prima, Hisayoshi Ito  
Graduate School of Software and Information Science, Iwate Prefectural University 
152-52 Sugo Takizawa, Japan 
email: { g231r019, g236q004}@s.iwate-pu.ac.jp, {prima, hito}@iwate-pu.ac.jp 
 
 
Abstract—Compared to traditional flat displays, the three-
dimensional (3D) spherical display allows us to see images more 
naturally from any directions. This display can show not only 
surface information data, such as digital globes, but also 3D 
objects. Some user interfaces, such as multi-touch and gesture 
interfaces, have been implemented on this display. In this study, 
we propose a novel perspective-corrected stylus pen that can be 
used for 3D interaction with the display. The stylus pen has six 
Degrees of Freedom (6DoF) and can be used as pointing and 
drawing device in the 3D space within the spherical display. 
Therefore, the user can see the auxiliary line from the pen tip 
from a different angle. We demonstrated the stylus in terms of 
accuracy, pointing stability and how users can correctly 
perceive it in the 3D space. Some applications, such as selecting 
objects inside a virtual fish tank, were presented to show the 
usability of the proposed stylus. 
Keywords-VR; 3D stylus; spherical display; virtual reality; 
perception. 
I.  INTRODUCTION 
In recent years, non-planar displays have been actively 
developed. These displays can display images that are more 
effective and immersive than flat displays. Non-planar 
displays can be broadly classified into three types: curved, 
cylindrical, and spherical. Curved displays have already been 
put to practical use in mobile devices. They provide excellent 
visibility even at the edges of the screen. Therefore, some 
additional information can be put on the edge of the screen. 
Cylindrical displays are expected to be new digital signages 
which can effectively display advertisements. Spherical 
displays, on the other hand, can display images from any angle. 
These displays can display not only surface information data, 
such as digital globes, but can also display three-dimensional 
(3D) objects inside.   
Many efforts have been conducted to produce spherical 
displays. These include a combination of multiple small flat 
display panels (Geo-Cosmos [1]), synchronized rotating 
Light-Emitting Diode (LED) strips [2], and a projection 
mapping system using a Digital Light Processing (DLP) 
projector [3]. PufferSphere [4], a commercially projector-
based spherical display, has a multitouch interface allowing 
human interaction with the display, such as pointing and 
rotating.  
The spherical display can be enhanced to represent 3D 
objects [5]. The 3D experiences can be achieved by using  
monocular (motion parallax) or binocular (stereoscopic) cues.  
Motion parallax is a type of depth perception cue in which 
objects that are closer appear to move faster than objects that 
are further. Stereoscopic vision refers to the sense of depth 
derived from the two eyes. Fafard et al. [6] indicate that users’ 
performance in various 3D interactions, such as pattern 
alignment, distance estimation, 3D selection, and 3D 
manipulation is consistently better when stereo cues are 
included. 
3D interactions with the 3D sphere display need a device 
that capable to define its 3D location (x, y, z) with respect to 
the center of the display and its posture information (pitch, 
yaw, roll). Hereafter, information of 3D location and posture 
is simply called Six Degrees of Freedom (6DoF).  
Currently, several input devices equipped with 6DoF 
sensors have been developed. The TouchTM Haptic Device [7] 
is a motorized device that applies force feedback on the user’s 
hand, allowing them to feel virtual objects and producing true-
to-life touch sensations as user manipulates on-screen 3D 
objects. This device acquires the 6DoF information from a 
sensor attached to the pen tip. The DodecaPen [8] is a stylus 
pen which obtains its 6DoF with sub-millimeter accuracy 
using multiple Augmented Reality (AR) markers arranged on 
a dodecahedron mounted on the stylus. Both styluses [7][8], 
however, are designed to work on a flat surface where the 
working area is limited. 
A stylus pen for the spherical display must be able to 
acquire the 6DoF information of the pen tip when touching the 
surface of the display. The arm for the TouchTM Haptic Device 
limits its working range, especially when working on the 
opposite side of the spherical display surface. This problem 
also applies to DodecaPen because the AR markers of the 
stylus will be hidden when working on the lower part of the 
spherical display. 
In this study, we propose a stylus pen which is suitable for 
a spherical display. Measurement of the 6DoF information is 
done using two sensors. Here, the 3D location (x, y, z) of the 
pen tip on the display surface is measured by an infrared (IR) 
camera installed at the bottom of the display. The posture 
information (pitch, yaw, roll) of the stylus pen is obtained 
using a gyro sensor. We believe that the new stylus pen's 
strategy for measuring 6DoF information is effective in 
capturing this information when the pen tip is touching the 
display surface. 
This paper is organized as follows. Section II describes 
related works in the development of 3D spherical displays. 
Section III introduces our approach to implement the 
perspective-corrected stylus pen. Section IV describes our 
experiment results in terms of accuracy, stability and visual 
perception. Finally, Section V presents our conclusions and 
future works. 
11
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

II. RELATED WORK 
There are some companies producing spherical displays, 
such as Global Imagination [3], PufferSphere [4], and 
ArcScience [9]. These displays were mainly intended to show 
earth surface data and 360-degree videos. Therefore, there are 
more like digital globes than displays. 
To our knowledge, SnowGlobe is the first published 3D 
spherical display [10]. This display was implemented by 
reflecting a projected image off a hemispherical mirror, 
allowing for a seamless curvilinear display surface. 
However, it had non-uniform resolution and the mirror caused 
a blind spot. Spheree is a spherical, multi-projector 
perspective-corrected display that supports 3D representation 
using parallax-based 3D depth cues [11]. Uniform resolution 
is mostly achieved because each projector covers a small area 
on the display. CoGlobe is a large 3D spherical display for 
multiple users [12]. It uses a multi-camera OptiTrack system 
for tracking users’ heads and multiplex viewpoints using 
modified active shutter glasses. 
For this study, we have built a 3D spherical display similar 
to Spheree, but only using a fish-eye lens-equipped single 
projector (Figure 1). A 4k projector was used to generate a 
high-resolution image onto the display, comparable with that 
of Spheree. Our display is capable of supporting monoscopic 
and stereoscopic displays. 
III. PERSPECTIVE-CORRECTED STYLUS PEN 
The proposed stylus pen can find its 6DoF information on 
any location on the display. As shown in Figure 2, the 3D 
location (x, y, z) of the pen tip on the display surface is 
measured with an IR camera. This camera captures the blob 
(the image of the light reflected from the IR LEDs) of the pen 
tip. An ellipse is then fitted to the blob, and the center of the 
ellipse is calculated as the position of the pen tip on the display 
surface. The posture information (pitch, yaw, roll) of the 
stylus pen is obtained using a gyro sensor. 
In order to simplify the design of the stylus pen, we use a 
mobile phone with a pen tip attached. The advantage of using 
a mobile phone is that we can use the built-in gyro information, 
and send that information to the computer that controls the 
spherical display. Using this information, the computer 
calculates the posture of the stylus pen and projects the 
auxiliary line from the pen tip according to the user’s 
viewpoint. Here, we used VIVE Tracker [13] to track the 
user’s head and define the viewpoint. Users can point out an 
object inside the spherical display using the auxiliary line 
from the pen tip, as shown in Figure 3.  
IV. EXPERIMENTAL RESULTS 
We evaluate the proposed stylus pen in terms of accuracy, 
pointing stability, and user experience. For the experiments, 
we built a spherical display with a diameter of 51 cm. The 
coordinate systems of the display, stylus pen and user's 
viewpoint are calibrated using the VIVE tracker. The display 
system runs on a desktop computer with a 3.6 GHz CPU, 32 
GB RAM, and a GTX980Ti graphics card. An iPhone 7 (iOS 
13) is used to get the posture information for the stylus pen.  
A. Accuracy 
Twelve arbitrary locations on the display surface were 
selected and the stylus pen was used to point to the center of 
the display from each location. The resulting 6DoF 
information of the stylus pen on each location was validated 
against the true 6DoF information (ground truth) as the vector 
 
 
 
(a) Our 3D spherical display 
(b) Earth 
(c) 3D human pose 
 
Figure 1. Our 3D spherical display (a) and some contents (b), (c) projected onto the display. 
 
Acrylic
globe
Fish
lens
Projector
 
 
Figure 2. Our proposed stylus pen. 
 
 
IR Camera
Stylus
Pen
IR Led
IR Led
12
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

connecting the display center to that location. Overall, the 
accuracy was achieved with an average of 1.08 degrees.  The 
ground truth vectors (red lines) and auxiliary lines from the 
pen tip (blue lines) are shown in Figure 4. We considered that 
our stylus pen is accurate to do 3D interactions within the 
spherical display. In practical use, most users are not aware of 
the differences within this range. 
B. Pointing Stability 
The stylus pen was rotated horizontally from 0 to 180 
degrees at a location toward the display. For each angle, the 
intersection (red dot) of the auxiliary line (blue line) from the 
pen tip with the display surface was calculated. The resulting 
points were observed to be horizontally distributed (Figure 5), 
indicating the pointing stability of the stylus pen. The error 
distribution is shown in Figure 6. 
 
 
 
Figure 3. Our working perspective-corrected stylus pen. 
 
 
Figure 4. The resulting auxiliary lines from the pen tip and their 
corresponding ground truths. 
 
Figure 5. Intersection points of the auxiliary lines from the pen tip 
and the display surface. 
 
 
x [m]
z [m]
y [m]
y [m]
z [m]
x [m]
13
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

C. Visual Perception 
In order to perform a visual evaluation, an experiment was 
performed in which a virtual fish tank was drawn on a 
spherical display and the subject was instructed to use a stylus 
pen to touch the fish from multiple directions (Figure 7). 
Three users participated in the experiment. All of them 
managed to touch all fishes in the spherical display. This result 
shows that the proposed stylus pen can be perceived in the 
same way as the real one.  
V. CONCLUSION 
In this study, we have proposed a novel perspective-
corrected stylus pen that can be used to interact with a 3D 
spherical display. A mobile phone with a pen tip attachment 
is used to build the stylus pen. The use of a mobile phone does 
not only make it easier to obtain posture information from the 
built-in gyro, but also has advantages, such as simplifying the 
design. The location where the stylus pen touches is detected 
by the IR camera installed in the spherical display. Our 
experiments have confirmed the high accuracy of the 
proposed stylus and show that it can be used to perform 
natural 3D interactions. We are working on putting a pressure 
sensor inside the stylus pen to enable the user to control the 
length of the auxiliary line from the pen tip by applying 
varying levels of pressure to the screen surface. In the future, 
the proposed stylus pen will be extended for use in virtual 
surgical training on a spherical display.  
REFERENCES 
[1] GK Design Group, http://www.gk-design.co.jp/en/works/309/. 
[retrieved: February, 2020] 
[2] T. Crespel, P. Reuter, and X. Granier, “A low-cost multitouch 
spherical display: hardware and software design,” Display 
Week 2017, May 2017, Los Angeles, California, United States. 
pp.619- 622, 10.1002/sdtp.11716 . hal-01455523. 
[3] S. W. Utt, P. C. Rubesin, and M. A. Foody, “Display system 
having a three-dimensional convex display surface,” US Patent 
7,352,340. 2005. 
[4] Pufferfish Ltd. pufferfishdisplays.co.uk, 2002. [retrieved: 
February, 2020] 
[5] G. Hagemann, Q. Zhou, I. Stavness., O. D. A. Prima, and S. 
Fels, “Here’s looking at you: A Spherical FTVR Display for 
Realistic Eye-Contact,” ISS 2018 - Proceedings of the 2018 
ACM International Conference on Interactive Surfaces and 
Spaces, pp. 357–362, 2018.  
https://doi.org/10.1145/3279778.3281456  
[6] D. Fafard et al., “FTVR in VR: Evaluating 3D performance 
with a simulated volumetric fish-tank virtual reality display,” 
Conference on Human Factors in Computing Systems, pp. 1–
12, 2019. https://doi.org/10.1145/3290605.3300763 
[7] The TouchTM Haptic Device, 3D Systems, 
 https://www.3dsystems.com/haptics-devices/touch. 
[retrieved: February, 2020] 
[8] P. C. Wu et al., ”DodecaPen: Accurate 6DoF tracking of a 
passive stylus,” UIST 2017 - Proceedings of the 30th Annual 
ACM Symposium on User Interface Software and Technology, 
pp.365–374, 2017. 
https://doi.org/10.1145/3126594.3126664 
[9] L. Thomas, F. Christopher, and L. Jonathan, “A self-contained 
spherical display system,” In ACM Siggraph 2003 Emerging 
Technologies, 2003. 
[10] J. Bolton, K. Kim, and R. Vertegaal, “SnowGlobe: A spherical 
fish-tank VR display,” In Conference on Human Factors in 
Computing Systems – Proceedings, pp. 1159–1164, 2011. 
https://doi.org/10.1145/1979742.1979719. 
[11] F. Ferreira et al., “Spheree: A 3D perspective-corrected 
interactive 
spherical 
scalable 
display,” 
2014. 
https://doi.org/10.1145/2614066.2614091. 
[12] Q. Zhou et al., “CoGlobe - a co-located multi-person FTVR 
experience,” ACM SIGGRAPH 2018 Emerging Technologies, 
SIGGRAPH 
2018, 
2018. 
https://doi.org/10.1145/3214907.3214914. 
[13] VIVE Tracker, https://www.vive.com/eu/vive-tracker/ 
[retrieved: February, 2020] 
 
 
 
Figure 7. The virtual fish tank used for the visual perception 
evaluation. 
 
 
 
Figure 6. Histogram of the error distribution during the 
pointing stability test. 
 
 
Frequency
Error in degrees
14
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-761-0
ACHI 2020 : The Thirteenth International Conference on Advances in Computer-Human Interactions

