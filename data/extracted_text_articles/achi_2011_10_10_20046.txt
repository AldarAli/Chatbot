Tactile Sensing for Safe Physical Human-Robot Interaction 
 
Norbert Elkmann, Markus Fritzsche, Erik Schulenburg 
Business Unit Robotic Systems 
Fraunhofer Institute for Factory Operation and Automation 
Magdeburg, Germany 
e-mail: norbert.elkmann@iff.fraunhofer.de 
markus.fritzsche@iff.fraunhofer.de 
erik.schulenburg@iff.fraunhofer.de 
 
 
Abstract— Human-robot interaction in a shared workspace 
permits and often even requires physical contact between 
humans and robots. A key technology for a safe physical 
human-robot interaction is the monitoring of contact forces by 
providing the robot with a tactile sensor as an artificial skin. 
This paper presents a pressure-sensitive skin for the mobile 
assistant robot LiSA (Life Science Assistant). It can be adapted 
to complex geometries and it can reliably measure contact on 
the entire robot body. The sensitive skin is equipped with 
integrated cushioning elements reducing the risk of dangerous 
injuries in physical human-robot interaction. Besides its safety 
function, the sensitive skin offers touch-based robot motion 
control that simplifies human-robot interaction. In the paper 
we describe the sensor setup and the hardware implementation 
on the mobile assistant robot LiSA and explain the strategies 
for a safe human-robot interaction. Beyond that we describe 
the algorithms enabling direct touch-based robot control and 
present some fundamental results from our evaluation 
experiments. 
Keywords- artificial skin; human-robot interaction; mobile 
robot; tactile sensor 
I. 
INTRODUCTION 
Long banished behind fences and safeguards, robots are 
now increasingly capturing new fields of application as 
service robots or assistance systems. New strategies in 
human-robot collaboration (HRC) erase the boundaries 
between workspaces. Safety and protection of humans are of 
utmost importance when humans and robots collaborate 
directly or come into contact in human-robot coworker 
scenarios. 
In such scenarios, the assurance of safe physical human-
robot interaction will rely on the results of a detailed risk 
assessment, identifying the various hazards and their 
association with physical quantities of robot motion. In 
general, it is essential that we can reliably limit the robot’s 
position and speed as well as its static force and its potential 
impact force. In case of an impact, we must also consider the 
post-impact behavior.  
State-of-the-art robot control systems can safely limit a 
robot’s speed and position, whereas safety-rated limitation of 
forces is currently not a characteristic of industrial robots. 
Thus, we propose to integrate an artificial skin into the 
overall safety concept for collaborative robots in order to 
provide safety-rated information on contact and on static 
forces. 
During the last 30 years various sensitive skins based on 
tactile sensors and using diverse approaches have been 
reported [1-3]. Most of them form an array of individual 
pressure sensors. Covering large parts of a robot body poses 
several significant engineering challenges.  
The tactile skin must fulfill certain design engineering 
requirements: It must be pliable to adapt to curved robot 
bodies, tough and dependable to withstand a significant 
number of contact cycles, energy-absorbing to soften 
collisions and, finally, easy to manufacture. In addition, there 
are also fundamental requirements for the sensor system’s 
reliability, since the tactile skin represents the only barrier 
between the robot’s forces and a human in direct physical 
human-robot interaction. 
Various attempts have been made to tackle these issues 
and to develop robot skin systems in recent years. Iwata et al. 
[4] used rigid covers on parts of their humanoid robot 
WENDY. The covers are mechanically secured at a single 
point on a multi-axis force sensor. This allows accurate 
measurement of forces and torques acting on the cover. The 
system has limited “multi-touch capability”. When several 
forces act on a cover at the same time, the associated multi-
axis force sensor only measures one force generated by all 
the force vectors applied. 
The wiring topology is one of the most challenging 
problems when implementing a distributed tactile sensor 
system. The larger the number of sensing elements, the 
thicker the wire bundle and the larger grows the amount of 
data. To solve this problem, piezo-resistive sensor patches 
with embedded data processing electronics were effectively 
implemented in the ARMAR-III robot [5]. Embedded 
electronics process local tactile data in order to limit the 
bandwidth requirements. The sensor patches are custom-
designed to cover the respective parts of the robotic arms.  
Ohmura et al. [6] developed a solution to adapt tactile 
sensor systems to the curved surfaces of robots. Their 
approach also applies a networked architecture to connect a 
large number of individual controllers, each scanning a 
limited number of taxels. The electronics and transducers are 
embedded in a tree-shaped flex/semi-flex PCB support, 
which simplifies mechanical adaptation to curved surfaces. 
212
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

Canata et al. [7] presented an alternative approach to 
cover complex geometries. Inspired by the principle of 
triangulation used in computer graphics, they applied a mesh 
of triangular shaped sensor modules to cover three-
dimensional surfaces. Each sensor module is supported by a 
flexible substrate, thus allowing the sensor to conform to 
smooth curved surfaces. Three communication ports placed 
along the sides of each sensor module allow interconnecting 
adjacent modules. 
The aforementioned solutions have already been 
implemented to solve a multitude of problems. However, a 
tactile sensor system implemented in direct human-robot 
interaction must not only be able to detect contact but also to 
cushion it if necessary. 
Furthermore, the sensor system must be able to absorb 
the stopping distance when the robot stops without applying 
high forces to the collision partners.  
The tactile sensors we analyzed prior to our research and 
development work are only conditionally suited for this 
application, since they lack the necessary softness and 
compliance. 
To solve these problems we implemented an energy-
absorbing layer into the tactile sensor solution applied to our 
mobile robot LiSA. With this additional layer we are not 
only able to measure interaction forces and represent them 
spatially and quantitatively resolved, moreover we are able 
to cushion collisions. The risk of dangerous injuries in 
human-robot interaction can be significantly decreased by 
this measure.  
The setup and implementation of our tactile sensor 
solution on the LiSA robot will be described in the following 
sections. 
II. 
SENSOR TECHNOLOGY 
This section deals with the setup of our tactile transducer. 
We will discuss adaptations to complex geometries and 
challenging ambient conditions. Finally, the data processing 
unit will be described. 
A. Tactile Transducer Technology 
The heart of our tactile transducer technology is a 
flexible measuring sensor (Figure 1), which is about 2 mm 
thick and entirely made of textile to obtain maximum 
mechanical reliability.  
Instead of classic cables, textile conductive paths span a 
sensor matrix which consists of flexible sensor cells. The 
individual sensor cells are based on variable, pressure-
dependent resistors and have a defined value in their 
unloaded state. Deviations from this value are a measure of 
the force acting on the sensor. Weiss et al. [8] describes the 
working principle of such sensor cells. 
 
 
Figure 1. Prototype 8x8 tactile transducer 
Since each sensor cell provides an analyzable signal even 
in the unloaded state, the functional capability of the 
individual sensor cells can be monitored. Thus it is possible 
to detect any failure of the individual sensor cells when the 
textile conductive paths short-circuit or are cut (Figure 2). 
The thusly achievable “intrinsic safety” of the sensor system 
is an essential basis for using the sensor system as a safety 
sensor. 
 
 
Figure 2. Sensor with related sensor data, showing a malfunction on a 
single sensor line (light gray) and normal sensor data (dark gray) 
 
For an optimal interaction between the robotic system’s 
geometry and the artificial skin, the tactile transducers 
should be adapted to the individual case of application, e.g., 
by customizing one or more of the following options:  
 
shape and size of the tactile transducers 
 
shape and size of the individual sensor cells 
 
force measurement range 
 
thickness 
 
shell material 
The structure of the textile sensor system allows for 
integrating application-specific cushioning zones (Figure 3). 
They consist of special energy-absorbing materials and 
therefore enable controlled deceleration and stopping of the 
robot system in case of an unintentional contact without 
exposing the collision partner to high load peaks. These 
cushioning zones include significant design factors such as 
the robot system’s speed and geometry and the safety 
circuit’s response time. 
 
Figure 3. Cross section of a tactile transducer,  
showing pressure-sensitive layer and energy-absorbing layer 
 
The tactile transducers may be constructed for a wide 
range of ambient conditions by selecting an appropriate shell 
material from waterproof, breathable or particularly rugged 
designs (Figure 4). Depending on its properties, the shell 
material is sewn, welded or bonded. 
 
 
Figure 4. Tactile transducer with related sensor data: 
a) water proof b) cut-resistant 
213
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

The tactile transducers may have any geometric shape 
and can even be adapted to two-dimensional curved free-
forms. The number, shape and size of the individual sensor 
cells can be customized.  
A demonstration of this geometry-adapted sensor 
system’s functionality can be found in a study in which the 
KUKA lightweight robot with extremely complex geometry 
served as the target system (Figure 5). 
 
 
Figure 5. KUKA lightweight robot  
(a) without and (b) with the tactile sensor system 
 
B. Sensor Controller 
Our tactile sensing system is equipped with an intelligent 
sensor controller as front end. It contains microcontroller-
based circuits scanning and sampling the connected tactile 
transducers. 
We use two separate multiplexers to address the 
individual sensor cells of our matrix-based tactile transducers 
(Figure 6). The number of channels needed is identical with 
the number of rows and columns. In order to eliminate the 
problem of crosstalk in matrix-based tactile sensor systems, 
we implemented a signal conditioning unit which is based on 
the zero potential method proposed by Shimojo et al. [9]. 
 
 
Figure 6. Block diagram of the sensor controller 
 
The resistance change of the selected sensor cells is 
measured by an integrated ADC. The ADC has a resolution 
of 10 bits at sampling frequencies up to 20 kHz. 
Rapid data communication interfaces such as CAN or 
USB are employed to make the acquired sensor data 
available. These data may thus be integrated into the robot 
control for further processing or visualization. 
Integrated preprocessing algorithms provide low-level 
safety functions. If the load applied to the tactile transducer 
exceeds a predefined threshold, a usually closed safety 
switch is opened. This safety switch is integrated into the 
robot system’s safety circuit and may be used to stop the 
robot’s movement. 
C. Sensor Topology 
 
Figure 7. Sensor topology 
 
As shown in Figure 7, a CAN or USB bus can be used to 
connect the multiple sensor controllers to a superordinate 
control. In turn, each sensor controller supports multiple 
tactile transducers. 
By default the tactile transducers are connected to the 
sensor controller via ZIF connectors. Custom connection 
boards (Figure 8) can be mounted to an extension header 
available on the sensor controller. 
 
 
Figure 8. Sensor controller with housing  
and custom connection board 
 
Using a logical AND link, the safety switch of each 
sensor controller can be integrated in the robot system’s 
safety circuit. Thus, if one controller fails or detects a 
dangerous contact, the robot system will enter a safe state. 
For pure safety applications, the sensor controller may be 
used stand-alone, i.e., the data interfaces merely serve 
parameterization. 
 
III. 
THE LISA ROBOT 
 
 
Figure 9. The LiSA robot interacting with a human 
 
214
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

The Life Science Assistant (LiSA) [10] was built and 
developed within the LiSA project supported by the German 
Federal Ministry of Education and Research as part of its 
program “Key Innovations: Service Robots”. 
The objective of this project was to develop a mobile 
service robot suitable for everyday routine tasks in lab 
environments of biotechnology companies (Figure 9). One 
key aspect of development was an overall system design 
aiming for safe human-robot interaction within shared 
workspaces. 
The LiSA assistant robot mainly consists of a mobile 
robot base with a robotic arm mounted atop. The robotic arm 
was realized by using a classic SCARA setup. Safe human-
robot cooperation is ensured by an extensive safety and 
sensor system on board the robot. Besides proven safety 
technologies, such as laser scanners and bumpers, that have 
already been implemented in automatic guided vehicle 
systems many times before, novel safety components and 
strategies such as the artificial skin were tested within the 
project. 
IV. 
AN ARTIFICIAL SKIN FOR LISA 
The LiSA robot has been equipped with fourteen 
geometry-adapted skin patches (Figure 10). Five of them are 
located on the robot base, four on the lower segment of the 
robotic arm and five on the upper segment.  
 
Figure 10. Exploded view of the LiSA robot  
showing the individual skin patches 
 
The skin patches were designed in a way that they 
entirely protect the robot in its directions of movement. The 
size and number of sensor cells and thus the attainable spatial 
resolution varies across the robot, depending on the positions 
of the skin patches.  
The biggest sensor cells with about 10 cm x 10 cm are 
located on the mobile robot base, and smaller sensor cells 
with about 3 cm x 3 cm cover the robotic arm. Altogether the 
robot’s surface is covered by 375 sensor cells. 
Initially, the placing of sensor cells was inspired by the 
human tactile sensor system: We have a low spatial 
resolution on the body (mobile robot base) and a higher 
spatial resolution on the extremities (the robotic arm). The 
extremities are mainly used for interaction and therefore 
require a precise determination of the contact position. 
Mounted on the mobile platform, the artificial skin just 
represents an additional feature complementing the existing 
bumpers and laser scanners. Thus even the low spatial 
resolution provides us with useful information. 
As shown in  
Figure 11 LiSA’s skin patches are set up in three layers. 
 
 
Figure 11. Exploded view of sensor patch 
 
The top layer forms the tactile sensor layer, the middle is 
a cushioning layer and the back layer can be best described 
as a contact layer, providing mechanical and electrical 
contact to the robot. 
To give an optimal fit to the sensor patches, all three 
layers are sewn together by using precast connection 
elements. These elements also guide the electrical signals 
from the top layer to the bottom layer. 
The cushioning layer fulfills two contradictory tasks. On 
the one hand it should be soft to cushion collisions. On the 
other hand it should be strong and durable to resist a large 
number of collisions and to give mechanical support to the 
tactile sensor layer placed on top of the cushioning layer. 
In accordance to the bumpers at the robot base we 
integrated a 40 mm thick cushioning layer into the skin 
patches placed at the mobile robot base. The skin patches at 
the robotic arm have been equipped with a 20 mm thick 
cushioning layer. 
 
V. 
IMPLEMENTATION OF FORCE-GUIDED  
MOTION CONTROL 
Due to the artificial skin we are able to detect forces 
applied to the robot’s surface. By interpreting these forces as 
motion commands, it is possible to implement touch-based 
motion control algorithms. Our current development stage 
includes implementation of such control algorithms on 
LiSA’s robotic arm.  
The robotic arm is a classic SCARA setup with four 
degrees of freedom (Figure 12). To apply force-guided 
motion control to all axes, we implemented three different 
strategies of motion control. 
Figure 12. The robotic arm of LiSA with control functions related to the 
skin patches, A / B – axis-wise motion control, C – Cartesian control,  
D – control functions for axis 3 / 4 and the gripper 
215
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

 
The skin patches A and B (as depicted in Figure 12) are 
used for axis-wise motion control of axis 1 and axis 2, 
respectively. Skin patch C can be used for simultaneous 
control of axis 1 and axis 2 in Cartesian space. Skin patch D 
is used to control axis 3, axis 4 and the gripper. 
A. Axis-wise motion control 
For axis 1 and axis 2, axis-wise motion control 
algorithms are implemented. The control algorithms are 
mainly based upon a torque compensation approach. In 
accordance with Figure 12 these algorithms are activated if 
forces are applied to the skin patches A or B. 
 
Figure 13. Top view of the robotic arm, with forces applied to axis 2 
 
As shown in Figure 13 forces Fi applied to the skin 
patches result in a torque Mres which the control algorithms 
try to compensate. Thus the affected axis is moving in the 
direction of the resulting torque with the speed vrot as 
calculated in (1). 
 
 
(1) 
Mmax  - maximal torque  
Fmax  - maximal force measureable by the tactile sensor 
amax  - maximal distance between center of rotation and force contact 
point 
 
B. Cartesian motion control 
The cylindrical casing of the lifting spindle is covered by 
skin patch C (cf. Figure 12). Pushing this cylinder causes a 
change of the gripper’s position in a horizontal plane.  
To achieve this movement we need to detect the 
individual forces Fi applied to the cylinder and sum up the 
appropriate force vectors. The resulting vector Fres indicates a 
direction and velocity of movement (Figure 14). It can be 
used to calculate the necessary rotational speeds for the axes 
1 and 2 to move the manipulator as desired. This approach is 
an easy way to teach horizontal Cartesian positions. 
 
Figure 14. Top view of the robotic arm, with forces applied to skin patch C 
 
C. Special Motion Control 
Axis 3 and axis 4 cannot be controlled directly since they 
are not covered by skin patches. Nevertheless we can provide 
touch-based motion control by implementing virtual buttons 
to the skin patch D (cf. Figure 12).  
We implemented two buttons for each axis and the 
gripper, as depicted in Figure 15. Unlike standard push 
buttons only providing an on/off signal, these tactile sensor-
based buttons give us force-based motion control: The higher 
the force applied to the button the faster the selected axis 
moves. The motion speed of the selected axis is calculated 
according to equation (2). 
(2) 
 
Figure 15. Skin patch D with special motion control functions 
A3+ / A3- / A4+ / A4- : motion control for axis 3 and axis 4  
open / close : motion control for the gripper 
 
VI. 
EXPERIMENTAL EVALUATION OF  
THE SAFETY FUNCTION 
As mentioned before, the cushioning layer integrated into 
the sensor setup is used to cushion collisions and to provide 
mechanical support to the tactile sensor layer. Thus the 
objective of our evaluation process was to show that our 
sensor setup can fulfill both contradictory tasks. 
In a first experiment we investigated the ability of the 
cushioning layer to give mechanical support to the tactile 
sensor layer. To do so, we integrated a tactile transducer with 
a 20 mm cushioning layer into a force measurement stand 
and recorded the sensor resistance and the applied pressure 
according to the compression of the tactile transducer. 
As illustrated in Figure 16, we have a noticeable change 
in resistance within the first two mm. Within this sensing 
range, the internal preprocessing algorithms of our sensor 
controller can generate a reliable stop signal. After signal 
generation about 15 mm can be used to stop the robot 
without loading the collision partner with high load peaks.  
Within this experiment we were also able to identify the 
minimal pressure needed to generate a reliable stop signal, 
which is about 0.25 N/cm². 
 
Figure 16. Results of first experiment 
216
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

In a second series of experiments we investigated the 
sensor system’s ability to cushion collisions. With the aid of 
a high dynamic force measurement stand we measured 
forces and impact energy. The main part of the force 
measurement stand is a three-component force measurement 
plate (Figure 17). The collisions were simulated by using a 
pendulum, whose deflection and thus kinetic energy were 
identical for all collision experiments. 
 
Figure 17. High dynamic force measurement stand 
 
We investigated two different collision scenarios. In a 
first experiment we applied one of our standard tactile 
transducers without cushioning layer to the measurement 
plate. In the second experiment we employed a tactile 
transducer with a 20 mm cushioning layer to cushion the 
collision. As shown in Figure 18 the use of a tactile 
transducer with cushioning layer can significantly reduce the 
load peak. In the given example the load peak could be 
reduced from 820 N to about 24 N, representing a reduction 
factor of 34. 
 
 
Figure 18. Results of collision experiments 
a) with standard tactile transducer  
b) with cushioned tactile transducer 
VII. CONCLUSION AND FURTHER WORK 
In this paper, we described the setup and system 
integration of a pressure-sensitive skin for a mobile robot. 
The use of mainly textile components enabled us to create a 
versatile and flexible skin solution.  
The textile setup makes the tactile transducers insensitive 
to mechanical stress like bending. This enables us to shim 
the tactile transducer by a cushioning layer. Since the 
cushioning layer provides the robot with a soft surface 
capable of absorbing collision energy, it also ensures an 
enhanced safety in human-robot interaction. 
The innovative mounting technology using snap fasteners 
for mechanical and electrical connection enables us to ensure 
that the sensor patches are mounted properly. 
The sensor technology primarily aims at covering large 
robotic structures with low to medium spatial resolution. It is 
hardly qualified for high spatial resolution applications such 
as the coverage of finger tips, etc. 
At the time of this publication our robot LiSA is entirely 
equipped with the sensitive skin. The sensor system has been 
successfully integrated into the emergency stop system and 
into the motion control system, as well. Thus we are able to 
provide a safe touch-based motion control interface for 
human-robot interaction scenarios. 
REFERENCES 
[1] 
J.G. Webster, “Tactile sensors for robotics and medicine”. New York: 
Wiley, 1988. 
[2] 
H.R. Nicholls, “Advanced tactile sensing for robotics”. Singapore: 
World Scientific, 1992. 
[3] 
V. Lumelsky, “Sensitive skin”. Singapore: World Scientific, 2000. 
[4] 
H. Iwata and S. Sugano, “Whole-body covering tactile interface for 
human robot coordination”, in Robotics and Automation, 2002. 
Proceedings. ICRA ‘02. IEEE International Conference on, 2002, pp. 
3818-3824 vol.4. 
[5] 
T. Asfour, K. Regenstein, P. Azad, J. Schröder, and R. Dillmann, 
“ARMAR-III: 
A 
Humanoid 
Platform 
for 
Perception-Action 
Integration”, Proceedings of 2nd International Workshop on Human-
Centered Robotic Systems, 2006 
[6] 
Y. Ohmura, Y. Kuniyoshi, and A. Nagakubo, “Conformable and 
scalable tactile sensor skin for curved surfaces”, in Robotics and 
Automation, 2006. ICRA 2006. Proceedings 2006 IEEE International 
Conference on, 2006, pp. 1348–1353. 
[7] 
G. Cannata, M. Maggiali, G. Metta, and G. Sandini, “An embedded 
artificial skin for humanoid robots”, in Multisensor Fusion and 
Integration for Intelligent Systems, 2008. MFI 2008. IEEE 
International Conference on, 2008, pp. 434–438. 
[8] 
K. Weiss and H. Woern, “The working principle of resistive tactile 
sensor cells”, Proc. of the IEEE International Conference on 
Mechatronics and Automation, Niagara Falls, Canada, July 2005 
[9] 
M. Shimojo, A. Namiki, M. Ishikawa, R. Makino, and K. Mabuchi, 
“A tactile sensor sheet using pressure conductive rubber with 
electrical-wires stitched method”, Sensors Journal, IEEE, vol. 4, no. 
5, pp. 589–596. 
[10] E. Schulenburg, N. Elkmann, M. Fritzsche, J. Hertzberg, and S. 
Stiene, “LiSA: Auf dem Weg zur sicheren Assistenzrobotik”, KI - 
Künstliche Intelligenz, vol. 24, no. 1, pp. 69–73, 2010 
[11] M. Fritzsche, N. Elkmann, “An Artificial Skin for Safe Human-
Robot-Interaction”. In: Humanoids 09. Workshop on Tactile Sensing 
in Humanoids – Tactile Sensors & beyond. (Paris 7. December 2009) 
- Proceedings, pp. 42-43. 
217
ACHI 2011 : The Fourth International Conference on Advances in Computer-Human Interactions
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-117-5

