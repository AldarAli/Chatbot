Toward a Multi-Domain Platform for Live Sensor Data Visualisation
and Collaborative Analysis
Marco Forin, Paolo Sacco, Alessio Pierluigi Placitelli
Vitrociset S.p.A.
Via Tiburtina 1020, 00156 Rome, Italy
Emails: {m.forin, p.sacco, a.placitelli.cons}@vitrociset.it
Abstract—In this work, we present a web platform that seeks
to tackle the challenges that come from the real-time visu-
alisation of georeferenced sensor data in a multi-user, multi-
touch environment. We introduce an input device agnostic user
interface and the concept of realistic input reaction. We discuss
the implemented components and the presentation system as a
whole. The demonstrated platform also provides a set of building
blocks to personalise the visualisation, easing its reuse in different
monitoring scenarios. Finally, we show how the platform can be
used to assist collaborative data visualisation and analysis.
Keywords–environmental monitoring; real-time GIS data analy-
sis; collaborative analysis; tabletops; natural user interfaces; multi
touch.
I.
INTRODUCTION
In the recent years, sensor networks have been used to solve
a variety of problems, ranging from environmental monitor-
ing [1] to ﬁne grained structural health monitoring [2]. Such
deployed sensors might be used to ensure public safety and
provide a steady ﬂow of information to higher level decision
makers, support systems and crisis ﬁrst responders [3][4]. The
amount of data collected by geographically distributed sensors,
independently of their function, can be of a considerable
volume and present a challenge to interactive visualisation. In
this work, we present a platform for sensor data presentation
and collaborative analysis. The platform aims to integrate
and visualise in a clear and understandable way live data
feeds coming from deployed sensors, geographical information
systems and the result of higher level reasoning coming from
data fusion engines or complex event processing. Moreover, it
is designed to allow its use on Multi-Touch Tables (MTT), thus
facilitating the collaboration and analysis through the means
of natural user interfaces. Practical use cases of the system
comprise real-time pollutant agents detection and warning
system, nuclear waste monitoring and tracking or situation
awareness and emergency monitoring in control rooms.
This paper is organized as follows. In Section II, we
describe the previously proposed methods for web-based sen-
sor data visualisation and discuss the limitations of these
methods. In Section III, we describe the design elements and
key principles we based our platform on. In Section IV, we
describe our platform and explain how it tries to address
the limitation of the approaches in the literature. Finally, in
Section V, we present our conclusions and the direction of
our future work.
II.
RELATED WORK
In recent years, many largely different approaches have
been proposed to interactively visualise considerable amounts
of data coming from geographically distributed sensors. In this
section, we introduce some of them, speciﬁcally focusing on
web-based solutions. The SenseWeb project [5] demonstrates
a web-based data gathering and visualisation infrastructure
relying on Microsoft SensorMap for the visualisation, although
not taking advantage of open geospatial standards. The Na-
tional Oceanic and Atmospheric Administration’s (NOAA)
nowCOAST [6] aggregates heterogeneous informations, such
as meteorological, oceanographic and hydrological data into
a single, web-based visualisation platform, only partly based
on open source technologies. Previous literature on multi-user,
multi-touch interactions mainly focused on researching novel
interaction techniques to mediate the issues involved in the
collaborative interaction on a shared surface, such as content
orientation, occlusion and reach [7]. The reacTable project
demonstrated a multi-user, collaborative, electro-acoustic mu-
sical instrument on a multi-touch table [8]. In DTLens [9], a set
of consistent interaction was investigated to allow multi-user
exploration of geographical data on tabletops. In [10], a multi-
touch system which allows multiple users to interact on a touch
sensitive surface. Even though many sensor data visualisation
systems have been demonstrated and implemented by the re-
search community, they do not support multi-touch interactions
out of the box thus not allowing collaborative multi-user touch
interactions. The ones that support this kind of interaction lack
real-time sensor live data integration with Geographic Infor-
mation Systems (GIS). Moreover, an additional shortcoming of
the aforementioned approaches is that their systems are tied to
a speciﬁc domain or hardware platform and do not provide
enough ﬂexibility to be reused in different scenarios.
III.
DESIGN PRINCIPLES
In this section, we describe the design principles we
followed in the development of the platform.
A. Easier deployment, scalability and easier maintainability
Given the power of modern consumer hardware and the
increasing efﬁciency of web browsing software, with the
rise of emergent technologies like HTML5 and WebGL, a
number of obstacles to the development of truly interactive
web applications have been removed [11]. As a consequence,
web applications can be considered as a feasible alternative to
native applications for interactive software. Our platform (see
Figure 1) is entirely based on state-of-the-art open technolo-
gies, exploiting the potential of the latest HTML5 draft [12]
and the latest Javascript and WebGL [13] speciﬁcations. The
strict adherence to open web standards and technologies allows
to have a platform-independent software system which is:
97
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-356-8
AMBIENT 2014 : The Fourth International Conference on Ambient Computing, Applications, Services and Technologies

1)
simple to deploy: the platform has to be deployed on
a single machine and is automatically accessible to
all the devices with a network connection;
2)
simple to maintain: updates have to be delivered to a
single machine;
3)
simple to scale: a variety of open source, enterprise
grade, components are already available for this pur-
pose.
B. Multi-user, touch environment
The platform needs to exploit the potential beneﬁts given
by the use of MTTs. Each element of the platform has to react
to touch inputs. The platform also has to abstract the user
away from the challenges involved in the collaborative use of
MTT including, but not limited to, content orientation, gestural
interaction and group interaction [7]. Moreover, the platform
has to provide support for legacy input devices like the mouse
and be easily extensible to support new input paradigms (i.e.,
touch-less interaction).
C. Extensible widgets
The platform User Interface is made up by reusable mod-
ules called widgets. Each widget has to be replaceable. The
developer has to be able to write new widget, either extending
available ones or starting from scratch.
D. Standard communication protocols
Modules within the platform have to communicate using
standard communication protocols and speciﬁcations. Since
the platform works within a web browser, protocols like
WebSocket [14], Server-Sent Events [15] and HTTP [16] are
used. Geospatial data is delivered through the main protocols
deﬁned by the Open Geospatial Consortium (OGC): Web
Feature Service (WFS), Web Coverage Service (WCS) and
Web Map Service (WMS) protocols.
E. Open source stack
The platform has to integrate the most commonly used,
widely tested, open source, third party libraries and encap-
sulate them into self-contained components, whenever this
is possible. In our platform the jQuery [17] library, a small
and fast Javascript library, is used to simplify web document
manipulation. The platform also makes extensive use of the
doT.js library [18] to provide template based presentation of
live sensor data. The platform web pages are served through
an instance of the Apache HTTP Server [19]. Furthermore,
geospatial data is served using GeoServer [20], which imple-
ments the OGC standards. The OpenLayers [21] library is used
to visualise data layers on bi-dimensional cartography while
the CesiumJS [22] is used for data visualisation in a three-
dimensional representation of the region of interest.
IV.
PLATFORM OVERVIEW
Our platform allows geographically distributed sensor data
visualisation. Its main strengths, which have been the focus of
our research activities, are its ﬂexibility and the multi-user,
multi-touch capabilities. User interactions are characterized
by the ability to use different input paradigms and devices,
such as touch-based and mouse-based commands. Depending
on the device used to access the platform, it can either be
used completely through touch or mouse inputs, or both of
them. Touch gestures are designed to maximize user action
throughput when using the system: commands are triggered
with the detection of a different number of touches or based
on the kinematic parameters of the touch points. The platform
user interface is designed as a desktop environment built within
a web application, beneﬁting of the cross-device availability
given by the latest web technologies. Furthermore, structuring
the web application as desktop environment, helps reducing the
learning time as the operator should be already familiar with
native desktop environments which are commonly available on
commodity personal computers.
A. Multi-touch, collaborative analysis
MTTs enable interaction with the hands and the ﬁngers,
providing each user in a multi-user scenario with the ability to
manipulate virtual objects as if they were physical. Moreover,
two-handed, multi-ﬁngered input is more natural and ﬂexible
than mouse and stylus input devices [23]. The multiple points
of contact in MTTs enable novel interaction ﬂows, enhancing
multiple user parallel reasoning and collaboration on the same
interface. The multi-user interaction on a MTT can be used
to exploit collaborative analysis and visualisation in different
scenarios [24], as well as improve the decision making process
in military [25] or clinical [26] settings. Due to the increasing
use of mobile touch devices such as phones and tablets, inter-
acting with touch surfaces has become a common practice, not
dependent on the age of the user. As a result of this, the domain
experts which are more resistant on using new software or
technologies have a more positive attitude toward MTTs which
aids the quicker learning of platform functionalities compared
to the use of legacy devices. Furthermore, since a MTT allows
a display to provide a common informative context as a shared
workspace, parallel and collaborative analysis can be easily
exploited. For example, if a user is examining the live data
coming from sensors deployed on an extended geographical
area detects an event of interest, he can send the relative
data to another user on the MTT for further analysis. In
another scenario, different users could concurrently analyse
different sensor feeds coming from different geographical areas
to resolve a common problem. The parallelism and the quick
data/information exchange in face-to-face settings around a
MTT may foster the collaboration among these individuals
and consequently give an advantage during decision making
processes and the analysis of emergency situations.
B. Widgets
A widget is a graphical user interface component which
is part of the presentation platform, consisting of a title bar,
a content area and input-reactive corners. To foster collabo-
ration [27] among multiple users around a multi touch table,
each widget in our platform can be repositioned and oriented
freely, since a widget presented right-side up to one user might
be upside-down for another. Widget repositioning is achieved
by dragging the title bar with a single ﬁnger, the size can be
varied by dragging its corners toward or away from each other
while its orientation is changed by performing a clockwise
or counter-clockwise rotation while holding down the two
98
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-356-8
AMBIENT 2014 : The Fourth International Conference on Ambient Computing, Applications, Services and Technologies

Figure 1: An overview of the sensor data presentation platform
ﬁngers on the aforementioned corners, thus allowing users to
organise the personal and group workspace on the table. In our
platform, we introduced the concept realistic input reaction:
the motion of a widget produced by user input is modelled by
taking in consideration the laws of the motion of points and
bodies or kinematics. Widgets behave as if they were physical
objects reacting to an applied force. This feature makes touch
manipulation of the widgets more natural and allows to transfer
the motion of the ﬁngers to the ﬁngers, thus enabling users to
drag widgets toward other users without moving around the
table, simply by dragging it with the appropriate speed and
then lifting the ﬁnger. We will brieﬂy review the main widgets
of the proposed platform.
1) Geospatial Data Widget: One of the components avail-
able within our platform is the Geospatial Data Widget (see
ﬁgure 2). This component is completely built using Javascript,
HTML5 and WebGL without relying on third party native
software or closed source libraries. It does not require the
installation of any browser plug-in as it is completely based
on open web standards. The visualization component is in-
tegrated within platform and provides the seamless blend of
geospatial data (aerial photographs, terrain elevation data) with
live georeferenced sensor information about the monitored
environment coming from the deployed sensors. Moreover,
the geospatial data widget is also able to display both a bi-
dimensional and a three-dimensional view of the monitored
environment. When a bi-dimensional view is activated, aerial
photographs of the region of interest are requested using
the WMS protocol. If a three-dimensional visualization is
requested, the terrain surface is built by exploiting aerial
photographs and terrain elevation data for the region of interest.
The visualisation is further augmented with additional data
layers (buildings and 3D models) and real-time data collected
from the sensors deployed on the ﬁeld (GPS positions, mea-
surements, video feeds, etc.). The style of each data feed can
be personalized at deployment time or runtime, thus allowing
to show different icons or models for different types of data
coming from the sensors. Besides, each single data feed can
be independently shown, hid or displayed with a particular
opacity by interacting with the relative entry in the list of
Figure 2: The geospatial data widget
available sensors. A personalised HTML page can be shown
when a sensor is selected in this widget. To ease the integration
with different information systems and fusion engines, real-
time information feeds can be streamed to the visualization
component using different open formats and protocols: JSON,
XML, GeoJSON and KML over WebSockets.
2) Common Alerting Protocol Widget: the Common Alert-
ing Protocol [28] (CAP) is an emergency alert format which
allows a consistent warning message to be disseminated over
heterogeneous warning systems. Our platform supports CAP
alerts visualisation and analysis through the CAP widget.
3) Data Table Widget: the data table widget displays the
data coming from the deployed sensors in a tabular format. It
can be either connected to a real-time sensor data feed or to
a database storage system. Customised queries can be used to
gather speciﬁc informations.
99
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-356-8
AMBIENT 2014 : The Fourth International Conference on Ambient Computing, Applications, Services and Technologies

4) Graph Widget: this widget produces a graphical rep-
resentation of the historical trend that a particular variable,
coming from the deployed sensors or a database connection,
assumes over time.
5) Video Streaming Widget: the video widget allows to
display a video stream within the platform. The stream can
come from a deployed sensor (i.e., a camera) or from a remote
server.
6) Organiser Widget: when dealing with more than one
widget on a single display, visual clutter might become an
issue. This control enables users to reorder the widgets within
the screen area by maximising the visibility of each widget’s
content area while spreading them around the empty areas
of the display. Classical widgets reordering functions, such
as widget tiling and cascading, are available as well. The
organiser also serves a tool to easily locate desired opened
widgets.
V.
CONCLUSION AND FUTURE WORK
In this work, a platform for the presentation and collabo-
rative analysis of real-time data coming from geographically
distributed sensor has been presented. Such system, which
has been entirely written as a web software without any
third party browser plug-in dependency, can be viewed in any
browser supporting the latest HTML5, Javascript and WebGL
speciﬁcations. Its presentation layer hides the heterogeneous
nature of the real-time data coming from remote sensors, thus
displaying data to the end user in a consistent and homo-
geneous way. Moreover, the presentation layer is optimised
for displaying on different devices: MTTs, mobile tablets and
personal computers. In particular, the platform is tailored to be
used on MTTs enabling easier, collaborative data analysis. To
further enhance the multi-touch collaborative experience, we
introduced the realistic input reaction for widgets, to adhere to
the user mental model of physical object movements. Future
work will be focused on extending the collaborative interac-
tion metaphors on multi-touch displays and adding support
for touch-less interactions. Furthermore, given the increasing
availability of augmented reality devices, additional research
efforts will explore the use of the platform on such devices.
Moreover, we will investigate how to describe the interface in
abstract fashion thus enabling its auto adjustment depending
on the used input device. Besides, an experimental campaign
is scheduled to assess the potential advantage of using the
platform, in a multi user environment, on a multi-touch table
in a command and control room scenario.
REFERENCES
[1]
L. Yu, N. Wang, and X. Meng, “Real-time forest ﬁre detection with
wireless sensor networks,” in Wireless Communications, Networking
and Mobile Computing, 2005. Proceedings. 2005 International Confer-
ence on, vol. 2.
IEEE, 2005, pp. 1214–1217.
[2]
S. Kim et al., “Health monitoring of civil infrastructures using wireless
sensor networks,” in Information Processing in Sensor Networks, 2007.
IPSN 2007. 6th International Symposium on, April 2007, pp. 254–263.
[3]
S. M. George et al., “Distressnet: a wireless ad hoc and sensor
network architecture for situation management in disaster response,”
Communications Magazine, IEEE, vol. 48, no. 3, 2010, pp. 128–136.
[4]
K. Lorincz et al., “Sensor networks for emergency response: challenges
and opportunities,” Pervasive Computing, IEEE, vol. 3, no. 4, 2004, pp.
16–23.
[5]
S. Michel et al., “Environmental monitoring 2.0,” in Data Engineering,
2009. ICDE’09. IEEE 25th International Conference on.
IEEE, 2009,
pp. 1507–1510.
[6]
M. Allard, “Noaa’s nowcoast: A gis-web mapping portal to discover
and display real-time coastal observations, satellite imagery and noaa
forecasts,” in 15th Symposium on Education, 2006.
[7]
C. Shen et al., “Informing the design of direct-touch tabletops,” IEEE
Comput. Graph. Appl., vol. 26, no. 5, Sep. 2006, pp. 36–46. [Online].
Available: http://dx.doi.org/10.1109/MCG.2006.109
[8]
M. Kaltenbranner, S. Jorda, G. Geiger, and M. Alonso, “The reactable*:
A collaborative musical instrument,” in Enabling Technologies: Infras-
tructure for Collaborative Enterprises, 2006. WETICE’06. 15th IEEE
International Workshops on.
IEEE, 2006, pp. 406–411.
[9]
C. Forlines and C. Shen, “Dtlens: multi-user tabletop spatial data
exploration,” in Proceedings of the 18th annual ACM symposium on
User interface software and technology.
ACM, 2005, pp. 119–122.
[10]
P. Dietz and D. Leigh, “Diamondtouch: a multi-user touch technology,”
in Proceedings of the 14th annual ACM symposium on User interface
software and technology.
ACM, 2001, pp. 219–226.
[11]
A. Taivalsaari and T. Mikkonen, “The web as an application platform:
The saga continues,” in Software Engineering and Advanced Applica-
tions (SEAA), 2011 37th EUROMICRO Conference on, Aug 2011, pp.
170–174.
[12]
Html5
draft
speciﬁcation.
[Online].
Available:
http://www.w3.org/TR/html5/ [retrieved: Jun., 2014]
[13]
Webgl
1.0
speciﬁcation.
[Online].
Available:
http://www.khronos.org/registry/webgl/specs/latest/1.0/
[retrieved:
Jun., 2014]
[14]
Websocket
speciﬁcation
(rfc6455).
[Online].
Available:
https://tools.ietf.org/html/rfc6455 [retrieved: Jun., 2014]
[15]
Eventsource
speciﬁcation.
[Online].
Available:
http://dev.w3.org/html5/eventsource/ [retrieved: Jun., 2014]
[16]
Http
speciﬁcation
(rfc2616).
[Online].
Available:
http://www.w3.org/Protocols/rfc2616/rfc2616.html
[retrieved:
Jun.,
2014]
[17]
jquery library. [Online]. Available: http://jquery.com/ [retrieved: Jun.,
2014]
[18]
dot.js template library. [Online]. Available: http://olado.github.io/doT/
[retrieved: Jun., 2014]
[19]
Apache httpd. [Online]. Available: http://httpd.apache.org/ [retrieved:
Jun., 2014]
[20]
Geoserver. [Online]. Available: http://geoserver.org/ [retrieved: Jun.,
2014]
[21]
Openlayers library. [Online]. Available: http://openlayers.org/ [retrieved:
Jun., 2014]
[22]
Cesiumjs library. [Online]. Available: http://cesiumjs.org [retrieved:
Jun., 2014]
[23]
R. Harper, Being human: Human-computer interaction in the year 2020.
Microsoft Research, 2008.
[24]
S. S. Krupenia and C. Aguero, “Asset distribution with a multitouch
table,” in Proceedings of the 9th International ISCRAM Conference.
2012, 2012.
[25]
N. Wahab and H. B. Zaman, “The signiﬁcance of multi-touch table in
collaborative setting: How relevant this technology in military decision
making,” Applied Mechanics and Materials, vol. 278, 2013, pp. 1830–
1833.
[26]
M. Avila-Garcia, A. E. Trefethen, M. Brady, and F. Gleeson, “Using
interactive and multi-touch technology to support decision making in
multidisciplinary team meetings,” in Computer-Based Medical Systems
(CBMS), 2010 IEEE 23rd International Symposium on.
IEEE, 2010,
pp. 98–103.
[27]
R. Kruger, S. Carpendale, S. D. Scott, and S. Greenberg, “Roles
of orientation in tabletop collaboration: Comprehension, coordination
and communication,” Computer Supported Cooperative Work (CSCW),
vol. 13, no. 5-6, 2004, pp. 501–537.
[28]
OASIS, “Common alerting protocol version 1.2,” 2010. [Online]. Avail-
able: http://docs.oasis-open.org/emergency/cap/v1.2/CAP-v1.2-os.html
100
Copyright (c) IARIA, 2014.     ISBN:  978-1-61208-356-8
AMBIENT 2014 : The Fourth International Conference on Ambient Computing, Applications, Services and Technologies

