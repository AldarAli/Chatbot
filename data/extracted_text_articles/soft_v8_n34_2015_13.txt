450
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
Recognition of Human Faces in the Presence of Incomplete Information  
 
Soodeh Nikan and Majid Ahmadi 
Electrical and Computer Engineering 
University of Windsor 
Windsor, ON, Canada 
nikan@uwindsor.ca and ahmadi@uwindsor.ca
 
 
 
 
Abstract—Proposed face recognition in this paper is a block 
based approach. Gabor magnitude-phase centrally symmetric 
local binary pattern has been used to extract directional texture 
characteristics of face at different spatial frequencies. Centrally 
symmetric local binary pattern is applied on the sub-blocks of 
magnitude and phase responses of Gabor images, which is the 
important contribution of the proposed work. Sparse classifier 
is employed as local classifier to find the sub-blocks class labels. 
We have evaluated the performance of the proposed algorithm 
on AR and ORL databases. In real world scenarios, partial face 
images are available to recognize the identity of an unknown 
individual. By comparing the recognition accuracy on the 
recognition results of image sub-blocks, we find the location and 
size of the most effective face sub-region for identification. 
Moreover, Chi-Square weighted fusion of image sub blocks at 
decision level leads to significantly improved recognition 
accuracy. We also evaluate the performance of the proposed 
algorithm in the presence of incomplete information for low 
resolution and occluded images.  
Keywords-face recognition; block based; effective subregion; 
partial image; incomplete information. 
I. 
 INTRODUCTION 
Face recognition is widely used as a biological 
identification technique which is applied to recognize an 
unknown individual by analyzing and comparing their facial 
image to the available database of known identities. It has a 
wide range of applications such as social networking, access 
control, forensic images, surveillance cameras, and law 
enforcement [1]. The accuracy of face recognition is affected 
by challenging conditions due to partial occlusion, low 
resolution, poor illumination, head pose variation, facial 
expression and blur effect. In recent years, many identification 
techniques were proposed in order to increase the accuracy of 
face recognition versus degrading conditions [1]. In holistic 
based approaches the whole face area is employed to extract 
features and deciding on the identity label. A robust image 
representation against occlusion and illumination variation 
was proposed in [2] using the combination of subspace 
learning and cosine-based correlation approach, which was 
applied on the orientation of gradient. However, local based 
techniques by dividing image into sub-regions and fusion of 
the extracted features or classification results, leads to 
robustness against variations in the appearance. Local Gabor 
binary pattern histogram (LGBPH) technique was proposed in 
[3], where the local binary pattern (LBP) histograms of sub-
blocks of Gabor magnitude images were combined. Different 
sub-blocks were differentiated in concatenation of features, by 
assigning a Kullback–Leibler divergence (KLD) weight to the 
corresponding sub-blocks. In [4] a block-based face 
recognition technique was proposed by extracting uniform 
LBP histograms. The results of local nearest neighbour 
classifiers were combined using an entropy weighted decision 
fusion to reduce the effect of sub-blocks with less information 
content. Local phase quantization (LPQ) and multi-scale LBP 
were applied on the proposed gradient based illumination 
insensitive representation of image sub-blocks in [5]. 
Weighted fusion at score and decision level found the identity 
of unknown individuals. In [6] the gray values of pixels in 
image sub-regions were concatenated and class specific multi 
sub-region based correlation filter bank technique (MS-CFB) 
was calculated for the training samples and test images. Local 
polynomial approximation (LPA) filter and directional scale 
optimization was proposed in [7]. LBP directional images 
were divided into sub-blocks at four levels. Finally, linear 
discriminant analysis (LDA) was applied on the concatenation 
of local histograms at four levels. Nevertheless, some facial 
areas that contain non-discriminative information can be 
excluded in the recognition process and computational 
complexity is reduced by analyzing fewer image sub-blocks 
instead of the whole face area [1]. We need to find the most 
effective sub-image to identify an unknown individual. This 
technique is very effective when some parts of the face are 
occluded by an external object. In some application, such as 
images acquired by surveillance cameras or forensic images, 
we have incomplete information from low resolution or partial 
face images. In some cases only a partial image of the face 
with a small amount of discriminative information is 
available. The proposed approach in [8] addressed partial face 
recognition using an alignment-free combination of multi-
keypoint descriptors (MKD) and sparse representation-based 
classification (SRC). A set of MKDs were applied on images 
in the gallery set and a partial probe image was represented as 
a sparse linear combination of gallery dictionary.  
This paper is built upon our proposed work in [1]. 
However, in this work, we proposed a weighted fusion 
technique to differentiate the effect of image sub regions on 
the identification decision based on their discriminative 
effectiveness. The image is divided into sub-blocks and the 
proposed face recognition technique, which is shown in Fig. 
1, is applied on local areas. The size and location of the most 
effective area of the face in identification process has been 
investigated through the experiments on four different 
databases. We proposed Gabor magnitude-phase centrally  

451
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 1.  Block diagram of the proposed face recognition technique [1]. 
 
symmetric local binary pattern (GMP-CS-LBP) technique as 
feature extractor based on the symmetry in a local area around 
image pixels [1, 9]. In order to include the magnitude and 
phase information of the local characteristics of face, which 
are insensitive against appearance changes, we have applied 
texture descriptor on the magnitude and phase responses of 
Gabor images. The extracted features are concatenated for 
each image sub-block. Sparse classifier is employed on image 
sub-regions to find the local class labels [1]. In this paper, we 
propose a weighted majority voting (MV) scheme, which 
combines local decisions. The Chi-Square (CSQ) distance 
measurement [10] of the histograms of image sub blocks is 
applied as the local weights. We also evaluate the performance 
of the proposed technique in the presence of incomplete 
information due to low resolution and partial occlusion.    
The rest of paper is organized as follows. In Section II, the 
configuration of feature extraction technique is explained in 
detail. Section III describes the classification approach. 
Section IV provides the experimental results. The paper is 
concluded in Section V. 
II. 
FEATURE EXTRACTION 
The proposed GMP-CS-LBP feature extraction in this 
paper is the fusion of magnitude and phase information of 
Gabor coefficients. Configuration of the proposed feature 
extraction technique is shown in Fig. 1 [1].  
A. Gabor Filter 
Gabor filter extracts the characteristics of signal at 
different scales and orientations, which resembles the 
mammalia response of vision cells. In order to acquire 
directionally selective local properties of a face image at 
various spatial frequencies, which are invariant against 
appearance changes due to expression and illumination 
variations, 2-D Gabor filters at 𝑆𝑚𝑎𝑥 scales and 𝑂𝑚𝑎𝑥 
orientaions are convolved by image [1]. Gabor filters are 
obtained as follows by ranging the spatial scale 𝑠 from 1 to 
𝑆𝑚𝑎𝑥 and orientation 𝑜 from 1 to 𝑂𝑚𝑎𝑥 [11, 12],   
         𝜓𝑠,𝑜(𝑥, 𝑦) =
𝑞𝑜,𝑠
2
𝜎2  . 𝑒
−(
𝑧2𝑞𝑠,𝑜
2
2𝜎2 )
 . [𝑒(𝑗𝑧𝑞𝑠,𝑜) − 𝑒
(−𝜎2
2 )],     (1) 
 
where 𝑞𝑠,𝑜 = 𝑞𝑠exp (𝑗𝜃𝑜) = [𝜋 2(√2)𝑠]
⁄
exp (𝑗𝜋 𝑜 8
⁄ ) (in 
this paper, we defined 5 scales and 8 orientations). 𝑧 = (𝑥, 𝑦), 
and 𝜎 = 2𝜋 [11, 12]. The magnitude and phase responses of 
Gabor filtered image are shown in Fig. 1 [1]. 
B. Centrally Symmetric Local Binary Pattern (CS-LBP) 
One of the most powerful local descriptors where the 
texture information are analysed by comparing the intensity 
value of local texture in a small neighbourhood and supress 
the monotonic offset of neighbour pixels is local binary 
pattern (LBP) analysis. LBP is a very fast technique and easy 
to execute [9, 12]. In a circular neighbourhood with radius R 
and P neighbours around each image pixel, we compared the 
neighbours with the centre pixel and depending on the sign of 
their difference a 1 or 0 value (for positive difference or 
negative difference, respectively) is assigned to the 
corresponding neighbours. Therefore, a P-bit binary pattern is 
associated with the centre pixel. Thus, for image pixels we 
have decimal values ranging from 0 to 2P, which are used to 
construct a histogram of 2P-bin as the texture features. We can 
reduce the number of histogram bins, which decreases the size 
of extracted features by employing the symmetry in the local 
area around each pixel. In centrally symmetric LBP (CS-LBP) 
technique [9], the centre symmetric pairs of neighbours are 
compared instead of comparing each of them with the centre, 
as shown in Fig. 2. Therefore, the range of decimal values is 
reduced to 0 − 2(P 2
⁄ ) and the stability of the extracted features  

452
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 2.  Calculation of CS-LBP for a pixel at (𝑢, 𝑣) [1]. 
against flat texture is increased. The calculation of decimal 
value associated with the binary patterns is as follows [1, 9], 
𝐶𝑆𝐿𝐵𝑃𝑑𝑒𝑐(𝑢, 𝑣) =
∑
𝐹 (𝐼𝑙 − 𝐼𝑙+(𝑃 2
⁄ ))
(𝑃 2
⁄ )−1
𝑙=0
2𝑙,  
                   𝑤ℎ𝑒𝑟𝑒   𝐹(𝑥) = {
1                𝑥 ≥ 𝑇ℎ.
0          𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒.
                  (2) 
(𝑢, 𝑣) is the position of centre pixel and 𝐼𝑙 is the intensity 
value of l𝑡ℎ neighbor of the centre. R and P are 1 and 8 in this 
paper. In order to increase the stability against flat areas, the 
intensity differences between centre symmetric pairs are 
compared to a threshold value (𝑇ℎ) greater than 0, which is 
used as threshold in LBP technique [9]. The value that is 
assigned as threshold is defined in the following section [1].  
C. Local GMP-CS-LBP Histograms 
In order to employ magnitude and phase information 
simultaneously, CS-LBP technique is applied on the 
magnitude and phase responses of Gabor images at different 
scales and orientations. However, the threshold value in (2) is 
different for comparing magnitude or phase information.  
Through the exhaustive search, in this paper we employ 0.1 
as the magnitude threshold and 90° as phase threshold. 
Following by calculation of the binary patterns and the 
corresponding decimal values of image pixels and 
constructing histograms, the 2(P 2
⁄ )-bin magnitude and phase 
histograms are concatenated [1].  
Furthermore, to find the most effective sub region of face 
image on the identification accuracy, we divide Gabor images 
into rectangular non overlapping sub blocks of 𝑚 × 𝑛 pixels. 
By concatenating the histograms of magnitude and phase 
responses of all scales and orientations of Gabor responses, 
we obtain a histogram of 2(P 2)
⁄
+1 × 𝑆𝑚𝑎𝑥 × 𝑂𝑚𝑎𝑥 bins for 
each image sub region [1].    
III. 
SPARSE CLASSIFICATION 
Local classifiers are based on the sparsest representation 
of the probe sample using the combination of corresponding 
gallery samples of the same class label [13]. Image samples, 
which are belonging to the same individual, lie on a linear 
subspace [1].  
                            𝑔 = [𝑔1, 𝑔2, 𝑔3, … , 𝑔𝑀].                           (3) 
                          𝑔𝑖 = [𝑓1
𝑔, 𝑓2
𝑔, 𝑓3
𝑔, … , 𝑓𝑁
𝑔].                          (4) 
Where g is gallery dictionary, which is including all gallery 
samples in the database. 𝑔𝑘 is matrix of 𝑘𝑡ℎ class of subject, 
which consists of gallery feature vectors as its columns (𝑓𝑘
𝑔 is 
the feature vector of the 𝑘𝑡ℎ sample in 𝑔𝑘), where 𝑀 and 𝑁 
are the number of classes and gallery samples per class, 
respectively. Therefore, using the matrix of gallery dictionary 
and a coefficient vector we can define the feature vector of a 
probe sample as a linear combination as follows [1, 13],   
                                      𝑓𝑖
𝑝 = 𝑔. 𝐵.                                     (5) 
Where 𝐵 = [0,0, … ,0, 𝛽1
𝑘, 𝛽2
𝑘, … , 𝛽𝑁
𝑘, 0,0, … ,0] and 𝛽𝑗
𝑘is the 
𝑗𝑡ℎ coefficient corresponding to the 𝑘𝑡ℎ class. The sparsest 
representation of probe sample can be achieved, if only the 
coefficients associated with class label of the probe sample are 
non-zero.  Those coefficients are calculated using the 𝑙1-norm 
solution of equation (5) and the identity label of the probe 
sample as follows [1, 13]. 
      (𝑙1):      𝐵̂1 = 𝑎𝑟𝑔𝑚𝑖𝑛‖𝐵‖1           𝑤ℎ𝑖𝑙𝑒  𝑓𝑝 = 𝑔. 𝐵.      (6) 
IV. 
DECISION FUSION 
In order to combine the local result on the image sub 
blocks and come up with a final decision on the identity of the 
unknown probe sample, majority voting scheme is applied as 
the decision fusion strategy. The votes of the image sub blocks 
are combined by adding up the local votes for each class of 
subject. Finally, the class of identity with maximum total 
votes is selected as the final decision [1].     
V. 
LOCAL WEIGHTING 
In order to differentiate between the effects of image sub 
blocks on the final decision on the identity of the probe 
sample, local weights are calculated on image sub regions. In 
this paper, we calculate the Chi-Square (CSQ) distance [10] 
between the histograms of probe image sub blocks and the 
local histograms in the class-prototype of corresponding class 
of probe sub-block. The class-prototype (CP) image in the 
proposed approach in this paper is the average image of all 
gallery samples belonging to each class of subject as follows. 
                 𝑊𝐶𝑆(𝑃𝐼𝑚, 𝐶𝑃𝑚) = ∑
(𝑃𝐼𝑏𝑗
𝑚−𝐶𝑃𝑏𝑗
𝑚)2
𝑃𝐼𝑏𝑗
𝑚+𝐶𝑃𝑏𝑗
𝑚
𝑁𝑏
𝑗=1
.                  (7) 
              𝐶𝑃𝑘 =
1
𝑁𝑘 ∑
𝑔𝑘,𝑙 
𝑁𝑘
𝑙=1
,        𝑘 = 1, 2, … , 𝑁𝑐.                (8) 
Where 𝑃𝐼𝑏𝑗
𝑚 and 𝐶𝑃𝑏𝑗
𝑚 are the 𝑗𝑡ℎ histogram bin in the 𝑚𝑡ℎ sub-
block of the probe image (PI) and class-prototype images, 
respectively. 𝐶𝑃𝑘 is the class-prototype of 𝑘𝑡ℎ class of subject. 
𝑁𝑐 is the number of classes and 𝑁𝑘 is the number of gallery 
samples belonging to 𝑘𝑡ℎ class (𝑔𝑘,𝑙 ) [5]. 

453
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
VI. 
EXPERIMENTAL RESULTS 
In order to evaluate the performance of proposed face 
recognition technique and effectiveness of image sub blocks 
on the recognition accuracy, we adopt four popular AR, ORL, 
LFW and FERET databases. We conduct four experiments 
and apply the identification algorithm on the 128 × 128 pixel 
images in the databases [1].   
A. Face databases 
 
AR Database: AR face database includes 2600 images 
of 100 individuals (50 men and 50 women) [14]. Each 
subject has 26 images taken at two different sessions 
in two weeks (13 images per session). The images in 
the database are affected by illumination variation, 
facial expression and partial occlusion. We have 
employed non-occluded images in session 1 as gallery 
set and non-occluded images in session 2 with 
appearance changes in different time as probe set. 
Sample images of one subject in AR database are 
shown in Fig. 3a [1].  
 
ORL Database: Olivetti research lab (ORL) database 
consists of 40 individuals with 10 images per subject 
and appearance variation due to illumination changes, 
different time of acquiring image, facial expressions 
(open/close eyes and smiling/not smiling), up to 20 
degree tilting and scales [15]. We randomly used 5 
samples per individual in the gallery set and the 
remaining 5 images per subject in the probe set. Thus, 
we have 200 images per set. Figure 3b shows gallery 
and probe image samples of one individual in ORL 
database [1].  
 
LFW Database: Labeled faces in the wild (LFW) 
database includes 13,233 web-downloaded images of 
5749 individuals [16]. LFW-a is the aligned version 
of LFW. Images are affected by pose and illumination 
changes, occlusion, blur, low resolution, race and 
aging effect in real-world scenarios. Some samples of 
LFW-a images are shown in Fig. 3c. In this paper, we 
randomly select 20 subjects with 12 images and less 
than 30 degree pose variation. Gallery set consists of 
the first half of 12 samples per individual ad probe set 
includes the rest.  
 
FERET Database: The Face Recognition Technology 
(FERET) program database [17] is a huge database 
consists of 14,051 grayscale images in different 
subsets based on various illumination, facial 
expression and pose conditions. In this experiment, 
we use subset ba, bj and bk of 200 individuals and one 
images per subject in each subset. Subset ba includes 
regular frontal images. Subset bj consists of 
alternative frontal images corresponding to ba set. 
Subset bk also contains frontal images corresponding 
to ba but with different lighting conditions. 400 
images in subsets bj and bk are used as the gallery set 
and subset ba is the probe set. Fig. 3d shows some 
samples of the probe images [5].  
 
Figure 3.  Sample images of one subject in (a) AR database, (b) ORL 
database, (c) LFW database, (d) FERET database. 
B. Partial Recognition Based on the Image Subblocks 
In this experiment we employ the proposed face 
recognition algorithm using an image sub-block at different 
locations and sizes. In order to find the effective size of 
selected sub-block, we find the accuracy of face recognition 
versus block size, which is shown in Fig. 4. It is shown that 
for all four databases, block size 32 × 16 pixels leads to the 
highest recognition accuracy. The location of the sub-block is 
near to the eye area. Fig. 5 shows the selected subregion for 
AR, ORL, LFW and FERET databases [1].  
C. Decision Fusion for Selected Size of Subblock  
Based on the results of previous section, the highest 
recognition accuracy is obtained at the block size of 32x16 
pixels for four face databases. In this experiment, we 
employed the most effective block size and apply CSQ-
weighted majority voting scheme by adding up the votes of  

454
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 4.  Recognition accuracy (%) of image subblocks for different 
block sizes. 
 
 
Figure 5.  Location of the most effective image subregion: (a) AR 
database, (b) ORL database, (c) LFW database, (d) FERET database. 
 
Figure 6.  Sample images of four databases at different resolutions 
(128x128, 64x64, 32x32, 16x16 and 8x8 pixels, respectively from left to 
right):  (a) AR database, (b) ORL database, (c) LFW database, (d) FERET 
database. 
local classification results of image sub-blocks and finding the 
class label with maximum vote as the final decision. The result 
of sub-blocks fusion is shown in Table I and compared to the 
accuracy of other existing techniques, which shows the 
effectiveness of the proposed face recognition technique.   
However, by employing the recognition process using 
only one sub-block of  32 × 16 pixels rather than the whole 
image or fusion of local recognition results, the computational 
cost is reduced up to 
1
40 [1].  
D. Effect of Low Resolution  
In this experiment, based on the results of previous 
sections, we use the block size of 32x16 pixels for images of 
size 128x128 pixels and apply the proposed face recognition 
technique on image sub blocks and find the final decision 
using majority voting scheme. We aimed to evaluate the effect 
of low resolution images on the recognition accuracies of four 
databases. In order to verify the effect of resolution, we 
reduced the size of images from 128x128 to 64x64, 32x32, 
16x16 and 8x8 pixels, respectively, and reduced the block 
sizes, relatively. Figure 6 shows images of four adopted 
databases at different resolutions. The recognition accuracy 
versus the image size is illustrated in Fig. 7. Reducing the 
resolution of images, degraded the accuracy of face 
recognition. However, the proposed technique shows relative 
stability against decreasing the resolution up to size of 32x32 
pixels.  
E. Effect of Partial Occlusion  
In this experiment, we evaluated the effect of partial 
occlusions on the face, which included non-facial information, 
on the recognition accuracy. We conduct two experiments in 
this section as follows. 
 
 
Figure 7.  Recognition accuracy (%) of image subblocks for different 
block sizes. 
TABLE I.  
RECOGNITION ACCURACY (%) OF DIFFERENT ALGORITHMS.   
Block Size 
Recognition Accuracy (%) 
AR 
ORL 
LFW 
FERET 
LBP+MV [4] 
93.42 
95.50 
63.81 
95 
CS-LBP+MV 
80.42 
91.50 
53.33 
56 
LGBFR [5] 
99 
98 
63.81 
96.5 
MS-CFB [6] 
95 
- 
- 
- 
SADTF [7] 
- 
98.50 
- 
- 
LCCR [18] 
95.86 
98 
- 
- 
Proposed Method  
(Decision Fusion 
using weighted MV) 
99.42 
98.50 
72.38 
95 
0
5
10
15
20
25
30
35
40
45
50
55
60
65
70
75
80
85
90
95
100
8x8
8x16
16x8
8x32
32x8
8x64
64x8
8x128
128x8
16x16
16x32
32x16
16x64
64x16
16x128
128x16
32x32
32x64
64x32
32x128
128x32
64x64
64x128
128x64
128x128
Recognition Accuracy %
Block Size (pixel)
ORL
AR
LFW
FERET
0
10
20
30
40
50
60
70
80
90
100
128x128
64x64
32x32
16x16
8x8
Recognition Accuracy %
Resolution (pixel)
ORL
AR
LFW
FERET

455
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 8.  Occluded images of one subject in AR database at two sessions. 
 
TABLE II.  
RECOGNITION ACCURACY (%) OF DIFFERENT ALGORITHMS.   
Method 
Sunglasses 
Scarf 
E-GV-LBP-M[19] 
47.22 
82.78 
E-GV-LBP-P[19] 
44.07 
86.67 
SADT[20] 
95.5 
75 
Proposed Method  
(Decision Fusion using weighted MV) 
88.83 
97.17 
 
 
Real occlusion: AR database contains occluded 
images with sunglasses and scarf on the face, which 
are real occlusions. Figure 8 shows some occluded 
samples in AR database. We used gallery set of 200 
images, by employing just two non-occluded images 
per subject with neutral expression in sessions 1 and 
2. Two probe sets of 600 images consist of 6 occluded 
images per individual with scarf and 6 with sun 
glasses from both sessions, respectively. Table II 
shows the recognition accuracy of the proposed 
approach compared to the previous works.        
 
Unreal occlusion: In order to evaluate the 
performance of the proposed approach in the presence 
of incomplete information, we put a mandrill image 
and a black box at random positions on the images of 
the probe set of LFW database and varied the size of 
occlusion box form 0% to 90% of the complete image 
size (128x128 pixels). The accuracy percentage of 
identification versus the percentage of the occlusion 
box coverage is shown in Fig. 9. Figure 10 shows 
occluded images of one subject in the LFW database 
with different size of occlusion box. The recognition 
breakdown point of the mandrill occlusion occurs at 
50% of the occlusion coverage while for the black box 
it occurs at 70% coverage, from where the 
identification accuracy decreases drastically. This is 
due to the fact that mandrill image contains facial 
components similar to the human’s which leads to the 
misclassification. 
 
VII. CONCLUSION 
A block based face recognition algorithm has been 
proposed in this paper by dividing the magnitude and phase 
responses of Gabor filtered images. CS-LBP is applied on 
image sub-blocks and concatenation of local histograms at 
different scales and orientations gives the features of image 
sub-regions. Weighted majority voting is applied to combine 
the local decisions, made by sparse classifiers, which leads to 
the final decision on the identification of unknown 
individuals. Chi-square distance measurements are adopted as 
the local weights. The proposed approach outperforms the 
previous works for AR, ORL, LFW and FERET databases. 
Evaluating the recognition accuracy of different sub-regions 
of the face images gives the size and location of the most 
effective local area, which reduces computational complexity 
up to 2.5% and is very close the eyes area [1]. Moreover, the 
performance of proposed technique is verified versus the 
presence of incomplete information by resolution reduction 
and partial real and unreal occlusion. Reducing the resolution 
of images, degrades the accuracy of face recognition. 
However, the proposed technique shows relative stability 
against decreasing the resolution up to size of 32x32 pixels 
and the reduction in the identification accuracy is not 
noticeable. The proposed technique outperforms the previous 
works for real occlusion by scarf and sunglasses on images in 
the AR database. Based on the results partial recognition 
experiment, eyes area is the most effective sub region. 
Covering the eyes area by sunglasses leads to more reduction 
in the recognition accuracy. In addition, for artificial 
occlusion, occluding the image by more than 70% of the face 
area with black box and more than 50% with mandrill image, 
reduces the identification accuracy drastically. 
 Although the recognition results in the presence of 
incomplete information are impressive, further research to 
improve the applicability of the proposed technique to more 
challenging scenarios is required. Moreover, adopting other 
weighting techniques in the decision fusion to reduce the 
effect of undesirable regions is a possible direction to extend 
this work.  
 
 
Figure 9.  Recognition accuracy (%) of image subblocks for different 
block sizes.
0
5
10
15
20
25
30
35
40
45
50
55
60
65
70
0%
10% 20% 30% 40% 50% 60% 70% 80% 90%
Recognition Accuracy %
Occlusion Coverage %
Mandrill
Black-Box

456
International Journal on Advances in Software, vol 8 no 3 & 4, year 2015, http://www.iariajournals.org/software/
2015, © Copyright by authors, Published under agreement with IARIA - www.iaria.org
 
Figure 10.  Recognition accuracy (%) of image subblocks for different block sizes.
REFERENCES 
[1] S. Nikan and M. Ahmadi, “Partial GMP-CS-LBP face 
recognition using image subblocks,” Proc. International 
Conference on Systems (ICONS15), Barcelona, Spain, April 
2015, pp. 36-39. 
[2] G. Tzimiropoulos, S. Zafeiriou, and M. Pantic, “Subspace 
learning from image gradient orientations,” IEEE Transactions 
on Pattern Analysis and Machine Intelligence, vol. 34, pp. 
2454-2466, 2012. 
[3] W. Zhang, S. Shan, X. Chen, and W. Gao, “Local Gabor binary 
patterns based on Kullback–Leibler divergence for partially 
occluded face recognition,” IEEE Signal Processing Letters, 
vol. 14, pp. 875-878, 2007. 
[4] S. Nikan and  M. Ahmadi, “Human face recognition under 
occlusion using LBP and entropy weighted voting,” Proc. 
International Conference on Pattern Recognition (ICPR12), 
Tsukuba, November 2012, pp. 1699-1702. 
[5] S. Nikan and M. Ahmadi, “Local Gradient-Based Illumination 
Invariant Face Recognition using LPQ and Multi-Resolution 
LBP Fusion,” IET Image Processing, vol. 9, pp. 12-21, 2015. 
[6] Y. Yan, H. Wang, and D. Suter, “Multi-subregion based 
correlation filter bank for robust face recognition,” Pattern 
Recognition, vol. 47, pp. 3487–3501, November 2014. 
[7] R. Mehta, J. Yuan, and K. Egiazarian, “Face recognition using 
scale-adaptive directional and textural features,” Pattern 
Recognition, vol. 47, pp. 1846-1858, 2014. 
[8] S. Liao, A. K. Jain, and S. Z. Li, “Partial face 
recognition:alignment-free approach,” IEEE Transactions on 
Pattern Analysis and Machine Intelligence, vol. 35, pp. 1193-
1205, May 2013. 
[9] M. Heikkila, M. Pietikainen, and C. Schmid, “Description of 
interest regions with local binary patterns,” Pattern 
Recognition, vol. 42, pp. 425-436, 2009. 
[10] T. Ahonen, A. Hadid, and M. Pietikainen, “Face recognition 
with local binary patterns,” Springer Computer Vision, vol. 
3021, pp. 469-481, 2004. 
[11] Z. Lei, S. Liao, M. Pietikäinen, and S. Li, “Face recognition by 
exploring information jointly in space, scale and orientation,” 
IEEE Trans. Image Process., vol. 20, pp. 247-256, 2011. 
[12] S. Nikan and M. Ahmadi, “Classification fusion of global & 
local G-CS-LBP features for accurate face recognition,” Proc. 
Int. Conf. on Testing and Measurement: Techniques and 
Applications (TMTA’15), Phuket, Thailand, pp. 303-307, 
January 2015. 
[13] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, 
“Robust face recognition via sparse representation,” IEEE 
Transactions on Pattern Analysis and Machine Intelligence, 
vol. 31, pp. 210-227, 2009. 
[14] A. Martinez and R. Benavente, “The AR face database,” CVC 
Technical Report, vol. 24, 1998. [Online]. Available from: 
http:// 
www2.ece.ohio-state.edu/~aliex/ARdatabase.html/ 
2015.11.25. 
[15] The AT&T Laboratories Cambridge website, Available from: 
http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.
html/ 2015.11.25. 
[16] G.B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller, 
“Labeled Faces in the Wild: a database for studying face 
recognition in unconstrained environments,” Technical Report, 
University of Massachusetts, 2007. 
[17] P.J. Phillips, H. Moon, S.A. Rizvi, and P.J. Rauss, “The 
FERET 
evaluation 
methodology 
for 
face-recognition 
algorithms,” IEEE Transaction on Pattern Analysis and 
Machine Intelligence, vol. 22, pp. 1090-1104, 2000. 
[18] X. Peng, L. Zhang, Z. Yi, and K. K. Tan, “Learning locality-
constrained collaborative representation for robust face 
recognition,” Pattern Recognition, vol. 47, pp. 2794-2806, 
September 2014. 
[19] Z. Lei, S. Liao, M. Pietikäinen, and S. Li, “Face recognition by 
exploring information jointly in space, scale and orientation,” 
IEEE Transactions on Image Processing, vol. 20, pp. 247-256, 
2011. 
[20] R. Mehta, J. Yuan, and K. Egiazarian, “Face recognition using 
scale-adaptive directional and textural features,” Pattern 
Recognition, vol. 47, pp. 1846-1858, 2014. 

