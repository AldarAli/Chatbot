An Investigation on the Relative Cost of Function Point Analysis Phases  
 
Luigi Lavazza 
Dipartimento di Scienze Teoriche e Applicate 
Università degli Studi dell’Insubria 
Varese, Italy 
email: luigi.lavazza@uninsubria.it 
 
 
Abstract— Function Point Analysis (FPA) is widely used, 
especially to quantify the size of applications in the early stages 
of development, when effort estimates are needed. However, 
the measurement process is often too long or too expensive, or 
it requires more knowledge than available when development 
effort estimates are due. To overcome these problems, early 
size estimation methods have been proposed, to get 
approximate estimates of Function Point (FP) measures. In 
general, early estimation methods (EEM's) adopt measurement 
processes that are simplified with respect to the standard 
process, in that one or more phases are skipped. EEM's are 
considered effective; however there is little evidence of the 
actual savings that they can guarantee. To this end, it is 
necessary to know the relative cost of each phase of the 
standard FP measurement process. This paper presents the 
results of a survey concerning the relative cost of the phases of 
the standard FP measurement process. It will be possible to use 
data provided in the paper to assess the expected savings that 
can be achieved by performing an early estimation of FP size, 
instead of properly measuring it. 
Keywords- functional size measurement; Function Point 
Analysis; IFPUG Function Points; measurement process; cost of 
measurement. 
I. 
 INTRODUCTION 
FPA [1][2][3][4] is widely used. Among the reasons for 
the success of FPA is that it can provide measures of size in 
the early stages of software development, when they are 
most needed for cost estimation. 
However, FPA performed by a certified FP consultant 
proceeds at a relatively slow pace: between 400 and 600 FP 
per day, according to Capers Jones [5], between 200 and 300 
FP per day according to experts from Total Metrics [6]. 
Consequently, measuring the size of a moderately large 
application can take too long, if cost estimation is needed 
urgently. Also, the cost of measurement can be often 
considered excessive by software developers. In addition, 
cost estimates may be needed when requirements have not 
yet been specified in detail and completely. 
To overcome the aforementioned problems, EEM's that 
provide approximate values of FP measures have been 
proposed. A quite comprehensive list of such methods is 
given in [7]. 
The goal of the work presented here is to assess the cost 
of the measurement activities (detailed in Section II.B). 
However, as mentioned in the introduction, there is little 
agreement on the cost of FP measurement: for instance, 
Capers Jones [5] and Total Metrics [6] provide quite 
different evaluations. Therefore, it appeared more viable to 
pursue an evaluation of the relative cost of the measurement 
phases. In this way, we will be able to assess how much we 
save ˗in terms of measurement effort, hence ultimately of 
money˗ by skipping a measurement phase, i.e., by not 
performing one of the activities of the standard measurement 
process. In fact, if a manger knows that applying the standard 
measurement 
process 
in 
her 
organization 
takes 
X 
PersonHours per FP, and a simplified measurement process 
allows for saving 70% of the effort, she can easily conclude 
that in her organization the application of the simplified 
process will take 0.7X PersonHours. 
The paper is structured as follows. Section II reports a 
few basic concepts of FPA. Section III describes how the 
surveys was carried out, illustrates the results of the survey 
and discusses the threats to the validity of the study. Section 
IV accounts for related work. Finally, Section V draws 
conclusions and briefly sketches future work. 
II. 
FUNCTION POINT ANALYSIS CONCEPTS 
FPA aims at providing a measure of the size of the 
functional specifications of a given software application. 
A. The model of the software being measured according to 
FPA 
FPA addresses functional specifications that are 
represented according to a specific model. The model of 
functional specifications used by FPA is given in Fig. 1. 
Briefly, Logical files are the data processed by the 
application, and transactions are the operations available to 
users. The size measure in FP is computed as a weighted 
sum of the number of Logical files and Transactions. The 
weight of logical data files is computed based on the Record 
Elements Types (RET), i.e., subgroups of data belonging to a 
data file, and Data Element Types (DET), i.e., the elementary 
pieces of data; besides, the weight depends on whether the 
data file is within the boundaries of the application, i.e., it is 
an Internal Logic File (ILF) or it is outside such boundaries, 
i.e., it is an External Interface File (EIF). The weight of 
transactions is computed based on the Logical files involved 
–see the FTR (File Type Referenced) association in Fig. 1– 
and the DET used for I/O; besides, the weight depends on 
the "main intent" of the transaction. In fact, depending on the 
16
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-498-5
ICSEA 2016 : The Eleventh International Conference on Software Engineering Advances

main intent, transactions are classified as External Inputs 
(EI), External Outputs (EO) or External Queries (EQ). 
 
SW application functional specifications
Logical file
Transaction
Data Element Type
Record Element Type
FTR
0..*
I/O
1..*
 
Figure 1.  The model of software used in FPA. 
B. The FPA measurement process 
According to the International Function Point User 
Group 
(IFPUG) 
measurement 
manual 
[3][4], 
the 
measurement process includes the following phases: 
1. Gathering the available documentation concerning 
functional user requirements; 
2. Identifying application boundaries; 
3. Determining the measurement goal and scope; 
4. Identifying Elementary Processes (Transactions) and 
Logical Data Files; 
5. Classifying transactions as EI, EO or EQ; classifying 
files as ILF or EIF; identifying RET, DET, FTR and 
determining complexity; 
6. Calculating the functional size; 
7. Documenting and presenting the measurement. 
 
The EEM's tend to skip as many as possible of the steps 
listed above. The idea is straightforward: the less phases 
have to be performed, the faster and cheaper is the process. 
However, some activities –namely, those involved in phases 
1, 2 and 4– are preparatory of the real measurement and 
cannot be skipped. Similarly, phase 7 can hardly be avoided. 
In any case, it should be noted that the simplification of the 
measurement process can affect phases 1 and 7 as well: on 
the 
one 
hand, 
a 
simplified 
process 
requires 
less 
documentation concerning Functional User Requirements 
(FUR); on the other hand, documenting and presenting a 
simplified 
measurement 
is 
easier 
and 
faster 
than 
documenting the full-fledged measurement. 
As a final observation, the extent of phase 7 depends on 
the context and the goal of measurement: for instance, if an 
organization is measuring the size of the application to be 
developed for "internal" purposes, the documentation can be 
kept to a minimum; on the contrary, if the functional size 
measures have to be used in a bid or in establishing the price 
of a contract, the documentation to be produced has usually 
to be quite detailed, and the presentation of the measures and 
measurement has also to be accurate. In practice, the cost of 
phase 7 depends more on the context and goal of the 
measurement than on the fact that the standard process or a 
simplified process were used.  
In conclusion, EEM's address mainly phases 4, 5 and 6. 
However, there is hardly any evidence of how much you 
save if you skip any of these phases. On the contrary, some 
evidence exists that by simplifying the measurement process, 
some measurement error is introduced [19]. 
III. 
EXPERIMENT AND RESULTS 
A. The survey 
The investigation described here was performed via a 
questionnaire, which was filled by people that are 
experienced in IFPUG Function Point measurement. 
The questionnaire was published on the kwiksurveys site 
[20]. The questionnaire was publicized via several channels: 
• 
An invitation to fill out the questionnaire was sent to the 
Italian Function Point User Association (www.gufpi-
isma.org); 
• 
A similar invitation was sent to the Nesma association 
[21]; 
• 
Finally, a question was published on ResearchGate [22], 
and experts were redirected to the questionnaire URL. 
The questionnaire is reported in the appendix. It can be 
noticed that the questionnaire targets both the IFPUG [3][4] 
and the Nesma [9] measurement processes. In fact, according 
to Nesma, "[Since 1994,] owing to [...] the intensive 
cooperation between the Nesma and the IFPUG, the 
counting guidelines of the NESMA and the IFPUG 
continuously came closer and closer. [...] With the 
publication of IFPUG CPM 4.2 (2004) the last major 
differences between IFPUG and NESMA disappeared." 
Therefore, mixing data concerning the current IFPUG and 
Nesma measurement processes is perfectly safe, and the 
results found apply equally well to both measurement 
methods. 
The questionnaire was published in November 2014, and 
answers were collected until April 2015. 
B. The Results of the survey 
31 answers were collected. Even if the number is not 
very large, it is nonetheless sufficient to get a reasonably 
reliable assessment of the relative cost of FP measurement 
activities. 
Of the respondents, 21 are certified Function Point 
Specialist (CFPS), and 4 are certified Function Point 
Practitioner (CFPP). Only 6 have no certification; however, 
of these, 2 use NESMA Function Points, therefore it is 
reasonable that they do not need an IFPUG certification. 
The experience of the respondents is also quite 
reassuring: 20 respondents have been using FP measurement 
for over 10 years; only two for less than 5 years. 
It should be noted that the questionnaire does not ask for 
a specific percentage for each phase; instead, it asks to 
specify in what range the actual percentage of effort belongs. 
This choice was due to two reasons: 1) the free version of the 
17
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-498-5
ICSEA 2016 : The Eleventh International Conference on Software Engineering Advances

questionnaire provided by kwiksurveys does not support the 
collection of numeric values, and 2) it is unlikely that a 
respondent knows the exact fraction of effort that is spent in 
each phase, while it is much more probable that he/she can 
indicate the correct range. 
 
TABLE I.  
ANSWERS CONCERNING RELATIVE PHASE COSTS 
Respondent 
Phase 1 
Phase 2 
Phase 3 
Phase 4 
Phase 5 
Phase 6 
Phase 7 
1 
11-15% 
0-5% 
0-5% 
26-30% 
36-40% 
0-5% 
16-20% 
2 
16-20% 
6-10% 
0-5% 
36-40% 
6-10% 
0-5% 
16-20% 
3 
6-10% 
0-5% 
0-5% 
6-10% 
46-50% 
0-5% 
11-15% 
4 
0-5% 
0-5% 
0-5% 
66-70% 
0-5% 
0-5% 
0-5% 
5 
0-5% 
6-10% 
6-10% 
36-40% 
16-20% 
0-5% 
0-5% 
6 
0-5% 
0-5% 
46-50% 
31-35% 
0-5% 
0-5% 
0-5% 
7 
6-10% 
6-10% 
0-5% 
21-25% 
26-30% 
0-5% 
11-15% 
8 
26-30% 
11-15% 
6-10% 
11-15% 
11-15% 
0-5% 
11-15% 
9 
16-20% 
0-5% 
0-5% 
21-25% 
21-25% 
0-5% 
11-15% 
10 
0-5% 
0-5% 
0-5% 
46-50% 
31-35% 
0-5% 
0-5% 
11 
31-35% 
0-5% 
0-5% 
21-25% 
16-20% 
11-15% 
0-5% 
12 
0-5% 
0-5% 
0-5% 
16-20% 
0-5% 
0-5% 
11-15% 
13 
0-5% 
0-5% 
0-5% 
21-25% 
46-50% 
0-5% 
0-5% 
14 
0-5% 
0-5% 
0-5% 
41-45% 
26-30% 
0-5% 
0-5% 
15 
11-15% 
6-10% 
0-5% 
36-40% 
11-15% 
0-5% 
0-5% 
16 
6-10% 
0-5% 
0-5% 
51-55% 
16-20% 
0-5% 
0-5% 
17 
6-10% 
6-10% 
0-5% 
26-30% 
6-10% 
36-40% 
6-10% 
18 
0-5% 
0-5% 
0-5% 
36-40% 
36-40% 
0-5% 
0-5% 
19 
6-10% 
6-10% 
0-5% 
11-15% 
11-15% 
0-5% 
41-45% 
20 
31-35% 
16-20% 
6-10% 
26-30% 
11-15% 
0-5% 
0-5% 
21 
16-20% 
6-10% 
6-10% 
16-20% 
11-15% 
6-10% 
16-20% 
22 
16-20% 
0-5% 
0-5% 
61-65% 
0-5% 
0-5% 
0-5% 
23 
0-5% 
56-60% 
16-20% 
66-70% 
51-55% 
0-5% 
11-15% 
24 
6-10% 
6-10% 
11-15% 
26-30% 
11-15% 
11-15% 
0-5% 
25 
11-15% 
6-10% 
0-5% 
21-25% 
21-25% 
11-15% 
6-10% 
26 
6-10% 
0-5% 
0-5% 
41-45% 
21-25% 
0-5% 
6-10% 
27 
41-45% 
6-10% 
0-5% 
6-10% 
6-10% 
6-10% 
11-15% 
28 
6-10% 
16-20% 
6-10% 
31-35% 
11-15% 
0-5% 
16-20% 
29 
11-15% 
0-5% 
0-5% 
66-70% 
11-15% 
0-5% 
0-5% 
30 
21-25% 
0-5% 
0-5% 
21-25% 
21-25% 
6-10% 
0-5% 
31 
0-5% 
0-5% 
0-5% 
6-10% 
6-10% 
0-5% 
0-5% 
 
 
          
The collected data concerning the relative effort required 
by each measurement phase are given in Table I. 
When information is collected via questionnaires, it is 
always possible that some respondents do not provide correct 
data. Therefore, before proceeding to the analysis of the 
collected data, it is necessary to remove unreliable answers 
from the dataset. In our case, the following problems were 
considered: 
1) The sum of the efforts spent in each phase must be 
100%. Having asked for ranges, we expect that the sum 
of the lower bounds of the ranges is ≤ 100% (but close 
to 100%) and that the sum of the upper bounds is ≥ 
100% (but close to 100%). Respondents 12, 23 and 31 
do not satisfy these conditions: total effort is in [27%, 
60%] range for respondent 12, in [200%, 230%] range 
for respondent 23 and in [12%, 45%] range for 
respondent 
31. 
These 
are 
clearly 
meaningless 
indications, therefore they have been excluded from the 
dataset. 
2) Among the remaining respondents, it is easy to spot a 
few outliers. Respondent 19 declared a fraction of effort 
for phase 7 (Documenting and presenting the 
measurement) that is almost half the total effort and 
more than double than the other respondents'. 
Respondent 27 declared an abnormally large amount of 
effort dedicated to phase 1 (Gathering the available 
documentation concerning FUR): such a large effort 
may be required in specific contexts, but is not 
representative of the general case (as other respondents 
clearly show). To preserve the representativeness of the 
data, the 
answers 
provided 
by 
the mentioned 
respondents have been excluded from the dataset. 
3) Respondents 4 and 5 declared that they use (EEM's). 
Their answers were removed from the dataset, since we 
18
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-498-5
ICSEA 2016 : The Eleventh International Conference on Software Engineering Advances

are interested in the relative cost of the standard 
measurement process. 
To analyze the data in Table I, the following procedure 
was adopted: 
1) For every phase, the mean values of the lower bound 
and upper bound of the given ranges were computed. 
Let MLBi and MUBi be the means of the upper and 
lower bound, respectively, for phase i. 
2) For every phase, Mi = (MLBi + MUBi)/2 was computed. 
Being the midpoint between MLBi and MUBi, Mi 
indicates the more likely value for the fraction of effort 
spent in the ith phase, according to respondents. 
3) It was then found that Σi=1,7 Mi = 91.4%. This is not 
acceptable, since the sum of the efforts dedicated to the 
measurement phases must equal the total measurement 
effort. Therefore, we computed a weighted version of 
Mi: WMi = 100 Mi/91.4, so that Σi=1,7 WMi = 100%. 
WMi is assumed to indicate the most likely value for the 
fraction of effort spent in the ith phase. 
The values of MLBi, MUBi Mi and WMi are given in 
Table II. 
TABLE II.  
MEAN VALUES OF PHASE RELATIVE COSTS 
Phase 
MLBi 
MUBi 
Mi 
WMi 
1 
10.8% 
15.0% 
12.9% 
14.1% 
2 
3.5% 
8.1% 
5.8% 
6.4% 
3 
3.4% 
8.1% 
5.8% 
6.3% 
4 
30.8% 
34.8% 
32.8% 
35.9% 
5 
18.8% 
22.9% 
20.9% 
22.8% 
6 
3.4% 
8.1% 
5.8% 
6.3% 
7 
5.3% 
9.8% 
7.5% 
8.2% 
 
Since in general the mean is affected by the smallest and 
largest values in the observed population, we repeated the 
procedure described above using the medians of upper and 
lower bounds. The results obtained are given in Table III.  
TABLE III.  
MEDIAN VALUES OF PHASE RELATIVE COSTS 
Phase 
MLBi 
MUBi 
Mi 
WMi 
1 
8.5% 
12.5% 
10.5% 
15.8% 
2 
0.0% 
5.0% 
2.5% 
3.8% 
3 
0.0% 
5.0% 
2.5% 
3.8% 
4 
26.0% 
30.0% 
28.0% 
42.1% 
5 
16.0% 
20.0% 
18.0% 
27.1% 
6 
0.0% 
5.0% 
2.5% 
3.8% 
7 
0.0% 
5.0% 
2.5% 
3.8% 
 
The results of the analyses provide some useful 
indications concerning the relative cost of the phases of FP 
measurement, performed according to the IFPUG or Nesma 
process. 
The results concerning the relative efforts derived using 
the means and the medians are fairly close: this fact supports 
the hypothesis that values reported in Tables II and III are 
actually representative of the real relative effort per phase. 
The fact that more than half the effort is concentrated in 
phases 4 and 5 also appears to confirm the reliability of 
results. In fact, it is popular wisdom that most measurement 
effort is required by the analysis of data and processes, 
which is concentrated in phases 4 and 5. 
C. Threats to validity 
A first threat to the validity of the study is due to the 
number of datapoints that were collected. Although it was 
possible to collect only 31 datapoints, we strived to 
guarantee the representativeness of the collected data by 
eliminating outliers, as well as data that appear incorrect. In 
any case, the size of the dataset that was finally analyzed 
(containing 24 datapoints) is not smaller than many datasets 
used for empirical software engineering studies. 
Concerning the statistical analyses that were performed 
in this study, they are so simple that it is unlikely that any 
serious threat to statistically validity actually applies. One 
could observe that confidence intervals for the mean values 
could have been computed, but having already asked for 
ranges rather than specific values, computing confidence 
intervals would have been sort of overkilling. 
Most respondents (23) are from Italy, four are form the 
Netherlands and the remaining ones are from Brazil, 
Switzerland and Belgium. The lack of geographic dispersion 
could be a limit for the generalizability of results. However, 
most respondents are certified Function Point Specialists or 
certified Function Point Practitioners, thus we can assume 
that they all follow the process specified in the official 
manuals [3][4][8][9]. If so, our results should be applicable 
to all the measurements performed according to the standard 
counting practices. 
IV. 
RELATED WORK 
There is not much literature concerning the cost of 
functional size measurement. A couple of documents report 
about the total cost of FP measurement [5][6], but none 
provides information concerning how the total effort is 
spread among the various measurement phases. 
Some indications are provided by the proposers of 
EEM's. For instance, it was reported that "the E&Q size 
estimation technique has been proved in practice to be quite 
effective, providing a response within ± 10% of the real size 
in most real cases, while the savings in time (and costs) can 
be between 50% and 90% (depending on the comprised 
aggregation level) with respect to corresponding standard 
measurement procedures." [18]  
It was also reported that "the results found with NESMA 
estimated fall within a reach  of  -6%  to  +15%  of  the  
corresponding  result  found  with  a  NESMA  detailed 
approach, and NESMA  estimated  FSM  is  performed  1,5  
times  as  fast  as  a  NESMA  detailed FSM." [12] 
These evaluations are probably optimistic to some extent. 
However, they are not precise enough to be used for decision 
making: for instance, it is not clear if the reported savings are 
evaluated with respect to the whole measurement process or 
only with respect to the core part (phases 4-6). 
19
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-498-5
ICSEA 2016 : The Eleventh International Conference on Software Engineering Advances

V. 
CONCLUSIONS 
The measurement process of IFPUG (and Nesma) FP is 
often considered too expensive and time consuming. To 
overcome this problem, EEM's have been proposed, to 
obtain faster and cheaper approximate measure estimates. 
However, it is quite difficult to estimate how much 
measurement effort can be actually saved by using an EEM 
instead of the standard measurement process. This 
knowledge would be clearly quite important for managers 
who have to choose whether to perform a full-fledged 
measurement or an approximate estimation. 
Since EEM's indicate what phases of the measurement 
process they allow to skip, to be able to evaluate the saving 
yielded by EEM's we need to know the relative cost of the 
measurement phases that compose the standard IFPUG 
measurement process. To this end, a questionnaire was 
proposed to professional measurers, and the collected 
answers were analyzed. 
The results of the analysis are reported in this paper (see 
Section B). 
Most EEM's allow for skipping phases 5 and 6. Among 
such methods are the NESMA estimated [8][11][12], 
Early&Quick Function Point [10], simplified Function Point 
[14] (not to be confused with the Simple Function Point 
method, which is a proper functional size measurement 
method, not an EEM method[17][15][16]), ISBSG average 
weights (which assigns to each basic functional component 
the average weight that type of component has in the ISBSG 
dataset [13]). 
According to the values given in Tables II and III, we can 
see that EEM's that allow to skip phases 5 and 6 are expected 
to save 28–30% of the measurement effort. Actually, as 
previously mentioned, also phases 1 and 7 are expected to 
become faster and simpler when EEM's are used. However, 
the analysis reported here does not support the evaluation of 
savings in phases 1 and 7, which are largely dependent on 
the context. 
Future work includes: 
• Extending the dataset, especially with answers from 
non-European 
countries, 
to 
make 
the 
dataset 
representative of a larger community of IFPUG users. 
• If possible, collecting real effort data from the field, 
instead 
of 
subjective 
indications 
provided 
by 
measurers. This would make it possible to analyze not 
only the relative cost of measurement phases, but also 
the actual cost of measurement. 
• Characterizing the contexts in which measurement is 
performed, to support the empirical evaluation of the 
dependency of the relative cost of measurement phases 
on the context.  
ACKNOWLEDGMENT 
The work presented here has been partly supported by the 
FP7 Collaborative Project S-CASE (Grant Agreement No 
610717), funded by the European Commission and by the 
“Fondo di Ricerca d’Ateneo” of the Università degli Studi 
dell’Insubria. 
REFERENCES 
[1] A. J. Albrecht, “Measuring Application Development 
Productivity”, Joint SHARE/ GUIDE/IBM Application 
Development Symposium, pp  83–92, 1979. 
[2] A. J. Albrecht and J. E. Gaffney, “Software function, lines of 
code and development effort prediction: a software science 
validation”, IEEE Trans. on Software Eng., vol. 9, pp. 639–
648, 1983. 
[3] International Function Point Users Group, “Function Point 
Counting Practices Manual - Release 4.3.1”, 2010. 
[4] ISO/IEC 20926: 2003, “Software engineering – IFPUG 4.1 
Unadjusted functional size measurement method – Counting 
Practices Manual”, ISO, Geneva, 2003. 
[5] C. Jones, “A new business model for function point metrics”, 
http://concepts.gilb.com/dl185, 2008. Last access June 12th, 
2016. 
[6] “Methods for Software Sizing – How to Decide which 
Method to Use”, Total Metrics, www.totalmetrics.com/ 
function-point-resources/downloads/R185_Why-use-
Function-Points.pdf, August 2007. Last access June 12th, 
2016. 
[7] L. Santillo, “Easy Function Points – ‘Smart’ Approximation 
Technique for the IFPUG and COSMIC Methods”, IWSM-
MENSURA, pp. 137–142, 2012. 
[8] ISO/IEC, ISO/IEC 24750:2005, Software Engineering 
“NESMA Functional Size Measurement Method, Version 2.1, 
Definitions and counting guidelines for the application of 
Function Point Analysis. International Organization for 
Standardization, Geneva, 2005. 
[9] NESMA, “Counting Practice Manual, Version 2.1”, 2004. 
[10] “Early & Quick Function Points for IFPUG methods v. 3.1 
Reference Manual 1.1”, April 2012. 
[11] nesma, Early Function Point Analysis, July 15, 2015, 
http://nesma.org/freedocs/early-function-point-analysis/ Last 
access June 12th, 2016. 
[12] H. S. van Heeringen, E. W. M. van Gorp, and T. G. Prins, 
Functional size measurement accuracy versus costs is it really 
worth it? Software Measurement European Forum, May 2009. 
[13] ISBSG, Worldwide Software Development–the Benchmark. 
Release 5, International Software Benchmarking Standards 
Group, 1998. 
[14] R. Meli and L. Santillo, Function Point Estimation Methods: a 
Comparative Overview, FESMA conference, pp. 2009. 
[15] L. Lavazza and R. Meli. "An Evaluation of Simple Function 
Point as a Replacement of IFPUG Function Point." IWSM-
MENSURA 2014. IEEE, pp. 196–206, 2014. 
[16] F. Ferrucci, C. Gravino, and L. Lavazza,  “Assessing Simple 
Function Points for Effort Estimation: an Empirical Study”, 
31st ACM Symposium on Applied Computing – SAC 2016, 
Pisa, April 4-8, pp. 1428–1433, 2016. 
[17] Simple Function Point Association, Simple Function Point - 
Functional Size Measurement Method Reference Manual 
v01.01, 
March 
2014, 
http://www.sifpa.org/en/sifp-
method/manual.htm. Last access June 12th, 2016. 
[18] L. Santillo, M. Conte, and R. Meli. "Early & Quick function 
point: sizing more with less." 11th IEEE International 
Symposium on Software Metrics, 2005. IEEE, 2005. 
[19] L. Lavazza and G. Liu, An Empirical Evaluation of 
Simplified Function Point Measurement Processes, Int. 
Journal on Advances in Software, vol. 6, n. 1-2, pp. 1-13, 
2013. 
[20] Kwiksurveys 
site, 
https://kwiksurveys.com/s.asp?sid= 
aazttngx1iibno6450647#/ Last accessed June 12th, 2016. 
[21] nesma association, www.nesma.org. Last accessed June 12th, 
2016. 
20
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-498-5
ICSEA 2016 : The Eleventh International Conference on Software Engineering Advances

[22] ResearchGate, http://www.researchgate.net/ Last accessed 
June 12th, 2016. 
APPENDIX - THE QUESTIONNAIRE 
A survey about the relative effort required by the phases 
of Functional Size Measurement 
A. About you... 
Question 
Possible answers 
Are you a certified Function 
Point Specialist (CFPS)? 
Yes/No 
Are you a certified Function 
Point Practitioner (CFPP)? 
Yes/No 
How 
many 
years 
of 
experience do have in FP 
counting? 
Less than 5 
Between 5 and 10 
More than 10 
How many FP per year do you 
count on average? 
No more than 200 
Between 200 and 1000 
Between 1000 and 5000 
More than 5000 
 
B. Relative effort required by the phases of functional size 
measurement 
According to your experience, what is the relative effort 
required by the phases of functional size measurement? 
Please, specify how big is the percentage effort for each 
phase, according to your experience. Please note that here we 
consider the measurement performed at the beginning of the 
project, based on functional user requirements. 
Thanks a lot for your answers! If you have any additional 
comment or remark, or if you want to be informed on the 
results 
of 
the 
survey, 
please send 
an 
email to: 
luigi.lavazza@uninsubria.it 
 
 
 
 
Question 
Possible answers 
Phase 1: gathering the available documentation concerning 
functional user requirements 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Phase 2: Identifying application boundaries 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Phase 3: Determining the measurement goal and scope 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Phase 4: Identifying Elementary Processes (Transactions) 
and Logical Data Files 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Phase 5: Classifying transactions as EI, EO or EQ; 
classifying files as ILF or EIF; identifying RET, DET, FTR 
and determining complexity 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Phase 6: Calculating the functional size 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Phase 7: Documenting and presenting the measurement 
0-5%, 6-10%, 11-15%, 16-20%, 21-25%, 26-30%, 31-35%, 
36-40%, 41-45%, 46-50%, 51-55%, 56-60%, 61-65%, 66-
70%, 71-75%, 76-80%, 81-85%, 86-90%, 91-95%, 96-100% 
Please, specify what measurement method the given data 
you gave apply to 
IFPUG 
NESMA 
Other 
Please, specify if the given data take into account some type 
of simplification 
No simplification 
Nesma estimated 
Nesma indicative 
Early & Quick FP 
Other 
 
 
21
Copyright (c) IARIA, 2016.     ISBN:  978-1-61208-498-5
ICSEA 2016 : The Eleventh International Conference on Software Engineering Advances

