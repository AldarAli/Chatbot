Developing a Decision Tool to Evaluate Unmanned System’s Command and Control 
Technologies in Network Centric Operations Environments 
Maria Olinda Rodas, Mark Veronda and Christian Szatkowski 
Command and Control Engineering Division 
Space and Naval Warfare System Center Pacific 
San Diego, California 
maria.rodas@navy.mil, mark.veronda@navy.mil, christian.szatkowski@navy.mil 
 
 
Abstract—Expert systems that evaluate new Command and 
Control (C2) technologies are necessary to determine their 
adequacy for Network Centric Operations (NCO) missions. 
New technologies for complex C2 NCO scenarios are currently 
being developed. However, little has been done to evaluate 
these 
new 
technologies 
for 
specific 
sets 
of 
mission 
requirements. There is neither a standard methodology to 
evaluate these new technologies, nor a research environment to 
test these technologies under realistic assumptions. This paper 
will introduce an expert system that will help decision makers 
evaluate these technologies and determine whether they can 
transition into practical applications for the Navy, and under 
which limitations.  
 
Keywords-operator capacity; supervisory control; expert 
systems; unmanned vehicles. 
I.  INTRODUCTION 
  The Department of Defense’s future vision for NCO is 
intended to increase combat control by networking relevant 
entities across a battlefield [1]. This new vision implies 
large amounts of information sharing and collaboration 
across different entities. An example of a futuristic NCO 
mission scenario is one in which a group of heterogeneous 
Unmanned Vehicles (UVs) are supervised by a single 
operator using NCO technology. In this type of complex C2 
scenario, UV operators will be subjected to vast amounts of 
information as compared to today’s command and control 
scenarios. Therefore, this vision brings with it a new 
problem that must be addressed: How to maintain an 
adequate workload to avoid information overload and 
resulting loss of situation awareness. Currently, C2 
technologies that allow the operator to control multiple UVs 
in a NCO scenario are rapidly increasing. The development 
of these new C2 technologies generates the tendency to 
exponentially increase the ratio of UVs to operators. 
However, if systems are inadequately designed or are used 
beyond their design capabilities, they will not adequately 
control for increased workload, which in turn will cause the 
operator to become overloaded and lose situation awareness. 
It is critical that military decision makers develop predictive 
models of human and system performance to evaluate the 
adequacy of a system’s design to satisfy specific mission 
requirements.   
 
This paper will start by discussing previous research in the 
area of UV operator capacity, to later explain the project 
goals, methodology and experimental results. Finally, it will 
end with a brief discussion of the future research plans and 
the implications of this study on future human-UV 
interaction research.  
II.  BACKGROUND 
  Mental workload is a limiting factor in deciding how many 
UVs an operator can control or supervise. In the case of one 
operator supervising multiple vehicles, the operator’s 
workload is measured by the effort required to supervise 
each vehicle and the overall task. The effort required to 
supervise an individual UV in a team depends on the 
efficiency of the system to reduce workload and increase 
situation awareness. Moreover, workload also depends on 
the complexity of the mission scenario. Some of the 
characteristics of a complex mission scenario as defined by 
military standards include: mission time constraints, 
precision constrains, repeatability in tasks (i.e., navigation, 
manipulations, etc.), level of collaboration required, 
concurrence and synchronization of events and behaviors, 
resource management (i.e., power, bandwidth, ammunition), 
rules 
of 
engagement, 
adversaries, 
and 
knowledge 
requirements [2]. The degree to which these characteristics 
are required also define workload. Consequently, if the 
system is not designed to achieve specific types of 
requirements, then when it is tested for those requirements 
the system may not perform them adequately.  
  Previous attempts to model operator capacity were 
developed to display temporal constraints associated with 
the system. The complexity of these measures progressed 
from measuring operator capacity in homogenous UVs 
controlled by one operator [3-7], to scenarios in which 
teams of heterogeneous UVs are supervised by one operator 
[8]. The first equation developed to predict operator 
capacity in homogenous UVs suggested that the operator 
capacity is a function of the Neglect Time (NT), or the time 
the UV operates independently, and Interaction Time (IT), 
or the time the operator is busy interacting, monitoring, and. 
making decisions with the system [3]. Critics of this method 
suggested 
that 
the 
equation 
lacked 
two 
critical 
considerations: 1) the importance of including Wait Times 
(WTs) caused by human-vehicle interaction, and 2) how to  
129
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

link this equation to measure effective performance [6]. 
Hence, WT is added to the equation to account for the times 
the UV has to perform in degraded state because the 
operator is not able to attend to it or is not aware of a new 
incoming event. Three WTs were identified: Wait Times 
due to Interaction (WTI), Wait Times due to Loss of 
Situation Awareness (WTSA), and Wait Times due to 
Queue (WTQ).  
Using a discrete event simulation, a research study 
attempted to create a link to performance by using a proxy to 
measure workload and situation awareness. In this model, 
the researcher intended to model heterogeneity in UV 
systems in order to evaluate the system’s design [8]. The 
human was modeled as a server attending to vehicle-
generated tasks – both exogenous and endogenous tasks – as 
defined by their arrival and service processes. The concept of 
utilization was introduced as a proxy for measuring mental 
workload. Utilization Time (UT) refers to the percentage of 
time the operator is busy. The concept of WTSA was used as 
a proxy to measure Situation Awareness. The UT and WTSA 
measures were computed as a type of aggregate effect of 
inefficiencies in information processing rather than being 
computed as individual measures of workload and situation 
awareness. The author of this model suggested that many 
other sources of cognitive inefficiencies, besides these two 
proxies, are manifested through cognitive delays. He 
emphasized that measures of UT and WTSA are extremely 
critical to determine supervisory performance and suggested 
that better methodologies to measure these variables need to 
be developed. 
III.  PROJECT GOALS 
This study aims to develop a model of operator capacity 
in a complex mission scenario that will serve to help decision 
makers determine whether a particular technology is 
adequate for an NCO mission scenario. Moreover, this study 
aims to develop a model of operator capacity that is more 
comprehensive. This model is intended to fill in the gaps of 
current research by introducing new variables and 
relationships to previous models. The model will be 
constructed in a way so prior knowledge about the 
relationship between variables will serve to better predict 
missing data, such as workload and situation awareness. 
Moreover, the model will be structured in a way that will 
make it easy to determine which areas in the system design 
need improvement. The ultimate goal of this study is to 
develop a decision-making tool that will serve to evaluate 
and determine the effectiveness and limitations of a 
particular NCO technology in a complex mission scenario.  
IV.  METHODOLOGY 
A. Approach 
    The approach taken by this research study was to model 
the decision-making process required to decide whether to 
increase a particular team size. This approach was taken in 
order to present decision makers with a decision-support 
tool that will ensure that knowledgeable decisions are made 
in regards to the adequacy of a given team size with a 
particular NCO technology. Modeling the decision-making 
process, as opposed to the environment, allows for more 
knowledgeable decisions because not only are the most 
important factors in the decision taken into account, but 
optimization of the recommended decision’s outcome is also 
possible. This approach provides adequate information to 
the user to make a decision. And while the model is based 
on answering this particular question, the nature of the 
situation is manifested in the model, thus allowing users to 
draw more conclusions than only the adequacy of the team 
size.  
 
B.   The Decision Network Model  
     A decision network was developed to model the 
decision-making process required to decide whether to 
increase a given team size with the selected NCO 
technology. Netica Bayesian Belief Network (BBN) 
software [9] was used to develop a decision network that 
incorporates quantitative and qualitative information about 
the model. This software was chosen mainly because it 
provides an effective display of quantitative and qualitative 
data and it can accommodate missing or incomplete data. 
Using a BBN allows researchers to compute unobservable 
variables (i.e., missing data) based on measures that are 
observed (i.e., prior knowledge). This feature is very 
important to determine variables such as Situation 
Awareness and Workload that were only computed as 
proxies in previous models. 
    A decision network consists of nature, decision, and 
utility nodes. Nature nodes represent variables over which 
the decision maker has no control (see yellow nodes in Fig. 
2). Decision nodes represent variables over which the 
decision maker can make a decision (see blue nodes in Fig. 
2). Utility nodes represent a measure of value, or the 
decision maker’s preferences for the states of the variables 
in the model (see pink nodes in Fig. 1). In this network, the 
outcome of a decision node is maximized by finding a 
configuration of the various states of the sets of variables 
that maximize the values of the utility node. Therefore, 
based on a series of requirements, or utility values, a 
decision network provides the user with the correct decision. 
Additionally, the arrows in the model represent reasoning 
relationships and are detailed in the conditional probability 
tables (CPTs) of the nature and utility nodes. In the CPT, 
the distribution of each node will be determined a priori 
based on the relationships specified in each conditional 
probability table.  
    This model makes several assumptions. First, the type of 
UV system addressed by this model is one in which a single 
human operator is responsible for supervising a team of 
heterogeneous UVs. The human operator is assumed to act 
in a supervisory control style, interacting with the system at 
discrete points in time (i.e., there is no manual control). 
Second, in this model, the human operator is responsible for 
supervising a team of heterogeneous UVs defending an oil 
130
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

platform from potential enemies. Third, the human operator 
could be situated in a ground-based, sea-based, or airborne 
control station. Fourth, the model was built in a way such 
that decision makers will use this model to help them decide 
if a particular technology is adequate for specific mission 
requirements. Finally, the model assumes that the decision 
making process required to make this decision is 
hierarchical; therefore, later decisions are based on earlier 
ones. The model captures attributes from the Operator 
Performance Model, the System Performance Model, and 
the Operator Capacity Model as shown in Figure 1. 
 
Figure 1. A high level representation on the attributes the model captures. 
Notice that variables of interest in Operator Performance Model are 
Operator Attention Allocation Strategies and Operator Decision Making 
Efficiency, while in the System Performance model are Usability, 
Automation Level and Algorithm Efficiency. The output of the operator 
capacity model is to determine an adequate team size.  
 
      The attributes captured in Figure 1 represent three major 
areas of relevance for the decision to increase the team size: 
system performance, operator performance, and cognitive 
workload (see Figure 2). These areas of relevance are 
represented in the model as sub-models; each of them 
contains one or more decision nodes that correspond to the 
decisions that must be made by the operator in each area to 
ensure that they are working adequately. The order in which 
the decision nodes have been organized represents the way 
in which decisions should be made (see blue nodes on 
Figure 2). The model represents a sequence of decisions in 
which later decisions depend on the results of earlier ones. 
In this model, the last decision is shown at the end of the 
sequence. The last decision determines whether a particular 
team size should be increased.  
    The first sub-model, system performance, includes three 
decision nodes with the followings decisions: 1) Is the 
interface effective? 2) Does the system have an adequate 
level of automation? 3) Are the system algorithms efficient 
for the task? These three decisions were included in this 
sub-model because they represent areas that are important to 
ensure good system performance. Some of the utility nodes 
for each of these decision nodes were identified from the 
literature, while some others were included to ensure that 
specific mission requirements are satisfied. For example, if 
the system has good interface usability, the situation 
awareness of the operator will be high. Moreover, if the 
situation awareness is high, the system’s automation level 
must be somehow effective to avoid loss of situation 
awareness and/or complacency. Then, to ensure that the 
mission requirements are satisfied, the algorithms used must 
be working efficiently toward achieving the mission goal. 
This efficiency is measured by the number of times the 
operator reassigns a mission that was previously assigned by 
the system, with a lower number signaling higher efficiency. 
Note that algorithm efficiency is defined in this model only 
as a result of the operator’s perceived trustworthiness of the 
system. If the system is not perceived as trustworthy, then 
the operator will tend to override the system frequently and 
the algorithm efficiency will be low.  
   The second sub-model, operator performance, needs to 
ensure that the operator performs effectively with the 
system being evaluated, as more UVs are introduced to the 
team, and the mission scenario becomes more complex. 
Since this is a supervisory control environment, operator 
performance is defined in terms of the operator’s decision 
making. There are two decisions (decision nodes) that are 
important to evaluate whether the operator’s performance is 
adequate for the task: 1) Is the operator’s task management 
strategy efficient? 2) Is the operator’s decision making 
efficient? The first decision is necessary to evaluate whether 
operators will efficiently prioritize different tasks that arrive 
simultaneously. 
   The second decision is necessary to evaluate whether the 
operator will successfully achieve the goals of the mission 
(i.e., protecting the asset from enemy attack). Together these 
two decisions summarize what is important to ensure a 
satisfactory operator performance. Please note that by 
measuring task management efficiency, an attention 
inefficiency component is included in this model.  
   Finally, the last sub-model, cognitive workload, includes 
the final decision node: ―Increase Team?” For this decision, 
it is important to ensure that operators are not overloaded, 
but instead their workload is adequate to successfully 
complete the mission scenario. This final decision node is 
the end of a sequence of decisions and therefore it depends 
on the outcomes of the previous decisions made in the 
system performance and operator performance sub-models. 
Hence, in order to avoid cognitive overload, not only does 
the system have to efficiently perform in the mission 
scenario, but the operator also has to perform efficiently to 
ensure that tasks are adequately managed and do not 
overload the operator. The cognitive workload and operator 
performance sub-models are strongly associated. If 
cognitive workload is too high, then the operator 
performance will be low. Therefore, the more inadequate 
management and tactical decisions operators make, the 
higher their workload will be.  
    System performance, operator performance, and cognitive 
workload are the foundation of this model. Most of the 
knowledge about the model relationships between variables 
was acquired from a literature review. Variables such as 
―Information Overload” and ―System Interruption‖ were 
included to emphasize the need to evaluate these aspects of 
the usability of the system (see Figure 2) in complex 
131
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

supervisory control tasks. These variables are relevant 
because they contribute to design interfaces, especially in 
the supervisory control environment in which large amounts 
of information, and large event queues can result in 
information overload and frequent system interruptions. 
 
 
Figure 2. Decision network representing the decision process involved in 
deciding whether to increase a particular team size. Notice that this picture 
displays the model with no data. When data are introduced into the model, 
the system provides the user with a recommended course of action that will 
be displayed as a percentage (i.e., Yes 90%). 
C.  Performance Measures  
      The model allows for measurement of several output 
variables. These variables include those implemented in the 
previous models [3-7], as well as specific user-defined 
metrics that the model allows to capture. Temporal 
measures such as UT and WT are used because they are 
critical in a system where the operator has limited attention 
resources that must be divided across multiple tasks. UT is 
used to capture the effects of alternate design variables on 
operator workload. Some researchers indicate that average 
UT and WT can allow for benchmarking and comparison to 
be made across applications [8, 10]. The level of autonomy 
in the model is captured through the NT. In addition to the 
basic metrics inherently captured by previous models, this 
model also captures mission-specific metrics. Some of the 
mission-specific metrics include the rate at which tasks are 
successfully completed, the UVs’ health status and the total 
time to complete the mission scenario. Furthermore, other 
measures being captured by the model include Information 
Overload, System Interruption, and Reassignment Rate. 
These three measures are important to evaluate the system 
performance. Information Overload and System Interruption 
are shown to be related to SA; therefore, they are used to 
help determine Situation Awareness (SA). For example, 
when the operator is overloaded with information, he/she is 
not able to focus on what is important, therefore vital SA is 
lost. Moreover, when the system is constantly interrupting 
the operator at any point in time, it drives the operator’s 
attention away from one task to focus on another, therefore 
affecting 
their 
SA. 
The 
system’s 
Frequency 
of 
Reassignment measure is used to evaluate the number of 
times the operator overrides the system. Identifying the 
amount of times the system has been overridden will help us 
determine how trustworthy the system is for the operator. 
The underlying assumption is that the more the operator 
overrides the system, the less reliable the algorithm for the 
system is. See Figure 3 for a list of the performance 
measures used as input in the model. 
 
PERFORMANCE 
MEASURES 
DEFINITION 
Wait Times due to lost of 
Situation Awareness( WTSA) 
Represents the amount of time the operator 
is not aware that the vehicle requires his 
attention. 
Wait Times due to Queue 
(WTQ) 
Represents the amount of time resulting 
from queues due to near simultaneous 
arrivals of tasks.  
Interaction Times (IT) 
Represents the amount of time the operator 
interacts with the vehicle. Includes 
monitoring and decision making time. 
Neglected Times (NT) 
Represents the amount of time each vehicle 
operates independently. 
Utilization Times (UT) 
Represents the amount of time the operator 
actively interacted with the display over the 
course of the experiment. 
Total Task Time 
Represents total time to complete the trial. 
Information Overload 
Represents information overload in the 
interface. 
System Interruption 
Represents the amount of time the operator 
was interrupted to attend a different task. 
Target Elimination Task- 
Success Rate 
Represents the ratio of eliminated enemies 
to the total number of identified enemies. 
Identification Task-Success 
Rate 
Represents the ratio of identified enemies 
to the total number of detected vehicles. 
Frequency of Reassignment 
Represents the operator’s trust in the 
system. Accounts for the times the operator 
reassigned a vehicle once that it was 
assigned by the system. 
UV Health Status 
Represents the amount of damage 
experienced by the vehicle. 
Figure 3. Performance measures collected during the experiment. 
D.  Experimental Apparatus 
   Since there is no test bed available that portrays all the 
complexities of a futuristic mission scenario, the Research 
Environment for Supervisory Control of Heterogeneous 
Unmanned 
Vehicles 
(RESCHU) 
developed 
by 
the 
Massachusetts Institute of Technology (MIT) was acquired 
and later modified to be used as a test bed in this study. The 
RESCHU simulator [8] is a test bed that allows operators to 
supervise a team of Unmaned Aerial Vehicles (UAVs) and 
Unmanned Underwater Vehicles (UUVs) while conducting 
surveillance and identification tasks. This simulation was 
modified for this study to include the following 
requirements: 1) a complex mission scenario with an asset 
to protect and multiple simultaneous enemies to attack, 2) a 
highly automated system such as mission definition 
language (MDL) and 3) a highly heterogeneous team that is 
made of at least three different types of UVs. The new 
version of the simulation is called RESCHU SPAWAR or 
RESCHU SP.  
It is important to mention that the Unmanned System 
technology selected as an example of a NCO’s technology 
that allows one operator to supervise multiple UVs is the 
Collaborative Sensing Language (CSL) developed at the 
132
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

University of California, Berkeley. The CSL [11] is a high-
level feedback control language for mobile sensor networks 
of UAVs. This system allows an operator to concentrate on 
high-level decisions, while the system takes care of low-level 
decisions, like choosing which UV to send for a particular 
type of task. A framework for the CSL was designed to 
integrate this technology into the complex mission scenario 
portrayed by the RESCHU SP simulator. The CSL version 
displayed in this simulation is only intended to illustrate one 
way to portray how this technology may work in more 
complex mission scenarios and with supervisory control of 
multiple heterogeneous UVs (see Figure 4). 
 
Figure 4. RESCHU SP simulator displays a mission scenario with a team 
size of nine UVs (blue icons in the map), three potential enemies (dark 
yellow icons in the map), and one identified enemy (red numbered icon in 
the map). The CSL tab shows missions that are currently active and other 
missions that are not yet submitted. 
 
   The team of UVs in the RESCHU SP simulator is 
composed of UAVs, UUVs, and Unmanned Surface 
Vehicles (USVs). There are two types of UAV, the MALE 
UAV and the HALE UAV; both travel to areas of interest to 
detect potential enemies. When a UAV detects a potential 
enemy, a USV is sent to the detection area to identify the 
vehicle (i.e., the unidentified vehicles appear as dark yellow 
numbered icons in map). Engaging the video payload that 
arrives at a detection area requires the operator to decide 
whether the vehicle detected is a potential enemy. If an 
enemy is identified, a UUV travels to the location to target 
the enemy. UUVs are slower than USVs and UAVs. UAVs 
are the fastest UVs.  
   The operator’s main task is to identify and target potential 
enemies while protecting an asset (i.e., oil platform). At the 
same time, the operator is responsible for supervising the 
path of the UVs, in order to avoid traveling through 
potential threat areas (bright yellow areas on the map). 
Threat areas are zones that operators should avoid in order 
to protect the health of their vehicles. Moreover, operators 
are also responsible for following chat messages which 
provide them with the necessary Intelligence and guidance 
to complete their missions. When a UAV detects a potential 
enemy, a visual flashing alert is issued to warn the operator. 
This alert indicates that the operator should command the 
CSL system to assign a UV to complete the task. The 
operator commands the CSL to complete the task through a 
right-click interaction. The CSL system chooses a UV that 
is appropriate for the task and one that is also in close 
proximity to the potential target. The operator is in charge of 
approving the CSL selection by submitting the task through 
the Submit All button in the CSL Editing Controls tab. In the 
case of multiple identification tasks submitted to the CSL at 
the same time, the operator’s task is to approve the CSL 
selection, and if applicable, determine the order in which the 
tasks should be conducted. For example, in a situation in 
which there is only one UV available for the task, the 
operator has to determine the order in which tasks should be 
conducted to ensure a good mission performance. Once the 
order of tasks has been determined, the operator needs to 
submit the commands so that the CSL can complete the 
tasks. Once that a task has been submitted, a selected UV is 
sent to location, when it arrives, a visual flashing alert warns 
the operator that the video payload is ready to engage. Then, 
the operator engages the video payload through a right-click 
interaction. The detected vehicle is viewed through the 
video image displayed in the Payload View tab to determine 
whether the detection is identified as the enemy. The 
operator identifies the vehicle by clicking on the Yes or No 
button below the payload view. A supervisor will inform the 
operator via chat whether the identification is correct or not. 
If the operator correctly identifies the vehicle as an enemy, 
the vehicle icon on the map becomes red. If the operator 
incorrectly identifies a detected vehicle as the enemy, the 
supervisor will override the operator; therefore, the icon will 
not change to red. The next step for the operator is to inform 
the CSL that a vehicle should be assigned to complete the 
target mission. Once again, the CSL system chooses a UV 
and sends it to the target location. When on target, a visual 
flashing alert is issued to inform the operator that the UV is 
ready to engage. The operator confirms this through a right-
click interaction, and the target is eliminated. In this way, 
the operator is responsible to identify all detections and 
eliminate all enemies in order to protect the asset.  
E.   Participants, Experimental Design and Procedure 
  Experiments were designed to be completed in two phases: 
1) the software and performance measures program 
verification phase, and 2) the model validation phase. First, 
it is desired to ensure that the requirements of the simulation 
and performance measures computation program are met. 
Second, it is desired to obtain data associated with the 
different levels of team size, in order to build confidence in 
the model’s accuracy at replicating human-UV-interaction 
under different conditions. Having team size as the 
independent variable, the model’s ability to replicate 
statistically significant effects on the operator performance 
and/or mission performance could be evaluated. Finally, 
133
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

having data sets associated with the different levels of team 
size allows for predictive validation by selecting a single 
data set associated with one of the conditions and predicting 
the results observed for a second condition. The recruited 
participants for the first experimental phase are students 
from the Naval Postgraduate School (NPS). The online test 
bed includes: a background and exit survey, an interactive 
tutorial, a practice trial, and one of a set of possible 
experimental conditions. 
   In order to ensure the validity of the variables and 
relationships represented in the model, the decision network 
was converted into a Bayesian Belief Network (BBN) to run 
validation analysis. The software’s Test with Cases analysis 
will be used to validate the network in the second phase of 
the experiments. The Test with Cases analysis examines if 
the predictions in the network match the actual cases. The 
goal of the test is to divide the nodes of the network into 
two types of nodes: observed and unobserved. The observed 
nodes are the nodes read from the case file, and their values 
are used to predict the unobserved nodes by using Bayesian 
belief updating. The test compares the predicted values for 
the unobserved nodes with the actual observed values in the 
case file and the successes and failures are then recorded. 
The report produced by this analysis has different measures 
that validate each node’s predicted capabilities. After 
evaluating the validity of the model, we can determine 
which relationships are incorrect and we can make the 
network learn those relationships through the collected 
cases. Finally, we can run sensitivity analysis and predictive 
validation analysis to determine which variable has the 
biggest effect on team size and how each variable affects the 
overall result of the model. 
   The study design is a between-subject design with three 
conditions: high team size, medium team size, and low team 
size. The high team size condition is composed of 9 UVs: 3 
UAVs, 3 USVs and 3 UUVs. The medium team size 
condition is composed of 7 UVs: 3 UAVs, 2 USVs and 2 
UUVs. Finally, the low team size condition is composed of 
5 UVs: 3 UAVs, 1 USV and 1 UUV. Notice that the UAV’s 
number was kept constant through the different conditions 
because the UAVs produce little interaction with the 
operator (i.e., UAVs only patrol for detection and operators 
only have to supervise their flight path to avoid flying into 
threat areas). The number of USVs and UUVs was 
gradually incremented to investigate how they affect the 
performance measures and therefore the model outcome. 
Furthermore, the baseline of a team of 5 UVs was decided 
after pilot testing the simulation with different team sizes. 
  The experimental test bed was designed for a web-based 
delivery, with an interactive tutorial and practice trial. A 
web-based experimentation was chosen in order to obtain as 
much data as possible. The website is Common Access Card 
(CAC) protected and participation is via invitation. Data 
collected from the simulation is being recorded to an online 
database. Demographic information is collected via a 
background 
survey 
presented 
before 
the 
tutorial. 
Participants are instructed to maximize their overall 
performance by: 1) avoiding threat areas that dynamically 
changed and therefore minimizing damage to the UVs, 2) 
correctly identifying enemies, 3) targeting enemies before 
they reach the asset, 4) overriding the system when 
necessary to minimize vehicle travel times and maximize 
mission performance, and 5) eliminating potential enemies 
as soon as possible.  
V.  EXPERIMENTAL RESULTS  
   Pilot tests were conducted at NPS and SPAWAR to 
evaluate the online test bed and performance measures. The 
results of these pilot tests indicated that the interactive 
tutorial was hard to understand, the simulation had bugs and 
the logic used for coding the performance measures was 
inaccurate. The test bed and performance measures were 
reviewed, a framework for improvement was developed and 
problematic areas were fixed. The first experiment was 
conducted at NPS in June, 2011. Data obtained is currently 
being analyzed. Results will be released in a future scientific 
publication. Due to the complexity of the software and the 
number of factors to be considered in the computation of the 
performance measures (i.e., multiple event types, vehicle 
types, performance measures, start and end times, etc.), we 
expect the verification phase to continue through next year.  
It is planned to start the validation phase in May, 2012. 
VI.  FUTURE RESEARCH 
   In the validation phase of this study, the model will be 
first validated with the current implemented technology. 
Next, the model will be validated with a different NCO 
technology in order to test whether the results of the model 
can be generalized to other NCO technologies with different 
system’s variables (i.e., usability, automation, etc.). 
Furthermore, learned workload and SA curves will be 
incorporated into the model to strength model predictions. 
Finally, a decision tool package will be developed to allow 
decision makers and/or system designers to evaluate NCO 
technologies. The decision tool package will include a 
program that will collect performance measures from 
simulations and feed the model in order to evaluate new 
NCO technologies.   
VII.  IMPLICATIONS FOR FUTURE RESEARCH 
   The implications of this study are various. First, the results 
of this study will allow a better understanding of what 
enables operator capacity in complex NCO mission 
scenarios. Second, by understanding the variables that affect 
operator capacity and the decision making process involved 
in evaluating NCO technologies, the results of this study 
will allow the development of specific C2 design 
requirements for technologies to be used in complex NCO 
mission 
scenarios. 
Third, 
by 
acquiring 
a 
better 
understanding of the dynamic between the operator 
capacity, the system, and the mission requirements, the 
results of this study will not only define performance 
134
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

measures for these complex environments but also 
determine an effective logic to extract them from any 
simulation and place them into the model for evaluation and 
prediction. Finally, the overall results of this study will help 
future research by providing scientists with a test bed and 
performance measures definitions for a NCO scenario to 
further expand this study and/ or conduct further studies in 
this crucial research area.  
ACKNOWLEDGMENT 
The authors wish to acknowledge the support of Dr. 
Mary Cummings (MIT) and Dr. Luca Bertuccelli (MIT) for 
providing guidance on the RESCHU code, Dr. Karl Hedrick 
(UC Berkeley) and Dr. Raja Sengupta (UC Berkeley) for 
providing guidance on the functionality of the CSL, Mr. John 
Falby (NPS) for recruiting participants for the pilot tests, and 
Dr. Douglas Lange (SSC Pacific) for being a great mentor 
and helping us through the process. 
REFERENCES 
[1] Department of Defense, Network Centric Warfare: Department of 
Defense Report to Congress, Office of the Secretary of Defense, 
Washington, DC, 2001.  
[2] H.M. Huang, K. Pavek, B. Novak, J. Albus, and E. Messina. ―A 
Framework for Autonomy Levels for Unmanned Systems (ALFUS)‖ 
presented at Proceedings of the AUVSI's Unmanned Systems North 
America, pp. 849–863, Baltimore, MD, USA, 2005.  
[3] D.R. Olsen and S.B. Woods. Fan-Out Measuring Human Control of 
Multiple Robots, CHI, vol. 6 (1), pp. 231-238, 2004.  
[4] M.L. Cummings and P.J. Mitchell. Predicting Controller Capacity in 
Supervisory Control of Multiple UAVs, IEEE Systems, Man and 
Cybernetics, Part A System and Humans, vol. 11(2), pp. 451-460, 2008.  
[5] J.W. Crandall and M.L. Cummings. Identifying Predictive Metrics for 
Supervisory Control of Multiple Robots, IEEE Transactions on Robotics 
Special Issue on Human-Robot Interaction, vol. 23(5), pp. 942-951, 2007.  
[6] M.L. Cummings, C.E Nehme, and J.W. Crandall. Predicting Operator 
Capacity for Supervisory Control of Multiple UAV,  Innovations in 
Intelligent Machines, vol. 70, Studies in Computational Intelligence J.S. 
Chahl, L.C. Jain, A. Mizutani, and M. Sato-Ilic, Eds., 2007.  
[7] J.W. Crandall  and M.L. Cummings. Developing Performance Metrics 
for the Supervisory Control of Multiple Robots. Presented at Proceedings 
of the 2nd Annual Conference on Human-Robot Interaction, pp. 33-40, 
2007.  
[8] C.E. Nehme. Modeling Human Supervisory Control in Heterogeneous 
Unmanned Vehicle Systems, Ph.D. Thesis, MIT Dept. of Aeronautics and 
Astronautics, Cambridge, MA, 2009.  
[9] Netica Software. Netica Bayesian Belief Network. Norsys Software 
Corporation. Vancouver, BC, Canada. Retrieved on May 15, 2011 from 
www.norsys.com.  
[10] P.E. Pina, B. Donmez,  and M.L. Cummings. Selective Metrics to 
Evaluate Human Supervisory Control Applications. Technical Report HAL 
2008-04, Massachusetts Institute of Technology, May 2008.  
[11] J. Love, J. Jariyasunant, E. Pereira, M. Zennaro, K. Hedrick, C. 
Kirsch, and R. Sengupta. CSL: A Language to Specify and Re-Specify 
Mobile Sensor Network Behavior,” 15th IEEE Real-Time and Embedded 
Technology and Applications Symposium, pp. 67-76, 2009.  
 
135
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) The Government of USA, 2011. Used by permission to IARIA.     ISBN: 978-1-61208-155-7

