Bridging the Gap: End-User Programmers in Modern Supply Chain Analytics
Ritsaart Bergsma
Faculty of Business, Management and Law
Windesheim University of Applied Sciences
Zwolle, the Netherlands
Email: rf.bergsma@windesheim.nl
Corn´e de Ruijt
Faculty of Business, Management and Law
Windesheim University of Applied Sciences
Zwolle, the Netherlands
Email: c.a.m.de.ruijt@windesheim.nl
Abstract—This paper examines the role of end-user programmers
in enhancing data-driven decision-making within supply chains,
particularly for Small and Medium-sized Enterprises (SMEs).
End-user programmers increasingly use low/no code software and
platforms to improve their organization’s analytical capability.
Low/no code provides less technical users access to analytical
tools, thereby enabling them to address supply chain challenges.
While low/no code simplifies the (data) modeling process, end-
user programmers do hold assumptions about the modeling
process that lack scientific support. This paper examines three
such assumptions: 1) their confidence in producing models with
few errors, 2) assumptions regarding in which context to use
machine learning, and 3) assumptions regarding the complexity
of making statistical results applicable. By reflecting on these
assumptions, this paper provides directions organizations can
adopt to support low/no code adaption within logistic SMEs.
Keywords–Supply chain management; low code/no code; Ana-
lytics Maturity Curve
I.
INTRODUCTION
Today’s supply chains encounter major challenges, often
experiencing disruptions in their intricate networks. These
disruptions lead to significant consequences and expenses
[1]. Smaller businesses are especially vulnerable, with 40%-
60% of them failing to endure significant disruptions [2] via
[1]. Logistics service providers are coping with workforce
issues due to labor shortages [3]. Furthermore, various groups
advocate for greater sustainability within supply chains (e.g.,
[4]).
Industry 4.0 technologies are seen as potential solutions
to these issues [5]. These technologies include cyber-physical
systems, the Internet of Things (IoT), and Big Data Analytics
(BDA) [5][6]. Several authors have outlined how these tech-
nologies can address supply chain challenges, which we will
refer to as the Industry 4.0 Promise (I4.0P). By accessing
substantial data in supply chains, better decision-making is
possible through BDA methods [6][7], and AI could even
drive complete automation [5][8]. A research by McKinsey
highlights how AI seems particularly promising in the logistics
sector [9]. Given the ambiguity of what exactly is meant by
“AI” [10], we imply the usage of Machine Learning (ML) tools
techniques, which we therefore abbreviate as AI/ML.
Despite the high potential promoted by BDA vendors and
consultants [11], companies struggle to translate their data
efforts into value [12]. This challenge extends to logistics
service providers, many of which are small and medium
enterprises (SMEs): they continue to face difficulties with
digitalization. Organizations not only handle their own logis-
tics and IT systems, but also cope with the complexities of
logistic networks and its underlying processes, creating addi-
tional barriers for digitalization [13]. This interconnectedness
in logistic networks might explain why some studies suggest
that the logistics sector lags behind in digitalization, compared
to other industries [14] via [13]. SMEs encounter challenges
when using data for analysis, including insufficient executive
support, limited skills and IT-support, and they express a need
for well-defined business problems [15].
Although these challenges are significant, ongoing ad-
vancements in data & AI could offer solutions to (some of)
these challenges. There is a growing trend in organizations
adopting low code and no code platforms [12], and this
trend is likely for good reason. These platforms bring notable
advantages, especially by creating a new layer of abstraction
for novice users of data/AI technology. This accessibility is
valuable for users with limited IT and data science expertise.
However, there are some caveats to the wide adoption
of data technology by less experienced users, which in the
remainder of this paper we will refer to as end-user program-
mers. Some of this stems from assumptions about BDA in
the Industry 4.0 Promise, which might create expectations that
lack scientific evidence. Additionally, there are human biases
in modeling and programming that professional programmers
are trained to capture but which low code users are often unfa-
miliar with. By exploring these caveats, we aim to contribute to
the discussion about which skills these new low/no code users
should acquire before creating and managing data solutions.
While many findings may apply more broadly, we specifically
focus on low/no code usage in logistics SMEs. The following
research questions are formulated:
RQ1: How are low code development platforms relevant
for SMEs within the logistics sector and what are the
challenges and necessary guidelines?
RQ2: How does the actual usage of BDA in decision-
making differ from end-user programmers’ expectations
when utilizing low/no code software for data modeling and
what are the implications of this disparity?
This paper is organized as follows. In Section II, we explore
the potential and challenges of low code platforms. In addition
we highlight guidelines that are particularly important in the
logistics sector. In doing so we answer RQ1. RQ2 addresses
some of the challenges end users will have when applying
these low/no code platforms to implement AI. Section III
will address the assumption of the analytical maturity curve
1
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

present at a lot of organizations and section IV scrutinizes the
assumption that ”data can speak for itself”. Both sections are
aimed at addressing RQ2. Finally, we summarize the paper’s
findings in Section V.
II.
LOW CODE FOR SMES (RQ1)
This section will discuss the emergence of low code
development platforms and their relevance to SMEs in the
logistics sector. In addition, it will discuss challenges of these
platforms and proper guidelines.
A. The data quality in logistics
Decisions made by supply chain managers cover inventory,
warehouse layout, procurement and routing. Most of these
decision problems have been studied extensively in OR lit-
erature but there exists a gap between theory and application.
Syntetos et al. analyze the gap between theory and practice
in supply chain forecasting and conclude that for example
data is often recorded at different frequencies (say daily) than
decision makers require (say weekly). Aggregating this data
can be complex and software packages often do not support
this ’temporal aggregation’ [16].
Adding to the complexity of supply chain management
is the frequently encountered issue of poor data quality at
SMEs [17]. Furthermore, planning and scheduling often rely
on decentralized spreadsheets. Supply chain managers often
find themselves manually collecting data, such as inventory
levels and order status, in an ad hoc manner. The decision
making that then follows is often done based on the intuition
and business knowledge of the manager.
B. The rise of low and no code platforms
While modern data technology can address data quality
concerns, SMEs might not be able to apply it directly as
they lack the necessary skills and IT support [15]. Enhancing
data quality is also expensive. According to Anaconda’s 2022
“The state of data science” survey, respondents spend around
22% of their time on data preparation and 16% on data
cleansing [18]. An earlier survey suggested that up to 70%
of time is consumed by tasks related to data cleansing [19].
However, recent studies propose that this knowledge gap is
closing, partly due to the rising popularity of low/no code
platforms [20]. Gartner predicts a 19.6% growth in the low
code market for 2023, attributed to a scarcity of tech talent
and an increasing hybrid and borderless workflow [21].
Low/no code empowers companies to create, deploy, and
maintain applications through drag-and-drop visual compo-
nents. This method avoids the need to master intricate coding
languages, making it easier for a broader range of users. No
code goes even further by eliminating coding completely [22].
Both low code and no code can aid in Extract, Transform
and Load (ETL), cutting significant time previously devoted to
these tasks [18]. It simplifies these tasks for non-technical staff.
With its comprehensibility to a broader range of professionals,
low code is said to have a democratizing effect, engaging
business experts too. This characteristic also makes it more
suitable for SMEs [23].
Low/no code brings numerous benefits. A survey of IT-
professionals highlighted that key advantages including ease of
use, resource savings, easy prototyping and increased produc-
tivity [24]. A study in the logistics sector found that low code
platforms reduce the reliance on skilled programmers [25]. Li
and Wu [20] also confirmed user preference for low code/no
code solutions.
Expanding employee involvement in data/AI projects is
just one benefit. Bridging the gap between data scientists
and business specialists also makes projects more meaningful
for organizations. Engaging domain experts in the data/AI
development process is crucial, especially for tasks like data
annotation, augmentation, and interpretation [23].
C. Challenges of low code platforms
While low/no code platforms offer exciting opportunities
for smaller firms, there are still several challenges companies
face when trying to put them to use. Setting proper guidelines
is key when trying to address these challenges.
The concern most mentioned by IT professionals is plat-
form dependence [24]. When an organization adopts a low
code platform, it relies on the platform’s vendor. Tied into this
challenge is the fragmentation of the low code landscape. Each
platform has its own low code developing paradigm. Using the
tool effectively requires the user to get acquainted with the
specific tool in question [26].
Another challenge mentioned in the literature is scalability
and interoperability [23][26]. Most low code platforms are well
suited for designing small applications but lack the ability to
support bigger infrastructures. For SMEs this is their number
of users is likely small. Interoperability is a challenge however,
since the IT infrastructure at small firms can still be scattered.
Lastly, there is the risk of inadequate maintenance and
testing. Although low code software is easily maintainable
[27], it might not be done in practice. Since the literature on
low code is still lacking in this area, it can be worthwhile to
look at evidence from studies on spreadsheet modeling. They
reveal that end-user programmers make considerably more
errors in modeling than professional programmers [28]. While
spreadsheets are often tested, many end-user programmers
do not follow structured testing methods that are typical in
software development [29]. Improper testing is often caused
by an overconfidence in end-users programmers’ ability to
identify errors in spreadsheets [30]. Spreadsheet modeling also
shows a lack of documentation: Hermans et al. [31] find
that only approximately one in three spreadsheets contains
documentation. As a consequence, spreadsheets are frequently
explained by inefficient and inconsistent 1-1 communication
between employees, such as via e-mail [32].
D. Guidelines for low code platforms
In order to address the aforementioned challenges, setting
proper guidelines can be helpful. Some literature already
exists on this topic. Rokis and Kirikova [27] mention seven
challenges based on a systemic literature review and Sundberg
and Holmstr¨om [23] mention specific guidelines when using
low code platforms in ML operations. In the context of SMEs
in the logistics sector, we propose the following guidelines:
Have an overarching organizational AI strategy
While low code platforms are user-friendly, merely provid-
ing them to professionals in the organization doesn’t ensure
their adoption and effective use [23]. A study which focused
on the application of low code platforms in supply chain
management concluded that the lack of an adoption strategy
2
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

is a major barrier in organizational adoption [33]. We propose
that organizations should not forget employee skill enhance-
ment as part of such a strategy. By adequately training users,
maintenance and testing can be improved.
Limiting platform dependence and increasing interoperability
Vendor lock-in is one of the main concerns surrounding low
code development platforms and mitigating it is challenging.
However, Ihirwe et al. [34] via [27] mention that ensuring
interoperability can help mitigate this dependence. Low code
applications should at least be able to communicate with the
external world using for example APIs. This is especially
important in supply chain management as information sharing
within the value chain is important [35].
Ensuring adequate testing and maintenance
Each low code development platform has specific ways of
maintenance and testing. Although maintenance of an appli-
cation might be easier compared to traditional programming
code, creating awareness within the organization is still needed.
Companies should also consider the ease of setting up testing
procedures as a criterium for vendor selection. The ability to
test applications varies across the different platforms [36].
III.
ON THE ROLE OF MACHINE LEARNING IN PLANNING
AND FORECASTING IN SUPPLY CHAINS (RQ2)
The analytical maturity assumption (AMA) is often used
to illustrate the typical roadmap towards becoming more data-
driven, and is therefore adopted in the I4.0P. Best known is the
analytics maturity curve by Gartner, though several adaptations
exist [37]. In this section we will challenge the validity of this
assumption and why machine learning might be benificial to
companies that have low levels of ”data-readiness”.
A. The Analytics Maturity Assumption
The AMA is found in numerous reviews on the role of
BDA in I4.0P (e.g., [6][7][37]). As illustrated in Figure 1, the
AMA outlines different stages that organizations go through to
enhance their analytical maturity, progressing from descriptive
(“What happened”) and diagnostic (“Why did it happen?”), to
predictive (“What will happen”) and prescriptive (“How can
we make it happen?”). With each stage, the complexity of the
(statistical) models increases. Where descriptive analytics is
mainly concerned with reporting from existing data sources,
i.e., the use of descriptive statistical techniques, predictive
and prescriptive analytics employ AI/ML to make accurate
forecasts and make data-driven decisions.
Advancing in the AMA relies largely on the availability
and quality of data sources. However, as mentioned earlier,
data quality is problematic in supply chains. Furthermore,
even if data quality is improved, there is no guarantee that
this data will lead to more accurate predictions [38]. In fact,
current academic literature is indecisive on whether ML is
preferred over traditional statistical methods for forecasting
[39][40]. So why, according the the AMA, does the usage
of ML in forecasting lead to better predictions? And if it does
not improve forecasting, what is then the business rationale for
ML, beyond forecasting?
B. Machine-learning for improving data quality
Analytical maturity models suggest that ML models are
aimed to “predict what will happen” (forecast) and to decide
the best course of action under such forecast [41]. Practical
applications of ML, however, show a different purpose. ML
is commonly employed to enhance ”data-readiness,” a concept
that goes beyond just data quality, but also ensures that data
is suitable for a specific context of forecasting and decision-
making [42].
Academic literature shows many examples where ML
enhances data-readiness. For instance, although Karkouch et al.
[43] present different data quality challenges in IoT, they
also list different strategies to contest these. Many of these
are ‘model-based’ algorithms that use ML to detect outliers.
Perhaps it should therefore be no surprise that outlier detection
is a common application of active learning [44].
ML is frequently used for data imputation, which under cer-
tain conditions improves the further forecasting/optimization
task, even if this ‘downstream’ task uses more traditional
statistical models [45]. Given the multimodality of many
datasets, the ML community has put its attention to techniques
such as ‘data fusion’ [46]. This allows integrating different
data sources for further downstream tasks. Also, recent Large
Language Models such as GPT-4 find their application in
what could be considered data preparation/data cleaning and
feature engineering tasks, such as data augmentation, text
classification, named entity recognition, and translation [47].
In other words, ML has become a method that offers a
clearer understanding of “what happened”, perhaps more than
“what will happen”. Here, the term ‘predict’ is ambiguous.
While the AMA seems to imply it is about time-based pre-
dictions (i.e., forecasts), the previous examples (predicting
outliers, missing data, missing labels, etc.) show that this is
often to improve data-readiness.
IV.
ON DATA-DRIVEN DECISION-MAKING (RQ2)
Data Analytics and Data Science have long been presented
as solutions for mitigating biases in decision-making (e.g., [48,
Ch. 1], [49, Ch. 2], [50]). This section will firstly address that
there exist other methods for reducing biases (such as wisdom
of the crowds). Secondly, it will question whether decision
makers within SMEs have the necessary skills to use data
driven methods such as machine learning.
A. Data-driven decision-making is not the only method for
reducing judgemental biases
This perspective is supported by findings from behavioral
economics, which identify decision biases, like the hindsight
bias or confirmation bias, which can lead to irrational choices
[51]. In the light of the scientific method, data and statistical
methods can be used to validate ones believes. By reducing
judgemental biases, improved decision-making may lead to
some “value”, whether economic or social [52, p. 6]. While
some studies indicate that companies that implement data-
driven decision-making outperform companies that do not [7],
many companies, including SMEs, struggle with data-driven
decision-making [53]. Decision are often based on personal
experience [50, Ch. 7].
What is frequently overlooked in the argument favoring
data science and analytics against judgmental biases is that
decision sciences have also introduced alternative methods for
bias reduction, or have studied when intuition can be trusted
and when not [54]. These methods, partially or fully relying on
3
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

What
happened?
Why did it
happen?
What will
happen?
How can we
make it happen?
Descriptive
Analytics
Diagnostic
Analytics
Predictive
Analytics
Prescriptive
Analytics
AI/ML is often used in data preparation/cleansing,
enhancing descriptive/diagnostic analytics
Figure 1. Gartner analytics maturity as presented by [37], where does AI/ML contribute value?
expert knowledge, differ from a complete reliance on ’letting
the data speak for itself’. Rather, they provide guidelines that
assist forecasters and decision-makers in reducing judgemental
bias. For example, the usage of Wisdom of the Crowds (WoC),
or variations such as “surprisingly popular” [55], are scarcely
mentioned in the I4.0P, nor the different guidelines forecasters
may use to eliminate judgemental biases [56].
End-user programmers and decision-makers could benefit
from these results in the decision sciences. They provide
methods for reliable decision-making in data-poor environ-
ments, which are prevalent in supply chains. Also, they are
easier to implement compared to methods that heavily depend
on data. Especially combining supply chain data with expert
judgement, following guidelines from the decision sciences,
may be fruitful. Although, as indicated by Syntetos et al. [16],
data may not be on the right decision-making level, it does
provide boundaries and conditions to which estimates from
expert judgement should adhere.
Only recently has the AI community shifted its perspec-
tive from model-centered to data-centered AI [57][58], and
has thereby increased its attention on the human aspect in
data sources, models and decision-making. As Balazka and
Rodighiero [59] pointed out, it is a person who decides what
data is collected, who gets access to the data, what data gets
labeled and how it is labeled. In essence, even if data is used
to support decision-making, it remains susceptible to human
judgement. However, this shift towards human-centeredness
has not been noticed in the review by Silva et al. [37] on
the role of BDA in Industry 4.0, hence, remains absent in the
I4.0P.
B. Can decision-makers interpret empirical results?
Decision-makers seem to neglect that the data and subse-
quent conclusions used for data-driven decision-making does
not have to be data or findings within their own context (e.g.,
within their own organization). When decision-makers are
asked about evidence-based practice (which does not only base
its decisions on own analysis, but also on other sources such as
experts and scientific literature), one finds that decision-makers
rarely consult scientific evidence that may generalize to their
own organization. Decision-makers report lack of time, lack of
understanding of scientific research, and the unreadability of
academic writing as reasons for not using empirical evidence
from the (scientific) community [50].
This reveals a paradox: if decision-makers, in SMEs or
elsewhere, lack the time and expertise to interpret scientific
(that is, data-driven) results, how can they accurately interpret
results from empirical evidence within their own organization,
which employ the same statistical principles? In terms of skills
end-user programmers and decision-makers require, it becomes
clear that although low/no code assists data modeling, there
remains a skill gap in how to interpret the outcomes of these
models and how to reflect these to existing literature.
V.
CONCLUSION AND FUTURE WORK
As low/no code platforms become more popular in organi-
zations, more professionals without formal IT/data science ed-
ucation will engage in data modeling. These platforms can help
improve organizations’ data-readiness in supply chains, while
also making data modeling easier for non-technical users. This
could therefore also benefit SMEs. Overall, low/code software
and platforms might help address various data challenges in
modern supply chains, such as IoT data quality problems and
the mismatch between data measurement and decision-making
levels.
However, there are several risks involved in this increase
in end-user programmers. In order to address the risks and
find potential guidelines we provide answers to the following
research questions:
RQ1: How are low code development platforms relevant
for SMEs within the logistics sector and what are the
challenges and necessary guidelines?
RQ2: How does the actual usage of BDA in decision-
making differ from end-user programmers’ expectations
when utilizing low/no code software for data modeling and
what are the implications of this disparity?
(RQ1) Guidelines on for low code platforms: While
research on the usage of different low/no code platforms
and solutions for analytical purposes is still in its infancy,
research from spreadsheet modeling suggests that end-user
programmers are more likely to make errors in modeling.
Therefore, SMEs should adhere to guidelines in order to reduce
this risk. Firstly, developing a comprehensive organizational
AI strategy that emphasizes employee skill enhancement is
needed. Secondly, reducing platform dependence and promot-
ing interoperability (via APIs) is key, especially when sharing
information within the supply chain. Lastly, ensuring proper
testing and maintenance is needed.
(RQ2) The Analytical Maturity Assumption: When end-
user programmers use low/no code software for modeling, they
hold certain expectations on how the models and algorithms
will support decision-making. These expectations often align
with the analytics maturity curve and underlying assumptions,
which in this paper we have called the Analyical Maturity
Assumption (AMA). However, evidence suggest that AMA
is flawed. In practice, predictive (machine learning (ML))
4
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

models are typically used to improve one’s understanding of
“what happened”. This by employing methods like outlier
detection, filling missing values, and data fusion. In contrast,
the literature is inconclusive on whether ML models should
be preferred over traditional statistical models in forecasting.
This observation may be especially relevant to actors in supply
chains: instead of using ML directly to improve forecasting
and decision-making, it may be wiser to use these techniques
to improve data-readiness. The refined data could then be
employed for forecasting/decision-making, where conventional
methods might be more fitting, .
(RQ2) Can end-user programmers/decision-makers in-
terpret statistical results?: There seems to be a paradox in
how organizations try to become more data-driven, and how
they use scientific evidence. Research towards evidence-based
practice shows that decision-makers rarely consult scientific
evidence that may well generalize to their own context. Rea-
sons include lack of time, lack of understanding scientific
research, and unreadability of research reports. If decision-
makers struggle with using research outcomes, how can they
grasp results from in-house data analysis rooted in the same
statistical principles? Put differently, while low/no code so-
lutions simplify the modeling part of data analysis, end-user
programmers and decision-makers should still be trained in
how to interpret results from statistical models, whether these
originate from in-house analysis or elsewhere. Organizations
should also acknowledge existing scientific evidence before
delving into their own data, to guide and benchmark their own
efforts.
Considering the growing adoption of low/no code plat-
forms, more research is needed in this area. In this paper
we found that low/no code platforms promise to democratize
AI solutions. However, there is a skill gap present at SMEs
which could form a potential risk when these platforms gain
in popularity. Research should focus on how both companies
and the low/no code platforms themselves address this skill
gap.
REFERENCES
[1] K. Katsaliaki, P. Galetsi, and S. Kumar, “Supply chain
disruptions and resilience: A major review and future
research agenda,” Annals of Operations Research, vol.
319, no. 1, pp. 965–1002, 2022.
[2] FEMA, “Make your business resilient: Business info-
graphic,” 2015.
[3] M. Kilibarda, V. Paji´c, and M. Andreji´c, “Human re-
sources in logistics and supply chains: Current state and
trends,” International Journal for Traffic and Transport
Engineering, vol. 9, no. 3, pp. 270–279, 2019.
[4] TKI
Dinalog,
“Topsector
logistiek
2022-2026
–
call
for
proposals,”
https://www.dinalog.nl/wp-
content/uploads/2022/12/Topsector-Logistiek-2022-
2026-Call-2-2022-Deel-A-Topsector-Logistiek-
FINAL.pdf, last accessed: 2023-10-10, 2022.
[5] K. Govindan, D. Kannan, T. B. Jørgensen, and T. S.
Nielsen, “Supply chain 4.0 performance measurement:
A systematic literature review, framework development,
and empirical evidence,” Transportation Research Part E:
Logistics and Transportation Review, vol. 164, no. 12, p.
102725, 2022.
[6] D. Ivanov and A. Dolgui, “A digital supply chain twin
for managing the disruption risks and resilience in the era
of industry 4.0,” Production Planning & Control, vol. 32,
no. 9, pp. 775–788, 2021.
[7] S. Winkelhaus and E. H. Grosse, “Logistics 4.0: a system-
atic review towards a new logistics system,” International
Journal of Production Research, vol. 58, no. 1, pp. 18–
43, 2020.
[8] R. Toorajipour, V. Sohrabpour, A. Nazarpour, P. Oghazi,
and M. Fischl, “Artificial intelligence in supply chain
management: A systematic literature review,” Journal of
Business Research, vol. 122, pp. 502–517, 2021.
[9] B. McKinsey, “The state of AI in 2022—and a half
decade in review,” http://ceros.mckinsey.com/mckinsey-
commentary-ai-hall-desktop-1, last accessed: 2023-10-
10, 2022.
[10] H. Sheikh, C. Prins, and E. Schrijvers, Mission AI: The
New System Technology.
Springer Nature, 2023.
[11] D. Ø. Madsen and T. Stenheim, “Big data viewed through
the lens of management fashion theory,” Cogent Business
& Management, vol. 3, no. 1, p. 1165072, 2016.
[12] Gartner, “Gartner survey reveals less than half of data
and analytics teams effectively provide value to the orga-
nization,”
https://www.gartner.com/en/newsroom/press-
releases/03-21-2023-gartner-survey-reveals-less-than-
half-of-data-and-analytics-teams-effectively-provide-
value-to-the-organization,
last
accessed:
2023-10-10,
2023.
[13] M. Cichosz, C. M. Wallenburg, and A. M. Knemeyer,
“Digital transformation at logistics service providers:
barriers, success factors and leading practices,” The Inter-
national Journal of Logistics Management, vol. 31, no. 2,
pp. 209–238, 2020.
[14] J. Riedl, Digital Transformation in the Logistics Industry,
2018.
[15] K. Gudfinnsson, “Towards facilitating bi adoption in
small and medium sized manufacturing companies,”
Ph.D. dissertation, University of Skovde, 2019.
[16] A. A. Syntetos, Z. Babai, J. E. Boylan, S. Kolassa,
and K. Nikolopoulos, “Supply chain forecasting: Theory,
practice, their gap and the future,” European Journal of
Operational Research, vol. 252, no. 1, pp. 1–26, 2016.
[17] B. T. Hazen, C. A. Boone, J. D. Ezell, and L. A.
Jones-Farmer, “Data quality for data science, predictive
analytics, and big data in supply chain management: An
introduction to the problem and suggestions for research
and applications,” International Journal of Production
Economics, vol. 154, pp. 72–80, 2014.
[18] Anaconda, “Anaconda state of data science report 2022,”
https://www.anaconda.com/resources/whitepapers/state-
of-data-science-report-2022, last accessed: 2023-10-10,
2022.
[19] G. Press, “Cleaning big data: Most time-consuming,
least
enjoyable
data
science
task,
survey
says,”
https://www.forbes.com/sites/gilpress/2016/03/23/data-
preparation-most-time-consuming-least-enjoyable-data-
science-task-survey-says,
last
accessed:
2023-10-10,
2016.
[20] L. Li and Z. Wu, “How can no/low code platforms help
end-users develop ml applications?-a systematic review,”
in International Conference on Human-Computer Inter-
action.
Springer, 2022, pp. 338–356.
5
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

[21] Gartner,
“Gartner
Forecasts
Worldwide
Low-Code
Development Technologies Market to Grow 20% in
2023,”
https://www.gartner.com/en/newsroom/press-
releases/2022-12-13-gartner-forecasts-worldwide-low-
code-development-technologies-market-to-grow-20-
percent-in-2023, last accessed: 2023-10-10, 2022.
[22] IBM Cloud education, “Low-Code vs. No-Code: What’s
the Difference?” https://www.ibm.com/blog/low-code-vs-
no-code, last accessed: 2023-10-10, 2022.
[23] L. Sundberg and J. Holmstr¨om, “Democratizing artifi-
cial intelligence: How no-code AI can leverage machine
learning operations,” Business Horizons, 2023.
[24] J. X. Silva, M. Lopes, G. Avelino, and P. Santos, “Low-
code and No-code Technologies Adoption: A Gray Lit-
erature Review,” in SBSI ’23: Proceedings of the XIX
Brazilian Symposium on Information Systems.
ACM,
2023, pp. 388–395.
[25] S. S. Bhattacharyya and S. Kumar, “Study of deployment
of “low code no code” applications toward improving
digitization of supply chain management,” Journal of
Science and Technology Policy Management, vol. 14,
no. 2, pp. 271–287, 2023.
[26] M. Tisi et al., “Lowcomote: Training the next generation
of experts in scalable low-code engineering platforms,”
in International Conference on Software Technologies:
Applications and Foundations, 2019.
[27] K. Rokis and M. Kirikova, “Challenges of low-code/no-
code software development: A literature review,” in Per-
spectives in Business Informatics Research, ¯E. Nazaruka,
K. Sandkuhl, and U. Seigerroth, Eds.
Cham: Springer
International Publishing, 2022, pp. 3–17.
[28] R. R. Panko, “What we don’t know about spreadsheet
errors today: The facts, why we don’t believe them, and
what we need to do,” in The European Spreadsheet Risks
Interest Group 16th Annual Conference (EuSpRiG 2015).
EuSpRiG, 2015.
[29] S. Roy, F. Hermans, and A. van Deursen, “Spreadsheet
testing in practice,” in 2017 IEEE 24th International
Conference on Software Analysis, Evolution and Reengi-
neering (SANER).
IEEE, 2017, pp. 338–348.
[30] R. R. Panko, “Two experiments in reducing overconfi-
dence in spreadsheet development,” Journal of Organiza-
tional and End User Computing (JOEUC), vol. 19, no. 1,
pp. 1–23, 2007.
[31] F. Hermans et al., “Spreadsheets are code: An overview
of software engineering approaches applied to spread-
sheets,” in 2016 IEEE 23rd International Conference
on Software Analysis, Evolution, and Reengineering
(SANER), vol. 5.
IEEE, 2016, pp. 56–65.
[32] F. Hermans and E. Murphy-Hill, “Enron’s spreadsheets
and related emails: A dataset and analysis,” in 2015
IEEE/ACM 37th IEEE International Conference on Soft-
ware Engineering, vol. 2.
IEEE, 2015, pp. 7–16.
[33] S. S. Bhattacharyya and S. Kumar, “Study of deployment
of “low code no code” applications toward improving
digitization of supply chain management,” Journal of
Science and Technology Policy Management, no. ahead-
of-print, 2021.
[34] F. Ihirwe, D. Di Ruscio, S. Mazzini, P. Pierini, and
A. Pierantonio, “Low-code engineering for internet of
things: a state of research,” in Proceedings of the 23rd
ACM/IEEE international conference on model driven
engineering languages and systems: companion proceed-
ings, 2020, pp. 1–8.
[35] Z. Lotfi, M. Mukhtar, S. Sahran, and A. T. Zadeh, “Infor-
mation sharing in supply chain management,” Procedia
Technology, vol. 11, pp. 298–304, 2013, 4th International
Conference on Electrical Engineering and Informatics,
ICEEI 2013.
[36] F. Khorram, J.-M. Mottu, and G. Suny´e, “Challenges &
opportunities in low-code testing,” in MODELS ’20: Pro-
ceedings of the 23rd ACM/IEEE International Conference
on Model Driven Engineering Languages and Systems:
Companion Proceedings.
ACM, 2020, pp. 1–10.
[37] A. J. Silva, P. Cortez, C. Pereira, and A. Pilastri, “Busi-
ness Analytics in Industry 4.0: A systematic review,”
Expert systems, vol. 38, no. 7, p. e12741, 2021.
[38] A. Paleyes, R.-G. Urma, and N. D. Lawrence, “Chal-
lenges in deploying machine learning: a survey of case
studies,” ACM Computing Surveys, vol. 55, no. 6, pp.
1–29, 2022.
[39] S. Makridakis, E. Spiliotis, and V. Assimakopoulos,
“Statistical and machine learning forecasting methods:
Concerns and ways forward,” PloS one, vol. 13, no. 3, p.
e0194889, 2018.
[40] C. S. Bojer and J. P. Meldgaard, “Kaggle forecasting
competitions: An overlooked learning opportunity,” In-
ternational Journal of Forecasting, vol. 37, no. 2, pp.
587–603, 2021.
[41] K. Kr´ol and D. Zdonek, “Analytics maturity models: An
overview,” Information, vol. 11, no. 3, p. 142, 2020.
[42] N. D. Lawrence, “Data readiness levels,” arXiv preprint
arXiv:1705.02245, 2017.
[43] A. Karkouch, H. Mousannif, H. Al Moatassime, and
T. Noel, “Data quality in internet of things: A state-
of-the-art survey,” Journal of Network and Computer
Applications, vol. 73, pp. 57–81, 2016.
[44] H. Trittenbach, A. Englhardt, and K. B¨ohm, “An
overview and a benchmark of active learning for outlier
detection with one-class classifiers,” Expert Systems with
Applications, vol. 168, p. 114372, 2021.
[45] S. J¨ager, A. Allhorn, and F. Bießmann, “A benchmark for
data imputation methods,” Frontiers in big Data, vol. 4,
p. 693674, 2021.
[46] T. Meng, X. Jing, Z. Yan, and W. Pedrycz, “A survey on
machine learning for data fusion,” Information Fusion,
vol. 57, pp. 115–129, 2020.
[47] H. Hassani and E. S. Silva, “The role of ChatGPT in
data science: how AI-assisted conversational interfaces
are revolutionizing the field,” Big data and cognitive
computing, vol. 7, no. 2, p. 62, 2023.
[48] T. H. Davenport and J. G. Harris, Competing on ana-
lytics: the new science of Winning.
Harvard Business
School Press, 2007.
[49] S. Makridakis, Forecasting, Planning, and Strategies for
the 21st Century.
Free Press, 1990.
[50] E.
Barends,
D.
M.
Rousseau,
and
R.
B.
Briner,
“Evidence-based management: The basic principles,” in
In Search of Evidence: Empirical findings and profes-
sional perspectives on evidence- based management. VU
University Press, 2015, pp. 203–220.
[51] D. Kahneman, Thinking, fast and slow (1st edition).
Farrar, Straus and Giroux, 2011.
[52] W. A. G¨unther, Data as strategic resources: Studies on
6
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

how organizations explore the strategic opportunities of
data.
Vrije Universiteit Amsterdam, 2019.
[53] A.-M. J¨arvenp¨a¨a, J. Jussila, and I. Kunttu, “Barriers
and practical challenges for data-driven decision-making
in circular economy smes,” in Big Data and Decision-
Making: Applications and Uses in the Public and Private
Sector. Emerald Publishing Limited, 2023, pp. 163–179.
[54] D. Kahneman and G. Klein, “Conditions for intuitive
expertise: a failure to disagree,” American psychologist,
vol. 64, no. 6, pp. 515–526, 2009.
[55] D. Prelec, H. S. Seung, and J. McCoy, “A solution to
the single-question crowd wisdom problem,” Nature, vol.
541, no. 7638, pp. 532–535, 2017.
[56] B. Mellers et al., “The psychology of intelligence anal-
ysis: Drivers of prediction accuracy in world politics.”
Journal of experimental psychology: applied, vol. 21,
no. 1, p. 1, 2015.
[57] M.
Mazumder
et
al.,
“Dataperf:
Benchmarks
for
data-centric
AI
development,”
arXiv
preprint
arXiv:2207.10062, 2022.
[58] D. Zha et al., “Data-centric artificial intelligence: A
survey,” arXiv preprint arXiv:2303.10158, 2023.
[59] D. Balazka and D. Rodighiero, “Big data and the little
big bang: An epistemological (r)evolution,” Frontiers in
big Data, vol. 3, 2020.
7
Copyright (c) IARIA, 2023.     ISBN:  978-1-68558-086-5
PREDICTION SOLUTIONS 2023 : International Conference on Prediction Solutions for Technical and Societal Systems - 2023

