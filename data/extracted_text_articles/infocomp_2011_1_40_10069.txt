The Simple Genetic Algorithm Performance: A Comparative Study on the
Operators Combination
Delmar Broglio Carvalho,
Jo˜ao Carlos N. Bittencourt
Tecnology Department
State University of Feira de Santana (UEFS)
Feira de Santana, Brazil
E-mail: {carvalho.db, joaocarlos}@ecomp.uefs.br
Thiago D’Martin Maia
Department of Mathematical Sciences
State University of Feira de Santana (UEFS)
Feira de Santana, Brazil
E-mail: tdmaia@uefs.br
Abstract—This paper presents a comparative and experi-
mental study about the performance of the Simple Genetic
Algorithm (SGA) using ﬁve classic benchmarking functions.
The performance analysis is accomplished on the combination
of the operators of reproduction and crossover with the control
parameters having been ﬁxed. The overall behavior of the
SGA is evaluated by the ﬁtness of the best individual analyzed
during the evolution and at the ending of the same one. The
results that are presented show that the SGA can be effective
and competitive to optimization on a test suite of benchmark
functions.
Keywords-Genetic
Algorithm;
Parameterization
of
GA;
Generational Replacement Model; Single-Point Crossover; Uni-
form Crossover.
I. INTRODUCTION
The Simple Genetic Algorithm (SGA) presented by
Goldberg [1] plays an important role in the use of the
approaches based on the dynamics of natural genetics and
still being a study target [2]. This proposal has been used
in the implementation of many derived approaches, and
many researchers have drawn the performance analysis of
the Genetic Algorithms (GAs) basing its studies in the
control parameters (populations size, crossover and mutation
rates) and their potential adjustment [3]. Normally, this
parameterization depends on the knowledge of the designer
about the problem deﬁnition; of the values attributed to the
parameters and of the adequate choice of the used methods
to implement the operators. In this universe of choices,
each designer can create a particular algorithm to a speciﬁc
problem [4]–[7], being always a generic SGA as the worse
one of the implementations.
In this paper, the SGA performance is examined into
ﬁve benchmarking functions, considering a ﬁxed size of the
population and constant crossover and mutation rates. The
performance test is carried out through for the combina-
tion of three strategies of reproduction and two kinds of
crossover. No additional strategy was established, and the
benchmarking functions were normalized to facilitate the
comparisons.
The present paper is structured as follows: Section II
presents the benchmarking functions and Section III de-
scribes the methodology used. In Section IV, results of
experiments are reported. In Section V, some general con-
clusions are mentioned.
II. BENCHMARKING FUNCTIONS
Many benchmarking functions have been used to perform
a stress test of various GA approaches. Digalakis [3] sum-
marizes this set of benchmarking functions, which comes the
set of characteristics required for benchmarking tests using
GAs. In this set, ﬁve functions had been selected to perform
the proposed study, which are listed below:
1) F1 function (Sphere): paraboloid function, smooth,
unimodal, convex, symmetric, and whose convergence to the
global optimum is easily achieved.
f1 (x) =
2
X
i=1
x2
i
(1)
−5.12 ≤ xi ≤ 5.12
2) F2 function (Rosenbrock): considered of high difﬁculty
level resembling a saddle function, imposing strong restric-
tions on the algorithms that are not suitable to search for
directions.
f2 (x) = 100

search for global optimal solution, given the existence of
numerous local solutions.
f4 (x) = 10 · n +
2
X
i=1

0
10
20
30
40
50
60
70
80
0.92
0.93
0.94
0.95
0.96
0.97
0.98
0.99
1
Generation
Normalized Fitness
Figure 1.
100 Independent runs and the mean value to F1 function with
combination C11.
0
10
20
30
40
50
60
70
80
0.986
0.988
0.99
0.992
0.994
0.996
0.998
1
Generation
Mean of 100 runs
C11
C12
C21
C22
C31
C32
Figure 2.
Comparative of the mean of the normalized ﬁtness, to F1
function, in 100 runs.
Table I
MEAN VALUES AND VARIANCES TO F1 FUNCTION.
10th generation
80th generation
µ
σ2 × 10−5
µ
σ2 × 10−5
C11
0.9972
1.5339
0.9997
0.1644
C12
0.9957
2.3725
0.9996
0.0454
C21
0.9943
3.9221
0.9998
0.0167
C22
0.9974
1.7816
0.9999
0.0249
C31
0.9983
1.3449
1.0000
0.000119
C32
0.9978
0.8595
0.9999
0.005012
and variance over the runs, becoming a criteria for numerical
comparisons.
The values in Table I show excellent results to any
combination for ongoing and stopped analysis. The low
values of variance demonstrate that any run can be effective
in the search of the optimal solution.
The obtained results to the combinations for functions F2-
F5 that are depicted in Figures 3-6 and Tables II-V show the
summarization of the results respectively by the measure of
mean and variance, respectively.
0
10
20
30
40
50
60
70
80
0.9995
0.9995
0.9996
0.9996
0.9997
0.9997
0.9998
0.9998
0.9999
0.9999
1
Generation
Mean of 100 runs
C11
C12
C21
C22
C31
C32
Figure 3.
Comparative of the mean of the normalized ﬁtness, to F2
function, in 100 runs.
Table II
MEAN VALUES AND VARIANCES TO F2 FUNCTION.
10th generation
80th generation
µ
σ2 × 10−8
µ
σ2 × 10−8
C11
0.9999
1.7021
1.0000
0.2462
C12
0.9999
3.5903
1.0000
0.5344
C21
0.9998
6.5557
0.9999
2.3654
C22
0.9999
2.5488
1.0000
0.9630
C31
0.9999
1.6755
1.0000
0.5718
C32
0.9999
1.2254
0,9999
0.7725
Table III
MEAN VALUES AND VARIANCE TO F3 FUNCTION.
10th generation
80th generation
µ
σ2 × 10−4
µ
σ2 × 10−4
C11
0.9978
2.3391
1.0000
0.0000
C12
0.9989
1.1815
1.0000
0.0000
C21
0.9967
3.4728
1.0000
0.0000
C22
1.0000
0.0000
1.0000
0.0000
C31
1.0000
0.0000
1.0000
0.0000
C32
1.0000
0.0000
1.0000
0.0000
In tables IV and V,the average decrease between rounds
over the previous tables due to the nature of performance
22
INFOCOMP 2011 : The First International Conference on Advanced Communications and Computation
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-161-8

0
10
20
30
40
50
60
70
80
0.98
0.985
0.99
0.995
1
1.005
Generation
Mean of 100 runs
C11
C12
C21
C22
C31
C32
Figure 4.
Comparative of the mean of the normalized ﬁtness, to F3
function, in 100 runs.
0
10
20
30
40
50
60
70
80
0.9
0.91
0.92
0.93
0.94
0.95
0.96
0.97
0.98
0.99
Generation
Mean of 100 runs
C11
C12
C21
C22
C31
C32
Figure 5.
Comparative of the mean of the normalized ﬁtness, to F4
function, in 100 runs.
Table IV
MEAN VALUES AND VARIANCES TO F4 FUNCTION.
10th generation
80th generation
µ
σ2 × 10−4
µ
σ2 × 10−4
C11
0.9604
7.1088
0.9853
2.2892
C12
0.9512
9.1016
0.9784
2.9781
C21
0.9431
13.123
0.9733
6.0680
C22
0.9594
6.5950
0.9809
2.5381
C31
0.9759
2.3428
0.9833
1.4531
C32
0.9576
5.6891
0.9743
4.5210
among the results is veriﬁed. To elect a winning combination
we decided to analyze the one variance with the lowest
since the average of the same order of magnitude. For the
two moments of evolution, the combination C31 is the one
0
10
20
30
40
50
60
70
80
0.75
0.8
0.85
0.9
0.95
1
Generation
Mean of 100 runs
C11
C12
C21
C22
C31
C32
Figure 6.
Comparative of the mean of the normalized ﬁtness, to F5
function, in 100 runs.
Table V
MEAN VALUES AND VARIANCES TO F5 FUNCTION.
10th generation
80th generation
µ
σ2 × 10−3
µ
σ2 × 10−4
C11
0.9771
1.63
0.9923
0.8348
C12
0.9593
5.14
0.9882
1.4573
C21
0.9384
16.53
0.9863
1.6812
C22
0.9736
2.87
0.9884
1.3815
C31
0.9827
1,77
0.9941
0.5224
C32
0.9745
1,13
0.9866
1.2796
with the best performance among the results. The lower
values obtained for the variance show that any round can be
effective in ﬁnding the optimal solution. After analysis of
these data, it appears that the solutions for all combinations
of the set of operations can be considered as optimal
solutions.
After examining these results, the good results gotten
in all the considered set’s combinations are veriﬁed. To
compose a generic sketch with all benchmarking functions
and the entire combinations set, these results were combined.
The Figures 7 and 8 show the similarity in performance to
the test functions and the combinations.
These results show that the benchmarking functions F1,
F2 and F3 impose the same behavior to all operators combi-
nations and, consequently, reliable results are obtained. The
functions F4 and F5, due to their nature, impose a different
behavior to the operators combinations. In this context, the
C31 combination preserves its good performance relatively
to others combinations, and the differences in the values,
veriﬁed according the variances values, are not signiﬁcant.
23
INFOCOMP 2011 : The First International Conference on Advanced Communications and Computation
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-161-8

F1  
F2  
F3  
F4  
F5  
0.93
0.94
0.95
0.96
0.97
0.98
0.99
1
Test function
Mean of normalized fitness
C11
C12
C21
C22
C31
C32
Figure 7.
Performance analysis at 10th generation.
F1  
F2  
F3  
F4  
F5  
0.97
0.975
0.98
0.985
0.99
0.995
1
1.005
Teste function
Mean of normalized fitness
C11
C12
C21
C22
C31
C32
Figure 8.
Performance analysis at 80th generation.
V. CONCLUSION
This paper has accomplished a performance analysis for
the SGA approach - a simple genetic algorithm. This ana-
lysis, using a subset of benchmarking functions and doing
combinations of operators, show the effectiveness of the
SGA algorithm. In other words, given a search space, a
convergence region is provided; local optima, which are
widespread in some objective functions, are overcomed;
and a useful set of feasible solutions is reached. These
experiments show that the combination of stochastic tour-
nament with single-point crossover is the combination that
provides better results. The results described in this paper
are signiﬁcant because they show that the basic formulation
of SGA is competitive in the different contexts found in the
objective functions.
REFERENCES
[1] D. E. Goldberg, Genetic algorithms in search, optimization and
machine learnin.
New York: Addison–Wesley, 1988.
[2] J.-Y. Xie, Y. Zhang, C.-X. Wang, and S. Jiang, “Genetic
algorithm and adaptive genetic algorithm based on splitting
operators,” in Jisuanji Gongcheng yu Yingyong (Computer
Engineering and Applications), vol. 46, no. 33, 21 Sep. 2010,
pp. 28–31.
[3] J. Digalakis and K. Margaritis, “An experimental study of
benchmarking functions for evolutionary algorithms,” Interna-
tional Journal of Computer Mathemathics, vol. 79, no. 4, pp.
403–416, April 2002.
[4] K. S. G. A. Jayalakshmi and R. Rajaram, “Performance
analysis of a multi-phase genetic algorithm in function op-
timization,” The Institution of Engineers (India) Journal - CP,
vol. 85, pp. 62–67, November 2004.
[5] J. C. F. Pujol and R. Poli, “Optimization via parameter map-
ping with genetic programming,” in Parallel Problem Solving
from Nature - PPSN VIII, ser. LNCS, X. Yao, E. Burke,
J. A. Lozano, JimSmith, J. J. Merelo-Guerv´os, J. A.Bullinaria,
J. Rowe, P. T. AtaKab´an, and H.-P. Schwefel, Eds., vol. 3242.
Birmingham, UK: Springer-Verlag, 18-22 Sep. 2004, pp. 382–
390.
[6] M.
Haseyama
and
H.
Kitajima,
“A
ﬁlter-
coefﬁcient
quantization
method
with
genetic
algorithm,”
pp.
399–402,
1999.
[Online].
Available:
http://doi.ieeecomputersociety.org/10.1109/ISCAS.1999.778869,
Last access date <retrieved: 10, 2011>
[7] J. Zhang, H. S. H. Chung, and W. L. Lo, “Pseudo-
coevolutionary genetic algorithms for power electronic circuits
optimization,” IEEE Trans. on Systems, Man and Cybernetics -
Part C: Applications and Reviews, vol. 36, no. 4, pp. 590–598,
2006.
[8] K. A. D. Jong, Evolutionary Computation.
Cambridge,
Massachusetts: MIT Press, 2006.
24
INFOCOMP 2011 : The First International Conference on Advanced Communications and Computation
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-161-8

