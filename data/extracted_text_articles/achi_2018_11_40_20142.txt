Extended Method to Alternate the Estimation of Global Purposes and Local Objectives
in Multiple Human-Agent Interaction
Yoshimasa Ohmoto∗, Takashi Suyama∗ and Toyoaki Nishida∗
∗Department of Intelligence Science
and Technology
Graduate School of Informatics
Kyoto University
Kyoto, Japan
Email: ohmoto@i.kyoto-u.ac.jp, suyama@ii.ist.i.kyoto-u.ac.jp, nishida@i.kyoto-u.ac.jp
Abstract—We are interested in how to realize the natural inter-
action between human and agent in a virtual world the same
way the human-human interaction occurs in real-world. The
differences between virtual experiences and real-world experi-
ences highlight the fact that the former are not equivalent to
the latter. We focused on the mental stances to establish the
social relationships between humans and agents. The purpose of
this study was to investigate whether the extended method to
alternate the estimation of local objectives and global purposes
using a network-connected two-layer model in multiple human-
agent interaction (eAEGL model) could induce the intentional
stance in human participants. We conducted an experiment to
evaluate the effect of the proposed method using two types of
agents: an agent that implemented eAEGL model and a simple
goal-oriented agent. The results suggest that the participants who
interacted with the eAEGL agent considered the agent to be an
interaction partner and they positively involved the agent in their
virtual world experiences.
Keywords–Multi-modal interaction; human-agent interaction;
multi-user interaction; intentional stance.
I.
INTRODUCTION
Many people use information technologies and devices
to perform their everyday tasks. Virtual reality (VR) tech-
niques and devices are developing rapidly and virtual reality
technology will be widely applied to training games that
are used in education, medical services, wellness, and ﬁtness
[1]. People can acquire various skills through game playing
[2] or through games used for physical rehabilitation [3].
Additionally, software developers evaluate the user interface
during the game usage [4]. In these applications, virtual agents
are used as interaction partners, such as an instructor for the
training, a rival character for giving motivation, or a crowd
simulating a situation.
However, the differences between virtual experiences and
real-world experiences highlight the fact that the former are
not equivalent to the latter. For example, the character agents
in the virtual world are not usually regarded as familiar friends
but, more prosaically, as multi-modal interfaces that provide
useful information. In such cases, once the user has learned
the rules of social interaction in the virtual world, he or she
may not be able to probe the true nature of those rules. As
a result, the user either obeys the rules blindly or ﬁnds them
impossible to follow. Therefore, we should consider how to
establish the social relationships between humans and agents.
In previous studies [6][7], we focused on the mental stances
that people took when interacting with their interaction partner
using three categories: physical stance, design stance, and
intentional stance [8]. The interaction partner can be both a
human and an agent. We considered the intentional stance
and the design stance as follows. The intentional stance is a
mental state in which people assume unobservable inner state
parameters for the interaction partner’s behaviour estimation.
Examples of the unobservable inner state parameters are
a behaviour model, emotional aspects, and decision-making
strategies of the interaction partner. Therefore, people who
assume the intentional stance pay attention to various inter-
action parameters because they do not accurately identify the
parameters that are important to obtain acceptable results in the
interaction. The design stance is a mental state in which people
believe they can estimate the interaction partner’s behaviour by
the observable interaction parameters. Therefore, people who
assume the design stance pay attention to only the observable
parameters that are clearly related to the interaction. The
main difference between the intentional stance and the design
stance is that people expect and accept that the results of the
interaction are different when they provide the same interaction
behaviour to their interaction partner.
In our previous studies [7][9], we proposed a method to
alternately propagate estimates of human’s objectives of the
subordinate tasks (local objectives) and human’s purposes of
the entire task (global purposes) during a collaboration task
through humna-agent interaction, using a network-connected
two-layer model of emphasizing factors. An agent implement-
ing this method estimates the human ’s local objectives from
his/her behaviour, and the human ’s global purposes from the
time series patterns of the local objectives. We believe that
this method, which could provide consistency and coordination
between local objectives and global purposes, could be useful
to enhance factors that induce and maintain the intentional
stance. For smooth interaction, it is important to understand the
meta-rules to maintain the consistency and coordination, and
the meta-rules are composed of some heuristics. By using this
method, participants spontaneously speculate on the meta-rules
through the interaction and pay attention to the unobservable
inner state of the agent.
Recently, we applied the alternating estimation of hu-
man mental states in one-to-one human-agent interaction in
a previous study [7]. However, multiple users often join a
virtual world simulation and interact with an agent in different
situations. Therefore, we should consider how to estimate
and integrate the alternating estimations of multiple human
212
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

mental states for an agent’s decision making in human-agent
interaction.
In the present study, we extended the method to alternate the
estimation of participants’ local objectives and global purposes
using a network-connected two-layer model in one-to-one
human-agent interaction to multiple human-agent interaction.
We separately described the local objectives in local tasks and
global purposes for the entire task for each human. Then, the
agent decides which global purpose of the human is similar
or conﬂicts with the agent’s global purpose. Subsequently, the
agent provides a goal-oriented behaviour related to the global
purposes, to support the local objectives in the local tasks.
This paper is organized as follows: In Section 2, we brieﬂy
introduce the related works. Section 3 provides an outline
of the proposed method. Section 4 contains a description
of our experiment that compared experimental and control
groups, and presents our results. In Section 5, we discuss
the achievements of this research and some future work. We
present our conclusion in Section 6.
II.
RELATED WORK
The typical way to speculate about a human’s intentions
within human-agent interaction is human-agent communica-
tion through a dialogue. Kitamura et al. [10], for example,
developed a system that matches users’ queries with search
targets by communicating with users throughout the interview.
Most of the research considered that people had reliable
demands and needs and they tried to uncover them. However,
especially in collaborative tasks, people’s demands and needs
are ambiguous and they are interactively changed through the
tasks in many cases. In human-human interaction, we do not
think that we can precisely speculate people’s intentions only
through a dialogue.
Agents that collaboratively perform various tasks have
been proposed in many studies, such as subordinate support
agents when people perform tasks on their own initiative and
automated attentive agents which automatically perform tasks
in line with a human’s wishes [11]. We assumed that the
intentional stance was partially induced in the participants in
the collaborative task because, if not, the engagement for the
collaboration would have been low and they might have failed
in the collaboration.
Some mutually directable methods and concepts affect task
performance [12][13]. Mixed-initiative, for example, refers to a
ﬂexible interaction strategy wherein each agent can contribute
to the task it does best. Furthermore, in general, the agents’
roles are not determined in advance, but are opportunistically
negotiated between them as the problem is being solved. In
many cases, they merely provide a division of roles among in-
teraction members; therefore, the consistency and coordination
for performing the task are still managed by the main person.
Dindo et al. [14] proposed that humans use the intentional
stance as a learning bias that sidesteps the (difﬁcult) structure
learning problem and bootstraps the acquisition of generative
models for others’ actions. They provided an example of how
structure initialization can help in the learning of new parts of
the model. In the example, they connected the action layer and
intention layer by networks and identiﬁed the user’s intentions
from the sequence of the actions. This revealed that the
network-connected layered model is effective for estimating
the intentions of humans. They considered the intentional
stance as a template of the structure generating the observed
behaviour. In contrast, we consider the intentional stance
itself as being an important factor to determine interaction
behaviours.
Shirouzu et al. [15] investigated how collaboration leads to
abstract and ﬂexible problem solving. The results indicated that
two factors, namely, individuals’ activeness in choosing and
conﬁrming the initial strategies and the frequent role exchange
between task-doing and monitoring in collaborative situations,
interact in collaboration to generate various solutions differing
in the degree of abstraction. These solutions are then reﬂected
upon by the participants to lead them to abstraction. This shows
that the observer’s mental factors inﬂuence his/her evaluation
of an observation target. In addition, in multiple human-
agent interaction, a participant has an interaction-doing role
whereas another has a monitoring role. Therefore, we should
consider that the development of the human-agent relationships
is different from that of one-to-one human-agent interaction.
III.
METHOD TO ALTERNATE ESTIMATION BY
REPRESENTING GLOBAL AND LOCAL GOAL-ORIENTED
BEHAVIOUR
Some methods induce the intentional stance, such as an
agent resembling a human or an animal in appearance [16][17].
These methods mainly focus on inducing the intentional stance
at the ﬁrst impression. However, if the activities among the
participants, including the agent, were not mutually inﬂuenced
by them each other in collaborative long-term interaction, the
participants would regard even human-human interactions as
’mechanical’ because these interactions make people believe
that they can estimate the interaction partner’s behaviour by
the observable interaction parameters.
In previous studies, we proposed a method to alternate es-
timation of local objectives and global purposes in a decision-
making situation [9] and applied the method to a collaborative
task for inducing and maintaining the intentional stance [7].
We called this Alternate Estimation by representing Global
and Local goal-oriented behaviour (AEGL). AEGL separately
describes an interaction partner’s local objectives in local tasks
and global purposes of the entire task. The agent implementing
the method estimates the interaction partner’s local objectives
and global purposes based on the interaction responses. After
the estimation, the agent updates its own local objectives
depending on the estimated partner’s global purposes. We
expected that the interaction partner also estimates the agent’s
global purposes from its behaviour for the local tasks in one-
to-one interaction. However, multiple users often join a collab-
oration task and interact with an agent in different situations.
In addition, when the agent interacts with multiple users, the
agent needs to prioritize the order of the interaction with the
users and consider the user’s global purposes. In this study, we
extended the method used to alternate the estimation of local
objectives and global purposes by a network-connected two-
layer model in one-to-one human-agent interaction to multiple
human-agent interaction. We called this extended method as
eAEGL. Figure 1 shows the outline of this process.
The main difference between the eAEGL in this study
and the AEGL in the previous work is to estimate the purposes
of multiple interaction partners and then to evaluate the effect
of agent’s interaction behavior towards each interaction partner
based on the degree of inﬂuence on agent’s purpose. The
eAEGL had lists of local objectives and global purposes, and
213
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

Action
(1), (4) 
Output
(2)
Estimation
(3)
Update and integration
Human
Agent
Action
Action
(2)
Estimation
Two-layered network
Figure 1. Outline of the alternating estimation process.
the relational networks for each user and its own depending on
the task. The parameters of the network nodes were updated
in a correspondent interaction behaviour of each user that
included verbal and nonverbal responses. Subsequently, the
parameters of the local objective nodes or global purpose
nodes were speculated based on the parameters of the network-
connected nodes. Based on the speculated parameters of global
purpose nodes, eAEGL evaluated whether the user was col-
laborative or competitive, and how strongly inﬂuenced was
the user’s purpose on the agent’s global purpose. This is
an extended point. We brieﬂy explain the interaction process
below.
First, an agent with eAEGL determines its local objective
based on weighted global purposes and provides appropriate
behaviour to achieve the local objective. Subsequently, the
agent estimates the local objectives of each user based on
the behaviour and responses. From the estimation, the agent
updates the weights of estimated global purposes of each user.
Based on the updated global purposes, the agent evaluates
whether each user is collaborative or competitive, and how
strongly the user’s purpose inﬂuences the agent’s global pur-
pose. The strength of the inﬂuence is the priority of the user.
The agent calculates the cost when intervening with the higher
priority user. If the cost is lower than a certain level, the agent
increases the weights of the agent’s global purpose related to
the intervention. Finally, all parameters of the global purposes
of each user and the agent are updated and integrated, then the
agent modiﬁes and determines its local objective based on the
parameters.
The agent’s representation to provide the goal-oriented
behaviour for inducing and maintaining the intentional stance
is different depending on whether the user is collaborative or
competitive. When the user is collaborative, the agent tries
to support the user’s local objectives if possible, but the
agent represents its global purposes through the local objective
activities. When the user is competitive, the agent tries to
interfere with the user’s local objectives. The interference itself
is a representation of the agent’s global purposes. The agent’s
behaviour is modiﬁed through the interaction like a trial-and-
error process. By repeatedly conducting the processes, the
agent can represent the goals of the agent’s activities towards
the multiple users.
IV.
EXPERIMENT
We conducted an experiment to investigate the effects of
the proposed method on a user’s impressions of the agent. In
the experiment, participants played a ”triangular ﬁeld game”
as a task. In this game, three players, an agent and two
participants, competed for scores obtained in multiple ways.
The participants could obtain scores regardless of other players
and interfere with other players. The task and the relationships
between the global purposes and the local objectives are more
complex than those in the previous study. One of the reasons
why we used the competitive task was that the participants
usually ignored an agent’s behaviour when multiple human
players participated in a collaborative task. It was very hard
to induce the participants’ active interaction towards an agent
when participants ignored the agent in a collaborative task.
In the task, we used two types of agents: an ’eAEGL
agent’ that provided interaction behaviour to the participants
based on the eAEGL and a ’goal-oriented agent’ that per-
formed goal-oriented actions which took the game states of
all participants into account, such as game scores and the
positions in the game ﬁeld. Both agents represented their goal
to induce the intentional stance. The eAEGL agent controlled
the representations based on the participants’ inner state,
such as collaborative or competitive. The goal-oriented agent
prioritized its own global purposes. For example, in a situation
in which a human participant interferes with an agent’s purpose
and another human participant very effectively obtain scores,
the goal-oriented agent tries to confront with the interfering
participants, but the eAEGL agent evaluates the effect of each
participant’s behavior and sometimes tries to interfere with the
participant obtaining scores.
The reason we did not adopt the AEGL agent in our
previous research was that, when the AEGL agent interacted
with multiple participants, the agent’s behaviour often changed
owing to the inﬂuence of the participant who interacted im-
mediately before. This means that it became rather difﬁcult
to estimate the agent’s intentionality from its goal-oriented
behaviour. We assumed that if the extended alternating esti-
mation could inﬂuence the mental stance of the participants
more than providing basic goal-oriented behaviour, the eAEGL
agent could induce and maintain the intentional stance.
Both agents were controlled by the experimenter manually
based on the predeﬁned rules (Wizard of Oz). But, the be-
haviour planning of the agents were automatically determined
based on the corresponding method; the eAEGL agent used the
method to alternate estimation by representing global and local
goal-oriented behaviour and the goal-oriented agent used the
method to plan its own goal depending on the game states and
situations. Each agent provided its next local objective and the
experimenter controlled each agent based on the predeﬁned
rules. The expressions of the multimodal behaviour by the
agents were also automatically produced.
To evaluate this, we analysed how frequently the partic-
ipants spontaneously interfered with the agent’s behaviour.
Although the players competed for scores in the task, the
players could not get scores by interfering with other players.
Therefore, if the participants considered that the agent was not
an interaction partner to perform the task excitingly, it would
be more efﬁcient to get a high score by not interfering with the
other players. We assumed that, when the participants had an
intentional stance toward the agent, they tried to interfere with
the agent. In addition, we asked the participants to complete
a questionnaire after the experiment.
214
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

Immersive display
Game control PC
Agent status
Game status
WoZ environment
The experimenter
Monitoring 
PC
Participant
Participant
Motion data
Determine the next 
local objective
Produce an agent’s 
behaviour
Result
Figure 2. The experimental environment.
A. Task
An agent and two participants joined a triangular ﬁeld
game in which three players competed for scores obtained in
multiple ways. In the game, each player had their own ﬁeld
in which each player stored treasures. The ﬁelds were placed
in a triangular form. At the centre of the triangle, there was a
neutral ﬁeld where three resources existed: gold coins, artistic
statues and weapons. When the players stored the resources
in their own ﬁelds, they obtained a score. Each player could
use the resources to get bonus scores, but the player needed to
spend considerable resources and time. While the player spent
time to get a bonus score, other players could interfere with
the process to get a bonus score. The winner was the player
with the highest score. One game session lasted for 20 min.
The agent’s primary global purpose was to gather bonus
scores. First, the agent tried to store statues. After the agent
stored enough statues to get a bonus score, he immediately
spent them to get the score. The agent evaluated the state of
the game including other players’ scores and the bonus process
of other players at regular intervals. The goal-oriented agent
selected a most efﬁcient way to get scores or to keep the score
different from the other players. The eAEGL agent estimates
the global purposes of each participant and the priority. If the
cost when interacting with the higher priority participant was
low enough, the agent tried to interact with the participant.
When the participant was collaborative (e.g., when the par-
ticipant tried to interfere with another participant with whom
the agent also tried to interfere), the agent tries to support
the participant’s local objectives. When the participant was
competitive, the agent tries to interfere with the participant’s
local objectives.
B. Experimental setting
The experimental setting is shown in Figure 2. We used an
Immersive Collaborative Interaction Environment (ICIE) [18]
and Unity3D [19] to construct the virtual environment and the
two agents. ICIE uses a cylindrical immersive display that is
composed of eight portrait orientation liquid-crystal-displays
(LCD) with a 65-inch screen size, arranged in an octagonal
shape. In this environment, participants could look around in
the virtual space with a low cognitive load, as in the real world.
A participant’s virtual avatar could be controlled by a game
pad.
a) The number of interferences 
in the purpose of the agent
b) The number of interferences 
in the purpose of another player
eAEGL
GO
eAEGL
GO
number
number
*
Figure 3. Results of the number of interferences in the purpose of other
players.
C. Procedure
The interactive agent who joined the game was randomly
selected. First, the participants were instructed regarding the
experimental procedures. The experimenter provided the fol-
lowing instructions about the agent: ’The agent can recognize
simple words. The agent has basic knowledge about the task.
The agent changes its behaviour and strategies depending on
your behaviour’. After the instructions were provided, the
experimenter started the game. The participants ﬁrst performed
a practice session and then performed two game sessions. Each
game session lasted for 20 min, with a 5-min rest interval
between sessions. In the rest interval and at the end of the
task, the participant completed questionnaires.
Eighteen Japanese college students (14 men and 4 women)
participated in the experiment. They were undergraduate stu-
dents aged 18 to 24 years (an average of 21.1 years). All of
them interacted with one of the agents for approximately 40
min. Ten participants (8 men and 2 women) interacted with the
goal-oriented agent (the ’GO group’) and the rest interacted
with the eAEGL agent (the ’eAEGL group’).
D. Analysis of the number of interferences in the purpose of
other players
We counted the number of the interferences in the bonus
process of other players. The players could not get scores by
interfering with other players. Therefore, it is more efﬁcient
to get a high score by not interfering with the other players.
If the participants considered that the agent was an interaction
partner who would make the task exciting, they tried to interact
with the agent by interfering in the bonus process.
We compared the results from the eAEGL group with those
from the GO group. These results are shown in Figure 3. A
Mann-Whitney U test showed that the number of interferences
with the agent in the eAEGL group was signiﬁcantly more
than that in the GO group (Z =-2.03, p = 0.047). On the other
hand, there was no signiﬁcant difference between the number
of interferences with another participant in the eAEGL group
than that in the GO group (Z = 0.835, p = 0.41). This result
suggests that eAEGL was successful in inducing the intentional
stance in multi-user interaction.
E. Analysis of the questionnaires
The purpose of this analysis was to investigate how the
proposed method tested in the present study inﬂuenced the
participants’ subjective impressions. The participants rated the
impressions of the agent on a seven-point scale, presented as
ticks on a black line without numbers. The Q1 and Q2 were
rated after the end of each session. The Q3 and Q4 were rated
215
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

score
score
a) The result of eAEGL group
b) The result of GO group
First half
Second half
First half
Second half
*
Figure 4. Q1: How carefully did the agent consider your intentions?
after the end of the experiment. We post-coded these scores
from 1 to 7. We performed the Mann-Whitney U tests on the
questionnaire data.
1) Q1: How carefully did the agent consider your inten-
tions?: The eAEGL agent estimated the global purposes of
each participant and the estimations were reﬂected on the
changes of the agent’s global purpose. The GO agent evaluated
the states of the game including the results of the participants’
behaviour and the results were reﬂected on the changes of the
agent’s global purpose. Therefore, the participants’ intentions
were more quickly reﬂected on the global purpose of the
eAEGL agent than that of the GO agent. This question was
asked to conﬁrm whether the difference inﬂuenced the partic-
ipants’ feeling. This question was rated after the end of each
session. The results have been shown in Figure 4. In the ﬁrst
and second sessions, there are no signiﬁcant differences (ﬁrst:
Z = -0.808, p = 0.44; second: Z = -1.40, p = 0.18). On the other
hand, we performed the Wilcoxon signed-rank test between the
responses regarding the ﬁrst and second half. Although there
was no signiﬁcant difference in the eAEGL group (Z=-1.56,
p=0.16), the score for the second session was signiﬁcantly
higher than that for the ﬁrst session in the GO group (Z =
-2.38, p = 0.023). This indicates that the participants in the
eAEGL group could quickly understand that the participants’
intentions were reﬂected on the global purpose of the agent.
The participants in the GO group ﬁrstly needed to understand
the game structures and the strategies for identifying the
relationships between the results of the participants’ behaviour
and the changes of the agent’s behaviour.
2) Q2: How strongly do you think that the agent considered
its strategies based on players’ intentions?: Although both
agents changed their global purposes and their behaviour
depending on the participants’ behaviour, there is a difference
in the causal relationship between the global purpose of the
agent and the intentions of the participant. This question was
asked to conﬁrm whether the participants were aware of the
rules to determine the agent’s strategies. This question was
rated after the end of each session. The results are shown in
Figure 5. In both the ﬁrst and second sessions, the score for
the eAEGL group was signiﬁcantly higher than that for the
GO group (ﬁrst: Z = -2.13, p = 0.030; second: Z = -2.40, p =
0.015). In addition, there are no obvious differences between
the ﬁrst session and the second session. This indicates that the
participants were aware of the effect of the inﬂuence of factors
that determined the agent’s behaviour early in the task.
3) Q3: How strongly do you want to play the game with
the agent again?: This question was asked to conﬁrm whether
score
score
a) The result of the first half
b) The result of the second half
eAEGL
GO
eAEGL
GO
*
*
Figure 5. Q2: How strongly do you think that the agent considered its
strategies based on players’ intentions?
eAEGL
GO
score
+
Figure 6. Q3: How strongly do you want to play the game with the agent
again?
the agent’s behaviour based on the eAEGL inﬂuenced the
subjective feeling of the participants. The result is shown
in Figure 6. There was a marginally signiﬁcant difference
between the groups (Z = -1.96, p = 0.058), which suggests
that the participants preferred the eAEGL agent.
4) Q4: How actively did you involve this task?: This
question was asked to conﬁrm whether the agent’s behaviour
based on the eAEGL inﬂuenced the evaluation of the whole
of the task. The result is shown in Figure 7. The score for the
eAEGL group was signiﬁcantly higher than that for the GO
group (Z = -2.12, p = 0.042). The human-agent interaction
which was not needed to efﬁciently achieve the task goal
inﬂuenced the positive impression about the whole of the task.
V.
DISCUSSION
The main contribution of this study is that the eAEGL
model is useful to induce the intentional stance of the par-
ticipant in complex multiple human-agent interaction. An
analysis of the number of interferences in the purposes of other
players helped us conﬁrm that the eAEGL group spontaneously
interacted with the agent to perform the task excitingly. In
addition, in Q3 and Q4 of the questionnaires, the scores for
the eAEGL group were relatively high. From these results, we
suggest that the participants who interacted with the eAEGL
agent considered that the agent was an interaction partner
(i.e., the participants took the intentional stance) and they
positively involved the agent in their virtual world experiences.
The suggestion is in agreement with our previous research
[7], and it can be said that we can extend the method to
alternate the estimation of local objectives and global purposes
in one-to-one human-agent interaction to multiple human-
agent interaction.
The Q1 and Q2 of the questionnaires were similar but
the results were different. The Q1 asked the impression of
the agent’s attitude towards the participant. The Q2 asked the
216
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

eAEGL
GO
score
*
Figure 7. Q4: How actively did you involve this task?
impression of the agent’s attitude towards all participants. In
this study, we applied the eAEGL to multiple-user interaction,
so that a participant could observe the interaction between an-
other participant and the agent. We expect that the observation
is important to estimate the agent’s behaviour model. Multi-
user interaction requires a complex decision-making process
to estimate multiple participants’ intentions and decide their
actions. By providing the opportunity to observe interactions
made by others, there is an advantage that it becomes easier to
estimate the behaviour model of the agent relatively. Although
it becomes easier to estimate the behavioural model of the
agent, we should be careful that participants are more likely
to take a design stance. It is important to continuously and
mutually change the inner state, such as through eAEGL, in
natural long-term interactions.
In this study, we could conﬁrm that the agent could
induce active interaction from the participants. This is one of
the limitations in our previous study. In addition, we could
apply the eAEGL to relatively long-term interactions. On the
other hand, we had to hand-code the two-layered relational
networks depending on the task. In the future, we will apply
the machine learning techniques to reconstruct the relational
networks through the human-agent interaction.
VI.
CONCLUSION
The purpose of this study was to investigate whether the
extended method to alternate the estimation of local objec-
tives and global purposes using a network-connected two-
layer model in multiple human-agent interaction could induce
the intentional stance in human participants. To evaluate the
method, we implemented two types of agents: an eAEGL
agent (that mutually estimates and changes global purposes
based on the priority and relationship with each participant),
and a goal-oriented agent (that performed goal-oriented actions
which took the game states of all participants into account).
We conducted an experiment to evaluate the effect of the
proposed method. The results suggest that the participants
who interacted with the eAEGL agent considered the agent
to be an interaction partner and they positively involved the
agent in their virtual world experiences. In future work, we
will attempt to update the relational two-layer network, which
is determined by the agent’s basic strategies and behaviour,
during the human-agent interaction.
ACKNOWLEDGMENT
This research is supported by Grant-in-Aid for Young
Scientists (B) (KAKENHI No. 16K21113), and Grant-in-Aid
for Scientiﬁc Research on Innovative Areas (KAKENHI No.
26118002) from the Ministry of Education, Culture, Sports,
Science and Technology of Japan.
REFERENCES
[1]
A. V. S. Mokka, J. Heinil¨a, and P. V¨alkkynen, “Fitness computer game
with a bodily user interface,” in Proceedings of the second international
conference on Entertainment computing., 2003, pp. 1–3.
[2]
M. Graaﬂand, J. Schraagen, and M. Schijven, “Systematic review
of serious games for medical education and surgical skills training,”
vol. 99, no. 10, 2012, pp. 1322–1330.
[3]
P. Rego, P. M. Moreira, and L. P. Reis, “Serious games for rehabilitation:
A survey and a classiﬁcation towards a taxonomy,” in Proceedings of
the 5th Iberian Conference on Information Systems and Technologies
(CISTI)., 2010, pp. 1–6.
[4]
K. Collins, K. Kanev, and B. Kapralos, “Using games as a method
of evaluation of usability and user experience in human-computer
interaction design,” in Proceedings of the 13th International Conference
on Humans and Computers.
University of Aizu Press, 2010, pp. 5–10.
[5]
Y. Maeda, K. Anezaki, and Y. Takeuchi, “An agentbased model for
simulating the group dynamics involved in excluding a minority,” in
Proc. 1st World Congress on Social Simulation, vol. 1, 2006, pp. 79–
86.
[6]
Y. Ohmoto, S. Takashi, and T. Nishida, “Effect on the mental stance
of an agent’s encouraging behavior in a virtual exercise game,” in
COGNITIVE 2016: The Eighth International Conference on Advanced
Cognitive Technologies and Applications.
IARIA, 2016, pp. 10–15.
[7]
Y. Ohmoto, T. Suyama, and T. Nishida, “A method to alternate the
estimation of global purposes and local objectives to induce and main-
tain the intentional stance,” in Proceedings of the Fourth International
Conference on Human Agent Interaction.
ACM, 2016, pp. 379–385.
[8]
D. C. Dennett, The intentional stance.
MIT press, 1989.
[9]
Y. Ohmoto, A. Matsumoto, and T. Nishida, “The effect of alternating
propagation of local objective and global purpose by a network-
connected two-layer model of emphasizing factors,” 2015, pp. 246–251.
[10]
M. Kitamura et al., “Design and development of dialogue system for
laddering search service,” IEICE technical report. Natural language
understanding and models of communication, Tech. Rep., 2008.
[11]
B. Shneiderman and P. Maes, “Direct manipulation vs. interface agents,”
interactions, vol. 4, no. 6, 1997, pp. 42–61.
[12]
J. Allen, C. I. Guinn, and E. Horvtz, “Mixed-initiative interaction,”
Intelligent Systems and their Applications, IEEE, vol. 14, no. 5, 1999,
pp. 14–23.
[13]
G. Klein, D. D. Woods, J. M. Bradshaw, R. R. Hoffman, and P. J.
Feltovich, “Ten challenges for making automation a” team player” in
joint human-agent activity,” IEEE Intelligent Systems, vol. 19, no. 6,
2004, pp. 91–95.
[14]
H. Dindo, F. Donnarumma, F. Chersi, and G. Pezzulo, “The intentional
stance as structure learning: a computational perspective on mindread-
ing,” Biological cybernetics, vol. 109, no. 4-5, 2015, pp. 453–467.
[15]
H. Shirouzu, N. Miyake, and H. Masukawa, “Cognitively active ex-
ternalization for situated reﬂection,” Cognitive science, vol. 26, no. 4,
2002, pp. 469–501.
[16]
B. Friedman, P. H. Kahn Jr, and J. Hagman, “Hardware companions?:
What online aibo discussion forums reveal about the human-robotic
relationship,” in Proceedings of the SIGCHI conference on Human
factors in computing systems.
ACM, 2003, pp. 273–280.
[17]
W. H. Dittrich and S. E. Lea, “Visual perception of intentional motion,”
PERCEPTION-LONDON-, vol. 23, 1994, pp. 253–253.
[18]
T. Nishida, A. Nakazawa, Y. Ohmoto, and Y. Mohammad, Conver-
sational Informatics: A Data-Intensive Approach with Emphasis on
Nonverbal Communication.
Springer, 2014.
[19]
“Unity,” http://unity3d.com/ (2017/12/01).
217
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-616-3
ACHI 2018 : The Eleventh International Conference on Advances in Computer-Human Interactions

