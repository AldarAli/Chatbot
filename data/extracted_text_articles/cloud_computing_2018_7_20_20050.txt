 
Analysis of Energy Saving Technique in CloudSim Using Gaming Workload 
        
       Bilal Ahmad  
      Sally McClean 
     Darryl Charles 
        Gerard Parr 
School of Computing, 
School of Computing,  
School of Computing,  
School of Computing, 
      Ulster University  
      Ulster University  
      Ulster University       University of East Anglia 
        Coleraine, UK                    Coleraine, UK                    Coleraine, UK  
      Norwich, UK 
                ahmad-b@ulster.ac.uk 
si.mcclean@ulster.ac.uk dk.charles@ulster.ac.uk 
     g.parr@uea.ac.uk 
 
 
Abstract—The IT industry has been totally revolutionized in the 
past few decades. Cloud Computing companies (Google, Yahoo, 
Gaikai, ONLIVE, Amazon and eBay) use large data centers 
which are comprised of virtual computers that are placed 
globally and require a lot of power cost to maintain. Demand 
for energy consumption is increasing day by day in IT firms. 
Therefore, Cloud Computing companies face challenge towards 
power costs. We address the solution for this energy saving 
problem by the enabling dynamic voltage and frequency scaling 
technique (DVFS) for gaming data centers. This helps service 
providers to meet the quality of service (QoS) and quality of 
experience (QoE) constraints by meeting service level 
agreements 
(SLAs). 
CloudSim 
platform 
is 
used 
for 
implementation of the scenario in which game traces are used 
as a workload for testing the technique. This can help gaming 
servers to save energy cost and maintain better quality of 
service for users placed globally in comparison with generally 
used Non-Power Aware technique. The results demonstrate that 
less energy is consumed by implementing a DVFS approach in 
comparison with Non-Power Aware technique when tested with 
same workload. 
Keywords- Energy Saving Technique; DVFS and Non-Power 
Aware Method; Gaming Workload; CloudSim Platform. 
I. 
INTRODUCTION 
Cloud Computing is one of the latest technologies that is 
growing across the globe rapidly. It is forming pillars for 
upcoming advancements in computing covering all aspects of 
parallel and distributed computing. Cloud computing is 
providing users with a substantial number of pay-per-use 
services, using the internet as a communication backbone. 
With the era of globalization, computing is also being 
transformed into a model where service is provided based on 
user requirements instead of hosting them permanently [1]. 
These advancements and innovations in the ﬁeld of cloud 
technology provisions the industries to have unlimited 
computational power while maintaining good quality of 
service (QoS). Cloud industries must maintain several service 
level agreements (SLAs) to meet good quality of service from 
the user and service provider perspective. The service 
provider is also responsible for availability of the resources 
whenever and wherever they are required by the user. IT 
industry can save energy and power cost using service 
oriented architecture alongside cloud computing. Whether 
from the domain of parallel or distributed computing there are 
three major service models, namely Software as Service 
(SaaS), Platform as Service (PaaS), and Infrastructure as 
Service (IaaS) [2]. The corresponding large amount of data 
management and streaming leads to an increase in energy 
consumption. This causes a major rise in cost and threat to the 
environment as large amount of carbon dioxide (CO2) is 
produced by these data servers [3]. Consequently, data 
centers are becoming unmaintainable. Therefore, a lot of 
work is being carried out and different kind of algorithms and 
techniques are being developed and implemented by 
researchers. Dynamic voltage and frequency scaling is one 
such technique that helps in reduction of power consumption. 
It reduces the use of underutilized resources by dynamically 
controlling the frequency parameter and uses different 
strategies to reduce static consumption by shifting load to the 
underutilized servers dynamically. Therefore, for the 
implementation of DVFS one needs to understand different 
factors like frequency and static power consumption. The 
amount of power that is being used in the data center can be 
managed by exploiting the trade-offs between service quality 
and service level agreement. Services that clouds are 
providing vary with time and have different workloads that 
require dynamic allocation of resources especially for Big 
Data Applications and MultiPlayer Games. Therefore, such 
techniques are required to be implemented in gaming with 
awareness of both DVFS and energy consumption while 
maintaining quality of service and quality of experience [4]. 
There are number of simulation tools which are being used 
for this research purpose, each having their deﬁned use. All 
these tools have one thing common, namely they all use a 
stack based design as cloud computing is a combination of 
internet, grid, and distributed computing. The stack based 
design model provides users with the ability to add their own 
designed code in the model. This helps in implementation of 
optimization techniques and management of resources for 
improvement of quality of services. Better experimentation 
and development of algorithm can help in saving energy cost 
and in increasing proﬁts. Therefore, for testing of new 
algorithms in IT industry researcher needs to have a secure 
platform. The selected platform should be fail safe and must 
avoid risk of customer’s data privacy and data impairment 
[6]. Most cloud computing platforms are software based as it 
is very difﬁcult and expensive to set a cloud server for test 
and trials purposes for each researcher. For example, it is 
practically difficult for researcher to use a data server 
consisting of 150 physical machines because of maintenance 
costs (e.g., energy, space, power, and cooling requirements) 
[5]. There is also no speciﬁc platform due to the following 
133
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-607-1
CLOUD COMPUTING 2018 : The Ninth International Conference on Cloud Computing, GRIDs, and Virtualization

 
reasons: relocation of the virtual machine, conﬁdentiality and 
data integrity, need for energy management, and cost 
modelling [8]. The main purpose of carrying this research is 
therefore to find the ways in which resource optimization can 
be performed in the gaming data centers. In our work we 
consider the following aspects of service quality: energy 
consumption and service level agreements, by using online 
gaming data in our experiments. In this paper, DVFS and 
Non-Power Aware technique will be tested and implemented 
for improvement of energy consumption and SLAs. Better 
results are expected to be achieved using DVFS technique as 
compared to Non-Power Aware technique; this hypothesis 
will be verified using real time gaming workload. The rest of 
this paper is organized as follows, Section II describes the 
related work; Section III describes basic details about DVFS 
and the platform; Section IV addresses the simulation 
environment; Section V discusses performance analysis and 
provides a discussion of our approach while, conclusions and 
future work close the article. 
II. 
RELATED WORK 
Recently, work has been carried in the ﬁeld of cloud 
computing particularly relating to the cluster servers and 
virtualized servers. Energy saving techniques have been 
suggested for large amount of data using the concept of 
changing voltage and frequency values. It has been 
demonstrated that this concept can save more energy as 
compared to dynamic power management technique when 
implemented in the real world [8]. Here, the authors use a 
single system by implementing and comparing three different 
energy saving concepts i.e., DVFS (supply voltage of 
underloaded servers is reduced), DNS scheme (idle servers 
are left in sleep mode) and DNS + DVFS. The author 
proposes that dynamic voltage and DNS together provide 
better results for energy saving. However, the paper does not 
compare and analyze the cost comparison by maintaining 
quality of service metrices [9]. A solution is provided to save 
cost and to earn more proﬁt on a large data scale by managing 
the scheduling of heterogenous machines with multiple users. 
This work is limited to just one quality of service metric i.e., 
cost from the service provider perspective [10]. Another 
algorithm was designed to optimize energy by using the 
concept of multi objective workﬂow and dynamic voltage 
scaling. However, the user was given the ability to choose 
between the cost or energy criterion [11]. In the ﬁeld of 
computing, distributed computing provisions user with fault 
tolerance, organization, and support for resources. Typically, 
resources are allocated to the users based on load balancing 
technique where all the resources are allocated to the broker 
that is wholly responsible for provisioning of resources when 
required [12].  
 In [16] the authors propose several energy saving 
algorithms using scheduling policies. However, the work was 
related to virtualization mechanism only for large scale global 
data centers [16]. Further work was carried out relating the 
energy saving mechanism to different kinds of workﬂow on 
the Green Cloud Platform using bi-objective scheduling to 
meet the quality of service metrices for energy consumption 
[11]. By looking at the related work to date, it is clear that 
most of the work carried out related to energy saving has 
involved single servers and unique tasks. However, these 
days cloud computing platforms like Gaikai, OnLive, and 
Amazon EC2 have servers that are using multipurpose 
applications that are dispersed geographically. There is a 
research gap in the ﬁeld of gaming especially for multiplayer 
games with users placed far apart from each other. On the 
other hand, some work in relation to energy saving has been 
carried using Big data with single purpose applications [6]. 
III. 
DVFS AND PLATFORM 
CloudSim is one of the platforms which provides QoS 
parameters such as: energy, cost model, latency, virtual 
machine characteristics, federation policy, and analyzing the 
network communication model. Based on this platform, 
several popular models have also been designed, namely 
iFogSim, 
Cloud 
Analyst, 
Network 
CloudSim 
and 
iCaroCloud. Therefore, it provides enough leverage for 
researchers to use it to perform tests and develop new models 
as required. CloudSim has a layered architecture which 
provides user with the ability to design and implement 
applications. It supports core functions, such as handling of 
events, creation of cloud servers, hosts, brokers, and virtual 
machines [13]. The CloudSim simulation layer supports 
creation of hosts under virtual machines, application 
execution and application monitoring. A researcher who 
wants to implement an application relating energy, hosts, 
VM and data centers will be doing at this level. This layer 
supports the SaaS platform and provides users with deﬁned 
quality of service levels with complex load reporting and 
application performance reports [14]. The topmost layer in 
the architecture is where a user writes a code and it allows 
the user to deﬁne a number of virtual machines, hosts, data 
centers, brokers, tasks etc. Therefore, it allows researchers to 
extend this layer and perform different tasks such as: 
generation 
of 
workload 
for 
monitoring 
designed 
experiments, designing of different cloud scenarios for 
robust 
testing 
and 
implementation 
of 
conventional 
applications in the cloud environment [13]. IaaS services can 
be simulated by extending different entities present in the 
cloud environments such as data centers. Such data centers 
consist of many hosts which are assigned to more than one 
virtual machines depending upon the rules deﬁned by the 
service provider [15]. The data center can also manage more 
than one host (physical components representing the 
computing server) which further manages virtual machines. 
Host provisioning supports single and multiple core nodes. 
Similarly, virtual machine allocation creates virtual machine 
scenarios on hosts for storage and memory related tasks [16]. 
After modelling and designing of the application, it is 
allocated to a running virtual machine through a speciﬁc 
deﬁned procedure. The virtual machines required to host 
multiple applications are provided on a First Come First 
Serve basis depending upon different hardware factors 
(storage, memory, cores etc.,). Therefore, simulation test 
scenarios relating to CPU cores are dependent upon factors 
134
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-607-1
CLOUD COMPUTING 2018 : The Ninth International Conference on Cloud Computing, GRIDs, and Virtualization

 
such as time usage, space sharing policy or allocating virtual 
machines as and when required [7]. 
     CloudSim has the capability to calculate the power 
consumption of data centers using the DVFS technique. It 
uses the current metric for cloud host input and returns 
calculated power as an output. Therefore, this provides 
researchers with the ability to design energy consumptions 
models and calculate the total power consumed during the 
designed experiment. CloudSim also provides developers 
with the capability for experimentation of dynamic scenarios 
i.e., different number of data centers or hosts can be created 
and deleted for testing unpredictable events in which users 
can join and leave the cloud application [17]. The DVFS 
scheme is limited to CPU optimization and adjusts the CPU 
power according to the workload that is being run on it. 
However, other components of the system that is memory, 
storage, RAM, bandwidth and network interfaces keep 
running on the same original frequency and no scaling is 
applied on them. The use of Dynamic Power Management 
(DPM) can turn down the power consumption for all the 
components of the system. The CPU has number of states for 
frequency and voltage which suggests that it has ability to 
provide better power performance as compared to basic 
approach [18]. Thus, powering up of system will require a 
large amount of energy using DPM as compared to DVFS 
technique [11]. 
 
 
 
Figure 1: Layered CloudSim Architecture 
IV. 
SIMULATION 
 For the implementation and evaluation of the proposed 
experiments the CloudSim simulation platform is used to 
provide users with the ability to perform the desired tests. 
These tests are carried out by using traces from a game as 
workload for the DVFS technique. The designed simulation 
consists of heterogeneous data centers consisting of 800 
physical hosts and 1000 virtual machines which are 
dynamically allocated by the broker. Half of the hosts are HP 
ProLiant ML110G4 (Xeon3040) and other half are HP 
ProLiant ML110G5 (Xeon3075) servers. The systems 
frequency characteristics are deﬁned based on how many 
instructions can be executed in one second (MIPs). Therefore, 
HP 
ProLiant 
ML110G4 
(Xeon3040) 
and 
ML110G5 
(Xeon3075) have MIPs rating of 1860 MHz and 2660 MHz, 
both being dual core servers. The deﬁned system 
speciﬁcations are suitable to the hardware requirements for 
the experimental workloads envisaged. Detailed parameters 
are given in Table I. 
 
TABLE I: DETAILS OF THE SYSTEM PARAMETERS 
 
System (HP ProLiant) 
MIPs 
Rating 
Cores  
RAM 
Hard 
Disk 
ML110G4 (Xeon3040) 
1860 
MHz  
Dual 
4 GB 
1 GB 
ML110G5 (Xeon3075) 
2660 
MHz 
Dual 
4 GB 
1 GB 
 
No dynamic allocation of virtual machines is performed in 
this test and host power adjustment is done based on their 
CPU utilization. A ﬁxed MIPs value is provided having a 
value of 1000 MIP per second for a virtual machine. The 
simulated model has a bandwidth rate of 1 Gbits per second 
and RAM 4 GB for each system. A ﬁxed deﬁned gaming 
workload is provided in this experiment that consist of traces 
from a popular multiplayer online game, namely World of 
Warcraft having a data set size of 3.5 GB. The data set 
consists of traces from real data of the popular massively 
multiplayer online game, World of Warcraft (runtime of 1107 
days, 91065 avatars, 667032 sessions, users located globally 
in 3 continents with different time zones) collected to analyze 
the quality of service parameters and consisting of game time, 
race attributes, current position, profession info, game 
position information, game level etc., [18]. It provides 
execution time of each host and energy is calculated based on 
power consumed by individual host. It uses time shared 
policy and rating of the processing elements is calculated by 
having millions of instructions per second. The total MIPs, 
i.e., total execution time is the sum of all the MIPs from each 
processing element (PE). Here, it is assumed that all the 
processing elements have same rating in the used machine. 
The service level agreements are also required as it is 
necessary to maintain the quality of service matrices [20]. 
The detailed parameters are summarized in Table II. 
 
TABLE II: DETAILED DESCRIPTION OF SYSTEM PARAMETERS 
 
Host MIPs 
Host RAM 
RAM 
Host 
PE(s) 
1860 
4096 MBs 
1Gbit/s 
02 
2660 
4096 MBs 
1Gbit/s 
02 
 
    The reasoning behind the SLA violation time per active 
hosts is based on the observation that if there is an application 
that is managing the virtual machine migrations and it is busy 
with a host that has 100% utilization, it will not be able to 
address other hosts waiting for service provisioning. 
Therefore, virtual machines are deprived of the desired 
performance level causing service SLA violations [19]. The 
mathematical definitions and formula follow, 
 
135
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-607-1
CLOUD COMPUTING 2018 : The Ninth International Conference on Cloud Computing, GRIDs, and Virtualization

 
 
 
  The SLA level is the product of two matrices i.e., how 
many SLA violations there are per unit time of active hosts 
and how much of the performance degradation is because of 
virtual machine migration (Equation 3). SLAV(H) is the 
violation of per unit time for active hosts, H(n) is number of 
hosts, SLAH(t)i represents the time duration that leads to SLA 
violation by reaching CPU utilization of 100%, AH(t)i is the 
total number of hosts(i) in the active state. 
 
 
 
  P(vm) is the effect on the performance because of virtual 
machines migration, VM(n) represents the total number of 
virtual machines, Pd(k) represents the level of degradation in 
the service of a particular virtual machine when it is migrated, 
Cpu(k) represents the total utilization of CPU of a particular 
virtual machine. Therefore, whenever a cloud server is 
considered for service level agreement violations it always 
depends on the above two factors independently described in 
(1) and (2). Therefore, service level violation is because of 
two factors: one is virtual machine migration and the other is 
when a host is overloaded resulting in SLA violation (SLAV) 
as follows [19], 
                SLAV = SLAV (H) × P (vm)  
                 (3) 
  SLAV(H) represents time required to have 100% CPU 
utilization by the active host and P(vm) shows performance 
degradation because of virtual machine migration. The 
overall performance of cloud servers can be analyzed by 
using the following equation,  
 
           Perf (DC) = Energy × SLAV  
                 (4)  
The CPU time is calculated from the following formula, 
 
     
 
 
     CPU(t) = CPU Time, PE = MIPs of one Processing 
Element, C(Le) = Length of Cloudlet, and C(Lo) = Load of 
Cloudlet. Here, MIPs represent how many instructions can be 
executed in one second, PE(x) the number of MIPs of one 
processing element, PE(y) represents MIPs of N number of 
hosts, 
 
      Total MIPs = PE(x) + PE(y)N(host)                   (6) 
Cost per million instructions related to a resource is 
calculated as follow, 
 
             
 
    Cost(s) = cost per second and PE(MIPs) = calculating 
MIPs of one processing element. The execution time is 
calculated as follows, 
 
 
 Sys(t) is current time in millisecond, Exe(t) is system 
execution time and 1000 is the defined MIPs rating. Thus, 
energy consumed by each host, performance measure, CPU 
utilization, total execution time, and SLA violations count can 
be calculated by using the above equations. Experimentation 
results are shown in Section V. 
V. PERFORMANCE ANALYSIS AND DISCUSSION 
This test calculates the energy performance across the 
data center in the given simulation environment. All the tests 
are carried out in the simulation environment i.e., the 
CloudSim package which is conﬁgured using Eclipse Luna 
and Java IDE. The dynamic voltage and frequency scaling 
technique has been applied to analyze the gaming workload 
of the World of Warcraft multiplayer game. The workload 
consists of data traces from servers which are collected over 
time of 1107 days. An unaltered version of DVFS is used; 
however, a typical game workload has been provided for 
testing the behavior of the proposed technique. The Non-
Power Aware simulation model with the same speciﬁcations 
is used for power analyzation of same gaming workload. The 
main difference between the Non-Power Aware and DVFS 
models lies in how resources are allocated to the hosts. All 
the parameters (RAM, bandwidth, storage, I/O file size etc.,) 
are deﬁned however, for DVFS, resources are allocated based 
on dynamic voltages and frequency ﬂuctuations of the central 
processing unit for the active hosts.  
 
 
 
               Figure. 2: DVFS vs Non-Power Aware Consumption in a Data 
Center 
 
In the Non-Power Aware model hosts consume the 
maximum amount of power, thus increasing cost of services 
and causing loss of proﬁt for service providers. Figure 2, 
shows power consumption in the cloud environment with a 
ﬁxed number of hosts and MIPs using Non-Power Aware and 
136
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-607-1
CLOUD COMPUTING 2018 : The Ninth International Conference on Cloud Computing, GRIDs, and Virtualization

 
Dynamic Voltage Frequency Scaling. For DVFS, the data 
show a linear trend for CPU power consumption as compared 
to Non-Power Aware technique. The results in Figure 2 are 
by way of a reality check and verify the theoretical concept 
that in DVFS, the CPU adjusts frequency according to the 
workload to minimize the power consumption and thus 
provides a linear trend. The hosts using dynamic voltage and 
frequency scaling technique for the same gaming data 
consume less energy as compared to the Non-Power Aware 
technique. It can also be demonstrated (Figure 2) that in the 
Non-Power Aware technique hosts are loaded to maximum 
values and consume more energy resulting in greater values 
of CO2 emissions.  
 The results also prove that quality of service is directly 
proportional to service level agreements i.e., if QoS is not 
observed for a certain amount of time then we have a SLA 
violation. Thus, by using DVFS, performance can be 
improved and energy consumption can be minimized 
resulting in a lot of cost saving from the commercial point of 
view (Figure 3). It can be seen that DVFS provides better 
trade-off for exploitation of SLAs per host for maintenance of 
quality of service and quality of experience. Figure 3, shows 
different parameters that can be analyzed towards quality of 
service. During the whole experiment DVFS uses less 
resources in the host when analyzed. Less energy 
consumption, mean time and number of host shutdown are 
performed during the experimentation. These results show 
that overall the best quality of service can be achieved by 
implementing DVFS in gaming servers placed globally.  
 
 
 
Figure 3: Detailed Analysis of the Proposed System 
 
It can be seen from the results that minimum service level 
agreement degradation (SLAV) is achieved using dynamic 
voltage frequency scaling technique. Therefore, by using 
dynamic voltage and frequency scaling technique overall 
SLA violation can be reduced and quality of service can be 
improved through having less service level agreement 
violations in the proposed system (Figure 4).  
 
0.10%
0.11%
0.04%
0.05%
0.00%
0.02%
0.04%
0.06%
0.08%
0.10%
0.12%
0.14%
SLA Performance
Degradtion
Overall SLA Violation
Service Level Agreement
Non Power Aware
DVFs
 
Figure 4: Service Level Agreement Violation (SLAV) 
 
     The difference in the amount of energy consumption, 
service level agreement and quality of service degradation 
can be seen through the results which is estimated on the 
basis of CPU utilisation. From the results, it can be seen 
 
 
 
Figure 5: Detailed Analysis of the Proposed System 
 
that if the DVFS technique is used, the best results for energy 
utilisation are achieved and 16% of energy could be saved in 
comparison to Non-Power Aware technique using the same    
gaming workload (Figure 5). 
137
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-607-1
CLOUD COMPUTING 2018 : The Ninth International Conference on Cloud Computing, GRIDs, and Virtualization

 
VI. 
CONCLUSION AND FUTURE WORK 
 The simulation tests that have been designed using 
CloudSim platform are based on two power consumption 
approaches i.e., DVFS and Non-Power Aware. The same 
workload (game data) and data center speciﬁcations are set 
for testing which technique performs better for power 
saving. The workload provided demonstrates that DVFS 
saves more energy as compared to general Non-Power 
Aware approach and obtains less SLAs violations which is 
important for maintaining QoS and QoE. CloudSim 
provides the ability to test the same workload scenario on 
two different power saving approaches. By using this 
simulation environment, a researcher can experiment and 
determine the amount of resources required (e.g., the 
number of Cloudlets, bandwidth, RAM, cost etc.,) for 
maintaining quality of service. Therefore, from the 
simulation results, it can be verified that cloud gaming data 
centers with the proposed DVFS technique can yield less 
energy 
consumption 
while 
fulﬁlling 
service 
level 
agreements for maintaining good quality of service leading 
to better quality of experience (QoE) for users placed 
globally. 
     In the future, this work will be enhanced and better ways 
and techniques to save energy will be explored for Big Data, 
Internet of Things and Gaming data centers. 
REFRENCES 
 
[1]  S. Sidana, N. Tiwari, A. Gupta, and I. S. Kushwaha, “Nbst 
algorithm: A load balancing algorithm in cloud computing,” in 
2016 International Conference on Computing, Communication 
and Automation (ICCCA), Conference Proceedings, pp. 1178–
1181. 
[2]  P. S. Rawat, P. Dimri, G. P. Saroha, and V. Barthwal, “Power 
consumption analysis across heterogeneous data center using 
cloudsim,” in 2016 3rd International Conference on Computing 
for Sustainable Global Development (INDIACom), Conference 
Proceedings, pp. 1–5. 
[3]  H. Luo, J. Cao, Y. Wang, and X. Hu, “The dynamic migration 
model for cloud service resource balancing energy consumption 
and qos,” in The 27th Chinese Control and Decision Conference 
(2015 CCDC), Conference Proceedings, pp. 6035–6039. 
[4]  P. Arroba, J. M. Moya, J. L. Ayala, and R. Buyya, “Dvfs-aware 
consolidation for energy-efﬁcient clouds,” in 2015 International 
Conference on Parallel Architecture and Compilation (PACT), 
Conference Proceedings, pp. 494–495. 
[5]  C. Prazeres and M. Serrano, “Soft-iot: Self-organizing fog of 
things,” in 2016 30th International Conference on Advanced 
Information Networking and Applications Workshops (WAINA), 
Conference Proceedings, pp. 803–808. 
[6]  W. Tian, M. Xu, A. Chen, G. Li, X. Wang, and Y. Chen, “Open-
source simulators for cloud computing: Comparative study and 
challenging issues,” Simulation Modelling Practice and Theory, 
vol. 58, Part 2, pp. 239–254, 2015. 
[7]  Horvath et al. “Dynamic voltage scaling in multitier web servers 
with end-to-end delay control,” IEEE Transactions on Computers, 
vol. 56, no. 4, pp. 444–458, 2007.  
 
[8]  D. Kliazovich, P. Bouvry, and S. U. Khan, “Dens: Data    
Center energy efﬁcient network-aware scheduling,” in Green       
Computing 
and 
Communications 
(GreenCom), 
2010 
IEEE/ACM Int’l Conference on & Int’l Conference on Cyber, 
Physical and Social Computing (CPSCom), Conference 
Proceedings, pp. 69–75. 
[9]  J. Burge, P. Ranganathan, and J. L. Wiener, “Cost-aware 
scheduling for heterogeneous enterprise machines,” in 2007 
IEEE International Conference on Cluster Computing, 
Conference Proceedings, pp. 481– 487. 
[10] F. Cao, M. M. Zhu, and C. Q. Wu, “Energy-efﬁcient resource   
management for scientiﬁc workﬂows in clouds,” in 2014 
IEEE World Congress on Services, Conference Proceedings, 
pp. 402–409. 
[11]  R. Buyya, C. S. Yeo, and S. Venugopal, “Market-oriented 
cloud computing: Vision, hype, and reality for delivering it 
services as computing utilities,” in 2008 10th IEEE 
International Conference on High Performance Computing 
and Communications, Conference Proceedings, pp. 5–13. 
[12]  A. Beloglazov and R. Buyya, “Optimal online deterministic 
algorithms 
and 
adaptive 
heuristics 
for 
energy 
and 
performance efﬁcient dynamic consolidation of virtual 
machines in cloud data centers,” Concurrent. Comput: Pract. 
Exper., vol. 24, no. 13, pp. 1397–1420, 2012. 
[13]   R. N. Calheiros, R. Ranjan, A. Beloglazov, C. A. F. De Rose, 
and R. Buyya, “CloudSim: A toolkit for modeling and 
simulation of cloud computing environments and evaluation 
of resource provisioning algorithms,” Softw. Pract. Exper., 
vol. 41, no. 1, pp. 23–50, Jan. 2011. [Online]. Available: 
http://dx.doi.org/10.1002/spe.995 
[14]   F. P. Tso, D. R. White, S. Jouet, J. Singer, and D. P. Pezaros, 
“The glasgow raspberry pi cloud: A scale model for cloud 
computing infrastructures,” in 2013 IEEE 33rd International 
Conference on Distributed Computing Systems Workshops, 
July 2013, pp. 108–112. 
[15]  G. Keller, M. Tighe, H. Lutﬁyya, and M. Bauer, “Dcsim: A 
data centre simulation tool,” in 2013 IFIP/IEEE International 
Symposium on Integrated Network Management (IM 2013), 
May 2013, pp. 1090–1091. 
[16]   A. Varasteh and M. Goudarzi, “Server consolidation 
techniques in virtualized data centers: A survey,” IEEE 
Systems Journal, vol. 11, no. 2, pp. 772–783, June 2017. 
[17]  S. Long and Y. Zhao, “A toolkit for modeling and simulating 
cloud data storage: An extension to cloudsim,” in 2012 
International Conference on Control Engineering and 
Communication Technology, Dec 2012, pp. 597–600. 
[18]  Y.-T. Lee, K.-T. Chen, Y.-M. Cheng, and C.-L. Lei, “World 
of Warcraft avatar history dataset,” in 2011 " In Proceedings 
of ACM Multimedia Systems 2011, Feb 2011, pp. 123–128, 
2011. 
[19]   J. V. Wang, K. Y. Fok, C. T. Cheng, and C. K. Tse, “A stable 
matching based virtual machine allocation mechanism for 
cloud data centers,” in 2016 IEEE World Congress on 
Services (SERVICES), Conference Proceedings, pp. 103–
106. 
[20]   A. Ahmed and A. S. Sabyasachi, “Cloud computing 
simulators: A detailed survey and future direction,” in 2014 
IEEE International Advance Computing Conference (IACC), 
Conference Proceedings, pp. 866–872. 
138
Copyright (c) IARIA, 2018.     ISBN:  978-1-61208-607-1
CLOUD COMPUTING 2018 : The Ninth International Conference on Cloud Computing, GRIDs, and Virtualization

