Inclusive Personalities for Conversational User Interfaces: A Preliminary 
Discussion 
 
Jennifer Strickland, Jeff Stanley 
The MITRE Corporation 
Bedford, MA, USA 
email:{jstrickland, jstanley}@mitre.org 
 
 
Abstract—Conversational user interfaces (CUIs) such as 
chatbots and voice assistants are increasingly used to deliver 
services not just in industry but in government. Therefore, it is 
increasingly important for CUIs to provide good experiences 
for constituents with diverse backgrounds and abilities. 
Existing research on CUI personality focuses on engaging 
typical target users. Synthesizing existing literature on CUI 
personalities with principles for inclusive design, we discuss 
how to design CUI personalities that provide good experiences 
for diverse users. Key considerations are to consider the user’s 
unique situation, their expectations and preferences toward 
technology, and their purpose in using the technology. Our 
intent is to identify challenges for future research and to move 
towards a set of guidelines for inclusive CUI design. 
Keywords- chatbot; personality; inclusive design; equitable 
design; cross-cultural design; accessibility. 
I. 
INTRODUCTION 
Conversational User Interfaces (CUIs) such as text-based 
chatbots and voice-based assistants have become a popular 
solution for commercial services and are increasingly used 
to deliver government services as well. While companies are 
motivated to design CUI personalities that reflect their 
brands and engage target customers, government services 
must be accessible to all constituents. Therefore, in this 
discussion, we go beyond the question of how to craft a CUI 
personality that relates well to users: We focus on how to 
craft a CUI personality that relates well to diverse groups of 
users with disparate needs, wants, and expectations. In other 
words, how does a CUI’s personality include or exclude 
sections of the population, and what research questions 
should be answered to ensure CUIs do not unintentionally 
alienate the people being served? 
Some existing research explores how a CUI’s content and 
interface should account for diverse needs, often by 
adapting existing web content standards to the complexities 
of CUIs [1][2]. These include standards for fonts and colors 
on the screen, reading level for text content, how elements 
can be navigated on a webpage, and how they should be 
labeled and placed. However, existing standards do not 
explicitly address the novel problem space of artificial 
personality. 
In this paper, we bring together research on CUI 
personality with principles for inclusive design and 
introduce topics to consider when designing inclusive CUI 
personalities. Our goal is to take a step towards guidelines 
for CUI personalities that serve all people. 
Section II introduces inclusive design principles and CUI 
personality and describes how the former can be applied to 
the latter. Section III discusses some of the challenges 
involved in designing CUI personalities that satisfy 
inclusive 
design 
principles. 
Section 
IV 
offers 
recommendations to help manage those challenges. Section 
V concludes the paper. 
II. 
BACKGROUND 
A. Inclusive Design 
Inclusive design is an approach seeking to ensure all can 
access and are included in the design and outcome of a 
service or product. This perspective encompasses ability, 
age, gender, culture, ethnology, race, socioeconomics, 
power, and vulnerability, among other characteristics. 
Inclusive design practitioners are expected to investigate 
their own biases, hire diverse teams, and consider “design 
for/with/by” approaches to process. Using design tools, 
frameworks, language, and processes that are accessible and 
inclusive is a key tenet of inclusive design. At the start of a 
project, it is a best practice to define a list of who the 
outcome may exclude, then use that to guide decision-
making. Being mindful of who is included or excluded is a 
key guidepost. 
In service of inclusive design, it is helpful to take a 
“design by” approach, bringing the service consumer into 
the design of outcomes. Hiring for lived experience is a 
tremendous asset to bringing awareness to inclusive 
processes. Design workshops that bring consumers into the 
design and development processes are incredibly valuable in 
ensuring outcomes serve diverse audiences. 
Government services are especially relevant for inclusive 
design due to the range of experiences served. Where else 
does a service have an audience with such diversity in 
geography, 
culture, 
economics, 
ability, 
etc.? 
Most 
commercial products are willing to exclude those with low 
incomes, yet those are some of the critical users for whom 
government services may be a matter of life or death. Many 
government agencies already use CUIs to deliver or 
supplement key public services [3]. 
1
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-896-9
CENTRIC 2021 : The Fourteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

B. CUI Personality 
Personality for CUIs, in a broad sense, is a topic of 
interest for researchers and industry. Personality shapes a 
CUI’s response content, either by carefully designing each 
piece of content [4] or by training the CUI’s language model 
on a particular data set [5]. Web-based CUIs often have a 
visual component like a headshot that can reflect a particular 
kind of personality. When considering voice-based systems, 
different voice types can similarly reinforce different kinds 
of personalities [6]. Some industry experts offer strategies 
for how to design CUI personalities. These include 
identifying personality traits the CUI should have, which 
can be based on established models of personality [7] or 
brand values [8]; and identifying kinds of people to use as 
models for the CUI’s behavior. Persson et al. [9] refer to 
these two strategies as trait schemas versus social role 
schemas; though it is possible to use both together, for 
instance as recommended by Google [10] when developing 
for Google Assistant. 
C. Application of Inclusive Design to CUI Personality 
Community experts provide six Inclusive Design 
Principles [11]; here, we give examples to illustrate their 
applicability to CUI personality. As we discuss challenges 
in this paper, we will refer to the principles most applicable 
to each. 
1. Provide comparable experience: A CUI should 
use simple straightforward language so that 
people who cannot fluently read the CUI’s 
language can complete tasks with success 
similar to those who can. 
2. Consider situation: A CUI should use empathy 
if users are likely to be under pressure. 
3. Be consistent: A CUI should adhere to familiar 
conversational conventions, such as Grice’s 
maxims (see [12]). 
4. Give control: A CUI should give the user plenty 
of opportunities to steer the conversation. 
5. Offer choice: A CUI should be responsive to 
different language styles and registers. 
6. Prioritize content: A CUI should convey only 
content most relevant to the conversation topic 
so the user can stay focused. 
7. Add value: A CUI should not engage in talk or 
offer conversation paths that do not improve 
user experience or satisfaction. 
 
III. 
CHALLENGES FOR INCLUSIVE CUI PERSONALITIES 
A. Grace, Respect, Empathy, and Mindful Language 
What sort of personality will best serve the user’s 
purpose and scenario? That is likely to vary depending on 
the individual’s perspective, which may itself vary based on 
culture, gender, age, ability, or any of several factors. To 
bring grace, respect, and empathy to the CUI personality, 
the design team must conduct inclusive research with a 
broad range of human experience to design mindful, 
effective (and possibly affective) conversation. 
Empathy can improve adoption of CUIs and improve 
human mood [13][14]. However, inaccurate empathy such 
as unmerited sympathy can decrease the user’s trust [15]. 
Consider how a person’s background may influence the 
perception of personality, and how that might impact the 
acceptance of a CUI. Taking a casual tone may be perceived 
as disrespectful or create comfort; using dark humor could 
build rapport or offend; over time the bot’s personality 
could adapt to the relationship’s evolution or maintain a 
purely transactional perspective, depending upon the goal of 
the CUI service and user needs.  
Follow the Inclusive Design Principles, “provide 
comparable 
experience,” 
“consider 
situation,” 
“be 
consistent,” “give control,” “offer choice,” and “add value.” 
B. User’s Self-Identification 
Imagine, if you will, that a CUI refers to you regularly as 
a different gender than you identify as, or refers to abilities 
that you do not have; how would you feel? An individual’s 
identity is a personal statement reflecting their history, 
experience, values, and mission. How might a CUI welcome 
the full range of human identity, which may vary in 
language, lingo, tone, and even code switching? 
When designing a CUI’s personality, the development 
team should be aware of any biases and stereotypes 
informing the design and how this could interact with users’ 
self-identification. For instance, a digital assistant modeled 
after a young female secretary might appeal to certain users 
but offend others [16]. 
Follow the Inclusive Design Principles, “consider 
situation,” “give control,” and “offer choice.” 
C. User’s Situation and Mood 
There are situations that may be particularly stressful for 
people, such as navigating an unfamiliar city. Google Maps 
anticipated this by offering character voices such as Morgan 
Freeman or Santa Claus, which can defuse tension. 
Additionally, conversations between passengers and drivers 
tend to be simple and concise to account for their divided 
attention [17][18]. 
The user’s mood, like situation, affects conversational 
priorities. While an impatient user needs answers quickly, 
other 
users 
might 
appreciate 
additional 
content 
acknowledging their emotional state, such as potential 
targets of fraud [19]. 
Follow the Inclusive Design Principles, “consider 
situation,” “be consistent,” and “prioritize content.” 
D. Politeness 
What level of formality and politeness should a CUI 
show its human user? The wrong level of politeness in 
language and behavior can easily offend or annoy, such as 
over-politeness 
among 
friends 
or 
rudeness 
among 
acquaintances. 
2
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-896-9
CENTRIC 2021 : The Fourteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

Politeness theory distinguishes between positive and 
negative face. Positive face can be thought of as the desire 
for affirmation and acceptance, while negative face can be 
thought of as the desire to maintain personal autonomy. 
Polite language such as “if you don’t mind” appeals to 
negative face, allowing room to politely refuse [20]. 
However, politeness is more than specific phrases. It is 
important to identify the range of face needs for the CUI’s 
intended users. Someone reporting a scam may feel ashamed 
of having been fooled. The CUI can consider the user’s 
positive face by showing empathy and understanding [19]. 
Meanwhile, technological assistants for people with 
disabilities need to consider negative face and assist only as 
needed and requested [21]. 
Humans expect the politeness of an interaction to be 
appropriate to the social relationship between the two parties 
[20]. Therefore, it is important to ask first whether users are 
likely to approach the CUI as a social partner, and if so 
whether the CUI is viewed as a close peer or as a formal 
representative of some organization.  
Follow the Inclusive Design Principles, “consider 
situation,” “give control,” “offer choice,” and “add value.” 
E. Different Interaction Styles and Preferences 
When speaking with CUIs assisting with chronic disease 
management, 
patients 
preferred 
different 
healthcare 
provider 
interaction 
styles, 
such 
as 
paternalistic, 
informative, and deliberative, based on their ages and the 
nature of their disease [22]. In domains like healthcare that 
have clear taxonomies of interaction styles, CUI designers 
need to determine what user attributes will influence their 
preferences, or simply test a range of interaction styles with 
a large representative sample of target users to understand 
which are preferred. 
Follow the Inclusive Design Principles, “consider 
situation,” “give control,” “offer choice,” and “prioritize 
content.” 
IV. 
RECOMMENDATIONS FOR INCLUSIVE CUI 
PERSONALITIES 
A. Know Your Users, and Be Aware of Who You Are 
Including and Excluding 
When designing a CUI, understand your audience 
through user research, interviews, and contextual inquiry. 
Some teams document a list of those they are willing to 
exclude (for example, users of Internet Explorer 7 since it is 
well-past the sell-by date) and keep the list in mind 
throughout the design and development to guide decision-
making. Providing a text-based chatbot along with any 
audio is a way to be inclusive of those with hearing 
considerations. For Veteran survivors of military sexual 
trauma, future research may reveal that some personality 
features may be too “soft” and make the Veteran feel they 
are not understood. Get to know your audience, and provide 
personalities that suit their needs. 
B. Offer a Range of Personalities for a Range of People 
Offering a selection of personalities is one avenue that 
some interfaces offer. For example, Siri offers a selection of 
voices, as well as languages from a range of countries and 
regions. Each has a slightly different personality, and some 
users select their language from a particular region because 
of the personality they associate with it, such as a U.S. user 
choosing a U.K. accented voice. Microsoft’s Clippy virtual 
assistant evolved to offer alternative avatars with different 
personalities. An important rule of thumb, though, is: “No 
matter what you choose, avatars won't cure bad interactions. 
Just ask Clippy” [23]. In other words, personality choices 
must be targeted and not just for the sake of variety. 
C. Make Sure the Bot’s Personality Enhances Its Purpose 
Understanding the user’s purpose is key in designing 
suitable services. Depending on the audience, the bot may 
need to be formal or casual; humor and even conflict may be 
used to provoke critical thinking, such as with “Bots of 
Conviction” [24]. In this case study, the bot asked the user if 
they would bury their loved ones beneath their bed. Users 
generally were surprised, which allowed the bot to reveal 
that in some ancient cultures they did this to keep their 
loved ones close. The bot’s personality is confidently of 
another culture, eliciting discourse and reflection. In helping 
Veterans ready for life after active duty, a bot may need to 
be both compassionate and challenging, as it reminds users 
to go to training, submit forms, and attend to other tasks. In 
contrast, the Amazon customer service bot is friendly, 
upbeat, and apologetic as it addresses customer service 
issues. If it took a humorous approach, that would likely 
offend some customers already upset about a product issue. 
D. Understand Users’ Tendency to Anthropomorphize 
Some of the challenges mentioned in this paper depend 
on whether users are likely to view the CUI as a social 
partner or a transactional means to an end. Factors affecting 
a user’s tendency to anthropomorphize technology include 
age, gender, computer anxiety, and need for interaction [25]. 
Users likely to anthropomorphize CUIs can be expected to 
appreciate social conventions such as appropriately polite 
and empathic language. 
E. Involve Diverse People in the Development Process 
Because people from different cultures and backgrounds 
have different expectations for conversations, the surest way 
to accommodate a range of people is to involve them in 
product design and testing. Politeness conventions, for 
example, differ between individualistic and collectivistic 
cultures [26]. 
Radar Pace, a virtual coach developed by Oakley and 
Intel, adjusts its personality by locale. In Spanish-speaking 
locales, the coach’s voice is female and gives responses that 
are “firm and authoritative”, while in French-speaking 
locales it has a male voice and is “encouraging and 
cooperative” [8]. Cross-cultural feedback was necessary to 
3
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-896-9
CENTRIC 2021 : The Fourteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

create an application that could be taken seriously as a 
coach by a variety of users. 
V. 
CONCLUSION 
In this paper we presented challenges that should be 
systematically addressed in research to move toward 
inclusive CUI personalities, as well as some overarching 
recommendations or themes to guide development. Studies 
exploring the impacts of empathy and politeness in 
conversational robots and software need to be integrated with 
studies of how diverse users respond to manifestations of 
social cues in technology. CUI development teams should 
take full advantage of user-centered research and design 
tools, such as personas, user stories, and structured 
interviews [27], to understand and anticipate the range of 
needs, attitudes, and expectations of their users. 
Most CUIs take an initially neutral personality and when 
an interaction becomes more complex transfers the 
conversation to a human being. Until a CUI can precisely 
adapt to a user’s preferences, that approach remains among 
the most inclusive. However, ambitious research, synthesis, 
and tool development can bring us closer to CUIs that serve 
all potential users at all times of day. 
 
Approved for public release. Distribution unlimited 20-
03275-5. 
REFERENCES 
[1] 
K. Lister, T. Coughlan, F. Iniesto, N. Freear, and P. 
Devine, “Accessible conversational user interfaces: 
considerations for design,” in Proceedings of the 17th 
International Web for All Conference, New York, NY, 
USA, 
Apr. 
2020, 
pp. 
1–11. 
doi: 
10.1145/3371300.3383343. 
[2] 
J. Stanley, R. ten Brink, A. Valiton, T. Bostic, and B. 
Scollan, “Chatbot Accessibility Guidance: A review and 
way forward,” in Proceedings of Sixth International 
Congress 
on 
Information 
and 
Communication 
Technology: ICICT 2021, London, vol. 3, X.-S. Yang, S. 
Sherratt, N. Dey, and A. Joshi, Eds. Brunel University, 
London: Springer Nature Singapore Pte Ltd., 2021, pp. 
919–942. Accessed: Apr. 14, 2021. [Online]. Available: 
https://www.springer.com/gp/book/9789811617805 
[3] 
J. Davis, “Government CIOs Prioritize Chatbots in 
Pandemic,” InformationWeek, Jan. 06, 2021. Accessed: 
Aug. 
12, 
2021. 
[Online]. 
Available: 
https://www.informationweek.com/leadership/governme
nt-cios-prioritize-chatbots-in-pandemic 
[4] 
L. Avanessian, “Bank of America: Designing Erica’s 
chatbot 
personality,” 
2018. 
https://loricavanessian.com/project/erica (accessed Mar. 
17, 2021). 
[5] 
Á. Callejas-Rodríguez, E. Villatoro-Tello, I. Meza, and 
G. Ramírez-de-la-Rosa, “From Dialogue Corpora to 
Dialogue Systems: Generating a Chatbot with Teenager 
Personality for Preventing Cyber-Pedophilia,” in Text, 
Speech, and Dialogue, Cham, 2016, pp. 531–539. doi: 
10.1007/978-3-319-45510-5_61. 
[6] 
C. Edwards, A. Edwards, B. Stoll, X. Lin, and N. 
Massey, “Evaluations of an artificial intelligence 
instructor’s voice: Social Identity Theory in human-robot 
interactions,” Comput. Hum. Behav., vol. 90, pp. 357–
362, Jan. 2019, doi: 10.1016/j.chb.2018.08.027. 
[7] 
S. Katz, “The ultimate guide to chatbot personality,” 
Medium, 
May 
18, 
2020. 
https://chatbotsmagazine.com/the-ultimate-guide-to-
chatbot-personality-b9665ab5e99d (accessed Jan. 04, 
2021). 
[8] 
A. Danielescu and G. Christian, “A Bot is Not a 
Polyglot: Designing Personalities for Multi-Lingual 
Conversational Agents,” in Extended Abstracts of the 
2018 CHI Conference on Human Factors in Computing 
Systems, Montreal QC Canada, Apr. 2018, pp. 1–9. doi: 
10.1145/3170427.3174366. 
[9] 
P. 
Persson, 
J. 
Laaksolahti, 
and 
P. 
Lonnqvist, 
“Understanding 
socially 
intelligent 
agents 
- 
a 
multilayered phenomenon,” IEEE Trans. Syst. Man 
Cybern. - Part Syst. Hum., vol. 31, no. 5, pp. 349–360, 
Sep. 2001, doi: 10.1109/3468.952710. 
[10] 
Google, “Create a persona - Conversation design process 
- Conversation design,” Designing Actions on Google, 
2021. 
https://designguidelines.withgoogle.com/conversation/co
nversation-design-process/create-a-persona.html 
(accessed Oct. 21, 2020). 
[11] 
H. Swan, I. Pouncey, H. Pickering, and L. Watson, 
“Inclusive 
Design 
Principles,” 
Inclusive 
Design 
Principles, 2021. https://inclusivedesignprinciples.org/ 
(accessed Aug. 09, 2021). 
[12] 
B. Jacquet, A. Hullin, J. Baratgin, and F. Jamet, “The 
Impact of the Gricean Maxims of Quality, Quantity and 
Manner in Chatbots,” in 2019 International Conference 
on Information and Digital Technologies (IDT), Jun. 
2019, pp. 180–189. doi: 10.1109/DT.2019.8813473. 
[13] 
T. Bickmore, A. Gruber, and R. Picard, “Establishing the 
computer–patient working alliance in automated health 
behavior change interventions,” Patient Educ. Couns., 
vol. 59, no. 1, Art. no. 1, Oct. 2005, doi: 
10.1016/j.pec.2004.09.008. 
[14] 
M. de Gennaro, E. G. Krumhuber, and G. Lucas, 
“Effectiveness of an Empathic Chatbot in Combating 
Adverse Effects of Social Exclusion on Mood,” Front. 
Psychol., 
vol. 
10, 
p. 
3061, 
Jan. 
2020, 
doi: 
10.3389/fpsyg.2019.03061. 
[15] 
H. Cramer, J. Goddijn, B. Wielinga, and V. Evers, 
“Effects of (in)accurate empathy and situational valence 
on attitudes towards robots,” in 2010 5th ACM/IEEE 
International Conference on Human-Robot Interaction 
(HRI), Osaka, Japan, Mar. 2010, pp. 141–142. doi: 
10.1109/HRI.2010.5453224. 
[16] 
F. D. Rosis, C. Pelachaud, and I. Poggi, “Transcultural 
believability in embodied agents: a matter of consistent 
adaptation,” in Agent Culture: Human Agent Interaction 
in a Multicultural World, S. Payr and R. Trappl, Eds. 
Mahwah, New Jersey: Lawrence Erlbaum Associates, 
2004, pp. 75–106. 
[17] 
J. Maciej, M. Nitsch, and M. Vollrath, “Conversing 
while driving: The importance of visual information for 
conversation modulation,” Transp. Res. Part F Traffic 
Psychol. Behav., vol. 14, no. 6, pp. 512–524, Nov. 2011, 
doi: 10.1016/j.trf.2011.05.001. 
4
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-896-9
CENTRIC 2021 : The Fourteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

[18] 
F. A. Drews, M. Pasupathi, and D. L. Strayer, 
“Passenger and cell phone conversations in simulated 
driving,” J. Exp. Psychol. Appl., vol. 14, no. 4, pp. 392–
400, 2008, doi: 10.1037/a0013119. 
[19] 
J. Guo, J. Guo, C. Yang, Y. Wu, and L. Sun, “Shing: A 
Conversational Agent to Alert Customers of Suspected 
Online-payment 
Fraud 
with 
Empathetical 
Communication Skills,” in Proceedings of the 2021 CHI 
Conference on Human Factors in Computing Systems, 
Yokohama 
Japan, 
May 
2021, 
pp. 
1–11. 
doi: 
10.1145/3411764.3445129. 
[20] 
P. Brown and S. C. Levinson, Politeness: Some 
Universals in Language Usage. Cambridge University 
Press, 1987. 
[21] 
J. R. Wilson, N. Y. Lee, A. Saechao, and M. Scheutz, 
“Autonomy and Dignity: Principles in Designing 
Effective Social Robots to Assist in the Care of Older 
Adults,” 2016. 
[22] 
C. Gross et al., “Personalization of Conversational 
Agent-Patient Interaction Styles for Chronic Disease 
Management: Results from two studies with COPD 
patients (Preprint),” Journal of Medical Internet 
Research, 
preprint, 
Dec. 
2020. 
doi: 
10.2196/preprints.26643. 
[23] 
C. Platz, Design Beyond Devices: Creating Multimodal, 
Cross-Device Experiences, 1st edition. New York: 
Rosenfeld Media, 2020. 
[24] 
M. Roussou, S. Perry, A. Katifori, S. Vassos, A. 
Tzouganatou, and S. McKinney, “Transformation 
through Provocation?,” in Proceedings of the 2019 CHI 
Conference on Human Factors in Computing Systems, 
New York, NY, USA: Association for Computing 
Machinery, 2019, pp. 1–13. Accessed: Aug. 12, 2021. 
[Online]. 
Available: 
https://doi.org/10.1145/3290605.3300857 
[25] 
M. Blut, C. Wang, N. V. Wünderlich, and C. Brock, 
“Understanding anthropomorphism in service provision: 
a meta-analysis of physical robots, chatbots, and other 
AI,” J. Acad. Mark. Sci., vol. 49, no. 4, pp. 632–658, Jul. 
2021, doi: 10.1007/s11747-020-00762-y. 
[26] 
P. Longcope, “The universality of face in Brown and 
Levinson’s politeness theory: A Japanese perspective,” 
Univ. Pa. Work. Pap. Educ. Linguist., vol. 11, no. 1, pp. 
69–79, 1995. 
[27] 
E. Adiseshiah, “Personas, scenarios, user stories and 
storyboards: what’s the difference?,” JUSTINMIND, Jul. 
28, 
2017. 
https://www.justinmind.com/blog/user-
personas-scenarios-user-stories-and-storyboards-whats-
the-difference/ (accessed Aug. 12, 2021). 
 
5
Copyright (c) IARIA, 2021.     ISBN:  978-1-61208-896-9
CENTRIC 2021 : The Fourteenth International Conference on Advances in Human-oriented and Personalized Mechanisms, Technologies, and Services

