Identiﬁcation of Personal Actions with Brightness Distribution Sensors
to Harmonize Domestic Affairs
Nobuaki Takaoka
Graduate school of Information Science and Engineering
Ritsumeikan University
Email: takaoka@de.is.ritsumei.ac.jp
Yusuke Kajiwara, Hiromitsu Shimakawa
College of Information Science and Engineering
Ritsumeikan University
Email: kajiwara@de.is.ritsumei.ac.jp
simakawa@de.is.ritsumei.ac.jp
Abstract—There are many attempts to recognize actions using
sensors in homes. Some of them aim to keep watching on
the elderly living alone, while others try to bring ecological
life, scheduling domestic actions consuming energy. We need
an inexpensive method to make it prevail in the society. In
the meantime, recognition results threaten privacy, if outsiders
obtain them. Almost all people mind whether they are used in
malicious ways. The sensor should prevent the leak of the privacy
of users. This work proposes a method to recognize various
domestic actions with a single kind of sensors, which is not only
inexpensive, but also safe enough to protect the privacy. The
method uses brightness distribution sensors presenting a sequence
of cells, each of which indicates the brightness of one direction
in the view area of the sensor. The method gets local features
along with the persons who conduct domestic actions. The method
enables to recognize both of domestic actions and the period in
which they are conducted. To evaluate the accuracy of the method,
10 men and women have participated in an experiment, where
they take various domestic actions in their own ways with 4
brightness distribution sensors installed on the wall of an actual
kitchen. As a result, the method has marked high performance
on the recognition of“ vacuuming ”,“ cooking ”, and“ taking
a rest ”, along with their periods. The method also identiﬁes all
examinees who conduct them in high accuracy. It is possible to
recognize domestic actions in actual home spaces.
Keywords–Domestic action; Brightness distribution sensor.
I.
INTRODUCTION
There are many attempts to recognize actions by robots [1],
[2], sensing [3] and constructing Internet of Things (IoT) [4]
in homes. Among them, recognition of actions by sensors in
homes is expected to bring various beneﬁts [5]. It allows us to
keep watching of the elderly living alone, as well as to make
domestic action schedules reducing energy consumption. In
Japan where the ratio of the elderly is increasing rapidly, it is
essential to keep watching of the elderly living alone, in order
to ﬁnd fatal accidents and mental decline due to loneliness.
Energy saving is also inevitable for people in Japan lacking
petroleum production. Inexpensive sensors would realize to
keep watching the elderly, even if there are few persons to
take care of the elderly. They would also contribute to using
electricity efﬁciently in daily activities. The recognition of
actions of each of family members would lead to accommodate
the timing of actions of every member so as to minimize the
energy consumption, avoiding degradation of the life quality
of whole members.
On the other hand, recording of domestic actions has dan-
gers to reveal the privacy of the family members to outsiders.
They mind unexpected troubles caused by improper use of
the records. Almost all people hate installing sensors which
recognize domestic actions from the viewpoint of the privacy.
We need low cost sensors to recognize domestic actions
with privacy protection. Nakajima et.al have developed bright-
ness distribution sensors [6] to detect emergencies for the
elderly, protecting their privacy. Using the brightness distri-
bution sensors, this work presents a method to recognize
domestic actions. The method identiﬁes domestic actions along
with persons who take them. A brightness distribution sensor
has a ﬁeld of vision like a camera. However, instead of a
real image of the ﬁeld, it produces brightness values of the
ﬁeld in one dimension. It protects the privacy because human
beings cannot understand the brightness values. Brightness
distribution sensors are realized inexpensively, changing lenses
of web cameras into rod lenses.
The paper presents the practicability of brightness distri-
bution sensors with the accuracy to recognize each of various
daily life actions taken in an actual environment. We have
experimented to distinguish 10 persons take various actions in
an actual living space. The method has identiﬁed both of actors
and periods of actions, such as“ vacuuming ”,“ cooking ”,
and“ taking a rest ”in high accuracy.
Section 2 presents related works. The proposed method is
explained in section 3. Section 4 presents an experiment to
verify the effectiveness of the proposed method. In section 5,
the paper discusses the experiment results. Section 6 concludes
the work.
II.
RELATED WORKS
In order to keep watching the elderly, a work presented
in [7] has conducted a long term investigation to detect their
accidents. Works presented in [8]–[11] utilize ubiquitous sen-
sors to identify domestic actions. The work in [8] recognizes
physiological actions, such as sleeping, meal, excreting, and
bathing. It detects unusual conditions of the elderly with
deviation from usual actions. It costs high for the method
presented in [8] to recognize actions, because they use qualiﬁed
sensors which are specialized to ﬁnd feature of these actions.
The method does not provide ability to generalize actions to
be recognized, but recognizes only 4 actions. It also fails
to recognize who takes the actions. It does not address the
versatility of daily life actions. A visit of a person other
than the family members may cause the method to present
unexpected outputs. The work explained in [9] is similar to
the previous one, because it keeps watching of the elderly,
using accelerometers, video cameras, and microphones.
There is also a method to keep watching of the elderly
with an integrated platform which manages energy and support
for the elderly to live safely and comfortably [10][11].These
method watches the elderly using image data, which a third
person can understand.
There are methods to detect domestic actions in smart
houses [12]–[15]. Family members can accommodate their en-
ergy consumption, following a schedule the method proposes.
The methods should not present a schedule which is far from
usual daily life [16]. Nakamura et al. proposes the method
which integrates data by GPS, smart taps, and laser range
152
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-426-8
SENSORDEVICES 2015 : The Sixth International Conference on Sensor Device Technologies and Applications

scanners [12]. The method cannot identify who has conducted
each of actions, even though it uses several laser range scanners
which are expensive. Generally, there are more than family
members in a house. The fail of recognition of actors prevents
the method to present a schedule acceptable to all members.
For example, let us consider a family where a speciﬁc person
is in charge of house-keeping. If the method cannot recognize
actors of actions, it might presents wrong schedule that makes
other family members to take care of the house keeping.
There are methods to recognize domestic actions with
smart meters which recognize electric power consumption of
every electronic appliances[13][14].There is also a method to
recognize domestic actions, measuring energy consumption of
each appliance [15]. They cannot recognize domestic actions
which do not consume electricity. It cannot provide proper
services, due to the lack of the generality.
III.
RECOGNITION OF DOMESTIC ACTIONS AND THEIR
ACTORS
A. Method overview
In the recognition of domestic actions, we should identify
actors of the actions, and the periods in which actors take
the actions. Various domestic actions must be recognized with
a single kind of sensors to reduce the cost. Since actors are
identiﬁed, we should provide a method to protect their privacy.
The proposed method realizes the recognition with sensors
which get brightness distribution. The sensors extract the
brightness distribution from original images of target objects.
Since it prevents the reconstruction of original images, it
protects the privacy.
The method calculates a background difference of the
brightness distribution acquired at home. It also calculates
a spatial difference and a temporal difference. They include
a lot of local features of domestic actions. Base on the
Bag-of-Features, the method represents each of brightness
distribution data the sensors sample at a speciﬁc time as
a multi-dimensional vector. Clustering all of the brightness
distribution data, the method calculates the centroid of each
cluster. The centroids are standards to represent features of
all brightness distribution data. For each cell in a speciﬁc
brightness distribution data, the method searches the cluster
nearest to the cell. Voting to the cluster, it constructs a
histogram for the brightness distribution data. The features of a
domestic action of an actor are represented with the histogram.
It is considered features vary with actors and kinds of domestic
actions. The shape of histograms is similar with each other
when a speciﬁc actor takes the same kind of domestic actions.
The method constructs a classiﬁer to detect domestic actions
and their actors from the shape of histograms. Actors take their
domestic actions anytime. The method constructs histograms
periodically to recognize domestic actions and their actors.
Figure 1 shows the overview of the method to periodically
recognize domestic actions and their actors. Taking the average
of the brightness vertically, brightness distribution sensors put
out brightness distribution data which consist of an array of
cells as many as the number of horizontal pixels of original
images. The method installs brightness distribution sensors at
home. It gets brightness distribution data of a background
image at a situation which contains no target person or target
object. The method also gets a time series of brightness distri-
bution data at a situation where a speciﬁc actor is conducting
each domestic action. The method calculates the background
difference, subtracting the brightness distribution data at the
domestic action from that of the background image. The
background difference expresses values which change when
the brightness distribution sensor captures persons and objects
different from the background image are captured. We address
Figure 1. Method overview
three kinds of local elements corresponds to the appearance,
the shape, and the motion from the background difference. The
appearance is the background difference itself, the difference
of the brightness of reﬂecting light of a target from that of the
background. The shape is expressed with the spatial difference
of the background difference. It is variation of the brightness
of reﬂecting light affected by the shape of a target. The motion
is expressed with the temporal difference of the background
difference. The motion is the brightness variation of reﬂecting
light affected by the motion of a target.
The method plots all cells of a time series of brightness
distribution data in three dimension space whose axes are
three local elements: the background difference, the position
difference, and the time difference. The method classiﬁes all
cells in the three dimension space into clusters. The centroid
of each cluster is the representative value of the cluster. On
the basis of the centroids, the method recognizes features of
a time series of brightness distribution data. Note that each
centroid is also represented with a three dimension vector
whose elements are the background difference, the position
difference, and the time difference. For example, suppose the
background difference and the position difference are 0 while
the time difference is 10 in the centroid of a cluster. The cluster
represents a feature pattern of motion. The method assigns the
vector of each cell to the cluster whose centroid is nearest
from the vector. Let us consider chronological brightness
distribution data in a domestic action of a speciﬁc person. The
method constructs a histogram which expresses the number of
vectors in a time series of brightness distribution data. The
shape of the histograms shows features of the domestic action
of the person.
The method also considers where the person takes the
action in the viewing ﬁeld of the brightness distribution sensor.
It divides an array of cells from a brightness distribution sensor
into two and three parts in each period. It also constructs
histograms from the divided cells. The method takes various
histograms to construct a discriminator of actions and their
actors with the Random Forest. The method gives histograms
which are constructed with newly data of chronological bright-
ness distribution into the discriminator. Providing a new time
series of brightness distribution data for the discriminator, the
method recognizes domestic actions along with their actors.
B. Brightness distribution sensor
The brightness distribution represents how brightness val-
ues distribute in an image of a target object. Suppose an
image of a target represented with a matrix, like one taken
with a Web camera. The brightness distribution is represented
with an array of cells, each of which expresses the average
153
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-426-8
SENSORDEVICES 2015 : The Sixth International Conference on Sensor Device Technologies and Applications

Figure 2. A brightness distribution sensor
Figure 3. Background difference
of the brightness of the column corresponding to the cell.
The result is an array of the brightness which spreads in the
row direction. A brightness distribution sensor realizes the
calculation optically, condensing vertical brightness with a rod
lens [6]. Figure 2 shows information acquired with a brightness
distribution sensor. Let n be the number of pixels in the row
direction of the sensor. The brightness distribution at time point
t, Bt, is formula (1) where B(t, p) is the brightness of the p-th
cell.
Bt = B(t, 0), B(t, 1), · · · , B(t, n)
(1)
A brightness distribution sensor has three advantages in the
recognition of domestic actions. First, a brightness distribution
sensor covers a large angle in a room to recognize various
domestic actions. It is programmable so as to recognize various
actions with brightness features. It reduces the number of
sensors required to recognize domestic actions. The sensor
has high versatility to recognize domestic actions. Second,
a brightness distribution sensor protects privacy. Since the
brightness values are averaged optically for every cell, the
third person cannot reconstruct an image of an actor taking a
speciﬁc domestic action. Third, a brightness distribution sensor
is inexpensive. We can implement a brightness distribution
sensor, exchanging lenses of a web camera into a rod lenses.
Utilizing the CMOS sensor of the web camera, we can make
an inexpensive brightness distribution sensor.
C. Background difference
Figure 3 shows how to calculate the background difference.
Let I and B are an array of the brightness distribution when
an target exists, and that when the target does not exist,
respectively. The background difference, D, is the difference
of I from B. The recognition of domestic actions should not be
affected by a background, such as the wall texture in a room.
However, brightness distribution data contains both of moving
objects and the background. Since background difference D
contains no background information, it contributes to more
precise recognition of domestic actions. Like the brightness
distribution, background difference D is formula (2) where
D(t, p) is the background difference value of the p-th cell at
time point t.
Dt = D(t, 0), D(t, 1), · · · , D(t, n)
(2)
Figure 4. Extracting feature patterns from local elements
D. Extraction of feature patterns with local elements
Figure 4 shows how to extract feature patterns from local
elements. Let D(t, p) is the background difference of the p-th
cell in the t-th frame of the chronological brightness distri-
bution data recording a speciﬁc domestic action. For the cell,
the method calculates three local elements: e1(t, p), e2(t, p),
and e3(t, p). The ﬁrst element, e1(t, p), is the background
difference, which is given with (3).
e1(t, p) = D(t, p)
(3)
It considers only the target, excluding the background, to show
the appearance of the target. The second element is obtained
with (4).
e2(t, p) = D(t, p) − D(t, p − 1)
(4)
e2(t, p) is the difference of the background difference value of
the cell from the neighbor one. It corresponds to the spatial
difference of the background difference value. Since the equa-
tion ﬁgures out the brightness difference in the neighboring
cells, it contributes to recognizing the shadow of a target to
show its shape. The third element is calculated with (5).
e3(t, p) = D(t, p) − D(t − 1, p)
(5)
Since e3(t, p) is the brightness difference in the neighboring
frames of the same cell, it is the time difference of the
brightness to recognize motion of the target. The method per-
forms clustering vectors consisting of the 3 local elements. It
regards the centroid vector of each cluster as a feature pattern.
Feature patterns allow us to represent motion of the target in
various domestic actions. For example, in vacuuming, many
cells would show a feature pattern of strenuous movement of
arms. The method classiﬁes all cells in the three dimension
space with the k-means.
E. Histograms for location
Figure 5 shows how to calculate histograms which show
a feature of domestic actions. For example, an actor proceeds
vacuuming along a path the actor determines. The path varies
with each actor. In addition, rules to determine paths are
qualitative and ambiguous. For example, one actor might have
a rule to proceed vacuuming around the table clockwise.
We should recognize where each feature pattern appears to
distinguish actors. The method divides each frame into two
and three parts. Combined with the original one, the method
gets in total 6 time series of brightness distribution data.
For each cell in the 6 time series, the method ﬁnds the
nearest cluster. The method constructs histograms for each
time series. Histograms constructed from the 6 time series
154
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-426-8
SENSORDEVICES 2015 : The Sixth International Conference on Sensor Device Technologies and Applications

Figure 5. Calculation of histograms
Figure 6. Division of a time series of brightness distribution data
represents features of brightness distribution data. The features
include the location where the actor takes the action, such as
person X proceeding vacuuming around the table clockwise.
Since each actor seems to have his own rule to conduct a
speciﬁc domestic action, the histograms presents features of
domestic actions of a speciﬁc actor.
F. Recognition of time series
The proposed method divides a whole time series of the
brightness distribution data into several parts. To detect when
an actor takes a speciﬁc action, it is necessary to recognize
domestic actions along with their actors in each part. When an
action is recognized, it is not preferable for several actions to
be taken in a single time series of brightness distribution data.
However, since the timing of each domestic action depends on
its actor, it is difﬁcult to ﬁnd the switching of one domestic
action to another. A single time series of brightness distribution
data can contain several domestic actions. As shown in Figure
6, the method sequentially recognizes domestic actions for
every time series of ﬁxed length, without the consideration
of switching of domestic actions. Instead of the considering
any switching of domestic actions, the method identiﬁes the
domestic action conducted for the longest time in a given
duration. It regards the domestic action as the one representing
the duration. The method constructs histograms sequentially
for every duration of a ﬁxed length. It gives the histograms
to a discriminator based on the Random Forest. Through the
process, the method recognizes domestic actions, their actors,
and the periods in which the actors conduct the domestic
actions.
Figure 7. Living space and domestic actions
IV.
AN EXPERIMENT IN LIVING SPACE
A. Outline of experiment
We have evaluated the proposed method to identify the
actor, the period, and the kind of domestic action conducted
in a living space. We validate identiﬁcation accuracy of the
method. Subjects are ten males and females who are all
twenties. Each subject conducts domestic actions one by one
in the living space. Figure 7 shows a sketch of a living space
with a kitchen on ﬂoorings, where domestic actions are taken
place in the experiment. We install four brightness distribution
sensors so that their visual ﬁelds coves whole of the living
space. Target domestic actions in the experiment should be
ones which frequently happen in any living space. We adopt
“ vacuuming ”, “ wiping a table ”, “ cooking ”, “ gargling
and hand washing ”, and“ taking a rest ”as target domestic
actions, in addition to“none ”, which means there is nobody.
The“ vacuuming ”action is a domestic action that a subject
vacuums the ﬂoorings. A subject might vacuum under the
tables and chairs, moving them. The “ wiping a table ” is a
domestic action that a subject wipes the table with a wet towel
placed on the sink. A subject might wipe under objects on the
table, moving the objects. The“cooking”is a domestic action
in which a subject takes an egg from the refrigerator, stirs the
egg inside a bowl, ﬂies the egg with salad oil with a frying pan,
serves it on a plate, and washes all the cooking utensils. The
cook utensils in the experiment are a bowl, a chopsticks, and
a frying pan. Ingredients in the experiment are eggs and salad
oil. The“gargling and hand washing”is a domestic action in
which a subject washes his own hands with soap and gargles
with water in the sink. The“gargling and hand washing”has a
peculiar vertical motion in front of the sink. We install sensor
B in the sideway at the sink so that it is rotated by ninety
degree from the gravity direction. The “ taking a rest ” is a
domestic action in which a subject spends time freely within
the visual ﬁeld of the brightness distribution sensors. It varies
with each subject. The“ none ”is a state in which no subject
stays in visual ﬁeld. We use a brightness distribution data of
the“none”to examine the rate of wrong detection of domestic
actions. Every subject conducts the 4 kinds of domestic actions
within 10 minutes. If they ﬁnish them earlier, they can spend
the remaining time with the “ taking a rest ” action. We do
not give subjects more speciﬁc directions for each kind of
domestic actions. We do not specify the time length and the
order of domestic actions. Brightness distribution data vary
with each subject. We examine the identiﬁcation accuracy of
domestic actions varying with subjects. After the ten minutes,
subjects take a rest for one minute outside the visual ﬁelds
of the brightness distribution sensors. The rest is treated as a
“ none ”state. Every subject repeats the above ﬁve times.
B. Evaluation method
We evaluate the ability of the proposed method in terms of
identiﬁcation of kinds and actors of domestic actions. We take
a video of all domestic actions. We divide the video data into
155
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-426-8
SENSORDEVICES 2015 : The Sixth International Conference on Sensor Device Technologies and Applications

slots, which of which lasts twenty seconds. We label every slot
with a pair of an actor and a domestic action the actor conducts
longest in the slot. Since the“ none ”has no actor, we do not
label any“none”slot. The method divides a set of brightness
distribution data from the four brightness distribution sensors
into periods. Each of the period lasts 20 seconds synchronized
with the video data. The method constructs histograms for each
period, according to the way explained in section 3. In the
experiment, the number of clusters in the k-means method is
25. Because of the synchronization, each period is associated
with a pair of histograms and a label. A discriminator is
trained, taking histograms and labels as explanatory variables
and response variables, respectively. We use the cross valida-
tion to verify the discriminator. In the cross validation, one
pair of histograms and a label is used as a test data, while
the remaining pairs are used as instruction data. We verify
the identiﬁcation ability of actors by the recall, the precision,
and the F measure. Let us consider periods where a speciﬁc
actor takes a speciﬁed action. The recall is the rate of the
correctly detected periods out of the periods the actor actually
takes the action. The precision is the rate of the correctly
detected periods out of all detected periods. The F measure
is the harmonic mean of the precision and the recall. The
identiﬁcation ability of domestic actions is also evaluated with
the recall, the precision, and the F measure.
C. Result of experiment
TABLE I. IDENTIFICATION OF DOMESTIC ACTIONS
Precision
Recall
F-measure
not existing
0.782
0.933
0.851
vacuuming
0.743
0.759
0.751
wiping a table
0.605
0.267
0.371
cooking
0.854
0.943
0.897
gargling and hand washing
0.855
0.355
0.461
taking a rest
0.806
0.709
0.754
Table I shows the result of the identiﬁcation of domestic
actions. Domestic actions with the high accuracy are the “
vacuuming”, the“cooking”, and the“taking a rest”action,
as well as the“none”state. On the contrary, the bad accuracy
is found for the“wiping a table”and the“gargling and hand
washing ”actions.
TABLE II. THE RESULT OF IDENTIFICATION OF ACTORS.
Precision
Recall
F-measure
actor A
0.770
0.765
0.768
actor B
0.824
0.801
0.813
actor C
0.781
0.791
0.786
actor D
0.877
0.839
0.857
actor E
0.894
0.900
0.897
actor F
0.785
0.780
0.783
actor G
0.852
0.789
0.819
actor H
0.758
0.763
0.760
actor I
0.726
0.558
0.631
actor J
0.793
0.793
0.793
The result of identiﬁcation of actors is presented in Table II.
The accuracy is fairly high for every actor. The results indicate
the proposed method recognizes an actor and the period when
the actor conducts the “ vacuuming ”, the “ cooking ”, and
the“ taking a rest ”actions in the experiment.
The 6 kinds of domestic actions are divided into 2 groups:
the“high accuracy”group and the“low accuracy”group in
order to examine what conditions cause misidentiﬁcation. The
“ high accuracy ”group contains actions identiﬁed with high
accuracy, while the“ low accuracy ”one consists of actions
with low identiﬁcation accuracy. As shown in Table1, the“high
accuracy”group includes the“vacuuming”, the“cooking”,
and the“taking a rest”actions, along with the“none”state.
Figure 8. Comparison of misidentiﬁcation patterns
The“ wiping a table ”and the“ gargling and hand washing ”
are listed in the“ low accuracy ”group.
Some actions are identiﬁed with high accuracy, while
others with low accuracy. Even if the actions of good accuracy
take place, the recognition accuracy might get lower in periods
where domestic actions switch or periods whose adjacent
periods contain domestic actions of low accuracy. We examine
how misidentiﬁed periods affect the identiﬁcation ability of the
method. We consider the following three patterns for sequential
three periods, to see their effects on misidentiﬁcation.
1)
An actor conducts distinct domestic actions of high
accuracy in each of the period, which is labeled with
“ distinct action of high accuracy in every period ”.
2)
An actor conducts a single domestic action of high
accuracy in all of the three periods, which is labeled
with“single action of high accuracy in every period”.
3)
An actor conducts domestic actions of low accuracy
in any of the three periods, which is labeled with
“ actions of low accuracy in some periods ”.
We examine how many times these patterns appear in misiden-
tiﬁed periods. We consider what condition makes the method
misidentify frequently.
The three patterns are labeled in Figure 8. Neither of the
ﬁrst and the second contains domestic action of low accuracy.
In the ﬁrst and the third pattern, domestic actions are switched.
The Figure 8 shows the percentages of periods in accord
with the misidentiﬁcation patterns over the whole experiment
periods for every actor. As the result, common to all actors,
the patterns are arranged as“actions of low accuracy in some
periods”,“distinct action of high accuracy in every period”,
and“ single action of high accuracy in every period ”, in the
descending order of their frequency.
V.
DISCUSSION
First, we address reasons for the low accuracy for some
actions. The“ wiping a table ”and the“ gargling and hand
washing ” actions are shorter than other domestic actions in
their length. In addition to that, hands move in front of a body
in the actions“. The method fails to extract feature of hands by
the background difference. Since those action resemble with
each other, the method fails to identify them.
156
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-426-8
SENSORDEVICES 2015 : The Sixth International Conference on Sensor Device Technologies and Applications

On the contrary, we have expected low accuracy while
actors are “ taking a rest ”, because they can take any ac-
tion during the period. However, the time prepared for the
experiment is so short that actors cannot afford to enjoy their
own free behavior when they ﬁnish all speciﬁed actions. They
take similar behavior while“taking a rest ”. The method gets
an unexpected high accuracy to identify the“ taking a rest ”
actions, even though there is no constraint for their behavior.
For all actors, the method gets the low accuracy of identi-
ﬁcation in the period where actions are switched or actions of
low accuracy are taken place in adjacent periods. Note that we
aim to identify the length of a speciﬁc domestic action, which
contributes to monitoring the elderly and scheduling actions to
save energy. To accomplish the aim, the misidentiﬁcation in
the switching of domestic actions brings less harmful impacts
than that during a single domestic action. If we consider only
domestic actions of high accuracy, we can expect more proper
recognition of their period.
VI.
CONCLUSION
In this paper, we propose the identiﬁcation method of
domestic actions, along with their actors, and period. The
method recognizes domestic actions with brightness distribu-
tion sensors. The recognition repeated in a ﬁxed period allows
to identify actors conducting domestic actions independent
from the timing the actors take the domestic actions.
The method identiﬁes actors and the period of the“ vac-
uuming ”, the “ cooking ”, the “ taking a rest ” actions in
high accuracy, in an experiment. The method contributes to
watching of the elderly and effective usage of electricity.
We are going to verify the effectiveness of the method with
other kinds of domestic actions.
REFERENCES
[1]
L. Piyathilaka and S. Kodagoda, “Human activity recognition for
domestic robots,” in Field and Service Robotics.
Springer, 2015, pp.
395–408.
[2]
M. Vinagre, J. Aranda, and A. Casals, “An interactive robotic system
for human assistance in domestic environments,” in Computers Helping
People with Special Needs.
Springer, 2014, pp. 152–155.
[3]
F. Xie, A. Song, and V. Ciesielski, “Genetic programming based activity
recognition on a smartphone sensory data benchmark,” in Evolutionary
Computation (CEC), 2014 IEEE Congress on.
IEEE, 2014, pp. 2917–
2924.
[4]
A. F. Santamaria, F. De Rango, D. Barletta, D. Falbo, and A. Imbrogno,
“Data analysis and integration of environmental sensors to meet human
needs,” in SPIE Sensing Technology+ Applications.
International
Society for Optics and Photonics, 2014, pp. 91 030A–91 030A.
[5]
S. Hattori, Y. Kameda, and Y. Ohta, “A study of multi-sensor correlation
toward abnormality recognition,” IEICE Technical Report MVE, vol.
104, no. 489, 2004, pp. 19–25, (in Japanese).
[6]
S. Nakashima, H. M. Lu, K. Miyata, Y. Kitazono, and S. Seiichi,
“Person localization system using privacy-preserving sensor,” Applied
Mechanics and Materials, vol. 103, 2012, pp. 622–627.
[7]
A. Hein, E.-E. Steen, A. Thiel, M. H¨ulsken-Giesler, T. Wist, A. Helmer
et al., “Working with a domestic assessment system to estimate the need
of support and care of elderly and disabled persons: results from ﬁeld
studies,” Informatics for Health and Social Care, vol. 39, no. 3-4, 2014,
pp. 210–231.
[8]
H. Tanaka and Y. Nakauchi, “Senior citizen monitoring system by using
ubiquitous sensors(mechanical systems),” Transactions of the Japan
Society of Mechanical Engineers, Series C, vol. 75, no. 760, 2009,
pp. 3244–3252, (in Japanese).
[9]
F. Feldwieser, M. Gietzelt, M. Goevercin, M. Marschollek, M. Meis,
S. Winkelbach et al., “Multimodal sensor-based fall detection within the
domestic environment of elderly people,” Zeitschrift f¨ur Gerontologie
und Geriatrie, vol. 47, no. 8, 2014, pp. 661–665.
[10]
L. Rossi, A. Belli, A. De Santis, C. Diamantini, E. Frontoni, E. Gambi
et al., “Interoperability issues among smart home technological frame-
works,” in Mechatronic and Embedded Systems and Applications
(MESA), 2014 IEEE/ASME 10th International Conference on.
IEEE,
2014, pp. 1–7.
[11]
I.-H. Bae, “An ontology-based approach to adl recognition in smart
homes,” Future Generation Computer Systems, vol. 33, 2014, pp. 32–
41.
[12]
S. Nakamura, A. Hiromori, H. Yamaguchi, T. Higashimno, Y. Yam-
aguchi, and Y. Shimoda, “Activity sensing, analysis and recommen-
dation in smarthouse,” in Multimedia, Distributed, Cooperative, and
Mobile Symposium, vol. 2014, jul 2014, pp. 1557–1566, (in Japanese).
[13]
J. Liao, L. Stankovic, and V. Stankovic, “Detecting household activity
patterns from smart meter data,” in Intelligent Environments (IE), 2014
International Conference on.
IEEE, 2014, pp. 71–78.
[14]
P. Cottone, S. Gaglio, G. L. Re, and M. Ortolani, “User activity
recognition for energy saving in smart homes,” Pervasive and Mobile
Computing, 2014.
[15]
J. Ranjan and K. Whitehouse, “Generating home energy footprint by
assigning ﬁxture usage to individuals in homes: poster abstract,” in
Proceedings of the 1st ACM Conference on Embedded Systems for
Energy-Efﬁcient Buildings.
ACM, 2014, pp. 226–227.
[16]
S. Hammer, M. Wißner, and E. Andr´e, “Trust-based decision-making
for energy-aware device management,” in User Modeling, Adaptation,
and Personalization.
Springer, 2014, pp. 326–337.
157
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-426-8
SENSORDEVICES 2015 : The Sixth International Conference on Sensor Device Technologies and Applications

