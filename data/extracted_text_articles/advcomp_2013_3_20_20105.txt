Reliable Outer Bounds for the Dual Simplex Algorithm
with Interval Right-hand Side
Christoph F¨unfzig
Fraunhofer Institute for Industrial Mathematics
Kaiserslautern, Germany
Email: c.fuenfzig@gmx.de
Dominique Michelucci, Sebti Foufou
Le2i, University of Burgundy
Dijon, France
Email: {dominique.michelucci, sebti.foufou}@u-bourgogne.fr
Abstract—In this article, we describe the reliable computation
of outer bounds for linear programming problems occuring in
linear relaxations derived from the Bernstein polynomials. The
computation uses interval arithmetic for the Gauss-Jordan pivot
steps on a simplex tableau. The resulting errors are stored as
interval right hand sides. Additionally, we show how to generate
a start basis for the linear programs of this type. We give details
of the implementation using OpenMP and comment on numerical
experiments.
Keywords-veriﬁed
simplex
algorithm;
interval
arithmetic;
tableau form; OpenMP parallelization
I. INTRODUCTION
Linear relaxation [1] is a common method to solve non-
linear systems in several variables with domains Di ⊂ R,
i = 1, . . . , N. For the system with variables x1 ∈ [0, 1] and
x2 ∈ [0, 1],
x2
1 − x2 = 0
x2 − x1 ≤ 0
a linear relaxation derived from the tangent plane in x1 =
x2 = 0.5 is
(x1 − 0.5) − (x2 − 0.5) − 0.25 ≥ 0
x2 − x1 ≤ 0
In [2], we presented linear relaxations for the monomials
x2
i and xixj, i < j with xi ∈ Di, xj ∈ Dj, which are derived
from the Bernstein polynomials on domain D. The curves
(xi, x2
i ), and the surfaces (xi, xj, xixj), i < j are enclosed
in a polytope, called Bernstein polytope (Figure 2).
With linear relaxation, a quadratic system
F(x) = 0, G(x) ≥ 0, x = (x1, . . . , xN)
gives a linear system in the variables xi, xii, and xij, i < j.
For example, a lower bound for component i can be obtained
by solving a linear program: minimize xi on the linear system
obtained with the Bernstein polytope for domain D.
In this article, we show how to use interval arithmetic in
a tableau-form implementation of the dual simplex algorithm
(Section II) to verify computations and to generate a tight
lower bound on the minimum value. The tableau has ﬂoating-
point entries and uses an interval right-hand side. In a pivot
operation of the Gauss-Jordan algorithm, rounding errors are
collected and stored in the right-hand side intervals (Section
II-B). For the application of linear relaxations using the
Bernstein polytope, we give two ways to generate a start basis
for the occurring linear programs in Section II-C. Finally, we
conclude on this work in Section IV.
A. Related Work
In an overview, there are three classes of methods for solv-
ing polynomial systems. Using computer algebra, polynomial
expressions (resultants) can be deﬁned, which are equal to
zero if and only if the polynomials have a common root. They
provide simple and effective methods for low degree problems
due to the degree of the resulting expression. Decomposing an
arbitrary polynomial in the ideal of the given polynomials is
possible with a special generator of the ideal. Such an ordered
generator (Gr¨obner basis) can be used to compute common
polynomial factors. From a computational point of view, these
methods need exact arithmetic. Recently, some articles [3]
work towards their numerical computation with tools from
interval arithmetic.
An established semi-numerical method solves a given poly-
nomial system P with the same number of equations as
variables. The method uses a continuation method [4] with
a scalar parameter t ∈ [0, 1] to deform a polynomial system
P 0 with known solutions to the given system P. Finding an
initial simple polynomial system P 0 for the given P is the
main difﬁculty of the method.
In this article, we solve quadratic polynomial systems by
branch-and-bound using a linear relaxation for the monomials.
We compute an outer bound for the optimum value of the
linear program reliably. In [2], the revised simplex code SoPlex
[5] in ﬂoating point arithmetic and a backward analysis of the
ﬁnal linear system for the objective value was used. The article
[6] gives a comparison of linear programming codes using
rational arithmetic and ﬂoating-point arithmetic. Of course,
the use of ﬂoating-point arithmetic, which is used at least in
parts of the code, is signiﬁcantly faster than exact rational
arithmetic. [7] describes how to compute a lower bound using
an arbitrary linear program solver. The authors use the weak
optimality theorem of linear programming: Any feasible point
y of the dual problem Aty ≤ c (max bty) gives a lower bound
bty for the minimum of the primal problem Ax = b, x ≥
0 (min ctx). As outlined in [7], the lower bounds obtained
from a veriﬁed, feasible point can be away from the optimum
value for ill-conditioned problems. The article [7] additionally
49
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-290-5
ADVCOMP 2013 : The Seventh International Conference on Advanced Engineering Computing and Applications in Sciences

 0
 0.2
 0.4
 0.6
 0.8
 1  0
 0.2
 0.4
 0.6
 0.8
 1
-1.5
-1
-0.5
 0
 0.5
 1
x1^2-x2
(x1-0.5)-(x2-0.5)-0.25
x1
x2
Fig. 1: Linear relaxation (dashed below) for x2
1 − x2 (solid above).
 0
 0.2
 0.4
 0.6
 0.8
 1
 0
 0.2
 0.4
 0.6
 0.8
 1
x
Bernstein polytope for x^2
B0^2(x)
B1^2(x)
B2^2(x)
 0
 0.2
 0.4
 0.6
 0.8
 1  0
 0.2
 0.4
 0.6
 0.8
 1
 0
 0.2
 0.4
 0.6
 0.8
 1
Bernstein polytope for x*y
B0^1(x)B0^1(y)
B0^1(x)B1^1(y)
B1^1(x)B0^1(y)
B1^1(x)B1^1(y)
x
y
Fig. 2: Bernstein polytope enclosing the curve (left) (x, x2): B2
0(x) ≥ 0, B2
1(x) ≥ 0, B2
2(x) ≥ 0. The surface (right)
(x, y, xy): B1
0(x)B1
0(y) ≥ 0, B1
1(x)B1
0(y) ≥ 0, B1
0(x)B1
1(y) ≥ 0, B1
1(x)B1
1(y) ≥ 0.
considers the computation of upper bounds. Concerning the
parallelization of simplex codes, [8] summarizes a number of
attempts. The authors of [9] consider the parallelization of the
sparse dual simplex code CPLEX. They make out the steepest-
edge pricing rule as a good candidate for parallelization, which
compares all infeasible rows based on the resulting change of
the dual variables.
B. Notation
We use R for the lower bound of an interval R and R
for the upper bound. median(R) denotes the median of the
interval bounds R and R computed as [0.5 (R + R)]−. For
a real number a, we denote by a− the largest ﬂoating-point
number smaller or equal to a, and by a+ the smallest ﬂoating-
point number larger or equal to a. We denote by ek the kth
vector of the canonical basis with ek,k := 1, and 0 otherwise.
As usual, an inequality between vectors, like x ≥ 0, applies
to all components i: xi ≥ 0.
II. LINEAR PROGRAMMING PROBLEM
A linear program in standard form is deﬁned by
min ctx
Ax = b
x ≥ 0
where A is a m × n real matrix, b is a m-component real
vector, and c is a n-component real vector. The system Ax = b
contains the linear equality constraints, and the function ctx
deﬁnes the linear objective function to be minimized. An
inequality at
1x ≤ b1 is transformed into an equality by a
new variable xs ≥ 0: at
1x + xs = b1, which is called a
slack variable [10]. Note that in our case it is m ≤ n, i.e.,
50
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-290-5
ADVCOMP 2013 : The Seventh International Conference on Advanced Engineering Computing and Applications in Sciences

our problem has at least as many variables as rows due to
the slack variables. There are several ways to ensure non-
negativity of variables. The ﬁrst way is to use symbolic
substitution of the problem variables ˜xi → (xi − Di) if
Di < 0 and change all equations and inequalities into problem
variables ˜xi ∈ [0, Di − Di]. This adds a linear number
of additional terms to the given problem. The second and
preferred way is to substitute all variables xi and xij locally
into ˜xi → (xi − Di) resp.
˜
xij → (xij − Di · Dj) so that
xi = ˜xi + Di resp. xij = ˜
xij + Di · Dj). Then row r changes
into 
k ark( ˜xk+Dk) = br which needs to be done only once
during tableau setup.
The tableau-form implementation of the simplex algorithm
(with column basis) selects a maximal subset of m linear
independent columns of A (corresponding to the basic vari-
ables of x), where m is the rank of the matrix A. The subset
with index set B is called a basis, and the corresponding
submatrix A∗,B is invertible; the rest matrix is denoted by
A∗,N. Non-basic variables always have a zero value. A basis
update operation maintains the reduced row-echelon form of
the tableau (xB = A−1
∗,Bb)
 ct
BxB
(cB − ct
BA−1
∗,BA∗,B)t
(cN − ct
BA−1
∗,BA∗,N)t
xB
A−1
∗,BA∗,B
A−1
∗,BA∗,N

(1)
which allows to look up the reduced costs in the ﬁrst row, the
objective function value in the ﬁrst column of the ﬁrst row, and
the basic variable values xB in the ﬁrst column below the ﬁrst
row of this tableau [10]. Furthermore, we group matrix rows
into equalities (without a slack variable) given by the index set
E and inequalities (each having a slack variable) given by the
index set I. Maintaining this form is possible with the Gauss-
Jordan algorithm from numerical linear algebra. As tableau
rows deﬁne basis variables, it is possible to check the non-
negativity constraints x ≥ 0 and to select a leaving variable in
the simplex algorithm (pricing [10]). The leaving variable is
replaced by an entering variable, which can be selected from
the reduced costs in the ﬁrst tableau row (ratio test [10]).
For applications, this dual form of the simplex algorithm is
beneﬁcial [11], which changes an infeasible basis with a sub-
minimum value into an optimum, feasible basis. It selects the
leaving variable from the infeasible basis ﬁrst and replaces
it by the entering variable. In contrast the primal form of
the simplex algorithm, selects the entering variable ﬁrst, then
selects the leaving variable until an optimum value is reached.
A. Pricing Rule and Ratio Test
Important for the performance of the solver is the pricing
rule, the ratio test, and the start basis [11]. For the pricing
rule, we consider the steepest-edge rule
Deﬁnition 1 (Goldfarb-Forrest pricing rule): Select row r
which has the most negative ratio
xr
|et
rA−1
∗,B|2 .
where d = et
rA−1
∗,BA∗,N is the change of the dual variables
per unit change of xr (see Equation 1). The values xr are
stored as right-hand sides described in the following Section
II-B, and A−1
∗B is part of the tableau.
For the ratio test, we use
Deﬁnition 2 (Harris ratio test): Select column s so that
ar,s is minimum with
cj
ar,j
≥ θr(ϵ), ar,j < 0, θr(ϵ) :=
min{ cj+ϵ
ar,j
: ar,j < 0}.
This rule chooses the element
cs
ar,s of the set { cj
ar,j ≥ θr(ϵ) :
ar,j < 0} deﬁned by a small parameter ϵ > 0. This allows to
choose the denominator ar,s < 0 with largest magnitude for
the division. Note that cj is non-negative up to rounding errors
for the dual simplex algorithm always. The ratio test traverses
the objective function row and the row r of the tableau in
parallel.
B. Pivot Steps using Interval Arithmetic
For the collection of computer arithmetic errors during a
pivot step of the Gauss-Jordan algorithm, we use interval
arithmetic. Let ar,s be the pivot element in row r, and Di
the variable domain for variable xi. Then the linear equation

j
ar,j
ar,s
xj = br
ar,s
transforms into an interval equation

j
Rr,jxj = Rr
where we can select a ﬂoating-point value ar,j ∈ Rr,j of the
interval so that Rr,j ⊂ ar,j + [(Rr,j − ar,j)−, (Rr,j − ar,j)+].
The intervals can be collected and stored as an interval right
hand side R′
r

j
ar,jxj = Rr−

j
[(Rr,j−ar,j)−, (Rr,j−ar,j)+]Dj =: R′
r
(2)
With the representative ar,j := median(Rr,j), the resulting
interval [(Rr,j − ar,j)−, (Rr,j − ar,j)+] has smallest width.
Figure 3 shows the hyperplane arrangement for an example.
Similarly, a row operation as required in the Gauss-Jordan
algorithm between row r and row i

j
(ai,j − ar,j
ai,s
ar,s
)xj = bi − br
ai,s
ar,s
can be performed in interval arithmetic

j
Ri,jxj = Ri
and rewritten using an interval right-hand side

j
ai,jxj = Ri −

j
[(Ri,j −ai,j)−, (Ri,j −ai,j)+]Dj =: R′
i
(3)
In this form, a sufﬁcient condition for the feasibility of
xi, i ∈ B is Ri ≥ Di. In case Ri < Ri, it is infeasible
and a candidate for the pricing rule. Otherwise some Ri have
smaller and larger than Di, in which case we stop the solving
process with a lower bound of the optimum value. Due to use
of interval right-hand sides, it is possible to reduce the number
of variables {xj} by replacing a variable xj with its interval
51
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-290-5
ADVCOMP 2013 : The Seventh International Conference on Advanced Engineering Computing and Applications in Sciences

Fig. 3: Hyperplane arrangement (grey) for the interval
equation [0.8, 1.2]x + [1.0, 1.0]y + [−0.5, 0.5] = 0. A thick
hyperplane results from the selection of interval
representatives 1.0x + 1.0y + [−0.7, 0.7] = 0.
Dj. In this way, an active subset of variables of the linear
program can be deﬁned.
In the geometric view of the polytope deﬁned by interval
right-hand sides, the thick hyperplanes bound a set of poly-
topes, which are not necessarily of the same topology. See
Figure 4 for an example, where the minimum-y vertex of the
outer hyperplanes is deﬁned by the intersection of r1 and r3,
but the minimum-y vertex of the inner hyperplanes is deﬁned
by the intersection of r1 and r2.
Note that these topology changes make situations possible,
where the outer polytope is non-empty but the inner polytope
is empty. In such cases, the algorithm can not decide feasibility
of the linear program.
C. Start Basis Generation
Inside the non-linear solver, we only have to handle objec-
tive functions of the form xi = et
ix for a variable index i. Start
basis generation can be done by performing the Gauss-Jordan
algorithm on the equation part AE,∗ of the system. This deﬁnes
a subset BE of the basis B. Note that the set BE depends
on the pivot selection strategy in the Gauss-Jordan algorithm
and does not need to change during pivoting in the simplex
algorithm. Also pricing rule and ratio test only consider the
inequalities I and the inequalities of the Bernstein polytope.
The ﬁrst possibility is to select only pivots with column
index different from i. In this case, where BE does not contain
variable index i, we can easily complete the basis from the
vertex with smallest value xi of the Bernstein polytope for
(xi, x2
i ). I.e., for minimization (with B(2)
i
the i-th quadratic
objective function
user equalities, n vars
u + 3c + 4d slack vars
u user inequalities, n vars
u + 3c + 4d slack vars
3c Bernstein inequalities
u + 3c + 4d slack vars
4d Bernstein inequalities
u + 3c + 4d slack vars
Fig. 5: Tableau organization with regions for the user system
and for the Bernstein polytope.
Bernstein polynomial)
(B(2)
0 (xi)
≥
0)
B(2)
1 (xi) = 2(−xii + (ui + vi)xi − uivi)
≥
0
B(2)
2 (xi) = xii − 2uixi + u2
i
≥
0
for maximization
B(2)
0 (xi) = xii + −2vixi + v2
i
≥
0
B(2)
1 (xi) = 2( −xii + (ui + vi)xi − uivi)
≥
0
(B(2)
2 (xi)
≥
0)
The second possibility is to select a pivot with column index
i. In this case, where BE contains the variable index i, we can
generate a start basis from the equation row k deﬁning variable
xi. Let xi+
j̸=i ak,jxj = Rk be row k. If there are columns
ak,j > 0 the current basis part BE is not optimum, and it can
be changed by primal steps into an optimum basis. I.e., for
each such column j with ak,j > 0 we determine a row r such
that ar,0 ≥ 0 and −ar,0
ak,j
ar,j < 0 is minimum. Both strategies
are compared in Section III based on a numerical example.
III. IMPLEMENTATION AND NUMERICAL EXPERIMENTS
We implemented the dual simplex algorithm in C/C++ using
the tableau organization shown in Figure 5. The tableau can be
stored as an m×n array of double-entries or in a sparse form
as an array of m rows of index/entry pairs. The right-hand side
vector is represented using the boost interval arithmetic library.
We additionally keep a basis description consisting of arrays,
var giving the index of the deﬁning row for a variable index,
and row giving the index of the variable deﬁned in a row. Both
are inverse to each other: row[var[j]] = j for variable index
j and var[row[i]] = i for row index i. We have one pivot
operation
1
ar,s Ar,∗ for the pivot row r, and m row operations
Ai,∗ + fiAr,∗ for all other rows i̸=r. The m different row
operations can be done in parallel using OpenMP. We use
the basis description to exclude basis columns, which are unit
vectors and therefore contain a zero value in the pivot row r.
Altogether, the number of multiplications and additions for a
row operation ranges from n−m to n. Note that in the interval
version (Equations 2 and 3), the pivoting and row operations
are not entrywise as in [12] but require a reduction operation
for the right-hand side interval. We avoid a parallel reduction
by storing the right-hand side updates [(Ri,j − ai,j)−, (Ri,j −
ai,j)+]Dj in an array and perform the summation sequentially.
Similarly, we perform the loop for the steepest edge pricing
rule and the loop for the ratio test in parallel using OpenMP
but without a critical section for the minimization.
52
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-290-5
ADVCOMP 2013 : The Seventh International Conference on Advanced Engineering Computing and Applications in Sciences

Fig. 4: Polytope bounded by thick hyperplanes r1, r2, r3 and r4. Note that the topology of the polytope built by the outer
hyperplanes (thick) is not the same as the one by the inner hyperplanes (thin).
In the following, we demonstrate the different strategies for
start basis generation on the example system mixed.sys:
0.5x1 = x2x3
0.5x2 = x1x3
0.5x3 = x1x2
on D1 = D2 = D3 = [−1, 1]. The basis variables are marked
with a box around them. When pivoting with x23, x13, x12,
the system is in reduced row-echelon form
0.5x1 = x23
0.5x2 = x13
0.5x3 = x12
and can be completed with two inequalities of the Bernstein
polytope for xii, i = 1, 2, 3 into a start basis. Figure 6, left,
shows a statistics of the interval width of the objective value
in the course of pivoting. The computation as described in [2]
performs one reduction of each variable before bisecting the
largest interval. For this problem (tableau size m = 19 × n =
33) on D1 = D2 = D3 = [−1, 1], it needs 47 reductions (410
pivot steps in total), 10 bisections, and the solution time is
0.30s using the sparse form (Windows 7/Visual Studio 2008,
Intel Pentium P8700, Dual Core 2.53GHz). The same solving
using the dense form takes 0.82s and produces different error
widths. The largest condition number of the tableau is 2.0.
When pivoting with x1, x13, x12, the system is in reduced
row-echelon form
0.5 x1 = x23
0.5x2 = x13
0.5x3 = x12
and can be completed with three inequalities of the Bernstein
polytope x23 into a start basis. Note that the reduced row-
echelon form for variables x2 and x3 is similar and thus
omitted here. Figure 6, right, shows a statistics of the interval
width of the objective value in the course of the pivot steps.
For this problem, the computation performs 47 reductions (275
pivot steps in total), 10 bisections, and the solution time is
0.32s. The same solving using the dense form takes 0.72s. The
worst condition number of the tableau is 846.3, and it results in
larger objective value intervals, i.e., worse lower bounds. In the
comparison, the second start basis results in less pivot steps in
the dual simplex iteration. Tableaus of larger condition number
normally occur if very small pivots were chosen. This can
be necessary for Bernstein inequalities corresponding to very
small intervals Di. It is possible to replace such a Bernstein
polytope by a thick plane or a thick line as described in [2].
In general, the tableau method tends to populate rows
quickly. On the system mixed.sys, the user and Bernstein
region of the tableau get ﬁlled approximately 60% to 80%.
For comparison with the revised simplex implementation
SoPlex, we compute a rigorous lower bound bty + e using the
duality gap
e = min{(ct − y∗ tA)x : x ∈ D}
The primal solution vector x∗ is directly available, and the
corresponding dual solution vector y∗ can be derived from the
constraint slackness at x∗. When solving the system mixed.sys,
the code performs around 500 pivot steps, which are fast due
to the revised simplex implementation. But large duality gap
sizes (larger than 10−10) occur for linear programs, where no
bound reduction could be achieved due to an early termination
in SoPlex.
53
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-290-5
ADVCOMP 2013 : The Seventh International Conference on Advanced Engineering Computing and Applications in Sciences

 1e-020
 1e-018
 1e-016
 1e-014
 1e-012
 1e-010
 50
 100
 150
 200
 250
 300
 350
 400
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
error
pivots
min/max x, mixed.sys
Interval width
Num pivots (min)
Num pivots (max)
 1e-020
 1e-018
 1e-016
 1e-014
 1e-012
 1e-010
 50
 100
 150
 200
 250
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
error
pivots
min/max x, mixed.sys
Interval width
Num pivots (min)
Num pivots (max)
Fig. 6: System mixed.sys with start basis from Bernstein polytope for xii (left) and from the equation system itself (right).
Errors are derived from the interval width of the objective value.
IV. CONCLUSION
In this paper, we presented a new way to implement the
dual simplex algorithm in tableau form with pivot steps using
interval arithmetic for the direct computation of a reliable
lower bound. Such an algorithm can be used for example in a
polynomial system solver using linear relaxations. Compared
to a lower bound computed from the duality gap, it is not
so much affected by the condition number of the given linear
program and an early termination of the simplex code. But due
to the use of the tableau form it performs more ﬂoating-point
operations than a revised simplex implementation (e.g., SoPlex
[5]) for a sparse input system due to the gradual increase of
non-zeros during pivot steps.
The computation is based on the Gauss-Jordan algorithm
and performs pivot steps in interval arithmetic that are par-
allelizable with OpenMP. We always avoid critical sections
for reduction operations. In the steepest edge pricing rule and
the ratio test, a suboptimal choice does not produce wrong
results and we could not observe any performance degradation.
For tableau storage, we choose row major order, which avoids
recomputing the row factors for a row operation. We prefer
sparse storage (as rows of index/entry pairs) over dense (as
an array). To avoid further ﬁll-in, we make use of a separate
basis description so that the locations of unit vectors in the
tableau are known.
For large systems, it is possible to work with an active set
of variables {xj} and replace all others with their interval Dj,
which is a major beneﬁt of using an interval right-hand side.
But with such wide intervals the topology changes, outlined
in Figure 4, need to be handled.
ACKNOWLEDGEMENTS
This research work has been funded by NPRP grant number
NPRP 09-906-1-137 from the Qatar National Research Fund
(a member of The Qatar Foundation).
REFERENCES
[1] R. Kearfott, “Discussion and empirical comparisons of linear relaxations
and alternate techniques in validated deterministic global optimization,”
Optimization Methods and Software, vol. 21, no. 5, 2006, pp. 715–731.
[2] Ch. F¨unfzig, D. Michelucci, S. Foufou, “Nonlinear systems solver in
ﬂoating-point arithmetic using LP reduction,” in ACM/SIAM Symposium
on Solid and Physical Modeling, 2009, pp. 123–134.
[3] M. Bodrato, A. Zanoni, “Intervals, syzygies, numerical Gr¨obner bases :
A mixed study,” in CASC 2006 Proceedings, V. G. Ganza, E. W. Mayer,
and E. V. Vorozhtsov, Eds., vol. 4194.
LNCS, Springer, September
2006, pp. 64–76.
[4] J. Verschelde, “Polynomial homotopy continuation with PHCpack,”
ACM Communications in Computer Algebra, vol. 44, no. 4, 2010, pp.
217–220.
[5] R. Wunderling, “SoPlex library version 1.4.2,” 1996.
[6] C. Keil, “A comparison of software packages for veriﬁed linear program-
ming,” Preprint Institute of Reliable Computing, Hamburg University of
Technology, 2008.
[7] ——, “Lurupa – rigorous error bounds in linear programming,” in
Algebraic and Numerical Algorithms and Computer-assisted Proofs,
Dagstuhl
Seminar
Proceedings
(Number
05391),
B.
Buchberger,
S. Oishi, M. Plum, and S. Rump, Eds., July 2006.
[8] J. Hall, “Towards a practical parallelisation of the simplex method,”
Computational Management Science, vol. 7, no. 2, 2010, pp. 139–170.
[9] R. E. Bixby, A. Martin, “Parallelizing the dual simplex method,”
INFORMS Journal on Computing, vol. 12, no. 1, Jan. 2000, pp. 45–
56.
[10] C. Papadimitriou, K. Steiglitz, Combinatorial optimization: Algorithms
and Complexity.
Dover, 1998.
[11] R. Bixby, “Solving linear and integer programs,” in Block Course
Combinatorial Optimization at Work, Berlin, M. Gr¨otschel, Ed., 2009.
[12] S. F. McGinn, R. E. Shaw, “Parallel Gaussian Elimination using
OpenMP and MPI,” in 16th Annual Int. Symp. on High Performance
Computing Systems and Applications, Moncton, Canada, June 2002, pp.
169–176.
54
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-290-5
ADVCOMP 2013 : The Seventh International Conference on Advanced Engineering Computing and Applications in Sciences

