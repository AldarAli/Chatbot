A Color Constancy Model for Non-uniform Illumination 
based on Correlation matrix 
 
Takashi Toriu 
Graduate School of 
Engineering 
Osaka City University 
 Osaka, Japan 
e-mail: toriu@ 
info.eng.osaka-cu.ac.jp 
Mikiya Hironaga 
School of Science and 
Engineering 
Kinki University 
Osaka, Japan 
e-mail: mhironaga@ 
info.kindai.ac.jp  
 
Hiroshi Kamada 
Graduate School of 
Engineering 
Kanazawa Institute of 
Technology 
Ishikawa, Japan 
e-mail: kamada@ 
neptune.kanazawa-it.ac.jp 
Thi Thi Zin 
Faculty of Engineering 
University of Miyazaki 
Miyazaki, Japan 
e-mail: thithi@ 
cc.miyazaki-u.ac.jp
 
 
Abstract—In this paper, we propose a novel color constancy 
model that works well even if illumination is not uniformly 
distributed. For this purpose, we introduce the positionally 
modified color correlation matrix. The color correlation matrix 
is a matrix that represents how different colors are correlated 
with one another. More concretely, the color correlation 
matrix is obtained as the spatial average of the product of two 
colors as <IiIj>, and consequently, it is independent of position 
parameters. In addition to this correlation matrix, we define 
two position dependent correlation matrices as <xIiIj> and 
<yIiIj>. We assume that the eigenvector of the correlation 
matrix corresponding to the largest eigenvalue presents the 
color gray when the illumination is parallel and white. Under 
this assumption, we can estimate the image when the 
illumination is parallel and white. The effectiveness of the 
proposed method is confirmed by simulation experiments 
using synthesized images and real images. 
Keywords-Color constancy; correlation matrix; non-uniform 
illumination; gray-world assumption; correlation between 
brightness and color. 
I. 
 INTRODUCTION 
Color constancy is one of miracle abilities in human 
vision. Object colors are correctly perceived independent of 
the illumination color. This ability is called color constancy 
[1]. In the field of computer vision, color recognition is an 
important and basic task. In fact, color recognition has been 
used as preprocessing for various problems such as robot 
vision, object recognition, human behavior recognition, 
human interface and so on. For example, Kamada et al. [2] 
proposed a system that can count students’ raising the color 
cards to accelerate communication between a teacher and 
many students in a classroom. In this system, it is very 
important to achieve accurate color recognition. 
Several methods have been proposed for color constancy. 
Among these methods, the ones based on Gray-world 
assumption have been popular and they are considered the 
basis of arguing color constancy [3]-[6]. Gray-world 
assumption states that the average of the colors of the objects 
in the scene is gray, and the influence of the illumination is 
eliminated based on this assumption. This method would 
work well when sufficient colors exist in the scene. As an 
extension, a method based on local averaging was proposed 
by Gijsenij et al. [7]. Further, other methods have been 
proposed using image statistics such as correlation between 
the brightness and color [8]-[12]. Golz et al. [8] discussed 
human color constancy based on the correlation between 
luminance and redness and concluded that redness of the 
illumination could be correctly estimated using the mean 
redness of the image and the correlation between luminance 
and redness of the image. Inspired by the paper [8], we 
developed a computational method to estimate illumination 
color by replacing human eyes with a camera [11]. 
Previously [13], we proposed another method based on 
“Minimum Brightness Variance Assumption”, in which it is 
assumed that variance of brightness is minimum when the 
illumination is white. 
In another previous work [14], we proposed a color 
constancy model based on the color correlation matrix. More 
concretely, we proposed two methods for color constancy. 
Both are based on the correlation matrix on the three-
dimensional space of colors, red, green and blue. In the first 
method, the eigenvector corresponding to the largest 
eigenvalue is assumed to be a good estimate of the 
illumination color. In the second method, it is assumed that 
the eigenvector corresponding to the largest eigenvalue 
presents the color gray when the illumination is white. The 
image under white illumination is predicted so as to satisfy 
the condition that the eigenvector corresponding to the 
largest eigenvalue presents the color gray.  
In these methods, we assumed that illumination is 
parallel, and therefore it is uniform against position variation. 
In this paper, we extend the previous method so that it works 
well for non-uniform illumination. For this purpose, we 
introduce the positionally modified color correlation matrix. 
The effectiveness of the proposed method is confirmed by 
simulation experiments using synthesized images and real 
images. 
40
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

This paper is organized as follows. In Section II, we 
outline of the previous method in which illumination is 
assumed to be parallel and be uniformly distributed spatially. 
In Section III, we extend this method in the case for non-
uniform illumination. In Section IV, we show the 
experimental results which reveal the effectiveness of the 
proposed method.  
II. 
OUTLINE OF THE PREVIOUS METHOD 
Let 
1
e , 
2
e and 
3
e  be three unit vectors representing 
color orientations of red, green and blue in the three-
dimensional 
color 
space. 
Then, 
the 
unit 
vector 
(
3 )
2
1
( )
3
1
e
e
e
e
+
+
L =
 represents the orientation of the 
white color. It is represented as 
(
)t
L
3 ,1 ,1 1
1
( )
=
e
 in 
terms of components. Let 
1( , )
x y
I
, 
2 ( , )
x y
I
 and 
3( , )
x y
I
 
be the color components red, green and blue of the input 
image at the point 
( , )
x y
 , respectively. This image can be 
represented as 
 
3
3
2
2
1
1
( , )
( , )
( , )
( , )
e
e
e
I
x y
I
x y
I
x y
I
x y
+
+
=
, 
(1) 
in the three dimensional color space. We represent it simply 
as 
x y t
x y I
x y I
I
x y
( , ))
( , ),
( , ),
(
( , )
3
2
1
=
I
. Then, 3 x 3 color 
correlation matrix K is defined  as 
 
∫
∫
>=
=<
−
−
/2
1
/2
1
/2
1
1/2
( , )
( , )
x y dxdy
x y I
I
I I
K
j
i
j
i
ij
. 
(2) 
where 
>
<
IiI j
 is the spatial average of 
( , )
( , )
x y
x y I
I
j
i
. 
We assume that the image is defined in the rectangle  area of 
1/ 2
,
1/ 2
≤
≤
−
x y
. 
Let 
x y t
x y S
x y S
S
x y
( , ))
( , ),
( , ),
(
( , )
3
2
1
=
S
be object color 
and let 
t
E
E E
)
,
,
(
3
2
1
E =
 be illumination color. We assume 
that illumination is parallel, and therefore it is uniform 
against 
position 
variation. 
Then, 
the 
 
image 
x y t
x y I
x y I
I
x y
( , ))
( , ),
( , ),
(
( , )
3
2
1
=
I
is determined as  
 
( , )
( , )
x y
E S
x y
I
i i
i
=
. 
(3) 
We call it the image generation formula. From (2) the color 
correlation matrix K  is obtained as  
 
>
<
>=
=<
j
i
j
i
j
i
ij
S S
E E
I I
K
. 
(4) 
Using 
this 
relation, 
the 
illumination 
color 
t
E
E E
)
,
,
(
3
2
1
E =
is determined so that the eigenvector 
corresponding to the largest eigenvalue of 
>
<
SiS j
is 
parallel to
(
)t
l
3 1 1 1
e = 1
 for the given 
>
=<
j
i
ij
I I
K
. 
Once E  is determined, the image under white illumination is 
estimated as 
 
i
i
i
E
x y
cI
x y
I
/)
( ,
ˆ ( , )
=
, 
(5) 
where c  is a factor which is determined to keep the 
brightness invariant. In other words, 
, )
(ˆ
I x y
 is considered to 
be an estimate of the object color 
( , )
S x y
. In practice, 
, )
(ˆ
I x y
is obtained as follows. 
First, let 
x y t
x y I
x y I
I
x y
( ˆ ( , ), ˆ ( , ), ˆ ( , ))
, )
(ˆ
3
2
1
=
I
 be the 
color components of the image to be estimated and let K~  be 
the correlation matrix of these. K~  is obtained as 
 
∑
=
y
x
t
x y
x y
N
K
,
( , )
ˆ)
,
(ˆ
1
ˆ
I
I
. 
(6) 
Since we assume that the eigenvector of K~ corresponding to 
the largest eigenvalue is parallel to the orientation of color 
gray, 
, )
(ˆ
I x y
 is estimated so that 
(
)t
l
1
1
3 1
e = 1
 is the 
eigenvector of Kˆ  with the largest eigenvalue. More 
specifically, 
, )
(ˆ
I x y
 is obtained by the following procedure. 
First, as an initialization, we set 
 
( , )
, )
(ˆ
x y
x y
I
I
=
, 
(7) 
where 
( , )
I x y
 is the input image. Second, calculate K~  
according to the equation (6), and obtain the eigenvector u  
of K~  with the largest eigenvalue. Then, update 
, )
(ˆ
I x y
 
according to 
 
ˆ ( , )
2
1
ˆ ( , )
x y
I
u
u
x y
I
i
i
i
i
+
←
α β
, 
(8) 
where α  is determined to keep the brightness invariant, and 
β  is a factor to modulate the speed of the image change. 
The larger β  is, the smaller the image change is. The above 
procedure should be terminated when the amount of image 
change according to (8) is less than a pre-determined value. 
The amount of image change is evaluated by the root-mean-
square error (RMSE).  
III. 
PROPSED METHOD 
In the method outlined in the last section, the illumination 
is assumed to be parallel implicitly. Therefore it is uniform 
against position variation. In this section, we extend it in the 
case for non-uniform illumination. More specifically, we 
assume that position dependence of the illumination is linear 
and is represented as 
 
)
1(
( , )
y
x
F
x y
E
yi
xi
i
i
ε
ε
+
+
=
. 
(9) 
41
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

Then, (3) is modified as 
 
( , )
)
1(
( , )
x y
y S
x
F
x y
I
i
yi
xi
i
i
ε
ε
+
+
=
. 
(10) 
and correspondingly the correlation matrix becomes 
,
)
12
1
12
1
1(
)
(
)
1(
)
1(
2
2
>
<
+
+
=
>
<
> +
<
+
>
<
=
>
+
+
+
+
<
=
>=
=<
j
i
y j
yi
x j
ix
j
i
j
i
yi
yi
j
i
x j
ix
j
i
j
i
j
i
y j
x j
j
i
yi
ix
j
i
j
i
ij
S S
F
F
y S S
x S S
F
F
S S
F
F
y
x
y S S
x
F
F
I I
K
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
 (11) 
where we assume that the image is defined in the rectangle  
area of 
1/ 2
,
1/ 2
≤
≤
−
x y
 and that 
 
.
12
1
,
12
1
,0
,0
,0
2
2
>
<
>=
> <
<
>=
<
>=
<
>=
<
>=
<
i
i
i
i
i
i
i
i
i
i
i
i
i
i
S S
y S S
S S
S S
x
xyS S
yS S
S
xS
 (12) 
Here, we introduce the positionally modified color 
correlation matrix as 
 
>
<
+
=
>
<
+
=
>
+
+
+
+
<
=
>
=<
j
i
x j
ix
j
i
j
i
x j
ix
j
i
y j
x j
j
i
yi
ix
j
i
i i
ij
x
S S
F
F
x S S
F
F
y
x
y S S
x
x
F
F
xI I
K
)
(
12
1
)
(
)
1(
)
1(
2
ε
ε
ε
ε
ε
ε
ε
ε
 (13) 
and 
 
>
<
+
=
>
<
+
=
>
+
+
+
+
<
=
>
=<
j
i
y j
iy
j
i
j
i
y j
iy
j
i
y j
x j
j
i
iy
ix
j
i
i i
ij
y
S S
F
F
y S S
F
F
y
x
y S S
x
y
F
F
yI I
K
)
(
12
1
)
(
)
1(
)
1(
2
ε
ε
ε
ε
ε
ε
ε
ε
 (14) 
From (11), (13) and (14) we obtain a system of equations 
for 
iε x
and 
iε y
 as follows. 
 
.
12
,
12
+
+
+
=
+
+
+
=
y j
yi
x j
ix
y j
i
y
ij
ij
y
y j
yi
x j
ix
x j
ix
ij
ij
x
K
K
K
K
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
ε
 
(15) 
This system of equations has 12 equations against 6 
unknown parameters 
iε x
and 
iε y
. Among them we use only 
i = j
 case (6 equations) for simplicity. Then, (15) becomes 
 
,
12
2
,
12
2
2
2
2
2
+
+
=
+
+
=
yi
i
x
i
y
i
y
yi
i
x
xi
i
x
T
T
ε
ε
ε
ε
ε
ε
 
(16) 
where 
ii
xii
xi
K
K
T
/
=
 and 
ii
yii
yi
K
K
T
/
=
. This system of 
six equations can be solved easily and we obtain 
 
.
)
1 12(
1
,
)
1 12(
1
2
2
2
2
2
2
2
2
yi
i
x
yi
xi
i
y
i
y
yi
i
x
yi
xi
i
x
i
x
T
T
T
T
T
T
T
T
T
T
+




+
−
−
=
+




+
−
−
=
ε
ε
 
(17) 
As is described in (9), illumination is determined by 
parameters 
iF , 
iε x
and 
iε y
. The remained problem is to 
obtain 
iF . For this purpose, we notice that (10) can be 
rewritten as 
 
( , )
1
( , )
x y
F S
y
x
x y
I
i
i
yi
i
x
i
=
+
+
ε
ε
. 
(18) 
If we set  
 
y
x
x y
I
x y
I
yi
i
x
i
i
ε
ε
+
= 1+
( , )
~ ( , )
. 
(19) 
Equation (18) becomes  
 
( , )
~ ( , )
x y
F S
x y
I
i
i
i
=
. 
(20) 
This equation has the same form as (3), which represents 
the image generation formula for the case when illumination 
is uniform. In view of this, the constant factor 
42
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

t
F
F F
)
,
,
(
3
2
1
F =
of the illumination color is determined so 
that the eigenvector corresponding to the largest eigenvalue 
of 
>
<
SiS j
is parallel to
(
)t
l
3 1 1 1
e = 1
 for the given 
>
=<
j
i
ij
I I
K
~ ~
~
.  
The algorithm of the proposed method is summarized as 
follows.  
Step 1: Calculate the correlation matrixes as 
∫
∫
>=
=<
−
−
/2
1
/2
1
/2
1
1/2
( , )
( , )
x y dxdy
x y I
I
I I
K
j
i
i i
ij
, 
∫
∫
>=
=<
−
−
/2
1
/2
1
/2
1
1/2
( , )
( , )
x y dxdy
x y I
xI
xI I
K
j
i
i i
xij
 
and 
∫
∫
>=
=<
−
−
/2
1
/2
1
/2
1
1/2
( , )
( , )
x y dxdy
x y I
xI
yI I
K
j
i
i i
yij
. 
Step 2: Set  
ii
xii
xi
K
K
T
/
=
 
 and  
ii
yii
yi
K
K
T
/
=
. 
Step 3: Get  
(
2 )
2
2
2
)
1 12(
1
yi
xi
yi
xi
xi
xi
T
T
T
T
T
+




+
−
−
=
ε
 
and  
(
2 )
2
2
2
)
1 12(
1
yi
xi
yi
xi
yi
yi
T
T
T
T
T
+




+
−
−
=
ε
. 
Step 4:Calculate the modified correlation matrix as 
∫
∫
+
+
+
+
=
>
=<
−
−
/2
1
/2
1
/2
1
1/2
)
)(1
1(
( , )
, )
(
~ ~
~
y dxdy
x
y
x
x y
x y I
I
I I
K
y j
x j
yi
i
x
j
i
i i
ij
ε
ε
ε
ε
. 
Step 5: Find 
t
F
F F
)
,
,
(
3
2
1
F =
 such that the eigenvector 
corresponding to the largest eigenvalue of the matrix 
1
1 ~
−
−
j
ij
i
K F
F
is parallel to
(
)t
l
3 1 1 1
e = 1
   
Step 6: Obtain the image under white illumination as 
i
i
i
G
x y
Ic
x y
I
/)
~ ( ,
ˆ ( , )
=
, 
where c  is a factor which is determined to keep the 
brightness invariant. 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Examples of images: (a ) an object color, (b) an input image, (c) a result by the Gray-world based method, (d) a result by the previous correlation 
based method and (e) a result by the proposed method. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. Root-mean-square error between the ideal image and the estimated image in the experiments using synthesized images. 
               (a)                                        (b)                                (c)                                    (d)                                    (e) 
43
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

IV. 
EXPERIMENTS 
We conducted two types of simulation experiments to 
confirm the effectiveness of the proposed methods. In the 
first experiments we synthesized images with 512 × 512 size 
which represents the object color. The image has 8 × 8 = 64 
blocks, and in each block the object colors are specified by 
1( , )
x y
S
, 
2( , )
x y
S
 and 
3( , )
x y
S
, which are determined at 
random and uniformly distributed from 0.0 to 1.0. In this 
manner, we prepared 100 samples of images representing 
object colors for each illumination condition mentioned 
below.  
 
Figure 3.Input images under common room lighting. 
 
An example of synthesized image is shown in Figure 1 
(a).Next, we set 
1
F , 
2
F and 
3
F  to be 0.4, 0.7, 1.0 
respectively as the constant factor of the color component 
red, green and blue (see equation (9)). Further, we set  
.0 95
,
.0 05,
,0.0
20
2
1
=
=
=
ρ
ρ
ρ

, which represent the 
magnitude of 
yi
xi
e
e
+
. Each 
exi
and 
eyi
is determined 
randomly as follows. First, 
exi
 is determined at random and 
uniformly distributed from 0.0 to 
ρm
 
19)
,2,1
(

m =
. Then, 
eyi
 is determined as 
xi
m
yi
e
e
−
= ρ
. In consideration of 
origin symmetry, we restricted 
exi
 and 
eyi
 to be zero or 
positive without loss of generality. The parameter 
ρm
 is 
considered to represent the amount of non-uniformity. Thus 
20 kind illumination conditions are defined according to (9). 
Then, we generate 100 input images for each non-uniformity 
parameter according to (10) using randomly synthesized 100 
sets of object colors 
1( , )
x y
S
, 
2( , )
x y
S
 and 
3( , )
x y
S
. In this 
way, we got 2000 (100 x 20) input images. An example of 
input 
image 
is 
shown 
in 
Figure 
1 
(b), 
where 
)
3,2,1
( =
+
i
e
e
yi
xi
 are set to be 0.95.For these 2,000 
images, we estimated images under white illumination based 
on the proposed method. We also estimated the images using 
the Gray-world based method and the previously proposed 
correlation based method for comparison. In Figure 2, the 
RMSE between the ideal image and the estimated images by 
the three methods are shown. Examples of estimated images 
by the three methods are shown in Figure 1 (c), (d) and (e). 
As can be seen in Figure 2, the proposed method has its own 
superiority when illumination non-uniformity is large. 
Inversely, when illumination is uniform, the previous method 
has rather better results.   
 Next, we conducted experiments using 9 groups of real 
images. Each group has 4 images, with one image taken 
under common room lighting. These are shown in Figure 3. 
The other three images in each group are taken under such 
illumination condition in which colored lamps (red, green 
and blue) are set from the upper right direction in addition to 
the common illumination. Figure 4 (a) shows an example of 
the input image under common room lighting. Figure 4 (b), 
(c) and (d) are examples of images taken under illumination 
condition where each of red, green and blue lamp is set.  
 
 
Figure 4. Examples of input images (a) – (d) and estimated images (e)- (j). 
(a) Common illumination is added. (b) Red illumination is added. (c) Green 
illumination  is added. (d) Blue illumination is added. (e), (g) and (i) show 
the results for the case when the input image is (a). (f), (h) and (j) show the 
results in the case when the input image is (d)  
 
 
 
 
 
im1 
 
 
 
 
im2 
 
 
 
 
im3 
 
 
 
 
im4 
 
 
 
 
im5 
 
 
 
 
im6 
 
 
 
 
im7 
 
 
 
 
im8 
 
 
 
 
im9 
 
(a) 
 
(b) 
 
(c) 
 
(d) 
 
(e) 
 
(f) 
 
(g) 
 
(h) 
 
(i) 
 
(j) 
44
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

Figure 5. Average RMSE between the estimated image under common 
illumination and the estimated image under colored illumination. 
Figure 6. Another example of input images (left hand), and the result by the 
proposed method  (right hand). 
Figure 7. Average RMSE between two the estimated image under common 
illumination and the estimated image estimated under colored illumination. 
 
Using these images, we conducted experiments to 
confirm the effectiveness of the proposed method. We 
compared three methods, Gray-world based method, the 
previously proposed correlation based method and the 
method proposed in this paper. To evaluate the effectiveness 
of each method, we calculate the RMSE between two 
estimated images. One is the image estimated from the 
image taken under common illumination. The other is the 
image estimated from the image taken under colored 
illumination. RMSEs for three illumination conditions are 
averaged. The results are summarized in Figure 5. As can be 
seen, proposed methods have smaller RMSE. It means that 
the proposed method is effective as a kind of a normalization 
tool of images to reduce image changes due to illumination 
changes. This method is not necessarily just a tool to obtain 
the image under white illumination. More specifically, the 
amount of change between two estimated images is less than 
the amount of change between the corresponding two input 
images with different illumination condition.  
Figure 4 (e) – (j) shows examples of the estimated images. 
Among them (e), (g) and (i) show the results for the case 
when the input image is (a), the image taken under common 
room lighting. On the other hand, (f), (h) and (j) show the 
results in the case when the input image is (d), the image 
taken under blue illumination. The pairs (e)-(f), (g)-(h) and 
(i)-(j) correspond to the Gray-world based method, the 
previous correlation based method and the proposed method. 
Figure 5 shows average RMSE between two estimated 
images. One is the image estimated from the image taken 
under common illumination. The other is the image 
estimated from the image taken under colored illumination. 
RMSEs for three illumination conditions are averaged. From 
this figure, we can see that the RMSE between the image (i) 
and (j), which is in the proposed method, is about o.o4, 
which is significantly less than in the Gray-world based 
method and in the previous correlation based method. 
 
 
Figure 8 Sample images. (a) Original images. (b) Results by Gray-world 
based method. (c) Results by the  previous  method.  (d) Results by the 
proposed method. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(a) 
(b) 
(c) 
(d) 
45
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

 
 
 
 
 
 
 
 
 
 
 
 
Figure 9 Mean standard deviation of pixel values. 
 
We are planning to apply the proposed method to the 
system that can count students’ raising the color cards to 
accelerate communication between a teacher and many 
students in a classroom [2]. An example of the color cards is 
shown in Figure 6 (a). The upper left part of the image is 
brighter than other parts. Figure 6 (b) is the result of the 
proposed method. Non-uniformity of the lighting effect is 
reduced. We prepared 4 groups of images like Figure 6 (a). 
Each group has 4 images with different illumination 
condition. One is taken under a common lighting, and the 
other three are taken under the common lighting added by 
another lamp with different strength. We evaluated the 
effectiveness of the proposed method in the same way as 
mentioned before, and we obtained the result shown in 
Figure 7. The proposed method has the lower RMSE. Figure 
6 (a) is an image included in the group Im3.  
We 
conducted 
other 
experiments 
to 
evaluate 
effectiveness of the proposed method in the case when 
illumination changes with setting of the sun. Figure 8 (a) 
shows 8 samples of original images taken in setting of the 
sun. We can see changes in these images caused by 
illumination change. These changes were eliminated by three 
color constancy models; the gray-world based method, the 
previous method and the proposed method. The results are 
shown in Figure 8 (a), (b) and (c). We calculated the 
standard deviation of pixel values over 8 images shown in 
Figure 8 (a), (b) and (c). Figure 9 shows the mean standard 
deviation. If this value is small, it means that effect of 
illumination change is effectively eliminated. From this 
figure, we can conclude that the proposed method is more 
effective than other two methods. 
V. 
CONCLUSION 
We extended the previous method [14] based on the color 
correlation matrix 
>
=<
j
i
ij
I I
K
so that it works well for 
non-uniform illumination. In the proposed method, we 
introduce the modified correlation matrix. 
>
=<
j
i
xij
xI I
K
 
and 
>
=<
j
i
xij
xI I
K
 to reduce the non-uniformity in the 
illumination. We conducted simulation experiments using 
synthesized image and confirmed that the proposed method 
has its own superiority when non-uniformity of the 
illumination is large. Inversely, when the illumination is 
uniform, the previous method has rather better results. We 
also confirmed that the proposed method is effective for real 
images too. In future work, we will address the problem that 
the proposed method does not have better result compared to 
the previous method when the illumination is uniform. 
REFERENCES 
[1] D. H .Foster, “Color constancy”, Vision Research, 51, 2011, 
pp.674-700. 
[2] H. Kamada and K. Masuda, “A Feasibility Study of 
Automatic Response Analyzer in Classroom Using Image 
Processing and Cards”, ICIC Express Letters, Part B, Vol.6, 
No.4, 2015, pp.919-926. 
[3] M.D’Zmura and P. Lennie “Mechanisms of color constancy”, 
J. Opt. Soc. Am.A, Vol.3, No.10, Oct. 1986, pp.1662-1672.  
[4] K. Barnard, V. Cardei and B. Funt “A comparison of 
computational 
color 
constancy 
algorithms. 
Part 
I: 
Methodology and experiments with synthesized data”, IEEE 
Trans. IP, 11, No.9, 2002, pp.972 -984. 
[5] H. 
Kawamura, 
K. 
Fukushima 
and 
N. 
Sonehara, 
“Mathematical conditions for estimating illumination color 
based on gray world assumption”, Proc. of the Society 
Conference of IEICE, 167, 1995. 
[6] F. Ciurea and B. Funt, “A Large Image Database for Color 
Constancy Research”, IS&T/SID Eleventh Color Imaging 
Conference, 2003. 
[7] A. Gijsenij and T. Gevers, ”Color Constancy by Local 
Averaging”, 14th International Conference of Image Analysis 
and Processing – Workshops, 2007. 
[8] M. 
Golz, 
”Influence 
of 
scene 
statistics 
on 
color 
constancy,”Nature, 415, 2002, pp.637–640. 
[9] J. Golz., “The role of chromatic scene statistics in color 
constancy: Spatial integration”, Journal of Vision, 8(13):6, 
2008, pp.1–16. 
[10] K. Barnard, L. Martin and B. Funt, “Colour by correlation in a 
three dimensional colour space”, Proc. of the Sixth European 
Conf. on Comp. Vis., 2000, pp.275–289. 
[11] T. Yoshida, M. Hironaga and T.Toriu, “Estimating and 
Eliminating a Biased Illumination with the Correlation 
between Luminance and Colors”, ICIC Express Letters,  
Vol..7, No.5, 2013, pp.1687-1692. 
[12] J. J. M. Granzier, E. Brenner, F. W. Cornelissen and J. B. J. 
Smeets ,“Luminance color correlation is not used to estimate 
the color of the illumination”, Journal of Vision, 5, 2005, 
pp.20–27. 
[13] N. Hasebe, M. Hironaga and T. Toriu, “A Color Constancy 
Model with Minimum Brightness Variance Assumption, 
ICIVC 2014. 
[14] T. Toriu, M. Hironaga and N. Hasebe, “Two methods for 
color constancy based on color correlation matrix”, ICGEC 
2015, submitted. 
 
 
(b) 
(c) 
(d) 
46
Copyright (c) IARIA, 2015.     ISBN:  978-1-61208-432-9
ICCGI 2015 : The Tenth International Multi-Conference on Computing in the Global Information Technology

