An Integrated EO-based Toolbox for Modernising CAP Area-based Compliance 
Checks and Assessing Respective Environmental Impact
                           Orestis Sampson, Nikos Iliakis, Valantis Tsiakos, Maria Krommyda, Angelos Amditis 
Institute of Communication and Computer Systems 
Athens, Greece 
emails: {orestis.sampson, nikos.iliakis, valantis.tsiakos, maria.krommyda, a.amditis}@iccs.gr
Abstract—As part of its ongoing move to simplify and 
modernise the EU’s Common Agricultural Policy (CAP), the 
European Commission has adopted new rules that allow a 
range of modern technologies to be used in the check systems 
for area-based CAP payments. This includes the possibility to 
use geotagged photos to support and complement checks when 
the latter do not lead to conclusive results and additionally to 
help avoid wasting time and money on the spot checks. They 
can also be used as ground truth information provided by 
farmers or other stakeholders. A system that can support the 
farmer in collecting the needed geotagged photos is presented 
here. The system will help with the automation and 
acceleration of a heavily manual process by facilitating the 
interaction between the farmers and the relevant authorities. 
Keywords-Common Agricultural Policy; Earth Observa- 
tion; remote sensing; drones; geotagged photos; environmental 
performance; farmers’ compliance. 
I. 
 INTRODUCTION  
The DIONE project proposes a close-to-market area-
based direct payments monitoring toolbox that addresses the 
Modernised Common Agricultural Policy (CAP) regulation 
of using automated technologies to ensure more frequent, 
accurate and inexpensive compliance checks. In particular, 
the toolkit showcases the capability of Sentinel data to 
monitor the crop diversification rules and integrates the 
generated crop-type maps in a way directly exploitable by 
the paying agencies. It includes in the analysis the so far 
neglected Ecological Focus Area (EFA) types, such as fallow 
land of all sizes, buffer strips, hedges and trees, by making 
use of super-resolution technology that improves the 10-20m 
Sentinel resolution to an improved resolution range. The 
toolkit also complements the use of Earth-Observation (EO) 
data with a system of reliable, ground-based geotagged 
photos, captured by the farmers, that exploits advances that 
allow for improved positional accuracy, low-footprint 
encryption techniques for improved data security and 
reliability and image detecting manipulation techniques. The 
system allows for an improved Land Cover/Land Use 
annotation and ensures the process is untampered. 
The main objective of this paper is to provide an 
overview of the geotagged photos in-situ component for 
complementing EO-data which are developed within the 
frame of the DIONE project. The geotagged photos are 
captured using smartphones and allow for an improved 
method for the provision of additional evidence regarding the 
CAP compliance monitoring. The added benefit is the 
quality and trust of the transmitted data as well as the 
application characteristics with respect to location accuracy 
and data collection process through the use of Augmented 
Reality (AR) features. 
Finally, a central data processing and storage system 
gathers the data, ensures their quality and provides user-
friendly Application Program Interfaces (APIs) for the 
curated data contained. The system ensures that only 
authorized parties are used as sources of the received data, 
that the integrity of the data and metadata [10] is not 
compromised, that no data with highly variable/outlier nature 
is going to be used and that appropriate forms of data storage 
are used to ensure easy retrieval. 
The rest of this paper is organized as follows. Section II 
describes the design of the system, core tech functionalities 
and use cases. Section III addresses the front-end side of the 
mobile application and describes the User Interface 
(UI)/User Experience (UX) aspects. Section IV offers some 
thoughts on the outcomes and future work. The 
acknowledgement and references close the article. 
II. 
SYSTEM DESIGN 
The data collection process is supported by a mobile 
application that exposes to the user all the related content 
about his/her parcels while enabling the conclusion of the 
process and the provision of the final photos to the Paying 
Agencies (PAs). On the other hand, a set of backend 
processes [15] [16] provide the necessary instructions for 
farmers to reach a given parcel as well as directions 
regarding the process of capturing appropriately a photo of a 
given parcel. 
In particular, the application enables the user to check if 
there are any requests from the Paying Agency for the 
provision of geotagged photos and, based on this, facilitate 
the overall process. The latter includes the provision of 
information on map related to the user’s parcels and his/her 
current position, navigation to the correct spot in the parcel 
for the photo acquisition, as well as use of AR to dictate the 
exact spot and direction he/she needs to place his/her mobile 
device while superimposing parcel boundaries to facilitate 
the process. 
 
1
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-946-1
SOFTENG 2022 : The Eighth International Conference on Advances and Trends in Software Engineering

 
             Figure 1. EDAS Hig-Level Architecture 
 
Ensuring the best possible positional accuracy is another 
essential requirement [12], whilst the application allows the 
exploitation of raw Global Navigation Satellite System 
(GNSS) measurements and enables the user to evaluate 
his/her positional accuracy. The photo acquisition process 
can also be initiated without an initial request from the 
Paying Agencies, allowing users to act proactively and 
provide geotagged photos in advance so as to assist 
compliance evaluation for their parcels. 
Moreover, aiming to support ease of use, the application 
provides local language menus, user friendly visualisation of 
detailed parcel information, as well as a tutorial with step-by-
step information of how to capture photos. 
Following the collection of the needed photos, the 
application enables the transmission of the collected figures 
along with their associated metadata. The minimum required 
metadata that are stored during the data acquisition process 
include: 
• Time, date and geographical location of the photo 
acquisition: This information is extracted directly without 
manual interference from the GNSS antenna embedded in 
the mobile devices. The positional accuracy can be improved 
to a meter or even sub-meter one, for the devices that can 
harness multiple location differentiators and European 
Geostationary 
Navigation 
Overlay 
Service 
(EGNOS) 
services. 
• Orientation, heading, of the camera at the time of photo 
capture: Its goal is to ensure the proper acquisition of the 
photo, pointing at the correct parcel. This information can be 
extracted from the compass system embedded in the device 
(10 degrees deviation) while also being deduced by 
exploiting the AR features of the geotagged photos 
framework. Regarding the latter, AR allows to identify and 
superimpose on the photo the land parcel border or other 
identifiable landmarks, and subsequently to capture multiple 
photos as needed and properly adjust the device positioning. 
• Identification of the operator. 
•Basic information on the mobile device and inbuilt 
camera i.e., mobile device brand, camera model, and focal 
length. 
 
 
 
Figure 2. A scheme representing the steps composing the usual life 
cycle a digital image undergoes. Imperfections in the CMOS manufacturing 
process introduce noise in the photos taken. 
 
       The application is available to operate both in online and 
offline mode. In this context, all data needed for the guidance  
of the user must be fetched beforehand and preferably while 
on a Wi-Fi connection. Thus, all actions and data acquired 
on-site must be stored locally in order to be sent to the 
backend later. 
The format of the acquired photos is stored according to 
the most commonly used standards in digital cameras. In this 
context, appropriate settings were considered towards 
ensuring appropriate quality of the photo as well as avoid 
losing image details due to compression levels. 
Users of the application are able to receive detailed 
instructions in order to fulfil the data acquisition process. In 
line also with the EU guidelines, a macro/panoramic photo is 
captured with the camera pointing higher at the horizon 
showing the corresponding field. In some cases, this type of 
format may represent the optimal evidencing option (i.e., 
mixture of crop as EFA cover crop). 
On the other hand, in order for the photos to be reliable 
there is a need to validate their integrity and origin and detect 
any attempts of digital manipulation of the photos. This is 
achieved through a server-side process (framework) that runs 
successively different image forensics techniques to locate 
any digital manipulation and ensure that the photo is taken 
by the correct user (farmer) in the correct parcel. The 
component firstly ensures that the file of the photo comes 
from the same device that the farmer used to authenticate 
himself/herself in the mobile application. In the second step, 
the photo file is checked aiming to detect any tampering 
from the time the image was taken and until it was uploaded 
to the system while also using methods to ensure location 
integrity. In the next steps of the process, forensics 
techniques specifically designed for photos are executed. In 
these steps, the goal is to verify that the user did not 
manipulate the photo digitally. 
This component also addresses the need to preserve 
private and personal information that may be exposed in the 
taken photos when they are reviewed by the inspectors of the 
Paying Agency. Thus, the last part of the server-side 
framework is an anonymization tool that is responsible for 
blurring any faces or license plates detected in the photos. 
 
2
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-946-1
SOFTENG 2022 : The Eighth International Conference on Advances and Trends in Software Engineering

 
 
                  Figure 3. The overall integrity process. 
 
Data acquisition. The starting point for the application 
use is through the transmission of a push notification by the 
toolbox API to the geotagged photos component regarding 
the parcel requiring the acquisition of geotagged photos. A 
geotagged photo consists of saving at least the location as 
latitude and longitude coordinates, date, time, orientation and 
the mobile device/camera information into a JavaScript 
Object Notation (JSON) file for each Portable Network 
Graphics (PNG) photo file. The notification is transmitted 
downstream to the mobile application in order to notify 
farmers regarding the parcel requiring geotagging. Through 
the geotagging photo app, farmers can view the route 
towards the parcel under investigation. Subsequently, they 
receive guidance regarding the process of taking a photo of 
the parcel with the use of AR techniques. The photo taken is 
uploaded and checked for integrity by the backend of the 
geotagging component and it is stored in a database. The 
compliance dashboard requests the geotag photo object 
which is fetched through the toolbox API. 
All app users are linked to their respective farmer unique 
id. This is achieved during the authentication-authorisation 
process and is facilitated by the toolbox API that is 
dynamically connected with the Paying Agencies systems. 
       Moreover, in order to benefit from all modern 
differentiators, a recent Android device is needed, that 
provides access to real time data extracted from raw GNSS 
data. The platform has strict limitations since the photos 
taken must represent the real state of a parcel at a very 
specific time and day. As many techniques as possible are 
needed in order to maximise the accuracy of the position.  
The user is able to monitor positional metadata extracted 
from raw GNSS data.  
 
 
 
Figure 4. Screenshots from the mobile application: (a) Overview page, (b) 
AR support for photo capturing 
 
      Based on the user’s device and Internet connectivity, 
they are able to benefit from different European Global 
Navigation Satellite System (EGNSS) differentiators (e.g., 
dual frequency GNSS [13]) to achieve improved positional 
accuracy and to assure positional data integrity. Positional 
accuracy requires data connection to be able to receive 
correctional data from the EGNOS Data Access Service 
(EDAS) service (Fig. 1). EDAS provides a wide variety of 
products, in different formats and different protocols [14]. 
Among these products, EDAS provides the EGNOS 
augmentation messages, as normally received by users via 
the EGNOS geostationary satellite. This message is 
transmitted in real-time by the EDAS Signal-In- Space 
(SISnet) service and is useful for users that won’t have an 
EGNOS supporting device. 
Positional data integrity can be achieved by analysing 
raw GNSS data for Open Service Navigation Message 
Authentication (OSNMA) [1][2][3] 
verifying 
Galileo 
signalling. In order to identify the Galileo messages, the raw 
bits of E1 I/NAV messages are taken from the receiver using 
Android calls and from there, the OSNMA relevant bits are 
extracted for authentication. Since all photo metadata must 
be as accurate as possible, the application makes sure that the 
positional accuracy is below the required threshold before 
the image capturing. 
Data integrity. In order to ensure that the file of the 
photo is not manipulated and is the same from the time the 
photo was taken, the technique of steganography [4] is 
utilised. Steganography is the practice of concealing a 
message within a file. In our case, we conceal a secret 
message right after the photo is taken and try to extract this 
message on the server side. Knowing that the message is 
concealed within the file, a successful extraction of the 
message would mean that the file is not tampered with. In the 
second step, a light-weight signature scheme [5] [6] aims to 
3
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-946-1
SOFTENG 2022 : The Eighth International Conference on Advances and Trends in Software Engineering

facilitate the secure transmission of the photo and operates as 
a pairing mechanism between the farmer and the mobile 
device used. During the sign in process, a pair of a private 
and a public key would be generated, and the public key is 
sent to the server to be saved. Every time the farmer takes a 
photo, the private key is used to sign the photo. The signing 
procedure ensures that the photo which was sent to the server 
was taken by the same device the farmer used to sign in. The 
signing scheme operates as a second level of assurance that 
the photo was not tampered on top of the steganography, as 
in the case of tampering, the signature is not able to be 
verified in the server process. 
In the next phase of the server-side procedure, an 
algorithm is executed so as to identify the device used to 
capture the photo. The identification becomes possible due to 
the fact that each component in a digital camera leaves 
intrinsic fingerprints in the final image output, which due to 
manufacturing choices are unique for each device. The 
component of the camera that makes possible the 
identification is the CMOS image sensor, which inserts a 
pattern noise in the photos which is unique for each device 
[7]. The process is depicted in Fig. 2. This step is useful to 
confirm that the noise matches the device the farmer is using. 
In what follows, two photo specific forensic algorithms 
are implemented. The first one is the copy-move forgery 
detection algorithm. In the copy-move forgery, the malicious 
actor replicates a portion of the photo inside the photo [8] 
[9]. The detection algorithm allows to avoid this kind of 
forgery. The second technique regards the way the 
information is saved inside the photo. As shown in Fig. 2, 
different processing steps take place before the final 
photo/file is created. The final step is the appliance of a 
compression. Every photo file is compressed using a specific 
algorithm. Taking this into consideration, the entire photo 
should be roughly at the same level; if a difference is 
detected, then it likely indicates a digital modification. So, 
the second forensic algorithm constitutes an investigation of 
the compression levels. One example of such an 
investigation is the error level analysis. 
In the next step of the procedure, a tool is used to extract 
the metadata that is embedded in the photo. This extracted 
data is verified with the data that have been stored in the 
database i.e., parcel location, time of photo etc. The main 
information to be obtained involves the location of the photo. 
Using the Galileo OSNMA, it can be guaranteed that users 
are utilising non- counterfeit navigation data coming from 
the Galileo satellites.  
Finally, a pre trained convolutional neural network is 
used so as to locate faces and license plates and blur them. 
The overall process is depicted in Fig. 3. 
For the implementation of the data integrity framework, 
the python programming language is utilised. For the first 
two steps, there are respective libraries (stegano and crypto 
libraries) that are exploited for the implementation. One 
thing to consider here is that we have to be careful in the 
choice of the techniques used due to the fact that some parts 
are implemented in the mobile application. So, we have to 
ensure that the respective parts should be possible to be 
implemented in C#, which is the language of the 
implementation of the mobile applications. Finally, one more 
benefit that python gives is the ability to execute bash 
commands and interact with other tools. A final 
consideration that should be taken into account, is which 
variation of the steganography technique to implement. That 
is because, we could make the algorithms in the last steps 
unable to be used due to the structure alteration of the photo, 
by embedding a secret message. 
III. 
MOBILE APPLICATION 
The application is developed in the Unity game engine to 
benefit from the integrated AR solution that ships with the 
engine. Unity is a cross-platform game engine developed 
initially as a Mac OSX exclusive game engine. As of 2018, 
the engine had been extended to support more than 25 
platforms. The engine can be used to create multi-
dimensional, virtual reality, AR applications. AR Foundation 
is a cross-platform framework built for the Unity engine that 
allows to build AR experiences once, then build for either 
Android or iOS devices. The package presents an interface 
for Unity developers to use, but does not implement any AR 
features itself. To use AR Foundation on a target device, 
separate packages are also needed to target platforms 
officially supported by Unity: (i) ARCore XR Plugin on 
Android (ii) ARKit XR Plugin on iOS. 
Along with Unity, some native android plugins were de- 
veloped, mainly to handle the low-level operations required 
for the raw measurements handling and integrity aspects 
[11]. The AR component aims to provide directions to 
farmers in order to enable retrieval of representative photos 
of a given parcel. The photo taken, along with the required 
metadata, is uploaded to be verified by the data integrity, 
validation and anonymization component of the geotagged 
photos framework and to be stored in the Central Database. 
Home screen – Authentication/Authorization. The 
geotagged mobile application provides translated text 
interface to accommodate for the users in different countries. 
The application is not open for general use, it is available 
only for registered users. In order to achieve this, the user 
must have registered themselves in the platform. 
Content visualization. The application displays recent 
news from the respective Paying Agency i.e., aspects of 
importance with respect to the application period, news on 
CAP implementation in their country, along with the latest 
pending Tasks for the user (Fig. 4), while the latter displays 
all the user’s declared parcels. A Task is an action required 
from the farmer by the Paying Agency Inspector. It is related 
to a specific parcel and its location can be specified by the 
Inspector. Each parcel has its own unique page in the mobile 
app to host the various Tasks related to it. However, a user 
can also act proactively and facilitate the compliance 
assessment process for their parcel, without receiving notice 
from the PA Inspector. More than that, the settings page is 
there to provide visual feedback in the form of the traffic 
light approach about the EGNSS differentiators supported by 
the device. 
Push notifications. A Paying Agency Inspector may 
create a new Task for the user at any time through the 
Compliance monitoring tool. In order to notify the user 
4
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-946-1
SOFTENG 2022 : The Eighth International Conference on Advances and Trends in Software Engineering

efficiently, a new Task in the Toolbox API triggers a push 
notification to be sent towards the mobile device. The Tasks 
have an associated status based on their progress which can 
be open, pending or completed. The push notification system 
for the mobile application, relies fully on the OneSignal 
service. 
Navigation to parcel and defined spots. After 
launching a specific Task, the user is presented with a map 
view. Its purpose is to guide the user to the Parcel this Task 
is associated with. The mapping platform of choice is the 
open source Mapbox which along with its very useful APIs, 
provides the building blocks for a complete position solution. 
Mapbox is a provider of custom online maps for websites 
and applications whose data is taken from open data sources, 
such as OpenStreetMap and NASA, and from purchased 
proprietary 
data 
sources. 
The 
Mapbox 
Software 
Development Kit (SDK) that is used in the context of the 
mobile application, constitutes an open-source toolset for 
building mapping applications for Android devices. An 
essential part of the SDK if the Native Location Provider that 
allows the application to make use of the native Android 
positioning module. That way, the Unity mechanism for 
position can be overridden and along with it, the low 
precision it offers. The routing functionality is provided by 
the 
Mapbox 
Directions API external 
service. The 
information is denoted on the map by connecting the user’s 
position and destination, along with turn-by-turn text 
instructions. 
Augmented reality photo capture. When requesting 
geotagged photos from the farmer, the intention is to obtain 
sufficient information in order to avoid any physical field 
visits by the Paying Agencies’ Inspectors. Therefore, the 
collected images should provide an overview of the parcel, 
but not necessarily cover its entirety and all the details (Fig. 
4). There are two types of photos that are required from the 
user, landscape or portrait. 
A landscape photo should depict a larger part of the field 
and include elements other than the main object such as crop 
and activity, if possible. This type of photo aims at reducing 
the uncertainty linked with the limited accuracy of the geotag 
and at providing an overview of the field condition. A 
portrait photo must serve to enable the robust identification 
of the element to evidence. This subject could be a mixture 
of crop as EFA cover, presence of rare crops that cannot be 
reliably discriminated in the Sentinel data etc. In the context 
of a Task created by a Paying Agency Inspector, the type of 
photo as well as the preferred camera orientation are 
specified during the creation of the Task in the Compliance 
monitoring tool. 
By using ARFoundation, the user is instructed on what 
is required of them, like where to take the photo from, 
camera orientation etc. Since a user can take geotagged 
photos either proactively or in the context of a Task, the 
application restricts the location of a photo accordingly. If 
the farmer takes initiative without having a request, he/she is 
allowed to take a photo from inside the parcel or near each 
one of the parcel’s corners. On the other hand, if there is a 
Task, the farmer is only allowed to take a photo within a 
radius from the location that the Inspector has selected when 
creating the specific Task. 
While in the AR session, the application continuously 
looks for active applications running in the background, that 
may tamper with the GNSS signal by mocking the actual 
location. In conjunction with ARFoundation, the “AR + GPS 
Location” Unity asset is used to position 3D objects in real-
world geographical locations via their GPS coordinates. This 
asset helps place all points of interest in the AR session so 
that they correspond to their real-world positions. Unity 
provides a mechanism to access location data, however this 
data is of low precision. This, in turn, leads to a lower 
position accuracy and a lower fidelity for the AR session in 
general. To overcome this, a method has been implemented 
to get the native location information directly from the 
Android system. 
The positional accuracy is being tracked and the digital 
content is drawn only when the accuracy is below a specific 
ceiling. On top of this, all the AR content is re-drawn 
whenever the accuracy is improved, so that the overall 
experience is improved as well. The geotagged mobile 
application does not use the traditional camera application to 
take the photos and this is because of the AR session 
occupying the camera hardware. Hence, there is no 
mechanism to automatically embed the Exchangeable image 
file format (EXIF) metadata to the file as it usually happens. 
Thus, a dedicated mechanism is employed, that takes the 
background of the image and in the resulting PNG file a 
custom method is applied to decode and embed the required 
metadata. 
Offline mode. The nature of the farming activities and 
the geotagged mobile application’s purpose mean that the 
most significant actions in the application’s lifecycle take 
place outdoors. Agricultural parcels are often situated in 
remote and mountainous places that are not covered by 
mobile network signal. Therefore, it is crucial that the 
functionalities of the application can be performed when no 
mobile signal reception is available. 
Since the data presented to the user needs to be as recent 
as possible, the first steps of the process require an Internet 
connection to fetch the relevant data. This data, in turn, is 
temporarily stored and is available while the application is 
“running” subsequently offline. 
Also unavailable is the access to the map view via 
Mapbox. The map relies on getting tile information via the 
Internet so no useful information can be presented otherwise. 
However, a user can download (automatic process) some 
initial map tiles in the map view, disconnect from the 
Internet, and have these initial tiles as guiding reference to 
the parcel in question. The entirety of the AR session is 
working offline. The AR content that is superimposed is 
based on the initial data fetched for the user from the 
Toolbox API. The photos taken are stored locally in the 
phone’s internal memory so that when a network connection 
is available, the user can browse through them and upload 
the most appropriate ones. As mentioned, the time and date 
of a taken photo are very important to the project as they 
provide a timestamp for the snapshot of the evolving crops in 
a parcel. The time integrity component is working offline as 
5
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-946-1
SOFTENG 2022 : The Eighth International Conference on Advances and Trends in Software Engineering

well. It can provide a date and time irrelevant of the phone’s 
settings or other external providers that require network to 
function. The only requirement is the reception of GNSS 
signals, which is a trivial task when outdoors. 
IV. 
CONCLUSION AND FUTURE OUTLOOK 
The presented solution offers a reliable and secure way to 
modernise the EU’s CAP. The farmers are given the ability 
to capture geotagged photos to support their applications and 
complement other systems when the latter do not lead to 
conclusive results. More importantly, it strengthens the 
interaction between the farmers and the relevant authorities. 
In order to improve the UX of the application, more 
guidance will be needed for the application user, especially 
anyone unfamiliar with such technologies. Hence, a screen 
needs to be added with brief instructions on what is required 
of them, how to take a photo, the restrictions applied etc. An 
instructional video may also be added. Since AR systems 
rely heavily on location accuracy as explained in the above- 
mentioned sections, the implementation of the EGNOS-
EDAS augmentation needs to be finalised, harnessing the 
required augmentation messages provided by the SISNet 
service of the EDAS platform. In parallel, various filtering 
methods may be utilized to stabilize existing position. In the 
backend side of things, the creation of a JSON schema is in 
order, to annotate and validate the JSON documents 
uploaded by the geotagged mobile application. By describing 
the data format, the quality of the submitted data can be 
ensured. With respect to the geotagged photos integrity 
framework, the OSNMA implementation needs to be 
integrated and subsequently a full test to be realised aiming 
to assess all the different cases. 
ACKNOWLEDGMENT 
     This work is a part of the DIONE project. This project has 
received funding from the European Union’s Horizon 2020 
research and innovation program under grant agreement No 
870378. 
REFERENCES 
 
[1] I. Fernandez-Hernandez et al., “A Navigation Message 
Authentication Proposal for the Galileo Open Service,” 
Navigation, Journal of The Institute of Navigation, vol. 63, 
no. 1, pp. 85-102, 2016. 
[2] Galileo Navigation Message Authentication Specification for 
Signal-In-Space Testing – v1.0 
[3] B. Motella, M. Nicola, and S. Damy, ”Enhanced GNSS 
Authentication Based on the Joint CHIMERA/OSNMA 
Scheme,” in IEEE Access, vol. 9, pp. 121570-121582, 2021, 
doi: 10.1109/ACCESS.2021.3107871. 
[4] N. F. Johnson and S. Jajodia, ”Exploring steganography: 
Seeing the unseen,” in Computer, vol. 31, no. 2, pp. 26-34, 
Feb. 1998, doi:10.1109/MC.1998.4655281. 
[5] R. Kaur and A. Kaur, ”Digital Signature,” 2012 International 
Conference on Computing Sciences, 2012, pp. 295-301, doi: 
10.1109/ICCS.2012.25. 
[6] An 
Introduction 
to 
Digital 
Signature 
Schemes 
arXiv:1404.2820 [cs.C] 
[7] Digital Camera Identification from Sensor Pattern Noise 
http://www.ws.binghamton.edu/fridrich/research/double.pdf 
[retrieved: May, 2021] 
[8] W. Luo, J. Huang, and G. Qiu, ”Robust Detection of Region-
Duplication Forgery in Digital Image,” 18th International 
Conference on Pattern Recognition (ICPR’06), 2006, pp. 746-
749, doi:10.1109/ICPR.2006.1003. 
[9] A. C. Popescu and H. Farid, “Exposing Digital Forgeries by 
Detecting Duplicated Image Regions.” , 2020. 
[10] The 
Metadata 
in 
PNG 
files, 
https://dev.exiv2.org/projects/exiv2/wiki/The 
Metadata 
in 
PNG files [retrieved April, 2021] 
[11] Android 
plugins 
in 
Unity, 
https://docs.unity3d.com/Manual/PluginsForAndroid.html 
[retrieved September, 2021] 
[12] Use of geotagged photographs in the frame of Common 
Agriculture 
Policy 
checks 
https://marswiki.jrc.ec.europa.eu/wikicap/images/c/ce/Geotag
ged JRC Report1.pdf [retrieved: October, 2021] 
[13] Advantages of dual-frequency GNSS in smartphones 
https://www.geospatialworld.net/blogs/advantages-of-dual-
frequency-gnss-in-smartphones/ [retrieved: November, 2020] 
[14] RTCA DO-229 Minimum Operational Performance Standards 
(MOPS) for Global Positioning System/Satellite-Based 
Augmentation System Airborne Equipment 
[15] MongoDB: 
the 
application 
data 
platform 
https://www.mongodb.com/  [retrieved: March, 2021] 
[16] The Open Source API Service for the Modern Web 
https://restheart.org/ [retrieved: March, 2021] 
 
 
 
 
6
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-946-1
SOFTENG 2022 : The Eighth International Conference on Advances and Trends in Software Engineering

