Towards an Adaptive L´evy Walk Using Artiﬁcial Endocrine Systems
Hugo Sardinha†∗, Mauro Dragone∗ and Patricia A. Vargas†
∗School of Engineering and Physical Sciences
†School of Mathematical and Computer Sciences
Edinburgh Centre for Robotics, Heriot-Watt University
Email: {hs20, m.dragone, p.a.vargas}@hw.ac.uk
Abstract—Behavioural adaptation is often observed in foraging
animals via coupling periods of localized search and long straight
forward motions, a well-known strategy named L´evy Walk. In
this paper we propose an adaptive L´evy Walk model to control
an autonomous agent. The model is comprised of a L´evy-based
controller modulated by an artiﬁcial endocrine system optimised
through evolutionary techniques. This new approach enables the
agent to control the transition between localized search and
long relocation when exposed to external stimulus. The model
is tested in exploration tasks where environments have resources
clustered into patches. Further tests incorporated environments
with different patch characteristics, such as patch size or resource
distribution within patches. Our model has shown to outperform
the benchmark approach in terms of search efﬁciency, highlight-
ing the beneﬁts of combining a L´evy Walk based controller with
a biologically inspired strategy for adaptation.
Keywords–Artiﬁcial Endocrine Systems; Adaptation; L´evy Walk;
Biologically Inspired Algorithms; Foraging; Autonomous Agents.
I.
INTRODUCTION
Foraging animals in nature have long been observed to
exhibit adaptive search strategies in order to ﬁnd beneﬁcial
environmental conditions, such as water or food sources [1].
To describe this motion of animals in the wild, computational
ecologists ﬁrstly attempted to use Brownian models to ﬁt
empirical data, over large spatial scales and long temporal
scales, with relative success [2]. However, these uncorrelated
models of motion did not account for the tendency that
animals show to continue moving in the same direction [3].
To better describe this behaviour, two major models have
been employed, the Correlated Random Walk (CRW) [4] and
the L´evy Walk (LW) [5]. As in Brownian motion, the CRW
considers a Gaussian distribution of walk lengths, but unlike
its predecessor, draws the re-orientation angle from a non-
uniform distribution, centered around the current heading, thus
generating a directional persistence. Conversely, the LW model
considers an uniform distribution to draw new orientations
but, unlike the previous models, draws length walks from a
power law distribution instead. Since power laws are heavy
tailed, this leads to occasional long walks, effectively coupling
periods of localized random search with periods of ballistic
relocation across the domain [6]. Figure 1 shows an example
of trajectories generated by Browanian and L´evy motions.
Consequently, several works used these models to develop
robot controllers in foraging scenarios, corroborating theo-
retical results [7] [8]. In fact, LWs have become regarded
as the optimal foraging strategy by subsequent works [9],
particularly when points of interest, or resources, are sparse
and randomly distributed [10]. However, different scenarios
exist where such resources may not materialize in this manner;
for example, in agricultural tasks such as the mapping of
weeds in a ﬁeld, where resources (weeds) tend to be clustered
(a) Brownian Motion
(b) L´evy Motion
Figure 1. Examples of trajectories generated by Brownian and L´evy motions
together in patches [11]. Danchin’s [12] deﬁnition of a patch
—“an homogeneous resource containing area (or part of
habitat) separated from others by areas containing little or no
resources”—is of crucial importance for the solution we here
present. Since resources are not distributed uniformly, but exist
in regions of locally high density there is an imposing drive
for an autonomous agent to be able to adapt its behaviour
in order to ﬁnd them efﬁciently [13]. In fact, one could
interpret LWs observed in nature as a consequence of an
underlying adaption mechanism, switching to localized search
when inside a patch, and switching back to ballistic motions
once no new resources are found. To interpret adaptation in
the context of either natural or artiﬁcial autonomous agents
we recall Ashby’s deﬁnition by which a form of behaviour
is considered adaptive if it maintains the essential variables
within physiological limits [14]. Such an ability to maintain
an internal equilibrium, known as homeostasis, is ubiquitous
in the animal kingdom [15], and depends strongly on the
endocrine systems these animals developed over the course
of their evolution [16]. These systems are responsible for
the production of hormones that regulate a myriad of bodily
functions such temperature, heart-rate, or the desire to hunt,
and have also inspired researchers to synthesise Artiﬁcial
Endocrine Systems (AES) for robot control [17]. Drawing
inspiration from hormone-based regulation in natural systems,
this work proposes an Endocrine-based L´evy Walk (ELW)
model for foraging in patchy environments, by which the
observable L´evy process is modulated by an underlying AES
endowing the forager with the ability to change its behaviour
in the presence of favourable environmental conditions.
The paper is divided as follows: Section II highlights the most
relevant models for our work; Section III describes in detail our
proposed model; Section IV presents our results and how they
compare to the benchmark, and ﬁnally Section V summarizes
our ﬁndings.
116
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-781-8
ADAPTIVE 2020 : The Twelfth International Conference on Adaptive and Self-Adaptive Systems and Applications

II.
RANDOM WALK MODELS
Random walks are a class of stochastic processes used
to model empirical data. Existing processes arise from the
intuitive idea of taking successive steps, each in random direc-
tion. Therefore, they consist of displacement events (i.e., walk
lengths) interspersed by reorientation events [18]. This section
explores the basic concepts of L´evy walks and, in particular,
the biological ﬂuctuation method proposed by Nurzaman et al.
[19], which will be used as a benchmark for our model.
A. L´evy walks
L´evy Walks are a random walk process characterized by
drawing each step length (ls) from a power law distribution:
P(ls) ∼ l−µ
s
,
1 < µ ≤ 3
(1)
where the parameter µ controls the shape of the distribution’s
tail, making ballistic relocations more (or less) common.
Previous work has shown that for µ ≥ 3 the motion becomes
Brownian, whereas when µ → 1, it becomes a series of
straight motions with negligible local searches [6]. At each
reorientation step, a new heading τ is generated such that τ ∼
U(−π, π). Some authors have proposed replacing an uniform
turning angle, and instead use a correlated reorientation, which
has shown to produce some improvement in search efﬁciency,
particularly in environments where resources are sparsely dis-
tributed [3] [20]. In our work, the proposed adaptive model will
be tested both with and without correlation, to study its effect
on patchy environments. Correlation is achieved by drawing τ
from a wrapped Cauchy distribution, whose probability density
function, given in [20], is as follows:
C(ρ, τ) = 1
2π
1 − ρ2
1 + ρ2 − 2ρ cos(τ)
(2)
where the parameter ρ represents how correlated the direction
of consecutive walks is. On the one hand, when ρ = 1,
correlation is complete and therefore the entire motion is a
continuous straight line, while on the other hand, when ρ = 0,
reorientations are in fact not correlated and τ assumes an
uniform distribution.
B. Biological Fluctuation
An alternative to distribution-based random walk models
was proposed by Nurzaman et al, where the transition between
local searches and ballistic motions happens based on the con-
cept of yuragi or biological ﬂuctuation [19]. This mechanism
is one by which certain bacteria are able to alter their gene
expression (and therefore their behaviour) in the presence, or
absence, of nutrients. A formal description of such behaviour
is given by the attractor selection model, represented by the
Langevin equation:
˙x(t) = −∇U(x(t))A(t) + ϵ(t)
(3)
where x and −∇U(x(t)) are respectively the state and dy-
namics of the attractor model, ϵ(t) is a noise term, and A(t)
represents a variable activity which indicates how well the
current state ﬁts the environment, chosen in Nurzaman’s work
to be respectively:
U(x(t)) = (x(t) − h)2
(4)
A(t) = R · A(t − 1) + f(t)
(5)
where f(t) represents the number of resources sensed, and R
is a decaying coefﬁcient with respect the previous value of
A(t). The way the system changes from continuously straight
motions to local search is modeled by a ﬁnite state machine
with two states: swimming or gliding, which corresponds
to a forward motion, and tumbling which corresponds to a
reorientation. One can observe, from the depiction of in Figure
2, that the transition from the gliding state G, to the tumbling
state T depends on a probability P(t). On one hand, if P(t)
is small the gliding motion continues and long relocations are
expected, whereas on the other hand, for high values P(t) a
tumbling step is more likely to occur, immediately followed
by another gliding step leading to a local search behaviour.
Figure 2. Finite state machine for behaviour
Based on the state of the system, the probability of tran-
sitioning between states is computed using (6). One can see,
from (3), that when A(t) increases, the ﬁrst term becomes
dominant and the value of the system’s state x decreases
towards attractor h (with 0 < h < 1), therefore leading to
a high probability transitioning from G to T .
P(t) = e−x(t)
(6)
On the other hand, when A(t) is very small, the dominant
term of (3) is the noise term ϵ(t), which, due to being applied
to ˙x, gradually makes the state x diverge from the attractor
leading to small value of P(t), and therefore a continued
gliding motion.
III.
ENDOCRINE-BASED ADAPTIVE L´EVY WALK
The underlying L´evy controller of most (if not all) artiﬁcial
agents, or foragers, can be considered to have two stages:
Generation and Execution. At the Generation stage a tuple
(τ, ls) is selected depending on µ and, if correlated, on ρ.
This tuple is used in the Execution stage to move the agent
in the direction τ while l(t) < ls, where l(t) is the distance
travelled since the beginning of the current walk. Our work
proposes that, in order to achieve adaptation, both µ and ls
need to change dynamically according to sensory input. Firstly,
as the forager enters a patch it is straightforward to envision
that µ should increase, so that the behaviour converges to a
local search. However, only changing the value of µ will have
little or no effect if the current step is not completed within the
patch in time for another tuple (τ, ls) to be generated. In order
to harness this intuition we introduce a desire to interrupt the
current walk, which will translate to a gradual decrease of ls
for the ongoing step. The speciﬁc AES proposed for L´evy walk
adaption is built upon the concepts put forward by Wilson et
al. [21] and Stradner et al. [22], where the level of a hormone
H at time t can be modelled by the following:
117
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-781-8
ADAPTIVE 2020 : The Twelfth International Conference on Adaptive and Self-Adaptive Systems and Applications

H(t) = c0 + c1H(t − 1) + c2S(t)
(7)
where c0, c1, c2 are constant coefﬁcients, H(t − 1) represents
the previous hormone level and S(t) is the stimulus received
from sensory input. The ﬁrst term, co, represents a base incre-
ment simulating a default and constant hormone production,
the second term c1H(t − 1) acts as decay over time, and
c2S(t) represents the contribution from the sensory stimulus
to the overall level of H(t). Wilson [21] highlights that one
could calculate the settling point of H(t), when no stimulus
is received, as Hs = c0/(1 − c1). Using (7) we model the
variation of µ as the hormone level itself and deﬁne:
µ(t) = a0 + a1µ(t − 1) + a2Sµ(t)
(8)
where Sµ(t) assumes a binary value depending on the variation
of number of resources sensed according to (9). Therefore, as
the forager enters a patch of resources, µ tends to increase,
while if there are no new resources µ(t) → µs = a0/(1−a1).
Sµ(t) =



1,
∆f(t) > 0
0,
∆f(t) ≤ 0
(9)
Modelling the aforementioned desire to interrupt the current
walk is done in a similar fashion, by considering the hormone
level β deﬁned as:
β(t) = b1β(t − 1) + b2Sβ(t)
(10)
Note that there is no b0 term, allowing in fact the value of
β(t) to decrease to zero. The stimulus function for β is given
in (11), where if f(t) is increasing, there is no stimulus to
the desire to interrupt the current walk since this means the
current walk step is providing a good strategy to ﬁnd resources.
Conversely, if the f(t) is decreasing this desire increases, and
does so proportionally to the normalized value of µ(t) between
its settling point (µs) and its maximum value (¯µ = 3), creating
an interdependence of these two artiﬁcial hormone quantities
as it also the case in several natural systems [16].
Sβ(t) =







0,
∆f(t) ≥ 0
¯µ − µ(t)
¯µ − µs
,
∆f(t) < 0
(11)
As one can see, when µ(t) → µs then the stimulus Sβ → 1
and when µ(t) → ¯µ Sβ → 0. In practical terms this means that
if the forager is ﬁnding fewer resources but the its µ(t) value
is large, it is already performing a local search and the desire
to interrupt that walk is irrelevant since it would already be a
local step. On the other hand, if µ(t) is small in the presence
of a varying number of resources then the desire is relevant
and it is stronger as µ(t) is further from ¯µ. Updating the target
step length is, in our model simply done by computing (12).
ls = ls

1 − β(t)

(12)
In summary, we can consider our endocrine-based model,
depicted in Figure 3, to have three main components, namely:
Figure 3. Endocrine-based L´evy Walk model.
the Hormone production module (H) that updates the values
of µ(t) and β(t); the L´evy controller (L) which controls the
pose of the forager, generates ls depending on µ and updates
it depending on β; and ﬁnally the sensory input module, S,
which given the new pose x(t) and the previously sensed
resources updates the stimulus functions.
IV.
EXPERIMENTS & RESULTS
The performance of our proposed model is assessed by a
series of experiments in different environments. The ﬁrst of
which is the one chosen by Nurzaman et al, (Environment
I) and comprises an arena of 1000x1000m where 10 patches
are randomly distributed. These patches are 10x10m and
contain 100 rewards each, also uniformly distributed. As in
Nurzaman’s work, we consider an agent whose ﬁeld of view
is 2x2m travelling at a speed of 1m/s over 10000s. Furthermore
we expand testing to environments where patches are 50x50
(Environment II) and 100x100 (Environment III) maintaining
reward density, and use these three environments to test the
inﬂuence of correlation ρ in our model. Figure 4 depicts these
environments. To choose the parameters for our model, namely
the coefﬁcients in (8) and (10), we implemented a Real-Coded
Genetic Algorithm (RCGA) where each solution is represented
by a generic chromosome of the type:
µs
a1
a2
b1
b2
ρ
Choosing µs as a decision variable makes for a more straight-
forward analysis of the solution, since µs represents the settling
point for µ, and a0 can be obtained from µs = a0/(1 − a1).
To optimize the model without correlation, ρ is set to 0 and
dropped from the chromosome. Parameters are evolved to
maximize search efﬁciency deﬁned in (13), where P is the total
number of rewards found and D the total distance travelled.
Individuals for crossover are selected by tournament and an
arithmetic crossover operator is used.
η = P/D
(13)
Mutation is done by selecting a random allele and changing its
value randomly between its predeﬁned limits, i.e., µs ∈ (1, 3]
and a1, a2, b1, b2 , ρ ∈ [0, 1]. The RCGA runs over 250
generations with a randomly initialized population of 100 and
a 5% elitism. Results of the optimization process are shown
in Table I, with and without correlation. The ﬁrst observation
we can make is that, as the size of patches increases from
environment I to III, the value of µs decreases. In fact, this
was an expected result, since in an environment where patches
118
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-781-8
ADAPTIVE 2020 : The Twelfth International Conference on Adaptive and Self-Adaptive Systems and Applications

Figure 4. Environments with uniformly distributed rewards.
TABLE I. PARAMETERS OPTIMIZED FOR ENVRIONMENTS I,II AND III.
Environment
µs
a1
a2
b1
b2
ρ
I
2.344
0.196
0.179
0.995
0.235
—
2.422
0.216
0.599
0.962
0.424
0.073
II
1.625
0.503
0.254
0.976
0.185
—
1.809
0.507
0.354
0.917
0.563
0.029
III
1.129
0.841
0.619
0.918
0.191
—
1.428
0.758
0.681
0.904
0.153
0.077
are of considerable size, a strategy that favours more frequent
ballistic motions, will tend ﬁnd new rewards more efﬁciently.
On the other hand, in an environment where patches are very
small, more frequent changes of direction are necessary to
ﬁnd these rewards, and therefore the µs is higher. We also
observe that parameter a1 increases with the increasing size
of patches. Recalling (8), the higher a1 becomes the slower
is the decay of µ(t). An increasing value a1 with patch size
shows that it is beneﬁcial to not let the value of µ(t) decay
too abruptly, sustaining more localized search for a longer
period. Concurrently a2, the weight of the stimulus to the
value of µ(t), also increases. Since µs is smaller for such
environments, the change of µ(t) to a point that translates
into local search needs to occur at a higher rate, and thus
the stimulus has a bigger weight. As for the coefﬁcients that
modulate β, we see that b1 always maintains a high value, but
decreases only slightly with increasing patch size, showing
that a slow decay of the desire to interrupt the current walk
is always desirable regardless of the size of patches. As for
the stimulus to this desire, i.e., the b2 parameter, has a higher
value when patches are smaller. Naturally, given the smaller
size of patches, the weight of the stimulus must be stronger so
that the current walk is interrupted sooner. Perhaps the more
interesting result is the one concerning the correlation ρ. These
results show that ρ always converges to very small values,
hinting that, in patchy environments, directional correlation
between steps might not play a signiﬁcant role. To conﬁrm
this hypothesis we show in Table II the average values for
Efﬁciency, number of Rewards Found and number of Patches
Found, for both the Endocrine-based L´evy Walk (ELW) and its
correlated version (CELW). These results show that, in fact,
even a negligible correlation can have an apparent negative
impact on the overall performance of the system, since the
ELW tends to outperform its correlated counterpart for most
TABLE II. COMPARISON BETWEEN ELW AND CELW OVER 100 RUNS.
Search Behaviour
Efﬁciency

Figure 5. Environments with Gaussian distributed rewards.
TABLE IV. PARAMETERS OPTIMIZED FOR ENVIRONMENTS IV AND V
Environment
µs
a1
a2
b1
b2
IV
1.659
0.152
0.511
0.940
0.499
V
1.445
0.489
0.495
0.980
0.194
The parameters of our model for these environments were
also obtained via the aforementioned RCGA, and are shown
in Table IV. For a fair comparison with the Yuragi model,
we conduct the same sensitivity analysis as Nurzaman et al.
to select the value of R in (5), which maximizes efﬁciency.
These results are summarized in Table V, where we include
the values reported by Nurzaman, in brackets, to validate our
own implementation. In the following analysis, we refer to
Yuragi A/B or C depending on which R is best suited for
a particular environment. Table V shows that Yuragi-A is
best suited for Environments II, IV and IV, and Yuragi-B for
Environments I and III. We also note that the values obtained
with our Yuragi implementation yield very close results to
those reported by Nurzaman, validating our implementation
for the subsequent analysis. Finally, the comparison between
the ELW and Yuragi approaches is presented in Table VI.
This table compares the results obtained with the optimized
ELW model for each particular environment (ELW-I, ELW-II,
etc.) with the corresponding Yuragi model chosen from the
sensitivity analysis in Table V. Highlighted values for each
metric show that the ELW always yields best performance
both across the different metrics and different environments.
However, one could still argue that our model requires prior
knowledge in order to select optimal parameters for the task.
To address this question, we perform a cross-testing analysis
and run each ELW model (ELW-I, ELW-II, etc.) in every
environment, and compare those results, both with the optimal
results for such environment, and with those achieved with
the Yuragi approach. This comparison is made in Table VII,
where the optimal efﬁciency values for each environment
are highlighted in green and the best Yuragi approach for
each environment is highlighted in red. Furthermore, we also
highlight the performance obtained with ELW-II and ELW-
IV, since these are able to consistently outperform the best
Yuragi solution, even in those environments for which the
ELW was not speciﬁcally optimized. The existence of sets
of ELW parameters that lead to a higher performance, in
comparison to the Yuragi approach, and regardless of the
environment is an important evidence of the superiority of the
TABLE V. SENSITIVITY ANALYSIS ON EFFICIENCY WITH VARYING R
Model
R
Env I
Env II
Env III
Env IV
Env V
A
0.99
0.26±0.11
8.98±2.38
19.74±3.51
0.35±0.13
3.93±0.99
(0.23±0.11)
B
0.90
0.29±0.10
7.41±1.98
24.07±4.48
0.29±0.11
3.19±0.89
(0.28±0.11)
C
0.50
0.21±0.09
6.72±1.61
20.70±4.69
0.24±0.10
2.49±0.79
(0.17±0.06)
TABLE VI. METRIC COMPARISON BETWEEN YURAGI AND ELW
Search behaviour
Efﬁciency

TABLE VII. CROSS-TESTING OF ELW PARAMETERS ACROSS ENVIRONMENTS.
Search Behaviour
Metric
Environment I
Environment II
Environment III
Environment IV
Environment V
ELW-I
Efﬁciency (10−2)
0.42±0.12
10.09±1.74
20.64±2.63
0.37±0.15
4.40±0.81
Rewards Found (102)
4.18±1.13
72.70±9.97
124.68±12.17
3.59±1.30
34.00±5.42
Patches Found
7.48±1.56
6.01±1.04
3.91±1.73
5.18±1.62
6.83±1.17
Efﬁciency (10−2)
0.40±0.10
15.02±2.14
38.81±3.74
0.38±0.11
6.17±0.92
Rewards Found (102)
3.92±0.99
126.50±11.32
266.51±18.25
3.73±1.05
55.92±7.74
ELW-II
Patches Found
7.27±1.43
9.58±0.21
8.59±1.08
7.08±1.38
9.80±0.47
ELW-III
Efﬁciency (10−2)
0.24±0.07
9.98±1.73
39.93±4.78
0.21±0.07
3.82±0.64
Rewards Found (102)
2.36±0.69
98.12±16.84
372.39±42.00
2.18±0.78
37.82±6.35
Patches Found
7.56±1.32
9.85±1.03
9.95±0.21
7.10±1.57
9.93±0.32
Efﬁciency (10−2
0.41±0.10
12.92±2.02
38.22±3.46
0.39±0.01
5.20±0.79
Rewards Found (102)
4.16±0.95
113.35±15.87
276.95±18.67
3.83±0.97
48.12±6.85
ELW-IV
Patches Found
7.32±1.29
9.87±0.37
9.49±0.67
6.89±1.29
9.85±0.36
ELW-V
Efﬁciency (10−2
0.36±0.11
15.01±1.87
39.01±3.61
0.35±0.11
6.21±0.85
Rewards Found (102)
3.60±1.12
127.10±13.51
274.55±17.48
3.56±1.11
56.71±7.13
Patches Found
6.98±1.50
9.66±0.55
8.87±0.87
7.12±1.45
9.73±0.46
Yuragi-A
Efﬁciency (10−2)
0.26±0.11
8.98±2.38
19.74±3.51
0.35±0.13
3.93±0.99
Rewards Found (102)
2.01±1.01
64.40±14.51
121.61±16.64
3.03±1.12
29.91±6.67
Patches Found
4.81±1.16
6.03±1.31
3.86±1.4
4.45±1.37
6.19±1.41
Yuragi-B
Efﬁciency (10−2)
0.29±0.10
7.41±1.98
24.07±4.48
0.29±0.11
3.19±0.89
Rewards Found (102)
2.61±1.01
61.80±15.68
180.59±29.03
2.58±0.95
27.17±7.29
Patches Found
5.20±1.53
7.19±1.41
6.07±1.48
4.85±1.45
7.43±1.65
REFERENCES
[1]
A. M. Reynolds and C. J. Rhodes, “The l´evy ﬂight paradigm: random
search patterns and mechanisms,” Ecology, vol. 90, no. 4, 2009, pp.
877–887.
[2]
H. C. Berg, Random walks in biology.
Princeton University Press, 93.
[3]
F. Bartumeus, M. G. E. da Luz, G. M. Viswanathan, and J. Catalan,
“Animal search strategies: a quantitative random-walk analysis,” Ecol-
ogy, vol. 86, no. 11, 2005, pp. 3078–3087.
[4]
P. Bovet and S. Benhamou, “Spatial analysis of animals’ movements
using a correlated random walk model,” Journal of theoretical biology,
vol. 131, no. 4, 1988, pp. 419–433.
[5]
G. Viswanathan et al., “L´evy ﬂights in random searches,” Physica A:
Statistical Mechanics and its Applications, vol. 282, no. 1-2, 2000, pp.
1–12.
[6]
O. B´enichou, C. Loverdo, M. Moreau, and R. Voituriez, “Intermittent
search strategies,” Reviews of Modern Physics, vol. 83, no. 1, 2011,
pp. 82–127.
[7]
G. M. Fricke, F. Asperti-Boursin, J. Hecker, J. Cannon, and M. Moses,
“From microbiology to microcontrollers: Robot search patterns inspired
by t cell movement,” in Artiﬁcial Life Conference Proceedings 13. MIT
Press, 2013, pp. 1009–1016.
[8]
V. Fioriti, F. Fratichini, S. Chiesa, and C. Moriconi, “Levy foraging in a
dynamic environment–extending the levy search,” International Journal
of Advanced Robotic Systems, vol. 12, no. 7, 2015, pp. 98–110.
[9]
M. E. Wosniack, M. C. Santos, E. P. Raposo, G. M. Viswanathan, and
M. G. da Luz, “The evolutionary origins of l´evy walk foraging,” PLoS
computational biology, vol. 13, no. 10, 2017, pp. 1–31.
[10]
V. K. Jandhyala and S. B. Fotopoulos, “Applications of random search
methods to foraging in ecological environments and other natural
phenomena–a review,” Environmetrics, vol. 29, no. 5-6, 2018, pp. 1–12.
[11]
F. Castaldi, F. Pelosi, S. Pascucci, and R. Casa, “Assessing the potential
of images from unmanned aerial vehicles (uav) to support herbicide
patch spraying in maize,” Precision Agriculture, vol. 18, no. 1, 2017,
pp. 76–94.
[12]
E. Danchin, L.-A. Giraldeau, and F. C´ezilly, Behavioural ecology, 2008.
[13]
J. Wawerla and R. T. Vaughan, “Robot task switching under diminishing
returns,” in IEEE/RSJ ICIRS, 2009, pp. 5033–5038.
[14]
W. Ashby, Design for a brain: The origin of adaptive behaviour.
Springer Science & Business Media, 2013.
[15]
P. L. deFur, “Use and role of invertebrate models in endocrine disruptor
research and testing,” ILAR journal, vol. 45, no. 4, 2004, pp. 484–493.
[16]
P. A. Vargas, R. C. Moioli, F. J. Von Zuben, and P. Husbands, “Home-
ostasis and evolution together dealing with novelties and managing
disruptions,” Int. J. Intel. Comp. and Cyb., 2009, pp. 435–454.
[17]
P. Vargas et al., “Artiﬁcial homeostatic system: a novel approach,” in
ECAL.
Springer, 2005, pp. 754–764.
[18]
F. Bartumeus, “L´evy processes in animal movement: an evolutionary
hypothesis,” Fractals, vol. 15, no. 02, 2007, pp. 151–162.
[19]
S. G. Nurzaman et al., “An adaptive switching behavior between levy
and brownian random search in a mobile robot based on biological
ﬂuctuation,” in 2010 IEEE/RSJ International Conference on Intelligent
Robots and Systems.
IEEE, 2010, pp. 1927–1934.
[20]
C. Dimidov, G. Oriolo, and V. Trianni, “Random walks in swarm
robotics: an experiment with kilobots,” in International Conference on
Swarm Intelligence.
Springer, 2016, pp. 185–196.
[21]
J. Wilson, J. Timmis, and A. Tyrrell, “A hormone arbitration system
for energy efﬁcient foraging in robot swarms,” in Annual Conference
Towards Autonomous Robotic Systems.
Springer, 2018, pp. 305–316.
[22]
J. Stradner, H. Hamann, T. Schmickl, and K. Crailsheim, “Analysis and
implementation of an artiﬁcial homeostatic hormone system: A ﬁrst case
study in robotic hardware,” in IEEE/RSJ ICIRS, 2009, pp. 595–600.
[23]
V. Trianni, E. Tuci, C. Ampatzis, and M. Dorigo, “Evolutionary swarm
robotics: A theoretical and methodological itinerary from individual
neurocontrollers to collective behaviors,” The Horizons of Evolutionary
Robotics, 2014, pp. 153–178.
121
Copyright (c) IARIA, 2020.     ISBN:  978-1-61208-781-8
ADAPTIVE 2020 : The Twelfth International Conference on Adaptive and Self-Adaptive Systems and Applications

