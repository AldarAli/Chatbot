A Multi-Agent Approach for Self-adaptive MRI Segmentation
Mohamed T. Bennai∗†, Smaine Mazouzi‡, Zahia Guessoum†§,
Mohamed Mezghiche∗ and St´ephane Cormier†
∗ LIMOSE Laboratory, University M’Hamed Bougara, Boumerd`es, Algeria
† CReSTIC, Reims Champagne Ardenne University, Riems, France
‡ Department of Computer Science, University of Skikda, Skikda, Algeria
§LIP6, Sorbonne University, Paris, France
email: m.bennai@univ-boumerdes.dz
Abstract—Medical image processing provides an important help
for establishing diagnoses for several pathologies. In medical
imagery, image segmentation is crucial for several applications
such as lesion detection and delimitation, and tracking of disease
evolution. Different image segmentation approaches have been
proposed. However, the segmentation parameters are beforehand
adjusted in most of those approaches. The latter do not allow
the segmentation process to handle all the situations that can
be found in the images. The goal of this paper is to introduce
a new multi-agent approach for self-adaptive segmentation of
Magnetic Resonance Image (MRI) data. Our approach is based
on situated agents that interact together, and where each agent
can perform discontinuity detection or similarity detection. Each
agent parameters rely on its location in the image. That approach
was implemented and tested on MRI data, and the ﬁrst results
are promising.
Keywords–Image processing, image segmentation, multi-agent
systems, Self-adaptation.
I.
INTRODUCTION
In the last decades, medical image processing was one of
the most active research ﬁelds in computer science. Segmenta-
tion is the most important and critical stage of the image pro-
cessing. The high diversity of images and the inhomogeneity
of artefacts’ distribution within the images, such as noise and
Intensity Non-Uniformity (INU) in Magnetic Resonance Image
(MRI), require the segmentation process to be adaptive so that
it can handle both the expected situations and unexpected ones.
Segmentation consists in partitioning a digital image into a
set of separated regions, and it is mainly used to extract objects
of interest present in an image. Several image segmentation
methods were published in the literature. Those segmentation
methods are mainly classiﬁed as follows [1]:
•
Edge-based segmentation: Edge-based methods aim
to ﬁnd the places of rapid transition from one to
other regions of different brightness or color value
[2]. The edge is determined by the extreme of the
ﬁrst order derivative or a zero crossing in the second
order derivative of the pixels’ intensity function [3].
One of the ﬁrst and most efﬁcient techniques, in this
approach, is the Canny edge detection algorithm [4].
•
Region-based segmentation: Region based segmenta-
tion methods use a set of predeﬁned criteria [3] to de-
compose an image into regions that contain connected
pixels with similar properties. Most of the existing
solutions use spatial information (pixel positions) with
brightness information in the classiﬁcation process of
pixels. One of the most effective techniques is the
region growing algorithm [5].
•
Other techniques: Some of the segmentation methods
described in the literature cannot be classiﬁed in the
two previous categories. Most of them were borrowed
from other disciplines and applied to image segmenta-
tion problem (genetic algorithm [6], graph theory [7],
neural networks [8], etc.), or multi-agent systems (ant
colonies, particle swarm optimization).
Multi-agent systems offer a set of properties that allow making
image segmentation adaptive. They take into account several
unexpected situations within the same image, or for a set
of images. In recent years, many works have been published
on image segmentation using multi-agent systems (for further
details see [9]). Even if they are able to successfully achieve
the image segmentation task, most of those multi-agent ap-
proaches are based on centralized agents and do not exploit
the full advantages of multi-agent systems such as coordination
mechanisms.
This paper introduce a new multi-agent approach for image
segmentation and its application to MRI data. The system built
with that approach is composed of two types of agents: Dis-
continuity agents and Similarity agents. Discontinuity agents
use image gradient for boundaries detection. Similarity agents
generate then homogeneous regions in an iterative and adaptive
aggregation process. This process uses the results provided by
the discontinuity agents that work on gray level intensity of
pixels. Each agent self-adapts to the image data by tuning the
best parameters according to the part of the image where it is
located.
The paper is organized as follows. Section 2 describes and
analyses existing multi-agent image segmentation approaches
to show that the adaptation in such approaches is an open
issue. Section 3 introduces the proposed multi-agent approach
and we show how agents self-adapt according to the content
of the image where they are located. Section 4 presents the
implementation and the experimental results. Finally, Section
5 summarizes the contribution and describes some perspectives
of this work.
II.
RELATED WORK
Image segmentation is a very active ﬁeld of computer
science. Several approaches have thus been proposed (see
[10]). To improve the efﬁciency of those segmentation ap-
proaches and to explore new ideas, recent works have proposed
to use multi-agent systems to distribute the segmentation
process, allowing adaptive processing in several cases. This
section describes and analyses those multi-agent segmentation
approaches.

Liu and Tang [11] introduced the ﬁrst adaptive approach
for image segmentation. They developed a multi-agent system
based on a set of reactive agents operating in a 2D image.
Agents select their behavior (breeding, moving and vanishing)
according to local stimuli of the environment. Each agent ex-
plores the environment searching for a pixel of a homogeneous
segment. After detecting this pixel, the agent breeds offspring
agents in their neighborhood aiming to ﬁnd the rest of the
segment. Such behaviors is a kind of adaptation to the image
content.
For the approach presented by Duchesnay et al. [12], the
segmentation is performed in two steps:
•
a pre-segmentation (using a quadtree for region de-
tection and an edge detection algorithm for contour
detection),
•
and a merging process (using agents interaction).
In the ﬁrst step, the system generates a set of regions and
contours. They are then used to create a society of agents
that are organized as an irregular pyramid and interact to
make merging decisions. This process is repeated until the
stabilization of the system. Agent self-organization, throw the
merge process, can be considered as a self-adaptation of the
organization according to the extracted segments of the image.
In [13], Germond et al. presented a framework for MRI
image segmentation based on the cooperation of three different
modules (a multi-agent system, a deformable model and an
edge detector). The multi-agent system is composed of two
different types of agents (region agents and edge agents).
Those agents use information provided by the deformable
model and the edge detector. Agents, in this system, adapt their
processing according to the results provided by the previous
modules.
The approach presented by Bourjot et al. [14] uses a swarm
mechanism inspired by the collective web weaving behavior
of social spiders for 2D grayscale image segmentation. The
approach is modeled as a multi-agent system where reactive
agents represent spiders exploring their environment, namely
the input image. During this exploration and according to
their behavior, agents interact together, select one of the
three different actions (move, ﬁx silk and return to web) to
weave webs. Self-switching between behaviors according to
the image data is also a kind of adaptation of agents to different
situations.
Recently Arbai and Allioui [15] proposed a multi-agent
system for the detection of Alzheimer lesions in MRI im-
ages. The system is divided into three main parts: the data,
the knowledge, and the agents. In this conﬁguration, three
different sorts of agents (supervisor agent, analysis agent and
segmentation agent) use the knowledge part to perform the
segmentation of the MRI image according to the data part. This
data represents the input image in addition to some information
extracted with pre-treatment.This approach is based on the
cooperation of agents using different segmentation methods.
Generally, MAS-based image segmentation relies on clas-
sical image segmentation algorithms. They encapsulate those
algorithms in agents. They then endow those agents with
interaction and coordination mechanisms to reach the global
goal which is the partition of an image into its structural parts.
However, in most of the published works, authors proceed
by a ﬁxed (off line) parameter tuning for all the parts of the
image where agents process. So, agents perform segmentation
task uniformly in the whole image. Such an approach does
not allow processing images where artefacts are not uniformly
distributed, such as MRI data.
In this work, we introduce a novel approach that allows
agents to self-adapt to the image data, so the processing will
be speciﬁc to each part of the image where an agent operates.
III.
A NEW MAS APPROACH
In the proposed multi-agent based approach, segmentation
is based on the collaboration of different types of agents.
The latter are situated in an environment, which is a two
dimension MRI image. Those agents interact to achieve the
image segmentation. Two kinds of agents are used and are built
aiming to get beneﬁts on the discontinuity and the similarity
properties of pixels. The discontinuity allows ﬁnding boundary
pixels of regions, while the similarity allows the agglomeration
of all pixels sharing a similar gray level intensity. The two
populations of agents cooperate to accomplish their goal: parti-
tioning the image into homogeneous regions. The segmentation
process is described in Figure 1. The two main phases of the
system are: discontinuities detection and similarities detection.
Figure 1. The two stages of image segmentation.

We show, in the following subsection, that similarity agents
are self-adaptive and perform region growing according to the
sub-region where they are situated. Each agent calculates the
used parameters according to the artefacts in the part of the
image where it operates, namely the noise and the Intensity
Non-Uniformity (INU).
A. Discontinuity detection
Discontinuity agents (DAgents) are created and uniformly
dispersed on the image. The image is decomposed in areas,
where each one is associated with a DAgent. DAgents are
thus situated; they execute their behavior without moving from
their positions. They ﬁrst calculate the standard-deviation of
the image data at the pixels in their respective areas. If the
calculated standard-deviation is bellow a given threshold, each
agent labels all the pixels of its area as probably region pixels
(Class 1). Otherwise, the agent estimates the gradient of the
pixels included in its area using a Sobel Filter [16]. The
gradient is then used to perform a k-mean clustering. Pixels
with high gradient are labeled as boundary pixels (Class 2),
pixels with low gradient are labeled as region pixels (Class 1).
Finally, DAgent chooses in its area the pixel (labeled C1) with
the lowest gradient and creates a Similarity Agent (SAgent)
on that position, and provides it the pixel similarity threshold
(PST) which is set to the standard-deviation of its area.
B. Similarities detection
SAgents are mobile agents exploring the image, seeking
homogeneous regions to detect and to delimit. The agent
behavior and parameters are deﬁned so that the regions of
the image can be extracted despite the alterations it contains,
which are the INU and the noise. After their creation, the
agents start their activity using the following behavior:
1)
Exploration: A SAgent explores its environment
searching for a seed pixel. A seed pixel is a Class
1 pixel with no Class 2 pixels in its neighborhood.
The size of the neighborhood can be set manualy
according to the content nature of the processed
images. It is low (3 x 3) for images that contain a
lot of details such as outdoor images, and it is higher
for images with vast homogeneous regions such in
several medical images. When encountering a seed
pixel, the SAgent switches to the next behavior.
2)
Region Growing: The method used in this step was
partially inspired by the work of Pohle and Toen-
nies [17]. Firstly, starting from its initial position,
a SAgent uses a random walk to self-adapt to the
homogeneous region in which it is moving, and
estimates its features. During this walk, the SAgent
considers all the encountered Class1 pixels with a
similar gray level, up to the threshold PST. The latter
depends on the SAgent, and it was communicated
by the DAgent. Its value depends on the intensity
of the pixels forming the neighborhood of the seed.
Secondly, the SAgent uses the set of explored pixels
to calculate the features of its region (i). The used
features are the gray level mean Ei and the standard
derivation σi. Finally, these features are used to per-
form a standard region growing. The SAgent, starting
from its seed pixel, iteratively adds to its region,
all the surrounding pixels satisfying the assimilation
predicate P and then, updates its region.
P(Pixel) =
(
true
if I(P) ∈ [Ei ± (σi × α)]
false
otherwise
where I(P) is the intensity of the pixel P, and α is an
adjustment parameter. This processing is iterated until
no more adjacent pixels can be added. The result of
this step is generally an over-segmented image with
too many regions. This over-segmentation has to be
reﬁned using a merge operation.
3)
Region Merge: In this step, The SAgents interact
together to expand their regions by merging with
those of their neighbors. Two SAgents are considered
as neighbor if they have adjacent region borders.
During their interaction, the SAgents use the contract
net protocol [18] to evaluate the relevance of the
merge of their two regions. Each SAgent evaluates
the beneﬁts of a merge by comparing the standard-
derivation of its region before and after the merge.
All possible merges are considered, and the SAgent
selects the one that minimizes the resulting standard
derivation. Then, the SAgent performs the merge of
its region and the chosen one. Lastly, the agent that
has performed the merge updates its list of neighbors
and starts looking for another merge, while the other
agent (involved in the merge) will be deactivated.
The process is repeated wwhile a merge is possible
between two neighbors.
4)
Region Finalization: the purpose of this step is to
calculate the ﬁnal borders of the detected regions. It
also allows the smoothing of the obtained regions.
Each SAgent browses the pixels situated inside its
region that were initially excluded during the region
growing step. The SAgent then assimilates all the pix-
els that satisfy the assimilation condition according to
the new region assimilation parameters.
When no more agents are active, the system stops and the
set of the non-overlapping obtained regions are displayed.
Similarity agents self-adapt to the levels of the artefacts in
their respective sub-regions by calculating and using suitable
parameters. In classical methods for MRI segmentation, a ﬁrst
stage for INU elimination must be performed, where it is
not always successful and it is time-consuming because of its
iterative nature
IV.
IMPLEMENTATION AND EXPERIMENTS
For the implementation of our approach, we choose to start
from scratch instead of using an existing platform such as
JADE or MADKIT. Our Multi-agent system is composed of
reactive agents with simple behavior and very low commu-
nication. Thus, we use the CSharp language and Microsoft
.Net Framework to implement our agents as generic classes.
We believe that this implementation allows us to keep full
control of the system and allows optimizing its performance.
C Sharp has already been used in multi-agent simulations [19]
and it provides an efﬁcient, reliable, and easy to program agent
framework for the development agent-based applications [20].
To validate the efﬁciency of the implemented approach,
some MR images from the Brain Web dataset are used.

Experiments are performed on a PC with an I7 1.9 GHz
processor and 8 GB RAM.
For our experiments, we choose the Brainweb phantom
database that it is a MRI dataset produced by McConnell
Brain Imaging Center at Montreal Neurological Institute [21].
It provides different simulated brain phantom volumes, with
different simulation options among which values of noise
and intensity non-uniformity. In our experiments, we use bi-
dimensional slices extracted from T1 MRI with an image size
181x217, and a pixel size of 1mm x 1mm. Those images are
generated in 9 versions by varying the level of noise ( 5%,
7%, 9%) the level of intensity non-uniformity (0%, 20%, 40%)
called INU. The image shown in Figure 2a is a slice of an MRI.
It is an image with a high level of noise. It is provided to
the implemented multi-agent segmentation system as an input
image. The system uses then the approach described in the
previous section. First, we show, in Figure 2b, the different
regions forming the brain tissues by averaging the intensities
within the slice. Figure 2c represents a binary image of the
contours that are generated at the ﬁrst step of the segmentation
process by the population of DAgents. Figure 2d introduces the
region corresponding to the white matter tissue of the brain at
this slice. We can notice that despite the high level on the
artefacts, the region was well delimited.
Figure 3 and Figure 4 introduce the results with two MRI
from the same dataset, with higher levels of INU (respectively
20% and 40%) and the high level of noise (5%). We can note
that despite such high level of deformation (Figures 3a,4a),
the obtained region contours, and the extracted white matter
region, introduced respectively in Figures 3c, 4c and Figures
3d, 4d were correctly computed.
(a) MRI Slice
(b) Average Gray Level
(c) Detected Edges
(d) WM Region
Figure 2. Segmentation example of a MRI slice with 5% of noise level and
0% INU.
(a) MRI Slice
(b) Average Gray Level
(c) Detected Edges
(d) WM Region
Figure 3. Segmentation example of a MRI slice with 5% of noise level and
20% INU.
(a) MRI Slice
(b) Average Gray Level
(c) Detected Edges
(d) WM Region
Figure 4. Segmentation example of a MRI slice with 5% of noise level and
40% INU.

According to the visual results, we can note the potential
of our approach to segment MRI data, by considering the
whole volume, slice per slice. In particular, we have faced
the INU problem in MRI by making agents self-adapt to their
respective sub-regions, so the artefact was efﬁciently treated.
To quantitatively evaluate our approach, we conducted a set
of tests using the κ-coefﬁcient (kappa), also known as Dice
similarity coefﬁcient as the evaluation metric for the White
Matter region extraction. This coefﬁcient is commonly used in
the medical image processing to evaluate the performance of
segmentation algorithms which has a predeﬁned ground truth
information or dataset. It is calculated using the following
formula [22]:
κ =
2 ∗ TP
(2 ∗ TP) + FP + FN
(1)
where TP, FP and FN are the numbers respectively of True
Positive, False Positive and False Negative instances of pixel
labeling. The value of the κ coefﬁcient well expresses the
segmentation quality.
The results of our experiments are presented in Table I:
TABLE I. κ Coefﬁcient calculated for white matter extraction with different
noise and INU levels
INU levels
Noise levels
0%
20%
40%
κ for 5%
93,4
94,9
94,7
κ for 7%
91,5
90,4
92,0
κ for 9%
91,2
89,5
90,5,
 82
 84
 86
 88
 90
 92
 94
00%
20%
40%
Kappa Coefficient
INU Level
5%
7%
9%
Figure 5. κ coefﬁcient evolution for White Matter extraction with different
noise and INU levels
Table I and Figure 5 show the effectiveness of our approach
for the White Mater despite the increase in artefact levels
occurring in the processed image. The obtained results show
that the increase in noise level has an impact on the quality
of the extraction, which is acceptable at such levels (5%, 7%
and 9%). This incidence is still minor compared to the level of
image degradation. Figure 5 also illustrates the robustness of
the approach against the INU artefact of the segmented image.
It thus reﬂects the adaptation that our system can demonstrate
in the execution of its task.
In addition to the intrinsic evaluation, we evaluate the qual-
ity of our results by comparing them to the ones obtained from
other segmentation methods published in the literature. For this
purpose, we used the comparison data provided by Yazdani et
al. [23]. The results introduced in [23] concern volumic data,
while ours are obtained from 2D slices. Nevertheless, this does
not signiﬁcantly affect the κ coefﬁcient in our case because it
is based on ratios of large sets of pixels or voxels.
TABLE II. κ Coefﬁcient calculated for white matter extraction with different
noise levels and 20% INU level
Noise level
Approches
5%
7%
9%
Our System
92,0
94,0
93,0
EM
92,2
90,1
86,4
SPM 5
93,6
90,2
86,3
HMC
93,9
92,3
91,7
Fast
94,8
94,3
91,9
FCM
92,0
88,0
84,0
NL-FCM
91,5
89,8
83,2
UFBSMRI
94,9
94,4
92,2
 80
 82
 84
 86
 88
 90
 92
 94
 96
5%
7%
9%
Kappa Coefficient
Noise
Our-System
EM
SPM-5
HMC
Fast
FCM
NL-FCM
UFBSMRI
Figure 6. κ coefﬁcient evolution for White Matter extraction with different
noise levels and 20% INU level with different approaches
In Table II and Figure 6, we can note that our multi-
agent system has acceptable results and has a good robustness
against increasing noise, compared to the methods involved in
the comparison. Due to the absence of data concerning the
other approaches for various INU levels, we were only able to
compare our results according to only 20% INU level.
With these results, we can assume that due to their capa-
bility of self-adaptation to their respective regions, the agents
of our approach do not need training data. Such a feature
allows the method to be usable for different images with
several artefact levels, without previous training. Also, agents
are weakly coupled, so they permit the physical distribution of
the method.

V.
CONCLUSION AND FUTURE WORKS
In this paper, we proposed a new multi-agent approach for
MRI segmentation. That approach is based on two different
populations of agents: Discontinuity Agents (DAgents) and
Similarity Agents (SAgents). These different agents interact
in an environment, namely the image, to perform its segmen-
tation. DAgents use image gradient and k-means classiﬁcation
to distinguish boundary pixels from region ones. SAgents use
then the resulting classiﬁcation during the region detection pro-
cess. SAgents start with an adaptive region growing algorithm,
where agents are competing to expand their regions. When no
more expansion is possible, SAgents collaborate the merge
their regions.
The proposed multi-agent approach does not require any
human interaction during the image segmentation. It also self-
adapts to different levels of image artefacts. Other advantages
of our approach are its capability of detecting many regions
in parallel during the segmentation process and its robustness
to noise and INU. Our approach gives promising issues for
the segmentation of different kinds of images. However, this
approach still suffers from some limitations such as the set-
ting of some parameters. Moreover, Other self-adaptive agent
strategies, such as social utility, will be considered in future
works.
REFERENCES
[1]
D. D. Patil and S. G. Deore, “Medical image segmentation: a review,”
International Journal of Computer Science and Mobile Computing,
vol. 2, no. 1, 2013, pp. 22–27.
[2]
S. Dantulwar and R. Krishna, “Performance analysis using single seeded
region growing algorithm,” International Journal of Innovative Research
in Advanced Engineering, vol. 1, no. 6, 2014, pp. 2349–2163.
[3]
G. E. Suji, Y. V. S. Lakshimi, and G. W. Jiji, “Image segmentation
algorithms on mr brain images,” International Journal of Computer
Applications, vol. 67, no. 16, April 2013, pp. 18–20.
[4]
J. Canny, “A computational approach to edge detection,” IEEE Trans-
actions on pattern analysis and machine intelligence, no. 6, 1986, pp.
679–698.
[5]
R. Adams and L. Bischof, “Seeded region growing,” IEEE Transactions
on pattern analysis and machine intelligence, vol. 16, no. 6, 1994, pp.
641–647.
[6]
B. Bhanu, S. Lee, and J. Ming, “Adaptive image segmentation using
a genetic algorithm,” IEEE Trans. Systems, Man, and Cybernetics,
vol. 25, no. 12, 1995, pp. 1543–1567.
[7]
Z. Wu and R. Leahy, “An optimal graph theoretic approach to data
clustering: Theory and its application to image segmentation,” IEEE
transactions on pattern analysis and machine intelligence, vol. 15,
no. 11, 1993, pp. 1101–1113.
[8]
A. N. Skourikhine, L. Prasad, and B. R. Schlei, “Neural network for
image segmentation,” in Applications and Science of Neural Networks,
Fuzzy Systems, and Evolutionary Computation III, vol. 4120.
Inter-
national Society for Optics and Photonics, 2000, pp. 28–36.
[9]
M. Amahrir, M. A. Sabri, and A. Aarab, “A review on image segmenta-
tion based on multi-agent systems,” in Intelligent Systems Conference
(IntelliSys), 2017.
IEEE, 2017, pp. 614–621.
[10]
N. M. Zaitoun and M. J. Aqel, “Survey on image segmentation
techniques,” Procedia Computer Science, vol. 65, 2015, pp. 797–806.
[11]
J. Liu and Y. Y. Tang, “Adaptive image segmentation with distributed
behavior-based agents,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 21, no. 6, 2002, pp. 544–551.
[12]
E. Duchesnay, J.-J. Montois, and Y. Jacquelet, “Cooperative agents soci-
ety organized as an irregular pyramid: A mammography segmentation
application,” Pattern Recognition Letters, vol. 24, no. 14, 2003, pp.
2435–2445.
[13]
L. Germond, M. Dojat, C. Taylor, and C. Garbay, “A cooperative
framework for segmentation of mri brain scans,” Artiﬁcial Intelligence
in Medicine, vol. 20, no. 1, 2000, pp. 77–93.
[14]
C. Bourjot, V. Chevrier, and V. Thomas, “A new swarm mechanism
based on social spiders colonies: from web weaving to region detection,”
Web Intelligence and Agent Systems: An International Journal, vol. 1,
no. 1, 2003, pp. 47–64.
[15]
K. Arbai and H. Allioui, “Mri images segmentation for alzheimer
detection using multi-agent systems,” in Advanced Intelligent Systems
for Sustainable Development (AI2SD’2018), M. Ezziyyani, Ed. Cham:
Springer International Publishing, 2019, pp. 298–313.
[16]
I. Sobel and G. Feldman, “A 3x3 isotropic gradient operator for image
processing,” a talk at the Stanford Artiﬁcial Project in, 1968, pp. 271–
272.
[17]
R. Pohle and K. D. Toennies, “Segmentation of medical images using
adaptive region growing,” in Medical Imaging.
International Society
for Optics and Photonics, 2001, pp. 1337–1346.
[18]
R. G. Smith, “The contract net protocol: High-level communication
and control in a distributed problem solver,” IEEE Trans. Computers,
vol. 29, no. 12, 1980, pp. 1104–1113.
[19]
R. Nourjou and M. Hatayama, “Simulation of an organization of spatial
intelligent agents in the visual c# .net framework,” International Journal
of Computer Theory and Engineering, IJCTE, vol. 6, no. 5, 2014, pp.
426–431.
[20]
A. Grosso, A. Gozzi, M. Coccoli, and A. Boccalatte, “An agent
programming framework based on the c# language and the cli,” in 1st
Int. Workshop on C# and .NET Technologies on Algorithms, Computer
Graphics, Visualization, Computer Vision and Distributed Computing,
Plzen, Czech Republic, vol. 1, no. 1-3, 2003, pp. 13–20.
[21]
D. L. Collins et al., “Design and construction of a realistic digital brain
phantom,” IEEE transactions on medical imaging, vol. 17, no. 3, 1998,
pp. 463–468.
[22]
M.
T.
Bennai,
Z.
Guessoum,
S.
Mazouzi,
S.
Cormier,
and
M. Mezghiche, “Towards a generic multi-agent approach for medical
image segmentation,” in International Conference on Principles and
Practice of Multi-Agent Systems.
Springer, 2017, pp. 198–211.
[23]
S. Yazdani, R. Yusof, A. Karimian, A. H. Riazi, and M. Bennamoun, “A
uniﬁed framework for brain segmentation in mr images,” Computational
and mathematical methods in medicine, vol. 2015, 2015, Article ID:
829893, URL: https://www.hindawi.com/journals/cmmm/2015/829893/
[accessed: 2019-04-08].

