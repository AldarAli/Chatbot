User-assisted Semantic Interoperability in Internet of Things 
Visually-facilitated Ontology Alignment through Visually-enriched Ontology and Thing Descriptions 
 
Oleksiy Khriyenko, Vagan Terziyan, Olena Kaikova 
IOG group, MIT Department and Agora Center 
University of Jyväskylä, P.O. Box 35 (Agora) 
FIN-40014 Jyväskylä, Finland 
e-mail: oleksiy.khriyenko@jyu.fi, vagan.terziyan@jyu.fi, olena.o.kaikova@jyu.fi  
 
 
Abstract — Today, we make a separation between the 
real/physical world and the Internet. It is time for these two be 
blended and provide ubiquitous access and interoperability 
online. We are approaching Internet of Things - a forthcoming 
technological revolution that will radically change our 
environment and enable innovative applications and services. 
To make this happen, we have to eliminate the fragmentation 
in used technologies and have to make the devices be used 
across various applications and services. We need to find a way 
to actually carry out the necessary and massive deployment of 
ubiquitous devices. So we need to put more effort into the 
design of tools to automate deployment and configuration of 
devices. This paper tackled a problem of an effective way to 
support interoperability in Internet of Things. We propose 
visually-enriched 
approach 
for 
user-powered 
ontology 
alignment and semantic description of Things. 
Keywords-Mashup supported semantic visual mapping; 
visual ontology alignment; visual semantic human interface; 
semantic interoperability. 
I. 
 INTRODUCTION 
With a purpose to better understand the need of proposed 
contribution, let us start with short samples of use case 
scenarios: 
Scenario 1: Person is traveling by car. Suddenly 
something is happened with the car and it needs to be 
repaired. Instead of searching nearest car service station, 
booking a time and filling a request form describing current 
state of the car; the car itself searches for correspondent 
services in the web, collects necessary data from the 
correspondent modules of the car and books a time for 
maintenance service. During the maintenance, car gets new 
spare-parts and integrates them to the central diagnostic 
system of the car (regardless of the fact that parts are 
produced by different vendors). In the same manner, car 
might negotiate and book appropriate time for annual 
technical check-up taking into account timetable of the 
owner, been connected to his/her personal organizer. During 
the trip, cat might suggest optimized schedule of refueling 
taking into account fuel consumption, location of gasoline 
stations and their prices, discounts and bonuses available for 
the driver and other relevant contextual information.  
Scenario 2: Person has bought “smart-home” system 
from some vendor. Vendor installs smart-home network 
with a set of smart-entities (sensors and actuators) and one 
control unit. So far, all the elements of the network belong 
to the same vendor and interoperate via the same ontology 
and communication protocol. A couple of month later, 
house owner buys a new smart-entity for good price from 
another vendor and connects it to the existing network. 
Later, friend of the house owner suggests some generic 
software application, which could be used as an upgrade of 
the smart-home network control unit and provides new 
useful features in comparison to the functionality of initial 
software of the control unit. This software application is 
produced by totally different vendor, and still can be 
installed to the control unit and communicate with all the 
connected to the smart-home network entities.        
Scenario 3: Person has several measurement units 
(produced by different vendors) that can measure his/her 
heartbeat rate, arterial pressure, distance person walked or 
run, and some other parameters related to his/her health 
condition and physical activities. Person easily connects all 
these devices to a smart-phone to be able to log and observe 
them. Later, from an application store, person buys an 
application that suggests correspondent diet, taking into 
account all the measured personal data. Entering a 
supermarket and to be connected to the local infrastructure 
of it, application starts to navigate person to the 
correspondent location of the suitable products for his/her 
diet or alert the person when he/she puts to the basket a 
product which consists inappropriate ingredients.               
All mentioned above stories are not fantasies. It is our 
tomorrow and, in some cases, even our today. Unfortunately, 
in case of our today, we have integration of systems 
produced 
by 
the 
same 
vendor. 
Supporting 
one 
interoperability modem in several products, vendor creates 
integrated environment for various applications and 
interaction scenarios to be run on it. All these applications 
should support correspondent predefined API and data 
model. But, it is not what we expect to be in our tomorrow. 
We need an open environment with possibility to integrate 
various 
systems 
and 
components 
(hardware, 
apps, 
communication channels, etc.) produced by different vendors 
(see Figure 1). With a goal to achieve such requirements, we 
104
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

are approaching Internet of Things (IoT) - a forthcoming 
technological revolution that will radically change our 
environment and enable innovative applications and services.  
Above the personal level, the IoT will also have an 
important impact on enterprises and on society in general. 
IoT will enable a global connectivity between physical 
objects (connecting “things”, not only places or people), will 
bring real-time machine-published information to the Web, 
as well as will enable a better interaction of people with the 
physical environment by combining ubiquitous access with 
ubiquitous intelligence. IoT will consist of a heterogeneous 
set of devices and communication strategies between them. 
Such a heterogeneous system should evolve into a more 
structured set of solutions, where “things” are uniformly 
discoverable, enabled to communicate with other entities, 
and are closely integrated with Internet infrastructure and 
services, regardless of the particular way (RFIDs, sensors, 
embedded devices) in which they are connected to the IoT.  
In this context, one of the challenging bottlenecks is to 
support interoperability between “entities” on a semantic 
level [1][2]. Therefore, in this paper we propose an approach 
towards visually-enriched semantics as an infrastructure for 
user-powered semantic technology enhancement. 
Paper consists of two main sections. Section 2 addresses 
semantic integration platform for IoT and a vision of user-
powered consumption of semantic technologies. Section 3 
presents a human-assisted ontology alignment approach.  
II. 
THING INTEGRATION ENVIRONMENT 
A. Smart Gateway - semantic integration platform for IoT 
We are already in the middle of era of automated 
machine communication. There is already a lot of machine-
to-machine communication going on out there; parking 
meters are connected, and vending machines automatically 
report when new supplies are needed. Every minute huge 
amount of data are being exchanged between machines for 
various purposes within various sectors. However, there is a 
big challenge in moving beyond application-specific devices 
and establishing an information model that will create re-use 
of the data generated by devices for new applications in 
different domains. Finding the right horizontal points in the 
solutions is a key. There are already useful deployments 
within the transport, automotive, building, health and utility 
sectors, but everything is still very sector-specific. We need 
to create an infrastructure that will make information 
generated from a car or a building understandable not only 
within their own specific application/system, but across of 
various applications and domains. 
The IoT will require interoperability at multiple levels. 
On the hardware side, such problems have to be addressed as 
handling a capability mismatch between traditional Internet 
hosts and small devices, as well as handling widely differing 
communication and processing capabilities in different 
devices. In the interface between the device and network 
domains, IoT gateways will provide a common interface 
towards many heterogeneous devices and networks [3]. We 
assume that all “things” (devices, sensors, actuators, etc.) are 
connected to the web. Digital “things” such as services 
usually are accessible through the web. Applications might 
be downloaded and installed to the integration platform - 
Smart Gateway. Thus, we have correspondent requirements 
for such a platform. Smart Gateway should allow installation 
of applications and further configuration of communication 
model with it, based on accompanied annotation of the 
application. In case of services, Smart Gateway should be 
able to access semantic annotation through service access 
point and configure communication model with it as well. 
Talking about physical world objects (device, sensors, 
etc.), usually they are accessible through the gateway - a 
control unit of a network provided by the same vendor. The 
only requirement - gateway should be presented in the web 
as a service with a set of capabilities provided by “things” 
 
Figure 1.  Thing Integration Environment. 
105
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

connected to the gateway (providing data or doing some 
actions). In case we cannot have single “thing” personally 
connected to the web, we should deal with sub-network that 
consists of mentioned “thing” and correspondent gateway. 
Thus, we will have a set of gateways connected to the web 
and ready to become a part of the integration environment. 
Having all the gateways accessible as web-services, all 
connected to them real world “things” become digital entities 
and might be registered to the Smart Gateway. 
Depending on a business model, Smart Gateway might 
be a part of a gateway, provided by certain vendor that would 
like to promote own network solution as en extendable open 
environment for entities produced by other vendors. Having 
Smart Gateway as a part of local network of connected 
“things”, services and applications is a suitable model in case 
of time-limited and highly secured runtime systems. At the 
same time, Smart Gateway might be considered as a separate 
integration solution - services located in the Cloud and 
accessible through the web. Been easily accessible, such 
“thing” integration service might be very popular among 
ordinary people who would like to create and manage their 
own smart spaces, integrate various services with ubiquitous 
“things”. Relevant research has been done in “Smart 
Resource” and “UBIWARE” projects with respect to Global 
Understanding Environment (GUN) [4].           
B. User-powered consumption of semantic technologies 
To achieve the vision of ubiquitous ‘things’, the next 
generation of integration systems will need different methods 
and techniques such as Semantic Web [5][6], Web Services 
[7][8], Mashups [9], Linked Data [10][11], etc.  
Semantic based technologies are viewed today as key 
technologies to resolve the problems of interoperability and 
integration within the heterogeneous world of ubiquitously 
interconnected objects and systems. Semantic Web is a 
vision with an idea of having data on the Web defined and 
linked in a way that it can be used by machines not just for 
display purposes, but for automation, integration and reuse of 
data across various applications. Semantic Web is considered 
as 
a 
standardized 
approach 
to 
achieve 
automated 
interoperability 
of 
heterogeneous 
systems/applications. 
Heterogeneity of systems and various data sources become a 
bottleneck for automated service integration, data processing 
and reuse. To make data ready to be consumed and 
processed by external systems, data sources and data should 
pass through the semantic adaptation [4][12] and be 
accessible in common uniform way. Due to the huge amount 
of application areas that Semantic Web technology tried to 
cover, community started to elaborate different standards and 
techniques to solve interoperability problems. As a result, we 
have a big variety of separated islands of information and 
management systems. These information islands internally 
follow the Semantic Web vision, but are heterogeneous from 
the general (global) interoperability point of view. This leads 
to the fact, that society and especially its business-oriented 
part has started to doubt that such widely spread activity will 
be so much beneficial for them. Only some applications and 
systems in restricted domains became really useful. Most 
probably, the reason for this is the decentralization of 
uncontrolled activities, which creates new problems on the 
way towards ubiquitous Semantic Web. There are no doubts 
that Semantic Web is a very promising technology, but it 
definitely lacks more centralized management or at least an 
environment that plays coordinative and supportive role and 
directs users towards proper technology utilization.  
Services providers, as well as producers of “things”, are 
the end users of the service-oriented technologies. They need 
appropriate controlled support from the infrastructure that 
facilitates interoperability of services/devices, integration of 
heterogeneous data sources, and provides platform for new 
services/application development. Thus, we have to provide 
such a coordinative and supportive environment that will 
facilitate development and growth of service and smart-
entity market. With respect to the current state of the art, we 
cannot expect that community of service providers and 
smart-entity vendors will build one global integration 
infrastructure with common ontology. We cannot expect that 
someone else (alone or in a consortium) will do the same. 
Current achievements in the area of interoperability of 
heterogeneous systems present technologies and tools for 
experts to build and manage adapters between heterogeneous 
systems or their components. Semantic Web is a technology 
for machines to better perform, providing services for human 
in automated or semi-automated way. In a case of 
unavailability of a common data model, we have to deal with 
semi-automated performance of the system when human 
become involved to the process not just as a consumer, but 
as an expert - necessary part in the chain to supervise and 
correct the process performed by machines [13].  
With an increase in the development of ontologies, we 
need tools and techniques for solving heterogeneity problems 
between different ontologies. Therefore we need ontology 
alignment [14][15][16][17], which helps us to bring different 
knowledge representations into mutual agreement. With 
respect to the scenarios mentioned above, ontology 
definitions of all the smart-entities and applications/services 
should be (semi-)automatically aligned by control unit of the 
network to ensure interoperability of them in a unified way. 
Regarding to the mentioned ontology alignment techniques, 
we may expect automatic alignment for simple and similar 
ontologies, but in all other cases, we will definitely need a 
human be involved into the process. This is largely a human-
mediated process. There are existing tools which can help 
with identifying differences among ontologies [18], but user 
interaction is still essential in order to control, approve, and 
optimize the alignment results.  
Unfortunately, approaching the era of ubiquitous services 
and IoT, we cannot expect availability of huge amount of 
professional experts involved to the daily processes of 
“things” interoperability support. We have to find a solution 
to bring technology closer to the ordinary user and make 
him/her able to not only utilize services, but to setup, 
configure and supervise interoperability process. We expect 
a human to be not only an end-user/consumer of technology 
world, but also to become an integral part of it, providing 
own expertise and capabilities. In all mentioned scenarios, 
person (owner of the smart-network) should be able to help 
the system to perform a proper ontology alignment through 
106
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

correspondent human interface of the alignment system. 
Owner of interoperable system does not only consume a 
service delivered by smart machines, but also plays a 
valuable role as a supervisor of interoperability process. 
Therefore, among variety of other adapters between 
heterogeneous entities, bridge to the human (human-to-
machine H2M and machine-to-human M2H interfaces) 
becomes one of the most important tools of next generation 
integration infrastructures. 
Such adaptation of the human to the technology world 
might be provided by Personal Assistant (PA) - supportive 
agent assigned to every user [13]. From one side, it should 
deal with human personality and adapts to his/her personal 
ontology and personal perception of environment. From 
another side, it should support common semantic standards 
and approach to be interoperable with other surrounding 
digital world entities (applications, services and systems). 
The main features of PA (among others) are:  
 
Enabling personal user ontology creation and 
ontology driven resource annotation;  
 
Ability to adjust to the personal user ontology, to the 
way user perceives the environment, information and 
knowledge; 
 
Ability to build personalized semantic mind-map 
based on user behavior and preferences; 
 
Enabling personalized natural user-driven way of 
querying, filtering, browsing and presentation of 
information. 
Personalized representation of information very much 
concerns a human supervised ontology alignment process. 
Ontologies very much differ from each other. The more 
specific, detailed and complex ontology we make, the more 
semantic value it has, but, it makes harder to integrate 
ontology with others. Taxonomies of different ontologies are 
not likely to be the same. Even developed by professionals, 
we still have different ontologies for the same problem 
domain. It would seem that experts, involved to the same 
domain, should operate with the same terms, use the same 
vocabulary and knowledge representation model. But, people 
are different, context and personal perception of surrounding 
world brings problems to interoperability process. As a part 
of the processes, human brings a certain level of uncertainty, 
and only human my help to solve the problem so far. Thus, 
to avoid heterogeneity in the resource annotations and 
simplify ontology alignment for automated interoperability 
between digital elements of the technology world, we may 
admit a necessity of personalized adaptation of every human 
(no matter whether it is an expert (knowledge provider) or 
user/customer) to the common information/data model. 
III. 
HUMAN-ASSISTED ONTOLOGY ALIGNMENT 
A. Visually-facilitated semantic matching 
Let us consider a scenario of installation of a new floor-
heating regulator to a “smart-home” system. Assuming that 
we have two different vendors (Vendor A - producer of the 
Control Unit for the smart-home system, and Vendor B - 
producer of the regulator for a floor-heating system), we 
have two different ontologies OntologyV
A and OntologyV
B. 
Vendor A logically defines all the floor-heating systems with 
respect to the room the system is associated with. Thus, 
OntologyV
A might contain such concepts as: living room 
floor-heating system, bedroom #1 floor-heating system, 
bedroom #2 floor-heating system, kitchen floor-heating 
system, bathroom floor-heating system, etc. From the 
Vendor A point of view, all these concepts refer to 
absolutely different sub-systems in the “smart-home” 
network. On the other side, association of the floor-heating 
system with particular room/place does not matter for 
Vendor B. Therefor, “floor-heating system” concept in the 
OntologyV
B is a more general and independent entity. 
Moreover, most probably “floor-heating system” concept 
will be named very much different in those two ontologies 
and automated alignment will be absolutely impossible.           
Since the Control Unit of the smart-home is a more 
general device (in comparison to specific Floor-heating 
system) and deals with many other devices and systems in 
the installed network, it utilizes more wide ontology. 
Therefore, to allow interoperability between the Control Unit 
and Floor-heating system, we have to map OntologyV
B to 
wider OntologyV
A. At the same time, we have to pay 
attention to the user’s (“smart-home” owner’s) OntologyH
i. 
In general case, every human has own personal ontology that 
will be supported by his/her PA for interaction with devices, 
services, 
applications 
and 
systems. 
But, 
for 
any 
system/application, to be a mediator between the human and 
some other system with its own ontology, personal human 
ontology itself should be mapped with ontology of mediator-
system in advance. PA will collect correspondent alignments 
of personal human ontology with ontologies of various 
mediating systems that human will be interacted with.  
Assuming that fully automated alignment is not possible, 
we do not consider the cases with very simple and self-
descriptive ontologies, where automated alignment might be 
done based on matching of synonyms of the property manes. 
Correspondent example of the research at this direction is a 
work performed in the IoT project, where authors are trying 
to minimize human involvement to the process of 
establishing interoperability between heterogeneous systems 
[3]. They try to retrieve (to build) ontologies from examples 
of massages that systems operate in communication process 
(requests, response, etc.). Authors build simple plane 
ontologies based on names of parameters used in the 
messages. Later, ontologies are automatically aligned and 
correspondent 
alignments 
are 
used 
for 
automatic 
interoperability between heterogeneous systems in runtime. 
But, as was mentioned, it might work in case of self-
descriptive messages, where parameters are named by words 
that make sense, without abbreviations and shortenings, and 
preferably in the same language. In all other cases (cases 
with complex hierarchy of sub-classes, cases of different 
domain description models, cases of multilingual and 
multicultural ontology definitions, etc.) this would not work 
automatically and will require human assistance. Thus, in 
cases of human-assisted alignment of personal human 
ontology or ontologies provided by different vendors, we 
need an innovative suitable for non-expert mechanism and 
correspondent user interface for ontology alignment.  
107
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

With respect to the research [19][20][21][22], there are 
some available Ontology Alignment and visualization tools: 
Foam algorithm [23], multiple-view plug-in for Protégé [24] 
- AlViz [25], BLOOMB system [21] and Knowledge 
Modeler[26]. There graphical primitives such as point, line, 
area, or volume are currently utilized to encode information. 
These objects are characterized by position in space, size, 
connections & enclosures, shape, orientation, and visual cues 
like color and texture, with temporal changes, and viewpoint 
transformations. Unfortunately, all these tools were 
elaborated for domain experts who know what ontology is 
and what information models might be used. Such tools 
present a lot of statistical data and analytics that might be 
very useful for the ontology engineer, but not for the 
ordinary user of a service. Information visualization should 
aim at making complex data easy accessible and understood 
for interactive investigation by the user. In case of smart-
home, we expect that user has a basic knowledge about a 
domain and functionality of the system. Therefore, we have 
to find more suitable approach for user-assisted ontology 
alignment. To be easily recognized by human, concepts and 
properties of different ontologies must be presented in the 
most understood form - in a form of image. An image (or 
other visual form) is the most common information 
representation model for human. It helps to understand the 
meaning and avoid verbal uncertainty presented in textual 
form. Therefore, user interface should be able to present 
semantics through interactive image mash-ups and user-
friendly browsing mechanism.  
Figure 2 shows us possible visual interpretations of the 
Vendor A, Vendor B and user ontologies with respect to the 
scenario of adding the living room floor heating system to 
the “smart-home” network. Since we are not consider 
“smart-home” owner as an expert in ontologies and complex 
control systems, we cannot expect that it would be possible 
for him/her to utilize currently available solutions for 
ontology alignment. Only we can expect is awareness of the 
user about purpose, capabilities and main functionality of the 
“smart-home” Control Unit and floor-heating system that 
he/she would like to add to the “smart-home” network. 
Having even such limited expertise of the problem domain, 
user is able to browse visual description of the Control Unit 
(structure of sub-systems, capabilities, inputs and outputs, 
properties, etc.) and description of the floor-heating system 
from another vendor to provide appropriate matching. User 
can intuitively map concepts and properties presented by 
images. Applying possible results, achieved on background 
from integrated modules of automated ontology alignment, 
Visual Ontology Alignment Tool assists user with 
suggestions and requests next necessary alignments caused 
by alignments made on the previous steps. Additional textual 
descriptions of visual annotations support user to make 
correct mapping. As a result, correspondent parts of 
ontologies OntologyV
A and OntologyV
B, which are related to 
the communication scenario between “smart-home” Control 
Unit (Vendor A) and floor-heating system (Vendor B), will 
be mapped and correspondent alignment will be used in 
runtime 
operation 
of 
the 
“smart-home” 
network.
 
Figure 2.  Visually-facilitated Ontology Alignment. 
108
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

B. Visually-enriched ontology and resource description 
To operate with visual representation model in a smart 
way, visualization tool should retrieve correspondent images 
together with ontologies. It means that ontologies should be 
extended with additional layer that contains visual definition 
of the concepts, classes and properties. Later in the text, we 
will call such visually-enriched ontology as Visual Ontology 
(VisOntology). We consider two scenarios of human-assisted 
visual enrichment (see Figure 4). In the first case, 
Ontology/Domain 
Expert 
creates 
VisOntology 
using 
Ontology Visual Enrichment Tool that adds correspondent 
image layer to the ontology. Later, Vendor provides 
annotation of the Service/System that was produced by 
Vendor. In the second case, Vendor itself provides visually-
enriched annotation (VisAnnotation) of the produced 
Service/System 
using 
Visually-enriched 
Resource 
Description Tool based on regular domain ontology provided 
by Ontology/Domain Expert. In this case, visually-enriched 
ontology might be automatically created from the visually-
enriched resource description during the annotation process. 
In case when it is difficult to associate any image with some 
of the concepts, tool will create an image with a 
correspondent text (word, character, sign, etc.) retrieved 
from the name of ontology element. One more case might 
have a place if we consider possibility for some third party to 
substitute Vendor in the Service/System annotation process 
and provide visual annotation in both previous cases. Both 
tools that were mentioned in the above use-cases have the 
same nature and similar functionality. Thus, let us consider 
them as a single tool for visual semantic enrichment.   
The main purpose of the tool is to help user to brows 
ontology and assign “visSemantics” property to every class, 
property and instance of the ontology. Figure 3 presents 
possible extension of RDF Schema with “visSemantics” 
property used for VisOntology and VisDescription. Talking 
about resource annotation, tool creates an annotation 
template based on assigned ontology and provides possibility 
to add visual description. In such a way, tool extends the 
concepts of the ontology with “visSemantics” property and 
correspondent value in a form of image. Currently we 
consider the range of this property as a literal URL of an 
image. In more advance version of VisOntology and 
VisDescription of the resource the range might be extended 
to video, audio or any other multimedia content.       
   
 
Figure 3.  “visSemantics” property. 
Visual enrichment is individual, as long as a set of 
images, used by VisOntology and VisAnnotation providers, 
is individual. Tool allows user to make key-word based 
image annotation/tagging and create a personal pool of 
annotated visual content for further use. Later, such 
annotated content for visual enrichment will be easily 
retrieved based on user search request or automatically 
suggested to a user based on attributes of self-descriptive 
elements of ontology. In case we have old-fashioned 
service/system description based on ordinary ontology, 
enrichment of the description might be still automated on 
some extend. Based on names of ontology concepts, Visual 
Enrichment Tool may search among annotated visual content 
and build visual layer automatically. Quality of automated 
enrichment might be relatively low in comparison to human 
assisted enrichment. But, even in worst cases, when we do 
not have any human involvement at the stage of resource 
annotation, it might help to retrieve at least some visual 
content for further visual ontology alignment process.            
Taking into account growing trend towards sharing and 
reuse of content, annotated visual content might be shared 
through various clouds and common spaces. Thus, tool can 
use not only own user’s visual content, but also will allow 
user to manage and extend his/her virtual visual content 
space with external sources. As a continuation of the work, 
authors also consider a possibility to utilize Social Web to 
share visual annotation content and VisOntologies.  
IV. 
CONCLUSION AND FUTURE WORK 
With the aim to elaborate an environment that enables 
integration of heterogeneous “things” and intelligent 
distributed systems within the Internet of Things framework, 
authors 
address 
the 
mechanism 
of 
human-assisted 
simplification of semantic matching to allow interoperability 
of entities in the IoT. Assuming unavailability of a sufficient 
amount of professional experts to be involved to the daily 
“things” integration support process, we proposed the way to 
make user be not just a consumer of thing-based services, but 
also an expert capable to compose and establish 
interoperability among the things. Taking into account 
specifics of the potential user and unsuitability of current 
ontology alignment tools for it, this paper presents a human-
driven approach towards visually-facilitated ontology 
alignment through visually-enriched ontologies and resource 
(thing) 
descriptions. 
Current 
implementation 
of 
correspondent toolset is concentrated on and consists of an 
interface for the final stage - Visual Ontology Alignment 
Tool that assumes existence of VisOntologies and 
VisDescriptions of Things. Implementation of the tool for 
visual enrichment of ontologies and resource descriptions is 
considered as a future continuation of presented work.           
ACKNOWLEDGMENT 
This research has been performed as part of IoT Tivit 
SHOK Program in MIT department (University of 
Jyvaskyla, Finland) funded by TEKES and consortium of 
industrial partners. Authors are grateful to the project team 
members from VTT (as well as other partners of the project) 
involved to the correspondent task for fruitful cooperation. 
@prefix :    <http://www.example.org/sample.rdfs#> . 
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>. 
@prefix rdfs:<http://www.w3.org/2000/01/rdf-schema#>. 
 
rdfs:vviissSSeemmaannttiiccss  
  
    rdf:type rdf:Property; 
  rdfs:domain rdfs:Resource; 
  rdfs:range rdfs:Literal. 
 
:FloorHeatingSystem 
  rdfs:subClassOf :HeatingSystem; 
  rdfs:vviissSSeemmaannttiiccss ”www.example.org/FHSystem.jpeg”. 
109
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

REFERENCES 
[1] D.J. Cook and S.K. Das, “How smart are our environments? 
An updated look at the state of the art”. Pervasive and Mobile 
Computing. 3(2), pp. 53-73, 2007. 
[2] J. Honkola, H. Laine, R. Brown, and O. Tyrkko, “Smart-M3 
information sharing platform”. Proc. IEEE Symp. Computers 
and Communications (ISCC’10), pp. 1041-1046, 2010. 
[3] K. Kotis and A. Katasonov, "Semantic Interoperability on the 
Web of Things: The Smart Gateway Framework", CISIS 
2012, Palermo, Italy, 2012. 
[4] O. Kaykova, O. Khriyenko, D. Kovtun, A. Naumenko, V. 
Terziyan, and A. Zharko, “Challenges of General Adaptation 
Framework for Industrial Semantic Web”, In: Amit Sheth and 
Miltiadis Lytras (eds.), Semantic Web-Based Information 
Systems: 
State-of-the-Art 
Applications, 
CyberTech 
Publishing, pp. 61-97, 2007.  
[5] Semantic Web, 2001. URL: http://www.w3.org/2001/sw/ 
[6] T. Berners-Lee, J. Hendler, and O. Lassila, “The Semantic 
Web”, Scientific American 284(5), 2001, pp. 34-43. 
[7] A. Ankolekar, M. Burstein, J.R. Hobbs, O. Lassila, D.L. 
Martin, D: McDermott, S.A. McIlraith, S. Narayanan, M. 
Paolucci, T.R. Payne, and K. Sycara, “DAML-S: Web Service 
Description for the Semantic Web”, 2002. URL: http://www-
2.cs.cmu.edu/~terryp/Pubs/ ISWC2002-DAMLS.pdf.  
[8] M. Paolucci, T. Kawamura,  T.R. Payne, and K. Sycara, 
“Importing 
the 
Semantic 
Web 
in 
UDDI”, 
2002. 
URL:http://www-2.cs.cmu.edu/~softagents/papers /Essw.pdf 
[9] EM. Maximilien, A. Ranabahu, and K. Gomadam, “An 
Online Platform for Web APIs and Service Mashups”. In 
IEEE INTERNET COMPUTING, IEEE Computer Society, 
2008, pp. 32-43. 
[10] T. Berners-Lee, “Linked Data - Design Issues”. 2006. URL: 
http://www.w3.org/DesignIssues/LinkedData.html 
[11] T. Heath and C. Bizer, “Linked Data: Evolving the Web into a 
Global Data Space” (1st edition). Synthesis Lectures on the 
Semantic Web: Theory and Technology, 1:1, 1-136. Morgan 
& Claypool. 2011. 
[12] O. Khriyenko and M. Nagy, “ Semantic Web-driven Agent-
based Ecosystem for Linked Data and Services”, In: 
Proceedings of the Third International Conferences on 
Advanced Service Computing, 25-30 September, 2011, 
Rome, Italy, 8 pp. 
[13] O. Khriyenko, “Collaborative Service Ecosystem - Step 
Towards the World of Ubiquitous Services”. In: Proceedings 
of the IADIS International Conference Collaborative 
Technologies 2012, 19-21 July,  2012, Lisbon, Portugal.  
[14] V. Spiliopoulos and G. A. Vouros, “Synthesizing Ontology 
Alignment Methods Using the Max-Sum Algorithm”, 
Knowledge and Data Engineering, IEEE Transactions on, 
vol.PP, no.99, pp.1-1.  
[15] K. Kotis, A. Katasonov, and J. Leino, “Aligning Smart and 
Control Entities in the IoT”, In: Proceedings of the 5th 
Conference on Internet of Things and Smart Spaces, 27-28 
August, 2012, St.-Petersburg, Russia.  
[16] K. Kotis, A. Valarakos, and G. Vouros, "AUTOMS: 
Automating Ontology Mapping through Synthesis of 
Methods.", In: Proceedings of the International Semantic Web 
Conference (ISWC'06), Ontology Matching International 
Workshop, Atlanta USA, 00/2006.  
[17] A. Valarakos, V. Spiliopoulos, K. Kotis, and G. Vouros, 
"AUTOMS-F: A Java Framework for Synthesizing Ontology 
Mapping Methods", i-Know,07, Graz, Austria, 00/2007. 
[18] P. Shvaiko and J. Euzenat, “Ontology matching: state of the 
art and future challenges”. IEEE Transactions on Knowledge 
and Data Engineering, 2012. 
[19] J.  Pina, E. Cerezo, and F. Seron, “Semantic visualization of 
3D urban environments”. Multimedia Tools and Applications, 
Volume 
59, 
Number 
2 
(2012), 
505-521, 
DOI: 
10.1007/s11042-011-0776-3. 
[20] M. Lanzenberger and J. Sampson, “Human-Mediated Visual 
Ontology Alignment”. HCI (9) 2007: 394-403. 
[21] P. Jain, P. Hitzler, A.P. Sheth, K. Verma, and P.Z. Yeh, 
“Ontology Alignment for Linked Open Data”. In: Proceedings 
of the 9th International SemanticWeb Conference, ISWC 
2010, Shanghai, China, November 7-11, 2010, Springer-
Verlag (2010) 402–417.  
[22] F. Kboubi, A.H. Chaibi, and M.B. Ahmed, 'Semantic 
Visualization and Navigation in Textual Corpus'. In: CoRR 
abs/1202.1841, 2012 . 
[23] M. Ehrig and Y. Sure, “Ontology mapping - an integrated 
approach. In: Bussler, C., Davis, J., Fensel, D., Studer, R. 
(eds.) Proceedings of the First European Semantic Web 
Symposium, 10-12 May, 2004, Heraklion, Greece. 
[24] Protégé-owl 
(Stanford 
Medical 
Informatics) 
- 
http://protege.stanford.edu/overview/protege-owl.html 
[25] M. Lanzenberger and J. Sampson, “Alviz - a tool for visual 
ontology alignment”. In: Society, I.C.S. (ed.) Proceedings of 
the IV06, 10th International Conference on Information 
Visualization, London, UK, July, 2006. 
[26] A. Sheth and D. Avant, "Semantic Visualization: Interfaces 
for exploring and exploiting ontology, knowledgebase, 
heterogeneous content and complex relationships," NASA 
Virtual Iron Bird Workshop, March 31 and April 2, 2004, CA. 
 
Figure 4.  Human-assisted visual enrichment scenarious. 
110
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-236-3
UBICOMM 2012 : The Sixth International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies

