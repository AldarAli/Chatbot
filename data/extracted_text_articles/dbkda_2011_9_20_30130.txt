An Optimistic Transaction Model for a
Disconnected Integration Architecture
Tim Lessner∗, Fritz Laux†, Thomas Connolly∗, Cherif Branki∗, Malcolm Crowe∗, and Martti Laiho‡
∗School of Computing, University of the West of Scotland, name.surname@uws.ac.uk
†Fakult¨at Informatik, Reutlingen University, Germany, fritz.laux@reutlingen-university.de
‡ Dpt. of Business Information Technology, Haaga-Helia University of Applied Sciences,
Finland, martti.laiho@haaga-helia.ﬁ
Abstract—This work presents a disconnected transaction
model able to cope with the increased complexity of long-
living, hierarchically structured, and disconnected transactions.
We combine an Open and Closed Nested Transaction Model with
Optimistic Concurrency Control and interrelate ﬂat transactions
with the aforementioned complex nature. Despite temporary in-
consistencies during a transaction’s execution our model ensures
consistency.
Index Terms—Disconnected Transaction Management; Opti-
mistic Concurrency Control; Advanced Transaction Models
I. INTRODUCTION
Nowadays, Transaction Management (TM) must not only
deal with short lived and ﬂat transactions, TM must provide
a transactional execution of long running and hierarchically
structured business processes, so called complex transactions,
involving many distributed loosely coupled, heterogeneous,
and autonomous systems, represented as services as in Service
Oriented Computing (SOC) for instance. To facilitate the loose
coupling and increase the autonomy data should be modiﬁed
in a disconnected and not in an online manner. By this we
mean that the set of proposed modiﬁcations to data is prepared
ofﬂine that requires a transacted sequence of operations on
separate database connections. Further, message exchange,
which takes place in such an architecture, is asynchronous
and so is the data access, too. From a transactional view, the
execution of a business process is a tree of interdependent and
interleaved transactions, and during its execution the ACID
(Atomicity, Consistency, Isolation, Durability) [1] properties
are often weakened, and they allow for temporary inconsisten-
cies to increase the performance. A locking isolation protocol,
for instance, where other concurrent transactions read only
committed results, leads to long blocking time caused by the
process’s duration and the asynchronous message exchange
typical for disconnected architectures.
A disconnected nature overcomes this challenge for the
price of a weakened isolation. The drawback of a weakened
isolation is that other transactions can read pending results,
which increases the danger for data to become inconsistent,
and a widely used solution is compensation to semantically
undo effects, also cascading effects, even after the transaction
technically commits. Compensation can be interpreted as a
necessity to conform to reality.
There are a couple of scenarios where a transaction be-
comes complex. The booking of a journey, for example,
involves several heterogeneous web applications. Also cloud
computing, where ﬂat transactions access a highly replicated
and distributed data storage, is confronted with a complex
transaction structure.
Before the paper introduces the Transaction Model in sec-
tion III, the problem is described by the next section, as well
as the contribution of the paper. Related work is discussed in
section IV and the Conclusion section completes this paper.
II. PROBLEM DESCRIPTION & CONTRIBUTION
One challenge is to provide a consistent transactional inte-
gration of heterogeneous systems, applications and databases
across database (DB), middleware (MW) and application layer.
A lot of work has been carried out regarding (i) the trans-
actional integration of heterogeneous systems (applications
or databases) by the research community and industry (see
[2][3][4]). In the relatively new domain of SOC many Web
Service speciﬁcations cover a plurality of aspects and they
all have in common that they provide a transactional interac-
tion to a certain degree between services, or more generally
components. These models have been motivated by the need
for Business (BT) or User Transactions (UT). Moreover, (ii)
transaction processing in DBMS has been addressed by a
vast amount of research which focuses on the correctness,
hence the serializability, of concurrent data processing in a
transparent way by considering write and read operations only.
However, we believe the problem is that a common formal
model integrating both aspects (i,ii) is missing, especially a
model that considers the ﬂat transactions as implemented by
components and the overlying complex structure of trans-
actions which guarantees consistency even if isolation or
atomicity is weakened.
The contribution of this paper is a formal transaction
model that interrelates the ﬂat transactions as implemented by
components with their composition and the resulting complex
transaction structure. We impose an Optimistic Concurrency
Control (OCC) structure within a component and require an
OCC at the MW layer. The approach allows the detection
of inconsistencies and furthermore decouples the concurrency
control (CC) mechanism of the DB layer and thereby provides
a solution for the “Impedance Mismatch” between (i) and
186
DBKDA 2011 : The Third International Conference on Advances in Databases, Knowledge, and Data Applications
Copyright (c) IARIA, 2011              ISBN:978-1-61208-115-1

(ii). We also believe that such a more integrated model helps
to determine a trade-off between consistency, availability,
and failure tolerance –user expectations– of a transactional
integration system.
III. TRANSACTION MODEL
We deﬁne a transaction t as a composition of several ﬂat
and short living transactions t1, t2, . . . , tn where components
COMP = comp1, . . . , compj implement these transactions
tn. As in some MW speciﬁcations like the Java Enterprise
Edition (JEE), components become part of the transactions,
and they are in a transaction scope and bound to the life
cycle of the component itself. In a disconnected architecture,
however, these components lose their context in terms of
the transaction as soon as the data is delivered. Components
communicate with a data access layer asynchronously and no
locks are kept because of the long-living and disconnected
nature.
The overview in ﬁgure 2 shows the dependencies between
the different concepts deﬁned in this section.
A. Disconnected Transaction
A disconnected transaction has a read sphere sphr and
a write sphere sphw. A sphere sph ∈ SPH is deﬁned as
a set sph = {t1, . . . , tn} of transactions which logically
groups transactions that belong together. Here, sph is a set
of ﬂat, short living, ACID transactions, and let transaction
t be a sequence of operations t = (op1, . . . , opm) with
OP = {op1, . . . , opm} as the set of data operations where
each opm is either of type read(DOm) or write(DOm), and
let DO be the set of all data objects DO = ∪k∈KDOk, K =
{1, 2, . . . , m}. If there are versions of DOk we denote a
version DOv
k, with superscript.
The disconnected behaviour is deﬁned by sphr ∩sphw = ∅
and some transaction t is either in sphr or sphw.
Regarding the deﬁnitions introduced so far from an im-
plementation point of view an implementation of dt, hence
the several ﬂat transactions in dt’s write and read sphere, is
required to initiate read and write transactions. Therefore, we
deﬁne comp as a component that implements dt. Additionally,
we deﬁne a component to be in one of the following phases:
reading (p1), disconnected and working (p2), validating (p3),
and writing (p4). Hence we deﬁne a component to be in the
phases similar to the phases of OCC. The difference, however,
is the explicit disconnected and working phase. Notice, we
impose this structure on a comp which may be seen as a design
guideline for the implementation of a single component.
Reading can be described as loading all the data required.
After the modiﬁcations take place validation starts. Validation
must be interpreted as a pre-phase of writing and only transac-
tions T w ⊆ sphw are allowed to enter p3 and p4 (transactions
T r ⊆ sphr can only enter the read phase). By following this
structure a comp can be seen as a component that follows the
OCC paradigm introduced by [5].
Within an implementation of comp, write transactions may
depend on each other and an explicit execution order like t1 →
t2 → t4 can be given. We deﬁne read transactions to not
depend on each other because they can be parallelised without
conﬂicting with each other.
Therefore, we deﬁne an explicit ordering over all writing
transactions T w and let Gdt be a directed, acyclic graph
Gdt = (V dt, Edt) as deﬁned in deﬁnition 1. The graph
deﬁnes an execution order between two transactions tn → to
and Gdt is a partial order over the set of transactions T ′w ⊆
(T w ∈ sphw). The set of transactions T ′′w represents free
transactions of a component comp, i.e., T ′′w /∈ V dt. Hence,
T w = T ′w ∪ T ′′w.
The SAGA [6] model introduced the notion of compensation
to semantically undo the effects of transactions. Compensation
has been introduced to cope with the requirement for a weak
isolation that arises if several sub-transactions form a long
living process but each of the sub-transactions is allowed
to commit and other transactions may read pending results.
In case the transaction aborts its sub-transactions, whether
committed or not, need to be undone, which is only possible
by executing a compensation, e.g., to cancel a ﬂight is the
compensation of booking a ﬂight. Our model also foresees
compensation transactions to semantically undo the effects of
a component, i.e., dt see III-C.
In our model a comp either provides its own sequence of
compensation transactions comp−1
i
= (t1, . . . , tn) or points
to another component comp−1
i
= compj representing the
compensation.
Finally, we deﬁne a disconnected transaction as:
Deﬁnition 1: Disconnected transaction dt
(1) A Disconnected transaction is deﬁned as dt
:=
(sphr, sphw, Gdt, comp, comp−1) with read sphere sphr =
(t1, . . . , tn), write sphere sphw = (t1, . . . , tm), a partial order
Gdt = (V dt, Edt) with V dt ≡ T ′w ⊆ T w and the set of edges
Edt is deﬁned as ∀tn, to ∈ V : tn → to ⇔ edt ∈ Edt with
edt = (tn, to). Let comp be the component that implements
dt, and let comp−1 be the compensation handler of dt. And,
∀comp ∈ COMP : comp is in exactly one phase p1,p2,p3 or
p4.
(2) ∀dt ∈ DT : sphr ∩ sphw = ∅
(3) dt only commits successfully if all T r and T w commit
successfully.
(4) In the case of failure the comp−1 must be executed to
semantically undo the changes of dt.
B. Consistency of dt
Due to the long-living and disconnected nature it would
be not favorable to lock data for as long as dt lasts because
locking hinders global progress of the transaction. However,
we must restrict this statement. No locking refers to the
entire life-cycle (p1-p4) of dt, and locking for the short living
transactions T is allowed, because they release their locks with
their commit and so, the blocking time is reduced to the time
validation and writing takes place (p3,p4). An exclusive access
during the validation and writing phase is necessary because
a consistent snapshot of a data object that has to be validated
is required and modiﬁcations must be written back eventually.
187
DBKDA 2011 : The Third International Conference on Advances in Databases, Knowledge, and Data Applications
Copyright (c) IARIA, 2011              ISBN:978-1-61208-115-1

We aim for a more decoupled transaction management. This
in turn requires validation to prevent from read and write
anomalies, like lost update. Our model foresees validation to
take place at the MW layer. By applying validation at the
MW layer we can basically decouple the DBMS in a sense
that consistency is already provided by the MW. To ensure
consistency at the MW the validation mechanism must perform
a validation as introduced by Kung and Robinson[5].
Deﬁnition 2: Validation
(1) Let RS(ti) be the set of DOi that is read by ti of comp
and let WS(tn) be the set of DOm eventually modiﬁed by tn
of comp. Also, let ts(RS(tn)) be the timestamp of the read set
of tn. Only if ts(RS(tn)) < ts(RS(to))∧RS(tn)∩RS(to) =
∅ ∧ WS(tn) ∩ WS(to) = ∅ ∧ WS(tn) ⊆ RS(tn) holds,
validation val(DOv
k) → DOv+1
k
is conﬂict free. Let val be
an algorithm that detects conﬂicts between two versions DOv
k
and DOv+1
k
of a data object by applying these aforementioned
rules.
(2) Further we require the validation to be “escrow serializ-
able” [7] and to obey the order deﬁned by Gdt.
By applying this validation schema outdated data, i.e.,
data that has been modiﬁed by other transactions during
the execution of dt, can be detected and anomalies can be
prevented. In our previous work [7] about optimistic vali-
dation in disconnected and mobile computing we introduced
“escrow serializability” ec and a “reconciliation mechanism”
that allows the number of validation conﬂicts to be reduced
by automatically replaying a certain class of operations. We
require the validation to be ec, and the execution of each t is
correct, if it is ec serializable.
Another issue which has to be considered is the possible
existence of so called atomic units within sphw. Atomic units
exist if some transactions T w are commit or abort dependent
to each other, i.e., transaction tn is only allowed to commit if
transaction tm does. To depict such dependencies we have to
extend our model.
1) Atomic Units: An atomic unit groups several ﬂat trans-
actions where an atomic outcome of the group is required. The
members of an atomic unit become sub-transactions. Consid-
ering the concept of atomicity the concept of an atomic unit
is ambiguous because something that is atomic now consists
of other atomic units, namely each sub-transaction itself. The
point is that atomic refers to the expected outcome and the
execution of several sub-transactions must be atomic. In other
words, atomicity is relative to the level of the transaction tree.
We introduce the notion of an atomic unit au
=
(t1, . . . , tn) as a sequence of ﬂat transactions, and let AUi =
{aui,1, . . . , aui,h} be the set of all atomic units of dti which
form an imposed structure on sphw
i ; thus sphw
i := AUi.
Deﬁnition 3: Atomic unit au of dt
(1) Let AUi = {aui,1, . . . , aui,h} be the set of all atomic
units of dti which is an imposed structure on sphw
i ; thus
sphw
i
:=
AUi. Further, let aui,h
=
(t1, . . . , tn) group
(tw
1 , . . . , tw
n ) ∈ T w into an indivisible group of transactions
where either all T w ∈ aui,h commit or abort. And, let AU be
the set of all AUi
Now, let csDOi be the change set –modiﬁcations– of data
objects modiﬁed by dti and csDOi(aui,h) the change set
of aui,h. The validation must now ensure that only if each
csDOi(aui,h) passes validation the modiﬁcations are written
back to the database. To achieve an atomic outcome for sphw
i
we need a Closed Nested Transaction CNT [8], [9] structure
that is able to guarantee an atomic outcome of sphw
i . We need
a CNT because of the imposed order and the atomic units
which may encompass several t.
Deﬁnition 4: Closed Nested Transaction CNT
(1) Let CNT(sphw
i ) be a closed nested transaction over
sphw
i which is deﬁned as a tree CNT(sphw
i ) = (V cnt, Ecnt)
with sphw
i as root node r which only commits if all its children
commit, the set of vertexes V cnt ≡ AUi and the set of edges
Ecnt is deﬁned as ∀aui,h, aui,j ∈ V cnt : aui,h → aui,j ⇔
ecnt ∈ Ecnt with ecnt = (aui,h, aui,j).
(2) If there exists an order (edge) ∃edt ∈ Edt = tm → tn
with tm ∈ aui,h and tn ∈ aui,j for h ̸= j then there must be
a dependency between aui,h and aui,j so that tm → tfirst ∈
aui,j, and tlast ∈ aui,j → tm+1 ∈ aui,h, with tfirst as the
ﬁrst and tlast as last element in aui,j, and let tm+1 be the
successor of tm so that tm → tm+1. Thus aui,j becomes part
of aui,h. If ¬∃(tm → tm+1) then aui,j runs concurrent to
aui,h.
(3) Further, the order of atomic units must terminate.
Example 1: CNT
Given sphw = (au1, au2, au3, au4, au5) with au1 = (t1,
t2,t3,t4), with au2 = (t5,t6), au3 = (t7,t8), au4 = (t9),
au5 = (t10), and
Gdt = (V dt = {t1,t3,t4,t5,t6,t7,t8,t9}, Edt =
{(t1,t3)(t3,t6)(t3,t4)(t5,t6)(t7,t8)(t7,t9)})
The resulting CNT, i.e., the execution model, is shown in
Fig. 1.Notice, au’s are shown as dashed lines. As shown, au2
becomes part of au1 because of the edges (t3, t6) and (t3, t4)
deﬁned in Gdt. Since there is no order deﬁned between t1, t2
it is possible to parallelise t2.
Regarding au3 = (t7, t8) and au4 = (t9) the situation
differs. Due to the order relations (t7, t8) and (t7, t9) au3 and
au4 must be executed serial.
To achieve an atomic outcome of CNT a Two-Phase-
Commit (2PC) is required between t2 and the transactions
t3, t5, t6, t4 with t1 as coordinator. One possibility to achieve
an atomic outcome of t3, t5, t6, t4 is to introduce a new
atomic unit au′
1. We regard this issue as implementation detail
and leave an answer open for future research. However, a
coordination between each chain in a branch is required. For
example, the coordinator initiates t3, awaits the result, in case
the result is a pre-commit, it initiates t5, then t6 and ﬁnally t4
if all of them sent their pre-commit au2 is committed and the
result is sent back as a pre-commit to t1. Between au1, au3,
and au5 a 2PC is required.
188
DBKDA 2011 : The Third International Conference on Advances in Databases, Knowledge, and Data Applications
Copyright (c) IARIA, 2011              ISBN:978-1-61208-115-1

Fig. 1.
Exemplary CNT (straight lines show possible parallelisation, curved
lines show an order)
According to the example some further speciﬁcation for
CNT is required to ensure an atomic outcome:
Deﬁnition 5: Commitment rules of CNT
(1) A parent is only allowed to commit if all its children
commit.
(2) Between all siblings of CNT a Two-Phase-Commit (2PC)
is required.
(3) Between a chain of au in a branch an external coordinator
must ensure:
(a) A successor of aui,h is only allowed to start if its
predecessor aui,h−1 pre-commits.
(b) If one aui,h in the chain aborts all other au have to abort,
too.
(c) If all au sent their pre-commit to the coordinator the
coordinator sends a commit message to all au and each au
has to commit, i.e., a commit is a promise by the au
(d) A DO can be passed from a au only to its predecessor.
Notice the difference between a parallel execution which
requires a 2PC and a chained one which requires coordination
for an ordered execution. Both have in common that a commit
is a promise that requires the pre-commit state and if only one
of the involved parties aborts, the entire au must be aborted.
Following the rules deﬁned in Deﬁnition 5 compensation is not
required, and recovery is possible because locks are released
after a commit of all involved transactions (compensation will
play an important role later in section III-C). Also, since a DO
is only passed between already pre-committed, au isolation is
maintained too. For further details in the domain of nested
transactions we refer to the seminal work [8], [9], [10], [1],
[11].
Now, we consider the concurrent execution of several dt.
Usually a correct, i.e., consistent, concurrent, execution is
given if the conﬂict graph between all transactions, dt in our
case, is acyclic. Our model, however, does not require such a
conﬂict graph and we rely on the optimistic validation instead.
The concurrent execution of several au of different dt is
correct if OCC is able to detect conﬂicts between au that are
either a sequence of transactions or single transactions, and if
the order within and between atomic units is obeyed. Hence, an
arbitrarily ordering of concurrent au is limited to the imposed
order deﬁned, but free transactions, i.e., atomic units, which
are not part of the order relation can interleave with ordered
atomic units in any way. Further, bear in mind that OCC is a
ﬁrst wins strategy.
A concurrent execution of several AU
=
(AUi
=
(aui,1, . . . , aui,j), AUk
= (auk,1, . . . , auk,l), . . .) must be
consistent because the OCC validation detects read-write or
write-write conﬂicts for some data object DO (see Deﬁnition
2) and an arbitrary interleaving of free transactions with
ordered au. In case of a conﬂict the transaction will be aborted.
Further, the CNT ensures an atomic and non-isolated out-
come. Hence, without providing a proof (see section V) OCC
and CNT should ensure a consistent and atomic outcome of
a concurrent execution of atomic units.
C. User Transaction ut
As already mentioned, a transactional integration has to deal
with a complex hierarchically structured transaction, referred
to as user transaction ut. An ut is a composition of several
components that interact with each other in a deﬁned order.
Deﬁnition 6: User transaction ut
Let UT = ut1, ut2, . . . , utm be the set of all user transac-
tions. We deﬁne an utm := (DTm, Gutm, AUTm) with DTm
as the set of disconnected transactions composed by ut. Gutm
is a directed, acyclic graph with Gutm = (V utm, Eutm) with
V utm ≡ DTm = dt1,m, . . . , dti,m and the set of edges Eutm
is deﬁned as ∀dtm,i, dtm,n ∈ V utm : dtm,i → dtm,n ⇔
eut ∈ Eutm with eut = (dtm,i, dtm,n). The dependency
dtm,i → dtm,n expresses an execution order, hence Gutm
represents a partial order over the set of disconnected transac-
tions DTm for utm. AUT is deﬁned in the following section.
In the following we consider the existence of atomic units
within an ut and how we can achieve an atomic outcome of
ut.
D. Consistency of ut
As already investigated by the research community a com-
plex transaction, like ut, must cope with sub-transactions de-
ﬁned by transactional boundaries within the execution model.
A transactional boundary demarcates parts of the complete
transaction and deﬁnes thereby sub- transactions, or in other
words atomic units (atomic refers to the outcome). These units
can now be interleaved in a concurrent execution which leads
to an increased performance because not an entire ut must be
scheduled.
Further, atomic units can be exploited to allow for a partial
rollback of ut if the sequence of corresponding compensation
steps is deﬁned. This is also known as the “Spheres of Joint
Compensation” model introduced by [12]. More details about
the settings and the technological realisation of transactional
boundaries can be found in [13], [14], [15].
We provide a more general notion of atomic units and focus
on the interrelation between these more high level units and
above deﬁned disconnected transactions.
189
DBKDA 2011 : The Third International Conference on Advances in Databases, Knowledge, and Data Applications
Copyright (c) IARIA, 2011              ISBN:978-1-61208-115-1

1) Atomic Units of ut: The following deﬁnitions are analog
to the ones in section III-A above.
Deﬁnition 7: Atomic unit aut of ut
Let AUTm
= {autm,1, . . . , autm,j} be the set of all
atomic units of utm with autm,j
= (dt1, . . . , dti), and
with (dt1, . . . , dti) ∈ Eutm. Atomic unit autm,j groups the
spheres of disconnected transactions into an indivisible group
where either all dti ∈ autm,j commit or abort. Hence, AUTm
is an imposed structure on an ut. And, let AUT be the set of
all AUTi.
In contrast to CNT which ensures an atomic outcome
after the validation takes place, a similar structure is required
that coordinates the validation for several dt, i.e., their write
spheres, grouped in an aut. Also, amongst all aut. Thus, a
transaction structure for the validation is required. Further,
the commitment rules and the coordination amongst the dt
is different to CNT. This is caused by the time between the
termination of two dt. Within one dt it is possible to bring in
the modiﬁcations of one atomic unit of dt in one step (there
is only one write phase), at this stage, one dti may enter its
termination (p3,p4) a long time before another dtk of the same
atomic unit enters its termination.
Eventually, this means that isolation is weakened and com-
pensation is required to semantically undo the effects because
a dt has to commit to release its locks and isolation is no
longer possible. This requires, as deﬁned in deﬁnition 1, each
dt to deﬁne its compensation, which may lead to a less
favourable cascading compensation. We refer to [6], [12], [16]
for a thorough discussion about compensation. Isolation is no
longer given, but since each t and, so each dt, must pass
the validation, our approach is able to detect and prevent
inconsistencies albeit after they arise, which we nevertheless
consider as a clear improvement because inconsistencies at the
DB level can be avoided despite a weak isolation.
Now, the coordination mechanism on top of the validation
is introduced. Similar to CNT we introduce an Open Nested
Transaction ONT which is considered open because of the
weak isolation.
Deﬁnition 8: Open Nested Transaction ONT
(1) Let ONT(dti) be an open nested transaction over uti
which is deﬁned as a tree ONT(uti) = (V ont, Eont) with
uti as root node r which only commits if all its children
commit, the set of vertexes V ont ≡ AUT and the set of edges
Eont is deﬁned as ∀autm,j, autm,k ∈ V ont : autm,j →
autm,k ⇔ eont ∈ Eont with eont = (autm,j, autm,k).
(2) If there exists an order (edge) ∃eut ∈ Eutm = dti → dtl
with dti ∈ autm,j and dtl ∈ autm,k for j ̸= k then there must
be a dependency between autm,j and autm,k so that dti →
dtfirst ∈ autm,k, and dtlast ∈ autm,k → dti+1 ∈ autm,j,
with dtfirst as the ﬁrst and dtlast as last element in autm,k,
and let dti+1 be the successor of dti so that dti → dti+1.
Thus autm,k becomes part of autm,j. If ¬∃(dti → dti+1)
then autm,j runs concurrent to autm,k.
(3) Further, the construction of an order of atomic units must
terminate.
Please bear in mind that a single dt is also encapsulated by
an aut and that a dt commits if its wspw does. So, actually
ONT is a structure over all wspw which are themselves
structured by CNT. Whereas ONT coordinates above the
validation, CNT coordinates below. To ensure an atomic
outcome for a dt some further speciﬁcation for ONT is
required:
Deﬁnition 9: Commitment rules of ONT
(1) A parent is only allowed to commit if all its children
commit. If one of its children abort compensation is required.
(2) Between a chain of aut the following holds:
(a) A successor of autm,j is only allowed to start if its
predecessor autm,j−1 commits.
(b) If one aut in the chain aborts all other aut have to abort
too, and the compensation handler of each dt of the same aut
must be called in reverse order as deﬁned by Gut
The commitment rules of ONT are different from the ones
deﬁned for CNT due to the open nature. As a concrete reali-
sation we propose to lodge an execution plan by a coordinator
(CO) for each ut, hence the model of the ONT itself. Each
dt which enters its write sphere has to register and must (i)
await the CO’s acknowledgement to enter the validation and
(ii) it has to send the ﬁnal outcome, commit or abort, to the
CO. If CO receives a commit message from a dt it marks the
corresponding node in the graph as committed, and in case of
an abort CO does not only mark the node as aborted, it must
initialise the compensation too. To control the compensation
a compensation model comp−1(ut) must be derived. We omit
a deﬁnition and the interested reader is referred to [12].
A dt is only allowed to enter the validation if all its
predecessors have already committed. A parent of several
siblings is only allowed to commit if all its children have
committed. To release locks only if all siblings commit is not
required because of the compensation, hence a 2PC [1] in
its classic deﬁnition is not required. Following this approach
the CO can obey the order and the status of each dt. The
suggested approach can be interpreted as reducing a graph to
its root node.
To complete the model we must show that the concurrent
execution of atomic units aut is also consistent. The argumen-
tation follows the same way as at the end of section III-B.
IV. RELATED WORK
The Nested Transaction Model has been introduced by
Moss [8] and can be seen as the seminal work concerning
Advanced, Workﬂow, or Business Transaction Models (see [2],
[4]). Spheres have been introduced by Davies [17] and can be
seen as the generalisation of the Nested Transaction Model
which itself can be seen as a generalisation of the chained
transaction model [1].
Compensation was already foreseen by Moss, but especially
the SAGA [6] model heavily applied compensation transac-
tions. The work by Leymann [12] especially focused on the
existence of atomic and compensation spheres. One inﬂuential
workﬂow transaction model is Reuters Contract model [18]
190
DBKDA 2011 : The Third International Conference on Advances in Databases, Knowledge, and Data Applications
Copyright (c) IARIA, 2011              ISBN:978-1-61208-115-1

which is a conceptual framework for the reliable execution of
long-lived computations in a distributed environment. OCC
was introduced by Kung and Robinson [5] and even if it
never gained a lot of attention as a CC mechanism in a
DBMS, its validation concept has been applied in synchroni-
sation concepts in Mobile Computing, for example, but rarely
adopted into the MW itself. The PyrrhoDB [19] is the only
database we are aware of that implements OCC as CC mecha-
nism. Laiho and Laux [20] thoroughly analysed Row Version
Veriﬁcation (RVV) as an implementation of OCC within a
disconnected architecture and their work provides, beside a
detailed discussion, patterns to implement RVV for a couple
of common databases and data access technologies at the MW
layer. Fekete et al. [21] also pointed out that an integration
of underlying short transactions and complex transactions is
important, and mechanisms to ensure consistency without the
need to lock data are required. Their work, however, introduces
research directions and not a formal model describing the
interdependence between ﬂat and complex transactions.
V. CONCLUSION AND FUTURE WORK
The deﬁned transaction model decouples the DB from
the MW layer by applying an OCC at the MW layer and
imposes an OCC phase model within a component. This
enables to detect overall inconsistencies despite temporal sub-
transactional inconsistencies. We also interrelated ﬂat trans-
actions with the complex transaction structure by applying
a CNT after the validation to ensure an atomic outcome,
and ONT coordinates the atomic outcome of ut above the
validation. This interrelation closes the gap between ﬂat and
complex transactions, and the application of OCC at the MW
can also help to establish a loose transaction coupling between
DB and MW.
Our future work will include a theoretical underpinning,
especially proofs, and focus on an implementation combining
our previous work [7] with this work. Our speciﬁc focus
is thereby on the semantics of transactions, as well as how
their transactional requirements can be expressed. On that
account we are working on the quantiﬁcation of consistency
requirements. This abstract model will form the basis for our
future work.
REFERENCES
[1] Jim Gray and Andreas Reuter. Transaction Processing: Concepts and
Techniques. Morgan Kaufmann, 1993.
[2] Sushil Jajodia and Larry Kerschberg, editors.
Advanced Transaction
Models and Architectures. 1997.
[3] Ahmed Elmagarmid, Marek Rusinkiewicz, and Amit Sheth, editors.
Management of heterogeneous and autonomous database systems. Mor-
gan Kaufmann Publishers Inc., San Francisco, CA, USA, 1999.
[4] Ting Wang, Jochem Vonk, Benedikt Kratz, and Paul Grefen. A survey
on the history of transaction management: from ﬂat to grid transactions.
Distrib. Parallel Databases, 23(3):235–270, 2008.
[5] H. T. Kung and John T. Robinson. On optimistic methods for concur-
rency control. ACM Trans. Database Syst., 6(2):213–226, 1981.
[6] Hector Garcia-Molina and Kenneth Salem. Sagas. In SIGMOD ’87:
Proceedings of the 1987 ACM SIGMOD international conference on
Management of data, pages 249–259. ACM, 1987.
[7] Fritz Laux and Tim Lessner. Escrow Serializability and Reconciliation
in Mobile Computing using Semantic Properties. International Journal
On Advances in Telecommunications, 2(2):72–87, 2009.
Fig. 2.
Dependencies between ut, dt, comp, t, CNT and ONT
[8] J. Eliot B. Moss. Nested transactions: an approach to reliable distributed
computing.
Massachusetts Institute of Technology, Cambridge, MA,
USA, 1985.
[9] J. Eliot B. Moss.
Open nested transactions: Semantics and support.
Workshop on Memory Performance Issues, 2006.
[10] Gerhard Weikum and Hans-J¨org Schek. Concepts and Applications of
Multilevel Transactions and Open Nested Transactions.
In Database
Transaction Models for Advanced Applications, pages 515–553. Morgan
Kaufmann, 1992.
[11] Gerhard Weikum and Gottfried Vossen.
Transactional Information
Systems: Theory, Algorithms, and the Practice of Concurrency Control
and Recovery. Morgan Kaufmann, 2002.
[12] Frank Leymann. Supporting Business Transactions Via Partial Backward
Recovery In Workﬂow Management Systems. In BTW, pages 51–70,
1995.
[13] Michael Beisiegel et al. Service component architecture (sca) v1.00,
2010-11-08, 2007.
[14] Olaf Zimmermann, Jonas Grundler, Stefan Tai, and Frank Leymann.
Architectural Decisions and Patterns for Transactional Workﬂows in
SOA. In ICSOC ’07: Proceedings of the 5th international conference
on Service-Oriented Computing, pages 81–93. Springer-Verlag, 2007.
[15] Heiko Schuldt, Gustavo Alonso, Catriel Beeri, and Hans-J¨org Schek.
Atomicity and isolation for transactional processes.
ACM Trans.
Database Syst., 27(1):63–116, 2002.
[16] Heiko Schuldt and Gustavo Alonso and Hans-J¨org Schek. Concurrency
Control and Recovery in Transactional Process Management. In Pro-
ceedings of the Eighteenth ACM SIGACT-SIGMOD-SIGART Symposium
on Principles of Database Systems, May 31 - June 2, 1999, Philadelphia,
Pennsylvania, pages 316–326. ACM Press, 1999.
[17] C. T. Davies. Data processing spheres of control. IBM Systems Journal,
17(2):179–198, 1978.
[18] Andreas Reuter and Kerstin Schneider and Friedemann Schwenkreis.
ConTracts Revisited. In Sushil Jajodia and Larry Kerschberg, editors,
Advanced Transaction Models and Architectures. 1997.
[19] Malcolm Crowe (University of the West of Scotland).
The Pyrrho
database management system (http://www.pyrrhodb.com/, 2010-11-02),
2010.
[20] Martti Laiho and Fritz Laux. Implementing optimistic concurrency con-
trol for persistence middleware using row version veriﬁcation. In Fritz
Laux and Lena Str¨omb¨ack, editors, The Second International Conference
on Advances in Databases, Knowledge, and Data Applications (DBKDA
2010), pages 45–50. IEEE Computer Society, 2010.
[21] Alan Fekete, Paul Greenﬁeld, Dean Kuo, and Julian Jang. Transactions
in loosely coupled distributed systems.
In Proceedings of the 14th
Australasian database conference - Volume 17, ADC ’03, pages 7–12,
Darlinghurst, Australia, Australia, 2003. Australian Computer Society,
Inc.
191
DBKDA 2011 : The Third International Conference on Advances in Databases, Knowledge, and Data Applications
Copyright (c) IARIA, 2011              ISBN:978-1-61208-115-1

