Enhancing Automatic Detection of Frustration Induced During HCI with  
Moment-based Biosignal Features 
 
Dimitris Giakoumis1,2, Dimitrios Tzovaras1 
1Informatics and Telematics Institute  
Centre for Research and Technology Hellas 
Thessaloniki, Greece 
dgiakoum@iti.gr, tzovaras@iti.gr 
George Hassapis2 
2Dept. of Electrical and Computer Engineering 
Aristotle University of Thessaloniki 
Greece 
ghass@auth.gr
 
 
Abstract—Enhancing HCI systems with the capability to detect 
user’s frustration and respond appropriately is a significant 
challenge. In this line, biosignal features based on the theory of 
orthogonal Krawtchouk and Legendre moments are assessed 
in the present work over their ability to enhance accuracy in 
automatic detection of frustration, which is induced through 
HCI, during video-game playing. Experimental evaluation, 
conducted over a multi-subject dataset over frustration 
detection 
showed 
that 
conventional 
features, 
typically 
extracted 
from 
Galvanic 
Skin 
Response 
and 
Electrocardiogram in the past, achieved correct classification 
rate (CCR) of 83.59%. Fusing these conventional features with 
moment-based ones extracted from the same modalities 
resulted to significantly higher accuracy, at the level of 93%. 
Furthermore, moment-based features lead also to over 10% 
increase in CCR when the aim was to identify both bored and 
frustrated cases, within a 3-classs affect detection problem.  
Keywords- automatic frustration detection, biosignals, 
moment-based features, video game-playing 
I. 
 INTRODUCTION  
Negative emotional states like frustration are likely to be 
induced during Human - Computer Interaction (HCI). 
Frustration is an emotional state commonly associated with 
anger. During HCI, it can cause a negative disposition of the 
user towards the machine [1]. In the context of video games, 
frustration is typically induced when game difficulty is in 
mismatch with the capabilities and/or preferences of the 
player [2]. It can lead to player’s disassociation from the 
game, dissatisfaction and resign. This is a case that may 
occur even in modern video-games, which, although 
carefully designed, do not take into account the player’s 
current emotional state and its specifics [2].  
Future game-playing systems can be augmented with the 
capability to automatically detect the player’s affective state 
and monitor user experience [3]. When needed, these 
systems will be capable to adjust playing context 
appropriately [4], so as to maintain entertainment through a 
closed biocybernetic loop [5]. Frustration is an emotional 
state that can play a key role in this context [6], since as it 
has been shown in the past, machines responding to player’s 
frustration can lead to improved gaming experience [1,2].  
However, a pre-requisite for building such future game-
playing systems, is to provide machines the capability to 
detect frustration effectively. 
A. Related Work 
During the past years, significant progress has been made 
in the field of automatic affect detection (e.g. [9,10,21]). This 
progress is important for a large variety of future HCI 
applications, ranging e.g. from affective games [7] to 
affective intelligent tutoring systems [12] that can be based 
on emotion sensitive e-learning models [8]. In this context, 
important efforts have been made so far towards enabling 
machines to automatically detect frustration. These studies 
utilized biosignals [11,12,14], video [12], or other data types 
[11,12] recorded during frustration induction, so as to build 
classifiers appropriate for detecting this negative emotional 
state.  
Features extracted from the Galvanic Skin Response 
(GSR) and Blood Volume Pulse (BVP) were used in [14], 
leading to frustration detection accuracy of 67.39% among a 
multi-subject (MS) dataset, having a computer game as 
stimuli. In [12], the focus was towards an affective learning 
companion, and frustration was predicted with accuracy of 
79% (MS), by utilizing features extracted from a face 
tracker, a posture sensing chair, a pressure mouse and GSR. 
Physiological features merged with contextual ones, 
extracted during students’ interaction with a tutoring system, 
lead in [11] to 88.8% frustration detection accuracy. In [15], 
using features extracted from biosignal (GSR, temperature 
and heart rate) modalities, frustration was recognized from 
five further emotion classes with accuracy of 78.3%. 
Focusing on HCI in respect of video games, biosignal (e.g. 
GSR and Respiration) features were found to correlate in [3] 
with frustration induced from video-game playing, whereas 
in [4] frustration was detected from biosignals and gameplay 
data with accuracy around 85%.  
From the above it is clear that in general, biosignals have 
good potential towards automatic frustration detection. 
However, although affect detection has significantly 
advanced during the recent years [16], frustration detection 
accuracy levels as well as in general emotion recognition 
(ER) ones have remained relatively limited, i.e. only rarely 
exceeding 90%. Therefore, evident is the need for new 
biosignal processing techniques, which will lead to more 
effective ER systems. Working towards this direction, [13] 
proposed biosignal features extracted from GSR and Inter-
342
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

Beat-Intervals (IBI) time series (calculated from the 
Electrocardiogram (ECG)), which are based on the theory of 
orthogonal Legendre [17] and Krawtchouk [18] moments. 
These moments have been widely used in the past for the 
purposes of image analysis and reconstruction. Such a 
typical example can be found in [18], where it was shown 
that based on weighted Krawtchouk moments, effective 
image reconstruction and object recognition can be achieved. 
However, before [13], features based on Legendre and 
Krawtchouk moments had not been considered as an option 
in biosignals-based affect detection. The use of these 
features, together with conventional, not-moment based ones 
typically utilized in the past, was found in that work to 
significantly increase effectiveness of automatic boredom 
recognition. 
B. Contribution 
Boredom and frustration are both negative emotions of 
high significance in the context of HCI applications. 
Therefore, the present work aims to enhance effectiveness of 
automatic frustration detection, by using moment-based 
biosignal features. Moreover, taking a step further from [13], 
we assess whether the moment-based features can deal with 
the problem of detecting whether the subject is getting both 
bored and frustrated during HCI. As explained in the 
following, it was found that combining moment-based 
features with conventional ones can significantly enhance the 
effectiveness of automatic frustration and also joint 
boredom/frustration detection, compared to the case where 
conventional features are used alone. 
II. 
BIOSIGNAL FEATURES EXTRACTION 
Various biosignal features were examined in the present 
study over their effectiveness in the given context. All 
features presented in the following were extracted from GSR 
and IBI time series recorded during rest periods and game-
playing trials of the dataset described in Section 3. 
A. Conventional features 
A set of “conventional” features was first extracted from 
all game-playing trials. These features, summarized in Table 
I, have proved in the past capable to form the basis for 
systems targeting automatic frustration detection, and ER in 
general. More details regarding the specifics (e.g. formulas) 
for the extraction of these features in the present study can be 
found in [13]. 
TABLE I.  
FEATURES EXTRACTED FROM THE GSR SIGNAL AND THE 
INTER BEAT INTERVALS (IBI) TIME SERIES  
Signal 
Conventional Features Extracted 
GSR 
Mean, Standard Deviation (SD), 1st derivative average, 1st 
derivative RMS, Number of SCRs, Average Amplitude of 
SCRs, Average Duration of SCRs, Maximum Amplitude of 
SCRs, δ(gsr), δnorm(gsr), γnorm(gsr), fd(gsr) 
IBI 
Mean, SD, LF/HF, RMSSD, pNN50, δ(ibi), δnorm(ibi), 
γnorm(ibi), fd(ibi) 
 
Moreover, all features of Table I were also extracted 
from only the first and last 10 seconds of each trial or resting 
period; then, the ratio between each feature’s value 
calculated from the first 10 seconds to the corresponding 
value calculated of the last 10 seconds was extracted as an 
extra feature (marked in the rest of the paper with the 
extension “_FL”). These ratios were calculated for all 
features that were applicable, similarly to [13]. In total, 37 
conventional features were extracted, 9 from IBI, 12 from 
GSR, and 16 as the feature value ratio between the first and 
last 10 secs of each trial. 
B. Biosignal Features Based on the Theory of Moments 
Legendre moments [17] are based on projecting a signal 
onto Legendre polynomials, which form a complete 
orthogonal basis set defined over the interval [-1,1]. For a 1D 
discrete signal f(xi), 
1≤ i ≤ N
, the 1D Legendre moment of 
order p is given by: 
 
∑
=
−
+
=
N
i
i
i
p
p
f x
x
P
N
p
L
1
)
) (
(
1
1
2
 
(1) 
where xi=(2i-N-1)/(N-1) and Pp(x) is the pth order Legendre 
polynomial given by:  
 
∑
=
−
−
−
−
−
=
2
/
0
2
2 )!
)!(
(!
2 )!
(2
)1
(
2
1
)
(
p
k
k
p
k
p
p
x
k
p
k
p
k
k
p
P x
 
(2) 
where x belongs in the span [-1,1]. Legendre polynomials 
were calculated with appropriate recursive relation [13]. 
Legendre moments of orders 0-39 were calculated for the 
GSR and IBI signals (features gsr_LgXX and ibi_LgXX 
respectively, where XX is the moment order), taken from the 
first 25 seconds of each trial so as to ensure uniformity in 
the extraction process. Prior to feature extraction, signals 
were sub-sampled at 4Hz and normalized to their subject-
specific 
global 
min 
and 
max 
values 
by 
)
)/(
( )
(
( )
min
max
min
X
X
X
X i
X i
−
−
=
, where X is either the GSR 
or IBI signal, X(i) is a GSR or IBI sample, Xmin and Xmax are 
the GSR or IBI signal’s min and max values recorded 
during all the specific subject’s game-playing trials. Only 
the first 40 orders were extracted as features; the use of 
higher ones would increase complexity and was not 
expected to provide added value. As shown in [10], these 
orders were capable to capture information conveyed 
through signal frequencies approximately up to 0.5Hz. 
Krawtchouk moments are based on a set of orthonormal 
polynomials; the n-order Krawtchouk classical polynomials 
are defined as: 
; 1 )
;
,
(
)
; ,
(
1
2
0
, ,
N p
x
n
F
x
a
x p N
K
N
k
k
k n p
n
− − −
=
= ∑
=
 
(3) 
where x,n=0,1…N, N>0, p belongs in the span (0,1) and 2F1 
is the hypergeometric function [18]. Weighted Krawtchouk 
polynomials (
)
( ; ,
K n x p N
) were introduced in [18]. For a 1D 
signal f(xi) of length N, the weighted Krawtchouk moments 
n
Q  are defined as: 
)
(
)1
,
;1
(
1
i
N
i
n
n
f x
p N
i
K
Q
−
−
= ∑
=
 
(4) 
343
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

where xi=i-1. In our case p was taken equal to 0.5, in order 
for the region-of-interest of the feature extraction process to 
be centered at the half of each trial’s first N samples. The 40 
first Krawtchouk moments (0-39) were calculated with (4) 
for the GSR and IBI time series (features gsr_KrXX and 
ibi_KrXX respectively, XX is the moment order), by 
following the same specifics as in the afore-described 
Legendre moments case. The analysis was restricted to the 
first 40 orders; in this case information conveyed through 
signal frequencies approximately up to 0.8Hz was captured.  
The moment-based feature variations proposed in [13] 
were also extracted and assessed over their effectiveness in 
the present work’s context. These moment-based feature 
variations have the rationale of suppressing the static 
parameter of the original moments calculation; i.e. the area 
between the projection polynomial and the x axis, which is 
always identical. By using (5) and (6) instead of (1) and (4) 
respectively, these features are defined as:  
∑
=
−
+
=
N
i
i
i
p
p
f x
x
P
p
L
1
mod
)1
)
)( (
(
)1
(2
 
(5) 
)1
)
1)( (
,
;1
(
1
mod
−
−
−
=∑
=
i
N
i
n
n
f x
p N
i
K
Q
 
(6) 
 
Based on the first 40 Legendre polynomials, 40 features 
were extracted from GSR and IBI signals (features 
gsr_LgmodXX and ibi_LgmodXX), by following the same 
procedure as in the original Legendre moment-based features 
case, and using (5) instead of (1). Similarly, by using (6) 
instead of (4), 40 further Krawtchouk-based features were 
extracted 
from 
each 
signal 
(features gsr_KrmodXX, 
ibi_KrmodXX).  
III. 
FRUSTRATION INDUCTION THROUGH REPETITIVE 
VIDEO GAME PLAYING 
All aforedescribed features were 
extracted from 
biosignals recorded through the experimental process 
described in [13]. The specific experiment had the purpose of 
naturally inducing negative emotions like boredom to 
subjects, by the repetitive playing of the same video-game. 
The game utilized was an easy “3D Labyrinth” one. In each 
repetition (trial), the subject started from the same point and 
had to find the exit of the labyrinth, which was always 
located at the same place. The “3D Labyrinth” resembled on 
its gameplay basis to modern commercial games played by 
vast amounts of gamers worldwide (i.e. 3D-based first 
person role playing games). At the same time, the overall 
repetitive playing procedure lacked in all three of Malone’s 
intrinsic qualitative factors for engaging game play 
(challenge, curiosity and fantasy) [19]. As a result, although 
at the beginning the game could be considered somewhat 
exciting, as soon as the subject had learned the shortest path 
to the labyrinth exit, boredom and negative emotions due to 
loss of interest were naturally induced. 
Taking into account the appraisal theory [20], the main 
factor manipulated during the experimental session was 
novelty, the absence of which is a key factor for boredom 
induction. Furthermore, low novelty may result to the 
induction of further emotions, such as irritation / cold anger. 
Therefore, it was rational to expect the appearance of 
frustration in subjects during the session, an emotional state 
that was monitored by self-reports (mid-trials questionnaires) 
throughout the experiment. After each trial, the subject 
answered a few questions directly assessing her/his 
emotional state. Among these questions were Likert-scaled 
(1-5, with labels in the range “Not at all”-“Very Much”) ones 
regarding the self-assessment of boredom and frustration that 
the subject experienced during the last trial, as well as one 
asking whether s/he wanted to play the game again.  
Data was collected from 19 subjects (14 male, 5 female) 
who frequently used computers in their work. These were 
between 23 and 44 years old, and their average age was 29. 
In total, 221 trials were recorded. The collected biosignals 
data was annotated as “Not Frustrated” (NF) or “Frustrated” 
(F) on the basis of the subjects answers to the frustration self 
assessment question. Each trial after which the answer to this 
question was “1” or “2” was labeled as belonging to the NF 
class. If this answer was “4” or “5”, the trial was assigned to 
the F class. Trials after which the respective answer was “3” 
were excluded from further analysis. As a result, an 
annotated dataset (A) consisting of 195 trials, 149 belonging 
to the NF and 46 to the F class, was obtained. Moreover, one 
further annotated dataset (B) was deployed, formulating a 3-
class ER problem, where trials were labeled as “not bored” 
(NB), “bored and not frustrated” (B/NF), or “bored and 
frustrated” (B/F). The idea behind dataset B was to evaluate 
the given biosignal GSR and IBI features over their 
capability to differentiate between cases of subjects who are 
1) not bored, 2) bored, but not frustrated, 3) bored, to the 
extent where frustration has also appeared during HCI. For 
this purpose, all trials after which the subject’s answer to the 
boredom self-assessment question was “1” or “2” (denoting 
absence of boredom) were annotated as NB. The rest of trials 
were annotated as B/NF or B/F, in respect to the answer to 
the frustration self-assessment question, similarly to the 
annotation of dataset A. Trials for which the answer either to 
the boredom or the frustration self-assessment question was 
“3” were excluded. As a result, dataset B consisted of 168 
trials in total, 55 NB, 70 B/NF and 43 B/F. 
IV. 
RESULTS 
Initially, the subjects’ answers to the mid-trials 
questionnaires were analyzed on the basis of Kendall’s tau 
correlation coefficient, examining correlations between 
boredom, frustration and the tendency to resign from game 
playing. Boredom correlated inversely to the subject’s 
willingness to continue playing (τ = -0.784, p<0.001, 
N=195). Inverse correlation was also found between the 
latter and the player’s frustration (τ = -0.208, p<0.001, 
N=195); frustration and boredom were also found to 
correlate (τ = 0.325, p<0.001). These results support the fact 
that boredom and frustration are two negative emotional 
states of great importance in the context of video-games. 
Their efficient automatic recognition from future game-
playing systems could contribute towards ensuring game-
playing quality and player satisfaction.  
344
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

In order to examine whether the moment-based features 
under consideration can improve automatic recognition of 
frustration that is induced during HCI, an LDA-based 
classifier was utilized, trying to solve classification problems 
related to frustration detection, which were formulated by the 
annotated data sets described above. Following leave-one-
out cross validation, the LDA weights as well as the class 
centroids were calculated on the basis of the train set, and 
each test case was classified as belonging to its less distant 
class, similarly to [13,21]. Classification accuracy was 
assessed in terms of the correct classification rate (CCR = 
number of all cases correctly classified / total number of 
cases). In order to find features with the best discrimination 
capabilities between emotional classes, a Sequential 
Backward Search (SBS) [21] feature selection process was 
employed, using the CCR as the feature selection criterion. 
SBS was applied on several initial feature sets (some of them 
described in Table II), as explained in the following. 
TABLE II.  
DESCRIPTION OF FEATURE SETS WHERE SBS WAS 
APPLIED, CONSISTING OF BOTH GSR AND IBI FEATURES 
Feature Set 
Features 
CONV 
All conventional features extracted from GSR and IBI 
M  
gsr_KrXX and ibi_LgXX features (XX=0-39) 
Mmod  
gsr_KrmodXX and ibi_LgmodXX features (XX=0-39) 
CM  
CONV and gsr_KrXX and ibi_LgXX features  
(XX=0-39) 
CMmod  
CONV and gsr_KrmodXX and ibi_LgmodXX features 
(XX=0-39) 
 
A. Frustration Detection with Conventional Features 
Using initially only GSR or IBI conventional features as 
initial feature sets for SBS, max average CCRs of 67.69% 
(132/195; NF: 102/ 149, F: 30/46) and 78.46% (153/195; 
NF: 115/149, F: 38/46) were respectively achieved. By 
fusing the GSR and IBI conventional features, feature set 
CONV was formed, from which SBS selected features: GSR 
{Mean, SD, 1st Deriv avg, 1st Deriv RMS, # of SCRs, Avg 
SCR Amplitude, δ, δnorm, fd, γnorm_FL, fd_FL}, IBI {SD, 
LF/HF, RMSSD, pNN50, γnorm, fd, Mean_FL, LF/HF_FL, 
RMSSD_FL, δ_FL, δnorm_FL}. These features achieved a 
max CCR of 83.59% in dataset A (Table III). In line with 
findings of previous works, the joint use of conventional 
GSR and IBI features was found effective towards automatic 
frustration detection, yet at a relatively limited accuracy 
level. 
TABLE III.  
CONFUSION MATRIX AFTER SBS ON CONV FEATURE SET 
Annot
ated as 
Classified 
as NF 
Classified 
as F 
Total 
CCR per 
Class 
NF 
126 
23 
149 
84.56% 
F 
9 
37 
46 
80.43% 
 
B. Frustration Detection with Moment-based Features 
Only 
Krawtchouk and Legendre moment-based features were 
found in [13] the most descriptive transformations of the 
GSR and IBI modalities respectively. Following this line, 
SBS was applied in the present study to feature sets Kgsr and 
Libi; the first contained the 40 gsr_KrXX features and the 
second the 40 ibi_LgXX ones. With Kgsr, a max CCR of 
77.44% (151/195; NF: 123/149, F: 28/46) was achieved in 
dataset A, whereas Libi produced a 68.21% (133/195; NF: 
104/149, F: 29/46) CCR. Then, feature set M was formed by 
fusing Kgsr and Libi. With this feature set, a max CCR of 
80.51% (157/195; NF: 124/149, F: 33/46) was obtained. 
Applying similar analysis for the moment-based feature 
variations, two further feature sets were fed to the SBS, 
Kmodgsr and Lmodibi, consisting of all gsr_KrmodXX and 
ibi_LgmodXX 
features 
extracted 
respectively. 
Kmodgsr 
produced a max CCR of 75.90% (148/195; NF: 122/149, F: 
26/46) and Lmodibi achieved 71.79% (140/195; NF: 116/149, 
F: 24/46). A further initial feature set was formed (Mmod) by 
fusing the above features, over which the SBS procedure 
produced a max CCR of 82.56% (161/195; NF: 129/149, F: 
32/46). Concluding, by completely replacing conventional 
features with moment-based ones, frustration detection 
accuracies close to the initial one (of the CONV feature set) 
were achieved in dataset A. 
 
Figure 1.  Max average CCRs obtained over Dataset A from the best 
features selected. 
C. Fusion of Conventional and Moment-based Features 
SBS was then applied to feature sets built from fusing the 
conventional features with the moment-based ones. Feature 
set CM consisted of the conventional features, together with 
all gsr_KrXX and ibi_LgXX ones. In the CMmod feature set, 
the gsr_KrmodXX and ibi_Lgmod XX moment-based feature 
variations were fused with the conventional features. SBS 
over CM produced a CCR of 91.79% (179/195; NF: 
142/149, F: 37/46), significantly higher (by 8.2%) than the 
result obtained from CONV. Moreover, SBS over CMmod 
achieved even higher frustration detection accuracy (Table 
IV); the best model built after SBS contained in this case 
features: GSR{gsr_KrmodXX; XX=2,4,5,8,9,14,19,20-22,26, 
27,39}, IBI{Mean, SD, LF/HF, pNN50, γnorm, fd, Mean_FL, 
345
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

LF/HF_FL, δnorm_FL, γnorm_FL, ibi_LgmodXX; XX=3-6,11,20, 
27,36,39}. 
TABLE IV.  
CONFUSION MATRIX OF SBS ON CMmod 
 (CCR=93.33%; 182/195)  
Annot
ated as 
Classified 
as NF 
Classified 
as F 
Total 
CCR per 
Class 
NF 
140 
9 
149 
84.56% 
F 
4 
42 
46 
80.43% 
 
As shown in Figure 1, fusing conventional features with 
moment-based ones significantly increased the accuracy of 
frustration detection among dataset A. Both CM and CMmod 
feature sets increased the max average CCR compared to 
CONV; by a maximum 9.74% in the latter case. The 
significance of this increase in performance was proved by a 
two-tailed paired t-test (p<0.001). Within the best final 
feature set (selected from CMmod), all conventional GSR 
features were replaced by moment-based ones, indicating the 
significance of the GSR moment-based feature variations in 
the context of automatic frustration detection. Such an 
example is the GSR SD, which although selected from 
CONV, it was discarded from SBS in the CMmod case and 
replaced by moment-based GSR features, despite the fact 
that the specific feature has been found in the past [4] 
particularly 
significant 
towards 
automatic 
frustration 
detection. Regarding the IBI signal, several moment-based 
features were selected in the final best model built; however 
they were not capable to totally replace conventional ones. 
Some of the latter (e.g. pNN50) were kept in the best model, 
and this underlines their significance towards automatic 
frustration detection. Nevertheless, it has to be noted that 
another such feature, RMSSD, was replaced by moment-
based features in the best final model built. 
D. Joint Automatic Detection of Boredom and Frustration 
The effectiveness of moment-based features was assessed 
also on the basis of a three-class ER problem, towards 
building a system capable to detect either not-bored, bored, 
or subjects being bored and frustrated as well. In order to do 
so, SBS was applied over feature sets CONV and CMmod, in 
respect of the afore-described dataset B. As shown from 
Table V, the joint use of moment-based features with 
conventional ones significantly increased (by 11.91%) the 
total accuracy of the LDA-based classifier over the given 3-
class ER problem. 
It has been shown in the past that more-than-two-class 
ER problems can be effectively split down into simpler 
binary ones, so as to increase ER efficiency [21]. Following 
this line, the afore-described original 3-class joint 
boredom/frustration recognition problem was also split into 
two binary ones; boredom and frustration detection. Two 
binary LDA classifiers were used in cascade, the first 
regarding boredom (LDA-b) and the second regarding 
frustration recognition (LDA-f). Cases were first classified as 
B/NB by LDA-b. Then, cases classified as B were fed to 
LDA-f, which decided whether the subject was also 
frustrated (B/F) or not (B/NF). Again, two feature set types 
were examined, CONV_bf and CMmod_bf. For CONV_bf, the 
best features selected from CONV in Section 4.1 and 
F_Set_C in [13] were used for the LDA-f and the LDA-b 
classifiers respectively. For CMmod_bf, the best combinations 
of conventional and moment-based features reported in 
Section 4.3 and [13] were used for the LDA-f and the LDA-b 
classifiers respectively. 
TABLE V.  
CONFUSION MATRICES PER FEATURE SET FOR THE 3-
CLASS ER PROBLEM  
Cases Classified 
as  
CCR 
Feature 
Set 
Cases 
Anno
tated 
as 
NB 
B/
NF 
B/F 
Total 
Cases 
Nr 
Per 
Class 
Total 
NB 
41 
10 
4 
55 
74.55% 
B/NF 
14 
44 
12 
70 
62.86% 
CONV 
B/F 
1 
8 
34 
43 
79.07% 
70.83% 
 
119/168 
NB 
45 
9 
1 
55 
81.82% 
B/NF 
8 
55 
7 
70 
78.57% 
CMmod 
B/F 
1 
3 
39 
43 
90.70% 
82.74% 
 
139/168 
 
Following this approach allowed conventional features to 
achieve an average CCR of 76.19% (128/168) among the 3 
classes, significantly increased (by 5.36%) compared to the 
respective result shown in Table V. Similarly, in the case of 
CMmod_bf, accuracy reached a CCR of 88.69% (149/168), 
increased by 5.95% compared to Table V. These results 
further depict the contribution of moment-based features in 
the domain of automatic ER; automatic multi-class ER 
systems based on conventional features can be enhanced 
towards increased efficiency by various techniques proposed 
in the past (e.g. [21]), and augmenting them with moment-
based features can lead to even increased effectiveness. 
V. 
CONCLUSIONS 
In this work, experimental evaluation showed that 
augmenting conventional biosignal features with moment-
based ones, significantly enhances the efficiency of binary 
frustration detection (NF vs. F), which is induced during 
HCI. Moment-based features were also found effective over 
a joint frustration and boredom detection ER problem, 
regarded from a 3-class perspective (NB vs. B/NF vs. B/F). 
When this problem was split into simpler binary ones, the 
accuracy of conventional features increased. However, the 
highest CCR was once more obtained by conventional 
features fused with moment-based ones.  
Biosignal sensors are anticipated to become wireless, 
smaller and less obtrusive in the future. This will pave the 
way for future practical HCI systems augmented with 
biosignals-based automatic affect detection capabilities. Such 
a case could be an affective game playing system that will be 
capable to understand in real-time whether negative 
emotions like frustration have appeared and subsequently 
adapt, so as to ensure game-playing quality. Similar rationale 
can be followed in further HCI constructions as well, like e-
learning systems etc. It has to be noted however, that in the 
present study, the real-time monitoring of frustration was not 
346
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

the immediate target, and off-line processing was applied to 
biosignals. Nevertheless, the on-line calculation of biosignal 
features based on the theory of moments can be regarded as 
feasible in future developments, since the processing power 
of modern PCs, along with multi-threading techniques 
already allow the simultaneous real-time extraction of large 
sets of biosingal features.   
The results of the present analysis clearly show that 
moment-based features are significantly helpful towards 
enhancing effectiveness in automatic detection of negative 
emotions like frustration induced during HCI, which is in 
turn expected to be of great importance towards future 
affective game-playing systems and other HCI applications 
as well.  
REFERENCES 
[1] J. Klein, Y. Moon, R. W. Picard. This computer responds to 
user frustration: Theory, design, and results, Interacting with 
Computers, Vol. 14, Is. 2, Feb. 2002, Pages 119-140. 
[2] C. Yun, D. Shastri, I. Pavlidis, Z. Deng, 2009. O’ game, can 
you feel my frustration?: improving user’s gaming experience 
via stresscam. CHI 2009, 2195–2204. 
[3] R.L. Mandryk, K.M. Inkpen and T.W. Calvert, Using 
psychophysiological techniques to measure user experience 
with entertainment technologies, Behaviour and Information 
Technology 25 (2) (2006), pp. 141–158. 
[4] G. N. Yannakakis, H. P. Martinez, and A. Jhala, “Towards 
Affective Camera Control in Games,” User Modeling and 
User-Adapted Interaction, vol. 20, no. 4, pp. 313–340, 2010 
[5] Stephen H. Fairclough, Fundamentals of physiological 
computing, Interacting with Computers, Volume 21, Issues 1-
2, Special issue: Enactive Interfaces, Jan. 2009, pp. 133-145. 
[6] Gilleade, K.M., Dix, A. (2004). Using frustration in the 
design of adaptive videogame. Paper presented at the 
Advances in Computer Entertainment Technology. 
[7] Eva Hudlicka. Affective game engines: Motivation and 
requirements. In Proceedings of the 4th Int. Conf. on the 
Foundations of Digital Games, pages 299–306. ACM, 2009 
[8] N. K. Sivaraman, L. L. Narayana Rao, K. L. Nitin, An 
Emotional System for Effective and Collaborative e-Learning, 
Fourth International Conference on Advances in Computer-
Human Interactions, ACHI '11, 2011 
[9] Mayer, C.; Wimmer, M.; Eggers, M.; Radig, B.; , "Facial 
Expression Recognition with 3D Deformable Models," 
Advances in Computer-Human Interactions, 2009. ACHI '09. 
Second International Conferences on , vol., no., pp.26-31, 1-7 
Feb. 2009 
[10] Z. Zeng,, M. Pantic, G. I. Roisman, T. S. Huang, “A survey of 
affect recognition methods: audio, visual, and spontaneous 
expressions”, IEEE T. Pattern Anal. Mach. Intell. 31(1): 39-
58, 2009. 
[11] S. McQuiggan, S. Lee, and J. Lester, Early prediction of 
student frustration, In Proc. of the 2nd Intl. Conf. on Affective 
Computing and Intelligent Interaction, Portugal, 2007 
[12] Ashish Kapoor, Winslow Burleson, Rosalind W. Picard, 
Automatic prediction of frustration, Int. J. Hum.-Comput. 
Stud, Volume 65, Issue 8, August 2007, Pages 724-736. 
[13] D. Giakoumis, D. Tzovaras, K. Moustakas, G. Hassapis, 
“Automatic Recognition of Boredom in Video Games using 
novel 
Biosignal 
Moment-based 
Features”. 
Affective 
Computing, IEEE Transactions on, Accepted for Publication 
[14] J. Scheirer, R. Fernandez, J. Klein, R. W. Picard, Frustrating 
the user on purpose: a step toward building an affective 
computer, Interacting with Computers, 14(2),pp.93-118, 
2002. 
[15] C.L. Lisetti and F.Nasoz, Using noninvasive wearable 
computers to recognize human emotions from physiological 
signals, EURASIP J. Appl. Signal Process, 1672-1687, Jan. 
2004 
[16] Calvo, 
R.A.; 
D'Mello, 
S., 
"Affect 
Detection: 
An 
Interdisciplinary Review of Models, Methods, and Their 
Applications,", IEEE Trans Affective Computing, 1(1), pp.18-
37, Jan. 2010 
[17] M.R. Teague, “Image analysis via the general theory of 
moments”, J. Opt. Soc. Am. 70 (8), pp. 920–930, 1980. 
[18] P-T. Yap, R. Paramesran, “Image Analysis by Krawtcouk 
Moments”, IEEE T. Image Process, 12 (11) pp. 1367-1377, 
Nov. 2003. 
[19] T. W. Malone, “What makes computer games fun?”, Byte, 
vol. 6, pp. 258–277, 1981 
[20] Scherer KR. “On the nature and function of emotion: A 
component process approach.” In: Scherer KR, Ekman P, 
eds.- Approaches to emotion. Hillsdale, NJ: Erlbaum, 
1984:293-318 
[21] J. Kim, and E. Andre, “Emotion recognition based on 
physiological changes in music listening”, IEEE Trans. 
Pattern Anal. Mach. Intell., 30(12):2067–2083, 2008 
 
 
347
Copyright (c) IARIA, 2012.     ISBN: 978-1-61208-177-9
ACHI 2012 : The Fifth International Conference on Advances in Computer-Human Interactions

