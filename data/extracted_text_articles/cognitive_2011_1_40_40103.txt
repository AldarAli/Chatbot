Discovering the Phase of a Dynamical System from a Stream of Partial Observations
with a Multi-map Self-organizing Architecture
Bassem Khouzam, HervÂ´e Frezza-Buet
Information, Multimodality and Signal
SupÂ´elec, UMI 2958 Georgia Tech/CNRS, Metz, France
{Bassem.Khouzam,Herve.Frezza-Buet}@supelec.fr
Abstractâ€”This paper presents a self-organizing architecture
made of several maps, implementing a recurrent neural net-
work to cope with partial observations of the phase of some
dynamical system. The purpose of self-organization is to set
up a distributed representation of the actual phase, although
the observations received from the system are ambiguous (i.e.
the same observation may correspond to distinct phases). The
setting up of such a representation is illustrated by experiments,
and then the paper concludes on extensions toward adaptive
state representations for partially observable Markovian deci-
sion processes.
Keywords-Dynamical Systems; Recurrent Neural Networks;
Self-Organization.
I. INTRODUCTION
In the design of artiï¬cial agents evolving in some envi-
ronment, one has to deal with information streams. Sensors
provide input streams to the information processing system
of the agent, and actuators actually produce a stream of
actions performed in order to exploit the environment. Such
an action stream is actually the output of the agent to the
environment. The coupling of the agent and the environment
through such information and energy streams is obvious for
any biologist who analyzes the behavior of some animal.
Nevertheless, in the ï¬eld of Computer Science and Machine
Learning, computation is often considered off-line, for tech-
nical reasons. The typical case is the use of data sets to train
the models, before actually using the trained models on-line.
This paper is a contribution to the part of Computer Sci-
ence that is rather involved in the design of situated systems,
thus actually focusing on the process of streams of informa-
tion. In that sense, it is related to reinforcement learning
approaches, that deal with sequential decision making of
an agent continuously interacting with its environment, as
well as temporal systems like recurrent neural networks that
handle sequences of input. Indeed, the model proposed here
allows to extract the phase of some dynamical system from a
sequence of observations computed from that phase. Let us
illustrate the need for such a feature from a straightforward
toy example.
Let us consider an animal perceiving the temperature T
of the ï¬‚oor. Let us suppose that any temperature T > T0 is
dangerous to it. In our example, the temperature oscillates
periodically between high and low values (for night and
day). The whole solar system conï¬guration is the phase of
the environment, noted xt here. It evolves in a deterministic
way, according to Newtonâ€™s law. The phase evolution is thus
driven by a transition function Ï† such as âˆ€t, xt+dt = Ï†(xt).
The temperature perceived by the animal is an observation
of the solar system, that can be expressed as T t = O (xt)
where O is the observation function, see ï¬gure 1. The sun
position in the sky P t = Oâ€²(xt) would have been another
observation of the solar system phase. Let us now consider
a time t for which the temperature T t = T0 âˆ’Ïµ is just below
the threshold. Should the animal try to hide away from the
sun? The answer depends on the phase xt, from which the
animal could know if the temperature is currently decreasing
or increasing. The decision would have been easier from
the perception of sun position P t, since Oâ€² is a bijective
function, and thus the values of P t allow to take the decision
directly from the current perception. If only T t is perceived
by the animal, an efï¬cient behavior requires that the animal
is able to represent internally a value Ë†xt from which it can
take the right decision, since values of temperature may
be ambiguous (similar temperatures are observed twice a
day). T is thus said to be a partial observation of x. The
current value Ë†xt is inferred and updated from the successive
observations T t. It is not required that Ë†x be the exact
representation of the phase x, i.e. the animal do not need to
know where the planets are, but Ë†x has to be set up such that
a bijective observation function implicitly exists from x to Ë†x.
Partially observed environments are of interest in rein-
forcement learning domain. While the general trend is to
ï¬nd Ë†xt before computing the corresponding value function
of each state, other works like [1] implement evaluation
with a recurrent network, but without explicitly extracting
some Ë†xt.
The neural architecture presented in this paper relies
on self-organizing neural networks in order to build such
an internal representation from ambiguous sequences of
observations. Many works in the literature try directly or
indirectly to ï¬nd Ë†xt. Concerning the use of self-organizing
maps, many enhancements on Kohonen basic map [2] like
in [3], [4], [5] consider the temporal dimension of input
sequences but they deal with the recognition of manually
19
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

O
X
Î¦ 
t
ot
Dynamical System
Model
t
X
^
Observer
Figure 1.
Dynamical system phase extraction.
o(t)
Delay map
Associative map
Input map
ğ´
ğ¼
ğ·
1:1
Ï
q
ğ¼q
ÏˆA= Ï€/2
Figure 2.
Model architecture. Input map and delay map are connected
via one-to-one connections, other connections are one-to-many connections
organized in strips. For unit q, Iq is the strip of kind I handled by q.
extracted sequences, rather than on-line stream of inputs.
Reservoir computing methods [6] are closer to that pur-
pose, since they handle inputs from a stream one by one.
Readout units then search the huge reservoir states in order
to locate few signiï¬cant states. The signiï¬cant states repre-
sents the phases of the system that provide the inputs.
For the best of our knowledge, the present work is the ï¬rst
attempt to ï¬nd a mapping of a dynamical system phase space
using on-line self-organizing recurrent neural networks.
II. THE MODEL
As mentioned above, our goal is to design a system
that generates an internal representation of the dynamical
system phases from the stream of observations emerging
from it. Our model is an effort in this direction, inspiring
from biological information. It is based on the
bijama
model [7], proposed and developed in our team. It enables
building computational cortical-like 2D-neural assemblies
called maps, made of computational units representing corti-
cal columns. Units allow to process in parallel external entry
and internal signals carried out by connections. A schematic
of the model is shown in Fig.s 2 and 3. The architecture
comprises three maps, namely the input map, the delay map,
and the associative map. The input map receives the external
input stream. Its activity is expected to represent at time t
the coding Ë†xt of the actual dynamical system phase xt.
The two other maps, the delay map and the associative
map are auxiliary maps that play the role of intermediate
structures for extracting Ë†xt from the input stream ot. Their
purpose is to re-inject the delayed activity of the input map
into its dynamics. This recurrent pathway actually reveals the
temporal dimension of the input stream. Map activities are
computed by a neural ï¬eld. Each unit has lateral recurrent
connections to other units within the map, implementing
an on-center/off-surround connectivity [8], [9]. The ï¬eld
performs lateral competition between units and computes
the activity of each one, so that the global map activity has
the shape of a bump (see dark meshes in Fig. 4). The bump
positions are actually the response of the map to its input.
Lateral competition, from which activity bumps emerge, is
used in the model in order to guide the process of self-
organization of inputs over the map surface. This is indeed
difï¬cult with neural ï¬elds as explained in [9] from which
the neural ï¬eld process used in this paper is taken. The
whole architecture evolution is controlled by successive time
steps. A time step is a discrete time instance at which the
activities of all units in all maps are evaluated once, using
an asynchronous evaluation scheme [9]. Another kind of
connectivity in the model is the inter-map connectivity. A
unit at the bi-dimensional position p in some local map can
be connected to a whole strip-shaped region Sp in some
remote map. Then unit p handles connections from the units
at positions q âˆˆ Sp in the remote map, as shown in Fig. 2.
Each connection in a strip between p and a remote unit q
handles a weight whose current value is Â¯st
pq, so that the strip
Sp owned by p handles a vector of weights Â¯St
p =

referred to as the thalamic module. It handles the external
input ot, and matches it against a stored prototype Ï‰t
p and
computes the similarity Î¸t
p.
Î¸t
p = eâˆ’(otâˆ’Ï‰t
p)
2
2Ïƒ2
(1)
The second module is referred to as the cortical module. It
handles the strip Ap emerging from the associative map, and
computes the matching ct
p,A between the strip weight vector
Â¯At
p and the activity vector At
p. The matching is computed
as follows, where B is a numerical constant:
ct
p,A =

At
p. Â¯At
p

max
 Â¯Atp
2, B

(2)
The third module is referred to as cortico-thalamaic
merging. It merges Î¸t
p and ct
p,A into one scalar Î½t
p as follows:
Î½t
p =
q
Î¸tp.Î² + (1 âˆ’ Î²).ct
p,A
(3)
Where Î² is a constant. The value of Î½t
p forms the ï¬nal input
ready to use by the neural ï¬eld, i.e. the upper module, to
compute the unit activity ut
p.
The unit activity is used to modulate the learning. Tha-
lamic learning implies moving Î¸t
p towards ot proportionally
to ut
p, as shown in (4).
Ï‰t+1
p
= Ï‰t
p + Î±Ï‰.ut
p.(ot âˆ’ Ï‰t
p)
(4)
Where Î±Ï‰ is a ï¬xed thalamic learning rate for all units.
On the other hand, cortical learning implies moving the
weight Â¯at
pq of each connection included in the strip Sp
towards the cortical input ut
q, as shown by 5.
Â¯at+1
pq
= Â¯at
pq + Î±S.ut
p.(ut
q âˆ’ Â¯at
pq)
(5)
Where Î±S is a ï¬xed cortical learning rate for all model
connections. The previous rule means that learning occurs
only in connections to active units in local maps.
The next map in the model is the associative map. Its
receives the actual activity of the input map as well as
its delayed activity exhibited by the delayed map, then it
performs lateral competition via the neural ï¬eld, and re-
injects the result into the input map through the previously
mentioned A strips. The ï¬rst module of a unit q of this map
handles the strip Iq emerging from input map and computes
the matching ct
q,I. The second module handles the strip Dq
emerging from delay map and computes the matching ct
q,D.
Both matching values are computed similarly to what was
shown in input map units, according to 2. The third module
is referred to as cortico-cortical merging. It merges ct
q,I and
ct
q,D in one scalar Âµt
q as follows:
Âµt
q =
q
ct
q,I.ct
q,I + noiseÂµ
(6)
copy
u
Input map
Associative map
Delay map
u
u
1:1
ğ´
ğ¼
unit p
unit q
apq
ğ·
Ï‰p
Î¸p
cp, ğ´
cq,ğ·
cq,ğ¼
Î¼q
Î½p
o
Figure 3.
Module stacks of the units in the three maps, and their cortical
inter-connections.
The purpose of noise is to boost the associative map activity
in units receiving null cortical activity before being injected
into the input map. The value of Âµt
q is actually the input to
the associative map neural ï¬eld module which computes the
unit activity ut
q.
The last map in the model is the delay map. It receives a
unit-to-unit copy of the input map activity and delays it for
some period of T time steps, using a T-length FIFO queue.
Units in this maps have two modules. The ï¬rst is the copy
module that copies ut
p from the input map. The second is
the FIFO module. Thus ut
p = utâˆ’T
q
where q is a position
in the input map and p the same position in the delay map.
There is no need for a neural ï¬eld in this map.
As can be seen, the proposed architecture requires no
prior conditions on the input stream, nor on the underlying
dynamical system, it is thus a model free architecture. The
model does not require to adjust any parameter during
execution. Learning rates are thus constant. Moreover, there
is no need for resetting output bump activities u when a new
observation oÏ„+1 is presented.
III. EXPERIMENTS
In this section, the model is tested to validate its capability
to ï¬nd an internal state representation of some unknown
dynamical system providing observations. A toy example
of dynamical system is used here to test the capacity of
spatio-temporal organization of the model. Let x âˆˆ C
represent the system phase, and let the transition function
be Ï† (x) = x.eiÏ•. Let us consider that the system transition
occurs at instant Ï„, thus we can write xÏ„+1 = Ï† (xÏ„) with
x0 = 0.5. Let the partial observation fed to the model be
O (xÏ„) = 0.5 + â„œ(xÏ„) + noiseo. Its values are kept in [0, 1].
The sampled stream values are perturbed by noise to test
the robustness to noisy observations.
The dynamical system phase can be thought of as the
position of a point moving in a steady speed on a circle,
and the observation is its noisy abscissa. This sinusoidal
observation is obviously ambiguous.
21
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

Figure 4.
Activity of model maps modules.
In this experiment, Ï„ is incremented every T time steps,
and each observation O (xÏ„) is fed to the model during T
time steps, i.e. ot = ot+1 = Â· Â· Â· ot+T âˆ’1 = O (xÏ„) and
ot+T = ot+T +1 = Â· Â· Â· ot+2T âˆ’1 = O

Successive bump positions #0
 0
 5
 10
 15
 20
 25
 30
 0
 5
 10
 15
 20
 25
 30
(a) Map activity Ï„ = 1 time steps.
Successive bump positions #132
 0
 5
 10
 15
 20
 25
 30
 0
 5
 10
 15
 20
 25
 30
(b) Map activity after Ï„ = 132 Ã— 50 i.e. t = Ï„ Ã— T = 158400 time
steps.
Successive bump positions #360
 0
 5
 10
 15
 20
 25
 30
 0
 5
 10
 15
 20
 25
 30
(c) Map activity after Ï„ = 360 Ã— 50 i.e. t = Ï„ Ã— T = 432000 time
steps.
Successive bump positions #554
 0
 5
 10
 15
 20
 25
 30
 0
 5
 10
 15
 20
 25
 30
A
B
C
D
E
(d) Map activity after Ï„ = 554 Ã— 50 i.e. t = Ï„ Ã— T = 664800 time
steps.
Figure 5.
Status of the input map during the system evolution. Grey-scaled values are the Ï‰ prototypes (white for 0, black for 1). P Ï„ is represented with
a poly-line, linking successive positions GÏ„âˆ’l+1, GÏ„âˆ’l+2, Â· Â· Â· , GÏ„, that are localized on the ï¬gures with red dots.
the poly-line. One cluster is formed by repeated visits of the
same system state. This indicates the stable representations
of states in the map space. Each thalamic region corresponds
to a range of close observations values. Within each region
there exists the representation of 2 or more states. For
example, the black region corresponds to observation values
close to 1, nevertheless, it contains 3 distinct successive state
representations marked A,B,C. When a range of observations
is located in the middle of the input values range, points
(like D,E) express non-successive states corresponding to the
same observation range, but in different temporal context.
Such duplications of states, related to the same value of
O, are progressively performed while the whole architecture
gets organized. It removes observation ambiguity. Thus, the
23
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

ensemble of state representations Ë†x (i.e. bump positions)
expresses a bijective mapping between the map surface
and the dynamical system phase space. This was possible
because the model allowed the previous state of the input
map to be considered in computing its new state, integrating
this way, its state history. The added noise to the input stream
did not affect the model capability to extract the mapping.
The experience was launched with numerical values for
the dynamical system as follows: Ï• = 2Ï€/15 and noiseo is
sampled from a uniform random noise U [âˆ’0.05, 0.05].
Model numerical values was initialized as follows: M =
30 for all maps, u0
p = 0, Ï‰0
p and Â¯a0
pq,Â¯i0
pq, Â¯d0
pq are initialized
to uniform random values from U [0, 1], Ïƒ = 0.07, Î±Ï‰ =
Î±S = 0.0416, B = 10, Î² = 0.25, noiseÂµ is sampled from
a uniform random noise U [0, 0.1], ÏI = ÏA = ÏD = 5.
ÏˆI = 90, ÏˆA = âˆ’90, ÏˆD = 0, T = 24, and l = 50.
IV. CONCLUSION AND FUTURE WORK
In this paper, a recurrent neural architecture is proposed
for setting up a representation of the phases of a dynamical
system from the stream of partial observations of that
dynamical system. The phase extraction relies on three
self-organizing modules, whose self-organizing processes
are coupled via strip-like connections, according to the
bijama model. Experiments show that this fully unsuper-
vised architecture is able to self-organize so that the token
of hidden phases of the dynamical system are explicitly
built in the input map. Indeed, for each bump position in
that map, a phase of the dynamical system can be assigned.
Moreover, the topology preservation that is expected from
self-organizing maps actually stands here, since the input
map is still a continuous mapping of the space where the
observation lives (here the interval [0, 1]).
In the one hand, seminal works by Elman and Jordan [10],
[11] have already addressed the learning of a dynamical
system from the stream of observation, but this was obtained
from a supervised approach. In the other hand, as mentioned,
reservoir computing approaches relies on high dimensional
representation spaces to build an a priori set of states, from
which the ones corresponding to the actual phases of the
system can be extracted by readout units. In both cases, the
setting up of a phase representation is not explicit. Here,
the whole architecture adapts for extracting explicit phase
representation by self-organization.
Future work will investigate the potential of the model
self-organization features in both space and time when
applied to systems exhibiting non-stationary dynamics. The
goal is to see if the model would be able to recruit new
regions in the input map or release useless regions when
the dynamic change. Future work consists also in using the
representation built in the input map as a state space for
taking decisions within Markovian decision processes. In a
more integrated model, such cortical representations could
indeed feed actor and critic neural modules, inspired from
basal ganglia modeling [12], [13], with a Markovian state
space representation that is updated from the current partial
information provided by the robot sensors.
ACKNOWLEDGMENTS
This work is part of the InterCell project supported by
INRIA, RÂ´egion Lorraine and SupÂ´elec.
http://intercell.metz.supelec.fr
REFERENCES
[1] I. Zhenzhen Liu; Elhanany, â€œA scalable model-free recurrent
neural network framework for solving pomdps,â€ in Approx-
imate Dynamic Programming and Reinforcement Learning,
2007. ADPRL 2007. IEEE International Symposium on, 2007,
pp. 119â€“126.
[2] T. Kohonen, M. R. Schroeder, and T. S. Huang, Eds., Self-
Organizing Maps, 3rd ed.
Springer-Verlag, Inc., 2001.
[3] G. J. Chappell and J. G. Taylor, â€œThe temporal kohonen map,â€
Neural Netw., vol. 6, pp. 441â€“445, March 1993.
[4] M. Varstal, J. Milln, and J. Heikkonen, â€œA recurrent self-
organizing map for temporal sequence processing,â€ in Ar-
tiï¬cial Neural Networks
ICANNâ€™97.
Springer Berlin /
Heidelberg, 1997, pp. 421â€“426.
[5] T. Koskela, M. Varsta, J. Heikkonen, and K. Kaski, â€œTime se-
ries prediction using recurrent som with local linear models,â€
Int. J. of Knowledge-Based Intelligent Engineering Systems,
pp. 60â€“68, 1997.
[6] M. LukoË‡seviË‡cius and H. Jaeger, â€œReservoir computing ap-
proaches to recurrent neural network training,â€ Computer
Science Review, vol. 3, no. 3, pp. 127â€“149, Aug. 2009.
[7] O. MÂ´enard and H. Frezza-Buet, â€œModel of multi-modal corti-
cal processing: Coherent learning in self-organizing modules,â€
Neural Networks, vol. 18, no. 5-6, pp. 646 â€“ 655, 2005,
iJCNN 2005.
[8] S. Amari, â€œDynamics of pattern formation in lateral-inhibition
type neural ï¬elds,â€ Biol Cyb, vol. 27, pp. 77â€“87, 1977.
[9] L. Alecu, H. Frezza-Buet, and F. Alexandre, â€œCan self-
organization emerge through dynamic neural ï¬elds compu-
tation? ,â€ Connection Science, vol. 23, no. 1, pp. 1â€“31, 2011.
[10] J. L. Elman, â€œFinding structure in time,â€ Cognitive Science,
vol. 14, pp. 179â€“211, 1990.
[11] M. I. Jordan, â€œAttractor dynamics and parallelism in a connec-
tionnist sequential machine,â€ in Proc. 8th Annual Conference
of the Cognitive Science Society.
Erlbaum, 1986, pp. 112â€“
127.
[12] K. Doya, â€œWhat are the computations of the cerebellum,
the basal ganglia and the cerebral cortex?â€ Neural Networks,
vol. 12, no. 7-8, pp. 961â€“974, 1999.
[13] A. Leblois, T. Boraud, W. Meissner, H. Bergman, and
D. Hansel, â€œCompetition between feedback loops underlies
normal and pathological dynamics in the basal ganglia,â€
Journal of Neuroscience, vol. 26, no. 13, pp. 3567â€“83, 2006.
24
COGNITIVE 2011 : The Third International Conference on Advanced Cognitive Technologies and Applications
Copyright (c) IARIA, 2011.     ISBN: 978-1-61208-155-7

