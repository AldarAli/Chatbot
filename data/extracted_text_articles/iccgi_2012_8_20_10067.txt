Impacts of a Whole Person eAssessment on Students’ Learning Performance  
and Faculty Development 
 
Koichi Nakajima 
Faculty of Economics 
Tezukayama University 
7-1-1 Tezukayama, Nara-city, Nara, Japan 
koichi2@tezukayama-u.ac.jp 
 
 
Abstract— We have developed an open education community 
based on our homegrown instructor-centric eTeaching system 
called TIES since 1996.  Its mission is to share educational 
content and pedagogical knowledge via the interuniversity 
collaboration. We currently host 83 universities in Japan and 
abroad with about 1,300 instructors and 70,000 students as 
users, and have more than 39,000 sharable materials.  TIES 
has an eAssessment system that assists an instructor to 
evaluate learning outcomes and levels of attainment of her 
students from a wide spectrum of their academic as well as 
non-academic efforts and performance.  The purpose of the 
system is to encourage students to self-review their intellectual 
growth, reflect on their personal attributes, and understand 
their strengths and limitations.  In this paper we elaborate 
impacts of this system on students’ learning performance from 
faculty development perspectives. We also report preliminary 
results of the new questionnaire that approximates students’ 
learning preferences, and analyze if such preferences can be 
correlated with the specific assessment attributes in the TIES 
eAssessment. 
 Keywords-TIES; eTeaching; eAssessment; faculty development; 
learning styles 
I. 
HOW TO EVALUATE STUDENT LEARNING? 
We all know that assessment is the most important issue 
with students and it defines their learning behavior in higher 
education.  Unfortunately, we observe a well-known problem 
of “surface learning” or memorization-only learning with 
little retention or use of knowledge after passing course.  
Thus we may have to conclude that our conventional 
assessment method of grading students’ achievement via 
tests and quizzes may not be enough to motivate and direct 
their learning toward “deep learning” [1]. 
In this paper, we first illustrate our eAssessment system 
that complements a standard method of marking students’ 
academic performance by encouraging students to recognize 
and develop their personal attributes and social skills.  
Second, we report preliminary results of the questionnaire 
developed to identify and approximate a learner’s learning 
preferences through his preferences for teaching styles.  The 
questionnaire attempts to identify learning preferences of a 
student in four criteria: Logic, Planning, Emotion, and 
Creativity (LPEC in short).  Third, we draw implications 
based on the data obtained from courses, and elaborate 
possible impacts of the new assessment approach on our 
pedagogical thinking and faculty development (FD in short).  
II. 
A BRIEF REVIEW OF TIES SYSTEM 
We have developed an instructor-centric “eTeaching” 
system called TIES since 1996 at Tezukayama University.  
Its goal is to help motivate and direct instructors to use IT 
effectively and happily, so that students in turn can get 
motivated and self-directed to improve learning by engaging 
in face-to-face, online or blended courses more happily and 
willingly.  
TIES community has started as a grass-roots initiative 
among a few instructors, and developed the concept of 
eTeaching based on the three principles of (1) interuniversity 
collaboration, (2) content and knowledge sharing, and (3) 
contribution to society.   
Fig. 1 summarizes the concept of eTeaching, where 
eLearning is considered to be a subset of the system inside 
the TIES eTeaching community supported by TIES Support 
Center (TIES SC in short) and interuniversity membership.  
TIES SC has helped us to develop the instructor-centric 
teaching-learning culture, and enabled our community to 
grow steadily.  We are currently hosting 83 universities 
mostly in Japan, with about 70,000 student users, and almost 
1,300 faculties.  The educational materials created by 
instructors are sharable, and amount to about 40,000 as 
shown in Table I. 
 
Harness External Resources
• Open Source
• Social Media 
• Mobile App
• Open Courseware and Education
• eLearning Consortia & NPOs
• Business World
TIES eTeaching Community
1. Content Sharing
2. Knowledge Sharing
3. Know how Sharing
4. Cost Sharing
5. System Sharing
eLearning for Students
1. Better Learning Outcome
2. Higher Self-Motivation
Increase Quantity of Content
Increase Quality of Content
TIES SC’s Functions
1. Teacher Relationship Management
2. Product Management
3. Account Management
4. R&D
Round-the-clock
Cloud Support-Monitor
 
Figure 1. The Concept of eTeaching 
 
154
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

TABLE  I. THE RECENT GROWTH OF TIES COMMUNITY 
Year
2006
2007
2008
2009
2010
2011Feb.
Institutional
Users
51
66
73
74
78
83
Instructors
320
801
907
1,021
1,099
1,271
Students
15,099
32,935
46,667
51,783
60,065
70,359
Lectures
548
817
1,053
1,345
1,582
1,810
Video Lectures
660
1,879
3,212
6,181
8,470
11,040
Sharable
Content
9,861
15,429
20,801
27,052
33,258
39,417
Lectures Open
to the Public
134
186
228
254
258
267
 
 
Fig. 2 shows a snapshot of TIES unique interface, where 
an instructor can have a bird’s-eye view of her syllabus, and 
flexibly create each lesson by selecting and arranging icons 
according to her own instructional design. She can use all the 
basic eLearning functionalities such as report and quiz 
systems, video editor, mobile learning, as well as a Web 
conference and lecture recording system, ePortfolio and 
eAssessment systems.  Its design also reflects the cultural 
preference of the Japanese students’ love of “cuteness” [2]. 
 
Each lesson can use a variety of content types and 
communication tools such as MS documents, video, PDF, 
quizzes, reports, polls, questionnaires, chat and bulletin 
board.
 
Figure 2.  TIES User Interface 
 
III. 
TIES ASSESSMENT SYSTEM AND FD 
In Japan we face the fundamental challenge of how to 
motivate students to learn more willingly and effectively, 
and also make them engage in learning more proactively.  
The development of TIES eAssessment system is a part 
of our efforts to solve the issue. The eAssessment project 
started in 2008 with a premise that our conventional grading 
system may be overly focused on academic skills, and that a 
new assessment system is needed to augment the current 
system by evaluating a student more as a whole-person [3]. 
The goal of this new assessment is to encourage students 
to understand their personal strengths and weaknesses, and to 
reflect on their social skills and self-review their intellectual 
growth.  After two years of intensive discussion involved by 
every department at Tezukayama University, we have laid 
out three basic evaluation criteria as follows:  (1) academic 
attributes, (2) personal qualities, and (3) social skills.   
Based on the three criteria, we have identified basic 
attributes and skills necessary for all students to acquire as 
well as those specific to their academic majors.  For example, 
academic attributes include abilities such as problem finding 
and solving, logical and critical thinking.  Personal qualities 
include business manners, aptitude of empathy, and venture 
spirit, among others.  Social skills cover abilities to negotiate 
and communicate with others as well as the capacity to cope 
with stress, for example.  Instructors are then advised to 
specify in the syllabus which skills and attributes are related 
to the course objectives for students to learn.  
The eAssessment system is made of a four-step process.  
In the first step, at the beginning of the course, each student 
is asked to rank listed attributes and skills according to his or 
her priority of importance.  The second step takes place at 
the end of the semester, where the student again evaluates 
the criteria in order of importance to see if there is any 
change of order after taking the course.  The third process is 
for each student to self-evaluate his progress of attainment 
on each criterion according to (1) significantly acquired more 
than before (select A), (2) acquired more than before (select 
B), and (3) unchanged (select C).  That is, if a student thinks 
he has acquired the required attributes and skills significantly 
more (more or unchanged) after taking the course than 
before the course, he selects A (B, C) in the system, 
respectively.  In the final step, the instructor evaluates the 
progress of the student same way by observing the difference 
of the student’s attainment of each criterion before the course 
and after the course.   
Fig. 3 illustrates the final outcome, and it appears in the 
student’s ePortfolio with a summary and radar chart. Table II 
is an example of the class data that help an instructor to grasp 
how students changed their attribute priorities before and 
after the course.  We often observe that students tend to mark 
A’s to the highest order of attributes.   Table II can also help 
us to identify a student who tends to select C’s regardless of 
his order of importance, and receive poor final grades often 
due to his low self-esteem and lack of self-confidence.  
Evaluating students from a wide spectrum of academic 
attributes, personality development and social skills, thus, 
has many implications on FD.  First, each instructor has to 
155
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

pay more attention to each student as an individual with vast 
potentials and abilities, and recognize him or her as “a whole 
person”.  Next, it requires an instructor to be aware of how 
her course is related to the educational mission of the 
university, and of its relevance to her department curriculum, 
when she prepares her syllabus.  Furthermore, she needs to 
focus more sharply on the objectives of her teaching context 
and related assignments in terms of the attributes that she 
expects her students to learn and acquire.  Last but not least, 
she has to assume additional responsibility for her students’ 
personal development as well as their academic performance. 
Though it requires more time and duty for an instructor 
to work on, this eAssessment system assists her to establish a 
close relationship with her students by understanding them 
better.  We believe that this understanding of a student as a 
whole person will empower an instructor to influence and 
motivate her students to learn more effectively for better 
learning outcome. 
 
Student’s Self-
assessment
Teacher’s Assessment
on Student’s Progress
Course Objectives
Student’s Priority
Before
After
Social Skills
Rational Thinking
Venture Spirit
IT Skills
 
Figure 3.  TIES eAssessment 
 
TABLE II. DATA FROM EASSESSMENT 
Low Self-
esteem
Change in Priority of 
Importance
Harmony between Self-assessment 
and Priority of Importance
Attributes Ranking 
Before the Course
Attributes Ranking 
After the Course
 
 
IV. 
LPEC QUESTIONNAIR AND FD 
In order to complement the eAssessment, we have also 
investigated the potential impact of different teaching styles 
on students’ learning motivation and performance.  As a 
result, we have developed a questionnaire called LPEC to 
assess students’ learning performance by identifying their 
preferences for teaching and class management styles, and 
tested its validity since 2005.  The questionnaire consists of 
two sets of questions, asking students what kind of class 
management and teaching styles they like and dislike.  Each 
student selects 8 out of a first set of 24 styles of class 
management and teaching styles that he likes, and another 8 
out of a second set of 24 styles that he dislikes. 
Then each one of those 8 selected answers per set of 
question is classified to four criteria of logic (L), plan (P), 
emotion (E) and creativity (C).  Finally, they are combined to 
yield the average class distribution of LPEC preferences.   
Questions to identify a student’s preference for L are like 
“teaching style based on logic, fact and evidence”, while 
“teaching style emphasizing creativity and new knowledge, a 
big picture and holistic approach” are categorized as a 
preference for C.  Similarly, keywords such as “a step-by-
step learning”, “concrete and procedural”, “teaching with a 
clear answer” are considered to belong to P, while keywords 
like “group work”, “role playing”, “student empowerment” 
are considered to show students’ preference for E.   
In this research area, the seminal work has been done by 
Felder and others [4][5]. They categorize students into four 
main learning styles as (1) active vs. reflective learners, (2) 
sensing vs. intuitive learners, (3) visual vs. verbal learners, 
and (4) sequential vs. global learners.  In order to identify 
students’ learning categories, they have created an Index of 
Learning Styles Questionnaire (ILSQ in short).  ILSQ is 
made of 44 binary questions, asking a student to answer the 
questions like “I find it easier” with (a) to learn facts, or (b) 
to learn concepts  [6].   
In addition to ILSQ, Glynn et al. propose the Science 
Motivation Questionnaire (SMQ in short) to use five factors 
that may influence a student’s learning performance.  Those 
five factors are (1) intrinsic motivation and personal 
relevance, (2) self-efficacy and assessment anxiety, (3) self-
determination, (4) career motivation, and (5) grade 
motivation [7]. 
      Our LPEC differs from ILSQ or SMQ first that the LPEC 
is trying to identify a student’s learning preferences by 
asking his preferences for teaching and class management 
styles.  This approach is based on our casual observation that 
students in Japan seem to have stronger opinions on our 
teaching styles and class management rather than their own 
learning styles.  This may be due to the fact that most of the 
students in Japan have to adapt their learning styles to their 
instructors’ teaching styles.   
Second, we also observe that students seem to know their 
likes and dislikes better than whether they are sensory or 
intuitive, and that students do not necessarily understand 
their motivation as assumed by ILSQ or SMQ.  Third, since 
students often feel lazy to answer many questions in a 
questionnaire, we have avoided asking them complicated or 
confusing questions that lose their interests.  Last but not 
least, some of our questions in LPEC reflect Japanese 
cultural values that may not be covered by ILSQ or SMQ.   
While the use of our questionnaire to identify student 
preferences is valid or not calls for more research, we like to 
present some data and attempt to interpret preliminary results.  
Fig. 4 shows the fixed-point observation of the LPEC of the 
2011 course called eLearning Economics, which teaches a 
wide range of topics from economics, finance, and IT.   
156
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

As for the eAssessment, we have selected six attributes 
for the course:  they are abilities to (1) find appropriate 
questions, (2) solve questions, (3) collect and analyze data, 
(4) take actions, (5) apply rational thinking of economics, 
and (6) pay attention to the global business trends.  
The data is collected at the beginning of the course 
(Apr.15), at the midterm (Oct.14) and at the end of the 
course (Jan.27).  The sample sizes of students answering the 
questionnaires are 37, 32, and 32, respectively.  Most of 
them are sophomore and junior students.   
Though this course is offered as one-year course, we 
announced at the end of the first half of the course before the 
summer vacation that we would change the teaching style 
radically from one-way teaching by an instructor to team 
learning and students’ engagement and empowerment.   
Fig. 4 shows a marked shift of students’ preference from 
P to E in the second half of the course.  The P type of 
teaching is a traditional teaching method of deduction, while 
E is characterized by the keywords like team work, friendly 
class atmosphere, communication and collaboration.   
 
21%
21%
19%
31%
27%
24%
18%
20%
26%
30%
32%
32%
17%
19%
21%
23%
25%
27%
29%
31%
33%
Apr.15
Oct. 14
Jan.27
Plan
Logic
Emotion
Creativity
 
Figure 4.  LPEC of eLearning Economics 
 
In addition to the shift of the students’ preferences from 
P to E, data of self-assessment results like Table II provided 
by students of the class clearly suggest that they are more 
confident of their learning performance, and that they think 
they have learned many of the assessment objectives more 
than they started the course.  And unlike a case highlighted 
in Table II, there was no student marking all C’s in this class.   
Then, we made more direct question asking the students 
which teaching style of the semester, first or second, they 
preferred.  The response is that 76% of the students preferred 
the second semester while the rest liked the first semester.  
Comments from students indicate that they think they 
learned more deeply and acquired assessment objectives 
better in the second semester than the first.  Many of them 
used the phrase like “my learning style harmonizes better 
with the teaching style of the second semester than that of 
the first”.  Thus, we conclude that the class distribution of 
LPEC can be significantly influenced if an instructor can 
prepare an appropriate instructional design to align with 
students’ tacit learning preferences.   
This result sharply contrasts with the class distribution of 
LPEC obtained from Development Economics taught in the 
same year as seen in Fig. 5, where the class size is 28.  We 
did not change the original teaching style of the class, and 
Fig. 5 suggests that students did not change their learning 
preferences, either.  Thus, the LPEC distribution is fairly 
stable throughout a year unless the instructor deliberately 
changes the “rule of the game”.   
Next, if such a conspicuous shift of the LPEC distribution 
seen in Fig. 4 frequently occurs or not, we have checked all 
the available LPEC data of the past eLearning Economics, 
and summarized them in  Table III, where S is a class size.   
Unlike the case of 2010 in Fig. 4, it is clear from Table 
III that none of the LPEC numbers taken from the past four 
years of the eLearning Economics changed abruptly.  
Likewise, we have checked the available past data of LPEC 
of Development Economics and found that they are fairly 
stable as seen in  Table IV.   
 
16%
14%
27%
30%
25%
25%
32%
31%
13%
15%
17%
19%
21%
23%
25%
27%
29%
31%
33%
Apr.4
Jan.27
Plan
Logic
Emotion
Creativity
 
Figure 5. LPEC of Development Economics 
 
TABLE III.  LPEC OF ELEARNING ECONOMICS: 2006 - 2009 
2006 Apr.14
2007Jan.12
2007Apr.20
2008Jan.25
L
19%
23%
21%
25%
P
29%
25%
27%
28%
E
18%
20%
22%
21%
C
34%
32%
30%
26%
S
115
60
45
26
2008Apr.18
2008Jul.25
2009Apr.10
2010Jan.29
L
22%
22%
21%
23%
P
27%
29%
29%
27%
E
20%
20%
20%
23%
C
31%
29%
29%
28%
S
44
40
40
33
2007
2008
2009
2006
 
 
157
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

 TABLE IV. LPEC OF DEVELOPMENT ECONOMICS: 2007-2009 
2009
2007 Apr.13
2007 Jul.13
2008 Apr.8
2008 Jul.22
2009 Apr.10
L
21%
21%
19%
18%
18%
P
23%
21%
29%
26%
27%
E
24%
29%
21%
24%
22%
C
32%
29%
31%
33%
32%
S
22
19
27
23
36
2007
2008
 
 
With a caveat that the LPEC questionnaire may not be 
valid, these preliminary LPEC course results appear to 
suggest the followings:  (1) students have tacit preferences 
for teaching style of the class, (2) these preferences are fairly 
stable and robust regardless of course characteristics, topics, 
and content, but (3) appropriate instructional design may be 
able to alter these preferences considerably.   
An immediate implication of these results to FD is that an 
instructor can accommodate students’ learning preferences 
and their assessment priority by adapting her teaching and 
class management styles to students’ preferences.  Without 
this learning-teaching alignment, both students and an 
instructor may get frustrated with each other, and students’ 
learning may deteriorate as time passes.  
More importantly, if an instructor can design her lecture 
style appropriately based on the LPEC data, she can manage 
her class more easily and expect better learning outcomes of 
students.  For example, if the instructor wants her students to 
acquire logical thinking as one of the assessment objectives, 
she can use L type of teaching style to change and direct 
students’ preferences more toward logic oriented content and 
context.   
 
V. 
CONCLUSION 
In Japan we face the urgent issue of implementing a more 
comprehensive evaluation management system, and creating 
a spontaneous and self-disciplined learning culture among 
students.   
To solve the problem, we have developed a whole-person 
approach to assess students from unconventional metrics of 
academic attributes, personal qualities, and social skills.   
To complement the eAssessment, we have also done 
research on relationship between learning styles of students 
and teaching styles of instructors, and have developed the 
questionnaire called LPEC to approximate students’ learning 
preferences via their preferences for class management and 
teaching styles.  This questionnaire is intended to augment 
the eAssessment system by assisting an instructor to align 
her teaching style with students’ assessment priority and 
preferred styles of learning.    
We have presented preliminary results based on the data 
obtained from two courses, indicating some usefulness of the 
approach.  However, eAssessment objectives are neither 
defined precisely to stand a rigorous scrutiny, nor applied 
unexceptionally.  Likewise, the LPEC questionnaire may not 
truly reflect unobservable nature and preference of students.  
Furthermore, we need to know how to teach students those 
attributes in practice.  That is, how can we teach a student, 
say, entrepreneurial spirit, which is not observable?  And 
how can we be sure that the student indeed acquires such a 
spirit after the course?   
One way to approach the problem is to use the data from 
the student’s self-evaluation of the entrepreneurial spirit as a 
dependent variable, and test its correlation with the LPEC 
distribution data to find out which style of teaching has a 
statistically significant coefficient.  That is, given that the 
student’s self-evaluation is correct, we can identify which 
teaching styles influence the student’s success of acquiring 
the qualitative concept of entrepreneurial spirit.   
Nonetheless, it seems safe to assume that students appear 
to have preferred styles of class teaching, and that they seem 
to be fairly stable, maybe due to their past learning practice.  
However, our small experiment suggests that a change of 
instructional method and goal can drastically change their 
preferences for better learning outcomes.  Thus, while we 
admit that the eAssessment with LPEC questionnaire is only 
an approximation of the student’s unobservable abilities and 
traits, we conclude that further research is worth pursuing.   
REFERENCES 
[1] F. Marton and R. Saljo, “On Qualitative Differences in 
Learning: Outcome and Process,”  British Journal of 
Educational Psychology, 46, 1976, pp. 4-11. 
[2] K. Nakajima, Mobile Internet Technology for A New Style of 
Learning and Teaching, The 2010 International Conference 
on e-Learning, e-Business, Enterprise Information Systems, & 
e-Government, EEE 2010, Proceedings, CSREA Press, 2010, 
pp. 16-20. 
[3] K. Nakajima, Innovation of TIES: eAssessment, Mobile 
Learning, and Digital Publishing, Tezukayama Journal of 
Business and Economics, vol.21, March 2008, pp. 187-197, in 
Japanese. 
[4] R.M. Felder and L.K. Silverman, "Learning and Teaching 
Styles in Engineering Education," Engineering Education, 78 
(7), 1988, pp. 674-681. The same paper with a 2002 preface is 
at http://www4.ncsu.edu/unity/lockers/users/f/felder/public/. 
[5] R.M. Felder, and B.A. Soloman, LEARNING STYLES AND 
STRATEGIES, 
http://www4.ncsu.edu/unity/lockers/users/f/felder/public/ILSd
ir/styles.htm.  
[6] B.A. Soloman, and R.M. Felder, Index of Learning Styles 
Questionnaire, 
http://www.engr.ncsu.edu/learningstyles/ilsweb.html. 
[7] S. M. Glynn, G. Taasoobshirazi, and P. Brickman, Science 
Motivation 
Questionnaire: 
Construct 
Validation 
With 
Nonscience Majors, Journal of Research in Science Teaching, 
46(2), 2009, pp. 127-146. 
 
158
Copyright (c) IARIA, 2012.     ISBN:  978-1-61208-202-8
ICCGI 2012 : The Seventh International Multi-Conference on Computing in the Global Information Technology

