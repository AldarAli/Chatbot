Detection of Pesticide Mist Distribution to Avoid Spray Drift 
 
Chaitali Dutta, Oky Dicky Ardiansyah Prima,  
Kanayo Ogura, and Koichi Matsuda 
Graduate School of Soft. and Info. Science, Iwate Prefectural University 
152-52 Sugo, Takizawa, Iwate, Japan 
e-mail: g231t202@s.iwate-pu.ac.jp, {prima, ogura_k, matsuda}@iwate-pu.ac.jp 
Shoichi Yuki 
 
YAMABIKO Corporation 
10-2 Sugo, Takizawa, Iwate, Japan 
email: s_yukixx@yamabiko-corp.co.jp 
 
 
Abstract—Agriculture has made great progress due to 
technological advances. Spraying pesticides plays an important 
role in protecting crops from insects and pests. Large 
mechanical sprayers have made it easier for farmers to spray 
large areas in a short time. However, there is a risk of pesticides 
being sprayed in unintended areas, causing damage to nearby 
fields and bodies of water. In this study, we propose an approach 
to detect pesticide mist distribution using the U-Net-based 
semantic segmentation technique. To train the semantic 
segmentation model, images of mist from sprinklers and 
gardening mist sprayers were used as training data. Our results 
show that the semantic segmentation technique could infer the 
distribution of pesticide mist. The extracted mist areas were 
found to exclude areas, such as workers, gardening poles, and 
clouds. Furthermore, we were able to estimate the Three-
Dimensional (3D) distribution of mist over the field based on the 
mist distribution in the continuous frame images. For the 
current attempt, we did not define the density of mist in the 
training data, however, we would like to consider estimating the 
density of mist in the future. 
Keywords-pesticide-mist; semantic segmentation; convolution 
neural network; agriculture; computer vision. 
I.  INTRODUCTION 
Recently, agriculture has taken leaps in production due to 
advances in engineering technology and its application in 
various key areas of agriculture. Pesticides are sprayed on 
agricultural fields to protect the crops from pests [1]. There 
are advanced sprayers, which can cover vast agricultural fields, 
such as low-pressure sprayers, high-pressure sprayers, foggers, 
air-carrier sprayers, and hand-operated sprayers. Low-
pressure sprayers are commonly mounted on a vehicle. The 
type of sprayer is chosen according to the size of the 
agricultural field. High-pressure sprayers can reach high trees 
and thick bushes. Foggers, also called mist blowers, convert 
liquid pesticides in the tank into vapor and spray them for 
intensive plant care. Air carrier sprayers use high-speed air to 
spray pesticides. Hand-operated sprayers, on the other hand, 
are used to spray small amounts of pesticides to affected areas 
and do not spray widely. 
The fine mist allows for uniform spraying of plants. The 
spread of the spray is affected by the environment [2]. As a 
result, adjacent fields and water bodies can become 
contaminated with pesticides. This problem is known as spray 
drift [3]. Research has been carried out before to mitigate this 
problem by adjusting the nozzle strength and mechanical 
tuning of the machine. However, these approaches cannot 
optimize the spraying up to a satisfactory degree because each 
time a sample must be taken from a specific distance and 
analyzed in the lab for sedimentation of the pesticide. This 
process is very time and resource-consuming. 
Artificial Intelligence and Computer Vision technology 
have been used in many fields in recent years, such as in the 
medical and automotive industries. Incorporating a Computer 
Vision approach to spray drift detection can provide highly 
accurate detection while saving time and resources. As video 
of pesticide spraying in the field is collected, tracking the 
position of the vehicle's movement from each of the video 
frames can be performed. By integrating the vehicle's position 
and spray distribution in all frames, the distribution of the 
spray in the field can be visualized in three dimensions. 
This study attempts to extract the distribution of pesticide 
mist in the video footage to create a Three-Dimensional Mist 
Model (3D-MM). The extraction is done by applying semantic 
segmentation to the video of pesticide spraying. To train the 
segmentation model, we collect public mist image data and 
manually annotate the regions of mist in the images. Finally, 
we will discuss the 3D-MM created by combining mist 
distributions extracted from all frames of the video. 
The rest of this paper is organized as follows. Section II 
discusses the related works of finding out an optimum method 
to mitigate the spray drift. Section III describes our proposed 
method to detect the mist distribution from an image. In 
Section IV, we summarize our results. Finally, Section V 
concludes our study and discusses future perspectives. 
 
II. RELATED WORKS 
Various studies have been conducted to prevent pesticide 
sprays from spreading outside the target field. The main factor 
in spreading is the size of the droplets. Droplet size depends 
on several factors, including nozzle pressure, liquid flow rate, 
air temperature, and humidity [1][4]. Small droplets are 
carried farther by the wind and thus remain suspended in the 
air for a longer period. Therefore, as droplet size decreases, 
the likelihood of spray drift increases. Most studies target 
spray drift for droplets less than 100 µm in diameter, while 
others recommend droplet thresholds of 50 µm, 150 µm, and 
200 µm in diameter [5][6]. Droplets from higher nozzles are 
more likely to be carried further by the wind before reaching 
the plant [7]. 
Attempts were made to reduce the possibility of spray drift 
by improving the air induction nozzles. However, no 
significant differences in droplet size, spray pattern width, or  
6
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

spray coverage were found [8]. Nozzles installed at 0.7 m and 
0.9 m with angles of 80° and 65°, respectively, would 
minimize spray drift. Similar results can also be obtained at 
0.5 m with an angle of 100°. Installing nozzles at lower 
positions is preferred to avoid spray drift [9]. A single nozzle 
type may not give satisfactory results in all scenarios. 
The combination of drift reduction methods consisting of 
sprayers with reflective shields and the application of coarse 
droplets may be an effective way to reduce spray drift [10]. 
Trees lined up along the wind direction in front of water 
bodies inside agricultural fields can significantly reduce spray 
drift [11]. 
There have been numerous advances in the field of deep 
neural networks for object detection and classification. 
Semantic segmentation based on Convolutional Neural 
Networks (CNNs) can classify objects at the pixel level [12] 
and learning an image of mist may be used to infer the 
distribution of pesticide mist. 
 
III. MATERIALS AND METHODS 
The task of semantic segmentation is to classify image 
classes at the pixel level. This method inherently requires the 
extraction of meaningful features in the input image, but this 
task can now be done automatically with CNNs. This study 
utilized semantic segmentation to identify the distribution of 
sprayed pesticides. Figure 1 shows how the pesticides were 
applied in our fields. The mist coming out of the nozzle 
appears white in the image, but the low-density portions are 
 
 
(a) Paddy field (big droplets) 
(b) Vegetable field (small droplets) 
Figure 1. Pesticide spraying: (a) paddy and (b) vegetable fields. 
 
 
 
Figure 2. U-Net architecture used in this study.  
7
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

translucent. The distribution of small droplets tends to spread 
in more directions because they spend more time suspended 
in the air than larger droplets. 
A. Network Architecture 
Our network architecture is based on U-Net [12], as shown 
in Figure 2. This network was built using the Neural Network 
Console [13], an engineer-oriented deep learning framework 
developed by Sony Group Inc. It consists of two major parts: 
the contracting path, which is constituted by convolution 
layers and the expanding path by deconvolution (up-
convolution) layers. Each convolution is followed by a batch 
normalization and a Rectified Linear Unit (ReLU). In total, 
the network has 11 convolutional layers. The size of the input 
image data and the resulting segmented image data is 512x512 
pixels. The Mean Squared Error (MSE) is used as the loss 
function for the network optimization process. 
B. Training 
Approximately 500 mist images were used to train the 
network. All images are resized to 512 x 512 pixels. About 
80% of these images were used for training, and the remaining 
20% were used for validation. Figure 3 shows several of 
collected mist images and their corresponding masks to train 
our network. Despite the variation in mist concentration, a 
single mask was used to represent the area where the mist is 
distributed, rather than generating masks by concentration. 
LabelMe, a labeling and annotation tool, was used for 
annotation [14].  
C. Building the 3D-MM 
The 3D-MM was generated from video footage of 
pesticide spraying in a field by integrating the segmentation 
of the mist distribution in each frame image in the depth 
direction. These bundled image data were once converted to 
point cloud data to generate volumetric data. With the 3D-
MM turned into volumetric data, the data can be sliced in any 
of the three axes allowing the distribution of mist at any point 
in the field to be viewed.  
 
IV. RESULTS 
Training and validation learning curves are as shown in 
Figure 4. The learning time required to reach 100 epochs was 
approximately one hour with a NVIDIA RTX3080 (8 GB) 
graphics accelerator. The learning and validation losses are 
smallest around the ninetieth epoch, and the difference 
between them is small. The weights of the network at this 
 
 
 
 
 
 
(a) Paddy field 
(b) Garden 
(c) Vegetable field 
Figure 3. Collected mist images (top) and their corresponding masks (bottom) to train our network. 
 
 
 
Insert images inside the table 
 
Figure 4. Training and validation learning curves of our network. 
 
8
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

point were used as the final weights in this study, and the 
learned model was generated.  
The resulting mist distributions extracted from each image 
are as shown in Figure 5. In the paddy field image, mist was 
successfully distinguished from clouds that were similar in 
color. In the vegetable field, despite the presence of people 
and gardening poles between the mist and the camera, we 
were able to successfully extract the mist area (Figure 5(b)). 
On the contrary, the extracted mist area will include the person 
behind the mist (Figure 5(c)). Overall, the results show that 
the network in this study was able to extract mist distributions 
well, although it adopted a fairly standard U-Net network.  
Figure 6 shows an Open3D visualization of the mist 
distribution at an arbitrary location from the reconstructed 3D-
MM. Our visualization method opens a new way to analyze 
mist distribution, whereas it has been difficult to confirm its 
distribution from different angles. By adding wind direction 
and speed data to this data, it may be possible to understand 
the relationship between the mist distribution and the wind. 
 
V. CONCLUSIONS AND FUTURE WORK 
In this study, we attempt to extract the distribution of 
pesticide mist in the video footage and create a 3D mist model. 
Extraction was performed by applying a U-Net based 
semantic segmentation to images of pesticide spraying. 
Despite the small number of images used to train the neural 
network, we were able to accurately extract the mist 
distribution regions in the images. The 3D mist model 
reconstructed in this study would provide further insight into 
pesticide mists and would provide an opportunity for a 
detailed analysis. As the present extraction of mist distribution 
relies on information solely from a single camera, better 
results could be obtained by adding multiple cameras or by 
considering the orientation information of the sprayer. 
ACKNOWLEDGMENT 
This work was done in collaboration with YAMABIKO 
Corporation and the Faculty of Software and Information 
Science, Iwate Prefectural University. 
 
REFERENCES 
[1] M. Farooq and M. Salyani, “Modeling of Spray Penetration and 
Deposition on Citrus Tree Canopies,” Transactions of the 
ASAE, 47(3), pp. 619-627,2004. 
[2] M. Salyani and R. P. Cromwell, “Spray Drift from Ground and 
Aerial Applications,” Transactions of the ASAE, 35(4), pp. 
1113-1120, 1992. 
[3] Introduction to Pesticide Drift, 
 
 
 
 
 
 
(a) Paddy field 
(b) Vegetable field 
(c) Vegetable field 
Figure 5. Extracted mist distributions from mist images in this study. 
 
Figure 6. Visualization of 3D-MM as volumetric data. Mist 
distribution at any location can be visualized. 
 
9
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

https://www.epa.gov/reducing-pesticide-drift/introduction-
pesticide-drift [retrieved: Jun, 2022] 
[4] K. Baetens, et al. “Predicting Drift from Field Spraying by 
Means of a 3D Computational Fluid Dynamics Model,” 
Computers and Electronics in Agriculture, 56(2), pp. 161-173, 
2007. 
[5] M. Al Heidary, J. P. Douzals, C. Sinfort, and A. Vallet, 
“Influence of Spray Characteristics on Potential Spray Drift of 
Field Crop Sprayers: A Literature Review,” Crop protection, 
63, pp. 120-130, 2014. 
[6] E. Hilz and A. W. Vermeer, “Spray Drift Review: The Extent 
to Which a Formulation Can Contribute to Spray Drift 
Reduction,” Crop Protection, 44, pp. 75-83, 2013. 
[7] P. C. H. Miller, M. B. Ellis, A. G. Lane, C. M. O'sullivan, and 
C. R. Tuck, “Methods for Minimising Drift and Off-target 
Exposure from Boom Sprayer Applications,” Aspects of 
Applied Biology, 106, pp. 281-288, 2011. 
[8] H. Guler, “Spray Characteristics and Drift Reduction Potential 
with Air Induction and Conventional Flat-fan Nozzles,” 
Transactions of the ASABE, 50(3), pp. 745-754, 2007. 
[9] J. Wilson, J. Nowatzki, and V. Hofman.  “Selecting Drift 
Reducing Nozzles,” FS-919 Revised, South Dakota Cooperative 
Extension Service and NDSU Extension Service, pp. 1- 8, 2008. 
[10] M. Wenneker and J.C. van de Zande, “Drift Reduction in 
Orchard Spraying Using a Cross Flow Sprayer Equipped with 
Reflection Shields (Wanner) and Air Injection Nozzles,” 
Agricultural Engineering International: the CIGR Ejournal, 
Manuscript ALNARP 08 014, X, pp.1-10,2008. 
[11] C. Vischetti, et al, “Measures to Reduce Pesticide Spray Drift 
in a Small Aquatic Ecosystem in Vineyard Estate.” Science of 
the Total Environment, 389(2-3), pp. 497-502, 2008. 
[12] O. Ronneberger, P. Fischer, and T. Brox, “U-Net: 
Convolutional Networks for Biomedical Image Segmentation,” 
MICCAI 2015. Lecture Notes in Computer Science, Springer, 
9351, https://doi.org/10.1007/978-3-319-24574-4_28, pp 234–
241,2015 
[13] T. Narihira,et al., “Neural Network Libraries: A Deep Learning 
Framework Designed from Engineers' Perspectives,” arXiv 
preprint arXiv:2102.06725, pp. 1- 12, 2021. 
[14] LabelMe, 
https://github.com/wkentaro/labelme   [retrieved: Jun ,2022.]
 
10
Copyright (c) IARIA, 2022.     ISBN:  978-1-61208-982-9
ACHI 2022 : The Fifteenth International Conference on Advances in Computer-Human Interactions

