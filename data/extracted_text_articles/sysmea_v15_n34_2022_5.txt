Distributionally Robust Chance-Constrained Zero-Sum Games with Moments Based
and Statistical Based Uncertainty Sets
Nguyen Hoang Nam
L2S, Centrale Supelec
University Paris Saclay
91190 Gif-sur-Yvette, France
hoang-nam.nguyen3@centralesupelec.fr
Vikas Vikram Singh
Department of Mathematics
Indian Institute of Technology Delhi
New Delhi, 110016, India
vikassingh@iitd.ac.in
Abdel Lisser
L2S, Centrale Supelec
University Paris Saclay
91190 Gif-sur-Yvette, France
abdel.lisser@centralesupelec.fr
Monika Arora
Department of Mathematics
Indraprastha Institute of Information Technology Delhi
New Delhi, 110016, India
monika@iiitd.ac.in
Abstract - We consider a two-player zero-sum game with
random linear chance constraints whose distributions are known
to belong to moments based uncertainty sets or statistical distance
based uncertainty sets. The game with chance constraints can be
used in various applications, e.g., risk constraints in portfolio
optimization, resource constraints in stochastic shortest path
problem, renewable energy aggregators in the local market.
We propose a reformulation of the chance constraints using
distributionally chance-constrained optimization framework. We
show that there exists a saddle point equilibrium of the game,
which is the optimal solution of a primal-dual pair of second-
order cone programs. As an application, we present a competition
of two firms in financial market to simulate our theoretical
results.
Keywords-Distributionally robust chance constraints; Zero-sum
game; Saddle point equilibrium; Second-order cone program.
I. INTRODUCTION
This paper is an extended version of
[1], presented at
the Seventeenth International Conference on Internet and Web
Applications and Services (ICIW), from June 26 to June 30,
2022 in Porto, Portugal.
Equilibrium is an important notion in game theory, in which
there is no incentive for any player to deviate unilaterally.
The researches in the literature usually focus on sufficient
conditions for the existence of an equilibrium point and its
characterization. The first notion of equilibrium was intro-
duced in the book Researches into the Mathematical Principles
of the Theory of Wealth by Cournot in 1838
[2]. In 1951,
Nash
[3] showed that there exists an equilibrium point in a
finite strategic game, which is known as a Nash equilibrium
nowadays. The theory of Nash equilibrium is especially hard
when it deals with practical applications with random payoffs
and strategy sets. In order to deal with random payoffs, the
most common way is using the expectation function, which
is equivalent to study deterministic payoffs. In many real life
applications, the strategy sets are restricted by random linear
constraints, which are called chance constraints. The distribu-
tion of random factors in chance constraints can be known
exactly or unknown, which leads to different approaches to
define a game. In known distribution case, the true distribu-
tion of random factors is usually assumed to be elliptically
distributed, which includes many known distributions, e.g.,
Gaussian distribution, Laplace distribution, Kotz distribution
or Pearson distribution. Otherwise, in unknown distribution
case, the true distribution of random factors is assumed to
belong to an uncertainty set, where only a partial information
of the distribution is known due to historical data and we
call these games as distributionally robust chance-constrained
games. A two-player zero-sum game is modeled using contin-
uous strategy sets, where the sum of two playersâ€™ payoffs is
zero. Consequently, it is defined using a single payoff function,
where one player plays the role of maximizer and another
player plays the role of minimizer. More commonly, a zero-
sum game is introduced with a payoff matrix, where the rows
and the columns are the actions of player 1 and player 2,
respectively. A Saddle Point Equilibrium (SPE) is the solution
concept to study the zero-sum games and it exists in the mixed
strategies
[4].
In the conference paper
[1], we considered a two player
zero-sum game with continuous strategy set, where the payoff
function has a special form and the strategies of each player are
modeled using random linear constraints reformulated as dis-
tributionally robust chance constraints. We proposed an SOCP
reformulation of distributionally robust chance constraints
under two uncertainty sets based on the partial information
about the mean vectors and covariance matrices of the random
constraint vectors. We showed the existence of an SPE and
characterized it as the optimal solution of a primal-dual pair
of SOCPs. The conference paper has some shortcomings, e.g.,
the payoff function has a quadratic form, the uncertainty sets
are mainly constructed based on moments from historical data
and it lacks of numerical results which allow us to compare
different uncertainty sets. As an extended version of
[1], our
contribution of this paper is as follows:
107
International Journal on Advances in Systems and Measurements, vol 15 no 3 & 4, year 2022, http://www.iariajournals.org/systems_and_measurements/
2022, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org

â€¢ We study a more general framework as compared to
[1] by considering two types of uncertainty sets based
on either the partial information on the mean vectors
and covariance matrices of the random constraint vec-
tors (moments based uncertainty sets) or the statistical
distance between their true distribution and a nominal
distribution (statistical based uncertainty sets). We show
that in both cases, there exists an SPE of the game and
an SPE problem is equivalent to a primal-dual pair of
SOCPs.
â€¢ As an application, we present a competition problem of
two firms in financial market and we show our numerical
results using randomly generated data to compare differ-
ent uncertainty sets considered in the paper.
We keep the same form of payoff function as considered in
the conference paper, since we need a different game model
for different form of payoff function, which would break the
uniformity of our paper. We might consider this point in future
works.
The rest of the paper is organized as follows. We present
related works in Section II. The definition of a distributionally
robust zero-sum game is given in Section III. Section IV
presents the reformulation of distributionally robust chance
constraints as second order cone constraints under different
uncertainty sets. Section V outlines a primal-dual pair of
SOCPs whose optimal solutions constitute an SPE of the
game. Section VI presents a competition of two firms in
financial market as and shows numerical results. Conclusion
and future works are given in Section VII.
II. RELATED WORK
In this section, we introduce previous studies on chance-
constrained games. Dantzig and later Adler showed the equiv-
alence between linear programming problems and two-player
zero-sum games
[5] [6]. Charnes
[7] generalized the
zero-sum game considered in
[4] by introducing linear
inequality constraints on the mixed strategies of both the
players and called it a constrained zero-sum game. An SPE
of a constrained zero-sum game can be obtained from the
optimal solutions of a primal-dual pair of linear programs
[7]. Singh and Lisser
[8] considered a stochastic version
of constrained zero-sum game considered by Charnes
[7],
where the mixed strategies of each player are restricted by
random linear inequality constraints, which are modelled using
chance constraints. When the random constraint vectors follow
a multivariate elliptically symmetric distribution, the zero-sum
game problem is equivalent to a primal-dual pair of Second-
Order Cone Programs (SOCPs)
[8]. Nash equilibrium is the
generalization of SPE and it is used as a solution concept for
the general-sum games
[3] [9]. Under certain conditions on
payoff functions and strategy sets, there always exists a Nash
equilibrium [10]. The general-sum games under uncertainties
are considered in the literature
[11]â€“[15], which capture
both risk neutral and risk averse situations. To the best of
our knowledge, the distributionally robust chance-constrained
approach has been widely studied in the literature but still not
completed in game setup. In this paper, we want to apply
different approaches in the literature to define uncertainty
sets in a distributionally robust chance-constrained game and
compare the performance of these approaches by simulation
using randomly generated data models.
III. THE MODEL
We consider a two player zero-sum game, where each player
has continuous strategy set. Let C1 âˆˆ RK1Ã—m, C2 âˆˆ RK2Ã—n,
d1 âˆˆ RK1 and d2 âˆˆ RK2. We consider X = {x âˆˆ Rm |
C1x = d1, x â‰¥ 0} and Y = {y âˆˆ Rn | C2y = d2, y â‰¥ 0}
as the strategy sets of player 1 and player 2, respectively.
We assume that X and Y are compact sets. Let u : X Ã—
Y â†’ R be a payoff function associated to the zero-sum game
and we assume that player 1 (resp. player 2) is interested in
maximizing (resp. minimizing) u(x, y) for a fixed strategy y
(resp. x) of player 2 (resp. player 1). For a given strategy pair
(x, y) âˆˆ X Ã— Y , the payoff function u(x, y) is given by
u(x, y) = xTGy + gTx + hTy,
(1)
where G âˆˆ RmÃ—n, g âˆˆ Rm and h âˆˆ Rn. The first term of (1)
results from the interaction between both the players whereas
the second and third term represents the individual impact of
player 1 and player 2 on the game, respectively. The strategy
sets are often restricted by random linear constraints, which
are modeled using chance constraints. The chance constraint
based strategy sets appear in many practical problems, e.g.,
risk constraints in portfolio optimization
[16]. In this paper,
we consider the case, where the strategies of player 1 satisfy
the following random linear constraints,
(a1
k)Tx â‰¤ b1
k, k = 1, 2, . . . , p,
(2)
whilst the strategies of player 2 satisfy the following random
linear constraints
(a2
l )Ty â‰¥ b2
l , l = 1, 2, . . . , q.
(3)
Let I1 = {1, 2, . . . , p} and I2 = {1, 2, . . . , q} be the index
sets for the constraints of player 1 and player 2, respectively.
For each k âˆˆ I1 and l âˆˆ I2, the vectors a1
k and a2
l are
random vectors defined on a probability space (â„¦, F, P). We
consider the case, where the only information we have about
the distributions of a1
k and a2
l is that they belong to some
uncertainty sets D1
k and D2
l , respectively. The uncertainty sets
D1
k and D2
l , are constructed based on the partially available
information on the distributions of a1
k and a2
l , respectively.
Using the worst case approach, the random linear constraints
(2) and (3) can be formulated as distributionally robust chance
constraints given by
inf
F 1
k âˆˆD1
k
P

for a given Î±1 = (Î±1
k)kâˆˆI1 and Î±2 = (Î±2
l )lâˆˆI2, the feasible
strategy sets of player 1 and player 2 are given by
S1
Î±1 =
n
x âˆˆ X|
inf
F 1
k âˆˆD1
k
P{(a1
k)Tx â‰¤ b1
k} â‰¥ Î±1
k, âˆ€ k âˆˆ I1
o
,
(6)
and
S2
Î±2 =
n
y âˆˆ Y |
inf
F 2
l âˆˆD2
l
P{(âˆ’a2
l )Ty â‰¤ âˆ’b2
l } â‰¥ Î±2
l , âˆ€ l âˆˆ I2
o
.
(7)
We call the zero-sum game with the strategy set S1
Î±1 for player
1 and the strategy set S2
Î±2 for player 2 as a distributionally
robust zero-sum game. We denote this game by ZÎ±. A strategy
pair (xâˆ—, yâˆ—) âˆˆ S1
Î±1 Ã— S2
Î±2 is called an SPE of the game ZÎ±
at Î± = (Î±1, Î±2) âˆˆ [0, 1]p Ã— [0, 1]q, if
u(x, yâˆ—) â‰¤ u(xâˆ—, yâˆ—) â‰¤ u(xâˆ—, y), âˆ€ x âˆˆ S1
Î±1, y âˆˆ S2
Î±2. (8)
IV. REFORMULATION OF DISTRIBUTIONALLY ROBUST
CHANCE CONSTRAINTS
We consider five different uncertainty sets based on the
partial information about the mean vectors and covariance
matrices of the random constraint vectors ai
k,
i = 1, 2,
k âˆˆ Ii and four different uncertainty sets based on the
statistical distance between the distribution of ai
k and a nom-
inal distribution. For each uncertainty set, the distributionally
robust chance constraints (4) and (5) are reformulated as
second-order cone (SOC) constraints.
A. Moments Based Uncertainty Sets
We consider five moments based uncertainty sets defined as
follows.
1) Uncertainty set with known mean and known covariance
matrix: In some situations, we do not know exactly the
true distribution of the random constraint vectors ai
k, for all
k âˆˆ Ii, i = 1, 2. We can only obtain some information of the
underlying distribution from historical data. For example, by
observing a sufficiently large number of data, we deduce the
values of mean vector and covariance matrix of ai
k approx-
imated by the sample mean Âµi
k and the sample covariance
matrix Î£i
k. We consider an uncertainty set, which includes all
distributions F i
k with mean vector Âµi
k and covariance matrix
Î£i
k defined as follows
D1,i
k

where Î³i
k > 0 is a strictly positive real number, Î£i
k is a positive
definite matrix, for the given matrices B1 and B2, B1 âª¯ B2
implies that B2 âˆ’ B1 is a positive semidefinite matrix. In
practical applications, we usually approximate the matrix Î£i
k
by the sample covariance matrix. The parameter Î³i
k is used in
controlling the uncertainty level, i.e., high value of Î³i
k implies
a large number of distributions in the uncertainty set, which
deals uncertain factors in a more secure way. We consider un
uncertainty set, which includes all distributions F i
k with mean
vector Âµi
k and covariance matrix satisfied the above constraint
as follows
D2,i
k

Using the similar arguments as in the Lemma 1, the constraint
(4) is equivalent to
b1
k + v1(x)
p
v2(x)
â‰¥
s
Î±1
k
1 âˆ’ Î±1
k
,
(19)
where
v1(x) =
ï£±
ï£²
ï£³
min
Âµ âˆ’ÂµTx
s.t.

and Î£i
k+ = Î£i
k + Ïµi
Î£,k. We consider an uncertainty set, which
includes all distributions F i
k defined as follows
D5,i
k (Âµi
k, Î£i
k) =
ï£±
ï£²
ï£³F i
k

The distribution of x is F i
k
Âµi
kâˆ’ â‰¤ E[x] â‰¤ Âµi
k+,
Î£i
kâˆ’ â‰¤ Cov[x] â‰¤ Î£i
k+
ï£¼
ï£½
ï£¾ ,
(25)
Since Î£i
k is a positive definite matrix, we can take Ïµi
Î£,k > 0
such that for any matrix H, if Î£i
kâˆ’ â‰¤ H â‰¤ Î£i
k+, then H is
a positive definite matrix. We define a set of vectors S1
k as
follows
S1
k =

Âµ âˆˆ Rm | Âµ(j) = Âµ1
kâˆ’(j) or Âµ1
k+(j), âˆ€ j = 1, . . . , m
	
,
where Âµ(j) is the jthâˆ’ component of Âµ,
Âµ1
kâˆ’(j) is the jthâˆ’
component of Âµ1
kâˆ’, and Âµ1
k+(j) is the jthâˆ’ component of Âµ1
k+.
For example, if Âµ1
kâˆ’ = (1, 2)T, Âµ1
k+ = (5, 6)T, then S1
k is a set
of 4 vectors

(1, 5)T, (1, 6)T, (2, 5)T, (2, 6)T	
. We define a set
of covariance matrix T 1
k as follows
T 1
k =

Î£ | Î£(j, w) = Î£1
kâˆ’(j, w) or Î£1
k+(j, w), 1 â‰¤ j, w â‰¤ m
	
,
Similarly, we define a set of vectors S2
k and a set of covariance
matrix T 2
k . The uncertainty set (25) is considered in [17]. We
assume that for each i = 1, 2 and k âˆˆ Ii, the true distribution
of ai
k belongs to the uncertainty set D5,i
k

TABLE I
LIST OF SELECTED Ï•âˆ’DIVERGENCES WITH THEIR CONJUGATE
RESPECTIVELY
Divergence
Ï•(t), t â‰¥ 0
Ï•âˆ—(s)
Kullback-Leibler
t log(t) âˆ’ t + 1.
es âˆ’ 1
Variation distance
|t âˆ’ 1|.
âˆ’1,
s â‰¤ âˆ’1,
s,
âˆ’1 â‰¤ s â‰¤ 1,
+âˆ,
s > 1.
Modified Ï‡2 - distance
(t âˆ’ 1)2.
âˆ’1,
s â‰¤ âˆ’2,
s + s2
4 ,
s > âˆ’2.
Hellinger distance
(
âˆš
t âˆ’ 1)2.
s
1âˆ’s,
s < 1,
+âˆ,
s â‰¥ 1.
Lemma 6. The constraint (4) is equivalent to
sup
Î»>0,Î²âˆˆR

f 1
k(Î», Î²)
	
â‰¥ Î±1
k,
(30)
where f 1
k(Î», Î²)
=
Î² âˆ’ Î»Î¸1
k âˆ’ Î»Ï•âˆ— 
âˆ’1+Î²
Î»

PÎ½1
k(M 1
k) âˆ’
Î»Ï•âˆ— 
Î²
Î»
 h
1 âˆ’ PÎ½1
k(M 1
k)
i
, and M 1
k =

Î¾ âˆˆ Rm | Î¾Tx â‰¤ b1
k
	
.
The constraint (5) is equivalent to
sup
Î»>0,Î²âˆˆR

f 2
k(Î», Î²)
	
â‰¥ Î±2
k,
where f 2
k(Î», Î²)
=
Î² âˆ’ Î»Î¸2
k âˆ’ Î»Ï•âˆ— 
âˆ’1+Î²
Î»

PÎ½2
k(M 2
k) âˆ’
Î»Ï•âˆ— 
Î²
Î»
 h
1 âˆ’ PÎ½2
k(M 2
k)
i
, and M 2
k =

Î¾ âˆˆ Rn | Î¾Tx â‰¤ b2
k
	
.
Proof. For k âˆˆ I1, consider the following optimization prob-
lem
vP
k =
inf
F 1
k âˆˆDÏ•,1
k
P

â€¢ If the uncertainty set is defined by (12), then ÎºÎ±i
k =
r
Î±i
k
1âˆ’Î±i
k
p
Î³i
k and N1 = P1 = N2 = P2 = 1, for all
i = 1, 2,
k âˆˆ Ii.
â€¢ If the uncertainty set is defined by (16), then ÎºÎ±i
k =
r
Î±i
k
1âˆ’Î±i
k
p
Î³i
k2 +
p
Î³i
k1

and N1 = P1 = N2 = P2 =
1, for all i = 1, 2,
k âˆˆ Ii.
â€¢ If the uncertainty set is defined by (21), then ÎºÎ±i
k =
r
Î±i
k
1âˆ’Î±i
k and N1 = P1 = N2 = P2 = M, for all i = 1, 2,
k âˆˆ Ii.
â€¢ If the uncertainty set is defined by (25), then ÎºÎ±i
k =
r
Î±i
k
1âˆ’Î±i
k and N1 = 2m; P1 = 2(m2), N2 = 2n, P2 =
2(n2), for all i = 1, 2,
k âˆˆ Ii.
â€¢ If the uncertainty set is defined by (29), then ÎºÎ±i
k =
Î¦(âˆ’1) 
H(Î¸i
k, 1 âˆ’ Î±i
k)

and N1 = P1 = N2 = P2 = 1,
where H and Î¦(âˆ’1) are defined in Lemma 7.
We assume that the strategy sets (35) and (36) satisfy the strict
feasibility condition given by Assumption 1.
Assumption 1.
1) There exists an x âˆˆ S1
Î±1 such that the
inequality constraints of S1
Î±1 defined by (35) are strictly
satisfied.
2) There exists an y
âˆˆ S2
Î±2 such that the inequality
constraints of S2
Î±2 defined by (36) are strictly satisfied.
The conditions given in Assumption 1 are Slaterâ€™s condition,
which are sufficient for strong duality in a convex optimization
problem. We use these conditions in order to derive equivalent
SOCPs for the zero-sum game ZÎ±.
V. EXISTENCE AND CHARACTERIZATION OF SADDLE
POINT EQUILIBRIUM
In this section, we show that there exists an SPE of the
game ZÎ± if the distributions of the random constraint vectors
of both the players belong to the uncertainty sets defined in
Sections IV-A and IV-B. We further propose a primal-dual pair
of SOCPs whose optimal solutions constitute an SPE of the
game ZÎ±.
Theorem 1. Consider the game ZÎ±, where the distributions of
the random constraint vectors ai
k, k âˆˆ Ii, i = 1, 2, belong to
the uncertainty sets described in Sections IV-A and IV-B. Then,
there exists an SPE of the game for all Î± âˆˆ (0, 1)p Ã— (0, 1)q.
Proof. Let Î± âˆˆ (0, 1)pÃ—(0, 1)q. For uncertainty sets described
in Sections IV-A and IV-B, the strategy sets S1
Î±1 and S2
Î±2 are
given by (35) and (36), respectively. It is easy to see that S1
Î±1
and S2
Î±2 are convex and compact sets. The function u(x, y)
is a bilinear and continuous function. Hence, there exists an
SPE from the minimax theorem
[4].
A. Equivalent Primal-Dual Pair of Second-Order Cone Pro-
grams
From the minimax theorem [4], (xâˆ—, yâˆ—) is an SPE for the
game ZÎ± if and only if
xâˆ— âˆˆ arg max
xâˆˆS1
Î±1
min
yâˆˆS2
Î±2
u(x, y),
(37)
yâˆ— âˆˆ arg min
yâˆˆS2
Î±2
max
xâˆˆS1
Î±1
u(x, y).
(38)
We start with the optimization problem
min
yâˆˆS2
Î±2
max
xâˆˆS1
Î±1
u(x, y).
By introducing auxiliary variables t1
kjw, the inner optimization
problem maxxâˆˆS1
Î±1 u(x, y) can be equivalently written as
max
x, t1
kjw
xTGy + gTx + hTy
s.t.
(i)
âˆ’ xTÂµ1
kj âˆ’ ÎºÎ±1
k
t1
kjw

2 + b1
k â‰¥ 0,
âˆ€ j = 1, 2 . . . , N1, w = 1, 2 . . . , P1, k âˆˆ I1,
(ii)
t1
kjw âˆ’

The first term of the objective function is a function of x
xTh
Gy âˆ’ (C1)TÎ½1 + g
âˆ’
X
kâˆˆI1
N1
X
j=1
P1
X
w=1

be optimal solutions of (42) and (43), respectively. Under
Assumption 1, (42) and (43) are strictly feasible. Therefore,
strong duality holds for primal-dual pair (42)-(43). Then, we
have
gTxâˆ— + (Î½2âˆ—)Td2 âˆ’
X
lâˆˆI2
N2
X
j=1
P2
X
w=1
Î»2âˆ—
ljwb2
l
= hTyâˆ— + (Î½1âˆ—)Td1 +
X
kâˆˆI1
N1
X
j=1
P1
X
w=1
Î»1âˆ—
kjwb1
k.
(44)
Consider the constraint (i) of (42) at optimal solution
(yâˆ—, Î½1âˆ—, Î´1âˆ—
kjw, Î»1âˆ—
kjw) and multiply it by xT, for any x âˆˆ S1
Î±1,
we have
xTGyâˆ— + gTx â‰¤ xT(C1)TÎ½1âˆ—
+
X
kâˆˆI1
N1
X
j=1
P1
X
w=1
h
xTÂµ1
kjÎ»1âˆ—
kjw + xT(Î£1
kw)
1
2 Î´1âˆ—
kjw
i
.
(45)
By using the Cauchy-Schwartz inequality, for any
k âˆˆ
I1, j = 1, 2 . . . , N1, w = 1, 2 . . . , P1, we have
xT(Î£1
kw)
1
2 Î´1âˆ—
kjw â‰¤ âˆ¥(Î£1
kw)
1
2 xâˆ¥2âˆ¥Î´1âˆ—
kjwâˆ¥2.
Using the constraint (ii) of (43), the above constraint implies
that
(xâˆ—)T(Î£1
kw)
1
2 Î´1âˆ—
kjw â‰¤ âˆ¥(Î£1
kw)
1
2 xâˆ¥2ÎºÎ±1
kÎ»1âˆ—
kjw.
Since x âˆˆ S1
Î±1, we have
C1x = d1.
Then, the constraint (45) implies that
xTGyâˆ— + gTx â‰¤ (Î½1âˆ—)Td1
+
X
kâˆˆI1
N1
X
j=1
P1
X
w=1
h
xTÂµ1
kjÎ»1âˆ—
kjw + (Î£1
kw)
1
2 xâˆ¥2ÎºÎ±1
kÎ»1âˆ—
kjw
i
,
which in turn implies by using the constraint (iii) of (43) that
xTGyâˆ— + gTx â‰¤ (Î½1âˆ—)Td1 +
X
kâˆˆI1
N1
X
j=1
P1
X
w=1
Î»1âˆ—
kjwb1
k.
Then, for any x âˆˆ S1
Î±1, we have
xTGyâˆ— + gTx + hTyâˆ— â‰¤ hTyâˆ— + (Î½1âˆ—)Td1
+
X
kâˆˆI1
N1
X
j=1
P1
X
w=1
Î»1âˆ—
kjwb1
k.
(46)
Similarly, for any y âˆˆ S2
Î±2, we have
(xâˆ—)TGy + gTxâˆ— + hTy â‰¥ gTxâˆ—
+ (Î½2âˆ—)Td2 +
X
lâˆˆI2
N2
X
j=1
P2
X
w=1
Î»2âˆ—
ljwb2
l .
(47)
Take x = xâˆ— and y = yâˆ— in (46) and (47), then from (44), we
get
u(xâˆ—, yâˆ—) = hTyâˆ— + (Î½1âˆ—)Td1 +
X
kâˆˆI1
N1
X
j=1
P1
X
w=1
Î»1âˆ—
kjwb1
k
= gTxâˆ— + (Î½2âˆ—)Td2 +
X
lâˆˆI2
N2
X
j=1
P2
X
w=1
Î»2âˆ—
ljwb2
l .
(48)
It follows from (46), (47), and (48) that
u(x, yâˆ—) â‰¤ u(xâˆ—, yâˆ—) â‰¤ u(xâˆ—, y), âˆ€ x âˆˆ S1
Î±1, y âˆˆ S2
Î±2,
which in turn implies that (xâˆ—, yâˆ—) is an SPE of the game
ZÎ±.
VI. NUMERICAL RESULTS
A. Competition in Financial Market
In this section, we consider a competition of two firms in
financial market. They invest in the same set of portfolios. Let
P = {1, 2, . . . , NP } be the set of portfolios. Let Aj be the set
of assets in the portfolio j. Assume that the sets Aj and Ak are
disjoint, for any j Ì¸= k. Let xk = (xkj)jâˆˆAk be the investment
vector of firm 1 in portfolio k and yk = (ykj)jâˆˆAk be the
investment vector of firm 2 in portfolio k. Let x = (xk)kâˆˆP
and y = (yk)kâˆˆP be the investment vector of firm 1 (resp. firm
2). The set of investments X of firm 1 is defined as follows
X =
ï£±
ï£²
ï£³x

X
jâˆˆAk
xkj = W 1
k , âˆ€j âˆˆ Ak, k âˆˆ P
ï£¼
ï£½
ï£¾ ,
and the set of investments Y of firm 2 is defined as follows
Y =
ï£±
ï£²
ï£³y

X
jâˆˆAk
ykj = W 2
k , âˆ€j âˆˆ Ak, k âˆˆ P
ï£¼
ï£½
ï£¾ ,
where W i
k is the total investment of firm i in portfolio k, for
any i = 1, 2 and k âˆˆ P. Let Li
k = (Li
kj)jâˆˆAk be a random loss
vector of firm i from portfolio k. Then, for a given investment
vector xk and yk, the total loss of firm 1 (resp. firm 2) caused
by portfolio k is defined as (L1
k)Txk (resp. (L1
k)Tyk). Each firm
wants to make sure that their random loss is below a maximal
allowable loss level with high probability. This condition is
modeled by the following inequality
P

(L1
k)Txk â‰¤ b1
k
	
â‰¥ Î±1
k,
(49)
and
P

(L2
l )Tyl â‰¤ b2
l
	
â‰¥ Î±2
l ,
(50)
where bi
k are deterministic vectors and Î±i
k are confidence
levels,
i = 1, 2, k âˆˆ P. We assume that the true distribution
of random loss vectors is unknown, but only known to belong
to some uncertainty set Di
k defined in Section IV. Then, the
feasible strategy sets of two firms are given by
inf
F 1
k âˆˆD1
k
P

(L1
k)Txk â‰¤ b1
k
	
â‰¥ Î±1
k, âˆ€ k âˆˆ P,
116
International Journal on Advances in Systems and Measurements, vol 15 no 3 & 4, year 2022, http://www.iariajournals.org/systems_and_measurements/
2022, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org

and
inf
F 2
l âˆˆD2
l
P

(L2
l )Tyl â‰¤ b2
l
	
â‰¥ Î±2
l , âˆ€ l âˆˆ P.
We assume that the total profit of both firm is zero, i.e., for
each profile of strategies (x, y) âˆˆ X Ã— Y , if firm 1 gains
a profit u(x, y), then firm 2 gains a profit âˆ’u(x, y). Firm 1
wants to maximize u
w.r.t
x, for y âˆˆ S2
Î±2 and firm 2 wants
to minimize u
w.r.t
y, for x âˆˆ S1
Î±1. We assume that u has
the form (1), i.e., u(x, y) = xTGy + gTx + hTy.
In order to find an SPE of (8), we solve the two SOCP
problems (42) and (43) using coneqp solver in CVXOPT. We
compare the uncertainty sets defined in Section (IV) with the
true model, in which we assume that the true distribution of
random loss vectors is known and follows Gaussian distribu-
tion. In this case, it is well known that the constraints (49) and
(50) are equivalent to SOC constraints
[25]. An SPE in true
model can be computed by solving an SOCP reformulation
[8].
B. Case Study
All
the
numerical
results
below
are
performed
us-
ing Python 3.8.8 on an Intel Core i5-1135G7, Proces-
sor 2.4 GHz (8M Cache, up to 4.2 GHz), RAM 16G,
512G SSD. We consider two firms investing in a port-
folio consists of four assets, i.e., P
= {1} and A1 =
{1, 2, 3, 4}. We generate randomly the vectors g and h in
(1) in [âˆ’3, 3]4 by the command â€numpy.random.uniform(-
3,3,size=(4,1))â€. The matrix G in (1) is randomly generated
by the command â€numpy.random.uniform(-3,3,size=(4,4))â€.
We take the confidence levels of two firms as Î±1
=
Î±2 = 0.9, the total investment of two firms in the port-
folio W 1
1 and W 2
1 are randomly generated on [20, 80] by
the command â€numpy.random.uniform(20,80)â€. The max-
imal
allowable
loss
levels
of
two
firms
b1
1
and
b2
1
are randomly generated on [100, 500] by the command
â€numpy.random.uniform(100,500)â€. The probability distribu-
tion of the loss of two firms L1
1 and L2
1 are assumed to
be Normal distributions with mean vector Âµ1
1 (resp. Âµ2
1)
and covariance matrix Î£1
1 (resp. Î£2
1). The mean vectors
are randomly generated on [8, 12]4 using the command
â€numpy.random.uniform(8,12, size=(4,1))â€. The covariance
matrix are defined as follows
Î£i
1 = AAT
4
+ I4, âˆ€ i = 1, 2,
where
A
is
a
4 Ã— 4
random
matrix
whose
all
entries
belong
to
[0, 1]
generated
by
the
command
â€A=numpy.random.random(size=(4,4))â€
and
I4
denotes
4 Ã— 4 identity matrix. For any i = 1, 2, we define sample
mean vector Âµi
sample and Î£i
sample by generating randomly a
sample of 100 observations Î¾i
1, . . . , Î¾i
100, which follow Normal
distribution with mean vector Âµi
1 and covariance matrix Î£i
1.
To do that, we generate a standard Gaussian vector by the
command
â€x=numpy.random.normal(0,1,4)â€.
We
generate
a Gaussian vector with mean vector Âµi
1 and Î£i
1 by taking
Î¾i
j = Bx + Âµi
1, where B is the Cholesky factorization of Î£i
1.
To get the Cholesky factorization of a matrix, we use the
command â€numpy.linalg.choleskyâ€. The sample mean vector
Âµi
sample and the covariance matrix Î£i
sample are defined as
follows
Âµi
sample =
1
100
100
X
j=1
Î¾i
j,
Î£i
sample = 1
99
100
X
j=1
(Î¾i
j âˆ’ Âµi
sample)(Î¾i
j âˆ’ Âµi
sample)T.
Now, we define other parameters for each model. For the
uncertainty set (12), we take Î³i
1 = 1.1, for any i = 1, 2. For
the uncertainty set (16), we take Î³i
11 = Î³i
12 = 1, for any
i = 1, 2. We take the uncertainty set (21) similarly as the
uncertainty set (9) by choosing M = 1. For the uncertainty
set (25), we take the radius vector Ïµi
Âµ,1 = (0.1, 0.1, 0.1, 0.1)4
and the radius matrix Ïµi
Î£,1 = 0.1 Ã— I4, for any i = 1, 2, where
I4 is 4 Ã— 4 identity matrix. For the uncertainty set (29), we
take Î¸i
1 = 0.05, for any i = 1, 2.
For the above instance, we compute an SPE of the true
model, where the true distribution of random loss vectors L1
1
and L2
1 follow Gaussian distributions with mean vector Âµ1
1
(resp. Âµ2
1) and covariance matrix Î£1
1 (resp. Î£2
1). We obtain an
SPE (xâˆ—, yâˆ—) given by
xâˆ— = (18.91, 19.45, 19.45, 20.22)T,
yâˆ— = (19.01, 20.15, 20.45, 18.71)T.
The profit of firm 1 for this instance is u(xâˆ—, yâˆ—) = âˆ’275.52.
Now, we calculate an SPE of the models defined in Section
(IV). For the uncertainty sets (9), (12), (16), (21) and (25), we
take Âµi
1 = Âµi
sample and Î£i
1 = Î£i
sample, for any i = 1, 2.
For the uncertainty set (29), we assume that the nominal
distribution Î½i
1 follows a Gaussian distribution with mean
vector Âµi
sample and covariance matrix Î£i
sample. We compare
the optimal profit value of firm 1 in above models with the
optimal profit value of firm 1 in the true model. The results
are given in Table III. We can see that for this instance, the
models defined by Ï•âˆ’divergence give better solution than the
models defined by moments since the optimal profit value in
Ï•âˆ’divergence uncertainty sets approximates well the optimal
profit value in true model. We also present the time analysis
TABLE III
LIST OF OPTIMAL PROFIT VALUES u(xâˆ—, yâˆ—)
True model
Known Mean
Known Covariance
Known Mean
Unknown Covariance
Unknown Mean
Unknown Covariance
Polytopic
-257.52
-221.11
-222.5
-224.8
-221.11
Componentwise
Bounds
Kullback
Leibler
Variation
Distance
Modified
Ï‡2 - distance
Hellinger Distance
-223.3
-255.1
-256.23
-255.8
-253.9
for a large numbers of assets size model by considering the
number of assets between 100 and 1000. For each case of
number of assets, we randomly generate 10 instances of the
known mean known covariance model, where the parameters
are defined similarly as above and we calculate the average
running time (in seconds) to solve the two optimization
117
International Journal on Advances in Systems and Measurements, vol 15 no 3 & 4, year 2022, http://www.iariajournals.org/systems_and_measurements/
2022, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org

problems (42) and (43). The results are given in Figure 1.
Fig. 1. CPU time (in seconds) to solve (42) and (43) in known mean known
covariance cases with different number of assets.
It is clear from Figure 1 that our optimization problems can
be solved efficiently in high dimension up to 1000 assets.
VII. CONCLUSION AND FUTURE WORK
We study a more general two player zero-sum game than
the model considered in
[1] under various moments based
and statistical based uncertainty sets. We propose a reformu-
lation of the chance constraints using distributionally chance-
constrained optimization framework and show that there exists
a mixed strategy SPE of the game. Under Slaterâ€™s condition,
the SPE of the game can be obtained from the optimal
solutions of a primal-dual pair of SOCPs. We present a
competition of two firms in financial market as an application
to figure out out theoretical results. The numerical experiments
are performed using randomly generated data on the game
up to 1000 assets and it is clear from our time analysis
that the SOCPs problems can be computed efficiently. For
our future works, we will study tractable reformulation of
the zero-sum game problem with different payoff structure
in a different game model and apply the game problem in
a different application to the competition in financial market
considered in this paper.
ACKNOWLEDGEMENT
This research was supported by DST/CEFIPRA Project No.
IFC/4117/DST-CNRS-5th call/2017-18/2 and CNRS Project
No. AR/SB:2018-07-440.
APPENDICES
APPENDIX A: PROOF OF LEMMA 7 - CASE HELLINGER
DISTANCE
For i = 1, 2 and k âˆˆ Ii, it suffices to calculate the value
of supÎ»>0,Î²âˆˆR

f i
k(Î», Î²)
	
with Hellinger distance divergence.
We consider two cases as follows
â€¢ Case 1: Î²
Î» < 1 â‡” Î² < Î». We have
Ï•âˆ—
Î²
Î»

=
Î²
Î» âˆ’ Î² ,
Ï•âˆ—
Î² âˆ’ 1
Î»

=
Î² âˆ’ 1
Î» + 1 âˆ’ Î² .
Therefore,
sup
Î»>0,Î²âˆˆR

f i
k(Î», Î²)
	
=
sup
Î»>0,Î²âˆˆR
PÎ½i
k(M i
k)
Î»2
(Î» âˆ’ Î²)(Î» âˆ’ Î² + 1) +
Î²2
Î² âˆ’ Î» âˆ’ Î»Î¸i
k.
Since Î» > 0 and Î² < Î», let Î³ = Î» âˆ’ Î², we deduce that
sup
Î»>0,Î²âˆˆR

f i
k(Î», Î²)
	
=
sup
Î»>0,Î³>0
(
Î»2
 
PÎ½i
k(M i
k)
Î³(Î³ + 1) âˆ’ 1
Î³
!
+ Î»(2 âˆ’ Î¸i
k) âˆ’ Î³
)
.
Let Q(Î», Î³) = Î»2

PÎ½i
k (M i
k)
Î³(Î³+1) âˆ’ 1
Î³

+Î»(2âˆ’Î¸i
k)âˆ’Î³. Note
that 0 â‰¤ PÎ½i
k(M i
k) â‰¤ 1 and Î³ > 0. Therefore, Q(Î», Î³) is
a second-order polynomial of Î» and the coefficient of Î»2
is negative. It is well known that the maximum value of
a second order function f(x) = ax2 + bx + c with a < 0
is c âˆ’ b2
4a and it holds at x = âˆ’b
2a . Hence, the maximum
value of Q(Î», Î³) holds at Î»âˆ— =
Î³(Î³+1)(2âˆ’Î¸i
k)
2(1+Î³âˆ’PÎ½i
k (M i
k)). Since
Î¸i
k < 2, it is clear that Î»âˆ— > 0. Then, the optimal value
of supÎ»>0,Î²âˆˆR

f i
k(Î», Î²)
	
holds when Î» = Î»âˆ— and we
have
sup
Î»>0,Î²âˆˆR

f i
k(Î», Î²)
	
= sup
Î³>0
(
âˆ’Î³ +
(2 âˆ’ Î¸i
k)2Î³(Î³ + 1)
4(Î³ + 1 âˆ’ PÎ½i
k(M i
k))
)
.
(51)
Let u = Î³ + 1 âˆ’ PÎ½i
k(M i
k), then u > 1 âˆ’ PÎ½i
k(M i
k).
Rewriting (51) as a function of u, we have:
sup
Î»>0,Î²âˆˆR

f i
k(Î», Î²)
	
=
sup
u>1âˆ’PÎ½i
k (M i
k)
F(u),
=
sup
u>1âˆ’PÎ½i
k (M i
k)

au + b
u + c

,
where a =

(2âˆ’Î¸i
k)2
4
âˆ’ 1

,
b =
(2âˆ’Î¸i
k)2PÎ½i
k (M i
k)(PÎ½i
k (M i
k)âˆ’1)
4
,
c = 1âˆ’PÎ½i
k(M i
k)+
(2âˆ’Î¸i
k)2(2PÎ½i
k (M i
k)âˆ’1)
4
. Note that a < 0
and b â‰¤ 0. We have: F
â€²(u) = a âˆ’
b
u2 . Hence, it can be
shown that F is decreasing on (uâˆ—, +âˆ), increasing on
(âˆ’uâˆ—, uâˆ—) and decreasing on (âˆ’âˆ, âˆ’uâˆ—), where uâˆ— =
q
b
a. Or,
uâˆ— =
s
(2 âˆ’ Î¸i
k)2
4 âˆ’ (2 âˆ’ Î¸i
k)2 PÎ½i
k(M i
k)(1 âˆ’ PÎ½i
k(M i
k)).
(52)
118
International Journal on Advances in Systems and Measurements, vol 15 no 3 & 4, year 2022, http://www.iariajournals.org/systems_and_measurements/
2022, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org

We have F(uâˆ—) = âˆ’2
âˆš
ab + c. We consider 2 cases as
follows
1: uâˆ—
â‰¤
1 âˆ’ PÎ½i
k(M i
k). Since F is decreasing on
(uâˆ—, +âˆ), it is also decreasing on (1 âˆ’ PÎ½i
k(M i
k), +âˆ).
Hence, supu>1âˆ’PÎ½i
k (M i
k) F(u) = 0, where the optimal
value holds when u â†’ 1 âˆ’ PÎ½i
k(M i
k) â‡” Î³ â†’ 0, which
violates (30).
2: uâˆ— > 1 âˆ’ PÎ½i
k(M i
k) > 0. Then, the optimal value of
supu>1âˆ’PÎ½i
k (M i
k) F(u) holds when u = uâˆ—. Therefore,
sup
Î»>0,Î²âˆˆR

f i
k(Î», Î²)
	
= F(uâˆ—) = âˆ’2
âˆš
ab + c.
Then, (30) is equivalent to
âˆ’ 2
s
(2 âˆ’ Î¸i
k)2
4

1 âˆ’ (2 âˆ’ Î¸i
k)2
4

PÎ½i
k(M i
k)(1 âˆ’ PÎ½i
k(M i
k))
â‰¥

1 âˆ’ (2 âˆ’ Î¸i
k)2
2

PÎ½i
k(M i
k) + (2 âˆ’ Î¸i
k)2
4
âˆ’ (1 âˆ’ Î±i
k).
(53)
By taking square on both side of (53), we obtain a second
order inequality of PÎ½(K) as follows
PÎ½i
k(M i
k)2 + BPÎ½i
k(M i
k) + C â‰¥ 0,
where B, C are defined in Table II. By solving the equality
x2 + Bx + C = 0, we have two solutions xmin < xmax
where xmin =
âˆ’Bâˆ’
âˆš
âˆ†
2
, xmax =
âˆ’B+
âˆš
âˆ†
2
. It is clear
that (53) is equivalent to either PÎ½i
k(M i
k) â‰¥ xmax or
PÎ½i
k(M i
k) â‰¤ xmin. Since Î¸i
k < 2 âˆ’
âˆš
2, we deduce that
1 âˆ’ (2âˆ’Î¸i
k)2
2
< 0. Therefore, we have

1 âˆ’ (2 âˆ’ Î¸i
k)2
2

xmin + (2 âˆ’ Î¸i
k)2
4
âˆ’ (1 âˆ’ Î±i
k)
>

1 âˆ’ (2 âˆ’ Î¸i
k)2
2

xmax + (2 âˆ’ Î¸i
k)2
4
âˆ’ (1 âˆ’ Î±i
k).
(54)
On the other hand, we have
âˆ’ 2
s
(2 âˆ’ Î¸i
k)2
4

1 âˆ’ (2 âˆ’ Î¸i
k)2
4

x(1 âˆ’ x)
= Â±

1 âˆ’ (2 âˆ’ Î¸i
k)2
2

x + (2 âˆ’ Î¸i
k)2
4
âˆ’ (1 âˆ’ Î±i
k)

,
where
x
=
xmin
or
x
=
xmax.
Note
that
âˆ’2
r
(2âˆ’Î¸i
k)2
4

1 âˆ’ (2âˆ’Î¸i
k)2
4

x(1 âˆ’ x) < 0. Using (54),
we deduce that
âˆ’ 2
s
(2 âˆ’ Î¸i
k)2
4

1 âˆ’ (2 âˆ’ Î¸i
k)2
4

xmax(1 âˆ’ xmax)
=

1 âˆ’ (2 âˆ’ Î¸i
k)2
2

xmax + (2 âˆ’ Î¸i
k)2
4
âˆ’ (1 âˆ’ Î±i
k)

,
and
âˆ’ 2
s
(2 âˆ’ Î¸i
k)2
4

1 âˆ’ (2 âˆ’ Î¸i
k)2
4

xmin(1 âˆ’ xmin)
= âˆ’

1 âˆ’ (2 âˆ’ Î¸i
k)2
2

xmin + (2 âˆ’ Î¸i
k)2
4
âˆ’ (1 âˆ’ Î±i
k)

.
or xmax satisfies (53) while xmin does not satisfy (53).
Then, (53) is equivalent to PÎ½i
k(M i
k) â‰¥ xmax.
â€¢ Case 2: 1 â‰¤ Î²
Î» â‡” Î» â‰¤ Î². We have
Ï•âˆ—
Î²
Î»

= +âˆ,
which implies that supÎ»>0,Î²âˆˆR

f i
k(Î», Î²)
	
= âˆ’âˆ, which
violates (30).
REFERENCES
[1] H. N. Nguyen, A. Lisser, V. V. Singh, and M. Arora, â€œZero-sum games
with distributionally robust chance constraints,â€ in 17th International
Conference on Internet and Web Applications and Services (ICIW),
pp. 7â€“12, IARIA, 2022.
[2] A. A. Cournot, Researches into the Mathematical Principles of the
Theory of Wealth. Macmillan Company, New York, 1897.
[3] J. Nash, â€œNon-cooperative games,â€ Annals of Mathematics, pp. 286â€“295,
1951.
[4] J. von Neumann, â€œOn the theory of games,â€ Math. Annalen, vol. 100,
no. 1, pp. 295â€“320, 1928.
[5] I. Adler, â€œThe equivalence of linear programs and zero-sum games,â€
International Journal of Game Theory, vol. 42, no. 1, pp. 165â€“177,
2013.
[6] G. B. Dantzig, â€œA proof of the equivalence of the programming problem
and the game problem,â€ in Activity analysis of production and allocation
(T. Koopmans, ed.), pp. 330â€“335, John Wiley Sons, New York, 1951.
[7] A. Charnes, â€œConstrained games and linear programming,â€ Proceedings
of National Academy of Sciences of the USA, vol. 39, pp. 639â€“641,
1953.
[8] V. V. Singh and A. Lisser, â€œA second-order cone programming formu-
lation for zero sum game with chance constraints,â€ European Journal
of Operational Research, vol. 275, pp. 839â€“845, 2019.
[9] J. F. Nash Jr, â€œEquilibrium points in n-person games,â€ Proceedings of
the National Academy of Sciences, vol. 36, no. 1, pp. 48â€“49, 1950.
[10] G. Debreu, â€œA social equilibrium existence theorem,â€ Proceedings of
National Academy of Sciences, vol. 38, pp. 886â€“893, 1952.
[11] U. Ravat and U. V. Shanbhag, â€œOn the characterization of solution sets
of smooth and nonsmooth convex stochastic Nash games,â€ SIAM Journal
of Optimization, vol. 21, no. 3, pp. 1168â€“1199, 2011.
[12] V. V. Singh, O. Jouini, and A. Lisser, â€œExistence of Nash equilibrium
for chance-constrained games,â€ Operations Research Letters, vol. 44,
no. 5, pp. 640â€“644, 2016.
[13] V. V. Singh, O. Jouini, and A. Lisser, â€œDistributionally robust chance-
constrained games: Existence and characterization of Nash equilibrium,â€
Optimization Letters, vol. 11, no. 7, pp. 1385â€“1405, 2017.
[14] P. Shen, A. Lisser, V. V. Singh, N. Gupta, and E. Balachandar, â€œGames
with distributionally robust joint chance constraints,â€ Optimization Let-
ters, vol. 15, pp. 1931â€“1953, 2021.
[15] V. V. Singh, A. Lisser, and M. Arora, â€œAn equivalent mathematical
program for games with random constraints,â€ Statistics and Probability
Letters, vol. 174, p. 109092, 2021.
[16] R. Ji and M. A. Lejeune, â€œRisk-budgeting multi-portfolio optimization
with portfolio and marginal risk constraints,â€ Annals of Operations
Research, vol. 262, pp. 547â€“578, 2018.
[17] L. El-Ghaoui, M. Oks, and F. Oustry, â€œWorst-case value-at-risk and
robust portfolio optimization: A conic programming approach,â€ Opera-
tions Research, vol. 51, no. 4, pp. 543â€“556, 2003.
[18] N. Rujeerapaiboon, D. Kuhn, and W. Wiesemann, â€œChebyshev inequal-
ities for products of random variables,â€ Mathematics of Operations
Research, vol. 43, no. 3, pp. 887â€“918, 2018.
119
International Journal on Advances in Systems and Measurements, vol 15 no 3 & 4, year 2022, http://www.iariajournals.org/systems_and_measurements/
2022, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org

[19] J. Cheng, E. Delage, and A. Lisser, â€œDistributionally robust stochastic
knapsack problem,â€ SIAM Journal of Optimization, vol. 24, no. 3,
pp. 1485â€“1506, 2014.
[20] E. Delage and Y. Ye, â€œDistributionally robust optimization under mo-
ment uncertainty with application to data-driven problems,â€ Operations
Research, vol. 58, no. 3, pp. 595â€“612, 2010.
[21] A. Ben-Tal, D. Den Hertog, A. De Waegenaere, B. Melenberg, and
G. Rennen, â€œRobust solutions of optimization problems affected by
uncertain probabilities,â€ Management Science, vol. 59, no. 2, pp. 341â€“
357, 2013.
[22] L. Pardo, Statistical Inference Based on Divergence Measures. Chapman
and Hall/CRC Press, New York, 2018.
[23] R. Jiang and Y. Guan, â€œData-driven chance constrained stochastic
program,â€ Mathematical Programming, vol. 158, no. 1, pp. 291â€“327,
2016.
[24] S. Boyd and L. Vandenberghe, Convex Optimization.
Cambridge
University Press, New York, 2004.
[25] R. Henrion, â€œStructural properties of linear probabilistic constraints,â€
Optimization, vol. 56, no. 4, pp. 425â€“440, 2007.
120
International Journal on Advances in Systems and Measurements, vol 15 no 3 & 4, year 2022, http://www.iariajournals.org/systems_and_measurements/
2022, Â© Copyright by authors, Published under agreement with IARIA - www.iaria.org

