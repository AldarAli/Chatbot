Brain Computer Interfaces as Stroke Rehabilitation Tools: 
Optimization of current strategies 
 
Arnau Espinosa, Rupert Ortner, Christoph Guger  
g.Tec medical engineering GmbH 
Schiedlberg, Austria  
espinosa@gtec.at, ortner@gtec.at, guger@gtec.at 
 
Danut Irimia 
Faculty of Electrical Engineering  
Technical University of Iasi 
Iasi, Romania 
danut.irimia@gmail.com 
 
 
Abstract— Brain-computer interfaces (BCIs) allow human 
communication without using the brain’s normal output 
pathways. A BCI is a tool that converts signals recorded from 
the user’s brain into control signals for different applications. 
Most BCI systems are based on one of the following methods: 
P300; steady-state visually evoked potentials (SSVEP); and 
event-related desynchronization (ERD). Electroencephalogram 
(EEG) activity is typically recorded non-invasively using active 
or passive electrodes mounted on the human scalp. In recent 
years, 
a 
variety 
of 
different 
BCI 
applications 
for 
communication and control were developed. A promising new 
idea is to utilize BCI systems as tools for brain rehabilitation. 
The BCI can detect the user's movement intention and provide 
online feedback for rehabilitation sessions. In many cases, 
stroke patients can re-train their brains to restore effective 
movement. Previous work has continued to show that higher 
density electrode systems can reveal subtleties of brain 
dynamics that are not obvious with only few electrodes. This 
paper tries to optimize current BCI strategies for stroke 
rehabilitation by comparing conventional bar feedback (bFD) 
to immersive 3-D virtual reality feedback (VRFB). Different 
electrode montages were also compared.  
Keywords- Brain Computer Interface; virtual reality; 
electroencephalogram; high density electrodes montage; Stroke 
rehabilitation; 3D Feedback. 
I. 
 INTRODUCTION  
Brain 
- 
Computer Interfaces (BCI) 
allow 
new 
communication channels using different mental states. In a 
typical BCI, a user performs voluntary mental tasks. Each 
task produces distinct patterns of electrical activity in the 
electroencephalogram (EEG). Using monitoring systems and 
on-line signal processing software, automatic tools can 
identify which mental tasks a user performed at specific 
times. Most modern BCI applications rely on one of three 
types of mental tasks, which are associated with different 
types of brain activity: 
Imagined movement, which produces event-related 
desynchronization (ERD) dominant over central electrode 
sites [1, 2]; 
Attention to oscillating visual stimuli, which produces 
steady-state visual evoked potentials (SSVEPs) dominant 
over occipital sites [3]; 
Attention to transient stimuli, which produces the P300 
event-related potential dominant over parietal and occipital 
sites [4, 5]. 
In the last few years, several publications suggested that 
using motor imagery based Brain-Computer Interface 
systems (MI-based BCI) can induce neural plasticity and 
thus serve as important tools to enhance motor rehabilitation 
for stroke patients [6, 7, 8, 9]. Ang et al. [6] reported higher 
2-month post-rehabilitation gain on Fugl-Meyer (FM) 
assessment scale for patients using a BCI-driven robotic 
rehabilitation tool compared to a control group (6.0 versus 
4.0), but without significant results. However, among 
subjects with positive gain, the initial difference of 2.8 
between the two groups was increased to a significant 6.5 
after adjustment for age and gender. Recently, Shindo et al. 
[7] tested the effectiveness of neurorehabilitation training 
when using a BCI for controlling online feedback from a 
hand orthosis. The motor-driven orthosis was hypothesized 
to help the patient extend his paralyzed fingers from 90 to 50 
degrees. That article also concluded that the therapy 
improved rehabilitation. Grosse-Wentrup et al. summarize 
the state of the art in this research field [10].  
Neurofeedback is a process that uses real-time displays 
of EEG or functional magnetic resonance imagining (fMRI) 
to illustrate brain activity, usually with the goal to control 
central nervous system activity. In MI-based BCIs, 
neurofeedback is critical to optimize the user’s performance. 
As the user practices the skill, sensory and proprioceptive 
(awareness of body position) input initiates feedback 
regulation through the relevant motor circuits. Over time, the 
skill becomes more and more automatic. The learning 
mechanism in this case is similar to learning to ride a bicycle 
[2]. Hence, the feedback must reflect the user’s task in an 
appropriate way. For example, when using the BCI for motor 
rehabilitation, the feedback should be similar to the motor 
activity.   
In [9], Ramos-Murguialday et al. investigated an online 
proprioceptive BCI system linking hand movements and 
brain oscillations, eliciting implicit learning effects and 
producing an increase in sensory-motor rhythms (SMR) 
related neural network excitation during motor imagery, 
passive and active movement. Their results demonstrated 
that the use of contingent positive proprioceptive feedback 
BCI enhanced SMR desynchronization during motor tasks. 
42
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

In this study, two different feedback strategies that can be 
used for a rehabilitation task are evaluated. During two 
sessions, the participants were asked to perform MI of either 
the right or left hand (in random order) as dictated by a 
visual paradigm. The first feedback strategy shows the hands 
of an avatar in a 3-D Virtual Reality Feedback environment 
(VRFB; see section II). Either the left or the right hand of the 
avatar moves according to the MI. For comparison, a popular 
strategy (bFB, e.g., in [1]) was used. Here the feedback 
entails the movement of a bar on the computer screen. This 
bar always starts in the middle of the screen and extends 
either to the left or right side of the screen, according to the 
detected motor imagination. Nine subjects were recorded 
with 63 EEG channels. Two subjects performed the same 
tasks using 63 and 27 channels (see Fig. 1 and 2). For these 
two persons, we evaluated the resulting accuracy difference. 
 Recently, Neuper and colleagues compared different 
BCI feedback strategies [11]. There, the realistic feedback 
consisted of a hand grasping a target, and the bar feedback 
was similar to the present study. While Neuper used only 
three bipolar channels for the classification, the present study 
used a common spatial patterns (CSP) approach that takes 
advantage of the high number of EEG channels.  
In the second section of this paper, subsections A and B 
describe the mathematical approach of the CSP method used 
for classification and the data analysis process. Subsections 
C and D present the workflow during one MI-based BCI 
session and the evaluated feedback strategies. 
 
II. 
METHODS 
A. 
Common spatial patterns 
The method of CSP is often used to discriminate two 
motor imagery tasks [12] and was first used for extracting 
abnormal components from the clinical EEG [13]. By 
applying the simultaneous diagonalization of two covariance 
matrices, researchers can construct new time series that 
maximize the variance for one task, while minimizing it for 
the other one. 
Given N channels of EEG for each left and right trial, the 
CSP method gives an N x N projection matrix. This matrix is 
a set of subject-dependent spatial patterns, which reflect the 
specific activation of cortical areas during hand movement 
imagination. 
With 
the 
projection 
matrix 
W, 
the 
decomposition of a single trial (denoted by X) is described 
by: 

Z WX


This transformation projects the variance of X onto the 
rows of Z and results in N new time series. The columns of 
W-1 are a set of CSPs and can be considered time-invariant 
EEG source distributions. 
Due to the definition of W, the variance for a left 
movement imagination is largest in the first row of Z and 
decreases with the increasing number of the subsequent 
rows. The opposite occurs for a trial with right motor 
imagery. For classification of the left and right trials, the 
variances have to be extracted as reliable features of the 
newly designed N time series. However, it is not necessary to 
calculate the variances of all N time series. The method 
provides a dimensionality reduction of the EEG. Mueller-
Gerking and colleagues [14] showed that the optimal number 
of common spatial patterns is four. Following their results, 
after building the projection matrix W from an artifact 
corrected training set XT, only the first and last two rows 
(p=4) of W are used to process  new input data X. Then the 
variance (VARp) of the resulting four time series is 
calculated for a time window T:  

  




T
t
p t
p
Z
VAR
1
2 

After normalizing and log-transforming, four feature 
vectors are obtained. 










 
4
1
log
p
p
p
p
VAR
VAR
f


With these four features, a linear discriminant analysis 
(LDA) classification is done to categorize the movement 
either as left-hand or right-hand. 
B. 
Data processing 
EEG data were recorded over 63 positions (see Fig. 1) or 27 
channels (see Fig. 2) of the motor cortex, using active 
electrodes (g.LADYbird, g.tec medical engineering GmbH, 
Austria). The single small spots show the electrode positions  
with 63 or 27 channels. C3, Cz and C4 are marked 
separately. A multichannel EEG-amplifier was used 
(g.HIamp, g.tec medical engineering GmbH) to record the 
data with a sampling frequency of 256 Hz. The workflow 
model is shown in Fig. 3. The sampled data went into a 
bandpass filter (Butterworth, 5th order) between 8 Hz and 30 
Hz before the four spatial filters were applied. The variance 
was computed for a moving window of one second. 
Normalization is done according to Eq. (3). Finally, the LDA 
classification drives the feedback block of the paradigm. 
C. 
Paradigm and sessions 
Before the tests started, the healthy users (all male right 
handed persons between 25 and 30 years old) were trained 
on motor imagery tasks until their performance was stable. 
After that, the two sessions with different feedback were 
executed. The workflow can be seen in the middle of Fig. 3. 
Each session consisted of seven runs; each run included 20 
trials for left-hand movement and 20 trials for right-hand 
movement in a randomized order. The first run (run1) was 
performed without providing any feedback. The resulting 
data were visually inspected, and trials containing artifacts 
43
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

were manually rejected. These data were used to compute a 
first set of spatial filters (CSP1) and a classifier (WV1). 
With this first set of spatial filters and classifier, another 
four runs (run2, run3, run4, run5) were performed while 
giving online feedback to the user. The merged data of these 
four runs (run 2, 3, 4 and 5) were used again to set up a 
second set of spatial filters (CSP2) and a classifier (WV2) 
that used a higher number of trials and was more accurate. 
Finally, to test the online accuracy during the feedback 
sessions, two more runs (run 6, run 7; merged data: run 6 and 
7) were done. 
Each trial lasted eight seconds; between each trial there 
was a random trial to trial interval between 0.5s and 1.5s to 
avoid adaptation. After two seconds, a beep directed the user 
to the upcoming cue. The cue-phase, during which the 
subject was told to imagine moving either the left or right 
hand, started at 3s and stopped at 4.25s. 
The end of the cue-phase was marked by a second beep. 
The feedback-phase started at 4.25s and lasted until the end 
of the trial (8s). The user was asked to perform the MI from 
the beginning of the cue-phase until the end of the feedback-
phase. 
 
 
Figure 1. Spatial patterns over 63 channels for S1 during VRFB runs 2, 3, 
4 and 5. The upper panel shows the first spatial filter. The lower 
panel is the last spatial filter.  
 
Figure 2. Spatial patterns for S1, during the same runs as in Figure 1. In 
this figure, only 27 channels were used .  
 
 
 
Figure 3. Workflow of the model. 
44
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

The error rate can be calculated by comparing the 
presented cue and the classified movement. The error rate, as 
displayed in Table I, was calculated by applying CSP2 and 
WV2 onto the merged datasets run 6 and 7. The classifier 
and the errors were calculated every 500 ms. For every such 
calculation, the classifier was applied to the features and the 
classification result compared to the cue, resulting in the 
error rate that was averaged over all trials. The “accuracy” 
term used in this paper refers to the difference between 100% 
and the calculated error rate. 
D. 
Feedback strategies 
Feedback strategy number one (bar feedback; bFB, see 
Fig. 4) is quite common for motor imagery tasks. A bar 
begins in the middle of the computer screen and extends 
either to the left or the right of the screen. If a left-hand 
movement is detected, the bar grows to the left; for a right-
hand movement, it extends to the right side. The length of 
the bar is proportional to the classified LDA-distance. 
During the cue phase, in addition to the bFB, a red arrow 
points to the left or to the right side of the screen, indicating 
to the user which MI he or she should perform. 
The virtual reality feedback (VRFB) strategy instead uses 
a virtual reality research system (g.VRsys, g.tec medical 
engineering GmbH, Austria). The user sits in front of a 3D-
PowerWall wearing shutter glasses. The size of the 
PowerWall is 3.2m x 2.45m, and the distance between 
PowerWall and user is about 1.5m. The user sees the left and 
right hands of an avatar from a first-person point of view 
(see Fig. 5). The only movement the avatar performs is the 
continuous opening and closing of either the left or the right 
hand. No modulation of the speed of the movement is done. 
During the cue-phase (from second 3 until second 4.25 of the 
experiment), the user needs to know which MI has to be 
performed. In the VRFB task, the opening/closing of one of 
the hands provides this information. After second 4.25, a 
second beep appears, and the observed movement of the 
avatar is the feedback to the performed MI. 
III. 
RESULTS 
We first compared results with 27 versus 63 channels 
across two subjects. For each session, the averaged error rate 
over all trials and over the single time-steps starting from 
3.5s until 8s is shown. Table I summarizes the results from 
these subjects, and a third subject (S3) who was only tested 
with 27 channels. These values reflect the accuracy resulting 
from applying CSP2 and WV2 to the data of runs 6 and 7, 
and show the online accuracy that the users experienced 
during these runs. The first number in each cell shows rhe 
mean error rate, the number in parentheses shows the 
minimum error for the single time-steps. For S1 and S2, the 
error rate was recorded twice: once with all 63 channels and 
again with only 27 channels (see Fig. 2). 
These data only reflect estimated error rates that the user 
would have experienced if only the subset of 27 electrodes 
would have been used. For S3, only the 27 channels were 
recorded. In three out of four sessions, the error rate 
increased as the number of electrodes was reduced, but in 
one session, it increased from 14.8% to 19.8% (S1, VFRB). 
The minimum error rate increased in three sessions and 
stayed constant in one of them (S1, bFB). The only 
exception where the mean error was higher for 63 channels 
than for 27 was for subject S1, while using virtual reality 
feedback. The main reason for this exception was the artifact 
contaminated EEG signal recorded by one of the electrodes 
placed on the forehead, where the conductive gel dried while 
performing the first 5 runs of the session. 
Fig. 6 shows an example of the error rate from S1 during 
the two sessions that used all 63 channels for classification. 
The black vertical line at second no. 3 indicates the onset of 
the cue.  
The error rate before the cue is about 50 percent and then 
drops below ten percent for both sessions. It stays below ten 
percent from second 5.5 until the end of the trial. 
 
TABLE I.  
RESULTS FROM THE SIX SESSIONS  
 
bFB 
VRFB 
 
Mean Err. (Min. Err.) (%) 
Mean Err. (Min. Err.) (%) 
Subject 
27ch 
63ch 
27ch 
63ch  
S1 
12.8 (2.5) 
12.75 (2.5) 
14.8 (5) 
19.8 (4.5) 
S2 
20.8 (11.25) 
19.9 (5.0) 
25 (12.5) 
19.2 (5.9) 
S3 
25.0 (8.0) 
  
21.8 (10.0) 
  
mean 
19.5 (7.25) 
16.3 (3.75) 
20.5 (10.1) 
19.5 (5.2) 
 
 
 
Figure 4. Bar feedback (bFB). 
 
 
 
Figure 5. Virtual reality feedback (VRFB). 
45
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

 
Figure 6. Error rate from the two feedback runs for S1. The vertical bar at 
3 seconds indicates the cue onset. 
 
TABLE II.  
ACCURACY OF 7 SUBJECTS USING THE 63 CHANNEL 
SYSTEM. 
 
bFB (63ch) 
VRFB (63ch) 
Subject 
Mean Err. 
(%) 
Min. Err. 
(%) 
Mean Err. 
(%) 
Min Err. 
(%) 
S4 
42.30 
33.80 
37.30 
31.30 
S5 
5.50 
0.00 
3.20 
0.00 
S6 
35.50 
20.00 
37 
25.00 
S7 
45.70 
37.50 
30.70 
25.00 
S8 
5.20 
2.50 
14.10 
5.00 
S9 
17.00 
11.30 
5 
1.30 
S10 
3.90 
1.30 
4.60 
0.00 
mean 
22.16 
15.20 
18.84 
12.51 
 
Table II summarizes the accuracy results of the seven 
subjects using all 63 channels. The first number shows the 
mean error rate and the second number shows the minimum 
error rate. The averaged and minimal error rates have been 
calculated using the same methods as Table I. The results 
show a significant performance variance between subjects. 
In three out of seven subjects, the error rate increased 
with the VRFB, but overall, the bFB yielded worse results 
compared to the virtual reality (S4, S5, S7 and S9). Better 
results are under 5% error in 3 subjects (S5, S6 and S10). 
IV. 
CONCLUSIONS 
 This study compared two different feedback strategies 
for performing MI for stroke rehabilitation. The VRFB 
provided realistic feedback that was similar to the imagined 
movements. Hence, we expected this strategy would lead to 
better classification. This hypothesis was not consistent with 
the results. In fact, performance was slightly worse with the 
VRFB in comparison to the bFB sessions. After the sessions, 
subjects said that it was quite disturbing when the classifier 
erred, and hence the “wrong” hand moved during the VRFB 
session. We propose that this mismatch between expected 
and actual feedback was primarily responsible for both this 
cognitive dissonance and worse performance. In future 
studies, we will only feedback when the correct hand is 
classified. 
The BCI performs better using 63 EEG channels instead 
of 27. This result should encourage the use of larger 
montages. Furthermore, the comparison of the spatial 
patterns shows that electrodes that are mounted over the 
motor cortex and near C3 and C4 (which are present in the 
63 and 27 channel configurations) are the most important. 
Furthermore, some positions that are not part of the 27 
channel-configuration are important for classification.  
The results we obtained with 64 electrodes encourage us 
to test 128 EEG-channel montages in future work. Also, the 
current study only shows results achieved by healthy users. 
A future goal will be to utilize the knowledge obtained here 
for rehabilitation of patients suffering from stroke. 
 
ACKNOWLEDGMENT 
The authors gratefully acknowledge the funding by the 
European Commission under Better, Decoder, Vere, and 
BrainAble projects. 
 
REFERENCES 
[1] C. Guger, G. Edlinger, W. Harkam, I. Niedermayer, and G. 
Pfurtscheller, “How many people are able to operate an EEG-
based brain-computer interface,” IEEE Trans. Neural Systems 
and Rehab. Engng., vol. 11, June 2003, pp. 145-147. 
[2] C. Neuper and G. Pfurtscheller, “Neurofeedback Training for 
BCI Control”, in Brain–Computer Interfaces, Revolutionizing 
Human-Computer Interaction, Springer, 2010, pp. 65-78. 
[3] O. Friman, I. Volosyak, and A. Gräser, “Multiple channel 
detection of steady-state visual evoked potentials for brain-
computer interfaces” IEEE Trans. Biomed. Engng., vol. 54, 
April 2007, pp. 742-750. 
[4] C. Guger, G. Edlinger, W. Harkam, I. Niedermayerm, and G. 
Pfurtscheller, “How many people are able to operate an EEG-
based brain-computer interface,” IEEE Trans. Neural Systems 
and Rehab. Engng., vol. 11, June 2003, pp. 145-147. 
[5] G. Townsend, et. al. “A novel P300-based brain-computer 
interface stimulus presentation paradigm: moving beyond 
rows and columns,” Clin Neurophysiol., vol. 121(7), July 
2010, pp. 1109–1120, 10.1016/j.clinph.2010.01.030 
[6] K. K. Ang, et al. “A clinical study of motor imagery-based 
brain-computer 
interface 
for 
upper 
limb 
robotic 
rehabilitation,” Proc. IEEE Eng. Med. Biol. Soc. (EMBC 
2009) Annual International Conference of the IEEE, 2009, pp. 
5981-5984, doi: 10.1109/IEMBS.2009.5332417. 
[7] K. Shindo, et al., “Effects of Neurofeedback Training with an 
Electroencephalogram-Based BrainComputer Interface for 
Hand Paralysis in Patients with Chronic Stroke: A 
Preliminary Case Series Study,” Journal of Rehabilitation 
Medicine, vol. 43(10), October 2011, pp. 951-957. 
46
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

[8] J.M. Antelis, L. Montesano, A. Ramos-Murguialday, N. 
Birbaumer, J. Minguez, “Continuous decoding of intention to 
move from contralesional hemisphere brain oscillations in 
severely affected chronic stroke patients”, Proc. IEEE Eng. 
Med. Biol. Soc., Annual International Conference of the IEEE 
EMBS, 
2012, 
pp. 
4099-103. 
doi: 
10.1109/ 
EMBC.2012.6346868. 
[9] A. Ramos-Murguialday, M. Schürholz, V. Caggiano, M. 
Wildgruber, A. Caria, E.M. Hammer, S. Halder, N. 
Birbaumer, “Proprioceptive Feedback and Brain Computer 
Interface (BCI) Based Neuroprostheses”, PLoS ONE 7(10): 
e47048. doi: 10.1371/journal.pone.0047048. 
[10] Grosse-Wentrup, M., Mattia, D.,  and Oweiss, K., “Using 
brain–computer interfaces to induce neural plasticity and 
restore function,” Journal of neural engineering, vol. 8(2), 
April 2011, doi:10.1088/1741-2560/8/2/025004 
[11] C. Neuper, R. Scherer, S. Wriessnegger, and G. Pfurtscheller, 
“Motor imagery and action observation: modulation of 
sensorimotor brain rhythms during mental control of a brain-
computer interface,” Clin Neurophysiol., vol. 120(2), January 
2009,  pp. 239-247, doi:10.1016/j.clinph.2008.11.015. 
[12] Blankertz, B., Tomioka, R., Lemm, S., Kawanabe, M. and 
Müller, K.-R., “Optimizing Spatial Filters for Robust EEG 
Single-Trial Analysis,” IEEE Signal Processing Magazine, 
vol. 25(1), 2008, pp. 41-56. 
[13] Z. Koles, “The quantitative extraction and topographic 
mapping of the abnormal components in the clinical EEG,” 
Electroencephalography and clinical Neurophysiology, vol.  
79(6), 1991, pp. 440-447, doi: 10.1016/0013-4694(91)90163-
X. 
[14] J. Mueller-Gerking, G. Pfurtscheller, and H. Flyvbjerg, 
“Designing optimal spatial filters for single-trial EEG 
classification in a movement task,” Clin Neurophysiol, vol. 
110(5), 1999, pp. 787-798. 
 
47
Copyright (c) IARIA, 2013.     ISBN:  978-1-61208-273-8
COGNITIVE 2013 : The Fifth International Conference on Advanced Cognitive Technologies and Applications

