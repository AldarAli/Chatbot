1
Human-Machine Interaction in Cyber-Physical Production Systems
Henrique Lopes Cardoso*, Jo˜ao Reis*, and Gil Gonc¸alves*
*SYSTEC, Research Center for Systems and Technologies
*FEUP, Faculdade de Engenharia Universidade do Porto, Portugal
*Email: {up201700417, jpreis, gil}@fe.up.pt
Abstract—As factories thrive to produce better and more precise
products, the cognitive load increases and the factory workers
performance starts to affect the results. This paper presents a
possible solution that aims to help the assembly line workers by
reducing their cognitive load when looking for the tasks they need
to execute for each product and consequently help the business.
The proposed solution focuses on a support interface designed to
grab the worker’s attention to the most important information
and uses it to integrate the human in the loop of a Cyber-Physical
System (CPS). In this paper, we present the architecture of the
developed and constructed CPS, which contains the interface, a
robotic arm and an artiﬁcial vision system.
Keywords–CPPS; Support Interface; Cognitive Load; Expertise
Level
I.
INTRODUCTION
As the manufacturing capacity of companies continues to
grow, extending their variety spectrum, the workload felt by the
human element of these production environment increases [1],
and their situational awareness during the operation decreases.
This solution has direct impact on the company’s operators,
since it is where the problem resettles and has an indirect
change on the company’s business. As for the assembly
line operators, it is expected that, with the resolution of the
presented problem, they are more attentive throughout the
work shift leading to a more precise performance which will
prompt a higher success rate and consequently boost their
conﬁdence and motivation. With a successful worker comes
a successful business. Due to the reduced failure level from
the operators, the company is able to produce more, faster and
with a higher quality. This improvement will avoid human and
material resources waste as the products will more likely get a
positive grade when being evaluated by the quality assurance
department.
There could be an enormous variety of combinations of tasks
in each assembly station, which raises the probability of error
if the operator is not certain of how and what set of tasks
to complete to fulﬁll a speciﬁc product’s requirements, and it
can get worse if the factory is capable of producing a large
number of different products. For each product that comes on
the assembly line there is a list of tasks to be completed on
each station on a short time lapse (around 3 minutes, for the
PSA Group) and when there are multiple products in a row
that require the same tasks the operator starts to ignore the
screen because it is not clear that the tasks changed or the
information has bad resolution [2] and simply performs the
same tasks that completed on the previous product. Mistakes
start to appear when suddenly a different product shows up
on the assembly line and the operator was not able to identify
the changes on the support interface. Most of this mistakes,
come from the fact that the operator was not capable to
detect the changes on the screen between each product that
shows up because the interface was developed without taking
into consideration the cognitive load of the employees, due
to the long working shifts, neither their expertise level. In
most production factories that contain an assembly line and
require human intervention during the process, the working
shifts can reach the 16 hours mark and a total of more than 60
hours a week, which is physically and mentally heavy [3],
[4] so there is a need to reduce their mental effort when
it comes to software that was created to assist the operator.
Human operators should not be treated like machines nor
expect that they preform like so as they will not perform
proﬁciently as soon as they integrate the production line. There
is a learning curve that must be taken into consideration and
treated carefully. There is a need to redevelop the support
interface system replacing the current one with another capable
of adapting to the user’s expertise level and also reduce the
operator’s mental effort when interacted with so that it really
becomes a Support Interface instead of just a screen with
information.
In Section 2 - Motivation and Related work, it is described
the motivation to address the problem and some related work
with this topic as well as the objective of the proposed. In
Section 3 - Research question and proposed concept, the reader
will be presented with the developed solution and all the as-
pects that where taken into account during its implementation
related with the Interface. In Section 4 - Scenario, is where
the CPS architecture, elements and sequence of activities are
described and explained. During Section 5 Discussion, the
reader is given a set of arguments that support the motivation
for this problem’s solution, some direct and indirect expected
results with the developed approach and also a few restriction
and frailties of the system. Finally on Section 6 - Conclusion,
there is given a wrap up of the whole problem proposal and
it’s solution.
II.
MOTIVATION AND RELATED WORK
Modern production lines beneﬁt from the Internet of Things
(IoT) and Industrial Cyber Physical Systems (ICPS) technolog-
ical advances to create environments where Smart Connected
Products can inﬂuence its own production process and com-
panies can beneﬁt from Service Based business models [5].
37
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

2
With the Industry 4.0 appearance, the human integrates
the CPS with its own Digital Twin representation, this way,
not only the machines are aware of the existence of other
machines but also of humans with which they can and must
interact. This integration came from need to change the roles
on the collaboration between both parts, from demanding
an adaptation from the human operator to the machine [6],
[7], to becoming the machine to adapt to the human. With
the evolution of the manufacturing paradigm, balancing and
changing the volume-variety relationship became a necessity.
From Mass Production where factories produce large amount
of similar products raising the volume and decreasing the
variety, to the Mass Customization, increasing the product
variety and reducing the volume manufactured of each model
[8]. With this evolution, companies are more agile and ca-
pable of responding to the client’s will which emphasizes
the importance of the human intervention on the assembly
line, bringing the human’s ﬂexibility to adjust to any expected
and unexpected changes [9]. The interplay between humans
and a CPS occurs either by direct manipulation, or with the
help of a mediating user interface and it is best applied in
a Cyber-Physical Production System (CPPS) which comes
from the fusion of cyber, physical, and socio spaces through
Industry 4.0 [10] and where the machines are responsible
for performing the heavier and repetitive operations, while
the human employees are responsible for handling shop-ﬂoor
equipment and supervising processes for high-level decision
making [6], aiming this way for the delivery of a high quality
product, taking advantages of both human and machine’s best
attributes to complete a task.
Normally, workload and awareness issues are handled by
changing the physical element’s (robotic manipulator) au-
tonomy levels, increasing them in order to ease the human
operator’s intervention. However we propose that changes are
made to the support interface, and to the manner in which
it is conveyed to the human operator, providing them with
a tool that affects the operator workload and awareness in
a positive fashion [11]. By now, we have identiﬁed the two
unexplored variables to the development of a support interface
for an assembly line worker. The main objective of this article
is to contribute for an easier, more intuitive and adaptable
interaction of the production line operator with the interface
that provides all the tasks to be executed during the process
as follows:
•
Providing the worker with an interface that is able
to adapt itself to the the user’s expertise and reduce
cognitive load.
This interface will be able to change based on the user’s
success rate over time which is gathered from an evaluation
team that makes sure that every task was executed correctly.
In order to have an adaptive interface and since this is inserted
in a Cyber-Physical Production System, the system needs to
know who is working at each shift which denotes to the need
of having a virtual representation of each operator, creating a
Digital Twin that will communicate with the remaining of the
components as well as hold the information about the operator
so that it can adapt the interface accordingly.
III.
RESEARCH QUESTION AND PROPOSED CONCEPT
The interface is the main aspect of the presented article as
it is the bridge between the Human and the remaining of the
system, it is the machine with which the Human communicates
and interacts.
As a way to identify the worker that is interacting with the
interface, a simple login page was created where the worker
has to insert a four digit login code that represents him in
the system and from this point forward the system has all the
required information to present the correct interface and the
tasks that the worker is capable of executing.
The developed interface is mainly composed of ”cards” that
contain the information regarding each task that the worker
must perform. The interface contains a top bar containing
complementary information such as the Station in which the
worker is working on and the stopwatch indicating how much
time the worker has to ﬁnish the tasks for that product. Right
below this top bar there is a section with a more relevant
information about the product in construction showing the
product’s name and extra features if the product demands so,
also in this section is placed the STOP and RESUME button.
Figure 1: Card with information about the task
These ”cards” (Figure 1) are essentially a rectangle where
all the necessary information about the task is presented,
containing the task’s title on the top part of the card, the task’s
description right bellow the title where it is explained in a more
extensive version how the task must be performed and after
this description, a list with the necessary Assets is presented,
indicating the quantity, code, name, image and the Zone’s letter
in which the worker must place the Asset if applied.
A. Grab user’s attention
By researching about the topic [12], it was found a way of
how one can grab the user’s attention through an interface and
using the acquired knowledge, Figures 2 and 3 where designed
and developed in order to grab user’s attention making sure he
is aware of what is happening on the system.
38
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

3
Figure 2: Card with information about a task that is only present when an
extra package is requested
The ﬁgure above represents a task that has to be executed
and that is why it has the same structure as regular task.
The only difference between the Figure 2 and Figure 1 is
how frequently they appear on the screen. For this project it
was deﬁned a Default set of tasks that must be performed
for every product that may show up for assembly and those
tasks are presented has Figure 1 demonstrates. Whenever a
product has a speciﬁc set of tasks that only belong to that
product they are presented as Figure 2 by changing the border
color to red that represents attention and caution and the title’s
background by adding a colored patterned as a way to enhance
their appearance and grab the worker’s attention to that new
and different task that is crucial for that products overall correct
assembly.
Figure 3: Message shown when waiting for the new product in line
While the Vision system is analysing the working area and
the Robotic Arm is reaching out for the new box of assets,
the worker is presented with the Message that Figure 3 is
showing. This happens so that the user is aware that the product
is complete and a new one is being prepared to get assembled
and by clearing the interface, we are able to attract the user
to the new information. This message is presented with a fat
rounded green border passing out a feeling of success and
achievement. Note that for this message it is used the Depth
and Size illusions to get the user to absorb the most important
information which in case would be the ”GET READY” part
of the message [13], [14], [15].
B. Cognitively Light Interface
In order to make all of the system’s interfaces as light
as possible for the worker, a list of suggestions was taken
into consideration and used as a guide to design them. The
interface contains a clear core area that contains the most
relevant information and instructions which are simple and
concise, as introduced before. Although there is a change on
the interface regarding the level of expertise of a user, the
format is consistent throughout the different interfaces either
if the expertise level changes or if the tasks are unique for a
product.
As to color schema, the taken approach was to keep the most
relevant information with a darker color and the less important
make it clear while having a white background.
C. Adaptive Interface
As it has been referred throughout the document, one of the
goals of this proposal is to develop an interface that is able to
adapt to the user’s expertise level, and that, is accomplished
by assigning an interface to each level of expertise available
which for the tests environment it was deﬁned as being three
levels.
Although these three interfaces vary from one another, their
changes are minimal keeping the fundamental structure intact
avoiding a contrary effect from the one it is aimed for. This
minimal changes rely on the format that the information is
shown to the user regarding the assets as it is the only type of
information that is ﬂexible to changes.
TABLE I: FORMAT OF INFORMATION AVAILABLE FOR EACH
LEVEL OF EXPERTISE
Image
Name
Code
Novice
Yes
Yes
Yes
Intermediate
No
Yes
Yes
Expert
No
No
Yes
Table I gives us information of what is the format of the
task’s information that is presented for each expertise level. As
it is visible, the Novice user is the one with less experience
which means that it is the one who needs more support and
so for each asset that is necessary for a task the card holds an
image, the name and a code that represent the asset. For an
Intermediate user, the asset is described with the name and the
code, ﬁnally for an Expert user, the asset is only represented
by it’s code.
IV.
SCENARIO
As a way to simulate an assembly line section as can be seen
in an industrial environment, a small system was developed
using the previously described interface, a robotic arm and a
camera. This section describes how we were able to get as
close as possible to a real world environment justifying the
appearance of every intervener on the system.
A. Human-in-the-loop of CPPS
The architecture created to test the proposed solution,
demonstrated on Figure 4, is divided into three main com-
ponents each with a smart component (Digital Twin) [16] that
represents it in the digital world and a forth smart component
that is responsible for the connections between all the other
39
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

4
three components and controls the action ﬂow of the system
and it is nominates Process Smart Component.
Figure 4: System’s Architecture
The ﬁrst component is the Support interface developed,
with which the worker interacts where the tasks are displayed
as the product progresses in the assembly line. The commu-
nication with the smart component happens every time a new
product enters the station where the smart component sends
an Id that represents the product, as well as the Time Period
in milliseconds and the support interface communicates with a
database where every task needed to be executed is provided
and then displayed to the worker.
The second component is the Robotic Arm whose job is
to deliver to the worker a box with every asset necessary to
complete the tasks. For this component, the smart component
is given the box position and the ﬁnal position and the arm
picks up the box and drops it at the ﬁnal position where the
worker starts to preform the tasks.
The ﬁnal component present in the system is the Vision
Camera that is responsible of verifying the tasks executed by
the worker and rate them in a speciﬁc scale with which the
algorithm will calculate the expertise level of the worker and
consequently adjust the interface to the user.
B. Test the scenario
A solution found to test the System presented on Figure 4
has the following workﬂow:
1)
Worker joins the Working Area
2)
Worker enters user code
3)
Robotic Arm moves assets box to near the worker
4)
Interface shows tasks
5)
Worker reads tasks
6)
Worker executes tasks
7)
Work time ends
8)
Camera analyses the area
9)
Repeats processes 3 to 8
The test case aims to simulate one Station of the produc-
tion/assembly line from the moment a worker starts the work-
ing shift until the evaluation moment.
In this process, the worker must execute all the tasks pre-
sented on the Interface by placing the assets on the different
areas deﬁned, within the Time Period previously deﬁned and
shown on the interface in a countdown format. The process
starts when the user enters the working station and enters his
user code, after this, the Interface receives the Product being
assembled at the time and gets all the tasks associated with it
from the database, ate the same time, the Robotic Arm grabs
the Box with the Assets and gives it to the user. At this point,
the user has gathered all the conditions to start executing the
tasks. When the time ends, the Vision Camera analyses the
Table Area and veriﬁes the ﬁnal result. In case of emergency,
i.e, the time is ending and the user feels that he wont be able
to ﬁnis the tasks, the user has the ability to press the STOP
button which will stop the whole system including the Robotic
Arm and Timer.
C. How it works
Now that the actions ﬂow for a proper test was presented
we may go a step further on understanding what is actually
happening ”behind the scenes” concerning the communications
and logic associated with the previously described actions ﬂow.
Figure 5: Flow connections between smart components
The above Figure 5 is composed of all the components of the
system that are evolved with the communications that happen
during the test execution, each arrow represents one of those
communications and it’s numerations indicate the data ﬂow
throughout the test case.
40
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

5
1)
User Login;
2)
Interface tells the Process Component that the user is
ready and the system may start;
3)
The Process Component tells the Robotic Arm to start
the movement;
4)
The Robotic Arm informs that the movement is com-
plete;
5)
The Process Component tells the interface which
product is being assembled and how much time the
worker has and so show the tasks to the worker;
6)
The Interface indicates that the time has terminated;
7)
The Process Component tells the Vision system to
start analysing;
8)
The Vision system answers with the objects position
on the working area;
9)
The Process Component passes it out to the Interface;
10)
The Interface saves the evaluation rate of the tasks after
comparing the objects real positions with the expected
ones.
Besides these, there are two other connections that can happen
at any time during the system’s execution and they are activated
by the worker when the Emergency button is pressed. This but-
ton is implemented on the Interface to simulate the Emergency
Stop Handle that is available throughout the entire assembly
line as a last minute resource if the worker feels that he will not
be able to complete all the tasks in time and the whole system
must freeze. For so there are two complementary connections
between the Interface and the Process Component:
1)
The Interface indicates that the emergency button was
clicked to STOP;
2)
The Interface indicates that the emergency button was
clicked to RESUME
V.
DISCUSSION
With the developed support interface, the main goal is
to affect in a positive manner the way the assembly line
workers do their job and this way, as a result of the workers
improvement, contribute for the success of the business in
which it is inserted. This interface was developed having in
mind the workers, their cognitive effort and their expertise
level as these are two of many other factors that inﬂuence the
worker’s performance. With the Cognitively Light approach
to the interface the main goal is to reduce the user’s precious
effort when reading from it and this way keep them more focus
throughout the whole working shift which itself is mentally
and physically demanding. The Expertise side of this solution
brings a huge advantage to the workﬂow of the production line
as a whole as it helps new employees to better integrate the
production line and the same way bring the best of the expert
worker’s performance by adjusting the way the information is
presented making it easy for novices and fast for experts.
With this solution implementation in a production line
environment there are a group of aspects that are expected to
improve either directly or indirectly. Are considered
Direct
improvements any positive aspect related with the production
line workers and Indirect improvements any better aspect
associated with the factory and company in which this solution
is implemented. Here are the expected positive topics:
Direct improvements:
•
Higher motivated workers
•
More focus workers
•
More energized workers
Indirect improvements:
•
Faster production
•
Less waste
•
Happier clients
•
More production variety
The presented interface was designed and developed having
in mind that it could be used by any type of user with full
mental and physical capabilities, regardless their gender, age
our ability with technology and that is why the it was thought
to have the least input from the user as possible, making it an
almost read only interface.
A. Restrictions/Frailties of the CPS
As everything in the world, this CPS also has a few
restrictions and frailties from each component on the system
that limit the tests and consequently delay the evolution process
demanding a higher number of tests and participants since the
tests complexity is also limited.
Interface:
•
Requires user input from external mouse controller;
Robotic Arm:
•
Maximum payload weight of 5 kilograms;
•
Maximum reach 0,85 meters;
Artiﬁcial Vision system:
•
Only able to detect Yellow, Green and Blue objects;
•
Not able to distinguish objects by their shape;
The described restriction are related to the current state of the
Cyber Physical System (CPS) which could be improved with
extra implementations.
VI.
CONCLUSION
Expertise and cognitive levels are two of many aspects that
inﬂuence a worker’s performance and with the presented article
we are introduced to a new approach for the support interface
that guides the workers throughout the assembly process that
helps to reduce the cognitive level and adapt to the expertise
and this way help to grow the business. By bringing the worker
to the CPPS and enabling a digital communication between
him and the rest of the system it is possible to adapt the
machines to the humans. Throughout this article, the reader
is presented with the design of this support interface and a
proposal of a CPS in which the human is part of.
41
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

6
REFERENCES
[1]
B. J. Pine, B. Victor, and A. C. Boynton, “Making mass customization
work,” Harvard business review, vol. 71, no. 5, 1993, pp. 108–11.
[2]
M. Sondalini. Unearth the answers and solve the causes of human
error in your company by understanding the hidden truths in human
error rate tables. Available at https://www.lifetime-reliability.com/cms/
tutorials/reliability-engineering/human error rate table insights/.
[3]
F. L. Association. Examining the impact of long hours on factory work-
ers. Available at http://www.fairlabor.org/blog/entry/examining-impact-
long-hours-factory-workers. [retrieved: September, 2011]
[4]
A. Burney. The life of a chinese factory worker. Available at https:
//woman.thenest.com/life-chinese-factory-worker-9239.html.
[5]
L. Neto, A. L. Madsen, R. Silva, J. Reis, P. McIntyre, and G. Gonc¸alves,
“A component framework as an enabler for industrial cyber physical
systems,” 2018.
[6]
L. Ant˜ao, “Cooperative human-machine interaction in industrial envi-
ronments,” Ph.D. dissertation, Faculdade de Engenharia da Universidade
do Porto, 2017.
[7]
L. Ant˜ao, R. Pinto, J. Reis, G. Gonc¸alves, and F. L. Pereira, “Cooper-
ative human-machine interaction in industrial environments,” 2018.
[8]
S. J. Hu, “Evolving paradigms of manufacturing: From mass production
to mass customization and personalization,” Proceedings of the Third
Conference on Object-Oriented Technologies and Systems, 2013.
[9]
I. Graessler and A. Poehler, “Integration of a digital twin as human
representation in a scheduling procedure of a cyber-physical production
system,” 2017.
[10]
F. Ansari, M. Khobreh, U. Seidenberg, and W. Sihn, “A problem-solving
ontology for human-centered cyber physical production systems,” Au-
gust 2018.
[11]
C. Fuchs, S. Ferreira, G. Gonc¸alves, and J. Sousa, “Adaptive consoles
for supervisory control of multiple unmanned aerial vehicles,” 2013.
[12]
J. Johnson, “Designing with the mind in mind: Simple guide to
understanding user interface design rules,” 2010.
[13]
S. Bradley. 11 ways to add depth to a design. Available at https:
//vanseodesign.com/web-design/pictorial-depth-cues/. [retrieved: Jan-
uary, 2012]
[14]
W. Zieli´nski. How to use contrast in ui design. Available at https:
//blog.prototypr.io/how-contrast-works-in-ui-design-21bf75a5a2bf. [re-
trieved: December, 2016]
[15]
J. Kliever. Designing with contrast: 20 tips from a designer. Available
at https://www.canva.com/learn/contrasting-colors/.
[16]
J. Reis, R. Pinto, and G. Gonc¸alves, “Human-centered application using
cyber-physical production system,” 2017.
42
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-723-8
INTELLI 2019 : The Eighth International Conference on Intelligent Systems and Applications

