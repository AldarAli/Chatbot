Cognitive Decision Support for Industrial Product Life Cycles: A Position Paper
Stefan Thalmann∥∗∗, Heimo Gursch†, Josef Suschnigg∗, Milot Gashi∗, Helmut Ennsbrunner‡,
Anna Katharina Fuchs§, Tobias Schreck ∗∗, Belgin Mutlu ∗, J¨urgen Mangler¶, Gerti Kappl††¶, Christian Huemer ††¶,
and Stefanie Lindstaedt ∗∗†
∗Pro2Future, Graz, Austria
∥University of Graz, Austria
†Know-Center, Graz, Austria
‡Fronius International, Pettenbach, Austria
§AVL List, Graz, Austria
¶Center For Digital Production, Vienna, Austria
∗∗ Graz University of Technology, Graz, Austria
†† TU Wien, Vienna, Austria
email: stefan.thalmann@uni-graz.at, josef.suschnigg@pro2future.at, milot.gashi@pro2future.at
Abstract—Current trends in manufacturing lead to more intelli-
gent products, produced in global supply chains in shorter cycles,
taking more and complex requirements into account. To manage
this increasing complexity, cognitive decision support systems,
building on data analytic approaches and focusing on the product
life cycle, stages seem a promising approach. With two high-tech
companies (world market leader in their domains) from Austria,
we are approaching this challenge and jointly develop cognitive
decision support systems for three real world industrial use cases.
Within this position paper, we introduce our understanding of
cognitive decision support and we introduce three industrial use
cases, focusing on the requirements for cognitive decision support.
Finally, we describe our preliminary solution approach for each
use case and our next steps.
Keywords–Product Life Cycle; Validation; Big Data Value
Chain.
I.
INTRODUCTION
Manufacturers are experiencing the request for ever more
intelligent products in shorter cycles from their customers. At
the same time, manufacturers are also facing increasing cost
pressures from global supply chains and increasingly complex
regulatory requirements. Consequently, a holistic view of the
Product Life Cycle (PLC) is a necessity to analyse and to man-
age these conﬂicting requirements. PLC management considers
information describing the design, development, validation,
production, usage, maintenance and disposal phase of a prod-
uct. The collected data from these stages is not limited to data
directly related to the design of the product, e.g., speciﬁcations,
or material usage. Moreover, it includes aspects related to the
product (e.g., change orders, procedures, suppliers, workﬂows,
etc.), as well as aspects related to the product (e.g., change
orders, procedures, suppliers, or workﬂows) [1] [2].
Collecting this data is a ﬁrst step. Importantly, the data
provides the opportunity to extract valuable knowledge from
it to derive insights signiﬁcant enough to trigger improvements
on any stage of the product life cycle. Hence, data analytics
approaches can help to extract actionable knowledge from the
data, laying the foundation for a better understanding of the
involved processes. Depending on the complexity, coverage
and scale of the product and its life cycle, the extracted
knowledge can be complex and manifold. Decision Support
Systems (DSS) are intended to reﬁne and present the extracted
knowledge, since they select the right information for a person
working on a particular task in a given stage of a product life
cycle [3] [4]. Based data analytic approaches they are also
named data driven DSS [5].
This paper reports from research efforts of a consortium
formed by industry and academia to tackle this challenge,
speciﬁcally, the research center Pro2Future and the industrial
partners AVL LIST GmbH (AVL) and Fronius International
GmbH (Fronius). Both industrial partners aim to leverage the
potential of cognitive DSS based on data analytic approaches.
AVL and Fronius are already adopting the Internet of Things
(IoT) paradigm by creating connected products, which are
constantly collecting data about their usage. This creates the
option of new data driven approaches towards cognitive DSS,
which we investigate in three different use cases. Each of
the use cases offers the option to research various aspects of
cognitive DSS, applied to a speciﬁc application domain. Due
to the importance and the complexity, we investigate novel
approaches outlined in this paper. The strategic goal of this
joint project is to investigate the potential of cognitive DSS in
the context of the PLC in industry.
This paper is organised as follows: The second section
gives a brief overview of research conducted in either cognitive
DSS and the product life cycle. The third section describes
three use cases on how engineers can be supported in their
work by DSS. Based on the use cases, the forth section dis-
cusses difﬁculties in integrating such systems into the industry,
whereas the last section gives an outlook for future work of
the three use cases separately.
II.
BACKGROUND
A. Cognitive Decision Support Systems
The overarching aim of decision support is to give users
the support for making better decisions [6]. Decision support
is particularly relevant for complex decision making problems,
3
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

where human deciders cannot process all relevant data in
time and in full detail for the decision, due to data volume,
velocity or complexity. Current developments, including IoT
or Industry 4.0, lead to an overwhelming amount of data
available for decision making [7]. Consequently, the demand
for decision support, during the whole decision process, also
increases [5]. To handle the complexity and volume of such
data driven decision problems, the decision making needs to
be supported by Information Technology (IT) [8].
DSS aim to help decision makers in utilising data and
models in solving unstructured or semi-structured problems,
to improve the decision quality [10]. A common approach
focuses on understanding the decision problem ﬁrst, and then
breaks down the decision-making process into several sub-
processes [11]. These smaller problems can then be addressed
by mathematical or algorithmic solutions [12], after the de-
cision has been structured [13]. The disadvantage of this
“classical” DSS is, that they are designed for one speciﬁc
decision problem and that it is difﬁcult to adapt them to new or
changed decision problems [14]. However, the digitisation of
industrial processes demands a high level of adaptability and
ﬂexibility [15]. Hence, more ﬂexible and cognitive approaches,
applicable to huge data sets with varying properties and
inherent format variety, are needed [16].
Cognitive computing, in general, aims to develop coherent,
uniﬁed, universal mechanisms, which are able to adapt to
new situations and are inspired by the human mind [17].
More speciﬁcally, cognitive systems rebuild aspects of human
thinking while adding the ability to handle big data sets [18].
Especially, the ability to handle big data sets is crucial for the
new emerging data-based decision problems. In the scope of
DSS, a cognitive system can give contextual insights from the
model, which is able to generate hypotheses in terms of giving
possible explanations, and to continuously learn from the input
data over time [14]. Summing up, in the context of our work
we deﬁne:
Cognitive DSS provide universal mechanisms capable of
adapting to changing data sets, to improve the decision quality.
Thereby, universal mechanisms refer to the ability to contin-
uously learn from the input data and to generate hypotheses
based on this learning. Improvement in the decision quality
means, that cognitive DSS present insights from big data sets
to decision makers in such a way, that the decision quality
increases.
B. Product Life Cycle
The PLC is a process describing stages of a product from
conceptional design, over production and usage, to the end
of life [2]. Due to the so-called forth industrial revolution,
big data plays an increasingly important role in the modern
industry and offers potential beneﬁts for several industry
sectors [19]. The usage of data can create value for industry
in many ways including increased productivity, better product
quality and higher competitiveness, on both the customer and
company side [20]. Since each of the process stages are
independent, it is necessary to implement a data-value chain for
each of the product life cycle stages separately [21]. Figure 1
depicts the relation between the PLC, the big data value chain
and how data and knowledge are exchanged between the two
processes [9]. This work picks up on these ideas and focuses
on the data usage process for the PLC validation stage, the
production stage and the in-use/service stage.
III.
USE CASES
The following use cases explain data usage in several stages
of the speciﬁc PLCs of our industry partners, implementing
cognitive decision support in different ways.
A. Powertrain Veriﬁcation and Validation
1) Context: An important aspect of AVL’s engineering
services is the Veriﬁcation and Validation (VV) of power-
train prototypes for automotive applications. This VV activity
follows the development stage in the PLC. The use case
introduced by [9] describes how data usage for VV can be
implemented. Veriﬁcation is a quality assurance process to
provide that the product fulﬁls its intended requirements [22]
(“Having developed the right product”). Requirements can
be driven by user needs (e.g., fuel or energy consumption,
engine performance and durability), but also imposed by legal
requirements (e.g., noise emission) [23]. Validation asks, if
the intended functionality can be provided over the product
lifetime (“Having developed the product right”). VV for pow-
ertrains can be either realised in a testing environment, so-
called testbeds, or in a customer usage-oriented test, based
on customer-oriented usage proﬁles (e.g., on road). During
such tests, hundreds of sensor signals are collected from the
powertrain operation as a function of time and/or powertrain
controls, like throttle control. These sensors provide data about
e.g., engine temperature, exhaust gas composition, pressures,
torque and other engineering parameters. Depending on the
purpose of a speciﬁc VV target, those tests can take thousands
of hours for every tested prototype instance under controlled
conditions, leading up to a tremendous amount of data. The
following use case is located in the early VV stage of the PLC
and focuses on functional requirements (mainly veriﬁcation),
but also durability requirements (mainly validation) of an
automotive engine. The tests investigated in this use case are
all conducted on automotive test beds, where the engine is
operated at predeﬁned load conditions.
2) Problem Description: A main challenge in powertrain
testing is to support engineers in assessing the condition
(health) of engines from large amounts of sensor measurement
data taken during test cycles. Many parameters (channels) are
measured during testing. A channel contains a value (also
called sample point) typically every 100 ms which corresponds
to a 10 Hz sample rate, but can have sample rates up to multiple
kHz. Depending on the test setup, up to hundreds of channels
can be recorded. It is a challenge for engineers, working with
this data, to observe every channel and to extract relevant
information from it. Depending on the test case, channel mea-
surements may be noisy, or external events may happen which
only get captured indirectly in the measurements. As a simple
solution, engineers manually select a number of channels
based on experience, and deﬁne thresholds for simple anomaly
detection [24]. The challenge of this approach is, that the
thresholds for each sensor need to be deﬁned manually, based
on individual experience. This can be done by experienced
engineers for some well-known sensors, but not for all sensors.
Furthermore, there are complex relationships between the
channels, involving correlations and lead-lag relationships, as
they are not independent from each other. DSS for powertrain
4
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

Figure 1. Transfer of knowledge between product life cycle stages and big data value chain by [9].
testing needs to help the test engineer in monitoring relevant
channels, guiding her or him to relationships and anomalies as
they occur, and predict possible failure cases early on for test
intervention, if needed.
3) Solution Approach: Powertrains are increasingly com-
plex systems and the know-how of domain experts is an indis-
pensable resource for a condition monitoring system. Research
on time series analysis has provided numerous algorithms to
detect trends, patterns and outliers in data [25]. We follow an
approach based on interactive visual data analysis (or visual
analytics). The idea is to combine data analysis algorithms
with appropriate visual representations, from which the expert
can efﬁciently perceive patterns found by the algorithms, and
by which he or she can interact with model parameters, and
drill down into data details for conﬁrmation and exploration
tasks. Visual analytics applications for industrial sensor data
have been developed for several applications recently. In [26], a
general approach for industrial sensor data has been proposed.
[27] focuses on predictive maintenance in the production stage
and [28] focuses on the in-use phase of the PLC, describing
more speciﬁc solutions. The SignalLens system [29] allows
to monitor large time series using an efﬁcient focus-and-
context visualization and representing features of interest to
guide the visual inspection by the expert. Approaches such as
these, aim for scalability of the analysis with large amounts
of data. In general, it is promising to combine the strengths
of human experts (background knowledge, abstract problem-
solving, etc.) and of computational data analysis (e.g., fast al-
gorithmic search for well-speciﬁed patterns in large data) [30].
To visualise time-dependent data several promising techniques
exist, including HorizonGraphs, RiverTheme Graphs or Heat
Maps [31], which could support the expert in exploring large
amounts of sensor data.
In addition to the visualisation techniques, computational
models can be trained for classiﬁcation, regression, clustering
or pattern recognition. Since engineers can have a better
understanding about the involved processes and parameters,
they should be supported in distinguishing between rare events
and true anomalies. In an unsupervised machine learning sce-
nario, the engineer can be supported by visually highlighting
potentially interesting outlying data and data patterns which
occur frequently. Based on such comparison, the engineer can
decide if an anomaly is relevant and needs further inspection,
or is transient. We are currently experimenting with showing
composite anomaly scores for a sequence of test cycles. By
comparing the measurements between cycles, experts can
quickly recognise larger differences in measurements, hinting
at possible anomalies for further inspection. Figure 2 illustrates
a glyph-based design to visualise anomalies in industrial test
cycles. It aggregates two different algorithms for anomaly
detection (top and bottom circular sector) and encodes the
anomaly scores by the intensity of red for visual perception of
humans. This design can be adapted for other datasets, as long
as they are collected from cyclic data, since those cycles has
been identiﬁed to be suitable as the granularity level for data
visualisation and analysis. However, cyclic data is reasoned by
the repetitive behaviour of many industrial tasks. Therefore,
the concept could be applicable on other industrial domains as
well.
The interaction of a domain expert with the visualisation
can be learned by the model in terms of parameter reﬁnement
and future decision support. This learning of domain expertise
in a cognitive model is also the key to make the desired
DSS, based on visual analytics, cognitive. At the end of the
workﬂow new knowledge is discovered, can be applied to
new products and lead to a constantly improving condition
monitoring system.
B. Welding Machine End Of Line
1) Context: The Final Test System (FTS), at the end of the
manufacturing process, is a crucial stage concerning the PLC.
In our application, every produced device must accomplish
a successful quality check by the FTS before it is sent to the
customer. In other words, each produced device has to undergo
a quality test as a ﬁnal inspection by the FTS.
The FTS fully automatically measures about 300 different
parameters and the process is supervised by an experienced
employee. For the test, three possible results are speciﬁed:
5
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

Figure 2. Glyph-based visualisation of anomaly scores. The outer segments
show different anomaly scores, while the center shows an aggregate score.
Firstly, the device passes all measurements in the ﬁrst run.
Secondly, the device passes the test successfully after multiple
iterations of the test and revisions. Thirdly, the device fails,
even after possible re-takes of measurements. In the ﬁrst and
the second case, the device is declared to work properly and
is ready for shipping to the customer. In the third case, the
device will be handed over to the repair centre for further
investigations. Hence, the FTS collects a large amount of data
about the devices and their conditions when passing or failing
the test.
2) Problem Description: When a device has an incident,
which cannot be solved by the customer, no FTS is at hand
to investigate the actual cause of device failure. Instead, a
maintenance procedure is started, and a repair team is sent
to the customer to identify the cause of the failure. Once, a
diagnosis is made the identiﬁed parts causing the failure will
be replaced with new ones.
This diagnosis process is not trivial, since the repair team
is obligated to recognise the cause direct in the ﬁeld with
far less sophisticated equipment than the FTS. The process of
failure identiﬁcation is complex and requires a knowledgeable
and experienced repair team as the amount of the reliable
information is small. Moreover, if the failure cause is unknown,
also the needed resources (e.g., spare parts and repair time)
cannot be known in advance. But particularly in our case, the
number of products in the ﬁeld and especially the product
variants are very high. Therefore, the repair team often needs
to anticipate the required resources in advance, which is time-
consuming, error-prone and in turn, leads to higher costs. The
objective is the creation of a cognitive DSS, which analyses
the FTS data and provides decision support for the repair team
in the ﬁeld. The DSS should use the identiﬁed knowledge
from production data to identify possible failures, based on
the known device behaviour and to recommend suitable repair
strategies. This system should learn from past cases, improve
over time by feedback and be able to transfer the learned to
new products or product variants.
3) Solution Approach: The process of the ﬁnal inspection
is complex regarding both the signiﬁcant number of measure-
ments and the variety of variants and options, respectively.
This means, that there is only a small set of comparable
measurements throughout all devices. This reduces the amount
of usable data and makes the learning more difﬁcult. Only for
a small set of common device features, there is a large volume
of data, but for the different options and variants there is
only a small sample available. Moreover, to provide solutions
that reﬂect the reality it is essential to consider the interde-
pendence between multiple components required to assemble
the system. Therefore, considering multi-component system
challenges [32] [33] and handling these properly could grant
advantages. By employing advanced applied machine learning
approaches (e.g., unsupervised learning methods [34]), com-
mon behaviour amongst different variants and options can be
recognised. Next, rule-based machine learning methods [35]
will be applied to identify associations within the maintenance
data. This step will extract additional knowledge about the
service activities, which will also be incorporated in the DSS.
Finally, apply acquired knowledge to recognise failures also
in previously unseen devices with similar error patterns, thus
supporting the repair team. Moreover, this approach will adapt
the learned parameters by incorporating the new knowledge
gained from the upcoming data leading to a cognitive DSS.
The DSS is therefore capable to aid the worker in the ﬁeld by
predicting the failure causes. Hence, the repair team can better
plan the needed resources thus reducing the repair costs.
C. Welding Machine Maintenance and Service
1) Context: In a modern industrial welding process, main-
tenance actions are required to keep the process operating at
its optimal conditions. Within the welding devices, multiple
sensors are integrated providing a condition monitoring of
process critical parameters. Commonly the monitored param-
eters include information about the voltage, current, or power
of each individual welding. Furthermore, information such as
the conﬁguration settings of the welding device, identiﬁcation
numbers of the welded component, etc. are also collected
during this process. While the collection of this process data is
commonly automated, collection of data about the maintenance
actions taken, often require the involvement of workers. For
an immaculate data collection, a data collection system is
provided, which protocol the maintenance action performed
on the welding device. Due to the involvement of the worker
during this process, this data collection is more laborious and
error-prone compared to a fully automated data collection.
2) Problem Description: A common maintenance proce-
dure is conveyed by monitoring the welding device in-use by
multiple integrated sensors. The readings from those sensors
can identify the possible need for maintenance actions of vari-
ous components, like changing the contact tip, cleaning the air
ﬁlter, etc. These necessary maintenance actions are conducted
by a worker in the manufacturing process and the execution of
the maintenance action is recorded. The beneﬁt now lies in the
combined recordings of the welding processes’ parameters and
the recorded maintenance actions. The objective is to support
the user in ﬁnding the perfect time to conduct a speciﬁc
maintenance activity so that the productivity and quality of
the welding process is optimal balanced. The cognitive DSS
analyses the process and maintenance data to identify possible
patterns within the data. These patterns are used to assist the
worker by recommending suitable maintenance activities.
The main challenge in the creation of the cognitive DSS is
the automated detection of the need for maintenance activities,
based on data-driven solutions, considering the variety of
variants and options. The product variants and options make
almost all devices different, hence also potentially requiring
6
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

different maintenance actions. These systems consist of mul-
tiple components, which are non-identical and dependent on
each other, leading to a multi-component system.
This high variety decreases the amount of data remarkably
regarding individual systems (variants and options), leading,
on the one hand, to a huge amount of data on the base core
of variants, and on the other hand, to small amounts of data
concerning the speciﬁc variants or options.
3) Solution Approach: Both, the small data challenge and
the various dependencies within multi-components need a
careful handling while preparing the data. Next, the knowledge
extracted from this data is used to improve the cognitive DSS,
which in turn will support the workers during the decision-
making process. Thus, to increase both the reliability and the
performance of the devices, we propose one approach based on
data mining techniques [36], such as temporal pattern mining
[37] and supervised learning methods [38]. First, assuming
that various variants and options are not entirely different, the
aim is to identify a relevant variant by applying exploratory
data analysis methods [39]. In this case, the aim is to de-
ploy a solution for a speciﬁc variant, or subgroup, and later
generalise it over all variants and options. Second, recognise
patterns (e.g., temporal patterns), within the process data, and
relate them to maintenance actions. Third, use the extracted
knowledge from previous step, to predict perfect timing for
maintenance actions. Finally, improve the prediction accuracy
by considering the interdependences between components.
Moreover, the DSS will learn from the actions taken and update
the optimal maintenance relevant parameters regarding each
component separately, leading to the creation of a dynamic
optimal maintenance activities strategy over time.
IV.
DISCUSSION
The success of the project highly depends on the ac-
ceptance of the proposed cognitive DSS by the involved
employees. To ensure this, we involved the potential end
users from an early stage onward consciously in the project
applying a participatory design approach. One important aspect
to engage the end users was that the cognitive DSS is designed
to support the human experts, and not to replace them [5].
Also, both our industry partners are convinced that, in the
foreseeable future, humans cannot be replaced in their core
processes, but need more support as work tasks become more
complex. The cognitive DSS provides assistance and support
by presenting insights from the analysed data, so that the
domain experts can develop a better understanding of the PLC.
This is an opportunity for the companies and their customers
alike by improving productivity, product and support quality
and, hence, increased competitiveness.
The participatory approach is not only applied during the
design and roll out of the ﬁrst version of our cognitive DSS
itself, rather it was also very important to collect and clean
the data in a participatory way. The strong engagement with
the end users was necessary to build the required domain
knowledge and to receive high quality feedback. This en-
gagement created awareness of the fact, that the quality data
collected during the execution of the PLC determines the
decision quality and thus is the secret to the success of the
DSS. The DSS can only be as good as the data it is built upon.
Hence, the end users need to understand that data collection
is a key activity and not only another administrative duty.
Relying on strong awareness building activities, we developed
well-deﬁned data capturing processes for collecting relevant
process and quality data from the end users. In doing so, we
capture domain knowledge to improve the DSS over time and
closing the feedback loop between the PLC and the DSS by
two links. Firstly, the data from the PLC going into the DSS
and, secondly, the information provided by the DSS to the
workers is linked to the PLC. As a result of this cognitive
element, users beneﬁt by improved decision support in return
for their efforts they spend in data collection activities.
All use cases deal with complex multi-component systems,
or even systems of systems creating an immense complexity
by all interactions and connections between the components.
Such complex systems need to be divided into smaller parts
to handle the complexity in a meaningful way. The proposed
multi-component analysis is doing this by the individual esti-
mation of the component’s wear, modelling interdependences
between components, and transferring of insights to different
but comparable sub systems.
The described project is ambitious, complex and requires
a high invest by all involved partners. Thereby, the investment
is not primary in software or servers, rather than in human
resources needed to achieve the required understanding and
awareness for introducing cognitive DSS. This is due to the
fact that continuous high-quality feedback from end users is
needed to ensure the continuous learning of the cognitive DSS.
Despite of these remarkable efforts, the company partners
are convinced that improved decision support will pay off.
Even more they believe that this is key to be successful in a
globalised and digitised world.
V.
OUTLOOK AND FUTURE WORK
We plan to further investigate different promising directions
within our industrial use cases described above. Therefore, in
this section we brieﬂy discuss the future work on each of the
three use cases separately.
A. Powertrain VV use case
It is a common approach in powertrain VV to deﬁne test
cycles with given engine speed and engine torque over time.
In these test cycles, the engine usage is simulated and repeated
until the required total test time is reached. For example,
in a durability test, such cycles take two hours and will be
repeated till the total time of two thousand hours is reached.
We base our design idea on the assumption that those cycles
are highly comparable and elaborate on this in future research.
In theory, all sensors should return similar measurements for
constant engine speed and engine torque. However, some
uncertainties need to be investigated in more detail. Over
time, the measurements of channels can differ by wearing
of the powertrain, environmental changes like temperature,
exchanging parts, faulty sensors or different undocumented
calibrations. Recognition of many of those anomalies should
be done by data analysis. For this purpose, we will investigate
if test cycles can be deﬁned as a granularity model for the
visualisation and the subsequent data analysis approach. This
combination seems promising to highlight anomalies and to
further identify if the conditions of the powertrain worsen over
time. To judge the conditions correctly, the system needs to
learn from user feedback so that the systems capture domain
knowledge over time. An idea for user feedback is to allow
7
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

experts to select and label data patterns corresponding to
certain events. The labels can be taken as training data to train
supervised data analysis methods, e.g., classiﬁers to apply to
new data.
Preliminary ﬁndings show promising results in applying
correlation-based anomaly detection. In this ﬁrst version, a
visualisation depicts the correlation matrix for every channel
combination of every cycle. By subtracting the matrices from
the reference cycle’s correlation matrix, the deviation of two
cycles can be visualised as a heat map. Also, deviating chan-
nels can be intuitively identiﬁed by engineers and further anal-
ysed. Another task for future work, is to investigate and apply
several anomaly detection algorithms. Finding the best model,
regarding predictability of data, for different applications, is a
hard task. Visual analytics offers the capability of engineers
to interact with data through information visualisation and
the underlying data analysis. Suitable techniques need to be
reviewed, and through design studies [40] in collaboration with
the end user engineers, further investigated and developed.
Consequently, the design needs to be evaluated, whereas pair
analytics [41], seems to be a feasible approach to evaluate
visual analytics applications.
B. End of line use case
The small data challenge in our end of line use case, i.e.,
the high variety of products and the small data sets of reference
measurements is a challenge for data driven approaches. In
the solution approach, we aim to identify common parameters
and values behaving similar of all different components of
product variants which are comparable. Finding the right level
of detail for the multi-component systems in the project is
also described as a major challenge in the literature
[32].
Our approach based on exploratory data analysis ﬁrst aims
to identify relationships and interdependencies. Next, the aim
is to recognise common error and fault indicators amongst
different product variants by applying unsupervised learning
approaches. Moreover, rule-based approaches are considered
to recognise patterns within the available data extracting
additional knowledge about the components and the service
activities. Lastly, over the time the decision variables will be
adapted every time new information is provided so that the
DSS learns.
C. Welding use case
The small data challenge also applies to the welding use
case. To solve this challenge for this use case, also similarities
between individual components and modules are identiﬁed
with the same means used in the other two use cases. Hence,
the ﬁrst step is to identify relevant variant, or group of variants
by applying exploratory data analysis methods. Next, within
an appropriate group of variants, so called clusters, machine
learning approaches will be performed to extract indicators to
predict the wear of different components. These indicators are
based on monitoring information obtained automatically and
maintenance action logs provided by the workers conducting
the maintenance. Both data is jointly analysed by frequent
pattern mining approaches to ﬁnd sequences of maintenance
actions on the component and cluster level. Lastly, the learned
parameters (e.g., maintenance strategy) will be adapted every
time new information describing the current health state of the
system and components are provided, respectively. Another
important aspect of our future work is to investigate how
the insights we gain can be used for process improvement.
More speciﬁcally, how these insights can be used to improve
business processes representing a concrete PLC during design
and run time. For this purpose, we want to create an interface
to the process management tool CENTURIO developed in the
research center CDP [42].
ACKNOWLEDGMENT
This research work is done by Pro2Future, AVL List
and Fronius International. Pro2Future is funded within the
Austrian COMET Program-Competence Centers for Excellent
Technologies- under the auspices of the Austrian Federal
Ministry of Transport, Innovation and Technology, the Austrian
Federal Ministry for Digital and Economic Affairs and of the
Provinces of Upper Austria and Styria. COMET is managed
by the Austrian Research Promotion Agency FFG.
REFERENCES
[1]
M. Eigner and R. Stelzer, Product Lifecycle Management, 2nd ed.
Berlin, Germany: Springer, 2009.
[2]
S. Terzi, A. Bouras, D. Dutta, M. Garetti, and D. Kiritsis, “Product
lifecycle management from its history to its new role,” Int. J. Product
Lifecycle Management., vol. 4, no. 4, 2010, pp. 360–389.
[3]
S. LaValle, E. Lesser, R. Shockley, M. S. Hopkins, and N. Kruschwitz,
“Big data, analytics and the path from insights to value,” MIT Sloan
Management Review, vol. 52, no. 2, 2011, pp. 20–31.
[4]
Y. Zhang, S. Ren, Y. Liu, T. Sakao, and D. Huisingh, “A framework
for big data driven product lifecycle management,” Journal of Cleaner
Production, vol. 159, 2017, pp. 229–240.
[5]
S. Thalmann, “Data driven decision support,” it-Information Technol-
ogy, vol. 60, no. 4, 2018, pp. 179–181.
[6]
S. Alter, “A work system view of dss in its fourth decade,” Decision
Support Systems, vol. 38, 12 2004, pp. 319–327.
[7]
F. Kache and S. Seuring, “Challenges and opportunities of digital
information at the intersection of big data analytics and supply chain
management,” International Journal of Operations & Production Man-
agement, vol. 37, no. 1, 2017, pp. 10–36.
[8]
S. Thalmann, Decision Support Framework for Selecting Techniques to
Prepare Knowledge Elements for Adaptive Use.
Innsbruck: Innsbruck
University Press, 2012.
[9]
D. Stanisavljevic, M. Rosenberger, G. Lechner, S. K¨orner, R. Kern,
B. Jeitler, and A. Stocker, “Ein Industrie 4.0-Use Case in der Motoren-
produktion,” Mensch und Computer 2018 - Workshopband, 2018.
[10]
R. H. Sprague, “A framework for the development of decision support
systems,” Management Information Sciences Quarterly, vol. 4, 12 1980,
pp. 1–26.
[11]
M. Carter and C. C. Price, Operations research: A Practical Introduction.
Crc Press, 2000.
[12]
V. L. Sauter, Decision Support Systems for Business Intelligence:
Second Edition.
Wiley, 2014.
[13]
M. A. Eierman, F. Niederman, and C. Adams, “DSS theory: A model
of constructs and relationships,” Decision Support Systems, 1995, pp.
1 – 26.
[14]
J. Hurwitz, M. Kaufman, and A. Bowles, Cognitive Computing and Big
Data Analytics, 1st ed.
Wiley, 2015.
[15]
M. Hermann, T. Pentek, and B. Otto, “Design Principles for Industrie
4.0 Scenarios,” in Proceedings of the 2016 49th Hawaii International
Conference on System Sciences (HICSS), ser. HICSS ’16. Washington,
DC, USA: IEEE Computer Society, 2016, pp. 3928–3937.
[16]
S. Thalmann, J. Mangler, T. Schreck, C. Huemer, M. Streit, F. Pauker,
G. Weichhart, S. Schulte, C. Kittl, C. Pollak et al., “Data analytics
for industrial process improvement a vision paper,” in 2018 IEEE 20th
Conference on Business Informatics (CBI), vol. 2.
IEEE, 2018, pp.
92–96.
[17]
D. S. Modha et al., “Cognitive computing,” Communications of the
ACM, vol. 54, no. 8, 2011, pp. 62–71.
8
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

[18]
Y. Chen, E. Argentinis, and G. Weber, “IBM Watson: How Cognitive
Computing Can Be Applied to Big Data Challenges in Life Sciences
Research,” Clinical Therapeutics, vol. 38, no. 4, 2016, pp. 688–701.
[19]
S. Yin and O. Kaynak, “Big Data for Modern Industry: Challenges and
Trends,” Proceedings of the IEEE, vol. 103, no. 2, 2015, pp. 143–146.
[20]
James et al., “Big data: The next frontier for innovation, competition,
and productivity,” McKinsey Global Institute, 2011, p. 156.
[21]
E. Curry, “The big data value chain: Deﬁnitions, concepts, and theo-
retical approaches,” in New Horizons for a Data-Driven Economy: A
Roadmap for Usage and Exploitation of Big Data in Europe, 2016.
[22]
P. G. Maropoulos and D. Ceglarek, “Design veriﬁcation and validation
in product lifecycle,” CIRP Annals - Manufacturing Technology, vol. 59,
no. 2, 2010, pp. 740–759.
[23]
E. Armengaud, “Industry 4.0 as Digitalization over the Entire Product
Lifecycle: Opportunities in the Automotive Domain,” 2017. [Online].
Available: http://link.springer.com/10.1007/978-3-319-64218-5
[24]
V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A
survey,” ACM computing surveys (CSUR), vol. 41, no. 3, 2009, p. 15.
[25]
M. Gupta, J. Gao, C. C. Aggarwal, and J. Han, “Outlier detection for
temporal data: A survey,” IEEE Transactions on Knowledge and Data
Engineering, vol. 26, no. 9, 2014, pp. 2250–2267.
[26]
S. Kimani, M. Leva, M. Mecella, and T. Catarci, “Visualization of
multidimensional sensor data in industrial engineering,” in 2013 17th
International Conference on Information Visualisation, July 2013, pp.
156–161.
[27]
W. Wu, Y. Zheng, K. Chen, X. Wang, and N. Cao, “A visual analytics
approach for equipment condition monitoring in smart factories of
process industry,” in 2018 IEEE Paciﬁc Visualization Symposium
(PaciﬁcVis), April 2018, pp. 140–149.
[28]
G. Sharma et al., “Multi-sensor visual analytics supported by machine-
learning models,” in 2015 IEEE International Conference on Data
Mining Workshop (ICDMW), 2015, pp. 668–674.
[29]
R. Kincaid, “Signallens: Focus+context applied to electronic time
series,” IEEE Transactions on Visualization and Computer Graphics,
vol. 16, no. 6, Nov 2010, pp. 900–907.
[30]
Keim et al., “Visual analytics: Deﬁnition, process, and challenges,” in
Information visualization.
Springer, 2008, pp. 154–175.
[31]
W. Aigner, S. Miksch, H. Schumann, and C. Tominski, Visualization
of Time-Oriented Data, 1st ed.
Springer, 2011.
[32]
K.-A. Nguyen, P. Do, and A. Grall, “Multi-level predictive mainte-
nance for multi-component systems,” Reliability Engineering & System
Safety, vol. 144, 2015, pp. 83–94.
[33]
A. Van Horenbeek and L. Pintelon, “A dynamic predictive maintenance
policy for complex multi-component systems,” Reliability Engineering
& System Safety, vol. 120, 2013, pp. 39–50.
[34]
T. Hastie, R. Tibshirani, and J. Friedman, “Unsupervised learning,” in
The elements of statistical learning.
Springer, 2009, pp. 485–585.
[35]
B. Liu, W. Hsu, and Y. Ma, “Integrating classiﬁcation and association
rule mining,” in Proceedings of the Fourth International Conference on
Knowledge Discovery and Data Mining, ser. KDD’98.
AAAI Press,
1998, pp. 80–86.
[36]
D. J. Hand, “Data mining,” Encyclopedia of Environmetrics, vol. 2,
2006.
[37]
I. Batal, D. Fradkin, J. Harrison, F. Moerchen, and M. Hauskrecht,
“Mining recent temporal patterns for event detection in multivariate time
series data,” in Proceedings of the 18th ACM SIGKDD international
conference on Knowledge discovery and data mining.
ACM, 2012,
pp. 280–288.
[38]
M. Kuhn and K. Johnson, Applied predictive modeling.
Springer,
2013.
[39]
C. H. Yu, “Exploratory data analysis,” Methods, vol. 2, 1977, pp. 131–
160.
[40]
M. Sedlmair, M. Meyer, and T. Munzner, “Design study methodology:
Reﬂections from the trenches and the stacks,” IEEE Transactions on
Visualization and Computer Graphics, vol. 18, no. 12, Dec 2012, pp.
2431–2440.
[41]
R. Arias-Hernandez, L. T. Kaastra, T. M. Green, and B. Fisher, “Pair
analytics: Capturing reasoning processes in collaborative visual analyt-
ics,” in Proceedings of the 2011 44th Hawaii International Conference
on System Sciences, ser. HICSS ’11.
IEEE Computer Society, 2011,
pp. 1–10.
[42]
F. Pauker, J. Mangler, S. Rinderle-Ma, and C. Pollak, “centurio.work
- modular secure manufacturing orchestration,” in Proceedings of the
Dissertation Award, Demonstration, and Industrial Track at BPM 2018
co-located with 16th International Conference on Business Process
Management (BPM 2018), Sydney, Australia, 2018., 2018, pp. 164–
171.
9
Copyright (c) IARIA, 2019.     ISBN:  978-1-61208-705-4
COGNITIVE 2019 : The Eleventh International Conference on Advanced Cognitive Technologies and Applications

